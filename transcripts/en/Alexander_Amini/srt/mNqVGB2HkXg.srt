1
00:00:02,220 --> 00:00:03,053
Good morning everyone,
as all of a sudden I'm the director of 

2
00:00:06,560 --> 00:00:07,393
IBM Research Cambridge.
It's literally just a few blocks down 

3
00:00:11,341 --> 00:00:12,174
the road.
I've worked probably 20 years in IBM 

4
00:00:14,161 --> 00:00:16,500
research,
primarily out of our New York lab,

5
00:00:17,190 --> 00:00:18,360
but I moved here,
uh,

6
00:00:18,450 --> 00:00:22,380
just uh,
three months ago to really start up this

7
00:00:22,381 --> 00:00:23,214
new ai lab,
a refocus and significantly grow the 

8
00:00:26,731 --> 00:00:28,680
Cambridge lab that we've,
we've already started.

9
00:00:29,400 --> 00:00:34,400
I intentionally chose a somewhat 
provocative title to my,

10
00:00:34,950 --> 00:00:36,810
a talk today.
Um,

11
00:00:37,290 --> 00:00:40,020
the reason I wanted to,
the beyond deep learning,

12
00:00:40,310 --> 00:00:42,660
it's not necessarily to say that you 
know,

13
00:00:42,661 --> 00:00:45,810
all of these deep learning techniques 
are going to be obsolete.

14
00:00:45,811 --> 00:00:49,200
That's definitely not what I'm trying to
say,

15
00:00:49,201 --> 00:00:51,330
but I am trying to say that,
you know,

16
00:00:51,331 --> 00:00:55,620
although there's a lot of exciting 
things that we can do with deep learning

17
00:00:55,621 --> 00:00:58,680
today,
there's also a frontier,

18
00:00:58,760 --> 00:00:59,340
a,
you know,

19
00:00:59,340 --> 00:01:00,173
a space that we can't do very well.
And so I hope to today talk to you 

20
00:01:05,281 --> 00:01:06,270
about,
you know,

21
00:01:06,271 --> 00:01:07,104
kind of what is an area of a boundary 
that we were not able to break through 

22
00:01:11,251 --> 00:01:16,251
at this time that I think is critical 
for machine intelligence,

23
00:01:16,290 --> 00:01:20,520
for artificial general intelligence.
So I'm hoping that today,

24
00:01:20,850 --> 00:01:22,950
uh,
I can set that up for you,

25
00:01:23,140 --> 00:01:24,270
uh,
hopefully,

26
00:01:24,290 --> 00:01:24,840
uh,
you know,

27
00:01:24,840 --> 00:01:25,673
motivate a additional people to come in 
and study this because I really believe 

28
00:01:28,861 --> 00:01:29,694
that it's a,
it's a critical area where we're 

29
00:01:31,390 --> 00:01:33,120
additional breakthroughs are needed.

30
00:01:35,760 --> 00:01:38,760
I'd like to first introduce a IBM 
research.

31
00:01:38,800 --> 00:01:39,780
Uh,
I don't know,

32
00:01:39,830 --> 00:01:40,663
uh,
how many of you actually know about IBM 

33
00:01:42,211 --> 00:01:45,060
research?
Some of you may have heard of us because

34
00:01:45,061 --> 00:01:45,894
of the jeopardy challenge.
So in 2011 we created a computer that 

35
00:01:50,401 --> 00:01:55,050
was able to beat the chest,
the jeopardy champions at that game.

36
00:01:55,310 --> 00:01:57,870
I'm very handily has,
as a matter of fact,

37
00:01:57,930 --> 00:01:58,970
uh,
uh,

38
00:01:59,370 --> 00:02:02,880
some people don't realize that our 
research division is,

39
00:02:02,881 --> 00:02:04,110
uh,
is quite significant.

40
00:02:04,111 --> 00:02:09,111
So we have 3000 people worldwide,
a 12 labs that are doing this research.

41
00:02:09,880 --> 00:02:11,590
Our researchers,
uh,

42
00:02:11,790 --> 00:02:15,110
pursue the same types of accolades that,
you know,

43
00:02:15,180 --> 00:02:20,180
the top university professors go after.
So a Nobel laureates touring awards,

44
00:02:20,731 --> 00:02:24,300
National Academy of Sciences,
National Academy of Technologies.

45
00:02:24,600 --> 00:02:28,190
So we pursue a very rigorous,
uh,

46
00:02:28,191 --> 00:02:29,190
you know,
set of,

47
00:02:29,210 --> 00:02:33,840
of research in the areas that we focus 
on all.

48
00:02:33,930 --> 00:02:35,100
And although I put the,
uh,

49
00:02:35,101 --> 00:02:38,960
the jeopardy challenge up there,
you're only as good as your,

50
00:02:38,961 --> 00:02:40,260
your most recent results.

51
00:02:40,260 --> 00:02:41,093
Right.
So I also wanted to make sure that I 

52
00:02:42,661 --> 00:02:45,810
talked a little bit about things that 
we've done more recently.

53
00:02:45,811 --> 00:02:46,820
So,
uh,

54
00:02:46,830 --> 00:02:48,290
in 2017,
uh,

55
00:02:48,300 --> 00:02:49,980
as an example,
uh,

56
00:02:49,981 --> 00:02:54,810
we created the first 50 cubit,
a quantum computer.

57
00:02:55,730 --> 00:02:58,050
Uh,
most people are kind of,

58
00:02:58,360 --> 00:02:59,090
uh,
you know,

59
00:02:59,090 --> 00:02:59,923
I expect to actually see some people 
announcing some other companies 

60
00:03:02,441 --> 00:03:06,970
announcing simulators for 50 on the 
order of 50 cubits.

61
00:03:07,000 --> 00:03:11,100
And the difference here is that we're 
talking about an actual 50 cubits,

62
00:03:11,130 --> 00:03:13,350
a quantum computer.
Uh,

63
00:03:13,450 --> 00:03:15,190
so we,
we also have the simulators,

64
00:03:15,610 --> 00:03:16,443
but we have the real quantum computers.
I think what's also unique about what 

65
00:03:19,541 --> 00:03:20,374
we're doing is that we're also making 
our quantum computing capabilities 

66
00:03:25,151 --> 00:03:25,984
available through the cloud so that 
people can kind of log in and they can 

67
00:03:28,391 --> 00:03:31,510
experiment and learn about what quantum 
computing is.

68
00:03:31,511 --> 00:03:33,940
So,
so very exciting program for us.

69
00:03:34,560 --> 00:03:35,930
We also,
in 2017,

70
00:03:35,931 --> 00:03:40,600
we were able to show a near linear scale
out in terms of,

71
00:03:40,620 --> 00:03:43,660
you know,
cafe deep learning models on,

72
00:03:43,661 --> 00:03:44,740
on our servers.

73
00:03:45,440 --> 00:03:46,273
We were able to show algorithms that 
were able to exploit the quantum 

74
00:03:50,981 --> 00:03:51,880
advantage.
Uh,

75
00:03:51,910 --> 00:03:56,910
so the idea is that if you,
in order to actually get the speed ups,

76
00:03:57,370 --> 00:03:58,960
uh,
on quantum computers,

77
00:03:59,230 --> 00:04:00,063
you need to be able to map problems into
a form where you can get that 

78
00:04:04,121 --> 00:04:06,070
acceleration.
And when you get that acceleration,

79
00:04:06,071 --> 00:04:06,904
then you're talking about exponential 
acceleration over traditional computers 

80
00:04:10,031 --> 00:04:11,530
that people are using today.
Uh,

81
00:04:11,630 --> 00:04:12,463
so this particular result was an 
algorithm that's able to basically map 

82
00:04:16,240 --> 00:04:18,490
small molecules,
models of small molecules,

83
00:04:18,550 --> 00:04:19,580
uh,
uh,

84
00:04:19,590 --> 00:04:24,590
onto the actual quantum computing system
so that we could demonstrate the ability

85
00:04:25,361 --> 00:04:27,550
to find the lowest energy state.
So,

86
00:04:27,670 --> 00:04:28,503
and,
and get that exponential speed up from 

87
00:04:30,071 --> 00:04:31,090
that.
Um,

88
00:04:31,880 --> 00:04:32,713
you know,
the thing is that in 2017 we were named 

89
00:04:34,620 --> 00:04:35,453
a number one,
a leading corporation for a scientific 

90
00:04:39,700 --> 00:04:42,730
scientific research at a corporate 
institute.

91
00:04:42,731 --> 00:04:44,470
So that's pretty exciting for us.

92
00:04:46,050 --> 00:04:50,740
I also wanted to just tell you a little 
bit about the Mit Watson Mit,

93
00:04:50,741 --> 00:04:51,574
IBM Watson Ai Lab.
It's obviously a very exciting 

94
00:04:54,190 --> 00:04:58,840
announcement for us.
So in September of 2017,

95
00:04:58,841 --> 00:05:03,841
we announced that we were building this,
a $240 million dollar,

96
00:05:04,510 --> 00:05:09,510
a joint effort with mit to pursue 
fundamental advances in ai.

97
00:05:10,900 --> 00:05:13,210
Uh,
the core areas are listed here.

98
00:05:13,211 --> 00:05:15,940
So when I say fundamental advances in 
Ai,

99
00:05:16,030 --> 00:05:17,500
it's really,
again,

100
00:05:17,501 --> 00:05:18,334
recognizing what we can and can't do 
with ai today and then trying to create 

101
00:05:23,171 --> 00:05:28,060
new algorithms to go beyond that.
So examples of problems,

102
00:05:28,090 --> 00:05:31,090
I'm just very quickly that we're 
interested in,

103
00:05:31,091 --> 00:05:33,520
in terms of the,
the new Ai Lab,

104
00:05:33,900 --> 00:05:35,590
uh,
one area is that,

105
00:05:35,920 --> 00:05:36,551
uh,
you know,

106
00:05:36,551 --> 00:05:41,020
learning causal structure from data is a
very challenging problem.

107
00:05:41,370 --> 00:05:42,203
Uh,
we're looking at how we can use data 

108
00:05:44,860 --> 00:05:45,693
that was captured due to a crisper 
mediations are crispr gene in 

109
00:05:50,561 --> 00:05:51,394
activations,
which basically has very large set of 

110
00:05:55,031 --> 00:05:58,280
interventional data where they're 
observing the whole genome.

111
00:05:58,580 --> 00:06:01,580
Um,
and we're going to try to learn a causal

112
00:06:01,581 --> 00:06:02,540
structure,
uh,

113
00:06:02,541 --> 00:06:03,410
you know,
from those,

114
00:06:03,440 --> 00:06:04,700
those intervention.
So that's,

115
00:06:04,720 --> 00:06:08,270
that's one example.
Another example in physics of Ai,

116
00:06:08,660 --> 00:06:10,370
uh,
basically what we're talking about,

117
00:06:10,371 --> 00:06:11,204
there's the ability to have ai help 
quantum computing and quantum computers 

118
00:06:15,141 --> 00:06:18,160
and quantum computers accelerate ai 
algorithms.

119
00:06:18,161 --> 00:06:20,600
So we're looking at problems,
for example,

120
00:06:20,760 --> 00:06:21,593
the machine learning algorithms that 
will help us to manage the state of the 

121
00:06:23,661 --> 00:06:25,460
quantum computer.
Also,

122
00:06:25,480 --> 00:06:26,630
uh,
looking at,

123
00:06:26,700 --> 00:06:27,800
uh,
for example,

124
00:06:27,801 --> 00:06:28,634
the ability to,
knowing what we know about quantum 

125
00:06:30,591 --> 00:06:31,880
computers,
knowing that,

126
00:06:32,030 --> 00:06:32,863
you know,
we're going to be in the small numbers 

127
00:06:34,011 --> 00:06:36,530
of,
of hundreds of cubits for some time,

128
00:06:36,531 --> 00:06:37,364
that the memory bandwidth between a 
traditional computers and the quantum 

129
00:06:40,701 --> 00:06:44,870
computers going to be relative small,
which of the machine learning algorithms

130
00:06:44,871 --> 00:06:48,770
will we be able to map onto those 
systems in order to get that exponential

131
00:06:49,040 --> 00:06:49,460
speed up.

132
00:06:49,460 --> 00:06:52,880
So those are just some of the examples 
of things that we're studying.

133
00:06:53,300 --> 00:06:54,810
Um,
also we,

134
00:06:54,811 --> 00:06:55,644
we feel that right now there are two 
industries that are really ripe for ai 

135
00:06:59,871 --> 00:07:02,930
disruption.
One is healthcare life sciences.

136
00:07:03,320 --> 00:07:07,490
The reason they are ripe for disruption 
is because that community has invested a

137
00:07:07,491 --> 00:07:09,980
lot to create what we refer to a 
structured knowledge.

138
00:07:10,250 --> 00:07:12,500
So you know,
gene ontology,

139
00:07:12,501 --> 00:07:13,630
you know,
Snow Med,

140
00:07:13,640 --> 00:07:14,473
clinical terms,
all of the structured knowledge that we 

141
00:07:15,921 --> 00:07:20,921
can combine with observational data and 
create new algorithms and insecurity.

142
00:07:20,991 --> 00:07:21,824
The reason why cyber security,
the reason why that one is ripe for 

143
00:07:23,781 --> 00:07:28,781
disruption is because if everybody is 
advancing these ai algorithms and people

144
00:07:29,421 --> 00:07:33,320
start to try to use those ai algorithms 
to attack our systems,

145
00:07:33,710 --> 00:07:34,543
it's very important that we also use ai 
algorithms to try to figure out how 

146
00:07:38,361 --> 00:07:41,240
they're going to do that and how to 
defend against that.

147
00:07:41,240 --> 00:07:42,073
So there's some of the examples.
The last one shared prosperity is about 

148
00:07:44,991 --> 00:07:49,991
how do we get nondiscrimination on bias 
morals into the algorithms,

149
00:07:50,961 --> 00:07:51,794
not just training on,
for scale out and accuracy and these 

150
00:07:55,011 --> 00:07:58,270
sorts of things.
All right?

151
00:07:58,310 --> 00:07:59,143
Uh,
we,

152
00:07:59,180 --> 00:08:04,180
we already had our first announcement in
terms of the new mit IBM Watson Ai Lab.

153
00:08:04,760 --> 00:08:09,760
So at nips we announced that we are 
releasing a 1 million video data set.

154
00:08:11,300 --> 00:08:12,133
Uh,
the idea for those of you are familiar 

155
00:08:13,581 --> 00:08:14,414
and you've probably learned a lot in 
this class about how people used image 

156
00:08:17,211 --> 00:08:20,690
net to make new breakthroughs in terms 
of deep learning.

157
00:08:21,100 --> 00:08:21,933
Uh,
just that volume of labeled data meant 

158
00:08:24,021 --> 00:08:27,290
that people could go in and run 
experiments and train networks that they

159
00:08:27,291 --> 00:08:28,740
could never do before.
Uh,

160
00:08:28,850 --> 00:08:30,110
so we've created,
uh,

161
00:08:30,120 --> 00:08:30,600
this,
uh,

162
00:08:30,600 --> 00:08:31,433
this million video data set,
a three second videos were chosen for a 

163
00:08:35,690 --> 00:08:38,510
specific reason.
I'm the lead for this project.

164
00:08:38,510 --> 00:08:40,230
Oh,
deliver is a,

165
00:08:40,280 --> 00:08:43,490
has great expertise,
not only in computer science but also in

166
00:08:43,491 --> 00:08:45,830
cognitive science.
And so it's expected that,

167
00:08:46,110 --> 00:08:46,943
you know,
three seconds is roughly the order of 

168
00:08:48,081 --> 00:08:51,860
times that it takes humans to recognize 
a certain actions as well.

169
00:08:51,861 --> 00:08:54,350
So we're,
we're kind of sticking with that time.

170
00:08:54,930 --> 00:08:55,763
Computers aren't the machine learning 
algorithms that you were learning about 

171
00:08:57,961 --> 00:09:00,390
today aren't able to do this.
Well,

172
00:09:01,440 --> 00:09:05,850
primary learned about so far was how to 
segment images.

173
00:09:05,851 --> 00:09:09,260
How to find objects within images,
how to classify those,

174
00:09:09,290 --> 00:09:11,820
those objects,
but not actions.

175
00:09:12,240 --> 00:09:13,073
And the reason why we also think that 
actions are important is because they 

176
00:09:15,811 --> 00:09:17,040
are composable,
right?

177
00:09:17,041 --> 00:09:20,760
So we want to be able to learn not just 
elemental actions from these videos,

178
00:09:21,000 --> 00:09:21,833
but then to start to think about how you
recognize and detect compositions of 

179
00:09:26,041 --> 00:09:26,874
actions and procedures that people are 
performing because then we can use that 

180
00:09:30,961 --> 00:09:31,794
to start to teach the computers to also 
perform those procedures or to help 

181
00:09:37,951 --> 00:09:41,160
humans to be able to perform those 
procedures better.

182
00:09:44,400 --> 00:09:45,233
Okay.
Now what I want to do is maybe take a 

183
00:09:47,101 --> 00:09:50,700
break from kind of the setup and get 
into the more technical part of the,

184
00:09:50,701 --> 00:09:51,780
uh,
of the talk today.

185
00:09:51,781 --> 00:09:52,650
So,
um,

186
00:09:52,920 --> 00:09:54,600
as I was saying earlier,
you know,

187
00:09:54,660 --> 00:09:57,210
what we've seen recently in deep 
learning is,

188
00:09:57,270 --> 00:09:59,370
is truly all inspiring.
I mean,

189
00:09:59,371 --> 00:10:00,204
in terms of the number of breakthroughs 
over over the last 10 years and 

190
00:10:02,971 --> 00:10:03,804
especially over the last five years,
it is very exciting breakthroughs in 

191
00:10:07,561 --> 00:10:08,410
terms of,
you know,

192
00:10:08,460 --> 00:10:10,890
being able to,
for certain tasks,

193
00:10:11,220 --> 00:10:11,821
uh,
you know,

194
00:10:11,821 --> 00:10:15,120
beat human error rates in terms of 
visual recognition.

195
00:10:15,121 --> 00:10:18,000
And speech,
a speech recognition and so on.

196
00:10:18,290 --> 00:10:19,123
Um,
but my position is that there are still 

197
00:10:22,440 --> 00:10:27,440
huge breakthroughs that are required to 
try to get to machine intelligence.

198
00:10:27,751 --> 00:10:32,751
So some examples of challenges that the 
systems of today aren't able to do.

199
00:10:33,901 --> 00:10:35,760
So one is that,
um,

200
00:10:35,850 --> 00:10:36,683
many,
many of the scenarios in order to get 

201
00:10:38,431 --> 00:10:43,150
the performance that actually is usable 
requires labeled data.

202
00:10:43,150 --> 00:10:43,983
It requires training data where you've 
actually labeled the objects and the 

203
00:10:46,651 --> 00:10:48,990
images and so on.
Um,

204
00:10:49,230 --> 00:10:53,550
while the systems are getting better in 
terms of doing unsupervised learning,

205
00:10:53,600 --> 00:10:54,433
uh,
because of the vast amount of data 

206
00:10:55,561 --> 00:10:57,690
that's available on the web.
Uh,

207
00:10:58,570 --> 00:11:03,570
the problem is that we at IBM care about
Ai for businesses,

208
00:11:03,870 --> 00:11:06,240
right?
And if you think of ai for businesses,

209
00:11:06,450 --> 00:11:11,450
there's just not that much deep domain 
data that we're able to find,

210
00:11:12,540 --> 00:11:14,370
right?
So if you think about the medical field,

211
00:11:14,700 --> 00:11:19,700
very deep expressive relations that are 
required to be understood.

212
00:11:20,330 --> 00:11:22,390
And of course a lot of labeled data.
Uh,

213
00:11:22,500 --> 00:11:23,111
you know,
uh,

214
00:11:23,111 --> 00:11:24,510
if you think of,
you know,

215
00:11:24,511 --> 00:11:25,344
uh,
an airline manufacturer and all of the 

216
00:11:26,910 --> 00:11:27,743
manuals they may have and they'd like to
try to be able to answer questions from 

217
00:11:30,601 --> 00:11:31,434
those and be able to reason and help 
humans understand how to conduct 

218
00:11:34,051 --> 00:11:35,280
procedures within those.

219
00:11:36,420 --> 00:11:37,253
There's not enough data out there on 
those fields in terms of relationships 

220
00:11:40,441 --> 00:11:44,610
and entities and so on for us to train.
So it requires a lot of labeling.

221
00:11:44,611 --> 00:11:45,444
Humans actually going through and 
finding the important entities and 

222
00:11:47,701 --> 00:11:48,534
relationships and so on.
So an important area that we need to be 

223
00:11:51,451 --> 00:11:53,260
able to break through is,
first of all,

224
00:11:53,261 --> 00:11:54,094
why?
Why,

225
00:11:54,130 --> 00:11:54,963
why do these machines,
why do these networks require so much 

226
00:11:57,521 --> 00:12:00,730
data labeled data?
And can we,

227
00:12:00,940 --> 00:12:03,430
can we address that?
Can we make the algorithms better?

228
00:12:04,240 --> 00:12:05,073
The second thing is that you've probably
realized that you train up the 

229
00:12:07,241 --> 00:12:09,580
algorithms and then they're able to 
perform some tasks.

230
00:12:09,880 --> 00:12:12,400
The tasks are getting more and more 
sophisticated,

231
00:12:12,430 --> 00:12:13,263
self driving cars and so on,
but you're still not training this 

232
00:12:16,391 --> 00:12:19,150
network so that it can form many 
different tasks.

233
00:12:19,600 --> 00:12:24,400
And even more importantly,
what happens is that you learn a model,

234
00:12:24,430 --> 00:12:26,200
and even though you may,
as part of the training,

235
00:12:26,201 --> 00:12:29,860
you may have reinforcement learning 
that's not lifelong learning,

236
00:12:29,861 --> 00:12:30,694
that's not just turning the cars out on 
the road and enabling them to continue 

237
00:12:34,601 --> 00:12:39,010
to learn and aggregate information and 
bring that into a representation so that

238
00:12:39,011 --> 00:12:40,800
they can adapt to,
you know,

239
00:12:40,870 --> 00:12:43,750
non stationary environments,
environments that change over time.

240
00:12:44,290 --> 00:12:45,550
Another thing is that,
you know,

241
00:12:45,820 --> 00:12:46,653
when we train these networks,
you kind of get it down to a certain 

242
00:12:48,221 --> 00:12:49,054
error rate.
But how do you keep improving the 

243
00:12:53,021 --> 00:12:55,540
accuracy even though the error rate is 
not that bad?

244
00:12:56,220 --> 00:12:58,840
Now go to them stone,
don't do well at this today.

245
00:12:59,740 --> 00:13:00,573
And then the last area is that it's 
really important that we're creating 

246
00:13:03,071 --> 00:13:04,960
algorithms that are interacting with the
humans,

247
00:13:04,961 --> 00:13:05,860
right?
That can,

248
00:13:06,240 --> 00:13:07,210
uh,
explain,

249
00:13:07,600 --> 00:13:08,433
uh,
how they may have come to a particular 

250
00:13:10,300 --> 00:13:13,000
decision or classification or whatever 
the case may be.

251
00:13:13,001 --> 00:13:18,001
So we need to try to think about how can
we build machines that can learn,

252
00:13:18,851 --> 00:13:21,520
that can listen,
interact with the humans,

253
00:13:21,880 --> 00:13:25,600
be able to explain their,
their decisions to humans.

254
00:13:25,601 --> 00:13:28,270
And so a big part of this is what we 
were,

255
00:13:28,330 --> 00:13:31,390
what I refer to and what many in the 
community refer to as,

256
00:13:31,391 --> 00:13:33,190
you know,
learning plus reasoning,

257
00:13:33,730 --> 00:13:34,563
meaning that we want to be able to 
reason on representations that are 

258
00:13:38,471 --> 00:13:39,304
learned preferably on representations 
that are learned in an unsupervised 

259
00:13:42,791 --> 00:13:43,624
manner.

260
00:13:46,490 --> 00:13:47,323
All right?
The first step in doing that is to be 

261
00:13:49,421 --> 00:13:52,120
able to make language itself 
computational,

262
00:13:52,270 --> 00:13:55,590
right?
So we are able to think about words as,

263
00:13:55,591 --> 00:14:00,010
as sort of symbols and what those words 
mean and the properties of them.

264
00:14:00,011 --> 00:14:00,844
And then reason about them.
If you think about all the algorithms 

265
00:14:03,281 --> 00:14:07,990
that you've been learning,
they expect the information to be coming

266
00:14:07,991 --> 00:14:10,150
to them as,
as numerical information,

267
00:14:10,151 --> 00:14:10,984
preferably as real valued information.
How do you go from text to real valued 

268
00:14:15,991 --> 00:14:16,824
information that can then be fed into 
these algorithms over time and then 

269
00:14:20,651 --> 00:14:24,540
computed on.
So one of the first areas here is,

270
00:14:24,541 --> 00:14:26,470
uh,
his word embeddings.

271
00:14:26,800 --> 00:14:29,710
Uh,
the reason I italicized words is because

272
00:14:30,040 --> 00:14:33,430
what you'll see is that we kind of 
started out with word embeddings,

273
00:14:33,431 --> 00:14:35,050
but now it's a,
you know,

274
00:14:35,230 --> 00:14:36,940
phrase,
embeddings document and vetting.

275
00:14:36,941 --> 00:14:38,590
So there's much more to this,
um,

276
00:14:39,100 --> 00:14:39,933
but let's,
let's start first with what do we mean 

277
00:14:41,141 --> 00:14:42,310
with word embeddings?

278
00:14:42,390 --> 00:14:47,230
Okay.
The point is to try to represent ordered

279
00:14:47,350 --> 00:14:48,183
as a real valued vector,
a that basically what that words means 

280
00:14:53,930 --> 00:14:55,940
in terms of other words,
right?

281
00:14:55,941 --> 00:14:56,741
So,
so the,

282
00:14:56,741 --> 00:15:01,460
the dimensions of that factor of the 
features or basically other words.

283
00:15:02,510 --> 00:15:03,343
And the point is that you can assign 
different weights on how well that word 

284
00:15:07,251 --> 00:15:09,300
relates to these other words.
Okay?

285
00:15:09,950 --> 00:15:10,783
Now the difficult part there is how do 
you learn that representation that's 

286
00:15:15,621 --> 00:15:20,621
going to give you that objective of 
making that vector really represent that

287
00:15:21,771 --> 00:15:25,870
word and be comparable to other words in
a way that the machine can,

288
00:15:25,900 --> 00:15:26,733
can compute on them.
So the idea is the first work earlier 

289
00:15:30,641 --> 00:15:31,880
work in this was,
all right,

290
00:15:32,420 --> 00:15:37,220
how do we do this?
Such that those embeddings,

291
00:15:37,221 --> 00:15:38,054
those vectors give you an understanding 
of similarity between this word and 

292
00:15:42,801 --> 00:15:43,634
other words within your dictionary first
model here was what they referred to as 

293
00:15:48,171 --> 00:15:49,340
a skip gram model.

294
00:15:49,660 --> 00:15:51,230
Uh,
basically what you try to do,

295
00:15:51,231 --> 00:15:53,990
as you say,
given a particular word,

296
00:15:54,830 --> 00:15:55,663
how well can I predict the words around 
at the words that are one hop away from 

297
00:15:59,061 --> 00:16:01,190
it to hop away from it,
three hops away from it.

298
00:16:02,370 --> 00:16:07,370
What they're trying to do is to train a 
set of vectors where you minimize,

299
00:16:07,650 --> 00:16:08,483
uh,
the,

300
00:16:08,660 --> 00:16:09,670
the,
um,

301
00:16:10,040 --> 00:16:10,873
the loss,
the prediction loss of being able to 

302
00:16:13,341 --> 00:16:15,980
predict the words around it based off of
that word.

303
00:16:16,700 --> 00:16:18,740
It was a very big difference for the 
community.

304
00:16:18,741 --> 00:16:21,020
Previously.
It had been mostly counts.

305
00:16:21,021 --> 00:16:24,500
People just kind of count the number of 
occurrences and then they would use that

306
00:16:24,501 --> 00:16:25,334
to try to almost make that the wait.
What this was doing was taking a deep 

307
00:16:30,081 --> 00:16:31,010
neural network.
Well,

308
00:16:31,190 --> 00:16:32,023
it was actually kind of a shallow neural
network to try to optimize or maximize 

309
00:16:38,720 --> 00:16:39,553
this law of probability of being able to
predict the words around it from that 

310
00:16:43,040 --> 00:16:46,130
and what they got from that is what you 
can kind of see here.

311
00:16:46,370 --> 00:16:47,203
This ability to place words,
symbols into a vector space such that 

312
00:16:53,570 --> 00:16:56,510
words that are similar are closer 
together.

313
00:16:56,570 --> 00:16:57,403
Right?
So,

314
00:16:57,490 --> 00:16:58,323
uh,
the point is you can see and also that 

315
00:17:00,500 --> 00:17:03,140
relationships between words,
you know,

316
00:17:03,141 --> 00:17:05,030
move in similar directions,
right?

317
00:17:05,031 --> 00:17:07,160
So what this figure is trying to show 
you is that,

318
00:17:07,161 --> 00:17:07,994
you know,
you can look at the countries that are 

319
00:17:09,081 --> 00:17:11,450
here on the,
on the left side,

320
00:17:11,690 --> 00:17:15,590
and you can see that there are similar 
to the ones that are,

321
00:17:15,920 --> 00:17:20,210
all countries are proximal,
the cities are proximal.

322
00:17:20,630 --> 00:17:21,463
Uh,
the,

323
00:17:21,530 --> 00:17:22,363
you know,
the vector that is going from countries 

324
00:17:24,591 --> 00:17:27,060
to city are,
uh,

325
00:17:27,070 --> 00:17:27,740
you know,
uh,

326
00:17:27,740 --> 00:17:29,420
essentially going in the same direction.
I'm sure.

327
00:17:29,450 --> 00:17:31,010
I'm not sure if you can actually see 
that,

328
00:17:31,550 --> 00:17:32,383
but the point is that this kind of a 
vector space gives us the ability to 

329
00:17:35,900 --> 00:17:40,900
compute on those real valued vectors and
then learn more about this.

330
00:17:40,910 --> 00:17:44,150
So our very first simple thing is to be 
able to,

331
00:17:44,151 --> 00:17:45,110
you know,
uh,

332
00:17:45,170 --> 00:17:47,450
be able to find other similar things,
right?

333
00:17:47,451 --> 00:17:48,950
You have,
you have something,

334
00:17:48,951 --> 00:17:49,784
you assemble Italy for example.
Can you find other things that are 

335
00:17:52,711 --> 00:17:56,130
similar to or related to Italy?
You can find other countries,

336
00:17:56,131 --> 00:17:58,250
you can find cities within Italy.
Um,

337
00:17:58,470 --> 00:18:00,450
so that's,
that's Kinda the first step.

338
00:18:01,340 --> 00:18:02,071
Uh,
the,

339
00:18:02,071 --> 00:18:03,050
you know,
so the first,

340
00:18:03,051 --> 00:18:04,200
the first,
uh,

341
00:18:04,230 --> 00:18:05,063
work,
there was this kind of distributed 

342
00:18:06,451 --> 00:18:09,180
representation that we're talking about 
here.

343
00:18:09,350 --> 00:18:10,183
Um,
the second is basically showing the 

344
00:18:12,121 --> 00:18:12,954
difference in terms of being able to 
second talk is a paper was about the 

345
00:18:18,090 --> 00:18:18,923
accuracy,
the significant jump and accuracy that 

346
00:18:20,911 --> 00:18:21,744
we got from being able to do that 
prediction based representation as 

347
00:18:25,621 --> 00:18:27,300
opposed to the account base 
representation.

348
00:18:27,301 --> 00:18:28,680
I put,
I signaled,

349
00:18:28,700 --> 00:18:30,150
you know,
ibm authors,

350
00:18:30,151 --> 00:18:34,260
people who are at or where it off ibm in
orange.

351
00:18:34,630 --> 00:18:37,000
And the last one is um,
the uh,

352
00:18:37,080 --> 00:18:37,913
facebook has actually recently we 
released this fast tax where you can 

353
00:18:40,561 --> 00:18:44,310
basically go in and very easily create 
your own embeddings.

354
00:18:44,580 --> 00:18:46,790
So first thing was,
you know,

355
00:18:46,840 --> 00:18:47,673
how do,
how do they create it and they went 

356
00:18:48,601 --> 00:18:51,660
after a specific thing.
How do you optimize that similarity?

357
00:18:51,960 --> 00:18:52,793
But what you'll see from the rest of the
talk is that there are many other ways 

358
00:18:55,381 --> 00:18:59,070
that you might want to try to figure out
how to place things together.

359
00:18:59,071 --> 00:19:03,420
Other constraints that you might want to
place on the vector space and how things

360
00:19:03,421 --> 00:19:07,290
are represented in that vector space.
So that you can accomplish tasks from it

361
00:19:10,680 --> 00:19:12,170
prior to,
uh,

362
00:19:12,210 --> 00:19:16,110
these types of representation,
the ideals for how people would actually

363
00:19:16,111 --> 00:19:19,620
go after representing knowledge and 
language.

364
00:19:19,830 --> 00:19:22,680
We're knowledge basis,
a structured knowledge.

365
00:19:22,681 --> 00:19:25,410
So our original ideas was,
alright,

366
00:19:25,500 --> 00:19:26,333
listen,
I have to be able to have a entities 

367
00:19:28,711 --> 00:19:29,700
that are well defined.

368
00:19:29,700 --> 00:19:32,730
I have to have well defined 
relationships between those entities.

369
00:19:32,731 --> 00:19:37,080
I have to have a rules that basically 
will give me information about,

370
00:19:37,380 --> 00:19:37,861
uh,
you know,

371
00:19:37,861 --> 00:19:38,694
categories of relationships or 
categories of entities and it's great 

372
00:19:44,130 --> 00:19:48,180
humans are able to do that.
They're able to lay out an entire space,

373
00:19:48,210 --> 00:19:49,260
you know,
describe,

374
00:19:49,470 --> 00:19:50,303
you know,
molecules and relationships between 

375
00:19:51,781 --> 00:19:52,614
molecules or jeans and relationships 
between genes and the targets that they 

376
00:19:56,491 --> 00:19:58,560
might be able to affect.
Humans can do that.

377
00:19:58,590 --> 00:20:01,500
Well,
a machines don't do it that way.

378
00:20:01,920 --> 00:20:03,330
Um,
that was the problem.

379
00:20:03,331 --> 00:20:06,690
So the second figure here was even 
though you,

380
00:20:06,691 --> 00:20:07,524
you know,
you kind of go out and you're able to 

381
00:20:07,981 --> 00:20:11,530
find a lot of things and wikipedia and 
Wikidata,

382
00:20:11,580 --> 00:20:12,413
you know,
freebase or some of the examples where 

383
00:20:13,441 --> 00:20:16,080
you can find structured information on 
the web.

384
00:20:16,290 --> 00:20:18,390
Even though you're able to find a lot of
information out here,

385
00:20:18,391 --> 00:20:21,360
and although this is a 2013 statement,
which you can see is that,

386
00:20:21,720 --> 00:20:22,553
uh,
in terms of the types of relationships 

387
00:20:24,451 --> 00:20:26,820
and completeness of that,
this is saying,

388
00:20:26,970 --> 00:20:27,803
okay,
well for the people that are in 

389
00:20:29,280 --> 00:20:34,280
wikipedia or freebase actually we only 
were missing about 80 percent of their,

390
00:20:35,490 --> 00:20:36,690
uh,
their education,

391
00:20:36,691 --> 00:20:37,830
where their education is from.

392
00:20:37,830 --> 00:20:38,730
We're,
we're missing,

393
00:20:39,000 --> 00:20:39,833
you know,
over 90 percent of their employment 

394
00:20:41,821 --> 00:20:42,481
history.
Right.

395
00:20:42,481 --> 00:20:43,314
So,
uh,

396
00:20:43,420 --> 00:20:45,810
even though it seems like it's a lot of 
information,

397
00:20:45,870 --> 00:20:46,703
a really sparse and very difficult for 
humans to be able to use the algorithms 

398
00:20:52,961 --> 00:20:53,794
that we have today to automatically 
populate knowledge bases that look like 

399
00:20:57,281 --> 00:21:01,680
the form that we understand and feel 
that we can apply our,

400
00:21:01,681 --> 00:21:02,514
our logic to.
So one of the first results in terms of 

401
00:21:07,030 --> 00:21:12,030
going from that symbolic knowledge into 
sub symbolic knowledge.

402
00:21:12,671 --> 00:21:15,040
So the vectors that I was talking about 
earlier was,

403
00:21:15,550 --> 00:21:19,960
could we redo our knowledge base is 
based off of these sub symbolic,

404
00:21:19,961 --> 00:21:21,010
these,
these vectors.

405
00:21:21,580 --> 00:21:22,413
If we were able to do that,
then we actually would be able to learn 

406
00:21:25,901 --> 00:21:28,500
much more data.
It's possible we could learn these,

407
00:21:28,501 --> 00:21:29,334
these representations and fill out some 
of the information that we're missing 

408
00:21:32,861 --> 00:21:36,310
from our knowledge basis of this.
First part was saying,

409
00:21:36,490 --> 00:21:36,911
okay,
look,

410
00:21:36,911 --> 00:21:40,810
I can take some of the information I can
find and freebase and other sources.

411
00:21:41,230 --> 00:21:42,063
What I'll do is I can use text 
information to try to build out these 

412
00:21:44,771 --> 00:21:47,980
embeddings.
I can find relationships are,

413
00:21:47,981 --> 00:21:48,814
I can find a entities that are in 
similar spaces and realize there may be 

414
00:21:53,081 --> 00:21:53,914
a relationship between these and I can 
start to populate more of the 

415
00:21:56,921 --> 00:21:59,920
relationships that I'm,
that I'm missing from my knowledge base.

416
00:22:03,430 --> 00:22:05,100
We're able to use this,
this,

417
00:22:05,110 --> 00:22:07,090
this principle of the,
uh,

418
00:22:07,091 --> 00:22:12,091
the embeddings and the knowledge basis 
to then start to grow the knowledge base

419
00:22:12,630 --> 00:22:13,690
that we have.
Right?

420
00:22:13,691 --> 00:22:14,650
So,
uh,

421
00:22:14,651 --> 00:22:15,484
this is basic.
The first study here is showing how we 

422
00:22:17,831 --> 00:22:18,664
took information about genes and 
diseases and drugs from ontologies that 

423
00:22:24,731 --> 00:22:26,560
were available,
uh,

424
00:22:26,650 --> 00:22:27,483
represented that learn vectors across 
that structured space so that we could 

425
00:22:31,961 --> 00:22:35,650
predict relationships that weren't in 
the knowledge base.

426
00:22:35,980 --> 00:22:36,813
That's important because if you think 
about how people get that information 

427
00:22:39,371 --> 00:22:40,204
today,
they actually do wet lab experiments to 

428
00:22:42,701 --> 00:22:45,250
try to understand if there is a 
relationship,

429
00:22:45,251 --> 00:22:48,400
if something upregulate something else 
because very expensive.

430
00:22:48,700 --> 00:22:53,110
If we can use this knowledge to make 
those predictions,

431
00:22:53,111 --> 00:22:56,590
then we can give other scientists places
to look.

432
00:22:56,890 --> 00:22:59,440
Looks like there might be an interaction
here.

433
00:22:59,560 --> 00:23:00,900
Maybe you could try that,
right?

434
00:23:01,500 --> 00:23:02,333
Uh,
the second set of results is a more 

435
00:23:04,301 --> 00:23:05,110
recent,
uh,

436
00:23:05,110 --> 00:23:06,530
basically,
um,

437
00:23:06,600 --> 00:23:08,440
you know,
it was a challenge issued by this mantic

438
00:23:08,441 --> 00:23:09,274
web community.

439
00:23:09,520 --> 00:23:13,420
How can we better improve this automated
knowledge based construction?

440
00:23:13,850 --> 00:23:17,020
So the team used a combination of these 
word embeddings,

441
00:23:17,370 --> 00:23:18,203
uh,
to be able to search for and validate 

442
00:23:21,011 --> 00:23:24,550
information gained from a set of 
structured and unstructured knowledge.

443
00:23:24,551 --> 00:23:27,010
So this is actually won a first place in
the,

444
00:23:27,011 --> 00:23:29,860
uh,
in the 2017 semantic web challenge.

445
00:23:31,510 --> 00:23:32,343
Okay.
So now we're kind of getting an idea 

446
00:23:34,211 --> 00:23:39,211
about how we would take a language,
make it computational,

447
00:23:40,780 --> 00:23:43,960
put it into a knowledge base so that we 
can aggregate it over time.

448
00:23:44,890 --> 00:23:48,050
But how are we going to get the neural 
networks to use that?

449
00:23:48,640 --> 00:23:49,473
That's the next question.

450
00:23:51,560 --> 00:23:52,393
Okay.
An example task of why you would want 

451
00:23:54,201 --> 00:23:57,560
those neural networks to be able to use 
that is question answering.

452
00:23:58,820 --> 00:23:59,653
You want to build up a knowledge base,
everything you can possibly find a and 

453
00:24:03,861 --> 00:24:07,820
then you want to be able to ask it 
questions and see if he can answer those

454
00:24:07,821 --> 00:24:08,654
questions.
We say that this requires memories 

455
00:24:11,451 --> 00:24:12,284
because the point is that if you think 
about some of the other tasks that you 

456
00:24:14,241 --> 00:24:16,370
may have seen,
you provide,

457
00:24:16,371 --> 00:24:20,450
once you train the network,
you provide an input and then you get an

458
00:24:20,451 --> 00:24:21,320
output,
right?

459
00:24:21,321 --> 00:24:25,750
You don't necessarily use longterm 
memories of,

460
00:24:26,050 --> 00:24:26,883
uh,
relationships and entities and all of 

461
00:24:28,191 --> 00:24:29,690
these sorts of things.
Okay.

462
00:24:29,930 --> 00:24:32,920
Um,
so this is a challenge.

463
00:24:32,930 --> 00:24:33,763
There was issue to the community 
essentially in terms of being able to 

464
00:24:36,651 --> 00:24:41,300
read some sentences and then being able 
to give an a question,

465
00:24:41,530 --> 00:24:42,770
get an answer to that.

466
00:24:43,100 --> 00:24:43,933
And there are different stages of the 
complexity of what is required in order 

467
00:24:47,961 --> 00:24:48,794
to answer the question.
Sometimes it's really just kind of 

468
00:24:50,030 --> 00:24:50,863
finding the sentence.
Sometimes it's being able to put 

469
00:24:53,451 --> 00:24:54,284
multiple sentences together.
Sometimes it's being able to a chain 

470
00:24:56,961 --> 00:25:01,760
across time and so there are many stages
of difficulties in order to do that.

471
00:25:02,070 --> 00:25:02,903
Um,
but what I want to focus on is some of 

472
00:25:05,931 --> 00:25:06,764
the early work in terms of creating a 
neural network that can then access 

473
00:25:11,810 --> 00:25:15,380
those knowledge bases and then be able 
to produce an answer from that.

474
00:25:15,650 --> 00:25:16,483
Right?
So the expectation is that you build up 

475
00:25:19,431 --> 00:25:23,450
those knowledge basis from as much 
information you can find previously,

476
00:25:23,840 --> 00:25:24,673
uh,
you train them such that they know how 

477
00:25:26,091 --> 00:25:26,924
to answer a question,
the types of questions that you'd like 

478
00:25:29,271 --> 00:25:30,920
them to answer.
Uh,

479
00:25:31,130 --> 00:25:32,170
and then from that,
when you,

480
00:25:32,210 --> 00:25:34,760
you handed a question is able to produce
an answer.

481
00:25:35,450 --> 00:25:40,190
The reason this is different from what 
people are doing today,

482
00:25:40,220 --> 00:25:43,070
it's not just about saying today what 
happens is,

483
00:25:43,700 --> 00:25:45,290
you know,
when you program a computer,

484
00:25:45,770 --> 00:25:47,300
then you tell it,
okay,

485
00:25:47,301 --> 00:25:49,400
I want to be able to access this place 
in memory.

486
00:25:49,401 --> 00:25:52,310
You know,
I do a query on a database and I say,

487
00:25:52,311 --> 00:25:54,200
okay,
I'd like for you to give me all the rows

488
00:25:54,440 --> 00:25:56,540
where the first name is,
is excellent.

489
00:25:56,541 --> 00:25:59,480
The last name is why they can come back 
and that's all programmed.

490
00:26:00,440 --> 00:26:01,273
These networks are instead learning how 
to access memory by looking at other 

491
00:26:07,791 --> 00:26:11,690
patterns of access to memory,
not program train it,

492
00:26:11,900 --> 00:26:12,733
train.
So the point here is the neural net is 

493
00:26:14,721 --> 00:26:19,640
the controller of how that memory is 
accessed in order to produce an answer.

494
00:26:20,240 --> 00:26:21,260
Okay.
Um,

495
00:26:21,340 --> 00:26:24,730
so what happens is that they,
it is a supervised a result.

496
00:26:24,731 --> 00:26:27,020
So they,
they do train jointly with,

497
00:26:27,021 --> 00:26:28,070
okay,
what are the inputs,

498
00:26:28,400 --> 00:26:30,080
what's the question that will be asked 
of that,

499
00:26:30,081 --> 00:26:33,140
what's the output that is desired from 
that?

500
00:26:33,800 --> 00:26:34,700
And then,
um,

501
00:26:34,940 --> 00:26:36,110
by providing many,
many,

502
00:26:36,111 --> 00:26:39,550
many examples of that,
then when you provided a new set of,

503
00:26:39,870 --> 00:26:41,330
of,
of information,

504
00:26:41,331 --> 00:26:42,164
then it's able to answer a question from
that by basically taking a vector 

505
00:26:47,191 --> 00:26:50,020
representation of the question queue,
uh,

506
00:26:50,070 --> 00:26:50,903
being able to map that onto the memory.
So the embeddings that were produced 

507
00:26:54,241 --> 00:26:55,074
from all the sentences that were entered
and then moving back and forth across 

508
00:26:58,861 --> 00:27:01,380
that until it gets to a confidence that,
uh,

509
00:27:01,770 --> 00:27:02,441
uh,
in,

510
00:27:02,441 --> 00:27:03,274
in an answer and transferring that into,
into an output on the first version of 

511
00:27:07,561 --> 00:27:08,410
this,
uh,

512
00:27:08,940 --> 00:27:09,773
uh,
the first version that's on the left 

513
00:27:10,651 --> 00:27:14,250
side wasn't able to handle many things 
in terms of understanding,

514
00:27:14,490 --> 00:27:16,650
you know,
kind of a temporal sequences,

515
00:27:16,860 --> 00:27:17,693
for example,
they weren't able to do multi hop and 

516
00:27:20,400 --> 00:27:23,640
second version,
which is much more recent,

517
00:27:23,641 --> 00:27:24,420
is,
you know,

518
00:27:24,420 --> 00:27:28,440
kind of full end to end training of that
control of the,

519
00:27:28,441 --> 00:27:29,274
uh,
of the network in order to try to start 

520
00:27:30,301 --> 00:27:32,130
to answer these questions a while.

521
00:27:32,370 --> 00:27:35,370
It's incredibly exciting.
Uh,

522
00:27:35,371 --> 00:27:37,200
you know,
there's still many of the questions that

523
00:27:37,201 --> 00:27:39,390
I was showing earlier that it really 
can't answer.

524
00:27:39,391 --> 00:27:41,910
So this is definitively not a solved 
problem,

525
00:27:42,360 --> 00:27:43,193
but you know,
hopefully what you can see is that how 

526
00:27:45,241 --> 00:27:46,074
we're starting to go up against problems
that we don't know completely how to 

527
00:27:50,011 --> 00:27:52,410
solve.
But we're starting to solve them.

528
00:27:52,800 --> 00:27:55,980
And instead of just creating neural 
networks,

529
00:27:56,010 --> 00:27:59,310
just an algorithm,
we are creating machines,

530
00:27:59,400 --> 00:28:00,233
right?
Or creating machines that have 

531
00:28:01,980 --> 00:28:04,340
controllers and they have memory,
uh,

532
00:28:04,350 --> 00:28:05,183
and they're able to perform tasks that 
go well beyond just what you could do 

533
00:28:08,250 --> 00:28:10,440
with the pure neural network algorithm.
They,

534
00:28:10,460 --> 00:28:11,293
they,
they leverage those neural network 

535
00:28:12,870 --> 00:28:15,360
algorithms throughout.
These are recurrent neural nets,

536
00:28:15,361 --> 00:28:17,610
lsts and so on.
But the point is,

537
00:28:17,611 --> 00:28:21,150
we're starting to try to put together a 
machines from this,

538
00:28:22,070 --> 00:28:23,220
uh,
if you,

539
00:28:23,280 --> 00:28:25,890
if you'd like to learn more about this 
topic,

540
00:28:25,910 --> 00:28:26,970
um,
there's,

541
00:28:27,000 --> 00:28:28,620
there's quite a bit of work in this.

542
00:28:28,620 --> 00:28:30,450
So one is,
uh,

543
00:28:30,451 --> 00:28:32,940
in addition to being able to answer 
those questions,

544
00:28:32,941 --> 00:28:35,910
if we could better isolate.
What's the question,

545
00:28:35,911 --> 00:28:36,744
right?
This is something that humans have a 

546
00:28:37,561 --> 00:28:39,000
problem with him.
Somebody comes in,

547
00:28:39,001 --> 00:28:40,830
they ask you a question and you kind of 
say,

548
00:28:40,831 --> 00:28:41,730
what,
wait,

549
00:28:41,731 --> 00:28:42,930
what,
what's really the question?

550
00:28:42,931 --> 00:28:44,370
You're,
you're asking me here.

551
00:28:44,371 --> 00:28:48,810
So we've done work in terms of being 
able to have better computers,

552
00:28:48,840 --> 00:28:51,610
better understand what's the question 
really being asked.

553
00:28:51,870 --> 00:28:52,703
Um,
we need systems that will help us to 

554
00:28:54,690 --> 00:28:55,523
train these models.
So a part of this work is to create a 

555
00:28:59,041 --> 00:28:59,874
simulator that can take texts that are 
ambiguous and generate questions of 

556
00:29:04,741 --> 00:29:05,574
certain forms that we can then use that 
to try to both train as well as test 

557
00:29:10,380 --> 00:29:12,670
some of these systems.
Um,

558
00:29:12,880 --> 00:29:17,760
another really interesting thing is that
a common sense knowledge is basically,

559
00:29:17,761 --> 00:29:18,594
you know,
they refer to it as what's in the white 

560
00:29:19,741 --> 00:29:21,060
space between what you read.

561
00:29:21,320 --> 00:29:26,160
You read a text and a lot of times 
there's a lot of common sense knowledge,

562
00:29:26,200 --> 00:29:26,700
uh,
you know,

563
00:29:26,700 --> 00:29:27,770
knowing that,
you know,

564
00:29:27,771 --> 00:29:28,604
you know,
the desk is made of wood and wood is 

565
00:29:29,671 --> 00:29:33,180
hard and all of these sorts of things 
help you to understand a question.

566
00:29:34,290 --> 00:29:37,140
Can't find that it's not a wikipedia 
muster.

567
00:29:37,160 --> 00:29:39,810
That common sense information isn't not 
in wikipedia.

568
00:29:40,440 --> 00:29:45,070
It's not easy for us to learn from texts
because people don't stated this.

569
00:29:45,420 --> 00:29:47,050
Third Work here is,
hey,

570
00:29:47,051 --> 00:29:50,020
can we take some of that common sense 
knowledge?

571
00:29:50,380 --> 00:29:51,213
Can we learn in vector space ways to 
represent information that's common 

572
00:29:56,411 --> 00:29:58,180
sense that,
that white space,

573
00:29:58,430 --> 00:30:01,720
uh,
and attach it to other information that,

574
00:30:01,770 --> 00:30:02,870
uh,
that we're able to,

575
00:30:02,871 --> 00:30:04,750
to read from,
from the web and so on.

576
00:30:05,310 --> 00:30:06,143
Um,
you know,

577
00:30:06,160 --> 00:30:08,530
some of the recent work as well as can 
we,

578
00:30:08,590 --> 00:30:12,820
can we use neural nets to basically 
learn what a program is doing,

579
00:30:13,870 --> 00:30:14,703
represent that,
and then be able to execute that 

580
00:30:17,681 --> 00:30:18,960
program,
um,

581
00:30:19,000 --> 00:30:20,110
programs,
you know,

582
00:30:20,111 --> 00:30:20,944
this right now,
people want to try to program a program 

583
00:30:23,051 --> 00:30:26,370
that takes a very sophisticated human 
skill to be able to probe,

584
00:30:26,590 --> 00:30:28,540
probe a program and understand it.

585
00:30:28,540 --> 00:30:31,060
And in fact,
humans don't do that very well.

586
00:30:31,090 --> 00:30:32,800
But if we could train machines to do 
that,

587
00:30:32,801 --> 00:30:35,830
then obviously that's a very powerful 
thing to do.

588
00:30:36,390 --> 00:30:37,223
Um,
we're also a paper that was just 

589
00:30:39,551 --> 00:30:40,384
published a couple of,
a couple of months ago in December at 

590
00:30:42,281 --> 00:30:44,170
nips.
I thought it was extremely interesting.

591
00:30:44,500 --> 00:30:45,333
Uh,
basically they're learning how to 

592
00:30:47,500 --> 00:30:48,333
constrain a vector representations such 
that they can induce a new rules from 

593
00:30:54,611 --> 00:30:58,450
those and that they can basically create
proofs.

594
00:30:58,510 --> 00:30:59,350
Right?
So when you,

595
00:30:59,910 --> 00:31:03,610
the reasonable proof is important is 
basically that's the beginnings of being

596
00:31:03,611 --> 00:31:04,444
able to explain an answer.
Someone if you ask the question of the 

597
00:31:08,410 --> 00:31:10,000
question from some of the other ones 
was,

598
00:31:10,001 --> 00:31:11,830
you know,
it's the apples in the kitchen,

599
00:31:12,180 --> 00:31:13,930
um,
why,

600
00:31:14,690 --> 00:31:15,523
because you have approved,
if you have the steps that you went 

601
00:31:17,621 --> 00:31:20,090
through in terms of the knowledge base,
uh,

602
00:31:20,260 --> 00:31:21,730
able to explain that out.

603
00:31:21,760 --> 00:31:24,640
Then suddenly people can interact with 
the,

604
00:31:24,641 --> 00:31:25,474
uh,
the system and use the system not only 

605
00:31:27,371 --> 00:31:32,080
to answer questions but to improve and 
lift what humans,

606
00:31:32,081 --> 00:31:34,360
the human knowledge as well.
Learn,

607
00:31:34,390 --> 00:31:37,630
learn from the computers right now,
the computers learn from us.

608
00:31:39,580 --> 00:31:42,190
And just finally,
if you'd like to do more,

609
00:31:42,220 --> 00:31:43,260
um,
you know,

610
00:31:43,261 --> 00:31:46,150
the research division is working on next
generation algorithms.

611
00:31:46,151 --> 00:31:46,984
Uh,
those come out through our watson 

612
00:31:48,760 --> 00:31:50,500
products.
We have a watson developer.

613
00:31:50,501 --> 00:31:52,390
Cloud makes it very easy.
You know,

614
00:31:52,391 --> 00:31:53,224
you can do things like you handed an 
image and it will hand back information 

615
00:31:55,511 --> 00:31:56,760
about what's in that image.
You,

616
00:31:56,761 --> 00:31:57,594
you hand at text,
it'll tell you information about the 

617
00:31:58,901 --> 00:32:00,610
sentiment of that,
you know,

618
00:32:00,611 --> 00:32:04,810
label information within it and so on.
So we have what we believe are very easy

619
00:32:04,811 --> 00:32:06,190
to use,
uh,

620
00:32:06,191 --> 00:32:07,330
you know,
uh,

621
00:32:07,331 --> 00:32:08,164
algorithms that take many of these 
things that we're talking about earlier 

622
00:32:11,680 --> 00:32:12,513
and make them very easy for anyone to 
use and incorporate in into their 

623
00:32:15,580 --> 00:32:18,550
programs.
So I think that's it for me.

624
00:32:18,910 --> 00:32:19,870
Any questions.

