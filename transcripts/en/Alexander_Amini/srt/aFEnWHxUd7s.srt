1
00:00:02,640 --> 00:00:03,473
Thank you for the invitation and I'm 
glad to give up through then 

2
00:00:05,710 --> 00:00:06,543
presentation or Basil Confederation 
meets a title as come to a vision meets 

3
00:00:09,961 --> 00:00:13,140
social media social network.
Actually a worry in this slice,

4
00:00:13,150 --> 00:00:13,983
I were introduced to the works that we 
have down in tens and Alf and as this 

5
00:00:17,731 --> 00:00:22,230
techniques is one or some research 
topics in our labs and as a,

6
00:00:22,530 --> 00:00:27,390
this topics can be shifted with the,
with the product of our company.

7
00:00:27,630 --> 00:00:28,463
Okay.
First I will give our introduction of 

8
00:00:30,180 --> 00:00:33,900
brief introduction of our company.
So I'm never sure whether have you heard

9
00:00:33,910 --> 00:00:36,240
tensen before?
Actually 10 center is,

10
00:00:36,241 --> 00:00:38,610
um,
one of the largest internet company.

11
00:00:38,760 --> 00:00:41,550
I think I can say that not only man of 
China,

12
00:00:41,600 --> 00:00:44,640
either on all over the world.
So this is the one of the largest,

13
00:00:45,120 --> 00:00:50,120
if not the company and the market 
capitalized is 500 billion US dollars.

14
00:00:50,371 --> 00:00:51,204
So I think that even comparable with 
facebook or even larger than facebook 

15
00:00:55,801 --> 00:00:56,634
and in sometimes,
and also we have several products and 

16
00:00:59,610 --> 00:01:02,220
several,
several trends for the most important.

17
00:01:02,220 --> 00:01:04,290
One is a social,
social,

18
00:01:04,291 --> 00:01:06,120
not social media,
social network.

19
00:01:06,210 --> 00:01:09,780
So we have wechat and uh,
they say which are also,

20
00:01:09,781 --> 00:01:13,410
we call the wishing in Chinese.
So we chat and Oscar Qq.

21
00:01:13,411 --> 00:01:16,710
So this is a two types of instant 
messenger or something like that.

22
00:01:16,711 --> 00:01:21,711
Facebook and Instagram,
I mean us and also we have games and the

23
00:01:22,651 --> 00:01:23,484
tencent games is the largest,
I think that's the number one game 

24
00:01:27,511 --> 00:01:28,344
company with have the ratio of you in 
the USA with the over 10 billion US 

25
00:01:33,271 --> 00:01:37,710
dollars in 2016.
And we have several,

26
00:01:38,060 --> 00:01:38,893
you know,
maybe someone is familiar with summer a 

27
00:01:40,261 --> 00:01:44,550
sale or should we have already acquired 
80% of the officers shares.

28
00:01:44,640 --> 00:01:47,520
So this is a,
we think that we are the largest.

29
00:01:47,521 --> 00:01:48,354
We,
we are the owners are the eight 

30
00:01:49,690 --> 00:01:51,930
percentage share.
The owners are so sale.

31
00:01:52,320 --> 00:01:53,153
And uh,
also we have some content working on 

32
00:01:54,980 --> 00:01:56,220
incontinence,
something like that.

33
00:01:56,220 --> 00:01:57,053
Tencent video,
this is something like the Netflix and 

34
00:01:58,990 --> 00:02:02,310
also the tencent music.
There's something like spotify and we'll

35
00:02:02,311 --> 00:02:05,210
have the largest a copywriter in a 
amount of China for the mill.

36
00:02:05,211 --> 00:02:07,470
That corns and also we have tens and 
news.

37
00:02:07,540 --> 00:02:11,610
So it about content.
And also because the Tanzania,

38
00:02:11,790 --> 00:02:14,880
one of the largest internet companies.
So we have the other,

39
00:02:14,881 --> 00:02:17,030
you know,
the businesses.

40
00:02:17,031 --> 00:02:19,950
That's how as a finance or insurance or 
something like that,

41
00:02:19,980 --> 00:02:22,680
this is all based on internet.
Okay.

42
00:02:22,710 --> 00:02:23,543
So these are the main structure of 
tensen and in the next hour give birth 

43
00:02:29,100 --> 00:02:31,470
instruction.
But Tessa allies that I were,

44
00:02:31,520 --> 00:02:32,353
I'm now in,
so it tends to an Arab have actually is 

45
00:02:35,311 --> 00:02:38,610
funded in 2016 and we have two 
locations.

46
00:02:38,640 --> 00:02:43,640
Why The or China in Shenzhen?
I'm China and a one office is Seattle.

47
00:02:44,100 --> 00:02:45,120
USA.
Okay.

48
00:02:45,300 --> 00:02:49,750
Actually we have four research topics 
under the center is the machinery.

49
00:02:49,750 --> 00:02:50,583
It is,
we've focused on the basic machine 

50
00:02:52,621 --> 00:02:53,710
learning,
uh,

51
00:02:53,790 --> 00:02:57,420
the machinery series and also large,
large scale machine learning platform.

52
00:02:57,450 --> 00:03:02,080
And as well as the,
and based on the machine learning part,

53
00:03:02,130 --> 00:03:05,370
we have three application and research 
areas come to vision,

54
00:03:05,410 --> 00:03:07,360
language and speech.
And uh,

55
00:03:07,420 --> 00:03:09,970
we would like do something actually 
from,

56
00:03:09,971 --> 00:03:10,804
for this that we focus on the areas of 
this application and we'd do some or 

57
00:03:14,240 --> 00:03:17,710
reinforced learning for the decision and
also general agent for the creation.

58
00:03:17,830 --> 00:03:22,540
And also we would like to maybe make 
some combinations for the [inaudible] of

59
00:03:22,541 --> 00:03:25,720
the world of the humans of the world.
Okay.

60
00:03:26,710 --> 00:03:27,940
So,
uh,

61
00:03:27,941 --> 00:03:28,774
in the following,
in a falling out this lecture I will 

62
00:03:30,611 --> 00:03:31,444
give an introduction about competitor 
varies the works that we have done in 

63
00:03:34,091 --> 00:03:35,570
computer vision.
And uh,

64
00:03:35,800 --> 00:03:36,633
we from the low level image and image 
video processing to the middle of the 

65
00:03:41,291 --> 00:03:42,124
image we do analysis and the human that 
depot was the major and the video 

66
00:03:45,550 --> 00:03:46,383
understanding.

67
00:03:46,450 --> 00:03:48,860
Okay.
And we have done several works here,

68
00:03:48,880 --> 00:03:51,660
subtract or start transfer the husband 
and said Lucia.

69
00:03:51,720 --> 00:03:52,553
Under the hazing I would like us to like
some topics that had already this 

70
00:03:55,781 --> 00:03:56,614
technology.
We have already got pop paper publish 

71
00:03:58,781 --> 00:04:03,781
and also shifted to the product.
And the second is the image analysis.

72
00:04:04,690 --> 00:04:05,523
We focusing will,
I will try to introduce some process 

73
00:04:07,651 --> 00:04:12,280
automation and as a video interest 
attractiveness and the video,

74
00:04:12,520 --> 00:04:14,020
uh,
classifications.

75
00:04:14,230 --> 00:04:17,200
And also in the last four,
the even harder deeper learning.

76
00:04:17,230 --> 00:04:20,900
In a deeper understanding of the videos,
I will give some influx images.

77
00:04:21,190 --> 00:04:24,760
I will give some instruction about 
captioning and also the natural language

78
00:04:24,761 --> 00:04:26,410
we do localization.
Okay.

79
00:04:27,250 --> 00:04:31,120
First they see the video stock transfer.
Let's say they'll give a brief,

80
00:04:31,480 --> 00:04:33,680
uh,
image about the video start transfer and

81
00:04:33,681 --> 00:04:34,514
we'll have the videos and we have a 
style imagery and we perform the stock 

82
00:04:37,301 --> 00:04:37,900
transfer.

83
00:04:37,900 --> 00:04:40,960
We would like the style of videos to 
preserve,

84
00:04:40,961 --> 00:04:43,570
to preserve the content of the video 
sequences.

85
00:04:43,780 --> 00:04:48,190
And also it will borrow the style 
information from the stout stout image.

86
00:04:48,520 --> 00:04:49,353
And the most important is,
and this is very popular in 2016 as a 

87
00:04:52,751 --> 00:04:55,210
prisma,
but nowadays for the video,

88
00:04:55,360 --> 00:04:56,193
we have the,
we are the first work working on the 

89
00:04:57,731 --> 00:04:58,564
videos for the video.
This is the most important thing to 

90
00:05:01,150 --> 00:05:04,270
maintain the temperature consistence 
between adjacent offerings.

91
00:05:04,450 --> 00:05:06,130
So from the,
you know,

92
00:05:06,131 --> 00:05:06,964
from the sucrose here,
the temporal we have compared with the 

93
00:05:10,361 --> 00:05:12,520
traditional image style transfer and 
though,

94
00:05:12,900 --> 00:05:15,430
oh,
compared with our proposal mastered,

95
00:05:15,640 --> 00:05:16,473
the image is traditional image start 
transfer cannot maintain the 

96
00:05:19,310 --> 00:05:22,930
consistencies.
So the circles and the box stays there.

97
00:05:22,931 --> 00:05:26,800
You can see that as a style changing the
changes a significantly.

98
00:05:26,830 --> 00:05:30,520
But for our video part,
it can maintain a good consistency.

99
00:05:30,521 --> 00:05:34,030
So this will prevent,
it will,

100
00:05:34,270 --> 00:05:38,080
uh,
it will eliminate the chattering jet,

101
00:05:38,110 --> 00:05:40,030
the flickering artifacts in the videos.

102
00:05:42,370 --> 00:05:43,203
Okay.
So this is the Memphis and was a man 

103
00:05:44,700 --> 00:05:45,533
network of our video stuff transfer.
And the first party is a style stylized 

104
00:05:49,140 --> 00:05:52,170
and network.
This is a very traditional and a,

105
00:05:52,180 --> 00:05:53,013
we have a a encoder decoder encoder,
decoder style style and we'll have the 

106
00:05:56,621 --> 00:05:58,820
encoders.
We escaped,

107
00:05:58,821 --> 00:06:03,020
we connected with five restaurants,
rest blocks and as the decoders.

108
00:06:03,200 --> 00:06:04,033
And after that we realize the last 
networks to computers are stylized 

109
00:06:08,180 --> 00:06:12,020
network and a content loss network and 
also the uh,

110
00:06:12,050 --> 00:06:12,883
the temperature loss.
So with this loss there's no well 

111
00:06:15,530 --> 00:06:16,363
designer we can,
we can try the networks to makes an 

112
00:06:18,791 --> 00:06:20,520
network had,
can burn,

113
00:06:20,570 --> 00:06:21,403
can preserve the content and the ad well
as introduced the style and as most 

114
00:06:25,851 --> 00:06:26,684
important and can preserve the 
consistency between our jason the 

115
00:06:28,581 --> 00:06:29,660
frames.
Okay.

116
00:06:29,810 --> 00:06:30,643
So for this or special training,
we have the two frame coordinator 

117
00:06:33,351 --> 00:06:34,184
training.
So it means that we input the address 

118
00:06:36,591 --> 00:06:37,424
into firms,
into the network and the then utilize 

119
00:06:38,961 --> 00:06:42,920
that design as obsessive as it design 
the loss function to train the network.

120
00:06:43,160 --> 00:06:44,540
And also,
uh,

121
00:06:44,960 --> 00:06:48,560
another,
another advantage is that we do not need

122
00:06:48,561 --> 00:06:50,600
to computer optical flow information on 
that,

123
00:06:50,660 --> 00:06:53,470
on the fly.
So it means that we can't,

124
00:06:53,480 --> 00:06:54,313
well we can't,
well Mexico we can well Max though 

125
00:06:58,720 --> 00:06:59,553
inference very fast because of which do 
not need to make a computer that optic 

126
00:07:03,441 --> 00:07:04,274
flow.
Normally the optical or is our most 

127
00:07:05,720 --> 00:07:09,040
complicated part in video parts.
Okay.

128
00:07:09,380 --> 00:07:11,280
And I see that it,
because we are uh,

129
00:07:11,400 --> 00:07:12,233
you know,
[inaudible] instant message APP is so 

130
00:07:17,151 --> 00:07:20,600
the person who will share their food,
their pictures in with the,

131
00:07:20,780 --> 00:07:22,280
with the,
with their friends.

132
00:07:22,340 --> 00:07:23,173
So the picture that may be taking and 
the different conditions for this case 

133
00:07:26,031 --> 00:07:27,890
we want to handle the,
yeah,

134
00:07:28,100 --> 00:07:33,100
makes the image quality house the house,
but for the low light images.

135
00:07:33,350 --> 00:07:35,660
So we have,
if you take an image in the low light,

136
00:07:35,840 --> 00:07:36,673
it can now you cannot define it cannot 
find the edge of the content and also 

137
00:07:40,340 --> 00:07:41,480
the color.

138
00:07:41,490 --> 00:07:43,220
You cannot find the,
uh,

139
00:07:43,370 --> 00:07:44,203
you cannot take the right colors.
So we proposed a method to enhance the 

140
00:07:47,991 --> 00:07:48,824
low light images and we have the image 
here and with Medicaid displayed to the 

141
00:07:52,491 --> 00:07:55,700
original video you made part and also 
the age apart.

142
00:07:55,820 --> 00:07:58,640
So because the algae the most selling to
the human perception.

143
00:07:58,760 --> 00:07:59,593
So for the low light in low light to 
input our regional part we do could we 

144
00:08:03,651 --> 00:08:07,660
use a [inaudible] style to encode the 
image and the color image,

145
00:08:07,670 --> 00:08:08,503
a catalog or no results.
And also for the age part we utilize 

146
00:08:11,750 --> 00:08:12,583
also something like the encoder decoder 
and the afterwards we have the skip the 

147
00:08:16,701 --> 00:08:20,150
layer and the ways the island style to 
catch the edge information.

148
00:08:20,240 --> 00:08:21,073
Then paste this to the continent 
formation and eh as an also the edge 

149
00:08:24,991 --> 00:08:27,380
information.
We'll combine them together then to have

150
00:08:27,620 --> 00:08:28,453
enhanced the quality of the images and 
then we got some perceptual losses and 

151
00:08:33,051 --> 00:08:37,250
also other adverse or loss is to enhance
the quality of the image.

152
00:08:38,060 --> 00:08:38,893
Okay.
This is some of the results and we have 

153
00:08:40,521 --> 00:08:45,521
the first row is a low light images 
provided and we use the our network that

154
00:08:46,340 --> 00:08:47,420
we encounter.
We can,

155
00:08:47,421 --> 00:08:48,254
well rick,
we recover the content of the image and 

156
00:08:51,021 --> 00:08:53,420
also the colors that can be well 
preserved.

157
00:08:54,080 --> 00:08:54,913
Okay.
So this is,

158
00:08:55,110 --> 00:08:58,100
this is a one pot of,
we can share the image,

159
00:08:58,650 --> 00:08:59,483
improve the image quality and uh,
the next is the next work is a mobile 

160
00:09:03,991 --> 00:09:04,824
pose estimation actually for the post 
has measured helping well to study the 

161
00:09:07,871 --> 00:09:08,704
[inaudible] had been well studied but 
for the mobile part if we need to 

162
00:09:12,691 --> 00:09:13,524
perform the network compression and also
Makayta to detect the scattering of 

163
00:09:17,670 --> 00:09:18,503
other joints very accurately.
So this means this part when mostly 

164
00:09:22,590 --> 00:09:25,890
focusing on the network compression and 
the networks are proning.

165
00:09:26,220 --> 00:09:27,660
Okay.
So they,

166
00:09:27,661 --> 00:09:28,494
we shifted the network from the pcs to 
the [inaudible] wise and we can perform 

167
00:09:32,611 --> 00:09:33,444
the detection of the person that Marty 
persons and also for some front end 

168
00:09:37,080 --> 00:09:41,610
background and something like,
and the also instances to the uh,

169
00:09:41,640 --> 00:09:43,410
to the colors of their closest.

170
00:09:43,530 --> 00:09:45,690
And as they see the demos here and then 
the first,

171
00:09:46,450 --> 00:09:47,283
the latte.
I think that this is a maybe for the 

172
00:09:49,770 --> 00:09:51,930
projection party.
So this is not for real time.

173
00:09:52,200 --> 00:09:53,033
And they see the 22 key points for the 
joints of the persons under the under 

174
00:09:57,841 --> 00:09:58,674
the left.
Why is the way considered to detect the 

175
00:10:00,721 --> 00:10:02,520
hand?
Because the most of the hand,

176
00:10:02,580 --> 00:10:06,090
the hand is detection will we'll 
facilitate our,

177
00:10:06,390 --> 00:10:07,500
you know,
the purchase,

178
00:10:07,501 --> 00:10:09,960
the interaction with the,
with the phones,

179
00:10:09,990 --> 00:10:11,850
all the,
all the TVS.

180
00:10:12,330 --> 00:10:16,200
Okay.
And also for our mobile post estimation,

181
00:10:16,201 --> 00:10:17,034
we have some,
you can see that for this one we are 

182
00:10:19,051 --> 00:10:23,940
Robinson to the full or half body,
half body,

183
00:10:24,000 --> 00:10:26,850
half body.
That inclusion is on the half bodies.

184
00:10:26,970 --> 00:10:27,803
And also we are,
we are able to perform a single or 

185
00:10:30,061 --> 00:10:31,950
multiple persons.
And also we are,

186
00:10:32,090 --> 00:10:32,923
you know,
we are insensitive to the dressing 

187
00:10:34,261 --> 00:10:36,030
colors or the other.

188
00:10:36,040 --> 00:10:39,400
They are the dressings and also we are 
robust.

189
00:10:39,401 --> 00:10:40,234
The to the front and back,
even from the front and back we had to 

190
00:10:42,851 --> 00:10:45,990
tack to the joints under the uh,
under the,

191
00:10:46,110 --> 00:10:47,560
under the,
under the uh,

192
00:10:47,610 --> 00:10:50,370
information of the scallops.
And uh,

193
00:10:50,400 --> 00:10:54,960
also we have already deployed this 
techniques into mobile Qq.

194
00:10:55,230 --> 00:10:57,290
And for this one,
this is uh,

195
00:10:57,340 --> 00:10:58,170
the,
the left,

196
00:10:58,170 --> 00:11:00,000
the right one is that detector of 
matter,

197
00:11:00,001 --> 00:11:02,610
person of the scallions and the 
laughter.

198
00:11:02,611 --> 00:11:03,444
Why is that we have the skeletons and we
can have a dancing machine so we can 

199
00:11:07,051 --> 00:11:07,884
follow the,
you know,

200
00:11:08,130 --> 00:11:10,530
the guidance that underperformed the 
dances and the zen,

201
00:11:10,710 --> 00:11:11,543
they say they're very interesting to 
interact with the phones or interacted 

202
00:11:14,240 --> 00:11:15,360
with the TVS.
Yeah.

203
00:11:15,600 --> 00:11:18,000
So you can,
with this one we can find that the,

204
00:11:18,001 --> 00:11:18,834
you know,
with the disciplines detection we can 

205
00:11:19,861 --> 00:11:24,861
track that can match your positions with
a designed other specified the actions.

206
00:11:25,860 --> 00:11:27,270
Okay.
So this is,

207
00:11:27,280 --> 00:11:30,180
I work on the post that information.
Okay.

208
00:11:31,050 --> 00:11:31,883
And another topic is very interesting 
topic either for the video 

209
00:11:35,041 --> 00:11:37,140
attractiveness attractiveness.
Now that,

210
00:11:37,141 --> 00:11:39,630
because for a,
we have the tencent video,

211
00:11:39,631 --> 00:11:40,464
so we have a lot of,
a lot of video dramas have a lot of 

212
00:11:43,580 --> 00:11:44,413
times TV series uploaded on the website.
So we want to find whether the users is 

213
00:11:49,261 --> 00:11:51,360
interested in to some part of the 
videos.

214
00:11:51,480 --> 00:11:52,313
So we would like to,
whether we can predict the video 

215
00:11:55,310 --> 00:11:59,500
attractive from the only the visual 
information or the outer inflammations.

216
00:11:59,560 --> 00:12:02,950
So for this one we have the video input 
and we,

217
00:12:03,220 --> 00:12:04,053
sorry,
we have the video input and also I also 

218
00:12:06,281 --> 00:12:07,114
is associated with the auto import and 
that we would like to predict it's 

219
00:12:10,450 --> 00:12:11,283
attracted us under the crunchiness is a 
orange line ended up predict wise is a 

220
00:12:16,930 --> 00:12:17,763
predict ones.
Either you the Blue Line actually for 

221
00:12:19,850 --> 00:12:20,683
this attractive,
it is very hard to get the ground truth 

222
00:12:23,071 --> 00:12:23,710
data.

223
00:12:23,710 --> 00:12:24,543
So we utilize the views because this is 
a tencent video have a lot of 

224
00:12:27,820 --> 00:12:29,590
registrators.
So there are many,

225
00:12:29,591 --> 00:12:30,520
many of you,
many,

226
00:12:30,521 --> 00:12:34,480
many viewers at this time.
So for each of these is this,

227
00:12:34,540 --> 00:12:35,373
each of these values in each points,
it means that at this specific time 

228
00:12:40,120 --> 00:12:40,953
harmon person have already have already 
watched this video sequence at this 

229
00:12:44,201 --> 00:12:46,080
specific time.
So the,

230
00:12:46,280 --> 00:12:47,113
uh,
the statistically the larger of the 

231
00:12:49,991 --> 00:12:52,020
number,
it means that their amendment,

232
00:12:52,380 --> 00:12:53,213
there are a lot of men,
a larger number of person watching this 

233
00:12:56,201 --> 00:12:58,300
video at this moment.
So this prominent,

234
00:12:58,301 --> 00:13:00,990
should it be the machine,
uh,

235
00:13:01,090 --> 00:13:03,100
more attractive,
much more attractive,

236
00:13:03,220 --> 00:13:06,190
attractive than they other with similar 
values.

237
00:13:06,280 --> 00:13:09,350
So we we utilize this video as a 
checklist.

238
00:13:09,570 --> 00:13:10,450
Crunch,
choose value.

239
00:13:10,810 --> 00:13:12,670
Okay.
So,

240
00:13:12,940 --> 00:13:13,773
uh,
for this task we built a large large 

241
00:13:16,180 --> 00:13:17,013
large scale data set.
We have a one style about west of the 

242
00:13:20,621 --> 00:13:24,100
pepsis and the in total about seven to 
eight hours.

243
00:13:24,310 --> 00:13:25,143
And uh,
there are,

244
00:13:25,510 --> 00:13:26,343
we consist of 2,270
episodes of American dramas and also 

245
00:13:31,031 --> 00:13:31,864
search.
So the two Korean dramas and also seven 

246
00:13:34,570 --> 00:13:37,210
episodes of China's drummers.
So we have this one,

247
00:13:37,211 --> 00:13:38,044
we can see that diverse of a types and 
we have also the v the view information 

248
00:13:42,921 --> 00:13:43,870
as we can,
you know,

249
00:13:43,871 --> 00:13:44,704
start a Mackie to the robusta,
to the video or check themselves 

250
00:13:48,580 --> 00:13:49,880
studying.
And the full,

251
00:13:49,890 --> 00:13:54,760
this is a statistical information of our
data set and the,

252
00:13:54,761 --> 00:13:59,620
this is a number of the episodes and 
this is a number of the views,

253
00:13:59,820 --> 00:14:03,100
attracting the views and the,
the law once in a lot.

254
00:14:03,280 --> 00:14:04,113
Okay.
And also besides of the views actually 

255
00:14:07,421 --> 00:14:09,340
for it,
because it's the father tencent video,

256
00:14:09,410 --> 00:14:10,243
you are for the v the video platform,
you will have some of the other better 

257
00:14:13,331 --> 00:14:16,390
data or some other user engagement tree 
formation.

258
00:14:16,450 --> 00:14:21,220
They are the nine catchment information 
would crowd is a start of a,

259
00:14:21,221 --> 00:14:25,600
is a stat of the forward and the end of 
the forward,

260
00:14:25,750 --> 00:14:29,500
the start of the backward and the start 
of the uh,

261
00:14:29,620 --> 00:14:30,453
end of the backward and also have some 
pallet screens and doubling the number 

262
00:14:34,451 --> 00:14:37,150
of the billing squeeze and as the likes 
of the polling screens.

263
00:14:37,330 --> 00:14:39,820
And also we have the,
the,

264
00:14:40,270 --> 00:14:42,910
the forward skips and a,
the first,

265
00:14:42,911 --> 00:14:45,730
the word faster.
We were real wind skips.

266
00:14:45,850 --> 00:14:46,683
So with this ones we can get another 
more information about the user 

267
00:14:49,901 --> 00:14:53,750
engagements with a video with as this 
user in catchments of videos,

268
00:14:53,900 --> 00:14:56,420
you can can have more info,
more detailed information about,

269
00:14:56,780 --> 00:15:01,780
they do our checklist and we can pass on
these engagements to analysis more.

270
00:15:02,280 --> 00:15:05,120
Uh,
Alana's more about the human behaviors.

271
00:15:06,860 --> 00:15:07,910
Okay.
Uh,

272
00:15:07,970 --> 00:15:11,240
as we mentioned before,
we would like to make a prediction about

273
00:15:11,241 --> 00:15:13,580
the attracted from the audio and the 
video,

274
00:15:13,680 --> 00:15:15,590
all the information and the visual 
information.

275
00:15:15,710 --> 00:15:18,400
So for this,
two different modalities because we have

276
00:15:18,401 --> 00:15:21,720
a audio part and the other visual part,
so we four,

277
00:15:21,740 --> 00:15:25,670
we proposed three different theorists.
Strategy.

278
00:15:25,700 --> 00:15:29,120
Why is in the low level and a y in the 
middle of error and the wine in the high

279
00:15:29,121 --> 00:15:29,660
level.

280
00:15:29,660 --> 00:15:32,360
And uh,
they see that three star.

281
00:15:32,450 --> 00:15:35,690
This is the structure of the film part.
And uh,

282
00:15:35,780 --> 00:15:38,660
we have also each part we propose,
we utilize,

283
00:15:38,690 --> 00:15:42,290
we perform our contact skating here.
Okay.

284
00:15:42,560 --> 00:15:45,660
So based on this,
this architecture that we perform,

285
00:15:45,661 --> 00:15:47,720
that prediction and we,
we have the,

286
00:15:47,750 --> 00:15:48,583
we also propose us three,
the three criteria to evaluate whether 

287
00:15:52,671 --> 00:15:56,810
we can actually the pro,
we can actually perform the Eh,

288
00:15:57,130 --> 00:15:59,510
uh,
accurate prediction.

289
00:15:59,600 --> 00:16:00,433
So we have,
we have the four metrics and a then 

290
00:16:03,201 --> 00:16:04,034
we'll compare to with different visual 
representation from vg to inception to 

291
00:16:08,871 --> 00:16:09,351
rest,
rest,

292
00:16:09,351 --> 00:16:10,184
not.
And therefore the other part would 

293
00:16:10,850 --> 00:16:15,230
compare with MFCC and an and also the 
[inaudible] part.

294
00:16:15,440 --> 00:16:19,940
So we can say that you consider all the 
auto feature,

295
00:16:19,941 --> 00:16:24,020
that innovative feature together we can 
get better results and better results.

296
00:16:24,290 --> 00:16:25,123
But if we can sample the middle level,
high level and a love of fueling 

297
00:16:29,190 --> 00:16:31,160
strategy together,
we can get to the best of performance.

298
00:16:31,680 --> 00:16:36,290
So understanding that run and nothing 
and nothing to note that is,

299
00:16:36,291 --> 00:16:38,150
I will have the,
if we have the engagements,

300
00:16:38,400 --> 00:16:40,790
the is that is the behavior of the 
users.

301
00:16:40,940 --> 00:16:41,773
So we can,
if we can get an engagement so we can 

302
00:16:43,611 --> 00:16:48,330
make a very accurate,
very accurate prediction on the video of

303
00:16:48,360 --> 00:16:52,250
checkmates because if they like it,
it will watch it and otherwise they will

304
00:16:52,410 --> 00:16:53,243
leave this,
leave this videos so that the human 

305
00:16:56,490 --> 00:16:59,540
engagements you the most important part 
in the indicator,

306
00:16:59,780 --> 00:17:03,410
the indicator of the video checklist.
Okay.

307
00:17:03,530 --> 00:17:05,960
So these are for the video 
attractiveness starting.

308
00:17:06,200 --> 00:17:07,033
And also we started,
we make some study around the video 

309
00:17:09,621 --> 00:17:10,454
classification and as a mentioned there 
before them and mentioned them by Lisa 

310
00:17:13,371 --> 00:17:15,830
before the moment at the moment,
same time,

311
00:17:15,890 --> 00:17:19,700
the three seconds of the video that also
about Vedo complications,

312
00:17:19,730 --> 00:17:23,150
right?
And then a nother before that,

313
00:17:23,320 --> 00:17:25,200
there's a,
uh,

314
00:17:25,290 --> 00:17:29,630
there's a benchmark tests that aren't 
the ucf one zero one.

315
00:17:29,780 --> 00:17:32,670
So we perform for this part,
we perform the two streams,

316
00:17:32,740 --> 00:17:36,110
we utilize that to stream [inaudible] on
the,

317
00:17:36,410 --> 00:17:39,160
on the video classification and the one 
stream is,

318
00:17:39,640 --> 00:17:40,970
uh,
describe the content.

319
00:17:40,971 --> 00:17:41,804
And once from it is crap.
The optical information optical flow 

320
00:17:43,970 --> 00:17:44,803
meet means that an emotion information 
between adjusting the frames and we 

321
00:17:47,871 --> 00:17:48,704
proposed a principal back propagation 
propagation that we forward all the 

322
00:17:52,501 --> 00:17:53,334
snippers so the forwarding Romanian can 
capture all the information of the 

323
00:17:56,131 --> 00:18:01,131
videos and but for the backward we will 
perform a selectively to backward only a

324
00:18:01,470 --> 00:18:06,210
selected number of snippers netplus.
So one info wine,

325
00:18:06,260 --> 00:18:07,093
a wine,
one benefit is that from this efficient 

326
00:18:10,570 --> 00:18:14,460
backpropagation we can't get no,
we can perform a efficient and training.

327
00:18:14,640 --> 00:18:15,473
And uh,
another benefit is that we can also 

328
00:18:17,971 --> 00:18:18,804
perform that it's named Paris in 
different scales to characterize the 

329
00:18:22,291 --> 00:18:24,570
emotion that different emotion formation
in the videos.

330
00:18:25,770 --> 00:18:27,320
Okay.
This is our,

331
00:18:27,350 --> 00:18:29,490
uh,
results and for this,

332
00:18:29,491 --> 00:18:30,324
that sets the pippin that here and how 
even now to achieve the type one error 

333
00:18:35,101 --> 00:18:39,150
rate in about only 8.6
the percentage.

334
00:18:39,210 --> 00:18:40,043
So this is a slow,
this is smaller than the other 

335
00:18:41,880 --> 00:18:43,960
competitive models.
Okay.

336
00:18:44,640 --> 00:18:47,030
Also for the beetle classifications,
we we po,

337
00:18:47,090 --> 00:18:49,020
Po,
we're participating in the youtube,

338
00:18:49,350 --> 00:18:50,183
Youtube eight main and challenge the 
here and now for the Youtube 8 million 

339
00:18:53,071 --> 00:18:53,904
challenges here.
They only provided the weight of the 

340
00:18:55,861 --> 00:18:59,250
features for the visual features and 
it'll auto features.

341
00:18:59,430 --> 00:19:00,263
So we work on the audio and the video 
feature to perform the video 

342
00:19:03,031 --> 00:19:03,864
classification.
And a we for this is that we perform a 

343
00:19:07,090 --> 00:19:10,410
tooth two level consultation.
Why in the end the video liable.

344
00:19:10,440 --> 00:19:11,273
So the Beta level where average is uh,
the all the frames together to get a 

345
00:19:14,391 --> 00:19:17,220
little bit of of the representation and 
uh,

346
00:19:17,430 --> 00:19:18,263
uh,
we propose the amount of fuel in layer 

347
00:19:19,651 --> 00:19:23,400
here as a deputy here and as empathy 
with,

348
00:19:23,520 --> 00:19:24,353
for the customer fires,
we tried to mix mixture of experts and 

349
00:19:27,511 --> 00:19:27,690
luck.

350
00:19:27,690 --> 00:19:32,690
Global accuracy.
Precision is Arbutus only 0.82.

351
00:19:33,660 --> 00:19:34,493
Okay.
And also we performed the friend level 

352
00:19:36,991 --> 00:19:37,824
classification.
Now from a level of transparency 

353
00:19:39,361 --> 00:19:40,194
[inaudible] it very intuitively to have 
the LSTM and all that Gio to model the 

354
00:19:45,270 --> 00:19:47,340
sequential data.
So for the video,

355
00:19:47,370 --> 00:19:48,203
the video feature,
this is the can be viewed as a 

356
00:19:49,921 --> 00:19:51,390
sequential data.
Say We,

357
00:19:51,391 --> 00:19:52,224
so we utilize the about directional lstm
and [inaudible] and the GRU and also we 

358
00:19:56,491 --> 00:19:57,660
consider different,
uh,

359
00:19:57,690 --> 00:20:01,050
different emotions information.
So we perform our motto scale wise.

360
00:20:01,170 --> 00:20:06,170
So for each scale we perform,
we perform a bad direction,

361
00:20:06,660 --> 00:20:08,510
but direction of Gru,
uh,

362
00:20:08,640 --> 00:20:12,060
our lstm and the JP here,
the global,

363
00:20:12,300 --> 00:20:17,300
the global average precision is 
thereupon 0.83

364
00:20:18,390 --> 00:20:19,223
and a if we consider the video level 
part and as a frame labral part 

365
00:20:21,991 --> 00:20:23,460
together,
we can get as a,

366
00:20:23,461 --> 00:20:26,730
jp is the 0.84.
And uh,

367
00:20:26,760 --> 00:20:29,690
we achieved about to the force positions
number four,

368
00:20:29,710 --> 00:20:33,720
the first productions over the 606 400 
submissions.

369
00:20:34,920 --> 00:20:37,870
Okay.
So this is about the video and image and

370
00:20:37,871 --> 00:20:39,540
the data analysis.
Okay.

371
00:20:39,930 --> 00:20:42,690
Afterwards I will ensure that I will,
uh,

372
00:20:42,720 --> 00:20:43,553
afterwards I will give a instruction 
about some workers who would have done 

373
00:20:46,930 --> 00:20:47,763
on the learn on the understanding.
One part is the image or understanding 

374
00:20:51,431 --> 00:20:56,040
here and the image I understanding this 
is a very difficult part because we a an

375
00:20:56,120 --> 00:20:56,953
image to understand the image caption 
and the image is a very difficult part 

376
00:21:00,131 --> 00:21:02,680
because we're not only to understand the
image content,

377
00:21:02,890 --> 00:21:07,890
but also we need to learn the language 
of the properties or the behavior of the

378
00:21:07,901 --> 00:21:08,734
language of compositions.
And also we need to perform a Amati 

379
00:21:11,890 --> 00:21:16,060
Motel interactions between the image and
the sentences.

380
00:21:16,540 --> 00:21:18,940
Okay.
So for this one here,

381
00:21:18,941 --> 00:21:19,774
we also utilize our traditional,
something like the traditional 

382
00:21:23,980 --> 00:21:24,813
architecture for the image.
We utilize that image you see in to 

383
00:21:27,480 --> 00:21:28,870
encode the information.

384
00:21:29,020 --> 00:21:33,670
And the week Max we get the image 
representation in the global wise and in

385
00:21:33,671 --> 00:21:36,430
the local wise for the,
if we have a saying here,

386
00:21:36,520 --> 00:21:39,550
if half a million,
if you are familiar with sailing for the

387
00:21:39,551 --> 00:21:40,110
last,
uh,

388
00:21:40,110 --> 00:21:42,340
at the uh,
fully connected layer,

389
00:21:42,370 --> 00:21:46,660
this is a global representation and the 
for the intermediate convolution layers,

390
00:21:46,690 --> 00:21:49,060
this is a global,
they see the local representations.

391
00:21:49,240 --> 00:21:52,600
So for each image,
a image,

392
00:21:52,601 --> 00:21:53,950
a thing,
we can get the,

393
00:21:53,980 --> 00:21:57,700
we can get to the image global and the 
local representations.

394
00:21:57,910 --> 00:22:00,630
And with this [inaudible] if we have 
different uh,

395
00:22:00,850 --> 00:22:01,683
uh,
the such as the inception and the rest 

396
00:22:03,991 --> 00:22:04,824
net or the egg,
we have different things that we will 

397
00:22:08,831 --> 00:22:13,000
have multiple,
multiple representation of the image for

398
00:22:13,001 --> 00:22:13,834
each year.
For each set we have a global 

399
00:22:15,731 --> 00:22:18,010
representation and a local 
representation.

400
00:22:18,280 --> 00:22:23,280
And with this different representations 
we can perform a marty stage attention.

401
00:22:24,100 --> 00:22:25,950
And the Marty come,
um,

402
00:22:26,130 --> 00:22:26,963
Maddie's stage attention can first to 
summarize the information from 

403
00:22:30,010 --> 00:22:33,270
definitely encoders such as the rest,
not in separate ways.

404
00:22:33,710 --> 00:22:38,140
You separately before and also the uh,
the vgg.

405
00:22:38,170 --> 00:22:40,630
So we can,
we can sample this,

406
00:22:40,930 --> 00:22:45,850
the present them together and also Max 
this representative and to interact with

407
00:22:45,851 --> 00:22:50,770
each other and for the attention part so
they can broadcast to their,

408
00:22:51,170 --> 00:22:53,440
their information to the other encoder 
to,

409
00:22:53,800 --> 00:22:56,840
to let the other encoder know whether 
you,

410
00:22:56,841 --> 00:23:00,610
what information has been already 
considered the for the generation part.

411
00:23:01,210 --> 00:23:04,900
Okay.
If we had afterwards with a will perform

412
00:23:04,901 --> 00:23:07,390
the multi stage attention,
then we'll utilize that.

413
00:23:07,391 --> 00:23:10,360
Another decoder,
you did another uh,

414
00:23:10,361 --> 00:23:14,020
another decoder to decode these 
representations.

415
00:23:14,110 --> 00:23:16,330
Two sentences.
The decoder.

416
00:23:16,390 --> 00:23:21,390
Normally we can utilize our R and R and,
and uh,

417
00:23:21,910 --> 00:23:24,940
the Alstom and Gio is the most effective
arlene's.

418
00:23:24,960 --> 00:23:26,260
So,
uh,

419
00:23:26,261 --> 00:23:30,100
we have in here we utilize that Lstm so 
we have definitely,

420
00:23:30,101 --> 00:23:32,680
we have the image,
you can call the catheter representation

421
00:23:32,740 --> 00:23:36,670
and then we have the Dakota to Dakota 
representation into a sentence.

422
00:23:37,630 --> 00:23:39,710
Okay.
So this is first,

423
00:23:39,750 --> 00:23:41,310
this,
this pay first.

424
00:23:41,370 --> 00:23:42,203
This is,
this task is you need to consider the 

425
00:23:45,381 --> 00:23:50,381
information of the continent and then 
you made in the image and also integrate

426
00:23:50,510 --> 00:23:54,080
with the sentences to make the two folks
on the,

427
00:23:54,110 --> 00:23:59,090
each object to is a generation of each 
words such as for the persons.

428
00:23:59,210 --> 00:24:01,520
You need to pay attention to the object 
of the,

429
00:24:01,730 --> 00:24:04,340
uh,
the person needs to pay attention to the

430
00:24:04,341 --> 00:24:05,720
local region,
other the persons,

431
00:24:05,870 --> 00:24:07,720
and then generate the words and the 
father,

432
00:24:07,730 --> 00:24:08,563
the hills.
You need to pay attention to the local 

433
00:24:09,891 --> 00:24:13,550
region of the image and then generates 
the words here.

434
00:24:14,150 --> 00:24:16,280
Okay.
So for these things,

435
00:24:17,390 --> 00:24:20,900
we propel based on our multi stage 
attention.

436
00:24:21,140 --> 00:24:22,350
We have,
uh,

437
00:24:22,400 --> 00:24:23,540
perform,
uh,

438
00:24:23,600 --> 00:24:26,110
you know,
we have some Meta hour that's under Mac,

439
00:24:26,150 --> 00:24:26,983
Microsoft,
the cocoa challenge here they say the 

440
00:24:28,851 --> 00:24:31,070
most,
I think that is the most,

441
00:24:31,080 --> 00:24:31,913
uh,
most influence board influence that fat 

442
00:24:35,210 --> 00:24:36,290
on the image captioning.

443
00:24:36,410 --> 00:24:38,960
For each image it will,
uh,

444
00:24:38,990 --> 00:24:43,400
each image is a company with five 
sentences under there about uh,

445
00:24:43,790 --> 00:24:46,540
uh,
about 100,000

446
00:24:46,850 --> 00:24:51,850
images and therefore h majors as it is 
accompanied with five sentences.

447
00:24:52,190 --> 00:24:55,640
So I think the appeared the pair Datas 
for image.

448
00:24:55,700 --> 00:25:00,700
Understand the pay data.
It is about 600 southern pairs.

449
00:25:01,160 --> 00:25:02,570
Okay.
Based on this data,

450
00:25:02,750 --> 00:25:05,930
you can perform the,
you can perform,

451
00:25:05,970 --> 00:25:08,830
you can perform,
you can promote a training of the the of

452
00:25:08,870 --> 00:25:09,703
your model and that's the image that the
results of the test data on the website 

453
00:25:13,910 --> 00:25:14,743
and a for this website we have,
we have several criteria to evaluate 

454
00:25:18,481 --> 00:25:21,480
your results and for the reason I say 
that for this,

455
00:25:21,481 --> 00:25:26,481
see the blue and the blue blue one blue 
two plus three blue for and also we have

456
00:25:26,571 --> 00:25:27,404
the meter Raj and cider say cid or this 
is for the crd or this is the most 

457
00:25:32,911 --> 00:25:33,744
suspicious specifically designed for 
evaluating the quality of the image 

458
00:25:37,071 --> 00:25:37,904
captioning.

459
00:25:37,970 --> 00:25:38,803
Okay.
So far this fall for this we can say 

460
00:25:43,671 --> 00:25:48,310
that for the CFI and the c 40 we can 
achieve all four.

461
00:25:48,311 --> 00:25:53,240
All the metrics we achieve the top one,
top wide results and the compared to the

462
00:25:53,241 --> 00:25:56,540
other.
Are there other models here?

463
00:25:57,200 --> 00:25:59,870
Okay.
Also we also,

464
00:25:59,871 --> 00:26:01,570
we have transformed,
we have,

465
00:26:01,580 --> 00:26:03,720
we have a collector,
another Chinese dataset.

466
00:26:03,770 --> 00:26:04,603
We have an image here and also we have 
the image and that is a company that a 

467
00:26:08,811 --> 00:26:13,210
Chinese sentences and a we're trying to 
models and also with deployed the,

468
00:26:13,280 --> 00:26:16,790
we have released the results and uh,
we,

469
00:26:17,450 --> 00:26:18,470
we,
we,

470
00:26:18,680 --> 00:26:19,513
we build a late later program in we chat
so you can experience it if you have 

471
00:26:25,731 --> 00:26:26,810
the,
which had here.

472
00:26:27,620 --> 00:26:28,453
Okay.
This is the Chinese for intelligent 

473
00:26:30,110 --> 00:26:31,640
image recognition.
Okay.

474
00:26:31,850 --> 00:26:36,080
So for this image it had for the Chinese
give a brief brief instruction.

475
00:26:36,140 --> 00:26:36,973
Uh,
very good disclosure about the content 

476
00:26:39,531 --> 00:26:40,430
of the image.

477
00:26:40,910 --> 00:26:41,810
Okay.
And the,

478
00:26:41,811 --> 00:26:42,644
for this,
if we have the image of captioning the 

479
00:26:43,981 --> 00:26:44,814
results,
we'll give a image and I gave her a 

480
00:26:46,591 --> 00:26:48,810
sentence or two describe the content of 
danger.

481
00:26:49,020 --> 00:26:51,690
We can perform first.
The most Australian boy,

482
00:26:51,720 --> 00:26:55,890
eataly is a performer he made discursion
and other is that we have this sentences

483
00:26:55,891 --> 00:26:56,724
that were going to perform the image 
retrieval and the also as well as the 

484
00:26:59,251 --> 00:27:03,090
magic recommendations and also for the 
visual dialogues.

485
00:27:03,360 --> 00:27:04,810
And uh,
the most important.

486
00:27:04,811 --> 00:27:05,644
I say if we have the image under the,
the discussions that we can help the 

487
00:27:08,221 --> 00:27:09,054
visually impairment.
Imparity he made a person to read or to 

488
00:27:13,861 --> 00:27:16,260
see the images.
Okay.

489
00:27:17,130 --> 00:27:19,800
So this is the work I imagine captioning
and uh,

490
00:27:19,950 --> 00:27:21,330
afterwards,
uh,

491
00:27:21,331 --> 00:27:25,530
the last work that I'm going to 
introduce is a natural language of video

492
00:27:25,560 --> 00:27:26,393
localization.
They see the also are very challenging 

493
00:27:28,740 --> 00:27:33,270
challenge a task one to you utilize a 
language we give.

494
00:27:33,410 --> 00:27:34,430
Uh,
will you try,

495
00:27:34,440 --> 00:27:37,230
are we giving our team the video and the
uh,

496
00:27:37,231 --> 00:27:39,540
natural language or discretion?
The girl,

497
00:27:39,610 --> 00:27:40,443
we would like to localize a stigma too 
in the video which a correspondent to 

498
00:27:43,921 --> 00:27:47,850
the given natural languages Christian,
it means that if you will,

499
00:27:47,880 --> 00:27:51,030
if we,
sorry if we have a very long,

500
00:27:51,031 --> 00:27:51,864
they do say process and a,
we have a sentence that described such 

501
00:27:55,201 --> 00:27:58,470
as a woman rails,
keep a kite back,

502
00:27:58,471 --> 00:27:59,304
lean forward herself.
We would like to localize this sentence 

503
00:28:02,940 --> 00:28:06,750
in the videos.
So this is a virtue as same as the image

504
00:28:06,751 --> 00:28:07,584
captioning.
It is a very challenge because first we 

505
00:28:10,621 --> 00:28:11,454
need to understand the language and the 
next that we need to understand the 

506
00:28:16,051 --> 00:28:16,860
video.
Same question,

507
00:28:16,860 --> 00:28:17,693
but for the video sequence,
the understanding is the human 

508
00:28:19,030 --> 00:28:21,210
challenges that you majors.
Because the temperature,

509
00:28:21,300 --> 00:28:24,240
we need to not only consider the image 
con the,

510
00:28:24,241 --> 00:28:25,074
the special content of the image,
but also we need to consider the 

511
00:28:28,020 --> 00:28:30,950
temporal relationship between the,
uh,

512
00:28:31,180 --> 00:28:32,160
adjusting the frames.

513
00:28:32,280 --> 00:28:35,040
So we perform,
we propose to us single story,

514
00:28:35,100 --> 00:28:35,933
a single stream and natural language.
They don't look as a Australian network 

515
00:28:39,420 --> 00:28:40,980
for this part.
We have the we,

516
00:28:41,070 --> 00:28:41,903
sorry.
Uh,

517
00:28:41,970 --> 00:28:42,803
we have the videos and I will have a 
sentence in the world perform frame by 

518
00:28:46,501 --> 00:28:47,334
word interactions or mentions here all 
mentioned Syria matching pro matching 

519
00:28:52,650 --> 00:28:56,610
performance matching between the 
sentence under the video.

520
00:28:56,760 --> 00:28:58,180
Then we have,
uh,

521
00:28:58,310 --> 00:28:59,120
uh,
with,

522
00:28:59,120 --> 00:29:04,120
with this matching behaviors,
we perform a temporal proposals and have

523
00:29:05,130 --> 00:29:05,963
different anchors.
Then we'll have definitely scores with 

524
00:29:07,891 --> 00:29:08,724
this,
the single stream processes we can 

525
00:29:10,680 --> 00:29:14,880
efficient and I localize the sentences.
He's a video sequences.

526
00:29:15,630 --> 00:29:18,780
Okay.
And as this is some results of our,

527
00:29:18,900 --> 00:29:23,850
this is someone who does of our proposed
a masters and they see the videos and as

528
00:29:23,860 --> 00:29:24,900
they say,
have a sentence,

529
00:29:25,110 --> 00:29:28,180
a man in a red shirt caps his hand.
And,

530
00:29:28,190 --> 00:29:29,023
uh,
the,

531
00:29:29,300 --> 00:29:30,510
the,
the,

532
00:29:30,511 --> 00:29:34,250
the gray ones is our ground shoes and a,
the green greenland is,

533
00:29:34,260 --> 00:29:39,260
we utilize a vgg 16 as the image as an 
encoder.

534
00:29:39,720 --> 00:29:44,720
And a for the blue ones is we utilize 
the inception before as an encoder.

535
00:29:46,060 --> 00:29:46,870
And,
uh,

536
00:29:46,870 --> 00:29:50,410
the yellow was when you guys assist 
really as the encoder.

537
00:29:50,560 --> 00:29:54,180
So you can see that if we utilize a vgg 
16 and,

538
00:29:54,181 --> 00:29:55,490
uh,
uh,

539
00:29:55,491 --> 00:29:56,324
inception before,
we can get a reasonable accurate or is 

540
00:29:59,951 --> 00:30:01,270
out at your,
for this,

541
00:30:01,900 --> 00:30:03,100
for this,
specify the task.

542
00:30:03,120 --> 00:30:06,490
We're up from all the competitor models 
on this,

543
00:30:06,491 --> 00:30:08,260
especially the task.
And therefore this,

544
00:30:08,261 --> 00:30:09,490
that sat the,
for this,

545
00:30:09,730 --> 00:30:10,563
the,
the camera was zoom out to show where 

546
00:30:13,091 --> 00:30:15,610
the,
what four is coming front so they can,

547
00:30:15,640 --> 00:30:17,670
you can see that,
uh,

548
00:30:17,710 --> 00:30:19,240
the for the,
for the,

549
00:30:19,290 --> 00:30:20,123
uh,
for the furion with during in the 

550
00:30:21,131 --> 00:30:26,131
inception before and optic flow,
we can get to the accurate prediction on

551
00:30:26,591 --> 00:30:28,630
this,
on this example.

552
00:30:29,230 --> 00:30:30,040
Okay.
Wait,

553
00:30:30,040 --> 00:30:30,760
uh,
another,

554
00:30:30,760 --> 00:30:32,530
uh,
besides we examine,

555
00:30:32,590 --> 00:30:37,590
we examine the frame and the frame by 
word attentions here and the,

556
00:30:38,111 --> 00:30:40,060
for this sentence,
what for,

557
00:30:40,090 --> 00:30:43,600
for this sentence,
for this center and worked for in forest

558
00:30:43,870 --> 00:30:47,230
for they say you can see that for this 
all video sequences in the forest,

559
00:30:47,620 --> 00:30:50,710
the first day is appeared over all 
frames.

560
00:30:50,740 --> 00:30:55,740
So the attach matters will be attended,
will be triggered at equally.

561
00:30:56,230 --> 00:31:00,070
But for this,
for this workforce only appearing in the

562
00:31:00,071 --> 00:31:04,390
forest first of frame so it won't have 
this here.

563
00:31:04,750 --> 00:31:06,250
Okay.
And uh,

564
00:31:06,450 --> 00:31:08,140
uh,
the same observation that can be,

565
00:31:08,360 --> 00:31:09,193
uh,
can be observed from this to give me 

566
00:31:11,650 --> 00:31:13,090
examples.
Okay.

567
00:31:13,210 --> 00:31:14,043
So this is a lots of works that I 
introduced about the computer vision 

568
00:31:17,560 --> 00:31:21,640
meets with no social network.
Actually,

569
00:31:21,641 --> 00:31:22,474
besides that in our lab with not only 
are we not only do the worker uncovered 

570
00:31:27,460 --> 00:31:28,680
variant,
but also we have some,

571
00:31:28,681 --> 00:31:31,630
some of the other works on the AI 
projects.

572
00:31:31,840 --> 00:31:34,590
The most important APP or one of the 
most important,

573
00:31:34,670 --> 00:31:35,503
I projected the APP plus house and we 
would like to deploys a or utilize the 

574
00:31:40,031 --> 00:31:45,031
AI technology to Max a health care.
And also the first,

575
00:31:45,100 --> 00:31:45,933
the healthcare,
the first day is that we would like to 

576
00:31:47,810 --> 00:31:52,810
ut that ai technology or deep learning 
and our to analysis a medical images and

577
00:31:53,080 --> 00:31:53,913
um,
to,

578
00:31:54,340 --> 00:31:59,340
to help the,
to help the doctors to Mac the uh,

579
00:32:01,030 --> 00:32:02,130
to,
uh,

580
00:32:02,230 --> 00:32:04,570
to have the detection to make the 
diagnosis.

581
00:32:04,750 --> 00:32:05,411
And the,
for this,

582
00:32:05,411 --> 00:32:09,430
for this specific,
for this specific cancers such as a lung

583
00:32:09,610 --> 00:32:13,540
cancer screens about for this 
recognition rate is about,

584
00:32:13,600 --> 00:32:18,600
is over 98 percentage.
And also in the future we would like to,

585
00:32:20,160 --> 00:32:22,060
uh,
would you lie to the,

586
00:32:22,420 --> 00:32:24,820
to perform a computer added that 
diagnosis.

587
00:32:25,030 --> 00:32:25,863
And we have some artists scripts about 
the distribution of the passions and 

588
00:32:30,191 --> 00:32:34,540
also we have some medical images about 
the passions and they would like to have

589
00:32:35,310 --> 00:32:36,143
a doctor to attack max attack gnosis and
also even in the future we have to have 

590
00:32:41,640 --> 00:32:42,473
the doctor to Oh,
this design the treatment about some of 

591
00:32:46,490 --> 00:32:47,990
the disease.
Okay.

592
00:32:48,710 --> 00:32:52,520
Another important topic is the Ai Gang 
because the gang,

593
00:32:52,700 --> 00:32:53,533
because tencent,
the game is the largest in the number 

594
00:32:55,161 --> 00:32:57,590
one game.
Company is a of the word.

595
00:32:57,740 --> 00:32:58,573
So would like to utilize the AI 
technology to evolve to be more deeply 

596
00:33:03,051 --> 00:33:04,100
involved in the game.

597
00:33:04,130 --> 00:33:04,963
Maybe that designed the plane or 
something like that to make the game to 

598
00:33:07,941 --> 00:33:10,990
be more interesting and a more,
uh,

599
00:33:11,190 --> 00:33:13,610
more interesting to the you,
to the players.

600
00:33:13,970 --> 00:33:18,410
Okay.
So I will give a brief summary here.

601
00:33:18,500 --> 00:33:19,333
And the first I will give an 
introduction about our talk computer 

602
00:33:22,211 --> 00:33:23,044
vision meets social networks.
And we introduced some works that we 

603
00:33:25,971 --> 00:33:29,660
have down in Tenson al up from that 
research,

604
00:33:29,680 --> 00:33:33,770
the product and something related to the
image of video processing,

605
00:33:33,800 --> 00:33:35,330
understanding,
analysis,

606
00:33:35,331 --> 00:33:37,720
something like that.
And also we have,

607
00:33:37,870 --> 00:33:40,760
I have introduced the,
about some one hour,

608
00:33:40,820 --> 00:33:41,750
uh,
several,

609
00:33:41,800 --> 00:33:43,490
uh,
our important projects.

610
00:33:43,670 --> 00:33:45,140
A applies to ax,
the ax,

611
00:33:45,141 --> 00:33:48,380
maybe house.
Are you in the future?

612
00:33:48,381 --> 00:33:50,960
Some robotics or something like that.
Okay.

613
00:33:51,320 --> 00:33:54,890
So this is my lecture.
Okay.

614
00:33:54,891 --> 00:33:55,724
Thank you.

