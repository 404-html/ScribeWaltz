1
00:00:03,190 --> 00:00:04,023
So a lot is being written and said about
deep learning and the new ai wave and 

2
00:00:10,470 --> 00:00:14,060
not everything is true.
So yes,

3
00:00:14,100 --> 00:00:14,933
one of the things that's natural,
so the idea that machines program 

4
00:00:19,171 --> 00:00:20,004
themselves these days and all the have 
to do is put mediocre data in turn the 

5
00:00:24,691 --> 00:00:29,691
crank and outcome excellent results.
But that is um,

6
00:00:31,600 --> 00:00:32,433
but I think of true magic in this deep 
learning and here's what really 

7
00:00:36,031 --> 00:00:36,864
fascinates me the most about this field 
is a deep learning led's or solve 

8
00:00:40,231 --> 00:00:41,064
problems.
We don't know how to program so we can 

9
00:00:45,391 --> 00:00:46,224
solve problems.
We actually don't understand in detail 

10
00:00:49,900 --> 00:00:53,370
sophia in sufficient detail that we can 
program a solution.

11
00:00:53,970 --> 00:00:56,790
The first time I witnessed this is quite
awhile ago,

12
00:00:56,791 --> 00:01:01,791
it was around 1992 I was in at eth in 
Switzerland working on a reading machine

13
00:01:04,261 --> 00:01:08,380
for the blind and we made good progress 
on printed texts.

14
00:01:08,420 --> 00:01:10,020
But we,
when we,

15
00:01:10,070 --> 00:01:15,070
we got nowhere for handwritten text.
And so I was reading through paper after

16
00:01:16,081 --> 00:01:21,000
paper was promising titles and just to 
be disappointed time and again.

17
00:01:21,390 --> 00:01:22,223
So most people back then they worked on 
capitol letters from eight to f for 

18
00:01:26,401 --> 00:01:27,234
example,
that tiny variations to the bitmap and 

19
00:01:30,941 --> 00:01:34,950
10 called it Fontin variant.
And then somebody pointed me to the work

20
00:01:34,951 --> 00:01:35,784
of Yonder coon and I looked into that 
and was very fascinated because he was 

21
00:01:40,021 --> 00:01:42,780
working with actual data from the u s 
postal service,

22
00:01:42,990 --> 00:01:44,700
no,
no cheating possible.

23
00:01:45,150 --> 00:01:47,970
And he claimed to have excellent 
results.

24
00:01:48,660 --> 00:01:53,070
And he's methods we are comparatively 
simple.

25
00:01:53,280 --> 00:01:58,260
So we rushed to re implementers and well
first we had to rush to actually collect

26
00:01:58,261 --> 00:02:02,600
data and then train the network and it 
felt like magic it,

27
00:02:02,601 --> 00:02:07,601
it would actually read and do this 
seemingly impossible task.

28
00:02:09,300 --> 00:02:13,950
So a year later I was fortunate to join 
that very team at bell labs.

29
00:02:14,550 --> 00:02:17,610
So I divided my presentation into two 
parts.

30
00:02:17,611 --> 00:02:19,890
The first part I will talk about the 
early uh,

31
00:02:19,920 --> 00:02:20,753
deep learning work at bell labs.
And then the second part I will talk 

32
00:02:24,031 --> 00:02:27,540
about our current vogue at Nvidia on 
self driving cars.

33
00:02:28,980 --> 00:02:33,980
So from 1990 from 1985 to 90 1995 was a 
10 year period.

34
00:02:36,091 --> 00:02:40,020
It was incredibly productive.
So in that team,

35
00:02:40,680 --> 00:02:43,260
that team not only created convolutional
networks,

36
00:02:43,350 --> 00:02:44,183
uh,
it also created support vector machines 

37
00:02:46,540 --> 00:02:51,000
as vms and later foundation of 
important,

38
00:02:52,170 --> 00:02:53,520
uh,
machine learning,

39
00:02:53,820 --> 00:02:56,430
learning theory,
and also,

40
00:02:56,670 --> 00:02:57,503
uh,
created several generations of neural 

41
00:02:58,771 --> 00:02:59,604
network.

42
00:03:01,040 --> 00:03:01,790
Okay.

43
00:03:01,790 --> 00:03:04,130
This is the building in homedale new 
Chelsea.

44
00:03:04,430 --> 00:03:08,770
So gigantic building,
actually a t eight house,

45
00:03:08,790 --> 00:03:10,460
about 6,000
employees,

46
00:03:10,970 --> 00:03:15,650
300 of those were in research and 30 of 
those in machine learning.

47
00:03:16,040 --> 00:03:19,610
So you'll probably recognize several of 
the names.

48
00:03:21,990 --> 00:03:22,823
Um,
and since as researchers we tended to 

49
00:03:26,041 --> 00:03:29,040
show up late in the day,
we always had to park way out here,

50
00:03:29,730 --> 00:03:30,563
which added about 10 more minutes to 
your commute just to walk into the 

51
00:03:33,661 --> 00:03:38,270
building and into your office.
There's these two ponds here.

52
00:03:38,990 --> 00:03:41,490
Uh,
could you imagine what they are for?

53
00:03:42,570 --> 00:03:43,920
They're not just landscaping.

54
00:03:45,530 --> 00:03:46,363
Yeah,

55
00:03:46,990 --> 00:03:47,823
yeah.
They thought that he takes changes for 

56
00:03:48,520 --> 00:03:50,470
the,
for the air conditioning of the building

57
00:03:50,710 --> 00:03:53,590
or it used to be late today,
replaced them with cooling towers.

58
00:03:55,710 --> 00:03:59,310
This is the very first data sets that 
I've worked with,

59
00:03:59,940 --> 00:04:00,773
uh,
collected among the researchers 

60
00:04:01,711 --> 00:04:02,544
themselves.
A later they got data from the U S 

61
00:04:05,550 --> 00:04:06,383
Postal Service.
Um,

62
00:04:06,480 --> 00:04:11,480
and then that grew into nist and nist,
which is still very widely used today.

63
00:04:16,480 --> 00:04:17,313
So a lot of the work was about what 
structure to be put into the learning 

64
00:04:20,771 --> 00:04:21,604
machines.
What prior knowledge do we equip them 

65
00:04:22,871 --> 00:04:24,580
with to,
to perform the task?

66
00:04:24,581 --> 00:04:26,020
Well,
um,

67
00:04:26,110 --> 00:04:30,970
if you talk about,
if you look at this example here and you

68
00:04:30,971 --> 00:04:31,804
needed to build a classifier that can 
distinguish between the red and the 

69
00:04:35,411 --> 00:04:40,411
green classes and you wonder what class 
does this x belong to?

70
00:04:42,460 --> 00:04:44,770
So if you take,
um,

71
00:04:45,040 --> 00:04:47,410
location east,
west,

72
00:04:47,411 --> 00:04:52,090
north,
south as you criteria to classify,

73
00:04:52,420 --> 00:04:56,200
then you would probably say the x 
belongs to Green.

74
00:04:58,140 --> 00:04:58,973
But if you understand that these points 
are actually real points on the surface 

75
00:05:02,021 --> 00:05:07,021
of the earth and it happens that the 
green ones are on board and the red ones

76
00:05:09,041 --> 00:05:09,874
are on land,
then you could change your criteria and 

77
00:05:12,401 --> 00:05:16,420
say,
let me take a level above the height,

78
00:05:16,421 --> 00:05:17,254
above sea level as the criteria,
in which case the problem becomes 

79
00:05:20,471 --> 00:05:22,620
trivial.
So this point is actually on land.

80
00:05:22,630 --> 00:05:27,630
So he belongs to the right class.
Anybody see that?

81
00:05:27,680 --> 00:05:28,513
He sees

82
00:05:31,300 --> 00:05:33,710
this is Manhattan,
New York.

83
00:05:35,270 --> 00:05:40,270
So this is an example how programming or
are using prior knowledge actually helps

84
00:05:41,451 --> 00:05:45,170
the classification task enormously.
Um,

85
00:05:45,171 --> 00:05:48,830
of course that led to the creation of 
convolutional networks.

86
00:05:48,890 --> 00:05:51,770
This is an old slide that we use to 
explain how they work.

87
00:05:52,340 --> 00:05:56,060
Naturally you have these convolutions 
that can learn to do,

88
00:05:56,360 --> 00:05:58,290
um,
today's lines,

89
00:05:58,320 --> 00:05:59,520
vertical,
horizontal,

90
00:05:59,521 --> 00:06:03,090
and then next layer can the deck at and 
so on.

91
00:06:03,900 --> 00:06:08,900
And of course the leap of faith was that
we don't have design these features,

92
00:06:09,691 --> 00:06:10,524
but actually like a numerical 
optimization algorithm find optimal 

93
00:06:14,671 --> 00:06:18,480
solutions.
Oh,

94
00:06:18,481 --> 00:06:21,900
he has an old video from yonder coon 
showing low net.

95
00:06:23,010 --> 00:06:23,660
Yeah,

96
00:06:23,660 --> 00:06:28,240
you supposed to own an old 80 and tpc I 
believe was a dsp accelerator in it.

97
00:06:31,400 --> 00:06:32,880
So yeah,
you may have seen the video.

98
00:06:32,881 --> 00:06:37,881
It's,
it's on youtube and at that time,

99
00:06:43,910 --> 00:06:44,631
many,
many,

100
00:06:44,631 --> 00:06:48,680
many brilliant minds tried so hard for 
years to solve the problem.

101
00:06:49,370 --> 00:06:53,720
And here comes,
this network can just does it was almost

102
00:06:53,721 --> 00:06:57,470
looks with ease.
Then young gets creative.

103
00:06:59,010 --> 00:07:01,350
I'm quite sure that this type of 
characters,

104
00:07:01,351 --> 00:07:06,351
we're not in the training side.
Some other people from the lab.

105
00:07:10,480 --> 00:07:12,400
This is Donnie Henderson,

106
00:07:14,380 --> 00:07:17,150
a three child who was the lab director 
at the time.

107
00:07:19,250 --> 00:07:24,250
So as we became to look at,
learning is essentially two main things,

108
00:07:25,641 --> 00:07:26,474
monies to build prior knowledge into the
architecture of what Vladimir about 

109
00:07:30,290 --> 00:07:32,720
calls,
structural risk minimization.

110
00:07:33,650 --> 00:07:34,483
And the other one is a capacity control.
So you need to match the size of your 

111
00:07:39,680 --> 00:07:40,513
network to the amount of diversity of 
the data that you have and one really 

112
00:07:44,631 --> 00:07:49,040
good tool to do that or to to analyze 
that these learning curves.

113
00:07:50,690 --> 00:07:55,690
So this is not the number of epochs he 
otis a actually each point on this chart

114
00:07:56,061 --> 00:07:56,894
is a fully trained network.
So what do you do is you measure the 

115
00:08:01,701 --> 00:08:06,701
performance of your network on the 
training set and on the test track while

116
00:08:07,040 --> 00:08:07,873
you're growing the and not the amount of
data that you're training the network 

117
00:08:10,461 --> 00:08:11,750
with.
So this is the,

118
00:08:11,751 --> 00:08:12,584
uh,
the number of examples that you use for 

119
00:08:13,881 --> 00:08:14,714
training.

120
00:08:14,990 --> 00:08:17,150
So if you have very,
very few examples,

121
00:08:17,151 --> 00:08:17,984
then the networks can essentially 
memorized a training set and the ad or 

122
00:08:22,331 --> 00:08:26,630
on the training side is zero.
While the error on the test that is very

123
00:08:26,631 --> 00:08:29,150
big.
And then as you grow the Dataset,

124
00:08:29,210 --> 00:08:30,610
the,
the,

125
00:08:30,611 --> 00:08:34,550
uh,
error on the test that calms down and at

126
00:08:34,551 --> 00:08:35,384
some point the networks can no longer 
memorize and that the entire data set 

127
00:08:39,711 --> 00:08:43,130
and the,
the training said Arrow starts to grow.

128
00:08:43,610 --> 00:08:48,560
And empirically it's been shown that 
these curves eventually die neat.

129
00:08:48,920 --> 00:08:51,110
And you don't need to plot the entire 
curve.

130
00:08:52,010 --> 00:08:54,980
It's usually in the middle between the 
two curves.

131
00:08:54,990 --> 00:08:58,530
So you can half a good idea what to 
expect.

132
00:08:59,310 --> 00:09:00,143
So if you hit this point a year,
then it becomes clear that it doesn't 

133
00:09:03,871 --> 00:09:04,704
help you to add more data.
You have to increase the capacity of 

134
00:09:07,201 --> 00:09:10,730
your network.
Uh,

135
00:09:10,731 --> 00:09:14,390
he has a learning curve from real life 
that we did last week.

136
00:09:14,660 --> 00:09:15,920
So this is,
uh,

137
00:09:16,040 --> 00:09:17,630
here,
uh,

138
00:09:17,690 --> 00:09:20,270
predicting the steering angle of a 
human.

139
00:09:20,271 --> 00:09:23,330
So how close does the netbook steer like
a human?

140
00:09:23,331 --> 00:09:24,820
And you see that,
uh,

141
00:09:25,130 --> 00:09:28,940
around here we reached a point where 
adding new data wouldn't help us.

142
00:09:32,100 --> 00:09:32,933
Then in the 90s,
[inaudible] was sometimes heated debate 

143
00:09:35,641 --> 00:09:39,060
about what is the best algorithm for 
classifying characters.

144
00:09:39,210 --> 00:09:40,043
And

145
00:09:40,540 --> 00:09:42,490
the,
the,

146
00:09:42,491 --> 00:09:43,324
uh,

147
00:09:44,480 --> 00:09:46,750
manager of the group at the time was 
Larry Charcoal.

148
00:09:46,760 --> 00:09:47,630
And he said,
well,

149
00:09:47,631 --> 00:09:50,150
let's just find out and combat all of 
those.

150
00:09:50,420 --> 00:09:52,350
So this was one of these ideal 
situations.

151
00:09:52,351 --> 00:09:53,184
Very had several people competing with 
ideas and everybody was convinced my 

152
00:09:55,941 --> 00:09:58,000
idea is the best.
Um,

153
00:09:58,010 --> 00:10:00,350
so I'll be combined them all and if I 
remember correctly,

154
00:10:00,351 --> 00:10:01,184
that's what,
that's the reason that they created the 

155
00:10:03,480 --> 00:10:06,920
nist database for.
So m stands for modified

156
00:10:09,850 --> 00:10:11,770
the result is somewhat interesting.
So,

157
00:10:11,860 --> 00:10:12,693
um,
k nearest neighbor that nobody believed 

158
00:10:14,651 --> 00:10:17,000
that that would be the winner.
Um,

159
00:10:17,060 --> 00:10:20,680
that was just there for reference.
Also fully connected network.

160
00:10:20,720 --> 00:10:23,800
They're just there for reference.
Then this is lanette one.

161
00:10:24,400 --> 00:10:25,233
This was optimized for a much smaller 
data set from the United States postal 

162
00:10:28,361 --> 00:10:29,194
survey.
So that didn't do very well on this 

163
00:10:31,241 --> 00:10:32,560
either.
In fact,

164
00:10:32,770 --> 00:10:34,900
it was even slightly versed and fully 
connected.

165
00:10:36,190 --> 00:10:39,260
And then these here,
these were the actual competitor.

166
00:10:39,261 --> 00:10:44,040
So this is a convolutional network,
but this time optimized for the lots are

167
00:10:44,070 --> 00:10:46,510
mds data set.
Uh,

168
00:10:46,600 --> 00:10:51,430
I'll get back to boosting in a minute.
Then different variations.

169
00:10:51,520 --> 00:10:53,860
Um,
so he,

170
00:10:53,861 --> 00:10:54,790
uh,
for example,

171
00:10:55,960 --> 00:10:58,660
k nearest neighbor of course,
has one big flaw.

172
00:10:58,750 --> 00:11:01,000
So if you'd just take the Euclidean 
distance,

173
00:11:01,060 --> 00:11:04,180
um,
as your metric as we did here,

174
00:11:04,900 --> 00:11:09,430
then if you shift to characters which 
are actually the same by a few pixels,

175
00:11:09,431 --> 00:11:12,490
then the Euclidean distance starts to 
become enormous.

176
00:11:12,760 --> 00:11:13,593
So it doesn't really measure how close 
to our house similar to characters are 

177
00:11:18,371 --> 00:11:19,490
very well.
So here,

178
00:11:19,520 --> 00:11:22,240
the idea of stop lights instead of using
the Euclidean distance,

179
00:11:22,241 --> 00:11:24,940
let's do the same thing.
I'm used the EUCLIDEAN distance,

180
00:11:24,941 --> 00:11:28,870
but not in the pixel space,
but in the uppermost feature map.

181
00:11:29,350 --> 00:11:34,000
And that's a boost.
It's the performance quiet a bit.

182
00:11:34,720 --> 00:11:38,530
Tangent distance was another one of the 
ideas we talked a lot at a time.

183
00:11:39,010 --> 00:11:39,843
Uh,
another clever trick to increase the 

184
00:11:41,710 --> 00:11:42,543
performance of k nearest neighbor.
So if you'll picture each character to 

185
00:11:46,181 --> 00:11:47,014
be a point in a very high dimensional 
pixel space and you start doing some 

186
00:11:51,210 --> 00:11:54,280
photo probations to eight without 
changing the actual characters.

187
00:11:54,281 --> 00:11:56,240
So you,
you rotate it all it a little bit,

188
00:11:56,241 --> 00:11:59,080
you shifted,
you grow the stroke a bit,

189
00:11:59,900 --> 00:12:00,733
um,
then that forms a surface around that 

190
00:12:03,641 --> 00:12:04,474
point.
And if you don't deviate too much from 

191
00:12:06,611 --> 00:12:09,310
the original point,
and you can model that as a plane.

192
00:12:10,000 --> 00:12:10,833
And the tangent reasons is simply the 
EUCLIDEAN distance between two such 

193
00:12:15,221 --> 00:12:16,054
planes.
I'm so clever idea was a lot of prior 

194
00:12:18,791 --> 00:12:23,791
knowledge of the problem built into and 
that also gets very good performance and

195
00:12:23,930 --> 00:12:26,680
optimal margin.
That's essentially an Svm.

196
00:12:27,460 --> 00:12:30,430
And so what's interesting is that they 
all have the exact same performance.

197
00:12:31,330 --> 00:12:34,720
The only one that actually improve the 
performance was boosting,

198
00:12:34,990 --> 00:12:37,360
which is kind of a different type of 
approach.

199
00:12:37,361 --> 00:12:38,194
So here you train multiple networks,
you're trying to second network on the 

200
00:12:41,231 --> 00:12:43,310
mistakes of the first one and your 
trainers.

201
00:12:43,340 --> 00:12:46,360
Third one on there,
the first to disagree.

202
00:12:46,690 --> 00:12:50,290
So you get multiple expert.
I specialize on different parts of it,

203
00:12:50,350 --> 00:12:51,183
of the training sentence.
So it's not too surprising that that 

204
00:12:53,411 --> 00:12:58,411
actually would increase the performance.
So what Larry said in hindsight is that,

205
00:12:59,470 --> 00:13:02,230
well,
it's not too surprising that I would all

206
00:13:02,350 --> 00:13:03,183
perform the same because everybody was 
doing the same type of approach in 

207
00:13:09,101 --> 00:13:09,934
exploring them the past capacity of 
their learning system by doing the 

208
00:13:13,271 --> 00:13:17,470
learning curves.
The one thing that stands out in my mind

209
00:13:17,471 --> 00:13:18,304
is the Svm because that has no prior 
built in knowledge about the task at 

210
00:13:22,661 --> 00:13:25,030
all.
But all of the others too.

211
00:13:27,610 --> 00:13:28,443
Um,
classification rate is not the only 

212
00:13:29,681 --> 00:13:32,170
thing that you should actually focus on.
Of course,

213
00:13:32,171 --> 00:13:35,320
it's also memory consumption,
which is not on this chart,

214
00:13:35,890 --> 00:13:36,723
a training time and inference time.
So all of the memory based k nearest 

215
00:13:39,851 --> 00:13:43,180
neighbor types,
they use very little training time,

216
00:13:43,181 --> 00:13:44,560
but then they use a lot of memory.

217
00:13:47,470 --> 00:13:48,303
So the lessons,
some of the lessons that I took from 

218
00:13:50,771 --> 00:13:52,510
that time is,
uh,

219
00:13:52,720 --> 00:13:55,240
one is still very relevant,
is look at the data.

220
00:13:55,690 --> 00:13:58,990
I've seen so many people miss important 
cues.

221
00:13:58,991 --> 00:14:02,680
I'm confused why you we was Rgb,
for example.

222
00:14:03,040 --> 00:14:04,900
That doesn't make your system failed 
completely.

223
00:14:04,901 --> 00:14:06,760
It just doesn't perform as well as he 
could.

224
00:14:08,170 --> 00:14:10,960
Um,
solid debugging tools are critical.

225
00:14:11,050 --> 00:14:11,883
These a neural networks have a nasty 
habit of a masking box and the they and 

226
00:14:17,851 --> 00:14:18,684
I adapted a,
they try their best to work around 

227
00:14:20,141 --> 00:14:22,650
parks,
um,

228
00:14:22,900 --> 00:14:23,733
validated training data.
Again that's related to look at the 

229
00:14:26,561 --> 00:14:28,060
data.
Um,

230
00:14:28,270 --> 00:14:29,103
so many data sets I've seen actually 
have a grave labeling mistakes and to 

231
00:14:34,061 --> 00:14:34,894
work is experimental in nature.
At least that's what it is to stay off 

232
00:14:37,961 --> 00:14:41,940
today.
So in most cases you can just copy paste

233
00:14:41,941 --> 00:14:45,670
or recipe from somebody else that will 
now give you the optimal results.

234
00:14:46,840 --> 00:14:47,673
And the last one is work with real data.
Synthetic data is great for debugging 

235
00:14:52,760 --> 00:14:55,010
and you can certainly explore certain 
trends,

236
00:14:55,011 --> 00:14:58,100
but to get a sense of very,
you really are,

237
00:14:58,600 --> 00:14:59,660
um,
you,

238
00:14:59,720 --> 00:15:01,370
you have to work with real data.

239
00:15:04,610 --> 00:15:07,850
So what happened after 95,
actually riding around the 95,

240
00:15:07,930 --> 00:15:09,920
uh,
uh,

241
00:15:10,250 --> 00:15:11,083
a t and t released a first production 
version of convolutional networks for 

242
00:15:15,020 --> 00:15:15,853
commercial check reading.
And eventually 20% of all the checks 

243
00:15:19,221 --> 00:15:22,940
written in the u s were processed by 
that system or right by that system.

244
00:15:23,450 --> 00:15:24,560
To me,
that was the real,

245
00:15:24,800 --> 00:15:25,633
the real sign of success.
If a technology is a commercially buy 

246
00:15:31,270 --> 00:15:35,450
apple at the set in the same year 
actually,

247
00:15:35,570 --> 00:15:36,403
um,
maybe in the morning sitting together 

248
00:15:39,710 --> 00:15:43,100
discussing how we should celebrate this 
fact.

249
00:15:43,190 --> 00:15:48,190
The success was the commercial check 
reading and a message came in that day.

250
00:15:48,291 --> 00:15:52,460
T and t d announcement came in at eight 
and t would break up into three parts.

251
00:15:52,940 --> 00:15:55,640
So that was quite a shock.
And then in 2002,

252
00:15:55,641 --> 00:15:58,370
there were mass layoffs and most people 
left.

253
00:15:59,300 --> 00:16:01,700
And some of the important folks from 
machine learning,

254
00:16:01,701 --> 00:16:04,640
they found themselves working together 
again,

255
00:16:04,730 --> 00:16:05,563
either add star power or for Darpa and 
created several programs such as locker 

256
00:16:10,340 --> 00:16:12,500
learning,
applied to ground robots,

257
00:16:13,200 --> 00:16:14,450
uh,
learning locomotion.

258
00:16:14,510 --> 00:16:15,343
One was even called deep learning and 
also the helping to get about his 

259
00:16:19,820 --> 00:16:22,070
difference.
Darpa challenges launched.

260
00:16:23,330 --> 00:16:24,163
And then in 2002 deep learning becomes 
really popular and I guess it's 

261
00:16:27,591 --> 00:16:28,424
triggered by the availability of data,
the availability of compute powers and 

262
00:16:34,131 --> 00:16:35,310
also,
uh,

263
00:16:35,330 --> 00:16:36,163
ready commercial applications.
So all of these large scale internet 

264
00:16:39,711 --> 00:16:43,640
applications in speech recognition and 
image classification,

265
00:16:43,990 --> 00:16:44,823
they bill radio at this point.
And I guess there was just not too much 

266
00:16:48,141 --> 00:16:53,120
money in check rating for the economy to
take notice back then.

267
00:16:56,300 --> 00:16:58,730
So this brings me to what you're doing 
today.

268
00:16:59,900 --> 00:17:04,070
Very similar technology applied to a 
self driving costs in this case.

269
00:17:04,700 --> 00:17:09,680
So felleston over the off the entire 
stack of and be yourself driving.

270
00:17:10,040 --> 00:17:14,930
So we have at the bottom the hardware 
that goes into the car,

271
00:17:15,200 --> 00:17:20,200
that's the drive px family of products.
The most recent is called Pegasus.

272
00:17:20,360 --> 00:17:25,360
That was just announced at ces.
Then we have the operating system or the

273
00:17:26,211 --> 00:17:27,710
old timer,
but I think system layer.

274
00:17:28,460 --> 00:17:32,140
And then on top of that is driver folks.
That's what I call the middle man.

275
00:17:32,141 --> 00:17:32,974
So that does sensor abstraction does a,
all the logging tools interprocess 

276
00:17:36,651 --> 00:17:37,484
communication and it has low level 
computer division library such as image 

277
00:17:41,511 --> 00:17:46,120
transformations.
And then on top of that is a drive a,

278
00:17:46,130 --> 00:17:47,900
b.
This is the application.

279
00:17:48,890 --> 00:17:49,723
Yeah.
So this is where it would be put 

280
00:17:50,951 --> 00:17:54,550
together all of the other technology to 
form actual applications.

281
00:17:54,850 --> 00:17:57,800
And some examples are here.
This is um,

282
00:17:57,880 --> 00:18:01,170
sensor fusion from radar and camera on 
this,

283
00:18:01,171 --> 00:18:05,730
this lidar point cloud processing or 
deep learning based object detector.

284
00:18:06,460 --> 00:18:09,550
So the detective boss here,
or to pedestrians back there.

285
00:18:10,030 --> 00:18:12,010
This is deep learning based,
uh,

286
00:18:12,060 --> 00:18:13,540
pre risk-based.
That action.

287
00:18:14,390 --> 00:18:15,223
Um,
this is localization based on hd maps 

288
00:18:17,890 --> 00:18:22,890
and then this year is a perception based
as a planning.

289
00:18:23,470 --> 00:18:26,440
This is actually what comes out of our 
group in New Jersey.

290
00:18:26,441 --> 00:18:28,630
So what a new Chelsea group is doing 
there,

291
00:18:28,660 --> 00:18:31,450
we contribute into this layer here

292
00:18:33,820 --> 00:18:37,780
and our goal is to solve the heart and 
on solves problems.

293
00:18:37,810 --> 00:18:40,180
And I think there's a lot of those in 
self driving car.

294
00:18:40,510 --> 00:18:43,060
So if I think back to a character 
recognition,

295
00:18:43,061 --> 00:18:47,590
if we can't even program handwritten 
character recognition,

296
00:18:48,670 --> 00:18:49,503
then it's very likely that dealing with 
other humans and all kinds of different 

297
00:18:55,421 --> 00:19:00,421
situations is likely not going to be 
solvable by just programming.

298
00:19:00,850 --> 00:19:03,370
So we concentrate on these heart 
problems for two reasons.

299
00:19:03,371 --> 00:19:06,340
One is that we want to provide 
algorithmic diversity.

300
00:19:07,540 --> 00:19:08,373
So in a safety critical system,
it's unlikely that you want to rely on 

301
00:19:12,371 --> 00:19:13,204
any single algorithm.
And the second reason is that we can 

302
00:19:16,931 --> 00:19:20,020
solve functionality that might not be 
solvable otherwise.

303
00:19:20,080 --> 00:19:20,913
Like,
uh,

304
00:19:21,340 --> 00:19:26,340
taking turns just based on perception 
without map data or learn to march on to

305
00:19:27,880 --> 00:19:28,713
a busy highway where you have to 
negotiate with the other cars and 

306
00:19:30,971 --> 00:19:34,570
squeeze yourself in.
And then other,

307
00:19:34,630 --> 00:19:36,980
the other labs,
um,

308
00:19:37,030 --> 00:19:40,990
the other autonomous labs in a Nvidia 
are in California,

309
00:19:41,020 --> 00:19:43,030
in Boulder,
in Seattle,

310
00:19:43,060 --> 00:19:47,320
and in Europe.
This is,

311
00:19:47,350 --> 00:19:48,183
oh,
we're actually back in the same 

312
00:19:48,701 --> 00:19:51,040
building,
which is cool.

313
00:19:51,520 --> 00:19:53,920
The building was empty for over 10 
years,

314
00:19:53,921 --> 00:19:56,140
but it's now being redeveloped for mixed
use.

315
00:19:56,500 --> 00:20:00,160
So there's a number of different tech 
tech companies in there.

316
00:20:00,161 --> 00:20:04,270
So in Eto is renting space around here 
and there's also,

317
00:20:04,271 --> 00:20:08,500
we're going to get restaurants and shops
and on the rooftop test plans to build a

318
00:20:08,501 --> 00:20:09,334
hotel.

319
00:20:11,770 --> 00:20:12,603
Uh,

320
00:20:12,870 --> 00:20:14,890
the reason why the tear is,
um,

321
00:20:14,970 --> 00:20:15,803
not so much sentimental.
It's because this is actually a very 

322
00:20:18,151 --> 00:20:20,880
good environment for testing,
self driving cars.

323
00:20:21,240 --> 00:20:22,073
We have plenty of space in the basement 
of the building to store and welcome to 

324
00:20:25,900 --> 00:20:27,780
cars.
And then there's two tunnels here.

325
00:20:28,350 --> 00:20:29,183
Then with that we can take and dare 
leaders right up to these private 

326
00:20:32,191 --> 00:20:33,300
routes.
Here on the campus.

327
00:20:34,050 --> 00:20:36,930
Driving Monster around here is actually 
two miles.

328
00:20:37,680 --> 00:20:38,513
And then right outside we have a very 
nice mix of highway local adults in the 

329
00:20:42,881 --> 00:20:47,881
residential adults.
The location is also quite

330
00:20:48,070 --> 00:20:49,630
nice.
Um,

331
00:20:49,720 --> 00:20:50,553
so I've got about 45 miles from New York
City and there's a train connection and 

332
00:20:54,431 --> 00:20:55,264
fairy.
So the train is about 60 to 70 minutes 

333
00:20:57,431 --> 00:21:00,580
and to failures faster actually can take
the shortcut.

334
00:21:00,581 --> 00:21:05,340
So it's around 40 minutes.
So

335
00:21:06,060 --> 00:21:09,570
what is a typical case where rule based 
system struggle?

336
00:21:09,630 --> 00:21:13,050
While this seems clear so they can 
detect these lane markings,

337
00:21:13,051 --> 00:21:13,884
localize the car within it and then half
a past planner and the controller and 

338
00:21:19,050 --> 00:21:22,040
thrive,
but just um,

339
00:21:22,170 --> 00:21:25,740
about a hundred meters further up on 
this road to situation looks like this.

340
00:21:25,920 --> 00:21:27,920
So it's much harder now.
So he can just,

341
00:21:27,940 --> 00:21:28,773
you have to double yellow line,
marker fainted and then the center one 

342
00:21:31,591 --> 00:21:34,800
is almost gone.
You can still solve it.

343
00:21:34,801 --> 00:21:36,990
Of course you can build a detector for 
this curb.

344
00:21:36,991 --> 00:21:37,824
But offense,
you may be able to reconstruct these 

345
00:21:39,311 --> 00:21:40,144
yellow lane marking.
Then you can measure the distance here 

346
00:21:42,211 --> 00:21:45,330
and decide that this is actually buy it 
at an online.

347
00:21:45,331 --> 00:21:47,490
This is probably two lines and I'm 
currently here,

348
00:21:47,610 --> 00:21:48,443
so I'm going to assume that there's 
actually a virtual lane here and I'm 

349
00:21:51,841 --> 00:21:54,510
going to drive down.
And then you have solved the problem for

350
00:21:54,511 --> 00:21:59,190
tastes for it is a scenario and then 
around the corner it's different again.

351
00:21:59,700 --> 00:22:03,180
So you have to start all over.
And then again and again.

352
00:22:04,020 --> 00:22:09,020
So it seems a big advantage if we can 
build a system that can derive to domain

353
00:22:09,211 --> 00:22:13,080
knowledge from data.
So by just observing humans,

354
00:22:13,260 --> 00:22:17,190
not by somebody telling it what it 
actually should look for in this scene.

355
00:22:18,960 --> 00:22:21,300
So what we,
this is one of the things that we built.

356
00:22:21,390 --> 00:22:23,880
Um,
if this is the line here,

357
00:22:24,540 --> 00:22:25,373
that's where the car currently is,
then we predict there would the human 

358
00:22:29,311 --> 00:22:30,144
drive.
So what is the short term trajectory 

359
00:22:31,711 --> 00:22:33,900
that the human will take given that 
image?

360
00:22:34,920 --> 00:22:38,670
And so collecting the data is relatively
simple.

361
00:22:38,671 --> 00:22:40,830
You just drive,
um,

362
00:22:40,920 --> 00:22:45,750
you can then derive this trajectory from
the IGA motion of the car.

363
00:22:46,110 --> 00:22:46,943
So that training labels,
you essentially collect them for free 

364
00:22:49,321 --> 00:22:53,400
without additional manual labor while 
you're collecting the data.

365
00:22:53,880 --> 00:22:54,713
And so then the,
the difference between what a human 

366
00:22:57,451 --> 00:22:58,284
drove and what the network predicts,
that's the Arrow signal that we back 

367
00:23:01,050 --> 00:23:04,500
propagate.
Uh,

368
00:23:04,501 --> 00:23:08,340
this is an example network architecture.
Um,

369
00:23:08,730 --> 00:23:12,390
this is from about two years ago.
It still looks similar but it's growing.

370
00:23:12,391 --> 00:23:13,224
So we constantly adapting to the,
to the current size of the training 

371
00:23:16,381 --> 00:23:17,214
side.

372
00:23:19,060 --> 00:23:20,560
Oh yeah.
See how good I feel.

373
00:23:20,580 --> 00:23:25,210
Universal sign.
These are all old.

374
00:23:31,940 --> 00:23:32,773
And with this approach,
it really doesn't matter why they're 

375
00:23:35,530 --> 00:23:36,363
doing hot rolled looks horrible,
grass overgrown or is a nice high 

376
00:23:38,581 --> 00:23:39,414
highway.
As long as the update that we can learn 

377
00:23:40,911 --> 00:23:45,911
from it currently not used anymore than 
our campus.

378
00:23:52,941 --> 00:23:57,580
So that's just the ideal.
What experimenting.

379
00:24:01,910 --> 00:24:02,743
Oh,
cool.

380
00:24:05,270 --> 00:24:09,050
So the noises in the background but not 
acting.

381
00:24:09,051 --> 00:24:09,884
This is actually real.
We struggle so much to get this to work 

382
00:24:13,020 --> 00:24:13,853
for.
An important deadline was just about 12 

383
00:24:16,281 --> 00:24:20,030
hours before the drop dead deadline that
those things started working.

384
00:24:20,900 --> 00:24:24,470
That was a big relief.
So this is um,

385
00:24:24,520 --> 00:24:27,540
uh,
a made up construction side but on paved

386
00:24:27,560 --> 00:24:28,920
section in the,
in about,

387
00:24:29,430 --> 00:24:31,560
uh,
people often ask 12,

388
00:24:31,670 --> 00:24:34,790
if you train this in California,
can he drive in New Jersey?

389
00:24:34,970 --> 00:24:37,010
So we,
we showed it here,

390
00:24:37,011 --> 00:24:37,844
we trained with California data only on 
a new Chelsea highway and he had at 

391
00:24:45,711 --> 00:24:50,450
night please linked slightly on an 
unpaved road in a nearby park.

392
00:24:57,960 --> 00:24:58,793
Got It.

393
00:25:01,690 --> 00:25:04,510
So we'll move on to something a little 
more practical.

394
00:25:04,820 --> 00:25:07,080
This is highway driving.
Um,

395
00:25:07,780 --> 00:25:11,080
so he had been driving,
you'll see here,

396
00:25:11,110 --> 00:25:13,860
you see this is what the network 
protects,

397
00:25:13,870 --> 00:25:14,703
what the human would drive and you see 
that line markings here are lousy and 

398
00:25:17,511 --> 00:25:18,344
then in part they're completely missing.
And that doesn't seem to impress the 

399
00:25:21,940 --> 00:25:23,530
netvault keep people,
they still protects,

400
00:25:23,900 --> 00:25:24,733
protects the correct trajectory.
What do you see here is we show the 

401
00:25:29,390 --> 00:25:30,223
trajectory is predicted from the most 
recent 10 frames and then correct them 

402
00:25:34,121 --> 00:25:34,954
for Iga motion of the car.
And then he showed them all on top of 

403
00:25:37,901 --> 00:25:39,970
each other.
This is a debugging tool.

404
00:25:40,020 --> 00:25:42,940
Um,
if the network is confident,

405
00:25:42,941 --> 00:25:43,774
it will be consistent with its 
predictions over a few frames and the 

406
00:25:47,681 --> 00:25:50,320
noodles are nice and tight.
And if it's not confidence,

407
00:25:50,321 --> 00:25:51,910
then they'll spread out all over the 
place.

408
00:25:51,911 --> 00:25:53,890
It will predict something different each
flame.

409
00:25:56,100 --> 00:25:59,610
So he had not to try taking,
take to the exit,

410
00:25:59,780 --> 00:26:01,260
uh,
or here again,

411
00:26:01,500 --> 00:26:03,610
this is all stuff that we haven't 
programmed.

412
00:26:03,630 --> 00:26:06,030
They just picked it up by observing 
humans.

413
00:26:13,120 --> 00:26:15,060
Um,
we're not limited to,

414
00:26:15,080 --> 00:26:18,160
to La on lane keeping.
We can also learn lane changes.

415
00:26:18,400 --> 00:26:19,233
So this is a video showing that the,
the lane changes or triggered manually 

416
00:26:24,131 --> 00:26:27,130
by a,
this is change and here driving and he's

417
00:26:28,190 --> 00:26:29,023
uh,
he's just taping the Labor for the turn 

418
00:26:30,701 --> 00:26:33,500
signal and that's,
that indicates to the corner they should

419
00:26:33,540 --> 00:26:34,780
now change lanes.

420
00:26:37,040 --> 00:26:39,380
We can also learn different,
uh,

421
00:26:39,440 --> 00:26:40,273
length of the lane changes.
So we can tell the car to do complete 

422
00:26:42,151 --> 00:26:46,770
the lane change and two meters or 100 
meters or 50 meters.

423
00:26:47,790 --> 00:26:49,670
That's actually quite exciting.
Uh,

424
00:26:49,671 --> 00:26:52,530
I tie waist speeds,
completing lane change and 50 meters.

425
00:26:55,400 --> 00:26:56,233
We can also allow him to take,
this was particularly exciting because 

426
00:27:01,581 --> 00:27:05,390
I'm not sure that's really any other 
ways you should do this.

427
00:27:12,980 --> 00:27:13,813
Well,
I know if I wasn't he cuddled goals is 

428
00:27:14,691 --> 00:27:18,500
to be able to send the car okay.
By fame,

429
00:27:20,930 --> 00:27:25,930
I would go back to the office.
Okay.

430
00:28:49,440 --> 00:28:52,470
So one of the things I mentioned before 
that,

431
00:28:52,520 --> 00:28:54,120
uh,
it's important that,

432
00:28:54,400 --> 00:28:58,440
or an important aspect of our work is to
learn by observing humans,

433
00:28:58,441 --> 00:29:01,710
not by manually programming things into 
the system,

434
00:29:01,711 --> 00:29:04,020
but nevertheless,
they want to understand what it actually

435
00:29:04,021 --> 00:29:06,180
learned.
So he'll be analyzed what,

436
00:29:06,270 --> 00:29:09,530
what is looking at this DC,
the green regions,

437
00:29:09,540 --> 00:29:10,373
these are the regions that the network 
is sensitive to and you see that it 

438
00:29:15,010 --> 00:29:19,050
learns to recognize that [inaudible] 
Lane markings,

439
00:29:20,070 --> 00:29:20,903
which is interesting because we never 
labeled a single lane marking during 

440
00:29:23,101 --> 00:29:25,860
training or here in a residential 
street.

441
00:29:25,861 --> 00:29:26,694
He learns to look at the cars.
But if you look closely and you can the 

442
00:29:29,401 --> 00:29:33,930
trees here or on our campus,
if there's no clear lane markings,

443
00:29:33,931 --> 00:29:36,160
it learns to figure it out to the 
Dextero.

444
00:29:36,170 --> 00:29:37,620
Dhs through other means.

445
00:29:38,920 --> 00:29:39,290
Okay.

446
00:29:39,290 --> 00:29:42,280
So this is an important,
a very important tool for us.

447
00:29:42,790 --> 00:29:46,050
Here's a short video,
you'll see a line match.

448
00:29:46,810 --> 00:29:49,810
So about the driving on the highway,
it's looking at both land markings,

449
00:29:49,840 --> 00:29:50,673
but this one will disappear in a moment.
And now instead of looking at the bowls 

450
00:29:55,121 --> 00:29:55,954
of a doubly wide lane is actually just 
following this one until the right one 

451
00:29:59,831 --> 00:30:02,560
comes close enough so it becomes a 
single lane again.

452
00:30:03,310 --> 00:30:07,240
And it picked that up by observing.
This is not us manually programming that

453
00:30:07,270 --> 00:30:10,160
into the system.
Um,

454
00:30:10,200 --> 00:30:11,033
at one point some day we needed a 
screenshot from the inside of the car 

455
00:30:14,740 --> 00:30:17,620
and there's a lot of construction going 
on on the campus currently.

456
00:30:17,621 --> 00:30:22,621
And bobcat comes out into our old way.
And if you look here,

457
00:30:23,020 --> 00:30:24,030
the network,
uh,

458
00:30:24,090 --> 00:30:24,923
prominently recognizes it even though 
we're quite soft and it's never seen 

459
00:30:28,001 --> 00:30:30,340
this type of vehicle in the training 
before.

460
00:30:31,960 --> 00:30:32,690
Yeah.

461
00:30:32,690 --> 00:30:34,020
So I wanted to close with,
uh,

462
00:30:34,160 --> 00:30:36,720
some open challenges.
My mind,

463
00:30:36,760 --> 00:30:39,110
these are,
while we have tons of open challenges,

464
00:30:39,111 --> 00:30:39,944
but these are two of the big ones.
One is to deal with ambiguous 

465
00:30:42,351 --> 00:30:43,184
situations.
So if you imagine any won't allow them 

466
00:30:45,621 --> 00:30:48,320
to merge onto a highway and you have a 
car right next to you,

467
00:30:48,800 --> 00:30:49,633
then you can either speed up and go in 
front or it can slow down and go behind 

468
00:30:53,740 --> 00:30:55,040
what he can do,
the average.

469
00:30:56,870 --> 00:30:58,790
So how would we,
how would we deal with that hobby?

470
00:30:58,791 --> 00:31:01,610
Can learn from that as more than one 
possible,

471
00:31:01,730 --> 00:31:05,150
a correct way of driving,
but you're only ever get one,

472
00:31:05,870 --> 00:31:06,501
one,
one,

473
00:31:06,501 --> 00:31:08,690
one of these possible options in each 
example.

474
00:31:09,200 --> 00:31:11,600
And then the other one is learned from 
imperfect behavior.

475
00:31:11,810 --> 00:31:16,810
So we have a ton and ton of data,
but currently we need to cut out all the

476
00:31:17,541 --> 00:31:18,740
imperfect driving.

477
00:31:18,740 --> 00:31:22,220
You don't want to teach the network to 
cutting corners and such.

478
00:31:22,530 --> 00:31:24,560
Okay.
And Andy Dazzler on multiple,

479
00:31:24,760 --> 00:31:26,870
what do you do?
So it may makes the humans,

480
00:31:27,770 --> 00:31:31,880
so if we can get around and figured out 
how he can learn on its own,

481
00:31:31,940 --> 00:31:35,090
what it actually should look at and 
Modis for dot outliers,

482
00:31:35,190 --> 00:31:37,760
we would have a ton more data that we 
can work with them.

483
00:31:39,110 --> 00:31:42,410
And so I will finish with this video 
here.

484
00:31:42,950 --> 00:31:45,410
Uh,
this was recorded recently in December.

485
00:31:45,650 --> 00:31:49,820
We got new data from a new sensor set of
a new car fleet.

486
00:31:49,880 --> 00:31:54,650
And so the first 10 hours came in all 
California data in the sun,

487
00:31:54,830 --> 00:31:56,630
very little night,
no rain.

488
00:31:57,950 --> 00:32:00,400
And so the first thing they usually do 
is we train and networks.

489
00:32:00,401 --> 00:32:03,260
We go out and test to see if it meets 
our expectations.

490
00:32:03,261 --> 00:32:05,090
This is kind of an end to end test to 
see,

491
00:32:05,091 --> 00:32:07,190
to make sure that nothing's wrong with 
this new data.

492
00:32:08,020 --> 00:32:10,010
Uh,
that day it happened to snow.

493
00:32:10,100 --> 00:32:14,120
So we were curious to see what happens 
and it actually is,

494
00:32:14,310 --> 00:32:15,400
uh,
performed.

495
00:32:15,401 --> 00:32:16,234
Surprisingly.
My also all this network has ever seen 

496
00:32:17,891 --> 00:32:18,724
is California data and is now driving in
the snow and no Chelsea or here at 

497
00:32:22,641 --> 00:32:23,480
night,
uh,

498
00:32:23,481 --> 00:32:28,481
on a potluck snow covered road was a 
lights from oncoming traffic.

499
00:32:32,420 --> 00:32:33,253
Okay.

500
00:32:34,450 --> 00:32:36,840
You can also see what it's looking at 
and it,

501
00:32:36,910 --> 00:32:40,420
it looks at what seems correct on the 
road here.

502
00:32:40,421 --> 00:32:41,254
It even looks at the tread of the tire 
tread markings in this now even though 

503
00:32:45,381 --> 00:32:47,370
it certainly hasn't seen that in,
uh,

504
00:32:47,590 --> 00:32:52,160
in the original training data.
And that brings me to the end.

505
00:32:52,550 --> 00:32:53,630
Thank you for your attention.

