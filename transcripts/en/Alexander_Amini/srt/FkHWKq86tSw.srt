1
00:00:03,110 --> 00:00:04,940
Thanks d dot.
So I'm,

2
00:00:05,480 --> 00:00:07,000
I'm punching and uh,
um,

3
00:00:07,050 --> 00:00:07,581
like the,
um,

4
00:00:07,581 --> 00:00:10,020
also adds a Google Cambridge office and 
uh,

5
00:00:10,100 --> 00:00:10,933
I'm one of the authors of tensorflow.
So we're going to change topic and talk 

6
00:00:13,101 --> 00:00:14,630
about tensorflow.
So,

7
00:00:14,631 --> 00:00:16,530
um,
I read your course material a little bit

8
00:00:16,550 --> 00:00:19,820
and I gathered as you all use tensorflow
in previous parts of the lecture.

9
00:00:19,821 --> 00:00:21,230
Is that right?
Great.

10
00:00:22,340 --> 00:00:23,173
Okay.
So my focus will be how to more 

11
00:00:25,941 --> 00:00:26,840
efficiently,
right,

12
00:00:26,870 --> 00:00:29,030
and debulk it,
machine learning models in tensorflow.

13
00:00:29,900 --> 00:00:33,560
So the question is whether you need to 
debug a machine learning model.

14
00:00:34,220 --> 00:00:35,053
I think the answer is yes,
of course machine learning models are 

15
00:00:36,831 --> 00:00:38,600
very different from traditional 
programs,

16
00:00:38,990 --> 00:00:43,990
but their software and their code and 
the software and they will have bugs and

17
00:00:44,110 --> 00:00:44,943
the,
you need to debug your models from time 

18
00:00:45,771 --> 00:00:48,350
to time.
So hopefully after this lecture you will

19
00:00:48,351 --> 00:00:51,650
know a little bit more about how to more
efficiently devalue our machine learning

20
00:00:51,920 --> 00:00:52,910
models in tensorflow.

21
00:00:54,230 --> 00:00:55,063
So before we dive into debugging,
I want to talk about how machine 

22
00:00:58,131 --> 00:00:58,964
learning models are represented in,
in the computer because that turns out 

23
00:01:02,961 --> 00:01:05,810
to be important for how you write and 
develop programs.

24
00:01:06,530 --> 00:01:10,100
So there are two ways in which a machine
learning model can be represented.

25
00:01:10,580 --> 00:01:12,560
So it's either a data structure or 
program.

26
00:01:13,340 --> 00:01:16,700
So if it's a data structure,
then when you write code to,

27
00:01:16,730 --> 00:01:19,210
for example,
define a layer of neural network,

28
00:01:19,760 --> 00:01:22,640
you're actually building our graph and 
those lines of code,

29
00:01:22,670 --> 00:01:25,070
when they're executed,
they don't actually do the competition,

30
00:01:25,071 --> 00:01:25,904
they're just building the graph and the 
graph needs to be fed into some kind of 

31
00:01:29,031 --> 00:01:32,600
machinery because I'm kind of execution 
engine to actually run the model.

32
00:01:33,140 --> 00:01:33,973
And the second way in which you can 
define a machine and the motto is to 

33
00:01:36,230 --> 00:01:38,300
write it as a program.
So that's more straightforward.

34
00:01:38,570 --> 00:01:39,403
So those kinds of lines of code will 
actually do the competition on either 

35
00:01:42,471 --> 00:01:45,710
the CPU or Gpu depending on whether you 
have a gpu or not.

36
00:01:46,680 --> 00:01:47,513
Um,
so the first paradigm is also called 

37
00:01:49,490 --> 00:01:51,650
symbolic execution or different 
execution.

38
00:01:52,100 --> 00:01:54,020
And the second one is also called I'm 
eager,

39
00:01:54,021 --> 00:01:54,854
execution or imperative execution.
So I'm now the question for you is 

40
00:01:58,311 --> 00:02:01,070
whether tensorflow is the first paradigm
or the Second Paradigm?

41
00:02:03,550 --> 00:02:04,820
So I heard someone said first,

42
00:02:06,960 --> 00:02:07,793
second,

43
00:02:08,870 --> 00:02:09,351
both.
Yeah.

44
00:02:09,351 --> 00:02:10,960
So I think it's a trick question,
right?

45
00:02:10,961 --> 00:02:11,794
So the answer is both.
So if you ask the question like half a 

46
00:02:14,900 --> 00:02:16,370
year ago,
then the answer will be only the first.

47
00:02:16,730 --> 00:02:20,090
But in the latest version of tensorflow,
we support both modes.

48
00:02:20,140 --> 00:02:20,973
Um,
and I'm going to give you some examples 

49
00:02:21,681 --> 00:02:26,270
in the following slides.
So by default tends to flow is the first

50
00:02:26,271 --> 00:02:27,930
node,
so that's the classical,

51
00:02:27,950 --> 00:02:31,610
um,
traditional tensorflow style.

52
00:02:31,940 --> 00:02:32,773
So,
um,

53
00:02:32,780 --> 00:02:36,590
just to give you a refresher of how to 
use tensorflow to define a simple model,

54
00:02:36,620 --> 00:02:40,820
you import the tensorflow stf and then 
you defined some constants or maybe some

55
00:02:40,821 --> 00:02:43,940
variables as inputs.
And then you write a line to say like,

56
00:02:43,941 --> 00:02:44,774
you want to multiply x and w and then 
you want to add the results of the 

57
00:02:48,111 --> 00:02:49,590
multiple patient to,
um,

58
00:02:49,640 --> 00:02:50,473
to another thing be right.
So you can think of this as a very 

59
00:02:52,341 --> 00:02:54,260
simple linear regression model,
if you will.

60
00:02:55,310 --> 00:02:56,143
Now,
the important thing here is when this 

61
00:02:57,231 --> 00:03:01,990
line is executed,
it's actually not doing the computation.

62
00:03:02,020 --> 00:03:04,600
So the multiplication will not happen at
this point.

63
00:03:04,630 --> 00:03:06,970
If we print the results of this line,
why?

64
00:03:07,290 --> 00:03:10,360
Then you will see it's not 40,
it's not 10 times four equals 40.

65
00:03:10,630 --> 00:03:11,650
Instead it's like,
um,

66
00:03:11,651 --> 00:03:12,484
it's like a abstract symbolic thing.
So it's called a tenser and it knows 

67
00:03:16,481 --> 00:03:17,314
what kind of operation it needs to do 
when it's actually executed in the 

68
00:03:19,151 --> 00:03:21,910
future.
So mall is that operation.

69
00:03:22,270 --> 00:03:23,103
It also needs an information about it 
also knows information about like what 

70
00:03:26,140 --> 00:03:29,230
dependencies are,
which are x and w in this case,

71
00:03:30,070 --> 00:03:32,260
but it's not shown in the printed 
message here.

72
00:03:32,290 --> 00:03:34,880
And likewise,
when you do Tfa ad,

73
00:03:34,930 --> 00:03:37,840
when that line of code is executed,
the addition will not happen.

74
00:03:37,841 --> 00:03:39,940
It's going to happen later.
So by later,

75
00:03:39,941 --> 00:03:41,630
I mean a case,
uh,

76
00:03:41,860 --> 00:03:45,490
the points at which you create a session
by calling tf that session.

77
00:03:45,850 --> 00:03:47,500
And when you have that session is 
created,

78
00:03:47,740 --> 00:03:50,040
it will basically automatically pull in 
the graph.

79
00:03:50,050 --> 00:03:54,640
You have not already built in the 
previous lines of code and then you tell

80
00:03:54,641 --> 00:03:55,474
the session like which tensor,
which abstract symbol in the graph you 

81
00:03:57,971 --> 00:04:00,940
want to execute,
and then it's going to basically analyze

82
00:04:00,941 --> 00:04:04,440
the structure of the graph,
sort out all the dependencies and topple

83
00:04:04,760 --> 00:04:08,230
logically execute other nodes in the 
graph to do the multiplication first and

84
00:04:08,231 --> 00:04:11,920
then do the audition next and it's going
to give you the final results,

85
00:04:11,921 --> 00:04:15,880
which is 42 so it can think of tfs 
session as a Ng.

86
00:04:16,120 --> 00:04:19,090
So it's going to run the model on CPU.
If you only have a CPU,

87
00:04:19,120 --> 00:04:20,830
it's going to run the model on Gpu if 
you have

88
00:04:21,430 --> 00:04:22,263
GPU.

89
00:04:25,000 --> 00:04:25,833
Now obviously I'm this paradigm of 
defining our model is not the most 

90
00:04:30,060 --> 00:04:33,010
straightforward because those lines of 
codes that looked like doing competition

91
00:04:33,011 --> 00:04:33,844
is not doing any actual competition.
And you need to learn a new api called 

92
00:04:37,650 --> 00:04:41,020
TF session.
So why does tensorflow do it this way?

93
00:04:42,630 --> 00:04:46,260
So obviously it's because there are some
advantages you can get.

94
00:04:46,560 --> 00:04:49,230
So the first advantage is because the 
model is a data structure,

95
00:04:49,500 --> 00:04:51,890
it's relatively easy to serialize this.
Um,

96
00:04:52,050 --> 00:04:52,883
and then these airlines,
there's somewhere else you can train a 

97
00:04:54,841 --> 00:04:55,674
model and then you can load your model 
onto some kind of other devices like 

98
00:04:58,711 --> 00:05:03,711
mobile devices or embedded devices like 
raspberry pie or a car or robots and you

99
00:05:04,741 --> 00:05:05,574
can also,
um,

100
00:05:05,580 --> 00:05:06,413
sterilize the motto and then load the 
model on like a faster hardware like 

101
00:05:09,720 --> 00:05:11,320
Google's tpu.
Um,

102
00:05:11,370 --> 00:05:12,203
so these things are hard,
hard to do if your model is a python 

103
00:05:14,341 --> 00:05:15,174
right,
if your model is a python program 

104
00:05:15,721 --> 00:05:18,210
because those devices may not have 
python and running them.

105
00:05:18,660 --> 00:05:21,280
And even if those devices have python 
running on,

106
00:05:21,340 --> 00:05:23,760
on them,
that's probably not what you want to use

107
00:05:23,970 --> 00:05:28,970
because python is slow sometimes.
So I have those links here in the slide.

108
00:05:29,700 --> 00:05:30,533
So I'm going to send those slides to the
course organizers and you can click on 

109
00:05:34,141 --> 00:05:34,974
those links if you're interested in any 
of those topics like deployments on 

110
00:05:37,160 --> 00:05:38,190
mobile devices and so on.

111
00:05:41,380 --> 00:05:45,210
So the next advantage is because your 
model is a data structure,

112
00:05:45,220 --> 00:05:48,070
you are not tied down to the language in
which the model is defined.

113
00:05:48,400 --> 00:05:50,350
So nowadays,
most machine learning models are written

114
00:05:50,351 --> 00:05:51,184
in python,
but maybe your application server or 

115
00:05:53,281 --> 00:05:54,114
maybe a web server is running Java or c 
plus plus and you don't want to rewrite 

116
00:05:57,180 --> 00:05:58,013
the whole stack in python just to be 
able to add some machine learning to 

117
00:06:01,471 --> 00:06:02,251
your stack,
right?

118
00:06:02,251 --> 00:06:03,030
So,
um,

119
00:06:03,030 --> 00:06:03,863
if a model is a data structure that you 
can save the model after training and 

120
00:06:06,211 --> 00:06:07,044
they can load it into Java or c plus 
plus or c sharp or any of the supported 

121
00:06:10,980 --> 00:06:11,813
languages and that you will be ready to 
serve the trained model from your web 

122
00:06:14,761 --> 00:06:15,900
server or application server.

123
00:06:17,910 --> 00:06:21,570
And the other nice thing about 
representing data as the model,

124
00:06:21,571 --> 00:06:22,404
as a data structure,
as you can distribute the model very 

125
00:06:24,841 --> 00:06:27,150
easily onto a number of machines called 
workers.

126
00:06:27,540 --> 00:06:30,180
And those workers will basically use the
same graph.

127
00:06:30,240 --> 00:06:34,110
They're going to do the exact same 
competition,

128
00:06:34,140 --> 00:06:36,540
but they are going to do it on different
slices of the training later.

129
00:06:36,541 --> 00:06:40,080
So this kind of training in a 
distributed way,

130
00:06:40,081 --> 00:06:43,370
it's very important for cases in which 
you need to treat them out.

131
00:06:43,430 --> 00:06:45,570
I'm a very large amounts of data 
quickly.

132
00:06:45,600 --> 00:06:48,570
I'm the kind of problem that's Google,
sometimes it has to deal with.

133
00:06:50,100 --> 00:06:50,933
So um,
of course you have to start to modify 

134
00:06:52,501 --> 00:06:56,400
your model graph so that the shared 
things like the weights variables in the

135
00:06:56,401 --> 00:07:00,180
model are shared on a server called 
primary receiver here,

136
00:07:00,810 --> 00:07:04,500
but that's basically distributed 
training intensive flow in a nutshell.

137
00:07:04,770 --> 00:07:05,760
So again,
if you're interested,

138
00:07:05,761 --> 00:07:06,594
you can look at the slide and can click 
that link to learn more about 

139
00:07:09,360 --> 00:07:12,340
distributor training.
Any questions so far?

140
00:07:15,700 --> 00:07:18,090
Okay.
Okay.

141
00:07:18,091 --> 00:07:18,811
So,
um,

142
00:07:18,811 --> 00:07:21,840
also because you're representing your 
model as a data structure,

143
00:07:22,320 --> 00:07:26,160
you're not limited by the speed on 
concurrency of the language in which the

144
00:07:26,161 --> 00:07:28,890
model is defined.
We know that on python is slow sometimes

145
00:07:29,220 --> 00:07:30,053
and even if you try to make python or 
parallel parallel as the by writing 

146
00:07:34,141 --> 00:07:36,510
multithreading,
you will run into the show called python

147
00:07:36,511 --> 00:07:39,480
global interpreter lock and that will 
slow you down,

148
00:07:39,510 --> 00:07:40,910
especially for the kind of,
um,

149
00:07:41,340 --> 00:07:43,410
competition.
Got a deep learning model needs to do.

150
00:07:43,940 --> 00:07:44,773
Um,
so the way in which we solve this 

151
00:07:45,481 --> 00:07:46,314
problem in symbolic execution is by 
sending the model as a data structure 

152
00:07:50,551 --> 00:07:53,620
from the layer of python c plus plus.
So there,

153
00:07:53,660 --> 00:07:54,493
um,
at the level of c plus plus you can use 

154
00:07:56,310 --> 00:07:57,143
true concurrency,
you can fully parallel buys things and 

155
00:07:59,161 --> 00:08:00,870
that can benefit the speed of the model.

156
00:08:03,200 --> 00:08:04,090
So obviously,
um,

157
00:08:04,130 --> 00:08:06,260
there are all those advantages,
but there are also,

158
00:08:06,280 --> 00:08:07,113
there was like,
um,

159
00:08:07,490 --> 00:08:09,730
shortcomings of symbolic execution,
for example.

160
00:08:09,740 --> 00:08:11,810
It's less intuitive,
it's harder to learn.

161
00:08:11,950 --> 00:08:12,521
Um,
so you,

162
00:08:12,521 --> 00:08:15,600
you need to spend some time getting used
to the idea of beauty.

163
00:08:16,080 --> 00:08:19,880
You're defining a model first and then 
run the model later with tf dot session.

164
00:08:20,230 --> 00:08:21,063
Um,
and it's harder to debug a way a model 

165
00:08:22,520 --> 00:08:24,620
goes around.
That's because everything,

166
00:08:24,860 --> 00:08:27,650
every actual competition happens inside 
the TF dot session.

167
00:08:27,651 --> 00:08:30,720
And that's a single line of Python code 
calling a c plus plus.

168
00:08:30,800 --> 00:08:34,300
So you can use the usual kinds of python
debugger to do bumped heads.

169
00:08:34,820 --> 00:08:37,370
But I'm going to show you that they were
actually very good tools in tensive flow

170
00:08:37,371 --> 00:08:39,320
that you can use to debug things that 
had been in.

171
00:08:39,650 --> 00:08:42,130
Do you have that session?
And uh,

172
00:08:42,131 --> 00:08:42,964
another shortcoming of a symbolic 
exclusion is that it's harder to write 

173
00:08:46,701 --> 00:08:47,660
control flow structures.

174
00:08:47,690 --> 00:08:48,523
So by that I mean I'm structure as like 
I'm looping over a number of things or 

175
00:08:52,221 --> 00:08:53,054
if else branches,
so that kind of thing that we encounter 

176
00:08:55,320 --> 00:08:56,153
in programming languages,
but some machine learning models also 

177
00:08:57,901 --> 00:08:58,740
need to do that,
right?

178
00:08:58,741 --> 00:08:59,574
So likely recurrent neural networks need
to loop over things and some kind of 

179
00:09:02,430 --> 00:09:06,630
fancy I'm a dynamic models need to do if
ellis branches and so on.

180
00:09:06,660 --> 00:09:09,840
I'm also going to show some slides to 
show those concrete examples.

181
00:09:10,860 --> 00:09:11,693
So it's very hard to sometimes very hard
to write that kind of control flow 

182
00:09:14,551 --> 00:09:18,660
structures in symbolic execution,
but it's much easier in eager execution.

183
00:09:20,220 --> 00:09:21,053
So I'm with Eager Execution Europe,
your program can be more authentic and 

184
00:09:24,511 --> 00:09:27,390
it's easier to learn and easier to read.
So here's an example.

185
00:09:27,420 --> 00:09:30,090
So on the left you're seeing the same 
code as before.

186
00:09:30,120 --> 00:09:33,600
So we are using the default symbolic 
execution of tensorflow.

187
00:09:34,040 --> 00:09:34,873
No.
Now how do we switch to the new eager 

188
00:09:36,790 --> 00:09:38,850
execution?
So it just add two lines of code.

189
00:09:39,330 --> 00:09:40,163
You import the eager module and then you
call a method called enabled eager 

190
00:09:42,960 --> 00:09:43,793
execution,
and you don't have to make any other 

191
00:09:45,001 --> 00:09:46,990
changes to your program in this case,
um,

192
00:09:47,100 --> 00:09:47,933
but you will because of these few lines,
you changed the semantics of these two 

193
00:09:51,271 --> 00:09:52,560
lines,
multiply and add.

194
00:09:52,890 --> 00:09:53,723
So now instead of building a graph,
this line is actually doing the 

195
00:09:56,131 --> 00:09:58,440
multiplication of ten four.
And if you print while,

196
00:09:58,441 --> 00:10:01,440
you will see the value and if you print 
the value of z,

197
00:10:01,441 --> 00:10:03,360
you will also see the value.
So everything is,

198
00:10:03,400 --> 00:10:05,640
I'm like a flutter and easier to 
understand.

199
00:10:08,430 --> 00:10:10,140
Now,
as I mentioned before,

200
00:10:10,310 --> 00:10:12,900
eager mode also makes it easier to 
control flow,

201
00:10:13,110 --> 00:10:18,110
dependency and the dynamic models.
So here's an example.

202
00:10:18,571 --> 00:10:21,030
So suppose you want to write a recurrent
neural network,

203
00:10:21,031 --> 00:10:23,280
which I think you have seen in previous 
parts of the lecture before,

204
00:10:23,670 --> 00:10:24,420
in,
um,

205
00:10:24,420 --> 00:10:27,780
in the default mode of tensorflow.
Here's about the amount of code you need

206
00:10:27,781 --> 00:10:29,070
to write.
So,

207
00:10:29,071 --> 00:10:29,904
um,
you cannot use the default native 

208
00:10:31,890 --> 00:10:35,770
foreloop or while loop in python.
You have to use the tensorflow's special

209
00:10:35,771 --> 00:10:38,100
wild loop.
And in order to use it,

210
00:10:38,101 --> 00:10:40,920
you have to define two functions,
one for the termination,

211
00:10:40,921 --> 00:10:43,950
conditioner of the loop and one for the 
body of the loop.

212
00:10:44,310 --> 00:10:45,143
And then you need to feed those two 
functions into the while loop and get 

213
00:10:48,160 --> 00:10:49,440
answers back.
And remember,

214
00:10:49,441 --> 00:10:50,274
those sensors are not actual values.
You have to send those 10 stairs into 

215
00:10:53,440 --> 00:10:54,900
session that runs,
get together actual value.

216
00:10:54,901 --> 00:10:55,734
So there are a few hoops to jump through
if you want to write a rn and from 

217
00:10:58,801 --> 00:11:00,720
scratch in the default mode of 
tensorflow,

218
00:11:01,260 --> 00:11:03,570
but with eager execution that things 
becomes much simpler.

219
00:11:04,290 --> 00:11:05,123
So you can use the native for loop in 
Python to loop over time steps and the 

220
00:11:08,731 --> 00:11:09,564
input and you don't have to worry about 
those symbolic tensors or sessions are 

221
00:11:12,901 --> 00:11:14,050
run the,
the,

222
00:11:14,080 --> 00:11:14,880
the,
um,

223
00:11:14,880 --> 00:11:18,600
the variables you get from this followup
is the result of the competition.

224
00:11:21,390 --> 00:11:25,800
So I'm eager mode makes it much easier 
to write the so called dynamic models.

225
00:11:25,830 --> 00:11:29,040
So what do we mean by static models in 
the dynamic models?

226
00:11:29,370 --> 00:11:30,203
So by static models we mean models who 
was structured don't change with the 

227
00:11:33,631 --> 00:11:34,464
input data.
And I think you have seen examples like 

228
00:11:36,701 --> 00:11:38,910
that in the image model sections of this
lecture.

229
00:11:38,911 --> 00:11:43,140
So the diagram here shows the inception 
model in tensorflow,

230
00:11:43,530 --> 00:11:44,363
so the model can be very complicated,
can have hundreds of layers and the can 

231
00:11:47,671 --> 00:11:48,504
do,
can do like a complicated competition 

232
00:11:49,771 --> 00:11:53,470
like convolution pooling and a dense 
manipulation and so on.

233
00:11:53,830 --> 00:11:54,663
But the structure of the model is always
the same no matter how the image 

234
00:11:57,311 --> 00:11:58,144
changes,
the image always has the same size and 

235
00:11:59,891 --> 00:12:01,830
the same cutter depth.
Um,

236
00:12:01,960 --> 00:12:03,970
but the model will always compute the 
same.

237
00:12:04,170 --> 00:12:05,003
I mean it will always do the same 
competition regardless how the image 

238
00:12:07,390 --> 00:12:08,200
changes.

239
00:12:08,200 --> 00:12:11,990
So that's what we mean by static model.
But there are also models was structured

240
00:12:11,991 --> 00:12:15,160
change with inputs and data.
So the recurrence,

241
00:12:15,161 --> 00:12:15,994
do you want network?
We have seen is actually an example of 

242
00:12:17,021 --> 00:12:17,854
that.
And the reason why it's changes is 

243
00:12:18,911 --> 00:12:19,744
because it needs to loop over things.
So in the simplest kind of recurrent 

244
00:12:22,790 --> 00:12:25,690
neural network,
it will loop over items in the sequence,

245
00:12:25,720 --> 00:12:26,553
like a words in a sentence.
So you can say that the length of the 

246
00:12:29,951 --> 00:12:32,380
model is proportional to the length of 
the input sentence,

247
00:12:32,800 --> 00:12:33,633
but there are also more complicated 
changes of the model structure with 

248
00:12:36,341 --> 00:12:37,174
input data.
So some of the state of the art models 

249
00:12:40,121 --> 00:12:40,954
that deal with natural language,
we actually take a parse tree of a 

250
00:12:43,750 --> 00:12:48,520
sentence as the inputs and the structure
of the model will reflect that tree.

251
00:12:49,720 --> 00:12:50,553
So,
um,

252
00:12:50,620 --> 00:12:52,800
as we have seen before,
it's complicated to your rights are wild

253
00:12:52,801 --> 00:12:54,740
loops or control flow structures in,
um,

254
00:12:54,840 --> 00:12:58,000
in those defaults symbolic mode.
Now if you want one to ride that kind of

255
00:12:58,001 --> 00:12:58,834
model,
it gets even more complicated because 

256
00:13:00,791 --> 00:13:04,570
there you will need to nest on 
conditional branches and a wild loops,

257
00:13:05,020 --> 00:13:05,853
but it's much easier to revise in that 
moment because you can just use the 

258
00:13:08,921 --> 00:13:11,980
native for loops and while loops and if 
statements in python.

259
00:13:12,430 --> 00:13:17,320
So we actually have an example to show 
you how to ride that kind of models.

260
00:13:17,340 --> 00:13:20,350
Dads take parse trees as input and the 
process natural language.

261
00:13:20,680 --> 00:13:23,140
So please check that out if you want.
You have a question,

262
00:13:25,710 --> 00:13:26,543
right?

263
00:13:27,060 --> 00:13:27,893
The tree is static.

264
00:13:32,010 --> 00:13:33,050
Okay.

265
00:13:33,400 --> 00:13:34,233
Yeah.
The tree is static in this particular 

266
00:13:35,530 --> 00:13:37,360
input,
but you can have a longer sentence,

267
00:13:37,390 --> 00:13:38,040
right?
There's the,

268
00:13:38,040 --> 00:13:40,480
the,
the grammar of the sentence.

269
00:13:40,620 --> 00:13:44,050
The sentence can change from one 
sentence to another,

270
00:13:44,080 --> 00:13:44,913
right?
So that will make the model structure 

271
00:13:46,030 --> 00:13:46,863
change as well.
So basically you can hard code the 

272
00:13:49,241 --> 00:13:50,074
structure of the model.
You have to like look how to treat and 

273
00:13:52,061 --> 00:13:52,910
then like,
um,

274
00:13:53,210 --> 00:13:54,043
uh,
do some kind of like an if else 

275
00:13:55,051 --> 00:13:59,080
statements and while loops in order to 
like turn the theory into the model.

276
00:14:00,260 --> 00:14:01,093
Yep.

277
00:14:03,200 --> 00:14:03,921
Okay.
So,

278
00:14:03,921 --> 00:14:04,754
um,
we have seen that the eco mode is very 

279
00:14:05,601 --> 00:14:06,434
good for um,
learning and debugging and for writing 

280
00:14:09,050 --> 00:14:11,950
control flow structures.
But sometimes you may,

281
00:14:11,970 --> 00:14:15,560
you may still want to debug a tensorflow
programs running in the default symbolic

282
00:14:15,650 --> 00:14:17,330
modes.
And there are a few reasons for that.

283
00:14:17,360 --> 00:14:18,193
First,
you may be using some kind of old code 

284
00:14:20,210 --> 00:14:22,910
of tensorflow that hasn't been ported to
eager mode yet.

285
00:14:23,330 --> 00:14:25,160
And some high level API as you might be 
using,

286
00:14:25,161 --> 00:14:29,120
like tf learned or terrorists or tf slim
have not been important to.

287
00:14:29,810 --> 00:14:32,330
Yes.
And you may want to stick to the default

288
00:14:32,331 --> 00:14:34,370
symbolic moments.
It because you care about speed on,

289
00:14:34,420 --> 00:14:37,820
because eco mode is sometimes slower 
than the default mode.

290
00:14:38,240 --> 00:14:38,781
So,
um,

291
00:14:38,781 --> 00:14:39,614
the good news is that we have a tool 
intensive flow that can help you like 

292
00:14:42,110 --> 00:14:45,060
debug attentive flow model running in 
the tf,

293
00:14:45,061 --> 00:14:49,820
the TF dot session in the mode,
and that's what was called tf dbg,

294
00:14:49,850 --> 00:14:51,650
or tensorflow debugger.

295
00:14:52,640 --> 00:14:53,473
So the way in mentioned you use it is 
kind of similar to the way in which he 

296
00:14:55,921 --> 00:14:57,320
was eager,
execution,

297
00:14:57,670 --> 00:14:58,503
important and additional module.
And after you have created the session 

298
00:15:01,491 --> 00:15:02,151
object,
you,

299
00:15:02,151 --> 00:15:02,984
we'll wrap the session object where the 
rapper in this case is called local 

300
00:15:05,511 --> 00:15:08,030
command line interface direct GRANDPA.
So,

301
00:15:08,031 --> 00:15:09,890
um,
you don't need to make any other changes

302
00:15:09,891 --> 00:15:10,724
to your code because this rapid object 
has the same interface as the unwrapped 

303
00:15:14,270 --> 00:15:16,070
object.
But basically you can,

304
00:15:16,090 --> 00:15:16,923
um,
you can think of this as like an 

305
00:15:17,631 --> 00:15:21,500
oscilloscope on some kind of instrument 
on your tf dot session,

306
00:15:21,501 --> 00:15:24,260
which is otherwise opaque.
So now,

307
00:15:24,290 --> 00:15:28,700
once you have wrapped that session,
when sessions are run is called,

308
00:15:28,820 --> 00:15:30,710
you're going to drop into the command 
line interface.

309
00:15:30,740 --> 00:15:33,050
You're going to see basically a 
presentation of,

310
00:15:33,420 --> 00:15:36,350
um,
one intermediate tensors are executed in

311
00:15:36,351 --> 00:15:39,230
the sessions are run and the structure 
and the graph and so on.

312
00:15:39,231 --> 00:15:43,910
So I encourage you to encourage you to 
play with that after the lecture.

313
00:15:44,960 --> 00:15:45,793
So

314
00:15:47,540 --> 00:15:48,373
the TTF debugger is also very useful for
debugging or kind of bugs in your 

315
00:15:51,531 --> 00:15:53,480
machine learning models which will 
probably occur.

316
00:15:53,810 --> 00:15:55,730
Those are called numerical instability 
issues.

317
00:15:55,760 --> 00:15:56,593
So by that I mean sometimes value is in 
the network who will become Nan's or 

318
00:15:59,601 --> 00:16:01,100
infinities.
So Nan stands,

319
00:16:01,370 --> 00:16:02,203
stands for not a number.
Naza infinities are like bad float 

320
00:16:05,180 --> 00:16:07,430
values that will sometimes happen.
Now,

321
00:16:07,910 --> 00:16:09,770
if you don't have a specialized tool in 
tensorflow,

322
00:16:09,830 --> 00:16:14,440
it can be difficult to pinpoint the 
exact notes which generates the nuns and

323
00:16:14,460 --> 00:16:15,293
infinities,
but the debugger has a special commands 

324
00:16:17,330 --> 00:16:21,560
with which you can run the model until 
any nodes in the graph contains Nan's or

325
00:16:21,561 --> 00:16:24,260
infinities.
So in our experience,

326
00:16:24,530 --> 00:16:25,363
that happens quite often and the most 
common causes of Nancy and infinities 

327
00:16:28,940 --> 00:16:31,430
are underflow and overflow.
So for example,

328
00:16:31,431 --> 00:16:33,950
if there's an underflow,
then a number will become zero.

329
00:16:34,250 --> 00:16:36,460
And when you use that number in division
or log,

330
00:16:36,500 --> 00:16:37,333
you will get infinities and overflow can
be caused by learning rates being too 

331
00:16:40,131 --> 00:16:40,964
high or by some kind of bad training 
example that you haven't sanitized or a 

332
00:16:45,370 --> 00:16:46,890
pre processed.
But um,

333
00:16:46,960 --> 00:16:47,793
the debugger should help you find the 
root cause of that kind of issue is 

334
00:16:49,631 --> 00:16:50,464
more,
more quickly.

335
00:16:53,290 --> 00:16:56,110
So the TF debugger is a command line 
tool.

336
00:16:56,350 --> 00:16:57,880
It's nice,
it's a low footprint.

337
00:16:58,240 --> 00:17:01,690
You can use it if you have access to a 
computer only via a terminal,

338
00:17:01,960 --> 00:17:02,793
but obviously it's going to be even 
nicer if we can debulk the tensorflow 

339
00:17:05,921 --> 00:17:06,754
models in a graphical user interface.
So I'm excited to tell you about a 

340
00:17:11,260 --> 00:17:12,093
feature of tensorflow that's upcoming.
So it's called tensor board director 

341
00:17:14,591 --> 00:17:17,940
plugin or visual graphical debugger for 
tensorflow.

342
00:17:17,950 --> 00:17:19,980
So it's not included in the latest 
release of

343
00:17:21,620 --> 00:17:22,880
has low,
which is one point five,

344
00:17:22,881 --> 00:17:25,160
but it's coming in the next release one 
point six.

345
00:17:25,700 --> 00:17:27,950
It's available for preview in Natalie's.
So,

346
00:17:27,951 --> 00:17:28,784
um,
you can copy and paste the code from 

347
00:17:30,141 --> 00:17:30,974
here,
install those nightly builds of 

348
00:17:32,050 --> 00:17:35,300
tensorflow and the cancer board.
And you can use the feature.

349
00:17:35,690 --> 00:17:38,390
So after you have installed these 
packages,

350
00:17:38,391 --> 00:17:39,224
you can run a command.
So I'm all the code in my slides are 

351
00:17:41,571 --> 00:17:43,700
copy paste to execute that Calabasas.
Yeah.

352
00:17:43,701 --> 00:17:46,580
So these are about the main features of 
upcoming tool.

353
00:17:46,820 --> 00:17:47,670
So,
um,

354
00:17:47,870 --> 00:17:48,703
if you're interested,
please copy and paste these code and to 

355
00:17:50,200 --> 00:17:51,033
try it out.
This slide here is just a reminder of 

356
00:17:54,121 --> 00:17:55,450
the main features in here.
Um,

357
00:17:56,370 --> 00:17:56,971
okay.
So as,

358
00:17:56,971 --> 00:17:58,470
as um,
summary,

359
00:17:58,500 --> 00:17:59,333
we see that there are two ways to 
represent the machinery models in 

360
00:18:01,171 --> 00:18:02,020
tensorflow,
um,

361
00:18:02,280 --> 00:18:06,720
or in any deep learning framework either
as a data structure or as a program.

362
00:18:07,020 --> 00:18:07,853
If it's a data structure then you will 
get symbolic execution and symbolic 

363
00:18:10,831 --> 00:18:14,580
execution is good for deployments,
distribution and optimization.

364
00:18:15,270 --> 00:18:17,730
And if it's a program that you will get 
eager execution,

365
00:18:17,731 --> 00:18:19,500
it's good for prototyping,
debugging,

366
00:18:19,501 --> 00:18:24,210
and a writing control flow structures 
and it's also easier to learn.

367
00:18:24,930 --> 00:18:25,763
And the country in terms of law supports
both modes so you can pick and choose 

368
00:18:27,901 --> 00:18:29,760
the best mode for you depending on your 
need.

369
00:18:30,360 --> 00:18:31,021
And,
uh,

370
00:18:31,021 --> 00:18:34,080
um,
we also went over tens of load debugger,

371
00:18:34,110 --> 00:18:36,660
both the command line interface and the 
browser version,

372
00:18:36,960 --> 00:18:39,600
which will help you debug your model 
more efficiently.

373
00:18:40,500 --> 00:18:41,333
So with that,
I'm going to thank my colleagues on the 

374
00:18:43,831 --> 00:18:46,860
Google brain team both in the amount of 
new headquarters and here in Cambridge.

375
00:18:47,090 --> 00:18:49,560
Um,
she and Mahima are the two collaborators

376
00:18:49,561 --> 00:18:52,020
with me on the cancer board,
debugger plugging project.

377
00:18:52,560 --> 00:18:54,640
And a tensorflow is an open source 
project.

378
00:18:54,750 --> 00:18:55,583
There have been over 1000 contributors 
like you who have fixed bugs and 

379
00:18:58,831 --> 00:18:59,664
contributing new features.
So if you see any interesting things 

380
00:19:01,530 --> 00:19:03,810
that you can do,
feel free to contribute to tensorflow on

381
00:19:03,811 --> 00:19:05,790
get hub.
If you have questions,

382
00:19:06,120 --> 00:19:06,953
please email me.
And if you see any bugs or feature 

383
00:19:09,691 --> 00:19:14,610
requests about tensorflow or 10 boards,
you can fall on the bugs on these links.

384
00:19:15,810 --> 00:19:17,300
Thank you very much for your attention.
The question.

