Speaker 1:          00:02          I want to bring this part of the class to an end, so this is our last lecture, but for our series of guest lectures and in this talk I hope to address some of the state of deep learning today and kind of bring up some of the limitations of the algorithms that you've been seeing in this class so far. So we've got a really good taste of some of the limitations specifically in reinforcement learning algorithms that lex gave in the last lecture and that's really going to build on a. or I'm going to use that to build on top of during this lecture and just to end on. I'm gonna bring you. I'm going to introduce you to some new frontiers in deep learning that are really, really inspiring and that the cutting edge of research today. Before we do that, I'd like to just make some administrative announcements so tee shirts have arrived and will be distributing them today and we'd like to distribute first to the registered for credit students. After that, we will be happy to distribute to registered listeners and then after that, if there's any remaining goal, give out to listeners if they'd want, if they're interested.

Speaker 1:          01:10          So for those of you who are taking this class for credit, I need to reiterate what kind of options you have to actually fulfill your credit requirement. So the first option is a group project proposal presentation. So for this option, you'll be given the opportunity to pitch a novel deep learning idea to a panel of judges on Friday. You'll have exactly one minute to make your pitch as error, as clear and as concisely as possible. So this is really difficult to do in one minute and this kind of one of the challenges that we're, we're putting on you in addition to actually coming up with the deep learning idea itself. If you want to go down this route for your final project, then you'll need to submit your teams, which have to be of size three or four by the end of today. So at 9:00 PM today, we'd like those in, um, you'll have to do teams of three and four.

Speaker 1:          02:00          So if you want a group working in groups of one or two, then you'll have to, you're, you're welcome to do that, but you won't be able to actually submit or final project as part of a presentation on Friday. You can submit it to us and we'll, we'll give you the grade for the class like that. Um, so groups are do 9:00 PM today and you have to submit your slides by 9:00 PM tomorrow. Presentations or our class on Friday in this room. If you don't want to do a project or a presentation, you have a second option, which is to write a one page paper review of a deep learning idea. Uh, so any idea or any paper that you find interesting is, is welcome here. So we really accept anything and we're really free in this, in this, um, option as well. I want to highlight some of the exciting new talks that we have coming up after today.

Speaker 1:          02:51          So tomorrow we'll have two sets of guest lectures. First we'll hear from Ernest Mueller, who is the chief architect of and videos self driving car team. So erzen and his team were actually known for some really exciting work that Aldo is showing yesterday during her lecture and they're known for this development of an end to end platform for autonomous driving that takes directly image data and produces a steering control command at the car for the car at the output. Then we'll hear about, we'll hear from two google brain researchers on recent advancements on image classification at Google. And also we'll hear about some super recent advancements and additions to the tensorflow pipeline that we're actually just released a couple of days ago. So this is really, really new stuff. Uh, tomorrow afternoon we'll get together for one of the most exciting parts of this class. Um, so what will happen is we'll have each of the sponsors actually come up to the front of the class here.

Speaker 1:          03:48          We have four sponsors that will present on each of these four boards and you'll be given the opportunity to basically connect with each of them through the, uh, through the ways of a recruitment booth. And basically they're going to be looking at students that might be interested in deep learning internships or employment opportunities. So this is really an incredible opportunity for you guys to connect with these companies in a very, very, very direct manner. So we highly recommend that you take advantage of that. There'll be info sessions with pizza provided on Thursday with one of these guests lecture with one of these industry companies and we'll be sending out more details with that today as well.

Speaker 1:          04:29          So on Friday we'll continue with the guest lectures and hear from Lisa and meany who is the head of IBM research and Cambridge. She's actually also the, uh, director of the MIT IBM lab. And this is a lab that was just founded a couple or actually about a month ago or two months ago. We'll be hearing about how IBM is creating ai systems that are capable of not only deep learning, we're going to step past deep learning, they're capable of or trying to be capable of learning and recently on a higher order sense. And then finally we'll hear from a principal researcher at ten cent ai lab about combining computer vision and social networks. It's a very interesting topic that we haven't really touched upon in this class. I'm just topic of social networks and using massive big data collected from from humans themselves. And then as I mentioned before, in the afternoon, we'll go through and hear about the final project presentations.

Speaker 1:          05:28          We'll celebrate with some pizza and the awards that will be given out to the top projects during those during that session as well. So now let's start with the technical content for this class, I'd like to start by just kind of overviewing the type of architectures that we've talked about so far. For the most part, these architectures can be thought of almost pattern recognition architecture. So they take us input data and the whole point of their pipeline, their internals are performing feature extraction and and what they're really doing is taking all of the century data, trying to figure out what are the important pieces, what are the patterns to be learned within the data such that they can produce a decision at the output. We've seen this take many forms, so the decision could be a prediction, could be a detection or even an action like in reinforcement learning setting. We've even learned how these models can be viewed in a generative sense to go in the opposite direction. It actually generate new synthetic data, but in general we've been dealing with algorithms that are really optimized to do well and only a single task, but they really failed to think like humans do, especially when we consider a higher order level of intelligence like I defined on the first day.

Speaker 1:          06:48          To understand this in a lot more detail, we have to go back to this very famous theorem, those dating back almost 30 years from today, the steering, which is known as the universal approximation. Durham was one of the most impactful theorems in neural networks when it first came out because it had such a profound. It such a profound claim. What it states is that a neural network with a single hidden layer is sufficient to approximate any function to any arbitrary level of accuracy. Now, in this class, we deal with networks that are deep. They're not single. Layered, so they're actually more than a single layer, so actually they continue to add more complexity than the network down, referring to here, but this theorem proves that we actually only need one layer to accomplish or to approximate any function in the world, and if you believe that any problem can actually be reduced to a sets of inputs and outputs and it's a form of a function than this theory on shows you that a neural network with just a single layer is able to solve any problem in the world.

Speaker 1:          07:54          Now, this is an incredibly powerful result, but if you look closely, there are a few very important caveats. I'm not actually telling you how large that hidden layer has to be to accomplish this task. Now, with the size of your problem, the hidden layer and the number of units in that hidden layer, maybe exponentially large. I know grow exponentially with the difficulty of your problem. This makes training that network very difficult, so I never actually told you anything about how to obtain that network. I just told you that it existed and there is a possible network in the realm of all neural networks that can solve that problem, but as we know in practice, actually training neural networks because of their noncombat structure is extremely difficult.

Speaker 1:          08:40          So this term is really a perfect example of the possible effects of overhyping in Ai. So over the history of ai we've had to ai winters and this theorem was one of the resurgence after the first day I went there, but it also caused a huge false hype in the power of these neural networks which ultimately lead to yet another ai winter. And I feel like as a class it's very important to bring this up because right now we're very much in the state of a huge amount of overhyping and deep learning algorithms. So these algorithms are, especially in the media being portrayed that they can accomplish human level intelligence and human level reasoning and simply this is not true. So I think such overhype is extremely dangerous and resulted well. We know it resulted in both of the two past ai winters and I think as a class that's very important for us to focus on some of the limitations of these algorithms so that we don't overhype them, but we provide realistic guarantees, are realistic expectations rather on what these algorithms can accomplish and finally going past these limitations. The last part of this talk will actually focus on some of the exciting research, like I mentioned before, that tries to take a couple of these limitations and really focus on possible solutions and possible ways that we can move past them.

Speaker 1:          10:11          Okay, so let's start and I think one of the best examples of a potential danger of neural networks comes from this paper from Google deep mind, a named understanding deep neural networks requires rethinking generalization and generalizations was this topic that we discussed in the first lecture. So this is the notion of a gap or a difference between your training accuracy and your test accuracy. If you're able to achieve equal training and test accuracy, that means you have essentially no generalization gap. You're able to generalize perfectly to to your test data set, but if there's a huge disparity between these two datasets in your model is performing much better on your training data set than your test data. So this means that you're not able to actually generalize to brand new images. You're only just memorizing the training examples. And what this paper did was they performed the following experiment, so they took images from image net so he can see four examples of these images here.

Speaker 1:          11:13          And what they did was they rolled a case I did die where k is the number of all possible labels in that data set and this allowed them to randomly assigned brand new labels to each of these images. So what used to be a dog, they call it now a banana and what they were used to be, that banana is now called the dog and what it used to be called that second dog is now a tree. So note that the two dogs have actually been transformed into two separate things. So things that used to be in the same class are now in completely disjoined classes and things that were in destroying classes may be now in the same class. So basically we're completely randomizing our labels entirely. And what they did was they tried to see if a neural network could still learn random labels and here's what they found. So as you'd expect when they tested this neural network with random labels, as they increase the randomness on the x axis, so going from left to right, this is the original labels before randomizing anything, and then they started randomizing their test accuracy gradually decreased. And this is as expected because we're trying to learn something that has absolutely no pattern in it.

Speaker 1:          12:28          But then what's really interesting is that then they looked at the training accuracy and what they found was that the neural network was able to, with 100 percent accuracy, get the training said correct. Every single time, no matter how many random labels they introduced, the training set would always be shattered or another words. Every single example in the training side could be perfectly classified. So this means that modern deep neural networks actually have the capacity to brute force memorize massive data sets, even on the size of image net with completely random labels. They're able to memorize every single example in that data set. And this is a very powerful result is it drives home this point that neural networks are really, really excellent function approximators. So this also connects back to the universal approximation theorem that I talked about before, but they're really good approximators for just the single function like I said, which means that we can always create this maximum likelihood estimate of our data using a neural network such that if we were given a new data points like this purple one on the bottom, it's easy for us to compute is estimate probability estimate output just by intercepting it with that maximum likelihood estimate, but that's only if I'm looking at a place that we have sufficient training data already.

Speaker 1:          13:54          What if I extend this x axes and look at what the neural network predicts beyond that in these locations. These are actually the locations that we care about most, right? These are the edge cases and driving. These are the cases that we don't have mit, many or a lot of data that was collected and these are usually the cases were safety. Critical applications are like are most important, right? So we need to be able to make sure when we sampled in neural network from these locations, are we able to know that the neural network, are we able to get feedback from the neural network that it actually doesn't know what it's talking about.

Speaker 1:          14:34          So this notion leads nicely into the idea of what is known as advertar adversarial attacks where I can give you can give and neural network to images on the left like this one, and on the right and adversarial image that to a human look exactly the same, but to the network, they're incorrectly classified 100 percent of the time. So the image on the right shows an example of a temple which when I feed to a neural network and gives me back label of a temple, but when I apply some adversarial noise, it classifies this image incorrectly as an ostrich. So for this, I'd like to focus on this piece specifically, so to understand the limitations of neural networks, the first thing we have to do is actually understand how we can break them, and this perturbed noise is actually very

Speaker 1:          15:26          intelligently designed, so this is not just random noise, but we're actually modifying pixels in specific locations to maximally change or mess up or output prediction. So we want to modify the pixels in such a way that we're decreasing our accuracy as much as possible. And if you remember back to how we actually train our neural networks, this might sound very similar. So if you're a member training, a neural network is simply optimizing over our weights feta. So to do this, we simply compute the gradients of Feta with sorry, the great into our last function with respect to theater, and we simply perturb our weights in the direction that will minimize our loss.

Speaker 1:          16:07          Now also remember that when we do this, we're perturbing theater, but we're fixing or x in our y. This is our training label. Our training data and returning labels. Now, for adversarial examples were just shuffling the variables a little bit, so now we want to optimize over the image itself, not the wage, so we fixed the weights and the target label itself and we optimize over the image x. We want to make small changes to that image x such that we increased our loss as much as possible and we want to go in the opposite direction of training now, and these are just some of the limitations of neural networks and for the remainder of this class, I want to focus on some of the really, really exciting new frontiers of deep learning that focus on just two of these specifically. I want to focus on the notion of understanding uncertainty and deep neural networks and understanding when our model doesn't know what it was trained to know. Maybe because it wasn't. It didn't receive enough training data to support that hypothesis. And furthermore, I wanted to focus on this notion of learning how to learn models. Because optimization of neural networks is extremely difficult. It's extremely limited and its current nature because they're optimized just to do a single test. So what we really want to do is create neural networks that are capable of performing one task, but a set of sequences of tasks that are maybe dependent in some fashion. So let's start with this notion of uncertainty in deep neural networks. And to do that, I'd like to introduce this field called Bayesian deep learning.

Speaker 1:          17:46          Nope. To understand beige and deep learning. Let's understand why we even care about uncertainty. So this should be pretty obvious. Let's suppose we're given a network that was trained to distinguish between cats and dogs at input. We're given a lot of testing or training images of cats and dogs, and it's simply at the output we're producing an output probability of being a cat or a dog.

Speaker 1:          18:12          Now, this model is trained on either on only cats or dogs. So if I showed another cat, it should be very confident in its output, but let's suppose I give it a horse and I forced that network because it's the same network to produce an output being a probability of a cat or a probability of a dog. Now we know that these probabilities have to add up to one because that's actually the definition that we constrain our network to follow. So that means by definition one of these categories, so the network has to produce one of these categories, so the notion of probability and the notion of uncertainty are actually very different, but a lot of deep learning practitioners optin mixed these two ideas, so uncertainty is not probability. Neural networks or detect are trained to detect or produce probabilities at three output at their output, but they're not trained to produce uncertainty values. So if we put this horse into the same network, we'll get a set of uncertain of probability values that add up to one. But what we really want to see is we want to see a very low uncertainty in that very low certainty in that prediction.

Speaker 1:          19:22          And one possible way to accomplish this in deep learning is through the eyes of Bayesian deep learning. And to understand this, let's briefly start by formulating our problem again. So first let's go through like the variables, right? So we want to approximate this variable y or output y given some raw data x. and really what we mean by training is we want to find this functional mapping f parameterized by our weights data such that we minimize the loss between our predict examples and our true outputs. Why? So based on neural networks take a different approach to solve this problem, they aim to learn it postier over our weights, given the data. So they attempt to say, what is the probability that I see this model with these weights given the data in my training set. Now it's called Bayesian deep learning because we can simply have a rewrite this posterior using bayes rule.

Speaker 1:          20:25          However, in practice it's rarely possible to actually compute this compute, this bayes rule, updates, and it just turns out to be intractable. So instead we have to find out ways to actually approximate it through sampling. So one way that we'll talk about today is a very simple notion that we've actually already seen in the first. And it goes back to this idea of using dropout. So if you're a member, what dropout was dropped out is this notion of randomly killing off a certain percentage of neurons in each of the hidden layers. Now I'm going to tell you not how to use it as a regular advisor, but how to use dropbox as a way to produce reliable uncertainty measures for your neural network. So to do this, we have to think of capital t stochastic passes through our network where each stochastic pass performance one iteration of dropouts.

Speaker 1:          21:20          Each time you iterate, dropout, you're basically just applying a Bernoulli mask of ones and Zeros over each of your weights. So going from the left to the right, you can see our weights, which is like this matrix here. Different colors represent the intensity of that weight and we element wise multiply those weights by our Bernoulli mask with, which is just either a one or a zero in every location. The output is a new set of weights with certain of those dropped out with certain aspects of those dropped out. Now all we have to do is compute this t times capital t times. We'll get a feta t weights and we use those stated t different models to actually produce an empirical average of our output class given the data. So that's this guy. Well, we're actually really interested in why I brought this topic up was the notion of uncertainty though, and that's the variance of our predictions right there. So this is a very powerful idea. All it means is that we can attain reliable model uncertainty estimates simply by trading our network during run time with dropout. And then instead of estimating or classifying just a single pass through this network at test time, we'd classify capital t two iterations of this network and then use that to compute a variance over these outputs. And that variance gives us an estimation of our uncertainty.

Speaker 1:          22:53          Not to give you an example of how this looks in practice. Let's look at this, uh, this network that was trained to take as input images of the real world and outputs predicted depth maps. Oh, it looks like my text was a little off. That's okay. So at the output we have a predicted death, not for each pixel to network is predicting the depth in the real world of that Pixel. Now, when we run Bayesian model uncertainty using the exact same dropout method that I just described, we can see that the end, the model is most uncertain in some very interesting locations. So first of all, pay attention to that location right there. And if you look where, where is that location exactly? It's just the window sill of this car and in computer vision windows and specular objects are very difficult to to basically model because we can't actually tell their surface reliably, right?

Speaker 1:          23:57          So we're seeing the light from actually the sky. We're not actually seeing the surface of the window in that location, so it can be very difficult for us to model the depth in that place. Additionally, we see that the model is very uncertain on the edges of the cars because these are places where the depth is changing very rapidly, so the prediction may be least accurate and these locations. So having reliable uncertainty estimates can be an extremely powerful way to actually interpret deep learning models and also provide human practitioners, especially in the realm of safe ai, is the way to interpret the results and also trust our results with a certain amount or a certain gram of salt. So for the next and final part of this talk, I'd like to address this notion of learning to learn. So this is a really cool sounding topic. It aims to basically learn not just a single model that's optimized to perform a single task like we've learned basically in all of our lectures previous to this one, but it learns how to learn which model to use to train that task.

Speaker 1:          25:14          So first, let's understand why we might want to do something like that. I hope this is pretty obvious to by now, but humans are not built in a way where we're learning where we're executing just a single task at a time were executing many, many, many different tasks and all of these tasks are constantly interacting with each other in ways that learning one task can actually aid speed up or deter the learning. You have another task at any given time, modern deep neural network architectures and not like this. They're optimized for a single task and this goes back to the very beginning of this talk where we talked about the universal approximator and as these models become more and more complex, what ends up happening is that you have to have more and more expert knowledge to actually build and deploy these models in practice and that's exactly why all of you are here. You're here to basically get that experience such that you yourselves can build these deep learning models. So what we want is actually an automated machine learning framework where we can actually learn to learn and this basically means we want to build a model that learns which model to use given a problem definition.

Speaker 1:          26:28          One example I'd like to just use as an illustration of this idea, so there are many ways that auto ml can be accomplished and this is just one example of those ways. So I'd like to focus on this illustration here and I'd like to walk through it. It's just a way that we can learn to learn. So this, this system focuses on two parts. The first part is the controller rnn in red on the left, and this controller rnn is basically just sampling different architectures of neural networks. So if you remember in your first lab you created an rnn that could sample different music notes. This is no different except now we're not sampling music notes. We're sampling an entire neural network itself. So we're sampling parameters that define that neural network. So let's call that the architecture or the child network. So that's the network that will actually be used to solve our task in the end. So that network has passed on to the second bop. So that network has passed on to the second one. And in that piece we actually used that network that was generated by the rnn to train a model depending on how well that model did,

Speaker 1:          27:42          we can provide feedback to the rnn such that it can produce an even better model on the next time step.

Speaker 1:          27:49          So let's go into this piece by piece. Let's look at just the rnn part in more detail. So this is the rnn or the architecture generator. So like I said, this is very similar to the way that you are generating songs and your first lab, except now we're not generating songs, the timestamps are going from layers on the x axis and we're just generating parameters or hyper parameters rather for each of those layers. So this is a generator for a convolutional neural network because we're producing parameters like the filter height, the filter with the stride height, etc. So what we can do is we can at each time step produce a probability distribution of over each of these parameters and we can essentially just sample and architecture or sample of child network. Once we have that child network, which I'm Showing right here in blue, we can train it using our data set that we ultimately want to solve. So we put our training data in and we get our predicted labels out. This is the, this is the realm that we've been dealing with so far in this class, right? So we have our, this is basically what we've seen so far. So this is just a single network and we have our training data that we're using to train it.

Speaker 1:          29:02          We see how well this does, depending on the accuracy of this model, that accuracy is used to provide feedback back to the rnn and update how it produces or how it generates these models. So let's look at this one more time. To summarize, this is an extremely powerful idea. It's really, really, really exciting because it shows that an rnn can be actually combined in a reinforcement learning paradigm where the rnn itself is almost like the agent in reinforcement learning. It's learning to make changes to the child network architecture. Depending on how that child network performs on a training set, this means that we're able to create an ai system capable of generating brand new neural networks specialized to solve specific tasks rather than just creating a single neural network that we create just to solve that tasks that we want to create that we want to solve. Thus, this has significantly reduced. The difficulty in optimizing these neural networks for our architecture is for different tasks and it's also reduces the need for expert engineers to design these architectures, so this really gets at the heart of artificial intelligence. So when I began this course, we spoke about what it actually means to be intelligent and lucy. I defined this as the ability to take information, process that information, and use it to inform future decisions.

Speaker 1:          30:36          So the human learning pipeline is not restricted to solving just one task at a time. Like I mentioned before, how we learn one task can greatly impact speed up or even slowed down our learning of other tasks and the artificial models that we've created today. Simply do not capture this phenomenon. To reach artificial general intelligence. We need to actually build ai that can not only learn a single task, but also be able to improve its own learning and reasoning such that it can generalize to sets of related and dependent tasks. I'll leave this with you as a thought provoking points that encourage you to to all talk to each other on on some ways that we can reach this, this higher order level of intelligence that's not just pattern recognition, but rather a higher order form of reasoning and actually thinking about about the problems that we're trying to solve.

Speaker 2:          31:30          Thank you. Thank you.