Speaker 1:          00:00          Humans are really good at pattern recognition. We use it in nearly every aspect of our lives. Recognizing people, knowing a song by the first few bars and the list is endless and in some cases pattern recognition involves taking existing empirical evidence to find trends and project future think the weatherman. Now the problem for humans is we often get it wrong. We overemphasize some facts, make big judgments based on too small of data sets, but technology is changing. All of this just as technology changed your ability to make an informed decision on which type of barriers best black bear. It's also going to augment and improve our abilities to make statistically sound decisions based on the patterns of millions of other humans. Some of these augmentations have already happened and can be examined. This is how Netflix can create a list of what you want to watch next based on your viewing history and millions of the other people's history.

Speaker 1:          00:55          These augmentations also help Amazon know what you want to buy next and these are all good and pretty benign forms of statistical profiling, but there are some implications to this usage of big data. They get uncomfortable. And if you're prone to obsessing over moral dilemmas, you might want to skip this one. So let's dive into this. Here's a hypothetical. Let's say in the US, the number one priority is to stop the listening and proliferation of nickelback. And after years of nickelback fans slipping through the cracks, they notice something. It seems that 90% of all known offenders had green hair. Now us humans doing as we do, we say, hey, we only have so many policing resources. Let's focus it all on these nickelback loving green haired people. Now this might be more effective, but the question is, should justice break its commitment to impartiality to be more effective?

Speaker 1:          01:42          Because out of a million green haired people search, maybe only one has nickelback CD. So even though the likelihood of a nickelback fan having green hair is 90% the likelihood of someone green hair like nickelback is 0.01% so is it right to accuse someone of atrocious music tastes just based on the trait of green hair? Well, most people, including myself, would say no, of course not. Whether someone likes nickelback on only one trait creates an astronomical error margin. So it's easy to focus on individual rights and justice being blind and all that. But this is the problem. This error margin is going to get much smaller soon. The digital image of each individual is getting clearer and more nuance and we're starting to use ai to sift through big data to find patterns of human behavior too large for humans to see on their own. So what happens when the s in Iaa is 99.9% sure that you like nickelback based on a hundred factors including such things as your spotify history of listening to nineties rock bands, frequent attendance of post grunge festivals and that Mega douchebag haircut.

Speaker 1:          02:42          So what do we do then? Suddenly a lot of questions open up, but it is nonetheless profiling based on circumstantial evidence. Are we allowed to get a search warrant for his house based on this? To what extent are we willing to let law enforcement use modern data to catch criminals? This is a problem that the justice system is going to, to grapple with soon. And I'm not sure we're prepared to deal with the change in thinking that it might require, nor am I sure that there is a correct answer. So let's leave our nickelback scenario. Sorry, nickelback fans and back into the real world for a second. What happens when the justice system is 99.9% sure that this guy is going to shoot up a school? Next step, do we lock him up before he's committed the crime and how do we weigh the individual's right to innocence until proven guilty against the collective desire for safety?

Speaker 1:          03:24          And if you for one second think this isn't a modern problem for us, considered this, both the Orlando shooter and London terrorists were both profile to be known risks before they attack. As our risk assessments become more accurate is their moral culpability if we don't act on this information, this uncomfortable dilemma is starting to pop up more and more and it's not going to go away. No, I'm like most of my videos where I make some final opinion on the issue. I really don't know the answer to this question, but what I do know for sure it is technology has augmented our ability to recognize patterns and digitally profile people more effectively than ever. And this might change the justices

Speaker 2:          04:01          some forever. You know what they say? If you could do good things for other people, you had a moral obligation to do those things. That's what's at stake here, not choice. We sponsored that.

Speaker 1:          04:14          Thank you guys so much for watching that video. It was a blast to make and I want to hear it from you in the comments below what you think about it. Do you think technology will change the justice system and just let me know your takeaway from the video. So if you liked that video, you can subscribe or watch another video here and I make new videos every Wednesday, so I hope to see you then.