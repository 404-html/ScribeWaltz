Speaker 1:          00:02          Good morning everyone, as all of a sudden I'm the director of IBM Research Cambridge. It's literally just a few blocks down the road. I've worked probably 20 years in IBM research, primarily out of our New York lab, but I moved here, uh, just uh, three months ago to really start up this new ai lab, a refocus and significantly grow the Cambridge lab that we've, we've already started. I intentionally chose a somewhat provocative title to my, a talk today. Um, the reason I wanted to, the beyond deep learning, it's not necessarily to say that you know, all of these deep learning techniques are going to be obsolete. That's definitely not what I'm trying to say, but I am trying to say that, you know, although there's a lot of exciting things that we can do with deep learning today, there's also a frontier, a, you know, a space that we can't do very well. And so I hope to today talk to you about, you know, kind of what is an area of a boundary that we were not able to break through at this time that I think is critical for machine intelligence, for artificial general intelligence. So I'm hoping that today, uh, I can set that up for you, uh, hopefully, uh, you know, motivate a additional people to come in and study this because I really believe that it's a, it's a critical area where we're additional breakthroughs are needed.

Speaker 1:          01:35          I'd like to first introduce a IBM research. Uh, I don't know, uh, how many of you actually know about IBM research? Some of you may have heard of us because of the jeopardy challenge. So in 2011 we created a computer that was able to beat the chest, the jeopardy champions at that game. I'm very handily has, as a matter of fact, uh, uh, some people don't realize that our research division is, uh, is quite significant. So we have 3000 people worldwide, a 12 labs that are doing this research. Our researchers, uh, pursue the same types of accolades that, you know, the top university professors go after. So a Nobel laureates touring awards, National Academy of Sciences, National Academy of Technologies. So we pursue a very rigorous, uh, you know, set of, of research in the areas that we focus on all. And although I put the, uh, the jeopardy challenge up there, you're only as good as your, your most recent results.

Speaker 1:          02:40          Right. So I also wanted to make sure that I talked a little bit about things that we've done more recently. So, uh, in 2017, uh, as an example, uh, we created the first 50 cubit, a quantum computer. Uh, most people are kind of, uh, you know, I expect to actually see some people announcing some other companies announcing simulators for 50 on the order of 50 cubits. And the difference here is that we're talking about an actual 50 cubits, a quantum computer. Uh, so we, we also have the simulators, but we have the real quantum computers. I think what's also unique about what we're doing is that we're also making our quantum computing capabilities available through the cloud so that people can kind of log in and they can experiment and learn about what quantum computing is. So, so very exciting program for us. We also, in 2017, we were able to show a near linear scale out in terms of, you know, cafe deep learning models on, on our servers.

Speaker 1:          03:45          We were able to show algorithms that were able to exploit the quantum advantage. Uh, so the idea is that if you, in order to actually get the speed ups, uh, on quantum computers, you need to be able to map problems into a form where you can get that acceleration. And when you get that acceleration, then you're talking about exponential acceleration over traditional computers that people are using today. Uh, so this particular result was an algorithm that's able to basically map small molecules, models of small molecules, uh, uh, onto the actual quantum computing system so that we could demonstrate the ability to find the lowest energy state. So, and, and get that exponential speed up from that. Um, you know, the thing is that in 2017 we were named a number one, a leading corporation for a scientific scientific research at a corporate institute. So that's pretty exciting for us.

Speaker 1:          04:46          I also wanted to just tell you a little bit about the Mit Watson Mit, IBM Watson Ai Lab. It's obviously a very exciting announcement for us. So in September of 2017, we announced that we were building this, a $240 million dollar, a joint effort with mit to pursue fundamental advances in ai. Uh, the core areas are listed here. So when I say fundamental advances in Ai, it's really, again, recognizing what we can and can't do with ai today and then trying to create new algorithms to go beyond that. So examples of problems, I'm just very quickly that we're interested in, in terms of the, the new Ai Lab, uh, one area is that, uh, you know, learning causal structure from data is a very challenging problem. Uh, we're looking at how we can use data that was captured due to a crisper mediations are crispr gene in activations, which basically has very large set of interventional data where they're observing the whole genome.

Speaker 1:          05:58          Um, and we're going to try to learn a causal structure, uh, you know, from those, those intervention. So that's, that's one example. Another example in physics of Ai, uh, basically what we're talking about, there's the ability to have ai help quantum computing and quantum computers and quantum computers accelerate ai algorithms. So we're looking at problems, for example, the machine learning algorithms that will help us to manage the state of the quantum computer. Also, uh, looking at, uh, for example, the ability to, knowing what we know about quantum computers, knowing that, you know, we're going to be in the small numbers of, of hundreds of cubits for some time, that the memory bandwidth between a traditional computers and the quantum computers going to be relative small, which of the machine learning algorithms will we be able to map onto those systems in order to get that exponential speed up.

Speaker 1:          06:49          So those are just some of the examples of things that we're studying. Um, also we, we feel that right now there are two industries that are really ripe for ai disruption. One is healthcare life sciences. The reason they are ripe for disruption is because that community has invested a lot to create what we refer to a structured knowledge. So you know, gene ontology, you know, Snow Med, clinical terms, all of the structured knowledge that we can combine with observational data and create new algorithms and insecurity. The reason why cyber security, the reason why that one is ripe for disruption is because if everybody is advancing these ai algorithms and people start to try to use those ai algorithms to attack our systems, it's very important that we also use ai algorithms to try to figure out how they're going to do that and how to defend against that.

Speaker 1:          07:41          So there's some of the examples. The last one shared prosperity is about how do we get nondiscrimination on bias morals into the algorithms, not just training on, for scale out and accuracy and these sorts of things. All right? Uh, we, we already had our first announcement in terms of the new mit IBM Watson Ai Lab. So at nips we announced that we are releasing a 1 million video data set. Uh, the idea for those of you are familiar and you've probably learned a lot in this class about how people used image net to make new breakthroughs in terms of deep learning. Uh, just that volume of labeled data meant that people could go in and run experiments and train networks that they could never do before. Uh, so we've created, uh, this, uh, this million video data set, a three second videos were chosen for a specific reason. I'm the lead for this project.

Speaker 1:          08:38          Oh, deliver is a, has great expertise, not only in computer science but also in cognitive science. And so it's expected that, you know, three seconds is roughly the order of times that it takes humans to recognize a certain actions as well. So we're, we're kind of sticking with that time. Computers aren't the machine learning algorithms that you were learning about today aren't able to do this. Well, primary learned about so far was how to segment images. How to find objects within images, how to classify those, those objects, but not actions. And the reason why we also think that actions are important is because they are composable, right? So we want to be able to learn not just elemental actions from these videos, but then to start to think about how you recognize and detect compositions of actions and procedures that people are performing because then we can use that to start to teach the computers to also perform those procedures or to help humans to be able to perform those procedures better.

Speaker 1:          09:44          Okay. Now what I want to do is maybe take a break from kind of the setup and get into the more technical part of the, uh, of the talk today. So, um, as I was saying earlier, you know, what we've seen recently in deep learning is, is truly all inspiring. I mean, in terms of the number of breakthroughs over over the last 10 years and especially over the last five years, it is very exciting breakthroughs in terms of, you know, being able to, for certain tasks, uh, you know, beat human error rates in terms of visual recognition. And speech, a speech recognition and so on. Um, but my position is that there are still huge breakthroughs that are required to try to get to machine intelligence. So some examples of challenges that the systems of today aren't able to do. So one is that, um, many, many of the scenarios in order to get the performance that actually is usable requires labeled data.

Speaker 1:          10:43          It requires training data where you've actually labeled the objects and the images and so on. Um, while the systems are getting better in terms of doing unsupervised learning, uh, because of the vast amount of data that's available on the web. Uh, the problem is that we at IBM care about Ai for businesses, right? And if you think of ai for businesses, there's just not that much deep domain data that we're able to find, right? So if you think about the medical field, very deep expressive relations that are required to be understood. And of course a lot of labeled data. Uh, you know, uh, if you think of, you know, uh, an airline manufacturer and all of the manuals they may have and they'd like to try to be able to answer questions from those and be able to reason and help humans understand how to conduct procedures within those.

Speaker 1:          11:36          There's not enough data out there on those fields in terms of relationships and entities and so on for us to train. So it requires a lot of labeling. Humans actually going through and finding the important entities and relationships and so on. So an important area that we need to be able to break through is, first of all, why? Why, why do these machines, why do these networks require so much data labeled data? And can we, can we address that? Can we make the algorithms better? The second thing is that you've probably realized that you train up the algorithms and then they're able to perform some tasks. The tasks are getting more and more sophisticated, self driving cars and so on, but you're still not training this network so that it can form many different tasks. And even more importantly, what happens is that you learn a model, and even though you may, as part of the training, you may have reinforcement learning that's not lifelong learning, that's not just turning the cars out on the road and enabling them to continue to learn and aggregate information and bring that into a representation so that they can adapt to, you know, non stationary environments, environments that change over time.

Speaker 1:          12:44          Another thing is that, you know, when we train these networks, you kind of get it down to a certain error rate. But how do you keep improving the accuracy even though the error rate is not that bad? Now go to them stone, don't do well at this today. And then the last area is that it's really important that we're creating algorithms that are interacting with the humans, right? That can, uh, explain, uh, how they may have come to a particular decision or classification or whatever the case may be. So we need to try to think about how can we build machines that can learn, that can listen, interact with the humans, be able to explain their, their decisions to humans. And so a big part of this is what we were, what I refer to and what many in the community refer to as, you know, learning plus reasoning, meaning that we want to be able to reason on representations that are learned preferably on representations that are learned in an unsupervised manner.

Speaker 1:          13:46          All right? The first step in doing that is to be able to make language itself computational, right? So we are able to think about words as, as sort of symbols and what those words mean and the properties of them. And then reason about them. If you think about all the algorithms that you've been learning, they expect the information to be coming to them as, as numerical information, preferably as real valued information. How do you go from text to real valued information that can then be fed into these algorithms over time and then computed on. So one of the first areas here is, uh, his word embeddings. Uh, the reason I italicized words is because what you'll see is that we kind of started out with word embeddings, but now it's a, you know, phrase, embeddings document and vetting. So there's much more to this, um, but let's, let's start first with what do we mean with word embeddings?

Speaker 1:          14:42          Okay. The point is to try to represent ordered as a real valued vector, a that basically what that words means in terms of other words, right? So, so the, the dimensions of that factor of the features or basically other words. And the point is that you can assign different weights on how well that word relates to these other words. Okay? Now the difficult part there is how do you learn that representation that's going to give you that objective of making that vector really represent that word and be comparable to other words in a way that the machine can, can compute on them. So the idea is the first work earlier work in this was, all right, how do we do this? Such that those embeddings, those vectors give you an understanding of similarity between this word and other words within your dictionary first model here was what they referred to as a skip gram model.

Speaker 1:          15:49          Uh, basically what you try to do, as you say, given a particular word, how well can I predict the words around at the words that are one hop away from it to hop away from it, three hops away from it. What they're trying to do is to train a set of vectors where you minimize, uh, the, the, um, the loss, the prediction loss of being able to predict the words around it based off of that word. It was a very big difference for the community. Previously. It had been mostly counts. People just kind of count the number of occurrences and then they would use that to try to almost make that the wait. What this was doing was taking a deep neural network. Well, it was actually kind of a shallow neural network to try to optimize or maximize this law of probability of being able to predict the words around it from that and what they got from that is what you can kind of see here.

Speaker 1:          16:46          This ability to place words, symbols into a vector space such that words that are similar are closer together. Right? So, uh, the point is you can see and also that relationships between words, you know, move in similar directions, right? So what this figure is trying to show you is that, you know, you can look at the countries that are here on the, on the left side, and you can see that there are similar to the ones that are, all countries are proximal, the cities are proximal. Uh, the, you know, the vector that is going from countries to city are, uh, you know, uh, essentially going in the same direction. I'm sure. I'm not sure if you can actually see that, but the point is that this kind of a vector space gives us the ability to compute on those real valued vectors and then learn more about this.

Speaker 1:          17:40          So our very first simple thing is to be able to, you know, uh, be able to find other similar things, right? You have, you have something, you assemble Italy for example. Can you find other things that are similar to or related to Italy? You can find other countries, you can find cities within Italy. Um, so that's, that's Kinda the first step. Uh, the, you know, so the first, the first, uh, work, there was this kind of distributed representation that we're talking about here. Um, the second is basically showing the difference in terms of being able to second talk is a paper was about the accuracy, the significant jump and accuracy that we got from being able to do that prediction based representation as opposed to the account base representation. I put, I signaled, you know, ibm authors, people who are at or where it off ibm in orange.

Speaker 1:          18:34          And the last one is um, the uh, facebook has actually recently we released this fast tax where you can basically go in and very easily create your own embeddings. So first thing was, you know, how do, how do they create it and they went after a specific thing. How do you optimize that similarity? But what you'll see from the rest of the talk is that there are many other ways that you might want to try to figure out how to place things together. Other constraints that you might want to place on the vector space and how things are represented in that vector space. So that you can accomplish tasks from it prior to, uh, these types of representation, the ideals for how people would actually go after representing knowledge and language. We're knowledge basis, a structured knowledge. So our original ideas was, alright, listen, I have to be able to have a entities that are well defined.

Speaker 1:          19:29          I have to have well defined relationships between those entities. I have to have a rules that basically will give me information about, uh, you know, categories of relationships or categories of entities and it's great humans are able to do that. They're able to lay out an entire space, you know, describe, you know, molecules and relationships between molecules or jeans and relationships between genes and the targets that they might be able to affect. Humans can do that. Well, a machines don't do it that way. Um, that was the problem. So the second figure here was even though you, you know, you kind of go out and you're able to find a lot of things and wikipedia and Wikidata, you know, freebase or some of the examples where you can find structured information on the web. Even though you're able to find a lot of information out here, and although this is a 2013 statement, which you can see is that, uh, in terms of the types of relationships and completeness of that, this is saying, okay, well for the people that are in wikipedia or freebase actually we only were missing about 80 percent of their, uh, their education, where their education is from.

Speaker 1:          20:37          We're, we're missing, you know, over 90 percent of their employment history. Right. So, uh, even though it seems like it's a lot of information, a really sparse and very difficult for humans to be able to use the algorithms that we have today to automatically populate knowledge bases that look like the form that we understand and feel that we can apply our, our logic to. So one of the first results in terms of going from that symbolic knowledge into sub symbolic knowledge. So the vectors that I was talking about earlier was, could we redo our knowledge base is based off of these sub symbolic, these, these vectors. If we were able to do that, then we actually would be able to learn much more data. It's possible we could learn these, these representations and fill out some of the information that we're missing from our knowledge basis of this. First part was saying, okay, look, I can take some of the information I can find and freebase and other sources. What I'll do is I can use text information to try to build out these embeddings. I can find relationships are, I can find a entities that are in similar spaces and realize there may be a relationship between these and I can start to populate more of the relationships that I'm, that I'm missing from my knowledge base.

Speaker 1:          22:03          We're able to use this, this, this principle of the, uh, the embeddings and the knowledge basis to then start to grow the knowledge base that we have. Right? So, uh, this is basic. The first study here is showing how we took information about genes and diseases and drugs from ontologies that were available, uh, represented that learn vectors across that structured space so that we could predict relationships that weren't in the knowledge base. That's important because if you think about how people get that information today, they actually do wet lab experiments to try to understand if there is a relationship, if something upregulate something else because very expensive. If we can use this knowledge to make those predictions, then we can give other scientists places to look. Looks like there might be an interaction here. Maybe you could try that, right? Uh, the second set of results is a more recent, uh, basically, um, you know, it was a challenge issued by this mantic web community.

Speaker 1:          23:09          How can we better improve this automated knowledge based construction? So the team used a combination of these word embeddings, uh, to be able to search for and validate information gained from a set of structured and unstructured knowledge. So this is actually won a first place in the, uh, in the 2017 semantic web challenge. Okay. So now we're kind of getting an idea about how we would take a language, make it computational, put it into a knowledge base so that we can aggregate it over time. But how are we going to get the neural networks to use that? That's the next question.

Speaker 1:          23:51          Okay. An example task of why you would want those neural networks to be able to use that is question answering. You want to build up a knowledge base, everything you can possibly find a and then you want to be able to ask it questions and see if he can answer those questions. We say that this requires memories because the point is that if you think about some of the other tasks that you may have seen, you provide, once you train the network, you provide an input and then you get an output, right? You don't necessarily use longterm memories of, uh, relationships and entities and all of these sorts of things. Okay. Um, so this is a challenge. There was issue to the community essentially in terms of being able to read some sentences and then being able to give an a question, get an answer to that.

Speaker 1:          24:43          And there are different stages of the complexity of what is required in order to answer the question. Sometimes it's really just kind of finding the sentence. Sometimes it's being able to put multiple sentences together. Sometimes it's being able to a chain across time and so there are many stages of difficulties in order to do that. Um, but what I want to focus on is some of the early work in terms of creating a neural network that can then access those knowledge bases and then be able to produce an answer from that. Right? So the expectation is that you build up those knowledge basis from as much information you can find previously, uh, you train them such that they know how to answer a question, the types of questions that you'd like them to answer. Uh, and then from that, when you, you handed a question is able to produce an answer.

Speaker 1:          25:35          The reason this is different from what people are doing today, it's not just about saying today what happens is, you know, when you program a computer, then you tell it, okay, I want to be able to access this place in memory. You know, I do a query on a database and I say, okay, I'd like for you to give me all the rows where the first name is, is excellent. The last name is why they can come back and that's all programmed. These networks are instead learning how to access memory by looking at other patterns of access to memory, not program train it, train. So the point here is the neural net is the controller of how that memory is accessed in order to produce an answer. Okay. Um, so what happens is that they, it is a supervised a result. So they, they do train jointly with, okay, what are the inputs, what's the question that will be asked of that, what's the output that is desired from that?

Speaker 1:          26:33          And then, um, by providing many, many, many examples of that, then when you provided a new set of, of, of information, then it's able to answer a question from that by basically taking a vector representation of the question queue, uh, being able to map that onto the memory. So the embeddings that were produced from all the sentences that were entered and then moving back and forth across that until it gets to a confidence that, uh, uh, in, in an answer and transferring that into, into an output on the first version of this, uh, uh, the first version that's on the left side wasn't able to handle many things in terms of understanding, you know, kind of a temporal sequences, for example, they weren't able to do multi hop and second version, which is much more recent, is, you know, kind of full end to end training of that control of the, uh, of the network in order to try to start to answer these questions a while.

Speaker 1:          27:32          It's incredibly exciting. Uh, you know, there's still many of the questions that I was showing earlier that it really can't answer. So this is definitively not a solved problem, but you know, hopefully what you can see is that how we're starting to go up against problems that we don't know completely how to solve. But we're starting to solve them. And instead of just creating neural networks, just an algorithm, we are creating machines, right? Or creating machines that have controllers and they have memory, uh, and they're able to perform tasks that go well beyond just what you could do with the pure neural network algorithm. They, they, they leverage those neural network algorithms throughout. These are recurrent neural nets, lsts and so on. But the point is, we're starting to try to put together a machines from this, uh, if you, if you'd like to learn more about this topic, um, there's, there's quite a bit of work in this.

Speaker 1:          28:28          So one is, uh, in addition to being able to answer those questions, if we could better isolate. What's the question, right? This is something that humans have a problem with him. Somebody comes in, they ask you a question and you kind of say, what, wait, what, what's really the question? You're, you're asking me here. So we've done work in terms of being able to have better computers, better understand what's the question really being asked. Um, we need systems that will help us to train these models. So a part of this work is to create a simulator that can take texts that are ambiguous and generate questions of certain forms that we can then use that to try to both train as well as test some of these systems. Um, another really interesting thing is that a common sense knowledge is basically, you know, they refer to it as what's in the white space between what you read.

Speaker 1:          29:21          You read a text and a lot of times there's a lot of common sense knowledge, uh, you know, knowing that, you know, you know, the desk is made of wood and wood is hard and all of these sorts of things help you to understand a question. Can't find that it's not a wikipedia muster. That common sense information isn't not in wikipedia. It's not easy for us to learn from texts because people don't stated this. Third Work here is, hey, can we take some of that common sense knowledge? Can we learn in vector space ways to represent information that's common sense that, that white space, uh, and attach it to other information that, uh, that we're able to, to read from, from the web and so on. Um, you know, some of the recent work as well as can we, can we use neural nets to basically learn what a program is doing, represent that, and then be able to execute that program, um, programs, you know, this right now, people want to try to program a program that takes a very sophisticated human skill to be able to probe, probe a program and understand it.

Speaker 1:          30:28          And in fact, humans don't do that very well. But if we could train machines to do that, then obviously that's a very powerful thing to do. Um, we're also a paper that was just published a couple of, a couple of months ago in December at nips. I thought it was extremely interesting. Uh, basically they're learning how to constrain a vector representations such that they can induce a new rules from those and that they can basically create proofs. Right? So when you, the reasonable proof is important is basically that's the beginnings of being able to explain an answer. Someone if you ask the question of the question from some of the other ones was, you know, it's the apples in the kitchen, um, why, because you have approved, if you have the steps that you went through in terms of the knowledge base, uh, able to explain that out.

Speaker 1:          31:21          Then suddenly people can interact with the, uh, the system and use the system not only to answer questions but to improve and lift what humans, the human knowledge as well. Learn, learn from the computers right now, the computers learn from us. And just finally, if you'd like to do more, um, you know, the research division is working on next generation algorithms. Uh, those come out through our watson products. We have a watson developer. Cloud makes it very easy. You know, you can do things like you handed an image and it will hand back information about what's in that image. You, you hand at text, it'll tell you information about the sentiment of that, you know, label information within it and so on. So we have what we believe are very easy to use, uh, you know, uh, algorithms that take many of these things that we're talking about earlier and make them very easy for anyone to use and incorporate in into their programs. So I think that's it for me. Any questions.