Speaker 1:          00:03          Hey, thanks very much for the invitation to speak to you. Um, yeah, so I'm going to be talking about deep generative models. Um, so when we talk about deep generative models, what we're really talking about here from my point of view is to essentially train neural nets, uh, from training examples in order to represent, uh, the distribution from which these came. So we can think about this as either explicitly doing density estimation where we have some samples here and we try to model those samples with some density estimation. Or we can think of it more like a this, which is what actually I'll be doing a lot more of this kind of thing, which is to essentially we're worried about sample generation here. So we have some training examples like this where we're sort of just natural images from the world and we're asked the asking a model to train, to learn to output images like this.

Speaker 1:          00:56          Now, uh, these are actually not true samples. These are actually just other images from the same trainings. I believe this is from image net. Uh, a few years ago or even a few months ago, this would have seemed obvious that this, you couldn't generate samples like this, but in fact nowadays, this is actually not so obvious that we couldn't generate these. So it's been a very exciting time in this area, in the amount of work we've done in the amount of progress we've made in the last few years has been pretty remarkable. And so I think part of what I want to do here is tell you a little bit about that progress. Give you some sense of where we were in say 2014 when this started really to accelerate and, and where we are now. So, yeah. So, so why generative models? Why do we care about gender to modeling? Well, there's a, there's a bunch of reasons.

Speaker 1:          01:44          Some of us are just really interested in making pretty pictures. And I confess that for the most part, that's what I'll be showing you today is just as an evaluation metric, uh, we'll, we'll just be looking at, at pictures, I'm just natural images and how well we're doing in natural images. But there's actually real tasks that we care about when we talk about gender to modeling. One of them is just, let's say you want to do some conditional generation, like for example, machine translation, right? So we're conditioning on some source sentence and we want to output some, uh, target sentence. Will the structure within that target sentence that the target language, let's say that the, the rules, the grammatical rules, you can model that structure using a generative model. So this is an instance of where we would do conditional generative modeling. Another example, uh, where, uh, this is something that we're actually looking a little bit towards is, is can we use generative models is outlier detection.

Speaker 1:          02:34          And actually recently these types of models have been integrated into rl algorithms to help them do exploration more effectively. This was duct work done, um, at deep mind, I believe. Uh, so here we're, we're, we're looking at, you know, a case where, you know, if you can think about kind of a, this is a toy toyish version of the autonomous vehicle, the task, and you want to be able to distinguish cars and wheelchairs and then you're going to have something like this and you don't want your classifier to just blindly say, oh, I think it's either a car or a wheelchair. You want your classifier to understand that this is an outlier, right? And you can use generative modeling to be able to do that by noticing that there aren't very many things like this example from the training set. So you can proceed with caution.

Speaker 1:          03:18          And this is kind of a big deal, right? Because we don't want, our classifiers are, our neural net classifiers are very, very capable of, of doing excellent performance classification. But, but any classifiers just trained to output one of the classes that it's been given. And so, uh, in cases where we actually are faced with something really new and that's not seen before or perhaps a illumination conditions that it's never been trained to, to cope with. We want models that are conservative in those cases. So we hope to be able to use generative models for that. Another case where we're looking at generative models being useful is in going from simulation to real, uh, examples of in robotics. So, so in robotics training these robots with neural nets is actually quite laborious. If you're really trying to do this on the real robot, it would take many, many trials and it's, it's not really practical in simulation.

Speaker 1:          04:09          This works much, much better. But the problem is, is that if you train a policy and simulation and transfer it to the real robot, well that's not going to work well. That hasn't worked very well because the environment is just too different. But what if we could use a generative model to make our simulations so realistic that that transfer is viable? So this is the one, another area that a number of groups are looking at this kind of x pushing gender modeling in this direction. So there's lots of really practical ways to use generate models beyond just looking at pretty pictures. Um, right. So, so I, I break down the kinds of generative models there are in the world and to two rough categories here. And maybe we can take issue with this. Oh, by the way, if you guys have questions, go ahead and ahead and ask me a while.

Speaker 1:          04:51          You have them. I think I, I like interaction as possible or you can just save them to the end. Either way is fine. Um, and sorry for my voice, I've got a cold. Uh, so yeah, we have auto regressive models and we have latent variable models. So auto regressive models are models where you basically define an ordering over your input, right? So for things like speech recognition or strather speech synthesis and the gender and modeling case, this is natural, right? It's just, there's a natural ordering to that data. It's just the temporal sequence for things like images. It's a little less obvious how you would define an ordering over pixels. But there are nonetheless models such as a pixel rnn and Pixel cnn that do just this. In fact, pixel CNN is a, is a really interesting model from this point of view. They basically define a convolutional neural net with a mask.

Speaker 1:          05:42          So if you remember our previous lecture we did, we saw these convolutional neural nets, but what they do is they stick a mask on it so that you've got sort of a causal direction. So you're only looking at previous pixels in the ordering that you've defined the, the, the, um, the, well, the ordering that defined by the, the auto regressive model. So, so you kind of maintain this, this ordering as you go through the confident and what that allows you to do is come up with a generative model that's supported by this continent, uh, that, you know, it's just a full generative model and it's a, it's a pretty interesting model in its own right. But because of I have rather limited time, I'm actually not going to go into that model in particular. Another thing I just want to point out here is that wave net is probably the state of the art model for speech synthesis right now.

Speaker 1:          06:29          And it forms the basis of a very interesting speech synthesis systems. It's another area where gender models have made remarkable contributions in the last few years, even the last few months. So now we're seeing models that you would be fairly hard pressed to distinguish between natural speech and and these kinds of models for the most part. So what I'm going to concentrate on is a latent variable models. So latent variable models are models that essentially posit that you have some latent variables that are hope that you hope will represent some latent factors of variation in the data, right? So these are, these are things that as you wiggle them, they're going to move the data in, in what you hope will be natural ways. Right? So you can imagine a latent variable for images corresponding to illumination conditions, right? Or if their faces a common, it's a common thing. We find is latent variable corresponded to a smart, right?

Speaker 1:          07:21          So if we move this latent variable, the image that we see that we generate, you know, a smile appears and disappears and these are the kind of latent variables that we want and we want to discover these. So this is really a challenging task in general. We want to take natural data, just unlabeled data and discover these latent factors that give rise to the variation. We see there's two kinds of models in this family that I'm going to be talking about. A adversarial auto encoders and generative adversarial nets are gans here. Uh, I work personally with both of these kinds of models. They serve different purposes for me. And, uh, yeah, well let's, let's dive in a, so first I'll talk about, uh, the variation all encoders. This actually was a model was developed simultaneously by two different groups. One at a deep mind is the bottom one here and then a king man dwelling at the University of Amsterdam.

Speaker 1:          08:16          So again, the idea behind the, uh, the, uh, the, the well latent variable models in general is kind of represented in this picture, right? So here's the space of our latent variables and we consist this kind of represented as being fairly simple. And we have our two coordinate zed one and zed too. And they're independent in this case and they're sort of fairly regular and they sort of form a chart for what is our complicated distribution here in, in, in x space, right? So this is, you can think of this as third of the data manifold. So you can think of this as image space for example, right? So image space embedded in pixel space, natural images, embedded pixel space form, this kind of manifold. And what we want is coordinates that allow you to, as you move sort of smoothly in this space, move along this what can be a very complicated manifold.

Speaker 1:          09:04          And so that's the kind of hope. What that, what, what we're looking for when we do latent variable modeling. So here's just an example of, of what I mean by exactly that. This is an early example using these various channel auto encoders. So here's a, the fray face data set, just a whole bunch of images of Brendan phrase face. Uh, that's in the Dataset. What we're showing here is the model, the, the model output, uh, of this variational auto encoder for different values of these latent variable zed one in zed to now we've kind of post hoc added these labels, pose and expression on them because you see if as we move the zed to here, you can see the expression kind of smoothly changes from what looks like a frown to eventually smile and through what looks over here like a stinging as well.

Speaker 1:          09:53          Sticking his tongue out, I guess. Uh, and in this direction there's a slight head turn. It's pretty subtle, but it's there. So, so we did, like I said, these were sort of post hoc, added the model just discovered that these were two sources of variation in the data, that we're relatively independent. And the model just pulled those out for something like amnesty. This is the, these are samples drawn on a model trained by ethnicity. It's a little less natural, right? Because in this case, you could, you could argue the data. It's really best model as something not with Leighton factors like continuously and factors, but more like in clusters. So you get this kind of somewhat interesting, somewhat bizarre relationship where you know, you've got some of this relationship with tilt happens here, but then the ones heard of morphs into a seven, which morphs into a nine. And you know, because these different regions in this continuous space that represent different examples here.

Speaker 1:          10:49          So a little bit more detail into how we do these kinds of a latent variable models, at least in the context of the variational auto encoder or va model. Um, so what we're trying to learn here is, is p of x some distribution over the data. We're trying to maximize the likelihood of the data. That's it. But the way we're going to parameterize our model is with a p of x given zed zed or is our latent variables, I'm sorry to Z, I guess for you guys. Uh, p of x given Z and then P of Z, right? Some, some prior distribution. Right? So this P of z here is, is typically something simple, right? It's some prior distribution. We actually generally want it to be independent. There's some modeling compromises to be made there. But the reason why you'd want it independent is because that helps get you the kind of orthogonal representation here.

Speaker 1:          11:37          So these guys, this dimension and this dimension, we want sort of not very much interaction in order to make them more interpretable. Um, yeah. And so, and the other thing we want to do is we want to think about how are we going to, so, so going from something simple, like you can think about this as like in a Gaussian distribution or a uniform distribution, but now we want a model g here that transforms zed from this space into this complicated space. And the way we're going to do that is with a neural net. Actually, in all of the examples that I'm going to show you today, the way we're going to do that is with a convolutional neural net. And the way to think about that, it's a bit of an interesting thing to think about going from some fully connected things that into some two dimensional input with a typology here in the natural image space x.

Speaker 1:          12:24          And so it's just the way going from a, what we talked about, it's kind of like the opposite path of where you would take to do a confidante classification. Um, there's a few different ways you could think about doing that. One of which is called a transposed convolution. This turns out to not to be such a good idea. Uh, this is a case where you essentially fill in a bunch of Zeros. Uh, it seems like the most acceptable way to do that right now is to just, once you get some small level typology here, you just, you do interpolation. So you just, you know, super sample from the image. Uh, you can do by linear interpolation and then do a conflict preserves that size. And then up sample again, comp up, sample comp, that tends to give you the best results. So, right? So when you see this kind of thing, this kind of thing for our purposes, think convolutional neural net.

Speaker 1:          13:13          All right? So it's important to point out that that if we had, uh, if we had over here, uh, ceds that go went, where's this [inaudible] that went with our ex, uh, we'd be done right? Because this is just a supervised learning problem at this point. And we'd be fine. The trick is these are latent, right? Need their hidden. We don't know these sets. We don't have, we haven't discovered them yet. So how do we learn with this model? Well, the way we're going to do it is we're going to use a trick that's actually been around for quite some time. Uh, it says, this isn't particularly new. We're going to use a variation lower bound on the data likelihood, right? So it turns out that we can actually express, uh, the, the data likelihood heard. Again, this is the thing we're trying to maximize. We can express a lower bound for it given by something like that.

Speaker 1:          13:57          So we posit that we have some cue distribution of zed that estimates is the posterior of zed for a given X. And we're trying to then um, I guess maximize this joint probability over x and zed minus the log cues that, so this is, this is this variation of lower bound. Um, one of the ways we can express this is you're trying to find the cute from [inaudible] point of view is if you were to find a cue that actually recovered the exact posterior distribution over zed given x, this would actually be a tight, lower bound, right? So then we would for sure be optimizing if we were at all now optimize this lower boundary would be for sure, optimizing likelihood in practice. That's what we're going to do anyway. We're going to have this lower bound, we're going to try to optimize it. We're trying to raise that up in hopes of raising up our likelihood.

Speaker 1:          14:48          Um, but the problem is this posterior, the actual posterior of, of say of this g model here, this neural net, right? This is just some forward model neural net. So computing the posterior of zed given acts and tractable. We have no good way of doing this. It's going to be some complicated thing and we have no sensible way of doing this, so we're going to approximate it with this queue in this way. So we're going to, now we can actually, and what's interesting about this formulation, and this is this is new to the variation. A lot of queries they've started or just reformulated this a little bit differently and what they've got is they come up with this, this different expression here, which actually can be thought of in two terms here. One is the reconstruction term here. If you look at what this is, this is just, you get some from some queue, you get a zed and you're just trying to reconstruct x from that said, so you start with x, you get a zed, and then you're trying to do a reconstruction of x.

Speaker 1:          15:39          From that said, this is where the name variational auto encoder comes from is because this really looks like an encoder on the side of queue here and a decoder here, and you're just trying to minimize that reconstruction error. But in addition to this, they add this regularization term, and this is interesting, right? So this is what they're doing here is they're basically saying, well, we want to regularize this posterior and there's actually new auto encoders don't have this, right? So I'm just trying to regularize this posterior to try to be a little bit closer to the prior here. And it's a common mistake when people learn about this to sort of think that, oh well the goal is for these things to actually match. That would be terrible, right? That means that you lose all information about x. You definitely don't want these things to match.

Speaker 1:          16:21          But it does act as a regular riser, sort of as a counterpoint to this reconstruction term. And so now we've talked a little bit about this, but what is this queue? Well, for the variation of wind coated, the queues going to be another neural net. And in this case we can think of it. This is just a straight confident for the case of natural images. So again, we've got our lower bound, their objective that we're trying to minimize and we're going to parameterize q as this neural net confident that goes from x to zed and we've got now are generative model here are decoder that goes from zed to x. Um, I'm going to add a few more details to make this thing actually Prac in practice. I've till now, this is not to uh, new, there's been instances of this kind of formalism of an encoder network and a decoder network, but what they do next is actually kind of interesting.

Speaker 1:          17:11          They notice that that if they parameterize this a certain way, if they say q is equal to it, actually you can use any continuous distribution here, but they pick a, a normal distribution here. So q of x is some normal distribution where the parameters mew in sigma from the defined this normal distribution are defined by this encoder network. Then they can actually encode it. Like this is called the reprioritization trick, where they take said our random variable here is equal to some function of the input. Mew Plus Sigma are scaling factor over some noise. And what this allows us to do now when they formulate it this way, is the one in training. This model, they can actually back prop through the decoder and into the encoder to train both models simultaneously. It looks a little bit like this. So they can do for propagation, start with an ex forward propagate to zed add noise here. That was that epsilon. And then for propagate here to this x Ha hat, which is our reconstruction, compute the air between x and x hat and back, propagate that error all the way through.

Speaker 1:          18:19          And that allows them to actually train this model very effectively in ways that we've never been able to train before this. This card trick came up and when you do that, this is the kind of thing that came out. So this came out in 2014. These are actually really, I promise these were really impressive results in, in 2014. Um, the first time we were seeing, so this is not a, this is from the FDA labeled facing the wild these days we use celebrate, um, and uh, this is imaging it. So, so not a whole lot there. Actually, this is a small version of image net. Um, but you can do things with this model actually. So for example, one of the things that we've done with this model is we actually just, we talked to, I mentioned briefly this pixel, CNN, we, we actually include this pixel cnn into the decoder side.

Speaker 1:          19:03          So one of the problems, if I just go back, one of the problems why we get these kinds of images is this model makes a lot of independence assumptions, right? And part of it is, is because we want those independents assumptions to make hers eds more interpretable, but they have consequences to them. And one of the consequences is you end up with kind of blurry images. That's, that's part of why you end up with biliary images because we're making these approximations in the variational, um, lower bound. And so by adding the pixel CNN that allows us to encode more complexity in here. And by the way, this is now a hierarchical version of the vie using pixel CNN that Lowe's, the law allows us to encode sort of complicated distributions in zed one here, uh, given the, the upper levels eds and with this kind of thing, uh, this is the kind of images that we can just synthesize using this variational.

Speaker 1:          19:50          Uh, we'll call this the, the pixel vie model. So a bedroom, these are bedrooms scenes, uh, so you can sort of see it's reasonably good clear bedroom scenes. And then image net, which you're, that, you know, you can see that it gets roughly the, the texture's, right? It's not really getting objects yet. Actually objects that are really tough to get when you model things in an unconditional way. What I mean by that is the model doesn't know that it's supposed to generate a dog, let's say if it was going to generate something. So it's just generating from p of x in general. And it's actually pretty challenging when we talk about image net. All right. So, so that's one way we can improve the uh, the va model. Another way we can improve the Vau models work on the encoder side. And that was done, uh, by uh, uh, a few people but culminating I think in the inverse auto regressive flow model.

Speaker 1:          20:40          So this is actually a very effective way to deal with it. The same kind of independence problems we saw that we're addressing on the decoder side, but they're addressing it on the encoder side. So you can kind of see just briefly what this is doing. So this is your prior distribution. Ideally you would like sort of the marginal posterior, which is sort of like combining all these things together to be as close to this as possible because any sort of disagreement between those two is really a modeling error. So it's an approximation error. So standard vie model is going to get going to learn to do something like this, which is, it's kind of as close as it can get to this while still maintaining independence in the distributions. Using this I f method, it's a bit of a complicated method that involves many, many iterations of transformations that you can actually, um, compute that are actually invertible that.

Speaker 1:          21:27          And you need this to be able to do the computation. But with that you can get this kind of thing, which is pretty much exactly what you'd want in this setting. So we've played around with this model and in fact, you know it, we find it works really well in practice actually. Um, yeah, so, but it's, again, it's on the encoder side. What we were doing with the Pixel va's on the is working on the decoder side. Um, but now, so this is actually fairly complicated. Both these models actually fairly complicated to use and a fairly involved. So one question is, is there another way to train this model but isn't quite so complicated? And, uh, so, uh, at the time a student of Yoshua Bengio and I, uh, Ian goodfellow was toying around with this idea and he came up with a generative adversarial nets.

Speaker 1:          22:11          And the way generative adversarial nets work is it posits the learning of a generative model g, um, in the form of a game. So it's a game between this generative model g here and a discriminator d. So the discriminators job is to try to tell the difference between true data and data generated from the generator, right? So it's trying to tell the difference between fake data that's generated by the generator and true data from the trending distribution. And it's just trained to do so. This guys trained to try to output one if, if it's true data and output zero. If it's fake data and the generator is being trained to fool the discriminator by using its own gradience against it essentially. So we back propagate the, the discriminate, the discriminator air all the way through through x. We usually have to use a continuous x for this and into the discriminator.

Speaker 1:          23:12          Now we're going to change the parameters of the, of the generator here in order to try to maximally fool the discriminator. So in us, sort of a more uh, um, uh, I guess abstract way to represent this looks like this. So we have the data on this side. We have the discriminator here with its own parameters. And this, again, for our purposes, those almost always a convolutional neural net. And then we have the generator, which is again one of these kind of flipped convolutional models cause it takes noises, input, it needs noise because it needs variability and then it converts that noise into something. An image space that's trained with these parameters are trained to fool the discriminator.

Speaker 1:          23:55          All right, so you know, we can be a little bit more formal about this. This is actually your objective function we're training on. So let's just break this down for a second. So from the discriminators point of view, what is this? This is just, it's called the cross entropy loss. It's literally just what you would apply if you're doing a classification with this discriminator. That's all this is from the generators point of view, the generator comes in just right here, right? It's the thing you draw these samples from and it's trying to minimize while the discriminators trying to maximize this quantity, this is essentially likelihood, uh, and, and, and the discriminant the generators moving in the opposite direction,

Speaker 2:          24:33          right?

Speaker 1:          24:35          So we can analyze this, this game to see, you know, this is a question, right? Does, well, you know, actually the way this happened was, um, at first he just tried it and it worked. It was kind of a overnight kind of thing and we got some very promising results. And then we set about trying to think about, well how do we actually explain what it's doing? Why does this work? And so, uh, we did a little bit of theory, which is useful to, to discuss. And I can tell you there's been a lot more theory on this topic that's been done that I will not be telling you about. But it's actually been a very interesting development in the last few years. But this, this is the theory that appeared in the original paper. So that the way we approached this was, let's imagine we have an optimal discriminator.

Speaker 1:          25:17          This turns out you can eat pretty easily. Show this is the optimal discriminator up here. Now you couldn't, this is not a practical thing, right? Because we don't know pr, which is probability of the real distribution. We don't, this is not available to us. This is only defined over training set. So only by training examples. So we actually don't, we can't instantiate this, but in theory, if we had this optimal discriminator, then the generator would be trained to minimize the Jensen Shannon divergence between the true distribution that gave rise to the training data and are generated distribution. So this is good, right? This is telling us that we're actually doing something sensible in this kind of nonparametric ideal setting that we don't, we're not really using but, but it's, um, but it's actually, it's interesting nonetheless. Um, so one thing I can say though, that in practice, we actually don't use exactly the objective function that I was just describing.

Speaker 1:          26:10          What we use instead is a modified objective function. And the reason is, is because if we were to minimize, Gee, what we had before was this term minimizing g, what happens is, is that as the discriminator to gets better and better, that the gradient on g actually saturate it goes to zero. So that's not very, uh, useful. If we want to train this small, and this is actually one of these, one of the practical issues that you see when you actually train these models is that you're constantly fighting this game between the, you're, you're sort of on this edge of, of the discriminator doing too well or, or the generator, uh, you know, it's a, it's, it's essentially, you're basically almost always fighting the discriminator because it's always going to, as soon as this discriminators starts to win this, this a competition between the gender and the discriminator, you end up with unstable training. And in this case, you end up with basically the, the generators stops training and the discriminator runs away with it. Well, that's actually in the original case. So what we'll do instead is we optimize this, which is a slight modification, but it's still monotonic and it actually corresponds to the same, the same fixed point. But, but what we're doing is we're just actually with respect to g, again coming in through the samples here or maximizing this quantity rather than minimizing this one.

Speaker 1:          27:24          Okay. So that's just a practical kind of heuristic thing, but it actually makes a big difference in practice.

Speaker 1:          27:30          All right. So when we did this, when we published first published this paper, this is the kind of results we would see and what you're looking at now is kind of movies formed by moving smoothly and zed space, right? So this is, you're kind of looking at transformations on the image manifold coming from smooth motions in zed space. So we were pretty impressed with these results again, and maybe they felt good at the time. Um, but there's been, you know, a few papers that have come out recently, well, not so recently. Actually at this point in 2016 there was a, this was came out in 2014 and 2016 there was a big jump in the quality. Um, and, and this was sort of one of those stages. This is the least squares Gan. This is just one example of many I could have pointed out. Um, but this is the kind of results we're seeing. So, so part of one of the, one of the secrets here is that it's one 28 by one 28. So bigger images actually give you a much better perception of quality in terms of the images. But so these are not necessarily, or generally not real bedrooms, these are, these are actually generated from the model, right? So trained on, you know, roughly I think 100,000 or at least a hundred thousand bedroom scenes asked to generate from these random zed bits. This is what it gives you.

Speaker 1:          28:46          So one thing you could think of, one thing that's certainly kind of occurred to me when I first saw these kinds of results is that well it's just over fit on some small set of examples and it's just learning these Delta functions, right? So, so that's not that interesting. In some sense it's kind of memorize some small set of data and it's enough that it looks good and it's impressive, but it doesn't seem like that's actually the case in one of the evidence. One of the parts of evidence it was pointed to, and this is in the DC Gann paper, um, was this, so that same trick that I showed you with the movies in damnest where where we were sort of moving smoothly and zed space, they applied basically that same idea here. So this is basically one long trajectory through zed space. And what you can see is starting up here on the ending up all the way down here, when you can see it's a smooth transition, right? And at every point it seems like, you know, a reasonable bedroom scene.

Speaker 2:          29:41          Okay.

Speaker 1:          29:42          So it really does seem like, like that picture that I showed you where we had the zed space, it was sort of smooth and then we had this x space, they've had this manifold on it. It really does feel like that's what's happening here, right, where we're moving smoothly and zed space and we're moving along the image manifold in x space. So for example, this, I guess, I don't know if this is a picture or tv, but it slowly morphs into a window I guess, and then kind of becomes clearly a window and then it turns into just into these edge sort of an edge of the room.

Speaker 1:          30:20          So one of the things actually if you want to nitpick about these, the models actually don't seem to understand three d geometry very well. It often gets the perspective just a little wrong sort of something might be interesting for future work. Um, so yeah. So one question, uh, you might be, it's a why, why do these things work well? And they keep in mind that, you know, when we talked about the v model, we actually had to do a quite a bit of work to get comparable results, right? We had to embed these, pick these, a pixel CNNS and the decoder, or we had to do some quite a bit of work to get the encoder to work right in these models. We literally just took a confident stuck in some noise at the beginning, pushed it through and we got these fantastic samples. It really is kind of that simple.

Speaker 1:          31:02          So what's going on? Like why is it working as well as its wills? It, it is. Um, and so I have a kind of an intuition for you. I kind of a cartoon view. Um, so imagine that this is the image manifold. So, so this is kind of a cartoon view of an image, a metaphor, but like this is in, in two pixel dimensions here. And, and we're imagining here that these are just parts of image manifold and they sort of, you know, share some features close by. But, but what this is basically representing is the fact that that most of this space isn't on the image manifold, right? Image manifold, some complicated nonlinearity and if you were to randomly sample in Pixel space, you would not land on this image manifold, which makes sense, right? Randomly sample in Pixel space, you're not getting a natural image out of it. This is sort of a cartoon view or my perspective on the difference between what you see with

Speaker 1:          31:53          maximum likelihood models of which the va is one and something like a Gan. So the maximum likelihood, the way it's trained is it has to give a certain amount of likelihood density for each real sample. If it doesn't, it's punished very severely for that. So it's willing to spread out it's probability mass over regions of the, of the input space or the or of the Pixel space, which actually doesn't correspond to a natural image. And so when we sample from this model, that's most of boy our samples come from, right? This is, these are these blurry images that we're looking at again, models things differently, right? Because it's the only playing this game between the encoder and, well, sorry, between the discriminator and the generator, all it has to do is sort of stick on, you know, some subset of the examples or maybe some subset of the manifolds that are present and not have enough diversity that the discriminator can't notice that it's modeling a subset.

Speaker 1:          32:50          So there's pressure on the model too to maintain a certain amount of diversity, but at the same time it doesn't actually face any pressure to model all aspects of the training distribution. It can just ignore certain aspects of the training examples or certain aspects of the training distribution without significant punishment from the, from the training algorithm. So anyway, that's, that's I think a good idea to have in your mind about the difference between how these methods work. Um, yeah. So, so just I'd like to sort of conclude with a few steps that have happened since the, uh, the gains. One of the things, this is something that we've done. We've actually, you know, you might ask, well gans are great, but in a way it's kind of unsatisfying because we start with [inaudible] and then we can generate images. So yes, we generate really nice looking images.

Speaker 1:          33:37          But, but we had this, you know, a hope when we started talking about these latent variable mount models that we could actually maybe infer the zed from an image, right? So we can actually extract some semantics out of the, of the image using these latent variables that you discover and in again, we don't have, then the question is can we actually within this generative adversarial framework, can we re incorporate inference mechanism? So that's exactly what we're doing here with this work. And this is actually a model we call alley, but they, the identical work essentially came out at the same time. Uh, I'll known as by again. And the basic idea here is just to incorporate in encoder into the model. So rather than just giving the data, distribute the data set, or here on, on the left or earlier, the Gan was defined, we had the decoder or generative model.

Speaker 1:          34:23          But over here, we only gave it x training examples. And here we only compare it against x, uh, generated from the, from the j the generator. But in this case, what we're doing is we take x and then we actually use an encoder here to, to generate a zed given x. And on the decoder we have again, our traditional Ganz style. We take us said sample from some simple distribution and we generate x. So again, this is the data distribution over here and code it to zed. And then we take our decode the sample from zed and we decode to x. And our discriminator now crucially is not just given x, but it's given x and zed. And it's asked, can you tell the difference in this joint distribution between the encoder side and the decoder side? That's the game. And what we find is, well first of all, it actually generates very good samples, which is interesting.

Speaker 1:          35:13          Uh, it's actually, it seems to generate sort of better samples and we see with comparable gans, which there might be some regularization effect. I'm not entirely sure why that would be, but actually it gets fairly compelling samples. This is just with a seller bay, a large data set of a celebrity images. Um, but this is the more interesting plot. So, so this is actually corresponds to a hierarchical version of this model. So this is why we have multiple sets. So this is ed one and said to, this is a two layer model inversion of this model. So if we just reconstruct from the higher levels Ed, which is this, you know, containing fairly little information because is this you? It's a single vector and then it has to synthesize into this a large image. What we're looking at here, a reconstruction. So we take this image, we encoded all the way to zed two and then we decode it.

Speaker 1:          36:01          And what we end up with is, is this, which is, you know, reasonably close but not that great. Right? And so as the same thing, you're going to kind of all, they sort of hold some piece of the information, which in some sense this is kind of, it's remarkable that does as well as it does because it's actually not trained to do reconstruction. Unlike something like the vie which actually explicitly trained to do reconstruction and this is just trained to match these two distributions. And this is kind of a probe to see how well it's doing. Cause we take x from one map a to zed and we take that set over and when we re synthesize the acts and we see we're seeing now an x space, how close did it come? And you know it does. Okay. But over here when we give it x one ends ed too.

Speaker 1:          36:42          So in this case we're really just giving it all of the latent variable information. We actually get much, much closer. Which is interesting because this is telling us that this pure joint modeling, in this case it'd be a joint modeling between x, Y, zed one ends, zed to that. This is enough to do fairly good reconstruction without ever actually explicitly building that in. So it's giving us an interesting probe into how close are we coming to learning this joint distribution and it seems like we're getting actually surprising the clothes. So it's like it's a testament to how effective I think this generative adversarial training exam algorithm actually is. So I want to just end with a few other things that have nothing to do with our work but I think are very, very interesting and well worth you guys learning about. So first one is cycle Gan cycle again is this really cool idea starting with, let's imagine you have two sets of datasets that somehow correspond but you don't know the correspondence you don't have, like there's an alignment that exists between these two data sets, but you might not know what, you might not have paired data.

Speaker 1:          37:43          This actually happens a lot. Say for example, this is not an image space, but a great example of this happens in machine translation, right? You almost always have lots of unilingual a data. So just text data in in a given language, but it's very expensive to get aligned data. But to data paired as a source and target distribution. If the question is what can you do if you just have unilingual data, how successful kicking you'd be at learning a mapping between the two. And they essentially use gans to do this. So this is the setup. They have some domain x here and her domain. Why here? And what they do is they start with an ex, they transform it through some convolutional neural net, usually a resonant based model into some y. And on this why they're going to evaluate it as a, as a, as a Gan style discriminator here.

Speaker 1:          38:31          So Ken acts a through g make a convincing why that's being, what's being measured here. So you can think of x is taking the place, which is some other image. Let's say this is some image to another image. This image x is taking the place of our, of our zed, of our random bits. It's getting it's randomness from x. And then we do the same thing. We can kind of transform it through f. So we've got x here, transform it through g, t to D and we evaluate on, on the our discriminator here on Gann style training. And then we re encode this annex. Now once we get here, that's over here. So we've taken ecs transformed it into why transform it back. They actually do what's called a cycle consistency loss, which is, this is actually a reconstruction. This is an l one reconstruction error and they back prop through f and g and then they, it's a symmetric relationship.

Speaker 1:          39:22          So they do the exact same thing on the other side. They start with why they see if they can transform it into acs, the compare the, they compare that that that generated x with true x is via a discriminator. And then again transform that to y and do the cycle consistency loss. So without any pair of data, this is the kind of thing that they can get. So a particular note is a horses and zebras, right? So, and this is a case where, you know, it's, it's impossible. Do they get this kind of pair data? Say you wanted a, a transformation that transformed horses to zebras and vice versa. You will never find pictures of horses and zebras in the exact same pose, right? That's just not a kind of Datas that you're ever going to be able to collect. And yet they do a fairly convincing job of doing this.

Speaker 1:          40:08          And you can see that they even turn like there's a little bit, this one actually doesn't do it very well, but oftentimes what you see as the turn like green grass a little bit more savannah like you took that kind of dulls it out because zebras are found generally in Savannah, let conditions, uh, they can do a winter to summer kind of transitions. I've seen examples data night, um, these are pretty interested in the various other things. Now I think there's, there's a lot of interesting things you can do with this dataset. And, and going back to, if you think about that simulation example with ro robotics that I gave the motivating example at the beginning. This is a prime application area for this kind of technology, but it will say that one of the things that they've done here is they assume a deterministic transformation between these two domains.

Speaker 1:          40:52          So I think there's a lot of interest looking at how do you actually break that kind of restriction and imagine something more like in many to many mapping between these two domains. So the last thing I want to show you is kind of the most recent stuff, which is just kind of mind blowing in terms of just the quality of generation that they, they show. So these are images from invidia actually. So I don't know if I'm, I'm uh, I'm sort of a undercutting, I don't know if he was going to show these or not, but uh, yeah, so these trained on, um, on the original, um, celebrate data set, the same one we had before, but now much, much larger images. Right? So 1,024 by 2024 and they're able get these kinds of uh, generated models. So I would argue that many of these, maybe all of the ones shown here essentially pass a kind of a, a turing test, right?

Speaker 1:          41:44          An image turing test. You cannot tell that these are not real people right now. I shouldn't say not all images actually, uh, look this good. Some of them are actually really spooky, but you can go online and look at the video and pick some out there. Yeah. Um, how they do this is with a really interesting technique and this is actually a so new, we, I have students that are starting to look at this, but we haven't really probed this very far. So I actually don't know, uh, how effective this is in general. But it's actually seems very interesting. So they just start with a tiny four by four image and once you train up that parameter, those parameters for both the discriminator here and the generator. So again, these are convolutions but we're starting with, with a relatively small input, we increased the size of the input, we add a layer and, and, and the, some of these parameters here actually formed by the parameters that gave you this image.

Speaker 1:          42:36          So you sort of just stick this up here and now you add some parameters and you'd now train the model to learn something bigger and you keep going and you keep going. And then you get something like this. As far as I'm concerned, this is this sort of, this amounts to kind of a curriculum of training does two things for you. One is it helps build a bit of global structure to the image because you're starting with such low dimensional, um, inputs. It, it helps reinforce the kind of global structure, but it also does something else, which is pretty important. It allows the model to sort of, um, not have to spend a lot of time training a very, very large model like this. Right? You sweet. I would imagine they spend relatively little time training here. Although this is Nvidia, so they might spend a lot of time training this, but um, but it allows you to spend a lot of the time sort of in much, much smaller models, so much more computationally efficient to train this model.

Speaker 1:          43:25          All right. So that's it for me. Thanks a lot. Oh wait. Oh yeah. Sorry. One more thing I forgot. Uh, this is just what they get. Unconditional image. A generation now with amnesty. So this is again, so you give it horse and then it's able to generate this kind of thing. So far it's able to generate this, right? So bicycles, it's able to generate these, which is pretty amazing. Um, quality. Uh, if you zoom in here, you can actually, it's kind of fun because the, it kind of gets the idea of, of, uh, these, these spokes, but not exactly like some of them just sort of end midway. Uh, but yeah, but still a pretty, pretty remarkable. All right. So, uh, thanks. If they have questions, I'll take them.