Speaker 1:          00:02          Good morning everyone, thank you for. Thank you all for joining us. This is mit success one nine one, and we'd like to welcome to welcome you to this course on introduction to deep learning. So in this course you'll learn how to build remarkable algorithms, intelligent algorithms, capable of solving very complex problems. They just a decade ago, we're not even a feasible to solve and let's just start with this notion of intelligence. So at a very high level, intelligence is the ability to process information so that it can be used to inform future predictions and decisions. Now when this intelligence is not engineered, but rather a biological inspiration such as in humans, uh, it's called human intelligence, but when it's engineered, we referred to it as artificial intelligence. So this course is a course on deep learning, which is just a subset of artificial intelligence. And really it's just a subset of machine learning which involves more traditional methods where we tried to learn a representations directly from data.

Speaker 1:          01:16          And we'll talk about this more in detail later today. But let me first just start by talking about some of the amazing successes that deep learning has had in the past. So in 2012, this competition called image net came out which tasks ai researchers to build an AI system capable of recognizing images, objects in images, and there is millions of examples in this data set and the winter in 2012 for the first time ever was a deep learning based system and when it came out, it absolutely shattered all other competitors and crushed the competition. I'm crushed, crushed the challenge, and today these deep learning based systems have actually surpassed human level accuracy on the image net challenge and can actually recognize images even better than humans can.

Speaker 1:          02:10          Now, in this class, you'll actually learn how to build complex vision systems, building a computer that knows how to see, and just tomorrow you'll learn how to build an algorithm that will take as input x ray images and as output, it will detect if that person has a pneumothorax. Just from that single input image. You'll even make the network explained to you why it decided to diagnose the way a diagnosed by looking inside the network and understanding exactly why it made that decision. Deep neural networks can also be used to model sequences where your data points are not just single images, but rather temporarily dependent. So for this you can think of things like predicting the stock price, translating sentences from English to or even generating new music. So actually today you'll learn how to create and actually you'll create yourselves and algorithm that learns that first listened to hours of music, learns the underlying representation of the notes that are being played in those songs and then alerts to build brand new songs that have never been heard before.

Speaker 1:          03:22          And there are really so many other incredible success stories of deep learning that I could talk for many hours about it and we'll try to cover as many of these as possible as part of this course. But I just wanted to give you an overview of some of the amazing ones that we'll be covering as part of the labs that you'll be implementing. And that's really a goal of what we want you to accomplish as part of this class. Firstly, we want to provide you with the foundation to do deep learning to understand what these algorithms are doing underneath the hood, how they work, and why they work. We will provide you with some of the practical skills to implement these algorithms and deploy them on your own machines and we'll talk to you about some of the state state of art and cutting edge research that's happening in a deep learning industries, deep learning academia institutions. Finally, the main purpose of this course is we want to build a community here at mit that is devoted to advancing the state of artificial intelligence. Advancing a state of deep learning. As part of this course will cover some of the limitations of these algorithms. There are many. We need to be mindful of these limitations. So I said we as a community can move forward and create more intelligent systems.

Speaker 1:          04:37          But before we do that, let's just start with some administrative details in this course. So this course is a one week course. Today is the first lecture we meet everyday this week, 10:30 AM to 1:30 PM, and this during this three hour time slot, we're broken down into a one and a half hour time slots, around 50 percent of the course. Each and each of those half a half sections of this course will consist of lectures, which is what you're in right now, and the second part is the labs where you will actually get practice implementing what you learn in lectures.

Speaker 1:          05:18          We have an amazing set of lectures lined up for you, so today we're going to be talking about some of the introduction to neural networks, which is really the backbone of deep learning. We're also talking about modeling sequence data, so this is what I was mentioning about the temporarily dependent data. Tomorrow we'll talk about computer vision and deep generative models. We have one of the inventors of generative adversarial networks coming to give that lecture for us, so that's going to be a great lecture and the day after that we'll touch on deep reinforcement learning and some of the open challenges in ai and how we can move forward past this course. We'll spend final two days of this course talking or hearing from some of the leading industry representatives doing deep learning in their respective companies and these are bound to be extremely interesting, extremely exciting, so I highly recommend attending of these as well.

Speaker 1:          06:16          For those of you who are taking this course for credit, you have two options to fulfill your greatest assignment. The first option is a project proposal. It's a one minute project pitch that will take place during Friday and for this you have to work in groups of three or four and what you'll be tasked to do is just come up with a interesting deep learning idea and tried to show some sort of results if possible. We understand that one week is extremely short to create any type of results or even come up with an interesting idea for that matter, but um, we're going to be giving out some amazing prizes, so including some Nvidia, Gpu and Google homes, uh, on Friday you'll, like I said, give a one minute pitch. There is somewhat of an arts to a pitching your idea and just one minute, even though it's extremely short, so we will be holding you to a strict deadline up that one minute. The second option is a little more boring, but you'll be able to write a one page paper about any deep learning paper that you find interesting. And really that's if you can't do the project proposal, you can do that.

Speaker 1:          07:29          This class has a lot of online resources you can find support on Piazza. Please post if you have any questions about the lectures to labs, installing any of the software, et Cetera. Also, try to keep up to date with the course website where we'll be posting all of the lectures, labs and video recordings online as well. We have an amazing team that you can reach out to at any time in case you have any problems with anything, feel free to reach out to any of us and we want to give a huge thanks to all of our sponsors who without this, without their support, this class would simply not happened the way, uh, the way it's happening this year.

Speaker 1:          08:11          So now let's start with the fun stuff and let's start by actually asking ourselves the question, why do we even care about deep learning? So why now and why do we, why do we even sit in this class today? So traditional machine learning algorithms typically defined sets of preprogrammed features and the data and they work to extract these features as part of their pipeline. Now, the key differentiating point of deep learning is that it recognizes that in many practical situations, these features can be extremely brittle. So at deep learning tries to do is learn these features directly from data as opposed to being hand engineered by the human.

Speaker 1:          08:58          That is, can we learn if we want to learn to detect faces, can we first learn automatically from data that to detect faces, we first need to detect edges and the image compose these edges together to detect eyes and ears, then compose these eyes and ears together to form higher level facial structure and this way, deep learning represents a form of a hierarchical model capable of representing different levels of abstraction in the data. So actually the fundamental building blocks of deep learning, which are neural networks have actually been existing, have actually existed for decades. So why are we studying this now? Well, there's three key points here. The first is that data has become

Speaker 1:          09:46          much more pervasive. We're living in a big data environment. These algorithms are hungry for more and more data and accessing that data has become easier than ever before. Second, these algorithms are massively parallel, likable, and can benefit tremendously from modern gpu architectures that simply just did not exist just less than more than a decade ago. And finally, due to open source tool boxes like tensorflow, building and deploying these algorithms has become so streamlined, so simple that we can teach it in a one week course like this, and it's become extremely deployable for the massive public. So let's start with now looking at the fundamental building block of deep learning. And that's the perceptron. This is really just a single neuron in a neural network. So yeah, I do have a perceptron or a single neuron is extremely simple. Let's start by talking about the forward propagation of information. Through this data unit, we defined a set of inputs x one x m on the left, and all we do is we multiply each of these inputs by their corresponding wait theta one through, say the end, which are those arrows. We take this weighted, we will take this weighted combination of all of our inputs, sum them up and pass them through a nonlinear activation function.

Speaker 1:          11:17          And that produces our output. Why? It's that simple. So we have m inputs, one output number, and you can see a summarized on the righthand side as a mathematics single mathematical equation. But actually I left out one important detail that makes the previous slide not exactly correct, so I left that this notion of a bias biases, uh, that green term you see on the left, and this just represents some way that we can allow our model to learn or we can allow our activation function to shift to the left or right. So it allows, if we provide, it allows us to, um, when we have no input features to still provide a positive output. So on this equation, on the right, we can actually rewrite this using linear Algebra and dod products to make this a lot cleaner. So let's do that. Let's say x capital x is a vector containing all of our inputs. X One, three, Xn capitol theater is now just a vector containing all of our status. They don't want to say to him, we can rewrite that equation that we had before is just applying a dot product between x and data. Adding our bias fate is zero. And applying our nonlinear u, G, g.

Speaker 1:          12:40          Now you might be wondering, since I've mentioned this a couple times now, what is this nonlinear function g? Well, I said it's the activation function, but, uh, let's see an example of what in practice ge actually could be. So one very popular activation function is the sigmoid function. You can see a plot of it here on the bottom right, and this is a function that takes its input. Any real number on the x axis and transforms it into an output between zero and one, because I'll, I'll put to this function are between zero and one. It makes it a very popular choice in deep learning to represent probabilities.

Speaker 1:          13:20          In fact, there are many types of nonlinear activation functions in deep neural networks. And here's some of the common ones throughout this presentation. You'll also see tensor flow code snippets like the ones you see on the bottom here, since we'll be using tensorflow for our labs. And well this is some way that I can provide to you to kind of link the material in our lectures with what you'll be implementing in labs. So the sigmoid activation function, which I talked about in the previous slide, now on the left, is a. it's just a function, like I said, it's commonly used to produce probability outputs. Each of these activation functions has their own advantages and disadvantages. Underwrite a very common activation function is rectified linear unit or value. This function is very popular because it's extremely simple to compute. It's piecewise linear. It's zero before with inputs less than zero, it's x with any input greater than zero, and the gradients are zero or one with a single nonlinearity at the origin.

Speaker 1:          14:22          And you might be wondering why we even need activation functions. Why can't we just take our dod product at our bias and that's our output. Why do we need the activation function? Activation functions introduce nonlinearities into the network. That's the whole point of why activations themselves are nonlinear. We want to model nonlinear data in the world because the world is extremely nonlinear. Let's suppose I gave you this, this plot green and red points, and I asked you to draw a single line, not a curve. Just align between the green and red points to separate them perfectly. You would find this really difficult and probably you could get as best as something like this. Now, if your activation function and your deep neural network was linear century, just composing linear functions with linear functions, your output will always be linear, so the most complicated deep neural network, no matter how big or how deep, if the activation function is linear, your output can only look like this, but once we introduced nonlinearities, our network is extremely more.

Speaker 1:          15:25          As the capacity of our network has extremely increased, we're now able to model much more complex functions. We're able to draw decision boundaries that were not possible with only linear activation functions. Let's understand this with a very simple example. Imagine I gave you a train network like the one we saw before. Sorry, I trained perceptron not in network yet. Just a single node and the weights are on the top, right, so status zero is one and the state of vector is three and negative to the network has two inputs, x one and x two, and if we want to get the output, all we have to do is apply the same story as before. So we apply the product of x and Theta, we add the bias and apply or nonlinearity, but let's take a look at what's actually inside. Before we apply that nonlinearity, this little, it looks a lot like just a two d line because we have two inputs and it is.

Speaker 1:          16:20          We can actually plot this line way equals zero in feature space. So this is space where I'm plotting x one, one of our features on the x axis and x to the other feature. On the y axis, we plot that line. It's just a decision boundary separating our entire space into two sub spaces. Now, if I give you a new point, negative one, two, and plotted on the sub and this feature space, depending on which side of the line of false on, I can automatically determine whether our output is less than zero or greater than zero. Since our line represents a decision boundary equal to zero, now we can follow the mass on the bottom and see that computing the inside of this activation function. We get one minus three minus two, sorry minus four, and we get minus six at the output before we applied the activation function.

Speaker 1:          17:14          Once we apply the activation function, we get zero point zero, $0 to so it negative what was applied to the activation functionalists negative because we fell on the negative piece of this sub space. Well, if we remember with the sigmoid function actually defines our space into two parts greater than one point five and less than point five. Since we're modeling probabilities and everything is between zero and one. So actually our decision boundary where the input to our network equals zero. Sorry, the. Sorry. The input to our activation function equals zero, corresponds to the output of our activation function being greater than or less than point five. So now that we have an idea of what a perceptron is, let's just start out by understanding how we can compose these perceptrons together to actually build neural networks. And let's see how this all comes together. So let's revisit our previous diagram up the perceptron know if there's a few things that you learned from this class, let this be one of them and we'll keep repeating it over and over. In deep learning, you do a dot product, you apply a bias and you add your non linearity. You keep repeating that many, many times for each node, each neuron in your neural network, and that's a neural network.

Speaker 1:          18:36          So let's simplify this diagram a little. I removed the bias since we are going to always have that and we just take her for granted from Nolan, I'll remove all of the weight labels for simplicity and note that z is just the input to our activation function. So that's just the dot product plus our bias. If we want the output of the network, why we simply take z and we apply or nonlinearity like before we wanted to find a multi output perceptron. It's very simple. We just added another perceptron. Now we have two outputs. Y One and y two. Each one has weight matrices, has weight factor theta corresponding to the weight of each of the inputs. Now let's suppose we want to go the next step deeper. We want to create now a single layer neural network.

Speaker 1:          19:31          Single layered neural networks are actually not deep networks yet. They're only. They're still shallow networks. There are only one layer deep, but let's look at the single layer neural network where now all we do is we have one hidden layer between our inputs and outputs. We call this hidden layer because it's states are not directly observable. They're not directly forced by by the AI designer. We only enforce the inputs and outputs. Typically the states in the middle are hidden and since we now have a transformation to go from our intimate space to our hidden hidden layer space and from our hidden layer space to our output layer space, we actually need to weight matrices, data, one end data to corresponding to the weight matrices of each layer.

Speaker 1:          20:21          Now, if we look at just a single unit in that hidden layer, it's the exact same story as before. It's one perceptron. We take it stopped product with all of the exits that came before it. And we apply A. Sorry, we take the dot product of the exes that came before with the weight matrices. Fate, is that a one? In this case, we apply a bias to get [inaudible]. And if we were to look at a different hidden unit, let's say z three, instead we would just take different weight matrices, different, uh, our dod product would change, our bias would change, but it does, I see change, which means it's activation would also be different. So from now on, I'm going to use this symbol to denote what is called as a fully connected layer. And that's what we've been talking about so far, so that's every note in one layer is connected to every node and another layer by these weight matrices.

Speaker 1:          21:12          And this is really just for simplicity, so I don't have to keep redrawing those lines. Now, if we want to create a deep neural network, all we do is keep stalking these layers and fully connected weights between the layers. It's that simple. But the underlying building block is that single perceptron said single dod product nonlinearity and bias. That's it. So this is really incredible because something so simple at the foundation is able to create such incredible algorithms. And now let's see an example of how we can actually apply neural networks to a very important question that I know you are all extremely worried about. You care a lot about. Here's the question you want to build an ai system that answers the following question. Will I pass this class? Yes or no? One or zero is the output to do this. Let's start by defining a simple to feature model.

Speaker 1:          22:07          One feature is the number of lectures that you attend. Second feature is the number of hours that you spend on your final project. Let's plot this data. In our feature space. We apply greenpoint's of people who pass. Red Points are people that fail. We want to know, given a new person, this guy, he spent a day, spent five hours on their final project and went to four lectures. We want to know did that person pass or fail the class and we want to build a neural network that will determine this. So let's do it. We have two inputs. One is for the others. Five, we have one hidden layer with three units and we want to see the final output probability of passing this class, and we computed as zero point one or 10 percent. That's really bad news because actually this person did pass the class. They passed it with probability one. Nope. Can anyone tell me why the neural network got this? Such so wrong? Why did it do this? Yeah, it is.

Speaker 2:          23:11          Exactly.

Speaker 1:          23:12          So this network has never been trained. It's never seen any data. It's basically a baby. It's never learned anything. So we can't expect it to solve a problem and knows nothing about. So to do this, to tackle this problem with training a neural network, we have to first define a couple things. So first we'll talk about the loss. The loss of a network basically tells our algorithm or our model how wrong our predictions are from the ground truth. So you can think of this as a between our predicted output and our actual output. If the two are very close, if we predict something that is very close to the true output, our loss is very low. If we predict something that is very far in a high level sense, far like in distance, then our loss is very high and we want to minimize this from happening as much as possible.

Speaker 1:          24:07          Now, let's assume we were not given just one data point one student, but we're given a whole class of students. So as previous data, I use this entire class from last year and if we want to quantify what's called the empirical loss, now we care about how the model did on average over the entire Dataset. Not for just a single student, but across the entire data set and how we do that is very simple. We just take the average of the loss of each data point. If we have end students, it's the average over end data points. This has other names besides empirical last. Sometimes people call it the objective function, the cost function, et cetera. All of these terms are completely the same thing. Now, if we look at the problem with binary classification, predicting if you pass or fail this class, yes or no, one or zero, we can actually use something that's called the softmax cross entropy loss.

Speaker 1:          24:58          Now, for those of you who aren't familiar with cross entropy or entropy, this is an extremely powerful notion that was actually developed, were first introduced here at mit over 50 years ago by Claude Shannon. Uh, in his master's thesis. Like I said, this was 50 years ago. It's huge in the field of signal processing thermodynamics. Really all of our computer science had seen in information theory. Now, instead of predicting a single one or zero output, yes or no, let's suppose we want to predict a, um, continuous valued function, not will I pass this class, but what's the grade that I will get it as a percentage, let's say zero to 100 now we're no longer limited to zero to one, but can actually output any real number on the number line. Now instead of using cross entropy, we might want to use a different loss. And for this, let's think of something like a mean squared error loss where as your predicted and you're true output diverged from each other, the loss increases as a quadratic function. Okay, great. So now let's put this new loss information to the test and actually learn how we can train a neural network like quantifying it's lost.

Speaker 1:          26:12          And really if we go back to what the loss is at the very high level, the last tells us how the network is performing, right? Did last tells us the accuracy of the network on a set of examples. And what we want to do is basically minimize the loss over our entire training set. Really, we want to find the set of parameters data such that that loss jff data, that's our empirical loss is minimum. So remember jff data takes us data and data's just our weights. So these are the things that actually define our network.

Speaker 1:          26:53          Remember that the last is just a function of these weights. If we want to think about the process of training, we can imagine this landscape. So if we only have two weights, we can plot this nice diagram like this, Beta zero and Beta one or two weights there on the floor. They're on the planer. Access on the bottom, JFK to zero, and three to one are plotted on the the Z axis. What we want to do is basically find the minimum of this loss of this landscape. If we can find the minimum, then this tells us where our loss is, the smallest, and this tells us where theater, where or what values of Beta zero and Beta one we can use to attain that minimum loss. So how do we do this? Well, we start with a random guests. We'd pick a point say to zero state of one, and we start there, we compute the gradients of this point on the last landscape. That's Dj de Seto. It's how the loss is changing with respect to each of the weights. Now this gradient tells us the direction of highest ascent, not decent. So this is telling us the direction going towards the top of the mountain.

Speaker 1:          28:10          So let's take a small step in the opposite direction. So we negate our gradient and we adjust our weight. So should we step into the opposite direction of that gradient such that we move continuously towards the lowest point in this landscape until we finally converged at a local minima. And then we just stop. So let's summarize this with some pseudo code. So we randomly initialized our weights. We loop until convergence the following. We compute the gradient at that point, and when simply we apply this update rule with the update takes as input the negative gradient. Now let's look at this term here. This is the gradient. Like I said, it explains how the loss changes with respect to each weight and the network, but I never actually told you how to compute this and this is actually a big, a big issue in neural networks. I've just kind of took it for granted. So now let's talk about this process of actually computing this gradient because without that gradient you're kind of helpless. You have no idea which way down is, you don't know where to go and your landscape. So let's consider a very simple neural network, probably the simplest neural network in the world. It contains one hidden units, one hidden layer and one output unit.

Speaker 1:          29:27          And we want to compute the gradient of our loss j of data with respect to theta to just stay at a two for now. So this tells us how a small change in theater to will impact our final loss at the output. So let's write this out as a derivative. We can start by just applying a chain rule because jff data is dependent on why, right? So first we want to back propagate through why our output all the way back to theater. To we can do this because why are output, why is only dependent on the input and data too. That's it, so we're able to just from that perceptron equation that we wrote on the previous slide, computer closed form, great end or close from derivative of that function. Now let's suppose I change state of two to three to one and I want to compute the same thing, but now for the previous layer and the previous wait, all we need to do is is a supply chain role. One more time back propagate those gradients that we previously computed one layer further. It's the same story. Again, we can do this for the same reason. This is because Z, one are hidden state is only dependent on our previous and put x and that single weight Fado one.

Speaker 1:          30:57          Now the process of backpropagation is basically you repeat this process over and over again for every weight in your network until you compute that gradient Dj d theater, and you can use that as part of your optimization process to find your local minimum.

Speaker 1:          31:16          Now, in theory, that sounds pretty simple. I hope. I mean, we just talked about some basic chain rules, but let's actually touch on some insights on training these networks and computing backpropagation and practice. Now, the picture I showed you before, it's not really accurate for modern deep neural network architectures. Modern deep neural network architectures are extremely non convex. This is an illustration or a visualization of the landscape like I've planted before, but have a real deep neural network of resonate 50 to be precise. This was actually taken from a paper published about a month ago, was the author's attempt to visualize the last landscape, to show how difficult gradient descent can actually be. So if there's a possibility that you can get lost in any one of these local Minima, there's no guarantee that you will actually find a true global minimum. So let's recall that update equation that will we defined during gradient descent.

Speaker 1:          32:11          So take a look at this term here. This is the learning rate. I didn't talk too much about it, but this basically determines how large of a step we take in the direction of our gradient and in practice setting this learning great. It's just a number, but setting it can be very difficult if we set the learning rate too low than the model get may get stuck in a local minima and may never actually find its way out of that local Minima ps at the bottom of local man. Well obviously gradient is zero, so it was just going to stop moving. If I said the learning rate too large, it could overshoot and actually diverged. Our model could blow up.

Speaker 1:          32:50          Okay. Ideally we want to use learning rates that are large enough to avoid local minima, but also still converged to our global minimum so they can overshoot just enough to avoid some local minima but then converge to our global minimum. Now, how can we actually set the learning rate? Well, one idea is let's just try a lot of different things and see what works best, but I don't really like the solution. Let's try and see if we can be a little smarter than that. How about we tried to build an adaptive algorithm that changes its learning rate as training happens. So this is a learning rate that actually adapts to the landscape that it's in. So the learning grade is no longer a fixed number. It can change, it can go up and down, and this will change depending on the location that the, that the update is currently yet the great end in that location, maybe how fast we're learning and many other many other possible situations. In fact, this process of optimization in deep neural networks and non convex situation has been extremely explored. There's many, many, many algorithms for computing adaptive learning rates and here are some examples that we encourage you to try out during your labs to see what works best and for your problems, especially with real world problems. Things can change a lot depending on what you learn in lecture and what really works in lab and we encourage you to just experiment, get some intuition about each of these learning rates and really understand them at a higher level.

Speaker 1:          34:30          So I want to continue this talk and really talk about more the practice of deep neural networks. This incredibly powerful notion of many batching and I'll focus for now if we go back to this gradient descent algorithm, this is the same one that we saw before and let's look at this term again so we found out how to compute this term using backpropagation, but actually what I didn't tell you is that the computation here is extremely calm, is extremely expensive. We have a lot of data points potentially in our data set and this takes us input a summation over all of those data points. So if our Dataset is millions of examples large, which is not that large in the realm of today's deep neural networks, but this can be extremely expensive just for one iteration, so we can compute this on every iteration. Instead, lets create a variant of this algorithm called stochastic gradient descent where we compute the gradient just using a single training example.

Speaker 1:          35:30          Now this is nice because it's really easy to compute the gradient for a single training example. It's not nearly as intense as over the entire training set, but as the name might suggest, this is a more stochastic estimate, as much more noisy. It can make us jump around the landscape in ways that we didn't anticipate. It doesn't actually represent the true gradient of our data set because it's only a single point, so what's the middle ground? How about we define a mini batch of be data points, compute the average gradient across those data points, and actually use that as an estimate of our true gradient. Now this is much faster than computing the estimate over the entire batch because b is usually something like 10 to 100 and it's much more accurate than sgd because we're not taking a single example, but we're learning over a smaller batch. A larger batch. Sorry. Nope. The more accurate our gradient estimation is, that means the more or the easier it will be for us to converge to the solution, faster means will converge smoother because we'll actually follow the true landscape that exists. It also means that we can increase our learning great to trust each update more.

Speaker 1:          36:44          This also allows for massively parallel likable computation. If we split up batches on different workers on different gps or different threads, we can achieve even higher speed ups because each thread can handle its own batch. Then they can come back together and aggregate together to basically create that single learning grade or complete complete that single training iteration. Now finally, the last topic I want to talk about is that of overfitting and regularization. Really this is a problem of generalization, which is one of the most fundamental problems and all of artificial intelligence, not just deep learning, but all of artificial intelligence, and for those who aren't familiar, let me just go over on a high level what overfitting is, what it means to generalize. Ideally in machine learning, we want the model that accurately describes our test data, not our training data, but our test data

Speaker 1:          37:47          said differently. We want to build models that can learn representations from our training data and still generalized well on unseen test data. Assuming you want to build a line to describe these points under fitting describes the process on the left, where at the complexity of our model is simply not high enough to capture the nuances of our data. If we go over 50 on the right, we're actually having too complex of a model and actually just memorizing our training data, which means that if we introduced a new test data point, it's not going to generalize well. Ideally what we want to, something in the middle, which is not too complex to memorize all of the training data, but still a contains the capacity to learn some of these nuances in the test set. So just to address this problem, let's talk about this technique called regularization. Now regularization is just this way that you can discourage your models from becoming too complex and after we've seen, as we've seen before, this is extremely critical because we don't want our data. We don't want our models to just memorize data and only do well in our training set.

Speaker 1:          39:04          One of the most popular techniques for regularization in neural networks is dropout. This is extremely simple idea. Let's revisit this picture of a deep neural network and then drop out all we do during a training on every iteration, we randomly drop some proportion of the hidden neurons with some probability p, so let's suppose p equals point five. That means we dropped 50 percent of those neurons like that. Those activations becomes zero and effectively they're no longer part of our network. This forces the network to not rely on any single node, but actually find alternative paths through the network and not put too much weight on any single example with any syngrid single nodes, so it discourages memorization. Essentially, John, every iteration, we randomly drop another 50 percent of the nodes, so in this iteration I may drop these on the next iteration. I may drop those and since it's different on every iteration, you're encouraging the network to find these different paths to his answer.

Speaker 1:          40:08          The second technique for regularization that we'll talk about is this notion of early stopping. Now we know that the definition of overfitting actually is just when our model starts to perform worse and worse on our test data set. So let's use that to our advantage. To create this early stopping algorithm, if we set aside some of our training data and use it only as test data, we don't train with that data. We can use it to basically monitor the progress of our model on unseen data so we can plot this curve. We're on the x axis, we have the training iterations. On the y axis, we have to loss. Now they start off going down together. This is great because it means that we're learning or training, right? That's great. There comes a point though where the testing data, where the testing data set and the loss for that Dataset starts to plateau. Now, if we look a little further, the training data set loss will always continue to go down as long as our model has the capacity to learn and memorize some of that data, but that doesn't mean that it's actually generalizing well because we can see that the testing dataset has actually started to increase.

Speaker 1:          41:17          This pattern continues for the rest of training, but I want to focus on this point here. This is the point where you need to stop training because after this point, you are overfitting and your model is no longer performing well on unseen data. If you stopped before that point, you're under fitting and you're not utilizing the full potential to full capacity of your network. So I'll conclude this lecture by summarizing three key points that we've covered so far. First, we've learned about the fundamental building blocks of neural networks called the perceptron. We've learned about stacking these units, these perceptrons together to compose very complex hierarchical models, and we've learned how to mathematically optimize these models using a process called backpropagation and gradient descent. Finally, we addressed some of the practical challenges of training these models in real life that you'll find useful for the labs today, such as using adaptive learning rates, batching and regularization to combat overfitting. Thank you. And, uh, I'd be happy to answer any questions now. Otherwise, we'll have rainy talk to us about some of the deep sequence models for modeling temporal data.