Speaker 1:          00:03          So a lot is being written and said about deep learning and the new ai wave and not everything is true. So yes, one of the things that's natural, so the idea that machines program themselves these days and all the have to do is put mediocre data in turn the crank and outcome excellent results. But that is um, but I think of true magic in this deep learning and here's what really fascinates me the most about this field is a deep learning led's or solve problems. We don't know how to program so we can solve problems. We actually don't understand in detail sophia in sufficient detail that we can program a solution. The first time I witnessed this is quite awhile ago, it was around 1992 I was in at eth in Switzerland working on a reading machine for the blind and we made good progress on printed texts.

Speaker 1:          01:08          But we, when we, we got nowhere for handwritten text. And so I was reading through paper after paper was promising titles and just to be disappointed time and again. So most people back then they worked on capitol letters from eight to f for example, that tiny variations to the bitmap and 10 called it Fontin variant. And then somebody pointed me to the work of Yonder coon and I looked into that and was very fascinated because he was working with actual data from the u s postal service, no, no cheating possible. And he claimed to have excellent results. And he's methods we are comparatively simple. So we rushed to re implementers and well first we had to rush to actually collect data and then train the network and it felt like magic it, it would actually read and do this seemingly impossible task. So a year later I was fortunate to join that very team at bell labs. So I divided my presentation into two parts. The first part I will talk about the early uh, deep learning work at bell labs. And then the second part I will talk about our current vogue at Nvidia on self driving cars. So from 1990 from 1985 to 90 1995 was a 10 year period. It was incredibly productive. So in that team, that team not only created convolutional networks, uh, it also created support vector machines as vms and later foundation of important, uh, machine learning, learning theory, and also, uh, created several generations of neural network.

Speaker 2:          03:01          Okay.

Speaker 1:          03:01          This is the building in homedale new Chelsea. So gigantic building, actually a t eight house, about 6,000 employees, 300 of those were in research and 30 of those in machine learning. So you'll probably recognize several of the names. Um, and since as researchers we tended to show up late in the day, we always had to park way out here, which added about 10 more minutes to your commute just to walk into the building and into your office. There's these two ponds here. Uh, could you imagine what they are for? They're not just landscaping.

Speaker 2:          03:45          Yeah,

Speaker 1:          03:46          yeah. They thought that he takes changes for the, for the air conditioning of the building or it used to be late today, replaced them with cooling towers. This is the very first data sets that I've worked with, uh, collected among the researchers themselves. A later they got data from the U S Postal Service. Um, and then that grew into nist and nist, which is still very widely used today.

Speaker 1:          04:16          So a lot of the work was about what structure to be put into the learning machines. What prior knowledge do we equip them with to, to perform the task? Well, um, if you talk about, if you look at this example here and you needed to build a classifier that can distinguish between the red and the green classes and you wonder what class does this x belong to? So if you take, um, location east, west, north, south as you criteria to classify, then you would probably say the x belongs to Green. But if you understand that these points are actually real points on the surface of the earth and it happens that the green ones are on board and the red ones are on land, then you could change your criteria and say, let me take a level above the height, above sea level as the criteria, in which case the problem becomes trivial. So this point is actually on land. So he belongs to the right class. Anybody see that? He sees

Speaker 2:          05:31          this is Manhattan, New York.

Speaker 1:          05:35          So this is an example how programming or are using prior knowledge actually helps the classification task enormously. Um, of course that led to the creation of convolutional networks. This is an old slide that we use to explain how they work. Naturally you have these convolutions that can learn to do, um, today's lines, vertical, horizontal, and then next layer can the deck at and so on. And of course the leap of faith was that we don't have design these features, but actually like a numerical optimization algorithm find optimal solutions. Oh, he has an old video from yonder coon showing low net.

Speaker 2:          06:23          Yeah,

Speaker 1:          06:23          you supposed to own an old 80 and tpc I believe was a dsp accelerator in it. So yeah, you may have seen the video. It's, it's on youtube and at that time, many, many, many brilliant minds tried so hard for years to solve the problem. And here comes, this network can just does it was almost looks with ease. Then young gets creative. I'm quite sure that this type of characters, we're not in the training side. Some other people from the lab. This is Donnie Henderson,

Speaker 1:          07:14          a three child who was the lab director at the time. So as we became to look at, learning is essentially two main things, monies to build prior knowledge into the architecture of what Vladimir about calls, structural risk minimization. And the other one is a capacity control. So you need to match the size of your network to the amount of diversity of the data that you have and one really good tool to do that or to to analyze that these learning curves. So this is not the number of epochs he otis a actually each point on this chart is a fully trained network. So what do you do is you measure the performance of your network on the training set and on the test track while you're growing the and not the amount of data that you're training the network with. So this is the, uh, the number of examples that you use for training.

Speaker 1:          08:14          So if you have very, very few examples, then the networks can essentially memorized a training set and the ad or on the training side is zero. While the error on the test that is very big. And then as you grow the Dataset, the, the, uh, error on the test that calms down and at some point the networks can no longer memorize and that the entire data set and the, the training said Arrow starts to grow. And empirically it's been shown that these curves eventually die neat. And you don't need to plot the entire curve. It's usually in the middle between the two curves. So you can half a good idea what to expect. So if you hit this point a year, then it becomes clear that it doesn't help you to add more data. You have to increase the capacity of your network. Uh, he has a learning curve from real life that we did last week. So this is, uh, here, uh, predicting the steering angle of a human. So how close does the netbook steer like a human? And you see that, uh, around here we reached a point where adding new data wouldn't help us.

Speaker 1:          09:32          Then in the 90s, [inaudible] was sometimes heated debate about what is the best algorithm for classifying characters. And

Speaker 2:          09:40          the, the, uh,

Speaker 1:          09:44          manager of the group at the time was Larry Charcoal. And he said, well, let's just find out and combat all of those. So this was one of these ideal situations. Very had several people competing with ideas and everybody was convinced my idea is the best. Um, so I'll be combined them all and if I remember correctly, that's what, that's the reason that they created the nist database for. So m stands for modified

Speaker 1:          10:09          the result is somewhat interesting. So, um, k nearest neighbor that nobody believed that that would be the winner. Um, that was just there for reference. Also fully connected network. They're just there for reference. Then this is lanette one. This was optimized for a much smaller data set from the United States postal survey. So that didn't do very well on this either. In fact, it was even slightly versed and fully connected. And then these here, these were the actual competitor. So this is a convolutional network, but this time optimized for the lots are mds data set. Uh, I'll get back to boosting in a minute. Then different variations. Um, so he, uh, for example, k nearest neighbor of course, has one big flaw. So if you'd just take the Euclidean distance, um, as your metric as we did here, then if you shift to characters which are actually the same by a few pixels, then the Euclidean distance starts to become enormous.

Speaker 1:          11:12          So it doesn't really measure how close to our house similar to characters are very well. So here, the idea of stop lights instead of using the Euclidean distance, let's do the same thing. I'm used the EUCLIDEAN distance, but not in the pixel space, but in the uppermost feature map. And that's a boost. It's the performance quiet a bit. Tangent distance was another one of the ideas we talked a lot at a time. Uh, another clever trick to increase the performance of k nearest neighbor. So if you'll picture each character to be a point in a very high dimensional pixel space and you start doing some photo probations to eight without changing the actual characters. So you, you rotate it all it a little bit, you shifted, you grow the stroke a bit, um, then that forms a surface around that point. And if you don't deviate too much from the original point, and you can model that as a plane.

Speaker 1:          12:10          And the tangent reasons is simply the EUCLIDEAN distance between two such planes. I'm so clever idea was a lot of prior knowledge of the problem built into and that also gets very good performance and optimal margin. That's essentially an Svm. And so what's interesting is that they all have the exact same performance. The only one that actually improve the performance was boosting, which is kind of a different type of approach. So here you train multiple networks, you're trying to second network on the mistakes of the first one and your trainers. Third one on there, the first to disagree. So you get multiple expert. I specialize on different parts of it, of the training sentence. So it's not too surprising that that actually would increase the performance. So what Larry said in hindsight is that, well, it's not too surprising that I would all perform the same because everybody was doing the same type of approach in exploring them the past capacity of their learning system by doing the learning curves. The one thing that stands out in my mind is the Svm because that has no prior built in knowledge about the task at all. But all of the others too.

Speaker 1:          13:27          Um, classification rate is not the only thing that you should actually focus on. Of course, it's also memory consumption, which is not on this chart, a training time and inference time. So all of the memory based k nearest neighbor types, they use very little training time, but then they use a lot of memory.

Speaker 1:          13:47          So the lessons, some of the lessons that I took from that time is, uh, one is still very relevant, is look at the data. I've seen so many people miss important cues. I'm confused why you we was Rgb, for example. That doesn't make your system failed completely. It just doesn't perform as well as he could. Um, solid debugging tools are critical. These a neural networks have a nasty habit of a masking box and the they and I adapted a, they try their best to work around parks, um, validated training data. Again that's related to look at the data. Um, so many data sets I've seen actually have a grave labeling mistakes and to work is experimental in nature. At least that's what it is to stay off today. So in most cases you can just copy paste or recipe from somebody else that will now give you the optimal results. And the last one is work with real data. Synthetic data is great for debugging and you can certainly explore certain trends, but to get a sense of very, you really are, um, you, you have to work with real data.

Speaker 1:          15:04          So what happened after 95, actually riding around the 95, uh, uh, a t and t released a first production version of convolutional networks for commercial check reading. And eventually 20% of all the checks written in the u s were processed by that system or right by that system. To me, that was the real, the real sign of success. If a technology is a commercially buy apple at the set in the same year actually, um, maybe in the morning sitting together discussing how we should celebrate this fact. The success was the commercial check reading and a message came in that day. T and t d announcement came in at eight and t would break up into three parts. So that was quite a shock. And then in 2002, there were mass layoffs and most people left. And some of the important folks from machine learning, they found themselves working together again, either add star power or for Darpa and created several programs such as locker learning, applied to ground robots, uh, learning locomotion. One was even called deep learning and also the helping to get about his difference. Darpa challenges launched. And then in 2002 deep learning becomes really popular and I guess it's triggered by the availability of data, the availability of compute powers and also, uh, ready commercial applications. So all of these large scale internet applications in speech recognition and image classification, they bill radio at this point. And I guess there was just not too much money in check rating for the economy to take notice back then.

Speaker 1:          16:56          So this brings me to what you're doing today. Very similar technology applied to a self driving costs in this case. So felleston over the off the entire stack of and be yourself driving. So we have at the bottom the hardware that goes into the car, that's the drive px family of products. The most recent is called Pegasus. That was just announced at ces. Then we have the operating system or the old timer, but I think system layer. And then on top of that is driver folks. That's what I call the middle man. So that does sensor abstraction does a, all the logging tools interprocess communication and it has low level computer division library such as image transformations. And then on top of that is a drive a, b. This is the application. Yeah. So this is where it would be put together all of the other technology to form actual applications. And some examples are here. This is um, sensor fusion from radar and camera on this, this lidar point cloud processing or deep learning based object detector. So the detective boss here, or to pedestrians back there. This is deep learning based, uh, pre risk-based. That action. Um, this is localization based on hd maps and then this year is a perception based as a planning. This is actually what comes out of our group in New Jersey. So what a new Chelsea group is doing there, we contribute into this layer here

Speaker 1:          18:33          and our goal is to solve the heart and on solves problems. And I think there's a lot of those in self driving car. So if I think back to a character recognition, if we can't even program handwritten character recognition, then it's very likely that dealing with other humans and all kinds of different situations is likely not going to be solvable by just programming. So we concentrate on these heart problems for two reasons. One is that we want to provide algorithmic diversity. So in a safety critical system, it's unlikely that you want to rely on any single algorithm. And the second reason is that we can solve functionality that might not be solvable otherwise. Like, uh, taking turns just based on perception without map data or learn to march on to a busy highway where you have to negotiate with the other cars and squeeze yourself in. And then other, the other labs, um, the other autonomous labs in a Nvidia are in California, in Boulder, in Seattle, and in Europe. This is, oh, we're actually back in the same building, which is cool. The building was empty for over 10 years, but it's now being redeveloped for mixed use. So there's a number of different tech tech companies in there. So in Eto is renting space around here and there's also, we're going to get restaurants and shops and on the rooftop test plans to build a hotel.

Speaker 2:          20:11          Uh,

Speaker 1:          20:12          the reason why the tear is, um, not so much sentimental. It's because this is actually a very good environment for testing, self driving cars. We have plenty of space in the basement of the building to store and welcome to cars. And then there's two tunnels here. Then with that we can take and dare leaders right up to these private routes. Here on the campus. Driving Monster around here is actually two miles. And then right outside we have a very nice mix of highway local adults in the residential adults. The location is also quite

Speaker 3:          20:48          nice. Um, so I've got about 45 miles from New York City and there's a train connection and fairy. So the train is about 60 to 70 minutes and to failures faster actually can take the shortcut. So it's around 40 minutes. So

Speaker 1:          21:06          what is a typical case where rule based system struggle? While this seems clear so they can detect these lane markings, localize the car within it and then half a past planner and the controller and thrive, but just um, about a hundred meters further up on this road to situation looks like this. So it's much harder now. So he can just, you have to double yellow line, marker fainted and then the center one is almost gone. You can still solve it. Of course you can build a detector for this curb. But offense, you may be able to reconstruct these yellow lane marking. Then you can measure the distance here and decide that this is actually buy it at an online. This is probably two lines and I'm currently here, so I'm going to assume that there's actually a virtual lane here and I'm going to drive down. And then you have solved the problem for tastes for it is a scenario and then around the corner it's different again. So you have to start all over. And then again and again. So it seems a big advantage if we can build a system that can derive to domain knowledge from data. So by just observing humans, not by somebody telling it what it actually should look for in this scene.

Speaker 1:          22:18          So what we, this is one of the things that we built. Um, if this is the line here, that's where the car currently is, then we predict there would the human drive. So what is the short term trajectory that the human will take given that image? And so collecting the data is relatively simple. You just drive, um, you can then derive this trajectory from the IGA motion of the car. So that training labels, you essentially collect them for free without additional manual labor while you're collecting the data. And so then the, the difference between what a human drove and what the network predicts, that's the Arrow signal that we back propagate. Uh, this is an example network architecture. Um, this is from about two years ago. It still looks similar but it's growing. So we constantly adapting to the, to the current size of the training side.

Speaker 3:          23:19          Oh yeah. See how good I feel. Universal sign. These are all old.

Speaker 4:          23:31          And with this approach, it really doesn't matter why they're doing hot rolled looks horrible, grass overgrown or is a nice high highway. As long as the update that we can learn from it currently not used anymore than our campus. So that's just the ideal. What experimenting. Oh, cool. So the noises in the background but not acting. This is actually real. We struggle so much to get this to work for. An important deadline was just about 12 hours before the drop dead deadline that those things started working. That was a big relief. So this is um, uh, a made up construction side but on paved section in the, in about, uh, people often ask 12, if you train this in California, can he drive in New Jersey? So we, we showed it here, we trained with California data only on a new Chelsea highway and he had at night please linked slightly on an unpaved road in a nearby park.

Speaker 1:          24:57          Got It.

Speaker 1:          25:01          So we'll move on to something a little more practical. This is highway driving. Um, so he had been driving, you'll see here, you see this is what the network protects, what the human would drive and you see that line markings here are lousy and then in part they're completely missing. And that doesn't seem to impress the netvault keep people, they still protects, protects the correct trajectory. What do you see here is we show the trajectory is predicted from the most recent 10 frames and then correct them for Iga motion of the car. And then he showed them all on top of each other. This is a debugging tool. Um, if the network is confident, it will be consistent with its predictions over a few frames and the noodles are nice and tight. And if it's not confidence, then they'll spread out all over the place. It will predict something different each flame. So he had not to try taking, take to the exit, uh, or here again, this is all stuff that we haven't programmed. They just picked it up by observing humans. Um, we're not limited to, to La on lane keeping. We can also learn lane changes. So this is a video showing that the, the lane changes or triggered manually by a, this is change and here driving and he's uh, he's just taping the Labor for the turn signal and that's, that indicates to the corner they should now change lanes.

Speaker 1:          26:37          We can also learn different, uh, length of the lane changes. So we can tell the car to do complete the lane change and two meters or 100 meters or 50 meters. That's actually quite exciting. Uh, I tie waist speeds, completing lane change and 50 meters.

Speaker 3:          26:55          We can also allow him to take, this was particularly exciting because I'm not sure that's really any other ways you should do this. Well, I know if I wasn't he cuddled goals is to be able to send the car okay. By fame, I would go back to the office. Okay.

Speaker 1:          28:49          So one of the things I mentioned before that, uh, it's important that, or an important aspect of our work is to learn by observing humans, not by manually programming things into the system, but nevertheless, they want to understand what it actually learned. So he'll be analyzed what, what is looking at this DC, the green regions, these are the regions that the network is sensitive to and you see that it learns to recognize that [inaudible] Lane markings, which is interesting because we never labeled a single lane marking during training or here in a residential street. He learns to look at the cars. But if you look closely and you can the trees here or on our campus, if there's no clear lane markings, it learns to figure it out to the Dextero. Dhs through other means.

Speaker 3:          29:38          Okay.

Speaker 1:          29:39          So this is an important, a very important tool for us. Here's a short video, you'll see a line match. So about the driving on the highway, it's looking at both land markings, but this one will disappear in a moment. And now instead of looking at the bowls of a doubly wide lane is actually just following this one until the right one comes close enough so it becomes a single lane again. And it picked that up by observing. This is not us manually programming that into the system. Um, at one point some day we needed a screenshot from the inside of the car and there's a lot of construction going on on the campus currently. And bobcat comes out into our old way. And if you look here, the network, uh, prominently recognizes it even though we're quite soft and it's never seen this type of vehicle in the training before.

Speaker 2:          30:31          Yeah.

Speaker 1:          30:32          So I wanted to close with, uh, some open challenges. My mind, these are, while we have tons of open challenges, but these are two of the big ones. One is to deal with ambiguous situations. So if you imagine any won't allow them to merge onto a highway and you have a car right next to you, then you can either speed up and go in front or it can slow down and go behind what he can do, the average. So how would we, how would we deal with that hobby? Can learn from that as more than one possible, a correct way of driving, but you're only ever get one, one, one, one of these possible options in each example. And then the other one is learned from imperfect behavior. So we have a ton and ton of data, but currently we need to cut out all the imperfect driving.

Speaker 1:          31:18          You don't want to teach the network to cutting corners and such. Okay. And Andy Dazzler on multiple, what do you do? So it may makes the humans, so if we can get around and figured out how he can learn on its own, what it actually should look at and Modis for dot outliers, we would have a ton more data that we can work with them. And so I will finish with this video here. Uh, this was recorded recently in December. We got new data from a new sensor set of a new car fleet. And so the first 10 hours came in all California data in the sun, very little night, no rain. And so the first thing they usually do is we train and networks. We go out and test to see if it meets our expectations. This is kind of an end to end test to see, to make sure that nothing's wrong with this new data. Uh, that day it happened to snow. So we were curious to see what happens and it actually is, uh, performed. Surprisingly. My also all this network has ever seen is California data and is now driving in the snow and no Chelsea or here at night, uh, on a potluck snow covered road was a lights from oncoming traffic.

Speaker 2:          32:32          Okay.

Speaker 1:          32:34          You can also see what it's looking at and it, it looks at what seems correct on the road here. It even looks at the tread of the tire tread markings in this now even though it certainly hasn't seen that in, uh, in the original training data. And that brings me to the end. Thank you for your attention.