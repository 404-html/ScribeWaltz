WEBVTT

1
00:00:02.610 --> 00:00:06.570
<v Speaker 1>I want to bring this part of the class </v>
<v Speaker 1>to an end,</v>

2
00:00:06.571 --> 00:00:10.620
<v Speaker 1>so this is our last lecture,</v>
<v Speaker 1>but for our series of guest lectures and</v>

3
00:00:10.621 --> 00:00:11.454
<v Speaker 1>in this talk I hope to address some of </v>
<v Speaker 1>the state of deep learning today and </v>

4
00:00:14.701 --> 00:00:15.534
<v Speaker 1>kind of bring up some of the limitations</v>
<v Speaker 1>of the algorithms that you've been </v>

5
00:00:18.091 --> 00:00:20.580
<v Speaker 1>seeing in this class so far.</v>
<v Speaker 1>So we've got a really good taste of some</v>

6
00:00:20.581 --> 00:00:21.414
<v Speaker 1>of the limitations specifically in </v>
<v Speaker 1>reinforcement learning algorithms that </v>

7
00:00:25.111 --> 00:00:29.170
<v Speaker 1>lex gave in the last lecture and that's </v>
<v Speaker 1>really going to build on a.</v>

8
00:00:29.480 --> 00:00:30.313
<v Speaker 1>or I'm going to use that to build on top</v>
<v Speaker 1>of during this lecture and just to end </v>

9
00:00:33.901 --> 00:00:35.490
<v Speaker 1>on.</v>
<v Speaker 1>I'm gonna bring you.</v>

10
00:00:35.550 --> 00:00:36.383
<v Speaker 1>I'm going to introduce you to some new </v>
<v Speaker 1>frontiers in deep learning that are </v>

11
00:00:40.171 --> 00:00:41.004
<v Speaker 1>really,</v>
<v Speaker 1>really inspiring and that the cutting </v>

12
00:00:42.391 --> 00:00:47.010
<v Speaker 1>edge of research today.</v>
<v Speaker 1>Before we do that,</v>

13
00:00:47.850 --> 00:00:48.683
<v Speaker 1>I'd like to just make some </v>
<v Speaker 1>administrative announcements so tee </v>

14
00:00:51.971 --> 00:00:54.900
<v Speaker 1>shirts have arrived and will be </v>
<v Speaker 1>distributing them today and we'd like to</v>

15
00:00:54.901 --> 00:00:58.110
<v Speaker 1>distribute first to the registered for </v>
<v Speaker 1>credit students.</v>

16
00:00:59.400 --> 00:01:00.233
<v Speaker 1>After that,</v>
<v Speaker 1>we will be happy to distribute to </v>

17
00:01:01.771 --> 00:01:03.480
<v Speaker 1>registered listeners and then after </v>
<v Speaker 1>that,</v>

18
00:01:03.481 --> 00:01:06.330
<v Speaker 1>if there's any remaining goal,</v>
<v Speaker 1>give out to listeners if they'd want,</v>

19
00:01:06.360 --> 00:01:07.280
<v Speaker 1>if they're interested.</v>

20
00:01:10.080 --> 00:01:12.180
<v Speaker 1>So for those of you who are taking this </v>
<v Speaker 1>class for credit,</v>

21
00:01:12.181 --> 00:01:17.181
<v Speaker 1>I need to reiterate what kind of options</v>
<v Speaker 1>you have to actually fulfill your credit</v>

22
00:01:17.731 --> 00:01:18.564
<v Speaker 1>requirement.</v>
<v Speaker 1>So the first option is a group project </v>

23
00:01:20.761 --> 00:01:23.610
<v Speaker 1>proposal presentation.</v>
<v Speaker 1>So for this option,</v>

24
00:01:23.611 --> 00:01:27.420
<v Speaker 1>you'll be given the opportunity to pitch</v>
<v Speaker 1>a novel deep learning idea to a panel of</v>

25
00:01:27.421 --> 00:01:28.254
<v Speaker 1>judges on Friday.</v>
<v Speaker 1>You'll have exactly one minute to make </v>

26
00:01:31.471 --> 00:01:35.250
<v Speaker 1>your pitch as error,</v>
<v Speaker 1>as clear and as concisely as possible.</v>

27
00:01:35.850 --> 00:01:36.683
<v Speaker 1>So this is really difficult to do in one</v>
<v Speaker 1>minute and this kind of one of the </v>

28
00:01:39.121 --> 00:01:39.954
<v Speaker 1>challenges that we're,</v>
<v Speaker 1>we're putting on you in addition to </v>

29
00:01:41.911 --> 00:01:44.970
<v Speaker 1>actually coming up with the deep </v>
<v Speaker 1>learning idea itself.</v>

30
00:01:46.500 --> 00:01:49.170
<v Speaker 1>If you want to go down this route for </v>
<v Speaker 1>your final project,</v>

31
00:01:49.920 --> 00:01:50.753
<v Speaker 1>then you'll need to submit your teams,</v>
<v Speaker 1>which have to be of size three or four </v>

32
00:01:54.061 --> 00:01:56.070
<v Speaker 1>by the end of today.</v>
<v Speaker 1>So at 9:00</v>

33
00:01:56.070 --> 00:01:57.090
<v Speaker 1>PM today,</v>
<v Speaker 1>we'd like those in,</v>

34
00:01:57.890 --> 00:01:58.723
<v Speaker 1>um,</v>
<v Speaker 1>you'll have to do teams of three and </v>

35
00:02:00.571 --> 00:02:00.900
<v Speaker 1>four.</v>

36
00:02:00.900 --> 00:02:03.510
<v Speaker 1>So if you want a group working in groups</v>
<v Speaker 1>of one or two,</v>

37
00:02:03.570 --> 00:02:05.120
<v Speaker 1>then you'll have to,</v>
<v Speaker 1>you're,</v>

38
00:02:05.150 --> 00:02:07.770
<v Speaker 1>you're welcome to do that,</v>
<v Speaker 1>but you won't be able to actually submit</v>

39
00:02:07.990 --> 00:02:12.180
<v Speaker 1>or final project as part of a </v>
<v Speaker 1>presentation on Friday.</v>

40
00:02:12.210 --> 00:02:13.043
<v Speaker 1>You can submit it to us and we'll,</v>
<v Speaker 1>we'll give you the grade for the class </v>

41
00:02:15.871 --> 00:02:17.760
<v Speaker 1>like that.</v>
<v Speaker 1>Um,</v>

42
00:02:17.940 --> 00:02:18.773
<v Speaker 1>so groups are do 9:00</v>
<v Speaker 1>PM today and you have to submit your </v>

43
00:02:21.871 --> 00:02:23.280
<v Speaker 1>slides by 9:00</v>
<v Speaker 1>PM tomorrow.</v>

44
00:02:23.490 --> 00:02:27.090
<v Speaker 1>Presentations or our class on Friday in </v>
<v Speaker 1>this room.</v>

45
00:02:27.840 --> 00:02:30.120
<v Speaker 1>If you don't want to do a project or a </v>
<v Speaker 1>presentation,</v>

46
00:02:30.150 --> 00:02:30.983
<v Speaker 1>you have a second option,</v>
<v Speaker 1>which is to write a one page paper </v>

47
00:02:33.080 --> 00:02:35.520
<v Speaker 1>review of a deep learning idea.</v>
<v Speaker 1>Uh,</v>

48
00:02:35.521 --> 00:02:39.670
<v Speaker 1>so any idea or any paper that you find </v>
<v Speaker 1>interesting is,</v>

49
00:02:39.760 --> 00:02:40.593
<v Speaker 1>is welcome here.</v>
<v Speaker 1>So we really accept anything and we're </v>

50
00:02:42.061 --> 00:02:43.890
<v Speaker 1>really free in this,</v>
<v Speaker 1>in this,</v>

51
00:02:43.891 --> 00:02:45.420
<v Speaker 1>um,</v>
<v Speaker 1>option as well.</v>

52
00:02:46.740 --> 00:02:47.573
<v Speaker 1>I want to highlight some of the exciting</v>
<v Speaker 1>new talks that we have coming up after </v>

53
00:02:50.701 --> 00:02:51.534
<v Speaker 1>today.</v>

54
00:02:51.600 --> 00:02:53.790
<v Speaker 1>So tomorrow we'll have two sets of guest</v>
<v Speaker 1>lectures.</v>

55
00:02:53.791 --> 00:02:57.930
<v Speaker 1>First we'll hear from Ernest Mueller,</v>
<v Speaker 1>who is the chief architect of and videos</v>

56
00:02:58.200 --> 00:02:59.033
<v Speaker 1>self driving car team.</v>
<v Speaker 1>So erzen and his team were actually </v>

57
00:03:01.931 --> 00:03:02.764
<v Speaker 1>known for some really exciting work that</v>
<v Speaker 1>Aldo is showing yesterday during her </v>

58
00:03:06.221 --> 00:03:07.054
<v Speaker 1>lecture and they're known for this </v>
<v Speaker 1>development of an end to end platform </v>

59
00:03:09.641 --> 00:03:10.474
<v Speaker 1>for autonomous driving that takes </v>
<v Speaker 1>directly image data and produces a </v>

60
00:03:14.320 --> 00:03:17.290
<v Speaker 1>steering control command at the car for </v>
<v Speaker 1>the car at the output.</v>

61
00:03:18.150 --> 00:03:18.983
<v Speaker 1>Then we'll hear about,</v>
<v Speaker 1>we'll hear from two google brain </v>

62
00:03:21.011 --> 00:03:25.300
<v Speaker 1>researchers on recent advancements on </v>
<v Speaker 1>image classification at Google.</v>

63
00:03:26.020 --> 00:03:30.280
<v Speaker 1>And also we'll hear about some super </v>
<v Speaker 1>recent advancements and additions to the</v>

64
00:03:30.281 --> 00:03:34.360
<v Speaker 1>tensorflow pipeline that we're actually </v>
<v Speaker 1>just released a couple of days ago.</v>

65
00:03:34.660 --> 00:03:36.130
<v Speaker 1>So this is really,</v>
<v Speaker 1>really new stuff.</v>

66
00:03:37.070 --> 00:03:37.903
<v Speaker 1>Uh,</v>
<v Speaker 1>tomorrow afternoon we'll get together </v>

67
00:03:39.131 --> 00:03:41.830
<v Speaker 1>for one of the most exciting parts of </v>
<v Speaker 1>this class.</v>

68
00:03:42.510 --> 00:03:43.343
<v Speaker 1>Um,</v>
<v Speaker 1>so what will happen is we'll have each </v>

69
00:03:45.221 --> 00:03:47.770
<v Speaker 1>of the sponsors actually come up to the </v>
<v Speaker 1>front of the class here.</v>

70
00:03:48.190 --> 00:03:49.023
<v Speaker 1>We have four sponsors that will present </v>
<v Speaker 1>on each of these four boards and you'll </v>

71
00:03:52.211 --> 00:03:55.360
<v Speaker 1>be given the opportunity to basically </v>
<v Speaker 1>connect with each of them through the,</v>

72
00:03:56.200 --> 00:03:59.020
<v Speaker 1>uh,</v>
<v Speaker 1>through the ways of a recruitment booth.</v>

73
00:03:59.050 --> 00:03:59.883
<v Speaker 1>And basically they're going to be </v>
<v Speaker 1>looking at students that might be </v>

74
00:04:02.171 --> 00:04:05.800
<v Speaker 1>interested in deep learning internships </v>
<v Speaker 1>or employment opportunities.</v>

75
00:04:05.801 --> 00:04:09.370
<v Speaker 1>So this is really an incredible </v>
<v Speaker 1>opportunity for you guys to connect with</v>

76
00:04:09.371 --> 00:04:12.190
<v Speaker 1>these companies in a very,</v>
<v Speaker 1>very,</v>

77
00:04:12.191 --> 00:04:13.024
<v Speaker 1>very direct manner.</v>
<v Speaker 1>So we highly recommend that you take </v>

78
00:04:15.611 --> 00:04:16.444
<v Speaker 1>advantage of that.</v>
<v Speaker 1>There'll be info sessions with pizza </v>

79
00:04:19.211 --> 00:04:20.044
<v Speaker 1>provided on Thursday with one of these </v>
<v Speaker 1>guests lecture with one of these </v>

80
00:04:23.470 --> 00:04:24.303
<v Speaker 1>industry companies and we'll be sending </v>
<v Speaker 1>out more details with that today as </v>

81
00:04:27.281 --> 00:04:28.114
<v Speaker 1>well.</v>

82
00:04:29.770 --> 00:04:30.603
<v Speaker 1>So on Friday we'll continue with the </v>
<v Speaker 1>guest lectures and hear from Lisa and </v>

83
00:04:33.041 --> 00:04:36.220
<v Speaker 1>meany who is the head of IBM research </v>
<v Speaker 1>and Cambridge.</v>

84
00:04:37.090 --> 00:04:39.950
<v Speaker 1>She's actually also the,</v>
<v Speaker 1>uh,</v>

85
00:04:40.120 --> 00:04:40.953
<v Speaker 1>director of the MIT IBM lab.</v>
<v Speaker 1>And this is a lab that was just founded </v>

86
00:04:46.001 --> 00:04:48.970
<v Speaker 1>a couple or actually about a month ago </v>
<v Speaker 1>or two months ago.</v>

87
00:04:50.210 --> 00:04:51.043
<v Speaker 1>We'll be hearing about how IBM is </v>
<v Speaker 1>creating ai systems that are capable of </v>

88
00:04:54.731 --> 00:04:57.250
<v Speaker 1>not only deep learning,</v>
<v Speaker 1>we're going to step past deep learning,</v>

89
00:04:57.880 --> 00:04:58.713
<v Speaker 1>they're capable of or trying to be </v>
<v Speaker 1>capable of learning and recently on a </v>

90
00:05:01.541 --> 00:05:02.374
<v Speaker 1>higher order sense.</v>
<v Speaker 1>And then finally we'll hear from a </v>

91
00:05:05.681 --> 00:05:06.514
<v Speaker 1>principal researcher at ten cent ai lab </v>
<v Speaker 1>about combining computer vision and </v>

92
00:05:10.361 --> 00:05:11.194
<v Speaker 1>social networks.</v>
<v Speaker 1>It's a very interesting topic that we </v>

93
00:05:14.021 --> 00:05:15.820
<v Speaker 1>haven't really touched upon in this </v>
<v Speaker 1>class.</v>

94
00:05:16.500 --> 00:05:17.333
<v Speaker 1>I'm just topic of social networks and </v>
<v Speaker 1>using massive big data collected from </v>

95
00:05:20.660 --> 00:05:25.420
<v Speaker 1>from humans themselves.</v>
<v Speaker 1>And then as I mentioned before,</v>

96
00:05:25.421 --> 00:05:26.254
<v Speaker 1>in the afternoon,</v>
<v Speaker 1>we'll go through and hear about the </v>

97
00:05:27.131 --> 00:05:28.480
<v Speaker 1>final project presentations.</v>

98
00:05:28.480 --> 00:05:32.320
<v Speaker 1>We'll celebrate with some pizza and the </v>
<v Speaker 1>awards that will be given out to the top</v>

99
00:05:32.800 --> 00:05:35.800
<v Speaker 1>projects during those during that </v>
<v Speaker 1>session as well.</v>

100
00:05:37.570 --> 00:05:40.060
<v Speaker 1>So now let's start with the technical </v>
<v Speaker 1>content for this class,</v>

101
00:05:41.350 --> 00:05:42.183
<v Speaker 1>I'd like to start by just kind of </v>
<v Speaker 1>overviewing the type of architectures </v>

102
00:05:46.001 --> 00:05:48.790
<v Speaker 1>that we've talked about so far.</v>
<v Speaker 1>For the most part,</v>

103
00:05:48.791 --> 00:05:52.360
<v Speaker 1>these architectures can be thought of </v>
<v Speaker 1>almost pattern recognition architecture.</v>

104
00:05:52.361 --> 00:05:57.361
<v Speaker 1>So they take us input data and the whole</v>
<v Speaker 1>point of their pipeline,</v>

105
00:05:57.891 --> 00:05:58.724
<v Speaker 1>their internals are performing feature </v>
<v Speaker 1>extraction and and what they're really </v>

106
00:06:03.111 --> 00:06:03.944
<v Speaker 1>doing is taking all of the century data,</v>
<v Speaker 1>trying to figure out what are the </v>

107
00:06:05.751 --> 00:06:06.584
<v Speaker 1>important pieces,</v>
<v Speaker 1>what are the patterns to be learned </v>

108
00:06:08.331 --> 00:06:11.840
<v Speaker 1>within the data such that they can </v>
<v Speaker 1>produce a decision at the output.</v>

109
00:06:12.470 --> 00:06:15.980
<v Speaker 1>We've seen this take many forms,</v>
<v Speaker 1>so the decision could be a prediction,</v>

110
00:06:16.380 --> 00:06:19.850
<v Speaker 1>could be a detection or even an action </v>
<v Speaker 1>like in reinforcement learning setting.</v>

111
00:06:20.780 --> 00:06:25.250
<v Speaker 1>We've even learned how these models can </v>
<v Speaker 1>be viewed in a generative sense to go in</v>

112
00:06:25.251 --> 00:06:28.550
<v Speaker 1>the opposite direction.</v>
<v Speaker 1>It actually generate new synthetic data,</v>

113
00:06:30.950 --> 00:06:31.783
<v Speaker 1>but in general we've been dealing with </v>
<v Speaker 1>algorithms that are really optimized to </v>

114
00:06:34.401 --> 00:06:35.234
<v Speaker 1>do well and only a single task,</v>
<v Speaker 1>but they really failed to think like </v>

115
00:06:38.961 --> 00:06:39.794
<v Speaker 1>humans do,</v>
<v Speaker 1>especially when we consider a higher </v>

116
00:06:41.931 --> 00:06:44.990
<v Speaker 1>order level of intelligence like I </v>
<v Speaker 1>defined on the first day.</v>

117
00:06:48.150 --> 00:06:48.983
<v Speaker 1>To understand this in a lot more detail,</v>
<v Speaker 1>we have to go back to this very famous </v>

118
00:06:51.371 --> 00:06:52.204
<v Speaker 1>theorem,</v>
<v Speaker 1>those dating back almost 30 years from </v>

119
00:06:54.611 --> 00:06:56.860
<v Speaker 1>today,</v>
<v Speaker 1>the steering,</v>

120
00:06:56.861 --> 00:06:58.900
<v Speaker 1>which is known as the universal </v>
<v Speaker 1>approximation.</v>

121
00:06:58.930 --> 00:06:59.763
<v Speaker 1>Durham was one of the most impactful </v>
<v Speaker 1>theorems in neural networks when it </v>

122
00:07:03.551 --> 00:07:06.340
<v Speaker 1>first came out because it had such a </v>
<v Speaker 1>profound.</v>

123
00:07:07.000 --> 00:07:07.833
<v Speaker 1>It such a profound claim.</v>
<v Speaker 1>What it states is that a neural network </v>

124
00:07:11.141 --> 00:07:11.974
<v Speaker 1>with a single hidden layer is sufficient</v>
<v Speaker 1>to approximate any function to any </v>

125
00:07:16.331 --> 00:07:18.910
<v Speaker 1>arbitrary level of accuracy.</v>
<v Speaker 1>Now,</v>

126
00:07:18.911 --> 00:07:21.790
<v Speaker 1>in this class,</v>
<v Speaker 1>we deal with networks that are deep.</v>

127
00:07:21.791 --> 00:07:23.050
<v Speaker 1>They're not single.</v>
<v Speaker 1>Layered,</v>

128
00:07:23.080 --> 00:07:24.760
<v Speaker 1>so they're actually more than a single </v>
<v Speaker 1>layer,</v>

129
00:07:24.970 --> 00:07:28.570
<v Speaker 1>so actually they continue to add more </v>
<v Speaker 1>complexity than the network down,</v>

130
00:07:28.571 --> 00:07:33.571
<v Speaker 1>referring to here,</v>
<v Speaker 1>but this theorem proves that we actually</v>

131
00:07:33.611 --> 00:07:38.611
<v Speaker 1>only need one layer to accomplish or to </v>
<v Speaker 1>approximate any function in the world,</v>

132
00:07:39.130 --> 00:07:39.963
<v Speaker 1>and if you believe that any problem can </v>
<v Speaker 1>actually be reduced to a sets of inputs </v>

133
00:07:43.991 --> 00:07:44.824
<v Speaker 1>and outputs and it's a form of a </v>
<v Speaker 1>function than this theory on shows you </v>

134
00:07:48.720 --> 00:07:49.553
<v Speaker 1>that a neural network with just a single</v>
<v Speaker 1>layer is able to solve any problem in </v>

135
00:07:53.291 --> 00:07:54.124
<v Speaker 1>the world.</v>

136
00:07:54.730 --> 00:07:56.800
<v Speaker 1>Now,</v>
<v Speaker 1>this is an incredibly powerful result,</v>

137
00:07:56.801 --> 00:07:59.950
<v Speaker 1>but if you look closely,</v>
<v Speaker 1>there are a few very important caveats.</v>

138
00:08:00.170 --> 00:08:01.003
<v Speaker 1>I'm not actually telling you how large </v>
<v Speaker 1>that hidden layer has to be to </v>

139
00:08:03.911 --> 00:08:06.100
<v Speaker 1>accomplish this task.</v>
<v Speaker 1>Now,</v>

140
00:08:06.101 --> 00:08:09.820
<v Speaker 1>with the size of your problem,</v>
<v Speaker 1>the hidden layer and the number of units</v>

141
00:08:09.821 --> 00:08:12.190
<v Speaker 1>in that hidden layer,</v>
<v Speaker 1>maybe exponentially large.</v>

142
00:08:12.191 --> 00:08:15.520
<v Speaker 1>I know grow exponentially with the </v>
<v Speaker 1>difficulty of your problem.</v>

143
00:08:16.060 --> 00:08:18.310
<v Speaker 1>This makes training that network very </v>
<v Speaker 1>difficult,</v>

144
00:08:18.311 --> 00:08:21.700
<v Speaker 1>so I never actually told you anything </v>
<v Speaker 1>about how to obtain that network.</v>

145
00:08:21.701 --> 00:08:26.470
<v Speaker 1>I just told you that it existed and </v>
<v Speaker 1>there is a possible network in the realm</v>

146
00:08:26.471 --> 00:08:28.360
<v Speaker 1>of all neural networks that can solve </v>
<v Speaker 1>that problem,</v>

147
00:08:28.361 --> 00:08:29.194
<v Speaker 1>but as we know in practice,</v>
<v Speaker 1>actually training neural networks </v>

148
00:08:32.530 --> 00:08:35.620
<v Speaker 1>because of their noncombat structure is </v>
<v Speaker 1>extremely difficult.</v>

149
00:08:40.550 --> 00:08:45.550
<v Speaker 1>So this term is really a perfect example</v>
<v Speaker 1>of the possible effects of overhyping in</v>

150
00:08:45.711 --> 00:08:46.544
<v Speaker 1>Ai.</v>
<v Speaker 1>So over the history of ai we've had to </v>

151
00:08:49.611 --> 00:08:50.444
<v Speaker 1>ai winters and this theorem was one of </v>
<v Speaker 1>the resurgence after the first day I </v>

152
00:08:57.571 --> 00:08:58.404
<v Speaker 1>went there,</v>
<v Speaker 1>but it also caused a huge false hype in </v>

153
00:09:01.021 --> 00:09:01.854
<v Speaker 1>the power of these neural networks which</v>
<v Speaker 1>ultimately lead to yet another ai </v>

154
00:09:04.501 --> 00:09:05.334
<v Speaker 1>winter.</v>
<v Speaker 1>And I feel like as a class it's very </v>

155
00:09:07.711 --> 00:09:08.544
<v Speaker 1>important to bring this up because right</v>
<v Speaker 1>now we're very much in the state of a </v>

156
00:09:14.431 --> 00:09:19.431
<v Speaker 1>huge amount of overhyping and deep </v>
<v Speaker 1>learning algorithms.</v>

157
00:09:20.070 --> 00:09:20.903
<v Speaker 1>So these algorithms are,</v>
<v Speaker 1>especially in the media being portrayed </v>

158
00:09:23.850 --> 00:09:24.683
<v Speaker 1>that they can accomplish human level </v>
<v Speaker 1>intelligence and human level reasoning </v>

159
00:09:28.950 --> 00:09:29.783
<v Speaker 1>and simply this is not true.</v>
<v Speaker 1>So I think such overhype is extremely </v>

160
00:09:32.641 --> 00:09:33.474
<v Speaker 1>dangerous and resulted well.</v>
<v Speaker 1>We know it resulted in both of the two </v>

161
00:09:37.231 --> 00:09:41.370
<v Speaker 1>past ai winters and I think as a class </v>
<v Speaker 1>that's very important for us to focus on</v>

162
00:09:41.371 --> 00:09:42.204
<v Speaker 1>some of the limitations of these </v>
<v Speaker 1>algorithms so that we don't overhype </v>

163
00:09:45.270 --> 00:09:47.400
<v Speaker 1>them,</v>
<v Speaker 1>but we provide realistic guarantees,</v>

164
00:09:47.401 --> 00:09:52.401
<v Speaker 1>are realistic expectations rather on </v>
<v Speaker 1>what these algorithms can accomplish and</v>

165
00:09:54.450 --> 00:09:57.240
<v Speaker 1>finally going past these limitations.</v>
<v Speaker 1>The last part of this talk will actually</v>

166
00:09:57.241 --> 00:10:00.690
<v Speaker 1>focus on some of the exciting research,</v>
<v Speaker 1>like I mentioned before,</v>

167
00:10:00.900 --> 00:10:05.900
<v Speaker 1>that tries to take a couple of these </v>
<v Speaker 1>limitations and really focus on possible</v>

168
00:10:06.541 --> 00:10:08.970
<v Speaker 1>solutions and possible ways that we can </v>
<v Speaker 1>move past them.</v>

169
00:10:11.100 --> 00:10:11.933
<v Speaker 1>Okay,</v>
<v Speaker 1>so let's start and I think one of the </v>

170
00:10:13.380 --> 00:10:14.213
<v Speaker 1>best examples of a potential danger of </v>
<v Speaker 1>neural networks comes from this paper </v>

171
00:10:18.601 --> 00:10:19.434
<v Speaker 1>from Google deep mind,</v>
<v Speaker 1>a named understanding deep neural </v>

172
00:10:22.411 --> 00:10:23.244
<v Speaker 1>networks requires rethinking </v>
<v Speaker 1>generalization and generalizations was </v>

173
00:10:27.991 --> 00:10:30.510
<v Speaker 1>this topic that we discussed in the </v>
<v Speaker 1>first lecture.</v>

174
00:10:30.511 --> 00:10:31.344
<v Speaker 1>So this is the notion of a gap or a </v>
<v Speaker 1>difference between your training </v>

175
00:10:35.431 --> 00:10:40.431
<v Speaker 1>accuracy and your test accuracy.</v>
<v Speaker 1>If you're able to achieve equal training</v>

176
00:10:40.981 --> 00:10:41.814
<v Speaker 1>and test accuracy,</v>
<v Speaker 1>that means you have essentially no </v>

177
00:10:43.111 --> 00:10:43.944
<v Speaker 1>generalization gap.</v>
<v Speaker 1>You're able to generalize perfectly to </v>

178
00:10:47.460 --> 00:10:48.293
<v Speaker 1>to your test data set,</v>
<v Speaker 1>but if there's a huge disparity between </v>

179
00:10:50.851 --> 00:10:51.684
<v Speaker 1>these two datasets in your model is </v>
<v Speaker 1>performing much better on your training </v>

180
00:10:54.691 --> 00:10:55.524
<v Speaker 1>data set than your test data.</v>
<v Speaker 1>So this means that you're not able to </v>

181
00:10:57.571 --> 00:11:02.571
<v Speaker 1>actually generalize to brand new images.</v>
<v Speaker 1>You're only just memorizing the training</v>

182
00:11:03.061 --> 00:11:03.894
<v Speaker 1>examples.</v>
<v Speaker 1>And what this paper did was they </v>

183
00:11:06.990 --> 00:11:11.130
<v Speaker 1>performed the following experiment,</v>
<v Speaker 1>so they took images from image net so he</v>

184
00:11:11.131 --> 00:11:13.410
<v Speaker 1>can see four examples of these images </v>
<v Speaker 1>here.</v>

185
00:11:13.590 --> 00:11:14.423
<v Speaker 1>And what they did was they rolled a case</v>
<v Speaker 1>I did die where k is the number of all </v>

186
00:11:19.321 --> 00:11:20.154
<v Speaker 1>possible labels in that data set and </v>
<v Speaker 1>this allowed them to randomly assigned </v>

187
00:11:25.621 --> 00:11:27.690
<v Speaker 1>brand new labels to each of these </v>
<v Speaker 1>images.</v>

188
00:11:28.110 --> 00:11:28.943
<v Speaker 1>So what used to be a dog,</v>
<v Speaker 1>they call it now a banana and what they </v>

189
00:11:32.760 --> 00:11:33.593
<v Speaker 1>were used to be,</v>
<v Speaker 1>that banana is now called the dog and </v>

190
00:11:35.341 --> 00:11:37.860
<v Speaker 1>what it used to be called that second </v>
<v Speaker 1>dog is now a tree.</v>

191
00:11:38.250 --> 00:11:39.083
<v Speaker 1>So note that the two dogs have actually </v>
<v Speaker 1>been transformed into two separate </v>

192
00:11:42.001 --> 00:11:42.834
<v Speaker 1>things.</v>
<v Speaker 1>So things that used to be in the same </v>

193
00:11:43.561 --> 00:11:44.394
<v Speaker 1>class are now in completely disjoined </v>
<v Speaker 1>classes and things that were in </v>

194
00:11:46.981 --> 00:11:49.290
<v Speaker 1>destroying classes may be now in the </v>
<v Speaker 1>same class.</v>

195
00:11:49.680 --> 00:11:53.350
<v Speaker 1>So basically we're completely </v>
<v Speaker 1>randomizing our labels entirely.</v>

196
00:11:54.040 --> 00:11:54.873
<v Speaker 1>And what they did was they tried to see </v>
<v Speaker 1>if a neural network could still learn </v>

197
00:11:57.910 --> 00:12:01.690
<v Speaker 1>random labels and here's what they </v>
<v Speaker 1>found.</v>

198
00:12:03.430 --> 00:12:07.510
<v Speaker 1>So as you'd expect when they tested this</v>
<v Speaker 1>neural network with random labels,</v>

199
00:12:07.870 --> 00:12:10.420
<v Speaker 1>as they increase the randomness on the x</v>
<v Speaker 1>axis,</v>

200
00:12:11.590 --> 00:12:12.423
<v Speaker 1>so going from left to right,</v>
<v Speaker 1>this is the original labels before </v>

201
00:12:14.500 --> 00:12:15.333
<v Speaker 1>randomizing anything,</v>
<v Speaker 1>and then they started randomizing their </v>

202
00:12:17.680 --> 00:12:18.513
<v Speaker 1>test accuracy gradually decreased.</v>
<v Speaker 1>And this is as expected because we're </v>

203
00:12:22.030 --> 00:12:25.480
<v Speaker 1>trying to learn something that has </v>
<v Speaker 1>absolutely no pattern in it.</v>

204
00:12:28.000 --> 00:12:28.833
<v Speaker 1>But then what's really interesting is </v>
<v Speaker 1>that then they looked at the training </v>

205
00:12:30.461 --> 00:12:35.410
<v Speaker 1>accuracy and what they found was that </v>
<v Speaker 1>the neural network was able to,</v>

206
00:12:35.740 --> 00:12:39.670
<v Speaker 1>with 100 percent accuracy,</v>
<v Speaker 1>get the training said correct.</v>

207
00:12:40.360 --> 00:12:41.193
<v Speaker 1>Every single time,</v>
<v Speaker 1>no matter how many random labels they </v>

208
00:12:44.441 --> 00:12:45.274
<v Speaker 1>introduced,</v>
<v Speaker 1>the training set would always be </v>

209
00:12:47.321 --> 00:12:48.154
<v Speaker 1>shattered or another words.</v>
<v Speaker 1>Every single example in the training </v>

210
00:12:50.831 --> 00:12:51.664
<v Speaker 1>side could be perfectly classified.</v>
<v Speaker 1>So this means that modern deep neural </v>

211
00:12:57.461 --> 00:13:02.461
<v Speaker 1>networks actually have the capacity to </v>
<v Speaker 1>brute force memorize massive data sets,</v>

212
00:13:03.190 --> 00:13:07.240
<v Speaker 1>even on the size of image net with </v>
<v Speaker 1>completely random labels.</v>

213
00:13:07.241 --> 00:13:11.110
<v Speaker 1>They're able to memorize every single </v>
<v Speaker 1>example in that data set.</v>

214
00:13:11.890 --> 00:13:12.723
<v Speaker 1>And this is a very powerful result is it</v>
<v Speaker 1>drives home this point that neural </v>

215
00:13:16.331 --> 00:13:19.930
<v Speaker 1>networks are really,</v>
<v Speaker 1>really excellent function approximators.</v>

216
00:13:20.650 --> 00:13:21.483
<v Speaker 1>So this also connects back to the </v>
<v Speaker 1>universal approximation theorem that I </v>

217
00:13:24.310 --> 00:13:25.143
<v Speaker 1>talked about before,</v>
<v Speaker 1>but they're really good approximators </v>

218
00:13:27.941 --> 00:13:29.710
<v Speaker 1>for just the single function like I </v>
<v Speaker 1>said,</v>

219
00:13:30.610 --> 00:13:31.443
<v Speaker 1>which means that we can always create </v>
<v Speaker 1>this maximum likelihood estimate of our </v>

220
00:13:33.611 --> 00:13:34.444
<v Speaker 1>data using a neural network such that if</v>
<v Speaker 1>we were given a new data points like </v>

221
00:13:38.651 --> 00:13:39.484
<v Speaker 1>this purple one on the bottom,</v>
<v Speaker 1>it's easy for us to compute is estimate </v>

222
00:13:43.070 --> 00:13:43.903
<v Speaker 1>probability estimate output just by </v>
<v Speaker 1>intercepting it with that maximum </v>

223
00:13:47.591 --> 00:13:48.424
<v Speaker 1>likelihood estimate,</v>
<v Speaker 1>but that's only if I'm looking at a </v>

224
00:13:51.431 --> 00:13:54.370
<v Speaker 1>place that we have sufficient training </v>
<v Speaker 1>data already.</v>

225
00:13:54.400 --> 00:13:55.233
<v Speaker 1>What if I extend this x axes and look at</v>
<v Speaker 1>what the neural network predicts beyond </v>

226
00:13:58.721 --> 00:14:02.200
<v Speaker 1>that in these locations.</v>
<v Speaker 1>These are actually the locations that we</v>

227
00:14:02.201 --> 00:14:03.730
<v Speaker 1>care about most,</v>
<v Speaker 1>right?</v>

228
00:14:03.731 --> 00:14:04.564
<v Speaker 1>These are the edge cases and driving.</v>
<v Speaker 1>These are the cases that we don't have </v>

229
00:14:07.901 --> 00:14:11.620
<v Speaker 1>mit,</v>
<v Speaker 1>many or a lot of data that was collected</v>

230
00:14:12.100 --> 00:14:15.040
<v Speaker 1>and these are usually the cases were </v>
<v Speaker 1>safety.</v>

231
00:14:15.041 --> 00:14:20.041
<v Speaker 1>Critical applications are like are most </v>
<v Speaker 1>important,</v>

232
00:14:20.590 --> 00:14:21.423
<v Speaker 1>right?</v>
<v Speaker 1>So we need to be able to make sure when </v>

233
00:14:22.601 --> 00:14:25.030
<v Speaker 1>we sampled in neural network from these </v>
<v Speaker 1>locations,</v>

234
00:14:26.050 --> 00:14:28.120
<v Speaker 1>are we able to know that the neural </v>
<v Speaker 1>network,</v>

235
00:14:28.180 --> 00:14:29.013
<v Speaker 1>are we able to get feedback from the </v>
<v Speaker 1>neural network that it actually doesn't </v>

236
00:14:30.851 --> 00:14:31.870
<v Speaker 1>know what it's talking about.</v>

237
00:14:34.600 --> 00:14:35.433
<v Speaker 1>So this notion leads nicely into the </v>
<v Speaker 1>idea of what is known as advertar </v>

238
00:14:38.590 --> 00:14:43.590
<v Speaker 1>adversarial attacks where I can give you</v>
<v Speaker 1>can give and neural network to images on</v>

239
00:14:44.471 --> 00:14:45.304
<v Speaker 1>the left like this one,</v>
<v Speaker 1>and on the right and adversarial image </v>

240
00:14:48.760 --> 00:14:52.260
<v Speaker 1>that to a human look exactly the same,</v>
<v Speaker 1>but to the network,</v>

241
00:14:52.261 --> 00:14:56.000
<v Speaker 1>they're incorrectly classified 100 </v>
<v Speaker 1>percent of the time.</v>

242
00:14:56.540 --> 00:14:59.910
<v Speaker 1>So the image on the right shows an </v>
<v Speaker 1>example of a temple which when I feed to</v>

243
00:14:59.930 --> 00:15:02.510
<v Speaker 1>a neural network and gives me back label</v>
<v Speaker 1>of a temple,</v>

244
00:15:03.830 --> 00:15:04.663
<v Speaker 1>but when I apply some adversarial noise,</v>
<v Speaker 1>it classifies this image incorrectly as </v>

245
00:15:09.561 --> 00:15:14.010
<v Speaker 1>an ostrich.</v>
<v Speaker 1>So for this,</v>

246
00:15:14.011 --> 00:15:16.590
<v Speaker 1>I'd like to focus on this piece </v>
<v Speaker 1>specifically,</v>

247
00:15:16.591 --> 00:15:18.590
<v Speaker 1>so to understand the limitations of </v>
<v Speaker 1>neural networks,</v>

248
00:15:18.610 --> 00:15:19.443
<v Speaker 1>the first thing we have to do is </v>
<v Speaker 1>actually understand how we can break </v>

249
00:15:21.541 --> 00:15:22.374
<v Speaker 1>them,</v>
<v Speaker 1>and this perturbed noise is actually </v>

250
00:15:24.961 --> 00:15:25.794
<v Speaker 1>very</v>

251
00:15:26.660 --> 00:15:29.540
<v Speaker 1>intelligently designed,</v>
<v Speaker 1>so this is not just random noise,</v>

252
00:15:29.900 --> 00:15:30.733
<v Speaker 1>but we're actually modifying pixels in </v>
<v Speaker 1>specific locations to maximally change </v>

253
00:15:35.240 --> 00:15:36.073
<v Speaker 1>or mess up or output prediction.</v>
<v Speaker 1>So we want to modify the pixels in such </v>

254
00:15:39.411 --> 00:15:43.310
<v Speaker 1>a way that we're decreasing our accuracy</v>
<v Speaker 1>as much as possible.</v>

255
00:15:43.790 --> 00:15:46.400
<v Speaker 1>And if you remember back to how we </v>
<v Speaker 1>actually train our neural networks,</v>

256
00:15:46.401 --> 00:15:50.210
<v Speaker 1>this might sound very similar.</v>
<v Speaker 1>So if you're a member training,</v>

257
00:15:50.211 --> 00:15:53.720
<v Speaker 1>a neural network is simply optimizing </v>
<v Speaker 1>over our weights feta.</v>

258
00:15:54.560 --> 00:15:55.393
<v Speaker 1>So to do this,</v>
<v Speaker 1>we simply compute the gradients of Feta </v>

259
00:15:57.111 --> 00:15:57.944
<v Speaker 1>with sorry,</v>
<v Speaker 1>the great into our last function with </v>

260
00:15:59.600 --> 00:16:03.380
<v Speaker 1>respect to theater,</v>
<v Speaker 1>and we simply perturb our weights in the</v>

261
00:16:03.381 --> 00:16:05.660
<v Speaker 1>direction that will minimize our loss.</v>

262
00:16:07.600 --> 00:16:10.870
<v Speaker 1>Now also remember that when we do this,</v>
<v Speaker 1>we're perturbing theater,</v>

263
00:16:10.920 --> 00:16:14.080
<v Speaker 1>but we're fixing or x in our y.</v>
<v Speaker 1>This is our training label.</v>

264
00:16:14.120 --> 00:16:16.570
<v Speaker 1>Our training data and returning labels.</v>
<v Speaker 1>Now,</v>

265
00:16:16.571 --> 00:16:20.860
<v Speaker 1>for adversarial examples were just </v>
<v Speaker 1>shuffling the variables a little bit,</v>

266
00:16:20.861 --> 00:16:23.710
<v Speaker 1>so now we want to optimize over the </v>
<v Speaker 1>image itself,</v>

267
00:16:23.740 --> 00:16:24.573
<v Speaker 1>not the wage,</v>
<v Speaker 1>so we fixed the weights and the target </v>

268
00:16:27.611 --> 00:16:31.480
<v Speaker 1>label itself and we optimize over the </v>
<v Speaker 1>image x.</v>

269
00:16:31.690 --> 00:16:32.523
<v Speaker 1>We want to make small changes to that </v>
<v Speaker 1>image x such that we increased our loss </v>

270
00:16:36.040 --> 00:16:39.010
<v Speaker 1>as much as possible and we want to go in</v>
<v Speaker 1>the opposite direction of training now,</v>

271
00:16:40.680 --> 00:16:41.513
<v Speaker 1>and these are just some of the </v>
<v Speaker 1>limitations of neural networks and for </v>

272
00:16:44.891 --> 00:16:47.900
<v Speaker 1>the remainder of this class,</v>
<v Speaker 1>I want to focus on some of the really,</v>

273
00:16:47.910 --> 00:16:51.580
<v Speaker 1>really exciting new frontiers of deep </v>
<v Speaker 1>learning that focus on just two of these</v>

274
00:16:52.120 --> 00:16:52.953
<v Speaker 1>specifically.</v>
<v Speaker 1>I want to focus on the notion of </v>

275
00:16:54.491 --> 00:16:55.324
<v Speaker 1>understanding uncertainty and deep </v>
<v Speaker 1>neural networks and understanding when </v>

276
00:16:58.781 --> 00:17:01.780
<v Speaker 1>our model doesn't know what it was </v>
<v Speaker 1>trained to know.</v>

277
00:17:01.990 --> 00:17:02.823
<v Speaker 1>Maybe because it wasn't.</v>
<v Speaker 1>It didn't receive enough training data </v>

278
00:17:05.110 --> 00:17:09.120
<v Speaker 1>to support that hypothesis.</v>
<v Speaker 1>And furthermore,</v>

279
00:17:09.121 --> 00:17:13.230
<v Speaker 1>I wanted to focus on this notion of </v>
<v Speaker 1>learning how to learn models.</v>

280
00:17:13.380 --> 00:17:17.760
<v Speaker 1>Because optimization of neural networks </v>
<v Speaker 1>is extremely difficult.</v>

281
00:17:17.850 --> 00:17:21.570
<v Speaker 1>It's extremely limited and its current </v>
<v Speaker 1>nature because they're optimized just to</v>

282
00:17:21.571 --> 00:17:22.404
<v Speaker 1>do a single test.</v>
<v Speaker 1>So what we really want to do is create </v>

283
00:17:24.001 --> 00:17:28.290
<v Speaker 1>neural networks that are capable of </v>
<v Speaker 1>performing one task,</v>

284
00:17:28.470 --> 00:17:33.390
<v Speaker 1>but a set of sequences of tasks that are</v>
<v Speaker 1>maybe dependent in some fashion.</v>

285
00:17:35.400 --> 00:17:38.640
<v Speaker 1>So let's start with this notion of </v>
<v Speaker 1>uncertainty in deep neural networks.</v>

286
00:17:38.641 --> 00:17:39.474
<v Speaker 1>And to do that,</v>
<v Speaker 1>I'd like to introduce this field called </v>

287
00:17:43.591 --> 00:17:44.520
<v Speaker 1>Bayesian deep learning.</v>

288
00:17:46.840 --> 00:17:48.760
<v Speaker 1>Nope.</v>
<v Speaker 1>To understand beige and deep learning.</v>

289
00:17:48.761 --> 00:17:52.440
<v Speaker 1>Let's understand why we even care about </v>
<v Speaker 1>uncertainty.</v>

290
00:17:52.500 --> 00:17:57.240
<v Speaker 1>So this should be pretty obvious.</v>
<v Speaker 1>Let's suppose we're given a network that</v>

291
00:17:57.241 --> 00:18:01.590
<v Speaker 1>was trained to distinguish between cats </v>
<v Speaker 1>and dogs at input.</v>

292
00:18:01.591 --> 00:18:05.400
<v Speaker 1>We're given a lot of testing or training</v>
<v Speaker 1>images of cats and dogs,</v>

293
00:18:05.670 --> 00:18:09.090
<v Speaker 1>and it's simply at the output we're </v>
<v Speaker 1>producing an output probability of being</v>

294
00:18:09.091 --> 00:18:10.260
<v Speaker 1>a cat or a dog.</v>

295
00:18:12.030 --> 00:18:12.863
<v Speaker 1>Now,</v>
<v Speaker 1>this model is trained on either on only </v>

296
00:18:14.281 --> 00:18:16.500
<v Speaker 1>cats or dogs.</v>
<v Speaker 1>So if I showed another cat,</v>

297
00:18:16.770 --> 00:18:19.200
<v Speaker 1>it should be very confident in its </v>
<v Speaker 1>output,</v>

298
00:18:19.800 --> 00:18:20.633
<v Speaker 1>but let's suppose I give it a horse and </v>
<v Speaker 1>I forced that network because it's the </v>

299
00:18:24.721 --> 00:18:25.554
<v Speaker 1>same network to produce an output being </v>
<v Speaker 1>a probability of a cat or a probability </v>

300
00:18:28.741 --> 00:18:29.574
<v Speaker 1>of a dog.</v>
<v Speaker 1>Now we know that these probabilities </v>

301
00:18:32.881 --> 00:18:33.714
<v Speaker 1>have to add up to one because that's </v>
<v Speaker 1>actually the definition that we </v>

302
00:18:35.341 --> 00:18:39.930
<v Speaker 1>constrain our network to follow.</v>
<v Speaker 1>So that means by definition one of these</v>

303
00:18:39.931 --> 00:18:40.764
<v Speaker 1>categories,</v>
<v Speaker 1>so the network has to produce one of </v>

304
00:18:42.391 --> 00:18:43.224
<v Speaker 1>these categories,</v>
<v Speaker 1>so the notion of probability and the </v>

305
00:18:46.081 --> 00:18:48.210
<v Speaker 1>notion of uncertainty are actually very </v>
<v Speaker 1>different,</v>

306
00:18:48.690 --> 00:18:52.230
<v Speaker 1>but a lot of deep learning practitioners</v>
<v Speaker 1>optin mixed these two ideas,</v>

307
00:18:52.470 --> 00:18:57.060
<v Speaker 1>so uncertainty is not probability.</v>
<v Speaker 1>Neural networks or detect are trained to</v>

308
00:18:57.150 --> 00:19:01.290
<v Speaker 1>detect or produce probabilities at three</v>
<v Speaker 1>output at their output,</v>

309
00:19:01.560 --> 00:19:04.770
<v Speaker 1>but they're not trained to produce </v>
<v Speaker 1>uncertainty values.</v>

310
00:19:06.050 --> 00:19:08.600
<v Speaker 1>So if we put this horse into the same </v>
<v Speaker 1>network,</v>

311
00:19:08.870 --> 00:19:12.380
<v Speaker 1>we'll get a set of uncertain of </v>
<v Speaker 1>probability values that add up to one.</v>

312
00:19:13.580 --> 00:19:14.413
<v Speaker 1>But what we really want to see is we </v>
<v Speaker 1>want to see a very low uncertainty in </v>

313
00:19:17.301 --> 00:19:20.330
<v Speaker 1>that very low certainty in that </v>
<v Speaker 1>prediction.</v>

314
00:19:22.290 --> 00:19:23.123
<v Speaker 1>And one possible way to accomplish this </v>
<v Speaker 1>in deep learning is through the eyes of </v>

315
00:19:25.760 --> 00:19:28.200
<v Speaker 1>Bayesian deep learning.</v>
<v Speaker 1>And to understand this,</v>

316
00:19:28.201 --> 00:19:30.780
<v Speaker 1>let's briefly start by formulating our </v>
<v Speaker 1>problem again.</v>

317
00:19:31.920 --> 00:19:36.060
<v Speaker 1>So first let's go through like the </v>
<v Speaker 1>variables,</v>

318
00:19:36.061 --> 00:19:36.894
<v Speaker 1>right?</v>
<v Speaker 1>So we want to approximate this variable </v>

319
00:19:39.721 --> 00:19:40.554
<v Speaker 1>y or output y given some raw data x.</v>
<v Speaker 1>and really what we mean by training is </v>

320
00:19:44.850 --> 00:19:49.850
<v Speaker 1>we want to find this functional mapping </v>
<v Speaker 1>f parameterized by our weights data such</v>

321
00:19:50.070 --> 00:19:54.660
<v Speaker 1>that we minimize the loss between our </v>
<v Speaker 1>predict examples and our true outputs.</v>

322
00:19:54.690 --> 00:19:55.523
<v Speaker 1>Why?</v>
<v Speaker 1>So based on neural networks take a </v>

323
00:19:58.831 --> 00:20:01.950
<v Speaker 1>different approach to solve this </v>
<v Speaker 1>problem,</v>

324
00:20:02.340 --> 00:20:05.970
<v Speaker 1>they aim to learn it postier over our </v>
<v Speaker 1>weights,</v>

325
00:20:06.060 --> 00:20:08.670
<v Speaker 1>given the data.</v>
<v Speaker 1>So they attempt to say,</v>

326
00:20:08.880 --> 00:20:09.713
<v Speaker 1>what is the probability that I see this </v>
<v Speaker 1>model with these weights given the data </v>

327
00:20:13.681 --> 00:20:14.514
<v Speaker 1>in my training set.</v>
<v Speaker 1>Now it's called Bayesian deep learning </v>

328
00:20:16.831 --> 00:20:21.270
<v Speaker 1>because we can simply have a rewrite </v>
<v Speaker 1>this posterior using bayes rule.</v>

329
00:20:25.090 --> 00:20:25.923
<v Speaker 1>However,</v>
<v Speaker 1>in practice it's rarely possible to </v>

330
00:20:27.581 --> 00:20:32.080
<v Speaker 1>actually compute this compute,</v>
<v Speaker 1>this bayes rule,</v>

331
00:20:32.140 --> 00:20:36.280
<v Speaker 1>updates,</v>
<v Speaker 1>and it just turns out to be intractable.</v>

332
00:20:36.340 --> 00:20:37.173
<v Speaker 1>So instead we have to find out ways to </v>
<v Speaker 1>actually approximate it through </v>

333
00:20:40.511 --> 00:20:41.344
<v Speaker 1>sampling.</v>
<v Speaker 1>So one way that we'll talk about today </v>

334
00:20:43.510 --> 00:20:47.140
<v Speaker 1>is a very simple notion that we've </v>
<v Speaker 1>actually already seen in the first.</v>

335
00:20:47.950 --> 00:20:50.230
<v Speaker 1>And it goes back to this idea of using </v>
<v Speaker 1>dropout.</v>

336
00:20:50.860 --> 00:20:51.693
<v Speaker 1>So if you're a member,</v>
<v Speaker 1>what dropout was dropped out is this </v>

337
00:20:53.741 --> 00:20:54.574
<v Speaker 1>notion of randomly killing off a certain</v>
<v Speaker 1>percentage of neurons in each of the </v>

338
00:21:00.220 --> 00:21:03.310
<v Speaker 1>hidden layers.</v>
<v Speaker 1>Now I'm going to tell you not how to use</v>

339
00:21:03.311 --> 00:21:04.144
<v Speaker 1>it as a regular advisor,</v>
<v Speaker 1>but how to use dropbox as a way to </v>

340
00:21:06.731 --> 00:21:10.060
<v Speaker 1>produce reliable uncertainty measures </v>
<v Speaker 1>for your neural network.</v>

341
00:21:11.290 --> 00:21:15.940
<v Speaker 1>So to do this,</v>
<v Speaker 1>we have to think of capital t stochastic</v>

342
00:21:15.941 --> 00:21:16.774
<v Speaker 1>passes through our network where each </v>
<v Speaker 1>stochastic pass performance one </v>

343
00:21:19.121 --> 00:21:20.290
<v Speaker 1>iteration of dropouts.</v>

344
00:21:20.980 --> 00:21:22.230
<v Speaker 1>Each time you iterate,</v>
<v Speaker 1>dropout,</v>

345
00:21:22.240 --> 00:21:23.073
<v Speaker 1>you're basically just applying a </v>
<v Speaker 1>Bernoulli mask of ones and Zeros over </v>

346
00:21:26.441 --> 00:21:29.110
<v Speaker 1>each of your weights.</v>
<v Speaker 1>So going from the left to the right,</v>

347
00:21:29.111 --> 00:21:32.320
<v Speaker 1>you can see our weights,</v>
<v Speaker 1>which is like this matrix here.</v>

348
00:21:32.380 --> 00:21:33.213
<v Speaker 1>Different colors represent the intensity</v>
<v Speaker 1>of that weight and we element wise </v>

349
00:21:36.851 --> 00:21:39.310
<v Speaker 1>multiply those weights by our Bernoulli </v>
<v Speaker 1>mask with,</v>

350
00:21:39.610 --> 00:21:42.340
<v Speaker 1>which is just either a one or a zero in </v>
<v Speaker 1>every location.</v>

351
00:21:43.810 --> 00:21:44.643
<v Speaker 1>The output is a new set of weights with </v>
<v Speaker 1>certain of those dropped out with </v>

352
00:21:48.461 --> 00:21:49.294
<v Speaker 1>certain aspects of those dropped out.</v>
<v Speaker 1>Now all we have to do is compute this t </v>

353
00:21:56.411 --> 00:21:57.244
<v Speaker 1>times capital t times.</v>
<v Speaker 1>We'll get a feta t weights and we use </v>

354
00:22:01.191 --> 00:22:06.191
<v Speaker 1>those stated t different models to </v>
<v Speaker 1>actually produce an empirical average of</v>

355
00:22:07.271 --> 00:22:12.190
<v Speaker 1>our output class given the data.</v>
<v Speaker 1>So that's this guy.</v>

356
00:22:13.240 --> 00:22:14.073
<v Speaker 1>Well,</v>
<v Speaker 1>we're actually really interested in why </v>

357
00:22:14.981 --> 00:22:17.740
<v Speaker 1>I brought this topic up was the notion </v>
<v Speaker 1>of uncertainty though,</v>

358
00:22:18.280 --> 00:22:23.110
<v Speaker 1>and that's the variance of our </v>
<v Speaker 1>predictions right there.</v>

359
00:22:24.220 --> 00:22:25.053
<v Speaker 1>So this is a very powerful idea.</v>
<v Speaker 1>All it means is that we can attain </v>

360
00:22:29.710 --> 00:22:34.050
<v Speaker 1>reliable model uncertainty estimates </v>
<v Speaker 1>simply by trading our network during run</v>

361
00:22:34.051 --> 00:22:34.884
<v Speaker 1>time with dropout.</v>
<v Speaker 1>And then instead of estimating or </v>

362
00:22:37.750 --> 00:22:41.200
<v Speaker 1>classifying just a single pass through </v>
<v Speaker 1>this network at test time,</v>

363
00:22:41.440 --> 00:22:42.273
<v Speaker 1>we'd classify capital t two iterations </v>
<v Speaker 1>of this network and then use that to </v>

364
00:22:46.661 --> 00:22:50.410
<v Speaker 1>compute a variance over these outputs.</v>
<v Speaker 1>And that variance gives us an estimation</v>

365
00:22:50.440 --> 00:22:51.280
<v Speaker 1>of our uncertainty.</v>

366
00:22:53.500 --> 00:22:55.930
<v Speaker 1>Not to give you an example of how this </v>
<v Speaker 1>looks in practice.</v>

367
00:22:56.080 --> 00:22:57.280
<v Speaker 1>Let's look at this,</v>
<v Speaker 1>uh,</v>

368
00:22:57.880 --> 00:22:58.713
<v Speaker 1>this network that was trained to take as</v>
<v Speaker 1>input images of the real world and </v>

369
00:23:04.090 --> 00:23:07.540
<v Speaker 1>outputs predicted depth maps.</v>
<v Speaker 1>Oh,</v>

370
00:23:07.570 --> 00:23:11.290
<v Speaker 1>it looks like my text was a little off.</v>
<v Speaker 1>That's okay.</v>

371
00:23:12.910 --> 00:23:15.760
<v Speaker 1>So at the output we have a predicted </v>
<v Speaker 1>death,</v>

372
00:23:15.770 --> 00:23:16.603
<v Speaker 1>not for each pixel to network is </v>
<v Speaker 1>predicting the depth in the real world </v>

373
00:23:21.070 --> 00:23:23.740
<v Speaker 1>of that Pixel.</v>
<v Speaker 1>Now,</v>

374
00:23:23.741 --> 00:23:28.270
<v Speaker 1>when we run Bayesian model uncertainty </v>
<v Speaker 1>using the exact same dropout method that</v>

375
00:23:28.271 --> 00:23:32.850
<v Speaker 1>I just described,</v>
<v Speaker 1>we can see that the end,</v>

376
00:23:32.890 --> 00:23:36.190
<v Speaker 1>the model is most uncertain in some very</v>
<v Speaker 1>interesting locations.</v>

377
00:23:36.550 --> 00:23:37.383
<v Speaker 1>So first of all,</v>
<v Speaker 1>pay attention to that location right </v>

378
00:23:38.651 --> 00:23:41.360
<v Speaker 1>there.</v>
<v Speaker 1>And if you look where,</v>

379
00:23:41.410 --> 00:23:42.243
<v Speaker 1>where is that location exactly?</v>
<v Speaker 1>It's just the window sill of this car </v>

380
00:23:46.270 --> 00:23:47.103
<v Speaker 1>and in computer vision windows and </v>
<v Speaker 1>specular objects are very difficult to </v>

381
00:23:53.530 --> 00:23:57.710
<v Speaker 1>to basically model because we can't </v>
<v Speaker 1>actually tell their surface reliably,</v>

382
00:23:57.711 --> 00:23:57.950
<v Speaker 1>right?</v>

383
00:23:57.950 --> 00:24:00.470
<v Speaker 1>So we're seeing the light from actually </v>
<v Speaker 1>the sky.</v>

384
00:24:00.620 --> 00:24:03.380
<v Speaker 1>We're not actually seeing the surface of</v>
<v Speaker 1>the window in that location,</v>

385
00:24:03.620 --> 00:24:07.730
<v Speaker 1>so it can be very difficult for us to </v>
<v Speaker 1>model the depth in that place.</v>

386
00:24:08.840 --> 00:24:09.673
<v Speaker 1>Additionally,</v>
<v Speaker 1>we see that the model is very uncertain </v>

387
00:24:11.600 --> 00:24:12.433
<v Speaker 1>on the edges of the cars because these </v>
<v Speaker 1>are places where the depth is changing </v>

388
00:24:17.390 --> 00:24:18.223
<v Speaker 1>very rapidly,</v>
<v Speaker 1>so the prediction may be least accurate </v>

389
00:24:20.181 --> 00:24:24.470
<v Speaker 1>and these locations.</v>
<v Speaker 1>So having reliable uncertainty estimates</v>

390
00:24:24.710 --> 00:24:25.543
<v Speaker 1>can be an extremely powerful way to </v>
<v Speaker 1>actually interpret deep learning models </v>

391
00:24:29.181 --> 00:24:34.181
<v Speaker 1>and also provide human practitioners,</v>
<v Speaker 1>especially in the realm of safe ai,</v>

392
00:24:34.970 --> 00:24:35.803
<v Speaker 1>is the way to interpret the results and </v>
<v Speaker 1>also trust our results with a certain </v>

393
00:24:42.441 --> 00:24:43.274
<v Speaker 1>amount or a certain gram of salt.</v>
<v Speaker 1>So for the next and final part of this </v>

394
00:24:49.021 --> 00:24:49.854
<v Speaker 1>talk,</v>
<v Speaker 1>I'd like to address this notion of </v>

395
00:24:51.750 --> 00:24:54.900
<v Speaker 1>learning to learn.</v>
<v Speaker 1>So this is a really cool sounding topic.</v>

396
00:24:56.810 --> 00:25:01.810
<v Speaker 1>It aims to basically learn not just a </v>
<v Speaker 1>single model that's optimized to perform</v>

397
00:25:02.071 --> 00:25:02.904
<v Speaker 1>a single task like we've learned </v>
<v Speaker 1>basically in all of our lectures </v>

398
00:25:06.360 --> 00:25:07.193
<v Speaker 1>previous to this one,</v>
<v Speaker 1>but it learns how to learn which model </v>

399
00:25:10.530 --> 00:25:12.330
<v Speaker 1>to use to train that task.</v>

400
00:25:14.380 --> 00:25:16.600
<v Speaker 1>So first,</v>
<v Speaker 1>let's understand why we might want to do</v>

401
00:25:16.601 --> 00:25:19.690
<v Speaker 1>something like that.</v>
<v Speaker 1>I hope this is pretty obvious to by now,</v>

402
00:25:20.050 --> 00:25:20.883
<v Speaker 1>but humans are not built in a way where </v>
<v Speaker 1>we're learning where we're executing </v>

403
00:25:25.811 --> 00:25:28.510
<v Speaker 1>just a single task at a time were </v>
<v Speaker 1>executing many,</v>

404
00:25:28.511 --> 00:25:29.344
<v Speaker 1>many,</v>
<v Speaker 1>many different tasks and all of these </v>

405
00:25:32.171 --> 00:25:33.004
<v Speaker 1>tasks are constantly interacting with </v>
<v Speaker 1>each other in ways that learning one </v>

406
00:25:37.181 --> 00:25:40.250
<v Speaker 1>task can actually aid speed up or deter </v>
<v Speaker 1>the learning.</v>

407
00:25:40.251 --> 00:25:45.100
<v Speaker 1>You have another task at any given time,</v>
<v Speaker 1>modern deep neural network architectures</v>

408
00:25:45.101 --> 00:25:45.934
<v Speaker 1>and not like this.</v>
<v Speaker 1>They're optimized for a single task and </v>

409
00:25:47.381 --> 00:25:48.214
<v Speaker 1>this goes back to the very beginning of </v>
<v Speaker 1>this talk where we talked about the </v>

410
00:25:49.961 --> 00:25:54.961
<v Speaker 1>universal approximator and as these </v>
<v Speaker 1>models become more and more complex,</v>

411
00:25:56.150 --> 00:25:56.983
<v Speaker 1>what ends up happening is that you have </v>
<v Speaker 1>to have more and more expert knowledge </v>

412
00:26:00.740 --> 00:26:01.573
<v Speaker 1>to actually build and deploy these </v>
<v Speaker 1>models in practice and that's exactly </v>

413
00:26:03.981 --> 00:26:04.814
<v Speaker 1>why all of you are here.</v>
<v Speaker 1>You're here to basically get that </v>

414
00:26:06.501 --> 00:26:10.730
<v Speaker 1>experience such that you yourselves can </v>
<v Speaker 1>build these deep learning models.</v>

415
00:26:13.350 --> 00:26:14.183
<v Speaker 1>So what we want is actually an automated</v>
<v Speaker 1>machine learning framework where we can </v>

416
00:26:18.571 --> 00:26:21.750
<v Speaker 1>actually learn to learn and this </v>
<v Speaker 1>basically means we want to build a model</v>

417
00:26:21.751 --> 00:26:26.751
<v Speaker 1>that learns which model to use given a </v>
<v Speaker 1>problem definition.</v>

418
00:26:28.760 --> 00:26:31.850
<v Speaker 1>One example I'd like to just use as an </v>
<v Speaker 1>illustration of this idea,</v>

419
00:26:31.880 --> 00:26:32.713
<v Speaker 1>so there are many ways that auto ml can </v>
<v Speaker 1>be accomplished and this is just one </v>

420
00:26:36.351 --> 00:26:37.184
<v Speaker 1>example of those ways.</v>
<v Speaker 1>So I'd like to focus on this </v>

421
00:26:39.560 --> 00:26:41.630
<v Speaker 1>illustration here and I'd like to walk </v>
<v Speaker 1>through it.</v>

422
00:26:41.660 --> 00:26:45.090
<v Speaker 1>It's just a way that we can learn to </v>
<v Speaker 1>learn.</v>

423
00:26:46.650 --> 00:26:49.650
<v Speaker 1>So this,</v>
<v Speaker 1>this system focuses on two parts.</v>

424
00:26:49.800 --> 00:26:52.830
<v Speaker 1>The first part is the controller rnn in </v>
<v Speaker 1>red on the left,</v>

425
00:26:53.640 --> 00:26:58.080
<v Speaker 1>and this controller rnn is basically </v>
<v Speaker 1>just sampling different architectures of</v>

426
00:26:58.081 --> 00:27:01.500
<v Speaker 1>neural networks.</v>
<v Speaker 1>So if you remember in your first lab you</v>

427
00:27:01.501 --> 00:27:04.980
<v Speaker 1>created an rnn that could sample </v>
<v Speaker 1>different music notes.</v>

428
00:27:05.970 --> 00:27:09.120
<v Speaker 1>This is no different except now we're </v>
<v Speaker 1>not sampling music notes.</v>

429
00:27:09.330 --> 00:27:12.570
<v Speaker 1>We're sampling an entire neural network </v>
<v Speaker 1>itself.</v>

430
00:27:12.780 --> 00:27:15.870
<v Speaker 1>So we're sampling parameters that define</v>
<v Speaker 1>that neural network.</v>

431
00:27:16.530 --> 00:27:19.110
<v Speaker 1>So let's call that the architecture or </v>
<v Speaker 1>the child network.</v>

432
00:27:19.170 --> 00:27:22.830
<v Speaker 1>So that's the network that will actually</v>
<v Speaker 1>be used to solve our task in the end.</v>

433
00:27:24.390 --> 00:27:27.120
<v Speaker 1>So that network has passed on to the </v>
<v Speaker 1>second bop.</v>

434
00:27:28.680 --> 00:27:30.810
<v Speaker 1>So that network has passed on to the </v>
<v Speaker 1>second one.</v>

435
00:27:32.280 --> 00:27:37.280
<v Speaker 1>And in that piece we actually used that </v>
<v Speaker 1>network that was generated by the rnn to</v>

436
00:27:37.681 --> 00:27:41.370
<v Speaker 1>train a model depending on how well that</v>
<v Speaker 1>model did,</v>

437
00:27:42.950 --> 00:27:46.730
<v Speaker 1>we can provide feedback to the rnn such </v>
<v Speaker 1>that it can produce an even better model</v>

438
00:27:46.790 --> 00:27:47.810
<v Speaker 1>on the next time step.</v>

439
00:27:49.510 --> 00:27:50.343
<v Speaker 1>So let's go into this piece by piece.</v>
<v Speaker 1>Let's look at just the rnn part in more </v>

440
00:27:53.621 --> 00:27:54.454
<v Speaker 1>detail.</v>
<v Speaker 1>So this is the rnn or the architecture </v>

441
00:27:56.741 --> 00:27:58.480
<v Speaker 1>generator.</v>
<v Speaker 1>So like I said,</v>

442
00:27:58.481 --> 00:28:02.200
<v Speaker 1>this is very similar to the way that you</v>
<v Speaker 1>are generating songs and your first lab,</v>

443
00:28:02.440 --> 00:28:03.273
<v Speaker 1>except now we're not generating songs,</v>
<v Speaker 1>the timestamps are going from layers on </v>

444
00:28:07.421 --> 00:28:08.254
<v Speaker 1>the x axis and we're just generating </v>
<v Speaker 1>parameters or hyper parameters rather </v>

445
00:28:15.700 --> 00:28:16.533
<v Speaker 1>for each of those layers.</v>
<v Speaker 1>So this is a generator for a </v>

446
00:28:18.461 --> 00:28:19.294
<v Speaker 1>convolutional neural network because </v>
<v Speaker 1>we're producing parameters like the </v>

447
00:28:22.121 --> 00:28:24.140
<v Speaker 1>filter height,</v>
<v Speaker 1>the filter with the stride height,</v>

448
00:28:24.170 --> 00:28:28.000
<v Speaker 1>etc.</v>
<v Speaker 1>So what we can do is we can at each time</v>

449
00:28:28.001 --> 00:28:28.834
<v Speaker 1>step produce a probability distribution </v>
<v Speaker 1>of over each of these parameters and we </v>

450
00:28:32.411 --> 00:28:35.770
<v Speaker 1>can essentially just sample and </v>
<v Speaker 1>architecture or sample of child network.</v>

451
00:28:36.430 --> 00:28:39.850
<v Speaker 1>Once we have that child network,</v>
<v Speaker 1>which I'm Showing right here in blue,</v>

452
00:28:40.570 --> 00:28:45.460
<v Speaker 1>we can train it using our data set that </v>
<v Speaker 1>we ultimately want to solve.</v>

453
00:28:46.150 --> 00:28:49.390
<v Speaker 1>So we put our training data in and we </v>
<v Speaker 1>get our predicted labels out.</v>

454
00:28:49.420 --> 00:28:50.253
<v Speaker 1>This is the,</v>
<v Speaker 1>this is the realm that we've been </v>

455
00:28:51.581 --> 00:28:54.010
<v Speaker 1>dealing with so far in this class,</v>
<v Speaker 1>right?</v>

456
00:28:54.011 --> 00:28:54.844
<v Speaker 1>So we have our,</v>
<v Speaker 1>this is basically what we've seen so </v>

457
00:28:56.741 --> 00:28:57.574
<v Speaker 1>far.</v>
<v Speaker 1>So this is just a single network and we </v>

458
00:28:59.051 --> 00:29:01.090
<v Speaker 1>have our training data that we're using </v>
<v Speaker 1>to train it.</v>

459
00:29:02.680 --> 00:29:07.000
<v Speaker 1>We see how well this does,</v>
<v Speaker 1>depending on the accuracy of this model,</v>

460
00:29:07.510 --> 00:29:08.343
<v Speaker 1>that accuracy is used to provide </v>
<v Speaker 1>feedback back to the rnn and update how </v>

461
00:29:13.391 --> 00:29:15.850
<v Speaker 1>it produces or how it generates these </v>
<v Speaker 1>models.</v>

462
00:29:18.340 --> 00:29:20.860
<v Speaker 1>So let's look at this one more time.</v>
<v Speaker 1>To summarize,</v>

463
00:29:21.490 --> 00:29:23.770
<v Speaker 1>this is an extremely powerful idea.</v>
<v Speaker 1>It's really,</v>

464
00:29:23.771 --> 00:29:27.100
<v Speaker 1>really,</v>
<v Speaker 1>really exciting because it shows that an</v>

465
00:29:27.130 --> 00:29:27.963
<v Speaker 1>rnn can be actually combined in a </v>
<v Speaker 1>reinforcement learning paradigm where </v>

466
00:29:31.691 --> 00:29:35.500
<v Speaker 1>the rnn itself is almost like the agent </v>
<v Speaker 1>in reinforcement learning.</v>

467
00:29:35.530 --> 00:29:40.530
<v Speaker 1>It's learning to make changes to the </v>
<v Speaker 1>child network architecture.</v>

468
00:29:41.080 --> 00:29:44.740
<v Speaker 1>Depending on how that child network </v>
<v Speaker 1>performs on a training set,</v>

469
00:29:46.750 --> 00:29:47.583
<v Speaker 1>this means that we're able to create an </v>
<v Speaker 1>ai system capable of generating brand </v>

470
00:29:50.531 --> 00:29:55.390
<v Speaker 1>new neural networks specialized to solve</v>
<v Speaker 1>specific tasks rather than just creating</v>

471
00:29:55.391 --> 00:29:59.320
<v Speaker 1>a single neural network that we create </v>
<v Speaker 1>just to solve that tasks that we want to</v>

472
00:29:59.321 --> 00:30:02.440
<v Speaker 1>create that we want to solve.</v>
<v Speaker 1>Thus,</v>

473
00:30:02.441 --> 00:30:03.274
<v Speaker 1>this has significantly reduced.</v>
<v Speaker 1>The difficulty in optimizing these </v>

474
00:30:05.861 --> 00:30:06.694
<v Speaker 1>neural networks for our architecture is </v>
<v Speaker 1>for different tasks and it's also </v>

475
00:30:10.481 --> 00:30:14.470
<v Speaker 1>reduces the need for expert engineers to</v>
<v Speaker 1>design these architectures,</v>

476
00:30:15.930 --> 00:30:19.080
<v Speaker 1>so this really gets at the heart of </v>
<v Speaker 1>artificial intelligence.</v>

477
00:30:19.500 --> 00:30:23.520
<v Speaker 1>So when I began this course,</v>
<v Speaker 1>we spoke about what it actually means to</v>

478
00:30:23.521 --> 00:30:24.354
<v Speaker 1>be intelligent and lucy.</v>
<v Speaker 1>I defined this as the ability to take </v>

479
00:30:27.451 --> 00:30:29.520
<v Speaker 1>information,</v>
<v Speaker 1>process that information,</v>

480
00:30:29.521 --> 00:30:33.510
<v Speaker 1>and use it to inform future decisions.</v>

481
00:30:36.100 --> 00:30:40.270
<v Speaker 1>So the human learning pipeline is not </v>
<v Speaker 1>restricted to solving just one task at a</v>

482
00:30:40.271 --> 00:30:41.560
<v Speaker 1>time.</v>
<v Speaker 1>Like I mentioned before,</v>

483
00:30:41.561 --> 00:30:42.394
<v Speaker 1>how we learn one task can greatly impact</v>
<v Speaker 1>speed up or even slowed down our </v>

484
00:30:46.841 --> 00:30:47.674
<v Speaker 1>learning of other tasks and the </v>
<v Speaker 1>artificial models that we've created </v>

485
00:30:50.771 --> 00:30:52.930
<v Speaker 1>today.</v>
<v Speaker 1>Simply do not capture this phenomenon.</v>

486
00:30:53.770 --> 00:30:55.900
<v Speaker 1>To reach artificial general </v>
<v Speaker 1>intelligence.</v>

487
00:30:55.901 --> 00:30:59.560
<v Speaker 1>We need to actually build ai that can </v>
<v Speaker 1>not only learn a single task,</v>

488
00:31:00.640 --> 00:31:01.473
<v Speaker 1>but also be able to improve its own </v>
<v Speaker 1>learning and reasoning such that it can </v>

489
00:31:04.721 --> 00:31:08.260
<v Speaker 1>generalize to sets of related and </v>
<v Speaker 1>dependent tasks.</v>

490
00:31:09.310 --> 00:31:10.143
<v Speaker 1>I'll leave this with you as a thought </v>
<v Speaker 1>provoking points that encourage you to </v>

491
00:31:13.420 --> 00:31:16.500
<v Speaker 1>to all talk to each other on on some </v>
<v Speaker 1>ways that we can reach this,</v>

492
00:31:16.680 --> 00:31:20.980
<v Speaker 1>this higher order level of intelligence </v>
<v Speaker 1>that's not just pattern recognition,</v>

493
00:31:21.460 --> 00:31:22.293
<v Speaker 1>but rather a higher order form of </v>
<v Speaker 1>reasoning and actually thinking about </v>

494
00:31:26.580 --> 00:31:28.570
<v Speaker 1>about the problems that we're trying to </v>
<v Speaker 1>solve.</v>

495
00:31:30.150 --> 00:31:35.150
<v Speaker 2>Thank you.</v>
<v Speaker 2>Thank you.</v>

