WEBVTT

1
00:00:03.190 --> 00:00:04.023
<v Speaker 1>So a lot is being written and said about</v>
<v Speaker 1>deep learning and the new ai wave and </v>

2
00:00:10.470 --> 00:00:14.060
<v Speaker 1>not everything is true.</v>
<v Speaker 1>So yes,</v>

3
00:00:14.100 --> 00:00:14.933
<v Speaker 1>one of the things that's natural,</v>
<v Speaker 1>so the idea that machines program </v>

4
00:00:19.171 --> 00:00:20.004
<v Speaker 1>themselves these days and all the have </v>
<v Speaker 1>to do is put mediocre data in turn the </v>

5
00:00:24.691 --> 00:00:29.691
<v Speaker 1>crank and outcome excellent results.</v>
<v Speaker 1>But that is um,</v>

6
00:00:31.600 --> 00:00:32.433
<v Speaker 1>but I think of true magic in this deep </v>
<v Speaker 1>learning and here's what really </v>

7
00:00:36.031 --> 00:00:36.864
<v Speaker 1>fascinates me the most about this field </v>
<v Speaker 1>is a deep learning led's or solve </v>

8
00:00:40.231 --> 00:00:41.064
<v Speaker 1>problems.</v>
<v Speaker 1>We don't know how to program so we can </v>

9
00:00:45.391 --> 00:00:46.224
<v Speaker 1>solve problems.</v>
<v Speaker 1>We actually don't understand in detail </v>

10
00:00:49.900 --> 00:00:53.370
<v Speaker 1>sophia in sufficient detail that we can </v>
<v Speaker 1>program a solution.</v>

11
00:00:53.970 --> 00:00:56.790
<v Speaker 1>The first time I witnessed this is quite</v>
<v Speaker 1>awhile ago,</v>

12
00:00:56.791 --> 00:01:01.791
<v Speaker 1>it was around 1992 I was in at eth in </v>
<v Speaker 1>Switzerland working on a reading machine</v>

13
00:01:04.261 --> 00:01:08.380
<v Speaker 1>for the blind and we made good progress </v>
<v Speaker 1>on printed texts.</v>

14
00:01:08.420 --> 00:01:10.020
<v Speaker 1>But we,</v>
<v Speaker 1>when we,</v>

15
00:01:10.070 --> 00:01:15.070
<v Speaker 1>we got nowhere for handwritten text.</v>
<v Speaker 1>And so I was reading through paper after</v>

16
00:01:16.081 --> 00:01:21.000
<v Speaker 1>paper was promising titles and just to </v>
<v Speaker 1>be disappointed time and again.</v>

17
00:01:21.390 --> 00:01:22.223
<v Speaker 1>So most people back then they worked on </v>
<v Speaker 1>capitol letters from eight to f for </v>

18
00:01:26.401 --> 00:01:27.234
<v Speaker 1>example,</v>
<v Speaker 1>that tiny variations to the bitmap and </v>

19
00:01:30.941 --> 00:01:34.950
<v Speaker 1>10 called it Fontin variant.</v>
<v Speaker 1>And then somebody pointed me to the work</v>

20
00:01:34.951 --> 00:01:35.784
<v Speaker 1>of Yonder coon and I looked into that </v>
<v Speaker 1>and was very fascinated because he was </v>

21
00:01:40.021 --> 00:01:42.780
<v Speaker 1>working with actual data from the u s </v>
<v Speaker 1>postal service,</v>

22
00:01:42.990 --> 00:01:44.700
<v Speaker 1>no,</v>
<v Speaker 1>no cheating possible.</v>

23
00:01:45.150 --> 00:01:47.970
<v Speaker 1>And he claimed to have excellent </v>
<v Speaker 1>results.</v>

24
00:01:48.660 --> 00:01:53.070
<v Speaker 1>And he's methods we are comparatively </v>
<v Speaker 1>simple.</v>

25
00:01:53.280 --> 00:01:58.260
<v Speaker 1>So we rushed to re implementers and well</v>
<v Speaker 1>first we had to rush to actually collect</v>

26
00:01:58.261 --> 00:02:02.600
<v Speaker 1>data and then train the network and it </v>
<v Speaker 1>felt like magic it,</v>

27
00:02:02.601 --> 00:02:07.601
<v Speaker 1>it would actually read and do this </v>
<v Speaker 1>seemingly impossible task.</v>

28
00:02:09.300 --> 00:02:13.950
<v Speaker 1>So a year later I was fortunate to join </v>
<v Speaker 1>that very team at bell labs.</v>

29
00:02:14.550 --> 00:02:17.610
<v Speaker 1>So I divided my presentation into two </v>
<v Speaker 1>parts.</v>

30
00:02:17.611 --> 00:02:19.890
<v Speaker 1>The first part I will talk about the </v>
<v Speaker 1>early uh,</v>

31
00:02:19.920 --> 00:02:20.753
<v Speaker 1>deep learning work at bell labs.</v>
<v Speaker 1>And then the second part I will talk </v>

32
00:02:24.031 --> 00:02:27.540
<v Speaker 1>about our current vogue at Nvidia on </v>
<v Speaker 1>self driving cars.</v>

33
00:02:28.980 --> 00:02:33.980
<v Speaker 1>So from 1990 from 1985 to 90 1995 was a </v>
<v Speaker 1>10 year period.</v>

34
00:02:36.091 --> 00:02:40.020
<v Speaker 1>It was incredibly productive.</v>
<v Speaker 1>So in that team,</v>

35
00:02:40.680 --> 00:02:43.260
<v Speaker 1>that team not only created convolutional</v>
<v Speaker 1>networks,</v>

36
00:02:43.350 --> 00:02:44.183
<v Speaker 1>uh,</v>
<v Speaker 1>it also created support vector machines </v>

37
00:02:46.540 --> 00:02:51.000
<v Speaker 1>as vms and later foundation of </v>
<v Speaker 1>important,</v>

38
00:02:52.170 --> 00:02:53.520
<v Speaker 1>uh,</v>
<v Speaker 1>machine learning,</v>

39
00:02:53.820 --> 00:02:56.430
<v Speaker 1>learning theory,</v>
<v Speaker 1>and also,</v>

40
00:02:56.670 --> 00:02:57.503
<v Speaker 1>uh,</v>
<v Speaker 1>created several generations of neural </v>

41
00:02:58.771 --> 00:02:59.604
<v Speaker 1>network.</v>

42
00:03:01.040 --> 00:03:01.790
<v Speaker 2>Okay.</v>

43
00:03:01.790 --> 00:03:04.130
<v Speaker 1>This is the building in homedale new </v>
<v Speaker 1>Chelsea.</v>

44
00:03:04.430 --> 00:03:08.770
<v Speaker 1>So gigantic building,</v>
<v Speaker 1>actually a t eight house,</v>

45
00:03:08.790 --> 00:03:10.460
<v Speaker 1>about 6,000</v>
<v Speaker 1>employees,</v>

46
00:03:10.970 --> 00:03:15.650
<v Speaker 1>300 of those were in research and 30 of </v>
<v Speaker 1>those in machine learning.</v>

47
00:03:16.040 --> 00:03:19.610
<v Speaker 1>So you'll probably recognize several of </v>
<v Speaker 1>the names.</v>

48
00:03:21.990 --> 00:03:22.823
<v Speaker 1>Um,</v>
<v Speaker 1>and since as researchers we tended to </v>

49
00:03:26.041 --> 00:03:29.040
<v Speaker 1>show up late in the day,</v>
<v Speaker 1>we always had to park way out here,</v>

50
00:03:29.730 --> 00:03:30.563
<v Speaker 1>which added about 10 more minutes to </v>
<v Speaker 1>your commute just to walk into the </v>

51
00:03:33.661 --> 00:03:38.270
<v Speaker 1>building and into your office.</v>
<v Speaker 1>There's these two ponds here.</v>

52
00:03:38.990 --> 00:03:41.490
<v Speaker 1>Uh,</v>
<v Speaker 1>could you imagine what they are for?</v>

53
00:03:42.570 --> 00:03:43.920
<v Speaker 1>They're not just landscaping.</v>

54
00:03:45.530 --> 00:03:46.363
<v Speaker 2>Yeah,</v>

55
00:03:46.990 --> 00:03:47.823
<v Speaker 1>yeah.</v>
<v Speaker 1>They thought that he takes changes for </v>

56
00:03:48.520 --> 00:03:50.470
<v Speaker 1>the,</v>
<v Speaker 1>for the air conditioning of the building</v>

57
00:03:50.710 --> 00:03:53.590
<v Speaker 1>or it used to be late today,</v>
<v Speaker 1>replaced them with cooling towers.</v>

58
00:03:55.710 --> 00:03:59.310
<v Speaker 1>This is the very first data sets that </v>
<v Speaker 1>I've worked with,</v>

59
00:03:59.940 --> 00:04:00.773
<v Speaker 1>uh,</v>
<v Speaker 1>collected among the researchers </v>

60
00:04:01.711 --> 00:04:02.544
<v Speaker 1>themselves.</v>
<v Speaker 1>A later they got data from the U S </v>

61
00:04:05.550 --> 00:04:06.383
<v Speaker 1>Postal Service.</v>
<v Speaker 1>Um,</v>

62
00:04:06.480 --> 00:04:11.480
<v Speaker 1>and then that grew into nist and nist,</v>
<v Speaker 1>which is still very widely used today.</v>

63
00:04:16.480 --> 00:04:17.313
<v Speaker 1>So a lot of the work was about what </v>
<v Speaker 1>structure to be put into the learning </v>

64
00:04:20.771 --> 00:04:21.604
<v Speaker 1>machines.</v>
<v Speaker 1>What prior knowledge do we equip them </v>

65
00:04:22.871 --> 00:04:24.580
<v Speaker 1>with to,</v>
<v Speaker 1>to perform the task?</v>

66
00:04:24.581 --> 00:04:26.020
<v Speaker 1>Well,</v>
<v Speaker 1>um,</v>

67
00:04:26.110 --> 00:04:30.970
<v Speaker 1>if you talk about,</v>
<v Speaker 1>if you look at this example here and you</v>

68
00:04:30.971 --> 00:04:31.804
<v Speaker 1>needed to build a classifier that can </v>
<v Speaker 1>distinguish between the red and the </v>

69
00:04:35.411 --> 00:04:40.411
<v Speaker 1>green classes and you wonder what class </v>
<v Speaker 1>does this x belong to?</v>

70
00:04:42.460 --> 00:04:44.770
<v Speaker 1>So if you take,</v>
<v Speaker 1>um,</v>

71
00:04:45.040 --> 00:04:47.410
<v Speaker 1>location east,</v>
<v Speaker 1>west,</v>

72
00:04:47.411 --> 00:04:52.090
<v Speaker 1>north,</v>
<v Speaker 1>south as you criteria to classify,</v>

73
00:04:52.420 --> 00:04:56.200
<v Speaker 1>then you would probably say the x </v>
<v Speaker 1>belongs to Green.</v>

74
00:04:58.140 --> 00:04:58.973
<v Speaker 1>But if you understand that these points </v>
<v Speaker 1>are actually real points on the surface </v>

75
00:05:02.021 --> 00:05:07.021
<v Speaker 1>of the earth and it happens that the </v>
<v Speaker 1>green ones are on board and the red ones</v>

76
00:05:09.041 --> 00:05:09.874
<v Speaker 1>are on land,</v>
<v Speaker 1>then you could change your criteria and </v>

77
00:05:12.401 --> 00:05:16.420
<v Speaker 1>say,</v>
<v Speaker 1>let me take a level above the height,</v>

78
00:05:16.421 --> 00:05:17.254
<v Speaker 1>above sea level as the criteria,</v>
<v Speaker 1>in which case the problem becomes </v>

79
00:05:20.471 --> 00:05:22.620
<v Speaker 1>trivial.</v>
<v Speaker 1>So this point is actually on land.</v>

80
00:05:22.630 --> 00:05:27.630
<v Speaker 1>So he belongs to the right class.</v>
<v Speaker 1>Anybody see that?</v>

81
00:05:27.680 --> 00:05:28.513
<v Speaker 1>He sees</v>

82
00:05:31.300 --> 00:05:33.710
<v Speaker 2>this is Manhattan,</v>
<v Speaker 2>New York.</v>

83
00:05:35.270 --> 00:05:40.270
<v Speaker 1>So this is an example how programming or</v>
<v Speaker 1>are using prior knowledge actually helps</v>

84
00:05:41.451 --> 00:05:45.170
<v Speaker 1>the classification task enormously.</v>
<v Speaker 1>Um,</v>

85
00:05:45.171 --> 00:05:48.830
<v Speaker 1>of course that led to the creation of </v>
<v Speaker 1>convolutional networks.</v>

86
00:05:48.890 --> 00:05:51.770
<v Speaker 1>This is an old slide that we use to </v>
<v Speaker 1>explain how they work.</v>

87
00:05:52.340 --> 00:05:56.060
<v Speaker 1>Naturally you have these convolutions </v>
<v Speaker 1>that can learn to do,</v>

88
00:05:56.360 --> 00:05:58.290
<v Speaker 1>um,</v>
<v Speaker 1>today's lines,</v>

89
00:05:58.320 --> 00:05:59.520
<v Speaker 1>vertical,</v>
<v Speaker 1>horizontal,</v>

90
00:05:59.521 --> 00:06:03.090
<v Speaker 1>and then next layer can the deck at and </v>
<v Speaker 1>so on.</v>

91
00:06:03.900 --> 00:06:08.900
<v Speaker 1>And of course the leap of faith was that</v>
<v Speaker 1>we don't have design these features,</v>

92
00:06:09.691 --> 00:06:10.524
<v Speaker 1>but actually like a numerical </v>
<v Speaker 1>optimization algorithm find optimal </v>

93
00:06:14.671 --> 00:06:18.480
<v Speaker 1>solutions.</v>
<v Speaker 1>Oh,</v>

94
00:06:18.481 --> 00:06:21.900
<v Speaker 1>he has an old video from yonder coon </v>
<v Speaker 1>showing low net.</v>

95
00:06:23.010 --> 00:06:23.660
<v Speaker 2>Yeah,</v>

96
00:06:23.660 --> 00:06:28.240
<v Speaker 1>you supposed to own an old 80 and tpc I </v>
<v Speaker 1>believe was a dsp accelerator in it.</v>

97
00:06:31.400 --> 00:06:32.880
<v Speaker 1>So yeah,</v>
<v Speaker 1>you may have seen the video.</v>

98
00:06:32.881 --> 00:06:37.881
<v Speaker 1>It's,</v>
<v Speaker 1>it's on youtube and at that time,</v>

99
00:06:43.910 --> 00:06:44.631
<v Speaker 1>many,</v>
<v Speaker 1>many,</v>

100
00:06:44.631 --> 00:06:48.680
<v Speaker 1>many brilliant minds tried so hard for </v>
<v Speaker 1>years to solve the problem.</v>

101
00:06:49.370 --> 00:06:53.720
<v Speaker 1>And here comes,</v>
<v Speaker 1>this network can just does it was almost</v>

102
00:06:53.721 --> 00:06:57.470
<v Speaker 1>looks with ease.</v>
<v Speaker 1>Then young gets creative.</v>

103
00:06:59.010 --> 00:07:01.350
<v Speaker 1>I'm quite sure that this type of </v>
<v Speaker 1>characters,</v>

104
00:07:01.351 --> 00:07:06.351
<v Speaker 1>we're not in the training side.</v>
<v Speaker 1>Some other people from the lab.</v>

105
00:07:10.480 --> 00:07:12.400
<v Speaker 1>This is Donnie Henderson,</v>

106
00:07:14.380 --> 00:07:17.150
<v Speaker 1>a three child who was the lab director </v>
<v Speaker 1>at the time.</v>

107
00:07:19.250 --> 00:07:24.250
<v Speaker 1>So as we became to look at,</v>
<v Speaker 1>learning is essentially two main things,</v>

108
00:07:25.641 --> 00:07:26.474
<v Speaker 1>monies to build prior knowledge into the</v>
<v Speaker 1>architecture of what Vladimir about </v>

109
00:07:30.290 --> 00:07:32.720
<v Speaker 1>calls,</v>
<v Speaker 1>structural risk minimization.</v>

110
00:07:33.650 --> 00:07:34.483
<v Speaker 1>And the other one is a capacity control.</v>
<v Speaker 1>So you need to match the size of your </v>

111
00:07:39.680 --> 00:07:40.513
<v Speaker 1>network to the amount of diversity of </v>
<v Speaker 1>the data that you have and one really </v>

112
00:07:44.631 --> 00:07:49.040
<v Speaker 1>good tool to do that or to to analyze </v>
<v Speaker 1>that these learning curves.</v>

113
00:07:50.690 --> 00:07:55.690
<v Speaker 1>So this is not the number of epochs he </v>
<v Speaker 1>otis a actually each point on this chart</v>

114
00:07:56.061 --> 00:07:56.894
<v Speaker 1>is a fully trained network.</v>
<v Speaker 1>So what do you do is you measure the </v>

115
00:08:01.701 --> 00:08:06.701
<v Speaker 1>performance of your network on the </v>
<v Speaker 1>training set and on the test track while</v>

116
00:08:07.040 --> 00:08:07.873
<v Speaker 1>you're growing the and not the amount of</v>
<v Speaker 1>data that you're training the network </v>

117
00:08:10.461 --> 00:08:11.750
<v Speaker 1>with.</v>
<v Speaker 1>So this is the,</v>

118
00:08:11.751 --> 00:08:12.584
<v Speaker 1>uh,</v>
<v Speaker 1>the number of examples that you use for </v>

119
00:08:13.881 --> 00:08:14.714
<v Speaker 1>training.</v>

120
00:08:14.990 --> 00:08:17.150
<v Speaker 1>So if you have very,</v>
<v Speaker 1>very few examples,</v>

121
00:08:17.151 --> 00:08:17.984
<v Speaker 1>then the networks can essentially </v>
<v Speaker 1>memorized a training set and the ad or </v>

122
00:08:22.331 --> 00:08:26.630
<v Speaker 1>on the training side is zero.</v>
<v Speaker 1>While the error on the test that is very</v>

123
00:08:26.631 --> 00:08:29.150
<v Speaker 1>big.</v>
<v Speaker 1>And then as you grow the Dataset,</v>

124
00:08:29.210 --> 00:08:30.610
<v Speaker 1>the,</v>
<v Speaker 1>the,</v>

125
00:08:30.611 --> 00:08:34.550
<v Speaker 1>uh,</v>
<v Speaker 1>error on the test that calms down and at</v>

126
00:08:34.551 --> 00:08:35.384
<v Speaker 1>some point the networks can no longer </v>
<v Speaker 1>memorize and that the entire data set </v>

127
00:08:39.711 --> 00:08:43.130
<v Speaker 1>and the,</v>
<v Speaker 1>the training said Arrow starts to grow.</v>

128
00:08:43.610 --> 00:08:48.560
<v Speaker 1>And empirically it's been shown that </v>
<v Speaker 1>these curves eventually die neat.</v>

129
00:08:48.920 --> 00:08:51.110
<v Speaker 1>And you don't need to plot the entire </v>
<v Speaker 1>curve.</v>

130
00:08:52.010 --> 00:08:54.980
<v Speaker 1>It's usually in the middle between the </v>
<v Speaker 1>two curves.</v>

131
00:08:54.990 --> 00:08:58.530
<v Speaker 1>So you can half a good idea what to </v>
<v Speaker 1>expect.</v>

132
00:08:59.310 --> 00:09:00.143
<v Speaker 1>So if you hit this point a year,</v>
<v Speaker 1>then it becomes clear that it doesn't </v>

133
00:09:03.871 --> 00:09:04.704
<v Speaker 1>help you to add more data.</v>
<v Speaker 1>You have to increase the capacity of </v>

134
00:09:07.201 --> 00:09:10.730
<v Speaker 1>your network.</v>
<v Speaker 1>Uh,</v>

135
00:09:10.731 --> 00:09:14.390
<v Speaker 1>he has a learning curve from real life </v>
<v Speaker 1>that we did last week.</v>

136
00:09:14.660 --> 00:09:15.920
<v Speaker 1>So this is,</v>
<v Speaker 1>uh,</v>

137
00:09:16.040 --> 00:09:17.630
<v Speaker 1>here,</v>
<v Speaker 1>uh,</v>

138
00:09:17.690 --> 00:09:20.270
<v Speaker 1>predicting the steering angle of a </v>
<v Speaker 1>human.</v>

139
00:09:20.271 --> 00:09:23.330
<v Speaker 1>So how close does the netbook steer like</v>
<v Speaker 1>a human?</v>

140
00:09:23.331 --> 00:09:24.820
<v Speaker 1>And you see that,</v>
<v Speaker 1>uh,</v>

141
00:09:25.130 --> 00:09:28.940
<v Speaker 1>around here we reached a point where </v>
<v Speaker 1>adding new data wouldn't help us.</v>

142
00:09:32.100 --> 00:09:32.933
<v Speaker 1>Then in the 90s,</v>
<v Speaker 1>[inaudible] was sometimes heated debate </v>

143
00:09:35.641 --> 00:09:39.060
<v Speaker 1>about what is the best algorithm for </v>
<v Speaker 1>classifying characters.</v>

144
00:09:39.210 --> 00:09:40.043
<v Speaker 1>And</v>

145
00:09:40.540 --> 00:09:42.490
<v Speaker 2>the,</v>
<v Speaker 2>the,</v>

146
00:09:42.491 --> 00:09:43.324
<v Speaker 2>uh,</v>

147
00:09:44.480 --> 00:09:46.750
<v Speaker 1>manager of the group at the time was </v>
<v Speaker 1>Larry Charcoal.</v>

148
00:09:46.760 --> 00:09:47.630
<v Speaker 1>And he said,</v>
<v Speaker 1>well,</v>

149
00:09:47.631 --> 00:09:50.150
<v Speaker 1>let's just find out and combat all of </v>
<v Speaker 1>those.</v>

150
00:09:50.420 --> 00:09:52.350
<v Speaker 1>So this was one of these ideal </v>
<v Speaker 1>situations.</v>

151
00:09:52.351 --> 00:09:53.184
<v Speaker 1>Very had several people competing with </v>
<v Speaker 1>ideas and everybody was convinced my </v>

152
00:09:55.941 --> 00:09:58.000
<v Speaker 1>idea is the best.</v>
<v Speaker 1>Um,</v>

153
00:09:58.010 --> 00:10:00.350
<v Speaker 1>so I'll be combined them all and if I </v>
<v Speaker 1>remember correctly,</v>

154
00:10:00.351 --> 00:10:01.184
<v Speaker 1>that's what,</v>
<v Speaker 1>that's the reason that they created the </v>

155
00:10:03.480 --> 00:10:06.920
<v Speaker 1>nist database for.</v>
<v Speaker 1>So m stands for modified</v>

156
00:10:09.850 --> 00:10:11.770
<v Speaker 1>the result is somewhat interesting.</v>
<v Speaker 1>So,</v>

157
00:10:11.860 --> 00:10:12.693
<v Speaker 1>um,</v>
<v Speaker 1>k nearest neighbor that nobody believed </v>

158
00:10:14.651 --> 00:10:17.000
<v Speaker 1>that that would be the winner.</v>
<v Speaker 1>Um,</v>

159
00:10:17.060 --> 00:10:20.680
<v Speaker 1>that was just there for reference.</v>
<v Speaker 1>Also fully connected network.</v>

160
00:10:20.720 --> 00:10:23.800
<v Speaker 1>They're just there for reference.</v>
<v Speaker 1>Then this is lanette one.</v>

161
00:10:24.400 --> 00:10:25.233
<v Speaker 1>This was optimized for a much smaller </v>
<v Speaker 1>data set from the United States postal </v>

162
00:10:28.361 --> 00:10:29.194
<v Speaker 1>survey.</v>
<v Speaker 1>So that didn't do very well on this </v>

163
00:10:31.241 --> 00:10:32.560
<v Speaker 1>either.</v>
<v Speaker 1>In fact,</v>

164
00:10:32.770 --> 00:10:34.900
<v Speaker 1>it was even slightly versed and fully </v>
<v Speaker 1>connected.</v>

165
00:10:36.190 --> 00:10:39.260
<v Speaker 1>And then these here,</v>
<v Speaker 1>these were the actual competitor.</v>

166
00:10:39.261 --> 00:10:44.040
<v Speaker 1>So this is a convolutional network,</v>
<v Speaker 1>but this time optimized for the lots are</v>

167
00:10:44.070 --> 00:10:46.510
<v Speaker 1>mds data set.</v>
<v Speaker 1>Uh,</v>

168
00:10:46.600 --> 00:10:51.430
<v Speaker 1>I'll get back to boosting in a minute.</v>
<v Speaker 1>Then different variations.</v>

169
00:10:51.520 --> 00:10:53.860
<v Speaker 1>Um,</v>
<v Speaker 1>so he,</v>

170
00:10:53.861 --> 00:10:54.790
<v Speaker 1>uh,</v>
<v Speaker 1>for example,</v>

171
00:10:55.960 --> 00:10:58.660
<v Speaker 1>k nearest neighbor of course,</v>
<v Speaker 1>has one big flaw.</v>

172
00:10:58.750 --> 00:11:01.000
<v Speaker 1>So if you'd just take the Euclidean </v>
<v Speaker 1>distance,</v>

173
00:11:01.060 --> 00:11:04.180
<v Speaker 1>um,</v>
<v Speaker 1>as your metric as we did here,</v>

174
00:11:04.900 --> 00:11:09.430
<v Speaker 1>then if you shift to characters which </v>
<v Speaker 1>are actually the same by a few pixels,</v>

175
00:11:09.431 --> 00:11:12.490
<v Speaker 1>then the Euclidean distance starts to </v>
<v Speaker 1>become enormous.</v>

176
00:11:12.760 --> 00:11:13.593
<v Speaker 1>So it doesn't really measure how close </v>
<v Speaker 1>to our house similar to characters are </v>

177
00:11:18.371 --> 00:11:19.490
<v Speaker 1>very well.</v>
<v Speaker 1>So here,</v>

178
00:11:19.520 --> 00:11:22.240
<v Speaker 1>the idea of stop lights instead of using</v>
<v Speaker 1>the Euclidean distance,</v>

179
00:11:22.241 --> 00:11:24.940
<v Speaker 1>let's do the same thing.</v>
<v Speaker 1>I'm used the EUCLIDEAN distance,</v>

180
00:11:24.941 --> 00:11:28.870
<v Speaker 1>but not in the pixel space,</v>
<v Speaker 1>but in the uppermost feature map.</v>

181
00:11:29.350 --> 00:11:34.000
<v Speaker 1>And that's a boost.</v>
<v Speaker 1>It's the performance quiet a bit.</v>

182
00:11:34.720 --> 00:11:38.530
<v Speaker 1>Tangent distance was another one of the </v>
<v Speaker 1>ideas we talked a lot at a time.</v>

183
00:11:39.010 --> 00:11:39.843
<v Speaker 1>Uh,</v>
<v Speaker 1>another clever trick to increase the </v>

184
00:11:41.710 --> 00:11:42.543
<v Speaker 1>performance of k nearest neighbor.</v>
<v Speaker 1>So if you'll picture each character to </v>

185
00:11:46.181 --> 00:11:47.014
<v Speaker 1>be a point in a very high dimensional </v>
<v Speaker 1>pixel space and you start doing some </v>

186
00:11:51.210 --> 00:11:54.280
<v Speaker 1>photo probations to eight without </v>
<v Speaker 1>changing the actual characters.</v>

187
00:11:54.281 --> 00:11:56.240
<v Speaker 1>So you,</v>
<v Speaker 1>you rotate it all it a little bit,</v>

188
00:11:56.241 --> 00:11:59.080
<v Speaker 1>you shifted,</v>
<v Speaker 1>you grow the stroke a bit,</v>

189
00:11:59.900 --> 00:12:00.733
<v Speaker 1>um,</v>
<v Speaker 1>then that forms a surface around that </v>

190
00:12:03.641 --> 00:12:04.474
<v Speaker 1>point.</v>
<v Speaker 1>And if you don't deviate too much from </v>

191
00:12:06.611 --> 00:12:09.310
<v Speaker 1>the original point,</v>
<v Speaker 1>and you can model that as a plane.</v>

192
00:12:10.000 --> 00:12:10.833
<v Speaker 1>And the tangent reasons is simply the </v>
<v Speaker 1>EUCLIDEAN distance between two such </v>

193
00:12:15.221 --> 00:12:16.054
<v Speaker 1>planes.</v>
<v Speaker 1>I'm so clever idea was a lot of prior </v>

194
00:12:18.791 --> 00:12:23.791
<v Speaker 1>knowledge of the problem built into and </v>
<v Speaker 1>that also gets very good performance and</v>

195
00:12:23.930 --> 00:12:26.680
<v Speaker 1>optimal margin.</v>
<v Speaker 1>That's essentially an Svm.</v>

196
00:12:27.460 --> 00:12:30.430
<v Speaker 1>And so what's interesting is that they </v>
<v Speaker 1>all have the exact same performance.</v>

197
00:12:31.330 --> 00:12:34.720
<v Speaker 1>The only one that actually improve the </v>
<v Speaker 1>performance was boosting,</v>

198
00:12:34.990 --> 00:12:37.360
<v Speaker 1>which is kind of a different type of </v>
<v Speaker 1>approach.</v>

199
00:12:37.361 --> 00:12:38.194
<v Speaker 1>So here you train multiple networks,</v>
<v Speaker 1>you're trying to second network on the </v>

200
00:12:41.231 --> 00:12:43.310
<v Speaker 1>mistakes of the first one and your </v>
<v Speaker 1>trainers.</v>

201
00:12:43.340 --> 00:12:46.360
<v Speaker 1>Third one on there,</v>
<v Speaker 1>the first to disagree.</v>

202
00:12:46.690 --> 00:12:50.290
<v Speaker 1>So you get multiple expert.</v>
<v Speaker 1>I specialize on different parts of it,</v>

203
00:12:50.350 --> 00:12:51.183
<v Speaker 1>of the training sentence.</v>
<v Speaker 1>So it's not too surprising that that </v>

204
00:12:53.411 --> 00:12:58.411
<v Speaker 1>actually would increase the performance.</v>
<v Speaker 1>So what Larry said in hindsight is that,</v>

205
00:12:59.470 --> 00:13:02.230
<v Speaker 1>well,</v>
<v Speaker 1>it's not too surprising that I would all</v>

206
00:13:02.350 --> 00:13:03.183
<v Speaker 1>perform the same because everybody was </v>
<v Speaker 1>doing the same type of approach in </v>

207
00:13:09.101 --> 00:13:09.934
<v Speaker 1>exploring them the past capacity of </v>
<v Speaker 1>their learning system by doing the </v>

208
00:13:13.271 --> 00:13:17.470
<v Speaker 1>learning curves.</v>
<v Speaker 1>The one thing that stands out in my mind</v>

209
00:13:17.471 --> 00:13:18.304
<v Speaker 1>is the Svm because that has no prior </v>
<v Speaker 1>built in knowledge about the task at </v>

210
00:13:22.661 --> 00:13:25.030
<v Speaker 1>all.</v>
<v Speaker 1>But all of the others too.</v>

211
00:13:27.610 --> 00:13:28.443
<v Speaker 1>Um,</v>
<v Speaker 1>classification rate is not the only </v>

212
00:13:29.681 --> 00:13:32.170
<v Speaker 1>thing that you should actually focus on.</v>
<v Speaker 1>Of course,</v>

213
00:13:32.171 --> 00:13:35.320
<v Speaker 1>it's also memory consumption,</v>
<v Speaker 1>which is not on this chart,</v>

214
00:13:35.890 --> 00:13:36.723
<v Speaker 1>a training time and inference time.</v>
<v Speaker 1>So all of the memory based k nearest </v>

215
00:13:39.851 --> 00:13:43.180
<v Speaker 1>neighbor types,</v>
<v Speaker 1>they use very little training time,</v>

216
00:13:43.181 --> 00:13:44.560
<v Speaker 1>but then they use a lot of memory.</v>

217
00:13:47.470 --> 00:13:48.303
<v Speaker 1>So the lessons,</v>
<v Speaker 1>some of the lessons that I took from </v>

218
00:13:50.771 --> 00:13:52.510
<v Speaker 1>that time is,</v>
<v Speaker 1>uh,</v>

219
00:13:52.720 --> 00:13:55.240
<v Speaker 1>one is still very relevant,</v>
<v Speaker 1>is look at the data.</v>

220
00:13:55.690 --> 00:13:58.990
<v Speaker 1>I've seen so many people miss important </v>
<v Speaker 1>cues.</v>

221
00:13:58.991 --> 00:14:02.680
<v Speaker 1>I'm confused why you we was Rgb,</v>
<v Speaker 1>for example.</v>

222
00:14:03.040 --> 00:14:04.900
<v Speaker 1>That doesn't make your system failed </v>
<v Speaker 1>completely.</v>

223
00:14:04.901 --> 00:14:06.760
<v Speaker 1>It just doesn't perform as well as he </v>
<v Speaker 1>could.</v>

224
00:14:08.170 --> 00:14:10.960
<v Speaker 1>Um,</v>
<v Speaker 1>solid debugging tools are critical.</v>

225
00:14:11.050 --> 00:14:11.883
<v Speaker 1>These a neural networks have a nasty </v>
<v Speaker 1>habit of a masking box and the they and </v>

226
00:14:17.851 --> 00:14:18.684
<v Speaker 1>I adapted a,</v>
<v Speaker 1>they try their best to work around </v>

227
00:14:20.141 --> 00:14:22.650
<v Speaker 1>parks,</v>
<v Speaker 1>um,</v>

228
00:14:22.900 --> 00:14:23.733
<v Speaker 1>validated training data.</v>
<v Speaker 1>Again that's related to look at the </v>

229
00:14:26.561 --> 00:14:28.060
<v Speaker 1>data.</v>
<v Speaker 1>Um,</v>

230
00:14:28.270 --> 00:14:29.103
<v Speaker 1>so many data sets I've seen actually </v>
<v Speaker 1>have a grave labeling mistakes and to </v>

231
00:14:34.061 --> 00:14:34.894
<v Speaker 1>work is experimental in nature.</v>
<v Speaker 1>At least that's what it is to stay off </v>

232
00:14:37.961 --> 00:14:41.940
<v Speaker 1>today.</v>
<v Speaker 1>So in most cases you can just copy paste</v>

233
00:14:41.941 --> 00:14:45.670
<v Speaker 1>or recipe from somebody else that will </v>
<v Speaker 1>now give you the optimal results.</v>

234
00:14:46.840 --> 00:14:47.673
<v Speaker 1>And the last one is work with real data.</v>
<v Speaker 1>Synthetic data is great for debugging </v>

235
00:14:52.760 --> 00:14:55.010
<v Speaker 1>and you can certainly explore certain </v>
<v Speaker 1>trends,</v>

236
00:14:55.011 --> 00:14:58.100
<v Speaker 1>but to get a sense of very,</v>
<v Speaker 1>you really are,</v>

237
00:14:58.600 --> 00:14:59.660
<v Speaker 1>um,</v>
<v Speaker 1>you,</v>

238
00:14:59.720 --> 00:15:01.370
<v Speaker 1>you have to work with real data.</v>

239
00:15:04.610 --> 00:15:07.850
<v Speaker 1>So what happened after 95,</v>
<v Speaker 1>actually riding around the 95,</v>

240
00:15:07.930 --> 00:15:09.920
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

241
00:15:10.250 --> 00:15:11.083
<v Speaker 1>a t and t released a first production </v>
<v Speaker 1>version of convolutional networks for </v>

242
00:15:15.020 --> 00:15:15.853
<v Speaker 1>commercial check reading.</v>
<v Speaker 1>And eventually 20% of all the checks </v>

243
00:15:19.221 --> 00:15:22.940
<v Speaker 1>written in the u s were processed by </v>
<v Speaker 1>that system or right by that system.</v>

244
00:15:23.450 --> 00:15:24.560
<v Speaker 1>To me,</v>
<v Speaker 1>that was the real,</v>

245
00:15:24.800 --> 00:15:25.633
<v Speaker 1>the real sign of success.</v>
<v Speaker 1>If a technology is a commercially buy </v>

246
00:15:31.270 --> 00:15:35.450
<v Speaker 1>apple at the set in the same year </v>
<v Speaker 1>actually,</v>

247
00:15:35.570 --> 00:15:36.403
<v Speaker 1>um,</v>
<v Speaker 1>maybe in the morning sitting together </v>

248
00:15:39.710 --> 00:15:43.100
<v Speaker 1>discussing how we should celebrate this </v>
<v Speaker 1>fact.</v>

249
00:15:43.190 --> 00:15:48.190
<v Speaker 1>The success was the commercial check </v>
<v Speaker 1>reading and a message came in that day.</v>

250
00:15:48.291 --> 00:15:52.460
<v Speaker 1>T and t d announcement came in at eight </v>
<v Speaker 1>and t would break up into three parts.</v>

251
00:15:52.940 --> 00:15:55.640
<v Speaker 1>So that was quite a shock.</v>
<v Speaker 1>And then in 2002,</v>

252
00:15:55.641 --> 00:15:58.370
<v Speaker 1>there were mass layoffs and most people </v>
<v Speaker 1>left.</v>

253
00:15:59.300 --> 00:16:01.700
<v Speaker 1>And some of the important folks from </v>
<v Speaker 1>machine learning,</v>

254
00:16:01.701 --> 00:16:04.640
<v Speaker 1>they found themselves working together </v>
<v Speaker 1>again,</v>

255
00:16:04.730 --> 00:16:05.563
<v Speaker 1>either add star power or for Darpa and </v>
<v Speaker 1>created several programs such as locker </v>

256
00:16:10.340 --> 00:16:12.500
<v Speaker 1>learning,</v>
<v Speaker 1>applied to ground robots,</v>

257
00:16:13.200 --> 00:16:14.450
<v Speaker 1>uh,</v>
<v Speaker 1>learning locomotion.</v>

258
00:16:14.510 --> 00:16:15.343
<v Speaker 1>One was even called deep learning and </v>
<v Speaker 1>also the helping to get about his </v>

259
00:16:19.820 --> 00:16:22.070
<v Speaker 1>difference.</v>
<v Speaker 1>Darpa challenges launched.</v>

260
00:16:23.330 --> 00:16:24.163
<v Speaker 1>And then in 2002 deep learning becomes </v>
<v Speaker 1>really popular and I guess it's </v>

261
00:16:27.591 --> 00:16:28.424
<v Speaker 1>triggered by the availability of data,</v>
<v Speaker 1>the availability of compute powers and </v>

262
00:16:34.131 --> 00:16:35.310
<v Speaker 1>also,</v>
<v Speaker 1>uh,</v>

263
00:16:35.330 --> 00:16:36.163
<v Speaker 1>ready commercial applications.</v>
<v Speaker 1>So all of these large scale internet </v>

264
00:16:39.711 --> 00:16:43.640
<v Speaker 1>applications in speech recognition and </v>
<v Speaker 1>image classification,</v>

265
00:16:43.990 --> 00:16:44.823
<v Speaker 1>they bill radio at this point.</v>
<v Speaker 1>And I guess there was just not too much </v>

266
00:16:48.141 --> 00:16:53.120
<v Speaker 1>money in check rating for the economy to</v>
<v Speaker 1>take notice back then.</v>

267
00:16:56.300 --> 00:16:58.730
<v Speaker 1>So this brings me to what you're doing </v>
<v Speaker 1>today.</v>

268
00:16:59.900 --> 00:17:04.070
<v Speaker 1>Very similar technology applied to a </v>
<v Speaker 1>self driving costs in this case.</v>

269
00:17:04.700 --> 00:17:09.680
<v Speaker 1>So felleston over the off the entire </v>
<v Speaker 1>stack of and be yourself driving.</v>

270
00:17:10.040 --> 00:17:14.930
<v Speaker 1>So we have at the bottom the hardware </v>
<v Speaker 1>that goes into the car,</v>

271
00:17:15.200 --> 00:17:20.200
<v Speaker 1>that's the drive px family of products.</v>
<v Speaker 1>The most recent is called Pegasus.</v>

272
00:17:20.360 --> 00:17:25.360
<v Speaker 1>That was just announced at ces.</v>
<v Speaker 1>Then we have the operating system or the</v>

273
00:17:26.211 --> 00:17:27.710
<v Speaker 1>old timer,</v>
<v Speaker 1>but I think system layer.</v>

274
00:17:28.460 --> 00:17:32.140
<v Speaker 1>And then on top of that is driver folks.</v>
<v Speaker 1>That's what I call the middle man.</v>

275
00:17:32.141 --> 00:17:32.974
<v Speaker 1>So that does sensor abstraction does a,</v>
<v Speaker 1>all the logging tools interprocess </v>

276
00:17:36.651 --> 00:17:37.484
<v Speaker 1>communication and it has low level </v>
<v Speaker 1>computer division library such as image </v>

277
00:17:41.511 --> 00:17:46.120
<v Speaker 1>transformations.</v>
<v Speaker 1>And then on top of that is a drive a,</v>

278
00:17:46.130 --> 00:17:47.900
<v Speaker 1>b.</v>
<v Speaker 1>This is the application.</v>

279
00:17:48.890 --> 00:17:49.723
<v Speaker 1>Yeah.</v>
<v Speaker 1>So this is where it would be put </v>

280
00:17:50.951 --> 00:17:54.550
<v Speaker 1>together all of the other technology to </v>
<v Speaker 1>form actual applications.</v>

281
00:17:54.850 --> 00:17:57.800
<v Speaker 1>And some examples are here.</v>
<v Speaker 1>This is um,</v>

282
00:17:57.880 --> 00:18:01.170
<v Speaker 1>sensor fusion from radar and camera on </v>
<v Speaker 1>this,</v>

283
00:18:01.171 --> 00:18:05.730
<v Speaker 1>this lidar point cloud processing or </v>
<v Speaker 1>deep learning based object detector.</v>

284
00:18:06.460 --> 00:18:09.550
<v Speaker 1>So the detective boss here,</v>
<v Speaker 1>or to pedestrians back there.</v>

285
00:18:10.030 --> 00:18:12.010
<v Speaker 1>This is deep learning based,</v>
<v Speaker 1>uh,</v>

286
00:18:12.060 --> 00:18:13.540
<v Speaker 1>pre risk-based.</v>
<v Speaker 1>That action.</v>

287
00:18:14.390 --> 00:18:15.223
<v Speaker 1>Um,</v>
<v Speaker 1>this is localization based on hd maps </v>

288
00:18:17.890 --> 00:18:22.890
<v Speaker 1>and then this year is a perception based</v>
<v Speaker 1>as a planning.</v>

289
00:18:23.470 --> 00:18:26.440
<v Speaker 1>This is actually what comes out of our </v>
<v Speaker 1>group in New Jersey.</v>

290
00:18:26.441 --> 00:18:28.630
<v Speaker 1>So what a new Chelsea group is doing </v>
<v Speaker 1>there,</v>

291
00:18:28.660 --> 00:18:31.450
<v Speaker 1>we contribute into this layer here</v>

292
00:18:33.820 --> 00:18:37.780
<v Speaker 1>and our goal is to solve the heart and </v>
<v Speaker 1>on solves problems.</v>

293
00:18:37.810 --> 00:18:40.180
<v Speaker 1>And I think there's a lot of those in </v>
<v Speaker 1>self driving car.</v>

294
00:18:40.510 --> 00:18:43.060
<v Speaker 1>So if I think back to a character </v>
<v Speaker 1>recognition,</v>

295
00:18:43.061 --> 00:18:47.590
<v Speaker 1>if we can't even program handwritten </v>
<v Speaker 1>character recognition,</v>

296
00:18:48.670 --> 00:18:49.503
<v Speaker 1>then it's very likely that dealing with </v>
<v Speaker 1>other humans and all kinds of different </v>

297
00:18:55.421 --> 00:19:00.421
<v Speaker 1>situations is likely not going to be </v>
<v Speaker 1>solvable by just programming.</v>

298
00:19:00.850 --> 00:19:03.370
<v Speaker 1>So we concentrate on these heart </v>
<v Speaker 1>problems for two reasons.</v>

299
00:19:03.371 --> 00:19:06.340
<v Speaker 1>One is that we want to provide </v>
<v Speaker 1>algorithmic diversity.</v>

300
00:19:07.540 --> 00:19:08.373
<v Speaker 1>So in a safety critical system,</v>
<v Speaker 1>it's unlikely that you want to rely on </v>

301
00:19:12.371 --> 00:19:13.204
<v Speaker 1>any single algorithm.</v>
<v Speaker 1>And the second reason is that we can </v>

302
00:19:16.931 --> 00:19:20.020
<v Speaker 1>solve functionality that might not be </v>
<v Speaker 1>solvable otherwise.</v>

303
00:19:20.080 --> 00:19:20.913
<v Speaker 1>Like,</v>
<v Speaker 1>uh,</v>

304
00:19:21.340 --> 00:19:26.340
<v Speaker 1>taking turns just based on perception </v>
<v Speaker 1>without map data or learn to march on to</v>

305
00:19:27.880 --> 00:19:28.713
<v Speaker 1>a busy highway where you have to </v>
<v Speaker 1>negotiate with the other cars and </v>

306
00:19:30.971 --> 00:19:34.570
<v Speaker 1>squeeze yourself in.</v>
<v Speaker 1>And then other,</v>

307
00:19:34.630 --> 00:19:36.980
<v Speaker 1>the other labs,</v>
<v Speaker 1>um,</v>

308
00:19:37.030 --> 00:19:40.990
<v Speaker 1>the other autonomous labs in a Nvidia </v>
<v Speaker 1>are in California,</v>

309
00:19:41.020 --> 00:19:43.030
<v Speaker 1>in Boulder,</v>
<v Speaker 1>in Seattle,</v>

310
00:19:43.060 --> 00:19:47.320
<v Speaker 1>and in Europe.</v>
<v Speaker 1>This is,</v>

311
00:19:47.350 --> 00:19:48.183
<v Speaker 1>oh,</v>
<v Speaker 1>we're actually back in the same </v>

312
00:19:48.701 --> 00:19:51.040
<v Speaker 1>building,</v>
<v Speaker 1>which is cool.</v>

313
00:19:51.520 --> 00:19:53.920
<v Speaker 1>The building was empty for over 10 </v>
<v Speaker 1>years,</v>

314
00:19:53.921 --> 00:19:56.140
<v Speaker 1>but it's now being redeveloped for mixed</v>
<v Speaker 1>use.</v>

315
00:19:56.500 --> 00:20:00.160
<v Speaker 1>So there's a number of different tech </v>
<v Speaker 1>tech companies in there.</v>

316
00:20:00.161 --> 00:20:04.270
<v Speaker 1>So in Eto is renting space around here </v>
<v Speaker 1>and there's also,</v>

317
00:20:04.271 --> 00:20:08.500
<v Speaker 1>we're going to get restaurants and shops</v>
<v Speaker 1>and on the rooftop test plans to build a</v>

318
00:20:08.501 --> 00:20:09.334
<v Speaker 1>hotel.</v>

319
00:20:11.770 --> 00:20:12.603
<v Speaker 2>Uh,</v>

320
00:20:12.870 --> 00:20:14.890
<v Speaker 1>the reason why the tear is,</v>
<v Speaker 1>um,</v>

321
00:20:14.970 --> 00:20:15.803
<v Speaker 1>not so much sentimental.</v>
<v Speaker 1>It's because this is actually a very </v>

322
00:20:18.151 --> 00:20:20.880
<v Speaker 1>good environment for testing,</v>
<v Speaker 1>self driving cars.</v>

323
00:20:21.240 --> 00:20:22.073
<v Speaker 1>We have plenty of space in the basement </v>
<v Speaker 1>of the building to store and welcome to </v>

324
00:20:25.900 --> 00:20:27.780
<v Speaker 1>cars.</v>
<v Speaker 1>And then there's two tunnels here.</v>

325
00:20:28.350 --> 00:20:29.183
<v Speaker 1>Then with that we can take and dare </v>
<v Speaker 1>leaders right up to these private </v>

326
00:20:32.191 --> 00:20:33.300
<v Speaker 1>routes.</v>
<v Speaker 1>Here on the campus.</v>

327
00:20:34.050 --> 00:20:36.930
<v Speaker 1>Driving Monster around here is actually </v>
<v Speaker 1>two miles.</v>

328
00:20:37.680 --> 00:20:38.513
<v Speaker 1>And then right outside we have a very </v>
<v Speaker 1>nice mix of highway local adults in the </v>

329
00:20:42.881 --> 00:20:47.881
<v Speaker 1>residential adults.</v>
<v Speaker 1>The location is also quite</v>

330
00:20:48.070 --> 00:20:49.630
<v Speaker 3>nice.</v>
<v Speaker 3>Um,</v>

331
00:20:49.720 --> 00:20:50.553
<v Speaker 3>so I've got about 45 miles from New York</v>
<v Speaker 3>City and there's a train connection and </v>

332
00:20:54.431 --> 00:20:55.264
<v Speaker 3>fairy.</v>
<v Speaker 3>So the train is about 60 to 70 minutes </v>

333
00:20:57.431 --> 00:21:00.580
<v Speaker 3>and to failures faster actually can take</v>
<v Speaker 3>the shortcut.</v>

334
00:21:00.581 --> 00:21:05.340
<v Speaker 3>So it's around 40 minutes.</v>
<v Speaker 3>So</v>

335
00:21:06.060 --> 00:21:09.570
<v Speaker 1>what is a typical case where rule based </v>
<v Speaker 1>system struggle?</v>

336
00:21:09.630 --> 00:21:13.050
<v Speaker 1>While this seems clear so they can </v>
<v Speaker 1>detect these lane markings,</v>

337
00:21:13.051 --> 00:21:13.884
<v Speaker 1>localize the car within it and then half</v>
<v Speaker 1>a past planner and the controller and </v>

338
00:21:19.050 --> 00:21:22.040
<v Speaker 1>thrive,</v>
<v Speaker 1>but just um,</v>

339
00:21:22.170 --> 00:21:25.740
<v Speaker 1>about a hundred meters further up on </v>
<v Speaker 1>this road to situation looks like this.</v>

340
00:21:25.920 --> 00:21:27.920
<v Speaker 1>So it's much harder now.</v>
<v Speaker 1>So he can just,</v>

341
00:21:27.940 --> 00:21:28.773
<v Speaker 1>you have to double yellow line,</v>
<v Speaker 1>marker fainted and then the center one </v>

342
00:21:31.591 --> 00:21:34.800
<v Speaker 1>is almost gone.</v>
<v Speaker 1>You can still solve it.</v>

343
00:21:34.801 --> 00:21:36.990
<v Speaker 1>Of course you can build a detector for </v>
<v Speaker 1>this curb.</v>

344
00:21:36.991 --> 00:21:37.824
<v Speaker 1>But offense,</v>
<v Speaker 1>you may be able to reconstruct these </v>

345
00:21:39.311 --> 00:21:40.144
<v Speaker 1>yellow lane marking.</v>
<v Speaker 1>Then you can measure the distance here </v>

346
00:21:42.211 --> 00:21:45.330
<v Speaker 1>and decide that this is actually buy it </v>
<v Speaker 1>at an online.</v>

347
00:21:45.331 --> 00:21:47.490
<v Speaker 1>This is probably two lines and I'm </v>
<v Speaker 1>currently here,</v>

348
00:21:47.610 --> 00:21:48.443
<v Speaker 1>so I'm going to assume that there's </v>
<v Speaker 1>actually a virtual lane here and I'm </v>

349
00:21:51.841 --> 00:21:54.510
<v Speaker 1>going to drive down.</v>
<v Speaker 1>And then you have solved the problem for</v>

350
00:21:54.511 --> 00:21:59.190
<v Speaker 1>tastes for it is a scenario and then </v>
<v Speaker 1>around the corner it's different again.</v>

351
00:21:59.700 --> 00:22:03.180
<v Speaker 1>So you have to start all over.</v>
<v Speaker 1>And then again and again.</v>

352
00:22:04.020 --> 00:22:09.020
<v Speaker 1>So it seems a big advantage if we can </v>
<v Speaker 1>build a system that can derive to domain</v>

353
00:22:09.211 --> 00:22:13.080
<v Speaker 1>knowledge from data.</v>
<v Speaker 1>So by just observing humans,</v>

354
00:22:13.260 --> 00:22:17.190
<v Speaker 1>not by somebody telling it what it </v>
<v Speaker 1>actually should look for in this scene.</v>

355
00:22:18.960 --> 00:22:21.300
<v Speaker 1>So what we,</v>
<v Speaker 1>this is one of the things that we built.</v>

356
00:22:21.390 --> 00:22:23.880
<v Speaker 1>Um,</v>
<v Speaker 1>if this is the line here,</v>

357
00:22:24.540 --> 00:22:25.373
<v Speaker 1>that's where the car currently is,</v>
<v Speaker 1>then we predict there would the human </v>

358
00:22:29.311 --> 00:22:30.144
<v Speaker 1>drive.</v>
<v Speaker 1>So what is the short term trajectory </v>

359
00:22:31.711 --> 00:22:33.900
<v Speaker 1>that the human will take given that </v>
<v Speaker 1>image?</v>

360
00:22:34.920 --> 00:22:38.670
<v Speaker 1>And so collecting the data is relatively</v>
<v Speaker 1>simple.</v>

361
00:22:38.671 --> 00:22:40.830
<v Speaker 1>You just drive,</v>
<v Speaker 1>um,</v>

362
00:22:40.920 --> 00:22:45.750
<v Speaker 1>you can then derive this trajectory from</v>
<v Speaker 1>the IGA motion of the car.</v>

363
00:22:46.110 --> 00:22:46.943
<v Speaker 1>So that training labels,</v>
<v Speaker 1>you essentially collect them for free </v>

364
00:22:49.321 --> 00:22:53.400
<v Speaker 1>without additional manual labor while </v>
<v Speaker 1>you're collecting the data.</v>

365
00:22:53.880 --> 00:22:54.713
<v Speaker 1>And so then the,</v>
<v Speaker 1>the difference between what a human </v>

366
00:22:57.451 --> 00:22:58.284
<v Speaker 1>drove and what the network predicts,</v>
<v Speaker 1>that's the Arrow signal that we back </v>

367
00:23:01.050 --> 00:23:04.500
<v Speaker 1>propagate.</v>
<v Speaker 1>Uh,</v>

368
00:23:04.501 --> 00:23:08.340
<v Speaker 1>this is an example network architecture.</v>
<v Speaker 1>Um,</v>

369
00:23:08.730 --> 00:23:12.390
<v Speaker 1>this is from about two years ago.</v>
<v Speaker 1>It still looks similar but it's growing.</v>

370
00:23:12.391 --> 00:23:13.224
<v Speaker 1>So we constantly adapting to the,</v>
<v Speaker 1>to the current size of the training </v>

371
00:23:16.381 --> 00:23:17.214
<v Speaker 1>side.</v>

372
00:23:19.060 --> 00:23:20.560
<v Speaker 3>Oh yeah.</v>
<v Speaker 3>See how good I feel.</v>

373
00:23:20.580 --> 00:23:25.210
<v Speaker 3>Universal sign.</v>
<v Speaker 3>These are all old.</v>

374
00:23:31.940 --> 00:23:32.773
<v Speaker 4>And with this approach,</v>
<v Speaker 4>it really doesn't matter why they're </v>

375
00:23:35.530 --> 00:23:36.363
<v Speaker 4>doing hot rolled looks horrible,</v>
<v Speaker 4>grass overgrown or is a nice high </v>

376
00:23:38.581 --> 00:23:39.414
<v Speaker 4>highway.</v>
<v Speaker 4>As long as the update that we can learn </v>

377
00:23:40.911 --> 00:23:45.911
<v Speaker 4>from it currently not used anymore than </v>
<v Speaker 4>our campus.</v>

378
00:23:52.941 --> 00:23:57.580
<v Speaker 4>So that's just the ideal.</v>
<v Speaker 4>What experimenting.</v>

379
00:24:01.910 --> 00:24:02.743
<v Speaker 4>Oh,</v>
<v Speaker 4>cool.</v>

380
00:24:05.270 --> 00:24:09.050
<v Speaker 4>So the noises in the background but not </v>
<v Speaker 4>acting.</v>

381
00:24:09.051 --> 00:24:09.884
<v Speaker 4>This is actually real.</v>
<v Speaker 4>We struggle so much to get this to work </v>

382
00:24:13.020 --> 00:24:13.853
<v Speaker 4>for.</v>
<v Speaker 4>An important deadline was just about 12 </v>

383
00:24:16.281 --> 00:24:20.030
<v Speaker 4>hours before the drop dead deadline that</v>
<v Speaker 4>those things started working.</v>

384
00:24:20.900 --> 00:24:24.470
<v Speaker 4>That was a big relief.</v>
<v Speaker 4>So this is um,</v>

385
00:24:24.520 --> 00:24:27.540
<v Speaker 4>uh,</v>
<v Speaker 4>a made up construction side but on paved</v>

386
00:24:27.560 --> 00:24:28.920
<v Speaker 4>section in the,</v>
<v Speaker 4>in about,</v>

387
00:24:29.430 --> 00:24:31.560
<v Speaker 4>uh,</v>
<v Speaker 4>people often ask 12,</v>

388
00:24:31.670 --> 00:24:34.790
<v Speaker 4>if you train this in California,</v>
<v Speaker 4>can he drive in New Jersey?</v>

389
00:24:34.970 --> 00:24:37.010
<v Speaker 4>So we,</v>
<v Speaker 4>we showed it here,</v>

390
00:24:37.011 --> 00:24:37.844
<v Speaker 4>we trained with California data only on </v>
<v Speaker 4>a new Chelsea highway and he had at </v>

391
00:24:45.711 --> 00:24:50.450
<v Speaker 4>night please linked slightly on an </v>
<v Speaker 4>unpaved road in a nearby park.</v>

392
00:24:57.960 --> 00:24:58.793
<v Speaker 1>Got It.</v>

393
00:25:01.690 --> 00:25:04.510
<v Speaker 1>So we'll move on to something a little </v>
<v Speaker 1>more practical.</v>

394
00:25:04.820 --> 00:25:07.080
<v Speaker 1>This is highway driving.</v>
<v Speaker 1>Um,</v>

395
00:25:07.780 --> 00:25:11.080
<v Speaker 1>so he had been driving,</v>
<v Speaker 1>you'll see here,</v>

396
00:25:11.110 --> 00:25:13.860
<v Speaker 1>you see this is what the network </v>
<v Speaker 1>protects,</v>

397
00:25:13.870 --> 00:25:14.703
<v Speaker 1>what the human would drive and you see </v>
<v Speaker 1>that line markings here are lousy and </v>

398
00:25:17.511 --> 00:25:18.344
<v Speaker 1>then in part they're completely missing.</v>
<v Speaker 1>And that doesn't seem to impress the </v>

399
00:25:21.940 --> 00:25:23.530
<v Speaker 1>netvault keep people,</v>
<v Speaker 1>they still protects,</v>

400
00:25:23.900 --> 00:25:24.733
<v Speaker 1>protects the correct trajectory.</v>
<v Speaker 1>What do you see here is we show the </v>

401
00:25:29.390 --> 00:25:30.223
<v Speaker 1>trajectory is predicted from the most </v>
<v Speaker 1>recent 10 frames and then correct them </v>

402
00:25:34.121 --> 00:25:34.954
<v Speaker 1>for Iga motion of the car.</v>
<v Speaker 1>And then he showed them all on top of </v>

403
00:25:37.901 --> 00:25:39.970
<v Speaker 1>each other.</v>
<v Speaker 1>This is a debugging tool.</v>

404
00:25:40.020 --> 00:25:42.940
<v Speaker 1>Um,</v>
<v Speaker 1>if the network is confident,</v>

405
00:25:42.941 --> 00:25:43.774
<v Speaker 1>it will be consistent with its </v>
<v Speaker 1>predictions over a few frames and the </v>

406
00:25:47.681 --> 00:25:50.320
<v Speaker 1>noodles are nice and tight.</v>
<v Speaker 1>And if it's not confidence,</v>

407
00:25:50.321 --> 00:25:51.910
<v Speaker 1>then they'll spread out all over the </v>
<v Speaker 1>place.</v>

408
00:25:51.911 --> 00:25:53.890
<v Speaker 1>It will predict something different each</v>
<v Speaker 1>flame.</v>

409
00:25:56.100 --> 00:25:59.610
<v Speaker 1>So he had not to try taking,</v>
<v Speaker 1>take to the exit,</v>

410
00:25:59.780 --> 00:26:01.260
<v Speaker 1>uh,</v>
<v Speaker 1>or here again,</v>

411
00:26:01.500 --> 00:26:03.610
<v Speaker 1>this is all stuff that we haven't </v>
<v Speaker 1>programmed.</v>

412
00:26:03.630 --> 00:26:06.030
<v Speaker 1>They just picked it up by observing </v>
<v Speaker 1>humans.</v>

413
00:26:13.120 --> 00:26:15.060
<v Speaker 1>Um,</v>
<v Speaker 1>we're not limited to,</v>

414
00:26:15.080 --> 00:26:18.160
<v Speaker 1>to La on lane keeping.</v>
<v Speaker 1>We can also learn lane changes.</v>

415
00:26:18.400 --> 00:26:19.233
<v Speaker 1>So this is a video showing that the,</v>
<v Speaker 1>the lane changes or triggered manually </v>

416
00:26:24.131 --> 00:26:27.130
<v Speaker 1>by a,</v>
<v Speaker 1>this is change and here driving and he's</v>

417
00:26:28.190 --> 00:26:29.023
<v Speaker 1>uh,</v>
<v Speaker 1>he's just taping the Labor for the turn </v>

418
00:26:30.701 --> 00:26:33.500
<v Speaker 1>signal and that's,</v>
<v Speaker 1>that indicates to the corner they should</v>

419
00:26:33.540 --> 00:26:34.780
<v Speaker 1>now change lanes.</v>

420
00:26:37.040 --> 00:26:39.380
<v Speaker 1>We can also learn different,</v>
<v Speaker 1>uh,</v>

421
00:26:39.440 --> 00:26:40.273
<v Speaker 1>length of the lane changes.</v>
<v Speaker 1>So we can tell the car to do complete </v>

422
00:26:42.151 --> 00:26:46.770
<v Speaker 1>the lane change and two meters or 100 </v>
<v Speaker 1>meters or 50 meters.</v>

423
00:26:47.790 --> 00:26:49.670
<v Speaker 1>That's actually quite exciting.</v>
<v Speaker 1>Uh,</v>

424
00:26:49.671 --> 00:26:52.530
<v Speaker 1>I tie waist speeds,</v>
<v Speaker 1>completing lane change and 50 meters.</v>

425
00:26:55.400 --> 00:26:56.233
<v Speaker 3>We can also allow him to take,</v>
<v Speaker 3>this was particularly exciting because </v>

426
00:27:01.581 --> 00:27:05.390
<v Speaker 3>I'm not sure that's really any other </v>
<v Speaker 3>ways you should do this.</v>

427
00:27:12.980 --> 00:27:13.813
<v Speaker 3>Well,</v>
<v Speaker 3>I know if I wasn't he cuddled goals is </v>

428
00:27:14.691 --> 00:27:18.500
<v Speaker 3>to be able to send the car okay.</v>
<v Speaker 3>By fame,</v>

429
00:27:20.930 --> 00:27:25.930
<v Speaker 3>I would go back to the office.</v>
<v Speaker 3>Okay.</v>

430
00:28:49.440 --> 00:28:52.470
<v Speaker 1>So one of the things I mentioned before </v>
<v Speaker 1>that,</v>

431
00:28:52.520 --> 00:28:54.120
<v Speaker 1>uh,</v>
<v Speaker 1>it's important that,</v>

432
00:28:54.400 --> 00:28:58.440
<v Speaker 1>or an important aspect of our work is to</v>
<v Speaker 1>learn by observing humans,</v>

433
00:28:58.441 --> 00:29:01.710
<v Speaker 1>not by manually programming things into </v>
<v Speaker 1>the system,</v>

434
00:29:01.711 --> 00:29:04.020
<v Speaker 1>but nevertheless,</v>
<v Speaker 1>they want to understand what it actually</v>

435
00:29:04.021 --> 00:29:06.180
<v Speaker 1>learned.</v>
<v Speaker 1>So he'll be analyzed what,</v>

436
00:29:06.270 --> 00:29:09.530
<v Speaker 1>what is looking at this DC,</v>
<v Speaker 1>the green regions,</v>

437
00:29:09.540 --> 00:29:10.373
<v Speaker 1>these are the regions that the network </v>
<v Speaker 1>is sensitive to and you see that it </v>

438
00:29:15.010 --> 00:29:19.050
<v Speaker 1>learns to recognize that [inaudible] </v>
<v Speaker 1>Lane markings,</v>

439
00:29:20.070 --> 00:29:20.903
<v Speaker 1>which is interesting because we never </v>
<v Speaker 1>labeled a single lane marking during </v>

440
00:29:23.101 --> 00:29:25.860
<v Speaker 1>training or here in a residential </v>
<v Speaker 1>street.</v>

441
00:29:25.861 --> 00:29:26.694
<v Speaker 1>He learns to look at the cars.</v>
<v Speaker 1>But if you look closely and you can the </v>

442
00:29:29.401 --> 00:29:33.930
<v Speaker 1>trees here or on our campus,</v>
<v Speaker 1>if there's no clear lane markings,</v>

443
00:29:33.931 --> 00:29:36.160
<v Speaker 1>it learns to figure it out to the </v>
<v Speaker 1>Dextero.</v>

444
00:29:36.170 --> 00:29:37.620
<v Speaker 1>Dhs through other means.</v>

445
00:29:38.920 --> 00:29:39.290
<v Speaker 3>Okay.</v>

446
00:29:39.290 --> 00:29:42.280
<v Speaker 1>So this is an important,</v>
<v Speaker 1>a very important tool for us.</v>

447
00:29:42.790 --> 00:29:46.050
<v Speaker 1>Here's a short video,</v>
<v Speaker 1>you'll see a line match.</v>

448
00:29:46.810 --> 00:29:49.810
<v Speaker 1>So about the driving on the highway,</v>
<v Speaker 1>it's looking at both land markings,</v>

449
00:29:49.840 --> 00:29:50.673
<v Speaker 1>but this one will disappear in a moment.</v>
<v Speaker 1>And now instead of looking at the bowls </v>

450
00:29:55.121 --> 00:29:55.954
<v Speaker 1>of a doubly wide lane is actually just </v>
<v Speaker 1>following this one until the right one </v>

451
00:29:59.831 --> 00:30:02.560
<v Speaker 1>comes close enough so it becomes a </v>
<v Speaker 1>single lane again.</v>

452
00:30:03.310 --> 00:30:07.240
<v Speaker 1>And it picked that up by observing.</v>
<v Speaker 1>This is not us manually programming that</v>

453
00:30:07.270 --> 00:30:10.160
<v Speaker 1>into the system.</v>
<v Speaker 1>Um,</v>

454
00:30:10.200 --> 00:30:11.033
<v Speaker 1>at one point some day we needed a </v>
<v Speaker 1>screenshot from the inside of the car </v>

455
00:30:14.740 --> 00:30:17.620
<v Speaker 1>and there's a lot of construction going </v>
<v Speaker 1>on on the campus currently.</v>

456
00:30:17.621 --> 00:30:22.621
<v Speaker 1>And bobcat comes out into our old way.</v>
<v Speaker 1>And if you look here,</v>

457
00:30:23.020 --> 00:30:24.030
<v Speaker 1>the network,</v>
<v Speaker 1>uh,</v>

458
00:30:24.090 --> 00:30:24.923
<v Speaker 1>prominently recognizes it even though </v>
<v Speaker 1>we're quite soft and it's never seen </v>

459
00:30:28.001 --> 00:30:30.340
<v Speaker 1>this type of vehicle in the training </v>
<v Speaker 1>before.</v>

460
00:30:31.960 --> 00:30:32.690
<v Speaker 2>Yeah.</v>

461
00:30:32.690 --> 00:30:34.020
<v Speaker 1>So I wanted to close with,</v>
<v Speaker 1>uh,</v>

462
00:30:34.160 --> 00:30:36.720
<v Speaker 1>some open challenges.</v>
<v Speaker 1>My mind,</v>

463
00:30:36.760 --> 00:30:39.110
<v Speaker 1>these are,</v>
<v Speaker 1>while we have tons of open challenges,</v>

464
00:30:39.111 --> 00:30:39.944
<v Speaker 1>but these are two of the big ones.</v>
<v Speaker 1>One is to deal with ambiguous </v>

465
00:30:42.351 --> 00:30:43.184
<v Speaker 1>situations.</v>
<v Speaker 1>So if you imagine any won't allow them </v>

466
00:30:45.621 --> 00:30:48.320
<v Speaker 1>to merge onto a highway and you have a </v>
<v Speaker 1>car right next to you,</v>

467
00:30:48.800 --> 00:30:49.633
<v Speaker 1>then you can either speed up and go in </v>
<v Speaker 1>front or it can slow down and go behind </v>

468
00:30:53.740 --> 00:30:55.040
<v Speaker 1>what he can do,</v>
<v Speaker 1>the average.</v>

469
00:30:56.870 --> 00:30:58.790
<v Speaker 1>So how would we,</v>
<v Speaker 1>how would we deal with that hobby?</v>

470
00:30:58.791 --> 00:31:01.610
<v Speaker 1>Can learn from that as more than one </v>
<v Speaker 1>possible,</v>

471
00:31:01.730 --> 00:31:05.150
<v Speaker 1>a correct way of driving,</v>
<v Speaker 1>but you're only ever get one,</v>

472
00:31:05.870 --> 00:31:06.501
<v Speaker 1>one,</v>
<v Speaker 1>one,</v>

473
00:31:06.501 --> 00:31:08.690
<v Speaker 1>one of these possible options in each </v>
<v Speaker 1>example.</v>

474
00:31:09.200 --> 00:31:11.600
<v Speaker 1>And then the other one is learned from </v>
<v Speaker 1>imperfect behavior.</v>

475
00:31:11.810 --> 00:31:16.810
<v Speaker 1>So we have a ton and ton of data,</v>
<v Speaker 1>but currently we need to cut out all the</v>

476
00:31:17.541 --> 00:31:18.740
<v Speaker 1>imperfect driving.</v>

477
00:31:18.740 --> 00:31:22.220
<v Speaker 1>You don't want to teach the network to </v>
<v Speaker 1>cutting corners and such.</v>

478
00:31:22.530 --> 00:31:24.560
<v Speaker 1>Okay.</v>
<v Speaker 1>And Andy Dazzler on multiple,</v>

479
00:31:24.760 --> 00:31:26.870
<v Speaker 1>what do you do?</v>
<v Speaker 1>So it may makes the humans,</v>

480
00:31:27.770 --> 00:31:31.880
<v Speaker 1>so if we can get around and figured out </v>
<v Speaker 1>how he can learn on its own,</v>

481
00:31:31.940 --> 00:31:35.090
<v Speaker 1>what it actually should look at and </v>
<v Speaker 1>Modis for dot outliers,</v>

482
00:31:35.190 --> 00:31:37.760
<v Speaker 1>we would have a ton more data that we </v>
<v Speaker 1>can work with them.</v>

483
00:31:39.110 --> 00:31:42.410
<v Speaker 1>And so I will finish with this video </v>
<v Speaker 1>here.</v>

484
00:31:42.950 --> 00:31:45.410
<v Speaker 1>Uh,</v>
<v Speaker 1>this was recorded recently in December.</v>

485
00:31:45.650 --> 00:31:49.820
<v Speaker 1>We got new data from a new sensor set of</v>
<v Speaker 1>a new car fleet.</v>

486
00:31:49.880 --> 00:31:54.650
<v Speaker 1>And so the first 10 hours came in all </v>
<v Speaker 1>California data in the sun,</v>

487
00:31:54.830 --> 00:31:56.630
<v Speaker 1>very little night,</v>
<v Speaker 1>no rain.</v>

488
00:31:57.950 --> 00:32:00.400
<v Speaker 1>And so the first thing they usually do </v>
<v Speaker 1>is we train and networks.</v>

489
00:32:00.401 --> 00:32:03.260
<v Speaker 1>We go out and test to see if it meets </v>
<v Speaker 1>our expectations.</v>

490
00:32:03.261 --> 00:32:05.090
<v Speaker 1>This is kind of an end to end test to </v>
<v Speaker 1>see,</v>

491
00:32:05.091 --> 00:32:07.190
<v Speaker 1>to make sure that nothing's wrong with </v>
<v Speaker 1>this new data.</v>

492
00:32:08.020 --> 00:32:10.010
<v Speaker 1>Uh,</v>
<v Speaker 1>that day it happened to snow.</v>

493
00:32:10.100 --> 00:32:14.120
<v Speaker 1>So we were curious to see what happens </v>
<v Speaker 1>and it actually is,</v>

494
00:32:14.310 --> 00:32:15.400
<v Speaker 1>uh,</v>
<v Speaker 1>performed.</v>

495
00:32:15.401 --> 00:32:16.234
<v Speaker 1>Surprisingly.</v>
<v Speaker 1>My also all this network has ever seen </v>

496
00:32:17.891 --> 00:32:18.724
<v Speaker 1>is California data and is now driving in</v>
<v Speaker 1>the snow and no Chelsea or here at </v>

497
00:32:22.641 --> 00:32:23.480
<v Speaker 1>night,</v>
<v Speaker 1>uh,</v>

498
00:32:23.481 --> 00:32:28.481
<v Speaker 1>on a potluck snow covered road was a </v>
<v Speaker 1>lights from oncoming traffic.</v>

499
00:32:32.420 --> 00:32:33.253
<v Speaker 2>Okay.</v>

500
00:32:34.450 --> 00:32:36.840
<v Speaker 1>You can also see what it's looking at </v>
<v Speaker 1>and it,</v>

501
00:32:36.910 --> 00:32:40.420
<v Speaker 1>it looks at what seems correct on the </v>
<v Speaker 1>road here.</v>

502
00:32:40.421 --> 00:32:41.254
<v Speaker 1>It even looks at the tread of the tire </v>
<v Speaker 1>tread markings in this now even though </v>

503
00:32:45.381 --> 00:32:47.370
<v Speaker 1>it certainly hasn't seen that in,</v>
<v Speaker 1>uh,</v>

504
00:32:47.590 --> 00:32:52.160
<v Speaker 1>in the original training data.</v>
<v Speaker 1>And that brings me to the end.</v>

505
00:32:52.550 --> 00:32:53.630
<v Speaker 1>Thank you for your attention.</v>

