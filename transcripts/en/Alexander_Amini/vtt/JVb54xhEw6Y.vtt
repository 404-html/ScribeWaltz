WEBVTT

1
00:00:03.030 --> 00:00:03.863
<v Speaker 1>Hey,</v>
<v Speaker 1>thanks very much for the invitation to </v>

2
00:00:05.790 --> 00:00:07.770
<v Speaker 1>speak to you.</v>
<v Speaker 1>Um,</v>

3
00:00:08.010 --> 00:00:08.843
<v Speaker 1>yeah,</v>
<v Speaker 1>so I'm going to be talking about deep </v>

4
00:00:09.720 --> 00:00:11.550
<v Speaker 1>generative models.</v>
<v Speaker 1>Um,</v>

5
00:00:11.580 --> 00:00:13.980
<v Speaker 1>so when we talk about deep generative </v>
<v Speaker 1>models,</v>

6
00:00:13.981 --> 00:00:14.814
<v Speaker 1>what we're really talking about here </v>
<v Speaker 1>from my point of view is to essentially </v>

7
00:00:17.941 --> 00:00:20.140
<v Speaker 1>train neural nets,</v>
<v Speaker 1>uh,</v>

8
00:00:20.190 --> 00:00:24.120
<v Speaker 1>from training examples in order to </v>
<v Speaker 1>represent,</v>

9
00:00:24.150 --> 00:00:26.460
<v Speaker 1>uh,</v>
<v Speaker 1>the distribution from which these came.</v>

10
00:00:26.820 --> 00:00:27.653
<v Speaker 1>So we can think about this as either </v>
<v Speaker 1>explicitly doing density estimation </v>

11
00:00:30.571 --> 00:00:31.404
<v Speaker 1>where we have some samples here and we </v>
<v Speaker 1>try to model those samples with some </v>

12
00:00:34.111 --> 00:00:38.700
<v Speaker 1>density estimation.</v>
<v Speaker 1>Or we can think of it more like a this,</v>

13
00:00:38.701 --> 00:00:41.850
<v Speaker 1>which is what actually I'll be doing a </v>
<v Speaker 1>lot more of this kind of thing,</v>

14
00:00:41.851 --> 00:00:44.880
<v Speaker 1>which is to essentially we're worried </v>
<v Speaker 1>about sample generation here.</v>

15
00:00:44.881 --> 00:00:45.714
<v Speaker 1>So we have some training examples like </v>
<v Speaker 1>this where we're sort of just natural </v>

16
00:00:49.801 --> 00:00:53.430
<v Speaker 1>images from the world and we're asked </v>
<v Speaker 1>the asking a model to train,</v>

17
00:00:53.431 --> 00:00:56.370
<v Speaker 1>to learn to output images like this.</v>

18
00:00:56.370 --> 00:00:57.270
<v Speaker 1>Now,</v>
<v Speaker 1>uh,</v>

19
00:00:57.570 --> 00:00:58.403
<v Speaker 1>these are actually not true samples.</v>
<v Speaker 1>These are actually just other images </v>

20
00:01:02.431 --> 00:01:06.090
<v Speaker 1>from the same trainings.</v>
<v Speaker 1>I believe this is from image net.</v>

21
00:01:06.330 --> 00:01:07.163
<v Speaker 1>Uh,</v>
<v Speaker 1>a few years ago or even a few months </v>

22
00:01:09.180 --> 00:01:10.013
<v Speaker 1>ago,</v>
<v Speaker 1>this would have seemed obvious that </v>

23
00:01:11.011 --> 00:01:13.260
<v Speaker 1>this,</v>
<v Speaker 1>you couldn't generate samples like this,</v>

24
00:01:13.261 --> 00:01:14.094
<v Speaker 1>but in fact nowadays,</v>
<v Speaker 1>this is actually not so obvious that we </v>

25
00:01:16.471 --> 00:01:17.304
<v Speaker 1>couldn't generate these.</v>
<v Speaker 1>So it's been a very exciting time in </v>

26
00:01:19.441 --> 00:01:20.274
<v Speaker 1>this area,</v>
<v Speaker 1>in the amount of work we've done in the </v>

27
00:01:22.110 --> 00:01:22.943
<v Speaker 1>amount of progress we've made in the </v>
<v Speaker 1>last few years has been pretty </v>

28
00:01:24.991 --> 00:01:27.630
<v Speaker 1>remarkable.</v>
<v Speaker 1>And so I think part of what I want to do</v>

29
00:01:27.631 --> 00:01:29.760
<v Speaker 1>here is tell you a little bit about that</v>
<v Speaker 1>progress.</v>

30
00:01:29.761 --> 00:01:30.594
<v Speaker 1>Give you some sense of where we were in </v>
<v Speaker 1>say 2014 when this started really to </v>

31
00:01:35.610 --> 00:01:37.830
<v Speaker 1>accelerate and,</v>
<v Speaker 1>and where we are now.</v>

32
00:01:38.670 --> 00:01:39.690
<v Speaker 1>So,</v>
<v Speaker 1>yeah.</v>

33
00:01:39.691 --> 00:01:41.310
<v Speaker 1>So,</v>
<v Speaker 1>so why generative models?</v>

34
00:01:41.311 --> 00:01:43.140
<v Speaker 1>Why do we care about gender to modeling?</v>
<v Speaker 1>Well,</v>

35
00:01:43.141 --> 00:01:44.370
<v Speaker 1>there's a,</v>
<v Speaker 1>there's a bunch of reasons.</v>

36
00:01:44.490 --> 00:01:46.770
<v Speaker 1>Some of us are just really interested in</v>
<v Speaker 1>making pretty pictures.</v>

37
00:01:46.771 --> 00:01:49.950
<v Speaker 1>And I confess that for the most part,</v>
<v Speaker 1>that's what I'll be showing you today is</v>

38
00:01:49.951 --> 00:01:52.410
<v Speaker 1>just as an evaluation metric,</v>
<v Speaker 1>uh,</v>

39
00:01:52.650 --> 00:01:53.760
<v Speaker 1>we'll,</v>
<v Speaker 1>we'll just be looking at,</v>

40
00:01:53.761 --> 00:01:54.594
<v Speaker 1>at pictures,</v>
<v Speaker 1>I'm just natural images and how well </v>

41
00:01:56.581 --> 00:01:57.414
<v Speaker 1>we're doing in natural images.</v>
<v Speaker 1>But there's actually real tasks that we </v>

42
00:01:59.071 --> 00:02:00.660
<v Speaker 1>care about when we talk about gender to </v>
<v Speaker 1>modeling.</v>

43
00:02:00.840 --> 00:02:01.673
<v Speaker 1>One of them is just,</v>
<v Speaker 1>let's say you want to do some </v>

44
00:02:03.181 --> 00:02:05.430
<v Speaker 1>conditional generation,</v>
<v Speaker 1>like for example,</v>

45
00:02:05.790 --> 00:02:06.960
<v Speaker 1>machine translation,</v>
<v Speaker 1>right?</v>

46
00:02:06.961 --> 00:02:10.740
<v Speaker 1>So we're conditioning on some source </v>
<v Speaker 1>sentence and we want to output some,</v>

47
00:02:10.760 --> 00:02:11.970
<v Speaker 1>uh,</v>
<v Speaker 1>target sentence.</v>

48
00:02:12.060 --> 00:02:16.140
<v Speaker 1>Will the structure within that target </v>
<v Speaker 1>sentence that the target language,</v>

49
00:02:16.141 --> 00:02:18.000
<v Speaker 1>let's say that the,</v>
<v Speaker 1>the rules,</v>

50
00:02:18.030 --> 00:02:18.863
<v Speaker 1>the grammatical rules,</v>
<v Speaker 1>you can model that structure using a </v>

51
00:02:21.271 --> 00:02:24.000
<v Speaker 1>generative model.</v>
<v Speaker 1>So this is an instance of where we would</v>

52
00:02:24.001 --> 00:02:27.480
<v Speaker 1>do conditional generative modeling.</v>
<v Speaker 1>Another example,</v>

53
00:02:27.481 --> 00:02:28.261
<v Speaker 1>uh,</v>
<v Speaker 1>where,</v>

54
00:02:28.261 --> 00:02:29.094
<v Speaker 1>uh,</v>
<v Speaker 1>this is something that we're actually </v>

55
00:02:29.431 --> 00:02:30.264
<v Speaker 1>looking a little bit towards is,</v>
<v Speaker 1>is can we use generative models is </v>

56
00:02:33.171 --> 00:02:34.010
<v Speaker 1>outlier detection.</v>

57
00:02:34.080 --> 00:02:34.913
<v Speaker 1>And actually recently these types of </v>
<v Speaker 1>models have been integrated into rl </v>

58
00:02:38.280 --> 00:02:41.010
<v Speaker 1>algorithms to help them do exploration </v>
<v Speaker 1>more effectively.</v>

59
00:02:41.280 --> 00:02:43.020
<v Speaker 1>This was duct work done,</v>
<v Speaker 1>um,</v>

60
00:02:43.080 --> 00:02:43.950
<v Speaker 1>at deep mind,</v>
<v Speaker 1>I believe.</v>

61
00:02:44.640 --> 00:02:45.510
<v Speaker 1>Uh,</v>
<v Speaker 1>so here we're,</v>

62
00:02:45.680 --> 00:02:46.920
<v Speaker 1>we're,</v>
<v Speaker 1>we're looking at,</v>

63
00:02:46.921 --> 00:02:47.820
<v Speaker 1>you know,</v>
<v Speaker 1>a case where,</v>

64
00:02:48.500 --> 00:02:50.070
<v Speaker 1>you know,</v>
<v Speaker 1>if you can think about kind of a,</v>

65
00:02:50.071 --> 00:02:53.370
<v Speaker 1>this is a toy toyish version of the </v>
<v Speaker 1>autonomous vehicle,</v>

66
00:02:53.490 --> 00:02:54.323
<v Speaker 1>the task,</v>
<v Speaker 1>and you want to be able to distinguish </v>

67
00:02:55.710 --> 00:02:56.543
<v Speaker 1>cars and wheelchairs and then you're </v>
<v Speaker 1>going to have something like this and </v>

68
00:02:58.951 --> 00:03:01.690
<v Speaker 1>you don't want your classifier to just </v>
<v Speaker 1>blindly say,</v>

69
00:03:01.691 --> 00:03:02.524
<v Speaker 1>oh,</v>
<v Speaker 1>I think it's either a car or a </v>

70
00:03:03.641 --> 00:03:04.474
<v Speaker 1>wheelchair.</v>
<v Speaker 1>You want your classifier to understand </v>

71
00:03:06.521 --> 00:03:08.350
<v Speaker 1>that this is an outlier,</v>
<v Speaker 1>right?</v>

72
00:03:08.351 --> 00:03:09.184
<v Speaker 1>And you can use generative modeling to </v>
<v Speaker 1>be able to do that by noticing that </v>

73
00:03:12.521 --> 00:03:16.570
<v Speaker 1>there aren't very many things like this </v>
<v Speaker 1>example from the training set.</v>

74
00:03:16.840 --> 00:03:18.430
<v Speaker 1>So you can proceed with caution.</v>

75
00:03:18.790 --> 00:03:20.330
<v Speaker 1>And this is kind of a big deal,</v>
<v Speaker 1>right?</v>

76
00:03:20.331 --> 00:03:21.880
<v Speaker 1>Because we don't want,</v>
<v Speaker 1>our classifiers are,</v>

77
00:03:22.090 --> 00:03:24.520
<v Speaker 1>our neural net classifiers are very,</v>
<v Speaker 1>very capable of,</v>

78
00:03:24.521 --> 00:03:26.650
<v Speaker 1>of doing excellent performance </v>
<v Speaker 1>classification.</v>

79
00:03:26.651 --> 00:03:27.484
<v Speaker 1>But,</v>
<v Speaker 1>but any classifiers just trained to </v>

80
00:03:28.631 --> 00:03:31.450
<v Speaker 1>output one of the classes that it's been</v>
<v Speaker 1>given.</v>

81
00:03:31.780 --> 00:03:32.830
<v Speaker 1>And so,</v>
<v Speaker 1>uh,</v>

82
00:03:32.831 --> 00:03:37.270
<v Speaker 1>in cases where we actually are faced </v>
<v Speaker 1>with something really new and that's not</v>

83
00:03:37.271 --> 00:03:38.104
<v Speaker 1>seen before or perhaps a illumination </v>
<v Speaker 1>conditions that it's never been trained </v>

84
00:03:41.171 --> 00:03:43.300
<v Speaker 1>to,</v>
<v Speaker 1>to cope with.</v>

85
00:03:43.720 --> 00:03:46.570
<v Speaker 1>We want models that are conservative in </v>
<v Speaker 1>those cases.</v>

86
00:03:47.260 --> 00:03:49.300
<v Speaker 1>So we hope to be able to use generative </v>
<v Speaker 1>models for that.</v>

87
00:03:49.570 --> 00:03:50.403
<v Speaker 1>Another case where we're looking at </v>
<v Speaker 1>generative models being useful is in </v>

88
00:03:53.531 --> 00:03:56.070
<v Speaker 1>going from simulation to real,</v>
<v Speaker 1>uh,</v>

89
00:03:56.080 --> 00:03:58.150
<v Speaker 1>examples of in robotics.</v>
<v Speaker 1>So,</v>

90
00:03:58.360 --> 00:03:59.193
<v Speaker 1>so in robotics training these robots </v>
<v Speaker 1>with neural nets is actually quite </v>

91
00:04:02.200 --> 00:04:03.033
<v Speaker 1>laborious.</v>
<v Speaker 1>If you're really trying to do this on </v>

92
00:04:04.991 --> 00:04:06.160
<v Speaker 1>the real robot,</v>
<v Speaker 1>it would take many,</v>

93
00:04:06.161 --> 00:04:09.670
<v Speaker 1>many trials and it's,</v>
<v Speaker 1>it's not really practical in simulation.</v>

94
00:04:09.670 --> 00:04:10.690
<v Speaker 1>This works much,</v>
<v Speaker 1>much better.</v>

95
00:04:10.691 --> 00:04:11.524
<v Speaker 1>But the problem is,</v>
<v Speaker 1>is that if you train a policy and </v>

96
00:04:13.031 --> 00:04:15.820
<v Speaker 1>simulation and transfer it to the real </v>
<v Speaker 1>robot,</v>

97
00:04:16.030 --> 00:04:18.820
<v Speaker 1>well that's not going to work well.</v>
<v Speaker 1>That hasn't worked very well because the</v>

98
00:04:18.821 --> 00:04:19.654
<v Speaker 1>environment is just too different.</v>
<v Speaker 1>But what if we could use a generative </v>

99
00:04:21.551 --> 00:04:25.600
<v Speaker 1>model to make our simulations so </v>
<v Speaker 1>realistic that that transfer is viable?</v>

100
00:04:26.170 --> 00:04:28.420
<v Speaker 1>So this is the one,</v>
<v Speaker 1>another area that a number of groups are</v>

101
00:04:28.421 --> 00:04:31.870
<v Speaker 1>looking at this kind of x pushing gender</v>
<v Speaker 1>modeling in this direction.</v>

102
00:04:32.020 --> 00:04:32.853
<v Speaker 1>So there's lots of really practical ways</v>
<v Speaker 1>to use generate models beyond just </v>

103
00:04:35.831 --> 00:04:37.900
<v Speaker 1>looking at pretty pictures.</v>
<v Speaker 1>Um,</v>

104
00:04:38.530 --> 00:04:39.130
<v Speaker 1>right.</v>
<v Speaker 1>So,</v>

105
00:04:39.130 --> 00:04:39.963
<v Speaker 1>so I,</v>
<v Speaker 1>I break down the kinds of generative </v>

106
00:04:41.561 --> 00:04:45.340
<v Speaker 1>models there are in the world and to two</v>
<v Speaker 1>rough categories here.</v>

107
00:04:45.341 --> 00:04:47.170
<v Speaker 1>And maybe we can take issue with this.</v>
<v Speaker 1>Oh,</v>

108
00:04:47.171 --> 00:04:49.060
<v Speaker 1>by the way,</v>
<v Speaker 1>if you guys have questions,</v>

109
00:04:49.420 --> 00:04:51.670
<v Speaker 1>go ahead and ahead and ask me a while.</v>

110
00:04:51.670 --> 00:04:52.670
<v Speaker 1>You have them.</v>
<v Speaker 1>I think I,</v>

111
00:04:52.671 --> 00:04:55.510
<v Speaker 1>I like interaction as possible or you </v>
<v Speaker 1>can just save them to the end.</v>

112
00:04:55.810 --> 00:04:57.550
<v Speaker 1>Either way is fine.</v>
<v Speaker 1>Um,</v>

113
00:04:58.000 --> 00:05:00.550
<v Speaker 1>and sorry for my voice,</v>
<v Speaker 1>I've got a cold.</v>

114
00:05:00.910 --> 00:05:01.481
<v Speaker 1>Uh,</v>
<v Speaker 1>so yeah,</v>

115
00:05:01.481 --> 00:05:05.170
<v Speaker 1>we have auto regressive models and we </v>
<v Speaker 1>have latent variable models.</v>

116
00:05:05.890 --> 00:05:06.723
<v Speaker 1>So auto regressive models are models </v>
<v Speaker 1>where you basically define an ordering </v>

117
00:05:11.201 --> 00:05:12.910
<v Speaker 1>over your input,</v>
<v Speaker 1>right?</v>

118
00:05:12.911 --> 00:05:17.860
<v Speaker 1>So for things like speech recognition or</v>
<v Speaker 1>strather speech synthesis and the gender</v>

119
00:05:17.861 --> 00:05:19.720
<v Speaker 1>and modeling case,</v>
<v Speaker 1>this is natural,</v>

120
00:05:19.721 --> 00:05:20.321
<v Speaker 1>right?</v>
<v Speaker 1>It's just,</v>

121
00:05:20.321 --> 00:05:21.154
<v Speaker 1>there's a natural ordering to that data.</v>
<v Speaker 1>It's just the temporal sequence for </v>

122
00:05:24.701 --> 00:05:26.980
<v Speaker 1>things like images.</v>
<v Speaker 1>It's a little less obvious how you would</v>

123
00:05:26.981 --> 00:05:30.820
<v Speaker 1>define an ordering over pixels.</v>
<v Speaker 1>But there are nonetheless models such as</v>

124
00:05:30.821 --> 00:05:33.820
<v Speaker 1>a pixel rnn and Pixel cnn that do just </v>
<v Speaker 1>this.</v>

125
00:05:33.970 --> 00:05:35.440
<v Speaker 1>In fact,</v>
<v Speaker 1>pixel CNN is a,</v>

126
00:05:35.680 --> 00:05:38.230
<v Speaker 1>is a really interesting model from this </v>
<v Speaker 1>point of view.</v>

127
00:05:38.231 --> 00:05:41.990
<v Speaker 1>They basically define a convolutional </v>
<v Speaker 1>neural net with a mask.</v>

128
00:05:42.010 --> 00:05:44.380
<v Speaker 1>So if you remember our previous lecture </v>
<v Speaker 1>we did,</v>

129
00:05:44.381 --> 00:05:48.490
<v Speaker 1>we saw these convolutional neural nets,</v>
<v Speaker 1>but what they do is they stick a mask on</v>

130
00:05:48.491 --> 00:05:50.890
<v Speaker 1>it so that you've got sort of a causal </v>
<v Speaker 1>direction.</v>

131
00:05:50.891 --> 00:05:51.724
<v Speaker 1>So you're only looking at previous </v>
<v Speaker 1>pixels in the ordering that you've </v>

132
00:05:55.031 --> 00:05:56.470
<v Speaker 1>defined the,</v>
<v Speaker 1>the,</v>

133
00:05:56.471 --> 00:05:57.304
<v Speaker 1>the,</v>
<v Speaker 1>um,</v>

134
00:05:57.620 --> 00:05:59.180
<v Speaker 1>the,</v>
<v Speaker 1>well,</v>

135
00:05:59.210 --> 00:06:02.150
<v Speaker 1>the ordering that defined by the,</v>
<v Speaker 1>the auto regressive model.</v>

136
00:06:02.390 --> 00:06:04.610
<v Speaker 1>So,</v>
<v Speaker 1>so you kind of maintain this,</v>

137
00:06:04.820 --> 00:06:08.900
<v Speaker 1>this ordering as you go through the </v>
<v Speaker 1>confident and what that allows you to do</v>

138
00:06:08.901 --> 00:06:11.980
<v Speaker 1>is come up with a generative model </v>
<v Speaker 1>that's supported by this continent,</v>

139
00:06:12.280 --> 00:06:12.730
<v Speaker 1>uh,</v>
<v Speaker 1>that,</v>

140
00:06:12.730 --> 00:06:13.563
<v Speaker 1>you know,</v>
<v Speaker 1>it's just a full generative model and </v>

141
00:06:14.811 --> 00:06:15.644
<v Speaker 1>it's a,</v>
<v Speaker 1>it's a pretty interesting model in its </v>

142
00:06:16.491 --> 00:06:17.324
<v Speaker 1>own right.</v>
<v Speaker 1>But because of I have rather limited </v>

143
00:06:19.251 --> 00:06:20.084
<v Speaker 1>time,</v>
<v Speaker 1>I'm actually not going to go into that </v>

144
00:06:21.771 --> 00:06:22.604
<v Speaker 1>model in particular.</v>
<v Speaker 1>Another thing I just want to point out </v>

145
00:06:24.021 --> 00:06:24.854
<v Speaker 1>here is that wave net is probably the </v>
<v Speaker 1>state of the art model for speech </v>

146
00:06:28.731 --> 00:06:29.870
<v Speaker 1>synthesis right now.</v>

147
00:06:29.870 --> 00:06:32.990
<v Speaker 1>And it forms the basis of a very </v>
<v Speaker 1>interesting speech synthesis systems.</v>

148
00:06:33.140 --> 00:06:33.973
<v Speaker 1>It's another area where gender models </v>
<v Speaker 1>have made remarkable contributions in </v>

149
00:06:36.471 --> 00:06:38.720
<v Speaker 1>the last few years,</v>
<v Speaker 1>even the last few months.</v>

150
00:06:38.960 --> 00:06:39.793
<v Speaker 1>So now we're seeing models that you </v>
<v Speaker 1>would be fairly hard pressed to </v>

151
00:06:42.291 --> 00:06:43.124
<v Speaker 1>distinguish between natural speech and </v>
<v Speaker 1>and these kinds of models for the most </v>

152
00:06:47.241 --> 00:06:49.760
<v Speaker 1>part.</v>
<v Speaker 1>So what I'm going to concentrate on is a</v>

153
00:06:49.761 --> 00:06:50.594
<v Speaker 1>latent variable models.</v>
<v Speaker 1>So latent variable models are models </v>

154
00:06:54.140 --> 00:06:58.910
<v Speaker 1>that essentially posit that you have </v>
<v Speaker 1>some latent variables that are hope that</v>

155
00:06:58.911 --> 00:07:03.560
<v Speaker 1>you hope will represent some latent </v>
<v Speaker 1>factors of variation in the data,</v>

156
00:07:04.010 --> 00:07:04.850
<v Speaker 1>right?</v>
<v Speaker 1>So these are,</v>

157
00:07:05.030 --> 00:07:06.800
<v Speaker 1>these are things that as you wiggle </v>
<v Speaker 1>them,</v>

158
00:07:06.830 --> 00:07:10.610
<v Speaker 1>they're going to move the data in,</v>
<v Speaker 1>in what you hope will be natural ways.</v>

159
00:07:10.640 --> 00:07:12.500
<v Speaker 1>Right?</v>
<v Speaker 1>So you can imagine a latent variable for</v>

160
00:07:12.501 --> 00:07:16.670
<v Speaker 1>images corresponding to illumination </v>
<v Speaker 1>conditions,</v>

161
00:07:16.671 --> 00:07:18.980
<v Speaker 1>right?</v>
<v Speaker 1>Or if their faces a common,</v>

162
00:07:19.010 --> 00:07:19.843
<v Speaker 1>it's a common thing.</v>
<v Speaker 1>We find is latent variable corresponded </v>

163
00:07:21.021 --> 00:07:21.950
<v Speaker 1>to a smart,</v>
<v Speaker 1>right?</v>

164
00:07:21.950 --> 00:07:26.390
<v Speaker 1>So if we move this latent variable,</v>
<v Speaker 1>the image that we see that we generate,</v>

165
00:07:26.420 --> 00:07:29.330
<v Speaker 1>you know,</v>
<v Speaker 1>a smile appears and disappears and these</v>

166
00:07:29.331 --> 00:07:33.550
<v Speaker 1>are the kind of latent variables that we</v>
<v Speaker 1>want and we want to discover these.</v>

167
00:07:33.551 --> 00:07:36.380
<v Speaker 1>So this is really a challenging task in </v>
<v Speaker 1>general.</v>

168
00:07:36.381 --> 00:07:37.214
<v Speaker 1>We want to take natural data,</v>
<v Speaker 1>just unlabeled data and discover these </v>

169
00:07:40.221 --> 00:07:43.010
<v Speaker 1>latent factors that give rise to the </v>
<v Speaker 1>variation.</v>

170
00:07:43.011 --> 00:07:47.180
<v Speaker 1>We see there's two kinds of models in </v>
<v Speaker 1>this family that I'm going to be talking</v>

171
00:07:47.181 --> 00:07:48.014
<v Speaker 1>about.</v>
<v Speaker 1>A adversarial auto encoders and </v>

172
00:07:49.671 --> 00:07:51.920
<v Speaker 1>generative adversarial nets are gans </v>
<v Speaker 1>here.</v>

173
00:07:52.920 --> 00:07:53.753
<v Speaker 1>Uh,</v>
<v Speaker 1>I work personally with both of these </v>

174
00:07:54.831 --> 00:07:58.370
<v Speaker 1>kinds of models.</v>
<v Speaker 1>They serve different purposes for me.</v>

175
00:07:58.371 --> 00:07:59.204
<v Speaker 1>And,</v>
<v Speaker 1>uh,</v>

176
00:07:59.450 --> 00:08:00.430
<v Speaker 1>yeah,</v>
<v Speaker 1>well let's,</v>

177
00:08:00.540 --> 00:08:03.620
<v Speaker 1>let's dive in a,</v>
<v Speaker 1>so first I'll talk about,</v>

178
00:08:03.700 --> 00:08:05.910
<v Speaker 1>uh,</v>
<v Speaker 1>the variation all encoders.</v>

179
00:08:05.990 --> 00:08:09.680
<v Speaker 1>This actually was a model was developed </v>
<v Speaker 1>simultaneously by two different groups.</v>

180
00:08:10.100 --> 00:08:15.100
<v Speaker 1>One at a deep mind is the bottom one </v>
<v Speaker 1>here and then a king man dwelling at the</v>

181
00:08:15.620 --> 00:08:16.453
<v Speaker 1>University of Amsterdam.</v>

182
00:08:16.670 --> 00:08:18.620
<v Speaker 1>So again,</v>
<v Speaker 1>the idea behind the,</v>

183
00:08:18.621 --> 00:08:19.550
<v Speaker 1>uh,</v>
<v Speaker 1>the,</v>

184
00:08:19.580 --> 00:08:21.320
<v Speaker 1>uh,</v>
<v Speaker 1>the,</v>

185
00:08:22.040 --> 00:08:22.873
<v Speaker 1>the well latent variable models in </v>
<v Speaker 1>general is kind of represented in this </v>

186
00:08:26.271 --> 00:08:26.901
<v Speaker 1>picture,</v>
<v Speaker 1>right?</v>

187
00:08:26.901 --> 00:08:27.734
<v Speaker 1>So here's the space of our latent </v>
<v Speaker 1>variables and we consist this kind of </v>

188
00:08:30.081 --> 00:08:30.914
<v Speaker 1>represented as being fairly simple.</v>
<v Speaker 1>And we have our two coordinate zed one </v>

189
00:08:34.071 --> 00:08:37.400
<v Speaker 1>and zed too.</v>
<v Speaker 1>And they're independent in this case and</v>

190
00:08:37.401 --> 00:08:38.234
<v Speaker 1>they're sort of fairly regular and they </v>
<v Speaker 1>sort of form a chart for what is our </v>

191
00:08:41.901 --> 00:08:44.270
<v Speaker 1>complicated distribution here in,</v>
<v Speaker 1>in,</v>

192
00:08:44.271 --> 00:08:45.560
<v Speaker 1>in x space,</v>
<v Speaker 1>right?</v>

193
00:08:45.561 --> 00:08:46.394
<v Speaker 1>So this is,</v>
<v Speaker 1>you can think of this as third of the </v>

194
00:08:47.121 --> 00:08:47.954
<v Speaker 1>data manifold.</v>
<v Speaker 1>So you can think of this as image space </v>

195
00:08:49.581 --> 00:08:50.331
<v Speaker 1>for example,</v>
<v Speaker 1>right?</v>

196
00:08:50.331 --> 00:08:53.180
<v Speaker 1>So image space embedded in pixel space,</v>
<v Speaker 1>natural images,</v>

197
00:08:53.200 --> 00:08:55.680
<v Speaker 1>embedded pixel space form,</v>
<v Speaker 1>this kind of manifold.</v>

198
00:08:55.890 --> 00:08:58.650
<v Speaker 1>And what we want is coordinates that </v>
<v Speaker 1>allow you to,</v>

199
00:08:58.651 --> 00:09:01.050
<v Speaker 1>as you move sort of smoothly in this </v>
<v Speaker 1>space,</v>

200
00:09:01.170 --> 00:09:03.920
<v Speaker 1>move along this what can be a very </v>
<v Speaker 1>complicated manifold.</v>

201
00:09:04.360 --> 00:09:05.990
<v Speaker 1>And so that's the kind of hope.</v>
<v Speaker 1>What that,</v>

202
00:09:06.000 --> 00:09:07.950
<v Speaker 1>what,</v>
<v Speaker 1>what we're looking for when we do latent</v>

203
00:09:07.951 --> 00:09:11.240
<v Speaker 1>variable modeling.</v>
<v Speaker 1>So here's just an example of,</v>

204
00:09:11.260 --> 00:09:12.093
<v Speaker 1>of what I mean by exactly that.</v>
<v Speaker 1>This is an early example using these </v>

205
00:09:14.671 --> 00:09:17.810
<v Speaker 1>various channel auto encoders.</v>
<v Speaker 1>So here's a,</v>

206
00:09:17.820 --> 00:09:18.653
<v Speaker 1>the fray face data set,</v>
<v Speaker 1>just a whole bunch of images of Brendan </v>

207
00:09:21.121 --> 00:09:22.320
<v Speaker 1>phrase face.</v>
<v Speaker 1>Uh,</v>

208
00:09:22.321 --> 00:09:26.640
<v Speaker 1>that's in the Dataset.</v>
<v Speaker 1>What we're showing here is the model,</v>

209
00:09:26.670 --> 00:09:28.860
<v Speaker 1>the,</v>
<v Speaker 1>the model output,</v>

210
00:09:29.560 --> 00:09:30.393
<v Speaker 1>uh,</v>
<v Speaker 1>of this variational auto encoder for </v>

211
00:09:32.401 --> 00:09:33.234
<v Speaker 1>different values of these latent </v>
<v Speaker 1>variable zed one in zed to now we've </v>

212
00:09:36.811 --> 00:09:37.644
<v Speaker 1>kind of post hoc added these labels,</v>
<v Speaker 1>pose and expression on them because you </v>

213
00:09:41.431 --> 00:09:42.264
<v Speaker 1>see if as we move the zed to here,</v>
<v Speaker 1>you can see the expression kind of </v>

214
00:09:44.761 --> 00:09:45.594
<v Speaker 1>smoothly changes from what looks like a </v>
<v Speaker 1>frown to eventually smile and through </v>

215
00:09:49.651 --> 00:09:53.580
<v Speaker 1>what looks over here like a stinging as </v>
<v Speaker 1>well.</v>

216
00:09:53.650 --> 00:09:55.140
<v Speaker 1>Sticking his tongue out,</v>
<v Speaker 1>I guess.</v>

217
00:09:55.470 --> 00:09:56.303
<v Speaker 1>Uh,</v>
<v Speaker 1>and in this direction there's a slight </v>

218
00:09:58.200 --> 00:10:00.300
<v Speaker 1>head turn.</v>
<v Speaker 1>It's pretty subtle,</v>

219
00:10:00.301 --> 00:10:01.920
<v Speaker 1>but it's there.</v>
<v Speaker 1>So,</v>

220
00:10:02.310 --> 00:10:03.960
<v Speaker 1>so we did,</v>
<v Speaker 1>like I said,</v>

221
00:10:03.961 --> 00:10:04.794
<v Speaker 1>these were sort of post hoc,</v>
<v Speaker 1>added the model just discovered that </v>

222
00:10:06.931 --> 00:10:09.330
<v Speaker 1>these were two sources of variation in </v>
<v Speaker 1>the data,</v>

223
00:10:09.331 --> 00:10:10.164
<v Speaker 1>that we're relatively independent.</v>
<v Speaker 1>And the model just pulled those out for </v>

224
00:10:14.311 --> 00:10:15.870
<v Speaker 1>something like amnesty.</v>
<v Speaker 1>This is the,</v>

225
00:10:15.871 --> 00:10:18.720
<v Speaker 1>these are samples drawn on a model </v>
<v Speaker 1>trained by ethnicity.</v>

226
00:10:18.810 --> 00:10:20.100
<v Speaker 1>It's a little less natural,</v>
<v Speaker 1>right?</v>

227
00:10:20.101 --> 00:10:22.140
<v Speaker 1>Because in this case,</v>
<v Speaker 1>you could,</v>

228
00:10:22.500 --> 00:10:23.333
<v Speaker 1>you could argue the data.</v>
<v Speaker 1>It's really best model as something not </v>

229
00:10:25.171 --> 00:10:27.570
<v Speaker 1>with Leighton factors like continuously </v>
<v Speaker 1>and factors,</v>

230
00:10:27.571 --> 00:10:28.404
<v Speaker 1>but more like in clusters.</v>
<v Speaker 1>So you get this kind of somewhat </v>

231
00:10:30.871 --> 00:10:31.704
<v Speaker 1>interesting,</v>
<v Speaker 1>somewhat bizarre relationship where you </v>

232
00:10:33.841 --> 00:10:34.674
<v Speaker 1>know,</v>
<v Speaker 1>you've got some of this relationship </v>

233
00:10:35.551 --> 00:10:38.220
<v Speaker 1>with tilt happens here,</v>
<v Speaker 1>but then the ones heard of morphs into a</v>

234
00:10:38.221 --> 00:10:39.990
<v Speaker 1>seven,</v>
<v Speaker 1>which morphs into a nine.</v>

235
00:10:40.220 --> 00:10:41.053
<v Speaker 1>And you know,</v>
<v Speaker 1>because these different regions in this </v>

236
00:10:43.261 --> 00:10:46.620
<v Speaker 1>continuous space that represent </v>
<v Speaker 1>different examples here.</v>

237
00:10:49.560 --> 00:10:50.393
<v Speaker 1>So a little bit more detail into how we </v>
<v Speaker 1>do these kinds of a latent variable </v>

238
00:10:53.521 --> 00:10:54.354
<v Speaker 1>models,</v>
<v Speaker 1>at least in the context of the </v>

239
00:10:55.081 --> 00:10:57.960
<v Speaker 1>variational auto encoder or va model.</v>
<v Speaker 1>Um,</v>

240
00:10:58.170 --> 00:10:59.003
<v Speaker 1>so what we're trying to learn here is,</v>
<v Speaker 1>is p of x some distribution over the </v>

241
00:11:02.521 --> 00:11:03.354
<v Speaker 1>data.</v>
<v Speaker 1>We're trying to maximize the likelihood </v>

242
00:11:04.471 --> 00:11:05.940
<v Speaker 1>of the data.</v>
<v Speaker 1>That's it.</v>

243
00:11:06.150 --> 00:11:11.150
<v Speaker 1>But the way we're going to parameterize </v>
<v Speaker 1>our model is with a p of x given zed zed</v>

244
00:11:11.411 --> 00:11:13.350
<v Speaker 1>or is our latent variables,</v>
<v Speaker 1>I'm sorry to Z,</v>

245
00:11:13.470 --> 00:11:15.120
<v Speaker 1>I guess for you guys.</v>
<v Speaker 1>Uh,</v>

246
00:11:15.150 --> 00:11:17.940
<v Speaker 1>p of x given Z and then P of Z,</v>
<v Speaker 1>right?</v>

247
00:11:17.941 --> 00:11:20.070
<v Speaker 1>Some,</v>
<v Speaker 1>some prior distribution.</v>

248
00:11:20.100 --> 00:11:23.430
<v Speaker 1>Right?</v>
<v Speaker 1>So this P of z here is,</v>

249
00:11:23.580 --> 00:11:25.800
<v Speaker 1>is typically something simple,</v>
<v Speaker 1>right?</v>

250
00:11:25.801 --> 00:11:26.634
<v Speaker 1>It's some prior distribution.</v>
<v Speaker 1>We actually generally want it to be </v>

251
00:11:29.071 --> 00:11:29.904
<v Speaker 1>independent.</v>
<v Speaker 1>There's some modeling compromises to be </v>

252
00:11:31.501 --> 00:11:32.334
<v Speaker 1>made there.</v>
<v Speaker 1>But the reason why you'd want it </v>

253
00:11:33.061 --> 00:11:33.894
<v Speaker 1>independent is because that helps get </v>
<v Speaker 1>you the kind of orthogonal </v>

254
00:11:36.991 --> 00:11:37.890
<v Speaker 1>representation here.</v>

255
00:11:37.890 --> 00:11:40.470
<v Speaker 1>So these guys,</v>
<v Speaker 1>this dimension and this dimension,</v>

256
00:11:40.471 --> 00:11:41.304
<v Speaker 1>we want sort of not very much </v>
<v Speaker 1>interaction in order to make them more </v>

257
00:11:43.291 --> 00:11:46.080
<v Speaker 1>interpretable.</v>
<v Speaker 1>Um,</v>

258
00:11:46.140 --> 00:11:46.651
<v Speaker 1>yeah.</v>
<v Speaker 1>And so,</v>

259
00:11:46.651 --> 00:11:50.460
<v Speaker 1>and the other thing we want to do is we </v>
<v Speaker 1>want to think about how are we going to,</v>

260
00:11:50.700 --> 00:11:52.470
<v Speaker 1>so,</v>
<v Speaker 1>so going from something simple,</v>

261
00:11:52.471 --> 00:11:53.304
<v Speaker 1>like you can think about this as like in</v>
<v Speaker 1>a Gaussian distribution or a uniform </v>

262
00:11:55.541 --> 00:11:56.374
<v Speaker 1>distribution,</v>
<v Speaker 1>but now we want a model g here that </v>

263
00:11:58.951 --> 00:12:02.950
<v Speaker 1>transforms zed from this space into this</v>
<v Speaker 1>complicated space.</v>

264
00:12:03.250 --> 00:12:05.230
<v Speaker 1>And the way we're going to do that is </v>
<v Speaker 1>with a neural net.</v>

265
00:12:05.440 --> 00:12:07.390
<v Speaker 1>Actually,</v>
<v Speaker 1>in all of the examples that I'm going to</v>

266
00:12:07.391 --> 00:12:08.920
<v Speaker 1>show you today,</v>
<v Speaker 1>the way we're going to do that is with a</v>

267
00:12:08.921 --> 00:12:11.680
<v Speaker 1>convolutional neural net.</v>
<v Speaker 1>And the way to think about that,</v>

268
00:12:11.860 --> 00:12:12.693
<v Speaker 1>it's a bit of an interesting thing to </v>
<v Speaker 1>think about going from some fully </v>

269
00:12:14.771 --> 00:12:15.604
<v Speaker 1>connected things that into some two </v>
<v Speaker 1>dimensional input with a typology here </v>

270
00:12:21.860 --> 00:12:24.160
<v Speaker 1>in the natural image space x.</v>

271
00:12:24.370 --> 00:12:27.070
<v Speaker 1>And so it's just the way going from a,</v>
<v Speaker 1>what we talked about,</v>

272
00:12:27.071 --> 00:12:27.904
<v Speaker 1>it's kind of like the opposite path of </v>
<v Speaker 1>where you would take to do a confidante </v>

273
00:12:30.731 --> 00:12:32.310
<v Speaker 1>classification.</v>
<v Speaker 1>Um,</v>

274
00:12:32.590 --> 00:12:34.510
<v Speaker 1>there's a few different ways you could </v>
<v Speaker 1>think about doing that.</v>

275
00:12:34.660 --> 00:12:36.940
<v Speaker 1>One of which is called a transposed </v>
<v Speaker 1>convolution.</v>

276
00:12:36.941 --> 00:12:39.280
<v Speaker 1>This turns out to not to be such a good </v>
<v Speaker 1>idea.</v>

277
00:12:39.490 --> 00:12:40.323
<v Speaker 1>Uh,</v>
<v Speaker 1>this is a case where you essentially </v>

278
00:12:41.230 --> 00:12:43.220
<v Speaker 1>fill in a bunch of Zeros.</v>
<v Speaker 1>Uh,</v>

279
00:12:43.270 --> 00:12:46.660
<v Speaker 1>it seems like the most acceptable way to</v>
<v Speaker 1>do that right now is to just,</v>

280
00:12:46.870 --> 00:12:49.480
<v Speaker 1>once you get some small level typology </v>
<v Speaker 1>here,</v>

281
00:12:49.481 --> 00:12:51.640
<v Speaker 1>you just,</v>
<v Speaker 1>you do interpolation.</v>

282
00:12:51.850 --> 00:12:53.790
<v Speaker 1>So you just,</v>
<v Speaker 1>you know,</v>

283
00:12:53.890 --> 00:12:55.630
<v Speaker 1>super sample from the image.</v>
<v Speaker 1>Uh,</v>

284
00:12:55.690 --> 00:13:00.280
<v Speaker 1>you can do by linear interpolation and </v>
<v Speaker 1>then do a conflict preserves that size.</v>

285
00:13:00.281 --> 00:13:02.320
<v Speaker 1>And then up sample again,</v>
<v Speaker 1>comp up,</v>

286
00:13:02.321 --> 00:13:04.990
<v Speaker 1>sample comp,</v>
<v Speaker 1>that tends to give you the best results.</v>

287
00:13:06.230 --> 00:13:06.581
<v Speaker 1>So,</v>
<v Speaker 1>right?</v>

288
00:13:06.581 --> 00:13:09.850
<v Speaker 1>So when you see this kind of thing,</v>
<v Speaker 1>this kind of thing for our purposes,</v>

289
00:13:09.851 --> 00:13:11.860
<v Speaker 1>think convolutional neural net.</v>

290
00:13:13.070 --> 00:13:15.750
<v Speaker 1>All right?</v>
<v Speaker 1>So it's important to point out that that</v>

291
00:13:15.760 --> 00:13:17.770
<v Speaker 1>if we had,</v>
<v Speaker 1>uh,</v>

292
00:13:17.980 --> 00:13:20.430
<v Speaker 1>if we had over here,</v>
<v Speaker 1>uh,</v>

293
00:13:20.470 --> 00:13:21.303
<v Speaker 1>ceds that go went,</v>
<v Speaker 1>where's this [inaudible] that went with </v>

294
00:13:22.991 --> 00:13:24.130
<v Speaker 1>our ex,</v>
<v Speaker 1>uh,</v>

295
00:13:24.170 --> 00:13:25.003
<v Speaker 1>we'd be done right?</v>
<v Speaker 1>Because this is just a supervised </v>

296
00:13:26.111 --> 00:13:28.210
<v Speaker 1>learning problem at this point.</v>
<v Speaker 1>And we'd be fine.</v>

297
00:13:28.480 --> 00:13:29.880
<v Speaker 1>The trick is these are latent,</v>
<v Speaker 1>right?</v>

298
00:13:30.000 --> 00:13:31.840
<v Speaker 1>Need their hidden.</v>
<v Speaker 1>We don't know these sets.</v>

299
00:13:31.841 --> 00:13:33.400
<v Speaker 1>We don't have,</v>
<v Speaker 1>we haven't discovered them yet.</v>

300
00:13:33.880 --> 00:13:37.000
<v Speaker 1>So how do we learn with this model?</v>
<v Speaker 1>Well,</v>

301
00:13:37.030 --> 00:13:37.863
<v Speaker 1>the way we're going to do it is we're </v>
<v Speaker 1>going to use a trick that's actually </v>

302
00:13:39.851 --> 00:13:41.570
<v Speaker 1>been around for quite some time.</v>
<v Speaker 1>Uh,</v>

303
00:13:41.571 --> 00:13:42.910
<v Speaker 1>it says,</v>
<v Speaker 1>this isn't particularly new.</v>

304
00:13:42.911 --> 00:13:46.480
<v Speaker 1>We're going to use a variation lower </v>
<v Speaker 1>bound on the data likelihood,</v>

305
00:13:47.080 --> 00:13:47.913
<v Speaker 1>right?</v>
<v Speaker 1>So it turns out that we can actually </v>

306
00:13:48.551 --> 00:13:49.980
<v Speaker 1>express,</v>
<v Speaker 1>uh,</v>

307
00:13:50.000 --> 00:13:51.700
<v Speaker 1>the,</v>
<v Speaker 1>the data likelihood heard.</v>

308
00:13:51.730 --> 00:13:52.563
<v Speaker 1>Again,</v>
<v Speaker 1>this is the thing we're trying to </v>

309
00:13:53.441 --> 00:13:54.274
<v Speaker 1>maximize.</v>
<v Speaker 1>We can express a lower bound for it </v>

310
00:13:56.800 --> 00:13:57.940
<v Speaker 1>given by something like that.</v>

311
00:13:57.940 --> 00:13:58.773
<v Speaker 1>So we posit that we have some cue </v>
<v Speaker 1>distribution of zed that estimates is </v>

312
00:14:02.380 --> 00:14:07.380
<v Speaker 1>the posterior of zed for a given X.</v>
<v Speaker 1>And we're trying to then um,</v>

313
00:14:08.350 --> 00:14:13.120
<v Speaker 1>I guess maximize this joint probability </v>
<v Speaker 1>over x and zed minus the log cues that,</v>

314
00:14:13.121 --> 00:14:15.820
<v Speaker 1>so this is,</v>
<v Speaker 1>this is this variation of lower bound.</v>

315
00:14:16.380 --> 00:14:17.213
<v Speaker 1>Um,</v>
<v Speaker 1>one of the ways we can express this is </v>

316
00:14:20.111 --> 00:14:23.080
<v Speaker 1>you're trying to find the cute from </v>
<v Speaker 1>[inaudible] point of view is if you were</v>

317
00:14:23.081 --> 00:14:23.914
<v Speaker 1>to find a cue that actually recovered </v>
<v Speaker 1>the exact posterior distribution over </v>

318
00:14:29.261 --> 00:14:32.830
<v Speaker 1>zed given x,</v>
<v Speaker 1>this would actually be a tight,</v>

319
00:14:32.831 --> 00:14:33.940
<v Speaker 1>lower bound,</v>
<v Speaker 1>right?</v>

320
00:14:34.390 --> 00:14:35.223
<v Speaker 1>So then we would for sure be optimizing </v>
<v Speaker 1>if we were at all now optimize this </v>

321
00:14:38.351 --> 00:14:41.230
<v Speaker 1>lower boundary would be for sure,</v>
<v Speaker 1>optimizing likelihood in practice.</v>

322
00:14:41.231 --> 00:14:43.090
<v Speaker 1>That's what we're going to do anyway.</v>
<v Speaker 1>We're going to have this lower bound,</v>

323
00:14:43.280 --> 00:14:44.113
<v Speaker 1>we're going to try to optimize it.</v>
<v Speaker 1>We're trying to raise that up in hopes </v>

324
00:14:46.271 --> 00:14:47.830
<v Speaker 1>of raising up our likelihood.</v>

325
00:14:48.130 --> 00:14:50.070
<v Speaker 1>Um,</v>
<v Speaker 1>but the problem is this posterior,</v>

326
00:14:50.090 --> 00:14:53.360
<v Speaker 1>the actual posterior of,</v>
<v Speaker 1>of say of this g model here,</v>

327
00:14:53.361 --> 00:14:54.194
<v Speaker 1>this neural net,</v>
<v Speaker 1>right?</v>

328
00:14:54.290 --> 00:14:56.450
<v Speaker 1>This is just some forward model neural </v>
<v Speaker 1>net.</v>

329
00:14:56.451 --> 00:15:00.350
<v Speaker 1>So computing the posterior of zed given </v>
<v Speaker 1>acts and tractable.</v>

330
00:15:00.680 --> 00:15:01.513
<v Speaker 1>We have no good way of doing this.</v>
<v Speaker 1>It's going to be some complicated thing </v>

331
00:15:03.411 --> 00:15:05.330
<v Speaker 1>and we have no sensible way of doing </v>
<v Speaker 1>this,</v>

332
00:15:05.450 --> 00:15:09.470
<v Speaker 1>so we're going to approximate it with </v>
<v Speaker 1>this queue in this way.</v>

333
00:15:09.471 --> 00:15:11.150
<v Speaker 1>So we're going to,</v>
<v Speaker 1>now we can actually,</v>

334
00:15:11.151 --> 00:15:12.950
<v Speaker 1>and what's interesting about this </v>
<v Speaker 1>formulation,</v>

335
00:15:12.951 --> 00:15:14.540
<v Speaker 1>and this is this is new to the </v>
<v Speaker 1>variation.</v>

336
00:15:14.541 --> 00:15:15.374
<v Speaker 1>A lot of queries they've started or just</v>
<v Speaker 1>reformulated this a little bit </v>

337
00:15:16.941 --> 00:15:20.390
<v Speaker 1>differently and what they've got is they</v>
<v Speaker 1>come up with this,</v>

338
00:15:20.450 --> 00:15:21.283
<v Speaker 1>this different expression here,</v>
<v Speaker 1>which actually can be thought of in two </v>

339
00:15:24.321 --> 00:15:26.720
<v Speaker 1>terms here.</v>
<v Speaker 1>One is the reconstruction term here.</v>

340
00:15:26.721 --> 00:15:28.670
<v Speaker 1>If you look at what this is,</v>
<v Speaker 1>this is just,</v>

341
00:15:28.671 --> 00:15:29.504
<v Speaker 1>you get some from some queue,</v>
<v Speaker 1>you get a zed and you're just trying to </v>

342
00:15:33.141 --> 00:15:36.290
<v Speaker 1>reconstruct x from that said,</v>
<v Speaker 1>so you start with x,</v>

343
00:15:36.320 --> 00:15:37.153
<v Speaker 1>you get a zed,</v>
<v Speaker 1>and then you're trying to do a </v>

344
00:15:38.001 --> 00:15:39.620
<v Speaker 1>reconstruction of x.</v>

345
00:15:39.620 --> 00:15:40.453
<v Speaker 1>From that said,</v>
<v Speaker 1>this is where the name variational auto </v>

346
00:15:42.201 --> 00:15:46.280
<v Speaker 1>encoder comes from is because this </v>
<v Speaker 1>really looks like an encoder on the side</v>

347
00:15:46.281 --> 00:15:47.114
<v Speaker 1>of queue here and a decoder here,</v>
<v Speaker 1>and you're just trying to minimize that </v>

348
00:15:50.271 --> 00:15:52.700
<v Speaker 1>reconstruction error.</v>
<v Speaker 1>But in addition to this,</v>

349
00:15:52.910 --> 00:15:56.750
<v Speaker 1>they add this regularization term,</v>
<v Speaker 1>and this is interesting,</v>

350
00:15:56.751 --> 00:15:57.584
<v Speaker 1>right?</v>
<v Speaker 1>So this is what they're doing here is </v>

351
00:15:58.281 --> 00:15:59.210
<v Speaker 1>they're basically saying,</v>
<v Speaker 1>well,</v>

352
00:15:59.270 --> 00:16:03.020
<v Speaker 1>we want to regularize this posterior and</v>
<v Speaker 1>there's actually new auto encoders don't</v>

353
00:16:03.021 --> 00:16:03.771
<v Speaker 1>have this,</v>
<v Speaker 1>right?</v>

354
00:16:03.771 --> 00:16:04.604
<v Speaker 1>So I'm just trying to regularize this </v>
<v Speaker 1>posterior to try to be a little bit </v>

355
00:16:08.661 --> 00:16:09.494
<v Speaker 1>closer to the prior here.</v>
<v Speaker 1>And it's a common mistake when people </v>

356
00:16:11.781 --> 00:16:12.614
<v Speaker 1>learn about this to sort of think that,</v>
<v Speaker 1>oh well the goal is for these things to </v>

357
00:16:14.541 --> 00:16:16.250
<v Speaker 1>actually match.</v>
<v Speaker 1>That would be terrible,</v>

358
00:16:16.251 --> 00:16:18.710
<v Speaker 1>right?</v>
<v Speaker 1>That means that you lose all information</v>

359
00:16:18.711 --> 00:16:19.544
<v Speaker 1>about x.</v>
<v Speaker 1>You definitely don't want these things </v>

360
00:16:20.331 --> 00:16:21.164
<v Speaker 1>to match.</v>

361
00:16:21.170 --> 00:16:22.003
<v Speaker 1>But it does act as a regular riser,</v>
<v Speaker 1>sort of as a counterpoint to this </v>

362
00:16:24.981 --> 00:16:25.814
<v Speaker 1>reconstruction term.</v>
<v Speaker 1>And so now we've talked a little bit </v>

363
00:16:29.061 --> 00:16:30.740
<v Speaker 1>about this,</v>
<v Speaker 1>but what is this queue?</v>

364
00:16:30.760 --> 00:16:32.800
<v Speaker 1>Well,</v>
<v Speaker 1>for the variation of wind coated,</v>

365
00:16:32.810 --> 00:16:34.360
<v Speaker 1>the queues going to be another neural </v>
<v Speaker 1>net.</v>

366
00:16:34.790 --> 00:16:35.623
<v Speaker 1>And in this case we can think of it.</v>
<v Speaker 1>This is just a straight confident for </v>

367
00:16:37.131 --> 00:16:40.310
<v Speaker 1>the case of natural images.</v>
<v Speaker 1>So again,</v>

368
00:16:40.311 --> 00:16:41.144
<v Speaker 1>we've got our lower bound,</v>
<v Speaker 1>their objective that we're trying to </v>

369
00:16:42.801 --> 00:16:47.801
<v Speaker 1>minimize and we're going to parameterize</v>
<v Speaker 1>q as this neural net confident that goes</v>

370
00:16:48.081 --> 00:16:48.914
<v Speaker 1>from x to zed and we've got now are </v>
<v Speaker 1>generative model here are decoder that </v>

371
00:16:53.211 --> 00:16:57.510
<v Speaker 1>goes from zed to x.</v>
<v Speaker 1>Um,</v>

372
00:16:57.660 --> 00:16:58.493
<v Speaker 1>I'm going to add a few more details to </v>
<v Speaker 1>make this thing actually Prac in </v>

373
00:17:01.101 --> 00:17:01.970
<v Speaker 1>practice.</v>
<v Speaker 1>I've till now,</v>

374
00:17:01.971 --> 00:17:04.430
<v Speaker 1>this is not to uh,</v>
<v Speaker 1>new,</v>

375
00:17:04.431 --> 00:17:05.264
<v Speaker 1>there's been instances of this kind of </v>
<v Speaker 1>formalism of an encoder network and a </v>

376
00:17:08.140 --> 00:17:08.973
<v Speaker 1>decoder network,</v>
<v Speaker 1>but what they do next is actually kind </v>

377
00:17:10.821 --> 00:17:11.210
<v Speaker 1>of interesting.</v>

378
00:17:11.210 --> 00:17:15.110
<v Speaker 1>They notice that that if they </v>
<v Speaker 1>parameterize this a certain way,</v>

379
00:17:15.111 --> 00:17:15.944
<v Speaker 1>if they say q is equal to it,</v>
<v Speaker 1>actually you can use any continuous </v>

380
00:17:18.741 --> 00:17:20.270
<v Speaker 1>distribution here,</v>
<v Speaker 1>but they pick a,</v>

381
00:17:20.450 --> 00:17:21.283
<v Speaker 1>a normal distribution here.</v>
<v Speaker 1>So q of x is some normal distribution </v>

382
00:17:24.561 --> 00:17:28.880
<v Speaker 1>where the parameters mew in sigma from </v>
<v Speaker 1>the defined this normal distribution are</v>

383
00:17:28.881 --> 00:17:33.230
<v Speaker 1>defined by this encoder network.</v>
<v Speaker 1>Then they can actually encode it.</v>

384
00:17:33.231 --> 00:17:35.420
<v Speaker 1>Like this is called the reprioritization</v>
<v Speaker 1>trick,</v>

385
00:17:35.600 --> 00:17:36.433
<v Speaker 1>where they take said our random variable</v>
<v Speaker 1>here is equal to some function of the </v>

386
00:17:39.801 --> 00:17:40.634
<v Speaker 1>input.</v>
<v Speaker 1>Mew Plus Sigma are scaling factor over </v>

387
00:17:42.831 --> 00:17:43.664
<v Speaker 1>some noise.</v>
<v Speaker 1>And what this allows us to do now when </v>

388
00:17:46.821 --> 00:17:48.920
<v Speaker 1>they formulate it this way,</v>
<v Speaker 1>is the one in training.</v>

389
00:17:48.921 --> 00:17:49.754
<v Speaker 1>This model,</v>
<v Speaker 1>they can actually back prop through the </v>

390
00:17:51.751 --> 00:17:55.710
<v Speaker 1>decoder and into the encoder to train </v>
<v Speaker 1>both models simultaneously.</v>

391
00:17:57.480 --> 00:18:01.080
<v Speaker 1>It looks a little bit like this.</v>
<v Speaker 1>So they can do for propagation,</v>

392
00:18:01.081 --> 00:18:06.000
<v Speaker 1>start with an ex forward propagate to </v>
<v Speaker 1>zed add noise here.</v>

393
00:18:06.060 --> 00:18:09.960
<v Speaker 1>That was that epsilon.</v>
<v Speaker 1>And then for propagate here to this x Ha</v>

394
00:18:10.050 --> 00:18:11.610
<v Speaker 1>hat,</v>
<v Speaker 1>which is our reconstruction,</v>

395
00:18:12.210 --> 00:18:15.030
<v Speaker 1>compute the air between x and x hat and </v>
<v Speaker 1>back,</v>

396
00:18:15.031 --> 00:18:17.160
<v Speaker 1>propagate that error all the way </v>
<v Speaker 1>through.</v>

397
00:18:19.620 --> 00:18:23.610
<v Speaker 1>And that allows them to actually train </v>
<v Speaker 1>this model very effectively in ways that</v>

398
00:18:23.611 --> 00:18:25.140
<v Speaker 1>we've never been able to train before </v>
<v Speaker 1>this.</v>

399
00:18:25.141 --> 00:18:28.200
<v Speaker 1>This card trick came up and when you do </v>
<v Speaker 1>that,</v>

400
00:18:28.201 --> 00:18:31.230
<v Speaker 1>this is the kind of thing that came out.</v>
<v Speaker 1>So this came out in 2014.</v>

401
00:18:31.350 --> 00:18:32.183
<v Speaker 1>These are actually really,</v>
<v Speaker 1>I promise these were really impressive </v>

402
00:18:33.481 --> 00:18:35.310
<v Speaker 1>results in,</v>
<v Speaker 1>in 2014.</v>

403
00:18:35.790 --> 00:18:37.500
<v Speaker 1>Um,</v>
<v Speaker 1>the first time we were seeing,</v>

404
00:18:37.501 --> 00:18:38.334
<v Speaker 1>so this is not a,</v>
<v Speaker 1>this is from the FDA labeled facing the </v>

405
00:18:39.961 --> 00:18:42.390
<v Speaker 1>wild these days we use celebrate,</v>
<v Speaker 1>um,</v>

406
00:18:42.660 --> 00:18:44.100
<v Speaker 1>and uh,</v>
<v Speaker 1>this is imaging it.</v>

407
00:18:44.101 --> 00:18:45.600
<v Speaker 1>So,</v>
<v Speaker 1>so not a whole lot there.</v>

408
00:18:45.601 --> 00:18:47.670
<v Speaker 1>Actually,</v>
<v Speaker 1>this is a small version of image net.</v>

409
00:18:48.090 --> 00:18:48.923
<v Speaker 1>Um,</v>
<v Speaker 1>but you can do things with this model </v>

410
00:18:51.481 --> 00:18:52.590
<v Speaker 1>actually.</v>
<v Speaker 1>So for example,</v>

411
00:18:52.591 --> 00:18:55.050
<v Speaker 1>one of the things that we've done with </v>
<v Speaker 1>this model is we actually just,</v>

412
00:18:55.220 --> 00:18:57.180
<v Speaker 1>we talked to,</v>
<v Speaker 1>I mentioned briefly this pixel,</v>

413
00:18:57.181 --> 00:18:58.980
<v Speaker 1>CNN,</v>
<v Speaker 1>we,</v>

414
00:18:59.010 --> 00:19:03.570
<v Speaker 1>we actually include this pixel cnn into </v>
<v Speaker 1>the decoder side.</v>

415
00:19:03.750 --> 00:19:05.400
<v Speaker 1>So one of the problems,</v>
<v Speaker 1>if I just go back,</v>

416
00:19:05.401 --> 00:19:06.234
<v Speaker 1>one of the problems why we get these </v>
<v Speaker 1>kinds of images is this model makes a </v>

417
00:19:08.611 --> 00:19:10.380
<v Speaker 1>lot of independence assumptions,</v>
<v Speaker 1>right?</v>

418
00:19:10.620 --> 00:19:11.453
<v Speaker 1>And part of it is,</v>
<v Speaker 1>is because we want those independents </v>

419
00:19:12.781 --> 00:19:14.550
<v Speaker 1>assumptions to make hers eds more </v>
<v Speaker 1>interpretable,</v>

420
00:19:14.610 --> 00:19:15.443
<v Speaker 1>but they have consequences to them.</v>
<v Speaker 1>And one of the consequences is you end </v>

421
00:19:18.121 --> 00:19:19.540
<v Speaker 1>up with kind of blurry images.</v>
<v Speaker 1>That's,</v>

422
00:19:19.590 --> 00:19:20.423
<v Speaker 1>that's part of why you end up with </v>
<v Speaker 1>biliary images because we're making </v>

423
00:19:22.111 --> 00:19:25.130
<v Speaker 1>these approximations in the variational,</v>
<v Speaker 1>um,</v>

424
00:19:25.830 --> 00:19:26.663
<v Speaker 1>lower bound.</v>
<v Speaker 1>And so by adding the pixel CNN that </v>

425
00:19:30.001 --> 00:19:33.270
<v Speaker 1>allows us to encode more complexity in </v>
<v Speaker 1>here.</v>

426
00:19:33.271 --> 00:19:34.104
<v Speaker 1>And by the way,</v>
<v Speaker 1>this is now a hierarchical version of </v>

427
00:19:35.491 --> 00:19:36.324
<v Speaker 1>the vie using pixel CNN that Lowe's,</v>
<v Speaker 1>the law allows us to encode sort of </v>

428
00:19:40.291 --> 00:19:42.600
<v Speaker 1>complicated distributions in zed one </v>
<v Speaker 1>here,</v>

429
00:19:42.800 --> 00:19:43.660
<v Speaker 1>uh,</v>
<v Speaker 1>given the,</v>

430
00:19:43.810 --> 00:19:46.650
<v Speaker 1>the upper levels eds and with this kind </v>
<v Speaker 1>of thing,</v>

431
00:19:46.870 --> 00:19:47.703
<v Speaker 1>uh,</v>
<v Speaker 1>this is the kind of images that we can </v>

432
00:19:48.451 --> 00:19:50.710
<v Speaker 1>just synthesize using this variational.</v>

433
00:19:50.730 --> 00:19:51.880
<v Speaker 1>Uh,</v>
<v Speaker 1>we'll call this the,</v>

434
00:19:51.881 --> 00:19:55.620
<v Speaker 1>the pixel vie model.</v>
<v Speaker 1>So a bedroom,</v>

435
00:19:55.650 --> 00:19:57.500
<v Speaker 1>these are bedrooms scenes,</v>
<v Speaker 1>uh,</v>

436
00:19:57.690 --> 00:20:01.530
<v Speaker 1>so you can sort of see it's reasonably </v>
<v Speaker 1>good clear bedroom scenes.</v>

437
00:20:01.531 --> 00:20:03.180
<v Speaker 1>And then image net,</v>
<v Speaker 1>which you're,</v>

438
00:20:03.510 --> 00:20:04.343
<v Speaker 1>that,</v>
<v Speaker 1>you know,</v>

439
00:20:04.360 --> 00:20:07.260
<v Speaker 1>you can see that it gets roughly the,</v>
<v Speaker 1>the texture's,</v>

440
00:20:07.261 --> 00:20:09.120
<v Speaker 1>right?</v>
<v Speaker 1>It's not really getting objects yet.</v>

441
00:20:09.121 --> 00:20:09.954
<v Speaker 1>Actually objects that are really tough </v>
<v Speaker 1>to get when you model things in an </v>

442
00:20:12.001 --> 00:20:14.610
<v Speaker 1>unconditional way.</v>
<v Speaker 1>What I mean by that is the model doesn't</v>

443
00:20:14.611 --> 00:20:16.320
<v Speaker 1>know that it's supposed to generate a </v>
<v Speaker 1>dog,</v>

444
00:20:16.321 --> 00:20:17.820
<v Speaker 1>let's say if it was going to generate </v>
<v Speaker 1>something.</v>

445
00:20:17.821 --> 00:20:20.700
<v Speaker 1>So it's just generating from p of x in </v>
<v Speaker 1>general.</v>

446
00:20:20.701 --> 00:20:23.330
<v Speaker 1>And it's actually pretty challenging </v>
<v Speaker 1>when we talk about image net.</v>

447
00:20:24.690 --> 00:20:25.620
<v Speaker 1>All right.</v>
<v Speaker 1>So,</v>

448
00:20:25.621 --> 00:20:29.640
<v Speaker 1>so that's one way we can improve the uh,</v>
<v Speaker 1>the va model.</v>

449
00:20:29.880 --> 00:20:33.330
<v Speaker 1>Another way we can improve the Vau </v>
<v Speaker 1>models work on the encoder side.</v>

450
00:20:33.600 --> 00:20:35.130
<v Speaker 1>And that was done,</v>
<v Speaker 1>uh,</v>

451
00:20:35.190 --> 00:20:36.670
<v Speaker 1>by uh,</v>
<v Speaker 1>uh,</v>

452
00:20:36.680 --> 00:20:40.680
<v Speaker 1>a few people but culminating I think in </v>
<v Speaker 1>the inverse auto regressive flow model.</v>

453
00:20:40.920 --> 00:20:43.520
<v Speaker 1>So this is actually a very effective way</v>
<v Speaker 1>to deal with it.</v>

454
00:20:43.650 --> 00:20:44.483
<v Speaker 1>The same kind of independence problems </v>
<v Speaker 1>we saw that we're addressing on the </v>

455
00:20:46.561 --> 00:20:48.520
<v Speaker 1>decoder side,</v>
<v Speaker 1>but they're addressing it on the encoder</v>

456
00:20:48.521 --> 00:20:51.610
<v Speaker 1>side.</v>
<v Speaker 1>So you can kind of see just briefly what</v>

457
00:20:51.611 --> 00:20:53.440
<v Speaker 1>this is doing.</v>
<v Speaker 1>So this is your prior distribution.</v>

458
00:20:53.441 --> 00:20:55.960
<v Speaker 1>Ideally you would like sort of the </v>
<v Speaker 1>marginal posterior,</v>

459
00:20:55.961 --> 00:20:56.794
<v Speaker 1>which is sort of like combining all </v>
<v Speaker 1>these things together to be as close to </v>

460
00:20:59.021 --> 00:21:04.021
<v Speaker 1>this as possible because any sort of </v>
<v Speaker 1>disagreement between those two is really</v>

461
00:21:04.511 --> 00:21:07.090
<v Speaker 1>a modeling error.</v>
<v Speaker 1>So it's an approximation error.</v>

462
00:21:07.210 --> 00:21:08.043
<v Speaker 1>So standard vie model is going to get </v>
<v Speaker 1>going to learn to do something like </v>

463
00:21:10.961 --> 00:21:11.561
<v Speaker 1>this,</v>
<v Speaker 1>which is,</v>

464
00:21:11.561 --> 00:21:12.394
<v Speaker 1>it's kind of as close as it can get to </v>
<v Speaker 1>this while still maintaining </v>

465
00:21:14.351 --> 00:21:18.460
<v Speaker 1>independence in the distributions.</v>
<v Speaker 1>Using this I f method,</v>

466
00:21:18.550 --> 00:21:20.770
<v Speaker 1>it's a bit of a complicated method that </v>
<v Speaker 1>involves many,</v>

467
00:21:20.771 --> 00:21:24.580
<v Speaker 1>many iterations of transformations that </v>
<v Speaker 1>you can actually,</v>

468
00:21:24.720 --> 00:21:25.553
<v Speaker 1>um,</v>
<v Speaker 1>compute that are actually invertible </v>

469
00:21:27.461 --> 00:21:27.820
<v Speaker 1>that.</v>

470
00:21:27.820 --> 00:21:29.770
<v Speaker 1>And you need this to be able to do the </v>
<v Speaker 1>computation.</v>

471
00:21:29.950 --> 00:21:31.630
<v Speaker 1>But with that you can get this kind of </v>
<v Speaker 1>thing,</v>

472
00:21:31.631 --> 00:21:34.030
<v Speaker 1>which is pretty much exactly what you'd </v>
<v Speaker 1>want in this setting.</v>

473
00:21:34.180 --> 00:21:35.980
<v Speaker 1>So we've played around with this model </v>
<v Speaker 1>and in fact,</v>

474
00:21:36.250 --> 00:21:38.860
<v Speaker 1>you know it,</v>
<v Speaker 1>we find it works really well in practice</v>

475
00:21:38.861 --> 00:21:40.210
<v Speaker 1>actually.</v>
<v Speaker 1>Um,</v>

476
00:21:40.600 --> 00:21:41.070
<v Speaker 1>yeah,</v>
<v Speaker 1>so,</v>

477
00:21:41.070 --> 00:21:41.681
<v Speaker 1>but it's,</v>
<v Speaker 1>again,</v>

478
00:21:41.681 --> 00:21:42.514
<v Speaker 1>it's on the encoder side.</v>
<v Speaker 1>What we were doing with the Pixel va's </v>

479
00:21:44.801 --> 00:21:47.290
<v Speaker 1>on the is working on the decoder side.</v>
<v Speaker 1>Um,</v>

480
00:21:47.500 --> 00:21:50.320
<v Speaker 1>but now,</v>
<v Speaker 1>so this is actually fairly complicated.</v>

481
00:21:50.321 --> 00:21:51.154
<v Speaker 1>Both these models actually fairly </v>
<v Speaker 1>complicated to use and a fairly </v>

482
00:21:53.531 --> 00:21:55.690
<v Speaker 1>involved.</v>
<v Speaker 1>So one question is,</v>

483
00:21:56.470 --> 00:21:59.560
<v Speaker 1>is there another way to train this model</v>
<v Speaker 1>but isn't quite so complicated?</v>

484
00:21:59.830 --> 00:22:00.460
<v Speaker 1>And,</v>
<v Speaker 1>uh,</v>

485
00:22:00.460 --> 00:22:01.420
<v Speaker 1>so,</v>
<v Speaker 1>uh,</v>

486
00:22:01.600 --> 00:22:03.830
<v Speaker 1>at the time a student of Yoshua Bengio </v>
<v Speaker 1>and I,</v>

487
00:22:03.860 --> 00:22:04.693
<v Speaker 1>uh,</v>
<v Speaker 1>Ian goodfellow was toying around with </v>

488
00:22:07.721 --> 00:22:11.410
<v Speaker 1>this idea and he came up with a </v>
<v Speaker 1>generative adversarial nets.</v>

489
00:22:11.950 --> 00:22:12.783
<v Speaker 1>And the way generative adversarial nets </v>
<v Speaker 1>work is it posits the learning of a </v>

490
00:22:15.821 --> 00:22:18.590
<v Speaker 1>generative model g,</v>
<v Speaker 1>um,</v>

491
00:22:18.640 --> 00:22:19.473
<v Speaker 1>in the form of a game.</v>
<v Speaker 1>So it's a game between this generative </v>

492
00:22:22.991 --> 00:22:23.824
<v Speaker 1>model g here and a discriminator d.</v>
<v Speaker 1>So the discriminators job is to try to </v>

493
00:22:33.191 --> 00:22:38.191
<v Speaker 1>tell the difference between true data </v>
<v Speaker 1>and data generated from the generator,</v>

494
00:22:39.340 --> 00:22:40.173
<v Speaker 1>right?</v>
<v Speaker 1>So it's trying to tell the difference </v>

495
00:22:40.811 --> 00:22:41.644
<v Speaker 1>between fake data that's generated by </v>
<v Speaker 1>the generator and true data from the </v>

496
00:22:45.460 --> 00:22:49.030
<v Speaker 1>trending distribution.</v>
<v Speaker 1>And it's just trained to do so.</v>

497
00:22:49.031 --> 00:22:51.100
<v Speaker 1>This guys trained to try to output one </v>
<v Speaker 1>if,</v>

498
00:22:51.120 --> 00:22:51.953
<v Speaker 1>if it's true data and output zero.</v>
<v Speaker 1>If it's fake data and the generator is </v>

499
00:22:55.691 --> 00:22:56.524
<v Speaker 1>being trained to fool the discriminator </v>
<v Speaker 1>by using its own gradience against it </v>

500
00:23:00.131 --> 00:23:02.550
<v Speaker 1>essentially.</v>
<v Speaker 1>So we back propagate the,</v>

501
00:23:02.551 --> 00:23:03.384
<v Speaker 1>the discriminate,</v>
<v Speaker 1>the discriminator air all the way </v>

502
00:23:05.711 --> 00:23:06.544
<v Speaker 1>through through x.</v>
<v Speaker 1>We usually have to use a continuous x </v>

503
00:23:10.541 --> 00:23:12.490
<v Speaker 1>for this and into the discriminator.</v>

504
00:23:12.490 --> 00:23:14.180
<v Speaker 1>Now we're going to change the parameters</v>
<v Speaker 1>of the,</v>

505
00:23:14.240 --> 00:23:19.240
<v Speaker 1>of the generator here in order to try to</v>
<v Speaker 1>maximally fool the discriminator.</v>

506
00:23:20.950 --> 00:23:22.540
<v Speaker 1>So in us,</v>
<v Speaker 1>sort of a more uh,</v>

507
00:23:23.190 --> 00:23:25.180
<v Speaker 1>um,</v>
<v Speaker 1>uh,</v>

508
00:23:25.630 --> 00:23:28.090
<v Speaker 1>I guess abstract way to represent this </v>
<v Speaker 1>looks like this.</v>

509
00:23:28.091 --> 00:23:28.924
<v Speaker 1>So we have the data on this side.</v>
<v Speaker 1>We have the discriminator here with its </v>

510
00:23:31.481 --> 00:23:32.410
<v Speaker 1>own parameters.</v>
<v Speaker 1>And this,</v>

511
00:23:32.411 --> 00:23:33.710
<v Speaker 1>again,</v>
<v Speaker 1>for our purposes,</v>

512
00:23:33.711 --> 00:23:35.650
<v Speaker 1>those almost always a convolutional </v>
<v Speaker 1>neural net.</v>

513
00:23:35.890 --> 00:23:36.723
<v Speaker 1>And then we have the generator,</v>
<v Speaker 1>which is again one of these kind of </v>

514
00:23:38.380 --> 00:23:41.130
<v Speaker 1>flipped convolutional models cause it </v>
<v Speaker 1>takes noises,</v>

515
00:23:41.200 --> 00:23:42.033
<v Speaker 1>input,</v>
<v Speaker 1>it needs noise because it needs </v>

516
00:23:42.890 --> 00:23:47.570
<v Speaker 1>variability and then it converts that </v>
<v Speaker 1>noise into something.</v>

517
00:23:47.571 --> 00:23:48.404
<v Speaker 1>An image space that's trained with these</v>
<v Speaker 1>parameters are trained to fool the </v>

518
00:23:51.051 --> 00:23:51.884
<v Speaker 1>discriminator.</v>

519
00:23:55.340 --> 00:23:56.340
<v Speaker 1>All right,</v>
<v Speaker 1>so you know,</v>

520
00:23:56.341 --> 00:23:57.930
<v Speaker 1>we can be a little bit more formal about</v>
<v Speaker 1>this.</v>

521
00:23:57.931 --> 00:24:00.150
<v Speaker 1>This is actually your objective function</v>
<v Speaker 1>we're training on.</v>

522
00:24:01.200 --> 00:24:02.730
<v Speaker 1>So let's just break this down for a </v>
<v Speaker 1>second.</v>

523
00:24:02.731 --> 00:24:04.860
<v Speaker 1>So from the discriminators point of </v>
<v Speaker 1>view,</v>

524
00:24:04.890 --> 00:24:06.030
<v Speaker 1>what is this?</v>
<v Speaker 1>This is just,</v>

525
00:24:06.060 --> 00:24:08.760
<v Speaker 1>it's called the cross entropy loss.</v>
<v Speaker 1>It's literally just what you would apply</v>

526
00:24:08.761 --> 00:24:10.920
<v Speaker 1>if you're doing a classification with </v>
<v Speaker 1>this discriminator.</v>

527
00:24:11.220 --> 00:24:14.190
<v Speaker 1>That's all this is from the generators </v>
<v Speaker 1>point of view,</v>

528
00:24:14.191 --> 00:24:16.290
<v Speaker 1>the generator comes in just right here,</v>
<v Speaker 1>right?</v>

529
00:24:16.530 --> 00:24:17.363
<v Speaker 1>It's the thing you draw these samples </v>
<v Speaker 1>from and it's trying to minimize while </v>

530
00:24:21.870 --> 00:24:25.530
<v Speaker 1>the discriminators trying to maximize </v>
<v Speaker 1>this quantity,</v>

531
00:24:25.710 --> 00:24:27.770
<v Speaker 1>this is essentially likelihood,</v>
<v Speaker 1>uh,</v>

532
00:24:28.020 --> 00:24:28.950
<v Speaker 1>and,</v>
<v Speaker 1>and,</v>

533
00:24:28.970 --> 00:24:31.950
<v Speaker 1>and the discriminant the generators </v>
<v Speaker 1>moving in the opposite direction,</v>

534
00:24:33.120 --> 00:24:33.953
<v Speaker 2>right?</v>

535
00:24:35.120 --> 00:24:38.470
<v Speaker 1>So we can analyze this,</v>
<v Speaker 1>this game to see,</v>

536
00:24:38.471 --> 00:24:39.261
<v Speaker 1>you know,</v>
<v Speaker 1>this is a question,</v>

537
00:24:39.261 --> 00:24:39.930
<v Speaker 1>right?</v>
<v Speaker 1>Does,</v>

538
00:24:39.930 --> 00:24:40.580
<v Speaker 1>well,</v>
<v Speaker 1>you know,</v>

539
00:24:40.580 --> 00:24:42.640
<v Speaker 1>actually the way this happened was,</v>
<v Speaker 1>um,</v>

540
00:24:42.890 --> 00:24:47.890
<v Speaker 1>at first he just tried it and it worked.</v>
<v Speaker 1>It was kind of a overnight kind of thing</v>

541
00:24:48.021 --> 00:24:48.854
<v Speaker 1>and we got some very promising results.</v>
<v Speaker 1>And then we set about trying to think </v>

542
00:24:52.491 --> 00:24:53.324
<v Speaker 1>about,</v>
<v Speaker 1>well how do we actually explain what </v>

543
00:24:54.381 --> 00:24:55.790
<v Speaker 1>it's doing?</v>
<v Speaker 1>Why does this work?</v>

544
00:24:55.820 --> 00:24:56.660
<v Speaker 1>And so,</v>
<v Speaker 1>uh,</v>

545
00:24:56.661 --> 00:24:59.800
<v Speaker 1>we did a little bit of theory,</v>
<v Speaker 1>which is useful to,</v>

546
00:24:59.860 --> 00:25:00.693
<v Speaker 1>to discuss.</v>
<v Speaker 1>And I can tell you there's been a lot </v>

547
00:25:02.181 --> 00:25:03.014
<v Speaker 1>more theory on this topic that's been </v>
<v Speaker 1>done that I will not be telling you </v>

548
00:25:05.121 --> 00:25:05.954
<v Speaker 1>about.</v>
<v Speaker 1>But it's actually been a very </v>

549
00:25:06.501 --> 00:25:09.440
<v Speaker 1>interesting development in the last few </v>
<v Speaker 1>years.</v>

550
00:25:10.520 --> 00:25:11.353
<v Speaker 1>But this,</v>
<v Speaker 1>this is the theory that appeared in the </v>

551
00:25:12.591 --> 00:25:14.600
<v Speaker 1>original paper.</v>
<v Speaker 1>So that the way we approached this was,</v>

552
00:25:14.601 --> 00:25:17.080
<v Speaker 1>let's imagine we have an optimal </v>
<v Speaker 1>discriminator.</v>

553
00:25:17.100 --> 00:25:18.800
<v Speaker 1>This turns out you can eat pretty </v>
<v Speaker 1>easily.</v>

554
00:25:18.801 --> 00:25:20.930
<v Speaker 1>Show this is the optimal discriminator </v>
<v Speaker 1>up here.</v>

555
00:25:21.110 --> 00:25:22.790
<v Speaker 1>Now you couldn't,</v>
<v Speaker 1>this is not a practical thing,</v>

556
00:25:22.791 --> 00:25:24.230
<v Speaker 1>right?</v>
<v Speaker 1>Because we don't know pr,</v>

557
00:25:24.231 --> 00:25:26.660
<v Speaker 1>which is probability of the real </v>
<v Speaker 1>distribution.</v>

558
00:25:26.661 --> 00:25:28.310
<v Speaker 1>We don't,</v>
<v Speaker 1>this is not available to us.</v>

559
00:25:28.311 --> 00:25:31.820
<v Speaker 1>This is only defined over training set.</v>
<v Speaker 1>So only by training examples.</v>

560
00:25:31.821 --> 00:25:34.040
<v Speaker 1>So we actually don't,</v>
<v Speaker 1>we can't instantiate this,</v>

561
00:25:34.041 --> 00:25:37.880
<v Speaker 1>but in theory,</v>
<v Speaker 1>if we had this optimal discriminator,</v>

562
00:25:38.450 --> 00:25:39.283
<v Speaker 1>then the generator would be trained to </v>
<v Speaker 1>minimize the Jensen Shannon divergence </v>

563
00:25:43.671 --> 00:25:44.504
<v Speaker 1>between the true distribution that gave </v>
<v Speaker 1>rise to the training data and are </v>

564
00:25:47.511 --> 00:25:50.240
<v Speaker 1>generated distribution.</v>
<v Speaker 1>So this is good,</v>

565
00:25:50.241 --> 00:25:51.074
<v Speaker 1>right?</v>
<v Speaker 1>This is telling us that we're actually </v>

566
00:25:51.471 --> 00:25:52.304
<v Speaker 1>doing something sensible in this kind of</v>
<v Speaker 1>nonparametric ideal setting that we </v>

567
00:25:55.401 --> 00:25:57.500
<v Speaker 1>don't,</v>
<v Speaker 1>we're not really using but,</v>

568
00:25:57.501 --> 00:25:58.340
<v Speaker 1>but it's,</v>
<v Speaker 1>um,</v>

569
00:25:59.090 --> 00:26:01.250
<v Speaker 1>but it's actually,</v>
<v Speaker 1>it's interesting nonetheless.</v>

570
00:26:02.780 --> 00:26:05.450
<v Speaker 1>Um,</v>
<v Speaker 1>so one thing I can say though,</v>

571
00:26:05.480 --> 00:26:06.313
<v Speaker 1>that in practice,</v>
<v Speaker 1>we actually don't use exactly the </v>

572
00:26:08.001 --> 00:26:09.830
<v Speaker 1>objective function that I was just </v>
<v Speaker 1>describing.</v>

573
00:26:10.100 --> 00:26:12.110
<v Speaker 1>What we use instead is a modified </v>
<v Speaker 1>objective function.</v>

574
00:26:12.111 --> 00:26:14.690
<v Speaker 1>And the reason is,</v>
<v Speaker 1>is because if we were to minimize,</v>

575
00:26:14.720 --> 00:26:15.553
<v Speaker 1>Gee,</v>
<v Speaker 1>what we had before was this term </v>

576
00:26:17.121 --> 00:26:19.010
<v Speaker 1>minimizing g,</v>
<v Speaker 1>what happens is,</v>

577
00:26:19.011 --> 00:26:21.290
<v Speaker 1>is that as the discriminator to gets </v>
<v Speaker 1>better and better,</v>

578
00:26:22.010 --> 00:26:25.340
<v Speaker 1>that the gradient on g actually saturate</v>
<v Speaker 1>it goes to zero.</v>

579
00:26:26.480 --> 00:26:28.380
<v Speaker 1>So that's not very,</v>
<v Speaker 1>uh,</v>

580
00:26:28.700 --> 00:26:30.230
<v Speaker 1>useful.</v>
<v Speaker 1>If we want to train this small,</v>

581
00:26:30.231 --> 00:26:33.110
<v Speaker 1>and this is actually one of these,</v>
<v Speaker 1>one of the practical issues that you see</v>

582
00:26:33.111 --> 00:26:33.944
<v Speaker 1>when you actually train these models is </v>
<v Speaker 1>that you're constantly fighting this </v>

583
00:26:36.980 --> 00:26:38.080
<v Speaker 1>game between the,</v>
<v Speaker 1>you're,</v>

584
00:26:38.081 --> 00:26:43.081
<v Speaker 1>you're sort of on this edge of,</v>
<v Speaker 1>of the discriminator doing too well or,</v>

585
00:26:44.220 --> 00:26:45.270
<v Speaker 1>or the generator,</v>
<v Speaker 1>uh,</v>

586
00:26:45.271 --> 00:26:45.681
<v Speaker 1>you know,</v>
<v Speaker 1>it's a,</v>

587
00:26:45.681 --> 00:26:46.501
<v Speaker 1>it's,</v>
<v Speaker 1>it's essentially,</v>

588
00:26:46.501 --> 00:26:47.334
<v Speaker 1>you're basically almost always fighting </v>
<v Speaker 1>the discriminator because it's always </v>

589
00:26:49.860 --> 00:26:52.170
<v Speaker 1>going to,</v>
<v Speaker 1>as soon as this discriminators starts to</v>

590
00:26:52.171 --> 00:26:53.004
<v Speaker 1>win this,</v>
<v Speaker 1>this a competition between the gender </v>

591
00:26:54.931 --> 00:26:57.090
<v Speaker 1>and the discriminator,</v>
<v Speaker 1>you end up with unstable training.</v>

592
00:26:57.091 --> 00:26:59.640
<v Speaker 1>And in this case,</v>
<v Speaker 1>you end up with basically the,</v>

593
00:27:00.090 --> 00:27:03.120
<v Speaker 1>the generators stops training and the </v>
<v Speaker 1>discriminator runs away with it.</v>

594
00:27:03.390 --> 00:27:04.890
<v Speaker 1>Well,</v>
<v Speaker 1>that's actually in the original case.</v>

595
00:27:04.950 --> 00:27:07.410
<v Speaker 1>So what we'll do instead is we optimize </v>
<v Speaker 1>this,</v>

596
00:27:07.500 --> 00:27:11.310
<v Speaker 1>which is a slight modification,</v>
<v Speaker 1>but it's still monotonic and it actually</v>

597
00:27:11.311 --> 00:27:13.620
<v Speaker 1>corresponds to the same,</v>
<v Speaker 1>the same fixed point.</v>

598
00:27:13.621 --> 00:27:14.454
<v Speaker 1>But,</v>
<v Speaker 1>but what we're doing is we're just </v>

599
00:27:15.151 --> 00:27:19.140
<v Speaker 1>actually with respect to g,</v>
<v Speaker 1>again coming in through the samples here</v>

600
00:27:19.230 --> 00:27:22.140
<v Speaker 1>or maximizing this quantity rather than </v>
<v Speaker 1>minimizing this one.</v>

601
00:27:24.360 --> 00:27:25.193
<v Speaker 1>Okay.</v>
<v Speaker 1>So that's just a practical kind of </v>

602
00:27:26.251 --> 00:27:27.084
<v Speaker 1>heuristic thing,</v>
<v Speaker 1>but it actually makes a big difference </v>

603
00:27:28.051 --> 00:27:28.884
<v Speaker 1>in practice.</v>

604
00:27:30.460 --> 00:27:32.210
<v Speaker 1>All right.</v>
<v Speaker 1>So when we did this,</v>

605
00:27:32.270 --> 00:27:33.860
<v Speaker 1>when we published first published this </v>
<v Speaker 1>paper,</v>

606
00:27:33.861 --> 00:27:34.694
<v Speaker 1>this is the kind of results we would see</v>
<v Speaker 1>and what you're looking at now is kind </v>

607
00:27:36.891 --> 00:27:41.570
<v Speaker 1>of movies formed by moving smoothly and </v>
<v Speaker 1>zed space,</v>

608
00:27:41.660 --> 00:27:42.380
<v Speaker 1>right?</v>
<v Speaker 1>So this is,</v>

609
00:27:42.380 --> 00:27:43.213
<v Speaker 1>you're kind of looking at </v>
<v Speaker 1>transformations on the image manifold </v>

610
00:27:46.641 --> 00:27:47.474
<v Speaker 1>coming from smooth motions in zed space.</v>
<v Speaker 1>So we were pretty impressed with these </v>

611
00:27:51.081 --> 00:27:53.420
<v Speaker 1>results again,</v>
<v Speaker 1>and maybe they felt good at the time.</v>

612
00:27:53.710 --> 00:27:55.310
<v Speaker 1>Um,</v>
<v Speaker 1>but there's been,</v>

613
00:27:55.670 --> 00:27:56.503
<v Speaker 1>you know,</v>
<v Speaker 1>a few papers that have come out </v>

614
00:27:57.891 --> 00:27:59.210
<v Speaker 1>recently,</v>
<v Speaker 1>well,</v>

615
00:27:59.720 --> 00:28:02.690
<v Speaker 1>not so recently.</v>
<v Speaker 1>Actually at this point in 2016 there was</v>

616
00:28:02.691 --> 00:28:05.750
<v Speaker 1>a,</v>
<v Speaker 1>this was came out in 2014 and 2016 there</v>

617
00:28:05.751 --> 00:28:08.330
<v Speaker 1>was a big jump in the quality.</v>
<v Speaker 1>Um,</v>

618
00:28:08.350 --> 00:28:09.183
<v Speaker 1>and,</v>
<v Speaker 1>and this was sort of one of those </v>

619
00:28:10.041 --> 00:28:11.460
<v Speaker 1>stages.</v>
<v Speaker 1>This is the least squares Gan.</v>

620
00:28:11.490 --> 00:28:14.420
<v Speaker 1>This is just one example of many I could</v>
<v Speaker 1>have pointed out.</v>

621
00:28:14.780 --> 00:28:15.613
<v Speaker 1>Um,</v>
<v Speaker 1>but this is the kind of results we're </v>

622
00:28:16.551 --> 00:28:17.180
<v Speaker 1>seeing.</v>
<v Speaker 1>So,</v>

623
00:28:17.180 --> 00:28:20.450
<v Speaker 1>so part of one of the,</v>
<v Speaker 1>one of the secrets here is that it's one</v>

624
00:28:20.451 --> 00:28:21.284
<v Speaker 1>28 by one 28.</v>
<v Speaker 1>So bigger images actually give you a </v>

625
00:28:23.960 --> 00:28:26.360
<v Speaker 1>much better perception of quality in </v>
<v Speaker 1>terms of the images.</v>

626
00:28:26.361 --> 00:28:30.650
<v Speaker 1>But so these are not necessarily,</v>
<v Speaker 1>or generally not real bedrooms,</v>

627
00:28:30.651 --> 00:28:31.484
<v Speaker 1>these are,</v>
<v Speaker 1>these are actually generated from the </v>

628
00:28:33.771 --> 00:28:34.940
<v Speaker 1>model,</v>
<v Speaker 1>right?</v>

629
00:28:34.970 --> 00:28:37.160
<v Speaker 1>So trained on,</v>
<v Speaker 1>you know,</v>

630
00:28:37.190 --> 00:28:38.023
<v Speaker 1>roughly I think 100,000</v>
<v Speaker 1>or at least a hundred thousand bedroom </v>

631
00:28:40.011 --> 00:28:42.950
<v Speaker 1>scenes asked to generate from these </v>
<v Speaker 1>random zed bits.</v>

632
00:28:42.951 --> 00:28:43.970
<v Speaker 1>This is what it gives you.</v>

633
00:28:46.300 --> 00:28:47.133
<v Speaker 1>So one thing you could think of,</v>
<v Speaker 1>one thing that's certainly kind of </v>

634
00:28:48.761 --> 00:28:49.594
<v Speaker 1>occurred to me when I first saw these </v>
<v Speaker 1>kinds of results is that well it's just </v>

635
00:28:52.931 --> 00:28:53.764
<v Speaker 1>over fit on some small set of examples </v>
<v Speaker 1>and it's just learning these Delta </v>

636
00:28:55.931 --> 00:28:57.400
<v Speaker 1>functions,</v>
<v Speaker 1>right?</v>

637
00:28:57.820 --> 00:28:59.830
<v Speaker 1>So,</v>
<v Speaker 1>so that's not that interesting.</v>

638
00:28:59.831 --> 00:29:00.664
<v Speaker 1>In some sense it's kind of memorize some</v>
<v Speaker 1>small set of data and it's enough that </v>

639
00:29:04.040 --> 00:29:09.040
<v Speaker 1>it looks good and it's impressive,</v>
<v Speaker 1>but it doesn't seem like that's actually</v>

640
00:29:09.131 --> 00:29:09.964
<v Speaker 1>the case in one of the evidence.</v>
<v Speaker 1>One of the parts of evidence it was </v>

641
00:29:11.381 --> 00:29:13.330
<v Speaker 1>pointed to,</v>
<v Speaker 1>and this is in the DC Gann paper,</v>

642
00:29:13.470 --> 00:29:14.500
<v Speaker 1>um,</v>
<v Speaker 1>was this,</v>

643
00:29:14.501 --> 00:29:15.334
<v Speaker 1>so that same trick that I showed you </v>
<v Speaker 1>with the movies in damnest where where </v>

644
00:29:18.701 --> 00:29:20.920
<v Speaker 1>we were sort of moving smoothly and zed </v>
<v Speaker 1>space,</v>

645
00:29:21.160 --> 00:29:23.530
<v Speaker 1>they applied basically that same idea </v>
<v Speaker 1>here.</v>

646
00:29:23.680 --> 00:29:28.600
<v Speaker 1>So this is basically one long trajectory</v>
<v Speaker 1>through zed space.</v>

647
00:29:28.990 --> 00:29:32.170
<v Speaker 1>And what you can see is starting up here</v>
<v Speaker 1>on the ending up all the way down here,</v>

648
00:29:32.320 --> 00:29:34.810
<v Speaker 1>when you can see it's a smooth </v>
<v Speaker 1>transition,</v>

649
00:29:35.500 --> 00:29:38.020
<v Speaker 1>right?</v>
<v Speaker 1>And at every point it seems like,</v>

650
00:29:38.170 --> 00:29:40.630
<v Speaker 1>you know,</v>
<v Speaker 1>a reasonable bedroom scene.</v>

651
00:29:41.600 --> 00:29:42.000
<v Speaker 2>Okay.</v>

652
00:29:42.000 --> 00:29:42.833
<v Speaker 1>So it really does seem like,</v>
<v Speaker 1>like that picture that I showed you </v>

653
00:29:45.271 --> 00:29:46.104
<v Speaker 1>where we had the zed space,</v>
<v Speaker 1>it was sort of smooth and then we had </v>

654
00:29:48.481 --> 00:29:50.580
<v Speaker 1>this x space,</v>
<v Speaker 1>they've had this manifold on it.</v>

655
00:29:50.790 --> 00:29:52.530
<v Speaker 1>It really does feel like that's what's </v>
<v Speaker 1>happening here,</v>

656
00:29:52.531 --> 00:29:53.364
<v Speaker 1>right,</v>
<v Speaker 1>where we're moving smoothly and zed </v>

657
00:29:54.331 --> 00:29:57.600
<v Speaker 1>space and we're moving along the image </v>
<v Speaker 1>manifold in x space.</v>

658
00:30:04.010 --> 00:30:05.240
<v Speaker 1>So for example,</v>
<v Speaker 1>this,</v>

659
00:30:05.480 --> 00:30:07.520
<v Speaker 1>I guess,</v>
<v Speaker 1>I don't know if this is a picture or tv,</v>

660
00:30:07.521 --> 00:30:12.080
<v Speaker 1>but it slowly morphs into a window I </v>
<v Speaker 1>guess,</v>

661
00:30:12.081 --> 00:30:12.914
<v Speaker 1>and then kind of becomes clearly a </v>
<v Speaker 1>window and then it turns into just into </v>

662
00:30:15.020 --> 00:30:17.750
<v Speaker 1>these edge sort of an edge of the room.</v>

663
00:30:20.410 --> 00:30:22.690
<v Speaker 1>So one of the things actually if you </v>
<v Speaker 1>want to nitpick about these,</v>

664
00:30:22.720 --> 00:30:26.410
<v Speaker 1>the models actually don't seem to </v>
<v Speaker 1>understand three d geometry very well.</v>

665
00:30:26.411 --> 00:30:27.244
<v Speaker 1>It often gets the perspective just a </v>
<v Speaker 1>little wrong sort of something might be </v>

666
00:30:31.181 --> 00:30:33.580
<v Speaker 1>interesting for future work.</v>
<v Speaker 1>Um,</v>

667
00:30:33.581 --> 00:30:34.780
<v Speaker 1>so yeah.</v>
<v Speaker 1>So one question,</v>

668
00:30:34.820 --> 00:30:35.890
<v Speaker 1>uh,</v>
<v Speaker 1>you might be,</v>

669
00:30:35.891 --> 00:30:38.410
<v Speaker 1>it's a why,</v>
<v Speaker 1>why do these things work well?</v>

670
00:30:38.411 --> 00:30:40.470
<v Speaker 1>And they keep in mind that,</v>
<v Speaker 1>you know,</v>

671
00:30:40.480 --> 00:30:41.313
<v Speaker 1>when we talked about the v model,</v>
<v Speaker 1>we actually had to do a quite a bit of </v>

672
00:30:44.021 --> 00:30:46.270
<v Speaker 1>work to get comparable results,</v>
<v Speaker 1>right?</v>

673
00:30:46.271 --> 00:30:48.370
<v Speaker 1>We had to embed these,</v>
<v Speaker 1>pick these,</v>

674
00:30:48.400 --> 00:30:52.900
<v Speaker 1>a pixel CNNS and the decoder,</v>
<v Speaker 1>or we had to do some quite a bit of work</v>

675
00:30:52.901 --> 00:30:55.330
<v Speaker 1>to get the encoder to work right in </v>
<v Speaker 1>these models.</v>

676
00:30:55.331 --> 00:30:58.720
<v Speaker 1>We literally just took a confident stuck</v>
<v Speaker 1>in some noise at the beginning,</v>

677
00:30:58.750 --> 00:31:01.120
<v Speaker 1>pushed it through and we got these </v>
<v Speaker 1>fantastic samples.</v>

678
00:31:01.121 --> 00:31:02.440
<v Speaker 1>It really is kind of that simple.</v>

679
00:31:02.770 --> 00:31:03.603
<v Speaker 1>So what's going on?</v>
<v Speaker 1>Like why is it working as well as its </v>

680
00:31:06.150 --> 00:31:06.940
<v Speaker 1>wills?</v>
<v Speaker 1>It,</v>

681
00:31:06.940 --> 00:31:08.050
<v Speaker 1>it is.</v>
<v Speaker 1>Um,</v>

682
00:31:08.051 --> 00:31:10.230
<v Speaker 1>and so I have a kind of an intuition for</v>
<v Speaker 1>you.</v>

683
00:31:10.250 --> 00:31:12.280
<v Speaker 1>I kind of a cartoon view.</v>
<v Speaker 1>Um,</v>

684
00:31:12.281 --> 00:31:14.920
<v Speaker 1>so imagine that this is the image </v>
<v Speaker 1>manifold.</v>

685
00:31:14.921 --> 00:31:15.754
<v Speaker 1>So,</v>
<v Speaker 1>so this is kind of a cartoon view of an </v>

686
00:31:16.901 --> 00:31:17.451
<v Speaker 1>image,</v>
<v Speaker 1>a metaphor,</v>

687
00:31:17.451 --> 00:31:19.990
<v Speaker 1>but like this is in,</v>
<v Speaker 1>in two pixel dimensions here.</v>

688
00:31:20.990 --> 00:31:21.823
<v Speaker 1>And,</v>
<v Speaker 1>and we're imagining here that these are </v>

689
00:31:23.201 --> 00:31:25.600
<v Speaker 1>just parts of image manifold and they </v>
<v Speaker 1>sort of,</v>

690
00:31:25.870 --> 00:31:28.480
<v Speaker 1>you know,</v>
<v Speaker 1>share some features close by.</v>

691
00:31:28.481 --> 00:31:29.314
<v Speaker 1>But,</v>
<v Speaker 1>but what this is basically representing </v>

692
00:31:30.401 --> 00:31:34.780
<v Speaker 1>is the fact that that most of this space</v>
<v Speaker 1>isn't on the image manifold,</v>

693
00:31:34.800 --> 00:31:35.633
<v Speaker 1>right?</v>
<v Speaker 1>Image manifold,</v>

694
00:31:35.650 --> 00:31:40.360
<v Speaker 1>some complicated nonlinearity and if you</v>
<v Speaker 1>were to randomly sample in Pixel space,</v>

695
00:31:40.361 --> 00:31:42.010
<v Speaker 1>you would not land on this image </v>
<v Speaker 1>manifold,</v>

696
00:31:42.310 --> 00:31:43.061
<v Speaker 1>which makes sense,</v>
<v Speaker 1>right?</v>

697
00:31:43.061 --> 00:31:43.894
<v Speaker 1>Randomly sample in Pixel space,</v>
<v Speaker 1>you're not getting a natural image out </v>

698
00:31:45.791 --> 00:31:46.624
<v Speaker 1>of it.</v>
<v Speaker 1>This is sort of a cartoon view or my </v>

699
00:31:49.181 --> 00:31:52.540
<v Speaker 1>perspective on the difference between </v>
<v Speaker 1>what you see with</v>

700
00:31:53.790 --> 00:31:58.560
<v Speaker 1>maximum likelihood models of which the </v>
<v Speaker 1>va is one and something like a Gan.</v>

701
00:31:58.680 --> 00:32:02.910
<v Speaker 1>So the maximum likelihood,</v>
<v Speaker 1>the way it's trained is it has to give a</v>

702
00:32:02.911 --> 00:32:06.660
<v Speaker 1>certain amount of likelihood density for</v>
<v Speaker 1>each real sample.</v>

703
00:32:07.320 --> 00:32:10.170
<v Speaker 1>If it doesn't,</v>
<v Speaker 1>it's punished very severely for that.</v>

704
00:32:10.230 --> 00:32:14.800
<v Speaker 1>So it's willing to spread out it's </v>
<v Speaker 1>probability mass over regions of the,</v>

705
00:32:14.900 --> 00:32:17.790
<v Speaker 1>of the input space or the or of the </v>
<v Speaker 1>Pixel space,</v>

706
00:32:17.880 --> 00:32:20.370
<v Speaker 1>which actually doesn't correspond to a </v>
<v Speaker 1>natural image.</v>

707
00:32:20.880 --> 00:32:21.713
<v Speaker 1>And so when we sample from this model,</v>
<v Speaker 1>that's most of boy our samples come </v>

708
00:32:23.791 --> 00:32:24.241
<v Speaker 1>from,</v>
<v Speaker 1>right?</v>

709
00:32:24.241 --> 00:32:26.130
<v Speaker 1>This is,</v>
<v Speaker 1>these are these blurry images that we're</v>

710
00:32:26.131 --> 00:32:28.740
<v Speaker 1>looking at again,</v>
<v Speaker 1>models things differently,</v>

711
00:32:28.741 --> 00:32:29.574
<v Speaker 1>right?</v>
<v Speaker 1>Because it's the only playing this game </v>

712
00:32:30.511 --> 00:32:32.130
<v Speaker 1>between the encoder and,</v>
<v Speaker 1>well,</v>

713
00:32:32.160 --> 00:32:32.993
<v Speaker 1>sorry,</v>
<v Speaker 1>between the discriminator and the </v>

714
00:32:33.391 --> 00:32:37.860
<v Speaker 1>generator,</v>
<v Speaker 1>all it has to do is sort of stick on,</v>

715
00:32:37.920 --> 00:32:38.753
<v Speaker 1>you know,</v>
<v Speaker 1>some subset of the examples or maybe </v>

716
00:32:41.031 --> 00:32:41.864
<v Speaker 1>some subset of the manifolds that are </v>
<v Speaker 1>present and not have enough diversity </v>

717
00:32:46.071 --> 00:32:50.240
<v Speaker 1>that the discriminator can't notice that</v>
<v Speaker 1>it's modeling a subset.</v>

718
00:32:50.360 --> 00:32:53.690
<v Speaker 1>So there's pressure on the model too to </v>
<v Speaker 1>maintain a certain amount of diversity,</v>

719
00:32:53.930 --> 00:32:54.763
<v Speaker 1>but at the same time it doesn't actually</v>
<v Speaker 1>face any pressure to model all aspects </v>

720
00:32:58.791 --> 00:32:59.624
<v Speaker 1>of the training distribution.</v>
<v Speaker 1>It can just ignore certain aspects of </v>

721
00:33:02.271 --> 00:33:03.104
<v Speaker 1>the training examples or certain aspects</v>
<v Speaker 1>of the training distribution without </v>

722
00:33:06.680 --> 00:33:11.420
<v Speaker 1>significant punishment from the,</v>
<v Speaker 1>from the training algorithm.</v>

723
00:33:11.900 --> 00:33:12.560
<v Speaker 1>So anyway,</v>
<v Speaker 1>that's,</v>

724
00:33:12.560 --> 00:33:13.393
<v Speaker 1>that's I think a good idea to have in </v>
<v Speaker 1>your mind about the difference between </v>

725
00:33:15.291 --> 00:33:18.650
<v Speaker 1>how these methods work.</v>
<v Speaker 1>Um,</v>

726
00:33:18.680 --> 00:33:19.071
<v Speaker 1>yeah.</v>
<v Speaker 1>So,</v>

727
00:33:19.071 --> 00:33:19.904
<v Speaker 1>so just I'd like to sort of conclude </v>
<v Speaker 1>with a few steps that have happened </v>

728
00:33:23.241 --> 00:33:24.610
<v Speaker 1>since the,</v>
<v Speaker 1>uh,</v>

729
00:33:24.650 --> 00:33:25.760
<v Speaker 1>the gains.</v>
<v Speaker 1>One of the things,</v>

730
00:33:25.761 --> 00:33:28.160
<v Speaker 1>this is something that we've done.</v>
<v Speaker 1>We've actually,</v>

731
00:33:28.460 --> 00:33:29.750
<v Speaker 1>you know,</v>
<v Speaker 1>you might ask,</v>

732
00:33:29.751 --> 00:33:30.584
<v Speaker 1>well gans are great,</v>
<v Speaker 1>but in a way it's kind of unsatisfying </v>

733
00:33:32.761 --> 00:33:35.150
<v Speaker 1>because we start with [inaudible] and </v>
<v Speaker 1>then we can generate images.</v>

734
00:33:35.151 --> 00:33:37.280
<v Speaker 1>So yes,</v>
<v Speaker 1>we generate really nice looking images.</v>

735
00:33:37.280 --> 00:33:38.690
<v Speaker 1>But,</v>
<v Speaker 1>but we had this,</v>

736
00:33:38.720 --> 00:33:39.553
<v Speaker 1>you know,</v>
<v Speaker 1>a hope when we started talking about </v>

737
00:33:40.461 --> 00:33:41.294
<v Speaker 1>these latent variable mount models that </v>
<v Speaker 1>we could actually maybe infer the zed </v>

738
00:33:44.751 --> 00:33:45.710
<v Speaker 1>from an image,</v>
<v Speaker 1>right?</v>

739
00:33:45.711 --> 00:33:49.100
<v Speaker 1>So we can actually extract some </v>
<v Speaker 1>semantics out of the,</v>

740
00:33:49.160 --> 00:33:49.993
<v Speaker 1>of the image using these latent </v>
<v Speaker 1>variables that you discover and in </v>

741
00:33:53.511 --> 00:33:54.350
<v Speaker 1>again,</v>
<v Speaker 1>we don't have,</v>

742
00:33:54.351 --> 00:33:55.184
<v Speaker 1>then the question is can we actually </v>
<v Speaker 1>within this generative adversarial </v>

743
00:33:57.891 --> 00:33:58.724
<v Speaker 1>framework,</v>
<v Speaker 1>can we re incorporate inference </v>

744
00:34:00.741 --> 00:34:01.574
<v Speaker 1>mechanism?</v>
<v Speaker 1>So that's exactly what we're doing here </v>

745
00:34:03.111 --> 00:34:03.944
<v Speaker 1>with this work.</v>
<v Speaker 1>And this is actually a model we call </v>

746
00:34:05.361 --> 00:34:06.021
<v Speaker 1>alley,</v>
<v Speaker 1>but they,</v>

747
00:34:06.021 --> 00:34:09.260
<v Speaker 1>the identical work essentially came out </v>
<v Speaker 1>at the same time.</v>

748
00:34:09.290 --> 00:34:10.760
<v Speaker 1>Uh,</v>
<v Speaker 1>I'll known as by again.</v>

749
00:34:10.910 --> 00:34:15.200
<v Speaker 1>And the basic idea here is just to </v>
<v Speaker 1>incorporate in encoder into the model.</v>

750
00:34:15.410 --> 00:34:18.410
<v Speaker 1>So rather than just giving the data,</v>
<v Speaker 1>distribute the data set,</v>

751
00:34:18.411 --> 00:34:20.510
<v Speaker 1>or here on,</v>
<v Speaker 1>on the left or earlier,</v>

752
00:34:20.511 --> 00:34:23.090
<v Speaker 1>the Gan was defined,</v>
<v Speaker 1>we had the decoder or generative model.</v>

753
00:34:23.210 --> 00:34:26.480
<v Speaker 1>But over here,</v>
<v Speaker 1>we only gave it x training examples.</v>

754
00:34:26.570 --> 00:34:28.580
<v Speaker 1>And here we only compare it against x,</v>
<v Speaker 1>uh,</v>

755
00:34:28.581 --> 00:34:32.390
<v Speaker 1>generated from the,</v>
<v Speaker 1>from the j the generator.</v>

756
00:34:32.840 --> 00:34:33.673
<v Speaker 1>But in this case,</v>
<v Speaker 1>what we're doing is we take x and then </v>

757
00:34:35.511 --> 00:34:40.511
<v Speaker 1>we actually use an encoder here to,</v>
<v Speaker 1>to generate a zed given x.</v>

758
00:34:41.510 --> 00:34:44.570
<v Speaker 1>And on the decoder we have again,</v>
<v Speaker 1>our traditional Ganz style.</v>

759
00:34:44.571 --> 00:34:48.500
<v Speaker 1>We take us said sample from some simple </v>
<v Speaker 1>distribution and we generate x.</v>

760
00:34:48.710 --> 00:34:49.543
<v Speaker 1>So again,</v>
<v Speaker 1>this is the data distribution over here </v>

761
00:34:50.990 --> 00:34:51.823
<v Speaker 1>and code it to zed.</v>
<v Speaker 1>And then we take our decode the sample </v>

762
00:34:54.351 --> 00:34:55.184
<v Speaker 1>from zed and we decode to x.</v>
<v Speaker 1>And our discriminator now crucially is </v>

763
00:34:57.771 --> 00:34:59.960
<v Speaker 1>not just given x,</v>
<v Speaker 1>but it's given x and zed.</v>

764
00:35:00.350 --> 00:35:01.183
<v Speaker 1>And it's asked,</v>
<v Speaker 1>can you tell the difference in this </v>

765
00:35:02.271 --> 00:35:05.420
<v Speaker 1>joint distribution between the encoder </v>
<v Speaker 1>side and the decoder side?</v>

766
00:35:06.650 --> 00:35:09.980
<v Speaker 1>That's the game.</v>
<v Speaker 1>And what we find is,</v>

767
00:35:10.220 --> 00:35:12.650
<v Speaker 1>well first of all,</v>
<v Speaker 1>it actually generates very good samples,</v>

768
00:35:12.651 --> 00:35:13.700
<v Speaker 1>which is interesting.</v>

769
00:35:13.730 --> 00:35:14.810
<v Speaker 1>Uh,</v>
<v Speaker 1>it's actually,</v>

770
00:35:15.920 --> 00:35:20.000
<v Speaker 1>it seems to generate sort of better </v>
<v Speaker 1>samples and we see with comparable gans,</v>

771
00:35:20.001 --> 00:35:21.800
<v Speaker 1>which there might be some regularization</v>
<v Speaker 1>effect.</v>

772
00:35:21.801 --> 00:35:22.634
<v Speaker 1>I'm not entirely sure why that would be,</v>
<v Speaker 1>but actually it gets fairly compelling </v>

773
00:35:24.861 --> 00:35:27.230
<v Speaker 1>samples.</v>
<v Speaker 1>This is just with a seller bay,</v>

774
00:35:27.231 --> 00:35:30.770
<v Speaker 1>a large data set of a celebrity images.</v>
<v Speaker 1>Um,</v>

775
00:35:30.980 --> 00:35:32.690
<v Speaker 1>but this is the more interesting plot.</v>
<v Speaker 1>So,</v>

776
00:35:32.691 --> 00:35:35.900
<v Speaker 1>so this is actually corresponds to a </v>
<v Speaker 1>hierarchical version of this model.</v>

777
00:35:35.901 --> 00:35:39.450
<v Speaker 1>So this is why we have multiple sets.</v>
<v Speaker 1>So this is ed one and said to,</v>

778
00:35:39.451 --> 00:35:42.600
<v Speaker 1>this is a two layer model inversion of </v>
<v Speaker 1>this model.</v>

779
00:35:42.810 --> 00:35:45.480
<v Speaker 1>So if we just reconstruct from the </v>
<v Speaker 1>higher levels Ed,</v>

780
00:35:45.570 --> 00:35:47.090
<v Speaker 1>which is this,</v>
<v Speaker 1>you know,</v>

781
00:35:47.190 --> 00:35:49.860
<v Speaker 1>containing fairly little information </v>
<v Speaker 1>because is this you?</v>

782
00:35:49.920 --> 00:35:54.630
<v Speaker 1>It's a single vector and then it has to </v>
<v Speaker 1>synthesize into this a large image.</v>

783
00:35:55.050 --> 00:35:56.970
<v Speaker 1>What we're looking at here,</v>
<v Speaker 1>a reconstruction.</v>

784
00:35:56.971 --> 00:35:57.804
<v Speaker 1>So we take this image,</v>
<v Speaker 1>we encoded all the way to zed two and </v>

785
00:36:01.021 --> 00:36:01.710
<v Speaker 1>then we decode it.</v>

786
00:36:01.710 --> 00:36:03.660
<v Speaker 1>And what we end up with is,</v>
<v Speaker 1>is this,</v>

787
00:36:03.870 --> 00:36:04.703
<v Speaker 1>which is,</v>
<v Speaker 1>you know,</v>

788
00:36:04.920 --> 00:36:07.210
<v Speaker 1>reasonably close but not that great.</v>
<v Speaker 1>Right?</v>

789
00:36:07.530 --> 00:36:09.630
<v Speaker 1>And so as the same thing,</v>
<v Speaker 1>you're going to kind of all,</v>

790
00:36:09.640 --> 00:36:12.090
<v Speaker 1>they sort of hold some piece of the </v>
<v Speaker 1>information,</v>

791
00:36:12.240 --> 00:36:13.073
<v Speaker 1>which in some sense this is kind of,</v>
<v Speaker 1>it's remarkable that does as well as it </v>

792
00:36:16.201 --> 00:36:19.050
<v Speaker 1>does because it's actually not trained </v>
<v Speaker 1>to do reconstruction.</v>

793
00:36:19.710 --> 00:36:20.543
<v Speaker 1>Unlike something like the vie which </v>
<v Speaker 1>actually explicitly trained to do </v>

794
00:36:22.321 --> 00:36:25.590
<v Speaker 1>reconstruction and this is just trained </v>
<v Speaker 1>to match these two distributions.</v>

795
00:36:25.591 --> 00:36:27.450
<v Speaker 1>And this is kind of a probe to see how </v>
<v Speaker 1>well it's doing.</v>

796
00:36:27.451 --> 00:36:32.330
<v Speaker 1>Cause we take x from one map a to zed </v>
<v Speaker 1>and we take that set over and when we re</v>

797
00:36:32.331 --> 00:36:35.040
<v Speaker 1>synthesize the acts and we see we're </v>
<v Speaker 1>seeing now an x space,</v>

798
00:36:35.100 --> 00:36:37.440
<v Speaker 1>how close did it come?</v>
<v Speaker 1>And you know it does.</v>

799
00:36:37.441 --> 00:36:40.880
<v Speaker 1>Okay.</v>
<v Speaker 1>But over here when we give it x one ends</v>

800
00:36:40.900 --> 00:36:41.740
<v Speaker 1>ed too.</v>

801
00:36:42.690 --> 00:36:43.523
<v Speaker 1>So in this case we're really just giving</v>
<v Speaker 1>it all of the latent variable </v>

802
00:36:45.751 --> 00:36:47.400
<v Speaker 1>information.</v>
<v Speaker 1>We actually get much,</v>

803
00:36:47.401 --> 00:36:48.234
<v Speaker 1>much closer.</v>
<v Speaker 1>Which is interesting because this is </v>

804
00:36:49.261 --> 00:36:51.600
<v Speaker 1>telling us that this pure joint </v>
<v Speaker 1>modeling,</v>

805
00:36:51.601 --> 00:36:54.070
<v Speaker 1>in this case it'd be a joint modeling </v>
<v Speaker 1>between x,</v>

806
00:36:54.071 --> 00:36:54.950
<v Speaker 1>Y,</v>
<v Speaker 1>zed one ends,</v>

807
00:36:54.951 --> 00:36:55.784
<v Speaker 1>zed to that.</v>
<v Speaker 1>This is enough to do fairly good </v>

808
00:36:58.801 --> 00:37:01.830
<v Speaker 1>reconstruction without ever actually </v>
<v Speaker 1>explicitly building that in.</v>

809
00:37:02.130 --> 00:37:05.340
<v Speaker 1>So it's giving us an interesting probe </v>
<v Speaker 1>into how close are we coming to learning</v>

810
00:37:05.341 --> 00:37:06.174
<v Speaker 1>this joint distribution and it seems </v>
<v Speaker 1>like we're getting actually surprising </v>

811
00:37:08.951 --> 00:37:09.784
<v Speaker 1>the clothes.</v>
<v Speaker 1>So it's like it's a testament to how </v>

812
00:37:12.091 --> 00:37:12.924
<v Speaker 1>effective I think this generative </v>
<v Speaker 1>adversarial training exam algorithm </v>

813
00:37:16.531 --> 00:37:17.364
<v Speaker 1>actually is.</v>
<v Speaker 1>So I want to just end with a few other </v>

814
00:37:20.971 --> 00:37:23.160
<v Speaker 1>things that have nothing to do with our </v>
<v Speaker 1>work but I think are very,</v>

815
00:37:23.161 --> 00:37:25.680
<v Speaker 1>very interesting and well worth you guys</v>
<v Speaker 1>learning about.</v>

816
00:37:25.950 --> 00:37:30.950
<v Speaker 1>So first one is cycle Gan cycle again is</v>
<v Speaker 1>this really cool idea starting with,</v>

817
00:37:31.770 --> 00:37:35.610
<v Speaker 1>let's imagine you have two sets of </v>
<v Speaker 1>datasets that somehow correspond but you</v>

818
00:37:35.611 --> 00:37:37.860
<v Speaker 1>don't know the correspondence you don't </v>
<v Speaker 1>have,</v>

819
00:37:37.861 --> 00:37:40.530
<v Speaker 1>like there's an alignment that exists </v>
<v Speaker 1>between these two data sets,</v>

820
00:37:40.531 --> 00:37:43.020
<v Speaker 1>but you might not know what,</v>
<v Speaker 1>you might not have paired data.</v>

821
00:37:43.230 --> 00:37:45.540
<v Speaker 1>This actually happens a lot.</v>
<v Speaker 1>Say for example,</v>

822
00:37:46.080 --> 00:37:46.913
<v Speaker 1>this is not an image space,</v>
<v Speaker 1>but a great example of this happens in </v>

823
00:37:49.530 --> 00:37:50.760
<v Speaker 1>machine translation,</v>
<v Speaker 1>right?</v>

824
00:37:51.150 --> 00:37:54.390
<v Speaker 1>You almost always have lots of </v>
<v Speaker 1>unilingual a data.</v>

825
00:37:54.570 --> 00:37:57.210
<v Speaker 1>So just text data in in a given </v>
<v Speaker 1>language,</v>

826
00:37:57.390 --> 00:37:59.490
<v Speaker 1>but it's very expensive to get aligned </v>
<v Speaker 1>data.</v>

827
00:37:59.550 --> 00:38:03.630
<v Speaker 1>But to data paired as a source and </v>
<v Speaker 1>target distribution.</v>

828
00:38:03.990 --> 00:38:07.320
<v Speaker 1>If the question is what can you do if </v>
<v Speaker 1>you just have unilingual data,</v>

829
00:38:07.560 --> 00:38:10.830
<v Speaker 1>how successful kicking you'd be at </v>
<v Speaker 1>learning a mapping between the two.</v>

830
00:38:11.160 --> 00:38:13.260
<v Speaker 1>And they essentially use gans to do </v>
<v Speaker 1>this.</v>

831
00:38:13.380 --> 00:38:14.213
<v Speaker 1>So this is the setup.</v>
<v Speaker 1>They have some domain x here and her </v>

832
00:38:16.711 --> 00:38:18.000
<v Speaker 1>domain.</v>
<v Speaker 1>Why here?</v>

833
00:38:18.510 --> 00:38:20.340
<v Speaker 1>And what they do is they start with an </v>
<v Speaker 1>ex,</v>

834
00:38:20.460 --> 00:38:22.950
<v Speaker 1>they transform it through some </v>
<v Speaker 1>convolutional neural net,</v>

835
00:38:22.980 --> 00:38:25.800
<v Speaker 1>usually a resonant based model into some</v>
<v Speaker 1>y.</v>

836
00:38:25.920 --> 00:38:28.290
<v Speaker 1>And on this why they're going to </v>
<v Speaker 1>evaluate it as a,</v>

837
00:38:28.560 --> 00:38:31.320
<v Speaker 1>as a,</v>
<v Speaker 1>as a Gan style discriminator here.</v>

838
00:38:31.590 --> 00:38:36.590
<v Speaker 1>So Ken acts a through g make a </v>
<v Speaker 1>convincing why that's being,</v>

839
00:38:37.220 --> 00:38:38.053
<v Speaker 1>what's being measured here.</v>
<v Speaker 1>So you can think of x is taking the </v>

840
00:38:40.571 --> 00:38:42.670
<v Speaker 1>place,</v>
<v Speaker 1>which is some other image.</v>

841
00:38:42.671 --> 00:38:44.590
<v Speaker 1>Let's say this is some image to another </v>
<v Speaker 1>image.</v>

842
00:38:44.860 --> 00:38:47.530
<v Speaker 1>This image x is taking the place of our,</v>
<v Speaker 1>of our zed,</v>

843
00:38:47.590 --> 00:38:51.370
<v Speaker 1>of our random bits.</v>
<v Speaker 1>It's getting it's randomness from x.</v>

844
00:38:52.270 --> 00:38:56.050
<v Speaker 1>And then we do the same thing.</v>
<v Speaker 1>We can kind of transform it through f.</v>

845
00:38:56.051 --> 00:38:58.570
<v Speaker 1>So we've got x here,</v>
<v Speaker 1>transform it through g,</v>

846
00:38:58.610 --> 00:38:59.443
<v Speaker 1>t to D and we evaluate on,</v>
<v Speaker 1>on the our discriminator here on Gann </v>

847
00:39:03.110 --> 00:39:05.770
<v Speaker 1>style training.</v>
<v Speaker 1>And then we re encode this annex.</v>

848
00:39:05.920 --> 00:39:08.800
<v Speaker 1>Now once we get here,</v>
<v Speaker 1>that's over here.</v>

849
00:39:08.801 --> 00:39:11.740
<v Speaker 1>So we've taken ecs transformed it into </v>
<v Speaker 1>why transform it back.</v>

850
00:39:12.100 --> 00:39:14.260
<v Speaker 1>They actually do what's called a cycle </v>
<v Speaker 1>consistency loss,</v>

851
00:39:14.261 --> 00:39:16.000
<v Speaker 1>which is,</v>
<v Speaker 1>this is actually a reconstruction.</v>

852
00:39:16.210 --> 00:39:17.043
<v Speaker 1>This is an l one reconstruction error </v>
<v Speaker 1>and they back prop through f and g and </v>

853
00:39:21.161 --> 00:39:22.630
<v Speaker 1>then they,</v>
<v Speaker 1>it's a symmetric relationship.</v>

854
00:39:22.630 --> 00:39:24.550
<v Speaker 1>So they do the exact same thing on the </v>
<v Speaker 1>other side.</v>

855
00:39:24.670 --> 00:39:27.490
<v Speaker 1>They start with why they see if they can</v>
<v Speaker 1>transform it into acs,</v>

856
00:39:27.491 --> 00:39:28.324
<v Speaker 1>the compare the,</v>
<v Speaker 1>they compare that that that generated x </v>

857
00:39:30.851 --> 00:39:31.684
<v Speaker 1>with true x is via a discriminator.</v>
<v Speaker 1>And then again transform that to y and </v>

858
00:39:35.321 --> 00:39:39.970
<v Speaker 1>do the cycle consistency loss.</v>
<v Speaker 1>So without any pair of data,</v>

859
00:39:40.120 --> 00:39:41.890
<v Speaker 1>this is the kind of thing that they can </v>
<v Speaker 1>get.</v>

860
00:39:43.370 --> 00:39:46.960
<v Speaker 1>So a particular note is a horses and </v>
<v Speaker 1>zebras,</v>

861
00:39:46.961 --> 00:39:47.381
<v Speaker 1>right?</v>
<v Speaker 1>So,</v>

862
00:39:47.381 --> 00:39:49.210
<v Speaker 1>and this is a case where,</v>
<v Speaker 1>you know,</v>

863
00:39:49.240 --> 00:39:50.260
<v Speaker 1>it's,</v>
<v Speaker 1>it's impossible.</v>

864
00:39:50.261 --> 00:39:52.450
<v Speaker 1>Do they get this kind of pair data?</v>
<v Speaker 1>Say you wanted a,</v>

865
00:39:52.451 --> 00:39:56.290
<v Speaker 1>a transformation that transformed horses</v>
<v Speaker 1>to zebras and vice versa.</v>

866
00:39:57.040 --> 00:40:02.040
<v Speaker 1>You will never find pictures of horses </v>
<v Speaker 1>and zebras in the exact same pose,</v>

867
00:40:02.351 --> 00:40:03.184
<v Speaker 1>right?</v>
<v Speaker 1>That's just not a kind of Datas that </v>

868
00:40:03.791 --> 00:40:04.624
<v Speaker 1>you're ever going to be able to collect.</v>
<v Speaker 1>And yet they do a fairly convincing job </v>

869
00:40:07.630 --> 00:40:08.290
<v Speaker 1>of doing this.</v>

870
00:40:08.290 --> 00:40:11.260
<v Speaker 1>And you can see that they even turn like</v>
<v Speaker 1>there's a little bit,</v>

871
00:40:11.350 --> 00:40:12.610
<v Speaker 1>this one actually doesn't do it very </v>
<v Speaker 1>well,</v>

872
00:40:12.611 --> 00:40:13.444
<v Speaker 1>but oftentimes what you see as the turn </v>
<v Speaker 1>like green grass a little bit more </v>

873
00:40:16.301 --> 00:40:17.134
<v Speaker 1>savannah like you took that kind of </v>
<v Speaker 1>dulls it out because zebras are found </v>

874
00:40:20.621 --> 00:40:22.570
<v Speaker 1>generally in Savannah,</v>
<v Speaker 1>let conditions,</v>

875
00:40:22.950 --> 00:40:23.783
<v Speaker 1>uh,</v>
<v Speaker 1>they can do a winter to summer kind of </v>

876
00:40:25.781 --> 00:40:28.710
<v Speaker 1>transitions.</v>
<v Speaker 1>I've seen examples data night,</v>

877
00:40:29.330 --> 00:40:30.163
<v Speaker 1>um,</v>
<v Speaker 1>these are pretty interested in the </v>

878
00:40:31.061 --> 00:40:33.940
<v Speaker 1>various other things.</v>
<v Speaker 1>Now I think there's,</v>

879
00:40:33.970 --> 00:40:36.420
<v Speaker 1>there's a lot of interesting things you </v>
<v Speaker 1>can do with this dataset.</v>

880
00:40:36.450 --> 00:40:37.750
<v Speaker 1>And,</v>
<v Speaker 1>and going back to,</v>

881
00:40:37.751 --> 00:40:41.120
<v Speaker 1>if you think about that simulation </v>
<v Speaker 1>example with ro robotics that I gave the</v>

882
00:40:41.121 --> 00:40:41.954
<v Speaker 1>motivating example at the beginning.</v>
<v Speaker 1>This is a prime application area for </v>

883
00:40:44.921 --> 00:40:45.754
<v Speaker 1>this kind of technology,</v>
<v Speaker 1>but it will say that one of the things </v>

884
00:40:47.471 --> 00:40:48.304
<v Speaker 1>that they've done here is they assume a </v>
<v Speaker 1>deterministic transformation between </v>

885
00:40:51.071 --> 00:40:52.000
<v Speaker 1>these two domains.</v>

886
00:40:52.300 --> 00:40:53.133
<v Speaker 1>So I think there's a lot of interest </v>
<v Speaker 1>looking at how do you actually break </v>

887
00:40:55.721 --> 00:40:56.554
<v Speaker 1>that kind of restriction and imagine </v>
<v Speaker 1>something more like in many to many </v>

888
00:40:59.141 --> 00:40:59.974
<v Speaker 1>mapping between these two domains.</v>
<v Speaker 1>So the last thing I want to show you is </v>

889
00:41:03.011 --> 00:41:03.844
<v Speaker 1>kind of the most recent stuff,</v>
<v Speaker 1>which is just kind of mind blowing in </v>

890
00:41:05.561 --> 00:41:07.610
<v Speaker 1>terms of just the quality of generation </v>
<v Speaker 1>that they,</v>

891
00:41:07.960 --> 00:41:08.793
<v Speaker 1>they show.</v>
<v Speaker 1>So these are images from invidia </v>

892
00:41:11.171 --> 00:41:12.190
<v Speaker 1>actually.</v>
<v Speaker 1>So I don't know if I'm,</v>

893
00:41:12.340 --> 00:41:15.340
<v Speaker 1>I'm uh,</v>
<v Speaker 1>I'm sort of a undercutting,</v>

894
00:41:15.520 --> 00:41:16.840
<v Speaker 1>I don't know if he was going to show </v>
<v Speaker 1>these or not,</v>

895
00:41:16.841 --> 00:41:17.890
<v Speaker 1>but uh,</v>
<v Speaker 1>yeah,</v>

896
00:41:17.891 --> 00:41:21.610
<v Speaker 1>so these trained on,</v>
<v Speaker 1>um,</v>

897
00:41:22.210 --> 00:41:24.930
<v Speaker 1>on the original,</v>
<v Speaker 1>um,</v>

898
00:41:25.070 --> 00:41:27.220
<v Speaker 1>celebrate data set,</v>
<v Speaker 1>the same one we had before,</v>

899
00:41:27.221 --> 00:41:29.410
<v Speaker 1>but now much,</v>
<v Speaker 1>much larger images.</v>

900
00:41:29.440 --> 00:41:30.820
<v Speaker 1>Right?</v>
<v Speaker 1>So 1,024</v>

901
00:41:30.821 --> 00:41:34.450
<v Speaker 1>by 2024 and they're able get these kinds</v>
<v Speaker 1>of uh,</v>

902
00:41:35.240 --> 00:41:38.690
<v Speaker 1>generated models.</v>
<v Speaker 1>So I would argue that many of these,</v>

903
00:41:38.691 --> 00:41:42.790
<v Speaker 1>maybe all of the ones shown here </v>
<v Speaker 1>essentially pass a kind of a,</v>

904
00:41:43.080 --> 00:41:44.270
<v Speaker 1>a turing test,</v>
<v Speaker 1>right?</v>

905
00:41:44.270 --> 00:41:45.103
<v Speaker 1>An image turing test.</v>
<v Speaker 1>You cannot tell that these are not real </v>

906
00:41:46.341 --> 00:41:50.060
<v Speaker 1>people right now.</v>
<v Speaker 1>I shouldn't say not all images actually,</v>

907
00:41:50.080 --> 00:41:51.140
<v Speaker 1>uh,</v>
<v Speaker 1>look this good.</v>

908
00:41:51.141 --> 00:41:51.974
<v Speaker 1>Some of them are actually really spooky,</v>
<v Speaker 1>but you can go online and look at the </v>

909
00:41:55.131 --> 00:41:57.080
<v Speaker 1>video and pick some out there.</v>
<v Speaker 1>Yeah.</v>

910
00:41:57.830 --> 00:41:58.663
<v Speaker 1>Um,</v>
<v Speaker 1>how they do this is with a really </v>

911
00:42:01.401 --> 00:42:03.680
<v Speaker 1>interesting technique and this is </v>
<v Speaker 1>actually a so new,</v>

912
00:42:03.681 --> 00:42:04.514
<v Speaker 1>we,</v>
<v Speaker 1>I have students that are starting to </v>

913
00:42:05.541 --> 00:42:06.374
<v Speaker 1>look at this,</v>
<v Speaker 1>but we haven't really probed this very </v>

914
00:42:08.421 --> 00:42:09.680
<v Speaker 1>far.</v>
<v Speaker 1>So I actually don't know,</v>

915
00:42:10.020 --> 00:42:12.170
<v Speaker 1>uh,</v>
<v Speaker 1>how effective this is in general.</v>

916
00:42:12.380 --> 00:42:13.910
<v Speaker 1>But it's actually seems very </v>
<v Speaker 1>interesting.</v>

917
00:42:13.911 --> 00:42:14.744
<v Speaker 1>So they just start with a tiny four by </v>
<v Speaker 1>four image and once you train up that </v>

918
00:42:19.671 --> 00:42:20.504
<v Speaker 1>parameter,</v>
<v Speaker 1>those parameters for both the </v>

919
00:42:21.471 --> 00:42:24.080
<v Speaker 1>discriminator here and the generator.</v>
<v Speaker 1>So again,</v>

920
00:42:24.081 --> 00:42:26.000
<v Speaker 1>these are convolutions but we're </v>
<v Speaker 1>starting with,</v>

921
00:42:26.150 --> 00:42:30.110
<v Speaker 1>with a relatively small input,</v>
<v Speaker 1>we increased the size of the input,</v>

922
00:42:30.111 --> 00:42:32.060
<v Speaker 1>we add a layer and,</v>
<v Speaker 1>and,</v>

923
00:42:32.070 --> 00:42:32.903
<v Speaker 1>and the,</v>
<v Speaker 1>some of these parameters here actually </v>

924
00:42:34.491 --> 00:42:36.560
<v Speaker 1>formed by the parameters that gave you </v>
<v Speaker 1>this image.</v>

925
00:42:36.560 --> 00:42:37.393
<v Speaker 1>So you sort of just stick this up here </v>
<v Speaker 1>and now you add some parameters and </v>

926
00:42:40.041 --> 00:42:40.874
<v Speaker 1>you'd now train the model to learn </v>
<v Speaker 1>something bigger and you keep going and </v>

927
00:42:43.671 --> 00:42:45.740
<v Speaker 1>you keep going.</v>
<v Speaker 1>And then you get something like this.</v>

928
00:42:46.550 --> 00:42:47.780
<v Speaker 1>As far as I'm concerned,</v>
<v Speaker 1>this is this sort of,</v>

929
00:42:47.781 --> 00:42:51.560
<v Speaker 1>this amounts to kind of a curriculum of </v>
<v Speaker 1>training does two things for you.</v>

930
00:42:51.740 --> 00:42:52.573
<v Speaker 1>One is it helps build a bit of global </v>
<v Speaker 1>structure to the image because you're </v>

931
00:42:55.851 --> 00:42:58.160
<v Speaker 1>starting with such low dimensional,</v>
<v Speaker 1>um,</v>

932
00:42:58.820 --> 00:42:59.311
<v Speaker 1>inputs.</v>
<v Speaker 1>It,</v>

933
00:42:59.311 --> 00:43:01.670
<v Speaker 1>it helps reinforce the kind of global </v>
<v Speaker 1>structure,</v>

934
00:43:01.970 --> 00:43:03.680
<v Speaker 1>but it also does something else,</v>
<v Speaker 1>which is pretty important.</v>

935
00:43:03.910 --> 00:43:05.950
<v Speaker 1>It allows the model to sort of,</v>
<v Speaker 1>um,</v>

936
00:43:06.140 --> 00:43:08.660
<v Speaker 1>not have to spend a lot of time training</v>
<v Speaker 1>a very,</v>

937
00:43:08.661 --> 00:43:10.280
<v Speaker 1>very large model like this.</v>
<v Speaker 1>Right?</v>

938
00:43:10.281 --> 00:43:11.114
<v Speaker 1>You sweet.</v>
<v Speaker 1>I would imagine they spend relatively </v>

939
00:43:12.351 --> 00:43:14.480
<v Speaker 1>little time training here.</v>
<v Speaker 1>Although this is Nvidia,</v>

940
00:43:14.481 --> 00:43:16.850
<v Speaker 1>so they might spend a lot of time </v>
<v Speaker 1>training this,</v>

941
00:43:17.180 --> 00:43:18.013
<v Speaker 1>but um,</v>
<v Speaker 1>but it allows you to spend a lot of the </v>

942
00:43:19.611 --> 00:43:21.470
<v Speaker 1>time sort of in much,</v>
<v Speaker 1>much smaller models,</v>

943
00:43:21.860 --> 00:43:25.010
<v Speaker 1>so much more computationally efficient </v>
<v Speaker 1>to train this model.</v>

944
00:43:25.610 --> 00:43:26.870
<v Speaker 1>All right.</v>
<v Speaker 1>So that's it for me.</v>

945
00:43:26.871 --> 00:43:28.280
<v Speaker 1>Thanks a lot.</v>
<v Speaker 1>Oh wait.</v>

946
00:43:28.310 --> 00:43:29.143
<v Speaker 1>Oh yeah.</v>
<v Speaker 1>Sorry.</v>

947
00:43:29.150 --> 00:43:30.530
<v Speaker 1>One more thing I forgot.</v>
<v Speaker 1>Uh,</v>

948
00:43:30.531 --> 00:43:33.290
<v Speaker 1>this is just what they get.</v>
<v Speaker 1>Unconditional image.</v>

949
00:43:33.330 --> 00:43:35.880
<v Speaker 1>A generation now with amnesty.</v>
<v Speaker 1>So this is again,</v>

950
00:43:35.881 --> 00:43:39.260
<v Speaker 1>so you give it horse and then it's able </v>
<v Speaker 1>to generate this kind of thing.</v>

951
00:43:39.560 --> 00:43:41.330
<v Speaker 1>So far it's able to generate this,</v>
<v Speaker 1>right?</v>

952
00:43:41.360 --> 00:43:43.550
<v Speaker 1>So bicycles,</v>
<v Speaker 1>it's able to generate these,</v>

953
00:43:44.030 --> 00:43:45.670
<v Speaker 1>which is pretty amazing.</v>
<v Speaker 1>Um,</v>

954
00:43:46.250 --> 00:43:47.310
<v Speaker 1>quality.</v>
<v Speaker 1>Uh,</v>

955
00:43:47.360 --> 00:43:48.740
<v Speaker 1>if you zoom in here,</v>
<v Speaker 1>you can actually,</v>

956
00:43:48.741 --> 00:43:51.740
<v Speaker 1>it's kind of fun because the,</v>
<v Speaker 1>it kind of gets the idea of,</v>

957
00:43:51.770 --> 00:43:52.431
<v Speaker 1>of,</v>
<v Speaker 1>uh,</v>

958
00:43:52.431 --> 00:43:53.840
<v Speaker 1>these,</v>
<v Speaker 1>these spokes,</v>

959
00:43:53.841 --> 00:43:56.930
<v Speaker 1>but not exactly like some of them just </v>
<v Speaker 1>sort of end midway.</v>

960
00:43:57.400 --> 00:43:58.310
<v Speaker 1>Uh,</v>
<v Speaker 1>but yeah,</v>

961
00:43:58.880 --> 00:44:00.800
<v Speaker 1>but still a pretty,</v>
<v Speaker 1>pretty remarkable.</v>

962
00:44:01.460 --> 00:44:02.271
<v Speaker 1>All right.</v>
<v Speaker 1>So,</v>

963
00:44:02.271 --> 00:44:03.020
<v Speaker 1>uh,</v>
<v Speaker 1>thanks.</v>

964
00:44:03.020 --> 00:44:04.780
<v Speaker 1>If they have questions,</v>
<v Speaker 1>I'll take them.</v>

