WEBVTT

1
00:00:02.220 --> 00:00:03.053
<v Speaker 1>Good morning everyone,</v>
<v Speaker 1>as all of a sudden I'm the director of </v>

2
00:00:06.560 --> 00:00:07.393
<v Speaker 1>IBM Research Cambridge.</v>
<v Speaker 1>It's literally just a few blocks down </v>

3
00:00:11.341 --> 00:00:12.174
<v Speaker 1>the road.</v>
<v Speaker 1>I've worked probably 20 years in IBM </v>

4
00:00:14.161 --> 00:00:16.500
<v Speaker 1>research,</v>
<v Speaker 1>primarily out of our New York lab,</v>

5
00:00:17.190 --> 00:00:18.360
<v Speaker 1>but I moved here,</v>
<v Speaker 1>uh,</v>

6
00:00:18.450 --> 00:00:22.380
<v Speaker 1>just uh,</v>
<v Speaker 1>three months ago to really start up this</v>

7
00:00:22.381 --> 00:00:23.214
<v Speaker 1>new ai lab,</v>
<v Speaker 1>a refocus and significantly grow the </v>

8
00:00:26.731 --> 00:00:28.680
<v Speaker 1>Cambridge lab that we've,</v>
<v Speaker 1>we've already started.</v>

9
00:00:29.400 --> 00:00:34.400
<v Speaker 1>I intentionally chose a somewhat </v>
<v Speaker 1>provocative title to my,</v>

10
00:00:34.950 --> 00:00:36.810
<v Speaker 1>a talk today.</v>
<v Speaker 1>Um,</v>

11
00:00:37.290 --> 00:00:40.020
<v Speaker 1>the reason I wanted to,</v>
<v Speaker 1>the beyond deep learning,</v>

12
00:00:40.310 --> 00:00:42.660
<v Speaker 1>it's not necessarily to say that you </v>
<v Speaker 1>know,</v>

13
00:00:42.661 --> 00:00:45.810
<v Speaker 1>all of these deep learning techniques </v>
<v Speaker 1>are going to be obsolete.</v>

14
00:00:45.811 --> 00:00:49.200
<v Speaker 1>That's definitely not what I'm trying to</v>
<v Speaker 1>say,</v>

15
00:00:49.201 --> 00:00:51.330
<v Speaker 1>but I am trying to say that,</v>
<v Speaker 1>you know,</v>

16
00:00:51.331 --> 00:00:55.620
<v Speaker 1>although there's a lot of exciting </v>
<v Speaker 1>things that we can do with deep learning</v>

17
00:00:55.621 --> 00:00:58.680
<v Speaker 1>today,</v>
<v Speaker 1>there's also a frontier,</v>

18
00:00:58.760 --> 00:00:59.340
<v Speaker 1>a,</v>
<v Speaker 1>you know,</v>

19
00:00:59.340 --> 00:01:00.173
<v Speaker 1>a space that we can't do very well.</v>
<v Speaker 1>And so I hope to today talk to you </v>

20
00:01:05.281 --> 00:01:06.270
<v Speaker 1>about,</v>
<v Speaker 1>you know,</v>

21
00:01:06.271 --> 00:01:07.104
<v Speaker 1>kind of what is an area of a boundary </v>
<v Speaker 1>that we were not able to break through </v>

22
00:01:11.251 --> 00:01:16.251
<v Speaker 1>at this time that I think is critical </v>
<v Speaker 1>for machine intelligence,</v>

23
00:01:16.290 --> 00:01:20.520
<v Speaker 1>for artificial general intelligence.</v>
<v Speaker 1>So I'm hoping that today,</v>

24
00:01:20.850 --> 00:01:22.950
<v Speaker 1>uh,</v>
<v Speaker 1>I can set that up for you,</v>

25
00:01:23.140 --> 00:01:24.270
<v Speaker 1>uh,</v>
<v Speaker 1>hopefully,</v>

26
00:01:24.290 --> 00:01:24.840
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

27
00:01:24.840 --> 00:01:25.673
<v Speaker 1>motivate a additional people to come in </v>
<v Speaker 1>and study this because I really believe </v>

28
00:01:28.861 --> 00:01:29.694
<v Speaker 1>that it's a,</v>
<v Speaker 1>it's a critical area where we're </v>

29
00:01:31.390 --> 00:01:33.120
<v Speaker 1>additional breakthroughs are needed.</v>

30
00:01:35.760 --> 00:01:38.760
<v Speaker 1>I'd like to first introduce a IBM </v>
<v Speaker 1>research.</v>

31
00:01:38.800 --> 00:01:39.780
<v Speaker 1>Uh,</v>
<v Speaker 1>I don't know,</v>

32
00:01:39.830 --> 00:01:40.663
<v Speaker 1>uh,</v>
<v Speaker 1>how many of you actually know about IBM </v>

33
00:01:42.211 --> 00:01:45.060
<v Speaker 1>research?</v>
<v Speaker 1>Some of you may have heard of us because</v>

34
00:01:45.061 --> 00:01:45.894
<v Speaker 1>of the jeopardy challenge.</v>
<v Speaker 1>So in 2011 we created a computer that </v>

35
00:01:50.401 --> 00:01:55.050
<v Speaker 1>was able to beat the chest,</v>
<v Speaker 1>the jeopardy champions at that game.</v>

36
00:01:55.310 --> 00:01:57.870
<v Speaker 1>I'm very handily has,</v>
<v Speaker 1>as a matter of fact,</v>

37
00:01:57.930 --> 00:01:58.970
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

38
00:01:59.370 --> 00:02:02.880
<v Speaker 1>some people don't realize that our </v>
<v Speaker 1>research division is,</v>

39
00:02:02.881 --> 00:02:04.110
<v Speaker 1>uh,</v>
<v Speaker 1>is quite significant.</v>

40
00:02:04.111 --> 00:02:09.111
<v Speaker 1>So we have 3000 people worldwide,</v>
<v Speaker 1>a 12 labs that are doing this research.</v>

41
00:02:09.880 --> 00:02:11.590
<v Speaker 1>Our researchers,</v>
<v Speaker 1>uh,</v>

42
00:02:11.790 --> 00:02:15.110
<v Speaker 1>pursue the same types of accolades that,</v>
<v Speaker 1>you know,</v>

43
00:02:15.180 --> 00:02:20.180
<v Speaker 1>the top university professors go after.</v>
<v Speaker 1>So a Nobel laureates touring awards,</v>

44
00:02:20.731 --> 00:02:24.300
<v Speaker 1>National Academy of Sciences,</v>
<v Speaker 1>National Academy of Technologies.</v>

45
00:02:24.600 --> 00:02:28.190
<v Speaker 1>So we pursue a very rigorous,</v>
<v Speaker 1>uh,</v>

46
00:02:28.191 --> 00:02:29.190
<v Speaker 1>you know,</v>
<v Speaker 1>set of,</v>

47
00:02:29.210 --> 00:02:33.840
<v Speaker 1>of research in the areas that we focus </v>
<v Speaker 1>on all.</v>

48
00:02:33.930 --> 00:02:35.100
<v Speaker 1>And although I put the,</v>
<v Speaker 1>uh,</v>

49
00:02:35.101 --> 00:02:38.960
<v Speaker 1>the jeopardy challenge up there,</v>
<v Speaker 1>you're only as good as your,</v>

50
00:02:38.961 --> 00:02:40.260
<v Speaker 1>your most recent results.</v>

51
00:02:40.260 --> 00:02:41.093
<v Speaker 1>Right.</v>
<v Speaker 1>So I also wanted to make sure that I </v>

52
00:02:42.661 --> 00:02:45.810
<v Speaker 1>talked a little bit about things that </v>
<v Speaker 1>we've done more recently.</v>

53
00:02:45.811 --> 00:02:46.820
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

54
00:02:46.830 --> 00:02:48.290
<v Speaker 1>in 2017,</v>
<v Speaker 1>uh,</v>

55
00:02:48.300 --> 00:02:49.980
<v Speaker 1>as an example,</v>
<v Speaker 1>uh,</v>

56
00:02:49.981 --> 00:02:54.810
<v Speaker 1>we created the first 50 cubit,</v>
<v Speaker 1>a quantum computer.</v>

57
00:02:55.730 --> 00:02:58.050
<v Speaker 1>Uh,</v>
<v Speaker 1>most people are kind of,</v>

58
00:02:58.360 --> 00:02:59.090
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

59
00:02:59.090 --> 00:02:59.923
<v Speaker 1>I expect to actually see some people </v>
<v Speaker 1>announcing some other companies </v>

60
00:03:02.441 --> 00:03:06.970
<v Speaker 1>announcing simulators for 50 on the </v>
<v Speaker 1>order of 50 cubits.</v>

61
00:03:07.000 --> 00:03:11.100
<v Speaker 1>And the difference here is that we're </v>
<v Speaker 1>talking about an actual 50 cubits,</v>

62
00:03:11.130 --> 00:03:13.350
<v Speaker 1>a quantum computer.</v>
<v Speaker 1>Uh,</v>

63
00:03:13.450 --> 00:03:15.190
<v Speaker 1>so we,</v>
<v Speaker 1>we also have the simulators,</v>

64
00:03:15.610 --> 00:03:16.443
<v Speaker 1>but we have the real quantum computers.</v>
<v Speaker 1>I think what's also unique about what </v>

65
00:03:19.541 --> 00:03:20.374
<v Speaker 1>we're doing is that we're also making </v>
<v Speaker 1>our quantum computing capabilities </v>

66
00:03:25.151 --> 00:03:25.984
<v Speaker 1>available through the cloud so that </v>
<v Speaker 1>people can kind of log in and they can </v>

67
00:03:28.391 --> 00:03:31.510
<v Speaker 1>experiment and learn about what quantum </v>
<v Speaker 1>computing is.</v>

68
00:03:31.511 --> 00:03:33.940
<v Speaker 1>So,</v>
<v Speaker 1>so very exciting program for us.</v>

69
00:03:34.560 --> 00:03:35.930
<v Speaker 1>We also,</v>
<v Speaker 1>in 2017,</v>

70
00:03:35.931 --> 00:03:40.600
<v Speaker 1>we were able to show a near linear scale</v>
<v Speaker 1>out in terms of,</v>

71
00:03:40.620 --> 00:03:43.660
<v Speaker 1>you know,</v>
<v Speaker 1>cafe deep learning models on,</v>

72
00:03:43.661 --> 00:03:44.740
<v Speaker 1>on our servers.</v>

73
00:03:45.440 --> 00:03:46.273
<v Speaker 1>We were able to show algorithms that </v>
<v Speaker 1>were able to exploit the quantum </v>

74
00:03:50.981 --> 00:03:51.880
<v Speaker 1>advantage.</v>
<v Speaker 1>Uh,</v>

75
00:03:51.910 --> 00:03:56.910
<v Speaker 1>so the idea is that if you,</v>
<v Speaker 1>in order to actually get the speed ups,</v>

76
00:03:57.370 --> 00:03:58.960
<v Speaker 1>uh,</v>
<v Speaker 1>on quantum computers,</v>

77
00:03:59.230 --> 00:04:00.063
<v Speaker 1>you need to be able to map problems into</v>
<v Speaker 1>a form where you can get that </v>

78
00:04:04.121 --> 00:04:06.070
<v Speaker 1>acceleration.</v>
<v Speaker 1>And when you get that acceleration,</v>

79
00:04:06.071 --> 00:04:06.904
<v Speaker 1>then you're talking about exponential </v>
<v Speaker 1>acceleration over traditional computers </v>

80
00:04:10.031 --> 00:04:11.530
<v Speaker 1>that people are using today.</v>
<v Speaker 1>Uh,</v>

81
00:04:11.630 --> 00:04:12.463
<v Speaker 1>so this particular result was an </v>
<v Speaker 1>algorithm that's able to basically map </v>

82
00:04:16.240 --> 00:04:18.490
<v Speaker 1>small molecules,</v>
<v Speaker 1>models of small molecules,</v>

83
00:04:18.550 --> 00:04:19.580
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

84
00:04:19.590 --> 00:04:24.590
<v Speaker 1>onto the actual quantum computing system</v>
<v Speaker 1>so that we could demonstrate the ability</v>

85
00:04:25.361 --> 00:04:27.550
<v Speaker 1>to find the lowest energy state.</v>
<v Speaker 1>So,</v>

86
00:04:27.670 --> 00:04:28.503
<v Speaker 1>and,</v>
<v Speaker 1>and get that exponential speed up from </v>

87
00:04:30.071 --> 00:04:31.090
<v Speaker 1>that.</v>
<v Speaker 1>Um,</v>

88
00:04:31.880 --> 00:04:32.713
<v Speaker 1>you know,</v>
<v Speaker 1>the thing is that in 2017 we were named </v>

89
00:04:34.620 --> 00:04:35.453
<v Speaker 1>a number one,</v>
<v Speaker 1>a leading corporation for a scientific </v>

90
00:04:39.700 --> 00:04:42.730
<v Speaker 1>scientific research at a corporate </v>
<v Speaker 1>institute.</v>

91
00:04:42.731 --> 00:04:44.470
<v Speaker 1>So that's pretty exciting for us.</v>

92
00:04:46.050 --> 00:04:50.740
<v Speaker 1>I also wanted to just tell you a little </v>
<v Speaker 1>bit about the Mit Watson Mit,</v>

93
00:04:50.741 --> 00:04:51.574
<v Speaker 1>IBM Watson Ai Lab.</v>
<v Speaker 1>It's obviously a very exciting </v>

94
00:04:54.190 --> 00:04:58.840
<v Speaker 1>announcement for us.</v>
<v Speaker 1>So in September of 2017,</v>

95
00:04:58.841 --> 00:05:03.841
<v Speaker 1>we announced that we were building this,</v>
<v Speaker 1>a $240 million dollar,</v>

96
00:05:04.510 --> 00:05:09.510
<v Speaker 1>a joint effort with mit to pursue </v>
<v Speaker 1>fundamental advances in ai.</v>

97
00:05:10.900 --> 00:05:13.210
<v Speaker 1>Uh,</v>
<v Speaker 1>the core areas are listed here.</v>

98
00:05:13.211 --> 00:05:15.940
<v Speaker 1>So when I say fundamental advances in </v>
<v Speaker 1>Ai,</v>

99
00:05:16.030 --> 00:05:17.500
<v Speaker 1>it's really,</v>
<v Speaker 1>again,</v>

100
00:05:17.501 --> 00:05:18.334
<v Speaker 1>recognizing what we can and can't do </v>
<v Speaker 1>with ai today and then trying to create </v>

101
00:05:23.171 --> 00:05:28.060
<v Speaker 1>new algorithms to go beyond that.</v>
<v Speaker 1>So examples of problems,</v>

102
00:05:28.090 --> 00:05:31.090
<v Speaker 1>I'm just very quickly that we're </v>
<v Speaker 1>interested in,</v>

103
00:05:31.091 --> 00:05:33.520
<v Speaker 1>in terms of the,</v>
<v Speaker 1>the new Ai Lab,</v>

104
00:05:33.900 --> 00:05:35.590
<v Speaker 1>uh,</v>
<v Speaker 1>one area is that,</v>

105
00:05:35.920 --> 00:05:36.551
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

106
00:05:36.551 --> 00:05:41.020
<v Speaker 1>learning causal structure from data is a</v>
<v Speaker 1>very challenging problem.</v>

107
00:05:41.370 --> 00:05:42.203
<v Speaker 1>Uh,</v>
<v Speaker 1>we're looking at how we can use data </v>

108
00:05:44.860 --> 00:05:45.693
<v Speaker 1>that was captured due to a crisper </v>
<v Speaker 1>mediations are crispr gene in </v>

109
00:05:50.561 --> 00:05:51.394
<v Speaker 1>activations,</v>
<v Speaker 1>which basically has very large set of </v>

110
00:05:55.031 --> 00:05:58.280
<v Speaker 1>interventional data where they're </v>
<v Speaker 1>observing the whole genome.</v>

111
00:05:58.580 --> 00:06:01.580
<v Speaker 1>Um,</v>
<v Speaker 1>and we're going to try to learn a causal</v>

112
00:06:01.581 --> 00:06:02.540
<v Speaker 1>structure,</v>
<v Speaker 1>uh,</v>

113
00:06:02.541 --> 00:06:03.410
<v Speaker 1>you know,</v>
<v Speaker 1>from those,</v>

114
00:06:03.440 --> 00:06:04.700
<v Speaker 1>those intervention.</v>
<v Speaker 1>So that's,</v>

115
00:06:04.720 --> 00:06:08.270
<v Speaker 1>that's one example.</v>
<v Speaker 1>Another example in physics of Ai,</v>

116
00:06:08.660 --> 00:06:10.370
<v Speaker 1>uh,</v>
<v Speaker 1>basically what we're talking about,</v>

117
00:06:10.371 --> 00:06:11.204
<v Speaker 1>there's the ability to have ai help </v>
<v Speaker 1>quantum computing and quantum computers </v>

118
00:06:15.141 --> 00:06:18.160
<v Speaker 1>and quantum computers accelerate ai </v>
<v Speaker 1>algorithms.</v>

119
00:06:18.161 --> 00:06:20.600
<v Speaker 1>So we're looking at problems,</v>
<v Speaker 1>for example,</v>

120
00:06:20.760 --> 00:06:21.593
<v Speaker 1>the machine learning algorithms that </v>
<v Speaker 1>will help us to manage the state of the </v>

121
00:06:23.661 --> 00:06:25.460
<v Speaker 1>quantum computer.</v>
<v Speaker 1>Also,</v>

122
00:06:25.480 --> 00:06:26.630
<v Speaker 1>uh,</v>
<v Speaker 1>looking at,</v>

123
00:06:26.700 --> 00:06:27.800
<v Speaker 1>uh,</v>
<v Speaker 1>for example,</v>

124
00:06:27.801 --> 00:06:28.634
<v Speaker 1>the ability to,</v>
<v Speaker 1>knowing what we know about quantum </v>

125
00:06:30.591 --> 00:06:31.880
<v Speaker 1>computers,</v>
<v Speaker 1>knowing that,</v>

126
00:06:32.030 --> 00:06:32.863
<v Speaker 1>you know,</v>
<v Speaker 1>we're going to be in the small numbers </v>

127
00:06:34.011 --> 00:06:36.530
<v Speaker 1>of,</v>
<v Speaker 1>of hundreds of cubits for some time,</v>

128
00:06:36.531 --> 00:06:37.364
<v Speaker 1>that the memory bandwidth between a </v>
<v Speaker 1>traditional computers and the quantum </v>

129
00:06:40.701 --> 00:06:44.870
<v Speaker 1>computers going to be relative small,</v>
<v Speaker 1>which of the machine learning algorithms</v>

130
00:06:44.871 --> 00:06:48.770
<v Speaker 1>will we be able to map onto those </v>
<v Speaker 1>systems in order to get that exponential</v>

131
00:06:49.040 --> 00:06:49.460
<v Speaker 1>speed up.</v>

132
00:06:49.460 --> 00:06:52.880
<v Speaker 1>So those are just some of the examples </v>
<v Speaker 1>of things that we're studying.</v>

133
00:06:53.300 --> 00:06:54.810
<v Speaker 1>Um,</v>
<v Speaker 1>also we,</v>

134
00:06:54.811 --> 00:06:55.644
<v Speaker 1>we feel that right now there are two </v>
<v Speaker 1>industries that are really ripe for ai </v>

135
00:06:59.871 --> 00:07:02.930
<v Speaker 1>disruption.</v>
<v Speaker 1>One is healthcare life sciences.</v>

136
00:07:03.320 --> 00:07:07.490
<v Speaker 1>The reason they are ripe for disruption </v>
<v Speaker 1>is because that community has invested a</v>

137
00:07:07.491 --> 00:07:09.980
<v Speaker 1>lot to create what we refer to a </v>
<v Speaker 1>structured knowledge.</v>

138
00:07:10.250 --> 00:07:12.500
<v Speaker 1>So you know,</v>
<v Speaker 1>gene ontology,</v>

139
00:07:12.501 --> 00:07:13.630
<v Speaker 1>you know,</v>
<v Speaker 1>Snow Med,</v>

140
00:07:13.640 --> 00:07:14.473
<v Speaker 1>clinical terms,</v>
<v Speaker 1>all of the structured knowledge that we </v>

141
00:07:15.921 --> 00:07:20.921
<v Speaker 1>can combine with observational data and </v>
<v Speaker 1>create new algorithms and insecurity.</v>

142
00:07:20.991 --> 00:07:21.824
<v Speaker 1>The reason why cyber security,</v>
<v Speaker 1>the reason why that one is ripe for </v>

143
00:07:23.781 --> 00:07:28.781
<v Speaker 1>disruption is because if everybody is </v>
<v Speaker 1>advancing these ai algorithms and people</v>

144
00:07:29.421 --> 00:07:33.320
<v Speaker 1>start to try to use those ai algorithms </v>
<v Speaker 1>to attack our systems,</v>

145
00:07:33.710 --> 00:07:34.543
<v Speaker 1>it's very important that we also use ai </v>
<v Speaker 1>algorithms to try to figure out how </v>

146
00:07:38.361 --> 00:07:41.240
<v Speaker 1>they're going to do that and how to </v>
<v Speaker 1>defend against that.</v>

147
00:07:41.240 --> 00:07:42.073
<v Speaker 1>So there's some of the examples.</v>
<v Speaker 1>The last one shared prosperity is about </v>

148
00:07:44.991 --> 00:07:49.991
<v Speaker 1>how do we get nondiscrimination on bias </v>
<v Speaker 1>morals into the algorithms,</v>

149
00:07:50.961 --> 00:07:51.794
<v Speaker 1>not just training on,</v>
<v Speaker 1>for scale out and accuracy and these </v>

150
00:07:55.011 --> 00:07:58.270
<v Speaker 1>sorts of things.</v>
<v Speaker 1>All right?</v>

151
00:07:58.310 --> 00:07:59.143
<v Speaker 1>Uh,</v>
<v Speaker 1>we,</v>

152
00:07:59.180 --> 00:08:04.180
<v Speaker 1>we already had our first announcement in</v>
<v Speaker 1>terms of the new mit IBM Watson Ai Lab.</v>

153
00:08:04.760 --> 00:08:09.760
<v Speaker 1>So at nips we announced that we are </v>
<v Speaker 1>releasing a 1 million video data set.</v>

154
00:08:11.300 --> 00:08:12.133
<v Speaker 1>Uh,</v>
<v Speaker 1>the idea for those of you are familiar </v>

155
00:08:13.581 --> 00:08:14.414
<v Speaker 1>and you've probably learned a lot in </v>
<v Speaker 1>this class about how people used image </v>

156
00:08:17.211 --> 00:08:20.690
<v Speaker 1>net to make new breakthroughs in terms </v>
<v Speaker 1>of deep learning.</v>

157
00:08:21.100 --> 00:08:21.933
<v Speaker 1>Uh,</v>
<v Speaker 1>just that volume of labeled data meant </v>

158
00:08:24.021 --> 00:08:27.290
<v Speaker 1>that people could go in and run </v>
<v Speaker 1>experiments and train networks that they</v>

159
00:08:27.291 --> 00:08:28.740
<v Speaker 1>could never do before.</v>
<v Speaker 1>Uh,</v>

160
00:08:28.850 --> 00:08:30.110
<v Speaker 1>so we've created,</v>
<v Speaker 1>uh,</v>

161
00:08:30.120 --> 00:08:30.600
<v Speaker 1>this,</v>
<v Speaker 1>uh,</v>

162
00:08:30.600 --> 00:08:31.433
<v Speaker 1>this million video data set,</v>
<v Speaker 1>a three second videos were chosen for a </v>

163
00:08:35.690 --> 00:08:38.510
<v Speaker 1>specific reason.</v>
<v Speaker 1>I'm the lead for this project.</v>

164
00:08:38.510 --> 00:08:40.230
<v Speaker 1>Oh,</v>
<v Speaker 1>deliver is a,</v>

165
00:08:40.280 --> 00:08:43.490
<v Speaker 1>has great expertise,</v>
<v Speaker 1>not only in computer science but also in</v>

166
00:08:43.491 --> 00:08:45.830
<v Speaker 1>cognitive science.</v>
<v Speaker 1>And so it's expected that,</v>

167
00:08:46.110 --> 00:08:46.943
<v Speaker 1>you know,</v>
<v Speaker 1>three seconds is roughly the order of </v>

168
00:08:48.081 --> 00:08:51.860
<v Speaker 1>times that it takes humans to recognize </v>
<v Speaker 1>a certain actions as well.</v>

169
00:08:51.861 --> 00:08:54.350
<v Speaker 1>So we're,</v>
<v Speaker 1>we're kind of sticking with that time.</v>

170
00:08:54.930 --> 00:08:55.763
<v Speaker 1>Computers aren't the machine learning </v>
<v Speaker 1>algorithms that you were learning about </v>

171
00:08:57.961 --> 00:09:00.390
<v Speaker 1>today aren't able to do this.</v>
<v Speaker 1>Well,</v>

172
00:09:01.440 --> 00:09:05.850
<v Speaker 1>primary learned about so far was how to </v>
<v Speaker 1>segment images.</v>

173
00:09:05.851 --> 00:09:09.260
<v Speaker 1>How to find objects within images,</v>
<v Speaker 1>how to classify those,</v>

174
00:09:09.290 --> 00:09:11.820
<v Speaker 1>those objects,</v>
<v Speaker 1>but not actions.</v>

175
00:09:12.240 --> 00:09:13.073
<v Speaker 1>And the reason why we also think that </v>
<v Speaker 1>actions are important is because they </v>

176
00:09:15.811 --> 00:09:17.040
<v Speaker 1>are composable,</v>
<v Speaker 1>right?</v>

177
00:09:17.041 --> 00:09:20.760
<v Speaker 1>So we want to be able to learn not just </v>
<v Speaker 1>elemental actions from these videos,</v>

178
00:09:21.000 --> 00:09:21.833
<v Speaker 1>but then to start to think about how you</v>
<v Speaker 1>recognize and detect compositions of </v>

179
00:09:26.041 --> 00:09:26.874
<v Speaker 1>actions and procedures that people are </v>
<v Speaker 1>performing because then we can use that </v>

180
00:09:30.961 --> 00:09:31.794
<v Speaker 1>to start to teach the computers to also </v>
<v Speaker 1>perform those procedures or to help </v>

181
00:09:37.951 --> 00:09:41.160
<v Speaker 1>humans to be able to perform those </v>
<v Speaker 1>procedures better.</v>

182
00:09:44.400 --> 00:09:45.233
<v Speaker 1>Okay.</v>
<v Speaker 1>Now what I want to do is maybe take a </v>

183
00:09:47.101 --> 00:09:50.700
<v Speaker 1>break from kind of the setup and get </v>
<v Speaker 1>into the more technical part of the,</v>

184
00:09:50.701 --> 00:09:51.780
<v Speaker 1>uh,</v>
<v Speaker 1>of the talk today.</v>

185
00:09:51.781 --> 00:09:52.650
<v Speaker 1>So,</v>
<v Speaker 1>um,</v>

186
00:09:52.920 --> 00:09:54.600
<v Speaker 1>as I was saying earlier,</v>
<v Speaker 1>you know,</v>

187
00:09:54.660 --> 00:09:57.210
<v Speaker 1>what we've seen recently in deep </v>
<v Speaker 1>learning is,</v>

188
00:09:57.270 --> 00:09:59.370
<v Speaker 1>is truly all inspiring.</v>
<v Speaker 1>I mean,</v>

189
00:09:59.371 --> 00:10:00.204
<v Speaker 1>in terms of the number of breakthroughs </v>
<v Speaker 1>over over the last 10 years and </v>

190
00:10:02.971 --> 00:10:03.804
<v Speaker 1>especially over the last five years,</v>
<v Speaker 1>it is very exciting breakthroughs in </v>

191
00:10:07.561 --> 00:10:08.410
<v Speaker 1>terms of,</v>
<v Speaker 1>you know,</v>

192
00:10:08.460 --> 00:10:10.890
<v Speaker 1>being able to,</v>
<v Speaker 1>for certain tasks,</v>

193
00:10:11.220 --> 00:10:11.821
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

194
00:10:11.821 --> 00:10:15.120
<v Speaker 1>beat human error rates in terms of </v>
<v Speaker 1>visual recognition.</v>

195
00:10:15.121 --> 00:10:18.000
<v Speaker 1>And speech,</v>
<v Speaker 1>a speech recognition and so on.</v>

196
00:10:18.290 --> 00:10:19.123
<v Speaker 1>Um,</v>
<v Speaker 1>but my position is that there are still </v>

197
00:10:22.440 --> 00:10:27.440
<v Speaker 1>huge breakthroughs that are required to </v>
<v Speaker 1>try to get to machine intelligence.</v>

198
00:10:27.751 --> 00:10:32.751
<v Speaker 1>So some examples of challenges that the </v>
<v Speaker 1>systems of today aren't able to do.</v>

199
00:10:33.901 --> 00:10:35.760
<v Speaker 1>So one is that,</v>
<v Speaker 1>um,</v>

200
00:10:35.850 --> 00:10:36.683
<v Speaker 1>many,</v>
<v Speaker 1>many of the scenarios in order to get </v>

201
00:10:38.431 --> 00:10:43.150
<v Speaker 1>the performance that actually is usable </v>
<v Speaker 1>requires labeled data.</v>

202
00:10:43.150 --> 00:10:43.983
<v Speaker 1>It requires training data where you've </v>
<v Speaker 1>actually labeled the objects and the </v>

203
00:10:46.651 --> 00:10:48.990
<v Speaker 1>images and so on.</v>
<v Speaker 1>Um,</v>

204
00:10:49.230 --> 00:10:53.550
<v Speaker 1>while the systems are getting better in </v>
<v Speaker 1>terms of doing unsupervised learning,</v>

205
00:10:53.600 --> 00:10:54.433
<v Speaker 1>uh,</v>
<v Speaker 1>because of the vast amount of data </v>

206
00:10:55.561 --> 00:10:57.690
<v Speaker 1>that's available on the web.</v>
<v Speaker 1>Uh,</v>

207
00:10:58.570 --> 00:11:03.570
<v Speaker 1>the problem is that we at IBM care about</v>
<v Speaker 1>Ai for businesses,</v>

208
00:11:03.870 --> 00:11:06.240
<v Speaker 1>right?</v>
<v Speaker 1>And if you think of ai for businesses,</v>

209
00:11:06.450 --> 00:11:11.450
<v Speaker 1>there's just not that much deep domain </v>
<v Speaker 1>data that we're able to find,</v>

210
00:11:12.540 --> 00:11:14.370
<v Speaker 1>right?</v>
<v Speaker 1>So if you think about the medical field,</v>

211
00:11:14.700 --> 00:11:19.700
<v Speaker 1>very deep expressive relations that are </v>
<v Speaker 1>required to be understood.</v>

212
00:11:20.330 --> 00:11:22.390
<v Speaker 1>And of course a lot of labeled data.</v>
<v Speaker 1>Uh,</v>

213
00:11:22.500 --> 00:11:23.111
<v Speaker 1>you know,</v>
<v Speaker 1>uh,</v>

214
00:11:23.111 --> 00:11:24.510
<v Speaker 1>if you think of,</v>
<v Speaker 1>you know,</v>

215
00:11:24.511 --> 00:11:25.344
<v Speaker 1>uh,</v>
<v Speaker 1>an airline manufacturer and all of the </v>

216
00:11:26.910 --> 00:11:27.743
<v Speaker 1>manuals they may have and they'd like to</v>
<v Speaker 1>try to be able to answer questions from </v>

217
00:11:30.601 --> 00:11:31.434
<v Speaker 1>those and be able to reason and help </v>
<v Speaker 1>humans understand how to conduct </v>

218
00:11:34.051 --> 00:11:35.280
<v Speaker 1>procedures within those.</v>

219
00:11:36.420 --> 00:11:37.253
<v Speaker 1>There's not enough data out there on </v>
<v Speaker 1>those fields in terms of relationships </v>

220
00:11:40.441 --> 00:11:44.610
<v Speaker 1>and entities and so on for us to train.</v>
<v Speaker 1>So it requires a lot of labeling.</v>

221
00:11:44.611 --> 00:11:45.444
<v Speaker 1>Humans actually going through and </v>
<v Speaker 1>finding the important entities and </v>

222
00:11:47.701 --> 00:11:48.534
<v Speaker 1>relationships and so on.</v>
<v Speaker 1>So an important area that we need to be </v>

223
00:11:51.451 --> 00:11:53.260
<v Speaker 1>able to break through is,</v>
<v Speaker 1>first of all,</v>

224
00:11:53.261 --> 00:11:54.094
<v Speaker 1>why?</v>
<v Speaker 1>Why,</v>

225
00:11:54.130 --> 00:11:54.963
<v Speaker 1>why do these machines,</v>
<v Speaker 1>why do these networks require so much </v>

226
00:11:57.521 --> 00:12:00.730
<v Speaker 1>data labeled data?</v>
<v Speaker 1>And can we,</v>

227
00:12:00.940 --> 00:12:03.430
<v Speaker 1>can we address that?</v>
<v Speaker 1>Can we make the algorithms better?</v>

228
00:12:04.240 --> 00:12:05.073
<v Speaker 1>The second thing is that you've probably</v>
<v Speaker 1>realized that you train up the </v>

229
00:12:07.241 --> 00:12:09.580
<v Speaker 1>algorithms and then they're able to </v>
<v Speaker 1>perform some tasks.</v>

230
00:12:09.880 --> 00:12:12.400
<v Speaker 1>The tasks are getting more and more </v>
<v Speaker 1>sophisticated,</v>

231
00:12:12.430 --> 00:12:13.263
<v Speaker 1>self driving cars and so on,</v>
<v Speaker 1>but you're still not training this </v>

232
00:12:16.391 --> 00:12:19.150
<v Speaker 1>network so that it can form many </v>
<v Speaker 1>different tasks.</v>

233
00:12:19.600 --> 00:12:24.400
<v Speaker 1>And even more importantly,</v>
<v Speaker 1>what happens is that you learn a model,</v>

234
00:12:24.430 --> 00:12:26.200
<v Speaker 1>and even though you may,</v>
<v Speaker 1>as part of the training,</v>

235
00:12:26.201 --> 00:12:29.860
<v Speaker 1>you may have reinforcement learning </v>
<v Speaker 1>that's not lifelong learning,</v>

236
00:12:29.861 --> 00:12:30.694
<v Speaker 1>that's not just turning the cars out on </v>
<v Speaker 1>the road and enabling them to continue </v>

237
00:12:34.601 --> 00:12:39.010
<v Speaker 1>to learn and aggregate information and </v>
<v Speaker 1>bring that into a representation so that</v>

238
00:12:39.011 --> 00:12:40.800
<v Speaker 1>they can adapt to,</v>
<v Speaker 1>you know,</v>

239
00:12:40.870 --> 00:12:43.750
<v Speaker 1>non stationary environments,</v>
<v Speaker 1>environments that change over time.</v>

240
00:12:44.290 --> 00:12:45.550
<v Speaker 1>Another thing is that,</v>
<v Speaker 1>you know,</v>

241
00:12:45.820 --> 00:12:46.653
<v Speaker 1>when we train these networks,</v>
<v Speaker 1>you kind of get it down to a certain </v>

242
00:12:48.221 --> 00:12:49.054
<v Speaker 1>error rate.</v>
<v Speaker 1>But how do you keep improving the </v>

243
00:12:53.021 --> 00:12:55.540
<v Speaker 1>accuracy even though the error rate is </v>
<v Speaker 1>not that bad?</v>

244
00:12:56.220 --> 00:12:58.840
<v Speaker 1>Now go to them stone,</v>
<v Speaker 1>don't do well at this today.</v>

245
00:12:59.740 --> 00:13:00.573
<v Speaker 1>And then the last area is that it's </v>
<v Speaker 1>really important that we're creating </v>

246
00:13:03.071 --> 00:13:04.960
<v Speaker 1>algorithms that are interacting with the</v>
<v Speaker 1>humans,</v>

247
00:13:04.961 --> 00:13:05.860
<v Speaker 1>right?</v>
<v Speaker 1>That can,</v>

248
00:13:06.240 --> 00:13:07.210
<v Speaker 1>uh,</v>
<v Speaker 1>explain,</v>

249
00:13:07.600 --> 00:13:08.433
<v Speaker 1>uh,</v>
<v Speaker 1>how they may have come to a particular </v>

250
00:13:10.300 --> 00:13:13.000
<v Speaker 1>decision or classification or whatever </v>
<v Speaker 1>the case may be.</v>

251
00:13:13.001 --> 00:13:18.001
<v Speaker 1>So we need to try to think about how can</v>
<v Speaker 1>we build machines that can learn,</v>

252
00:13:18.851 --> 00:13:21.520
<v Speaker 1>that can listen,</v>
<v Speaker 1>interact with the humans,</v>

253
00:13:21.880 --> 00:13:25.600
<v Speaker 1>be able to explain their,</v>
<v Speaker 1>their decisions to humans.</v>

254
00:13:25.601 --> 00:13:28.270
<v Speaker 1>And so a big part of this is what we </v>
<v Speaker 1>were,</v>

255
00:13:28.330 --> 00:13:31.390
<v Speaker 1>what I refer to and what many in the </v>
<v Speaker 1>community refer to as,</v>

256
00:13:31.391 --> 00:13:33.190
<v Speaker 1>you know,</v>
<v Speaker 1>learning plus reasoning,</v>

257
00:13:33.730 --> 00:13:34.563
<v Speaker 1>meaning that we want to be able to </v>
<v Speaker 1>reason on representations that are </v>

258
00:13:38.471 --> 00:13:39.304
<v Speaker 1>learned preferably on representations </v>
<v Speaker 1>that are learned in an unsupervised </v>

259
00:13:42.791 --> 00:13:43.624
<v Speaker 1>manner.</v>

260
00:13:46.490 --> 00:13:47.323
<v Speaker 1>All right?</v>
<v Speaker 1>The first step in doing that is to be </v>

261
00:13:49.421 --> 00:13:52.120
<v Speaker 1>able to make language itself </v>
<v Speaker 1>computational,</v>

262
00:13:52.270 --> 00:13:55.590
<v Speaker 1>right?</v>
<v Speaker 1>So we are able to think about words as,</v>

263
00:13:55.591 --> 00:14:00.010
<v Speaker 1>as sort of symbols and what those words </v>
<v Speaker 1>mean and the properties of them.</v>

264
00:14:00.011 --> 00:14:00.844
<v Speaker 1>And then reason about them.</v>
<v Speaker 1>If you think about all the algorithms </v>

265
00:14:03.281 --> 00:14:07.990
<v Speaker 1>that you've been learning,</v>
<v Speaker 1>they expect the information to be coming</v>

266
00:14:07.991 --> 00:14:10.150
<v Speaker 1>to them as,</v>
<v Speaker 1>as numerical information,</v>

267
00:14:10.151 --> 00:14:10.984
<v Speaker 1>preferably as real valued information.</v>
<v Speaker 1>How do you go from text to real valued </v>

268
00:14:15.991 --> 00:14:16.824
<v Speaker 1>information that can then be fed into </v>
<v Speaker 1>these algorithms over time and then </v>

269
00:14:20.651 --> 00:14:24.540
<v Speaker 1>computed on.</v>
<v Speaker 1>So one of the first areas here is,</v>

270
00:14:24.541 --> 00:14:26.470
<v Speaker 1>uh,</v>
<v Speaker 1>his word embeddings.</v>

271
00:14:26.800 --> 00:14:29.710
<v Speaker 1>Uh,</v>
<v Speaker 1>the reason I italicized words is because</v>

272
00:14:30.040 --> 00:14:33.430
<v Speaker 1>what you'll see is that we kind of </v>
<v Speaker 1>started out with word embeddings,</v>

273
00:14:33.431 --> 00:14:35.050
<v Speaker 1>but now it's a,</v>
<v Speaker 1>you know,</v>

274
00:14:35.230 --> 00:14:36.940
<v Speaker 1>phrase,</v>
<v Speaker 1>embeddings document and vetting.</v>

275
00:14:36.941 --> 00:14:38.590
<v Speaker 1>So there's much more to this,</v>
<v Speaker 1>um,</v>

276
00:14:39.100 --> 00:14:39.933
<v Speaker 1>but let's,</v>
<v Speaker 1>let's start first with what do we mean </v>

277
00:14:41.141 --> 00:14:42.310
<v Speaker 1>with word embeddings?</v>

278
00:14:42.390 --> 00:14:47.230
<v Speaker 1>Okay.</v>
<v Speaker 1>The point is to try to represent ordered</v>

279
00:14:47.350 --> 00:14:48.183
<v Speaker 1>as a real valued vector,</v>
<v Speaker 1>a that basically what that words means </v>

280
00:14:53.930 --> 00:14:55.940
<v Speaker 1>in terms of other words,</v>
<v Speaker 1>right?</v>

281
00:14:55.941 --> 00:14:56.741
<v Speaker 1>So,</v>
<v Speaker 1>so the,</v>

282
00:14:56.741 --> 00:15:01.460
<v Speaker 1>the dimensions of that factor of the </v>
<v Speaker 1>features or basically other words.</v>

283
00:15:02.510 --> 00:15:03.343
<v Speaker 1>And the point is that you can assign </v>
<v Speaker 1>different weights on how well that word </v>

284
00:15:07.251 --> 00:15:09.300
<v Speaker 1>relates to these other words.</v>
<v Speaker 1>Okay?</v>

285
00:15:09.950 --> 00:15:10.783
<v Speaker 1>Now the difficult part there is how do </v>
<v Speaker 1>you learn that representation that's </v>

286
00:15:15.621 --> 00:15:20.621
<v Speaker 1>going to give you that objective of </v>
<v Speaker 1>making that vector really represent that</v>

287
00:15:21.771 --> 00:15:25.870
<v Speaker 1>word and be comparable to other words in</v>
<v Speaker 1>a way that the machine can,</v>

288
00:15:25.900 --> 00:15:26.733
<v Speaker 1>can compute on them.</v>
<v Speaker 1>So the idea is the first work earlier </v>

289
00:15:30.641 --> 00:15:31.880
<v Speaker 1>work in this was,</v>
<v Speaker 1>all right,</v>

290
00:15:32.420 --> 00:15:37.220
<v Speaker 1>how do we do this?</v>
<v Speaker 1>Such that those embeddings,</v>

291
00:15:37.221 --> 00:15:38.054
<v Speaker 1>those vectors give you an understanding </v>
<v Speaker 1>of similarity between this word and </v>

292
00:15:42.801 --> 00:15:43.634
<v Speaker 1>other words within your dictionary first</v>
<v Speaker 1>model here was what they referred to as </v>

293
00:15:48.171 --> 00:15:49.340
<v Speaker 1>a skip gram model.</v>

294
00:15:49.660 --> 00:15:51.230
<v Speaker 1>Uh,</v>
<v Speaker 1>basically what you try to do,</v>

295
00:15:51.231 --> 00:15:53.990
<v Speaker 1>as you say,</v>
<v Speaker 1>given a particular word,</v>

296
00:15:54.830 --> 00:15:55.663
<v Speaker 1>how well can I predict the words around </v>
<v Speaker 1>at the words that are one hop away from </v>

297
00:15:59.061 --> 00:16:01.190
<v Speaker 1>it to hop away from it,</v>
<v Speaker 1>three hops away from it.</v>

298
00:16:02.370 --> 00:16:07.370
<v Speaker 1>What they're trying to do is to train a </v>
<v Speaker 1>set of vectors where you minimize,</v>

299
00:16:07.650 --> 00:16:08.483
<v Speaker 1>uh,</v>
<v Speaker 1>the,</v>

300
00:16:08.660 --> 00:16:09.670
<v Speaker 1>the,</v>
<v Speaker 1>um,</v>

301
00:16:10.040 --> 00:16:10.873
<v Speaker 1>the loss,</v>
<v Speaker 1>the prediction loss of being able to </v>

302
00:16:13.341 --> 00:16:15.980
<v Speaker 1>predict the words around it based off of</v>
<v Speaker 1>that word.</v>

303
00:16:16.700 --> 00:16:18.740
<v Speaker 1>It was a very big difference for the </v>
<v Speaker 1>community.</v>

304
00:16:18.741 --> 00:16:21.020
<v Speaker 1>Previously.</v>
<v Speaker 1>It had been mostly counts.</v>

305
00:16:21.021 --> 00:16:24.500
<v Speaker 1>People just kind of count the number of </v>
<v Speaker 1>occurrences and then they would use that</v>

306
00:16:24.501 --> 00:16:25.334
<v Speaker 1>to try to almost make that the wait.</v>
<v Speaker 1>What this was doing was taking a deep </v>

307
00:16:30.081 --> 00:16:31.010
<v Speaker 1>neural network.</v>
<v Speaker 1>Well,</v>

308
00:16:31.190 --> 00:16:32.023
<v Speaker 1>it was actually kind of a shallow neural</v>
<v Speaker 1>network to try to optimize or maximize </v>

309
00:16:38.720 --> 00:16:39.553
<v Speaker 1>this law of probability of being able to</v>
<v Speaker 1>predict the words around it from that </v>

310
00:16:43.040 --> 00:16:46.130
<v Speaker 1>and what they got from that is what you </v>
<v Speaker 1>can kind of see here.</v>

311
00:16:46.370 --> 00:16:47.203
<v Speaker 1>This ability to place words,</v>
<v Speaker 1>symbols into a vector space such that </v>

312
00:16:53.570 --> 00:16:56.510
<v Speaker 1>words that are similar are closer </v>
<v Speaker 1>together.</v>

313
00:16:56.570 --> 00:16:57.403
<v Speaker 1>Right?</v>
<v Speaker 1>So,</v>

314
00:16:57.490 --> 00:16:58.323
<v Speaker 1>uh,</v>
<v Speaker 1>the point is you can see and also that </v>

315
00:17:00.500 --> 00:17:03.140
<v Speaker 1>relationships between words,</v>
<v Speaker 1>you know,</v>

316
00:17:03.141 --> 00:17:05.030
<v Speaker 1>move in similar directions,</v>
<v Speaker 1>right?</v>

317
00:17:05.031 --> 00:17:07.160
<v Speaker 1>So what this figure is trying to show </v>
<v Speaker 1>you is that,</v>

318
00:17:07.161 --> 00:17:07.994
<v Speaker 1>you know,</v>
<v Speaker 1>you can look at the countries that are </v>

319
00:17:09.081 --> 00:17:11.450
<v Speaker 1>here on the,</v>
<v Speaker 1>on the left side,</v>

320
00:17:11.690 --> 00:17:15.590
<v Speaker 1>and you can see that there are similar </v>
<v Speaker 1>to the ones that are,</v>

321
00:17:15.920 --> 00:17:20.210
<v Speaker 1>all countries are proximal,</v>
<v Speaker 1>the cities are proximal.</v>

322
00:17:20.630 --> 00:17:21.463
<v Speaker 1>Uh,</v>
<v Speaker 1>the,</v>

323
00:17:21.530 --> 00:17:22.363
<v Speaker 1>you know,</v>
<v Speaker 1>the vector that is going from countries </v>

324
00:17:24.591 --> 00:17:27.060
<v Speaker 1>to city are,</v>
<v Speaker 1>uh,</v>

325
00:17:27.070 --> 00:17:27.740
<v Speaker 1>you know,</v>
<v Speaker 1>uh,</v>

326
00:17:27.740 --> 00:17:29.420
<v Speaker 1>essentially going in the same direction.</v>
<v Speaker 1>I'm sure.</v>

327
00:17:29.450 --> 00:17:31.010
<v Speaker 1>I'm not sure if you can actually see </v>
<v Speaker 1>that,</v>

328
00:17:31.550 --> 00:17:32.383
<v Speaker 1>but the point is that this kind of a </v>
<v Speaker 1>vector space gives us the ability to </v>

329
00:17:35.900 --> 00:17:40.900
<v Speaker 1>compute on those real valued vectors and</v>
<v Speaker 1>then learn more about this.</v>

330
00:17:40.910 --> 00:17:44.150
<v Speaker 1>So our very first simple thing is to be </v>
<v Speaker 1>able to,</v>

331
00:17:44.151 --> 00:17:45.110
<v Speaker 1>you know,</v>
<v Speaker 1>uh,</v>

332
00:17:45.170 --> 00:17:47.450
<v Speaker 1>be able to find other similar things,</v>
<v Speaker 1>right?</v>

333
00:17:47.451 --> 00:17:48.950
<v Speaker 1>You have,</v>
<v Speaker 1>you have something,</v>

334
00:17:48.951 --> 00:17:49.784
<v Speaker 1>you assemble Italy for example.</v>
<v Speaker 1>Can you find other things that are </v>

335
00:17:52.711 --> 00:17:56.130
<v Speaker 1>similar to or related to Italy?</v>
<v Speaker 1>You can find other countries,</v>

336
00:17:56.131 --> 00:17:58.250
<v Speaker 1>you can find cities within Italy.</v>
<v Speaker 1>Um,</v>

337
00:17:58.470 --> 00:18:00.450
<v Speaker 1>so that's,</v>
<v Speaker 1>that's Kinda the first step.</v>

338
00:18:01.340 --> 00:18:02.071
<v Speaker 1>Uh,</v>
<v Speaker 1>the,</v>

339
00:18:02.071 --> 00:18:03.050
<v Speaker 1>you know,</v>
<v Speaker 1>so the first,</v>

340
00:18:03.051 --> 00:18:04.200
<v Speaker 1>the first,</v>
<v Speaker 1>uh,</v>

341
00:18:04.230 --> 00:18:05.063
<v Speaker 1>work,</v>
<v Speaker 1>there was this kind of distributed </v>

342
00:18:06.451 --> 00:18:09.180
<v Speaker 1>representation that we're talking about </v>
<v Speaker 1>here.</v>

343
00:18:09.350 --> 00:18:10.183
<v Speaker 1>Um,</v>
<v Speaker 1>the second is basically showing the </v>

344
00:18:12.121 --> 00:18:12.954
<v Speaker 1>difference in terms of being able to </v>
<v Speaker 1>second talk is a paper was about the </v>

345
00:18:18.090 --> 00:18:18.923
<v Speaker 1>accuracy,</v>
<v Speaker 1>the significant jump and accuracy that </v>

346
00:18:20.911 --> 00:18:21.744
<v Speaker 1>we got from being able to do that </v>
<v Speaker 1>prediction based representation as </v>

347
00:18:25.621 --> 00:18:27.300
<v Speaker 1>opposed to the account base </v>
<v Speaker 1>representation.</v>

348
00:18:27.301 --> 00:18:28.680
<v Speaker 1>I put,</v>
<v Speaker 1>I signaled,</v>

349
00:18:28.700 --> 00:18:30.150
<v Speaker 1>you know,</v>
<v Speaker 1>ibm authors,</v>

350
00:18:30.151 --> 00:18:34.260
<v Speaker 1>people who are at or where it off ibm in</v>
<v Speaker 1>orange.</v>

351
00:18:34.630 --> 00:18:37.000
<v Speaker 1>And the last one is um,</v>
<v Speaker 1>the uh,</v>

352
00:18:37.080 --> 00:18:37.913
<v Speaker 1>facebook has actually recently we </v>
<v Speaker 1>released this fast tax where you can </v>

353
00:18:40.561 --> 00:18:44.310
<v Speaker 1>basically go in and very easily create </v>
<v Speaker 1>your own embeddings.</v>

354
00:18:44.580 --> 00:18:46.790
<v Speaker 1>So first thing was,</v>
<v Speaker 1>you know,</v>

355
00:18:46.840 --> 00:18:47.673
<v Speaker 1>how do,</v>
<v Speaker 1>how do they create it and they went </v>

356
00:18:48.601 --> 00:18:51.660
<v Speaker 1>after a specific thing.</v>
<v Speaker 1>How do you optimize that similarity?</v>

357
00:18:51.960 --> 00:18:52.793
<v Speaker 1>But what you'll see from the rest of the</v>
<v Speaker 1>talk is that there are many other ways </v>

358
00:18:55.381 --> 00:18:59.070
<v Speaker 1>that you might want to try to figure out</v>
<v Speaker 1>how to place things together.</v>

359
00:18:59.071 --> 00:19:03.420
<v Speaker 1>Other constraints that you might want to</v>
<v Speaker 1>place on the vector space and how things</v>

360
00:19:03.421 --> 00:19:07.290
<v Speaker 1>are represented in that vector space.</v>
<v Speaker 1>So that you can accomplish tasks from it</v>

361
00:19:10.680 --> 00:19:12.170
<v Speaker 1>prior to,</v>
<v Speaker 1>uh,</v>

362
00:19:12.210 --> 00:19:16.110
<v Speaker 1>these types of representation,</v>
<v Speaker 1>the ideals for how people would actually</v>

363
00:19:16.111 --> 00:19:19.620
<v Speaker 1>go after representing knowledge and </v>
<v Speaker 1>language.</v>

364
00:19:19.830 --> 00:19:22.680
<v Speaker 1>We're knowledge basis,</v>
<v Speaker 1>a structured knowledge.</v>

365
00:19:22.681 --> 00:19:25.410
<v Speaker 1>So our original ideas was,</v>
<v Speaker 1>alright,</v>

366
00:19:25.500 --> 00:19:26.333
<v Speaker 1>listen,</v>
<v Speaker 1>I have to be able to have a entities </v>

367
00:19:28.711 --> 00:19:29.700
<v Speaker 1>that are well defined.</v>

368
00:19:29.700 --> 00:19:32.730
<v Speaker 1>I have to have well defined </v>
<v Speaker 1>relationships between those entities.</v>

369
00:19:32.731 --> 00:19:37.080
<v Speaker 1>I have to have a rules that basically </v>
<v Speaker 1>will give me information about,</v>

370
00:19:37.380 --> 00:19:37.861
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

371
00:19:37.861 --> 00:19:38.694
<v Speaker 1>categories of relationships or </v>
<v Speaker 1>categories of entities and it's great </v>

372
00:19:44.130 --> 00:19:48.180
<v Speaker 1>humans are able to do that.</v>
<v Speaker 1>They're able to lay out an entire space,</v>

373
00:19:48.210 --> 00:19:49.260
<v Speaker 1>you know,</v>
<v Speaker 1>describe,</v>

374
00:19:49.470 --> 00:19:50.303
<v Speaker 1>you know,</v>
<v Speaker 1>molecules and relationships between </v>

375
00:19:51.781 --> 00:19:52.614
<v Speaker 1>molecules or jeans and relationships </v>
<v Speaker 1>between genes and the targets that they </v>

376
00:19:56.491 --> 00:19:58.560
<v Speaker 1>might be able to affect.</v>
<v Speaker 1>Humans can do that.</v>

377
00:19:58.590 --> 00:20:01.500
<v Speaker 1>Well,</v>
<v Speaker 1>a machines don't do it that way.</v>

378
00:20:01.920 --> 00:20:03.330
<v Speaker 1>Um,</v>
<v Speaker 1>that was the problem.</v>

379
00:20:03.331 --> 00:20:06.690
<v Speaker 1>So the second figure here was even </v>
<v Speaker 1>though you,</v>

380
00:20:06.691 --> 00:20:07.524
<v Speaker 1>you know,</v>
<v Speaker 1>you kind of go out and you're able to </v>

381
00:20:07.981 --> 00:20:11.530
<v Speaker 1>find a lot of things and wikipedia and </v>
<v Speaker 1>Wikidata,</v>

382
00:20:11.580 --> 00:20:12.413
<v Speaker 1>you know,</v>
<v Speaker 1>freebase or some of the examples where </v>

383
00:20:13.441 --> 00:20:16.080
<v Speaker 1>you can find structured information on </v>
<v Speaker 1>the web.</v>

384
00:20:16.290 --> 00:20:18.390
<v Speaker 1>Even though you're able to find a lot of</v>
<v Speaker 1>information out here,</v>

385
00:20:18.391 --> 00:20:21.360
<v Speaker 1>and although this is a 2013 statement,</v>
<v Speaker 1>which you can see is that,</v>

386
00:20:21.720 --> 00:20:22.553
<v Speaker 1>uh,</v>
<v Speaker 1>in terms of the types of relationships </v>

387
00:20:24.451 --> 00:20:26.820
<v Speaker 1>and completeness of that,</v>
<v Speaker 1>this is saying,</v>

388
00:20:26.970 --> 00:20:27.803
<v Speaker 1>okay,</v>
<v Speaker 1>well for the people that are in </v>

389
00:20:29.280 --> 00:20:34.280
<v Speaker 1>wikipedia or freebase actually we only </v>
<v Speaker 1>were missing about 80 percent of their,</v>

390
00:20:35.490 --> 00:20:36.690
<v Speaker 1>uh,</v>
<v Speaker 1>their education,</v>

391
00:20:36.691 --> 00:20:37.830
<v Speaker 1>where their education is from.</v>

392
00:20:37.830 --> 00:20:38.730
<v Speaker 1>We're,</v>
<v Speaker 1>we're missing,</v>

393
00:20:39.000 --> 00:20:39.833
<v Speaker 1>you know,</v>
<v Speaker 1>over 90 percent of their employment </v>

394
00:20:41.821 --> 00:20:42.481
<v Speaker 1>history.</v>
<v Speaker 1>Right.</v>

395
00:20:42.481 --> 00:20:43.314
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

396
00:20:43.420 --> 00:20:45.810
<v Speaker 1>even though it seems like it's a lot of </v>
<v Speaker 1>information,</v>

397
00:20:45.870 --> 00:20:46.703
<v Speaker 1>a really sparse and very difficult for </v>
<v Speaker 1>humans to be able to use the algorithms </v>

398
00:20:52.961 --> 00:20:53.794
<v Speaker 1>that we have today to automatically </v>
<v Speaker 1>populate knowledge bases that look like </v>

399
00:20:57.281 --> 00:21:01.680
<v Speaker 1>the form that we understand and feel </v>
<v Speaker 1>that we can apply our,</v>

400
00:21:01.681 --> 00:21:02.514
<v Speaker 1>our logic to.</v>
<v Speaker 1>So one of the first results in terms of </v>

401
00:21:07.030 --> 00:21:12.030
<v Speaker 1>going from that symbolic knowledge into </v>
<v Speaker 1>sub symbolic knowledge.</v>

402
00:21:12.671 --> 00:21:15.040
<v Speaker 1>So the vectors that I was talking about </v>
<v Speaker 1>earlier was,</v>

403
00:21:15.550 --> 00:21:19.960
<v Speaker 1>could we redo our knowledge base is </v>
<v Speaker 1>based off of these sub symbolic,</v>

404
00:21:19.961 --> 00:21:21.010
<v Speaker 1>these,</v>
<v Speaker 1>these vectors.</v>

405
00:21:21.580 --> 00:21:22.413
<v Speaker 1>If we were able to do that,</v>
<v Speaker 1>then we actually would be able to learn </v>

406
00:21:25.901 --> 00:21:28.500
<v Speaker 1>much more data.</v>
<v Speaker 1>It's possible we could learn these,</v>

407
00:21:28.501 --> 00:21:29.334
<v Speaker 1>these representations and fill out some </v>
<v Speaker 1>of the information that we're missing </v>

408
00:21:32.861 --> 00:21:36.310
<v Speaker 1>from our knowledge basis of this.</v>
<v Speaker 1>First part was saying,</v>

409
00:21:36.490 --> 00:21:36.911
<v Speaker 1>okay,</v>
<v Speaker 1>look,</v>

410
00:21:36.911 --> 00:21:40.810
<v Speaker 1>I can take some of the information I can</v>
<v Speaker 1>find and freebase and other sources.</v>

411
00:21:41.230 --> 00:21:42.063
<v Speaker 1>What I'll do is I can use text </v>
<v Speaker 1>information to try to build out these </v>

412
00:21:44.771 --> 00:21:47.980
<v Speaker 1>embeddings.</v>
<v Speaker 1>I can find relationships are,</v>

413
00:21:47.981 --> 00:21:48.814
<v Speaker 1>I can find a entities that are in </v>
<v Speaker 1>similar spaces and realize there may be </v>

414
00:21:53.081 --> 00:21:53.914
<v Speaker 1>a relationship between these and I can </v>
<v Speaker 1>start to populate more of the </v>

415
00:21:56.921 --> 00:21:59.920
<v Speaker 1>relationships that I'm,</v>
<v Speaker 1>that I'm missing from my knowledge base.</v>

416
00:22:03.430 --> 00:22:05.100
<v Speaker 1>We're able to use this,</v>
<v Speaker 1>this,</v>

417
00:22:05.110 --> 00:22:07.090
<v Speaker 1>this principle of the,</v>
<v Speaker 1>uh,</v>

418
00:22:07.091 --> 00:22:12.091
<v Speaker 1>the embeddings and the knowledge basis </v>
<v Speaker 1>to then start to grow the knowledge base</v>

419
00:22:12.630 --> 00:22:13.690
<v Speaker 1>that we have.</v>
<v Speaker 1>Right?</v>

420
00:22:13.691 --> 00:22:14.650
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

421
00:22:14.651 --> 00:22:15.484
<v Speaker 1>this is basic.</v>
<v Speaker 1>The first study here is showing how we </v>

422
00:22:17.831 --> 00:22:18.664
<v Speaker 1>took information about genes and </v>
<v Speaker 1>diseases and drugs from ontologies that </v>

423
00:22:24.731 --> 00:22:26.560
<v Speaker 1>were available,</v>
<v Speaker 1>uh,</v>

424
00:22:26.650 --> 00:22:27.483
<v Speaker 1>represented that learn vectors across </v>
<v Speaker 1>that structured space so that we could </v>

425
00:22:31.961 --> 00:22:35.650
<v Speaker 1>predict relationships that weren't in </v>
<v Speaker 1>the knowledge base.</v>

426
00:22:35.980 --> 00:22:36.813
<v Speaker 1>That's important because if you think </v>
<v Speaker 1>about how people get that information </v>

427
00:22:39.371 --> 00:22:40.204
<v Speaker 1>today,</v>
<v Speaker 1>they actually do wet lab experiments to </v>

428
00:22:42.701 --> 00:22:45.250
<v Speaker 1>try to understand if there is a </v>
<v Speaker 1>relationship,</v>

429
00:22:45.251 --> 00:22:48.400
<v Speaker 1>if something upregulate something else </v>
<v Speaker 1>because very expensive.</v>

430
00:22:48.700 --> 00:22:53.110
<v Speaker 1>If we can use this knowledge to make </v>
<v Speaker 1>those predictions,</v>

431
00:22:53.111 --> 00:22:56.590
<v Speaker 1>then we can give other scientists places</v>
<v Speaker 1>to look.</v>

432
00:22:56.890 --> 00:22:59.440
<v Speaker 1>Looks like there might be an interaction</v>
<v Speaker 1>here.</v>

433
00:22:59.560 --> 00:23:00.900
<v Speaker 1>Maybe you could try that,</v>
<v Speaker 1>right?</v>

434
00:23:01.500 --> 00:23:02.333
<v Speaker 1>Uh,</v>
<v Speaker 1>the second set of results is a more </v>

435
00:23:04.301 --> 00:23:05.110
<v Speaker 1>recent,</v>
<v Speaker 1>uh,</v>

436
00:23:05.110 --> 00:23:06.530
<v Speaker 1>basically,</v>
<v Speaker 1>um,</v>

437
00:23:06.600 --> 00:23:08.440
<v Speaker 1>you know,</v>
<v Speaker 1>it was a challenge issued by this mantic</v>

438
00:23:08.441 --> 00:23:09.274
<v Speaker 1>web community.</v>

439
00:23:09.520 --> 00:23:13.420
<v Speaker 1>How can we better improve this automated</v>
<v Speaker 1>knowledge based construction?</v>

440
00:23:13.850 --> 00:23:17.020
<v Speaker 1>So the team used a combination of these </v>
<v Speaker 1>word embeddings,</v>

441
00:23:17.370 --> 00:23:18.203
<v Speaker 1>uh,</v>
<v Speaker 1>to be able to search for and validate </v>

442
00:23:21.011 --> 00:23:24.550
<v Speaker 1>information gained from a set of </v>
<v Speaker 1>structured and unstructured knowledge.</v>

443
00:23:24.551 --> 00:23:27.010
<v Speaker 1>So this is actually won a first place in</v>
<v Speaker 1>the,</v>

444
00:23:27.011 --> 00:23:29.860
<v Speaker 1>uh,</v>
<v Speaker 1>in the 2017 semantic web challenge.</v>

445
00:23:31.510 --> 00:23:32.343
<v Speaker 1>Okay.</v>
<v Speaker 1>So now we're kind of getting an idea </v>

446
00:23:34.211 --> 00:23:39.211
<v Speaker 1>about how we would take a language,</v>
<v Speaker 1>make it computational,</v>

447
00:23:40.780 --> 00:23:43.960
<v Speaker 1>put it into a knowledge base so that we </v>
<v Speaker 1>can aggregate it over time.</v>

448
00:23:44.890 --> 00:23:48.050
<v Speaker 1>But how are we going to get the neural </v>
<v Speaker 1>networks to use that?</v>

449
00:23:48.640 --> 00:23:49.473
<v Speaker 1>That's the next question.</v>

450
00:23:51.560 --> 00:23:52.393
<v Speaker 1>Okay.</v>
<v Speaker 1>An example task of why you would want </v>

451
00:23:54.201 --> 00:23:57.560
<v Speaker 1>those neural networks to be able to use </v>
<v Speaker 1>that is question answering.</v>

452
00:23:58.820 --> 00:23:59.653
<v Speaker 1>You want to build up a knowledge base,</v>
<v Speaker 1>everything you can possibly find a and </v>

453
00:24:03.861 --> 00:24:07.820
<v Speaker 1>then you want to be able to ask it </v>
<v Speaker 1>questions and see if he can answer those</v>

454
00:24:07.821 --> 00:24:08.654
<v Speaker 1>questions.</v>
<v Speaker 1>We say that this requires memories </v>

455
00:24:11.451 --> 00:24:12.284
<v Speaker 1>because the point is that if you think </v>
<v Speaker 1>about some of the other tasks that you </v>

456
00:24:14.241 --> 00:24:16.370
<v Speaker 1>may have seen,</v>
<v Speaker 1>you provide,</v>

457
00:24:16.371 --> 00:24:20.450
<v Speaker 1>once you train the network,</v>
<v Speaker 1>you provide an input and then you get an</v>

458
00:24:20.451 --> 00:24:21.320
<v Speaker 1>output,</v>
<v Speaker 1>right?</v>

459
00:24:21.321 --> 00:24:25.750
<v Speaker 1>You don't necessarily use longterm </v>
<v Speaker 1>memories of,</v>

460
00:24:26.050 --> 00:24:26.883
<v Speaker 1>uh,</v>
<v Speaker 1>relationships and entities and all of </v>

461
00:24:28.191 --> 00:24:29.690
<v Speaker 1>these sorts of things.</v>
<v Speaker 1>Okay.</v>

462
00:24:29.930 --> 00:24:32.920
<v Speaker 1>Um,</v>
<v Speaker 1>so this is a challenge.</v>

463
00:24:32.930 --> 00:24:33.763
<v Speaker 1>There was issue to the community </v>
<v Speaker 1>essentially in terms of being able to </v>

464
00:24:36.651 --> 00:24:41.300
<v Speaker 1>read some sentences and then being able </v>
<v Speaker 1>to give an a question,</v>

465
00:24:41.530 --> 00:24:42.770
<v Speaker 1>get an answer to that.</v>

466
00:24:43.100 --> 00:24:43.933
<v Speaker 1>And there are different stages of the </v>
<v Speaker 1>complexity of what is required in order </v>

467
00:24:47.961 --> 00:24:48.794
<v Speaker 1>to answer the question.</v>
<v Speaker 1>Sometimes it's really just kind of </v>

468
00:24:50.030 --> 00:24:50.863
<v Speaker 1>finding the sentence.</v>
<v Speaker 1>Sometimes it's being able to put </v>

469
00:24:53.451 --> 00:24:54.284
<v Speaker 1>multiple sentences together.</v>
<v Speaker 1>Sometimes it's being able to a chain </v>

470
00:24:56.961 --> 00:25:01.760
<v Speaker 1>across time and so there are many stages</v>
<v Speaker 1>of difficulties in order to do that.</v>

471
00:25:02.070 --> 00:25:02.903
<v Speaker 1>Um,</v>
<v Speaker 1>but what I want to focus on is some of </v>

472
00:25:05.931 --> 00:25:06.764
<v Speaker 1>the early work in terms of creating a </v>
<v Speaker 1>neural network that can then access </v>

473
00:25:11.810 --> 00:25:15.380
<v Speaker 1>those knowledge bases and then be able </v>
<v Speaker 1>to produce an answer from that.</v>

474
00:25:15.650 --> 00:25:16.483
<v Speaker 1>Right?</v>
<v Speaker 1>So the expectation is that you build up </v>

475
00:25:19.431 --> 00:25:23.450
<v Speaker 1>those knowledge basis from as much </v>
<v Speaker 1>information you can find previously,</v>

476
00:25:23.840 --> 00:25:24.673
<v Speaker 1>uh,</v>
<v Speaker 1>you train them such that they know how </v>

477
00:25:26.091 --> 00:25:26.924
<v Speaker 1>to answer a question,</v>
<v Speaker 1>the types of questions that you'd like </v>

478
00:25:29.271 --> 00:25:30.920
<v Speaker 1>them to answer.</v>
<v Speaker 1>Uh,</v>

479
00:25:31.130 --> 00:25:32.170
<v Speaker 1>and then from that,</v>
<v Speaker 1>when you,</v>

480
00:25:32.210 --> 00:25:34.760
<v Speaker 1>you handed a question is able to produce</v>
<v Speaker 1>an answer.</v>

481
00:25:35.450 --> 00:25:40.190
<v Speaker 1>The reason this is different from what </v>
<v Speaker 1>people are doing today,</v>

482
00:25:40.220 --> 00:25:43.070
<v Speaker 1>it's not just about saying today what </v>
<v Speaker 1>happens is,</v>

483
00:25:43.700 --> 00:25:45.290
<v Speaker 1>you know,</v>
<v Speaker 1>when you program a computer,</v>

484
00:25:45.770 --> 00:25:47.300
<v Speaker 1>then you tell it,</v>
<v Speaker 1>okay,</v>

485
00:25:47.301 --> 00:25:49.400
<v Speaker 1>I want to be able to access this place </v>
<v Speaker 1>in memory.</v>

486
00:25:49.401 --> 00:25:52.310
<v Speaker 1>You know,</v>
<v Speaker 1>I do a query on a database and I say,</v>

487
00:25:52.311 --> 00:25:54.200
<v Speaker 1>okay,</v>
<v Speaker 1>I'd like for you to give me all the rows</v>

488
00:25:54.440 --> 00:25:56.540
<v Speaker 1>where the first name is,</v>
<v Speaker 1>is excellent.</v>

489
00:25:56.541 --> 00:25:59.480
<v Speaker 1>The last name is why they can come back </v>
<v Speaker 1>and that's all programmed.</v>

490
00:26:00.440 --> 00:26:01.273
<v Speaker 1>These networks are instead learning how </v>
<v Speaker 1>to access memory by looking at other </v>

491
00:26:07.791 --> 00:26:11.690
<v Speaker 1>patterns of access to memory,</v>
<v Speaker 1>not program train it,</v>

492
00:26:11.900 --> 00:26:12.733
<v Speaker 1>train.</v>
<v Speaker 1>So the point here is the neural net is </v>

493
00:26:14.721 --> 00:26:19.640
<v Speaker 1>the controller of how that memory is </v>
<v Speaker 1>accessed in order to produce an answer.</v>

494
00:26:20.240 --> 00:26:21.260
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

495
00:26:21.340 --> 00:26:24.730
<v Speaker 1>so what happens is that they,</v>
<v Speaker 1>it is a supervised a result.</v>

496
00:26:24.731 --> 00:26:27.020
<v Speaker 1>So they,</v>
<v Speaker 1>they do train jointly with,</v>

497
00:26:27.021 --> 00:26:28.070
<v Speaker 1>okay,</v>
<v Speaker 1>what are the inputs,</v>

498
00:26:28.400 --> 00:26:30.080
<v Speaker 1>what's the question that will be asked </v>
<v Speaker 1>of that,</v>

499
00:26:30.081 --> 00:26:33.140
<v Speaker 1>what's the output that is desired from </v>
<v Speaker 1>that?</v>

500
00:26:33.800 --> 00:26:34.700
<v Speaker 1>And then,</v>
<v Speaker 1>um,</v>

501
00:26:34.940 --> 00:26:36.110
<v Speaker 1>by providing many,</v>
<v Speaker 1>many,</v>

502
00:26:36.111 --> 00:26:39.550
<v Speaker 1>many examples of that,</v>
<v Speaker 1>then when you provided a new set of,</v>

503
00:26:39.870 --> 00:26:41.330
<v Speaker 1>of,</v>
<v Speaker 1>of information,</v>

504
00:26:41.331 --> 00:26:42.164
<v Speaker 1>then it's able to answer a question from</v>
<v Speaker 1>that by basically taking a vector </v>

505
00:26:47.191 --> 00:26:50.020
<v Speaker 1>representation of the question queue,</v>
<v Speaker 1>uh,</v>

506
00:26:50.070 --> 00:26:50.903
<v Speaker 1>being able to map that onto the memory.</v>
<v Speaker 1>So the embeddings that were produced </v>

507
00:26:54.241 --> 00:26:55.074
<v Speaker 1>from all the sentences that were entered</v>
<v Speaker 1>and then moving back and forth across </v>

508
00:26:58.861 --> 00:27:01.380
<v Speaker 1>that until it gets to a confidence that,</v>
<v Speaker 1>uh,</v>

509
00:27:01.770 --> 00:27:02.441
<v Speaker 1>uh,</v>
<v Speaker 1>in,</v>

510
00:27:02.441 --> 00:27:03.274
<v Speaker 1>in an answer and transferring that into,</v>
<v Speaker 1>into an output on the first version of </v>

511
00:27:07.561 --> 00:27:08.410
<v Speaker 1>this,</v>
<v Speaker 1>uh,</v>

512
00:27:08.940 --> 00:27:09.773
<v Speaker 1>uh,</v>
<v Speaker 1>the first version that's on the left </v>

513
00:27:10.651 --> 00:27:14.250
<v Speaker 1>side wasn't able to handle many things </v>
<v Speaker 1>in terms of understanding,</v>

514
00:27:14.490 --> 00:27:16.650
<v Speaker 1>you know,</v>
<v Speaker 1>kind of a temporal sequences,</v>

515
00:27:16.860 --> 00:27:17.693
<v Speaker 1>for example,</v>
<v Speaker 1>they weren't able to do multi hop and </v>

516
00:27:20.400 --> 00:27:23.640
<v Speaker 1>second version,</v>
<v Speaker 1>which is much more recent,</v>

517
00:27:23.641 --> 00:27:24.420
<v Speaker 1>is,</v>
<v Speaker 1>you know,</v>

518
00:27:24.420 --> 00:27:28.440
<v Speaker 1>kind of full end to end training of that</v>
<v Speaker 1>control of the,</v>

519
00:27:28.441 --> 00:27:29.274
<v Speaker 1>uh,</v>
<v Speaker 1>of the network in order to try to start </v>

520
00:27:30.301 --> 00:27:32.130
<v Speaker 1>to answer these questions a while.</v>

521
00:27:32.370 --> 00:27:35.370
<v Speaker 1>It's incredibly exciting.</v>
<v Speaker 1>Uh,</v>

522
00:27:35.371 --> 00:27:37.200
<v Speaker 1>you know,</v>
<v Speaker 1>there's still many of the questions that</v>

523
00:27:37.201 --> 00:27:39.390
<v Speaker 1>I was showing earlier that it really </v>
<v Speaker 1>can't answer.</v>

524
00:27:39.391 --> 00:27:41.910
<v Speaker 1>So this is definitively not a solved </v>
<v Speaker 1>problem,</v>

525
00:27:42.360 --> 00:27:43.193
<v Speaker 1>but you know,</v>
<v Speaker 1>hopefully what you can see is that how </v>

526
00:27:45.241 --> 00:27:46.074
<v Speaker 1>we're starting to go up against problems</v>
<v Speaker 1>that we don't know completely how to </v>

527
00:27:50.011 --> 00:27:52.410
<v Speaker 1>solve.</v>
<v Speaker 1>But we're starting to solve them.</v>

528
00:27:52.800 --> 00:27:55.980
<v Speaker 1>And instead of just creating neural </v>
<v Speaker 1>networks,</v>

529
00:27:56.010 --> 00:27:59.310
<v Speaker 1>just an algorithm,</v>
<v Speaker 1>we are creating machines,</v>

530
00:27:59.400 --> 00:28:00.233
<v Speaker 1>right?</v>
<v Speaker 1>Or creating machines that have </v>

531
00:28:01.980 --> 00:28:04.340
<v Speaker 1>controllers and they have memory,</v>
<v Speaker 1>uh,</v>

532
00:28:04.350 --> 00:28:05.183
<v Speaker 1>and they're able to perform tasks that </v>
<v Speaker 1>go well beyond just what you could do </v>

533
00:28:08.250 --> 00:28:10.440
<v Speaker 1>with the pure neural network algorithm.</v>
<v Speaker 1>They,</v>

534
00:28:10.460 --> 00:28:11.293
<v Speaker 1>they,</v>
<v Speaker 1>they leverage those neural network </v>

535
00:28:12.870 --> 00:28:15.360
<v Speaker 1>algorithms throughout.</v>
<v Speaker 1>These are recurrent neural nets,</v>

536
00:28:15.361 --> 00:28:17.610
<v Speaker 1>lsts and so on.</v>
<v Speaker 1>But the point is,</v>

537
00:28:17.611 --> 00:28:21.150
<v Speaker 1>we're starting to try to put together a </v>
<v Speaker 1>machines from this,</v>

538
00:28:22.070 --> 00:28:23.220
<v Speaker 1>uh,</v>
<v Speaker 1>if you,</v>

539
00:28:23.280 --> 00:28:25.890
<v Speaker 1>if you'd like to learn more about this </v>
<v Speaker 1>topic,</v>

540
00:28:25.910 --> 00:28:26.970
<v Speaker 1>um,</v>
<v Speaker 1>there's,</v>

541
00:28:27.000 --> 00:28:28.620
<v Speaker 1>there's quite a bit of work in this.</v>

542
00:28:28.620 --> 00:28:30.450
<v Speaker 1>So one is,</v>
<v Speaker 1>uh,</v>

543
00:28:30.451 --> 00:28:32.940
<v Speaker 1>in addition to being able to answer </v>
<v Speaker 1>those questions,</v>

544
00:28:32.941 --> 00:28:35.910
<v Speaker 1>if we could better isolate.</v>
<v Speaker 1>What's the question,</v>

545
00:28:35.911 --> 00:28:36.744
<v Speaker 1>right?</v>
<v Speaker 1>This is something that humans have a </v>

546
00:28:37.561 --> 00:28:39.000
<v Speaker 1>problem with him.</v>
<v Speaker 1>Somebody comes in,</v>

547
00:28:39.001 --> 00:28:40.830
<v Speaker 1>they ask you a question and you kind of </v>
<v Speaker 1>say,</v>

548
00:28:40.831 --> 00:28:41.730
<v Speaker 1>what,</v>
<v Speaker 1>wait,</v>

549
00:28:41.731 --> 00:28:42.930
<v Speaker 1>what,</v>
<v Speaker 1>what's really the question?</v>

550
00:28:42.931 --> 00:28:44.370
<v Speaker 1>You're,</v>
<v Speaker 1>you're asking me here.</v>

551
00:28:44.371 --> 00:28:48.810
<v Speaker 1>So we've done work in terms of being </v>
<v Speaker 1>able to have better computers,</v>

552
00:28:48.840 --> 00:28:51.610
<v Speaker 1>better understand what's the question </v>
<v Speaker 1>really being asked.</v>

553
00:28:51.870 --> 00:28:52.703
<v Speaker 1>Um,</v>
<v Speaker 1>we need systems that will help us to </v>

554
00:28:54.690 --> 00:28:55.523
<v Speaker 1>train these models.</v>
<v Speaker 1>So a part of this work is to create a </v>

555
00:28:59.041 --> 00:28:59.874
<v Speaker 1>simulator that can take texts that are </v>
<v Speaker 1>ambiguous and generate questions of </v>

556
00:29:04.741 --> 00:29:05.574
<v Speaker 1>certain forms that we can then use that </v>
<v Speaker 1>to try to both train as well as test </v>

557
00:29:10.380 --> 00:29:12.670
<v Speaker 1>some of these systems.</v>
<v Speaker 1>Um,</v>

558
00:29:12.880 --> 00:29:17.760
<v Speaker 1>another really interesting thing is that</v>
<v Speaker 1>a common sense knowledge is basically,</v>

559
00:29:17.761 --> 00:29:18.594
<v Speaker 1>you know,</v>
<v Speaker 1>they refer to it as what's in the white </v>

560
00:29:19.741 --> 00:29:21.060
<v Speaker 1>space between what you read.</v>

561
00:29:21.320 --> 00:29:26.160
<v Speaker 1>You read a text and a lot of times </v>
<v Speaker 1>there's a lot of common sense knowledge,</v>

562
00:29:26.200 --> 00:29:26.700
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

563
00:29:26.700 --> 00:29:27.770
<v Speaker 1>knowing that,</v>
<v Speaker 1>you know,</v>

564
00:29:27.771 --> 00:29:28.604
<v Speaker 1>you know,</v>
<v Speaker 1>the desk is made of wood and wood is </v>

565
00:29:29.671 --> 00:29:33.180
<v Speaker 1>hard and all of these sorts of things </v>
<v Speaker 1>help you to understand a question.</v>

566
00:29:34.290 --> 00:29:37.140
<v Speaker 1>Can't find that it's not a wikipedia </v>
<v Speaker 1>muster.</v>

567
00:29:37.160 --> 00:29:39.810
<v Speaker 1>That common sense information isn't not </v>
<v Speaker 1>in wikipedia.</v>

568
00:29:40.440 --> 00:29:45.070
<v Speaker 1>It's not easy for us to learn from texts</v>
<v Speaker 1>because people don't stated this.</v>

569
00:29:45.420 --> 00:29:47.050
<v Speaker 1>Third Work here is,</v>
<v Speaker 1>hey,</v>

570
00:29:47.051 --> 00:29:50.020
<v Speaker 1>can we take some of that common sense </v>
<v Speaker 1>knowledge?</v>

571
00:29:50.380 --> 00:29:51.213
<v Speaker 1>Can we learn in vector space ways to </v>
<v Speaker 1>represent information that's common </v>

572
00:29:56.411 --> 00:29:58.180
<v Speaker 1>sense that,</v>
<v Speaker 1>that white space,</v>

573
00:29:58.430 --> 00:30:01.720
<v Speaker 1>uh,</v>
<v Speaker 1>and attach it to other information that,</v>

574
00:30:01.770 --> 00:30:02.870
<v Speaker 1>uh,</v>
<v Speaker 1>that we're able to,</v>

575
00:30:02.871 --> 00:30:04.750
<v Speaker 1>to read from,</v>
<v Speaker 1>from the web and so on.</v>

576
00:30:05.310 --> 00:30:06.143
<v Speaker 1>Um,</v>
<v Speaker 1>you know,</v>

577
00:30:06.160 --> 00:30:08.530
<v Speaker 1>some of the recent work as well as can </v>
<v Speaker 1>we,</v>

578
00:30:08.590 --> 00:30:12.820
<v Speaker 1>can we use neural nets to basically </v>
<v Speaker 1>learn what a program is doing,</v>

579
00:30:13.870 --> 00:30:14.703
<v Speaker 1>represent that,</v>
<v Speaker 1>and then be able to execute that </v>

580
00:30:17.681 --> 00:30:18.960
<v Speaker 1>program,</v>
<v Speaker 1>um,</v>

581
00:30:19.000 --> 00:30:20.110
<v Speaker 1>programs,</v>
<v Speaker 1>you know,</v>

582
00:30:20.111 --> 00:30:20.944
<v Speaker 1>this right now,</v>
<v Speaker 1>people want to try to program a program </v>

583
00:30:23.051 --> 00:30:26.370
<v Speaker 1>that takes a very sophisticated human </v>
<v Speaker 1>skill to be able to probe,</v>

584
00:30:26.590 --> 00:30:28.540
<v Speaker 1>probe a program and understand it.</v>

585
00:30:28.540 --> 00:30:31.060
<v Speaker 1>And in fact,</v>
<v Speaker 1>humans don't do that very well.</v>

586
00:30:31.090 --> 00:30:32.800
<v Speaker 1>But if we could train machines to do </v>
<v Speaker 1>that,</v>

587
00:30:32.801 --> 00:30:35.830
<v Speaker 1>then obviously that's a very powerful </v>
<v Speaker 1>thing to do.</v>

588
00:30:36.390 --> 00:30:37.223
<v Speaker 1>Um,</v>
<v Speaker 1>we're also a paper that was just </v>

589
00:30:39.551 --> 00:30:40.384
<v Speaker 1>published a couple of,</v>
<v Speaker 1>a couple of months ago in December at </v>

590
00:30:42.281 --> 00:30:44.170
<v Speaker 1>nips.</v>
<v Speaker 1>I thought it was extremely interesting.</v>

591
00:30:44.500 --> 00:30:45.333
<v Speaker 1>Uh,</v>
<v Speaker 1>basically they're learning how to </v>

592
00:30:47.500 --> 00:30:48.333
<v Speaker 1>constrain a vector representations such </v>
<v Speaker 1>that they can induce a new rules from </v>

593
00:30:54.611 --> 00:30:58.450
<v Speaker 1>those and that they can basically create</v>
<v Speaker 1>proofs.</v>

594
00:30:58.510 --> 00:30:59.350
<v Speaker 1>Right?</v>
<v Speaker 1>So when you,</v>

595
00:30:59.910 --> 00:31:03.610
<v Speaker 1>the reasonable proof is important is </v>
<v Speaker 1>basically that's the beginnings of being</v>

596
00:31:03.611 --> 00:31:04.444
<v Speaker 1>able to explain an answer.</v>
<v Speaker 1>Someone if you ask the question of the </v>

597
00:31:08.410 --> 00:31:10.000
<v Speaker 1>question from some of the other ones </v>
<v Speaker 1>was,</v>

598
00:31:10.001 --> 00:31:11.830
<v Speaker 1>you know,</v>
<v Speaker 1>it's the apples in the kitchen,</v>

599
00:31:12.180 --> 00:31:13.930
<v Speaker 1>um,</v>
<v Speaker 1>why,</v>

600
00:31:14.690 --> 00:31:15.523
<v Speaker 1>because you have approved,</v>
<v Speaker 1>if you have the steps that you went </v>

601
00:31:17.621 --> 00:31:20.090
<v Speaker 1>through in terms of the knowledge base,</v>
<v Speaker 1>uh,</v>

602
00:31:20.260 --> 00:31:21.730
<v Speaker 1>able to explain that out.</v>

603
00:31:21.760 --> 00:31:24.640
<v Speaker 1>Then suddenly people can interact with </v>
<v Speaker 1>the,</v>

604
00:31:24.641 --> 00:31:25.474
<v Speaker 1>uh,</v>
<v Speaker 1>the system and use the system not only </v>

605
00:31:27.371 --> 00:31:32.080
<v Speaker 1>to answer questions but to improve and </v>
<v Speaker 1>lift what humans,</v>

606
00:31:32.081 --> 00:31:34.360
<v Speaker 1>the human knowledge as well.</v>
<v Speaker 1>Learn,</v>

607
00:31:34.390 --> 00:31:37.630
<v Speaker 1>learn from the computers right now,</v>
<v Speaker 1>the computers learn from us.</v>

608
00:31:39.580 --> 00:31:42.190
<v Speaker 1>And just finally,</v>
<v Speaker 1>if you'd like to do more,</v>

609
00:31:42.220 --> 00:31:43.260
<v Speaker 1>um,</v>
<v Speaker 1>you know,</v>

610
00:31:43.261 --> 00:31:46.150
<v Speaker 1>the research division is working on next</v>
<v Speaker 1>generation algorithms.</v>

611
00:31:46.151 --> 00:31:46.984
<v Speaker 1>Uh,</v>
<v Speaker 1>those come out through our watson </v>

612
00:31:48.760 --> 00:31:50.500
<v Speaker 1>products.</v>
<v Speaker 1>We have a watson developer.</v>

613
00:31:50.501 --> 00:31:52.390
<v Speaker 1>Cloud makes it very easy.</v>
<v Speaker 1>You know,</v>

614
00:31:52.391 --> 00:31:53.224
<v Speaker 1>you can do things like you handed an </v>
<v Speaker 1>image and it will hand back information </v>

615
00:31:55.511 --> 00:31:56.760
<v Speaker 1>about what's in that image.</v>
<v Speaker 1>You,</v>

616
00:31:56.761 --> 00:31:57.594
<v Speaker 1>you hand at text,</v>
<v Speaker 1>it'll tell you information about the </v>

617
00:31:58.901 --> 00:32:00.610
<v Speaker 1>sentiment of that,</v>
<v Speaker 1>you know,</v>

618
00:32:00.611 --> 00:32:04.810
<v Speaker 1>label information within it and so on.</v>
<v Speaker 1>So we have what we believe are very easy</v>

619
00:32:04.811 --> 00:32:06.190
<v Speaker 1>to use,</v>
<v Speaker 1>uh,</v>

620
00:32:06.191 --> 00:32:07.330
<v Speaker 1>you know,</v>
<v Speaker 1>uh,</v>

621
00:32:07.331 --> 00:32:08.164
<v Speaker 1>algorithms that take many of these </v>
<v Speaker 1>things that we're talking about earlier </v>

622
00:32:11.680 --> 00:32:12.513
<v Speaker 1>and make them very easy for anyone to </v>
<v Speaker 1>use and incorporate in into their </v>

623
00:32:15.580 --> 00:32:18.550
<v Speaker 1>programs.</v>
<v Speaker 1>So I think that's it for me.</v>

624
00:32:18.910 --> 00:32:19.870
<v Speaker 1>Any questions.</v>

