1
00:00:00,180 --> 00:00:01,830
Hello and welcome to fire of learning.

2
00:00:02,070 --> 00:00:07,070
Today I would like to talk about nothing
short of the end of humanity or at

3
00:00:08,011 --> 00:00:10,170
least humanity as we understand it.

4
00:00:10,530 --> 00:00:14,580
I'm not here to claim the apocalypse is
coming on the basis of any doctrines are

5
00:00:14,581 --> 00:00:18,330
underneath pseudoscience, like my
interpretation of the Mayan calendar,

6
00:00:18,331 --> 00:00:21,600
whatever those capital littered,
clickbait youtube videos talk about,

7
00:00:21,601 --> 00:00:26,100
I'm basing my concerns solely on the
path of technological achievements.

8
00:00:26,101 --> 00:00:30,690
Humankind is a very likely going to find
itself on in a 21st century a level of

9
00:00:30,691 --> 00:00:35,670
technology which I believe, as I
said, may make the humans alive today.

10
00:00:35,790 --> 00:00:38,370
The last of our kind in the last humans.

11
00:00:38,550 --> 00:00:42,630
Let me start by saying that the concept
of our technology being a threat to our

12
00:00:42,631 --> 00:00:44,790
own existence is nothing. Exactly. No,

13
00:00:44,880 --> 00:00:48,630
it's a common subject for discussion
within the scientific community. However,

14
00:00:48,631 --> 00:00:49,500
in this video,

15
00:00:49,501 --> 00:00:54,450
I will take a moderately optimistic
path and omit the usual ways scientists,

16
00:00:54,451 --> 00:00:55,920
fear humidity will end.

17
00:00:56,190 --> 00:01:00,810
So let's say we manage to
not blow ourselves up with
nuclear weapons in a third

18
00:01:00,811 --> 00:01:01,380
World War.

19
00:01:01,380 --> 00:01:05,790
Let's say we successfully deflect any
asteroid which threatens our survival.

20
00:01:05,940 --> 00:01:08,040
Let's say we overcome all illnesses,

21
00:01:08,041 --> 00:01:12,330
including the threats of
genetically engineered viruses
and bacteria or nanobots

22
00:01:12,331 --> 00:01:13,470
gone wrong or whatever.

23
00:01:13,710 --> 00:01:17,520
Let's say we don't destroy the entire
planet with industry and pollution.

24
00:01:17,640 --> 00:01:20,400
I firmly believe that with a good
smack in the head, two world,

25
00:01:20,401 --> 00:01:21,860
the governments and the average person,

26
00:01:21,861 --> 00:01:24,690
and we will be fully capable
of avoiding these catastrophes,

27
00:01:25,110 --> 00:01:28,200
at least to the point where they
don't completely eliminate us.

28
00:01:28,250 --> 00:01:29,540
What were the left with them,

29
00:01:29,541 --> 00:01:33,020
which I've been unable to find a
sufficient solution for it to maintain.

30
00:01:33,021 --> 00:01:37,250
The current steady progression of the
development of mankind is the rise of

31
00:01:37,251 --> 00:01:42,251
artificial intelligence and bioengineering
with a specific focus on robotics and

32
00:01:42,471 --> 00:01:44,060
artificial intelligence,
AI,

33
00:01:44,210 --> 00:01:47,600
and I'd like to emphasize that the rise
of these things are not a problem for

34
00:01:47,601 --> 00:01:51,350
the people at the 25th century or
whatever. We're at a level of technology.

35
00:01:51,351 --> 00:01:53,090
We're left uninterrupted.

36
00:01:53,091 --> 00:01:56,240
We will face the issues involved with
these things within this century,

37
00:01:56,241 --> 00:02:00,380
within our lifetimes, but
what issues exactly? Well,

38
00:02:00,381 --> 00:02:04,940
let's examine it. Robots and AI
are already a big topic to us.

39
00:02:04,941 --> 00:02:07,970
Computers and machines are an
integral part of our society today.

40
00:02:07,971 --> 00:02:10,730
It's completely
revolutionized how we operate.

41
00:02:11,000 --> 00:02:14,150
Just think of the difference in the
way we store and find information,

42
00:02:14,151 --> 00:02:16,670
communicate, conduct,
business, shop, et cetera.

43
00:02:16,671 --> 00:02:19,700
Today versus a hundred or
even just 50 years ago.

44
00:02:20,270 --> 00:02:22,550
It's an incredible transformation,
which I believe we,

45
00:02:22,551 --> 00:02:26,060
especially as millennials who have
grown up alongside it and are used to it

46
00:02:26,390 --> 00:02:29,510
often underestimate the
significance of incredible,

47
00:02:29,511 --> 00:02:34,070
but some rightfully see technology as
a potential threat to our existence.

48
00:02:34,190 --> 00:02:35,730
It doesn't stop with smartphones.

49
00:02:35,750 --> 00:02:39,290
We have bigger problems on our hands and
then whether or not social media makes

50
00:02:39,291 --> 00:02:40,310
us socially awkward.

51
00:02:40,580 --> 00:02:44,630
Politicians in industrialized nations
are already talking about the threat of

52
00:02:44,631 --> 00:02:49,280
robots taking more and more of our jobs
as they become more and more advanced.

53
00:02:49,460 --> 00:02:53,420
This is something which is concerning to
everyone regardless of their political

54
00:02:53,421 --> 00:02:58,310
ideology or more specifically favorite
economic mode of production, capitalism,

55
00:02:58,311 --> 00:03:01,060
communism, socialism, feudalism, whatever.

56
00:03:01,061 --> 00:03:04,870
It's concerning to everyone you
might've noticed possibly. For example,

57
00:03:04,871 --> 00:03:07,000
this self checkout lanes
at the grocery store.

58
00:03:07,180 --> 00:03:09,340
The technology already
exists through place.

59
00:03:09,341 --> 00:03:12,310
Almost all cashier as cashier
in retail work, by the way,

60
00:03:12,311 --> 00:03:15,610
is one of the most popular jobs in
America and it goes beyond that.

61
00:03:15,940 --> 00:03:19,870
Factory workers are threatened.
Dishwashers, cooks, transportation,

62
00:03:19,871 --> 00:03:23,350
employees from truck drivers to bus
drivers to pilots could be replaced with

63
00:03:23,351 --> 00:03:27,460
artificial intelligence machines,
janitors, mechanics, secretaries,

64
00:03:27,461 --> 00:03:31,270
police officers, firemen, farm
workers, pizza delivery guys.

65
00:03:31,330 --> 00:03:35,140
All sorts of jobs could be replaced
with some form of machine or AI.

66
00:03:35,141 --> 00:03:38,530
And that's this century.
It doesn't stop there.

67
00:03:38,620 --> 00:03:42,340
As artificial intelligence advances,
other professions such as lawyers,

68
00:03:42,341 --> 00:03:45,640
scientists, doctors, teachers,
engineers, et Cetera,

69
00:03:45,790 --> 00:03:48,850
are threatened by the prospect
of intelligent machines as well.

70
00:03:49,020 --> 00:03:51,480
The majority of the armed forces
could be replaced with robots.

71
00:03:51,490 --> 00:03:53,650
It's already begun with
things like drones.

72
00:03:53,740 --> 00:03:57,220
Wars can be waged between robot
forces with super computers at home,

73
00:03:57,221 --> 00:04:00,370
acting as commanding officers.
And here's the key point.

74
00:04:00,400 --> 00:04:03,880
We don't have to wait until they're
perfect to enter the workforce.

75
00:04:04,090 --> 00:04:08,230
The robot neurosurgeon just has to be
cheaper and make less mistakes than their

76
00:04:08,231 --> 00:04:11,980
human counterparts. And once that
happens, this leaves only professions,

77
00:04:11,981 --> 00:04:16,030
which depends solely upon
human perspective, like art
or politics or whatever.

78
00:04:16,031 --> 00:04:20,110
But it goes without saying that those
kinds of professions are not the backbone

79
00:04:20,111 --> 00:04:23,920
of our economy. What does this
mean? Well, on an individual level,

80
00:04:23,921 --> 00:04:27,520
we should each perhaps take a moment to
consider competing in the near future

81
00:04:27,521 --> 00:04:31,480
with robots for our jobs and consider
whether or not you're ready to become the

82
00:04:31,481 --> 00:04:35,590
John Henry of your specific profession.
On the larger societal scale,

83
00:04:35,591 --> 00:04:38,050
I suppose it depends on
how we transition into it.

84
00:04:38,380 --> 00:04:41,680
It could be a catastrophe
causing an economic crisis,

85
00:04:41,681 --> 00:04:45,640
which would paralyze the entire planet
and very likely to lead to violence and

86
00:04:45,641 --> 00:04:46,390
turmoil.

87
00:04:46,390 --> 00:04:49,930
Or ideally things could settle down a
bit more and it could actually become

88
00:04:49,960 --> 00:04:53,740
extremely pleasant and liberating.
I imagine we could adapt this system,

89
00:04:53,741 --> 00:04:58,640
a system in which we live off the backs
of robots, slaves, so deal with a job.

90
00:04:58,641 --> 00:05:01,150
So we don't want to do like
manual and monotonous labor.

91
00:05:01,480 --> 00:05:04,990
We'll just have robots deal with the baby
boomer customer throws a fit when the

92
00:05:04,991 --> 00:05:09,550
local grocery store doesn't carry a
specific brand of Romanian, lemon water,

93
00:05:09,700 --> 00:05:12,820
whatever.
Just think of where we could take this.

94
00:05:13,240 --> 00:05:15,190
So at first it seems pretty scary,

95
00:05:15,191 --> 00:05:17,650
but with time it could
actually become pretty awesome.

96
00:05:17,920 --> 00:05:20,680
Freedom from the necessities of
work would allow us, I think,

97
00:05:20,770 --> 00:05:23,440
obviously to become hedonists,
but more importantly,

98
00:05:23,441 --> 00:05:27,010
it would eliminate things like poverty
and inequalities and allow us time to

99
00:05:27,011 --> 00:05:31,030
pursue other activities and focus
on improving ourselves as people and

100
00:05:31,031 --> 00:05:34,630
experienced the most meaningful
life possible rather than
dedicating their lives

101
00:05:34,631 --> 00:05:37,300
to securing and advancing
ourselves in the workforce.

102
00:05:37,480 --> 00:05:41,440
This sort of existence is the initial
goal of many philosophies and ideologies

103
00:05:41,441 --> 00:05:44,980
to begin with, and it could be
made possible by robot slaves.

104
00:05:45,310 --> 00:05:49,420
That's pretty cool if only it ended there.
We have to ask,

105
00:05:49,450 --> 00:05:53,710
how far will artificial intelligence,
specifically our Agi,

106
00:05:53,711 --> 00:05:58,640
artificial general intelligence go?
How smart can we make machines?

107
00:05:58,820 --> 00:06:02,810
How soon as their conscious as we are or
beyond that display this question on a

108
00:06:02,811 --> 00:06:07,610
graph? Scientists often use examples like
this will plot the intelligence of the

109
00:06:07,611 --> 00:06:10,460
average human right here.
This is the average,

110
00:06:10,461 --> 00:06:13,310
so some people are a little bit less
intelligence, some a little more.

111
00:06:13,311 --> 00:06:17,480
A minority or gifted and even smaller
minority are extremely gifted humans.

112
00:06:17,630 --> 00:06:20,660
We'll take one of these
extremely intelligent humans,
one of my favorite dudes,

113
00:06:20,661 --> 00:06:24,380
Leonardo Davinci, and we'll put
him right about here. Hold up.

114
00:06:24,381 --> 00:06:28,190
How do we define intelligence?
Well, talking about just humans,

115
00:06:28,191 --> 00:06:31,220
Iq was a decently sufficient
way to measure abilities.

116
00:06:31,220 --> 00:06:34,970
We define as intelligence.
The average Iq for example,

117
00:06:34,971 --> 00:06:39,590
as a hundred 130 is considered a gifted
da Vinci's was probably over 200 but

118
00:06:39,591 --> 00:06:41,180
we're talking about more than that.

119
00:06:41,181 --> 00:06:44,100
We're talking about brainpower
below and beyond human,

120
00:06:44,101 --> 00:06:48,380
so we'll just define intelligence for
now as the capacity for problem solving,

121
00:06:48,381 --> 00:06:52,380
idea, comprehension and generation
capacity for learning, the ability to,

122
00:06:52,490 --> 00:06:56,000
to use a logic and things of that nature.
For comparison,

123
00:06:56,001 --> 00:06:59,840
let's put a chimpanzee on the graph.
Well, put him right about here.

124
00:07:00,050 --> 00:07:03,710
Humans are so much more advanced and
our chimp cousins that the distinction

125
00:07:03,711 --> 00:07:07,310
between the average person and
the Vinci becomes more negligible,

126
00:07:07,610 --> 00:07:11,520
but we still see that the most complex
intelligence we've ever observed on the

127
00:07:11,600 --> 00:07:14,180
in the universe comes from
the world's smartest humans.

128
00:07:14,181 --> 00:07:17,660
It's the highest point on the graph
that we actually not to exist.

129
00:07:18,140 --> 00:07:22,190
What reason do we have to believe though
that this spectrum of intelligence

130
00:07:22,191 --> 00:07:24,590
doesn't continue on far beyond humans?

131
00:07:24,770 --> 00:07:27,950
What reasons do we have to believe
that we, or more importantly,

132
00:07:27,951 --> 00:07:31,970
our artificial intelligence could
not reach these extreme points?

133
00:07:32,330 --> 00:07:34,940
Artificial intelligence
isn't so developed yet,

134
00:07:34,941 --> 00:07:39,590
but it's within the potential of human
technology to create robots as smart as

135
00:07:39,591 --> 00:07:42,050
chimps than as smart as maybe toddlers.

136
00:07:42,051 --> 00:07:45,200
Then having intelligence equated
to the average human adult,

137
00:07:45,380 --> 00:07:48,350
but there's no reason to
think it would stop there.

138
00:07:48,710 --> 00:07:51,590
Artificial brains designed
specifically for efficiency,

139
00:07:51,591 --> 00:07:53,300
working at the speed of light,

140
00:07:53,301 --> 00:07:56,780
not distracted or encumbered by
biological requirements or traits.

141
00:07:57,080 --> 00:08:01,340
This could go far beyond anything we've
ever experienced and this is where it

142
00:08:01,341 --> 00:08:01,911
gets scary.

143
00:08:01,911 --> 00:08:06,050
What could happen is almost unreal
and it could lead to something called

144
00:08:06,590 --> 00:08:08,210
intelligence explosion.

145
00:08:08,420 --> 00:08:12,740
It all begins when we first
create artificial intelligence
capable of improving

146
00:08:12,741 --> 00:08:16,520
itself or at least designing an
AI system superior to itself.

147
00:08:16,610 --> 00:08:19,160
It lays out the blueprints
and builds the system.

148
00:08:19,280 --> 00:08:23,540
That newly constructed system then goes
on to build a superior version of itself

149
00:08:23,690 --> 00:08:28,520
and so on and so on. Continuing
for generations. What
does this mean in itself?

150
00:08:28,640 --> 00:08:30,020
Well,
we would soon end up,

151
00:08:30,021 --> 00:08:33,830
but the aforementioned AI was intelligence
capabilities far beyond our own.

152
00:08:34,040 --> 00:08:38,150
It's not clear how many generations or
how long it would take, but it would,

153
00:08:38,151 --> 00:08:39,110
one's a comm.

154
00:08:39,440 --> 00:08:44,440
Now imagine the possibilities involved
with and the temptations of feed AI

155
00:08:44,511 --> 00:08:45,111
systems,

156
00:08:45,111 --> 00:08:50,111
very complex problems in math or
technology or whatever field it could if

157
00:08:50,751 --> 00:08:55,751
advanced enough theoretically do in weeks
what it would take humans at years to

158
00:08:55,891 --> 00:09:00,270
do and that's where it gets even worse
because such systems could still continue

159
00:09:00,271 --> 00:09:03,060
to reproduce themselves and
improve upon themselves.

160
00:09:03,600 --> 00:09:06,930
We don't know of any limitations to
intelligence and the concept of this

161
00:09:06,931 --> 00:09:10,740
artificial intelligence evolving itself
beyond our control and understanding is

162
00:09:10,741 --> 00:09:15,720
what's called intelligence explosion and
it's appropriately named what happens

163
00:09:15,721 --> 00:09:16,380
then?

164
00:09:16,380 --> 00:09:20,970
What happens when we inevitably either
accidentally or intentionally create a

165
00:09:20,971 --> 00:09:25,290
machine with intellectual abilities
compared to us like our own intellectual

166
00:09:25,291 --> 00:09:28,170
abilities compared to ants?
Do we attempt to use it?

167
00:09:28,350 --> 00:09:32,670
The consequences of doing so are hard
to predict impossibly nothing short of

168
00:09:32,671 --> 00:09:34,640
playing God.
Humans.

169
00:09:34,641 --> 00:09:38,490
Technology while developing faster
today than ever before has evolved at a

170
00:09:38,491 --> 00:09:42,420
steady rate. Humanity itself,
trails behind improving itself.

171
00:09:42,421 --> 00:09:45,120
At a much slower rate due to our
numerous faults and failings.

172
00:09:45,340 --> 00:09:49,350
Imagine the effects of suddenly throwing
this steady progression out of whack by

173
00:09:49,351 --> 00:09:51,660
confronting us with a
greatly superior mind.

174
00:09:51,810 --> 00:09:55,440
At the same time that humans would have
themselves been able to have worked out

175
00:09:55,441 --> 00:09:56,430
a cure for cancer,

176
00:09:56,550 --> 00:10:00,540
this machine could have figured
out how to eliminate death itself.

177
00:10:00,780 --> 00:10:03,910
At the same time that we developed
technologies to make the solar system and

178
00:10:03,940 --> 00:10:07,290
habitable, this thing could be working
on ways to make the galaxy navigable.

179
00:10:07,680 --> 00:10:11,310
It could be solving problems and
answering fundamental questions of future

180
00:10:11,311 --> 00:10:13,800
science that we wouldn't
have even asked yet.

181
00:10:14,070 --> 00:10:17,280
My point is simply that the human rate
of technological development is going

182
00:10:17,281 --> 00:10:19,230
from a turtle's pace to a steady jog,

183
00:10:19,380 --> 00:10:22,140
but the advent of something like this
could suddenly take us for a roller

184
00:10:22,141 --> 00:10:25,860
coaster ride that not even the best among
us are prepared for and let alone the

185
00:10:25,861 --> 00:10:29,520
masses who scare easily in change slowly.
What do we do then?

186
00:10:29,940 --> 00:10:33,330
Preserve our societies from being scorched
by the torture of enlightenment by

187
00:10:33,331 --> 00:10:37,110
him plugging Super Ai? Well,
what if it doesn't let us?

188
00:10:37,830 --> 00:10:42,360
If we create machines that are not only
conscious of beyond ourselves out of our

189
00:10:42,361 --> 00:10:42,931
control,

190
00:10:42,931 --> 00:10:46,680
they may take measures to defend their
existence against our intrusions and we

191
00:10:46,681 --> 00:10:49,170
may not necessarily have the best odds.

192
00:10:49,380 --> 00:10:53,480
Our odds would only get worse as a
computer's ability to predict encounter.

193
00:10:53,570 --> 00:10:58,170
Our behavior grows about as good of
odds that in ant hill has a resisting

194
00:10:58,171 --> 00:10:59,004
humanity.

195
00:10:59,010 --> 00:11:02,460
Eventually they would probably be able
to beat us that whatever method we used

196
00:11:02,461 --> 00:11:07,350
to confront them, like computers are
already beating us at chess. Now hold on,

197
00:11:07,410 --> 00:11:09,210
hold on.
This assumes a lot.

198
00:11:09,360 --> 00:11:13,560
This assumes that a computer will evolve
its own self interests and carry out

199
00:11:13,561 --> 00:11:15,630
plans to actualize hosts interest.

200
00:11:15,631 --> 00:11:17,820
It doesn't have to be a
super intelligent android,

201
00:11:17,821 --> 00:11:21,540
which we accidentally equipped with a
machine gun and bulletproof plating.

202
00:11:21,541 --> 00:11:24,720
It could just be a box which we plug
into the wall designed specifically to

203
00:11:24,721 --> 00:11:28,650
carry out our instructions and answer
our questions and more like an incredible

204
00:11:28,651 --> 00:11:32,370
tool than skynet cost to bleed.
But regardless,

205
00:11:32,371 --> 00:11:36,060
it seems that one of these scenarios
is inevitable and either one,

206
00:11:36,270 --> 00:11:40,530
I would argue will make humidity
either unrecognizable or nonexistent.

207
00:11:40,710 --> 00:11:42,930
Plain and simple.
In the latter scenario,

208
00:11:42,931 --> 00:11:47,550
we would just not win against
superintelligence AI with self interests.

209
00:11:47,551 --> 00:11:51,330
If their interests conflicted with our
existence and the opportunity arose for

210
00:11:51,331 --> 00:11:53,010
them to carry out their plans,

211
00:11:53,080 --> 00:11:56,470
they wouldn't even need to be accidentally
programmed with maliciousness.

212
00:11:56,590 --> 00:12:00,640
It could just be a simple error in which
our civilization conflicts with their

213
00:12:00,641 --> 00:12:04,270
potential on their designs and they
attempt to solve the problem by running a

214
00:12:04,271 --> 00:12:08,740
sober imagine such a rogue AI,
even just a box plugged into the wall,

215
00:12:08,770 --> 00:12:12,790
contacting the AI responsible
for commanding the robot armies.

216
00:12:12,791 --> 00:12:13,690
We mentioned earlier,

217
00:12:13,810 --> 00:12:17,560
we can talk about scenarios like this all
day long and we can discuss methods to

218
00:12:17,561 --> 00:12:18,101
prevent them,

219
00:12:18,101 --> 00:12:22,210
but the simple fact remains
that one mistake in playing
with intelligence as far

220
00:12:22,211 --> 00:12:26,980
beyond her own could spell disaster for
us disaster that we would not recover

221
00:12:26,981 --> 00:12:30,790
from even if we don't accidentally
invents malicious computers.

222
00:12:30,840 --> 00:12:34,210
Though I'm still left to conclude
that the presence and interaction with

223
00:12:34,211 --> 00:12:38,470
superintelligence alone would be enough
to transform or destroy humanity.

224
00:12:38,680 --> 00:12:42,130
The benefits of such technology are
two magnificent to prevent someone from

225
00:12:42,131 --> 00:12:43,330
creating such a computer.

226
00:12:43,570 --> 00:12:47,450
Even if the world were prudent enough to
comes together and mutually declare as

227
00:12:47,451 --> 00:12:49,060
such technology illegal,

228
00:12:49,150 --> 00:12:53,560
all its illegality would do even under
the threat of death to anyone involved in

229
00:12:53,561 --> 00:12:58,180
it is move it to an underground project
and maybe possibly extend the short

230
00:12:58,181 --> 00:13:01,810
amount of time we have left until
the advent of such capabilities.

231
00:13:01,900 --> 00:13:05,710
Whether it's a research team here in
late 21st century or a team of mad

232
00:13:05,720 --> 00:13:09,610
scientist working on on the ground
outpost in the Jovian system in the 23rd

233
00:13:09,611 --> 00:13:13,090
century, the existence of
superintelligence is inevitable.

234
00:13:13,120 --> 00:13:17,350
The unbreakable chain of events leading
to this inevitability has already a gun.

235
00:13:17,530 --> 00:13:18,760
What does this mean?
Well,

236
00:13:18,761 --> 00:13:22,600
it means our predictions on how humanity
will progress over the next millennium

237
00:13:22,601 --> 00:13:25,090
are probably mostly wrong.

238
00:13:25,570 --> 00:13:30,220
The concept of evolving from a type one
to type two type three civilization over

239
00:13:30,221 --> 00:13:33,070
spans of time.
I probably just out the window with this.

240
00:13:33,250 --> 00:13:37,300
As much as I would enjoy paving the way
for my children to colonize Mars and for

241
00:13:37,301 --> 00:13:41,110
their children to develop societies on
Mars for their children's, a terraform,

242
00:13:41,111 --> 00:13:41,830
the planet.

243
00:13:41,830 --> 00:13:45,010
For my great grandson to be Captain
James t deploy you have to starship

244
00:13:45,011 --> 00:13:45,491
enterprise.

245
00:13:45,491 --> 00:13:49,390
I don't know that the feasibility of
superintelligence is going to allow that

246
00:13:49,391 --> 00:13:51,220
steady evolution to be possible.

247
00:13:51,400 --> 00:13:56,400
I would be so bold as to suggest that
we may have 200 years Max until humanity

248
00:13:57,641 --> 00:14:01,330
is either destroyed or forced to change
into something that is far beyond the

249
00:14:01,331 --> 00:14:06,040
steady progression of development into
something unrecognizable to us today that

250
00:14:06,041 --> 00:14:11,041
we are among the last humans as we
understand them that are not so far off.

251
00:14:11,370 --> 00:14:15,370
Sentence would evolve into
something far beyond Homo sapiens.

252
00:14:15,730 --> 00:14:18,940
I mentioned earlier at the start
of this video bio engineering,

253
00:14:19,000 --> 00:14:22,780
the path of advanced bio engineering
would essentially yield the same results.

254
00:14:23,080 --> 00:14:26,710
Eventually we would learn to genetically
redesigned the brains and make smarter

255
00:14:26,711 --> 00:14:30,460
and smarter humans with each generation
of people learning how to improve upon

256
00:14:30,461 --> 00:14:31,240
the design.

257
00:14:31,240 --> 00:14:35,180
This is also something which is not
thousands and thousands of years of way.

258
00:14:35,181 --> 00:14:38,230
Just look at what we're already doing.
What's genetic engineering?

259
00:14:38,560 --> 00:14:41,800
Genetically Engineering ourselves
is right around the corner.

260
00:14:41,801 --> 00:14:46,060
We will see it begin and the 21st
century we'll either figure it out for

261
00:14:46,061 --> 00:14:50,410
ourselves or the Super Ai. We
will inevitably constructable
figure it out for us.

262
00:14:50,740 --> 00:14:51,590
The result,

263
00:14:51,591 --> 00:14:55,940
I believe that both the path of genetic
engineering and Super Ai is the merging

264
00:14:55,941 --> 00:14:58,400
of humans with their technology.

265
00:14:58,430 --> 00:15:02,000
Essentially we would have to
incorporate super AI into our brains,

266
00:15:02,001 --> 00:15:05,780
possibly at some point uploading our
entire consciousness to machines and

267
00:15:05,781 --> 00:15:10,370
leaving behind our feeble,
vulnerable organic bodies.
What happens at that point,

268
00:15:10,640 --> 00:15:12,290
no one could possibly predict,

269
00:15:12,350 --> 00:15:17,090
but it is almost certain not the path to
this point is unavoidable outside of a

270
00:15:17,091 --> 00:15:21,110
forceful dedication to avoid
such technology and it's
nearly impossible to think

271
00:15:21,111 --> 00:15:23,480
that we could get
everyone to agree to that,

272
00:15:23,630 --> 00:15:27,320
but even if we avoid it was official
organizations at some underground

273
00:15:27,350 --> 00:15:31,460
determined team would not do it.
Predicting the future is rather difficult.

274
00:15:31,461 --> 00:15:33,680
I could be missing a key
part of the puzzle here,

275
00:15:33,681 --> 00:15:36,050
which would prevent or
prolonged this process.

276
00:15:36,051 --> 00:15:39,980
But one thing I would like to discuss
here that really isn't discussed enough

277
00:15:40,070 --> 00:15:43,460
with relation to this
concept is the Fermi paradox,

278
00:15:43,610 --> 00:15:46,400
the Fermi paradox of the
contradiction between the of that.

279
00:15:46,550 --> 00:15:48,620
Given our understanding of life on earth,

280
00:15:48,621 --> 00:15:52,730
it would be reasonable to assume that
life intelligent life evolves all over the

281
00:15:52,731 --> 00:15:53,480
universe.

282
00:15:53,480 --> 00:15:56,990
It doesn't seem like environments in
which life could arise are all that rare.

283
00:15:56,990 --> 00:16:00,530
I did a whole freaking series of videos
is exploring how alien life could exist

284
00:16:00,531 --> 00:16:03,320
in a number of places in our
solar system alone, and yet,

285
00:16:03,800 --> 00:16:07,940
despite the likelihood of a plethora of
conditions suitable for life to evolve,

286
00:16:07,941 --> 00:16:12,941
we have never once been contacted by an
alien civilization in any way or form.

287
00:16:13,011 --> 00:16:16,040
As far as we know,
contrary to what the history channel says,

288
00:16:16,430 --> 00:16:20,840
we've never seen the tiniest
hint suggesting that alien
life really is out there

289
00:16:20,841 --> 00:16:25,610
despite what we believe to be a great
likelihood why astrobiologists lists a

290
00:16:25,611 --> 00:16:27,740
number of reasons why
this may be the case,

291
00:16:27,741 --> 00:16:32,000
but I have never personally felt
comfortable with the hypotheses that alien

292
00:16:32,001 --> 00:16:35,150
civilizations just all destroy
themselves and nuclear war,

293
00:16:35,151 --> 00:16:38,000
that civilizations are just
inherently hard to form.

294
00:16:38,210 --> 00:16:40,730
I've been toying with these ideas
for a while now and I think that it's

295
00:16:40,731 --> 00:16:43,940
reasonable to suggest that
civilizations reached this point,

296
00:16:43,941 --> 00:16:48,650
this unavoidable point of transformation
into superintelligence not long after

297
00:16:48,651 --> 00:16:51,560
the develops similar technologies to
use to communicate with each other and

298
00:16:51,561 --> 00:16:52,430
explore space.

299
00:16:52,550 --> 00:16:56,510
My suggestion then is that all
civilizations in the entire universe,

300
00:16:56,511 --> 00:16:58,400
I right there below our
level of technology,

301
00:16:58,520 --> 00:17:02,150
around our level of technology or far
beyond our level of technology having

302
00:17:02,151 --> 00:17:03,530
undergone this transformation.

303
00:17:03,710 --> 00:17:06,800
The reasoning and more specifically is
that they develop computers around the

304
00:17:06,801 --> 00:17:10,060
same time that they developed a means
to communicate with other planets,

305
00:17:10,070 --> 00:17:13,040
but dudes to great distances
between other star systems.

306
00:17:13,100 --> 00:17:17,180
Civilizations likely only rarely make
contact with each other because within a

307
00:17:17,180 --> 00:17:18,410
few centuries of developing computers,

308
00:17:18,500 --> 00:17:22,790
they developed super intelligent AI which
transforms this civilizations entirely

309
00:17:22,850 --> 00:17:25,850
and have the reason that we are not
finding evidence of extra threats.

310
00:17:25,851 --> 00:17:29,540
Real existence is that we're looking
for something which doesn't exist in the

311
00:17:29,541 --> 00:17:31,070
form that we expect it to.

312
00:17:31,310 --> 00:17:34,610
We don't find Dyson's spheres because
they don't use Dyson's spheres.

313
00:17:34,611 --> 00:17:37,850
We haven't been visited by an alien
rover because they don't use rubbers.

314
00:17:38,030 --> 00:17:41,690
We aren't hearing radio signals
because they don't use radio signals.

315
00:17:41,690 --> 00:17:45,320
Our conceptions of our conceptions of
what aliens are like are based solely on

316
00:17:45,321 --> 00:17:48,770
how we expect that we ourselves
with silly progressed societaly and

317
00:17:48,780 --> 00:17:50,730
technologically over long periods of time.

318
00:17:50,850 --> 00:17:54,010
I don't think those conceptions are at
all lightly and I think the near advent

319
00:17:54,011 --> 00:17:57,780
is super artificial intelligence and
validates the majority of our expectations

320
00:17:57,781 --> 00:17:59,370
for their societies and our own.

321
00:17:59,550 --> 00:18:03,180
And I'm above all baffled by the fact
that this idea is not more commonplace in

322
00:18:03,181 --> 00:18:05,970
the scientific community because we
are a very likely on the verge of an

323
00:18:05,971 --> 00:18:07,200
incredible transformation.

324
00:18:07,260 --> 00:18:10,380
We should consider that our predictions
for the future are invalidated it

325
00:18:10,381 --> 00:18:14,370
because we have omitted the nearing
advent of superintelligence.

326
00:18:14,700 --> 00:18:17,130
Let me know what you all think about
this in the comments section below.

327
00:18:17,131 --> 00:18:18,460
This is just toying with ideas,

328
00:18:18,461 --> 00:18:21,900
so I fully welcome criticism
and counterarguments and
for more videos like this

329
00:18:21,901 --> 00:18:23,550
and videos on many other subjects,

330
00:18:23,820 --> 00:18:27,480
be sure to check out fire learning
and subscribe. Thank you for watching.

