Speaker 1:          00:03          If you think much about physics and cognition and intelligence, it's pretty obvious the human mind is not the smartest possible general intelligence and you more than humans are the highest jumpers are the fastest runners. We're not going to be the smartest thinkers if you are going to work toward agi rather than focusing on some narrow application. There's a number of different approaches that you might take and I've spent some time just surveying the Agi field as a whole and organizing an annual conference on their gi. And then I've spent a bunch of more time on a specific agi approach, which is based on the open cog open source software platform in the big picture. One way to approach Agi is to try to emulate the human brain at some level of precision, and this is the approach I see. For example, Google deep mind taking.

Speaker 1:          01:03          They've taken deep neural networks, which in their common form are mostly a model of visual and auditory processing in the human brain. And now in the recent work such as the DNC differential neuro computer, they're taking these deep networks that model visual or auditory processing and their coupling that with a memory matrix which models some aspect of what the hippocampus does, which is the part of the brain that deals with working memory, short term memory among other things. So this illustrates an approach where you take neural networks emulating different parts of the brain and maybe you take more and more in the neural networks and building different parts of the human brain. You try to get them to all work together, not necessarily doing computational neuroscience, but trying to emulate the way different parts of the brain are doing processing and the way they're talking to each other.

Speaker 1:          01:59          A totally different approach is being taken by a guy named Marcus hooter in Australian National University. He wrote a beautiful book on Universal Ai in which he showed how to write a superhuman infinitely intelligence thinking machine and like 50 lines of code. The problem is it would take more computing power than there is in the entire universe to run. So it's so, it's not practically useful, but they're then trying to scale down from this theoretical Agi to find something that that will really work. Now the approach we're taking in the open cog project is different than either of those we're attempting to emulate at a very high level. The way the human mind seems to work as an embodied social, generally intelligent agent, which is coming to grips with hard problems in the context of coming to grips with itself and its and its life in the world.

Speaker 1:          03:01          We're not drawing the model the way the brain works at the level of neurons and neural networks. We're looking at the human mind more from a high level cognitive point of view. What kinds of of memory are there? Well, there's semantic memory about abstract knowledge or concrete facts. There's episodic memory of our other biographical history, their sensory motor memory. There's associative memory of things that have been related to us in our lives. There's procedural memory of how to do things and we then look at the different kinds of learning and reasoning the human mind can do. We can do logical deduction sometimes. We're not always good at it. We date, we make emotional intuitive leaps and strange creative combinations of things we learned by trial and error and habit. We learned socially by imitating, mirroring, emulating or opposing others, these different kinds of memory and learning that the human mind has.

Speaker 1:          04:03          One can attempt to achieve each of those where the cutting edge computer science algorithm rather than trying to achieve each of those functions and structures and the way the brain does. So what we have in open cog, we have a central knowledge repository, which is very dynamic and lives in ram on a large network of computers, which we call the atom space. And for, for the mathematicians or computer science in the audience, the Adams space is what you'd call a, uh, weighted labeled hypergraph. So it has nodes, it has links. A link can go between two nodes or a link ego between three, four, five or 50 nodes. Different nodes and links have different types and the nodes and links can have numbers attached to them and know your link could have a weight indicating a probability or a confidence. It could have a weight indicating how important it is to the system right now or how important it is in the longterm, so it should be kept around and the systems memory on this Adam space this way did labeled hypergraph.

Speaker 1:          05:15          We can have a lot of different ai processes working together cooperatively, so the the atom space, the memory stores, what we would call neural symbolic. That means we can represent nodes and links that are like neurons in the brain, which is fairly low level, but we can also represent nodes and links that are higher level representing pieces of of symbolic logic expressions. So we can do explicit logical reasoning, which is pretty abstract and low level neural net stuff. In the same hypergraph the same items space acting on this Adam space. We have deep neural networks for visual and auditory perception. We have a probabilistic logic engine which does abstract reasoning. We have an evolutionary learning algorithm that uses genetic algorithm type methods to try to evolve radical new new ideas and concepts and look for data patterns and we have a neural net type dynamic that spreads activity and importance throughout the network.

Speaker 1:          06:25          A few other algorithms, a pattern mining algorithm that just scans through the whole admin space looking for surprising stuff and the trick is all these different cognitive algorithms have to work together cooperatively to help each other rather than hurt each other. See the bottleneck in essentially every ai approach ever taken, be it a neural net, a logic engine, the genetic algorithm, whatever the bottleneck in every ai approach ever taken has been what we call common tutorial explosion. And what that means is you have a lot of data items, you're a lot of perceptions coming into your eye or you have a lot of possible moves on the chessboard or a lot of possible ways to move the wheel of the car and there's so many combinations of possible data items and possible things you could do. Sifting through all those combinations becomes an exponential problem.

Speaker 1:          07:25          I mean if, if you have a thousand things, there's two to the 1020 a combined them and that and that's the way to money. So how the sift through common tutorial explosions is the core problem everyone has to deal with in a deep neural network as currently pursued it solved by making the network have a very specific structure which reflects the structure of visual and auditory streams. And in a logic engine you don't have that sort of luxury because a logic engine has to deal with anything. Not, not just sensory data, but what we do in open cog is we've worked out a system where each of the cognitive processes can help the other one out when it, when it gets stuck in some communist oriel explosion problems. So if if a deep neural network turning the perceived things gets confused because it's dark or it's looking at something it never saw before, well maybe the reasoning engine can come in and do some inference to cut through that confusion.

Speaker 1:          08:25          If logical reasoning is getting confused and doesn't know what step to take next cause there's just so many possibilities are there. And not much information about the mall. Maybe you fish into your sensory motor memory and you use deep learning to visualize something you saw before. And that gives you a clue of how to pair through the many possibilities that the, that the logic engine is seeing. Now you can model this kind of cognitive synergy mathematically using a branch of mathematics called category theory, which is something I've been working on lately. But what's really interesting more so is to build a system that manifests this and achieves general intelligence as a result. And that's what we're doing in the open card project. We're not there yet to general intelligence, but we're getting there step by step. We're using our open source open cog platform to control David Hanson's beautiful, incredibly realistic humanoid robots like this Sophia robot, which has gotten a lot of media attention in the last year.

Speaker 1:          09:35          We're using open card to analyze biological data related to the genetics of, of longevity. And we're doing a host of other consulting projects using this. So we're, we're proceeding on an r and d track and an application track at at the same time. But our end goal with the system is to use cognitive synergy on our neural symbolic knowledge store to achieve initially human level Ai. But that's just nearly stage goal and then ai much beyond the human level. And that is another advantage of taking an approach that doesn't adhere slavishly to the human brain. The brain is pretty good at recognizing faces because millions of years of evolution when into that part of the brain. But for doing science or math or logical reasoning, your strategic planning, we're pretty bad. And these are things that we started doing only recently in evolutionary time as a result of of modern culture.

Speaker 1:          10:39          So I think actually opened cognitive, other AI systems have potential to be far better than, than human beings at the sort of logical and strategic side of things. And I think that's quite important because if you take a human being and upgrade them to like 10,000 Iq, the the, the outcome might not be what you want because you, you've got a motivational system and an emotional system that basically evolved in prehuman animals. Where as if you architect a system where rationality and and empathy play a deeper role in the architecture, then as its intelligence ramps way up, we may find the more beneficial outcome.