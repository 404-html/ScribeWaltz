Speaker 1:          00:00          I see no obstacle to computers eventually, uh, becoming conscious in some sense. That'll be a fascinating experience. Um, as a physicist, I want to know if those computers do physics the same way humans do physics and there's no doubt that those machines will be able to, um,

Speaker 1:          00:23          evolve computationally potentially at a faster rate than humans. And in the long term, the, the, um, ultimate highest forms of consciousness on the planet may not be purely biological, but that's not necessarily a bad thing. We always present computers as if they don't have capabilities of empathy or a emotion, but I would think that any intelligent machine would ultimately have experience that it's a learning machine and ultimately it would learn from its experience like a, like a biological conscious being. And therefore it's hard for me to believe that it would not be able to have many of the characteristics that we now associate with being human. Elon Musk and others who have expressed concern and Stephen Hawking are friends of mine and I understand their potential concerns, but I'm frankly not as concerned about ai in the near term, at the very least, as many many of my friends and colleagues are.

Speaker 1:          01:20          It's far less powerful than people imagined. I mean, you try to get a robot to fold laundry and I've just been told you can't even get full robot to fold laundry at. Someone just wrote me. They were surprised when I said an elevator is an old example of the fact that when you get an elevator, you're, it's a primitive form of a computer and you're and you're giving up control of the of the fact that it's going to take you where you want to go. Cars are the same thing. Machines are useful because they're tools that help us do we want to do, and I think computation machines are exempt, are good examples of that. One has to be very careful in creating machines to not assume they're more capable than they are. That's true in cars. That's true in vehicles that we make. That's true in weapons. We create that's true in defensive mechanisms we create and so to me, the dangers of Ai, what are mostly due to the fact that people may assume the devices they create are more capable than they are and don't need more control and monitoring. I guess I find the opportunities to be far more exciting than the dangers. The unknown is always dangerous, but

Speaker 1:          02:29          ultimately machines and computational machines are

Speaker 1:          02:37          improving our lives in many ways. We of course have to realize that the rate at which machines are, are evolving in capability may far exceed the rate at which society is able to deal with them. The fact that teenagers aren't talking to each other, but always looking at their phones, not just teenagers. I was just in a restaurant here, New York this afternoon and half the people were not talking to people they were with, but we're staring at their phones. While that may be not a good thing for societal interaction and people may have to come to terms with that, but I don't think people view their phones as a danger. They view their phones as a tool that in many ways, um, allow them to do what they would otherwise do more effectively.