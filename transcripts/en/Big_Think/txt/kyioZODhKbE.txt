Speaker 1:          00:05          So most of us think that information is the best way to convince people of our truth and in fact it doesn't work that well and we see that all the time, right? We see it where with climate change, where there's tons of data suggesting that climate change is manmade, but about 50 percent of the population doesn't believe it or with people arguing about things like how many people were in the neck in the presidential inauguration. So we have facts, but people decide which facts they want to listen to, which facts they want to take and change their opinions in which they want to disregard. And one of the reasons for this is when something doesn't confirm to what I already believe, what people tend to do is either disregard it or rationalize it away because information doesn't take into account what makes us human, which is our emotions, our desires, our motives, and our prior beliefs.

Speaker 1:          01:02          So for example, in one study my colleagues and I tried to see whether we could use science to change people's opinions about climate change. The first thing we did was ask people, do you believe in manmade climate change? Do you support the Paris agreement? And based on their answers, we divided them into the strong believers and the weak believers. And then we gave them information for some people. We said that scientists have reevaluated the data and now conclude the things are actually much worse than they thought before that the temperature would rise by about seven degrees to 10 degrees. For some people, we said the scientists have reevaluated data and they now believe that actually the situation is not as bad as I thought. Um, it's much better and the rise in temperature would be quite small. And what we found is that people who did not believe in climate change when they heard that the scientists are saying, actually it's not that bad.

Speaker 1:          01:55          Um, they changed their beliefs even more in that direction. So they became more extremists in that direction. But when they hear that, the scientists think it's much worse, they didn't nudge. And the people who already believe that climate change is manmade. When they heard that things are actually, scientists are saying are much worse than they did before. They moved more in that direction, so they became more polarized, but when they heard that the scientists are saying it's not that bad. They didn't touch much. So we gave people information and as a result it caused polarization. It didn't cause people to come together. So the question is what's happening inside our brain that causes this? And in one study, my colleagues and I scanned brain activity of two people who were interacting and what we found was when those two people agreed on a question that we gave them, the brain was really encoding what the other person was saying, the details that they gave.

Speaker 1:          02:49          But when the two people disagreed, it looked metaphorically as if the brain was switching off and not encoding what the other person was saying. And as a result, when the two agreed, they became even more confident. But when they disagreed, there wasn't as much of a change in their confidence in their own view. What has been shown by [inaudible] and colleagues from Yale University is that the more intelligent you are, the more likely you are in fact, to change data at will. So what they did is they first gave participants in their experiment, I'm analytical, a math questions to solve, and then they gave them data about gun control, is gun control actually reducing violence. And they found that more intelligent people actually were more likely to twist data at will to make it conform to what they already believed. So it seems that people are using their intelligent, not necessarily to find the truth, but to take in the information and change it to conform to what they already believe.

Speaker 1:          03:55          So, um, yeah, so that suggests that just giving people information without considering first where they're coming from may backfire at us. Um, but we don't always need to go against someone's conviction in order to change their behavior. And let me give you an example for this is a study that was conducted at Ucla, um, were what they wanted to do is convince parents to vaccinate their kids. And some of the parents didn't want to vaccinate their kids because they were afraid of the link with autism. So they had two approaches. First they said, well, the link with autism is actually not meal. Here's all the data suggesting there isn't a link between vaccines and autism. And it didn't really work that well, but instead they use another approach. So instead of going that way, they used another approach which is, let's not talk about autism.

Speaker 1:          04:46          We don't necessarily need to talk about autism to convince you to vaccinate your kid. Instead they said, well look, these vaccines protect kids from deadly diseases right from the measles. And they showed them pictures of what the measles are. Because in this argument about vaccines, people actually forgot what the vaccines are for, what are they protecting us from? And they highlighted that and didn't necessarily go on to discuss autism. And that had a much better outcome for the parents were much more likely to say, yes, we are going to vaccinate our kids. So the lesson here is that we need to find the common motives. The common motives in this case was the health of the children, right? Not necessarily going back to the the thing that they were arguing about that they disagreed about.