Speaker 1:          00:00          Big Data is not an unmitigated good like many things in society, in fact, probably all things, it comes with risks as well and it comes with a dark side and one dark side of course is privacy that exists today. It'll exist tomorrow. Maybe it gets bigger with big data as well, but there is something else to play for something else that's a little bit more troubling still and that is if you will propensity it, is big data algorithms making a prediction of what you are likely to do before you've actually done it. Now the criminal justice system has never really dealt with this sort of problem before. Typically you have to commit a crime before you were penalized for that crime, but what if it is simply a prediction that you have a likelihood of committing a crime? Would society be remiss not to intervene?

Speaker 1:          00:46          If I could tell with a 98 percent statistical accuracy that you are likely to shoplift in the next 12 months? Public Safety requires that I interact and maybe I don't put you into jail. It's not minority report. It's not pre crime. I have a social worker knock on your door and say, we'd like to help you. We'd like to get you an afterschool job. If you're a teenager, we'd like to sort of support you. Well, that sounds like it's a benefit, but in reality, if you think about it, this person is going to be stigmatized in the eye of his peers, school teachers, parents, in fact, he'll probably feel stigmatized in his own eyes and feel badly, and we might even encourage the tort sort of behavior that we want to prevent. The point is that he will have been a victim of a prediction about him and he could rightly say, I will be the two percent that will not a shoplift that I'll exercise my moral choice. So the solution seems to be in a big data world. We want to send how sanctify the notion of the human volition of human free will and to preserve that as a central attribute.