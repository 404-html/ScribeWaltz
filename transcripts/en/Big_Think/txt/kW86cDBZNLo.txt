Speaker 1:          00:03          Yeah, the way I think about attention is really as a problem of routing routing signals, so actually we know a lot about how signals come in through your sensory apparatus, through your ears and your eyes. We know an awful lot about how the retina works, how the Cochlea Works, we understand how the signals travel up and eventually they percolate up to the cortex. In the case of sound, they percolate up to the auditory cortex and we know a lot about a fair amount about how they look once they get there and after that we kind of lose track of them and we can't really pick up the signal until we're. They're coming out the other end. We know a lot about movement. We understand an awful lot about what happens when a nerve impulse gets to a muscle and how muscles contract. That's been pretty well understood for 50 years or something.

Speaker 1:          00:56          You're more than that, so where we really lose track of them is when they enter into the early parts of the sensory cortex and when there we pick them up again, sort of on the on the other side, and so attention is one of the ways in which signals can find their destination if you like. So think about it in terms of a really specific a problem. Imagine that I asked you to raise your right hand. When I say go, okay, so I say go you raise your right hand, go raise your right hand. Now let's change it. And I say, go raise your left hand, go raise your left hand. So somehow the same signal coming in through your ear is producing different activity at the other end, somehow the signal on the sensory side had to be routed to either the muscles of your right hand or the muscles of your left hand.

Speaker 1:          01:49          Now, attention is a special case of that kind of general routing problem at the brain faces all the time because when you attend to, let's say your a sounds rather than your visual input or when you attend to one particular auditory input out of many, what you're doing is you're selecting some subset of the inputs in this case, coming in to your ears and and subjecting them to further processing and you're, you're taking those signals and routing them downstream and doing stuff with them. How that routing happens. That's the aspect of attention that my lab focuses on. So, so the basic setup for the problem that I'm interested in is this. Imagine that you're at a cocktail party. There are a bunch of conversations going on and you're talking to someone, but there's all this distracting stuff going on. The side lines. You can make a choice.

Speaker 1:          02:46          You can either focus on the person you're talking to and ignore the rest. Or as often happens, you find that the conversation that you're engaged in is not as interesting. And uh Huh. Uh Huh. Oh really? Summer. Okay. And you start focusing in on this conversation on the right, your ability to focus in on this conversation while ignoring that conversation. That is sort of the challenge. Understanding how we do that is the challenge of, of my research and that, that problem actually has two separate aspects. So there's one aspect of that problem that is really a problem of computation. It's, it's a problem that is a challenge to basically any computer, namely, uh, we have a whole bunch of different sounds and from a bunch of different sources and they're super imposed at the level of the ears and somehow they're, they're added together. And to us it's typically pretty effortless for us to separate out those different threads of the conversation.

Speaker 1:          03:45          But actually that's surprisingly difficult tasks. So a computers maybe 10 years ago already, we're getting pretty good at doing a speech recognition and in, in a controlled situations and quiet rooms. Computers were actually pretty good at recognizing even a random speakers, but when people actually start deploying these in real world settings where there's traffic noise and whatnot, the computer algorithms broke down completely. And it was sort of surprising at first because that's the aspect that we as humans seem to have a not much trouble with at all. So the, the, uh, ability to take apart the different components of an auditory scene, that's what we've evolved for hundreds of millions of years to do really well. Um, so that's one aspect of attention. There's almost this sort of, um, uh, aspect of it that happens before we're even aware of it, where the auditory scene is broken down into the components. The other aspect, which is, uh, the one that we're sort of more consciously aware of is the one where out of the many components of this conversation, we have this auditory seem. We select one and that's the one we focus in on, right? So it, at this hypothetical cocktail party, uh, we have the choice of focusing on either the conversation we're engaged in or this one or that one.