Speaker 1:          00:05          Hollywood movies make people worry about the wrong things in terms of superintelligence, well, we should really worry about it. It's not malice, but competence where we have machines that are smarter than us, whose goals just aren't aligned with ours for example. I don't hate that. So I don't go out of my way to stop button and if I see one on the sidewalk, but if I'm in charge of this hydroelectric dam construction and just as I'm going to flood this value of water, I see an ant until very no tough luck for the ads, right? Their goals weren't aligned with mine and because I'm smarter, it's going to be my goals, not the ants goals that get fulfilled. We never want to put humanity and the role of those ads. On the other hand, it doesn't have to be bad if you solve the goal.

Speaker 1:          00:54          Layman problem. My little babies tend to be in a household surrounded by human level. Intelligence is the smarter than the babies and they leave their parents right. And that works out fine because the goals of the parents are wonderfully align with the goals of the child. So the chaplain just all good. And this is one vision that a lot of ai researchers have. The friendly ai vision that we will succeed and not just making machines that are smarter than us, but also machines that then learn, adopt, then retain our goals as they get ever smarter. It might sound easy to get machines to learn and adopt and retain our goals, but these are all very tough problems. First of all, if you take yourself driving taxi and tell it in the future to take you to the airport as fast as possible and then you get there covered in vomit and chased by helicopters and you said, no, no, no, no, that's not what I wanted.

Speaker 1:          01:50          And it replies. That is exactly what you asked for. Venue have appreciated how hard it is to get a machine to understand your goals, your actual goals. You know, a human cab driver would have realized that you also had other goals that were unstated because she was also a human and has all this shared reference frame. But a machine doesn't have that unless we explicitly teach it that. Right. And then once the machine understands our goals, there's a separate problem getting them to re adopt the goals. Anyone who has had kids knows how hard or how big the difference is between making the kids understand what you want and actually adopt your goal to do what you want and, and finally, even if you can get your kids to adopt your goals, that doesn't mean they're going to retain them for life. Right? My kids are a lot less excited about lego now than they were when they were little and we don't want machines as they ever get ever smarter to gradually change their goals away from being excited about protecting us and thinking of this thing about taking care of humanity is just a little childhood thing like Lego is that they get bored with.

Speaker 1:          02:55          Eventually. If we can solve all three of these quests, tech challenges, getting machines to understand our goals, adopt the man, retain them, then we can create an awesome future because everything I love about civilization as the product of intelligence. Then if we can use machines to amplify our intelligence, then we used to have this potential to solve all the problems that are dumping us today and create a better future than we even dare to dream of. If machines ever surpass us and can outsmart us at all tasks, that's going to be a really big deal because intelligence is power. The reason that we humans have more power on this planet than tigers is not because we have larger muscles are sharper clause, right? It's because we're smarter than the Tigers and in this exact same way, it's machines are smarter than us. It becomes perfectly plausible for them to control us and become the rulers of this planet and beyond.

Speaker 1:          03:55          And um, when I j good made this famous analysis of how you could get an intelligence explosion, we're intelligence just kept creating greater and greater intelligence leaving us far behind. He also mentioned that this super intelligence would be the last invention that men need ever make. And what he meant by that, of course, was it so far, the most intelligent being on this planet that's been doing all the inventing, it's been us, but once we make machines that are better than us at the inventing all future technology that we ever need can be created by those machines. If we can make sure that they do things for us that we want and to help us create an awesome future where humanity can flourish like never before.

Speaker 2:          04:44          Mm.