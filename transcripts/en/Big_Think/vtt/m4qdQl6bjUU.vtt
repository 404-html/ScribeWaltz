WEBVTT

1
00:00:05.510 --> 00:00:09.710
<v Speaker 1>Hollywood movies make people worry about</v>
<v Speaker 1>the wrong things in terms of</v>

2
00:00:09.711 --> 00:00:11.850
<v Speaker 1>superintelligence,</v>
<v Speaker 1>well,</v>

3
00:00:11.860 --> 00:00:14.240
<v Speaker 1>we should really worry about it.</v>
<v Speaker 1>It's not malice,</v>

4
00:00:14.720 --> 00:00:18.770
<v Speaker 1>but competence</v>
<v Speaker 1>where we have machines that are smarter</v>

5
00:00:18.771 --> 00:00:22.010
<v Speaker 1>than us,</v>
<v Speaker 1>whose goals just aren't aligned with</v>

6
00:00:22.011 --> 00:00:26.520
<v Speaker 1>ours for example.</v>
<v Speaker 1>I don't hate that.</v>

7
00:00:26.521 --> 00:00:30.590
<v Speaker 1>So I don't go out of my way to stop</v>
<v Speaker 1>button and if I see one on the sidewalk,</v>

8
00:00:30.920 --> 00:00:34.370
<v Speaker 1>but if I'm in charge of this</v>
<v Speaker 1>hydroelectric dam construction and just</v>

9
00:00:34.371 --> 00:00:36.890
<v Speaker 1>as I'm going to flood this value of</v>
<v Speaker 1>water,</v>

10
00:00:36.891 --> 00:00:39.470
<v Speaker 1>I see an ant until very no tough luck</v>
<v Speaker 1>for the ads,</v>

11
00:00:39.471 --> 00:00:41.510
<v Speaker 1>right?</v>
<v Speaker 1>Their goals weren't aligned with mine</v>

12
00:00:41.840 --> 00:00:44.780
<v Speaker 1>and because I'm smarter,</v>
<v Speaker 1>it's going to be my goals,</v>

13
00:00:44.870 --> 00:00:49.610
<v Speaker 1>not the ants goals that get fulfilled.</v>
<v Speaker 1>We never want to put humanity and the</v>

14
00:00:49.611 --> 00:00:52.730
<v Speaker 1>role of those ads.</v>
<v Speaker 1>On the other hand,</v>

15
00:00:52.731 --> 00:00:54.830
<v Speaker 1>it doesn't have to be bad if you solve</v>
<v Speaker 1>the goal.</v>

16
00:00:54.830 --> 00:00:58.910
<v Speaker 1>Layman problem.</v>
<v Speaker 1>My little babies tend to be in a</v>

17
00:00:58.911 --> 00:01:03.320
<v Speaker 1>household surrounded by human level.</v>
<v Speaker 1>Intelligence is the smarter than the</v>

18
00:01:03.321 --> 00:01:05.150
<v Speaker 1>babies and they leave their parents</v>
<v Speaker 1>right.</v>

19
00:01:05.390 --> 00:01:09.650
<v Speaker 1>And that works out fine because the</v>
<v Speaker 1>goals of the parents are wonderfully</v>

20
00:01:09.651 --> 00:01:13.190
<v Speaker 1>align with the goals of the child.</v>
<v Speaker 1>So the chaplain just all good.</v>

21
00:01:13.820 --> 00:01:16.520
<v Speaker 1>And this is one vision that a lot of ai</v>
<v Speaker 1>researchers have.</v>

22
00:01:16.840 --> 00:01:20.810
<v Speaker 1>The friendly ai vision that we will</v>
<v Speaker 1>succeed and not just making machines</v>

23
00:01:20.811 --> 00:01:25.310
<v Speaker 1>that are smarter than us,</v>
<v Speaker 1>but also machines that then learn,</v>

24
00:01:25.550 --> 00:01:28.250
<v Speaker 1>adopt,</v>
<v Speaker 1>then retain our goals as they get ever</v>

25
00:01:28.251 --> 00:01:31.400
<v Speaker 1>smarter.</v>
<v Speaker 1>It might sound easy to get machines to</v>

26
00:01:32.990 --> 00:01:37.990
<v Speaker 1>learn and adopt and retain our goals,</v>
<v Speaker 1>but these are all very tough problems.</v>

27
00:01:38.360 --> 00:01:41.540
<v Speaker 1>First of all,</v>
<v Speaker 1>if you take yourself driving taxi and</v>

28
00:01:41.541 --> 00:01:44.780
<v Speaker 1>tell it in the future to take you to the</v>
<v Speaker 1>airport as fast as possible and then you</v>

29
00:01:44.781 --> 00:01:47.390
<v Speaker 1>get there covered in vomit and chased by</v>
<v Speaker 1>helicopters and you said,</v>

30
00:01:47.570 --> 00:01:47.841
<v Speaker 1>no,</v>
<v Speaker 1>no,</v>

31
00:01:47.841 --> 00:01:48.410
<v Speaker 1>no,</v>
<v Speaker 1>no,</v>

32
00:01:48.410 --> 00:01:49.610
<v Speaker 1>that's not what I wanted.</v>

33
00:01:50.030 --> 00:01:54.470
<v Speaker 1>And it replies.</v>
<v Speaker 1>That is exactly what you asked for.</v>

34
00:01:55.040 --> 00:01:59.270
<v Speaker 1>Venue have appreciated how hard it is to</v>
<v Speaker 1>get a machine to understand your goals,</v>

35
00:01:59.271 --> 00:02:00.650
<v Speaker 1>your actual goals.</v>
<v Speaker 1>You know,</v>

36
00:02:00.651 --> 00:02:05.150
<v Speaker 1>a human cab driver would have realized</v>
<v Speaker 1>that you also had other goals that were</v>

37
00:02:05.151 --> 00:02:09.200
<v Speaker 1>unstated because she was also a human</v>
<v Speaker 1>and has all this shared reference frame.</v>

38
00:02:09.440 --> 00:02:13.060
<v Speaker 1>But a machine doesn't have that unless</v>
<v Speaker 1>we explicitly teach it that.</v>

39
00:02:13.070 --> 00:02:15.740
<v Speaker 1>Right.</v>
<v Speaker 1>And then once the machine understands</v>

40
00:02:15.741 --> 00:02:17.690
<v Speaker 1>our goals,</v>
<v Speaker 1>there's a separate problem getting them</v>

41
00:02:17.691 --> 00:02:21.850
<v Speaker 1>to re adopt the goals.</v>
<v Speaker 1>Anyone who has had kids knows how hard</v>

42
00:02:21.851 --> 00:02:24.860
<v Speaker 1>or how big the difference is between</v>
<v Speaker 1>making the kids understand what you want</v>

43
00:02:25.100 --> 00:02:29.300
<v Speaker 1>and actually adopt your goal to do what</v>
<v Speaker 1>you want and,</v>

44
00:02:29.301 --> 00:02:31.520
<v Speaker 1>and finally,</v>
<v Speaker 1>even if you can get your kids to adopt</v>

45
00:02:31.521 --> 00:02:32.780
<v Speaker 1>your goals,</v>
<v Speaker 1>that doesn't mean they're going to</v>

46
00:02:32.781 --> 00:02:34.130
<v Speaker 1>retain them for life.</v>
<v Speaker 1>Right?</v>

47
00:02:34.400 --> 00:02:38.660
<v Speaker 1>My kids are a lot less excited about</v>
<v Speaker 1>lego now than they were when they were</v>

48
00:02:38.661 --> 00:02:43.370
<v Speaker 1>little and we don't want machines as</v>
<v Speaker 1>they ever get ever smarter to gradually</v>

49
00:02:43.371 --> 00:02:47.030
<v Speaker 1>change their goals away from being</v>
<v Speaker 1>excited about protecting us and thinking</v>

50
00:02:47.031 --> 00:02:51.800
<v Speaker 1>of this thing about taking care of</v>
<v Speaker 1>humanity is just a little childhood</v>

51
00:02:53.060 --> 00:02:55.190
<v Speaker 1>thing like Lego is that they get bored</v>
<v Speaker 1>with.</v>

52
00:02:55.190 --> 00:02:58.280
<v Speaker 1>Eventually.</v>
<v Speaker 1>If we can solve all three of these</v>

53
00:02:58.281 --> 00:02:59.440
<v Speaker 1>quests,</v>
<v Speaker 1>tech challenges,</v>

54
00:02:59.950 --> 00:03:01.690
<v Speaker 1>getting machines to understand our</v>
<v Speaker 1>goals,</v>

55
00:03:01.810 --> 00:03:03.280
<v Speaker 1>adopt the man,</v>
<v Speaker 1>retain them,</v>

56
00:03:03.520 --> 00:03:07.210
<v Speaker 1>then we can create an awesome future</v>
<v Speaker 1>because everything I love about</v>

57
00:03:07.570 --> 00:03:09.610
<v Speaker 1>civilization as the product of</v>
<v Speaker 1>intelligence.</v>

58
00:03:10.420 --> 00:03:13.210
<v Speaker 1>Then if we can use machines to amplify</v>
<v Speaker 1>our intelligence,</v>

59
00:03:14.050 --> 00:03:18.340
<v Speaker 1>then we used to have this potential to</v>
<v Speaker 1>solve all the problems that are dumping</v>

60
00:03:18.341 --> 00:03:22.750
<v Speaker 1>us today and create a better future than</v>
<v Speaker 1>we even dare to dream of.</v>

61
00:03:23.320 --> 00:03:27.190
<v Speaker 1>If machines ever surpass us and can</v>
<v Speaker 1>outsmart us at all tasks,</v>

62
00:03:27.340 --> 00:03:32.170
<v Speaker 1>that's going to be a really big deal</v>
<v Speaker 1>because intelligence is power.</v>

63
00:03:32.410 --> 00:03:36.730
<v Speaker 1>The reason that we humans have more</v>
<v Speaker 1>power on this planet than tigers is not</v>

64
00:03:36.731 --> 00:03:40.710
<v Speaker 1>because we have larger muscles are</v>
<v Speaker 1>sharper clause,</v>

65
00:03:40.711 --> 00:03:42.160
<v Speaker 1>right?</v>
<v Speaker 1>It's because we're smarter than the</v>

66
00:03:42.161 --> 00:03:46.450
<v Speaker 1>Tigers and in this exact same way,</v>
<v Speaker 1>it's machines are smarter than us.</v>

67
00:03:47.950 --> 00:03:52.950
<v Speaker 1>It becomes perfectly plausible for them</v>
<v Speaker 1>to control us and become the rulers of</v>

68
00:03:53.410 --> 00:03:55.210
<v Speaker 1>this planet and beyond.</v>

69
00:03:55.990 --> 00:03:59.830
<v Speaker 1>And um,</v>
<v Speaker 1>when I j good made this famous analysis</v>

70
00:03:59.831 --> 00:04:02.230
<v Speaker 1>of how you could get an intelligence</v>
<v Speaker 1>explosion,</v>

71
00:04:02.390 --> 00:04:06.310
<v Speaker 1>we're intelligence just kept creating</v>
<v Speaker 1>greater and greater intelligence leaving</v>

72
00:04:06.311 --> 00:04:09.880
<v Speaker 1>us far behind.</v>
<v Speaker 1>He also mentioned that this super</v>

73
00:04:09.881 --> 00:04:14.410
<v Speaker 1>intelligence would be the last invention</v>
<v Speaker 1>that men need ever make.</v>

74
00:04:14.830 --> 00:04:16.660
<v Speaker 1>And what he meant by that,</v>
<v Speaker 1>of course,</v>

75
00:04:16.661 --> 00:04:20.170
<v Speaker 1>was it so far,</v>
<v Speaker 1>the most intelligent being on this</v>

76
00:04:20.171 --> 00:04:21.820
<v Speaker 1>planet that's been doing all the</v>
<v Speaker 1>inventing,</v>

77
00:04:22.120 --> 00:04:25.870
<v Speaker 1>it's been us,</v>
<v Speaker 1>but once we make machines that are</v>

78
00:04:25.871 --> 00:04:30.871
<v Speaker 1>better than us at the inventing all</v>
<v Speaker 1>future technology that we ever need can</v>

79
00:04:31.751 --> 00:04:36.160
<v Speaker 1>be created by those machines.</v>
<v Speaker 1>If we can make sure that they do things</v>

80
00:04:36.190 --> 00:04:41.190
<v Speaker 1>for us that we want and to help us</v>
<v Speaker 1>create an awesome future where humanity</v>

81
00:04:42.251 --> 00:04:43.720
<v Speaker 1>can flourish like never before.</v>

82
00:04:44.390 --> 00:04:44.980
<v Speaker 2>Mm.</v>

