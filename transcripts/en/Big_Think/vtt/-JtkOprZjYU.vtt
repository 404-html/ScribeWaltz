WEBVTT

1
00:00:05.440 --> 00:00:07.580
<v Speaker 1>So one of the things that worries me,</v>
<v Speaker 1>the noticed,</v>

2
00:00:07.910 --> 00:00:10.860
<v Speaker 1>uh,</v>
<v Speaker 1>in the technology world today is the</v>

3
00:00:10.861 --> 00:00:15.120
<v Speaker 1>degree to which the external world has</v>
<v Speaker 1>view technology with more and more</v>

4
00:00:15.121 --> 00:00:18.000
<v Speaker 1>cynicism and the degree to which,</v>
<v Speaker 1>uh,</v>

5
00:00:18.180 --> 00:00:19.740
<v Speaker 1>you know,</v>
<v Speaker 1>there's a little bit of a backlash</v>

6
00:00:19.741 --> 00:00:22.800
<v Speaker 1>starting.</v>
<v Speaker 1>And I think that there's a few drivers</v>

7
00:00:22.801 --> 00:00:25.110
<v Speaker 1>for that.</v>
<v Speaker 1>I think the recent elections is sort of</v>

8
00:00:25.111 --> 00:00:27.150
<v Speaker 1>one example where people feel that they</v>
<v Speaker 1>were manipulated,</v>

9
00:00:27.390 --> 00:00:29.550
<v Speaker 1>I should say,</v>
<v Speaker 1>by third parties of using technology.</v>

10
00:00:29.970 --> 00:00:32.940
<v Speaker 1>Um,</v>
<v Speaker 1>and I think separate from that,</v>

11
00:00:32.970 --> 00:00:35.340
<v Speaker 1>there's also just the sort of media</v>
<v Speaker 1>waves where,</v>

12
00:00:35.341 --> 00:00:36.180
<v Speaker 1>you know,</v>
<v Speaker 1>uh,</v>

13
00:00:36.220 --> 00:00:39.300
<v Speaker 1>media tends to go in cycles where the</v>
<v Speaker 1>press would build something up and then</v>

14
00:00:39.301 --> 00:00:41.160
<v Speaker 1>tear it down and then build something up</v>
<v Speaker 1>and tear it down.</v>

15
00:00:41.490 --> 00:00:45.300
<v Speaker 1>And I think technology was really built</v>
<v Speaker 1>up in the media for a 20 year period or</v>

16
00:00:45.301 --> 00:00:48.030
<v Speaker 1>so.</v>
<v Speaker 1>And now it's sort of a time of reckoning</v>

17
00:00:48.060 --> 00:00:49.710
<v Speaker 1>and to some extent,</v>
<v Speaker 1>um,</v>

18
00:00:49.730 --> 00:00:54.330
<v Speaker 1>I think that's very unfortunate because</v>
<v Speaker 1>I believe that optimism is a reflexive</v>

19
00:00:54.331 --> 00:00:56.880
<v Speaker 1>asset and sort of the George Soros view</v>
<v Speaker 1>of the world where,</v>

20
00:00:57.120 --> 00:00:58.170
<v Speaker 1>you know,</v>
<v Speaker 1>something that,</v>

21
00:00:58.200 --> 00:00:58.950
<v Speaker 1>uh,</v>
<v Speaker 1>people,</v>

22
00:00:58.950 --> 00:01:00.810
<v Speaker 1>uh,</v>
<v Speaker 1>give value to gains value.</v>

23
00:01:00.940 --> 00:01:02.580
<v Speaker 1>Uh,</v>
<v Speaker 1>by that belief in the value of that</v>

24
00:01:02.581 --> 00:01:04.140
<v Speaker 1>thing.</v>
<v Speaker 1>And,</v>

25
00:01:04.170 --> 00:01:06.120
<v Speaker 1>uh,</v>
<v Speaker 1>if you actually look at the major</v>

26
00:01:06.121 --> 00:01:09.690
<v Speaker 1>changes that have happened in the world</v>
<v Speaker 1>is because people have been extremely</v>

27
00:01:09.691 --> 00:01:11.930
<v Speaker 1>optimistic in ways that some folks</v>
<v Speaker 1>thought were,</v>

28
00:01:11.990 --> 00:01:13.620
<v Speaker 1>was irrational.</v>
<v Speaker 1>Um,</v>

29
00:01:13.800 --> 00:01:16.530
<v Speaker 1>but that optimism allowed them to</v>
<v Speaker 1>actually accomplish that giant goal.</v>

30
00:01:16.531 --> 00:01:17.364
<v Speaker 1>I mean,</v>
<v Speaker 1>think of,</v>

31
00:01:17.490 --> 00:01:19.310
<v Speaker 1>uh,</v>
<v Speaker 1>putting somebody on the moon and what we</v>

32
00:01:19.311 --> 00:01:21.570
<v Speaker 1>were able to accomplish in the sixties</v>
<v Speaker 1>or,</v>

33
00:01:21.600 --> 00:01:22.231
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

34
00:01:22.231 --> 00:01:24.660
<v Speaker 1>think about a variety of other examples</v>
<v Speaker 1>like that.</v>

35
00:01:24.661 --> 00:01:27.690
<v Speaker 1>The Manhattan project or you know,</v>
<v Speaker 1>major breakthroughs of all sort of come</v>

36
00:01:27.691 --> 00:01:32.220
<v Speaker 1>through and enormous sense of optimism</v>
<v Speaker 1>and we can do this a manifest destiny</v>

37
00:01:32.221 --> 00:01:33.510
<v Speaker 1>and Sorta,</v>
<v Speaker 1>you know,</v>

38
00:01:33.511 --> 00:01:36.630
<v Speaker 1>the development of the United States as</v>
<v Speaker 1>a country is a good example of that on</v>

39
00:01:36.631 --> 00:01:38.250
<v Speaker 1>the sort of country and governance</v>
<v Speaker 1>level.</v>

40
00:01:38.760 --> 00:01:41.220
<v Speaker 1>Um,</v>
<v Speaker 1>and so one thing that I've seen more and</v>

41
00:01:41.221 --> 00:01:46.221
<v Speaker 1>more increasingly is a increase in</v>
<v Speaker 1>cynicism and people being made fun of</v>

42
00:01:46.920 --> 00:01:49.080
<v Speaker 1>for saying they want to change the world</v>
<v Speaker 1>when they're genuine about it.</v>

43
00:01:49.350 --> 00:01:52.470
<v Speaker 1>And I think that's a very big negative.</v>
<v Speaker 1>And so one of my,</v>

44
00:01:52.500 --> 00:01:55.020
<v Speaker 1>one of the things I've been thinking a</v>
<v Speaker 1>lot about recently is how can you</v>

45
00:01:55.021 --> 00:01:58.470
<v Speaker 1>actually increase the seidel optimism?</v>
<v Speaker 1>What are the mechanisms by which people</v>

46
00:01:58.471 --> 00:02:01.830
<v Speaker 1>can become more enthusiastic about their</v>
<v Speaker 1>future and more enthusiastic about</v>

47
00:02:01.831 --> 00:02:03.810
<v Speaker 1>technology?</v>
<v Speaker 1>Because if you look at the changes that</v>

48
00:02:03.811 --> 00:02:06.270
<v Speaker 1>technology has wrought over the last 20,</v>
<v Speaker 1>30 years,</v>

49
00:02:06.570 --> 00:02:11.370
<v Speaker 1>it literally has lifted tens or hundreds</v>
<v Speaker 1>of millions of people out of poverty.</v>

50
00:02:11.371 --> 00:02:14.640
<v Speaker 1>It has created access to global markets</v>
<v Speaker 1>that has created access to global</v>

51
00:02:14.641 --> 00:02:15.990
<v Speaker 1>information.</v>
<v Speaker 1>Uh,</v>

52
00:02:16.020 --> 00:02:17.490
<v Speaker 1>you know,</v>
<v Speaker 1>everybody's walking around with</v>

53
00:02:17.491 --> 00:02:20.700
<v Speaker 1>literally a super computer in their</v>
<v Speaker 1>pocket that gives them the access to the</v>

54
00:02:20.701 --> 00:02:23.050
<v Speaker 1>sum of all of humanity's knowledge,</v>
<v Speaker 1>uh,</v>

55
00:02:23.070 --> 00:02:25.170
<v Speaker 1>with maybe the exception of scientific</v>
<v Speaker 1>journals which are still blocked.</v>

56
00:02:25.560 --> 00:02:27.080
<v Speaker 1>So I do think that,</v>
<v Speaker 1>um,</v>

57
00:02:27.210 --> 00:02:29.490
<v Speaker 1>people should be incredibly optimistic</v>
<v Speaker 1>about the future.</v>

58
00:02:29.850 --> 00:02:32.550
<v Speaker 1>And one thing I wonder about is how can</v>
<v Speaker 1>you help spread that optimism?</v>

59
00:02:32.550 --> 00:02:34.980
<v Speaker 1>Because I think if people believe they</v>
<v Speaker 1>can do something,</v>

60
00:02:34.981 --> 00:02:37.230
<v Speaker 1>they often achieve things that they</v>
<v Speaker 1>never thought was possible.</v>

61
00:02:37.920 --> 00:02:41.970
<v Speaker 1>So a lot of people have recently had a</v>
<v Speaker 1>lot of very cogent concerns around the</v>

62
00:02:41.971 --> 00:02:44.010
<v Speaker 1>rise of misinformation and</v>
<v Speaker 1>disinformation,</v>

63
00:02:44.730 --> 00:02:46.920
<v Speaker 1>uh,</v>
<v Speaker 1>on social media platforms and how that</v>

64
00:02:46.921 --> 00:02:50.190
<v Speaker 1>impacted our last election.</v>
<v Speaker 1>And you know,</v>

65
00:02:50.191 --> 00:02:51.690
<v Speaker 1>I think those are very legitimate</v>
<v Speaker 1>concerns.</v>

66
00:02:51.691 --> 00:02:54.570
<v Speaker 1>And I think some of the platforms have</v>
<v Speaker 1>made pretty major mistakes in terms of</v>

67
00:02:54.571 --> 00:02:55.830
<v Speaker 1>how they've approached some of those</v>
<v Speaker 1>things.</v>

68
00:02:56.340 --> 00:02:58.050
<v Speaker 1>Um,</v>
<v Speaker 1>it's interesting though because if you</v>

69
00:02:58.051 --> 00:03:00.460
<v Speaker 1>look at it over the arc of history,</v>
<v Speaker 1>uh,</v>

70
00:03:00.520 --> 00:03:03.250
<v Speaker 1>this is not a new story.</v>
<v Speaker 1>Every time that there's a new</v>

71
00:03:03.490 --> 00:03:05.320
<v Speaker 1>technology,</v>
<v Speaker 1>particularly around media,</v>

72
00:03:05.640 --> 00:03:07.300
<v Speaker 1>uh,</v>
<v Speaker 1>there's a set of outcries around how</v>

73
00:03:07.301 --> 00:03:11.740
<v Speaker 1>that media is corrupting culture or how</v>
<v Speaker 1>it's destroying certain aspects of our</v>

74
00:03:11.741 --> 00:03:13.300
<v Speaker 1>life.</v>
<v Speaker 1>And in some cases those are real</v>

75
00:03:13.301 --> 00:03:14.710
<v Speaker 1>concerns.</v>
<v Speaker 1>Um,</v>

76
00:03:14.740 --> 00:03:17.950
<v Speaker 1>there's a great book from Tom standage</v>
<v Speaker 1>about the early telegraph in the 18</v>

77
00:03:17.951 --> 00:03:19.450
<v Speaker 1>hundreds called the Victorian Internet.</v>

78
00:03:19.810 --> 00:03:23.290
<v Speaker 1>And he basically makes the argument that</v>
<v Speaker 1>a lot of the behavior that exists online</v>

79
00:03:23.291 --> 00:03:26.500
<v Speaker 1>today was being done by telegraph</v>
<v Speaker 1>operators in the 18 hundreds because</v>

80
00:03:26.501 --> 00:03:30.010
<v Speaker 1>they were just sitting on these lines</v>
<v Speaker 1>talking with each other over Morse code.</v>

81
00:03:30.280 --> 00:03:32.350
<v Speaker 1>And they would gossip and they would</v>
<v Speaker 1>trade recipes.</v>

82
00:03:32.351 --> 00:03:35.470
<v Speaker 1>And it would date a,</v>
<v Speaker 1>but also it was a way for news to spread</v>

83
00:03:35.471 --> 00:03:37.460
<v Speaker 1>quickly.</v>
<v Speaker 1>And a lot of people argued that it was a</v>

84
00:03:37.461 --> 00:03:39.760
<v Speaker 1>downfall of a variety of things.</v>
<v Speaker 1>It was,</v>

85
00:03:39.761 --> 00:03:41.950
<v Speaker 1>it could be the downfall of markets</v>
<v Speaker 1>cause suddenly markets were more</v>

86
00:03:41.951 --> 00:03:45.100
<v Speaker 1>efficient or it could impact religion or</v>
<v Speaker 1>other things.</v>

87
00:03:45.490 --> 00:03:47.950
<v Speaker 1>And then we had radio actually before</v>
<v Speaker 1>radio,</v>

88
00:03:47.951 --> 00:03:51.250
<v Speaker 1>we had newspapers in the early 19</v>
<v Speaker 1>hundreds and there was the wave of</v>

89
00:03:51.251 --> 00:03:53.890
<v Speaker 1>yellow journalism.</v>
<v Speaker 1>There was a Spanish American war that</v>

90
00:03:53.891 --> 00:03:56.560
<v Speaker 1>was caused by,</v>
<v Speaker 1>by a new form of media.</v>

91
00:03:56.950 --> 00:04:00.880
<v Speaker 1>And then we had radio and radio was</v>
<v Speaker 1>corrupting the youth by spreading rock</v>

92
00:04:00.881 --> 00:04:03.610
<v Speaker 1>and roll and sin and you know,</v>
<v Speaker 1>all sorts of bad things.</v>

93
00:04:04.030 --> 00:04:06.130
<v Speaker 1>And then we had TV,</v>
<v Speaker 1>which was turning everybody into</v>

94
00:04:06.131 --> 00:04:08.170
<v Speaker 1>vegetables.</v>
<v Speaker 1>And then we had,</v>

95
00:04:08.200 --> 00:04:09.430
<v Speaker 1>um,</v>
<v Speaker 1>video games,</v>

96
00:04:09.431 --> 00:04:11.290
<v Speaker 1>which was turning all of our children</v>
<v Speaker 1>into killers.</v>

97
00:04:11.770 --> 00:04:14.260
<v Speaker 1>Uh,</v>
<v Speaker 1>and now we have social media as the next</v>

98
00:04:14.410 --> 00:04:17.560
<v Speaker 1>new media platform.</v>
<v Speaker 1>And instagram is destroying our youth.</v>

99
00:04:18.100 --> 00:04:20.110
<v Speaker 1>And I think that fact about instagram is</v>
<v Speaker 1>true,</v>

100
00:04:20.470 --> 00:04:21.880
<v Speaker 1>but I'm joking about that.</v>
<v Speaker 1>But,</v>

101
00:04:21.910 --> 00:04:24.370
<v Speaker 1>um,</v>
<v Speaker 1>and the broader context,</v>

102
00:04:24.371 --> 00:04:27.790
<v Speaker 1>if you think about it,</v>
<v Speaker 1>every time we have a new form of media,</v>

103
00:04:28.180 --> 00:04:31.450
<v Speaker 1>we make the argument that that form of</v>
<v Speaker 1>media is the thing that's going to</v>

104
00:04:31.451 --> 00:04:33.670
<v Speaker 1>destroy our society.</v>
<v Speaker 1>That's corrupting our politics,</v>

105
00:04:33.671 --> 00:04:36.790
<v Speaker 1>is corrupting our children.</v>
<v Speaker 1>This destroying our ability to think for</v>

106
00:04:36.791 --> 00:04:39.610
<v Speaker 1>ourselves and every time society has</v>
<v Speaker 1>turned out okay.</v>

107
00:04:39.850 --> 00:04:44.320
<v Speaker 1>Now that doesn't mean that social media</v>
<v Speaker 1>platform shouldn't be reacting or</v>

108
00:04:44.321 --> 00:04:45.940
<v Speaker 1>shouldn't be addressing these issues.</v>
<v Speaker 1>I'm just saying,</v>

109
00:04:45.941 --> 00:04:48.400
<v Speaker 1>if you look at it through the larger</v>
<v Speaker 1>lens of history,</v>

110
00:04:48.520 --> 00:04:49.600
<v Speaker 1>this is not a new story.</v>

