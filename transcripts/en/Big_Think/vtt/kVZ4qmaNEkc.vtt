WEBVTT

1
00:00:06.710 --> 00:00:07.543
<v Speaker 1>Attended</v>

2
00:00:08.660 --> 00:00:13.660
<v Speaker 2>about a month ago,</v>
<v Speaker 2>a meeting in Japan in Kyoto organized by</v>

3
00:00:15.800 --> 00:00:20.800
<v Speaker 2>a remarkable individual named a Koji Omi</v>
<v Speaker 2>who was among other things or finance</v>

4
00:00:21.771 --> 00:00:25.880
<v Speaker 2>minister of Japan for awhile and I only</v>
<v Speaker 2>saw one,</v>

5
00:00:25.910 --> 00:00:30.380
<v Speaker 2>has been holding this annual conference</v>
<v Speaker 2>on science,</v>

6
00:00:30.890 --> 00:00:35.360
<v Speaker 2>technology and society and he calls it</v>
<v Speaker 2>light and shadow,</v>

7
00:00:36.470 --> 00:00:41.270
<v Speaker 2>light and shadow,</v>
<v Speaker 2>a very Japanese way of saying science</v>

8
00:00:41.271 --> 00:00:46.271
<v Speaker 2>can shed light to extraordinary positive</v>
<v Speaker 2>things that it also has a dark side.</v>

9
00:00:47.271 --> 00:00:52.271
<v Speaker 2>It creates shadows.</v>
<v Speaker 2>This is true of anything economic power,</v>

10
00:00:53.750 --> 00:00:58.160
<v Speaker 2>military power and scientific power have</v>
<v Speaker 2>a bright side.</v>

11
00:00:58.190 --> 00:01:02.090
<v Speaker 2>They have a dark side.</v>
<v Speaker 2>We must be very aware of that.</v>

12
00:01:03.260 --> 00:01:08.260
<v Speaker 2>I'm a great believer that</v>
<v Speaker 2>we should have full freedom as</v>

13
00:01:09.741 --> 00:01:14.741
<v Speaker 2>conceivable for the human mind to</v>
<v Speaker 2>explore nature and understand.</v>

14
00:01:16.520 --> 00:01:21.520
<v Speaker 2>However,</v>
<v Speaker 2>we have to be aware of the consequences</v>

15
00:01:21.770 --> 00:01:26.770
<v Speaker 2>of some of the kinds of knowledge that</v>
<v Speaker 2>we are beginning to develop and I</v>

16
00:01:27.711 --> 00:01:31.700
<v Speaker 2>suspect that over this coming decade or</v>
<v Speaker 2>so,</v>

17
00:01:32.540 --> 00:01:36.950
<v Speaker 2>that we're going to face a lot of very</v>
<v Speaker 2>deeply ethical questions.</v>

18
00:01:37.040 --> 00:01:42.040
<v Speaker 2>As life science becomes more and more</v>
<v Speaker 2>the basis of technology and action.</v>

19
00:01:45.290 --> 00:01:48.470
<v Speaker 2>We should never be afraid of learning of</v>
<v Speaker 2>discovery,</v>

20
00:01:49.370 --> 00:01:54.370
<v Speaker 2>but we need to be cautious as we move</v>
<v Speaker 2>into new technological areas because</v>

21
00:01:56.691 --> 00:01:59.270
<v Speaker 2>they move so fast,</v>
<v Speaker 2>you know,</v>

22
00:01:59.271 --> 00:02:02.270
<v Speaker 2>in the old days,</v>
<v Speaker 2>you could generally develop technology.</v>

23
00:02:02.271 --> 00:02:04.030
<v Speaker 2>It took a lifetime,</v>
<v Speaker 2>uh,</v>

24
00:02:04.390 --> 00:02:07.070
<v Speaker 2>you know,</v>
<v Speaker 2>for the automobile to reach 25 percent</v>

25
00:02:07.071 --> 00:02:09.950
<v Speaker 2>of the public,</v>
<v Speaker 2>whereas the worldwide web did it and</v>

26
00:02:09.980 --> 00:02:12.230
<v Speaker 2>seven and a half years.</v>
<v Speaker 2>So this,</v>

27
00:02:12.280 --> 00:02:17.090
<v Speaker 2>this pace</v>
<v Speaker 2>doesn't always give us the time to think</v>

28
00:02:17.091 --> 00:02:21.410
<v Speaker 2>through before we moved.</v>
<v Speaker 2>And we saw that in genetically modified</v>

29
00:02:21.411 --> 00:02:26.411
<v Speaker 2>foods which created a cultural figure in</v>
<v Speaker 2>Europe that the people who were doing</v>

30
00:02:27.501 --> 00:02:31.520
<v Speaker 2>the original marketing really hadn't</v>
<v Speaker 2>stepped back and thought through.</v>

31
00:02:32.420 --> 00:02:37.420
<v Speaker 2>So the two areas that I think we're</v>
<v Speaker 2>going to have to think deeply about are</v>

32
00:02:38.690 --> 00:02:40.280
<v Speaker 2>certainly,</v>
<v Speaker 2>uh,</v>

33
00:02:40.350 --> 00:02:45.350
<v Speaker 2>the whole world that's beginning to</v>
<v Speaker 2>evolve of synthetic biology and the</v>

34
00:02:46.131 --> 00:02:47.870
<v Speaker 2>increasing genetic knowledge.</v>

35
00:02:47.870 --> 00:02:50.150
<v Speaker 2>We're going to have a very selves and</v>
<v Speaker 2>others.</v>

36
00:02:50.840 --> 00:02:53.240
<v Speaker 2>What really is going to constitute</v>
<v Speaker 2>wisdom?</v>

37
00:02:53.241 --> 00:02:57.710
<v Speaker 2>How are we going to decide what one</v>
<v Speaker 2>wants to know?</v>

38
00:02:58.430 --> 00:03:01.210
<v Speaker 2>Uh,</v>
<v Speaker 2>how do we start thinking about things</v>

39
00:03:01.211 --> 00:03:04.870
<v Speaker 2>when we begin creating life forms which</v>
<v Speaker 2>were doing,</v>

40
00:03:05.350 --> 00:03:08.410
<v Speaker 2>you know,</v>
<v Speaker 2>you walk up and down the halls of a</v>

41
00:03:08.411 --> 00:03:12.190
<v Speaker 2>place like mit,</v>
<v Speaker 2>hear the kids talking about biohacking.</v>

42
00:03:12.820 --> 00:03:14.080
<v Speaker 2>That means,</v>
<v Speaker 2>you know,</v>

43
00:03:14.081 --> 00:03:17.930
<v Speaker 2>we're taking organisms,</v>
<v Speaker 2>we're taking the stuff of life and we're</v>

44
00:03:17.950 --> 00:03:21.660
<v Speaker 2>mixing it up and playing around.</v>
<v Speaker 2>We're not creating monsters when we're</v>

45
00:03:21.670 --> 00:03:26.670
<v Speaker 2>doing things at a molecular level that</v>
<v Speaker 2>we have to think through what's going to</v>

46
00:03:26.921 --> 00:03:30.640
<v Speaker 2>happen.</v>
<v Speaker 2>The whole field of genetic counseling,</v>

47
00:03:30.641 --> 00:03:32.050
<v Speaker 2>what do you want to know?</v>
<v Speaker 2>Should you know,</v>

48
00:03:32.051 --> 00:03:36.930
<v Speaker 2>should you know that you've got an very</v>
<v Speaker 2>high probability of having Alzheimer's,</v>

49
00:03:36.970 --> 00:03:37.930
<v Speaker 2>uh,</v>
<v Speaker 2>later on.</v>

50
00:03:38.320 --> 00:03:43.320
<v Speaker 2>So I think most of the areas we have to</v>
<v Speaker 2>think most deeply about are going to be</v>

51
00:03:43.451 --> 00:03:48.451
<v Speaker 2>driven by the infusion of life science</v>
<v Speaker 2>into things that directly affect us into</v>

52
00:03:48.641 --> 00:03:51.820
<v Speaker 2>medicine,</v>
<v Speaker 2>into the production and materials and so</v>

53
00:03:51.821 --> 00:03:52.654
<v Speaker 2>forth.</v>

54
00:03:52.840 --> 00:03:56.140
<v Speaker 2>At the same time,</v>
<v Speaker 2>I don't want to slow that because I</v>

55
00:03:56.141 --> 00:03:59.590
<v Speaker 2>believe within,</v>
<v Speaker 2>it belies a lot of the resolution of</v>

56
00:03:59.980 --> 00:04:04.980
<v Speaker 2>environmental problems and so forth</v>
<v Speaker 2>because we learned from nature to design</v>

57
00:04:05.471 --> 00:04:09.670
<v Speaker 2>and grow as opposed to physically</v>
<v Speaker 2>manufacture materials.</v>

58
00:04:09.671 --> 00:04:12.610
<v Speaker 2>We can do it generally with a lot less</v>
<v Speaker 2>energy,</v>

59
00:04:12.611 --> 00:04:15.340
<v Speaker 2>with more uses of natural materials and</v>
<v Speaker 2>so forth,</v>

60
00:04:15.700 --> 00:04:20.700
<v Speaker 2>but we do have to think that through a</v>
<v Speaker 2>more understandable example because</v>

61
00:04:21.251 --> 00:04:25.600
<v Speaker 2>we're in some ways further down the path</v>
<v Speaker 2>is people will have some legitimate</v>

62
00:04:25.601 --> 00:04:30.601
<v Speaker 2>concerns about nanotechnology and it's a</v>
<v Speaker 2>complicated area because a nano just</v>

63
00:04:32.831 --> 00:04:37.831
<v Speaker 2>really refers to building things out of</v>
<v Speaker 2>extremely small molecules and particles</v>

64
00:04:39.450 --> 00:04:41.680
<v Speaker 2>and we've been doing this forever on one</v>
<v Speaker 2>hand,</v>

65
00:04:42.040 --> 00:04:44.050
<v Speaker 2>but on the other hand,</v>
<v Speaker 2>we're starting to,</v>

66
00:04:44.350 --> 00:04:47.110
<v Speaker 2>uh,</v>
<v Speaker 2>take metals and various materials and</v>

67
00:04:47.111 --> 00:04:51.880
<v Speaker 2>put them in this very small form that</v>
<v Speaker 2>can enter directly into cells,</v>

68
00:04:51.881 --> 00:04:53.710
<v Speaker 2>can be breathed in,</v>
<v Speaker 2>in different ways.</v>

69
00:04:54.100 --> 00:04:58.630
<v Speaker 2>Chances are 99 percent of it is not</v>
<v Speaker 2>going to be dangerous,</v>

70
00:04:59.020 --> 00:05:03.850
<v Speaker 2>but we have to be willing to kind of</v>
<v Speaker 2>make the investments as we go along to</v>

71
00:05:03.851 --> 00:05:08.851
<v Speaker 2>engage bright people who by the way</v>
<v Speaker 2>cannot all be professional scientists</v>

72
00:05:09.311 --> 00:05:13.060
<v Speaker 2>and engineers.</v>
<v Speaker 2>We need lay people and thinkers engaged</v>

73
00:05:13.660 --> 00:05:16.090
<v Speaker 2>and just think airway through some of</v>
<v Speaker 2>these issues.</v>

74
00:05:16.660 --> 00:05:18.730
<v Speaker 2>At the same time,</v>
<v Speaker 2>you know,</v>

75
00:05:18.760 --> 00:05:21.790
<v Speaker 2>I believe in boldness and I believe in</v>
<v Speaker 2>taking risks.</v>

76
00:05:22.380 --> 00:05:26.170
<v Speaker 2>It's just that we don't want to take</v>
<v Speaker 2>risks on scales and with people who</v>

77
00:05:26.171 --> 00:05:28.450
<v Speaker 2>don't know they're taking risk and so</v>
<v Speaker 2>forth.</v>

78
00:05:28.720 --> 00:05:33.700
<v Speaker 2>We just need deeper thought and these</v>
<v Speaker 2>newer areas because they're moving so</v>

79
00:05:33.701 --> 00:05:38.701
<v Speaker 2>rapidly and I think we're going to face</v>
<v Speaker 2>some really tough ethical decisions in</v>

80
00:05:39.310 --> 00:05:43.900
<v Speaker 2>these areas and they're not gonna all be</v>
<v Speaker 2>easily resolved and going back to</v>

81
00:05:43.901 --> 00:05:48.550
<v Speaker 2>something you asked about earlier,</v>
<v Speaker 2>it can't just be science and</v>

82
00:05:48.551 --> 00:05:49.970
<v Speaker 2>engineering.</v>
<v Speaker 2>You know it.</v>

83
00:05:50.510 --> 00:05:54.220
<v Speaker 2>We live in a democracy.</v>
<v Speaker 2>We have political processes for making</v>

84
00:05:54.221 --> 00:05:58.730
<v Speaker 2>decisions.</v>
<v Speaker 2>We just want those decisions to be truly</v>

85
00:05:58.760 --> 00:06:03.760
<v Speaker 2>well informed and questions shaped in</v>
<v Speaker 2>ways that really make sense and are</v>

86
00:06:05.751 --> 00:06:06.320
<v Speaker 2>appropriate.</v>

