WEBVTT

1
00:00:03.540 --> 00:00:07.830
<v Speaker 1>If you think much about physics and</v>
<v Speaker 1>cognition and intelligence,</v>

2
00:00:08.100 --> 00:00:12.930
<v Speaker 1>it's pretty obvious the human mind is</v>
<v Speaker 1>not the smartest possible general</v>

3
00:00:12.931 --> 00:00:16.980
<v Speaker 1>intelligence and you more than humans</v>
<v Speaker 1>are the highest jumpers are the fastest</v>

4
00:00:16.981 --> 00:00:19.860
<v Speaker 1>runners.</v>
<v Speaker 1>We're not going to be the smartest</v>

5
00:00:20.070 --> 00:00:25.070
<v Speaker 1>thinkers if you are going to work toward</v>
<v Speaker 1>agi rather than focusing on some narrow</v>

6
00:00:26.911 --> 00:00:30.960
<v Speaker 1>application.</v>
<v Speaker 1>There's a number of different approaches</v>

7
00:00:30.961 --> 00:00:35.961
<v Speaker 1>that you might take and I've spent some</v>
<v Speaker 1>time just surveying the Agi field as a</v>

8
00:00:37.321 --> 00:00:40.380
<v Speaker 1>whole and organizing an annual</v>
<v Speaker 1>conference on their gi.</v>

9
00:00:40.680 --> 00:00:45.680
<v Speaker 1>And then I've spent a bunch of more time</v>
<v Speaker 1>on a specific agi approach,</v>

10
00:00:46.560 --> 00:00:51.560
<v Speaker 1>which is based on the open cog open</v>
<v Speaker 1>source software platform in the big</v>

11
00:00:52.201 --> 00:00:55.170
<v Speaker 1>picture.</v>
<v Speaker 1>One way to approach Agi is to try to</v>

12
00:00:55.171 --> 00:00:59.070
<v Speaker 1>emulate the human brain at some level of</v>
<v Speaker 1>precision,</v>

13
00:00:59.310 --> 00:01:01.950
<v Speaker 1>and this is the approach I see.</v>
<v Speaker 1>For example,</v>

14
00:01:01.951 --> 00:01:03.630
<v Speaker 1>Google deep mind taking.</v>

15
00:01:03.960 --> 00:01:08.580
<v Speaker 1>They've taken deep neural networks,</v>
<v Speaker 1>which in their common form are mostly a</v>

16
00:01:08.581 --> 00:01:13.410
<v Speaker 1>model of visual and auditory processing</v>
<v Speaker 1>in the human brain.</v>

17
00:01:13.740 --> 00:01:18.740
<v Speaker 1>And now in the recent work such as the</v>
<v Speaker 1>DNC differential neuro computer,</v>

18
00:01:19.320 --> 00:01:24.320
<v Speaker 1>they're taking these deep networks that</v>
<v Speaker 1>model visual or auditory processing and</v>

19
00:01:24.691 --> 00:01:28.230
<v Speaker 1>their coupling that with a memory matrix</v>
<v Speaker 1>which models some aspect of what the</v>

20
00:01:28.231 --> 00:01:31.230
<v Speaker 1>hippocampus does,</v>
<v Speaker 1>which is the part of the brain that</v>

21
00:01:31.231 --> 00:01:35.190
<v Speaker 1>deals with working memory,</v>
<v Speaker 1>short term memory among other things.</v>

22
00:01:35.310 --> 00:01:40.310
<v Speaker 1>So this illustrates an approach where</v>
<v Speaker 1>you take neural networks emulating</v>

23
00:01:40.381 --> 00:01:43.830
<v Speaker 1>different parts of the brain and maybe</v>
<v Speaker 1>you take more and more in the neural</v>

24
00:01:43.831 --> 00:01:46.380
<v Speaker 1>networks and building different parts of</v>
<v Speaker 1>the human brain.</v>

25
00:01:46.620 --> 00:01:49.380
<v Speaker 1>You try to get them to all work</v>
<v Speaker 1>together,</v>

26
00:01:49.560 --> 00:01:52.500
<v Speaker 1>not necessarily doing computational</v>
<v Speaker 1>neuroscience,</v>

27
00:01:52.710 --> 00:01:57.480
<v Speaker 1>but trying to emulate the way different</v>
<v Speaker 1>parts of the brain are doing processing</v>

28
00:01:57.481 --> 00:01:59.130
<v Speaker 1>and the way they're talking to each</v>
<v Speaker 1>other.</v>

29
00:01:59.590 --> 00:02:04.590
<v Speaker 1>A totally different approach is being</v>
<v Speaker 1>taken by a guy named Marcus hooter in</v>

30
00:02:05.160 --> 00:02:10.160
<v Speaker 1>Australian National University.</v>
<v Speaker 1>He wrote a beautiful book on Universal</v>

31
00:02:10.230 --> 00:02:14.730
<v Speaker 1>Ai in which he showed how to write a</v>
<v Speaker 1>superhuman infinitely intelligence</v>

32
00:02:14.731 --> 00:02:17.130
<v Speaker 1>thinking machine and like 50 lines of</v>
<v Speaker 1>code.</v>

33
00:02:17.970 --> 00:02:22.710
<v Speaker 1>The problem is it would take more</v>
<v Speaker 1>computing power than there is in the</v>

34
00:02:22.711 --> 00:02:24.780
<v Speaker 1>entire universe to run.</v>
<v Speaker 1>So it's so,</v>

35
00:02:24.781 --> 00:02:28.680
<v Speaker 1>it's not practically useful,</v>
<v Speaker 1>but they're then trying to scale down</v>

36
00:02:28.681 --> 00:02:33.681
<v Speaker 1>from this theoretical Agi to find</v>
<v Speaker 1>something that that will really work.</v>

37
00:02:34.830 --> 00:02:39.830
<v Speaker 1>Now the approach we're taking in the</v>
<v Speaker 1>open cog project is different than</v>

38
00:02:40.470 --> 00:02:45.120
<v Speaker 1>either of those we're attempting to</v>
<v Speaker 1>emulate at a very high level.</v>

39
00:02:45.660 --> 00:02:50.130
<v Speaker 1>The way the human mind seems to work as</v>
<v Speaker 1>an embodied social,</v>

40
00:02:50.430 --> 00:02:55.380
<v Speaker 1>generally intelligent agent,</v>
<v Speaker 1>which is coming to grips with hard</v>

41
00:02:55.381 --> 00:02:59.680
<v Speaker 1>problems in the context of coming to</v>
<v Speaker 1>grips with itself and its and its life</v>

42
00:02:59.681 --> 00:03:00.514
<v Speaker 1>in the world.</v>

43
00:03:01.120 --> 00:03:05.760
<v Speaker 1>We're not drawing the model the way the</v>
<v Speaker 1>brain works at the level of neurons and</v>

44
00:03:05.761 --> 00:03:09.640
<v Speaker 1>neural networks.</v>
<v Speaker 1>We're looking at the human mind more</v>

45
00:03:09.641 --> 00:03:11.470
<v Speaker 1>from a high level cognitive point of</v>
<v Speaker 1>view.</v>

46
00:03:11.471 --> 00:03:13.630
<v Speaker 1>What kinds of of memory are there?</v>
<v Speaker 1>Well,</v>

47
00:03:13.631 --> 00:03:18.631
<v Speaker 1>there's semantic memory about abstract</v>
<v Speaker 1>knowledge or concrete facts.</v>

48
00:03:18.971 --> 00:03:23.080
<v Speaker 1>There's episodic memory of our other</v>
<v Speaker 1>biographical history,</v>

49
00:03:23.081 --> 00:03:27.400
<v Speaker 1>their sensory motor memory.</v>
<v Speaker 1>There's associative memory of things</v>

50
00:03:27.401 --> 00:03:29.770
<v Speaker 1>that have been related to us in our</v>
<v Speaker 1>lives.</v>

51
00:03:30.010 --> 00:03:34.390
<v Speaker 1>There's procedural memory of how to do</v>
<v Speaker 1>things and we then look at the different</v>

52
00:03:34.391 --> 00:03:39.190
<v Speaker 1>kinds of learning and reasoning the</v>
<v Speaker 1>human mind can do.</v>

53
00:03:39.191 --> 00:03:43.300
<v Speaker 1>We can do logical deduction sometimes.</v>
<v Speaker 1>We're not always good at it.</v>

54
00:03:43.330 --> 00:03:46.900
<v Speaker 1>We date,</v>
<v Speaker 1>we make emotional intuitive leaps and</v>

55
00:03:47.110 --> 00:03:52.110
<v Speaker 1>strange creative combinations of things</v>
<v Speaker 1>we learned by trial and error and habit.</v>

56
00:03:52.690 --> 00:03:55.540
<v Speaker 1>We learned socially by imitating,</v>
<v Speaker 1>mirroring,</v>

57
00:03:55.570 --> 00:04:00.250
<v Speaker 1>emulating or opposing others,</v>
<v Speaker 1>these different kinds of memory and</v>

58
00:04:00.251 --> 00:04:02.710
<v Speaker 1>learning that the human mind has.</v>

59
00:04:03.160 --> 00:04:08.050
<v Speaker 1>One can attempt to achieve each of those</v>
<v Speaker 1>where the cutting edge computer science</v>

60
00:04:08.051 --> 00:04:13.051
<v Speaker 1>algorithm rather than trying to achieve</v>
<v Speaker 1>each of those functions and structures</v>

61
00:04:14.530 --> 00:04:17.920
<v Speaker 1>and the way the brain does.</v>
<v Speaker 1>So what we have in open cog,</v>

62
00:04:17.950 --> 00:04:22.950
<v Speaker 1>we have a central knowledge repository,</v>
<v Speaker 1>which is very dynamic and lives in ram</v>

63
00:04:25.241 --> 00:04:29.020
<v Speaker 1>on a large network of computers,</v>
<v Speaker 1>which we call the atom space.</v>

64
00:04:29.050 --> 00:04:33.100
<v Speaker 1>And for,</v>
<v Speaker 1>for the mathematicians or computer</v>

65
00:04:33.101 --> 00:04:37.570
<v Speaker 1>science in the audience,</v>
<v Speaker 1>the Adams space is what you'd call a,</v>

66
00:04:37.870 --> 00:04:39.970
<v Speaker 1>uh,</v>
<v Speaker 1>weighted labeled hypergraph.</v>

67
00:04:40.090 --> 00:04:42.730
<v Speaker 1>So it has nodes,</v>
<v Speaker 1>it has links.</v>

68
00:04:42.970 --> 00:04:46.420
<v Speaker 1>A link can go between two nodes or a</v>
<v Speaker 1>link ego between three,</v>

69
00:04:46.421 --> 00:04:48.220
<v Speaker 1>four,</v>
<v Speaker 1>five or 50 nodes.</v>

70
00:04:49.120 --> 00:04:53.950
<v Speaker 1>Different nodes and links have different</v>
<v Speaker 1>types and the nodes and links can have</v>

71
00:04:54.040 --> 00:04:57.730
<v Speaker 1>numbers attached to them and know your</v>
<v Speaker 1>link could have a weight indicating a</v>

72
00:04:57.731 --> 00:05:01.510
<v Speaker 1>probability or a confidence.</v>
<v Speaker 1>It could have a weight indicating how</v>

73
00:05:01.511 --> 00:05:06.300
<v Speaker 1>important it is to the system right now</v>
<v Speaker 1>or how important it is in the longterm,</v>

74
00:05:06.460 --> 00:05:11.460
<v Speaker 1>so it should be kept around and the</v>
<v Speaker 1>systems memory on this Adam space this</v>

75
00:05:12.780 --> 00:05:15.130
<v Speaker 1>way did labeled hypergraph.</v>

76
00:05:15.460 --> 00:05:20.460
<v Speaker 1>We can have a lot of different ai</v>
<v Speaker 1>processes working together</v>

77
00:05:20.620 --> 00:05:23.890
<v Speaker 1>cooperatively,</v>
<v Speaker 1>so the the atom space,</v>

78
00:05:24.130 --> 00:05:27.970
<v Speaker 1>the memory stores,</v>
<v Speaker 1>what we would call neural symbolic.</v>

79
00:05:28.390 --> 00:05:33.370
<v Speaker 1>That means we can represent nodes and</v>
<v Speaker 1>links that are like neurons in the</v>

80
00:05:33.371 --> 00:05:35.800
<v Speaker 1>brain,</v>
<v Speaker 1>which is fairly low level,</v>

81
00:05:36.010 --> 00:05:41.010
<v Speaker 1>but we can also represent nodes and</v>
<v Speaker 1>links that are higher level representing</v>

82
00:05:41.141 --> 00:05:46.141
<v Speaker 1>pieces of of symbolic logic expressions.</v>
<v Speaker 1>So we can do explicit logical reasoning,</v>

83
00:05:47.110 --> 00:05:50.770
<v Speaker 1>which is pretty abstract and low level</v>
<v Speaker 1>neural net stuff.</v>

84
00:05:51.070 --> 00:05:56.070
<v Speaker 1>In the same hypergraph the same items</v>
<v Speaker 1>space acting on this Adam space.</v>

85
00:05:56.930 --> 00:06:01.820
<v Speaker 1>We have deep neural networks for visual</v>
<v Speaker 1>and auditory perception.</v>

86
00:06:02.420 --> 00:06:06.710
<v Speaker 1>We have a probabilistic logic engine</v>
<v Speaker 1>which does abstract reasoning.</v>

87
00:06:07.370 --> 00:06:11.470
<v Speaker 1>We have an evolutionary learning</v>
<v Speaker 1>algorithm that uses genetic algorithm</v>

88
00:06:11.480 --> 00:06:16.480
<v Speaker 1>type methods to try to evolve radical</v>
<v Speaker 1>new new ideas and concepts and look for</v>

89
00:06:17.151 --> 00:06:22.151
<v Speaker 1>data patterns and we have a neural net</v>
<v Speaker 1>type dynamic that spreads activity and</v>

90
00:06:23.331 --> 00:06:25.790
<v Speaker 1>importance throughout the network.</v>

91
00:06:25.910 --> 00:06:29.100
<v Speaker 1>A few other algorithms,</v>
<v Speaker 1>a pattern mining algorithm that just</v>

92
00:06:29.510 --> 00:06:34.280
<v Speaker 1>scans through the whole admin space</v>
<v Speaker 1>looking for surprising stuff and the</v>

93
00:06:34.281 --> 00:06:39.281
<v Speaker 1>trick is all these different cognitive</v>
<v Speaker 1>algorithms have to work together</v>

94
00:06:40.640 --> 00:06:44.360
<v Speaker 1>cooperatively to help each other rather</v>
<v Speaker 1>than hurt each other.</v>

95
00:06:44.540 --> 00:06:49.460
<v Speaker 1>See the bottleneck in essentially every</v>
<v Speaker 1>ai approach ever taken,</v>

96
00:06:49.910 --> 00:06:52.160
<v Speaker 1>be it a neural net,</v>
<v Speaker 1>a logic engine,</v>

97
00:06:52.161 --> 00:06:56.180
<v Speaker 1>the genetic algorithm,</v>
<v Speaker 1>whatever the bottleneck in every ai</v>

98
00:06:56.181 --> 00:07:00.380
<v Speaker 1>approach ever taken has been what we</v>
<v Speaker 1>call common tutorial explosion.</v>

99
00:07:00.710 --> 00:07:03.920
<v Speaker 1>And what that means is you have a lot of</v>
<v Speaker 1>data items,</v>

100
00:07:03.921 --> 00:07:07.910
<v Speaker 1>you're a lot of perceptions coming into</v>
<v Speaker 1>your eye or you have a lot of possible</v>

101
00:07:07.911 --> 00:07:12.350
<v Speaker 1>moves on the chessboard or a lot of</v>
<v Speaker 1>possible ways to move the wheel of the</v>

102
00:07:12.351 --> 00:07:17.351
<v Speaker 1>car and there's so many combinations of</v>
<v Speaker 1>possible data items and possible things</v>

103
00:07:18.501 --> 00:07:21.920
<v Speaker 1>you could do.</v>
<v Speaker 1>Sifting through all those combinations</v>

104
00:07:22.550 --> 00:07:24.980
<v Speaker 1>becomes an exponential problem.</v>

105
00:07:25.040 --> 00:07:27.410
<v Speaker 1>I mean if,</v>
<v Speaker 1>if you have a thousand things,</v>

106
00:07:27.680 --> 00:07:31.730
<v Speaker 1>there's two to the 1020 a combined them</v>
<v Speaker 1>and that and that's the way to money.</v>

107
00:07:31.820 --> 00:07:36.820
<v Speaker 1>So how the sift through common tutorial</v>
<v Speaker 1>explosions is the core problem everyone</v>

108
00:07:37.341 --> 00:07:42.341
<v Speaker 1>has to deal with in a deep neural</v>
<v Speaker 1>network as currently pursued it solved</v>

109
00:07:43.251 --> 00:07:48.251
<v Speaker 1>by making the network have a very</v>
<v Speaker 1>specific structure which reflects the</v>

110
00:07:48.321 --> 00:07:51.140
<v Speaker 1>structure of visual and auditory</v>
<v Speaker 1>streams.</v>

111
00:07:51.440 --> 00:07:56.150
<v Speaker 1>And in a logic engine you don't have</v>
<v Speaker 1>that sort of luxury because a logic</v>

112
00:07:56.151 --> 00:07:57.770
<v Speaker 1>engine has to deal with anything.</v>
<v Speaker 1>Not,</v>

113
00:07:57.771 --> 00:08:02.771
<v Speaker 1>not just sensory data,</v>
<v Speaker 1>but what we do in open cog is we've</v>

114
00:08:03.111 --> 00:08:08.111
<v Speaker 1>worked out a system where each of the</v>
<v Speaker 1>cognitive processes can help the other</v>

115
00:08:08.451 --> 00:08:11.810
<v Speaker 1>one out when it,</v>
<v Speaker 1>when it gets stuck in some communist</v>

116
00:08:11.811 --> 00:08:15.500
<v Speaker 1>oriel explosion problems.</v>
<v Speaker 1>So if if a deep neural network turning</v>

117
00:08:15.501 --> 00:08:18.800
<v Speaker 1>the perceived things gets confused</v>
<v Speaker 1>because it's dark or it's looking at</v>

118
00:08:18.801 --> 00:08:22.640
<v Speaker 1>something it never saw before,</v>
<v Speaker 1>well maybe the reasoning engine can come</v>

119
00:08:22.641 --> 00:08:25.580
<v Speaker 1>in and do some inference to cut through</v>
<v Speaker 1>that confusion.</v>

120
00:08:25.940 --> 00:08:30.710
<v Speaker 1>If logical reasoning is getting confused</v>
<v Speaker 1>and doesn't know what step to take next</v>

121
00:08:30.711 --> 00:08:33.470
<v Speaker 1>cause there's just so many possibilities</v>
<v Speaker 1>are there.</v>

122
00:08:33.471 --> 00:08:38.180
<v Speaker 1>And not much information about the mall.</v>
<v Speaker 1>Maybe you fish into your sensory motor</v>

123
00:08:38.181 --> 00:08:42.440
<v Speaker 1>memory and you use deep learning to</v>
<v Speaker 1>visualize something you saw before.</v>

124
00:08:42.680 --> 00:08:47.230
<v Speaker 1>And that gives you a clue of how to pair</v>
<v Speaker 1>through the many possibilities that the,</v>

125
00:08:47.231 --> 00:08:52.231
<v Speaker 1>that the logic engine is seeing.</v>
<v Speaker 1>Now you can model this kind of cognitive</v>

126
00:08:53.421 --> 00:08:58.421
<v Speaker 1>synergy mathematically using a branch of</v>
<v Speaker 1>mathematics called category theory,</v>

127
00:08:59.220 --> 00:09:01.560
<v Speaker 1>which is something I've been working on</v>
<v Speaker 1>lately.</v>

128
00:09:02.100 --> 00:09:07.100
<v Speaker 1>But what's really interesting more so is</v>
<v Speaker 1>to build a system that manifests this</v>

129
00:09:08.671 --> 00:09:12.570
<v Speaker 1>and achieves general intelligence as a</v>
<v Speaker 1>result.</v>

130
00:09:12.571 --> 00:09:15.030
<v Speaker 1>And that's what we're doing in the open</v>
<v Speaker 1>card project.</v>

131
00:09:15.031 --> 00:09:17.790
<v Speaker 1>We're not there yet to general</v>
<v Speaker 1>intelligence,</v>

132
00:09:17.791 --> 00:09:22.791
<v Speaker 1>but we're getting there step by step.</v>
<v Speaker 1>We're using our open source open cog</v>

133
00:09:23.371 --> 00:09:27.480
<v Speaker 1>platform to control David Hanson's</v>
<v Speaker 1>beautiful,</v>

134
00:09:27.540 --> 00:09:31.620
<v Speaker 1>incredibly realistic humanoid robots</v>
<v Speaker 1>like this Sophia robot,</v>

135
00:09:31.650 --> 00:09:35.220
<v Speaker 1>which has gotten a lot of media</v>
<v Speaker 1>attention in the last year.</v>

136
00:09:35.580 --> 00:09:40.580
<v Speaker 1>We're using open card to analyze</v>
<v Speaker 1>biological data related to the genetics</v>

137
00:09:40.741 --> 00:09:42.810
<v Speaker 1>of,</v>
<v Speaker 1>of longevity.</v>

138
00:09:42.811 --> 00:09:46.680
<v Speaker 1>And we're doing a host of other</v>
<v Speaker 1>consulting projects using this.</v>

139
00:09:46.681 --> 00:09:49.770
<v Speaker 1>So we're,</v>
<v Speaker 1>we're proceeding on an r and d track and</v>

140
00:09:49.771 --> 00:09:52.380
<v Speaker 1>an application track at at the same</v>
<v Speaker 1>time.</v>

141
00:09:52.800 --> 00:09:57.800
<v Speaker 1>But our end goal with the system is to</v>
<v Speaker 1>use cognitive synergy on our neural</v>

142
00:09:59.341 --> 00:10:04.341
<v Speaker 1>symbolic knowledge store to achieve</v>
<v Speaker 1>initially human level Ai.</v>

143
00:10:04.771 --> 00:10:09.771
<v Speaker 1>But that's just nearly stage goal and</v>
<v Speaker 1>then ai much beyond the human level.</v>

144
00:10:10.590 --> 00:10:15.150
<v Speaker 1>And that is another advantage of taking</v>
<v Speaker 1>an approach that doesn't adhere</v>

145
00:10:15.151 --> 00:10:19.980
<v Speaker 1>slavishly to the human brain.</v>
<v Speaker 1>The brain is pretty good at recognizing</v>

146
00:10:19.981 --> 00:10:24.600
<v Speaker 1>faces because millions of years of</v>
<v Speaker 1>evolution when into that part of the</v>

147
00:10:24.601 --> 00:10:27.870
<v Speaker 1>brain.</v>
<v Speaker 1>But for doing science or math or logical</v>

148
00:10:27.871 --> 00:10:29.610
<v Speaker 1>reasoning,</v>
<v Speaker 1>your strategic planning,</v>

149
00:10:29.970 --> 00:10:33.420
<v Speaker 1>we're pretty bad.</v>
<v Speaker 1>And these are things that we started</v>

150
00:10:33.421 --> 00:10:38.421
<v Speaker 1>doing only recently in evolutionary time</v>
<v Speaker 1>as a result of of modern culture.</v>

151
00:10:39.450 --> 00:10:44.450
<v Speaker 1>So I think actually opened cognitive,</v>
<v Speaker 1>other AI systems have potential to be</v>

152
00:10:45.150 --> 00:10:49.320
<v Speaker 1>far better than,</v>
<v Speaker 1>than human beings at the sort of logical</v>

153
00:10:49.321 --> 00:10:53.700
<v Speaker 1>and strategic side of things.</v>
<v Speaker 1>And I think that's quite important</v>

154
00:10:53.701 --> 00:10:58.701
<v Speaker 1>because if you take a human being and</v>
<v Speaker 1>upgrade them to like 10,000 Iq,</v>

155
00:10:59.440 --> 00:11:03.360
<v Speaker 1>the the,</v>
<v Speaker 1>the outcome might not be what you want</v>

156
00:11:03.361 --> 00:11:06.150
<v Speaker 1>because you,</v>
<v Speaker 1>you've got a motivational system and an</v>

157
00:11:06.151 --> 00:11:11.151
<v Speaker 1>emotional system that basically evolved</v>
<v Speaker 1>in prehuman animals.</v>

158
00:11:11.680 --> 00:11:16.680
<v Speaker 1>Where as if you architect a system where</v>
<v Speaker 1>rationality and and empathy play a</v>

159
00:11:17.551 --> 00:11:22.551
<v Speaker 1>deeper role in the architecture,</v>
<v Speaker 1>then as its intelligence ramps way up,</v>

160
00:11:22.650 --> 00:11:25.260
<v Speaker 1>we may find the more beneficial outcome.</v>

