1
00:00:01,910 --> 00:00:05,840
Right now we would like to invite our
guest Avanto professor John seely Brown,

2
00:00:06,080 --> 00:00:10,010
who was conferred and honorary doctor of
information systems degree in

3
00:00:10,011 --> 00:00:13,070
recognition of his outstanding record as
a scientist,

4
00:00:13,100 --> 00:00:16,730
scholar and innovator on the stage to
say a few words,

5
00:00:16,940 --> 00:00:18,110
Professor Brown,
please.

6
00:00:31,900 --> 00:00:32,733
Good afternoon.

7
00:00:36,850 --> 00:00:41,490
Soon as you've already seen,
you can learn a tremendous amount,

8
00:00:42,480 --> 00:00:45,900
but the ability to improvise is a very
good skill.

9
00:00:45,901 --> 00:00:48,090
If you want to be a dean.
Steve

10
00:00:50,040 --> 00:00:55,040
felt for you up here.
I had a brief conversation with Steve

11
00:00:55,531 --> 00:01:00,531
coming over and you heard this morning,
all these magnificent things that I

12
00:01:01,321 --> 00:01:05,080
supposedly have done a while.
I got this wonderful award for it,

13
00:01:06,000 --> 00:01:11,000
but he was surprised when I kind of came
up in a conversation.

14
00:01:12,060 --> 00:01:17,060
I cow did such a hardcore geek as I was
turning into such a softy into such a

15
00:01:21,571 --> 00:01:24,480
person that believes in the power of
social science.

16
00:01:25,690 --> 00:01:26,550
And I said,
Steve,

17
00:01:26,551 --> 00:01:28,260
you know,
it's actually quite simple.

18
00:01:29,010 --> 00:01:33,750
You didn't talk about my first job.
My first job that happened to have been

19
00:01:33,780 --> 00:01:37,830
the youngest licensed bookie in New York
state.

20
00:01:39,480 --> 00:01:43,830
I got that job 18 years old because I
was a geek.

21
00:01:44,160 --> 00:01:48,060
I could compute all kinds of amazing
things in my head with blinding speed,

22
00:01:48,870 --> 00:01:53,730
but within the first day of my job,
I discovered being able to be able to

23
00:01:53,731 --> 00:01:56,520
compute amazingly complex things in my
head,

24
00:01:56,580 --> 00:02:01,290
didn't really matter what really
mattered was being able to read the

25
00:02:01,291 --> 00:02:06,270
people approaching me to make book,
because if you could read them,

26
00:02:06,540 --> 00:02:09,870
you suddenly realize which ones are
going to teach you in which ones

27
00:02:09,871 --> 00:02:10,704
weren't.

28
00:02:10,950 --> 00:02:15,000
And was kind of the first moment that I
began to realize that maybe it was more

29
00:02:15,001 --> 00:02:19,950
important to read context that just be
able to compute the content.

30
00:02:20,270 --> 00:02:22,530
Um,
and that's where I kind of Steve started

31
00:02:22,531 --> 00:02:25,740
down this path,
but that's not why I'm here today.

32
00:02:26,940 --> 00:02:29,040
Today.
We live in,

33
00:02:29,100 --> 00:02:33,780
in some ways a terrifying world,
but also an exciting world.

34
00:02:33,810 --> 00:02:35,610
We've already heard left,
right,

35
00:02:35,611 --> 00:02:39,180
and sideways the amazing kinds of
disruptions that are happening.

36
00:02:40,200 --> 00:02:44,640
But we,
we here in this room have the unusual

37
00:02:44,641 --> 00:02:49,140
property that yes,
we are creating the tools that lead to

38
00:02:49,141 --> 00:02:53,640
radical disruption around the world.
But simultaneously,

39
00:02:54,060 --> 00:02:59,060
we're creating the tools that let us to
build new ways to learn new ways to

40
00:02:59,741 --> 00:03:01,990
work,
new ways to innovate,

41
00:03:02,260 --> 00:03:06,220
new ways to create meeting.
So in some sense we're causing the

42
00:03:06,221 --> 00:03:09,520
disruptions,
but we're also creating the tools in

43
00:03:09,521 --> 00:03:14,521
which to reinvent the industrial world,
the corporate world,

44
00:03:15,130 --> 00:03:18,670
the learning world,
the world of actually making meaning

45
00:03:18,671 --> 00:03:20,080
left,
right and sideways.

46
00:03:20,920 --> 00:03:23,110
So of his call.
This the big shift.

47
00:03:23,620 --> 00:03:27,490
We call it the big shift because perhaps
for the first time in the history of

48
00:03:27,491 --> 00:03:30,370
civilization,
we're moving from a world you might call

49
00:03:30,371 --> 00:03:35,371
an s curve world where you have a moment
of radical punctuation with 50,

50
00:03:35,651 --> 00:03:38,800
60,
70 years or more or less stability in

51
00:03:38,801 --> 00:03:41,770
terms of the infrastructures that
defining how we work,

52
00:03:41,771 --> 00:03:42,640
learn,
interact,

53
00:03:42,641 --> 00:03:43,990
socialize,
etc. Etc.

54
00:03:44,920 --> 00:03:47,260
That has bEen a history of the last 300
years.

55
00:03:47,261 --> 00:03:49,210
Don't worry,
I won't bore you with taking you through

56
00:03:49,211 --> 00:03:52,840
300 years,
but we now live and what we all in this

57
00:03:52,841 --> 00:03:57,841
room would call the exponential world
where basically we no longer have these

58
00:03:58,720 --> 00:04:03,070
long periods of stability with which to
reinvent how we work,

59
00:04:03,280 --> 00:04:08,280
how we learn and so on.
But we're entering as a world in which

60
00:04:08,591 --> 00:04:13,591
in fact we can't even tell our students
what they should know five years from

61
00:04:14,081 --> 00:04:19,081
now because in fact,
we're moving into a world in which the

62
00:04:19,091 --> 00:04:24,091
average half life of a skill is moving
from about 30 years to about five years.

63
00:04:26,890 --> 00:04:30,520
That means that we're going to have to
do most of our learning after we leave

64
00:04:30,521 --> 00:04:32,830
here today,
and we're going to have to do most of

65
00:04:32,831 --> 00:04:36,460
our learning in the workplace itself in
one form or another.

66
00:04:37,690 --> 00:04:40,870
In fact,
those of us that design corporate

67
00:04:40,871 --> 00:04:43,120
architectures,
institutional architectures,

68
00:04:43,121 --> 00:04:47,590
have to step back and realize that for
the last hundred years,

69
00:04:48,700 --> 00:04:52,990
the west became powerful.
The east became powerful because we

70
00:04:52,991 --> 00:04:57,991
could actually build institutions that
understood how to leverage scalable

71
00:04:58,510 --> 00:05:02,500
efficiency.
We knew how to scale things,

72
00:05:02,890 --> 00:05:06,400
but to make things scalable,
they had to become predictable.

73
00:05:08,110 --> 00:05:10,600
Predictability was the coin of the
realm,

74
00:05:11,410 --> 00:05:15,970
and virtually every single corporate
strategy I've ever looked at found new

75
00:05:15,971 --> 00:05:18,910
ways to leverage.
If you wish,

76
00:05:18,970 --> 00:05:23,410
scalable efficiency.
But here's the dirty secret.

77
00:05:24,550 --> 00:05:29,550
Those very things that made her so
successful for the last 50 or 60 years

78
00:05:30,880 --> 00:05:33,670
are the very things that stand in our
way now

79
00:05:35,170 --> 00:05:39,280
because they no longer work because we
don't have predictability.

80
00:05:39,550 --> 00:05:44,200
We can't predict customer needs.
We can't preDict what object to build in

81
00:05:44,201 --> 00:05:47,260
massive quantities,
store up in warehouses and distributed

82
00:05:47,261 --> 00:05:50,710
through superior transportation
infrastructures and so on and so forth.

83
00:05:51,820 --> 00:05:56,170
So some of us have been looking at the
issue of how do we actually move from

84
00:05:56,200 --> 00:06:01,200
basically an underlying strategic basis
of all our institutions of scalable

85
00:06:01,761 --> 00:06:05,720
efficiency to the notion of scalable
learning.

86
00:06:07,040 --> 00:06:11,210
How do we actually think about
reinventing corporations,

87
00:06:11,510 --> 00:06:13,640
public institutions and so on and so
forth,

88
00:06:13,850 --> 00:06:18,710
whose job it is to make sure that those
of us that work in those institutions

89
00:06:19,040 --> 00:06:23,780
learn faster than almost anywhere else.
For example,

90
00:06:24,560 --> 00:06:27,290
why kids today go to google?
Eat by the way,

91
00:06:27,291 --> 00:06:30,440
is not because of money.
Believe it or not,

92
00:06:31,280 --> 00:06:35,060
it's because at google,
in the bay area where I come from,

93
00:06:36,040 --> 00:06:38,600
you will learn faster.
There.

94
00:06:38,660 --> 00:06:43,660
you learn newer technologies there in
virtually any other place in the country

95
00:06:44,390 --> 00:06:45,980
and probably the world.

96
00:06:47,240 --> 00:06:51,260
In fact,
there's a very Interesting book out

97
00:06:51,800 --> 00:06:56,800
called the race against the machine
written by two economists from mit that

98
00:06:57,261 --> 00:07:02,261
are trying to explain why in fact maybe
they're going to be so few jobs are

99
00:07:02,571 --> 00:07:05,290
fewer jobs in the new normal protocol
call,

100
00:07:05,300 --> 00:07:06,350
so to,
so to speak,

101
00:07:06,760 --> 00:07:10,370
um,
because basically most of our jobs as

102
00:07:10,371 --> 00:07:15,371
they claim can now be done by machines.
that probably is somewhat true,

103
00:07:17,810 --> 00:07:22,810
but some of us are reframing the race
against the machine to be the race with

104
00:07:26,210 --> 00:07:31,210
the machine.
How do we actually think about how do we

105
00:07:31,761 --> 00:07:36,761
in the machine work together better than
either one by ourselves,

106
00:07:37,131 --> 00:07:39,530
by themselves,
and in fact,

107
00:07:39,531 --> 00:07:43,820
that causes us to radically we frame
what do we think about in terms of

108
00:07:43,850 --> 00:07:48,850
augmented intelligence,
augmented capabilities to innovate and

109
00:07:48,921 --> 00:07:51,620
so on and so forth.
In fact,

110
00:07:52,850 --> 00:07:57,140
if you play chess,
you may be surprised to know that of

111
00:07:57,141 --> 00:07:58,460
course,
a few years ago,

112
00:07:58,461 --> 00:08:03,461
ibm built this mega machine that
actually ended up building beating the

113
00:08:03,561 --> 00:08:08,561
world champion.
But here's what you might not know.

114
00:08:09,940 --> 00:08:14,940
You take the world's best chess players.
You take the world's best mega machines,

115
00:08:17,290 --> 00:08:22,290
and guess what?
both can be easily beat by a moderately

116
00:08:24,191 --> 00:08:29,191
good chest team playing with a
moderately good machine.

117
00:08:31,150 --> 00:08:36,150
Well these kids have figured out is how
to use the machine to augment what they

118
00:08:36,311 --> 00:08:39,430
do so well.
The pair of those things working

119
00:08:39,431 --> 00:08:44,431
together,
man in machine now beats the hell out of

120
00:08:44,561 --> 00:08:49,561
the world's best chess machine and the
world's best chess players.

121
00:08:51,310 --> 00:08:56,310
So I want to suggest that we go forward.
We have to be very creative in how we

122
00:08:56,371 --> 00:09:00,630
think better about augmenting human
intelligence and how we can work more

123
00:09:00,631 --> 00:09:05,160
effectively with machines.
But I want to suggest equally

124
00:09:05,161 --> 00:09:09,510
challenging because some of you here are
also going to be architecting

125
00:09:09,511 --> 00:09:13,800
organizations of the future.
We ought to be thinking about how do we

126
00:09:14,190 --> 00:09:19,190
reinvent institutional architectures to
actually lead to scalable learning in

127
00:09:21,931 --> 00:09:26,931
the workplace and in our governments and
I think that is a new type of design

128
00:09:27,901 --> 00:09:32,901
challenge and we add to that what we're
now capable of doing with cloud

129
00:09:33,871 --> 00:09:38,190
computing
and now how we can actually rethink

130
00:09:38,280 --> 00:09:43,280
learning on demand as well so that
anytime we get stuck we can pull

131
00:09:44,581 --> 00:09:49,581
information tours,
but that pulling content that's not

132
00:09:50,341 --> 00:09:51,450
pulling context.

133
00:09:51,750 --> 00:09:54,180
That's not pointing dispositions and so
on,

134
00:09:54,810 --> 00:09:57,930
so we gotta kind of be careful to keep
in mind the difference between

135
00:09:57,931 --> 00:10:01,950
character,
difference between dispositions and the

136
00:10:01,951 --> 00:10:06,570
difference between knowledge.
I'm fond of using the term,

137
00:10:06,571 --> 00:10:09,960
the entrepreneurial learner,
not because I'm concerned about how to

138
00:10:09,961 --> 00:10:14,160
train entrepreneurs per se,
but I'm very interested in the

139
00:10:14,220 --> 00:10:19,140
disposition that says,
every moment of the day I personally

140
00:10:19,560 --> 00:10:24,560
have a chance to learn something new and
if you can actually do something,

141
00:10:25,050 --> 00:10:30,050
put yourself out in the edge,
often get stuck and then what you do.

142
00:10:30,330 --> 00:10:34,890
You pull information.
We're moving from an education based on

143
00:10:34,891 --> 00:10:39,891
push to learning on demand pull,
but now I pull the information into a

144
00:10:40,531 --> 00:10:43,530
context,
into a situation that's personally

145
00:10:43,531 --> 00:10:47,610
meaningful to me because it stuck out.
I'm trying to go to use that information

146
00:10:47,611 --> 00:10:51,990
as fast as can be,
a to see if I can get myself unstuck.

147
00:10:52,500 --> 00:10:57,500
So that's how suddenly all of a sudden
learning becomes so real and I can make

148
00:10:58,951 --> 00:11:01,650
it so personal that whatever you do this
way,

149
00:11:01,830 --> 00:11:06,830
you basically never forget.
So I do want to suggest that a couple of

150
00:11:07,351 --> 00:11:09,660
things we should be thinking about as we
leave today.

151
00:11:11,400 --> 00:11:15,930
I think one is to make sure we ourselves
don't get stuck in ruts.

152
00:11:17,610 --> 00:11:22,610
My single biggest advice to most
corporate ceos is what are you doing to

153
00:11:23,461 --> 00:11:28,461
make sure you aren't stuck in a rut?
And if this game is changing every five

154
00:11:28,621 --> 00:11:30,960
years as opposed to every 35 or 40
years,

155
00:11:31,740 --> 00:11:34,650
that means the things that made us
successful yesterday,

156
00:11:35,220 --> 00:11:37,650
maybe exactly the things that blind us
today.

157
00:11:38,520 --> 00:11:41,490
So how do we keep from being stuck in
ruts?

158
00:11:42,520 --> 00:11:46,140
I'm going to suggest the second thing as
we move in increasingly from thinking

159
00:11:46,141 --> 00:11:51,141
about machines is we can take apart like
clocks to we now living in a world where

160
00:11:52,531 --> 00:11:54,010
everything is interconnected.

161
00:11:54,280 --> 00:11:57,490
The smallest moves can now propagate
around the world.

162
00:11:57,630 --> 00:12:00,760
Um,
we may have to shift from thinking about

163
00:12:00,761 --> 00:12:05,761
machines and mechanisms to thinking
about biology as a fundamental metaphor.

164
00:12:06,730 --> 00:12:11,560
How do we think about emerging systems?
How do we begin to understand sometimes

165
00:12:11,800 --> 00:12:15,070
certain moves seem so positive on the
surface,

166
00:12:15,250 --> 00:12:18,310
but ended up having all kinds of
secondary consequences,

167
00:12:18,580 --> 00:12:23,580
which is always a way that many complex
ecological systems actually work,

168
00:12:24,820 --> 00:12:28,300
so I think we're actually going to be
moving if you wish,

169
00:12:28,660 --> 00:12:32,800
as coral poppers,
head on the world of clocks,

170
00:12:32,890 --> 00:12:36,720
mechanical systems that can be
deconstructed and tinkered with here,

171
00:12:36,920 --> 00:12:41,500
buy gear to a world of clouds,
not as a pun,

172
00:12:41,860 --> 00:12:44,710
not as cloud computing,
or they could talk forever about cloud

173
00:12:44,711 --> 00:12:46,810
computing,
but as clowns,

174
00:12:46,811 --> 00:12:49,890
as these things in the sky that are
emergent,

175
00:12:50,560 --> 00:12:55,180
how do we start designing emerging
systems because clouds are complex

176
00:12:55,181 --> 00:12:57,510
adaptive systems and as soon as you
touch it,

177
00:12:57,550 --> 00:13:01,840
something changes.
Those are the challenges we face

178
00:13:01,900 --> 00:13:05,800
tomorrow.
Good luck and helping us all figure out

179
00:13:06,040 --> 00:13:08,080
how to live in the new world.
Thank you.

180
00:13:10,590 --> 00:13:13,260
Thanks.

