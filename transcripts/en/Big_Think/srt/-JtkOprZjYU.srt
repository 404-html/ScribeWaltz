1
00:00:05,440 --> 00:00:07,580
So one of the things that worries me,
the noticed,

2
00:00:07,910 --> 00:00:10,860
uh,
in the technology world today is the

3
00:00:10,861 --> 00:00:15,120
degree to which the external world has
view technology with more and more

4
00:00:15,121 --> 00:00:18,000
cynicism and the degree to which,
uh,

5
00:00:18,180 --> 00:00:19,740
you know,
there's a little bit of a backlash

6
00:00:19,741 --> 00:00:22,800
starting.
And I think that there's a few drivers

7
00:00:22,801 --> 00:00:25,110
for that.
I think the recent elections is sort of

8
00:00:25,111 --> 00:00:27,150
one example where people feel that they
were manipulated,

9
00:00:27,390 --> 00:00:29,550
I should say,
by third parties of using technology.

10
00:00:29,970 --> 00:00:32,940
Um,
and I think separate from that,

11
00:00:32,970 --> 00:00:35,340
there's also just the sort of media
waves where,

12
00:00:35,341 --> 00:00:36,180
you know,
uh,

13
00:00:36,220 --> 00:00:39,300
media tends to go in cycles where the
press would build something up and then

14
00:00:39,301 --> 00:00:41,160
tear it down and then build something up
and tear it down.

15
00:00:41,490 --> 00:00:45,300
And I think technology was really built
up in the media for a 20 year period or

16
00:00:45,301 --> 00:00:48,030
so.
And now it's sort of a time of reckoning

17
00:00:48,060 --> 00:00:49,710
and to some extent,
um,

18
00:00:49,730 --> 00:00:54,330
I think that's very unfortunate because
I believe that optimism is a reflexive

19
00:00:54,331 --> 00:00:56,880
asset and sort of the George Soros view
of the world where,

20
00:00:57,120 --> 00:00:58,170
you know,
something that,

21
00:00:58,200 --> 00:00:58,950
uh,
people,

22
00:00:58,950 --> 00:01:00,810
uh,
give value to gains value.

23
00:01:00,940 --> 00:01:02,580
Uh,
by that belief in the value of that

24
00:01:02,581 --> 00:01:04,140
thing.
And,

25
00:01:04,170 --> 00:01:06,120
uh,
if you actually look at the major

26
00:01:06,121 --> 00:01:09,690
changes that have happened in the world
is because people have been extremely

27
00:01:09,691 --> 00:01:11,930
optimistic in ways that some folks
thought were,

28
00:01:11,990 --> 00:01:13,620
was irrational.
Um,

29
00:01:13,800 --> 00:01:16,530
but that optimism allowed them to
actually accomplish that giant goal.

30
00:01:16,531 --> 00:01:17,364
I mean,
think of,

31
00:01:17,490 --> 00:01:19,310
uh,
putting somebody on the moon and what we

32
00:01:19,311 --> 00:01:21,570
were able to accomplish in the sixties
or,

33
00:01:21,600 --> 00:01:22,231
uh,
you know,

34
00:01:22,231 --> 00:01:24,660
think about a variety of other examples
like that.

35
00:01:24,661 --> 00:01:27,690
The Manhattan project or you know,
major breakthroughs of all sort of come

36
00:01:27,691 --> 00:01:32,220
through and enormous sense of optimism
and we can do this a manifest destiny

37
00:01:32,221 --> 00:01:33,510
and Sorta,
you know,

38
00:01:33,511 --> 00:01:36,630
the development of the United States as
a country is a good example of that on

39
00:01:36,631 --> 00:01:38,250
the sort of country and governance
level.

40
00:01:38,760 --> 00:01:41,220
Um,
and so one thing that I've seen more and

41
00:01:41,221 --> 00:01:46,221
more increasingly is a increase in
cynicism and people being made fun of

42
00:01:46,920 --> 00:01:49,080
for saying they want to change the world
when they're genuine about it.

43
00:01:49,350 --> 00:01:52,470
And I think that's a very big negative.
And so one of my,

44
00:01:52,500 --> 00:01:55,020
one of the things I've been thinking a
lot about recently is how can you

45
00:01:55,021 --> 00:01:58,470
actually increase the seidel optimism?
What are the mechanisms by which people

46
00:01:58,471 --> 00:02:01,830
can become more enthusiastic about their
future and more enthusiastic about

47
00:02:01,831 --> 00:02:03,810
technology?
Because if you look at the changes that

48
00:02:03,811 --> 00:02:06,270
technology has wrought over the last 20,
30 years,

49
00:02:06,570 --> 00:02:11,370
it literally has lifted tens or hundreds
of millions of people out of poverty.

50
00:02:11,371 --> 00:02:14,640
It has created access to global markets
that has created access to global

51
00:02:14,641 --> 00:02:15,990
information.
Uh,

52
00:02:16,020 --> 00:02:17,490
you know,
everybody's walking around with

53
00:02:17,491 --> 00:02:20,700
literally a super computer in their
pocket that gives them the access to the

54
00:02:20,701 --> 00:02:23,050
sum of all of humanity's knowledge,
uh,

55
00:02:23,070 --> 00:02:25,170
with maybe the exception of scientific
journals which are still blocked.

56
00:02:25,560 --> 00:02:27,080
So I do think that,
um,

57
00:02:27,210 --> 00:02:29,490
people should be incredibly optimistic
about the future.

58
00:02:29,850 --> 00:02:32,550
And one thing I wonder about is how can
you help spread that optimism?

59
00:02:32,550 --> 00:02:34,980
Because I think if people believe they
can do something,

60
00:02:34,981 --> 00:02:37,230
they often achieve things that they
never thought was possible.

61
00:02:37,920 --> 00:02:41,970
So a lot of people have recently had a
lot of very cogent concerns around the

62
00:02:41,971 --> 00:02:44,010
rise of misinformation and
disinformation,

63
00:02:44,730 --> 00:02:46,920
uh,
on social media platforms and how that

64
00:02:46,921 --> 00:02:50,190
impacted our last election.
And you know,

65
00:02:50,191 --> 00:02:51,690
I think those are very legitimate
concerns.

66
00:02:51,691 --> 00:02:54,570
And I think some of the platforms have
made pretty major mistakes in terms of

67
00:02:54,571 --> 00:02:55,830
how they've approached some of those
things.

68
00:02:56,340 --> 00:02:58,050
Um,
it's interesting though because if you

69
00:02:58,051 --> 00:03:00,460
look at it over the arc of history,
uh,

70
00:03:00,520 --> 00:03:03,250
this is not a new story.
Every time that there's a new

71
00:03:03,490 --> 00:03:05,320
technology,
particularly around media,

72
00:03:05,640 --> 00:03:07,300
uh,
there's a set of outcries around how

73
00:03:07,301 --> 00:03:11,740
that media is corrupting culture or how
it's destroying certain aspects of our

74
00:03:11,741 --> 00:03:13,300
life.
And in some cases those are real

75
00:03:13,301 --> 00:03:14,710
concerns.
Um,

76
00:03:14,740 --> 00:03:17,950
there's a great book from Tom standage
about the early telegraph in the 18

77
00:03:17,951 --> 00:03:19,450
hundreds called the Victorian Internet.

78
00:03:19,810 --> 00:03:23,290
And he basically makes the argument that
a lot of the behavior that exists online

79
00:03:23,291 --> 00:03:26,500
today was being done by telegraph
operators in the 18 hundreds because

80
00:03:26,501 --> 00:03:30,010
they were just sitting on these lines
talking with each other over Morse code.

81
00:03:30,280 --> 00:03:32,350
And they would gossip and they would
trade recipes.

82
00:03:32,351 --> 00:03:35,470
And it would date a,
but also it was a way for news to spread

83
00:03:35,471 --> 00:03:37,460
quickly.
And a lot of people argued that it was a

84
00:03:37,461 --> 00:03:39,760
downfall of a variety of things.
It was,

85
00:03:39,761 --> 00:03:41,950
it could be the downfall of markets
cause suddenly markets were more

86
00:03:41,951 --> 00:03:45,100
efficient or it could impact religion or
other things.

87
00:03:45,490 --> 00:03:47,950
And then we had radio actually before
radio,

88
00:03:47,951 --> 00:03:51,250
we had newspapers in the early 19
hundreds and there was the wave of

89
00:03:51,251 --> 00:03:53,890
yellow journalism.
There was a Spanish American war that

90
00:03:53,891 --> 00:03:56,560
was caused by,
by a new form of media.

91
00:03:56,950 --> 00:04:00,880
And then we had radio and radio was
corrupting the youth by spreading rock

92
00:04:00,881 --> 00:04:03,610
and roll and sin and you know,
all sorts of bad things.

93
00:04:04,030 --> 00:04:06,130
And then we had TV,
which was turning everybody into

94
00:04:06,131 --> 00:04:08,170
vegetables.
And then we had,

95
00:04:08,200 --> 00:04:09,430
um,
video games,

96
00:04:09,431 --> 00:04:11,290
which was turning all of our children
into killers.

97
00:04:11,770 --> 00:04:14,260
Uh,
and now we have social media as the next

98
00:04:14,410 --> 00:04:17,560
new media platform.
And instagram is destroying our youth.

99
00:04:18,100 --> 00:04:20,110
And I think that fact about instagram is
true,

100
00:04:20,470 --> 00:04:21,880
but I'm joking about that.
But,

101
00:04:21,910 --> 00:04:24,370
um,
and the broader context,

102
00:04:24,371 --> 00:04:27,790
if you think about it,
every time we have a new form of media,

103
00:04:28,180 --> 00:04:31,450
we make the argument that that form of
media is the thing that's going to

104
00:04:31,451 --> 00:04:33,670
destroy our society.
That's corrupting our politics,

105
00:04:33,671 --> 00:04:36,790
is corrupting our children.
This destroying our ability to think for

106
00:04:36,791 --> 00:04:39,610
ourselves and every time society has
turned out okay.

107
00:04:39,850 --> 00:04:44,320
Now that doesn't mean that social media
platform shouldn't be reacting or

108
00:04:44,321 --> 00:04:45,940
shouldn't be addressing these issues.
I'm just saying,

109
00:04:45,941 --> 00:04:48,400
if you look at it through the larger
lens of history,

110
00:04:48,520 --> 00:04:49,600
this is not a new story.

