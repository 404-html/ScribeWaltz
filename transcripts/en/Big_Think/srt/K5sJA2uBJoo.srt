1
00:00:00,090 --> 00:00:04,020
I see no obstacle to computers
eventually,

2
00:00:04,320 --> 00:00:07,140
uh,
becoming conscious in some sense.

3
00:00:07,920 --> 00:00:10,950
That'll be a fascinating experience.
Um,

4
00:00:10,980 --> 00:00:13,980
as a physicist,
I want to know if those computers do

5
00:00:13,981 --> 00:00:18,870
physics the same way humans do physics
and there's no doubt that those machines

6
00:00:18,871 --> 00:00:21,390
will be able to,
um,

7
00:00:23,130 --> 00:00:26,400
evolve computationally potentially at a
faster rate than humans.

8
00:00:26,580 --> 00:00:28,800
And in the long term,
the,

9
00:00:28,890 --> 00:00:29,723
the,
um,

10
00:00:30,180 --> 00:00:35,100
ultimate highest forms of consciousness
on the planet may not be purely

11
00:00:35,101 --> 00:00:38,550
biological,
but that's not necessarily a bad thing.

12
00:00:39,120 --> 00:00:44,120
We always present computers as if they
don't have capabilities of empathy or a

13
00:00:45,550 --> 00:00:48,210
emotion,
but I would think that any intelligent

14
00:00:48,211 --> 00:00:52,500
machine would ultimately have experience
that it's a learning machine and

15
00:00:52,501 --> 00:00:54,510
ultimately it would learn from its
experience like a,

16
00:00:54,720 --> 00:00:58,080
like a biological conscious being.
And therefore it's hard for me to

17
00:00:58,081 --> 00:01:03,081
believe that it would not be able to
have many of the characteristics that we

18
00:01:03,601 --> 00:01:07,740
now associate with being human.
Elon Musk and others who have expressed

19
00:01:07,741 --> 00:01:12,060
concern and Stephen Hawking are friends
of mine and I understand their potential

20
00:01:12,061 --> 00:01:15,750
concerns,
but I'm frankly not as concerned about

21
00:01:15,751 --> 00:01:17,640
ai in the near term,
at the very least,

22
00:01:17,641 --> 00:01:20,250
as many many of my friends and
colleagues are.

23
00:01:20,420 --> 00:01:22,440
It's far less powerful than people
imagined.

24
00:01:22,441 --> 00:01:25,140
I mean,
you try to get a robot to fold laundry

25
00:01:25,141 --> 00:01:29,160
and I've just been told you can't even
get full robot to fold laundry at.

26
00:01:29,161 --> 00:01:31,140
Someone just wrote me.
They were surprised when I said an

27
00:01:31,141 --> 00:01:34,380
elevator is an old example of the fact
that when you get an elevator,

28
00:01:34,381 --> 00:01:36,750
you're,
it's a primitive form of a computer and

29
00:01:36,751 --> 00:01:41,070
you're and you're giving up control of
the of the fact that it's going to take

30
00:01:41,071 --> 00:01:43,200
you where you want to go.
Cars are the same thing.

31
00:01:43,710 --> 00:01:47,760
Machines are useful because they're
tools that help us do we want to do,

32
00:01:48,270 --> 00:01:51,630
and I think computation machines are
exempt,

33
00:01:51,660 --> 00:01:56,660
are good examples of that.
One has to be very careful in creating

34
00:01:56,761 --> 00:02:00,330
machines to not assume they're more
capable than they are.

35
00:02:01,410 --> 00:02:04,050
That's true in cars.
That's true in vehicles that we make.

36
00:02:04,051 --> 00:02:06,390
That's true in weapons.
We create that's true in defensive

37
00:02:06,391 --> 00:02:11,391
mechanisms we create and so to me,
the dangers of Ai,

38
00:02:11,880 --> 00:02:16,410
what are mostly due to the fact that
people may assume the devices they

39
00:02:16,411 --> 00:02:19,980
create are more capable than they are
and don't need more control and

40
00:02:19,981 --> 00:02:22,590
monitoring.
I guess I find the opportunities to be

41
00:02:22,591 --> 00:02:26,100
far more exciting than the dangers.
The unknown is always dangerous,

42
00:02:26,520 --> 00:02:27,353
but

43
00:02:29,700 --> 00:02:34,700
ultimately machines and computational
machines are

44
00:02:37,560 --> 00:02:42,560
improving our lives in many ways.
We of course have to realize that the

45
00:02:43,051 --> 00:02:48,051
rate at which machines are,
are evolving in capability may far

46
00:02:48,901 --> 00:02:51,630
exceed the rate at which society is able
to deal with them.

47
00:02:51,840 --> 00:02:54,810
The fact that teenagers aren't talking
to each other,

48
00:02:54,990 --> 00:02:57,450
but always looking at their phones,
not just teenagers.

49
00:02:57,451 --> 00:03:01,150
I was just in a restaurant here,
New York this afternoon and half the

50
00:03:01,151 --> 00:03:02,920
people were not talking to people they
were with,

51
00:03:03,130 --> 00:03:07,160
but we're staring at their phones.
While that may be not a good thing for

52
00:03:07,180 --> 00:03:10,630
societal interaction and people may have
to come to terms with that,

53
00:03:11,260 --> 00:03:13,720
but I don't think people view their
phones as a danger.

54
00:03:14,110 --> 00:03:16,510
They view their phones as a tool that in
many ways,

55
00:03:16,870 --> 00:03:19,660
um,
allow them to do what they would

56
00:03:19,870 --> 00:03:21,490
otherwise do more effectively.

