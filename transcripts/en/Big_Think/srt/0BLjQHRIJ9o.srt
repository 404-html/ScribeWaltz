1
00:00:04,170 --> 00:00:05,003
I sort of interesting fact is that while
today programming is viewed as the 

2
00:00:09,930 --> 00:00:10,763
extremely male dominated field,
it was totally the opposite at the dawn 

3
00:00:14,911 --> 00:00:16,720
of computing.
All programmers of uh,

4
00:00:16,940 --> 00:00:20,010
uh,
from the very beginning where women had,

5
00:00:20,011 --> 00:00:22,290
and it was because this job was seen as 
being beneath men.

6
00:00:22,830 --> 00:00:23,910
Uh,
and,

7
00:00:24,180 --> 00:00:26,820
uh,
so somehow in the interceding 30,

8
00:00:26,821 --> 00:00:27,654
40,
50 years that's come Jack Gender 

9
00:00:30,290 --> 00:00:31,123
Dynamics has completely shifted around.
But what we're seeing now is that 

10
00:00:36,510 --> 00:00:39,930
sometimes it's the implicit biases that 
we have,

11
00:00:40,170 --> 00:00:41,003
which are holding back women and 
minorities from entering the workforce 

12
00:00:44,941 --> 00:00:45,710
and,
uh,

13
00:00:45,710 --> 00:00:47,970
either as data scientists or,
uh,

14
00:00:47,971 --> 00:00:49,140
or as computer,
uh,

15
00:00:49,470 --> 00:00:53,880
engineers and software engineers.
And we've seen a lot of research in this

16
00:00:53,881 --> 00:00:57,450
area that's shown that there can be some
implicit biases that,

17
00:00:58,200 --> 00:00:59,033
uh,
and how we judge people once we know 

18
00:01:01,111 --> 00:01:02,330
about,
uh,

19
00:01:02,340 --> 00:01:03,280
their ne,
uh,

20
00:01:03,420 --> 00:01:04,253
from their name,
their sort of their gender or their 

21
00:01:06,690 --> 00:01:07,523
race.

22
00:01:07,800 --> 00:01:08,633
And what we do right when we assess the 
people who were going to be working for 

23
00:01:13,471 --> 00:01:17,460
us is we are completely blind to these 
things.

24
00:01:17,461 --> 00:01:20,190
We actually strip away the name when we 
consider people,

25
00:01:20,480 --> 00:01:21,570
um,
applications.

26
00:01:21,571 --> 00:01:22,404
We just look at how they perform on a 
series of challenges that we give them 

27
00:01:25,740 --> 00:01:28,380
that really try to test their ability 
to,

28
00:01:28,850 --> 00:01:29,683
uh,
be a data scientist and test their 

29
00:01:31,561 --> 00:01:35,190
understanding of these kind of core 
fundamental mathematical and programming

30
00:01:35,370 --> 00:01:37,200
concepts.
And,

31
00:01:37,340 --> 00:01:38,280
uh,
when we do that,

32
00:01:38,550 --> 00:01:41,430
I think it actually becomes a much more 
fair process,

33
00:01:41,760 --> 00:01:42,593
um,
and it actually can help increase the 

34
00:01:45,211 --> 00:01:47,910
number of women and underrepresented 
minorities,

35
00:01:48,290 --> 00:01:49,020
uh,
in,

36
00:01:49,020 --> 00:01:49,853
uh,
who sort of make it through the 

37
00:01:50,491 --> 00:01:51,324
screening process.
Just to give you one sort of quick 

38
00:01:53,160 --> 00:01:54,860
anecdote about this,
uh,

39
00:01:54,930 --> 00:01:55,763
there's a famous story about music 
auditions in the 1970s where orchestras 

40
00:02:01,170 --> 00:02:05,880
had a very,
very tiny percentage of their members or

41
00:02:05,881 --> 00:02:06,714
their,
uh,

42
00:02:06,800 --> 00:02:08,190
uh,
their players.

43
00:02:08,190 --> 00:02:09,930
They're the people who are playing in 
the orchestra,

44
00:02:10,230 --> 00:02:11,370
uh,
as women.

45
00:02:11,820 --> 00:02:13,570
And what happened,
uh,

46
00:02:13,800 --> 00:02:14,633
is at some point they decided to try to 
break free from this and they will put 

47
00:02:18,481 --> 00:02:21,500
down a curtain between the performer and
the artist,

48
00:02:21,530 --> 00:02:22,363
the auditioner and the judge judging 
panel that was trying to determine 

49
00:02:25,351 --> 00:02:28,620
whether these people should be allowed 
to play in the orchestra.

50
00:02:29,190 --> 00:02:31,140
And when they did the results were night
and day.

51
00:02:31,170 --> 00:02:33,320
There's a famous study of,
um,

52
00:02:33,450 --> 00:02:34,580
that's up on,
uh,

53
00:02:34,650 --> 00:02:37,080
the National Bureau of Economic 
Research's websites,

54
00:02:37,260 --> 00:02:39,540
uh,
published by two famous researchers from

55
00:02:39,541 --> 00:02:42,660
Harvard talking about this.
It's called a orchestra in diversity.

56
00:02:42,900 --> 00:02:45,840
And it talks about how the results were 
night and day difference,

57
00:02:46,080 --> 00:02:47,190
uh,
that women,

58
00:02:47,220 --> 00:02:48,053
the fraction of women who made it past 
the screening round shot up something 

59
00:02:51,151 --> 00:02:52,860
like seven fold,
uh,

60
00:02:53,190 --> 00:02:54,120
uh,
between,

61
00:02:54,480 --> 00:02:56,520
uh,
not having the curtain down and having a

62
00:02:56,521 --> 00:02:57,354
curtain down and it just goes to sort of
show that's at this time there was an 

63
00:03:00,611 --> 00:03:05,611
implicit bias that women weren't really 
the kind of caliber of musician that you

64
00:03:06,640 --> 00:03:11,640
needed to be able to perform at a 
Carnegie Hall.

65
00:03:11,990 --> 00:03:12,910
Uh,
right.

66
00:03:13,120 --> 00:03:14,290
Uh,
at these kinds of top,

67
00:03:14,610 --> 00:03:15,790
uh,
that's kind of top level,

68
00:03:15,791 --> 00:03:16,624
some phonic performance.
And when you put down a curtain and you 

69
00:03:18,881 --> 00:03:19,714
just listened to them as opposed to 
being able to see whether they were a 

70
00:03:23,471 --> 00:03:25,170
man or a woman,
uh,

71
00:03:25,210 --> 00:03:26,043
you then without that kind of knowledge,
you suddenly were forced to make 

72
00:03:28,781 --> 00:03:31,660
judgments just based in the music,
just based on their ability.

73
00:03:32,050 --> 00:03:33,850
And you saw that they w,
uh,

74
00:03:33,851 --> 00:03:36,370
the,
that you are much more willing to let in

75
00:03:36,371 --> 00:03:37,720
women than before.

