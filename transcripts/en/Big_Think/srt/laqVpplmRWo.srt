1
00:00:00,480 --> 00:00:04,080
In a nutshell,
we take the most useful research from

2
00:00:04,081 --> 00:00:08,940
cognitive science about how the human
brain reasons and makes decisions and

3
00:00:09,180 --> 00:00:12,690
the errors that the human brain tends to
make when reasoning or making decisions

4
00:00:12,750 --> 00:00:17,280
and we turn that research into workshops
that people can use to apply it to their

5
00:00:17,281 --> 00:00:20,730
own lives and improve their own decision
making about their health,

6
00:00:20,760 --> 00:00:22,890
their finances,
their relationships,

7
00:00:22,920 --> 00:00:26,280
and the decisions that they make for the
first society and the world in general

8
00:00:26,490 --> 00:00:30,090
about how to vote and how to treat other
people and what they can do to improve

9
00:00:30,091 --> 00:00:33,210
the world.
One example of rationality and action,

10
00:00:33,211 --> 00:00:36,420
just to give you a sense of what it
looks like and how it's relevant.

11
00:00:36,720 --> 00:00:39,120
Back in 1985,
intel,

12
00:00:39,150 --> 00:00:40,080
uh,
had a,

13
00:00:40,440 --> 00:00:44,400
a large foot in the memory chip
manufacturing business and they'd been

14
00:00:44,401 --> 00:00:47,100
losing money on a memory chips for
years.

15
00:00:47,130 --> 00:00:52,080
So the two co founders,
Andy Grove and Gordon Moore met to

16
00:00:52,081 --> 00:00:53,760
figure out what to do,
uh,

17
00:00:53,761 --> 00:00:58,500
and at one point and he asked what do
you think a new CEO would do if the

18
00:00:58,501 --> 00:01:00,510
board kicked us out and brought in a new
CEO?

19
00:01:00,750 --> 00:01:02,220
And without hesitating,
Gordon replied,

20
00:01:02,221 --> 00:01:03,930
Oh,
he would get out of the memory business

21
00:01:04,320 --> 00:01:05,011
and any,
he said,

22
00:01:05,011 --> 00:01:07,500
well,
so is there any reason we shouldn't do

23
00:01:07,501 --> 00:01:11,250
that if we just walk out the door and
come back in and switch out of the

24
00:01:11,251 --> 00:01:13,340
memory business?
And in fact that's exactly what they've

25
00:01:13,341 --> 00:01:15,240
decided to do.
And it was a huge success.

26
00:01:15,540 --> 00:01:19,380
Um,
and this is just one example of a

27
00:01:19,381 --> 00:01:23,310
cognitive bias that appears in lots of
contexts and lots of scales called the

28
00:01:23,311 --> 00:01:26,790
commitment effect,
where we stick with a business plan or a

29
00:01:26,791 --> 00:01:31,260
career or relationship long after it's
become quite clear that it's not doing

30
00:01:31,261 --> 00:01:34,650
anything for us or that it's actively
destructive or self destructive because

31
00:01:34,651 --> 00:01:38,160
we have an irrational commitment to
whatever we have been doing for a awhile

32
00:01:38,340 --> 00:01:40,950
because we don't like the idea of our
past investments having gone to waste or

33
00:01:40,951 --> 00:01:42,480
because it's become part of our
identity.

34
00:01:42,660 --> 00:01:47,100
And the technique that Andy and Gordon
used to snap themselves out of the

35
00:01:47,101 --> 00:01:49,950
commitment.
The fact is also a really generally

36
00:01:49,951 --> 00:01:53,910
useful technique called looking at a
problem as if you were an outsider,

37
00:01:53,911 --> 00:01:56,190
an outside party over the past few
decades.

38
00:01:56,220 --> 00:02:00,660
Cognitive scientists have learned a lot
about this and many other biases that

39
00:02:00,810 --> 00:02:03,210
human brains are subject to when we try
to make decisions,

40
00:02:03,480 --> 00:02:05,730
but fortunately,
cognitive science has also learned a lot

41
00:02:05,760 --> 00:02:08,760
about things that we can do to improve.
So at the center for applied

42
00:02:08,761 --> 00:02:10,500
rationality,
we're taking that research,

43
00:02:10,590 --> 00:02:12,960
teaching people about the biases where
they occur,

44
00:02:13,230 --> 00:02:16,470
when we're vulnerable to biases,
and then teaching them simple and easy

45
00:02:16,471 --> 00:02:20,700
mental habits like looking at a problem
as if you're an outsider to overcome

46
00:02:20,701 --> 00:02:24,300
those biases.
Rationality also is a significant public

47
00:02:24,301 --> 00:02:26,520
good,
and that's one of the main motivations

48
00:02:26,521 --> 00:02:30,600
behind the founding of CFR.
Society would look very different if

49
00:02:30,660 --> 00:02:32,970
rationality,
rational thinking and decision making

50
00:02:32,971 --> 00:02:35,430
more widespread just to name a few of
many,

51
00:02:35,431 --> 00:02:36,750
many things that I could name.

52
00:02:37,050 --> 00:02:42,030
We as a society would demand evidence
from politicians for the claims that

53
00:02:42,031 --> 00:02:44,490
they made.
We would notice when politicians were

54
00:02:44,700 --> 00:02:47,370
misdirecting us by playing on our
emotions,

55
00:02:47,730 --> 00:02:51,210
we would be less vulnerable to prejudice
and stereotypes.

56
00:02:51,240 --> 00:02:53,550
Um,
because we would be wary of the

57
00:02:53,551 --> 00:02:56,910
confirmation bias,
which is a very universal bias in which

58
00:02:56,911 --> 00:02:59,160
you,
you look for examples,

59
00:02:59,290 --> 00:03:01,630
fit a stereotype,
but you don't look for examples that

60
00:03:01,780 --> 00:03:04,870
don't fit the stereotypes you ended up
confirming and reinforcing a stereotype

61
00:03:04,871 --> 00:03:07,930
in your minds.
We would spend our money much more

62
00:03:07,931 --> 00:03:10,720
effectively as a society to stave off
important risks.

63
00:03:10,870 --> 00:03:14,220
The fact that things like terrorism and,
um,

64
00:03:14,350 --> 00:03:17,370
crimes like abduction are,
uh,

65
00:03:17,470 --> 00:03:21,610
so vividly portrayed on the news makes
them a much more salient and makes us

66
00:03:21,611 --> 00:03:25,030
overweight those risks the same way we
overweight any kind of evidence.

67
00:03:25,031 --> 00:03:27,130
It's particularly vivid or salient.
Um,

68
00:03:27,160 --> 00:03:31,000
even if it isn't actually the best bang
for our buck in terms of risk reduction.

