1
00:00:02,820 --> 00:00:05,480
You liked with monster is a big

2
00:00:06,130 --> 00:00:10,110
that was created by a whole bunch of
caricaturists.

3
00:00:10,340 --> 00:00:13,150
But it's interesting that virtually
anybody,

4
00:00:13,390 --> 00:00:16,150
unless they're a professionalist story
and writing about the enlightenment,

5
00:00:16,510 --> 00:00:20,200
anybody throwing out discussions about
the enlightenment,

6
00:00:20,201 --> 00:00:22,750
whether it be Robert Kagan on the right
or,

7
00:00:23,260 --> 00:00:24,730
um,
gee,

8
00:00:24,731 --> 00:00:27,940
I don't know who on the left Fuko on the
left.

9
00:00:28,280 --> 00:00:29,500
Um,
whoever it is,

10
00:00:29,830 --> 00:00:33,190
um,
sees the enlightenment as an isoline

11
00:00:33,250 --> 00:00:35,890
cold being who is sublimated,
Ooh,

12
00:00:35,950 --> 00:00:40,540
passion to reason who believes that
reason is instrumental and calculating

13
00:00:40,541 --> 00:00:45,310
and a matter of technology who has a
blind faith in progress and thinks that

14
00:00:45,311 --> 00:00:48,250
the world is inexhaustibly going forth
for the better.

15
00:00:48,700 --> 00:00:49,533
Uh,
what's,

16
00:00:49,600 --> 00:00:50,980
what are the,
some of the features of the

17
00:00:50,981 --> 00:00:52,740
enlightenment monster?
Um,

18
00:00:52,870 --> 00:00:55,930
those are the crucial ones.
They don't actually fit anyone,

19
00:00:56,350 --> 00:00:59,260
which is why I called them the
enlightenment monster in the book.

20
00:00:59,290 --> 00:01:03,010
Because if you look at the enlightenment
itself,

21
00:01:03,011 --> 00:01:06,010
and you don't need to be a historian and
you don't need to dig into the archives,

22
00:01:06,250 --> 00:01:11,250
all you need to do is read candide,
which was written in 1759 that is in the

23
00:01:11,891 --> 00:01:14,470
middle of the enlightenment by Voltaire.

24
00:01:14,800 --> 00:01:19,060
You see a critique of this very
simplistic enlightenment attitude from

25
00:01:19,061 --> 00:01:22,450
the heart of the enlightenment itself.
That is the enlightenment itself knew

26
00:01:22,660 --> 00:01:24,130
that,
uh,

27
00:01:24,220 --> 00:01:28,180
progress wasn't necessary.
They only thought it was possible.

28
00:01:28,420 --> 00:01:32,230
They knew that other things besides
reason were important.

29
00:01:32,231 --> 00:01:35,260
They spend at least as much time talking
about the emotions as they did about

30
00:01:35,261 --> 00:01:36,420
reason.
Uh,

31
00:01:36,520 --> 00:01:40,900
and they weren't interested in reason
because they were icu or because they

32
00:01:40,901 --> 00:01:45,901
were merely technological,
but because reason was a democratic

33
00:01:47,560 --> 00:01:52,210
instrument against superstition and
authority reason as opposed not to

34
00:01:52,211 --> 00:01:55,150
passion,
but to somebody intuition,

35
00:01:55,180 --> 00:01:56,050
right?
Just as well.

36
00:01:56,230 --> 00:02:00,070
God told me to invade another countries.
So that's a private intuition and

37
00:02:00,071 --> 00:02:02,350
there's no way that I can explain it to
you,

38
00:02:02,351 --> 00:02:03,830
but I just know it.
Um,

39
00:02:04,120 --> 00:02:09,120
it's one way of not using reason.
Another way of not using reason is,

40
00:02:09,370 --> 00:02:14,370
uh,
is to simply use rhetoric to simply use

41
00:02:14,700 --> 00:02:17,320
soundbites,
play the same sound bites over and over

42
00:02:17,321 --> 00:02:20,350
without looking at an entire speech in
context.

43
00:02:20,670 --> 00:02:24,190
Um,
and to create superstition and fear.

44
00:02:24,490 --> 00:02:27,400
And the enlightenment was attempting to
use reason,

45
00:02:27,401 --> 00:02:30,070
which is a faculty we all have,
we can all develop.

46
00:02:30,520 --> 00:02:32,890
Uh,
and we can all debate about,

47
00:02:33,220 --> 00:02:38,220
as I gather you're doing with this
program rather than a appealing to

48
00:02:38,621 --> 00:02:42,640
authority or superstition.
So all of those,

49
00:02:42,760 --> 00:02:44,740
uh,
all of his criticism of the

50
00:02:44,741 --> 00:02:47,650
enlightenment occurred within the
enlightenment itself.

51
00:02:47,880 --> 00:02:49,030
Uh,
the idea,

52
00:02:49,150 --> 00:02:52,300
the other feature of the enlightenment
of course is that people think it was

53
00:02:52,360 --> 00:02:56,470
totally irreverent and anti religious.
It was not irreverent.

54
00:02:56,740 --> 00:02:59,020
It,
most members of the,

55
00:02:59,440 --> 00:03:04,370
there's some who were sheer atheists and
who I even would call irreverent,

56
00:03:04,460 --> 00:03:08,950
lacking a sense of reverence that I do
think is terribly important.

57
00:03:09,250 --> 00:03:14,250
But most of them thought that science
would lead to a greater appreciation of

58
00:03:15,071 --> 00:03:19,960
the glories of creation and gratitude
for the fact that we live in a marvelous

59
00:03:19,961 --> 00:03:23,380
world.
That was how they soil science as,

60
00:03:23,470 --> 00:03:27,640
as a contributing to human progress,
not simply,

61
00:03:27,641 --> 00:03:31,390
although these are important enough
helping to eradicate disease and poverty

62
00:03:31,391 --> 00:03:32,224
and prejudice,

63
00:03:32,790 --> 00:03:35,940
but also in creating a sense of wonder
and gratitude

64
00:03:42,680 --> 00:03:45,180
for enlightenment values.
Because I don't,

65
00:03:45,590 --> 00:03:49,840
we think that there's one,
one of the things that when people

66
00:03:49,841 --> 00:03:51,940
associate something positive with the
enlightenment,

67
00:03:52,000 --> 00:03:54,130
which unfortunately is rare enough these
days,

68
00:03:54,430 --> 00:03:56,110
uh,
they talk about tolerance.

69
00:03:56,470 --> 00:04:01,390
Tolerance is fine as far as it goes.
If you already believe in something,

70
00:04:01,960 --> 00:04:06,430
but it's deeply wimpy,
um,

71
00:04:06,760 --> 00:04:08,840
in the sense that,
uh,

72
00:04:09,220 --> 00:04:13,360
you might conceivably get somebody to
refrain from doing something in the name

73
00:04:13,361 --> 00:04:16,240
of tolerance,
you will have a very hard time getting

74
00:04:16,480 --> 00:04:20,110
them to do anything for something in the
name of tolerance because,

75
00:04:20,170 --> 00:04:23,830
uh,
it's not a value that has a lot of

76
00:04:23,831 --> 00:04:27,190
content.
So instead I've asked that we look at

77
00:04:27,191 --> 00:04:30,670
four different enlightenment values.
One I named two already,

78
00:04:30,671 --> 00:04:35,050
which is reason the other is reverence,
which I also discussed.

79
00:04:36,040 --> 00:04:39,400
Third,
which we've come to take for granted is

80
00:04:39,401 --> 00:04:42,430
happiness.
I think it's very easy for

81
00:04:42,431 --> 00:04:46,420
fundamentalist to look at American
consumerist culture and we've seen a

82
00:04:46,421 --> 00:04:49,150
terrorist do that and say,
you know what?

83
00:04:49,420 --> 00:04:54,420
This is not my idea of the meaning of
life of society that's consumed with,

84
00:04:54,990 --> 00:04:59,470
uh,
whoever dies with the most toys wins as

85
00:04:59,471 --> 00:05:02,510
a bumper sticker in the 90s used to say,
ah,

86
00:05:02,620 --> 00:05:05,530
there's something revolting about that
as a sense of value.

87
00:05:05,830 --> 00:05:07,870
That's not what the enlightenment was
talking about,

88
00:05:07,900 --> 00:05:11,110
about sheer materialism.
The enlightenment was talking about a

89
00:05:11,111 --> 00:05:16,111
right to happiness as distinguished from
whatever fee you got stuck with.

90
00:05:18,730 --> 00:05:21,700
I started my chapter on happiness with
the book of job,

91
00:05:21,730 --> 00:05:25,030
which may seem like a counter intuitive
place to start.

92
00:05:25,540 --> 00:05:28,570
And I started that way because the book
of job is the most read book of the

93
00:05:28,571 --> 00:05:31,240
Bible.
But until the enlightenment,

94
00:05:31,570 --> 00:05:36,570
everyone who read job read him the way
job's friends did that his job had it

95
00:05:38,741 --> 00:05:43,741
coming okay and they went to crazy
lengths to try and construct a story

96
00:05:44,380 --> 00:05:49,380
such that Joe deserve whatever it is
that he got in the enlightenment,

97
00:05:50,411 --> 00:05:53,500
you suddenly began to have a notion that
hey,

98
00:05:53,501 --> 00:05:58,190
actually it would be possible for bad
things to happen to good people and good

99
00:05:58,191 --> 00:05:59,900
things to happen to bad people.

100
00:06:00,020 --> 00:06:05,020
This is not what God has ordained.
And what that means is if bad things

101
00:06:05,661 --> 00:06:09,500
happen to good people,
the world people in the world have a

102
00:06:09,501 --> 00:06:14,501
right to step up and try to change them.
You said before you have that idea if

103
00:06:14,901 --> 00:06:17,000
people were sick,
well you know,

104
00:06:17,090 --> 00:06:19,910
it was probably God's will if people
were poor.

105
00:06:19,911 --> 00:06:21,680
Hey,
that was certainly God's will.

106
00:06:22,040 --> 00:06:26,570
So until you have the idea that
happiness is not something in a last

107
00:06:26,571 --> 00:06:31,010
golden age or something that you might
look forward to in heaven,

108
00:06:31,250 --> 00:06:34,430
but something that if you fundamentally
do what you should do,

109
00:06:34,431 --> 00:06:38,060
you have a right to on earth.
Until you have that idea,

110
00:06:38,240 --> 00:06:43,240
you don't get a sense of justice.
So that's the third enlightenment value.

111
00:06:43,491 --> 00:06:46,910
When the final one is the value of hope,
which is very different from optimism.

112
00:06:47,470 --> 00:06:49,070
Uh,
the people in the enlightenment,

113
00:06:49,100 --> 00:06:50,300
we're not sunny.

114
00:06:50,300 --> 00:06:54,800
They knew how bad things could be.
If you read some of these pieces,

115
00:06:55,010 --> 00:06:57,320
you'll be amazed.
They sounded like they could be written

116
00:06:57,321 --> 00:07:01,400
in the late 20th century.
It's as far as their understanding of

117
00:07:01,401 --> 00:07:06,200
just how dark human beings could be.
So they don't believe that human beings

118
00:07:06,201 --> 00:07:10,520
are perfect.
They just don't believe that they're

119
00:07:10,880 --> 00:07:14,300
committed to original sin.
And interestingly enough,

120
00:07:14,301 --> 00:07:16,570
I think both,
um,

121
00:07:17,090 --> 00:07:22,090
a lot of traditional Christians as well
as a lot of secular postmodernists,

122
00:07:24,681 --> 00:07:29,570
and this is very interesting.
Someone likes Sukkot is actually talking

123
00:07:29,571 --> 00:07:34,430
or he doesn't talk about it of course,
but it's actually giving us as a

124
00:07:34,431 --> 00:07:39,431
foundation and notion of original sin,
what ever one tries to do to improve on

125
00:07:43,970 --> 00:07:47,810
the world is doomed to futility.
Because in fact,

126
00:07:47,811 --> 00:07:52,811
we're all driven by nothing but power
and whatever looks like an alleviation

127
00:07:53,481 --> 00:07:57,200
of injustice is in fact going to be a
refinement of certain techniques of

128
00:07:57,201 --> 00:07:58,034
power.

129
00:07:58,190 --> 00:08:03,190
So when the enlightenment does a way
with those kinds of ideas of original

130
00:08:03,591 --> 00:08:04,430
sin,
I mean,

131
00:08:04,490 --> 00:08:07,070
that's a postmodern return to original
sin.

132
00:08:07,610 --> 00:08:09,200
They're saying,
you know what,

133
00:08:09,380 --> 00:08:10,790
things can get better.
And,

134
00:08:10,880 --> 00:08:12,590
uh,
I think

135
00:08:14,210 --> 00:08:18,710
our own time has seen so many clear
ideas.

136
00:08:18,940 --> 00:08:23,940
So somebody clear examples of ways in
which the world has been changed by

137
00:08:24,081 --> 00:08:27,290
ideals for the better,
but not necessarily.

138
00:08:27,291 --> 00:08:31,280
Torture is a very good example.
If you think about the fact that 300

139
00:08:31,281 --> 00:08:32,660
years ago,
uh,

140
00:08:32,810 --> 00:08:36,980
scenes that would turn your stomach to
read about are things you would have

141
00:08:36,981 --> 00:08:39,830
taken your kids to watch on a Saturday
afternoon,

142
00:08:40,670 --> 00:08:41,930
and you realize,
well,

143
00:08:42,650 --> 00:08:46,790
that was in the heart of civilization.
We've abolished that now,

144
00:08:47,360 --> 00:08:51,080
of course,
as we've seen in the last five years,

145
00:08:51,350 --> 00:08:54,530
this is not necessary progress.
You can turn the clock back.

146
00:08:54,531 --> 00:08:58,950
And one of the things that has to happen
to restore America's moral authority is

147
00:08:58,951 --> 00:09:03,630
for us to take a resoundingly stand
again against torture and for the

148
00:09:03,631 --> 00:09:07,950
enlightenment.
But it is a kind of progress.

149
00:09:07,980 --> 00:09:09,330
It happened.
Uh,

150
00:09:09,331 --> 00:09:11,580
it doesn't happen necessarily,
but it can happen

151
00:09:12,190 --> 00:09:17,190
if we were fortunate.
[inaudible].

