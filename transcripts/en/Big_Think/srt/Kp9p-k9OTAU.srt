1
00:00:00,240 --> 00:00:02,460
There is a pattern to the introduction
of technologies.

2
00:00:02,490 --> 00:00:04,750
When Gutenberg invented the press,
uh,

3
00:00:04,890 --> 00:00:07,560
some of the earliest authors were
frightened of having their words and

4
00:00:07,561 --> 00:00:09,570
thoughts set down permanently
distributed widely.

5
00:00:09,780 --> 00:00:12,960
Jonathan Swift said that a book of
versus kept in a drawer showed only to

6
00:00:12,961 --> 00:00:14,720
friends was like a,
a,

7
00:00:14,910 --> 00:00:16,620
you know,
a fine lasts,

8
00:00:16,650 --> 00:00:19,380
but once printed as a book,
it was like a common whore and you want

9
00:00:19,381 --> 00:00:20,460
to,
can buy for two crown.

10
00:00:21,540 --> 00:00:22,910
Fast forward to the,
the,

11
00:00:22,911 --> 00:00:26,010
the,
the prior kind of moral panic we've had

12
00:00:26,011 --> 00:00:29,220
about privacy came because of the
technology in the year 1890,

13
00:00:29,610 --> 00:00:33,690
the first major law review article
written by Louis Brandeis and said go

14
00:00:33,710 --> 00:00:37,830
warren.
The tried to look for a legal basis to a

15
00:00:37,831 --> 00:00:41,310
right to privacy in the United States
was inspired by the invention of a

16
00:00:41,311 --> 00:00:43,500
technology,
the Kodak Camera,

17
00:00:44,430 --> 00:00:47,700
and that caused some measure of moral
panic and fear.

18
00:00:48,180 --> 00:00:50,930
The New York Times at the time has
stories about fiendish.

19
00:00:50,940 --> 00:00:52,470
Kodak is lying in.
Wait,

20
00:00:52,471 --> 00:00:54,530
a young vanderbilt,
a horse horsewhip,

21
00:00:54,540 --> 00:00:58,310
a Kodak or a president.
Teddy Roosevelt outlawed Kodak,

22
00:00:58,311 --> 00:01:00,570
him in Washington parks.
Now what happened?

23
00:01:01,050 --> 00:01:02,430
Well,
we got used to cameras,

24
00:01:02,431 --> 00:01:04,050
in fact,
we're happy to pose in front of them as

25
00:01:04,051 --> 00:01:05,760
I am right now.
Uh,

26
00:01:05,910 --> 00:01:10,290
and what really went on there was that a
new technology caused a change that our

27
00:01:10,291 --> 00:01:14,160
norms weren't ready for.
And until such time as we had new norms,

28
00:01:14,161 --> 00:01:17,850
we had new agreements about how we
operate as a society around this were

29
00:01:17,851 --> 00:01:19,680
unsettled.
We're afraid of what could go wrong.

30
00:01:19,980 --> 00:01:20,731
Well,
that's what's happening with the

31
00:01:20,731 --> 00:01:22,740
Internet with a much bigger technology
that it is.

32
00:01:23,040 --> 00:01:25,680
It's causing new opportunities.
It's causing change.

33
00:01:25,681 --> 00:01:30,681
It also causes fear and disruption and
sometimes even a moral panic,

34
00:01:31,681 --> 00:01:32,790
which is what I think we're going
through now.

35
00:01:33,120 --> 00:01:35,310
Privacy matters.
Privacy is important.

36
00:01:35,311 --> 00:01:36,180
That needs protectors.

37
00:01:36,180 --> 00:01:37,950
I have a private life.
All that is true,

38
00:01:38,250 --> 00:01:41,040
but we also have this magnificent tool,
the publicness,

39
00:01:41,041 --> 00:01:45,480
the Internet in all of our hands.
We can find form and act as publix now

40
00:01:45,481 --> 00:01:49,950
in ways that we couldn't before.
That's a magnificent ability and my fear

41
00:01:50,160 --> 00:01:52,110
is that if governments come in to
regulate,

42
00:01:52,290 --> 00:01:56,910
the net will lose some of that power and
some of them want us to lose that power

43
00:01:56,911 --> 00:02:00,990
because they fear that power,
so I think we have to be aware of

44
00:02:01,230 --> 00:02:04,110
demonizing technology,
things like tracking cookies,

45
00:02:04,111 --> 00:02:06,840
being bad for us or worried about
technology first off,

46
00:02:06,841 --> 00:02:09,960
because we're walking into the hands of
those who would limit the technology

47
00:02:10,440 --> 00:02:14,310
rather than what we should do.
What society is long done is you

48
00:02:14,311 --> 00:02:19,311
regulate the behaviors so you can use a
telephone to do good things and Simon

49
00:02:19,730 --> 00:02:21,840
someone an ambulance,
you could use it to do bad things into

50
00:02:21,841 --> 00:02:22,650
fraud.
People,

51
00:02:22,650 --> 00:02:25,510
the technology isn't bad.
It's the behavior we regulate.

52
00:02:25,920 --> 00:02:30,090
Yet nowadays we're seeing efforts by
governments to come in and regulate on

53
00:02:30,091 --> 00:02:34,530
the whole the Internet,
so even Canada and Australia want to

54
00:02:35,010 --> 00:02:37,980
filter all the content on the net to get
to pedophilia.

55
00:02:38,490 --> 00:02:40,290
Well,
they create an ability and an

56
00:02:40,291 --> 00:02:42,630
architecture that also Iran and China
will use.

57
00:02:42,990 --> 00:02:43,940
We have to be aware of that.

