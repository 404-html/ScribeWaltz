1
00:00:03,620 --> 00:00:06,150
Yeah,
the way I think about attention is

2
00:00:06,151 --> 00:00:10,110
really as a problem of routing routing
signals,

3
00:00:10,410 --> 00:00:15,410
so actually we know a lot about how
signals come in through your sensory

4
00:00:16,651 --> 00:00:19,200
apparatus,
through your ears and your eyes.

5
00:00:19,950 --> 00:00:22,560
We know an awful lot about how the
retina works,

6
00:00:22,561 --> 00:00:27,210
how the Cochlea Works,
we understand how the signals travel up

7
00:00:27,211 --> 00:00:30,720
and eventually they percolate up to the
cortex.

8
00:00:30,721 --> 00:00:33,630
In the case of sound,
they percolate up to the auditory cortex

9
00:00:33,631 --> 00:00:37,950
and we know a lot about a fair amount
about how they look once they get there

10
00:00:38,220 --> 00:00:41,490
and after that we kind of lose track of
them and we can't really pick up the

11
00:00:41,491 --> 00:00:44,820
signal until we're.
They're coming out the other end.

12
00:00:44,821 --> 00:00:48,780
We know a lot about movement.
We understand an awful lot about what

13
00:00:48,781 --> 00:00:52,500
happens when a nerve impulse gets to a
muscle and how muscles contract.

14
00:00:52,501 --> 00:00:55,980
That's been pretty well understood for
50 years or something.

15
00:00:56,310 --> 00:01:00,510
You're more than that,
so where we really lose track of them is

16
00:01:00,511 --> 00:01:05,511
when they enter into the early parts of
the sensory cortex and when there we

17
00:01:06,100 --> 00:01:08,760
pick them up again,
sort of on the on the other side,

18
00:01:09,060 --> 00:01:14,060
and so attention is one of the ways in
which signals can find their destination

19
00:01:17,341 --> 00:01:19,980
if you like.
So think about it in terms of a really

20
00:01:19,981 --> 00:01:24,450
specific a problem.
Imagine that I asked you to raise your

21
00:01:24,451 --> 00:01:26,160
right hand.
When I say go,

22
00:01:26,640 --> 00:01:29,160
okay,
so I say go you raise your right hand,

23
00:01:29,220 --> 00:01:31,140
go raise your right hand.
Now let's change it.

24
00:01:31,750 --> 00:01:33,630
And I say,
go raise your left hand,

25
00:01:33,990 --> 00:01:38,190
go raise your left hand.
So somehow the same signal coming in

26
00:01:38,191 --> 00:01:42,030
through your ear is producing different
activity at the other end,

27
00:01:42,031 --> 00:01:46,680
somehow the signal on the sensory side
had to be routed to either the muscles

28
00:01:46,681 --> 00:01:48,930
of your right hand or the muscles of
your left hand.

29
00:01:49,350 --> 00:01:52,950
Now,
attention is a special case of that kind

30
00:01:52,951 --> 00:01:57,951
of general routing problem at the brain
faces all the time because when you

31
00:01:58,741 --> 00:02:03,741
attend to,
let's say your a sounds rather than your

32
00:02:04,411 --> 00:02:09,411
visual input or when you attend to one
particular auditory input out of many,

33
00:02:11,160 --> 00:02:15,450
what you're doing is you're selecting
some subset of the inputs in this case,

34
00:02:15,451 --> 00:02:20,280
coming in to your ears and and
subjecting them to further processing

35
00:02:20,700 --> 00:02:23,640
and you're,
you're taking those signals and routing

36
00:02:23,641 --> 00:02:26,040
them downstream and doing stuff with
them.

37
00:02:26,041 --> 00:02:30,390
How that routing happens.
That's the aspect of attention that my

38
00:02:30,391 --> 00:02:31,890
lab focuses on.
So,

39
00:02:32,490 --> 00:02:35,910
so the basic setup for the problem that
I'm interested in is this.

40
00:02:35,911 --> 00:02:39,780
Imagine that you're at a cocktail party.
There are a bunch of conversations going

41
00:02:39,781 --> 00:02:44,190
on and you're talking to someone,
but there's all this distracting stuff

42
00:02:44,191 --> 00:02:45,420
going on.
The side lines.

43
00:02:45,690 --> 00:02:46,590
You can make a choice.

44
00:02:46,590 --> 00:02:50,010
You can either focus on the person
you're talking to and ignore the rest.

45
00:02:50,280 --> 00:02:53,490
Or as often happens,
you find that the conversation that

46
00:02:53,491 --> 00:02:56,180
you're engaged in is not as interesting.
And uh Huh.

47
00:02:56,230 --> 00:02:57,190
Uh Huh.
Oh really?

48
00:02:57,600 --> 00:02:58,500
Summer.
Okay.

49
00:02:58,620 --> 00:03:01,150
And you start focusing in on this
conversation on the right,

50
00:03:01,151 --> 00:03:04,840
your ability to focus in on this
conversation while ignoring that

51
00:03:04,841 --> 00:03:08,200
conversation.
That is sort of the challenge.

52
00:03:08,201 --> 00:03:10,330
Understanding how we do that is the
challenge of,

53
00:03:10,360 --> 00:03:14,140
of my research and that,
that problem actually has two separate

54
00:03:14,141 --> 00:03:17,260
aspects.
So there's one aspect of that problem

55
00:03:17,560 --> 00:03:21,130
that is really a problem of computation.
It's,

56
00:03:21,250 --> 00:03:26,250
it's a problem that is a challenge to
basically any computer,

57
00:03:26,321 --> 00:03:27,430
namely,
uh,

58
00:03:27,460 --> 00:03:31,510
we have a whole bunch of different
sounds and from a bunch of different

59
00:03:31,511 --> 00:03:36,511
sources and they're super imposed at the
level of the ears and somehow they're,

60
00:03:37,030 --> 00:03:40,990
they're added together.
And to us it's typically pretty

61
00:03:40,991 --> 00:03:44,650
effortless for us to separate out those
different threads of the conversation.

62
00:03:45,430 --> 00:03:48,940
But actually that's surprisingly
difficult tasks.

63
00:03:48,941 --> 00:03:53,800
So a computers maybe 10 years ago
already,

64
00:03:53,801 --> 00:03:58,801
we're getting pretty good at doing a
speech recognition and in,

65
00:03:59,080 --> 00:04:03,010
in a controlled situations and quiet
rooms.

66
00:04:03,250 --> 00:04:08,250
Computers were actually pretty good at
recognizing even a random speakers,

67
00:04:09,070 --> 00:04:13,660
but when people actually start deploying
these in real world settings where

68
00:04:13,661 --> 00:04:17,110
there's traffic noise and whatnot,
the computer algorithms broke down

69
00:04:17,111 --> 00:04:20,890
completely.
And it was sort of surprising at first

70
00:04:20,891 --> 00:04:25,840
because that's the aspect that we as
humans seem to have a not much trouble

71
00:04:25,841 --> 00:04:27,760
with at all.
So the,

72
00:04:27,790 --> 00:04:28,820
the,
uh,

73
00:04:28,830 --> 00:04:32,740
ability to take apart the different
components of an auditory scene,

74
00:04:32,741 --> 00:04:37,150
that's what we've evolved for hundreds
of millions of years to do really well.

75
00:04:37,480 --> 00:04:39,690
Um,
so that's one aspect of attention.

76
00:04:39,700 --> 00:04:41,710
There's almost this sort of,
um,

77
00:04:42,330 --> 00:04:44,580
uh,
aspect of it that happens before we're

78
00:04:44,590 --> 00:04:47,920
even aware of it,
where the auditory scene is broken down

79
00:04:47,921 --> 00:04:50,320
into the components.
The other aspect,

80
00:04:50,321 --> 00:04:51,710
which is,
uh,

81
00:04:51,790 --> 00:04:55,240
the one that we're sort of more
consciously aware of is the one where

82
00:04:55,270 --> 00:04:58,030
out of the many components of this
conversation,

83
00:04:58,270 --> 00:05:02,110
we have this auditory seem.
We select one and that's the one we

84
00:05:02,111 --> 00:05:03,580
focus in on,
right?

85
00:05:03,581 --> 00:05:07,960
So it,
at this hypothetical cocktail party,

86
00:05:08,190 --> 00:05:11,950
uh,
we have the choice of focusing on either

87
00:05:11,951 --> 00:05:15,160
the conversation we're engaged in or
this one or that one.

