Speaker 1:          00:00:01       So, uh, we're now at the stage where we're considering the implications of uncertainty. So I hope that the subtlety and surprise element of the class will gradually pick up, uh, without increasing the difficulty. The complexity will pick up a little bit, but not the difficulty. It's just you have to keep a few more things in your head, but the mathematics isn't any harder. So we started, we ended last time talking about default and inferring default probabilities. And so I just want to finish off that discussion. So suppose that at any stage of the tree, you know, lots of things can happen in the world. We're always going to model the uncertainty in the future by a tree with different things happening. And at each of these nodes people are going to have a discount rate. So maybe it'll be a, you know, uh, r equals 20% and here are could equal 15%, something like that. And we want to add to this the possibility that there's the fault. So if we add the possibility of default, you know, on these things keep going and maybe their payoffs at the end or pay offs along the way.

Speaker 1:          00:01:23       If at any point in the tree like this one, we add a new possibility, which is the default possibility.

Speaker 2:          00:01:33       Okay?

Speaker 1:          00:01:34       And we assume, so this just happens by when new people to fall, they never default before they have to make a payment. So when do they default exactly when they're supposed to make a payment. So suppose that this guy is going to default here when he's going to make a payment. You know what every possible scenario he would default there. So you've got a very simple uh, model of default. Okay? So not a very realistic one where the guy defaults in all of these following scenarios. Okay? So some things just bad once he's gotten here, you know that he's not going to make the payment the next period. And let's suppose we further assume that only does it, not only does he default there, but he defaults on everything thereafter. So the payoff is just going to be zero here. So this is going to be, originally we had probabilities, p one p two p three, let's say for the probabilities. Now we're going to have probabilities d for default and then one minus d times all of these,

Speaker 2:          00:02:37       right?

Speaker 1:          00:02:38       So essentially what have we done? We've simply replaced in our calculation of payoffs and present values, we've simply replaced these possibilities with probability p one p two p three we added another possibility, but the payoffs are zero here. Nothing's going to happen from then on except zero. And we said that happened with probability, which means presumably all of these have to be scaled down by that. So they still add up to one. So essentially the point I'm trying to make is that default,

Speaker 2:          00:03:10       uh, that, uh, leads who

Speaker 1:          00:03:16       zero payoffs thereafter after is just

Speaker 2:          00:03:25       like discounting more.

Speaker 1:          00:03:33       Why is that? Because whatever calculation you did for the value here of what the bond could possibly be worth there is, it's all the same numbers as they were before, except we've multiplied it by one minus d. Okay. So it's the same thing. So instead of going one over one plus r times, you know, future payoffs, that's no default value.

Speaker 2:          00:03:59       Hmm.

Speaker 1:          00:04:03       Okay. Now, so that time, suture payoffs, now we've got the fault value under this special kind of the fall is going to be one minus d times one over one plus r times the same future payoffs. Okay. But always could make one. I could rewrite one minus D as one over one plus s or something. And so then I really have just one over one plus r times one over one plus s. So that's just one over one plus r Plus s plus s. So that's going to equal one over one plus r Plus s plus r s times future values. Okay, so the effect of this special kind of default, we just get zero thereafter. You know, the guy decides after this payment, I'm not gonna make any more payments on DePaul. The faulting from then on. That's the same thing when valuing the future payoffs. It's the same thing as instead of discounting by our discounting by r plus s with a little bit. Our Times, as you know, if rns are small numbers, this is probably quite a small number. So default probabilities get mapped into spreads that are called. Okay. The Way to evaluate it is just you just multiply it by one minus D, which is the same thing as discounting by a higher number. And that a higher number is almost the same. It's very close to r plus d as a matter of fact, because one minus D is one of one plus ass. If d is very small, s is going to be very close to d as well.

Speaker 2:          00:05:53       Okay.

Speaker 1:          00:05:53       Okay, so on Uproxx. Okay, so,

Speaker 3:          00:06:00       okay, so that, okay, so what's the implication of this, the implication of this in a special case, special case, again, where are we? We don't have, we just have, you know, no one certainty except we have default. So here or there could be d one one minus d one and here there could be probably living to fall two on one minus t two probability of default three one minus d three and we've got interest rates are zero. So this will be, um, I zero I f one F two.

Speaker 1:          00:06:40       Okay. So if you knew what the interest rate was going to be today, you knew what the interest rate was going to be tomorrow. You knew what the interest rate was going to be the day after tomorrow. There no uncertainty about interest rates, they're perfectly anticipated will, but you know that there's a probability of default each time. So in Stage one, this guy might default before making his payment here, which case you're just going to get zero. In Stage two, he might default, instead of making this payment, won't pay the coupon, he'll just default. Or in year three he might default. Okay. So what's the implication of what we just said? Um, you can evaluate this bond. The payoffs are the bond. So let's say it pays off

Speaker 3:          00:07:22       coupon, c c a hundred plus city. Okay.

Speaker 1:          00:07:27       All right. The way you would evaluate that without the fault is you would just take

Speaker 3:          00:07:33       the value of the coupon. The present value would have been one, um, would have been, uh, you would have done it recursively, you would have gotten, you know, p three equals a hundred plus c, then you would have said p two, it would've gone. And your computer, you're going to said p two is one over one plus I f two times a hundred plus c. Okay. And then p won equals. So the value here is the hundred plus c discounted by that Ford, right? Then [inaudible] would have been c plus p two divided by one plus I f one. So you take the value here, time to that. So this is in case there's no default, and p zero would have been c plus p one over one plus I f zero. All right? So that's how you would have done it by backward induction. But now that you know,

Speaker 1:          00:08:34       chances, there's default. You have to, you have to not multiply by one. Plus I have to, you have to multiply all the sides

Speaker 3:          00:08:42       things by the probability of default. You'd have to multiply this by, if we change colors by one minus d, You'd have to multiply this by one minus d two and you'd have to multiply this by one minus d one times one minus d two and this by one minus, uh, sorry, this would be one minus d three. This is one minus d three times d two and this is one minus d one times one minus d two friends, one minus d three.

Speaker 4:          00:09:23       Okay.

Speaker 3:          00:09:23       Okay. So this value would be the old value got here multiplied by one minus d three multiplied by this one, minus d three. This value is what you would've gotten here, but you've already scaled it down. So multiplied by one minus dean too. And this is why one minus t one. So what's the upshot? The upshot is had you. And so then this is okay. So that gives you the price, uh, with the fault. Okay. So

Speaker 4:          00:09:53       Yup.

Speaker 3:          00:10:12       Well I could have done it two ways. I could have written. So what you're suggesting is a better way would have been to say p two the default, the default fine p two is going to be one minus d three times p three okay. Which is also equal to p three because there's no default after here, the world just sends than p one is equal to one minus d two times p two okay. But that P to remember is already one minus d three times a p three okay. And then p zero is going to be one minus d one times one minus d two times p one but that's equal to one minus d one times one minus d two times p one which is one minus the three times p three

Speaker 4:          00:11:18       right?

Speaker 3:          00:11:21       Sorry. If you go from here to here, the value here is a hundred plus c. So if p three is just a hundred plus C, that's leave it as 100 plus c that's what the guy actually pays. Okay. So the present value would just be um oh. Then you have to divide all this by one plus I to, sorry, this is one plus I f two all making a mess of this and this is a, okay, so usually you'll go back from here to here discounting by

Speaker 1:          00:11:53       the interest rate. Okay? But now we're going to have to also multiply by the probability that you default to go back here. So we get a lower number. P two is not just a 100 plus c divided by one plus I f that's the discounting. You also have to multiply by the probability of default. Then when you go back one period further, you have to discount again. Okay? So I should have multiple divided this by one plus I f one you have to discount it and also you have to multiply it by the probability of default. Okay? But the thing you're, you're bringing backwards is p two which has already taken to account the probability of default the next time. Okay? And then when you go back one step further, you have to do the whole thing again divided by one plus I f zero.

Speaker 2:          00:12:50       Okay.

Speaker 1:          00:12:51       I have one minus. This is p one, not p two. So I have a,

Speaker 2:          00:12:58       okay.

Speaker 1:          00:12:59       No. Okay. So, but I'm switching the, the peas on you. I've got a pee. Okay. So when you have p when we go from here. Okay. You can, the value here, we just calculated it was going to be p two. Okay. So here, the value of p one taking into account the fault is one minus d two times p two. Okay. Which already takes into account that the fault next time. Um,

Speaker 2:          00:13:28       yeah,

Speaker 1:          00:13:28       thanks P to discounted by the interest rate here. So I've got the one minus d two here now and I discount back to here. You're saying how come the [inaudible] showing up anymore? Cause I'm, I'm just at the one that's your question. Right. Okay. So it doesn't show up. It's just a p zero is one minus Dijuan oh you're asking this, you're right. One minus steam on you are right times p one divided by one plus I f zero. That's right. But if I plug in for p one p one already had, that's where the dean too came from. So p ones got the deed to it. So it's one minus d one times one minus t two times p two and then p two had a p three or it. So I've got all the defaults in it. Are you with me now? So sorry about that.

Speaker 1:          00:14:15       So you're right, I said it wrong. So, okay, so, but this is the point. This is Jay. This was supposed to be obvious. I didn't even think about it. What I'm the next step is the thing that's not obvious. Okay. So to discount, you just figure the here the potential cash flows, you're discounting them by the interest rate. You also have to discount it again by the fact that the guy might actually pay you. So that gives you a lower present value. Pink to yellow p two is less than the, no default, quite p too. When you discount again, you're discounting the yellow pea to by the interest rate here. And also the fact that the guy might not pay. So you have to disk multiplied by one minus t two and also the fact that he might not pay the the the forward. Right. Okay. And You keep moving that backwards. Okay. So that was supposed to be obvious. Even though I made it sound complicated, what slightly subtler is just saying the same thing backwards, which is suppose that I, um, saying the same thing backwards is suppose I knew all these forward rate suppose.

Speaker 2:          00:15:27       Okay.

Speaker 3:          00:15:30       I knew the forward rate. Suppose, suppose I, uh, suppose I had a bunch of bonds. So polls, I had American bonds, bonds, um, coupon bonds.

Speaker 3:          00:15:53       Okay. And so the American coupon bonds are going to, are, you know, they're going to pay, you know, the one year pays a coupon c one and has a face of a hundred and has a price high one. The two year American bond has a coupon seed to a face of a hundred and a price of Pi two. And let's say the five year has some things see five phase of a hundred and the price pie five. Okay. Now from that we know that we can deduce, you know what all the forwards are. We did that in the first class.

Speaker 1:          00:16:29       Okay. So now suppose at the same time we have Argentina,

Speaker 1:          00:16:35       were there many Argentine sovereign bonds promise payments and dollars by the way, they're trying to trade them internationally. So let's say Argentina, we also have the Argentina bonds. See Hat one a hundred pie hat one that's the one year down to the five year, which is the Argentina see had five a hundred and p hat five by had five it's price. Now let's suppose that um, Argentina could default whereas America can't. So it's quite likely that pie one will be less than the American pie one and pie five is going to be less than the American pie five because all these bonds might default. So if the coupons were the same, if you see one hat was the saying, the c one and c five hat was the same as [inaudible], the fact that Argentina could default obviously would mean it's bonds would trade less for the American ones. So the question is, can you figure out the default probabilities very quickly in Argentina without having to do a lot of complicated calculations? Well one thing you could do one thing and the answer is yes. And why is that? Because you could take this data and you could say, so we can just erase this here. We could say assuming

Speaker 3:          00:17:57       no default, um,

Speaker 1:          00:18:02       we could explain these prices.

Speaker 2:          00:18:07       Okay.

Speaker 1:          00:18:07       These prices by finding, just like we did in America, the Argentine Argentine forwards.

Speaker 2:          00:18:17       Okay.

Speaker 3:          00:18:18       Forwards one plus I hat zero one plus I hat forward one and one plus I hat forward for.

Speaker 1:          00:18:31       Okay, so these are the Argentine forwards. Now these four words would be much bigger than the American forwards. Why is that? Because the prices in Argentina are so much lower. If you're assuming there's no default assuming no default contrary to fact, how could you explain all these very low prices where you must think that in Argentina they've got very high interest rates and very high forwards. So the discounting more and that's why they've got lower prices and we know how to get those forwards. Assuming there was no default. So the trick I'm merely pointing out now is that if we now go back and say, Aha, Argentina doesn't have different Ford's because anyone in Argentina, the bonds are denominated in dollars precisely so that people can be crossover investors and American can put his money in Argentina or an Argentine can put his money in America.

Speaker 1:          00:19:24       So you can move your money to either place. So it must be that the forward rates can't be different. If you knew for sure you're going to get paid in Argentina, you'd have to have the same Ford rates in America. So the reason these forward rates are higher is because there's a chance of default. So what is the chance of default? So I claim the chance of default is, and I was supposedly, you're supposed to realize this now, if I'd been clear before you would have gotten it, he would see where I'm going. The chance of default is incredibly simple to find out. So it's one minus d a t

Speaker 3:          00:20:03       equals what?

Speaker 1:          00:20:07       Okay. But in terms of Ford's is what? It's not pie. This pie, this isn't the zero price. This is the big price of the bond. So it's not pie hat t over piety. What is it though?

Speaker 2:          00:20:26       So,

Speaker 1:          00:20:38       okay, this is going to be a bigger number than that. And the fact that ratio is the default probability.

Speaker 2:          00:20:46       Okay,

Speaker 1:          00:20:51       so, so this is assuming, remember that if the Argentine bonds defaults at this period, say it's never going to pay anything after that, you're going to get zero payoff and all the other barns, Argentine bonds will also default. I claim that this is going to be the, uh, this is the easy way of getting the default probability. And so the differences in the forwards is just explain by the default probabilities. And so the extra Argentine interest, if this is a higher number than that, you know, this is approximately one minus d is approximately one over one plus the, which is, and so it's basically, you know, this is very close to that. Basically if d, if all the numbers are IMB or small than I, F t minus one is approximately I f t minus one, the American one plus this default rate in Argentina. Okay. So I should probably have a hat because what I'm referring to Argentina with the hat.

Speaker 2:          00:21:50       Okay.

Speaker 1:          00:21:52       All right. So why is that true? I just argued and how could that possibly be true?

Speaker 1:          00:22:01       Okay. The week. Okay. So you see what I'm claiming that you have now a very simple algorithm for finding out, inferring what Argentina default rates are. You can just, again, I'm making a special assumption that when Argentina defaults, you get nothing. That really isn't the case. There's some huge convention that happens in all the countries get together. They defaulted on, they've got some big meeting and you know, someone like Brady invents some idea will, they'll old less than there'll be a writing down of principle by the way. So whenever this happens, there is recovery is recovery, uh, after, uh, writing down of principal. Okay? So what all the countries do as they say, okay, we know you can't pay all that you owe us, we'll settle for half of it. We'll write down the principle and we'll hold you to that half or to a third of it. Okay. And so this is one of the things we curiously haven't done in America where all these homeowners can't pay and we don't write down their principle. We just throw them out of their houses. But anyway, let's say you wrote the principle down to zero and that special case, you could easily infer from the price of the Argentine bonds what the default probabilities were and by this formula. And so the question is why is that true?

Speaker 1:          00:23:17       Okay? We know how to calculate the forwards and America given the American data. That was one of the first things we did in class. We said that every American company in the whole country financial company is doing that. Everybody has those four words calculated. Okay? Now, if you give them the Argentine data, which is after all just coupons and the prices of the bonds, you could find Argentine forwards assuming there's no default. But that of course, but, but, but there is the fault. So it must be that they, there are, they have access to the American interest rates and forwards. But the Argentine mine bond might default. But you see what we did when we did this calculation, the difference between the backward induction in America from here to here was just discounting by the American forward. Okay. To go to Argentina, we had to discount by the American Ford and multiplied by one minus d. So discounting it again. So all I'm saying is that in the u s one, we went backwards. We just discounted by this thing in Argentina, when you go backwards, you have to discount, buy this thing.

Speaker 2:          00:24:26       Okay?

Speaker 1:          00:24:31       So those things have to be the same. Okay? So the Argentinian discount is like taking the, uh, um, I hope I haven't got the thing, see, the American Ford's is going to be less than the Argentine Ford's. It's going to be like that.

Speaker 2:          00:24:48       Okay?

Speaker 1:          00:24:51       Okay. So that's it. There's nothing to, uh, else to show except that whenever you're going backwards here, you're discounting. Remember you're discounting by the, uh, you know, the, the, the interest rate times the probability that you're actually going to pay off. And so that's what it is in a Argentina.

Speaker 2:          00:25:11       Um, hang on.

Speaker 1:          00:25:16       Hope have an inverted one of these. Uh,

Speaker 2:          00:25:22       okay.

Speaker 1:          00:25:23       Yeah, exactly. So if you write one minus d times the American thing in the denominator. So as I said to to, to do the disc carrying in Argentina at every step, going back from here to here, what did we do in Argentina? We simply took one minus d that was the default rate hat in Argentina and discounting it at the American forward.

Speaker 1:          00:25:45       Okay? So that's what I did here. So if I take one minus d hat, you know, multiplied by one. So I take one minus t hat multiplied by one over this. Okay? I just get one over the Argentine discount and that's how we calculated. That's how we went backwards with our recursion. Just taking the interest rate, the discount one over one plus I times one minus d and that's how we discounted going backwards. And so therefore in Argentina, if you're forgetting that there's default and you're just thinking you have to discount at the right rate and you're getting this discount, you're getting this number. But in reality you should have been taking this divided by that. So therefore figuring out this and knowing that tells you what this has to be. So it's extremely simple to deduce what the market thinks. Argentinian default probabilities are year by year. If you make the ad to the assumption that once they default, they default completely. And if you think you're only going to get a little bit back, well then the calculation won't change that much. Okay. Yeah.

Speaker 1:          00:26:51       Yeah. So you could also do it by using the price of Zeros, but to me the best thing is the, the easiest thing is using the forwards, but you can also do it by zero. Okay. So that's all I wanted to say. All right, so and, and, and as I said, the one last thing to say is that if these numbers are all small, then one minus one over one minus D or one minus d one minus D is approximately equal to one over one plus d. Okay. That's if d is very small, those are practically the same things. And then, you know, if you multiply one over one plus d by One over one plus I, it's almost one over one plus d plus Psi. So it's almost this thing, it's not quite true, literally true. But it's very close to say that the gap between Argentinian forwards and American Fords is just the default probability in Argentina and that that reason is why it's called a default spread. Okay. You just add some spread to the interest rate and you've pretty even, so you can guess by the spread what the probability of default is. If it's a 6% interest there and a 3% interest, you know if the 8% interest there in 3% interest here, somebody must think the probability of default is 5% there. That's it. Okay,

Speaker 1:          00:28:09       so let's now move to a tree where you have to make decisions. So I'm going to now describe the method of backward induction, which occurs over and over and over again. And we've used it a couple times, but not in its subtlest form. So backward induction, a backward induction. Okay. Now who first invented the idea of backward induction? Well, the first person who spelled it out formally was Armello who's a in 1910 I think that's within a couple of years, a famous mathematician Frankel's or mallow axioms. And he proved that chess, that there is an optimal strategy. There is an optimal strategy strategy in chess by backward induction.

Speaker 1:          00:29:08       Okay? So for example, let's take a game. So we always are on a tree, but now we're going to use a slightly extended definition of a tree. A tree is going to look like this, you know, there. So it's a root finite number of branches from every, I want to formally define a tree. You know what it sort of looks like. Okay. And there's no reason why the number of branches has to be two or even has to be the same from every point. But the reason we're going to extend it is the, the node is going to be described, is going to describe by who moves. So let's say white is moving here and black is moving here. You know, let's say the outcomes are a win for white. I win for black, a draw or a draw. Okay, so the question is, so it's a to move chess game, white moves first up or down.

Speaker 1:          00:29:59       Then after white moves, black moves up or down, and then the gay man's, and depending on where position you reach, either it's a win for wide, a win, win for black or a draw. So what should white do? Assuming that black is a smart player, what should she do so clearly? Um, so what did Zur mellow do? He said, not only there's an optimal strategy, but you know what the outcomes should be with rational players. So as [inaudible] said, if white goes up, okay, then black is clearly going to go down and win the game. So white ought to be thinking here, if I go up the game of it won't end for another period. It's already lost. So the value of the game is already zero. Okay? So this method of backward induction attaches the value here. We have values at the end, okay? And so to figure out what the right thing to do is buy backward induction, you can propagate the values backwards.

Speaker 1:          00:30:57       If black makes the right choice here, but you know the, the payoff is black gets the negative of white. So the right choices here are a black could get negative one or could get zero. So black clearly wants to get zero. So black could win the game by moving down. So black, surely we'll move down. So I should think of the game is already lost here and pretend that I had a shorter tree with the final valuation of zero at this node. Similarly, if white goes down, it doesn't matter what black does, uh, the game is going to be drawn. So quite should think to himself, the game is already a draw. If I go down and now white has an easy choice, do I want to move to a loss or do I want to move to a draw so clearly white so I could, I could just pick a move for black year.

Speaker 1:          00:31:41       Clearly white is going to go down and therefore with correct play, the game is a draw. So by backward induction, you figure out the correct play. Now why is this surprising? Because chess has an incredibly big tree, not an infinite tree. You know, there are all these rules that keep it finite. If you reached the same position three times, it's considered a draw. If you make something like 50 moves in a row without upon moving, it's a draw. Whatever those rules are. I used to play chess quite a bit, I've even forgotten. But whenever those rules are, they're designed to make the game finite. So the tree is finite and so it's impossible to see the whole tree. And how should you know what to do at the beginning, but you don't know what to do at the beginning too. You know what blacks going to do afterwards and to what could happen later in the tree.

Speaker 1:          00:32:25       But if you were fast enough to put the whole thing on a computer, you could figure out what to do at the beginning because your best move at the beginning depends on what you think black is going to do next, which depends on what he thinks you're going to do after that, which depends what you think he'll do after that. But if the tree ends, you can always go backwards from the end to the beginning and figure out what to do at the very beginning. Okay. So this is a familiar argument to all of you. I think it was a beautiful argument in, um, in chess in 1910 and then it was anticipated, I mean, in, in mathematics in 1910, the chess players of course, all knew about it. So Stein, it, who was a world champion from when to when something like 1870 or so, two or 1880, let's say to let's say 1921 to 1894, I think it was, world champion from then to their Lasker became the champion then.

Speaker 1:          00:33:21       So he wrote a bunch of books and stuff in which he said, you know, there's a backward induction value to chess, but since we can't figure that out on general principles, you can tell by looking at the configuration of pieces, what the right possible move is. And so you can, you can have positional, you know, you can have positional, uh, values. So I'll do that. And then you can have the backward induction values. So for instance, a puddle positional value might tell you that, uh, you know, having a doubled ponds is a bad thing. Having control of the center's a good thing and you add up all those pluses and minuses and you'd get these positional values. And so, um, he said your positional, you know, if you've got the right positional, uh, algorithm, right, positional understanding, your positional sense of what to do, you only need to analyze one move deep. You can figure out what the best positions going to be and move that way. And if we really understand the game properly, that positional thinking, that strategic thinking. So let's call the strategic thinking is going to give you the same decision as the exhaustive analysis of all the possibilities, which is tactical thinking.

Speaker 2:          00:34:36       Okay,

Speaker 1:          00:34:36       okay. So the two should amount to the same thing. Now in fact people can't do the full tactical thing and also they don't have the full strategic understanding either. So they kind of mixed strategy and tactics and that's what makes the game interesting. So no one has ever written this, but I'm sure there's an interesting study to be made about what games are interesting and they must be the kinds of games where you can mix. There's always a mixture of strategy. And tactics in game theory as we describe it and economics, there's no such thing as strategy. All of this is out. It's all just backward induction, which is what I'm teaching you. Um, so the way computers play chess incidentally is, and the guy who invented this is Shannon. Uh, so he's a famous

Speaker 2:          00:35:19       mmm.

Speaker 1:          00:35:21       You know, a famous professor of information systems. So an engineering professor. So he, he said, well, you can't look at the whole tree, which is too long in chess. So what you should do. So all of this extends way further. Maybe you can only look to moves deep. So what Shannon recommend is look as far as you can put it in your computer, apply some positional thinking to evaluate these positions at the pseudo end of the tree. So it's really not a win for white, let's just pretend white so far ahead that we'll call it a win and a loss and a draw on the draw. You know, that's just my looking at positional values and then having a sign those terminal nodes values. Now by backward induction, you can figure out what the value is here and exactly what the right first move to make is.

Speaker 1:          00:36:07       And then after whites move, black will come here. Black can now look to moves deep. So blacks going to look from here all the way down here. He's going to do is positional evaluator to these nodes and try and figure out what they're worth and then do backward induction to figure out what his right move is. Anyway, that's basically the idea of all chess algorithms. And then they've gotten refined by saying, why don't we throw lots of refinements? So I used to be very interested in this. I don't think I'll talk more about it unless anyone wants to ask me something. So there's the origin of backward inductions are mellows, uh, proof and uh, you know, it's obviously a big deal in chess and the chess players all knew about it before as a Merrill low, but they didn't write anything down. His formulas are mellow. So how does this apply to everything we do in economics? Why? I want to give a series of examples culminating in market examples, but starting off a little far from life. So the first one I want to give is the red and the black.

Speaker 1:          00:37:08       So then there's just two games. This is the first one I invented 10 years ago, but I don't think there's any way. I think there they aren't that original. I thought they were when I invented them. But anyway, so the red and the black, it works like this. There's a deck of cards, 52 cards, deck of 52 cards and you can um, someone offers you. So half of them are 26 read, right? And 26 black, which is all I care about the cards and someone offers you a game and they say, okay, the decks upside down, they've been shuffled. You can turn over a card and if it's black, I'll pay you a dollar if it's red and you have to pay me a dollar. So I'm offering you this chance to play this game. And of course, um, you know, you can quit whenever you want to. I can't keep forcing you to play. So anytime you want to, you can quit. So that's the game. Uh, can stop

Speaker 1:          00:38:07       whenever you want. Okay? And once you drove a car and you throw it away. And so I'm, all these examples are going to be examples of stopping games. And you'll see an economics that, you know, when you prepay on a mortgage or when you call a bond, you're stopping the thing. The contract's ending. I mean, your life is going on, but that contract is ending. So want to know when's the right time to take an action like that. So red, black is a simple game like that where you turn over a card, you, if it's black, you're in the black, you win a dollar. If it's red, you lose a dollar and you can stop whenever you want. So you have an option. So I call this an option and most people totally underestimate the value of options. So let's just figure out how to figure out the optimal thing to do. What would you do in this game? Would you play if I gave you the chance to play? I think we did this on the very first day. Yes. You're about to say something. Your hand twitched. I thought, yeah,

Speaker 4:          00:39:12       I was going to say.

Speaker 1:          00:39:29       Okay, so we're, I'm not, I'm going to now disagree with what you said, but it's very interesting what he said. He said, look, if you draw a card at the beginning, it's 50 50. Whether you're going to win or not. If you win, you get a dollar. If you lose, you lose a dollar 50 50 chance. You know, if you're a little bit afraid of if a full dollar loss is more important to you than a dollar game, that's a bad, you don't have that, that's the right away. It's not very good. Uh, not very good odds. I mean, it's barely even. Okay. And if you're a little bit risk averse and it's barely even, you shouldn't play. Okay, but now is it really barely even this game? Yep.

Speaker 4:          00:40:08       You should play it because even point you might as well,

Speaker 1:          00:40:22       right? So you can't possibly lose, if you play this right, you can always go to the very end of the deck. We're ignoring, you know, good point. We're ignoring your utility of time. She can always go to the end of the deck and assure yourself of zero. So this is actually a pretty valuable option to be able to stop. Like he says, you can stop. Uh, if the first one's black, you could stop and then you've won a dollar. If the f a whole bunch of them are red and you lose while you can always go to the end of the deck and get zero so you're never going to lose and you have a chance of winning. So obviously you should play. Even if you are risk averse, um, you should play. And, but now the question is, can we tell exactly? Suppose your risk neutral, how many dollars do you expect to win?

Speaker 4:          00:41:04       Okay.

Speaker 1:          00:41:05       Would you guess?

Speaker 4:          00:41:09       Yup.

Speaker 1:          00:41:11       You'd expect to get zero. Okay. Now he just made an argument that you should expect more than zero because for instance, he said, take this strategy, pick a card. If it's black, you went into all or quit. You're a dollar. I had. So with 50% of the chime, you're plus a dollar. If it's red the first time, just close your eyes and play to the end of the game and you're going to get zero because you're going to win 26 times and lose 26 times. So that's equal to 0.5. So there's one strategy that gets you 50 cents on average, you can't lose and half the time you'll get a dollar. But that may not be the best strategy. Yup. Right. Okay. So he's saying, you know, this is an ambitious enough, this surely gets half a dollar, but you could do much better. Like let's just wait. You know, the first time, suppose you get a dollar, suppose you get black the first time. So that gives you a dollar. Now the trouble is the deck is starting to turn against you now it's 25 blacks in 26 reds. So what would you do then? You'd stop or keep going.

Speaker 4:          00:42:31       Okay,

Speaker 1:          00:42:31       well the, the, the deck is against you. So now your very next draw is unfavorable. And by the way, playing till the end of the deck is going to lose you a dollar because they're 25 black and 26 red. So this argument that if you just played at the end of the deck, you'll break even. It's not true after you've already taken a black one out so you could lose it. You know from that on, you're starting to run a little bit of a risk. So we're ignoring risk aversion, we're just caring about expected dollars. The fact is the deck is against you, so should you play or not? And so a first reaction is, hell no, the Dex against me, why should I draw another card? But you still have the option of going to the end of the deck. So the most you could lose is a dollar.

Speaker 1:          00:43:12       If he went all the way to the end of the deck. And who knows? Maybe you'll get a run of more black cards in the beginning and make a lot more than a dollar. Okay, so you should choose another card. Okay. In which case if you get black again, if you've got red on the next card, you'd be breaking even. But now it's 24 20 sorry, 25 25 and by the previous argument, it's obvious you should pick another one because the worst you can do is break even from then. But what if you got two blacks in a row? Well now the deck is way against you. It's 26 red and 24 black. So your, you know, now you've only got a 48% chance of drawing a black when the next time the deck is going further against you. Should you really draw another black card?

Speaker 1:          00:43:58       It seems another card, it's, you know, it's more likely to be read. Well the answer is yes. And suppose you got a black one again, meaning your three up and now the deck is 26 23 sorry, I went the other way. 26 red, 23 black. It's getting further and further against you. Should you draw another card? Well, what you've got is you've got a bad deck working against you, but you've got this option or working in favor of you. So the question is how valuable is the option? And Mike, I said people always underestimate the value of options. And so, okay, go ahead.

Speaker 4:          00:44:41       Option A, is there any loose condition is a either bounced out or worse than your wind conditions?

Speaker 1:          00:44:47       Yes. But what is that condition?

Speaker 4:          00:44:49       13 months

Speaker 1:          00:44:51       you would take, you would, if you got 10 blacks in a row, you would keep drawing blacks. Is that what you're saying?

Speaker 4:          00:44:58       Well, I mean at that point, if you see that, that's awesome. I'm assuming that you just pick another red and then put up the end of the game. You could lose, uh, would it be

Speaker 1:          00:45:08       13 more? So you're saying you want to keep drawing blacks until if you played till the end of the deck, you would lose as much as you'd want up until that point. So you want are never run the risk of losing money, of losing more. Okay. Do you see that strategy would get you to quit after the first one? After the first black, if he ran to the end of the day, uh, you know, your strategy doesn't make sense. You're always going to, by going to the end of the deck, you're always going to undo everything you've won until that point because you'll be zero no matter what. If he'd go to the end of the deck,

Speaker 4:          00:45:41       yeah, she did. You quit. Whenever you have more black cars, their red card number of black cars

Speaker 1:          00:45:54       dec is less

Speaker 4:          00:45:56       number red.

Speaker 1:          00:45:59       Yes.

Speaker 4:          00:46:00       Whenever we do have one dog,

Speaker 1:          00:46:01       no, that's it. So he's saying just the common sensical thing. After you draw one black card, he would quit because now the deck is against you. It's 25 red and only 25 black. The dex against you. Why go on and play against an unfavorable deck. You've got your dollar be satisfied and quit. That's his recommendation. But that's wrong. And it's because you're doing what everybody does. You underestimate the option. The option is incredibly valuable here and now I just want to show how to compute what your optimal strategy is and I think you'll be surprised. Okay, you should keep drawing. Not three times if he got a fourth black card. Okay, so you've already made $4. It's a sunk cost. You've got this horrible deck. It's 26, 22. Should you keep playing? Yes you should. Yes you can. If you've got, if you get a fifth black card in a row, you're up $5. The deck is horribly against you. Should you keep playing? Yes, you should. So anyway, um, it's really shocking, I think. Okay, so now let's just see how to compute this out so that we don't have to argue about it. It's just a little bit of mathematics and you just see how a surprising this calculation is. So how would you do it?

Speaker 1:          00:47:32       Okay, well, the key is to figure out how to put it into a tree. So I'm not going to draw a picture because it gets too complicated, but basically what you want to know is how valuable. Remember the tree in backward induction? It was. Take the thing at the end and then figure out at the beach by propagating the values backwards. So if I have black and red here and I've got one black card and no red cards, the value to me of that is what I'm going to win a dollar for sure. If there's only one black card left in the deck and no red cards, I know I'm going to play to the end and get a dollar. And obviously the value of two black cards, no red cards is $2 et cetera. And I also know what's the value to me of no black cards.

Speaker 1:          00:48:22       And one if I know that there are no black, you know, you know what every stage what's left in the deck. Cause you've seen what came up before. So if they're, if you're at the very end of the deck with no black cards and one red card, what's the value of that position to you? Zero not minus one zero. Why is that? Because you're going to quit. You're not going to play the value. And that's the critical step seeing that this is zero. Okay. Someone said minus one that difference between zero and minus one. That's the whole heart of the thing. So zero one, two, the value of that is also zero. You're just going to quit. Okay. So what in general is the value? What is the value of v if there be black cards and our red cards? What's the value to you?

Speaker 1:          00:49:09       Well, crucial step is that you can choose to quit by not playing. So this is the value from then on to you be, you know, so be black cards left for red. Our red cards left. You could get zero by quitting. Okay. Or You could draw a card. Now what happens to you if you draw a card? What happens to you if you draw a card? Well, with probability be over being plus art. You win a dollar, right? But then you move on to the new deck. And so what do I write? V here? V of B minus one. And are,

Speaker 2:          00:49:58       okay.

Speaker 1:          00:49:59       Okay. But with probability are Overby. Plus are you drew a red card. So it's minus one, but then you move on to a deck that has one less red card and that's it. You either decide to stop or if you've decided to draw a, you know what the chances of getting a black card are. You look at the black cards, 26 out of, you know, if I'm, I'm, I'm down there, it's 21 out of 47 sounds horrible. 21 out of 47 I win a dollar. 26 out of 47 I lose a dollar. So the immediate draw is terrible. But if I get a black card, I moved to this situation and if I get a red card, I moved to this situation. Okay. So that's clearly, okay. So do you agree with me that that's what the value is going to be? And so if you look at, okay, so now, okay, is there any questions? This is a critical formula. How critical spot does everyone, it's Sophia be here now in trouble. Somebody came and said hello to me after class and now I know her name. So just this formula makes sense.

Speaker 2:          00:51:21       Yeah.

Speaker 1:          00:51:22       Kathleen? Yes. Is it Katherine or Kathleen? Catherine. Okay. Catherine, you, you, so you agree with this formula, right? Okay. But this formula is the key is just like our tree. Once you know what the values are down here, you can always go backwards and figure out the value here. Okay. So, um, uh, you know, so what is the tree the tree's going to have? Well, I'm going to draw it on a, I'll do it on a computer. So now he can just do the sonic computer.

Speaker 2:          00:51:59       MMM.

Speaker 1:          00:52:01       I hope I don't have to do that. Okay, so you have this by the way, and your, uh, it's on the web. Oh No.

Speaker 1:          00:52:17       Why are all these, okay, the red question mark. Okay, so here it is. So you can see that on, on this. I can do it with this on this thing. It's, by the way, this was, uh, uh, I did my own spreadsheet and an undergraduate last year thought it was so messy that a, she just, we did it for me. So this is her doing, it looks much better than I did. So anyway, here are the number of cards. This is what the number of black cards left. This is the number of red cards left. And the, and then when you go to the, you know, the corresponding coordinate like this one, this is the value of the game. When you have one black card and one red card, it's a fee. Even though there's an even deck, it's a favorable gain to you. Why is that?

Speaker 1:          00:53:01       Because you draw the first card. If it's black, which happens with probability, 50% you win a dollar. So you've got half a dollar. If it's red, which happens with a 50% probability, you can draw the next one. And so you end up with zero. And by the way, if he got a black the first time, obviously you stop. So you get 50% chance of a dollar and stopping or 50% chance of going to the end and getting nothing. So it's value 50% but that's a bad way of that number. She's got a much better way of calculating it. Okay? So what she said is if this is the, uh, if you had, you know, no red cards and only black cards, the value is to go to the end of the deck and just win them all. Okay. So if you've got only red cards in the deck and the top line is no black cards, obviously you should quit right away.

Speaker 1:          00:53:45       So we've got this first thing trivially done. Now how do you figure out this thing? Well, if you look at the formula up there, it's just the formula you wrote, okay? We wrote, which is you could quit if he wanted to. So you have to take the Max of zero. But if you go on and draw, I can't read what's written there. If you go on and draw, there's is going to be, you know, the probability of red, okay? This is the probability of getting a read over the total number of cards. Times losing a dollar, okay? Plus what happens is you then move. If you do red, then you go to, um Oh, what did she do?

Speaker 1:          00:54:33       C four we're almost seeing forest here, okay? Right? So, sorry, I was getting confused with the car. And so c four is this squared. Okay? That's the value in here. So see forces, if you draw a red card the first time it happens with this probability, the number of reds over the total number of cards, you lose a dollar and then you move to the position c four which is one back here, the one where you've got one less red card and just the black card left. Okay. On the other hand, you could have drawn the first time, not the red one, but the black one. Okay. Divided by the total number of cards. And he would have won a dollar, but then you would have moved to the position where you had one last black card, which is d three which is up here.

Speaker 1:          00:55:11       Okay? So instead of doing the whole game, she says half the time you win and are half the time you win. But then you move over to here and get that value. Half the time you lose and then you lose a dollar. And when you move over to here. So she's done that. That same formula appears in every box. So all you had to do with just copy it, you know it's Max's and euro. And then the chance that you're going to lose a dollar, which is the number here of red over the total, it's times minus a dollar and then moving over to here. Or You could get the probability of winning a dollar with the black cards and then, but then you would end up see when a dollar and then even, but then you move up to here. Okay, so it's very simple now the, okay, so, so, okay, so she's done it and notice that all of Overdeck is even at one party each. So it sounds like a fair game. It's not. It's a favorable game because you have an option. So you all understood that. But the thing is the option is much more valuable than you think. So let's see what the value of a game is. Okay? It's when you had 26 black cards and 26 red cards. We have to go way over here.

Speaker 2:          00:56:16       Here. Sorry. Where am I going? Not the right answer.

Speaker 1:          00:56:24       Okay, here it is. 26 26 the value of the game is $2.60 not just half a dollar. You wanted to quit wherever you are at half a dollar. It's not looking up anymore. So you want, so you wanted to quit with a hat. You don't have to the first draw, okay? But it's much better than that. So now what the shocking thing though is so poll. So this means with 26, 26 you can, you have a favorable gaming, you should draw. If you didn't draw it, be worth zero. So obviously you're supposed to draw here. If you get a black card, you're going to go here. So hearing your down, you've gotten a card and you've got one more. Uh, you know, it wasn't that likely you're going to get black. But if you did 50% chance, you go here. So you win a dollar and now you're at this position.

Speaker 1:          00:57:09       Now, if you were supposed to stop, you would have a, if you're supposed to stop at that point, what would you have done? If you're supposed to stop at that point, you would have had value zero. So the fact that that number is positive is telling you, even when the deck is against you, 25 you can't see it. It's 25 blacks and only and still 26 reds. It's still a favorable game. You should draw a card and if by some miracle you want a dollar, you would have moved to here. So now you're 26 red in 24 black, but the game is still favorable. You should draw another dollar. Another, sorry, another card. Okay. And if you win again, you're here. Now you've gone one, two, three times. You've drawn blacks and you should still draw another one four times getting blacks. You should still draw another one, five consecutive black draws the card.

Speaker 1:          00:57:58       The deck is now 26 against you and 21 in your favor. You should draw again, the game is still slightly favorable. And uh, it just seems shocking. That could be the case, but this is the proof that it's the case. So anyway, that illustrates the power of the option of being able to continue. And if we, and if you work, you're going to work out low numbers two and three in the homework, and then you'll see very clearly why it is that this option is just so powerful. It's uncannily strong. So there are any questions about this? Yes.

Speaker 5:          00:58:29       Um, I'm still a little bit confused. I didn't know that the ocean by those probabilities guys pretty is a little bit against you, especially when you, after five weeks, why do one another? Yes. The option by that is a little bit about it. Let's do it again. Yeah.

Speaker 1:          00:58:50       This isn't the option value and this is the value of plain. Okay. So it says the option value is bigger than the more important than the fact that the cards are against you. So he's asking, my ta is asking how could it possibly be that the deck is now 26 red in 21 black totally against you. And according to this calculation, you should still draw. He can't see the advantage in drawing because the odds are pretty high. You're going to get a red card time. Okay, well that's true. You're going to get a red card next time. But the thing is, your downside is limited. You can never, here's a way of thinking about it. You can never, you're up five cards. You can never lose more than $5 from that point on because you can always play to the end of the deck, right?

Speaker 1:          00:59:40       Which means you, you, you lose the five back that you already won. So there's a downside. The downside of losing is limited. Here. On the other hand, there's a big upside to you. You might by some miracle draw, um, 10 consecutive black ones at that point, and then you could quit. Okay? And then you'd have a big, so your upside is much bigger than your downside. Now, the upsides less probable than the downside. So it's not so obvious, which is going to be bigger. Is the option value more important or is the fact that the deck is against you more important? It would be impossible to intuit the answer, but we don't have to intuit it. We just proved it. We've solved for the optimal strategy. Are there any other questions? It's quite amazing, right? This, uh,

Speaker 2:          01:00:26       okay.

Speaker 1:          01:00:27       I'm going to pause for a second. Yes. Okay. That's what we just did. So let's try it again.

Speaker 1:          01:00:45       Okay. So what we did this, number V is the expected profit you're going to make if you start with B black cards and our red cards. And now the intuitive mind figures that if B is less than our, you've got an unfavorable deck and you should just quit. Okay? But that's not the case. You can figure out what the profit is, how by doing backward induction, you couldn't tell what the value of this bond is here with all these defaults and stuff until you started computing backwards till you got to here. So the same way here, we know at the edges it's very obvious when all the cards are black or all the cards or, or a red that's up here. It's obvious what the value is. But if you have a position here, you can figure out what the value is of being in that position of one and one.

Speaker 1:          01:01:36       You could quit and be zero. Or You could say, what am I chances of getting a black card and winning a dollar if I get a black card, then I moved to this position, but I already figured out this position's value cause I'm doing backward induction. Right? That's got one less, um, sorry. If I draw a black card, I go this way, it's got one less black card and we already know that valley, that position is zero. So to figure out the value of this position, I know the chance of getting a black card. Then I'm going to end up in that position, which is value zero. Okay, I won't draw anymore or I'm going to get a red card and then I'm going to move to this position over here. Who's value I've already computed. Okay, so that gives me the value here. How do I figure out the value here?

Speaker 1:          01:02:16       Well it's now two reds and one black, so this looks really bad. Actually, this position, the value of this I happen to know is zero. Okay? How could it be with two red cards and only one black card? Actually the value of the position is zero. Well, what do I do? The chances of getting a black card the first time or a third. So via one, two is going to be a third. Okay. I'm getting a black card plus then I go to here, which is no black cards left and just red cards. Okay. Which obviously is zero plus two thirds. Okay. Two thirds of the time I get a red card and lose a dollar. But then I'm going to move to here with one red card where I have v of one and one which I've already figured out the answer to. Right. This was v of one and one has value a half. Okay. So therefore we have one and two is going to be two thirds times minus one plus v of one to write. I just drew a black card. So it's no longer,

Speaker 1:          01:03:15       no, I drew a red card, so it's one and one. So I started with one black and two reds. A third of the time I get a black card. Two thirds of the Times I get a red card. But after getting the red card, the position is now one black and one red or red card disappeared. That's over here. Okay, so you get a black card. I moved to here. We know what if I get a red card, I moved to there. But v of one lawn is worth a half. So that's equal to one third times one plus zero plus two thirds imes minus one plus a half. Okay? Which equals one third minus one third, which equals zero. Okay? So starting at this point, you've got one red card and two black cards. It looks horrible to pick a card. Two thirds of the time you're going to get the wrong card, but you're still have a position that's actually equal in value because if you get that a black card, which wins, you stop.

Speaker 1:          01:04:12       If you get a red card, you're now in a position that's equal deck and the deck is fee that's favorable for you because if you get another black card, you stop. And if you get a red card, you keep playing until the end. Okay? So, um, uh, okay. So that's it. So how can you do this by backward induction? You have the stuff on the edges and then you, you solve for all these things along the side here. And having done that, now I can solve for this one cause I've got up into the left and I do that whole row. Then I can do this whole row and then I can just do I back introduction to the whole, you know, the whole thing. And the computer does that instantly. So it figures out the value of every single node and it's shocking with the answer is so there any other questions about this?

Speaker 2:          01:04:56       Hm,

Speaker 5:          01:05:00       Ben, you, so I, I tell you initially taking care about it as well. I imagine you stay till the end for, you could choose to play in this game and after your wing are you living, then you'll

Speaker 4:          01:05:18       get the option that's continue with the game as a separate that option.

Speaker 1:          01:05:24       Well that is your option. The option is always to keep playing or to stop. Okay. So let's, let's just do, and with the value I wrote down, is the value of the game to you of being able to play the whole game however you want. Okay, so now let's do the, let's do another example. Yes. Right? So if you got it,

Speaker 4:          01:05:51       is that, my question is, is it preference to risk or is it actually the rationality?

Speaker 1:          01:05:56       Right. So this is going to become very important very shortly. So his question is, I just proved, you know, if you can call that approved by computer, the computer proved that even if you got five blacks in a row, you should still draw another card. Of course things are quite risky now because you know there's a very good chance you're going to lose on that very next card. So he's saying if you're risk averse, maybe you would stop there. And how can you distinguish somebody who's risk averse from someone who's just dumb and can't make the calculation? So we have to, so that's going to be a question we're going to take up in the very next class. But I would say that it's usually because people are dumb and can't make the calculation. So they just don't realize how valuable, how favorable the situation is they're in by having this option to be able to play to the end of it, to stop when they want to stop. Okay. So let's just do one more example. Suppose that you, um, suppose that you are undergraduates and you want to get married. You've been told that's a good idea and you, it's going to be very a sexist thing. But anyways, also a game I invented, which turned out not to be

Speaker 4:          01:07:09       okay.

Speaker 1:          01:07:11       As original as I thought. Uh, so I call this the optimal marriage problem. So,

Speaker 4:          01:07:18       okay.

Speaker 1:          01:07:18       So let's say you knew you were going to meet a thousand women. You're taking, telling him from the guy's point of view,

Speaker 4:          01:07:26       okay,

Speaker 1:          01:07:27       you're going to meet a thousand women. Okay. 1,000 women and each woman you meet her suitability. You can't tell until you meet her and talk to her. And after you meet her, uh, each woman's suitability, each suitability is he uniform lead distributed

Speaker 1:          01:07:52       on zero one. Okay. So what do I mean by that? I mean you meet or you talk to her, you get to know her and then you just draw, you know, and so when you, before you met her, you have no idea how suitable she's going to be after you've talked to her, you understand how suitable the best is. It's one the worst at zero. And it could be a draw anywhere between zero and one before you meet her. You have no idea. After you meet her, you know exactly suitable she is and they're going to be a thousand of them that you're going to meet. You couldn't meet. Like the problem is that after you've talked to him and you can marry her then, or if you move on or you can move on, but once you've moved on, you can never go back to her. So the question is, um, so you understand the problem. The problem is that let's say the first woman is 0.95 or 0.9. Oh you think, Gosh, how suitable this is a great match. But you know, I've got 999 more women to go. Maybe I'll do better. And then you get Zeros from then on. And so you've missed your 0.9 and so you're not going to, you're going to end up marrying the last one who's maybe a zero for you. That doesn't mean she's a zero just for you. A zero. So I trying anyways.

Speaker 1:          01:09:13       Okay, so what should your optimal strategy be and are you playing the optimal strategy? So what do you think? You know, just intuitively, what's the optimal strategy? Of course we're going to do it by backward induction, but what do you think it's going to look like? The optimal strategy. Yes.

Speaker 2:          01:09:32       Yeah.

Speaker 1:          01:09:32       Right. That is the actual, that's what's going to happen. We're going to prove this, but he's, he's exactly picked, he said, you set a threshold here at the beginning. You know, you'll marry her if she's above some number. You keep to that threshold for a while and you haven't married anyone. You'd say, Oh my God, I'm running out of women. And then you're in standards just collapse. Okay. So it's best for patients. That's it. Okay. So that's absolutely right. But the only interesting thing is to figure out how high the standard should be. So how high do you think it is at the beginning?

Speaker 2:          01:10:08       Okay,

Speaker 1:          01:10:08       what would you say the number is at the beginning?

Speaker 2:          01:10:12       Okay.

Speaker 1:          01:10:13       Okay. Now let me give you a hint. Uh, if you divide up. Okay, so there's, here's one and there's a thousand women. So here's zero, okay? So they're randomly picked. So if you could look at all the women and see and pick out the most suitable one, what would her suitability be? Well, her suitability would be, um, her suitability. So top the top on average will be something like a thousand, over 1,001. Okay? This is a famous problem. If you take and people randomly, uh, you know, you take any numbers, you pick random when uniformly in zero one, the top one on average is going to be, if there's a thousand women, it's a thousand over a thousand. One second top, he's going to be 999 over 1,001. So this very standard statistical result actually was derived by a, by a former professor and World War II. The Americans captured German tanks, which had all their serial numbers on them.

Speaker 1:          01:11:19       And uh, you know, they see the first tank was number one, the second tank was number two. The third tank they made was number three. So we captured a bunch of them. And then we had to guess how many tanks did they make. Anyhow, so the, so it's related to this, uh, to this idea that if the uniformly distributed on zero one the top one's going to be on average a thousand or 1,001, nine 99 or 1001, et cetera. But now you've seen, so, okay, so where, what standard would you set for the first one? Right? You have to set some threshold here. You know, here's one, and here's zero. By the end you'll take any, you know, but the last woman you've got, you're going to take her no matter what. So what, uh, what should the threshold be? Well, it's hard to tell. We can't do it except by backward induction. So what would you guess?

Speaker 2:          01:12:06       Awesome.

Speaker 1:          01:12:07       One we're then you'll never take or if it's one, because the odds of getting exactly one r zero. So what would you guess?

Speaker 2:          01:12:14       Huh?

Speaker 1:          01:12:15       So you'd set the threshold this high, a thousand over 1,001. Okay. So that means you're expecting to get as good a woman is. If you could go to the very end and look at all of them, you never make a mistake. I told you there's a chance you'll make a mistake. The first one's the best. It doesn't quite come to your threshold and all the rest of their worst. Then you end up with a disaster here. So you know you, you, you, you know, so you, you have a chance of not doing that once your, you're setting to highest standard here cause you have a very good chance of saying no to all these women and then ending up with what's you right. Okay. However you're on the right track. So amazingly, this is the answer. This is the threshold. Okay? So you should set the threshold at where you expect the second highest woman to be second highest match to be.

Speaker 1:          01:13:03       And that is why there's so many novels about the other woman. Because if you're playing optimally, you should be ending up with the second best woman and there should be one other woman that at the end of your life you regret that you didn't wait for and, but only one other woman. So anyway, I just, I just want to prove this to you in the same way we proved it before, just by solving for backward induction for the optimal. So we can just do this by backward induction. We know exactly what to do. Okay? So I, you know, it's one thing to say what you should do. It's another thing to prove. That's what you should do. And I'm going to prove it now. So you can just see by backward induction how, how easy it is to do these things. Okay. So it's only, you know, I'm going to have to take four minutes.

Speaker 1:          01:13:48       If you can hang out for four minutes, we'll get this. So what happens with two women left? What's v of to what should you do? What should your threshold be for two, what is your threshold be? For two women. So here's the threshold and we have two and three. Okay? So I'll tell you threshold for one threshold for one woman is zero. If it's the last woman there, you know, you w w whatever she is, she's, you know, it's, that's it. You're going to might as well marry or it's only going to can't be negative. Okay? And then the value I'm carotid is the value of one is going to be a half, right? Because if there's one woman left, you're going to take her no matter what. And on average you'll get a half. So the question is now, what's the threshold when they're two women left and what's your expected payoffs? So what's the threshold if they're two women left, you'll see the second to last woman, you talk to her, you find out how good the matches you should take her if she's above the matches above what? No, there was only one woman left after her. So

Speaker 2:          01:14:57       good.

Speaker 1:          01:14:58       So I have right, because if you don't take her, you're going to go to the last woman on average, you're going to get a half. So there's no point in taking someone who's match is less than a half. When the break, next step, you are an average, you're going to get a half. So your threshold is a half. So what's your expected quality of the match? Well, with probability a half you get, you make you with probability a half, she's going to be above a half. And if she's above a half, she's going to be halfway between one and a half. So it's three quarters. And with probability, uh, sorry, this end with probability a half, she's going to be below a half and you're going to pass on her and go to the last one and it'll be on average a half. Okay, so this is three A's loss.

Speaker 1:          01:15:44       Um, no, probably the half. She's going to be three quarters and probability a half, she'll be a half. So three A's was one quarter is five eighths. Okay. Now what if there were three women, what should the threshold be for three women and what's the value of three? Okay, so the threshold should be v of two, which is five eighths. Okay. And what's the value? The value is going to be, what's the chance that you take the one you just meet? Well, the odds that she's above a half is three A's. So it's three times the average of one and you know, halfway between. So she's above five days. So she's somewhere between one in five days. So that's going to be a one plus five days over to Kate plus five ace of the time you pass on her and then you get five A's. So that equals if we just do that in a little bit more generally it's one minus V two. Okay. So that's one minus v two times one Plus v two divided by two plus V of two times. Um,

Speaker 2:          01:16:59       we have to,

Speaker 1:          01:17:03       okay, so that's what the pro, that's the formula. So for any, so in general v of t hey, you set the threshold at v of t minus one. So with probability V of t minus one you're going to get one plus v of t minus one divided by two and with probability one minus, um no. This is one minus V of t minus one with probability V of t minus one you're going to get, you're going to pass on her and go to the next thing. So you get just v of t minus one. Okay? So that's just a formula. V of t equals some function of v of t minus one. So you can program that into a computer, which is ending. Now with this one picture, that's the end of it. Sorry, I know I've gone over, but this is the last picture and only take a second. So zero yield curve. Optimal marriage. Okay, so here it is. Here's with one woman your your value. Oh Shit. Sorry. With one woman, the value is a half one match to go.

Speaker 1:          01:18:17       Okay? So the number on the left is with one match to go. The valley's a half with two. It's five days with three. We computed that too. So you can tell for however many women you want. Now what I've done on the right number is this, and plus one over. It's an over n plus n minus one of rent plus one. Okay? So that's the second best woman. How how good she'd be on average for you. And as you go down further and further, you see these numbers are getting to be the same. So this number, this number is practically the same. And if you go down to the very bottom, you'll see they're identical, okay? Up to an incredible number of decimal places. You get the, the, the, these two numbers are the same. So if there are enough women, you're going to hear, get exactly the second best, and it's going to be the problem with the other one. But anyway, the point of all this was to just illustrate how powerful the option is. It's as if you could go to the very end and pick out the second best one, even though you have to do them sequentially.