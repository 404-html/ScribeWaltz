Speaker 1:          00:00:01       We've dealt so far with the case of certainty and we've done almost as much as we could in certainty. And, uh, I now want to move to the case of uncertainty, which is really where things get much more interesting and things can go wrong. So I'm going to cover this. Okay. So we're ready to start.

Speaker 2:          00:00:29       Okay.

Speaker 1:          00:00:31       So, so far we've considered as is the case of certainty. So with, with uncertainty, things get much more interesting. And I want to remind you of a few of the basics of, of a mathematical statistics that I'm sure you know. So, you know, we deal with a random variables which have uncertain outcomes, but with well-defined, with well defined probabilities.

Speaker 2:          00:01:08       Okay?

Speaker 1:          00:01:11       Okay? So another step that we're not going to take in the scores, just to say, people just have no idea what the chances are. Something's going to happen. Shiller things we live in a world like that where, you know, who knows what the future's gonna be like, and people, they hear a story and then everybody gets wildly optimistic and then they hear some terrible story and then everyone gets wildly pessimistic, you know? And that kind of mood swing can affect the whole economy. I'm not going to deal with that. It's hard to quantify and I'm not exactly sure it's as important as he thinks it is. So we're going to deal with the case where many things can happen, but you know what the chances are that they could happen. He's still, lots of things can go wrong in that case. So there are a couple things that I, uh, words that I want to you to know, which we went over last time.

Speaker 1:          00:01:56       And I'll just do an example. So suppose we always deal with states of the world. Okay? States of nature that was live, it's his idea. So let's take the simplest case where with probability a half you could get one and with probability a half you can get minus one. Okay? So that's a random variable. It could, you could, you know, it might be how your investment does half the time you're going to make a dollar. Half the time you got to lose a dollar. So he defined the, so this is x. So he defined the expectation of x, which I write as x bar as the probability of the upstate happening. So let's just call that one half times one plus one half times minus one which equals zero. Then I define the variance of X. Okay

Speaker 1:          00:02:43       to be how, what's the expectation of the square difference from the, from the expectation. So how uncertain it is, you know you're sort of on average expecting to get zero. So uncertain it is as measured by how far from zero you are, but we're going to square it. So it's one half times one minus x bar squared plus one half times minus one minus x bar squared equals one half times one plus one half times run jealously equals one. So the variances one and then I'll write the standard deviation of x equals the square root of the variance of x equals the square root of one, which is also one. So very often we're going to use the expectation of acts. That's going to be how good the thing is. And the standard deviation is going to be how uncertain it is. And people aren't going to like soon we're going to introduce the idea that people don't like uncertainty and this is the measure of what they do.

Speaker 1:          00:03:41       Like it, it pays off on average a big number. Say this one doesn't, but it could. And and the, the measure of uncertainty is the standard deviation. I choose that rather than the variance for a reason. You'll see it makes all the grass prettier. But also if you double x, you'll double the um, the expectation obviously because you just double everything inside here. The variance though, you're going to end up squaring the two. If you double, if you double axe, you'll double all these outcomes and the mean. So you'll end up multiplying the variance by four, whereas you'll multiply the standard deviation by two. So we scaling just rescale is these two numbers and as a funny effect on that number. So that's the reason why we use these two. Okay? Now you can take another example by the way, which is a 0.9 times three. Let's call this y and 0.1 times minus something.

Speaker 1:          00:04:42       How about scholars? One third and this minus three. Okay. Now, what's the expectation of why the expectation of why equals 0.3 righty? Well, let's just write it out is 0.9 times a third plus 0.1 times minus three, which you can well 0.3 minus 0.3 which equals zero. So the expectation of this random variable is the same as the expert station of that random variable. And now the variance of this, of why is 0.9 times a third minus zero squared plus 0.1 times minus three minus zero squared, which equals 0.9 times one ninth right? Plus Point one 0.1 times. Um, mine. Okay, which equals 0.1 plus 0.9 which equals one which is the same as the other one. So here we've got another random variable which looks different from this. So clearly standard deviation and expectation don't characterize things. This looks quite different from that one has the same standard deviation, the same expectation.

Speaker 1:          00:06:10       Okay? So we're going to come back to what the differences between these two variables in a second. So there's another thing I want to introduce, which is the covariance of x and Y. Okay? So we could look at the outcomes of these variables. Where am I going to write this? We could look, I'll write it over here. We could look at the outcome of these variables in a picture like this. And so here we have x, and here we have y. So x credit, turn out to be expert. Turn out to be one one. Why is a third okay? And X could turn out to be one one Y is minus three. So here's an outcome and here's an outcome. And acts could be minus one and we could get a third or minus three. So therefore outcomes, which looked at here, okay, so if you looked at Exelon, it's got a 50 50 chance you're here or here. If you look at why alone, it's a 90% chance up there and a 10% chance down there. So those are called the marginal distributions. But the joint distribution, we would have to add a number.

Speaker 1:          00:07:20       So if you looked at x alone, by the way, you would say x alone, you'd say, here's zero, here's one, here's minus one. So you could have this or this with probability a half and a half and why? You know, you could have sold this way with why you could have a third or minus three and here the probability is going to be point mine and 0.1. So that's what we have. Those are the missus zero. Those are the pictures that uh, we started with. Okay, so you know where x could end up and where, why could end up? Well, you don't know where they jointly could end up. So if they end up on the long diagonal, that means when x is high, wind tends to behind. And vice versa, if you, and if you end up down here, x is low and why is low? So to the extent that the probability is on the long diagonal, they're correlated together to the extent that the probabilities on the off diagonal there negatively correlated.

Speaker 1:          00:08:21       So anyway, to get a night to get a sense of that, the covariance is going to be the probability probability of one comma a third times one minus x Bar Times a third minus y bar. Okay. Plus the probability of, I'll just go around the circle of a minus one comma, m a third times minus one x Bar Times, uh, uh, times a third minus y bar. Okay. Plus the probability of m minus one and a third. Uh, sorry, what did I just do? I did minus one, the third. I've already done that. So I'm down here. So minus one and minus three times minus one minus x bar times minus three minus x Bar plus probability of the ordered pair.

Speaker 1:          00:09:32       Thank you. And probability. What's the point? I haven't done yet. One Comma minus three times one minus x Bar Times minus three minus y bar. Okay, so now why does that covariance pick up the idea of correlation? Well, to the extent that the probabilities are high here and over there on the along diag know this term is going to get a lot of weight and um, the what is the other term minus one minus three and this term is going to get a lot of weight. So to the extent that you're on the long diagonal, this term and this term are going to get a lot of weight, but you see those terms, this is going to be positive because it's one minus zero and a third mind is too. So that's a positive term and this is negative minus one minus zero minus three minus you.

Speaker 1:          00:10:19       So negative times a negative is also positive till the extent that you're down here and up there, you're going to get big positive numbers in the covariants to the extent you're on the off diagonal, you'll get big probabilities here, but they all multiply negative terms. This is a minus and this is a minus because one of the terms is above the mean and the other one's below the mean. That's what it means to be in the off Dag. So covariance is giving you a sense of whether things are moving together are moving opposite the opposite way. Okay? So those are the basic things you have to know. And I guess another couple of things are, the covariance is linear in x, right? Because the covert, if you double x, every time you see the x variable over here, it's always an x outcome minus an x bar, an x outcome minus an x bar.

Speaker 1:          00:11:04       Next outcome minus an x bar. Next outcome minus x bar. So if you double x, you're going to double every term. So it's linear in ax, linear, an x and y. And so one last thing to keep in mind is that the variance. So the, uh, the variance of a x is just the covariance of x with itself. Obviously if you just plug in x equal to y, you just get the formula for, for a covariance, okay? And similarly, because they're linear, the covariance of x plus y with it's so the variance of x plus y one more formula of x plus y by linearity. Well, first of all, that's the covariance of x plus y with itself. And therefore by linearity. Now I'm just going to do linear stuff that's equal to the covariance of x with x, okay? And plus the covariance of why with y plus two times the covariance of x with y. So I could take, since it's linear, I could just, okay, I just do the linear parts, right? Covariance of x plus y with x plus wise covariance of x plus y with x plus covariance of Eczema. Swag with why. Then I repeat the linearity thing and I get down to that. Okay. So those are basically the key formulas, uh, to know. Okay. So now I'm going to make three little observations that come out of Alvis that are quite fascinating. So quite elementary. There are any questions about this, these numbers? Yes.

Speaker 2:          00:12:46       Oh yeah, I'm that the probability of negative one, negative one, negative three.

Speaker 1:          00:12:59       Why did we give, say that again?

Speaker 2:          00:13:01       Underlying probability of making one

Speaker 1:          00:13:05       probably have a negative one. Common negative three. That's this outcome. Here. We underlined it. Not because it was very likely, but because this term is going to be positive. This is positive. And this is positive. So to the, so the whole point is the joint distribution is not specified, not determined by, uh, the distributions

Speaker 1:          00:13:33       of x alone and why alone. Okay. So, even if I know the probability of what x could do and I know what the probabilities that why could do that, doesn't tell me anything about what numbers I should put on these four outcomes. For example, I could have at one extreme x when x is high, why is high? It can't be exactly that because the probabilities are different. So or, or I could, you know, if they're there, these numbers and those numbers don't determine these four numbers. Okay. So there are many different numbers I could put in these four squares, which would give me in total this probability outcome for x and then total this probability outcome for why. So an easy way to see that is if I made them I shoulder. Okay. So, so the distribution now, um, so okay, so what are the observations I want to make? Okay. Um,

Speaker 1:          00:14:38       for instance, I could say if x turns out to be a half, then I'll always assume why. Turns out to be a half. Okay. And then with the other 40% of the time, why might turn to be when wise high x might have to turn off. So I could have, I could have that, you know, I could put a, so here are some ways I could do this. I could put 50% here, 0.5 here, right? So 50% then 40% of the time this is going to turn out, okay. So I have a 0.5 here, okay. Then what can I do with the rest of this? Uh, this plus this has to add up to 50%. Okay. And so 50% I could have x turnout to be here.

Speaker 3:          00:15:27       MMM.

Speaker 1:          00:15:29       50% of the time. X. Okay. So when x is one, I could have, why always turn out to be one. So that means I must have a probability here of x, uh, of probability is zero here because here's x 50% so this plus this ax is going to churn out 21 50% of the time. Now how much of the time is why going to turn out to be down here? Point one. So suppose I put these probabilities 0.4 now. So you see that x is 50% of the time, x is one and 50% of the time x is minus one. Okay. Now how many of the Times is x is y a third point, five plus point for so 90% of the time and then 10% of the time, why is minus three? So here's one way of putting probabilities on the dots that produces this outcome.

Speaker 1:          00:16:19       But I could have chosen another way of doing it the way that you probably had in mind where I assume they're totally independent. That is knowing the outcome of acts in this way of doing it. If I know that extra.to B one y has to turn out to be a third. So they, they're very dependent x's somehow causing wire. Determining why x has a lot of information about why. Suppose I make them independent. I say what happens here has nothing to do with what happens over there. Then I'd write the probabilities instead of these, I'd ride it. Um, 0.45, hey, I take a half times 0.9 is 0.45. And then the chance that you go up, you go down for x, which is 0.5 and up for up for y, which is a minus point forth, which is also 0.45 here. Okay? And then I'd go 0.05 here and 0.05 there. So here, knowing that a y has a good outcome tells you nothing about what ax is going to do. It's still equally likely actions, good or bad. Knowing that, well, I had a bad outcome. Why is still equal? X is still likely to be equally likely good or bad, okay. And simply knowing the outcome of x tells you nothing about the outcome of why this is nine times this. And this is nine times that. So this is the yellow is independence,

Speaker 3:          00:17:41       okay.

Speaker 1:          00:17:42       Hey, which is probability x equals x times x and y equals y equals

Speaker 1:          00:17:50       the product. Probably x equals x times probability y equals y. So that's the case of independence. So in the case of independence, knowing something about one variable tells you nothing about what happened to the other variable, but you could do other joint things. So the joint, this, although the knowingly each of them separately, it doesn't tell you how they're jointly distributed. And the covariance is an effort to see whether they're sort of correlated together or whether they're correlated independently. So independence, by the way, independence implies covariance equals zero. Okay. And that's obvious because what's happening in the x variables got nothing to do with what's happening in the y variable. So since it's linear and acts, you can hold why fix and and, and the access just the same and you're going to get something that adds up to zero. So for any fixed value of why this number, we'll just give you the expectation of x, which won't depend on why it's going to be zero in every case.

Speaker 1:          00:18:46       So therefore, the, if they're independent, the covariance has to be zero. Okay? So independence means x and y tell you nothing. That means the covariance of zero. They could be positively distributed, like up here or negatively distributed either way. You want to do it. Does that make sense? You asked me about this. Yeah. Okay. All right. So what, what are the key simple observations here that, uh, are gonna inform a lot of our behavior on drug uncertainty? Well, it'll, it's gonna turn out that expectation is good and um, standard deviation is bad. Okay? So if we take this variable that we just found w x and Y, we're both here, x and y were both there, right? They each had standard deviation one and expectations zero. So this is the standard deviation. So x is here, and by the way, so as y, same thing. Well, suppose I put half my money into x and I put half my money into why. And if I put half my money in each, let's say I get half the pay off of each. Okay? I make half the bat and I get half of the outcome. What happens to my, what happens to my expectation? Well, the expectation of that

Speaker 1:          00:20:16       obviously equals a half x bar plus a half wide bar. Charlottesville equals zero. So it's staying the same expectation hasn't moved, but what's the variance of a half x plus a half? Why?

Speaker 1:          00:20:37       Okay. Well, by that formula, it's the covariance. So I'm just going to do this formula. I'm going to do a half here and a half here, okay? So it's the cove, okay? So it's the same thing. So it's the covariance of a half facts with a half x was the covariance of the half experts. A half. Why? Plus a half and a half. Okay? But the covariance of a half x with a half x is just, okay, what is that? It's the variance of a half x. But we already saw from our definition of Varian's over here. Remember if you double ax, you're going to multiply the various by four because you're squaring things, okay? So this is going to turn out to be a quarter times the variance of x and this which is a half and a half. Why is going to be a quarter times the variance of y? And if the two are independent, the covariance will be zero.

Speaker 1:          00:21:40       So in this example of these two variables, if I take the, the orange distribution where they're independent, you know, I can, I can do an x outcome and have this standard deviation and this expectation, zero expectation. And that standard deviation, I could do the why thing, get the same standard deviation, or I can put half my money in each. It seems like a total waste of time to put half my money in each. After all, they are giving me the same standard deviation. But no, it isn't. If they're independent, you're shockingly drastically reducing your standard deviation because if they're independent, the covariances zero. And so this plus this, the variance of x equal the variance of y is just the half. The variance of x equals half the variance of y. Okay, so that's shocking. So the standard deviation, therefore the square root of that is one over the square root.

Speaker 1:          00:22:34       So by putting half your money in each, you've now loose this when they're independent. So this is, this is the standard deviation of one half x plus one half lie, uh, x, y independent. Okay. Move from this point to that point, you reduced your standard deviation without affecting your expectation. Okay? So the first lesson that, uh, we're going to see applied, I'm just, you know, this is all mathematics. So, you know, mathematicians understood those, of course a long time ago. But to realize this has an application, economics wasn't so obvious. So this is the thing of, of Shakespeare knew it. You know, it's a diversification. So don't put all your, you know, spread your investments out into different waters. Shakespeare, you know, Antonio had a different ship on each ocean. So instead of putting all the ships on the same ocean, you put them on different oceans, which he assumed was independent.

Speaker 1:          00:23:30       So he had the same expected outcome, assuming the pads were just as quick to wherever he was selling the stuff, same expected outcome, and that each of the waters were equally dangerous, but he drastically reduced his ex is, is variants. And because there are a lot of oceans and a lot of ships, you know, this number went down further and further. So the key is to look for independent risks. Okay. So that's one lesson in mathematics that has a big application than economics. What's a second, um, thing? Well, the second thing is that if you add a bunch of risks together, so I'm gonna say this loosely, so this is if you add a bunch of risks together. So by the way, what's the generalization of this before I say this, if you had an and independent

Speaker 4:          00:24:24       risks with

Speaker 1:          00:24:28       uh, identical

Speaker 4:          00:24:30       means and variances, okay means

Speaker 1:          00:24:37       let's call them all x bar and variances, uh, sigma squared. Hey, let's say they all have expectation e and standard deviation, sigma squared variance, sigma squared. Each of them has that. Then what happens to the, okay, so each of them has standard deviations. So they're all identical like x and y and the same expectations. They're on the same standard deviation one. So once I had 20 of those and I put, um, one 20th of my money into each of them, what would happen to my expectation?

Speaker 2:          00:25:13       Okay,

Speaker 1:          00:25:14       one over n a dollars in each one

Speaker 1:          00:25:20       implies what happens to my, my expectation expectation equal to what each of them had. Expectation. E I now split my money among all of them, all with the same expectation. That also has to have expectation. He all right, just like this thing, putting half my money and why and half my money in acts, wherever the x one y was over here, x is there half my money in acts and half my money in. Why is going to give me the same expectation? If I had 12 projects like that that were independent, I'd still have the same expectation, but my standard deviation, what's going to happen to my standard deviation? Well, the variance, the variance is going to be, so what's gonna Happen to the standard deviation? By what factor? So the variance. So each it's going to be, yeah, what's going to happen to the variance? Put one over n dollars and each of an identical, uh, but independent, uh, investments. What will my variance bay,

Speaker 1:          00:26:41       the variance is going to equal over n times sigma squared. Why is that? Because each one will have one over n dollars in it. So its variance is going to be one over n squared times sigma squared, but they're in of them. Okay. So it's going to be in times one of rand squared. So it's just one of Ren. So implies the standard deviation, which implies the standard deviation. So I'll call it standard deviation is one over the square root of n times sigma. Okay, so it's just as generalization, we've got one over the square root of two, so if I did and have them instead of two of them might have one over the squared event. So those turned out to be very useful formulas which are going to come up over and over again and let's just say it again so you get this straight.

Speaker 1:          00:27:28       If I have two independent random variables and I split my money evenly between them and they have the same expectation, it doesn't have to be zero could be a positive number. If I split my money between them, I haven't changed my expectation because each dollar where hover, I split it. I'm putting into something with the same expectation. But because they're independent, you get a lot of off diagonal things happening. The off diagonal things. Remember a canceling one, investments turning out well, exes, sorry. That's on the Dang the off diagonal elements are good in a way because if one investments turning out well, sorry, turning out badly, the other one's turning out well. So here investment wah, why is turning out badly? ButX is turning out well. So to the extent you're off the diagonal, your um, canceling some of your bad outcomes because one's good and the other is bad.

Speaker 1:          00:28:19       So, uh, that way you leave the expectation the same, but you reduce the variance. In fact, it would be even better if you could put everything on the off diagonal. But to the extent you get at least some stuff on the off diagonal, you're reducing the risk. Okay. And how fast you reduce it. When they're independent, you reduce it, dividing it equally because the variance is a square thing. Half your money in one and half. And the other means the variance of the first is a quarter and the variance of the second is a quarter. But now there are two of them. So the total variance is a half of what it was before. If you have 10 of them, each one is a 10th. The money. So it's got one, 100th of the variance, but there are 10 of them. So it's ten one hundredth, one over n the variance. If you take the standard deviation, it's one over the square root of N. Okay. So that's the rate at which you can reduce your, your, uh, uncertainty and your risk. And we're going to come to, you'll see this gets much more concrete and next lecture. But one more. Okay? So this is just stuff that most of you know. So one more thing if you add a bunch of them, bunch of independent things together, independent random variables. So I'm gonna speak very loosely now. We are bowls. Uh, you get, you get a normally distributed random variables

Speaker 1:          00:29:44       and I'm very molt, normally distributed random variable with the corresponding,

Speaker 3:          00:29:55       uh,

Speaker 1:          00:29:55       expectation and standard deviation. Okay? Now, so if you take these, you take half your money in ancient. So if he took, okay, so what am I saying? Okay, so I don't want to speak to precisely about this because if you've seen this before and seen a proof, you know everything about it. If you haven't, it's just too many subtleties to absorb. But the normal distributed random variables, the bell curve that looks like that, I wasn't too, okay, it looks like this. Okay, so there's the bell curve with expectations. Zero. Okay, so it's this bell curve. Now what's special about it? It hasn't a particular formula which has got an exponential to a minus x squared thing and he's got a particular formula to it, which if you know, you know, if you don't, it's written down whenever we're going to use the exact formula, but it looks like that.

Speaker 1:          00:30:44       So these are the outcomes acts and this is the probability, probability of outcome or frequency about com. Okay, so the bigger x is, and this is the mean equals zero, I've assumed the mean is zero. So this is, if you take a really big acts, it's very unlikely to happen. And a really small acts is very unlikely to happen and axes near the mean are pretty likely to happen. So anyway, it's amazing that if you add this random variable to itself a bunch of times, it can only produce one and minus one. Right. This one produces totally different outcomes. A third in minus threes are completely separate out their, their, their disjoint outcomes. But if you add this together, you know, you can get 25 ones and 10 minus ones. So that gives you 15 over here, you know, you could have,

Speaker 3:          00:31:36       mmm,

Speaker 1:          00:31:37       25 will never get me there. So you can get a hat. So I'm sorry, that was a bad example. If I had 30 things I could get, you know, 18 ones and 12 minus ones, that'll give me six. You could have gotten six over here, but with 30 outcomes you could get, you know, all 30 of them could have turned out to be one and that would have gotten you pretty close to the same outcome. So it's not, you know, just because these outcomes are separate. Once you're adding them up, you're starting to produce numbers different from one and minus one. You know, and these added up, if you take the right combination of one third in minus third, you can start reproducing things like to get a one here, you can reduce three tops and then you're, you're, you're producing a one. So anyway, this shocking thing is if you add a bunch of these random variables that are independent to each other, you get something normally distributed that looks like that because this random variable had exactly the same mean and standard deviation, you have the same number of these, you're going to get outcomes that are almost identically distributed.

Speaker 1:          00:32:33       So in the limit, this random variable, enough of these added together looks exactly the same as these added together. Okay? That's the second surprising mathematical fact. And the third thing that we're going to use is that the normal distribution is characterized by the mean and standard deviation. That's all it takes to write the formula. This down. And these numbers, these are called thin tail. These, these probabilities go to zero very fast. So you shouldn't expect many outlying dramatic things to happen. Okay. And in the world they do happen. And so we're going to see that much of classical economics is built on normally distributed things. And so you can't see, you shouldn't expect any gigantic outliers to ever happen. And it seems natural to build it on that kind of assumption because if you add things that are independent, you get normal distributions all the time and things seem independent. So why shouldn't you get normal distributions? And yet we must not get it because we have so many outliers. Okay. So that's the basic background of mathematics, learning questions about any of that. I'm just assuming you know all that. And now we're

Speaker 4:          00:33:41       Ghana, we're gonna move to economics.

Speaker 1:          00:33:49       Yeah, I think that's all the background you need. Okay. So here's, I want to do one more thing, which is maybe background, but it's quite a, it's used in economics all the time. Okay. And it's called the iterated expectations. Okay. So if I told you that these variables were correlated, like these appear like the orange things, if I told you what x turned out to be, that would tell you a lot about what, why was going to be. So for example, if I told you that x was a sorry, the the white ones are the correlated ones. If I tell you that x has turned out to be one that tells you that why has to be a good outcome of a third? Because if x is one, this never happens. So the only thing that can happen if x is one is that why it turns out to be a third. So knowing ax is going to completely change your mind about the expectation of why. So conditional expectation, I should have said this before. Conditional expectation

Speaker 4:          00:35:08       simply means we computing recomputing expectation

Speaker 1:          00:35:21       using um, updated probabilities

Speaker 1:          00:35:29       from your information out in probably done this in high school. So I'm not, I'm just going to assume you know how to do this. So in this case, if I tell you something like x has turned out to be one that tells you that only these two outcomes are possible. So that means that the only two outcomes in the white case have happened with probably 0.5 and zero. But if I tell you x is that come out to one, the conditional probabilities have to add up to once you just scale things up. So it's, you know, that x has, you know, that why I had to have been the good outcome appear. Okay? If I tell you that the bad outcome for, for a why has happened, if you have any of probabilities of x of a 0.1. Okay, let's see. So the zero makes things too easy. Suppose I tell you that the, uh, I tell you the good outcome of why has happened. What are the chances now that x has been gotten the good outcome in the white probability case?

Speaker 2:          00:36:27       Okay.

Speaker 1:          00:36:27       If I tell you that why it turned out to be a third and the white probability case, what's the probability that x turned out to be one conditional on that?

Speaker 2:          00:36:36       Yeah.

Speaker 1:          00:36:36       Five nights. Okay, so that's it because the probabilities are now you're reduced with 0.4 and 0.5, so five ninths of the time. Okay. So that's an idea which I assume you all can fit. It's very intuitive and it's way too long to explain. Then I'm sure you know how to do that. So anyway, the conditional expectation, blah. So the iterated expectation is simply this. It's an obvious idea, but it's going to be incredibly useful to us. It says, if I, if you ask me, what are the chances that the Yankees are going to win the world series against the Dodgers? Let's suppose that soon it's going to play, the Yankees are going to beat the Dodgers. What do you think the chance, what's the probability that's going to happen? What do you expect the chances are if I then ask you your opinion? My opinion after the first game, well, obviously if the Yankees win the first game, my opinion's going to go up. So I'm gonna have a different opinion. If the Dodgers win the first game, my opinion is going to go down. So I'll have a different opinion. But you can ask now another question. What's your expected opinion going to be?

Speaker 2:          00:37:37       Okay.

Speaker 1:          00:37:37       The law of iterated expectations is the ex expected. So the expectation of x has to equal the expected expectation of x given some information. So here's what I think the Yankees are 70% likely to win. If I say after the first game, I'll think it's 80% and after the first game, if the Dodgers win, I'll think it's gone down to, you know, a 65% it had better be that the average of my opinions after the information is the same as the number I started with. Okay. That's the law. That's just common sense and I'm not going to bother to prove that. So that's incredibly important that you're, you're, it's not only the expectation of x, but as you learn stuff, you can anticipate your opinion's going to change. But your average opinion has to always stay the same as as as x was. Okay. So that's the, that's the last of the background. And now I want to do simple application of this. So in fact, to that very question, suppose that you're playing a a world series, the Yankees are playing the uh, the Yankees are playing the Dodgers and let's suppose that the Yankees have a 60% chance of winning any game.

Speaker 1:          00:39:00       Yeah, I'll just do it here. Yankees have a 60% chance of winning any game. What's the chance of the Yankees win a three game world series.

Speaker 2:          00:39:11       Okay.

Speaker 1:          00:39:12       How do you figure that out? Well, a naive way, a simple way of figuring that out is to say, well what could happen? Life can mean a Yankee win. Let's call that an up or a Yankee loss. Let's call that a down. Okay. And this could happen was probably 0.6 or point for the Yankees could win again. Okay. So that's probably 0.6. We have two Yankee wins or the Yankees could lose the second game. So that's probably point for the Yankees could lose or could win. That's 0.6 and this is 0.4. Okay. And that's, we've only played two games. The Yankees could win a third. Well, you don't need to play this game cause they've already won a three game series. But if you did it wouldn't matter. Wait for, or we could go up or down. Okay, the Yankees after winning and losing could then when probably 0.6 or could lose.

Speaker 1:          00:40:13       Okay. Or after losing and winning, they could win again or they could lose after losing and winning, they could lose. So this is probability 0.4 and this is 0.6 and then finally we have this, we have this. So this is 0.6. Okay? So this is what the tree looks like. You could imagine eight possible paths, each of link three where you give the whole sequence of wins and losses. So to compute the probability that the Yankees, when you look at all the, so in this case, the Yankees win, right? They would have already one here. But if you play it out, it doesn't matter. They're going to win here and here I've got two wins and one loss here they've got one. When two wins and one loss, they win. Here, they've got, you know, lost win. When they win the world series here, they lose, win, lose, they lose the world series. Here's lose, win, win, lose, lose. They also lose the world series here. It's lose, lose, they've lost the world series loss. Okay? So these are the possible outcomes. So you can compute the probability of every path there, eight of them, and then multiply that probability by the outcome and you'll get the chance at the Yankees won the world series, right? That's clear to everybody. But there's a much faster way of doing it and putting it on a computer. Okay? And that's using the law of the iterated expectation. So first of all,

Speaker 1:          00:41:37       so this is called the tree. So we're gonna use trees all the time. Some tree, I don't want to formally define it, it's just you start with something and stuff can happen. You know, stuff happens every period. And so you just write down all the things that can happen and then you write down all the things that can happen after that. And the thing unfolds like a tree that's formal enough to be, to describe a tree. And here we've got it. But you notice that the tree, the number of things happening grows exponentially. It's horrible to have to compute something growing exponentially, but they're often recombining trees. Oh. So if I ask, by the way, in this tree, whatever the opinion is here, which turns out to be 0.68 something, yeah, I should have asked you to guess 0.68 something. If you write down in the opinion that opinion has to be the average of the opinion here and the opinion here. So if I take the opinion here at times, 0.6 plus the opinion here at times 0.4 that's also going to equal 0.68 okay. And that's what's going to be the key to computing the thing much faster rather than going through every branch, which is such a pain. Okay. So because they're an exponential exponential number of exponentially growing, growing number of pads, very bad to have to compute by hand. But we noticed that we could look at a recombining tree.

Speaker 2:          00:42:58       Okay.

Speaker 1:          00:42:59       Okay. The, the, these two nodes are essentially the same. What difference does it make if the Yankees win one and lose one or lose one. And when one in both cases they're there at the same spot there even in the world series. And since we assume the probability of winning and game is the same 0.6 and 0.4 independent of what's happened before, you might think you're learning, you know something about all their starter pitched here and you know he didn't last the whole game and stuff like that. So I'm, I'm not allowing for any of that. I'm just saying it's a 0.6 0.4 chance for the Yankees to win no matter what happens. So all you care about at any point from then on is what the s who's one, how many games. So these nodes are basically identical and these nodes are identical because it all ended up with the Yankees. The Dodgers ahead two to one and here the Yankees were head to, to one near the Yankees were ahead, three to zero and zero to three. So the recombining tree, which has all the same information is just this,

Speaker 2:          00:43:56       this, this.

Speaker 1:          00:44:07       Okay, this tree. So this tree only has one, two, three, four, five you know, has far, you know, it's one node, two nodes, three nodes, and four nodes. As time goes by growing linearly instead of growing one to two to four to eight, which is growing exponentially. So I could have a very long world series and write it as a finite tree and just point 0.6 and 0.4 here at every stage.

Speaker 1:          00:44:36       Okay, so how am I going to solve this? Now we'll over here. I know the Yankees ended up winning all three games here. They want to hear they won one here, they one nuns. So those are the outcomes. So instead of trying to figure out path by path who these exponential number of pads, what the chances of each path or why there's hard to compute here. It's 0.6 times 0.6 times point for the complicated calculation. Okay, I'm not going to do something simple. I'm going to say what would I think if the Yankees had already won two games? Well I know that they would win. Okay, that's a one. That series is already over. What would I think after the Dodgers won the first two games? I know it was over. What would I see? And so how did I get that? Is Point six times one plus 0.4 times one. That's one. The Dodgers 0.6 times zero plus 0.4 times zero. That's zero. Okay, so that's my opinion. If the Dodgers win two games, here's my opinion of the Dodgers and the Yankees won two games. What's my opinion? What would my opinion be if they split? Well, if they split, what would my opinion be?

Speaker 2:          00:45:39       Okay,

Speaker 1:          00:45:40       if I started here. So after game two they've each one one game, I don't know who won the first one, but it was one to one after two games. Now what would I think exactly? So it's 0.6 it's 0.6 times one plus 0.4 times zero. So the odds, I would think the Yankees would win the world series here with one game left knowing that they win 60% of the time. It's a 0.6 but now what do I think if the Yankees win the first game? What's my opinion?

Speaker 2:          00:46:10       Okay.

Speaker 1:          00:46:10       So it's 0.6 times one so it's 0.6 plus 0.4 times 0.6 that's 0.24 so that's 0.84 here. And what's my opinion after the Yankees lose the first game and the Dodgers win, what do I think is going to happen? What might, what would my opinion be here? It's 0.6 times having an opinion of 0.6 so it's 0.36 loss 0.4 times knowing that's all over plus 0.4 times zero. So it's equal to 0.36. Okay. So that's, that's, that's so I've now figured out not only am I solving this thing much faster than I could over there, but I'm finding interesting numbers on the way I'm now figuring out what would I think after the Yankees won the first game. Well now I think it's 84% what would I think after the Dodgers won the first game, I think it was only 36% chance of the Yankees winning. Okay. And so now what's my opinion at the very beginning?

Speaker 2:          00:47:15       Okay,

Speaker 1:          00:47:16       it's 0.6 times point 84 it's my chance of having this opinion. Plus my chance of having that opinion plus 0.4 times 0.36 um oh no, a five oh four maybe plus 2144

Speaker 2:          00:47:41       what is that? Six four

Speaker 1:          00:47:45       wearing six 48 six times 84 looks like five Oh four and four times 36 and it's like one 44 so looks like 0.648 gave me, that's what you said. So that's it. I've solved it now. Okay. So that's the method of iterated expectation. And we're going to turn this into quite an interesting theory in a second, but I want to now put that on the computer to show you just how completely obvious this is. I mean, not obvious fast. This is so you could solve for any number of uh,

Speaker 2:          00:48:19       yeah,

Speaker 1:          00:48:20       a series of any length you could instantly solve. Okay. And now we're going to, we're going to price bonds that way too. So class.

Speaker 2:          00:48:36       Okay.

Speaker 1:          00:48:38       Okay. So what did I do? I, this is a spreadsheet you had, I simply had the probabilities of the Yankees winning, which was 0.6 which I could change. Oh,

Speaker 1:          00:49:15       okay. So this is the simplest thing to do, but now suppose that, okay, so we said the Yankees can win every game with probability 0.6 so then what did I do? I went down to here, I gave myself some room. I didn't do very a very long series. So now what does each of these things say? Each of these nodes like that one says, if I can read it, it says, so this is my opinion of winning the world series. It says, my opinion here is going to be the chance I go up. Okay, that's the probability. That's a two. That's 0.6 the chance I go up times what my opinion would be over here plus the chance that I go down, which is here, chance I go to here, which is one minus that number 0.6 that's frozen up their times. Whatever I thought would be my opinion here.

Speaker 1:          00:50:05       So you see that's the same. I just write that once I wrote that one's here. That thing about, you know the probability, my opinion there is the probability of going up. That's s a dollar a dollar too. That's 0.6. It's frozen times, what my opinion would be on the square over one and up one plus one minus dollar a two times my opinion over one and down one. So I just copied that as many times as I want it to down the column. And then I copied it again across all the roads. So all of these entries are identical. They're all just copies of each other. Okay, so just as iterate your opinion from what you know it was forward. Okay. Now how do I take a three game world series? Well, we're starting here. This will be one game, one game two, game three.

Speaker 1:          00:50:52       So all I have to do now is put a ones everywhere here like one enter. And now I'll copy this Schrole copy and go all the way down here. Because when you, when you're above the them. Okay, so that's it. So we've got all the numbers. Okay. So why is that? Because my opinion here, I remember the numbers, we got the game, the series goes one game, two games, three games. So if you end up above the middle, that means the Yankees won the majority of gains. Your payoff is one. Okay. Your probability of the Yankees winning is one. Okay. And so now what's your opinion going to be? Um,

Speaker 1:          00:51:29       you know, if you've won two games then the Yankees have to have one. Okay. What if the Yankees Win the first game? Well, there you remember the numbers. We've got 1.6 and zero. So here's the 0.84 is the average of 1.6. Here's the 0.36 which was the average of a 0.6 and zero. And then we come down to the middle, which is 0.648. Okay. So it's a, what do I do if I want to play a seven game world series? Okay. I have to get rid of this. Uh, and if it's a seven game world series, I would just now I want to restore what I had before. So I'm going to copy all this, uh, control.

Speaker 2:          00:52:05       Oh, copy.

Speaker 1:          00:52:09       Okay. So I'm back to where I was before. So this was basically, you see what I'm doing here. This is game. Hasn't started. This is the first game, second game, third game, fourth game, fifth gang, 16 seventh game. Every square is just saying, my opinion is my average of what my opinion will be next time. If I want to make it a seven game world series, I just plug in ones here. There must be some faster way of doing this, but I plug in ones here. So control, copy and here are all the ones down to above the thing. Control v and now I've, I've solved my opinion backwards and I've got the chances of the Yankees winning a seven game world series or 71% so the longer the world series goes, the better the chances are the Yankees win if they're better in each individual game and you can do it instantly. So there are any questions about that.

Speaker 1:          00:52:58       Okay, so that is a trick we're going to use over and over again to price bonds. You do it by backward induction because of the law of iterated expectations. Your opinion today of what's going to happen way in the future when you get a lot of information has to be the average opinion you're going to have after you get some information. But before you know what the final outcome is. And so realizing that you just take the pieces of information one by one and worked backwards from the end and you solve things instantly, which would take, you know, in the brute force way an exponentially growing length of time to do if you did an path by path. Okay. So let's now, um, I want now I want to turn to an application of this to one subject, which is let's just not do the world series. Let's do a more interesting problem. I hope I have time to finish the story. Okay. So the more interesting problems, this let's suppose that the, uh, let's suppose our uncertainties of a different kind

Speaker 1:          00:54:11       instead of not knowing the outcome of the world series. Let's say we don't know how impatient we are. So remember that most important idea so far that we've seen because we haven't done uncertainty yet. Most important idea we've seen so far is impatience. That's the reason why you have to, you get an interest rate and the interest rate is the key to finding out the value of everything. So Irving Fisher put tremendous weight on impatience and now that we're talking about uncertainty, the natural thing to make uncertain is how impatient you are going to be. So we want to talk a little bit more about impatience. So impatience.

Speaker 2:          00:54:53       Okay,

Speaker 1:          00:54:54       why Irving Fisher is the discount. So I, in fact I want to talk about this in sort of realistic terms. Do we really believe that people just discount the future? You know that they, one year they discount by Delta two years, they just can't buy Delta squared three years by Delta cubed, four years by Delta to the fourth. Is it really true that every year people think of as Delta less important as the year before?

Speaker 2:          00:55:25       Okay.

Speaker 1:          00:55:26       I mean the arguments for that is, you know, you might not live beyond a certain, you know, the poor at imagination. So imagination, poor imagination. We've said this before, per imagination and mortality are the two arguments for discounting. But let me tell a story that seems to contradict that. Suppose someone asks you to clean your room and they give you a choice of doing it. I'm thinking of my son for example, say clean your room Constantine. And uh, so if I say do it today or do it tomorrow, that makes a huge difference to him. I mean, just a huge difference doing it today for doing it tomorrow. He'll think doing it today is just impossible doing it tomorrow, you know, I can almost force him into agreeing to that. So clearly there's a big discount between today and tomorrow. But what about between today? What about between a year from now and a year and a day from now?

Speaker 1:          00:56:24       Do you think Constantino think there's any difference from that in that? And the answer is no. He just, you know, if I say Constantine, you agree to clean it a year, 365 days from now or 366 days from now to him, there's hardly any difference. But you know, there's hardly any trade off. One is hardly more valuable than the other. Of course. The both pretty unimportant, but the ratio of the two doesn't even seem important to him. So that's called hyperbolic discounting. If you do any experiment with people or with um, with people or with animals, you know, you add, you, you, you make a bird do something and you know, he, if he does more stuff, he gets the things faster. You know, he'll do a lot of stuff to get it in the next minute as opposed to in two minutes. But the amount that hit, but, but he won't, the difference between what he'll do in 10 minutes versus 11 minutes is very small. Okay. So hyperbolic discounting is quite, is uh, is discounting march hyperbolic discounting is discounting much less Len exponential discounting.

Speaker 1:          00:57:36       So this has a tremendous importance for the environment. If you fought that people exponentially discounted, like they, they fund each year was only 95% as if the interest rate's 5% it sounds like the discounting is 0.95. So if next year's only 95% is important as this year and the year after, that is only 95% is important as the first year. And the third year is only 95% is important as a second year 0.95 in a hundred years to the hundredth is an incredibly small number. So there's no point in doing something today and investing a lot of resources in order to clean up the environment and help people a hundred years from now. Because by discounting at this much, nobody could. You know what's the difference? Because the future so unimportant, you shouldn't be investing resources now to do something that's going to have such a small effect later. So in all the reports on the environment, a crucial half of the report is devoted to what the discount rate should be.

Speaker 1:          00:58:34       So, but they never thought of doing the most obvious thing, which is to ask what would happen if the discounting was uncertain. All of these are certain discount rates. So what if you made the the discounting uncertain? What would you imagine doing? So suppose you discount today at 100% and maybe next period you're going to discount at 200% this is the interest rate and hearing it might go down to 50% could go up to 400% or it could, could, could go down to 100% again. Okay. Or it could go down to 25% and all this kind of discounting I have in mind, you don't know. So delta equals one over one plus r and this is our, our zero are up or down. Okay. So maybe the, maybe the discount is uncertain and it goes like that. So it's a geometric random walk. I keep multiplying or dividing by two. I multiply or divide by two. I multiply or divide by two. That seems to make for a lot of discounting, these numbers are going up very fast. It seems like, you know, the higher the are, the less you care about the future. So the question is if you ask for a dollar sometime in the future, what will people be willing to pay for it? Okay. So how, I mean, so you know, you know today that you think the future is only half as important as the present. Let's say these all have probability a half,

Speaker 1:          01:00:10       okay. And tomorrow it might be that you think the future is only two thirds. The next years only two thirds is important as the, that current year or you might think the future's only one third as as important as this year. So you'll see how this is working. Two years from now you might think the future is only one fifth as the third years, only one fifth is importance. The second year here. Or you might think the third years is half as important as the second year here. Or you might think it's a four fifths is important as the third year. Okay, so you don't know what it's going to be. And if anything, this process seems to give you a, this process seems to give you a bias towards getting really high numbers. Okay. High discounts, meaning the future doesn't matter. Okay. So, but nobody bothered to stop. So this is the most, this is the most famous interest rate process and finance. This is called the whole Lee interest rate model. Where are you think today's interest rate might be 4% maybe it'll get multiple, maybe only 10% higher next year, a 10% lower. It'll keep going up and down like that. And that's the uncertainty about the interest rate. So if we think interest rates are so important in patients is so important and we want to add uncertainty first place to do it as to the interest rate and the holy model and finance does that. Nobody bothered to compute this out more than 30 years.

Speaker 1:          01:01:30       Okay. Suppose you computed, okay, compute what out. Suppose you get a dollar for sure in year one. Okay. How much would you pay for a dollar in year one? Well, your discount is 100% you pay a half a dollar. How much would you pay for a dollar in year two? A dollar in year two. Well, you know how much more dollar now is worth than a year from now, but you don't know two years from now. So you have to work by backward induction here. A dollar for sure is worth a dollar. What would I pay for it here I pay a third of a dollar. Okay, and what would I pay for it here? Well, the discount is two thirds. I paid two thirds of a dollar. So what would I pay for it back here, I pay half times a third plus half times two thirds discounted a hundred percent so that's some low.

Speaker 1:          01:02:21       So it's a half cents. One third plus a one sixth, which is a half times a half, which is a quarter I guess. Okay. So I pay a quarter. So for any time I could figure out DFT equals amount, I would pay him. I'm going to be done in one minute amount. I would pay today, today for $1 for sure at time t and that number obviously is going to go down as t goes up. So, and we know how to compute it by backward induction. You just put the ones further and further out and then you go backwards by backward deduction. But just like for the world series, I could do that for any tea. However big I want to. And on a computer and the spreadsheet which I wrote for you, you could do this instantly. Okay. And nobody bothered to do this for tea bigger than 30 because bonds basically, we don't last for more than 30 years.

Speaker 1:          01:03:23       So what's the point in doing it for p bigger than 30 so a hundred years. There are virtually no financial instruments that are a hundred years long. So they didn't bother to do this. Suppose you did it for every t you know, up to a thousand years. While you can do it on a computer very easily, you can even prove a theorem of what it's like. So in the problem set, I'm going to ask you to do a few of these and what you're going to find is that, um, people are hyperbolic that you get your discount a lot. Like it's pretty close to a hundred percent for the first few periods. But after that, you're going to be anyway, you're going to find out what the numbers turn out to be when you do it in a computer. Okay? So we're gonna start with random interest rates next period. The most important variable in the economy.