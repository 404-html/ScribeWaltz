1
00:00:00,310 --> 00:00:01,810
In this expert interview,

2
00:00:02,350 --> 00:00:06,070
we'll be speaking with doctor
Brian Commute son who's
an associate professor of

3
00:00:06,071 --> 00:00:10,990
psychology at Stanford University and
the director of the symbiotic project on

4
00:00:11,000 --> 00:00:14,800
affect of neuroscience. And he is one
of the leading figures in this area.

5
00:00:14,801 --> 00:00:18,910
We'll speak with us about the field
of neuroeconomics and emotion.

6
00:00:19,210 --> 00:00:20,990
So doctor Knutson,
um,

7
00:00:21,160 --> 00:00:25,990
received his bachelor degree in psychology
and comparative religion from Trinity

8
00:00:25,990 --> 00:00:30,640
University and his Phd from Stanford
University after which he did postdoctoral

9
00:00:30,730 --> 00:00:35,530
research and affect of neuroscience
at the medical school and the National

10
00:00:35,530 --> 00:00:36,100
Institute of Health.

11
00:00:36,100 --> 00:00:39,670
His laboratory uses multiple
methods including psychometrics,

12
00:00:39,671 --> 00:00:44,320
psychophysiology brain
imaging and pharmacology to
investigate neuro mechanisms

13
00:00:44,321 --> 00:00:46,180
that underlie emotional experience.

14
00:00:46,480 --> 00:00:50,440
And he also explores implications of
this work for clinical disorders have an

15
00:00:50,441 --> 00:00:53,530
effect and addiction as well as
for economic decision making.

16
00:00:54,010 --> 00:00:58,450
Their discovery that neural activity
correlates with expected value and can be

17
00:00:58,451 --> 00:00:59,620
used to predict choice,

18
00:00:59,621 --> 00:01:04,570
including financial risk taking and
product purchases has helped seed new and

19
00:01:04,571 --> 00:01:07,750
exciting interdisciplinary
fields including neuro economics,

20
00:01:07,990 --> 00:01:09,900
neuro finance and neuromarketing.

21
00:01:10,380 --> 00:01:15,380
Dr [inaudible] has received young
investigator awards from the American

22
00:01:15,400 --> 00:01:15,640
Psychiatric Association,

23
00:01:15,640 --> 00:01:18,640
the National Alliance for research
on schizophrenia and depression.

24
00:01:18,910 --> 00:01:21,340
And the Academy of
Behavioral Medicine Research.

25
00:01:21,700 --> 00:01:26,700
He's also a fellow of the American
Psychological Society and Academy of

26
00:01:26,740 --> 00:01:27,160
Behavioral Medicine Research.

27
00:01:27,160 --> 00:01:29,950
His research is funded by grants
from several organizations,

28
00:01:29,951 --> 00:01:33,280
including the National Institutes of
Health and National Science Foundation.

29
00:01:33,790 --> 00:01:37,290
He's been invited to speak about his
research and psychology, psychiatry,

30
00:01:37,320 --> 00:01:41,470
neuroscience, economics, finance and
marketing departments around the world.

31
00:01:41,920 --> 00:01:42,840
And his laboratories.

32
00:01:42,850 --> 00:01:47,140
Research is regularly featured in top
journals and popular media outlets.

33
00:01:47,350 --> 00:01:51,130
So I now turn to our very special
experts and emotion interview with Doctor

34
00:01:51,131 --> 00:01:54,720
Brian Knutson. So welcome, Brian.

35
00:01:54,750 --> 00:01:57,900
Thanks for speaking with us today.
Thanks for having me.

36
00:01:58,290 --> 00:02:02,370
So I know we're all curious to know a bit
about what got you first interested in

37
00:02:02,371 --> 00:02:03,460
emotion.
Um,

38
00:02:03,780 --> 00:02:07,920
I know that you came to this in a
path that isn't typical of everyone,

39
00:02:08,070 --> 00:02:09,570
and I'd love to hear your story,

40
00:02:10,530 --> 00:02:15,450
right? So this sort of dates me, but
when I was a psychology graduate student,

41
00:02:15,510 --> 00:02:18,000
uh, people talked about
emotion and the brain somewhat,

42
00:02:18,001 --> 00:02:21,090
but they never talked about
the two together. So, um,

43
00:02:21,420 --> 00:02:24,210
I studied emotion at that time,
facial expression of emotion.

44
00:02:24,870 --> 00:02:28,530
And I went to work with a guy named Paul
Ekman who studies facial expression of

45
00:02:28,531 --> 00:02:33,531
emotion and I was a postdoc in his lab
and he noticed that I was spending a lot

46
00:02:33,781 --> 00:02:38,760
of time taking classes in the
medical school and he said to me, uh,

47
00:02:38,790 --> 00:02:41,310
you can continue doing this.
You're doing your work, it's fine,

48
00:02:41,311 --> 00:02:43,980
but you really want to do this,
go this route.

49
00:02:44,010 --> 00:02:46,650
Then you need to work with somebody who
thinks about the brain and thinks about

50
00:02:46,651 --> 00:02:49,980
emotion. Uh, and there are only three
people in the world who do that right now.

51
00:02:50,570 --> 00:02:53,850
Uh, one was Richie Davidson and that was
Joe to do in other was Jaak Panksepp.

52
00:02:54,540 --> 00:02:59,040
So I decided to take the risk
and go work with Jaak in.

53
00:03:00,210 --> 00:03:03,340
And he was very interesting at that time
because he was claiming that animals

54
00:03:03,341 --> 00:03:05,710
had emotion and you can
model it and in rats,

55
00:03:05,770 --> 00:03:08,380
all these very radical things at the time.
So I did,

56
00:03:08,381 --> 00:03:13,300
I went and worked with Yak and I really
got my hands dirty working with the

57
00:03:13,301 --> 00:03:16,330
brain and neuro pharmacology.
And based on that,

58
00:03:16,331 --> 00:03:19,690
that sort of sent me off on this weird
trajectory of affect of neuroscience.

59
00:03:19,691 --> 00:03:22,150
I ended up at at uh,
uh,

60
00:03:22,270 --> 00:03:24,800
the National Institute of
Health for another post doc.

61
00:03:25,060 --> 00:03:28,660
And there I got exposure to brain
imaging. Uh, my boss basically said,

62
00:03:28,661 --> 00:03:31,510
I have this time, do you want
to do something with it? And uh,

63
00:03:31,900 --> 00:03:35,650
that then got me into brain imaging.
So I've always been interested in emotion,

64
00:03:35,651 --> 00:03:38,190
but the neuroscience part came later.
We're married.

65
00:03:38,260 --> 00:03:42,510
Cool. So I'd love to ask you a bit more
about your current research now. Um,

66
00:03:42,880 --> 00:03:46,720
so I mean we can all relate to some
extent to the way that emotion shift,

67
00:03:46,721 --> 00:03:51,580
the way we spend money or how our economic
situations influence how we feel in

68
00:03:51,581 --> 00:03:52,414
the moment.

69
00:03:52,450 --> 00:03:56,110
And your work is really cool here
because it looks at this sort of neuro

70
00:03:56,111 --> 00:03:59,920
economics of emotion.
So this bridge is fields of psychology,

71
00:03:59,921 --> 00:04:01,600
neuroscience and economics.

72
00:04:01,960 --> 00:04:05,500
And it's this very timely and
exciting field to so many people.

73
00:04:05,940 --> 00:04:09,640
And at the same time it's this rapidly
developing and, and new field as well.

74
00:04:09,880 --> 00:04:13,750
And so I just wondered if you could share
with us some of the kind of scientific

75
00:04:13,751 --> 00:04:17,860
puzzles that are gripping people in
studying these kinds of questions.

76
00:04:18,580 --> 00:04:21,180
Absolutely. I mean, it's a
very exciting time. Yeah. Uh,

77
00:04:21,320 --> 00:04:24,580
this technology for looking into the
brain, not only at the cortical level,

78
00:04:24,581 --> 00:04:27,160
but deep in the subcortical level,
uh,

79
00:04:27,161 --> 00:04:31,090
at a second to second temporal resolution
has really only been with us for the

80
00:04:31,090 --> 00:04:34,510
past decade or so. So, uh, as
we're discovering new things,

81
00:04:34,511 --> 00:04:36,040
we're also innovating new methods.

82
00:04:36,280 --> 00:04:39,010
And that doesn't just apply to the
fancy magnets or the head coils,

83
00:04:39,011 --> 00:04:41,920
but also to how you designed the study,
how you analyze your data.

84
00:04:42,190 --> 00:04:44,320
Timing is really important.
And in fact,

85
00:04:44,440 --> 00:04:48,040
one thing that we've been focusing on
is can you not only see arousal in the

86
00:04:48,041 --> 00:04:49,270
brain,
but can you see valence,

87
00:04:49,420 --> 00:04:52,510
which seems very basic from an
emotional perspective, but really it's,

88
00:04:52,530 --> 00:04:56,080
it's a question that's at the root of
all studies of athletic and emotion.

89
00:04:56,530 --> 00:05:00,400
And the reason we're so focused on
payments, meaning good versus bad,

90
00:05:00,910 --> 00:05:04,330
is because we think that not only will
it allow us to see how people were

91
00:05:04,331 --> 00:05:06,970
reacting to things,
but also what they're about to do.

92
00:05:07,600 --> 00:05:10,720
And so we've specifically
focused on two emotional states,

93
00:05:10,721 --> 00:05:13,480
which is rather limited,
really to be honest. Um,

94
00:05:13,570 --> 00:05:18,400
two emotional states that we think
are evoked when people anticipate, uh,

95
00:05:18,401 --> 00:05:21,580
uncertain, good events are
uncertain, bad events. Uh,

96
00:05:21,610 --> 00:05:23,530
we call them positive
arousal and negative arousal,

97
00:05:23,531 --> 00:05:27,130
and they fit right into this aspect
of framework. I'm thinking about, uh,

98
00:05:27,370 --> 00:05:31,210
people's experience. So positive arousal
involves emotions like excitement,

99
00:05:31,240 --> 00:05:33,680
energy, even pride. Uh,

100
00:05:33,730 --> 00:05:38,380
negative arousal involves emotions
like anxiety, irritability, um,

101
00:05:38,770 --> 00:05:39,603
and so,
uh,

102
00:05:39,610 --> 00:05:43,180
these kinds of emotions are especially
important to us because we think that

103
00:05:43,181 --> 00:05:46,960
they occur not only in response to
something that just happens and outcome,

104
00:05:47,230 --> 00:05:50,290
but also in anticipation of
things that have not yet happened.

105
00:05:50,500 --> 00:05:54,490
So they're truly psychological and we
also think that they drive behavior.

106
00:05:54,491 --> 00:05:58,670
So they will push you towards
approach or avoidance respectively.

107
00:05:58,820 --> 00:06:00,200
So they will in essence,

108
00:06:00,201 --> 00:06:04,600
allow us to predict whether somebody
will approach or avoid a situation. Okay.

109
00:06:05,040 --> 00:06:05,811
How fascinating.

110
00:06:05,811 --> 00:06:09,530
So what do you think that are some of the
major challenges researchers are going

111
00:06:09,531 --> 00:06:12,710
to face in this field of
neuroeconomics of emotion?

112
00:06:13,720 --> 00:06:15,070
So one of the challenges,

113
00:06:15,110 --> 00:06:20,050
a lot of them are sort of
the same challenges that
most emotion researchers face

114
00:06:20,230 --> 00:06:21,430
when there's an additional layer.

115
00:06:21,431 --> 00:06:25,270
So the same challenges that emotional
researchers face is that they want to

116
00:06:25,271 --> 00:06:29,330
measure something that often is
assessed with self report, uh,

117
00:06:29,420 --> 00:06:33,990
and correlate it with either, you know,
behavior or skin conductance, you know,

118
00:06:34,020 --> 00:06:37,810
physiology or something like
that. And those correlations
can be pretty loose. Uh,

119
00:06:37,811 --> 00:06:40,600
so, you know, people aren't always
aware of, I think what they're feeling,

120
00:06:40,860 --> 00:06:45,400
but sometimes they can act in an emotional
way and not be aware of it or come up

121
00:06:45,401 --> 00:06:48,550
with an explanation that
really isn't relevant to the
w why they behave that way.

122
00:06:48,820 --> 00:06:51,070
In fact, we can set up
situations like that in the lab.

123
00:06:51,071 --> 00:06:54,280
So one of the problems is that things
don't always hang together very well.

124
00:06:54,530 --> 00:06:56,240
Another problem,
uh,

125
00:06:56,290 --> 00:07:00,550
which is unique to our situation
is the problem of timing. Uh,

126
00:07:00,820 --> 00:07:02,820
everything that we do,
uh,

127
00:07:02,940 --> 00:07:07,360
we have to make predictions not only about
what will happen where, but also when,

128
00:07:07,940 --> 00:07:10,180
especially when it comes
to anticipating things.

129
00:07:10,540 --> 00:07:14,680
And so we have to think very carefully
about the timing of events that happens

130
00:07:14,681 --> 00:07:19,180
in our, in our, in our both in
our experiments and our analysis.

131
00:07:19,510 --> 00:07:23,470
And we have to be precise about that.
And that's something that in psychology,

132
00:07:23,650 --> 00:07:24,880
you know,
some people have thought about,

133
00:07:24,881 --> 00:07:29,290
but really we've lacked the technology
to sort of really link up physiological

134
00:07:29,291 --> 00:07:34,291
measures online with emotional
tendencies and emotional self reports.

135
00:07:34,630 --> 00:07:37,960
And what I mean by that is that you would
want to have sort of a self report of

136
00:07:37,961 --> 00:07:40,120
good versus bad,
sort of on an ongoing scale.

137
00:07:40,270 --> 00:07:44,170
But the very act of doing that kind of
a rating may interfere with the emotion.

138
00:07:44,230 --> 00:07:48,040
And so there are a lot of technical issues
that we need to resolve to get things

139
00:07:48,041 --> 00:07:51,580
on the same time scale so we can really
test our hypotheses about how affect

140
00:07:51,581 --> 00:07:52,750
matches up with brain activity.

141
00:07:53,290 --> 00:07:53,411
Well,

142
00:07:53,411 --> 00:07:57,130
it's interesting you're talking about
timing and kind of the Tempur or focus of

143
00:07:57,131 --> 00:08:00,990
the studies that we do because one of
the many amazing things you've done,

144
00:08:01,000 --> 00:08:01,421
your research,

145
00:08:01,421 --> 00:08:06,250
but one of them has really been to
parse apart the anticipation from the

146
00:08:06,251 --> 00:08:07,960
consumption of rewards.

147
00:08:08,230 --> 00:08:11,500
And so I know this is something that
is relevant to just a host of different

148
00:08:11,501 --> 00:08:15,760
fields, not only in you know,
aspect of science, but in
clinical science, you know,

149
00:08:15,761 --> 00:08:17,350
thinking about economic decision making.

150
00:08:17,620 --> 00:08:20,530
And I wonder if you could just tell us
a little bit about what this distinction

151
00:08:20,531 --> 00:08:23,770
is between wanting something
and liking something.

152
00:08:24,130 --> 00:08:26,920
Right. So, um, I joke with
people that a lot of my,

153
00:08:27,190 --> 00:08:31,420
you're imaging experiments that are really
built around rat experiments and it's

154
00:08:31,421 --> 00:08:34,810
really true like going in and studying
rats and they're basic motivational

155
00:08:34,811 --> 00:08:37,960
states really informs even our,
uh,

156
00:08:38,020 --> 00:08:41,200
studies of how people decide whether to
invest or not or whether they want to

157
00:08:41,201 --> 00:08:43,900
buy an item or not. Obviously ratchet
aren't doing this, but they're deciding,

158
00:08:44,200 --> 00:08:46,640
I want to get that food. I want
to look away that Predator. Uh,

159
00:08:46,641 --> 00:08:49,600
and we think that those motivational
surrogates are not only conserve but are

160
00:08:49,601 --> 00:08:54,520
used by all of us in our day
to day decisions. Um, so, uh,

161
00:08:55,760 --> 00:08:58,800
I want to make sure I get your, uh,
the answer your question, right.

162
00:09:00,570 --> 00:09:03,300
Locations of this, what is the
difference between wanting and liking?

163
00:09:03,301 --> 00:09:07,050
So once thanks in rats,
it's very interesting.

164
00:09:07,051 --> 00:09:10,290
He's by Kent Berridge at the University
of Michigan is he's been able to

165
00:09:10,560 --> 00:09:14,740
neurochemically and to some extent
in euro anatomically dissociate, um,

166
00:09:15,030 --> 00:09:18,050
wanting,
what do you call is wanting from liking a,

167
00:09:18,060 --> 00:09:21,330
and then he does these clever experiments
where he has rats eating food and he

168
00:09:21,331 --> 00:09:25,020
puts them on a plexiglass plates.
You can observe their mouth movements.

169
00:09:25,290 --> 00:09:27,610
He can distinguish, uh, you know, um,

170
00:09:27,990 --> 00:09:32,150
at the tasty movement of licking your
lips to us, sucrose solution from the,

171
00:09:32,710 --> 00:09:37,290
the disgust expression of gaping and
spitting out things which also human

172
00:09:37,291 --> 00:09:38,124
infants and even show

173
00:09:38,370 --> 00:09:40,500
and typical expressions of Brian's here.

174
00:09:41,220 --> 00:09:43,870
Yeah. So I often make these
expressions, unfortunately, you know,

175
00:09:43,871 --> 00:09:48,400
my students complain about it,
but you do. Uh, yes. But so, uh,

176
00:09:48,570 --> 00:09:50,890
he can distinguish these
as hedonic measured.

177
00:09:50,891 --> 00:09:53,970
So when he calls liking from
actually how much food you eat.

178
00:09:54,420 --> 00:09:58,780
And what he finds is that if you give
them raw dopaminergic drug that stimulates

179
00:09:58,890 --> 00:10:01,770
dopamine, they'll eat more. They
don't show more tasty expressions,

180
00:10:02,040 --> 00:10:05,040
you giving them an opiate
charging drug like heroin. Um,

181
00:10:05,100 --> 00:10:08,850
they will actually not eat,
but they will show more lip smacking.

182
00:10:09,210 --> 00:10:12,060
So we can distinguish the so
called wanting from liking.

183
00:10:12,510 --> 00:10:15,580
And one idea that we've uh,
uh,

184
00:10:16,320 --> 00:10:19,650
we've used his ideas and we've sort of
extended them into the human realm is

185
00:10:19,651 --> 00:10:22,770
that the one thing is about appetitive
motivation is about going out and getting

186
00:10:22,771 --> 00:10:27,360
good stuff. It has an evolutionary
value, uh, and the liking is different.

187
00:10:27,361 --> 00:10:30,480
It's about saying, okay, this was good
and now we should go for more of it.

188
00:10:30,480 --> 00:10:32,400
And so obviously those
things should be correlated,

189
00:10:32,670 --> 00:10:36,780
but it should happen at different points
in a cycle of consuming something.

190
00:10:36,900 --> 00:10:38,250
First you have a positive motivation.

191
00:10:38,330 --> 00:10:40,290
If it gets you to go
out and get good stuff,

192
00:10:40,590 --> 00:10:43,680
then you have the liking and that she
can better feed feedback and informed the

193
00:10:43,720 --> 00:10:45,710
Watson. But the, the,

194
00:10:45,720 --> 00:10:48,660
the new developments in brain imaging
have allowed us to actually just

195
00:10:48,690 --> 00:10:52,950
explicitly in time separate out when you
want something from when you like it.

196
00:10:53,230 --> 00:10:56,880
And we haven't actually looked at at
tastes so much even looked at money cause

197
00:10:56,881 --> 00:11:01,470
we wanted to focus on the wanting
component and money is really great.

198
00:11:01,471 --> 00:11:03,390
It gives you lots of control.
Okay.

199
00:11:03,940 --> 00:11:06,550
Yes. I wondered if you actually
wanted to say something about this.

200
00:11:06,551 --> 00:11:10,370
I mean you developed the tasks that
thousands of researchers have used the

201
00:11:10,630 --> 00:11:12,500
monetary incentive delay task.
Yeah.

202
00:11:13,070 --> 00:11:14,060
Yeah.
So we didn't stay,

203
00:11:14,120 --> 00:11:17,690
we developed this task because we were
frustrated with other aspect of stimuli.

204
00:11:18,050 --> 00:11:21,370
We've found them to be too variable that
people had variable reactions even in

205
00:11:21,380 --> 00:11:25,310
the sugar water. Uh, it's pictures
and so forth. And so we thought,

206
00:11:25,311 --> 00:11:27,070
well money should engage people.
And,

207
00:11:27,100 --> 00:11:29,970
and in fact it does and it shouldn't
elicit affective responses.

208
00:11:29,971 --> 00:11:33,530
And in fact it does. That's a big
advantage. And we've seen this, you know,

209
00:11:33,531 --> 00:11:37,280
not only an undergrads but
also in community samples
and people all around the

210
00:11:37,281 --> 00:11:40,520
world when they are
anticipating a monetary gain.

211
00:11:40,550 --> 00:11:43,280
We see a prominent positive arousal.

212
00:11:43,281 --> 00:11:46,280
We see neural responses when
they're anticipating losing money.

213
00:11:46,281 --> 00:11:49,610
We see positive and negative or, uh, a
prominent negative arousal, not positive.

214
00:11:50,120 --> 00:11:52,400
And we also see other
neural responses to that.

215
00:11:52,760 --> 00:11:56,800
And so it just so happened adventitious
leave that money turned out to be great

216
00:11:56,980 --> 00:12:01,870
brain imaging tool to elicit activity and
these motivational circuits. Um, and so,

217
00:12:02,230 --> 00:12:06,460
uh, we did that work funded
by the NIH and they di,

218
00:12:06,490 --> 00:12:09,730
they funded us because they wanted us
to be able to visualize these circuits

219
00:12:10,030 --> 00:12:14,200
that have also been implicated, not
just in one thing and so forth. Uh,

220
00:12:14,380 --> 00:12:18,500
but also in, uh, uh, psychiatric
disorders. And so, um,

221
00:12:18,880 --> 00:12:20,560
there's sort of two levels of what we do.

222
00:12:20,561 --> 00:12:22,240
One level is what I call the phasic level.

223
00:12:22,241 --> 00:12:25,250
It's sort of like the decisions we
make on an everyday basis. Yeah.

224
00:12:25,270 --> 00:12:26,650
There's what I'd call the tonic level,

225
00:12:26,651 --> 00:12:30,370
which is sort of individual differences
and the responsiveness of these circuits.

226
00:12:30,371 --> 00:12:33,550
And that's, that's the level at which
people are interested in these tasks.

227
00:12:33,551 --> 00:12:35,680
Not just to understand
economic decision making,

228
00:12:35,890 --> 00:12:39,190
but to try to disentangle the
different symptom profiles that people,

229
00:12:39,191 --> 00:12:40,480
psychiatric disorders,
Sab,

230
00:12:40,960 --> 00:12:44,740
and maybe visualize what the
overall responsiveness of
these circuits and try to

231
00:12:44,741 --> 00:12:49,330
understand whether that can help us to
predict how they'll do with a therapy or

232
00:12:49,331 --> 00:12:51,100
a drug regimen or whether they'll improve

233
00:12:51,810 --> 00:12:56,160
such important clinical
health implications of the
work you do and of the tasks

234
00:12:56,161 --> 00:12:58,930
you developed.
I know many people use it in myself,

235
00:12:58,931 --> 00:13:01,980
in my lab trying to parse
apart the nature of, you know,

236
00:13:01,981 --> 00:13:06,840
reward and people suffering from mood
disorders thanks to your task. Well,

237
00:13:06,870 --> 00:13:08,010
I hope it will be useful.

238
00:13:09,810 --> 00:13:12,310
It's a little scary. I mean, you know, uh,

239
00:13:12,390 --> 00:13:16,590
I didn't think it would be so widely
used when we developed it. Uh,

240
00:13:16,710 --> 00:13:19,530
and you never know with neuroimaging,
what's going to be a good probe.

241
00:13:19,920 --> 00:13:22,890
That's part of the reason we have to
do all this localization work is that,

242
00:13:23,400 --> 00:13:26,960
you know, you never know actually how
the brain is responding to things. Uh,

243
00:13:26,970 --> 00:13:30,990
you know, and this is an issue, you know,
just going back to emotion research,

244
00:13:31,260 --> 00:13:34,380
we don't know actually how the brain
is emotionally responding to things.

245
00:13:34,560 --> 00:13:36,780
We don't know if it's doing
so in a dimensional way,

246
00:13:37,080 --> 00:13:39,870
in a categorical way if
it's not doing so at all.

247
00:13:39,871 --> 00:13:43,820
Some people are arguing that
you can't even see value in
the brain, you know, and,

248
00:13:43,821 --> 00:13:46,290
and this seems unlikely to need,
but it could be true.

249
00:13:46,620 --> 00:13:50,640
So on the one hand, there's
all this promise, you know,

250
00:13:50,641 --> 00:13:55,140
maybe we can tease apart psychiatric
symptom profiles, we can predict choice.

251
00:13:55,410 --> 00:13:56,243
On the other hand,

252
00:13:56,460 --> 00:14:00,240
there's still a lot of open questions
about how actually is the brain responding

253
00:14:00,241 --> 00:14:01,930
to things emotional and,
uh,

254
00:14:01,990 --> 00:14:04,500
and how can we visualize that
using the tools that we have.

255
00:14:05,800 --> 00:14:07,390
So lots of unanswered mysteries,

256
00:14:07,391 --> 00:14:11,680
which keeps academics and researchers
in the field busy. Right? Keep us busy.

257
00:14:12,160 --> 00:14:15,520
So you talked a little bit about
how this work has implications for

258
00:14:15,640 --> 00:14:17,410
psychopathology and mental health.

259
00:14:17,860 --> 00:14:21,490
Do you think it has important implications
also for economic decision making?

260
00:14:22,090 --> 00:14:23,590
I do. Um, you know,

261
00:14:23,591 --> 00:14:27,360
I just got back from Nyu where I was
talking about neuro marketing. Hmm.

262
00:14:27,490 --> 00:14:29,890
So there've been all
these kinds of fields.

263
00:14:29,891 --> 00:14:34,360
Neuros dash field's emerging from this
and a lot of promises, you know, uh, by,

264
00:14:34,390 --> 00:14:38,830
not necessarily by scientists but by
people run businesses or the press.

265
00:14:39,340 --> 00:14:43,540
And you know, there's a lot of hype to be
honest. But I do think there is promise.

266
00:14:43,870 --> 00:14:48,130
Uh, and the reason I think
there is promise is that we
can actually at this point

267
00:14:48,400 --> 00:14:49,930
take these signals out of the brain,

268
00:14:49,931 --> 00:14:53,840
these anticipatory that we associate
with positive arousal, negative arousal,

269
00:14:54,260 --> 00:14:57,890
and use them to predict better than
chance whether people will decide to buy

270
00:14:57,891 --> 00:15:01,100
something, whether they will
decide to take a financial risk,

271
00:15:01,340 --> 00:15:04,360
whether they'll decide to take
a gamble for instance. Uh,

272
00:15:04,550 --> 00:15:08,220
and we don't have to know this is without
knowing anything about who you are, uh,

273
00:15:08,240 --> 00:15:12,980
what you saw or your explicit stated
preferences for those items. Um,

274
00:15:12,981 --> 00:15:16,400
so this is pretty exciting. This is
almost like mind reading, if you will.

275
00:15:16,790 --> 00:15:20,180
And we know that these
solutions generalize across
people. So it's not just that,

276
00:15:20,450 --> 00:15:21,980
you know,
I have a really good map of June's brain,

277
00:15:21,981 --> 00:15:24,230
but it's not going to work in my brain.
Um,

278
00:15:24,500 --> 00:15:28,670
so for us this is very exciting because
it gets that not just description and

279
00:15:28,671 --> 00:15:32,660
explanation that also prediction and
perhaps control which are the goals of

280
00:15:32,661 --> 00:15:36,020
science. Um, and, uh,
right now I'd say we're,

281
00:15:36,021 --> 00:15:41,021
we're at about 75% in predicting what
people will buy a and if we ask people

282
00:15:41,841 --> 00:15:45,650
what they like and how much they'll pay a,
I'd say we get a similar predictions.

283
00:15:45,680 --> 00:15:46,720
So,
uh,

284
00:15:46,730 --> 00:15:51,730
but there are other instances where
people have predicted choice even in,

285
00:15:51,811 --> 00:15:52,041
in the,

286
00:15:52,041 --> 00:15:55,790
in the case that somebody has not said
that they explicitly likes something.

287
00:15:55,791 --> 00:16:00,791
So I'm thinking of a study by Greg Burns
on adolescents listening to music and

288
00:16:01,491 --> 00:16:05,780
then trying to predict how well those
songs sold three years later. Uh,

289
00:16:05,800 --> 00:16:08,940
and using nuclease to Cummins
activity to actually predict songs.

290
00:16:08,941 --> 00:16:10,550
Sales when adolescents,

291
00:16:10,640 --> 00:16:15,020
explicit writing ratings of liking
did not predict this on sales.

292
00:16:15,310 --> 00:16:19,010
Those kinds of experiments are like
science fiction and they need to be

293
00:16:19,011 --> 00:16:22,130
replicated obviously. But it's
pretty interesting from, uh,

294
00:16:22,190 --> 00:16:24,860
from the standpoint of applying science.
Well,

295
00:16:24,861 --> 00:16:29,861
and you've also to try to understand
how we anticipate aspect and how that

296
00:16:30,111 --> 00:16:34,940
relates to financial risk taking
too. That's right. Yeah. I mean,

297
00:16:34,941 --> 00:16:37,580
we think that I'm using these methods,
uh,

298
00:16:37,581 --> 00:16:42,581
we can just get another window on
anticipatory effect and the people and use

299
00:16:42,771 --> 00:16:46,580
that to understand not only just minute
to minute or second to second decisions,

300
00:16:46,760 --> 00:16:51,420
but also life financial outcomes. And you
know, a lot of people have looked at, uh,

301
00:16:51,590 --> 00:16:55,520
health outcomes and emotional traits, you
know, and I think that's very important,

302
00:16:55,521 --> 00:17:00,410
actually understudied. Um, but not many
have looked at life financial outcomes.

303
00:17:00,410 --> 00:17:02,660
It's like, you know, how many
assets do you have? How am I,

304
00:17:02,710 --> 00:17:07,370
how many dads do you have? Um, what
is your risk preference profile?

305
00:17:07,640 --> 00:17:09,190
Uh, but in fact, you know, uh,

306
00:17:09,380 --> 00:17:13,070
it could be that these
things are completely
circumstantial. So that is that,

307
00:17:13,100 --> 00:17:14,840
you know,
the things that happened to you in life.

308
00:17:14,841 --> 00:17:18,710
And we all know that those can have a
serious impact on your finances matter

309
00:17:18,750 --> 00:17:19,550
quite a bit.

310
00:17:19,550 --> 00:17:24,550
But it also could be that they're enduring
dispositional effective styles that

311
00:17:25,460 --> 00:17:29,840
influence your financial decisions over
and over and over and that that can have

312
00:17:29,841 --> 00:17:32,750
a cumulative effect on your life.
Financial outcomes.

313
00:17:32,960 --> 00:17:36,320
And we just started in deed
defined that some of our markers,

314
00:17:36,321 --> 00:17:41,150
you both behavioral and neural of an
effect of style are Arlene to life

315
00:17:41,151 --> 00:17:41,841
financial app.

316
00:17:41,841 --> 00:17:45,830
And so we can find for instance that a
performance on a simple game learning

317
00:17:45,831 --> 00:17:50,070
task is linked to assets,
uh, or performance on a
simple loss learning tasks,

318
00:17:50,071 --> 00:17:55,050
which looks the same to a behaviorist is,
is linked to an absence of debts.

319
00:17:55,230 --> 00:17:58,350
This is one of the far out findings
that we have recently that you know,

320
00:17:58,530 --> 00:18:00,540
we're replicating but um,

321
00:18:00,870 --> 00:18:05,520
we can look at these efficacy
profiles sort of bed many levels.

322
00:18:05,521 --> 00:18:06,720
And that's exciting to me too.

323
00:18:06,721 --> 00:18:11,310
So we can not just be comfortable with
asking people on a questionnaire the

324
00:18:11,311 --> 00:18:11,941
psychometrics,

325
00:18:11,941 --> 00:18:15,600
but also trying to link that to brain
structure and brain function. Uh,

326
00:18:15,720 --> 00:18:18,530
and to distinguish it from other types of,
um,

327
00:18:18,900 --> 00:18:23,220
individual differences is like the working
memory or reversal learning or things

328
00:18:23,221 --> 00:18:24,000
like that.

329
00:18:24,000 --> 00:18:27,360
It seems like a really important theme
in your work has really been just linking

330
00:18:27,361 --> 00:18:31,320
data across multiple levels of analysis
to really get at the questions that are

331
00:18:31,321 --> 00:18:32,250
most important.

332
00:18:32,890 --> 00:18:36,880
That's actually how I characterize
our work to students. As I say,

333
00:18:37,210 --> 00:18:41,320
you know what we were added value is or
what we seem to be good at is saying,

334
00:18:41,321 --> 00:18:44,680
here's a really big effect up here.
Here's another big effect down here.

335
00:18:45,430 --> 00:18:48,940
How are those connected?
Are they connected at all?
And it sounds really easy,

336
00:18:48,941 --> 00:18:52,240
but it's actually quite difficult because
you have all these other effects at

337
00:18:52,241 --> 00:18:54,790
this level and at that level
and they're sparse connections.

338
00:18:54,791 --> 00:18:58,570
So only a few of those things are actually
robustly connected. But I find it,

339
00:18:58,650 --> 00:18:59,860
it's really rewarding.

340
00:19:00,070 --> 00:19:03,820
It allows me to talk to and work with
colleagues in other areas and that's how I

341
00:19:03,821 --> 00:19:04,660
want him to fastest.

342
00:19:05,260 --> 00:19:08,860
So when you think then about where the
sort of future of the field is headed,

343
00:19:09,160 --> 00:19:12,970
do you think a big part is linking these
disparate areas or where do you see the

344
00:19:12,971 --> 00:19:14,590
future of emotion headed and Europe?

345
00:19:14,780 --> 00:19:19,510
Wow, I'm biased by you know,
the direction we're going.

346
00:19:19,511 --> 00:19:22,870
So I will be really interested to listen
to your other interviews. You know,

347
00:19:22,871 --> 00:19:25,680
what other people say, be educated.
But of course, you know, for,

348
00:19:26,080 --> 00:19:28,750
for us what I want is this
linking of the levels.

349
00:19:28,960 --> 00:19:33,960
So I want to see how his brain function
connected to effect of self reporting

350
00:19:34,661 --> 00:19:38,620
and how is that connected to choice and
how is that connected to life outcomes.

351
00:19:38,770 --> 00:19:43,150
I want that vertical linkage. Um, and,
and you know, I want it to be empirical.

352
00:19:43,151 --> 00:19:44,780
I want it to have numbers.
Um,

353
00:19:45,340 --> 00:19:49,510
I wanted to have sort of
transfer functions that we
can use to like say, okay,

354
00:19:49,720 --> 00:19:52,470
if this event happened,
if dopamine fired, um,

355
00:19:53,050 --> 00:19:56,350
if they're likely to take this financial
risk. And if they do that enough,

356
00:19:56,650 --> 00:19:59,770
they're likely to put more money
in their bank or not, you know,

357
00:19:59,950 --> 00:20:02,770
and that will have the
following social impact.

358
00:20:02,771 --> 00:20:05,470
So it would be really cool to have
a theory with that kind of power,

359
00:20:05,650 --> 00:20:08,200
that kind of cross level
power. Um, so that's one,

360
00:20:08,500 --> 00:20:10,480
one thing on my wishlist is
to have something like that.

361
00:20:10,720 --> 00:20:12,780
That's a fantastic wishlist.
Items.

362
00:20:14,410 --> 00:20:16,600
Hopefully we'll see what
the funding agencies thing.

363
00:20:18,420 --> 00:20:22,380
So then the last question I had for you
is just what kind of advice would you

364
00:20:22,381 --> 00:20:26,730
give students who are thinking about
embarking in this kind of wild field,

365
00:20:26,731 --> 00:20:29,250
almost science fiction?
Like as you said of emotion.

366
00:20:29,570 --> 00:20:31,460
Um, what, what would you tell them?

367
00:20:32,900 --> 00:20:37,460
It's tricky and I should have thought
about this more before we talked, but you,

368
00:20:37,850 --> 00:20:41,900
because what I usually tell my students
is don't do what I did, uh, which is,

369
00:20:42,170 --> 00:20:45,800
you know, I spent, I literally
spent, you know, nine,

370
00:20:45,860 --> 00:20:48,010
eight or nine years
without any interviews.

371
00:20:48,011 --> 00:20:52,820
So I graduated with a phd,
I went into a Postdoc,

372
00:20:52,840 --> 00:20:55,970
I was on the market, you
know, for eight years. Uh,

373
00:20:56,050 --> 00:20:58,370
nobody was interested
in what I was doing a,

374
00:20:58,410 --> 00:21:02,420
or they probably just
thought it was pulling two
preliminary and then suddenly a

375
00:21:02,480 --> 00:21:04,760
eight interviews and four offers. So, uh,

376
00:21:04,761 --> 00:21:07,390
that was about the time I was
publishing my brain imaging stuff.

377
00:21:07,391 --> 00:21:09,640
So for a while it looked like,
you know,

378
00:21:09,670 --> 00:21:13,540
this guy is doing crazy stuff and
then suddenly everybody's like, oh,

379
00:21:13,541 --> 00:21:15,760
this is feasible. We can do
this. This is interesting.

380
00:21:16,570 --> 00:21:20,920
And so it's very hard to
predict the Zeitgeist guys.
It's sort of like investing.

381
00:21:20,921 --> 00:21:25,870
It's hard to predict the market and I
don't know what the optimal strategy is.

382
00:21:25,871 --> 00:21:29,170
I think, I almost think for a
person like me, if you're like me,

383
00:21:29,200 --> 00:21:31,990
which probably many people are not,
um,

384
00:21:32,260 --> 00:21:35,470
I had to have the intrinsic motivation
to pull me through. Uh, and,

385
00:21:35,471 --> 00:21:38,830
and the conviction that what I was doing
was really the right way to answer the

386
00:21:38,831 --> 00:21:40,390
question,
which is how do emotions were.

387
00:21:40,660 --> 00:21:43,210
I felt like I had to go
to the neural level. Um,

388
00:21:43,270 --> 00:21:46,780
I'm not sure if that's a good strategy.
Now I guess what I would say,

389
00:21:46,960 --> 00:21:50,650
the two things I would say
are get a good strong effect.

390
00:21:51,210 --> 00:21:52,550
The behavioral effect,
not a,

391
00:21:52,560 --> 00:21:56,260
not a neural effect that you can really
tweak in different ways and explain and

392
00:21:56,261 --> 00:21:59,440
explore different levels. Um, that's
one thing that I think is useful.

393
00:21:59,650 --> 00:22:03,140
Another thing is, uh,
get a good method and,

394
00:22:03,240 --> 00:22:07,620
and explore a new method that
you can be an expert in a,

395
00:22:07,630 --> 00:22:12,270
because I think then you're not only an
expert on some sort of field or the fact

396
00:22:12,870 --> 00:22:16,360
that you've investigated, but to be an
expert in a Methodist, quite valuable,

397
00:22:16,361 --> 00:22:17,770
especially in neuro imaging,

398
00:22:17,800 --> 00:22:20,080
the way that things are advancing
every year that are the new things.

399
00:22:20,380 --> 00:22:21,610
And there are new things to explore.

400
00:22:21,730 --> 00:22:24,460
It's not as easy as it sounds because
you want to be an expert in a method that

401
00:22:24,461 --> 00:22:25,900
you think will have some longevity.

402
00:22:26,170 --> 00:22:29,170
But there are so many needs out
there for better methods. Um,

403
00:22:29,230 --> 00:22:32,780
and so I think there's
a lot of opportunity for
students to become experts in

404
00:22:32,781 --> 00:22:33,614
that way.

405
00:22:33,810 --> 00:22:37,140
Thank you so much for speaking
of the three, Ryan. It was great.

406
00:22:37,260 --> 00:22:38,520
Great hearing your thoughts.

407
00:22:38,580 --> 00:22:41,730
This concludes our expert
and emotion interview series.

408
00:22:41,731 --> 00:22:44,310
That's doctor Brian Knutson,
front of Stanford University.

