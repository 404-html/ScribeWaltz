Speaker 1:          00:00          Welcome back to human emotion. Today we're going to be talking about the way in which emotions may actually influence our sense of what is right from what is wrong. So this is the field referred to as emotion and morality. Now in what way could emotions really shape our sense of what's morally right and morally wrong? Well, if we think about emotions and morality, some recent work that's actually emerged here at Yale University by researchers, Kylie Hamlin, Paul Bloom, and Karen when has showed that young babies as young as the one you can see right here in the photo have this almost innate sense of right from wrong and a preference for morally right and good characters over morally wrong characters. So it seems that were almost born with this tendency to discriminate between right and wrong and actually prefer, you know, the morally right or good person. Moreover, moral judgments are a pervasive part of humanity.

Speaker 1:          00:57          We can see a variety of different religious doctrines that really outline, um, the ways in which, you know, emotions and feelings essentially play a role in our moral judgements. So in Buddhism, you know, there's these doctrines that sit suggest to hurt, not others with with that which pains yourself. Um, were Christian based traditions say all things whatsoever he would, that men should do to you. Do you, do you even? So to them for this is the law and the prophets. And finally on the right you can see here within Muslim traditions, no one of you is a believer until he desires for his brother that which he desires for himself. And so what you want to see here is that across different religious traditions, not only our moral judgments pervasive, but that part of what underlies these moral scruples are emotions themselves. Seeing emotions like pain or seeing emotions here, like desire.

Speaker 1:          01:52          So it seems that what my actually underlie, our very sense of right and wrong are our feelings or emotions towards actions of other people as well as actions of ourselves. So this leads us to think that, you know, emotions seem to play this orchestra role in guiding our moral beliefs in our moral judgments. But in another words, you know, can we be more without emotions? In other words, how much do emotions essentially influence our sense of what is right from what is wrong and how much can emotions also influence morally relevant behavior? So both for the good as well as the bad. Um, so these are some of the questions we're going to be looking at today where we're going to be really looking at, as you can see here, the good from the bad. And to what extent emotions play a role in shaping who we are.

Speaker 1:          02:43          Can they actually shape our moral character? Some people may say then, well, if emotions play such a central role in shaping the goodness and badness of who we are and the goodness and badness of our behaviors, then our really just elaborated feelings that we have some feeling of desire and we put these kind of cognitive and linguistic layers on top of it and turn that into a moral judgment. Can there be more to morality than just emotions? So today we're going to be looking at things such as the sense in which we feel bad for people who suffer. We think that that's morally wrong. We also feel a sense of loyalty to friends and family, right? We think there's a sense of being morally good if we're loyal to those close around us. We also feel guilty about doing things that we consider morally wrong or bad.

Speaker 1:          03:38          So what we're seeing here is emotions are feeling compassion for those who suffer loyalty or love towards family and friends and guilt about doing what we consider to be morally wrong. Things that go against our own values like pigging out at a kitchen, you know, fridge late at night. So then a question comes up, do emotions, can they actually causally make us good people? And if so, what kinds of emotions make us good people? By contrast, can emotions also make us bad? And to what extent can they even help explain some of the most heinous and evil behavior known to mankind? Can, did emotions really play a role in shaping some of the altruistic behavior, you know of mother Theresa and some of the, you know, just morally repugnant behavior of Hitler. So here's where I want to guide us today. So this is our segment on emotions and morality.

Speaker 1:          04:34          And this is going to be our introduction to what are called moral emotions. And this is our part one of a three part series on moral emotions. So what we're gonna do today is I'm first going to introduce you to what our moral emotions. Second, we're going to look at the ways in which researchers have tried to organize different families or classes of moral emotions. Then we'll actually talk about the extent to which, you know, contemporary neuroimaging research actually suggests that our brain may actually play a critical role in determining our more reactions to different kinds of behaviors. Finally, we'll conclude with our normal tea takeaway questions. And we'll have a couple expert interviews today with two renowned experts on morality and emotion. So let's start today by first introducing this concept of moral emotions. Sort of what do we mean by this term? Are these a specific class or type of emotions?

Speaker 1:          05:32          So one of the sort of fathers of moral emotions, um, is Jonathan Height. So he seen as the authoritative figure here and has wrote several comprehensive pieces about what exactly moral emotions are. This includes, as you can see here, his writings on the moral emotions as well as what he called the new synthesis in moral psychology. And John Hype said, morality is therefore like the temple on the hill of human nature. It is our more sacred attributes, a trait that is often said to separate us from other animals and bring us closer to God. So when describing moral emotions, he highlights the fundamental importance to all humans of morality and moral virtues. So what is a moral emotion then? So recent theorists have suggested that emotions, as we've seen earlier, play a huge role in morality. They shape what's wrong and what's right. And in fact, they may even be in charge of this temple of morality, as alluded to in the quote earlier by Jonathan Height.

Speaker 1:          06:38          And if we look at what a definition of moral emotions might be, we see here that the moral emotions are those emotions that are linked to the interest or welfare of either society as a whole or people other than the agents. And in particular height identified what he thought of his to prototypical features of a moral emotion. The first, he called disinterested, illicit hers. So some emotions occur when good or bad things happen to oneself, like fear or happiness, and they require the self to be related to something outside of oneself. Maybe you're happy that your friend got engaged or you're fearful. You know that someone that you don't like, um, maybe after you, right? But other emotions are triggered when your own self has nothing at stake, right? And the triggering event, like seeing photos here of a starving child or an abused animal, right?

Speaker 1:          07:34          Um, and the more and emotion can be triggered by what's called these disinterested Alyssa sitters. So things in which the self has nothing at personal stake, the more it can be considered a prototypical emotion response. So that's the first feature of a moral emotion as proposed by Jonathan Height. The second is what he referred to as a pro social action tendency. So what's really unique about moral emotions is that they motivate a very specific kind of behavior or action tendency. Um, but it's not to fight or it's not to flee or it's not to rest. Instead, moral emotions are associated with action tendencies that are really geared at benefiting other people or trying to uphold the general social order. So this is what's referred to as these pro social action tendencies that are part and parcel of what a moral emotion is. Now here what you see is a figure that has been illustrated by John Height that really tries to depict two of these criteria we just talked about in two dimensional space.

Speaker 1:          08:43          You can see the prosocial, um, nature of the action tendency on the left and on the bottom right, the disinterestedness of the solicitors, right? So the prototypical moral emotions are what you're going to see in the top right corner. So here we see anger, elevation, guilt, and compassion. So what it's trying to do here is really distinguished between moral emotions, which are high on both of these domains, pro sociality, as well as disinterestedness, no solicitors from other kinds of emotions like sadness and pride and fear. So we've now briefly talked about what a moral emotion is. And we've talked about sort of the two prototypical features of a moral emotion. So now I want us to delve in more deeply to what's thought of as the family or classification system of the variety of different kinds of moral emotions out there. So now we're going to turn to this idea of moral emotion families as you can see right here.

Speaker 1:          09:39          So what are these emotions and how can we categorize them according to different categories of moral emotions or different ways in which they influence how we think of what is right versus how we distinguish what is wrong in the world around us. So this is what's considered the moral emotion families. And as you can see here, it's broken up into two larger families. The other condemning emotions, including contempt, anger, and discussed as well as self conscious emotions, uh, that we talked about earlier in class, including shame, embarrassment and guilt. And this is then also thought of as two smaller families, which include other suffering emotions like compassion and other praising emotions like gratitude and elevation. So we're going to start today with these two large families here. And in particular we're going to start here with the other condemning emotions. So this is content anger and discussed.

Speaker 1:          10:36          So this is what's called, in other words, the cad triad, right? So here John Height argued that we live in this rich world of reputations of third party concerns. He said, we care that what other people do to each other, right? And we readily develop negative feelings towards people we may have never even actually met, right? And it's these negative feelings towards characters that we may not even know that unites this family of what's called the aether condemning moral emotions. So this includes again, contempt, anger and disgust, or the CA d triad. And I'll walk you through each of these three according to the solicitor and their associated action tendency. So if we start with anger, what you can see here is that anger, which we talked about earlier in class, is elicited in response to goal blockage or frustration. So you're trying to pursue a goal and something gets in the way.

Speaker 1:          11:31          It's also associated in response to unjustified insults, betrayal, trail and unfair treatment. The action tendency associated with anger as to be motivated to attack back, right? To humiliate, to get revenge towards the person or thing that seems to be acting immorally. So we see that anger, for example, um, is a moral emotion in so far as it motivates us to readdress injustices and can be applied actually to the benefit of society in cases that include things like racism, oppression or exploitation, that anger may actually motivate us to act against. The societal injustices discussed is really interesting too cause we see discussed expanding out into the social moral domain to repel things that are disgusted. So this makes sense. And as adaptive when we think of contaminated food for example, but fascinatingly discussed seems to also sort of permeate our moral judgments that have nothing whatsoever to do with like toxic food substances.

Speaker 1:          12:33          So for example, we want little to do with things associated with Hitler for example. And little can be done, you know, to cleanse a sweater of, of a hated person, right? Um, so discuss is also prosocial as a moral emotion and that it motivates or triggers people to set up reward and punishment structures that really act as these strong deterrents to culturally inappropriate behaviors, especially those that involve the body. Um, so if we look here, we look at the illicit or have discussed, we see, um, two different kinds of discuss. We see core discussed, which is this sort of basic emotion. It's a rejection system, usually was food related and is really in response to food and trying to expel toxic food from the body. But when we start to expand, discuss and sort of bring it into the domain of morality, we see that it's thought of as this guardian of the temple of the body.

Speaker 1:          13:27          And it gets triggered by violation of cultural rules for how to use bodies. So when relating to drug use, sexual behavior, et cetera. And there's also the socio moral disgust for different kinds of social transgressions such as cruelty and behavior. Um, and the action tendency as a motivation to avoid, expel or break off contact with offending entities and can include motivations even wash or try to purify oneself, remove contact from this entity. Um, but what's sort of the dark side here of disgust and the way it relates to morality is that it can actually be really disturbing at times is it carries a sense of condemnation. So recent research by David Pizarro and colleagues has actually showed that discussed is a major underlying feature for the moral condemnation for example, of homosexuals. So you can sort of take, discuss too far and have it even pervade moral judgements about other people's sexual lives and behaviors.

Speaker 1:          14:29          Um, so disgust as a moral emotion. Let's talk about this a bit more. So there's different ways in which we can think of disgust as a moral emotion. So, and Pizarro and colleagues outlined three claims. You see the first year that attempt to describe really how discussed and moral judgments are causally connected. Um, so each of these makes a separate argument for how disgust and more morality are related. So I'll walk you through each of them. So the first is, you can see here is that disgust is a consequence of moral violations. So the claim here is that discussed is experienced as a result of appraising a mall that a moral violation has occurred. And in response to what are referred to as moral purity or taboo violations, some of this supportive evidence here is that, and this is a really interesting scenario that Paul Rosin and discussed, is that people actually experienced, discussed in response to what are thought of as very harmless moral violations.

Speaker 1:          15:27          So he'll to pick these scenarios where he asks people to report how they feel if a family's dog were run over by a car and they pick up the, you know, the pet dog and they decided to prepare and eat it for dinner. And most people will suggest that this is morally wrong, right? And that may be driven by a sense of disgust. Um, and then there's also another example of, you know, having sex with a dead chicken, right? This is somewhat a harmless moral offense, but many people report this being morally wrong. And it's almost a sense of disgust that drives these judgments. The second is this claim that discussed is an amplifier of moral judgments. So here what we see is that discuss seems to make things even more wrong than they are, right? So you may think something's wrong and discuss, just ratchets up the ante and makes you feel like it's even more wrong than it already was.

Speaker 1:          16:20          So some of the supportive evidence here is that when you induce feelings of disgust and people, they actually make harsher judgments of moral violations, right? So you definitely don't want, if you're, you know, going to court, um, and they're determining your sentence, you don't want your judge to already be feeling disgusted when he comes in because he's more likely to make a more harsh moral judgment and likely to perhaps even punish you further. So discuss just seems to make us more harsh and condemning the moral behaviors of others. And then finally, as you can see, or here at the bottom discussed, is also thought of as a moralizing emotion by itself. So the claim here is that morally neutral acts that are not inherently right or wrong can become moral in virtue of being perceived as disgusting. So in other words, the feeling of disgust itself is evidence that the act is morally wrong.

Speaker 1:          17:13          And this leads to what we talked about earlier where people who feel disgust towards homosexual behavior that that discussed itself is actually what may explain their antigay moral attitudes such as being gay must be wrong. This also applies to incest and people even feel this way watching neutral films. So the fact is just by feeling disgusted about something, it may lead you to then decide that it must be morally wrong. Um, so these are three ways in which you know, discussed, may be influencing our moral judgments. If you'd like to learn more about this, I highly recommend a Ted talk by David Pizarro, who's also one of our expert interviews later today where he talks about the way in which disgust influences many important and even, uh, you know, everyday political decisions we make in society, including our attitudes towards homosexuality, for example. So you, I highly recommend checking out his talk, which is entitled the strange politics of discussed and how it influences our moral life.

Speaker 1:          18:18          So finally, um, what I want to turn to now is contempt in this triad. So contempt is elicited when you're looking down on someone or feeling morally superior to them and you're perceiving that that other person just doesn't seem to measure up to the right sort of moral standards, right? So contempt is interesting in that it's almost this middle sibling of anger and disgust. It seems to kind of fall right in the middle. And the tendency that's associated with contempt is to promote this what's called social cognitive change or you treat others with less, more respect and less consideration. So if we think about this cad triad hypothesis, what really, um, it states is that there's moral emotions, um, that are experienced, um, at the core in response to violations of three moral codes as follows. So in other words, this, the cad, um, triad acts as guardians of different parts of the moral order.

Speaker 1:          19:17          So the first you can see here is see for community, which includes disrespect and violations of duty or here Archi. And this is where the experience of contempt plays in second is autonomy. So when you perceive moral violations of rights and fairness, it's emotion of anger, you know, sort of picks up and begins to play a role in moral judgments. And then finally the D is divinity. So here if there's potentially moral violations of physical purity such as food and sex taboos such in the case of homosexuality, incest, you know, having sex with the dead chicken. As we talked about earlier, these emotions of disgust really seemed to play a role in shaping our assumption that there's been these important violations. So it's community autonomy and divinity. So now what I want to turn to is the second domain of these two large families of moral emotions.

Speaker 1:          20:14          And these are the self conscious emotions. So we've talked about shame earlier in class, which is elicited by a negative evaluation of oneself. Um, the behavior includes a hunched over posture, retreating or hiding from a social group and a consequence in which are actually less likely to take corrective action. You kind of step back in a way. There's also embarrassment, which we've talked about earlier as well, associated with violating social conventions or norms and really motivates you to try to acknowledge mistake the mistake, remedy the social transgression and repair the relationship. And consequence actually promotes more sort of pro social actions like forgiveness, laughter, liking and trust. And then finally, guilt, which, um, we also talked about earlier. But as a refresher, this involves a negative evaluation of an action. One, did you feel negative emotion towards the target and you have a motivation to try to address the problem or remedy the behavior?

Speaker 1:          21:10          Okay. So how are these emotions, shame, embarrassment, and guilt? Actually moral emotions. So here we can see with shame, there's this distinction mooching prodo shame, which is nonmoral how one should act and what's called moral shame. So when you violate a norm and you know that someone else knows about the violation, and thus there's must be a defect in your one's core self. So you appraise oneself as morally bad. And the case of embarrassment, it can be a moral emotion when it's elicited by appraisals of one social identity or persona as either damaged or threatened. And finally with guilt, um, when you see a violation of more rules are imperatives, especially if they're caused, um, if they've caused harm or suffering to others, you then appraise your own actions as morally bad. So although these are self conscious emotions, they also play an important role in our own moral wellbeing and the way in which we evaluate to what extent the actions we've done are morally good, good or bad.

Speaker 1:          22:16          So these two smaller families, we'll touch in our next a second module and moral emotions where we turn to what's considered the lighter side of moral emotions where we talk about compassion and gratitude and elevation. Um, for now though, the last domain I want to cover today is this idea that can we actually have a moral brain? And hear this work was really spearheaded by Dr. Joshua Green at Harvard University who conducted one of the first studies using functional neuro imaging to investigate the role of emotional engagement in moral judgment. Right. So although up to this point, we had spoken a lot about how emotion plays an important role in moral judgements of what's right versus what's wrong. We have known very little about the neural correlates, that underlying emotional judgements. So Dr Josh Green and his colleagues tried to really systematically investigate these questions by having participants presented with different kinds of moral dilemmas while they were undergoing a functional magnetic resonance imaging scan.

Speaker 1:          23:19          So I'm gonna walk you through some of the moral dilemmas that participants in his study actually saw. And I'd like you to think too, while we go through these, um, what decisions you might have made when presented with these dilemmas. So the first dilemma, as you can see here is referred to as the trolley dilemma. So on the trolley dilemma and when something is follows. So there was a runaway trolley headed for five people. As you can see on the bottom track here, it's actually four people there, but it was headed for a group of people who would be killed if it proceeded on its course alone. And the only way to save them was to hit a switch. You're here standing with the switch and if you hit that switch, it would turn the trolley onto a different set of tracks at the top where it would kill one person instead of a larger group of people at the bottom.

Speaker 1:          24:07          So the question that I have for you is, should you, the person with the switch turn the trolley in order to save, you know, four or five people at the expense of killing one person. So what would you say in this scenario, what should you do? Well, most people in the scenario would say yes, they would switch the trolley to kill one person at the expense of four or five people down here at the bottom. The second dilemma is called the footbridge dilemma. And this is a little bit different, so consider a similar problem, um, but it's now called the footbridge dilemma. Instead of the trolley dilemma. So as before, you've got this crazy runaway runaway trolley that is threatening to kill a large group of people on the other side of the track, right? And you're now standing on a footbridge next to a very large, uh, overweight stranger.

Speaker 1:          24:59          And here, the only way to save this group of people is to just push this big guy off the bridge. So he lands and plops on the tracks below where his body is so large that he's actually going to stop the trolley mid action. Now he's going to die, but the other people will be saved. So should you say these other people normally refer to as, you know, a group of five people by pushing the stranger to his death, what would you say? Would you say, yes, you should do it or no, you shouldn't. What's really interesting here is that most people say, no, you should not do that. Even though they said yes and the earlier dilemma. So what we're seeing here, um, is that the top with our, um, trolley dilemma, people will say yes to pushing the lever to save a group of people at the expense of killing one person.

Speaker 1:          25:56          But they will say no to pushing someone off the bridge themselves to save the Group of people at the expense of the life of one person. So this has really created a puzzle for more researchers. Why is one scenario acceptable? But the others not? So Josh Green, his colleagues argue that the critical differences, how a Mo, how we emotionally process these two scenarios. So the footbridge scenario, the second one at the bottom seems to be more emotionally salient because you have to actually physically touch and push a man off the bridge. Whereas in the first scenario at the top, the trolley dilemma, Oh, you have to do is hit a switch. So it may be that some moral dilemmas actually engage a deeper and richer kind of emotional processing than others, which affects people's judgments of what is right and what is wrong. And he actually also tried to then understand what might be some of the um, you know, neural systems that are involved in differentiating these two scenarios.

Speaker 1:          26:58          So the first is our trolley dilemma and he talks about this as the moral impersonal scenario. So here what you saw in the research they did putting people into the scanner is more activation and cognitive processing and working memory systems such as the middle frontal gyrus and the right and left parietal lobes. By contrast, when we looked at the footbridge dilemma, this was called the moral personal condition. You actually saw greater activation in the posterior cingulate gyrus, the right and left angular gyrus, and the medial frontal gyrus, which are more heavily associated with emotional processes as opposed to more cold cognitive processes in the trolley scenario bub. So Green and colleagues concluded that what might be right versus wrong is actually driven by the extent to which emotional salience is processed in the brain as opposed to more kind of cool cognitive processing. So this is why we feel that one scenario up here is right and okay to do.

Speaker 1:          28:01          And the scenario down here is morally unacceptable or wrong to do so. Interesting. Then in conclusion was we think about morality in emotion. Let's ask ourselves a question. So Hume said, reason is an odd only to be the slave of the passions and can never pretend to be any other office than to say serve and obey them. So does emotion or morality predominate the other? So whether you take one perspective or the other that emotions completely override or morality or that our morality can exist. Independent arm of our emotions. I don't think that any of us can argue that emotions and morality are not centrally related to one another. And in fact, we know that emotions play a huge role in helping create and maintain our everyday sense of morality. And our sense of what is right is wrong, a right versus wrong, and a sense of what we feel is good from what we feel is bad.

Speaker 1:          29:02          And I think important. Wherever you stand in this debate, knowing more about moral psychology will help you understand why some people have different moral views. So why do some people view homosexuality is absolutely wrong? And others you'd is completely acceptable without any reservations whatsoever. So you might think about to what extent they're different emotional dispositions, maybe shaping beliefs as important as whether or not someone should or should not be able to be in a relationship with someone of the same sex, for example. Um, so think about this wherever you stand and knowing that emotions fundamentally shaped morality and that maybe one per chapter dominates over the other, but regardless of that, they both are intimately related to one another. So with that, I'm going to now conclude with our takeaway questions, um, and our introduction to moral emotions today. So the first question, um, covers what were the core features of what makes up a moral emotion in the first place?

Speaker 1:          30:09          How is it different from other classes of emotions? Second, can you describe the different moral families of an emotion? In other words, what is the cad triad hypothesis within this broader framework? Finally, what is the supportive neural evidence from studies using Fmri tools for the critical role of emotion in, in motivating and explaining moral judgments of right versus wrong. We'll now turn to our expert interviews today where we have two fascinating experts, leaders in the field of emotion and morality and this is part of our experts and emotion interview series for our expert in emotion interview. We have the honor of speaking with Dr Jonathan Heit. Jonathan Height is the Thomas Cooley professor of ethical leadership at the Nyu Stern School of business and received his Ba from Yale University and phd from the University of Pennsylvania. He then did his post doctoral research at the University of Chicago as well as in Orissa, Indiana or India.

Speaker 1:          31:18          Sorry, I'm just going to start that over. Okay. Cause I messed it up for our experts in emotion interview. We have the honor of speaking with Dr Jonathan Heit. Jonathan Heit is the Thomas Cooley professor of ethical leadership at the Nyu Stern School of business. He received his Ba from Yale University and phd from the University of Pennsylvania and also completed postdoctoral research at the University of Chicago. He was a professor at the University of Virginia from 1995 until 2011 when he joined the Stern School of business at Nyu. His research focuses on morality, it's emotional foundations, cultural variations and developmental course. He began his career first studying negative moral emotions, such as discussed shame and vengeance, but then later moved on to the understudied positive moral emotions such as admiration. Ah, an elevation. This work got him involved with the field of positive psychology in which he's been a leading researcher. He's the co developer of the moral foundations theory and of the research site, your morals.org he uses his research to help people understand and respect the moral motives of their enemies.

Speaker 1:          32:29          He's won three teaching awards from the University of Virginia and one from the governor of Virginia. He spoken twice at the Ted Conference, one on politics and one on religion. He's been named as a top 100 global thinker by in 2012 by foreign policy magazine and as the author of more than 90 academic articles and two books, including the happiness hypothesis, finding modern truth and ancient wisdom and the righteous mind why good people are divided by politics and religion. So I now turn to a very special experts and emotion interview with Doctor Jonathan Heit on morality and emotion.