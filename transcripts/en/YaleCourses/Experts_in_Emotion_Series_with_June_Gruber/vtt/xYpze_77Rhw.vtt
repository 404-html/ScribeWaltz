WEBVTT

1
00:00:00.600 --> 00:00:02.280
Welcome back to human emotion.

2
00:00:02.730 --> 00:00:06.870
So I want you to start out by first remembering a time that you felt a strong

3
00:00:06.871 --> 00:00:07.704
emotion.

4
00:00:08.250 --> 00:00:13.250
Now pause for a second in this exercise and really focus on what made you feel

5
00:00:14.341 --> 00:00:16.020
that emotion in the first place.

6
00:00:16.230 --> 00:00:19.740
Was it an image you saw a movie you recently watched,

7
00:00:20.070 --> 00:00:23.010
a conversation you had with a friend or a partner?

8
00:00:23.670 --> 00:00:26.790
So these are some of the questions we try to think about when we're trying to

9
00:00:26.791 --> 00:00:30.960
trigger emotions in the lab as emotion researchers.

10
00:00:31.320 --> 00:00:32.580
And we try to ask ourselves,

11
00:00:32.581 --> 00:00:37.560
how can we trigger and create these same feelings we all know and experience in

12
00:00:37.561 --> 00:00:41.640
our everyday life in the lab when we try to study emotion.

13
00:00:42.000 --> 00:00:46.320
So the spot exercise is really intended to get you to think about the kinds of

14
00:00:46.321 --> 00:00:50.940
emotions you experience and how if you were a scientist in this field,

15
00:00:51.210 --> 00:00:55.530
you might try to recreate those very same feelings in a research study.

16
00:00:56.340 --> 00:01:00.900
So one of the most authoritative handbooks on this topic and that will really

17
00:01:00.901 --> 00:01:04.890
guide much of what we discussed today is called the handbook of emotion

18
00:01:04.891 --> 00:01:09.010
elicitation and assessment by James Cone.
And John J out.

19
00:01:09.020 --> 00:01:12.270
And so this is also included in your weekly readings.

20
00:01:12.540 --> 00:01:17.540
So what we're going to be doing here today is discussing some of the common

21
00:01:17.881 --> 00:01:20.550
tools and methods of human emotion.

22
00:01:20.850 --> 00:01:25.770
So today we'll be focusing specifically on the laboratory elicitation of emotion

23
00:01:26.010 --> 00:01:30.510
by learning about all the different kinds of cool tools and methods that we can

24
00:01:30.511 --> 00:01:33.510
use to try to understand and quantify emotion.

25
00:01:33.660 --> 00:01:37.890
So imagine yourself here in the laboratory as an emotion scientist.

26
00:01:38.070 --> 00:01:41.820
What are you going to do?
How are you going to measure it?
So,

27
00:01:42.110 --> 00:01:45.540
and what we're going to be doing today is starting our first part of a three

28
00:01:45.541 --> 00:01:48.360
part series on emotion elicitation and measurement.

29
00:01:48.630 --> 00:01:52.740
Really getting at what actually makes us emotional in the first place,

30
00:01:52.980 --> 00:01:57.180
and how can we study it.
So our roadmap today will go as follows.

31
00:01:57.390 --> 00:02:01.260
We'll start by discussing several tools and methods used to elicit emotion,

32
00:02:01.530 --> 00:02:04.400
and then we'll move on to our takeaway questions for this lecture,

33
00:02:04.420 --> 00:02:07.740
covering the three broad content areas that you should have gained after

34
00:02:07.741 --> 00:02:08.760
watching this lecture.

35
00:02:09.210 --> 00:02:13.380
And finally we'll move on to our expert interview or announced figure in the

36
00:02:13.381 --> 00:02:17.010
area of emotion elicitation and the way that we measure it.

37
00:02:17.550 --> 00:02:22.290
So let's start with some of the tools and methods.
And before we do that,

38
00:02:22.530 --> 00:02:27.510
what I'd like to do is focus on three key emotion processes that these different

39
00:02:27.511 --> 00:02:31.680
tools can help us elicit or tap into.
So you already see the first one here,

40
00:02:31.681 --> 00:02:33.300
which is emotion reactivity.

41
00:02:33.570 --> 00:02:37.810
So this is one of the core processes and we try to elicit emotion that we focus

42
00:02:37.811 --> 00:02:42.780
on.
So emotion reactivity can be defined as the type magnitude and duration of a

43
00:02:42.781 --> 00:02:47.781
response to internal and external environmental accused that have significance

44
00:02:48.841 --> 00:02:50.220
for our personal goals.

45
00:02:51.360 --> 00:02:55.770
The second important process we try to elicit as researchers and scientists of

46
00:02:55.771 --> 00:02:58.320
emotion is what's called emotion regulation.

47
00:02:58.770 --> 00:03:02.830
So this has been defined as the processes by which individuals influence which

48
00:03:02.831 --> 00:03:05.260
emotions they have,
when they have them,

49
00:03:05.261 --> 00:03:09.730
and how they experience and express these emotions.
Finally,

50
00:03:09.731 --> 00:03:11.650
we have emotional understanding.

51
00:03:11.860 --> 00:03:15.670
So this is different from reactivity in regulation is it's more focusing on the

52
00:03:15.671 --> 00:03:18.400
knowledge that people have about,
you know,

53
00:03:18.401 --> 00:03:21.850
whether we or other people are experiencing emotions.

54
00:03:22.030 --> 00:03:25.750
So can we accurately pick up on her own emotions in the moment and can we

55
00:03:25.751 --> 00:03:28.780
actually see and detect them and other people?

56
00:03:30.400 --> 00:03:31.233
<v 1>So</v>

57
00:03:33.930 --> 00:03:38.340
<v 0>we'll be focusing on eight broad domains of emotional dissertation.</v>

58
00:03:38.370 --> 00:03:42.090
And today we'll start with the first four at the top that are highlighted in
red.

59
00:03:42.600 --> 00:03:45.450
And what we're going to be doing is moving through each of these tools,

60
00:03:45.690 --> 00:03:48.060
defining them,
providing an example,

61
00:03:48.750 --> 00:03:52.530
and discussing some of the relative strengths and limitations of each of these

62
00:03:52.531 --> 00:03:55.320
tools.
So let's first start with some clips.

63
00:03:58.010 --> 00:03:58.810
<v 1>Yeah.</v>

64
00:03:58.810 --> 00:04:03.810
<v 0>So we know that emotions and real life often occur in response to dynamic and</v>

65
00:04:04.871 --> 00:04:07.780
external visual and auditory stimuli.

66
00:04:08.350 --> 00:04:12.190
So film clips are really nice and that they have a high degree of ecological

67
00:04:12.191 --> 00:04:13.510
validity in this respect,

68
00:04:13.750 --> 00:04:17.770
which helps us generalize the kinds of emotions that we see when we have people

69
00:04:17.980 --> 00:04:21.640
view films to maybe more everyday life emotional experiences.

70
00:04:22.330 --> 00:04:27.330
Some clips were first used to elicit emotion from the 1960s in studying stress

71
00:04:27.371 --> 00:04:28.204
responses.

72
00:04:28.450 --> 00:04:33.280
And since then there's been a huge development and really putting forth a wide

73
00:04:33.281 --> 00:04:36.790
repertoire of film clips that can be used to elicit all kinds of distinct

74
00:04:36.791 --> 00:04:41.590
emotions that range from amusement to anger,
contentment,
disgust,
fear,

75
00:04:41.860 --> 00:04:46.150
sadness,
surprise,
and even a neutral comparison or baseline state.

76
00:04:46.450 --> 00:04:50.560
So you see here in this slide are an example of some key prototypical films that

77
00:04:50.561 --> 00:04:54.190
researchers often use to elicit feelings of happiness,
sadness,

78
00:04:54.191 --> 00:04:57.130
and a more baseline neutral state using a screen saver.

79
00:04:57.400 --> 00:04:59.080
And you have participants,
as you can see,

80
00:04:59.081 --> 00:05:02.320
the man in the bottom left corner who will come into the laboratory,

81
00:05:02.500 --> 00:05:05.830
sit at a computer desk and view these films on a monitor.

82
00:05:06.840 --> 00:05:07.080
<v 1>Yeah.</v>

83
00:05:07.080 --> 00:05:12.000
<v 0>So let me show you a brief example of a happy film clip that's widely used in</v>

84
00:05:12.001 --> 00:05:16.080
emotion research.
So this is,
uh,
a film clip to picking Sarah Hughes,

85
00:05:16.320 --> 00:05:17.940
winning the Olympic gold medal.

86
00:05:18.180 --> 00:05:21.750
And you'll see the excitement and happiness as she learns of her,
you know,

87
00:05:21.810 --> 00:05:23.340
fantastic award.

88
00:05:23.580 --> 00:05:27.720
And this has been shown to reliably licit high arousal positive states such as

89
00:05:27.721 --> 00:05:28.800
excitement.
And Joy

90
00:05:29.840 --> 00:05:34.840
<v 1>[inaudible]</v>

91
00:05:40.720 --> 00:05:44.420
Aye.

92
00:06:04.880 --> 00:06:06.390
<v 0>So let's contrast this.
Um,</v>

93
00:06:06.560 --> 00:06:09.950
so we'll now contrast this with one of the most common sad films.

94
00:06:10.220 --> 00:06:14.360
And this is a film taken from the Champ to picking a young boy crying and

95
00:06:14.361 --> 00:06:16.190
mourning over the death of his father.

96
00:06:16.490 --> 00:06:20.540
And this film has been reliably used by researchers to elicit high degrees of

97
00:06:20.541 --> 00:06:21.374
sadness.

98
00:06:21.410 --> 00:06:25.670
So take a moment to watch this film and see how you feel as you watch the scene

99
00:06:25.671 --> 00:06:26.504
unfold.

100
00:06:38.280 --> 00:06:39.113
<v 1>Your aunt.</v>

101
00:06:51.520 --> 00:06:52.353
Yeah,

102
00:06:57.870 --> 00:06:58.703
yeah,

103
00:07:02.770 --> 00:07:03.603
please.

104
00:07:12.830 --> 00:07:13.663
Okay.

105
00:07:21.280 --> 00:07:22.113
Yeah,

106
00:07:29.540 --> 00:07:30.373
<v 2>yeah.</v>

107
00:07:45.600 --> 00:07:46.433
Oh

108
00:07:53.620 --> 00:07:54.680
yeah.
Wake up.

109
00:08:01.520 --> 00:08:03.030
Oh,
what?
No,
what,

110
00:08:06.850 --> 00:08:07.683
<v 1>sorry.</v>

111
00:08:09.120 --> 00:08:09.953
<v 2>Ooh,</v>

112
00:08:13.480 --> 00:08:14.550
he got to go home.

113
00:08:19.380 --> 00:08:20.213
<v 0>There.
You see.</v>

114
00:08:20.230 --> 00:08:24.850
So there you see an example of some of the most commonly use positive and

115
00:08:24.851 --> 00:08:26.170
negative films in the field.

116
00:08:26.530 --> 00:08:30.850
So when we summarize film clips as a tool to elicit emotion,
where are we at?

117
00:08:31.300 --> 00:08:35.290
Well,
it seems that films are incredibly good at eliciting the three domains of

118
00:08:35.291 --> 00:08:38.770
emotion processes.
We started out with emotional reactivity,

119
00:08:38.771 --> 00:08:42.220
looking at people's responses to the film emotion regulation,

120
00:08:42.221 --> 00:08:47.050
looking at how they may try to either up regulate or amplify or downregulate or

121
00:08:47.051 --> 00:08:50.890
deintensify their emotion as well as emotion understanding by asking

122
00:08:50.891 --> 00:08:55.860
participants how do they think the people in those film clips felt the of film

123
00:08:55.861 --> 00:08:58.140
clips or that they have good ecological validity.

124
00:08:58.380 --> 00:09:01.860
They're dynamic and they're embedded within a social context where most of our

125
00:09:01.861 --> 00:09:03.930
richest emotional experiences occur.

126
00:09:04.410 --> 00:09:08.040
The disadvantages of films though is that they require high cognitive demands on

127
00:09:08.041 --> 00:09:08.730
the participant.

128
00:09:08.730 --> 00:09:12.780
They can be thematically complex and they can be difficult for some participants

129
00:09:12.781 --> 00:09:13.740
to follow throughout.

130
00:09:14.160 --> 00:09:17.970
And we know that films can't elicit elicit the full array of emotions.

131
00:09:17.971 --> 00:09:19.320
For example.
To date,

132
00:09:19.321 --> 00:09:23.310
we have no good film clips that can reliably elicit anger as an example.

133
00:09:24.540 --> 00:09:29.460
So now let's move on to static photos.
So by photos,

134
00:09:29.640 --> 00:09:34.050
what we're known in the field as some of the most,
you know,

135
00:09:34.051 --> 00:09:38.880
robust images that can elicit emotions come from this repository of emotional

136
00:09:38.881 --> 00:09:43.080
images known as the international aspect of picture system or I apps.

137
00:09:43.350 --> 00:09:48.350
The I apps consists of more than 700 colored images of different kinds of

138
00:09:48.781 --> 00:09:53.400
situations selected due to their ability to reliably list robust,

139
00:09:53.640 --> 00:09:56.640
positive,
negative,
and more neutral emotion states.

140
00:09:56.850 --> 00:10:00.270
And here's some examples that you can see here from the ops image system.

141
00:10:00.480 --> 00:10:02.790
So these are nice because they've been widely used,

142
00:10:02.791 --> 00:10:07.080
they're publicly available and have standardized ratings for both arousal level

143
00:10:07.110 --> 00:10:09.870
as well as how positive or negatively valence they are.

144
00:10:10.080 --> 00:10:12.630
So I'll walk you through just a few examples of them now.

145
00:10:13.020 --> 00:10:15.240
So in addition to these three you see here,

146
00:10:15.780 --> 00:10:18.180
this is a positive image from the IOP system.

147
00:10:18.900 --> 00:10:23.280
Another high arousal positive image of a very negative image.

148
00:10:24.450 --> 00:10:27.630
This is one of the erotica,
high arousal positive images.

149
00:10:28.320 --> 00:10:32.280
And ideally this would be a neutral image for most people unless you have a

150
00:10:32.281 --> 00:10:35.520
special relationship with file cabinets.
Um,

151
00:10:35.580 --> 00:10:39.210
and this is another negative image designed to illicit low arousal,

152
00:10:39.270 --> 00:10:41.280
negative emotions like sadness.

153
00:10:42.120 --> 00:10:47.070
This is seen as a positive image of a peaceful landscape and another positive

154
00:10:47.071 --> 00:10:50.160
image of,
you know,
dolphins playing in the water with a soccer ball.

155
00:10:51.030 --> 00:10:53.820
So in addition to the iops photos,

156
00:10:53.821 --> 00:10:58.140
another category of photos that are frequently used to elicit emotion include

157
00:10:58.141 --> 00:11:02.280
images of human faces,
displaying prototypical expressions of emotion.

158
00:11:02.281 --> 00:11:03.240
As you can see here,

159
00:11:03.630 --> 00:11:08.220
the theory behind this is that emotion expressions in the human face are a

160
00:11:08.221 --> 00:11:11.670
robust illicit or of emotion expressed to other people.

161
00:11:12.180 --> 00:11:16.890
So commonly used databases for emotional photos include the facial action coding

162
00:11:16.891 --> 00:11:19.590
system repertoire by Paul Ekman.
Um,

163
00:11:19.620 --> 00:11:23.370
this is an example of the kinds of images you might see in a Paul Ekman system.

164
00:11:23.780 --> 00:11:24.090
Um,

165
00:11:24.090 --> 00:11:29.040
as well as more recent developments to try to expand the kinds of images we have

166
00:11:29.041 --> 00:11:33.240
beyond these kind of six basic emotions of anger,
see,
you know,
fear,

167
00:11:33.390 --> 00:11:34.980
happiness,
sadness,

168
00:11:35.010 --> 00:11:40.010
disgust to include more subtle and socially complex emotions by Dacher Keltner

169
00:11:40.351 --> 00:11:44.400
and colleagues at Berkeley.
So they've included images that express,
you know,

170
00:11:44.401 --> 00:11:48.750
Co coy smiles,
compassion,
desire,
and even pride.

171
00:11:49.440 --> 00:11:53.890
So when we summarize static photos,
again just like films fairy,

172
00:11:54.010 --> 00:11:54.791
fantastic,

173
00:11:54.791 --> 00:11:59.791
stimulate to elicit reactivity regulation and you can use them to index emotion,

174
00:11:59.981 --> 00:12:03.790
understanding the advantages relative to films or that they actually have

175
00:12:03.791 --> 00:12:07.630
relatively low cognitive demand as well as low language demand.

176
00:12:07.631 --> 00:12:11.770
There isn't any sort of script that people have to follow and interpret.

177
00:12:12.340 --> 00:12:15.670
The disadvantages though is that there's a limited range of emotions that you

178
00:12:15.671 --> 00:12:17.470
can elicit using photos.

179
00:12:17.680 --> 00:12:21.910
The I app system that we saw is often biased towards a certain narrow category

180
00:12:21.911 --> 00:12:24.970
of emotions,
like disgust,
that really nasty photo.

181
00:12:24.971 --> 00:12:28.240
You saw the teeth with all the tumors amusement.

182
00:12:28.241 --> 00:12:32.070
So you see the dolphins playing with a soccer ball and sexual arousal,

183
00:12:32.071 --> 00:12:35.910
although some people argue that the photos like the ones you saw Alyssa horror

184
00:12:35.920 --> 00:12:37.990
amusement than arousal.
Um,

185
00:12:38.050 --> 00:12:41.290
and also when we think about the images of human facial expressions,

186
00:12:41.620 --> 00:12:46.300
they are often these kind of caricature ask exaggerated expressions of fear or

187
00:12:46.301 --> 00:12:50.620
happiness and they may not really be generalizable to the more subtle kinds of

188
00:12:50.621 --> 00:12:53.350
emotion expressions we see in our everyday life.

189
00:12:53.680 --> 00:12:55.720
So those are films and photos.

190
00:12:55.990 --> 00:13:00.850
Now let's turn to relived emotions or autobiographical memories of our own

191
00:13:00.851 --> 00:13:05.710
personalized emotional life events.
So here with relived emotions,

192
00:13:05.920 --> 00:13:10.450
what we're really trying to do is get inside someone's head and have them recall

193
00:13:10.480 --> 00:13:13.840
the kinds of emotional memories that are most salient to them.

194
00:13:14.260 --> 00:13:19.120
So an example of how to elicit relived emotions includes using a semi structured

195
00:13:19.121 --> 00:13:23.560
interview to prompt participants to try to retrieve memories of a specific event

196
00:13:23.561 --> 00:13:28.150
that elicited emotion.
And once they recall an event and they're identified,

197
00:13:28.360 --> 00:13:33.310
they're asked to try to now go back in time and relive the memories as strongly

198
00:13:33.311 --> 00:13:33.911
as possible,

199
00:13:33.911 --> 00:13:38.911
almost to put yourself in the shoes of where you were and who you were with when

200
00:13:39.521 --> 00:13:40.600
you felt that emotion.

201
00:13:40.601 --> 00:13:43.900
Maybe it was here like this young girl Christmas Day and getting the most

202
00:13:43.901 --> 00:13:45.280
awesome present possible.

203
00:13:46.240 --> 00:13:49.150
So when we think of relived emotions,

204
00:13:49.151 --> 00:13:53.050
there's two categories that we can really focus on.
One,

205
00:13:53.051 --> 00:13:56.620
our autobiographical memories.
So like what we just talked about,

206
00:13:56.621 --> 00:14:00.820
these are the personally relevant emotional memories from our own lives.

207
00:14:01.030 --> 00:14:06.030
So it can be asking you to recall maybe the happiest moment in your life or the

208
00:14:06.431 --> 00:14:07.870
saddest moment in your life.

209
00:14:08.620 --> 00:14:11.980
This is distinct from what are called shared memories.

210
00:14:12.250 --> 00:14:15.190
So these are shared memories like nine 11 of you know,

211
00:14:15.220 --> 00:14:18.460
significant historic or group events.

212
00:14:18.670 --> 00:14:21.400
And these are often talked about as flashbulb memories.

213
00:14:21.790 --> 00:14:25.510
So these are things that you share with a collective group as opposed to Autobio

214
00:14:25.780 --> 00:14:28.660
autobiographical memories that are really about your own individualized

215
00:14:28.661 --> 00:14:33.100
experience.
So the processes that we lived,

216
00:14:33.101 --> 00:14:35.500
emotions can really tap into our reactivity,

217
00:14:35.501 --> 00:14:39.550
looking at how we respond to recalling emotions and regulations.

218
00:14:39.551 --> 00:14:43.810
So how can we try to increase or decrease the emotions we feel when we're

219
00:14:43.811 --> 00:14:45.160
thinking about these memories?

220
00:14:45.910 --> 00:14:50.400
The advantages of relived emotions is unlike films,
uh,

221
00:14:50.401 --> 00:14:54.410
and photos for that matter.
These are more personally salient.

222
00:14:54.411 --> 00:14:57.770
There are about your own emotion experience.
And so as a result,

223
00:14:57.771 --> 00:15:00.200
they can be more engaging for the person you know,

224
00:15:00.201 --> 00:15:04.340
to get into as opposed to watching films or images of other people experiencing

225
00:15:04.341 --> 00:15:06.650
emotional events.
And so for that reason,

226
00:15:06.651 --> 00:15:09.200
they're thought thoughts have what's called good ecological validity,

227
00:15:09.440 --> 00:15:14.390
meaning that they map on really well to real world or real life emotional

228
00:15:14.391 --> 00:15:17.870
experiences and events.
Some of the disadvantages,
however,

229
00:15:17.871 --> 00:15:20.270
is that there are more radiographic meaning.

230
00:15:20.271 --> 00:15:23.030
They vary from person to person that you bring into the lab.

231
00:15:23.330 --> 00:15:27.620
So it's hard to standardize these across participants because each of us have

232
00:15:27.621 --> 00:15:31.460
our own unique emotional lives and our own unique emotional memories.

233
00:15:31.820 --> 00:15:32.601
And so you know,

234
00:15:32.601 --> 00:15:35.180
this is something that you always have to think about when you're using these

235
00:15:35.181 --> 00:15:38.720
kinds of stimuli is that each person you bring in is essentially going to

236
00:15:38.721 --> 00:15:42.320
generate a different memory from the person before or after them.

237
00:15:43.430 --> 00:15:46.400
Also,
you know,
Azure,
we're trying,
trying to recall an emotional memory.

238
00:15:46.401 --> 00:15:48.770
It has high cognitive or memory demand.

239
00:15:49.040 --> 00:15:53.120
So it can be difficult for people on the one hand to really internally visualize

240
00:15:53.121 --> 00:15:57.710
a memory in great detail and then also feel the emotion,
right?

241
00:15:57.890 --> 00:16:02.180
It's almost like trying to draw a really complex picture but also feel the

242
00:16:02.181 --> 00:16:04.220
emotions that the picture in genders.

243
00:16:04.370 --> 00:16:08.120
So this can be a difficulty that's often brought up with relived memories.

244
00:16:09.290 --> 00:16:12.440
So we talked about films,
photos,
relived emotions,

245
00:16:12.441 --> 00:16:15.680
and now we're going to turn to dyadic interactions here.

246
00:16:16.490 --> 00:16:20.690
What we're really looking at,
our interactions between people.

247
00:16:21.110 --> 00:16:25.640
So dyadic interactions can include differences in who the people are.

248
00:16:25.940 --> 00:16:30.410
So it can be between two people who are spouses to family members,

249
00:16:30.770 --> 00:16:33.710
a caregiver and the person they're taking care of,

250
00:16:34.010 --> 00:16:36.710
two friends or even to strangers.

251
00:16:37.220 --> 00:16:41.240
And usually these kinds of interactions settings consists of having people come

252
00:16:41.241 --> 00:16:42.980
into the lab,
sit down,

253
00:16:43.010 --> 00:16:46.760
like you see the people here on the slide and engage in brief conversations,

254
00:16:46.761 --> 00:16:51.080
maybe between five and 10 minutes proceeded by a silent baseline period

255
00:16:51.081 --> 00:16:51.914
beforehand.

256
00:16:52.280 --> 00:16:56.420
And the conversation topics can range from neutral everyday context such as

257
00:16:56.421 --> 00:16:57.410
events of the day,

258
00:16:57.530 --> 00:17:02.510
positive topics such as discussing things that people enjoy doing together or

259
00:17:02.511 --> 00:17:05.000
negative context.
So with romantic partners,

260
00:17:05.001 --> 00:17:08.450
a can discussing relationship problems or between strangers,

261
00:17:08.451 --> 00:17:11.330
it can be sharing a time of personal suffering or loss.

262
00:17:12.830 --> 00:17:16.850
So when you're doing these kinds of tasks at the end you can tap into emotion

263
00:17:16.851 --> 00:17:21.320
experience asking each partner how did they feel at the end of that conversation

264
00:17:22.070 --> 00:17:24.290
as well as emotion perception.

265
00:17:24.350 --> 00:17:28.190
So how do you think your partner's feeling right now after that conversation?

266
00:17:28.520 --> 00:17:32.270
And this enables you to get at not only the own the individual's experience,

267
00:17:32.450 --> 00:17:36.890
but their ability to accurately gauge or what was called empathic accuracy.

268
00:17:36.891 --> 00:17:41.210
How good are they at really mapping on an understanding the emotions of other

269
00:17:41.211 --> 00:17:42.044
people.

270
00:17:42.680 --> 00:17:46.400
So the summary here for dyadic interactions is that indeed it maps on to all

271
00:17:46.401 --> 00:17:51.210
three key emotion to s discussed reactivity,
regulation and understanding.

272
00:17:51.211 --> 00:17:55.110
It is perhaps even the best at emotion understanding cause you're really getting

273
00:17:55.111 --> 00:17:59.490
in the moment in Vivo interactions and asking them with a real human being,

274
00:17:59.730 --> 00:18:03.420
how well are they at picking up on their emotions and comparing it to what that

275
00:18:03.421 --> 00:18:05.250
other person actually reports healing.

276
00:18:05.730 --> 00:18:09.780
The advantages are that it has good ecological validity and that it occurs in

277
00:18:09.781 --> 00:18:11.850
more naturalistic social context.

278
00:18:11.851 --> 00:18:16.230
So this is something that we can say might likely map on to how the person

279
00:18:16.231 --> 00:18:19.920
emotionally operates around other people in their own life.

280
00:18:20.700 --> 00:18:25.070
The disadvantages,
much like relived emotional memories is that again,
it's,

281
00:18:25.080 --> 00:18:28.560
it's pretty idiographic.
It will vary from diet to diet,

282
00:18:28.800 --> 00:18:32.010
what they talk about and the kinds of emotions that they experience.

283
00:18:32.310 --> 00:18:34.380
It's not easy to standardize across dyads.

284
00:18:34.381 --> 00:18:38.670
It's not easy to get the exact two people in every experiment and ensure that

285
00:18:38.671 --> 00:18:42.510
exactly what they talk about is,
you know,
mapped content wise.

286
00:18:43.110 --> 00:18:46.650
And also we know that people's emotional responses get influenced by both

287
00:18:46.651 --> 00:18:47.640
members of a dyad.

288
00:18:47.970 --> 00:18:52.080
So the way that one person responds or reacts will shift and change the emotions

289
00:18:52.081 --> 00:18:55.440
of the other person in the dyadic membership.

290
00:18:55.920 --> 00:18:59.760
So it's a little bit messy and that you don't have all the rigorous experimental

291
00:18:59.761 --> 00:19:04.650
control that you have with films or pictures or even memories to that extent.

292
00:19:04.980 --> 00:19:09.510
But in many ways it most easily translates into the kinds of emotions we really

293
00:19:09.511 --> 00:19:13.710
feel when we're having conversations with people in our everyday lives,

294
00:19:13.890 --> 00:19:16.710
be it our friends,
our partners,
or our colleagues.

295
00:19:17.460 --> 00:19:21.630
So we've talked about films,
static photos,

296
00:19:21.780 --> 00:19:24.060
relived emotions and dyadic interactions.

297
00:19:24.330 --> 00:19:28.160
And in our next lecture we'll touch on the bottom four here looking at the

298
00:19:28.170 --> 00:19:31.590
another sort of realm of emotion elicitation tools.

299
00:19:32.280 --> 00:19:36.720
So what I want to now do is turn to our takeaway questions mapping the kind of

300
00:19:36.721 --> 00:19:40.590
key conceptual things that you should have gained out of this lecture today.

301
00:19:42.180 --> 00:19:47.180
The first asked what were the four emotional elicitation tools covered today?

302
00:19:48.360 --> 00:19:48.990
Second,

303
00:19:48.990 --> 00:19:53.430
which of the three emotional processes did each of these four tools target?

304
00:19:54.540 --> 00:19:55.373
And finally,

305
00:19:55.710 --> 00:19:59.610
what are the strengths and limitations of each of the tools discussed today?

306
00:20:00.960 --> 00:20:05.580
And now we'll turn to our expert interview with a fantastic knowledgeable

307
00:20:05.581 --> 00:20:10.500
scholar in the field of emotional elicitation and measurement and this is part

308
00:20:10.501 --> 00:20:14.070
of our experts in emotion interview series through Yale University.

309
00:20:15.570 --> 00:20:20.190
Will be speaking today with Dr John Jb Allen on emotion elicitation.

310
00:20:20.640 --> 00:20:25.380
Dr. Allen received his phd from the University of Minnesota and is currently a

311
00:20:25.381 --> 00:20:27.390
distinguished professor of psychology,

312
00:20:27.420 --> 00:20:30.930
cognitive science and neuroscience at the University of Arizona.

313
00:20:31.800 --> 00:20:36.000
Dr. Allen is an expert in emotional elicitation and has co edited the handbook

314
00:20:36.001 --> 00:20:37.290
of emotional elicitation.

315
00:20:37.980 --> 00:20:41.880
His well known research program involves using psychophysiological tools to

316
00:20:41.881 --> 00:20:46.170
understand the etiology and treatment of both mood and anxiety disorders.

317
00:20:47.710 --> 00:20:51.100
He has published over 120 scientific papers,

318
00:20:51.580 --> 00:20:55.810
received numerous grants and awards for his research that include the early

319
00:20:55.811 --> 00:20:59.320
career award for the Society for psychophysiological research,

320
00:20:59.710 --> 00:21:01.540
as well as his passion for teaching,

321
00:21:01.870 --> 00:21:04.630
including the graduate college and Professional Education,

322
00:21:04.631 --> 00:21:08.740
teaching and mentoring award and designation as a university distinguished

323
00:21:08.741 --> 00:21:11.890
professor.
In addition to his expertise in emotion,

324
00:21:12.160 --> 00:21:15.250
he's also an avid mountain biker and Eunice cyclist.

325
00:21:15.520 --> 00:21:20.520
So I now turn to a very special experts in emotion interview with Doctor John J

326
00:21:20.680 --> 00:21:22.330
B Allen on emotion elicitation.

