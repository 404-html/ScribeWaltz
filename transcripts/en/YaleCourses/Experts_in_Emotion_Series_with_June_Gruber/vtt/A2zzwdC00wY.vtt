WEBVTT

1
00:00:01.670 --> 00:00:05.960
Today we'll be speaking with doctor Gerald core on emotion and cognition.

2
00:00:06.260 --> 00:00:10.550
Dr Core is a Commonwealth professor of psychology at the University of Virginia

3
00:00:10.820 --> 00:00:14.420
and formerly an alumni distinguished professor at the University of Illinois.

4
00:00:14.870 --> 00:00:18.590
His research focuses on emotion and it's cognitive consequences.

5
00:00:18.860 --> 00:00:21.500
He's coauthored the cognitive structure of emotions,

6
00:00:21.501 --> 00:00:26.150
a general theory of how psychological situations elicit emotions and make them

7
00:00:26.151 --> 00:00:30.710
intense.
It's chief application is in computer science as the emotion engine of

8
00:00:30.711 --> 00:00:34.670
intelligent agents and robots,
computer games and interactive training modules.

9
00:00:35.030 --> 00:00:38.540
His research has been funded by both the NIH and NSF and concerns.

10
00:00:38.541 --> 00:00:40.700
The effect is information hypothesis,

11
00:00:41.000 --> 00:00:46.000
which clarifies how emotional information about value and urgency help to shape

12
00:00:46.011 --> 00:00:49.310
or regulate cognition,
motivation,
and even memory.

13
00:00:49.700 --> 00:00:54.110
Dr Clore has served as an associate editor of cognition and emotion as faculty

14
00:00:54.111 --> 00:00:58.550
in the Nih consortium on emotion and as a visiting professor at Harvard

15
00:00:58.550 --> 00:01:01.310
University.
He's also been a visiting scholar at Harvard,

16
00:01:01.340 --> 00:01:05.030
Oxford in New York University and a fellow of the Centers for advanced study,

17
00:01:05.031 --> 00:01:08.270
Illinois,
Stanford and the Rockefeller Center in Italy.

18
00:01:08.690 --> 00:01:12.350
In 2010 he was elected to the American Academy of Arts and Sciences.

19
00:01:12.620 --> 00:01:16.820
And in 2013 he received the William James Award for scientific achievement from

20
00:01:16.821 --> 00:01:20.260
the association for Psychological Science.
Today,

21
00:01:20.261 --> 00:01:24.340
I'm very delighted to have Dr Gerald core from the University of Virginia

22
00:01:24.520 --> 00:01:28.330
speaking with us today on emotion and cognition.
So welcome,
Jerry.

23
00:01:28.331 --> 00:01:29.710
Thanks for speaking with us today.

24
00:01:30.770 --> 00:01:31.603
<v 1>Thank you.</v>

25
00:01:31.930 --> 00:01:33.640
<v 0>So I wanted to start out,
Jerry,</v>

26
00:01:33.641 --> 00:01:37.360
by asking you a bit about what first got you interested in emotion?

27
00:01:39.160 --> 00:01:43.780
<v 1>Well,
I was a graduate student at the University of Texas and we were working on</v>

28
00:01:43.781 --> 00:01:46.420
interpersonal attraction,
uh,

29
00:01:46.510 --> 00:01:51.510
and at the time the theories of why you like April emphasized people's beliefs

30
00:01:52.481 --> 00:01:55.770
about other people you like,
people that you know,
positive things about.

31
00:01:56.600 --> 00:01:57.433
<v 2>Uh,</v>

32
00:01:57.490 --> 00:02:01.930
<v 1>but it seemed to me that surely liking was more a matter of feeling than</v>

33
00:02:01.931 --> 00:02:02.764
believing.

34
00:02:03.300 --> 00:02:04.133
<v 2>Uh,</v>

35
00:02:04.480 --> 00:02:05.051
<v 1>so,</v>

36
00:02:05.051 --> 00:02:09.820
but the trouble is beliefs and feelings are hard to separate in the lab.

37
00:02:10.960 --> 00:02:15.880
And actually a roommate of mine who was in graduate school at the time solve

38
00:02:15.881 --> 00:02:20.881
this problem by simply showing happy or sad films to people and having them make

39
00:02:21.941 --> 00:02:26.230
judgements about,
uh,
individuals that they had information about.

40
00:02:27.120 --> 00:02:30.900
And what he found was that regardless of your beliefs about the other person,

41
00:02:30.910 --> 00:02:35.560
if you felt better,
you like them better.
And that made a lot of sense to me.

42
00:02:36.440 --> 00:02:40.660
Uh,
as a matter of fact,
uh,
Charlie's,
my,
my friend,

43
00:02:40.661 --> 00:02:45.661
Charlie's method that he made up has now become a kind of standard social

44
00:02:45.671 --> 00:02:50.671
psychological thing to do to induce irrelevant FX check to see how it works in

45
00:02:51.431 --> 00:02:53.280
judgements and decision making and so forth.

46
00:02:55.390 --> 00:02:57.580
Another kind of influenced,

47
00:02:57.960 --> 00:03:02.320
I came soon that when I had become a professor at Illinois,

48
00:03:02.350 --> 00:03:07.350
I did a study of conversations and we were trying to see what people said in

49
00:03:07.631 --> 00:03:10.210
conversations that made other people like them.

50
00:03:11.620 --> 00:03:15.760
But it turned out that much more important than what they sin.

51
00:03:16.090 --> 00:03:21.090
It was what the razors got to say about themselves in the conversations.

52
00:03:21.760 --> 00:03:25.660
So people when they felt rewarded and got to talk about themselves,

53
00:03:26.030 --> 00:03:29.030
like the other person,
um,
uh,

54
00:03:29.180 --> 00:03:34.180
which in the in a way is no surprise what we thought it was very important to

55
00:03:34.571 --> 00:03:35.260
start with,

56
00:03:35.260 --> 00:03:40.210
look at people's own responses as a determine of their view of the world.

57
00:03:42.280 --> 00:03:47.280
And I guess the other main part of this is a colleague of mine at the University

58
00:03:47.741 --> 00:03:50.950
of Illinois,
Andrew or Tony.
Uh,

59
00:03:51.070 --> 00:03:55.530
and I started thinking about emotion and eventually wrote a book about an

60
00:03:55.540 --> 00:03:57.310
emotion.
Um,

61
00:03:57.640 --> 00:04:02.640
and the idea was to really make computers more emotionally intelligent.

62
00:04:03.420 --> 00:04:05.860
Now the idea wasn't to make them feel anything,

63
00:04:06.190 --> 00:04:11.140
but to give them a kind of emotion knowledge so that they could interact with

64
00:04:11.141 --> 00:04:15.760
people and understand their emotions.
Um,

65
00:04:16.420 --> 00:04:18.910
so we wrote this book and it covers a,

66
00:04:18.970 --> 00:04:23.970
it has a theory that covers 22 emotions and what makes them occur and what makes

67
00:04:25.811 --> 00:04:27.280
them intense or mile.

68
00:04:28.030 --> 00:04:31.330
And it turned out to be the biggest hit in computer science.

69
00:04:31.840 --> 00:04:36.760
So today if you look online under,
oh,
Si,
si or Tony Clore and Collins,

70
00:04:36.761 --> 00:04:40.180
which is the authorship,
uh,
and anything else,

71
00:04:40.300 --> 00:04:45.300
you can find lots of applications in computer science to games and tutors and

72
00:04:46.511 --> 00:04:50.890
therapy and all kinds of stuff.
So

73
00:04:52.570 --> 00:04:53.530
I guess that's that.

74
00:04:53.930 --> 00:04:55.280
<v 0>Excellent.
So I mean,</v>

75
00:04:55.281 --> 00:04:58.700
it's really interesting to hear about where your path and emotion first started.

76
00:04:59.090 --> 00:04:59.481
And I mean,

77
00:04:59.481 --> 00:05:02.930
since then you've been one of the most pioneering figures and thinking about

78
00:05:03.230 --> 00:05:06.710
emotion generally and how it relates the way we think about the world.

79
00:05:07.010 --> 00:05:09.710
And so what I wanted to ask you a bit about,
you know,

80
00:05:09.711 --> 00:05:13.160
is your groundbreaking research that's really pioneered the way that we

81
00:05:13.161 --> 00:05:16.220
understand this,
you know,
intricate,
um,

82
00:05:16.280 --> 00:05:20.870
an important link between an affect and cognitive processes in terms of

83
00:05:21.110 --> 00:05:25.400
specifically such as how effect influences things like judgment and your affect

84
00:05:25.401 --> 00:05:26.540
is information theory.

85
00:05:26.780 --> 00:05:29.930
So I wonder if you could say a bit about what are some of the fundamental

86
00:05:29.931 --> 00:05:32.510
principles that are outlined in this approach of yours?

87
00:05:33.860 --> 00:05:35.030
<v 1>Well,
um,</v>

88
00:05:35.330 --> 00:05:40.330
I guess the key discovery that we made is that the impact of one's ethic really

89
00:05:41.841 --> 00:05:46.841
depends on what its object is and the kind of classic them duration of that it

90
00:05:48.871 --> 00:05:53.480
was.
And the experiments that Norbert Schwarz,
who was a postdoc at the time,
uh,

91
00:05:53.540 --> 00:05:56.450
and I did in the early eighties,

92
00:05:56.630 --> 00:06:01.630
and we called people on the phone on sunny or rainy spring day is in the Midwest

93
00:06:05.190 --> 00:06:07.730
at the University of Illinois.
Uh,

94
00:06:07.760 --> 00:06:12.350
and people were a little happier on sunny days and not so happy on cold and

95
00:06:12.351 --> 00:06:15.230
rainy days.
And we've been asked them,

96
00:06:15.231 --> 00:06:19.590
we gave them a little too item life satisfaction interview.
Uh,

97
00:06:19.640 --> 00:06:22.910
and we discovered that on when people were happy,

98
00:06:23.140 --> 00:06:27.560
they thought life in in general was pretty good.
And when they were less happy,

99
00:06:27.561 --> 00:06:31.370
they thought life in general was not saying it well.

100
00:06:31.371 --> 00:06:34.250
There's lots of ways to explain that of course.
But what we,

101
00:06:34.640 --> 00:06:38.930
an additional group was refers to ask some of them about the weather,

102
00:06:39.680 --> 00:06:44.120
uh,
making salient this real cause of how they felt.

103
00:06:44.780 --> 00:06:49.220
And for those people there was no relationship between their mood and,
uh,

104
00:06:49.280 --> 00:06:53.810
the life satisfaction.
Because all the feelings were about something else.

105
00:06:54.740 --> 00:06:59.740
So it really taught us this lesson about the impact of ethic being,

106
00:07:00.681 --> 00:07:05.360
depending on what it seems to be about and shows that rather than being a

107
00:07:05.361 --> 00:07:07.190
thoroughly automatic process.

108
00:07:07.430 --> 00:07:11.450
It depends on how you parse your own experience.
Um,

109
00:07:13.260 --> 00:07:14.093
of course,
uh,

110
00:07:14.690 --> 00:07:19.320
in our experiments we often get people to misattribute their feelings.

111
00:07:19.321 --> 00:07:22.710
So we show them a movie that you're relevant and then ask them the judgments

112
00:07:22.730 --> 00:07:25.310
about their life.
And you might think,
well,

113
00:07:26.000 --> 00:07:30.410
what a silly way to design a person,
uh,
in the real world.

114
00:07:30.920 --> 00:07:35.360
I think people's feelings by and large are right on target.
People know,

115
00:07:35.750 --> 00:07:36.470
well,

116
00:07:36.470 --> 00:07:41.470
we think of it as information and people find it to be accurate information on

117
00:07:42.051 --> 00:07:42.884
the whole.

118
00:07:43.580 --> 00:07:47.480
So the experiments are not a good model in that sense for the way it isn't the

119
00:07:47.481 --> 00:07:50.860
real world,
but they allow us to look inside and a way.

120
00:07:53.810 --> 00:07:56.780
<v 0>So in some ways,
I mean,
what do you,</v>

121
00:07:56.810 --> 00:08:00.140
what do you see as the most important and central discoveries?
I mean,

122
00:08:00.141 --> 00:08:02.860
you've talked about some already.
Um,
you know,

123
00:08:02.930 --> 00:08:05.900
outlined in this aspect is as information theory.

124
00:08:07.030 --> 00:08:08.480
<v 1>Well,
uh,</v>

125
00:08:09.130 --> 00:08:13.420
some years ago we actually laid out a series of principles that we thought some

126
00:08:13.421 --> 00:08:17.230
of these experiments illustrated.
And,
uh,
and I again,

127
00:08:17.231 --> 00:08:22.231
I think the overarching one is this idea that it all depends on once the object

128
00:08:23.320 --> 00:08:28.320
is and a lot of emotion and ethic research is all focused on the ethic and

129
00:08:28.751 --> 00:08:33.520
emotion itself.
But again,
it's what it's about.

130
00:08:33.670 --> 00:08:37.600
Emotions we think are more situated and then people realize,

131
00:08:37.930 --> 00:08:41.530
so they're really more about that current situation.
Um,

132
00:08:41.710 --> 00:08:46.660
and of course the emotion places,
constraints on how people think and so forth.

133
00:08:47.470 --> 00:08:50.860
Uh,
but again,
a lot of the power lies in the object.

134
00:08:51.910 --> 00:08:54.610
And the reason these experiments can work.
Yes.

135
00:08:54.611 --> 00:08:57.870
Because is always about what is currently in mind.

136
00:08:58.590 --> 00:09:00.330
It's always about the moment.

137
00:09:01.260 --> 00:09:06.240
And so if you ask somebody about their life satisfaction while you've made them

138
00:09:06.450 --> 00:09:11.400
feel good,
they're suddenly attend how they feel and it's,

139
00:09:11.570 --> 00:09:15.420
it appears to be about life satisfaction.
Uh,

140
00:09:15.630 --> 00:09:17.160
so in that sense,

141
00:09:17.280 --> 00:09:22.280
moods and depression and affective of states that lasts through time can be a

142
00:09:22.591 --> 00:09:26.310
problem.
Um,
well there are a number of,

143
00:09:26.311 --> 00:09:28.800
there's about a dozen principals,
but I won't go through them here.

144
00:09:29.790 --> 00:09:29.971
<v 0>Well,</v>

145
00:09:29.971 --> 00:09:33.420
one question I have for you is to what extent do you think this theory applies

146
00:09:33.421 --> 00:09:35.220
equivalently across,
you know,

147
00:09:35.221 --> 00:09:39.360
positive valence states on the one hand and negatively balanced states on the

148
00:09:39.361 --> 00:09:40.194
other?

149
00:09:41.040 --> 00:09:45.660
<v 1>Well,
um,
it certainly does.
That is the bows are informed and uh,</v>

150
00:09:46.200 --> 00:09:50.460
uh,
positive ethics says that something is good and negative effect says that

151
00:09:50.461 --> 00:09:52.690
something is bad.
Uh,

152
00:09:53.040 --> 00:09:58.040
and one of the discoveries is that an important object is one's own thoughts,

153
00:10:01.750 --> 00:10:06.240
uh,
which we'll talk about in a minute I think.
But yes,

154
00:10:06.360 --> 00:10:10.830
negative aspect is as important as positive aspect,

155
00:10:11.390 --> 00:10:16.190
uh,
because negative effect essentially says,
are you sure you want to do that?
Uh,

156
00:10:16.320 --> 00:10:18.270
and often that's important.

157
00:10:19.630 --> 00:10:22.810
<v 0>So you mentioned we're going to talk about something in a second and well,</v>

158
00:10:22.811 --> 00:10:26.680
a second has passed.
So the question I have then is just,
I mean,

159
00:10:26.681 --> 00:10:29.920
it's about the work you've done where you've really provided these novel

160
00:10:29.921 --> 00:10:32.950
insights into the role of emotion in,
you know,

161
00:10:32.951 --> 00:10:36.790
cognitive processing thinking and also problem solving.

162
00:10:37.090 --> 00:10:40.030
And I wondered if you could tell us a bit more about some of the discoveries

163
00:10:40.031 --> 00:10:42.820
that you found here that you think are especially important to know?

164
00:10:44.220 --> 00:10:47.670
<v 1>Well,
yes.
Um,
people,
it turns out,</v>

165
00:10:47.700 --> 00:10:50.820
do you think differently in different states?

166
00:10:50.850 --> 00:10:55.230
We've looked primarily just at happy and sad states,
uh,

167
00:10:55.260 --> 00:10:59.220
positive and negative feelings.
Uh,
so for example,

168
00:11:00.540 --> 00:11:04.910
um,
we've gone through sort of the cognitive tech Expo

169
00:11:06.930 --> 00:11:11.160
and looked at a Verot eddy of street cognitive phenomena and said,

170
00:11:11.670 --> 00:11:15.570
what happens if you try a false memory experiment?
For example,

171
00:11:15.571 --> 00:11:17.400
when people are happy,
when they're sad,

172
00:11:18.060 --> 00:11:21.510
it turns out for a whole list of standard phenomena.

173
00:11:22.110 --> 00:11:24.270
People only do the when they're happy.

174
00:11:24.720 --> 00:11:27.300
As you go through the standard cognitive textbooks,

175
00:11:27.301 --> 00:11:31.380
a lot of the standard phenomenon like semantic priming,
which is a very common,

176
00:11:31.381 --> 00:11:36.180
easily produced phenomenon.
People feel even a little sad.
They don't show it.

177
00:11:37.710 --> 00:11:40.350
People use stereotypes when they're happy.

178
00:11:40.351 --> 00:11:42.870
People look at the big picture when they're happy.

179
00:11:42.871 --> 00:11:47.170
There are a number of kinds of distinctive cognitive,
uh,

180
00:11:47.220 --> 00:11:52.140
characteristics that seem to be tied to the positive and negative habit.
Well,

181
00:11:52.410 --> 00:11:55.780
you can imagine a of theories grew up to explain this.

182
00:11:55.890 --> 00:11:58.210
It was about a dozen current theories,

183
00:11:58.660 --> 00:12:03.160
but recently we realized that all of them make one assumption that might be

184
00:12:03.161 --> 00:12:07.570
wrong,
including the explanations that we've offered.
Um,

185
00:12:08.140 --> 00:12:12.790
they all assume that these specific effective states really are dedicated to a

186
00:12:12.791 --> 00:12:15.400
particular kind of thinking.

187
00:12:16.540 --> 00:12:21.470
And it finally occurred to us that that may not be true.
So,
uh,
and,

188
00:12:21.520 --> 00:12:26.440
and the bottom line here is going to be that rather than a happy mood making you

189
00:12:26.441 --> 00:12:28.450
look at the big picture,
for example,

190
00:12:28.930 --> 00:12:32.290
it makes you do whatever you're ready to do.

191
00:12:33.310 --> 00:12:36.060
So we,
uh,

192
00:12:36.610 --> 00:12:40.240
did a series of experiments in which we,
uh,

193
00:12:40.330 --> 00:12:45.010
changed what people were prepared to do.
So for example,

194
00:12:45.190 --> 00:12:45.971
most of us,

195
00:12:45.971 --> 00:12:50.971
most of the time look at a somewhat expanded view of things.

196
00:12:51.510 --> 00:12:55.300
That's just the default.
So in an experiment,

197
00:12:55.301 --> 00:12:59.350
we made the default the opposite to look at details,

198
00:12:59.351 --> 00:13:02.440
to be very local in focus.
And then we,
again,

199
00:13:02.520 --> 00:13:05.320
an induced to happy and sad mood.
And the question was,

200
00:13:05.740 --> 00:13:10.090
so we'll happy mood make you global or local.

201
00:13:11.090 --> 00:13:16.090
What we found was that happy mood made you do whatever you were ready to do.

202
00:13:16.390 --> 00:13:17.560
So in these cases,

203
00:13:17.561 --> 00:13:20.920
people were ready to look at the details and the happy people started looking at

204
00:13:20.921 --> 00:13:25.210
the details and the sad people looked at the big picture because the sad mood

205
00:13:25.211 --> 00:13:29.560
said,
don't do that.
You are about to do.
Don't do that.

206
00:13:30.780 --> 00:13:31.613
Uh,
well,

207
00:13:32.740 --> 00:13:37.740
we've now done lots of experiments and just about any mood related phenomena,

208
00:13:38.110 --> 00:13:40.260
it can be turned on its head,
uh,

209
00:13:41.320 --> 00:13:45.580
by changing what the default is by what people are,
what's accessible.

210
00:13:46.300 --> 00:13:48.070
Uh,
and so it's sort of fun to,

211
00:13:48.520 --> 00:13:53.520
to overturn partly our own work as well as her friends and work and see it's a

212
00:13:53.921 --> 00:13:54.760
little bit simpler.

213
00:13:54.761 --> 00:13:59.350
So positive effect in thinking is a little like reward.

214
00:13:59.800 --> 00:14:04.660
It's not dedicated to anything in particular.
Perhaps it just says yes,

215
00:14:05.020 --> 00:14:09.580
uh,
to whatever's online or no.
In the case of negative ethic,

216
00:14:10.270 --> 00:14:14.620
now
we automatically evaluate everything.

217
00:14:15.280 --> 00:14:16.113
<v 4>Uh,</v>

218
00:14:16.480 --> 00:14:20.680
<v 1>and positive effect is good in the sense that it says,
yes,</v>

219
00:14:20.681 --> 00:14:25.090
do what you're good at,
what you're ready to do.
But of course,

220
00:14:25.480 --> 00:14:27.190
sometimes you don't want to do that.

221
00:14:27.191 --> 00:14:32.110
And negative ethic is important because it says,
no,
not here,
not now.
Um,

222
00:14:32.830 --> 00:14:37.360
I sometimes mentioned that,
uh,
John Dewey and his theory of education,

223
00:14:37.750 --> 00:14:41.950
I kind of a father of American education theory had a kind of the same idea.

224
00:14:41.951 --> 00:14:42.221
He said,

225
00:14:42.221 --> 00:14:47.221
you don't really learn anything unless you reach a problem until your negative

226
00:14:47.621 --> 00:14:51.800
FX is no do something new,
don't the same old thing.

227
00:14:54.550 --> 00:14:58.210
<v 0>So do you think that there are certain kinds of cognitive processes that may be</v>

228
00:14:58.360 --> 00:15:02.290
most intimately related to effect some more than others?

229
00:15:03.140 --> 00:15:03.640
<v 3>Okay.</v>

230
00:15:03.640 --> 00:15:06.430
<v 1>Well that's an interesting question.
Um,</v>

231
00:15:06.490 --> 00:15:09.190
it looks to me like just about anything,

232
00:15:09.550 --> 00:15:14.290
that that ethic is much more central than I think we've ever thought.

233
00:15:14.770 --> 00:15:18.800
So it governs how we act,
how we perceive,
uh,

234
00:15:19.570 --> 00:15:21.010
and what we remember.

235
00:15:21.490 --> 00:15:26.150
We remember things that are emotionally arousing,
uh,

236
00:15:26.540 --> 00:15:30.580
Eh,
eh,
are a couple of days after emotional arousal.

237
00:15:30.581 --> 00:15:34.630
Even if the arousal occurs after what you learn,
you remember it really well,

238
00:15:34.660 --> 00:15:39.660
which is of course sadly what happens in something like PTSD or other trauma

239
00:15:39.671 --> 00:15:42.920
related problems.
So if guns,

240
00:15:42.960 --> 00:15:47.530
his memory and influences judgment,
it influences decision making.

241
00:15:48.430 --> 00:15:53.240
I'm attracted to the idea proposed by a Roy Baumeister that,
uh,

242
00:15:53.980 --> 00:15:54.813
<v 3>mm,</v>

243
00:15:55.200 --> 00:15:59.610
<v 1>the,
the bottom line and decision making really is anticipated ethic.</v>

244
00:16:00.450 --> 00:16:05.400
We do metal simulations and make a decision if we,
if we anticipate,
oh,

245
00:16:05.401 --> 00:16:08.080
that's going to work out well of course.
Uh,

246
00:16:08.160 --> 00:16:11.340
but in some sense there's a lot of work on emotion and decision making.

247
00:16:12.240 --> 00:16:14.600
Not all of it wonderful.
Uh,

248
00:16:15.000 --> 00:16:17.990
but it seems to me that's sort of the overall truth.
Mm hmm.

249
00:16:18.810 --> 00:16:23.250
So I'm not sure I can find any cognitive process to that,
that it doesn't implies

250
00:16:23.770 --> 00:16:24.603
<v 3>hm.</v>

251
00:16:24.710 --> 00:16:28.880
<v 0>Like you're saying,
it just permeates all of our sort of thinking life,
you know,</v>

252
00:16:28.881 --> 00:16:29.750
so to speak.

253
00:16:30.950 --> 00:16:35.520
<v 1>Well,
we evaluate things and evaluations are crucial to actions.
Right.</v>

254
00:16:37.430 --> 00:16:41.140
<v 0>So thinking about,
you know,
some of the other work that you've been doing,
um,</v>

255
00:16:41.210 --> 00:16:41.571
I mean,

256
00:16:41.571 --> 00:16:46.070
you've also conducted this really fascinating work looking at the role of an

257
00:16:46.080 --> 00:16:50.300
effect in what some people think of as more cognitively complex processes such

258
00:16:50.301 --> 00:16:51.560
as moral judgments.

259
00:16:52.070 --> 00:16:54.470
And I wonder if you could say a little bit about your work here,

260
00:16:54.471 --> 00:16:57.920
where you've looked at the role of a particular kind of emotion,
disgust,

261
00:16:57.921 --> 00:16:58.460
you know,

262
00:16:58.460 --> 00:17:02.480
and how that might actually influence the kinds of moral judgments we make about

263
00:17:02.481 --> 00:17:04.520
what's good and what's bad.

264
00:17:05.610 --> 00:17:09.020
<v 1>Yes.
We,
uh,
a former postdocs and Otis Chenault,
uh,</v>

265
00:17:09.030 --> 00:17:14.030
and I decided to see if discuss a specific emotion would inform decisions and

266
00:17:14.791 --> 00:17:18.900
judgments just like happy and sad mood does.
Uh,

267
00:17:18.901 --> 00:17:22.920
so we did a variety of experiments in which we made people disgusting man in

268
00:17:22.921 --> 00:17:27.750
various ways.
One of them was to have people sit at a,
in a very messy room,

269
00:17:28.400 --> 00:17:30.840
uh,
and a desk with dirty,
clean axes.

270
00:17:30.841 --> 00:17:34.310
And we gave them a chewed up pencils to work with and it was thoroughly

271
00:17:34.320 --> 00:17:35.930
disgusting.
Uh,

272
00:17:36.030 --> 00:17:41.010
or in one case we used a commercially available fart spray to discuss them.

273
00:17:41.430 --> 00:17:45.640
Or we simply had the,
asked them to think about lots of disgusting thing,

274
00:17:45.660 --> 00:17:49.350
which is pretty effective.
And then we gave them,
well,

275
00:17:49.351 --> 00:17:53.580
we did one of these things at a time and then gave them moral standard moral

276
00:17:53.581 --> 00:17:55.680
judgments scenarios to ask them.

277
00:17:55.681 --> 00:18:00.030
So is this behavior Mrl or is this okay?
Uh,

278
00:18:00.870 --> 00:18:03.900
things like the trolley problem,
some people may have heard them.

279
00:18:04.740 --> 00:18:08.190
And what we found is that when people felt disgusted,

280
00:18:08.640 --> 00:18:12.600
they tended to see morally ambiguous things as immoral.

281
00:18:13.350 --> 00:18:16.920
Uh,
it moved their set point about what was immoral,

282
00:18:17.520 --> 00:18:22.410
especially for people who said they paid attention to their own bodily

283
00:18:22.411 --> 00:18:25.590
reactions.
Not so much for people who don't,

284
00:18:26.310 --> 00:18:29.870
but that sort of fit into the larger story that we use our own affective

285
00:18:29.880 --> 00:18:32.280
reactions as information.

286
00:18:33.900 --> 00:18:38.610
And this then led to another,
a former student,

287
00:18:38.611 --> 00:18:43.210
uh,
uh,
uh,
and I had to,
uh,

288
00:18:43.500 --> 00:18:46.470
Gary Sherman to,
to do a series of studies.

289
00:18:46.471 --> 00:18:51.160
We've been working on color perception of black and white.
Uh,

290
00:18:51.350 --> 00:18:54.140
and it occurred and we were looking at that and evaluation.

291
00:18:54.270 --> 00:18:56.260
And it occurred to Gary that,
um,

292
00:18:57.460 --> 00:19:00.810
you may not be about good and bad generally,
but about morality.

293
00:19:01.410 --> 00:19:05.760
So we developed something called moral stroop test in which we simply ask people

294
00:19:05.761 --> 00:19:09.780
to name the color of the font black or white against a gray background,

295
00:19:10.590 --> 00:19:15.390
uh,
when the words were either moral or immoral in meaning angel,

296
00:19:15.391 --> 00:19:18.270
devil,
Sin a charity.
And so forth.

297
00:19:19.800 --> 00:19:24.540
And we found that for people who were disgusted,
it was,

298
00:19:24.900 --> 00:19:29.900
they were slow in saying white when the word was devil or black when the word

299
00:19:31.411 --> 00:19:35.790
was charity or something.
So a real stroop effect.

300
00:19:36.150 --> 00:19:41.100
But it was heightened by disgust and a general tendency to be discussed,

301
00:19:41.101 --> 00:19:42.270
sensitive as well.

302
00:19:43.380 --> 00:19:46.980
Actually the most recent one that just came out and psych science recently,
um,

303
00:19:48.420 --> 00:19:50.940
we,
well we looked,

304
00:19:50.941 --> 00:19:55.230
we had people see if they could see numbers,

305
00:19:56.040 --> 00:19:58.950
uh,
printed against a background,

306
00:19:58.951 --> 00:20:03.690
the same colors that we might have a quite number two against a white background

307
00:20:03.900 --> 00:20:07.830
or every shade of gray and difference between the number and the background.

308
00:20:08.880 --> 00:20:13.740
And we found this amazing thing,
which is that when people are quite disgusted,

309
00:20:13.800 --> 00:20:18.150
these are people who were high and disgust sensitivity that we made disgust for

310
00:20:18.151 --> 00:20:18.984
that group.

311
00:20:19.710 --> 00:20:23.280
They were actually more perceptive.

312
00:20:23.310 --> 00:20:26.940
They were more accurate in seeing what the rest of us couldn't see.

313
00:20:27.060 --> 00:20:28.400
They could accurately seek,

314
00:20:28.410 --> 00:20:33.390
read the number against the background that looked identical.
Uh,

315
00:20:33.420 --> 00:20:37.440
and this was interestingly true only at the white end of the continuum at the

316
00:20:37.441 --> 00:20:41.400
dark end,
no different.
So when disgusted,

317
00:20:42.090 --> 00:20:45.960
well discussed,
then kind of not only makes us want to avoid impurities,

318
00:20:46.290 --> 00:20:48.760
but it actually better able to detect them.

319
00:20:51.920 --> 00:20:55.830
Yeah.
So you can sit down,
not inconsistent with other data about,
for example,

320
00:20:55.840 --> 00:20:56.673
fear,

321
00:20:56.850 --> 00:21:01.850
I mean enhancing visual acuity and other ways in which emotion seems to affect

322
00:21:02.641 --> 00:21:04.410
perception as well as thought.

323
00:21:05.470 --> 00:21:08.930
<v 0>Yeah,
I mean,
it's just a really interesting,
this special role that disgusts,</v>

324
00:21:08.931 --> 00:21:12.720
seems to play in rural judgments from all the really interesting insights.

325
00:21:12.721 --> 00:21:15.640
And you just talked about in your work,
it makes me wonder,
you know,

326
00:21:15.641 --> 00:21:19.660
to what extent do we think about aspect more generally and influencing moral

327
00:21:19.661 --> 00:21:20.950
judgments?
Can't,

328
00:21:20.951 --> 00:21:24.700
can we think of it as a general sort of relationship or is it really specific to

329
00:21:24.701 --> 00:21:25.870
things like discussed?

330
00:21:27.650 --> 00:21:32.150
<v 1>Well,
uh,
just about any evaluative judgment is going to involve ethic.</v>

331
00:21:32.210 --> 00:21:34.570
It seems to me,
uh,
and,
uh,

332
00:21:35.020 --> 00:21:40.020
it's a good question because the research that Gary and I have done really makes

333
00:21:40.671 --> 00:21:45.671
it look like disgust is specifically about the purity aspect of morality.

334
00:21:46.740 --> 00:21:49.580
And according to my former colleague John Height,

335
00:21:49.581 --> 00:21:54.581
there are about five different moral intuitions are which purity is only one.

336
00:21:55.560 --> 00:21:58.990
Uh,
so it remains to be seen in a way.

337
00:22:00.050 --> 00:22:03.320
<v 0>Yeah.
So many things that are on the future horizon of emotion.
Um,</v>

338
00:22:03.870 --> 00:22:07.170
which makes me think about it a little bit.
Um,
from your perspective,
I mean,

339
00:22:07.500 --> 00:22:11.330
where do you see the future of emotion research headed?
What,

340
00:22:11.331 --> 00:22:12.840
what is the horizon out there?

341
00:22:13.870 --> 00:22:14.190
<v 5>Yeah,</v>

342
00:22:14.190 --> 00:22:15.570
<v 1>well,
that's a good question.</v>

343
00:22:16.680 --> 00:22:17.880
<v 5>Yeah.
Uh,</v>

344
00:22:19.020 --> 00:22:22.620
<v 1>I recently wrote a chapter for a handbook,
a call,</v>

345
00:22:22.621 --> 00:22:24.390
five new ideas about emotion.

346
00:22:24.391 --> 00:22:27.060
And there were five new ideas that appeared in the last five years.

347
00:22:27.510 --> 00:22:29.760
There's a lot happening in the study of motion.

348
00:22:29.870 --> 00:22:32.610
And then basic things like asking again,
well,

349
00:22:32.611 --> 00:22:35.450
what is an emotion and how does it arise and what,

350
00:22:35.460 --> 00:22:38.070
how does it influence cognition and perception and actions on it?

351
00:22:39.280 --> 00:22:40.113
<v 5>MMM.</v>

352
00:22:42.020 --> 00:22:45.800
<v 1>And I think one of the more interesting developments is the idea that,</v>

353
00:22:46.810 --> 00:22:50.360
uh,
how to emotion,
well,
let me back up.

354
00:22:51.080 --> 00:22:53.960
Let's think of a,
like a behavioral ecologist.

355
00:22:55.150 --> 00:22:59.840
Humans like other animals as they're,
as they're,

356
00:22:59.990 --> 00:23:04.010
as having their behavior guided by ultimate concerns,

357
00:23:04.011 --> 00:23:08.090
like their resources.
And if you watch him a bird or an animal,

358
00:23:08.100 --> 00:23:09.080
then this environment,

359
00:23:10.250 --> 00:23:15.250
everything that it does is guided by the necessity to achieve certain resource

360
00:23:15.591 --> 00:23:19.460
gains and defend itself and,
and have shelter and so forth.

361
00:23:20.000 --> 00:23:22.760
And surely we're not that different.

362
00:23:23.660 --> 00:23:28.660
So an interesting development is to look at at emotion as a signal about that

363
00:23:30.651 --> 00:23:32.390
assists in resource management.

364
00:23:32.840 --> 00:23:36.550
We did a couple of experiments with a colleague Denny profit,
uh,

365
00:23:36.560 --> 00:23:41.030
in which we get made people sad and had had them judge the slant of the hill.

366
00:23:41.031 --> 00:23:44.300
Something that profit does regularly.
There's judge slams.

367
00:23:44.880 --> 00:23:49.610
They'll be found that when you're sad a hill look steeper and if you're on top

368
00:23:49.611 --> 00:23:53.090
of a hill and you're frightened because you're standing on a skateboard,

369
00:23:54.890 --> 00:23:58.910
it looks deeper.
And a variety of studies are now being done.

370
00:23:58.911 --> 00:24:03.110
Looking at making it look like emotion,

371
00:24:03.560 --> 00:24:08.230
um,
is concerned in part with resource management.

372
00:24:09.340 --> 00:24:14.340
That is the general position of profit is that our perception is informed by how

373
00:24:14.771 --> 00:24:18.540
tired we are or how much resources,
how many resources we got.

374
00:24:19.870 --> 00:24:23.530
But,
uh,
my former postdoc,
Simona Chanel,

375
00:24:23.531 --> 00:24:27.100
took this in an especially interesting direction saying,
well,
for humans,

376
00:24:27.610 --> 00:24:30.490
social resources are remarkably important.

377
00:24:30.491 --> 00:24:32.830
We are the ultra social species.

378
00:24:33.220 --> 00:24:37.900
We're the only species perhaps that cooperate with non-kin,

379
00:24:38.590 --> 00:24:42.070
please cooperate.
But they're all related,
uh,
within a high.

380
00:24:42.540 --> 00:24:44.500
But we cooperate with strangers.

381
00:24:44.680 --> 00:24:49.030
We will form teams and we'll even sacrifice for each other.

382
00:24:49.960 --> 00:24:52.540
And so the question is,
how does that work?

383
00:24:52.541 --> 00:24:57.330
How does all this hyper sociality keep us together?
Uh,

384
00:24:57.370 --> 00:25:01.840
and I think the answer is the social emotions.
If you start listing emotions,

385
00:25:01.930 --> 00:25:05.900
uh,
you'll discover that gene,
most of them are social,
emotional,

386
00:25:06.220 --> 00:25:11.220
gratitude and love and jealousy and brief and on and on.

387
00:25:12.220 --> 00:25:15.180
Right?
And so the idea,

388
00:25:15.310 --> 00:25:20.310
perhaps it's interesting that these emotions are helping us,

389
00:25:21.300 --> 00:25:26.050
well,
get an information about and motivate us to act in a way that maintains our

390
00:25:26.051 --> 00:25:28.620
resources.
Uh,
that is,

391
00:25:28.650 --> 00:25:31.140
we're all going to be in groups and work together.

392
00:25:31.160 --> 00:25:34.120
We care a lot about whether other people who are trustworthy.

393
00:25:34.480 --> 00:25:38.020
So a lot of what we do is to show other people,
I'm a good group member,

394
00:25:38.080 --> 00:25:42.730
I'm trustworthy and loyal.
Uh,
and when we find somebody who isn't,

395
00:25:42.760 --> 00:25:46.210
we all gossip about them and make sure everybody knows you don't trust that

396
00:25:46.211 --> 00:25:47.610
person anyways.

397
00:25:47.611 --> 00:25:52.120
So the ultimate resource for humans is perhaps needs social resources and an

398
00:25:52.150 --> 00:25:53.950
awful lot of human emotion.

399
00:25:54.010 --> 00:25:58.090
It's really about the management of those sources perhaps,

400
00:25:58.600 --> 00:26:00.970
but not much has been done from that perspective.

401
00:26:00.971 --> 00:26:03.370
And there's a whole lot of interesting questions for,

402
00:26:03.610 --> 00:26:05.560
for new investigators to think about.
I think

403
00:26:06.300 --> 00:26:09.120
<v 0>I'm in,
so you're talking about new investigators and it makes me wonder,</v>

404
00:26:09.360 --> 00:26:13.350
when your investigators come to you,
um,
post docs,
graduate students,

405
00:26:13.351 --> 00:26:15.930
undergraduates asking you for advice,

406
00:26:15.990 --> 00:26:19.930
they're thinking about maybe embarking into this field of emotion,
um,

407
00:26:20.100 --> 00:26:21.570
what kind of advice do you give them?

408
00:26:22.580 --> 00:26:23.030
<v 3>Okay,</v>

409
00:26:23.030 --> 00:26:24.530
<v 1>well,
um,</v>

410
00:26:25.550 --> 00:26:26.383
<v 3>okay.</v>

411
00:26:27.050 --> 00:26:31.910
<v 1>One of the things that I say often to students is that I try to encourage them</v>

412
00:26:31.911 --> 00:26:35.990
not to be social psychologists or a cognitive psychologist or clinical

413
00:26:35.991 --> 00:26:40.190
psychologist,
but psychologists to kind of take a broader view,

414
00:26:40.630 --> 00:26:45.480
uh,
because again,
consistent with the idea about the resources,

415
00:26:45.481 --> 00:26:47.820
I guess,
um,
emotions,

416
00:26:47.821 --> 00:26:52.821
part of a much larger system and we're not really going to understand it just by

417
00:26:53.431 --> 00:26:54.264
looking at,

418
00:26:54.330 --> 00:26:59.330
at this emotion phenomenon and that emotion phenomenon without thinking also how

419
00:26:59.401 --> 00:27:02.100
does it fit into some larger picture?

420
00:27:02.160 --> 00:27:07.160
So emotion like a jigsaw puzzle pieces more interesting once you see it fitting

421
00:27:08.401 --> 00:27:08.710
in

422
00:27:08.710 --> 00:27:09.543
<v 0>in the hole.</v>

423
00:27:12.550 --> 00:27:15.040
I just want to thank you again for joining us today.

424
00:27:15.340 --> 00:27:18.730
It was great to hear your insights and hear a bit about your thoughts on

425
00:27:18.731 --> 00:27:20.860
cognition and emotion,
Jerry,
so thank you.

426
00:27:21.500 --> 00:27:22.333
<v 1>Well,
thank you.</v>

427
00:27:23.340 --> 00:27:27.210
<v 0>So this concludes our experts in emotion interview with Dr. Gerald Clarke from</v>

428
00:27:27.211 --> 00:27:28.410
the University of Virginia.

