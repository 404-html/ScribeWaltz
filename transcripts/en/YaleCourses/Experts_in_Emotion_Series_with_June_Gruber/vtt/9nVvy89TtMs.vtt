WEBVTT

1
00:00:01.400 --> 00:00:03.080
For our experts interview.

2
00:00:03.230 --> 00:00:07.670
We'll have the honor of speaking with Dr. David Pizarro and associate professor

3
00:00:07.671 --> 00:00:10.070
of psychology at Cornell University.

4
00:00:10.550 --> 00:00:14.030
Dr Pizarro is a leading figure in morality and emotion.

5
00:00:14.240 --> 00:00:17.990
His research interests are in moral judgment and the effects of emotion on

6
00:00:17.991 --> 00:00:18.824
judgment.

7
00:00:18.890 --> 00:00:22.940
He received his phd from Yale University and has received research grants from

8
00:00:22.941 --> 00:00:26.690
the National Science Foundation and was a summer fellow at the center for the

9
00:00:26.691 --> 00:00:28.760
advanced study in the behavioral sciences.

10
00:00:29.060 --> 00:00:33.560
He's also given a wide the acclaim Ted talk on the strange politics of
discussed.

11
00:00:33.830 --> 00:00:38.780
So I'm pleased today to be speaking with Dr. David Pizarro on morality and

12
00:00:38.781 --> 00:00:42.520
discussed.
Hi David.

13
00:00:42.521 --> 00:00:44.140
Thanks for speaking with us today.

14
00:00:45.060 --> 00:00:45.893
<v 1>Thank you,
June.</v>

15
00:00:46.200 --> 00:00:48.180
<v 0>So we're all curious,</v>

16
00:00:48.210 --> 00:00:51.570
what got you first interested in emotion in the first place,

17
00:00:51.571 --> 00:00:53.250
sort of where did it all begin?

18
00:00:54.460 --> 00:00:58.360
<v 1>The honest truth is that I was interested in moral and ethical judgment first</v>

19
00:00:58.750 --> 00:01:01.660
and I really,
really wanted him to study moral psychology.

20
00:01:01.661 --> 00:01:05.770
But that was at a time when it wasn't a very popular topic,
uh,

21
00:01:05.920 --> 00:01:09.160
especially within social psychology,
which is what I had started studying.

22
00:01:09.790 --> 00:01:12.100
But I realized that if I studied emotion,

23
00:01:12.670 --> 00:01:16.690
a lot of work in social psychology had to do with emotion and its influence on

24
00:01:16.691 --> 00:01:20.090
behavior and some of that work was on its influence on altruism and prosocial

25
00:01:20.200 --> 00:01:21.390
behavior.
Uh,

26
00:01:21.430 --> 00:01:26.350
so because emotion had this deep link to morality already,

27
00:01:26.351 --> 00:01:31.060
both from old school philosophy and in more modern social psychology,

28
00:01:31.061 --> 00:01:33.700
I decided,
well,
okay,
well also study emotion.

29
00:01:33.910 --> 00:01:37.960
Just as a way I kind of is a sneaky way to study morality,

30
00:01:38.800 --> 00:01:41.830
but I came to love it on its own as I hope is evident.

31
00:01:42.530 --> 00:01:46.940
<v 0>So being a sneak star then I want to ask you a few questions about your
research.</v>

32
00:01:46.941 --> 00:01:49.400
So,
um,
you studied discuss,

33
00:01:49.401 --> 00:01:52.790
I know most of us can all things think about things that like did really

34
00:01:52.791 --> 00:01:54.140
discussed us in everyday life.

35
00:01:54.141 --> 00:01:57.080
I know I'm pretty disgust sensitive and I think you might be too.

36
00:01:57.790 --> 00:02:00.350
<v 1>Barry Barry Disgust sensitive problem.</v>

37
00:02:00.351 --> 00:02:03.740
Actually hard to do research.
Yes.

38
00:02:04.800 --> 00:02:07.710
<v 0>Can you tell me what is discussed really?</v>

39
00:02:07.890 --> 00:02:09.870
Like why do we have it in the first place?

40
00:02:10.960 --> 00:02:15.630
<v 1>Uh,
that's,
that's the million dollar question,
isn't it?
Disgust is,</v>

41
00:02:16.150 --> 00:02:16.983
um,

42
00:02:17.460 --> 00:02:21.770
what many would call a basic universal emotion that is no matter where you look,

43
00:02:21.780 --> 00:02:24.120
it appears that people across the world habit,

44
00:02:24.270 --> 00:02:26.550
it emerges fairly early on in life.

45
00:02:26.790 --> 00:02:31.200
And it seems to be an emotion that's dedicated to a pretty specific function.

46
00:02:31.410 --> 00:02:36.030
And that function is to keep you away from eating or touching things that might

47
00:02:36.031 --> 00:02:36.864
make you sick.

48
00:02:37.530 --> 00:02:41.640
So even the word disgust betrays the origins,
uh,

49
00:02:41.730 --> 00:02:46.650
that the gust part refers to the tastes function.

50
00:02:46.950 --> 00:02:51.690
And for instance,
if you give little babies are really bitter sour taste.

51
00:02:51.960 --> 00:02:55.410
They make a very similar face to what we make when we had discussed it as
adults.

52
00:02:55.800 --> 00:03:00.190
So the thinking is that disgust is an emotion that evolved really to keep us

53
00:03:00.191 --> 00:03:03.020
away from,
from what we now consider gross things.
But,

54
00:03:03.160 --> 00:03:05.020
but what we say when we say gross things,

55
00:03:05.021 --> 00:03:08.020
we really mean things that are dangerous because of their possible possible

56
00:03:08.021 --> 00:03:08.854
contamination.

57
00:03:09.600 --> 00:03:13.620
<v 0>So then are there things that discussed all humans universally or does it seem</v>

58
00:03:13.621 --> 00:03:15.150
to very cross culturally?

59
00:03:15.620 --> 00:03:17.450
<v 1>Yes.
So disgust.</v>

60
00:03:18.260 --> 00:03:22.580
Disgust is a great emotion because the list of things that seem to discuss

61
00:03:22.581 --> 00:03:24.710
people universally is pretty robust.

62
00:03:24.980 --> 00:03:28.730
And so when no matter really where you look across the world with some

63
00:03:28.731 --> 00:03:29.564
exceptions,

64
00:03:29.660 --> 00:03:34.430
people don't like things like pus and feces and Al Roker rotten meat,

65
00:03:35.660 --> 00:03:39.590
at least I haven't encountered any culture that eats puss on a regular basis as

66
00:03:39.591 --> 00:03:42.450
a delicacy.
See this,

67
00:03:42.510 --> 00:03:46.310
this actually shows you another feature of discuss how easy it is to engender a

68
00:03:46.500 --> 00:03:48.050
disgusting,
especially people like us.

69
00:03:48.860 --> 00:03:52.510
But that's not to say just because as you is emotion researchers,

70
00:03:52.530 --> 00:03:56.000
we loved the universal part.
So the list for discussed seems pretty,

71
00:03:56.030 --> 00:04:00.860
pretty big and robust,
but the list of culturally variable disgust,

72
00:04:01.040 --> 00:04:04.040
you listed her as those things that make us,
he's lead disgusting,
uh,

73
00:04:04.100 --> 00:04:07.610
is actually much larger.
So,
um,
I'll give you an example.

74
00:04:08.240 --> 00:04:12.950
For Chinese people,
the fact that we eat cheese is pretty gross.

75
00:04:12.980 --> 00:04:17.390
So they,
they,
they're,
they're,
they're going to ask us questions like,

76
00:04:17.750 --> 00:04:20.180
wait,
you wait until the milk gets rotten.

77
00:04:20.510 --> 00:04:24.260
And then you wait until it curdles up into solid balls and you combine those

78
00:04:24.261 --> 00:04:25.370
together and you eat them.

79
00:04:25.430 --> 00:04:28.520
And to them that's just utterly disgusting of course to us.

80
00:04:29.030 --> 00:04:30.070
Many of the things that,
uh,

81
00:04:30.071 --> 00:04:34.250
that people eat in mainland China might be disgusting and that reaction is just

82
00:04:34.251 --> 00:04:37.220
as powerful,
but it is culturally variable.

83
00:04:37.310 --> 00:04:41.540
And one reason that it kind of has to be culturally variable is that we grew up

84
00:04:41.541 --> 00:04:43.070
in different environments,
different,

85
00:04:43.100 --> 00:04:46.730
different places and we're required as children to eat different things.

86
00:04:46.731 --> 00:04:48.740
It would be very bad for,

87
00:04:49.010 --> 00:04:54.010
for us to have such a rigid disgust response that even as infants we rejected

88
00:04:54.441 --> 00:04:54.741
everything.

89
00:04:54.741 --> 00:04:59.741
So there's a huge variety of things that we can learn to eat and not be

90
00:05:00.051 --> 00:05:00.920
disgusted by.

91
00:05:01.970 --> 00:05:05.030
<v 0>What's really cool about the work you've done on discussed too is that you show,</v>

92
00:05:05.031 --> 00:05:09.140
it's not just,
you know,
uh,
designed to sort of expel,
you know,

93
00:05:09.410 --> 00:05:13.760
nasty curdles and cheese balls or you know,
whatever,
whatever your thing is,

94
00:05:13.761 --> 00:05:16.040
but that it actually also can influence,

95
00:05:16.041 --> 00:05:19.370
you've shown like higher order moral reasoning such as,
you know,

96
00:05:19.371 --> 00:05:24.170
attitudes about homosexuality or political affiliation and how is it possible

97
00:05:24.171 --> 00:05:28.540
that discuss can influence these kinds of more complex attitudes.
Okay.

98
00:05:29.080 --> 00:05:29.531
<v 1>Yeah.</v>

99
00:05:29.531 --> 00:05:34.531
So that was a puzzle to us because it really does seem like disgust ought to be

100
00:05:36.251 --> 00:05:38.980
constrained to just those things that might make you sick.

101
00:05:39.250 --> 00:05:43.900
The problem is nowadays we have all kinds of information about what really is

102
00:05:43.960 --> 00:05:46.780
dangerous and what really isn't.
So we know,
for instance,

103
00:05:46.781 --> 00:05:50.630
we have a proper germ theory of disease.
We know that,
uh,

104
00:05:50.710 --> 00:05:54.550
shaking someone's hand won't give us HIV for instance.
Um,

105
00:05:54.850 --> 00:05:59.070
discussed as the emotion,
didn't really know that.
And so the story that,
that,
uh,

106
00:05:59.150 --> 00:06:04.040
I believe about how disgust evolved and many others who studied,

107
00:06:04.100 --> 00:06:04.820
discussed,

108
00:06:04.820 --> 00:06:09.820
believe this is that discussed sort of spread from not just keeping us from

109
00:06:09.890 --> 00:06:14.420
eating bad things but also from anything that might be potentially
contaminating.

110
00:06:15.050 --> 00:06:19.460
But what happens is that people are one big source of pathogens for us.

111
00:06:19.730 --> 00:06:24.560
And so anybody who encounters a stranger whom they have never encountered
before,

112
00:06:24.910 --> 00:06:29.180
um,
is running the risk that they're going to carry diseases that we don't have

113
00:06:29.181 --> 00:06:33.710
immunity for.
And so it behooves us to have this emotion that,

114
00:06:33.740 --> 00:06:36.230
that actually would keep us away from,
uh,

115
00:06:36.470 --> 00:06:41.180
from coming into close contact with especially people who look sick.

116
00:06:41.210 --> 00:06:44.660
So any marker that you might have a disease,
like an infection.

117
00:06:44.970 --> 00:06:48.530
One of the disgust solicitors that I use very reliably is I have a friend who's

118
00:06:48.531 --> 00:06:53.120
a dermatologist and she gave me access to this data,
Bank of,
of skin diseases,

119
00:06:54.600 --> 00:06:59.090
just skin.
These are like a big warning sign,
like stay away from me because you,

120
00:06:59.200 --> 00:07:02.120
this might happen to your skin.
And uh,

121
00:07:02.540 --> 00:07:06.500
and so because discussed as these features,
one,
it's really,

122
00:07:06.501 --> 00:07:08.780
really easy to elicit.
All right.
You know,
as you,

123
00:07:09.110 --> 00:07:11.870
as you know in his other people who you're gonna interview know,

124
00:07:12.110 --> 00:07:14.940
sometimes it's really hard to bring people in for the lab and actually discuss

125
00:07:14.941 --> 00:07:18.740
them.
Um,
so it's really easy to elicit,
uh,
it,

126
00:07:19.010 --> 00:07:22.460
it can easily be tagged to people because people are a potential source of

127
00:07:22.461 --> 00:07:23.240
pathogens.

128
00:07:23.240 --> 00:07:28.240
So now what you have is an emotional system that's biased toward rejecting and

129
00:07:29.061 --> 00:07:30.830
avoiding individuals.

130
00:07:30.831 --> 00:07:35.831
And sometimes even groups that might either appear diseased or might have any

131
00:07:36.171 --> 00:07:40.820
sort of difference in their hygiene,
in their cleanliness,
customs in there,

132
00:07:40.850 --> 00:07:44.330
in the food that they eat or even in their sexual behavior.
Um,

133
00:07:44.331 --> 00:07:47.300
and it turns out that sex is quite easily linked to disgust.

134
00:07:47.480 --> 00:07:51.570
I don't think I need to go into an exam.
Any examples about that?
Um,

135
00:07:51.740 --> 00:07:54.380
but in the sexual domain is one that lends itself very nicely.

136
00:07:54.381 --> 00:07:57.170
So a lot of the work on discussed has been around,
uh,
it's,

137
00:07:57.230 --> 00:08:02.090
it's it function and preventing us from,
from engaging in incest.
Um,

138
00:08:02.120 --> 00:08:04.010
so that's a good thing.
And so,

139
00:08:04.070 --> 00:08:08.720
so now you have an emotion that can easily be linked to individuals or groups,

140
00:08:08.721 --> 00:08:11.300
especially ones that are different who are different from us.

141
00:08:11.750 --> 00:08:15.680
And it makes sense that it would be a very powerful emotion if what you're

142
00:08:15.681 --> 00:08:18.410
trying to do is convince somebody else that,
for instance,

143
00:08:18.620 --> 00:08:20.930
homosexual behaviors is wrong.
Right?

144
00:08:20.960 --> 00:08:23.690
It gives you that powerful gut reaction that,
oh,
that's gross.

145
00:08:23.720 --> 00:08:27.560
That's something that I don't do.
Um,
and,
and therefore it's wrong.

146
00:08:28.770 --> 00:08:32.790
<v 0>So do you think that this is a special feature of discuss that it's a special</v>

147
00:08:32.791 --> 00:08:35.790
emotion that can,
you know,
influence our moral judgments?

148
00:08:35.791 --> 00:08:40.260
Or are there other emotions that share these kind of similar features as

149
00:08:40.261 --> 00:08:41.094
discussed?

150
00:08:41.780 --> 00:08:43.760
<v 1>You know,
when it comes down to it,
if you,</v>

151
00:08:43.790 --> 00:08:45.920
if you really as somebody who studies morality,

152
00:08:45.921 --> 00:08:49.850
if what I really want to do is try to explain all of human moral judgment,

153
00:08:50.060 --> 00:08:51.830
discuss,
there's only going to play a small role.

154
00:08:52.520 --> 00:08:55.040
All emotions have this power to influence,

155
00:08:55.290 --> 00:09:00.290
to influence judgment broadly and moral judgment in particular discussed has uh,

156
00:09:01.140 --> 00:09:04.460
it appears to have a very specific tie to,

157
00:09:04.500 --> 00:09:08.490
to human morality that some of the other ones don't.
But um,

158
00:09:09.240 --> 00:09:11.790
but when you look at it,
some of some of the emotions,

159
00:09:11.791 --> 00:09:15.720
some of our social emotions for instance,
like anger and sympathy or empathy,

160
00:09:16.080 --> 00:09:18.780
those are kind of tailor made for,

161
00:09:18.840 --> 00:09:23.840
for our social relations and something that we might refer to as ethical

162
00:09:24.121 --> 00:09:26.730
judgment.
So for instance,
when you're angry at somebody,

163
00:09:26.731 --> 00:09:30.960
it often contains this element of blame that they did something that they should

164
00:09:30.961 --> 00:09:35.000
not have done.
And I want justice or revenge.
Disgust.

165
00:09:35.300 --> 00:09:38.880
Disgust is interesting in that even though it might only affect a small bit of

166
00:09:38.881 --> 00:09:41.130
our moral judgments,
it isn't,

167
00:09:41.400 --> 00:09:46.050
it's proper domain doesn't seem to be moral evaluation in the same way that

168
00:09:46.140 --> 00:09:48.030
anger or sympathy might be.

169
00:09:48.250 --> 00:09:51.180
Sympathy seems like it was built to make us care about other people.

170
00:09:51.181 --> 00:09:54.360
Anger seems like it was built to,
to keep others from cheating.

171
00:09:54.361 --> 00:09:59.361
US discussed seems to have been built to keep us away from gross sickly things

172
00:10:00.600 --> 00:10:03.360
and now it seems overextended.

173
00:10:03.720 --> 00:10:08.250
And so it seems as if if it fires it over fires and in a way that actually might

174
00:10:08.251 --> 00:10:12.120
make our moral judgments,
we might have to be careful in a way that we,

175
00:10:12.121 --> 00:10:14.520
we don't necessarily have to be careful for some other emotions.

176
00:10:14.720 --> 00:10:19.700
<v 0>So not let discuss,
kind of go,
uh,
on,
on harness.
Just kind of go wild.</v>

177
00:10:19.930 --> 00:10:22.990
<v 1>Right.
And one example I like to give people is,
um,
you know,</v>

178
00:10:23.890 --> 00:10:26.590
just because something is disgusting doesn't mean that it's wrong.

179
00:10:26.591 --> 00:10:31.270
So for instance,
I find it very disgusting to,
uh,
to pick your nose,
right?

180
00:10:31.300 --> 00:10:33.040
I think everybody probably find that,
discuss it,

181
00:10:33.041 --> 00:10:36.710
but nobody goes around saying down with nose picking.
Um,

182
00:10:37.570 --> 00:10:38.290
and so when,

183
00:10:38.290 --> 00:10:42.610
when you're using discussed as the sole as the sole measure of whether or not

184
00:10:42.611 --> 00:10:43.750
you think something is wrong,

185
00:10:43.920 --> 00:10:46.870
I think you really need to kind of check yourself and say,
oh look,

186
00:10:46.871 --> 00:10:49.690
there's a lot of,
lot of really disgusting things.
But,
but are,

187
00:10:49.870 --> 00:10:51.730
is it necessarily true that they're wrong?

188
00:10:51.790 --> 00:10:55.600
And what we find is that what may be going on is it some people are more likely

189
00:10:55.601 --> 00:10:59.860
to use,
discussed as input into their moral judgment than others.

190
00:11:00.010 --> 00:11:03.310
And so while everybody might be disgusted,
say a particular sexual acts,

191
00:11:03.520 --> 00:11:05.440
some people stop at the disgust and say,

192
00:11:05.441 --> 00:11:09.190
well that has nothing to do with what I believe about whether you ought to be

193
00:11:09.191 --> 00:11:10.024
allowed to do that.

194
00:11:10.120 --> 00:11:14.650
But some people actually find it as a perfectly reasonable thing to use their

195
00:11:14.651 --> 00:11:15.484
disgust as input.

196
00:11:16.080 --> 00:11:19.650
<v 0>So you've also found that discuss influences really important,
you know,</v>

197
00:11:19.651 --> 00:11:24.651
health care related behaviors such as deciding to go for a cancer screening or

198
00:11:24.811 --> 00:11:28.500
to avoid it.
Right.
So what impact you think,
discuss,

199
00:11:28.501 --> 00:11:32.280
can actually have on our own health and sort of public health policy?

200
00:11:32.650 --> 00:11:34.360
<v 1>Yeah,
this is an interesting,
uh,</v>

201
00:11:34.400 --> 00:11:37.840
an interesting feature of disgust that my colleague Nathan Considine,

202
00:11:37.841 --> 00:11:41.280
who is actually a clinical health psychologist was interested in.

203
00:11:41.300 --> 00:11:42.520
I hadn't given it much thought,

204
00:11:42.670 --> 00:11:45.790
but the truth of the matter is when you have a disease,

205
00:11:45.820 --> 00:11:48.700
it's easy to be disgusted at yourself.
Um,

206
00:11:48.850 --> 00:11:53.850
and so a lot of these health health behaviors require us to go to the doctor and

207
00:11:55.811 --> 00:12:00.430
do things like provide stool samples or you're in samples or show the doctor

208
00:12:00.431 --> 00:12:03.700
that disgusting part of your body that you've been embarrassed to show anybody

209
00:12:03.701 --> 00:12:07.930
else.
And that given the power of disgust,
you know,
I've said a few times now,

210
00:12:07.931 --> 00:12:08.764
it's a strong,

211
00:12:09.100 --> 00:12:13.780
it's a strong avoidance response when you feel disgust for yourself.

212
00:12:14.140 --> 00:12:17.590
Um,
Eh,
you are ashamed to show the doctor this.

213
00:12:17.650 --> 00:12:20.740
This is a very powerful motivation that keeps people away from going to the

214
00:12:20.741 --> 00:12:25.330
doctor.
So there are all kinds of,
of uh,
uh,
people who for instance,

215
00:12:25.540 --> 00:12:28.450
have a growth that goes completely unchecked.

216
00:12:28.780 --> 00:12:31.480
And by the time they go to the doctor,
the doctor's like,

217
00:12:31.481 --> 00:12:35.410
why haven't you come in earlier?
And the truth is that they were,

218
00:12:35.440 --> 00:12:40.090
they were afraid to or ashamed or disgusted by themselves.

219
00:12:40.360 --> 00:12:42.640
And so part of what I think needs to be done is,

220
00:12:42.700 --> 00:12:47.700
is I think people don't realize that doctors in fact are very,

221
00:12:48.851 --> 00:12:53.620
very well trained in avoiding discussed for that particular domain.
And so,

222
00:12:53.680 --> 00:12:55.640
uh,
and so one of the,

223
00:12:55.660 --> 00:12:58.840
the health messages when we're trying to convince people to engage in,

224
00:12:58.841 --> 00:13:01.450
in these positive health behaviors like screening behaviors,

225
00:13:01.780 --> 00:13:05.180
we need to tell them,
look,
doctor seen a lot grosser than that.
Right?

226
00:13:07.230 --> 00:13:11.290
That's right.
I'm sure they have.
And maybe you're the one person,
right?

227
00:13:13.480 --> 00:13:13.720
Well,

228
00:13:13.720 --> 00:13:16.780
I think anybody who browses the Internet for a sufficient period of time has

229
00:13:16.781 --> 00:13:18.730
probably seen just as many gross things as I have.

230
00:13:20.000 --> 00:13:24.400
What do you think then is in the store for the future study of emotion?

231
00:13:26.240 --> 00:13:29.990
What's that?
It's,
it's interesting.
I,
uh,

232
00:13:30.160 --> 00:13:31.810
when I started studying emotion,

233
00:13:32.170 --> 00:13:35.530
it seemed like a fairly novel thing.

234
00:13:35.620 --> 00:13:38.890
So the history of the study of emotion and psychology is kind of interesting.

235
00:13:38.891 --> 00:13:42.810
So we had some very,
very powerful early,
uh,
early research and then,

236
00:13:42.860 --> 00:13:45.700
and then we just started ignoring it for a while and then there was this

237
00:13:45.701 --> 00:13:50.140
explosion of research and emotion that that was exciting.
And,
um,

238
00:13:50.170 --> 00:13:54.540
and I think a lot of the reason that there was this explosion was because of an

239
00:13:54.550 --> 00:13:59.370
increased availability of methods to study emotion.
There.

240
00:13:59.400 --> 00:14:03.280
There are more and more methods that psychologists can use.
Um,

241
00:14:03.580 --> 00:14:07.420
and that hasn't seem to stop.
So my fear was always like this would,

242
00:14:07.540 --> 00:14:11.310
it would ebb and flow in that,
that we might sort of lose interest in emotion,

243
00:14:11.320 --> 00:14:14.410
but I don't think that's happening.
I think with increased methods more,

244
00:14:14.411 --> 00:14:17.410
we're learning more and more about what emotions are and what they do.

245
00:14:18.130 --> 00:14:21.100
And so I'm actually really optimistic about the future.
I mean,

246
00:14:21.101 --> 00:14:25.540
now nowadays we can buy devices for a couple of hundred dollars that are

247
00:14:25.541 --> 00:14:30.130
portable,
that can measure your physiological reactions.
Um,
throughout the day.

248
00:14:30.400 --> 00:14:33.010
We couldn't do that even when I was in graduate school.
It was,

249
00:14:33.310 --> 00:14:34.840
which was a year ago June,

250
00:14:37.090 --> 00:14:40.150
that would have cost us thousands and thousands of dollars.
And so,

251
00:14:40.180 --> 00:14:44.200
so there's nothing to stop us from.
And even with Internet data collection,

252
00:14:44.201 --> 00:14:49.030
even if you're talking about just shirt,
sheer,
subjective emotional responses,
um,

253
00:14:49.150 --> 00:14:52.010
it's,
it's just becoming easier and easier to study emotion.

254
00:14:52.340 --> 00:14:56.660
So I think that the big task before us won't be to,
to gather data.

255
00:14:56.810 --> 00:15:00.350
It will be to make sense of the overwhelming amount of data that we have.

256
00:15:00.620 --> 00:15:02.240
So we need,
we need young,

257
00:15:02.241 --> 00:15:07.010
good emotion theorists to try to make sense of what's going on in these data.

258
00:15:07.011 --> 00:15:10.040
And I hope that that's,
that's,
that's actually what happens in the next 10 years.

259
00:15:10.041 --> 00:15:13.370
People who are smarter than you and I who are currently in graduate school will

260
00:15:13.371 --> 00:15:16.280
come along and make some sense of it all still in Grad school.

261
00:15:18.560 --> 00:15:20.120
<v 0>Well,
speaking of the students then,</v>

262
00:15:20.121 --> 00:15:24.320
sort of what advice would you give Grad students or younger students,

263
00:15:24.321 --> 00:15:26.690
people may be thinking about studying emotion?
What,

264
00:15:26.870 --> 00:15:29.900
what advice would you give for them as they think about embarking in this,

265
00:15:30.200 --> 00:15:32.780
you know,
uncharted terrain.

266
00:15:33.200 --> 00:15:34.033
<v 1>Yeah.
The,</v>

267
00:15:34.080 --> 00:15:38.340
the biggest piece of advice I have is don't lose your curiosity,

268
00:15:38.341 --> 00:15:40.530
your broad curiosity.
Um,

269
00:15:40.890 --> 00:15:43.860
because if we're really going to make progress,

270
00:15:43.861 --> 00:15:45.720
we need students who are interested,

271
00:15:46.260 --> 00:15:49.830
intrinsically interested in the topic such that they will read,

272
00:15:49.980 --> 00:15:53.790
they will learn about every everything.
Emotion,
as you know,

273
00:15:53.791 --> 00:15:58.080
is one of the most truly interdisciplinary topics in psycho.
I mean,

274
00:15:58.081 --> 00:16:02.460
psychology is already touches on so many other fields,

275
00:16:02.700 --> 00:16:07.620
but emotion in particular,
you can read a evolutionary biology,

276
00:16:07.621 --> 00:16:10.260
genetics,
you can read sociology,

277
00:16:10.290 --> 00:16:13.200
you can read the philosophy of emotion.

278
00:16:13.590 --> 00:16:17.820
And there's this problem that when when students come into Grad school,

279
00:16:17.821 --> 00:16:19.770
we have to get them narrow.

280
00:16:20.340 --> 00:16:24.720
You come in with all of these broad interests and you're forced to go narrow or

281
00:16:24.721 --> 00:16:28.800
in there,
you know,
by the time you're done,
your dissertation is like,
you know,

282
00:16:28.830 --> 00:16:32.370
on the effects of x on y when Z is,

283
00:16:32.420 --> 00:16:36.390
is in population,
you know,
and it's,
it becomes such a narrow,

284
00:16:36.391 --> 00:16:40.410
narrow topic that that has the possibility of killing peoples breadth.

285
00:16:40.980 --> 00:16:41.970
And so,

286
00:16:42.180 --> 00:16:46.290
so don't lose sight of the fact that this is a truly deep and interesting and

287
00:16:46.291 --> 00:16:49.770
broad question and read,
read whatever floats your boat.

288
00:16:49.771 --> 00:16:54.750
That has to do with the topic.
You know,
if you read robotics,

289
00:16:54.751 --> 00:16:58.680
you can learn about emotion.
Don't,
don't stop doing that.
Um,
and,

290
00:16:58.740 --> 00:17:00.210
and for God's sakes,

291
00:17:00.211 --> 00:17:03.180
don't do anything that you don't feel any intrinsic interest in.

292
00:17:03.181 --> 00:17:06.870
They will never pay you enough to study something that you don't want to study

293
00:17:06.871 --> 00:17:08.910
just because it's the hot or popular topic.

294
00:17:10.200 --> 00:17:12.760
<v 0>Well,
thanks for talking with us today,
David.
Um,</v>

295
00:17:13.260 --> 00:17:17.250
this concludes our experts and emotion interview with Dr. David Pizarro from

296
00:17:17.251 --> 00:17:18.120
Cornell University.

