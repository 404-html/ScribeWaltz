1
00:00:02,360 --> 00:00:06,390
So welcome back everybody.
It's probably, uh,

2
00:00:06,870 --> 00:00:11,870
will take a while to wrestle your brains
back to what we were talking about

3
00:00:12,271 --> 00:00:15,870
before the break. Um, and I'll, I'll,

4
00:00:15,871 --> 00:00:20,310
I'll do my best to help in that endeavor.
And um,

5
00:00:21,160 --> 00:00:22,200
we're talking,

6
00:00:22,800 --> 00:00:26,850
we're really finishing up the
first two thirds of the course.

7
00:00:26,880 --> 00:00:31,140
Well by talking about John Rawls.
Um,

8
00:00:31,860 --> 00:00:33,180
a very

9
00:00:34,740 --> 00:00:39,740
interesting figure and phenomenon
in modern political philosophy.

10
00:00:42,670 --> 00:00:47,220
We finish it up the first two thirds
of the course in the sense that,

11
00:00:47,280 --> 00:00:50,100
um,
this is the third enlightenment tradition.

12
00:00:50,101 --> 00:00:55,101
We're talking about the first two having
been utilitarianism and Marxism and

13
00:00:56,401 --> 00:00:58,170
after we finished with the roles,

14
00:00:58,180 --> 00:01:01,380
we're going to talk about the Anti
Enlightenment tradition and then the

15
00:01:01,381 --> 00:01:04,290
democratic traditions.
Um,

16
00:01:04,710 --> 00:01:09,710
so roles is an odd figure in some ways.

17
00:01:10,830 --> 00:01:12,060
Um,
if,

18
00:01:12,600 --> 00:01:17,600
if I had been here or if my predecessor
from a prior generation had been here,

19
00:01:21,360 --> 00:01:26,360
I teach teaching a course like
this in the 1950s or early 1960s.

20
00:01:27,930 --> 00:01:32,930
And somebody had speculated that maybe
are very major figure would emerge in

21
00:01:36,841 --> 00:01:39,330
American political philosophy.

22
00:01:40,350 --> 00:01:43,740
There would've been a lot of skepticism
and they would have been even more

23
00:01:43,741 --> 00:01:48,741
skepticism if somebody had said and
they would have been a theorist of the

24
00:01:49,621 --> 00:01:51,150
social contract.

25
00:01:52,140 --> 00:01:55,470
And I think that would have been
two reasons for that skepticism.

26
00:01:56,130 --> 00:01:59,040
One is that political philosophy

27
00:02:00,870 --> 00:02:05,610
was really not thought to
be a particularly important
area of philosophy of

28
00:02:05,611 --> 00:02:10,080
academic philosophy in
the 1950s and 1960s,

29
00:02:11,100 --> 00:02:11,990
the people who,

30
00:02:12,010 --> 00:02:17,010
who were sort of seen as the cutting edge
in philosophy were doing philosophy of

31
00:02:17,401 --> 00:02:20,610
language, logic, epistemology,

32
00:02:20,611 --> 00:02:25,611
metaphysics and political philosophy was
sort of weighed down on the totem pole.

33
00:02:27,390 --> 00:02:27,691
Uh,

34
00:02:27,691 --> 00:02:32,691
it was a subdivision of ethics and sort
of ethics for many people if you like.

35
00:02:34,770 --> 00:02:35,603
Um,

36
00:02:35,760 --> 00:02:40,760
and the notion that anybody in philosophy
who did political philosophy would

37
00:02:41,251 --> 00:02:46,251
turn out to be a major figure would
have attracted a lot of skepticism among

38
00:02:46,981 --> 00:02:51,300
academic philosophers.
And yet John Roles,

39
00:02:51,320 --> 00:02:54,270
I think today, and if you, if you polled,

40
00:02:54,271 --> 00:02:59,271
if you went around the most prestigious
philosophy departments in the world,

41
00:02:59,980 --> 00:03:03,460
not just in the English
speaking world today and said,

42
00:03:03,850 --> 00:03:08,850
who was the most important philosopher
of the last third of the 20th century?

43
00:03:09,581 --> 00:03:11,690
Not Political Philosophy,
just philosopher.

44
00:03:12,400 --> 00:03:13,233
MMM.

45
00:03:13,350 --> 00:03:16,590
And you and you asked that question of

46
00:03:18,500 --> 00:03:18,890
okay,

47
00:03:18,890 --> 00:03:23,210
people in major philosophy departments
around the world roles would be cited

48
00:03:23,211 --> 00:03:24,920
more than any other person.

49
00:03:25,800 --> 00:03:26,030
Yeah.

50
00:03:26,030 --> 00:03:28,610
That, any doubt about it. I
don't have any doubt about it.

51
00:03:28,700 --> 00:03:31,100
He'd decided more than any other person.

52
00:03:32,200 --> 00:03:33,033
MMM.

53
00:03:35,150 --> 00:03:38,900
So that's one reason people would have
been skeptical that they just didn't

54
00:03:38,901 --> 00:03:41,210
think political philosophy
is that important and,

55
00:03:41,310 --> 00:03:45,440
and this sort of serious heavyweights
in phosphene did other things.

56
00:03:46,130 --> 00:03:51,130
But then I think the second reason people
would have been skeptical is that a

57
00:03:51,141 --> 00:03:55,760
theorist of the social contract and
everybody knew that the social contract,

58
00:03:55,761 --> 00:03:59,060
which is you all know has been
around in its modern form,

59
00:03:59,070 --> 00:04:03,830
at least since the 17th century. Everybody
knew it had these two huge problems.

60
00:04:04,130 --> 00:04:07,670
One was that it didn't have,
um,

61
00:04:09,060 --> 00:04:09,890
okay,

62
00:04:09,890 --> 00:04:12,950
any grounding in natural
law that people accepted.

63
00:04:13,700 --> 00:04:16,310
And the second was it never
was a social contract.

64
00:04:17,480 --> 00:04:22,480
We now know from 150 years of anthropology
than ever was a social contract.

65
00:04:22,790 --> 00:04:27,790
Aristotle was closer to being accurate
when he sort of treated human beings as

66
00:04:28,461 --> 00:04:32,060
inherently political.
There was never a pre political condition.

67
00:04:32,990 --> 00:04:33,823
MMM.

68
00:04:34,230 --> 00:04:38,920
And as you now know,
because we've studied Robert Nozick MMM.

69
00:04:39,850 --> 00:04:44,850
The revival of the social
contract tradition answered
both those questions first

70
00:04:45,101 --> 00:04:49,780
by replacing natural law with
some version of a manual cons,

71
00:04:49,781 --> 00:04:51,880
ethics. So ethic, uh,

72
00:04:51,910 --> 00:04:55,060
con becomes the place
holder for natural law.

73
00:04:56,050 --> 00:04:57,490
And on the other hand,

74
00:04:57,491 --> 00:05:02,110
working with hypothetical contracts
rather than actual contracts.

75
00:05:02,111 --> 00:05:05,140
The asking the question,
what would people agree to?

76
00:05:05,141 --> 00:05:07,930
Not what did people agreed to,
uh,

77
00:05:07,931 --> 00:05:10,690
under certain specified conditions.

78
00:05:11,170 --> 00:05:14,800
But neither of those ideas
was central to Nozick.

79
00:05:15,210 --> 00:05:20,210
I was invented by Nozick rare that both
of those ideas were invented by roles

80
00:05:21,340 --> 00:05:25,600
and Nozick was one of many
people who reacted to roles.

81
00:05:25,930 --> 00:05:30,250
I had pedagogical reasons for
dealing with Nozick first,

82
00:05:30,280 --> 00:05:34,810
namely that his argument, it goes,
grows so directly out of locks.

83
00:05:35,110 --> 00:05:39,310
But if this was a course in the history
of 20th century political philosophy,

84
00:05:39,550 --> 00:05:41,890
of course we would have done roles first.

85
00:05:42,310 --> 00:05:46,510
And it's really important to say this
because no one knows x book would never

86
00:05:46,511 --> 00:05:49,000
have been written.
But for roles.

87
00:05:49,330 --> 00:05:53,800
And I think that one measure of the
importance of roles is that there are

88
00:05:53,801 --> 00:05:58,801
probably 50 bucks and I don't know how
many articles that would never have been

89
00:06:00,141 --> 00:06:04,850
written, but for roles you can go out
and find roles as book in the library,

90
00:06:05,120 --> 00:06:08,780
uh, and you'll find it on
the shelf next to the book.

91
00:06:08,990 --> 00:06:12,590
Just books listing the
citations to roles as buck.

92
00:06:13,490 --> 00:06:16,820
And so that's a very interesting fact.

93
00:06:17,000 --> 00:06:22,000
It's also an interesting fact because
roles is not a great in the sense that we

94
00:06:23,181 --> 00:06:25,940
think of as Hobbes, Locke or male ow, ow,

95
00:06:25,941 --> 00:06:30,941
Dewey who we don't read in this course
as great in the sense that he does.

96
00:06:32,750 --> 00:06:37,750
Most of those people had a view of
the world that range right across all

97
00:06:42,350 --> 00:06:46,100
domains of knowledge. So if
you read, you know, locked,

98
00:06:46,101 --> 00:06:48,050
he had a philosophy and a view of,

99
00:06:48,110 --> 00:06:52,970
of knowledge of you have language of
your theology, of your politics, uh,

100
00:06:52,990 --> 00:06:56,660
a view of everything.
Mel had a theory of science.

101
00:06:56,661 --> 00:07:00,080
He had a mathematical theory. He had, um,

102
00:07:00,350 --> 00:07:04,660
theories of meaning. He had, um, uh,

103
00:07:04,690 --> 00:07:09,590
an epistemology and he had a theory
of politics. Dewey, same story.

104
00:07:09,591 --> 00:07:11,270
There's a,
there's a whole,

105
00:07:11,330 --> 00:07:16,100
there's a whole world view that's worked
out in every what we today think of as

106
00:07:16,101 --> 00:07:18,740
disciplines,
but for most of the tradition,

107
00:07:19,040 --> 00:07:22,340
we're not divided up in the
way we divide things up today,

108
00:07:22,580 --> 00:07:27,580
but they have the people we tend to call
greats had a view that ranges across

109
00:07:28,521 --> 00:07:30,940
the whole range, the whole, um,

110
00:07:31,160 --> 00:07:35,120
gamut of knowledge,
uh,

111
00:07:35,150 --> 00:07:38,240
roles that didn't do that.
He doesn't have a metaphysics,

112
00:07:38,241 --> 00:07:41,390
he doesn't have a pest homology,
doesn't have a theory of science.

113
00:07:41,391 --> 00:07:45,400
He doesn't have a theory of language.
He only wrote this book. Uh,

114
00:07:45,470 --> 00:07:49,550
basically you wrote some articles
which led up to the book and then some,

115
00:07:49,880 --> 00:07:54,580
some things that follow out of the book,
but basically his book,

116
00:07:54,581 --> 00:07:59,030
the theory of Justice
is it, um, and so he's,

117
00:07:59,031 --> 00:08:02,570
he's not a great in that sense
of the greats of the tradition,

118
00:08:02,960 --> 00:08:07,960
but he certainly has more intellectual
staying power than anyone.

119
00:08:08,150 --> 00:08:12,340
Any con contemporary in a broad sense
of the word that you've read in this

120
00:08:12,341 --> 00:08:14,720
course or we'll read in this course.

121
00:08:15,020 --> 00:08:19,520
People will still be reading
roles long after, um,

122
00:08:20,150 --> 00:08:24,800
uh, people like me have been
forgotten about. So, um,

123
00:08:25,030 --> 00:08:29,210
in that sense it's a really
important figure and uh,

124
00:08:29,211 --> 00:08:32,030
he's a really important figure,
um,

125
00:08:32,300 --> 00:08:35,720
also in the sense that even if
you don't like his arguments,

126
00:08:36,320 --> 00:08:40,250
even if you've completely
unpersuaded by all of his arguments,

127
00:08:40,490 --> 00:08:44,150
you have to come to grips
with them. Uh, I don't,

128
00:08:44,240 --> 00:08:48,440
I'm not in sympathy with any
of his major arguments. Um,

129
00:08:48,470 --> 00:08:53,330
but he's, he's not, you cannot work in
this field and not deal with John Rolls.

130
00:08:53,331 --> 00:08:57,750
That's how important he is and
he's going to be for a long time.

131
00:08:58,650 --> 00:09:02,100
So that's just by way of background,
um,

132
00:09:02,160 --> 00:09:04,980
and letting you know
what you're dealing with.

133
00:09:05,280 --> 00:09:10,280
One other thing I'd say about a theory
of justice is it is not a well written

134
00:09:11,041 --> 00:09:16,010
book. It's not badly written
in the sense that it's unclear.

135
00:09:16,340 --> 00:09:18,950
Any given paragraph is clear enough.

136
00:09:19,250 --> 00:09:22,430
If you sit down and figure
out what the jargon means,

137
00:09:22,850 --> 00:09:25,310
it's not a hard and
that in the sense that,

138
00:09:25,510 --> 00:09:27,890
um,
uh,

139
00:09:29,170 --> 00:09:33,580
say the technical sides of,
of, of marks or parade or hard,

140
00:09:34,360 --> 00:09:36,550
but it's not captivating writing.

141
00:09:36,790 --> 00:09:41,620
You need a chair with a hard back to
read this book and there's a reason for

142
00:09:41,621 --> 00:09:46,570
that. The reason is that although
the book was published in 1971,

143
00:09:47,100 --> 00:09:47,933
mmm,

144
00:09:48,620 --> 00:09:53,620
roles actually came up with the main
ideas in the 1960s in a couple of articles

145
00:09:54,131 --> 00:09:57,230
and most famous of which was
called justices fairness.

146
00:09:57,740 --> 00:10:01,100
And he circulated these
articles in the profession,

147
00:10:01,101 --> 00:10:06,020
in the philosophy profession and he kept
getting criticisms and he eventually

148
00:10:06,021 --> 00:10:10,160
had a book manuscript and he circulated
the book manuscript and he kept getting

149
00:10:10,161 --> 00:10:13,760
criticisms and every time
somebody sent him a criticism,

150
00:10:13,940 --> 00:10:17,060
he added three paragraphs
to address the criticism.

151
00:10:17,660 --> 00:10:21,680
This is not the way to write a book
if you want it to be captivating.

152
00:10:21,681 --> 00:10:26,681
So it's got this kind of almost plodding
quality that's a sort of at variance

153
00:10:27,621 --> 00:10:30,980
with the, the hype I just
gave you about his importance,

154
00:10:31,310 --> 00:10:36,170
but it's to do with the composition
of the book. Uh, I mean the actual,

155
00:10:36,171 --> 00:10:40,430
oh, there's 10 years of endlessly
fiddling with this manuscript.

156
00:10:40,980 --> 00:10:44,590
Uh,
and I should should also say that he,

157
00:10:44,670 --> 00:10:49,670
he eventually did a second edition
of the book later in his life.

158
00:10:50,320 --> 00:10:51,153
MMM.

159
00:10:52,560 --> 00:10:56,730
Which is a substantial rewrite of
it from the first edition. So he,

160
00:10:56,910 --> 00:11:01,430
he was somebody who couldn't, who
couldn't stop fiddly. Um, and it's not a,

161
00:11:01,450 --> 00:11:05,130
it's not a trait to which I would,
I would commend to you,

162
00:11:05,640 --> 00:11:08,250
but in any event, there
it is. So, and it's,

163
00:11:08,460 --> 00:11:11,430
it's any long and if not plotting,

164
00:11:11,431 --> 00:11:16,050
certainly ponderous a buck.
And My, my goal in the,

165
00:11:16,060 --> 00:11:21,060
in these lectures about roles is to try
and pull out the main ideas for you.

166
00:11:21,361 --> 00:11:25,770
And in particularly the main
enduring ideas, because Raul's,

167
00:11:25,771 --> 00:11:29,310
like everybody else,
we've read as an architect,

168
00:11:29,311 --> 00:11:33,450
tonic theorist fails. The,
the pieces don't add up there.

169
00:11:33,451 --> 00:11:36,930
Big logical holes in the big structure.
Um,

170
00:11:36,931 --> 00:11:40,020
so if you want it to be the
silver bullet or the final word,

171
00:11:40,021 --> 00:11:42,960
it's not going to happen.
Nonetheless,

172
00:11:43,170 --> 00:11:47,820
there are very important in
during insights, uh, questions,

173
00:11:47,821 --> 00:11:50,940
roles put on the table,
which have not gone away.

174
00:11:50,941 --> 00:11:55,240
And I'm not going to go away for
anybody who wants to think about the

175
00:11:55,241 --> 00:12:00,190
fundamentals of political association.
So,

176
00:12:00,220 --> 00:12:01,053
um,

177
00:12:02,240 --> 00:12:02,500
okay,

178
00:12:02,500 --> 00:12:06,790
what are these ideas?
Well, they, they get,

179
00:12:07,450 --> 00:12:12,450
I think Mick stop to some extent or hidden
or obscured or it's made to seem more

180
00:12:13,211 --> 00:12:14,920
complicated than they should be,

181
00:12:15,280 --> 00:12:18,250
partly because of the
architecture of his theory,

182
00:12:18,940 --> 00:12:22,810
partly because of the way
he does the exposition.

183
00:12:23,590 --> 00:12:26,530
He has the story about
the original position,

184
00:12:26,680 --> 00:12:31,420
which is his version of the social con,
the hypothetical social contract.

185
00:12:31,780 --> 00:12:34,060
And,
and let me just give you the intuition,

186
00:12:34,660 --> 00:12:39,370
but I want to preface it by saying it's
actually not important to his theory.

187
00:12:39,610 --> 00:12:44,610
It's really an expository device
because what he does is he structures a

188
00:12:46,961 --> 00:12:51,961
hypothetical choice and then he gives
you a certain kinds of information to get

189
00:12:52,541 --> 00:12:54,400
you to choose a certain outcome.

190
00:12:56,150 --> 00:13:00,920
So unless the outcome is
itself independently desirable,

191
00:13:01,400 --> 00:13:04,070
um,
the fact that this,

192
00:13:04,130 --> 00:13:07,760
this thought experiment leads
to it is of no interest.

193
00:13:07,761 --> 00:13:10,730
Let me give you an example
before we get into roles,

194
00:13:10,731 --> 00:13:15,290
which is one that he himself Gibbs,
and this is the,

195
00:13:15,350 --> 00:13:18,860
I'm not sure if it seemed one of the
excerpts you read or not, but this is a,

196
00:13:19,190 --> 00:13:23,210
an observation that has been
around long before royal. She says,

197
00:13:23,480 --> 00:13:27,320
what is the fair way to cut a
cake? Is this, you read anybody?

198
00:13:27,470 --> 00:13:29,090
What's a fair way to cut a cake?

199
00:13:29,290 --> 00:13:30,123
Yeah,

200
00:13:31,370 --> 00:13:32,600
probably not if nobody,

201
00:13:32,960 --> 00:13:36,590
I'm sure you spent your spring
break wading through roles. Yeah,

202
00:13:42,150 --> 00:13:43,520
correct.
So you give the,

203
00:13:43,770 --> 00:13:48,690
the person with a knife gets the
last slice and what will they do?

204
00:13:53,130 --> 00:13:53,870
Okay.

205
00:13:53,870 --> 00:13:56,570
So if you say, well, how
would they divide it?

206
00:13:59,300 --> 00:14:04,130
Yeah. If you think so. So what are
the, are two assumptions there?

207
00:14:04,131 --> 00:14:07,820
Okay. You say, what's the fair
way to cut a cake? The answer,

208
00:14:07,821 --> 00:14:10,470
the fair way to cut a cake is to give the,
the,

209
00:14:10,730 --> 00:14:14,750
the person with the knife gets
the last slice. What will they do?

210
00:14:15,080 --> 00:14:19,010
They will divide it equally. Right?
That's how the person or the last,

211
00:14:19,370 --> 00:14:22,610
the knife gets a biggest possible slice.
Right?

212
00:14:24,290 --> 00:14:25,280
Right.
Yeah.

213
00:14:26,090 --> 00:14:26,923
Okay.

214
00:14:27,220 --> 00:14:30,630
Anyone think that's not the fair
way to cut a cake? Do it anyway.

215
00:14:35,170 --> 00:14:38,710
Okay. Well there are two assumptions
there that are worth bringing to the fore.

216
00:14:38,711 --> 00:14:42,360
Just just for, um, pup.

217
00:14:42,510 --> 00:14:44,890
Is that what I'm going to say
to you about roles in a minute?

218
00:14:45,310 --> 00:14:50,310
One is that we think dividing
the cake equally is the right

219
00:14:52,010 --> 00:14:53,390
is, you know, we, we're,

220
00:14:53,600 --> 00:14:57,080
we've devised a system where the
case can you get equally divided,

221
00:14:58,370 --> 00:15:03,180
right? But do it, do we think it should
be equally divided? What if we, it,

222
00:15:03,560 --> 00:15:07,310
what if I added other
information? Like, uh,

223
00:15:07,610 --> 00:15:12,610
one of the people in the room was starving
and hadn't eaten for three days or

224
00:15:14,361 --> 00:15:16,760
one was a diabetic or,
right.

225
00:15:16,880 --> 00:15:20,990
And we could add other information which
would make you one to do you want to

226
00:15:20,991 --> 00:15:23,330
get an equal division?
Right?

227
00:15:23,570 --> 00:15:28,100
So the cake cutting example doesn't
show you that equality is a good thing.

228
00:15:28,101 --> 00:15:33,101
It presumes that you've already decided
equality is a good thing and you want to

229
00:15:33,381 --> 00:15:36,800
get the person to choose equality.
Right.

230
00:15:38,740 --> 00:15:39,573
Okay.

231
00:15:39,700 --> 00:15:41,470
Then the other thing that it,
it is,

232
00:15:41,530 --> 00:15:46,390
it assumes is that people are gonna
behave self interestedly, right? When we,

233
00:15:46,420 --> 00:15:50,110
when we give the person the knife
and say divided however you like,

234
00:15:50,320 --> 00:15:51,850
you get the last slice,

235
00:15:52,270 --> 00:15:55,780
we're assuming that she or he will behave,

236
00:15:55,781 --> 00:16:00,110
be wanting to get the biggest
possible slice. So we've uh,

237
00:16:00,130 --> 00:16:04,900
immediately we've got two assumptions
built into their one that equality is a

238
00:16:04,901 --> 00:16:08,440
good thing. That's the result
we actually do want to get.

239
00:16:09,190 --> 00:16:13,090
And secondly that people are going
to behave in a self interested way,

240
00:16:13,900 --> 00:16:17,050
right? Which isn't to say
they're bad assumptions,

241
00:16:17,051 --> 00:16:21,130
but it's to note that they
are assumptions. Okay.

242
00:16:22,540 --> 00:16:27,090
Now rolls as original position
has the same structures,

243
00:16:27,100 --> 00:16:30,130
the cake cutting fee for
both of those reasons.

244
00:16:30,670 --> 00:16:35,670
He has a distributed outcome
that he wants to convince you is,

245
00:16:36,700 --> 00:16:40,210
is a good thing and
he's going to create a,

246
00:16:40,240 --> 00:16:45,240
a hypothetical choice situation
that will lead you to it,

247
00:16:47,050 --> 00:16:47,381
right?

248
00:16:47,381 --> 00:16:52,240
But that doesn't itself establish
that it is a good thing.

249
00:16:52,241 --> 00:16:55,300
You have to have some other argument to
convince you that it is a good thing.

250
00:16:55,840 --> 00:16:57,310
And I'll tell you what that argument is,

251
00:16:57,311 --> 00:17:02,110
but it's completely independent of this
expository expository device that's

252
00:17:02,111 --> 00:17:03,400
modeled on the cake cutting.

253
00:17:03,970 --> 00:17:08,170
So the expository device that's model
on the cake cutting goes like this.

254
00:17:08,560 --> 00:17:11,530
It says,
imagine,

255
00:17:13,340 --> 00:17:17,540
imagine you had to design a social order,
a society

256
00:17:19,190 --> 00:17:22,220
and it co which include in
a broader sense of the word,

257
00:17:22,221 --> 00:17:26,150
it will include an economic system,
a political system and so on.

258
00:17:27,630 --> 00:17:28,463
Okay.

259
00:17:28,540 --> 00:17:30,100
And you didn't know

260
00:17:32,960 --> 00:17:37,910
whether you were going to turn out
to be ritual poor male or female,

261
00:17:38,870 --> 00:17:43,460
what you are going to be, whether
you're going to be an athlete or a nerd.

262
00:17:44,360 --> 00:17:49,160
Um, you didn't have any particular
information about yourself.

263
00:17:49,350 --> 00:17:52,980
Do you watch your, where are you
going to have an Iq or low Iq musical?

264
00:17:52,981 --> 00:17:56,250
Not Musical. I had good
athlete, a bad athlete, nothing.

265
00:17:56,790 --> 00:18:00,090
You didn't have that kind of
information about yourself.

266
00:18:02,030 --> 00:18:02,580
Yeah.

267
00:18:02,580 --> 00:18:04,340
Which doesn't mean that there,

268
00:18:04,440 --> 00:18:08,160
there could be people who didn't
have those characteristics, right?

269
00:18:08,360 --> 00:18:13,360
It's just like say you have to design
the rules of chess and you didn't know

270
00:18:13,711 --> 00:18:16,890
whether or not you're going to be good
at using bishop better using our bishop.

271
00:18:16,891 --> 00:18:21,660
Then, but then using a night, but
yet to agree on certain rules. Okay.

272
00:18:21,661 --> 00:18:24,570
So the rules for designing society,

273
00:18:25,380 --> 00:18:30,380
you're going to choose while being
ignorant of what he calls particular facts

274
00:18:32,910 --> 00:18:34,470
about your circumstances.

275
00:18:34,471 --> 00:18:38,190
You're gonna know only
certain pretty general things.

276
00:18:38,820 --> 00:18:42,900
Like he says,
it's a world of moderate scarcity.

277
00:18:42,901 --> 00:18:46,140
So it,
it's not super abundance,

278
00:18:46,141 --> 00:18:49,950
which is a good thing cause we found
out when we studied Marx that there's no

279
00:18:49,951 --> 00:18:53,370
coherent idea of super
abundant, moderate scas. The,

280
00:18:53,371 --> 00:18:56,910
it's not very,
it's not a developing country.

281
00:18:57,810 --> 00:19:01,110
What we think of today. Is it the
third world or developing country?

282
00:19:01,440 --> 00:19:04,920
It's basically principals for
countries of the sort we live in.

283
00:19:06,300 --> 00:19:08,250
Okay. So, um,

284
00:19:09,360 --> 00:19:14,360
moderate scarcity and we're gonna assume
certain basic when he calls laws of

285
00:19:16,771 --> 00:19:18,510
psychology and economics.

286
00:19:18,870 --> 00:19:23,370
And I think that people largely behave
self interestedly is the most important

287
00:19:23,371 --> 00:19:27,030
of those. Um, but beyond that,

288
00:19:27,031 --> 00:19:29,940
you're not going to have particular
knowledge about yourself and your

289
00:19:29,941 --> 00:19:32,220
circumstances in particular,

290
00:19:32,970 --> 00:19:37,620
sorry to use particular into conflicting
ways. But in Perth in particular,

291
00:19:37,950 --> 00:19:41,730
you're not going to have the kind of
knowledge that would allow you to buy us

292
00:19:41,731 --> 00:19:46,350
things in your own direction so that if
you knew you were going to turn out to

293
00:19:46,351 --> 00:19:49,560
be female, you could, you know,

294
00:19:49,561 --> 00:19:52,020
say women should earn
twice as much as men,

295
00:19:52,050 --> 00:19:55,410
but you're not going to know whether
you're going to turn out to be female or

296
00:19:55,411 --> 00:19:56,160
male.

297
00:19:56,160 --> 00:20:00,570
So the kind of knowledge you're going to
be denied is the kind of knowledge that

298
00:20:00,571 --> 00:20:04,920
would let you buy us
things in your own favor.

299
00:20:06,030 --> 00:20:06,361
Okay.

300
00:20:06,361 --> 00:20:11,361
So that's the sense in which
he's trying to be a contrarian.

301
00:20:14,130 --> 00:20:19,130
He calls his principles procedural
expressions of the categorical imperative.

302
00:20:20,700 --> 00:20:24,660
There's a mouthful for you on the
first day back from spring break.

303
00:20:25,590 --> 00:20:30,510
We know what the categorical
imperative is, right? It's, it's, um,

304
00:20:32,950 --> 00:20:37,950
it's the imperative to choose things that
are universalize about things that you

305
00:20:39,731 --> 00:20:44,590
would, well, regardless of the
consequences. So thanks. You would,

306
00:20:44,591 --> 00:20:49,570
well, from every conceivable standpoint
and what roles is trying to do,

307
00:20:49,571 --> 00:20:53,530
I says these a procedural expression
of it. What he's trying to do is say,

308
00:20:53,770 --> 00:20:57,790
well,
if you don't have knowledge of where,

309
00:20:57,820 --> 00:21:01,750
which kind of person you're going to
turn out to be in terms of rich or poor

310
00:21:01,751 --> 00:21:06,751
male or female or black or white or
Hispanic or some other ethnic group or a

311
00:21:07,930 --> 00:21:12,100
religious of some sort, or as atheist,
you don't know any of those things.

312
00:21:12,820 --> 00:21:16,630
You're going to have to think
about what are the social,

313
00:21:16,660 --> 00:21:21,660
what are the best social rules for people
regardless of who they turn out to be.

314
00:21:23,770 --> 00:21:28,180
And that's the sense in which he wants
to think of himself as a content.

315
00:21:28,810 --> 00:21:32,660
So where's for nosy could sort
of just a slogan for Rawls.

316
00:21:32,710 --> 00:21:35,380
It's really built into the
structure of his argument.

317
00:21:36,160 --> 00:21:36,993
Okay.

318
00:21:37,350 --> 00:21:42,350
And the idea of the original position
is to force us even while recognizing

319
00:21:43,261 --> 00:21:48,261
where self interested to force us
to think about society as a whole,

320
00:21:50,160 --> 00:21:51,720
to think about what,
what,

321
00:21:51,750 --> 00:21:56,730
what would be desirable regardless
of who you turned out to be.

322
00:21:58,130 --> 00:21:58,780
Okay.

323
00:21:58,780 --> 00:22:01,240
And so then his eye,
the basic way, the book,

324
00:22:01,270 --> 00:22:03,550
if you had time to read the whole book,

325
00:22:03,940 --> 00:22:08,940
the Basic Way the book proceeds is he
starts out with this complete veil of

326
00:22:09,911 --> 00:22:14,890
ignorance and tries to get
to get you to agree with him

327
00:22:16,700 --> 00:22:21,090
and this sense, it's not even really a
social contract. He's, he's not saying,

328
00:22:21,330 --> 00:22:24,900
you know, would you agree with one
another? What he wants to say is,

329
00:22:25,590 --> 00:22:29,250
will you the reader agree with me,
John Rawls,

330
00:22:29,430 --> 00:22:34,430
that any rational church and would choose
the principles that I'm arguing for.

331
00:22:37,310 --> 00:22:38,930
In that sense,
he's actually,

332
00:22:39,690 --> 00:22:39,910
yeah,

333
00:22:39,910 --> 00:22:42,670
we can't do it in this course
because we did an read Hobbs.

334
00:22:42,970 --> 00:22:44,590
He's actually more like Hobbes.

335
00:22:44,591 --> 00:22:48,190
Then he is like lock because you know,

336
00:22:48,191 --> 00:22:53,191
for hubs the social contract isn't a
legitimate because anybody made it,

337
00:22:55,241 --> 00:22:58,420
but because it must be
rational to make it,

338
00:22:59,720 --> 00:23:04,720
any rational person says Hobbs would
agree to give up their freedom to an

339
00:23:05,421 --> 00:23:10,310
absolute sovereign because anything else
needs to civil war in is just madness.

340
00:23:10,580 --> 00:23:12,250
So it's,
it's an,

341
00:23:12,280 --> 00:23:16,190
it's a property of rationality
for Hobbs that people were,

342
00:23:16,220 --> 00:23:20,900
we'll accept the authority
of the sovereign. There isn't
really a contract. Well,

343
00:23:20,901 --> 00:23:24,920
Rawls is more like hubs on
that point. He's, he's saying,

344
00:23:25,190 --> 00:23:28,100
I want to pee.
I John Rawls want to persuade you,

345
00:23:28,101 --> 00:23:33,101
the reader that any rational person would
choose my principles of justice over

346
00:23:35,241 --> 00:23:39,200
the going alternatives
because his style of thinking,

347
00:23:39,780 --> 00:23:40,150
okay,

348
00:23:40,150 --> 00:23:45,150
people go on and on about roles being
abstract and an ideal theorist and head in

349
00:23:45,201 --> 00:23:49,730
the clouds. But actually his actual way
of proceeding is, isn't that it's very,

350
00:23:49,760 --> 00:23:53,900
it's comparative.
Basically what he does is he says,

351
00:23:53,901 --> 00:23:58,220
well, what are the going
alternatives? There's utilitarianism.

352
00:23:58,560 --> 00:24:01,970
There's, there are other ones
you haven't read in the score.

353
00:24:01,971 --> 00:24:06,140
So it's this perfectionism,
which is what he thinks of in Aristotle.

354
00:24:06,380 --> 00:24:08,600
There's Marxism.
Um,

355
00:24:09,140 --> 00:24:13,460
I want to show you that my principal
does better than the going alternatives

356
00:24:13,700 --> 00:24:18,110
from the perspective of being
behind this veil of ignorance.

357
00:24:18,410 --> 00:24:22,850
If somebody else comes along with another
principal and shows that it does even

358
00:24:22,851 --> 00:24:24,680
better than mine,
then I would give it up.

359
00:24:24,710 --> 00:24:28,010
So his basic mode of
reasoning is comparative.

360
00:24:28,870 --> 00:24:32,680
Okay.
And

361
00:24:34,210 --> 00:24:38,770
what, so what he does is he as
a general principle of justice,

362
00:24:39,910 --> 00:24:44,910
which he wants to persuade you off first
from behind this veil of ignorance and

363
00:24:45,251 --> 00:24:49,090
then more specific applications of it.
Um,

364
00:24:49,870 --> 00:24:54,790
he ends up coming up with two principles
of justice that are the applications,

365
00:24:54,791 --> 00:24:58,270
which are really three principles.
So I'll go through them with you,

366
00:24:59,440 --> 00:25:02,770
but then more if you win more
and more into the book he gets,

367
00:25:03,070 --> 00:25:08,070
he keeps adding information and lets you
design more specific institutions and

368
00:25:09,371 --> 00:25:13,960
so on. Always with the caveat that
as you get more information later,

369
00:25:14,050 --> 00:25:18,430
you can't go back and undo
choices that you made earlier.

370
00:25:19,330 --> 00:25:21,940
Right.
So it's sort of like,

371
00:25:22,000 --> 00:25:27,000
I don't know if you've been around long
enough to ever see Congress go through a

372
00:25:27,701 --> 00:25:31,780
base closing exercise for the military,
um,

373
00:25:32,140 --> 00:25:32,860
where they,

374
00:25:32,860 --> 00:25:37,150
they realize that there's going to be
special pleading from every can, you know,

375
00:25:37,151 --> 00:25:41,770
say say they're going to get
rid of 30 military basis. Um,

376
00:25:41,800 --> 00:25:46,630
every congressional district that has a
base in it is going to have good reasons

377
00:25:46,631 --> 00:25:49,840
why yes,
we should get rid of 30 basis,

378
00:25:49,841 --> 00:25:52,720
but not the one in our district.
Right.

379
00:25:53,110 --> 00:25:56,230
We Know wanna stop making
submarines in Groton,

380
00:25:58,790 --> 00:26:03,120
right? Whatever it is. And so
what they do is they get an, they,

381
00:26:03,150 --> 00:26:06,650
they get, they create a commission, um,

382
00:26:07,160 --> 00:26:12,160
that agrees on the base closing nationwide
and they have to vote up or down on

383
00:26:12,501 --> 00:26:17,501
the entire package and then they can start
undoing it later so that the just has

384
00:26:19,371 --> 00:26:24,200
a kind of structure of a base closing
commission that as the veil of ignorance

385
00:26:24,201 --> 00:26:28,190
starts to be lifted, you know,
and then you discover, well,

386
00:26:28,191 --> 00:26:31,280
actually I turned out to
be female rather than male.

387
00:26:31,550 --> 00:26:33,470
I can't then say,
oh,

388
00:26:33,471 --> 00:26:38,170
well women should get some
certain particular kind of
advantage. Right. So that,

389
00:26:38,171 --> 00:26:42,830
that's the way the book proceeds.
Now.

390
00:26:42,900 --> 00:26:45,120
Um,
I think

391
00:26:46,890 --> 00:26:51,390
one other reason I should tell you about,

392
00:26:52,270 --> 00:26:52,440
oh,

393
00:26:52,440 --> 00:26:57,090
actually two reasons I should tell you
about concerning why this book had such a

394
00:26:57,091 --> 00:26:57,960
big impact,

395
00:26:58,410 --> 00:27:02,910
why this book has had the
staying power that it's had.

396
00:27:03,240 --> 00:27:03,721
One is,

397
00:27:03,721 --> 00:27:08,721
it's really very much a book of the
1960s and seventies where there was just

398
00:27:09,300 --> 00:27:10,051
some extent,

399
00:27:10,051 --> 00:27:15,051
a crisis of confidence about liberal
democratic institutions born of the

400
00:27:15,871 --> 00:27:17,360
student's movement and this,

401
00:27:17,400 --> 00:27:21,240
the Vietnam War and
everything that went with it.

402
00:27:21,600 --> 00:27:23,550
That is to say,
uh,

403
00:27:23,730 --> 00:27:27,600
there was a generation of people who
thought we needed to have critical

404
00:27:27,601 --> 00:27:31,770
standards for evaluating
government and utilitarianism,

405
00:27:31,860 --> 00:27:36,270
which was the main alternative around,
didn't seem to provide them.

406
00:27:36,840 --> 00:27:41,430
And roles came up with this notion that
we could come up with an independent

407
00:27:41,431 --> 00:27:44,970
standard for judging

408
00:27:46,780 --> 00:27:51,780
actually existing political systems and
then use it to see how they measure up.

409
00:27:53,290 --> 00:27:57,640
I wouldn't have to be rooted in natural
law and all the problems that went with

410
00:27:57,641 --> 00:28:02,200
it and was going to be rooted
in this universal content ideal.

411
00:28:02,650 --> 00:28:07,650
And it would give us a principles by
which we could evaluate not only what our

412
00:28:08,471 --> 00:28:10,660
government does,
but other governments.

413
00:28:10,661 --> 00:28:15,661
So I think it was just some extent kind
of thirst for criteria that that was

414
00:28:18,341 --> 00:28:22,030
characteristic of that era that,
um,

415
00:28:22,660 --> 00:28:27,040
gave rolls his staying power.
But then I think the other reason,

416
00:28:28,090 --> 00:28:29,290
the other reason

417
00:28:31,000 --> 00:28:34,900
that Rawls has had
staying power was that he

418
00:28:36,430 --> 00:28:41,430
change the subject that people who had
been squabbling about utilitarianism for

419
00:28:43,421 --> 00:28:48,100
150 years had been arguing about
because, and again, this is,

420
00:28:48,130 --> 00:28:52,300
you know, this now because of
the first half of this semester,

421
00:28:53,200 --> 00:28:56,200
but utilitarianism had basically been

422
00:28:57,580 --> 00:28:58,413
mmm.

423
00:29:00,390 --> 00:29:02,580
Struggling between two variants.

424
00:29:03,150 --> 00:29:06,990
One which we think often the
terminology of this course as classical

425
00:29:06,991 --> 00:29:10,680
utilitarianism we might call objectivist,

426
00:29:11,010 --> 00:29:14,490
where you make strong
interpersonal judgments of utility.

427
00:29:15,150 --> 00:29:17,360
And the problem with that as we saw is,

428
00:29:17,520 --> 00:29:20,160
and as Raul says repeatedly in his book,

429
00:29:20,640 --> 00:29:24,360
it doesn't take seriously the
differences among persons.

430
00:29:24,810 --> 00:29:28,920
You could see this in the
utility monster example.

431
00:29:28,950 --> 00:29:31,830
You could see this in the,
um,

432
00:29:32,160 --> 00:29:35,700
the problems that we have with
the bag lady and Donald Trump.

433
00:29:35,880 --> 00:29:39,000
You can see this in problems
with the disabled that,

434
00:29:39,440 --> 00:29:42,850
that if you don't allow
interpersonal, I, I'm sorry,

435
00:29:42,851 --> 00:29:45,790
if you do allow interpersonal
judgments of utility,

436
00:29:46,090 --> 00:29:51,090
you can do draconian things in
the name of maximizing utility.

437
00:29:51,610 --> 00:29:54,670
But if you, if you say, no,
we're not going to do that,

438
00:29:54,671 --> 00:29:59,671
and you make the neoclassical move and
use then say we cannot even allow that.

439
00:30:00,371 --> 00:30:05,371
Taking a nickel from Trump and giving it
to the bag lady necessarily leads to an

440
00:30:05,590 --> 00:30:07,870
increase in social utility,

441
00:30:08,650 --> 00:30:11,170
then you seem to have the
opposite problem. So the,

442
00:30:11,590 --> 00:30:16,350
the objectivist problem is it allows,
uh,

443
00:30:16,810 --> 00:30:19,990
people to be used in the
name of maximizing utility.

444
00:30:20,350 --> 00:30:22,660
The subjectivist version,

445
00:30:23,620 --> 00:30:28,620
the neoclassical version doesn't seem
to allow any interpersonal judgments of

446
00:30:29,141 --> 00:30:33,760
utility, both a deeply
morally unsatisfying. And so,

447
00:30:33,850 --> 00:30:38,850
and the proponents of each one 10
to make the case for their view,

448
00:30:40,180 --> 00:30:44,560
mainly by pointing to the
demerits of the other view. Right?

449
00:30:44,561 --> 00:30:48,610
And they're both right.
Both of these views have serious demerits.

450
00:30:49,420 --> 00:30:52,900
And so part of what roles does
is he changes the subject.

451
00:30:54,040 --> 00:30:58,600
He changes the subject,
and he changes it in an interesting way.

452
00:30:59,890 --> 00:31:01,060
He says,
luck.

453
00:31:02,750 --> 00:31:03,580
Okay.

454
00:31:03,580 --> 00:31:08,580
The truth is we should be objectivist
about some things and subjectivist about

455
00:31:09,431 --> 00:31:13,750
other things. And what does he
mean by this? He says, luck.

456
00:31:15,450 --> 00:31:15,800
Okay.

457
00:31:15,800 --> 00:31:20,800
People are substantially alike about
on some dimensions and unalike on other

458
00:31:21,141 --> 00:31:24,680
dimensions. There's deep
pluralism of values. Yes,

459
00:31:25,280 --> 00:31:29,780
but you know we basically have the same
needs, the same physiology, the same.

460
00:31:30,110 --> 00:31:34,520
We tend, we tend to need
the same kinds of resources.

461
00:31:35,270 --> 00:31:40,270
So let's focus on resources
rather than on utility.

462
00:31:41,690 --> 00:31:46,690
Let's focus on some basic resources that
everybody needs regardless of whether

463
00:31:48,081 --> 00:31:53,081
they're going to be intellectuals or
artists or sportsman or sportswomen or

464
00:31:54,500 --> 00:31:56,450
politicians.
There's still,

465
00:31:56,510 --> 00:32:00,590
there's certain things you're going
to need more of rather than less off.

466
00:32:00,620 --> 00:32:04,130
Other things being equal
sort of instrumental goods.

467
00:32:04,160 --> 00:32:08,000
You could think of them as
well and let's focus on that.

468
00:32:08,300 --> 00:32:10,610
And especially in political.

469
00:32:11,430 --> 00:32:12,263
Yeah,

470
00:32:12,430 --> 00:32:13,540
political theory.

471
00:32:13,870 --> 00:32:17,920
Those are a good thing to focus on
because after all we're talking about what

472
00:32:17,921 --> 00:32:22,690
the state might know might not
do and the state, as we all know,

473
00:32:23,290 --> 00:32:25,300
you know,
acts with blunt instruments.

474
00:32:25,301 --> 00:32:29,290
This idea of the government sort of
putting a utility amateur and the people's

475
00:32:29,291 --> 00:32:33,680
tongues to find out what their utility is.
That's not it.

476
00:32:34,740 --> 00:32:38,680
It's, it's apart from being
technically problematic.

477
00:32:38,681 --> 00:32:42,650
It's know nobody wants that.
It's morally undesirable.

478
00:32:42,920 --> 00:32:47,270
So you have to think about just the
state as something that action with blunt

479
00:32:47,300 --> 00:32:50,180
instruments.
And you can only really,

480
00:32:50,750 --> 00:32:53,840
if you want to a realistic
political theory,

481
00:32:54,050 --> 00:32:59,050
you should focus on some basic resources
in the society that the state could

482
00:33:00,111 --> 00:33:01,280
have some impact on.

483
00:33:02,270 --> 00:33:07,270
So instead of various
competing definitions of
utility or welfare role says

484
00:33:08,061 --> 00:33:11,600
let's change the subject
to talking about resources,

485
00:33:13,130 --> 00:33:14,450
um, that, uh,

486
00:33:14,930 --> 00:33:19,930
have the quality a that the things
that we could really imagine the state

487
00:33:20,001 --> 00:33:25,001
dealing with and be that an instrumentally
valuable to people no matter what

488
00:33:25,341 --> 00:33:28,100
they turn out to one in life.
So that,

489
00:33:28,101 --> 00:33:33,050
that's a second reason he was
important. He, she, of course,

490
00:33:33,830 --> 00:33:37,520
academics are not comfortable
unless they create an ism word.

491
00:33:37,790 --> 00:33:41,610
So the ism word is resources and roles.
I should,

492
00:33:41,611 --> 00:33:46,611
as in resources and it stops talking about
welfarism stops talking about utility

493
00:33:48,951 --> 00:33:53,480
or welfare or the subjective
experiences that people get,

494
00:33:54,000 --> 00:33:57,920
um, but rather the resources
that they have at their disposal.

495
00:33:58,670 --> 00:34:03,350
So that's a second reason I think he's
had his views have had a lot of staying

496
00:34:03,351 --> 00:34:03,770
power.

497
00:34:03,770 --> 00:34:08,660
People who don't like his particular
resources theory have nonetheless embraced

498
00:34:08,720 --> 00:34:11,930
other resources. Theories. Again,

499
00:34:11,931 --> 00:34:16,280
sort of in the wake of
roles, if you like. Okay,

500
00:34:16,281 --> 00:34:20,690
so what is the basic idea?
What is the basic principle?

501
00:34:22,020 --> 00:34:22,510
Okay,

502
00:34:22,510 --> 00:34:25,960
it's,
it's his general conception of justice,

503
00:34:25,961 --> 00:34:30,490
which he says all social values
by which he means resources.

504
00:34:30,491 --> 00:34:33,850
As I've just said it to you now,

505
00:34:34,510 --> 00:34:37,060
and it's going to say that they're three

506
00:34:39,290 --> 00:34:43,530
while he is,
he talks about liberty's opportunities,

507
00:34:43,950 --> 00:34:48,270
income and wealth, which he
treats together. So that's three,

508
00:34:48,570 --> 00:34:52,050
and then a fourth one.
The social bases of self respect.

509
00:34:52,770 --> 00:34:54,270
I'll come back to all of that in minute.

510
00:34:54,750 --> 00:34:59,750
I'd have been distributed equally unless
an unequal distribution or any of any

511
00:34:59,941 --> 00:35:03,630
of all of these values is
to everybody's advantage.

512
00:35:04,140 --> 00:35:05,820
That is the basic idea.

513
00:35:06,450 --> 00:35:11,450
All social values by which he means
resources should be distributed equally

514
00:35:13,530 --> 00:35:18,300
unless an unequal distribution
benefits everyone.

515
00:35:18,630 --> 00:35:23,340
That is the first and most general
formulation of his principal.

516
00:35:25,460 --> 00:35:29,240
So let me just back up a little bit.

517
00:35:30,860 --> 00:35:31,540
Okay.

518
00:35:31,540 --> 00:35:36,310
I'll go through liberties, opportunities,
income, and wealth in more detail.

519
00:35:36,780 --> 00:35:39,690
Starting in a minute,
I'm just gonna mention this.

520
00:35:39,691 --> 00:35:44,691
Social bases for self-respect briefly and
then not talk about it anymore because

521
00:35:45,301 --> 00:35:46,770
of time limitations.

522
00:35:46,771 --> 00:35:51,480
And because rolls himself never
says anything much about them.

523
00:35:51,650 --> 00:35:52,483
Uh,

524
00:35:53,880 --> 00:35:54,700
yeah.

525
00:35:54,700 --> 00:35:57,400
And what he has to say.
I don't think it's very coherent.

526
00:35:57,401 --> 00:36:01,900
So we'll just forget about the
social bases of self respect, um,

527
00:36:01,930 --> 00:36:04,870
for the moment.
Maybe come back to them later.

528
00:36:05,560 --> 00:36:10,550
But so here's the thing ought to be
distributed equally unless an unequal

529
00:36:10,630 --> 00:36:13,930
distribution works to
everybody's advantage.

530
00:36:17,000 --> 00:36:20,900
Now you might say why,
right?

531
00:36:20,970 --> 00:36:23,900
That's the first question,
right?

532
00:36:24,020 --> 00:36:28,010
It's the first question you ask and
roles is not going to give you a straight

533
00:36:28,011 --> 00:36:30,320
answer. He's not. There's not a, because

534
00:36:32,320 --> 00:36:36,940
for the reason I said to, Oh yeah, his
reasoning is comparative. So he says,

535
00:36:36,941 --> 00:36:41,020
well you could, you could say
this is one candidate principal,

536
00:36:41,230 --> 00:36:46,090
you bring another candidate principal,
like say utilitarianism.

537
00:36:46,300 --> 00:36:50,860
And we'll look at both from behind the
veil of ignorance and see which makes

538
00:36:50,861 --> 00:36:53,770
more sense to beck.
Okay.

539
00:36:53,890 --> 00:36:57,790
So that's the sense in which he has
a comparative advantage argument,

540
00:36:57,970 --> 00:36:59,350
not a knockdown,

541
00:37:00,040 --> 00:37:04,680
philosophical demonstration from first
principles that this must follow.

542
00:37:05,830 --> 00:37:06,281
So,

543
00:37:06,281 --> 00:37:10,600
while I do want to say that he thinks it
follows from the nature of reason that

544
00:37:10,601 --> 00:37:11,920
you would make this choice,

545
00:37:12,250 --> 00:37:16,360
it's only a comparative
choice and somebody could
come along with something else

546
00:37:16,780 --> 00:37:18,130
and,
um,

547
00:37:20,960 --> 00:37:25,460
convince you that it does better than
his principal. And then he'd have to, uh,

548
00:37:25,510 --> 00:37:27,980
except that,
so,

549
00:37:35,410 --> 00:37:36,243
okay.

550
00:37:36,350 --> 00:37:40,730
What he does, and this is his
resources. I mean action is he,

551
00:37:40,790 --> 00:37:43,910
he defines these primary goods.

552
00:37:44,330 --> 00:37:48,620
Primary goods are these instrumental
goods, these things you would,

553
00:37:48,680 --> 00:37:53,060
other things being equal rather
have more of than less off.

554
00:37:54,290 --> 00:37:58,100
Uh, and the, the three we're
going to focus on our liberties,

555
00:37:58,880 --> 00:38:02,060
opportunities and income and wealth.

556
00:38:03,080 --> 00:38:07,460
And I'm gonna we'll probably only
manage to deal with liberty's today,

557
00:38:07,461 --> 00:38:10,250
but it'll give you a flavor
of how his reasoning works.

558
00:38:11,360 --> 00:38:16,130
So what our liberties,
well,

559
00:38:16,131 --> 00:38:20,030
that pretty much the sort of thing in
the bill of rights and the American bill

560
00:38:20,031 --> 00:38:24,710
of rights, freedom of speech, freedom
of religion, freedom of association.

561
00:38:25,510 --> 00:38:26,470
MMM.

562
00:38:29,150 --> 00:38:33,560
Freedom actually did participate in
democratic politics is one that he talks

563
00:38:33,561 --> 00:38:36,640
about. Um, and he's,

564
00:38:36,670 --> 00:38:40,810
his principle for the
distribution of liberties is,

565
00:38:40,870 --> 00:38:42,880
I just put it up there.
He says

566
00:38:47,200 --> 00:38:51,940
each person has to have an equal right
to the most extensive system of total

567
00:38:52,330 --> 00:38:55,840
extensive time. I told you
this ponderous, extensive,

568
00:38:55,841 --> 00:39:00,841
total system of liberties compatible
with a similar system of liberty for all.

569
00:39:02,540 --> 00:39:05,950
It sounds like a lot of words,
not saying very much.

570
00:39:06,280 --> 00:39:11,280
So let me show you why it says more than
it might appear to say at first sight.

571
00:39:14,110 --> 00:39:17,860
Let's take the example
of religious freedom.

572
00:39:21,160 --> 00:39:22,510
So

573
00:39:26,480 --> 00:39:27,313
okay,

574
00:39:27,850 --> 00:39:32,680
let's say, well, should we
have an established religion?

575
00:39:40,690 --> 00:39:44,440
How can we reason about this
from behind the valve ignorance?

576
00:39:44,800 --> 00:39:46,060
We'd are no

577
00:39:48,180 --> 00:39:50,490
once the veil of ignorance is left dead,

578
00:39:50,970 --> 00:39:55,380
why that we're going to be Christians
or Jews or Muslims or atheists or

579
00:39:55,381 --> 00:39:59,370
agnostics or something else, right?
We don't, we don't know that.

580
00:40:00,600 --> 00:40:01,433
Right?

581
00:40:02,070 --> 00:40:05,910
So how should we think about the question
of whether it should be an established

582
00:40:06,300 --> 00:40:07,133
religion?

583
00:40:10,010 --> 00:40:10,850
Well,

584
00:40:12,410 --> 00:40:15,250
and this is where his one of his,

585
00:40:15,290 --> 00:40:18,680
his conceptual innovations comes in.
He says,

586
00:40:19,730 --> 00:40:24,730
the way to think about it is from the
standpoint of the most adversely affected

587
00:40:27,470 --> 00:40:28,303
person.

588
00:40:31,170 --> 00:40:35,940
Cause you don't know who you're going
to be. Right? So for any principal,

589
00:40:36,450 --> 00:40:37,830
if, if you could say, well,

590
00:40:37,831 --> 00:40:42,831
if I was the most adversely affected
person by that principle and I would still

591
00:40:43,891 --> 00:40:44,724
choose it,

592
00:40:46,930 --> 00:40:51,930
then it starts to look like procedural
expression of the categorical imperative

593
00:40:53,080 --> 00:40:58,000
because if the person most disadvantaged
by it would choose it over the going

594
00:40:58,001 --> 00:41:02,200
alternatives, then presumably
everybody else would. Okay.

595
00:41:02,560 --> 00:41:03,393
And so,

596
00:41:03,530 --> 00:41:08,050
so this is a misunderstanding of
roles that people often get into.

597
00:41:08,560 --> 00:41:13,350
He says
at one point,

598
00:41:13,351 --> 00:41:18,351
if the standpoint of justice is the
standpoint of the least advantaged person,

599
00:41:19,740 --> 00:41:23,250
but this is not a kind of
bleeding heart liberal point.

600
00:41:23,850 --> 00:41:27,690
He's not saying the stand point of
justice is a standpoint of the least

601
00:41:27,691 --> 00:41:31,920
advantage person because we should feel
sorry for the least advantaged person,

602
00:41:32,700 --> 00:41:37,220
that poor bag lady and that rich Trump
isn't that disgusting to contemplate.

603
00:41:37,460 --> 00:41:41,810
That's not his point.
It's a self interested point,

604
00:41:41,840 --> 00:41:43,580
completely self interested point.

605
00:41:44,030 --> 00:41:49,030
He's saying you figure out what you
would choose in this situation of turning

606
00:41:50,871 --> 00:41:53,060
out to be the most disadvantaged person.

607
00:41:54,170 --> 00:41:56,000
That is a stand point of justice.

608
00:41:56,001 --> 00:42:00,080
Not because we feel badly for
the most disadvantaged person,

609
00:42:00,350 --> 00:42:04,340
but because we want a universalized
about principle. Okay.

610
00:42:04,670 --> 00:42:07,970
That's the point.
So it's not,

611
00:42:08,330 --> 00:42:12,440
it's not that he's, as I said,
it's not a bleeding heart point.

612
00:42:13,250 --> 00:42:14,690
It's a self interest point.

613
00:42:14,900 --> 00:42:18,560
It's it's self interest in the
service of universalize ability.

614
00:42:18,561 --> 00:42:23,561
It's to get people to pick a principle
that they would affirm no matter what.

615
00:42:26,990 --> 00:42:27,570
Okay.

616
00:42:27,570 --> 00:42:32,190
That's the sense in which roles
thinks of himself as a content.

617
00:42:33,750 --> 00:42:37,140
Okay,
now let's come back to religious freedom.

618
00:42:38,670 --> 00:42:39,810
Wow.

619
00:42:42,980 --> 00:42:47,980
If we had an established church and
you turned out to be a member of the

620
00:42:49,251 --> 00:42:52,310
established religion,
you would be completely happy.

621
00:42:53,700 --> 00:42:58,440
But if we had an established church and
you'd turned out to be a nonbeliever or

622
00:42:58,441 --> 00:43:02,460
believer in a different religion,
you wouldn't be happy. Right?

623
00:43:02,461 --> 00:43:03,960
You'd be less happy,

624
00:43:03,961 --> 00:43:08,961
at least then the person who turns out
to belong to the established religion.

625
00:43:11,490 --> 00:43:12,960
That part's straightforward.

626
00:43:13,530 --> 00:43:16,740
But that's not the interesting comparison.

627
00:43:16,890 --> 00:43:20,820
It's not the illuminating comparison.
So Raul says,

628
00:43:22,050 --> 00:43:23,460
think about it like this.

629
00:43:27,200 --> 00:43:31,430
The question's whether or not to have an
established church established religion.

630
00:43:31,760 --> 00:43:34,730
Right?
So think about the,

631
00:43:34,900 --> 00:43:39,050
the person who is not a member
of the established religion

632
00:43:42,910 --> 00:43:45,760
in a world in which there
is an established religion,

633
00:43:46,920 --> 00:43:47,753
right?

634
00:43:49,140 --> 00:43:54,140
Versus the believer in a world in
which there is no established religion.

635
00:43:57,620 --> 00:44:01,640
Because if, if, if, if you
suppose you're an atheist, right?

636
00:44:02,630 --> 00:44:05,390
And we have no established religion,
you're happy.

637
00:44:05,630 --> 00:44:09,140
But if on the other hand are
the fundamentalist is unhappy.

638
00:44:10,790 --> 00:44:11,623
Right?

639
00:44:12,560 --> 00:44:13,490
But so for Rawls,

640
00:44:13,491 --> 00:44:18,491
the relevant comparison is would you
rather be a fundamentalist in a regime

641
00:44:22,430 --> 00:44:24,380
where there's no established religion

642
00:44:25,020 --> 00:44:25,890
or

643
00:44:27,910 --> 00:44:31,830
and nonbeliever in a regime where
there is an established religion.

644
00:44:32,780 --> 00:44:33,400
Okay.

645
00:44:33,400 --> 00:44:38,400
And his argument for this established
religion is that the believer in the

646
00:44:39,161 --> 00:44:44,161
disestablishment regime has more religious
freedom than the nonbeliever and the

647
00:44:45,491 --> 00:44:48,640
established machine.
Right.

648
00:44:49,510 --> 00:44:54,510
To make this concrete fundamentalists
have more religious freedom in America

649
00:44:56,020 --> 00:44:59,020
than non fundamentalists
have in Saudi Arabia.

650
00:44:59,060 --> 00:45:00,890
Yeah. Well, Iran.

651
00:45:02,460 --> 00:45:07,460
So the reason to prefer the reason to
prefer this establishment of religion is

652
00:45:10,291 --> 00:45:14,880
that if you're trying to maximize the
religious freedom of the least advantaged

653
00:45:14,881 --> 00:45:15,714
person,

654
00:45:16,080 --> 00:45:20,640
it's you have to look at the least
advantage person in all of the possible

655
00:45:21,000 --> 00:45:24,510
regimes of governing religion.
Right?

656
00:45:24,990 --> 00:45:29,990
And so the defense of the establishment
clause of the u s he doesn't talk about

657
00:45:30,901 --> 00:45:35,490
this example, but I'm, it's my
example, but it's his logic, right?

658
00:45:35,670 --> 00:45:39,330
If you said the roles in defense of
the establishment clause of the u s

659
00:45:39,331 --> 00:45:44,070
constitution, that's what it
would be. It's not, you know,

660
00:45:44,071 --> 00:45:44,990
fundamentalist.

661
00:45:44,991 --> 00:45:49,991
Often Christian fundamentalists often
criticize the establishment clause,

662
00:45:50,791 --> 00:45:53,460
particularly in the way it's
been interpreted by the courts.

663
00:45:53,640 --> 00:45:57,870
They say it's presented as neutral
among religions and it's not,

664
00:45:58,650 --> 00:46:02,070
it's not neutral because it works.
You know,

665
00:46:02,071 --> 00:46:06,690
people who think they shouldn't be an
established religion getting exactly what

666
00:46:06,691 --> 00:46:11,400
they want, but we who think that should
be, don't get exactly what we want.

667
00:46:11,401 --> 00:46:15,900
So it's not neutral. Correct.
That correct. It's not neutral.

668
00:46:16,710 --> 00:46:21,710
And roles actually contributes to
confusion here because sometimes he talks

669
00:46:22,411 --> 00:46:24,840
about his theory as as neutral.

670
00:46:26,290 --> 00:46:27,123
It's not neutral.

671
00:46:28,890 --> 00:46:32,340
And the, the, the requirement is
not that it should be neutral,

672
00:46:32,370 --> 00:46:36,390
but rather that it should give the
most extensive religious freedom

673
00:46:38,380 --> 00:46:39,090
okay.

674
00:46:39,090 --> 00:46:44,070
To the person who's most disadvantaged
in either system. So as I said,

675
00:46:44,250 --> 00:46:48,390
the key point is that the believer,

676
00:46:50,750 --> 00:46:50,980
okay,

677
00:46:50,980 --> 00:46:52,870
has more religious freedom.

678
00:46:52,900 --> 00:46:57,900
If you have something like the
u s s establishment clause,

679
00:46:58,890 --> 00:47:00,690
then the nonbeliever has,

680
00:47:01,140 --> 00:47:05,740
when you have a fundamentalist
regime that's the claim.

681
00:47:06,100 --> 00:47:10,840
And so you want to give the most
extensive system of religious freedom

682
00:47:11,080 --> 00:47:13,540
compatible with a light system for all

683
00:47:14,900 --> 00:47:15,733
right?

684
00:47:15,870 --> 00:47:20,870
And the way you get compared with the
light system for all is to look at it from

685
00:47:21,631 --> 00:47:25,110
the standpoint of the most
adversely affected personnel,

686
00:47:25,111 --> 00:47:28,950
the least advantaged person in any case.

687
00:47:30,040 --> 00:47:34,630
So that's the basic way in which
he reasons. And that's why these,

688
00:47:34,840 --> 00:47:36,070
this sort of rather

689
00:47:39,640 --> 00:47:43,750
empty sounding phrase here,
that is this first principle,

690
00:47:44,170 --> 00:47:44,980
uh,

691
00:47:44,980 --> 00:47:49,330
actually has more content than might
appear to be the PSI at first sight to be

692
00:47:49,331 --> 00:47:52,210
the case. Right? So it's, it's, um,

693
00:47:52,750 --> 00:47:57,310
the standpoint of justice is a standpoint
of the most disadvantaged person,

694
00:47:57,700 --> 00:47:59,920
not because of being a bleeding heart,

695
00:47:59,921 --> 00:48:04,150
but because you want a universalized
about principle and we,

696
00:48:04,151 --> 00:48:09,151
it's just the cake cutting you giving
the knife to the right person is getting

697
00:48:09,701 --> 00:48:11,170
the last slice.
You say,

698
00:48:11,500 --> 00:48:16,500
pick the system that will give you the
most religious freedom when you just,

699
00:48:16,990 --> 00:48:20,290
when you later discover
what your beliefs are,

700
00:48:21,290 --> 00:48:22,123
right?

701
00:48:22,740 --> 00:48:26,980
And that is the principle you
should affirm. And that is why I,

702
00:48:26,981 --> 00:48:29,850
religious fundamentalists should choose

703
00:48:32,420 --> 00:48:36,870
disestablish the establishment
clause of the u s okay.

704
00:48:37,080 --> 00:48:40,800
Now somebody might come along with some
other principal and show that it does

705
00:48:40,801 --> 00:48:45,720
better and then we'd have to go through
the process again. But, so that,

706
00:48:45,721 --> 00:48:48,870
that's the basic structure
of Rawlsian reasoning.

707
00:48:48,960 --> 00:48:52,620
If you lie about principles of Justice,

708
00:48:53,700 --> 00:48:57,600
okay, we'll pause there
and pick up on Wednesday.

