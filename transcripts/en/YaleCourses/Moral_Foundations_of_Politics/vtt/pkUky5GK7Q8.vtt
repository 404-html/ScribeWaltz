WEBVTT

1
00:00:01.560 --> 00:00:02.191
Okay.

2
00:00:02.191 --> 00:00:06.690
This morning we're going to carry on talking about Jeremy Bentham and classical

3
00:00:06.720 --> 00:00:08.160
utilitarianism.

4
00:00:08.880 --> 00:00:13.880
And I'm going to begin by making a few points about the measurement of utility,

5
00:00:16.190 --> 00:00:16.590
um,

6
00:00:16.590 --> 00:00:21.590
which we we bumped into in a glancing kind of way last time,

7
00:00:21.661 --> 00:00:26.430
but we're going to dig into it a little bit and then we're gonna move from that

8
00:00:26.431 --> 00:00:31.431
into talking about a utility and distribution in classical utilitarianism.

9
00:00:34.340 --> 00:00:34.620
Uh,

10
00:00:34.620 --> 00:00:39.620
how we should think about the measurement of utility across the whole society

11
00:00:39.721 --> 00:00:43.970
and what implications Bentham's argument has for that.

12
00:00:44.330 --> 00:00:49.330
That I think you'll start to see why classical utilitarianism became such an

13
00:00:50.461 --> 00:00:55.461
ideologically powerful doctrine in the 18th and 19th centuries.

14
00:00:56.010 --> 00:01:00.750
So just briefly to recap,
we've talked last time about

15
00:01:02.340 --> 00:01:06.570
Bentham's principle being maximize the greatest happiness of the greatest

16
00:01:06.571 --> 00:01:10.530
number.
The idea being that if you think of a,
in this case,

17
00:01:10.531 --> 00:01:13.760
a very simple two person society,
um,

18
00:01:13.800 --> 00:01:17.220
and you think of that as the status quo,

19
00:01:17.400 --> 00:01:20.820
a has that much utility B has that much utility.

20
00:01:21.150 --> 00:01:26.150
Anything on this side of the status quo would be an improvement for society.

21
00:01:27.631 --> 00:01:32.631
The greatest happiness of the greatest number we'll have been increased.

22
00:01:34.140 --> 00:01:37.280
Now that's all very abstract.
And,

23
00:01:37.350 --> 00:01:41.100
and by way of trying to make it somewhat more concrete,

24
00:01:41.400 --> 00:01:46.140
let's notice two features of utility measurement.

25
00:01:46.950 --> 00:01:49.800
The first as a,
as I said to you last time,

26
00:01:50.130 --> 00:01:52.560
as far as Bentham is concerned,

27
00:01:52.561 --> 00:01:56.550
this is a doctrine of what I called objective egoism.

28
00:01:57.000 --> 00:02:01.110
That people are self interested and behave self interestedly,

29
00:02:01.410 --> 00:02:03.390
but that we can figure out what's,

30
00:02:03.630 --> 00:02:08.630
what's likely to motivate them regardless of their own interpretation of their

31
00:02:09.181 --> 00:02:12.720
actions or behavior.
We have our interpretation.

32
00:02:12.721 --> 00:02:15.570
Remember Bentham says the rare case,

33
00:02:15.600 --> 00:02:18.820
as with as with the physiology of the human body.

34
00:02:18.821 --> 00:02:21.990
So with the anatomy and physiology of the human mind,

35
00:02:22.200 --> 00:02:26.730
it's the rare case that you get it right about yourself.
Um,

36
00:02:28.050 --> 00:02:33.050
and it's the objective scientific calculus that's gonna tell us what maximizes

37
00:02:34.051 --> 00:02:37.050
people's utility.
But you might say,
well,

38
00:02:37.051 --> 00:02:39.810
how is that actually going to work?

39
00:02:40.890 --> 00:02:43.050
So the two steps here,

40
00:02:43.170 --> 00:02:48.170
the first one is that he thinks all utility is quantifiable.

41
00:02:49.140 --> 00:02:52.330
Went through that last time.
But the,
the,

42
00:02:52.331 --> 00:02:57.060
the piece I didn't mention is that it follows from that that utility is

43
00:02:57.061 --> 00:02:59.590
reduceable to a single index.

44
00:02:59.920 --> 00:03:03.190
And in this case Bentham's thinking off money,

45
00:03:04.420 --> 00:03:08.450
money is going to be the measure of utility in his team.

46
00:03:09.100 --> 00:03:14.100
And that means that we could think of these units of utility is having a kind of

47
00:03:14.831 --> 00:03:18.430
dollar value.
So you know,

48
00:03:18.460 --> 00:03:22.030
anytime you think this doctrine is,
is crude or extreme,

49
00:03:22.031 --> 00:03:23.890
remember my point that this is a,

50
00:03:23.891 --> 00:03:28.450
this is a guy we takes every thought to the logical extreme.

51
00:03:28.960 --> 00:03:33.820
But if so you get one.
Let's,
let's just for simplicity's sake,

52
00:03:34.000 --> 00:03:39.000
say one standard international UTL costs a dollar and let's suppose you

53
00:03:41.951 --> 00:03:46.951
experienced to standard into national utiles of pain from coming to class.

54
00:03:49.720 --> 00:03:54.720
Then I could make you indifferent between coming to class and not coming to

55
00:03:55.331 --> 00:04:00.331
class by paying you $2 we could get you to come to class if I paid $3 and I

56
00:04:01.871 --> 00:04:05.950
would not get you to come to class if I paid a dollar.
Right?

57
00:04:06.190 --> 00:04:10.550
And so that's the second point.
In the,
in the first instance we,

58
00:04:10.570 --> 00:04:15.570
we say that utility is quantifiable and expressible through money.

59
00:04:16.720 --> 00:04:21.420
But then related to that and as indicated,
the example I just gave you,
um,

60
00:04:21.850 --> 00:04:24.700
we can work with the doctrine of revealed preference.

61
00:04:24.880 --> 00:04:29.650
We can vary the price that we charge admission for the course.

62
00:04:29.920 --> 00:04:32.160
So let's say we charge,
let's,

63
00:04:32.170 --> 00:04:37.170
let's imagine I'm the three of you and one of your experiences to you tells the

64
00:04:39.431 --> 00:04:44.431
pain from coming to class one experiences three utils of pain and one experience

65
00:04:45.661 --> 00:04:47.140
is to utiles of pleasure.

66
00:04:47.141 --> 00:04:51.910
There's one perverse student in the audience who actually likes coming to the

67
00:04:51.911 --> 00:04:55.660
class.
Um,
so then we would find that if,

68
00:04:55.720 --> 00:04:58.120
if we paid a dollar,

69
00:04:59.530 --> 00:05:04.330
one of you would come,
if we increase increase such a to 52 of you would come.

70
00:05:04.331 --> 00:05:09.331
And so we could vary the price to get information about your utility and we

71
00:05:11.081 --> 00:05:16.081
could even influence your behavior without actually changing your preferences.

72
00:05:16.870 --> 00:05:20.770
And that's a very important distinction to make.
So we could,

73
00:05:20.800 --> 00:05:25.410
we could you your preference to come or not to your,

74
00:05:25.411 --> 00:05:29.710
your enjoyment from coming or not coming to class wouldn't change by your

75
00:05:29.711 --> 00:05:33.150
behavior would change if we,
um,

76
00:05:33.550 --> 00:05:35.050
vary the price.
Okay.

77
00:05:35.051 --> 00:05:40.051
So that we can influence your behavior by manipulating the incentives without

78
00:05:41.920 --> 00:05:45.100
regard to what your underlying preferences are.

79
00:05:45.310 --> 00:05:48.700
And we could allow them actually just stay the same.

80
00:05:49.570 --> 00:05:54.250
You'd rather be at home asleep,
but if the price is high enough,

81
00:05:54.251 --> 00:05:58.460
you'll come anyway.
Okay.

82
00:05:58.490 --> 00:06:02.810
So that's all well and good at the level of thinking about,
uh,

83
00:06:02.900 --> 00:06:04.850
one individual's behavior.

84
00:06:04.940 --> 00:06:09.940
The what about thinking about society in a more general terms?

85
00:06:12.740 --> 00:06:14.330
When we talk about

86
00:06:15.890 --> 00:06:19.130
utilitarianism in Bentham's system,

87
00:06:20.180 --> 00:06:22.070
classical utilitarianism,

88
00:06:22.460 --> 00:06:27.460
we see that he operates with these numbers attached to specific actions or

89
00:06:29.751 --> 00:06:34.490
policies and that we can make comparisons across individuals.

90
00:06:34.790 --> 00:06:37.280
So to put this in the jargon of economists,

91
00:06:37.670 --> 00:06:42.670
Bentham allows interpersonal comparisons of utility.

92
00:06:43.370 --> 00:06:46.700
Bentham allows interpersonal comparisons of utility.

93
00:06:47.150 --> 00:06:48.440
We can say that if,

94
00:06:49.280 --> 00:06:54.280
if you take one unit of utility from one person and give it to another person,

95
00:06:56.870 --> 00:07:01.870
their utility will go up and the first two person's utility is going to go down.

96
00:07:02.990 --> 00:07:04.280
Okay,
so it's a it,

97
00:07:04.340 --> 00:07:09.200
it's a doctrine of interpersonal comparisons of utility.

98
00:07:09.740 --> 00:07:12.440
And for those of you who are mathematicians here,

99
00:07:12.740 --> 00:07:17.240
it might also be worth noting that Bentham operates with cardinal scales.

100
00:07:17.241 --> 00:07:20.690
These are additive things.
You can actually think about these.

101
00:07:20.691 --> 00:07:25.610
It's sort of lumps are pleasure or pain experience.

102
00:07:25.850 --> 00:07:30.850
Then I moved around across people and can be added and subtracted.

103
00:07:31.700 --> 00:07:33.620
And so I've put up just here to sort of,

104
00:07:33.621 --> 00:07:36.560
so you can think your way through this doctrine.

105
00:07:37.190 --> 00:07:39.180
If you imagine a status quo,

106
00:07:39.230 --> 00:07:44.230
perfectly egalitarian world in which each person has six units of utility,

107
00:07:47.120 --> 00:07:51.800
you can start RCO south.
Well,
let's imagine if we could redistribute things,

108
00:07:52.520 --> 00:07:56.380
what would that mean as far as Bentham's doctrine is concern,

109
00:07:56.840 --> 00:08:01.610
but what I've given given in this first column as a potential departure from the

110
00:08:01.611 --> 00:08:06.611
status quo is the utility monster example we talked about last time with if

111
00:08:08.211 --> 00:08:13.211
turns out layer need has a vastly superior capacity to experiment,

112
00:08:14.390 --> 00:08:19.010
variance pleasure than anybody else,
then we would,
we would,

113
00:08:19.040 --> 00:08:22.670
we could get a huge increase in total utility

114
00:08:24.500 --> 00:08:26.620
without,
um,

115
00:08:28.110 --> 00:08:32.120
by taking a lot from BNC and giving it to layer need.

116
00:08:32.630 --> 00:08:37.460
So,
um,
that,
that would say allow,
right?

117
00:08:37.490 --> 00:08:42.380
All we could think of this change from the status quo,

118
00:08:42.860 --> 00:08:46.640
we go to a more a Galitary and society.
And again,

119
00:08:46.641 --> 00:08:50.090
the greatest happiness of the greatest number has increased.

120
00:08:50.420 --> 00:08:53.090
We have a world here where there are eight 18,

121
00:08:53.091 --> 00:08:57.230
you'd chosen their world care where there are 19 Utah.

122
00:08:57.930 --> 00:09:00.300
Or think about this case.

123
00:09:00.690 --> 00:09:05.340
We might think of this as a kind of scheme activation of the [inaudible]
problem.

124
00:09:05.760 --> 00:09:06.593
If,

125
00:09:06.780 --> 00:09:11.780
if the utility that the Arians gain from a practicing genocide and ethnic

126
00:09:15.631 --> 00:09:20.631
cleansing against the Jews exceeds the utilities that the Jews lose,

127
00:09:21.110 --> 00:09:26.040
there would be no reason under Bentham's doctrine not to do it.

128
00:09:27.600 --> 00:09:27.931
Okay.

129
00:09:27.931 --> 00:09:32.931
Now this a certain ambiguity in the phrase maximize the greatest happiness of

130
00:09:34.681 --> 00:09:36.510
the greatest number,

131
00:09:37.080 --> 00:09:41.190
which Bentham never finally resolves.
The ambiguity is where the,

132
00:09:41.191 --> 00:09:45.900
he's saying just maximize the total.
So he had the totals bigger than 18.

133
00:09:46.050 --> 00:09:50.760
Here,
the totals bigger than 18 here,
the totals bigger than 18.
Um,

134
00:09:50.761 --> 00:09:51.240
so it's,

135
00:09:51.240 --> 00:09:56.100
it's obviously the case that it's preferable for on Bentham scheme to the status

136
00:09:56.101 --> 00:10:01.101
quo or is he perhaps saying maximize the utility of the majority,

137
00:10:03.000 --> 00:10:05.790
the greatest happiness of the greatest number.

138
00:10:06.180 --> 00:10:09.030
That greatest number simply meaning the majority.

139
00:10:09.360 --> 00:10:11.910
But in that second interpretation,

140
00:10:12.090 --> 00:10:17.090
you could still get highly any galatarian distributions being judged superior to

141
00:10:17.611 --> 00:10:21.570
the status quo.
Because if you imagine going from here to here,

142
00:10:22.380 --> 00:10:23.720
we've got,
um,

143
00:10:23.940 --> 00:10:28.140
a majority here experiencing 12 youth shells of pleasure.

144
00:10:28.500 --> 00:10:30.330
<v 1>And,
uh,</v>

145
00:10:31.330 --> 00:10:36.330
<v 0>here we have a majority of to experiencing 17 potentially utiles of pleasure.</v>

146
00:10:40.420 --> 00:10:45.420
So there is some ambiguity there as to just what Bentham meant,

147
00:10:46.510 --> 00:10:49.420
but most of the time he is taken as having men.

148
00:10:49.990 --> 00:10:51.700
Just the crude statement,

149
00:10:51.880 --> 00:10:56.260
maximize the total amount of utility in this society.

150
00:10:56.560 --> 00:11:00.850
And so that nuance between whether we're saying the greatest number means a

151
00:11:00.851 --> 00:11:05.851
majority or just the total amount is not something that will detain us any

152
00:11:07.150 --> 00:11:07.983
further.

153
00:11:09.370 --> 00:11:10.203
<v 1>Now</v>

154
00:11:12.230 --> 00:11:16.040
<v 0>you could say,
okay,</v>

155
00:11:17.060 --> 00:11:18.320
so far so good,

156
00:11:18.321 --> 00:11:23.321
but isn't all of this a little counter intuitive after all?

157
00:11:25.290 --> 00:11:28.050
Um,
if you compare,

158
00:11:28.250 --> 00:11:33.250
let's focus on the difference between the status quo and distribution for here.

159
00:11:36.020 --> 00:11:39.620
These people might be on the verge of starvation.

160
00:11:40.520 --> 00:11:45.520
Surely giving them a unit of utility is going to be much more enhancing to their

161
00:11:48.051 --> 00:11:52.340
happiness.
Then giving a a unit of utility.

162
00:11:55.330 --> 00:11:58.240
Anyone know what the principle behind that idea is?

163
00:12:02.620 --> 00:12:07.480
Anyone want to take?
How many of you have done econ,

164
00:12:07.610 --> 00:12:12.280
the econ 101 the first econ course?
Yeah.
So what?

165
00:12:12.310 --> 00:12:16.240
What is,
what is the principle that would tell you?

166
00:12:17.260 --> 00:12:18.093
<v 2>MMM.</v>

167
00:12:19.890 --> 00:12:23.370
<v 0>What is the principle that will tell you if you have no food and I gave you a</v>

168
00:12:23.371 --> 00:12:24.360
loaf of bread,

169
00:12:24.930 --> 00:12:29.930
you'll utility goes up a lot more than if I have 10 10 loaves of bread and I

170
00:12:30.761 --> 00:12:32.520
give you a loaf of bread.
Somebody.

171
00:12:34.110 --> 00:12:34.943
<v 2>Okay.</v>

172
00:12:37.450 --> 00:12:38.870
<v 3>Diminishing marginal utility.
Yeah,</v>

173
00:12:39.460 --> 00:12:44.280
<v 0>marginal utility.
The principle of diminishing marginal utility.</v>

174
00:12:44.670 --> 00:12:49.080
All good things,
and this is,
this is the idea,

175
00:12:50.520 --> 00:12:54.240
just encapsulate it to make it a little bit more dramatic.

176
00:12:54.241 --> 00:12:58.830
If you don't have a car and somebody gives you a Porsche turbo,

177
00:12:59.660 --> 00:13:03.330
you'll your tellers just going to go off a huge amount,
right?

178
00:13:04.500 --> 00:13:08.400
But if you already have a Porsche turbo and somebody gives you a second one,

179
00:13:08.730 --> 00:13:13.590
you're going to get less new utility from the second portion then you had from

180
00:13:13.591 --> 00:13:16.680
the first.
And if somebody gives you a third one,

181
00:13:16.681 --> 00:13:18.450
you're going to have less utility,

182
00:13:18.570 --> 00:13:23.040
less new utility from the third one that you had from the second.

183
00:13:23.041 --> 00:13:25.740
It's not that you won't get any new,
but you'll get less.

184
00:13:26.160 --> 00:13:31.160
And the principle of diminishing marginal utility says that this line will get

185
00:13:31.231 --> 00:13:33.870
flatter and flatter and flatter toward infinity.

186
00:13:34.620 --> 00:13:37.140
You'll always get more utility

187
00:13:38.910 --> 00:13:42.630
from a new increment if the same good,

188
00:13:44.490 --> 00:13:49.490
but it'll be less new utility then you get got from the previous increment of

189
00:13:49.831 --> 00:13:54.480
that same good.
Okay.
That's the concept of diminishing marginal utility.

190
00:13:54.990 --> 00:13:55.270
You're,

191
00:13:55.270 --> 00:14:00.270
the new utility you get diminishes at the margin for each new Porsche is less

192
00:14:01.021 --> 00:14:05.730
valuable to you than the previous portion.
Now

193
00:14:07.680 --> 00:14:08.850
is that plausible?

194
00:14:15.640 --> 00:14:19.270
Anyone think there's a problem with that idea?

195
00:14:26.310 --> 00:14:27.143
<v 2>Yeah.</v>

196
00:14:28.850 --> 00:14:32.120
<v 3>Um,
they deal with like shoes.
If you're given like one shoe,</v>

197
00:14:32.300 --> 00:14:35.870
you're going to get absolutely no that utility.
But if you're given two shoes,

198
00:14:35.900 --> 00:14:38.240
like a written left,
then maybe you'll get more utility.

199
00:14:38.430 --> 00:14:39.150
<v 0>Okay.</v>

200
00:14:39.150 --> 00:14:43.560
So shows like if we just kept giving you lights of right shoes,

201
00:14:44.610 --> 00:14:48.150
there'd be that there'd be a problem.
Okay.
So I think Bentham,

202
00:14:48.151 --> 00:14:52.700
what have to say would have to be pairs of shoes,
right?
I,
yeah,
I guess.

203
00:14:52.790 --> 00:14:55.580
Okay.
So that's a good,
but that's a,

204
00:14:55.810 --> 00:15:00.770
that's a great example to start us off on this.
Um,
what else?
Any,
any,

205
00:15:00.950 --> 00:15:05.090
anything else anyone might find problematic?
Yeah,
over here.

206
00:15:07.940 --> 00:15:08.241
<v 4>Well,</v>

207
00:15:08.241 --> 00:15:12.110
it just seems that if we're going by diminishing marginal utility that if you

208
00:15:12.111 --> 00:15:15.080
had everyone literally,
you know,
dirt poor and always starving,

209
00:15:15.090 --> 00:15:17.300
you gave him just a little bit of something there happening.

210
00:15:17.301 --> 00:15:20.090
It's an increase so much more because it got that much little,

211
00:15:20.540 --> 00:15:23.390
but people would still be living in misery technically.

212
00:15:23.610 --> 00:15:25.230
<v 0>Just explain that a little bit more.</v>

213
00:15:25.990 --> 00:15:28.100
<v 4>Well,
marginal utility is,
you know,
you,</v>

214
00:15:28.200 --> 00:15:31.270
if you had a little bit of something for the first time,

215
00:15:31.390 --> 00:15:34.030
your happiness increases so much more because the first time,

216
00:15:34.540 --> 00:15:35.560
so if people were to,

217
00:15:35.561 --> 00:15:40.140
if you were to give people very little food or anything at all and he'd just,

218
00:15:40.141 --> 00:15:42.670
the link gave him a little bit,
they'd get really,
really happy about it.

219
00:15:43.090 --> 00:15:45.400
But by his,
by this,
that or the nozzle,

220
00:15:45.401 --> 00:15:48.250
if they're already very wealthy and they got something more there wouldn't

221
00:15:48.251 --> 00:15:48.791
really be happy.

222
00:15:48.791 --> 00:15:53.110
So it'd be more beneficial to the utility if they only got a little bit.

223
00:15:53.111 --> 00:15:54.400
So there would be very,
very happy.

224
00:15:54.590 --> 00:15:57.050
<v 0>Okay.
That's a very sophisticated observation.</v>

225
00:15:57.051 --> 00:16:00.830
I'm just going to put it to one side and come back to it in about 10 minutes.

226
00:16:00.831 --> 00:16:03.920
When I start talking about redistribution.
Okay.

227
00:16:04.250 --> 00:16:08.600
But anything else about if we still focusing on one individual,

228
00:16:08.900 --> 00:16:13.190
anything else that might be problematic with this notion of diminishing marginal

229
00:16:13.250 --> 00:16:14.330
utility over here?

230
00:16:17.870 --> 00:16:19.300
<v 4>Let's say your C,</v>

231
00:16:19.301 --> 00:16:22.300
just because you're rich doesn't mean you don't want to be more rich.

232
00:16:22.360 --> 00:16:25.720
And just because you have a certain amount of money doesn't mean more money

233
00:16:25.721 --> 00:16:28.870
isn't going to make you equally as happy as it did before.

234
00:16:29.140 --> 00:16:32.230
<v 0>Okay,
that's true.
But why is it problematic?</v>

235
00:16:34.700 --> 00:16:35.533
<v 2>MMM,</v>

236
00:16:35.700 --> 00:16:39.360
<v 0>so I don't know.
Well,
well,
I think you hit on something really important.</v>

237
00:16:39.960 --> 00:16:43.890
There are a lot of people who think that the principle of diminishing marginal

238
00:16:43.891 --> 00:16:48.891
utility means that money is less important to people as they have more of it.

239
00:16:49.890 --> 00:16:54.120
We'd say after we said the principle of diminishing marginal utility of all good

240
00:16:54.121 --> 00:16:58.530
things,
right?
Money is a,
it's a way of purchasing good things.

241
00:16:58.800 --> 00:16:59.660
So your,

242
00:16:59.680 --> 00:17:04.680
your example might be thought to suggest that this implies the more money you

243
00:17:05.521 --> 00:17:08.910
have,
the less important money is to you.
Okay?

244
00:17:09.510 --> 00:17:13.740
So you're right.
But notice what that means.

245
00:17:14.040 --> 00:17:16.860
Does it mean that rich people will care less about money?

246
00:17:24.250 --> 00:17:29.250
It's a tricky question because the first impulse is to say yes,

247
00:17:29.641 --> 00:17:34.410
they'll care less about money.
But the answer is no.
Why is the answer no?

248
00:17:37.570 --> 00:17:38.403
<v 2>Yeah,</v>

249
00:17:41.600 --> 00:17:42.291
<v 0>exactly.</v>

250
00:17:42.291 --> 00:17:47.291
They need more money to get the same amount of happiness precisely because of

251
00:17:47.571 --> 00:17:50.130
the principle of diminishing utility.

252
00:17:50.670 --> 00:17:55.670
So you got it exactly right to see that money creates some problematic,

253
00:17:56.140 --> 00:18:00.180
um,
examples for the principle of diminishing marginal utility.

254
00:18:00.480 --> 00:18:05.480
But the thing that follows from it is that that for Donald Trump to get more

255
00:18:07.051 --> 00:18:11.220
utility,
you have to give him a huge amount of new money just to,

256
00:18:11.250 --> 00:18:16.250
for him to get the same amount of new utility as somebody who only has $10,000.

257
00:18:19.500 --> 00:18:24.480
Right?
So the,
the way to think about the desire for money,

258
00:18:24.481 --> 00:18:29.160
it's a bit like sort of a heroin addict needs more and more and more new heroin

259
00:18:29.161 --> 00:18:30.240
to get the same head,

260
00:18:31.580 --> 00:18:32.413
<v 1>right?</v>

261
00:18:32.680 --> 00:18:34.630
<v 0>So the more money you have,
actually,</v>

262
00:18:34.631 --> 00:18:39.631
the more money you will want in order to get the next marginal increment of

263
00:18:40.241 --> 00:18:41.074
utility.

264
00:18:41.140 --> 00:18:46.140
So we should expect rich people to be greedy by this theory,

265
00:18:46.360 --> 00:18:50.560
not to become more and more indifferent to money.

266
00:18:50.890 --> 00:18:55.480
Very important assumption and a lot of people get that wrong when they think

267
00:18:55.481 --> 00:18:59.800
about the principle of diminishing marginal utility.

268
00:19:00.240 --> 00:19:03.880
There are any other examples of this doctrine that might make it seem

269
00:19:04.240 --> 00:19:05.080
problematic?

270
00:19:07.080 --> 00:19:07.980
<v 1>Yeah,
over there.</v>

271
00:19:10.300 --> 00:19:13.360
<v 5>Second Force Turbo.
If I had a second Porsche turbo,</v>

272
00:19:13.361 --> 00:19:15.970
I would be just really reckless with it and I could do whatever I want.

273
00:19:15.971 --> 00:19:20.110
Like I wouldn't have to protect the first Porsche turbo as much.
Yeah.

274
00:19:21.160 --> 00:19:25.210
But I mean it's like,
I mean there's more you can do with it,
right?

275
00:19:25.510 --> 00:19:27.280
<v 0>Yeah.
So why is that a problem?</v>

276
00:19:27.780 --> 00:19:32.340
<v 5>Well then wouldn't the second car,
I mean like say CV,
you have like,</v>

277
00:19:32.341 --> 00:19:34.560
you know you're,
you have a little bit and you're given a little bit,

278
00:19:35.070 --> 00:19:38.250
your utility goes up,
but you really want to protect that little bit.

279
00:19:38.251 --> 00:19:42.870
But when you get more,
maybe it encourages you to to to say money.

280
00:19:43.180 --> 00:19:43.680
Spend

281
00:19:43.680 --> 00:19:47.520
<v 0>the second one.
What are you saying?
You wouldn't want the second one,</v>

282
00:19:47.910 --> 00:19:51.210
but why wouldn't I want that?
If you had one you will.
And I said,
I'll give you,

283
00:19:51.211 --> 00:19:53.550
I'll give you my one.
It's right out there.
You wouldn't want it.

284
00:19:53.820 --> 00:19:55.320
<v 5>It's not the,
it's not that I wouldn't want it</v>

285
00:19:55.610 --> 00:20:00.490
<v 0>say like Jay Leno who like,
right,
how many cars does Jay Leno happy?</v>

286
00:20:00.580 --> 00:20:03.070
<v 5>Too Big.
It's not that it wouldn't want it,</v>

287
00:20:03.071 --> 00:20:07.780
but maybe the utility for the second one in some cases would be more than the

288
00:20:07.781 --> 00:20:09.890
utility for the first one.
So the curve would be thrown away

289
00:20:12.160 --> 00:20:16.870
because you want to protect that first one,
like so.
So I mean,

290
00:20:16.871 --> 00:20:18.430
so you don't lose what little you have.

291
00:20:19.490 --> 00:20:22.300
<v 0>Okay.
So that's a possibility.
Any,</v>

292
00:20:22.310 --> 00:20:26.000
any other examples of where this becomes problematic?

293
00:20:27.020 --> 00:20:29.480
I mean,
think about bear

294
00:20:31.310 --> 00:20:35.780
one beer increases your utility a lot the next,

295
00:20:36.560 --> 00:20:39.620
you know,
and then [inaudible] and the 14th.
And it is,

296
00:20:39.621 --> 00:20:44.480
this is an economic at some,
you know,
or taking an aspirin,

297
00:20:44.690 --> 00:20:45.440
isn't it kind of,

298
00:20:45.440 --> 00:20:46.273
<v 1>you know,</v>

299
00:20:48.080 --> 00:20:52.390
<v 5>no.
Uh,
what about other values like integrity?</v>

300
00:20:52.810 --> 00:20:56.350
If you have a little bit of integrity,
uh,
and you get some more,

301
00:20:56.500 --> 00:21:00.970
but if you have a lot of integrity,
you know,
like,
uh,
a little bit more,

302
00:21:00.971 --> 00:21:02.110
it's still worse than equal.

303
00:21:02.620 --> 00:21:07.620
<v 0>The integrity is a great example because why don't you start putting values like</v>

304
00:21:08.261 --> 00:21:10.690
that out there?
It threat,
I think,

305
00:21:10.691 --> 00:21:15.340
threatens the idea that it's all reducible to a single index,
right?

306
00:21:15.460 --> 00:21:16.600
Because,

307
00:21:17.110 --> 00:21:18.200
<v 2>mmm,</v>

308
00:21:20.880 --> 00:21:24.480
<v 0>you can't,
having a little bit of integrity,</v>

309
00:21:24.481 --> 00:21:26.730
sort of like being a little bit pregnant,
right.

310
00:21:26.731 --> 00:21:31.470
One once Elliot speced it spits his integrity as blown.

311
00:21:32.580 --> 00:21:36.420
It's not like he's there.
There's some it,
it's,
it's,
it's,

312
00:21:36.450 --> 00:21:39.300
it's a binary good either habit or you doubt.
Right.

313
00:21:39.630 --> 00:21:42.990
People think he's either a hypocrite or is not.
It's a binary thing.

314
00:21:42.991 --> 00:21:47.610
It's maybe some people are somewhat hypocritical,
but it's,

315
00:21:47.611 --> 00:21:52.590
it seems like it's a,
there's a threshold there,
one side of her or the other.

316
00:21:52.591 --> 00:21:57.591
And so there might be some good just like integrity that are not easily

317
00:21:58.171 --> 00:22:02.190
capturable in this logic.
We should put that out there.

318
00:22:02.970 --> 00:22:04.920
But yeah,
over here.

319
00:22:08.450 --> 00:22:12.770
<v 5>What about like a health,
I mean it's not quite binary,
you know,</v>

320
00:22:12.771 --> 00:22:14.150
cause you can be in medium health,

321
00:22:14.151 --> 00:22:17.450
but I think it would be pretty useful to be healthy and then super healthy.

322
00:22:17.480 --> 00:22:20.600
Like I gets,
you know,
add Infinium Infinium

323
00:22:21.750 --> 00:22:22.583
<v 2>health.</v>

324
00:22:25.730 --> 00:22:27.080
<v 0>The thing about health,
it's,</v>

325
00:22:27.200 --> 00:22:31.820
it's tricky to actually less so in our day then Bentham's it's tricky to think

326
00:22:31.821 --> 00:22:36.580
about redistributing health,
right?
Although,
you know,
uh,

327
00:22:37.970 --> 00:22:42.960
you'll see that there we,
we will come up against some pretty bizarre cases.
I,

328
00:22:42.990 --> 00:22:46.580
if,
you know,
if some people are cited and some people are blind,

329
00:22:46.581 --> 00:22:49.160
you could transfer and you could do eye transplants.

330
00:22:49.161 --> 00:22:53.690
Should we be transplanting from the sight to the blind?
Are you Billy?
You know,

331
00:22:53.691 --> 00:22:57.020
the blind person would gain more utility from getting one.

332
00:22:57.021 --> 00:23:00.710
I then a sighted person would get loose from losing one eye.

333
00:23:00.711 --> 00:23:01.970
So shouldn't we do that?

334
00:23:02.420 --> 00:23:06.980
So that can be also give you some,

335
00:23:07.190 --> 00:23:11.900
some ways of proceeding that would make you queasy,

336
00:23:12.560 --> 00:23:16.940
right?
If you allow the principle of diminishing marginal utility,

337
00:23:17.710 --> 00:23:22.070
what,
what,
what would,
what about the examples I threw out there?

338
00:23:22.071 --> 00:23:26.930
Bare and aspirins.
They're a bit like the sort of left shoe examples,

339
00:23:26.931 --> 00:23:27.764
right?

340
00:23:27.770 --> 00:23:32.330
I don't think those ashy deep problems for Bentham's theory because I think what

341
00:23:32.331 --> 00:23:36.950
he would say as well,
uh,
you,
your drink beer,

342
00:23:36.951 --> 00:23:38.150
at some point you would start,

343
00:23:38.151 --> 00:23:42.920
you would sell the beer rather than make yourself paralytic drunk,
uh,

344
00:23:42.921 --> 00:23:47.060
and feel terrible.
You'd sell the and use that to buy some other guard,

345
00:23:47.510 --> 00:23:48.200
uh,

346
00:23:48.200 --> 00:23:52.880
that would give you increasing utility at a diminishing marginal rate.

347
00:23:53.420 --> 00:23:54.860
So,
um,

348
00:23:56.450 --> 00:24:01.130
the main thing is that the fungibility of utility in it and it's,
um,

349
00:24:01.190 --> 00:24:03.770
express ability in terms of money,

350
00:24:04.160 --> 00:24:07.100
although as was pointed out here,
um,

351
00:24:07.220 --> 00:24:11.270
when we think about the diminishing marginal utility even have money,

352
00:24:11.450 --> 00:24:15.750
we shouldn't think that that makes you care less about money.
The richer you get,

353
00:24:15.770 --> 00:24:19.400
we have that.
It will make you care more about money,

354
00:24:19.790 --> 00:24:24.600
the richer that you get.
Okay.
Now here's a,

355
00:24:24.770 --> 00:24:29.420
here's this historical statement about the principle of diminishing marginal

356
00:24:29.421 --> 00:24:30.254
utility.

357
00:24:31.220 --> 00:24:36.220
Every serious economist since the 18th century has assumed that the principle of

358
00:24:38.841 --> 00:24:40.880
diminishing marginal utility is true,

359
00:24:41.840 --> 00:24:43.880
including Jeremy Bentham.

360
00:24:45.020 --> 00:24:50.020
You can do economics without assuming that the principle of diminishing marginal

361
00:24:51.501 --> 00:24:52.520
utility is true.

362
00:24:52.850 --> 00:24:57.850
And I think if you throw out some of these problematic instances like integrity,

363
00:24:59.840 --> 00:25:02.870
um,
I think that what,

364
00:25:03.260 --> 00:25:07.700
what Bentham would have said or what any economist would have said,
well,
yes,

365
00:25:07.701 --> 00:25:12.701
there are some things that are not capturable easily or easily captured by this

366
00:25:14.661 --> 00:25:17.690
idea,
but it's if you want to get it right,

367
00:25:17.720 --> 00:25:21.080
if you want to see how people are going to behave,

368
00:25:21.740 --> 00:25:22.730
if you want to get it right,

369
00:25:22.731 --> 00:25:27.170
it's a better assumption than any of the competing assumptions you could make.

370
00:25:27.650 --> 00:25:31.070
It's going to get you closer to the truth more of the time.

371
00:25:31.190 --> 00:25:35.870
Then not assuming the principle of diminishing marginal utility is true.

372
00:25:36.800 --> 00:25:41.800
So Bentham would have probably said that I th I think if questioned or if

373
00:25:42.591 --> 00:25:47.520
somebody had probed with some of these counter examples,
so it's,

374
00:25:47.540 --> 00:25:52.540
it's the best assumption you can make given that you've got to assume something.

375
00:25:58.090 --> 00:25:58.990
But now,

376
00:25:59.050 --> 00:26:03.640
and now I want to come back to the sophisticated point that was made in the

377
00:26:03.641 --> 00:26:06.190
middle at the back there a few minutes ago.

378
00:26:06.250 --> 00:26:11.250
When you start to think about the utility that people at the bottom of the

379
00:26:11.321 --> 00:26:16.321
social order derived from a particular good versus the utility that the people

380
00:26:16.541 --> 00:26:21.430
at the top of the social order derive from some particular good.

381
00:26:21.790 --> 00:26:25.480
Because in Bentham scheme,
remember we are allowing

382
00:26:27.310 --> 00:26:29.410
comparisons across individuals.

383
00:26:30.160 --> 00:26:33.610
Let's suppose a two person society again.

384
00:26:34.420 --> 00:26:35.260
Um,

385
00:26:35.950 --> 00:26:40.150
and let's suppose it consists of Donald Trump.

386
00:26:40.410 --> 00:26:41.950
It can be a multiperson society,

387
00:26:41.951 --> 00:26:46.951
but we just to focus to Donald Trump and a homeless woman living out of a,

388
00:26:48.270 --> 00:26:51.450
out of a left luggage locker in grand central station.

389
00:26:53.640 --> 00:26:55.590
Actually they know lockers at grand central,

390
00:26:55.591 --> 00:26:58.230
but there are at Penn at Penn station.
Okay.

391
00:26:59.950 --> 00:27:00.783
<v 2>MMM.</v>

392
00:27:02.870 --> 00:27:03.860
<v 0>And the question is,</v>

393
00:27:04.340 --> 00:27:08.830
should we take a dollar from Trump and give it to the bag lady?
What,

394
00:27:08.930 --> 00:27:13.040
what should we,
yes.
No.
How many think yes?

395
00:27:14.030 --> 00:27:16.940
Okay.
Yeah.
Almost everybody.

396
00:27:18.530 --> 00:27:19.363
Why?

397
00:27:19.490 --> 00:27:24.200
Because by assumption with the principle of diminishing marginal utility,

398
00:27:24.201 --> 00:27:26.900
we take the dollar off on Trump up there.
He,

399
00:27:26.930 --> 00:27:31.550
his loss of utilities negligible,
but we give it to the,
the woman,

400
00:27:31.820 --> 00:27:36.320
uh,
who is starving down here and her gain.

401
00:27:36.350 --> 00:27:39.440
And you tell these enormous from that dollar,
right?

402
00:27:40.280 --> 00:27:42.440
So we should take the dollar from Trump.

403
00:27:42.950 --> 00:27:46.370
Let's assume there's no dead weight loss to the government and all of that for

404
00:27:46.371 --> 00:27:48.590
right now,
we will just keep it simple.

405
00:27:48.800 --> 00:27:53.570
We should take that dollar from Trump and we should give it to the bag lady and

406
00:27:53.571 --> 00:27:57.230
the greatest happiness of the greatest number.
Well,
having creased,

407
00:27:58.330 --> 00:28:02.540
right?
But then maybe we should take another dollar,

408
00:28:03.800 --> 00:28:06.710
shouldn't we?
I mean it worked the first time.

409
00:28:06.950 --> 00:28:11.950
So we should take a second dollar from Trump and give it to the bag lady and the

410
00:28:12.951 --> 00:28:15.860
third dollar and a fourth dollar.

411
00:28:16.460 --> 00:28:18.260
When are we going to stop?

412
00:28:21.920 --> 00:28:23.480
When are we going to stop?

413
00:28:26.510 --> 00:28:27.343
<v 2>Yup.</v>

414
00:28:30.100 --> 00:28:34.420
<v 0>Yeah.
We're going to stop at the point of perfect equality,
right?</v>

415
00:28:34.421 --> 00:28:38.430
We're going to keep redistributing until they have the same amount.

416
00:28:42.400 --> 00:28:47.400
So now you should be able to start to see why classical.

417
00:28:47.741 --> 00:28:52.741
You'll tell a terrorism was a doctrine that was thought to be profoundly radical

418
00:28:54.910 --> 00:28:59.910
and frightening to rich man because it has this built in impetus for downward

419
00:29:03.821 --> 00:29:08.320
redistribution.
You can say,
well,
they'll be cost,
they'll be dead weight loss.

420
00:29:08.321 --> 00:29:12.550
To the state and so on,
but still the underlying logic says,

421
00:29:12.551 --> 00:29:17.551
take it from Trump and give it to the bag lady right at the margin.

422
00:29:17.561 --> 00:29:18.970
That's what you should do,

423
00:29:22.930 --> 00:29:27.930
and bent them completely sore that this was an implication of his doctrine.

424
00:29:29.110 --> 00:29:31.300
Now,
Bentham was a fairly radical guy.

425
00:29:31.301 --> 00:29:36.160
He was a supporter of democracy,
which was a radical thing at that time,

426
00:29:36.850 --> 00:29:38.280
but he wasn't he.

427
00:29:38.350 --> 00:29:42.820
He washed on this egalitarian as all of that and he wanted to temper

428
00:29:45.640 --> 00:29:50.500
the downward redistribution that flows from his principal and so

429
00:29:52.390 --> 00:29:53.800
he makes a distinction.

430
00:29:55.730 --> 00:29:56.563
<v 2>Okay.</v>

431
00:29:56.620 --> 00:30:01.240
<v 0>Between what he refers to as absolute and practical equality.</v>

432
00:30:03.130 --> 00:30:03.491
He says,

433
00:30:03.491 --> 00:30:08.350
suppose by the commencement be made by the power of a government of any kind in

434
00:30:08.351 --> 00:30:09.920
the design of establishing it,

435
00:30:10.180 --> 00:30:13.900
absolute equality that's redistributing to equality.

436
00:30:14.200 --> 00:30:18.280
The effect would be that instead of everyone's having an equal share in the some

437
00:30:18.281 --> 00:30:23.281
of the objects of general desire and in particular the means of subsistence and

438
00:30:24.041 --> 00:30:25.060
the matter of abundance,

439
00:30:25.330 --> 00:30:30.130
no one would have any share of it at all before any division of it could be

440
00:30:30.131 --> 00:30:34.480
made.
The hole would be destroyed and destroyed along with it,

441
00:30:34.660 --> 00:30:35.500
by those,

442
00:30:36.550 --> 00:30:41.550
those by whom as well as those for the sake of whom did the division had been

443
00:30:42.040 --> 00:30:42.873
ordained.

444
00:30:43.960 --> 00:30:48.960
He's basically saying if you want to reduce that to a bumper sticker is saying

445
00:30:50.500 --> 00:30:53.830
the rich will burn that crops before giving them to the poor.

446
00:30:58.200 --> 00:31:01.500
And that is a common argument in politics.

447
00:31:01.501 --> 00:31:03.660
It's the sort of reverse of trickle down,

448
00:31:04.770 --> 00:31:05.603
<v 1>right?</v>

449
00:31:07.950 --> 00:31:12.950
<v 0>Trickled down is the notion that you allow inequality because the rich create</v>

450
00:31:13.740 --> 00:31:15.410
more wealth for everybody,

451
00:31:16.710 --> 00:31:19.200
<v 1>right?
The pie bigger for everybody.</v>

452
00:31:20.380 --> 00:31:25.210
<v 0>And so the greatest amount of utility is increased by allowing inequality.</v>

453
00:31:26.080 --> 00:31:29.800
This is the inverse claim.
Bentham's saying,
well,
yes,

454
00:31:29.801 --> 00:31:34.270
in principle absolute equality would maximize the greatest happiness of the

455
00:31:34.271 --> 00:31:38.230
greatest number.
But in fact,
if a government set out to do that,

456
00:31:38.470 --> 00:31:40.150
the rich would rebel.

457
00:31:42.840 --> 00:31:46.770
And this is a claim that is often made in every day politics.

458
00:31:47.820 --> 00:31:49.380
So,
um,

459
00:31:49.560 --> 00:31:54.560
you'll destroy incentives to work is the claim that you'll hear a,

460
00:31:54.600 --> 00:31:59.600
when we have arguments about raising taxes in the run up to the fall elections,

461
00:32:01.080 --> 00:32:01.913
<v 1>right</v>

462
00:32:02.770 --> 00:32:07.150
<v 0>in the transition to democracy in South Africa,</v>

463
00:32:08.650 --> 00:32:13.650
people said the wipe pharmas will destroy their farms before turning them over

464
00:32:15.310 --> 00:32:17.830
to the majority turned out not to be true.

465
00:32:20.110 --> 00:32:23.350
So Tho those examples put on the table,

466
00:32:24.070 --> 00:32:28.720
what sort of forest is this claim have?
It's really an empirical claim

467
00:32:33.340 --> 00:32:38.340
and we don't really know how much the rich will before burning their crops be

468
00:32:42.631 --> 00:32:46.440
zoom.
I believe they'll allow some redistributive taxation,

469
00:32:46.740 --> 00:32:51.690
but we don't know how much and a lot of the day to day argument of politics

470
00:32:51.691 --> 00:32:52.830
turns around how much.

471
00:32:53.190 --> 00:32:57.870
So Bentham makes a distinction between absolute and practical equality and he

472
00:32:57.871 --> 00:33:01.140
says we should redistribute to the point of practical equality,

473
00:33:01.141 --> 00:33:06.141
but not to the point of absolute equality because it has redistributing beyond

474
00:33:08.070 --> 00:33:13.070
practical equality has this perverse counter trickle down logic and that's not

475
00:33:15.200 --> 00:33:16.770
going to be acceptable.

476
00:33:18.090 --> 00:33:18.700
<v 2>Okay.</v>

477
00:33:18.700 --> 00:33:21.430
<v 0>From the standpoint of the principle of utility.</v>

478
00:33:24.430 --> 00:33:25.263
Okay.

479
00:33:27.220 --> 00:33:32.220
So when you allow both interpersonal comparisons of utility in you assume

480
00:33:35.080 --> 00:33:36.880
diminishing marginal utility,

481
00:33:37.150 --> 00:33:40.960
utilitarianism becomes a very radical doctrine.

482
00:33:41.200 --> 00:33:45.340
You can hedge it in to some extent with claims of this sort.

483
00:33:46.800 --> 00:33:47.420
<v 2>Okay.</v>

484
00:33:47.420 --> 00:33:52.420
<v 0>But they are themselves controversial and you're going to get into a very messy</v>

485
00:33:53.901 --> 00:33:58.901
world of macroeconomic predictions and counter predictions about whether and

486
00:34:01.520 --> 00:34:05.600
when you reach this point of practical equality,
uh,
when the,

487
00:34:06.080 --> 00:34:06.913
the,
uh,

488
00:34:07.040 --> 00:34:12.040
gains from downward redistribution offset by the losses from the shrinking of

489
00:34:13.010 --> 00:34:13.843
the pie.

490
00:34:15.940 --> 00:34:18.850
Now some of you might've said,
well,

491
00:34:20.320 --> 00:34:22.930
at the beginning of this course of lectures,

492
00:34:23.230 --> 00:34:28.230
Shapiro said every enlightenment thinker is committed to too.

493
00:34:29.890 --> 00:34:30.260
<v 2>Okay?</v>

494
00:34:30.260 --> 00:34:35.090
<v 0>Postulates.
One is that we can have a scientific theory of politics.</v>

495
00:34:35.780 --> 00:34:40.780
And the other is that individual freedom operationalized as a doctrine of rights

496
00:34:42.440 --> 00:34:45.830
is the most important.
Good.
Now,

497
00:34:45.831 --> 00:34:48.530
having sat through these lectures on Benson,

498
00:34:48.860 --> 00:34:52.040
I can see what he's saying about science.
You know,

499
00:34:52.310 --> 00:34:55.880
Bentham has this monomaniacal view of science.

500
00:34:57.200 --> 00:35:01.010
He's got his objective egoism.
He can figure it all out.
What,

501
00:35:01.100 --> 00:35:04.820
what will maximize social utility and run around the world?

502
00:35:04.821 --> 00:35:09.821
Writing Constitutions for people can devise a whole public policy that's going

503
00:35:10.001 --> 00:35:14.000
to scientifically maximize the utility of society,

504
00:35:14.540 --> 00:35:19.190
but you know,
I'm not seeing a whole lot of room for rights in this doctorate.

505
00:35:20.660 --> 00:35:24.200
It seems to allow ethnic cleansing,
even genocide.

506
00:35:24.470 --> 00:35:29.470
It seems to allow redistribution from one person to another all justified on the

507
00:35:31.101 --> 00:35:36.101
grounds that this is maximizing total utility of society.

508
00:35:37.471 --> 00:35:38.940
Well even if it is,

509
00:35:40.740 --> 00:35:44.010
how does this respect individual rights?

510
00:35:48.050 --> 00:35:52.220
My just wrong.
If there's something,
some elementary thing I've missed here,

511
00:35:53.510 --> 00:35:57.260
there's not much room for rights in Bentham's doctrine.

512
00:35:59.850 --> 00:36:02.150
Well,
I'm just wrong that these enlightenment thinkers,

513
00:36:02.151 --> 00:36:05.030
we're committed to individual rights.

514
00:36:06.740 --> 00:36:11.150
It would be a reasonable inference from what I've said so far,

515
00:36:11.660 --> 00:36:12.680
but remember

516
00:36:19.240 --> 00:36:20.100
well Bentham,

517
00:36:20.950 --> 00:36:24.850
when we try to maximize you tell it in the society.

518
00:36:24.880 --> 00:36:27.220
Individual motivation is vital.

519
00:36:28.690 --> 00:36:33.100
This is a passage I I read to you last week,
but I'm just repeating it.

520
00:36:33.101 --> 00:36:35.650
The greatest enemies of public is ah,

521
00:36:35.651 --> 00:36:40.150
the selfish and this social passions necessary as they are.

522
00:36:40.600 --> 00:36:45.600
Society is held together only by the sacrifices that men can be induced to make

523
00:36:47.470 --> 00:36:52.270
of the gratifications.
They demand to obtain these sacrifices.

524
00:36:52.540 --> 00:36:54.220
Is the greatest difficulty,

525
00:36:55.660 --> 00:36:58.570
the greatest task of government.

526
00:37:00.010 --> 00:37:05.010
He's saying you have to work with individual motivations.

527
00:37:06.160 --> 00:37:09.520
You can't ignore them.
And I think that's,

528
00:37:09.550 --> 00:37:14.550
that is the point that's behind his distinction between absolute and practical

529
00:37:16.780 --> 00:37:20.800
equality.
The ritual burn the crops before giving them to the poor.

530
00:37:20.801 --> 00:37:22.570
You have to take that into account.

531
00:37:22.780 --> 00:37:27.780
You have to see individuals as the basic generators of utility.

532
00:37:31.000 --> 00:37:35.170
In another piece of phantoms writing,
which I didn't have your read,

533
00:37:35.171 --> 00:37:37.770
but I'll just put it out there because it's,

534
00:37:38.030 --> 00:37:42.700
it's where you start to see our old friend,
the workmanship ideal,

535
00:37:43.000 --> 00:37:46.720
creeping by the back door into utilitarianism.

536
00:37:47.710 --> 00:37:51.910
Bentham says,
Lord does not say to man work and I will reward you,

537
00:37:52.420 --> 00:37:54.250
but it says Labor.

538
00:37:54.910 --> 00:37:58.450
And by stopping the hand that would take them from you,

539
00:37:58.480 --> 00:38:02.740
I will ensure you the fruits of your labor.
It's natural,

540
00:38:02.741 --> 00:38:06.790
insufficient reward without which w without me,

541
00:38:06.791 --> 00:38:10.510
you cannot preserve.
If industry creates,
it is law,

542
00:38:10.511 --> 00:38:15.511
which preserves if at the first we owe everything to labor at the second and

543
00:38:15.701 --> 00:38:19.960
every succeeding moment,
we are everything to law.

544
00:38:20.800 --> 00:38:25.800
So another way of thinking about this is that Ben femmes idea of the state is

545
00:38:26.861 --> 00:38:28.780
essentially regulatory.

546
00:38:29.560 --> 00:38:33.760
It stays the hand of the somebody else who would steal your goods,

547
00:38:34.600 --> 00:38:37.900
but the cannot itself create utility.

548
00:38:39.750 --> 00:38:41.340
Labor creates utility.

549
00:38:42.780 --> 00:38:47.040
And this is why I say that workmanship are all I,

550
00:38:47.050 --> 00:38:51.720
that idea that we first confronted when we talked about lock comes into

551
00:38:51.721 --> 00:38:56.721
utilitarianism by the back door because Ben time's going to say,

552
00:38:58.680 --> 00:39:01.170
unless you respect individual rights,

553
00:39:01.500 --> 00:39:06.500
you're not going to be a ball to maximize utility for the society as a whole.

554
00:39:08.580 --> 00:39:12.360
So the state is basically a regulative state,

555
00:39:12.660 --> 00:39:17.660
not a state that's actively involved in creating utility for individuals.

556
00:39:20.970 --> 00:39:25.470
A,
we'll do some redistribution to the point of practical equality.

557
00:39:25.740 --> 00:39:30.740
But the basic idea is that the state should be hands off with respect to the

558
00:39:32.941 --> 00:39:35.580
utility creation in the society.

559
00:39:35.870 --> 00:39:39.330
It's industry that creates utility labor work.

560
00:39:39.630 --> 00:39:44.630
So incentives are going to be important going forward if you're going to

561
00:39:45.570 --> 00:39:47.250
maximize utility.

562
00:39:49.090 --> 00:39:54.090
So that's the way in which we see that even a classical utilitarian like Bentham

563
00:39:57.070 --> 00:39:58.450
is gonna resist.

564
00:39:59.780 --> 00:40:00.230
<v 2>Yeah.</v>

565
00:40:00.230 --> 00:40:04.100
<v 0>Dispensing with the doctrine of individual rights.</v>

566
00:40:06.960 --> 00:40:11.960
Now there's a problem with his mode of doing this and the problem arises because

567
00:40:17.220 --> 00:40:22.220
the claim that the rich will burn that crops before giving them to the poor

568
00:40:22.830 --> 00:40:24.150
might not be true.

569
00:40:26.230 --> 00:40:26.990
<v 2>Yeah.</v>

570
00:40:26.990 --> 00:40:31.990
<v 0>And even if we get to last extreme circumstances like South Africa before and</v>

571
00:40:32.421 --> 00:40:33.710
after the transition,

572
00:40:34.730 --> 00:40:39.730
when we look at actual debates in contemporary politics in the United States,

573
00:40:40.970 --> 00:40:45.080
this is what we see.
Ronald Reagan comes in and says,

574
00:40:45.380 --> 00:40:50.310
if we cut taxes,
this is a 1980 if we cut taxes,
um,

575
00:40:50.510 --> 00:40:55.510
the pie will get bigger for all and there'll be actually more revenue.

576
00:40:56.840 --> 00:41:01.490
And so utilitarianism says,
do it.
And the Democrats say no,

577
00:41:01.550 --> 00:41:03.320
now they wowed.
Um,

578
00:41:03.800 --> 00:41:07.700
and it's an empirical argument and you will fine.
I,

579
00:41:07.701 --> 00:41:12.701
if you go back now and look at what happened during the 1980s perfectly credible

580
00:41:14.811 --> 00:41:19.610
economists will line up on both sides because they cut the taxes bought,

581
00:41:19.640 --> 00:41:20.360
of course,

582
00:41:20.360 --> 00:41:25.160
eight other things happen as well that affect the macro economy.

583
00:41:26.330 --> 00:41:29.680
Right?
And disentangling who got who,

584
00:41:29.900 --> 00:41:34.900
how much the tax cuts were responsible for happened versus how much many other

585
00:41:37.190 --> 00:41:39.320
things that happened were responsible.

586
00:41:39.800 --> 00:41:42.350
Nobody really knows.

587
00:41:43.400 --> 00:41:47.780
Or if you look at the current debate we've watched and are watching unfold about

588
00:41:47.781 --> 00:41:50.090
the economic stimulus.

589
00:41:51.700 --> 00:41:56.700
If the economy turns around between now and November,

590
00:41:57.890 --> 00:42:02.600
you know,
the Democrats will probably do a lot better than if it doesn't.

591
00:42:03.330 --> 00:42:06.770
Um,
but you know,
the Republicans will say,
well,

592
00:42:06.771 --> 00:42:11.270
it would have turned around faster if we hadn't had all this taxation,

593
00:42:12.120 --> 00:42:14.900
you know,
and Paul Krugman will say,
well,

594
00:42:14.901 --> 00:42:18.260
it would have turned around even faster if we'd had more taxation.

595
00:42:18.860 --> 00:42:23.860
And so a lot of the problem in debating incentives once you get into the real

596
00:42:26.061 --> 00:42:31.061
world of macro economic policy making is that a,

597
00:42:33.111 --> 00:42:34.780
you never have the counterfactual.

598
00:42:34.910 --> 00:42:39.290
You can't go and rerun history without the stimulus.
Right.
Well,

599
00:42:39.291 --> 00:42:44.240
without the Reagan tax cuts and be the sheer complexity.

600
00:42:44.241 --> 00:42:48.500
So many other things happen.
The price of oil goes up or the,
you know,

601
00:42:48.501 --> 00:42:53.420
commodities collapse or the dollar or this or that or the Chinese,
you know,

602
00:42:53.421 --> 00:42:54.254
revalued,

603
00:42:54.560 --> 00:42:59.560
do or don't change the value of that currency so that when it gets down to it,

604
00:43:04.280 --> 00:43:05.720
when it gets down to it,

605
00:43:07.250 --> 00:43:11.630
you're not going to get a definitive answer to the question.

606
00:43:11.930 --> 00:43:14.960
What is the point of practical equality?

607
00:43:14.990 --> 00:43:18.500
When are we past the point of practical equality?

608
00:43:19.940 --> 00:43:20.430
<v 2>Okay.</v>

609
00:43:20.430 --> 00:43:22.740
<v 0>To use Bentham's terminology,
oh,</v>

610
00:43:22.741 --> 00:43:25.500
we close to it and we gone by it or we know where near it.

611
00:43:25.980 --> 00:43:29.490
You know there've been periods in our history when we've had marginal top

612
00:43:29.491 --> 00:43:31.890
marginal tax rates of 90%

613
00:43:34.540 --> 00:43:35.373
<v 2>right?</v>

614
00:43:35.480 --> 00:43:40.480
<v 0>Reagan thought a top marginal tax rate of 40% was beyond the point of practical</v>

615
00:43:42.410 --> 00:43:43.243
equality.

616
00:43:43.880 --> 00:43:47.480
You never going to get a definitive resolution of those questions,

617
00:43:48.620 --> 00:43:53.270
but if we think back to what the aspiration of the early enlightenment was,

618
00:43:53.570 --> 00:43:55.040
it was certainty

619
00:43:59.060 --> 00:44:01.810
to use.
The example,

620
00:44:01.820 --> 00:44:06.820
remember I read you from Hobbs is six professors of his epistle dedicated re on

621
00:44:07.551 --> 00:44:09.710
the to the six professors of mathematics.

622
00:44:10.130 --> 00:44:13.190
He said for the things we don't make,

623
00:44:14.540 --> 00:44:17.510
we can't know.
We can only guess about the causes,

624
00:44:18.370 --> 00:44:19.203
<v 2>right?</v>

625
00:44:20.560 --> 00:44:23.080
<v 0>Well here we are guessing about the causes.</v>

626
00:44:24.070 --> 00:44:29.070
We don't really know and there will be the people who want either policy will be

627
00:44:29.411 --> 00:44:31.360
able to find a plausible,

628
00:44:31.470 --> 00:44:36.000
a set of experts to defend their view.

629
00:44:36.270 --> 00:44:41.220
So you get into this very messy world of macro economic prediction.

630
00:44:43.780 --> 00:44:48.780
If you want to put some limits on the radical edge of classical utilitarianism

631
00:44:52.560 --> 00:44:55.770
[inaudible] as a matter of history,
that's not how it went.

632
00:44:56.820 --> 00:44:59.340
As a matter of history.
How it went

633
00:45:00.870 --> 00:45:05.870
was to rethink the analytical structure of utilitarianism in a way that

634
00:45:08.371 --> 00:45:13.371
completely defanged it's radical redistributive edge without any reference to

635
00:45:15.751 --> 00:45:20.751
these messy macro economic considerations and just how that happened in the

636
00:45:22.171 --> 00:45:26.340
transition from classical to what we're going to call neoclassical

637
00:45:26.341 --> 00:45:30.990
utilitarianism is the subject with which I will begin on Wednesday.

638
00:45:31.320 --> 00:45:31.770
See you then.

