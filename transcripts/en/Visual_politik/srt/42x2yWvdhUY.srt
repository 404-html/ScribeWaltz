1
00:00:09,000 --> 00:00:09,833
Many of you may have experienced doubts 
about certain future technological 

2
00:00:12,711 --> 00:00:13,544
advancements.
I mean don't deny it's a fear of 

3
00:00:14,931 --> 00:00:16,760
technology,
of artificial intelligence,

4
00:00:16,761 --> 00:00:20,120
of autonomous cars or factories with our
work as a smart robots,

5
00:00:20,121 --> 00:00:22,760
it's totally fine if I think of odd jobs
being taken away.

6
00:00:22,761 --> 00:00:25,190
If a few gaining power at the expense of
others,

7
00:00:25,250 --> 00:00:26,083
inequalities multiplying,
it's even machines controlling us and 

8
00:00:28,611 --> 00:00:30,950
taking over the world.
It's scary stuff.

9
00:00:31,030 --> 00:00:32,030
Well,
but I'm an adult.

10
00:00:32,110 --> 00:00:37,110
I always pickwick,
no enemy and this boy my arm.

11
00:00:42,890 --> 00:00:45,560
It's like kind of machines really 
replace human beings.

12
00:00:45,561 --> 00:00:46,394
Could they really manage to teach 
themselves and take control of 

13
00:00:48,921 --> 00:00:49,754
civilization?
What role are people going to play in a 

14
00:00:59,851 --> 00:01:00,684
world of intelligent machines folks,
this fear of change of the unknown of 

15
00:01:04,291 --> 00:01:05,124
the future.
Has it become something like our own 

16
00:01:07,020 --> 00:01:07,853
21st century Phantom,
a fanzine that is now moving all around 

17
00:01:11,281 --> 00:01:12,900
the planet.
Although you know what?

18
00:01:12,960 --> 00:01:14,760
Truthfully,
this is nothing new.

19
00:01:14,790 --> 00:01:16,920
The relationship between human beings 
and machines,

20
00:01:16,921 --> 00:01:19,350
it's never been simple.
It is always awakened.

21
00:01:19,380 --> 00:01:20,213
Mixed Feeling,

22
00:01:25,020 --> 00:01:25,853
oh go has landed cause that the same 
noise you heard when you signed your 

23
00:01:30,211 --> 00:01:31,330
sportswear contract.

24
00:01:33,440 --> 00:01:34,600
Fair them.
Then there's others.

25
00:01:34,610 --> 00:01:35,443
Even as an opportunity for progress,
there are those who view them with 

26
00:01:37,641 --> 00:01:40,250
distrust and those who view them as 
great allies,

27
00:01:40,310 --> 00:01:41,143
and of course there are always those who
predicted that because of all these 

28
00:01:43,101 --> 00:01:45,740
machines,
the end of humanity is getting nearer.

29
00:01:45,800 --> 00:01:46,790
By the way,
before we can send you,

30
00:01:46,791 --> 00:01:47,624
what group do you belong to,
you let me know in the comments below 

31
00:01:49,491 --> 00:01:51,890
and also we've got a survey about it at 
the end of the video.

32
00:01:51,891 --> 00:01:54,260
So check that out.
And of course along with all these fairs

33
00:01:54,261 --> 00:01:55,094
are the typical contradictions that 
always arise just because the machines 

34
00:02:00,381 --> 00:02:01,214
take our jobs and at the same time we 
complain about the mundane and 

35
00:02:03,681 --> 00:02:06,560
exhausting jobs to which many employees 
are subjected,

36
00:02:06,590 --> 00:02:09,260
especially the least qualified ones or 
for example,

37
00:02:09,261 --> 00:02:10,094
another very typical contradiction.
Almost every day we hear union leaders 

38
00:02:12,771 --> 00:02:13,604
demanding a shorter work day while at 
the same time rejecting or wanting to 

39
00:02:16,581 --> 00:02:17,414
hold technology,
which you know would actually lead to 

40
00:02:19,521 --> 00:02:20,430
that shorter work.
Yeah.

41
00:02:22,870 --> 00:02:23,230
Then

42
00:02:23,230 --> 00:02:24,063
there's one of my favorites.
Many politicians continually denounce 

43
00:02:26,600 --> 00:02:27,433
workers,
low purchasing power while they place 

44
00:02:29,110 --> 00:02:33,040
obstacles and even pro habits 
technologies that increased productivity

45
00:02:33,100 --> 00:02:33,933
and lower prices.
Maybe you've thought about the taxi 

46
00:02:35,501 --> 00:02:36,334
sector runs platforms like Uber.
We at visual politics certainly half of 

47
00:02:39,161 --> 00:02:41,800
course to view it in the end,
adapting to new changes.

48
00:02:41,820 --> 00:02:42,653
It tends to be just a matter of time.
Do you know a single person who worries 

49
00:02:46,390 --> 00:02:49,360
about jobs that have disappeared because
of mobile phones?

50
00:02:49,420 --> 00:02:50,253
Do you know anyone who wants to ban 
electric power because it can hard to 

51
00:02:52,660 --> 00:02:54,700
candle factory workers,
but it's true.

52
00:02:54,730 --> 00:02:55,563
As we mentioned before,
the arrival of artificial intelligence 

53
00:02:57,971 --> 00:03:01,300
has led to some questions and some new 
challenges,

54
00:03:01,330 --> 00:03:04,360
but before we talk all about that,
let's look back at the history.

55
00:03:06,080 --> 00:03:06,913
Okay.

56
00:03:12,320 --> 00:03:13,550
Fear of change.

57
00:03:14,230 --> 00:03:15,063
Sure.

58
00:03:16,490 --> 00:03:17,323
The political speeches we hear everyday,
they pose nothing new and the lungs 

59
00:03:21,081 --> 00:03:24,890
raised about technological changes.
They come directly from such speeches.

60
00:03:24,950 --> 00:03:25,783
Seek from the very beginning,
from the time human beings lived in 

61
00:03:28,491 --> 00:03:29,324
caves,
humanity has progressed thanks to the 

62
00:03:31,371 --> 00:03:36,020
use of tools together to cultivate.
Do you conserve food,

63
00:03:36,021 --> 00:03:39,260
ought to improve productivity.
It's all because of tools.

64
00:03:39,320 --> 00:03:42,200
Tools have given us the chance to 
achieve better lives.

65
00:03:42,290 --> 00:03:43,160
In fact,
nowadays,

66
00:03:43,170 --> 00:03:47,150
community is experiencing the greatest 
welfare and all of its history.

67
00:03:47,190 --> 00:03:48,023
Sure.

68
00:03:49,000 --> 00:03:51,340
However,
during a particular moment in history,

69
00:03:51,341 --> 00:03:55,120
tools and machines became something like
an enemy to be beaten,

70
00:03:55,240 --> 00:03:56,073
at least for a certain part of society.
We're of course talking about the time 

71
00:03:59,201 --> 00:04:00,034
of the industrial revolution.
This is despite the fact that the 

72
00:04:02,171 --> 00:04:06,810
industrial revolution meant a huge leap 
in terms of welfare for billions of,

73
00:04:06,820 --> 00:04:11,050
yeah,
does that at the time,

74
00:04:11,051 --> 00:04:15,150
machines began to be used widely.
Protests against them multiplied and its

75
00:04:15,151 --> 00:04:18,940
movements of all kinds emerged against 
the use of new technologies.

76
00:04:18,970 --> 00:04:22,090
The basic argument was that so many 
machines would leave artisans,

77
00:04:22,091 --> 00:04:24,180
workers and peasants out of what.

78
00:04:24,570 --> 00:04:25,403
Okay.

79
00:04:26,410 --> 00:04:27,243
Famous of these reactions was that of 
the Luddites who you were at the 

80
00:04:29,621 --> 00:04:30,454
beginning of the 19th century,
promoted attacks against factories and 

81
00:04:33,011 --> 00:04:36,640
especially against machines.
They hated them with all their might and

82
00:04:36,641 --> 00:04:40,390
of course had to destroy them because a 
world with machines would be terrible.

83
00:04:41,590 --> 00:04:43,090
Between you and me,
let's just say that,

84
00:04:43,091 --> 00:04:45,010
thank goodness they didn't get their 
way.

85
00:04:45,040 --> 00:04:45,873
I mean,
can you really imagine what life would 

86
00:04:46,841 --> 00:04:48,730
be like?
But before we continue,

87
00:04:48,820 --> 00:04:51,850
here's a question.
What do you think about trains?

88
00:04:51,910 --> 00:04:52,743
Do you like them?
Do you think they useful or maybe you 

89
00:04:54,281 --> 00:04:55,960
consider them dangerous?
The channels is,

90
00:04:55,961 --> 00:04:58,870
are you probably think that they're 
worth having around.

91
00:04:58,900 --> 00:05:01,180
While the eighth president of the United
States,

92
00:05:01,181 --> 00:05:02,014
President Martin van Buren,
he wouldn't agree with you as Michael 

93
00:05:05,530 --> 00:05:07,570
Cox and Richard Alm tell us in that 
book,

94
00:05:07,600 --> 00:05:10,360
myths of the rich and poor,
why we're better off than we think.

95
00:05:10,420 --> 00:05:14,560
In 1829 Martin van Buren,
who was very concerned about the dangers

96
00:05:14,561 --> 00:05:15,394
of the railroad,
he was so concerned that he even wrote 

97
00:05:17,831 --> 00:05:19,420
to the president,
Andrew Jackson,

98
00:05:19,421 --> 00:05:22,510
to asking to push a railroad ban.
Yep.

99
00:05:22,570 --> 00:05:23,403
You heard that,
right?

100
00:05:25,530 --> 00:05:26,363
Martin van Buren thought that the 
railroad would risk the jobs of 

101
00:05:28,771 --> 00:05:29,604
thousands of people who worked in 
deliveries and in canals and boat 

102
00:05:32,641 --> 00:05:33,870
construction.
In fact,

103
00:05:33,871 --> 00:05:34,704
since Van Buren also thought that it 
ships were essential to defend the 

104
00:05:37,021 --> 00:05:37,854
United States,
so you considered the railroad to be a 

105
00:05:39,421 --> 00:05:41,190
serious threat to national scale.

106
00:05:44,480 --> 00:05:47,330
Not all in that same letter addressed to
President Andrew Jackson.

107
00:05:47,360 --> 00:05:48,193
Van Buren also warns about the danger of
a transportation system that moved a 

108
00:05:51,411 --> 00:05:53,690
whopping 24 kilometers per hour.

109
00:05:57,670 --> 00:05:58,503
Yeah.

110
00:06:03,650 --> 00:06:04,431
Yes.
These arguments,

111
00:06:04,431 --> 00:06:07,670
they do seem a bit ridiculous nowadays,
but at the time,

112
00:06:07,671 --> 00:06:11,450
many people took these ideas very 
seriously and it's okay.

113
00:06:11,510 --> 00:06:12,343
It's true.
Technological changes have caused 

114
00:06:13,821 --> 00:06:16,310
difficulties throughout history.
Think for example,

115
00:06:16,370 --> 00:06:19,070
about what happens with the development 
of telecommunications.

116
00:06:19,130 --> 00:06:21,590
See Wenzel often.
He became massive in its early days.

117
00:06:21,591 --> 00:06:22,424
When you wanted to talk to someone,
you gave an operator the name and 

118
00:06:24,471 --> 00:06:26,520
surname of the person you wanted to talk
to.

119
00:06:26,710 --> 00:06:27,543
Rehab.
Would you call it the charges on this 

120
00:06:28,811 --> 00:06:29,644
for me,
please?

121
00:06:29,800 --> 00:06:30,730
One moment please.

122
00:06:36,030 --> 00:06:38,910
The second half of the 20th century,
which really wasn't so long ago,

123
00:06:38,940 --> 00:06:42,720
tens of thousands of operators worked 
connecting long distance calls.

124
00:06:42,750 --> 00:06:44,580
There's of course,
made the calls very,

125
00:06:44,680 --> 00:06:45,240
yeah,

126
00:06:45,240 --> 00:06:46,073
stock tag,
the world's smallest slightest cellular 

127
00:06:47,981 --> 00:06:49,730
phone.
I can see the battery,

128
00:06:49,940 --> 00:06:52,590
one of the phone or anywhere like this,
man,

129
00:06:53,820 --> 00:06:54,760
how are you?

130
00:06:55,000 --> 00:06:55,833
By 1980 technology allowed 
communications to be made directly 

131
00:06:58,680 --> 00:07:00,690
without any intermediaries other than 
need.

132
00:07:00,720 --> 00:07:03,750
The operators became irrelevant in the 
calls became very,

133
00:07:03,751 --> 00:07:04,584
very cheap.

134
00:07:05,880 --> 00:07:08,820
So the question is what happened to all 
of the operators?

135
00:07:08,850 --> 00:07:11,400
Well,
they had to find new jobs and yes,

136
00:07:11,401 --> 00:07:15,300
I know adapting isn't always easy,
but evidently this change until often it

137
00:07:15,330 --> 00:07:17,940
was very beneficial for society as a 
whole.

138
00:07:17,970 --> 00:07:20,850
Communications,
it became easier and much cheaper.

139
00:07:20,910 --> 00:07:21,743
That's why the important thing is to 
generate lots of employment 

140
00:07:24,181 --> 00:07:28,410
opportunities within a society and to 
make it relatively easy to change jobs.

141
00:07:28,440 --> 00:07:29,273
Can you just imagine if a state,
if a government had forbidden these 

142
00:07:31,321 --> 00:07:32,154
positions from disappearing,
that country's communications would 

143
00:07:34,320 --> 00:07:35,153
still be very slow.
People would sometimes have to wait 

144
00:07:37,380 --> 00:07:40,680
hours to speak with someone and cools 
would be very expensive.

145
00:07:40,740 --> 00:07:41,573
All of this would have made the economy 
and the total number of jobs in that 

146
00:07:44,131 --> 00:07:46,410
country.
Not very good because folks,

147
00:07:46,440 --> 00:07:49,500
we tend to forget one thing now as you 
watch this video,

148
00:07:49,501 --> 00:07:52,840
your going through the time in history 
where technology is used them.

149
00:07:52,841 --> 00:07:53,410
Yeah.

150
00:07:53,410 --> 00:07:54,243
See,

151
00:07:56,870 --> 00:07:57,703
you know what?
It's also the time where people worked 

152
00:07:59,400 --> 00:08:00,410
the most.
In fact,

153
00:08:00,411 --> 00:08:01,244
it's curious,
but the countries that use the most 

154
00:08:02,721 --> 00:08:06,350
robots are precisely those that suffer 
the least unemployment,

155
00:08:06,380 --> 00:08:08,570
which is definitely not a bad thing.
Now,

156
00:08:08,571 --> 00:08:10,430
some of you might be thinking,
come on Simon,

157
00:08:10,431 --> 00:08:12,680
artificial intelligence,
that's going to be different.

158
00:08:12,710 --> 00:08:14,300
Well,
let's dive into that.

159
00:08:14,430 --> 00:08:19,430
Are you listening?
I'm of a,

160
00:08:22,981 --> 00:08:23,814
I,

161
00:08:25,310 --> 00:08:25,810
Debbie.
Have you,

162
00:08:25,810 --> 00:08:26,643
uh,
the time of artificial intelligence and 

163
00:08:28,420 --> 00:08:30,400
robots,
it's already here.

164
00:08:30,430 --> 00:08:31,263
Everyday we use more products and more 
services that function with artificial 

165
00:08:34,061 --> 00:08:34,894
intelligence from voice assistants do 
the autonomous cars that are already 

166
00:08:37,391 --> 00:08:39,130
beginning to circulate.
And yes,

167
00:08:39,160 --> 00:08:43,300
the speed with which this intelligence 
progresses is certainly impressive.

168
00:08:43,330 --> 00:08:44,163
We could say that artificial 
intelligence involves applying the 

169
00:08:46,151 --> 00:08:48,670
enormous power of computers to solve 
problems.

170
00:08:50,110 --> 00:08:51,430
Well,
in the last 30 years,

171
00:08:51,431 --> 00:08:55,980
the cost of computing capacity,
it became 200 times cheaper.

172
00:08:56,010 --> 00:08:56,843
To give you an idea of what this means,
we could say that if the car industry's 

173
00:08:59,400 --> 00:09:00,233
cost to devolved in the same way today,
high ends car would cost only for 10 

174
00:09:03,361 --> 00:09:05,430
thousandths of what it does.
Now,

175
00:09:05,460 --> 00:09:09,540
this would make it cheaper than a single
Venezuelan boulevard.

176
00:09:09,630 --> 00:09:12,240
And yes,
they've all of our under Nicolas Maduro,

177
00:09:12,540 --> 00:09:13,373
we won't eat those.
This evolution is precisely what 

178
00:09:18,631 --> 00:09:23,550
explains why today a playstation four 
costs less than $400 even if it is about

179
00:09:23,551 --> 00:09:27,570
2000 times more powerful than the Cray 
to supercomputer.

180
00:09:27,690 --> 00:09:29,550
One of the most famous computers in 
history,

181
00:09:29,551 --> 00:09:32,850
which beat all records back in 1984 and 
this computer,

182
00:09:32,880 --> 00:09:37,880
unlike the playstation four weighed two 
and a half tons and cost $18 million.

183
00:09:40,380 --> 00:09:45,150
Today a playstation four can perform 1.8
4 trillion floating point operations per

184
00:09:45,151 --> 00:09:45,984
second.
This would take a person approximately 

185
00:09:47,370 --> 00:09:48,203
60,000 years to do and it's precisely 
this enormous calculation capacity that 

186
00:09:52,441 --> 00:09:56,100
allows ais to replace us in several 
tasks.

187
00:09:58,090 --> 00:09:58,923
For example,
sooner or later the autonomous car will 

188
00:10:00,761 --> 00:10:01,594
end up imposing itself.
We simply wouldn't be able to compete 

189
00:10:03,881 --> 00:10:04,714
with its calculation abilities,
especially now that these machines have 

190
00:10:06,911 --> 00:10:09,640
managed to perceive their environment 
thanks to cameras,

191
00:10:09,760 --> 00:10:12,010
microphones and sensors.
So yes,

192
00:10:12,040 --> 00:10:12,873
based on how things are evolving,
it seems almost certain that in a 

193
00:10:15,491 --> 00:10:16,324
relatively short time,
many mechanical and routine jobs from 

194
00:10:18,911 --> 00:10:22,060
factories to the field will be carried 
out by smart machines.

195
00:10:25,990 --> 00:10:28,390
It means the productivity will increase 
the lawsons with us.

196
00:10:28,570 --> 00:10:31,900
That also means most people's well being
will also increase.

197
00:10:32,590 --> 00:10:33,423
I think the next 30 years people will 
only work four hours a day and maybe 

198
00:10:36,611 --> 00:10:39,820
four days a week.
My grandfather worked 16 hours a day and

199
00:10:39,821 --> 00:10:41,860
the farmland and he thought he was very 
busy.

200
00:10:41,980 --> 00:10:45,280
We work eight hours five days a week and
we think we are very busy.

201
00:10:45,340 --> 00:10:48,520
Jack Ma,
chairman of Alibaba and no Dallas.

202
00:10:48,550 --> 00:10:49,383
During this time,
many new jobs will be created of all 

203
00:10:51,311 --> 00:10:52,144
kinds because you see,
the question we may want to ask 

204
00:10:54,281 --> 00:10:57,820
ourselves is how close are the machines 
to surpassing us?

205
00:10:57,850 --> 00:10:59,700
Well,
for some tasks that really close,

206
00:10:59,710 --> 00:11:01,150
but for many,
not really.

207
00:11:01,270 --> 00:11:03,150
You see,
machines can compete very quickly,

208
00:11:03,160 --> 00:11:07,060
but they have problems learning.
Computers are very inefficient learners.

209
00:11:07,061 --> 00:11:09,910
They only recognize patterns after 
analyzing something.

210
00:11:09,911 --> 00:11:14,620
An overwhelming number of times since 
this is humanity's great advantage,

211
00:11:16,140 --> 00:11:20,140
the most advanced machine learning 
systems require thousands of examples to

212
00:11:20,141 --> 00:11:20,974
acquire new concepts.
While humans can generalize from a few 

213
00:11:23,501 --> 00:11:24,334
examples.
Many animals can learn from a limited 

214
00:11:26,261 --> 00:11:27,094
number of experiences,
but humans seem particularly good at 

215
00:11:29,741 --> 00:11:33,100
generalizing based on just a few 
experiences.

216
00:11:33,160 --> 00:11:33,993
Greg Corrado,
Stanford neuroscientist and director of 

217
00:11:36,491 --> 00:11:37,324
augmented intelligence at Google.
This explains why nowadays humans are 

218
00:11:40,781 --> 00:11:43,510
far superior in areas such as 
creativity,

219
00:11:43,540 --> 00:11:45,130
innovation,
intuition,

220
00:11:45,250 --> 00:11:46,480
and empathy.
Folks,

221
00:11:46,510 --> 00:11:48,700
nobody can predict the future,
but until now,

222
00:11:48,730 --> 00:11:52,480
machines have always meant more jobs and
better welfare for all

223
00:11:58,910 --> 00:12:01,670
in the near future.
It's almost certain that what is already

224
00:12:01,671 --> 00:12:02,504
happening will continue to happen.
Some jobs will be destroyed and many 

225
00:12:05,901 --> 00:12:08,900
others will be created and also need 
highly qualified ones,

226
00:12:08,930 --> 00:12:09,763
but jobs of all kinds,
and it's probably working hours will 

227
00:12:12,081 --> 00:12:14,720
decrease and to real wages will 
increase.

228
00:12:14,721 --> 00:12:15,554
Beyond that.
It's very hard to predict what may or 

229
00:12:16,851 --> 00:12:17,684
may not happen,
but let's not fall into the same 

230
00:12:19,221 --> 00:12:20,054
mistakes that former US president Martin
van Buren fell in Duke during his fear 

231
00:12:23,870 --> 00:12:24,703
and rejection of the railroad.
There are still many challenges to 

232
00:12:27,390 --> 00:12:31,250
overcome in the world such as poverty 
and environmental sustainability and the

233
00:12:31,251 --> 00:12:33,200
machines.
They can really help us a lot.

234
00:12:33,230 --> 00:12:35,870
But now as the alternate,
what's your perspective on ai?

235
00:12:35,900 --> 00:12:39,500
Do you leave your comments below as well
as in this survey?

236
00:12:39,550 --> 00:12:42,140
So I really hope you enjoyed the video.
Please do hit like if you did,

237
00:12:42,141 --> 00:12:44,660
and don't forget to subscribe for brand 
new videos.

238
00:12:44,661 --> 00:12:46,160
Also,
don't forget to check out our friends at

239
00:12:46,161 --> 00:12:46,994
the reconsider media podcasts.
They provided the vocals in this 

240
00:12:49,011 --> 00:12:50,150
episode,
but we're not mine.

241
00:12:50,151 --> 00:12:51,890
Also,
this channel is made possible because of

242
00:12:51,891 --> 00:12:52,724
our patrons on Patrion.
Please consider joining them and 

243
00:12:54,741 --> 00:12:58,190
supporting our mission of providing 
independent political coverage.

244
00:12:58,610 --> 00:13:00,620
And as always,
thank you for watching.

245
00:13:01,160 --> 00:13:02,110
We won't eat them.
Solution,

246
00:13:04,820 --> 00:13:07,780
start tagging the world's smallest,
slightest cellular phone.

247
00:13:08,030 --> 00:13:09,500
I can't even feed the battery.

