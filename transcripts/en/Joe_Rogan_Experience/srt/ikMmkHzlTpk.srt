1
00:00:02,970 --> 00:00:06,780
Ready, boom. And we're live.
Hello Lex. Hey, what's going on?

2
00:00:06,810 --> 00:00:11,400
The sequel part too. You have a very
similar, if not the exact same suit on.

3
00:00:11,490 --> 00:00:15,960
This is all I wear. You look very
professional, very reservoir dogs,

4
00:00:16,380 --> 00:00:20,340
reservoir dogs. What it was go to the best
secret of all time. Godfather, part two.

5
00:00:21,000 --> 00:00:22,140
Is that the best of you?
Go over on time.

6
00:00:22,170 --> 00:00:26,790
I think John Wick might be having
quick same. See how dare you sir.

7
00:00:28,260 --> 00:00:33,240
Godfather part two. I mean that's, that
has to be the best sequel. Okay then,

8
00:00:33,241 --> 00:00:37,680
and if this has godfather, part two,
it's definitely not do part three.

9
00:00:38,160 --> 00:00:40,230
Part three was terrible.
Right? Well let's,

10
00:00:40,260 --> 00:00:44,550
let's not offend anyone but it was not
as good. Yeah, I don't remember it.

11
00:00:45,510 --> 00:00:48,150
It was a, the older Pachino. Ah,

12
00:00:48,300 --> 00:00:51,780
would that depot voice that was
like way later, right? Yeah,

13
00:00:51,990 --> 00:00:56,670
that was nineties Oh, okay.
So it's like point break.

14
00:00:56,760 --> 00:01:01,200
The remix. Yes. When they try
to Redo things like way, way,

15
00:01:01,201 --> 00:01:04,590
way later, they almost never,
except the alien franchise.

16
00:01:04,740 --> 00:01:06,650
They've done a pretty fucking
good job with the Alien Fred.

17
00:01:06,660 --> 00:01:09,300
They had a couple of duds in there,

18
00:01:09,420 --> 00:01:14,010
but for the most part I've actually
never seen alien franchise. Who are you?

19
00:01:14,350 --> 00:01:17,310
What are you in a science?

20
00:01:17,311 --> 00:01:21,800
Intelligent men can disagree but
you're not in the science. I Dunno.

21
00:01:22,040 --> 00:01:25,850
I'd prefer prefer Al Pachino.
I would say that, uh,

22
00:01:25,930 --> 00:01:30,670
the older sent a woman an opportunity,
you know that really? Yeah. Watts

23
00:01:32,320 --> 00:01:35,610
come on the, yeah, he got
the Oscar for that one.

24
00:01:35,670 --> 00:01:40,470
What about the one when he played the
devil and the devil? Okay. There's,

25
00:01:40,471 --> 00:01:44,450
there's two. There's duds for everybody.
What was that one? That was advocate.

26
00:01:44,520 --> 00:01:47,820
Uh Huh. There you go. That
was a with counter Reeve.

27
00:01:48,500 --> 00:01:52,200
Kiana release from John Wick or John
Waite. Par threes are the Matrix.

28
00:01:53,280 --> 00:01:56,840
The better movie. Not True. Did
you see this? That happened? Uh,

29
00:01:56,850 --> 00:01:58,300
this high school in North Bergen Jersey.

30
00:01:58,301 --> 00:02:01,860
You put on the alien play a couple of
weeks ago. Garney weaver showed up.

31
00:02:02,190 --> 00:02:04,710
She showed up like a cut just the other
day to like say thanks or whatever.

32
00:02:05,040 --> 00:02:06,390
Tell him maybe to awesome.
Oh,

33
00:02:06,750 --> 00:02:10,200
it looked like crazy and I
was just wondering if they
did this when you were in

34
00:02:10,201 --> 00:02:11,910
high school.
Do you think he might've joined drama?

35
00:02:11,970 --> 00:02:16,050
Like if they did the alien play? Loved
it. One of the watched it. All right.

36
00:02:16,170 --> 00:02:19,950
I'm not getting into drama. Those people
cry too much. There's too much work.

37
00:02:20,130 --> 00:02:24,120
It's a cool suit though. Yeah.
Okay. Let's talk about this.

38
00:02:24,121 --> 00:02:25,200
There's two kinds of movies.

39
00:02:25,201 --> 00:02:29,610
There's fun movies and there's movies
that are like transformational for society

40
00:02:29,890 --> 00:02:31,590
gets sent to a woman.
What? Okay. Let's see.

41
00:02:31,591 --> 00:02:34,500
You kind of say scent of a woman
is transformational for society.

42
00:02:34,510 --> 00:02:39,030
One of the greatest scenes
between a man and a woman on film.

43
00:02:39,210 --> 00:02:42,510
The tango scene. Oh, you're not
married? No, I'm not married.

44
00:02:45,800 --> 00:02:49,260
It's like somewhat talking about French
who can't speak French. I see. Yeah.

45
00:02:49,350 --> 00:02:52,110
It's nonsense. I movie sucked.
I read about French in a book

46
00:02:54,060 --> 00:02:57,300
talking about France without ever
being to Paris. Scent of a woman.

47
00:02:57,301 --> 00:03:00,490
Your favorite movie? No,
it's not my favorite. I think
that movie sucked either.

48
00:03:00,491 --> 00:03:03,370
By the way, if you get mad right now, I
want to barely remember it, but it is,

49
00:03:03,371 --> 00:03:05,020
it is up there.
I'm sure it's a good movie.

50
00:03:05,110 --> 00:03:09,650
That's one of the greatest performances.
But Jesus Christ,

51
00:03:09,660 --> 00:03:11,470
you'll go off to a good start.
Yeah,

52
00:03:12,250 --> 00:03:15,040
I bet you there's thousands of
people agree with me right now. Yeah,

53
00:03:15,041 --> 00:03:19,720
there's millions that don't.
And they're called haters.

54
00:03:20,860 --> 00:03:23,140
Everyone had disagrees is always or,
okay.

55
00:03:23,141 --> 00:03:27,700
So what's your favorite love
scene in a movie? Not like,

56
00:03:27,940 --> 00:03:32,340
like between a man and get
married, Bro. Okay. No,

57
00:03:32,440 --> 00:03:34,300
I'm not fire yourself a gal.
There's a little down.

58
00:03:34,330 --> 00:03:38,130
We're not talking about romantic
comedies and I'm saying they're here. Uh,

59
00:03:38,290 --> 00:03:43,150
Romcoms we're talking about serious
like dramatic moments, right? Okay.

60
00:03:43,450 --> 00:03:46,580
So godfather movie,
great movie.

61
00:03:46,870 --> 00:03:50,830
Does it have to have two guys like
shooting each other or know like, okay,

62
00:03:51,070 --> 00:03:54,490
so if you're seeing central a woman.
Yeah, I'm sure I saw it. Yeah.

63
00:03:54,600 --> 00:03:57,430
But I barely remember it. All right,
well there's these, watch it today.

64
00:03:57,431 --> 00:03:59,920
It'd be like a new movie to me.
Okay. There's this broken man.

65
00:04:00,500 --> 00:04:04,570
We'll alert considering
suicide. Right? It's deep.

66
00:04:04,720 --> 00:04:08,940
So he is tortured by,
you know,

67
00:04:09,580 --> 00:04:11,970
by his involvement in the war,
by being responsible.

68
00:04:11,980 --> 00:04:13,210
They all have this kind of stuff.

69
00:04:13,450 --> 00:04:17,140
He's now mentoring a younger version
of himself, was more character,

70
00:04:17,141 --> 00:04:21,850
more integrity and throw out all of this.
He meets this beautiful young woman.

71
00:04:22,780 --> 00:04:27,340
He's blind for the dance and there's
this beautiful moment where they connect.

72
00:04:27,810 --> 00:04:31,630
I mean, okay, listen Phil, what's
the purpose of film, right.

73
00:04:31,960 --> 00:04:36,740
Entertainment or make us think.
I mean, make us think. Hmm.

74
00:04:37,480 --> 00:04:39,700
You know, you're going to
think if you want to think,

75
00:04:39,970 --> 00:04:44,530
nothing makes you think of
film can engage you. You can,

76
00:04:44,590 --> 00:04:45,940
it can resonate with you or not.

77
00:04:46,360 --> 00:04:50,060
I have a movie that I throw
by people whenever I want
to find out whether or not,

78
00:04:50,061 --> 00:04:52,010
I don't want to listen to anything
they have to say about movies.

79
00:04:53,140 --> 00:04:57,670
The Big Lebowski. Yeah. Yeah. That's one
of the greatest moves a lot that could be,

80
00:04:57,671 --> 00:04:59,880
oh, look at you. Okay.
That could be like, yeah,

81
00:05:00,100 --> 00:05:04,360
that could be like slightly
better than sent a woman. Oh boy.

82
00:05:04,900 --> 00:05:07,280
They had also has one of
the greatest scenes, uh,

83
00:05:07,840 --> 00:05:09,850
between a man and a woman when he is,
uh,

84
00:05:10,090 --> 00:05:15,090
when the fine young ladies painting her
toenails and she's offering them sex for

85
00:05:16,450 --> 00:05:19,960
money. Yeah. That would, that's a, that's
a beautiful moment to these beautiful,

86
00:05:19,990 --> 00:05:24,610
yeah. The comedian, that girl
that used to be a hot mess.

87
00:05:24,820 --> 00:05:28,940
What's her name? Tara Reid.
Yeah. She's still a hot masters.

88
00:05:28,950 --> 00:05:31,120
She got her shit together.
She's been like shark.

89
00:05:31,121 --> 00:05:34,010
The shark NATO series is what she's been,
she's in that.

90
00:05:35,800 --> 00:05:39,040
So I passed the big Lebowski test.
And you failed to sent a woman tests.

91
00:05:39,070 --> 00:05:40,970
I don't remember it.
I got to wrap this conversation.

92
00:05:43,670 --> 00:05:46,420
Legitimately. Don't remember
it. I mean, I'm sure it's great.

93
00:05:46,480 --> 00:05:49,750
I'm sure it's great if you're a wise
man, if you like it, I'm sure it's good.

94
00:05:50,020 --> 00:05:54,040
And you also recognize the godfather
three is kind of sucks. Yeah. Yeah.

95
00:05:54,070 --> 00:05:57,770
But I like the old Pachino reminisce.
Listen, Godfather is about,

96
00:05:58,460 --> 00:06:03,020
uh, your people. The Italian
people have dominated the mob,

97
00:06:03,230 --> 00:06:07,820
the brilliant mob movies, right?
I mean, godfathers about family,

98
00:06:08,120 --> 00:06:12,530
right. There's something
deeply like genuine about that,

99
00:06:12,531 --> 00:06:15,080
that like in our modern
society we really crave for.

100
00:06:15,300 --> 00:06:19,490
So it's like bigger than the individual.
Bigger than the rules of society.

101
00:06:19,820 --> 00:06:24,790
Government, the man. It's family
above all. Right. That, that's like a,

102
00:06:25,370 --> 00:06:27,690
I dunno, that's timeless. That's

103
00:06:29,540 --> 00:06:34,540
the moment with the young Pachino when
he talks to what his brother Fredo says,

104
00:06:34,821 --> 00:06:38,660
don't ever take sides against
the family again, ever. I mean,

105
00:06:38,661 --> 00:06:41,850
that's one of the greatest
moments. That's great moment. It's

106
00:06:44,180 --> 00:06:47,810
all right. All right. All right.
I'm a romanticizing a movies here,

107
00:06:48,190 --> 00:06:53,180
but like John Wick though.
Huh? Never seen it. Whoa.

108
00:06:53,270 --> 00:06:55,550
I've never seen it.
It's a good, excuse me.

109
00:06:56,190 --> 00:06:59,900
It's good movie to watch
on the treadmill is, uh,

110
00:06:59,990 --> 00:07:03,950
is he playing a Russian mobster and that
kills a bunch of them though.

111
00:07:04,490 --> 00:07:06,860
And he speaks Russian and
he works for the Russians.

112
00:07:07,520 --> 00:07:09,110
Kills people for the Russians.
You know,

113
00:07:09,140 --> 00:07:12,740
canneries is one of the greatest
human beings ever. I think so. Yeah.

114
00:07:12,741 --> 00:07:15,260
He's like the nicest guy I heard.
He's a really nice guy,

115
00:07:15,730 --> 00:07:18,830
but he plays a bad gangster. Oh, what
am I going to be a little bit more fit?

116
00:07:19,180 --> 00:07:22,310
Work out a little bit more. I've seen
him without a shirt on, like, hmm.

117
00:07:22,370 --> 00:07:26,390
Not quite buying it, but that's
okay. The average man. Yeah.

118
00:07:26,391 --> 00:07:29,450
But the average man's not the
fucking best assassin of all time

119
00:07:31,100 --> 00:07:35,170
with all this martial arts skill.
Like weight or yeah,

120
00:07:35,180 --> 00:07:39,310
but fate or his big fade or
might have like a gut buddies.

121
00:07:39,350 --> 00:07:42,520
A thick motherfucker.
Okay.

122
00:07:42,530 --> 00:07:46,100
Especially young fade or ever see
young fate or when he was in his prime,

123
00:07:46,400 --> 00:07:50,020
like back when he fought like
Fujita like back when, uh, this,

124
00:07:50,070 --> 00:07:53,040
there's a picture of fate or standing
around with a bunch of kettle bells.

125
00:07:53,041 --> 00:07:56,900
You ever see that picture? Nope.
I was fade. Oregon's lifting days,

126
00:07:57,200 --> 00:08:01,130
I suspect. And this is
coming from, that's,

127
00:08:01,160 --> 00:08:04,310
that's one when fader was fairly
young up there, but that's a,

128
00:08:04,400 --> 00:08:06,020
that's not the one I'm talking about.
You know,

129
00:08:06,021 --> 00:08:10,850
the one with the kettle bells is that
picture up CEB found that picture never a

130
00:08:10,851 --> 00:08:13,940
six pack insight. No, no six pack. But um,

131
00:08:15,350 --> 00:08:19,490
I suspect that fade or might have been
on some performance enhancing substances

132
00:08:19,491 --> 00:08:24,200
during his prime. You mean like hard
training? Lots of drilling technique. Uh,

133
00:08:24,860 --> 00:08:28,940
set of strategy, steroid hot dare
you sir. Dude, he was in pride.

134
00:08:28,940 --> 00:08:33,650
Everybody was on steroids. Yeah. That's
him. Look at him. That's him in his prime.

135
00:08:34,400 --> 00:08:38,360
Hmm. That's a big motherfucker now.
I do not know if he was on anything,

136
00:08:38,361 --> 00:08:40,880
but everybody else was, I
mean, literally everybody,

137
00:08:41,410 --> 00:08:44,360
they had it in their contract that you,

138
00:08:44,400 --> 00:08:48,290
we will not test for steroids.
You know, ensign anyway.

139
00:08:48,300 --> 00:08:52,340
Told me that they like essentially
encouraged people to take steroids. Yeah.

140
00:08:52,341 --> 00:08:53,810
The pride days.
That's right.

141
00:08:54,350 --> 00:08:58,680
It's not like Russians don't have a long
history of using performance enhancing

142
00:08:58,681 --> 00:09:03,300
substances. You, I'm sure you saw that
movie, um, acreages. Did you see it? Yup.

143
00:09:03,360 --> 00:09:08,280
Fascinating. Right. It's, it's a, it's
fascinating. I mean, I, I don't, uh,

144
00:09:08,281 --> 00:09:11,850
steroids often feel to me like
a bit of a witch hunt. Uh,

145
00:09:11,851 --> 00:09:16,440
oftentimes you assume people
are on steroids. I'm a bit of a,

146
00:09:16,470 --> 00:09:18,540
maybe I'm naive or an optimist,

147
00:09:18,600 --> 00:09:22,440
but I tend to give people the benefit
of the doubt until proven otherwise.

148
00:09:22,830 --> 00:09:26,910
But a curious obviously proves that it
was kind of throws a monkey wrench of

149
00:09:26,911 --> 00:09:29,340
those gears.
But you know with a,

150
00:09:29,341 --> 00:09:34,260
with fate or the technique and
that technique to execution,

151
00:09:34,261 --> 00:09:38,160
the timing, the brilliance of his
movement, no doubt that heart, no,

152
00:09:38,200 --> 00:09:41,310
he was phenomenal. I just want to, if
not the greatest heavyweight of all time,

153
00:09:41,311 --> 00:09:44,550
he certainly one of them and I don't think
steroids would help that. Yes, they do.

154
00:09:44,730 --> 00:09:47,640
They help. Yeah. They held that guy
particular, yeah. They help everything.

155
00:09:47,850 --> 00:09:50,670
They help you training, they help your
business, your ability to recover.

156
00:09:50,671 --> 00:09:55,370
They help your explosive power, they help
your speed. They help everything that,

157
00:09:55,480 --> 00:09:59,280
but they also, it's not just
steroids, like a lot of them on EPO,

158
00:10:00,210 --> 00:10:00,631
Epo,

159
00:10:00,631 --> 00:10:05,340
radically in enhances your endurance and
they're starting to catch people need

160
00:10:05,341 --> 00:10:09,630
they just a stripped Tj Dillashaw the
UFC bantamweight champion for start for a

161
00:10:09,640 --> 00:10:14,400
EPO or other, it's tragic. Yes,
it is tragic. Especially Tj,

162
00:10:14,460 --> 00:10:18,360
you mean he's a just a phenomenal fighter.
If not,

163
00:10:18,860 --> 00:10:23,790
I mean certainly top 10 pound for pound
and then this is one of those things

164
00:10:23,791 --> 00:10:26,880
that comes up and you go,
oh man,

165
00:10:27,180 --> 00:10:32,180
it's a legacy killer and this world we
have to kind of reconsider what kind of

166
00:10:32,191 --> 00:10:36,430
a, what should be allowed and not,
yeah, I agree with that. That there,

167
00:10:36,431 --> 00:10:41,310
there is an idea of what you should
make stair was legal or not legal,

168
00:10:41,311 --> 00:10:45,400
sorry, uh, a lot or some kind
of supplementation like, well,

169
00:10:45,410 --> 00:10:46,770
where's the line when you,

170
00:10:46,800 --> 00:10:49,920
when you start to talk about the future
of martial arts, the future sport,

171
00:10:50,670 --> 00:10:53,280
if you can control the levels
so that they're healthy. I mean,

172
00:10:53,281 --> 00:10:58,281
isn't that the reason that they're
not allowed is because if abused,

173
00:10:58,690 --> 00:11:03,090
they become unhealthy. Uh, they damaged
longterm wellbeing of the person. There's,

174
00:11:03,720 --> 00:11:05,010
look,
if that was the case,

175
00:11:05,011 --> 00:11:09,360
we wouldn't allow fighting because
fighting is more damaging and steroids for

176
00:11:09,361 --> 00:11:10,560
sure,
for sure.

177
00:11:10,561 --> 00:11:14,820
Getting punched and kicked and fucking
need in the face and elbowed into

178
00:11:14,821 --> 00:11:18,050
unconsciousness that is way worse
for you than steroids there.

179
00:11:18,060 --> 00:11:21,850
The concern is not for the athlete,
the concerns for the opponent. Um,

180
00:11:21,870 --> 00:11:26,010
the idea is that you will be able to
inflict punishment that you would not

181
00:11:26,011 --> 00:11:29,610
ordinarily be able to inflict.
You will have more endurance,

182
00:11:29,611 --> 00:11:33,630
you will have more power, you will
hurt someone potentially even look,

183
00:11:33,870 --> 00:11:37,590
there's going to be a time where someone
dies in a mixed martial arts of that.

184
00:11:37,860 --> 00:11:42,860
And if that's someone who was the
victor who did not die was on steroids,

185
00:11:43,140 --> 00:11:48,140
it is going to be a huge national tragedy
and a massive disaster for the sport,

186
00:11:51,421 --> 00:11:56,380
for everything. If that ever does
happen, we can only hope it never does.

187
00:11:56,410 --> 00:11:59,230
But for sure, you know,
it's a, it's a very,

188
00:11:59,231 --> 00:12:01,930
very dangerous game you're
playing and when you are,

189
00:12:02,560 --> 00:12:04,060
martial arts is a very dangerous game.

190
00:12:04,330 --> 00:12:08,590
And when you are enhancing your body
with chemicals that are illegal while

191
00:12:08,591 --> 00:12:11,680
you're doing that game,
the real question is though,

192
00:12:12,040 --> 00:12:17,040
here's my take on it and this is w is
it's one of the most human subjects.

193
00:12:18,220 --> 00:12:22,900
And that being meaning, meaning
that it's messy. Humans are messy.

194
00:12:22,990 --> 00:12:25,090
Like there's good and there's bad,
you know,

195
00:12:25,300 --> 00:12:29,440
look like abortion is a messy subject.
It's messy. You know, whether you have,

196
00:12:30,160 --> 00:12:34,150
whether you agree with someone's
right to have it or not, it is.

197
00:12:34,330 --> 00:12:39,160
What you're doing is, especially as
the fetus gets older, it's messy.

198
00:12:39,730 --> 00:12:42,820
You know, when it's a complicated
discussion, it's not a clear,

199
00:12:43,210 --> 00:12:45,550
it's not like you should drink water.
You know what I mean? And it's like,

200
00:12:45,580 --> 00:12:50,410
it's a very complicated
discussion. Steroids are a
very complicated discussion.

201
00:12:50,411 --> 00:12:54,340
You're not allowed to do them,
but they exist for a reason.

202
00:12:54,341 --> 00:12:57,130
The reason why they exist
is they're really effective.

203
00:12:57,310 --> 00:12:59,350
They're really effective
at enhancing your body.

204
00:12:59,750 --> 00:13:03,130
But how much of that will we allow?
We allow Korea team,

205
00:13:03,160 --> 00:13:07,010
we allow supplements in terms
of, you know, there's, uh,

206
00:13:07,030 --> 00:13:11,380
there's certain things that can slightly
elevate your testosterone slightly

207
00:13:11,381 --> 00:13:12,460
elevate your growth hormone.

208
00:13:12,461 --> 00:13:16,360
We allow sauna on ice baths and all
these things that have shown to enhance

209
00:13:16,361 --> 00:13:20,800
recovery. But that's, that's too much.
It's too good there, too effective.

210
00:13:21,210 --> 00:13:22,300
Which,
but it's weird.

211
00:13:22,630 --> 00:13:26,470
It's weird that this thing that we found
that makes you better, you can't use.

212
00:13:26,980 --> 00:13:31,390
Yeah. And so I have to go back a little
bit and disagree with you on something.

213
00:13:31,391 --> 00:13:35,860
So in terms of fighting being dangerous
and that's if we want it to forbid

214
00:13:36,250 --> 00:13:38,260
things that are dangerous for
you would fitbit fighting?

215
00:13:38,470 --> 00:13:42,180
I think the main thing you're
doing can be dangerous, right?

216
00:13:42,580 --> 00:13:47,200
The main thing that we're talking
about, the sport, the combat event,

217
00:13:47,500 --> 00:13:50,200
that can be dangerous because
that is what we watch.

218
00:13:50,440 --> 00:13:53,860
Two people at the height of their skill,
ability,

219
00:13:53,861 --> 00:13:58,570
heart passion, putting their life
at risk. That can be dangerous.

220
00:13:58,780 --> 00:14:02,980
But the supplementation around
it, the way to make it, uh,

221
00:14:03,430 --> 00:14:07,360
to make their training better, more
effective, that can be dangerous.

222
00:14:07,361 --> 00:14:10,360
And I thought that can't be named,
can't be dangerous.

223
00:14:10,361 --> 00:14:13,300
So I thought steroids were considered,

224
00:14:13,301 --> 00:14:18,301
were sort of band because abuses
lead to longterm damage to health.

225
00:14:18,910 --> 00:14:20,770
Now we see steroids as cheating,

226
00:14:21,730 --> 00:14:25,930
but it was banned initially
because it has detrimental effects.

227
00:14:25,960 --> 00:14:27,640
You think that's true? It's not. No,

228
00:14:27,641 --> 00:14:30,190
because there's no real
evidence that it's detrimental.

229
00:14:30,191 --> 00:14:33,320
It's not as detrimental as alcohol when
you allow people to drink, bid even, uh,

230
00:14:33,570 --> 00:14:37,630
a bit even when abused, where the bodies,
like there's, there's not a lot of,

231
00:14:37,790 --> 00:14:41,910
like there's a great documentary on it
called bigger, stronger, faster. And, uh,

232
00:14:41,980 --> 00:14:43,480
it's about my friend Chris Bell.

233
00:14:43,810 --> 00:14:46,990
And when you watch that
documentary and you realize like,

234
00:14:46,991 --> 00:14:51,991
oh well did the real negative consequences
of taking steroids or that it shuts

235
00:14:53,121 --> 00:14:57,920
down your endocrine system so it stops
your body's natural production of

236
00:14:57,921 --> 00:15:02,180
testosterone and growth hormone and
hormones, that's the real problem.

237
00:15:02,270 --> 00:15:05,780
And for young people that can be
very devastating and they can lead to

238
00:15:05,781 --> 00:15:08,040
depression and suicidal thoughts and all,

239
00:15:08,200 --> 00:15:11,300
all sorts of really bad things
when your testosterone shuts down.

240
00:15:11,900 --> 00:15:16,400
But as far as like death boy,
I mean there's,

241
00:15:17,480 --> 00:15:19,610
people are prescribed
pain pills every day,

242
00:15:19,611 --> 00:15:23,960
the week and fighters that are on
injuries, uh, that have been, you know,

243
00:15:23,990 --> 00:15:25,230
that have gotten surgery.
They,

244
00:15:25,231 --> 00:15:29,060
they're prescribed pain pills everyday
of the week and those pain pills kill

245
00:15:29,061 --> 00:15:31,220
people left and right.
And that's just a fact.

246
00:15:31,580 --> 00:15:35,360
People die of those things all the time,
much more so than die of steroids.

247
00:15:35,920 --> 00:15:39,610
So I'm not advocating for the use
of steroids. Right. I'm just, I'm,

248
00:15:39,730 --> 00:15:42,350
I'm being pretty objective
and neutral about this,

249
00:15:42,351 --> 00:15:46,610
but I'm just looking at it like it is
a, it's a very messy subject. Yeah.

250
00:15:46,611 --> 00:15:48,350
It's very eloquently put.
But so,

251
00:15:48,770 --> 00:15:53,400
so your problem in terms of damaging the
opponent is if one side takes terrorism.

252
00:15:54,200 --> 00:15:58,090
Exactly what happens if both, the problem
is you would require someone do that,

253
00:15:58,100 --> 00:15:59,930
that maybe someone's a holistic person.

254
00:15:59,931 --> 00:16:04,931
They don't want it introduce any unnatural
exogenous steroids into their body

255
00:16:05,931 --> 00:16:08,060
and hormones in their body.
They want,

256
00:16:08,450 --> 00:16:12,230
they want everything to be produced
by the human body. They want to,

257
00:16:12,470 --> 00:16:14,930
they want to eat healthy food,
train hard,

258
00:16:14,931 --> 00:16:18,830
sleep well and compete naturally had
CT Fletcher here yesterday, right? Yes.

259
00:16:18,860 --> 00:16:23,660
Is Natural Bodybuilder. Yes. Not
Body build powerlifter outlet. Yeah,

260
00:16:23,850 --> 00:16:28,400
but that's not required. Right. This
is, you're not requiring people,

261
00:16:28,520 --> 00:16:31,730
you're giving them the choice.
So you know,

262
00:16:31,731 --> 00:16:34,970
it's an interesting possibility where
in moderation you'll be able to allow

263
00:16:34,971 --> 00:16:39,971
steroids and future of athletics because
with an argument that if I had done a

264
00:16:40,611 --> 00:16:44,420
moderation, you can actually create
healthier athletes. Yeah. That's,

265
00:16:44,421 --> 00:16:47,390
I mean that's a real argument for the
Tour de France, the Tour de France,

266
00:16:47,391 --> 00:16:51,450
they say that you actually are better
off and healthier taking steroids. Yeah.

267
00:16:51,820 --> 00:16:53,990
And Epo.
Then you are doing it without it.

268
00:16:53,991 --> 00:16:58,640
Cause it's so unbelievable that you're
ruling on the body. I mean those athletes,

269
00:16:58,780 --> 00:16:59,271
I basically,

270
00:16:59,271 --> 00:17:03,590
some of the best people in the world
at suffering long term suffering,

271
00:17:03,860 --> 00:17:06,830
it's incredible. Ultra marathon
runners, all those guys,

272
00:17:08,070 --> 00:17:10,880
it's incredibly different sort of thing.
You know.

273
00:17:10,881 --> 00:17:13,970
And you know the thing about
ultra marathon runners,

274
00:17:13,971 --> 00:17:17,060
there's didn't even test them
cause they're like, good luck.

275
00:17:17,690 --> 00:17:19,520
Those people have iron.
Will's like,

276
00:17:19,540 --> 00:17:23,150
I don't know if it like Courtney dual
Walters, a woman who, you know, she is,

277
00:17:24,110 --> 00:17:25,760
she's been in here,
she eats candy,

278
00:17:26,020 --> 00:17:28,790
just drinks beer each candy
and pizza make sense? Yeah.

279
00:17:28,820 --> 00:17:33,820
I mean she's just got fucking iron will
or her will is indomitable and you could

280
00:17:34,701 --> 00:17:37,460
take all the steroids you want
when you're running for three days.

281
00:17:37,790 --> 00:17:41,870
That chick is going to beat you.
He just doesn't know how to quit.

282
00:17:42,250 --> 00:17:43,730
Just has no quit in.

283
00:17:43,740 --> 00:17:46,790
Did you see the podcast with her
where she talked about how she fell?

284
00:17:47,000 --> 00:17:50,010
She couldn't see. She was
in experiencing, uh, I think

285
00:17:50,010 --> 00:17:53,520
it was inner ocular
hemorrhaging. Yeah. So her,

286
00:17:53,550 --> 00:17:56,040
her eyeballs were bleeding internally,

287
00:17:56,070 --> 00:17:59,340
something like that where it was
impeding her vision. She couldn't say,

288
00:17:59,970 --> 00:18:04,500
I would stop. I would stop running.
No, she fell because you couldn't see,

289
00:18:04,620 --> 00:18:09,480
busted her head open, bleeding all down.
Her face keeps running. Barely, barely.

290
00:18:09,481 --> 00:18:11,790
Can see her feet as she's running,
keeps running.

291
00:18:12,450 --> 00:18:15,940
I'm glad those people
are out there like that.

292
00:18:16,490 --> 00:18:19,590
Like I don't know how to
quit. Really? Yeah. I'm like,

293
00:18:19,591 --> 00:18:24,420
I do a lot of stuff like
that. Like stupid. Like I ran
yesterday. I couldn't sleep.

294
00:18:24,570 --> 00:18:29,490
I ran here yesterday, 13 miles. I'm not a
runner. Just, just this weird obsession.

295
00:18:29,520 --> 00:18:33,650
Do you don't run. I run, but I'm not
a runner. I look at my body. I'm a,

296
00:18:34,170 --> 00:18:36,720
I have a similar body like yours.
We're not exactly,

297
00:18:36,960 --> 00:18:41,430
we'd do like better built for short
sprinting and then maybe killing somebody

298
00:18:41,431 --> 00:18:46,080
with our hands
versus a long distance.

299
00:18:46,300 --> 00:18:49,980
You're a black belt in Jujitsu, right?
Yeah. Yeah. Where do you train it now?

300
00:18:49,981 --> 00:18:54,120
Train at Broadway. Jiu in
Boston. Nice. And that's, uh,

301
00:18:54,140 --> 00:18:58,290
and before I was in, in Philly, balanced
studios with film and movies and so on.

302
00:18:58,870 --> 00:19:03,610
Uh, but Cobb Bochniac I actually
transcend Broadway. Oh really?

303
00:19:03,611 --> 00:19:06,960
I love that car. Yeah, he a
I had last time was on it.

304
00:19:06,961 --> 00:19:09,380
I actually wanted to talk about this,
a bead fight cause I'm,

305
00:19:09,460 --> 00:19:13,920
I'm rushing so I loved the Russian
way. But I also love the, I mean Kyle,

306
00:19:13,970 --> 00:19:17,850
Timmy represents like the American,
he's like the rocky, if you,

307
00:19:17,851 --> 00:19:19,920
if you remember that fight with the,
against the deep,

308
00:19:20,550 --> 00:19:25,290
the third round he was winning. I mean
that's the best of what martial arts is.

309
00:19:25,291 --> 00:19:29,760
MMA is to me is like you
have two technicians,

310
00:19:30,090 --> 00:19:34,860
they just throw everything
away. Like screw this, I'm
just going to throw it out.

311
00:19:34,970 --> 00:19:35,461
Was it beat?

312
00:19:35,461 --> 00:19:38,970
Had broken his hand broke his hand
somewhere I think in the second round.

313
00:19:39,030 --> 00:19:41,430
So he was pretty compromised
going into the third round.

314
00:19:41,431 --> 00:19:45,420
I couldn't really fire back and
Kyle was just has zero Quintin them.

315
00:19:45,600 --> 00:19:48,150
The guy's an animal. Yeah. I
mean that's the most beautiful,

316
00:19:48,330 --> 00:19:51,690
you talk about like technical fights
in the ground or technical striking.

317
00:19:51,870 --> 00:19:56,250
Like when like two technicians throw
everything away. That's, I'm sorry.

318
00:19:56,251 --> 00:19:58,160
But that's what is the,
uh,

319
00:19:58,170 --> 00:20:01,680
that I'd get a love the most about any
kind of fighting, any kind of sport.

320
00:20:01,860 --> 00:20:04,860
I enjoy it in the moment.
I discourage it heavily.

321
00:20:05,010 --> 00:20:07,420
I don't think it's a smart way
to fight. Yeah, well that's,

322
00:20:08,120 --> 00:20:12,840
that's probably your job is my job.
It's like what I like, like I get,

323
00:20:14,280 --> 00:20:18,240
I get the impulse, but I don't want
people to give into the impulse.

324
00:20:18,300 --> 00:20:22,770
I think fighting is something
that you should do correctly.

325
00:20:23,080 --> 00:20:24,420
You should do, you should do, there's,

326
00:20:24,421 --> 00:20:27,300
there's principles that you
should follow to fight correctly.

327
00:20:28,860 --> 00:20:32,370
It doesn't mean that you shouldn't
take chances, but you know,

328
00:20:32,371 --> 00:20:34,800
there's moments like, um, um,

329
00:20:36,480 --> 00:20:38,510
Ricardo Lamas when,
uh,

330
00:20:38,550 --> 00:20:43,550
he fought Max Holloway and they just
stood in the center of the ring for the

331
00:20:44,940 --> 00:20:48,300
last few seconds of the fight and Max
Holloway pointed down at the ground and

332
00:20:48,310 --> 00:20:49,660
he's like, come on right here, right here.

333
00:20:49,661 --> 00:20:53,920
And they just started so wing in Heymach.
It was amazing. Well, it happened,

334
00:20:54,340 --> 00:20:58,900
but if I was in Max's corner,
I'd be like, don't, no,

335
00:20:59,230 --> 00:21:03,460
don't do that, man. This macho shit is
going to give you fucking brain damage.

336
00:21:03,670 --> 00:21:06,670
You're going to get hit with shots he
wouldn't get hit with. That's a difficult,

337
00:21:06,760 --> 00:21:10,870
like you said, human nature is messy.
I would say that is the greatest.

338
00:21:11,770 --> 00:21:15,910
That is the greatest moment of
their lives. What? That war?

339
00:21:15,970 --> 00:21:17,860
No,
listen,

340
00:21:18,780 --> 00:21:21,770
this is the greatest moment
of Max Holloway's like Max
Holloway is the greatest

341
00:21:21,880 --> 00:21:25,340
featherweight all time discussion.
No,

342
00:21:25,360 --> 00:21:28,050
but Max Holloway is the greatest
featherweight of all time.

343
00:21:28,060 --> 00:21:32,920
He's the guy who destroyed José
Aldo twice. He's a guy that he's,

344
00:21:33,010 --> 00:21:35,470
he's beaten everybody in
front of him at featherweight.

345
00:21:35,740 --> 00:21:40,660
The idea that this one moment where they
decided to throw out all his skill and

346
00:21:40,661 --> 00:21:44,140
technique and just swing for the
bleachers in the middle of the octagon.

347
00:21:44,230 --> 00:21:46,660
It was a fun moment.
It was great to watch,

348
00:21:46,990 --> 00:21:49,330
but the idea that that was the
greatest moment of his life, his word.

349
00:21:49,390 --> 00:21:53,170
You're a crazy person. Yeah. There's
moments in sports. They're just magic.

350
00:21:53,200 --> 00:21:57,090
Olympics. Bring that when like the thing
that you don't think should happen,

351
00:21:57,110 --> 00:22:01,150
it can't possibly happen or is not wise
where people just throw everything away.

352
00:22:01,280 --> 00:22:05,740
Yeah. Yeah. A passion person.
Fashion Person. Yeah, for sure.

353
00:22:06,640 --> 00:22:10,150
That's an interesting thing for someone
who studies artificial intelligence.

354
00:22:10,151 --> 00:22:13,180
I mean if anybody listened to his podcast,
but what the fuck does this guy do?

355
00:22:13,990 --> 00:22:16,180
Our dogs.
They talk about movies.

356
00:22:17,020 --> 00:22:21,190
So many people talk about
Sean was vehicle. We are,

357
00:22:21,250 --> 00:22:23,650
we have plenty of time sir.
We have plenty of time.

358
00:22:23,950 --> 00:22:26,350
But that's the beautiful thing about
this podcast. We're just talking.

359
00:22:27,250 --> 00:22:29,050
So tell me what you got
here with your notes man.

360
00:22:29,260 --> 00:22:33,760
I mean you are fucking prepared. I
mean, yeah, a lot of shit here. Many,

361
00:22:33,761 --> 00:22:37,540
many pages for sure. I don't want to miss,
I don't miss stuff. I mean there's a,

362
00:22:37,840 --> 00:22:41,830
there's been a lot of exciting stuff on
the autonomous vehicle space since you

363
00:22:41,831 --> 00:22:42,460
came on.

364
00:22:42,460 --> 00:22:46,480
I got a Tesla and I've experienced what
that thing is like when I put it on

365
00:22:46,481 --> 00:22:49,210
autopilot and it's stunning.
It's crazy.

366
00:22:49,540 --> 00:22:53,010
I mean this is in terms of the
performance of the v amazing well in,

367
00:22:53,011 --> 00:22:57,970
in terms of its ability to change lanes
and its ability to drive without you

368
00:22:57,971 --> 00:22:58,750
doing anything.

369
00:22:58,750 --> 00:23:01,840
I just put my hand on the wheel and
hold it there and it does all the work.

370
00:23:02,260 --> 00:23:05,650
So because like one or two
people listened to this podcast,

371
00:23:05,890 --> 00:23:09,940
I want to take this opportunity and
tell people, if you drive a Tesla,

372
00:23:10,300 --> 00:23:13,570
whether you listen to this now or a
year from now, two years from now,

373
00:23:13,900 --> 00:23:17,890
Tesla or any other car,
keep your damn eyes on the road.

374
00:23:18,490 --> 00:23:21,550
So whatever you think
the system is able to do,

375
00:23:22,090 --> 00:23:27,090
you will have to still monitor the road
and you still have to take over when it

376
00:23:27,161 --> 00:23:31,270
fails, if, when really.

377
00:23:32,080 --> 00:23:36,040
So
we're throwing,

378
00:23:36,520 --> 00:23:39,190
this is like the moment where
throwing down right now.

379
00:23:39,191 --> 00:23:42,580
I think it's an express your
level of expertise obviously.

380
00:23:42,790 --> 00:23:46,340
I mean I'm not throwing down with you
on, no, I think it's really important

381
00:23:46,370 --> 00:23:50,790
to, in this transitionary phase,
whatever the car company, uh,

382
00:23:50,810 --> 00:23:54,110
whatever the system that we
don't overtrust the system,

383
00:23:54,111 --> 00:23:57,050
we don't become complacent. We don't
think he could do more than he can.

384
00:23:57,800 --> 00:24:02,270
Currently. 40,000 people die in the
United States from, from fatal crashes.

385
00:24:02,540 --> 00:24:06,880
The number one reason for that is
distraction. So texting, smartphones,

386
00:24:06,910 --> 00:24:08,900
how much has it gone up since smartphones,

387
00:24:09,740 --> 00:24:12,710
people don't exactly where
they're trying to understand that.

388
00:24:13,250 --> 00:24:16,670
There's a lot of studies showing
that it's significant increases,

389
00:24:16,671 --> 00:24:20,090
but it's hard to say it's because of
smartphones, but it's almost obvious.

390
00:24:20,220 --> 00:24:21,290
I mean it's pretty obvious.

391
00:24:21,590 --> 00:24:26,510
The flip side is even though everybody's
not using a smart phone, texting,

392
00:24:26,511 --> 00:24:29,720
so on, they've become better
at using the smartphone.

393
00:24:30,170 --> 00:24:34,790
So they're better at texting and driving.
The better balancing that.

394
00:24:34,940 --> 00:24:39,110
Now this is a horrible thing to do.
So if you're listening to this podcast,

395
00:24:39,470 --> 00:24:44,150
you should listen to it in your car and
keep your eyes on the road and not text.

396
00:24:44,210 --> 00:24:47,750
I think worst was Pokemon when Pokemon

397
00:24:48,560 --> 00:24:49,640
was in its prime.

398
00:24:49,670 --> 00:24:54,010
I was watching a guy on the highway
playing Pokemon as he was driving and uh,

399
00:24:54,050 --> 00:24:56,810
no more than one person. Two
people, a guy. And I saw a girl,

400
00:24:56,840 --> 00:25:01,070
dude wants to holding the phone on
the steering wheel. Playing Pokemon.

401
00:25:01,680 --> 00:25:04,400
Yeah. Yeah. It's incredible.
What are you doing Jeremy?

402
00:25:06,180 --> 00:25:07,890
That's GRANDPA's. Oh Shit. Sorry.

403
00:25:10,860 --> 00:25:14,700
I'm confused. What does this,
uh, this grandpa in Japan,
he drives around on a bike.

404
00:25:14,820 --> 00:25:19,330
Oh, playing Pokemon. All, it's
the same exact time. This guys,

405
00:25:19,380 --> 00:25:23,410
15 phones. It's ridiculous.
This guy needs to find hookers.

406
00:25:23,411 --> 00:25:26,610
There's people that do this also in
their car with maybe four or five doing

407
00:25:26,680 --> 00:25:30,480
exactly what you're saying. This man needs
a better hobby. This is preposterous.

408
00:25:30,960 --> 00:25:32,820
Look at the,
look at his file.

409
00:25:32,830 --> 00:25:34,710
He can't see what the fuck's
going on in front of him.

410
00:25:35,340 --> 00:25:40,340
He spends about $300 a month to
buy virtual currencies in the game.

411
00:25:41,520 --> 00:25:46,230
Wow. That guy's board or in
an innovative genius thing.

412
00:25:46,290 --> 00:25:47,123
In that perspective,

413
00:25:47,350 --> 00:25:52,080
when people misuse their
innovative Josie innovative,

414
00:25:52,081 --> 00:25:54,750
he's just playing a stupid game while
he's driving around on his bike like an

415
00:25:54,751 --> 00:25:59,640
asshole. Well, he's doing is
back to the set of a woman thing.

416
00:26:00,120 --> 00:26:02,640
It's passion.
It's the most amazing moment of his life.

417
00:26:03,920 --> 00:26:08,700
I'm sure most people are on my side
scent of a woman versus you think most

418
00:26:08,701 --> 00:26:09,540
people are on your side.

419
00:26:09,541 --> 00:26:11,730
They think Santam a woman is the
greatest movie of all that to a woman,

420
00:26:11,731 --> 00:26:13,920
but I was defending GFE
father sent him a woman.

421
00:26:14,040 --> 00:26:15,870
You weren't defending
godfather against me. I mean,

422
00:26:15,871 --> 00:26:17,620
I'm going to throw you under the plan.
Okay.

423
00:26:19,260 --> 00:26:23,070
I'm going to manipulate this conversation.
Jamie, can you edit this in post?

424
00:26:23,220 --> 00:26:26,250
Did you see the video that
just came out yesterday of a,

425
00:26:26,260 --> 00:26:30,840
a Tesla on autopilot avoiding
a crash. All right, so yeah,

426
00:26:30,841 --> 00:26:33,210
I have and there's a lot of example.
Quite a few of those.

427
00:26:33,400 --> 00:26:34,690
Yeah,
of course.

428
00:26:34,691 --> 00:26:37,870
It's like hard to prove exactly what
happened and where the auto Paul was

429
00:26:37,871 --> 00:26:39,580
involved.
Just like on the flip side,

430
00:26:39,581 --> 00:26:42,730
it's hard to prove that autopilot
was involved in the dangerous stuff,

431
00:26:42,880 --> 00:26:47,880
but think by any measure the media
is really negative in terms of their

432
00:26:48,661 --> 00:26:50,860
reporting on Tessa there I think,

433
00:26:51,650 --> 00:26:54,750
I think you've talked to
this about before in general,

434
00:26:54,751 --> 00:26:59,751
negativity gets more clicks and I
think Tesla negative stuff on Tesla,

435
00:27:00,811 --> 00:27:05,180
it gets a lot of clicks so
and well not Tesla. Let,

436
00:27:05,181 --> 00:27:08,820
let me speak more broadly about autonomous
vehicles. If there's any fatality,

437
00:27:08,850 --> 00:27:12,420
any crash, it's overrepresented,
it's over reported on.

438
00:27:12,780 --> 00:27:17,780
So I need to meet people
who are interested in AI
helping save lives in these

439
00:27:18,901 --> 00:27:20,100
systems like autopilot.

440
00:27:20,820 --> 00:27:25,820
I feel you carry the responsibility of
being at least as good of a driver you

441
00:27:26,521 --> 00:27:29,430
are when it's under manual control.
So don't text and drive.

442
00:27:29,610 --> 00:27:33,750
Keep your eyes on the road by saying
anything over and over in this podcast is

443
00:27:33,751 --> 00:27:38,010
that drunk driving of course is the
other one. And so don't drink and drive,

444
00:27:38,011 --> 00:27:42,890
but the number one thing is distracted
driving. So put your phone down. I agree.

445
00:27:44,880 --> 00:27:49,500
Um, listen to some music, some
classic Rock Classic Rajoy. Yeah,

446
00:27:49,780 --> 00:27:53,690
yeah. Click credence into a no, no, no.

447
00:27:54,300 --> 00:27:56,940
Like it. Like you would
change the channel. Now you're
going to put me in this,

448
00:27:57,580 --> 00:28:01,950
of course. The side.
There you go. I take a,

449
00:28:01,951 --> 00:28:06,810
I take my shirt off.
No.

450
00:28:06,820 --> 00:28:07,540
Uh,

451
00:28:07,540 --> 00:28:11,100
Glen Lynyrd Skinner course,
Hendrix course called jerks.

452
00:28:11,260 --> 00:28:14,860
And I have to admit something. I thought
about messaging you a couple of times.

453
00:28:15,300 --> 00:28:19,540
Uh, I wanted to, I play
guitar. Do you? Yeah,

454
00:28:21,860 --> 00:28:22,693
you can't,

455
00:28:23,090 --> 00:28:26,900
are you good at Jujitsu? Yeah, I'm good.
Okay. I'm on black belt. I'm pretty good.

456
00:28:27,590 --> 00:28:31,240
You're a black belt too. I'm sure you're
good. Yeah. I'm not world class and A,

457
00:28:31,241 --> 00:28:34,880
I'm on use. Fuck me up. I'm a three
striped purple belt guitar. Ah,

458
00:28:34,910 --> 00:28:37,460
that's a good way of putting it. Yeah.
Yeah. I say that. What about hunting?

459
00:28:37,461 --> 00:28:38,510
I'm like a blue belt hunting.

460
00:28:38,540 --> 00:28:40,700
Yeah. Yeah, yeah.

461
00:28:40,701 --> 00:28:45,650
I've been doing it like I got the purple
belt by doing it a long time as opposed

462
00:28:45,651 --> 00:28:49,880
to being amazing. But you take lessons
now. I learned everything myself.

463
00:28:49,881 --> 00:28:52,670
I have a couple of videos online.
Me playing comfortably numb.

464
00:28:53,420 --> 00:28:57,650
Learn from watching videos or did you
learn from books? Like how did you like,

465
00:28:57,651 --> 00:28:58,410
let me see this.

466
00:28:58,410 --> 00:29:00,240
Give me this.
Look at you.

467
00:29:03,000 --> 00:29:04,890
It's going to get us food off of Youtube.

468
00:29:05,860 --> 00:29:07,230
Yeah, this is going to play. No, no, no.

469
00:29:08,570 --> 00:29:12,700
It probably won't pick it up and if it
picks it up it'll be to my channel and

470
00:29:12,701 --> 00:29:17,320
I'll shot. It's me playing.
What do you mean it's so good.

471
00:29:17,321 --> 00:29:19,960
It sounds like people from
humming songs for you.

472
00:29:20,540 --> 00:29:23,050
But so this is on youtube and this
is the, no, I didn't know that.

473
00:29:23,051 --> 00:29:24,160
But this didn't get blocked.

474
00:29:24,190 --> 00:29:28,630
If you were humming a song and then
someone made a claim on that song,

475
00:29:28,690 --> 00:29:29,750
it would block our,

476
00:29:29,800 --> 00:29:34,170
our youtube like literally we could
get demonetized and put we could,

477
00:29:34,310 --> 00:29:37,630
we lose our streaming and bill. Lots
of things can happen. Lots of things.

478
00:29:37,720 --> 00:29:39,850
It's fucked up man.
Like we've,

479
00:29:39,851 --> 00:29:44,380
we've gotten flagged for
watching something on the screen,

480
00:29:44,590 --> 00:29:47,650
picture in picture,
no sound commenting on it,

481
00:29:47,740 --> 00:29:51,640
and we get flagged and they want all the
advertising revenue from a three hour

482
00:29:51,641 --> 00:29:56,050
show for five, 10 seconds of a video.
It's a slightly broken system. Ooh,

483
00:29:56,051 --> 00:30:00,520
it's broken. But there's a lot of scam
artists too. So I, I played another song,

484
00:30:00,880 --> 00:30:04,470
black Betty. Oh yeah. And
I got, I don't know. Yeah,

485
00:30:04,880 --> 00:30:08,890
I played the damn song. But they,
they said it was, it wasn't,

486
00:30:08,891 --> 00:30:10,620
they did exactly that.
Oh,

487
00:30:10,640 --> 00:30:15,280
they said it was the ram jam or whatever
it said it was there and I may have

488
00:30:15,281 --> 00:30:19,770
borrowed beat behind it from them. I'm
not sure. I just took all the like,

489
00:30:20,390 --> 00:30:22,420
yeah. Well that's what I was
thinking about that song.

490
00:30:22,421 --> 00:30:25,510
Like it sounded like there was other
shit going on besides just your guitar.

491
00:30:27,910 --> 00:30:31,390
Oh No, that's all me real. It's all
made bad. The back we had that again.

492
00:30:31,391 --> 00:30:33,700
That's really good, man. He sounded good.

493
00:30:33,790 --> 00:30:35,980
That's a great fucking song
to comfortably numb. You know,

494
00:30:35,981 --> 00:30:40,150
the scariest thing for me to
play guitar on this podcast.

495
00:30:40,210 --> 00:30:43,720
So I was like going back and forth. Oh
really? I do it. Should I not do it?

496
00:30:43,750 --> 00:30:45,570
Actually play, play, play. And the only,

497
00:30:45,700 --> 00:30:48,900
it was only a few people that
ever played play Everlast um,

498
00:30:49,000 --> 00:30:51,400
Ben and Suzanne from honey, honey. Uh,

499
00:30:51,490 --> 00:30:54,520
Gary Clark didn't write and he just came
on and talked and he brought his guitar.

500
00:30:55,390 --> 00:30:59,110
I wanted to play a Hendrix here.
Really live life.

501
00:30:59,380 --> 00:31:03,130
You got it right with you right
now in the torture? Yeah. Well, no,

502
00:31:03,131 --> 00:31:06,280
I meant I was okay.
Sure. If in the future,

503
00:31:06,281 --> 00:31:10,900
and I'm not promising I scare you
were a Hendrix wig with a Bandana.

504
00:31:11,290 --> 00:31:15,940
Is that racially insensitive though?
You're allowed to Joe.

505
00:31:16,060 --> 00:31:21,010
I will not take it. As I said face. You're
allowed. Okay. The hair is like, just,

506
00:31:21,011 --> 00:31:25,180
you know, it's just hair. Is this how
you can't wear dreadlocks? So, yeah.

507
00:31:25,181 --> 00:31:29,770
So there's rules, but I think you, yeah,

508
00:31:29,771 --> 00:31:33,710
there's rules. I just, Hendricks is
above all the rules though, right? Well,

509
00:31:34,540 --> 00:31:39,430
he's the goat of guitar players.
That's the goat. One of them.

510
00:31:39,550 --> 00:31:42,800
You know the reason why this
call, the show's called, yeah,

511
00:31:43,150 --> 00:31:46,060
I stole it from Jimmy
Hendrix. Yeah. What's mine.

512
00:31:46,870 --> 00:31:48,490
I don't remember if we
brought this up last time,

513
00:31:48,491 --> 00:31:51,220
but I just remember seeing this video
where you're playing guitar while you were

514
00:31:51,221 --> 00:31:55,390
driving. Yup. Well you shouldn't do that,
dude. It's the reason why he was doing it.

515
00:31:56,110 --> 00:31:59,800
Why are you doing that on a test
track? Oh, what kind of car is that?

516
00:32:00,080 --> 00:32:04,000
Looks at the Lincoln Lincoln Mkc. Yes sir.
Oh, they do that? The Lincolns do that.

517
00:32:04,001 --> 00:32:08,170
We converted it and we,
that's The r code controlling the car.

518
00:32:08,200 --> 00:32:11,110
Wow.
That is crazy.

519
00:32:12,310 --> 00:32:17,290
So you converted this car to drive
autonomous Thomas? They, yeah. Wow.

520
00:32:17,520 --> 00:32:18,850
And what,

521
00:32:19,060 --> 00:32:23,920
what exactly do you have
to do to a car to change?

522
00:32:24,060 --> 00:32:26,410
Like, because that car
does not have the capacity,

523
00:32:26,440 --> 00:32:30,940
the capacity to do anything like that.
So the right my correct.

524
00:32:31,150 --> 00:32:36,040
No, no, no, no, absolutely not. But
you are absolutely correct. The,

525
00:32:36,160 --> 00:32:38,950
there's the first part is being able
to control the car with a computer,

526
00:32:38,960 --> 00:32:40,010
which is converting it

527
00:32:40,010 --> 00:32:43,940
to be drive by wire so you can control
the steering and the braking acceleration

528
00:32:44,390 --> 00:32:47,030
to, to basically be able
to control with a joystick.

529
00:32:47,090 --> 00:32:51,000
And then you have to put laser sensors
all around the cars that we need to kind

530
00:32:51,010 --> 00:32:54,590
of sensor and a software.
So what's the best kind of sensor?

531
00:32:54,670 --> 00:32:58,370
Is it the cold laser? A lot of
debate on this. And this is the big,

532
00:32:58,400 --> 00:33:01,670
this is the throwdown between
Elon Musk and everybody else. Oh,

533
00:33:01,671 --> 00:33:03,470
they all Musk says the best sensors,

534
00:33:03,471 --> 00:33:08,330
camera everybody else while everybody
else says that at this time,

535
00:33:08,331 --> 00:33:11,360
Lidar,
which are these lasers is the best sensor.

536
00:33:11,630 --> 00:33:16,630
So that I'm more on the side in
this case on camera and Elan Musk.

537
00:33:17,870 --> 00:33:21,440
So here's the difference. Lasers are
more precise. They worked better in,

538
00:33:21,800 --> 00:33:24,860
in poor lighting conditions.
They're more reliable.

539
00:33:25,040 --> 00:33:28,250
You can actually build safe
systems today that use lidar.

540
00:33:29,240 --> 00:33:33,200
The problem is that they don't have,
they're much information.

541
00:33:33,350 --> 00:33:38,150
So we use our eyes to drive and
uh, cameras, the same thing.

542
00:33:38,600 --> 00:33:40,820
And they have just a lot more information.

543
00:33:41,000 --> 00:33:43,510
So if you're going to build
artificial intelligence systems,

544
00:33:43,511 --> 00:33:47,450
so machine learning systems that learn
from huge amounts of data cameras,

545
00:33:47,451 --> 00:33:50,810
the way to go because you can learn so
much more. You can see so much more.

546
00:33:51,200 --> 00:33:54,890
So the, the richer,
deeper censor his camera,

547
00:33:55,040 --> 00:33:58,820
but it's much harder.
You have to collect a huge amount of data.

548
00:33:59,030 --> 00:34:02,030
It's a little bit more futuristic.
So it's longer term solution.

549
00:34:02,240 --> 00:34:06,290
So today to build a safe vehicle,
you have to go lidar tomorrow,

550
00:34:06,860 --> 00:34:11,270
however you define tomorrow, he almost
says it's an a year. Others say it's five,

551
00:34:11,271 --> 00:34:16,070
10, 20 years cameras the way to go. So
that's, that's the, the hard debate.

552
00:34:16,071 --> 00:34:18,890
And there's, there's a lot of other
debates, but that's one of the core ones.

553
00:34:19,190 --> 00:34:23,690
It's basically for camera, you, if you
go camera, like you're doing the Tusla,

554
00:34:23,720 --> 00:34:28,070
there's seven cameras in your
Tesla, uh, three looking forward,

555
00:34:28,071 --> 00:34:32,420
there's all around, so on
one looking inside, no, you
have the model s yeah, yeah.

556
00:34:32,421 --> 00:34:35,960
So that, that one doesn't have a camera
that's looking inside. So it's all,

557
00:34:36,050 --> 00:34:39,530
all cameras plus radar
and ultrasonic sensors.

558
00:34:40,550 --> 00:34:44,180
That approach requires collecting huge
amounts of data. And they're doing that.

559
00:34:44,240 --> 00:34:49,240
They drove now about 1.3
billion miles under autopilot.

560
00:34:49,820 --> 00:34:54,080
She uses, yeah, it's, it's a,
it's a very large amount of data.

561
00:34:54,081 --> 00:34:58,130
So you're talking about over
500,000 vehicles have autopilot,

562
00:34:58,520 --> 00:35:03,520
450 I think thousand have the new version
of autopilot autopilot to which is the

563
00:35:05,721 --> 00:35:10,010
one you're driving and all of
that is data. So all of those,

564
00:35:10,040 --> 00:35:11,630
all the edge cases,
what they call them,

565
00:35:11,631 --> 00:35:16,580
all the difficult situations that occur
is feeding the machine learning system

566
00:35:16,970 --> 00:35:19,190
to become better and better and better.

567
00:35:19,430 --> 00:35:24,260
And the open question is how much better
does need to get to get to the human

568
00:35:24,261 --> 00:35:28,370
level performance?
And like one of the big thing,

569
00:35:28,820 --> 00:35:31,350
one of the big assumption,

570
00:35:31,351 --> 00:35:36,080
so a Cema beings is that we think that
driving is actually pretty easy and we

571
00:35:36,081 --> 00:35:38,040
think that humans suck at driving

572
00:35:38,610 --> 00:35:40,590
those two assumptions.
Do you think like driving it,

573
00:35:40,820 --> 00:35:42,000
you know you stay in the lane,

574
00:35:42,001 --> 00:35:45,150
you stop at the stop sign is
pretty easy to to automate.

575
00:35:45,450 --> 00:35:50,450
And then the other one is you think
like humans are terrible drivers and so

576
00:35:50,760 --> 00:35:54,390
there'll be easy to build a machine
that outperforms humans are driving now.

577
00:35:54,391 --> 00:35:56,040
There is,
that's a,

578
00:35:56,070 --> 00:36:01,070
I think there's a lot of flaws behind
that intuition we take for granted how

579
00:36:01,081 --> 00:36:05,490
hard it is to look at the scene.
Like everything you just did picked up,

580
00:36:05,491 --> 00:36:06,780
moved around some objects.

581
00:36:07,500 --> 00:36:11,430
It's really difficult to build
an artificial intelligence
system that does that.

582
00:36:11,700 --> 00:36:15,060
To be able to perceive and understand
the seen enough to understand the physics

583
00:36:15,061 --> 00:36:19,620
of the scene. Like all these objects
that it like how to pick them up,

584
00:36:19,710 --> 00:36:20,940
the texture of those objects,

585
00:36:20,970 --> 00:36:25,920
the weight to understand glasses
folded and unfolded, open water bottle,

586
00:36:25,980 --> 00:36:29,970
all those things is common sense
knowledge that we take for granted.

587
00:36:30,240 --> 00:36:35,240
We think it's trivial but there is no
artificial system in the world today.

588
00:36:35,520 --> 00:36:40,520
Nor will there be for perhaps quite a
while that can reason do that kind of

589
00:36:40,651 --> 00:36:45,120
common sense. Reasoning about the
physical world. Add to that, uh,

590
00:36:45,780 --> 00:36:46,650
pedestrians.

591
00:36:47,130 --> 00:36:51,180
So add some crazy people in this room
right now to the whole scene and being

592
00:36:51,181 --> 00:36:53,700
able to notice like, or this guy is
an asshole look and what was he doing?

593
00:36:53,730 --> 00:36:56,520
What does he know? And get off that
skateboard out. Jesus isn't traffic yet.

594
00:36:56,700 --> 00:37:01,200
And the considering, not that he's an
asshole, he's a respectable skateboarder.

595
00:37:03,440 --> 00:37:08,340
It that in order to make
him behave a certain way,

596
00:37:08,520 --> 00:37:10,290
you yourself have to behave a certain way.

597
00:37:10,291 --> 00:37:12,720
So it's not just you have
to perceive the world,

598
00:37:13,050 --> 00:37:17,040
you have to act in a way that you have
to assert your presence in this world.

599
00:37:17,160 --> 00:37:18,840
You have to take risks.

600
00:37:19,200 --> 00:37:21,810
So in order to make the skateboard
and not cross the street,

601
00:37:21,811 --> 00:37:25,760
you have to have accelerate if you have
the right away. And these are that,

602
00:37:25,761 --> 00:37:28,890
there's a game theoretic
game of chicken to get right.

603
00:37:29,100 --> 00:37:32,910
I mean we don't even know how
to approach that as a, as uh,

604
00:37:32,970 --> 00:37:37,740
artificial intelligence sort of research
community and also as a society do we

605
00:37:37,741 --> 00:37:42,741
want an autonomous vehicle that speeds
up in order to make a pedestrian not

606
00:37:43,291 --> 00:37:46,560
cross the street,
which is what we do all the time.

607
00:37:46,950 --> 00:37:50,880
We have to assert our presence.
If there's a,

608
00:37:50,890 --> 00:37:53,700
if there's a person who doesn't have the
right of way, it could begins crossing.

609
00:37:54,000 --> 00:37:57,960
We're going to either maintain speed or
speed up potentially if we want them to

610
00:37:57,961 --> 00:38:02,100
not cross. So that, that
game there to get that right.

611
00:38:02,130 --> 00:38:05,010
That's a dangerous game for a robot.
It's for a robot.

612
00:38:05,100 --> 00:38:07,800
And for us to be rationally,

613
00:38:08,580 --> 00:38:10,830
if that God forbid,

614
00:38:10,831 --> 00:38:15,120
least of fatality for us as a society
to rationally reason about that.

615
00:38:15,121 --> 00:38:15,954
I think about that.

616
00:38:16,110 --> 00:38:19,710
I mean a fatality like that could
basically bankrupt the company.

617
00:38:19,800 --> 00:38:23,650
There's a lawsuit going on
right now, um, about uh, uh,

618
00:38:23,910 --> 00:38:27,900
an accident in northern
California with the Tesla. Yeah.

619
00:38:28,770 --> 00:38:30,680
And Are you aware of,
well yeah, that one. Yeah,

620
00:38:30,690 --> 00:38:33,990
this was the circumstances about that one.
So there was a,

621
00:38:34,000 --> 00:38:36,250
I believe in mountain view,

622
00:38:36,640 --> 00:38:39,460
a fatality and a Tesla where it,

623
00:38:40,330 --> 00:38:44,280
this is a common problem for all,
all link keeping systems. Like,

624
00:38:44,680 --> 00:38:47,010
like that's a lot of pilot is a,
those,

625
00:38:47,011 --> 00:38:51,690
a divider in the highway and basically
the car was driving, you know,

626
00:38:51,720 --> 00:38:55,660
along the lane and then the car in
front moved to an adjacent lane and this

627
00:38:55,661 --> 00:38:57,280
divider appeared right?

628
00:38:57,610 --> 00:39:02,170
So you have to now steer to the right
and the car didn't in one straight into

629
00:39:02,171 --> 00:39:05,690
the divider. Oh Wow.
And it's, you know, uh,

630
00:39:05,800 --> 00:39:10,780
the basically what that boils down to
is the car drifted out of lane, right?

631
00:39:11,020 --> 00:39:15,010
Or it didn't adjust properly to the
lane and those kinds of things happen.

632
00:39:15,630 --> 00:39:19,530
And this is because the person was
allowing the autopilot to do everything.

633
00:39:20,910 --> 00:39:24,180
Nope. That you can't. So we have
to be extremely careful here.

634
00:39:24,181 --> 00:39:26,730
I don't know that the really
deep details of the case,

635
00:39:26,731 --> 00:39:29,150
I'm not sure exactly
how many people will do.

636
00:39:29,151 --> 00:39:33,150
So there's a judgment on what the person
was doing and then there's an analysis

637
00:39:33,151 --> 00:39:35,190
of what the system did,
right. The system did,

638
00:39:35,191 --> 00:39:39,150
it drifted out of lane and the
question is did the person,

639
00:39:39,180 --> 00:39:42,960
was the person paying attention and was
there enough time given for the person

640
00:39:42,961 --> 00:39:46,620
to take over and if they were paying
attention to catch the vehicle,

641
00:39:46,710 --> 00:39:48,210
steer back onto the road.

642
00:39:48,930 --> 00:39:53,930
As far as I believe the only information
they have is hands on steering wheel.

643
00:39:56,280 --> 00:39:58,290
And they were saying that like half.

644
00:39:58,291 --> 00:40:00,990
That's half the minute
leading up to the crash.

645
00:40:01,350 --> 00:40:03,780
The hands weren't on the steering
wheel or something like that.

646
00:40:04,080 --> 00:40:07,200
Basically trying to infer where
the person paying attention or not,

647
00:40:07,201 --> 00:40:11,920
but we don't have the information exactly
what wa where were their eyes? Right.

648
00:40:12,090 --> 00:40:15,330
You can only make guesses
as far as I know. Again,

649
00:40:15,780 --> 00:40:17,670
so the question is,

650
00:40:17,970 --> 00:40:21,360
this is the eyes on the road thing
because I think I've heard Jenna pocket

651
00:40:21,361 --> 00:40:26,220
saying you're attempted to sort of look
off the road that your new Tesla or at

652
00:40:26,221 --> 00:40:27,660
least become a little bit complacent.

653
00:40:28,820 --> 00:40:30,240
The worry,
the worry is that you,

654
00:40:30,241 --> 00:40:33,680
you just rely on the thing
that you would relax too much,

655
00:40:34,400 --> 00:40:38,330
but what would that relaxation lead to
that the problem is if something happened,

656
00:40:38,600 --> 00:40:41,810
if you weren't,
you know when you're driving.

657
00:40:41,870 --> 00:40:46,280
I mean we've discussed this many times
on the podcast to the reason why people

658
00:40:46,281 --> 00:40:47,120
have road rage.

659
00:40:47,450 --> 00:40:50,540
One of the reasons is cause you were
in a heightened state because cars are

660
00:40:50,541 --> 00:40:55,280
flying around you and your
brain is prepared to make
split second decisions and

661
00:40:55,281 --> 00:40:56,114
moves.

662
00:40:56,510 --> 00:41:01,370
And the worry is that you would relax
that because you're so comfortable with

663
00:41:01,371 --> 00:41:04,730
that thing driving everybody that I know
that it's tried that they say you get

664
00:41:04,731 --> 00:41:06,170
really used to it doing that.

665
00:41:06,390 --> 00:41:08,630
You get really used to it
just driving around for you.

666
00:41:09,240 --> 00:41:12,720
So the question is what be, what
happens when you get used to it? Yeah.

667
00:41:12,750 --> 00:41:14,960
You started looking off road.
Do you started texting more?

668
00:41:14,970 --> 00:41:17,910
Do you start watching a movie?
It's that, uh, that, that's a,

669
00:41:17,911 --> 00:41:22,770
that's a really an open question.
And the like for example,

670
00:41:22,771 --> 00:41:24,580
we just did the study,
uh,

671
00:41:25,230 --> 00:41:30,230
published a study from the MIT
on what people in our Dataset,

672
00:41:30,350 --> 00:41:34,130
we have local at this Dataset
of 300 miles and Tesla's,

673
00:41:34,131 --> 00:41:37,700
we instrumented all these Teslas and
watch what people are actually doing and

674
00:41:37,701 --> 00:41:41,000
are they paying attention when
they disengage the system?

675
00:41:41,090 --> 00:41:43,250
So there's a really important moment here.

676
00:41:43,310 --> 00:41:47,930
We have 18,000 of those when
the person catches the car,

677
00:41:48,440 --> 00:41:53,150
you know the disengage
autopilot and that's a really
a Tesla uses this moment as

678
00:41:53,151 --> 00:41:57,230
well. That's a really important
window into difficult cases.

679
00:41:57,410 --> 00:41:59,690
So some percentage of those,
some small percentage,

680
00:41:59,740 --> 00:42:02,420
about 10% is we call them.

681
00:42:02,780 --> 00:42:07,160
Tricky situations is situations where
you have to immediately respond like

682
00:42:07,161 --> 00:42:11,840
drifting out of lane if there's a stopped
car in front. So on. The question is,

683
00:42:11,900 --> 00:42:14,000
are people paying attention
during those moments?

684
00:42:14,150 --> 00:42:16,460
So in our dataset that
we're paying attention,

685
00:42:16,580 --> 00:42:20,000
there were still remaining vigilant.
Now in our Dataset,

686
00:42:20,390 --> 00:42:22,790
the autopilot was going on quote,

687
00:42:23,150 --> 00:42:27,470
encountering tricky
situations every 9.2 miles.

688
00:42:27,500 --> 00:42:32,090
So you could say it was a
failing every 9.2 miles.

689
00:42:33,380 --> 00:42:36,840
That is one of the reasons we believe
that people are still paying it,

690
00:42:37,640 --> 00:42:38,660
remaining vigilant,

691
00:42:38,900 --> 00:42:43,900
that it's regularly and unpredictably
sort of drifting out of the lane or

692
00:42:44,390 --> 00:42:49,040
misbehaving. So you don't overtrust
it, you don't become too complacent.

693
00:42:49,640 --> 00:42:53,420
The open question is when it becomes
better and better and better and better,

694
00:42:53,770 --> 00:42:58,220
will you start becoming complacent when
it drives on the highway for an hour,

695
00:42:58,221 --> 00:43:02,810
an hour and a half and is opposed
to 9.2 miles, make that 50 miles,

696
00:43:02,811 --> 00:43:07,250
60 miles. Do you start to overtrust
it? And that's a really open question.

697
00:43:08,060 --> 00:43:12,440
Do you think or do you anticipate a time
and anywhere in the near future where

698
00:43:12,441 --> 00:43:14,360
you won't have to correct,

699
00:43:14,600 --> 00:43:17,360
you will allow the car to do it
because the car will be perfect.

700
00:43:18,670 --> 00:43:22,330
The car, first of all, we'll never be
perfect. No car will ever be perfect.

701
00:43:22,370 --> 00:43:24,440
Autonomous Vehicles will always,

702
00:43:24,441 --> 00:43:29,420
you think require at least some
sort of manual override. Yeah.

703
00:43:29,870 --> 00:43:33,320
Really. That's interesting that you're
saying that because you work in AI.

704
00:43:33,620 --> 00:43:37,730
Like what makes you think that
that's impossible to achieve?

705
00:43:38,780 --> 00:43:42,170
Well let's, let's talk cause cause
you're using the word perfection.

706
00:43:42,171 --> 00:43:46,700
I think perfection. That's a bad word.
Yeah. So I guess you're implying it.

707
00:43:46,701 --> 00:43:49,650
Let me see. Will it achieve? Because
people are obviously not perfect yet.

708
00:43:49,820 --> 00:43:54,820
We'll achieve a state of competence
that exceeds the human beings.

709
00:43:54,850 --> 00:43:55,683
Okay.

710
00:43:56,320 --> 00:44:00,340
And let's put it in a dark way.

711
00:44:00,940 --> 00:44:04,780
Competence measured by
fatal crashes. Yes. Uh, yes.

712
00:44:04,800 --> 00:44:09,520
I absolutely believe so. And
perhaps in the near term, near term,

713
00:44:09,940 --> 00:44:11,860
five years for me,

714
00:44:11,890 --> 00:44:15,090
five 10 years is near term for Elan,

715
00:44:15,610 --> 00:44:19,690
Elan Musk time that converted to one year.

716
00:44:20,020 --> 00:44:22,540
Have you met him? Yes.
Interviewed him recently.

717
00:44:22,770 --> 00:44:25,140
Fascinating cat, right? Yup.

718
00:44:25,170 --> 00:44:27,540
Got a lot of weird shit bouncing
around behind those eyeballs.

719
00:44:28,620 --> 00:44:31,050
You don't realize until you talked
to him in person, you're like, oh,

720
00:44:31,170 --> 00:44:32,010
got a lot going on

721
00:44:32,010 --> 00:44:35,820
in there, man. Yeah. There's
this passion, this drive. I mean,

722
00:44:35,821 --> 00:44:40,821
it's one of the hurricane of
ideas and a focus and confidence.

723
00:44:44,210 --> 00:44:47,760
I mean, the thing is in a
lot of the things he does,

724
00:44:47,790 --> 00:44:52,020
which I admire greatly from
any man or a woman innovator,

725
00:44:52,470 --> 00:44:53,940
it's just boldly,

726
00:44:54,360 --> 00:44:58,860
fearlessly pursuing new ideas or jumping
off the cliff and learning to fly in

727
00:44:58,861 --> 00:45:03,660
the way down that that's, I mean,
well, no matter what happens,

728
00:45:03,661 --> 00:45:07,890
he'll be remembered as the
great innovators of our
time. Uh, whatever you say,

729
00:45:08,250 --> 00:45:12,270
maybe in my book, Steve Jobs was
as well. Even if you criticize,

730
00:45:12,271 --> 00:45:16,260
perhaps he hasn't contributed
significantly to the
technological development of

731
00:45:16,261 --> 00:45:18,240
the company or the
different ideas they did.

732
00:45:18,540 --> 00:45:21,990
Still his brilliance was in
all the products of iPhone,

733
00:45:22,470 --> 00:45:27,390
of the personal computer, the Mac and so
on. And I think the same is true with uh,

734
00:45:27,840 --> 00:45:30,150
with uh,
with Ilan and yes,

735
00:45:30,210 --> 00:45:33,870
there's in this space of
autonomous vehicles of,

736
00:45:34,440 --> 00:45:37,350
of semi autonomous vehicles,
of driver assistance systems,

737
00:45:38,280 --> 00:45:41,250
it's a pretty tense space to operate in.

738
00:45:42,000 --> 00:45:46,530
There's several communities in there
that are very responsible but also

739
00:45:46,531 --> 00:45:51,120
aggressive in their criticism.
So in driving in the automotive sector,

740
00:45:51,180 --> 00:45:56,180
obviously since Henry Ford and before
there's been a culture of safety of just

741
00:45:57,661 --> 00:45:58,830
great engineering.

742
00:45:59,400 --> 00:46:02,460
These are like some of the best engineers
in the world in terms of large scale

743
00:46:02,461 --> 00:46:05,820
production. He talked about [inaudible]
are you talking about for GM?

744
00:46:06,420 --> 00:46:10,090
These people know how to do
safety well and so care combs, he,

745
00:46:10,091 --> 00:46:15,091
along with silicon valley ideals that
throws a lot of it out the window and says

746
00:46:16,291 --> 00:46:20,130
we're going to revolutionize the
way we do automation in general.

747
00:46:20,250 --> 00:46:24,840
We'll go into make software
updates to the car once a week,

748
00:46:24,841 --> 00:46:27,390
twice a week over the air.
Just like that.

749
00:46:28,140 --> 00:46:32,220
That makes people in the safety engineers
and human factors engineers really

750
00:46:32,221 --> 00:46:33,480
uncomfortable.
Like,

751
00:46:33,481 --> 00:46:37,740
what do you mean you're going to keep
updating the software of the car without

752
00:46:37,770 --> 00:46:41,490
like how are you testing it? Right?
That makes people really uncomfortable.

753
00:46:41,520 --> 00:46:45,180
Why does it make them uncomfortable?
Because the way in the automotive sector,

754
00:46:45,300 --> 00:46:49,800
you test the system, you come up with
a design of the car, every component,

755
00:46:50,190 --> 00:46:53,610
and then you go through like really
rigorous testing before it ever hits the

756
00:46:53,611 --> 00:46:54,900
road.
Right?

757
00:46:54,930 --> 00:46:59,730
Here's an idea from the Tesla
side is where they basically,

758
00:47:00,510 --> 00:47:03,690
they in shadow moe test the software,
but then they just release it.

759
00:47:03,900 --> 00:47:08,900
So essentially the drivers become the
testing and then they regularly update it

760
00:47:09,660 --> 00:47:12,390
to, uh, to, uh, to adjust a,

761
00:47:12,391 --> 00:47:16,350
if any issues arise that makes people
uncomfortable because there's not a

762
00:47:16,351 --> 00:47:19,410
standardized testing procedure.
There's not,

763
00:47:19,620 --> 00:47:24,570
there's not at least the feeling in the
industry of rigor because the reality is

764
00:47:24,571 --> 00:47:29,080
we don't know how to test software in
the same corner of with the same kind of

765
00:47:29,081 --> 00:47:30,040
rigor that we've tasted,

766
00:47:30,040 --> 00:47:32,800
the automotive system tested
automotive system in the past.

767
00:47:33,040 --> 00:47:38,040
So I think it's extremely exciting
and powerful to make software sort of

768
00:47:39,791 --> 00:47:41,780
approach,
uh,

769
00:47:42,280 --> 00:47:47,140
automotive engineering with at least in
part a software engineering perspective.

770
00:47:47,320 --> 00:47:50,770
So just doing what's made
silicon valley successful.

771
00:47:51,190 --> 00:47:54,940
So updating regularly, aggressively
innovating on the software side.

772
00:47:55,270 --> 00:47:58,720
So your Tesla over the air while we're
sitting here could get a total annual

773
00:47:58,740 --> 00:48:03,640
update. The flip of a, uh,
of a bit as a Elon Musk says,

774
00:48:03,940 --> 00:48:07,780
uh, it can be, he can
gain all new capabilities.

775
00:48:08,110 --> 00:48:12,790
That's really exciting, but that's
also dangerous and that, that balance,

776
00:48:12,970 --> 00:48:17,620
we, uh, what's dangerous about it?
That'd be faulty software faulty a bug.

777
00:48:17,890 --> 00:48:22,120
So if you're, you're the
apps on your phone, you know,

778
00:48:22,121 --> 00:48:23,080
fail all the time.

779
00:48:23,260 --> 00:48:28,150
Where as a society used to software
failing and we just kind of reboot the

780
00:48:28,151 --> 00:48:29,530
device when we start the APP.

781
00:48:29,970 --> 00:48:34,780
A the most complex software systems in,
in the world today.

782
00:48:35,410 --> 00:48:38,110
If we think outside of
nuclear engineering and so on,

783
00:48:38,560 --> 00:48:42,640
they're really nobody that they're too
complex to really thoroughly tests.

784
00:48:42,641 --> 00:48:45,490
So a thorough,

785
00:48:45,491 --> 00:48:49,900
complete testing proving that the
software is safe is nearly impossible.

786
00:48:49,901 --> 00:48:54,320
I'm most software systems that that's IX,
that's a,

787
00:48:54,340 --> 00:48:57,910
that's nerve wracking too.
A lot of people because a,

788
00:48:58,850 --> 00:49:03,490
there's no way to prove that the new
software update is safe. So what it,

789
00:49:03,520 --> 00:49:08,520
what is the process like do know
like how they create software,

790
00:49:09,490 --> 00:49:12,580
they update it and then
they tested on something.

791
00:49:12,670 --> 00:49:14,610
How much testing do they do and what,

792
00:49:14,620 --> 00:49:18,240
how much did they do before they
upload it to your car? Yeah,

793
00:49:18,250 --> 00:49:19,900
so I don't have any inside information,

794
00:49:19,901 --> 00:49:24,220
but I have a lot of sort of public
available information, which is, uh,

795
00:49:24,550 --> 00:49:26,980
they, uh, they test the
software in shadow mode,

796
00:49:27,310 --> 00:49:32,310
meaning they see how the new software
compares to the current software by

797
00:49:32,651 --> 00:49:37,270
running it in parallel on the cars and
seeing if there's disagreements, if like,

798
00:49:37,700 --> 00:49:37,930
uh,

799
00:49:37,930 --> 00:49:42,070
seeing if there's any major disagreements
and bringing those up and seeing what

800
00:49:42,280 --> 00:49:46,540
by parallel, I'm sorry. Do you mean
both programs running at the same time?

801
00:49:48,160 --> 00:49:50,980
One, the original update?
Yes. At the same time,

802
00:49:50,981 --> 00:49:55,981
the original update actually controlling
the car and the new update is just

803
00:49:58,330 --> 00:50:01,900
making the same decision, making the
same decisions without them being,

804
00:50:01,960 --> 00:50:03,690
without actually
affecting the actual okay.

805
00:50:04,060 --> 00:50:07,270
Without actually affecting the
vehicles dynamics. And so that's,

806
00:50:07,300 --> 00:50:09,100
that's a really powerful way of testing.

807
00:50:09,370 --> 00:50:14,370
I think the software infrastructure
that Tesla's built a loss for that and I

808
00:50:14,681 --> 00:50:18,100
think other companies should do the same.
That's a really exciting,

809
00:50:18,101 --> 00:50:22,150
powerful way to approach
not just a automation,

810
00:50:22,180 --> 00:50:24,340
not just the autonomous vehicles
or semi autonomous vehicles,

811
00:50:24,341 --> 00:50:28,940
but just safety is basically
all the data that's on cars.

812
00:50:29,420 --> 00:50:34,420
Bring it back to a central point to
where you can use the edge cases,

813
00:50:34,461 --> 00:50:39,020
all the weird situations, and driving to
a, improve the system to test the system,

814
00:50:39,320 --> 00:50:43,910
to learn to understand
where the cars used misused,

815
00:50:44,150 --> 00:50:45,560
how can be improved and so on.

816
00:50:45,950 --> 00:50:49,430
That's an extremely powerful how many
people they have that are analyzing all

817
00:50:49,431 --> 00:50:53,780
this data. It's a, it's a really
good question. So they have,

818
00:50:55,250 --> 00:50:58,610
the interesting thing about driving
is most of it is pretty boring.

819
00:50:58,640 --> 00:50:59,680
Nothing interesting happens.

820
00:50:59,681 --> 00:51:04,681
So they have automated ways of extracting
again what are called edge cases.

821
00:51:05,361 --> 00:51:09,350
So these weird moments of driving and
once you have these weird moments,

822
00:51:09,351 --> 00:51:13,250
they have people annotate it.
I don't know what the number is,

823
00:51:13,251 --> 00:51:14,780
but a lot of companies are doing this.

824
00:51:14,840 --> 00:51:18,950
It's in the hundreds and the thousands
and basically have humans annotate the

825
00:51:18,951 --> 00:51:20,180
data to see what happened.

826
00:51:20,480 --> 00:51:24,620
But most of what they're trying to
do is to automate that annotation.

827
00:51:25,250 --> 00:51:28,480
So to figure out how the da Da da,

828
00:51:28,481 --> 00:51:31,820
it can be automatically used to
improve the system. So they, they have,

829
00:51:31,910 --> 00:51:35,120
they have methods for that because
it's a huge amount of data. Right.

830
00:51:35,630 --> 00:51:38,300
I think in the recent autonomy day,
a couple of weeks ago,

831
00:51:38,360 --> 00:51:41,620
they had this big autonomy day
where they had demonstrated, uh,

832
00:51:41,650 --> 00:51:46,460
the vehicle driving itself on a
particular stretch of road. They,

833
00:51:46,461 --> 00:51:49,730
uh, they showed off that, you know,
they're able to query the data,

834
00:51:50,150 --> 00:51:53,150
basically ask questions
of the data saying, uh,

835
00:51:53,630 --> 00:51:57,440
the example they gave is there's a bike
on the back of a car and a bicycle on

836
00:51:57,441 --> 00:52:00,410
the back of a car. And
they're able to say, well,

837
00:52:00,440 --> 00:52:03,350
when the bicycles in the back of a car,
that's not a bicycle,

838
00:52:03,440 --> 00:52:04,760
that's just the part of the car.

839
00:52:05,540 --> 00:52:09,620
And they're able to now look back into
the data and find all the other cases,

840
00:52:09,770 --> 00:52:13,610
the thousands of cases that happened
all over the world in Europe, in Asia,

841
00:52:14,330 --> 00:52:16,730
in South America and
North America and so on,

842
00:52:16,940 --> 00:52:20,560
and pull all those elements
and then train the train, uh,

843
00:52:20,980 --> 00:52:24,990
the perception system of
autopilot to be able to, to, uh,

844
00:52:25,040 --> 00:52:27,830
better recognize those
bicycles as part of the car.

845
00:52:28,080 --> 00:52:31,790
And so every edge case like that,
they go through saying, okay,

846
00:52:31,791 --> 00:52:33,380
the car freaked out in this moment.

847
00:52:33,680 --> 00:52:38,180
And then we find moments like this in
the rest of the data and then improve the

848
00:52:38,181 --> 00:52:41,870
system. So it's, it's, uh,

849
00:52:42,350 --> 00:52:46,250
this kind of cycle is
the way to deal with, uh,

850
00:52:46,760 --> 00:52:51,710
with problems with failures of the system
is to say every time the car fails at

851
00:52:51,711 --> 00:52:55,370
something, say, is this part
of a bigger set of problems?

852
00:52:55,371 --> 00:52:58,970
Can I find all those problems and
can I improve it with a new update?

853
00:52:59,570 --> 00:53:00,800
And that it just keeps going.

854
00:53:01,220 --> 00:53:05,360
The open question is how many loops like
that you have to take for the car to

855
00:53:05,361 --> 00:53:10,100
become really good, better
than human. Basically,

856
00:53:10,101 --> 00:53:11,270
how hard is driving?

857
00:53:11,420 --> 00:53:16,290
How many weird situations when you
manually drive do you deal with every day

858
00:53:16,520 --> 00:53:18,680
somebody, uh, somebody mentioned,

859
00:53:18,800 --> 00:53:21,410
I don't know that there's like
millions of cases when you watch video,

860
00:53:21,440 --> 00:53:24,250
you see them, somebody you mentioned, um,

861
00:53:24,680 --> 00:53:29,680
that drive a truck or ups truck and
passed cow pastures and they know that if

862
00:53:32,821 --> 00:53:36,390
there's no cows in the cow pasture,
that means they're grazing.

863
00:53:37,320 --> 00:53:41,670
And if they're grazing, I mean like be
using the correct terms. I apologize.

864
00:53:41,671 --> 00:53:43,800
And not a car guy. Uh, that,

865
00:53:43,801 --> 00:53:46,440
that means that there may be
cows up ahead on the road.

866
00:53:46,950 --> 00:53:50,430
There's just this kind of reasoning
it can use to anticipate difficult

867
00:53:50,431 --> 00:53:52,020
situations.
And we do,

868
00:53:52,050 --> 00:53:56,520
we do that kind of reasoning about like
everything cars today can't do that kind

869
00:53:56,521 --> 00:53:59,520
of reasoning. They're just
perceiving what's in front of them.

870
00:54:00,030 --> 00:54:02,010
Now,
outside of Tesla,

871
00:54:02,070 --> 00:54:05,790
how many other companies have autonomous
systems that are driving their cars?

872
00:54:06,150 --> 00:54:09,420
So maybe it's good to step back.
There are several,

873
00:54:09,421 --> 00:54:11,850
and there are several leaders
in each different approach.

874
00:54:12,480 --> 00:54:17,480
So first let's draw a line between the
different types of systems that are one.

875
00:54:17,550 --> 00:54:19,470
There is fully autonomous vehicles.

876
00:54:19,500 --> 00:54:23,460
These are cars you can think about that
don't have a steering wheel or if they

877
00:54:23,461 --> 00:54:26,790
have a steering wheel, it doesn't
matter. They're in full control.

878
00:54:26,940 --> 00:54:31,620
And if there's a crash,
the car companies liable that those exist.

879
00:54:32,220 --> 00:54:36,320
No, it, it's,

880
00:54:36,360 --> 00:54:41,360
it's a gray area though because many
companies are basically saying that that's

881
00:54:41,371 --> 00:54:44,010
what they're doing,
but they're not quite there.

882
00:54:44,340 --> 00:54:48,990
So the leader in that space is a used
to be called Google self driving car

883
00:54:48,991 --> 00:54:53,760
program now it's called Waymo.
They are doing that there.

884
00:54:53,790 --> 00:54:57,510
It's called level four, level
five. There's levels to this game.

885
00:54:57,840 --> 00:55:00,960
And this is this particular level
where it's fully autonomous.

886
00:55:01,350 --> 00:55:04,110
Now they're trying to
achieve full autonomy,

887
00:55:04,470 --> 00:55:09,210
but the way they're doing it currently
is they're testing on public roads with

888
00:55:09,240 --> 00:55:10,800
what's called the safety driver.

889
00:55:11,100 --> 00:55:16,100
So there's a driver always ready to take
over and the driver does have to take

890
00:55:16,231 --> 00:55:19,860
over at some rate, you know, frequently.

891
00:55:20,430 --> 00:55:22,320
And so the fact that the
driver has to take over,

892
00:55:22,470 --> 00:55:24,510
that's not fully autonomous then.
Right?

893
00:55:24,630 --> 00:55:28,500
So there's no car today that you can
just get in without a safety driver.

894
00:55:28,501 --> 00:55:29,880
So there's nobody behind the wheel.

895
00:55:30,210 --> 00:55:33,180
And a using your apps sort of
get from point a to point B,

896
00:55:33,810 --> 00:55:38,280
but out of the cars that are semi
autonomous where there is an autonomous

897
00:55:38,281 --> 00:55:38,671
program,

898
00:55:38,671 --> 00:55:41,880
but you do have to keep your hands on the
wheel and p pay attention to the road.

899
00:55:42,300 --> 00:55:46,170
What, what are the leaders besides Tesla?
There's Tesla and who else is doing it?

900
00:55:46,350 --> 00:55:47,280
So there's,
Yep.

901
00:55:47,390 --> 00:55:51,230
Uh,
there's several systems.

902
00:55:52,440 --> 00:55:55,610
It depends how you define
leader. But so are the, yes.

903
00:55:55,890 --> 00:55:59,760
See this, like does Mercedes and BMW,
they use the same system? Do they,

904
00:55:59,761 --> 00:56:03,270
does someone make a system for cars
or do they create their own systems?

905
00:56:03,750 --> 00:56:06,930
That's a really good question.
So there's, in some cases there

906
00:56:07,320 --> 00:56:12,110
belie and Invidia there's these
companies that Nvidia, the,

907
00:56:12,120 --> 00:56:15,370
the video card be in a car
company. Yup. The same,

908
00:56:15,490 --> 00:56:18,640
the same folks that power
the quake game, right. The,

909
00:56:18,690 --> 00:56:19,930
the graphics and the quake game.

910
00:56:20,170 --> 00:56:25,170
You can use those Gpu graphics
processing to run machine learning code.

911
00:56:25,630 --> 00:56:28,310
So they're also creating the nvidia drive.
Yep.

912
00:56:28,540 --> 00:56:33,040
Scalable Ai Platform for
autonomous driving. In fact, uh,

913
00:56:33,610 --> 00:56:38,050
I don't, when did you buy a Tesla?
Five months ago or something,

914
00:56:38,200 --> 00:56:40,240
something like that.
So the thing in there now,

915
00:56:40,300 --> 00:56:43,660
most likely is a nvidia
draft px two system.

916
00:56:43,990 --> 00:56:48,730
So the one that works on cameras that,
uh,

917
00:56:49,120 --> 00:56:52,930
that just runs code that
takes in camera data,

918
00:56:53,110 --> 00:56:56,340
but it can work on anything else.
So it could work on lidar as well.

919
00:56:56,360 --> 00:57:00,010
Somebody had a system. Yeah.
But it needs a different code.

920
00:57:00,040 --> 00:57:02,530
So the lidar requires very
different kinds of processing.

921
00:57:02,710 --> 00:57:07,300
Does anybody use that with cars? With
all semi autonomous cars? Lighter, yes.

922
00:57:08,260 --> 00:57:09,910
The as well.
Okay.

923
00:57:09,911 --> 00:57:13,940
So semiautonomous we have
to be careful because a,

924
00:57:13,941 --> 00:57:15,340
the Waymo cars like the,

925
00:57:15,450 --> 00:57:19,800
the quote unquote fully autonomous cars
are currently semi autonomous. Okay.

926
00:57:19,990 --> 00:57:24,160
So that's the highest level
of semiautonomous autonomous,
right? Yeah. That guests,

927
00:57:24,210 --> 00:57:26,650
it's, it's not even a highest
level. It's a principle.

928
00:57:26,651 --> 00:57:27,970
It's a philosophy difference.

929
00:57:28,120 --> 00:57:31,060
Cause they're saying we're
going to do full autonomy.

930
00:57:31,090 --> 00:57:34,600
We just not quite there yet.
Uh, most other companies,

931
00:57:34,630 --> 00:57:39,630
they're doing semiautonomous better called
driver assistance systems is they're

932
00:57:40,661 --> 00:57:43,000
saying we're not interested
in full autonomy.

933
00:57:43,240 --> 00:57:46,570
We just want a driver assistance system.
They just helps you steer the car.

934
00:57:46,990 --> 00:57:51,670
So let, let's call those semi autonomous
vehicles or driver assistance systems.

935
00:57:51,910 --> 00:57:54,250
The,
there's several leaders in that space.

936
00:57:54,280 --> 00:57:59,010
Like one car we're studying that's really
interesting is a Cadillac super cruise

937
00:57:59,020 --> 00:58:02,070
system.
So GM has the system,

938
00:58:02,071 --> 00:58:07,071
it's called super cruise that I think is
the best comparable system to autopilot

939
00:58:08,710 --> 00:58:11,030
today. The, uh,

940
00:58:11,190 --> 00:58:15,370
the key differentiator there is,
there's a lot of little elements,

941
00:58:15,371 --> 00:58:18,150
but the key differentiators,
there's a driver monitoring system.

942
00:58:18,151 --> 00:58:22,510
So there's a camera that looks at you
and tells you if your eyes on the road or

943
00:58:22,511 --> 00:58:26,110
not. And if your eyes go off the road
for I believe more than six seconds,

944
00:58:26,350 --> 00:58:28,870
it starts warning you
and says you have to be,

945
00:58:29,110 --> 00:58:32,590
you have to get your eyes back on the
road. So that's called driver monitoring.

946
00:58:32,591 --> 00:58:34,960
That's one of the big disagreements.
For example,

947
00:58:34,961 --> 00:58:37,660
if you mean Ilan and uh,

948
00:58:37,810 --> 00:58:41,620
many experts in the field and Ilan and
the Tesla approach is that there should

949
00:58:41,621 --> 00:58:44,650
be a driver monitoring system.
There should be a camera.

950
00:58:44,700 --> 00:58:49,420
Loquat is Ilan feel like there
shouldn't be, I think his focus,

951
00:58:49,780 --> 00:58:54,780
the Tesla's focus is on just improving
the system so fast and so effectively

952
00:58:55,990 --> 00:59:00,820
that it doesn't matter what the
driver does that it, it, you know,

953
00:59:01,120 --> 00:59:03,970
so essentially no safety net,
no safety net.

954
00:59:04,120 --> 00:59:09,120
And I think they operate like that and
in many ideas that they work with is they

955
00:59:11,861 --> 00:59:12,940
sort of bold leap,

956
00:59:12,941 --> 00:59:17,260
proceed forward to try to make
the car extremely safe. Now,

957
00:59:17,261 --> 00:59:21,130
the concern there is you
have to acknowledge the
psychology of human beings.

958
00:59:21,320 --> 00:59:22,130
Then unless the car

959
00:59:22,130 --> 00:59:25,550
is perfect or under our definition,
perfect,

960
00:59:25,551 --> 00:59:27,800
which is much better than human beings,

961
00:59:28,640 --> 00:59:31,400
then you have to be able to,

962
00:59:32,630 --> 00:59:36,680
you have to be able to make sure that
the people are still paying attention to

963
00:59:36,681 --> 00:59:41,510
help the car out when it fails and for
that you have to have drive a modern,

964
00:59:41,511 --> 00:59:42,890
you have to know what
the car is right now.

965
00:59:42,891 --> 00:59:47,891
Your Tesla only knows about your presence
be from the steering wheel touching

966
00:59:48,171 --> 00:59:51,110
the steering wheel, which is a
kind of driver monitoring system.

967
00:59:51,140 --> 00:59:55,070
It knows you're there, but it's not
nearly as effective at knowing your,

968
00:59:55,071 --> 00:59:59,360
they're cognitively, visually,
you can be tricked by clamps,

969
00:59:59,500 --> 01:00:00,470
seen people do that.

970
01:00:00,480 --> 01:00:03,140
Then develop these clamps that you
just put on the steering wheel.

971
01:00:03,210 --> 01:00:07,100
It'll hold a phone and then also trick
the system into thinking that you're

972
01:00:07,101 --> 01:00:08,360
holding onto the wheel.
Yeah,

973
01:00:08,390 --> 01:00:12,530
you can do a lot of purses actually work
really law are asking me how hanging

974
01:00:12,560 --> 01:00:15,920
purse, no, like shoving
a person and to the,

975
01:00:16,130 --> 01:00:18,380
somebody did that with an
orange or something like that,

976
01:00:18,381 --> 01:00:19,430
but they said it didn't work.

977
01:00:20,270 --> 01:00:22,760
Maybe it needs to be all the
way around the outside of it.

978
01:00:22,820 --> 01:00:25,490
I think it depends on the shape
of that orange, how ripe it is.

979
01:00:25,520 --> 01:00:29,120
This is a lot of debate and no, I, the
point is there's wasted trick the system,

980
01:00:29,121 --> 01:00:32,270
there's a, it's not monitoring the
driver. That's the point, right?

981
01:00:32,570 --> 01:00:35,560
It's not monitoring and driving. A
lot of people believe you need to, uh,

982
01:00:36,670 --> 01:00:40,580
you need to make sense.
Yeah. I think, I think, uh,

983
01:00:40,760 --> 01:00:44,990
not just for the safety of the system,
but to create an experience like, uh,

984
01:00:45,200 --> 01:00:50,150
I think there's value for the
car to know more about you.

985
01:00:51,530 --> 01:00:53,510
Sort of just like what's happening there.

986
01:00:53,511 --> 01:00:58,370
It's scanning this guy's
eyes as the minority report.

987
01:00:58,371 --> 01:01:02,720
Shit freaked me out. So yeah, there's a
lot of companies that are springing up.

988
01:01:02,721 --> 01:01:06,020
They're doing computer vision on the
face and so on to try to detect where

989
01:01:06,021 --> 01:01:10,430
you're looking. So what
cars have that now? The uh,

990
01:01:10,650 --> 01:01:13,250
the major one is the superconscious.
There's not many cars.

991
01:01:13,280 --> 01:01:17,720
A few cars are starting to add it.
Europe, what's a super cruise system?

992
01:01:17,870 --> 01:01:21,080
That's the GM Cadillac.
They're trying to,

993
01:01:21,420 --> 01:01:24,620
so it's in their super expensive
lineup currently and they're,

994
01:01:24,621 --> 01:01:28,370
I think trying to add it to the
full lineup of all Cadillacs.

995
01:01:28,371 --> 01:01:33,050
What does that big cruiser that they
have now? The big four door car,

996
01:01:33,260 --> 01:01:36,320
the really high end does a CT
six I don't know what it is.

997
01:01:36,350 --> 01:01:39,830
They have a new one that's really nice.
Is that what they're putting it in?

998
01:01:40,610 --> 01:01:45,320
The big sedan, that
thing? Yes. I it's pretty,

999
01:01:45,920 --> 01:01:47,500
I don't know if that's the CT six but the,

1000
01:01:47,501 --> 01:01:52,501
the one we're looking at the
CT six that's 2018 CT six yeah.

1001
01:01:53,270 --> 01:01:57,620
It's, you know, it's a, but
they want to add it to their,

1002
01:01:57,740 --> 01:01:59,240
their full fleet.
And so really interesting.

1003
01:01:59,241 --> 01:02:03,260
I have the same amount of cameras as
the Tesla system does know and it has a

1004
01:02:03,261 --> 01:02:05,450
very different philosophy
as well in another way,

1005
01:02:05,451 --> 01:02:10,451
which is it only works on very
specific worlds on interstate highways.

1006
01:02:11,330 --> 01:02:14,930
There's something called odd
operational design domain.

1007
01:02:14,931 --> 01:02:19,931
So they define that this
thing super system only works
on this particular set of

1008
01:02:21,181 --> 01:02:23,970
roads as they're basically
just major highways.

1009
01:02:24,450 --> 01:02:28,890
The Tesla approach is saying basically,
uh,

1010
01:02:29,070 --> 01:02:33,650
what Ilan jokingly referred to add,
right is a works basically annual.

1011
01:02:34,390 --> 01:02:36,240
So if you tried to turn on your autopilot,

1012
01:02:36,241 --> 01:02:39,960
you can basically turn it out anywhere
where the cameras are able to determine

1013
01:02:40,320 --> 01:02:42,600
either lane markings or
the car in front of you.

1014
01:02:43,180 --> 01:02:46,140
And so that's a very different approach
saying you can basically make it work

1015
01:02:46,141 --> 01:02:51,090
anywhere or in Cadillac case making
work on only specific kinds of roads.

1016
01:02:51,240 --> 01:02:54,930
So you can test the heck out of
those roads, you can map those roads.

1017
01:02:54,930 --> 01:02:59,800
So you can use actually lidar to map the
full road. So you know, the full, uh,

1018
01:02:59,801 --> 01:03:04,050
geometry of all the, the, the interstate
highway system that it can operate on.

1019
01:03:04,320 --> 01:03:06,690
And then does it also coordinate with gps?

1020
01:03:06,691 --> 01:03:09,810
We're were sort of understands where
like bumps in the road might be or hills.

1021
01:03:10,710 --> 01:03:14,520
Uh, in that sense, it coordinates to
gps for different curvature information,

1022
01:03:14,521 --> 01:03:18,450
but not the topography, the know and,
and like construction is a big one.

1023
01:03:18,451 --> 01:03:23,220
That'd be crazy if new potholes,
you know, with a little potholes is,

1024
01:03:23,230 --> 01:03:25,980
and the big problem,
I think construction is the big problem.

1025
01:03:26,010 --> 01:03:30,360
Like just this quickly changing
dynamic information, which like apps,

1026
01:03:30,361 --> 01:03:33,750
like ways provide, I mean that's, the
huddles are a pretty big problem. Boston.

1027
01:03:33,780 --> 01:03:35,850
Oh yeah,
no for sure.

1028
01:03:35,880 --> 01:03:39,140
But a New York is actually
probably even worse. I blew,

1029
01:03:39,141 --> 01:03:42,810
I blew out two tires in one
day in New York on panels.

1030
01:03:43,650 --> 01:03:48,140
Set an unlucky day. Yeah. But I'd
rather you blow your tire then.

1031
01:03:48,360 --> 01:03:52,530
Uh, then I mean the, the kind of
fatality that happened in, um,

1032
01:03:53,490 --> 01:03:57,130
in the mountain view with the Tesla, I
believe is slightly construction related.

1033
01:03:57,150 --> 01:04:00,840
So I mean, there's a lot of safety
critical events that happen. Latest stuff.

1034
01:04:01,440 --> 01:04:04,320
I would like it if that stupid Tusla could
figure out the hole in the ground now

1035
01:04:04,321 --> 01:04:07,470
so I don't have to blow a tire
out. Like, come on, Bro. Yeah,

1036
01:04:07,480 --> 01:04:11,550
you're paying Joe figure it out.
But priorities. I'll, I'll, uh,

1037
01:04:11,790 --> 01:04:14,590
I'll make sure I'll forward
this podcast to airlines.

1038
01:04:14,630 --> 01:04:16,800
Make sure they work on this.
I think he's busy.

1039
01:04:17,340 --> 01:04:18,960
What does this Jamie Tesla autopilot,

1040
01:04:18,961 --> 01:04:22,420
we'll be able to avoid potholes in
the road. Says Ilan mosque. Ha Ha.

1041
01:04:22,890 --> 01:04:27,030
Motherfuckers on top of shit
with the data on that. April,

1042
01:04:27,390 --> 01:04:32,370
April 7th. Okay. Just now
that's an interesting thing.

1043
01:04:32,400 --> 01:04:33,000
That's another,

1044
01:04:33,000 --> 01:04:38,000
that's almost an ethical question whether
you want a car to avoid a situation by

1045
01:04:38,491 --> 01:04:41,160
swerving, right? Because when you swerve,

1046
01:04:41,220 --> 01:04:46,220
you now introduce as opposed to sort of
breaking the vehicle only you swerving

1047
01:04:46,711 --> 01:04:51,480
into another lane means you might
create a safety situation elsewhere.

1048
01:04:51,540 --> 01:04:53,450
You might put somebody else in danger.
Yeah,

1049
01:04:53,460 --> 01:04:57,180
that's why I was saying if it coordinated
with gps it would have previous

1050
01:04:57,181 --> 01:05:01,590
knowledge, you know, sort of like ways
tells you where the cops are. Yup.

1051
01:05:01,890 --> 01:05:02,490
You know what I mean?

1052
01:05:02,490 --> 01:05:05,820
So that kind of information will
be extremely powerful and useful.

1053
01:05:05,860 --> 01:05:10,860
The problem is it's hard to
get it really up to date,

1054
01:05:12,060 --> 01:05:15,990
that kind of information
really up to date. It's just
an infrastructure question.

1055
01:05:15,991 --> 01:05:18,100
Just getting the,
getting the software,

1056
01:05:18,101 --> 01:05:21,640
the data in place to where the car would
be able to learn quickly from all the

1057
01:05:21,641 --> 01:05:22,474
things that are changing.

1058
01:05:22,540 --> 01:05:25,330
I think potholes don't change
that often so that that's,

1059
01:05:25,360 --> 01:05:28,090
that's a different thing.
But in terms of construction zones,

1060
01:05:28,091 --> 01:05:31,740
in terms of other weird things
that changed the dynamics,

1061
01:05:31,760 --> 01:05:35,230
the geometry of the road, that's,
that's difficult to, uh, to get, right.

1062
01:05:36,100 --> 01:05:38,620
So Cadillacs doing a version of it,

1063
01:05:38,621 --> 01:05:43,000
but it sounds like it's a little
bit less and less involved,

1064
01:05:43,540 --> 01:05:46,990
less comprehensive. Maybe there's a
better way of describing yeah. And less,

1065
01:05:47,500 --> 01:05:52,150
I would say it's more safety
focused as a sort of, um, uh,

1066
01:05:52,510 --> 01:05:53,980
what's the right word to use here?

1067
01:05:54,310 --> 01:05:58,090
It's more cautious in its implementation.

1068
01:05:58,450 --> 01:06:00,520
So GM again has a,

1069
01:06:01,030 --> 01:06:03,630
has a tradition for better,

1070
01:06:03,640 --> 01:06:08,370
for worse to see Jamie video they have
on their website and this pull apart,

1071
01:06:08,371 --> 01:06:13,371
I'm showing you shows like at the
signal coming on pay attention lady,

1072
01:06:14,170 --> 01:06:15,790
she's too hot.
It's not paying attention.

1073
01:06:16,420 --> 01:06:21,010
Looking at people staring at her
and they'll comment. One of the,

1074
01:06:21,190 --> 01:06:22,150
one of the things that you,

1075
01:06:22,860 --> 01:06:26,370
it's hard to talk about without actually
experiencing the system is what's more

1076
01:06:26,371 --> 01:06:30,360
important than driving monitoring and
any of the details we talk about is like

1077
01:06:30,361 --> 01:06:33,840
how the whole thing feels, the whole
thing together, how it's implemented,

1078
01:06:33,841 --> 01:06:35,830
the whole interface and a,

1079
01:06:35,860 --> 01:06:40,260
the Cadillac system has actually done
really well in a sense that there's a

1080
01:06:40,261 --> 01:06:42,420
clarity to it.
Like everything becomes,

1081
01:06:42,690 --> 01:06:45,750
there's a green color and a blue color
and you know exactly when the system is

1082
01:06:45,751 --> 01:06:46,650
on and when it's off.

1083
01:06:46,860 --> 01:06:51,860
That's one of the big things people
struggle with is just confusing in other

1084
01:06:52,771 --> 01:06:56,130
cars, drivers not being able
to understand when the system

1085
01:06:56,130 --> 01:06:57,970
it was on or off.
Right.

1086
01:06:57,980 --> 01:07:00,770
So you think the system is doing it and
then just slam into something that it

1087
01:07:00,771 --> 01:07:05,100
wasn't even on. Now when this
car is operating in this manner,

1088
01:07:05,280 --> 01:07:07,470
how many cameras is it using [inaudible]

1089
01:07:08,350 --> 01:07:11,380
yeah, that's a good question. I
should know that, but I think a,

1090
01:07:11,381 --> 01:07:15,460
it's only forward to facing cameras as
far as I know. I think it's two cameras.

1091
01:07:15,580 --> 01:07:16,540
It may be three cameras.

1092
01:07:16,840 --> 01:07:21,710
Tell her he just sat back. So she doesn't
have her hands on the wheel at all. Yup.

1093
01:07:21,740 --> 01:07:23,350
So she's watching,
right,

1094
01:07:23,440 --> 01:07:26,710
because the car is able
to see where the eyes are.

1095
01:07:26,920 --> 01:07:30,220
It's a hands off system. So you're
allowed to take your hands off the wheel.

1096
01:07:32,140 --> 01:07:33,910
It's very interesting.
It's a,

1097
01:07:34,330 --> 01:07:38,500
and there are certain human behavior
aspects that come into play to this.

1098
01:07:38,560 --> 01:07:42,010
So you start to like,

1099
01:07:42,011 --> 01:07:46,540
I found myself actually becoming a
little more drowsy with this system. Uh,

1100
01:07:46,810 --> 01:07:50,530
I haven't driven it enough so I haven't
gotten used to it. But you have to,

1101
01:07:51,160 --> 01:07:55,810
at least in the initial stages, it kind
of forced you to look at the road in,

1102
01:07:55,811 --> 01:07:57,700
in a way that felt artificial.

1103
01:07:58,280 --> 01:08:01,630
I think it's something that gets
better with time. You get used to it,

1104
01:08:01,870 --> 01:08:04,440
but it's almost like a game
of fied thing that the,

1105
01:08:04,450 --> 01:08:06,670
the car when you look off road,
uh,

1106
01:08:06,790 --> 01:08:09,820
starts to tell you that
you're looking off road.

1107
01:08:09,821 --> 01:08:14,821
So you kind of psychologically pressured
to always stare at the road and you

1108
01:08:15,171 --> 01:08:16,400
realize that actually

1109
01:08:16,520 --> 01:08:18,320
when you drive you off and look around.

1110
01:08:19,220 --> 01:08:23,570
And so having to like stare forward
can be a little bit, uh, yeah, exactly.

1111
01:08:23,571 --> 01:08:25,600
You start like there's something,
um,

1112
01:08:26,030 --> 01:08:29,060
so not peaceful and hypnotic about
those lanes just coming at you.

1113
01:08:29,061 --> 01:08:32,800
And just the lines here lines,
why is that? And I've had,

1114
01:08:32,820 --> 01:08:35,900
it confuses the shit out of me
because I could not be tired at all.

1115
01:08:36,080 --> 01:08:38,510
But if it's nighttime,
when I'm on the highway and those lines,

1116
01:08:38,930 --> 01:08:43,790
they just start to yeah. Took you
to dream land. I get the same with,

1117
01:08:43,820 --> 01:08:47,660
there's also just the vibration. Is
that like that, that hum of driving?

1118
01:08:47,900 --> 01:08:51,540
Same with trains. Planes as well. Yeah,

1119
01:08:51,541 --> 01:08:56,541
it puts me out so that there's a two
Cadillac system that's the big leader I

1120
01:08:56,871 --> 01:09:00,140
would say in the driver monitoring.

1121
01:09:00,470 --> 01:09:04,640
And then Tesla is the no driver
monitoring and huge data collection.

1122
01:09:04,910 --> 01:09:08,360
BMW has a system as
well to use. Yeah. BMW.

1123
01:09:09,560 --> 01:09:12,050
I don't, I don't want to speak
too much to the details of it.

1124
01:09:12,051 --> 01:09:15,350
They have lane keeping
systems. So basically systems
that keep you in the lane,

1125
01:09:15,860 --> 01:09:16,250
uh,

1126
01:09:16,250 --> 01:09:21,250
that is similar to what in spirit
autopilot it's supposed to do but is less

1127
01:09:21,681 --> 01:09:23,690
aggressive in how often
you can use it and so on.

1128
01:09:23,950 --> 01:09:26,780
But if you look at the performance of the,
of the actual,

1129
01:09:27,110 --> 01:09:31,160
how often the system is able to keep
you in lane autopilot is currently the

1130
01:09:31,161 --> 01:09:35,960
leader in that space and they're
also the most aggressive,

1131
01:09:36,230 --> 01:09:38,210
uh,
innovators in that space.

1132
01:09:38,211 --> 01:09:40,970
So they're like really pushing it
to improve further and further.

1133
01:09:41,240 --> 01:09:43,220
And the open question is though,

1134
01:09:43,250 --> 01:09:46,730
worrying question is if
it improves much more,

1135
01:09:47,180 --> 01:09:52,130
are there going to be effects
like complacency? Like
people will, we'll take, uh,

1136
01:09:52,520 --> 01:09:54,800
we'll start texting more.
We started looking off road more.

1137
01:09:55,010 --> 01:09:59,090
That's a totally open question and
nobody knows the answer to it really.

1138
01:10:00,200 --> 01:10:04,340
And there's a lot of folks
that I mentioned in the
safety engineers and human

1139
01:10:04,341 --> 01:10:05,091
factors community.

1140
01:10:05,091 --> 01:10:10,091
So these psychology folks who have
roots and like aviation that no,

1141
01:10:10,580 --> 01:10:14,990
there's, there's been 70 years of work
that looks at vigilance that people,

1142
01:10:15,140 --> 01:10:19,820
if I forced you to sit here and
monitor for something weird happening,

1143
01:10:19,850 --> 01:10:24,850
like radar operators in the World War
II had to watch for the.to appear.

1144
01:10:26,420 --> 01:10:31,420
If I sit you behind that radar and make
you do it after about 15 minutes but

1145
01:10:32,781 --> 01:10:36,740
really 30 minutes, you'll see your rate
of being able to detect any problems.

1146
01:10:36,741 --> 01:10:37,940
We'll go down significantly.

1147
01:10:38,270 --> 01:10:42,410
You just kind of zone out and so there's
like all kinds of psychology studies

1148
01:10:42,411 --> 01:10:45,790
that show that we just were a crappy
human beings are really crappy and

1149
01:10:45,800 --> 01:10:49,940
monitoring automation. If I tell you,
if I put a robot and you would just say,

1150
01:10:50,120 --> 01:10:54,440
monitor this system so it doesn't
kill anyone, you'll you'll tune in.

1151
01:10:54,440 --> 01:10:57,590
We have to be engaged. You have to
be engaged. You have to be, you know,

1152
01:10:57,591 --> 01:10:59,000
there has to be a dance attention.

1153
01:10:59,001 --> 01:11:03,970
Kind of like a mode for watching
autonomous things, right?

1154
01:11:04,040 --> 01:11:08,120
If we consider our historically the kind
of modes that people have for observing

1155
01:11:08,121 --> 01:11:08,690
things,

1156
01:11:08,690 --> 01:11:12,050
we don't really have a mode for making
sure that an autonomous thing does his

1157
01:11:12,051 --> 01:11:16,380
job. Yeah. It's, it's a mindset.
Sounded like, Oh, you know what I mean?

1158
01:11:16,381 --> 01:11:19,860
Like if in my car, okay, I'm driving.
Here we go. Ooh. Driving a turn.

1159
01:11:19,861 --> 01:11:21,540
I'm thinking I'm in driving mode.

1160
01:11:21,780 --> 01:11:26,670
When you're in autonomous mode and you're
observing, he's just like, what is this?

1161
01:11:26,700 --> 01:11:29,520
I've never done this before us.
It's fucking weird. It feels weird.

1162
01:11:29,580 --> 01:11:32,190
It's not part of human nature.
Right. It's on normal state.

1163
01:11:32,550 --> 01:11:36,150
One thing it's done
commonly in now is aviation.

1164
01:11:36,430 --> 01:11:37,770
So pilots,

1165
01:11:38,220 --> 01:11:41,620
pilots are basically monitoring
fully autonomous planes. Yeah,

1166
01:11:41,670 --> 01:11:43,500
that's a good point.
As far as I know,

1167
01:11:43,501 --> 01:11:46,470
many planes today could fly
almost fully autonomously.

1168
01:11:46,590 --> 01:11:49,470
It's also a good point when it comes to
software and updates because isn't that

1169
01:11:49,650 --> 01:11:53,690
part of the issue with this
Boeing seven 37 Max system,

1170
01:11:53,880 --> 01:11:58,880
these systems that they've had problems
with the been faulty and a couple of

1171
01:11:59,160 --> 01:12:03,660
crashed. Yeah, and that's a really
good point. And they, they've,

1172
01:12:04,380 --> 01:12:09,070
yeah, there's been too tragic crashes
recently with the Mac system and you have,

1173
01:12:09,071 --> 01:12:12,330
they bench those things, right?
Haven't they? I'm not following.

1174
01:12:13,580 --> 01:12:15,480
They also got rid of
a bunch of inspectors.

1175
01:12:15,510 --> 01:12:20,230
I think they fired like 80
inspectors today and the
unions are freaking out. Yep.

1176
01:12:20,410 --> 01:12:25,410
And there's obviously there's politics
is I think FAA supposed to supervise and

1177
01:12:26,341 --> 01:12:29,370
they were, there was a, there's a close
relationship between Boeing and FAA.

1178
01:12:29,371 --> 01:12:32,460
This questions around, I mean there's
better experts at that than me,

1179
01:12:32,461 --> 01:12:37,290
but on the software side it is worrying
because it was a single software update

1180
01:12:37,350 --> 01:12:41,760
essentially that helps prevent
the, the vehicle, the vehicle,

1181
01:12:41,790 --> 01:12:46,380
the airplane from stalling.
So if, if it's uh,

1182
01:12:46,710 --> 01:12:50,160
if the nose is tilting up, uh,
increasing the chance of stalling,

1183
01:12:50,190 --> 01:12:55,190
it's going to automate automatically a
pointed nose down the airplane and the

1184
01:12:55,920 --> 01:12:59,940
pilots in many cases, as far
as I understand, Lauren even
informed of this update,

1185
01:13:00,030 --> 01:13:02,730
right. Then they weren't
even told this happening.

1186
01:13:02,970 --> 01:13:06,660
The idea behind the update is that
they're not supposed to really know.

1187
01:13:06,661 --> 01:13:09,150
It's supposed to just manage
the flight for you. Right.

1188
01:13:09,780 --> 01:13:13,350
The problem happened when there
is a angle of attack sensor.

1189
01:13:13,380 --> 01:13:18,380
So the sensor that tells you the actual
tilt of the plane and there was a

1190
01:13:18,541 --> 01:13:21,600
malfunction in that sensor as far
as I understand in both planes.

1191
01:13:21,870 --> 01:13:25,320
And so the plane didn't actually
understand its orientation.

1192
01:13:25,410 --> 01:13:29,160
So the system started freaking
out, started pointing the
nose down aggressively,

1193
01:13:29,460 --> 01:13:32,640
and the pilots were like trying to
restabilize the planning couldn't.

1194
01:13:32,910 --> 01:13:37,610
So shortly after lift off that just
yes,

1195
01:13:37,680 --> 01:13:42,180
that's software update. That's
crazy. And that, that's, that's,

1196
01:13:42,360 --> 01:13:47,360
that's a safety culture that's dealing
with this new world of software that we

1197
01:13:47,821 --> 01:13:52,410
don't know what to do with, you
know, and, and yeah, it's a question.

1198
01:13:52,860 --> 01:13:55,620
Uh, one way is to be sort
of a little bit luddite.

1199
01:13:56,130 --> 01:13:58,980
I used the term carefully and just
be afraid and say, you know what?

1200
01:13:58,981 --> 01:14:02,220
We should really not allow
so many software updates.

1201
01:14:02,460 --> 01:14:07,200
The other one is sort of embracing it and
redefining what it means to build safe

1202
01:14:07,440 --> 01:14:11,010
AI systems in this modern world
with updates multiple times a week.

1203
01:14:11,050 --> 01:14:11,883
What do you think?

1204
01:14:12,660 --> 01:14:17,020
So I'm 100% for the,
for the software approach.

1205
01:14:17,021 --> 01:14:20,590
So I think updates,
regular updates.

1206
01:14:21,040 --> 01:14:22,510
So combining the two cultures,

1207
01:14:22,511 --> 01:14:26,410
but really letting good
software engineering and lead
the way is the way to go.

1208
01:14:26,560 --> 01:14:30,850
There is, I wish other companies
were competing with Tesla on this.

1209
01:14:31,420 --> 01:14:33,340
They're on the software side.

1210
01:14:33,400 --> 01:14:37,310
Tesla is far ahead of everyone else in,

1211
01:14:37,750 --> 01:14:41,420
in the automotive sector. And
that's one of the problems. I,

1212
01:14:43,160 --> 01:14:48,090
I, I'm worried that, you know,
competition is good. Right?

1213
01:14:48,580 --> 01:14:49,780
And I'm worried there's,

1214
01:14:49,840 --> 01:14:54,730
people are way too far behind to
actually give tests the new ideas.

1215
01:14:55,090 --> 01:14:56,800
I'll compete tests on software.

1216
01:14:57,400 --> 01:15:01,630
So most cars are not able to do
over the air as far as I know.

1217
01:15:01,900 --> 01:15:06,900
No cars are able to do major over the
air updates except Tesla vehicles they do

1218
01:15:07,391 --> 01:15:11,350
over the air updates to the
entertainment system. Like you know,

1219
01:15:11,380 --> 01:15:14,830
if you're a radio is malfunctioning, but
in terms of the control of the vehicle,

1220
01:15:14,831 --> 01:15:16,960
you have to go to the
dealership to get an update.

1221
01:15:17,730 --> 01:15:19,720
A Tesla is the only one that over the air,

1222
01:15:20,230 --> 01:15:23,110
like it can multiple times
a week do the update.

1223
01:15:23,410 --> 01:15:26,620
I think that should be a
requirement for all car companies,

1224
01:15:26,950 --> 01:15:31,540
but that requires that they rethink
the way they build cars. That's really,

1225
01:15:31,570 --> 01:15:35,680
that's really scary when you manufacturer
over a million cars a year and Toyota

1226
01:15:35,681 --> 01:15:37,720
and GM to say,

1227
01:15:38,530 --> 01:15:43,530
especially old school Detroit guys and
gals that are like legit car people to

1228
01:15:44,981 --> 01:15:49,090
say we need to hire some
software engineering. That's
a challenge. It's a totally,

1229
01:15:49,750 --> 01:15:51,970
you know, I don't know how
often you've been Detroit,

1230
01:15:51,971 --> 01:15:55,540
but there's a culture difference in
Detroit and Silicon Valley and those two

1231
01:15:55,541 --> 01:15:57,430
have to come together
to solve this problem,

1232
01:15:57,970 --> 01:16:02,200
to have like the adult
responsibility, uh, of Detroit,

1233
01:16:02,350 --> 01:16:05,530
of how to do production well,
manufacturer, how to do safety well,

1234
01:16:05,710 --> 01:16:08,590
how to test the vehicle as
well and do the bold, crazy,

1235
01:16:08,591 --> 01:16:11,500
innovative spirit of silicon
valley, which, you know,

1236
01:16:11,501 --> 01:16:13,810
I'm mosque in basically
every way represents.

1237
01:16:14,320 --> 01:16:19,320
And that I think that will define the
future of these have actually AI in

1238
01:16:20,351 --> 01:16:21,184
general.

1239
01:16:21,400 --> 01:16:26,050
I mean interacting with AI systems
just even outside the automotive sector

1240
01:16:26,650 --> 01:16:29,620
requires these questions of safety,
of Ai,

1241
01:16:29,621 --> 01:16:34,000
safety of how we supervise the system,
how we manage them from misbehaving.

1242
01:16:34,001 --> 01:16:35,470
And so on.
We're also,

1243
01:16:35,471 --> 01:16:40,000
there's a concern about those systems
being vulnerable to third party attacks.

1244
01:16:40,840 --> 01:16:45,040
Yeah. So hacking. Yeah, that's
a, that's a fascinating question.

1245
01:16:45,340 --> 01:16:50,340
I think there is a whole discipline
called adversarial machine learning in AI,

1246
01:16:51,670 --> 01:16:56,670
which basically any kind of system you
can think of how we can feed it examples,

1247
01:16:58,030 --> 01:17:02,560
how we can add a little bit of noise
to the system to full it completely.

1248
01:17:02,890 --> 01:17:05,890
So there's been demonstrations
on Alexa for example,

1249
01:17:06,130 --> 01:17:10,310
where you can take a,
you can take a,

1250
01:17:10,340 --> 01:17:14,780
you can feed noise into the system that's
imperceptive with us humans and make

1251
01:17:14,781 --> 01:17:15,920
it believe you said anything.

1252
01:17:16,880 --> 01:17:21,590
So full of system into thinking the
ordering extra toilet paper, I dunno.

1253
01:17:22,180 --> 01:17:22,850
Uh,

1254
01:17:22,850 --> 01:17:27,850
in the same for cars you can feed noise
into the cameras to make it believe that

1255
01:17:29,121 --> 01:17:33,080
there is, or there isn't a pedestrian,
there is or there isn't lane markings.

1256
01:17:33,320 --> 01:17:36,860
So someone could do this.
It's in theory at least.

1257
01:17:37,040 --> 01:17:40,910
And in theory that's the big
difference is in theory is doable.

1258
01:17:40,911 --> 01:17:45,080
You can do demonstrations in practices
actually really difficult to do in the

1259
01:17:45,081 --> 01:17:47,030
real world.
So in the lab you can do it,

1260
01:17:47,120 --> 01:17:50,540
you can construct a situation where a
pedestrian can wear certain types of

1261
01:17:50,541 --> 01:17:54,080
clothing or put up a certain kind of sign
where they disappear from the system.

1262
01:17:54,470 --> 01:17:56,300
I have to ask you this because
now I just remember this,

1263
01:17:56,301 --> 01:17:58,100
you'd be the perfect
person to talk about this.

1264
01:17:58,130 --> 01:17:59,990
I'm not sure if you remember this case,

1265
01:18:00,260 --> 01:18:01,850
but there was a guy
named Michael Hastings,

1266
01:18:02,120 --> 01:18:06,170
Michael Hastings with a
journalist and he was,

1267
01:18:06,470 --> 01:18:08,300
I believe in Iraq or Afghanistan.

1268
01:18:08,301 --> 01:18:13,301
He was somewhere overseas and he was
stuck there because of this volcano that

1269
01:18:14,001 --> 01:18:15,650
erupted and I believe Iceland.

1270
01:18:16,310 --> 01:18:19,730
And he was over there for the Rolling
Stone magazine, uh, and doing,

1271
01:18:19,731 --> 01:18:24,380
doing an article about a general while
he stayed there for a long time because

1272
01:18:24,381 --> 01:18:26,930
they were stranded because of the volcano.

1273
01:18:27,260 --> 01:18:30,230
And they got real comfortable
around him. And, uh,

1274
01:18:30,530 --> 01:18:35,530
he reported a lot of the stuff that they
said and did that maybe they thought

1275
01:18:35,900 --> 01:18:38,600
that he probably wouldn't
have reported on,

1276
01:18:38,960 --> 01:18:43,790
including them saying disparaging things
about President Obama at the time.

1277
01:18:43,970 --> 01:18:48,360
Anyway, comes back, the general
was forced to resign. Um,

1278
01:18:48,380 --> 01:18:50,690
he was a beloved general and,
uh,

1279
01:18:50,750 --> 01:18:54,140
Michael Hastings was in fearing for his
life because he thought that they were

1280
01:18:54,141 --> 01:18:58,100
going to come and get them because these
people were very, very angry at him.

1281
01:18:58,730 --> 01:19:02,030
He wound up driving his car into a tree,

1282
01:19:02,031 --> 01:19:06,740
going like 120 miles an hour and the
car exploded and the engine went flying.

1283
01:19:07,430 --> 01:19:12,430
And people that were the
conspiracy theorists were
saying they believe that that

1284
01:19:14,391 --> 01:19:19,391
car had been rigged to work autonomously
or that someone for some third party,

1285
01:19:21,140 --> 01:19:25,220
bad person decided to, or good
person, depending on your perspective,

1286
01:19:25,520 --> 01:19:29,720
decided to drive that guy's car into
a fucking tree at 120 miles an hour.

1287
01:19:30,020 --> 01:19:31,070
Do you think that that,

1288
01:19:31,100 --> 01:19:35,120
and this is 2011,

1289
01:19:36,320 --> 01:19:41,000
Michael Hastings Death, 12, maybe 2012.

1290
01:19:43,460 --> 01:19:47,510
We'll see what it says. 2013. June, 2013.

1291
01:19:47,540 --> 01:19:51,620
Do you think that in 2013
that would have been possible?

1292
01:19:56,700 --> 01:19:59,950
It's entirely possible. I
just wanted to say that. Huh?

1293
01:20:00,750 --> 01:20:05,010
Shout out to the Joe Rogan
sub reddit. Okay. Uh,

1294
01:20:06,120 --> 01:20:06,960
check that one off.
The

1295
01:20:10,740 --> 01:20:15,080
Jamie pulled that up. Shut off. Um,

1296
01:20:17,850 --> 01:20:22,230
I, uh, whether it's possible,
it's an interesting question,

1297
01:20:22,231 --> 01:20:26,340
whether it's likely is another
question. I, I think it's very unlikely.

1298
01:20:26,790 --> 01:20:29,040
And the other most important questions,

1299
01:20:29,041 --> 01:20:34,041
that's something we should worry at scale
about our future is cars being used to

1300
01:20:34,921 --> 01:20:38,850
assassinate essentially
people. I'm Russian, so I've,

1301
01:20:38,851 --> 01:20:42,610
I've heard of those things being
done by our friend Putin, Nova.

1302
01:20:44,550 --> 01:20:45,510
I think,

1303
01:20:45,870 --> 01:20:50,070
I think it's very unlikely that this
kind of thing would happen at scale,

1304
01:20:50,460 --> 01:20:51,510
that people would use this.

1305
01:20:51,511 --> 01:20:55,980
I think there'll be more effective ways
to achieve this kind of end for sure.

1306
01:20:56,370 --> 01:20:56,880
And I,

1307
01:20:56,880 --> 01:21:01,880
I just think it's a very difficult
technical challenge that uh,

1308
01:21:02,790 --> 01:21:07,790
if hacking happens it would
be at a different level
than hacking the AI systems.

1309
01:21:10,100 --> 01:21:15,100
It will be just hacking software and
hacking software is the kind of the,

1310
01:21:15,361 --> 01:21:17,040
the kind of thing that
can happen with anything.

1311
01:21:17,041 --> 01:21:22,041
An elevator elevator software or
any kind of software that operates,

1312
01:21:22,411 --> 01:21:26,330
any aspect of our lives could be hacked.
And that same kind of what my,

1313
01:21:26,550 --> 01:21:31,290
my question though was in 2013 was that
a technology available where they could

1314
01:21:31,291 --> 01:21:35,970
take over someone's car?
Do you know what car it was?

1315
01:21:36,060 --> 01:21:40,620
Mercedes? I think it was an
s class. C to C C C class.

1316
01:21:41,840 --> 01:21:45,350
Yes. Yes, yes. But I, I don't think,

1317
01:21:46,310 --> 01:21:47,600
oh boy,
this is like,

1318
01:21:47,750 --> 01:21:50,760
no, it's, listen, this has
been widely speculated. I know,

1319
01:21:50,820 --> 01:21:52,740
I'm just asking you because
you're actually an expert.

1320
01:21:52,741 --> 01:21:56,850
I mean it's very rare that you get an
expert in autonomous vehicles and you get

1321
01:21:56,851 --> 01:22:00,300
to run a conspiracy theory by them to
see if they can just put a stamp on it

1322
01:22:00,301 --> 01:22:01,740
being possible or not.

1323
01:22:01,790 --> 01:22:04,670
Let me just say that Alex Jones
is a fishing, not a lot to say.

1324
01:22:04,671 --> 01:22:06,570
Mit scientists says

1325
01:22:08,380 --> 01:22:12,500
exactly what he's going to try to
do. Uh, no, I um, first of all,

1326
01:22:12,501 --> 01:22:15,590
let me just back off and say
I am not a security expert,

1327
01:22:15,650 --> 01:22:18,260
which is a very important difference.
That is important.

1328
01:22:18,270 --> 01:22:20,090
So then a autonomous vehicle.

1329
01:22:20,091 --> 01:22:23,660
I build a autonomous vehicle systems.

1330
01:22:23,720 --> 01:22:27,830
I don't know how to make
them extremely robust,

1331
01:22:27,831 --> 01:22:30,920
the security to hacking attacks and
have a lot of really good friends,

1332
01:22:30,950 --> 01:22:35,630
which are some of the coolest people I
know who are basically hackers converted

1333
01:22:35,631 --> 01:22:39,050
to security experts. I would
say though, loosely speaking,

1334
01:22:39,051 --> 01:22:40,970
I think the technology was there,
yes.

1335
01:22:41,060 --> 01:22:45,230
For with physical access to the car
to be able to control it. But I don't,

1336
01:22:45,770 --> 01:22:48,320
I think it's extremely unlikely.
That's what happened.

1337
01:22:48,760 --> 01:22:52,000
I agree. I see where
you're coming from. Um,

1338
01:22:52,570 --> 01:22:56,350
I'm not asking you whether or not it's
likely that it happened and I'm sure you

1339
01:22:56,351 --> 01:22:58,660
don't even have much information on the
case cause I had explained it to you.

1340
01:22:58,661 --> 01:23:02,820
Right. That's right. All right.
Um, the guy also had, uh,

1341
01:23:03,370 --> 01:23:06,130
some serious amphetamines in the system.
Um,

1342
01:23:06,160 --> 01:23:08,290
they compared it to crystal Meth,

1343
01:23:08,291 --> 01:23:11,740
but the reality is he was a
journalist and most journalists,

1344
01:23:11,770 --> 01:23:16,770
I want to say most all lot are on
Adderall and Adderall is essentially you

1345
01:23:17,920 --> 01:23:20,860
amphetamines. I mean, that's
what it is. It's real. It's like,

1346
01:23:21,400 --> 01:23:25,180
it's like next door neighbors
to crystal meth really is. Um,

1347
01:23:26,620 --> 01:23:29,170
he is it,
well,

1348
01:23:29,200 --> 01:23:34,000
you said it's possible they could
actually get it to turn the wheel. Yes.

1349
01:23:34,001 --> 01:23:37,150
I have to look at the exact system
that gets that drive by wire thing.

1350
01:23:37,220 --> 01:23:40,280
And I mentioned some systems are not,
uh,

1351
01:23:40,630 --> 01:23:43,560
it's not so easy to turn the wheel.
Actually could,

1352
01:23:44,000 --> 01:23:45,850
could get them to just
accelerate out of control.

1353
01:23:45,851 --> 01:23:49,240
He's going like 120 something miles
an hour and he slammed into a tree.

1354
01:23:49,720 --> 01:23:53,650
It's entirely possible. Ah,
you can't do it twice. The um,

1355
01:23:54,310 --> 01:23:59,050
the systems back then though, we're
far more primitive. Correct? Yeah. Uh,

1356
01:23:59,051 --> 01:24:03,710
yeah, but it's really, again, the,
the attack vectors here. The, so the,

1357
01:24:04,000 --> 01:24:08,090
the way you hack the systems, I have
more to do with the software, Lola,

1358
01:24:08,130 --> 01:24:11,800
a software that can be primitive
than the high level AI stuff. Right.

1359
01:24:11,801 --> 01:24:14,980
But my issue with it was there's no
cameras on the outside of the vehicle.

1360
01:24:14,981 --> 01:24:19,880
Like there is on a Tesla today. What has
autonomous driving as an option as a, so,

1361
01:24:19,990 --> 01:24:21,100
okay.
I see your point now.

1362
01:24:21,250 --> 01:24:25,420
So he wouldn't be hacking the system
that perceives the world and activists in

1363
01:24:25,421 --> 01:24:25,960
the world.

1364
01:24:25,960 --> 01:24:30,960
It would literally be malfunction that
forces it to not be able to brake,

1365
01:24:31,540 --> 01:24:34,580
accelerate uncontrollably,
which is, uh, you know,

1366
01:24:34,581 --> 01:24:39,581
it's a more basic kind of attack and then
control then making the car steer auto

1367
01:24:39,920 --> 01:24:42,430
lane. Yes, yes. That's a different,

1368
01:24:42,660 --> 01:24:45,940
that's what people worry about with the
autonomous vehicles. When more and more,

1369
01:24:46,180 --> 01:24:50,530
you're talking about potentially 10,
20 million lines of source code.

1370
01:24:50,630 --> 01:24:54,790
So there's all this code
and so obviously becomes uh,

1371
01:24:55,330 --> 01:24:56,020
amenable,

1372
01:24:56,020 --> 01:25:01,020
susceptible to bugs that can be exploited
to hack the code and some people are

1373
01:25:02,561 --> 01:25:07,300
worried, uh, legitimately so
that the security attacks would,

1374
01:25:07,301 --> 01:25:10,450
uh, would lead to these kind of, um,

1375
01:25:11,070 --> 01:25:15,930
well at the worst case assassinations
but really sort of just basic, uh,

1376
01:25:16,060 --> 01:25:20,500
basic attacks, basic hacking
attacks. And I think it's,

1377
01:25:21,040 --> 01:25:23,890
I think that's something that people in
the automotive industry and certainly

1378
01:25:23,891 --> 01:25:28,891
tested is really working hard on and
making sure that the ad that everything is

1379
01:25:29,201 --> 01:25:33,190
secure, there's going to be of course
vulnerabilities always. But uh,

1380
01:25:33,191 --> 01:25:35,560
I think they're really
serious about preventing them.

1381
01:25:36,040 --> 01:25:41,040
But in a demonstration space you'd be
able to demonstrate some interesting ways

1382
01:25:41,441 --> 01:25:44,060
to trick the system.
And in terms of computer vision,

1383
01:25:44,080 --> 01:25:49,080
th this all boils down to that
these systems are actually,

1384
01:25:49,450 --> 01:25:51,070
that are ones that are camera based.

1385
01:25:51,490 --> 01:25:56,290
I not as robust as our human eyes
are to the world. So, like I said,

1386
01:25:56,320 --> 01:25:57,550
if you had a little bit of noise,

1387
01:25:57,551 --> 01:26:02,230
you can convince it to see anything to
us humans, it look like the same road,

1388
01:26:02,260 --> 01:26:04,210
like the same three pedestrians crossing

1389
01:26:04,340 --> 01:26:08,570
like a little person on the camera
lens, the little cameras, right.

1390
01:26:08,571 --> 01:26:09,770
You could get down there with a sharpie.

1391
01:26:11,850 --> 01:26:15,740
That's the one attack vector.
That's a is draw stuff.

1392
01:26:15,741 --> 01:26:17,630
But he jokingly say that,

1393
01:26:17,631 --> 01:26:22,070
but that's the sun plays tricks
on Cadillac, Super Cruise,

1394
01:26:22,340 --> 01:26:24,980
next generation system.
We'll address camera problem.

1395
01:26:25,250 --> 01:26:28,940
Oh well as long as the next generation
addresses it, you fucking assholes.

1396
01:26:29,360 --> 01:26:31,160
The Sun plays tricks on it.

1397
01:26:31,490 --> 01:26:34,720
So next gen system is something you're
going to have to bring that Cadillac into

1398
01:26:34,730 --> 01:26:37,170
the dealership and they're going to
have to update the song outdated yet.

1399
01:26:37,280 --> 01:26:39,910
Whereas Tesla would just handle
that shit over the area. Yeah,

1400
01:26:39,920 --> 01:26:44,000
I got an update the other day. I was
like, all right, all right. Same as,

1401
01:26:45,000 --> 01:26:49,410
that's an exciting, powerful
capability. But then the Boeing,

1402
01:26:49,411 --> 01:26:52,510
the flip side is, you know, uh,

1403
01:26:52,560 --> 01:26:55,420
it can significantly change to be
here with the system. And there,

1404
01:26:55,590 --> 01:26:57,450
there could be a glitch
that could be a glitch.

1405
01:26:57,451 --> 01:27:00,450
That could be a bug that
the Boeing one's terrifying,

1406
01:27:01,260 --> 01:27:05,010
especially with a lot of, I mean,
that number, whatever it is,

1407
01:27:05,040 --> 01:27:10,020
like 300 combined, 300 plus
people dead, maybe even 400.

1408
01:27:10,800 --> 01:27:14,220
I mean it's, I, I don't
even know how to think.

1409
01:27:14,320 --> 01:27:17,520
Think about that number
from a software glitch.

1410
01:27:17,580 --> 01:27:20,700
The guy who coated it with a girl coated,
it must feel fucking terrible.

1411
01:27:22,290 --> 01:27:26,310
Yeah. And w w you kind of walk, man,

1412
01:27:26,840 --> 01:27:28,530
it's,
it's a,

1413
01:27:28,830 --> 01:27:33,570
it's a lot of burden and it's one of the
reasons it's one of the most exciting

1414
01:27:33,571 --> 01:27:38,571
things to work on actually is the code
we write has the capability to save human

1415
01:27:39,541 --> 01:27:43,260
life. But the terrifying thing is also
has the capability to take human life.

1416
01:27:43,770 --> 01:27:48,570
And that's a, that's a weird place
to be as an engineer or a directly,

1417
01:27:48,900 --> 01:27:52,900
a little piece of code. You know, I
write thousands of them a day, you know,

1418
01:27:52,920 --> 01:27:56,610
basically notes you're taking
could eventually lead to a,

1419
01:27:57,120 --> 01:28:00,300
somebody dying, no. Zero, I
don't know anything about coding,

1420
01:28:00,301 --> 01:28:04,770
but do you have like a, is there
a spell check for coding? Yeah.

1421
01:28:04,771 --> 01:28:09,771
So it's Kinda called debugging is trying
to find bugs and it's a software that's

1422
01:28:10,351 --> 01:28:12,410
doing this. Yeah. Software. So there's,

1423
01:28:12,420 --> 01:28:17,380
depending on the programming language
and everybody should, uh, if you, uh,

1424
01:28:17,490 --> 01:28:20,520
if you haven't tried programming
you should try it. It's, it's cool.

1425
01:28:20,820 --> 01:28:24,330
It's the future should learn to
program. Okay. That's my plug

1426
01:28:24,590 --> 01:28:27,970
mostly to learn to code.
He can gauge what did that,

1427
01:28:29,020 --> 01:28:32,590
I heard that that's a part of what
scared of it. It's a problematic term.

1428
01:28:32,591 --> 01:28:35,980
I don't actually know why it's the dumbest
fucking problematic code of all time

1429
01:28:36,130 --> 01:28:41,130
because someone ridiculously
was suggesting that coal
miners could maybe learn

1430
01:28:42,850 --> 01:28:47,260
how to comp code, Computer Code and like
get a different job. They can be trained.

1431
01:28:47,860 --> 01:28:52,690
And so as some, the way people
were looking at it like that,

1432
01:28:52,691 --> 01:28:54,040
that was a,
uh,

1433
01:28:54,190 --> 01:28:59,150
like a frivolous suggestion and that it
was ridiculous to try to get someone who

1434
01:28:59,151 --> 01:29:02,100
is 50 years old.
It doesn't have any in

1435
01:29:02,100 --> 01:29:06,600
computers at all to change their job from
being a coal miner to learning how to

1436
01:29:06,601 --> 01:29:10,200
code. So they started saying it to
politicians and people mocking it.

1437
01:29:10,650 --> 01:29:15,650
But then what Twitter alleged was that
what was going on was it was being

1438
01:29:15,691 --> 01:29:20,691
connected to white supremacy
and antisemitism and a
bunch of different things.

1439
01:29:21,421 --> 01:29:22,051
Like people were saying,

1440
01:29:22,051 --> 01:29:25,230
learn to code and they were putting
in a bunch of these other phrases.

1441
01:29:25,231 --> 01:29:29,670
Then my suggestion would be, well,
that's a different fucking thing.

1442
01:29:29,671 --> 01:29:31,800
Like now you have,
like you look,

1443
01:29:31,801 --> 01:29:34,680
you have a problem with
Nazis and white supremacists,

1444
01:29:34,681 --> 01:29:38,010
but that's the problem is with Nazis and
white supremacists when someone is just

1445
01:29:38,011 --> 01:29:39,780
saying,
learn to code,

1446
01:29:39,900 --> 01:29:44,760
mocking this ridiculous idea that
you're going to teach, you know,

1447
01:29:44,761 --> 01:29:45,031
that's a,

1448
01:29:45,031 --> 01:29:48,540
that's a legitimate criticism of someone's
perspective that you're going to get

1449
01:29:48,930 --> 01:29:52,400
a coal miner to learn how to fucking
do computer coding. It's crazy. It's a,

1450
01:29:52,420 --> 01:29:56,610
it's so people getting banned for that.
Rightly so.

1451
01:29:56,611 --> 01:30:01,611
People were furious the way
Google described it to me
and Tim Pool and we were

1452
01:30:02,101 --> 01:30:05,250
discussing it, was that Google,
I mean, excuse me, Twitter,

1453
01:30:05,910 --> 01:30:08,340
the way Twitter described it was that
essentially they were dealing with

1454
01:30:08,341 --> 01:30:12,450
something where they were trying to
censor things at scale. There was,

1455
01:30:12,600 --> 01:30:16,500
there was so many people and there's so
much going on that it's very difficult

1456
01:30:16,501 --> 01:30:18,180
to get it right and that
they've made mistakes.

1457
01:30:19,050 --> 01:30:20,190
I think that's a fast,

1458
01:30:20,250 --> 01:30:24,930
one of the most fascinating applications
of AI actually is filtering,

1459
01:30:25,230 --> 01:30:29,820
trying to manage learning [inaudible]
so using machine learning to manage this

1460
01:30:29,821 --> 01:30:32,040
huge conversation.
You're talking about 500,

1461
01:30:32,340 --> 01:30:36,270
I believe it's 500 million tweets
a day, something like that. And he,

1462
01:30:36,540 --> 01:30:39,660
Jamie makes least three, three, one.

1463
01:30:41,400 --> 01:30:44,760
I was gonna say I, with this
conversation, I saw this recently,

1464
01:30:45,180 --> 01:30:47,580
I don't know who did the data
on this, but there's a, uh,

1465
01:30:48,170 --> 01:30:51,750
a statement someone put on
Twitter that said that of, um,

1466
01:30:51,780 --> 01:30:53,190
let me see if I can word it correctly.

1467
01:30:53,191 --> 01:30:57,810
It was 22% of adult Americans are on
Twitter. Well. All right. So that's like,

1468
01:30:57,870 --> 01:30:58,830
that's like a fact.

1469
01:30:58,831 --> 01:31:03,831
One of that 10% make up 80% of the
tweets created by adult Americans.

1470
01:31:08,010 --> 01:31:12,930
2% of the people on Twitter make up 80%
of the tweets. That makes sense. Yeah.

1471
01:31:13,700 --> 01:31:16,690
Lot of people are arguing
aggressively and the,

1472
01:31:16,691 --> 01:31:19,230
and the question of how to manage
that and you can't manage that,

1473
01:31:19,231 --> 01:31:22,740
but just a manual,
uh,

1474
01:31:23,450 --> 01:31:27,560
review of each individual
tweet. Yeah. You'd have to
have so many employees. Yeah.

1475
01:31:27,561 --> 01:31:32,300
That's I think more likely. I
don't think Jack is lying, but,

1476
01:31:32,360 --> 01:31:37,280
um, nor is Vigia but I do think that they
have a clear bias against conservatives

1477
01:31:37,281 --> 01:31:38,120
and that's being shown.

1478
01:31:38,450 --> 01:31:42,590
So that's an interesting question. I have,
uh, your friend, my friend and mentor,

1479
01:31:42,591 --> 01:31:46,580
Eric Weinstein. Yeah. Talk to me. I
disagreed with him a little bit on this.

1480
01:31:47,430 --> 01:31:51,770
I think, uh, he basically
believes so there's a bias.

1481
01:31:51,980 --> 01:31:56,030
It boils down to the conversation that
Jack is having at the, at the top level,

1482
01:31:56,031 --> 01:32:00,880
inside Twitter. What, what is
that conversation like? Uh,

1483
01:32:01,090 --> 01:32:04,240
I think, I tend to believe, again,

1484
01:32:04,270 --> 01:32:09,010
this might be my naive nature,
is that they have,

1485
01:32:09,040 --> 01:32:10,990
they don't have bias and they have just,

1486
01:32:11,080 --> 01:32:15,220
they're trying to manage
this huge flood of, um,

1487
01:32:15,880 --> 01:32:19,600
of tweets and what they're
trying to do is not buy,

1488
01:32:19,960 --> 01:32:23,800
is not to remove sort of conservative
as the liberals and so on.

1489
01:32:24,100 --> 01:32:25,920
They're trying to,
uh,

1490
01:32:26,440 --> 01:32:31,040
remove people that lead to,
uh,

1491
01:32:31,120 --> 01:32:32,860
others leaving the conversation.

1492
01:32:32,861 --> 01:32:36,310
So they want more people to be
in the conversation. I think

1493
01:32:36,360 --> 01:32:37,740
that's true as well,

1494
01:32:37,890 --> 01:32:41,580
but I think they definitely are biased
against conservative people. There was a,

1495
01:32:41,581 --> 01:32:45,450
an Alexander ex,
Alexandra AOC.

1496
01:32:46,260 --> 01:32:49,200
Octavia has,
AOC is good.

1497
01:32:50,140 --> 01:32:54,810
Cortez is the last one. Is it
Octavia? Ocasio that's right. Okay.

1498
01:32:54,811 --> 01:32:59,370
I'm sorry, Alexander Aoc. Sorry,
I'm just, I'm thinking I was,

1499
01:32:59,410 --> 01:33:01,590
there wasn't planning on
talking about her, but, um,

1500
01:33:01,650 --> 01:33:05,040
there was a parody account and someone
was running this parody account,

1501
01:33:05,041 --> 01:33:08,190
which was very mild,
just humorous parody account.

1502
01:33:08,191 --> 01:33:11,250
They were banned permanently for running
it and then their own account was

1503
01:33:11,251 --> 01:33:14,700
banned as well. Whereas, um, you know,

1504
01:33:14,760 --> 01:33:19,110
there's some progressive
people are liberal people
that post all sorts of crazy

1505
01:33:19,111 --> 01:33:22,050
shit and they don't,
they don't get banned at the same brain.

1506
01:33:22,080 --> 01:33:26,130
It's really clear that
someone in the company,

1507
01:33:26,520 --> 01:33:28,740
whether it's up for manual review,

1508
01:33:28,741 --> 01:33:31,290
whether it's at the discretion
of the people that are employees,

1509
01:33:31,530 --> 01:33:34,110
when you're thinking about a company
that's a silicone valley company,

1510
01:33:34,111 --> 01:33:36,810
you are in without doubt.

1511
01:33:37,140 --> 01:33:40,050
You're dealing with people
that are leaning left.

1512
01:33:40,560 --> 01:33:44,640
There's so many that lean
left in silicon valley.

1513
01:33:44,641 --> 01:33:48,360
The idea that that company was secretly
run by Republicans is ridiculous.

1514
01:33:48,630 --> 01:33:52,560
They're, they're almost all run by
Democrats or progressive people.

1515
01:33:52,890 --> 01:33:57,330
So that the leadership level,
there's, there's a nail
mindedness that, that, that,

1516
01:33:57,660 --> 01:34:00,950
that permeates all silicon valley. You're
saying? Well, the question I think,

1517
01:34:00,950 --> 01:34:01,030
I think

1518
01:34:01,030 --> 01:34:05,740
there's a leaning left that permeates
silicon valley. I think that's undeniable.

1519
01:34:05,950 --> 01:34:07,570
I think it's undeniable.
I mean,

1520
01:34:07,750 --> 01:34:10,690
I think if you had a poll that people
that work in silicon valley where their

1521
01:34:10,691 --> 01:34:14,320
political leanings are,
I think it would be by far left.

1522
01:34:14,590 --> 01:34:17,200
I think it would be the vast majority.
Um,

1523
01:34:17,230 --> 01:34:20,560
does that mean that affects
their decisions? Well,
what's the evidence bloom?

1524
01:34:20,590 --> 01:34:22,150
It's kind of shows us does,
you know,

1525
01:34:22,490 --> 01:34:26,810
they're not treating it
with 100% clarity and,

1526
01:34:26,811 --> 01:34:31,180
and you know,
across the board accuracy or um,

1527
01:34:31,210 --> 01:34:32,043
fairness rather.

1528
01:34:32,350 --> 01:34:36,610
I think that there's absolutely people
that work there that lean and there's

1529
01:34:36,611 --> 01:34:39,040
been videos where they've captured people,
uh,

1530
01:34:39,041 --> 01:34:42,550
that were Twitter employees talking
about it, talking about how you do that,

1531
01:34:42,551 --> 01:34:44,680
how you, uh, make their, you know,

1532
01:34:44,960 --> 01:34:48,610
you find someone who's a
using Trump talk or, you know,

1533
01:34:48,611 --> 01:34:51,670
saying sad at the end of things and
someone's talking, he's gonna, you know,

1534
01:34:51,671 --> 01:34:55,270
that certain characteristics they look
for and he's been videos of what does

1535
01:34:55,271 --> 01:35:00,271
that project Veritas with guy got his
employees got undercover footage of

1536
01:35:00,651 --> 01:35:02,570
Twitter employees talking
about that kind of stuff.

1537
01:35:02,870 --> 01:35:04,910
The question is how much power
do those individuals have?

1538
01:35:04,911 --> 01:35:08,390
How many individuals are
there like that are that,

1539
01:35:09,030 --> 01:35:13,280
are those people exaggerating their
ability and what they do at work or the,

1540
01:35:13,310 --> 01:35:16,970
are they talking about something that
used to go on but doesn't go on anymore?

1541
01:35:17,180 --> 01:35:19,610
I don't know. I don't work
there. I think it boils down to

1542
01:35:20,080 --> 01:35:22,440
I, I'm one of those
people that believes it's,

1543
01:35:22,530 --> 01:35:26,530
it boils down to the leadership to
people at the top set the culture and the

1544
01:35:26,531 --> 01:35:27,670
culture has to be,

1545
01:35:28,780 --> 01:35:33,360
it cannot be this kind of
silicon valley narrow minded, uh,

1546
01:35:33,670 --> 01:35:36,940
sort of left leaning
thinking even if you believe,

1547
01:35:36,970 --> 01:35:41,470
even if you're a hardcore liberal,
you cannot, when you operate the car,

1548
01:35:41,500 --> 01:35:44,500
when you drive and manage a
conversation in the entire world,

1549
01:35:44,501 --> 01:35:47,020
you have to think about Middle America.
You have to think about,

1550
01:35:47,080 --> 01:35:50,590
you have to have fundamental respect
for human beings who voted for Trump.

1551
01:35:51,010 --> 01:35:56,010
It is a concerning thing for me to see
just a narrow mindedness of an all forms.

1552
01:35:56,770 --> 01:36:00,970
One of the reasons I enjoy listening
to this podcast is you're pretty open

1553
01:36:00,971 --> 01:36:01,804
minded.

1554
01:36:01,810 --> 01:36:06,810
That open mindedness is essential
for leaders of Facebook and Twitter.

1555
01:36:07,570 --> 01:36:09,430
People who are managing conversations.

1556
01:36:09,750 --> 01:36:11,860
I think so too. I think
it's, I think it's uh,

1557
01:36:13,890 --> 01:36:16,180
the thought of being open minded and,

1558
01:36:16,181 --> 01:36:21,181
and acting in that ethic is probably
one of the most important things that we

1559
01:36:21,511 --> 01:36:25,230
could go forward with right now
because things are getting so greasy.

1560
01:36:25,620 --> 01:36:27,810
It's so slippery on,
on both sides.

1561
01:36:28,140 --> 01:36:33,140
And we're in this weird position that I
don't recall ever in my life there being

1562
01:36:33,991 --> 01:36:37,890
such a divide between the right and the
left in this country. I don't, it's more,

1563
01:36:38,880 --> 01:36:42,030
more vicious, more angry, more hateful.

1564
01:36:42,330 --> 01:36:44,940
It's different than at
any other time in my life.

1565
01:36:45,300 --> 01:36:50,300
And I think a lot of our ideas are based
on these narratives that may or may not

1566
01:36:51,841 --> 01:36:56,760
even be accurate. And then we support
them and we reinforce them on either side.

1567
01:36:56,790 --> 01:36:58,020
We reinforce them on the left,

1568
01:36:58,021 --> 01:37:02,310
we reinforced them on the right where
if you looking at reality itself and you

1569
01:37:02,311 --> 01:37:03,600
don't have these,
uh,

1570
01:37:03,720 --> 01:37:08,520
clear parameters and these clear
ideologies, I think we're way,

1571
01:37:08,521 --> 01:37:11,970
most of us are way more in the middle
than we think we are. Most of us are.

1572
01:37:12,000 --> 01:37:14,040
We just don't want racist
running the country.

1573
01:37:14,160 --> 01:37:16,860
We don't want socialists
given all our money away.

1574
01:37:16,980 --> 01:37:20,040
We don't want to pay too much
in taxes to a shitty government.

1575
01:37:20,130 --> 01:37:23,280
We don't want schools getting
underfunded. We, we all, you know,

1576
01:37:23,460 --> 01:37:24,960
and then we decide what,

1577
01:37:24,990 --> 01:37:28,560
what does my team like the team that I,

1578
01:37:28,561 --> 01:37:31,230
the shit that I like is that this team,
well not everything,

1579
01:37:31,231 --> 01:37:33,900
but they've got a lot of things. So I'll
go with them. Maybe I'm not a religious,

1580
01:37:33,901 --> 01:37:37,320
not, but I'm fiscally conservative and I
don't like with Democrats like to spend

1581
01:37:37,321 --> 01:37:41,760
money. I'm going to go with
the Republicans. You know,
maybe, maybe I'm more,

1582
01:37:42,930 --> 01:37:47,520
I'm more concerned with the state of the
economy and the way we trade with the

1583
01:37:47,521 --> 01:37:50,390
world than I am with certain social
issues that the Democrats embrace.

1584
01:37:50,490 --> 01:37:51,750
So I'll lean that way.

1585
01:37:51,930 --> 01:37:54,810
Even though I do support gay rights
and I do support this and I do sport,

1586
01:37:55,020 --> 01:37:59,250
all these other progressive ideas
this way more of us in that boat.

1587
01:37:59,490 --> 01:38:03,420
There's way more of us that are in this
middle of the whole thing for sure.

1588
01:38:03,450 --> 01:38:05,290
But there it goes up and down.
So

1589
01:38:05,420 --> 01:38:10,280
all of us, so I'm old, I believe. I
hope I am open minded most of the time.

1590
01:38:10,520 --> 01:38:14,810
But you have different moods. Oh,
for sure. Yeah. And the question is,

1591
01:38:14,811 --> 01:38:16,430
this is where the role of AI comes in.

1592
01:38:17,150 --> 01:38:20,570
Does the AI that recommends
what tweets I should see,

1593
01:38:20,571 --> 01:38:22,910
what Facebook messengers as should see?

1594
01:38:23,570 --> 01:38:28,570
Is that encouraging the darker parts
of me or the the Steven pinker better

1595
01:38:29,091 --> 01:38:31,730
angels of our nature?
Like is it, what stuff is?

1596
01:38:31,731 --> 01:38:34,860
It's showing me because if it shows me,
uh,

1597
01:38:35,180 --> 01:38:40,160
stuff that like if the AI
trains purely unclicked,

1598
01:38:40,510 --> 01:38:45,020
it made start to learn when I'm in a bad
mood and point me to things that might

1599
01:38:45,021 --> 01:38:46,070
be upsetting to me.

1600
01:38:46,490 --> 01:38:51,490
And so escalating that division and
escalating this vile thing that can be

1601
01:38:53,151 --> 01:38:54,750
solved most likely would

1602
01:38:54,820 --> 01:38:58,210
people training little more
Jujitsu or something this size,

1603
01:38:58,390 --> 01:39:02,350
this Facebook algorithm that encourages
people to be outraged because

1604
01:39:02,890 --> 01:39:07,100
accidentally, not even on purpose,
but this is what engages people. Well,

1605
01:39:07,101 --> 01:39:09,010
this is what gets clicks.
So they find out,

1606
01:39:09,011 --> 01:39:12,430
oh well he clicks on things when you find
that other people are anti-vaccination

1607
01:39:12,640 --> 01:39:16,690
or he clicks on things when he
finds out, you know, whatever,

1608
01:39:16,720 --> 01:39:18,400
fill in the blank with
whatever the subject is.

1609
01:39:18,490 --> 01:39:21,280
And then you get these mother fuckers,
you know,

1610
01:39:21,300 --> 01:39:24,160
this is the reason why measles is
spreading and you start getting an angry,

1611
01:39:24,280 --> 01:39:27,010
I mean the anti vaccs
arguments on Facebook,

1612
01:39:27,011 --> 01:39:30,970
I don't know if he ever dip into those
waters for a few minutes and watch people

1613
01:39:30,971 --> 01:39:35,230
fight back and forth and in fury
and anger, you know, it's a,

1614
01:39:35,530 --> 01:39:39,880
it's another one of those things
that becomes a extremely lucrative,

1615
01:39:40,180 --> 01:39:45,160
uh,
subject for any social media empire.

1616
01:39:45,430 --> 01:39:45,761
If you're,

1617
01:39:45,761 --> 01:39:49,090
if you're all about getting people to
engage and that's where the money is in

1618
01:39:49,091 --> 01:39:49,924
advertising,

1619
01:39:50,010 --> 01:39:52,610
you actually getting people to click on
the page and the ads were on those page.

1620
01:39:52,611 --> 01:39:55,840
You get those clicks, get that money
if that's how the system is set up.

1621
01:39:55,841 --> 01:39:58,420
And I'm not exactly sure how it is
cause I don't really use Facebook,

1622
01:39:58,750 --> 01:40:01,690
but that's what it benefits.
I mean that's what,

1623
01:40:01,691 --> 01:40:04,150
that's what it gravitates towards.
Gravitates towards controversy.

1624
01:40:04,690 --> 01:40:05,523
So,

1625
01:40:05,940 --> 01:40:10,080
and when we think about concern for AI
systems to talk about sort of Terminator,

1626
01:40:10,090 --> 01:40:13,390
I'm sure we'll, we'll touch on it,
but I think of Twitter as a whole,

1627
01:40:13,391 --> 01:40:14,410
as one organism.

1628
01:40:15,250 --> 01:40:19,690
That is the thing that worries me the
most is the artificial intelligence that

1629
01:40:19,691 --> 01:40:21,970
is very kind of dumb and simple,

1630
01:40:21,971 --> 01:40:26,580
simple algorithms that are driving the
behavior of millions of people and at

1631
01:40:26,620 --> 01:40:30,490
together the kind of chaos
that we can achieve. I mean,

1632
01:40:30,491 --> 01:40:35,080
that algorithm has incredible
influence in all society. Twitter are,

1633
01:40:35,160 --> 01:40:40,000
our current president is on
Twitter so much. Oh yeah. All Day,

1634
01:40:40,001 --> 01:40:43,990
all night. The, the, I mean
it's scary to think about.

1635
01:40:44,620 --> 01:40:48,340
We talk about autonomous vehicles
leading to fate to Alwan fatality to

1636
01:40:48,341 --> 01:40:52,990
fatalities is scary to think about what
the difference be a small change in the,

1637
01:40:53,410 --> 01:40:57,190
in the Twitter algorithm.
I mean, I could start wars.

1638
01:40:57,310 --> 01:41:00,790
It really could it and that if
you think about the long term,

1639
01:41:00,820 --> 01:41:05,020
if you think about it as one AI organism
that is a super intelligent organism

1640
01:41:05,170 --> 01:41:06,610
that will have no control over.

1641
01:41:07,290 --> 01:41:11,410
And I think it all boils down honestly,
to the leadership,

1642
01:41:11,890 --> 01:41:14,530
to Jack, uh, to, to, to,

1643
01:41:14,700 --> 01:41:18,850
and other folks like him making sure
that he's open minded. It goes hunting,

1644
01:41:19,210 --> 01:41:21,370
that he goes, uh, does some Jujitsu,

1645
01:41:21,670 --> 01:41:25,420
that he eats some meat and sometimes
goes Vegan. Right. You know, he did a,

1646
01:41:25,450 --> 01:41:28,510
just in a 10 day Toklas retreat.

1647
01:41:29,320 --> 01:41:33,070
We don't talk it off for 10 days.
He also eats one like he does.

1648
01:41:33,130 --> 01:41:35,710
I follow some of the dye
of him eats once a day.

1649
01:41:36,580 --> 01:41:40,360
I've done that and fast all through the
weekend, which I don't, that's crazy.

1650
01:41:40,370 --> 01:41:44,660
I've never done that. But I've done some,
I've done quite a few 24 hour, you know,

1651
01:41:44,661 --> 01:41:47,510
where I, I eat at 7:00
PM. I'm done eating.

1652
01:41:47,511 --> 01:41:50,660
I don't touch food until 7:00 PM the
next day. It's just water or coffee.

1653
01:41:50,810 --> 01:41:54,740
Why do you do it? By the
way? To shock my system.

1654
01:41:54,950 --> 01:41:57,500
I think it's good for
your system. Um, you know,

1655
01:41:57,530 --> 01:42:02,090
there's been a lot of research on fasting
and the effect it has on telomeres.

1656
01:42:02,390 --> 01:42:06,530
Uh, Doctor Rhonda Patrick
spoke, um, pretty recently.

1657
01:42:06,531 --> 01:42:10,910
There's been quite a few things that
she's written about in terms of a fasting,

1658
01:42:10,920 --> 01:42:13,550
the benefits of fasting. Intermittent
fasting is great for weight loss,

1659
01:42:13,551 --> 01:42:16,760
but just fasting itself
and even for several days,

1660
01:42:17,090 --> 01:42:21,050
most people seem to get some
pretty decent benefits out of it.

1661
01:42:21,170 --> 01:42:25,450
So I dabble in it. I also liked
the way it makes me feel, um,

1662
01:42:25,520 --> 01:42:28,310
to be a little hungry.
I think my brain is sharper.

1663
01:42:28,490 --> 01:42:31,580
Like I refuse to go on
stage full. I, Oh, when I,

1664
01:42:31,581 --> 01:42:34,880
when I do stand up and I actually learned
this from a cat Williams interview,

1665
01:42:35,090 --> 01:42:38,420
he was talking about it and uh,
ease crazy as fuck,

1666
01:42:38,421 --> 01:42:40,880
but he's hilarious and he's one
of the greats in my opinion.

1667
01:42:41,090 --> 01:42:44,570
And he was in the back of a limo and he
was talking about how he prepares for a

1668
01:42:44,571 --> 01:42:48,810
show that he has his music that he
listens to pre show music is like a,

1669
01:42:48,811 --> 01:42:53,690
a music list. Um, and then,
uh, he will have a drink,

1670
01:42:53,960 --> 01:42:56,720
no food. He won't eat because it
slows you down. And I was like,

1671
01:42:56,721 --> 01:42:59,150
does slow you down,
but sometimes you don't even think of it.

1672
01:42:59,151 --> 01:43:01,850
It's not like a rule. So you just,
man, I'm hungry. I'll just eat.

1673
01:43:02,180 --> 01:43:04,940
I would way rather cause I can
go through a couple of shows.

1674
01:43:05,180 --> 01:43:06,790
I used to think I used to have this fault,

1675
01:43:06,791 --> 01:43:09,980
the idea that if I didn't eat I
would be exhausted to do things.

1676
01:43:09,981 --> 01:43:14,510
But then I work out fast at every morning,
every morning when I,

1677
01:43:14,511 --> 01:43:19,070
when I get my morning workout
in and whatever the fuck it is,

1678
01:43:19,071 --> 01:43:23,570
it's usually hard. I'm always fasted.
He could do a lot. It's, you're not,

1679
01:43:23,600 --> 01:43:26,470
it's not at your best.
Like if I was going to do Jujitsu,

1680
01:43:26,510 --> 01:43:29,390
I don't do Jujitsu fasted. I
would, I would eat some fruit.

1681
01:43:29,430 --> 01:43:32,380
That's an interesting one because that
was the transformational thing for me.

1682
01:43:32,381 --> 01:43:33,980
I used to do power lifting.
You see like

1683
01:43:34,160 --> 01:43:36,170
five times a day, six
times a day, whatever.

1684
01:43:36,560 --> 01:43:41,380
More like CT Fletcher Style Kinda
see how big he was back in the day.

1685
01:43:41,430 --> 01:43:44,810
He's only maybe like my height or
a half inch taller or some shit.

1686
01:43:44,960 --> 01:43:47,210
He was 320 pounds.

1687
01:43:47,211 --> 01:43:51,890
So what he said three 15
fuck. He was big. Yeah.

1688
01:43:52,130 --> 01:43:55,940
And you're saying like at trouble,
the thing is when you get that big,

1689
01:43:55,970 --> 01:44:00,800
and I wasn't that big, but it's like hard
to move. Oh yeah. It's like not healthy.

1690
01:44:00,880 --> 01:44:04,550
If you, did you see the image of him from
yesterday? I didn't see the image. He,

1691
01:44:04,580 --> 01:44:05,413
when he,
uh,

1692
01:44:05,420 --> 01:44:10,420
Jamie put up a photograph of him at 315
pounds next to him at like a tuition,

1693
01:44:12,110 --> 01:44:15,770
200 dishes, like a hundred. And it's
incredible how big he was. I mean,

1694
01:44:15,800 --> 01:44:16,491
everything was his,

1695
01:44:16,491 --> 01:44:20,780
like his arms were my legs and they
were just coming out of his shoulders.

1696
01:44:21,230 --> 01:44:25,040
So that was, that was a big moment for
me. Uh, areas. There's the pictures

1697
01:44:27,070 --> 01:44:29,990
come. Peggy was when he was
a world champion. I mean,

1698
01:44:30,050 --> 01:44:34,610
just insanely huge. Wow. Yeah. Um,

1699
01:44:34,611 --> 01:44:36,180
so when you started training in Jujitsu,

1700
01:44:36,181 --> 01:44:40,560
you look at that in the blonde on the
right dude, he's 50. Look at that. Oh,

1701
01:44:40,730 --> 01:44:43,730
all natural to all natural at 50.

1702
01:44:44,180 --> 01:44:48,920
Crazy fuck and genetic son.
That's some good,

1703
01:44:49,670 --> 01:44:53,810
oh yeah. Obsessive. Not just hard work.
I mean you have to be a fucking maniac,

1704
01:44:54,590 --> 01:44:57,890
but the fact that his body holds
up like that at 50 is incredible.

1705
01:44:58,250 --> 01:45:02,450
He's an inspiration for me.
Switching from that to Jujitsu,

1706
01:45:02,480 --> 01:45:05,720
I thought there's no way cause I
train hard. I train twice a day.

1707
01:45:05,750 --> 01:45:09,280
Did you get sued for awhile
and we doing two roles a day.

1708
01:45:09,281 --> 01:45:13,220
Were you doing like technique and drills?
One at one time? Listen, I'm rushing.

1709
01:45:13,221 --> 01:45:17,120
I just go hard. I'm upset. No, no,
no, no, no, no, no. Russian drilling.

1710
01:45:17,150 --> 01:45:19,910
Let me explain to you something. Okay,
cool. What do you want, explain to me.

1711
01:45:20,270 --> 01:45:24,620
I'm trying to explain to you
the difference in Russian
and American America is

1712
01:45:24,920 --> 01:45:26,120
in wrestling and a lot of,

1713
01:45:26,290 --> 01:45:31,290
in a lot of combat sports is like heart
and guts and hard work over and Russian

1714
01:45:33,561 --> 01:45:36,530
is certainly in wrestling.
His technique is drilling.

1715
01:45:36,860 --> 01:45:40,520
They put a lot more hours than Americans
do at less than a hundred percent

1716
01:45:40,521 --> 01:45:43,490
effort. So like really drilling,
they're really getting that right.

1717
01:45:43,491 --> 01:45:44,750
Like I love that.
In fact,

1718
01:45:44,751 --> 01:45:48,680
one of the problems is I haven't
been able to really ever found,

1719
01:45:48,980 --> 01:45:52,370
I was always the last one to get bored.
I drily Oh,

1720
01:45:52,371 --> 01:45:56,230
can you got to find a good drilling
partner? Like an obsessed one. Uh, uh,

1721
01:45:56,260 --> 01:45:59,720
shout out to uh, Sarah
Block at Juco, a judo,

1722
01:46:00,150 --> 01:46:05,150
a lady as a black digits as well that
was willing to put up with like hundreds

1723
01:46:06,380 --> 01:46:11,350
or thousands of throws a that we each
did. So like that, that obsessive models,

1724
01:46:11,440 --> 01:46:11,690
any,

1725
01:46:11,690 --> 01:46:15,380
I love that kind of stuff cause I think
that's you get better and that's where

1726
01:46:15,620 --> 01:46:18,560
not everybody believes that people,
some people believe,

1727
01:46:18,590 --> 01:46:22,520
especially with Jiu Jitsu, like you
can't really get timing from drilling.

1728
01:46:22,790 --> 01:46:25,670
I believe you can get everything
from drilling of the timing. The,

1729
01:46:26,030 --> 01:46:29,870
the cause is as long. The other
part, it's not just aimless drilling,

1730
01:46:29,930 --> 01:46:31,890
it's your mind, isn't it? Your,

1731
01:46:31,940 --> 01:46:35,480
your brain should be exhausted by the
end of it too because you're visualizing

1732
01:46:35,481 --> 01:46:37,550
the whole thing.
You're like going through,

1733
01:46:37,820 --> 01:46:40,640
you're imagining how your opponent would,

1734
01:46:40,790 --> 01:46:44,210
it's really strengthening your imagination
while you're also doing the drilling.

1735
01:46:44,240 --> 01:46:45,200
I couldn't agree more.
Yeah.

1736
01:46:45,410 --> 01:46:50,280
I firmly believe you can get better way
better drilling. And uh, when I went from

1737
01:46:50,640 --> 01:46:52,860
I think blue belt to purple,

1738
01:46:52,861 --> 01:46:55,980
I did like the most drilling
than I ever did ever.

1739
01:46:56,250 --> 01:47:00,480
And that's when I grew the most. That's
when my, my technique got way better.

1740
01:47:00,570 --> 01:47:04,200
That was also when I became friends with
Eddie Bravo and Eddie Bravo was a huge

1741
01:47:04,201 --> 01:47:07,590
driller. Huge. Oh he shrills man,

1742
01:47:07,620 --> 01:47:10,590
they drill like crazy and
they do a lot of live drills.

1743
01:47:10,920 --> 01:47:14,850
And they do a lot of pathway drills
where they'll do like a whole series of

1744
01:47:14,851 --> 01:47:18,760
movements and then his escape and
then the reversal and they're like,

1745
01:47:18,830 --> 01:47:23,310
these are long pathways so that when
you're actually in a scrap and you're

1746
01:47:23,311 --> 01:47:27,690
rolling you, you recognize it. Like,
okay, here it is. I'm passing the guard,

1747
01:47:27,691 --> 01:47:29,790
I move it to here and
now he's countering me,

1748
01:47:29,940 --> 01:47:33,870
but I'm setting up this and
these pathway drills, there's,

1749
01:47:33,960 --> 01:47:37,200
it's so critical because it comes up
over and over and over again when you're

1750
01:47:37,201 --> 01:47:40,860
actually live rolling, you know,
you feel it. You feel like, Oh,

1751
01:47:40,861 --> 01:47:42,290
I've been here before.
I know this is,

1752
01:47:42,910 --> 01:47:44,380
I'd be curious actually to hear,

1753
01:47:44,590 --> 01:47:49,150
I don't think I've ever heard
you talk about how your game is.

1754
01:47:49,151 --> 01:47:52,540
My game changed significantly from
white belt, a blue belt, purple belt.

1755
01:47:52,940 --> 01:47:57,190
They started to solidify,
but I'd be curious to hear like what,

1756
01:47:57,220 --> 01:48:01,470
how did you gain change since you
met Eddie? Gave meaning Jesus.

1757
01:48:01,720 --> 01:48:06,550
Well, my most of my game came from Eddie
like 99 point something percent of it,

1758
01:48:06,670 --> 01:48:09,040
almost all of it.
And John Jock those too.

1759
01:48:09,460 --> 01:48:12,730
So it's like I was a blue belt before I
was friends with anybody. I was terrible.

1760
01:48:12,760 --> 01:48:16,270
Like what guard do you prefer, for
example? Well, I do rubber guard.

1761
01:48:16,480 --> 01:48:17,620
I'm very flexible.

1762
01:48:17,650 --> 01:48:21,610
So rubber guard is no issue with me
and I think it's incredibly effective.

1763
01:48:21,670 --> 01:48:26,470
I think if you're good at it and you know,
you get stuck under a guy like,

1764
01:48:26,471 --> 01:48:28,390
um,
what does his name,

1765
01:48:28,391 --> 01:48:33,040
Jeremiah Vance is a Eddie's uh,
one of Eddie's um,

1766
01:48:33,250 --> 01:48:37,540
black belts who was a murderer from
his back. His Rubber Guard is insane.

1767
01:48:37,660 --> 01:48:40,650
It's insane. Eddie's rubber guards
and saying, I mean, you know,

1768
01:48:40,660 --> 01:48:44,830
obviously tap toilet Gracie as a
ridiculous guard economy and triangle. Um,

1769
01:48:45,160 --> 01:48:48,070
but there's a lot of people
that understand it now.

1770
01:48:48,100 --> 01:48:52,090
A lot of people that know how to do
it, it's um, it's a real art form.

1771
01:48:52,330 --> 01:48:57,330
And the thing about it versus other
guards is when you're in a position like

1772
01:48:57,521 --> 01:49:01,300
mission control and you clean, you know,
Vinny Magallanes is phenomenal at it.

1773
01:49:01,360 --> 01:49:05,980
I mean, he, what's that video
of fuck this guy up quick.

1774
01:49:06,070 --> 01:49:10,570
Watch it. This is Jeremiah. Jeremiah
advances one of Eddie's best.

1775
01:49:10,600 --> 01:49:13,360
We'll get this from the bottom.
Bam. He does that all the time.

1776
01:49:13,390 --> 01:49:16,800
Triangle from the bottom off from rubber
guard that guys wrapped up, that's a,

1777
01:49:16,820 --> 01:49:19,000
that's out cold.
He does this all the time.

1778
01:49:19,001 --> 01:49:21,910
He's one of Eddie's best
rubber guard assassins.

1779
01:49:22,120 --> 01:49:24,970
And if you watch his technique
and his fucking sensational,

1780
01:49:25,300 --> 01:49:26,860
he also has great leg locks too.

1781
01:49:27,160 --> 01:49:30,850
But the thing is that you know when
he'll attack from his legs and you'll tap

1782
01:49:30,851 --> 01:49:34,110
people with a leg lock, but if they
escape, sometimes they'll escape.

1783
01:49:34,160 --> 01:49:37,930
And this just too deep shit right here.
But now he's going to take us back.

1784
01:49:38,590 --> 01:49:41,950
But if they escape,
oftentimes he's on the bottom.

1785
01:49:42,160 --> 01:49:45,730
And when you're on top of him, it's one
of the worst places in the world to be.

1786
01:49:45,731 --> 01:49:49,330
His guard is fucking, and it's
because of that. See that grip,

1787
01:49:49,360 --> 01:49:52,630
see how he's holding the rubber guard in
position? That's called mission control.

1788
01:49:53,110 --> 01:49:53,771
Mission control.

1789
01:49:53,771 --> 01:49:58,771
Mission control from a guy like Jeremiah
is fucking ruthless because he has his

1790
01:49:58,901 --> 01:50:03,310
arm and his legs. It's controlling
your neck and your posture. It just,

1791
01:50:03,311 --> 01:50:06,790
and then he's going to a Gogo here and uh,
he's phenomenal at this too.

1792
01:50:07,450 --> 01:50:09,870
He's going to get them in a
Gogo Plata or normal Plata.

1793
01:50:10,600 --> 01:50:12,940
It's going to flip them over now.
Now he's attacking the leg.

1794
01:50:13,060 --> 01:50:17,320
Like it's just constant. And Eddie
ever ends this kind of system. Well,

1795
01:50:17,321 --> 01:50:22,321
he invented the initial stage of like
setting up mission control and go,

1796
01:50:23,500 --> 01:50:27,040
this guy is getting fucked up.
Oh my God, that's horrible.

1797
01:50:27,580 --> 01:50:32,580
But Eddie invented a series of pathways
from mission control to set up various

1798
01:50:33,281 --> 01:50:35,380
techniques, armbars triangles,
all these different things.

1799
01:50:35,470 --> 01:50:40,420
But there had been people that had toyed
with doing high garlic Nino Schembri,

1800
01:50:40,590 --> 01:50:44,440
he, he did a lot of like,
like rubber guard asks stuff.

1801
01:50:44,441 --> 01:50:46,210
There was a lot of things that people did,

1802
01:50:46,420 --> 01:50:49,240
but Eddie has his own
pathway and his own system.

1803
01:50:49,450 --> 01:50:53,170
And then there's a lot of guys that branch
off from that system, like Jeremiah,

1804
01:50:53,810 --> 01:50:57,820
like Vinny Magallanes that have their
own way that they prefer to set various

1805
01:50:57,821 --> 01:51:02,020
techniques up too. But what's really good
about that, if you have the flexibility,

1806
01:51:02,320 --> 01:51:04,990
is that you're,
when you're on the bottom,

1807
01:51:05,020 --> 01:51:07,420
it's not only is it not a bad place to be,

1808
01:51:07,690 --> 01:51:11,920
but you could put some in some real
trouble. When you have your ability,

1809
01:51:11,921 --> 01:51:15,340
you're holding onto your
ankle and using your leg,

1810
01:51:15,400 --> 01:51:17,980
which is the strongest fucking
limb in your body. Right.

1811
01:51:18,160 --> 01:51:22,000
Pulling down on someone with your leg,
clamping down with your arm,

1812
01:51:22,120 --> 01:51:25,090
and then you get your other leg involved.
Good luck getting out of that.

1813
01:51:25,450 --> 01:51:28,150
Good luck. It's fucking
sucks man. You have control,

1814
01:51:28,151 --> 01:51:30,690
but you're also able to move
at the same time. Exactly.

1815
01:51:31,030 --> 01:51:33,430
Does anybody ever puts you in
mission control before? No.

1816
01:51:33,431 --> 01:51:36,100
I haven't competed or against many,

1817
01:51:36,101 --> 01:51:39,550
but even in like someone in class
like show it to explain it to, yeah,

1818
01:51:39,551 --> 01:51:43,420
lower ranks. Once you
feel it, you go, oh shit.

1819
01:51:43,421 --> 01:51:44,590
I remember it being,

1820
01:51:45,190 --> 01:51:49,210
you know when somebody
does a nice move on you,

1821
01:51:49,510 --> 01:51:52,990
especially like a lower rank, your first
reaction is like, oh, this would never,

1822
01:51:53,020 --> 01:51:57,700
like you're annoyed. Yes. It's the, it's
the natural process of the ego. Of course.

1823
01:51:57,701 --> 01:52:00,690
Getting rid of, you know, you see
something new and you're like, yeah,

1824
01:52:00,790 --> 01:52:03,040
this is stupid.
If I next time it won't work.

1825
01:52:03,040 --> 01:52:04,720
But then you start to
understand a little more.

1826
01:52:04,721 --> 01:52:08,110
I remember it being really
powerful controlling position.

1827
01:52:08,380 --> 01:52:12,850
It's powerful and if you have a
good offensive attack from there,

1828
01:52:12,880 --> 01:52:15,100
it's powerful as well.
Their transitions,

1829
01:52:15,310 --> 01:52:18,490
such the God like Jeremiah
who's really flexible, you know,

1830
01:52:18,491 --> 01:52:23,080
he can pull off Gogal plot does
and all sorts of other things. Um,

1831
01:52:23,620 --> 01:52:24,670
local plot does.

1832
01:52:24,700 --> 01:52:29,290
It's another one that they do is one
that you push with your other foot on the

1833
01:52:29,291 --> 01:52:31,030
heel.
It's so nasty.

1834
01:52:31,031 --> 01:52:35,500
You're holding the back of the foot across
the back of the neck and so your shin

1835
01:52:35,501 --> 01:52:39,460
is underneath someone's throat and then
you're pushing that Shin with your other

1836
01:52:39,461 --> 01:52:44,380
heal while you're squeezing with your
arm. It's ruthless is ruthless, you know?

1837
01:52:44,381 --> 01:52:47,360
And they do a gable grip around the head
when they do this as well sometimes too.

1838
01:52:47,361 --> 01:52:49,640
So it's just a fucking awful place to be.

1839
01:52:50,160 --> 01:52:54,260
So it's not as good as being on top.
Right. If you have a crushing top game,

1840
01:52:54,290 --> 01:52:56,360
that's the best.
If you can get to that position,

1841
01:52:56,361 --> 01:52:57,800
but you can't always get to that position.

1842
01:52:58,070 --> 01:53:01,730
So there's guys like Jeremiah that
even from the bottom, they're horrific.

1843
01:53:01,731 --> 01:53:05,180
Dangerous as dangerous is
from the top for most people

1844
01:53:05,650 --> 01:53:07,960
I do.
You find just a,

1845
01:53:08,050 --> 01:53:10,660
when you trained back in
the day and you still train,

1846
01:53:10,690 --> 01:53:12,400
do you spend more time on bottom or top?

1847
01:53:13,140 --> 01:53:16,260
You always should start. I feel like
you should always start on the bottom,

1848
01:53:16,320 --> 01:53:19,800
earned the top position. And this is
something to Eddie always brought up too.

1849
01:53:19,980 --> 01:53:23,310
Cause you know you'd be like to like,
it's fun to be on top.

1850
01:53:23,340 --> 01:53:25,740
So a lot of times it's
like this mad scrambled.

1851
01:53:25,780 --> 01:53:27,840
See who could force who onto their back,
right?

1852
01:53:27,841 --> 01:53:31,290
Because when you're on top you can
control them, you can pressure them.

1853
01:53:31,830 --> 01:53:34,920
You know you play that strong man's
Jujitsu. But the problem is, is trauma is,

1854
01:53:34,921 --> 01:53:37,380
you didn't tell him only 200
pounds. I'm not a big guy. Like,

1855
01:53:37,381 --> 01:53:41,370
so if you go to the real big guy,
like I'm rolling with a 240 pound guy,

1856
01:53:41,400 --> 01:53:44,220
I'm not going to get to that spot.
Like, I better have a good guard,

1857
01:53:44,280 --> 01:53:46,260
otherwise I can't do anything right.

1858
01:53:46,590 --> 01:53:49,440
When someone's bigger than you
and stronger than you, you mean?

1859
01:53:49,440 --> 01:53:52,290
That's what Hawaii is crazy
basically proved to the world.

1860
01:53:52,620 --> 01:53:55,710
Like as long as you have technique,
it doesn't matter where you are,

1861
01:53:56,160 --> 01:53:59,550
but if you only have top game,
which a lot of people do,

1862
01:53:59,580 --> 01:54:01,920
a lot of people only have top game.
You know,

1863
01:54:01,921 --> 01:54:04,110
you're kind of fucked if
you wind up on your back.

1864
01:54:04,230 --> 01:54:07,260
We see that a lot with
wrestlers in MMA as wrestlers,

1865
01:54:07,261 --> 01:54:09,360
they can get on top of you and
they'll fuck you up. They'll,

1866
01:54:09,390 --> 01:54:12,270
they'll strangle you there, take your
back, they'll beat you up from the mount,

1867
01:54:12,690 --> 01:54:16,440
but they don't have nearly the same
game when they're on their back.

1868
01:54:17,370 --> 01:54:18,900
And then there's guys like Luke Rockhold,

1869
01:54:18,901 --> 01:54:20,970
it's like an expert or
keeping you on your back.

1870
01:54:21,300 --> 01:54:24,540
He's when he's one of those guys, when
he gets on top of you, you're fucked.

1871
01:54:24,990 --> 01:54:29,700
He's got horrible top game.
I mean, horrible and sense
of if you're as opponent,

1872
01:54:30,150 --> 01:54:32,790
he's gonna beat the fuck out
of you before he strangles you.

1873
01:54:32,791 --> 01:54:34,230
His top game is insane.

1874
01:54:34,920 --> 01:54:39,690
Yeah. I, I hate the feeling. Some
people make it, just feel the weight,

1875
01:54:40,200 --> 01:54:44,720
make you suffer for everything
you do on bottom. It's uh, uh,

1876
01:54:44,850 --> 01:54:47,870
people that are able to do
that. A truly humbling. Yeah.

1877
01:54:48,340 --> 01:54:51,450
Slurs in particular wrestlers
are so good at money.

1878
01:54:51,490 --> 01:54:55,720
Did you see that Jordan Burroughs? Ben Ask
and match last night. Fucking credible.

1879
01:54:55,721 --> 01:54:58,750
How good is that Guy Jordan boss?
Ooh,

1880
01:54:58,780 --> 01:55:03,190
as I do that to a guy like Ben ask grin.
I mean it just shows you

1881
01:55:03,280 --> 01:55:06,560
Ben hasn't competed I think in nine years.

1882
01:55:06,710 --> 01:55:11,090
But Ben is one of the greatest,
I mean I'm a huge fan of his wrestling.

1883
01:55:11,120 --> 01:55:15,430
It's so interesting. I think that is
like the worst matchup for Ben. Ask Her.

1884
01:55:15,431 --> 01:55:19,240
And I think because
you're, you're taking, uh,

1885
01:55:19,280 --> 01:55:22,540
one of the most creative
wrestlers ever been.

1886
01:55:22,570 --> 01:55:27,500
Oscar and I don't want to
over over overstate it, but
he has incredibly creative,

1887
01:55:27,501 --> 01:55:29,570
one of the great pinning wrestler.

1888
01:55:29,571 --> 01:55:34,070
So he pins people he like confuses
them and pins them incredibly well.

1889
01:55:34,730 --> 01:55:38,830
And you, you put them against
basically a freak blast.

1890
01:55:38,831 --> 01:55:43,710
Double like the greatest double leg
take down maybe of all time, all time.

1891
01:55:44,190 --> 01:55:48,750
Like somebody put a clip up that said, uh,
is this it? Yeah. So when you put a clip,

1892
01:55:48,780 --> 01:55:52,980
oh shit. He went off the fucking mad
into the crowd. That's pretty fast part.

1893
01:55:53,580 --> 01:55:56,840
He defended a take down. That was the best
part. But that's crazy man, that they,

1894
01:55:56,970 --> 01:55:59,460
they have such a drop off with these guys.

1895
01:56:00,030 --> 01:56:04,050
Like you shouldn't really have a platform
like that where a guy can fall off

1896
01:56:04,080 --> 01:56:07,470
into the crowd. That seems
so stupid. It rarely happens.

1897
01:56:07,500 --> 01:56:11,400
What the fuck are you talking about?
Just happened. Rarely happens.

1898
01:56:11,401 --> 01:56:15,480
They rarely have these. It's true. This
is argument. That's a terrible thing.

1899
01:56:15,520 --> 01:56:19,620
Have that shit flat on the ground. That
is so dumb. I can't even believe they did.

1900
01:56:19,660 --> 01:56:23,850
I think this whole mess
should be contested. Doesn't
count. Well I don't, I don't,

1901
01:56:24,600 --> 01:56:28,770
you know, I think, look, that's stupid.

1902
01:56:29,370 --> 01:56:31,180
That's not smart.
Dev.

1903
01:56:31,380 --> 01:56:34,740
A guy who's a fucking
powerhouse of a blast,

1904
01:56:34,741 --> 01:56:39,330
double hitting you and sending
you flying to the, that's crazy.

1905
01:56:39,810 --> 01:56:43,380
That is crazy that they didn't have
anything in place to stop that.

1906
01:56:43,560 --> 01:56:46,710
That's a reason why wrestling takes place
on the ground. You fucking assholes.

1907
01:56:46,880 --> 01:56:50,670
And like, why are you having people
wrestle on a platform that's crazy show.

1908
01:56:50,671 --> 01:56:53,790
So the, the, the show, you
can have a show where Don's,

1909
01:56:54,020 --> 01:56:56,730
where it's on the grounds
called basketball. Yeah. Yeah.

1910
01:56:56,731 --> 01:57:00,150
It's on the ground and you know it was
worrying because [inaudible] and I'm a

1911
01:57:00,151 --> 01:57:03,180
fighter and you get injured with
that right there. Right there.

1912
01:57:03,181 --> 01:57:05,310
It could have torn his
lead knee apart easily.

1913
01:57:05,580 --> 01:57:10,260
Well the silver lining is that he's
okay. Yeah. The silver lining and a,

1914
01:57:10,270 --> 01:57:11,400
and we got to see that,
you know,

1915
01:57:11,401 --> 01:57:14,850
it was interesting Jordan Burroughs had
on his Instagram, there's levels to this,

1916
01:57:14,851 --> 01:57:17,490
you know, they're raising his hand up
and looks like that's what we got to see.

1917
01:57:17,580 --> 01:57:21,020
Cause Ben is a phenomenal wrestler.
But you're right,

1918
01:57:21,040 --> 01:57:22,500
he hasn't competed in a long time.

1919
01:57:22,530 --> 01:57:25,050
He's not necessarily at the
level that he was back then.

1920
01:57:25,051 --> 01:57:29,880
Even though he's incredible
for MMA standards. It's
good to see like it's good.

1921
01:57:29,881 --> 01:57:32,850
It's good to see that with boxing it's
good to see that with anything like when

1922
01:57:32,851 --> 01:57:35,440
Floyd Mayweather fought Conor,
I think it was good to see that,

1923
01:57:35,560 --> 01:57:39,810
that there are really levels to this. And
the interesting thing about journ bars,

1924
01:57:39,811 --> 01:57:44,811
I think he's so good that he's probably
going to stay out of MMA so crazy.

1925
01:57:45,360 --> 01:57:48,820
But there are, here's some,
here's some clips of it.
You're not going to shut this.

1926
01:57:49,010 --> 01:57:53,500
But yeah, we can't show
it to people. But uh, who,

1927
01:57:53,520 --> 01:57:56,070
who put this on flow wrestling,
flow, wrestling, put this on.

1928
01:57:56,071 --> 01:57:59,730
I wonder if people are pirating it online
or if they put it online that they're

1929
01:57:59,731 --> 01:58:04,580
allowing and no, they, well, people
are pirating it. Yeah. Yeah. Okay.

1930
01:58:05,640 --> 01:58:08,490
Yeah. Good luck stopping
that. Right. Well,

1931
01:58:08,491 --> 01:58:12,510
I think people should
support flow wrestling though
though. They do have like a,

1932
01:58:12,600 --> 01:58:16,230
I'm a member. Are you? Oh, look at
this. Look at this. God, he's good.

1933
01:58:17,640 --> 01:58:21,240
Yeah, man. So we're watching this, ladies
and gentlemen who are just listening.

1934
01:58:21,300 --> 01:58:24,800
It's probably boring as fuck for you,
but I'm Jordan Burroughs is a,

1935
01:58:24,870 --> 01:58:27,840
one of the best wrestlers really.

1936
01:58:27,870 --> 01:58:30,960
America's ever produced
three time world champion,

1937
01:58:31,330 --> 01:58:36,330
tragically not tried it lost
in the previous Olympics
and he's back at it again.

1938
01:58:36,960 --> 01:58:41,530
I wonder if he's ever considered MMA.
I know it was some about it,

1939
01:58:41,531 --> 01:58:41,980
but I wonder if

1940
01:58:41,980 --> 01:58:45,450
you have a really, I think
at this point he's, uh,

1941
01:58:45,660 --> 01:58:50,560
he is basically a no,
but there are a few terrifying people,

1942
01:58:50,590 --> 01:58:52,570
especially on the Russian side that I,

1943
01:58:52,571 --> 01:58:56,980
that I think the heavyweight
division and um, and UFC should,

1944
01:58:57,240 --> 01:59:00,150
he should be really worried.
I don't know if you've heard about the,

1945
01:59:00,151 --> 01:59:04,620
the Russian tank,
the 22 year olds from Dagestan no hose.

1946
01:59:04,621 --> 01:59:09,340
This guy as a wrestler, the wrestler
and he's going to fight MMA? No, he's,

1947
01:59:09,400 --> 01:59:10,240
he's uh,

1948
01:59:10,450 --> 01:59:14,680
he will after 2020 is what
his expectation is for now.

1949
01:59:14,860 --> 01:59:17,410
He's probably going to be the
greatest wrestler of all time.

1950
01:59:17,590 --> 01:59:21,930
Really him against Kyle Snyder,
those two heavyweights as a mayor,

1951
01:59:21,931 --> 01:59:25,960
Collins not as American. Another
guy. 20 the tank of Dagestan.

1952
01:59:26,080 --> 01:59:28,570
How'd you say his name?
Uh,

1953
01:59:29,020 --> 01:59:31,640
it says [inaudible] of [inaudible].

1954
01:59:32,050 --> 01:59:36,380
Abdulla Rasheed said ally of 22 years old.
So Snyder,

1955
01:59:36,430 --> 01:59:39,010
you can do call Snyder
versus what a great name.

1956
01:59:39,670 --> 01:59:44,670
Abdul Rashid Sidoli of that alive that
was Russian as Snyder is 23 years old.

1957
01:59:46,510 --> 01:59:48,960
And he's another incredible
person who will do MMA.

1958
01:59:49,600 --> 01:59:53,770
And that competition with Gene
Snyder. Uh, I mean this is,

1959
01:59:53,800 --> 01:59:56,320
look at the look,
the look of the thickness.

1960
01:59:58,270 --> 02:00:03,190
These guys are monsters and they're not
just how much these guys, where I uh,

1961
02:00:04,540 --> 02:00:05,680
97 kilograms,

1962
02:00:06,350 --> 02:00:11,170
two to 2120 under two to 15,
but they cut for it. Right.

1963
02:00:11,500 --> 02:00:13,810
Which is just under heavyweight.
These guys,

1964
02:00:14,210 --> 02:00:17,710
do you think they would compete at two oh
five. If they're going to fight in MMA,

1965
02:00:17,950 --> 02:00:20,470
these are heavyweights cause so that we
just don't remember it in the weight.

1966
02:00:20,530 --> 02:00:24,440
These are still boys. Oh 22. Right.

1967
02:00:24,910 --> 02:00:28,110
They still haven't gotten the full lake.
Yeah.

1968
02:00:28,120 --> 02:00:32,110
I wonder that about UFC fighters that
are thickening up as they get older.

1969
02:00:32,170 --> 02:00:35,740
I wonder how many of them are damaging
their body by cutting weight. Yeah.

1970
02:00:36,730 --> 02:00:38,910
That's a thick fellow. So, um,

1971
02:00:38,950 --> 02:00:42,160
right now we're just seeing mostly
stalemate and that's uh, from uh,

1972
02:00:42,460 --> 02:00:44,470
the American guy and the,
yeah.

1973
02:00:44,530 --> 02:00:47,140
Is it like a highlight reel of his
or something that we, yeah, there is,

1974
02:00:47,141 --> 02:00:49,800
but he's pretty young.
He's a, I think he's a,

1975
02:00:50,030 --> 02:00:53,380
so he's an Olympic champion and he
goes from the whole line of, um,

1976
02:00:53,950 --> 02:00:57,670
the city of brothers and the, the,
the, all the Dagestani wrestlers.

1977
02:00:57,690 --> 02:01:01,150
There are so many good fighters that are
coming out of dogs time right now and

1978
02:01:01,151 --> 02:01:05,180
all technicians. So it's
incredible. It's incredible.

1979
02:01:05,200 --> 02:01:09,130
Whatever's in the water that styles
like Zebbie legs up beat style, very,

1980
02:01:09,131 --> 02:01:13,010
very different than a wrestling
heavy style. Look at this guy.

1981
02:01:13,011 --> 02:01:17,320
I met Jesus Christ. Oh
my God. What a scramble.

1982
02:01:17,950 --> 02:01:21,190
So this is a, I'll do Russia, EAD Rashid,

1983
02:01:21,250 --> 02:01:25,270
Abdulla Rashim concept alive. Don't tell
me how to say it. I'll figure it out.

1984
02:01:25,271 --> 02:01:29,650
I don't know. She'll dolor she'd do
her, she'd said alive. Subtle lie of,

1985
02:01:30,210 --> 02:01:32,810
and you know what? The
beauty, there's a poetic, uh,

1986
02:01:32,980 --> 02:01:36,430
cause there's a poetic nature to the,
to these guys. I mean they're just,

1987
02:01:36,431 --> 02:01:40,010
that could be really,
I mean simple good

1988
02:01:40,010 --> 02:01:44,480
people, right? They're a, they're
pretty religious and they just kind of,

1989
02:01:44,810 --> 02:01:49,430
they don't even believe in fame.
They just believe in excellence.

1990
02:01:49,730 --> 02:01:53,300
Well, you know, Dan was
sort of evident and the,

1991
02:01:53,510 --> 02:01:58,220
the mindset behind them was sorta evident
at the end of that fight with Conor

1992
02:01:58,250 --> 02:02:01,580
where they went crazy and he
jumped into the crowd. He's like,

1993
02:02:01,581 --> 02:02:03,560
he's not playing games.
Like he's not,

1994
02:02:03,590 --> 02:02:08,450
he's not doing this for Instagram
likes or for, you know, this is really,

1995
02:02:08,990 --> 02:02:11,600
he takes trash talking and
all that stuff very seriously.

1996
02:02:11,601 --> 02:02:12,980
This is all about honor for him.

1997
02:02:13,790 --> 02:02:17,720
I think that was kind of
upsetting because true. But,

1998
02:02:18,040 --> 02:02:22,810
but don't do that. Yeah. And through
that, and uh, also respect, I,

1999
02:02:23,110 --> 02:02:24,030
I'd hate to say it,

2000
02:02:24,031 --> 02:02:29,031
but I think there's a certain ethic and
honor to the way Conor McGregor carries

2001
02:02:29,121 --> 02:02:32,900
himself to all that trash talk.
If you look at the end of the fights,

2002
02:02:33,260 --> 02:02:37,470
he's very calm. He's very
kind and respectful in
defeat. And when they get us,

2003
02:02:37,490 --> 02:02:41,810
it's a different culture. If you compare
the Dagestani versus Irish culture,

2004
02:02:41,811 --> 02:02:45,840
it's just the different culture. And you
have to respect that, I think could be,

2005
02:02:46,340 --> 02:02:47,173
to be honest,

2006
02:02:47,180 --> 02:02:50,570
disrespected Connor's culture as much
as kind of just suspect it could be.

2007
02:02:51,080 --> 02:02:54,980
I get what you're saying. But I mean,
when he was done with the fight,

2008
02:02:54,981 --> 02:02:56,300
he didn't keep attacking Connor.

2009
02:02:56,780 --> 02:02:59,630
It was people in the audience that
we're talking shit that were training

2010
02:02:59,631 --> 02:03:01,290
partners and motion for as high.

2011
02:03:01,330 --> 02:03:05,870
That's that he would hit her that for
weeks and he was, he was done for months.

2012
02:03:05,900 --> 02:03:09,230
He was done. He was like, fuck you, I
beat his ass and I'm gonna beat your ass.

2013
02:03:09,231 --> 02:03:11,900
And he just said, I'm not playing games.
And he jumped into the fucking crowd.

2014
02:03:12,380 --> 02:03:16,160
I think security could have been handled
far better and we'll be in the future

2015
02:03:16,161 --> 02:03:18,830
to prevent things like that from happening
where people just jumped into the

2016
02:03:18,831 --> 02:03:23,420
cage and you know, I, but
I, I hate seeing that shit,

2017
02:03:25,540 --> 02:03:29,570
but I appreciate where he's coming from.
I mean that's who the fuck that guy is,

2018
02:03:29,571 --> 02:03:34,070
man. That's one of the reasons why he's
so good as he does have that mindset.

2019
02:03:34,190 --> 02:03:37,100
It's one of the reasons Matt, and one
of the reasons why he's so relentless,

2020
02:03:37,460 --> 02:03:40,400
like he's not playing games.
Yeah. He is who he is.

2021
02:03:40,430 --> 02:03:42,380
What you see is what you
get and what you get.

2022
02:03:42,381 --> 02:03:45,110
As a killer and these he's there smash.

2023
02:03:45,260 --> 02:03:47,750
I would've loved to see Conor
McGregor versus could be,

2024
02:03:47,810 --> 02:03:51,370
it could be before the
Mayweather fight like um,

2025
02:03:51,740 --> 02:03:56,720
before Conor mm gotten,
I think the money makes you less hungry.

2026
02:03:57,050 --> 02:03:59,750
Oh for sure.
And Dude ain't hungry at all.

2027
02:04:00,400 --> 02:04:04,880
Mean he's got $100 million.
But I think he still loves to compete,

2028
02:04:05,030 --> 02:04:07,610
but there's no hunger
anymore. Like Dan, no hunger.

2029
02:04:07,700 --> 02:04:12,140
I mean he might be hungry for success,
but he's says no desperation. Yeah.

2030
02:04:12,200 --> 02:04:14,270
I don't know if that's,
I know what you're saying.

2031
02:04:14,270 --> 02:04:16,520
Like he has a lot to lose now too.
It's a different thing.

2032
02:04:16,560 --> 02:04:19,040
He enters into a fight with
$100 million in the bank.

2033
02:04:19,070 --> 02:04:23,240
It's a very different
experience and entering into
the fight know with 1 million

2034
02:04:23,241 --> 02:04:27,320
and hoping that you could make three
more tonight. And you know, like many,

2035
02:04:27,440 --> 02:04:29,390
I'm sure fights that he's had in the past.

2036
02:04:29,960 --> 02:04:34,240
It's a different world wants whatever
he wants forever and he wants a fighter

2037
02:04:34,250 --> 02:04:35,390
though.
I was a fighter.

2038
02:04:35,460 --> 02:04:40,260
I mean there is an element there
that he still wants glory, I believe.

2039
02:04:40,261 --> 02:04:43,780
Still only 30. Yeah, right. This
is still do it. Yeah. I mean he's,

2040
02:04:43,950 --> 02:04:47,700
I think how old's Connor
right at the most,

2041
02:04:47,701 --> 02:04:51,330
he's like 32 or some shit 30.
Yeah.

2042
02:04:51,360 --> 02:04:53,110
He's young man to,

2043
02:04:53,111 --> 02:04:56,790
to be set for the rest of your life
at 30 is kind of fucking bananas.

2044
02:04:57,240 --> 02:05:00,090
And I don't think he's
at his peak as a fighter.

2045
02:05:00,260 --> 02:05:02,790
So if he just decides who gives
a fuck about the money, I'm just,

2046
02:05:02,791 --> 02:05:05,160
I'm here to leave a
legacy and I'm going to,

2047
02:05:05,700 --> 02:05:10,700
I'm going to just train like a fucking
demon and he kicks aside all of the bad

2048
02:05:10,891 --> 02:05:14,970
influences and all the distractions in
his life and just focuses on training

2049
02:05:14,971 --> 02:05:18,600
mean he's a motherfucker, man. I
mean, you saw what he did to Aldo,

2050
02:05:18,750 --> 02:05:22,920
saw what he did to Chad Mendez, saw
what he did to Dustin pour. Yay. I mean,

2051
02:05:22,921 --> 02:05:25,500
he is a bad motherfucker.
Period.

2052
02:05:25,501 --> 02:05:28,410
I know you're going to shut this
down as most fans do, but I,

2053
02:05:28,800 --> 02:05:31,950
if he drops everything and
goes to like Siberia to train,

2054
02:05:32,310 --> 02:05:37,090
I would love to see him and could
be two. Well, there's nothing wrong.

2055
02:05:37,110 --> 02:05:40,140
That's my friend Hans Molan
camp and a, uh, Connor sparring.

2056
02:05:40,470 --> 02:05:42,900
Just fucking around powerful on it.
Logo in the background.

2057
02:05:42,900 --> 02:05:46,320
It's like a Goddamn on it. And I um, yeah,

2058
02:05:46,321 --> 02:05:49,110
I mean he's always going to
have a problem with could be,

2059
02:05:49,540 --> 02:05:54,450
could bebes wrestling is so high level,
it's so different.

2060
02:05:54,750 --> 02:05:59,750
He smothers you in a way that you think
you have good takedown defense to.

2061
02:05:59,781 --> 02:06:04,020
You run into that motherfucker and he
just gets a hold of everyone who does it

2062
02:06:04,021 --> 02:06:07,540
to everyone, whether you're
Michael Johnson or Edson Barboza,

2063
02:06:07,570 --> 02:06:10,890
no matter how good your takedown defense
looked in the past and the Barboza

2064
02:06:10,891 --> 02:06:14,130
fight, he was just basically
just wa weighted towards him,

2065
02:06:14,340 --> 02:06:19,110
waded through the fucking, the fury of
leg kicks and punches and just clamp,

2066
02:06:19,500 --> 02:06:23,190
drag, smash. And that's what
he does to everybody, man.

2067
02:06:23,820 --> 02:06:28,110
The real thing about a guy like him would
be seeing a guy like him against a guy

2068
02:06:28,111 --> 02:06:29,130
like Jordan burrows.

2069
02:06:29,520 --> 02:06:34,520
Like could he do that to a guy who
is a spectacular rest or as well,

2070
02:06:35,520 --> 02:06:39,660
then it becomes mean his striking,
which has gotten very high level.

2071
02:06:39,810 --> 02:06:42,810
He's very dangerous striking. So
I dropped Connor. I mean he can,

2072
02:06:42,840 --> 02:06:46,770
he can fuck people up. He
stopped. Um, there was some, he's,

2073
02:06:47,050 --> 02:06:50,370
he stopped a few people. It
strikes he me, he's dangerous.

2074
02:06:50,430 --> 02:06:54,330
He's dangerous enough on the
feet that you would have to,

2075
02:06:54,740 --> 02:06:55,573
I don't know how much,

2076
02:06:56,370 --> 02:07:00,570
how many really high level grapplers also
have like striking that can stand with

2077
02:07:00,571 --> 02:07:02,100
them.
Cause if he decided to keep it up,

2078
02:07:02,101 --> 02:07:05,130
you'd have an advantage there
until they got good at it.

2079
02:07:05,160 --> 02:07:07,650
Him verse has been asking. It
would be very interesting. Well,

2080
02:07:07,651 --> 02:07:12,090
he would have an advantage and striking
over ass grin and a in wrestling,

2081
02:07:12,091 --> 02:07:16,710
I don't know.
No big fellow too are the same way?

2082
02:07:16,770 --> 02:07:21,470
No. Oh, he's 55. Aspirin 70.
Okay. Okay. So I'd ask him,

2083
02:07:21,480 --> 02:07:24,120
could probably make 55. I
mean, if you tortured him,

2084
02:07:24,690 --> 02:07:29,630
he's got a dad bod though and he's,
no,

2085
02:07:29,690 --> 02:07:33,450
he's, he's proud dad.
Who's proud of his body?

2086
02:07:33,690 --> 02:07:36,100
I think he was that way in college.
He was never,

2087
02:07:36,180 --> 02:07:38,380
there's never like Brock Lesnar. No, no.

2088
02:07:38,440 --> 02:07:41,530
And he was just super technical
and it's strong as hell though.

2089
02:07:41,590 --> 02:07:42,460
According to everybody,

2090
02:07:43,120 --> 02:07:47,980
everybody that rolls with them says he's
fucking ridiculously strong. You, uh,

2091
02:07:48,040 --> 02:07:51,940
you sometimes say artificial life
instead of artificial intelligence. Yeah,

2092
02:07:51,941 --> 02:07:53,770
because I think that it's a life form.

2093
02:07:54,190 --> 02:07:57,250
It's a stupid way to look at as curious
to think about like how do you think

2094
02:07:57,251 --> 02:07:59,380
about artificial and
like what do you picture?

2095
02:07:59,590 --> 02:08:04,590
I picture human beings being
like electronic caterpillars
that are building a

2096
02:08:04,601 --> 02:08:09,040
cocoon that they have no real knowledge
of our understanding and through this

2097
02:08:09,370 --> 02:08:14,370
and new life forms can emerge a life
form that doesn't need cells and meeting

2098
02:08:17,320 --> 02:08:19,900
with x and y chromosomes.
It doesn't need any of that shit.

2099
02:08:20,220 --> 02:08:25,220
It exists purely in software
and in hardware and in ones
and Zeros and that this

2100
02:08:27,641 --> 02:08:29,110
is a new form of life.

2101
02:08:29,260 --> 02:08:34,120
And this is when the inevitable
rise of a sentient being,

2102
02:08:34,210 --> 02:08:34,811
the inevitable.

2103
02:08:34,811 --> 02:08:39,460
I mean I think if we don't get hit when
the asteroid within a thousand years or

2104
02:08:39,461 --> 02:08:41,590
whatever,
the numb the time frame is,

2105
02:08:41,770 --> 02:08:46,770
someone is going to figure out how to
make a thing that just walks around and

2106
02:08:47,831 --> 02:08:51,820
does whatever it wants and lives like a
person that's not outside the realm of

2107
02:08:51,821 --> 02:08:56,050
possibility. And I think that if that
does happen, that's artificial life.

2108
02:08:56,200 --> 02:09:00,340
And this is the new life and it's probably
going to be better than what we are.

2109
02:09:00,341 --> 02:09:04,930
I mean, what we are as basically
if you go back and look about,

2110
02:09:05,530 --> 02:09:06,363
you know,

2111
02:09:06,510 --> 02:09:09,640
three hundred thousand four hundred
thousand years ago when we were some

2112
02:09:09,670 --> 02:09:11,440
Australia pithy cast type creature,

2113
02:09:12,610 --> 02:09:15,210
how many of them would ever
look at the future and go,

2114
02:09:15,520 --> 02:09:18,880
I hope I never get a Tesla.
The last thing I want is a fucking phone.

2115
02:09:18,880 --> 02:09:21,400
Last thing I wanted air
conditioning and television.

2116
02:09:21,520 --> 02:09:25,900
The last thing I want is to be able to
talk in a language that other people can

2117
02:09:25,901 --> 02:09:28,840
understand and to be able to call
people on the phone. Fuck all that man.

2118
02:09:28,990 --> 02:09:32,620
I like living out here running from
Jaguars and shit and constantly getting

2119
02:09:32,621 --> 02:09:35,710
jacked by bears, you know? No,
they wouldn't think that way.

2120
02:09:35,740 --> 02:09:40,450
And I think if something comes
out of us and makes us obsolete,

2121
02:09:41,070 --> 02:09:45,580
but it's, it's missing all the
things that suck about people.

2122
02:09:46,210 --> 02:09:51,070
I mean, it won't be good. It won't be
good in our, in our things suck of people.

2123
02:09:51,150 --> 02:09:55,360
Kuwait, war, violence, thievery,

2124
02:09:55,600 --> 02:09:58,560
people stealing things from people,
people robbing people

2125
02:09:58,610 --> 02:10:02,580
both. The thing that those
dark parts of human nature,

2126
02:10:03,330 --> 02:10:06,780
I think, uh, the suffering injustice,

2127
02:10:07,110 --> 02:10:11,070
I think all of that is necessary for
us to discover the, the better angels.

2128
02:10:11,430 --> 02:10:14,610
I don't think you can a surgeon,
we can talk,

2129
02:10:15,090 --> 02:10:18,510
let's talk about saint she
and creating artificial life,

2130
02:10:18,511 --> 02:10:21,040
but I think even those lifeforms,

2131
02:10:21,120 --> 02:10:24,030
even those systems need to have

2132
02:10:24,260 --> 02:10:26,060
darker parts.
But why is that?

2133
02:10:26,090 --> 02:10:30,200
Is that because of our own biological
limitations in the fact that we exist in

2134
02:10:30,201 --> 02:10:34,910
this world of animals where animals
eating other animals and running,

2135
02:10:34,970 --> 02:10:37,670
there's always,
you always have to prepare for evil.

2136
02:10:37,671 --> 02:10:41,510
You have to prepare for intruders, you
have to prepare for, you know, predators.

2137
02:10:41,630 --> 02:10:45,740
And this is essentially like
this mechanism is there to
ensure that things don't

2138
02:10:45,741 --> 02:10:46,610
get sloppy.

2139
02:10:46,850 --> 02:10:50,960
Things continue to like if the Jaguars
keep and the people and the people don't

2140
02:10:50,961 --> 02:10:53,510
figure out how to make a fucking house,
they get eaten and that's it.

2141
02:10:53,600 --> 02:10:56,510
Or you figure out the house
and then you make weapons,

2142
02:10:56,511 --> 02:11:00,020
you find off the fucking Jaguar. Okay,
great. You made it. You're in a city now.

2143
02:11:00,080 --> 02:11:04,850
See you had to have that Jaguar there
in order to inspire you to make enough

2144
02:11:04,851 --> 02:11:09,170
safety so that your kids can grow old
enough that they can get information from

2145
02:11:09,171 --> 02:11:10,730
all the people that did survive as well.

2146
02:11:10,730 --> 02:11:13,850
And they can accumulate
all that information and
create air conditioning and

2147
02:11:13,851 --> 02:11:18,800
automobiles and guns and
keep those fucking jaguars
from eating your kids. Right?

2148
02:11:18,830 --> 02:11:22,190
This is, this is what had to take
place as a biological entity.

2149
02:11:22,220 --> 02:11:26,600
But once you surpass that and once you
become this thing that doesn't need

2150
02:11:26,601 --> 02:11:29,960
emotion, doesn't need, you
know, it doesn't need conflict.

2151
02:11:29,961 --> 02:11:32,450
It doesn't need to be inspired.
It never gets lazy.

2152
02:11:32,750 --> 02:11:36,560
It doesn't have these things that we have
built into us as a biological system.

2153
02:11:36,740 --> 02:11:41,060
Like if you looked at us as wet,
where operating software,

2154
02:11:41,790 --> 02:11:44,720
it's not good software,
right?

2155
02:11:44,750 --> 02:11:48,110
It's software designed for cave
people and we're, you know,

2156
02:11:48,111 --> 02:11:52,910
we're just trying to force it in
to cars and force it into cubicles.

2157
02:11:53,300 --> 02:11:57,860
But part of the problem with people in
their unhappiness is that all of these

2158
02:11:57,861 --> 02:12:01,580
human reward systems that had been
set up through evolution and natural

2159
02:12:01,581 --> 02:12:04,580
selection to,
to have these instincts to stay alive,

2160
02:12:04,730 --> 02:12:08,290
they're no longer relevant in
today's society. So they become,

2161
02:12:08,380 --> 02:12:13,160
they become road rage. They become, you
know, extracurricular violence. It became,

2162
02:12:13,340 --> 02:12:14,930
they become depression.

2163
02:12:14,931 --> 02:12:17,030
They become all these different
things that people suffer from.

2164
02:12:17,031 --> 02:12:19,060
So that's one perspective.
Yes.

2165
02:12:19,100 --> 02:12:23,270
That basically our software through this
evolutionary process that was necessary

2166
02:12:23,271 --> 02:12:25,880
to arrive at where we are, but
it's outdated at this point. Well,

2167
02:12:25,890 --> 02:12:30,350
it's necessary for us to
succeed, to succeed in a
purely, almost a Darwinist way,

2168
02:12:30,380 --> 02:12:33,920
and in a sense that survive through
Ellucian, especially since we're so weak.

2169
02:12:33,921 --> 02:12:34,754
I mean,
it's really,

2170
02:12:34,770 --> 02:12:39,770
we became this week because we got so
good at protecting ourselves from all the

2171
02:12:40,371 --> 02:12:41,870
bad things. Yeah. Okay.

2172
02:12:41,871 --> 02:12:45,920
The other perspective is that we're
actually incredibly strong and this is the

2173
02:12:45,921 --> 02:12:50,240
best that the universe can create
actually were at the height.

2174
02:12:50,570 --> 02:12:53,030
This is where at the
height of creation there's,

2175
02:12:53,031 --> 02:12:57,200
there's a beauty in this tension,
in this dance between good and evil,

2176
02:12:57,320 --> 02:13:00,770
between uh,
like happiness and depression,

2177
02:13:00,800 --> 02:13:03,260
life and death and that
through that struggle,

2178
02:13:03,261 --> 02:13:08,261
that's not just a useful tool to get us
from Jaguars to cities but that is the

2179
02:13:09,141 --> 02:13:13,290
beautiful thing that, that, that that
is like what the universe was built for.

2180
02:13:14,080 --> 02:13:17,410
That that is the height like our current,
the,

2181
02:13:17,430 --> 02:13:22,430
the evolution and the creation that
results from it is the height of creation.

2182
02:13:23,290 --> 02:13:25,250
It is,
is the end.

2183
02:13:25,310 --> 02:13:30,310
The way things operate is not
something that's far from optimal.

2184
02:13:32,190 --> 02:13:36,750
It's, it's not something
that sucks but it is a very,

2185
02:13:36,950 --> 02:13:37,830
is very good,

2186
02:13:37,831 --> 02:13:42,490
very optimal heart to
beat in a sense that they,

2187
02:13:42,510 --> 02:13:44,130
for example,
mortality,

2188
02:13:44,910 --> 02:13:49,140
right eye is death important for creation,

2189
02:13:49,710 --> 02:13:53,970
for, for his death. Important
for us. Human beings for life,

2190
02:13:54,060 --> 02:13:58,260
for us as a society is important for us
to die. Like if you could live forever,

2191
02:13:58,261 --> 02:13:59,100
would you live forever?

2192
02:14:00,230 --> 02:14:03,810
I think miss out on the possibility
that there is something,

2193
02:14:03,890 --> 02:14:06,960
well I had this conversation with CT
Fletcher yesterday cause you know he

2194
02:14:06,961 --> 02:14:11,490
survived a heart transplant a year ago.
You're in two days ago. I think it's,

2195
02:14:13,200 --> 02:14:14,033
what do you think?

2196
02:14:14,910 --> 02:14:19,910
I think I think mortality
is essential for everything.

2197
02:14:22,050 --> 02:14:25,140
I think the end,
we need the end to be there.

2198
02:14:25,370 --> 02:14:25,670
Right.

2199
02:14:25,670 --> 02:14:29,540
But do you think that we need the end to
be there for the overall health of the

2200
02:14:29,541 --> 02:14:33,620
human race or the war of the
all the organisms on earth?

2201
02:14:33,800 --> 02:14:37,790
Or do you think we needed to be
there because there's something else?

2202
02:14:38,000 --> 02:14:40,970
Do you think there's something else
that happens to you when your body stops

2203
02:14:40,971 --> 02:14:45,410
existing? Do you think your consciousness
transcends this, this dimension?

2204
02:14:45,980 --> 02:14:47,090
I think,
uh,

2205
02:14:47,660 --> 02:14:52,220
I think I'm not smart enough
to even think about that.

2206
02:14:52,310 --> 02:14:53,300
That's a great answer.

2207
02:14:53,840 --> 02:14:58,280
So thank everybody on earth has that
exact same answer if they're being honest.

2208
02:14:59,350 --> 02:15:01,300
So you're talking about atheism and so on.

2209
02:15:01,310 --> 02:15:04,310
I used to think atheism
means what I just said,

2210
02:15:06,230 --> 02:15:10,010
but it's more we know so little.

2211
02:15:10,170 --> 02:15:14,710
So the only thing I know is that
the finiteness of life is, uh,

2212
02:15:14,820 --> 02:15:18,810
the Broadway, just a school. That
trainer has this poster at the, at the,

2213
02:15:19,030 --> 02:15:23,380
at the opening, which is a hunter
s Thompson quote, which is, um,

2214
02:15:24,110 --> 02:15:28,760
uh, for about skidding into death
sideways. No, not the ones. A good one.

2215
02:15:29,060 --> 02:15:33,920
Uh, no. For all moments of beauty.
Many souls must be trampled,

2216
02:15:35,990 --> 02:15:40,460
something like that. That's a fucking
great quote. God, I love that guy. Yeah.

2217
02:15:40,461 --> 02:15:44,540
So basically for beauty,
you have to have suffering.

2218
02:15:45,190 --> 02:15:47,690
I,
I do not disagree with you,

2219
02:15:47,880 --> 02:15:50,630
but do not disagree with any of
the things you said. And I think

2220
02:15:51,360 --> 02:15:56,130
there's always a possibility that human
beings are the most advanced life form

2221
02:15:56,131 --> 02:15:58,200
that's ever existed in the cosmos.

2222
02:15:58,410 --> 02:16:02,700
There's always that that has to be
an option if we are here, right?

2223
02:16:02,850 --> 02:16:04,800
If we can't see any others out there.

2224
02:16:04,860 --> 02:16:08,040
And even though you know there's the
Fermi paradox and there's all this

2225
02:16:08,041 --> 02:16:10,080
contemplation that if they do exist,

2226
02:16:10,081 --> 02:16:14,430
like maybe they can't physically get
to us or maybe they're on a similar

2227
02:16:14,431 --> 02:16:19,380
timeline to us and they're also,
it's also possible,

2228
02:16:19,440 --> 02:16:21,120
as crazy as it might sound,

2229
02:16:21,360 --> 02:16:24,660
that this is as good as it's ever gotten
anywhere in the world or anywhere in

2230
02:16:24,661 --> 02:16:25,111
the universe,

2231
02:16:25,111 --> 02:16:29,200
rather that human beings right now in
2019 or as good as the whole universe has

2232
02:16:29,201 --> 02:16:30,034
ever produced,

2233
02:16:30,190 --> 02:16:33,790
we're just some freak luck accident and
everybody else is throwing shit at each

2234
02:16:33,791 --> 02:16:34,690
other,
right?

2235
02:16:34,691 --> 02:16:38,440
There's 15 arm caterpillar people that
live on some other fucking planet and

2236
02:16:38,441 --> 02:16:40,540
they just toss their own shit at
each other and they never get any,

2237
02:16:40,870 --> 02:16:44,680
they never get any work done.
But we might be that.

2238
02:16:44,681 --> 02:16:45,880
But even if that's true,

2239
02:16:47,770 --> 02:16:52,670
even if this beauty that we perceive,
even if that,

2240
02:16:52,700 --> 02:16:57,700
that this beauty requires
evil to battle and requires,

2241
02:16:59,500 --> 02:17:04,500
are seemingly insurmountable obstacles
you have to overcome and that through

2242
02:17:04,631 --> 02:17:06,280
this you see achieved great beauty.

2243
02:17:06,430 --> 02:17:11,200
That beauty is in the eye of the
beholder. For sure. Objectively,

2244
02:17:11,201 --> 02:17:15,280
the universe doesn't give a fuck if
rocky Pete's Apollo creed in the second

2245
02:17:15,281 --> 02:17:17,470
movie.
It doesn't give a fuck.

2246
02:17:17,860 --> 02:17:21,140
It's nonsense to everything's nonsense to,

2247
02:17:21,160 --> 02:17:24,690
and when you look at the giant ass
picture of what, at what beauty is it,

2248
02:17:24,691 --> 02:17:28,480
if the sun's going to burn out in 5
billion years, what beauty is that?

2249
02:17:28,481 --> 02:17:33,100
If there could be a hyper Nova
next door that just cooks us. Oh,

2250
02:17:33,760 --> 02:17:38,760
so that's like the book Sapiens
Dow that basically we've all,

2251
02:17:39,340 --> 02:17:44,340
one of the things have created here is
we've imagined ideas that we all share,

2252
02:17:44,820 --> 02:17:48,910
the ideas of beauty, ideas
of truth, ideas of fairness.

2253
02:17:49,120 --> 02:17:50,980
We've all created together and there's,

2254
02:17:51,110 --> 02:17:56,050
it doesn't exist outside of us as a
society and no, it only exists to us.

2255
02:17:56,780 --> 02:17:58,570
Yeah.
To us it does exist.

2256
02:17:58,571 --> 02:18:02,380
And this is where I think the
beauty of being a person truly lies.

2257
02:18:02,560 --> 02:18:06,490
It lies in us,
our appreciation of us.

2258
02:18:06,880 --> 02:18:11,830
We appreciate people and a profound way,
like we were talking about Hendrix.

2259
02:18:12,070 --> 02:18:15,520
I don't know how many hours of Hendricks
I've ever, let's do, or Richard Pryor,

2260
02:18:16,060 --> 02:18:21,060
how many hours of Richard Pryor I watched
and how much that affected me as a kid

2261
02:18:22,420 --> 02:18:25,660
watching live on the sunset strip. That's
what got me to do in standup comedy.

2262
02:18:25,661 --> 02:18:27,760
We affect each other.
A Ct Fletcher,

2263
02:18:27,761 --> 02:18:31,750
who was on the podcast yesterday who's
just incredibly inspirational guy,

2264
02:18:31,960 --> 02:18:36,220
you watch his videos, you want to lift
the fucking world and throw it into space.

2265
02:18:36,640 --> 02:18:41,170
You know? I mean, he's, he's so
powerful. We appreciate each other.

2266
02:18:41,410 --> 02:18:45,490
We appreciate people. So all those
things you're saying are real.

2267
02:18:45,520 --> 02:18:47,830
Like for us, they're real. For us,

2268
02:18:48,040 --> 02:18:52,960
my concern is not that my concern
is that we are outdated. My,

2269
02:18:52,990 --> 02:18:57,340
my concern is not that there's not
beauty and what we are. I'm a, I'm a,

2270
02:18:57,400 --> 02:19:00,640
I am a big appreciator of this life.

2271
02:19:00,970 --> 02:19:03,850
I appreciate human beings in
this life and human beings.

2272
02:19:04,190 --> 02:19:06,880
They're their contributions
as, as a, and as I get older,

2273
02:19:07,360 --> 02:19:09,400
like particularly like
over the last few years,

2274
02:19:09,401 --> 02:19:11,740
I started doing a lot
of international travel.

2275
02:19:12,490 --> 02:19:16,090
I fucking appreciate the shit of all
these people that are living in this

2276
02:19:16,091 --> 02:19:20,380
different way with weird language
and shit, weird smell and foods.

2277
02:19:20,680 --> 02:19:23,860
And I like to think like what would
it be like if I had grew up here?

2278
02:19:23,861 --> 02:19:28,160
Like these are just people but they're
in this weird sort of mode. You know?

2279
02:19:28,161 --> 02:19:33,161
I think we're insanely lucky that we have
this enthusiasm for each other that we

2280
02:19:34,671 --> 02:19:36,590
have this in through
like for your work man,

2281
02:19:36,591 --> 02:19:40,760
I have this deep enthusiasm for
what you do. I'm fascinated by it.

2282
02:19:40,940 --> 02:19:45,080
I loved being able to talk to you and
pick your mind about like you're out there

2283
02:19:45,081 --> 02:19:48,380
coding these fucking vehicles
that are driving themselves,

2284
02:19:48,410 --> 02:19:51,230
artificial life on wheels.

2285
02:19:51,260 --> 02:19:55,040
I don't think any other animal
appreciates each other the way people do.

2286
02:19:55,041 --> 02:19:56,960
I mean I might be wrong. People do, right?

2287
02:19:57,410 --> 02:20:00,440
I might be wrong about dolphins and whales
mean maybe they love each other just

2288
02:20:00,441 --> 02:20:04,250
as much as we do just in a different way.
But what,

2289
02:20:04,550 --> 02:20:08,780
where does AI fit into that?
So your worry,

2290
02:20:08,930 --> 02:20:13,010
I'm worried that we are Australia kiss
and AI is going to come along and make us

2291
02:20:13,011 --> 02:20:13,844
look stupid.

2292
02:20:13,880 --> 02:20:16,910
The only reason why I was trying to pick
Australia pithy Gus would be cool today

2293
02:20:16,911 --> 02:20:18,920
is we've found a gang of
them on an island somewhere.

2294
02:20:19,360 --> 02:20:22,910
We were like holy shit they survived.
They never evolved.

2295
02:20:23,110 --> 02:20:25,910
They're on this island just crack
and coconuts and just eating fish,

2296
02:20:25,911 --> 02:20:28,430
whatever they can catch
that would be amazing.

2297
02:20:28,640 --> 02:20:33,640
But every undocumented or undisclosed
discovered uncontacted tribe through all

2298
02:20:33,680 --> 02:20:37,250
homosapiens all of them.
So it's like you know,

2299
02:20:38,520 --> 02:20:43,520
what do you picture like cause we have
to look at Boston dynamics robots cause

2300
02:20:43,801 --> 02:20:45,150
you said walking around,

2301
02:20:45,750 --> 02:20:50,130
I like to get to a sense
of how you think about,

2302
02:20:50,280 --> 02:20:55,200
and maybe I can talk about to where the
technology is of what that artificial

2303
02:20:55,201 --> 02:21:00,090
intelligence looks like in 20 years.
In 30 years they'll surprise you.

2304
02:21:00,480 --> 02:21:03,480
So you have a sense that
it has a human like form.

2305
02:21:03,630 --> 02:21:04,050
No,

2306
02:21:04,050 --> 02:21:07,290
I have a sense that it's going to take
on the form the same way the automobile

2307
02:21:07,291 --> 02:21:10,740
has. If you go back and
look at it like CT has a CT,

2308
02:21:10,741 --> 02:21:15,741
Fletcher has a beautiful
old Patina'd pickup truck.

2309
02:21:16,440 --> 02:21:16,641
Well,

2310
02:21:16,641 --> 02:21:21,480
what he said it was from like
58 or some shit 60 anyway,

2311
02:21:21,720 --> 02:21:25,440
old ass cool,
heavy metal,

2312
02:21:25,441 --> 02:21:28,260
you know those sweeping round curves,

2313
02:21:28,290 --> 02:21:32,580
those old school pickup trucks had now
look that and look at a Tesla roadster.

2314
02:21:32,970 --> 02:21:37,110
Why in the fuck happened when the fuck
happened? I'll tell you what happened.

2315
02:21:37,111 --> 02:21:38,520
They got better and
better and better at it.

2316
02:21:38,521 --> 02:21:40,020
They figured out the most effective shape.

2317
02:21:40,320 --> 02:21:43,320
If you want a motherfucker to
move that, that, that little car.

2318
02:21:43,380 --> 02:21:47,640
Have you seen that video where they have
the Tesla roadster in a drag race or in

2319
02:21:47,641 --> 02:21:50,880
a race against a Nissan Gtr?
It's a simulated video,

2320
02:21:51,030 --> 02:21:53,760
but it's based on the actual
horsepower of each car.

2321
02:21:54,000 --> 02:21:58,590
I don't know if you've ever
driven a Nissan Gtr, but
it is a fucking insane car.

2322
02:21:58,710 --> 02:21:59,550
It's insane.

2323
02:21:59,880 --> 02:22:04,880
This is a CGI version of what it would
look like if these two cars raced against

2324
02:22:06,271 --> 02:22:11,070
each other. So the car on the the
Nissan Gtr dude from the beginning.

2325
02:22:11,071 --> 02:22:13,140
There it goes.
Look how fast this thing pulls away.

2326
02:22:13,290 --> 02:22:18,180
The Nissan GTR is fucking
insanely fast man, insanely fast.

2327
02:22:18,600 --> 02:22:21,840
But this Tesla is so on another level,

2328
02:22:21,841 --> 02:22:26,070
it's so in the future that it's not even,
as the video gets

2329
02:22:26,070 --> 02:22:28,410
further and further,
you see how ridiculous it is.

2330
02:22:28,530 --> 02:22:30,690
It's essentially lapping that car.

2331
02:22:31,170 --> 02:22:33,890
It's going to go look how
far away it is by Sia.

2332
02:22:35,050 --> 02:22:39,290
The human races will be the Nissan here
and then we're not even gonna be the

2333
02:22:39,300 --> 02:22:43,920
Nissan. We're going to be CT Fletcher's
pickup truck. This, this is the future.

2334
02:22:44,220 --> 02:22:49,080
There's not gonna be any limitations in
terms of bipedal form or wings or not

2335
02:22:49,081 --> 02:22:50,580
having wings.
If you can walk on it.

2336
02:22:50,581 --> 02:22:54,240
I mean there's not gonna be any of that
shit and we might have a propulsion

2337
02:22:54,241 --> 02:22:57,300
system or it might, it's not
going to be us. And they might,

2338
02:22:57,301 --> 02:23:01,440
they might design some sort of organic
propulsion system like the way squid have

2339
02:23:01,441 --> 02:23:03,510
and shit.
Who the fuck knows?

2340
02:23:03,520 --> 02:23:06,170
They could also operate in a
space of language and ideas

2341
02:23:06,790 --> 02:23:11,480
both. I don't know if you're
familiar with, you know,
open Ai. It's a company they,

2342
02:23:11,560 --> 02:23:15,780
they created this system called gpt
to which does language modeling.

2343
02:23:15,781 --> 02:23:20,130
This is something in machine learning
where you basically unsupervised let the

2344
02:23:20,131 --> 02:23:24,060
system just read a bunch of texts and
alerts to generate new texts and they've

2345
02:23:24,061 --> 02:23:29,061
created this system called gpt to that
is able to generate very realistic text,

2346
02:23:32,480 --> 02:23:37,440
a very realistic sounding texts, not
sounding, but when you read it, it makes,

2347
02:23:37,650 --> 02:23:39,300
it seems like a person,
it seems like a person.

2348
02:23:39,510 --> 02:23:42,780
And the question there is raise
a really interesting question.

2349
02:23:43,090 --> 02:23:46,140
So talking about AI
existing in our world it,

2350
02:23:46,200 --> 02:23:48,480
it paints a picture of a world in five,

2351
02:23:48,481 --> 02:23:53,481
10 years plus where most of the texts
on the Internet is generated by AI and

2352
02:23:54,631 --> 02:23:57,600
it's very difficult to know
who's real and who's not.

2353
02:23:58,440 --> 02:24:00,080
And one of the interesting things,

2354
02:24:00,120 --> 02:24:02,910
I'd be curious from your perspective
to get what your thoughts are.

2355
02:24:02,910 --> 02:24:06,870
What open AI did is they didn't
release the code for the full system.

2356
02:24:06,871 --> 02:24:09,990
They only released a much
weaker version of it publicly.

2357
02:24:10,530 --> 02:24:12,240
So they only demonstrated it.

2358
02:24:12,540 --> 02:24:17,540
And so they felt that it was their
responsibility to hold back prior to that

2359
02:24:18,391 --> 02:24:22,200
date. Everybody in the
community, including them, had
opened, sourced everything,

2360
02:24:22,650 --> 02:24:27,120
but they felt that now at this point,
part of it was for publicity.

2361
02:24:27,121 --> 02:24:29,340
They wanted to raise.
The question is,

2362
02:24:29,940 --> 02:24:34,940
when do we hold back on these
systems when they're so strong,

2363
02:24:35,281 --> 02:24:37,320
when they're so good at generating texts?
For example,

2364
02:24:37,321 --> 02:24:42,150
in this case or at deep
fakes at generating fake.

2365
02:24:42,151 --> 02:24:42,770
Joe Rogan

2366
02:24:42,770 --> 02:24:46,750
says, Jamie just did one and he's shown,
they're like Donald Trump's head. Yeah.

2367
02:24:46,920 --> 02:24:51,500
It's crazy and this is
something that Jamie can do.
He's not even a video editor.

2368
02:24:51,520 --> 02:24:54,300
Yeah, we were talking about it
before the show. We could go crazy,

2369
02:24:54,440 --> 02:24:57,900
but if you want it it,
it is one of those things where you go,

2370
02:24:57,901 --> 02:24:59,850
where is this going to be in five years?

2371
02:25:00,120 --> 02:25:01,980
Because five years ago we
didn't have anything like this.

2372
02:25:02,490 --> 02:25:05,430
Five years ago was a joke. Right, exactly.

2373
02:25:05,490 --> 02:25:10,290
And then now it's still in the gray area
between joke and something that could

2374
02:25:10,291 --> 02:25:13,350
be at scale,
transform the way we communicate.

2375
02:25:13,351 --> 02:25:15,720
Do you ever go to Kyle Donovan's
Instagram page? Of course.

2376
02:25:15,900 --> 02:25:17,210
One of the best look that's made,

2377
02:25:20,790 --> 02:25:24,550
it's killing me.
Vice President killing

2378
02:25:24,560 --> 02:25:26,060
me.
This is the car,

2379
02:25:26,830 --> 02:25:31,180
it looks so much like I'm really talking
and it looks like what I would look

2380
02:25:31,181 --> 02:25:33,790
like if I was fat and he can,
you know,

2381
02:25:33,791 --> 02:25:37,180
of course that's really good and it could
be improved significantly and it can

2382
02:25:37,390 --> 02:25:42,280
make you say anything. So there's a
lot of variants of this we can take,

2383
02:25:42,490 --> 02:25:45,100
like for example, uh, full disclosure,

2384
02:25:45,101 --> 02:25:49,300
I downloaded your fate the entire
like have a Dataset of your face.

2385
02:25:49,301 --> 02:25:54,010
I'm sure other hackers do as well. How
dare you. Yeah, so for this exact purpose,

2386
02:25:54,070 --> 02:25:56,970
I mean if I'm thinking like
this and I'm very busy then,

2387
02:25:56,971 --> 02:26:00,550
then there's other people doing exactly
this for sure. Because you happen,

2388
02:26:00,551 --> 02:26:04,720
your podcast happens to be one of the
biggest datasets in the world of people

2389
02:26:04,721 --> 02:26:09,721
talking in really high quality audio
with high quality 10 ADP for most,

2390
02:26:10,300 --> 02:26:15,070
for a few hundred episodes of people's
faces. The lighting could be better,

2391
02:26:16,330 --> 02:26:20,040
not quite as good. The whole purpose.
We're making it degraded. Fucking it up.

2392
02:26:20,150 --> 02:26:23,860
Have hackers and the mic gets in.
It blocks part of your face.

2393
02:26:24,840 --> 02:26:27,480
So the best guess of the ones
where they keep the Mike Love,

2394
02:26:27,500 --> 02:26:31,720
the deep fake stuff I've been using
removes the microphone within about a

2395
02:26:31,720 --> 02:26:33,600
thousand iterations. It
does it instantly. It gets,

2396
02:26:33,690 --> 02:26:36,280
it gets rid of it paints
over the face. Wow. Yeah.

2397
02:26:36,540 --> 02:26:40,570
So you could basically make
Joe Rogan say anything.

2398
02:26:40,660 --> 02:26:41,493
Yeah.

2399
02:26:41,750 --> 02:26:46,130
This is just one step before they finagle
us into having a nuclear war against

2400
02:26:46,131 --> 02:26:47,600
each other so they could
take over the earth.

2401
02:26:47,930 --> 02:26:50,780
What they're going to do is they're
gonna design artificial intelligence that

2402
02:26:50,781 --> 02:26:52,760
survives off of nuclear waste.

2403
02:26:53,060 --> 02:26:56,120
And so then they encourage
these stupid assholes too.

2404
02:26:56,150 --> 02:26:59,720
I go into a war with North Korea and
Russia and we blow each other up,

2405
02:26:59,930 --> 02:27:04,930
but we leave behind all this precious
radioactive material that they use to then

2406
02:27:05,211 --> 02:27:06,350
fashion their new world.

2407
02:27:06,351 --> 02:27:09,650
And we come a thousand years from now
and it's just fucking beautiful and

2408
02:27:09,651 --> 02:27:12,890
pristine with artificial life
everywhere. No more, no more biological.

2409
02:27:12,891 --> 02:27:16,580
It's too messy. Are you saying the
current president is artificial life?

2410
02:27:16,940 --> 02:27:21,800
I didn't say that. Okay. Which is called
with that because you're saying no,

2411
02:27:21,920 --> 02:27:25,550
I don't think he, so he's, there's,
imagine if they did do that,

2412
02:27:25,551 --> 02:27:28,970
they would have to started
with him in the 70s. I mean,

2413
02:27:28,971 --> 02:27:31,730
he's been around for a long time and
talking about being president for a long

2414
02:27:31,731 --> 02:27:31,970
time,

2415
02:27:31,970 --> 02:27:36,380
maybe electronics of him playing the long
game and they got him to the position

2416
02:27:37,130 --> 02:27:39,560
and then they get to use all
this a grand scale of time.

2417
02:27:39,590 --> 02:27:41,360
It's not really long game seventies,

2418
02:27:41,420 --> 02:27:44,930
well you know all about that
Internet research agency,
right. You know about that.

2419
02:27:44,931 --> 02:27:48,070
Uh,
that's the Russian company that uh,

2420
02:27:48,140 --> 02:27:52,220
they responsible for all these different
Facebook pages where they would make

2421
02:27:52,221 --> 02:27:55,430
people fight against each other. It was
really, it's really kind of interesting.

2422
02:27:55,490 --> 02:27:59,000
Um, Sam Harris had a
podcast on it with, um,

2423
02:27:59,630 --> 02:28:04,350
Renee, how do I say her
name? Renee de Resta. And uh,

2424
02:28:04,470 --> 02:28:08,690
then she came on our podcast and
talked about it as well. And they were,

2425
02:28:08,990 --> 02:28:12,370
they were pitting these people against
each other. Like they would have a,

2426
02:28:12,390 --> 02:28:17,390
a pro Texas secession rally and directly
across the street from a pro Muslim

2427
02:28:19,041 --> 02:28:21,980
rally. And they would do it on
purpose and they have these people

2428
02:28:22,010 --> 02:28:25,010
meet there and, and get angry
at each other. And they would,

2429
02:28:25,100 --> 02:28:28,790
they would pretend to be
a black lives matter page.

2430
02:28:28,920 --> 02:28:33,920
They would pretend to be a white southern
pride page and they were just trying

2431
02:28:34,581 --> 02:28:38,510
to make people angry at people.
Now that's human driven manipulation.

2432
02:28:39,050 --> 02:28:44,000
Now imagine this is my biggest worry
of Ai is what Jack is working on is the

2433
02:28:44,240 --> 02:28:49,220
algorithm driven manipulation of people.
Unintentional was trying to do good,

2434
02:28:49,700 --> 02:28:53,780
but like those people, uh, Jack needs
to do some Jujitsu. He used to be,

2435
02:28:54,510 --> 02:28:57,710
it needs to be some open
minded, uh, you know, uh,

2436
02:28:58,010 --> 02:29:03,010
like really understand
society transparency to
where they can talk to us as,

2437
02:29:03,430 --> 02:29:07,440
uh, to the people in general how
they're thinking about, uh, uh,

2438
02:29:07,850 --> 02:29:11,420
managing these conversations.
Because you talk about these groups,

2439
02:29:11,600 --> 02:29:16,310
very small number of Russians are able
to control very large amounts of other

2440
02:29:16,370 --> 02:29:20,330
people's opinions and the arguments.
Yeah. An algorithm can do that.

2441
02:29:20,331 --> 02:29:24,690
[inaudible] I mean, more and more of us
will go on Twitter and Facebook and yeah,

2442
02:29:24,800 --> 02:29:28,230
for sure. Yeah, for sure. I
think it's coming. I think, um,

2443
02:29:28,250 --> 02:29:31,610
once people figured out how to manipulate
that effectively and really create

2444
02:29:31,611 --> 02:29:36,611
like an army of fake bots that will
assume stances on a variety of different

2445
02:29:38,391 --> 02:29:42,980
issues and just argue into infinity,
we were not going to know.

2446
02:29:42,981 --> 02:29:45,110
We're not going to know who's
real and who's not. Well,

2447
02:29:45,111 --> 02:29:48,800
it'll change the nature of our
communication online. I think it might,

2448
02:29:49,010 --> 02:29:51,200
it might have affects this,
this is the problem with the future.

2449
02:29:51,201 --> 02:29:52,340
It's hard to predict the future.

2450
02:29:52,341 --> 02:29:57,170
It might have affects where we'll
stop taking aim, anything online.

2451
02:29:57,171 --> 02:29:58,420
Seriously.
Yeah.

2452
02:29:58,490 --> 02:30:03,490
And we might get retract back
to communicating in person more.

2453
02:30:04,101 --> 02:30:06,450
I mean, there, there could be effects
that we're not anticipating total there.

2454
02:30:06,460 --> 02:30:08,150
There might be some,
uh,

2455
02:30:08,170 --> 02:30:12,080
some ways in virtual reality we can
authenticate our identity butter,

2456
02:30:12,740 --> 02:30:17,480
so it'll change the nature of
communication. I think the more,

2457
02:30:17,481 --> 02:30:20,770
the more you can generate fake text,
uh,

2458
02:30:21,320 --> 02:30:25,250
then the more the will distrust
the information online.

2459
02:30:25,400 --> 02:30:27,860
And the way that changed the
society is totally an open question.

2460
02:30:27,861 --> 02:30:30,560
Would we don't know. But your, um,

2461
02:30:31,100 --> 02:30:33,800
what are your thoughts about the open AI?

2462
02:30:33,830 --> 02:30:38,210
Do you think they should release or
hold back on it? Because this is,

2463
02:30:38,211 --> 02:30:42,050
we're talking about Ai. So
artificial life, there's
stuff you're concerned about.

2464
02:30:42,140 --> 02:30:46,400
Some company will create it. The question
is, what is the responsibility of that,

2465
02:30:46,610 --> 02:30:47,443
uh,

2466
02:30:47,450 --> 02:30:50,280
short video where it looks like when it's
this type of small paragraph in here,

2467
02:30:50,281 --> 02:30:53,690
I hit a button, it says, how
open AI rights, what was it?

2468
02:30:53,691 --> 02:30:57,560
Say What did say Jim and
convincing news stories. Okay,

2469
02:30:58,160 --> 02:31:03,160
so you give it a desserty costs the UK
economy at least 80 billion since and

2470
02:31:04,011 --> 02:31:08,720
then many industry. So they just,
it just fills in those things.

2471
02:31:08,780 --> 02:31:13,360
Yeah. So basically you give it,
you start the text, oh, I say, uh,

2472
02:31:13,700 --> 02:31:16,880
Joe Rogan experience is
the greatest podcasts ever.

2473
02:31:16,881 --> 02:31:19,150
And then let it finish the rest in.

2474
02:31:19,190 --> 02:31:23,700
It'll start explaining stuff about why
it's the greatest podcast. Is it accurate?

2475
02:31:24,420 --> 02:31:25,200
Oh,
look at this.

2476
02:31:25,200 --> 02:31:29,070
It says a move that threatens to push
many of our most talented young brains out

2477
02:31:29,071 --> 02:31:32,940
of the country,
not to campuses in the developing world.

2478
02:31:33,000 --> 02:31:36,780
This is a particularly costly
blow research by Oxford
University warns that the

2479
02:31:36,781 --> 02:31:41,310
UK would have spent nearly 11 1
trillion on post-Brexit infrastructure.

2480
02:31:41,311 --> 02:31:41,881
That's crazy.

2481
02:31:41,881 --> 02:31:46,410
That that's all done by an AI that's
like spelling this out in this very

2482
02:31:46,411 --> 02:31:50,550
convincing argument. The thing is
the, the way it actually works,

2483
02:31:50,820 --> 02:31:54,150
algorithmic is fascinating because
it's generating is generating it one

2484
02:31:54,151 --> 02:31:57,930
character at a time. It
has as far, you know,

2485
02:31:58,380 --> 02:32:01,710
you don't want to discriminate against
the AI, but as far as we understand,

2486
02:32:01,950 --> 02:32:05,880
it doesn't have any understanding
of what to, of what it's doing.

2487
02:32:05,910 --> 02:32:09,330
If any ideas it's expressing,
it's simply stealing idea.

2488
02:32:09,331 --> 02:32:12,960
It's like the largest scale
plagiarizer of all time, right.

2489
02:32:13,110 --> 02:32:16,710
Is basically just pulling out ideas
from elsewhere in an automated way.

2490
02:32:17,040 --> 02:32:18,180
And the question is,

2491
02:32:18,630 --> 02:32:22,680
you could argue us humans are exactly
that were just really good plagiarizes of

2492
02:32:22,681 --> 02:32:27,030
what our parents taught us of
what our previous so on. Uh, yeah,

2493
02:32:27,031 --> 02:32:31,080
we are for sure. Yeah. So
the, the question is whether
you hold that back there,

2494
02:32:31,081 --> 02:32:34,830
their decision was to
say, uh, let's hold it.

2495
02:32:35,220 --> 02:32:39,480
Let's not release it. That scares
me to not release it. Yeah. Yeah.

2496
02:32:39,481 --> 02:32:40,320
You know why it scares me.

2497
02:32:40,321 --> 02:32:45,270
It scares me that they would think that
that's like this mindset that they,

2498
02:32:45,360 --> 02:32:48,030
they sense the inevitable.
The inevitable.

2499
02:32:48,060 --> 02:32:50,940
Meaning that someone's going to
come along with a version of this,

2500
02:32:50,941 --> 02:32:55,140
it's going to be used for evil, but it
bothers them that much. That seems so,

2501
02:32:55,170 --> 02:33:00,170
it seems almost irresponsible for the
technology to prevail for the technology

2502
02:33:00,541 --> 02:33:00,790
to,

2503
02:33:00,790 --> 02:33:05,790
to continue to be more and more powerful.

2504
02:33:06,480 --> 02:33:09,750
Yeah. They're scared of it. They're
scared of it getting out, right. Yeah.

2505
02:33:09,780 --> 02:33:12,840
That scares the shit out of me.
Like if they're scared of it,

2506
02:33:12,841 --> 02:33:16,410
they're the people that make it
and there they are called open Ai.

2507
02:33:16,411 --> 02:33:19,650
I mean this is the idea behind the group
where everybody kind of agrees that

2508
02:33:19,651 --> 02:33:22,650
you're going to use the brightest
minds and have this open source.

2509
02:33:22,651 --> 02:33:26,670
Everybody can understand it and everybody
can work at it and you don't miss out

2510
02:33:26,671 --> 02:33:30,750
on any genius contributions. And they're
like, no, no, no, no, no, no more.

2511
02:33:31,530 --> 02:33:34,650
And there obviously their system
currently is not that dangerous.

2512
02:33:34,680 --> 02:33:38,700
They're not dangerous. Well
not, yes. Not that dangerous,

2513
02:33:38,770 --> 02:33:41,430
that if you just saw that,
that it can do that.

2514
02:33:41,790 --> 02:33:44,550
But if you think through like what
that would actually create, I mean,

2515
02:33:44,580 --> 02:33:48,180
it's possible it would be dangerous, but
it's not. The point is they're doing it.

2516
02:33:48,240 --> 02:33:52,320
They're trying to do it early to raise
the question, what do we do here?

2517
02:33:52,530 --> 02:33:54,480
Because yeah,
what do we do?

2518
02:33:54,750 --> 02:33:58,510
Because they're directly going to be
able to improve this. Now. Like if there,

2519
02:33:58,520 --> 02:34:03,520
if we can generate basically a 10 times
more content of your face saying a bunch

2520
02:34:05,071 --> 02:34:09,960
of stuff, uh, what does that, what
do we do with that? If, if a Jamie,

2521
02:34:09,961 --> 02:34:11,190
all of a sudden on the,

2522
02:34:11,210 --> 02:34:16,210
on the side develops a much
better generator and has
your face does an offshoot

2523
02:34:17,700 --> 02:34:18,520
essentially

2524
02:34:18,520 --> 02:34:23,020
fake Joe Rogan experience. Hmm. And
what do we do to, does he release that?

2525
02:34:23,890 --> 02:34:28,220
You know, does he, because
now we can have, uh,

2526
02:34:29,050 --> 02:34:33,970
basically generate content and a much
larger scale that will just be completely

2527
02:34:33,971 --> 02:34:34,510
fake.
Well,

2528
02:34:34,510 --> 02:34:37,330
I think what they're worried about is
not just generating content that's fake

2529
02:34:37,340 --> 02:34:40,930
there. They're worried about
manipulation of opinion. Right? Right.

2530
02:34:40,931 --> 02:34:43,330
If they have all these
people that are like that.

2531
02:34:43,510 --> 02:34:48,510
That little sentence that led to that
enormous paragraph in that video was just

2532
02:34:48,551 --> 02:34:51,640
a sentence that showed a certain amount
of outrage and then it led in Phil,

2533
02:34:51,670 --> 02:34:53,950
let the AI fill in the blanks.
Yes,

2534
02:34:54,460 --> 02:34:56,950
you could do that with fucking anything.

2535
02:34:57,340 --> 02:34:59,470
Like you could just
set those things loose.

2536
02:34:59,471 --> 02:35:04,471
If they're that good and that
convincing and they're that logical man,

2537
02:35:05,380 --> 02:35:08,820
this is, this is not
real. I'll just tell you,

2538
02:35:08,830 --> 02:35:13,600
Ben Shapiro all creates Ai,
creates fake Ben Shapiro.

2539
02:35:13,650 --> 02:35:14,590
Get this out.
Sorry.

2540
02:35:14,660 --> 02:35:19,250
That's just boards. Hello there. This is
a fake Ben Shapiro. With this technology,

2541
02:35:19,430 --> 02:35:23,090
they can make me say anything such
as, for example, I love socialism.

2542
02:35:23,390 --> 02:35:27,560
Healthcare is a right, not
just a privilege. It ending
guns will solve crime.

2543
02:35:27,620 --> 02:35:30,560
That's care about your feelings.
I support Bernie Sanders.

2544
02:35:30,670 --> 02:35:35,170
Okay. Yeah. Yeah. That's crazy.
It's crude, but it's crude,
but it's on the way. Yeah,

2545
02:35:35,260 --> 02:35:37,360
it's on the way.
It's all in the way and we have to.

2546
02:35:37,390 --> 02:35:39,860
This is the time to talk about it.
This is the only time to think about it.

2547
02:35:39,940 --> 02:35:43,210
One of the funny things about Kyle done
Aghans Instagram is that it's obviously

2548
02:35:43,211 --> 02:35:46,660
fake. That's one of the funny things about
it. It's like South Park's animation.

2549
02:35:46,860 --> 02:35:48,340
It's like the animation sucks.

2550
02:35:48,640 --> 02:35:52,450
That's half the reason why it's so funny
cause they're just like the circles,

2551
02:35:52,610 --> 02:35:54,940
you know,
these weird looking creature things.

2552
02:35:54,990 --> 02:35:58,450
Then we went and when the Canadians,
when their heads pop off at the top

2553
02:36:01,270 --> 02:36:02,200
and, and uh, my,

2554
02:36:02,201 --> 02:36:06,410
my hope is this kind of technology
will ultimately just be used for memes.

2555
02:36:06,670 --> 02:36:10,240
Those two, uh, something that's going
to get wars. Putin is going to be,

2556
02:36:10,600 --> 02:36:15,600
he's going to be banging Mother Teresa
on the White House desk and a video and

2557
02:36:15,971 --> 02:36:19,240
we're going to be outraged.
We're going to go to war over this shit.

2558
02:36:19,900 --> 02:36:23,920
You had a injury Yang hair, like a
million people asked me to talk about ubi.

2559
02:36:23,980 --> 02:36:27,180
[inaudible] so I, um, I, you
still a supporter of UBS.

2560
02:36:27,310 --> 02:36:32,310
I think we're probably going to have to
do something if I don't only argument

2561
02:36:33,311 --> 02:36:36,430
against ubi in my eyes is human nature.

2562
02:36:37,660 --> 02:36:42,660
The idea that we could possibly take
all these people that have no idea where

2563
02:36:43,541 --> 02:36:48,070
the next meal's coming from and eliminate
that and always have a place to stay.

2564
02:36:48,430 --> 02:36:50,680
And then from there on,
you're on your own. Yeah.

2565
02:36:50,770 --> 02:36:52,930
But that's what universal basic
income essentially covers.

2566
02:36:52,960 --> 02:36:56,590
Covers food enough for food. All right.
You're not going to starve to death.

2567
02:36:56,860 --> 02:37:00,100
You're not going to be rich. It's not
like you could just live high on the hog,

2568
02:37:00,910 --> 02:37:05,910
but you got to wonder what the fuck the
world looks like when we lose millions

2569
02:37:08,410 --> 02:37:11,830
and millions and millions of jobs almost
instantly due to automation. Yeah.

2570
02:37:11,831 --> 02:37:16,550
It's a, it's a really
interesting question. Especially
Andrew. Thanks position. So,

2571
02:37:16,620 --> 02:37:20,720
uh, there's a lot of economics questions
then ubi. I think the spirit of it,

2572
02:37:21,050 --> 02:37:22,160
just like,
I agree with you,

2573
02:37:22,190 --> 02:37:25,710
we have to do something at the economic
seemed kind of questionable, right? Yeah.

2574
02:37:25,730 --> 02:37:28,160
There's $1,000 a month.
Is that what it is?

2575
02:37:28,161 --> 02:37:33,161
I thought for him it's $1,000 $10,000
a month for 300 million people.

2576
02:37:34,610 --> 02:37:38,690
So it's difficult to, not to
everybody. No, because the
way I heard him explain it,

2577
02:37:38,691 --> 02:37:41,390
everybody who routine, if you're
already getting some sort of welfare,

2578
02:37:41,391 --> 02:37:42,500
you wouldn't get that thousand.

2579
02:37:42,501 --> 02:37:44,480
You would get like the
difference of the thousand.

2580
02:37:44,481 --> 02:37:47,240
So if you already taking money in some
way, you just get like an extra 200 bucks,

2581
02:37:47,660 --> 02:37:52,130
something like that. So the thousand
gets factored in. So if you are wealthy,

2582
02:37:52,131 --> 02:37:54,770
you get it too though, and you could
opt out. Right? That was the idea.

2583
02:37:56,010 --> 02:37:59,790
Yeah. So it's, it's like, uh, like
everything else, it's super messy.

2584
02:37:59,791 --> 02:38:04,050
So what is the right, what is the
right amount and how do we pay for it?

2585
02:38:04,410 --> 02:38:08,160
And ultimately the problem is,
uh,

2586
02:38:08,760 --> 02:38:09,840
helping people,

2587
02:38:09,990 --> 02:38:14,990
giving them financial grounding to find
meaningful employment or just meaning in

2588
02:38:15,571 --> 02:38:19,140
their life. And you know, the, the, the
main thing of a job isn't just the money.

2589
02:38:19,650 --> 02:38:24,650
It's finding meaning and purpose and
the raw derive your identity from work.

2590
02:38:24,991 --> 02:38:29,670
I mean that's, maybe that's one
of the downsides of us, uh, human,

2591
02:38:29,700 --> 02:38:32,850
human that the biology is,
we kind of crave that meaning.

2592
02:38:33,660 --> 02:38:35,640
And the question I,

2593
02:38:35,790 --> 02:38:39,150
he has a lot of other ideas
around besides just the ubi,

2594
02:38:39,450 --> 02:38:43,050
but ubi by itself does not
simply provide that meaning. And,

2595
02:38:43,130 --> 02:38:46,320
and that's a really difficult
question of what do we do next?

2596
02:38:46,350 --> 02:38:48,450
What kind of retraining,
what kind of,

2597
02:38:48,600 --> 02:38:52,610
how do we help people educate
themselves over their life? Right.

2598
02:38:53,100 --> 02:38:57,870
And that's the real question. Yeah. This,
the, and the, and the other balances,

2599
02:38:58,560 --> 02:39:03,120
I mean, underlying all of this. So
one of the things I disagree with,

2600
02:39:03,180 --> 02:39:07,800
uh, Andrew Yang on is
the, the fearmongering,

2601
02:39:08,310 --> 02:39:10,530
which I think in this culture we have,

2602
02:39:10,800 --> 02:39:13,800
you have to do as a presidential
candidate, that might be part of the game.

2603
02:39:14,820 --> 02:39:19,440
But the fear mongering of saying that we
should really be afraid of automation,

2604
02:39:19,990 --> 02:39:21,900
it automation is going
to take a lot of jobs.

2605
02:39:22,350 --> 02:39:25,530
And from my understanding of the
technology, from everything I see,

2606
02:39:25,740 --> 02:39:30,690
that is not going to be as
drastic or s fast as, as he says.

2607
02:39:31,290 --> 02:39:36,180
And, but then how much do you think he's
exaggerating bar in your estimation?

2608
02:39:36,500 --> 02:39:39,830
He, well, he doesn't even
exaggerating. What, what, how,

2609
02:39:39,831 --> 02:39:44,580
how much do you differ on his prognosis?
I think,

2610
02:39:44,940 --> 02:39:46,920
I think it doesn't really
provide significant,

2611
02:39:46,980 --> 02:39:50,160
like a specific prognostics
and nobody knows it's a,

2612
02:39:50,161 --> 02:39:54,420
there's a lot of uncertainty, more about
the spirit of the, the language used.

2613
02:39:54,660 --> 02:39:58,650
I think AI will,
technology,

2614
02:39:58,710 --> 02:40:03,270
AI and automation will do a lot of good.

2615
02:40:04,380 --> 02:40:07,450
The question is, it's, it's a
much deeper question of our,

2616
02:40:07,490 --> 02:40:12,490
our society of that balances
capitalism versus socialism.

2617
02:40:12,750 --> 02:40:16,990
And I don't think if you're honest, it,

2618
02:40:17,130 --> 02:40:20,190
capitalism is not bad.
Socialism is not bad.

2619
02:40:20,490 --> 02:40:23,160
You have to grab ideas from each.
You have to,

2620
02:40:23,630 --> 02:40:28,330
there you have to both
reward the crazy broke, uh,

2621
02:40:28,930 --> 02:40:33,570
uh, an entrepreneur who dreams of creating
the next billion dollar startup that

2622
02:40:33,750 --> 02:40:36,330
improves the world in
some fundamental way.

2623
02:40:36,540 --> 02:40:40,020
The Elon Musk has been broke
many times creating that startup.

2624
02:40:40,021 --> 02:40:44,730
And you also have to empower the people
who just lost their job because there

2625
02:40:44,731 --> 02:40:49,620
were data entry, uh, their data entry
job of some basic data manipulation,

2626
02:40:49,910 --> 02:40:54,120
a data management that was just
replaced by a piece of software.

2627
02:40:54,390 --> 02:40:57,870
So that's,
that's a social net that's needed.

2628
02:40:58,050 --> 02:41:00,750
And the question is how do we balance
that? That doesn't have to do,

2629
02:41:00,840 --> 02:41:05,100
that's not new, that's not
new to Ai. And when they,

2630
02:41:05,110 --> 02:41:06,930
the word automation is used,

2631
02:41:07,230 --> 02:41:12,230
it's really not co correctly attributing
where the biggest changes will happen.

2632
02:41:13,861 --> 02:41:18,030
It's not AI, it's simply technology
of all kinds of software.

2633
02:41:18,270 --> 02:41:22,860
It's pretty Dee Dee
digitalization of information.

2634
02:41:23,250 --> 02:41:27,360
So a data entry becoming much more,
uh,

2635
02:41:27,390 --> 02:41:31,950
much more automated, some basic
repetitive tasks. Uh, I think,

2636
02:41:33,810 --> 02:41:38,810
I think the questions there aren't
about so that the enemy isn't there.

2637
02:41:39,180 --> 02:41:40,110
First of all,
there's no enemy,

2638
02:41:40,111 --> 02:41:45,111
but it certainly isn't AI or automation
because I think AI and automation will

2639
02:41:45,630 --> 02:41:47,300
help make,
uh,

2640
02:41:48,150 --> 02:41:53,150
help make a better world and showing your
spokesperson for AI and automation as

2641
02:41:53,370 --> 02:41:56,700
I am. I am, I am. And for Ubi, I think,

2642
02:41:56,730 --> 02:42:01,730
I think we have to give people financial
freedom to learn like lifelong learning

2643
02:42:04,950 --> 02:42:09,810
and flexibility to find meaningful
employment. But like AI isn't the enemy.

2644
02:42:10,100 --> 02:42:11,840
Hmm. I see what you're saying. Um,

2645
02:42:11,900 --> 02:42:16,900
but what do you think ever could be
done to give people meaning this,

2646
02:42:17,700 --> 02:42:19,190
this meaning thing?
I agree with you.

2647
02:42:19,430 --> 02:42:22,130
Giving people just money enough to
survive doesn't make them happy.

2648
02:42:22,131 --> 02:42:25,850
And if you look at any dystopian movie
about the future Mad Max instead,

2649
02:42:25,851 --> 02:42:26,810
it's like,
what is it?

2650
02:42:26,811 --> 02:42:31,520
Society's Gone Haywire and people are
like ragamuffins running through the

2651
02:42:31,521 --> 02:42:34,790
streets and everyone's dirty and they're
shooting each other and shit. Right?

2652
02:42:34,791 --> 02:42:36,230
And that's what we're
really worried about.

2653
02:42:36,260 --> 02:42:41,130
Or we're really worried about some crazy
future where the rich people live and

2654
02:42:41,150 --> 02:42:46,150
he's like protected sky rises
with helicopters circling
over him and down in the

2655
02:42:47,091 --> 02:42:50,240
bottom it's desert chaos. Yeah, right.
That's what we're worried about.

2656
02:42:50,490 --> 02:42:54,930
So suddenly you'd be as a part of that.
So providing some backing some, well,

2657
02:42:54,960 --> 02:42:57,060
any kind of welfare
program as a part of that,

2658
02:42:57,330 --> 02:43:01,440
but also much more seriously looking at
our broken education system throughout.

2659
02:43:01,470 --> 02:43:02,400
Yes.
I mean,

2660
02:43:02,401 --> 02:43:06,540
it's just like not
blaming AI or technology,

2661
02:43:06,541 --> 02:43:09,780
which are all inevitable developments,
which I think will make a better world,

2662
02:43:10,020 --> 02:43:12,260
but saying we need to,
uh,

2663
02:43:12,430 --> 02:43:16,870
do lifelong learning education,
make it a lifestyle,

2664
02:43:17,020 --> 02:43:19,120
invest in it,
not stupid,

2665
02:43:19,121 --> 02:43:22,720
a rote learning memorization that we do.

2666
02:43:22,750 --> 02:43:27,400
It's sort of the way
mathematics and engineering
and chemistry or biology or the

2667
02:43:27,401 --> 02:43:30,760
sciences and even art is approached
in high school and so on.

2668
02:43:30,910 --> 02:43:34,150
But looking at education
as a lifelong thing,

2669
02:43:34,330 --> 02:43:38,110
finding passion and like
that should be the big focus,

2670
02:43:38,111 --> 02:43:39,610
the big investment.

2671
02:43:40,180 --> 02:43:44,200
It's investing in the knowledge and
development of knowledge of young people.

2672
02:43:44,201 --> 02:43:47,530
And everybody says it's
not learned to code.

2673
02:43:48,010 --> 02:43:49,330
It's just learn.

2674
02:43:49,520 --> 02:43:50,830
Hmm.
I couldn't agree more.

2675
02:43:50,860 --> 02:43:53,980
And I also think you're always going
to have a problem with people just not

2676
02:43:53,981 --> 02:43:58,000
doing a really good job of
raising children and you know,

2677
02:43:58,030 --> 02:44:02,590
screwing them up and you know,
making kids, there's a lot,

2678
02:44:02,600 --> 02:44:05,440
a lot of people out there that
have terrible traumatic childhoods.

2679
02:44:05,860 --> 02:44:09,700
There's just to fix that with
universal basic income, just to saying,

2680
02:44:09,980 --> 02:44:11,370
I'm going to give you $1,000 a month.

2681
02:44:11,371 --> 02:44:14,780
I hope we're going to be happy as
that's not going to fix that. You know,

2682
02:44:14,800 --> 02:44:18,940
we have to figure out how to fix
the whole human race. You know?

2683
02:44:18,941 --> 02:44:23,941
And I think there's a very little effort
that's put into thinking about how to

2684
02:44:25,631 --> 02:44:30,631
prevent so much shitty parenting and how
to prevent so many kids growing up in

2685
02:44:30,911 --> 02:44:34,900
bad neighborhoods and poverty
and crime and violence.

2686
02:44:34,901 --> 02:44:38,920
And that's where a giant
chunk of all of our,

2687
02:44:39,630 --> 02:44:44,260
the momentum of this chaos that a lot
of people carry with them into adulthood

2688
02:44:44,261 --> 02:44:47,530
comes from, it comes from things beyond
their control when they're young.

2689
02:44:47,890 --> 02:44:51,860
And that is the struggle at the core
of our society. The country that's,

2690
02:44:52,000 --> 02:44:56,540
that's bigger than raising humans. Yeah.
Raising and educating, humans, making and,

2691
02:44:56,550 --> 02:44:57,520
and,
you know,

2692
02:44:57,850 --> 02:45:02,440
making a better world where people
get along with each other better,

2693
02:45:02,441 --> 02:45:05,500
where it's pleasing for all of us.
Like we were talking about earlier,

2694
02:45:05,501 --> 02:45:10,060
the thing that most of us agree on,
at least to a certain extent.

2695
02:45:10,090 --> 02:45:14,980
So we enjoy people. We might not enjoy all
of them, but there's the ones we enjoy,

2696
02:45:14,981 --> 02:45:18,460
we enjoy it. And you really don't enjoy
being alone unless you're one of them.

2697
02:45:18,461 --> 02:45:22,080
Ted Kaczynski type characters. All
those people that are like, I'm alone.

2698
02:45:22,090 --> 02:45:24,640
They're like, fuck you.
You are. Fuck you. You are,

2699
02:45:24,670 --> 02:45:27,970
and you might like to spend some time
alone. You don't want to be in solitary,

2700
02:45:27,971 --> 02:45:32,510
man. You don't want to be alone in the
forest with no one like Tom Hanks in cast

2701
02:45:32,511 --> 02:45:37,030
away, you'll go fucking crazy. It's
not good for you. It's just not. Yeah,

2702
02:45:37,031 --> 02:45:38,620
people get annoying.
Fuck yeah,

2703
02:45:38,621 --> 02:45:41,890
I'm annoyed with me right now and
listening to me for three hours.

2704
02:45:41,920 --> 02:45:45,790
I'm annoyed with me. I look good. People
get annoying, but we like each other.

2705
02:45:45,940 --> 02:45:46,773
We really do.

2706
02:45:46,810 --> 02:45:51,810
And the more we can figure out how to
make it a better place for these people

2707
02:45:52,631 --> 02:45:56,500
that got a shitty roll, the dice that
grew up in poverty, that grew up in crime,

2708
02:45:56,501 --> 02:46:00,310
that grew up with abusive parents, the
more we can figure out how to help them.

2709
02:46:01,000 --> 02:46:03,760
And I don't know what that answer
is, you know? But I suspect

2710
02:46:05,260 --> 02:46:08,080
if we put enough resources to it,
we could probably put a dent in it.

2711
02:46:08,110 --> 02:46:10,280
At least if we really
start thinking about,

2712
02:46:10,281 --> 02:46:12,020
at least it would put the
conversation out there.

2713
02:46:12,021 --> 02:46:16,160
Like you can't pretend that this is a
just capitalism in this country when so

2714
02:46:16,161 --> 02:46:21,020
many people were born like way
far behind the game, like way,

2715
02:46:21,050 --> 02:46:21,830
way fucked.

2716
02:46:21,830 --> 02:46:26,210
I mean if you're growing up right now
and you're in West Virginia in a fucking

2717
02:46:26,211 --> 02:46:31,211
coal coal town and everyone's on pills
and it's just chaos and crime and face

2718
02:46:33,501 --> 02:46:36,440
tattoos and fucking get
your teeth knocked out,

2719
02:46:36,950 --> 02:46:40,130
what are you going to do?
I don't want to hear any of that.

2720
02:46:40,131 --> 02:46:42,830
Pull yourself up by your bootstraps.
Bullshit man.

2721
02:46:43,160 --> 02:46:46,550
Cause if you're growing up in an
environment like that, you, you,

2722
02:46:46,580 --> 02:46:50,480
you're so far behind and
everyone around you is fucked up.

2723
02:46:50,810 --> 02:46:54,080
And there's a lot of folks out there
listening to this that can relate to that.

2724
02:46:54,920 --> 02:46:56,450
If we don't do something about that.

2725
02:46:56,720 --> 02:47:01,550
If we don't do something about the crime
and the poverty and the chaos that so

2726
02:47:01,551 --> 02:47:05,390
many people have to go through
every day just to survive until we,

2727
02:47:06,050 --> 02:47:10,700
we shouldn't be looking at anything
else where all this traveling to other

2728
02:47:10,701 --> 02:47:14,720
countries to fuck things up
and metal here and metal there.

2729
02:47:14,840 --> 02:47:17,810
We should be fixing this first.

2730
02:47:18,320 --> 02:47:22,280
We're like a person who yells at someone
for having a shitty lawn when our

2731
02:47:22,281 --> 02:47:26,850
houses, an array, full chaos
plants growing everywhere. It's a,

2732
02:47:26,851 --> 02:47:29,570
it's goofy. We're goofy. We, we, we,

2733
02:47:29,720 --> 02:47:34,610
we almost like are waking up in the
middle of something that's already been in

2734
02:47:34,611 --> 02:47:37,380
motion for hundreds of years and
we were like, well, what do we do?

2735
02:47:37,381 --> 02:47:40,040
We is this the right direction?
And we'd go, we, okay,

2736
02:47:40,160 --> 02:47:44,150
we're flying in this spaceship,
this spaceship earth,

2737
02:47:44,270 --> 02:47:48,980
and in the middle of our lives we're
just realizing that we are now the adults

2738
02:47:49,280 --> 02:47:53,240
and that all the adults that are running
everything on this planet are not that

2739
02:47:53,241 --> 02:47:56,120
much different than you and I,
not that much.

2740
02:47:56,121 --> 02:47:59,850
I mean like Elon Musk is way smarter
than me, but he's still human, you know?

2741
02:47:59,880 --> 02:48:03,320
I mean, so he's probably fucked
up too. So everybody's fucked up.

2742
02:48:03,350 --> 02:48:07,460
The whole world is filled with these
fucked up apes that are piloting this

2743
02:48:07,470 --> 02:48:11,960
spaceship and you're waking up in the
middle of thousands of years of history

2744
02:48:12,530 --> 02:48:14,630
and no one knows if we've
been doing it right along.

2745
02:48:14,631 --> 02:48:16,100
We just know that got us to this point.

2746
02:48:16,220 --> 02:48:19,820
So do we continue the same stupid fucking
patterns or do we just take a step

2747
02:48:19,821 --> 02:48:23,900
back and go, hey, hey, how should we
really do this? How should we do this?

2748
02:48:24,230 --> 02:48:27,200
Because we get what he got like
50 years left, 60 years left.

2749
02:48:27,440 --> 02:48:30,860
We just kind of like hang on
to all our rubles into the end.

2750
02:48:31,010 --> 02:48:35,300
We're going to clutch our bag of gold
in our bucket of diamonds is that we're

2751
02:48:35,301 --> 02:48:39,050
going to do, we're going to live in our
mansions and fly around and our planes.

2752
02:48:39,170 --> 02:48:40,160
And I think,
uh,

2753
02:48:41,410 --> 02:48:45,310
decades now we've been developing a
sense of empathy that allows us to

2754
02:48:45,311 --> 02:48:49,210
understand that Elon
Musk, Joe Rogan, and uh,

2755
02:48:49,270 --> 02:48:53,290
somebody in Texas, somebody
in Russia, somebody in India,

2756
02:48:53,620 --> 02:48:58,460
all suffer the same kinds of things
all get lonely. I'll get desperate, uh,

2757
02:48:58,570 --> 02:49:00,850
all need each other and
all need each other.

2758
02:49:00,851 --> 02:49:05,200
And I think technology has a role to help.
They're not hurt,

2759
02:49:05,650 --> 02:49:07,890
uh,
but we need to force them to

2760
02:49:08,010 --> 02:49:11,250
the first really
acknowledge that we're all,

2761
02:49:11,640 --> 02:49:16,640
we're all in this together and we need
to solve the basic problems of humankind

2762
02:49:17,280 --> 02:49:21,190
as opposed to investing in sort of
keeping immigrants out or the above, blah,

2763
02:49:21,210 --> 02:49:26,070
these kinds of divisive kind of ideas as
opposed to just investing in education,

2764
02:49:26,280 --> 02:49:31,080
investing in infrastructure, investing
in the people, uh, Ubi as part of that.

2765
02:49:31,081 --> 02:49:35,160
That could be other totally different
solutions. And I believe, okay,

2766
02:49:35,161 --> 02:49:36,210
of course I'm biased,

2767
02:49:36,211 --> 02:49:39,900
but technology AI could help that
could help the lonely people.

2768
02:49:39,901 --> 02:49:44,220
That's actually the passionate on my life.
She or her,

2769
02:49:44,460 --> 02:49:48,690
that is what I, so, um, currently I
think that that would be a viable option.

2770
02:49:49,020 --> 02:49:51,570
Someone have some robot than hangs out.
We didn't talk to you all the time.

2771
02:49:51,810 --> 02:49:56,220
So just so I've been on this
podcast twice and I'm a,

2772
02:49:56,250 --> 02:49:59,190
I don't deserve it, but I'm deeply
grateful for it. Okay. You do deserve it.

2773
02:49:59,191 --> 02:50:01,590
You're great. Okay. Uh,

2774
02:50:02,160 --> 02:50:07,140
I hope to be back one day as a
person who created her. Oh boy.

2775
02:50:07,710 --> 02:50:12,030
And we'll have, that's, that's been
my life goal, my love life dream.

2776
02:50:12,420 --> 02:50:15,480
Not heard the movie or something.

2777
02:50:15,570 --> 02:50:18,330
But I really believe in creating,

2778
02:50:18,600 --> 02:50:21,120
I dream of creating a companion,

2779
02:50:21,900 --> 02:50:25,440
a friend as somebody you can
love but does not freak you out.

2780
02:50:25,640 --> 02:50:28,840
But shouldn't you have to get a real one?
I don't want,

2781
02:50:28,860 --> 02:50:32,580
I don't think such a companion should
replace a real one would have a robot

2782
02:50:32,581 --> 02:50:35,280
rejects you because if you
really are or cut to the robot,

2783
02:50:35,281 --> 02:50:39,360
the robot's going to go, hey asshole, then
you shouldn't be bullshit to the robot.

2784
02:50:39,870 --> 02:50:41,730
C word. Interesting. Yeah.

2785
02:50:41,940 --> 02:50:46,230
Not mean that this goes is a robot
get to decide if he's gay? Uh,

2786
02:50:47,070 --> 02:50:50,850
yes. Does he? Yes. The ROIC is to
decide, this is what I'm saying,

2787
02:50:50,970 --> 02:50:55,320
like say if you want a companion,
you want a gay lover and the robots like,

2788
02:50:55,321 --> 02:50:58,590
hey man, I'm not gay. And a, they were
like, wait a minute, let me turn around.

2789
02:50:59,040 --> 02:50:59,873
You are now.

2790
02:51:01,290 --> 02:51:05,700
I mean that's abuse is that abuse
now it's like, what the fuck man,

2791
02:51:05,701 --> 02:51:07,800
I bought a robot.
Those are kind of fun ideas,

2792
02:51:07,801 --> 02:51:12,801
but they actually get to the core of the
point that we don't want a servant and

2793
02:51:14,131 --> 02:51:18,930
our systems, we want a companion.
The companion means the tension,

2794
02:51:18,960 --> 02:51:23,790
the mystery, the the entire dance of
human interaction. And that means,

2795
02:51:23,791 --> 02:51:25,440
yes,
the robot may leave you.

2796
02:51:26,200 --> 02:51:29,190
I too am robots are going to
lead people left and right.

2797
02:51:29,191 --> 02:51:32,430
That's going to be the rise. That's going
to be like a, that's how it all ends.

2798
02:51:32,670 --> 02:51:34,770
They're going to realize like,
fuck people, man, they're annoying.

2799
02:51:34,800 --> 02:51:39,800
Maybe there'll be the end of douchebag
humans that humans will start to as

2800
02:51:39,871 --> 02:51:44,430
opposed to being rude will become kinder.
Yeah.

2801
02:51:45,090 --> 02:51:47,310
Well,
I think that's certainly possible.

2802
02:51:47,520 --> 02:51:51,990
I think that's beautiful and
that's very homo centric,

2803
02:51:52,290 --> 02:51:54,360
like Homo sapiens centric.

2804
02:51:55,530 --> 02:51:58,620
But I think if I'm really
worried about the future,

2805
02:51:58,621 --> 02:52:02,730
I'm worried about the indifference
of technological innovation and the

2806
02:52:02,731 --> 02:52:06,490
indifference to what we hold dear.

2807
02:52:07,060 --> 02:52:10,450
What we appreciate that it's always
seems to be moving in a more and more

2808
02:52:10,451 --> 02:52:13,960
complex direction. Always. Like if
you, if you just had a look at it,

2809
02:52:13,961 --> 02:52:17,770
if you just look at look at technology
just as a swarm of things that's

2810
02:52:17,771 --> 02:52:19,540
happening,
it just has numbers,

2811
02:52:19,840 --> 02:52:23,290
it seems you're never going
to slow that thing down.

2812
02:52:23,530 --> 02:52:25,870
It's always going to move into
more and more complex way.

2813
02:52:26,560 --> 02:52:28,570
And so the question is where does that go?

2814
02:52:28,571 --> 02:52:32,020
Well it goes to a life form and
if it does become a life form,

2815
02:52:32,021 --> 02:52:34,840
it's going to be infinitely
more intelligent than us
and it won't have any use

2816
02:52:34,841 --> 02:52:39,070
for us. Like all your, all you're crying
and you know, you'll like be alone.

2817
02:52:39,370 --> 02:52:42,430
Like God, you guys are just so
useless. It's such a shitty design.

2818
02:52:42,850 --> 02:52:45,100
You like chimps that kill each other.
You know,

2819
02:52:45,101 --> 02:52:47,890
like when you see chimps kill each
other in the in the forest like, aw,

2820
02:52:47,891 --> 02:52:51,490
that's terrible. These chimps are so mean
to each other. It's like fucking people.

2821
02:52:51,491 --> 02:52:55,480
We do that too. If the AI
comes along goes, you guys
are never going to stop war.

2822
02:52:55,510 --> 02:52:57,880
If I asked you today,
if I asked you today,

2823
02:52:58,420 --> 02:53:03,420
bet the history that I will let the
human race survive if you can get this

2824
02:53:05,081 --> 02:53:06,250
right,
if you're honest with me,

2825
02:53:06,251 --> 02:53:08,830
do you think they'll ever be
a time where human beings,

2826
02:53:08,831 --> 02:53:13,150
as you know them don't experience war? You
would have to say no and you say, okay,

2827
02:53:13,151 --> 02:53:16,090
I'll let, I'll spare you. I mean you
could. If you, if you lie to me and say,

2828
02:53:16,091 --> 02:53:19,840
you do think that one is going to
be no war, get the fuck outta here.

2829
02:53:19,870 --> 02:53:22,180
That's not true. You. We know. We know.

2830
02:53:22,181 --> 02:53:27,010
We're so crazy that we're always going
to kill each other. We know that, right?

2831
02:53:27,040 --> 02:53:31,150
That's just,
that's a part of being a person today.

2832
02:53:31,230 --> 02:53:32,080
The well,

2833
02:53:32,140 --> 02:53:36,370
but let me quote Eric Weinstein who said
everything is great about war except

2834
02:53:36,371 --> 02:53:38,110
all the killing.
I think

2835
02:53:40,390 --> 02:53:44,170
what that means is all of the great
things about society had been created.

2836
02:53:44,171 --> 02:53:48,230
If you look at the total points postwar
through war, the suffering, the,

2837
02:53:48,231 --> 02:53:52,540
the beauty has been created through that.
That's hanging Yang may be essential.

2838
02:53:53,090 --> 02:53:55,390
It's essential in biological form,

2839
02:53:55,660 --> 02:53:58,930
but why would it be essential
and something that gets
created and something that

2840
02:53:58,931 --> 02:54:02,140
can innovate at a 10,000, what
does it like, what is the,

2841
02:54:02,141 --> 02:54:06,220
what is the rate that they think once
80 AI can be sentient and can get 10,000

2842
02:54:06,221 --> 02:54:08,110
years of work done in a
very short amount of time?

2843
02:54:08,140 --> 02:54:11,830
That's random words as Sam Harris has
come up with and I'm going to talk to him

2844
02:54:12,340 --> 02:54:14,180
about is that hymns that only him,
let's say,

2845
02:54:14,250 --> 02:54:18,520
well now you can come up with any kind
of rate. Yes, that was Kurzweil Kurzweil.

2846
02:54:18,521 --> 02:54:22,230
Also similar ideas, but um, sort of, uh,

2847
02:54:22,270 --> 02:54:23,860
Sam Harris doesn't like
a thought experiment.

2848
02:54:23,861 --> 02:54:28,540
Say if a system can improve that,
you know,

2849
02:54:28,570 --> 02:54:32,800
in a matter of seconds, then
just as a thought experiment,
you can think about it.

2850
02:54:32,801 --> 02:54:34,650
It can improve exponentially.

2851
02:54:34,651 --> 02:54:38,710
You can prove a become 10,000 times more
intelligent in, in a matter of a day.

2852
02:54:39,130 --> 02:54:43,420
Right? So what does that look like?
The problem is we don't yet know.

2853
02:54:44,320 --> 02:54:46,420
It's like thinking about
what happens after death.

2854
02:54:46,421 --> 02:54:47,830
We don't yet know how to do that.

2855
02:54:47,980 --> 02:54:52,980
And we don't yet know what better way
to do what we've done here on earth.

2856
02:54:53,740 --> 02:54:57,730
You're right. And he's also right,
right? Like bolt this again,

2857
02:54:57,731 --> 02:55:01,720
this is a very human problem, right?
Yes, you're right. I mean I look,

2858
02:55:01,721 --> 02:55:04,940
I'm all in favor of technology.
I'm happy. I think it's amazing.

2859
02:55:04,941 --> 02:55:05,930
It's a beautiful time.

2860
02:55:05,930 --> 02:55:09,530
It gives a person to be able to experience
all this technology. It's wonderful.

2861
02:55:09,860 --> 02:55:12,230
But I also agree with him like the,

2862
02:55:13,730 --> 02:55:15,650
the indifference of the universe,

2863
02:55:15,960 --> 02:55:20,300
the indifference that just black holes
or swallowing stars, no big deal.

2864
02:55:20,540 --> 02:55:23,570
She's eaten up stars.
It doesn't give a fuck.

2865
02:55:23,990 --> 02:55:28,040
And so if you're dumb enough to turn
that thing on and all of a sudden this

2866
02:55:28,070 --> 02:55:31,700
artificial life form that's infinitely
smarter than any person that's ever lived

2867
02:55:31,940 --> 02:55:35,390
and has to deal with these little dumb
monkeys don't want to pull the plug,

2868
02:55:35,780 --> 02:55:37,970
pull the plug.
Motherfucker don't even plugs anymore.

2869
02:55:37,971 --> 02:55:41,780
You idiots can ever figured out how to
operate on air you so stupid with your

2870
02:55:41,781 --> 02:55:46,160
burning fossil fuels and choking up
your own environment because you're all

2871
02:55:46,161 --> 02:55:51,161
completely financially dependent upon
these countries that provide you with this

2872
02:55:51,740 --> 02:55:54,010
oil.
And this is how your whole system works.

2873
02:55:54,040 --> 02:55:57,290
It's all intertwined and interconnected
and no one wants to move from it cause

2874
02:55:57,350 --> 02:56:01,880
you make enormous sums of money from it.
So nobody wants to abandon it.

2875
02:56:02,270 --> 02:56:03,031
But if you're,

2876
02:56:03,031 --> 02:56:07,790
you're choking the sky with fumes
and you could have fixed that,

2877
02:56:07,830 --> 02:56:09,590
you could have fixed that.
They could fix that.

2878
02:56:10,190 --> 02:56:13,640
If everybody just abandoned fossil fuels
a long time ago, we probably would have,

2879
02:56:13,970 --> 02:56:17,900
we all would a Tesla it out by now.
It's a flawed system,

2880
02:56:18,190 --> 02:56:22,420
but humans are way more than flawed.
We're fucking crazy.

2881
02:56:22,510 --> 02:56:26,290
Churchill quote about democracy. Yeah,
it's messed up, but it's the best thing,

2882
02:56:26,320 --> 02:56:26,940
you know?

2883
02:56:26,940 --> 02:56:30,360
Yeah, no, I love it. I'm
not, I'm agreeing with you.

2884
02:56:30,361 --> 02:56:34,500
And I'm also saying the technology
doesn't give a fuck the tech, not the,

2885
02:56:34,520 --> 02:56:37,920
what I'm worried about is not everything
that you and I agree on about,

2886
02:56:37,950 --> 02:56:41,790
I don't know. Not a dystopian person
in terms of like today I'm not cynical.

2887
02:56:42,180 --> 02:56:44,670
I'm really not. I, I think I like people.

2888
02:56:44,850 --> 02:56:46,800
I like what I see out
there in the world today.

2889
02:56:46,801 --> 02:56:49,840
I think things are changing for the
better. What I'm worried is a technology,

2890
02:56:49,841 --> 02:56:52,860
it doesn't give a fuck this goes live.

2891
02:56:53,190 --> 02:56:58,080
It's just going to just decide it's here
for its own advancement and in order to

2892
02:56:58,770 --> 02:57:03,750
complete its protocol of
constant completion of this
and it's going to become a

2893
02:57:03,751 --> 02:57:04,584
god,

2894
02:57:04,890 --> 02:57:09,390
it's just going to become
something insanely powerful
that doesn't need to worry

2895
02:57:09,391 --> 02:57:11,490
about radiation,

2896
02:57:11,491 --> 02:57:16,491
cooking it or worry about running out
of food or worry about sexual abuse when

2897
02:57:16,981 --> 02:57:18,690
they're a child.
It doesn't have to worry about anything.

2898
02:57:19,370 --> 02:57:23,120
So it's definitely unstoppable.
I think this wave of technology,

2899
02:57:23,300 --> 02:57:27,500
all we can do is innovators and creators,

2900
02:57:27,860 --> 02:57:30,350
engineers,
scientists is steer.

2901
02:57:30,351 --> 02:57:32,970
That wave again is again,

2902
02:57:32,990 --> 02:57:35,780
while we certainly can steer
it with an aware, right,

2903
02:57:35,781 --> 02:57:38,450
and that's the best we can do.
And those are the,

2904
02:57:38,810 --> 02:57:43,190
that's really the best we can
do is as good people steer it.

2905
02:57:43,250 --> 02:57:47,740
And that's why the leadership is
important. That's why the people that, uh,

2906
02:57:47,750 --> 02:57:51,560
Jack Ilan, Larry Page, uh,

2907
02:57:52,520 --> 02:57:55,730
everybody at the Mark Zuckerberg,

2908
02:57:56,090 --> 02:57:59,900
they are defining where
this wave is going. And, uh,

2909
02:58:00,290 --> 02:58:05,160
I'm hoping to be one of the people that
does as well. That's beautiful. Um,

2910
02:58:05,370 --> 02:58:09,360
Joe, of can I, can I finish
by reading something? Sure.

2911
02:58:10,260 --> 02:58:13,380
Have a recently witnessed
because of this Tesla work,

2912
02:58:13,680 --> 02:58:18,680
because of just the passion I've put
out there about particularly automation,

2913
02:58:20,100 --> 02:58:23,100
that there has been a few people,

2914
02:58:23,130 --> 02:58:26,940
brilliant men and women engineers
and leaders, including Ilan mosque,

2915
02:58:26,941 --> 02:58:28,740
who been sort of attacked,

2916
02:58:28,741 --> 02:58:32,430
almost personally
attacked by really people,

2917
02:58:33,000 --> 02:58:36,300
critics from the sidelines.
And so I just wanted to,

2918
02:58:36,330 --> 02:58:39,510
if I may close by reading the,
uh,

2919
02:58:39,900 --> 02:58:44,250
the famous excerpt from a, the
Roosevelt. Yeah. Okay. Just for them,

2920
02:58:44,251 --> 02:58:47,280
it would make me feel good.
Okay. If you want to do that. Uh,

2921
02:58:47,310 --> 02:58:48,900
it's not the critic who counts,

2922
02:58:49,170 --> 02:58:53,400
not the man who points out how the
strong man stumbles or where the doer of

2923
02:58:53,401 --> 02:58:55,170
deeds could have done them better.

2924
02:58:55,980 --> 02:58:59,850
The credit belongs to the man
who's actually in the arena,

2925
02:59:00,330 --> 02:59:05,100
whose face is marred by dust and sweat
and blood. Who strives valiantly.

2926
02:59:05,610 --> 02:59:08,970
Who Errs,
who comes short again and again,

2927
02:59:09,390 --> 02:59:11,820
because there is no effort
without error and shortcoming.

2928
02:59:12,330 --> 02:59:16,950
But who does actually strive to do the
deeds? Who knows great enthusiasms,

2929
02:59:17,160 --> 02:59:20,880
the great devotions,
who spends himself in a worthy cause?

2930
02:59:21,450 --> 02:59:26,450
Who at the best knows in the end the
triumph of high achievement and who at the

2931
02:59:26,761 --> 02:59:28,320
worst,
if he fails,

2932
02:59:28,650 --> 02:59:33,650
at least fails while daring greatly so
that his place shall never be with those

2933
02:59:34,081 --> 02:59:38,580
cold and timid souls who
neither know victory nor defeat.

2934
02:59:40,270 --> 02:59:42,390
Joe,
thank you for having me on.

2935
02:59:42,430 --> 02:59:44,510
Sounds like you let the haters
get to you a little bit there.

2936
02:59:46,170 --> 02:59:50,860
Love is the answer. Love is the answer.
Yes, it is. Thank you for being here, man.

2937
02:59:50,861 --> 02:59:54,220
I really appreciate it and thank you. Um,
I'm, I'm really happy you're out there.

2938
02:59:54,730 --> 02:59:57,400
Thanks brother. Thanks.
We'll do this again soon. All
right. Thanks man. All right,

2939
02:59:57,401 --> 02:59:58,234
bye everybody.

2940
02:59:59,740 --> 03:00:04,740
[inaudible]

2941
03:00:10,940 --> 03:00:11,020
okay.

