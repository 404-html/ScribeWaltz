Speaker 1:          00:00:02       The infamous Jamie double finger gun and we're live. How are you sir? Good. Seeing that it's coming back. Looking healthy. Looking fresh. When I stopped eating meat since I last saw I heard about that. I want to talk to you about that. And uh, I don't know that

Speaker 2:          00:00:18       correlating with health. I, every time I worry about this out loud, I get hate mail from vegans and vegetarians. You say stop,

Speaker 1:          00:00:25       you start putting your bullshit on us. Well you, they, they don't like when you associate any negative consequences whatsoever with only in vegetables because it's because it's essentially a cult. It's a wonderful cult of people that want to take care of animals, be nice to animals, but they're very tribal, very tribal, very cult like. And if you say anything that's negative against Vegans, they gang up. I go to forums and I read the things they say they organize like little troll attacks and they make youtube videos. It's kind of hilarious, like from a psychological standpoint.

Speaker 2:          00:00:58       Yeah. I mean, you know, obviously I don't want it to become a new religion or my, my one religion, but there is a moral high ground to the position that I find very attractive because I felt like a hypocrite as a mediator now. Um, and I don't think there's necessarily extends to someone like you who hunts and feels okay about hunting. Um, and I don't have an argument against hunting the way I do against factory farming or, or more, more or less any of the way we get meat. Um, you know, the, the environmental implications of it, but it's um, so it is very captivating as a position and you feel like an ass and when, once you, once you go far enough into the inquiry, you feel like an asshole not being sensitive to these concerns and just, I'm ignoring how you're getting your food three times a day. But, um, I'm not yet for me. I maybe, I'm sure there's individual variation and I'm not the smartest vegetarian in the world in terms of how I prepare my food and how attentive I am to it. So the onus is somewhat on me, but I, I'm, uh, I'm not totally sure it's uh, the healthiest thing for me so I, you know, so you say this started, you said you look healthy. Mbi, I feel like my health is somewhat with reign under this has been about nine months.

Speaker 1:          00:02:18       Weathering, um, are you getting your blood checked? Are You doing year 12 supplementation? Yeah, that's essential oils. Essential [inaudible] is essential as well. Most people are just not going to get enough from the sun. And are you monitoring your intake of fatty acids and things along those lines? Not really beyond the supplementation. I'm, I'm just, uh, trying to get the food in. Yeah. Well it's good. It's all good stuff, but it's really important, like one of the things that people rage against, unfortunately, it's the stigma and it's fats, it's dietary cholesterol, dietary cholesterol and saturated fats which are critical for hormone. And it's one

Speaker 3:          00:03:00       of the reasons why people when they get an all vegetable diet, if you're not really careful with coconut oil, you got to eat a lot of coconut oil. I'm a big fan of Avocados. I eat a lot of Avocados, a lot of avocado oil, coconut oil as well though. Almond butter, nuts, things on those lines like you, you really need to get those essential fats. Well actually I'm not Vegan so I would like to be Vegan, but. But I'm still eating dairy. And did you say you would like to be? No one's holding you. No one's holding you down to Goddammit Sam, you need to have some milk? No, no. I think just. I think I would screw it up again. I'm going to reap the whirlwind when from the Vegans, but I should've brought you some eggs, but I eat eggs. I eat eggs and a, but as you know, you can only eat so many eggs and, and so much dairy, but I eat a lot of eggs.

Speaker 3:          00:03:44       The eggs are very good for you too. Here's the, there's another thing, dietary cholesterol, like people are always concerned with dietary cholesterol. Well, that was a big myth for the longest time. As a matter of fact, dietary cholesterol barely moves the needle and blood lipids, a lot of them people have cholesterol issues. It's sedentary lifestyle. There's genetics, there's all sorts of other variables, but people with healthy lifestyles, it doesn't seem to be that dietary cholesterol is bad for you. And also it's essential for testosterone production. Yeah. Yeah. So I get a ton of, or not a ton, but I'm not trying to avoid saturated fat. So I, um, I get a fair amount of. You have a yard? Uh, yeah. Could you raise some chickens? No, no, not after this. I'll take you to my house. So I'll show you the chicken setup we have. We just got five new ones.

Speaker 3:          00:04:39       We have an 18 now. One of them died. They just fucking die sometimes. You don't know why. Just go in the chicken coop. One's dead father time got in there with his side and they're getting kind of old now. Some of them, I don't know how old the chicken lasts honestly, but they're like pets. They give you food, like there's no negativity. I opened the door, they come up to me, the run around. I feed feel like there's no, they're not trapped. As a matter of fact, they go into their pen at night, like you leave it open and they wander around my. I have a big yard. They wander in my yard, they eat a bunch of bugs and stuff and then they go back inside when they want to. So there's no like animal captivities, no cruelty. There's nothing weird going on. And so those eggs, they're pretty much Karma free.

Speaker 3:          00:05:24       Oh yeah, yeah. No, I don't doubt that. It's just when you read the details of how our dairy and I mean it's near arguably as bad if not worse than much of the meat production. So you know, moving from eating, eating me to being a vegetarian in some ways is a symbolic move ethically if you, if you really wanted to, to not participate in the machinery, but there's an issue with me that's for vegetarianism. There is an issue with the how they gather food. I mean there's, there's a giant issue that people don't want to take into consideration is like how are they growing all this food? How they growing all these plants. Well, one of the things they're doing is they're displacing wildlife that chewing up this ground in these combines, if you eat grain and particular combines indiscriminately, just chew up all that stuff and they get deer, Fonz, mice, rabbits, rats, rodents, untold amount of bugs if you want to get really deep. I mean there's no like being a Vegan and being a vegetarian is most certainly less cruel and less harmful overall, but it's not Karma free. It can't, unless you're growing your own stuff. If you can grow all your own vegetables and you essentially live on a small farm, yeah, you could. You could do it and really feel good, but it's. If you're buying it in the store, you're participating in factory farming. Whether you like it or not, you're just participating it vegetable farming, but it's. There's still issues.

Speaker 2:          00:06:54       Oh yeah, yeah, yeah. Just, just viewer. I had this guy on my podcast boom. Have a lady who's running this company called Memphis meats, which is cultured meat is a startup in silicon. Oh, okay. Um, and then try that. I haven't tried it. No, I want to try it, but it was a fascinating conversation because he basically, what's, what's fascinating to me on two levels is one is just, it's fascinating that we're on the cusp of being able to produce actual biologically identical meat. That is, that is totally cruelty. I mean, it's, it's, there's no, there's no implication of cruelty at all in it. Right. And you would just grow, grow this in a Vat, the way you brew beer essentially. And uh, so that's, you know, that seems like the future. But what's interesting psychologically is that people have this, this creepy feeling around it, which is very strange because it, so you, I'm telling you, I can take the misery and death out of the process, right?

Speaker 2:          00:07:56       I can take the suffering animal out of it. I can take the chaos of the slaughterhouse out of it. There's no, you know, a cow that has been mistreated for its whole life, stumbling in blood and feces on the way to the, you know, the killing floor. Um, and somehow removing all of that makes it creepy or people, right? They want, they want, they want that. I mean, that's the natural way to get me, and if I told you this is grown in a vat by a guy in a white lab coat and has no xeno viruses and no bacteria, nothing, you know, antibiotics were used to pump this thing up and it's just the cells you want people start to just kind of an eerie feeling that, that, that I think we're going to get over. But it's interesting psychologically that it's there in the first place.

Speaker 2:          00:08:41       Did you get that feeling or you just know the people know? I hope they understand it. I mean, I'm, I'm past it, but I understand it. Who Do you know that got it, that just, I just see the reaction that, you know, when I actually pulled this on twitter, I'm at 20 percent of pay, like 15,000 people answered the poll. So it was like, it was a, it's not a scientifically valid poll of the general population. It's just whoever got it on my, on my feet. But um, it was interesting to see. I, I, I asked, you know, of the people who wouldn't switch, I asked would you switch? And something like 80 percent said they would switch if this was affordable and available and safe. Um, but of the people who wouldn't switch, it was 25 percent wouldn't switch because it's just creepy and 25 percent assume that it was um, a not healthy.

Speaker 2:          00:09:30       I think I forgot the, the for the breakdown. Um, another 25 percent was we're already vegan or vegetarian and didn't want to eat meat, but there was an ick factor for at least 25 percent of the people who wouldn't do it. I understand it. I wonder how many people would go back to eating meat if they could raise it this way. Like how many people who had gone vegan would go back to eating this scientifically created lab created beef? I think enough for a series market. Yeah, for sure. Well, there'd be a serious market for it for sure. If they could get the cost effective. Because last time I saw it was like quarter million bucks for a cheeseburger. I think it's down. I think it's $18,000 from me for. I mean, it'll eventually be like, you know, the Apollo computers now fit in your pocket much stronger in fact, than the Apollo computers.

Speaker 2:          00:10:20       Well, the sequencing, the genome, this, this I just noticed, which is fascinating. Um, sequencing the genome 15 years ago, cost $3,000,000,000. It's now 3000, so it's a million fold reduction in cost in 15 years. That's insane. So something like that, things tend to scale that way. So yeah, that's a giant scale though when you talk about human history, that's awesome. Good Lord. Imagine if you're a guy who spent 3 billion of it 15 years ago and you're like, God, if I just fucking wait here would to saved so much money. And that's mean. We don't anticipate that. When we think of how difficult it is to solve certain problems, we don't. And this is ray Kurzweil's point of records while who I think is, is a bit of a cult leader. And um, I'm a carnival barker on many topics. This, this point, he makes it again and again I think is quite valid, which is when you're factoring how difficult it will be to get into the end zone, whatever that ends on is you're not tending to factor all of the improvements and the compounding improvements in technology along the way. So I would love to get back to Ray Kurzweil, but I wanted to bring up this point about did you. One of the things about going Vegan, especially when you proclaim and you go public with going Vegan, if you back out of that, that's where, that's where I am as a vegetarian. They get fucking mad. They get mad. Did you see that family? A couple that runs a bunch of Vegan restaurants. Um, and they decided to start eating meat again. Even though they, a Vegan restaurants,

Speaker 1:          00:11:53       they decided to start. They have their own farm, they raise their own cattle and they started eating their own cattle. It was real weird too because they brought, there was a lot of Jesus in their message, right? There was a lot of, like Jesus said, we're supposed to take care of the biblical quotes. You know, like really obscure biblical quotes about food, like, oh, okay, like what are you doing here? But they have a. Here it is. Vegans were bold against owners of famous La Vegan restaurants after meat eating outed. Well, I think, I don't think you could say the outage because I'm pretty sure they put it on their facebook page. Like the guy was like first cheeseburger and 15 years. Is this, this is cafe gratitude. Yes.

Speaker 2:          00:12:34       Oh yeah. So, well the other thing that's hilarious about that restaurant, which I like it. The food is good, but have you been there? No. So everyone, now forgive me if this is no longer true, but at one point every employee there did the, um,

Speaker 1:          00:12:49       the landmark forum that the successor to asked. Oh, that's right. They get sued for that. Who gets this? This, this, this restaurant is one of the reasons why they closed one of the restaurants. Can you explain that though? Because. Okay, so landmarks. So,

Speaker 2:          00:13:02       um, which I've never done this. So again, I'm speaking outside the, the cult walls. But um, so runner earhart was a, a sixties. Um, you know, human potential figure who started asked, I'm never met him, um, but, uh, you know, obviously impressive enough as a person to get a lot of people to spend a lot of time doing whatever he said. And he had this, he had this, um, a growth, a course called asked, which has been, I mean, you've seen it in many movies, no name comes to mind now, but some version of this where you can keep everyone in the room and the people have to ask permission to go to the bathroom and there's kind of like a pressure cooker situation socially where you have everyone sort of torn down. I'm actually the classic case of this, I think this, this wasn't ss was the forum which is now the successor to.

Speaker 2:          00:14:00       So they were at one point hired to do coaching, uh, of, you know, various companies. And I think they're hired by the FAA. I wrote about this in one of my books in a footnote. It was the FAA FAA hired the forum to coach their, their, um, uh, administrators. And one of the exercises they a force these guys to do is, they almost certainly were mostly guys, um, they chained the boss to his secretary and had for like the whole day and they had to go to the bathroom together and like sort of, you know, ego annihilating experience. Anyway, this is, this is the recipe that, that, that, um, one of the recipes that asked is pioneered. This is not to say that people don't go to the forum and get a lot out of it. I, I've actually met those people. But

Speaker 1:          00:14:52       the, um, every employee of this restaurant apparently has gone or used to go do the forum. Um, so it's a very, you walk into the restaurant and your interaction with, with people in the restaurant is, is unlike most restaurants, people are just very, you know, lots of eye contact and, and it's just, it's an intense, it's intense restaurant. And also the stuff on the menu, um, this was just so lacerating I could never comply. But the, um, the name of everything on the menu is like, I am humble, I am magical alliance. So you have to, you're, you're meant to order it that way. Like I am humble. Oh God, I'll have an I am humble and they're given to you. It's your humble. So that's that. That becomes a little of. That goes a long way.

Speaker 1:          00:15:44       Well, they're retarded. That's what's going on. And if you go to is good though. I, I don't, uh, don't get me the wrong way. The food is good, but it makes sense then that they would go all Jesus, he religiousy when they were trying to justify their meat consumption. Jamie, see soon as you pull up the quotes for them, a justifying their meat consumption because it was real weird. I was like, how weird is that? These guys are like using Jesus and religion to justify eating cows when they've been a Vegan for all those years. What did you not listen to Jesus all those other years? Like you're like, fuck you, Jesus. I'm not eating meat. Like what was the, what was the turnaround there? It doesn't make any sense. Well, I don't think you can pull veganism out of the Bible unless you know a.

Speaker 1:          00:16:25       well, I guess if you go back to the garden and there's nothing about them eating meat, right? It's just, it was all provided from the trees. There's no slaughterhouse in the garden and Riparian Ism is fairly old. Mean. Vegetarianism has been around in Hindu cultures and so many different cultures forever, but not veganism. Right? I mean, veganism is really fairly recent. It's pretty impractical in history. Okay. Hurting remanence of our best tool to restore fertility to the earth. Keep the earth covered in reverse. Desertification and climate change. He wrote, we need cows to keep the earth alive. Cows make an extreme sacrifice for humanity, but that's their position in God's plan as food for the predators. Whoa. Huh. That's a strange quote, but I think there was more of them, but that's good enough. But there was. There was more of that kind of stuff. Like all the sudden he's a predator.

Speaker 1:          00:17:17       Predators go after animals. They chase him down and they kill them. It, I guess we're kind of predators in a way, but we're some new thing where some completely new thing. We. We use weapons or we corral them and if you've got them corralled and you just stick in that no country for old men thing in their head and killing them with it, I mean that's what they're doing, right? If you're doing that, it's like, I don't know if you're allowed to call yourself a predator. Well, historically were predatory and chimps are predators. Know not. Not entirely, but they are that

Speaker 2:          00:17:50       too.

Speaker 3:          00:17:50       We're certainly a kind of a Predator, but we're so much different now and this is what we're talking about. We're talking about factory farming and these weird businesses where they slam all these animals, these entirely too small places and they live in their own feces and urine and I'm sure you've seen that drone footage from the pig farm. I've seen a lot of pig farm footage, but I don't know if I've seen drone footage. I don't think I've seen lakes of urine feces. It's disgusting. It's unbelievable. They, this guy flew this thing. I mean they have these ag gag laws which are evil. Oh yeah, and if you don't know what those means, what that means. Ag Gag laws are laws that they make it a federal crime to show all of the abuse of these animals, to show factory farming because it'll affect the business so drastically and so radically when people are exposed to the truth that they've made it illegal. Those laws should be illegal. Those laws are scary. They're scary aspect of human beings. I've never seen this with some toxic lake. It's a lake of pee and poop and all those things are stuffed to the gills with pigs.

Speaker 2:          00:18:57       Yeah. That is a book, um, uh, eating animals, Jonathan Safran [inaudible] book, which is worth reading if you think you're immune to the details because it's just. I mean, there's the, there's two aspects to it. There's the cruelty aspect, which is actually three aspects. There's the cruelty aspect, which is horrific. Um, there's the environmental energy use issue which has also just totally untenable. And then there's just the, if you have any concern about your own health and the contamination, I mean just, just the getting all these antibiotics that weren't prescribed to you that you don't want, but it's still getting into you through this, this food chain. Um, and I mean, just the stuff that they like the chickens, I mean, the, the, the details about chicken farming is almost the most horrible. But I mean, they're, they're, they're covered in just, uh, just the, the foulest uh, no pun intended.

Speaker 2:          00:19:59       Just the most disgusting material they go into like a broth that's just like pure bacteria and um, uh, I mean they have to be washed with just ammonia or whatever they put on them. I mean, it's just to really wash with a moment that I, I forget the details, but it's just the read Jonathan Safran Safran for his book on this. It's just, um, the, uh, the details of what goes on from the chickens. Actually, I think largely because they're so small and it more of the process of killing them as automated, that they almost get the worst of it because they're, I mean, they're just, they're like, they're getting singed before they're done before that. I mean, there's just, it's just not. I mean, at least with a cow, you've got a single person interacting with a single cow, however, and it's, there's less chaos and in, in the machinery, but chicken is just get 'em pulverized.

Speaker 2:          00:20:53       And um, I think, I mean, that's arguably, that's the one of the greatest pain points ethically comes around just just egg industry because fully half the chickens that the male chicks just immediately get, get thrown into a, literally like a meat grinder because they're not the same chicken that is a broiler chicken. I mean, the genetically they're not the same. They don't, they don't grow into the same kind of chicken that would be useful. So they, they're, they're useless. And so they don't lay eggs and you, you don't eat them. And so they just get a, literally just fed into a, like a woodchipper, uh, alive. I mean there's no, and again, this is in some ways an artifact of them being so small that it would be so much of a Ha, just too much of a hassle to stun them appropriately. Right.

Speaker 1:          00:21:44       If they had to. They made a law. We had to bury them all and put little crosses in the ground. The labor intensive Jesus. I mean I was like millions and billions, you know, I was on the highway and there was a chicken truck that was passing me, one of those trucks that's containing live chickens and they just stacked to stacked and cages on top of each other cage on top of cage just shitting on each other and I'm watching this and I'm like, it's so weird that we're allowed to do that with some animals. Like if you were doing that with horses, people would lose their fucking minds. Have you had dogs in boxes like that stacked and in the open air on the highway and you're driving down the road with them. People would freak out, but no one bats an eye at these chickens. This chicken truck is. It's chickens or weird thing. We have like a hierarchy of animals that we love and we're not really big into reptiles, not really big into birds.

Speaker 2:          00:22:34       It has something to do, I think with facial expressiveness a little bit. And Mr Fisher also away down like the fact that fish have these cold expressionless faces no matter what happens, that, that's, that cuts down on empathy, but I think its size, its facial display and it's also the sounds they make, right? So, you know, if a lobster could scream every time it went to the pot, you know, um, it would be, it'd be a different encounter with, you know, just how much do I want to eat this thing. Um, uh, and so something obviously like an ape or something that's cute. I mean, it's amazing what a, what a fluffy tail will get you the difference between a squirrel and a rat. Right.

Speaker 1:          00:23:17       It's crazy. It is crazy. Squirrels could just hang out with everybody. We're cool with them. They look so close to rats. So like, God, I'm so close. It's like a hot girl sister. It's like, what the fuck? Like, so, so much so close. There was an article today about some woman who had rescued a lobster from a restaurant and dropped it off in the ocean and the journey of this all and how you should think of this lobster or something with a cute, and if you did,

Speaker 2:          00:23:46       then you would appreciate her efforts and understand that this lobster, even though they're not even capable of feeling pain in lobsters, they don't have enough nervous system. Their nervous systems aren't strong enough for them to feel pain. They don't have the same sort of sensors that we have. Allegedly. Yeah, I don't. I, I, I've threatened to do this actually when I. When I decided to become a vegetarian, I said at some point maybe I will just do a, a, a taxonomy of the kind of a comparative neuroanatomy across species just to see where we could plausibly say, you know, the suffering really begins to matter. The killing anything. No. Actually, there, there are what are called by Val vegans who eat clams and oysters and Mussels, and I could get into that because they think that, you know, there's no way you can make an argument that there's no basis for suffering there.

Speaker 2:          00:24:33       Well, if there's no feeling, there's no suffering, my argument against that Tau is lobsters are clearly not happy when you throw them in boiling water. So what's that reaction? I think anything that can behave, they can move right and move away from the stimulus, the, the evolutionary rationale for it to experience pain on the question of consciousness is difficult. You know, where consciousness emerges. And I think there is clearly an unconscious pain mechanisms, the same mechanisms that give us pain at a certain level. We can be unconscious and yet they can be just as effective. I mean, all of our reflexes are like that. So you touch a hot stove, you're pulling your hand away actually before you consciously registering. Um, and that's as it should be because you're faster that way. Um, so it's possible to have unconscious pain, but anything they can move very quickly is going to evolve and ability to move away from noxious stimuli and that, um, uh, there's every reason to make that, you know, in, in, in evolutionary terms as salient and is as urgent as possible, and then our pain responds is that for us, and there's no reason to withhold that from any other animal that's clearly avoiding stuff with all of its power, right?

Speaker 2:          00:25:54       Yeah. It seems to me that there's got to be all the way down to mushrooms because everybody eats mushrooms, even vegans, but mushrooms breathe in oxygen and they breathe out carbon dioxide. They're way closer to humans than they really are to plants. They're weird. They're a strange sort of an organism that's been mushrooms. Yeah. They're not necessarily like a plant. I mean, we think of them as a plan because they grow, but they're a fungus. It's a type of life form and they interlink through the mycelium. It will. Terence Mckenna. Okay. If you got him talking on mushrooms long enough, he would, uh, it's very spooky stuff that he thought about them. But there's no nervous system there. I think the crucial, um, variable is the complexity of a nervous system. So suffering and pain and emotions. Yeah, I mean, just when you're, when you're. So there's suffering is one component of it, but then there's just the question of what sort of experience can this creature be deprived?

Speaker 2:          00:26:58       Right? So when you ask like, why is it a tragedy or why would it be a tragedy to, to kill someone painlessly in their sleep, right? So there's no suffering there. Right? And if anything you've just ended whatever suffering they were going to have in their future, why would that be a tragedy if it happened to all of us tonight? Right? Just, you know, this, um, some neurotoxin comes down from space and kills us all in our sleep and no suffering is associated with it. The only, uh, you know, ethically speaking, the only problem there, and it's a huge one, is that it forecloses all of the possible happy future is most of us are, all of us are, at least some of us we're going to have. So the, all of the good things that we could have done over the next million years aren't going to get done.

Speaker 2:          00:27:45       Um, all of the beauty, all the creativity, all of the joy, all of that just gets canceled. Um, and so, so leaving the, the painfulness of pain aside, you know, why is it wrong to deprive any given animal of life? Well, they're in so far as that life has any intrinsic value in so far as that in so far as the being that animal is better than being nothing. Right? Then you're also just canceling all of that good stuff. And for that, you know, for any good stuff, you need a, a nervous system. Yeah. If and for any pain you need to. Nervous system. So far as we understand this, um, though there are people who say any good stuff, what do you experience any original movement though, right? Like being prejudice about the experiences that plants are having been by being immobile, you know, have you ever thought ever paid attention to some of the more recent research on plant intelligence and weird stuff that's going on with them?

Speaker 2:          00:28:43       Calculations and they're exuding, I'm expressing some sense that causes a when they're being eaten, causes other other plants. Downwind changed their flavor to avoid predation. There was a New Yorker article on this. I forget when this came out. We. It's weird. There's weird. There's weird stuff that plants do, which, and I remember the details of that article aren't so clear to me. I remember not knowing what to think about some of it, but some of it clearly can be explained in evolutionary terms. That doesn't imply any experience. It just, it could all be dark and it's all blind mechanism, but so the, it still has consciousness. The consciousness as we know it is. What's most valuable to you? Well, I think it's the only thing that's valuable to anything. It's like when you're going to talk about value, so it's like, you know, if this, if this cup has no experience, right?

Speaker 2:          00:29:39       So if, if my trading places with it insofar as you can make sense of that concept is synonymous with just canceling my experience. Well then there's, there's, this cup is unconscious. There's nothing that is like to be the cup. When I break it, I haven't created a suffering. I haven't, I haven't done anything unethical to the cup, I have no ethical responsibilities toward the cup, but the moment you give me something that can be made happy or be made miserable depending on how I behave around it or toward it, well then I'm, I'm ethically entangled with it. And then it's. And then, and that begins to scale. I'm in, I think in a fairly linear way with just how complex the thing is. So, and this is maybe something we even talked about on a previous podcast. Um, you know, if I'm driving home today and I know bug hits my windshield, you know that that has whatever ethical implication it has, but it's given what I believe about bugs and given how small they are and given how little they do and given how primitive their nervous systems are, um, you know, I'm not going to lose sleep over, you know, killing a bug.

Speaker 2:          00:30:51       If I hit a squirrel, I'm going to feel worse. If I had a dog, I'm going to feel worse than his son was a kid. Obviously I may never get over it and even if I live to be a thousand, right, so the, the scaling and, and granted there are cultural accretions there so you can. I justify that the way I feel about a dog as opposed to a deer, you know, that there's a difference, but the difference is one of richness of experience in so far as we understand what other species experience,

Speaker 1:          00:31:23       you could make that argument to justify eating animals as opposed to being accountable. Right? You could say, well, what kind of experiences a deer have? They're just running around the woods. Try not to get eaten. They eat grass they made. It's very simple. It's a very simple experience in comparison to your average person that lives in Los Angeles that reads books, you know, I mean someone who goes into a lot of trips, someone has a lot of loved ones. Someone who has a great career. Someone who's deeply invested in their work. Yeah. Is much more. Yeah. Yeah. There's much more complexity and the deer behave just as deer all over the place and it's a very primitive sort of a life form. Well, if you go further and further back, like what did. It seems like you can keep going with that and one of the things that I that concerns me the most about plants, not concerns me but puzzles me the most about plants is whether or not the way I look at them, me personally, my prejudices about them, I just not thinking at all of them as being conscious. What if we think about things in terms of the complexity of their experiences, just because we're, we're prejudiced about things that move made. It's entirely possible that like, it's going to sound really stupid, but I've said a lot of stupid shit. I went into a grow room once, like a pot grow room, right? This guy had his Mac daddy room and

Speaker 3:          00:32:40       I walked in. I was like, this is like being in a room full of people. This feels weird as fuck. It felt. It felt very weird. It felt like there was a tangible like vibe of life in there and there's no other way to describe that without sounding like a complete moron, but, but, but it was my experience. I know what it's like to be that more on, but you know what I mean. Take enough acid. You know what you're talking. I'm not saying that we shouldn't eat plants. I'm not done. I've seen people were ready up in arms with their twitter fingers ready to get off, but what I am saying is it's entirely possible that all things that are alive have some sort of a way of of being conscious. May Not be mobile, may not be as expressive, but there might be the stillness of you without language when you're in a place of complete peace, when you're in a zen meditative state.

Speaker 3:          00:33:34       What about that? Stillness is really truly associated with being a human are really, truly associated with being an English speaking person in North America. Almost nothing. It's just an existence. Right, and then everything else sort of branches out from that and then humans, we all make the agreement that of course it branches out far further and wider than any other animal, but how do we know that these plants aren't branching out like that too? How do we know that? Then if they're having some communication with each other, if they're responding to probation, if they're literally changing their flavor, they're doing all these calculations and all these strange things that they're finding out that plants are capable of doing, like what? What is going on there? We don't know necessarily. I'm agnostic on the question of how far down consciousness goes and I agree that there's very likely a condition of something like pure consciousness that really is separable from the details of any given species.

Speaker 3:          00:34:31       I mean it's something that I've experienced myself. It feels like you certainly have this experience, what you know, what its implications are. I don't know, but you can have the experience of just consciousness and it doesn't have any personal or even human reference point, so it's not. It's not. You're not even. It doesn't even have a reference point in one of the channel that the human sense channels so you're not seeing. You're not hearing, you're not smelling and you're not thinking and you're yet. You are. So there is still just open conscious experience and whether that is. That is what it's like to be a plant. I don't know because I don't know what the relationship between consciousness and information processing in the brain actually is though. It's not, you know, it's, it's totally plausible. In fact, um, I think it's probably the most plausible thesis that there is some direct connection between information processing and integrated information processing and consciousness and that and that there is nothing that's like to be this

Speaker 2:          00:35:38       cup and, you know, the atoms are not conscious and, and, and, but yet, but that the thesis that every, that consciousness goes all the way down into the, the most basic constituents of matter, um, that, that thesis is called Panpsychism and philosophy and that's pan everywhere. A psych is a mind. Um, so that the mind is sometimes everywhere in nature. That's not, you can't rule that out. I mean, there's nothing we know about the world to rule that out. What I think you can rule out is, um, the, the, the richness of the content of consciousness in these species. And so, so plants are not having conversations like this, right? So plants don't understand what we're doing. There's no way they would. There's just. No, they don't have nervous systems, they're not there, they can't be processing information in a way that would give them what we know as a, as a rich experience. But your point about the timescale and movement is, um, is totally valid if, if, if every time you walked into a room you're affirmed, just turned and looked at you, just oriented towards you and followed you around the room with its, with its leading branch, you would feel very different about, it's the possibility that it's conscious, right?

Speaker 3:          00:36:55       You'd be a good person to ask this, but is that a, an urban myth that if you sing to your plants, your plants, music, that they grow better?

Speaker 2:          00:37:03       Uh, I haven't looked into it. I would have.

Speaker 3:          00:37:05       When you define, I would bet that it is. Yes. It sounds like one of those things will chicks who like crystals tell you. Yeah, no. Yeah, I would bet. I would bet that it is. I sing to my flowers and they grow so beautiful. Yeah. It seems like one of those things that people say, I'm definitely not insinuating that plants would have as rich and experience as human beings, but I don't think a deer has as rich an experience. No, no. As a human being either. And it's just to me, my, um, my, my curiosity lies in the future of understanding plant intelligence. Like wouldn't it be fascinating if we found out that they, like, one of the reasons why psychedelic drugs puzzled me so much is that they exist and there's a lot of plants you could just eat them and you have your brain already has this place.

Speaker 3:          00:37:47       It'll go. If you eat these plants, like if you eat pod, if you, uh, if you try the San Pedro cactus out this spring, uh, you, you can, you can have these really powerful psychedelic experiences just from a plant. Like why does the human mind interact with these plants like that? Like especially fungus, like when you have like major league mushroom trips, it's very strange sort of feeling like you're in communication with another Mckenna described it best in that way. That there's someone there that it's not just you and hallucinations. It has this distinct feeling that there's someone there and that someone according to the. The hippiest of hippies is plan intelligence. It's my mother, Gaia. It's the earth itself. It's all life. It's love. It's God. It's all. It all exists inside the intelligence that's intertwined in nature. It's one of the most things that one of the things that's most puzzling about the most potent of all psychedelics, which is dimethyltryptamine, that it's in so many different plants like to make dimethyltryptamine containing plants illegal would be hilarious because there'd be like hundreds and hundreds of plants they'd have to make illegal like including like full Eris grass.

Speaker 3:          00:39:05       It's just really rich and five methoxy dimethyltryptamine, which is the most potent potent form of it. Also our own brains, so every, every brick, every brain makes it a little weird little lizards that have retinas and lenses where their pineal gland is. They're making it in their little screwy little lizard brains. We don't even know what the hell is for like the the, the questions about are just so much. There's so many more questions than there are answers. They were like, you've paid attention to, um, uh, rick strassman stuff, the general, that book did you know, that the cottonwood research foundation and actually found mice brains producing dimethyltryptamine. So it's been proven that it's actually been growing in the pineal gland, the gland that they had always.

Speaker 2:          00:39:51       Yeah. Yeah. I, I, I had assumed that if I got that from the book or not, but that's crazy

Speaker 3:          00:39:59       as a neuroscientist. Like doesn't that kind of freak you out that those Egyptians had those third eyes and like all the eastern mysticism had that pineal gland highlighted. It was like the on the end of shafts are staff. They would put those pine cones like how the hell they know all that.

Speaker 2:          00:40:15       Well, there is a, I mean the third eye metaphor or I mean it's not as more than a metaphor, you know, anatomically, but it's, um, it's a, uh, it's an, it correlates with the kind of experience you can have. I don't actually know if the experience people have. That's the shocker of you need to talk in yoga terms. Um, I don't know if that has anything to do with the pineal gland, I, it may be because I don't know, I don't think anyone's done this neuroimaging experiment where he can get people who can reliably produce a, a third eye opening sort of experience and, and scan their brains while they do it. In fact, I'm almost positive that hasn't been done. But, um, there is a phenomenology here of people having a kind of inner opening of, it's almost certainly largely a matter of, of visual cortex getting stimulated, but you can, you can meditate in such a way as to produce this experience.

Speaker 2:          00:41:16       And, um, it's also, it's an experience that you have more or less on, on different psychedelics. Psychedelics are much more visual than others and certain doses in particular like mushrooms and DMT, which I've never taken, which, which, you know, you can say better than I, but it's, it's reported to be quite visual and the, um, the experience, uh, so in most people when they close their eyes, unless they have to, having hypnogogic imagery is before sleep or they just have to happen to be, you know, super good visualizers of, of imagery. You close your eyes and you just basically have darkness there right now that now if you close your eyes and if you're listening to this and you close your eyes and you look into the darkness of your closed eyes, this, that actually is, that's it. That's a, that is as much your visual field as it is when your eyes are open, right?

Speaker 2:          00:42:09       I mean, it's not like your visual field hasn't gone away when you close your eyes. It's just, it's now, there's not much detail for you to notice again, unless you are in some unusual state, but that, you know, based on, on different techniques of meditation. And this happened spontaneously, again, with hypnogogic images or, or with psychedelics, that space can open up in to a, just a massive world of visual display, right? So you can just see a full blown, you know, three d movie in there, um, and it's a, uh, um, but most of us just take it for granted that when you close your eyes, you, you're functionally blind, you can't see anything and you were not, were not interested in that space, but you can actually train yourself to look deeply into that space as a, as a technique of meditation.

Speaker 3:          00:43:01       I don't want to interrupt you, but does that have implications in people having eye witness testimony and eye witness experiences that turned out to not be true at all? Because if you think about the, the, the, the human mind and the imagination be able to being able to create imagery once the eyes are closed, like you can in sensory deprivation tanks like 10 sensory deprivation tanks are that a lot of people's experiences are very visual even though it's in complete darkness. Now you know how people see things and they thought they saw something. And it turns out to not be true at all, whether it's big foot or whether it's a robbery or a suspect, and they get the details completely outright, but isn't it possible that under fear and when your your pulse is jacked up and your adrenaline's running and you're worried about all these possibilities in your imagination starts formulating predetermined possibilities. You should be looking out for like what if it's big foot? What if it's a Robert Wood? If it's an alien, what if it's at this and then these people that swear they saw these things that everybody knows they didn't like. Maybe there was video footage or for whatever it was. Is it possible that your brain can do that? Two, U and t can literally show you things that aren't real?

Speaker 2:          00:44:13       Oh yeah, I can do that. Although I think the unreliability of of witness testimony and it's shockingly unreliable, is more a matter of memory that the corruption of memory and the way memories are recall are there especially vulnerable when you're recalling them can be revised when you were in the act of recall. And it's very easy to tamper with people's memory, you know, albeit inadvertently. I mean you can do this on purpose too, but, but people just do it with bad interrogation techniques. So you know, the, the, the cop will ask you, you know, so when did you see the, you know, the woman at the crosswalk and he's just put a woman at the crosswalk into your memory, right? So because you, you can't help it visualize a woman at the crosswalk and his memory is very fragile. And so when you're, whenever you're giving an account of an experience, even if it's an experience that happened half a second ago, now we're in the domain of memory.

Speaker 2:          00:45:14       Now we're in the domain of, of, of just what you can report a we're not, it's not a matter of what you're consciously experiencing. No. I know there was a case in India where I believe it was a woman was convicted of murder through the use of an Fmr rye or a functioning magnetic resonance imagery machine. And through this Fmr I, they determined in some strange way that she had functional knowledge of the crime scene. And the argument against that, I believe, was that she could have developed functional memory of the crime scene by being told you're being prosecuted for a crime. You might go to jail for murder. Here's the crime scene. Like it's or just being unlucky enough to be familiar as, I mean, normally when this gets done and there are people who do it in the states, but they don't use Fmri as their modality, but they, they do, um, they do sort of interrogate people's familiarity.

Speaker 2:          00:46:16       Uh, and they, they use eeg as a, as a, um, as a way of monitoring. Um, uh, their familiarity with those. Show them, you know, if you are shown evidence from the crime scene that only the perpetrator could have seen, you know, hopefully it's really something that only the perpetrator could have seen. But if, you know, if they show you the picture and you know, you see the, Oh yeah, you know, I have that Ikea End table and you know, I have that dress from banana republic or whatever. Um, that just by dint of bad luck, you're familiar with something that you're being shown from the crime scene and especially if it's a murder, you're talking about someone who's. She was probably intimate with. She probably knew them at least. So she's probably been good house. Yeah, I think that would be obviously a case where you really couldn't do it at all.

Speaker 2:          00:47:05       How does it work? Why don't I know no one in the states as far as I know, unless this has changed in the last year or so since I've paid attention to this. You can't, this none. None of this is admissible in court were only on India and it's only the one case that I ever heard of crazy premature use of the technology. But how does the technology work? Like what does it, what does it actually seeing where you have, um, with Eeg, I think this has worked out more. You can have a, a, a, a kind of a canonical familiarity response to a stimuli. If you've seen something, again, if you've seen seen something for the first time, you know, is it would be a novelty response. Seeing something for the third, fourth, fifth time would be a different response and you can, I mean, this has been, um, uh, again, it's been a long time since I've looked at this particular research and I don't know how, you know, I don't know what they're calling these, these wave forms now.

Speaker 2:          00:48:00       I mean there was a p 300 wave form at one point and they're there way forms that come from certain areas of the brain at certain timing intervals based on, you know, from the moment of, of receiving a stimulus, you know, let's say a photograph. Um, and they are the hallmark of either being familiar or not with this thing. And um, yeah, so I mean it's not, there's no question that at a certain point we will have reliable mind reading machines. I think I'm not. I think it's really just a matter of time. I think there's also no question that we don't have them now, at least not in a way that we can, we can send some, send someone to prison on the basis of what their brain did an experiment. But I mean, just, just as you, I mean anything but a lot, a lot of this, the most interesting stuff is unconscious, but anything you're consciously aware of having seen before, right?

Speaker 2:          00:49:01       So if you, if you were to show me this Cup, right? And then, uh, five seconds later say, is this the cup I showed you? You know, I have a, a very clear sense of. Yeah, that's the cup, right? So, and if you show me a completely different cup, I'm going to have a very clear internal sentiment. No, that's. And that's not the cup. If you're having that experience, you know, that that is absolutely something about the state of your brain that can be discriminated by a person outside your brain running the appropriate experiment is just our tools are still sufficiently course that, you know, it's not like, you know, sequencing your dna where we can say, yeah, that was you. And what's your, your uh, blood at the crime scene. But, um, eventually it will be, it will be just, there'll be no basis to doubt it because I'll be able to put you through a paradigm where it'll just be clear, I know your thoughts, right?

Speaker 2:          00:50:06       So to think of how much faith you would have in this technology, if you could open your computer and read any file a file of your choosing that I have never seen, right? So the contents of which are, are completely blind, I'm completely blind to and I'm scanning your brain while you're reading this journal entry or a newspaper or whatever. And at the end of that I can say, well, you know, based on this report, you clearly read a story about Donald Trump and you, you actually don't like Donald Trump. And I could tell you in detail about, you know, what you were consciously thinking about, um, you know, if you did that, if you could do that 100 percent of the time, right? At a certain point, the basis to doubt the validity of the mind reading machine would just go away. You would just, it would be like, you know, it's like, are you here really hearing my voice right now?

Speaker 2:          00:51:01       You certainly seem to, you know, it's, it's just, it would become a, just a, a background assumption that the technology works at a certain point just as though the meat is scary. The fake meat. That idea is terrifying. The idea of losing the, the, losing your thoughts. Yeah. The ownership. Like losing a thought, becoming non autonomous, like the idea of everybody sharing thoughts, it seems almost inevitable. Well, this, you know, I don't know that we would decide to do this. Certainly I don't think we would do. We would do this all the time, right? I mean it might be Sunday doing something, but no option. We might be compelled to do it. I mean, if, if you're at a murder trial, right? If you, someone who may have killed somebody, you, you, I mean, the, the fifth amendment becomes interesting in that case. But, um, uh, we have worked that out for DNA evidence, right?

Speaker 2:          00:51:54       So you, you have a right to take the fifth, but you don't have a right to withhold your blood from the proceeding. Right? So I get, I get to look at your blood or your saliva so you don't have to talk, but I can read your mind. Yeah. Yeah. And that's, I think that's a. well, and it's, this is like the iphone case, you know, it's like I thus far decided that we can't compel apple to unlock an iphone. Uh, this is just the ultimate case of that. So the, the argument in favor of apple is this is far too intimate and far too comprehensive. Look at a person's mind. Uh, you know, once you have cracked their iphone, you, you're basically walking around the corridors of their brain, um, uh, that's a, that's a slippery slope. We don't want to go down, but ultimately we will be able to do it with brains.

Speaker 2:          00:52:45       And I think it obviously you're going gonna want all of the safeguards that you can easily imagine and probably some you have yet to imagine on this process, but safeguards in place. I think this would be the best thing that could ever happen to us in terms of, of, you know, when you look at a criminal justice system and that when you look at the price we pay for not being able to tell whether someone is innocent or guilty or whether they're lying. It is just, it is the most intolerable price that I see in society. It's just, it's just the amount of human misery born of not being able to demonstrate that someone is lying reliably. It's just, it's off. It's, it's the biggest lever that would, I think we could pull certainly when you have prisons that are filled with a lot of people that are probably innocent.

Speaker 2:          00:53:39       Yeah. Oh yeah. People who have gone to to the gallows, no doubt. And we know innocent people who have been killed. And so one way to deal with as you be, be against the death penalty. Right? So there's always a chance to find their innocence. But imagine being in prison on death row for 30 years and you know, for rape or rape, you didn't commit, you know, it's um, it's so horrible. Terrifying. So yeah, that would be the major argument. It would be such a simple solution. Really A, now there are corner cases that wouldn't be solved. I think there are people who are delusional or easily self deceived who either would be lying and, but you know, so convinced of the truth of their lives that they would pass this, this lie detector presumably. Um, and then there are people who are so sick, suggestible that they can be led to believe something that's not true.

Speaker 2:          00:54:32       I mean they'd be the people who can be convinced that you get these false confessions of, in response to a crime. I mean, it's a, it's one of the strangest things in the world, but you know, when, when someone gets murdered, this doesn't get publicized very much. But it's a very common experience of police officers or police departments to hear from people in the community who are confessing to the crime and they didn't commit it. They just come in and they say, I did it, and they, they give all this, you know, this bogus account of what happened and these, and this is a sign of mental illness or these, you know, these are people I'm seeking attention and some morbid way, but there are people clearly who are so suggestible that they can either lead themselves to believe or be led by others to believe that they've done things they didn't do.

Speaker 2:          00:55:23       And, and in, in just shocking detail. There was another New Yorker article on, um, uh, I think it was written by William Languish, um, uh, this years ago, but, uh, on a, a satanic panic, a case where a guy got a accused of running a satanic cult, uh, by I think his daughter who was in hypnosis, hypnosis recovery therapy, right? Um, so she had been led down the primrose path by her therapist. And so she obviously was fairly suggestible and she recalled the most lurid, just insane Rosemary's baby style, you know, cult, uh, imaginable going on in her town where the friends of dad were coming over and raping everyone. And there was a human sacrifice of infants and the infants were buried by the barn and um, she, this, the dad was so suggestible that he just confessed and he was just, he and he was given more details and he went to prison.

Speaker 2:          00:56:33       I don't know, this is this now an old article. It's probably like 10 or 15 years old, but this guy, this guy just fully confessed, right? And, uh, the journalist I believe was language. Um, uh, at the end they actually did a Ted guy is now in prison, right? The process is completed. Justice has been done. Uh, the daughter convinced that her, her dad has a satanic monster and uh, as, as he, and he's now in prison and they went in and interviewed him asking followup questions with just details that they made up, right? Because they began to suspect that he was just this kind of suggestibility machine, right? Who just would cop to anything. And so they went in and they just made up stuff like, oh, you know, there's, you know, a few more details want to iron out. Your daughter said that there was a time where, you know, you got a, you brought in a horse and riding on the horse and um, and then you killed the horse.

Speaker 2:          00:57:28       I've, I, I'm not, I'm making these details up because I don't remember. But, um, something that they just concocted. Right. And he said, Oh yeah, yeah, yeah. That's, um, so, and he just copped to that. It was, it became like a twilight zone. It's like a perfect twilight zone episode where they, like now you realize that this guy has been put away is just saying yes to everything. Right. And that's, that's um, so clearly that they resolve it. I don't know. Again, I don't know if he ever wrote any followup on this because this as I recall, and this, uh, this is like a 15 year old story. It just, they ended with like, you know, the twilight zone moment where now you realize this guy is innocent and just saying yes to everything. And his daughter crazy, she shares his jeans. I don't remember.

Speaker 2:          00:58:11       I don't recall what the daughter did with that. Uh, but he, um, I mean the, the story and perhaps there's more to the story, but the story on his face was totally exculpatory, like, like the reader experience was you got to let this guy out of prison tomorrow because you know, I'm fucked and he needed. If he gets out and he's mine is probably so screwed up by this whole experience and if he really does believe that he ran these satanic rituals, just the guilt and shame of it all. I mean we're assuming that his mind works. I mean this is the thing that I wonder how many people were like functionally deeply, deeply damaged, but they're functional. Like they're there, they're going to the same schools and you go to, they work where you work, but they're barely a person. They're like, all their connections are all fucked up. Like if you went into the back wiring or their head, if you were like an appliance repair person, like sell your TV's not working. Huh? Let me go back here. What the fuck is all this mean? How many people are like that, that are just sort of kind of functional? My question is if we do get to a point where you could read minds, what if you go into their minds and you find out, well, this is what they really think, like this is not a liar, this is a person

Speaker 3:          00:59:22       who's seeing things that aren't there, like a person who's completely delusional, like people that have these. I'm hallucinating a hallucinogenic visions like some people have like really like deeply troubling visual images that they see match. If he's poor, fucking people really are seeing that and if you could read their mind, you would. You would literally be inside the mind of a person whose mind isn't functioning and we can get sort of an understanding about what that would be like. Yeah. Well, this has been done in a very simple way. Where you with schizophrenia who mostly have auditory hallucinations, you can now detect auditory cortex activity, so mishaps, misinterpretations. We just know that they're. They're auditory cortices are active in the same way that when you're hearing my voice, it's going to be active. When they're hearing internal voices, it's active. Whoa, that's crazy. Which is what you would expect.

Speaker 3:          01:00:18       Maybe be the surprise would be the other way if it, if nothing was going on and auditory cortex and they were hearing voices, then wow, then that would be more surprising to me. That's fascinating. You can watch the hallucinations take place inside the mind of the person and you can stimulate hallucinations in people you can stimulate out of body experiences and people with, with transcranial magnetic stimulation and. Yeah, how do they do that? They've been able to do that recently and to try to give people the same sort of experience that they claim to have had when like on the operating table. That's what people have a lot, right? When they're almost dead. Yeah. Yeah. What's going on? What is that?

Speaker 2:          01:01:00       Well, that is, um, uh, there's an area, I believe this is the temporal parietal junction, which is sort of like here, um, what you're pointing to a lot of time talking to you and not talking to the millions. Um, but uh, it's um, you know, where the temporal lobe and the parietal lobes intersect. Um, and the, um, I think it was first discovered in surgery on an epileptic where they, so are you in, in any kind of resection of the brain where the people are awake because there's no pain sensors in the brain so you can, you can stay awake while you're getting brain surgery and they tend to keep you awake if they're going to be removing areas of the brain, you know, let's say a tumor or the focus of an epileptic seizure, um, and they don't want to remove working parts, especially the language part.

Speaker 2:          01:01:57       So, so they're, um, they're keeping people awake and they're probing, uh, those areas of the cortex to see what it's correlated within the person's experience. So you said there having them talk, they're having them answer questions and they're, and they're putting a little bit of current in that area which would be disruptive of normal. And you know, you can see there they're mapping the almost entirely mapping language cortex when they do this. But there have been experiences where they, they, I'm a neurosurgeon will, will put a little current in, in an area near this region of the brain and people will have this out of body experience where they're, you know, up in the corner of the room looking down on their bodies or um, you know, the classic, you know, astral projection experience where the or the um, um, the near death experience where, you know, people have, have risen out of their body or seem to have risen out of their body and consciousness now seems to be located elsewhere.

Speaker 2:          01:03:04       And that's a, um, uh, there's just, uh, the, the, that region of the brain is, um, I mean, virtually every region of the cortex does many, many things. There's no, there's no one region of the brain that does one thing. You know, there's a couple of exceptions to this, but the, um, uh, so the burden, the whole brain is participating in, in much of what we do and it's just a greater or lesser degrees of activity. But in terms of your, your mapping, your body in space, this is, you know, the parietal lobe is, has got a lot to do with that and when that gets disturbed, you can have weird experiences. You can have the experience of, I'm not recognizing your body or parts of your body. You're like, you, like, you don't really like Alien Hand Syndrome where you'd like your left arm. Uh, seems seems like another person's arm, you know, and people, you know, try to disown half their body.

Speaker 2:          01:04:05       Um, and uh, you can trick people with visual, um, uh, changes of display like you can, you can wear headgear where you can make me feel like it's like a, it's called the body swapping illusion. I can feel like I am located. My consciousness is located in your body. Looking back at me, there's a, there's a clever experiment that they did where, um, that is the ultimate extension of what has long been called the rubber hand illusion where you can, you can put like my two hands are on the table. Now you can set up an experiment where if you put a rubber hand, um, if, if you, if you set this up in a way where I am, I am assuming I have my two hands here. Um, you can, uh, you can put a rubber hand in its place and um, touch, touch this rubber hand with it, with a brush, right?

Speaker 2:          01:05:04       So, so the, so I'm seeing the rubber hand get touched. W W with a brush and I'm a, I can feel like my hand is being touched. Like it's like if my hand is being touched, my hand is elsewhere under the table being touched with a brush at the same time. I can feel like my hand is now the rubber hand, right? I could, so I can feel like my hand is in place of the rubber hand based on visual and tactile. Um, you know, the simultaneity of my scene, the rubber hand get touched with a brush and my feeling my hand, which is now under the table being touched with the brush. I'm, I'm not explaining that setup great, but people can look it up. But you can do the same thing to a, to the ultimate degree with this video goggles display where I'm getting input, visual input from where you're standing.

Speaker 2:          01:05:54       So like if you come up to shake my hand, right, I'm, I'm seeing you come up to me and shake my hand, but I'm seeing it from your point of view, right? So like I'm getting, you know, visual input from, from, you know, I now feel like I'm walking up to me shaking my hand and you can, you can just kind of feel like you are consciousness is, is out, is over there, you know, outside your body. Um, and it's just to say that, that our, our sense of self, our sense of being located where we are in our heads is largely a, and in some cases almost entirely a matter of a vision, right? It's a matter of fact. The fact that you feel you're over there is because you're, I mean, that's where your eyes are here. You're behind your eyes. You feel like you're behind your eyes. And when you and tricks of a vision can, can, uh, seem to dislodge, um, that's that sense of being located there.

Speaker 3:          01:06:51       So stimulating one area of the brain electrically has been shown, like even just transdermally, just the, I guess, what do they do? They put little, little, what are those things called? Those little glue on things. Electrodes. And they can.

Speaker 2:          01:07:07       You're talking about eeg. They're reading from the brain, right?

Speaker 3:          01:07:11       No, I'm actually talking about some new experiments that they've been doing that they were talking about on radio lab. And apparently there's a bunch of, do it yourselfers that or if you ever listened to radio lab. Amazing Awhile. But yeah, amazing podcasts like one of the best our. But it has this one episode that dealt with people learning certain skills while the outside of their brain is being stimulated with like a little electrode. And this woman who was one of the reporters went to a sniper training thing where they set up the scenario and they give you like a fake gun and you pointed the screen. He tried to hit the targets as all these things are happening. Uh, she did it once. Yeah. Nine Volt Nirvana is the name of the episode. Right, right. It is an outstanding episode. It's so fascinating. Anyway, she goes through one. She's terrible at it. She just sucks terribly. Then they hook her up to this machine. They attached this electrode to a certain certain area of her brain, stimulate one area of her brain and she goes through it like a fucking sniper time, slows down. She gets 20 out of 20. So she goes from being a complete failure to being awesome at it and some weird state

Speaker 2:          01:08:15       that she described and they're talking about of the US government's using it and they're trying to train soldiers and snipers and people to try to understand this mindset and try to achieve this mindset and that they're trying to do it. And there's certain companies that are experimenting with it at least by stimulating the outside of your head. Was it. So I could not know this particular story. I remember hearing that title though, but the transcranial magnetic stimulation is magnetic energy, which is, you know, the, the flip side of electrical energy. So if you apply a big magnet to the side of your head, you are changing the electrical properties of your cortex. Is that what they're doing? Well, no, I'm, I'm wondering if they've just made a transcranial magnetic device so small that it's, that it's um, I don't think it's Magneto is direct. Current.

Speaker 2:          01:09:07       Yeah. Well, yeah. Okay. Direct current stimulation. Transcranial direct current stimulation. Yeah, that's what it's called. TCD will say. Yeah, I'm unaware of the specifics of this, but it's, it's been true for a long time that with, with, with um, a much bigger device in a lab, you can change a person's performance for good or for ill on, on various tasks just by and, and it's just an electromagnet which is focusing its energy on various areas of the cortex. So bizarre. Yeah. Because what we're doing, I mean you are, you are disrupting a neural firing, but your, you can disrupt areas that are inhibiting other things you want to release. So it's, it can be, it's not always synonymous with the degradation of performance mean you could, you could increase performance on a certain task by taking one region of the brain offline are more or less offline.

Speaker 2:          01:10:09       Um, but I'm not, you know, I'm not aware of how far they've taken it in terms of doing anything that seems useful in terms of performing something. I mean what the research I'm more aware of is just using this to figure out what various regions of the brain are doing. I mean I a mapping function because you want to see if I disrupt area and area here, what, how does that show up in an experiment and that gives you some clue as to as to what that region is doing, at least in that task. As much as we know about the mind and being able to do things like this. Like overall, if you had a really like trying to map out the exact functions of the mind and how everything works, how far do you think we are along the understanding that we halfway to think we understand half of how the brain works.

Speaker 2:          01:10:55       Not what I mean, I wouldn't even know how to quantify it at this point. It's just we know a ton, right. And we know how we know a lot about where languages and where facial recognition is. And so your, your, your visual cortex been really well mapped and um, uh, we know a lot and the last 150 years based on just the neurological injury and, and then in the last, uh, decades based on imaging technology, we know regions of the brain that, you know, absolutely governed language and regions of the brain that have basically nothing to do with language, you know, to take one example, um, and we know a lot about memory and we, we know about a lot about the different kinds of memory, uh, but it's um, there's, you know, I think there's probably, there's much more. We don't know what's even more um, because I kind of the greatest friction in the system.

Speaker 2:          01:12:01       There's not often a lot to do with what we know. Right. So like the, like knowing is not enough for certain things. It's not because he tried to intervene is another part of the process, which where there are no guarantees, I mean the, the, the, the way we can intervene in the functioning of the brain is incredibly crude, you know, pharmacologically or with surgery or with a device like that. Um, so to get, to get from a place of really refined knowledge to a place of being able to do something we want to do with that knowledge, that's another step. And that's, that's a step that is, um, you know, I, I, there's no reason to think that we're not going to take it at some point, but it's an additional complexity to get inside the head safely and help people, you know, or improve function.

Speaker 2:          01:12:50       Um, uh, even if you know a lot about what you know, those areas of the brain do, but we don't, we don't know. We haven't cracked the neural code. We don't know. We don't know how consciousness is arising in the brain. Um, we wouldn't know how to build a, a, a computer that does what we do to say nothing of experience the world as we experience it yet. And um, and we may be going down paths where we will build it more by happenstance, whereas like we will, we, when we build it and not quite know how it's doing, what it's doing, but it seeming to do more or less what we do, I would be doing it very differently. I mean, so the, there are two paths are at least two distinct paths in artificial intelligence and one path could take a, could try to emulate what the brain is doing and that obviously requires a real detailed understanding of what the brain is doing.

Speaker 2:          01:13:51       Another path would be to just ignore the brain, right? So like there's no reason why artificially intelligent machines, even machines that are super human in their capacities need to do anything, uh, that is similar to what we do with our brains. You know, it wouldn't, you know, neurochemical circus, so because they're going to be organized differently and um, you know, could be organized quite differently and obviously made of totally different stuff. Um, so whether you want to go down the path of emulating the brain on the basis of have a detailed understanding of it or you just want to go down the path of maximizing intelligent behavior in machines or some combination of the two, they're there. They're not necessarily, they're, they're distinct and, and, um, one doesn't entail really knowing that much about the brain necessarily. So there's really two different ways they can go about it.

Speaker 2:          01:14:53       Either they could try to reproduce a brain, which people are, they can make. Yeah, I mean, if they can make fake meat, why can't they make fake brain tissue? It seems like they could. I mean, I know a woman got her bladder replaced with stem cells. Did you hear about that? They took stem cells and recreated her own bladder in a, she had a bladder cancer, so they built her a new bladder and a laboratory and put her own ladder back in her body. That is sanely fascinating. Now, if they can figure out how to extract a little bit of brain tissue thing is that the brain is famously the most complicated object in the universe. A bladder is essentially a bag, you know, so it's a big leap. It's a big leap, but it's not, um, you know, I think it's a leap we will take and you know, whether we take, whether the May maybe a leap we take in this step wise way where we build machines down a path that is not at all analogous to recreating brains, which allow us to then understand the brain, you know, totally.

Speaker 2:          01:16:00       I'm in, in the, uh, in the Ray Kurtzweil sentence where we can upload ourselves, if that makes any sense. Um, but it's a uh, uh, I, I think, I think information processing is at bottom what intelligence is, I think that is, that is not really up for dispute at this point that any, any intelligence system is processing information and our brains are doing that. Um, and any machine that is going to exhibit the kind of general intelligence that we exhibit a and surpass us, we'll be doing by dent of its hardware and software. Something deeply analogous to what our brains are doing. But again, it may not, we may not get there based on, um, directly emulating what our brains are doing and we may get there before we actually understand, understand our brains in a way that would allow us to emulate it. It's always very interesting

Speaker 3:          01:17:10       to me how it seems to be. There's always a pushes and pulls in, in life and when you have things that are as horrific as factory farming and people are exposed to it, then there's this rebound and where people were trying to find a solution. And I always wonder like if will that be the first artificial life that we create? Like Zombie cows, like some made, if we've figured out that meat in the lab is not good because it has to actually be moving around for it to be good for you. Maybe maybe they'll come up with some idea to just look, we're going to make zombies were going to make livestock that essentially can just move forward and consume food. There's no thought whatsoever. These are zombies. You can go right up to him and you wave your hand in front of them. They don't even move.

Speaker 3:          01:17:54       Is it okay to kill those and then go from that to making artificial people? Because it seems to me that artificial people, it's going gonna happen. I mean it's just a matter of how much time, if they're making bladders and then they're going to start making all sorts of different tissues with stem cells to try to replace body parts in Oregon's and they're, they're gonna, they're gonna work their way through an actual human body. It's going to happen. What do you mean? You mean a, a brainless person that would be like spare parts for, for you? For sure. That's an option, but I think also an artificial human, I mean might take a thousand years, but I think if we stay alive, if human beings rather, if human beings continue to evolve technologically within the next hundred years, we're going to have artificial people that are completely see that people. So we're going to build a biological person, hundred percent. So it's that sense that synthesize synthesized person, right? So it's not, we're not, you're not talking about the perfect robot. You're talking about an actual person built up cell by cell,

Speaker 2:          01:18:53       yet you know, there's no, there's no reason why that's not possible. And whether or not we would do it is, is another question. But yeah,

Speaker 3:          01:19:02       I had a, I had this somebody would China where you're. Yeah, well presumably there are limits. Even in China, they do an experience. There's already with human embryos. I don't know what they're doing in China. I believe they are. I believe they got the goal to have that dog festival every year. I see people tweet about China's a big place though, can't remember them all in there, but you know, um, uh, what does that gene splicing software, Chris Perrysburg to using crisper on a human fetuses or human embryos. Right? So good luck, good luck world. Well, so China is creating super athletes. There are many issues there.

Speaker 2:          01:19:39       Mean. So when you're talking about a changing the genome and you, especially when you're talking about changing the germ line, you know, and then it gets passed onto future generations that, that has big implications. But um, you know, I don't see why, I mean this goes to, it's like the artificial meat conversation, so to, to grow meat in a vat is ethically the same thing as, at least my view. It'd be the same thing as producing a brainless cow, right? The, so you have the whole cow that you could slaughter, but it has no brain. And so presumably there's no experience in this animal, but it is the fully functioning animal, right? So let's say you could produce that and it would be a, you would produce healthy meat. It's just a messier. Presumably you have to feed this thing, right? Um, or, or I don't know how you get it to eat, but you know, you'll say you feed it intravenously.

Speaker 2:          01:20:37       It all begins to look weirder and Weirder, but there is no suffering there because there's no brain. Um, I think we would, and I think we have decided to bypass that vision and just go straight to the VAT and just build it up, sell, buy, sell, and build up only what we need, which is the meatball or the steak or a. and so why have the author and the and the organs that you don't want and the mess, and I'm the kind of the energy intensive aspects of, of producing whole animal and I think with like spare parts for humans rather than create a clone of yourself that has no brain, that you just keep in a, in a vat somewhere in your garage, uh, where you can get spare kidneys when you need them. Um, we would just be able to print the kidneys and that is that because that gets around a lot of the weirdness, right? It'd be weird to have a copy of yourself that's just a spare parts, uh, whereas it wouldn't be weird or at least in my view, wouldn't be weird. It would be fantastic to be able to go into a hospital when your kidneys are failing and they just take a cell and print you a new kidney.

Speaker 3:          01:21:46       Yeah. Um, I think that can be expected. And that's going to. I mean, if it's possible, it seems like it's going in. The bladder example you just gave is, is uh, what's happening there. It's amazing. But I always want to extrapolate things to some bizarre place a thousand years from now for some reason because, uh, I've, I've been, you know, since I got into Dan Carlin's hardcore history, um, I've, it really fucked my mind up about how I think about the past in this way that I look like a thousand years ago in comparison to today. And I, you know, I try to think, well, how much different will people be a thousand years from now? And it probably way more different. Yeah. You know, I mean the, the fascination that we have with ancient histories that we, one of the things obviously we want to know where we came from, but also we can kind of see people today doing similar shit if they were allowed to. Like if everything went horribly wrong, people at their base level of kind of similar today as they were a thousand years from now, one of them might be running for president. We can talk about that. And when I think about the future a thousand years from now with the way technology is accelerating and the just the capacity that we have an ability change, things

Speaker 1:          01:23:06       to change the world, change physical structures to change bodies, to dig into the ground and extract resources like we're getting better and better at changing things and manipulating things that extracting power from the sun and extracting salt from the water. There's like all this bizarre change technology that's consistently and constantly going on with people and it continues to get better when I think about a thousand years from now and artificial people and light and this concept of being able to read each other's minds and being able to map out imagery and pass it back and forth from mind to mind and like a clear spreadsheet form like a. What does that movie with Tom Cruise movie. Minority report. Thank you. Mean that's the way it's on the way. It's going to be incredibly strange to be a person. Yeah. Whether we will be people in a thousand years, I think you would.

Speaker 1:          01:24:00       Unless we have done something terrible and knocked ourselves back a thousand years, uh, I think we will decide to change ourselves in that time in ways that will make us. And we, you know, they'll be, there may be many different species. It's like tattoos, you know, you, you have a bunch of tattoos. I have none. You could take that a lot further if you can just begin really tinkering with everything, you know? Oh yeah. If you want to get nutty and put the bolts in your head and shit or just, just give yourself a, just fundamentally different genetic, uh, abilities, right? I mean like if you could just go, you could become a different species if you took it far enough.

Speaker 1:          01:24:41       Maybe that's what the aliens are. Maybe that's why they all look the same. Maybe they figured it out like a little. You got to look alike. Otherwise you can't appreciate each other. When one guy's weird looking, one guy short, one guy's got a big nose. Everybody is so confusing to many people. I could hate everybody look exactly the same. So the government gets together with all the people to their planet and they go, look where we have a problem with this good looking thing. Bullshits holding us back. A lot of people that are stupid, that getting ahead, we've got all look the same blank, emotionless and big giant eyes. That's it. They all just went in with a passion for molesting cattle, allegedly. I think that's people. People are blaming that on the aliens. I had this guy on my podcast, David Deutsch. Have you heard of him?

Speaker 1:          01:25:24       He was a physicist at Oxford. Yes. I have. Why ever heard of him? He wrote a book. He gave it at least one ted talk and he's written two very good books. The first came out about 10 years ago, the fabric of reality and the more recent one is the beginning of infinity. And I'm extremely smart guy and I'm very nice guy. And He, um, he has this thesis which he, he and I don't totally agree about the implications going forward for ai, but the, um, he's convinced me that his basic thesis, which is fascinating, which is his, his, um, the role

Speaker 2:          01:26:04       that knowledge plays in our universe or the potential role that it plays and his argument is that in any corner of the universe, anything that is compatible with the laws of physics can be done with the requisite knowledge. So that as, uh, his, his argument about how deep knowledge goes and therefore how valuable it is in the end. So I'm queuing off your notion of building an artificial person. I mean literally, you know, sell by salary, atom by atom, if that. There's every reason to believe that's compatible with the laws of physics. I mean, we exist, right? So we, we got built by the happenstance of, of biology. Um, if we had what he calls a, a universal constructor, you know, the smallest machine that could assemble and the other machine atom by atom, um, we could, we could build anything. Adam. Bye Adam. Right? And um, so he has this vision of it like you could literally go into a, um, an area of deep space that is as close to a vacuum as possible and you know, begins sweeping up stray hydrogen atoms and fuse them together and generate heavier elements.

Speaker 2:          01:27:27       I mean literally, so you could start with nothing but hydrogen, right and, and bay with the requisite knowledge, few bit, build your own little fusion reactor, create heavier elements, and based on those elements, create the smallest machine that can then assemble anything else atom by atom, uh, including more of itself. Right? And you could start this process of building anything from a person to, you know, if there's something far more advanced than a person to a planet, but just anything is made of atoms, right? Anything is organized and, and, and so the, the limiting factor in, in that case is always the knowledge, right? So it's either the eliminating factors, either the laws of physics, either this can't be done because it's physically impossible or the knowledge is what you're lacking. And I'm given that human beings are physically impossible. There should be some knowledge path whereby you could assemble one atom by atom, right?

Speaker 2:          01:28:29       There's no, there's no reason why there's no deep physical reason why that wouldn't be the case that the reason is it's we don't know how to do it right. But presumably a, it'd be possible for us to, to acquire that knowledge. And so the, the horizon of knowledge is just extends functionally without limit, right? There's just, there's, we were nowhere near the place where we know everything that's knowable, um, as, as witnessed by the fact that we don't yet know how to build a, a human atom by atom. Um, but when you imagine just the changes that could occur in our world, uh, w w with, with the frontiers of knowledge explored, you know, 10,000 years beyond where we are now. I mean, it would be, we will be unrecognizable to ourselves and everything would be equivalent to magic. You know, if we could see it now.

Speaker 2:          01:29:27       And, and most of human history is not like that in most of human history. Have you dropped into any period of human history? It was, for all intents and purposes, identical to the way it was 500 years before and 500 years before that. It's only very recently where you would drop in and be surprised by the technology and by the culture and by the, the, the, what is being done with language and the consequences of, of a cooperation among apes like ourselves. And um, so I think that this is one place where someone like Kurtzweil makes a lot of sense. This is, this is clearly accelerating, right? And if we, and if we don't do something catastrophic, uh, to set us back, this acceleration is, is the implication is that the future is going to be far less recognizable than it has been in an, in any other period of human history to the idea of creating a little machine that you could shoot out into the universe and we'll build you a planet.

Speaker 2:          01:30:35       Yeah. Yeah. But the planet is a planet. It's not the planets obviously big and the basis for our biosphere and everything we care about. But the planet is not what's complicated. It's the ecosystem. It's the life on the planet. And our own brains being the ultimate example of, of, of that complexity, but presumably intelligent systems can become much more complex than that, right? There's no reason to think that we are near the summit of possible intelligence, a biological or otherwise. And I'm a, yeah, it's a, uh, once you, once you begin thinking about building things atom by atom, then then, then the, the future begins to look very weird because it's, and automating that process, right? Where you have, and this is, this is the promise of nanotechnology, um, where you have something, you tiny machines that can, can both build more of themselves and more of anything else that would be made of, of tiny machines or assemble anything atom by atom or treat your own body like a machine that it is and deal with it atom by atom.

Speaker 2:          01:31:56       I mean, that's the possibilities of intervention in the human body or, or then virtually limitless. Um, so it's a uh, um, yeah. I mean, that's, that's where we, that's where the physical world begins to look. Just totally fungible. One, you know when you're not talking about surgery where you're cutting into someone's head and hoping you know in very coarse way, hoping you're not taking out areas of brain that they need, but you're talking about actually repairing A. I mean if you're talking, if you can, if you can tinker with Adam's in a way that you understand you, then you're talking about repairing anything, you know. Then in creating anything. Yeah, like literally Dr Manhattan style, build ice condos on Mars. I mean you could create art with it. You could do anything with it. It would just somehow or another have to be programmed with whatever pattern you were trying to create.

Speaker 2:          01:32:52       You could, you could essentially like make an earth somewhere else with all the biological diversity, water, even intelligent life that all could be done through some sort of a machine. Well it is only one day. It is at bottom. Again, just the information. It's the knowledge of how to organize and how to implement it. So it's like it's analogous to what has happened in films now where like an animation and film has gotten good suddenly. Right? Where you can see like, like if they can animate, you know, waving hair and full and flowing water and it looks pretty damn good at it. It looked terrible 30 years ago. Right. And we just acclimated to look terrible, but I'm now at you can, you can really trick the eye. You can build up scenes of nature where they're not actually using any photography of nature to build it up.

Speaker 2:          01:33:48       It's just, it's all a confection of, of ones and zeroes. Right. They've just, they've just, they've just built it in, in software like the revenant. Perfect example, that giant bear, the attack Leonardo Dicaprio. See, I don't know how that was done, but I mean, I, I, I had heard that that was all just pure CGI. Right. Then when there was a dude in a costume that acted it out with them. But, uh, essentially it was just all CGI. Yeah. Um, yeah. So that, so that the fact that that's beginning to look good, that's just, I mean, obviously that's just all surface that doesn't, has no implication for the um, you know, building a rendering of a bear on film is not the same thing as building a bear, but the fact that we can move so far into a building, I'm modeling that kind of complexity visually. Just imagine what a superintelligent, um, mind could do with a thousand years to, to work at it. Right? And that's, and that's we're on the cusp of. And when I say cuss, you know, I don't mean five years, but let's say a century we're on the cusp of a producing the kind

Speaker 1:          01:34:58       of technology that will allow for that. And if we put it into perspective photography, I don't believe was even invented until the early 18 hundreds when it was first. It says sounds about photographs of Lincoln. There are though. Yeah. So was that the early 18 hundreds when he was killed? I'm 18, sixties, five, 10, 65. So somewhere after that or somewhere before the other, they invented photography. So essentially give or take 10 years, 200 years ago. That's really amazing. Oh yeah. If you stop thinking about the revenue from 200 years ago, we couldn't figure out how to get sound in our movies until that 100 years ago. That thought right there just actually just freaked me out with a 200 year thought. Like how little 200 years is the hmong gold days and now 200 years ago they didn't even have cameras and now they do and now they have this insane ability to recreate things like game of thrones, wolves and dragons and she's riding around on dragon. I'm like, it looks like she's on a dragon. It doesn't look like old school King Kong movies, you know, you ever tried to watch those videos in. There are some pleasure in that. There are awesome. They're awesome too to to just get into for fun. But as far as like visual effects, what they can do now. And the idea that it's all been done over 200 years is just spectacular. Not just capturing the image, but then recreating an artificial version and projecting it, which is, you know, a thousand times more difficult. And there's

Speaker 2:          01:36:33       the other feature here of the compounding power of knowledge and technology were you. There are certain gains that are truly incremental, whereas just everything is hard. Won. Everything is just one percent better than its predecessor, but then there are other gains that, where it's just, you have created an ability that takes you, it seems like a kind of quantum leap beyond where you were and uh, where you go from just fundamentally not being able to, to do anything in that domain. And then all of a sudden the domain opens up totally. So know flight is an example, right? So for the longest time people couldn't fly and it was obvious that you can't fly or you're heavier than air and you're not, you don't have feathers and you're not. There's no way to flap your arms fast enough. We're never going to fly. Right? And then at a certain point flight as possible and opens this whole domain of innovation.

Speaker 2:          01:37:36       Uh, but the difference between not being able to flow in, there's no, there's no progress you can make on the ground that it doesn't, doesn't, uh, uh, avail itself of the, uh, the principles of flight as we now know them that's going to get you closer. You know, you can't jump a little bit higher and it's just not. And so there's, it doesn't matter what you do with your shoes. Uh, so there, there are, there are kind of fundamental gains that opened up a whole dna sequencing is, is a more recent example where understanding and having access to the genome and that's you go from, uh, the only way to influence the, your descendants is to basically make a good choice in wife, right, or husband to you can just create a new species in a test tube if you wanted to write and that, and that's a, um, that kind of a compounding power of, of, um, understanding the way things work.

Speaker 2:          01:38:42       Uh, the, you know, that that's, I think we're at the beginning of a process that could look very, very strange very, very quickly. And, um, you know, I think, uh, you know, obviously we were both in good and bad ways, but, um, there's, I don't think there's any brake to pull on this train. I even, knowledge and intelligence are the most valuable things we have, right? So we're going to, we're going to grab more in so far as we possibly can, as quickly as we can and the moments of us deciding not to know things and not to learn how to do things. I mean, those are so few and far between as to be almost impossible to reference, right? I mean that there are moments where people try to pull the brakes and say there's the whole conference and I say, you know, should we be doing any of this, but then, you know, China does it or, or threatens to do it. And um, we wind up finding some way to do it, uh, uh, that, that we consider ethical. Um, so there are things like, you know, germline tinkering that we, as far as I know don't do and have decided for good reason. We're not doing. But um, is that going to stop people from, from doing this? I don't, I don't think there's any way

Speaker 1:          01:40:02       they're more worried about actual real diseases than they are. Man Made Diseases. When we went to the CD CCS at disease control, CDC, CDC in Galveston, I guess that's what it is. It gets the name of the organization, but it's a building where they housed some of the most horrendous viruses and diseases known demand. Like they had anthrax in the CDC has, has a lot of that. Yeah. Yeah. And they have these crazy walls like thick thick walls and vacuums in the ceilings and everyone's wearing suits and they wanted us get in the suits and I went, fuck you. There's no way I'm going in that room. You did this for one of your shows for a TV show with Duncan Trussell, the questions, everything show because we were talking about weaponized diseases. And the CDC was like, forget all that. Like the real diseases that are constantly morphing.

Speaker 1:          01:40:55       We have to stay on top of like, that's what we should be terrified of actual real diseases. Like no one's shown any ability to create this stuff that's more fucked up than what we already have, but weaponized anthrax and things along those lines. Like these Russian guys we talked to, they were talking about how they had vats of this stuff. They had all kinds of crazy diseases that they had created just in case we had gotten into some insane mutually assured destruction, you know, a disease spreading thing like they were down for that. They were like, well, we have to be prepared in case to the United States. Does that. Whoa, but what their concern is the center for Disease Control's guys that they were concerned with. Things like Ebola, things morphing things becoming airborne, natural things, new strains of the flu that become impossible. Murcia mercy as a terrifying one. Mercy is one that has a lot of people scared. A lot of doctors. Scared. Yeah. It's a medication resistant. Staph infection that's kills people. I mean, it can. It can absolutely kill people if you don't jump on it quick and take the most potent antibiotics we have and even then it takes a long time.

Speaker 2:          01:42:03       Yeah, yeah. Well, it's a, um, I actually just tweeted this recently, I think I said well with some billionaire with some, you know, zero point one percent or develop some new antibiotics because clearly the government and the market can't figure out how to do it and it really is, it's falling through the cracks in the government market paradigm where it's like either the government will do it or the market will do it, but neither are doing it because the market can't. Bill can't generate the rationale for developing antibiotics because it's so costly and you take them, you know, what you take with any luck, you take them, you know, once every 10 years for 10 days. And that's it. I mean, it's not, it's not like Viagra or any of the antidepressant or any drug that you're going to take regularly for the rest of your life. And um, so there's no real market incentive to do it. And, or at least not enough of one to spend a billion dollars developing an antibiotic. And the government apparently is not doing it. And we're running out of antibiotics. And this has been in the news a lot recently, but we're close to being in a world where it's as though we don't have antibiotics, we're, we're, we're a superbug away from, from being in that world and

Speaker 1:          01:43:21       freaking me out. Sam Harris. Oh, I get freaked out. So it's super bugs are the big concern, right? Do you think about that in Jujitsu? Do I've gotten staff right? My friend Ari had it and we were playing pool and he was limping and I go, what's going on with your leg? Man? He goes, I got a spider bite. I go, let me say. It pulls up his pants. You've got staff, you've got to get a doctor. And he hasn't even done Jujitsu and years and I think he got staff again and I think it's one of those things where once I guess everyone has it on their body and when you get an infection then it spreads and grows and apparently it can be a reoccurring thing. So people who get it, particularly Murcia apparently they can get it again and it can, it can get pretty bad.

Speaker 1:          01:44:09       There was that one fighter who just died, I don't think related to that, but he had these. Kevin randleman random. Yeah, yeah, yeah. Had the men. He was that. That was mercer, right? A 100 percent. Yeah. Yeah. He was in the hospital. What was it was staff. I don't know if it was mercy, it could have been just staff that he ignored for long periods of time, but it was 100 percent staff and he died. I don't know what exactly was the cause of his death, but I can't think that that helped him any. I mean he had gotten so bad that it had eaten through his body. If you, if you're interested in us for people online that are listening, Google, Kevin Randleman staph infection and these are horrific photos that look like, like something took a bite out of him, like his under his arm pit.

Speaker 1:          01:44:57       There's, I mean I'm like a fist sized chunk of meat was missing. Yeah. Yeah. It's really, really scary stuff. Um, so yeah, skin infection. There it is right there. You could take a good look deep in see his muscle tissue. That is hardcore, no exaggeration, so was like a baseball sized hole and he's got two of them. He's got another one lower down on his back, which is eating its way through his body. But that was, that was a year before he died. Right? Or say some years. Yeah, it was years before he died. Um, but who knows, like how devastating that might've been. Like that's a really, really bad infection and I think that once your body's that compromise to me, you're like really close to. I mean he's a real. He was a really tough, strong, healthy guy. He was a super athlete so I'm assuming his body probably fought it off pretty well. So it's probably one of the reasons why you let it go so long. Probably didn't, maybe didn't even understand how dangerous it was or who knows. Maybe it just jumped on him really quick.

Speaker 4:          01:45:57       My Dad's girlfriend just got it on her face and she was in the hospital for two weeks and they were afraid it was going to spread to her brain and it almost did. And she's not 100 percent out of the woods yet, but she's back home now. It's just got a little scratch on her face and it spread into her cheek and then into heard from her cheek. She got a little red swelling and then she couldn't see. And then she had to go in the hospital. You got staff chill out. Heavy antibiotics right away.

Speaker 2:          01:46:22       Yeah, that's it. This is one area that this, this worries me. They were, I mean they're, they're the bad things we do. And obviously there's a lot to be worried about their, you know, the stupid wars and the, and the, uh, things that, it's just obvious that, that, um, you know, if we could stop creating needless pain for ourselves or needles conflict, you know, that would lead a much nicer life. But then there are the good things we neglect to do based on the fact that we just can't, we don't have a system where the incentives are aligned to just make it easy or, or, um, truly compelling to do them. And the idea that we are not producing the next generation of antibiotics as quickly as possible is just unthinkable to me. And yet, and yet we simply were just hamstrung by the fact that we have a political and economic system.

Speaker 2:          01:47:22       That is where the, this, there's no incentive, right? Like the government. We don't want to raise taxes, right? We don't, we're so over committed in the ways we spend money, uh, the public money, um, and we're so short sighted that we, even if we suddenly saved money in one area, it's not like we would immediately directed to this lifesaving necessary work, right? Um, and the market can't get on top of this. So it's, it really would, it would be like, you know, uh, something that, you know, the bill and Melinda Gates Foundation could do and maybe maybe they're actually doing this and I just don't know about it. They're doing a lot of medical work obviously. But, um, yeah, we're talking about some billions of dollars to just get this. You get kind of a laser focus on, on this problem. But it's such an obvious problem. And that's really the only thing that's holding it back.

Speaker 2:          01:48:17       That's what's going on. It's not a research issue, it's just a financial issue. Well, I'm sure that the research has to be done because it's, you know, if it was, if it was totally obvious how to build the next generation of antibiotics that would not be vulnerable to having their efficacy canceled, you know, in, in three years by just just the natural selection among the microbes, you know, someone would do it very, very cheaply. But, uh, so it's, uh, I'm, I'll admit that it, it's probably not easy to do, but it's got to be doable and it's super important to do. I mean, when you look at just what cesspools hospitals have become, where people come at, you know, something like 200,000 people a year die in the US based on essentially getting, been getting killed by the machinery of the hospital right there, getting killed by their doctors and nurses. Most of them, some of this is, is um, you know, drug overdoses or, or, or, um, kind of incompetence in, in dosing or given some of the wrong medication or whatever, you know, 200,000 people, 200,000 people a year. Right. But a lot of it is just doctors not washing their hands. Right. And, but some of this is also super bugs where it's like, it's, it's the burden on hand washing in a hospital is higher and higher because hospitals just or just covered in, in super germs, right? So it's a, a

Speaker 3:          01:49:52       cycle haunted house. You're trying to fix people and around the house or a bunch of demons that are trying to kill people you're trying to fix. I mean that if look, obviously it's not, but if you were a person who was inclined to believe things like back in the day before they figured out microscopes, I mean, what else is that other than a demon? You've got a hospital that's filled with super bugs. Where else are they? There's nowhere else in the hospitals and Jim were they getting them? Probably from the hospitals, but it's just like a haunted house circle. Hunter House is trying to kill the people that live in the house.

Speaker 2:          01:50:28       It is well, and it's also just ironic that you go to the hospital to save your life, right? You go when you are, by definition you're most vulnerable and you are a and you're in your lane, your body open to the intrusions of the place because that means they have to get. They have to get into your body to help you. Right, and yet that is the very mechanism whereby you're getting all this misery and death imposed on you and it's. It is as simple as hand washing though in many of these cases, right? It's just doctors and nurses not washing their hands. That is insane. It's so insane to think that that is a gigantic issue that we have these bugs that tried to get into your body and kill you is one. So that's one area. I don't know if you ever had the bad luck to be associated with a Nicu and neonatal Icu, but our first daughter who's totally fine was born five weeks early and had to be in the Nicu for a week and there are people who are in the Nicu for months, you know, the babies born at 23 weeks or so.

Speaker 2:          01:51:40       Um, and it's just, it's just a totally heroin. But, um, but also just these incredibly compassionate, just amazing places where you just doctors, nurses or our total heroes, but that's a space where you see the hand washing protocol just exactly as it needs to be. You know, like people are, they just have, have understood, you know, finally that you, if you're going to go into the Nicu and see your baby or be around anyone else's baby and you are going to wash your hands in as complete way as, as, um, 21st century science. Understand how to do that. And it's um, you know, it is. It's almost like the decontamination zone of, you know, Silkwood the nuclear reactor or she get hosed down. Um, but it's, uh, yeah, it's uh, my hand washing and the fact that we can't even do that perfectly. It's pretty impressive.

Speaker 3:          01:52:39       Now, is it a fact that mercer was created by medications or is that a belief or has that been proven

Speaker 2:          01:52:46       that it was created by a resistance to medications? It gets stronger? Yeah. Well, no. Yes, it's a fact that all of these bugs are evolving and just by dent of happenstance, they are producing a changes in their genome that leaves them no longer vulnerable to antibiotic X. Right. Um, so whether it's methicillin or, or any of it's related antibiotics, and so that, this is what antibiotic resistance is. These, these, these bacteria, um, uh, their genomes mutate and unfortunately with bacteria they also can swap jeans let laterally across bacterial species. So it's not like only their descendants in that line can inherit that, these genetic changes they can, they can transfer genetic changes across bacteria. So it just, it optimizes the process. And again, this is all blind. It's not like bacteria want to become drug resistant, but some percentage of them in any generation will tend to become in some generation, will become drug resistant and then that, then then in the presence of the drug, they will be selected for, you know, if you keep bombarding people with penicillin, you will be selecting for the bacteria that isn't sensitive to penicillin in those people and say the overuse of antibiotics and the overuse of antibiotics in our food chain is also part of this picture.

Speaker 2:          01:54:27       Right? So it's the fact that we are, I don't know what the percentage is, but it's, it's more antibiotic use certainly in cattle and pigs than in, uh, people. Um, and the same evolutionary principles are happening there too. So, you know, so you don't know what, what we're doing to ourselves. I, it can't be good to be using antibiotics everywhere in agriculture. And then kind of waiting to see what happens. Well, we know for a fact that we get diseases mean swine flu, avian flu like Josie, no viruses. Yeah. Yeah. And a lot of these are coming out of these facilities where they're processing cattle, pigs, I mean, that's another element to it. So it's just that most of infectious disease over the ages has been born of proximity to animals and that's the result of agriculture. So the fact that you have people in bird markets in China who, you know, they're, they're dealing with with chickens and ducks endlessly in confinement, and then you've got, you know, wild birds flying overhead, dropping their droppings into that space and you have, you just, and you have a viruses that jump species from, from birds to pigs and back again.

Speaker 2:          01:55:53       And uh, you know, some of the stuff only stays in those animals and, and doesn't become active and people. But again, it's just, it's just like, is this evolution is just this endless lottery, we'll where it's just, you just got change and change and change upon change and um, something makes the jump in this case between species and thrives or not based on the opportunities to thrive. So you have something that becomes airborne, right? You have, you have a, a, um, a virus that is absolutely deadly and people but isn't airborne and is difficult to contract, right? Well, then it's a, it's a fairly well behaved, you know, it could be scary, but it's not going to become a global pandemic, but then suddenly you could get a mutation on that virus or that bacteria that allows it to be, you know, aspirated in, become airborne and a cough and hailed and big and spread that way.

Speaker 2:          01:56:57       Well then you have this, this, um, you know, the possibility of a pandemic and um, and also the time course of an illness is, is irrelevant. So you have, you have something which kills you very quickly and horribly. Well then that's, that's the kind of thing that is going to be harder to spread because people become suddenly so sick. They don't, they're not getting on airplanes, they're not going to conferences, they're not starting new relationships. They're, they're in bed dying, right? So, but if you had something that had a time course that you felt great for a month, but you're yet your infectious, uh, and then it kills you will then, then it's spread is only limited by the damage you can do in that month of gallivanting around. Right? You know, so, um, it's a, um, and again, these mutations are just happening spontaneously. So it's, it's a, it really is a, um, it's a matter of good and bad luck. They all have one function. What killed things they do, our, they overcome, they overcome bodies with their life form. They spread. Will there have met their other functions. I mean, obviously this is all blind and there was no intention or purpose behind it, but there are viruses and other infectious diseases that produce penicillin know that. But the produce functions which, which are behaviorally relevant. I mean, so that there was a spread and forgotten is it? Um, so toxoplasmosis it makes mice less fearful and the presence of cats. Yeah.

Speaker 1:          01:58:42       Yeah. So, so like say the behavioral changes that makes them attracted to urine, right? They get erect right around cat urine. So he's into their demise, so it spreads to cats and there are theses that that either

Speaker 2:          01:58:55       infectious diseases that change human behavior that, you know, the depression is the result of infectious illness that we're not aware of or um, um, yeah, I mean, so there's a lot that could be going wrong with us that we haven't attributed to viruses and bacteria, which in fact are, is at bottom a matter of a virus, viruses and bacteria. Actually, Alzheimer's is, there was recently a report that suggested that Alzheimer's is the result of a brain's immune response to infection, infectious illness, um, uh, I think it was bacterial, um, this is just in the last week or so that the, um, the plaques associated with Alzheimer's that you see throughout the brain might in fact be the remnants of an immune response to some something having invaded the cross, the blood brain barrier. Um, so yeah, so if Alzheimer's is the result of infectious disease and that, that is a score that as a, um, as a, uh, a major problem that would be nice to solve with the right antibiotic regime.

Speaker 1:          02:00:18       Could you imagine? I mean, that would have been fascinated if that existed during Reagan's time. I think it just clear them up because you remember when he will, like when when someone publicly starts to go like that and it's a, a guy like Ronald Reagan who was an actor and a president and you see him starting to lose his grip on his memory. You knew, you hear all the reports about it that it's a particularly disturbing because it's exhibited, it means that's the head guy, you know, to think that that was just a disease. That's crazy.

Speaker 2:          02:00:49       Yeah. Yeah. I don't remember when that became at all obvious. I remember. I, I know people were trying to do a kind of a retrospective analysis of it, but I don't remember when anyone started to talk about the possibility that he was not all there and I don't remember it happening actually during his presidency, but know

Speaker 1:          02:01:14       you were both young at that point. So, um, I do remember comedians doing jokes about it. Yeah. That's like one of my main points of references or we'll. They did have this like weird sort of out of it grandpa type character that they would do towards his second run, you know? Right. I don't know if that was years before they were referencing like when, when was it all going bad them? Yeah. I mean neurologists are very neurologist can spot neurological illness really well. I mean they, they, they are walking around seeing neurological illness all over the place. I'm sure there were neurologists who were talking about him long before anyone else was in those terms. Well, there was this old joke that Jimmy tingled did. Timmy tingles hilarious political comedian from Boston. He had this joke about a Ronald Reagan's trial where he couldn't remember if he sold arms to Iran.

Speaker 1:          02:02:11       It was Mr to President next time you sell ams to Iran, jotted down, make a note, put it on the refrigerator, but it was just. That was his. That was his excuse when he was in trial and everybody thought that this is bullshit. This is his defense. He doesn't remember, and then it started coming out that he had. And then the conspiracy theory was he was always fine. He was like, was that guy's name Vincent the Chin Gigante who'd walk around in a bathrobe and pretend to be crazy. I remember that guy, the mob guy. No, there's a famous mob guy who was running the mob but pretending to be a crazy old man. So he would walk around with people. I forget how they busted him, but he had it nailed. He'd walked around the bath robe and talk to himself and he will put on an act like going on the street and act like a crazy person.

Speaker 1:          02:03:01       And then he would go on walks with like these capos and tell them, look, kill this fucking guy and get me a million bucks and all that kind of crazy shit. But all the while he had an world wire. Some somehow or another they caught him. I don't remember exactly how they caught them, but everyone knew like they kind of knew he was doing that. And so some people were thinking that's what Reagan was doing. It was getting closer. I don't remember what I did, what I ran in a matter of fact, I don't remember shit. I can't think I got a disease. I can't remember anything and just started pretending was. It could be both. Could be true. I mean he could only clearly did have Alzheimer's in the end, but he could have also been lying. What if it was a big conspiracy? There'll be a great movie like how good of an actor was Ronald Reagan who was such a good actor to the latter days of his years.

Speaker 1:          02:03:42       You've avoided interviews by pretending to have Alzheimer's. He felt like that was the only way out, so it just. Him and Nancy, they prepped her lines and when, when you know he'd go out there to the public, he just started acting like he couldn't remember anything. Alzheimer's. Unfortunately it's going to be a bigger and bigger story. It's really a baby boomer moment is coming and it's just going to. This is something we need a full court press on to. Yeah. If you can find that that's actually a disease and you can cure that disease. That's a disease and infectious disease. Well, the, if you ever seen the support stuff on the Toxoplasma Robertson Stanford, he's the guy that's like one of the four forefront researchers and one of the guys is like really vocal about stress and. But he, yeah, they were also talking about a direct proportionate, a direct relationship between motorcycle crashes and testing positive for toxoplasmosis and they felt, they felt that it might've either hindered reaction time or loosened inhibitions to same way it sort of triggers these mice to go near cats.

Speaker 1:          02:04:51       Yeah, yeah, yeah. That's what I was referencing. Yeah. So I think it's a lot of, it's speculation, but there's a lot of strong court. There's a strong correlation apparently to motorcycle crashes and that is, I guess one of his professors had told him that when he was younger and he remembered it while they were dealing with some guy who came into the er victim of motorcycle crash, but it kind of makes sense. Yeah. Well, you know, the underlying biology of risk avoidance and, and not risk seeking is, that's fairly well conserved in mammals. It's not like there's a reason why we do most of our research in things like mice. I mean, it's not a totally analogous brain, but it's are similar enough to us that, you know, doing research on dopamine receptors in mice is, allows us to extrapolate to humans and um, yeah, so it's a um, uh, it's not, it wouldn't be a surprise that it's having an effect on people.

Speaker 1:          02:06:00       Was it Steve? Remember I was supposed to bring this up to you before? Um, when you were talking about, um, plants and plants having some sort of a consciousness, was it steven pinker see if you could find this? Who gave a speech where he talked about how some plants you can actually use sedatives on them and that some of them actually produced certain neurochemicals like dopamine, if that makes any sense that Steven pinker. No, it didn't make any sense. Right? Well, it was surprised me if pinker said anything about this, but I haven't heard anything about it. I think it was a speech he was given about something, but I think it's controversial. It's one of the reasons why I wanted to bring it up to you because I had never heard that before that a plant can produce. It was either dopamine or Serotonin in that somehow or another sedatives would be, would be effective on a plant.

Speaker 1:          02:06:53       I tell it didn't make any sense. I don't know what effective means. Uh, I don't know either. That's why I waited for you have a plant that's pretty. Well, it's a dated as far as I'm concerned. I remember as soon as I saw this, I'm like, must get this to Sam Harris, please decipher. But I actually. Everything I almost everything I remember about or that I learned about plant biology I've forgotten. So I don't know, but I'm pretty sure if you can't find it does not have a brain stuff for Steven pinker and in plants and consciousness, but nothing with sedatives specifically coming up with that. Maybe it was two. Maybe I can come. What's the combined two different articles they made? Did the pink one? I know it was. What did what pinker say about

Speaker 3:          02:07:36       plants and consciousness? Oh, he was just talking about the surprising amount of calculations. I think that was one of the, uh, we'd have to read the entire piece, but I think it was just, they were just highlighting what we know so far I've reached the limits of the human bladder. Oh, how dare you this early. You're too healthy, man. Coffee and water. So what have you found on it, Jamie?

Speaker 4:          02:07:57       Not really, nothing specific about it, but I did have something earlier that was kind of interesting. I'll show it to you here when you was talking about Ai. I put up something on minority report and that pulled me to this article, which Microsoft has an app that can, it's actually developed by Hitachi. It's called predictive crime and that analytics, um, they can predict crimes up to 91 percent accuracy. And then there's also already being enacted at Maryland and Pennsylvania as of 2013. They have crime prediction software that can find out if an inmate that's going to be released is going to predict or committed another crime. And so they're using that to follow them. And there's some civil rights people that are saying like, you can't do that. Obviously that's not good.

Speaker 3:          02:08:46       Hold on, scroll down just a little bit. What is it? Professor Burke says his algorithm could be used to help set bail amounts and also decides sentences in the future.

Speaker 4:          02:08:56       And then I got down to this part in Chicago. They're doing something and they have it. It's called a heat list in Chicago. They have 400 residents that are listed as potential victims and subjects with the greatest propensity of violence and they go and knock on their door and tell them that they're being watched. And I like I've clicked on this thing and it's an actual like Chicago directive from the police.org. It's a pilot program about going and tell people that are being watched for someone might be after you or some shit like that out. It's really crazy. I didn't want to interrupt you guys to tell you about this, but

Speaker 3:          02:09:29       custom notification under the violence reduction initiative in partnership with the John Jay College of criminal justice community team who will serve as outreach partners when the social service and community partners show show him this. This is crazy. While the while we were doing this, Microsoft has this, these programs scroll up to the top Jamie. They revealed an application they think that can predict crimes in the future and decide if inmates get parole.

Speaker 4:          02:10:01       It uses all sorts of data, public data from twitter, a closed circuit camera feeds, public Wifi signals. There's like an la. There's all sorts of microphones all over the place listening for gunshots and whatnot. There's this New Light Poles I told you about that are adding four g connectivity to the city that obviously can be added to this probably if they needed it.

Speaker 3:          02:10:22       Sure. Yeah. That doesn't surprise me at all. I mean, I think, I think that is a, um, all of that's come in. I mean it would just look at just consumer behavior. We just just look at how someone

Speaker 2:          02:10:34       can understand about you based on your zip code and your last three Netflix movies you watch to the end and it just a few other data points, right? And then we basically know we can predict, you know, with some horrendous accuracy what you're going to like a given, you know, the menu of options. I mean, we can advertise to you, uh, with, with immense precision. I'm in facebook, obviously is, is at the forefront of this, but uh, when you talk about, when you add everything else that's coming more and more intrusive technology of the sort we've been talking about, it's, you know, none of that surprising, right?

Speaker 1:          02:11:18       Nothing surprising anymore. If you had read that 30 years ago, it would have looked like an article in the onion here, right? You'd be like, what they're going to have. This is judge dredd. This is crazy. Here's the onion version, which did just happen, right? I think this was Microsoft where they put out a, what they were calling an Ai Bot on twitter. There was a ai that just became a Hitler loving sex spot because it was being turned up by its interaction with people trolling on twitter. Did you see the guy who got arrested for falling asleep inside his tesla when it was on auto drive? No. No, no, no. He got busted. I don't know if he got arrested. He got busted though. They have cameras. Have camera photos of him rolling through an intersection, completely unconscious on his way to work. Look at this guy. Look, look at this. The car is driving him and he's asleep while it's on autopilot. This is insanity. This is going to be okay.

Speaker 2:          02:12:15       Great moment to see. And I'm sure this is coming where a one self driving cars become just obviously the only truly safe alternative. Then you'll be arrested for the opposite violation. You'll be, you'll be arrested. W if your hands are on the wheel, if you're driving a car that is this ape piloted as opposed to a robot driven. And that's that say, um, maybe we got 30,000 people a year dying every year based on ape driving. Um, so the moment we crack that, which we're very close to doing, um, it's just going to seem you're, I mean, you've, you've got your old muscle cars or whatever you're into, it's going to be like, that's going to be the equivalent of like, you know, celebrate Tory gunfire. You're going to reserve the right to like at, at your wedding

Speaker 1:          02:13:10       shoot, shoot your ar 15 and the air and not care where the bullet lands going to have to get a licensed, operate them. You're going to have to move out of the big city. You get to take them to the hills and unload the amount of, uh, of the back of a truck driving for a very short distance as right monitor how much a governor on them that they can go five miles an hour. Yeah, yeah. I mean if you look at, in terms of safety for sure. And then it seems to be the thing that's the reoccurring theme, right? You give up your privacy for safety. He, you give up your, your ability to drive a car wherever you want, whenever you want, however you want to give that up to give that up for safety and uh, people are really reluctant to give up fun shit like lying and driving their car fast.

Speaker 1:          02:13:59       Like those two things. People are going to have a hard time with you, like actually getting into the, into their mind, seeing their actual mind and being able to do that so we can know without a doubt whether or not someone's guilty or innocent. But my question to you is if you could get inside someone's mind and it was like that really super. I'm a suggestive guy that you were talking about earlier that just confessed all the horrific demonic possession stuff and eating babies. What if it's like getting to that guy's mind? What if you can't tell?

Speaker 2:          02:14:30       Well, the case that, that worries me, and this is perhaps an inept segue to a politics, but the, um, I mean we're in people's minds. You get someone talking long enough, you know their minds. I mean, they, they, they can only conceal what they're about. A only so well right, and you can because you're a super smart wizard type. Just Jamie, I don't know about. I don't know if he's a mind reader, but the question is what will people care? You know? It's like if you, if you have, we don't even need a lie detector. If you have someone who's openly line right, who, who just gets caught in lies again and again, you could see it too. You feel it right, but people don't seem to care in the least in a political process. Now I'm thinking in this case of trump where you have someone who is in in some cases line or just changing his mind in such an incoherent way that it's the functional equivalent of line.

Speaker 2:          02:15:36       I mean someone who becomes totally unpredictable. He has a stance that is a on Tuesday and it'll be on Wednesday and when the discrepancy is pointed out, he tells her to go fuck yourself. Right? So it's just. No, there is no accountability to his, his own states of consciousness that he's going to be held to. And the people who love him don't seem to care. They actually in it, as far as I can tell, I don't know so many of these people personally, but from based on, you know, social media and seeing the few articles where someone has explained why they love trump. People view this as a kind of this sort of this dishonesty what is on, in my view, both dishonesty and a kind of a kind of theatrical hucksterism of person who's, who's pretending to be many things that he probably isn't.

Speaker 2:          02:16:32       They see it as a new kind of authenticity, right? Like this guy, he's just letting it rip. He doesn't care what is, what is true. He doesn't care what your expectations for coherence are. He's just going to tell you to fuck yourself every which way. And this is the new way of being honest, right? This is a new form of integrity. It's amazing to watch. It's getting has been. I'm someone who actually, I remember on my own podcast, I think I was talking to Paul Bloom, this gal psychologist, who's, who's great and we had taught. We got into politics and this is at least a year ago, but at that point I said there's no way we're going to be talking about trump and a year. I mean, this is kind of completely flame out and I was, this is a, I don't tend to make predictions, but this was a clear moment that I remember making a prediction, which is now obviously false. Um, but I just couldn't imagine it, that this was this when people were going to find this compelling enough to, for, for him to be on the, on the cusp of getting elected. It's, it is terrifying. Have you talked, have you talked to this issue to death on your podcast? Or. I guess we kind of have. Well, I think this is how everybody feels.

Speaker 3:          02:17:40       Everybody feels like you're supposed to be like with their person, whether it's Bernie or whether it's for Hillary or whether you're a trump supporter or whatever it is. Like you have to be all in. But like if you look at the choices that we're given, the. None of these kids really be described as ideal. Like Hillary Clinton. You could want a woman in the White House and you want to, you want to show everyone that a woman can do that job just as well as a man and she's got the most experienced and she certainly has the most experience dealing with foreign governments and she certainly has the most experience in politics, can make an easy a, but she's also involved in to criminal investigations. She had an observer in her bathroom. This is squirrely stuff going on like, no, she's. She's terrible in. Anyways, she was gay marriage, Oh, 2013 and then wouldn't admit the change of mind either.

Speaker 3:          02:18:31       She's a politician, she's probably a brilliant woman, but she's also set in her ways and a politician, a politician to the end and part of being a politician is being a fucking huckster. You got to be able to get those people to see your side and the way you do that is to talk like this. You can't talk like a normal person needs a speech coach. They all do. He's terrible to. Trump's not even good at it and he kicks their asses. I know, but who knows, but her voice or she, she has a kind of to use the sexist trope. She has a

Speaker 2:          02:19:04       real for when you were, when you get her in front of a mic and there's a crowd and she thinks she's talking over the crowd, which she doesn't have to do because she's in front of a mic. The sound you get is just, it's, it's, she's yelling when she doesn't need to yell at someone. Someone has to teach her how to dial that back.

Speaker 3:          02:19:21       What you just did is called mansplaining. I'm explaining to the men in her who should, who should

Speaker 2:          02:19:28       talk some sense into her, but she is, she's a, she's a bad candidate, right? I have no doubt that she's very smart and she is well informed and she's qualified and she is absolutely who I will vote for given the choices. But you know, I totally understand people's reservations with her. She's a liar. She's an opportunist. She's just almost preternaturally and authentic. I mean, she's just like, she will just focus group every third sentence and you feel that from her. Right? And, and this is all true, and yet I also believe that people who say I've never met her, but people who know her and have met her say behind closed doors, you know, one on one, she's incredibly impressive and great. Um, but that doesn't translate into her candidacy. She probably thinks she has to do it. Old School, you know, I mean, the way she's doing it, but she, I mean, the thing is, she's, when you look at the, what's worked, what worries me?

Speaker 2:          02:20:26       So I went on facebook the other day and I, I've said very little about this, but I've made enough noise is of the sort that I just made, that people understand that I've, that I'm for Clinton, despite all my reservations about her. Um, and when I got on my own facebook page, which you have to assume is filtered by the people who are following me on facebook. And I already liked me in some sense, just like a thousand comments of pure pain. I mean, no one loves hillary. No one, no one said, oh, thank God someone's someone smart is for Hillary. Um, it was all just Bernie people and trump people flaming me for, for, for the most tepid possible endorsement of Clinton. All I said was, listen, I understand Clinton's a liar and she's, and she's an opportunist and she's, um, I, I completely get your reservations about her, but at least she's a grownup, right?

Speaker 2:          02:21:22       And she's going to be the candidate. It's not going to be sanders for the moment. Now is the moment to put your political idealism behind you. If you're a sanders person and recognize that there's a vast difference between Clinton and trump and no itch. No, she's not going to change the system, but he's also not going to run civilization off a cliff. Right? And I didn't, I forget how I said it on facebook, but it was just the most, it was just, it really was a lesser of two evils argument. And it just, it was, um, it's amazing to see how energized and passionate people are in defensive trump and sanders. And there's almost none of that for Clinton. It's like people are just sheepishly saying that they just divulging that they will vote for Clinton, but they are may. Maybe somewhere that I haven't noticed. Someone loves absolutely loves Clinton, but it's just, it's. She does not have her defenders the way these guys do. Have you seen the man enough to vote for her campaign? No. No. It's with like hipster dudes with tattoos and beards that are going to vote for Hillary. No, I hope it's fake

Speaker 1:          02:22:26       because it's so brilliant. I hope it's not real. Is it fake? Is it God? It's so good though because it's not that fake. It's pretty good. Like you could almost see. So wait a minute. I mean this is not for her, right? This is. No, no, no. It's not bad for just funny. If someone would like make a joke, political ad, you know that you have to be man enough to vote for Hillary was like, there's guys out there that would buy that. They would. They would, they'd do it. It's a scary time because it doesn't seem like anybody that you would want to be president wants to be president and so we're left with, all right, what do you pick? It's like as if we're going to play the super bowl with three of the shittiest teams we can find. We're just going to go get some drunk high school kids, get some inmates with club feet, which is going to throw whoever we're going to have the worst game ever and this was what this game is. It's not a good game. This is not a game where you've got like a John F Kennedy versus a Lyndon Johnson or it's not. It's not like like powerful characters. It's trump I guess is a really powerful character, but in more ways like a showman character, like what what he's doing. He's like, he's putting on a great show and he's going to win probably because he's putting on such a great show and people like a great show, but I do think. I think

Speaker 2:          02:23:57       I'm now have among the people who think something new witnessed were witnessing something new with trump. It's not just the same old thing where the process is so onerous that it's selecting for the kind of narcissist or thick skin person who is willing to submit to the process. And then there are many, most of the good people just aren't going to put up with this. I mean, yes, there's that too. But there's, um, there's something, there's a, it's a moment among the electorate where it's like, it's fun. It's an antistatic. There's an ant, there's enough of an antiestablishment mood and vote now is it happening with, with sanders to where people just want to jam a stick in the wheel of the system just to see what happens. So it's like, well, this is the main gripe against Hillary really is that she is politics as usual.

Speaker 2:          02:24:59       She's not going to change the system, right? People want to change the system, but they're not really thinking about the implications of radically changing the system. And in the case of trump, um, I may hear or someone who is, who was advertising his lack of qualifications for the office in every way that he can. It's like he, like, there is no, I mean, I'm not even, I'm not even bothered by his racism or his misogyny or his demagoguery or his bully. I mean, all of that I'm willing to to guess is an act right. That he's decided that that's somehow pandering his base and he's actually, in truth, he doesn't have a racist bone in his body. Say I'm willing to, to believe that amount. I don't know why I would think that's plausible, but it's, it's, it's, uh, you know, I have a hunch that he's far more liberal than he seems and it's just pandering.

Speaker 2:          02:25:55       But the thing that, that, um, can't be true is there's no way he's actually brilliant and well informed about all the issues and is saying the things he's saying. He's not pretending to be as uninformed and as incoherent and as irresponsible as he's seeming. Um, because you wouldn't withhold information. It will make you a better leader. Well, it's just, it's. Yeah. And it's just, well, it's just the vacuous snus of his speech. It's like he's, he'll say that he'll say the same thing three times in a row. And it was meaningless the first time, right? He'll say, it's going to be amazing. It's going to be very, very amazing. Trust me, it's going to be so amazing. And he does. He does this with everything. If you look at the transcripts of his speeches and the fact that he can't, he has never met so far as I've seen.

Speaker 2:          02:26:48       He has never once strung together a string of sentences that was even interesting. Right? But he'd be like, he's, he's never. He just, there's never a moment where I read or I say, Oh, this guy is smarter and better informed than I realized at that moment. Never comes where I keep expecting to see that happen. Um, and it's a little bit like my head is this image of like imagine you have an urn, right? And you just keep pulling things out of it and all you pull out of it as junk, right. You know, you pull, you know, chicken bones and broken marbles and gum and, and it's, it's still possible that you, that if you root around in that earn long enough, you're going to find the hope diamond. I mean, in each round that you pull something out that really has no logical implication for the next thing you might pull out of the earn, but mines aren't like that when I see what this guy says, he does not say anything that a well informed, intelligent person would say.

Speaker 2:          02:27:49       And it's just. And, and ideas are connected, right? It's like you can't, um, you can't fake this stuff. You can't fake, you can't fake being this, this uninformed and you can't fake being really well informed and he's just, I mean, we just look at one policy that he wants a, the, the um, uh, you know, the rounding up of illegal aliens, right around 11 million illegal aliens. Now this, this gets stated as, yeah, we're going to round them up and send them back to Mexico. And what worries me is no one seems to care about that. If you just look at the implications of doing this, it has this one policy. Claim alone is so impractical and unethical. It's just, what are we talking about here? You're talking like your gardener, your housekeeper or the person who works at the carwash. The person who picks the vegetables that you buy in the market is going to get a knock on the door in the middle of the night by the Gestapo and get sent back to.

Speaker 2:          02:28:49       The vast majority of these people are, are, are law abiding. People are just working at jobs that Americans by and large don't want to do. And many of them have kids who were American citizens, right? And somebody to say someone's got kids under the age of 10 who are American citizens and what you're going to send that person back to Mexico and you're going to do this by the hundreds of thousands and millions. It's just that one point alone held in isolation from all of the other things he said. The crazy things like climate change is a hoax concocted by the Chinese to destroy our manufacturing base. And, um, you know, the, the fact that he likes Putin, I mean, everything else he said, write this one policy. Claim alone should be enough to disqualify a person's candidacy. It's so crazy with the moment you, you look at it, um, and yet no one seems to care.

Speaker 2:          02:29:41       In fact, it's just, it's just more energizing to the people who already like it. I know that he said that he wanted to build a wall, but I didn't know that said that he wanted to get rid of the illegal aliens, round them up and around them up and do one with them, send them back to their country. It's so crazy. It's such a crazy idea and it's so brutal. The idea that. I mean, it's like a, it's a sub human thing. The only reason why people would come to America is because they felt they felt like it would make their life better. So people take a big risk. It's not, there's not an easy way to do it. If you're poor, you don't have any qualifications for any unusual job. I mean you're trying to get across to Mexico, but everybody who does it does it because they want to improve their life.

Speaker 2:          02:30:22       You know, and the idea that one group of people shouldn't be able to do it in one group should just because they were born on the right side of some strange line that is only a couple hundred years old, but I actually, no, I'll go further in meeting him in the middle. Whereas. So, so I think we should be able to defend our borders. Right? So it is. I don't have a good argument for having a porous border that we can't figure out how to defend and we don't know who's coming into the country. Right. So, so I think building the wall is almost certainly a stupid idea among his many stupid ideas, but I think it would be great to know who's coming into the country and have a, a purely legal process by which that happened. I mean, ultimately that's got to be the goal, right? Um, and we are in perfectly doing that.

Speaker 2:          02:31:09       And um, so I don't have an argument for open borders or porous borders, but the question is what do you do with 11 or 12 million people who are already doing jobs we want them to do that help our society and the vast majority of them are law abiding people who as you say, or just trying to have better lives, the idea that you're going to break up families and send people back by the millions and the idea that you're going to devote your law enforcement resources to doing this when you have real terrorism and real crime to, to, to deal with is just pure insanity. Right? And, and also totally unethical and yet he doesn't get any points docked for this aspiration. I mean, it's just, it's one of the things around which people are rallying. But the climate change thing is also insane and dangerous.

Speaker 2:          02:32:03       He was a birther, right? Yeah, right. He was one of the original birthers. He was saying that Obama's birth certificate was bullshit and he was born in Kenya, right? Wasn't he one of those guys? Oh yeah, he was, he was. Um, I would love it if funding that for awhile. Yeah, I would love to if he got in the office and just said, listen folks, I am nothing like this person. I pretended to be to win the presidency. I just wanted to show you that you can be manipulated and get it together. Then peaches, punk to all going to hire some people who actually know how to run things and we'll see. That's the, the, the smart people who are voting for him think. And this is, I think an actual, a crazy position. But they think that he is just pandering to the idiots who he needs to pander to to get into office.

Speaker 2:          02:32:53       So He's, he's not disavowing the white supremacists votes with the, the Alacrity that you would if you were a decent human being and you found out that David Dukes who supported you, um, uh, because he needs to. He just, he needs those votes and he knows that, that most of the people in his base aren't going to care and he can just kind of move on in the news cycle. And he's doing this on all these issues. Where he looked, where smart people see that he looks like a buffoon and, and, and they are treating him as a, the people who don't like him or treating him as a comic figure who he can't really believe that stuff. He's not really, he's too sophisticated to really believe that stuff. So He's just pandering. Um, I mean, one is that people aren't seeing if that's true, just how unethical and weird that is right here.

Speaker 2:          02:33:45       The guy has no compunction about lying and demonizing people. It's like, well, let's say he, let's say he thinks that that Clinton really isn't guilty, but Bill Clinton isn't really guilty of, of a rape. Right? And now he's calling him a rapist. Right now, at the time he was saying he wasn't a rapist and he's just being defamed. And this is outrageous. He was taking, he was taking the side of a friend who, you know, he invited to his wedding, but now he's, he's calling him a rapist, right? A sexual Predator who's, who've harmed women's rights more than anyone. I'm so, which is true, right? So there's, there's no version of the truth here that makes trump look at all acceptable as a person. It's like either he knew he was a rapist and was defending him because he was just cozying up to power at that point, right.

Speaker 2:          02:34:31       Didn't care that he's a rapist or now he, he knows he still, he's still the guy who thinks he wasn't a rapist, but now he's just for purely opportunistic reasons. He's, he's, he's willing to call a guy a rapist who he knows isn't, um, they're both horrible. Right? And it's not like there's new evidence has come forward in the intervening years that would have changed his mind about what happened in, in Clinton's presidency. So he's um, uh, but I think people think that he's got to be much more sophisticated than he is and that if he got into office, he would just be a totally sober and presidential person. There's just no reason to believe that. I mean that if he thinks climate change is a hoax and that we should pull out of the Paris accord, then we should ramp up coal production and when to bring back the coal jobs. I mean, this is what he's saying, right? There is no reason to think he doesn't believe this at this point. Um, that's just, it is a disastrous thing for a president to think. The only, um,

Speaker 3:          02:35:38       fascinating versions of this that I've been hearing from people that I respect are that the idea that he is like, uh, the political version of the asteroid that killed the dinosaurs. Like he's going to come down and smash it and it's going to be so chaotic that they're going to be forced to reform the system and people are going to respond in turn, like the way people responding against factory farming and more people are going Vegan, like that kind of thing. They're going to see it and they get to respond in turn that has such a. So it's like he's going to toss the applecart up in the air. It's just going to fuck this whole goofy system up. And then we'll be able to rebuild after trump has dismantled all the, all the different special interest groups and lobbyists and all the people that we really would like to get out of the system.

Speaker 3:          02:36:21       We really don't like the. The. The fact that they're such insane amounts of influence that big corporations and lobbyists have had on the way. Laws get passed that. This might be the way to do it. You have some wild man. Everyone's fired. You have fired. You have fire Jetson. It's like a character. Like he's coming in. His hair's plastic is all fired up. He's a billionaire. He made all his own money, sort of. Dad gave him some money, but he turned it into a lot of money. Point being, he doesn't need anybody to. My truth is he's probably lying about the amount of money has to. Is He is, but he's a baller for sure though, right? At the very least, he's got to be worth some cash. Yeah. I made. It could be a big difference between what he's claiming and what is in fact true.

Speaker 2:          02:37:01       But he's. He's a many pieces here. When people assume that because he's a successful businessman, he must understand the economy, right? Which is no necessary connection there, right? There's a lot of rich who are totally confused about economics. Um, and uh, you know, most economists don't have a lot of money, so there's no real connection there. But the,

Speaker 5:          02:37:25       the uh,

Speaker 2:          02:37:28       I mean, so what you're describing is a kind of just random, like, like you're just, let's just, let's just smash the window and then see what happens. Right? Like I'm going to light a fire to this place and see what happens. And that's, um,

Speaker 2:          02:37:45       it almost any process by which you would change the system is more intelligent than that, you know, and, and it's also not value in how much harm one bad president could do, right? Like, there's no, I think even, I haven't tested this, but I'm imagining that even trump supporters would answer this question the way I would hope, which is like if I had a crystal ball that could tell you, I can't tell you who's going to be president, but it tells you how it works out for the next president. So like if I, if I look in the crystal ball and it says the next president of United States is a disaster, right? Just, it's like the worst president we've ever had. You just think of, you know, just just failures of governance and, and the toxic influence of narcissism and Hubris that comes along just like once every thousand years.

Speaker 2:          02:38:37       Right? Just, just disaster. I think, you know, even if you're a trump supporter, which candidate that was like only trump is, is likely to screw things up that badly. It's not a Clinton is going to, is going to be almost perfectly predictable. She's going to be a politician. She's going to, she's going to be basically centrist on a lot of the, on foreign policy and domestic policy. You know, she's going to be liberal on social issues. Um, she is not going to try to dismantle NATO and to get into a war with North Korea or get into an alliance with Putin or image. She's not going to do something insane. Um, and so alliance with Putin. Yeah, he, he said basically only favorable things about Putin. They're homeless, they're tight. So she get get, uh, hopefully we'll, we'll see pictures with both of them on horseback, shirtless and a golf shirt on. He'll probably keep my shirt on. I don't see them as being the shirtless guy. I know. Yeah.

Speaker 2:          02:39:49       When, when you just look at the landscape between Bernie and Hillary in him and uh, you know, to me it looks like the last gasps of a dying system. So that's representative government system for a lot of people are saying that things like that, but they're not hearing just nihilistic. That is if. True. Right, right. It's like, oh, well we, there's so much stuff we have to get right. And there's so much. And the only tool to get it right is, is having your, your mind actually understand what's going on in the world and how to manipulate the world in the direction you want it to go. So you have to understand like what, whether or not climate change is true, your beliefs about it have to be representative of that truth. Right? So like, if let's say, you know, let's say it's, let's say I'm mistaken and there's, you know, there is no human caused climate change is not a problem and every moment spent thinking about it, worrying about it, correcting for it is just a waste of time.

Speaker 2:          02:40:58       That's just throwing out, you know, the wealth of the world, right? That would be a terrible thing, right? So it really matters who's right about that and the fact that we have a president or a candidate who is coming in saying, uh, this is all bullshit, you know, in, in defiance of all of the science, um, is, uh, and it's, it's true, but it's on every other part of the problem. He doesn't know anything about it. I guarantee you he doesn't know the difference between Sunni and Shia Islam or which countries are Sunni predominantly in which are Shia predominantly. And I mean, I'm sure he's going to do, I don't know when he's gonna Cram for this final exam, I'm sure before one of those debates he's going to get, you know, someone's gonna sit down with him and give him some bullet points. He's got to have in his head, but his head is just not in this game.

Speaker 2:          02:41:48       It's never been in this game. It's obvious from everything he says and that's what that is. Something you can't say about Clinton. Right? For all of her flaws as a person, I don't care how much you hate her as a person. She understands what's going on in the world and that that difference is so enormous. Forget about all the other character flaws of this guy who is just obviously going to. I mean he's, but are we attached to much to this idea of one person being the figurehead, figure it out. Someone has to be the decider. If we all woke up today, if everybody woke up and there was just no government, there was nothing more. All just what happened? I don't know, but we've got to figure out how to run this thing. Well, we had no, no previous understanding of government. Would you think anybody would say, we need one dude to just run this whole giant continent filled with 300 million people who are most likely if we woke up and we had technology like we have today, we have the ability to communicate like we have today with social media and whatever.

Speaker 2:          02:42:46       We would probably say we need to like figure this out amongst each other and find the people that have the most qualified for each one of these positions and we'll start running our government that way. Well that that's what we're attempting to do, but it's just, and I totally agree with you that it is astonishing that out of a nation of 300 million people, these are the choices you would think you would think would be starting from your base. That you know, your zero set point of just, you know, now we're going to reboot civilization. Um, you would think that if you had this kind of process, each candidate would be more impressive than the next man. You'd be like, I can't believe each, each person who came to the podium like James, oh yeah. It'd be like, it'd be like the dunk contest, you know, for the NBA and be like, oh my God, I could just, when you thought you saw the best dunk in your life, you know, the next guy comes along and it would be that.

Speaker 2:          02:43:41       It would be that on every topic, right? It'd be like you'd be talking about the science of climate change. You'd be talking about the actual dynamics of the war on terror, so topics that seem to have no relationship where you would have to be. You'd be amazed at anyone could be an expert in all of them. You would find someone who is an expert, a functional expert in all of them. Agility, winter dude. Yeah, yeah. But, but someone who also ethically wise who wasn't just wasn't obviously an asshole. Um, and who, uh, who, who had a, a mature relationship to change in his or her mind. Right? So, like the whole bit about flip flopping and, and not, um, you know, being like someone who could honestly represent changes of mind in, in, across a political career. Right. You know, it's nowhere written. That is a good thing to believe today, what you believe 20 years ago.

Speaker 2:          02:44:41       In fact, if they do that on every topic, it means basically you haven't been in dialogue with the world, but there's something, it's so taboo to change your mind that either you have to lie about it or you have to pretend it was a, it was always that way. Or um, it's just a, uh, the system, the system is, is broken in that respect, but given the choices, you know, and when you have a choice between someone who is for all her flaws, been in the game for long enough to be really well informed and capable of compromise and capable of, uh, not just, uh, just breaking the entire machine and you have someone who's just, he could just got stepped off the set of his reality TV show and then the lied about everything and, uh, and elbowed his way onto your television set and never left because, you know, CNN couldn't figure out how to give the mic to someone else. Um, it's, uh, it's amazing. Well, he's a product of attention because they realize that there's the heated race, right? The heated race, this guy was really famous and in a heated race, this guy would say some crazy stuff and so they would tune into him so everybody had to do an intro. So because of him saying crazy stuff, he accelerated the amount they were talking about them. So they're constantly talking about him and barely talking other people and.

Speaker 1:          02:46:10       But he's created

Speaker 2:          02:46:11       warm hole in our political process now where there's nothing so crazy that could disqualify him among the people who like him to so he can just keep it just like nuclear bombs of craziness that, that, that the press can't ignore that the, every time they think, okay, this is the crazy thing he said that's going to harm his candidacy, so let's shine a light on it. It just helps him, you know, he could, he could, he could, he could get on twitter right now and say, you know who I'd like to fuck,

Speaker 1:          02:46:38       I'd like to fuck Nikki Minaj and, and it would work for him. It was work for them. You would see a use a tweet storm of a billion people who say, I'd like to fuck Nikki Minaj to go get her, and it's insanity. That's where we are. But in a sense, if w w we, we do admit this is a fucked up system. It's not ideal. It should definitely be reworked and it's so hard to rework. Wouldn't the best way to rework it? A trump asteroid just slams right into the White House. Boom, blows the whole thing sky high. Who knows what terrible things have to happen, but maybe that would be enough. The thing is we have those, those assets,

Speaker 2:          02:47:22       troy's are coming anyway. So when you look at like nine slash 11 was an asteroid, right? So it's like a or, or a superbug that, that becomes a pandemic, that these are things that are coming and we need people who are in touch with, with reality to deal with them. Right? So like the moment someone advertises their, not only their ignorance, but the fact that they don't care, that they're ignorant and they do that this again and again, they keep doubling down that person. It's like if you put that person at the helm, what you have done is basically put chaos at the hill, right? It's like, like, this is, this person's going to believe whatever he believes, regardless of the information coming in and regardless of the consequences, that's just. I mean, it's, it's, it's worse than having no one in charge. I mean, because you've, you've, you've put the power in this person's hands, right?

Speaker 2:          02:48:18       So this, this person is, everything has to go through this node in the network that is just like an information scrambling device. Right? So like, know how Matt, no matter how good the information is coming in, you have everything that you've got a bottleneck here which just screws up the signal, right? Um, that's what you're doing. If you're, if you're, if you're hiring someone like this, who I'm, I mean, yeah, in the best case, you're, what you stated earlier would in fact be true, which, uh, he'll, he'll get into the oval office and even he will be scared about, of the prospect that he is now

Speaker 1:          02:48:52       running the better part of human civilization. And he will hire the best people,

Speaker 2:          02:48:58       some semblance of the best people he can get access to and say, tell me how to not screw this up. And that will be a. and then it'll. Then it'll essentially be business as usual. Right? Insofar as you've hired, the best people will be people. People who are deeply in this game already, right? You know, he'll defer to the generals when it comes time to make

Speaker 3:          02:49:20       wore the being real. Really pragmatic about how they pick politicians and how they push certain people and decided I had to push others. Do you think that something like trump completely changes how they move forward now they realized that this can happen. Like now that you see that people are so goofy were so wwe eat out that you can get this guy, you know, I mean this is, this is where we're at. We're, we've got a guy. I told them the wall just got 10 foot.

Speaker 6:          02:49:45       Hi. Everybody gets crazy. Like how could you say that?

Speaker 3:          02:49:50       Yeah. Once they realize that that's possible. How long before you get like some motivational speaker type dudes? Long before they started jumping in there, Tony Robbins had presence. That's what we have. I mean, that's. Oh, this is way worse than Tony Robbins for president. Yeah. Way. Way more positive dude. Yeah. Yeah. But I'd vote for him. You know, Tony Robbins, positive guy. No, that's not what I mean. I mean, but that sort of ability to excite people get like one of those motivational speaker dudes, those guys. Whereas a lot of yoga pants and he's gonna. He's gonna be the next president is going to get us in shape. Getting be a reality show. America is a reality show where there were awesome. We're the best.

Speaker 2:          02:50:32       Did you see this press conference he held? I think it was yesterday. I did not know. There was a very funny moment where there was one journalist. I didn't recognize who it was, who gets hooked. So trump was being very combative with the press pool and he was, he was basically, you know, shouting them down, not answering any of the questions. And one journalist, just a gas said, is this what is going to be like when your president and is this, how is this what is going to be like to be in the White House press corps and deal with you? And uh, and he said, yes, this is exactly what's gonna be like. And, but you, you could just see that like the journalists, like they, they, they turn the camera on the room, a journalists and they, they are astonished by what is happening here. Like they don't know they're participating in this process and in, in, in some sense they've created this process. Um, but, uh,

Speaker 6:          02:51:27       no, not all of you. Many of you are enough of us. Is this what you do? Is it, is this what it's going to be like covering you if your president? Yeah, let, let me just have this kind of take charge in the restroom. Okay. Yeah, it is going to be like this David. If the press writes false stores like they did with this because you know, half of you are amazed that I raised all this money. If the press writes false start as like they did where I want it to keep a low profile, I didn't want the credit for raising all this money for the vets. I wasn't looking for the credit and by the way more money is coming in. I wasn't looking for the credit but I had no choice but to do this because the press was saying I didn't raise any money. Them not only that, I raise it, much of it was given a long time ago and there is a vetting process and I think you understand that, but when I raised almost $6,000,000 in probably in the end were raised more than six because more is going to come in and is coming in. But when I raised five point 6 million, as of today, Maura's coming in and I. and, and this is going to phenomenal groups and have many of these people vetting the people that are getting the money. And

Speaker 2:          02:52:30       you played the moment I was referring to probably live here. Is it a case where he's probably almost certainly line about his history of giving to veterans affairs and says he, he gave money very recently after people started fishing around to see if he actually had given the money that he claimed to have given to, to veterans. Um, but, uh, I mean this is, what's difficult about this is that, I mean the pr, yes, there are the presses highly imperfect and there and also partisan and there are false stories and there are exaggerations and they screw people over. Yes. And there are reasons to not trust the press from time to time, but in this case you have a, someone who there is no amount of fact checking and discuss information of his statements that, that forces him to ever acknowledge anything that he's done wrong and the and the lack of acknowledgement that he pays no price for it among, among the people who like him.

Speaker 2:          02:53:43       And so the press is powerless and then, and then. But the net result of like a, of a press conference like this, if you were a trump's follower is he just showed how biased and and petty the press pool is. And the press do need to just be beaten up by a strong man who, who's not going to stand for their bullshit, but it's a, it's a, um, I mean it's unbecoming at the very least, that kind of communication. It's kind of unbecoming that person that we expect. And that's pretty mild. No, that's my. Compared to his leg, his parody of the, of the, um, the disabled reporter. Who He. I mean, you saw that bit where he did like a, a, um, a cerebral palsy invitation at, at one of his speeches. He was the. Yeah. Oh yeah, yeah. He was interviewed by. I don't happen to know who the reporter was. Oh, he was making. He was making fun of somebody with cerebral palsy. He's done so many things that you could, that you would think would be fundamentally canceling of a person's political aspirations. Like, like you, you can't even cut marco rubio pretending to be like a. just goofy on someone's cerebral palsy, added at one of his campaign events. Oh, trend, right. One of the things that some Ted Cruz was that video of him

Speaker 1:          02:55:04       with his family, the outtakes where they like, oh, you didn't see it. It's a gem. It's spectacular. It's him with his mom and he's like, my mom prays for me often for hours everyday, and she like her. She looks. I'm like, what the fuck? You're talking about four hours every day? No, I don't. He can't even say that. And so they have all these really awkward moments like, okay, I'm going to go in for a hug. I'm going to say I love you. It's all. It's all like weirdly mapped out and that got online and people were like, Oh, Christ, okay. See this is. This is a bad game. Like you're not even good at this game. This is you. You're terrible at this game. Yeah. He was objectively terrible. Well, that's his. That's trumped competition. Well, the thing that would think about

Speaker 2:          02:55:48       crews that never even got out, which was the reason to be scared about a Cruz presidency, was his level of religious craziness. I mean, no one was even pushing on that because there was just enough to push on before

Speaker 1:          02:56:00       and got to that door and then you have to hold onto those weapons. But I mean, it hadn't been for had crews been the nominee, it would have been all about religion. What's, what's odd is that that's not a handicap in 2016 that you can have that and people consider it an asset.

Speaker 2:          02:56:17       Well, the one thing that's surprising and actually hopeful in trump's candidacy is the fact that he has, he has dissected out the religious, social conservative component of, of the Republican Party. So like the evangelicals, for the most part, we're going for trump over crews when it was pretty clear to them that trump was just pretending to be religious. And I mean, so it's a. trump gave one speech at know I think Liberty University where he spoke. He said Corinthians two, um, and you know, that's not the way any bible reader would, would speak about the second Corinthians. How would you say it? Second Corinthians, that's how you would say, yeah. Yeah. And so, so he, so he said Corinthians two as like, as though this is something that he just opened every, every night before he went to sleep. And so it's clear that it was clear to them that he's, that he is just, just mining the language, you know, or, or I'm impersonating a person to faith and um, but they don't care really as long as he does it.

Speaker 2:          02:57:27       And that's, that is, you know, if you're gonna look for a silver lining to this, it, it shows that it's not, it's they just want a space where their religious convictions are not under attack and they don't really care that the person in charge share them. Just usually, if you pretend to share them, that's good enough. And that's, um, that's better than actually carrying that. This person really believe in the rapture or anything else that is quite obviously crazy. Um, but, uh, yeah, so I don't think any Christian who was voting for trump thinks they'll say, I'm not going to judge another man's faith, right? Or I'm not. Who am I to say what's really in his heart? Right? They'll say that, but he's just given you, if you've been paying attention to who he's been and, and if you just look at how he talks about these things, um, I don't think he's falling any, any Christian that. So I think they're willing to vote for someone for it now, for other reasons that are fairly depressing in their own right. They're willing to vote for someone who's, who doesn't really play the game the way they do.

Speaker 2:          02:58:40       You have to believe in God to be President Two thousand 16. Right? Wouldn't you? Wouldn't you say that? That has to pretend to believe in God. But I think with trump, I think, I think the pretense is, is obvious enough that I don't think he's fooling the better part of the people who were voting for him who, who would, who would say they care about a person of faith being in the White House. So I, if anything, he might be in one thing he might be breaking is the barrier on having an atheist president because I think he, you know, it's just nobody, nobody thinks he is a person to faith. I don't think anyone really thinks that. So he's perfect. He's made, it might be our first atheist president who would help us in that, in that regard as well. Another trump media right into the White House. I'm starting to sound like a trump supporter.

Speaker 2:          02:59:29       Occasionally an asteroid does something good. Who would be the ideal president? I mean like what, what kind of a person? I mean it would probably be a person who doesn't seek attention. Probably be a person that. Well, I don't think it could be that. I mean the, the, the process is even, even an optimized process will be, um, will, will require enough sacrifice of what ordinary people want. Most of the time that it will be an unusual personality who has to get promoted and you will, you will be on some metric be. I mean, it's almost by definition narcissistic to think that you should be in this role right? Who are you to think that you should be running a civilization at this moment in human history? Um, and to, for you to be on it, for you to honestly stand at the podium and say, I'm the guy or the woman like, I am the most qualified, I should be doing this.

Speaker 2:          03:00:28       Right. I can help. Um, you know, if you, if you're going to scrutinize the kind of personality that could give rise to those opinions, it's not you. Yeah. There's some dials you would probably want to chain tweak if you, if you had to be married to this person or if it's not an optimal personality. So there's going to be kind of pathology of, of power seeking that might be just intrinsic to it. But, um, you want someone who is actually wise ethically. I mean, just, just, you're just trying to map that onto trump, right? Just, he's. Imagine someone saying thing I like about trump is that he is so deeply ethical and wise, right? It's just, it does not. I mean, it's like saying it's because of his hair looks so natural. Yeah. I mean, there's, there's no, um, it, it is the antithesis of what he is, right?

Speaker 2:          03:01:25       Um, the, the thing I like about trump is that he is so well informed about the way the world works and where he's not informed, he recognizes his ignorance so quickly and he remedies it as fast as possible. He do know he seeks out the best experts, defers to them. Um, and uh, you know, he's just, he's mindful of the limits of his knowledge. Seo As, as he is about his expertise and his expertise is vast. Right. You'd want to be able to say that about a president. You could not begin to say that about trump, right? You could probably say that. Honestly. You could probably say that about Clinton, right? Like, for, for all her defects, she's very knowledgeable and I'm sure she will just try it. Where she, where she doesn't feel like she's got the knowledge he's going to try to go to, go to the source of the knowledge.

Speaker 2:          03:02:21       Right. Just grab the best experts you can find. Um, I think she, I think she will be as aware as you are. I would be of the consequences of not knowing what's going on, right? She's just going to want to find out what's going on. Whereas this, I mean all trump has advertised about himself is that he thinks that bluster and banality and bullying will win in every situation. It's just like it's just attitude. He's the guy is the guy is winging it and it could not be more obvious that this guy is winging it on every level. I mean like it's just, it is. It is, isn't it? There there'd be no way for him to signal the fact that he's winging it more clearly than he is with everything he's doing and and yet there's no penalty.

Speaker 1:          03:03:14       Do you think it's possible that in this age of information, the way we can communicate with each other that we're going to experience these cycles, these waves, these in and outs, these high and low tides of really smart presidents and really stupid president and we just people revolt and there's just. It's so easy to stay alive. It's plenty of students who fill out there and so they're only willing to vote for other dme folks, so the other dme folks get into position. They send out the frequency that only the dummies here and everybody else is going, what the fuck is everybody voting for this guy for what is happening, and then it makes the smart people rebound and for years and challenge themselves a new because they they need some of an enemy to rally against to reach their full potential and that without the low tide, you cannot have the high tide Sam Harris. Hopefully that's not an analogy that applies for the maintenance of civilization. This smell the time man. Maybe at the very least, it's a wakeup call for the political establishment. This silly game that you've been running have two candidates just doesn't work. Someone can cooperate your candidacy. Get in there, throw the fucking monkey wrench into the gear system and guess what? Trump's running for president now. He's the. He's the head, he's the head guy for the Republicans. How is that even possible? They don't know.

Speaker 2:          03:04:35       Amazing. It is a way, if nothing else, it has a total wakeup call for the Republicans. I mean, they are just,

Speaker 1:          03:04:40       it's June aghast. Yeah, it's June. Everything's decided locked down. So we have July, August, September, October, November. We're that close.

Speaker 2:          03:04:53       But he's not someone who has been, who is aligned with the Republican platform in most ways. Right. So it's like he's been, truth is virtually no one knows what his policies are because he, he keeps changing his position on things like taxation and it's like, if there actually is no keys, he said he's talked to on both sides of, of, of core issue, core Republican issues. But I mean, in many ways he's left of Hillary, right? He's, you know, he's left of Hillary in terms of being an isolationist. Like he's, you know, he, his, his relationship to war is, but both extremes. Like, he's like, no, we're just gonna. We're gonna get out of the world's business. Right? We're going to be isolationists, which is deeply anti Republican. Um, but I'm going to be the maniac who you're never going to know who I'm going to bomb next.

Speaker 2:          03:05:51       We're going to, we're going to wipe out isis. We're just straight away, right. Did Not, not a man left standing. Um, and I'm not gonna take any shit from anyone including China and North Korea. And so he's that. But we're going to pull back in a huge way and not be in anyone's business, right? He said both of those things. Um, uh, it's, it's, it's way too interesting way it may. We don't want politics to be this interesting and it's going to be November is going to be if the polls are closed and watching those debates and, and, and, and, uh, waiting for swinging the polls as a result, it's just going to be, it's to be way too interesting. That's gonna be like watching the superbowl, those first debates, you know, it's going to be 100 million people watching those debates. I have a prediction. I think, uh,

Speaker 1:          03:06:48       I think it's entirely possible. This whole thing was a plot that didn't work out. I think he probably came out of the gate

Speaker 2:          03:06:56       saying crazy shit, thinking he would tank the Republican Party and get his friend Hillary Clinton into the White House that she didn't attend to work out. He kept trying to insult her, kept trying to make stuff up about Mexicans and it just kept making them get better and better and now he's stuck. He can't pull out that. That would be. That would be a great moment. That would change the system. Well, we're going to have to go through something like this in order for us to realize that this is crazy, that a guy can just do this, can just not really have any interest in politics until that. And then he should get the Nobel prize for everything. If he pulls out at this point and says, listen, I'm just, I took you to the precipice here just because I wanted you to recognize how unstable this situation is. I mean, you, you guys could elect a demagogue who is actually an incoherent demagogue.

Speaker 2:          03:07:49       I'm not, I haven't even been playing an incoherent authoritarian. Right? I'm, I'm, I'm, uh, on one hand, a very liberal right and tolerant and on the other hand I'm like getting ready to be Hitler and you guys can't figure out who I am and yet you're still prepared to vote for me. Um, I mean, yeah, for him to do a postmortem on, on his Punkin of, of the culture, that would be the best thing to ever happen. But, uh, I don't think that's what's happening. We need someone like this so that we realize how silly this whole thing is. Do we need some, we need a qualified person to deal with all of the other hassles and dangers that are coming our way, that have nothing to do with, with what we do. But that person's not there. Even even if we were doing everything perfectly, they would still be this tsunami of risk and hassle and waste and all the rest of the world's chaos that is coming our way.

Speaker 2:          03:08:55       And it just forget, even if we had our, our house in order, in every respect, we still have terrorism and the global climate change will, you know, you've got, you've got China and India and what are they doing in terms of a compliant with, with, um, climate goals? Uh, you have all the things we've been talking about, the virtual certainty that there's going to be a pandemic at the, what I'm talking about, bioterrorism, we're talking about just the sheer fact that in 1919 there was a killer flu and there's going to be another killer flew, right? There's just no way. There's not gonna be another killer flu. Um, and we need, we need people and we need people, people to smart people to change the, to optimize the system, to deal with these kinds of things. And if we're promoting religious maniacs and, and crazy narcissists and liars and ignoramuses and only those people, how could this end will.

Speaker 3:          03:10:00       No, this is just a weird year for heavyweight boxing. You know, they have those weird years for Tony happened to be where you could be the heavyweight champion of the world. They went through a period of time in like the early eighties for Tyson came around was a series of like these champs that were like, you know, sort of like journeymen fighters and then Tyson came along. Maybe that's what it is, but only only with heavyweights, right? Yeah. Mostly with heavyweights. Yeah. Yeah. The lighter weights, they were always bad ass, but I think that maybe that's what's going on. Maybe we need to have this bad season, get the season out of our way, realize the danger of having an inept person in office, whether it's a liar or a to hates money or, or, or trump or whoever it is. Just go through it and realize how silly it is that we have it set up this way still.

Speaker 2:          03:10:48       Yeah. Except people thought that of Hitler. I mean, this is any comparison to Hitler obviously brands you as a, um, an exaggerator but

Speaker 3:          03:10:59       they thought let them get in there and fuck it up and then we'll have somebody better. Hitler was a, a

Speaker 2:          03:11:03       comic figure for awhile, for a good long while. And people were including the American press were incredibly slow to recognize what a sinister character he was. And he was, he was considered a buffoon and a. and there was, you know, there was like a, Oh, this is, maybe Jamie can find this. I think it was home and garden. I think it was homeland, it house in home and garden, you know, there was a, a, like a write up on his, you know, Eagle's nest or his house that was just, just this pure puff piece of, of, you know, Hitler love in our architectural magazine. I'm at home with the fuel. I think this is it. This is a, was like a guardian right up under something. Homes and gardens. Yeah. So that people can see the, um, the actual pages. I think they're pdfs online of the actual pages of the article.

Speaker 2:          03:11:57       But this is probably a, the actual text of the article. But it's hilarious. It's just, you know, like architectural digest does, you know, the Eagle's nest and. But it's at a time where it's not too far away from a moment where it should have been absolutely obvious to every thinking person that this guy was going to try to conquer the world for evil. Right? And yet it was not obvious. And, and when you look at how it was not obvious, it's pretty humble. I mean, you, you don't know, you would have been necessarily different because up until this conversation practically, I've been looking at trump as a clown. Right? But how, how, what, what would this clown actually do with the power of the presidency? I, you know, I don't know that he couldn't be. I mean, he's, he's given voice to a kind of authoritarianism that, you know, some people are, his enemies are noticing, his friends are discounting, but he's talked about, you know, going after the press.

Speaker 2:          03:13:00       And I mean, he's bragged about how many people, he's gonna Torture, right? He's talked about, you know, well of course we're gonna would do waterboarding and we're going to do worse and what maybe will kill the kill the families of terrorists. Right? And he told he he, but there's a kind of a um, I mean it's just, he's going to make America great again. He, what would he do if he actually had more power than anyone in the world? I think it's, it's, it's a legit question. The transition from comedy to a, Oh my God, we can't take this back, you know, in anything like a short order, you know, that would be, that could well be terrifying. What do go back to the question of heavyweights? Why do you think you could be a fake heavyweight and not a fake

Speaker 3:          03:13:49       middleware? There's not that many really good athletes. They go to boxing when they really large. They tend to go to football or interesting or basketball after really tall. It's like, um, if you look at the amount of money that like guys in the NBA can make or guys in the NFL can make. I mean, they're really top level guys can make a tremendous amount of money. So when you get to really super athlete guys, um, they tend to gravitate towards the big name. I mean, there's no bigger name sport than football. So getting someone to abandoned the whole team thing and having the balls to go one on one in a cage and having that mentality that's also very different because it's not necessarily the smartest thing to do, but it's the most challenging thing to do and there's some really smart people that do it.

Speaker 3:          03:14:34       So even though cage fighting isn't, it's not the safest way to get through life for a lot of people that engage in it and it becomes like an extreme, extremely difficult pursuit and then that's what it becomes to them, you know? And in the heavyweight division, those guys were being lured into other ways and boxing was just kind of went in through like a hit, a peak and a valley when Ali. And then it went. Larry Holmes, Larry Holmes was amazing. People didn't appreciate him for how good he was. So that doesn't have the middleweight level. That was not the same competition for that kind of athlete. It will for a little dinky little lulls in the middleweight division, but it's always pretty fucking strong.

Speaker 2:          03:15:13       But I mean, why? Why wouldn't you have the same competition for the high level athlete at one 65 weight? I mean there's just not our favorite sports or require bigger people. Yeah. Bowling,

Speaker 3:          03:15:25       basketball and football and baseball doesn't really apply here. The amount of cultures that produce heavyweights, first of all are fairly limited. Like very few heavyweights have come from Asia except a polynesian guys, which I guess is kind of Asian. But like uh, like Samoans, samoans known to be great for. But giant, sturdy heavyweights. Like the Chinese don't really produce them that often, so they don't. The people don't get that big in Japan. Sumo, but yeah, but they're very fat. There's never been like a guy who looks like Mike Tyson that came out of Japan and the eighties, you know what I mean? We're seeing more of that now. But I mean if we had a guy that was like a Japanese version of Mike Tyson just to super fast, blinding knockout fighter with a fucking head, like a brick wall and the giant neck that started above his ears and went down to his traps.

Speaker 3:          03:16:20       You remember Tyson when he first came on the scene, he was unbelievably terrifying, so there was never been a Japanese person that has that kind of physical strength, so I think it's limited genetically and I think in a lot of the competitive boxing countries that tend to be poor countries and I think also in a lot of poor countries you'll see much smaller men like you'll see like some some manner like flyweights, like it's very rare you find an American flyweight. Most Americans are larger. They get more food. I think it probably has a lot to do with it or just just the genetics in general. But like South America produces a lot of flyweights like the Philippines. Of course we're manny Pacquiao came from him. He was like eight weight classes lower when he first started and if you're a great athlete at at 120 pounds or 130 minutes.

Speaker 3:          03:17:07       Not a lot of sports. Yeah. What else can you do? Especially if you read. Some of these guys are really tiny, but they're amazing boxers, like, um, I mean there's a ton of them, but the United States, Johnny Tapio was a smaller guy. I think what it would wait to Johnny Tappia fight out. So you find that there was some lightweight guys that were just so incredible. They brought so much attention to those divisions, but there was never. This is my little peaks and valleys where greatness comes in and people have to recover and the new people come along with are great, but there's always been pretty steady. What did he fight at? Super Flyway? Yeah. So he was one of the rare Americans, Mexican American Johnny Tap. He was a bad motherfucker super fly away. Which is, what is that like one slash 26 or something? Maybe 1:30.

Speaker 3:          03:17:56       I don't even know what that [inaudible] Bantam weight. I think it's in the UFC. It's different. There's different weight classes. One hundred, 15 pounds. Wow. Crazy. That was tiny. Yeah. And he was a wild, wild guy. They did a documentary about him. How did he do? He died. Yeah, he died. I don't remember, but he had a lot of problems with drugs and crime and craziness and he had like Mi Vida loca tattooed on his chest. I might get you to the presidency now. He was a wild man, but just an amazing fighter to watch. So much fun. But I think, you know, put in where the bigger people are, you know, I just think they tend to gravitate towards other sports and I think that's all it is. And boxing like always like one 60, 1:47 and one [inaudible] always been like the promised land. That's sugar ray Leonard and Marvin Hagler.

Speaker 3:          03:18:50       Roberto Duran. I'm a floyd mayweather's in there. Sure. Shane Mosley's in there. So many guys are in that mix. That's the sweet spot. That's always has been this great fighters in pretty much every class. Strength and speed that. Yeah. I think you see in the UFC to. There's um, well I think, well when it comes to just freak movements, I always think that the flyweights in the Bantam weight, it's 25 and 35, so the fastest and the best coding like 20 percent faster than. Yeah. But I always wonder like, how much of that is because they're just not affected by gravity as much because that was effected by the, the blows that are being landed by the other guy. It's like, it's. Unless it's mighty mouse. Mighty mouse is the one of the few guys in that division that consistently stops people. Did you see his last fight with Henry Cejudo?

Speaker 3:          03:19:36       No, it was, it was incredible. It was insane. I mean, he, um, he fought this Guy Henry, so who does an Olympic gold medalist, one of the best wrestlers to ever compete in MMA. I mean, he is just a stud wrestler and a really good kickboxer too. And mighty mouse clenched up with them and hit them with these knees to the body that we're just out of this world technical. Just so perfect. No wind up, no slop. Just drilled them in on each side with perfect precision and he just crumbled. He was like, what the fuck? He got the victory on knees to the body, just need the shit out of his body and eat them in the face. But it was the fluidity of the way. Who is moving his knees in the perfect position? I mean, it was, there were so perfectly oiled, like everything was going down a path that it had gotten a million times, which just like a tight clench or.

Speaker 3:          03:20:28       Oh yeah, but it was, it was better than I've ever seen. I mean, it was without a doubt the most. One of the most. Well there's two, there's another one in between Anderson Silva and rich Franklin, but that was like a prolong brutal beat down where Anderson just keep beating him up, beating him up in the clench and broke his nose. Is that. There's one where uh, yeah, I, I saw, I remember victor was at Wildman or, or was it silver? I can't remember if someone just won on a knee to the chest against someone who was. Can you, can you need someone who's, who's down? It was jail son and. Yeah. Anderson Silva. Yeah. Yeah, yeah, yeah. That was pretty brutal. What, what mighty mouse did in this fight. That was crazy. It was the precision of the placement of the knees and how quick they came.

Speaker 3:          03:21:11       Just Bam, Bam, Bam, Bam. Just controlled him and he's controlling. Your guy was an Olympic gold medalist wrestler, just a stud wrestler. It was really pretty impressive stuff. Like really, really amazing sharp technique. But I wonder what could a heavyweight even move like that? Yeah, probably not. No, I mean, as you get bigger, there are just things you can't do. It clearly is. There's a limit to the size you can be and be not only athletic, but even ambulatory. I mean, you can't, you couldn't have a 30 foot tall person who could walk around and, you know, your bones would break and, you

Speaker 2:          03:21:46       know, because because mass goes up, but with a cube of, um, just the side. So it's why it's why if you, um, a part of ammunition that kind of a different point. But like if you, if you could drop an ant off the empire state building and it'll, it's, it'll fall and hit the ground and be fine. If you dropped a horse off the empire state building, it's going to, you know, be illiquid horse. Um, it's a, uh, I mean they are, you have, you know, kind of the air resistance with surface area, uh, the, the air resistance goes up with, by, by the square, the surface area, so, but that doesn't counteract for the mass going up with a cube, the volume. So, so the horse is bigger, you'd think it might be able to kind of act like a wing more as much as the atwood.

Speaker 2:          03:22:39       He has got a lot of air resistance is giant. It's always a horse, but it's, um, it's, it's mass is going up with, with a cube of. It's with the cube of its size. So it's um, uh, the air doesn't resist this fall at all compared to them what it's doing for an end. Um, but yeah, but yeah, we haven't the limit on this. This is one function, like if you, if you're going to engineer the super athlete and if we're going to give you like a chimpanzee muscle proteins or whatever to make you super explosive and strong, um, you'd have to get that right with your, you know, your connective tissue and your bones and everything else because you could rip your own arm off with your holistic moves.

Speaker 2:          03:23:22       Imagine if you had chimps strength and human tendencies like good luck once you take your own arm off and beat the person with it. Well use. I'm sure you saw that video of the little boy who got into the gorilla cage. Yeah. Shoot the gorilla. That seemed. I heard a lot of. I didn't pay a lot of attention to the commentary, but it seemed pretty straightforward to me. I mean, they have to shoot the gorilla. Yeah. Like I'm with the zoo on that one. I missed. Totally tragic and it's how is the zoo? The zoo was certainly culpable for having an enclosure that a three year old or four year old can get into. Right? I. How the hell did that happen? But. So you've got to fix that and um, but it's totally tragic, but once you have a 400 pound gorilla that has a human child and is not letting it go and just kind of dragging it around, I mean, it wasn't looking at aggressive toward the child, but it just, the fact that it moved it around, would that kind of force who then, who knows what was going to happen?

Speaker 2:          03:24:24       I mean, it looked like you had to end that as quickly as possible. We have to assume that that girl is going to know that a baby's more fragile than a baby gorilla. We'd have to assume. I don't assume anything. You can't say no, no. There's no way I could know. I never experienced that have just ripped or torn his head off easily. Accidentally. Oh yeah. Easily.

Speaker 3:          03:24:44       No. Was totally tragic. And I'm sure the, the, uh, the parents and this and the zoo are reaping sufficient criticism. But um, once that situation is unfolding, I think, I mean, you can't tranquilizer because it doesn't work fast enough. So I might grab a, a fear and it's being attacked. Jesus Christ. That's scary though, but if it was your kid, I think he'd probably shoot that fucking gorilla if it was your kid. Yeah. It's um. I mean if more people were carrying guns you where it was in Cincinnati, right. If that had been in Texas a property with some innocent bystander who was going to take the law into his own hands and Chuck Norris plants. I'm prayed over the open fire. Yeah. It's, I saw some horrible comments to where people like they should just shot the parents while they were at it. I'm like, well, it's easy to be outraged.

Speaker 3:          03:25:46       Somebody fucked out. It's a little kid. Shouldn't have been able to get in. First of all this you gotta see gorilla and closure. It is an architectural failing. They should, it should be impossible. It's not like, it's not just like a year old could do it. How could a three year old, like it should be impossible for an adult to get in there with it, with a gorilla would have been. It's been happening with like pretty regularly lately. Like guys had been breaking into zoos and it's like some guy tried to kill the lions recently, right? Jesus Christ. I mean, you gotta realize you gotta a lot of responsibility when you have monsters in occasion, your city, you can't let babies get in there with them. I mean, that's a gorilla as awesome as it is, but if it wanted to attack you, it's a monstrous beast. It's a thing with power that you couldn't even fathom.

Speaker 3:          03:26:34       A gorilla could literally pick you up and throw you. Like you could have football. I mean, they can launch you there is so strong. Oh yeah, don't do it. Didn't we? Google it. They get to be like 500 pounds or something crazy. Yeah. Well this was like 400 pounds, but not, but not. Not Four hundred pounds, like a Boston sap. Four hundred pounds when he was 300 pounds, but it's like a 300 pound gorilla is much stronger than Bob Sapp. Yeah. They're not equivalent pounds. It's unfathomable. The amount of physical strength and must just sucks that they keep them in zoos in the first place. It sucks that they had to kill him, but it really sucks that they keep doing the zoo thing with smart stuff, like if you want to have giraffes in the zoo. And I had a whole bit about it that they look like real relaxed because there's no lions around, you know, like they don't care, they just give them some food. But there's some animals that look tortured and primates in particular, they just look so freaked out in this enclosure and this weird place where people are staring at them. They're pacing and trying to get away from people's gazes. It's just, I think it's very,

Speaker 2:          03:27:42       very stressful to them. I think. Well, it's a hard question, uh, of what to do given certainly these species or are on the verge of extinction. Right? So like how do you preserve them? I mean, you obviously you can preserve them in all kinds of technical ways, like, like, you know, have their DNA frozen and, and be able to reboot them at a certain point when we, when we haven't, when we figured out how to preserve their habitat. But the, um, I mean, I, I think that I got to think there's a role for, for good zoos to, to get it because you also, you just want to maintain the public's connection to these animals because the decision to destroy habitat is made by people who don't really care about the prospects of extinction. Right. It's a very good point when you present it that way because the people that are over there are face, I mean the people that are over in Africa trying to save gorillas and chimps and I mean that is an unbelievably difficult struggle and they might not make it when there's a real concern that if there was no regulation at all and there was no one telling anybody what to do, but they could just go in there and wipe them all out.

Speaker 2:          03:28:54       Well, that's mean historically that's what we've done. Right? So if any, with kind of everything that we profited from anything that you can make money off of anything that you can. I mean the, the, I don't know what the hell they use chimps and gorillas for. Well there's the whole trade. Well, no, they, they just, I mean there's bushmeat they eat them, but then there's the, why do they call it bushmeat? Well there's, you go into the Bush, you go into it's content, just shoot everything. Well, it's just, it's just your, they're hunting species that you know, you don't think of is food species, but they're, you know, they're eating monkeys and gorillas and, and that's why they call it bushmeat. Well, I mean, bushes. They call bushes like the jungle. So it's um, it's just hunting species that are, that are, they're not, they're not.

Speaker 2:          03:29:39       Um, the, there's the other component of it which is they're like, you know, the, the crazy ideas that the Chinese have about the medicinal properties of tiger bone, wine writer, Rhino Horn or so let's say you have these species that are being hunted by poachers because there's a market for their, um, their parts, um, you know, like I the ivory trade, but the, um, now, but some, some people just eat species that are endangered to just the deterrent. Bushmeat is always associated with primates for some reason. I was always trying to figure out why. I don't know, is that true? No, probably not. Maybe my mind was when I read about people eating chips and how common it was, my friend Steve Rinella did a show in Bolivia where they shot and they ate a monkey and it's so weird to watch these people. Yanomami the Yanomami, uh, they live in Bolivia and they live in very much like the way they probably live hundreds of years ago.

Speaker 2:          03:30:41       They are handmade bows and arrows. He's long spear like arrows that it's not like a regular bone marrow that's like a five foot long arrow restraint. They walk around barefoot and uh, they have some Russian shotgun and their favorite thing to do is they have a Russian shotgun. The other got a Russian shotgun and somehow they got from somebody and it made it all the way deep into the jungle. But the shelves are very precious. But their favorite thing to do is shoot an eat monkeys. It's like their number one favorite thing to eat and they cooked it on the show and it was really weird to watch. You talk about some strange genetic connection that you have with a very, very human shape, like the lips and the eyes and the face of a, you can recognize a certain amount of human in that little little fella when they are fellow female, whatever female version of fellow would be.

Speaker 2:          03:31:33       But um, so they, they cooked it over this fire and then made this stew out of it. Right? Well, actually to go back to our, um, cultured meat conversation, one thing that's weird about that prospect is that if, in fact, so if you're making, if you're growing cells in a vat, then there's no problem with cannibalism, right? So that you could be growing human meat and fat, right? That's that. I mean there's zero ethical problem, but it's just as, as rote task is as a, at least to my palate, has fairly grotesque thing to contemplate. But these are just the distinction I'm just talking about. I mean, you know, there is no in principle, human DNA, right? And this and that. And at the cellular level, the, the, the, the, the difference between human muscle protein and bovine muscle protein is not me. That's if this, if this was never attached to an animal, it's a. we're dealing with concepts here and it's like when you, if you bite a fingernail and swallow it or you are practicing auto cannibalism, right? I mean it's, it's a,

Speaker 2:          03:32:54       at some level it is a concept is doing a lot of work. It's uninsurable when you're talking about depriving another person of life. But if you're talking about spinning up sells in a Vat, then then it becomes, well, does it really matter whether this is. This was a person, you know, maybe people would decide that would be the only ethical choice to hasten cultured human meat. If you can eat meat, you have to eat human meat. There's the end of this economy. You can't harm any other animals. Not only can you, you have to eat yourself. This is what the cattle industry could do to just quash this. That just spread the rumor that there are human cells and those vats and you go to your local center, you get scraped and then they start making your monthly supply of you. Soylent Green is people

Speaker 3:          03:33:38       and they just have it in a vat and they break you off a cube every week. He'd take it back to you and you eat yourself and that's the only meat you were allowed to eat yourself while we figured out a way to live in harmony with nature. We just have to kill everything except us and then eat ourselves. Tell us which part of your own body you want to eat for the rest of your life and we will culture themselves. Well, I know it was you that I was having this conversation with once, I believe where we were talking about how when areas become more educated and women become more educated, it tends to slow the population down like people tend to. They tend to even worry that if these graphs continue further on that people in industrialized parts of the world as you know the they get into the first world. If they do, they'll more likely to have less and less people.

Speaker 2:          03:34:28       Paul has less and less children. Fertility goes down with literacy and education with among women. Yeah. Um, and there's know. So just to kind of map that onto, you know, life is, you know, adheres is a women given all the choices available, know educational, economic and an ability to plan a pregnancy. So here we have women who want to have careers, want to go to college and they, they delay pregnancy to the point where they have realized a lot of those um, aspirations and so pregnancies come later and later and later and, and, and families get smaller and smaller and, and um, and so, you know, virtually no one chooses to have 10 kids, um, in the face of all of this other opportunity that were the things they also want that life, right? Even if, if they, if they can avoid it, if you can't avoid it, well then you just find yourself with 10 kids. Right? Or if you have some religious dogma which says, you though it's possible to avoid. You shouldn't avoid it because you were put here to have as many kids as possible,

Speaker 3:          03:35:39       but are you allowed to bring that up? When you talk about the population crisis, are you allowed to. I mean, that's a, that's a fascinating piece of information.

Speaker 2:          03:35:48       Well, what, which population crisis are you thinking of? Because there, there is a bunch of them. They're two different ones. They're two opposite ones, which is China where they don't let you have girls will just, you. You don't want the, they live lesson that I think they've relaxed that a, I think they've relaxed the one child policy, but I'm not sure I remember hearing something about that. And the other one you would say India. Well, no, no, I'm excited. States know that there are the other, there there's an overpopulation crisis in certain countries and in and disproportionately in the developing world and there is under population in the development world. I mean they're there. Most of western Europe is not replacing itself. So you're having, um, these senescent populations, uh, who have to, they just have to import the, they rely on immigration for, for just that to carry on the functions of society because they're just, they're not at anywhere near replacement rate is the most surprising detail that brings us home is that there are more adult diapers as Japan and more adult diapers sold in Japan than baby diapers. Now just think about that for the implication of that for society, right? How do you have as a sign of how do you have a functioning society, you know, barring, you know, perfect robots that can tend to your needs, um, where you have just,

Speaker 7:          03:37:18       um,

Speaker 2:          03:37:19       disproportionate number of people who are no longer economically productive relying on the Labor of the young to, you know, keep them alive and cure their diseases and, and um, uh, defend them from crime and all that. But the, the ratio is totally out of whack, right? So you need, we need people like the world is a giant Ponzi scheme on some level you keep, you need new people to come in to maintain it for the old people. Barring, you know, apart from having some technology that allows you to do that without people. Um, but I think our, everything I've heard about population recently, it suggests that we are on course, you know, globally to peak around nine and a half billion and then taper off. I don't, I don't think anyone now is forecasting this totally unsustainable growth where we're going to wind up with the St Louis and I nine and a half billion people you said billing, um, where we're going to hit something like 20 billion people, right?

Speaker 2:          03:38:23       I don't think anyone, even the most mouth, Uzi and people are expressing that concern at the moment, which, which was the case like 20 or 30 years ago where they thought this is just going to keep going and we're going to hit the carrying capacity of the earth, which is something like 40 billion people. Um, wow. Uh, I don't think anyone thinks w w because we're just. Fertility is falling everywhere but it. But it has fallen actually below replacement in the developed world. Do you think in our lifetimes in or in our children's lifetime, it's feasible that we figure out a way in some way to, I'm not endorsing like taking people's money and giving it to other people, but in some sort of a way to eliminate poverty. Is that even possible? Is it ever going to be possible to completely eliminate poverty worldwide and within like a lifetime?

Speaker 2:          03:39:20       Well, I think we talked about this the last time when we spoke about ai, but I mean this is the implication of much of what we talked about here. If you, if you imagine building the perfect labor saving technology, right? What do you imagine? Just having a machine that can build any machine that can do any human labor, you power by sunlight more or less for the cost of raw materials. Right? So you're, you're talking about the ultimate wealth generation device and now we're not just talking about blue collar labor, we're talking about the kind of labor you and I do, right? So like the artistic labor and scientific labor and um, you know, just a machine that comes up with good ideas. Right? And here's what we're talking about, general artificial intelligence, um, this, if in the right political and economic system, this would just cancel any need for people to have to work to survive, right?

Speaker 2:          03:40:18       It just would be, there'd be enough of everything to go around. And then the question would be, do we have the right political and economic system where we, where we actually could spread that wealth or would we just, we just find ourselves in some kind of horrendous arms race and, and, uh, uh, situation of, of wealth inequality, unlike any we've ever seen. Um, it's a, um, we don't, we don't have the, it's not in place now. And if someone just handed us this device, you know, if, if, um, and it were, you know, all of my concerns about ai or gone, I mean, there's no question about this thing I'm doing things we didn't want it would do exactly what we want when we want it. And there's no, there's just no danger of it. That's interest becoming misaligned with our own. It's just like a perfect oracle and a perfect designer of new technology.

Speaker 2:          03:41:11       Um, if it was handed to us now, I would expect just complete chaos, right? I would explain if, if, if facebook built this thing tomorrow and announced it or rumor spread that they had built it, right? What are the implications for Russia and China? Well, in so far as they are as adversarial as they are now, it would be rational for them to just nuke California, right? Because it, because the happiness device is, there's a winner take all scenario. I mean, you, you, when the world, if you have this device, you can turn the lights off in China, you know, the moment you have this device, you can just imagine it's just the ultimate because literally we're talking about and you know, many people are may doubt whether such a thing as possible. But again, we're just talking about the implications of intelligence that can make refinements to itself in over time course.

Speaker 2:          03:42:11       That is, it bears no relationship to what we experienced as apes. Right? So you're talking about a system that can make changes to his own source code, um, and become better and better at learning and more and more knowledgeable. Has Instantaneous, if we give it access to the Internet, it has instantaneous to all human and machine knowledge and uh, it does, you know, thousands of years of work every, every day of our lives, right? They thousands of years of equivalent human level intellectual work. It's just a, it's on our intuitions completely falter to, to, to capture just how immensely powerful such a thing would be. And there's no reason to think this isn't possible. I mean, the, the, the most skeptical thing you can honestly say about this is that this isn't coming soon, right? It's like, this is not to say that this is not possible. Makes no scientific sense at this point.

Speaker 2:          03:43:10       There's no reason to think that a sufficiently advanced digital computer can't, can't instantiate general intelligence of the sort that we have. There's no reason to think that. I mean, the intelligence has to be at bottom some form of information processing and if we get the algorithm right with enough hardware resources and the, and the limit is definitely not the hardware at this point. It's, it's the, the algorithms. Um, there's just no reason to think this can't take off and, and scale and that we would be in the presence of something that is, that is, uh, like having an, an alternate human civilization in a box that is making thousands of years of progress every day. Right? So just imagine that if you had in a box, you know, the 10 smartest people who've ever lived and you know, every time, every week they make 20,000 years of progress, right?

Speaker 2:          03:44:08       Because, because that is the actual, the, you were talking about electronic circuits being a million times faster than, than biological circuits. So even if it was just, and I believe I said this the last time we talked about ai, but this is, you know, this is what brings it home for me, even if it's just a matter of faster, right? It's not, it's not anything especially spooky. Just this can do human level, intellectual work, but just a million times faster. And again, this totally under sells the prospects of superintelligence. I think human level intellectual work is, is, um, uh, it's gonna seem pretty paltry in the end, but if you just imagined just speeding it up. If you imagine if we were doing this podcast, imagine how smart I would seem if between every sentence. I actually had a year to figure out what I was going to say next.

Speaker 2:          03:45:02       Right? And so I say this one sentence and you say, you asked me a question and then in my world I just have a year. I'm going to go spend the next year getting, getting ready for, for Joe, and it's going to be perfect. And this is just compounding upon itself. Like not only can I not, not only, uh, I, um, am I working faster? Ultimately I can change my, my ability to work faster. I mean, we're talking about software that can change itself. You're talking about something that, that becomes self improving. So there's a compounding and function there. But, um, it's the point is, is unimaginable, uh, in terms of how, uh, how much change this could affect. And if you imagine the best case scenario where this is under our control, right, where there's no alignment problem, where it's just, it doesn't, this thing doesn't do anything that surprises us, this thing will always take direction from us.

Speaker 2:          03:45:56       It will never, it will never develop interests of its own. Right? Which is again, the fear. But let's, let's just say this is totally obedient. It's just an oracle and a genie route in, in one. And um, you know, we say, you know, cure Alzheimer's and it cures Alzheimer's, you know, you solve the protein folding problem and, and it just is. It's just often running and to develop a perfect nanotechnology and it does that. This is all, again, going back to David Deutsch, there's no reason to think this isn't possible because anything that's compatible with the laws of physics can be done given the requisite knowledge, right? So you just get enough intelligence as long as you're not violating the laws of physics, you can do something in that space. Um, so, but the problem is this is a winner take all scenario. So facebook does it tomorrow, and China and Russia find out about it.

Speaker 2:          03:46:52       They can't afford to wait around to see whether the US decides to do something not entirely selfish with this, right? Because they're their worst fears could be realized if Donald Trump is president, was Donald Trump going to do with a perfect ai when he has already told the world that he hates Islam? Right? Um, it's a, it's a, um, we would have to have a political and economic system that allowed us to absorb this ultimate wealth, save it will wealth producing technology. Um, and, and again, so this may sound like pure Saifai craziness to people. I don't think there is any reason to believe that it is, but walk way back from that edge of craziness and just look at dumb ai, you know, narrow ai, just self driving cars and automation. And I'm an intelligent algorithms that can do human level work, uh, that is already poised to change our world massively and create massive wealth inequality, which we have.

Speaker 2:          03:47:59       We have to figure out how to spread this wealth. What do you do when you can automate a 50 percent of, of human labor? Were you paying attention to the artificial intelligence go match? Yeah. I don't actually play go, so I wasn't paying that kind of attention to it, but I'm aware of what happened there. And you know, the rules of go. I'm not, not so that I know. Actually I don't, I don't, I don't play, I don't know. I don't know if I know vaguely how you, how you, um, how it looks when a game is played, but I don't supposed to be very complicated. The more complicated and more possibilities than chess and that's why it took 20 years longer for a computer to be the best player in the world. Um, it's, it is. Um, did you see how the computer did it too?

Speaker 2:          03:48:49       Well, I didn't, I, I know, I mean this is the company that did it is deep mind which was acquired by Google and they're at the cutting edge of ai research and yeah. Well, it's, the cartoons are unfortunately not so far from what is possible, but um, the, uh, yeah, I mean there's, again, this is not, this is not general intelligence. We're talking like these are not machines that can even play tic Tac toe right now. There's some, there, there have been some moves away from this or like deep mind has trained an algorithm to play all of the Atari Games like, uh, from 1980 or whenever and it is very quickly became superhuman on most of them I think. I don't think it's superhuman human, all of them yet. But it could play in a space invaders and all these and break out all these games that are, are, um, uh, uh, to highly unlike one another and it's the same algorithm becoming expert and superhuman in all of them.

Speaker 2:          03:49:55       And that's, that's a new paradigm and it's using a technique called deep learning for that. Um, and that's, and that's been very exciting and I will be incredibly useful. You know, this is in the other, the flip side of all this. I know that everything I tend to say on this sound scary, but this is all like, I mean, the next scariest thing is not to do any of this stuff. It's like we, we want intelligence, we want automation, we want to figure out how to solve problems that we can't get solved. So like intelligence is the best thing we've got. So we want more of it. Uh, but we have to have a system where, I mean, it's scary that we have a system where if you gave the best possible version of it to one research lab or to one government, it's not obvious that that wouldn't destroy humanity, right.

Speaker 2:          03:50:44       That wouldn't lead to massive dislocations where you'd have, you know, some trillionaire who's trumpeting his new device and, and just, you know, 50 percent unemployment in the US, you know, in a month. Right. I mean like he, like, it's not obvious how we would absorb this level of, of progress. Um, and we, we, we definitely have to, to figure out how to do it. And now of course we can't assume the best case scenario. Right? That's the best case scenario. I think there's a few people that put it the way you put it, that terrify the shit out of people and everyone else seems to have this rosy vision of increased longevity and automated everything and everything

Speaker 3:          03:51:26       and easy to get to work and medical procedures would be easier. They're going to know how to do it, but everybody looks at it like we are always going to be here, but are we obsolete? I mean, is this idea of a living thing that's creative and wrapped up in emotions and lust and desires and jealousy and all the pettiness that we celebrated all the time. We still see it. It's not getting any better. Right? If, if we obsolete, I mean, what if this thing comes along and says, listen, there's a way to do. You're going to abandon all that stupid shit. He can abandon all that makes you all the stuff that makes you fun to be around. Yeah, and also fucks with. You can live three times as long without that stuff. Oh, I think it.

Speaker 2:          03:52:08       It would in the best case, would usher in a, a. The possibility of, of kind of fundamentally creative life where on the order of something like the Matrix, whether it's in the matrix or it's just in the world that has been made as beautiful as, as possible. Um, based on

Speaker 2:          03:52:37       what would functionally be an unlimited resource of intelligence. Let me just say, it's just like for there to be a, a, an ability to solve problems of a sort that we can't currently imagine. I mean, it's just, it really is like a place on the map that you can't, you can't, you can indicate it's over there. You know, it's like the blank spot on the map. Ms Dot why it's called the singularity, right? It's like, this is it. This is a, uh, it was, it was John von Neumann, the. I'm the inventor of Game Theory who a mathematician who, um, want along with Alan Turing and a couple of other peoples who's really responsible for the computer revolution. He was the first person to use this term singularity to describe just this, that, that there's a speeding up of, um, information processing technology and a cultural reliance upon it, uh, beyond which we can't actually foresee the level of change that can come over our society.

Speaker 2:          03:53:40       It's like, you know, an event horizon past which we can't see. Um, and uh, this certainly becomes true when you talk about these intelligent systems being able to make changes to themselves. And again, we're talking mostly software. It's not, I'm not imagining, I mean the most important breakthroughs are almost certainly at the level of have better software. I mean, is we have, in terms of the computing power that the physical hardware on earth, it's not, that's not what's limiting our ai at the moment. It's not like we need more more, um, hardware, um, but we will get more hardware to up to the limits of physics and it gets smaller and smaller as it has a. and, you know, if quantum computing becomes possible or practical, um, that will, uh, and actually David Deutsch is, is, um, the physicist I mentioned is one of the fathers of the concept of quantum computing that will open up a whole nother area, a extreme of computing power.

Speaker 2:          03:54:49       That is, I'm not at all analogous to the kinds of, of uh, machines we have now. But, um, it's just, when you imagine people don't, people seem to always want to have it. I just had this conversation with, with Neil degrasse Tyson on my podcast. He named Robert. It was just keeping people. I'm just, I'm just attributing these ideas to handle a. he's not a, he doesn't take this line at all. He's not at all. He thinks it's all bullshit, right? He's not at all worried about Ai. What does he think he thinks that, you know, we just, we just use. He's drawing an analogy from how we, you currently use computers, that they just, they just keep helping us do what we want to do. Like we decide what we want to do with computers and we just add them to our process. And that process becomes automated and then we'll find new job somewhere else, like you didn't need a stenographer once you have voice recognition technology.

Speaker 2:          03:55:49       And I'm a. that's not a problem, a stenographer, I'll find something else to do. And so the economic dislocation isn't that bad and computers will just get better than they are. And you know, eventually Siri will actually work, you know, and you'll, she'll answer your questions well and you're not, it's not going to be a laugh line what series said to you today. And um, then all of this, we'll just proceed to make life better right now. None of that is imagining what it will be like to make because it will be a certain point where you'll have systems that are, you know, it's like the Cha, the best chess player on earth is now always going to be a computer right there. There's no, there's not going to be a human born tomorrow that's going to be better than the best computer. I mean, it's like, it's already like it's.

Speaker 2:          03:56:42       We have super human chess players on earth. Now imagine having computers that are superhuman at every, every task that is relevant, every intellectual task, right? So the best physicist is a computer. You know, the best medical diagnostician is a computer. The best. A prover of math. Theorems has a computer, the best engineers, a computer, right? Then there's no, there's no reason why we're not headed there. I mean, it would be the only reason I could see we're not headed there is it something massively dislocating happens that prevents us from continuing to improve our intelligent machines. But if you just the moment admit that intelligence is just a matter of information processing and you admit that we will continue to improve our machines unless something heinous happens because it's intelligence and automation are the most valuable things we have. Um, at a certain point, whether you think it's in five years or 500 years, we're going to find ourselves in the presence of superintelligent machines.

Speaker 2:          03:57:45       And then at that point, the best source of innovation for the next generation of software or hardware or both will be the machines themselves. Right? So then you. So then you just have, then that's where you get what, what was, what the mathematician Ij good described as, as the intelligence explosion, which is just that the process can take off on its own. And this is where, you know, the singularity people, um, either either are hopeful or worried, but because there's nothing, there's no guarantee that this process will be remain aligned with our interests. And, and every person who I meet even, you know, very smart people like Neil, um, who says they're not worried about this, when you actually drill down on why they're not worried, you find that they're actually not imagining machines making changes to their own source code. Um, and they're not [inaudible] they're, they, they simply believe that this is so far away that we don't have to worry about it now.

Speaker 2:          03:58:57       Right? And that's actually a nonsequitor I mean, to say that this is far away, is not actually grappling with. It's not an argument that this isn't going to happen. And um, and it's based on what to, and it's, and it's based on, first of all, there's no, there's no reason to believe. Jamie want to find out where it is. Um, there's no, I mean we don't know how long it will take us to prepare for this, right? So like, like if you were, if you knew this was going to take 50 years for this to happen, is 50 years enough for us to prepare politically and economically to deal with the ramifications of this and to do it and to say nothing of actually building the ai safely in a way that's aligned with our interests. I don't know. I mean 50, so 50 years is we've had the iphone for what, 10 years?

Speaker 2:          03:59:53       Nine years. It's like 50 years. Not a lot of time right. To, to deal, to deal with this. And um, this has no reason to think it's, it's that far away if we keep making progress. I mean it's, it's not, it will be amazing if it were 500 years away. I mean that, that seems like it's, it's, it's more likely from what I mean, the sense I get from the people who are doing this work, it's far more likely to be 50 years than 500 years. Like, you know, I'm uh, I mean the peanut that people who think this is a long, long way off or they're saying, you know, 50 to 100 years, no one says 500 years. No, no. As far as I know, no one who is actually close to this work and some people think it could be in five years, right?

Speaker 2:          04:00:50       I mean the people who are, you know, like the deep mind people who are very close to this or are the sorts of people who say because the people, the people who are close to this work are astonished by what's happened in the last 10 years. Like we went from a place of very little progress to, you know, wow, this is all of a sudden really, really interesting and powerful. And um, and again, progress is compounding in a way that's counter intuitive. People systematically overestimate how much change can happen in a year and underestimate how much change can happen in 10 years. And I, you know, as far as estimating how much change can happen in 50 or 100 years, I don't know that anyone is good at that.

Speaker 3:          04:01:36       How could you be with giant leaps come giant exponential leaps off those leaps and it's. It's almost impossible for us to really predict what we're going to be looking at 50 years from now, but I don't. I don't know what they're going to think about us. That's what's most bizarre about it as well. We really might be obsolete if we look at how ridiculous we are. Look at this political campaign, look at what we pay attention to in the news, look at the things we really focus on where are strange, ridiculous animal, and if we look back on some strange dinosaur that had a weird neck, why should that fucking thing make it? You know, why should we make it? We might be here to make that thing and that thing takes over from here with no emotions, no lust, no greed, and just purely existing electronically and for what reason?

Speaker 2:          04:02:27       Well, that that's a little scary. There are, there are computer scientists who, when you talk about why they're not worried or talk to them about why they're not worried, they just swallow this pill without any qualm like we're gonna make the thing that is far more powerful and beautiful and important than we are. And it doesn't matter what happens to us. I mean that was our role. Our role was to build these mechanical gods and, and it's fine if they squash us and I've, yeah, I've literally heard a, a people say I've heard someone give a talk. That's what woke me up to, oh, to how interesting this areas. I went to this conference in, in San Juan about a year ago and there were a, you know, like the people from deep mind where they are and the people who were very close to this work were there.

Speaker 2:          04:03:23       And I'm going to hear some of the reasons why you shouldn't be worried from people who were interested in common. The fear is so they could get on with doing their very important work. Um, it was amazing because they were highly uncompelling reasons not to be worried was just so, so they had a, they had a desire to be compelled. They're not, they're not at all. I will know that people, people want to do this. There's a deep assumption in many of these people that we can figure it out as we go along. Right. You know, it's just like we're gonna we're just gonna get going to get closer. We're foot. We're far enough away now, even five year. Even if it's five years, five years, we'll, we'll, we'll get there. Once we get closer, once we get something a little scary, then we'll pull the brakes and talk about it.

Speaker 2:          04:04:19       But the problem is they are assigned. Everyone is essentially in a race condition by default and you have, you know, Google is racing against facebook and the US is racing against China and every, every group is racing against every other group. Um, however you want to conceive of groups. This is a, to be the first one to be the first one with an incredibly powerful, narrow ai is to be the next, you know, multibillion dollar company, right? So everyone's trying to get there and uh, if they suddenly get there and sort of overshoot a little bit and now they've got something like general intelligence or something close to what we're relying on every. And they know everyone else is attempting to do this, right? Um, W we don't have a system set up where everyone can pull the breaks together and say, listen, we've got to stop racing here.

Speaker 2:          04:05:15       We have to share everything. We have to share the wealth with the share the information we have to um, this truly has to be open source in every conceivable way. And um, we have to diffuse this winner take all dynamic. Um, you know, I think we need something like a Manhattan project to figure out how to do that, you know, not, not to figure out how to build the AI, but to figure out how to, to build it in a way that does not create an arms race that does not create an incentive to build unsafe ai, which is almost certainly going to be easier than building safe ai interested to work out all of these issues because it's not because what I think we are, we're going to build this by default. We're just going to keep building more and more intelligent machines and this is going to be done in by everyone who can, can do it with each generation.

Speaker 2:          04:06:09       If we were even talking about generations, it's going to be. It will have the tools made by the prior that are more powerful than anyone imagined 100 years ago and it just going to keep going like that. Did anybody actually make that quote about giving birth to the mechanical gods or. That was just made, but it was, there was a scientist that actually was thinking and saying that, but that was, that was the content of what he was saying. He's, we're going to build the next species that is far more important than we are and that's a good thing. And it, and actually I can go there with him. I mean, it actually, the only, the only caveat here is that unless they're not conscious, right? Like say if the true horror for me is that we can build things more intelligent than we are, more powerful than we are a and that can squash us and they might not.

Speaker 2:          04:07:07       They might be unconscious, right? That there might be nothing like the universe could go dark if they squashes right, or, or at least our corner of the universe could go dark. And yet these things will be immensely powerful. Um, so if, and this is just, you know, the jury's out on this, but if there's nothing about intelligence scaling that demands that consciousness come along for the ride, um, then it's possible that, I mean nobody thinks our machines are, you know, very few people would think are machines that are intelligent or conscious. Right? So at what point does consciousness come online or maybe it's possible to build super intelligence that's unconscious, you know, super powerful, does everything better than we do, you know, it'll recognize your emotion better than, than another person can, but then the lights aren't on that. That's, that's also, I think possible, but maybe it's not possible, but that's, that's the worst case scenario because in the ethical silver lining, in speaking outside of our self interest now, but just from a bird's eye view, the ethical silver lining to building these mechanical gods that are conscious is that yes, okay, we've, in fact if we have built something that is far wiser and has far more beautiful experiences and deeper experiences of the universe and we could ever imagine.

Speaker 2:          04:08:28       And there there's something that it's like to be that thing that's just, you know, it is a hesitant kind of a godlike, a experience. Well that would be a very good thing. Then we will have built and we will have built something that was, you know, if you stand outside of our narrow self interest, I can understand why the, he would say that he was just assuming what was scary about that particular talk because he was assuming that consciousness comes along for the ride here. And I don't know that that is a safe assumption, but this really terrifying thing is who, if, if, if this is constantly improving itself and it's under the Beck and call of a person then. So it's either conscious conscious where it as itself, right?

Speaker 3:          04:09:14       It acts as an individual thinking unit. Right? Or as a thing outside of it's aware, right? Either it is or it isn't. And if it isn't aware and some person can manipulate it, like imagine if it's getting 10,000. How many, how many thousands of years in a week did you say? If it was just improvement, it was just a million times faster than we are. It's 20,000 years, 20,000 years in a week and a week in a week. So with every week this thing constantly gets better at even doing that. Right? So it's reprogramming itself. So it's all exponential.

Speaker 2:          04:09:48       Presumably it just, it just imagine again, if you could keep it in the most restricted case, you could just keep it at our level,

Speaker 3:          04:09:56       just, just faster, just a million times faster. But if it did, all of these things, if it kept going and kept, every week was thousands of years, we're going to control it. A person that's even more insane. Just imagine being and

Speaker 2:          04:10:09       dialogue with something that had, that lived the 20,000 years of human progress in a week and you come back, you know, on Monday and say, listen, um, I, I, that thing I told you to do last Monday, I want to change that up and this thing has made 20,000 years of progress. Um, and if it's in a condition where it has access, I mean, so we're imagining this thing, you know, in a box, you know, air gapped from the Internet and it's got nothing. It's got no way to get out, right? Uh, even that is an unstable situation, but just imagine this emerging in some way online, right? Already being out in the wild, right? So let's say it's in a financial market, right? Um, that's again, this is what worries me most about this and what is also interesting is that our intuitions here, I think the primary intuition that people have is no, no, no, no, that's just, that's just not possible or not at all likely, but if you're going to find, you're going to think it's impossible or even unlikely, you have to find something wrong with the claim.

Speaker 2:          04:11:15       That intelligence is just a matter of information processing. Um, I don't know any scientific reason to doubt that claim at the moment. Um, and a very good reasons to believe that it's just undoubtable, uh, and the, and you have to doubt that we will continue to make progress in the design of intelligent machines. And, but once you, then it's, then the, all this left is just time, right? If, if, if intelligence is just information processing and we, we're going to continue to build better and better information processors, at a certain point we're going to build something that is super human. Um, and so whether it's in five years or 50, it's a huge. I mean, it's, it's the biggest change in human history I think we can imagine, right? Um, so, uh, and, and people I what I felt fine, I keep finding myself in the presence of people who seem, at least to my eye to be refusing to imagine it like that they're treating it like the y two k virus or whatever where it's just the y two k bug where it just may or may not be an issue. Right? Like, it, like it's a hypothetical, like maybe this is just, we're going to get there and it's going to be. It's either not going to happen or it's going to be trivial, but how you don't, if you don't have an argument for why this isn't going to happen,

Speaker 7:          04:12:48       uh,

Speaker 2:          04:12:49       then you have to have then then you're left with, okay, what's it going to be like to have systems that are better than we are at everything in the entire intellectual space.

Speaker 7:          04:13:04       Um, and

Speaker 2:          04:13:08       you know, what will happen if that suddenly happens in one country and not in another, right? It's um, it's, uh, it's, I mean, it has enormous implications, but it just sounds like science fiction. I don't know what's scarier. The idea that an artificial intelligence can emerge, it's conscious, it's aware of itself, and then acts to present per, per protect itself, or the idea that a person, a regular person like, have today could be in control of essentially a god. Right? Because if this thing continues to get smarter and smarter with every week and more and more power and more and more potential, more and more understanding, thousands of years, I mean it's just, yeah, this one person, a regular person controlling that is almost more terrifying than creating a new line or, or any group of people who don't have the total welfare of humanity as their central concern.

Speaker 2:          04:14:02       And so just imagine what would, what would China do with it now? Right? What would we, what would we do if we thought China, you know, Baidu or what are some Chinese company was on the verge of this thing? What would it be rational for us to do? You know, if North Korea had it, it would, it would be rational to nuke them given what they say about their relationship with the rest of the. So it's um, well that kind of rational, that kind of power is. It's so life changing. It's so paradigm shifting, right? But if you have to wind this back to what someone like Neil degrasse Tyson would say, is that the only basis for fear is, yeah, don't give your superintelligent ai to the next Hitler, right? That's, that's obviously bad. But if we don't, if we're not idiots and we just use it, well, we're fine. And that I think is an intuition that is just, that's just a failure to, to unpack what is entailed by,

Speaker 2:          04:15:05       again, something like an intelligence explosion, a process that once, once you're, you're talking about something that is able to change itself and you have to get. So what would it be like to guarantee level? So we decide, okay, we're just not going to build anything that can make changes to his own source code. You know, any change to, to, to software to certain point is going to have to be run through a human brain. Um, and we're going to have veto power. Well, is every person working on ai going to abide by that rule? It's like what we agreed not to clone humans, right? But we're going to stand by that agreement for in the rest of human history and is, you know, is our agreement binding on China or Singapore or any other country that might think otherwise, it's just, it's a free for all and at a certain point we're going to be, you know, close enough, everyone's going to be close enough to making the final breakthrough that, um, unless we have some agreement about how to proceed if someone is going to get there first, that is a terrifying scenario of the future.

Speaker 2:          04:16:15       You know, you cemented this last time you were here, but not as extreme as this time. You seem to be accelerating the rhetoric. Exactly, yes. You're going deep. Boy, hope you're wrong. I'm on team Neil degrasse Tyson. This one go neil, um, and well and so in defensive of the other side too. I should say that. So David Deutsch also thinks I'm wrong, but he thinks I'm wrong because we will integrate ourselves with these machines. I mean, so this will be, there'll be extensions of ourselves and they can't help but be aligned with us because we will, we will be connected to them. That seems to be the only way we could all get along. We have to merge, become one, but I just think there's no, there's no deep reason why, like even if we decided to do that, right, like in the US or, or, or in half the world one, there's, I think there are reasons to worry that even that could go haywire, but there's no guarantee that someone else couldn't just build ai in a box.

Speaker 2:          04:17:16       I mean, if we're, if we can build ai such that we can merge our brains with it. Um, someone can also just build ai in a box, right? And, and that's, uh, um, and then, then you inherit all the other problems that people are saying, we don't have to worry about if it was a good Cohen brothers movie, it would be invented in the middle of the presidency of Donald Trump. And so then that's when ai would go live. And then ai would have to challenge Donald Trump. They'd would have like an insult contest, but that, that that's when this thing becomes so comically a terrifying. Whereas just just imagine Donald Trump being in a position to make the final decisions on topics like this for the country that is act is going to do this almost certainly in the near term. It's like, should we have a Manhattan project on this point, Mr.

Speaker 2:          04:18:10       President, um, you know, the idea that anything of value could be happening between his ears on this topic. We're 100 others like it I think is now really inconceivable. And so what, uh, what, what price could we, might we pay for that kind of inattention and, and self satisfied in attention to these kinds of issues? Well, this, this issue, if this is real and if this could go live in 50 years, this is the issue you're in. Unless we fuck ourselves up beyond repair before then and shut the power off if it keeps going. Yeah. No, I think it is. I think it is the issue, but unfortunately it's the issue that doesn't. It sounds like a goof. It does just sound. You sound like a crackpot even worried about this issue. It sounds completely ridiculous, but that might be what's how it's sneaking in?

Speaker 2:          04:19:05       Yeah. Yeah. I mean, it just, it. Just imagine that the tiny increment that would make suddenly make it compelling. I mean, just imagine, I mean chest doesn't do it because chess is so far from any central human concern. But just imagine if your, if your phone recognized your emotional state better than any than your best friend or your wife or anyone in your life and then did it reliably. Right? So as your body, like that movie with Joaquin for her, he falls in love with his phone. Right? I mean, that's just not, you know, that is not far off that far off. It's not, it's a very discreet ability. I mean, you could do that. You could do that without any, any other ability. And the phone really. It's like, it doesn't, it doesn't have to to, uh, stand on the shoulders of any other kind of intelligence. It could just, you know, you have. This could be, you could do this with just brute force in the same way that you have a great chess player that doesn't necessarily understand that it's playing chess. You could have some facial recognition, facial recognition of emotion and the and the tone of voice, recognition of emotion and the idea that it's gonna. It's gonna be a very long time for computers. They get better than people at that I think is is very far fetched.

Speaker 3:          04:20:24       I was thinking. Yeah, I think you're right. I was just thinking, how strange would it be if you had headphones on and your phone's in your pocket and you have rational conversations with your phone, like your phone knew you better than you know you like. I mean, I don't know what to do. I mean, I don't think I was out of line. She yelled at me. I mean, what should I say and I would have listened to every one of your conversations with your friends. Exactly. Train up on that. Just talk to you about it and go, listen man, this is what you gotta do. Your sounding angry. You got defensive. He got defensive. I apologize. Relax. Let's all move on. If you could accelerate it. Are you okay? You right man. Right man. And like you're talking to this little artificial. Maybe that's the first version of artificial intelligence. Uh, we suggest we go. All right. Let's give it a and like self help guys

Speaker 2:          04:21:06       in your phone of like a personal trainer in your phone. How to talk to girls and it's probably slow down. Slow down. You're talking too fast, Kinda cool. Yeah, that would, I mean literally like giving you information. They'll be like step one. That'd be like the Sony Walkman. Remember when you had a Walkman, like a cassette player that was like a VCR. I know when we were on our way to what we have today where you have 30,000 songs in your phone or something. I think I remember the first Walkman. The first thing I just want to, back when I skied, there was something called, it was called astral tunes or something. It was like, it was like a car radio that you could just put in a pack on your chest. Um, yeah it was. They kept coming out with those sounds they would get smaller and smaller, so then that little, the little dude would start telling you, Yo, man, dude, listen to keep replace me every year.

Speaker 2:          04:21:56       Just let them stick me in. Your brain will be together all the time. I've been given you good advice for years, Bro. Let me in your brain, and so you and this little artificial intelligence has you have a relationship over time. Eventually it talks you into getting your head drilled and screw it in there, and your artificial intelligence has always powered by your central nervous system. Have you seen most of these movies? Like did you see her and. No, I didn't know. And that was one of my top 10 all time favorite movies. Yeah, I love that movie. Actually. I like it. I saw it twice. I said I, I, I was slow to realize how well they did it. I mean, it was just the first time I saw it, I thought I wasn't as impressed and I watched it again and they really, first of all the performance of, of um, I forgot the actress's name. Uh, the candor candor is that with the woman who plays the robot in x, Makkah is just fantastic, but I'm scary. Good. Tuck you in anything.

Speaker 4:          04:23:01       We're getting a little full on time. Yeah, what do we like five hours and a half hours in? But I just got a note about this, about the Philip. Wait a minute. How many hours for a half hour computer's about to fill up. We did. We just did a four and a half hour. We were ready to keep going to Jesus. I, Jamie, didn't, you know what man, once you opened up that box up Pandora's box of shit and I've looked up, is there any sort of concept of autism and ai, like a spectrum of Ai, like Oh, there are dumb ai and there's going to be smart Ai.

Speaker 2:          04:23:34       Yeah, yeah, yeah, I know. So, I mean the scary thing. So yeah, it's like super autism. There's no, um, across the board there's, I think that super intelligence and motivation and goals are totally separable. So you could have a super intelligent machine that is purposed toward a goal that just seems completely absurd and harmful and non common sensical. And they said they, the example that Nick Bostrom uses in book superintelligence, which was a great book, um, and did more to inform my thinking on this topic than any other source. He talks about a paperclip maximizer. You could, you could build a super intelligent paperclip maximizer. Now, not that anyone would do this, but the point is you could build a machine that was, that was smarter than we are in every conceivable way, but all it wants to do is produce paperclips. Right now that seems counterintuitive, but there's no, there's no reason when you dig deeply into this, there's no reason why you couldn't build a superhuman paperclip maximizer just wants to turn everything, you know, just like literally the atoms in your body would be better used as paperclips.

Speaker 2:          04:24:43       Um, and so this is just a, the point he's making is that superintelligence could be very counterintuitive. It's not necessarily going to inherit everything we find, as you know, common sensical or, or emotionally appropriate or wise or desirable. It could be totally foreign, totally trivial in some way, you know, focused on something that means nothing to us but means everything to it because of some cork and how it's motivation system is structured and yet it can build the perfect nanotechnology that will allow it to build more paperclips. Right? So, um, and Lisa, at least I don't think anyone can see why that's ruled out in advance. I mean, there's no reason why we would intentionally build that, but the fear is we might build something that either is not perfectly aligned with our goals and our common sense and our, and our, um, aspirations and that it could form some kind of separate instrumental goals to get what he wants he wants that are totally incompatible with life as we know it.

Speaker 2:          04:25:55       And that's, you know, again, the, the examples of this are always cartoonish. Like, you know how I mean, Elon Musk said, you know, if you built up super intelligent machine and he told it to reduce spam, well then it could just kill all people as a great way to reduce spam, right? Um, but see the reason why that's law, if it's laughable, but you, you can't assume the common sense won't be there unless we've built it, right? Like, you have to have anticipated all of this. You can't, if you say take me to the airport as fast as you can. Again, this is Bostrom, you know, and you have a super intelligent automatic car. Um, you know, a self driving car, you'll just, you'll get to the airport covered in vomit because it'll just, it's just going to go as fast as it can go. Um, so it's a, it's our intuitions about what it would mean to be super intelligent necessarily are, are. Um, I mean there's no, we have to correct for them because I think our intuitions are bad. You're freaking me out and you've been freaking me out for over an hour and a half. Freaked out that we did four and half hours and I thought that's ridiculous. We're coming up on three, man. I hope wrong about all that stuff.

Speaker 3:          04:27:02       Maybe so it doesn't. It doesn't seem that. I don't know. It doesn't look that Rosie. Jamie, I'm sorry. I'm sorry. To be such a buzzkill. Look to the woods. Might have to figure out how to live off the land. You're the ultimate prepper. No, it ain't easy, man. Fucking I'm bad at it. I'll starve wellstar. I won't be a vegetarian. I'll come to your house for bear meat and it might get ugly. Folks, let's hope Sam Harris wrong. Thank you brother. Appreciate it. And your podcast. Tell people how to get us. Waking Up is my podcast and you can find it on my website, Sam Harris, dot org, or on itunes. You can get his book, one of his books if you go to audible.com, forward slash Joe, right? Isn't that get one? Go get one of those folks. All right, thank you ladies and gentlemen. Thank you Sam. That was awesome. Thank you bro.