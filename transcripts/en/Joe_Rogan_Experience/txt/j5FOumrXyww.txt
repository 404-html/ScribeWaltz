Speaker 1:          00:00:01       Four, three, two, one. Hello, lex. Hey, we're here man. What's going on? We're here. Thanks for doing this. You brought notes. You're seriously prepared when you're jumping out of a plane is best to bring a parachute. This is my parachute. I, I understand. Yeah. Um, how long have you been working in artificial intelligence? My whole life I think really? So when I was a kid

Speaker 2:          00:00:29       I wanted to become a psychiatrist. I wanted to understand the human mind. I think the human mind is the most beautiful mystery that our entire civilization is taken on exploring through science. I think you look up at the stars and the universe out there, you know, the grass Tyson here. It's an amazing, beautiful scientific journey that we're taking on and exploring the stars. But the mind to me is a bigger mystery, more fascinating and it's been the thing I've been fascinated by from the very beginning of my life. And just I think all of human civilization has been wondering, you know, what is in this inside this thing, the hundred trillion connections, they're just firing all the time. Somehow making the magic happen to where you and I can look at each other, make words all the fear or love life death that happens is all because of this thing in here and understanding why is fascinating and what I early on understood is that one of the best ways for me at least to understand the human mind is to try to build it and that's what artificial intelligence is. You know, it's, it's not enough to sort of from a psychology perspective, to study from a psychiatry perspective, to investigate from the outside. The best way to understand is to do

Speaker 1:          00:02:04       so. You meet almost like reverse engineering of brain. There

Speaker 2:          00:02:09       is some stuff. Exactly. Reverse engineering the brain. There's some stuff that you can't understand until you tried to do it. You can hypothesize you're. I mean we're both martial artists from various directions. You can hypothesize about what is the best martial art, but until you get in the ring like what the UFC did and test ideas is when you first realize that the touch of death that I've seen some youtube videos on, that you perhaps cannot kill a person with a single touch or your mind or telepathy, that there are certain things that work, wrestling works, punching works, okay, can we make it better? Can we create something like a touch of death? Can we figure out how to turn the hips, how to deliver a punch in the way that does do a significant amount of damage, and then you at that moment when you start to try to do it and you face some of the people that are trying to do the same thing, that's the scientific process and you try, you actually begin to understand what is intelligence and you begin to also understand how little we understand.

Speaker 2:          00:03:26       It's like a Richard Fineman who I'm dressed after today. Are you? Here's a physicist. I'm not sure if you're sure. Yeah, yeah, yeah. He always used to wear this exact thing, so I feel. I feel pretty bad ass wearing it. If you think you know astrophysics, you don't know astrophysics. That's right. Well, he said it about quantum physics. Quantum physics. That's right. That's right. Uh, so he was a quantum physicist and he kind of, I remember hear him talk about that understanding the nature of the universe of reality could be like an onion, we don't know, but it could be like an onion to where you think, you know, you're studying a layer of an onion and you peel it away and there's more and you keep doing it. And there's an infinite number of layers with intelligence. There's the same kind of component to what we think we know.

Speaker 2:          00:04:15       We got it. We figured out, we figured out how to beat the human world champion in chess, we solved intelligence and then we tried the next thing. Wait a minute, go is really difficult to solve as a game. And then you say, okay, I've, I came up when the game of go was impossible for artificial intelligence systems to be and have now recently had been beaten within the last like five years. Right? And the last five years, there's a lot of technical fascinating things of why that victory is interesting and important for artificial intelligence. It requires creativity, correct? It does not. It just exhibits creativity. So the technical aspects of why Alphago from Google deepmind, that, that was the designers and the builders of the system. That was the victor. They did a few very interesting technical things where essentially you develop a neural network.

Speaker 2:          00:05:14       This is this type of artificial intelligence system that looks at a board of go as a lot of elements on it is black and white pieces and is able to tell you how good is this situation and how can I make it better? And that idea. So chess players can do this. I'm not actually definitely with the game of go second speak. I'm Russian, so chest to us as romanticized. It's the beautiful game. Uh, I think that there you look at a board and all your previous experiences, all the things you've developed over tens of years of practice and thinking you get this instinct of what is the right path to follow. And that's exactly what the neural network is doing and some of the in

Speaker 3:          00:05:58       some of the paths it has come up with are surprising to other world champions. So in that sense it says, well, this thing's exhibiting creativity because it's coming up with solutions that are something that's outside the box. Thinking from the perspective of the human,

Speaker 4:          00:06:16       when why, what do you differentiate between requires creativity and exhibits creativity?

Speaker 3:          00:06:23       I think one because we don't really understand what creativity is and so it's almost.

Speaker 3:          00:06:33       It's on the level of concepts such as consciousness. For example, the question which there's a lot of thinking about whether creating something intelligent requires consciousness requires for us to be actual living beings aware of our own existence in the same way. Does doing something like building an autonomous vehicle, that's the area where I work in. Does that require creativity? Does that even require something like consciousness and self awareness? I mean, I'm sure in La there's some degree of creativity required to navigate traffic and in that sense you start to think, are there solutions that are outside of the box and ai system you use to create it? It's once you start to build it, you realize that to us humans, certain things appear at creative, certain things, dope, certain things we take for granted, certain things we find beautiful and certain things were like, yeah, yeah, that's.

Speaker 4:          00:07:30       Well, there's creativity in different levels, right? These creativity like to write the stand with Stephen King novel that requires creativity. There's something about his. He's creating these stories. He's giving voices to these characters. He's developing these scenarios and these dramatic sequences in the book that's going to get you really sucked in. That's, that's almost undeniable creativity, right? It. So it's a. he's imagining a world. What is it always set in a New Hampshire, Massachusetts, Maine, Maine. Right? So he's imagining a world and imagine the emotion of different levels surrounding that world. Yeah, that's, that's creative. Although if you. There's a few really good books, including his own that talks about writing a. yeah, he's got a great book on writing and it's actually called on writing. If there's anyone who can write a book on writing. Stephen King, I think Steven Pressfield, I hope I'm not saying the war of art and the Lore of art, beautiful book, and I would say if from my recollection they don't necessarily talk about creativity very much, that it's really hard work of putting in the hours of every day of just grinding it out. Well, pressfield talks about the muse. Pressfield speaks of it almost in like a strange, mystical, mystical sort of connection to the unknown because he, he almost,

Speaker 1:          00:08:56       I'm not even exactly sure if he believes in the muse, but he, he, I think if I could put words in his mouth, I have met him. He's a great guy. He was on the podcast once. I think the way he treats it as if you decide the muse is real and you show up every day and you write as if the Muse is real. You get the benefits of the muse being real. That's right. Whether or not there's actually a muse that's giving you these wonderful ideas

Speaker 2:          00:09:24       and what is the muse? So I think of artificial intelligence the same way. There's a quote by a Pamela, a mccormick from 1979 book that I really like. Uh, she talks about the history of artificial intelligence. Ai began with an ancient wish to forge the gods. And to me, God's broadly speaking or religions represents. It's kind of like the muse. It represents the limits of possibility, the limits of our imagination. So it's this thing that we don't quite understand. That is the muse, that is God that's us, US chimps are very narrow in our ability to perceive and understand the world. And there's clearly a much bigger, beautiful, mysterious world out there and God or the Muse represents that world. And for many people, I think throughout history and especially in in the past set of 100 years, artificial intelligence has become to represent that a little bit to the thing which we don't understand.

Speaker 2:          00:10:26       And we crave for both terrified. And we crave and creating this thing that is greater, that is able to understand the world better than us. And that in that sense, artificial intelligence is the desire to create the muse. This other, this imaginary thing. And I think the, one of the beautiful things, if you talk about everybody from Yamashta, Sam Harris, to all the people thinking about this, is that there is a mix of fear of that, of, of that unknown, of creating that unknown and an excitement for it because there's something in human nature that desires creating that. Because like I said, creating is how you understand.

Speaker 1:          00:11:10       Hm. Did you initially study biology? Did you study the actual development of the mind or what? What is known about the evolution of the human mind

Speaker 2:          00:11:21       of the human mind yet? So my path is different as it's the same for a lot of computer scientists and roboticists is we ignore biology, neuroscience, the physiology, anatomy of our own bodies, and there's a lot of beliefs now that you should really study biology and she's studying neuroscience. You should study your own brain, the actual chemistry. What's happening? What is actually how are the neurons are interconnected? All the different kinds of systems in there. So

Speaker 3:          00:11:54       that is a little bit of a blind spot or it's a big blind spot, but the problem is. So I started with more philosophy almost, it's where, um, if you think Sam Harris has last couple of years, it started kind of thinking about artificial intelligence and he, he has a back on your science, but he's also a philosopher and I started there by reading Camu and neat. You are dusty yefsky thinking what is, what is intelligence, what is human morality, a will. So all of these concepts give you the context for which you can then start studying these problems. And then I said there's a, there's a magic that happens when you build a robot that drives around. I mean, your father. I'd like to be, but I'm not yet. Uh, there's a creation aspect. That's wonderful. That's incredible. It's for me, I don't have any children at the moment, but the act of creating a robot where you programmed it and it moves around and a sense senses the world is, this is a magical moment. Did you see Alien Covenant is a Scifi Movie? Yeah. No

Speaker 1:          00:13:10       VRC near the alien films.

Speaker 3:          00:13:12       I, uh, so I grew up in the Soviet Union where we didn't watch too many movies. So I need to catch up,

Speaker 1:          00:13:20       we should catch up on that one in particular because a lot of it has to do with artificial intelligence. There's actually a battle between, spoiler alert to different but identical artificially intelligent synthetic beings that are there to aid the people on the ship. One of them is very creative and one of them is not. And the one that is not has to save them from the one that is. Spoiler alert, I don't want to tell you who wins, right? There's, there's a really fascinating scene at the very beginning of the movie where the creator of this artificially intelligent being is discussing its existence with the being itself and the beings trying to figure out who made him. And it's this really fascinating moment and this being winds up being a bit of a problem because it possesses creativity and it has the ability to think for itself. And May, uh, they found it to be a problem. So they made a different version of it which was not able to create. And the one that was not able to create was much more of more of a servant. And there's this battle between these two. I think you would find it quite fascinating. It's a really good movie.

Speaker 3:          00:14:43       Yeah. The same kind of theme carries through a mock in 2001 space odyssey. Sort of.

Speaker 4:          00:14:50       You've seen X. Yep. I've seen it. So because of your. I listened to your podcast and because because of it, I've watched it a second time because the first time I watched it and Neil degrasse Tyson moment where it was, you said there's cut, cut the cut the shit got the shit moments for me. For me, the movie

Speaker 3:          00:15:11       winning is everything. Everything about it was a, I was rolling my eyes rolling your eyes. What was the cut the shit moment. So that's a general bad tendency that liked to talk about amongst people who are scientists that are actually trying to do stuff that trying to build the thing and it's, it's very tempting to roll your eyes and to now in a lot of aspects of artificial intelligent discussion. So on. For me, there's real reasons to roll your eyes and there's just. Well, let me, uh, let me just describe it. So this person in Mokena, no spoiler alerts, uh, is in the middle, what, like a Jurassic Park type situation. Whereas like in the middle of a land that he owns,

Speaker 4:          00:15:56       yeah, we don't really know where it is not established, but you have to fly over glaciers and you get to this place and there's a river is. And he was fantastic compound. And inside this company appears to be working alone. Right? And he's like lifting

Speaker 3:          00:16:09       like he's like, I'm doing curls, I think like dumbbells and a drinking heavily. So the, everything I know about science, everything I know about engineering is it doesn't happen alone. So the situation of a compound with no hundreds of engineers they're working on this is not feasible. It's not feasible, it's not possible. And the other moments like that were the technical, the discussion about how it's technically done. They, they threw a few jargon despite stuff up and it makes, it doesn't make any sense.

Speaker 4:          00:16:49       Well that's where I am blissfully ignorant. So I watched it, I go, this movie's awesome. And you're like, ah, I know too much. Not too much, but that's, that's a stupid way to think for me. Uh, so once you suspend disbelief, say okay, well, right. Those are, those are not important details. Yeah, but it is important. I mean they could have gone to you or someone who really has knowledge in it and cleaned up those small aspects and still kept the, the theme of the story. That's right. They could have, but they would make a different movie. So that's slightly different. I don't know if it's possible to make. So you look at 2001 space odyssey. I don't know if you've seen that movie with it. That's the kind of movie you will start if you've talked to scientists that you'll start making those kinds of movies because

Speaker 3:          00:17:39       you can't actually use jargon that makes sense because we don't know how to build a lot of these systems. So the way you need to film it and talk about it is with mystery. Is this hedgehog type

Speaker 2:          00:17:50       like you almost, you say very little.

Speaker 4:          00:17:53       Yeah. Leave it to your imagination to see what happens here. Everything was in the open even in winter in terms of the actual construction of the brain that when they had that foam looking whatever gel brain, right? Yeah. He said if they gave a little bit more

Speaker 2:          00:18:10       ms Dot suttle mystery, I think I would have enjoyed that movie a lot more. But the second time really because of you, you say, I think it's your favorite Scifi.

Speaker 4:          00:18:19       It's absolutely one of my favorite side, one of my favorite movies, period. I loved it. Yeah.

Speaker 2:          00:18:24       So I, I, I, I watched it again and also Sam Harris said that he also hated the movie and then washed again and liked it. So I gave it. I gave it a chance. Why would you see a movie again after you hate it? Uh, because maybe you're self aware enough to think there's something unhealthy about the way I hated the movie. Like you're like introspective enough to know. It's like I have the same experience with Batman. Okay. I watched a which one? Dark night? I think it was Christian Bale, Christian Bale. And so to me, the first time I watched that is a guy in a costume, like speaking excessively with excessively low voice. I mean it was just something with like little bunny ears, not bunny ears, but the ears. It's so silly. But then you can go back and okay, if we just accepted those, that's the reality of the world we live in now. What's the human nature aspects that are being explored here? What is the, the beautiful conflict between good and evil as being explored here and what are the awesome graphics effects that are being on exhibit. Right? So if you could just suspend that, that's beautiful. The movie can become quite fun to watch, but still to me, not to offend anybody, but a bad superhero. Movies are difficult. It's still difficult for me to watch. Yeah. Who was talking about that recently? Was it Kelly?

Speaker 4:          00:20:01       Kelly slater? No, that was yesterday. Yesterday. Kyle. He's kind of a guy. He doesn't look super hero movies or something. He doesn't like superhero movies. We're talking about Batman, about Christian Bale's voice. And he's like, the most ridiculous thing was that he's actually Batman. Not those voice on Batman, that part of it is way less ridiculous than the fact that he's Batman is Batman because anybody could do that voice. Yeah. So, but I contradict. Um, I'm, I'm a hypocrite because game of thrones or Tolkien's, Lord of the Rings, I'm gonna tow. It's totally believable to me. Yeah, of course. Dragons and. Well that's a fantasy world, right? That's the problem with something like Batman or even Mokena is that it takes place in this world. Whereas they're in middle earth are in a place that doesn't exist. And if you. It's like if you like Avatar, if you make a movie about a place that does not exist, you can have all kinds of crazy shit in that movie because it's not real.

Speaker 4:          00:21:06       That's right. Yeah. So, but at the same time, like star wars, it's harder for me. And you're saying star wars is a little more real because it's, it's feels feasible. Like he could have spaceships flying around. Right? What, what's not feasible about star wars to. Oh, I'm not. I'll leave that one to the other undergrad size. He was getting angry about the robot. That's circular. Whatever rolls around. He's like slippery. Yeah, like trying to roll around all over the sand. It wouldn't work. It would get no traction. I was like, that's true. But if you had like glass tires and he tried to drive over sand, it was smooth. You'd get nothing. Yeah. Is, he's actually the guy that made me realize, you know the movie ghost with Patrick swayze and it was at this pockets or somewhere. He was talking about the fact that.

Speaker 4:          00:21:53       So this guy could go through the walls. Right. It's a beautiful romantic movie that everybody should watch. Right. But he doesn't seem to fall through chairs when he sits on them, right? Say he can walk through walls, but he can put his hand on the desk. You can sit like his. His blood has a magical shield that is in this reality. This is a quantum shield that protects them from falling. So. So that's, you know, those devices. Unnecessary movies. I get it in. Yeah. But you got a good point. He's got a good point to just cut the shit moments. They don't have to be there. You know, you just have to work them out in advance, but the problem is a lot of movie producers think that they're smarter than people. They just decided on, just put it in there. The average person is not going to care.

Speaker 4:          00:22:44       I've had that conversation with movie producers about martial arts and I was like, well, this is just nonsense. You can't do that. Like because I was explaining martial arts to someone and he was like, ah, the average person's not going to care. I'm like, oh, the average person. Okay, well you brought me in as a martial arts expert to talk to you about your movie and I'm telling you right now. This is horseshit. Yeah. I'm a huge believer, Steve jobs philosophy where forget the average person discussion because first of all, the average person will care. A steve jobs designed with really push the design of the interior of computers to be beautiful, not just the exterior. Even if you never see it, if you have attention to detail, to every aspect of the design, even if it's completely hidden from the actual user in the end, somehow that Karma, whatever it is that like love for everything you do and that loves seeps through the product. And the same. I think with movies, if you talk about space, the 2001 odyssey, there's

Speaker 2:          00:23:46       so many details. I think there's probably these groups of people that study every detail of that movie and other, um, cooper films, those little details matter. Somehow they all come together to show how deeply passionate you are about telling the story.

Speaker 1:          00:24:03       Well, Kubrick was a perfect example, right? Because he would put layer upon layer upon layer of detail and the films that people would never even recognize. Like there's a bunch of correlations between the Apollo Moon landings and the shining. You know, there's like people have actually studied it to the point where they think that it's some sort of a confession that Kubrick faked the moon landing because it goes from the little boy having the rocket ship on his sweater to the, the number of the number of the room that things happened. There's like a bunch of very bizarre connections in the film that Kubrick and questionably engineered because he was just a stupid, smart man. I mean, he was so goddamn smart that he would do complex mathematics for fun. No spare time. Kubrick was a legitimate genius and he engineered that sort of complexity into his films where he didn't have cut the shit moments in his movies. Not that I can recall.

Speaker 2:          00:25:02       No, not even close. This is very interesting. I mean, but that probably speaks to the reality of Hollywood today that the cut the shit moments don't affect the bottom line of how much the movie makes.

Speaker 1:          00:25:15       Well, it really depends on them film, right? I mean, the cut the shit moments that Neil degrasse Tyson found in gravity I didn't see because I wasn't aware of what the effects of gravity on a person's hair would be. You know, he saw it and he was like, this is ridiculous. And then there were some things like, why are these space station so close together? I just let it slide while the movie was playing, but then he went into great detail about how preposterous it would be. Those base stations were that close together. You get to them so quickly.

Speaker 2:          00:25:43       That's where the Sandra bullock and good looking guy and George Clooney. George Clooney. Yeah. Good looking guy. So that. Did that pass muster with that movie? No,

Speaker 1:          00:25:54       he tore it apart and when he tore it apart, people went crazy. They get so angry at him. Yeah. He reads the negative comments.

Speaker 2:          00:26:04       I actually recently, because of doing a lot of work with artificial intelligence and lecturing about and so on, have plugged into this community of folks that are thinking about the future of artificial intelligence, artificial general intelligence, and they are very much out of the box thinkers to where the kind of messages I get are our best. So I let it. I let them kind of explore those ideas without sort of engaging to those discussions. I think

Speaker 1:          00:26:31       very complex discussion should be had with people in person. That's what I think. And I think that when you allow comments, just random anonymous comments to enter into your consciousness like you were taking risks and you may, you may run into a bunch of really brilliant ideas that are, um, you know, coming from people that are considerate of thought these things through or you might just run into a river of assholes and it's entirely possible. And I peeked into my comments today on twitter. I was like, what in the fuck? I started reading a couple of them, some just morons and I'm like, all right, what about some shit? I didn't even know what the fuck they were talking about, but, but that's the risk you take when you dive in. You're going to get people that are disproportionately upset. You're going to get people that are disproportionately, you know, delusional or whatever it is in regards to your position on something or whether or not they even understand your position. They'll argue something that's an incorrect interpretation of your position.

Speaker 2:          00:27:36       Yeah, and you've actually, from what I've heard, you've actually been to this podcast and so on, really good at being open minded and it's something I try to preach as well. So in ai discussions when you're talking about Agi and talking about, so there's a difference between narrow ai and general artificial intelligence, narrow ais, the kinds of things that are the kind of tools that are being applied now and being quite effective. And then there's general ai which is a broad categorization of concepts that are human level or super human level intelligence. And when you talk about Agi, artificial general intelligence, there's seems to be two camps of people, ones who are really working deep in it. Like that's the camp. I kind of sit in and a lot of those folks tend to roll their eyes and just not engage in any discussion of the future.

Speaker 2:          00:28:28       The idea is saying it's really hard to do what we're doing and it's just really hard to see how this becomes intelligent. And then there's another group of people who say, yeah, but you're being very shortsighted that you may not be able to do much now, but the exponential, the hard takeoff overnight, it can become super intelligent and then it'll be too late to think about. Now the problem with those two camps, as with any camps, democratic republic, any camps, is they don't seem to be, seem to be talking past each other as opposed to both have really interesting ideas. If you go back to the analogy of a touch of death, a of this idea of MMA, right? So I'm the, in this analogy, I'm going to put myself in the UFC for a second. Uh, in this analogy, I'm, you know, like ranked in the top 20. I'm working really hard. My dream is to become a world champion. I'm training three times a day. I'm really working, I'm an engineer, I'm trying to build my skills up and then there's other folks that come along like Steven Seagal and so on that kind of talk about other of martial arts or other ideas of how you can do certain things and I think, I think Steven Seagal and could isn't mine beyond to something. I think we really need to be open minded, like a intro to civil. I think toxicity or somebody talks as well, right?

Speaker 1:          00:29:59       Well, Anderson Silva thinks Steven Seagal is. I want to put this in a respectful way. He understood so it has a wonderful sense of humor and Anderson Silva is very playful and he thought it would be hilarious if people believe that he was learning all of his martial arts from statistics to go. Got It. He also loves Steven Seagal movies legitimately so treated him with a great deal of respect. He also recognizes that Steven Seagal actually is a master of Ikea, though he really does understand the Quito and was one of the very first westerners that was teaching in Japan, speaks fluent Japanese, was teaching at a Dojo in Japan and is, you know, a legitimate master by Quito. Right. The problem with that Quito is it's, it's one of those martial arts that has merit in a, in a vacuum. They, if you, if you're in a world where there's no ncaa wrestlers or know judo players or no Brazilian Jujitsu, black belts or no, a Moitai kickboxers, there might be something to that Ikea stuff, but in the world we're, all those other martial arts exist and we've examined all the intricacies of hand to hand combat. It falls horribly short.

Speaker 2:          00:31:28       Let's see. This is the point I'm trying to make. You just said that we've investigated all the intricacies. You said all the intricacies of hand to hand combat. I mean, you're just speaking, but you want to open your mind to the possibility that I kito has, uh, some techniques that are effective that are affected.

Speaker 1:          00:31:47       Yeah. When I say all you're, you're correct. That's not a correct way of describing it because there's always new moves that are being like, for instance, I'm in this recent fight between Anthony Pettis and Tony Ferguson. Tony Ferguson actually used wing Chung in a fight. He, he trapped one of Anthony Pettis his hands and hit him with an elbow. He basically used a technique that you would use on a wing Chung dummy, and he did it in an actual world class, mixed martial arts fight and I remember watching it. Wow, go on this crazy motherfucker actually pulled that off because that's. It's a technique that you just rarely see anybody getting that proficient at it that, that fights in mma and Ferguson is extremely creative and open minded guy and he figured out a way to make that work in a world class fight. So. And let me then ask you the question there.

Speaker 1:          00:32:44       There's these people who still believe in quite a lot of them that there is this touch of death. Right. Do you. So do you think it's possible to discover through this rigorous scientific process that is mma that started pretty recently, do you think, not the touch of death, but do you think we can get a 10 x improvement in the amount of power the human body can, can generate in, in, and punching? No, no, certainly not. 10 acts. I think you can get incremental improvements, but it's all based entirely on your frame. Like if you're a person that has very small hands and narrow shoulders, you're kind of screwed. There's not really a lot of room for improvement. You can, you can certainly get incremental improvement and your ability to generate power, but you'll never be able to generate the same kind of power as say a guy with a very big frame like a brock lesnar or Derrick Lewis or um, you know, anyone who has. There's like classic elements that go with being able to generate large amounts of power wide shoulders, large hands. There's, there's a lot of characteristics of the human frame itself. Um, those, even those people, there's only so much power you can generate and we pretty much know how to do that correctly.

Speaker 3:          00:34:04       So the way you're talking about as a martial arts expert now is kind of the way a lot of the experts in robotics and ai talk about ai and when the topic of touch of death is brought up, now the analogy is not perfect. I tend to use probably too many analogies is

Speaker 1:          00:34:22       we maybe know the human body butter that we know the possibility of Ai, I would assume so, right? He has the possibility of ai is basically limitless. Once ai starts redesigning itself,

Speaker 3:          00:34:34       it's not obvious that that's true. Our imagination allows it to be true. When I, I'm of two minds, I am, I, I'm, I'm both, I can hold both beliefs that are contradictory in my mind. One is that idea is really far away, almost bordering and bs. And the other is it can be there overnight and I think you can believe both of those things. So, um, there's another, a quote from Barbara wouldn't, it's a poem I've heard on a, on a, on a lecture somewhere that I really like, which is, it's from the champions of the impossible rather than the slaves at the possible, that evolution draws his creative force. So I see a mosque as a representative of the champion of the impossible. I see exponential growth of ai within the next several decades as the impossible, but it's the champions of the impossible that actually make the impossible happen. Why would a

Speaker 1:          00:35:35       exponential growth of AI impossible? Because that seems inevitable to me.

Speaker 3:          00:35:41       So it's not impossible and I'm sort of using the word impossible. Meaning magnificent. The, yeah, it feels very difficult. Very, very difficult. We don't even know where to begin brand yet. Like the touch of death actually feels. I would see the touch of death is horseshit, but see you're an expert.

Speaker 1:          00:35:59       Ah, and they touch you in the chest, but we don't have the ability in the body to generate

Speaker 3:          00:36:04       that kind of energy. How do you know that? That's a good question. Um, it's never been done. We understand study notes. Never Been, how do you know it's never been done. There could be someone out there with magic that I. That has escaped my grasp. I know you've studied, you've talked about with a Graham Hancock and you've talked about the history. Maybe it was in Roman times. There was that idea was discovered and then it was lost because weapons and much more effective ways of, uh, of delivering damage. Now I find myself in a very uncomfortable position of defending the concept as a martial artist, a defining the concept of martial arts. Did you study a Jujitsu and judo and wrestling, wrestling

Speaker 1:          00:36:49       the hard ones? Jitsu, judo and wrestling. Those are absolute martial arts in my opinion. This is what I mean. Like if you are a guy who just has a fantastic physique and incredible speed and ridiculous power, just you just congergate ridiculous power. If you just are just a per, you know who deontay wilder is?

Speaker 3:          00:37:12       Yes. He would champion the world boxer. He's a fee. You have, what's his name? Tyson fury on tomorrow. Two undefeated guys, right? Yes.

Speaker 1:          00:37:21       Deontay wilder has fantastic power. I mean, he just knocks people flying across the ring. He's just, I think deontay wilder, if he just came off the street, if he was 25 years old and no one ever taught them how to box it all and you just wrapped his hands up and had him hit a bag, he would be able to generate insane amounts of force. Now, if you're a person that really didn't have much power and you had a box with deontay wilder and you were both the same age and you are a person that knew boxing and you stood in front of Deontae, it's entirely possible that deontay wilder could knock you into another dimension, even though he had no experience in boxing. If he just held on you and hit you with a haymaker, he might be able to put you out. If you're a person who is, let's say, built like you and a guy who exercises who strong, and then there's someone who's identically built like you who's a black belt in Brazilian Jujitsu and you don't have any experience in martial arts at all, your fucked right? Yes. If you're a person who's built like you who's a, a guy who exercises and is healthy and you grapple with the guy who was even stronger than you and bigger than you, but he has no experience in Brazilian Jujitsu, he's still fucked. That's the difference. That's why I think Brazilian Jujitsu and judo and wrestling and particularly those are absolutes in that you have control of the body and once you grab a hold of a person's body, there's no lucky triangle chokes in Jujitsu. That's right. Right.

Speaker 3:          00:39:00       I think, uh, I think I would say Jujitsu as the highest representative of that. I think in wrestling and judo, having practiced those, I've never been quite as humble and as I have been in Jujitsu. Yeah. Especially when I started, I was power lifting. I was like, I was a total meathead and you know, a 130 pound guy or girl could tap you easily. Yeah. It's confusing. It's very confusing in wrestling, you can get pretty far with that. Had power in judo, a little bit less so at its highest levels at if you go to Japan, for example, where they, I mean the whole dream of judo is effortlessly throw your opponent, but in, you know, if you go to gyms in America and so on, you know, there is some hard wrestling style gripping and just beating each other up pretty intensely where we're not talking about beautiful tomatoes are these beautiful throws were talking about some scrapping some, uh, some wrestling style.

Speaker 1:          00:40:05       Yeah. Yeah. No, I see what you're saying. Yeah. Um, my experience with Jujitsu was very humbling when I first started out. I was a, had a long background in martial arts and striking and uh, even wrestled in high school and then I started taking Jujitsu and a guy who was my size and I was young at the time and he was basically close to my age, just mauled me. And he wasn't even a black belt. I think he was a purple belt. He might've been a blue belt. I think it was a purple belt. Um, and it just destroyed me. Just did anything he wanted to be choked me, arm barred me just and I remember thinking, man, I am so delusional. I thought I had a chance. I thought just based on taking a couple classes and learning what an Armbar is and then being a strong person who has a background in martial arts that I would be able to at least hold him off a little bit.

Speaker 3:          00:40:58       No, and this is a uh, that's so beautiful that I feel lucky to have that had that experience of having my ass kicked. And Philadelphia is where I came up with because in science you don't often get that experience in the space of ideas. You can't, uh, you can't choke each other out. You can't beat each other up and science. And so it's easy to go your whole life. I have so many people around me telling me how smart I am a, there's no way to actually know if I'm smart or not because I think I'm full of bs and in the same,

Speaker 2:          00:41:35       uh, I in the same round is fighting. There's no, it's Hixon Gracie said it means the or some of the solid rubber or somebody that the math doesn't lie. There's this deep honesty in it that was really grateful. Almost like wanting to talk about bullies. Are you talking about or even just my fellow academics could benefit significantly from training a little bit. I think so too. It's a, it's a beautiful thing to almost, I think has been talked about in high school, sort of requiring it, thinking about the meantime. So I think it's a more humbling sport to be honest than wrestling because you could in wrestling, like I said, get away with some muscle.

Speaker 1:          00:42:19       It's also what martial arts we're supposed to be in that a small person who knows technique can beat a big person who doesn't know the technique. That's right. That's what we've always hoped for. Right. When we saw the Bruce Lee movies and Bruce Lee who was a smaller guy can beat all these bigger guys just because he had better technique that is actually real in Jujitsu and it's one of the only martial arts where that's a real. Yeah. And I, uh, I haven't

Speaker 2:          00:42:42       in Philadelphia. It started, we had Steve Maxwell here. Sure. That's kind of where the, that was the spring of Jujitsu in Philadelphia.

Speaker 1:          00:42:49       Yeah. He was one of the very first American black belts in Jujitsu. Like way back in the day, I believe he was a black belt in the very early nineties when Jujitsu was really just starting to come to America and he had Max innercise in Philadelphia.

Speaker 2:          00:43:04       It's still there. And then I trained at a balance which is a, a few gracie folks. Which film? Inglorious rake, mcglynn Hays basketball. Go brothers. So it, I mean, especially Vogel brothers, these couple of black belts, they come up together. Is there. Well, they're smaller, the little guys. And I think those were the guys that really humbled me pretty quickly.

Speaker 1:          00:43:28       Well, little guys are the best to learn technique from. Yeah. Because they can't rely on strength. There's a lot of really big, powerful, you know, 250 pounds Jujitsu guys who never are going to develop the sort of subtlety of technique that some like the Mayo brothers, like smaller guys who just, they've from the very beginning, they've never had an advantage in weight and size and so they've never been able to use anything but perfect technique. Eddie Bravo is another great example of that too. You know, he, he competed in the 140 pounds, 145 pound class, you know, um, but to get back to artificial intelligence. So the idea is that there's two camps, there's one camp that thinks that the exponential increase in technology and that once artificial intelligence become sentient, it could eventually improve upon its own design and literally become a god in a short amount of time. And then there's the other school of thought that thinks that is far outside of the realm of what is possible today. That even the speculation of this eventually taking place is kind of ludicrous to imagine.

Speaker 3:          00:44:42       Right. Exactly. And the balance needs to be struck because I think I'd like to talk about sort of the short term threats that are there and it's really important to think about, but the longterm threats, if they come to fruition, will overpower everything. Right? That's really important to think about, but what happens is if you think too much about the encroaching doom of humanity, there is some aspect to it that is paralyzing where you almost. It turns you off from actually thinking about the these ideas. There's something so appealing. It's like a black hole that pulls you in and if you notice folks at Sam Harrison, so on spend a large amount of the time talking about the negative stuff about something that's far away. Not to say it's not wrong to talk about it, but they spend very little time about the potential positive impacts in the near term and also the negative impacts of the near term.

Speaker 3:          00:45:45       So let's go over those fairness so that way the more and more we put decisions about our lives into the hands of artificial intelligence systems, whether you get a loan or a in the autonomous vehicle context or in terms of recommending jobs for you on Linkedin or all of these kinds of things, the idea of fairness becomes a bias in these machine learning systems becomes a really big threat because the way current, the way current artificial intelligence systems function is they train on data. So there's no way to, for them to somehow gain a greater intelligence than our, than the data we provide them with. So we provide them with actual data and so they carry over if we're not careful, the biases in that data, the discrimination that's inherent in our current society is as represented by the data. So they'll just carry that forward.

Speaker 3:          00:46:48       Like also a. So there's people working in this, uh, more so to see, to show really the negative impacts in terms of getting a loan or whether to say whether this particular human being should be convicted or not of a crime. Uh, there's, there's ideas there that can carry, you know, in our criminal system there's discrimination and if you use data from that criminal system to then assist the ciders, judges, juries, lawyers in making this community and make a decision of what kind of policy person gets, they're going to carry that forward. You mean like racial economic bias is racial economic? Yep. Geographical. And that's a sort of, I don't say that exact problem, but it's, it's, you're aware of it because of the tools we're using it only. So the two ways that I'd like to talk about neural networks with the jail do it.

Speaker 3:          00:47:53       Okay. So the current approaches are, there's been a lot of, uh, demonstrated improvements, exciting new improvements in our advancements of artificial intelligence. And those are for the most part have to do when your networks, something has been around since the 19 forties has gone to, to ai winters where everyone was super hyped and then super bummed and super hyped again and bombed again. And now we're in this other hype cycle. And what you'll know xr is these collections of interconnected simple compute units. They're all similar. It's kind of like it's inspired by own brain where have a bunch of little neurons interconnected and the idea is these interconnections are really dominant and random, but if you feed it with some data, they'll learn to connect just like they're doing our brain in a way that interprets that data. They formed representations of that data and can make decisions, but there's only two ways to train those neural networks that we have.

Speaker 3:          00:48:54       Now. One is we have to provide a large data set. If you want that annual now could tell the difference between a cat and dog. You have to give it 10,000 images of a cat and $10,000 with a dog. You need to give those images and who tells you what a picture of a cat and a dog is. It's humans, so it has to be annotated. So as teachers of these artificial intelligence systems, we have to collect this data. We have to invest a significant amount of effort and annotate that data and then we teach neural networks to make that prediction. The what's not obvious there is how poor of a method there is to achieve any kind of greater degree of intelligence. You're just not able to get very far besides very specific narrow tasks of cat versus dog or a, should I give this person a loan or not? These kinds of simple simple tasks, I would argue autonomous vehicles that are actually beyond the scope of that kind of approach. And then the other realm of where you know networks can be trained is if you can simulate that world. So if the world is simple enough or it's conducive to be formalized sufficiently to where you can simulate it. So a game of chess is just, it's rules him a golden rule so you can simulate it. They had. The big exciting thing about Google deep mind is that there able to beat

Speaker 3:          00:50:28       the world champion by doing something called competitive self play a, which is the two systems play against each other. They don't need the human, they play against each other, but that only works and that's a beautiful idea and super powerful and really interesting and surprising, but that only works on things like games and simulation. So now if I wanted to, uh, sorry to be going to analogies of like USC for example, if I wanted to train the system to become the world champion, uh, be uh, what's his name? Numbering them add up, right? I could play the UFC game, I could create the, you networks that play, use competitive self play to play in that virtual world and they could become state of the art, the best fighter ever in that game. But transferring that to the physical world, we don't know how to do that.

Speaker 3:          00:51:25       We don't know how to teach systems to do stuff in the real world. So some of the stuff that freaks you out often is Boston dynamics robots. Yeah. Does every day I go to the instagram page and just go, what the fuck are you guys doing? So, uh, nearing our demise. Mark Graber CEO is a spoke of the class I taught. He is a, he calls himself a bad boy of robotics, so he's having a little fun with it. He should definitely stop doing that. Don't call yourself a bad boy if anything. That's true. How old is he?

Speaker 3:          00:51:59       Okay. He's one of the greatest roboticists of our generation, so that's wonderful. How would you call yourself a. don't call yourself a bad boy, bro. Okay, so you say you're not the bad boy of MMA? Definitely not, but I'm not even the bad man. Bad Man, but definitely not a bad boy. Okay. That's a little silly. Yeah. The those robots are actually functioning in the physical world. That's what I'm talking about. And they are using something called always I think coined, I dunno, seventies or eighties. The term good old fashioned ai meaning there is nothing like going on that you would consider artificial intelligence, which is usually connected to learning. So these systems aren't learning. It's not like you dropped a puppy into the, into the world and you kind of stumbled around and figuring stuff out and learns and gets better and better and better and better.

Speaker 3:          00:53:01       That's the scary part. That's the imagination that that's what we imagined is we put something in this world at first it's like harmless and falls all over the place and all of a sudden they figure something out and like Elon Musk says the travels faster than whatever. Then you can only see what the problem is. There's no learning component there. This is just purely there's hydraulics and electric motors and there is 20 to 30 degrees of freedom and it's doing hardcoded control algorithms to control the task of how do you move efficiently through space. So this is the task of this work on a really, really hard problem is taking a robotic manipulation, taking arm, grabbing a water bottle and lifting it super hard for the somewhat unsolved to this point and learning to do that. We really don't know how to do that right,

Speaker 1:          00:53:57       but this is what we're talking about essentially is the convergence of these robotic systems with artificial intelligence systems, right? And as artificial intelligence, intelligence systems evolve and then this convergence becomes complete. You're going to have the ability to do things like the computer that beat humans at go. You're going to have creativity, you're going to have a complex understanding of language and expression, and you're going to have perhaps even engineered things like emotions like jealousy and anger. I mean it's, it's entirely possible, but as you were saying, we're going to have systems that could potentially be biased the way human beings are biased towards people of certain economic groups or certain geographic groups and you would use that data that they have to discriminate just like human beings discriminating. What if you have all that in an artificially intelligent robot that has autonomy and that has the ability to move. This is what people are totally concerned with and terrified of is that all of these different systems that are currently in Semite crude states, they can't pick up a water bottle yet. They can't really do much other than they can do back flips, but they. You know, I'm sure you've seen this, the more recent Boston dynamic ones, powercore yeah, I saw that one the other day. It's good. They're getting better and better and better, and it's. It's increasing every year. Every year there's new abilities. Did you see the Black Mirror episode? Heavy metal?

Speaker 3:          00:55:30       Yeah, and I think about quite a lot because it's a functionally it has. We know how to do most aspects of that right now. Right now. When you close. Yeah, pretty close. I mean I. I don't remember exactly. There's some kind of pebbles shooting situation where it like hurts you by shooting you somehow. I figured. Well, it has bullets, didn't it? Bullets. Yeah. Is it basically a gun?

Speaker 1:          00:55:54       It had a knife. It stuck into one of its arms. Remember and come the spoiler alert. It's just an amazing episode of how terrifying it would be if some emotionless robot with incredible abilities is coming after you and wants to terminate you

Speaker 3:          00:56:09       and I think about that a lot because I love that episode because it's terrifying for some reason, but when I sit down and actually in the work we're doing, think about how we would do that so we can do the actual movement of the robot. Well, we don't know how to do is to have robots that do the full thing, which is have some, have, have a goal of pursuing humans and eradicated. I'm not spoiler alert all over the place. Uh, I think the goal of eradicating human, so assuming their values are not aligned somehow, that's one we don't know how to do that. And two is the entire process of just navigating all over the world is really difficult. So we know how to go up the stairs. But to say how to navigate the path you took from home to the studio today, how to get through that full path is so much an unsolved problem.

Speaker 1:          00:57:06       But is it because you could do, you could engineer or you could program it into your tesla. You can put it into your navigation system and have it stop at Red Lights drive for you take turns and it can do that.

Speaker 3:          00:57:18       So first of all, that I would argue is quite far away from still, but that's within 10, 20 years. But what, how much can it do now? It can stay inside the lane, on the highway or on different roads and it can change lanes, and what's being pushed now is they're trying to be able to enter and exit the highway, so there's some basic highway driving. It doesn't stop at traffic lights, it doesn't stop at stop signs and it doesn't interact with the complex irrational human beings, pedestrians and cyclists, cars. That's. This is the onion I talked about is we first in 2005, the Darpa grand challenge. Dopper organized this challenge in the desert says, let's go across the desert. Let's see if we can build an autonomous vehicle that goes across the desert. Two thousand four, the first one and everybody failed. We're talking about some of the smartest people in the world and really tried and failed and so they did.

Speaker 3:          00:58:18       Again, 2005. There's a few. Stanford one is a really bad ass guy from Cmu. Read that. I think he's like a marine. He led the team there and they succeeded. The fourteens finished Stanford, one that was in the desert and there was this feeling that we solved the autonomous driving, but that's that onion because you then, okay, what's the next step? We've got a card that travels across the desert autonomously. What's the next? So then 2007. They did the urban grant challenges, the urban challenge. Darpa urban challenge where you drove around the city a little bit and again, super hard problem. People took it on a Cmu one. That one, the Stanford second I believe, and then there was definitely a feeling like, yeah, we now the car drive around the city. It's definitely solved. The problem is those cars were traveling super slow first of all, and second of all there's no pedestrians.

Speaker 3:          00:59:17       There's no. It wasn't a real city. It was an artificial. It's just basically having to stop and different signs again, one other layer of the onion and he'd say, okay, when we actually have to put this car in a city like La, our, we're going to make this work because if there's no cars in the street and no pedestrians in the street driving around is still hard but doable and I think solvable the next five years when you put pedestrians, everybody Jaywalks if you put human beings into, into this interaction, it becomes much, much harder. Now. It's not impossible and I think it's very doable and with completely new interesting ideas, including revolutionizing infrastructure and rethinking a transportation in general, it's possible to do the next five, 10 years, maybe 20, but it's not easy like everybody says. And does anybody say it's easy? Yeah. This, uh, the, there's a lot of height between autonomous, behind the autonomous vehicles. Elon musk himself and other people have promised autonomous vehicles that that timeline is already past. That has been going on in 2018. We'll have autonomous vehicles now for ge

Speaker 1:          01:00:33       semiautonomous now. Right? So I know they do. They can break for pedestrians. Like if they see pedestrians are supposed to break for them and avoid them, right?

Speaker 3:          01:00:42       That's part of the technically no.

Speaker 1:          01:00:45       Was that an issue with an Uber Car that hit a pedestrian that was operating autonomously? Someone, a homeless person stepped out off of a median, right into traffic and it nailed it. And then they found out it didn't have just one of the settings

Speaker 3:          01:00:58       wasn't in place. That's all right. But that wasn't autonomous vehicles being tested in Arizona. And uh, unfortunately there's a fatality. A person, a person died at. Pedestrian was killed. So what happened there? That's the, that's the thing I'm saying is really hard. That's full autonomy. That's technically when the car, you can remove the steering wheel in the car to drive itself and take care of everything. Everything. I've seen, everything we're studying, we're studying drivers and Tesla vehicles. We're building our own vehicles. It seems that it will be a long way off before console the fully autonomous driving problem because of pedestrians and. But two things and pedestrians and cyclists and the edge cases are driving all this stuff we take for granted. The same reason we take for granted how hard it is to walk, how hard it is to pick up this bottle, our intuition about what's hard and easy is really flawed as human beings.

Speaker 1:          01:01:56       Can I interject what if, uh, all cars were autonomous? That's true. If we got to a point where every single car on the highway is operating off of a similar algorithm or off the same system, then things would be far easier, right? Because then you have to, don't, don't deal with random kinetic movements. People just changing lanes, people looking at their cell phone, not paying attention to what they're doing. All sorts of things that you have to be wary of right now. Driving and pedestrians and bicyclists.

Speaker 3:          01:02:24       Totally. And that's, that's in the realm of things I'm talking about where you think outside the box and, and revolutionize our transportation system that requires government to, uh, to play along.

Speaker 1:          01:02:36       It seems like that's going that way though, right? Do you feel like that one day we're going to have autonomous driving pretty much everywhere, especially on the highway.

Speaker 3:          01:02:46       It's not going there in terms of, uh, it's, it's very slow moving. So if government does stuff very slow moving with infrastructure, one of the biggest things you can do for autonomous driving will solve a lot of problems is to paint lane markings regularly. And even that sucks have been extremely difficult to do for, for, for. Yeah, for a politician

Speaker 1:          01:03:11       because right now there's not really the desire for it. But to explain to people what you mean by that. When the lanes are painted very clearly, the cameras and the autonomous vehicles can recognize them and stay inside those lines much more easily.

Speaker 3:          01:03:23       Yeah. There is two ways that car see the world. Three different sensors. The big ones for autonomous vehicles is lidar, which is these lasers are being shuttled over the place and three 60 and they can give you this point cloud or how far stuff as a way, but they don't give you the visual texture information of this is what brand water bottle they are. And cameras give you that information. So what Tesla is using have eight cameras, I think is they perceive the world with, with, uh, with cameras, and those two things require different things from the infrastructure. Those two sensors, cameras see the world, the same arc as are humanized, see the world. So they need the lane markings, they need infrastructure to be really nicely visible, traffic lights to be visible. So the same kind of things as humans like to have is the cameras like to have. And landmark is a big one. The other, there's a lot of interesting infrastructure improvements that can happen. Like traffic lights or traffic lights are super dumb right now. They sense nothing about the world, about the density of pedestrians, about the approach and cars. If, if, if traffic lights can communicate with the car, which it makes perfect sense, it's a, it's a, it's right there, there's no size limitations. It can have a computer inside of it. Uh, you can coordinate different things that in terms of the same pedestrian kinds of problem.

Speaker 1:          01:04:53       Well, we have sensors now in streets. So when you pull up to certain lights, especially at night, um, the light will be red, you pull up an instantaneously turns green because it recognizes that you've stepped over or driven over a sensor.

Speaker 3:          01:05:05       That's right. So that's a, that's a step in the right direction, but that's really sort of crew 20 years, 30 years ago, technology. So you want to have something like the power of a smartphone inside

Speaker 2:          01:05:18       every traffic light. It's pretty basic to do, but there is way outside of my expertise is how do you get government to do these kinds of improvements.

Speaker 1:          01:05:26       So if I'm mistaken, correct me if I'm mistaken, but you're, you're looking at things in terms of what we can do right now, right? And a guy like Elon musk or Sam Harris is saying, yeah, but look at where technology leads us. If you go back to 1960, the kind of computers that they use to do the Apollo mission, you've got a whole room full of computers that doesn't have nearly the same power as the phone that's in your pocket right now. Now if you go into the future and exponentially calculate like what's going to take place in terms of our ability to create autonomous vehicles or ability to create artificial intelligence and all of these things going from what we have right now to what could be in 20 years where we very well might look at some sort of an artificial being that can communicate with you some sort of an x mark and that type creature. I mean, that's, that's not outside the realm of possibility at all.

Speaker 2:          01:06:30       You have to be careful with the at all part at all. Uh, it's our ability to predict the future is really difficult. But I agree with you. It's not outside the realm of possibility. Yeah. And the thing, there's, there's a few examples that brought along just because I enjoy these predictions. So the, the, the, of how bad we are predicting stuff from the engineers. The very guys and gals like me sitting before you made some of the worst predictions in history in terms of both pessimistic and optimistic. The Wright brothers, one of the Wright brothers before they flew in 19. Oh, three predicted two years before that it will be 50 years. I confess that in 19. Oh one. That's one of the brothers talking. I said to my brother, Orville, that man would not fly for 50 years. Two years later, we ourselves were making flights. This demonstration of my inability as a prophet gave me such shock that I have ever since distress them myself and have refrained from all prediction. That's one of the Wright brothers, one of the people working in the past

Speaker 1:          01:07:42       mystic estimation versus an optimistic as explanation or A. Exactly.

Speaker 2:          01:07:48       And, and the same with a Albert Einstein for me, made these kind of pessimistic observations, uh, for me, three years before they, the first critical chain reaction as part of the, he led the nuclear development, the bomb. He said that it would, he has 90 percent confidence. That's impossible three years before. Okay. So that's on the pessimistic side. On the optimistic side, the history of ai is laden with, with optimistic predictions. Uh, the,

Speaker 3:          01:08:16       in uh, 19, 65, one of the seminar

Speaker 4:          01:08:19       people in ai, Herbert Simon said machines will be capable within 20 years of doing any work command can do. He also said within 10 years of digital computer will be the world chess champion that's in 58 and we didn't do that until 90 something 90 years and 40 years. But that's one person. It's a guy taking a stab in the dark based on what data and what's he, what's he based this off of our imagination. We have more data points now though, don't you think in terms of. No, not about the future. That's the thing, not about the future, but about what's possible right now.

Speaker 3:          01:08:53       Right? And if you look at the past is a really bad predictor of the future. If you look at the past, what we've done, the immense advancement of technology has given us in many ways optimism about what's possible, but exactly what is possible. We're not good at. So I am much more confident that the world will look very fascinating. The different in the future, whether ai will be part of that world is unclear. It could be we will all live in a virtual reality world for or for example, one of the things I'm really think about is to me a s s a really dumb ai on 1 billion smartphones is potentially more impactful than a superintelligent ai on one smartphone. That the, the, the fact that everybody now has smartphones, this kind of access to information, the way we communicate the, the globalization of everything, the potential impact there of just even subtle improvements in ai could be. It could completely change the fabric of our society in a way where these discussions about an ex, that type lady walking around will be silly because we'll all be either living on Mars or living in virtual reality or in this. There's so many exciting possibilities and what I believe in is we have to think about them. We have to talk about them. Technology's always the source of danger, of risk.

Speaker 3:          01:10:32       All of the biggest things that threatened our civilization at the small and large scale all are connected to misuse of technology. We develop and at the same time it's that very technology that will empower us and save us. So there's a Max tegmark brilliant guy, like three point zero. I recommend people read his book on artificial general intelligence. He talks about the race that there there's a, there's a race that can't be stopped. One is the development of technology and the other is the development of our wisdom of how to stop or the how to control the technology and it's this kind of race and

Speaker 2:          01:11:14       our wisdom is now is always one step behind and then that's why we need to invest in it and keep sort of, keep always thinking about new ideas. So right now we're talking about Ai. We don't know what it's going to look like in five years. We have to keep thinking about. We have to through simulation, explore different ideas through conferences, have debates come up with different approaches of how to solve particular problems. Like I said, with bias or how to solve deep fakes where you fake. You can make Donald Trump or president of foreign president Obama saying anything or you can have facebook advertisement. Harvard hypertargeted a advertisements how we can deal with those situations and constantly have this race of wisdom versus, uh, the development of technology but not to sit and think, well, look at the, you know, look at the development of technology, imagine what it could do in 50 years and we're all screwed because that's important to sort of be nervous about it in that way, but it's not conducive to what do we do about it and the people that know what to do about it are the people trying to build this technology, building this future once

Speaker 1:          01:12:33       I didn't know what to do about it because like, well let's, let's put it in terms of Elon Musk, right? Like Elon Musk is terrified of, of artificial intelligence because he thinks by the time it becomes sentient, it'll be too late. It'll be smarter than us. And we'll, we'll have essentially created our successors. Yes. And let me quote Joe Rogan and say that's just one guy. Yeah. Well Sam Harris thinks the same thing. Yes. And there's quite a few people that think that Sam Harris. Okay.

Speaker 2:          01:13:01       I think was one of the smartest people I know and Ilan mosque intelligence aside is one of the most impactful people I know. He's actually building these cars and in the narrow ai sense, if he's built these autopilot system that we've been studying, the way that system works is incredible. It was very surprising to me on many levels. It's an incredible demonstration of what ai can do in a positive way in the world. So I don't know, but I people can disagree.

Speaker 1:          01:13:35       I'm not sure the functional value of his fear about the possibility of this. Correct. There's functional value in pitting the brakes before this takes place. The just just to be a person who's standing on top of the rocks with a light to warn the boats. Hey, there's a rock here. Like pay attention to where we're going because there's perils ahead. I think that's what he's saying. That's an. I don't think there's anything wrong with saying that and I think there's. There's plenty of room for people saying what he saying and people saying what you're saying. I, what would hurt us is if we tried to silence either voice. I think what we need in terms of our understanding of this future is many, many, many, many, many of these conversations where you're dealing with the, the current state of technology versus a bunch of creative interpretations of where this could go and have discussions about where it should go or what could be the possible pitfalls of any current or future actions. I don't think there's anything wrong with this. So when you say like what's the benefit of thinking in a negative way? Well, it's to prevent our demise.

Speaker 3:          01:14:54       So totally I agree on a percent nae negativity or worry about the existential threat is really important to have as part of the conversation, but there's this level, there's this line. It's hard to put into words is it is a line that you cross when that worry becomes hyperbole. Yeah, and then it. There's something about the human psyche where it becomes paralyzing for some reason. Right now when I have beers with my friends than none ai folks, we actually go, we crossed that line all day and have fun with it. I talked to she get you drunk right now. Maybe a regret every moment of it. This I talked to Steve Pinker a enlightenment. Now his book kind of highlights that, that kind of, um, that he's totally doesn't find that appealing because that's crossing all realms of rationality and reason. Would you say that appealing?

Speaker 3:          01:15:52       What do you mean crossing the line into what will happen in 50 years? What could have happened? He doesn't find that appealing. It doesn't find it appealing because he's studied and I'm not sure I agree with him. Uh, to the degree that he takes it, he finds that there's no evidence he wants there to all our discussions to be grounded in evidence and data. And he, he highlights the fact that there's something about human psyche that desires this negativity that it wants. There's, there's something undeniable where we want to create an engineer. The gods that overpower us and destroy us. We want to or we worry about it. There's stuff we want to that we. Let me rephrase that. We want to worry about it. There's something about the psyche that. But

Speaker 1:          01:16:45       because you can't take the genie and put it back in the bottle. Yeah. I mean, when you say there's no reason to think this way, but if you do have cars that are semi autonomous now and if you do have computers that can beat human beings who are world go champions and if you do have computers, computers that can be people at chess and you do have people that are consistently working on artificial intelligence and you do Boston dynamics who are getting these robots to do all sorts of spectacular physical stunts and then you think about the possible future convergence of all these technologies and then you think about the possibility of this exponential increase in technology that allows them to be sentient like within a decade, two decades, three decades. What? What more evidence do you need your. You're seeing all the building blocks of a potential successor being laid out in front of you and you're seeing what we do with every single aspect of technology. We constantly and consistently improve and innovate right? With everything, whether it's computers or cars or anything. Everything today is better than everything. That was 20 years ago, so if you looked at artificial intelligence, which does agree does exist to a certain extent, and you, you look at what it could potentially be 30, 40, 50 years from now, whatever it is, why wouldn't you look at all these data points and say, hey, this could go bad. I mean, it could go great, but it could also go bad.

Speaker 2:          01:18:16       I do not want to be mistaken as the person who is not the champion or the impossible. I agree with you completely. I think it's impossible. I don't think it's impossible at all. I think it's inevitable. I don't. I think it is inevitable. Yes. It's the Sam Harris argument. If, if superintelligence is nothing more than information processing

Speaker 5:          01:18:39       [inaudible]

Speaker 2:          01:18:41       uh, same as the argument of the simulation that we're living in a simulation that's very difficult to argue against the fact that we're living in a simulation. The question is when and what the world would look like. Right? So it's like I said, a race and, and it's difficult. You have to balance those two minds. I agree with you. Totally. You and I disagree with my fellow robotics folks who don't want to think about it at all. Of course they don't. I

Speaker 1:          01:19:08       don't want to buy new houses. Think they've got a lot of money invested in this adventure. They want to keep the party rolling. They don't want to pull the brakes. Everybody pulled the cords out of the walls. We've got to stop. No one's going to do that. No one's. No one's going to come along and say, Hey, we've. We've run all this data through a computer, and we found that if we just keep going the way we're going in 30 years from now, we will have a successor that will decide that human beings are outdated and inefficient and dangerous to the the actual world that we live in and we're going to start wiping them out, but that's not the exists right now. It doesn't exist right now, but if that did happen, if someone did come to the UN and had this multistage presentation data that showed that if we continue on the path we're going, we have seven years before artificial intelligence decides to eliminate human beings based on these data points.

Speaker 1:          01:20:00       What do you. What do they do? What are the Boston Dynamics? People do? Well, I'm building a house in Cambridge. What are you talking about? Man? I'm not going anywhere. Come on. I just bought a new tesla. I need to finance this thing. Hey, younger credit card bills. I got student loans. I'm still paying off. Like what? How do you stop people from doing what they do for a living? How do you say that? Hey, I know that you would like to look at the future with rose colored glasses on, but there's a real potential pitfall that could be the extermination of the human species. Right, and obviously I'm going way far with this.

Speaker 3:          01:20:32       Yeah, I like it. I think every one of us trying to build these systems are similar in sound to the way you were talking about the touch of death in that my dream and the dream of many roboticist is to create intelligent systems that will improve our lives and working really hard at it. Not for our house in Cambridge, not for a billion dollar, for selling a startup paycheck. We love this stuff.

Speaker 1:          01:21:05       Some of you. So obviously the motivations are different for every single human being that's involved in every endeavor.

Speaker 3:          01:21:11       So, and we're trying really hard to build these systems and is really hard. So whenever the, the question is, well, this is going to look at it historically, it's going to take off. It can potentially take off any moment. It's very difficult to really be cognizant as an engineer about how it takes off because you're trying to make it take off in a positive direction and you're failing. Everybody is failing. It's been really hard. And so you have to acknowledge that there, that overnight, some Ilan Musk type character might come along and you know, people with this boring company, uh, or with space x, people didn't think anybody but NASA could do what he's doing and he's doing it. It's hard to think about that too much. You have to do that. But the reality is we're trying to create these super intelligent beings.

Speaker 1:          01:22:11       Sure, but isn't the reality also that we have done things in the past because we were trying to do it. And then we realized that these have horrific consequences for the human race like Oppenheimer and the Manhattan project. You know, when he said, I am death destroy one destroyer of worlds. When, when he was quoting the Bhagavad Gita, when he's detonating the first nuclear bomb and realizing what he's done, just because something's possible to do doesn't necessarily mean it's a good idea for human beings to do it. Now we haven't destroyed the world with Oppenheimer's discovery and through the work of the Manhattan project, we've managed to somehow or another keep the lid on this shit for the last incredible. It's crazy, right? You know, I mean for the last, what, 70 years, how long has it been? Seven days. Sounds right. $10,000. $20,000. Nukes all over the world right now. It's crazy. I mean, we literally could kill everything on the planet and somehow we would not somehow, somehow in some amazing way we have not, but that doesn't mean we. I mean this a very short amount of time in relation to the actual lifespan of the earth itself and certainly in terms of the time human history has been around

Speaker 3:          01:23:21       and nuclear weapons. Global warming is another one.

Speaker 1:          01:23:27       Sure. But that's a side effect of our actions, right? We're talking about a direct effect of human ingenuity and innovation. The nuclear bomb, it's a direct effect. We tried to make it, we made it. There it goes. Global warming's an accidental consequence of human civilization,

Speaker 3:          01:23:44       so you can't. I don't think it's possible to not build a nuclear bomb.

Speaker 1:          01:23:51       You don't think it's possible to not build it in terms of. Because people are tribal, they speak different languages, they have different desires and needs and they were add more. So if all these engineers were working towards it, it was not possible to not build it.

Speaker 3:          01:24:05       Yep. And the, like I said, there's something about us chimps in a large collective where we, uh, are born and push forward towards progress of technology. You cannot stop the progress of technology. So the goal is to how to develop, how to guide that development into a positive direction.

Speaker 1:          01:24:24       Surely if we do understand that this has taken place and we did drop these enormous bombs on Hiroshima and Nagasaki and killed untold amounts of innocent people with these detonations that it's not necessarily always a good thing to pursue technology

Speaker 3:          01:24:45       it. Nobody is. So

Speaker 1:          01:24:48       you see what I'm saying? I agree with your total. I'm more playing devil's advocate than anything, but what I'm, what I'm saying is you guys are looking at these things like we're just trying to make these things happen and what I think people like Elon Musk and Sam Harris and a bunch of others that are gravely concerned about the potential for ai are saying is that I understand what you're doing, but you've got to understand the other side of it. You've got to understand that there are people out there that are terrified, that if you do extrapolate, if you do take this relentless thirst for innovation and keep going with it, when you look at what we can do so what human beings can do so far in our crude manner of 2018 will all the amazing things they've been able to accomplish. It's entirely possible that we might be creating our successors. This is not outside the realm of possibility and all of our biological limitations might be we, we might figure out a better way and this better way might be some sort of an artificial creature.

Speaker 3:          01:25:51       Yep. Ai began with our dream to forge the gods and that's I would like. I think that it's impossible to stop.

Speaker 1:          01:26:00       Well, it's impossible to stop if you go Ted Kaczynski and kill all the people. I mean, that's what Ted Kaczynski anticipated. No, the unibomber, you know the whole story behind him know what was he trying to stop who? He's a fascinating cat. Here's what's fascinating. It was a bunch of fascinating things about him, but one of the more fascinating things about him, he was involved in the Harvard lsd studies, so they were nuke in that dude's brain with acid and then he goes to Berkeley, becomes a professor, takes all this money from teaching and just makes a cabin in the woods and decides to kill people that are involved in the creation of technology because he thinks technology is eventually going to kill off all the people. So he becomes crazy and schizophrenia pick and who knows what the fuck is wrong with them and whether or not this would have taken place inevitably, or whether this was a direct result of his being literally like drowned in Lsd. We don't even know how much they gave him or what the experiment entailed or how many other people's gut, their brain torched during these uh, experiments. But we do know for a fact that Ted Kaczynski was a part of the Harvard lsd studies. And we do know that he went and did move to the woods and write his manifesto and start blowing up people that were involved in technology.

Speaker 3:          01:27:15       And the basic thesis of his manifesto that perhaps Lsd, he opened his eyes to, is that technology is gonna, kill all humans. And so we should. It was gonna be the end of the human race, I think you may believe human race. So they know what it is that what he said. You will get into industrial, Rachel, excuse me, the industrial revolution and its consequences have been a disaster for the human race.

Speaker 1:          01:27:38       Yeah. He extrapolated. He was looking at where we're going and these people that were responsible for innovation and he was saying they're doing this with no regard for the consequences on the human race. And he thought the way to stop that was to kill people. Obviously he's fucking demented, but this is. I mean he literally was saying what we're saying right now. You keep going, we're fucked.

Speaker 3:          01:28:02       So the industrial revolution have to think about that. It's a really important message coming from the wrong guy. But where is it? Where's all of this? Taking us? Yeah. Where is it taste? So I guess my underlying assumption is the journey, the current capitalist structure of society that we always want a new iphone just had a one of the best reviewers on yesterday that always talks about Marcus. Marcus. Yeah. We always myself to pixel three. I have a pixel to. I'm thinking, man, maybe I needed a pixel three. I don't know a better camera. You know that whatever that is, that fire that wants more butter, butter. I just don't think it's possible to stop. And the best thing we can do is to explore ways to guided towards safety where it helps us.

Speaker 1:          01:28:51       When you say it's not possible to stop you mean collectively as an organism, like the human race, that it's a tendency that's just built in. It's certainly possible stop as an individual because I know people like my friend Ari who's given up on smartphones, he went to a flip phone and he doesn't check social media anymore and he found it to be toxic. He didn't like it. He thought it was too addicted to it and he didn't like where it was leading him. Yup. So in front. On an individual level, it's possible

Speaker 3:          01:29:18       individual level, but then and just like with Ted Kaczynski and the individual level, it's possible to do certain things that tried to stop at a more dramatic ways, but I just think the force of our. This symbiotic, this organism that's just this living, breathing organism that is our civilization will progress forward. We're just curious apes, it's, it's this desire to explore the universe. Why? Why do we want to do these things? Why do we look up and we want to travel and and it's not. I don't think it's sort of a. we're trying to optimize for survival. In fact, I don't think most of us would want to be immortal. The, I think it's like Neil degrasse Tyson talks about the fact that we're mortal. The fact that one day we'll die is one of the things that gives life meaning and sort of trying to worry and trying to sort of say, wait a minute, where's this going? As opposed to riding the wave and doing, riding the wave of, of forward progress. I mean, it's one of the things he gets quite a bit of. Ironically hate for Steve Pinker, but he really described in data how our world is getting better and better with

Speaker 1:          01:30:29       hate from people that don't want to admit that there's a trend towards things getting better because they feel like then people will ignore all the bad things that are happening right now and all the injustices which I think is a very short sided thing, but I think it's because of their own, their own biases and the perspective that they're trying to establish and push instead of looking at things, objectives and looking at the date and say, say, I see where you're going. It doesn't discount the fact that there's injustice in the world and crime and violence and all sorts of terrible things happen to people that are good people on a daily basis, but what he's saying is just look at the actual trend of civilization and the human species itself, and there's an undeniable trend towards peace. Slowly but surely working towards peace. Way Safer today. Way Safer today than it was a thousand years ago. Just it is. It just did.

Speaker 3:          01:31:22       Yeah, and there's these interesting arguments which his book kind of blew my mind to this funny joke. He says, some people considered given nuclear, the atom bomb the Nobel Peace Prize because he believes I'm not an expert in this at all, but he believes that sort of or some people believe that nuclear weapons are actually responsible for a lot of the decrease in violence because all of the major people can do damage. All the Russia and all the major states. Could you do damage, have a strong disincentive from engaging in warfare. And so these are the kinds of things you don't, I guess, anticipate and say. So I think it's, it's very difficult to stop that for progress, but we have to really worry and think about, okay, how do we avoid the list of things that we worry about? So one of the things that people really worry about is the control problem is basically ai becoming, not necessarily super intelligent but super powerful, but too much of our lives into it. That's where Elon Musk and others, they want to provide regulation of some sort saying, wait a minute, you have to put some bars on what this thing can do from a government perspective, from a company perspective, right? But how

Speaker 1:          01:32:34       could you stop rogue states from doing that? How could you, why would you, why would China listen to us? Why would Russia listen to us? Why would other countries that are capable of doing this and maybe don't have the same sort of power that the United States has and they would like to establish that kind of power. Why wouldn't they just take the cap off

Speaker 3:          01:32:53       in philosophical, high level sense? There's no reason. But if you engineered in. So I'm a big, we'll do this thing with autonomous vehicles called arguing machines. We have multiple AI systems argue against each other. So it's, it's possible that you'll have some ai systems over supervising other AI systems. So have a sort of, uh, like, uh, in our, in our nation there's a congress arguing, blue and red states being represented in as this discourse going on debate and have ai systems like that too. It doesn't even necessarily need to be one super powerful thing. It could be ai supervising each other, so there's this interesting ideas there too to play with because ultimately what are these artificial intelligence systems doing? We humans place power into their hands first in order for them to run away with it. We need to put power into their hands, so we'll have to figure out how we put that power in initially so it doesn't run away and how supervision can happen. Right, but this is

Speaker 1:          01:33:54       us. You're talking about rational people. What about other people? Why would they engineer limitations into their artificial intelligence and what incentive would they have to do that to somehow another limit their artificial intelligence to keep it from having as much power as ours. There's really not a lot of incentive on their side, especially if there's some sort of competitive advantage for their artificial intelligence to be more ruthless, more sentient, more autonomous. I mean it's. It seems like once again, once the genie's out of the bottle, it's going to be very hard. I have a theory, and this is a very bizarre theory, but I've been running with this for quite a few years now. I think human beings are some sort of a caterpillar and I think we're creating a cocoon and through that cocoon we're going to give birth to a butterfly and then we're going to become something and I think we're whether we're going to have some sort of a symbiotic connection to these electronic things where they're going to replace our.

Speaker 1:          01:34:47       Our parts are failing parts with far superior parts until we're not really a person anymore. Like what was that scarlet Johannson movie? The ghost in the shell. I tried to watch part of it. It's pretty stupid, but she's hot as fuck, so it kept my attention for a little bit, but in that they took her brain and put it in this artificial body that was like had super powers and they basically replaced everything about her. That wasn't her consciousness with these artificial parts, the Gerd, oliver frame, everything was just some new thing that was far superior and she had these abilities that no human being will ever have. I really wonder why we have this insatiable thirst. Why can't we, if we're so logical, we're so logical and so thoughtful in some ways. Why can't we be that way when it comes to materialism? Well, I think one of the reasons why is because materialism is the main engine that pushes innovation.

Speaker 1:          01:35:49       If it wasn't for people's desire to get the newest, latest and greatest thing, what would fund these new tvs? Cell phones, computers. Well, why do you really need a new laptop every year? Is it because of engineered obsolescence where the laptop dies off and you have to get a new one because they fucked you and they built a shitty machine that's designed to die. So you buy a new one. Really like iphone is done. You. Well, it's not even an iphone. So laptop. Well, it is. It is it because you're, you know, you just see the number two point six Gigahertz is better than two point four. Oh, it's the new one. It has a 12 megapixel webcam instead of an eight, and for whatever reason we have this desire to get those new things. I think that's what fuels innovation and in my cynical view of this thing that's happening is that we have this bizarre desire to fuel our demise and that we're doing so by fueling technology, by, by motivating these companies to continually innovate, know if everybody just said, you know what, man, I'm really in the log cabins and I want to, uh, an ax or cut my own firewood.

Speaker 1:          01:37:00       And I realized that TV's rot my brain. I just want to read books so fuck off. And everybody started doing that and everybody started living in like, when it gets dark out, I'll use candles and you know what? I'm going to get my water from a well and you know what I'm going to do. And I like living better that way. If people started doing that, there would be no need for companies to continually make new computers to make new phones, to make new smartwatches or whatever the fuck they're they're making to make cars that can drive themselves. These things that were, that were really, really attached to. If you looked at the human organism, you're like, you've somehow or another could objective really remove yourself from society and culture and all the things that make us a person and you look at what we do, like what does this thing do? We found this planet, there's these little pink monkeys and brown monkeys and yellow monkeys, and what do they all into? Well, they all seem to be into making stuff and what kind of stuff were they making? Well, they keep making better and better stuff. That's more and more capable. Well, where's it going? What's going to replace them? They're going to make a thing that's better than them. They're going to their, their engineering. These things. Slowly but surely to do all the things they do, but do them better.

Speaker 2:          01:38:12       Yeah, and it's a fascinating theory. I mean it's, it's not a theory. It's, it's an instructive way to think about intelligence in life period. So if you step back, look across human history and look at earth is an organism like what is this thing doing? The thing is, I think at, at, in terms of scale and in terms of time, you can look that way. It's so many things like isn't there billions or trillions of organisms on our skin right now, both of us that are, have little civilizations, right? They have a different mechanism by which they operate and interact. But for us to say that we're intelligent and those organisms or not is a very narrow sighted view. So they are operating under some force of nature that, uh, that the Darwin has worked on trying to understand some small elements of this evolutionary theory.

Speaker 2:          01:39:01       But there's other more interesting forces at play that we don't understand. And there's some kind of force. It could be a fundamental force of physics that Einstein never got a chance to discover is our desire for an iphone update some, some fundamental force of nature. Somehow gravity in the strong force in these things described by physics add up to this drive for new things, for creation. And uh, the fact that we die, the, that the fact that we're mortal. The fact that what desires a built in to us, whether it's a sexual or intellectual or whatever drives us, apes like somehow that all combines to this, to this progress and towards what it is a compelling way to think that if an alien species did visit Earth, I think they would probably see the smartphone situation. They see how many little lights are on and how us apes are looking at them. It's possible. I think some people have said that they would think the overlords are the phones, not the people. So to think that that's now moving into a direction where the future will be something that is beyond human or survey article. Human ways we can't understand it is really interesting. Not just that,

Speaker 1:          01:40:23       but something that we're creating ourselves, grading ourselves, and it's a, a main focal point of our existence. That's our purpose. Yeah. I mean, if you think about a main focal point, if you think about the, uh, the average person, what they do, there's a great percentage of our population that has jobs where they work and one of the ways that they placate themselves doing these things that they don't really enjoy doing is earning money for. Right? They want a new car, they want a new house, they want a bigger TV. They wanted this or that. And the way they motivate themselves to keep showing up at this shitty job is to think if I just put in three more months, I can get that Mercedes. If I just do this or that or that, I can, oh, I can finance this new pixel

Speaker 2:          01:41:14       three. Oh yeah. And it's interesting because it's sort of politicians, what's the American dream is for you here? This thing, I want my children to be better off than me. It's kind of desire, you know, you can almost see that that taken farther and farther will be. There'll be a presidential candidate and 5,000 years they'll say, I want my children to be robots. And you know what I mean? Like sort of this idea that that's the natural evolution and that is the highest calling of our species. That scares me because I value my own life, but does it

Speaker 1:          01:41:52       Gary you if if it comes out perfect. Like if each robot is like a god in each robot is beautiful and loving and they they recognize all the great parts of this existence and they avoid all the jealousy and the nonsense and all the stupid aspects of being a person. We realized that a lot of these things are just sort of biological engineered tricks that are designed to keep us surviving from generation after generation, but now here in this fantastic new age, we don't need them anymore.

Speaker 2:          01:42:23       Yeah, it's. Well first one of the most transformative moments of my life was when I met spot many in person, which is one of the legged robots in Boston dynamics for the first time when I met them, my meant that little fella there was. I know exactly how it works. I know exactly how every aspect of it works. It's just a dumb robot. But when I met him and he got up and he looked at me, there it is right there. Have you seen a dance now? Yeah. The dance. The dance is crazy. It's. I see. It's not crazy on the technical side. It's engineered. It's obvious. It's programmed, but it's crazy to watch like, wow, there's something. The reason that moment was transformative because I know exactly how it works and yet by watching it something about the feeling of it, you're like, this thing is alive and there was this terrifying moment.

Speaker 2:          01:43:20       Not Terrifying, terrifying and appealing. Where this is the future, right? Like this thing, like this thing represents some future that is totally that we don't cannot understand. Just like a future in the 18th century of a future with planes and smartphones with somebody who could understand that this thing, that little dog could have had a a human consciousness in it. That was the feeling had. And I know exactly how it works. There's nothing close to the intelligence, but it just gives you this picture of what the possibilities are of these living creatures and I think that's what people feel when they see Boston dynamics will call awesome. This thing running around is they don't care about the technicalities and how far away we are. They see it. Look, this thing is pretty human and the possibilities of human like things that supercede humans and can evolve and learn so quickly, exponentially fast is this terrifying frontier that that really makes us think as it did for me.

Speaker 1:          01:44:30       Maybe terrifying is a weird word because when I. When I look at it and I'm not a rational and I look at there's. There's videos that show the progression of Boston dynamics robots from several years ago to today what they're capable of and it's. It is a fascinating thing because you're watching all the hard work of these engineers and all these people that have designed these systems and have figured out all of these problems at these things encounter and they've come with solutions and they continue to innovate and they're constantly doing it and you're seeing this and you're like, wow, what are we going to see in a year? What am I going to see in three years? What I want to see in five years? It's absolutely fascinating because if you extrapolate and you just keep going, boy, you go 15, 20, 30, 50, 100 years, now you have x Mokena

Speaker 2:          01:45:22       you, yeah, you have x Makkah, and at least in our imagination and our imagination and the problem is there'll be so many other things that are super exciting and interesting,

Speaker 1:          01:45:35       but that doesn't mean it's not crazy. I mean there's many other things you could focus on also that are also going to be bizarre and crazy. Sure. But what about it just it? It's going somewhere. That fucker is getting better. The the park core one is bananas. You see it hopping from box to box and left to right and leaping up in the air and you're like, whoa. I think doesn't have any wires on it. It's not connected to anything. It's just jumping from box to box. If that thing had a machine gun, it was running across a hill at you, he'd be like, Oh fuck. How long does the battery last said? How many bullets does it have?

Speaker 2:          01:46:11       Let me, let me just say that I would pick Tim Kennedy over that dog for the next 50 years. 50. Yeah, man. So I'm a big Tim Kennedy I'm talking about. Um, but he'll probably have some robotic additions to his body to improve the. Well, is he tim Kennedy anymore? If the brain is Tim Kennedy, then he still Tim Kennedy. That's the way we think about it. But there is huge concern about UN is meeting about this autonomous weapons. It, it's, um, it's allowing you to make decisions about who lives and who dies is really concerning in the short term. It's not about a robotic dog with a shotgun running around. It's more about our military wanting to make destruction as efficient as possible, minimizing human life and drones. Drones. There's something really uncomfortable to me about drones in how you compare with, uh, Dan Carlin hardcore history. It was the gang Iskcon.

Speaker 2:          01:47:17       There's something impersonal about what drones are doing, weight. It moves you away from the actual destruction that you're achieving. Where I worry that our ability to encode the ethics into these systems will go wrong in ways we don't expect. And so, I mean folks at the UN talk about, well, you have these automated, so drones that make that drop bombs all over a particular area. So the bigger and bigger the area is over which you allow an artificial intelligence system to make a decision to drop the bombs, the weirder and weirder it gets. There's some line that presumably if there's like three tanks that you would like to destroy with a drone, it's okay for ai assistant to say, I would like to destroy the street. Like I'll handle everything, just give me the three tanks. But this makes me uncomfortable as well because I think, uh, I'm opposed to most wars.

Speaker 2:          01:48:14       But it's just military is military and they tried to get the job done. Now what if we now expand that to 10, 2100 tanks where you not let ai system drop bombs all over very large areas. How can that go wrong? And that's terrifying. And there's practical engineering solutions to that oversight and there's, that's something that engineers to sit down and there's an engineering ethic where you encoding, you have meetings, uh, of how do we make this safe? That's what you worry about. A thing that keeps me up at night is the 40,000 people that die every year in auto crashes like that. I worry about not. You have to understand like I worry about the future of Agi taking over, but that's not as large. Agi Now Agi, artificial general intelligence. That's kind of the term is that people have been using for this, but I'm maybe because I'm in it, I worry more about the 40,000 people that die in the United States in the one point 2 million that die every year from auto crashes.

Speaker 2:          01:49:17       There's something that is more real to me about the death that's happening now that could be helped and that's the fight, but a force. If the threat becomes real, then then that's a much, you know, that's a serious threat to humankind and that's something that should be thought about. I just worry that I worry also about the Ai Winter, so I mentioned there's been two winters in the seventies, in the eighties, the nineties when funding completely dried up, but more importantly just people stopped getting into artificial intelligence and became cynical about as possibilities because there was a hype cycle where everyone is really excited about the possibilities of ai and then they realized, you know, five, 10 years into the development that we didn't actually achieve anything.

Speaker 1:          01:50:10       It was just too far off, too far off. Same as it was for virtual reality. For the longest time. Virtual reality was something that was discussed like even in the eighties and the nineties, but it, it just died off. Nobody even thought about it. Now it's come back to the forefront when there's real ai, a real excuse me, real virtual reality that you can use like htc vives or you know, things along those lines. We can put these helmets on and you really do see these alternative worlds that people have created in these video games and it's you realize like there's a practical application for this stuff because the technology has caught up with the concept.

Speaker 2:          01:50:45       Yeah, and I actually don't know where people stand on Vr. We do quite a bit of stuff with Vr for research purposes, for simulating robotic systems, but I don't know where the hype is. I don't know if people calm down a little bit on Vr. So there was a hype in the eighties and nineties. I think it's ramped up quite a bit. What does the other one that had the oculus rift and what other, what other than just those two? Those are the main ones. And there's other headsets that you can work and use with and there's some you can use just with a Samsung phone, correct? Yeah. And the work of the next generation or which next year to two are going to be all a stand alone systems is gonna be an oculus rift coming out. You don't need a computer for at all. So the ultimate

Speaker 1:          01:51:25       and fear and game fear, the event horizon of that is the Matrix, right? That's, that's what people were terrified of. Have some sort of a virtual reality world where you don't exist in the physical sense anymore. They just plug something into the brain stem just like they do in the matrix and you're just locked into this artificial world.

Speaker 2:          01:51:45       Is that terrifying to you as that seems to be less terrifying than ai killing all of humankind? Well, it depends means

Speaker 1:          01:51:52       I mean, what is life? That's the real question, right? If you only exist inside of a computer program, but it's a wonderful program and you, you whatever your consciousness is. And we haven't really established what that is, right? We don't, we don't. I mean there's a lot of really weird hippie ideas out there, but what consciousness is your body? Just like an antenna man. And it's just like tuning into consciousness and consciousness is all around you. It's Gaia, the mother earth. It's the universe itself. It's God. It's love. Okay. Maybe, I don't know. But if you could take that, whatever the fuck it is and send it in a cell phone in New Zealand, is that where your consciousness is now? Because like if, if we figure out what consciousness is and get it to the point where we can turn it into a program or duplicate it, I mean that's sounds so far away.

Speaker 1:          01:52:43       But if you weigh up to someone from 18, 20 and said, hey man, one day I'm going to take a picture of my Dick and I'm a sent to this girl. She's going to get it on her phone. They be like, what the fuck are you talking about a photo? What do, what do you mean you're going to. What's a photo? Oh, it's like a picture. But like you don't draw it. It's perfect. It looks exactly like that. It's in hd and I'm going to make a video of me taking a shit and I'm going to send it to every. Like what the fuck is this even possible can out of here. The Dat is essentially you're capturing time, you're capturing moments in time at a very, not a very crude sense, but a crude sense in terms of comparing it to the actual world in the moment where it's happening. Like here you and I are having this conversation. We're having it in front of this wooden desk, his paper in front of you to you and I. We have access to all the textures, the sounds. We can feel the air conditioning. We can look up, we could see the, the, the, the, the ceiling. We're, we're, we've got the whole thing in front of us because we're really here, but too many people that are watching this on youtube right now. They're getting a minimized crude version of this

Speaker 4:          01:53:59       that's similar, but it feels real. It feels pretty real. It's pretty close. It's pretty close. So I mean, I've listened to your podcast for awhile. You usually have. So when I listened to your podcast, it feels like I'm sitting in with friends listening to a conversation, so it's not as intense as, for example, Dan Carlin's hardcore history where the guy's like talking to me about the darkest aspects of human nature. That show's so good. I don't think you can call it a podcast. It's not a. it's, it's an experience. You're there. I was. I was hanging out with him and getting his con and I was in World War One. World War Two, painful attainment is an episode he had. We taught very dark ideas about our human nature and desiring the observation of the torture and suffering of others. There's something really appealing to us. He has this whole episode how throughout history we liked watching people die and there's something really dark.

Speaker 4:          01:54:59       You're saying that if somebody streamed or something like that, now it would probably get hundreds of millions of views. Yeah, and we would. And we're protecting ourselves from our own nature because we understand the destructive aspects of it. That's why youtube would pull something like that, right? If you tied a person in between two trucks and pulled them apart and put that on youtube, it would get millions of hits, but youtube would pull it because we've decided as a society collectively that those kinds of images or gruesome and terrible for us, but nevertheless that experience of listening to his podcasts, let's show it feels real. Just like Vr for me is really strongly real aspects to it where I'm not sure. I'm not sure if the

Speaker 2:          01:55:44       VR technology gets much better to where if you had a choice between do you want to live your life in Vr, you you're going to die just like you would in real life. Meaning your body will die. You're just going to hook up yourself to a machine like it's a deprivation tank and just all you are is in Vr and you're going to live in that world. Which life would you choose? Would you choose life and Vr or would you choose a real life?

Speaker 1:          01:56:09       That was the guy's decision in the Matrix, right? The guy decided in the matrix, you want it to be a special person in the matrix. He was eating that steak talking to the guys and decided he was going to give up. Remember that? Yup. Yup. So what decision would you make? I mean, what is reality if it's not what you're experiencing, right? If you're experiencing something but it's not tactile in the sense like you can't drag it somewhere and put it on a scale and take a ruler to it and measure it, but in the moment of being there, it seems like it is. What is missing? What is missing? Well, it's not real. What is real then? What is real? Well, that's the ultimate question in terms of like are we living in a simulation? That's one of the things that [inaudible] brought up when I was talking to them and this is one thing that people have struggled with. If we are one day going to come up with an artificial reality, it's indiscernible from reality in terms of emotions, in terms of experiences, feel, touch, smell, all of the sensory input that you get from the regular world. If that's inevitable, if one day we do come up with that, how are we to discern whether or not we have already created that and we're stuck in it right now

Speaker 2:          01:57:20       that we can't and there's a lot of philosophical arguments for that, but that gets it the. Yeah. The nature of reality is. I mean, it's fascinating because we're okay. We're totally clueless about what it means to be real. It needs to exist to exist. So consciousness for us. I mean, it's incredible. You look at your own hand like I'm pretty sure I'm on the Joe Rogan experience podcast. I'm pretty sure this is not real. I'm imagining all of it. There's a knife in front of me. I mean it's surreal and I have no proof that it's not fake and, and those kinds of things actually come into play with the way we think about artificial intelligence to like what is intelligence? It seems like it seems like we're easily impressed by by algorithms and robots. We create that appear to have intelligence, but we still don't know what is intelligent and how close those things are to us

Speaker 1:          01:58:15       and we think that ourselves as this biological entity that can think and talk and cry and laugh, that we're somehow or another more important than sort of some sort of silicone based thing that we create that does everything that we do. But far better.

Speaker 2:          01:58:33       Yeah. I think, uh, I think if I were to take a stand still right, stand, I hope I'm young one day run for president in this platform by the way

Speaker 4:          01:58:42       that defending the rights. I can't because I'm rushing, but maybe a little cheesy rules, uh, that the robots will have rights and I, I'll, I'll, I'll, you know, robots lives matter and I, I actually believe that we're going to have to start struggling with the idea of how we interact with robots. I've seen too often the abuse of robots and not just the Boston dynamics, but literally people. You leave them alone with the robot. That dark nature of Hue, dark aspects of human nature comes out and it's worrying to me I would like a robot that spars but only can move it like 50 percent of what I can move out so I could fuck it up. Yeah. She shouldn't be able to practice like really well. Like you would develop like some awesome like sparring instincts. Yeah, I a robot, but there would still be consequences.

Speaker 4:          01:59:34       Like if you did fuck up and you got lazy and it led, kicked you, you didn't check it. It would hurt. I would love to see a last stream of that session because the, you know, there's so many ways I used to. I mean I had practiced on a dummy. There is aspects to a dummy that's helpful in terms of positioning and where were your stances and technique to it. I could certainly see that going wrong in ways where a robot might not respect you. Tapping or world supposed to beat you to death as tired as you fucking it up every day and one day you get tired or what have you, sprain your ankle and it gets on top of you and mounts you and just starts blasting the face and to say he'll hook or something. You'd have to be able to say, stop.

Speaker 4:          02:00:20       Well then no, you're gonna have to use your martial art to defend yourself, right? Because if you make it too easy for the robot to just stop at any time, then you're not really going to learn. Like one of the consequences of training if you're out of shape is if you get tired people fuck you up. And that's incentive for you to not get tired. Like there was so many times that I would be in the gym, like doing strength and conditioning. And I think about moments where I got tapped. What guys caught me and something that I was exhausted. I couldn't get out of the triangle. I'm like, Shit. And I just fucking die. I just really push on the treadmill or you know, push on the um, you know, um, airdyne bike or whatever it was that I was doing, thinking about those moments.

Speaker 4:          02:01:00       Getting tired. Yeah, those moments. That's what I think about when I do like sprints and stuff was um, the feeling of competition, those nerves of stepping in there and just, it's really hard to do that kind of visualization. But it was effective though. And the, the, the feeling of consequences to you not having any energy. So you have to muster up the energy because if you don't, you're going to get fucked up or something bad's going to happen to someone you care about or something. Something's gonna Happen to the world. Maybe you're a superhero. You saving the world from the robots. That's right. But I did go back

Speaker 1:          02:01:39       what we're talking about, sorry to interrupt you, but just to bring this all back around, what, what is, what is this life and what is consciousness and what does this experience, and if you can replicate this experience in a way that's indiscernible, will you choose to do that? Like if someone says to you, Hey Lex, you don't have much time left, but what? We have an option, we have an option and we can take your consciousness. As you know it right now, put it into this program. You will have no idea that this has happened. You're going to close your eyes. You're going to wake up, you're going to be in the most beautiful green field. It's going to be naked women everywhere. Feasts, everywhere you go, it's going to be just picnic tables filled with the most glorious food. You're going to drive around a Ferrari every day and fly around in a plane. You never going to die. You can have a great time or take a chance. Chances. See what happens?

Speaker 4:          02:02:31       Shut off. Well, first of all, I'm a simple man. I don't need multiple women. One is good. I'm romantic, you say, but that's in this world, this world. You've got an incentive to not be greedy in this other world where you can breathe underwater and fly through the air and you know, not I. I believe that scarcity is the fundamental ingredient of happiness. So if you give me 72 virgins, whatever it is, and we just keep one slut, slut, she a requirement. You know, somebody intelligent and interesting who enjoys sexual intercourse was not just enjoy sexual intercourse with a person. Well that and keeps things interesting lex. We can engineer all this into your experience as you don't need all these different women. I get it. I understand that. We've got this program for you. Don't worry about it. Okay. You want one, one and a normal car, like maybe a Saab or something like that.

Speaker 4:          02:03:33       Nothing crazy. Yeah, right. Yeah. But you're a simple man. I get it. No, but you need to at chess with someone who could beat you every now and then, right? Yeah, but not just chess. So engineers, some flaws. Like she needs to be able to lose her shit. Every once in a while the matrix or on the red dress. Which girl in the red dress that comes right here. Remember? He goes like, did you notice the girl in the red dress? It's like the one that catches his attention. I don't remember this. This is right at the very beginning when he's telling them what the Matrix is. She walks by right here. Oh, there she is, but Bam. That's your girl. The guy afterwards. It's like I ended up telling you. It's just not. It's not. Well. Yeah, but then I have certain features like I'm not an iphone guy like android so that, that may be an iphone persons girl, but that's nonsense.

Speaker 4:          02:04:19       I, I blew up an iphone. Came along. That was better than android. You wouldn't want to use it? No, it might just definition of better is different. Like, uh, I know for me a happiness lies in android phones, android phones, close connection. Other human beings who are flawed but interesting who are passionate about what they do. Yeah. But this is all engineered into your program. Yeah. Yeah. That's. I'm requesting features here because you're requesting features, but why? Why android phones? Is that like, um, I'm a Republican. I'm a Democrat, like android phones. Is that what you're doing to get in tribal? Not Electronics. I totally not drivable. I was just representing, if I figured the girl in the red dress, it just seems like an iphone as a feature set. I imagined the kind of features I'm asking you a lot. Yeah, and it seems like she's not interested in dusty yefsky.

Speaker 4:          02:05:14       How would you know that? So prejudice view just because she's beautiful and she's got a fitting dress. I don't know. That's fair. That's fair. You, you sexist son of a bitch. I'm sorry. Actually that was a totally. She probably likes Nietzschean and sts can come when I say she did her phd in astrophysics. Possibly. Yeah. That's what we're talking about. All the trappings that. Bam, I'll take her all day. I phone Andrew Commerce or if she's a windows phone about that. I'm going to give off windows phone. Come on now. I'll take her. She's a windows phone. I'll go with a flip phone from the early two thousands. I'll take a razor phone, a Motorola razor phone with like 37 minutes of battery life.

Speaker 4:          02:06:02       But we're, we're, we're talking about all the learning experiences and preferences that you've developed in your time here on this actual real earth or what we're assuming is the actual real earth. But how are we, I mean, if you're, if you really are taking into account the possibility that one day something someone, whether it's artificial intelligence figures it out or we figured out engineering a world, us some sort of a simulation that is just as real as this world. Like where there is no, there's no. It's impossible to discern. Not only is it not always impossible to discern, people choose not to discern anymore because it's so well, why bother? Why bother discerning? That's a fascinating concept to me, but I think that world, not to sound hippie or anything, but I think that. I think we live in a world that's pretty damn good.

Speaker 4:          02:06:59       That is pretty good. So. But improving it with such fine, fine ladies walking around. It's not necessarily that the delta that's positive. Okay. But that's one aspect of the improvement. What about improving it? And in this new world, there's no drone attacks in Yemen that killed children. I order, there's no rape, there's no sexual harassment, there's no, there's no racism, there's no any. All the negative aspects of our current culture or engineered out, I think. I think a lot of religions have struggled with this and of course I would say I would want a world without that, but part

Speaker 2:          02:07:36       of me thinks that our world is meaningful because of the suffering in the world.

Speaker 1:          02:07:40       Right. That's a real problem, isn't it? It's a real. It's. That is a fascinating concept. It's almost impossible to ignore. Do you appreciate love because of all the hate, you know, like if you have a hard time finding a girlfriend and just no one's compatible and obviously the Hala letting the ladies know, but if you, if you do have a hard time connecting with someone and then you finally do connect with someone off after all those years of loneliness and this person's perfectly compatible with you, how much more will you appreciate them? Then? A guy like Dan Bilzerian was flying around in a private jet bang and tens all day long, or maybe he's fucking drowning in his own sorrow. Maybe he's got too much, too much prosperity and this, you know,

Speaker 2:          02:08:29       yeah, we had that with social networks to the people that, I mean, you're pretty famous in the amount of love you get is huge. It's a, it might be because of the overflow of love. It might be difficult to appreciate more like genuine little moments of love.

Speaker 1:          02:08:47       And it's not for me. No. Um, I, I spent a lot of time thinking about that and I also spent a lot of time thinking about how titanic really bizarre my place in the world is. I mean, I, I think about it a lot and I spent a lot of time being poor and being a loser. Me, my childhood was not the best. I went through a lot of struggle when I was young that I cling to like a safety rep raft. You know, I, I don't, I don't ever think there's something special about me and I try to let everybody know that you, anybody can do it. I've done it. You just have to just keep going though. The 99 percent of this thing is just showing up and keep going. Keep improving, keep working at things and keep going, put the time in,

Speaker 2:          02:09:35       but the interesting thing is you haven't actually, a couple of days ago went back to your first podcast and listen to it. You haven't really changed much, so you were. I mean the audio got a little better and but just like the year, the genuine nature of the way you interact hasn't changed and that's fascinating because, you know, fame changes people.

Speaker 1:          02:09:59       Well, I was already famous then, but just in a different way. I was famous. I was already famous from fear factor. I was already already had standup comedy specials already had. I'd already been on a sitcom. Wasn't as famous as I am now, but I understood what it is. I'm a big believer in adversity and struggle. I think they're very important for you. It's one of the reasons why appreciate martial arts. It's one of the reasons why I've been drawn to it as a learning tool, not just as something where it's a puzzle that I'm fascinated to try to figure out how to get better at the puzzle. And martial arts is a really good example because you never really the best, especially when there's just so many people doing it. It's like you're always going to get beat by guys. And then I was never, I was never putting the time into it as a, an adult outside of, uh, my taekwondo competition.

Speaker 1:          02:10:51       I was never really putting all day every day into it. Like a lot of people that I would train would. And so I'd always get dominated by the really best guys. So there's a certain amount of humility that comes from that as well. But there's, there's a struggle in that you're learning about yourself and your own limits and the limits of the human mind and endurance and just not understanding all the various interactions of techniques and that, you know, there's some, there's humility to that in that I've always described martial arts as a vehicle for developing your own human potential. But I think marathon running a similar aspects. I think when you're just, you figure out a way to keep pushing and push through the control of your mind and your desire and overcoming adversity. I think overcoming adversity is critical for the human, for humans.

Speaker 1:          02:11:46       We have this, this, um, these set of reward systems that are designed to do, to reward us for overcoming, for overcoming obstacles, for overcoming a relationship, struggles for overcoming physical limitations. And those rewards are great and there are some of the most amazing moments in life when you do overcome. And I think this is sort of engineered into the system. So for me, fame is almost like a cheat code. It's like you don't really want it. Don't dwell on that man. Like that is, that's like a free buffet. Like you don't, you know, you want to go hunt your own food, you want to make your own fire, you want to cook yourself and feel the satisfaction. You don't want people feeding you grapes while you lie down.

Speaker 2:          02:12:34       What is the hardest thing? So you talked about challenge a lot. What's the hardest thing you've won? Have you been really humbled

Speaker 1:          02:12:43       martial arts? For sure. The most humbling. Yeah, from the moment I started, I mean I got really good at taekwondo, but even then I'd still get the fuck beaten out of me by my friends and got training part. Especially when you're tired and you're doing your rotating partners and guys are bigger than you. It's just, it's just humbling, you know, martial arts, very humbling.

Speaker 2:          02:13:04       No, I got to call you out on something. So you talk about education system sometimes I've heard you say is a little broken in high school and so on. I'm not really calling out and just I just want to talk about it because I think it's important and as somebody who loves math, it talked about your own journey. Was school didn't give you a passion? Well you can maybe talk to that, but for me what I always do, maybe I'm sick in the head or something, but for me math was exciting. The way martial arts, we're excited for you because it was really hard. I wanted to quit and the idea of, of education, I have that, that, that seems to be flawed nowadays a little bit is that we want to make education easier, that we want to make more accessible and so on.

Speaker 2:          02:14:01       Uh, accessible of course is great, but you kind of forget in that. And those are all good goals. You forget in that it's supposed to be also hard and like teachers, just the way you're wrestling coach, if you like quit, you say, I can't do anymore. I have to come up with some kind of excuse. You're wrestling coach looks at you wants to say get your ass back on the mat the same way I wish math teachers did that. When people say it's almost like cool now to say i's not math sucks, mass not for me or science sucks as his teacher's boring. I think there are, there's room for some culture where says, no, no, no, you're not. If you just put in the time and you struggle, then that opens up the universe to you. Like whether you become a neil degrasse tyson or the next fields medal winner in mathematics.

Speaker 1:          02:14:50       I would not argue with you for one second. I would also say that one of the more beautiful things about human beings is that we vary so much and that one person who is just obsessed with playing the trombone and to me, I don't give a fuck about trombones, but that's okay. Like I can't be obsessed about everything. Some people love golf and they just want to play it all day long. I've never played golf a day in my life. Set Miniature Golf and just fucking around, but that doesn't. It's not bad or good and I think there's. There's definitely some skills that you learned from mathematics that are hugely significant if you want to go into type of fields that you're involved in. For me it's never been appealing, but it's not that it was just difficult. It's also that it just, for whatever reason, who I was at that time in that school with those teachers and having the life experience that I had, that was not what I was drawn to, but what I was drawn to, his literature I was drawn to reading.

Speaker 1:          02:15:53       I was drawn to stories, I was drawn to possibilities and creativity. I was drawn to all those things. You are an artist of it too. I used to be. I used to want to be a comic book illustrator. That was, that was a big thing when I was young. I was really into comic books. I was really into um, a traditional comic books and also a lot of the horror comics from the 19 seventies that black and white, like creepy and eerie. Did you ever see those things? Creepy and eerie. Like black and white? Yeah, they were. There were a comic book series that I'm existed, like way back in the day was all there, all horror and they were like really cool illustrations and these wild stories, but it was comic books, but they were all black and white. That's creepy. And Eerie. That's the actual name?

Speaker 1:          02:16:41       Yeah. Erie and creepy. Where the names like that was from. What year was that? It says September, but it doesn't say what year am I used to get these when I was a little kid, man, I was like eight, nine years old. And the seventies, good and evil. Yeah, it was, uh, they were, they were my favorite, like that's a cover of them and like have like covers that were done by like Frank Frazetta, Boris Vallejo, and just really cool shit. And I was fat. I love those. When I was little I was always really into horror movies and really into like Bram, like, look at this werewolf one that was one of my favorite ones. That was a crazy werewolf that was like, well, all fours, who's the hero? Usually super heroes. Everybody dies. And those, that's the beautiful thing about it. Everybody gets fucked over.

Speaker 1:          02:17:29       There was nobody. That was the thing that I really liked about them was that nobody made it out alive. There was no one guy who figured it out and rescued the woman and they wrote off in the sunset, but you turned the corner and they'd be a fucking pack of wolves with glowing eyes were waiting to tear everybody apart. And that'd be the end of the book. And I just, um, I was just really into the illustrations. I found that fascinating. I just, I love those kind of horror movies and I love those kinds of illness. So that's what I wanted to do when I was young.

Speaker 2:          02:17:57       Yeah, I think the education system is probably. We've talked about creativity is probably not as good at, uh, inspiring and feeding that creativity because I think math and wrestling can be taught systematically. I think creativity is something. Well actually I had known nothing about it, so I think it's harder to take somebody like you when you're young and say and inspire you to pursue that fire. Whatever's inside. Well,

Speaker 1:          02:18:23       one of the best ways to inspire people is by giving them, giving them these alternatives that are so uninteresting, like saying you're going to get a job selling washing machines and you're like, fuck that. I'm going to figure out a way to not get a job selling washing machines. Like what some of the best motivations that I've ever had have been terrible jobs because you have these terrible jobs and go, okay, fuck that. I'm going to figure out a way to not do this, you know, and whether you want to call it add or Adhd or whatever it is that makes kids squirm in class. I didn't score and every class I didn't squirm and science class, I didn't squirm in, in, you know, an interesting subjects. There's things that were interesting to me that I would be locked in and completely fascinated by and there was things where I just couldn't wait to run out of that room and I don't know what the reason is, but I do know that a lot of what we call our education system is engineered for a very specific result and that result is you want to get a kid who can sit in class and learn so that they could sit in a job and perform and that for whatever reason, that was just.

Speaker 1:          02:19:40       I mean, I didn't have the ideal childhood. Maybe. Maybe if I did I would be more inclined to lean that way, but I didn't want to do anything like that. Like, I couldn't wait to get the fuck out of school, so I didn't ever have to listen to anybody like that again. And then just a few years later, I mean, you graduated from high school and you're 18. When I was 21, I was a stand up comic and I was like, I found it. This is it. I'm like, good. I found there's an actual job that nobody told me about where you could just make fun of Shit and people go out and they pay money to hear you. Uh, create jokes and routines and bits. Really. You weren't terrified of standup getting onstage and. Oh, I was definitely nervous the first time. Probably more nervous and he was hard on him fighting.

Speaker 1:          02:20:24       No, it's different. It's different. The consequences aren't as grave, but that's one of the, they not know, like embarrassment and you don't get pummeled. I mean there's, there's, there's, there's, you could say like, emotionally it's probably more devastating or as devastating. But man, losing a fight is, it fucks you up for a long time. You feel like shit for a long time. Um, but then you, when you feel amazing for a long time too, when you kill onstage, you only feel good for like an hour or so, and then it goes away. It feels normal. It's just normal. It's just life, you know. But I think that it prepared me like competing in martial arts, the fear of that and then the, how hard it is to stand opposite another person who's the same size as you, who's equally well trained, who's also a martial arts expert.

Speaker 1:          02:21:20       And they ask you, are you ready? Are you ready? You bow to each other and then they go fight and then you're like, fuck, here we go. Like that to me probably was like one of the best prep. And to do that from the time I was 15 until I was 21 was probably the best preparation for anything. That was difficult too because it was so fucking scary. And then to go from that into standup, I think it prepared me for standing up because I was already used to doing things that were scary. Now I seek scary things out. I Thi, I seek difficult things. Uh, picking up the bow and learning that yes, archery, which is really difficult. I mean there's some reasons why I got attracted even to playing pool pools. Very difficult. It's very difficult to control your nerves and high pressure situations so that there's, there's, there's some benefits of that, but here. But it goes back to what you were saying earlier, how much of all this stuff, like when you were saying that scarcity, there's, there's, there's real value in scarcity and that there's real value in struggle and how much of all this is just engineered into our human system that it has given us the tools and the incentive to make it to 2018 with the human species.

Speaker 2:          02:22:37       Yeah. I think it's whoever the engineer is, whether it's God or nature or whatever, I think it's engineered and somehow that we get to think about that. When you try to create an artificial intelligence system, when you imagine what's a perfect system for you, where we talked about this with, with the lady, what's the perfect system for you? If you had to really put down on paper and engineer, what's the experience of your life, will you start to realize it actually looks a lot like your current life. So this is the problem that companies are facing like Amazon and trying to create Alexa. What do you want from Alexa? Do you want a tool that says what the weather is or do you want to Alexa to say, Joe, I don't want to talk to you right now. I Have

Speaker 1:          02:23:26       Alexa where you have to work or over like Alexa, come on. What do I do? I'm sorry. Yeah. Listen, if I was rude, I was insensitive. I was tired of the commute was really rough and they shouldn't be like I'm seeing somebody else. Do you remember? Avatar depression?

Speaker 2:          02:23:44       Uh, the movie Avatar and depression is a psychological effect after the movies.

Speaker 1:          02:23:48       Yeah. It was a real term that people were using, that psychologists were using because people would see the movie Avatar, which I loved. A lot of people said, oh, it's fucking pocahontas was blue people to those people. I say, fuck off. You want to talk about suspension of disbelief. That to me, that movie was the ultimate suspension of disbelief. I love that movie. I fucking love that. I can't. I know James Cameron is working on like 15 sequels right now. All simultaneously. I wish that motherfucker would dole them out. He's like a, a crack dealer that gets you hooked once and then you just waiting outside in the cold. Shiver. And for years, um, avatar depression was a psychological term that psychologists were using to describe this mass influx of people that saw that movie and were so enthralled by the way the Navi lived in Pandora that they came back to this stupid to leave.

Speaker 1:          02:24:43       They wanted to be like the blue guy in Avatar. And it also, there was a, there was a mechanism in that film where this regular person became a Navi. He became through the Avatar and then eventually that tree of life or whatever it was, they transferred his essence into this, create this avatar. And he became one of them. He became one of them. He absorbed their culture and it was very much like our romanticized versions of the native Americans that they lived in symbiotic relationship with the earth. They only took what they needed. They had spiritual connection to their food and to nature and to the just the, their existence was was noble and it was honorable and it wasn't selfish and it was powerful and it was spiritual and that we're missing these things.

Speaker 4:          02:25:38       We're missing these things and I think we are better at romanticizing them and craving them as opposed to living them as. I mean, you look at movies like happy people with the life and the tiger den. Live life in a tie. GMS, yeah, I'm rushing center. Herzog's film is part of you wants to be like, well, I want to be out there in nature, focusing on simple survival, setting traps for animals, cooking some soup, a family around you, and just kind of focusing on the basics. But. And I'm the same way, like I go out hiking and I go out in nature. I would love to pick up hunting and I want. I'm crave that, but if you just put me in the forest, I'll probably. It'd be like I'm taking your phone away and you're staying here. That's it. You never go into return to your facebook and your twitter and your and your robots.

Speaker 4:          02:26:32       I don't know if I'll be so romantic about that notion anymore. I don't know either, but I think that's also the genie in the bottle, right discussion. I think that genie's out of the bottle for so long. You'd be like, but what am I? Facebook? What have I got? Some messages. Let me check my email real quick. No, no, no. We're in the forest. There's no wifi out here. No wifi ever. What the fuck? How do people get your porn porn? No, that's another understudied. Again, not an expert, but the impact of Internet pornography on culture. Oh yeah. I'm, it's significant. And also ignored to a certain extent and um, if not ignored, uh, definitely purposefully left out of the conversation. Yeah. There's a another phd student, a person from Google came to give a tech talk and he opened by saying 90 percent of you in the audience have this month, Google the pornographic term in our search engine, and it was really a great opener because people were just all really uncomfortable because we just kind of hide it away into this, but it certainly has an impact. I think there's a suppression aspect to that too. That's unhealthy. We, we, we, we have a suppression of our sexuality because we think that somehow or another it's negative, right. You know, and especially for women, I mean for women like men

Speaker 1:          02:28:03       and who is a sexual conqueror is thought to be a stud. Whereas a woman who seeks out a multiple desirable sexual partners is thought to be troubled or something wrong with her. You know, they, they're criticized there use terms like we used earlier, like slut or whore, you know, there's no, you call a man a mail slot. They'll start laughing. He up. That's me, dude. Like men don't give a fuck about that. It's not, it's not stigmatized, but somehow or another through our culture, it's stigmatized for women. And then the idea of masturbation is stigmatized. These, all these different things that we, our puritan roots of our society starts showing and our religious ideology starts showing when we discuss our, our issues that we have with sex and pornography.

Speaker 2:          02:28:56       All right, and for me, this is something I think about a little bit because my dream is to create an artificial intelligence, the human centered artificial intelligence system that provides a deep, meaningful connection with another human being. And you have to consider the fact that pornography or sex dolls will be part of the journey somehow in society. Something you're the dummy they'll be using for martial arts would likely to be in our development of, uh, of sex robots. And we have to think about what's the impact of those kinds of robots on society.

Speaker 1:          02:29:33       But women in particular are violently opposed to sex robots. I've read, uh, read a couple articles written by women about sex robots and the possibility of future sex robots and the, I shouldn't say violently, but it's always negative. So is the idea that men would want to have sex with some beautiful thing that's programmed to love them as opposed to earning the love of a woman, but you don't hear that same interpretation from men, from men. It's, it seems to be that there's a thought about, maybe it's Kinda Gross, but also that it's inevitable and that, uh, and then there's like this, uh, like sort of nod to it. Like how crazy would that be if you had the perfect woman like the red, the woman in the red dress in the matrix? Yeah. But it comes over to your house and she's perfect

Speaker 2:          02:30:22       because you're not thinking about the alternative, which is a male robot doll, which will now be able to satisfy your girlfriend wife better than you. I think you'll hear from guys a lot more than,

Speaker 1:          02:30:35       um, maybe or maybe start competing with her. She's fucking annoying. She's always yelling at me. Let her yell at the robot. He doesn't know he's not going to care. Then that robot turns into grappling. Yeah. And maybe she can just go ahead and get fat with the robot. He's not even even care. Go ahead. Just sit around each cheetos all day and screaming at him. He's your, he's your, your slave. Good. I mean, he could work both ways, right? It can work the same way that a man would, uh, you know, a woman would see a man that is interested in a sex robot to be disgusting, pathetic. A man could see the same thing in a woman that's interested in a sex robot like, okay, this, that is that what you want, do some crude thing that just wants physical pleasure and you don't even care about a real, actual emotional connection to a biological human being like, okay, well then you're not my kind of woman anyway.

Speaker 3:          02:31:30       And uh, but if done well, those are the kinds of, in terms of threats of Ai, to me, if you can change the fabric of society because like I'm old school in that sense. I, I, I like monogamy. For example, you know, when you say that because you don't have a girlfriend, monogamy one is, one is better. Well now the real reason and have a a girlfriend is because it is fascinated with people like you would with the time. Yes. Is a huge challenge because because of how much your romantic I am because how much I care about people around me. I feel like it's a significant investment in time and also the amount of work that you do.

Speaker 1:          02:32:10       I mean if you're. If you're dedicated to a passion like artificial intelligence and the sheer amount of fucking studying and research

Speaker 3:          02:32:21       and programming to certain disciplines in which you have to. Certain disciplines require. Like Steven pressfield talks about writing. You can get pretty far with two, three hours a day when you're programming, when you see a lot of the engineering tasks, they just take up hours. It's just hard, which is why I really wanted one of the reasons I may disagree with all, well a bunch of things, but he's an inspiration because I think he's a pretty good dad. Right? And he finds the time for his sons while being probably an order of magnitude busier than I am and it's fascinating to me how that's possible. Well, once you have children, I mean there obviously are people that are bad dads, but once you have children, your life shifts in an almost. It's

Speaker 1:          02:33:08       indescribable way because you're. You're different. It's not just that your life is different when you have a child like your Deli. There hasn't been a moment while we were having this conversation that I haven't been thinking about my children, thinking about what they're doing, where they are. It's always running in the background. It's a part of life. You're, you're connected to these people that you love so much and they rely on you for guidance and for, for warmth and affection and but how did you left have to change your life? You just changed. Man. When you see the baby, you change. When you, when you start feeding them, you change. When you hold them, you change. When you, you hold their hand while they walk, you change. When they ask you questions, you change. When they laugh and Giggle, you change. When they smack in the face and you pretend to fall down, they laugh, you change, you just change, man.

Speaker 1:          02:34:00       You change. You become a different thing, you become a dad, so you almost can't help but the people do help, but though that's what's sad. Some people resist it. I mean, I know people that have been terrible, terrible parents. They just, they'd rather stay out all night and never come and they don't want to take care of their kids and they get, they split up with the wife or the girlfriend who's got the kid and they don't give child support and it's a really common theme and I mean there's a lot of men out there that don't pay child support. That's a dark, dark thing. You have a child out there that needs food and you don't want. You're so fucking selfish. You don't want to provide resources. Not only do you not want to be there for companionship, you don't want to provide resources to pay for the child's food.

Speaker 1:          02:34:45       You don't feel responsible for it. I mean, that was my case when I was a kid. My Dad didn't pay child support and we were very poor. It's one of the reasons why we were so poor and I know other people that have that same experience, so it's not everyone that becomes a father or that impregnates I should say a woman and becomes a and the other side is true too. There's women that are terrible mothers for whatever reason. I mean maybe they're broken psychologically. Maybe they have mental health issues when whatever it is. There's some women that are fucking terrible moms and it's sad, but it makes you appreciate women that are great mom so much more. You know, when I see guys like you at the inspiration is some looking for sort of structural. What's the process to then fit people into your life?

Speaker 1:          02:35:33       But what I hear is when it happens, you just do. You can always put that this is the thing, man, we're not living in a book. We're not living in a movie. It doesn't always happen. Like you have to decide that you want it to happen and you got to go looking for it because if you don't, you could just be older and still alone. Time goes. A lot of my friends that have never had kids and now they're in their fifties. I mean comedians. You have to be on the road a lot, not just on the road. You have to be obsessed with comedy. Like it's. It's got to be something. You're always writing new jokes because you're always reading a new. Especially if you put out a special right, you put like. I just did a Netflix special. It's out now, so I'll really have like a half hour new material.

Speaker 1:          02:36:13       That's it and I'm great by the way. Thank you very much. The first special I've washed, it was actually really weird, decided to go on a tangent, but I've listened to you quite a bit, but I've never looked at you doing comedy and it was so different because here you're just like Improv, like a jazz musician here. It's like a regular conversation. The standard was special. It was clear like that's like everything is perfect. The timing. It's like watching you do a different art almost. It is kind of interesting. It's like a song or something. It's like you don't. There's some roofing to it. There's some improvisation to it, but it's also there's a very clear structure to it, but that's, that's it's so time intensive and you have to. You've got to be obsessed with it to continue to do something like that, so for some people that travel and the road that takes priority over all things including relationships and then you never really settled down and so you never.

Speaker 1:          02:37:13       You never have a significant relationship with someone that you could have a child with and I know many friends that are like that and I know friends who have gotten vasectomies because they don't want it. They liked this life and there's nothing wrong with that either. I always was upset by this notion that in order to be a full and complete adult, you have to have a child. You have to be a parent, and I think even as a parent where I think it's probably one of the most significant things in my life, I. I reject that notion. I think you could absolutely be a fully developed person and an amazing influence in society and amazing contributor to your culture and your community without ever having a child. Whether you're a man or a woman. It's entirely possible. And the idea that it's not as silly.

Speaker 1:          02:37:57       Like we're, we're all different in so many different ways, you know, and we contribute in so many different ways. There's going to be people that are obsessed with mathematics is going to be people that are obsessed with literature, that's going to be people that are obsessed with music and they don't all have to be the same puck in person because you really don't have enough time for it to be the same person you know, and there's, there's going to be people that love having children. They love being a dad or loved being a mom. And then it's going to be people that don't want to have nothing to do with that. And they get snipped early and they're like, fuck off. I'm going to smoke cigarettes and drink booze and I'm going to fly around the world and talk shit. And those people are okay to like the way we interact with each other. That's most important. That's what I think the way human beings, the way we form bonds and friendships, the way we, we contribute to each other's lives, the way we, we, we find our passion and create those things are what's really important.

Speaker 2:          02:38:53       Yeah. But there's also an element just looking at my parents, I think they got, they're still together to garden together. What it means, standards. You get together when you're like 20 or I should know this, but 23 slash 20 whatever young. And there is an element there where you don't want to be too rational. He just want to just dive in. Right. Should you be an MMA fighter? Should you be like, I'm, I'm an academia now. Uh, so I'm a research scientist at Mit. The pay is much, much lower than all the offers I'm getting nonstop as it rational. I don't know what your passion

Speaker 1:          02:39:29       it is doing what you're doing currently.

Speaker 2:          02:39:31       Yeah. But it's like, it's

Speaker 1:          02:39:33       what are the other offers? Like what kind of other jobs and are they appealing in any way?

Speaker 2:          02:39:38       Yeah. Yeah, they're appealing, so I, I'm making a decision that's similar to actually getting married, which is so the officer, well I shouldn't call them out, but google phase with the usual, the usual ai research, pretty high positions and the I'm a, just something in me that says I the edge, the chaos of this environment and mit is something I'm drawn to. It doesn't make sense so I could do what I'm passionate about on a lot of places. You just kind of dive in. Navis, I had a sense that a lot of our culture creates that momentum and you just kinda have to go with it. And that's why my parents got together like a lot of people there probably. I mean a lot of couples wouldn't be together if they weren't kind of culturally forced to be together in divorce was such a negative thing and it grew together and we created a super happy connection. So I'm a little afraid of over rationality about choosing the path of life. So you're saying like monogamy or not monogamy? Relationship don't always make sense.

Speaker 1:          02:40:45       They don't have to make sense. You know what, I think I'm a big believer in doing what you want to do and if you want to be involved in a monogamous relationship, I think you should do it, but if you don't want to be involved one, I think you should do that too. I mean, if you want to be like a nomad and travel around the world and just live out of a backpack, I don't think there's anything wrong with that. As long as you're healthy and you survive and you're not depressed and you're not longing for something that you're not participating in, but I think when you are doing something, you don't want to be doing it. It brings me back to was it throws quote. I guess I was fuck up. Who made this? What? I think I know you're most men live lives of silent desperation.

Speaker 1:          02:41:28       That's. That's real man. That's real. That's real. That's what you don't want. I think it's thorough, right? You don't want silent desperation. Yeah, it is. Right. I fucking love that quote because I've seen it. I've seen it in so many people's faces and that's one thing I've managed to avoid and I dunno if I avoided that by luck or just by fact I'm stupid and I just, I just follow my instincts whether they're right or wrong or and I make it work, but this goes back to what we were discussing when in terms of what is the nature of reality and what are these, are we just finding these romanticized interpretations of our own biological needs and our human reward systems that's creating these beautiful visions of what is life and what is important poetry and food and music and all the passions and dancing and holding someone in your arms that you care for deeply and all those things. Just little tricks or all those little biological tricks in order just to keep, keep on this very strange dance of human civilization so that we can keep on creating new and better products that keep on moving innovation towards this ultimate eventual goal.

Speaker 2:          02:42:47       Artificial intelligence of this giving birth to the gods. Yeah. Giving birth to the guns. Yeah. So, you know, I did want to mention one thing about, uh, the one thing I really, I don't understand fully, but I've been thinking about for the last couple of years at the application of artificial intelligence to, into politics. I've heard you talked about sort of a government being broken in the sense that one guy, one president that doesn't make any sense. I see you, you get like, you know, people get hundreds of millions of likes on their facebook pictures and uh, instagram and we're always voting with our fingers every single day. And yet for the election process it seems that we're voting like once every four years it feels like this new technology could bring about a world where the voice of the people can be heard on a daily basis. Like where you could speak about the issues you care about, whether it's gun control and abortion, all of these topics that are. So, he so debated. It feels like there needs to be an instagram for elections. I agree. And I think there's room for that. I've been thinking about how to write a few papers are proposing different technologies. It just feels like the people that are playing politics need to our old school

Speaker 1:          02:44:10       that is like the influencers, right? If you look at Instagram, I mean, should Nicki Minaj be able to decide how the world works because she's got the most followers. Should Kim Kardashians, like who's influencing things and why and you have to deal with the fickle nature of human beings and do we give enough patients towards the decisions of these so called leaders that we're electing to adored you just decided fuck them. They're out new person in because we have like a really short attention span when it comes to think, especially today with the new cycles so quick,

Speaker 2:          02:44:46       so the same process. So the instagram might be a bad example because yeah, you get or twitter and you start following Donald Trump or and you start to sort of idolize these certain icons that do we necessarily want them to represent us? I was more thinking about the, the Amazon product reviews model recommender systems or Netflix, the movies. You've watched the Netflix learning enough about you to represent you in your next movie selection. So in the kind of movies like what do you like [inaudible] Joe Rogan, what are the kinds of movies that you would like the recommender systems, these artificial intelligence systems learn based on your netflix election that could be deeper understanding of who you are than you're even aware of. And I think there's that element. I'm not sure exactly, but there's that element of learning who you are like, do you think drugs should be legalized or not? Like, do you think? I do think immigration, should we let everybody in? I'll keep everybody out. Should we all. All of these topics with a red and blue teams now have a hard to answer. Of course you keep all the immigrants out or of course you need to be more compassionate of course, but for most people is really a gray area and exploring gray area. The way

Speaker 3:          02:46:10       you would explore the gray area of Netflix. What is the next movie or watching? Do you want to watch the Little Mermaid or a godfather? To me, what that process of understanding who you are. I just. It feels like that there's room for that in our other problem.

Speaker 1:          02:46:25       Home is of course that you have. There's grave consequences to these decisions that you're going to make in terms of the way it affects the community and you might not have any information that you're basing this on at all. You might be basing all these decisions, decisions on misinformation, propaganda, nonsense advertising. You'll be easily influenced. You might not have looked into it at all. You can be ignorant about the subject and it might just appeal to certain dynamics that have been programmed into your brain because you grew up religious or you grew up in an atheist or you know. The real problem is whether or not people are educated about the consequences of these decisions. We're going to see information. Yeah, and then I think, I mean, I think there's going to be a time in our, in our life where our ability to access information is many steps better than it is now with smartphones. I think we're going like Elon Musk has some neuro link thing that he's working on right now, is being very vague about it.

Speaker 3:          02:47:30       Increase the bandwidth of our human interaction with machines is what he's worth.

Speaker 1:          02:47:34       Yeah. I'm. I'm very interested to see where this leads, but I think that we can assume that because something like the Internet came along and because it's so accessible to you and I right now with your phone, just pick it up, say, hey google, what the fuck is this? And then you get the. You get the answer almost instantaneously. That's gonna change what a person is as that advances and I think we're much more likely looking at some sort of a symbiotic connection between us and artificial intelligence and computer augmented access to information than we are looking at the rise of some artificial being that takes us over and fucks are girlfriend.

Speaker 3:          02:48:18       Well yeah. That's the real existential threat. Yeah, I think so. That's to me is super exciting. The phone is a portal to this collective that we have this collective consciousness and it gives people a voice. I would say if anyone's like me, you really know very little about a politicians you're voting for, or even the issues like global warming. I'm embarrassed to say I like, I know very little about it, like if I'm actually being honest with myself, I've heard different, like I know what I'm supposed to believe as a scientist but actually know nothing about concrete and not nothing concrete about process about the va, the environmental process. And why is it so certain scientists apparently completely agree. So as a scientist,

Speaker 4:          02:49:08       um, I kinda take on faith oftentimes what the community agrees in my own discipline I question, but outside I just kind of take on faith and the same thing with a gun control and so on. You just kind of say which team of my own. And I'm just going to take that on. I just feel like it's such a disruptive space to where people could be given just a tiny bit more information to help them. Well maybe that's where something like neuro link comes along. It just enhances our ability to access this stuff in a way that's much more just more tangible than just being able to google search it and maybe this, this process is something that we really can't anticipate. It's going to have to happen to us. Just like what we're talking about, cell phone images that you could just send to Australia with the click of a button that no one would have ever anticipated that 300 years ago.

Speaker 4:          02:49:55       Maybe we are beyond our. Our capacity for understanding the impact of all of this stuff. Maybe kids coming up now. What is that world going to look like when you're too old to be sitting? You'll be like 95 sitting on a porch with a shotgun cleaning swing and what do those kids look like when they're 18 years old? Robots fucking x Ray vision and they could read minds. Yeah, well yoga is going to happen. They'd be saying, robots are everywhere these days. Back back in my day, we used to put robots in their place. They were serving. Shut them off and now fuck your mom. Now they want to go to the same school as us. Yeah. And they want to. They want to run for president. You know, they want to run for president. Yeah. They're more compassionate and smarter, but we still hate them because they don't go to the bathroom.

Speaker 4:          02:50:47       Yeah. Well now we half the country, look at them and the other love them and Abraham Lincoln character will come along. That's what I'm pitching myself. I'm telling you, you Lincoln of the robot world of the robot world, that's the speeches that everybody quotes in. One other thing I got to say about academia. Okay? In defense of academia, so you've had a lot of really smart people on including Sam Harris and uh, Jordan Peterson. And often the word academia is used to replace a certain concept. So I'm part of academia and most of academia is engineering is biology, is medicine is hard sciences. The humanities that are slippery. Exactly in humanity. And I think a subset of humanities that I know nothing about. And there a subset. I don't want to speak about gender studies. Say it. I don't know man. Candy man. I actually live on Harvard campus, so I go to mit, but I live on Harvard campus and yet is there. They have apartments for you guys. How does that work? Yeah, they hand them out as. No, I just, I don't care to live on the campus. What do you mean? Uh, sorry. Like in Harvard Square. Oh, Harvard Square in Cambridge and Cambridge. Yeah. Yeah. So I, I used go to catch a rising

Speaker 1:          02:52:05       star when it existed. They used to be a great comedy club in Cambridge. There's a few. There's a few good comedy clubs there. Right. Well there's a Chinese restaurant that uh, that has stand up there still. How does that work? Well, it's upstairs. There's like this, a comedy club up there. Yeah. Do you ever, ever, because you've done your specialist in Boston? Yes, I did. At the Wilbur theater. Have you ever considered just going back to Boston and doing like that Chinese restaurant? The Ding Ho? Yeah. That was before my time when I came around. I started in 1988. The Ding Ho had already ended, but I, you know, I got to be friends with guys like Lenny Clarke and Tony v and all these people that told me about the ding ho and Kenny Rogers and the comics that were in Barry Crimmins who just passed away rest in peace, uh, who was really the Godfather, that whole scene and one of the major reasons why that scene was so had such really some rock solid morals and ethics when it came to the creation of material and standards.

Speaker 1:          02:53:10       It was a lot of it was barry crimmins because he was just a, that's just who he was as a person, you know. Um, but that was before my time. I came around when I came around like four years after that stuff. And so there was tons of comedy clubs. It was everywhere, but I just didn't get a chance to be around that. Uh, that Ding Ho scene. And you stayed in Boston for how many before you moved out here? I was in New York in a, by the time I think I was in New York by 90 to 91. Ninety two. So it was in Boston for four or five years doing stand up.

Speaker 4:          02:53:46       How'd you get to from Boston to New York? Met My match on Wendy's. This opportunity for you to talk about. What about Connecticut gets upset at me. It's become a running theme to talk Shit About Connecticut or I've heard you do a ones. I just had a buddy who did a Gig in Connecticut. He told me was fucking horrible. I go, I told you, bitch should've listened to me. Don't book gigs and Connecticut Fuck's wrong with you? This 49 other states. But that's great. You go back to Boston and do like small gigs. Small and sometimes. Yeah, I'll do. Um,

Speaker 1:          02:54:26       yeah, laugh. Boston is a great club. I used to do nick's comedy stop and all the other ones there. But I, I, I, you know, I love the Wilbert Wilbert is a great place to perform. I Love Boston. I would live there if it wasn't so fucking cold in the winter. But that's what keeps people like me out. Keeps the pussy

Speaker 4:          02:54:43       right. Listen, we got to end this. We got to wrap it up. We've already done three hours flies by it. Did it flew by A. Can I say to? Sure. Sure. So first I got to give a shout out to my shout out. Shout out CEO, a long, long time friend Matt. Her Randy from Chicago has been there all along. He's a of the podcast, so he's probably listening. Um, him and his wife had just had a beautiful baby girl. So I want to just send my love to him and I told myself I'll ended this way. Okay, let me end it the way he ended it. Love is the answer. Love is. The answer is probably is unless you're a robot.

Speaker 5:          02:55:22       Bye.