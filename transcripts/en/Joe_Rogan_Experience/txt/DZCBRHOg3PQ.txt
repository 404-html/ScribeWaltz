Speaker 1:          00:00:00       Five four, three, dos uno, come on. Tri caster

Speaker 1:          00:00:12       live. Well, live plays and gentlemen to my left, uh, Tim Timple, everybody knows and loves him. Viga, what is it? How do you, how do I pronounce your last name again? Not Visa. Vigia Vigia Gadi Gadi and your position at Twitter is I lead trust and safety. Legal and public policy. That's a lot. That's a lot. And Jack Dorsey, ladies, gentlemen. Um, first of all, thank you everybody for doing this. Appreciate it. Thank you. Feels the feels all of a sudden there's tension in the room. We're all, we're all loosey Goosey. Just a few minutes ago, attention never wins. Like, oh, this is really happening. Here we go. Um, before we get started we should say, because there were some things that people wanted to, uh, have us talk about. One that the cash APP is one of the sponsors of the podcast. It's been a sponsor for a long time and also a giant supporter of my good friend Justin is fight for the forgotten charity, building wells for the pygmies in the Congo.

Speaker 1:          00:01:09       This is very important to me and I'm very happy that you guys are a part of that and you are connected to that. I don't, uh, that's, I mean it's easy for someone to say that doesn't have an influence on the way we discuss things, but it doesn't, so if it does, I don't know what to tell you. I'm going to mention too, just cause I don't want people to come out and freak out later. I actually have like 80 shares in square, which isn't really that much, you know, but, but it's something, it is, it is. So I don't want people to think, you know, whatever you, you're the CEO of square, I think, right? Yup. Yeah. There you go. Well, there you go. We on, we on the cash up out. And the reason why we decided to come together is, um, we had, I thought, a great conversation last time, but there was a lot of people that were upset that there were some issues that we didn't discuss or didn't discuss in depth enough or they felt that I didn't press you enough.

Speaker 1:          00:01:55       I talked to Tim because, uh, you know, Tim and I have talked before and he made a video about it and I felt like his criticism was very valid. So we got on the phone, we talked about it, and I knew immediately within the first few minutes of the conversation that he was far more educated about this than I was. So I said, would you be willing to do a podcast and perhaps do a podcast with Jack? And he said, absolutely. So we did a podcast together. It was really well received. People felt like we covered a lot of the issues that, um, they felt like I didn't bring up. And so then Jack and I had discussed it and we said, well, let's bring Tim on and then have Vigia on as well. I say that right? Yeah, that's a hard one. Sorry. I'll get it right.

Speaker 1:          00:02:34       I promise. Uh, but, so we're here, we're here, um, today. Uh, you know, do you know who Sean Baker is? He's a doctor who's a prominent proponent of the carnivore diet. His post was, his account was frozen today. I just sent it to Jamie. Yeah, his count was frozen today because of an image that he had, because he's a proponent of the carnivore. There's a lot of people that believe that this elimination diet is very healthy for you and it's known to cure a lot of autoimmune issues with certain people, but some people ideologically opposed it because they think it's bad for the environment or you shouldn't eat meat or whatever the reasons are. This is huge. And the bitcoin community, yes. Yeah. Well it's the, for a lot of people that have autoimmune issues with particularly psoriasis and arthritis is, is a lifesaver. It's crazy. It's essentially, it's an autoimmune issue, so because he has a photo of a lion in a header eating a looks like a wheel to peace or something like that, his account was locked for violating these rules, rules against graphic violence or adult content in profile images. That seems a little silly and I, I wanted to just mention that right away now, whose decision is something like that, like who decides to lock a guy's account out because it has a nature image? If you know natural predatory behavior

Speaker 2:          00:03:57       on this particular case, it's probably an algorithm that detected it and made some sort of an assessment. But as a general rule, how we operate as a company as we rely on people to report information to us. So if you look at any tweet and you can kind of pull down on the carrot on the right and you can say report the tweet and then you have a bunch of categories you can choose from what you want to report. Um, I think this one in particular though, it was probably an algorithm.

Speaker 1:          00:04:20       So how does does, does he have the option to protest that or to ask someone to review it?

Speaker 2:          00:04:27       Absolutely. And I, I, I'm guessing that people are already reviewing it, but there's a choice to appeal any action and that would go to a human to make sure that it is actually a violation of the roles or in this case, if it's not, then it would be removed. Is that a violation of the rules? I image? I don't think so. I don't think that that would be what we're trying to capture in terms of graphic images and an avatar. It's more about violence towards, uh, humans unless it was some sort of cruelty depicting or walls or something like that. But this seems not the intention of the role.

Speaker 1:          00:04:56       Does this ha this one of the reason why I wanted to bring this up immediately, does this highlight a flaw in the system in that people can target an individual cause with him, he's uh, he, like I said, he's a doctor and a proponent of this carnivore die, but he's also, he ruthless in his condemnation and mocking of vegans. He does it all the time and so then they get upset at him and they can target posts and just report them and mass. And when they do that, then this becomes an issue.

Speaker 2:          00:05:26       I think this does reveal part of, um, you know, the challenges that we face as a global platform at scale and this PR, I don't, I don't know what happened in this case, sorry. It's hard for me to talk about it. But what I would say is that it doesn't really matter if one person reports it or 10,000 people report it. Like we're going to review the reports and we're going to make an assessment and we're never going to, you know, kick someone off the platform finally and forever without a person taking a look and making sure that it's an actual violation. Right. Okay. So, but the, but the mob

Speaker 3:          00:05:58       reporting behavior, it does happen.

Speaker 4:          00:05:59       Yeah, it does. It happens across the spectrum. I'd have to assume it's going to be one direction. I, I can't imagine he would target vegans, but vegans would talk at him. Right? Well, he might, I mean, he doesn't, but is he the kind of guy is going to want to report to vegans and get them banned from Twitter. Of course you're gonna wanna make fun of them. He's going to make fun of them. They're going to target him to try and get them removed by exploiting the system that you guys have.

Speaker 2:          00:06:19       It may not be him though. It can also be his followers. It's a really complicated world out there. So yeah, you don't want the motivations of why people mob report are different and it's not always something under someone's control.

Speaker 1:          00:06:30       We could ease and even be other carnivore diet proponents who are just jerks that don't like him because he's getting all the love people are weird. Yeah. But it's history. The idea though is that it does kind of highlight a bit of a flaw in that it's good that someone can like, cause you might see something awful, someone doxing someone or something like that and then you can take that and report it and then people can see it and get rid of it and minimize the damage

Speaker 4:          00:06:56       that there's another big problem here and that is the Carnivore Diet legitimately healthy? Is it a threat to your health? And if it is is what is Twitter's responsibility in controlling that information? Right. So just to clarify my, my, my opinion is if he wants to be a proponent for the carnivore diet, let them, but you've got people on Youtube who are being d ranked for certain beliefs about certain health issues that I don't agree with. And so one of the risks then is, you know, we're coming towards a position where people think some ideas are better than others. Therefore, as a company we're going to restrict access to certain information. You mean like anti-vaxxer. Exactly. Right. So I guess I'm trying to say is at what point would you guys restrict someone from sharing info, like false information about vaccines? I could get someone hurt

Speaker 2:          00:07:39       that is not a violation of Twitter was roles. No, I, I think,

Speaker 3:          00:07:44       I mean that'd be interesting to hear your ideas around this book or our perspective right now is, um, around this concept of variety of perspective. Like are we, are we encouraging more echo chambers and filter bubbles or we at least showing people other information that might be counter to what they see. And there's, there's a bunch of research that would suggest that further emboldens reviews. There's also research that were suggested. It at least gives him a consideration about what their, what they currently believe. So w you guys, oh, go ahead. Sorry. Given the dynamics of our network being completely public, we're not organized around communities. We're not organized around topics. Um, we have a little bit more freedom to show more of the spectrum of any one particular issue. And I think that's how we would, we would approach it from the start that said, we haven't really dealt much with misinformation more broadly across like these sorts of topics. We've, we've focused our efforts on elections and uh, well mainly elections right now.

Speaker 1:          00:08:46       Yeah. Youtube is a different animal. You know, someone can really convince you that the earth is flat. If you're gullible and you watch a 45 minute youtube video right now it's kind of a different

Speaker 2:          00:08:56       thing. But I want to, I want it to just kind of, uh, get into that statement you made about misinformation and whether or not you'll police it. So like, I think that the tough part of this is really an love to have a discussion about this is do you really want corporations to police what's true and not true? Absolutely not. So really, really tough position. But you guys do that. We try not to do that. We don't want to do that. But you do and your rules. But the places that we focus on is where we think that people are going to be harmed by this in a direct and tangible way that we feel a responsibility to correct ourselves. Rules to what do you mean by that? Gender dead naming and mis-gendering that's a specific ideology that's unique to a very small faction of people in this world that you guys actually banned people for.

Speaker 2:          00:09:37       So the way I think of it is it's behavior based. And I know you think of it as content and we can, we can disagree on this point, but this is about why are you doing this to a trans person? Why are you calling them by this name when they've chosen to go by a different name or why are you outing them in some way? Like what is your intent and purpose behind that? [inaudible] mean to interrupt. But in the interest of clarity, I wanted to explain what deadnaming means. Right? Right. So that, so, uh, a transgender individual changes their name when they transition. A dead name would be the birth name or the name they went by before the transition. So that was my mom's probably going what and what's a debt name? And I will clarify to your role specifically targeted mis-gendering and deadnaming.

Speaker 2:          00:10:19       I believe it's correct. Right? So years ago we passed a policy that we call our hateful conduct policy and that prohibits targeting or attacking someone based on their belonging and, and any number of groups, whether it's because of their religion or their race or their gender, their sexual orientation and their gender identity. So it was something that's broad based is that you, you can't choose to attack people because of these characteristics will have limits on what characteristics you police. Right? So you're not, you're not a banning people, but for targeted trans species. Others, right. Uh, will, we have also general abuse and harassment are walls, right? Which says you can't engage in abuse and harassment on the platform, but you can't designate someone, but you can call them stupid. Uh, generally, I mean, if you created an account that, uh, only was there to call the same person stupid 5,000 times, we'd probably view that as a, you know, targeted, harassed, targeted harassment.

Speaker 2:          00:11:10       It's a function of the bit, it's a fortunate behavior because people with our system can do this in massive velocity. Ultimately silence you from a platform or to say like I give up, I don't want to deal with this thing so we can just get into all of the big examples. I mean uh, starting with painting to Tim, but can we just take a step back and try to level set of what we're trying to do with our policies because I think it's worth doing. Yes. So as, as a, as a high level, I personally, and this isn't my job to run the policy team, I believe that everyone has a voice and should be able to use it and I want them to be able to use it online. Now where we draw a line is when people use their voice and use their platform to abuse and harass other people to silence them.

Speaker 2:          00:11:53       Because I think that that's what we've seen over the years is a number of people who have been silenced online because of the abuse and harassment they've received. Any, either stop talking or they leave the platform and its entirety. If you look at free expression and free speech laws around the world, they're not absolute. They're not. Absolutely. There's always limitations on what you can say and it's when you're starting to endanger other people. So my question then is when I was physically threatened on Twitter, you guys refuse to take down the tweet and I showed up in Berkeley and someone physically threatened me because they were encouraged to, when I was in Venezuela I was physically threatened by high profile individual, 10,000 people tweeting at me. You guys do nothing. Right? So I guess there's the obvious question of why does it always feel like your policies are going one direction politically you say it's about behavior.

Speaker 2:          00:12:35       You said it several times already, but I've already, I've got tons of examples of that not being the case and you will always be able to find those examples. Examples where you guys were alerted multiple times and did nothing. Like when Antifa docs, a bunch of law enforcement agents, some of the tweets were removed, but since September, this tweet is still live with a list of private phone numbers addresses yet Kathy Griffin, she's fine. The guy who threatened the lives of these kids in Covington and said, lock him in school and burn it down. You did nothing. I mean he got suspended it take his tweets down. Was he banned for threatening the lives of kids? Absolutely not. There again, we have an, um, I'm happy to talk about all these details. We have our policies that are meant to protect people and are meant to enable free expression as long as you're not trying to silence somebody else.

Speaker 2:          00:13:20       Now we take a variety of different enforcement mechanisms around that. Sometimes you get warned, sometimes we were, your tweet is forced to be deleted. It's a very rare occasion where we will outright suspend someone without any sort of warning or any sort of ability to understand what happened. What did you guys do with Kathy Griffin when she was saying she wanted the names of those young kids were in the maggot hat. So the Covington high school counts. That's all right. That's a great example, Joe. So in that particular case, you know, our doxing policy really focuses on posting private information, which we don't consider names to be private. We consider your home address, your home phone, your home phone number or your mobile phone number, those types of things to be private. So in that particular case we took what I think now is probably a very literal interpretation of our policy and said that that was not a doxing incident.

Speaker 2:          00:14:06       Do you think that was an error? I think that it was shortsighted and given the context of what was going on there that um, if I was doing this all over again, I would probably ask my team to look at that through the lens of what was the purpose behind that tweet. And if the purpose was in fact to identify these kids to either docs them are abusing, harass them, which it probably was, then we should be taking a more expansive view of, of that policy and including that type of content. Especially considering the fact they're minors. Exactly. Right away though. Exactly. The approach. So this is a trial and error sort of learn and move on with new information sort of a deal. Absolutely. We're gonna learn, we're gonna make a ton of mistakes. We're trying to do this, uh, with hundreds of millions of accounts all around the world, numerous languages. We're going to make mistakes even if we get, there will always be mistakes, but we're hoping to learn from those and to make ourselves better and to catch cases like Tim's or others where we clearly may have made an error. And I'm open to having those discussions. I'm not, I'm sorry Tim familiar with your specific cases, but I'd love to follow up with you and

Speaker 4:          00:15:08       you want to understand what it's like. You want to pull it up. So it's a, B I t. Dot. L Y slash Antifa tweet, all lowercase.

Speaker 5:          00:15:16       This is also an evolution in prioritization as well. We're, one of the things we've come to recently is we do, we do need to, we do need to prioritize these efforts both in terms of policy enforcement, um, how we're thinking about evolving them. Um, one of the things that we want to focus on as number one is physical safety. And this leads you immediately to something like doxing. And right now the only way we take action on a docksin case is if it's reported or not. What we want to move to is to be able to recognize those in real time, at least in the English language, recognize those in real time through our machine learning algorithms and take the action before it has to report it. So we're focused purely right now on going after a docksin cases with our algorithms so that we can be proactive. That also requires a much more rigorous appeals process to correct us when we're wrong, but we think it's tightly scoped enough. It impacts the most important thing, which is someone's physical safety. Once we learned from that, we can really look at the, the biggest issue with our system right now is all the burden is placed upon the victim. So we only act based on reports. We don't have a lot of enforcement. Um, especially with, with more of the more, the more the take downs that are run through machine learning and deep learning.

Speaker 4:          00:16:36       But if, if something is reported, a human does review it eventually or are there a series of reports that you'd never get to?

Speaker 5:          00:16:42       There's, there's probably reports we don't, I mean we prioritize a queue based on severity and the city. The thing that Walmart, mark severity is something like physical safety or private information or whatnot. So generally we try to get through everything, but we have to prioritize that cue even coming in.

Speaker 4:          00:16:57       So if, if someone threatened the lives of someone else, you would, would you band that account? Would you tell them like, like let's say someone tweeted three times, kill these people, I want them dead three times. Is that, yes. You didn't, you didn't abandon him though that up, Jamie. That's a, I don't know. I don't, I don't necessarily want to give out specific usernames because they're not, people just point the finger at me and saying, I'm getting these people band. But yeah. You know, during Covington, this guy said multiple times too. He wanted his followers to go and kill these kids. Yeah.

Speaker 5:          00:17:27       And we have to look at that. But we also have look in the context, cause we also have, I think we talked about this a little bit in the last podcast, but we, we have gamers on the platform who are saying exactly that to their friends that they're going to meet at the game in the game tonight. And without the context of that relationship, with the context of the conversation that we're having, we would take the exact same action on, on them incorrectly. Yeah.

Speaker 4:          00:17:50       That I, that I understand. I think in the case of Covington though, this user was so high profile, he's a verified user. He's got something like 20,000 followers and it was highlighted by numerous conservative media outlets saying, wow, this guys, it screenshot it. It's being shared. I mean you had a Disney producer like saying a picture of a wood chipper with a body being thrown in at saying that's what you want it to happen. You know. So I, I do know that some of these accounts got locked. Producer was doing that. That. Well, I'll, I'll clarify fact check me on that. But that's the, basically the conversation that was had it, there's a guy, Disney was, he posted a picture of from Fargo of someone being tossed in a wood chipper and he says, I want all these Maga kids, you know, done like this. You had another guy who specifically said lock them in the school, burn it down, set a bunch of disparaging things and then said if you see them fire on that many tweeted that more than once

Speaker 2:          00:18:35       and that those accounts where those tweets were taken down, those were violations of our rules.

Speaker 4:          00:18:39       That's, I'm pretty sure it's actually illegal to do that. Right. It's to, to, to tell, to tell you or any individual to commit a felony is a crime like, right.

Speaker 2:          00:18:48       Yeah. Incitement of violence in many places. I just have to wonder how, like I understand the context issue, but this is what, this is what I talk, what other context and scale too though. Right. That's him. Those accounts were actioned. They may not have been action the way you want it to, but the, the tweets were forced to be deleted and the account were shorts. I can penalty for that. So I understand that. What kind of a penalty? Well, again, as I said it earlier, Joe, we don't, uh, usually, uh, automatically suspend accounts with one violation because we want people to learn. We want people to understand what they did wrong and give them an opportunity not to do it again. Right? And it's, it's a big thing to kick someone off the platform. And I take that very, very seriously. So, so I want to make sure that when someone violates our rules, they understand what happened and they're given an opportunity to, you know, get back on the platform and change their behavior.

Speaker 2:          00:19:37       And so in many of these cases, what happens is we will force someone to acknowledge that their tweet violated our rules, forced them to delete that tweet before they can get back on the platform. And in, in many cases, if they do it again, we give them a timeout, which is like seven days. When we say, look, you've done it again. It's a temporary suspension. If you do it again, you're a mom. I'm totally a mom. Exactly. And your mom too. And if you do it again then you're done. Right. So it's kind of like, you know, three strikes. So it's sort of like baseball. And so in some of these cases at Tim's referencing, I have to imagine because the streets weren't deleted, they are violations of our rules. People are upset that the account came back again and was allowed to say other things. But we did take action on those tweets. They were violations of it. And then you have people like Milo who was mean to a person and you delete, you banned him permanently. There's more than I actually Tim, let's talk about it. Yeah, yeah. I'm, I'm happy to talk about Milo and actually brought the tweets.

Speaker 4:          00:20:29       It can also, so let's, let's preface that by saying, the point I want to make sure is clear is that you had somebody who actively called for the death of people. I understand the context issue. Maybe he's talking about video games, probably the some scale. And scale. So this is a verified user

Speaker 2:          00:20:41       and that's just the complexity and enacting not an excuse for why we don't do it in a particular writer. And then

Speaker 6:          00:20:48       there, there are a lot of other examples too. They get into more egregious areas that I've, I've prepared. So here we have someone with over 20,000 followers. He's verified numerous times insights his followers to commit a crime against these kids. The action taken against him is delete the tweets. You get a suspension, you get time out. Then you have people like Alex Jones who be rated a CNN reporter permanently banned. You get Milo Yiannopoulos. He was mean permanently banned. That that's your impression. That's not what happened. Okay, let's, let's, let's play, let's do this one at a time. Let's start with Milo. What was the details with Milo? Milo had a number of tweets that violated, our rule has gone back to 2014 but I'm going to talk about the final three and this three snakes concept. Um, he claimed to be a buzzfeed reporter and his bio.

Speaker 6:          00:21:33       Um, and he's a verified accounts that is impersonation. I'm not sure why he did that. He did do that. We'll buzzfeed's a left wing thing. So he was doing parody a potentially, but our party rules are very specific that if you have an account that's mean being, uh, is a parody account, you need to say that it is a parody accounts. People, everybody who knows Milo would know that he's not a buzz feed reporter. That people who don't know Milo, we'll look at that verified account and say, but he wasn't verified after awhile. You removed as verification. He violated our rules around verification. So the vowel, the verification was removed because of the buzzfeed thing. I believe so. I can, I can confirm them. Could I believe so. He also a docked someone, he posted, um, private information about an individual. So that was the second one.

Speaker 6:          00:22:19       He tweeted to somebody else. Um, if you are my child, I'd have dashed your head on a rock and try it again, which we viewed as a threat. Really. That's, I'm seems like he's saying like, your mom should have swallowed you. You know, it's like, you know what I'm saying? He's like, you're, you're a mistake. I'll take that. That's a threat. I understand why reasonable people would have different impressions. I'm just going through and telling you what they are just so we can have all the facts on the table and then we can debate them. And then the last one, we found a bunch of things that he posted that we've viewed as incitement of abuse against Leslie Jones. So there's a bunch of them. But the one that I like to look at in which really convinced me is he posted to doctor tweets that were supposedly by Leslie Jones.

Speaker 6:          00:23:05       They were fake tweets. Um, the first one said, white people are getting on my nerves. Like how can you call yourself human? And then the second one said, the God damn a slur for a Jewish person at Sony ain't paid me yet. Damn bics nude better pay up. This was just a fake tweet that someone had photo-shopped two for two, two fake tweets. And we know they were faked because we could still tell from the software and they were faked, can't always tell. So it is possible that he didn't know they were faked. It's possible someone send it to him and he didn't do his due diligence and looking it

Speaker 1:          00:23:45       up.

Speaker 2:          00:23:46       It is possible. But it was pointed out to him that they were fake because he left it on. And not only did he leave it on, he said, don't tell me some mischievous intranet. Rascal made them up. Exclamation point. So this and the context of a bunch of other things he was saying towards Leslie Jones on Twitter, I and my team felt that this was taken as a whole incitement of harassment against her.

Speaker 1:          00:24:09       Wasn't there another issue with multiple accounts that were connected to him?

Speaker 2:          00:24:14       Uh, there were a bunch of other issues on the background, but these are the three primary things that we looked at in terms of,

Speaker 1:          00:24:21       but the other things that were in the background, weren't they multiple accounts that were connected to him? Like

Speaker 2:          00:24:28       I think that I'm, I'm not sure about that. Uh, Joe, I think it was more that we found him to be engaging in coordinated behavior and inciting people to, to attack Leslie Jones.

Speaker 1:          00:24:38       Now with a case like him? No, I'm just going to be honest. When I'm listening to those or listening to read those tweets out, they don't sound that bad. And they certainly don't sound as bad as calling for the death of a child who's wearing a maggot hat. Throw him into a woodshop or the fact that that guy is still out there tweeting and yet Milo's not Milo's initial, the whole thing stemmed from, other than the buzzfeed thing, stemmed from his legitimate criticism of a film. And he's, you know, he's a satirist. He was mocking this film.

Speaker 2:          00:25:08       The doxing incident wasn't related to doxing. Yeah. Why don't we, why don't we stop? We all agree that doxing, if something that Twitter should take action 100%, right? Yeah. Because frightened people in real life. And I take an enormous amount of responsibility for that because I fear daily for the things that are happening on the platform that are translating into the real world. So, uh,

Speaker 7:          00:25:30       Milo is a contentious figure and there are certainly things you can pull up that I wouldn't agree with. Anything he did there. I think those are horrible. I think Joe brought up some really good points, but what about Chuck Johnson? Why was Chuck Johnson Band? I don't have those details in front of me to, Chuck Johnson said that he was preparing something to take out d deray Mckesson, and in the, in a journalistic context, people take this to me and he was going to do a dossier or some kind of hit piece on Deray is permanently banned. And my understanding, and it's been a long time since I've read this, there was some leaked emails, I think from Dick Costolo where he said maybe it wasn't deck. I don't want to drag deck. I don't know who it was, exactly what they said. I don't care. Just get rid of him. And he was off. So you have, and again, maybe there's some hidden context there, I don't know. But on the surface,

Speaker 1:          00:26:10       the concern is that this is always leaning towards the left.

Speaker 7:          00:26:15       Oh, it absolutely is. And I'm, I'm, I'm not even getting started. Yeah,

Speaker 2:          00:26:19       I can understand why you feel that way. I don't think that's true. I think we look at each individual instance of violations of our rules and try to make the best case that we can. Right. Just not trying. And I, I do think Joe, just to just to say, I do think we've failed in a couple of ways and I want, I want to admit that. Okay. Number one, we haven't done enough education about what our roles are because a lot of people violate our rules and they don't even know it. Like some of the statistics that we've looked at, like for a lot of first time users of the platform, if they violate the rule once, almost two thirds of them never violate the rules again. So we're not talking about like a bunch of people accidentally. Like if they know what the rules are, most people can avoid it.

Speaker 7:          00:26:54       And most people when they feel the sting of a violation, they go, okay, I don't want to lose my rights to post.

Speaker 2:          00:27:00       Exactly. And they're, and they're able to do it. So we have a lot of work to do on education so people really understand what the rules are in the first place. The other thing we have to do to address these allegations that were doing this from a bias perspective is to be really clear about what types of behavior are caught by our rules and what types are not, and to be transparent within the product. So when a particular tweet is a found to be in violation of our rules being very, very clear like this wheat was found to be in violation of this particular role and that's all work that we're doing is we think the combination of education and transparency is really important, particularly for an open platform like Twitter. It's, it's just part of who we are and we have to build it into the product.

Speaker 7:          00:27:37       I appreciate that. Your particular thoughts though on those examples that he described when he talking about someone saying they should throw these children into a wood chipper versus Chuck Johnson saying he should take this guy, he wants to prepare a dossier to take this guy out, or how did he say it? He said something like, I'm going to take out deray McKesson with, he said, I'm preparing to take out Derek, something like that. I can't remember. I can understand. It could be misconstrued as he was trying to assassinate him. Right. You could, you could misconstrue it that, but not a direct threat. But the other one's a direct threat. One guy has banned for life, the other guy is still

Speaker 2:          00:28:09       posted and we can, I'm happy to follow up. I was, you don't have all the Chuck Johnson. It's not about one thing. As I said, it's about a pattern and practice of violating our rules and we, we don't want to kick someone off for one thing, but if there's a pattern in practice like there was from Milo, we are going to have to take action at some point because we can't sit back and let people be abusing, harassed and silenced on the cloud.

Speaker 7:          00:28:28       Well, so, so one really important thing that needs to be stated is that Twitter by definition is a biased platform in favor of the left period. It's not, it's not a question. I understand you might have your own interpretation, but it's very simple. Conservatives do not agree with you on the definition of mis-gendering. If you have a rule in place that specifically adheres to the left ideology, you by default are enforcing rules from a biased perspective.

Speaker 2:          00:28:50       Well, Tim, there are a lot of people on the left who don't agree with how we're doing our job either for sure and those people think that we don't take enough action on it and are Rasman and then we left far too much behavior go.

Speaker 7:          00:28:59       That's a radical example though. I mean what he's talking about, I mean in terms of generalities, the in general things lean far more left. Would you agree with that? I don't know what that means, but in this particular case it's how the speech is being used. This is a new vector of attack that people have felt that I don't want to be on this platform anymore because I'm being harassed and abused and I need to get the hell out. What people harassed and abused me all day and night. You don't do anything about that. I, I, my, my, my notifications permanently locked at 99 you have a worse than I do. I mean you got substantially more followers and I don't click the notification tab anymore because it's basically just harassment. And I even when, so this is a really funny anecdote, I was covering a story in Berkeley and someone said if you see him

Speaker 4:          00:29:42       attack him like it was, it was, I'm paraphrasing, they said basically to swing at me, take my stuff, steal from me, and Twitter told me after review, it was not a violation of their policy. Somebody made an illusion to me being a homosexual and I reported that instantly gone. So when I shot, so, so for me I'm looking, I'm like, well of course, of course Twitter is going to enforce the social justice aspect of their policy immediately, in my opinion, probably because you guys have a PR constraints and you're probably nervous about that. But when someone actually threatens me with a crime and insights, their followers to do it and nothing got done and I'm not the only one who feels that way.

Speaker 2:          00:30:15       Well Tim pessimistic. If someone acts in that manner and threatens to hurt you, that's a violation of our rules. Right? Maybe there was a mistake there and I'm happy to go and correct that and we can do it offline so we don't fear any sort of reprisal against you. But that's a mistake. That's not an agenda on my part or on the team spark.

Speaker 4:          00:30:32       Would this be any PR constraints? That is not. So why did you ban Alex Jones? Can we get out of that? You want to get into that? Absolutely. Are you ready? For sure. All alright. Oh I've been ready for um, well let, let, let, let me say this. The reason I bring him up is that Oliver, Darcy, one of the lead reporters covering Alex Jones in his content set on CNN that it was only after media pressure did these social networks take action. So that's why I bring him up specifically cause it sort of implies you are under PR constraints to get rid of him.

Speaker 2:          00:31:03       I think if you look at the Pr, that's what her went through and that incident, it wouldn't be that we looked good in it. You have to, and that's not at all why we took action on it.

Speaker 5:          00:31:10       Sorry. You'll have to look at the full context on the spectrum here because one of the things that happened over a weekend is what Alex mentioned on your, on your podcast with him. He was removed from the Itunes podcast directory. That was the, that was the linchpin for him because it it, it drove all the traffic to what he said. Basically zero immediately after that we saw our peer companies, Facebook, Spotify, Youtube also take action. We did not, we did not because we, when we looked at our service and we looked at the reports on their service, we did not find anything in violation of our rules. Then we got into a situation where suddenly a bunch of people were reporting content on our platform, including CNN who wrote an article about all the things that might violate our rooms, rules that we looked into and we gave him one of the other warnings and then we can get into the actual details. But yeah, we did not follow, we, we resisted just being like a domino with our peers because it wasn't consistent with our rules in the contract we put in before our customers. So what was it that made you ban them?

Speaker 2:          00:32:29       So there were three separate incidents that came to our attention after the fact, uh, that were reported to us by, by different users. Uh, there was a video that was uploaded that showed a child's being violently thrown to the ground and crying. So that was the first one. The second one was a video that we viewed as incitement of violence. I can read it to you. It's a, sure it's a little, it's a little bit of a transcripts, but, um, but now it's time to act on the enemy before they do a false flag. I know that Justice Department's crippled a bunch of followers and cowards, but there's groups, there's grants, juries, there's, you called for it. It's time, politically, economically and judiciously and legally and criminally to move against these people. It's got to be dumb now. Get together. The people, you know, aren't traders, aren't cowards, aren't helping their frickin bats, hedging their fucking bets like all these other assholes do. And let's go, let's do it. So people need to have there and then there's a bunch of other stuff, but at the end, so people need to have their battle rifles ready and everything ready at their bedsides and you've gotta be ready because the media is so disciplined in their deception.

Speaker 1:          00:33:27       So this is you're, you're saying that this is a call to violence against the media.

Speaker 2:          00:33:32       That's what it sounded like to us at the time. And there've been a number of incidents of violence against the media. And again, I take my responsibility for what happens on the platform and how that translates off platform very seriously. And that felt like it was an incitement to violence. If he only tweeted the incitement to violence would have been fine. If he only treats only tweeted that trans posted that transcript saying, get your battle rifles ready, you wouldn't have deleted his account. I, again, context matters to him. It's not about one thing. So we'd have to look at the entire context of what's going on. So I'm asking was that, was that agregious enough for you to say that alone? That wasn't, that wasn't there was one number two. Right, right. So then I guess the question is what was the video context of the kid being thrown to the ground? Was it newsworthy? We obviously didn't think so in depicting violence against the child is not something that we would allow on the platform, even if it's a news content. Um, if it was a, there are certain types of situations where if you were reporting on, um, you know, war zone and, and things that might be happening, we would put an interstitial on that type of content that's graphic or violent. But we didn't feel that that was the context here.

Speaker 1:          00:34:31       Well, there's a video that's been going around that was going around a few four or five weeks ago, the one where the, the girls were yelling at that big giant guy and the guy punched that girl in the face and she was like 11 years old. I saw that multiple times on Twitter. That was one of the most violent things that we're seeing. This giant man punched this 11 year old girl in the face. And that was, was that removed from Twitter?

Speaker 2:          00:34:53       I don't know. I would have to go see if anyone reported it to us. I think one of the issues here is too is, you know, you do you want me to get to the third one? The third strike, um, we looked at was a verbal altercation that Alex got into with a journalist. And in that altercation there were, which was uploaded to Twitter. Um, there were a number of statements using eyes of the rat, even more evil looking in person. He's just scum. You're a virus to America and freedom smelling like a possum that climbed out of the rear end of a dead cow. You look like a possum that got caught doing some really, really nasty stuff in my view. So it was a bunch of, that's really, that's hilarious. Pattern and practice. But it was a verbal altercation that was posted on our classrooms. So, so we took the totality of this having been warned that we have rules against abuse and harassment of individuals. We saw this pattern in practice, one strike, two strike, three strikes and we made a decision to promote.

Speaker 1:          00:35:49       Last one was on periscope. Is that what it was that he uh, broadcast through?

Speaker 2:          00:35:53       Um, I think it was originally on periscope, but it was also re posted from multiple related accounts onto Twitter.

Speaker 4:          00:36:01       So we can, we can agree with you when you say these things. Like, you know, Alex said this, it sounds like a threat. He was berating this person's saying awful things. But ultimately your judgment is the contacts. You say we have to pay attention to the context. We just trusting that you made the right decision.

Speaker 2:          00:36:16       Well, I'm, I'm giving you as much facts as I can give your hair. And I think that this is the real hard part of content moderation at scale on global platforms. It's not easy and I don't think jack or I would tell you that it's easy.

Speaker 1:          00:36:28       Yes. A imposturous volume do you guys have to deal with? And that's one of the things that I wanted to get into with Jack when I first had them on because when my thought, and um, I wasn't as concerned about the censorship as many people were, my main concern was what does it like to start this thing that's kind of for fun? And then all of a sudden it becomes the premier platform for free speech on the planet earth. So

Speaker 2:          00:36:54       it is that, but it's also a platform that's used to abuse and harass a lot of people and, and used in ways that none of us want it to be used. But nonetheless, it happens. And I think it's an enormously complicated challenge, uh, for any company to do content moderation at scale. And that's something that we are sitting down thinking about how do we take this forward the future, because this is,

Speaker 4:          00:37:14       it doesn't scale. Yeah. So, so, so let's, let's take the other context. Now we, we've heard what you said, why what Alex Jones did was bad and now we can look at it this way. Oliver Darcy, who has on numerous occasions, insulted conservatives recently on CNN, called them gullible being sold red meat by grifters repeatedly covers a story. I'm going to do air quotes because I think to an extent he is allowed to cover these stories. He keeps going after Alex Jones, he keeps digging through his history. Then he goes on TV and says, we got him banned. Then Alex Jones confronts him and a very aggressive and mean way and that's your justification for four or I should say I invert the timeline. Basically you have someone who is relentlessly digging through stuff, insulting you, you know, calling you names Po ripper, sifting through your history, trying to find anything they can to get you terminated going on TV, even writing numerous stories. You confront them and say you're evil and you say a bunch of really awful mean things and then you, you bet him. Right?

Speaker 2:          00:38:04       So when you post that information all over the country,

Speaker 4:          00:38:07       right? But you have a journalist who recently went on TV and said Seapak is a bunch of gullible conservatives being fed red meat by grifters. You can tell this guy's not got honesty, an anonymous agenda. So what you have it to me, it looks like the Conservatives to an extent. Probably we'll try and mass flag people on the left. But from an ideological standpoint you have the actual, you know, whatever people want to call it. Sector of identitarian left that belief free speech is a problem that have literally showed up in Berkeley burning free speech signs

Speaker 2:          00:38:36       and then you have conservatives who are tweeting mean things and the conservatives are less likely in, I think it's fair to point out, less likely to try and get someone else band because they like playing off them. And the left is, is targeting them. So you end up having disproportionate a lot of assumptions in what you're saying. And I don't know what basis you're saying those things. I mean you have conservatives demanding free speech and you have liberals, uh, I shouldn't say liberals. You have w w what people refer to as the regressive left calling for the restrictions on speech. You have these, I don't know what those terms mean to be honest with you. We have people on all sides of the spectrum who believe in free speech and I, I believe that to be the case. So your platform restricts speech. Our platform promotes speech unless people violate our rules and in a specific direction, in any interaction.

Speaker 2:          00:39:22       But uncle, oh, I don't want to say his name. The guy who calls for death gets a suspension. The guy who insinuates that gets a permanent ban. You're misinterpreting what I'm saying and I feel like you're doing it deliberately. It's not about one particular thing. It's about a pattern in practice of violating a pattern and practice of banning. Only one faction of people recently published an article where they looked at 22 high profile bandings from 2015 and found 21 of them were only on one side of the cultural debate, but I don't look at the political spectrum of people and I'm looking at their tweets. You have a bias, your bias and your, you're targeting specific individuals because your rule support this perspective. No, it, they don't agree with that. Well, can you be clear though in like what rules support that purse specifically? The, the easiest one is mis-gendering, right?

Speaker 2:          00:40:04       Because that's so clearly ideological. If you ask a conservative what is mis-gendering, they'll say if someone is biologically male and you call them, you know, she a biologic and me and you called a mushy, that's mis-gender gender as a conservative view. The, the, the progressive view is inverted. So now you actually have in your policies a rule against the conservative perspective. I have a rule against the abuse and harassment of trans people on our platform. That's what my rule is. We just give context in the background as to why the why that is. And I brought some, some research. So we obviously received a lot of feedback. So we don't make these roles in a vacuum. Just to be clear, we have a bunch of people all around the world to give us context and the types of behavior they're seeing, how that translates into real world harm.

Speaker 2:          00:40:49       And uh, they give us feedback and they tell us like you should consider different types of rules, different types of perspectives, different. Like for example, when we try to enforce hateful conduct in a are hateful conduct policy. And in particular country, we are not going to know all of a slur words that are used to target people of a particular race or a particular religion. So we're going to rely on building out a team of experts all around the world who are going to help us enforce our rules. So in the particular case of m Ms Generating, I'm just trying to pull up some of the studies that we looked at, but we looked at, um, the American Association of Pediatrics and looked at the number of transgender youth that were committing suicide. It's an astronomical, I'm sorry, I can't find it right now in front of me. It's a really, really high statistic that's like 10

Speaker 6:          00:41:34       times what the normal suicide rate is of normal teenagers. And we looked at the causes of what that was happening. And a lot of WWE was not just violence towards those individuals, but it was bullying behavior and what was, what were those bullying behaviors that were contributing to that. And that's why we made this rule because we thought, and we believe that those types of behaviors were happening on our platform. And we wanted to stop it. Now there are exceptions to this rule. We don't, and this is all, this isn't about like public figures and there's always going to be public figures that you're going to want to talk about and that's, that's fine. But this is about are you doing something with the intention of abusing and harassing a trans person on the platform and are they viewing it that way and reporting it to us so that we take action.

Speaker 6:          00:42:17       So I will just state, I actually agree with the rule from my point of view. I agree that bullying and harassing Trans People's and higher, entirely wrong. I disagree with it, but I just want to make sure it's clear to everybody who's listening. My point is simply that, you know, Ben Shapiro went on a talk show and absolutely refused and that's his shtick. You know, and he's one of the biggest podcasts in the world. So if you have all of his millions upon millions of followers who are looking at this rule saying, this goes against my view of the world and it's literally 60 plus million in this country. You do have a rule that's ideologically bent and it's, it's true. You, you did the research, you believe this, well then you have Ben Shapiro who did his research and doesn't believe it. Yeah. And I relied on the American Association of Pediatrics and, uh, you know, human rights council and other, and I'm sure he has his sources too, for when he gives his statements.

Speaker 6:          00:43:05       The point is a bit of equally just wonder if they have that context. I mean, that's, and that's where we have also, it's, it's, it's just explaining the why behind a lot of reasons. I would agree. And I think it's fine. You did research and you found this to be true, but we can't simply say maybe Ben Shapiro and the other conservatives who feel this way, don't know. We have to wait. We can't, you know, the point I'm trying to make is, it's, it's simply whether you believe it, what, whether you justified or not is not the point. The point is, you do, you do have this rule. That rule is at odds with conservatives, period. Well, I think I, I think that you're, you're generalizing, but I think it is really important as Jack said, to the why behind these things, the why as to protect people from abuse and harassment on our platform and understand what you essentially created a protected class.

Speaker 6:          00:43:49       If this is the case, because despite these studies and what you know, the studies are showing there's a gigantic suicide rate amongst trans people, period. It's a 40% it's an outrageously large now, whether that is because of gender dysphoria with us because of the complications from sexual surgery, sexual transition surgery, whether it's because of bullying, whether it's because of this awful feeling of being born in the wrong gender, whether that all that is yet to be determined. The fact that they've shown that there's a large amount of trans people that are committing suicide, I don't necessarily think that that makes, that makes sense in terms of

Speaker 1:          00:44:32       people from someone's perspective, like a Ben Shapiro saying that if you are biologically female, if you are born with a double x chromosome, you will never be x, y. If he says that that's, that's a violation of your policy and this is, you are creating a protected class

Speaker 6:          00:44:52       to be, to be fair, targeted 30 saying it or, or targeting. So express that opinion. So what if he said title to express that opinion if he's doing it in a manner that's targeted at an individual repeatedly, repeatedly, repeatedly, and saying that, okay, but what about, what about, you know, what's going on with it?

Speaker 1:          00:45:09       Martina Navratilova right now, Martina natural over why? Why can I say her last name now? The Napa tro. I don't think I've ever said it. Martina Navajo Tullow VA is it till over Trello Va. Anyway, epic World Class Legend Tennis Player, right? Who happens to be a lesbian is um, being harassed because she says that she doesn't believe that trans women, meaning someone who is biologically male, who transitions to a female should be able to compete in sports against biological females. This is something that I agree with. This is something I have personally experienced a tremendous amount of harassment because I stood up when there was a woman who was a trans woman who was fighting biological females in mixed martial arts fights and destroying these women. And I was saying, what did you just watch this and tell me this doesn't look crazy to you? Um, well, I, well, my point is you should be able to express yourself in, if you say that you believe someone is biologically male, even though they identify as a female, that's a perspective that should be valid.

Speaker 1:          00:46:17       I mean that this is someone's, someone's, this is, first of all, it's biologically correct. So we, we have a problem in that. If your standards and your policies are not biologically accurate, then you're dealing with an ideological, I, you know, an ideological policy. And just because, I mean, I don't, I don't want to target trans people. I don't want to harass them. I certainly, I'll call anybody whatever they want. I mean, if you want to change your name to a woman's name and identify as a woman, I'm 100% cool with that. But by saying, I don't think that you should be able to compete as a woman. This opens me up for harassment and I never will hoard it. Any of it, I just don't pay attention to it. Right.

Speaker 6:          00:47:01       Going into like Megan Murphy for instance, right? You can call that target harassment. If Megan Murphy who was a, for those that are, don't, don't know, she's a radical feminist who refuses to use the transgender pronouns. If she's in an argument with a trans person over whether or not they should be allowed in sports or in biologically female spaces and she refuses to use their pronoun because of her ideology, you'll bend them. Again, it depends on the context on the platform and it's also not banned

Speaker 2:          00:47:30       permanently. Like you get Warren, she was banned permanently. But listen, she was hearing about what happened. What did he explain it to me? What, what, what did she actually do? My understanding and I don't have the tweet by tweet the way that I did for the others, but my understanding is that she was warned multiple times for um, mis-gendering an individual that she was in an argument with in this individual is actually bringing a lawsuit against her in Canada as well. So you have an argument between two people again and you have a rule that enforces only one side of the ideology and you've banned only one of those people. We have a rule that attempts to address what we have perceived to be instances of abuse or harassment or ideology,

Speaker 1:          00:48:11       right? But it is an ideology, right? If she's saying a man is never a woman, if that's what she's saying. And then biologically she's correct. We obviously have a debate here. This is not a clear cut. This is not something like you can say water is wet, you know this is dry. It's, and this is not like something you can prove. This is something where you, you have to acknowledge that there's an understanding that if someone has a trans person, we all agree to consider them a woman. And to think of them as a woman, to talk to them and address them with their preferred name and their preferred pronouns. But biologically this is not accurate. So we have, we have a divide here. We have a divide between the conservative estimation of what's happening and then the definition. That's the liberal definition of it.

Speaker 2:          00:48:54       I think that's right Joe. And I think what I'm trying to say is that it's not that you can't have those viewpoints. It's an if you're taking those viewpoints in your targeting and at the, at a specific person in a way that reflects your intents to abuse and harass.

Speaker 1:          00:49:07       What if it's in the context of the conversation? What if she's saying that I don't think that trans women should be allowed in these female spaces to make decisions for women. And then this person's arguing and she says, a woman is biologically female. You are never going to be a woman.

Speaker 2:          00:49:21       She responded with men aren't women though. And that was her first in the series of events. That's what got her the suspension and the warning. Um, that was one of many tweets that was part of providing context and that was actually the second, second actually strike is my understanding. But why is that a strike? Yeah, why is that a strike? But again, like it's the context of I don't, I don't have all the trees in front of me. There were like 10 or 12 tweets going back and forth and my understanding is that in the context of all of those, she was mis-gendering a particular person. Not that she was holding a baby or statement, wasn't it? I don't know. It was. So you don't, you're having, you're having an individual who was debating a high profile individual in her community and she's expressing her, her ideology of versus hers and you have opted to band one of those ideologies. It's within the

Speaker 1:          00:50:05       text of this conversation. This is, this is what is being debated. Whether or not someone is in fact a woman when they were born a male.

Speaker 2:          00:50:13       I understand that this is controversial. I do. I especially to a radical feminist. I understand why, why people would not agree with the role, but that being said, it is a rule on our platform and once you're warned about the rule to repeatedly post the same content is also going to be a violation of our rules.

Speaker 1:          00:50:30       Rabid. The rule, it's, this seems like a good example of an ideologically based rule. If if you're, if she's saying that a man is never a woman though, that is not in that context harassment. That is a very specific opinion that she has that happens to be biologically accurate. Now, I don't, you know, I don't agree with targeting harassment on anybody and I targeted harassment on trans people or or straight people or whatever. I don't, I don't agree with it. I don't think you should do it. It's just, it's not something I want to do. But in this context, what she's saying is not just her, her expression, but it's accurate.

Speaker 4:          00:51:11       I think an important point is if I tweet it to you, Joe, Joe, you are not a hamster. That's clearly not a violation of the rules. However, there are identify as a hamster? Well No, uh, it, it wouldn't be clear cause I know, I know people who have specifically began using insults of animals to avoid getting kicked off the platform for breaking the rules. Certain individuals who have been suspended now use certain small woodland creatures in place of slurs so they're not really insulting you and it's fine. But there are people who considers themselves trans species. Now I'm not trying to belittle the trans community by no means. I'm just trying to point out that you have a specific rule for one set of people and they're there. So there are people who have general body dysphoria. You don't have rules on that. There are people who have actually amputated their own arms. You don't have rules on that. You have a very specific rule set. And in more importantly in the context of a targeted conversation, I can say a whole bunch of things that would never be considered a rule break. But that one is which is ideologically driven.

Speaker 2:          00:52:08       Yeah. Thank you for the feedback. I mean we're, we're again always learning and trying to understand different people's perspectives. And I'll, all I'll say is that our intent is not to police ideology. Our intent is to police behaviors that we view as abuse, movement, harassment, and I hear your point of view and it's something that I'll definitely discuss with my team.

Speaker 4:          00:52:27       And even in this case, it wasn't, it wasn't just um, no going against this particular role, but also things that were more ban evasive as well, including taking a screenshot of the original tweet, reposting it, which is against her or term, sir. Well that sounds like it's more of the accident. It sounded like a protest against your role. I understand you have to ban them for it,

Speaker 2:          00:52:49       but people can protest any one of our rules. We can't, we can't like let them do that.

Speaker 4:          00:52:53       No, no, no. I haven't purchased any of that. I'm not, dating is great. I understand you're saying, but I just want to make sure I point out she was clearly doing it as an effort to push back on what she viewed as an ideologically driven role.

Speaker 1:          00:53:01       Well, this is what the problem is. This is a real debate in the LGBT community. This is a debate where there is a division and there's a division between people that think that Trans Women are invading biological female spaces and making decisions that don't benefit these biological females, CIS gender, whatever you want to call them. This is an actual debate and it's a debate, a debate amongst people amongst left wing people. And it's a debate amongst liberals. This is, I mean I would imagine the vast majority of people in the LBGT community are in fact on the left. And this is one example of that. So you have a protected class that's having an argument with a woman who feels like there's an ideological bent to this conversation that is not, not only not accurate, but not fair. And she feels like it's not fair for biological women. The same as Martina,

Speaker 4:          00:53:56       I'll, I'll, uh, take this to its logical conclusion. I got sent a screenshot from somebody and maybe it's faked. I think it was real. They were having an argument with someone on Twitter and responded with, Dude, comma, you don't know, blah, blah blah. And they got a suspension and a lockout had deleted the tweet because the individual using a cartoon Avatar with the eight with with the apparently with Sam reported it and said that I'm transgender and he's calling me dude and the dude and the Twitter user actually got a suspension for it. So I can understand mistakes happen, but when you have a rule that's like that, there's colloquial terms that are like, man, come on. Don't say that. Yeah,

Speaker 1:          00:54:28       dude is like, we say like, oh, like I asked you guys when you were going to take a photo in front of this thing. I said, guys, but I included you. Thank you. Thank you. Yeah, it's, it's tricky, but in this case of Megan Murphy, that's her name, right? Yeah. That doesn't make any sense to me. That seems like she should be allowed to express herself in this is, this is not being, she's not being mean, but I saying a man has never a woman. This is a perspective that that is scientifically accurate and that's, that's part of the problem.

Speaker 4:          00:55:03       I, I, I, I just don't want it to run into, to beating a dead horse. So I think I want to,

Speaker 1:          00:55:07       it's a really important thing to go over all the nuances of this particular subject because I think that one in particular highlights this idea of where the problems lie and having a protected class. And I think we should be compassionate. We have a lot of protected classes, gender, race, nationality, like these are the protective, but this not for white people. When you say gender or race, when it's not all protected category. So you can't attack someone for their belonging to a particular race or a particular religion? Well you can mock white people ad nauseum. It's not a problem. It doesn't get, it doesn't get removed. I'm not talking about mocking, I'm talking about abusing and harassing. But I mean if you mok a black person in the same way, it would be considered targeted racism. And again, it's about targeted harassment on the platform. But well, I mean what is targeted harassment?

Speaker 1:          00:56:00       I mean, but when you're, okay, look, if you ha, what is racism? Is Racism own it? I mean there's this progressive perspective of racism that it's only possible if you're from a more powerful class only punching down. That's the only racism. I don't think that makes any sense. I think racism is looking at someone that is from whatever, whatever race and deciding that they, in fact less or less worthy or less valuable, whatever it is that that takes place across the platform against white people. Now I'm not saying white people need to be protected. I know it's easier being a white person in America. It's a fact, but it's hypocritical to have a policy that only distinguishes, you can make fun of white people all day long. But if you decide to make fun of Asian folks or you know, fill in the blank that is racist, but making fun of white people isn't and it doesn't get removed. There are tons of tooling. How about Sara Jong From The New York Times? That's a,

Speaker 4:          00:56:58       well, I can actually explain that one. Please do. There's, that was, uh, my understanding is that you guys started banning people, official entities policies around 2015 and most all the tweets he made was prior to that. And so you didn't enforce the old,

Speaker 2:          00:57:08       yeah. So are hateful conduct policy, Joe, just to be clear is, is across the board, meaning like it doesn't just protect women and protects men and women and protects all races. It doesn't matter. And this is how the law is set up in the United States, right? You can't discriminate against white men. You can't discriminate against black men. Like those are the laws, right? Like that's the structure. It is. It doesn't, it doesn't take into consideration

Speaker 1:          00:57:30       power. Someone says something about white people and Mark's white people on Twitter. What do you do about that? If it's targeted harassment targeted at a person. So just white people in general. If you say something about why people in general, it's not an issue.

Speaker 2:          00:57:44       Well, I mean we focus on targeted harassment, which is behavior that is targeted against an individual who belongs to that class. Okay. Because if you try to police every opinion that people have about different races or religions, like obviously that's a very different story. So this is about if you target that to somebody who belongs to that class and that's reported to us, that is a violation of our rules. And so in the Sarah Jiang case, a lot, we did see many tweets, uh, of that nature that we're focused on. Uh, people who are white or men. And our rules in this area came into effect in 2015 which was our hateful conduct policy. And a lot of those tweets were from a time period where those rules weren't enough.

Speaker 1:          00:58:23       And in her defense, she was actually supposedly responding to people that have, you don't believe that

Speaker 4:          00:58:29       come on over three years and she's tweeting blanket statements about, yeah, sure, sure. But so, so I will say too, obviously I've done it

Speaker 2:          00:58:37       finish on my one point. So in, in that case, there were tweets from before the rules went into effect and tweets from after the rules went into effect. And we did take action on the tweets from after the rules went in.

Speaker 4:          00:58:47       She's also pretty young, but he did. So I want to point, uh, yeah, she's in her twenties. We're talking about something that might've happened eight years ago, right? 20. It was like 2011 to 13. But, but I do want to point this out, um, before coming on. I've obviously did it. Dot. I did a decent amount of research. I searched for slurs against white people, black people, Latinos, and I found copious, just, just tons and tons of them. Now they don't go back. Most of what I found in go back too far because it does seem like you guys are doing your best, but there is a lot and it targets white people, black people, Jewish people. It's everywhere. And I, and I can, I can, I can understand that. You, you got a hundreds of millions,

Speaker 2:          00:59:22       but, uh, let's, let's, let's, let's try another, uh, subject to address that point. Um, and I think Jack talked about this a little bit. Like this is where right now we have a system that relies on people to report it to us, which is a huge burden on people. And especially if you are, uh, happened to be a high profile person and Tim, you would, you would understand this. You're not going to sit there and report every tweet and Joe, y'all understand this isn't like, it's not worth your time. You're not going to go through a tweet by tweet as people respond to you and report it. People tell us this all the time. So this is where we have to start getting better at identifying when this is happening and taking action on it without waiting for somebody to tell us the time. Using an algorithm though, do you not miss context? I mean, it seems to me that

Speaker 3:          01:00:02       there's a lot of people that say things in humor, you know, the, the, or slurs within particular communities, which is perfectly reasonable, right? Right. So yes, there is a danger of the algorithm is missing context and that's why we, we really want to go carefully into this and this is why we've scoped it down first and foremost to doxing, which is at least first to hit our number one goal, protecting physical safety, like making sure that nothing done online will impact someone's physical safety on offline, on our platform in this case. The second is that there are patterns around doxing that are much easier to see without having the context. There are, there are exceptions of course, cause you could docs, um, someone's public, you know, uh, uh, representatives, public, uh, office, phone number and email address and the algorithm might catch that, not have the context that this is a US representative and this information is already public. So essentially this just, it highlights how insanely difficult it is to monitor all of these posts. And then what is the volume? Like what, what are we dealing with? Like how many posts do you guys get at

Speaker 2:          01:01:09       day? A hundreds of millions of posts a day. And how many human beings are manually reviewing any of these things? I don't have that, that number. A lot. A lot. Thousands, hundreds of thousands. How many employees you guys have? We have, uh, 4,000 employees around the world. That's it. Yeah,

Speaker 3:          01:01:27       we have 4,000 employees. The reason that's crazy though, but stop and think about that. 4,000 people that are monitoring hundreds of millions of tweets on we, we have, uh, we have, uh, we have a small team who's monitoring tweets and some of them are employed by us. Some of them are contractors throughout, throughout the world. So 4,000 employees, total, 4,000 employees who are engineers, who are designers, who are lawyers. So the number of people actually monitoring tweets is probably less than a thousand. Uh, well the reason we don't give out specific numbers is we need to scale these dynamically, right? If we see a particular event within, uh, within country, we might hire a hundred more people on contract to deal with it, right? Whereas they may not be full time and, and, and with us the entire time, they have the ability to take down tweets. Uh, they have Dave the, so as we get reports, it goes into a queue and those are ranked by severity. And then we people who look at

Speaker 5:          01:02:19       our roles and look at the look at the tweets and looking at the behavior in the context around it. And they have the ability to go down that enforcement spectrum. The vigil talked about one, make people log in, read why it's a violation over tweet and delete it to temporary suspensions. And finally a permanent suspension, which is the absolute last resort, which we ultimately do not want to do. We want to make sure that our rules are also guided towards incentivizing more healthy conversation and, and more, more participation. Yep.

Speaker 4:          01:02:51       So let, let, let, let me ask you, um, the rules you have are not based in US law, right? US law doesn't recognize restrictions on hate speech. It's considered free speech. So if you want to stand on a street corner and yell the craziest things in the world, you're allowed to on your platform, Twitter, you're not allowed to. So even in that sense alone, your rules do have an ideology behind them. I don't completely disagree. I think, you know, I don't want harassment. Um, but the reason I bring this up is getting into the discussion about democratic health of a nation. So I think it's, it can't be disputed at this point that Twitter is extremely powerful in influencing elections. You know, I, I'm pretty sure you guys published recently a bunch of tweets from foreign actors that were trying to mettle in elections. So even you as a company recognize that foreign entities are trying to manipulate people using this platform.

Speaker 4:          01:03:35       So I, there's, there's a few things I want to ask beyond this, but if wouldn't it be important then to just as a, at a certain point, Twitter becomes so powerful in influencing elections and giving access to even the president's tweets that you should allow people to use the platform based under the norms of US law, First Amendment, free speech, right to expression on the platform. This is becoming too much, uh, of, uh, it's becoming too powerful and how our elections are taking place. So even if you are saying, well, hate speech is our role and a lot of people agree with it. If at any 0.1 person disagrees, there's still an American who has it right to this, you know, to access to the public discourse and you've essentially monopolized and not completely, but for the most part. So isn't there some responsibility on you to guarantee at at a certain extent, less regulation happen, right? Like, look, if you, if you recognize foreign governments are manipulating a lot, our elections, then shouldn't you guarantee the right to an American to access this platform to be involved in the electoral process?

Speaker 8:          01:04:34       Yeah,

Speaker 2:          01:04:35       I'm not sure I see the, the, the tie between those things, but I will address one of your points, which was, uh, we're not, we're a platform that serves the world. So we're a global, uh, 75% of the users of Twitter or outside of the United States. Oh No. Right, right, right. So we don't, uh, apply laws. I'm just one country when we're thinking about it and we think about, um, how do you have a global standard that can meet the threshold of as many countries as possible because we want all the people in the world to be able to participate in that conversation. Yeah.

Speaker 5:          01:05:05       And so it also meet elections like the Indian election coming up.

Speaker 4:          01:05:08       Right. And I'm, my, my understanding is you were also accused of being biased against conservatives in India recently. There was a report on that as well as you held up a sign that said something offensive about the Brahmin. Yeah. So in that sense, even in other countries, you're accused of the same things that you're being accused of by American conservatives. I think that the situations are very, very different. Um, and I don't think that that the ideologies in play are the same at all. Well, so the, the reason we clarify that, I, I'm not sure what you're talking about, but we, we did have our vice president of public policy testify in front of Indian parliament a couple of weeks ago and he was, they were really focused on election integrity and safety and abuse and harassment of women and political figures and the likes. So, so my, my, my concern I guess is I recognize your globe.

Speaker 4:          01:05:58       You're a company that serves the world, but as an American I have the concern that the democracy I live in the Democratic Republic, I'm sorry, in the democratic functions are healthy. One of the biggest threats is, you know, Russia and Iran, Russia, Iran, China, they're trying to meddle in our elections using your platform. And it's effective. So much so that you've actually come out and removed many people. You know, Covington was apparently started by account base in Brazil. You know, the Covington scandal where this fake news goes viral was reported by CNN. That was a, it was a dummy account. They were trying to prop it up and they were pushing out this out of context information. So they do this, they use your platform to do it. You've now got a platform that is so powerful in our American discourse that foreign governments are using it as weapons against us.

Speaker 4:          01:06:39       And you've taken a stance against the laws of the United States. I don't mean like against like you're breaking the law. I mean you, you have rules that go beyond the scope of the u s which will restrict American citizens from being able to participate. Meanwhile, foreign actors are free to do so, so long as they play by your rules. So our elections are being threatened by the fact that if there's an American citizen who says, I do not believe in your mis-gendering policy and you bend them, that person has been removed from public discourse on Twitter. Right. But they don't get banned for saying they don't agree with it. Sure. Specifically violating it by targeting an inlet, let's say in protest and individual repeatedly says, no, I refuse to use your pronouns in like Megan Murphy's case and she's a Canadian, so I don't want to use her specifically.

Speaker 4:          01:07:19       The point I'm trying to make is at a certain level there are going to be American citizens who have been removed from this public discourse which has become so absurdly powerful. Foreign governments weaponize it because you have different rules than the American country has. Just to be clear on my understanding, and I'm not an expert on all the platforms, is that foreign governments use multiple, multiple different ways to interfere in elections and it's not limited to our platform nor is that limited to social media, but the president does. I made her president is on a lot of different platforms as as the White House. I think it's fair to point out the media coverage of his Twitter account is insane and they would run a new stories every time he tweets and so certainly undeniable. I'm just pointing out that there are a number of different avenues for this and individuals have choices and how they use the platform, so valued to have other platforms, but he uses Twitter as exclusively and what I'm trying to bring up is that if Twitter refuses to acknowledge this problem, you are facing regulation.

Speaker 4:          01:08:12       I don't, I don't know if you care about that, but at a certain point, which problem, if, if you're going to restrict American citizens from participating on a platform where even the president speaks and it's essentially you have a private, privately owned public space, uh, if, if I could use an analogy that would be most apt and you've set rules that are not recognized by the u s in fact, when it came to a supreme court hearing that said, hate speech is not a violation, it's actually protected free speech. So there's an actual odds. So there might be someone who says, I refuse to live by any other means than what the supreme court has sent down. That means I have a right to hate speech. You will bend them. That means your platform is so powerful. It's, it's being used to manipulate elections and you have rules that are not recognized by the government to remove American citizens from that discourse. So as a private platform, you become too powerful to not be regulated if you refuse to allow people free speech.

Speaker 5:          01:09:03       But I'm trying to pick apart the connection. I think so, yes, we, we do have an issue with, um, foreign entities and misinformation and, and this is a extremely complicated issue, which we're just beginning to understand and grasp and take action on. I don't think that issue is solved purely by not being more aggressive on something else that is taking people off the platform entirely as well, which is abuse and harassment. It's a cost benefit analysis ultimately in our rules are designed again and you know, they don't always manifest this way in the outcomes, but in terms of what we're trying to drive is opportunity for every single person to be able to speak freely on the platform. And that's absolutely not true.

Speaker 4:          01:10:00       You don't allow hate speech, hate speech. So free speech is not on your platform. I said, speak for everyone that create the opportunity for everyone to speak on our service. Unless you Dave, it's hate speech. Right? And then

Speaker 5:          01:10:15       part of that, the recognition that we're taking action on is that when some people encounter particular conduct that we see them wanting to remove themselves from the platform completely, which goes against that principle of enabling everyone to speak or giving people the opportunity to speak are so rules are focused on the the opportunities presented and we have particular outcomes to make sure that those opportunities are

Speaker 4:          01:10:40       so as possible. Let's, let's separate the first that the, the point I made about foreign governments was just to explain the, the, the power that your platform holds here. How can be weaponized? We'll separate that now. When antifa shows up to Berkeley and bashes a guy over that with a bike lock that is suppressing his speech, right? That's a act of physical violence. However, when antifa links hands and blocks the door so that no one can go to an event that is also legally allowed, right? So what you're saying is that if someone is engaging in behavior such as going on Twitter and shouting someone down relentlessly, that's something external to what happens in, in the world under the u s government. I am allowed to scream very close to you and not let you speak in public, but on Twitter you don't allow that.

Speaker 4:          01:11:21       So there's a dramatic difference between what Twitter thinks is okay and what the u s government thinks is okay. Our democracy functions and how Twitter functions. The issue I'm pointing out is that we know Twitter is becoming extremely important in how our public discourse is occurring, how our culture is culture is developing and who even gets elected. So if you have rules that are based on a global policy, that means American citizens who are abiding by all of the laws of our country are being restricted from engaging in public discourse because you've monopolized it. Can I counter that though? Because these foreign governments are restricted by the same rules. So if they violate those same rules, they will be, they will be removed. So play within those rules. They can participate in the discourse even if they are just trying to manipulate our elections. On the other hand, if the people that are on the platform play by those rules, they can also counteract unless their ideology goes in line with us.

Speaker 4:          01:12:11       Law and on is legally allowed as opposed to what you allow. So foreign governments can can absolutely keep making new accounts and keep building and keep manipulating. They can even post things that'll go viral and then get banned and not care. Right. But a private American citizen can say, here's my opinion. I refuse to back down. I see what you're saying. You will ban him. So we can see that at a certain point you have a lot [inaudible]. Twitter is slowly gaining in, in my opinion, too much control from your personal ideology based on what you've researched, what you think is right over American discourse. If you, if Twitter, and this again, it's my opinion, I'm not a lawmaker, but I would have to assume if Twitter refuses to say in the United States you are allowed to say what is legally acceptable period. Then lawmakers only choice will be to enforce regulation on your company.

Speaker 2:          01:12:57       Actually, Tom, I spend quite a bit of time talking to lawmakers as part of my role, had a public policy. Um, I spent a lot of time in DC. I want to say the Jack and I have both spent a lot of time in DC and I think from the perspective of of lawmakers, um, they are across the spectrum are also in favor of policing, abuse and harassment online and bullying online. Well those are things that people care about because they affect their children and if they affect their communities and they fact individuals. And so I don't think that, and as a, as a private American business, we can have different standards than what an American government owned corporation or American government would have to institute. Those are two different things. American bit. And I understand your point about the influence and I'm not denying that. Certainly Twitter is an influential platform, but like anything, whether it's the American law or the rules of Twitter or the rules of Facebook or wills of any platform, there are rules and those rules have to be followed. So it is your choice whether to follow those rules and to continue to participate in a civic dialogue and it's your choice to not do that.

Speaker 4:          01:14:04       Absolutely. You've monopolized public discourse to an extreme degree and you say my way or the highway we are facing and we haven't monopolize

Speaker 6:          01:14:12       it. There are many different avenues for people to continue to have a voice. There are many different platforms that offer that. We are a largely influential one. I'm not trying to take away from that and we're a very important one. You don't need to be the most important. It's just that you are extremely important and that's, and that's a compliment. Twitter has become extremely powerful, but at a certain point you should not have the right to control what people are allowed to say. No private or look, I'm a social liberal. I think we should regulate you guys because you are unelected officials running your system the way you see fit against the wishes of a democratic republic. And there are people who disagree with you or being excised from public discourse because of your ideology. That terrifies me. And we can take it one step further just so I understand.

Speaker 6:          01:14:52       So are you suggesting that we don't have any policies around, uh, abuse and harassment on the platform? Um, I'm trying to understand what it is I'm saying cause I'm not, I'm not sure I'm following you. So you, you don't think we should have any rules about abuse and harassment. So even that, the threats that you received that you mentioned that we didn't, but you mentioned a number of threats that you received in your quite frustrated that we hadn't taken action on them. That you think we shouldn't have roles. That I'm frustrated because of the hypocrisy. So when I, when I see, I see the flow of one direction and then what I see are Republican politicians who in my opinion, you're just too ignorant to understand what the hell is going on around them. And I see people burning signs that say free speech. I see you openly saying, we recognize the power of our platform and we're not going to abide by American norms.

Speaker 6:          01:15:37       I see the manipulation of Twitter for in violation of our elections. I see. Democratic operatives in Alabama waging a false flag campaign using fake Russian accounts and the, and the, and the guy who runs that company has not been banned from your platform even after it's been written by the New York Times. He was doing this. So we know that not only are people manipulating your platform, you have rules that remove honest American citizens with bad opinions who have a right to engage in public discourse. And it's like you recognize it but you like having the power. I'm not quite sure at what point, get back to my points. So you believe that Twitter should not have any roles about abuse and harassment or any sort of hate speech on the platform that that's your position. That's a extremely reductive. I don't know that maybe too simplistic.

Speaker 6:          01:16:20       The point I'm trying to make is, but ain't, you're trying to make your, you're asking us to comply with the u s law that would criminalize potential speech and put people in jail for it. And you're asking us to enforce those, those terms while, I mean if you insight death, you will. That's a crime you can go, you can go to jail for that. So at the very least you could, you like when you, when you have people on your platform who committed crime, you don't ban them. I say, well that's really weird. And then when you have people on your platform who say a bad naughty word, you do band them. I say, well that's really weird. I mean I've seen people get banned for, for tweeting an end to you. I understand what they're trying to do when they tweet letters at Uga, but they get suspended for it and they get a threat. You know, like you can't, let's, let's talk about learning to code. What do you, what do you mean by that? There are people who know that they can tweet a single letter and the next person knows what letter they need to tweet. You see what I'm saying? So you'll see, you know, one user

Speaker 4:          01:17:10       we'll say and the next years or we'll put an I the next user. Yes. And so they get suspended for doing so. And, and these are, these are the people who are trying to push the buttons on the rules. Right? They get suspended for that. Absolutely. So, because I think here's the thing, I think, I think your team understands what they're doing, however it gets really dangerous territory. If someone, someone accidentally tweets an end and you assume they're trying to engage in harassment campaign, which is why I said let's talk about learning to code. But we do, we do look at coordination of it, of accounts or direct messages.

Speaker 2:          01:17:44       Uh, I dunno about direct messages, but until you read the direct messages, we don't redirect messenger. We don't read them unless someone reports a direct message to us that they have received.

Speaker 1:          01:17:53       And so you read their direct messages that they send to you.

Speaker 2:          01:17:56       So if, if you have a direct message and someone says something terrible and then like you receive a death threat and your report that to us, then you receive, then we would read it. Cause you've reported it.

Speaker 1:          01:18:05       Do, does anyone in the company have access to direct messages other than that?

Speaker 2:          01:18:10       Um, only in the context again of reviewing reports that were, are not accessible. Um, not to my knowledge. I don't know what you mean.

Speaker 1:          01:18:18       We're not resemble, we're not reading them. Is it possible that someone could go into Tim's direct messages and just read his direct messages? I don't think so. So if Tim writes an n and I write an I and Jamie writes a, Gee, can you go into our direct messages and say, Hey, let's fuck with Jack and we're going to write this stuff out and we're going to do it and let's see if they banned us.

Speaker 2:          01:18:39       You can't read that? I don't think so.

Speaker 1:          01:18:42       So if that's the case, I don't want to know if there was a concerted effort. I think what he's saying, I was like, if we, if we do see those train of replies and that is, that is coordination.

Speaker 4:          01:18:52       You know, what people are doing, the point of showing, like how do you prove it? Well, I think beyond the end, you know, the first person or with a letter, you can't prove he did it, but everybody else, you kind of can. I don't, but I don't think we would. Well, I've, look, I can say this, I've been sent numerous screenshots from people. Screenshots can be faked. I recognize it, but I've seen people actually tweet. And then I've seen the tweet follow right after one. One letter though. Yeah. Someone tweeted at you a someone decently high profile, like a big youtuber tweeted an end at you and then got like a 12 hour suspension. But let's talk about learning to code. Right. And why are people being suspended for ta tweeting Hashtag learn to code?

Speaker 2:          01:19:28       Yup. We did some research on this. Yes, we did some research on us. Um, so there was a situation, I guess about a month ago or so where a number of journalists or receiving a variety of tweets, um, some containing a learn to code, some containing a bunch of other, um, coded language that was wishes of harm. And these were thousands and thousands of tweets being directed at a handful of journalists. And we did some research and what we found was, uh, a number of the accounts that we're engaging in this behavior, which is tweeting at the journalist with this either learn to code or things like day of the rope and other coded language. Uh, we're actually, um, Ban of Asian accounts. That means accounts that have been previously suspended. And we also learned that there was a targeted campaign being organized off our platform to abuse and harass these journalists. That's not true.

Speaker 7:          01:20:24       Does he see, here's the thing, an activist who works for NBC wrote to that story and then lobby. Do you, you issued an official statement and then even the editor and chief of the daily caller got a suspension for tweeting, learn to code at the day, at the daily show.

Speaker 2:          01:20:36       So I have never talked to anybody from NBC about this issue.

Speaker 7:          01:20:40       No. So they reported don't misrepresent me. They report it at the narrative goes far and wide amongst your circles. Then all of a sudden you're seeing high profile conservatives tweeting a joke, getting suspensions.

Speaker 2:          01:20:50       So again, some of these tweets actually contained, um, death threats, wishes of harm, other coded language that we've seen to mean, um, death to journalists. So it wasn't about just the learn to code, it was about the context of it.

Speaker 7:          01:21:07       Can we, come on, that's not true. That's just not true. The editor in chief of the daily caller was suspended for tweeting nothing but hashtag learn to code.

Speaker 2:          01:21:14       Sorry Tim, can I, can I finish what I'm saying? Yeah. So we were looking at the context and what was happening is there were journalists receiving hundreds of tweets, some had death threats, some had wishes of harm, some just learn to code. And in that particular context we made a decision, we consider this, this type of behavior about dog piling, which is when all of a sudden individuals are getting tons and tons of tweets at them. They feel very abused or harassed on the clock.

Speaker 7:          01:21:37       Can we pause this? Cause this, we're super confusing for people who don't know the context. The learn to code thing is in response to people saying that people that are losing their jobs like coal miners and truck drivers and things like that, we could learn to code. This was, it was almost like ingest initially or if it wasn't ingest initially it was so poorly thought out as a suggestion that pizza started mocking it. Right? Correct. So that's correct. The first stories that came out were simply like Ken miners learn to code. There was no liners. Right, and they'll hashtag learn to code is just a meme. It's not even necessarily a conservative one that you will see more conservatives using. It was people are using it to mock how stupid. The idea of taking a person who's on an educators in their 50s who should our learn some new form of vocation and then someone says learn to code and so then other people when they're losing their job or when something's happening, people would write, learn to code because it's a mean.

Speaker 7:          01:22:30       Well, not even necessarily. I would, I would just characterize, learn to code as a meme that represents the elitism of modern journalists and how they target certain communities with disdain. Okay. So, so to, to, to make that point, there are people who have been suspended for tweeting something. Like I'm not too happy with how, you know, buzzfeed reported the story Hashtag learn to code, right? Making representation of these people are snooty elites who live in ivory towers. But uh, but, but again, you know, this is a meme that has nothing to do with harassment, but you know, it's, some people might be harassing somebody in, might tweet it. Why would we expect to see, even still, I'm still getting messages from people with screenshots saying I've been suspended for using a Hashtag and the editor in chief of the daily caller, right? He, he, he, he, he took, he quote, tweeted a video from the daily show with Hashtag learn to code and he got a suspension for it. So why, why learn to code? Why is that alone so egregious? And I don't think it is so gracious. So is it just something that got stuck in an algorithm?

Speaker 2:          01:23:26       Uh, no. It was a, again, a specific set of issues that we were seeing. I'm targeting a very specific set of journalists and it wasn't just the learn to code, it was a couple of things going on. A lot of the accounts tweeting learn to code where band invaders, which means it curiously been suspended. A lot of the accounts had other language in them are of tweets out other language like day of the brick day of the rope of ready. These are all coded meanings for violence against people. Right. Um, and so, and the people who are receiving this, we're receiving hundreds of these in what appeared to us to be a coordinated harassment campaign. And so we were trying to understand the context of what was going on and take action on them. Because again, I don't know, Joe, if you've ever been the target of a dog piling event on Twitter, but it is not particularly fun when thousands of people or hundreds of people are tweeting at you and saying things.

Speaker 2:          01:24:18       And that's can be viewed as a form of harassment. And it's not about the individual tweet. It is about the volume of things that are being directed at you. You understand. And so in that particular case, we made the judgment call and it is a judgment call, um, to take down the tweets that were responding directly to these journalists that were saying learn to code even if they didn't have a wish of harm specifically attached to them because of what we viewed as coordinated attempt, uh, to harass them. And again, like I was saying, some of the other signals and coded language and we were worried that learn to code was taking on a different meaning. I understand what in that particular context.

Speaker 7:          01:24:58       So, but in and of itself though, it's still seems like there's alternative meanings to learn to code. It still could be used as Tim was saying to mark, uh, you know, elite, snooty, okay.

Speaker 2:          01:25:11       Yes, yes, absolutely. I agree with you. So it's really about the context of what was happening in that situation and all those other things. I think in a very different situation we would not take action on that.

Speaker 7:          01:25:21       Hmm. Okay. But does not seem like your, you're throwing a blanket over a very small issue. Um, I think you learned to code in itself is very small. The blanket is cast over racism. The blanket is cast over this, all the other horrible things that are attached to it, but the horrible things that are attached to it, the real issue, this learn to code thing is kind of a legitimate protest in people saying that these minors should learn to code. That's kind of preposterous. The first articles weren't mean. It was just it learn to code kind of identified. You have these journalists who are so far removed from Middle America that they think you can take a 50 year old man who's never used a computer before and put them in a, you know, the stories I think were legitimate. Yes. But the point more so is

Speaker 4:          01:26:04       it was a meme. The hashtag the idea of learn to code condenses this idea. And it's easy to communicate, especially when you only have 280 characters that there is a class of individual in this country. I think you mentioned on uh, was it Sam Harris that the left, the left liberal journalists only follow each other in the, in the run up to the 25th, 2016 elections. Yeah. And so, uh, I mean I s I still believe that to be true and I've worked in these offices. It has changed. They've done the study on the visualization and other is a lot more cross pollination. But we, what we saw is a folks who are bordering on the left and on a spectrum mainly followed folks on the left and folks on the right fold. Everyone, right. You were talking about earlier that there's these bubbles, there's, there's bubbles and we've helped create them and maintain them.

Speaker 4:          01:26:48       So, so here's what ends up happening and this is one of the big problems that people have with this story. Particularly, particularly you have a left wing activist who works for NBC News. I'm not accusing you of having read the article. He right. He, he's, he spends a uh, like a day lobbying to Twitter saying, guys, you have to do this. You have to make these changes. The next day he writes a story saying that four Chan is organizing these, these, these harassment campaigns and death threats and while four Chan was doing threads about it, you can't accuse fortune simply for talking about cause right. It was talking about it too as what's Twitter. So then the next day he, after he published his article, now he's getting threats and then Twitter issues a statement saying we will take action and to make matters worse, when John Levine, a writer for the rap, got a statement from one of your spokespeople saying, yes, we are banning people for saying learn to code.

Speaker 4:          01:27:35       A bunch of journalists came out and then lied. I had no idea why he's saying this is not true. This is fake news. Then a second statement was published by Twitter saying it's part of a harassment campaign. And so then the mainstream narrative becomes, oh, they're only banning people who are part of a harassment campaign. But you, you literally see legitimate high profile individuals getting suspensions for, for joining us on a joke. Oh, they're there for sure. Probably mistakes in there. I don't think that any of us are claiming that we've got that's 100% right and probably our team having a lack of context and to actually what's happening as well. And we would fully admit we probably were way too aggressive when we first saw this and made mistakes. I hope this clarifies. Then you have situations like this where you can see, you know, the, this journalist, I'm not going to name him, but he routinely has very like left wing, I don't want to use overtly a esoteric words, but uh, intersectional dogmatic points of view.

Speaker 4:          01:28:25       Right? So this is considered me. So like intersectional feminism is considered like a small ideology. It people refer to these groups as the regressive left or the identitarian left. These are basically people who hold views that a person is judged based on the color of their skin instead of the content of their character. So you have the right wing version of which is like the ultra right, the left wing version, which is like, um, intersectional feminism is, is, is how simple referred to. So you'll see people say things like, you know, when they typically, when they rag on white men or when they say like white feminism, these are, these are signals that they hold these particular views. And these are, these are becoming more pervasive. What ends up happening is you have a journalist who clearly holds these views. I don't you want to call him a journalist.

Speaker 4:          01:29:05       He writes extremely biased and out of context story, Twitter takes action in response, a seemingly in response. Then we can look what happens with Oliver Darcy at CNN. He says, you know, the people at Seapak are the conservatives are gullible eating red meat from grifters, among other things, disparaging comments about the right. And he's the one who's primarily advocating for the removal of certain individuals who you then remove. And then when Kathy Griffin calls for Doxing, that's fine. When this guy, he calls for the death of these kids, he gets, he gets a slap on the wrist and, and look, I understand the context matters, but grains of sand to make a heat and eventually you have all of these stories piling up and people are asking you why it only flows in one direction. Because I gotta I gotta be honest. I'd imagine that calling for the death three times of any individuals or bandit ball offense, even without a warning, he just get rid of him.

Speaker 4:          01:29:48       But it didn't happen. Right. We see, we see these, you know, people say men aren't women though, and they get a suspension. We see people say the editor and chief of the daily caller, maybe the best example Hashtag learned to code, uh, quoting the daily show and you get to suspension, just threatening death and inciting death is a suspension to it. If it feels like it's only going in one direction. Yeah, I think we have a lot of work to do to explain more clearly when we're taking action and why. And certainly looking into any mistakes we may have made in those particular situation.

Speaker 1:          01:30:17       Breathe that in tech. I think we can all agree this, oh, I would hope you agree tech tends to lean left like tech companies, Facebook, Twitter, Google.

Speaker 4:          01:30:28       I I would be willing to bet that a conservative running a social network would not have a hate speech policy. I mean you look at Gab and you look at mines and mines not even right wing. Yeah,

Speaker 1:          01:30:37       right. They're not right wing at all. They're just, they just staunchly support free speech. Right, right. I don't think gab is necessarily, I don't think the owner is necessarily right when either, I don't know much about him. I think he's like a libertarian. I don't want to, uh, I don't want to specify either. I don't know. I don't know enough. But I know that there, when you read what they write, they're just staunchly committed to free speech. But they, you know, stop doxing. They will, they will do things to stop targeted harassment and doxing and things along those lines. Sometimes slowly, admittedly. But they want, they just want an open platform. What my point is is that I think a lot of people that are on the right feel disenfranchised by these platforms that they use on a daily basis. I don't know what the percentage are.

Speaker 1:          01:31:23       The percentages are in terms of the number of people that are conservative that use Twitter versus the number of people that are liberal, but I would imagine it's probably pretty close, isn't it? I don't know the numbers. I don't know because we don't ask people, but then we'd have to, we'd have to infer all that. Okay. Based on what we're saying or because, so let's not even go there, but then, but the, the, the people that run, whether it's Google or Twitter or Facebook, any of these platforms, Youtube for sure. Powerful leaning towards the left.

Speaker 9:          01:31:55       Okay.

Speaker 1:          01:31:55       When we all agree to that, we don't ask our employees, but my guess is

Speaker 5:          01:32:00       that many employees at tech companies are probably liberal. It's really fascinating, but I also think, yeah, I mean your point, oh, all the companies you mentioned are in exactly the same region as well. We do. You know, we do have the challenge of some monocultural thinking as well, but we, and we, you know, I have said publicly that, you know, yes we will have more of a liberal bias within our company, so this to CNN, but that doesn't mean that we put that in our rules. Right? But hold on because what I'm getting at is that at some point in time things have to get down to a human being looking and reviewing a cases. And if you guys are so left wing in your, your, your staff and the area that you live in and all of these things, things are almost naturally going to lean left if is that fair to say if we were purely looking at the content, but a lot of this agent work is based on the behaviors, all the things that we've been discussing in terms of the context of the actual content itself, what the roles are, the mis-gendering policy, right?

Speaker 5:          01:33:11       So your, your rules do reflect your, your bubble, right. Go to the middle and you know, go to middle America and go hang out at a conservative town. They're not going to agree with you. Your rules are based on your bubble in San Francisco or whatever city. I'm from Middle America, I'm from Saint Louis, Missouri. And I hear the point. I definitely hear the point in terms of like us putting this rule forth, but we have to balance it with the fact that people are being driven away from our platform. And they may not disagree. They may not agree with me on that. My folks from Missouri, but I think they would see some valid argument and what we're trying to do to again, increase the opportunity for as many people as possible to talk. That's, that's it. It's not driving the new that you're speaking to where you stop, what, what community is and isn't deserving of protection are conservatives not deserving of protection for their opinions.

Speaker 5:          01:33:57       But I want to focus in a way on individuals and increasing the absolute number of people who have opportunity to speak on the platform in the first place. So then do you need a rule for a body dysphoria? Do you need a rule for other kin? Right? You see what I'm asking you? You, you have a specific, I see what you're asking me. Like, and, and this came from a call and research and there there's, there's disagreement as to whether this is the right outcome or not and this is the right policy. And yes, our bias does influence looking in this direction and our bias does take, um, our biases influence us putting a rule like this in place. But it is with the understanding of creating as much opportunity as possible for as many people to speak based on the actual data that we see of people leaving the platform because of experiences that have, why did your research stop there? It hasn't stopped. We, we are, our rules aren't set in and something that just stops and doesn't evolve. We're going to constantly question, we're going to get feedback from people on every end of the spectrum of any particular issue and make changes

Speaker 1:          01:35:03       accordingly. Doesn't stop. And to your credit. I really do appreciate that the fact that you're very open about that you have made mistakes and that you're continuing to learn and grow and that your company is reviewing these things and trying to figure out which way to go. And I think we all need to pay attention to the fact that this is a completely new road. This road did not exist 15 years ago. There was nothing there. That is a tremendous responsibility for any con, any company, any group of human beings to be in control of public discourse on a scale unprecedented in human history. And that's what we're dealing with here. This is not a small thing and I know people that have been banned to them. This is, this is a matter of ideology. This is a matter of, this is a matter of that there's a lot of debate going on here and this one of the reasons why I wanted to bring you on because Tim, cause you know so much about so many of these cases and so much because you are a journalist and you're, you're very aware of the implications and all the problems that have been that maybe have slipped through my fingers.

Speaker 1:          01:36:00       So I do want to make one thing really clear though. I have a tremendous amount of respect and trust for you. And you say you wanted to solve this problem simply because you're sitting here right now and these are, these other companies aren't right? Jackie went on Sam Harris, you are on a get with Gad sad. And that says to me a good faith effort to try and figure out how to do things right. So as, as much as I, I'll apologize for getting kind of angry and being emotional.

Speaker 5:          01:36:22       Oh, so he was hungry. I look, we also haven't been great at explaining our intent and there's a, there's a few things going on. One, as Joe indicated, centralized global policy. A scale is almost impossible. And, and we realize this, different services have different answers to this. Reddit has a community based policy where a, each topic, each subreddit has its own policy and, and you know, there's, there's some benefit to that. So that's problem number one. We know that this very binary off or on platform isn't right and it doesn't scale and it ultimately goes against our key initiative of wanting to promote more healthier conversation. I just don't think that's what you're doing. I and, and I, I hear you. I hear you. Yeah, but like, so we're not done. We're not, we're not done. We're not finished with our work and we need to, the reason I'm going on all these podcasts and having these conversations and ideally vigils getting out there more often as well because we don't see enough for him to hear enough for her.

Speaker 5:          01:37:28       We need to have these conversations so we can learn, we can, we can get the feedback and also pay attention to where the technology is going. Before the podcast we talked a little bit about, and I talked about it on this, our previous podcasts and also Sam's, that technology today is enabling content to live forever in a way that was not possible before. You can say that everything on the Internet lives forever. But that's not generally not true because any host or any con connection, take it down, the block chain changes all that. It can actually exist forever, permanently without anyone being able to touch it. Government, company, individual. And that is a reality that we need to pay attention to and really understand our value. And I believe a lot of our value in in the future, not today, again, we have a tons of, we have a ton of work is to take a strong stance of like we are going to be a company like given this entire Corpus of conversation and content within the world, we're going to work to promote healthy public conversation.

Speaker 5:          01:38:27       That's what we want. That's what we're gonna do. And if you disagree with it, you should be able to turn it off and you should be able to access anything that you want as you would with the Internet. But those are technologies that are just in the formative stages and presenting new opportunities to companies like ours. And, and there's a ton of challenges with them in a ton of the things that we've discussed over the past hour that it doesn't solve and maybe exacerbates, especially around things like election and foreign interference and, um, some of the regulatory concerns that you're bringing.

Speaker 4:          01:39:01       There's a few issues, right? Your definition of what is or isn't healthy,

Speaker 5:          01:39:05       right? Yes, yes. And, and, and we want that to be public. Like we want that we're, we're going, we have four indicators right now that we're working on with an external lab. We won't other labs too. We want to give it up open source, make sure that people can comment on it, that people can help us define it. We'll use that interpretation on our own algorithms and then push it. But that has to be open. That has to be transparent. Are we there today? Absolutely not. We're not there yet.

Speaker 4:          01:39:29       I this this course of action to me it looks like a Fahrenheit four 51 future where everything is so offensive. Everything must be restricted. I see. That's the path I see that you're on. You want to have a healthy conversation, you want to maximize the amount of people. That means you've got to cut off all the tall grass and level everything out. So if, if, if, if you've decided that this one rule needs to be enforced because certain things are offensive.

Speaker 5:          01:39:49       No, but can I explain what, what health at least means to us and the skeptical or get so like we talked a little bit about this on the previous podcasts, but what we have four indicators that we're trying to define and try to understand if there's actually something there. One is shared attention. Is a conversation generally shared around the same objects or is it disparate? So like as we're having conversation, the four of us are having a conversation. Are we all focused on the same thing or as Joe on his phone, which you were earlier or like whatever is going on. Because a more shared attention will, will lead to healthier conversation number two is shared reality. Not whether something is factual, but are we sharing the same facts? Is the earth round? Is the world flat? So we, we can, we are meant, yes, we can tell what facts are we sharing and what facts are we not sharing?

Speaker 5:          01:40:43       What percentage of the conversation. So that's, that's the second indicator. Third is receptivity. Are the participants receptive to debate and to civility and to uh, expressing their opinion? And even if it is, um, something that might be a hurtful or are people receptive to at least look at and be empathetic and, and look at what's behind that week. This is the one we have the most measurement around today. We can determine and predict when someone might walk away from a Twitter conversation because they feel it's toxic. I just ignore them all basically. So, and we see, we see that in our data. Right? So you, and there's some conversations that you get into and you and you, you know, persist. And then the finally is variety of perspective. Are we, are we actually seeing the full spectrum of any topic that's being talked about? And these are not meant to be taken as individual parts, but in unison how they played together. And we've written these out, we haven't gotten far enough in actually defining what they look like and what they mean. And we certainly haven't gotten good enough at understanding when we deploy a solution, like being able to follow a Hashtag, does that impact variety of perspective to the positive? Does it impact shared reality to the negative? What not. So this is how we're thinking about it. And as we think more about that, that influences our product and influences our enforcement and influences our policy as well.

Speaker 4:          01:42:07       What you're describing sounds wildly different to what Twitter is, right? So you're, you have a goal for where you want to get with those, those metrics. So what confuses me then when you, when you, when we talk about someone like Megan Murphy who, sure she violated your rules, but in the context of a conversation, you know, you recognize people will sometimes get heated with each other if you know, how do you do is a healthy conversation when no one is being negative. What if, what if people are yelling at each other and being mean and insulting where mis-gendering them.

Speaker 5:          01:42:34       I think it's a question of what thresholds you allow and the more control we can give people to very the spectrum on what they want to see. Um, that feels right to me. I mean, Joe in, in your, your Alex podcast did exactly this thing. You're hosting a conversation. You had both of your guests who started talking over each other and you pause the conversation. You said, let's not get combatative. Someone said, I'm not being combative. You said you're all talking over each other and, and there's a dynamic that the conversation then shifted to that. Got to some deeper points, right? It could have just said, let that happen and, and, and let it go. And that's fine too. It's, it's, it's up to who is viewing and experiencing that conversation. And I agree with you, it is completely far off from where we are today.

Speaker 5:          01:43:28       We've not only have, we had to address a lot of these issues that we're talking about at this table, but we've also had to turn the company around from a business standpoint. We'd have, we've had to fix all of our infrastructure that's over 10 years old and we had to go through two layoffs because the company was too large. So we have to prioritize our efforts and I don't know any other way to do this, be really specific about our intentions and our aspirations and, and the intent and the why behind our actions and not everyone's going to agree with it in the, in the particular moment.

Speaker 4:          01:44:03       So, uh, so I will, I want to, I want to point this out before I make my next statement though. Just real quick. It seems like the technology is moving faster than the culture. So I do recognize your, you guys are in a rock and a hard place. How do you get to a point where you can't have that open source crypto, blockchain technology that allows for free and open speech at the same time the technology exists. Twitter has been replicated numerous times in different ways. Mastodon for instance. Yup. What's disconcerting to me is, you know, and, and maybe you have research on this, which is why you've taken the decision that you have, but when you ban someone, because they've said, you know, bad opinions mis-gendering well, they're not going to go away. They're going to try and find anywhere they can speak. So what effectively happens is you're, you're taking all of these people from a, from a wide range of the most, uh, tease a prison analogy, murderers all the way to pot smokers, and you're putting in the same room with each other and you're saying you're not welcome here. Well, what happens when you take someone who smokes pot and put them in prison with a bunch of gang bangers and murderers, they fall into that. So

Speaker 5:          01:44:57       I totally get the point and I'm hyper aware of our action sending more and more things into that.

Speaker 1:          01:45:02       Well, this is something that I wanted to discuss is really important in this vein of thinking. What about roads to redemption? What about someone like Megan Murphy lit about someone, Anyone Alex Jones. Milo is, is it Ken? We find a path for people to get back to the platform that for good or for bad, like it or not, there is one video platform that people give a shit about and that's youtube. You get kicked off of Youtube, you're doomed and that's just reality. You can go, Vimeo is wonderful. There's a lot of great video platforms out there. They have a fucking tiny fraction of the views that youtube dubs. That's just reality. The same thing can be said for Twitter, whether or not other platforms exist is that's inconsequential. The vast majority of people are on Twitter. The vast majority of people that are making, you know post about the news and breaking information, they do it on Twitter. What can be set up and have you guys given consideration to some sort of a path to redemption?

Speaker 5:          01:46:05       Yeah, the, there's, there's redemption and there's rehabilitation. Okay. You know, we, we haven't done a great job at having a cohesive stance on rehabilitation and redemption. We have it in parts. So the, the whole focus behind, um, the temporary suspensions is to at least give people pause and think about why they violated our why and how they violated our particular rules that they signed up for when they came in through our terms of service. Right. Whether you agree with him or not. Like this is the agreement that we have.

Speaker 1:          01:46:41       Well, do you know, I'm just thinking this, I'm sorry to interrupt you, but it would be kind of hilarious if you guys had an option, like a, a mode of Twitter, an angry mode. Like fuck, I'm angry right now. So I'm going to type some things and it says, hey dude, why don't you just think about this? We're going to hold it for you in the Q and. A. We will do that. People do that. People do that in their drafts, but in they do. I'm sure they did. But it would be funny if you had an angry mode. Yeah. But like me, you guys, I noticed you guys are using a lot of curse words and you're saying a lot of bad things were going to put you in an angry mode. So think about this. So you have to make several clicks if you want to post this and there is research to suggest that people expressing that actually tends to minimize more violent physical. Uh Oh for sure. Dot. Everyone says that with emails, if you're, if you're gonna, if you're in the middle of the night and someone sends you an email and you find it insulting, you ready your type anemia and then go to sleep, wake up in the morning like I'm going to say something nice. You know? That's how I wind up interacting with these people. But what, what do you think can be done for people like let's say Megan Murphy because she seems one of the, it's as easy to see her perspective is any what? What do you think could be

Speaker 2:          01:47:48       done for her? I think, I think you're right. I think that I would love to get to a point where we think of a suspensions is temporary and she's banned for life right now. That's the only option that we've built into our roles, but we have every capability of changing that and that's something that I want my team to focus on is thinking about, as Jack said, not just coming back after some time bound period, but also like what more can and should we be doing within the product itself early on to educate people about the role. So one of the things that we're working on as a very, very simplified version of the Twitter rules, that's two pages, not 20. I've made sure that my lawyers don't write it. It's written in as plain English as we can. We try to put examples in there and like really taking the time to educate people.

Speaker 2:          01:48:35       And I got, people aren't always going to agree with those roles and we have to address that too, but at least simplifying it and educating people so that they don't even get to that stage. But once they do understanding that there are going to be different contexts in people's lives, different times they're going to say and do things that they may not agree with. And they don't deserve to be permanently suspended for forever from a platform like Twitter. Oh, great. So how do you get to it? So we, we, this is something that actually we just had a meeting on this earlier this week, uh, with our executive team. Um, and, you know, identifying kind of some of the principles by which we would want to think about, um, you know, time bounding, suspension. So it's work. We have to do it and we're gonna figure it out. And I'm not going to tell you what's coming out right away, but it's on, it's on our roadmap. It's something that we want to do. Why don't you set up a jury system? When someone reports something instead of you having to worry about it, there would be no accusation of bias if 100,000 users were randomly selected to determine cause the periscope does this. Yep.

Speaker 1:          01:49:31       Yeah. And we've learned. So scope doesn't see a please explain that we, uh, so periscope has a, um, uh, uh, uh, content moderation jury. So we flag based on the machine learning algorithms. Um, and in some cases, um,

Speaker 3:          01:49:48       particular replies, we send them to a small jury of folks to ask, is this against our from service or is this something that you believe should be in the channel or 90 [inaudible] know to be on the jury? No, it's, it's random. So you were chosen and you decide whether or not you want to participate. Yup. Okay. And it's, it's good. It has some flaws that has some, some gaming aspects to it as well. But like we, we do have a lot of experiments that we're testing and like, we want to build confidence and like, it's actually driving the outcomes that we think are, are useful. Um, and periscope is a good playground for us across many regards.

Speaker 4:          01:50:27       I think ultimately one of the greater philosophical challenges is that you are a massively powerful corporation. You have international investors. I believe as a Saudi prince owns what, 6% of Twitter? So when I, is that true? I'm just wanna make sure it's correct.

Speaker 2:          01:50:40       We're a publicly traded corporate or anybody can buy stock, but that doesn't mean they have a influence on data.

Speaker 4:          01:50:46       Well, I think depending on which political faction you asked, I'll say money is influence, right? So I'm not going to say that the Saudi prince who invested in Twitter, because again, I've only a, it's been a while since I've read these stories. It's like showing up to your meetings and throwing his weight around, but at a certain point, not doing that, but, but you know, for I, I might do, I have to trust you, right? This is a guy who's throwing, throwing it over a billion dollars, I think into Twitter. Twitter has influence on our elections, foreign governments, foreign government actors have stake in Twitter. It worries me then when you base your rules on your personal decisions on an unelected group of people, you, you have such tremendous power in this monopoly on public discourse, near monopoly. Like he was saying you some platforms, Twitter has no real competition.

Speaker 4:          01:51:23       So I just have to hope and trust you have the best interest at heart, but you at the end of the day, it's, it's, it's authoritarian. No one chose you to be in charge of this. I understand you mentioned you discovered Twitter, but here I am looking at, you know, both of you have this tremendous power over whether or not someone can get elected. You can choose to band someone and tell me all day and night you have a reason for doing it. I just have to trust you. That's terrifying. There's no proof. There's no proof Alex Jones at any of these things other than thinks he's posted. Right. I understand that. That's actually what I was on the phone with to Alex was texting me saying that he'd never did anything to endanger any child and that he was disputing what people were saying about a video of a child getting harmed. And so do we just trust an unelected, uh, I mean, you were extreme, extremely wealthy individuals. Saudi princes, you know, it's a publicly traded company who knows where the infant is coming from. Your rules are blessed not based on a global policy and I'm sitting here watching, wow, these people who are never chosen in this position and have too much power over my, my, my, my, my politics.

Speaker 2:          01:52:17       I think that that's why it's so important that we take the time to build transparency into what we're doing and that's part of what we're trying to do is not just in being here and talking to you guys, but also building it into the product itself. I think one of the things that I've really loved about a new product launch, what we've done is to disable any sort of ranking in the home timeline if you want and you don't have to see our algorithms at play anymore. These are the kinds of things that we're thinking about. How do we give power back to the people, our service so that they can see what they want to see and they can participate the way they want to participate and this is longterm and I get there, we're not there yet, but this is how we're thinking about it

Speaker 5:          01:52:54       and you can imagine where that goes. I mean an interest one switch and turning all the algorithms off or what, what does that do? What does that look like? Um, so these are the conversations that we're having in the company, whether they be good ideas or bad ideas. We haven't determined that just yet, but we, we, we definitely look, I definitely understand the mistrust that people have in our company and myself in the corporate structure and all the variables that are associated with it, including who chooses to buy on the public market, who chooses not to. I, I get all of it and I grew up on the Internet. I'm a believer in the internet principles and I want to do everything in my power to make sure that we are consistent with those ideals. At the same time, I want to make sure that every single person and do everything in my power has the opportunity to participate.

Speaker 4:          01:53:45       So let me ask you a question then, um, for your policy as it pertains to say, Saudi Arabia, right? Do you enforce the same hate speech rules on Saudi Arabia? Are Our roles are global? We enforced them against everyone. So even in countries where it's criminal to be LGBT, you will still banned someone for, for saying something disparaging to, or it was saying something to that to that, to that effect. Like let's say Saudi Arabia sent in, someone's took to death for a, I don't want to call it how your base specific, let's call it Iran Ron, because I believe that's the big focus right now with Trump administration. Iran. It's my understanding it's still punishable by death. I could be wrong, but it is criminal. If someone then directly targets one of these individuals, will you ban them? I mean, do you guys function any round? Cause I think we're blocked in Iran. Yeah, that's what I figured. But there are some countries where, for instance, I'm Michelle Malkin recently got really angry because she received notice that she violated blasphemy laws in Pakistan. Right. So you do follow some laws in some countries, but it's not a viable, I guess the question I'm asking you is in Pakistan, it's very clearly a different culture. They don't agree with your rules.

Speaker 5:          01:54:47       We do have a per country takedown, meaning that I'm content might be nonvisible within that country, but visible throughout the rest of the world. But so

Speaker 2:          01:54:54       look, I guess the question, just to add onto what Jack's saying, we actually are very, very transparent about this. So we publish a transparency report every six months. The details, every single request that we get from every government around the world and the content that they ask us to remove. And we post that to an independent third party site. So you could go right now and look and see every single request that comes from the Pakistani government and what content they're trying to remove from Pakistan. And I, I've,

Speaker 4:          01:55:19       I've seen a lot of conservatives get angry about this and it's kind of confusing, confusing. I'm like, this is a really good thing. I would want to know if Pakistan wanted to kill me. No anger, a blasphemy laws posting pictures of Muhammad. So, uh, it's a, it's a crime. Are they angry about our transparency report? Are there, there's, there's a perception that you sending that notice is like a threat against them for violating blasphemy laws. Whereas it's very clearly just letting you know a government has taken action against you,

Speaker 2:          01:55:44       which it's saying that the government has restricted access to that content in that country. And the reason we tell users or tell people that that's happened is because a lot of them may want to file their own suit against the government or a lot of them may be in danger if they happen to be under that particular governments jurisdiction and they may want to take action to protect themselves if they know that the government is looking at the content in their accounts. So we don't always know. We don't, we send the notice to everybody, we don't always know where you are or what country you live in. And so we just send that notice as like to try to be as transparent as possible.

Speaker 4:          01:56:15       The, the main point I was trying to get to is your policies support a community, but there may be laws in a certain country that does not support that community and finds a criminal. Right. So your actions are now directly opposed to the culture of another name of the country. I guess the point I'm trying to make is that if you enforce your values, which are uh, you know, perceivably not even the majority of this country, if you're, you know, consider yourselves more liberal leaning and you're half of the United States, but you're enforcing those rules on the rest of the world that use the service. It's sort of forcing other cultures 20 or to yours.

Speaker 3:          01:56:48       So a lot of, a lot of our rules are based in more the UN declaration that isn't just purely us.

Speaker 4:          01:56:55       Doesn't the UN declaration guarantee the right of all people through any medium to express their opinion?

Speaker 3:          01:57:00       It does. And it also has, can, it also has conditions around particular speech, inciting violence. Um, and um, some of the, some of the aspects that we speak to as well, and it protects from the covenant

Speaker 2:          01:57:12       stories, whether it's religion, race, gender, sexual orientation, those are all also protected under the UN covenant to Protect Human Rights.

Speaker 3:          01:57:22       Ooh, we'll give that a pause. I'm sure we have many more things to talk about Doug. No worries. I don't want to just just saying this has got a bunch of other things that,

Speaker 4:          01:57:33       you know, cause here's the thing, there's a bunch of other issues having to do with bias and censorship and I feel like we've kind of beaten that horse relentlessly.

Speaker 3:          01:57:40       But I think that horse is good to beat. It's also good to address why the worst is being beaten and why, why it exists in the first place. Um, and I, I really, I want to say this again. I really appreciate the fact that you guys are so open and that you're willing to come on here and talk about this cause you don't have to. This is your decision and especially you, Jack, after we had that first conversation and the, the blow back was so hard, you wanted to come and clarify this. And I think this is so important to give people a true understanding of what your intentions are versus what perceptions are. You. Appreciate it. Thank you for hosting us again. And um, look, I, I think it's also important that the company is not just me. We have people in the company who are really good at this and are making some really tough decisions and having tough conversations and, and getting pushed back and getting feedback and they have the best intentions. So what, so let's, I'll,

Speaker 4:          01:58:42       I'll get back into the meat of things to get to beating the dead horse. I don't know if you have any data on why Jacob Wall was recently banned.

Speaker 2:          01:58:48       Do you have that? Uh, uh, I believe

Speaker 4:          01:58:50       who is chicken wall? He's a, I don't know how to describe me as a conservative personality, but he's very, very, uh, controversial for like fake news or something. I don't know too much about them so I don't want to accuse them of things because I don't know who he is. But he was, uh, he was in something where you tried accusing Muller of like sexual assaults and it turned out to be like just completely fake, ridiculous. Good. This was a gentleman that was in the USA Today article where he admitted that he was going to, he had a use tactics in the past to influence the election and he will continue to do so using all of his channels. Yes.

Speaker 2:          01:59:25       When we saw that report, our team, um, looked at his account, we noticed there were multiple accounts tied to his account, so fake accounts that he had created that we're discussing political issues and pretending to be other people from other firms that we would have phone numbers, linking accounts together or email addresses and some cases, Ip addresses, other types of metadata that are associated with accounts. So we can link those accounts together. And having multiple accounts in and of itself is not a violation of our rules because some people will have their work account, the personal account. It's when you're deliberately pretending to be someone else and manipulating a conversation about a political issue. And those are exactly the stint, the types of things that we saw the Russians do, for example, in the 2016 elections. So it was that playbook and that type of activity that we saw about Jacob Wall. And that's why his accounts were suspended. Did you investigate Jonathan Morgan? I don't know who that is. Why the, that's, that's the important question of why I, I don't, I don't know who that is, but that's, that's, it might be that someone at Twitter investigated him. I personally don't know.

Speaker 4:          02:00:27       So, uh, one of the issues that I think is really important to get to is you should know who he is. He's more important than Jacob Wallets, but for some reason, you know about this conservative guy and not the Democrat who, who helped metal in the Alabama election. Well, so Jonathan, according to near sheer volume, they have to pay attention to it. Right? Right, right. But it's, it's about grains of sand making a heap and the flow of a direction where we can see Jacob Wall has said he's done this. So you're like, we're gonna investigate. We banned him. It was recently reported and covered by numerous outlets that a group called new knowledge was meddling in the Alabama election by creating fake Russian accounts to manipulate national media and to believing that Roy Moore was propped up by the Russians. Facebook banned him and as well as for their people. But Twitter didn't, he's still at it

Speaker 2:          02:01:07       did ban the accounts that were engaged in the behavior.

Speaker 4:          02:01:09       I do remember that. I do remember signing this division in our team. That's worse though. So you didn't bend the guy doing it, but you band the people like

Speaker 2:          02:01:16       so in the case of Jacob Wall, we were able to directly attribute through email addresses and phone numbers, his direct connection to the accounts that were created to manipulate the election. If we're not able to tie that direct connection on our platform or law enforcement doesn't give us information to tie attribution, we won't take action. And it's not because of political ideology, it's because we want to be damn sure before we take action it. So someone could use a VPN perhaps and maybe additional email accounts and they could game the system in that. We are certainly sophisticated ways that people can, can do, uh, things to mask who they are and what accounts that they're controlling.

Speaker 5:          02:01:52       Interesting internal conversation to just to provide more light and to what happens. Like I got a, I got an email or a text from Vigia, um, one morning and said, we are going to permanently suspend those particular account and it's not a, you know, what do you think it's, we are going to do this. And I then have an opportunity at task questions. I asked a question why she gave me a link back to the document of all the findings and USA Today. Um, we took the action. I was on Twitter. A bunch of people pointed me at this particular case since some of those tweets to her what's going on? So that's well that's in the background.

Speaker 4:          02:02:32       Wouldn't you just terminate anybody associated with the company that was doing this? I mean you keep in mind too, at the time when this campaign was happening, this is what pieces he had, he admitted to engaging in the operation in a quote to New York Times and you banned the accounts associated with it. So if you know he's the one running the company, wouldn't you be like, okay, your gun,

Speaker 2:          02:02:48       um, do you want us to take every single newspaper accounts attribution? Because what we were able to do in the Jacob Wall situation was actually tie those accounts in our own systems, right. That he will actually control the rounds. Not just take the word of a newspaper.

Speaker 4:          02:03:01       Yeah. You can have a second. You said you band his accounts. Yes. And you know from his own statement and from his tweets that he was the run running, running the company. Jacob Wall.

Speaker 2:          02:03:11       No, no, no, no, no. Jonathan Morgan. Oh, sorry. I'm getting confused.

Speaker 4:          02:03:14       So, uh, uh, Jacob Wall, it's announced in the USA Today. He says, I'm doing this and you're like, okay, we can look at as like how we can see it. We get rid of him with, with new knowledge. You said you did

Speaker 2:          02:03:24       those counts down? I believe we were able to take down a certain cluster of accounts that we saw engaging in the behavior, but we weren't necessarily able to tie it back to one person controlling those. Like even if they say they did it and this is where I get back. Like we like to have some sort of attribution that's the direct that we can see. Would we just take the any newspaper or any article at face value and just action them. That's it. Go. Do you have to contact him and get some sort of a statement from him in order to take down as account? And obviously I don't think he would admit to manipulating Twitter if Twitter asked him. So get the fact that he communicated with a newspaper. Right.

Speaker 4:          02:04:00       To clarify, uh, what they said, what they claimed to the New York Times was that it was a false flag. Uh, New York Times said they reviewed internal documents that showed, they admitted it was a false flag operation. Um, the guy who runs the company said, Oh, his company does this. He wasn't a aware necessarily, but it was an experiment. So He's, he's given kind of a, in my opinion, duplicitous, like, you know, not straight forward, but at the time of this campaign, which he claims to know about, he tweeted that it was real. So during the Roy Moore campaign, he tweets, wow, look at the Russians. Then it comes out later. His company is the one that did it. So you're kind of like, oh, so this guy was up his own fake news. Right. Then when they get busted he goes, oh no, it's just my company doing an experiment. But You tweeted it with real pyramid, you use your verified Twitter account to push the fake narrative your company was pumping on this platform. And so, so the point I want to make, I guess is

Speaker 2:          02:04:52       it sounds like we need to take a closer look at this one

Speaker 4:          02:04:54       ban and bring back Morgan murder. Well, Meghan Murphy, Megan Murphy, sorry. Morgan Murphy is a friend of mine. Te, te Te. Te to, sorry Morgan. So this is the, I haven't read the story. It's been like two months since the story broke. So I could have my, you know, I don't want to, I don't want to get sued and have my facts wrong, but the reason I brought this up was not to accuse you of wrongdoing. What's the point out that I don't, I don't think that the people who work at Twitter are twirling their mustaches, laughing, you know, bad pressing the ban button whenever they see a conservative. I think it's just, there's a bias that's unintentional that flows in one direction. So you see the news about Jacob Wall and I think there's a reason for it too. There's a couple of reasons for one, yours, your staff is likely more, you've mentioned more like the Tylene left and look at certain sources.

Speaker 4:          02:05:37       Uh, so you're going to hear about more things more often and take action on those things as opposed to the other side of the coin. But, but we, we have to consider like where the actions are taking place. And I'm speaking more broadly to the 4,000 people that we have as a company versus deliberateness that we have on bridges team. I just mean when we, when we look at a company wide average of all of your employees and the direction they lean versus the new sources they're willing to read, you're going to see a flow in one direction, whether it's intentional or not. And so I think the challenges,

Speaker 2:          02:06:04       well we don't generally rely on new sources to find inspiration of our platform. We we're looking at what we're seeing, the signals we can see and once in a while we will get tipped off to something. But like for the most part when we're looking at manipulation, it's not like the New York Times can tell us like what's going on on the platform where the ones that have the metadata ABAG accounts, where are the ones that can see patterns of behavior at scale.

Speaker 4:          02:06:24       But I hear your point. I knew one name and I didn't know another name and it was because visual said you don't work permanently banning this account. And yes, we, we didn't have the same sort of findings in the other particular account, which I got feedback on pass to her and, and we didn't find what we needed to find I think,

Speaker 2:          02:06:42       but to be clear, the team had taken action on those stuff months ago when it actually had happened. Got It. Got It.

Speaker 4:          02:06:46       Yeah, I think, you know, uh, a lot of what people assume is malintent is sometimes fake news. You know, I think one of my biggest criticisms in terms of what's going on our culture is the news system is, like you pointed out, although it's changed, left wing journalists only follow themselves. I, that's my experience. I've worked for these companies. And so they repeat the same narratives. They don't get out of their bubble, even today. They're still in a bubble and they're not seeing what's happening outside of it. And then what happens is, you know, we, uh, according to date, I think this is from Pew, most new journalism jobs are in blue districts. So you've got people who only hear the same thing. They only cover the same stories. So if, you know, um, we hear, uh, about Jesse Small light, we hear about how the stories it goes, it goes wild. But there's like 800 instances of Trump supporters wearing maga hats, getting beaten. You know, throughout the past couple of years we had a guy show up to a school in Eugene with a gun and fire two

Speaker 3:          02:07:36       rounds at a cop wearing a smash the patriarchy and she'll shirt. And those stories don't make the headlines. So it's, you know, when, when the journalists are inherently in a bubble, the information you're going to get as a big company who follows these news organizations is going to be inherently one side as well. And then you only action you're gonna be able to take is what you, you know, you can't ban someone if you don't know they're doing it. But I hear you. I think that our biggest issue, and the thing that I, I want to fix the most is the fact that we create and sustain and maintain these echo chambers. Yeah. Well, you, you're rolling out that new feature that allows you to hide replies, right? We're, we're, we're testing, we're experimenting with a inability to, um, enable people to have more control as you would expect to a host over the conversation.

Speaker 3:          02:08:18       And like, Facebook allows that. Yeah, but I don't think they have the level of transparency that we want to put into it. So we actually want to show whether a comment was moderated and then actually allow people to see those comments. Um, so both showing the action that this person moderated a particular comment and then you can actually see the, so if it's one click, one click, one click over, one tap over. Um, that's how we're thinking about it. It might change in the future, but we, we can't do this with a level of transparency because we minimize something. Visit spoke to earlier, which is speaking truth to power, holding people to account. Even things like the fire festival where, you know, you had these organizers who were deleting every single comment, moderating every single comment that called this thing of fraud. And don't go here. We can't, we can't, we can't reliably. And, and like just from a responsibility standpoint, ever create a feature that enables more of that to happen. And that's how we're thinking about even features like this. I'm going to jump right off into a different train cart here. Has Law enforcement ever asked you to keep certain people on the platform even after they violated your rules?

Speaker 10:         02:09:26       Uh,

Speaker 3:          02:09:27       not that I'm aware. So then this, you know, to the, to the next question pertained to bias. You have the issue of Antifa versus the proud boys and Patriot prayer and a Twitter permanently excised anyone associated with the proud boys antifa accounts who have broken the rules repeatedly branded known cells that have been involved in vines all still active.

Speaker 10:         02:09:47       Okay.

Speaker 6:          02:09:48       Is there a reason? Well, with the proud boys, what we were able to do was actually look at documentation and announcements that, you know, the leaders of that organization had made and their use of violence in the real world. So that was where we were focused on and subsequent to our decision, I believe the FBI also designated that's not true. It's not true. That's not true. No. Okay. No, that's not true yet. You know, the proud boys started out as a joke. Gavin McInnes, Anthony [inaudible] who was a part of opie and Anthony knows his own show, tall, told me about it happened on his show because there was a guy that was on the show and they made a joke about starting a gang based on him cause he was a very a feminine guy. And they would call him the proud boys. And I'm the, they went into detail about how this thing

Speaker 4:          02:10:34       from a joke and saying that you could join the proud boys and everyone was, you know, it was like being silly to people joining it and then it becoming this thing to fight antifa and then becoming infested with white nationalists and becoming was thing well in, in, in, in many ways it hell it was, but it's been documented how it started and what it was and misrepresented as to why it was started. I think there's some things that should be clarified about them. But Gavin has made a bunch of statements that crossed the line. He claims he claims to be joking. And so that's, that's what he did on my podcast. He was talking to me about Antifa. The ANTIFA was blocking people like Ben Shapiro speeches and things along those lines. And stopping conservatives for speaking, you should just just punch them in the face.

Speaker 4:          02:11:19       We're going to have to start kicking people's asses. And I was like, well, this is the risk, not just irresponsible but foolish and short sided and it's just a dumb way to talk. So then you have the antifa groups that are engaging in the same thing. We've, we, you know, the famous bike lock basher incident where a guy shut up, hit seven, uh, he hit seven people over that with a bike lock. Um, they subsequently released his, damn, I'm going to leave that out for the time being. You have other groups like by any means, by any means necessary. You have in, um, uh, Portland for instance, there are specific branded factions. There is, uh, the, the tweet I mentioned earlier where they docs ice agents and they said, do whatever inspires you with this information. And I mean, you're tagged in it a million times.

Speaker 4:          02:11:58       I know you probably can't see it, but you can actually see that some of the tweets and the threat I removed. But the main tweet itself from an antifascist account linking to a website straight up saying like, here's the private home details, phone number addresses of these law enforcement officers is not removed in September. So here's what you end up seeing is, uh, again to point. I think one of the big problems in this country is the media because it was reported that the FBI designated probably was an extremist group, but it was a misinterpretation based. Uh, uh, sheriff wrote a draft saying with the FBI considers them to be extremists. The media then reported hearsay from the sheriff and the FBI came out and said, no, no, no, we never meant to do that. That's not true. We are just concerned about violence. So the proud boys, I'll get purged.

Speaker 4:          02:12:38       And again, I think, you know, Gavin's a different story, right? If you want to go after the individuals who are associated with that group versus the guy who goes on the show. And says outrageous things and goes and Joe show. And then you have the Antifa branded sells. Like what I mean by that is they have specific names. They sell merchandise and they're the ones showing up throwing mortar shells into crowds. They're the ones showing up with, with crowbars and bats and whacking people. I was in Boston and there was a rally where conservatives are planning on putting on a rally. It was literally just like Libertarians and conservatives antifa shows up with crowbars bats in balaclavas with weapons threatening them. And so I have to wonder if, if you know, these people are allowed to organize in your platform. Are you concerned about that?

Speaker 4:          02:13:18       Why aren't they being banned when they violate the rules? Yeah, absolutely. We're concerned about that. Has the FBI designated them as a domestic terrorist? Yes. I'm sorry. Homeland Security in New Jersey has listed them under domestic terrorism. So, so here I understand is a conundrum in that the general concept of anti fascism is a loose term. That means you oppose fascism, right. But antifa is now they have a flag. They've had a flag since the Soviet, you know, a Nazi Germany in the Soviet era and they've brought it back there. Specific groups that I'm not going to mention by name that have specific names and they sell merchandise. They've appeared and various news outlets. They've expressed their desire to use violence to suppress speech. There was a,

Speaker 2:          02:13:53       is that a centralized organization the same way that I hear you on proud boys, but like where they have like tenants that are written out and there was a leader and like,

Speaker 4:          02:14:02       uh, no, it's not the same, but there are specific branded cells. So that's why I bring them up. Specifically, I realize, you know, someone showing up to a rally wearing a black hoodie and sunglasses. We, who are you gonna ban? But there are groups that that organize specifically called for violence. They, they, they pushed the line as close as, as, as lightly as possible. They advocate sabotage and things like this. And you know, when the proud boys go out and get in fights, they're not getting in fights with themselves. They're, you know, so

Speaker 1:          02:14:28       point out to the, they decided to call for violence based on Antifa calling for violence based on Antifa actually actively committing violence against conservative people that were there to see different,

Speaker 4:          02:14:39       well, it partly started because in Berkeley there was a Trump rally. So actually after Milo got chased out of the Berkeley, they were, there was $100,000 in damages. I mean, there's a video of some guy in all black cracking. Someone on the back was on the ground looking like they're unconscious. So these conservatives see this and they decided to hold a rally saying we won't back down. They hold a rally in Berkeley and then Antifa shows up again. I understand you can't figure out who these people are. For the most part, they are decentralized. But then this insights, uh, an escalation, you then get the rise of the base to stick. Man, they called it, this guy shows up in armor with a stick and he starts swinging back and now you have two factions forming. So while I recognize it's much easier to ban a top down group, there are, you know, the difference I would get I guess is while will you look at the proud boys, it's straight, top down vertical. You look at Antifa and there's different cells of varying size and their different accounts. So I have to, uh, to like, I guess the argument I could make as if you're going to bend the proud boys by all means for under your justification. But if you look at a specific channel that's got 20,000 followers that cheers them on, right? These are people who throw mortar shells into crowds. Isn't that advocating for terrorism and incitement to violence? Yeah, absolutely. So I guess the question is how come they don't get removed?

Speaker 2:          02:15:52       Well, in the past when we've looked at, um, antiviral, we, it's, we ran into this decentralization issue, which is we weren't able to find the same type of information that we were able to find about Prometheus, which was a centralized leadership base documentation of what they stand for. Um, but absolutely. I mean it's something that we'll continue to look into and to the extent that they are using Twitter to organize any sort of offline violence that's completely prohibited under our rules. And we would absolutely take action. Two.

Speaker 1:          02:16:17       Why Gavin was Bam that, was there a specific thing that he did or was it as the association with the proud boys and association with the problem? You know, he's a abandoned that he's not only that he's disassociated themselves with it and said that it got out of him

Speaker 2:          02:16:30       and he doesn't want to have anything to do with it. Yeah. And I think this is a great test case for how we think about, uh, getting people back on the platform.

Speaker 1:          02:16:37       Yeah. In the center. He's an interesting case because he's a really a provocateur and he fancies himself, you know, sort of a punk rocker and he just, he likes stirring shit. I mean [inaudible] when he came on my show last time he was on, he was dressed up like a Michael Douglas and falling down, you know, he, he did it on purpose. He brought a briefcase and everything. I'm like, what are you doing? It's like a Michael Douglas and falling down like he's, he's a showman in many ways and he did not mean for this to it go the way it went. He thought it would be this sort of innocent fun thing to be a part of and then other people got involved in it. And then when people call for violence, the problem is they think that you know you're going to just hit people and that's going to solve a problem. It just creates a much more, much more comprehensive problem.

Speaker 4:          02:17:24       Why it's important to point out, Gavin said has had meant like you said things way worse than than Alex Jones ever did. Sure. Whether you want to say it's a joke or not. He said things like, you know, choke him, punch him like directly. Yup. But I guess was the primary reason for getting rid of them was what you thought that the FBI had designated them an extremist group?

Speaker 2:          02:17:41       No, cause we did it many months in advance. Oh, okay. Yeah, I was just,

Speaker 1:          02:17:45       so, he just, it was just his association with the proud boys.

Speaker 2:          02:17:48       I don't recall and I would have to go back and I don't want to misstate things. I don't recall whether those statements that you're referring to of Gavin's we're on

Speaker 4:          02:17:55       Twitter, so they weren't. Um, there's another, you know, when it comes to the weaponization of rules against, like Gavin isn't creating a compilation of things he's ever said out of context and then sending them around to get himself banned. Other people are doing that to him, activist who don't like him and it's effective. In fact, I would actually like to point out, um, there's one particular user who has repeatedly made fake videos attacking one of your other high profile conservatives. So much so that he's had to file police reports, harassment complaints, and it just doesn't stop, you know? So I guess I'll ask this after to this regard. If someone repeatedly makes videos of you out of context, fake audio accusing you of doing things you've never done, at what point is that valuable?

Speaker 2:          02:18:34       Yeah. Again, if it's targeted harassment and we can establish that, it's just a really hard thing with a US determining whether something is fake or not.

Speaker 1:          02:18:40       Well, it's awesome when, when things are out of context, you still have video of the person saying that. I agree that it's not a contest that it's disingenuous, but it's still the person saying it and you're making a compilation of some preexisting or audio or video.

Speaker 4:          02:18:55       So I think in, in this instance of Gavin, like one of the things he said was like a call to violence, but he was talking about, uh, like it was in the context of talking about a dog and being scolded. Yeah. So he was like, hit him, just hit him. And then it's like, it turns out he's talking about dog, like we're doing something wrong. Right. And they take that and they snippet and then it goes viral. And everyone that's flagging saying, you got to ban this guy. Good. I understand you. Like, you know, but, uh, I guess the issue is if people keep doing that to destroy someone's life. So, so I think there's, there's a, there's a bigger discussion. I think. Um, both of you could probably shed some important light on too, outside of Twitter. This weaponization of content from platforms is

Speaker 7:          02:19:27       being used to get people banned from their banking accounts. You know, they're getting there. We can talk about patriotic for instance, and again I'm not, this is, this may just be something you could chime in on. Patrion band, a man named Carl Benjamin, also known as Sargon of a cod. He's also banned from Twitter and it was because you know why he got banned from Twitter.

Speaker 2:          02:19:44       Um, I can see

Speaker 6:          02:19:49       that's an interesting one.

Speaker 2:          02:19:52       Uh, I do have some, some of the details here. Um, do you want me to read them? Okay. Um, it looks like it's going to be growth. It's not stuff that I love saying. Um, but I will say it. What job said I shouldn't make, he doesn't like cursing either. Um, let's see. I curse more than he does, so I guess I should say it a first strike. Um, fuck white people kill all men die. CISCOM none of the above qualify as hate speech one was that, uh, I don't have the dates. I'm sorry.

Speaker 7:          02:20:25       He's, he's a white guy. I mean obviously he's joking around there. Fuck white people. It also sounds like he's trying to make a point about your roles and how you enforce them. Not Actually, which is also exactly why you got kicked off patriarch. He was, it was exactly. Yeah. Well, I know he also posted a photo of interracial gay porn at some white nationalists to make them angry. Yes. Yeah. He's funny. He's funny. As I'm dying, I, I can understand how a posting that photo is that agregious violation of the rules, whether, whether or not he was trying to insult some people. That's a very good point. And I wanted to bring that up. Is Porn a violation of the rules?

Speaker 6:          02:21:01       Uh,

Speaker 7:          02:21:02       porn generally? No. Good. Really good for you. Why would cause any bends in my feed all the time. I follow a couple of naughty girls and occasionally they post pictures of themselves engaging in intercourse. I'm like, yikes. So then what, what else, what are the other strikes for Saigon?

Speaker 2:          02:21:18       Um, let's see. Um, there was the use of a Jewish slur. Um, how do you use it? A two or a person. You trader remaner white genocide supporting his Llama file.

Speaker 6:          02:21:33       Did you were slower lover

Speaker 2:          02:21:35       that should keep you going Hashtag Hitler was right,

Speaker 7:          02:21:38       but, but these are general opinions. These are targeted. They're targeted at somebody that that sounds like he's being like he's making a joke. I understand in context the, it sounds like the other one, like in context what he's saying, particularly the fact that he's a white guy. That doesn't sound like a racial slur at all. I mean he's saying fuck white people and he is white

Speaker 2:          02:21:58       and context. Again, these are tied together. I always knew that person was not to be trusted that fucking Jewish slur.

Speaker 7:          02:22:06       Oh, so there's a lot, there's a bunch of very specific person targeting trying to be very provocative saying this without a specific Jewish person. I don't know the race of this person. I'm sorry. And this is not okay, but this is not it. This is not parody. This is not joking around. We didn't view it that way. I'm just telling, I'm not trying to like read, litigate all this. I'm

Speaker 4:          02:22:26       just telling you what they were. I knew he had done things that were like egregious violations of the rules because, you know, plain simple, I didn't bring him up to go through and try and figure out a feat, but that it does sound like, at least the first one was meant to be a critique of. So there are a bunch of others. If you want to hear him more than that, keep it rolling. Again, targeted, this is how I know one day that I'll be throwing you from a helicopter. You're the same kind of malignant cancer. Don't forget it. Um, so there's just, it's not one thing or two things or three things. This just like a bunch of them. Even though you throw someone from a Heloc, well he doesn't really like you in that helicopter, but admittedly, and I, so, so he, he, he, he's on youtube by the name of Sargon of Akkad is a big account and I've, I've criticized him for being overly mean in the past and I think it's exemplified by angry, but, but he, he has a very different now.

Speaker 4:          02:23:12       And I guess the reason I brought him up was not very different though. How so? Well, a lot of the content, he makes as much calmer. He's, he's less likely to insult someone directly. He makes probably recognizing that he's on his last straw. Oh, definitely. Especially ticked off of Twitter. He's on Youtube. He's probably got a mind his p's and q's. Oh, but so, um, the reason I brought him up again, but we'll move on was that activists found a live stream from eight months ago. I totally forgot why I was bringing it up because we've moved so far away from where we were. But um, they, they pull this clip from an hour and a half or whatever into a two hour live stream on a small channel. They only have 2000 views sent to Patrion and then Patriot and said, yep, that's a violation and banned him out.

Speaker 4:          02:23:51       Right. Without warning. Which again, I understand it's different from what you guys do. You do suspensions first. But, uh, I guess the reason I was bringing up was to talk about a few things. Um, why blocking isn't enough. Why muting isn't enough. And if you think that it's driving people off the platform, people post my tweets on Reddit, I blocked them, they use a dummy account, load up my tweet, post it to reddit and then spam me on reddit. So you know, blocking and even leaving Twitter would never do anything short of me shutting up. There's nothing you can do to protect me or anyone else.

Speaker 5:          02:24:20       Look, I mean these are exactly the conversations we're having are one, the reason why I don't think blocking and muting or enough is one, I don't think we've made mute powerful enough. It's spread all over the service. Uh, you, you can use it and then you got to go find where you actually meet. These people are in their little profile page and that's just, uh, it's not a, it's a disaster. It just doesn't work in the same way that it should work. In the same way that follow works, which is just the inverse event,

Speaker 4:          02:24:48       I noticed that now I get a notification that says, you can't see this tweet because you made it this person before. I would just see a weird reply and be like, oh, it's one of those. Exactly. So

Speaker 5:          02:24:56       there's also all this infrastructure that we have to fix in order to like pass those through in terms of what action you took or what action someone else talked to be transparent about what's happening on the network. The second, um, the second thing that block is really interesting. I think it's, uh, my own view is it's wholly an unsatisfying because what you're doing is your blocking someone. They

Speaker 3:          02:25:24       get notification that you've blocked them, uh, which may embolden them even more, which causes, you know, others around and ramifications from, from the network. But also that person can log out of Twitter and then look at your tweets. Uh, just on the public web, because we're, we're public so it doesn't feel as as rigorous and as durable as something like making mute much stronger.

Speaker 4:          02:25:48       I guess the challenge is no matter what rule you put in place, people are going to harass you if you're a, if you're engaging in public discourse, you know, if I go out in the street and yell out my opinion, somebody could get in my face if I get off Twitter cause I'm sick. I mean look, you know, I'm sure you get it way worse than I do, especially as you know, the high profile probably getting it right now. Yeah, totally. Oh, me too. God, I can only imagine, but so, so the only thing I can do is, look, we're not on Twitter right now. We're on Joe Rogan's podcast and they're still going to target you on Twitter. They're still going to, it's, I guarantee we're all of a reddit. The leftist probably railing on me, the rights wailing on you guys. So it's, it's, it seems like even if you try everything in your power to make Twitter healthier and better, it's not going to change anything

Speaker 1:          02:26:29       that I'm not sure about that because one of the things that I do think is that just, I'm not in favor of a lot of this heavy handed banning and a lot of the things that have been going on, particularly like a case like the Megan Murphy case. But what I think that we are doing is we're, we're exploring the idea of civil discourse where we're trying to figure out what's acceptable and what's not acceptable and you're communicating about this on a very large scale and it's putting that out there and then people are discussing it whether they agree or disagree with a vehemently defend you or, or hate you. They're discussing this and this is, I think this is how these things change and they change over long periods of time. Think about words that were commonplace just a few years ago that you literally can't say anymore. Right. You know, I mean, there's so many of them that were extremely commonplace or not even thought to be offensive 10 years ago that now you can get banned off.

Speaker 4:          02:27:30       Well, so it was for, but that's, that's a good point to argue against banning people and to cease enforcing hate speech rules. Yeah, I agree with that as well. I think it's both things. Let me, let me, let me, let me tell you something important. I was in the UK at an event, um, for a man named [inaudible] who, I don't know if you've heard of oh, sure. Yeah, yeah. Dan is the guy who got charged and convicted of making a joke where he had his, his pug do a Nazi salute. But I was there and I was arguing that a certain white nationalists had used racial slurs on youtube. He has, I don't want to name him, and some guy in the UK said, that's not true. He's never done that. And I said, you're crazy. Let me pull it up. Unfortunately, I don't know why, but when I did the Google search, nothing came up.

Speaker 4:          02:28:11       What I did notice at the bottom of the page, it said, due to, you know, UK law, certain things have been removed. So I don't know if it's exactly why I couldn't pull up a video proving or tweets anything. Because I think using these words gets rescript from the social platforms. I could not prove to this man the first century in that in the UK that this man is a VPN and then get around that. Uh, yeah. I mean at the time I was just like trying to pull it up and I'm like, oh, that's weird. So now you have someone who doesn't realize he's a fan of a bigot because the law has restricted the speech. So there's a point to be made if you, I understand, you want a healthy, like you, you want Twitter to grow, you need it to grow. The shareholders needed to grow, the advertisers need to advertise.

Speaker 4:          02:28:51       So you've got all these restrictions. But allowing people to say these awful things, make sure we stay away from them and it allows us to avoid certain people. And it isn't an important to know that these people hold these beliefs. If you get rid of him, you know, someone could walk into a business and you wouldn't even know that they were a neo Nazi, but if they were high profile saying there things you'd be like that's the guy at home. Like you're absolutely right. This is like one of my favorite sayings is that sunlight is the best disinfectant and it's so, so, so true. I like one of the biggest problems with censorship is the fact that you pushed people underground and you don't know what's going on. And this is something I worry about. It's not that I don't worry if you ban people for these roles, I also worry about driving people away from the platform and affecting their real lives. So what we're trying to find this right balance and I hear you like you may not think we're drawing the lines in the right place and we get that feedback all the time and we're always trying to find the right places. But I worry as much about like the underground and like being able to shine a light on these things is as anything else.

Speaker 5:          02:29:51       I think it's a cost benefit analysis and we have to constantly rehash it and do it. Like we, we have the technology we have today and we are looking at technologies which opened up the aperture even more and we all agree that a binary on or off is not the right answer and it is not scalable. We have started getting into nuance within our enforcement and we've also started getting into nuance with the presentation of, of content. So you know, one path might have been for some of your replies for us to just remove that, those, you know, offensive replies completely. We don't do that. We hide it behind an interstitial to protect the original tweeter and it, and, and also folks who don't want to see that they can still see everything. They just have to do one more top. So that's one solution. Ranking is another solution, but as technology gets better and we get better at applying to it, we have a lot more optionality. Whereas we don't, we don't have that as much today.

Speaker 4:          02:30:55       I feel like I'm just gonna reiterate an earlier point though. You know, if you recognize sunlight is the best disinfectant, you're, it's like you're, you're chasing after a goal that can never be met if you want to. If you want to protect all speech and they start banning certain individual, you want to, you want to increase the amount of healthy conversations, but you're banning some people. Well, how long until this group is now funded by that group? How long until you've banned everybody? I hear you. I don't believe a permanent ban promotes health. Don't,

Speaker 5:          02:31:19       I don't believe that. But we, we have to, we have to work with the technologies, tools and conditions that we, that we have today. So, and evolve over over time to where we can see examples. Um, like, uh, this woman at the Westboro Baptist Church who was using Twitter every single day to spread hate against the Lgbtqa community. And over time we had, I think it was three or four folks on Twitter who would engage her every single day about what she was doing. And she actually left the church. She's amazing. And she is, she's not pulling her family out of that as well. And you could make the argument that if we banned that account early on, she would have never left the church. I completely hear that. We, we get it. It's, it's just,

Speaker 4:          02:32:07       well, so let's, let's, I just want to make sure we had, we're advancing the conversation too and not just going to go back. So, uh, I'll just ask you this. Have you considered allowing some of these people permanently banned back on with some restrictions? Maybe you can only tweet twice per day, maybe you can't retweet or something to that effect.

Speaker 6:          02:32:21       I think we're very early in our thinking here, so we're, we're open minded to how to do this. I think we agree philosophically that permanent bands aren't extreme case scenario and it shouldn't be one of our, you know, regular use tools in our tool chest. So how we do that I think is something that we're actively talking about today. Is there a timeline that we can, so, so look in all, I think dad would fix a lot of problems. You think so? Yes. I really do. Like, I'm just curious like are you thinking like bands of a year or five years, 10 years? I'm just curious like what is, what is a reasonable ban in this kind of context? I think reasonably so much enough to state their case as to why they want to be unbanned. Like someone should have to have a, uh, like a well measured, considerate response to what they did wrong. Did, do they agree with what they did wrong? Maybe perhaps saying why they don't think they did anything wrong and you could review it from there.

Speaker 4:          02:33:12       Hmm. I think, um, you know, one of the challenges, we have the benefit in English common law of hundreds of years of precedent and developing new rules and figuring out what works and doesn't, Twitter is very different. So I think with the technology, I don't know if you need permanent bands or even, or even suspensions at all, you could literally just, uh, I mean, lock someone's account is essentially suspending them. But, uh, I, I again, I wouldn't claim to know anything about the things you go through, but what if you just restricted most of what they could say? You know, you block certain words in a certain dictionary. If someone's been, if someone was greased hill open, no, but, but, but the thing about it this way, is it better that they're permanently banned or it sounds better but it's not, it's not good. I don't know to think about it this way. Instead of being suspended for 72 hours, you get a dictionary block from hate speech words. Right. Does that not make sense? People

Speaker 6:          02:33:59       just use kind of language. This is what we see all the time. Yeah, I don't, well they could move. What do you, what do you think about perhaps instead of w w w w is it possible to have levels of Twitter, like a completely uncensored unmoderated level of Twitter and then you know, have like a rated r and then have like a

Speaker 3:          02:34:17       PG 13 yeah, I mean I don't think that's a bad idea. We, we have those levels in place today, but you don't really see them. One, we have a not safe for work switch, which you can turn on or off. Oh really? And let's say for work switch off. Joe, do you think so based on what you're seeing, you know it's there. So we have that and then as victor pointed out earlier, you know, we have the timeline. We'd, we started ranking the timeline, uh, about three years ago. We enabled people today to turn that off completely and see, you know, the reverse cron of everything they follow. You can, you can imagine a world where that switch has a lot more power over more of our algorithms throughout more of the surface areas. You can imagine that. So these are all the questions that are on the table.

Speaker 3:          02:35:05       Yes. About timeline. And this is, this is a challenging one. I don't know about timeline because first we, we've decided that our priority right now is going to be on proactively enforcing a lot of this content specifically around anything that impacts physical safety, like, like doxing. So bright. But there's so many examples of what you guys not doing that I, I know, but that, that's what we, that's what we're fixing right now. That's a privatization. We think more in terms of milestones and the particular timeline. We're going to move as fast as we can, but some of it's a function of our, of our infrastructure, of the technology we have to, we have to bring to bear. Do you guys have conversations about trying to shift the public perception of having this left wing bias? Maybe possibly addressing it? Yeah. All right, well that's what they're doing right now, right?

Speaker 3:          02:35:56       Yeah. I mean I went on the Sean Hannity show. I, you know, we, we, how was that we brought ourselves before. It was pretty a lot of sunlight. It was short and he, well it was short and um, there run a lot of really tough questions and that was a feedback as well. And I, I get it. Like, look again, I'm also, I'm from Missouri. My Dad is a Republican. He listened to Hannity, he listened to rush Limbaugh. My mom was a democrat. And I feel extremely fortunate that I was able to first see that spectrum, but also feel safe enough to express my own point of view. But when I go on some of them like Hannity, I'm not talking to entity, I'm talking to people like my dad who listened to him. And I want to get across how we think and, and also that our thinking evolves.

Speaker 3:          02:36:41       And here's the challenges we're seeing. And like, this is our intent. This is what we're trying to protect. And we're, we're gonna make some mistakes along the way and we're going to admit to them we didn't admit to them in the past week and middle to a lot more, uh, over over the past three years. Um, but, you know, I, I don't know any other way to address some of these issues. It all, it all goes back to trust. Like our, one of our core operating principles is earning trust. How do we earn more trust? And I, you know, the people in the world who do not trust us at all. And there are some people who trust us a little bit more, but this is the thing that want to measure this

Speaker 4:          02:37:16       the thing that we want to get better at. I saw you get a conversation with I think Katie Hertzog no, no, no. Who was it that was the wrong person you had, you had a Twitter conversation with Kara. Kara Swisher. Wow. Wrong person, but someone got got shut up. Uh, and, and you know, I I see that the left goes at you in the opposite direction. They want more, they want more banning, they want more restrictions. And then looked at the, the right is saying less. Right. So I mean in terms of solving the problem, tell us what their conversation was about. Uh, I do you want to summarize cause it, cause my, the thing I was pointing out specifically was that you were being asked to do more in terms of controlling, it wasn't just more, but to be a lot more specific about what actions we've taken to promote more health on the platform.

Speaker 4:          02:37:56       Like, what products did we change? What policies did we introduce in the past two years? Um, uh, so she was asking questions. Every question she asked. She wanted me to be a lot more specific and some of these things have something that is a very specific, some are directional right now because like we, we have to prioritize, you know, the, the direction and, and I talked about like, you know, we've decided that physical safety is going to be a priority for us. And to us that means like being a whole lot more proactive around things like toxin. So two suggestions, I guess I'm not going to imply that you have unlimited funding, but we did mention the peer review. Dot. Right? Right. And you had the, you mentioned earlier with layoffs and retraction, uh, peer review, which we mentioned, but have you considered opening an office, even a small one for trust and safety in an area that's not predominantly blue so that at least you have, like you can have some pushback is what is learned to code mean and then they could tell you.

Speaker 2:          02:38:52       Absolutely. So that, that's, uh, that's great feedback. And just so you know, the trust and safety team is also global team and the enforcement team isn't global team. So it's not like people from California who are looking at everything making decisions there are global. Now I hear your point about who trains them in the materials they have and all that. And like we have to think about that. And um, that's, that's one thing that Jack has really been pushing us to think about is how do we decentralize our workforce? Because out of San Francisco in particular, so this is something he's very focused on.

Speaker 4:          02:39:20       What about publishing evidence of wrongdoing in a banning? So when people say, you know, what did Alex Jones really do? Maybe a lot of people didn't realize what you, what you saw.

Speaker 2:          02:39:29       And again, it's an issue of trust. Yeah, I love this, Tim. I'm a lawyer. So by training, um, we're thinking of doing something called, we call case studies, but essentially like this is our case law. This is what we use. And so on high profile cases, cases, people ask us about like to actually publish this so that we can go through, you know, tweet by tweet just like this. Because I think a lot of people just don't understand and they don't believe us when we're saying these things. So to put that out there so people can see it, and again, they may disagree with the calls that we're making, but we at least want them to see why we're making these calls, I think. And that that I do want to do. I want to at least start that by the end of this year.

Speaker 4:          02:40:05       So I, I think, you know, ultimately my main criticism stands and I don't see a solution to in that Twitter is an unelected, you know, unaccountable as far as I'm concerned. When it comes to public discourse, you have rules that are very clearly at odds as we discussed. I don't see a solution to that. And I think in my opinion, we can have this kind of like we've tone things down. We've had some interesting conversations, but ultimately, unless you're willing to allow people to just speak, speak entirely freely, you are in, uh, we have an unelected group with a near monopoly on public discourse in many capacities. And I understand it's not everything. It is big too and it's, you know, what I see is you are going to dictate policy whether you realize it or not, and that's going to terrify people and it's going to make violence happen.

Speaker 4:          02:40:46       It's gonna make things worse. You know, the, the, I hate bringing up this example on the, on the rule from mis-gendering because I'm actually, I understand it and I can agree with it to a certain extent. Um, and I've, you know, um, nothing but we're nothing but respect for the trans community. But I also recognize we've seen an escalation in street violence. We see a continually a disenfranchised large faction of individual in his country. We then see only one of those factions band. We then see a massive multinational billion dollar corporation with private and foreign investors. And it looks to me like if you hold, if you know, foreign governments are trying to manipulate us there. I don't, I don't see a direct solution to that problem that you do have political views, you do enforce them. And that means that Americans who are abiding by American ruler being excised from political discourse and that's the future. That's it.

Speaker 3:          02:41:32       Yeah. We, we do have views on, on the approach and, and again, uh, we, we ground this in creating as much opportunity as possible for the largest number of people. Right? That's where it starts and where we are today. Um, we'll certainly evolve but like that, that is what we are trying to base our, our rules and judgments not, and I get that. That's an ideology. I completely understand it. But we, we also have to, we also have to be free to experiment with solutions and experiment with evolving policy and putting something out there that might look right at the time and evolving. I'm not saying this is it, but like we, we look to research, we look to our experience and data on the platform and, and we make a call and if we get it wrong, we're, we're going to admit it and we're, we're going to evolve it.

Speaker 4:          02:42:28       But I guess, do you, uh, do you understand my point? I understand the point that there are, there are American citizens abiding by the law who have a right to speak and be involved in public discourse that you have decided aren't allowed to.

Speaker 3:          02:42:38       Yeah. And, and I think we've discussed, um, like we, we, we don't see that as a win a win

Speaker 6:          02:42:45       as not promoting health ultimately over time. Right. But is ultimately what is your priority? Do you have it prioritized in terms of what you got w what you guys would like to change? I think Jack has said it a couple of times, but the first thing we're going to do is prioritize people's physical safety because that's gotta be, you already have done that pretty much, right? When you do that more, we've prioritized it. Okay. We're doing the work. I don't think companies like ours make the link enough.

Speaker 3:          02:43:12       But what does he mean online and offline ramifications? What's the main criticism? What's the main criticism you guys, is it censorship that you guys experience? Is it censorship is a banning, like what does it, what ends? What do you get that at most? It depends on who. Every single person has a different criticisms. So I don't think there's a universal opinion. I mean you just painted the picture right between like the, the, the left end of the spectrum is asking for more. Sure. And the right is asking for less at, that's very simplified just for this country, but at a high level. Yeah, that's consistent.

Speaker 4:          02:43:42       I mean, my opinion would be, as much as I, I don't, I don't like a lot of what people say about me, what they do. The rules you've enforced on Twitter have done nothing to stop harassment towards me or anyone else. Right. I swear to God my Twitter, I mean my reddit is probably, you know, 50 messages from various, you know, far left and left wing sub reddits lying about me. It calling me horrible names, quote, tweeting me and these people are blocked, right? And I, and I never used to block people because I thought it was silly because they can get around it anyway. But I decided to at one point, because out of sight, out of mind, if they see my tweets last, they'll probably interact with me last. But they do this and they lie about what I believe. They lie about what I stand for and they're trying to destroy everything about me and they do this to other people.

Speaker 4:          02:44:20       I recognize that. So ultimately I say, well, what can you do? It's going to happen. I'm one of these platforms. The Internet is a thing, as they say on the Internet, welcome to the Internet. So you know, to me, I see Twitter trying to enforce all these rules to, to maximize good. And all you end up doing is stripping people from the platform, putting them in dark corners of the web where they get worse. And then you don't actually solve the respite problem. Really targeted dark corner of the web. Right? Right. No, I'm not talking to, but there are dark corners of reddit. There are alternatives. I mean the Internet isn't gonna go away and people have found alternatives. And here's the other thing that's really disconcerting. We can see a trend among all of these different big silicon valley tech companies. Uh, they, they hold a similar view to you guys.

Speaker 4:          02:44:59       They banned similar ideology and they're creating a parallel society. You've got alternative social networks popping up that are taking the dregs of the, of the mainstream and give them a place to flourish, grow, make money. Now we're seeing people be banned from mastercard, from band, from paypal, even banned from chase bank because they all hold the same similar ideology to you. Oh, it's, it's, you know, in some capacities, uh, I don't know exactly why chase does it. I assume it's because you'll get some activists who alive. When we were talking about there've been a series of individuals band from chase bank accounts have been, yes, their accounts were closed. I think maybe the most notable might be Martina Marketta. I don't know much about her. I follow her on Twitter and their tweets are typical conservative, fair. And she created a comic, I think it's called lady alchemy.

Speaker 4:          02:45:43       She's a Trump supporter and she got a notice that her business account was terminated. You then have Joe Biggs who previously worked with Info wars. I don't know much about this. I didn't follow up, but he tweeted out, chases shattered my account. And then you have the new chairman of the proud boys and reggae. I forgot his last name. Tario or something. And so I was really white. Oh no, he's a, he's Afro Cuban. I know. That's what's the letter. But I, you know, so, so what, what I see across the board, it's not just, and it's what I wanted to bring up before about your perspective on these things. You guys are like, we're going to do this one thing and no snowflake blamed itself for the avalanche. But now what do we have? We have conservatives being stripped from paypal. We have certain, I'll just say individual strip from paypal, patrion financing.

Speaker 4:          02:46:25       So they set up alternatives. Now we're seeing people who have, like you mentioned, Westboro Baptist Church, and she's been deradicalized by being on the platform. But now we have people who are being radicalized by being pushed into the dark corners and they're building and they're getting, they're growing and they're growing because there's this, this idea that you can control this and you can't, you know, uh, I think you mentioned earlier that there are studies showing and also counter studies, but people exposed to each other is better. I found something really interesting and because I have most at whether or not people want to believe that's all of my friends are on the left and some of them are even like socialists. And they're absolutely terrified to say to talk because they know they'll get attacked by the people who call for censorship and try to get him fired.

Speaker 4:          02:47:07       And when I talked to them, I was talking to a friend of mine in La and she said, is there a reason to vote for Trump? And I explained a very simple thing about Trump supporters. This was back in 2016 and I said, oh, well, you know, you've got a lot of people who are concerned about the free trade agreements sending jobs overseas. So they don't know much about Trump, but they're gonna vote for him because he supported that and so did Bernie. And then the response is really, I didn't know that. And so you have this, this ever expanding narrative that Trump supporters are Nazis and the Maga hat is the KKK hood. And a lot of this rhetoric, you know, emerges on Twitter. But when, when a lot of these people are getting excised, then you can't actually meet these people and see that they're actually people. And they may be mean. They may be mean people, they may be awful people, but they're still people. And even if they have bad opinions, sometimes you actually, I think in most instances you find the regular people,

Speaker 1:          02:47:53       well, there's a part of the problem of calling for censorship and banning people in that it is sometimes effective and that people don't want to be thought of as being racist or in support of racism were in support of nationalism or any of these horrible things. So you feel like if you support these Banning's you support positive discourse in a good society and all these different things, what you don't realize is what you're saying is that this does create these dark corners of the web and these other social media platforms evolve and have farm. It mean when you're talking about bubbles and about these, uh, the, these group think bubbles, the worst kind of group think bubbles is a bunch of hateful people that get together and decide their posts. They've been persecuted instead of, like we were talking about with Megan Phelps having an opportunity to maybe reshaped their views by having discourse with people who choose to, or not choose to engage with them.

Speaker 4:          02:48:47       Well, let's, let's think about the, the logical end of where this is all going. You want healthier conversation, so you're willing to get rid of some people who then feel persecuted and have no choice but to band together with others. Mastercard, chase, Patrion, they all do it. Facebook does it. They're growing. These platforms are growing. They're getting more users, they're expanding, they're showing up in real life and they're there. You know, even these people who are band aren't the Neo Nazi evil. They're just regular people who have banded together that forms a parallel finance system, a parallel economy. You've got Patriot alternatives emerging where people are saying, you know, we, we reject you and now I want a platform where people say the most ridiculous things. Now

Speaker 1:          02:49:22       money normalizes that as well. That's also, that's what I mean by parallel society. To them, everything they're doing is just and right, and you can't stop them anymore and it develops hate for the opposing viewpoint. You Start Hating people that are progressive because these are the people that, like you and I have talked about the data and society report that labeled us as all right, adjacent or whatever. Now more fake news coming out about it. Right? So that's connected because you and I have talked to people that are a on the ride or far right, that somehow or another were secretly far right and that there's this influence network of people together and says fake. Well, it's, it's a schizophrenia connection. That's one of those weird things where people draw a circle. Oh, you talked to this guy and this guy talked to that guy, therefore you know that. Yeah.

Speaker 4:          02:50:04       Well, so, so, so here's a, an expanded part of this problem. Uh, so this, this, you're probably not familiar, but a group called data and society published what's entirely fake report labeling 81 alt-right adjacent or wherever they want to call it, youtube channels included Joe Rogan and me. It's fake. But you know what a couple dozen news outlets wrote about it as if it was fact. You believe the proud boys were labeled as Fba. Uh, by the FBI's extremists when they actually weren't, it was a sheriff's report from someone not affiliate with the FBI, but they are activists within media who have an agenda. And we, we saw this with learn to code. It was an NBC reporter who very clearly is in, you know, left wing identitarian writing a story for NBC. Then your average American sees that NBC story thinks it's factual. Then everyone talks about it.

Speaker 4:          02:50:45       Then your people hear about it. Then you start banning people. So you know, the, I guess to drive the point home, the snowflake one blame itself for the avalanche. You guys are doing what you think is right. So is Facebook, youtube, patriot, all these, all these platforms and it's all going to result in one thing. It's going to result in groups like Patriot prayer on the proud boys sang. I refuse to back down showing up. It's gonna result an Antifa showing up. It's going to result in more extremism. You've got an Antifa count that published the home addresses and phone numbers that hasn't been banned. That's going to further show conservatives that the, the p, the policing is asymmetrical. Whether, you know, it is or isn't. And I think the only outcome to this on the current course of action is like insurgency. We've seen people planting bombs in Houston, tried to blow up a statue.

Speaker 4:          02:51:28       We saw someone plant a bomb at a police station and Eugene, Oregon, two weeks before that, a guy showed up with a gun and fired two rounds at a cop wearing a smash the patriarchy and she'll share. So you know, so, so that happens. Then a week later they say you killed our comrade. Then a week later Obama's planted, I don't believe it's a coincidence. Maybe it is, but I lived in New York. I got out too many people knew who I was and there was people sending me emails with threats and I'm like, this is escalating. You know, we've seen throughout the past years with Trump, we've seen, um, Breitbart has a list of 640 instances of Trump supporters being physically attacked or harassed in some way. There was a story the other day about an 81 year old man who was attacked and it seems like everything's flowing in one direction and nobody wants take responsibility and say maybe we're doing something wrong. Right. This is why that, that's why I brought up earlier regulation as a, in my opinion, inevitable.

Speaker 3:          02:52:15       Yeah, I mean I, I don't think it's going to be the responsibility of any one company. We, we have a desire and need to be clear that we have a desire to promote health and in public conversation and as we've said, like I, I don't think over time a permanent ban promotes health. I, I, I don't, but we have, we have to, we have to get there. There are exceptions to the rule of course, but like we, we, we, we just have work to do and I, I had the benefit of conversations like this is, we're talking about it more, but the people will naturally call us out. Like you got to, you got to show it as well. Do you fear regulation? I don't, I don't fear regulation. If, if we're talking about regulation in the government, intervention in the job of if a regular job is to protect the individual and make sure that they level the playing field and they're not pushed by any particular special interest, like companies like ours who might, you know, uh, PR work with irregular to protect our own interest, that I think is incorrect.

Speaker 3:          02:53:19       I agree that we should have, um, an agency that can help us protect the, protect the individual and level the playing field I had. So I think oftentimes companies see themselves as reacting to regulation. I think we need to take more of an education role. So I don't fear it. I want to make sure that we're educating regulators on what's possible, what we're seeing and where we could go. When you say educating regulators, that's initiating irregulation [inaudible] not necessarily. I mean there we might just be Todd Keating regulators who are these regulators. These are folks who, who might be tasked with coming up with a proposal for particular legislation or laws, um, to present to, um, uh, legislators. So it's making sure that we are educating to the best of our ability. This is what we are, this is what we see, this is where technology is going.

Speaker 3:          02:54:13       And do you think you can hold off regulation now, do you think that by these approaches and by being proactive and by taking a standard, perhaps offering up a road to redemption to these people and making clear distinctions between what you're, what you're allowing, what you're not allowing, you can hold off regulation or do you disagree with what he's saying about regularly? No, I don't believe that should be. Our goal is to hold off regulation. I believe we should be, we should participate like any other citizen, whether it be a corporate citizen or an individual citizen in helping to guide the right regulation.

Speaker 4:          02:54:45       So, uh, are you familiar, and I could be wrong on this because it's been like 15 years since I've done this. Are you familiar with the clean water restoration act at all? I don't expect you to be. It's a very specific thing. So, uh, it was at some point in like the early seventies there was a river in Ohio, and again, I could be wrong, it's been 15 years. I used to work for an environmental organization, started on fire. And what was typically told to us was that all of these different companies said we're doing the right thing. But like as I mentioned, the snowflake doesn't blame itself. So over time the river was so polluted it became sludge and lit on fire. And so someone said, if all of these companies think they're doing the right thing and they've all just contributed to this nightmare, we need to tell them blanket regulation.

Speaker 4:          02:55:25       And so what I see with these companies, like banking institutions, public discourse platforms via distribution, I actually, I'm really worried about what regulation will look like because I think the government is going to screw everything up, but I think there's going to be a recoil of a, at first I think the Republicans, because I watched the testimony you had in Congress and I thought they had no idea what they're talking about, nor did they care. There was like a couple of people who make good points, but for the most part they were like, I don't whatever, and asked about Russia and stuff. So they have no idea what's going on. But there will come a time when you know, for instance, one of the, one of the great things they brought up was that by default when someone in DC signs up, they see way more Democrats than Republicans.

Speaker 4:          02:56:01       Right. You, you remember that when you testified? Yeah. So, well that there's an issue and I don't think I, I believe you when you say it's Algorithmic, that these are, you know, prominent individuals. So they get automatically recommended. But then there, so again, the solution to that, like how do you regulate a programmer to create an algorithm to solve that problem is, is it's crazy you're regulating someone to invent a technology. But I feel like there'll be a backlash when too many, right now we're seeing the reason, one of the reasons we're having this conversation is that conservatives feel like they're being persecuted and repressed. So then it's going to escalate from, it's not going to stop with these conversations.

Speaker 2:          02:56:34       And so that we're, we've been having a lot of talks about this particularly around algorithms. And, um, one of the things that we are only focused on is not just fairness in outcomes but also explainability of algorithms. And I know Jackie, you love this stuff, so I don't know if you want to talk a little bit about our work there.

Speaker 5:          02:56:47       You know what I mean? We, um, so there's two fields of research within artificial intelligence or rather new, but I think really impactful for our industry. One is fairness and ml. So you're guessing what fairness and machine learning, like learning and deep learning. So looking at everything from what data set is fed to an algorithm. So like the training data set all the way to how the algorithm actually behaves on that, on that data set, making sure that it, it does not develop bias over the launch at longevity of the algorithms use case. So that's one area that we want to lead in. And we've been working with some of the leading researchers in the industry to do that because the reality is a lot of this human judgment is moving algorithms. And the second issue with it moving now rhythms is algorithms today can't necessarily explain the decision making criteria that they use so they can't explain. And the way that you make a decision, you explained why you make that decision. Algorithms today are not being programmed in such a way that they can even explain that you may wear an Apple Watch for instance. It might tell you to stand every now and then. Um, right now those algorithms can't explain why, why they're doing that, right? That, that's a bad example

Speaker 3:          02:58:02       cause he does it every food, every 50 minutes. But, um, as we offload more and more of these decisions both internally and also individually two watches and two cars and whatnot, there, there was no, uh, there's no ability right now for that algorithm to actually go through and list out the criteria used to make that decision. So this is another area that we'd like to get really good at if we want to continue to be transparent around our actions, because a lot of these things are just black boxes and they're being built in that way because there's been no research into like, well how do we get these algorithms to explain what their decision is? That question hasn't been asked.

Speaker 4:          02:58:39       My fear is it's technology that you need to build, but the, the public discourse is there. We know that foreign governments are doing this. We know that democratic operatives in Alabama did this. And so I imagine that, you know, with Donald Trump, I, I, you know, he talked about an executive order for free speech on college campuses so that the, the chattering is here. Someone's going to take a sledgehammer to Twitter, to Facebook, to youtube and just be alike for not understanding the technology behind it, not willing to give you the benefit of the benefit of the doubt and just saying, I don't care why you're doing it. We are mad. You know what I mean? And then pass some bells and, and then it's over again. Clarifying, I, I think you guys are biased and I think what you're doing is dangerous, but I think that doesn't matter. It doesn't matter what you think is right. It matters that all of these companies are doing similar things and it's, and it's, and it's already terrifying people. I mean, look, when, when I saw somebody got banned from their bank account, that's terrifying. And paypal has done this for a long time, you know,

Speaker 1:          02:59:33       seems like more grievous than being banned from any social justice or social media platform that that seems to me to be worthy of

Speaker 4:          02:59:43       boycott Patriot patriot and issued a statement about a man, I believe his name is Robert Spencer and they said mastercard instructed us to ban him. And you know what? You know, I'll say this to me mentioning chase, paypal, mastercard terrifies me. I'm on the Joe Rogan podcast right now, calling out these big companies in defiance.

Speaker 1:          03:00:00       I would like to know all the specifics of why they chose to do that. And I would hope that they would release some sort of a statement explaining why they chose to do that. Maybe there's something we don't know.

Speaker 4:          03:00:08       There was a, there was a reporter, and I could be in this wrong because I didn't follow it very much with big league politics. Who said that after reporting on paypal negatively they banned him. That's terrifying. So less reporting on it. In what way? Like reporting on the saga. A issue. No, apparently is a journalist. He wrote about something bad pay pal did league politics is conservative and so all of a sudden he got a notification that they can't tell them why, but he's gone. So I see these big tech monopolies. I see youtube, Facebook, Twitter, I see paypal, mastercard and they're doing it and they all say they're doing the right thing. But all of these little things they're doing are adding up to something nightmarish and some legislators going to show up and in a matter of time with a sledgehammer and just he's in whack. Your Algorithm.

Speaker 1:          03:00:48       Well, it's really the same stupid logic where I was talking about were, you know Gavin was saying punch people. When you punch people, it doesn't end there. Oh yeah. The Punch man banned them and it doesn't end there. It doesn't end there. You give to realize also,

Speaker 4:          03:01:01       uh, Twitter is how old now? 11 years old. 12 years old. 13 years old, 13 years old. Well, 13 years from now. What are the odds that there's not going to be something else? Just like it? Well, pretty slim. Uh, how we do collect a million, no, but let's, let's, let's talk about the incestuous relationship that a lot of these journalists have been defending the policies you guys push. Gab It was, was, was a, a study was done. I talked about this last time where they found 5% of the tweet of the, I don't wanna say tweets, but the post on Gab where hate speech compared to Twitter's like 2.4. So it's a marginal increase yet gab is called the white supremacy network. Of course you go on it and yeah, absolutely exists. They say that synagogue shooter. Oh, he was a gap user. He was a Twitter user too.

Speaker 4:          03:01:40       He posted on Twitter all the time. So why the media is targeting, it's, it's such a crazy nightmarish reality. It is active narrative. And when the Guardian, uh, I believe it was the Daily Mail called Count Danky law and Nazi hate criminal. It's like really made a joke on youtube and he's being, he was arrested. Um, I thank God every day we have the first amendment in this country. Well there's a cover of a newspaper that was cause he got a new job somewhere they get, he got fired for that. He got kicked off the show. Wow. Yeah. That's so, so you have cause of trying again. Let me ask you another thing. Do you guys, do you guys take the advice of the southern poverty law center?

Speaker 4:          03:02:14       Do we take the advice of like, so it's, it's widely circulated, the SPLC lobbies, various social platforms to ban certain people. They advise. Uh, it's an important, they advised youtube as, as the Anti Defamation League. Do you use them in your decision making process? It rule development. We're very aware of the flaws with certain of their research and we're very careful about who we take advice from. But do you take advice from them? I think that they have certainly reached out to our team members, but there's certainly nothing definitive that we take from them. We don't take action. You'll never take an action based on the information received from them. The reason I bring that up specifically is that they're cited often, you know, in the United States, there's other groups like a hope not hate in the UK and now they're all going to point their, you know, figurative guns at me for saying this.

Speaker 4:          03:02:56       But the southern poverty law center, uh, wrote an article where they claimed I went to Iran for a Holocaust deniers conference and I've never been to Iran. And their evidence was this guy found an archived website from a Holocaust denier with my name on it. And that was their proof. And there are people who have been labeled, you know, extremist by this organization that have been Sam Harris. Sam Harris was started with, yeah, I mean it didn't, they lose a big lawsuit they settled on. Yeah. So, so again, like not, not to imply that you guys do use it, but I asked specifically because it's been reported, other organizations do. So we have activist organizations, we have journalists that I can attest to our APP, absolutely activists, cause I've worked for, I worked for vice, I worked for a fusion. I was told, uh, it implicitly not explicitly to lie to side with the audience as it were.

Speaker 4:          03:03:41       I've seen the narratives they push and I've had conversations with people that I'm not going to, I'm going to keep relatively off the record. Journalists who are terrified because they said the narrative is real. Right? One journalist in particular said that he had read, he had evidence of, you know, essentially he had reason to believe there was a wrongdoing. But if he talks about it, he could lose his job. And there, there was a journalist who reported to me that data and society admitted their report was, was, was, was uh, incorrect. And now you've got organizations lobbying for terminating Joe and I because of this stuff. So this, this narrative persists. Then you see all the actions I mentioned before and all the organizations saying we're doing the right thing. And I got to say like we're living in, I mean, I feel like we're looking at the doorway to the nightmare dystopia of, yeah, I, I, I just want to clarify like, uh, I don't, I don't know if we're going around and saying we're, we're necessarily doing the right thing.

Speaker 4:          03:04:33       We're saying why we're doing what we're doing. Right? Right. That's what we need to get better at. And I, I don't want to hide behind what we believe is like the right thing. We have to clearly rationalize why we're making the decision we're making and more of that. That's, that to me is the prevention from this snowflake avalanche metaphor. Well, but, but I think it's just obvious to point out, again, I said this before, we can have the calm conversation and I can understand you, but for I'm from where I'm sitting, you hold a vastly different ideology than I do and you have substantially more power and controlling my government. That terrifies me. And what's my, what makes it worse is that a Saudi prince, as lace was reported that decided prints owns a portion of that company. So I'm sitting here like just a little American, can't do anything to stop it.

Speaker 4:          03:05:18       I'm just watching this unaccountable machine churn away and you're just one snowflake in an avalanche. All these other companies are as well. And I'm like, well here we go. This is going to be a ride. The other ones, just as if it just said that Saudi princes and have any influence, but am I supposed to trust that that's the, that's the issue, right? I'm not, I'm not trying to insinuate he showing up to your meetings and telling you what to do, but when someone dumps $1 billion a year company, I think it's silly to, to imply that they don't at least have some influence. But, but regardless, and unlike the Internet within a company like ours, you don't necessarily see the protocol. You don't see the, the, the processes. And, and that's just an area where we can do a little much later, I guess, you know, beat it over the head a million times.

Speaker 4:          03:05:54       It'd be the dead horse. I think ultimately, yeah, I get what you're doing. I think it's wrong. I think it's terrifying and I think we're looking, we're slow. We're on the avalanche already. It's happened. And where we're heading down to this nightmare scenario of the future where it terrifies me when I see people who claim to be supporting liberal ideology, burning signs that say free speech, threatening violence against other people. You have these journalists who do the same thing. They accuse everybody of being a Nazi, everybody of being a fascist Joe Rogan, and you're like, you're like a socialist. As far as I know. You're like ubi proponent, you know? I wouldn't necessarily say I'm very, I'm being facetious. I'm being crazy liberal and except for second amendment, that's probably the only thing that I disagree with a lot of liberals. And then you see what the media says about everybody.

Speaker 4:          03:06:34       You see how they called Jordan Peterson all day and night. Alt right. The alt right hates him. And this narrative is used to strip people of their income to, to remove them from public discourse. And it looks foolish because it, it Neil ultimately upon examination, like you were saying that sunlight is the best disinfection. Absolutely. Upon examination, you realize that this is not true at all and that these people look foolish like the date in society article. No, no. I know all these organisations publish that as fact without looking at any data. Maybe some did, but anybody, but yeah, man and no, no, no, no. They're still talking about millions and millions of people who's, who are these people that are still siding it? Guardian will cleanse the company, start yelling shame, but so, so, so look foolish. We now have, uh, and this which makes things muddier as we now have a guy who's claiming that he did an, uh, this, you're gonna love this.

Speaker 4:          03:07:21       There's a guy claiming that the 81 accounts listed on this thing as alt right have been d are no longer being recommended on youtube. And so I looked at the, the statistics for various people on these channel because first of all, my channel is doing great. My recommendations are way up, uh, as our yours. A lot of people are growing. And I did a comparison like subscribers are up, views are up, what's this guy claiming? And apparently he did a big sampling of videos where he for some reason thought you Joe Rogan, we're 12% of all the videos in this network. And then when the, when it's data stopped working, he claimed that everything stopped. So he actually produced a graph of primarily you or your channel and then when his system stopped working he published that and it was picked up by it and now you have people claiming the alt right has been banned from, from Youtube.

Speaker 4:          03:08:06       And it's more fake news based off fake news based off fake news. I don't understand what you're saying. So, so basically there's a guy claiming that because of data and society, we have been stripped of recommendations on Youtube that you just to tell you one thing that is true though, we don't trend like Alex Jones was saying like, uh, the video we did got 9 million views, but it's not trending. And I said, well, it's because my videos never trend. They just don't trend while you're, but I think it's probably because of the language that's used. I think that's, that's part of the issue. It's the subject matter in language. I think they have a, they have a bias against swearing and, and you know, extreme topics and subjects. I don't think that's true because you've had like a late night TV hosts to talk about really messed up things.

Speaker 4:          03:08:50       They all swear, don't swear though. The, the, it's not, it's not a matter of, and what they talk about, whether that's messed up in comparison to what we talk about, it's probably pretty different. You know what, man, I'm a, I'm fairly resigned to this future happening no matter what we do about it. And so I bought a van and I'm going to convert it to us Christ. Well, I'm coming to a workstation, right? You're going to be a prepper bro. No, no, no, no, no, no, no, no, no, no, no. First of all, I will say it's hilarious to me like that people have bandaids they never use, but they don't store like at least one emergency, like food supply. It's like you never use band aids. Why do you have them? But, uh, no. I, I do. I, I see this every day. It was a couple of years ago, I said, wow, I see what's happening on social media. We're going to see violence. Boom, violence happened. I said, oh, it's going to escalate. Someone's gonna kill. Boom. Charlottesville happened and it's like, I, I've, there have been statements from foreign security advisors, international security experts saying we're facing down high probability of civil war. And I know it sounds crazy. It's not going to look like what you think it looks like. It may not be as extreme as it wasn't 18 hundreds but this was, I think, I think it was in the Atlantic where they surveyed something like 10 different international security

Speaker 7:          03:09:54       experts who said, based on what the platforms are doing based on how the people are responding. One Guy said it was like 90% chance, but the average was really high. Well, let's, let's look outside of the idea of physical war and let's look at the war of information. What we're talking about, what's happening with foreign entities invading social media platforms and trying to influence our elections and our democracy. That is a war of information. That is, that war is already going on. If you're looking at something like data and society, that's sort of an act of war in that regard, right? It's a, it's an information war. An attempt to, to lie to people, to step out there, there their ideological opponents and it's also one of the woman who wrote that said that it's been proven over and over again. The D platforming is an effective way to silence and then called for us to be men.

Speaker 7:          03:10:40       It's kind of hilarious. I don't think she was saying that we should be banned. I don't think she said, well she should be. She said something to the effect of Youtube has to take action to prevent this from, you know, well you know, but people see someone saying things that they don't agree with. It's very important for people to understand where silencing people leads to. And I don't think they do. I think people have these very simplistic ideologies and these very, very narrow minded perceptions of what is good and what is wrong. And I think, and I've been saying this over and over again, but I think it's one of the most important things to state. People need to learn to be reasonable. They need to be learned to be reasonable and civil discourse. Civil discourses. It's extremely important. And think over the long term. Yes. They go to the locker and understand it. You're playing chess. Yeah. Um, we did three hours and 30 minutes then when nobody had a p. Amazing. I'm proud of all of you.

Speaker 7:          03:11:33       We did start a little late. Yeah, like three 15. Okay. I mean, I guess the last thing I can say is I don't think, I think we had a good conversation. I think we did. I honestly, I don't think we felt anything. I don't think there's many, if any, do you think we could do this again, like six months and see where you guys are at in terms of like what I think is important is the road to redemption. I think that would open up a lot of doors for a lot of people to appreciate you. We're going to need more than six months, just do it. Here's the scary thing. The information travels faster than you can, right? That's the point I was making, that our culture is going to evolve faster than you can catch up to that problem because there's a problem and I don't, wow. You know, technology took a big leap. Twitter existed, the Internet existed. Now we're all talking so quickly. You can't actually solve the problem before that. People get outraged by it.

Speaker 5:          03:12:17       So no, I, I could, I mean there was an early phrase on the Internet by some of the earliest and Internet engineers and designers, which is code is law and a lot of, a lot of what companies like ours and startups and random folks who are individuals who are contributing to the Internet will change parts of society in some for the positive and some for the negative and the most, I think the most important thing that we need to do is to, as we just said, shine. I'll punch your light on it, make sure that people know where we stand and where we're trying to go and what bridges we might need to build from our current state to the future state and, and, and be open about the fact that like we're not going to, and this is do your other point. We're not going to get to a perfect answer here like it, it's, it's just going to be steps and steps and steps and steps and the fee.

Speaker 5:          03:13:16       What we need to build is agility. What we need to build is an ability to experiment very, very quickly and take in all these feedback loops that we get some feedback loops like this, um, within the numbers itself and then integrate that much faster. What's wrong with the, with the Geri system on Twitter? Why wouldn't that work? I don't know why I want to work on, I'm not saying we want to test that. Like we're testing the periscope and, and, and I don't have a reason, a compelling reason why we want to do it within Twitter either. I, I don't, so we likely will, but you know, again, we were a company of so many resources, finite resources, finite people, and we need to prioritize and we've decided you may disagree with this decision, but we've decided that physical safety and the admission of off-platform ramifications, uh, is critical for us. And we need to be able to be a lot more proactive in our enforcement, uh, which will lead to stronger answers. And we want, we want to focus on the physical safety aspect. And doxing is a perfect example that has patterns that are recognizable. And then we can move on.

Speaker 4:          03:14:20       I, I hear it and I just feel like, you know, the conclusion I can come from the conversation is you're going to do what you think needs to be done. I think what you're doing is wrong and ultimately nothing's going to change. I got it. You're going to, you're going to try new technologies. You're going to try and do it systems from the, from where I see it, I think you have an ideology diametrically opposed to mine. I mean, not to an extreme degree. I think there are people who are more like, I'm not conservative. There are a lot of people who are, who are probably think, you know, I'll, I'll say this too. You're a symbol for a lot of them and so I can definitely respect you having a conversation. There are so many different companies that do things that piss people off. You sitting here right now, I'm sure there's a ton of conservatives who are you pointing all of their anger and you because you are here, but you know, ultimately I just feel like, I don't think anything's going to change. I think you're on your path, you know what you need to do and you're trying to justify it and I'm looking at what Twitter is doing as very wrong and it's, it's, it's uh, oppressive and ideologically driven and I'm trying to justify why you shouldn't do it, but nothing's going to change

Speaker 5:          03:15:18       mine. My intention is to build a platform that gives as many people as possible opportunity to freely express themselves

Speaker 1:          03:15:25       and some people believe the United States has already done that and Twitter is now going against what the u s has developed over hundreds of years. This is called have a platform. I mean the United States doesn't have a platform to do that. Twitter is when you're talking about the Internet, the United States, if they want to come up with the United States Twitter, like a, a solution on alternative that the government runs and they use it, use free speech to govern that. Good luck. Good luck with that.

Speaker 7:          03:15:50       Well, it's a h institutes challenge and also I recognize not just, you know, almost insurmountable. I mean the have the dummies that are in charge of the United States government. This is why I said regulation to is scary. Yeah, that's a terrible idea. But so, but you know, and I, I think it's important to point out too that a lot of people don't realize, you guys have to contend with profits. You have to be able to make money to pay your staff. There's no, like you don't get free money to run your company. So aside from the fact that you have advertisers want to be in the platform, I imagine a lot of these companies are enforcing hate speech policies because advertisers don't want to be associated with certain things. So that creates, you know, through advertisement, cultural restrictions. That's 100% of the problem, right. At 100% of the problem with most of these platforms including youtube.

Speaker 7:          03:16:32       Absolutely. Yeah. I mean when the PD pie thing happened and all of these, uh, you know, restrictions came down on, on advertising and content creators, that's where it comes from. It all comes from, from money. It's why, uh, I'll let those good, just to be clear, those can be segmented as well. Second to advertisers, advertisers can choose where they went to, where they want to be placed, certainly. But the platform recognizes that there's a huge blow back and they're losing money. I mean, look at the, the, the peto scandal. It just happened on Youtube. It was people posting comments with timestamps. They weren't even breaking the rules and advertisers pull up the platform and youtube didn't realize because they weren't breaking the rules, they just creepy dudes. So maybe people also, there were putting comments and so one of the most preposterous responses to that was that content creators are going to be responsible for their comments.

Speaker 7:          03:17:20       Well, they've just turned them off. Well, the problem with the sledgehammer hammer like me is that I put out a lot of content and there's millions of views and it's impossible to moderate all the comments and we don't moderate them at all. Right. About Youtube band only on videos with minors. So they deleted all comments, videos with mine videos where they say youth, but you know what I'm saying? If you put a youtube video on, you have a bunch of people that say a bunch of racist things and your youtube comments, you could be held responsible and get a fuck. No, no, no, no, no, no. You clarified that. They clarified that one recently. They said that people words, but the first initial statement was that you were going to responsible for your comments and then they said it's only Michael like Philip to Franco.

Speaker 7:          03:18:01       And a lot of people freaked out and then they qualify then. But so the reason I bring that up is just because there's going to be things that even if you segment your advertisers from you, look, you know, I, I pointed out, I think the Democrats are in a really dangerous position because outrage culture, although it exists in all factions, is predominantly on one faction. And so when Trump comes out and says something really offensive, you know, grab 'em by the, you know what I'm talking about? The Trump supporters laugh. They bought tee shirts that said it, the people on the left, the Democrat types, they got angry. So what happens now you see Bernie Sanders, he's being dragged. The media is looking for blood and they're desperate. They're laying people off, they're dying and they will do whatever it takes to get those clicks. I there was an like, you know is I have to do with Twitter though. It has to do with the fact that someone's going to find something on your platform and they're going to call your advertiser and say,

Speaker 4:          03:18:48       look what Twitter is doing. And you're going to be like, oh, we had no idea. And then too bad and canceled all ads. Your money's dried up. And so the reason I bring that up is I recognize Twitter. Youtube, Facebook is, other platforms are worried. Money has to come from somewhere to pay people. So you also have to realize you've got the press that's salivating looking for that juicy story where they can accuse you of wrongdoing because it'll get them clicks, they'll make money. And that means even though Youtube did nothing wrong with these comments, it was just a creepy group of people who didn't break the rules, who figured out how to manipulate the system. Youtube eight like you had had to take the, take that one. The advertisers pulled out youtube lost money, so you did then panics sledgehammers comments. Just wipe them out that that can happen to anybody. Right. We're in a really dangerous time.

Speaker 1:          03:19:28       Oh. Also in their defense though, they have to deal with that. I mean they have a bunch of pedophiles that are posting comments. No, for sure. I mean what do you do about that? What do you know what other than higher millions of people to moderate every single video that's put on Youtube, which is almost impossible.

Speaker 4:          03:19:42       The point I'm trying to break bring up is that even if Twitter want it to say, you know what, we're going to have free speech. What happens? Advertisers rock later. Even if you segment it, they're going to be threatened to buy it and so the restrictions are going to come from whether or not you can make money doing it.

Speaker 1:          03:19:55       I don't know about that. I don't know. I think that that is changing and I think that is changing primarily because of the Internet. If you look at what was acceptable in terms of people discussing that would get advertisement. It was network television standards. Now that's changing. I mean there's, there's going to be, there's ads on a lot of the videos that I put out that have pretty extreme content. It's because advertisers are changing their perspective. I don't think so. They're shifting their hundred percent shifting. That's why this, this podcast has ads.

Speaker 4:          03:20:25       Sure, sure. I mean, I don't think it's to the point where everyone's lost all ads, but I look, you think George Carlan will be allowed to do his bit today?

Speaker 1:          03:20:31       Yes. No, no. Come on man. Not Right. He would be able to do it. Listen, there's stuff like that on Netflix specials that are out right now. Things are changing. It's just in the process of this transformation where people are understanding that because of the Internet first, if you look at late night conversations, how about j Cole Bear saying that President Trump has Putin's dick in his mouth. How about him saying that on television? Do you really think that would have been done 10 years ago? It wouldn't have been or 15 years ago or 20 impossible. Not Possible. [inaudible] standards are changing because of the Internet, so things that were impossible to say on network television. Just 10 years ago. You, Kevin, Kevin, Kevin Hart lost his Oscar hosting Gig because of Gi loss 10 years ago, but do you know why he lost? He lost it because people were complaining, right? Because people who were activists were complaining that he had said some homophobic things and they do it every had subsequently apologized for before they ever listened. That count count dangle as a comedian like, can I look? You were to discuss this. I know I'm with you and I understand what you're saying. I'm Canadian, but I'm a comedian and I understand where things are going. The the, the demise of free speech is greatly exaggerated. That's what I'm saying. I'm saying there's a lot of people out there that are complaining,

Speaker 7:          03:21:46       but the problem is not necessarily that there's so many people that are complaining. The problem is that people are reacting to those complaints. Right? The vast majority of the population is recognizing that there is an evolution of free speech that's occurring in our culture, in an all cultures around the world, but this is a slow process that when you're in the middle of it, it's so almost like evolution. While you're in the middle of it, you don't think anything is happening, but it's fucking happening. Yep. I agree with you. I agree with you that the majority of people are like, that's funny. I don't care. But the minority has kind of dictating things right now for now and not even dictating things. So just making a lot of that noise is having an effect. That's what data and society was an attempt at. Right. I don't think it was effective.

Speaker 7:          03:22:25       That's why we're still here. We're talking right now it was one attack, but I mean any of the, of articles that are written about all sorts of things that are inaccurate or some people have been eating your bond bank accounts and some people have been kicked off. Yes. This is why it's important to have this conversation and conversations like that. Well, so, so here's what I'll say. I just, I crossed my fingers and I wait for when you implement blockchain technology, bro. Well the van is going to be a mobile production studio so I can travel around when things are getting crazy. A lot of water. Well, food, I'm putting a bandaid so putting a shower in it. Okay. It's going to be like I'm at a computer and monitors and I'm be able to do video so I can travel around when everything's happening. But, but I just write this up. I want to see the blockchain version of Twitter where it said exists. That's what I want to see. It's going to happen whether we like it or not. Um, any last thoughts? Nope. I just want to thank you Joe. This has been great. And Tim, thanks for your [inaudible]. Thank you. We're always listening and I've learned a lot today. Thank you. I really appreciate you guys. Thank you jack. Thank you. Any last things? I think we've said it all. That's a wrap folks. No more ear beatings. Goodnight everybody.

Speaker 7:          03:23:29       That was awesome. Thank you. Right. Thank you. Thanks for talking. I really do appreciate it. Could you, I just want to followup on a couple of things

Speaker 6:          03:23:36       they worry mean you mentioned an NCF account that docs, policemen. Can you please just send the elwise slash candy but we bit dot. Ly Slash [inaudible] and then, um, would you DM me? I'll follow you. Would you DM me the, the accounts that you said had to read them? You know, uh, no. Uh, I believe in minimizing harm. And if, Aye. Aye. Aye. So, uh, when Patriot, I won't, I won't take action on it, but I want to understand why. Pick acting on him and I can't learn from that unless we, so, so, uh, when Lawrence [inaudible] got banned from patriarchy, hold on. A lot of people were, right now

Speaker 9:          03:24:19       this is streaming frozen.