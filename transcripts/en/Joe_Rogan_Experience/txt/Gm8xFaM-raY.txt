Speaker 1:          00:00:10       Sam harris, ladies and gentlemen. All right, there we go. We're live to the world. You're going to do a read fucked up. I don't do that anymore. Oh, cool. I do it before or after. Um, that way the conversation isn't garbled by five minutes of ads. Just got annoying. No, that's a good call. Yeah. Well there's two different versions of this. The one that goes up on youtube. So the one that goes on Youtube has no ads in it unless youtube puts up pants and the one that goes on podcasts or itunes rather has a, the ads. So there you go. So we could just talk. Yeah, we're good to see you. Good to see you too, man. Absolutely. It's a, it's an interesting time. I know you're at an MMA fan. Do you know about the John John's situation? I've heard rumors about it, but I don't actually know how far the misbehavior run.

Speaker 1:          00:00:54       So he got stripped of his title today or yesterday actually. They announced a new title fight between Daniel Cormier and Anthony Rumble Johnson. They will be fighting for the now vacated title. Jon Jones is likely going to jail what a. It was a hit and run crash into a pregnant woman who allegedly, I should say it broke her arm. She was rushed to the hospital, but pregnant got to be terrifying for her. We had a car crash and smashed by a guy runs a red light and then flees the scene of the crime, so he drove away. He ran away and ran away. Cars wrecked cars wrecked. You see the images of her car. I couldn't imagine unless he was driving fucking Humvee on how he could get away. It was pretty bad. Was it a dui or or that we don't know because he disappeared for like 24 hours at least.

Speaker 1:          00:01:44       Probably even more a couple of days. I think he disappeared for which, you know, obviously the speculation would be that he was on something that he would worry about getting tested for for 24 hours or 48 hours or whatever it was. That I think of how desperate to move and, and hapless and move that is to run away from the car that you're leaving in the seed, which is obviously traceable to you. It's not like we're getting out of the problem and you're leaving an injured person there to. Yeah, I mean it's a disaster, but it's worse because he actually ran back to the car stuff out of the car and then ran away again. No Man id by a cop. Right. A disaster all across the board. But not what we're here for. But I know you're an MMA fan, so. No, we have it.

Speaker 1:          00:02:26       But bringing up. Yeah. I actually have a question for you though in the close topic. Um, and we have a list of questions that we got from twitter but mcgregor or Aldo, I'm. Who knows, that's my answer is going to be interesting. It's going to be very interesting fight. We've never seen mcgregor in with anybody remotely as talented as Josie. Aldo. Not even remotely. It doesn't mean you can't win because everybody that Mcgregor has been in with, he steamrolled. He steam rolled really talented guys like Dustin ea and just he's. He's fucking good. Yeah, he's good. He's really good, really confident, and he. He really fucks with people's heads. He's so confident and so good at talking, and so there's so much charisma about him that I think it's intimidating to his opponents. I think when they get in there with him, his just overwhelming belief and belief is an incredibly powerful thing.

Speaker 1:          00:03:20       If you really, truly believe that you are the best and you say it, your opponents have to wonder because everybody's, everybody questions themselves, especially in the world of, of fighting because you know, one is if you were born a rhino, okay, and, uh, you were about to get into a fight with a parakeet, you'd absolutely be confident because you've always been a rhino and that parakeets just a parakeet that parakeets fucked. But a person is a, is a work in progress and not just from your fighting style, but your ability to manage your own mind, your ability to manage insecurities and anxieties. Just the existential angst that comes with being a human being that's navigating their way through this complicated world. There's variables, there's, there's days you're up and days you're down and then you add into that martial arts and you don't get good at martial arts unless you get your ass kicked.

Speaker 1:          00:04:15       There's only one way through. I mean you can be one of those John Jones types. It's unbelievably physically talented and have a leg up on a lot of people, but even John had to get his ass kicked. You had to. He had to. He had to compete and wrestling against guys who were better than him. He had to learn martial arts. You had a spa. I mean there's gonna be days. You're up in days, you're down. There's no way. So when you get in there with a guy like conor mcgregor to take pot hole that craziest because he's just like, fuck, this guy's overwhelming. It's like if you can put on a show like that, if you can put your peacock feathers up and and a puff up your back, heres get those bristles up nice and high like a cat when it's angry and hunch your back up.

Speaker 1:          00:04:57       Like there's a reason why that exists in nature. Well, it's beyond what Mohammed Ali used to do. She's taken it to so it's going gonna be fascinating psychologically to see him when he loses. If when, when that day comes, it will come eventually and he has lost. He's lost to a guy named Joe Duffy who's now in the UFC and he's very good. This guy, Joe Duffy is fucking very good, but he had. He lost since his rise to. No, he has not lost until you've been in the UFC and he. But in all fairness, the one style that he has not faced, which is the most difficult style, has never faced a wrestler. It was never faced a guy who can get in there and get him to the ground and outwork him and just sap his energy wrestlers. They get on top of you and you can't get them off and you get exhausted trying and they they're punching you in the face and elbow you in the face and punching you in the body and constantly trying to strangle you and then the round is up and you'd get up and the next round comes and they do it again.

Speaker 1:          00:05:56       Boom. You're on your back and boom, you're getting punched in the face. He's never faced a guy like that before. All the fighters he's faced to have chosen to stand up with him and he's a very high level boxer. He was amateur champion as a boxer. He's got very good to Jitsu skills. Very good morning ty. Good. Very good. Everything. We just never seen him against a top flight wrestler, but Aldo is not that. All those. Not that, but although is a world class Brazilian Jujitsu fighter, like people who are not aware of his ground skills. I'll go beat a guy named Cole Breena and an actual Jujitsu competition. Just very high level Breanna's world championship caliber. So Aldo is going to present him with some things inside the octagon that he's never faced before. However, although has been fighting professionally for a very long time, and I'm like a race car that doesn't ever get its tires changed or doesn't ever get it.

Speaker 1:          00:06:52       Suspension redone. Your as a human being, your body can literally only take so many miles. There's only so many times you can go to war. There's so many, so many sparring sessions you can take part in only so many wrestling sessions you can take part in. There's just a certain amount your body can take and we don't know when that number is, when when you reach that number though, that's it, and now there's no turning back unless you're using testosterone or growth hormone or some. Some things that turn your body into the superhuman sort of experiment to. Unless he's doing that, which we've seen from Vito Belfort, Vito Belfort's, the only guy who actually got better as he got older talking to my guy from UFC 12, miracle of science. It's exactly what it is. Absolutely fascinating, and you can't completely discount his training because this training is what made him better, but his ability to recover was essentially supernatural.

Speaker 1:          00:07:46       You know, he's fighting. I'm in the same car that Jones is supposed to fight. He's fighting Chris Weidman, but now Nevada has made testosterone replacement therapy illegal. So his last three performances, which are some of the best performances of his career, the knockout of Michael bisping knockout of Luke rockhold and the knockout of Dan Henderson. Those were all while he was on testosterone. So yeah. Okay. Yeah, so things get weird now. Now you see what a 37 year old man really looks like, you know, optimizing hormones as best he can naturally. Hopefully. Yeah. Well 37 sounds young. It sounds like that level of testosterone. Well, you know, it's also the, the level of testosterone have a regular 37 year old man versus the level of testosterone for someone going through a camp when you're going through those camps is absolutely brutal. Like Jon Jones and Daniel Cormier, they both got tested randomly before. They're, their um, title fight and their testosterone levels were so low. People will weren't wondering like, Hey, maybe these guys are doing something. Maybe they were doing steroids and that made their testosterone levels drop, but what's most likely it's testosterone to epitestosterone that was very low

Speaker 2:          00:08:56       testosterone levels. Most likely. It's just the brutality of training. It's so hard. It's so hard to do. You, you, you showing up everyday exhausted and your muscles are sore and your body's exhausted. You've got to go through it all again tomorrow and you're getting kicked and punched and you lifting weights and you're doing sprint and you jumping up on boxes and and then the next day all over again and your body just can't keep up, especially when you get into your thirties. Yeah. All right, well the answer that and I will watch it with interest. It's going to be very exciting. Let me know if you want to go. It's in. I, we'll talk about that. We'll talk about Sam Harris goes to the fights as a neuroscientist to disturb you at all. When you're seeing these guys getting, getting their heads rattled to you when you're. You're very aware of what's going on behind the scenes.

Speaker 2:          00:09:47       In the actual brain itself. Yeah. Well, I just, I just talked about this in my blog with this writer Jonathan Gottschall, who I told you about it at one point. I'm trying to get him on the podcast. Yeah, he's great. And um, so we had a conversation which we publish the transcript of, but he, he's got this book that the professor in the cage where he's an academic, he's an English professor and he decided to get really damn may and fight a real cage match. Um, and so it's, uh, it's interesting book and so he and I were talking about the discomfort. We have stress seeing people get brain damage in real time for our amusement. And yeah, it does make me uncomfortable, but I'm also part of what's thrilling. I mean, I, you know, I'm as thrilled by the prospect of a knockout too. It's kind of, it's not even a conscious thrill is just when, when things start going that way you feel your own, you know, testosterone or something kick in.

Speaker 2:          00:10:43       And um, but I am a, his recommendation was that, and I'm sure he's not the only person who's thought of this, he thought the gloves she'd come off and the gloves are making it, that you making it realistic to just send enlist overhand rights and other crazy punches, you know, full force into people's heads for, for, you know, 30 minutes. Whereas if you, if you were to, if it was a bare knuckle fight, you, you couldn't really be fewer knockouts but you couldn't deliver that kind of brain trauma because you'd be breaking your hands. Now obviously there are things like elbows and knees and kicks and so people would still be getting hurt. But what do you think about that? Would that change? If I'm a big advocate of that, and I've said it many times, I've said it on the air, I've talked about it on this podcast. I think it's a very unrealistic, the way you're allowed to not just put gloves on, but also wrap your hands up. Taping lists. Your risk is a joint. It flexes and when you tape it up and they get that sucker up nice and tight, then it becomes something completely unrealistic. If you punch someone with your hand without a glove on and with no hand wraps, it's way easier to hyper extend your wrist or twists or tweak or break it.

Speaker 1:          00:11:54       Your hand brakes. You hit someone in the forehead for heads are far harder than your knuckles are. Most likely you're going to break it unless you hit them on the nose and the eye on the jaw. You're, you're going to hurt your hand and you can only throw so many punches like that and even just hitting a heavy bag without being wrapped up. You just screw up your wrist and your hands. Yeah, you have to really learn how to tighten everything up and you have to really strengthen your wrist and you have to strengthen your, your, your hand muscles. It's a completely different thing, which is why the, uh, Kinda the karate students would hit a mucky water, which is a board that's wrapped with a rope. And the idea behind punching that board wrapped in rope over and over again as you develop these intense calluses all over the front two knuckles, which is really the only way you're supposed to hit someone.

Speaker 1:          00:12:37       Those are the knuckles that are reinforced by the wrist. Whereas the where the pinky finger is and the ring finger, those knuckles are not reinforced nearly as well, especially if you have a larger hands like your hand. Like my hand spreads out past my wrist. It doesn't go in a straight line from my wrist to the pinky. It actually goes out to the side so that, that, that knuckles not enforced by anything. If you punch someone with a boxing glove on with that knuckle, you're fine, right? If you punched someone with an MMA glove on, it's less supported. If you punch them on bare knuckle, you are very likely to break your hand. If you punched someone full force on the forehead and you hit the with the pinky knuckle, you're very likely to break your hand. It's a high possibility. Also, it it. It also impedes your grappling to have those gloves on.

Speaker 1:          00:13:23       Right? Garcia went to, yeah, I'm so huge issue. Marcello Garcia fought in Japan, I believe it was, had this guy's back and couldn't finish them. I was just grabbing and grabbing gloves, gloves, holding onto the gloves. The guy just worked on his defense and the gloves with a like Marcello's specialties, the rear naked choke and the rear naked choke. A big part of it is sliding your hands underneath the guy's Chin like and we have the glove there. There's all this extra padding that makes it very difficult to get your hand in the proper position to formula to get the choke right, right, right in the back of the head. It's also very difficult to get the glove and the back of the head, so a lot of times you'll see in an mma fight, guys are used poor technique and still finish the choke will.

Speaker 1:          00:14:07       They'll use their palm on the top or the back of their head because they can't do this. Can't do this movement where it's actually the back of your hand should touch the back of your opponent's head because all like to someone who doesn't understand Jujitsu, that's very complicated, but I agree with them. I think that a gloves would help a lot. Yeah. Or gloves or no gloves, right? Yeah. I think would help a lot, but I think it's also. It would be. It would be beneficial for everyone to have some intensely comprehensive scans done on a regular basis. I don't know if that would be prohibitive financially. I don't know how much that would cost. I don't know how much that would even reveal because apparently one of the things that is troublesome for

Speaker 2:          00:14:52       these nfl players is a when they die and they do autopsies on them and they revealed damage that they had no idea before mean I don't know how much like an Fmr and Mri can detect when it comes to the actual damage. Well it can, but to what end because you know you're getting it. If you're just going to be in a job where you have to get hit in the head, forget about competition. Just training, I mean these guys train hard so they're getting hit in the head to prepare them to get hit in the head, in the match.

Speaker 2:          00:15:24       You're just, you. It's not even, it's like smoking. It's like the causal linkage between getting hit in the head and brain trauma is 100 percent. It's just a matter of it's just a matter of how much you can you individually by dent of luck can take until you actually have damage that matters. Uh, so, you know, I obviously haven't had an experience anything like an MMA fighter, but I regret all the head injuries I took just training as a. Now in martial arts, I just don't let myself get hit in the head, but in, as a teenager I got hit in the head a fair amount and I played soccer and headed the soccer ball and that always felt totally weird. You know, that you had, did you play soccer? You know, he had a soccer ball. You immediately get a kind of a rusty taste in your mouth, you know, and it's just unlike anything else that happened that day.

Speaker 2:          00:16:15       Except the other time you got hit in the head, um, and he's not crazy that no one would ever think that soccer or another give you traumatic brain injury. It's because it doesn't knock you out. We have this until recently. I, I'd say like in the last couple of decades we had this erroneous assumption that you had to get a knockout. You got to get knocked out that brain damage, but she just looked thuds just a little, like I was talking to a doctor who said that water skiing can give you brain damage. Waterskiing just hitting, just the bouncing, just wave riding, you know, like that bouncing. That stuff can give you brain damage, right? Like your brain gets rattled around inside of your head, the connective tissue dislodges and it doesn't heal back. Yeah. Well, I mean, so I spoke about this with Jonathan to that there's obviously all of these sports and just, you know, forms of recreation that that entails some risk of injury and death.

Speaker 2:          00:17:11       Right? And so, and people should be able to do these things in informed of the risks. And so he, the cheerleader and the example he brought up, his cheerleader, cheerleader sometimes hit the ground and just, you know, fantastically injured. So all these things that don't necessarily seem like high testosterone, high risk, you know, you're just foolishly reckless. Sports can be very dangerous and skiing is very dangerous to and read a rock climb and they're things that are, that are even just nonviolent, that don't entail much risk of injury until they kill you. Like Free Solo rock climbing, you're climbing, everything's. Maybe you hurt your hands in the past, but then all of a sudden you're dead because you just went up 500 feet without a rope and fell. So there's all these kinds of risks that people can take. But the problem that the problem that I think differentiates striking sports from even something like football is that the progress in the sport is synonymous with the damage.

Speaker 2:          00:18:15       So you know, if you and I are are, are in a boxing match or a kickboxing match hitting each other, the every instance of successfully degrading each other's performance with respect to the head. Hitting someone in the head is synonymous with delivering injury to the brain. It's not like, it's not incidental like in football where, and I was trying to tackle you. I was not hoping to hurt your brain, but you know, you fell, fell down hard and uh, did um, this is just a trade of, of brain damage and um, yeah, so it's, it's, it's a interesting ethically, you know, I don't know. Again, I think people should be free to do it, but I think people, you know, we should be informed about it and I would, I would certainly vote to pull the gloves off and make it more. It would just make it more realistic combatively to.

Speaker 2:          00:19:05       It's insofar as you want to see what works. Combatively I'm more interested to see what two people can do just with their bare hands. Then when they've got these, you know, most certainly. And you know, one of the interesting things that has been brought up online, um, over the last couple days about this John Jones situation, is this a rational erratic behavior? Does this imply that or does it somehow or another is it, is it correlated to brain damage? I mean, it certainly can be. Can Be, right. I mean that's one of the issues with brain damage. Impulsive behavior. Yeah. Especially in the frontal lobes because your frontal lobes regulate your emotional and behavioral outbursts and when those connections, when either the cell body is or the connections between the gray matter in the frontal lobes and your, your limbic system and your basal Ganglia and in other areas in the brain when that gets damaged, yeah, you have these classic impulse control problems where you just, you know, you just reached out and grabbed the woman standing next to you at starbucks because you couldn't dampen the, the impulse to do it.

Speaker 2:          00:20:16       You know, that's hard for people to grasp because again, this should be really clear. I am without a doubt not trying to let him off the hook. What he did was horrible. If it was someone in my family that he hit with that car, I would be unbelievably furious. I'm incredibly disappointed in him. I think the UFC absolutely did the right thing in stripping him of his title and I think law enforcement is going to do the right thing by putting them in jail. I mean they're going to just. You can't do that. You can't hit someone with a car

Speaker 3:          00:20:48       and leave the scene of the crime that it is a crime, but there are things that people do because they have brain damage and that's where the real question comes up is obviously they are responsible ultimately for their own actions, but what is it that's responsible for making them do that action? And we could. We had this long conversation wants to podcasts ago. I think of bliss, about free will and determinism. These are variables that come into play when it comes to the ultimate actions that you choose to do. The ultimate movements that you choose to take. The, the, the, the, the thought processes are questionably dependent upon the brain itself. If the brain is getting damaged and if we have proven that some of the, some of the issues with people that have brain damage, his impulse control. You got to wonder, man, when you see fighters do wild crazy shit. How much of that is due to getting just bunked in the fucking head off?

Speaker 2:          00:21:51       Yeah. Yeah. Except for me that it breaks down a little differently because they, my views on free will change the picture of how I view moral culpability in those situations so that even if even if we knew his brain wasn't damaged, right? So he, let's say had never got hit in the head or we did a scan on him before the car accident and we saw, and it's the perfect scan is a scan of that we'll have 50 years from now, don't fuck ourselves up. And um, so we just know that he's got a totally healthy brain, uh, by whatever metric of health we have. But uh, he got into that situation, behaved exactly as irresponsibly as he did the, his behavior still is the result of causes that he as an agent isn't ultimately responsible for. Now, this has, has certain this as sort of the punchline, which has certain consequences, but one of the consequences is not that we can't respond to his misbehavior, that he can't, that we can't put them in jail, that we can't, that we couldn't have intervened at any point along the way to have made him a better person.

Speaker 2:          00:22:59       And it said there, there are, there are, there's a difference between voluntary and involuntary behavior, even if it's all just causally propagated from the moment of the big bang. But I do view it as, um, I think the brain damage case is a little bit of a red herring because it's on some level, it's all just Qa, unconscious causes that the, the person himself can't ultimately account for. So, you know, there are situations in which he, I'm sure in his life, behaved like a Mench, you know, behave totally responsibly. And there's situations where he behaved like this. Um, and he can't, he can't account for the difference in those two cases. He can't account for why, but let's just, it's a fact that if he had gotten one hour more sleep the night before and hadn't had a fight with his girlfriend and had his blood sugar level was a little bit higher and had, had, you know, I hadn't had a friend who had told him to drink one more beer, which he normally would have resisted but couldn't because of all the other factors I've just mentioned.

Speaker 2:          00:24:07       And that is the difference that made the difference that caused him to be this total misfit on the road. Um, whereas if you had just tweaked those dials a little bit, you know, fight with a girlfriend, one more bite of food in the morning, he would have been. He would have acted as you would have acted in that case. Say So. Ultimately, let's say that's true then that then that there's something, there's a kind of bad luck component to, to all of this creeping in and there's a concept of moral luck, which is due to the philosopher Thomas Nagel, who, who's done a lot of interesting work, half of which I really agree with. And some of it I don't, but the concept of moral luck is that it does seem unfair that there are many situations in which people create immense harms doing stuff that you and I have gotten away with.

Speaker 2:          00:25:03       You know, I mean, they're not, they're not worse people than we are like, you know, they, you know, you, you and I have both driven when we shouldn't have driven, you know, we had one beer too many or were there things that we did or you're looking at, you look at a text, you know, you know, you should never look at your phone when you're driving, but you decide, okay, I'm expecting a text and you look and there are people who are looking at that text right now and just, you know, killing some child in the crosswalk. Right? And their lives are going to be ruined and you know, they're gonna go to prison and they're exactly like you and me. Right? So there's, there's a, there's an aspect of luck here, but that the luck actually propagates backward into the kind of brain you have, the kind of upbringing you had, the kind of parents you had, the kind of, you know, the fact that you got hit in the head as hard as you did or didn't and no one has made themselves.

Speaker 2:          00:25:52       So I'm a little bit more, I'm less judgmental about some of these things given my view of freewill, but I'm not, it's not that I'm not interested in making the interventions that would make a difference in whatever we could have done to have gotten him to behave differently. We should have done whatever we should need to do now to him to make society better and to make him better and to get restitution for the woman, what we should do. All that. And so this doesn't tell locking up certain dangerous people and it doesn't tell, you know, we have to keep, keep ourselves safe from people who are going to reliably act badly. And um, and I don't know where he falls on that spectrum, but it's just, it's not the difference between the feeling you get when you hear, oh, it was brain damage. I sort of have that feeling about everything.

Speaker 2:          00:26:43       You know, what if you, if, if we, if he gets a brain scan, if he goes to trial now he gets a brain scan and we, and we find that his brain is just massively damaged in all the right areas that would have eroded his impulse control. Right. That would seem to let them off the hook a little bit. It would, he would, he would look like someone who is unlucky more than he would look like a bad person. Right. And I sort of see bad people as unlucky to. I mean, I got recognize that there are certain people who are quite classically bad people. They're psychopaths who you just, not only can you not rely on them, you can rely on them to be bad actors, you know, so you have to, you have to be in a posture of, of self defense with respect to these people. But I do view them as an unlucky on some fundamental level.

Speaker 3:          00:27:29       That's I. I shared that thought and I shared that thought much more as I get older and I have a more philosophical point of view when it comes to people that live in impoverished neighborhoods, especially like this Baltimore thing that was going on. We're just having this conversation the other day about or last podcast about these kids at robbed the Rte reporter, and if you've seen the video of it, there's an to reporter interviewing these kids that are on the street that are causing all this havoc and Baltimore and they start swarming this reporter and then a robber and take her purse and took off. And I'm like, imagine being one of those kids. Imagine being in that environment. Imagine being. You want to talk about determinism managing, being born into this crime Britain environment. Who knows what kind of family you have, who knows what kind of influences you have, who knows what kind of experiences that you've had that you've had to react to and protect yourself from and developed this hardened, thick skin and attitude and also survival instincts.

Speaker 3:          00:28:34       And you also, your your family or the people that you can reliably count on are the people that you hang out in the street, your gang. And that is the big thing with gang violence. One of the big things with gang violence, one of the dirty secrets of it is it, a lot of it comes from broken homes. When people don't have a strong family environment and people they can count on and trust. They don't have anybody who is there for them and then they find someone that's there for them in the gang and the gang becomes their new family and they will do anything to keep that love, to reinforce that love and we all want to look at it as they're criminals. They should be home by 10. There's a curfew on the street. It's completely unrealistic. And if you were in their point of view or if you were in their life rather, and if you saw it through their point of view, you would probably see exactly what they say you would. You would look at life, the way they look at life. Also, there's another variable here, which is just just

Speaker 2:          00:29:24       the influence of mob behavior, people, people will behave in crowds in ways that they wouldn't otherwise. Is that. What is that? What's the mechanism behind that? Yeah, it's a facet. Well, I don't, I can't speak to the mechanism neurologically, but it's a, it's a fascinating social that has been thought about for at least a century. It's, you know, there was a philosopher, I'm Elias Canetti who wrote a book crowds and power, which is very interesting on this topic. I'm a crowd. A crowd is almost like a fire, you know, once it gets started, the mob will behave by its dynamics that aren't really explained by the individual intentions of the individuals in the mob. And because actually there's a great book. Do you ever hear this book? Uh, among the thugs by Bill Buford? He, um, having product 20, 25 years ago. He's, he's a, uh, not really nice writer.

Speaker 2:          00:30:18       He, he edited a literary magazine, Granta I believe back in the day. And he, he got fascinated with the phenomenon of soccer hooliganism and he wanted, he just, he went to the UK and just start hanging out with these, these are just die hard, you know, I guess they were, I don't know, Manchester United or arsenal fans, but just he just got in with these guys who are normal guys like plumbers and electricians and people have had real lives. These were not just teenagers who were thugs. They were, they were people who had families but soccer was their life and they became, they became a soccer hooligans. And. But what's, what's brilliant about the book, and again it's been at least 20 years since I read it, so I could be a little off in my recollection here, but what I recall is that he wrote it in such a way that these guys, he was hanging out with war.

Speaker 2:          00:31:13       Really the protagonist. He got you in on their side for about 75 pages or so. And then when they start misbehaving, when they, when they go to their first game against the Italians and, and form a mob and starting to just marauding the streets. And you know, Bash kids in the head, I mean, it's like they start behaving like sociopath in this crowd, but he catches you out totally because you are, these are, you're on their team for about 75 pages and you're, you're, you're identified with them. You sort of laughed with them. You kind of, you've bonded with them as he did and then he reveals the level of, of thuggery that they are capable of as a, as a mob. And it was really, it was, as I recall, it being a fascinating book, but it is, it's just a fact that, that people will do in a crowd, even when you see it's a part of, it's the social proof situation where you see everyone doing something and that on some level, um, gives you license to do it.

Speaker 2:          00:32:13       So the end, there's kind of a, it's just contagious. We wouldn't see when you see people breaking windows or jumping on a car or turning over a car or alluding there, it takes a less of any individual to participate in that. You know, it takes less for you to go in and grab a television set when you've seen 100 of your neighbors do it then if you have and you wouldn't have that morning, just woken up deciding to rob the store yourself. Um, so it's a, um, I mean we all like to think we're the sort of people who would stand against the mob. We would be the German who would've hid Jews in our basement and stood against the Nazis and, and, and you can multiply those cases ad Nauseum, but what a lot of psychological science shows that the. Yeah, there are those people, there are the people who will stand against the tide of imbeciles who are going to do something heinous, but most people are part of the tide and it's just a very common phenomenon.

Speaker 2:          00:33:15       The social license. That's a really interesting way to describe it because that is what, what it is right here. I mean, isn't that a big part of war mean? A big part of war is doing things that you would never do on a normal basis and in a normal scenario, on a regular basis, you are asked to put bullets under other human beings. One of the things that I thought was really interesting about, uh, the, the, the controversy about American sniper, the Chris Kyle movie was he was talking about what it was like the first time he killed someone and that he is in a book, I don't believe this was in the movie, but that he had this feeling before he shot someone like, is this okay? I can actually do this, is it's okay to do this. And then he grew to enjoy it and then he grew, it became commonplace and normal and he's like, yeah, they're bad guys and I'm going to shoot him, but this license, the social license and then is a accentuated with this, this mob mentality.

Speaker 2:          00:34:15       That's mean you're, you're a part of an army and you have an enemy and it's the life or death consequences of life or death scenario that you're a part of it. The whole thing is escalated. It's the highest level of that type of behavior that we have in, in society, in our culture today. Well, interesting. Interestingly, it takes a lot to get people to kill in war. I think there's some myths around how easy it is for soldiers to shoot at the bad guy. But there have been studies done in prior war is where some shocking percentage of soldiers either never fired their guns or fired above their targets on purpose. They didn't want to kill anyone. And that's been, uh, and, and so some of the discipline of training soldiers has been against the grain of those tendencies trying to get people to actually try to kill the other person.

Speaker 2:          00:35:18       Um, and, you know, I think we've become more successful probably doing that. Uh, you know, this is not something I know a ton about. I just know that this, this research is out there and what the main dynamic I think with, with soldiers is you are trying to keep your buddy safe and he's trying. He or she now is trying to keep you safe and that, that, you know, they're, they're not only firing at you, trying to kill you, they're trying to kill your buddy or just did and slash or just, you know, wounded him or her and now it's just a very simple dynamic that you're just, you've bonded with the person to your right and to your left and you guys are really in it together and it's a matter of keeping you just going home safe, you know? And so what's going to, what is required in that situation?

Speaker 2:          00:36:04       Well, you got to shoot at the people in the other trench. Um, and so every, so now obviously there are aspects of war making that don't fit that mold and some of the more disturbing aspects that actually require less of us in terms of like you're dropping bombs from 30,000 feet or you're flying a drone from an office park out outside of Las Vegas or wherever they were, wherever they are. And so we find that customers telescopic approach to war, different ethically. And I think it is, it's different in a variety of ways that are interesting, but I think it's, it's, yeah, it's not so much that that war unleashes in most people, this blood lust that is, that they're, you know, they're struggling to contain in the civilized world and adjust that once the, the tap is open in a foreign country, you just have Rambo's everywhere that people are really conflicted about what they do and a lot of people try to not do anything of consequence.

Speaker 2:          00:37:06       There is a great episode of one of Dan Carlin's podcasts, one of the hardcore history podcast about world war one, and I believe it was about the Germans and the English that they had been in battle with each other and they had sort of, without verbally agreeing to this, they had sort of agreed to a ceasefire during lunch. Oh yeah. It was fascinating. Do you know the story? Yeah. Yeah, please. Because I've heard a, I knew the story, but I've also listened to Dan's podcast, which is think I got from you. It's just fantastic. He's the best size. I think that all of all of them are great, but that series on world war one is just a masterpiece. It's just, it's really, um, you know, he's doing something remarkable there. Um, but yeah, that's where they, this trench warfare was the most brutal of just, it was just this, uh, you know, horror compounded upon horror endlessly for years to no evident gain.

Speaker 2:          00:38:09       I mean, these people, they're there, there fighting for yards of ground forever and just tens of thousands of people are, are dying and they're, they're basically camped out on the decomposing bodies of the people who died before them. And there is just, it's the most horrible version of warfare you've ever heard about. And then there's this no man's land between the trenches where you know, people who will kind of run out there trying to make an incursion into the enemy trench will get caught on barb or they'll get a shot and then you'll hit you. So you have this spectacle of people injured and dying. People in the no man's land between the trenches, you know, howling for hours and hours and hours and misery. And when someone goes to try to rescue them, they get shot and, and so, but there were periods where the, the two sides just a agreed that this was just, and again, how that was communicated was kind of interesting.

Speaker 2:          00:39:07       I don't actually recall the details there, but it was, there was a kind of a tacit agreement that emerged where, okay, we're going to let you get your, we're not going to shoot it to you when you get the, the, the, the injured person or the dead bodies. Um, and there was one Christmas, I believe where they just basically went out and the exchange cigarettes and you know, had an impromptu soccer game and they just, they basically called the war off at a certain point and then got chastised by the higher ups for, for doing that. And then the war started all over again. But yeah, they actually socialized at one point.

Speaker 1:          00:39:38       It's amazing. It really is an amazing depiction of what must have been an impossible place to be in, to try to imagine being a person standing on the decomposing bodies for being forced to shit in a coffee cup. And throw it over the top of the trench and I mean and know that no one's getting out of this. I mean you might be one of a thousand people that's going to die in the next couple of hours. You might be, you know, you, you might make it to next week, you might not. I mean, and just the stress that you're dealing with the, the non human aspect of that life, like this is not a normal thing that you ever expected to deal with. There's not a normal set of scenarios is not your, your, your brain, the way you grew up, you are not prepared for this life. You're just thrust into it and it doesn't make any sense. And then to have that all sort of eroded to the point where on Christmas you guys are hanging out and then the, the generals come in and say fuck this. You got to kill those people. And next thing you were killing each other again. Like, so you have this brief glimpse of, you know, some utopia inside of, of war.

Speaker 2:          00:40:51       Yeah. Well, what was so weird about that war in particular was that the run up to it was so romanticized and idealistic. I mean you had a kind of a war fever that, that happened throughout Europe where this was just looked at as in the rosiest possible terms like this is just the true glory of, of manhood to be an expressed. Finally we have a, it's like it was approached like the World Cup or something. I'm sure it was like pure exuberance around the prospect of fighting this war, uh, in many quarters. And you know, that you'd be surprised if that ever happened again. And so it's a little bit like what's happening with Ge Jihadists, but they have beliefs that, that caused that to make more sense. I mean, they, they believe they're gonna go to paradise when they get killed in this war. So it's. But it's hard to map your own psychology onto the cream of, of English youth where they were just just going off with this, this level of enthusiasm, having no idea or I guess part of it it was they had no idea just how horrible it was going to be.

Speaker 2:          00:41:58       But they, um, yeah, the, it's, you know, you read homer and war is this glorious thing. The, the war ethic you get from, from ancient civilizations is something that we have, I think largely outgrown, but you can really see it in world war one, don't you think? A lot of people had that similar attitude post nine slash 11, especially when the World Trade Center towers went down and there was this flag waving fewer in America unlike anything I'd ever seen. I remember post 9:11. I remember driving down the street. I'm leaving the street near my house and entering into this main street and every car, every car had an American flag. Every car. It was insane. I mean, it was, uh, if you, if you did, I didn't have an American flag. I was looked at odd, you know, like this is, this is, this is an unprecedented time in history and then all these people were signing up for war.

Speaker 2:          00:42:59       All these people were signing up because they wanted to go over there. They wanted to fight the good fight, and then you start hearing things from people like, like Pat Tillman, who left a career as an nfl player, very promising career as a pro athlete and all of a sudden he's over there and this war and his impression of it was that it was acute clusterfuck. It was nothing like what he wanted. It was nothing like what he expected and he was very verbal about that. Very, very, very openly critical about that. And a lot of people think that's one of the reasons why he died. You know, there's a giant conspiracy theory that they killed him because he was talking to him. He's killed by friendly fire. He was killed by American troops and there was. The conspiracy theory was that they shut him up because he was so openly critical of what was going on over there, that it wasn't what he thought it was going to be.

Speaker 2:          00:43:46       He thought it was going to be this incredibly organized group of heroes that went over there to fight these evil bad guys that are held mountain destruction and suicide bombing their way into the America to kill the American dream mean. This is the idealistic version of it. Well, I think there is an idealistic version of good and bad actors in this case. It's just the reality of fighting this war is so messy and that it's. Yeah, it's, it's you. Afghanistan I think was pretty clear cut morally that we had to do something against al Qaeda and by definition, once the Taliban wouldn't release Osama bin Ladin to us, we had to do something against the Taliban. I mean, that's. He was. And they were sheltering him. Um, and so I didn't, I didn't feel ethically conflicted over that, but that was such a mess. I think you're, you're so going into Afghanistan, the reality of what it takes to go into Afghanistan and kill the bad guys is so messy that there's arguably no good way to do it.

Speaker 2:          00:44:51       There's no, there's no way to do it, which at the end of the day is going to look like a success. And so the men, maybe that's something we're now learning that you have to, um, this is so messy that you have to be, you really have to pick your moments, uh, and the, and the far more surgical than we've ever been inclined to be. And, and, and, and not even think about defeating the enemy ultimately, but just kind of keeping the enemy at bay containing this problem for long enough to change minds or change culture in science in some other way. Because even in, in this case, I think it was, it was very clear cut, you know, we're killing members of al Qaeda was, was a good idea. And I think it's still a good idea. It's just, you know, you have a drone strike, kills some of them and also kills some of the hostages as we now see.

Speaker 2:          00:45:41       And it also kills some of the people standing too close to the bomb blast and it's ethically messy, you know, so it's, it's at. But I think there are instances of it that are certainly necessary, but someone has to be thinking very clearly about how we proceed in a world where there really are people trying to destroy us. It's not that there's, there's no bad guys, there are bad guys. Um, was that where the foreign policy argument comes into play because some people say those bad guys are bad guys because of us foreign policy because of the way we have intervened and dominated really can natural resources. You think it's confused? Yeah. Yeah. So before we dive into that, I'm looking at a list of topics that were brought up by our twitter people and I'm just, I'm just gonna I'll read the list just so we have it in our heads and you can decide what you want to deal with here, but Islam, anything but Islam.

Speaker 2:          00:46:37       Abby Martin, abby, Martin, Abby Martin. Um, so I think we have to deal with Abby Martin. Abby, who is a good friend. I love abby. She's crazy though, uh, in a good way, but she's, she's wild. And she accused you of being one of the new atheists with your anti Islamic rhetoric and uh, you know, that's nothing new to you. You accused of that in the past. Um, did she misrepresent your point of view? Did you listen to it? Yeah, I did. I did listen to it. And should we play it or no? I don't think you need, you don't need that. But what did she say and what would do not agree with what she said? Well, she said it was really interesting listening to her because. So I listened to the whole podcast and she didn't mention me until like the second hour. I'm, I'm listening to this.

Speaker 2:          00:47:25       I'm thinking I'm actually, I'm actually having a conversation with you in my head as I'm listening to this and I'm thinking and show you. It's kind of remarkable what you are able to do here because you're having a conversation with her. If I have, from my point of view, you were just drinking from a firehose of bullshit, right? It's just like she is what she's saying the so much wrong with what she's saying and, but yet you're in a position to have a conversation with her. That is where there's just like a ton of goodwill and it doesn't run to the digital and you can have a conversation with me in the same vein, but then I was thinking I could not. I mean, I'm sure she's a perfectly nice person and I would, you know, I would, I would be very nice talking to her, but I, I have a feeling now of more or less total hopelessness, talking to someone as polarized on these issues as, as I view her to be a.

Speaker 2:          00:48:17       and so I was kind of praising you in my mind thinking that I couldn't do what you're doing here. At that instance, she just mentioned me, right? So it's like, it was like one of those bad scenes in a movie where he let the television starts talking to the, to the character. She just, she just kind of called me out and then represented more or less totally misrepresented my views. Um, so, so she said, she said many things that are just inaccurate, which we can talk about, but, but in terms of, uh, what she attributes to me, she said that I only care about intentions, right? So that all intentions are all that matters. So if we kill a billion people but meant well, we're fine and if and if, if the Muslims kill a million people but don't mean well, they're far worse than we are ethically.

Speaker 2:          00:49:08       And that's intentions are all that matter. And she was, I think in her defense. I mean, she's, I'm sure she's never read anything I've written, but she was reacting to a snippet of a, a podcast where I push back against some of the things that Noam Chomsky has said. Um, and I have, I haven't thought that I, I've, I've said in my first book that Chomsky doesn't value intent, the, the ethical role of intentions enough. And I said something very brief in a podcast that bounced around. And so that's what you heard. So she misconstrued me, their intentions are not all that matters, obviously, but intentions do matter. So if someone, if someone stabs you right, the difference between them doing it on purpose because they want to kill you and then doing it by accident because they were cutting, you know, you guys were cooking in the kitchen and they didn't know you were there.

Speaker 2:          00:50:00       They turned and they stuck a knife into your belly. Um, it's, it's a world of difference ethically, right? So, and, and the, the crucial difference is the person's intentions tell you a tremendous amount about what they're likely to do in the future. The Guy who stabbed you once because he wants to kill you is very likely going to stab you again until you're dead, right? I mean, he's trying to kill you. The, your friend in the kitchen who stabbed you by accident is going to be rushing you to the hospital in the next instance. This is a kind of addition dent, disingenuous comparison because I mean, are you describing the difference between accidentally killing civilians with us with a, like a surgical strike in quotes of a drone strike versus killing someone with a suicide bomb? What are you trying to kill as many people that are random as possible.

Speaker 2:          00:50:50       So I'm just, I'm using a very idealized example just to show you that the role of intention is not all that matters because getting stabbed still sucks. Right? So if you assume the same stab wounds, you still have the same problem, but one of them, one of your scenarios is completely innocent and accidental. Yeah. The other one is murderous intent. Okay. So, so those are, those are the extremes, right? So then you can have gradations along that continuum, right where you have, and some were more in the middle would be you're trying to kill a bad guy and you accidentally killing it on the same person as well. Absolutely. And, and it's, it's totally an or, or you or you think you've got the bad guy and you've just got bad intelligence and you just, all you kill isn't innocent person, right? You could be, let's say you were being totally surgical.

Speaker 2:          00:51:31       You're a sniper. You're going to just kill one person with one bullet, but you've got the wrong person through no fault of your own right or worse yet the bullet goes through that person and kill someone else. Oh, so all kinds of scenarios like that. And, and they're, they're very common scenario I think, which is your bombing, the bad guy. You're reasonably sure you're bombing the bad guy and he really is the bad guy, but you're also reasonably sure that you're going to injure or kill some innocent people and you're okay with that because the reality of fighting war is you never get the bad guy standing all alone 500 yards from the next person. So if you can, if you want to fight this war with drones, say you have to accept some level of collateral damage. Now I don't actually, I mean I am not privy to any kind of intelligence, you know, I'm not, I'm not in those circles and I'm not, I'm not one of those people, so I don't know just how Obama or anyone in a position of responsibility makes those calculations what is acceptable collateral damage, but we know that some level of collateral damage is acceptable because otherwise it would be impossible to fight war at all.

Speaker 2:          00:52:42       Right. So a, we know that some level of collateral damage is acceptable. Just driving on our roads. We 30,000 people die every year on our roads. We could dial that number down to zero. Right. If you, if, if we were committed to no death on our roads, we could get there. We would just all have to drive five miles an hour. Right. But the difference is that when you're driving, you're not intending on someone. It's an unintended consequences that transportation is a big difference between that and the unintended consequence of violence. So we'll know which is definitely. Let's get into that. Let's see it. Let's see if there is. This is an unintended consequence, unintended but foreseeable consequence, in fact, certain consequence of our keeping the speed where it is, right? You and I both know like let's say we could vote, vote on this, you know, what do you want the speed limit to be?

Speaker 2:          00:53:31       It's, you know, let's say it's 75 miles an hour. We know that if we reduced it to five, there'd be some other costs and, and I'm sure there'd be some other ways in which people might die. It would be harder to get you an ambulance, get into the hospital, would be hitting a traffic jam and some people would die on the way the hospital site. But leave that aside, we would save tens of thousands of lives every year if we just took all the fun out of driving and, or just forget about that, forget about it. Let's keep the speed limit exactly where it is, but no matter what car you have, there's a governor on it and you cannot go past the legal speed limit ever. Right? So if you're in a 25 mile an hour zone, know whatever your car is, you've got a porsche or whatever you like to drive.

Speaker 2:          00:54:16       It can only go 25 miles an hour, not a, not a, I'm a mile and hour more, no matter how he hit the throttle. And that would be true in every zone there. People would resist that and their reasons for resisting it is just that it wouldn't be driving will be less fun right now. That is a. If anything is indefensible when you're talking about kids being killed, that is right as a, as a far more superficial commitment than wanting to get the higher ups in Al Qaeda who are trying to at some point blow up an American city. Right? But imagine if as many innocent people died from driving from one activity, like think about the amount of people that die. They do, but they don't. They do, but the numbers are nowhere near. What about the numbers, numbers, numbers, numbers. What are the percentage of people that have in it died?

Speaker 2:          00:55:11       The innocent people that have died because of drones more than 80 percent. More than 80 percent. I don't actually. I just have to plead ignorance on that. I don't know those numbers. They're crazy. They're very high or very high, but. But hold on. Wait, wait, wait for a second. Because you were talking about something like driving for $30,000 a year. Every year. Reliably. Last 10 years has been 300,000 people. How many people who drive on a daily basis wind up driving their whole life and never killing anybody? Most. Most. Well how many drone strikes, but that's why. How many drones trikes wind up not killing innocent people. Almost none, but that's not necessarily the way to analyze it or at least I would argue that's not the way, but let's just talk about numbers for instance, because another problem I had with Abby Martin, she was using this number $2 million debt in Iraq and Afghanistan.

Speaker 2:          00:56:01       Where did she get that number? There's no that no credible person is using that number. What do you think the number is the number? Almost certainly in order million. No, no. That. That number is almost certainly an order of magnitude to high it in the sober estimates are like 200,000 and most of that most is the result of sectarian violence, right? It's not, we didn't kill 200,000 people. We went in to Iraq and this if of we're mostly talking about Iraq, that the numbers are much higher there than an Afghanistan. We went into Iraq. We, we did some very stupid, understandable things and also some very stupid things, but we took the lid off of a, a simmering civil war that the real catastrophe of rack apart from our going in in the first place, which I never supported. But the real catastrophe is that having gone in, we failed to anticipate the level of sectarian hatred and we did very little to, to hedge against it.

Speaker 2:          00:57:02       And we kicked off a civil war which someone like Abby Martin, clearly things we are entirely responsible for. So when we know when she, uh, death squads are taken out, the power drills and drilling holes into the heads of their neighbors and the Sunni or returning the favor, that's us. We are culpable for that. Now I don't accept that, uh, these people were there, they're killing one and they've got a blood feud going back over a millennium now and we pop the cork on it in Iraq and that's a terrible thing to have have collaborated in and we probably should've foreseen it. So if we're culpable, it's for not having anticipated certain of these consequences of our actions, but we are not the people. We are not the Sunni, her killing Shia and we're not the Shia, Herculean, Sunni. And the same is true in, in Afghanistan.

Speaker 2:          00:57:54       We are not the Taliban who, who, who are blowing themselves up in crowds of fellow Afghans as a way of making their country ungovernable so that we have to leave right now. Again, you could fault us for not having anticipated this closely enough and or, or done something effective to prevent it. And ironically, which faulting faultiness for in that case probably in Iraq is once we saw how bad this was getting, you're faulting us for leaving, right? You the argument there is the compassionate thing to have done there. If insofar as we could have anticipated the rise of Isis and all of the that you just this consequent death hold death toll, you're faulting us for leaving because we, because our political interests and our stomach was no longer aligned with this project and you know, so that's the, I'm not sure that's an argument that someone like Abby Martin wants to make, that we should have stayed longer than we should've spent more money than that we should have killed more people in an effort to keep the locals from killing so many more people.

Speaker 2:          00:58:56       So anyway, this, the, the number 2 million is plucked out of a bad dream. I don't know where she got 2 million who was setting up, I don't know anything to 100 than me. Obviously you're not going over there counting bodies. So who was saying it's $200,000? Who's saying it's 2 million? Okay. Well, so I'll tell you I'm the highest number that at one point seemed credible, was based on a Lancet article. Lancet is a British medical journal, very well regarded, but it has something. Jamie just put this up on the screen here, what is this from Jamie rack body, so that's 200,000, but what is, who was making this Iraq body count? Dot Org website. It says, let's read what it says, documented civilian deaths from violence. One hundred and 38,000 to 156,000 total violent deaths including combatants 211,000 and this is a. What is this up from says from following the 2003 invasion, but is this different?

Speaker 2:          00:59:56       I think this is total counting. They keep counting. So there are different ways to do this. One is you can, you can count bodies, right? And and the information there is not perfect because some people die and their death doesn't get reported. You know, not everyone has a death certificate so you can count, you can count bodies, you can get reports of of of the actual deaths. The other thing you can do is you can estimate the amount of death that would have occurred in the absence of an invasion and then compare the rate, the reports of a statistical sample of an area and compare the reports of death based on the past based on, yeah, based on what's happening now and you see a differential there and then you extrapolate to the rest of the population and so that's what the authors of this Lancet article, they did that and they came up with a number, a 600 or 650,000 and that article has been widely criticized.

Speaker 2:          01:00:55       Not to the point of it being unpublished, but I don't think it's been retracted, but I don't think any serious person thinks that article is representative of the facts. And so what they did for instances they they took. They would take a cluster of I think 40 homes in an area and asked the people who has died, who do you know who has to, who has died and how did they die, and then they would get. They would just based on that sample. They do that in many different sites around Iraq. Based on those samples, they will extrapolate to the rest of the population and they came up with $600, 650,000. So one criticism I read about that article was that they, they seem to have focused on areas in near major thoroughfares in big cities where you know, where I eds were far more common than other places and in those same cities or in other places in Iraq.

Speaker 2:          01:01:50       So like so places like the very place you would, you would most likely plant an Iud is a, is a non especially representative place to poll all the families in the area to see whether they've lost loved ones in the war. Right. So that, that was one way to get an unrealistic number. The other thing is that the, it seemed that there were just some shady things with the researchers where they weren't releasing their data, their and their methods and the communication with them broke down. And so anyway, the sober people trust who focus on these things, I think that's a fictional number. And that's one third, not even one third of what abby is working with. Excuse me.

Speaker 2:          01:02:29       I think I caught Arboreta. It's cold. Just just watching that podcast, I think I got his goal. I think that we can agree that even 200,000 people dead is a tremendous tragedy. Horrific, tremendous tragedy. So was the semantics argument over whether or not it's tenfold that number or whatever it is you just disagree with? That's not okay. Manix is a bad word. Tenfold, tenfold. And, but even more important is we didn't go in and kill 200,000 people. We went in and killed, I'm sure some tens of thousands of people, many of whom were were, you know, the baptist, the Revolutionary Guard. Right. And we unleashed a Maelstrom of internet dating, sectarian conflict, religious conflict, and we fail to contain it and it would have taken more blood and treasure to contain it. And um, so it's, it's a, it's a huge problem. I'm not minimizing the horror of Iraq.

Speaker 2:          01:03:34       I can, I, I never supported our invasion of Iraq, the things I've said that have been spun as supportive it are drawn from conversations with the sort that you and I are having now. So if for instance, I've said things like, am I might've been on your podcast, I said at one point, um, even if we had gone into Iraq for purely humanitarian reasons, right? Let's, we're going to go in to remove Saddam. He's a criminal, he's a psychopath. This was a hostage situation. We're going to get him out of there and we're just going to dump money on these people to commit to so that the standard of living rises to something like Marin County. Right? So this is our goal. That's actually our intention, right? Even if that were the intention, it still would've been a nightmare. We still would have been unleashed the sectarian horror.

Speaker 2:          01:04:20       We still would have had suicide bombers against us. Now I believe that to be true, right? So I say something like that and some people listen to this conversation and they say, well, Sam thinks that we went into a rack for humanitarian reasons. He thinks we went into a rack just to make it like marine county. Right. So that's the sort of pushback I get from the Abbey Martins of the world. No, I've never, I've never said that. I'm just saying that, that the truth is so sinister that even if our intentions were perfectly benign and we're just trying to raise the standard of living there and make, you know, even just give them the freedom to practice their own religion. Right. So we're trying to make this like Nebraska, um, it would have been a bloodbath given the beliefs of, of sorts of people who now populate a group like Isis.

Speaker 2:          01:05:06       So anyway, that's, that's my claim. So this is just one aspect of what you disagreed with. What she said. Well, it just, so her 2 million number, the 2 million down to the ground. I mean she's, she's just has this, she's a lefty. She, she's well shoot, but she has a kind of confabulatory style. Again, I'm not really denigrating her personally, but I don't know her. I'm sure she's, she's a good person, but there's a style of talking that you run into with people where there's just. It's kind of confabulatory we're just sort of talking and it sounded good and you're just sort of spitballing, but you're using numbers, right? You're new, you're using numbers like 2 million or you're saying things like, our biggest export is weapons. The landmark research proves the US led war on terror has killed as many as 2 million people, but this is a fraction of the western responsibility for deaths in Iraq and Afghanistan over the last two decades.

Speaker 2:          01:05:57       Last month, Washington DC based Physicians for social responsibility released a landmark study concluding that the death toll from 10 years of the war on terror since the nine slash 11 attacks is at least one point $3 million. It could be as high as $2 million and we just finished it just so we can get to it. 90 seven page report by the Nobel Peace Prize winning doctor's group is the first to tally up the total number of civilian casualties from the US led counterterrorism interventions in Iraq, Afghanistan, and Pakistan. Right. Okay, well, so, so clearly that's where she got this number. She got it from somebody who got over there. Um, I think that number is the sorts of people I taught. So for instance, when I as a sanity check when I heard Abby Martin, I sent an email to my friend Steven pinker who is an incredibly sober scientist. I'm just a very careful researcher.

Speaker 2:          01:06:49       He was, he wrote this truly landmark book on the decline of violence in the last century that the better angels of our nature came out a few years ago. He was like 800 pages on this topic, very data driven book. And uh, he's, he did a tremendous amount of research for this and he's, um, he's an incredibly well respected Harvard scientist. So I pinged him about this and I said, I'm hearing in liberal circles that we killed 2 million people in, in Iraq and Afghanistan. Sir, is there any chance that this is true? And he bailed. He said, more or less. What I'm saying to you now that this is, it's almost certainly in order of magnitude too high, the highest briefly credible study was the lands that one that was, I don't know, I'm, I didn't know about this and I don't know what he in particular would say about this study, but undoubtedly they use the same sort of extrapolation methods.

Speaker 2:          01:07:43       They're not counting bodies. They're there, they're doing based on where the ambient level of death over the years. They think it's gone up by the tune of 2 million, uh, in those, in those countries. Um, but anyway, so, so Steve said, no, this is, this is a totally fanciful number and here's why. And he broke it down for me. And then I did, did a little more reading on the topic, the, but again, the crucial, I think it really matters whether the number is 200,000 or 2 million. I don't want to be loose on that. But the crucial ethical difference is did we go in and perform our own sort of final solution against the Iraqis and the Afghanistans trying Afghanis trying to kill millions of people a Hitler or did we wander into a situation where we unleashed a civil war and are we culpable for that and I don't think we are.

Speaker 2:          01:08:43       We're culpable for something, but we're not. We are not the Sunni's killing the Shia and vice versa. You believe that that is the majority of. Absolutely. Absolutely. I don't know if that necessarily the new study necessarily agrees with that. I'm sure. Well, I. I would be astonished if they didn't that Lancet study. It says it's, it's likely to be far more accurate than the figures initially. Which study is likely to be the 200,001, 655,000 deaths. So wait a minute. The people who were saying it may be 2 million, but it's at least 100. According to the PSR started the must disputed Lancet Study Lancet study that estimated 500, 655,000. I us up to two, 2006 and over a million until today by extrapolation was likely to be far more accurate than the IBCs figure. In fact, there were four can confirms a virtual consensus among among epod, demolish a epidemiologist on the reliability of the Atlanta is coming from the so I don't want to totally.

Speaker 2:          01:09:46       I'm not saying I'm not open to this information, but the website you are pulling this from is just just trash, right? Middle East is just. I mean this. This is the. These guys publish the serial plagiarist who's been stalking me, who I vowed not to name. I missed. Just the stuff they publish is just pure insanity. I mean Google me on this site and you'll get madness jobs, so they're. They're talking about a study. They didn't perform the steps, but I can't publish it in real time. I can vet their representatives that study and see who the hell. Who was at say perform that study. I can't read that. PSR physicians the social response. So that's a real group. But again, the problem only one problem here is that this whole area has become so politicized that it's hard to even, you know, like Amnesty International has embarrassed itself with supporting a jihadist organization in the UK and they just at the 11th hour pulled out their support, but the, for, for a very long time, they were just in the same trench with jihadists and not knowing it or, or, or they should have known it.

Speaker 2:          01:10:58       I mean people were telling them, but they were still, they were very slow to realize it. So I don't, you know, you don't know, um, you should be slow to, to, uh, take even a humanitarian organizations word for the significance of a given study. Um, but, you know, I would find, I would find it frankly amazing if we had killed anything like that number of people and why. Well, I would, I would find it amazing if that number of people had died, I would find it. I, it's, it's, it's unthinkable to me that we killed 2 million people. It's over 12 years of war. But even if you killed, you know, mentally you just know where all this death is coming from, you know, where the bombings that the Iud is, that truck bombs that, the blowing up of mosques, we're not doing that. Right. So that's the body count when you look at, when you look at the penalty, we're paying for killing people and when we look at how much we don't have our own soldiers don't want to die unnecessarily in our own cabinet level of casualties.

Speaker 2:          01:12:10       We're not on the, on the other, on the other side of all those guns. I mean we've done just a tremendous amount of internet seeing violence in both Afghanistan and Iraq and that is just killing, you know, like a bomb will go off and 100 people at a mosque will be dead. So Abby Martin, I think, I don't think I'm being uncharitable here. I think she thinks we're responsible for that, for the Sunni Shia violence. Yes. Okay. So whatever the number is, that's, that's your argument with that. You were saying that I was swimming in a sea of bullshit before that, right? What else was bullshit? Well, I think, um, I, I don't remember all the details, but. So for instance, one thing she said is that our main export his arms, that's not true. That's not true. That's not true. So it may be what does our main export.

Speaker 2:          01:13:01       I think our main export is like machinery, like everything, everything you like, farming equipment and pumps and road making those corn. That was a guess. I think it's technically know it's, I think it's airplanes and I mean everything they find out everything that's a machine I think is. So maybe arms falls into that category, but when you look at machines, number one to $119,000,000,000 in machines, 13 point five percent of total exports. Number two, electronic equipment, 171 billion oil, $157 billion. Number three vehicles, $135 billion number for aircrafts and spacecrafts, $124. Billion. Number six, medical tech, net technical equipment, 84 billion. Number seven gems, precious metals and coins, 65 billion. That's interesting. Number Eight, plastics, 63 billion. Number nine, pharmaceuticals, 43 billion coming in strong with the Viagra. Number 10 organic chemical. So guns aren't even in the top 10 machines. Yeah, but I'm sure that. Well you got, you have to think that weaponry is somehow spread across aircraft machines and aircraft vehicles.

Speaker 2:          01:14:13       I, well, I mean I'll cut her the, the benefit of the doubt there that be there is because you know that, that let's find a more comprehensive list that actually includes arms because it seemed that that's pretty sneaky as if it is machines and she might be somehow or another will say it's export, you know, $50,000,000,000 in arms a year. I don't know what it is, but it's um, and that's, that's a whole nother conversation whether we should be doing that. I think that's suicidally stupid in certain cases that we're arming people who are eventually going to be using these arms against us or our friends. But conspiracy theory would be that that's how they perpetuate this whole constant cycle of war. So you have to keep arming your random. Well No. So I think the economic interests of defense contractors is not something that I am especially sanguine about. It's not, you know, I think that the, the, the role of the possible role of corruption there and a concert of callous indifference to the effects of, of being in this business. I think that's, that's a very real concern. But so to say that we, this is our main export is bombs essentially. That's not true. Now maybe what she meant to say is we are the main export of weaponry in the world. It's probably just, which is probably true, but that's not what she said. Or maybe she said both and I only heard one.

Speaker 3:          01:15:36       No, I think you're correct in what she said she might be getting. You know, that's the problem. Unless you're doing the look. We live in a world that's so broad and comprehensive that unless you're doing the actual research herself and not just doing it, but doing it over a long period of time and very meticulous, most likely you don't know the actual numbers unless there's very few things that I could talk about with utmost certainty that aren't involved directly in my own life. And when you deal with numbers, like numbers of imported guns, export had guns, people dying in a place that you've never even visited. Boy, you were relying on a lot of people's data. Yeah,

Speaker 2:          01:16:11       yeah. Yeah. And one thing that really is depressing is the degree to which people are. So this conversation is so politicized that you just even signed the climate change conversation. The fact that there are people who are too, you can always find someone with a phd to sit up there and say, you know, I don't think cigarettes caused cancer. Right? I mean, you can find those people. You can find the people who are, who are engineers who say that nine slash 11 had to be an inside job because you know, the melting point of steel, blah, blah, blah, and you can find on all these issues you, you get incredibly politicized science and it's so, but if certain things don't pass the smell test and 2 million to me, 2 million people doesn't pass the smell test. Certainly if you're going to say that we killed those 2 million people that we, we, you know, did we, we did double the level of a Rwandan genocide intentionally.

Speaker 2:          01:17:11       That was what we did. That just seems completely masochistically hallucinatory to me. I see your point. Um, I don't know who's right, but I see your point now. Was there anything else that she said that you needed to dispute? Um, I don't think so. I mean, the thing I can say just categorically is that what she said about my concern about intention is, is just not true. It is. If you intentions matter because they are the best predictor as to what the, what the person is likely to do in the future. If you know someone is killing people because he intends that he wants that, he wants to cause grief and suffering and death will then you know this is a person you have to jail or kill and this is not a good actor. If someone does it because they. They did it by accident or they didn't foresee the consequences of their actions or they were trying to get the bad guy and they they, they produce collateral damage.

Speaker 2:          01:18:10       It's a very different scenario and the at the body count may be the same. And so the thing I faulted Chomsky for in the past is that he seems to talk about situations where all you need to concern yourself as with his body count. So that. The example I dealt with in my first book, the end of faith was a, and this was in reaction to a short book. He did right after nine slash 11 called nine slash 11. He talked about the Clintons bombing of the shift of a pharmaceutical plant in Sudan, in retaliation for the embassy bond bombings. Al Qaeda bombings in Kenya in the nineties. And he talked about this bombing of the pharmaceutical plant as a, as a great atrocity, seemingly equivalent to the atrocity of nine slash 11 or worse, um, because of the, of the consequences for Sudan of having their for half the supply of pharmaceuticals destroy, they couldn't, you know, people would die from preventable illness as a result of this.

Speaker 2:          01:19:11       Well, what an incredible atrocity except, you know, the representation of our government was not. And I think any rational thinking on this topic, which would suggest that our intention was not to destroy a pharmaceutical plant. We claim to be bombing what we thought was a chemical weapons factory were run by al Qaeda and we wanted to degrade that capacity of theirs after they hit just bombed to embassies in east Africa. So, um, let's just say that's true, but who knows what our actual intentions were. But if, if our intention was to bomb a chemical weapons plant that we didn't know was a pharmaceutical plant and we bombed a pharmaceutical plant that was being used for peaceful purposes. And as a result, tens of thousands of people didn't get their medicine and died. That is not an equivalent atrocity to intentionally killing tens of thousands of people. Right? It's a, it's, it's an instance of bad luck.

Speaker 2:          01:20:07       You were trying to get the bad guys. We bombed it in the middle of the night as far as I know, Clinton didn't even think anyone would be there. Right. So it's possible that we weren't trying to kill anyone per se. We were just trying to bomb a chemical weapons plant. If you accept that to be true, then the fact that tens of thousands of people died as a result doesn't have the same ethical significance. It is much more like you and I are just trying to get home at 55 miles an hour, but we're participating in a system that's going to kill 30,000 people this year based on our speed limits. We're not intending to kill any of those people. Right? It's just. And, but perhaps we should have foreseen. So it was bad data was bad data. Well, no, I mean that's, that's what our government said about his actions.

Speaker 2:          01:20:51       Now let's say, let's say that's not true. Let's say, um, let's say it was a pharmacy, let's say we knew it was a pharmaceutical medical plans, but we also thought it was a chemical weapons plant and we bombed it really knowing what the bat, you know, we thought we were going to get the chemical weapons facility, but we also knew we were going to destroy all of their, their pharmaceutical infrastructure and that would have cascading bad effects that all things considered. We didn't care that much about. Right. Let's say, let's say it was that the place on this continuum of, you know, moral callousness, well that's still different than trying to kill 10,000 people by taking away their medicine. Right? It's, it's, um, it's May, may, May. In My, in my view, it may not be so different and it's something that we would be culpable for.

Speaker 2:          01:21:40       But I think you have to what Matt, the reason why intentions matter is because they are, they're the clear expression of what we are committed the ends to which we're committed. If the kind of world we want to live in. And so you have. I mean, this is what I did in that first book I asked them, this is a thought experiment I called the, um, the perfect weapon where I said, well, you know, just imagine what a group would do if they had perfect weapons, right? Where they know there's no such thing as collateral damage. They could just target everyone they wanted to target. They would never hit the, you know, the sound been lawns mom who happened to be standing too close to him. They just go, they're just going to hit Osama bin Ladin. Um, so what would any one group do with the perfect weapon?

Speaker 2:          01:22:27       What would Bibi Netanyahu do with perfect weapons? What would Hitler have done with perfect weapons? What would Bill Clinton do with perfect weapons? People like Chomsky and Abby Martin talk about the Clintons and the bushes and the net and Yahoos and the Dick Cheney's of the world. And I'm not necessarily equating all of those people, but they're all, they're all sort of in a certain area for me. I'm, uh, as though they would act with the perfect weapon exactly the way Hitler or Osama bin Laden or Saddam Hussein would act with the perfect weapon that we have a level of malevolence, a level of commitment that makes you so much of what she was saying essentially that kind of the, the intentions of our government are to go around the world killing Brown skinned people and that was a pick a phrase she used and that, and the spirit in which he talked about our culpability on the world stage is very much in the sense that we have intentionally murdered millions of brown skin people because we don't care about them.

Speaker 2:          01:23:31       And maybe it's part of the reason why we, we want them dead. Right? Um, and that's, I do not believe that's the situation we're in. I believe. I certainly unbelief that someone like President Obama wants to create massive collateral damage. And if you gave him the perfect weapon, I'm reasonably sure he would target the bad guys. People who, if you and I could vote on whether these people should go down 90, we would have a 90 percent convergence with him. Right. We wouldn't find ourselves in the presence of a, of a psychopath who just was so amped up on his power to kill that he would be killing, you know, and frank. Right. Whereas there are people who really did kill and frank because they intended to kill hand, frank and everyone like her. Right. There's a difference. Is there any culpability? Is there any.

Speaker 2:          01:24:23       Do you put any blame on the United States government and our foreign policy and our decisions as far as the domination of global natural resources, whatever we've done overseas is, is that in any way responsible for the hatred that these people have for America in the first place? Yeah. Well, yeah, and beyond the hatred, uh, responsible for our alliances with people who commit outright human rights by Saudi Arabia. Yeah. So the fact that we can't just break all ties with Saudi Arabia, the fact that we can't twist their arm and get them to behave like civilized, a civilized culture, a culture on the world stage at this point. So they're, they're jailing and, and caning bloggers. This is one, a atheist blogger. I'm a Rafe Badawi. I'm sorry if I'm mispronouncing his name. Um, you know, it's a, it's an absolute scandal. The fact that we can't apply more pressure to them and that isn't as far as I can tell, entirely explained by our dependence on oil and our unwillingness we have the technology to break this dependence on oil.

Speaker 2:          01:25:43       The fact that we have such entrenched financial interests that's keeping us tied to oil. Um, and that, that the whole military industrial complex is tuned to safeguard those interests for, for us in the world that have those interests have been, they've been monetized, they been controlled, well monopolize, roll back the clock 50 years there I'm sure was not an alternative to being dependent on oil. Right. There's a certain point. So we're totally dependent on oil. Civilization just needs petrochemicals to survive. And they all happen to be buried in the ground, in inconveniently, under the palaces of these religious maniacs, the that may have been the situation then. So how culpable we are are we for securing our interests and not just we the US, but you know, the west at that point by, by entering a relationship with the house of sowed. That's one question that may have been a marriage of necessity and there have been marriages of necessity with tyrants, I think in the past, but now the fact that we can't sprint to the finish line and get off of oil, right?

Speaker 2:          01:26:55       We know this is a dwindling resource, we know is a disaster for climate change. We know that there would be a, uh, the, the financial and technological renaissance that's waiting if we all just grab Elon Musk's coattails and, and, and go towards sustainable energy. Um, all of this, you know, our interests and what we're funding both sides of the war on terror. It makes absolutely no sense. So we should just make a full court press in the direction of sustainability, energy security, and getting ourselves into a position to say to the people like the Saudis, you treat your bloggers better or we're going to bankrupt you, right? I mean, it's just, you all, all their wealth is coming down of the ground, right? So the moment we don't need this wealth or need to defend it, what would be in a much better position to demand that they, that people treat women better throughout the world and they treat, you know, they, they honor free speech, etc.

Speaker 2:          01:27:56       So I think it's a scandal that we, we are not, uh, doing that and I think we asked, we are culpable for doing that, but given the, given what would happen to us in the near term if we lost access to oil. And again, I'm not juSt talking about us, I'm talking about europe and just the whole world. it's a, it's been a very difficult situation to be in and it's understandable that we have gotten into this situation, but I don't find it understandable now that we, we aren't, um, you know, sprinting away for it. So fucking

Speaker 3:          01:28:29       define your point of view. Your point of view is more of a pragmatic take on what the world is currently at this stage. It's not your, you're not taking away the responsibility of the United States government. You're not saying that they haven't made horrific decisions. You're not saying that they haven't been manipulated by these gigantic corporations that are profiting off of the war that we're currently involved in, that you were just saying that if you want to look at the actual reality of the good guys and the bad guys and where, where the world is fucked right now. There are certain things that have to be done and there are certain

Speaker 2:          01:29:02       people that have to be taken out. If you do not, you put everyone else at risk. Is that, is that a good? That's fair. Well, I guess I would only tweak it add that and I. This is the ipad saying this for 10 years, at least, are now closer to 15 years and It just never gets heard. I can grant someone like chomsky, you know, 80, 90 percent of his thesis. Right. So yeah, I think he's, he pushes forward into kind of a masochistic voodoo a little bit. But, but we have done horrific things historically. Right. And, and the question is just how far you want to roll you. You'll walk back in your, in your time machine. But you know, starting with, you know, our treatment of the native americans on up and it depends on who, who the we is. But we be in the United States, right?

Speaker 2:          01:29:53       So we get, we get here, we start behaving badly and we behave badly for a very long while and we have done terrible things. And yet it is also true that we have enemies we haven't made. We have people. There are people who have had the benefit of everything the west has to offer, who are waking up today deciding to join isis for reasons that have nothing to do with us foreign policy or if they do have something to do with us foreign policy. It's based on a theological grievance. It's not based on any real political concern for the lives of the palestinians is based on you've got infidels too close to muslim holy sites. Um, and you have the problem. The, the intellectual and moral problem I've spent more time focused on is the problem of someone like jihadi john, right? The guy who has got a degree in computer science, right?

Speaker 2:          01:30:45       He comes from a middle upper, middle class background in the uk. He's got all the opportunity anyone could want that. There are at least 3 billion people, probably something like 5 billion people, excuse me, who would, who would trade places with him to be in a position of such opportunity in this world. And yet, the opportunity he wants to take is to move to Iraq or Syria and, you know, cut the heads off of journalists and aid workers, journalists and aid workers. They're not know navy seals. They captured. They want to kill the aid workers. It's not an accident, it's not, it's not something that, it's not like a perversion of their impulse is not like, oh, I would really wish this guy wasn't an aid worker or a journalist, you know, but when he's the only guy we have no, this is, this is their commitments or that horrible.

Speaker 2:          01:31:41       Right? And, and, um, you have to explain how, and this is something that someone like abby martin and someone like noam chomsky is the phenomenon. they really don't explain how is it that someone with all the opportunity who's never been victimized by anyone, how is it that he is committed to the most of horns and profligate misuse of human life where he's just his risk ready to burn up the world, right? And now how do you get tens of thousands of people like this coming from a first world societies and map. And so then, so given that, given that phenomenon, then what explains the commitments of the people who don't have all those opportunities right there, the people who are born in these societies are shell shocked and had been mistreated at who, who are, who have understandable grievances against us, right? They are part of the collateral damage.

Speaker 2:          01:32:33       We've been bombing over there after. All right? So it's no mystery that they would hate the west, right? Some of them. I meAn, some of them still love the west, some of them still are trying to get out. Some of that I hear from, I fear I hear from atheist in these countries who don't hate the west. I mean they don't follow. They don't follow abby martin's line on this. They don't, they don't. They understand why we were bombing in their neighborhoods. Right? But, um, the fact is this is really like a science experiment there, prIstine cases of people who have no rational grievance, who devote their lives to waging jihad and they're not mentally ill and they're not. And that's, that's the, that's the problem that I, that, that problem is scaling thing that I worry about is that as a meme that is spreadable you don't have to ever meet anyone affiliated with a terrorist organization to get this idea into your head. And, and so that's, that's the piece I have focused on. Um, and it's not that I've denied the reality of the other pieces.

Speaker 3:          01:33:31       Is this related in any way to just a natural instinct that's a certain amount of people have to be contrarians. I mean there's certain amount of people that when they, when they find any sort of large group that's in power, they want to oppose them. If they find a band that's popular, they want to hate it. If they find a political party that's in control, they want to oppose it. There's a certain amount of people that are just natural contrarians. When they find a group that is absolutely committed and completely involved in an ideology to the point where they're rabid about it, it becomes attractive to them and they want to join that resistance to fight against the death star that is the United States. I'm not religious by any stretch of the imagination, but what I am is curious and one of the things that I like to do is I like to watch a really pious or really obsessed religious people.

Speaker 3:          01:34:25       I love to watch videos of them because I find it fascinating and there's a certain amount of. When I see the islamic scholars that are talking in absolutes, absolute confidence about their beliefs, there's a certaIn amount of that that I personally find attractive. I don't want to join isis. I don't want to become a muslim, but when I see someone almost like what we're talking about with conor mcgrEgor earlier where he just fucking believes, man. When someone believes I was watching this guy. I forget his name, but he's a guy from. He lives in the uk and he's this rabid islamic scholar that he. All of his tweets are on. How islam is superior and it doesn't have to be adjusted like the laws of modern society and secular wisdom is inferior to the islamic wisdom and blah, blah, blah. I watched this guy do this youtube video where he's describing how islamic culture is superior to western culture in terms of the way they manage money and he made a lot of fucking good points and made a lot of good points about wealth and about, uh, about building economies and about how you, you know, you take a company that's only worth $100,000, but you could sell it for a million dollars or you know, trade it, you know, you have stocks and this is invisible wealth and islam doesn't allow invisible wealth because that's how society is get crushed and that's how we're other economies crumble.

Speaker 3:          01:35:50       And I'm watching this guy with his moral certainty and his extreme confidence in what he's saying absolute. And it becomes compelling. And I'm not joining. I'm not, I'm not saying that he got me, but I'm saying that I'm just absolutely admitting there's a per a certain aspect of human nature that gets compelled to join groups. Oops.

Speaker 2:          01:36:12       Oh yeah, yeah. Well, there's something, there's that component of it which, which I understand, but there's also just the, the religious ecstasy component, the aesthetics, the emotional component of it, which I really understand and I'm susceptible to so far. I have a blog post leaves called islam and the misuses of ecstasy where it's actually the first blog posts I ever wrote where I realized I could not possibly have written this in book form or in a newspaper because it relied on embedded video. And the only way to have done this with was with embedded video. And um, I wrote this, I think in, you know, once again over protest the, something was said about me by glenn greenwald or somebody to show it. Yeah. The charge had been that I totally lack empathy, right? Like, I'm not, I don't even know what it's like to be, you know, what these people are getting out of their religion.

Speaker 2:          01:37:08       Right. I've just demonized a whole people I don't understand religion and so I wrote this blog post to trying to indicate how far from the truth that was. So I wrote. So I, I put the example of the call to prayer, right? Which I think, I mean there, there are some that sound kind of ratty, but a nice call to prayer I think is one of the most beautiful sounding things humanity has ever produced, right? I mean, I, that, that hits me, that gets into my bones, right? I don't, I don't have to imagine what a devout muslim, his feeling when he hears the call to prayer. I think it's absolutely beautiful. Right? And without even knowing the length. Exactly. right. And I'm not without ever having been a muslim or believe in any, you know, if that sound and again to your listeners can just read that blog post, I only dimly remember what I wrote, but if that's, if that ritual was purposed as to towards some other end, right?

Speaker 2:          01:38:04       If that ritual just was signifying, you know, let's all get up in the morning and consider how profound human consciousness is and consider our togetherness on this, you know, rock spinning through empty space and realized that we just have this common project to make the world beautiful. Right? If that was what that meant, right? I would just want a minaret, you know, right next to my house in the, you know, I mean I would just, I would, I would be totally on board with, with, with the, the experience of, of, of participating in that. so I'm totally empathetic there. And I. So I went through many other instances of this where something I'm seeing in the muslim world, I, I really grok how beautIful and meaningful and captivating this is for people. But then at the end I put in a, a, um, a quranic recitation and sermon by a. Forgot his name now, but some shake who's got, you know, like 10 times the number of twitter followers you have, right?

Speaker 2:          01:39:05       I mean, so he's like, he's not a fringe figure. He's a muslim rockstar and you know, you see the translation of what he, he's given this tear filled recitation of the koran, which again is beautiful, right? He's a great, he's a great singer and I'm at the end. It's a packed house in wherever it was, Saudi Arabia, Yemen, and um, but what is being said there is so ethically ugly right center essentially celebrating that the tortures of hell, right? And just, just expressing a certainty that, that, that infidels are going to go to hell and how, you know, this is a, you have to organize your life around this question, but just how to, how to escape the torments of hell. And the only way to do it has to be a true believer in, in the koran and mohammed, etc. And this is at the center of the, of the, the mandola of their ethical concern.

Speaker 2:          01:40:07       There's nothing matters but nothing, nothing in this life matters but avoiding hell fire. And so there's kind of a ghastly perversion of this impulse that I think many of us feel. I certainly feel it to transcend yourself, to experience bliss and ecstasy and compassion. And um, and you know, it's, it is very much, it's, it's, it's very much like burning man for people. I mean it's like if, if, imagine at burning man, whereas just as ecstatic as it was attracting all the smart people that it attracts but strewn throughout, it was a message of just true divisiveness like everyone else who's not here is going to be tortured for eternity and they deserve it and we shouldn't be their friends and we should fuck them over any way we can when we get out of this place. And if god had wanted to enlighten them, he would have, but he hasn't.

Speaker 2:          01:41:06       So we're the only ones here and, and it just kind of an a, a durable message of us and them thinking that just cannot be dissolved. Right? That's what's going on in the muslim world. And, and that's a huge problem because it does, it's pulling all the strings of, you know, I mean, it's not just islam. Obviously christianity has a version of this and, and all religions and principle have a version of this, but there are differences there. There is no version of jihad that know there's no buddhist jihad. It's not to say that buddhist can't do terrible things and it's not to say you can't find buddhist reasons for doing terrible things, but their jihad, jihad martyrdom, paradise. TheSe, this, this is the jewel, you know, horrible jewel that, that so many millions of people are contemplating in, in an islamic context. And that's, that's what I'm worried about and I'm not insensitive to the, to the experience people are having is this version of islam, recent in human history.

Speaker 2:          01:42:13       There's this extreme radical version of this. There are some things you can say that have, you know, with wahhabism and salafi style islam generally that have been politicized and tuned up in a negative way in the last century that you can say that, but the reality is that jihad is as old as islam and islam spread by jihad and it isn't the original version of jihad or on your own vices. Oh no, that's just. No, I mean there is that component to it. There is a energy hot and an outer jihad, but there was always an outer jihad and that's how muhammad spread the faith and mohammed. I mean, so to answer your question very simply, as I did somewhere, I just said there's absolutely nothing isis is doing. The islamic state is doing that. Mohammed didn't do right. I think I said good luck finding something significant that some difference between.

Speaker 2:          01:43:14       I mean taking sex slaves, right? Muhammad took sex slaves and gave sex slaves to his. His generals. It was totally kosher. Kosher thing to do. If You're going to follow the example of stefan that kosher. Yeah. Nobody. Hello? I mean if you're going, if you're going to follow muhammad's example, which is a real, is perhaps the main lens through what you have to look at this. There's the. That's just what's in the koran and there's what's in the huddle with the larger literature and there's the example of muhammad, which is, which is a tested two in both those literatures and in the early biographies about him. Mohammed was not like the buddha. He was not like jesus. He was not like he was not. He was, he was a conquering warlord, who's succeeded, right? And that is an example that is very different from the example of a guy who got crucified or the example of a guy spent his wife meditating and then teaching, right?

Speaker 2:          01:44:11       If, if the buddha had been lopping heads off, you know, add every sermon and advocating just talking endlessly about when to kill people and how many people to kill and you know, how many sex later, how to treat your sex lives. If that was, if that was just strewn throughout the buddhist teaching, I would expect buddhists to behave exactly the way we see members of isis and al qaeda and al shabaab and boko haram behave. How to treat your sex slaves. Sure. How many. So yes, how do you treat your sex lives? Why don't you taking, taking sex? I mean taking sex slaves, taking immediate. So you can. It's not adultery if you're having sex with sex slaves, it's adultery. If you're, if you're having sex with someone, you care about other women, right? Or other muslim women, but you're convenient. Um, no, you can slavery.

Speaker 2:          01:45:06       I mean this, this is the horror of of abrahamic religion. Generally. These are. ThIs is why we know these are books were not authored by a moral genius. The bible and the koran can't give you a basis to resist slavery. They did slavery, supported in both traditions, so the fact that we have after centuries decided to more or less unanimously that slavery is an abomination that proves that there's more moral wisdom to be found outside of these books than inside. At least on that point and I met and I would argue on virtually every other point of consequence. Now it's not that. It's not to say they're not jams of, of, of moral wisdom and in some of these books, but they're not best found in those books and there's so much else in there that is just that gives you the ethic of the taliban and that's, and that's.

Speaker 2:          01:46:02       It's an inconvenient fact because it is. This is what the fundamentalist fundamentalist do that. The islamists, the jihadists, look at the books, know that the members of isis right now have the theology on their side. It's not like they're ignoring the books. They're looking at the books very literally and they're saying, you know what, in here, you know, what are we, what are we doing that you don't find in the books? Essentially it's like we were just. This is just connecting the dots, you know, that was one of the videos that you would post it up on your blog that you and I discussed the guy that was standing in front of all those people that was talking about stoning people for adultery or the treatment of homosexuals and how this is not radical islam. This is just islam and that

Speaker 3:          01:46:50       was shocking and that's one of those videos where you posted or you talk about it and you get a million people that get upset at you over it. Get a million people that call you islamophobic or what have you and get upset about it and a lot of those are the same people. There was a weird thing that happened after charlie hebdo that really kind of freaked me oUt where there was a lot of liberals and progressives that we're pointing to the callousness of the cartoons as almost a justification for murdering a bunch of cartooniSts that, you know, the punching down thing kept being discussed, this weird liberal obsession with the way humor is disseminated that in somehow or another it justified or at least a rationalize the fact that they could just gunned down cartoonists, cartoonists, you're not talking about people that are doing experiments on monkeys or people that are a torturing animals mean you're not talking about people that are imprisoning other human beings. You're not talking about people that are, you know, even even stopping people from doing anything, just mocking them in cartoons

Speaker 2:          01:48:01       or, and in this case mocking also christianity and the vatican and many of the things that were interpreted, interpreted as racist, warranty. Even racist if You understood french or french politics. So it's, it's no, it's shocking. And people like the people who missed the, the train on this, people like gary trudeau, the doonesbury creator. I mean, he just, just, uh, came out against, um, uh, charlene abdo and a bunch of writers who belonged to the pen America organization, which is the whole point of which is to defend free speech. They just walked out of a gala event or declined to show up because penn had given charlene abdo the, you know, the freedom of expression award this year as they should have. And some prominent people, uh, pro laughter in protest. And um, it's, uh, no, the faculty is that, what, what is that? It's, it's political correctness and fears about being perceived as a racist and this and this notion that you should, that it makes sense to have a double standard here where you can, um, that there's some trade off between freedom of expression and freedom of religion.

Speaker 2:          01:49:19       Where, where, when the freedom that's being claimed on the religious side is the freedom not to be offended, right? To, not. So, I mean, what, what really, what's happening here is some number of muslims are demanding that non muslims follow the taboos of islam. So it's taboo for you to say anything negative about the profit or even to depict him in a drawing, right? That's, that's where it gets rewarded and we want you to follow this taboo though you are not muslim and we feel so strongly about this that we're going to kill you or threatened to make credible threats of killing you or we're just going to, when people do kill you, we're going to blame you for having gotten yourself killed, for having been so stupid and insensitive by caricaturing the profit and that whole. I mean that just has to lose. I mean that we have to.

Speaker 2:          01:50:12       We have to hold to free speech so unequivocallY that all the people over here who think that, that there is this trade off between religious sensitivity and free speech, just have to realize that that they've lost because we don't play this game with any other religion or just think about this analogy I've used before, but the book of mormon, right? It just, it just pillories mormonism. It makes mormonism look ridiculous, right? What are the mormons do in response? The mormons took out ads in playbill, right? If it was, it was very cute. What they did, they took out ads. Like if you, if you like the play, you know, you come, come and learn the real stuff. Right. It was just, it was totally civil. Good natured. Find that either my favorite cult, right? Yeah, yeah. They really are. I like them way more than I even like scientology, which is my second favorite, but, but trey parker and matt stone are not looking over their shoulders for the mormon assassins, but they've come here about muslims.

Speaker 2:          01:51:09       but briefly they didn't even. They put muhammad in a bear suit. It was just a bear. Right. And then they had to put the bear suit in a van and then they pulled it off the air war still. I had to pull it off the air and we're still. It made sense for them to pull it off the air given the actual nature of the threat. And so we've. So as I've argued, we have already lost our freedom of speech on this issue and to the, that one individual issue. We've almost the only issue on earth really. And there are people on the liberal side of this argument who think that is a good thing, that, that is a, that you are a racist to question the, the, um, the decency of that situation and it's just not truly so it's a completely insane doctrine that is, that we should not have to, we should be able to criticize to our heart's content without threats of violence as we, as we can with every other insane doctrine.

Speaker 2:          01:52:06       Do you think that that's fear, that's a fear of islam, the fear of retaliation, that they want to be on the side of the others because it's so dangerous because they are the only religion that will come out and kill you. And these same people I've found that will call people out on being islamophobic will not say a fucking peep about anti christian rhetoric. If you start talking shit about jesus or christianity, they never have a word to say about it because it's not dangerous because it's not dangerous to be on that side. I think it's much more just white guilt and, um, and political correctness. There's definitely some of that as just a sense that it's just, it is. If you take. Again, I don't mean to trash abby per se. If you met her, you'd love her. She's a great person. She's cool, but, but if this is, if you take her view of our foreign policy, if you just agreed with her down the line does check all those boxes.

Speaker 2:          01:52:59       2 million people. We did it all. We, you know, we just kill brown skin people all over the world because we just liked to sell bombs and that's really what our moral core, you know. Then yeah. Then we should have a fair amount of white guilt. Right. Then it's understandable that you think that more or less any a non western population that expresses a grievance against us has a point. Well, isn't there a real problem with saying our cars? You and I have nothing to do with that and we're a part of this weird gang called the United States of America. Whenever you say us, what we've done us. I mean we haven't done shit, but we're somehow another lumped into this group. That's a big part of it, but we've participated in a system, the existence of which is predicated on some of this shit, so existence of which existed long before you and I are ever born.

Speaker 2:          01:53:51       We're born into a system. We have zero control over. well that. And that's why I think that some of the greatest ethical changes, uh, the greatest ethical progress for us as a species is going to come not with each one of us developing an ethical code that allows us to be a hero, you know, personally and just bucking the system and bucking a trend from morning till night. We need to design systems that are more benign, you know, so it's like, it comes down to the, you know, our smartphones. Like is there a way to produce a smartphone that is ethically benign right now? At the moment it seems like there isn't, or at least we're not. We're not being so scrupulous as to find one. But you mean as far as conflict minerals? Exactly. All of it's like it could have, can, what? Could we actually be good people all the way down the supply chain, slave labor, all the way down.

Speaker 2:          01:54:39       Now I would pay more for that phone. There's no question. What do you know? There was a phone that they were trying to produce about that. It was called the fair phone going and it was non conflict minerals. It was uh, the. But it was only three j. Nobody wants a piece of shit. That's why I'm not kidding. But that's where it comes down to is called the fairfax are. Hold on. Our better nature is so tenuous that this, the difference between four g and three g could make the difference, right? It's like, yeah, let's see if they've moved up to four g, I'll fucking buy it. Right, right. It's got to be. Nobody wants to be my look at that. They're sold out. Wow. My point is no one should have to have a bad phone to be a good person. Right? So true. So we want systems that is adorable, right? When you see liberals with an iphone six, like listen son, but it's. No, but it's, it's weird. We are those liberals to look at that guy with a fair fall and that's what you get when you get a fair fault. That's perfect. That goddamn brick, something the size of a toaster, the ice tea video from 1988, that breakfast at that guy's got up to his ear is an unfair iphone. That

Speaker 1:          01:55:44       is a terrible way to sell your phone. Why would you have that fuck of ridiculous? You can't put that in your pocket sun. Yeah. Well, all of those people that buy those things and have those, those extreme liberal values, progressive values. You have to deal with the absolute reality that at the very least, your phone is being produced in a factory where people are jumping off the roof. That's a fact. Unless they're making them in Korea, the samsung phones, I think ethically, I think they have like a leg up on the iphone in the sense that you know the fox con buildings where they have nets installed around the building to keep people from jumping off the roof because it sucks so bad there, and I've heard the argument against that. All the amount of people that you got to deal with, the fact that these factories employee half a million people and the number of people that commit suicide is directly proportionate to the same number of people that would commit suicide in the regular population, but they're killing themselves at work. Like how many people kill themselves at work? Like that's not normal and they live at work. Okay, well that's not normal either. You got slaves. These are essentially wage slaves.

Speaker 2:          01:56:51       Again, these are situations where there's often, or at least sometimes no good option immediately. So when you think of like child labor laws in a place like Pakistan,

Speaker 1:          01:57:03       I know, but look at that phone dude, look how beautiful that talks to you and shit. Come on on that screen pretty. I'm not going to lose any sleep at night over your own enough phone. Thanks buddy.

Speaker 2:          01:57:16       Um, I think you and I would and millions of other people would probably. I mean, I know I would, but I think millions. If, if we could make the problem transparent, we would pay more to be truly good actors across in all of the streams of influence and um, but there are certain situations again where I just mentioned, you know, child labor laws in Pakistan, if you go, if you just say no kids can work, right? Because this is obscene. This is, you know, we haven't done this in the west for over 100 years. You know, we don't want kids in stitching together our soccer balls, right? These kids should be in school. Well, there are situations where that may be workable, right? Where you get the kid out of the factory and where he's been working 14 hours a day and you get him into school and he's got a better life.

Speaker 2:          01:58:11       But there are many situations and in places like Pakistan, where know what you've just done is you've made it impossible for this kid to work and you've further impoverished his family because he wasn't gonna go to school anyway. Now he's going to find it. He's going to be picking stuff out of a trash heap or whatever it is. And he, he does that you haven't put in place and alternative that's workable. And so we in many pro with many problems of this sort, we have to find a path forward where the first doors we open, all the choice, the doors we have to open, all suck, right? And, and there. And there are there situations, geo politically that are like that where you can either back a guy who's a dictator, right? But he's secular and he's committed to a first approximation to soca basically sane relations with the rest of the world. But he's, he really is a dictator and he really has a history of treating people badly. And he's going to treat political dissent very badly because of the possible consequences for him if he doesn't, because the society's is bursting, coming apart at the seams, um, or you can just let the islamists and the jihadist run the place. Right? And that is a, you know, there's no good option and it's understandable that we have in many cases chosen the dictator there.

Speaker 1:          01:59:32       Well that was sort of the situation with saddam hussein, right? Yeah. Me, psychopath. Children were psychopaths, murderers, serial killers, he did horrific things, but he was very secular in the way he ran his country. And so There we're were facing this on many fronts and I want to ask you this because you have these extreme opinions about these things. You have these extreme criticisms. If you could, if ultimately someone said, look, sam, you're going to be king of the world. You are going to be the guy that gets to sort this mess out. We need someone to engineer a global culture. What would be the step that you would take to try to alleviate some of the suffering of the world? Alleviate some of the bloodshed, alleviate all these conflicts. Is geopolitical conflicts

Speaker 2:          02:00:20       well in this area? The first few things I would do it we've already talked about. One is I would, I would make it absolutely clear that free speech just wins, right? So whenever you got into a charlie hebdo situation or, um, the danish cartoons, you know, the riots over those cartoons, a we've hit, we've had half a dozen situations like that in the last 10 years.

Speaker 4:          02:00:46       Um, the people that

Speaker 2:          02:00:50       even our own government can't eat what we're fighting a war on terror and we still can't defend free speech it when, when those situations are up. So for instance, this was over the, the innocence of muslims film on, remember that film? It was a youtube film that kicked off. I'm riots everywhere.

Speaker 1:          02:01:10       Was that true though? Because I, I've heard so many versions. Okay.

Speaker 2:          02:01:14       Well, I mean the main cut benghazi thing was, it's true that it did kick off a riots everywhere, but the thing that was egregious about

Speaker 4:          02:01:24       are

Speaker 2:          02:01:28       government statement there was that we basically just rather than to take the totally same line of saying, listen, in our society, we were committed to freedom of speech and you can make films about anything here and it that never gives you license to kill people, right? Uh, or to burn embassies full stop. What was adam wIth the documentary? What it was? It was a film called the innocent, I think the innocence of muslims or innocence of muslims, um, made by some crackpot somewhere. And it was just a youtube video, but it got spun as this major scandal in the muslim world and it reliably produced this, this reaction of the sort that the danish cartoons had. And um, we rather than just hold the line for free speech we have in the state department said something like, you know, we, we totally repudiate this, this attack upon islam.

Speaker 2:          02:02:27       And I like, we just distanced ourselves from it just as a way of, of trying to contain the madness, right? It was, it was a symptom of just how, how afraid we are that this sort of thing can get out of hand in the muslim world because it can write you if, if there's a rumor that occur on got burned or if some pastor in Florida threatens to burn the koran reliably, doesn't people by the dozens get killed in places like Afghanistan because they're just, you know, it's in a way that a suicide bombing between sunni and shia never produces a response of that sort. So It's a um, uh, I would hold to free speech and I would, I would just make that because free speech is the freedom that safeguards every other freedom. If you can't speak freely, you can't. if you can't criticize powerful people or powerfully bad ideas, there's just no way to, to defend society from, from slipping, slipping back into theocracy or any other kind of medieval situation.

Speaker 2:          02:03:32       And um, so you have to defend free speech even for even speech you don't like, you know, slightly holocaust denial laws in, in, in western europe. It's illegal to deny the holocaust in Germany and a few other countries. I think Australia, I'm in France and it's a ludicrous law. You should be totally free to deny the holocaust and then everyone else should be free to treat you like an idiot and you should be able to. You should be free to destroy your reputation, right? The fact that we're putting people in or that they are putting people in jail for denying the holocaust is totally counterproductive and it does look like in defensive muslim apologists, it does look like a double standard. You're going to put people in jail for denying the holocaust, but you're going to alloW, allow sharley abdo to criticize the profit. How does that make sense?

Speaker 2:          02:04:22       Right? I totally agree with them there. We should not. We should not be criminalizing any form of speech. So it was felt stupid. Yeah, and they're so. But there are people tryIng to push through blasphemy laws as a polItician in the uk who recently just said he would make islamophobia a criminal offense, right? He would. I'm sure he would make the sorts of things I say about islam criminally actionable in the uk, right? That this is a disaster at the wrong road to go down. So first thing, and I think that's a hugely important thing, and the other piece we just talked about is just getting off of oil. I mean, just imagine that one change, right? We could get off of oil and that would prove beyond any shadow of a doubt that spending your life splitting hairs about a muslim theology and demonizing the rest of the world and exporting madrasa you crazy madrasa by the tens of thousands all over the world is as the saudis do, it would prove it.

Speaker 2:          02:05:30       That is not a way to join the community of functional nations because absent inability to pull their wealth out of the ground, they have no intellectual content. They don't. They don't produce anything of value that anyone wants that that's a problem they would have to solve. Right? If they don't want to be beggared in in a global community. Well isn't that an issue? Also with the ideology of the religion is that you're not allowed to question or change or manipulate the way you approach life because it's all dictated by their religion. Finances. Well, it's part of it and just when you. When you look at societies where they keep half the population that the female half a more or less hostage and unable to get educated or to work or to drive cars are made depending on which society you're talking about this economically and socially, it doesn't make any sense if you know, in a context where you need to produce intellectual content to be part of the global conversation.

Speaker 2:          02:06:31       So the only way they've been able to do this is because of the fact that they have an extreme amount of mind that comes from more manual. Certainly if we're talking about the oil states. Yeah. And so that's. If we, if oil were no longer valuable and we actually could get to a time where that would be the case where it's an oil is just just dirty, a dirty fluid that no one wants to have anything to do with. Right. Um, it, uh, that would be, that would be a huge change. Now I'm sure there's another side of this argument where it would be a destabilizing change. I mean, just imagine how things will start to run off the rails and the middle east if oil is worthless. Right? And what Saudi Arabia going to be like maybe arguably, I think they've probably hedged their, their beds and they have so much money in other investments now that at least the royal family would be fine. But, um, it's a, um, it's a huge part of the problem and as you pointed out, it keeps us double dealing and, and, and being, um, um, a captive to the cycle of, of defending our very real economic interests. I mean really like existential interests in terms of our energy supply, uh, over the years and producing, um, a mayhem, um, as a result.

Speaker 1:          02:07:53       But how do you get someone to abandoned such a rigid ideology? How do you get someone to open their mind up to the possibility that this was just written by people? There's is just a way of governing people and keeping people in line and which is essentially every single religion that's ever been created.

Speaker 2:          02:08:10       Well, it happens. And actually there's another point that, that abby martin made, which I agree with. I just, I, I, she, she doesn't, we don't agree with it for the, we don't think this thought for the same reasons, but she pointed out that that religions change, right? That you roll back the clock. Five hundred or so years, christians were burning people alive and pro, actively proper prosecuted people for blasphemy. You had the inquisition in europe and that was every bit as much of a horror show is what's going on in Iraq now. So look, christianity can be just as bad as islam. Now it's true as a matter of history, that is in fact true. There are differences between islam and christianity that are nevertheless important, but the crucial pieces that christianity did not change from the inside. You know, christianity got hammered from the outside by a renaissanCe and reformation initially, which was bloody and horrible, but it got hammered by a, a, the forces of a scientific revolution and an attendant industrial revolution and capitalism and the rest of culture that didn't want to be shackled to theocracy for very good reason.

Speaker 2:          02:09:26       Right? And so like, once you have a real science of medicine, you don't have to ask the priest while your child was flopping around on the floor. And when the priest diagnosis as demonic possession, you don't take it seriously, right? you know, you now, you now have a neurologist to talk to. I mean this is, these are, there's progress made outside of religion which propagates back to religion and applies a lot of pressure to it. So. So christianity has been humbled and mastered by the secular world, by humanism, by science, by the rest of our conversation with ourselves. And this has not happened in the muslim world. And it should happen. It has to happen. We have to figure out how to engineer it for muslims. And it's not, again, it's not going to come from the outside, you know, the, you know, non muslims, they're not going to force it on muslims.

Speaker 2:          02:10:13       But we have to support the genuine reformers and the people who are, who are fighting for the rights of women and gays and free thinkers in the muslim world. And the hoRrible thing is that the liberals, the liberals on our side don't do that. The liberalS on our side criticize people like me and even ayaan hirsi ali, you know, a former muslim who, who has a, was being hunted by theocrats, rIght? They criticize her as a bigot for how, how unsparing her criticism is of islam. Whereas she is fighting for the rights of women to be equal in the muslim world. Right? And so there are liberal liberalism has just, has truly lost the plot here. And we have to be committed to the same. I mean, we, we are concerned about the rights of women in silicon valley, right? I mean, that's how it feet. Our concerns are now like where, why aren't, why isn't there an equal number of women in venture capital?

Speaker 2:          02:11:12       Now, what a fucking scandal, right? There are people who can go on for hours about that. Right? I'm not saying it's not a pathetic potential scandal. Great. Let's talk about that scandal. But let's talk about the fact that, you know, girls, six years of age are getting clear, direct dummies by barbarians in septic conditions. And everyone around them think is a good and necessary thing, right? Um, and you know, women who get raped get killed because they brought dishonor on their family. I mean, this is, this is. There's another planet over there that we have to interact with because it's violent. It's coming our way for no other reason, but there's another reason. There's the ethical imperative of, of figuring out how to help people who are, who are hostage to a bad system. And, and um, so yeah, let's be, let's be for women's rights globally, but what does that look like?

Speaker 2:          02:12:05       That looks like a rather staunch criticism of the way women are treated under islam. There's a lot of seemingly openminded european cultures that have opened the door for a lot of islamic immigrants or muslim immigrants to come over to their country. Now they're dealing with a lot of the issues that involve these ideologies being a part of their culture now. Yeah. Well, I mean they are in a situation similar to ours with latin America where they just, they need immigrant labor, right? They haVe a. They're actually worse than the us in terms of their replacement rate. You got a bunch of countries in western europe who are becoming these senescent populations. They're just not replacing themselves and they need immigrant labor and the real, the most of the available labor is coming from, from the muslim world. And then you also have the problem of political refugees who are leaving war torn places for obvious reasons and winding up in the closest, closest shores, you know, across the mediterranean.

Speaker 2:          02:13:07       And um, so yeah, it's a, the people they're attracting are different from, from the many muslim immigrants we get in the us who are coming to work for google or to the, they get engineering degrees are two different demographic largely. Okay. I think we've covered that suBject into the ground or so. So let me, I'll just mention the things on this list and you can send me a big kiss. And again I don't. I hope, I hope what I said about abby didn't seem mean spirited. I'm just like, she just, she actually is wrong about me. And, and if I'm wrong about her, I'm happy to be enlightened on that topic. Will be interesting to her two hours. Sit down together. That'd be hilarious. You. I'll bring the tequila. Is that what's necessary for me to bring my own tequila? Um, so what did freewill.

Speaker 2:          02:13:58       I think this comes up again, a ai, which is that something you concerned with? Yeah, I did. I actually just blogged about this and digital and spoke about it, but I think it was in my head to talk about because I heard you talk about it with someone. It might have been duncan trussell most likely. I've talked about it many times, but hey, I just got onto this. I'm on the bandwagon here because I hadn't really thought about it at all. I'm not really a scifi geek. I don't read science fiction. And the word in neuroscience has been for a very long time. And really science generally is it ai hasn't panned out. it's not that it's inconceivable was something interesting is going to happen, but it has been old style. Ai was really a dead end and we never really got out of that particular culdesac and, and we just haven't made much progress.

Speaker 2:          02:14:53       And so we have, you know, the best chess player in the world is a computer the size of this table, but, um, the prospect of having truly general artificial intelligence, uh, and super human level intelligence, that's not something we have to worry about in the near term at all. But then I, um, I heaRd a, as many people did a, my friend, my friend elan musk say something which seemed quite a hyperbolic. He thought it wAs the greatest threat to humanity, probably worse than nuclear weapons. And there was a lot of pushback against him, uh, there. and, but, you know, I actually, I know ilan and I, I, I knew he wouldn't say that without any basis for it. And it just so happened there was a conference that had been scheduled long before in puerto rico in san juan that was really like a closed door conference for the people who are really at the cutting edge of ai research.

Speaker 2:          02:15:52       It was organized by the future of life institute, which is a, a, um, a nonprofit purpose toward, to kind of looking at, at the existential threat and, and looking at, and in this case how to, how to create a but not foreseeing the, the, the, um, the existential problems around the development of ai. And it was a conference. I mean, maybe there were 70 people at the conference and it was, it was all people who are doing this work. And, um, a couple, I mean, I, I literally think I was one of maybe two people who had sort of talked his way into the conference. Everyone else was just invited and they were, they had a good reason to be there. And um,

Speaker 2:          02:16:35       what was interesting is that outside this conference, ilan was getting into a lot of pushback. Like, dude, you don't know what you're talking about. Go back to your rockets and your cars, but you don't know anything about computers apparently. And he was getting this pushback from serious people. People who like are on the edge.org website where I also occasionally published and you know, roboticists at mit and people who should, he have a former top people at microsoft, people who you think are very close to this would would say, no, no, this is 50 or 100 years out and this, this is crazy. Um, and so anyway, I went to this conference just wanting to see what was, what was up and what was interesting and I frankly scary was that at the conference even among people who were clearly drunk the kool aid and are just not willing to pull the brakes on this at all. I mean they don't even, it's arguably, it's hard to conceive of how you would pull the brakes on this because the, the, the incentive to make these breakthroughs, financial aid are so huge that, you know, if you don't do it, someone will. And so everyone's just, it's just pedal to the metal. But, um,

Speaker 2:          02:17:51       basically even the people who were going at this most aggressively were people who were conceding that huge. It was not at all fanciful to say that huge breakthroughs in artificial general intelligence could come in, uh, in, in five or 10 years. Right? Given the nature of the progress that had been made in the last 10 years. And the scary thing is that when you, when you look at the details, it's not at all obvious to see a path forward that doesn't just destroy us. It's because it's not. You think that,

Speaker 2:          02:18:30       yeah, I think most people's default bias, and it was mine frankly go into this, was well this, this probably kind of like y two k, right? Everyone is worried that, you know, the clocks are going to change and all of our computers are going to seize up and we're gonna have a real problem on our hands, but that clock changes and nothing happens. Right? So this is just, you've got a bunch of nerds worried about something that just doesn't happen. Right? So is that an analogy for the situation? And I. And it really isn't. It's what's going on here as you're talking about. And even in the most benign. Caitlin, let me just step back because I'm assuming that a lot of people understand what we're talking about here.

Speaker 5:          02:19:15       The,

Speaker 2:          02:19:16       what we're talking about is, is producing what's called strong ai or or often called agi, artificial general intelligence. You're talking about a machine that is where the intelligence is not brittle. It's not like, you know, like you know that the best chess playing computer in the world can't play tic tac toe, right? So it's like, it. All it can do is play chess. So it's not, it's not a general intelligence. You're talking about something that is a, that learns how to learn in such a way that the learning transfer is to novel situations and it's, it's, uh, doesn't degrade. If you give it a new problem, it won't. It won't get worse at the other problems that it got good at it because you're giving it new problems now. So you're getting something that's, that's that scales that can move into new territories. They can, they can be, they can become better at learning.

Speaker 2:          02:20:11       And in the, in the ultimate case can make improvements to itself mean once these machines become the best designers of the next iteration of software and hardware. Well then you get this sort of, this exponential takeoff function, or you know, often called the singularity where you have something where there's a runaway effect where they were, it's just, you can't. This is now that the capacities are, are, um, it's gotten away from you. And um, so the, you imagine what's often said is that we're going to build something. The near term goal is to build something that's human level intelligence, right? So you're going to build that. We have a chess computer that's not quite as good as a person and then it is as good as a person and now it's a little better than a person, but it's still not so much better is to be completely uncanny to us.

Speaker 2:          02:21:02       And we're thinking of doing that for everything. But the truth is that as a mirage, we're not going to build a human level agi. Once we build an agi, it's going to be better at which you'd say, once we build a true, truly generalizable intelligence, something that can prove mathematical theorems and make scientific hypotheses and test them, and, um, you know, everything a human can do, it's going to be so much better than a human because of, for a variety of reasons. One is that your phone is already better than you. I mean super human in many respects. It has a super human memory. It has a super human capacity to calculate, right? So it's a, it's a. And if you hook it to the internet, it has potential access to all of human knowledge, right? So we're not going to build a human level, agi, we're going to build something that is going to be not an agi, right?

Speaker 2:          02:21:52       It's going to be like a dumb chess playing computer until it isn't, and then it's going to be super human, right? And when you're talking about something that runs a potentially a million times or more faster than a human brain. So you're not talking about a biological system, now you're talking about photons. Um, it could make you just, you just do the math and you see that, you know, this thing is running for a week that is the equivalent of 20,000 years of intellectual progress. So it's just like what you get the people alive in a room for 20,000 years, right? With access to all of the world's information and an ability to model, you know, new experiments and computational abilities of the sort that, that we don't can't imagine. And twentY thousand years from now, what are they going to come back to you with that, that's going to be one week of this machine running, right?

Speaker 2:          02:22:46       So this is how this thing sort of escapes, like what, how do we feel that we can control the goals and the behavior of a system that is capable of making 20,000 years of progress in a week. Right? Um, and what, when you hear about how they're going about designing these systems, it is kind of uncanny. They're talking about designing, you know, like black black box and the systems were in. The first thing you want to do is not give it access to the internet, right? You're what? Just going to cage this thing, right? So because you don't want to get out, right? So, but you want to attempt it. You want to see that it. See if it's trying to get out, right? So you're going to give it like a dummy ether net port that you're monitoring, right? I mean this is the, the, the, the people doing this work at the highest level are talking about games like this where like how do you know whether the thing is lying to you that tried to make.

Speaker 2:          02:23:41       How do you, how do you know whether it knows about the internet, how do you know whether it. So this is called a honeypot strategy. Were you tempted to make certain moves in the direction of acquiring more power than you wanted to give it? And then you can just, you know, shut it off immediately. But you're talking about guys, you know, um, who are a lot younger than us, who many of whom are somewhere on the asperger's continuum who are drinking a lot of red bull and, and uh, have billions of dollars at their disposal to, to do this work. And um, uh, there's a, there's a huge responsibility not to do anything that obviously destroys the world. And the problem is even when you think even when you think about the most benign versions of this, the possibility of destroying the world is not fanciful. So like it just forget about what I just said about 20,000 years of progress.

Speaker 2:          02:24:39       Just imagine we build this. We have an ai. If someone, you know, working for facebook or whatever builds this thing, it's totally with solved what's called the control problem. We figured out how to keep this thing doing our bidding, right? It doesn't, it's not gonna design come up with near term goals that, that are antithetical to human happiness. Like because it's just a nontrivial problem. If you say, okay, just have to be committed to human wellbeing, right? If that, if that's the foundational architecture of the system, um, it depends what that means in certain cases. I mean, what if the, the thing the size, okay, if I'm, if I'm committed to human well being, I'm going to kill all the unhappy people, right? Or I'm just going to plug it electrodes into the right part of the brain of every humAn being and give them just pure pleasure, right?

Speaker 2:          02:25:22       You have to solve these problems. Um, but so let's say we build something, it's totally under our control. It works perfectly and we don't have to worry about the control problem. We still have to worry about the, the political and economic effects of building something that's going to put the better part of humanity out of work, right? I mean, you're talking about now something they can build further iterations of itself where the cost of building versions of itself now is going to plummet as more or less the cost of raw materials. You're talking about a, a labor saving device of a sort that no one has ever anticipated and we don't have a political system that can absorb that. We have a political system where we would see the cover of some, some picture of some trillionaire on the, on the cover of ink magazine, and we would hear that, that unemployment now is it 30 percent even among white collar people?

Speaker 2:          02:26:17       Um, and so we need, we need to, even if we were going to, I mean it's, it's humbling to realize that even if we were given the perfectly labor saving device, it could still, it can screw up the world. We couldn't, we couldn't share, we couldn't reliaBly share that wealth with all of humanity, which is of course what we should do, but we're in a system where the chinese and the rUssians would probably reasonably worried that we're going to use this thing to, as the ultimate tool of war, right? Both terrestrial and cyber. So just imagine the cyber war and the drone war. We could unleash on the rest of the world if we had the ultimate war making computer, right? And they didn't. So this is like a winner take all scenario that is unsustainable politically. So we have to get politically, we have to be in a position and economically where if this thing were handed to us, we could use it for benign purposes and share the wealth and where we're not even, we're not there yet.

Speaker 2:          02:27:14       And that is the best case scenario that isn't even dealing with any of the problems of this thing be having a will of its own, which of course it would. Is it possible that it's the next stage of life? Yeah. Well that's the other uncanny thing at this conference, you had a few people whose names escape me. Unfortunately I'm, I'm actually know the rules of the conference where I couldn't even mention their names if they hadn't escaped me. So I'm really, yeah. whoa. A secret rules, whether it's called the chatham house rules at certain conferences are organized under in board meetings, are organized under these rules where you. Because you want to encourage. So there's no press there. Right. And you want to encourage just free exchange of ideas and you can talk about what was talked about there, but you can't give any attribution and you can't.

Speaker 2:          02:28:05       I mean, nothing's. Nothing's formally at puerto rico. Oh, you got to go to another country. Sort of. Not really, but sort of. Yeah. I don't know that that was. I think it was just they were looking for good. Whether it was in the middle of the trees. They had plans they wanted to go to where that giant arecibo is not the, uh, one of the big telescopes they use to search for extraterrestrial intelligence from the movie contact. Isn't that in puerto rico? No, I don't know. A cbo disc. That's it. So they have some of those things in the southern hemisphere.

Speaker 2:          02:28:39       So then it was. Oh, so your question, your question about whether the next day, july, I mean, are we at caterpillar? So anyone giving birth to a butterfly that we're not aware of. Essentially one, one of these guys gave a talk that was all purpose toward making that ethical case that this is that puerto rico? Yeah. They're talking to aliens brown. Not even letting you know that already. They're already planning aliens are making these things. They're making an alien. That's what an alien looks that. But that's the thing, this thing that then gets that weird, like when you imagine this thing getting away from us. Yeah, it would be its own. Now whether or not it would be conscious. I mean I, I am actually agnostic as to whether or not a super intelligent computer would by definition be conscious. It could be unconscious, it could be that it could be nothing that is like to be that sort of system or, or it could be conscious.

Speaker 2:          02:29:30       But in any case, this one guy gave a talk. One guy gave a talk where he, where he just speculated about this thing taking off and more or less standing in relation to us. The way we stand in relation to bacteria or snails are life forms that we just squash without a qualm and that that's a total totally benign acceptable. Not, not only acceptable but to be hoped for. Right? Because we are anyway and I can sort of follow. I can follow him there at least halfway. If you imagine that these are conscious and actually become the center of the greatest possible happiness in the universe. Right? So like if it's, if you imAgine we build, if we give birth to a conscious machine that is essentially a god, right, that has interests and states of pleasure and insight and meaning that we can't even imagine.

Speaker 2:          02:30:29       Right. That is that thing by definition, by my definition becomes more important than us. Right. Then we really are like the chickens that, you know, I hope we don't kill them to eat them, but they're just chickens and we're more important because we have a greater greater scope to our pains and pleasures. And that's not to say that I don't see any moral problem with killing chickens. I'm just saying that we are more important than chickens because of the nature of human experience and it's possibilities. But if we build a machine that stands in relation to us, the way we stand in relation to chickens or or far beyond, right? I mean there's the, there's nowhere written that the spectrum of possible intelligence and somewhere close to where we are. Not only that there's nowhere written that they cannot create far better versions and we could ever possible no, that's.

Speaker 2:          02:31:19       So that's what, that's implicit in what I'm saying. We're imagining that this, this take off would be this machine create the. Yeah, makes recursive improvements to itself or to, or to new generations. Yeah. So it's just, it's changing its own code. It's learning how to build better versions of itself and it just, it just takes off. And if you put the one horrible possibility is that this is not conscious, right? That there's no good that has come of it. This, this is just blind, um, mechanism which still is godlike in its power, excuse me. And, and it could be, could be antithetical to our survival or it could just sort of part Ways with us, you know, that's the mind fuck of all mindfox is that we really are just a caterpillar and we're giving birth to this ultimate fractal intelligence that's infinite in its span.

Speaker 2:          02:32:15       You could create something within like, as you said, a week, 20,000 years of, of human intelligence and the greatest minds in it could do that in a week. And then a week later, another $100,000 more fractal keeps going on and on and on. It's exponential in its in its reach and that we really will be outdated like almost instantaneously and sorta kinda crazy that like as you said, a lot of these guys that are creating these things are on the spectrum and it was like, what? What is that from an is is it? Is it, is it possible that this, that these super intelligent human beings that have a lot of them do have the sort of asperger's he way of approaching life and a lot of them aren't on the spectrum. Who did naTure sort of design that in order to make sure that we do create these things?

Speaker 2:          02:33:09       I mean if everything in life, if life itself, everything in life, we will look at alpha wolves and the way caterpillar is interact with their environment and bugs and whatever. All that stuff's natural is human behavior. Human cognitive thinking is human. Creativity is all that nature is all that just a part of human beings. Ultimate curiosity almost inevitably leading to the creation of artificial intelligence. And was it sort of programmed into the system to create something far better than, than what we are? Well, I wouldn't say it's programmed into the system or necessarily. I think you can explain all this just by everything being pushed from behind, by it's, you know, we're following our own interests. We're trying to survive. We have all of the, the, the, uh, inclinations and abilities that evolution has selected for in us. And we have an ability to create increasingly powerful technology and the but the inevitability of this is hard to escape when they're really only two assumptions.

Speaker 2:          02:34:10       You, all you have to assume is that we are going to build better and better computers, which I think you have to assume a part from the possibility that we're just going to destroy ourselves and, and lose the, the ability to do so. But if We don't destroy ourselves some other way, we are going to continue to make progress in both hardware and software design. And the only other thing you have to assume that there's nothing magical about the wetware we have inside our heads as far as information processing is concerned. And that it's possible to build intelligent machines in silicon, right? So, and, and I don't, I don't, I can't imagine any at this point, serious scientist fundament mentally down in either of those two assumptions. I mean, there's nobody thinks that there's something magical about being, you know, neural material when it comes to intelligent processing of information that is underlying intelligence and we're just going to keep making progress.

Speaker 2:          02:35:12       So at some point this progress is going to birth a generation of computers that is better able to make this sort of progress than we are. And then it, then it takes off. And so, and so, it's something that the benign version of this that some people imagine, and this is where the whole singularity begins to sound like a religion, but there are many people in silicon valley imagining that we're going to merge with these machines. We're going to upload our, our consciousnesses onto the internet eventually and become immortal and just live in sort of the dreamscape of, of, you know, the paradise, um, and uh, that we have engineered into our machines. And, uh, I mean that, that vision presupposes a few other things that are more much more far fetched than the first two things that I, first, two assumptions I just listed.

Speaker 2:          02:36:09       one is that before this happens, we will have, we will crack the neural code and truly understand how to upload the information in human brain into another medium and that you could move, you know, consciousness, mind and consciousness into, into the internet, um, or onto some other, um, uh, you know, he could back yourself up on, on a hard drive and they're just philosophical, fundamental. so philosophical problems about what it would even mean to do that, right? I mean, in what sense are you surviving? If you back, if you copy your brain, the full contents of your brain, uh, successfully into a new medium, haven't they? Haven't, we just doubled you and then when you die, aren't you just dying every bit as much as you would be dying if we hadn't done that, I mean, that's their problems, sort of identity that had come in there that are sort of hard to solve. But um, now there are people who are looking at this as a, it's very much like we're, we're building the matrix in some sense and we're going to leap into it at the opportune moment and it's going to be glorious.

Speaker 2:          02:37:12       That is such a utopian possibility. Like that's the utopian version x mackey now, right? Which comes out. This isn't an outright now. Yeah. Yeah. So I haven't seen it yet, but I mean this is what we're talking about and that's just, that is probably the most benign version of it in an artificial person that's like, you can't distinguish it between that and a real person, but not if you've seen the film. Well I haven't, but our own consciousness is. I mean, it's so archaic in comparison. If you're talking about something that can exponentially increase in one week, 20,000 years and then on and on and on from there, why would you want to take your consciousness in and download it? I mean, it's like a chicken asking him how his day and check out exactly like, well, where am I going to go in this new world?

Speaker 2:          02:37:59       And turned it into einstein. Would it really want to go back to being an anti preferred digging in the dirt and just dropping my eggs and cutting leaves and what would it do? I mean, ultimately this is an escapable it seems like, I mean, we are our thirst for ingenuity and innovation is just never ever going to slow down and in and our ability to do that is never going to slow down either unless we, unless a supervolcano hits or haven't they. And the other side of this is there's so many problems that we would want artificial intelligence to solve for us. I mean, just what you think of, you know, curing alzheimer's or solving global economic problems, or how great would it be to have a reliably benign superintelligence, which literally would be like an oracle, right? um, or, or a god to help us solve problems that we're not smart enough to solve and that, you know, but the prospect of building that and keeping it reliably benign or keeping ourselves from going nuts in its presence, that's just a non trivial problem which in almost instantaneously recognize that part of the problem is us itself, us that, where the problem.

Speaker 2:          02:39:12       That's one reasonable fear. Yeah. Yeah. And It would also immediately recognize like, hey, this planet is only got like another billion years of reliable sunlight. Like we've gotta get the fuck out of here and propagate the universe. Well, there's a great book if you really want to get into this. There's the book by the philosopher nick bostrom a and he actually might've been the one who convinced ilan this is such a problem. And I, you know, I read his, he was one of the organizers of this conference and virtually everyone had read his book at the conference. He wrote a book called superintelligence, which lays out the whole case. And virtually everything that you've heard me say on this topic is, is some version of, of, of a concern that he expresses in that book. And um, It's a, it's a, it's very interesting because he just goes through it, you know, it's like 400 pages of systematically closing the door to every utopian way, way this could go right for us.

Speaker 2:          02:40:14       And he just says like, yeah, well know here are the things you're not foreseen about how, you know, even a, um, let me just have to anticipate absolutely everything. So if, if, if you're trying to create a machine that, that is going to read, you know, blocks spam, right? You need to create a machine that will not as a strategy for reducing spam, just kill people. Right? Mean, that's a way to reduce spam. And, but it's like, that's the only way. Yeah. It's like common sense things that you can't, you can't and you can't assume common sense in a super intelligent machine unless you, unless you have engineered it into the architecture or you have, you have taught it, you've built it to emulate your strategies where they, where you would be able to build a machine where it would not only would not merely emulate current human values, it would seek to, to be ultimately you want a, you want a, a, a machine that instantiates the values that we should have.

Speaker 2:          02:41:19       You know that. Not that we necessarily do at any moment. And what was interesting, one thing that's interesting to me in thinking about this is that the moment you think about building a machine like this, you realize that you have to solve some fundamental philosophical problems. You can't pretend that that everyone, everyone has this equivalently valuable values, right? You can't because you have to decide what to engineer into this thing. So do you want to engineer the values of jihadists and is submitted to the taliban, get a vote on what, how we should design the values of this thing? Well, I think it's Pretty, obviously the answer to that is no. Um, but then you have to cut through basically every other moral quandary we have, we, because this thing is going to be acting on the basis of a values, but initially wouldn't it be even if it's independent and autonomous, it's gonna automatically realize that a lot of our ideas are based on our own biological needs and that the, a lot of those are unnecessary for it or yet, but we will be building it.

Speaker 2:          02:42:24       I mean if we're, if we're saying we're going to build it not to be merely self interested, we're going to be, we're going to build it to conserve our interests. Whatever those deepest interests are ultimately utopian though. I mean because otherwise we're building, you know, satan and we're building, which is what ilan must say. Somebody in the, in. Yeah. I mean we're building something that's just going to readjust. We're building a wrecking ball and we're going to swing it out away from the planet and watch it hurdle back. So essentially the unabomber was right. Have you ever seen people, a few people have done this with his tax because there are sections of his texts that can read totally irrational and people are people. Occasionally we'll put a section there and then it's not until you turn the page and have already agreed

Speaker 1:          02:43:11       with it that you see who wrote it. UM, but, uh, yeah. Well, yeah, it's, it's, it's interesting to see that were. We are kind of headed toward some kind of precipice here. Do you know how he lost his mind? Do you know the story about ted kaczynski? I don't know. He was part of the harvard lsd studies. They dose the shit out of that dude. Yeah, they dosed him. He went to berkeley. I started teaching and saved Up all his money from teaching and went to the woods and started blowing up people that were involved in technology. Yeah, there's a, there's a documentary called the net and I believe it's from Germany. I believe it was a german documentary, but it's very secretive, like who was and was not involved in those harvard lsd studies. What people on the other side of those studies, and I knew richard alpert who became us but didn't kill everybody, didn't break everybody's brain.

Speaker 1:          02:44:06       No, no, but I mean he might've had a vision that he chased down, you know, add to the final point and he recognized from his experiences like, whoa, if we keep going, this is inevitable. And became obsessed wiTh it. Obviously you know, you will, you're dealing. One of the things that people try to connect his various drugs with schizophrenia and mental illnesses and most of those have not been able to stick because there's a certain percentage of people that will inevitably have issues and if those are the percentage of people that have issues with schizophrenia or various mental illnesses are almost mirrored by the percentage of people who do psychedelic drugs, various psychoactive drugs and develop these mental issue. So it might not be the cause, but it is some, it's a concern. And if you get a guy who may have a propensity for mental illness and you dose the shit out of him with lsd, yeah.

Speaker 1:          02:45:05       Might get a ted kaczynski. No, I think there are some people who certainly shouldn't take any drugs there and you know, I'd be, I've had bad experiences on, on a variety of psychedelics and as well as good ones obviously, but the bad experiences I could see in the wrong mind affecting you permanently in a way that it's not good for you or anyone else you can go off the road. I've, I went off the rails for a couple of weeks once, not really off the rails. I was totally functional. Most people probably didn't even know that I was off the rails, but uh, my, the way I describe it is that my grip on reality had gotten very slippery. Like I was kinda hanging on, like ever done chin ups with sweaty hands. Uh, yeah. Yeah. I'm not exactly sure how many you can get on before your hands give out, you know, and that's kind of how I felt.

Speaker 1:          02:45:55       I didn't feel like I had a chalk on my hands and wrists traps. I felt like I had a slippery grip on reality. Thankfully within a couple of weeks it came back to felt normal, but especially the first days afterwards, she's very intense psychedelic experience. That was like as boundary dissolving as you can get there maybe might be like an argument that there's probably several versions of of each person based on your reactions to whatever experiences you have, but that might've been version two point. Oh, of me. Like after that, like I'm a different person. I became a different person because of the and that could easily be what happened to poor old ted. It like, yeah, like you said, like some of his, his assertions, like if you look at the direction that technology is headed, I mean obviously he was fucking batshit crazy, but he said some things that weren't batshit crazy. Yeah. Yeah. Well that's the thing. So if we can make a meme, if you could just say ted kaczynski was right, right. We'll just put that in quotes. Put. Put that on twitter. His boils down to today is, is putting a photo of you with a quote taken completely out of context and everybody sort of shits on it or agrees or disagrees. It is a and fun on,

Speaker 2:          02:47:17       you know, I think it's you're, you're doing well. if you just, if you never knowingly do that. I mean if you never knowingly misrepresent your opponent, then you can get into Just knock down, drag out arguments about anything, right? and then it's all fine, but as long as you're interacting with a person's actual views, then condemn those views and criticize those views to the to to whatever degree. But if you're, if part of your proJect or the entirety of your project is simply knowingly sliming them with a misrepresentation of their views because you can get away with it because you know [inaudible], you know their, their views are either. So I'm hard to understand for most people or there's people aren't going to take the time to do it. That

Speaker 1:          02:48:04       intellectually defaming people well. It's also that there's a desire to win. A lot of people have that. They apply to debates and it makes them intellectually dishonest because they don't want to agree that someone that they might have a disagreement with may have a point or two, you mean you might disagree with the entirety of what they're saying, but somewhere along the line you might, it might be possible that you could see where they're coming from even if you don't agree, but you, it just, it throws your argument into a bad position. So you abandoned it.

Speaker 2:          02:48:39       And the thing is that the merit of an argument has no relationship to it source. Really. It's like either the argument succeeds or fails based on the, the structure of the argument and it's connection to evidence or it doesn't. Right. And it doesn't matter if it was hitler's argument for the destruction of the jews or, or you know, ted kaczynski said something true about the progress of technology. It's whether it's true or not about the progress, progress of technology. It has nothing to do with the source, but people imagine that you can. If you don't like the source, there's no burden to actually address the arguments. And if you don't like the arguments as successful rejoinder is just to trash the source, right? That's neither of those are true. If you want to deal with the, the, if you want to get at what's true in the world, you have to deal with arguments on their merits and you have to deal with evidence and, and it doesn't matter if the evidence is coming from a thoroughly obnoxious source, it's not sufficient to say, well, I, you know, I hate the source or as shorthand, we'll all have to pr to, to privilege our attention and time.

Speaker 2:          02:49:51       So if, if you know, a source is disreputable at a certain point, you know, you can just decide, well, I don't need to hear it from this person because I know this person doesn't understand what he's saying and his lied in the past. So I'll wait to hear it from somebody else. Um, so yeah, it's not that the source doesn't matter at all, but you're not actually addressing truth claims if you're just disparaging the source of those claims.

Speaker 1:          02:50:16       Um, we don't have much time left. We have less than 10 minutes. Is there anything else you'd want to get into?

Speaker 2:          02:50:23       And then we had the only other thing on this list, which is just too big for 10 minutes and we're going to get in trouble, is people, lot of people hit us with cops, baltimore, selfdefence, violence, weapons, all of that stuff.

Speaker 1:          02:50:39       Yeah. Um, that's a big one. That's an hour. That's. Yeah, at least. Yeah. And it's also, it's also we don't need to talk about it. Once artificial intelligence kicks in, we're not going to have crime anymore. Yeah, we've pretty much cured it all with the final hour. The artificial intelligence conversation sort of trumps the whole thing because it was islam is not going to important when there's robots that can read your brain. I mean, we're going to not need people anymore. So you don't need religion. You don't need lies. Charlie updos completely irrelevant. It will be a footnote in history. It'll be like there were monkeys. They through their shit. And then there were robots that can think for themselves and that was it. But forget about all that other building, the eiffel tower and the.

Speaker 2:          02:51:22       And what, what's scary about this thing is that it's, it's very hard to. I mean, so I read the book, I went to the conference, I've written about this, I've spoken about this, I hang out with people who are worried about this and it's actually still hard to keep this concern and view it just, it does feel like the moment you spend 10 minutes not thinking about it, to start thinking about it again, makes you feel like,

Speaker 1:          02:51:46       um, maybe that's just all crazy bullshit, but what am I really going to be a super intelligent machine that's going to take you to swallow the world? RigHt? Listen to that. The devil's greatest trick. Yeah. Right now with the impressionists, the devil's greatest, the, it doesn't make sense. Yeah. But it's in. This is on you.

Speaker 2:          02:52:05       Unlike other, I mean, other things have this character like it's hard to really worry about climate change because it's an abstraction. I mean, it's hot out there today, but how much hotter is it than it used to be? And, you know, um, or you know, during the cold war we knew that we had, we still have these icbm is pointed in all the wrong directions, but um, you know, we're living under the continuous threat of something going wrong and, and annihilating the better part of humanity and it's, he had his heart. It's much easier to worry about other far more easier to worry about twitter than it is to worry about that. But this thing is so kind of lampoon bubble and it's, I mean, this is kind of a goofy notion which seems just too strange to even be the substance of good credible fiction.

Speaker 2:          02:52:55       And yet when you look at the assumptions you need to get on the train, there's only two and they're not. I mean, and, and they're. And they're very hard to doubt the truth of, again, we just have to keep making progress. And there's nothing magical about biological material in terms of an intelligent system. And by the time it becomes a threat to everyone, by the time we recognize it as a threat, ideally it will be too late. Well, that's. People have different timings of the tate where they call the takeoff, you know, whether it's a hard take off or something more gradual, but um, yeah, there's a, a, it's the kind of thing that could happen in secret and all of a sudden things are different in a way that no one understands. And you can also make this argument that if you look at all the issues that we have in this world, that so many of them are almost unfixable without this.

Speaker 2:          02:53:53       Yeah. Again, that's what I, that's what I said is the other side. I said, I think in my blog post, the only thing scarier than the development of strong artificial artificial intelligence is not developing it because we need, we need that. We have problems for which we need to. Intelligence is our only asset ultimately. You know what I mean? It's everything. It's given us everything good. Right? And why should we accept our limited biological, biological intelligence? We can come up with something infinitely more intelligent and it's a progress in this, in this area. It seems almost an intrinsic good. I mean, jUst because we want to, we want to be able to whatever you want, clean the ocean, you want to be able to solve problems and you want to be able to anticipate the new, the, the negative consequences of your doing good things and mitigate those. And intelligence is just, it's the thing you used to do that puts on their freaK. Everybody out. Sam Harris out blog. You blog, sam harris.org, sandbox.org and podcast. Sam harris on twitter. Uh, sam harris. Org without twitter. Yeah. Thanks man. I appreciate it. Always a good time. Lots of fun. Yeah. All right.

Speaker 3:          02:55:04       Much love my friends. We will be back on friday with rich roll until then. See soon. Bye. Bye.

Speaker 6:          02:55:28       Exactly. Never met him, but.