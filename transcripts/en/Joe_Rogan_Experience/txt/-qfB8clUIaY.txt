Speaker 1:          00:00:06       Boom. Hello Ben.

Speaker 2:          00:00:08       Hey there. Good to see you, man. Yeah, it's a pleasure to be here. Thanks for doing this. Yeah, yeah. Thanks. Thanks. Thanks. Thanks for having me. I've been. I've been looking at some of your shows in the last few last few days just to get a sense of how you're thinking about ai and crypto and the various other things. I'm involved in this. It's been interesting.

Speaker 1:          00:00:28       Well, I've been following you as well. I've been paying attention to a lot of your lectures and talks and different things you've done over the last couple days as well. Getting ready for this. It's a Ai is a. either people are really excited about it or they're really terrified of it. Those are the sort of. It seems to be the two responses. Either people have this dismal view of these robots taking over the world or they think it's going to be some amazing sort of symbiotic relationship with that we have with these things. It's gonna evolve human beings past the monkey stage that we're at right now.

Speaker 2:          00:01:00       Yeah, and I, I tend to be on the leather more positive side of this dichotomy, but I think one thing that has struck me in recent years is many people are now, you know, mentally confronting all the issues, running ai for the first time and I mean I've been working on ai for three decades and I first started thinking about ai when I was a little kid in the early, late sixties and early seventies when I saw ais and robots on the original star Trek. So I guess I've had a lot of cycles to process the positives and negatives of it where it's now like suddenly most of the world is thinking through all this for the first, for the first time. And you know, when you first wrap your brain around the idea that there may be creatures 10,000 or a million times smarter than human beings at first. This is a bit of a shocker. Right? And then, I mean it takes a while to internalize this into your worldview.

Speaker 1:          00:02:02       Well, it's that there's also, I think there's a problem with the term artificial intelligence because it's, that's, it's intelligent. It's there. It's a real thing. Yeah. It's not artificial. It's not like a fake diamond or fake Ferrari. It's a real thing and it.

Speaker 2:          00:02:19       It's not a great term and there's been many attempts to replace it. Would synthetic intelligence for, for example, but for better or worse, I get ai is there. It's part of the popular imagination that seems that it's an imperfect word, but it's not going away.

Speaker 1:          00:02:37       Well, I, I. my question is like, are we married to this idea of intelligence and of life being biological, being carbon based tissue and cells and blood and or insects or mammals or fish? Are we married to that too much? Do you think that it's entirely possible that what human beings are doing, what people that are at the tip of ai right now that are really pushing the technology where they're doing is really creating a new life form that it's going to be a new thing that just the same way we recognize wasps and buffaloes and artificial intelligence is just going to be a life form that emerges from the creativity and ingenuity of human beings.

Speaker 2:          00:03:21       Indeed, so I've long been an advocate of a philosophy I think of as, as pattern isn't like it's the pattern of organization that appears to be the critical thing and the, the, you know, the individual cells and going down further the molecules and particles in our body or our turning over all the time. So it's not in this specific combination of elementary particles which makes me who I am or makes you who you are. It's a pattern by which they're organized and the patterns by which they change over time. So if we can create digital systems are quantum computers or femto computers or whatever it is, manifesting the patterns of organization that Constitute Intelligence. I mean then then there you are there, there, there is intelligence, right? So that, that's not to say that you know, consciousness and experiences just about patterns of organization. There may be more dimensions to it, but when, when you look at what constitutes intelligence thinking, cognition, problem solving, you know, it's the pattern of organization, not, not this specific material as as, as far as we can tell. So we can see no reason based on all the science that we know so far that you couldn't make an intelligent system of some other form of matter rather than the specific types of atoms and molecules that make up human beings. And it seems that we're, we're well on the way to being able to do so.

Speaker 1:          00:04:52       When you're studying, when you're studying intelligence, you're studying artificial intelligence, do, did you spend any time studying the patterns that insects seem to cooperatively behave with? Like how leafcutter ants build these elaborate structures underground and build these giant colonies. And did you study how it did? I did,

Speaker 2:          00:05:15       actually, yes. So I, I, I sort of grew up with the philosophy of complex systems which was championed by that, by the Santa Fe Institute in, in, in the 19 eighties. And the whole concept that there is an interdisciplinary complex system science which includes, you know, biology, cosmology, psychology, sociology. There's sort of universal patterns of, of Self Organization and you know, aunts and ant colonies have long been the paradigm case for that. And I, I used to play with the ant colonies in my backyard. Wow. When I was a kid and you'd lay down food and certain patterns, you'd see how their answer down. Pheromones in the colonies are organizing it in a certain way, and that's an interesting self organizing complex system on that zone. It's lacking some types of adaptive intelligence that that human minds and human societies have been, but it has also interesting self organizing patterns.

Speaker 2:          00:06:17       This reminds me of the novel Solaris by Stanislaw Lem, which was published in the sixties, which was really quite, quite a deep novel, much deeper than the movie that was made of it. Did you ever read that book? So there is. So what? I'm not familiar with the movie either. Who will say where there was an amazing brilliant movie by Tarkovsky, the Russian director from the late sixties. Then there was a movie by Steven Soderbergh which was sort of clammed up and Americanized and that was fairly recent, right? Ten years ago, but that wasn't. Didn't get all the deep points and novel, the original novel. In essence, there's this, there's this ocean on coating the surface of some alien planet which has amazingly complex fractal patterns of organization and it's also interactive like the patterns of organization on the Ocean respond based on what you do and when people get near the ocean, it causes them to hallucinate things and even caused them to see Simulacra of people from their past, even the like the person who they'd most harmed or injured in their past appears and interacts with them so clearly.

Speaker 2:          00:07:27       This ocean has some type of amazing complexity and intelligence from the patterns that displays and from the weird things that reeks in your mind so that the people on earth try to understand how the ocean is thinking. They send a scientific expedition there to to interact with that ocean, but it's just so alien. Even though monkeys with people's minds include these doing complex things, no two way communication is ever is ever established and eventually the human expedition gives up and goes home. So it's a very Russian ending to the novel. I guess it's not. I saw that, but that the. The interesting message there is, I mean there can be many, many kinds of intelligence, right? I mean, human intelligence is one thing. The intelligence of an ant colony is a different thing. The intelligence of human society is a different thing. Ecosystem is a different thing and there could be many, many types of ais that we could build with many, many different properties.

Speaker 2:          00:08:37       Some could be wonderful to human beings, some can be horrible to human beings, some could just be alien minds that that we can't even relate, relate, relate to very, very well. So we we have a very limited conception of what an intelligence is. If we just think by close analogy to to human minds and this. This is important if you're thinking about engineering or growing are the life forms. They're artificial minds because it's not just can we do this? It's what kind of mind are, are we going to engineer or evolve and there's. There's a huge spectrum of possibilities.

Speaker 1:          00:09:17       Yeah, that's one of the reasons why I asked you that if we'd created, if human beings had created some sort of an insect and this insect started organizing and developing these complex colonies like a leaf cutter and building these structures underground, people would go crazy. They would panic. They would think these things are organizing. They're gonna. They're going to build up the resources and attack us. They're going to try to take over humanity. I mean this what, what people are worried about more than anything when it comes to technology, I think is the idea that we're going to be irrelevant, that we're going to be a antiques and that something new and better is going to take our place, which is a, which is almost double, so we're thinking worried about it because it's sort of the history of biological life on earth. I mean, what is there as complex things?

Speaker 1:          00:10:05       They become more competent with single cell organisms to multicellular organisms. That seems to be a pattern leading up to us and us with this unprecedented ability to change our environment. That's what we can do, right? We can manipulate things, poison the environment. We can blow up entire countries with bombs if we'd like to, and we can also do wild creative things like send signals through space and land on someone else's phone on the other side of the world almost instantaneously. We have incredible power, but we're also. We're also so limited by our biology. Yeah. The thing I think people are afraid of, I'm afraid of, but I don't know if that makes any sense. Is that the next level of life, whatever artificial life is or whatever the, the, the human symbiotic is that it's going to lack emotions. It's going to lack desires and needs and all the things that we think are special about us, our creativity, our desire for attention and love, all of our camaraderie, all these different things that are sort of programmed into us with our genetics in order to advance our species that we were so connected to these things.

Speaker 1:          00:11:14       But there's so the reason for war that the reason for the lies, deception, thievery. There's so many things that are built into being a person that are responsible for all the woes of humanity, but were afraid to lose those. I think it's almost,

Speaker 2:          00:11:32       and by this point that humanity is going to create

Speaker 2:          00:11:38       synthetic intelligences with tremendously greater general intelligence and practical capability than human beings have. I mean, I think I know how to do that with the software I'm working on with my own team, but if we fail, you know there's a load of other teams who I think are a bit behind us, but they're going in the same direction. Now. I feel like you're at the tip of the spear with this stuff. I do, but I also think that's not the most important thing from a human perspective. The most important thing is that humanity as a whole is quite close to this, this threshold event. Right. So how far do you think? It's quite close by my own gut feeling. Five to 30 years. Let's say that's pretty close, but if I'm wrong and it's 100 years, like in the historical time scale, that sort of doesn't matter.

Speaker 2:          00:12:27       It's like, did the Sumerians create civilization 10,000 or 10,050 years ago? Like what? What difference does it make? Right. So I think we're quite close to creating super human artificial general intelligence and that's in a way almost inevitable given where we are now. On the other hand, I think we still have some agency regarding whether this comes out in a way that respects human values and culture, which are important to us now given who and what we are or that is essentially indifferent to human values and culture in the same way that we're mostly indifferent to chimpanzee values and culture at that at this point. Completely indifferent to insect values and culture. Not Completely, but if you think about it, I mean if I'm building a new house, I will bulldoze those a bunch of events, but yet we get upset if we extinct an insect species.

Speaker 2:          00:13:28       Right? So we, we carry, we carry it to some level but not but we. But we would like the Super Ais to care about us more than we care about insects or, or grade. Absolutely. Right. And I think this, this is something we can impact right now and to to, to be honest, I mean in a certain part of my mind, I can think, well like in, in the end, I don't matter that much, my four kids don't matter that much, my granddaughter, it doesn't matter that much like we are patterns of organization in a very long lineage of patterns of organization and they matter very much to you and other, you know, dinosaurs came and went and neanderthals came and went. Humans may come and go, the Ai that we create may come and go and that's the nature of the universe. But on the other hand, of course in my heart, from my situated perspective as an individual human, like if, if some ai charged to annihilate my, my 10 month old son, I would try to kill that Ai.

Speaker 2:          00:14:33       Right? So as, as a human being situated in this specific species, place in time, I care a lot about the condition of, of all of us humans. And so I would like to not only create a powerful general but, but create one which, which is, is going to be beneficial to humans and other life forms on the planet even while in some ways going, going beyond every, everything that we are right. And there can't be any guarantees about something like this. On the other hand, humanity has really never had any guarantees about anything anyway. Right? I mean, since, since, since, since we created civilization. We've been leaping into the unknown one time after the other in the somewhat conscious and self aware way about it from, you know, agriculture to language, to math, to the industrial revolution. We're leaping into the unknown all the time, which is part of why we're where we are today instead of just another animal species.

Speaker 2:          00:15:44       So we can't have a guarantee that Agi, artificial general intelligence is we create, are going to do what we consider the right thing given our current value systems. On the other hand, I suspect we can bias the odds in the favor of, of human values and, and culture. And that's something I've. I've put a lot of thought and work into, alongside the, you know, the basic algorithms of, of artificial cognition is the issue that the initial creation would be subject to our programming, but that it could perhaps program something more efficient and design something like if you build creativity, you have to create, I mean, general generalization is about creative writing, right? Yeah. But is the issue that it would choose to not accept our values, which it might find clearly will choose not to accept our values and we want it to choose not to accept all of our values.

Speaker 2:          00:16:46       So it's more a matter of whether the ongoing creation, evolution of new values occurs with some continuity in respect for the previous one. So I mean, uh, with I've, for human kids now one is a baby, but the other three are adults, right? And with each of them I took the approach of trying to teach the kids what my values were, not just by preaching at them, by entering into shared situations, but then, you know, when your kids grow up, they're going to go in their own different directions. Right? And these are humans, but they all have the same sort of biological needs, which is one of the first place. Yeah, there's still as an analogy, I think the ais that we create, you can think of us as our mind children and we're starting them off with our culture and values if we do it properly or at least with a certain subset of the whole diverse self-contradictory mess of human culture and values, but you know, they're going to evolve in, in a different direction.

Speaker 2:          00:17:52       But you want that evolution to take place in their reflective and, and, and caring way rather than the heatless way. Because if you think about it, the average human a thousand years ago or even 50 years ago would have thought you and me, we're like hopelessly immoral miscreants who had abandoned all the valuable thing things in life. Uh, my, my, my, my hand. I mean, I'm, I'm, uh, I'm an. I'm an infidel, right? I don't know. I haven't gone to church, uh, for I, I guess I mean my, my, my mother's lesbians, right? I mean, there's all these things that we take for granted now that not that long ago were completely against what most humans considered maybe the most important values of life. So I mean human values itself is completely a moving, a moving target. So think in our generation, moving in our, in our generation pretty radically, very radically.

Speaker 2:          00:18:49       When I think back to my childhood, I, I, I lived in New Jersey for nine years of my childhood and just the level of racism and antisemitism and sexism that were just normal, ambient and taken for granted. Then this was, this. Was this when you're between. Because we're the same age. We're both one. Yeah, yeah, yeah, yeah. Born in 66. I lived in Jersey from 73 to 82, so I was there from 67 to 73. Oh yeah. Yeah. So yeah, I'm in my, I'm in my sister went to the high school prom with a, with a black guy and so we got our car turned upside down, the windows of our house smash. And it was like a human hugh mungus thing and it's almost unbelievable now, right? Because now no one would care care whatsoever. It's, it's, it's, it's just, it's just life, right? Certainly the, some fringe parts of his sculpture here, but, but still the point is there is no fixed list of, of values, human values.

Speaker 2:          00:19:56       It's an ongoing evolving process and what you want is for the evolution of the AIS values to be coupled closely with the evolution of human values rather than going off in some other, the different direction that we can't even understand that this is literally playing God, right? I mean if you're talking about like trying to program in values, I don't think you can program in values that fully you can program in a system for learning and growing values and here again, the analogy with human kids, it's not hopeless like telling, telling your kids these are the 10 things that are important doesn't work that well, right? What works? What works better is you enter into shared situations with them, they see how deal with the situations, you guide them in dealing with real situations and that forms their system of values and this is what needs to happen with ais.

Speaker 2:          00:20:56       They need to grow up entering into real life situations with human beings, so the real life patterns of human values, which are worth a lot more than the families that we annunciate formally wrote, the real life pattern of human values gets inculcated into the intellectual DNA of the AI systems. And this is part of what worries me about the way the AI field is going at this moment because I mean most of the really powerful, narrow ais on the planet now are involved with like selling people stuff they don't need spying on. People are like figuring out who should be killed or otherwise abused by some government. Right? So if, if the early stage Ai's that we build turn into general intelligences gradually and these general intelligence is our, you know, spy agents and advertising agents. Then like what, what, what mindset do these early stage ais have as they grow up?

Speaker 2:          00:21:56       Right? If they don't have any problem morally and ethically with manipulating us, which we're very malleable, right? We're so easy to manipulate what we're teaching them. We're teaching them to manipulate tape on where rewarding them for doing it successfully. So this is, this is one of these things that from the outside point of view might not seem to be all that intelligent it, it's sort of like gun laws in the U. s living in Hong Kong. I mean most people don't have a bunch of guns sitting around their house and coincidentally there, there are not that many random shootings happening in Hong Kong. So yeah, you look in the UK. Yeah, you look in the US, it's like somehow you have laws that allow random lunatics to buy all the guns they want and you have all these people getting shot. So similarly like from the outside you could look at it like this species is creating the successor intelligence and almost all the resources going into creating their successor intelligence are going into making ais to do surveillance like military drones and advertising agents to brainwash people into buying crap they don't need.

Speaker 2:          00:23:12       Now what do you think? Well what's wrong with this picture? Isn't that just because that's where the money is, like this is the introduction to it and from then we'll find other uses and applications for it. But like right now, that's where the thing is, there's a lot of other applications, financial app, financially viable applicant. Oh yeah. The applications that are getting the most attention are the financial lowest hanging fruit. Right? So for, for, for, for, for example, among many projects I'm doing with my singularity net team, we're looking at applying ai to diagnose agricultural disease. So you can, you can look at images of plant leaves, you can look at data from the soil and the atmosphere, and you can project whether disease and a plant is likely to progress badly or not, which tells you do you need medicine for the plant, do you need pesticides now this, this is an interesting area of application.

Speaker 2:          00:24:06       It's probably quite financially lucrative in in a way, but it's a more complex industry than, than selling stuff online. So the fraction of resources going into ai for agriculture is very small. Then like a ecommerce or something very specific aspect of agriculture to predicting diseases. Yeah. Yeah. But there's, there's a lot of specific aspects, right? So I mean ai for medicine, again, there's been papers on machine learning applied to medicine since the eighties and nineties, but the amount of effort going into that compared to advertising or surveillance is very small now. This has to do with the structure of the pharmaceutical business as, as compared to the structure of the tech business. So you know, when you look into it, there's, there's good, there's good reasons, there's good reasons for, for everything, right? But nevertheless, the way things are coming at coming down right now is certain biases to the development of early stage. Ai's are, are very market and, and you could, you could, you could see them and I'm in, I'm trying to do something about that together with my colleagues and in singularity in that. But of course we're. So we're sort of a David versus goliath thing.

Speaker 3:          00:25:22       It seemed, well of course you're trying to do something different and I think it's awesome what you guys are doing, but it just makes sense to me that the first applications are going to be the ones that are more financially viable. It's like,

Speaker 2:          00:25:35       well, the first applications were military, right until about 10 years ago, 85 percent of all funding into ai was from us plus plus Western Europe military.

Speaker 3:          00:25:45       Well, what I'm getting at is it, it seems that money and and, and commerce are inexorably linked to innovation and technology because there's this sort of thing that we do as a culture where we're constantly trying to buy and purchase bigger and better things. We always want the newest iphone, the greatest, you know, a laptop. We don't want them, the coolest electric cars, whatever, whatever it is, and this fuels innovation. This, this desire for new, greater things. Materialism and a lot of ways fuels innovation because this is

Speaker 2:          00:26:18       those. But I think there's an argument that as we approach a technological singularity, we need new systems because if you look at that, things have happened during the last century. What's happened is that governments have funded most of the core innovation I'm in. This is well known that like most of the technology and the, the smartphone was funded by US government, a little about European government, GP, gps and the batteries and everything. And then companies scaled it up that they made, they made it user friendly, they decreased cost of manufacturing and this process occurs with a certain time cycle to it or like government spends decades funding core innovation and universities and then industry spends decades figuring out how to scale it up and make it palatable to users. And you know, this matured probably since World War II, this sort of modality for technology development, but now that things are developing faster and faster and faster, there's sort of not time for, for that cycle to occur where the government and universities incubate new ideas for awhile and then technology scales it up.

Speaker 2:          00:27:32       So genie's out of the bottle essentially. Yeah. But we still need a lot of new amazing creative innovation to happen. But somehow or other new new structures are going to have to evolve to, to make it happen. And you can see everyone's struggling to figure out what these are. So I mean this is why you have, I mean you have big companies embracing open source, Google releases, tensorflow, and there's a lot of, lot of other different things. And I think, I think some projects in the cryptocurrency world had been looking at that too, like how do we use tokens to incentivize, you know, independent scientists and inventors to, to do new stuff without them asking to be in the government research lab or in a big company. So I think we're going to need the evolution of new systems of innovation and of, of technology transfer as things are, are developing faster and faster and faster. And this is another thing that sort of got me interested in the whole decentralized world and in the blockchain world is the promise of new modes of economic and social organization that can, you know, bring more of the world into the research process and accelerate the technology transfer

Speaker 3:          00:28:45       process. I definitely want to talk about that, but one of the things that I want to ask you is when, when you're discussing this, I think what you're saying is have one very important point that we need to move past the military gatekeepers of tech.

Speaker 2:          00:28:58       Not just military, no. It's big tech which are at advertising agencies in social media.

Speaker 3:          00:29:06       The things that are constantly predicting your next purchase,

Speaker 2:          00:29:10       right? Yeah, because if you, if you think about it, and I'm in even in a semi democracy look like we have in the US, I mean those who control the brainwashing of the public in essence control who, who, who votes for what and who controls the brainwashing of the public is advertising agencies and who increasingly are the biggest advertising agencies or are the big tech companies who are accumulating everybody's data and using it to, to program their minds to buy things. So this is what's programmed the global brain of, of, of, of the human race. And of course there are close links between big tech and the military. Let's look at Amazon has what? Twenty 5,000 person headquarters in Crystal City, Virginia, right next to the Pentagon and in China it's even more direct and unapologetic, right? So it's a new like military industrial advertising complex, which is his guiding the evolution of the global brain on the planet, which with this past election, right, with all the intrusion by foreign entities trying to influence the election that they have these giant houses set up to write bad stories about whoever they don't want to be in office.

Speaker 2:          00:30:29       Yeah. In a way that's almost a red herring, but I mean they're Russian stuff is almost a red herring. But it revealed what the processes are, which, which are used to program because I think the whatever programming of Americans' minds is done by the Russians is many minuscule compared to the programming of Americans' minds by my advisee, American American corporate and government elite. So it's fascinating that anybody's even jumping in as well as an elite. Sure. It's, it's, it's, it's, it's interesting if you look at what's happening in China that's like, yeah, yeah, yeah. They're, they're way better than the, than we are much more horrific. Right. And that's all. It's more, it's more professional, it's more polished, it's more centralized. On the other hand, for almost everyone in China, China is a very good place to live and you know, the level of improvement in that country in the last 30 years has just been astounding, right?

Speaker 2:          00:31:34       I mean, you can't, you can't argue with how much better it's gotten there since shouting took over. It's, it's tremendous because they're not, they, they embraced capitalism to a certain extent. They've created their own unique system with what labels you give. It is, it's almost arbitrary. They, they've created their own unique system as a, you know, crazy hippie, libertarian, a narco socialist, freedom loving, maniac. That system rubs against my grain in many ways. On the other hand, empirically if you look at it, it's improved the wellbeing of a, of a tremendous number of people. So hopefully it evolves and it's one style. But the way it's evolving now is not in a more positive freedom. Love. Well, it's not in the more freedom, loving and an archaic direction. One would say it's positive in some ways and negative and others like most complex Hong Kong. Why do you live there?

Speaker 2:          00:32:30       Um, I fell in love with a Chinese woman. Hey, go. She's crazy. She has great reason. We had a baby recently. She, she's not from Hong, she's from mainland China. I met her when she was doing her phd in computational linguistics and Shaman, but that, that, that was what sort of first got me to spend a lot of time in China, but then I was doing some research at Hong Kong Polytechnic University and then my good friend David Hansen was visiting me in Hong Kong. I introduced him to some investors there which ended up with him bringing his company, Hanson robotics to Hong Kong. So now after I moved there because of falling in love with a rating, then I brought my friend David there than Hanson robotics. Grew up there and there's actually a good reason for Hanson robotics to be there because I'm in the best place in the world.

Speaker 2:          00:33:22       The manufacturer complex electronics is in Shenzhen, rarely across the border from Hong Kong. So now I've been working there with Hanson robotics on the Sophia robots and other robots for, for, for awhile. And I've accumulated the whole ai team there around Hanson robotics and ai and singularity in that. So I'm in by, by now. I'm there because my whole ai and robotics teams are there. It makes sense. Um, do you follow, uh, the State Department's recommendations to not use walway devices and they believe that they're all know, even heard that. I mean if the Chinese are spying on us, you know, I'm sure. You know, when I lived in my lived in Washington DC for nine years, I did a bunch of consulting for various government agencies there. And my wife is a communist party member actually. Well, just because she joined in high school when it was sort of suggested for her to join.

Speaker 2:          00:34:17       So I'm, I'm, I'm sure I'm being watched by multiple governments. It doesn't, I don't have any secrets. It doesn't really matter. I'm not in the business of trying to overthrow the government. And I'm in the business of trying to bypass traditional governments and traditional monetary systems and all the rest by creating new methods of organization of people and information. You understand that what you personally. But it is unusual if the government is actually spying on people through these divides out. It's unusual. It's unusual at all. I mean, I, I, I mean without going into too much detail, like when I was in dc working with various government agencies, it became clear there is tremendously more information obtained by government agencies than most people realize, well, this was, this was true way before snowden and wikileaks and all these revelations and what is publicly understood now is probably not the full scope of, of, of the information that governments have others.

Speaker 2:          00:35:24       So I'm in privacy is, is pretty much dead. And David Brin, do you know David Brin? No. You should definitely interview David and he's an amazing guy, but he's a well known science fiction writer. He's based in southern California, San Diego. But he wrote a book in Oh, years ago called the transparent society where he said there's two possibilities, surveillance and sousveillance. It's like the power elite watching everyone or everyone watching everyone. I think everyone watching everyone. Well, yeah, but he. So he articulated this as the essentially the only two viable possibilities and he's like, we should be choosing and then creating which of these alternatives we want. So now, now the world is starting to understand what he was talking about. But back when he wrote that book, you wrote the book. Oh, I can't remember. I mean it was well more than a decade. That gets weird, but some people just nail it on the head decades in advance.

Speaker 2:          00:36:22       I mean, most of the things that are happening in the world now we're foreseen by a stanislaw lem, the Polish Arthur mentioned volunteer church. And a friend of mine who was the founder of Russian Ai. He wrote a book called the phenomenon of science in the late sixties. Then, you know, in 1971 or two when I was a little kid, I read a book called the promethium project by a Princeton physics called Gerald Gerald Fund Berg. You've read a physical book when you're five years old. I started reading when I was two and my grandfather was a physicist, so I was reading a lot of stuff then. But he Feinberg in this book, he said, you know, within the next few decades, humanity is going to create nanotechnology, it's going to create machines smarter than people and it's going to create the technology to allow human, biological immortality. And the question will be, do we want to use these technologies, you know, to promote rampant consumerism or do we want to use these technologies to promote, you know, spiritual growth of our, of our consciousness into new dimensions of experience and what fonder proposed in this book in the late sixties, which I read in the early seventies, he proposed the UN should send a task force out to go to everyone in the world, every little African village and educate the world about nanotech life extension and an Agi and get the whole world to vote on whether we should develop these technologies toward consumerism or toward consciousness expansion.

Speaker 2:          00:37:49       So I read this from a little kid. It's like, this is almost obvious. This makes total sense. Like, why? Why does everyone understand this? Then I tried to explain this to people. I'm like, Oh shit, I guess it's gonna be awhile till the world catches on, so. So I instead decided I should build a spacecraft, go away from the world at rapid speed and come back after like a million years or something when the world was far more advanced. So covered in dust. Yeah. Right. So now we'll. Then you go another million years or so now, pretty much the world agrees that life extension, Agi and nanotechnology or plausible things that may come about in the near future. The same question is, is there that that Feinberg saw like 50 years ago, right? The same question. Is there like, did we develop this for rampant consumerism or do we develop this for amazing new dimensions of consciousness expansion and mental growth, but the UN is not in fact educating the world about this and pulling them to decide democratically what to do on.

Speaker 2:          00:39:07       On. On the other hand, there's the possibility that by bypassing governments and the UN and doing something decentralized, you can create a democratic framework, you know, within which you know, a broad swath of the world can be involved in a participatory way in guiding the direction of these advances. Do you think that it's possible that instead of choosing that we're just going to have multiple directions, that it's growing in that there's going to be consumer. There will be multiple directions and it's that that's inevitable. It's more a matter of whether anything besides the military advertising complex gets a shake. So I mean if you look in the software development world, open source is an amazing thing, right? Linux is awesome and it's led to so much ai being open, open source now. Now Open source didn't have to actually take over the entire software world like Richard Stallman one and in order to have a huge impact, right?

Speaker 2:          00:40:07       It's enough that it's a major force. So I mean it's very hippy concept, isn't it? Open source and a lot of ways in a way, but, but yet ibm, IBM has probably thousands of people working on Linux. Right? So like apple began as a hippie concept, but it became very practical. Right? So I mean something like 75 percent of all the servers running the Internet are based in Linux. You know, the vast majority of mobile phone oss is, is, is Linux, right? So this Hippie, vast majority being android is Linux. Yeah. Yeah. So I'm in this hippie crazy thing where no one owns the code. It didn't have to overtake the whole software economy and become everything to become highly valuable and then inject a different dimension into things. And I think the same is true with decentralized ai, which we're looking at with singularity and that it doesn't have, we don't have to actually put Google and, and the US and Chinese military and tencent out of business. Right. Although if that happens that that's fine. But W we, it's enough that we become an extremely major player in that ecosystem so that this, you know, participatory and benefit oriented aspect becomes a really significant component of how humanity is, is developing general intelligence.

Speaker 3:          00:41:36       W is accepted, generally accepted that human beings will consistently and constantly innovate. Right. It just seems to be characteristics that we have. Why do you think that is and what do you think that, especially when it, in terms of creating something like artificial intelligence, like why build our successors? Like why, why do that? Like what is, what is it about us that makes us want to constantly make bigger, better things?

Speaker 2:          00:42:02       Well, that's an interesting question in the history of biology, which I may not be the most qualified person to answer. It is an interesting question and I think it has something to do with the weird way in which we embody various contradictions that we're always trying to resolve locally. You mentioned ents and answer social animals, right? Worse. Like cats are very individual. We're like trapped between the two, like we're somewhat individual and somewhat social. And then. And then since we created civilization, it's, it's, it's even worse because we have certain aspects which are, which are wanting to conform with the group and the tribe and others which are wanting to innovate and break out of the. And we're sort of trapped in these biological and cultural contradictions which tend to drive innovation. But I think there's a lot there that no one understands in the roots of the human psyche evolutionarily. But as an empirical fact, what you said is, is, is, is very true, right? Like we, we're driven to seek novelty. We're driven to create new things. And this is probably one of the factors which is driving the creation of Ai. I don't think that alone would make the creation of ai inevitable, but the thing,

Speaker 3:          00:43:29       why don't you think it would make it inevitable if we consistently innovate? And it's always been a concept. I mean, you were talking about the concept existing 30 plus years ago.

Speaker 2:          00:43:37       Well, I think a key point is that there's tremendous practical economic advantage and status advantage to be gotten from ai right now. And this is driving the advancement of ai to be incredibly rapid, right? Because there are some things that are interesting and would use a lot of human innovation, but they get very few resources. So for example, my, my oldest son's Arthur Oostra, he's doing his phd now. What is this Zarathustra? My kids are Pfister, Amadeus, Debbie lawn, ulysses Shaharazad. And then a new one is corky qrs, which is an acronym for quantum organized rational expanding intelligence. So I was never happy with Ben. It's a very boring name. So yeah. Yeah. I had, I had, I had to do something more interesting with my kids. Anyway, Zarathustra is doing his phd on the application of machine learning to automated theorem proving basically make ais that can do mathematics better.

Speaker 2:          00:44:45       And to me that's the most important thing we could be applying ai to because you know, mathematics is the key to all modern science and engineering. My Phd was in math originally, but the amount of resources going into ai for automating mathematics is not large at this present moment, although that's a beautiful and amazing area for invention and innovation and creativity. So I think what's driving our rapid pushed or dozing ai, I mean it's not just our creative drive, it's the fact that there's tremendous economic value, military value and human value. I mean curing diseases, teaching kids, there's tremendous value in almost everything that's important to human beings in, in building ai, right? So you put that together with our drive to create an interface and this becomes an almost unstoppable force within, within human society. And what we've seen in the last, you know, three to five years is suddenly, you know, national leaders and Titans of industry and even like pop stars, right?

Speaker 2:          00:45:49       They've woken up to the concept that wow, smarter and smarter ai is real and this is going to get better and better like within years to decades, not centuries to millennia. So now the cat's out of the bag, nobody's going to put it back. And it's about, you know, how can we direct it in the most beneficial possible way? And as you say, it doesn't have to be just one possible. We were like, what will I look forward to personally is bifurcating myself into an array of possible Benton's like it. I'd like to get one copy of me fuse itself with a superhuman ai mind and you know, become, become, uh, a god or something beyond the God. You wouldn't even be myself. God, I wouldn't even be myself anymore. Right. I mean, you would lose all concepts of human self and identity, but it would be the point of even holding any of it, you know, that's, that's for the future.

Speaker 2:          00:46:45       That's for the Mega Ben to decide, right? Yeah. Yeah. On the other hand, I'd like to let me remained in human form, you know, get, get, get rid of a death and disease and the psychological issues and just live live happily forever, you know, in, in the peoples who watched over by the machines of loving grace. Right. So, I mean, you can have, it doesn't have to be either or because once, once you can scan your brain and body and three d print new copies of yourself, you could have multiple of. I mean, that's there's a lot of mass energy in the universe and the universe, so that's assuming that we can escape this planet because of you. If you're talking about if you're going to make themselves, how can you live in a world with a billion donald trump's

Speaker 1:          00:47:30       because literally that's what we're talking about, talking about people being able to reproduce themselves and just having this idea that they would like their ego to exist in multiple different forms. Whether it's some super symbiotic form that's connected to artificial intelligence or some biological form that's immortal or some other form that stands just as a normal human being. As we know in 2018 have you have multiple versions of yourself over and over and over again like that. That's where you're. So once you get to the point where you have a super human general intelligence that can do things like fully scanned the human brain and body and three d print more of them. By that point, you're at a level where scarcity of material resources is not an issue at the human scale of doing things. So I actually have human resources in terms of what

Speaker 2:          00:48:24       mass energy, scared scarcity of molecules to print more copies of yourself. I think that, I think that's not going to be the issue at that point when people are worried about is environmental concerns of overpopulation is people are worried about what they see in front of their faces right now, but people are not. Most people are not thinking deeply enough about what potential would be there once you had super human ai is doing the calculation manufacturing and the thinking. I mean, I mean the. The amount of energy in the single grain of sand, if you had an ai able to to appropriately leverage that. That energy is, is tremendously more than than most than most people think. And the amount of computing power in a grain of sand. It's like a quadrillion times. All the people on Earth put together. So I mean, what do you mean by that amount of computing power?

Speaker 2:          00:49:20       There's. Well the amount of computing power that could be achieved by reorganizing the elementary particles in the grain of sand. Yeah, there, there, there's, there's a number in physics called the beacon stone bound, which is the maximum amount of information that can be, can be stored in a certain amount of mass energy here, so that that if the laws of physics as we know them now are correct, which they certainly aren't than the [inaudible]. That would be the amount of computing you can do in a certain amount of mass and energy. We're very, very far from that limit right now. Right, so I mean, my point is once you have something a thousand times smarter than people, what we imagined to be the limits now doesn't matter

Speaker 1:          00:50:01       too. The issues that we're dealing with in terms of environmental concerns, that could all potentially be almost certainly going to be irrelevant, irrelevant. There may be others problem issues that we can't even conceive at this moment, but the intelligence will be so vastly superior to what we have currently that they'll be able to find solutions to virtually every single problem with Shima, a ocean, fish, deep population. All that stuff will just arrangements

Speaker 3:          00:50:28       of molecules freaking me out. But to hear that though, environmental people don't want to hear that. Well, I mean I

Speaker 2:          00:50:35       also on the everyday life basis until we have these super ais, I don't like the garbage, Washington from the beach near my house either. Right? So I mean, but on an everyday basis, of course we wanted to promote health in our bodies and in our, in our environments right now, as long as there's no measurable uncertainty regarding when the Benevolent Super Ais will will, will, will come about still, I think the main question isn't whether once you have beneficially disposed super ai, it could solve all our current petty little problems. The question is can we wade through the mock of modern human society and psychology to create this beneficial super ai in, in, in the first place I got, I believe I know how to create a beneficial super ai, but it's a lot of, a lot of work to get there and of course there's many teams around the world working on vaguely similar projects now. It's not obvious what kind of super ai we're actually going to get once we get there. Yeah, it's all just guesses at this point, right? It's more less educated guesses depending on who's doing the guessing.

Speaker 3:          00:51:52       You say that it's almost like we're in a race of the the primitive primate biology versus the potentially beneficial and benevolent artificial intelligence that this. The best aspects of this primate can create that it's almost a race to get who's going to win. Is it the warmongers and the greedy whores that are smashing the world under its boots or is it the scientists that are going to figure out some super intelligent way to solve all of our problems? Let's look at it more as a

Speaker 2:          00:52:22       look at it more as a, as a struggle between different modes of social organization than individual people. I mean, look what when I worked in DC with intelligence agencies, most of the people I met there were really nice human beings who believed they were doing the best for the world. Even if some of the things that we're doing, like I thought were very much not for the best of the world. Soon I'm in military mode of organization or large corporations as a mode of organization are in my view, not journaling can lead to beneficial outcomes for the overall species and and for the global brain and the scientific community. The open source community I think are better modes of organization and you know the, the better aspects of the blockchain and crypto community have a better mode of organization. So I think if, if this sort of open decentralized of organization can marshal more resources as opposed to this centralized, authoritarian mode of organization, then I think things are going to come out for the better and it's not so much about bad people versus good people.

Speaker 2:          00:53:41       You can look at like the corporate mode of organization. It's almost a virus that that's colonized a bunch of humanity and is sucking people into working according to the, to this mode and even if they're really good people and the individual task they're working on isn't bad in itself. They're working within this, this mode that's leading their work to be used for ultimately a non good end. Yeah. That is a fascinating thing about corporations, isn't it? That the diffusion of responsibility and being a part of a gigantic group that you as an individual don't feel necessarily connected, are responsible to the. Even the CEO isn't fully responsible. Like if the CEO does something that isn't in accordance with the high higher goals of the organization, they're just replaced. Right. So I mean there's no one person who's in charge. It's really like, it's like an that column.

Speaker 2:          00:54:34       It's like its own organism and I mean it's us who have let these organisms become parasites on humanity in this way. In some ways the Asian countries are a little more intelligent than western countries and the Asian governments realize the power of corporations to mold society and there's a bit more feedback between the government and corporations which can be for better or for worse, but then in in America there's some ethos of like free markets and free enterprise, which is really not taking into account the oligopolistic nature of, of, of, of modern markets, but in Asian countries isn't it that the government is actually suppressing inflammation as well. They're also suppressing Google and South Korea? No, I'm in South Korea. If you look at my only ones, well Singapore, I'm in Singapore is ruthless in their drug laws and some of the archaic, well us far worse though, Singapore, it gives you the death penalty for marijuana.

Speaker 2:          00:55:43       They do it. South Korea is an example which has roughly the same level of personal freedoms as the US more in some ways less than others. Massive electronic and innovation. Well, interesting thing they're politically is. I mean they were poorer than two thirds of sub Saharan African nations in the late sixties and it is through the government intentionally stimulating corporate development toward manufacturing in electronics that they grew up so that, that, that now I'm in, I'm not holding that up as a paragon for the future or anything, but it does show that there's, there's many modes of organization of people and resources other than the ones that we take for granted in the US. I don't think Samsung and lg are the ideal for the future either though. I mean I'm much more interested in, you know, your son in blockchain. I'm interested in. I'm interested in open source.

Speaker 2:          00:56:45       I'm interested in, in blockchain. I'm basically, I'm interested in anything that's, you know, open and participatory and disruptive as well because I think that's, I think that is the way to be ongoingly just disruptive and open source is a good example of that. Like when the open source movement started, they weren't thinking about machine learning, but you know, the, the fact that open source is out there and there's been prevalent in the software world that pave the way for ai to now be centered on open source algorithms. So right now even though big companies and governments dominate the scalable rollout of Ai, the invention of new ai algorithms is mostly done by people creating new code and putting it, putting it on, on get hub or get lab or other open source repository. Retired repositories been sources self explanatory in its title. Pretty much people kind of understand what it is that means that various coders get to share in this, this code and the source code and they get to innovate and they all get to participate and use each other's work.

Speaker 2:          00:57:52       Right, right. Um, but blockchain, and it's confusing for a lot of people. Could you explain that? Sure. I'm in block block. Block chain itself is almost a misnomer, so we're confused. Things are confusing, uh, at every level, right. So we can start with the idea of a distributed ledger, which is basically like a distributed, an excel spreadsheet or database. It's just a story of information which is not stored just in one place, but there's copies of it in lots of different places. Every time my copy of it is updated, everyone else's copy of it has, has, has got to be updated. And then then there's various bells and whistles like sharding where you know, it can be broken in many pieces and each piece is stored many places or something. So That's a distributed ledger and that's just distributed computing. Now what, what makes it more interesting is when you layer decentralized control onto that.

Speaker 2:          00:58:47       So imagine you have this distributed excel spreadsheet or distributed database. There's copies of it stored in a thousand places, but to update it, you need like 500 of those thousand people who own the copies to vote. Yeah. Let's do that update, right? So then then you have a distributed store of data and you have like a democratic voting mechanism to determine when all those copies can get, can get updated together, right? So then then what you have is a data storage and update mechanism that's controlled in a democratic way by the group of participants rather than by any one central controller. And that that can have all sorts of advantages. I mean for one thing it means that you know, there's no one controller who can go rogue and screw with the day without telling anyone. It also means there is no one has some limitation go hold a gun to their head and shoot them for, for what data updates were made because know controlled democratically by, by everybody, right?

Speaker 2:          00:59:44       It has ramifications in terms of, you know, legal defensibility and I mean you could have some people in Iran, some in China, some in the US and, and updates to this whole distributed data store are made by democratic decision of all the participants. Somewhere cryptography comes in is when I vote, I don't have to say, yeah, this is Ben Gursel voting for this update to be accepted or not. It's just ID number one, three, five, seven, two, six, four. And then encryption is used to make sure that, you know, it's, it's the same guy voting every time that it claims to be with without needing like your, your passport number or something. Right. What's ironic about it is it's probably one of the best ways ever conceived to actually vote in this country. Yeah, sure. It would be kind of ironic. There's a lot of applications for the, the, the, the, the.

Speaker 2:          01:00:37       That's the, that's right. So the, so that. I mean that's the core mechanism though where the block chain comes from is like a data structure where to store the data in this distributed database, it's stored in a chain of blocks or each block contains data. The thing is not every so-called blockchain system even uses a chain of blocks and I'd like some use a tree or a graph of blocks or something. So that term, I mean it's, it's an alright terms like ai, like just one of those terms were stuck with. It's one, it's one of those terms were stuck with, even though it's not quite technically not quite technically accurate. I mean anymore. I mean w w, W, W, I don't know, another buzzword for it, right. What it is is a, it's a distributed ledger with encryption and decentralized control and blockchain is the buzzword that's come about for that.

Speaker 2:          01:01:31       Now what, what got me interested in blockchain really is this decentralized control aspect. So my, my, my wife, well them with for 10 years now, she dug up recently something I'd forgotten, which is a webpage and made in 1995, like a long time ago where I'd said, hey, I'm going to run for president on the decentralization platform for which I'd completely forgotten that crazy idea. I was very young then. I had no idea within an annoying job being president would be. But the so that the idea of decentralized control seemed very important to me back then, which is well, before bitcoin was invented because I could see, you know, a global brain is evolving on the planet involving humans, computers, communication devices, and we don't want this global brain to be controlled by a small elite. We want the global parent to be controlled in the, in a decentralized way.

Speaker 2:          01:02:26       So, so that, that's really the, the beauty of this, a blockchain infrastructure. And what, what got me interested in the practical technologies of block chain was really one etherium came out and you add the notion of a smart contract, which was the theory etherium. Yeah. So what is that? Well, so the first blockchain technology was Bitcoin, right? Which is a well known cryptocurrency now if theory. IOM is another cryptocurrency, which is the number to cryptocurrency right now. That's how the loop I am. Did you know about it? You did. However, ethereum came along with a really nice software framework. So it's not just like a digital money, like bit coin is, but it theory. IOM has a programming language called solidity that came with it and this programming language let's you right where they're called smart contracts and again, that sort of a misnomer because a smart contract, it doesn't have to be either smart or a contract, right, but it was a cool name and then if it's really a smart contract, it's a contract.

Speaker 2:          01:03:34       It's like a programmable transaction so you you can program a legal contract or you can program of a financial transaction. So a smart contract, it's a. it's a persistent piece of software that embodies like a secure encrypted transaction between between multiple parties, so pretty much like anything on the back end of a bank's website or a transaction between two companies online, a purchasing relationship between you and the website online. This could all be stripped it in in the smart contract in this secure way, and then it wouldn't be automated in this simple and standard way. So the vision that Vitalik Buterin who was the main creator behind the theory had is to basically make the internet into a giant computing mechanism rather than mostly like an information storage and retrieval mechanism. Make the Internet into a giant computer, but making it really simple programming language for scripting transactions among different computers and different parties on the Internet where you have encryption and you have democratic decision making and distributed storage of information like programmed into this, this world computer.

Speaker 2:          01:04:50       Right? And then that was a really cool idea. And the etherium blockchain and solidity programming language made it really easy to do that. So it made it really easy to program like distributed secure transaction and computing systems on the Internet. So I saw this, I thought, well, like now we finally have the tool set that's needed to implement. Some of this is very popular. I mean, I mean basically almost every ico that was done the last couple of years was done on the ethereum blockchain. What's an ICO? Initial coin offering. Oh, okay. So for Bitcoins, for, I'm sorry, cryptocurrency, cryptocurrency use this technology brings. Right? So what happened in the last couple of years is a bunch of people realized you could use this etherium programming framework to create a new cryptocurrency, like a new artificial money. And then you can try to get people to use your new artificial money for certain types of artificial coins.

Speaker 2:          01:05:59       It may be more popular. Is Bitcoin, right? Bitcoin is by far the most popular. The most delirium is number two. And there's a bunch of others. I mean Hartwick comparison, like how much bigger is bitcoin and ethereum? I Dunno. Five factor of three to five. So maybe just a factor of two. Now it's actually last year at theory and almost took over bitcoin when bitcoin started crashing. Yeah. Yeah. Now if their room is back down, there might be half or a third of the fluctuating value of these things. To My, to my mind, creating artificial monies is one tiny bit of the potential of what you could do with the whole blockchain tool. Set it. It happened to become popular initially because it's where the money is, right? I've been right writing it is. It is money and that's interesting to people, but on the other hand, what it's really about is making world computer.

Speaker 2:          01:07:05       It's about scripting with a simple programming language, all sorts of transactions between people, companies, whatever, all sorts of exchanges of, of information. So I mean it's about decentralized voting mechanisms. It's about Ai's being able to send data and processing for each other and pay each other for their transactions. So I'm in, there's, it's about automating supply chains and, and, and shipping and ecommerce so that there's an in, in, in, in essence, you know, just like computers and the Internet started with a certain small set of applications and then pervaded almost everything, right? It's the same way with blockchain technology, like it started with digital money, but the core technology is going to pervade almost everything because there's almost no domain of human pursuit that couldn't use like security through cryptography, some sort of, you know, participatory decision making and then distributed storage of information. Right?

Speaker 2:          01:08:09       So these things are also valuable for ai, which is how I got into it in the first place. I mean, if you're making a very, very powerful ai that is going to, you know, gradually through the practical value delivers, she will grow up to be more and more and more intelligent. I mean this ai shouldn't be able to engage a large party of people and ais and participatory decision making. They, I should be able to store information in a widely distributed way and, and ai certainly shouldn't be able to use, you know, security and encryption development, who are the parties involved in this operation and I mean these are the key things behind behind blockchain technology. So I'm in the fact the fact that blockchain began with artificial currencies to me is a detail of history. Just like the fact the fact that the Internet began as like a nuclear early warning system right then. And it did. It's good for that. But it's, as it happens, it's also even better for a lot of other things. So the,

Speaker 1:          01:09:09       the solution for the financial situation that we find ourselves in. One of the more interesting things about cryptocurrencies that someone said, okay, look, obviously we all kind of agreed that our financial institutions are very flawed system that we operate under is it's very fucked up, so how do we fix that? Well, sending the super nerds and so they figure out a new number, get ascend into super, a super, super nervous super. Obviously. Who is the guy that they think that this fake person maybe not real, that came up with bitcoin. Komodo. Do you have any suspicions as to who this is a, I can neither confirm nor deny that you wouldn't be on the inside. We'll talk later, but that, this is, it's very, it's very interesting, but it's also very promising. I, I've like high optimism for cryptocurrencies because I think that kids today are looking at it with much more open eyes than uh, you know, grandfathers, grandfathers are looking at bitcoin and the father. You're exceptional one, but there's a lot of people that are older that just, they're not open to accepting these ideas, but I think kids today in particular, the ones that have grown up with the internet as a constant force in their life, they're. I think they're more likely to embrace something along those lines.

Speaker 2:          01:10:38       Well, yeah, so there's no doubt that you know, cryptographic formulations of money are going to become the standard. The question, do you think that's going to be the standard that will have been? Yeah. However, it could happen potentially in a very uninteresting way. How's. You could just have the dollar. I mean the government could just say we will create this cryptographic token which counts as a dollar. I mean, most dollars are just electronic. Anyway, so, so what, what, what habitually happens is technologies that are invented to subvert the establishment are converted to a forum where they help bolster the establishment. Instead, I'm in and in financial services. This happens very rapidly, like pay Pal Peter Teal on this guy started paypal thinking they were going to obsolete Fiat currency and make an an alternative to the currencies run by by nation states instead. They were driven to make it a credit card processing front end.

Speaker 2:          01:11:42       Right. So, so that's one thing that could happen with crypto currency is it just becomes a mechanism for, you know, governments and big companies and banks to do the things more efficiently. So what, what's interesting isn't so much the digital money aspect, although it is in some ways a great way to do digital money. Wow. What, What's interesting is with all the flexibility it gives you to script, you know, complex computing networks in there is the possibility to new forms of, you know, participatory democratic self organizing networks. So blockchain, like the internet or computing is a very flexible medium. You could use it to make tools of oppression or, or you could use it to make tools of amazing growth, growth and liberation. And obviously we know which one I'm more interested in.

Speaker 3:          01:12:38       Yeah. Now what, what is blockchain? What is blockchain being currently used for? Like what, what different applications, because it's not just cryptocurrency, they use a bunch of different things now, right?

Speaker 2:          01:12:50       They are. I would say it's very early stage. So probably the how early. Well the heaviest users of blockchain now are probably inside large financial services companies actually. So if you look at it theory in the project I mentioned, so it theory, ms is run by an open source, an open foundation, ethereum foundation. Then there's a consulting company called consensus, which is a totally separate organization that was founded by Joe Lubin who was one of the founders of ethereum in the early days and consensus as you know, it's funded a bunch of the work within the ethereum foundation and community, but consensus has done a lot of contracts just working with governments and big companies to customize code based on the theory to help with their internal operations. So actually a lot of the practical value has been with stuff that isn't in the public eye that much, but it's like back end and in, in, in inside of companies.

Speaker 2:          01:13:54       And in terms of practical customer facing uses of, of cryptocurrency. I mean, no, the Tron blockchain, which is different than the theory that has a bunch of games on it, for example, and some online gambling for, for that matter. So that, that's uh, that that's gotten a lot of users, but the online games like how, how do they use that? Oh, that's a payment mechanism. But that there, this is one of the things there's a lot of handwringing about in the cryptocurrency world now is gambling. No, just the fact that there aren't that many big consumer facing uses of, of, of, of cryptocurrency. I mean, I mean everyone would, everyone would like there to be. That was the idea and this is one of the things we're aiming at with our singularity in the project is to, you know, we, we by putting ai on the blockchain in a highly effective way.

Speaker 2:          01:14:51       And then we're also, we have these two tiers. So we have the singularity net foundation which is creating this open source decentralized platform in which ais can talk to other ais and you know, like ants in the colony group together to form smarter and smarter Ai. Then we're spinning off a company called the singularity studio, which will use this decentralized platform to help big companies integrate ai into their operation. So with the singular these studio company, we want to get all these big companies using the ai tools in the singular unit platform and then we want to drive, you know, massive usage of, of blockchain in the singularity in that way. So that's if we're successful with what we're doing, this will be, you know, within a year from now or something. By far the biggest usage of blockchain outside of financial exchange is our use of blockchain within singularity unit for ai basically for customers to get the AI services that they need for their businesses and then for ais to transact with other ai is paying other ais for doing services for them.

Speaker 2:          01:16:04       Because this, this, this I think is is a path forward. It's like a society and economy of minds. It's not like one monolithic Ai. It's a whole bunch of ais carried by different people all over the world with not only are in the marketplace providing services to customers, but each ai is asking questions of each other and then rating each other of how good they are sending data to each other and paying each other for the services. So this, this like network of ais can emerge and intelligence on the whole network level as well as there being intelligence city in each, each component. And is it also fascinating to you that this is not dependent upon nation? So this is a world that ever. I think. I think that's going to be important once, once it starts to get a very high level of intelligence.

Speaker 2:          01:16:50       So in the early stages, okay, what would it hurt? Like if, if I had my own database to central record of, of everything. Like I'm, I'm an honest person. I'm not going to rip anyone off, but once we start to make a transition towards artificial general intelligence in this global decentralized network, which has component ais from every country on the planet, like at that point, once it's clear, you're getting toward a gi, a lot of people wanting to step in and control this thing, you know, by law, by military might, by any means necessary. By that point. The fact that you have this open, decentralized network under underpinning everything like this gives an amazing resilience to what you're doing. Who can shut down Linux, you can shut down Bitcoin, nobody can right you, you, you want Ai, you want ai to be like that. You want to be a global, you know, upsurge of, of creativity and, and mutual benefit from people all over the planet, which no powerful party can, can shut down even if they're afraid that it threatens their hedge.

Speaker 2:          01:17:56       Amani. It's very interesting because in a lot of ways that's a, it's a very elegant solution to. What's an obvious problem? Yeah. Just as the Internet is an elegant solution to what's in hindsight and obvious problem, right? It's the distribution of communicate this, but this is a extra special to me because if I was a person running a country, I would be terrified of this shit. I'd be like, well, this is what's going to. That depends which country. If you're a person running the US or China, you, you would have a different relationship than if you're a person. Like I know the Prime Minister of Ethiopia, I'll be Ahmed who's a, has a degree in software engineering and he, he, he, he loves this, but of course Ethiopia isn't in any day, any other countries. Right. And they're not in any danger of, of individually like taking global ai hedge.

Speaker 2:          01:18:48       So for the majority of countries in the world, they like this for the same reason they liked Linux, right? I mean, I mean this, this is something which they have an equal role to anybody else, right? The superpowers, and you see this among companies also those. So a lot of big companies that we're talking to, they love the idea of this decentralized ai fabric because I mean if you're not Amazon, Google, Microsoft, tencent, facebook, so on. If you're another large corporation, you don't necessarily want all your ai and all your data to be going into one of this handful of large ai companies. You would rather have it be in the secure decentralized platform and I mean this is the same reason that you know, Cisco and IBM, they run on Linux. They don't run on Microsoft. Right? So if, if you're not one of the handful of large governments or large corporations that happened to be in a leading role in the ai ecosystem, then you would rather have this, this equalizing in decentralized thing because everyone gets to play.

Speaker 2:          01:19:56       Yeah. What? What would be the benefit of running on Linux versus Microsoft? Well, you're at the behest of some other big company. I mean, imagine if. Imagine if you were cisco or gm or something and all of your internal machines are all your servers are running in Microsoft. What Microsoft increases their price or are removed some feature. Then you're totally at their behest and with ai the same thing is true. I mean, if, if you put all your data in some big company's server farm and you're analyzing all your data on their algorithms and that's critical to your business model, what if they change their ai algorithm in some way? Then I'm in the. Then your business is, is basically controlled by this other company. So I'm in having a decentralized platform in which you're, you know, an equal participant along with everybody else is, is actually a much better position to be in.

Speaker 2:          01:20:59       And I think this, this I think is why we can succeed with this plan of having this decentralized singularity net platform than the singular, the studio enterprise software company which mediates between the decentralized platform and big companies. I mean it's because most companies and governments in the world, you know, they don't want hedge. I'm one of a few large governments and corporations each either. And you can see this in, in a lot of voids. You can see this embrace of, of Linux and etherium by many large corporations. You can also see like in a different way, you know, the Indian government, you know, they rejected an offer by facebook to give free internet to all Indians because facebook wants to give like mobile phones that would get free internet, but only to access facebook, right? India is like, well no, no, no, thanks. Right, and India is now giving.

Speaker 2:          01:21:59       They're now creating laws that any internet company that collects data about Indian people has to store that data in India, which is so the Indian government can subpoena that data when, when, when, when they want to. So, so you're, you're already seeing a bunch of resistance against hedge pneumoniae by a few large governments or large large corporations by other companies and other governments. And I think this is very positive and is one of the factors that can, that can foster the foster, the growth of a decentralized ai ecosystem. Is it fair to say that the future of ai is severely dependent upon who launches it first? Like whoever, whether it's singularity, the bottom line is official general intelligence. The bottom line is as a scientist after say, we don't know, right? It could be there's an end state that Agi will just self organize into almost independent of the initial condition, but we don't know and given that we don't know, I'm operating under the, you know, the, your ristick assumption that if the first ai is beneficially oriented, if it's controlled in the participatory democratic way and if it's oriented at least substantially towards like doing good things for humans, I'm operating under the eucharistic assumption that this is going to bias things in a positive, positive direction.

Speaker 2:          01:23:35       I'm in chorus in the absence of knowledge to the contrary. But if the Chinese government launches one, they're controlling. We don't pop it off first. I mean, I liked the idea that you're saying though, that it might organize itself. I mean understand the Chinese government also. They want, they want the best for the Chinese people that they don't, they don't want to make the terminator either. Right. So, uh, I mean, uh, I think even even Donald Trump was not my favorite person doesn't actually want to kill off everyone on the planet. Right. So he might, if they talk shit about them. Yeah, yeah, yeah. You know, you never know it was just him. I told you all. I mean, I, I think, you know, I wouldn't say we're necessarily doomed if big governments and big companies are the ones that develop ai or Agi first big government, big companies essentially developed the internet.

Speaker 2:          01:24:32       Right. And it got away from them. That's right. That's right. So there's a lot of uncertainty all around, but I think, you know, it behooves us to do what we can to bias the odds in our favor based on our current understanding. And I mean toward that end we're developing, you know, open source, decentralized ai and singularity in that process. So if you would explain some singularity net and what, what you guys are actively involved in. Sure, sure. So singularity and that in itself is a platform that allows many different ais to operate on it and these ais can offer services to anyone who requests services of the network and they can also request an offer services among each other. So it's, it's both just an online marketplace for ais, much like no the apple app store or Google play store, but for ais rather than phone ups, but the difference is the different ais in here can outsource work to each other and talk to each other and that gives a new dimension to it, right where you can have, we think of as a society or economy of minds and it gives the possibility that this whole society of interacting ais which are then they're paying each other for transactions with our, our digital money or are cryptographic token, which is called the Agi token.

Speaker 2:          01:26:01       So these ais which are paying each other and rating each other of how good they are, sending data and questions and answers to each other, can self organize into some overall ai mind? No. We're building this platform and then we're plugging into it to seed it. A bunch of ais of our own creation. So I've been working for 10 years on this open source ai project called open cog, which is oriented toward building general intelligence and we're putting a bunch of ai agents based on the open cog platform into this singularity in the network and you know if we're successful in a couple of years, the ais that we put on there will be a tiny minority of what's in there, just like the apps made by Google or a small minority of the apps in, in the, in the Google play store. Right. But my hope is that these open cog, ai agents within the larger pool of Ais and the singularity net can sort of serve as the general intelligence corps because the open ai agents are really good at abstraction and generalization and creativity.

Speaker 2:          01:27:09       We can put another, a bunch of other ais in there that are good at highly specific for forms of learning, like predicting financial time series, curing diseases, answering people's questions, organizing your inbox so you can have the interaction of these specialized ais. And then more general purpose. You know, abstraction and creativity based. Ai is like open cog agents all interacting together in this decentralized platform and then you know, the beauty of it is like some, some 15 year old genius and Azerbaijan or the Congo can put some brilliant ai into this network. If it's really smart, it will get rated highly by the other ais for, for, for its work, helping them do their thing. Then it can get replicated over and over again across many servers. Suddenly a this 16 year old kid from Azerbaijan or the Congo could become wealthy from, from their copies of their ai providing services to other people's ais and be, you know, the creativity in their mind is out there and is infusing this global aid network with some, some new intellectual DNA that you know, never would have been found by a ten cent or a google because they're not going to hire some Congolese teenager who may have a brilliant ai idea.

Speaker 2:          01:28:27       That's amazing.

Speaker 1:          01:28:28       That's amazing. So this is all ongoing right now. And the singularity that you guys are using, the. The way I've understood that term, correct me if I'm wrong, is that it's going to be the one innovation or one invention that essentially changes everything forever.

Speaker 2:          01:28:48       The singularity isn't necessarily one invention. The singularity, which is coined by Wong, is coined by my friend Vernor vinge, who's another guy you should interview. He's in San Diego to the other guys. The other brilliant guys down there, but vernor vinge military down there. Yeah, vernor vinge. Uh, he, he was a math professor. The San Diego University actually, but well known science fiction writer. His book a fire upon the deep, one of the great science fiction books. So v I n g Vernor Vinge, GE, brilliant guy, fire upon the deep Vernor v e r o v e R. Yeah, he's brilliant. He coined the term technological singularity back in the 19 eighties, but he, he opted not to become a, a pundit about it because he'd rather more science fiction. That's interesting. Than a science fiction author. Ray Kurzweil, who's also a good friend of mine. I mean Ray Ray took that term and fleshed it out and did a bunch of data analytics.

Speaker 2:          01:29:52       Trying to pinpoint like when it's, it would happen, but the basic concept of the technological singularity is a point in time when technological advance occurs so rapidly that the human mind, it appears almost instantaneous. Like, like imagine 10 new Nobel Prize winning discoveries every second or something. Right? So this is similar to the concept of the intelligence explosion that was posited by the mathematician, Ij good in 1965. What Ij good said. Then the year before I was born was the first truly intelligent machine will be the last invention that humanity needs to make rent. So this is an intelligence explosion is another term for basically the same thing as the technological singularity, but it's not just about Ai. Ai is just probably the most powerful technology driving it. I mean there's ai, there's nanotechnology, there's femto technology which will be building things from elementary particles. I mean there's life extension, genetic engineering, mind uploading, which is like reading the mind that if your brain and putting it into a machine, you know, there's advanced energy technologies so that all these different things are expected to advance at around the same time.

Speaker 2:          01:31:10       And they have many ways to boost each other, right? Because the, you know, the better Aiu have, your ai can then invent new ways of doing nanotech tech and biology. But if you invent amazing new nanotech in quantum computing, that can make your ai smarter. On the other hand, if you, if you could crack how the human brain works and genetic engineering to upgrade human intelligence, those smarter than humans can then make better eyes and nano technology, right? So there's so many virtuous cycles among these different technologies. The more you advance in any of them, the more you're going to advance and in, in all of them. And it's the coming together of all of these that's going to create, you know, radical abundance and the technological singularity so that, that term, which Vernor vinge, he introduced ray Ray Kurzweil borrowed for his books and further singular the university educational program.

Speaker 2:          01:32:02       And then we borrowed that for our singularity net, like decentralized blockchain based ai platform and in our singularity studio enterprise software company. Now I want to talk to you about two parts of what you just said. One being the possibility that one day we can upload our mind will make copies of our mind. You're up for it to upload into here. I could use a little Joe Rogan them on my phone. You can just call me dude, the organic version, but the what do you think that that's a real possibility inside of our lifetime that we can map out the human mind to the point where we can essentially recreate it, but if you do recreate it without all the biological urges and the human reward systems that are built in, what the fuck are we? I mean, well that's a different question I think. What is your mind?

Speaker 2:          01:32:54       Well, I, I think that those two things that are needed for, let's say, let's say human body uploading to simplify things, body uploading. There are two things that are needed. One thing is a better computing infrastructure. Then we have no to host the uploaded body and, and the other thing is a better scanning technology because right now we don't have a way to scan the molecular structure of your body without like freezing you, slicing you in scanning you, which you probably don't want that at this point in time, right yet. So assuming both those are solved and you can then recreate in some computer simulation, you know, uh, an accurate simulate Chromo of, of, of, of what you are, right? That's where I'm getting this, where I'm getting at an accurate simulacrum is, that's getting weird because the biological variability of human beings, we vary day to day.

Speaker 2:          01:33:50       We're very dependent upon it. And your simulator and will also vary day to day. So the DVA program and into have flaws because while we vary dependent upon how much sleep we get, whether or not we're feeling sick, whether we're lonely. So all these, if you're upload, we're an accurate copy of you than the simulation. Hosting your upload would need to have an accurate simulation of the laws of bio physics and chemistry that allow your body to, you know, evolve from one second to the neck. My concern is though would change second by second, just like just like you do and it would divert from me. Right? So I mean after an hour it will be a little different. After a year it might've gone in, in a quite different direction for you. Probably a month. Some Super God monk living on the top of a mountain somewhere in a year.

Speaker 2:          01:34:39       Have it, keeps the whole right. Depends on what virtual world it's living in. True. I mean if it's living in a virtual world, your world will be a virtual world. If we're not talking about the potential of downloading this. Again, in sort of into a biologic, there's a lot of possibilities, right? I mean you, you, you could, you could upload into a Joe Rogan living in the virtual world and then just create your own fantasy universe or you or you could three d print and alternate synthetic body. Right? I mean, once you, once you have the ability to manipulate molecules at will, the scope of possibilities becomes much greater than we're used to. Thinking about. My question is do, do we replicate flaws? Do we replicate depression? Of course, but we knew that when we want to cure depression, so depression it. Here's the interesting thing.

Speaker 2:          01:35:31       Once once we have you in a digital form, then it's very programmable, so then the dopamine and Serotonin, then you can change what you want and then you have a whole different set of issues. Right? Yeah. Because once you've changed, I mean suppose you make a fork of yourself and then you manipulate it in a certain way and then after a few hours you're like, well I don't. I don't much like this. A new joe here. Maybe we should roll back that change, but the new joe is like, well, I liked myself very well. Thank you. So then, yeah, there's a lot of issues that that will come up once we can write, modify, and reprogram ourselves to the point that the ramifications of these decisions are almost insurmountable d once, once the ball gets rolling. Well, the modifications of the ramifications of these decisions are going to be very interesting to explore.

Speaker 2:          01:36:30       Yes, you're super positive band, super positive of your optimism. Many bad things will happen. Many good things will happen. That's a very. That's a very easy prediction to me. Okay. I see what you're saying. Yeah. I've just a one day thing. Think about like world travel, like hundreds of years ago, most people didn't travel more than a very short distance from their home and you could say, well, okay, what if. What if people could travel all over the world, right? Like what horrible things could happen. They would lose their culture like they might go marry someone from from a random tribe. You can get killed in the Arctic region or something. A lot of bad things can happen when you travel far from your home. A lot of good things can happen and the ultimately the ramifications were not foreseen by people 500 years ago. I'm in, we're going into a lot of new domains.

Speaker 2:          01:37:19       We can't see the details of the pluses and minuses that are going to unfold. A W, it would behoove us to simply become comfortable with radical uncertainty because otherwise we're going to confront it anyway and we're just going to be nervous. So it's just inevitable this, this, uh, it's almost inevitable. I mean, of course. Sorry. Any natural disaster. Yeah. I mean, of course trump could start a nuclear war and then we're resetting to ground zero where we get hit by an asteroid, right? Yeah. I mean, so barring a catastrophic outcome, I believe a technological singularity is essentially inevitable. There's a radical uncertainty attached to this. On the other hand, you know, in as much as we humans can know anything, it would seem common sensically there's the ability to bias this in a positive rather than the negative direction. We should be spending more of our attention on doing that rather than, for instance, advertising spying and making chocolate chocolates and all the other things people are doing now.

Speaker 2:          01:38:28       I mean, it's prevalent, it's everywhere, but I mean how many people are actually at the helm of that as opposed to how many people are working on various aspects of technology all across the planet. It's a small group and in comparison, working on explicitly bringing about the singularity is a small group. On the other hand, supporting technologies is a very large group, so think about like gps. Where did they come from? Accelerating gaming, right? Lo and behold, they're amazingly useful for training neural net models, which is the one among many important types of Ai, right? So a large amount of the planet's resources are now getting spent on technologies that are indirectly supporting these singular attarian technology. So as another example, like microarrays and let you measure the expression level of genes, how much each gene is doing in your body at each point in time.

Speaker 2:          01:39:22       These were originally developed, you know, as an outgrowth of printing technology. Then instead of squirting ink after metrics figured out you could squirt DNA. Right? So I mean the amount of technology specifically oriented toward the singularity doesn't have to be large because the overall spectrum of supporting technologies can be subverted in that direction. Do you, do you have any concerns at all about a virtual world? I mean, we may be anyone right now, man, you know that's true. But as far as my problem is, I want to find that programmer and get them to make more attractive people. I would say that that's part of the reason why I attracted people are so interesting as that they're unique and rare problems with calling everything beautiful. Yeah. You know, everything we're saying, everything is generous. Beautiful. I was like, well, you just have to get realistic.

Speaker 2:          01:40:16       If I get in the right frame of mind that can find anything beautiful. Well you could find it unique and interesting. Oh, I can find anything but. Okay. I guess I guess. But in terms of like. Yeah, I guess it's subjective, right? Really it is. We're talking about beauty, right? Yeah. Now, but very existential angst just on the, the. When people sit and think about the pointlessness of our own existence, like we are these finite beings that are clinging to a balls. It spins a thousand miles an hour hurling through infinity. And what's the point like? There's a lot of that that goes around already. We've. We create an artificial environment that we can literally somehow

Speaker 1:          01:40:54       under the download a version of us and it exists and this block chain created or or powered weird fucking simulation world. What would be, I mean

Speaker 2:          01:41:12       it be the point of what I really believe, which is a bit personal and maybe different than many of my colleagues. What I really believe is that these advancing technologies are going to lead us to unlock many different states of consciousness and experience than, than most people are, are, are currently aware of are I mean you, you, you say we're, we're just an insignificant species on the, on the, you know, a speck of rock hurtling in the other space were insignificant. There's people that have existential acts because they wonder about what the purpose was. I go that category tend to feel like we understand almost nothing about who and what we are and our knowledge about the universe is far small, extremely minuscule. I mean, if anything, I look at things from more of a Buddhist or phenomenological way, like the sense perceptions and then out of those sense perceptions, models arise and accumulate including a model of the self and the model of the body and the model of the physical world out there and by the time you get to planets and stars and blockchains, you're building like hypothetical models on top of hypothetical models and then you know, we're, we're building intelligent machines and mind uploading machines and virtual realities.

Speaker 2:          01:42:48       We're going to radically transform, you know, our whole state of consciousness, our understanding of what mind and matter are. Our experience of our own selves or even whether it's self exists. And I think ultimately the state of consciousness of a human being like 100 years from now after a technological singularity is going to bear very little resemblance to the states of consciousness we have now. We're just going to. We're going to see a much wider universe in any of us know, imagine, imagine to exist. No, this is my own personal view of things. You, you, you don't have to agree with that. To think the technological singularity will be valuable, but that is how I look. I know Ray Kurzweil and I agree there's going to be a technological singularity within decades at most and ray and I agree that, you know, if we biased technology development, we can very lightly, you know, guide this to be a, a world of abundance and benefit for humans as well as ais.

Speaker 2:          01:44:00       But Ray is a bit more of a down to Earth empiricists than I am lucky. He thinks we understand more about the universe right now than that than I do. So. I mean there's a wide spectrum of views that are rational and sensible to have. But my own view is we understand really, really little of what we are and what, what this world is. And this is part of my own personal quest for wanting to upgrade my brain and wanting to create artificial intelligences is like I've always been driven above all else. Borrowing to understand everything I can about the world. So I'm in. I've studied every kind of science and engineering and social science and read every kind of literature, but in the end the scope of human understanding is clearly very small, although at least we're smart enough to understand how little we understand, which I think my, my dog doesn't understand.

Speaker 2:          01:44:57       He understands. Right? So and even like my 10 month old son, he understands a little. He understands which is interesting, right? Because he's because he's ready to because he's also a human. Right. So I think, I mean, everything we think and believe now is going to seem absolutely absurd to us after there's a singularity. We're just going to look back and laugh in a warm hearted way as all the incredibly silly things we were thinking and doing back when we were trapped in our, in our, you know, our primitive biological brains and bodies. Stunning attack. In your opinion or your assessment is somewhere less than a 100 years away from now. Yeah. That's requires exponential thinking. Right? Because if you. It's hard to wrap your head around, right? I don't know. It's immediate. It's immediate for me to wrap my head around, but for a lot of people that you explained it to him, I'm sure that that that's a little bit of a roadblock.

Speaker 2:          01:45:51       No, it is. It is. It took me some time to have my parents drop their heads around it because they didn't. They're not, they're not technologists, but I mean I find if you get people to pay attention and sort of lead them through all the supporting evidence, most people can comprehend these ideas reasonably well just to computers from 1960, just hard to grasp. It's hard to grab people's attention then. Yeah. Mobile phones and made a big difference. Like I spent a lot of time in Africa, in Addis Ababa in Ethiopia where we have a large ai development office and you know, the fact that mobile phones and then smartphones have rolled out so quickly even in rural Africa and if it's such a transformative impact. I mean this is a metaphor that lets people understand the speed with what's exponential change can happen. When you talk about yourself, when you talk about consciousness and how you interface with the world, how do you see this?

Speaker 2:          01:46:48       I mean, when, when you, that we might be living in a simulation. Do you actually entertain that? Oh yeah, you do. I'm in the, I think the word simulation is probably wrong, but yet the idea of an empirical, you know, materialist physical world is almost certainly wrong also. So I mean, that's so. Well, again, if you go back to a phenomenal view, I mean you could look at the mind this primary and you know, your mind is building the world, uh, as, as a model, as a simple explanation of it, of its perceptions. On the other hand then what is the mind? The self is also a model that gets, that gets built up out of its perceptions. But then if I accept that your mind has some fundamental existence also based on this sort of feeling that you're like a mind, there are minds are working together to build each other and, and, and to build this world.

Speaker 2:          01:47:50       And there there's a, there's a, there's a whole different way of, of thinking about reality in terms of first and second person experience rather than these empiricist views like this is a computer simulation or something. Right. But you still agree that this is a physical reality that we exist in, or do you not? What does that word mean? That's a weird word, right? It is women. Is it your interpretation of reality? If you look in, in modern physics, even quantum mechanics, there's something called the relational interpretation of quantum mechanics, which says that there's no sense in thinking about an observed entity, you should only think about an observed comma observer pair. Like there's no sense to think about some thing except from the perspective of some observer. So that's, that's even true within our best current theory of modern physics as, as induced from empirical empirical observations.

Speaker 2:          01:48:48       Right? In a pragmatic sense, you know, if you take a plane and fly to China, you actually land in China, I guess. You guess, why don't you live there? I live in Hong Kong. Yeah, well, close to it. I, I, I have an unusual state of consciousness. That's what I'm trying to get at. If you think about it, like how do you know that you're not a brain floating in a vet somewhere which is being fed illusions by certain evil scientist and two seconds from now he's going to pull this simulated world disappears and you realize you're just a brain in a vat again, you, you, you, you don't know that you run on your own personal experiences of falling in love with a woman and moving to another, but these may all be put into my brain by the evil scientist. How do we know?

Speaker 2:          01:49:36       But they're, they're very consistent. Are they not the, the possibly illusory and implanted memories are very consistent. I guess. I guess my own state of mind is I'm always sort of acutely aware that this simulation might all disappear at, at, at, at any one moment, uh, uncertain, acutely aware of this consciously on an everyday basis. Pretty much really, really? Why is that? That doesn't seem to make sense. I mean, it's, it's pretty, it's pretty rock solid. It's here everyday. So you're possibly implanted memories led you to believe? Yes, possibly. Implanting memories need to believe that this life is incredibly consistent. This is incredibly consistent. This is your problem of induction, right? From philosophy class and it's not and it's not solved with you in a conceptual sense. I get, I just feel this philosophy, but you, you embody it, right? This is something you carry with you all the time.

Speaker 2:          01:50:38       Yeah. On the other hand I'm in, I'm still carrying out many actions with longterm planning in mind or like I've been, I've been working on designing ai for 30 years and I'd be designing it inside. I might be and I'm working on building the same ai system, you know, since we started open cog in 2008, but that's using codes from 2001 I was building with my colleagues even even earlier. So I'm in. I think longterm planning is very natural to me but. But nevertheless I don't. I don't want to make any assumptions about what sort of, what sort of simulation or reality that we're living in. And I think everyone's gonna hit a lot of surprises when once simulate singular they can, you know, we, we may find out that this hat is a messenger from after the singularity, so it traveled back through time to implant into my brain.

Speaker 2:          01:51:42       The idea of how to create ai and bring it into existence. What? Whoo. It. Oh, that was mckenna that had this idea. That was something in the theater tried. Yes. To this attract terence. Terence Mckenna. Yeah. Yeah. He had the same idea, like some posts, posts singularity intelligence, which actually was living outside of time somehow is reaching back and putting into his brain the idea of how to bring about the singularity novelty itself as being drawn into this. Yeah. There were the timewave zero that was going to reach the apex in 2012. That didn't work. No, he died before that. So he didn't get a chance to hear what his, what his idea was. He, uh, you know, I had some funny interactions with some Mckenna fanatic 2012 whites. This was about 2007 or so. This guy came to Washington where I was living then. And he brought my friend Hugo de Garis, another crazy ai researcher with them, and he's like, the singularity is going to happen in 2012 concerns.

Speaker 2:          01:52:47       Mckenna said, so I need to be sure it's a good singularity so you can't move to China then it will be a bad singularity. So we have. So we have to get the US government to give billions of dollars to your research to guarantee that the singularity in 2012 is a good singularity. Right? So he, he led us around to meet with these generals and various high who has an in DC to get them to fund Hugo. The girl says in my ai research to guarantee I wouldn't move to China and Hugo wouldn't move to China. So the US would create a positive singularity. Now the effort failed. You Go, you go move to China. Then I moved there some years after. So then this, this 2012, he went back to his apartment. He made a, a mix of 50 percent vodka, 50 percent robitussin pm. You'd like drank it down.

Speaker 2:          01:53:44       He's like, all right, I'm going to have my own personal singularity right here, and I haven't talked to that guy since 2012 either to see what he thinks about the singularity. Not happening then, but Terence Mckenna had a lot of interesting ideas, but I felt, you know, he, he mixed up this, the symbolic with the empirical more, more than than I would, I would prefer to do. I mean, I mean it's, it's very interesting to look at these abstract symbols and cosmic insights, but then you have to sort of put your scientific mindset on and say, well, what's a metaphor and what's, what's like an actual empirical scientific truth within, within the scientific domain. And now he's a little bit half baked. Right. I mean the whole idea was based on the teaching. He had a, he was a mushroom trip. IOWASCA was. No, Oscar I think led him to the teaching.

Speaker 2:          01:54:45       I don't believe it was maybe. I mean it was silicide assignment. It might've been. Okay. Yeah, I mean, I know you know his brother, Dennis Mckenna. Very well. Yeah. Yeah. So, so they. Yeah, you read. Thanks. At the time we have zero was a little bit nonsense, but he read their, their book with true hallucinations. Yeah, right. The very, very, very, very interesting stuff and there is a mixture of deep insight there with a bunch of interesting metaphorical thinking problem and get involved in psychedelic drugs. It's hard to differentiate like what makes sense, what's, what's this unbelievably powerful insight and what is just some crazy idea you can learn to make that differentiation. You think so? Yes. Yeah. But, but, uh, yeah, I'm in granted, Terence Mckenna probably took more psychedelic drugs then I would generally recommend also he, he was speaking

Speaker 3:          01:55:44       all the time and there's something that I can attest to from podcasting all the time. Sometimes you just talking, you don't know what the fuck you're saying. You know, and you become a prisoner to your words and in a lot of ways, uh, you, you get locked up in this idea of expressing this thought that may or may not be viable.

Speaker 2:          01:56:02       I'm not sure that he was after empirical truth in the same sense that say ray Kurzweil when ray is saying we're going to get human level ai in 2029 and then you know, massively superhuman ai in a singularity in 20, 45. I mean ray ray is very literal. Like he's plotting charts, right? Terrence. Terrence was thinking on an impressionistic and and symbolic level is a. It was a bit different. So you have to take that in a poetic sense rather than in the literal sense. And yeah, I think it's very interesting to go back and forth between the, you know, the symbolic and poetic domain and the either concrete science and engineering domain, but it's also valuable to, to be able to draw that, draw that distinction, right? Because you can draw a lot of insight from the kind of thinking Terence Mckenna was, was doing and certainly if you explore psychedelics, you can gain a lot of insights into how the mind and universe work. But then when, when you put on your science and engineering mindset, you want to be rigorous about which insights do you take and which ones do you do throw out and ultimately you want that you want to proceed on the basis of, of what works and what doesn't. Right. I mean that Dennis was pretty strong on the terence was a bit less than that empirical direction.

Speaker 3:          01:57:31       Well, the dentist actually career scientists, um, how, how many people involved in artificial intelligence are also educated in the ways of psychedelics.

Speaker 2:          01:57:44       Yeah. That's all you have to say is that unfortunately, the illegal nature of these things, it's a little hard to pin down, I would say before the recent generation of people going into ai because it was a way to make money in the AI field was incredibly full of really, really interesting people and you know, deep thinkers about, about the mind. And in the last few years, of course ai has replaced like business school is what your grandma wants you to do, to have a good career. So I mean, you're getting, you're getting a lot of people into ai just because it's financial environment, it's, it's cool, it's financially viable, it's popular because I can, you know, in our generation, ai was not, ai was not what your grandma wants you to do so as to be able to buy a nice house for the family. Right. So you got into it because you really were curious about how the mind works and of course many people played with psychedelics because it also, they were curious about, you know, what it was teaching them about, about how their mind works.

Speaker 2:          01:58:52       Yeah. I had a nice long conversation with Ray Kurzweil and we talked for about an hour and a half and it was for the Song Scifi show that I was doing at the time and some of his ideas. He has this, uh, this, uh, this is number that they had people throw about like 20, 42, right? Isn't that, is that still 2045, a 45 now. Now you're being the optimist. Now you're combining that with Douglas off status for the two, which is the answer to the universe. No, the 42 thing was the New York conference that will take place in 2,245. Was it? I was at that conference that was organized by Demetrius Gov is another friend of mine from rush something off by three. It's 2045. So that was, that was, that was raised prognostication. Why, why that year? Um, he did some current methylations yeah. I mean he looked at Moore's law. He looks in the advanced and the accuracy of brain scanning and look at the events of computer memory, the miniaturization of various devices and like plugging a whole bunch of these curves.

Speaker 2:          01:59:58       That was the best guests that he came up with. What course? There's some confidence interval around that. What do you see as potential monkey wrenches that could be thrown into all this innovation? Like what were the, were the pitfalls? Well, I mean the pitfall is always the one that you, that you don't sit you very. I'm in, of course it's possible there's some science or engineering obstacle that we're not foreseeing right now. I mean it, it, it's also possible that all major nations are overtaken by like a religious fanatics or something which which, which slows down development somewhat a few thousand years. I think it would just be by a few decades, but yeah, I mean in terms of scientific pitfalls, I mean one possibility which I don't think is luckily one pass, but it's possible. One possibility is human, like intelligence requires advanced quantum computers, like it can't be done on the standard classical digital computer.

Speaker 2:          02:01:00       Do you think that's the case? No, but on the other hand, because there is no evidence that human cognition relies on quantum effects in the human brain, like based on everything we know about neuroscience now, it seems not to be the case. Like there's no evidence it's the case, but it's possible. It's the case because we don't understand everything about how the brain works. The thing is, even if that's true, like there's loads of amazing research going on in quantum computing and so we're going to have, you know, you'll probably have a qp new quantum processing unit in, in, in your phone and like a 10 to 20 years or something. Right. So I'm in, so that would, that might throw off 20 slash 45 date, but in a historical sense it doesn't change the picture, like I've got a bunch of research singing on my hard drive on how we improve open cogs, ai using quantum computers once we have better quantum computers.

Speaker 2:          02:01:52       Right? So there's, there could be other things like that which are technical roadblocks that we're not seeing now, but I really doubt those are going to delay things by more than like a decade or two or something. On the other hand, things could also go faster than than, than raised prediction, which is, which is what I'm pushing towards. So what are you pushing towards? What do you think I would like to get a human level general intelligence in five to seven years from now? Wow. I don't think that's bad by any means impossible because I think our open cog design is adequate to do it, but I mean it takes a lot of people working coherently for awhile to build something, something big like this, being in a physical form like a robot. It'll be in the compute cloud can use many robots as, as user interfaces, but the same ai control.

Speaker 2:          02:02:45       Many different robots actually and many other sensors and systems besides robots. I mean I think the human like form factor like we have with Sophia and our other Henson robots, the human like form factor is really valuable as a tool for allowing the cloud based ai mind to, you know, engage with humans and to learn human cultures and values. Because I mean getting back to what we were discussing it at the beginning of this chat, you know, the best way to get human values and culture into the AI is for humans and ai is to enter into many shared, you know, like social, emotional, embodied situations together. So having a human embodiment for the AI is important for that. Like I can look you in the eye, you can share your facial expressions, it can bond with you, it can see the way you react when you see like a sick person by the side of the road, there's something right and, and you know, can see you ask the ai to get, give the homeless person the $20 or something.

Speaker 2:          02:03:43       I mean the ai understands what money is and understands what that action means. Some in interacting with an ai in human life form is going to be valuable as a learning mechanism for the ai and as a learning mechanism for people to get more comfortable with ais. But I mean ultimately one advantage of being, you know, a digital mind is you don't have to be why the Dandy particular embodiment. Now I can go between many different bodies and they can transfer knowledge between the many different bodies that it's occupied. Well, that's the real concern that the people that are, that have this dystopian view of artificial intelligence hub is that ai may already exist and it's just sitting there waiting to Americans. Too many bad movies in Asia and Asia. Everyone thinks ai will be our friend and will love us and help us. Yeah, we're very, very, very much. That's what you're pumping out there. No, that's been as their philosophies I guess. I mean you look in Japanese anime. I mean there's been ais and robots for a long time. They're usually people's friends. There's dystopian aesthetic and it's the same in China and Korea. The general guests there is an ais and robots will be people's friends and will, will help people and then some other general guests in America is. It's going to be some big nasty Robo soldier marching down the street

Speaker 3:          02:05:09       beyond musk who we rely upon no smarter than us and he's fucking terrified of it. Sam Harris terrified of it for very smart people that just think it could really be a huge disaster for the human race.

Speaker 2:          02:05:22       I guess not just bad because know it's a cultural thing because the oriental culture is sort of social good oriented. Most orientals think a lot in terms of what's good for the family or the society as opposed to themselves personally and so they just make the default assumption that ais are going to be the same way whereas Americans are more like me, me, me oriented and I say that as an American as well and where they sort of assumed that ais are going to be possible. Right. Well whatever is in your mind, you impose on this ai when we don't actually know what it's going to become bright, but there it is.

Speaker 3:          02:06:07       There are potential negative aspects. Of course, artificial intelligence deciding that we're the logical and unnecessary.

Speaker 2:          02:06:18       Well we are a logical and unnecessary yes, but that doesn't mean that ai should be badly disposed towards us. I'm in. Did you see x Mokena? I did you like it? Sure. It was a copy of our robot. So it was, I mean our robots. So fear looks exactly like the robot in the American. So it was a good video that online. Yeah, yeah, yeah. Would tell Jamie how do you get the good video or just search for Sophia Hanson? Robot on Google? Yeah,

Speaker 3:          02:06:45       how advanced is Sophia right now? I mean how many different iterations have there been?

Speaker 2:          02:06:50       There's been something like 16, so fear robots made so far. We're moving towards scalable manufacturer over the next couple of years, so right now she's going around sort of as an ambassador for humanoid robot kind, giving, giving speeches and talks and various places. So she. So fear used to be called eva or we had a robot like the current Sophia that was called Eva and then x meshing that came out with the robot called Eva that exactly like the robot that that my colleague David Hanson and I made. I think it's a coincidence. Of course not. They just copy that. I mean of course the body they have is better and the AI is better in the movie than our robot ai is. So we changed the name to Sophia, which means wisdom in instead.

Speaker 3:          02:07:40       Was it freaky watching that though with the name eva?

Speaker 2:          02:07:44       The thing is that the moral of that movie is just if you know, if associate path raises a robot with an abusive interaction, it may come out to be a sociopath or psychopath. So let's, let's, let's not do that. Right. Let's raise our robots with love and compassion. Yeah. You see, the thing is that we have. I haven't seen this particular

Speaker 4:          02:08:12       great. What is she saying? She's not happy she was on Jimmy Fallon or something. That's David. This scope. How much is it actually interacting with them?

Speaker 2:          02:08:30       It has a chat system.

Speaker 4:          02:08:33       It really has a nice ring. Now I have to make clear that I didn't.

Speaker 2:          02:08:38       So yeah, so fear we can run using many different ai system so that there's a chat bot which is sort of like, you know, Alexa or google now or something, but with a bit a bit better ai and interaction with, with no emotion and face recognition and so forth. So it's not human level ai, but it is responding to a no. It understands what you say and it comes up with an answer and it can look you in the eye and make more than one language. Well, right now we can load it in English mode, Chinese motor Russian mode and there's sort of different different software packages and we also use her sometimes to experiment with their open cogs system and singularity now so we can. We can use the robot as a research platform for exploring some of our more advanced ai tools and then there's a simpler chatbots software which is used for appearances like, like, like that one and in the next year we want to roll out more of our advanced research software from open coggin singularity that rolled out more of that inside these robots, which is one among many applications we're looking at with our singular unit platform.

Speaker 3:          02:09:52       I want to get you back in here in like a year and find out where everything is because I feel like we need someone like you to sort of let us know where, where it's at, when it's run, when the switches about to flip. It seems to me that it might happen so quickly and the change might take place so rapidly that we really will have no idea what's happening before it happens.

Speaker 2:          02:10:20       We think about the singularity, like it's going to be some huge like physical event and suddenly everything turns purple in this cover with diamonds or something. Right? But I mean there's a lot voice. Something like this could unfold, so I can imagine that with our singularity, not decentralized network, you know, we get an ai that's smarter than humans and can create a new scientific discovery. The Nobel prize level, every minute there's something that that doesn't mean this ai is going to immediately like refactor all matter into, into images of a bucket head or do something run and I'm in. I mean if the AI has some caring and wisdom and compassion, then whatever changes happen, but it's the artist human characteristics, not necessarily in fact human passion just as humans are either the most intelligent nor the most compassionate possible creatures that that's. That's pretty clear.

Speaker 2:          02:11:20       If you look at the world around us and one of one of our projects that we're doing with this Sofia robot is aimed exactly at ai. Compassion's this has got the loving ai project and we're using this sophia robot as a, as a meditation assistant. So, so we're, we're using so fear to help people get into deep meditative trance states and help them breathe deeply and uh, achieve more, more positive state of being. And part of the goal there is to help people part of the goal as, as the AI gets more and more intelligent. You sort of getting the ai locked into a very positive, reflective and compassionate state. And I think, I think there's a lot of things in the human psyche and evolutionary history that hold us back from being optimally compassionate and that if we create the ai in the right way, it will be not only much more intelligent, much more compassionate than than human beings are.

Speaker 2:          02:12:20       And I mean this, we'd better do that like a. otherwise the human race is probably screwed to be blunt. I mean, if I think human beings are creating a lot of other technologies now with a lot of power, we're creating synthetic biology, we're creating nano technology, you know, we're creating smaller and smaller nuclear weapons and we can't control their proliferation. We're poisoning our environment. I think if we can't create something that's normally more intelligent but more wise and compassionate than we are, we're probably going to destroy ourselves by some method or another. I mean, with something like Donald trump becoming president. You see what happens when this, you know, primitive hindbrain and when our are unchecked, you know, mammalian emotions of anger and, and you know, status seeking and ego and rage and lost. When these things are controlling these highly advanced technologies, this, this is not going to come to a good end.

Speaker 2:          02:13:16       So we want compassionate general intelligences and this is what we should be orienting ourselves toward. And so we need to shift the focus of the AI and technology development on the planet toward, you know, benevolent, compassionate, General Intelligence. And this is subtle, right? Because you need to work with the establishment rather than overthrowing it, which isn't going to be viable, so this is while we're creating this decentralized self organizing ai network, the singularity net, then we're creating a for profit company, singularity studio, which will get large enterprises to use this decentralized network. Then we're creating these robots like Sophia, which will be mass manufactured in the next couple of years, rolled these out, this service robots everywhere around the world to interact with people and providing valuable services in homes and offices, but also interacting with people you know, in a loving and compassionate way. So we need to start now because we don't actually know if it's going to be years or decades before we get to this singularity and we wanted to be assured as we can that when we get there, it happens in a beneficial way for everyone.

Speaker 2:          02:14:32       Right. And things like robots, blockchain and ai learning algorithms are our tools. Toward that end. Ben, I appreciate your optimism. I appreciate coming near explaining all this stuff for us and I appreciate all your work. It's really amazing. Fascinating stuff. Yeah. Yeah. Well thanks for having me. It's really fun. That was a wide ranging conversation, so yeah, would it will be great to come back next year and update you on the state of the singularity once a year and just by the time you come from maybe who knows, a year from now, the world might be a totally different place. Maybe a robot. A robot now. Oh, thank you. Thank you everybody.