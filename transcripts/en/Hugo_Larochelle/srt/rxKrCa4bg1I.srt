1
00:00:00,120 --> 00:00:00,790
Yeah.

2
00:00:00,790 --> 00:00:01,301
In this video,

3
00:00:01,301 --> 00:00:04,960
we'll start our discussion on the
application of neural networks to computer

4
00:00:04,961 --> 00:00:05,980
vision problems.

5
00:00:08,650 --> 00:00:13,650
So we've looked so far the fundamentals
behind a fundamental ideas behind neural

6
00:00:13,811 --> 00:00:15,250
networks and concepts.

7
00:00:15,580 --> 00:00:19,870
And now we'll start looking at a
application of neural networks to specific

8
00:00:19,871 --> 00:00:24,220
problems. And this first series
of videos will look at, uh,

9
00:00:24,250 --> 00:00:27,370
specifically at computer vision problems.
Uh,

10
00:00:27,371 --> 00:00:31,060
computer vision is the design of
computers that can process visual data.

11
00:00:31,061 --> 00:00:36,061
So images or video to accomplish some
given tasks that humans can accomplish

12
00:00:36,761 --> 00:00:41,320
easily. And, uh, specifically in the, uh,

13
00:00:41,350 --> 00:00:43,150
this video in the upcoming videos,

14
00:00:43,270 --> 00:00:47,290
we'll focus on the problem of object
recognition, visual object recognition.

15
00:00:47,890 --> 00:00:51,450
So in that context, uh, the,
uh, computer or the, the,

16
00:00:51,451 --> 00:00:55,450
the program is giving us
input and image and a,

17
00:00:55,451 --> 00:01:00,400
the computer must identify what's the
identity of the object that's present at

18
00:01:00,401 --> 00:01:04,660
the center or more or less at the center
of the image. And so for instance,

19
00:01:04,661 --> 00:01:09,520
we have an example here from the very
famous caltech one o one data set to data

20
00:01:09,521 --> 00:01:13,780
set of how a hundred 101,
a different objects for which,

21
00:01:14,170 --> 00:01:18,250
uh, we have, uh, several examples
of images of those objects.

22
00:01:18,970 --> 00:01:23,150
And, uh, for instance, we
have an example here of a,

23
00:01:23,320 --> 00:01:24,760
the image of a sunflower,

24
00:01:24,761 --> 00:01:29,761
which is 112 pixels by 50 pixels and
the computer must take that as input and

25
00:01:31,601 --> 00:01:35,120
then tell us at the
output that, uh, this uh,

26
00:01:35,200 --> 00:01:40,200
particular image contains the image of a
sunflower where sunflower is one of the

27
00:01:40,541 --> 00:01:44,350
101 different categories in the Caltech,
one on one data center.

28
00:01:48,320 --> 00:01:53,050
So what we'd like to do is design neural
networks that are specifically adapted

29
00:01:53,051 --> 00:01:56,130
in design for computer vision problems.
Uh,

30
00:01:56,330 --> 00:01:59,230
the reason for that is that
Darson and issues with, uh,

31
00:01:59,300 --> 00:02:01,940
the type of data we have to
manipulate in computer vision.

32
00:02:02,300 --> 00:02:06,470
And there are certain characteristics
of the data we can also explore to get

33
00:02:06,500 --> 00:02:07,333
better results.

34
00:02:08,000 --> 00:02:13,000
So when the issue we have to think
about is that images are extremely high

35
00:02:13,221 --> 00:02:15,320
dimensional inputs.
Uh,

36
00:02:15,321 --> 00:02:19,100
so we've have an image
of 150 by 150 pixels.

37
00:02:19,430 --> 00:02:24,430
Then what we'll have to manipulate
really is 150 times 150 different inputs.

38
00:02:25,451 --> 00:02:29,030
So 22,000 times, sorry, 22,000,

39
00:02:29,031 --> 00:02:31,040
500 different inputs.

40
00:02:31,310 --> 00:02:35,300
And that's what gray scale images where
each input would be the intensity,

41
00:02:35,301 --> 00:02:37,910
the grayscale intensity
of each, uh, pixels.

42
00:02:37,911 --> 00:02:40,700
If we have RGB images and colors,

43
00:02:40,910 --> 00:02:45,170
then we have three times as much input
elements that we have to manipulate.

44
00:02:45,740 --> 00:02:50,060
So this means a lot of
parameters and this means a,

45
00:02:50,061 --> 00:02:55,040
so we can be, uh, quite a
susceptible to overfitting. And a,

46
00:02:55,041 --> 00:02:59,530
this also means a lot of computation
time if we're not careful. Okay.

47
00:03:00,850 --> 00:03:05,440
Uh, but also image data is, is
particular, uh, for instance,

48
00:03:05,500 --> 00:03:09,820
the order of the inputs is uh,
actually meaningful. In fact,

49
00:03:09,821 --> 00:03:11,590
more specifically,
uh,

50
00:03:11,591 --> 00:03:16,591
the pixels where each pixel is in
actual input for our neural network is

51
00:03:17,440 --> 00:03:20,170
organized in a particular to d topology.

52
00:03:20,171 --> 00:03:23,400
So pixels are organized spatially,
uh,

53
00:03:23,410 --> 00:03:26,740
where a certain pixels are close spatially
in other pixels are actually far away

54
00:03:26,741 --> 00:03:31,000
from each other in the specialty.
And the image a for video data.

55
00:03:31,001 --> 00:03:35,800
Then we have a three d topology
where pixels are organize both,

56
00:03:35,850 --> 00:03:38,410
uh,
spatially and through time.

57
00:03:39,280 --> 00:03:41,740
And so that's something we
might want to explore it.

58
00:03:42,250 --> 00:03:47,250
And also thinking about object
recognition Darson and then variances in,

59
00:03:47,830 --> 00:03:50,560
uh,
the way an input image might change,

60
00:03:50,561 --> 00:03:55,180
which actually doesn't change the
identity of the object in the image.

61
00:03:55,540 --> 00:03:56,141
So for instance,

62
00:03:56,141 --> 00:04:00,200
if we take an image and we take the
object in it and we actually translate it,

63
00:04:00,460 --> 00:04:01,660
then that should,

64
00:04:01,690 --> 00:04:05,820
that doesn't change the fact that the same
object is actually present in the, uh,

65
00:04:05,860 --> 00:04:10,390
in the image. If we change the
amount of illumination, uh,

66
00:04:10,450 --> 00:04:13,480
in the scene where we're
taking a picture of the image,

67
00:04:13,540 --> 00:04:17,590
that doesn't also change the identity
of the object in the, in the scene.

68
00:04:18,130 --> 00:04:21,250
And so that's also something we
would like to explore it in a,

69
00:04:21,251 --> 00:04:25,840
ideally to build some invariants and be
able to generalize to new pictures of

70
00:04:25,841 --> 00:04:28,390
the same object where the position,

71
00:04:28,420 --> 00:04:32,730
the exact position of the object that's
changed or the elimination has changed

72
00:04:32,731 --> 00:04:33,564
in the scene.

73
00:04:34,840 --> 00:04:39,650
So we'll focus on a type of
neural net that tries to, uh,

74
00:04:39,670 --> 00:04:43,420
exploits these. I explain these
ideas to get good performance.

75
00:04:43,690 --> 00:04:46,060
They're known as convolutional networks,

76
00:04:46,600 --> 00:04:51,600
and there are characterized by three
different properties that a really defined

77
00:04:51,851 --> 00:04:53,440
convolutional neural networks.

78
00:04:53,920 --> 00:04:57,760
The first one is local connectivity of
the hidden units, meaning that each shit,

79
00:04:57,761 --> 00:05:00,160
and yet it's going to be
connected only to a small,

80
00:05:00,210 --> 00:05:04,630
a small local region in the
image, uh, parameters sharing.

81
00:05:04,631 --> 00:05:06,880
So the hidden units,
a lot of the hidden units,

82
00:05:06,881 --> 00:05:10,450
we'll share parameters with
each other. And then, uh,

83
00:05:10,480 --> 00:05:15,480
the use of a pooling and sub sampling
operations between a hidden layers in a

84
00:05:16,391 --> 00:05:19,000
compulsion and neural network.
So in the following videos,

85
00:05:19,001 --> 00:05:22,510
we'll look at these three ideas separately
that really defined convolutional

86
00:05:22,511 --> 00:05:23,230
neural networks.

