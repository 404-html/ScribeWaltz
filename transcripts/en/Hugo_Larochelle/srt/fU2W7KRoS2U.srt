1
00:00:00,730 --> 00:00:01,301
In this video,

2
00:00:01,301 --> 00:00:06,220
we'll see how to compute the gradients
of the loss function with respect to the

3
00:00:06,221 --> 00:00:10,330
parameters of the lug, urinary factors
in a conditional random fields.

4
00:00:13,370 --> 00:00:15,020
So,
uh,

5
00:00:15,050 --> 00:00:18,830
we are deriving the stochastic
gradient descent training algorithm for

6
00:00:18,831 --> 00:00:21,770
conditional random fields and in
their chain conditional random fields.

7
00:00:22,040 --> 00:00:26,450
We've seen the last function before and
now we're going to start looking at how

8
00:00:26,451 --> 00:00:29,780
to compute the gradients with respect
to the different parameters of the log

9
00:00:29,781 --> 00:00:31,190
linear conditional random fields.

10
00:00:33,450 --> 00:00:36,450
So before we've defined the loss as the,
uh,

11
00:00:36,500 --> 00:00:41,500
negative log of the probability of the
true label sequence given the inputs

12
00:00:41,971 --> 00:00:43,830
sequence.
So now let's look at the gradient.

13
00:00:45,280 --> 00:00:46,113
Okay.

14
00:00:47,120 --> 00:00:47,953
Alright,

15
00:00:47,980 --> 00:00:52,980
so we'll focus now on the gradient with
respect to the urinary luck factors.

16
00:00:53,200 --> 00:00:56,530
That is a u r y k prime,

17
00:00:56,740 --> 00:00:59,520
where why keep prime
can be any class labels.

18
00:00:59,521 --> 00:01:03,100
So it's not necessarily the observe
class labels for any class label,

19
00:01:04,240 --> 00:01:08,500
sort of partial. There it live of
the negative log of their property,

20
00:01:08,501 --> 00:01:09,460
of a given sequence.

21
00:01:09,461 --> 00:01:14,461
Why given some input sequence x with
respect to the urinary factor for some

22
00:01:15,880 --> 00:01:17,810
arbitrary, uh, label,

23
00:01:17,811 --> 00:01:22,811
why prime acquisition k is going to
be actually quite similar to the,

24
00:01:23,501 --> 00:01:27,580
a gradient of the pre, uh, activation
at the output layer of a neural network.

25
00:01:27,820 --> 00:01:29,350
It's going to be minus.

26
00:01:30,250 --> 00:01:30,640
Okay.

27
00:01:30,640 --> 00:01:35,480
The, uh, uh, the, uh, identity
function of weather. Why k?

28
00:01:35,481 --> 00:01:39,430
So the Keith label and why
here is equal to y Prime K,

29
00:01:39,431 --> 00:01:44,020
which is d label for which
we're considering, uh, the,

30
00:01:44,110 --> 00:01:44,680
uh,

31
00:01:44,680 --> 00:01:49,680
the parameters of the urinary factors
minus the probability according to our

32
00:01:51,161 --> 00:01:56,161
model of actually observing for the Keith
label the actual value of y prime gay,

33
00:01:58,110 --> 00:02:00,400
uh, Ford, they give an input. So again,

34
00:02:00,401 --> 00:02:05,401
we have this a formula
which is essentially minus
what we would like to see,

35
00:02:05,890 --> 00:02:09,700
which is a, that's a w, oh,
sorry. What we actually observe,

36
00:02:09,701 --> 00:02:14,160
which is a label of white gay minus what,
uh,

37
00:02:14,320 --> 00:02:18,890
we currently predict. So
we have essentially a, uh,

38
00:02:18,930 --> 00:02:19,571
a term here,

39
00:02:19,571 --> 00:02:23,980
which is only one when we're considering
the union factor for the correct answer.

40
00:02:24,190 --> 00:02:28,110
Mine is the probability
distribution, uh, uh, the, uh,

41
00:02:28,180 --> 00:02:31,810
current value for the current value of
the parameters of the conditional random

42
00:02:31,811 --> 00:02:33,910
fields for the key of label.

43
00:02:34,590 --> 00:02:39,010
Cause that's actually quite similar to
the neural network reactivation, uh,

44
00:02:39,520 --> 00:02:43,480
uh, value add the output layer for
classification that we seen before.

45
00:02:44,620 --> 00:02:49,600
So if we consider the specific case of
a conditional random feel where we have

46
00:02:49,780 --> 00:02:54,160
for a given context of we just won
three different neural networks,

47
00:02:54,161 --> 00:02:57,830
one that computes sum
reactivation based on the uh,

48
00:02:58,000 --> 00:03:02,350
current position and other one
based on the input on the left.

49
00:03:02,351 --> 00:03:06,170
And then the one based on the input on
the right, we consider the gradient,

50
00:03:06,180 --> 00:03:09,730
which respect to uh,
all of these pre activation,

51
00:03:09,950 --> 00:03:14,500
a function at the output layer of these
three neural networks that would give us

52
00:03:15,010 --> 00:03:16,130
the following,
uh,

53
00:03:16,240 --> 00:03:21,240
gradients with the minus the one hot a
vector with a one at the real value of

54
00:03:23,501 --> 00:03:28,501
the label at position k minus the vector
of marginal probabilities for what the

55
00:03:30,310 --> 00:03:33,590
label might be according to the,
uh,

56
00:03:33,640 --> 00:03:36,440
current conditional random
fields for position. Okay.

57
00:03:37,420 --> 00:03:42,420
So that's for the neural network that
looks at the input at the current position

58
00:03:42,911 --> 00:03:46,900
came. And uh, if we're for the
one that's looking on the left,

59
00:03:46,901 --> 00:03:50,740
well the grading is going to
be zero if k is equal to one.

60
00:03:50,741 --> 00:03:54,850
So if it's not greater than one, and
that's because, uh, and four k equals one.

61
00:03:54,851 --> 00:03:59,320
There is no neural net trying to predict
from x zero since zero doesn't exist.

62
00:03:59,620 --> 00:04:02,660
And similarly, we have also
an indicator function, uh,

63
00:04:02,710 --> 00:04:05,830
for the one that looks to the right,
uh,

64
00:04:05,831 --> 00:04:09,920
so that the grain that is zero
if k is equal to capital k.

65
00:04:11,400 --> 00:04:15,840
So now let's look at the
derivation for this formula, uh,

66
00:04:15,870 --> 00:04:19,350
for uh, how, so let's try
to see why this is true.

67
00:04:21,220 --> 00:04:22,040
Okay?

68
00:04:22,040 --> 00:04:22,421
All right.

69
00:04:22,421 --> 00:04:27,421
So we're looking at the partial derivative
of the negative log probability of

70
00:04:28,390 --> 00:04:30,220
some vector of labels.

71
00:04:30,221 --> 00:04:34,880
Why given some input x with
respect to the, uh, uh,

72
00:04:34,930 --> 00:04:38,680
lug a factor, the urinary luck factor, uh,

73
00:04:38,681 --> 00:04:43,510
and its value for a, some given
label. Why prime cane so gay,

74
00:04:43,511 --> 00:04:46,900
it means we're looking at the
position came the sequence and right.

75
00:04:46,901 --> 00:04:49,990
Prime key would be some value
between one and capital's seat.

76
00:04:51,620 --> 00:04:51,830
Okay,

77
00:04:51,830 --> 00:04:53,720
so, uh, here,

78
00:04:54,110 --> 00:04:58,730
the only thing I've done is just write
what it is minus the log of p of y given

79
00:04:58,731 --> 00:05:02,210
x for a log linear,
sorry,

80
00:05:02,211 --> 00:05:03,860
for linear chain CRF.

81
00:05:04,310 --> 00:05:07,550
So remember we have dialogue of
the exponential of these terms.

82
00:05:07,551 --> 00:05:11,720
So we just have these terms. Once we
applied the log minus the log of zed,

83
00:05:11,721 --> 00:05:15,890
because before we had dividend
divided by the partition function.

84
00:05:16,100 --> 00:05:19,880
So the log of that would be minus
the log of the partition function.

85
00:05:23,230 --> 00:05:23,750
Okay.

86
00:05:23,750 --> 00:05:27,380
Now, uh, the gradients of this, sorry,

87
00:05:27,381 --> 00:05:29,300
the partial derivative
of this whole expression,

88
00:05:29,301 --> 00:05:32,630
which respect to that
term is going to be one.

89
00:05:32,631 --> 00:05:36,020
If the KF label is actually y prime k,

90
00:05:36,230 --> 00:05:40,200
otherwise that particular
expression is not going to be,

91
00:05:40,420 --> 00:05:42,020
it's not going to appear here.
Okay.

92
00:05:42,021 --> 00:05:47,021
So the gradient for any other position
then gay of these terms here is zero.

93
00:05:47,660 --> 00:05:51,910
The grid, the derivative with
respect to that, uh, of that, sorry.

94
00:05:51,911 --> 00:05:53,510
With respect to this,
it's also zero.

95
00:05:53,540 --> 00:05:57,260
So it's only the case for the
same k which is important.

96
00:05:57,440 --> 00:06:01,950
And if whyK is equal to pry prime k,
then we'll have the exactly the same term.

97
00:06:01,951 --> 00:06:05,270
So the death of thousands
going to be one now.

98
00:06:05,350 --> 00:06:07,780
Otherwise they're going to be zero.
And then minus that they're,

99
00:06:07,820 --> 00:06:09,650
they've upped the log partition function.

100
00:06:10,680 --> 00:06:11,140
Okay.

101
00:06:11,140 --> 00:06:15,250
So we're just like the narrative to
this minus that narrative to have that.

102
00:06:16,690 --> 00:06:17,523
Okay.

103
00:06:18,110 --> 00:06:22,190
So let's do that specific term that they
would have the lug partition function.

104
00:06:22,730 --> 00:06:27,730
So the derivative of the log is just
one over that one over zed types.

105
00:06:28,640 --> 00:06:33,230
It of, of, of whatever we were
taking the logarithm logarithm of,

106
00:06:35,520 --> 00:06:36,150
okay.

107
00:06:36,150 --> 00:06:39,180
Now here I'm just riding the
expression for the partition function.

108
00:06:39,210 --> 00:06:42,270
So because I've used a symbol,
why prime gay? I'll use instead.

109
00:06:42,310 --> 00:06:44,100
Why prime prime for,
uh,

110
00:06:44,220 --> 00:06:49,220
referring to the sequence of overs
over which I'm taking this sum here,

111
00:06:49,380 --> 00:06:50,213
the nest at some.

112
00:06:53,090 --> 00:06:53,730
Okay.

113
00:06:53,730 --> 00:06:56,640
Now I can push the,
uh,

114
00:06:56,641 --> 00:07:00,410
so did the narrative of a sum is the,
some of the derivatives,

115
00:07:00,411 --> 00:07:04,350
so I can push that they're the
insight here. So right here.

116
00:07:04,960 --> 00:07:06,780
So that's what I've done right here.

117
00:07:09,550 --> 00:07:14,230
And now, uh, they're the,
about the uh, exponentiate UD.

118
00:07:14,670 --> 00:07:19,090
Uh, some of, uh, factors
of luck, the factors, well,

119
00:07:19,120 --> 00:07:21,810
it here, uh, Aau, right?

120
00:07:21,820 --> 00:07:25,780
Prime K does not appear then
it's zero and it's, it won't,

121
00:07:25,990 --> 00:07:29,560
it won't appear if y Prime K
is not equal in the sequence.

122
00:07:29,561 --> 00:07:34,000
Y prime is not equal to right
prime prime cake. Uh, oh, sorry.

123
00:07:34,001 --> 00:07:38,860
In the sequence. Why [inaudible]
if I had the position gay, uh,

124
00:07:38,890 --> 00:07:43,630
it's value is not the value of
y prime gay then, uh, the, uh,

125
00:07:43,720 --> 00:07:45,880
then, uh, the derivative of
that is going to be zero.

126
00:07:45,890 --> 00:07:49,240
It's going in because it's going to be
constant with respect to that variable.

127
00:07:49,810 --> 00:07:51,550
However,
if it does appear,

128
00:07:51,970 --> 00:07:56,230
then the live of the exponential
is the exponential itself.

129
00:07:56,470 --> 00:08:00,520
So it's going to be that term and times
to their develop the argument. Well,

130
00:08:00,521 --> 00:08:03,940
it's just going to be one much
like it was one right here.

131
00:08:04,480 --> 00:08:08,560
So essentially what we'll get is
the indicator function of weather.

132
00:08:08,830 --> 00:08:13,830
Why prime case equal to y prime prime k
times the exponential of the sum of all

133
00:08:14,471 --> 00:08:15,310
luck factors.

134
00:08:17,300 --> 00:08:17,800
Yeah.

135
00:08:17,800 --> 00:08:19,780
Now let's notice that here,

136
00:08:19,900 --> 00:08:24,900
that's the numerator of the probability
to conditional problem probability in a

137
00:08:26,440 --> 00:08:30,640
conditional random fields.
And that's the partition function.

138
00:08:30,670 --> 00:08:31,570
So I can just,

139
00:08:32,440 --> 00:08:32,900
yeah,

140
00:08:32,900 --> 00:08:36,290
remove it here and just divide by here.

141
00:08:38,020 --> 00:08:38,290
Okay.

142
00:08:38,290 --> 00:08:39,490
And then what do I get?

143
00:08:39,790 --> 00:08:44,790
Well I get that this whole term here is
just the probability of observing as the

144
00:08:45,851 --> 00:08:47,230
sequence of labels,

145
00:08:47,610 --> 00:08:52,530
a y prime prime law and followed by why
program to up to why pride pride the

146
00:08:52,540 --> 00:08:56,700
capital k and then this here is here

147
00:08:59,760 --> 00:09:04,760
and now if I think there's some
over opposite all sequences of uh,

148
00:09:06,440 --> 00:09:10,260
and only consider the terms
were in all these sequences,

149
00:09:10,261 --> 00:09:15,000
I won't consider the sequences such that
y prime prime k is equal to y prime k,

150
00:09:15,330 --> 00:09:18,940
then I'm just summing the
probability of our sequences, uh,

151
00:09:18,990 --> 00:09:21,210
which satisfied this condition.

152
00:09:21,240 --> 00:09:25,190
So all sequences such that the key
element that the sequence is right,

153
00:09:25,191 --> 00:09:27,920
prime came. And so there's
some of all of these, uh,

154
00:09:28,020 --> 00:09:32,980
John probably is just the marginal
probability that y prime gay,

155
00:09:33,290 --> 00:09:37,620
uh, is the key if label in the
sequence. So I do obtain that.

156
00:09:37,621 --> 00:09:42,130
This term here is p of
y prime gay given x.

157
00:09:42,900 --> 00:09:46,740
And so I do have that the gradient,
the parts of their,

158
00:09:46,741 --> 00:09:51,030
they would just back to the logging area
factor is the indicator function minus

159
00:09:51,031 --> 00:09:52,710
the probability under the model.

160
00:09:56,620 --> 00:09:58,210
So that's great. I know, uh,

161
00:09:58,211 --> 00:10:01,750
we now have the gradients of the
and the partial data they've,

162
00:10:02,060 --> 00:10:04,120
with respect to the log you neri factor,

163
00:10:04,360 --> 00:10:08,140
but we don't have it with respect to the
parameters in the login error factor.

164
00:10:08,770 --> 00:10:10,350
Fortunately we've seen that,
uh,

165
00:10:10,430 --> 00:10:14,500
the backpropagation that allows us to
very efficiently applied the chain rule

166
00:10:14,501 --> 00:10:17,530
and back propagate the
gradients to all the parameters.

167
00:10:17,770 --> 00:10:21,070
So essentially from the
parameters of the login,

168
00:10:21,080 --> 00:10:24,900
there factors that gives me
essentially the uh, uh, uh,

169
00:10:24,910 --> 00:10:29,620
the partial though the which respect to
the pre activation values at the output

170
00:10:29,621 --> 00:10:32,940
layer of the neural
nets, uh, inside the CRF.

171
00:10:33,010 --> 00:10:36,640
And then I can just take those gradients,
those partial derivatives and back,

172
00:10:36,641 --> 00:10:39,520
propagate them towards all
the parameters of the model.

173
00:10:40,660 --> 00:10:45,280
Now notice that because it's the same
neural network at each position in the

174
00:10:45,281 --> 00:10:46,390
conditional random fields,

175
00:10:46,450 --> 00:10:51,450
I need to accumulate all the gradients
for every position and the sequence.

176
00:10:52,540 --> 00:10:56,620
So all of these greatest need to
be accumulated into, uh, the, uh,

177
00:10:56,650 --> 00:10:58,900
my computation of the parameter gradients.

178
00:11:01,260 --> 00:11:01,820
Okay.

179
00:11:01,820 --> 00:11:05,750
So let's look at the specific
case of linear, linear chain,

180
00:11:05,751 --> 00:11:10,670
conditional random fields. So the case
where the luck factors are linear. So, uh,

181
00:11:11,030 --> 00:11:13,820
this will be the neural
network from the center,

182
00:11:13,821 --> 00:11:17,090
the computation that looks
at the aligned input.

183
00:11:17,150 --> 00:11:21,620
So it'd be in linear transformation
plus bias. Then we have the,

184
00:11:21,650 --> 00:11:26,060
uh, uh, computation that looks
at, and sorry, that's a mistake.

185
00:11:26,090 --> 00:11:30,860
That should be, um, oh, sorry. Yeah,
so that's one way of writing it.

186
00:11:30,890 --> 00:11:34,610
I could have written it came out
is one here and k minus one here.

187
00:11:34,790 --> 00:11:37,640
I could have rhythm Kate bus one here.
Keep the last one here.

188
00:11:37,641 --> 00:11:41,110
But let's just assume now
that, uh, we have this, uh,

189
00:11:41,190 --> 00:11:45,050
lug linear model where the, uh, uh,

190
00:11:45,180 --> 00:11:49,100
urinary luck factors are just linear
function of the context window.

191
00:11:51,130 --> 00:11:51,963
Yeah.

192
00:11:52,430 --> 00:11:56,380
So in this, the, uh, Great
Edward, respect to the bias.

193
00:11:57,610 --> 00:11:58,091
And also,

194
00:11:58,091 --> 00:12:03,091
I just want to say that notice I didn't
put a bias here or here and that's

195
00:12:03,400 --> 00:12:07,480
because I would just be redundant
since, uh, I mean just a single bias,

196
00:12:07,830 --> 00:12:09,130
uh,
is sufficient.

197
00:12:11,710 --> 00:12:16,660
So the greatest of respect of
the bias would be the gradient,

198
00:12:17,080 --> 00:12:20,680
uh, with respect to the, uh, uh,

199
00:12:20,740 --> 00:12:25,600
pre activation function, uh,
for the center of the window,

200
00:12:25,840 --> 00:12:28,480
but summed over all positions.

201
00:12:28,481 --> 00:12:32,530
So that's the green of the activation
function at our position case or for all

202
00:12:32,531 --> 00:12:35,110
inputs xk all position can't actually,

203
00:12:35,830 --> 00:12:40,830
and we've seen before that the gradient
was essentially this the one hot vector

204
00:12:41,411 --> 00:12:45,510
minus the vector of marginal
probabilities for the position gain.

205
00:12:45,511 --> 00:12:49,970
So I'm just summing over all positions
game and now if only the greatest of

206
00:12:49,971 --> 00:12:51,710
respect to the weights,
uh,

207
00:12:51,970 --> 00:12:54,940
that connects the input that's
at the current position.

208
00:12:54,941 --> 00:12:58,960
K or that's to the left or to the right?
Well,

209
00:12:58,961 --> 00:13:03,310
I get something that's essentially
very similar. It's again,

210
00:13:03,311 --> 00:13:07,930
the a 100 vector minus the vector
marginal probabilities. But for,

211
00:13:08,400 --> 00:13:12,340
uh, this part of the Pr,
this parameter Matrix,

212
00:13:12,510 --> 00:13:17,510
I'm also surprised by the transpose
of the vector aligned with the current

213
00:13:19,391 --> 00:13:23,680
position. K. This one I multiplied
by the vector to the left,

214
00:13:23,740 --> 00:13:25,480
the transpose of the vector to the left,

215
00:13:25,481 --> 00:13:27,880
and he transposed to the
of the vector to the right.

