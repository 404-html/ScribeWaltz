1
00:00:00,880 --> 00:00:05,250
And this video will motivate the design
of neural networks that are dedicated

2
00:00:05,251 --> 00:00:07,440
for natural language processing problems.

3
00:00:09,930 --> 00:00:13,510
So natural process,
natural language processing is a,

4
00:00:13,560 --> 00:00:18,560
the field that concerns itself with any
problem or tasks that involve some sort

5
00:00:19,021 --> 00:00:23,580
of language data. Uh, in the, uh,
this veto. In the following videos,

6
00:00:23,581 --> 00:00:26,950
we'll actually focus on textual data,
uh,

7
00:00:26,970 --> 00:00:31,970
so data from web pages or written
documents that have been converted into a

8
00:00:33,481 --> 00:00:37,230
actual words like Ascii
characters for instance. Um,

9
00:00:37,260 --> 00:00:42,260
speech processing is often considered
as part of the types of problems where,

10
00:00:42,830 --> 00:00:45,790
uh, that NLP addresses, uh,

11
00:00:45,810 --> 00:00:50,040
but it actually has its own
dedicated, uh, research community.

12
00:00:50,220 --> 00:00:51,330
That's what our conferences,

13
00:00:51,331 --> 00:00:55,950
just for speech processing and the natural
language processing conferences often

14
00:00:56,340 --> 00:01:00,570
mainly concerned themselves and
concentrate on a textual processing.

15
00:01:00,990 --> 00:01:04,620
And so in the following videos,
we'll mainly focus on that text data.

16
00:01:05,760 --> 00:01:07,820
So much like for computer vision,
uh,

17
00:01:07,860 --> 00:01:12,180
we could think about whether we
could design neural networks that are

18
00:01:12,270 --> 00:01:17,270
specifically designed for solving
a text processing problems.

19
00:01:18,300 --> 00:01:23,300
And one particular a specificity of
textual data that we'll want to take into

20
00:01:24,181 --> 00:01:27,930
account with design neural networks in
order to design better neural networks

21
00:01:27,931 --> 00:01:31,260
for textual data is the
fact that as we'll see,

22
00:01:31,261 --> 00:01:34,710
text data is inherently high dimensional.
Uh,

23
00:01:34,800 --> 00:01:39,800
the words that will be manual
relating for performing certain, uh,

24
00:01:39,870 --> 00:01:44,340
tasks, uh, we'll see that
intrinsically a priority.

25
00:01:44,341 --> 00:01:49,140
They are very, very high dimensional
objects and manipulating dose,

26
00:01:49,410 --> 00:01:52,650
uh, in a naive way in the neural
network can lead to some problems.

27
00:01:53,010 --> 00:01:56,100
And so there have been
solutions for, uh, the,

28
00:01:56,101 --> 00:01:59,370
this particular high
dimensionality problem for an
LP that had been introduced.

29
00:01:59,760 --> 00:02:04,440
And, uh, as we see in the following
videos, we'll see how to leverage, uh,

30
00:02:04,441 --> 00:02:07,830
and directly address the
high dimensionality of words.

31
00:02:07,860 --> 00:02:12,030
And then it will be problems
for many different tasks.

32
00:02:12,450 --> 00:02:14,550
So we'll see that in the following videos.

