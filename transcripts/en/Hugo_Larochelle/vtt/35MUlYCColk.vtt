WEBVTT

1
00:00:00.630 --> 00:00:01.360
Okay.

2
00:00:01.360 --> 00:00:05.530
<v 1>In this video we'll finally look at the derivation for the pre training</v>

3
00:00:05.531 --> 00:00:07.600
procedure and a deep belief network.

4
00:00:09.060 --> 00:00:09.893
<v 0>Okay.</v>

5
00:00:10.430 --> 00:00:13.440
<v 1>So,
uh,
now we seen the version all bound.</v>

6
00:00:13.480 --> 00:00:17.800
We're ready to see the detail of the derivation for how we can,
uh,

7
00:00:17.860 --> 00:00:21.620
pre train a deep belief network by first training in Rpm.

8
00:00:21.890 --> 00:00:26.890
Then taking it Suedes as is as the initialization of the first uh,

9
00:00:27.640 --> 00:00:31.760
layer sitting my belief net of a two hidden layer at DPN and then pretrained

10
00:00:31.761 --> 00:00:35.000
only the top RBM part.
And then once that's finished,

11
00:00:35.420 --> 00:00:37.280
we use the uh,

12
00:00:37.430 --> 00:00:42.170
weights of the VPN here as the initialization for this thing might belief net,

13
00:00:42.390 --> 00:00:45.200
uh,
for the two hidden layers in three hidden there.

14
00:00:45.201 --> 00:00:50.201
Dbn and then we are trained only the top RBM part and so on for as many layers

15
00:00:50.451 --> 00:00:54.330
as we want.
Um,
in what follows?
Uh,

16
00:00:54.380 --> 00:00:59.270
I'm going to focus on the case where we start from a,

17
00:00:59.290 --> 00:01:00.720
uh,
first,
uh,

18
00:01:01.010 --> 00:01:06.010
one he didn't layer DPN or just an RBM and then we use it to initialize a,

19
00:01:06.430 --> 00:01:09.620
uh,
two hidden,
they are DPN where we take these weights,

20
00:01:09.740 --> 00:01:12.950
initialize the sigma belief net part here.

21
00:01:13.220 --> 00:01:17.870
And then a train the top a restricted Boltzmann machine here.

22
00:01:19.010 --> 00:01:23.360
So keep this a specific case in mind in what follows.

23
00:01:26.070 --> 00:01:28.730
So we saw the various snowbound which uh,

24
00:01:28.880 --> 00:01:33.320
gives us for any model with uh,
some latent variables,

25
00:01:33.760 --> 00:01:38.760
a lower bound here on the actual log probability for some given observation x.

26
00:01:42.370 --> 00:01:44.080
And uh,
when we've,

27
00:01:44.090 --> 00:01:48.350
when we've seen in particular is that in this version Nobel and we introduce a

28
00:01:48.530 --> 00:01:52.460
variational posterior Qa h one given x and that,
uh,

29
00:01:52.490 --> 00:01:56.180
if Q h one is equal to p of h one,
then it's actually very tight.

30
00:01:56.450 --> 00:01:59.810
We get inequality between this and that.
And uh,

31
00:01:59.840 --> 00:02:04.310
the courses actually cue is going to be with respect to p uh,

32
00:02:04.330 --> 00:02:06.410
the pursue your p of h one given x,

33
00:02:06.530 --> 00:02:10.220
then the tighter the bound here is going to be.
Okay.

34
00:02:10.221 --> 00:02:13.610
So that's something we're going to exploit in our derivation of the pre training

35
00:02:13.611 --> 00:02:14.444
algorithm.

36
00:02:15.530 --> 00:02:16.363
<v 0>Okay.</v>

37
00:02:16.690 --> 00:02:21.360
<v 1>All right.
First thing we're going to do is that will,</v>

38
00:02:21.450 --> 00:02:25.410
uh,
instead of writing this term here as like a p of x,

39
00:02:25.660 --> 00:02:30.660
give p of x and h one we had to write it as the sum of a log of p of x given h

40
00:02:33.721 --> 00:02:38.040
one plus logo,
p of h one.
So that's because,
uh,

41
00:02:38.070 --> 00:02:42.030
p of x given h p of x and h one is a product of this times.

42
00:02:42.060 --> 00:02:45.390
That is what we think the log,
it's just a,
some of them.
Okay.

43
00:02:47.400 --> 00:02:51.690
Now imagine that,
uh,
so in this,
sorry,

44
00:02:51.691 --> 00:02:53.760
in the single hidden layer DPN,

45
00:02:53.790 --> 00:02:58.790
which really is just an RBM p of x given h one and p of h one,

46
00:03:00.730 --> 00:03:04.180
uh,
depending on the same parameters of the same model.

47
00:03:04.390 --> 00:03:07.520
So this is just the regular conditional in the risk.

48
00:03:07.680 --> 00:03:12.680
Most machine and P of h one would actually curse fun to,

49
00:03:13.420 --> 00:03:15.190
um,
sorry.

50
00:03:15.330 --> 00:03:20.330
Poh One would be equal to the sum over all values of x of p of x and h one.

51
00:03:22.060 --> 00:03:27.060
So that's how we could compute p of h one in one hidden layer DPN or just a,

52
00:03:28.570 --> 00:03:30.640
which is just a regular restricted posts from Michigan.

53
00:03:31.760 --> 00:03:32.120
<v 0>Okay.</v>

54
00:03:32.120 --> 00:03:36.830
<v 1>So when we jump to the two hidden there DPN case,
uh,</v>

55
00:03:36.831 --> 00:03:41.831
what we will do as we've described before is that to model p of h one we'll use

56
00:03:44.331 --> 00:03:49.331
a separate model with its own set of parameters and the model we'll use is going

57
00:03:50.391 --> 00:03:55.370
to be an RBM which has its own additional hidden layer h two.

58
00:03:56.120 --> 00:03:57.080
So in other words,

59
00:03:57.400 --> 00:04:02.400
p of h one once we go from a single rpm to a uh,

60
00:04:02.660 --> 00:04:03.320
to hidden there,

61
00:04:03.320 --> 00:04:08.320
DBN is going to curse fund to the marginalization of that second hidden layer in

62
00:04:09.921 --> 00:04:13.370
this,
uh,
top most RBM that we've introduced.

63
00:04:13.670 --> 00:04:18.670
So pfh one is going to be the sum over h two of a Pov h one and h two where this

64
00:04:19.401 --> 00:04:24.080
is an RBM with its own set of parameters that are not the same parameters as in

65
00:04:24.130 --> 00:04:27.180
a p of x given h one.
So this is to,

66
00:04:27.980 --> 00:04:32.150
this part is going to have its own set of connections between h x and h one.

67
00:04:32.151 --> 00:04:35.410
And this is going to have its own connections between h one and h two.

68
00:04:38.880 --> 00:04:39.713
<v 0>Okay.</v>

69
00:04:39.900 --> 00:04:44.670
<v 1>So if we do this,
uh,
it means that once we've added this second layer,</v>

70
00:04:44.671 --> 00:04:48.510
we've not untied the parameters with respect to which we have to do an

71
00:04:48.511 --> 00:04:53.370
optimization where we're training a between this part of the bound and this

72
00:04:53.371 --> 00:04:54.000
part.

73
00:04:54.000 --> 00:04:59.000
So now this part is a free with respect to changes to this part here because

74
00:05:00.901 --> 00:05:04.650
they have different parameters.
And in the Katrina peer training case,

75
00:05:04.651 --> 00:05:06.840
actually we were just going to fix that part.

76
00:05:06.841 --> 00:05:09.060
We'll just assume that this is not moving anymore.

77
00:05:09.061 --> 00:05:12.210
We're using the same parameters for p of x given h one,

78
00:05:12.211 --> 00:05:16.650
and they're going to be a set to the uh,
uh,

79
00:05:16.710 --> 00:05:20.640
parameters of the single layer RBM that we've pretrained initially.

80
00:05:21.180 --> 00:05:25.350
And so when we get to train the second layer,
we only need to change.

81
00:05:25.351 --> 00:05:28.590
We're only changing this part here because the predators aren't involved in that

82
00:05:28.830 --> 00:05:32.740
section.
So if we train our,
uh,

83
00:05:32.810 --> 00:05:36.690
second hidden there to maximize the bone,
it's,

84
00:05:36.780 --> 00:05:38.550
it means that,
um,

85
00:05:38.880 --> 00:05:42.560
the only terms here that are dependent on the parameters of that second hidden

86
00:05:42.570 --> 00:05:46.740
there are here.
So in other words,

87
00:05:46.950 --> 00:05:50.410
we can ignore that because it doesn't depend on the second hidden their

88
00:05:50.430 --> 00:05:55.110
parameters.
And we can ignore all of this because to have a h one given x,

89
00:05:55.111 --> 00:05:59.360
that's a separate posterior model and the approximate exterior,
uh,

90
00:05:59.361 --> 00:06:01.940
which we'll talk about in the next slide,
but it's,

91
00:06:01.941 --> 00:06:06.170
it's separate that has its own set of parameters which,
which are not adjusted.

92
00:06:07.340 --> 00:06:09.350
And so if we're maximizing this,

93
00:06:09.351 --> 00:06:14.120
then it's the same thing as minimizing minus that which is here.

94
00:06:14.150 --> 00:06:16.190
So minus the sum over each one of Qa,

95
00:06:16.191 --> 00:06:19.460
h one given x times log of p of h one.

96
00:06:20.990 --> 00:06:24.650
And um,
and because this is an RBM,

97
00:06:24.800 --> 00:06:29.800
it actually corresponds to minimizing the negative log likelihood of,

98
00:06:30.800 --> 00:06:31.633
um,

99
00:06:31.700 --> 00:06:35.840
examples or samples from queue of h one given x.

100
00:06:35.900 --> 00:06:40.630
So it's like we're training in RBM on data that was generated for,
uh,

101
00:06:40.670 --> 00:06:45.200
by Q of h one given x by our approximate mysteria.
Okay.

102
00:06:45.201 --> 00:06:48.500
So when we're maximizing dispositional bound,

103
00:06:48.920 --> 00:06:53.180
it's now been converted to the problem of training in Rpm on some of the

104
00:06:53.240 --> 00:06:56.710
observations that are generated by this approximate the mysterium.

105
00:06:57.350 --> 00:06:59.780
So for a given training example x,

106
00:07:00.230 --> 00:07:05.230
what we could do is generate a bunch of samples from Q of h one given x and then

107
00:07:05.660 --> 00:07:10.070
use those,
provide those to the learning algorithm of the RBM,
which is going to,

108
00:07:10.290 --> 00:07:11.750
uh,
optimize the,

109
00:07:11.751 --> 00:07:15.710
its parameters to minimize the negative log likelihood of these parameters.

110
00:07:16.280 --> 00:07:18.830
And if we have a whole training,

111
00:07:18.860 --> 00:07:23.270
a set of examples x that it means that we would actually,

112
00:07:23.390 --> 00:07:24.920
for each training example,

113
00:07:24.921 --> 00:07:29.921
we'll need to provide a set of samples from Q of h one given x t.

114
00:07:30.120 --> 00:07:32.690
So now we'd have separate training examples.

115
00:07:32.700 --> 00:07:36.430
We'd collect this big training set of uh,

116
00:07:36.810 --> 00:07:41.510
a sample hidden layers for a where we get a few samples from each training

117
00:07:41.511 --> 00:07:45.530
example and putting all those together would feed that to the learning algorithm

118
00:07:45.531 --> 00:07:48.630
or restricted poster machine.
And that's how we could,
uh,

119
00:07:48.710 --> 00:07:51.800
try to optimize this lower bound here.

120
00:07:52.790 --> 00:07:55.650
So this starts to look a lot like a,

121
00:07:55.670 --> 00:08:00.020
the training procedure we seen before where to train the second layer of a feet

122
00:08:00.021 --> 00:08:01.790
for no network with Matt,

123
00:08:02.090 --> 00:08:05.430
transform all the data from the,
uh,

124
00:08:05.450 --> 00:08:10.040
of its input representation x to the latent representation h of x.

125
00:08:10.041 --> 00:08:11.410
And then we train,
uh,

126
00:08:11.730 --> 00:08:14.870
an additional second hidden layer on top of that representation.

127
00:08:15.350 --> 00:08:18.080
What has changed is that in this context,

128
00:08:18.081 --> 00:08:21.830
what is different is that we actually sampling from a posterior to get these

129
00:08:21.831 --> 00:08:24.920
observations were not performing it just a Ford Past.

130
00:08:28.400 --> 00:08:32.780
Now what should we use for this approximate posterior cue of h one given x?

131
00:08:34.310 --> 00:08:37.460
This bound applies in any case,
but we know that it's tight.

132
00:08:37.520 --> 00:08:41.150
If Qa h one given x is actually close to the,
uh,

133
00:08:41.200 --> 00:08:45.830
posterior peak of h one given x in this two hidden layer DBM.

134
00:08:47.450 --> 00:08:52.450
So what we'll use is actually the posterior of the first layer RBM.

135
00:08:53.480 --> 00:08:57.480
So,
uh,
in other words,
uh,
if you remember,

136
00:08:57.481 --> 00:09:01.170
if you have a single layer,
RBM,
um,

137
00:09:01.290 --> 00:09:06.140
computing the getting the per is equivalent to or requires to do it four feet

138
00:09:06.141 --> 00:09:09.600
forward,
sigmoidal computing a feet forward sigmoidal layer,

139
00:09:09.601 --> 00:09:13.140
which gives us all the probabilities of each hidden units.

140
00:09:13.440 --> 00:09:18.180
And then to sample from that,
mysteria would just look at each value,

141
00:09:18.400 --> 00:09:20.280
uh,
in the Avi Chit in unit.

142
00:09:20.670 --> 00:09:25.530
And then this would give us the probability of each in an unit being sampled to

143
00:09:25.531 --> 00:09:26.364
one.

144
00:09:26.970 --> 00:09:30.570
So to get a two sample from that choice of posterior,

145
00:09:30.571 --> 00:09:34.740
which would be the posterior of are a model that has just one hidden layer and

146
00:09:34.741 --> 00:09:35.940
corresponds to an RBM,

147
00:09:37.050 --> 00:09:39.990
we would just compute if feed forward pass and then sample.

148
00:09:41.370 --> 00:09:46.370
Now what's interesting here is that if we initialize the weights of the second

149
00:09:46.741 --> 00:09:49.620
layer RBM in our second,
uh,

150
00:09:49.621 --> 00:09:52.020
in our two hidden their deep belief network,

151
00:09:52.560 --> 00:09:56.940
then we will start our optimization problem,
uh,

152
00:09:57.000 --> 00:10:00.720
at a point where this is exactly equal to that.

153
00:10:01.980 --> 00:10:03.280
Um,
so,
and,

154
00:10:03.350 --> 00:10:08.350
and that's because a to hidden layer a db n is actually equivalent to one hidden

155
00:10:09.361 --> 00:10:12.510
there RBM.
So let's look at that in more detail.

156
00:10:13.550 --> 00:10:14.010
<v 0>Okay.</v>

157
00:10:14.010 --> 00:10:17.280
<v 1>So imagine we have a one hidden layer RBM.</v>

158
00:10:18.360 --> 00:10:22.140
So here to simplify to illustration,
just assume x and h one are vectors.

159
00:10:23.100 --> 00:10:27.250
And now we want to actually initialize the,
uh,

160
00:10:27.330 --> 00:10:28.620
we're going to start training

161
00:10:28.990 --> 00:10:29.823
<v 0>a</v>

162
00:10:30.840 --> 00:10:35.280
<v 1>two hidden there.
DBN.
So where we have directed edges here,</v>

163
00:10:36.970 --> 00:10:40.420
and we've added this a second hidden there,
here,

164
00:10:40.421 --> 00:10:43.300
and here we have undirected edges.
So this farms in RBM.

165
00:10:45.230 --> 00:10:47.270
So the first thing to notice if,
uh,

166
00:10:47.390 --> 00:10:52.390
these connections are parent tries by w and if we take them this same w and we

167
00:10:53.181 --> 00:10:54.590
fix it to the parameters here,

168
00:10:54.591 --> 00:10:59.420
and then for this layer we actually use w transpose.
So in other words,

169
00:10:59.421 --> 00:11:03.680
we set the parameters here to be w transpose the transpose of this matrix here.

170
00:11:04.220 --> 00:11:07.910
Then this model and that model are exactly equivalent.

171
00:11:08.480 --> 00:11:12.830
So one way to think,
uh,
to see this is that if were to sample from,

172
00:11:13.100 --> 00:11:14.690
uh,
this RBM,

173
00:11:14.691 --> 00:11:18.800
we would say initialized x to some random values and we'd perform gib sampling.

174
00:11:18.830 --> 00:11:23.600
So we sample h one and an x and an h one and an excellent,
continue like this.

175
00:11:23.900 --> 00:11:28.890
Uh,
infinitely.
And then at some point,
um,
you know,
as if we get close to,
uh,

176
00:11:28.930 --> 00:11:31.310
the equal in distribution,
we could just observe x in,

177
00:11:31.311 --> 00:11:34.790
this would be a sample from,
uh,
from the distribution.

178
00:11:35.600 --> 00:11:39.950
Now if you want it to sample from,
uh,
two hidden layer DBN,

179
00:11:40.340 --> 00:11:40.880
uh,

180
00:11:40.880 --> 00:11:45.620
w we do is that we could say we have to do Gibbs sampling here and eventually

181
00:11:45.740 --> 00:11:46.640
sample x.

182
00:11:47.540 --> 00:11:52.540
But because this is w transpose and this is w performing gib sampling here is

183
00:11:53.171 --> 00:11:57.370
equivalent to performing gib sampling here.
Uh,
so in other words,

184
00:11:57.520 --> 00:11:58.390
when for instance,

185
00:11:58.391 --> 00:12:03.100
we're sampling from h one to x discourages funds to taking each one and sampling

186
00:12:03.101 --> 00:12:06.160
age too.
It's the same exact same procedure.

187
00:12:06.820 --> 00:12:11.410
And once we get an h one and we simple x instead,

188
00:12:12.310 --> 00:12:14.620
then,
um,
this actually again,

189
00:12:14.740 --> 00:12:19.120
is exactly the same thing as taking each one and sampling each do instead.

190
00:12:19.810 --> 00:12:23.620
So in other words,
if we take all of the Gibbes sampling steps here,

191
00:12:23.650 --> 00:12:26.440
they could equally,
uh,

192
00:12:26.500 --> 00:12:28.960
have been derived by doing gib sampling here.

193
00:12:28.961 --> 00:12:31.930
And then the very last step of good sampling,

194
00:12:32.410 --> 00:12:35.140
going from age one to x instead and observing x.

195
00:12:36.310 --> 00:12:39.490
So from that argument,
these two models are exactly the same,

196
00:12:39.670 --> 00:12:44.320
which means that initially if we've initialize the parameters of the second

197
00:12:44.321 --> 00:12:47.890
layer RBM as the transpose of the first hidden layer,

198
00:12:48.430 --> 00:12:51.880
then it means that the posterior,
uh,

199
00:12:51.910 --> 00:12:54.670
as we computed in a first hidden layer,

200
00:12:54.700 --> 00:12:58.870
one hand them their RBM is the trooper steer or also for that model.

201
00:13:00.250 --> 00:13:02.320
And so if to sum up,

202
00:13:02.350 --> 00:13:07.350
if we initialize the two hidden layer DBM by first training in RBM taking it

203
00:13:09.241 --> 00:13:11.710
swayed w and initializing the weights here,

204
00:13:11.711 --> 00:13:14.410
two w and the way it's here to w transpose,

205
00:13:14.770 --> 00:13:19.360
we have that by using this posterior a of h one given x,

206
00:13:19.720 --> 00:13:19.960
uh,

207
00:13:19.960 --> 00:13:24.960
we are starting optimization at a point where this is exactly equal to or lower

208
00:13:25.391 --> 00:13:26.224
bound here.

209
00:13:26.890 --> 00:13:31.120
And then as we're going to train in our greedy peer training procedure,

210
00:13:31.150 --> 00:13:35.020
only those weights here.
So we're only changing the weights here.

211
00:13:35.020 --> 00:13:40.020
So they're going to depart from w transpose then our approximation here,

212
00:13:41.171 --> 00:13:44.640
which is only going to use w,
uh,

213
00:13:44.850 --> 00:13:49.570
where w is kept fixed.
Uh,
as we're changing these values and we keep those fixed,

214
00:13:49.600 --> 00:13:51.180
then it's not going to be true anymore.

215
00:13:51.181 --> 00:13:56.181
Cue of h one given x is not going to be equal to the troop posterior appeal of h

216
00:13:56.201 --> 00:13:58.780
one given x in this two hidden there.

217
00:13:58.781 --> 00:14:03.781
Dbn but what's nice is that at least we have a good initialization starting

218
00:14:04.091 --> 00:14:05.940
point where we are tightly uh,

219
00:14:06.130 --> 00:14:09.520
close to what's the true luck probability of the data.

220
00:14:09.610 --> 00:14:12.800
And as we move along well we'll keep pushing uh,

221
00:14:13.240 --> 00:14:17.860
from that point on the lower bound up and which means that we're guaranteed to

222
00:14:17.861 --> 00:14:22.060
at least improve over a log of p of x a little bit and uh,

223
00:14:22.570 --> 00:14:27.220
uh,
as uh,
optimization progresses.
Um,

224
00:14:27.280 --> 00:14:31.570
then we'll all be optimistic optimizing a variational bounds or a lower bound

225
00:14:31.571 --> 00:14:32.620
the log of p of x,

226
00:14:32.621 --> 00:14:36.070
but at least we'll have started at a point where we were at the first step will

227
00:14:36.071 --> 00:14:37.270
be guaranteed to improve it.

228
00:14:39.130 --> 00:14:44.130
And so that's the justification for providing using this person and layer with

229
00:14:44.531 --> 00:14:48.580
its suedes w to initialize the to hit and they're at DBN.

230
00:14:48.640 --> 00:14:51.190
That's because in this bearish no bound setting,

231
00:14:51.440 --> 00:14:56.440
we actually gets a tight correspondence between the version of bound of the two

232
00:14:56.661 --> 00:15:01.661
hidden there DBN and its actual log probability for some given example X.

233
00:15:06.210 --> 00:15:10.410
Okay.
So,
um,
so I've just described how we set u h one given x,

234
00:15:10.411 --> 00:15:15.411
we just used the previously pretrained weights to derive ARPA steer over the uh,

235
00:15:16.830 --> 00:15:21.830
hidden layer h one and then we'll use that posterior to train an RBM,

236
00:15:23.010 --> 00:15:26.910
which is the second layer RBM at corresponds to p of h one here.

237
00:15:27.090 --> 00:15:30.840
And the way we do that is that we take each training sample XD,

238
00:15:31.050 --> 00:15:33.390
we sample a hidden there for it.

239
00:15:33.630 --> 00:15:37.530
We construct a training set like this and then we feed it to a learning

240
00:15:37.531 --> 00:15:39.180
algorithm for a restricted Boltzmann machine,

241
00:15:39.181 --> 00:15:43.090
which is going to train the weights of that second hidden layer.
Um,

242
00:15:43.920 --> 00:15:48.870
in practice people often instead of sampling from Qa h one given x,

243
00:15:49.050 --> 00:15:54.050
they will actually use the factor of probabilities as if we were doing for

244
00:15:54.451 --> 00:15:58.530
propagation,
their regular neural network.
This is really an approximation.

245
00:15:58.560 --> 00:16:00.690
There's not a lot of justification for doing that,

246
00:16:00.691 --> 00:16:02.400
but that's what people do in practice.

247
00:16:02.640 --> 00:16:04.650
If most of the units are either zero and one,

248
00:16:04.651 --> 00:16:08.550
it's going to be very close to the actual thing.
Uh,
and uh,

249
00:16:08.551 --> 00:16:11.490
and practice it works well.
And now if we do this,

250
00:16:11.491 --> 00:16:15.630
then we get exactly the pre training procedure for feed forward neural network

251
00:16:15.990 --> 00:16:16.950
where we use,

252
00:16:17.010 --> 00:16:21.940
because this vector of probabilities is this h of x that we've,
uh,

253
00:16:22.100 --> 00:16:24.840
uh,
defined in the context of a feed forward no network.

254
00:16:25.260 --> 00:16:28.020
So then we get exactly the pre training procedure.

255
00:16:32.000 --> 00:16:36.650
Now we can repeat this procedure,
uh,
by adding more and more hidden layers.

256
00:16:36.651 --> 00:16:40.430
So we started with a first hidden there,
uh,
one hidden there,

257
00:16:40.431 --> 00:16:45.110
RBM and then we use these weights to initialize the,
do a hidden there RBM.

258
00:16:45.290 --> 00:16:49.190
And then again,
uh,
what we do for a three hidden there.

259
00:16:49.250 --> 00:16:52.820
DBN sorry.
Yeah,
I meant to hit in there DBN here.

260
00:16:52.890 --> 00:16:54.830
And then to get a three hidden in there at Dbn,

261
00:16:55.550 --> 00:16:59.690
we just think the prior here and convert it into an RBM.

262
00:16:59.691 --> 00:17:04.280
And then we use the weights that were pretrained here as the fixed value for

263
00:17:04.281 --> 00:17:05.114
these weights here.

264
00:17:05.960 --> 00:17:10.160
And then to get our posterior up to this layer layer here,

265
00:17:10.400 --> 00:17:14.570
we actually go up by using the same weights.
Okay.

266
00:17:14.600 --> 00:17:19.160
So we using the same weights to go up in the hidden there.
Now at this point,

267
00:17:19.161 --> 00:17:20.900
once we are at three hidden layers,

268
00:17:20.901 --> 00:17:25.340
we don't get a title rebound over a log of p of x.

269
00:17:26.030 --> 00:17:30.560
So this argument that I said where,
uh,
we get an equivalence,

270
00:17:30.870 --> 00:17:34.520
uh,
and a tight bound doesn't apply once we reach three hidden theirs.

271
00:17:34.760 --> 00:17:36.110
But still it does,

272
00:17:36.170 --> 00:17:41.170
the procedure is still corresponds to maximizing a bound on the actual log

273
00:17:41.571 --> 00:17:44.330
likelihood of the data for that dbs.
It's just,

274
00:17:44.331 --> 00:17:49.290
we're not starting at a point where we actually are exactly equal to log of p of

275
00:17:49.291 --> 00:17:53.850
x.
So in theory,
the,
uh,
as we go on,

276
00:17:53.851 --> 00:17:58.380
we're not guaranteed that,
uh,
our approximation as we are training the Dbn,

277
00:17:58.760 --> 00:18:02.330
uh,
for the posterior Q of h one given x or a Qa h two given x,

278
00:18:02.331 --> 00:18:07.290
once we at a training,
a third hidden layer,
uh,
we're not guaranteed.

279
00:18:07.291 --> 00:18:11.130
It's going to be close to the troop exterior,
it might actually get very far.

280
00:18:11.250 --> 00:18:15.020
So this only means that we're improving.
Um,
uh,

281
00:18:15.021 --> 00:18:20.010
we might not be improving on the look like you and we might be going to be

282
00:18:20.011 --> 00:18:23.020
improving on the no bound,
but uh,

283
00:18:23.070 --> 00:18:28.020
still we might be extracting a better features by doing this.
And uh,

284
00:18:28.050 --> 00:18:29.560
as we've seen,
uh,

285
00:18:29.561 --> 00:18:33.710
if we think of this procedure as a good initialization four feet for room feed

286
00:18:33.740 --> 00:18:37.140
forward neural network,
we actually do get a good initialization.

287
00:18:37.141 --> 00:18:39.640
So a good set of initial features,
uh,

288
00:18:39.880 --> 00:18:44.070
that are implemented by each hidden layer and that after some supervised by

289
00:18:44.071 --> 00:18:46.950
tuning,
uh,
uh,
provide good results.

290
00:18:47.930 --> 00:18:50.190
Now in the context of a deep belief network,

291
00:18:50.520 --> 00:18:55.520
we do have a specific fine tuning algorithm for a fine tuning and this case,

292
00:18:56.430 --> 00:18:57.740
the,
uh,

293
00:18:57.810 --> 00:19:02.810
value of the sum over our training example of log of p of x t.

294
00:19:05.560 --> 00:19:09.900
Uh,
this algorithm known as the uptown algorithm is described in the original

295
00:19:09.901 --> 00:19:13.080
reference for deep belief networks.
I'm not going to talk about it here,

296
00:19:13.081 --> 00:19:14.370
but you can go look it up.

297
00:19:14.700 --> 00:19:18.600
It would be useful if we wanted to do a train this deep belief networks in an

298
00:19:18.601 --> 00:19:22.770
unsupervised way and train all hidden layers at the same time as opposed as to

299
00:19:22.771 --> 00:19:27.720
just adding layers one after another.
And if we do this retraining procedure,

300
00:19:28.200 --> 00:19:32.520
uh,
first before doing the up down algorithm,
we get better results.

301
00:19:32.521 --> 00:19:36.870
And that's how this particular procedure was.
Why was first proposed?

302
00:19:37.940 --> 00:19:40.890
All right.
So,
uh,
for more details on deep belief networks,

303
00:19:40.891 --> 00:19:44.550
I really encourage you to look at this paper in a sense.

304
00:19:44.551 --> 00:19:49.100
It's really the paper that started the whole deep learning,
uh,
uh,

305
00:19:49.140 --> 00:19:51.420
recent advances in the literature.

306
00:19:51.421 --> 00:19:55.770
So it's a really good read that's worth taking a look at.

307
00:19:56.430 --> 00:19:58.500
And that's about it for a deep belief networks.

