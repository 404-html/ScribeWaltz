WEBVTT

1
00:00:00.850 --> 00:00:01.371
And this video,

2
00:00:01.371 --> 00:00:06.020
we'll start looking at the specific problem of learning and training neural

3
00:00:06.021 --> 00:00:09.430
networks with many hidden layers.
And a,

4
00:00:09.470 --> 00:00:13.040
this is known in the research community as a problem of deep learning.

5
00:00:16.000 --> 00:00:19.480
We have to find before a multi layer neural network,

6
00:00:19.481 --> 00:00:22.750
which could have in arbitrary number of hidden layers.
So in this case,

7
00:00:22.751 --> 00:00:25.690
we had one here and one here.
Now,

8
00:00:25.691 --> 00:00:29.380
if you've played a little bit with a neural network and you've trained them with

9
00:00:29.381 --> 00:00:33.130
regular backpropagation,
you might have noticed that,
uh,

10
00:00:33.131 --> 00:00:37.060
actually rarely you would benefit from having two hidden layers that often for

11
00:00:37.061 --> 00:00:40.840
many problems,
a single hidden layer will actually work best.

12
00:00:41.320 --> 00:00:44.440
And that this has been noticed in the literature.

13
00:00:44.441 --> 00:00:48.580
And people have mainly focused on training or when they were using neural

14
00:00:48.581 --> 00:00:53.500
network in the,
uh,
in the somewhat recent past,
uh,

15
00:00:53.530 --> 00:00:56.230
they've focused on learning just a single hidden there.

16
00:00:56.740 --> 00:01:00.520
And yet intuitively as we'll see for certain problems,

17
00:01:00.530 --> 00:01:02.820
it actually makes more sense that,
uh,

18
00:01:02.890 --> 00:01:06.700
we would be training neural networks with many hidden layers.

19
00:01:07.030 --> 00:01:10.390
And yet we're sort of,
uh,
notice that we've,
uh,

20
00:01:10.900 --> 00:01:14.710
we're hitting this wall where we're not actually able to train them properly,

21
00:01:15.100 --> 00:01:19.670
uh,
for certain cases for certain problems.
And so,
uh,

22
00:01:19.720 --> 00:01:23.080
what we'll see is that there's been a lot of research on,

23
00:01:23.120 --> 00:01:24.940
I'm trying to understand why that is,

24
00:01:24.941 --> 00:01:28.690
what it is that we have problems turning these deep neural networks and what are

25
00:01:28.691 --> 00:01:31.680
the solutions that have been found,
uh,
which,
uh,

26
00:01:31.750 --> 00:01:35.620
work well and actually allow us for certain problems to actually train,
uh,

27
00:01:35.621 --> 00:01:39.760
well these deep neural networks and obtained much better results than if we had

28
00:01:39.761 --> 00:01:44.380
focused on neural networks with just a single hidden layer.
Okay.

29
00:01:44.381 --> 00:01:45.131
So in this video,

30
00:01:45.131 --> 00:01:48.910
actually tried to motivate and give you the intuition for why we think it's a

31
00:01:48.911 --> 00:01:49.780
good idea too,

32
00:01:49.781 --> 00:01:54.340
to try to put some effort into training these deeper neural networks.

33
00:01:57.950 --> 00:02:02.500
So when I'm talking about deep learning,
I really talking about,
uh,

34
00:02:02.780 --> 00:02:06.250
the problem of just learning models,
which,
uh,

35
00:02:06.410 --> 00:02:10.280
incorporate this notion of multiple layers of representation.

36
00:02:10.760 --> 00:02:13.760
So a multilayer feedforward neural network is one example,

37
00:02:13.880 --> 00:02:18.880
but it could be also a multilayer graphical models like deep belief networks,

38
00:02:19.611 --> 00:02:23.120
which we'll see in the,
uh,
in the video later on.

39
00:02:23.390 --> 00:02:25.040
And a deep Boltzmann machine,

40
00:02:25.580 --> 00:02:29.670
which you can go look up in the paper that's referenced on the,
uh,

41
00:02:29.690 --> 00:02:31.820
website of discourse.
Um,

42
00:02:31.940 --> 00:02:36.940
so really we're interested when we talk about deep learning of learning models

43
00:02:36.951 --> 00:02:39.410
that have multiple layers of representation,

44
00:02:39.440 --> 00:02:42.680
and it might not just be a feed forward neural networks.

45
00:02:43.700 --> 00:02:48.260
We're particularly interested in models where the layers correspond to so-called

46
00:02:48.261 --> 00:02:51.740
distributed representation.
So by representation,

47
00:02:51.860 --> 00:02:56.060
I mainly mean the a vector of units which eat,

48
00:02:56.240 --> 00:02:57.021
try each,

49
00:02:57.021 --> 00:03:01.390
tried to extract some information about perhaps a presence of a particular

50
00:03:01.391 --> 00:03:02.350
feature or not.

51
00:03:02.950 --> 00:03:06.970
And when we're talking about distributed representations specifically,

52
00:03:07.390 --> 00:03:10.090
we're talking about,
uh,
layer,
uh,

53
00:03:10.091 --> 00:03:14.140
where the units are not essentially are not mutually exclusive.

54
00:03:14.230 --> 00:03:17.190
That is each unit can,
uh,

55
00:03:17.290 --> 00:03:20.410
will compute a separate feature about the input.

56
00:03:20.980 --> 00:03:25.120
And the fact that they're not mutually exclusive means that two units can

57
00:03:25.121 --> 00:03:30.120
actually be active,
so have a high value at the same time.
So,
uh,

58
00:03:30.250 --> 00:03:34.210
for a representation of,
uh,
features and images,

59
00:03:34.450 --> 00:03:37.870
then you might have features that represent what's going on in the background

60
00:03:37.871 --> 00:03:41.440
and you might have features that represent what's going on in the foreground.

61
00:03:41.710 --> 00:03:46.460
And if the background and the foreground are not related,
uh,
are,
and uh,

62
00:03:46.540 --> 00:03:47.373
they're not,

63
00:03:47.400 --> 00:03:50.770
there aren't things are mutually exclusive with respect to what's happening in

64
00:03:50.771 --> 00:03:52.360
the background and the foreground.

65
00:03:52.600 --> 00:03:57.600
Then having these features that are separate makes a lot of sense because then

66
00:03:57.701 --> 00:04:00.960
we don't have to have features that are,
um,

67
00:04:01.480 --> 00:04:05.350
that need to represent specific combinations of what's going on in the

68
00:04:05.351 --> 00:04:09.220
background and the background.
We can just separate the modeling part.
Uh,

69
00:04:09.221 --> 00:04:11.290
the way the model,
uh,

70
00:04:11.320 --> 00:04:16.320
sort of learns and models this information through different units and

71
00:04:16.511 --> 00:04:20.460
different,
uh,
elements in my distributed representation.
So that's the,

72
00:04:20.461 --> 00:04:22.570
the quality of distributed representations.

73
00:04:22.571 --> 00:04:26.740
The fact that there are units that are mutually exclusive and I thought are not

74
00:04:26.741 --> 00:04:30.580
mutually exclusive and that can be active at the same time and can represent

75
00:04:30.581 --> 00:04:34.900
separate things,
uh,
that are quote unquote independent.

76
00:04:35.440 --> 00:04:39.780
So this can be contrasted with say,
a clustering approach to,
uh,

77
00:04:39.970 --> 00:04:44.710
learning features are a representation of a,
of inputs,

78
00:04:44.990 --> 00:04:48.440
uh,
of data where in clustering,
uh,

79
00:04:48.550 --> 00:04:53.550
each unit is essentially a different cluster and a unit can only belong.

80
00:04:54.021 --> 00:04:57.670
So a,
an input can only belong to a single cluster.
So in that sense,

81
00:04:57.910 --> 00:05:02.140
the units and my representation in the Costa rain representation are mutually

82
00:05:02.141 --> 00:05:05.980
exclusive.
And that's less interesting because in this case,

83
00:05:06.430 --> 00:05:07.840
a particular,
the,
the,

84
00:05:08.080 --> 00:05:13.030
the representation is less rich because you cannot malo many things at the same

85
00:05:13.031 --> 00:05:13.900
time.
Uh,

86
00:05:13.901 --> 00:05:18.040
your representation will tell you whether this particular input falls into a

87
00:05:18.041 --> 00:05:22.600
particular box and,
and,
and it needs to be this specific box.

88
00:05:22.900 --> 00:05:24.220
Uh,
so for instance,

89
00:05:24.280 --> 00:05:27.550
if you were to model images to have things happening in the background and the

90
00:05:27.551 --> 00:05:31.660
foreground,
then the cluster will tell you,
you know,
this,

91
00:05:31.900 --> 00:05:36.340
say this image is represented by this particular configuration of the foreground

92
00:05:36.430 --> 00:05:39.370
and a particular configuration of the background.

93
00:05:39.520 --> 00:05:43.540
And you cannot sort of separate these two factors of variation into different

94
00:05:43.541 --> 00:05:48.130
parts of your,
uh,
of your model.
Okay.
So that's what we'll be interested in.

95
00:05:48.131 --> 00:05:49.510
What we're talking about deep learning,

96
00:05:49.720 --> 00:05:53.470
learning these models with many layers of representation where each

97
00:05:53.471 --> 00:05:58.030
representation would be,
each layer would correspond to a,
uh,

98
00:05:58.130 --> 00:06:02.870
representation.
So,

99
00:06:02.930 --> 00:06:04.700
okay,
why a deep learning?

100
00:06:04.701 --> 00:06:09.290
Why do we think that it's important that we have these multiple layers of,
uh,

101
00:06:09.291 --> 00:06:12.620
of representation?
Uh,
a,

102
00:06:12.650 --> 00:06:17.650
an inspiration and a motivation that's often a reference is that of the visual

103
00:06:17.751 --> 00:06:22.670
cortex.
So the part of the brain that processes visual stimuli.

104
00:06:23.360 --> 00:06:24.490
And uh,

105
00:06:24.590 --> 00:06:29.450
what we know from neuroscience is that when light hits the Retina,

106
00:06:29.660 --> 00:06:30.493
uh,
then,
uh,

107
00:06:30.590 --> 00:06:34.040
the way the brain will process that information is that it will go through

108
00:06:34.041 --> 00:06:39.041
several regions of the brain like this to the region known as Lgn and then v One

109
00:06:40.430 --> 00:06:42.800
v Two v four and so on.

110
00:06:43.400 --> 00:06:48.110
And also what we know by examining the behavior of neurons in these different

111
00:06:48.111 --> 00:06:49.530
regions is that,
uh,

112
00:06:49.550 --> 00:06:53.810
some of these regions actually extract specific visual features.
So for instance,

113
00:06:53.811 --> 00:06:54.470
in the region,

114
00:06:54.470 --> 00:06:59.470
the one we know that we get neurons that are sensitive to a simple visual forms

115
00:06:59.811 --> 00:07:04.020
like edges or corners.
When we reach v four,

116
00:07:04.021 --> 00:07:08.810
then we get neurons that are more representative of particular groups,

117
00:07:08.960 --> 00:07:10.020
uh,
of a,

118
00:07:10.021 --> 00:07:14.360
of features until we reach the region known as ait,

119
00:07:14.361 --> 00:07:19.310
where we get a much higher level description,
uh,
such as,
uh,

120
00:07:19.311 --> 00:07:22.370
neurons,
highly sensitive to particular faces or objects.

121
00:07:23.060 --> 00:07:27.710
And because pro information is being processed into the sequence of regions,

122
00:07:28.060 --> 00:07:32.110
uh,
which are akin to our layers in our neural networks,
uh,

123
00:07:32.120 --> 00:07:35.500
then we know that whenever we,
uh,
neurons,

124
00:07:35.540 --> 00:07:39.350
essentially activity is dependence on the combination of the activity of what's

125
00:07:39.351 --> 00:07:42.140
going on say in the region before and then,

126
00:07:42.620 --> 00:07:45.320
and then that region itself is a combination.

127
00:07:45.350 --> 00:07:49.520
The neurons essentially represents a combination of patterns of neurons in the

128
00:07:49.521 --> 00:07:52.910
previous region and so on.
So I have this idea that the neuron,

129
00:07:53.000 --> 00:07:57.440
the way that the brain,
the way it extracts particular,
uh,

130
00:07:57.470 --> 00:08:02.470
information about visual input is by combining features which are itself

131
00:08:03.110 --> 00:08:05.720
themselves,
combinations of lower level features,

132
00:08:05.721 --> 00:08:09.290
which are themselves combinations of lower level features.
And that's,

133
00:08:09.350 --> 00:08:12.350
we can actually model this with a,
to model this,

134
00:08:12.351 --> 00:08:14.840
we need a multilayer a representation.

135
00:08:15.650 --> 00:08:18.830
And so our cartoon representation of this is that,
you know,

136
00:08:18.831 --> 00:08:20.750
when we might want to have a first layer,

137
00:08:20.751 --> 00:08:24.920
which represents very simple things like edges or distributed representation of

138
00:08:24.921 --> 00:08:26.720
that where we have a hidden,

139
00:08:26.721 --> 00:08:30.830
you can extract this particular edge and another one that can tell you whether

140
00:08:30.831 --> 00:08:34.910
this particular edge is present and this one or whether there's something like

141
00:08:34.911 --> 00:08:38.720
this and so on.
So at the first layer of representation,

142
00:08:38.750 --> 00:08:42.740
we'd get these types of features and then another layer we'd get a combination

143
00:08:42.741 --> 00:08:45.110
of some of these features.
So for instance,

144
00:08:45.200 --> 00:08:48.260
a nose would be a combination of this feature with that feature.

145
00:08:48.261 --> 00:08:51.770
So we'd have a second layer hidden unit that would tell us,

146
00:08:52.070 --> 00:08:55.530
and this would be the nose hidden unit in this cartoon where it would tell us

147
00:08:55.531 --> 00:09:00.030
that this feature and this feature is active.
So I think there was a nose.
Um,

148
00:09:00.270 --> 00:09:04.120
and so for a mouth it'd be that feature with that feature.
And so one of the,

149
00:09:04.121 --> 00:09:08.480
until we get a third layer of a feature,
uh,

150
00:09:08.700 --> 00:09:12.300
or third day or unit,
which would tell us whether there's both eyes,

151
00:09:12.301 --> 00:09:16.980
mouth and nose.
So does there is a face in the,
in the input.
Okay.

152
00:09:16.981 --> 00:09:19.970
So that's this intuition,
uh,

153
00:09:19.980 --> 00:09:24.810
for how we would be a good way of processing visual information tells us that

154
00:09:24.811 --> 00:09:28.590
perhaps a multilayer representation,
the visual data would be better.

155
00:09:31.830 --> 00:09:33.870
Um,
there's also,
uh,

156
00:09:33.900 --> 00:09:38.650
some theoretical justification that have been put forth in the literature.
Uh,

157
00:09:38.670 --> 00:09:42.930
we can actually show that,
uh,
the model with a deep architecture.

158
00:09:43.020 --> 00:09:44.220
So with a,

159
00:09:44.370 --> 00:09:47.970
what I mean by architecture is just a structure of the computations that is

160
00:09:47.971 --> 00:09:50.940
decomposed into multiple layers.
Um,

161
00:09:51.120 --> 00:09:55.110
Ken represent certain functions much more efficiently and more compactly with

162
00:09:55.111 --> 00:09:59.660
fewer units.
Uh,
then if we don't allow this,
uh,

163
00:09:59.700 --> 00:10:03.690
if we,
if we had used instead the a single layer architecture say,

164
00:10:04.590 --> 00:10:04.831
so.

165
00:10:04.831 --> 00:10:09.831
One example that's well known that that's been proposed as an illustration for

166
00:10:10.050 --> 00:10:14.160
why deep architectures are important is the case of bullying functions.

167
00:10:14.940 --> 00:10:17.610
So consider the case of bullying circuits,

168
00:10:17.760 --> 00:10:20.310
which are very similar to feed forward neural network,

169
00:10:20.340 --> 00:10:23.610
but they're essentially neural network where the hidden units,

170
00:10:23.670 --> 00:10:27.860
all the new units really in the network are logic gates that,
uh,

171
00:10:28.020 --> 00:10:32.310
compute things like an or and not functions.
Uh,

172
00:10:32.311 --> 00:10:36.630
with respect to their arguments.
And so,
uh,
in this case,

173
00:10:36.631 --> 00:10:39.510
the network would be a combination of all of these logic gates.

174
00:10:41.400 --> 00:10:45.710
So we can show that any bullying function can be represented into what we could

175
00:10:45.720 --> 00:10:49.470
respond to a single hidden layer bullying circuit where we just have,

176
00:10:49.530 --> 00:10:50.520
you have your inputs,

177
00:10:50.760 --> 00:10:55.500
you have a layer of these or not functions type of functions,

178
00:10:55.670 --> 00:10:57.240
uh,
in some hidden there.

179
00:10:57.241 --> 00:11:01.260
And then eventually another combination of that hidden layer to get an output

180
00:11:01.261 --> 00:11:02.970
that would represent that could,
uh,

181
00:11:03.210 --> 00:11:07.990
if the hidden layer is large enough represent any bullying function.
Uh,

182
00:11:08.040 --> 00:11:08.431
however,

183
00:11:08.431 --> 00:11:12.990
there are cases where that would actually require an exponential number of these

184
00:11:13.050 --> 00:11:16.260
bullying hidden units.
And Moreover,

185
00:11:16.261 --> 00:11:21.261
we can actually show that there are bullying functions such that if you restrict

186
00:11:21.991 --> 00:11:24.000
yourself to a single hidden layer,

187
00:11:24.480 --> 00:11:28.710
then you would need an exponential number of these hidden units in that single

188
00:11:28.711 --> 00:11:29.544
hidden there.

189
00:11:29.850 --> 00:11:34.740
Whereas if you actually allowed yourself to adapt a number of layers and have as

190
00:11:34.741 --> 00:11:36.360
many layers as you want,

191
00:11:36.690 --> 00:11:41.690
then you could obtain the representation of the same functions or model exactly

192
00:11:41.881 --> 00:11:45.870
the same bullying function,
but with a polynomial number of hidden units.

193
00:11:46.380 --> 00:11:50.540
So I want to go through the technical details of how you can show this.
Uh,

194
00:11:50.560 --> 00:11:52.680
I found a discussion of this particular result.

195
00:11:52.681 --> 00:11:55.450
You can look at this paper here by myself and colleagues,

196
00:11:56.500 --> 00:12:01.500
but this is more of a theoretical as opposed to a more intuitive and practical

197
00:12:02.170 --> 00:12:05.500
justification or motivation for using,
uh,
and,
and,

198
00:12:05.520 --> 00:12:10.520
and considering seriously the problem of training and learning deep models.

199
00:12:12.930 --> 00:12:13.520
<v 2>Okay.</v>

200
00:12:13.520 --> 00:12:17.670
<v 1>And I just want to end with illustrations that this has paid off in the recent</v>

201
00:12:17.671 --> 00:12:21.320
past.
So for instance,
Microsoft Research in,
uh,

202
00:12:21.390 --> 00:12:24.590
2011,
uh,
uh,

203
00:12:24.630 --> 00:12:26.670
showed that they could gain very,

204
00:12:26.671 --> 00:12:30.900
very good speech recognition systems by using deep neural networks.

205
00:12:31.170 --> 00:12:34.590
So,
uh,
what's interesting here is that we're not talking about images.

206
00:12:34.591 --> 00:12:39.300
Now we are talking instead about speech.
We can make a similar argument that,
uh,

207
00:12:39.600 --> 00:12:39.811
you know,

208
00:12:39.811 --> 00:12:43.740
it would make sense to have lower level features are combined into mid level

209
00:12:43.741 --> 00:12:48.420
features,
combined them into higher level features.
Uh,
but,
um,

210
00:12:48.990 --> 00:12:49.980
even in practice,

211
00:12:49.981 --> 00:12:53.910
we actually see that using these deep neural networks in the speech system

212
00:12:53.911 --> 00:12:56.100
actually has,
is,
is very,
very helpful.

213
00:12:56.101 --> 00:13:01.101
And they were able to get a historically very significant gains and beats the

214
00:13:01.740 --> 00:13:03.300
current state of the art at that time,

215
00:13:03.301 --> 00:13:06.300
which was mostly based on a hidden Markov models.

216
00:13:06.630 --> 00:13:11.520
And so now in 2013,
the best speech recognition systems are really based on,

217
00:13:11.550 --> 00:13:12.780
on deep neural networks.

218
00:13:13.620 --> 00:13:18.150
So that's one of the illustration that really it pays off to consider and do

219
00:13:18.151 --> 00:13:20.040
well at training these deep neural networks.

220
00:13:21.790 --> 00:13:22.130
<v 2>Okay.</v>

221
00:13:22.130 --> 00:13:24.230
<v 1>Another example is,
uh,</v>

222
00:13:24.231 --> 00:13:29.231
for vision and giving an example of a story by a particular experiment by Google

223
00:13:29.241 --> 00:13:33.950
researchers,
uh,
which we're able to train on,
uh,
many cores,

224
00:13:34.130 --> 00:13:39.130
these very big and multilayer neural networks to extract useful visual features

225
00:13:40.490 --> 00:13:43.190
out of images.
What they did is that they took a,

226
00:13:43.191 --> 00:13:48.191
essentially thumbnails from youtube videos and a train in some unsupervised way,

227
00:13:48.591 --> 00:13:52.610
a deep neural network.
And then they were able to extract some useful features,

228
00:13:52.640 --> 00:13:56.210
which at the time was,
uh,
giving very good results for say,

229
00:13:56.220 --> 00:14:00.080
performing a task like,
uh,
uh,
the recognition of objects in images.

230
00:14:00.380 --> 00:14:05.000
And you'd even have some features which you could sort of somehow analyze the

231
00:14:05.001 --> 00:14:07.610
activity and actually know this,
that some of these features,

232
00:14:07.611 --> 00:14:10.490
funds would be sensitive if we'd be active,

233
00:14:10.520 --> 00:14:13.190
if in the input that was the face of a cat.

234
00:14:13.990 --> 00:14:17.600
And so people joked a little bit about the fact that there are neural networks.

235
00:14:17.600 --> 00:14:22.460
We're using 16,000 cores to be trained to use,
uh,
many,
many cores.

236
00:14:22.461 --> 00:14:26.720
And of course,
Google has access to that type of infrastructure.
And,
uh,
that,

237
00:14:26.780 --> 00:14:30.080
you know,
it took 16,000 cores to get a feature and then fired a cat.

238
00:14:30.081 --> 00:14:32.570
But of course,
there were many more features that did other things.

239
00:14:32.571 --> 00:14:36.140
Some were less well understood than others.
But,
uh,

240
00:14:36.240 --> 00:14:39.020
it did yield essentially at that time,

241
00:14:39.100 --> 00:14:42.950
a state of the art system for extracting visual features for,
uh,

242
00:14:43.010 --> 00:14:47.180
object recognition and the particular data set they considered.
So again,

243
00:14:47.210 --> 00:14:51.670
here we have another example where deep learning has paid off.
So,
uh,

244
00:14:51.680 --> 00:14:55.970
what we'll see in the,
uh,
uh,
next videos is,
uh,
uh,

245
00:14:56.000 --> 00:15:00.470
tried to get some intuition for why it was actually hard before to train these

246
00:15:00.471 --> 00:15:04.730
deep neural networks and then talk about some of the advances that have been

247
00:15:04.731 --> 00:15:07.310
made and have allowed us to get these,
uh,

248
00:15:07.430 --> 00:15:10.070
very good system for either speech or vision.

