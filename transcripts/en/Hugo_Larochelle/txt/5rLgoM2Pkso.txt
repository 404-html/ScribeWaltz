Speaker 1:          00:00          In this video, we'll discuss the concept of under complete and over complete hidden layers in auto encoders, which will help us identify another weakness of a deal. Two encoders as we've defined it so far. So now in this video we'll talk about what's the impact of the size of the hidden layer. So the output of the encoder, the size of that factor, what's the impact of choosing different values for that size when we're training 20 quarter in terms of the types of features or that type of information that we'll learn about, uh, our input distribution,

Speaker 1:          00:43          well distinguish two cases. The first case is known as the under complete case, so hidden layers under complete if it's smaller than the input layer, if it contains less elements, uh, then the input vector. So in that sense we see that the hidden layer has to compress the input. It has more, it has less bits to a store. The what we would like to be the same information as the input layers. So there'd be fewer bits in the representation of that vector. Then the representation of that vector, just by the fact that this is a larger vector and then that factor. And so because of that, when we're training the autoencoder really it needs to learn to compress and it needs to learn to compress or it will be trained to compress well, uh, only inputs that are generated by our training distribution. So all the inputs that are present in our training, a set aren't going to be welcome pressed.

Speaker 1:          01:39          And because a d a hidden layer has, because it's lossy compression, we have to remove certain bits, uh, quote unquote, then it means that there are certain factors that he won't be able to reconstruct perfectly. And so really in the under complete case, we have the nice thing that the auto encoder, we'll learn to learn good features for the training distribution in the sense that these are going to be these hidden units here are going to be a good for being able to reconstruct inputs that are, uh, that look similar to what's found in the training set. But it's going to be bad for other types of inputs, say a random input. So if we put the random vector here and our training set does not contain random vectors, then um, because this is a new example and, uh, because our training layer are hidden layer has, uh, uh, less capacity than the original input space, then it will possibly not be able to reconstruct perfectly. Okay. Because it will have to lose some information. And presumably that's information that in this case it's important to have that information to encode that vector, but not in this case.

Speaker 1:          02:56          Now what about the other case is when the encoder, the hidden layer is a bigger than the input layer. So then we say that we're in the over complete case and now in this case, then there's actually no compression that's required by the autumn quarter. Uh, and in fact, if you think about it, each had an unit could just copy an individual element of the input vector. Uh, so, you know, this could go here, this here, this here, this here, uh, and so on like this. Uh, and then there even be some hidden units that we'd be left and would not need to be a use because by just copying each of these elements here into the hidden layer, then we could just put back the information into the reconstruction and get a perfect reconstruction. So you think a little bit about, you can try to think a little bit about how you could parent tries no 20 quarters.

Speaker 1:          03:53          So it's that it does this in the over a complete case and uh, and then if we do this, then we think about the value of that representation. Well, really it's, it's, it has no value. It doesn't extract anything that's meaningful. Uh, it's just copied the information element by element. So I'm really feeling that as the input say to some other classifier is going to be equivalent to feeling just the original input. Uh, and yet if say we're interested in extracting features for linear classifier, we actually want to have a lot of features Alania class fire as a very small capacity. And the more features we give it, the more opportunity we give it to be able to distinguish between different classes. So that's actually in a sense of bug in the irregular or twin quarter. And also this partly explains why we weren't not learning some particularly meaningful features when we saw the example or we're training an autoencoder or numbness a, it could just do something very similar to just copying the, uh, um, copying the pixels into individual, separate a hidden units, and then reconstruct them back into the, uh, the reconstruction output.

Speaker 1:          05:12          And so that's another problem with, you know, tone quarter where in the over complete case, uh, it's actually not encouraged to learn anything meaningful. So in the next videos, we'll see two ways of addressing that problem and such a way that we actually be able to extract some meaningful features for, uh, be getting good results in terms, for instance, of our classification task.