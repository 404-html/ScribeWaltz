Speaker 1:          00:00          Yeah.

Speaker 2:          00:00          And this video will introduce a very useful tool known as d look like you who had variational bound.

Speaker 1:          00:07          Yeah.

Speaker 2:          00:09          So in the previous video we talked that, uh, we introduced the uh, model deep belief network and then I talked about the fact that this idea of retraining neural networks by stacking rbms, uh, actually came from deep belief networks. And then I tried to give an idea for how this was useful in the context of a deep belief network where, uh, we would try to initialize a three hidden layer deep belief networks by first training and RBM and taking its weights first hidden layer weights to initialize the sigmoid belief network, part of a two hidden layer DBN at which case we would keep those fix to pretrained the second a hidden layer RBM weights in the two hidden layer, the BN. And then after doing that for awhile, we would use the two first hidden layer weights initialize the sigma belief network, part of the three hidden layer DBN and then we would be left with the procedure of training the top RBM weights of the three hidden there. DBN. And so to actually describe exactly how this procedure will, uh, come about. And, and, and the actual details of the algorithm will need a tool known as the log likelihood variational, uh, bound. And so in this video will introduce what this is exactly

Speaker 2:          01:31          to introduce the a variational bound. Uh, we will need the concavity explored the concavity property of the logarithm function. So, uh, the logarithm function is a concave function, which looks like this. And a concave function has the following property. So if you take a, so let's just think about the log as are concave function. If you take the log of a weighted average of some numbers, Ai, where the weights of each AI is going to be this Amigo I here and a Omega I is that it can be any, uh, wait, as long as it's a, they're all greater than equal than zero. And uh, they sent two. One. Okay. So this, so that this is a weighted average of each of these numbers. Ais, well, the log of this weighted average for a concave function is always going to be greater or equal. Then the same way that average but of the logarithm of the numbers Ai.

Speaker 2:          02:34          So, uh, visually if we had two numbers, a one and a two a, then what this would correspond to is that the weighted average between the log of a one and the log of a two, which corresponds to this line here. So this line is, uh, the way that average between log of a one and luck of a two. So luck of a one is here, not going to two is here. And so any way that average would fall between the straight line between these two points. So that line is always going to be below the logarithm of that function between a one and a two. So the Logarithm, in other words of any weighted average between a one and a two using the same weights. Okay. So that this is visually, we see that for a concave function would always get this, we get this, this, that this line would be below the actual function. And so that's what this property refers to. But for any number of points, not just, uh, not necessarily just to, but any weighted combination, uh, between, uh, any number of weeks. Sorry, Alpha for numbers. So that's an important property that will leverage to get our variational bounds.

Speaker 1:          03:48          Yeah.

Speaker 2:          03:49          Okay. So the idea of a variational bound of the log likelihood for some model, uh, is actually very useful for a lot of graphical models with a latent variables. So imagine we have any model p of x n h one A. I could have written just h, uh, to be general, but we'll use it, uh, in the previous, uh, in the next slides, in the next video for this specific case of the first thing than they are in DBN. But any model that defines the distribution of an x using some latent variable, each one is going to have the following version of the idea of the various, you know, bound is to take the log likelihood, which might be too complicated, too complicated to compute. So log of Q of x would requires summing over each one. And, uh, there are some models. If there are, uh, uh, that might be too complicated in the interactions between x and h one or the number of values of each one to allow for performing that some, uh, exactly.

Speaker 2:          04:50          So instead we'll, we'll derive is an expression where we've added these new parameters, this sort of separate a model if you want to think about it this way, uh, which we call queue of h one given x u of h one given x is sort of a separate model. It's a, and you can think of it, that's an approximation of what would be the true posterior under our model p of h one given x. So cube h one given x can be different from p u of h one given that's it's a separate, it has its separate set of parameters. And by introducing these extra variables, we'll actually be able to formulate a lower bound on the log likelihood. And this lower bound we have sort of properties that are interesting for a, if we wanted to actually optimize this look like we could then optimize instead the lower bound. And by pushing the lower bound up, we can hope that we also pushing the actual lug likelihood up. So that's the idea that the main usage for the Farish northbound that we often seen the literature.

Speaker 1:          05:54          Yeah.

Speaker 2:          05:55          Okay. So how do we actually get this, uh, lower bound? So we have that log of p of x is equal to this expression here. So let's, uh, go into a two steps. So first, ignore this term here in this term here. So what this sustain saying is that the log of p of x is the log of the sum over h one of p of x and h one. Okay. So where's marginalizing h one? So that gives us p of x. So that's equal. And now what we're doing is that we're just introducing this virginal. A model will perceive your queue of h one given x by multiplying and dividing by it. Okay. So these would normally cancel. So that's why we haven't changed anything. So that's why we have the equality.

Speaker 1:          06:39          Yeah.

Speaker 2:          06:39          And now we are already ready to use the property of a concavity concavity of the log function. So by using those, considering those as our weights and those here, the ratio p of x and h one divided by Q of h one given x as our numbers a I then we can exploit the concavity of the lug by saying that this is great or an equal, then the weighted average. So we're summing over all values of h one weighted by Q of h one given x of dialogue of this number here. So the racial p of x and h one divided by Q of h one given x. Okay. So this here we can think of it as a huge way that some over an exponential number of values of age. Uh, if we think of an Rbm, for instance, where these are binary in the take, uh, so globally to take two to the number of hidden units values.

Speaker 2:          07:38          Um, and so now this a way that some weekend, uh, uh, obtain it slower bound by doing the a way that some, instead of the log of the ratio here and not exploiting the fact that the log of a ratio is the, uh, differences of the logs, then we get that, uh, this whole expression here as just, uh, there's some over each one of Qa, h one given x lug of the numerator here, p of x and h one minus the sum over each one of Q h one given x times the log of Qh one given X. Okay. So we just, uh, almost straight forwardly exploited the concavity of the log function and that gave us our lower bound on the log probability under a model p of x, which is a lower bounded by this expression here for any choice of what Qa h one given x is. And that's because for any way to the average, this is true. So these are the weights of our average or for any chores of our posterior approximate posterior Qa, Chuang given x. We have this, uh, that this is a greater or equal than this whole expression here.

Speaker 1:          08:52          Okay,

Speaker 2:          08:53          so this is called the variational or variational lower bound. Uh, so I just, uh, remove that. What was in between this and this whole expression here. One property of this, uh, various northbound is that if our separate pacira Qa h one given x is actually exactly the same as the true conditional in our model, you have h one given x, then we actually have an equality. So this would be equal. So let's do a very quick and dirty demonstration of this. Um, so log of p of x and h one, we can write it as the, uh, lug of a p of h one given x plus log of p of x. So that's because p of x one and an h one is p of h one times p of h one given x times p of x. Then take the log of that. That's just going to be the sum of the lugs. Now, uh, we are considering the case where Q is exactly the same sp. So we'll just change the

Speaker 3:          09:58          choose two PS.

Speaker 2:          10:01          And now we notice that we have uh, the sum over, uh, each one of Poah, one given x times the log of p of h one given x. And then we have minus the, exactly the same thing here. So this term would disappear with this one would be canceled out by this one. And now we just have some of her, uh, h one of Poah, one given x times the log of p of x. Well, the log of p of x does not depend on each one, so we could actually put it right in front of the sum and then we'd some over just p of h one given x, which would be one. So we would be left with just log of p of x, which is exactly this year. Okay. That's a very, we can dirty demonstration that for Qa Schwann given x, uh, equal to p of y.

Speaker 2:          10:53          Given x, we actually have inequality. And just generally the more Q of h one given x is going to be different from the trooper steer, then the less tight this bound will be. The bigger the difference between this and that whole expression is going to be. And in fact, the difference between the left and right a part of this, uh, bound here is going to be the, uh, something known as the KL divergence between Q of h one and p of h one, which is this expression here. So in general, the Kale divergence is a, you can think of it as a kind of difference, uh, distance between, um, uh, distributions. It's not a distance because it's not symmetric. If we changed the order of these two arguments, we get different numbers. Uh, we can get different numbers. Uh, but we see that point since it's zero.

Speaker 2:          11:41          If Q is equal to p. So, um, in this expression, if we have p here and p here than this cancels out with that. So we get log of one like of one is zero. So all the terms are going to be Zeros. Okay. So what's interesting with the various nor bound is that it's a suggests and a procedure for optimizing the log probability of our training data. Uh, even if you have a model where we can compute that term exactly. And the approach we'll take is to try to instead work with the lower bound and tried to push up the lower bound. And the way that this is usually done is that we would first, um, uh, at the first step we would try to find our approximation Q of h one that is as close as possible to the trooper steer. So we would optimize the Kale divergence between two NP for some family of models for our posterior RQ.

Speaker 2:          12:39          And then once that's done, then we will keep Q fixed and we'll actually optimize with respect to just the log of p of x and h one. And if we make good choices for what this, uh, approximate posterior here is, then, uh, it turns out that for a certain cases and certain models, uh, we actually, uh, can much more easily optimize this expression here. So then we alternate, the algorithm would be alternate between updating Q and updating, updating cue of dating Pete. And you do this until convergence. And so by doing this, so we, when I say updating, we say maximize this expression with respect to Q, and then maximize this expression with respect to p and then alternate, uh, until convergence. So by doing this, we push up the lower bounds or where ideally a, you know, we can hope that we actually pushing this and also the Emr with them is based on this idea. But where at the east step, uh, it corresponds to finding Q, which is exactly equal to p if you're familiar with the stuff here. So that's, uh, that's why I'm talking about it here. It's a very, very useful tool in general for training, uh, probabilistic graphical models. And we'll also use it for, uh, in the next video for deriving the greedy layer wise training procedure for a deep belief network.