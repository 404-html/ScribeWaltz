Speaker 1:          00:00          In this video, we'll look at the biological inspiration behind a neural networks. So we've seen a mathematical definition or what do we mean by a multilayer neural network? Uh, so mathematically we have an input vector, which we call the input layer. And then this vector is transformed into hidden layers where, uh, where each hidden layer is composed of a hidden units, which are all a computed by a linear transformation followed by nonlinear gravity. And then so we compose these operations until we reach an output layer, which makes a particular prediction if we're doing classification and tries to predict the class to which the input the lungs. So on that we'll look at, uh, what is the biological inspiration behind this model? Why is it that we call these little units here neurons and, uh, uh, how did this mathematical formulation, uh, I was at derived from an inspiration, uh, from, uh, actual neurons and actual the actual brain.

Speaker 1:          01:07          That's first talk about this idea of structuring a model into several layers of preprocessing, of hidden units. Uh, one inspiration that we often refer to is, uh, from the visual Cortex in the brain. That is the part of the brain that interprets the visuals to Menai that we get from our retina. Uh, so what we know about the visual Cortex is that it is a decomposing two layers of regions that are connected to each other. So information from the retina is a, a pass to a first region called Lgn, and eventually it reaches another region of neurons, which is called V one. Now, uh, the one, uh, is a known to have neurons that are sensitive to particular simple visual forms like edges and corners. And then this information. So the activity of these neurons is a influences the activity of another region called [inaudible]. And then eventually it reaches another region called v four, which now starts, uh, extracting some features related to more intermediate visual forms or features.

Speaker 1:          02:21          So essentially groups or combinations of simpler features like edges and corners. And then this eventually reaches pit and then ait where we get neurons that are sensitive to particular faces or particular objects in the visual field. So we see that process, the processing of information in the visual Cortex goes through these, uh, layers or regions that are put in sequence into the processing of the brain. Now we can look at their cartoon explanation of what we can do with a such a processing of a or a sequence of regions. Say we have a first region that might extract different edges in an image, and then these, these features would be reused by a subsequent region, which would then combine these features are, for instance, we could have a nose detector that would combine the, uh, this feature with this feature. So this would be this line here and this line here.

Speaker 1:          03:25          Uh, we could have a mouth, a neuron which would detect mouse by detecting the presence of this, this line here and this line here, which is this line here in this line here. And then something that would detect, uh, two eyes. So that would be this feature and this feature. And then again, the activity of these neurons that can detect noses and mouths and eyes could be combined to get a whole phase detector, which would be active if they're neuron that detected a mouth, a nose, and two eyes. Uh, we're, uh, we're actually a activated where detecting these, these particular features. Okay. So this is the, uh, brain inspiration behind having several layers of, uh, processing of hidden layers. So each of these parts here would correspond to essentially do a layer of neurons in our artificial neural network.

Speaker 2:          04:25          Okay.

Speaker 1:          04:26          No, let's not talk about individual neurons and the way that mathematically we write them out. Uh, where does that come from? So, um, let's talk a little bit about the actual brain. Now. We estimate that there are about 10 to the 10 and 10 to the 11 neurons in the human brain. Um, Easter on receive information from other neurons through their dendrites. So then right is kind of like the ears of the, uh, the neurons that a, so he received information from other neurons. It is connected to and a, and then information from that comes from these dendrites is processed within the cell body of the neuron, which is called the Soma. Then, uh, the neuron will send information through a cable, a quote, unquote, which is called the accent. And, uh, then this accent is going to be connected with other neurons. Then rights and the point of connection between Iran Saxon, uh, it's in the branches out of its accent. And, uh, the other neurons dead rights is going to be called the synopsis. That's the point of connection where an accident, uh, reaches, uh, some other neurons, dendrites.

Speaker 2:          05:39          Okay.

Speaker 1:          05:39          There's a cartoon illustration of, uh, of all of these different terms. So for a given neuron, it has some then dried. So these are these arrows here, and this is how information is being sent into the cell body or the Soma of the neuron. Then there's some chemical activity that happens here and the result of this chemical activity, uh, this results into an electrical signal that is sent through an accent and there's an accent is then becomes some branches which are eventually connected to other neurons. Uh, a dendrites and the point of connection between these then rights. So this little square here in this cartoon illustration with this point of connection would be synapsis. So the snaps is where the Axon reaches and other neurons that dragon.

Speaker 2:          06:33          Okay.

Speaker 1:          06:34          Now, um, we'll call an action protection potential and electrical impulse, which travels through, uh, the, uh, a neuron's Axon. So this is actually how our neuron, we'll communicate with other neurons. This is how it's going to eat to send information. And a, so essentially this action potential corresponds to a spike in the electrical voltage electrical potential. Sorry. So spikes in voltage in, uh, um, of the accent and I'm now and action potential that is generated at a neuron is generated. I don't know, I'm sorry if it only if it receives enough of the right pattern of spikes from other neurons that is connected to. And so essentially this, uh, uh, level of activity from the other neurons, uh, from which a given they're on this receiving information through extend rights. If it, if this amount of activity reaches a certain threshold and has the right pattern, then our, uh, the neuron question, uh, will also, uh, um, uh, generating an action potential will also spike.

Speaker 2:          07:48          Okay.

Speaker 1:          07:48          Now, um, neurons will actually generate several spikes every second. Uh, so, uh, there's actually going to be a frequency of spikes and that this is called the firing rate of a neuron. And this is actually a, you know, one of the main information or main characterization of the activity of a neuron. So we'll often look at its firing rate as a description, a number that will describe whether a neuron is very active or not. Actually, neurons always fire a little bit. And uh, this sort of a constant level of firing is known as the spontaneous firing rate, uh, but they will actually fire much more given the right stimulus that is given the right pattern of firing rates in the other neurons it's connected to. Then our neuron, we'll, uh, might increase. It's a firing rate and my generate many more spikes.

Speaker 2:          08:45          Okay.

Speaker 1:          08:47          Now, uh, so essentially the firing rates of some other neurons that are connected to a given their on, so we'll call those neurons the input neurons, they will effectively combined to influence the firing rate of their neurons. It's connected to, okay. So if we have one neuron and then it's actually connected to many more neurons, so they have, uh, their accent and eventually it reaches the, uh, some dendright of this neuron here. The firing rates or information would be propagated in this way. So the firing rate of these neurons will influence the firing rate of that neuron that these neurons are connected to. And so depending on the properties of the dendright and the accent, so the dendright of this neuron and the accents of these neurons and neuron can either work, um, so one of these neurons can either, uh, make, uh, the, uh, firing rate of that neuron increase or decrease, uh, by increasing its own firing rate.

Speaker 1:          09:58          So if we say that the firing rate of say that neuron a will tend to increase the firing rate of that neuron, then we'll say that this neuron here excites this neuron here and the otherwise if it decreases it, then we'll say will inhibit the firing rate of that neuron. Okay. So now with all that being said, uh, what's the relationship with our artificial neurons? So while they tried to essentially approximate, uh, this process of firing rates that are, uh, that, uh, played together to influence the firing rates of other neurons. So the activation or the output activation of a given their on. So after the activation function, we can think of it as sort of a firing rate. So this is a, you know, if you have a sigmoid, this a number between zero and one. So that's not necessarily a, the right range for a firing rate.

Speaker 1:          10:54          But if we can, we can, we should think of the activation as a sort of the equivalent of the firing rate of that neuron. Now the weights between the neurons, they actually model whether some given neuron will excite or inhibit other neurons. So if we have a positive connection between two neurons, it means that the input neuron will excite the, uh, output neuron neuron it's connected to. And uh, if, uh, instead it inhibits. So, uh, then we'll have a negative connection. Okay. So these weights, uh, essentially translate this idea that firing rates can either increase or decrease the firing rates of other neurons and then the activation function and also the bias within the neuron there sort of a model for this threshold, the behavior of action potentials. So I said that the firing rates or the firing activities of the neurons that some given their on this connected to needs to reach a certain level for this neuron to actually spike and a, so this is what the activation function and the bias, uh, sorta tried to model.

Speaker 1:          12:06          So if you have a sigmoidal function, we'll take this form here and then the bias will determine what's the basic pre activation of the neurons of the biases negative. Then, uh, so this would be at zero. If the bisons negative, then the reactivation would start here. So this is saying that the pre activation where we combine the activation of the neurons it's connected to. So there are sort of firing rates, uh, this, uh, in this particular case, it would mean that it needs to go quite a bit over a zero to reach the maximum firing rate of that neuron. Okay. So this is, we can think of this or the sort of soft threshold and, uh, and so this is what the activation function in the biases trying to model this a soft version of this special, that behavior.

Speaker 2:          12:56          Yeah.

Speaker 1:          12:57          Okay. So that's, uh, uh, all we'll say about the biological connection between a artificial neural networks and real biological neurons. Um, often when we do develop neural networks, we don't always go back and think about, okay, let's try to make our neurons more biologically plausible. Some people use this in their research research, improve and design better neural networks. Uh, but some other will instead focus on the mathematical properties of artificial neurons and try to play with that. But it's still a important to know that, uh, you know, there is some, uh, they'll fairly weak connection between real artificial, real neurons and not deficient in neurons.

Speaker 2:          13:42          Okay.

Speaker 1:          13:43          And, uh, actually you want to see some neurons in action. I suggest you go look at the recording of the Hubble and weaseled experiment where, uh, a neuron in a v one region of a cat, uh, visual cortex is being recorded. So you can actually hear the neurons spike as a visual stimuli, which corresponds to some lighting pattern is being changed at, in the visual field of a cap. So this is a nice experiment to watch and to get a more tangible feel of, of what a, an actual neurons behavior, uh, looks like. It's like.