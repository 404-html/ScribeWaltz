Speaker 1:          00:00          In this video, we'll discuss a very interesting relationship between sparse coating models and a v one neurons.

Speaker 2:          00:08          Yeah.

Speaker 1:          00:09          So v one is a region in the brain that is part of the visual cortex. The visual Cortex is responsible for, uh, visual processing in the brain. And, uh, what's special about the one is that it's, it is fairly well known and well understood compared to other regions in the brain. And in particular their neurons that are there are a well known for being able to detect a very simple specific edges in images. So that is very a simple contrasts in a elimination in images. And each neuron is really a responsible for detecting, uh, detecting these edges at different positions and different angles in, uh, and someone's field of view. And so a very famous experiment was to see what, how this compared with, uh, a, as far as coding models does. So does as Parsco Inc model learn features that are, uh, similar to the types of features that v one neurons might be extracting in the visual field.

Speaker 1:          01:14          So they experiment that was done is to take a image of a natural scenes, like a big image like this with some trees and uh, uh, a mountain behind and so on. And then, uh, because this is a very large image and it'll be compassionately, uh, expensive to actually train as part getting model on this whole image, we instead take certain regions in it and extract patches from it. So, uh, so for instance, from a, you know, these, we'd get patches that look kind of like that part of a tree and then we have some background behind it. Uh, so this, these patches would look at this part of the tree here and I should say I'm giving the reference for the image, but this is a, uh, did, did, uh, uh, an experiment based on that. But the actual experiments, the first experiment on this is a, is not from, from this paper. This is actually an extension of sparse coding, which is actually worth reading.

Speaker 2:          02:08          Okay.

Speaker 1:          02:09          The actual reference for this experiment is this paper here by all cells and fields is a very famous paper. And so they took these natural image patches. So we say patches because it's very small portions of a much bigger image. And they, uh, train a sparse coating model, a variant of this possibility mandala was described in the previous videos, uh, on these patches. And then they looked at the features that were extracted. So here we have a visualization of these features. So for each neuron, each element in my sparse codenamed Vector, a I day essentially looked at at, so at the Associated Adam, also the dictionary column and visualized it. And when we look at it, I'll, each neuron actually seems like a look, like it's actually extracting a Ajay formation. So for instance, uh, this, uh, let's say this neuron here seems sensitive. If we have a sharp contrast change where we go from white and then black and then white.

Speaker 1:          03:11          So that's, that's an edge. Uh, we have another one here, which looks at, again, an edge, but that is with this angle as opposed to this angle, it's, that corresponds to a slightly different position in the patch. And, uh, we see there's a big variety in the position of the edge that's being detected, a, the orientation as well as well as the scale or um, the uh, and signal processing term, their frequency of the, uh, of the edge and a, so actually each Adam will say is tuned to particular, uh, position orientation and spatial frequency. And we see something very similar, similar in v one neurons where, uh, we actually have neuron cell are tune again to the detection of particular edges but with different position orientation, then spatial frequency in our field of view. So this was a very surprising discovery by Alsace and, and feel, which, uh, really motivated the exploration of, of sparsity in the neural networks.

Speaker 1:          04:17          So it really suggests that the brain might be doing something similar. It might be trying to learn a sparse, a representation of our visual stimuli, uh, such that it maintains as much information, but that it is sparse in sparsity, might just be related to the fact that, uh, neurons, uh, waste energy when they are firing. So they don't want to have, uh, uh, they want the fire all the time. So that would be the, uh, so this sort of energy consumption, a constraint would be related to the sparsity constraint and as far as coding. And so this has motivated a lot of researchers to look into many more variants of, of models with, uh, uh, which look at different types of sparsity and actually a lot of other variants of the sparks scoring models, which are not technically sparse coding, but in core incorporate the notion of sparsity as been shown to also extract these types of, uh, uh, sparse features. So edge detectors, uh, at different positions and uh, and uh, frequency and so on. And so there's a huge body of literature on different types of models on supervised more leg track sparsity that extract features and are based on sparsity a notion of sparsity. And I encourage you all to go look at this literature and also look at a website of, for this course, for references for such models.