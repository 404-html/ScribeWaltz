Speaker 1:          00:00          Yeah.

Speaker 2:          00:00          In this video, we'll start our discussion on the application of neural networks to computer vision problems.

Speaker 2:          00:08          So we've looked so far the fundamentals behind a fundamental ideas behind neural networks and concepts. And now we'll start looking at a application of neural networks to specific problems. And this first series of videos will look at, uh, specifically at computer vision problems. Uh, computer vision is the design of computers that can process visual data. So images or video to accomplish some given tasks that humans can accomplish easily. And, uh, specifically in the, uh, this video in the upcoming videos, we'll focus on the problem of object recognition, visual object recognition. So in that context, uh, the, uh, computer or the, the, the program is giving us input and image and a, the computer must identify what's the identity of the object that's present at the center or more or less at the center of the image. And so for instance, we have an example here from the very famous caltech one o one data set to data set of how a hundred 101, a different objects for which, uh, we have, uh, several examples of images of those objects. And, uh, for instance, we have an example here of a, the image of a sunflower, which is 112 pixels by 50 pixels and the computer must take that as input and then tell us at the output that, uh, this uh, particular image contains the image of a sunflower where sunflower is one of the 101 different categories in the Caltech, one on one data center.

Speaker 2:          01:48          So what we'd like to do is design neural networks that are specifically adapted in design for computer vision problems. Uh, the reason for that is that Darson and issues with, uh, the type of data we have to manipulate in computer vision. And there are certain characteristics of the data we can also explore to get better results. So when the issue we have to think about is that images are extremely high dimensional inputs. Uh, so we've have an image of 150 by 150 pixels. Then what we'll have to manipulate really is 150 times 150 different inputs. So 22,000 times, sorry, 22,000, 500 different inputs. And that's what gray scale images where each input would be the intensity, the grayscale intensity of each, uh, pixels. If we have RGB images and colors, then we have three times as much input elements that we have to manipulate. So this means a lot of parameters and this means a, so we can be, uh, quite a susceptible to overfitting.

Speaker 2:          02:54          And a, this also means a lot of computation time if we're not careful. Okay. Uh, but also image data is, is particular, uh, for instance, the order of the inputs is uh, actually meaningful. In fact, more specifically, uh, the pixels where each pixel is in actual input for our neural network is organized in a particular to d topology. So pixels are organized spatially, uh, where a certain pixels are close spatially in other pixels are actually far away from each other in the specialty. And the image a for video data. Then we have a three d topology where pixels are organize both, uh, spatially and through time. And so that's something we might want to explore it. And also thinking about object recognition Darson and then variances in, uh, the way an input image might change, which actually doesn't change the identity of the object in the image.

Speaker 2:          03:55          So for instance, if we take an image and we take the object in it and we actually translate it, then that should, that doesn't change the fact that the same object is actually present in the, uh, in the image. If we change the amount of illumination, uh, in the scene where we're taking a picture of the image, that doesn't also change the identity of the object in the, in the scene. And so that's also something we would like to explore it in a, ideally to build some invariants and be able to generalize to new pictures of the same object where the position, the exact position of the object that's changed or the elimination has changed in the scene. So we'll focus on a type of neural net that tries to, uh, exploits these. I explain these ideas to get good performance. They're known as convolutional networks, and there are characterized by three different properties that a really defined convolutional neural networks. The first one is local connectivity of the hidden units, meaning that each shit, and yet it's going to be connected only to a small, a small local region in the image, uh, parameters sharing. So the hidden units, a lot of the hidden units, we'll share parameters with each other. And then, uh, the use of a pooling and sub sampling operations between a hidden layers in a compulsion and neural network. So in the following videos, we'll look at these three ideas separately that really defined convolutional neural networks.