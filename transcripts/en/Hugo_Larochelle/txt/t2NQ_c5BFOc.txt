Speaker 1:          00:00          In this video will introduce a different type of, of doing quarter known as DT noise ingo twin quarter. We talked in the previous video how a over complete hidden layer in the regular auto encoder, uh, doesn't make a lot of sense in terms of what we can expect. The auto encoder can learn. And that's because it could actually just learn, uh, to copy individual elements in the input vector. And then h of x would just be a copy essentially of the input. So would not sell, be encouraged to learn meaningful features. And so now we'll see that, uh, with this new formulation known as the [inaudible], we will get a set of hidden units which extract interesting structure from the, uh, from our training set.

Speaker 1:          00:49          There's an idea is actually quite simple and uh, we'll see that it essentially directly addresses the problem that an auto encoder could learn. A regular coder could, could learn to just copy the input. So the idea is to train, uh, so the model is known as Dt nosing or two a quarter. And you'll see very clearly why it's called like that. So the idea is to learning representation and extracted by the end quarter that is robust to the introduction of noise into the input. And so the idea will be that instead of feeding to deal in quarter, the original input x, well actually feed a noisy version of it. And this noisy version, which I'm calling x stilled, is going to be the result of taking x and then passing it through a noise process or some probabilistic process which will take x and in generate this instilled in some way based on x.

Speaker 1:          01:49          Um, so one popular way of, uh, for this noise pro public choice of this lowest process is to just randomly assign certain elements of the inputs to zero, where a will choose to assign an input to a value of zero with some probability, uh, which is a hyper parameter would have to tune. So in this example here, say the probability was half, uh, then, um, we would iterate over the inputs and then say for this input, I flip a coin. Uh, maybe the coin says that I should add some noise. So in this case, instead of copying x, I would just, I would actually not copying and set the value of that unit in excel two zero. Here I flip a coin, I get a different outcome which says copies. So I copy it, I copy it here, here, I don't copy it. Uh, and again, uh, for all and so on for all the input elements.

Speaker 1:          02:45          So we do this sort of randomly. So if we did that another time for the same input x, we get a different pattern of Zeros and that's I actually crucial. So now what we've done is that we're feeding the to the interim quarter noisy variant where some of the elements in for this noise process has been essentially erased in this sense. We could choose other types of noise, we could add Goshen additive noise by adding a see Gulshan those with the mean zero in a particular variants, which would be a hyper parameter would have to tune. And then to train the Dooney denoising auto quarter. So from [inaudible] we get a encoder value h of x still, and then we get a reconstruction x hat and not x hat. We don't compare it to external that we actually compare it to the original input. So the last function compares x stilled.

Speaker 1:          03:40          So x hat to ex not ex stilled. And now we see that in this case, uh, for one thing we can get a perfect reconstruction error by just copying instilled, uh, into different units here. Uh, so for instance, because they tone quarter gets a zero here, uh, but this zero was actually the result of some noise then at the reconstruction. If it's trying to actually reconstruct that value, it can't entirely trust this value because in this case, actually it's zero. So it's actually not the right valve. We can not just copy at the output the value of zero. That would be a terrible, uh, prediction to do in terms of the loss. So instead they do nosing autoencoder will be forced to use other inputs, for instance, that input and that input to a, and then learn about what's the relationship normally between these two inputs.

Speaker 1:          04:32          Say, and this other input here. And, uh, and then using by learning what that relationship can be a, then it might be able then to infer from it a more reliable prediction of what this input was based say on these two inputs. So that's what the hidden layer will be forced to try to do. And this will thus force it to have hidden units that extract particular types of, of, of structures that we tend to see. So predict, uh, you know, different types of correlations between the inputs that we tend to see, uh, in the input vectors in our training distribution. So by doing this, we really broke and made impossible, not optimal, uh, this, uh, uh, behavior in the Taco of just copying each input because there's noise in it. So by adding noise, we're forcing you to learn about the structure of the input distribution and a, and then we're forcing it to us, uh, at the same time learn more meaningful features, uh, as we'll see in the next slide.

Speaker 1:          05:37          So here's an illustration of, of, of how it's training. Um, so imagine in this, uh, cartoon example that, uh, we can reconstructing vectors in two dimensions and that our training distribution is such that, uh, really all examples sort of lie around this one dimensional mind manifold. This one dimensional curved lines here essentially corresponds to where, uh, almost all of the data from my input distribution lines and when I'm training, what I'm doing is that I'm taking one of these ex, uh, training examples with these different x's would be samples in my training set and am I adding some noise? So that's pushing it away from the manifold. And then the, uh, what the auto encoder is trying is to take this x still, which has been pushed away from the manifold and projected back on the metaphor especially it's strange to projected exactly two x.

Speaker 1:          06:33          And so on average, what it's going to do is sort of tried to push back the data where most of the training data usually is. And so by doing this, really it's learning about this structures. In this case, the structure of the data is essentially the shape of that manifold. And so we see here in this visual illustration that, uh, we're forcing you are towing quarter to learn about what that structure is because it needs to know what that structure is in order to know where to project back. The, uh, noisy, uh, uh, the noisy inputs x still, uh, to be able to get a good reconstruction, uh, x hat.

Speaker 2:          07:10          Okay.

Speaker 1:          07:10          So for our images, you know, uh, we wouldn't be in two D, But, uh, for images, we, we do have the notion that most images a lie on their lower dimensional metaphor, which represent variations such as translations and rotations and small deformations. And so, uh, if this was an example, then a noisy example would look something like this. It would kind of look like a character, but not exactly would be slightly off the manifold. And then we will learn to push this back into this here and a, again, in a sense, we're also learning to distinguish between true inputs and a noisy inputs. Uh, if we had an a lot of noise, then we would be generating something like this. And so we'd be learning essentially that we don't want to be able to reconstruct this perfectly. What do you want to be able to reconstruct perfectly is things that look like digits like this.

Speaker 1:          08:07          Even if they have a little bit of noise, we'd be able to reconstruct him back into a nice looking digit, whereas this which has a lot of noise, we will not learn to reconstruct it into it's all noisy version. Um, so again, we were filed back in the setting where we have hidden units that are good at reconstructing things that look like the data, that training data. And that is not good at reconstructing things that are very noisy because noisy things like this or less noisy things like this are going to be projected back into a nun that we, the image. So, uh, let's look at the actual features we get when we trained the Nemnus. So this is an example of a feature is trained by an auto encoder without corrupting the inputs. So that's just a regular old twin quarter here. Now if we take 25% of the input, 25% of the input, and we set it to zero. So we have this masking noise type of, uh, corruption. Yeah, we see now that a lot of the hidden units, their filters start looking more like edge detectors. For instance, we have these sort of pen stroke like detectors here, here and here. Uh, this is also kind of like a pen stroke detector in the sense that we have some, uh, ink here. And then it's saying there's background, right? Uh, besides the, uh, the ink. Um, we also noticed that, uh, the filter for instance, this one which was not looking too bad is no, so for you,

Speaker 1:          09:36          keep your eyes on this one.

Speaker 2:          09:38          Okay.

Speaker 1:          09:38          We see that I'd, the filter actually got bigger and uh, and that's part of it also because if we add a lot of noise, like 25% of noise in the input, then each unit to be able to say what kind of structure is present? Is it a sort of edge like this? Then it needs to integrate out many more pixels because, uh, because uh, you know, many of them might be noisy, so you want to cover enough that you, you have enough in your set of pixels, your feet, your, that this hidden unit is doing it's computation over. So that sort of the, the noise can be washed out of the computation.

Speaker 2:          10:15          Okay.

Speaker 1:          10:16          And then feed, I add even more, we get even more a bigger, uh, filters, bigger receptive fields. So when we're talking about receptive fields, we were talking about the, uh, number of pixels for which the weights with a is significantly far from zero. So this would be white or black in these images. So we see again that we get some interesting features. We are kind of like pen stroke detectors and uh, uh, there are actually, uh, oops, sorry. There actually again, bigger because we've added more noise. So it's trying to cover a larger part of the image to be able to extract, uh, and, and figure out more accurately what the structure is mean. We get, again, like a lot of these sort of a pen stroke detectors here in here that we didn't get without any noise.

Speaker 1:          11:06          Uh, here's another experiment where, uh, we train a natural limits patches. So we taken, that's what they mentioned, like the image of a forest or something like that. And then we take small windows or patches of pixels. So these are like a few pixels by a few pixels on these with their very small, tiny images, extract him from the larger image of a natural, a natural scene. And, uh, if we tried an auto encoder with the squared difference loss and a, we add gaussian noise, then the types of filters we get are really interesting. Do you look a lot like edge detectors? So they're like high intensity or positive intensive? I, yes. Yeah, high intensity compared with low intensity. So for instance, this would be active. We get something, you know, high intensity pixels next to low pixels. So that's really an edge. Uh, and if we actually had trained a PCA on these images, so we're not showing these here, but that's not the type of filters we would get. We actually get a lot of these sort of spatial high frequency filters that we saw in the, uh, regular auto encoder where some of the filters were mostly gray and we saw like smaller ridges, uh, kind of, uh, waves in the, uh, in the filter,

Speaker 3:          12:22          uh, uh,

Speaker 1:          12:23          with high frequency. So we would see these types of things if we actually trained the PCA model on the same images. So now we see that we don't get that for the nosing auto encoder. The optimal solution is PCA. It's actually a very different solution which extracts features, which are much more meaningful. Uh, in terms of the types of things we'd like to know about the image, say fort recognizing objects. So detecting the, uh, our contours of an object should be useful for being able to identify a, what's the nature

Speaker 3:          12:54          that object.

Speaker 1:          12:58          And um, and also it's not equivalent to taking the regular tone quarter he had and adding a lot of weight. Tk. So I mentioning this because it's been shown that adding Goshen noise in the input,

Speaker 3:          13:10          uh, uh, uh,

Speaker 1:          13:13          and then Tony Quarter, if we, if discussion Norris was very, very small, then in the limit of towards being zero, uh, then it's essentially equivalent to some sort of weight decay or regularization on the weight. And, uh, but in fact, if you trained irregular autoencoder, which some way decay, you, we actually don't recover the same solution. We get these high frequency filters that,

Speaker 3:          13:38          uh, uh,

Speaker 1:          13:40          once we got on the images of, of characters, for instance, at our more,

Speaker 3:          13:44          uh, uh, you know, that are, um,

Speaker 1:          13:47          more silver alert to what we'd expect with a PCA, for instance. So really this is giving you a different solution from either strong way decay or a, or just PCA. This is really a, uh, a solution in terms of filters that, uh, is much more satisfying. And indeed, when we tried to use these features for classifying images, we do get much better performances than just with a regular touring quarter. So that's it for the nosing or throwing quarters.

Speaker 3:          14:14          Okay.