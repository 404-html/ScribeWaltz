Speaker 1:          00:00          Yeah.

Speaker 2:          00:00          In this video we'll define the loss function we'll be using for training are all networks. So we've seen the stochastic gradient descent algorithm. So in this video we're talking about defining this loss function here that we need, uh, as an ingredient for performing stochastic. Great. In the sense.

Speaker 1:          00:18          Okay.

Speaker 2:          00:19          Um, so we know that a neural network for classification, we can think of the output layer as giving us an estimate, uh, of a given some input. Uh, what is the probability that it belongs to class? See what is the property that the, uh, why the target associated with x is actually equal to some given class c? So F of x, a capital f of x, which is the output layer of our neural network. That's a vector. And so the CFO element would give us the probability that x belongs to the CF class and the whole vector gives us the whole distribution conditional distribution of what the target could be given x, uh, as estimated by the neural network. So something I would be fairly intuitive would be to maximize the probability of the correct target yt given some given, uh, input XD from our training center.

Speaker 2:          01:20          Now we're framing our training as a minimization problem that as a maximisation problem. So we'll convert, there's problem maximizing the probabilities into a minimization by using what is known as the negative log likelihood. So the negative log likelihood is a, so l of f of x and y where x is the input and wise, the true target is going to be minus the log and it's going to be the natural log. I'll use still log even though sometimes we write ln four, the natural log. So it's going to be minus log. The YF element of my output layer. Why is, because this is why is this is the why here. So this is the actual true target. So I'm going to minimize minus log of the white of the output layer, which is the estimate of x belonging to a label. Why? Um, so, uh, because log is um, sort of relationship between maximizing the probability and minimizing the lug.

Speaker 2:          02:27          My, the negative log prop is that, uh, maximizing the, maximizing something is the same thing as maximizing the lug of something because log is a monotonically increasing function. And then maximizing something is the same thing as minimizing the negative of something. Okay. So these two problems are actually equivalent and other way of writing the negative log likelihood is as follows, minus the sum over all possible classes. See of d, uh, an identifier, the function which is one if y, which is the true target, is equal to see this index over which I'm summing. And then so this identity function is one if this is true in zero otherwise. So if y is equal to c, then multiply one by the lug of f of x, F c, which is my estimate of the probability of the true class being c. And otherwise, if why is not equal to c, then this term is zero.

Speaker 2:          03:30          So this term disappears. So effectively, it means that you know, this, the only non zero term is this one. So that's why these two things are equal. Um, so we take the log to simplify, uh, and uh, also to get some numerical stability. Uh, um, uh, so yeah, so we, we take the log to get some numerical stability and also to simplify the math when we were going to compute a, in particular their relatives of the parameters and uh, uh, this, uh, [inaudible] is also known as the cross entropy. Uh, so if you're familiar with, uh, you know, a little bit about, uh, information theory, um, the cross entropy between two distribution is a, actually takes this form. So in fact, this would be the cross entropy or with the minus would be the cross entropy between this distribution here, which puts it probably have one over there, true class and zero over all other class. So the Co, the cross entropy do twin, this distribution and that distribution, which is the distribution that is output by our neural network. So, um, this is going to be the last function we'll use for training on neural network.