Speaker 1:          00:00          In this video, we'll discuss the, uh, idea of local connectivity in convolutional neural networks.

Speaker 2:          00:07          Yeah.

Speaker 1:          00:08          So, uh, we mentioned that we would, uh, in a previous video that we would, uh, talk about conventional known networks as a type of neural network that are specifically adapted for a computer vision problems. And that we'll first talk about a first property of conversional known networks, uh, which is a local connectivity of its hidden units.

Speaker 1:          00:28          So the idea is very simple. If you have the hidden layer in these convolutional neural networks, uh, then each unit in the hidden layer is actually going to be connected not to all the, uh, units in the previous hidden there in the previous layer. So in, for the first layer, this would be the, the visible layer of the input layer. Uh, it's actually instead going to be connected only to a small number of units. And specifically it's going to be connected to a unit in the locally, a spatially localized region of a dean. But so fun since we could have this hidden units here be connected only to the inputs that are present in that region of the image in this unit could be written, uh, connected to only these inputs here in that region and so on. Uh, in fact, what we will have is that we have a first in our first unit that will connected only to these, uh, inputs here. And then another one connected to a, a region that is right next to it. This will be the next thing in the unit. And you have like your hidden units for all of these small windows in the, uh, original input.

Speaker 1:          01:42          Um, it hidden unit will be connected to all the, uh, so called channels. So, uh, if we have agreed scale image, uh, then you're connected to just one channel, which is the intensity of the green scale intensity of the pixels. And then we have a color image, then we'll connect it to all three channels. There are the g and the beach handle. So that is the density of the red channel, the green channel, the Blue Chattel, and the image. And so this, uh, local connectivity property, we'll solve the two following problem. The first one is that if we had fully connected hidden there, uh, we would actually have an unmanageable number of parameters and, uh, if we increased the number of hitting this we could have on these so many hidden units, uh, without having memory problems and started with just in terms of just storing the providence of that, uh, no one network.

Speaker 1:          02:34          The other thing is that computing the, uh, linear activation. So I mean the pre activations of the hidden units, we actually be very expensive. If the hidden there was fully connected, uh, it would scale and the size of the, uh, of the input and the input size is very big. So that would be very expensive by adding heat should in unit be connected to only a small subset of the inputs. Then we reduced number of, of uh, multiplications we have to do between weights and inputs. So that's gonna give us a procedure which is a much more efficient. When we're talking about the, uh, uh, part of the image that a, a unit is connected to, we're going to refer to that as a receptive field. So the, the grayish area here are the receptive fields of the different units. Uh, and uh, sometimes I'm going to refer to our as being the height or the width if they're square of the receptive fields.

Speaker 2:          03:33          Okay.

Speaker 1:          03:34          And, um, so this slide is just to emphasize that if you have many channels, for instance, three channels in RGB images. So we have the, our channel here, the B channel in the, uh, sorry, the g channel here and the beach channel here. Uh, then we would actually get a heating unit would normally be connected to all channels. So to simplify those, this receptive field corresponded to four units, uh, which is clearly not true, but just to simplify things. Then we have four units here and four units here. Uh, then this hidden unit here would have, uh, 12 connections for here, plus the four here, plus the four here. Okay. So that's the idea of local connectivity and convolutional neural networks.