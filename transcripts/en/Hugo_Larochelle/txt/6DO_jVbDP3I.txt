Speaker 1:          00:00          Okay.

Speaker 2:          00:00          In this video, we'll look at an example of what we get when we train an auto encoder on some real data.

Speaker 2:          00:08          All right, so we have this auto encoder here. It's a feed forward neural network. It outputs a reconstruction of the input and then we've looked at how we could define a loss that compares the reconstruction with the input. And then using that loss we can, uh, compute the gradients which respect to the pre activation and then back propagate that through the network in order to do stochastic gradient descent training of the auto encoder on some set of unlabeled data. So let's look at what we get in terms of, uh, a later and representation in terms of features. If we train such an auto encoder, uh, on some real data. So we'll go back to the MDS data set, which, uh, we've looked at the phone when we talked about the restrictive Bolsa machine. So, uh, we'll train, we'll a lot of show is a result of training and ongoing color on that, the same data. And, uh, we'll look at each hidden unit in the encoder and see what kind of features it extracts, what kind of representation it extracts from the input.

Speaker 2:          01:15          So again, each square here is going to be one hidden unit in a deal toy quarter and a, it's a visualization of the weight factor between all inputs and specific hidden units. And so gray means a weight of zero black, a weight that's negative. And why a weight that's positive that we see that duo tone quarters seems to have learned, for instance, that we tend to have either white pixels close to each other in a spatially localized region or black pixel. It doesn't seem Harvard to have learned a very interesting feature such as stroke detectors or edge detectors. Uh, it actually has a lot of them, which are mainly zero and they're actually kind of um, uh, we'd say, uh, uh, they have, they show high spacial frequency, uh, but they don't seem to extract a particular particularly appealing and meaningful visual pattern. Um, it has understood that pixels around that are in some neighborhoods tend to have the same value, but otherwise it does. It doesn't seem to have understood a lot of the structure that's got, characterizes a Henry did characters. So why is that? And can we improve on that? So it turns out this auto encoder can still be useful in certain contexts, and we'll be able to talk about this when we talk about deep learning or we will also be able to improve it. And so in the next videos I'll talk about what's a problem here that we have with this particular way of training on auto encoder. And then we'll talk about some alternative solutions.