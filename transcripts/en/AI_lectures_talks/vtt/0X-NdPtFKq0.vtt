WEBVTT

1
00:00:00.600 --> 00:00:05.600
<v Speaker 1>And welcome to the second Royal </v>
<v Speaker 1>Television Society and institution of </v>

2
00:00:05.600 --> 00:00:07.590
<v Speaker 1>Engineering and technology public </v>
<v Speaker 1>lecture.</v>

3
00:00:07.830 --> 00:00:10.800
<v Speaker 1>I'm Tim Davie.</v>
<v Speaker 1>I'm sharing tonight and you know when we</v>

4
00:00:10.801 --> 00:00:15.801
<v Speaker 1>conceived of this lecture series,</v>
<v Speaker 1>our aim was to hear from some of the </v>

5
00:00:15.801 --> 00:00:19.521
<v Speaker 1>world's finest minds who work in the </v>
<v Speaker 1>spaces that bridge cutting edge science </v>

6
00:00:19.741 --> 00:00:22.950
<v Speaker 1>and technology with human creativity and</v>
<v Speaker 1>media.</v>

7
00:00:23.820 --> 00:00:26.710
<v Speaker 1>The amazing response,</v>
<v Speaker 1>and we were lucky to be there last year,</v>

8
00:00:26.711 --> 00:00:31.711
<v Speaker 1>whose those of us who saw Mike Lynch in </v>
<v Speaker 1>full flow suggested we were onto </v>

9
00:00:31.711 --> 00:00:36.141
<v Speaker 1>something and the excitement in the room</v>
<v Speaker 1>tonight speaks to the enduring appeal in</v>

10
00:00:36.211 --> 00:00:41.211
<v Speaker 1>my mind,</v>
<v Speaker 1>a public lectures in sparking our </v>

11
00:00:41.211 --> 00:00:42.930
<v Speaker 1>imagination in many ways.</v>
<v Speaker 1>And I really believe this.</v>

12
00:00:42.990 --> 00:00:47.130
<v Speaker 1>We are lucky enough to be enjoying </v>
<v Speaker 1>another golden age of advancement.</v>

13
00:00:47.131 --> 00:00:52.131
<v Speaker 1>The demands public engagement and debate</v>
<v Speaker 1>over 200 years.</v>

14
00:00:52.561 --> 00:00:57.561
<v Speaker 1>It was a rather precocious Humphry Davy </v>
<v Speaker 1>that was wowing crowds and causing </v>

15
00:00:58.050 --> 00:01:03.050
<v Speaker 1>carries traffic jams with sellout </v>
<v Speaker 1>lectures on the nature of human progress</v>

16
00:01:03.720 --> 00:01:05.220
<v Speaker 1>and scientific knowledge.</v>

17
00:01:05.760 --> 00:01:10.620
<v Speaker 1>Noticeably as a friend of Coleridge,</v>
<v Speaker 1>he was fascinated by the intersection of</v>

18
00:01:10.621 --> 00:01:14.190
<v Speaker 1>the subjective and the technical and the</v>
<v Speaker 1>possibilities,</v>

19
00:01:14.280 --> 00:01:16.770
<v Speaker 1>the endless possibilities that this </v>
<v Speaker 1>throws up.</v>

20
00:01:17.310 --> 00:01:19.560
<v Speaker 1>So tonight at this wonderful </v>
<v Speaker 1>institution,</v>

21
00:01:19.860 --> 00:01:23.100
<v Speaker 1>we continue that tradition with our very</v>
<v Speaker 1>special speaker,</v>

22
00:01:23.400 --> 00:01:26.220
<v Speaker 1>Dennis Hassabis,</v>
<v Speaker 1>that's the best dentist,</v>

23
00:01:26.250 --> 00:01:31.250
<v Speaker 1>will talk for 35 minutes or so.</v>
<v Speaker 1>Then we'll open up for q and a and I'll </v>

24
00:01:31.250 --> 00:01:35.481
<v Speaker 1>be conducting will have the lights up </v>
<v Speaker 1>and were really up for a good old </v>

25
00:01:35.481 --> 00:01:36.450
<v Speaker 1>discussion with you guys.</v>
<v Speaker 1>As you know,</v>

26
00:01:36.840 --> 00:01:40.710
<v Speaker 1>Dennis is acknowledged as a world </v>
<v Speaker 1>leading thinker in the realm of Ai,</v>

27
00:01:41.280 --> 00:01:46.280
<v Speaker 1>which in recent years has become where </v>
<v Speaker 1>the hottest topics dominating the media </v>

28
00:01:46.280 --> 00:01:48.990
<v Speaker 1>and the imagination of the public.</v>
<v Speaker 1>You know my world.</v>

29
00:01:48.991 --> 00:01:53.991
<v Speaker 1>We run a recent and BBC survey which was</v>
<v Speaker 1>looking at which jobs are at risk of </v>

30
00:01:53.991 --> 00:01:58.971
<v Speaker 1>computerization.</v>
<v Speaker 1>We attracted two point 3 million page </v>

31
00:01:58.971 --> 00:02:02.991
<v Speaker 1>views.</v>
<v Speaker 1>People viewing that and seeing how safe </v>

32
00:02:02.991 --> 00:02:02.991
<v Speaker 1>they were.</v>

33
00:02:03.480 --> 00:02:07.110
<v Speaker 1>Liz needs little introduction,</v>
<v Speaker 1>but I have to say his achievements,</v>

34
00:02:07.111 --> 00:02:10.200
<v Speaker 1>but even the highest achievers cv db in </v>
<v Speaker 1>the shade,</v>

35
00:02:10.780 --> 00:02:15.780
<v Speaker 1>chess master,</v>
<v Speaker 1>30 World Games Championship winner five </v>

36
00:02:15.780 --> 00:02:17.160
<v Speaker 1>times running.</v>
<v Speaker 1>Successful poker player,</v>

37
00:02:17.161 --> 00:02:20.820
<v Speaker 1>particularly impressive double first in </v>
<v Speaker 1>computer science at Cambridge.</v>

38
00:02:21.270 --> 00:02:26.270
<v Speaker 1>A pioneering video games developer lead </v>
<v Speaker 1>of numerous important pieces of research</v>

39
00:02:27.360 --> 00:02:32.360
<v Speaker 1>in the field of neuroscience.</v>
<v Speaker 1>Notably his landmark paper on the </v>

40
00:02:32.400 --> 00:02:37.400
<v Speaker 1>similarities of how we shape memory and </v>
<v Speaker 1>how we imagine the future was a landmark</v>

41
00:02:38.491 --> 00:02:43.491
<v Speaker 1>and breakthrough piece of research and </v>
<v Speaker 1>then of course founder of deep mind in </v>

42
00:02:43.491 --> 00:02:47.511
<v Speaker 1>2011,</v>
<v Speaker 1>which was then sold to Google in 2014 </v>

43
00:02:47.511 --> 00:02:51.810
<v Speaker 1>with Dennis becoming vp engineering with</v>
<v Speaker 1>special responsibility for ai.</v>

44
00:02:52.920 --> 00:02:56.760
<v Speaker 1>Deep mind has set out a goal of solving </v>
<v Speaker 1>intelligence.</v>

45
00:02:56.840 --> 00:03:01.840
<v Speaker 1>A humble objective specifically dennis </v>
<v Speaker 1>just said he is involved in building </v>

46
00:03:01.901 --> 00:03:05.890
<v Speaker 1>something that can expect the unexpected</v>
<v Speaker 1>gracefully.</v>

47
00:03:07.060 --> 00:03:10.660
<v Speaker 1>I think that's probably a great brief </v>
<v Speaker 1>for an audience of a public lecture.</v>

48
00:03:11.210 --> 00:03:12.460
<v Speaker 1>Dennis,</v>
<v Speaker 1>the floor is yours.</v>

49
00:03:20.550 --> 00:03:25.550
<v Speaker 2>Well,</v>
<v Speaker 2>thanks very much tim for that very </v>

50
00:03:25.550 --> 00:03:27.411
<v Speaker 2>generous introduction.</v>
<v Speaker 2>So it's a real pleasure to be here and </v>

51
00:03:27.411 --> 00:03:30.641
<v Speaker 2>I'm giving this lecture and I'm going to</v>
<v Speaker 2>talk about artificial intelligence and </v>

52
00:03:31.260 --> 00:03:33.600
<v Speaker 2>its impact on the future.</v>
<v Speaker 2>In fact,</v>

53
00:03:33.601 --> 00:03:36.120
<v Speaker 2>it could be the relatively near term </v>
<v Speaker 2>future.</v>

54
00:03:37.920 --> 00:03:42.920
<v Speaker 2>So Ai is really the science of making </v>
<v Speaker 2>machines smart and I got into ai firstly</v>

55
00:03:45.151 --> 00:03:50.130
<v Speaker 2>through the medium of games and Games </v>
<v Speaker 2>started for me with chess.</v>

56
00:03:50.340 --> 00:03:55.340
<v Speaker 2>As Tim said,</v>
<v Speaker 2>I started playing chess when I was very </v>

57
00:03:55.340 --> 00:03:57.651
<v Speaker 2>young at the age of four and I think if </v>
<v Speaker 2>you play chess seriously from such a </v>

58
00:03:57.651 --> 00:03:59.220
<v Speaker 2>young age and you're quite an </v>
<v Speaker 2>introspective kid,</v>

59
00:03:59.221 --> 00:04:04.221
<v Speaker 2>which I was,</v>
<v Speaker 2>then you start thinking a lot about how </v>

60
00:04:04.221 --> 00:04:05.310
<v Speaker 2>is it that your brain is coming up with </v>
<v Speaker 2>these moves,</v>

61
00:04:05.311 --> 00:04:06.710
<v Speaker 2>these ideas,</v>
<v Speaker 2>um,</v>

62
00:04:06.840 --> 00:04:09.450
<v Speaker 2>that allow you to play this game and win</v>
<v Speaker 2>these games.</v>

63
00:04:09.840 --> 00:04:14.190
<v Speaker 2>And I started thinking a lot about this </v>
<v Speaker 2>as I got into my teenage years.</v>

64
00:04:16.010 --> 00:04:17.840
<v Speaker 2>And allied with that,</v>
<v Speaker 2>um,</v>

65
00:04:17.960 --> 00:04:18.500
<v Speaker 2>I,</v>
<v Speaker 2>uh,</v>

66
00:04:18.560 --> 00:04:21.370
<v Speaker 2>got into computing or actually bought my</v>
<v Speaker 2>first computer,</v>

67
00:04:21.371 --> 00:04:26.371
<v Speaker 2>is that x spectrum here,</v>
<v Speaker 2>48 k with some winnings from a chess </v>

68
00:04:26.371 --> 00:04:26.670
<v Speaker 2>tournament.</v>
<v Speaker 2>And uh,</v>

69
00:04:26.690 --> 00:04:30.170
<v Speaker 2>when I was about eight years old and I </v>
<v Speaker 2>started teaching myself how to program.</v>

70
00:04:30.440 --> 00:04:33.440
<v Speaker 2>And I think very early on in the </v>
<v Speaker 2>engineers and the audience will,</v>

71
00:04:33.500 --> 00:04:35.270
<v Speaker 2>I think,</v>
<v Speaker 2>resonate with this.</v>

72
00:04:35.450 --> 00:04:40.450
<v Speaker 2>I sort of realized I'm on an intuitive </v>
<v Speaker 2>level that this competed a kind of </v>

73
00:04:40.820 --> 00:04:43.310
<v Speaker 2>special type of machine.</v>
<v Speaker 2>You know,</v>

74
00:04:43.311 --> 00:04:48.311
<v Speaker 2>most machines like cars and planes,</v>
<v Speaker 2>they allow us to extend our physical </v>

75
00:04:48.311 --> 00:04:48.920
<v Speaker 2>capabilities.</v>
<v Speaker 2>You know,</v>

76
00:04:48.921 --> 00:04:52.070
<v Speaker 2>cars allow us to move faster than we can</v>
<v Speaker 2>run planes allow us to fly,</v>

77
00:04:52.340 --> 00:04:54.740
<v Speaker 2>um,</v>
<v Speaker 2>but I think computers do that,</v>

78
00:04:54.890 --> 00:04:56.810
<v Speaker 2>but in the realm of our minds,</v>
<v Speaker 2>um,</v>

79
00:04:56.870 --> 00:05:01.870
<v Speaker 2>they really extend the capabilities of </v>
<v Speaker 2>the brain and this really came clear to </v>

80
00:05:01.870 --> 00:05:06.781
<v Speaker 2>me when I used to write my first </v>
<v Speaker 2>programs and did sort of basic math </v>

81
00:05:06.781 --> 00:05:07.780
<v Speaker 2>calculations and other things which,</v>
<v Speaker 2>um,</v>

82
00:05:07.810 --> 00:05:12.810
<v Speaker 2>it really struck me.</v>
<v Speaker 2>You could set something running </v>

83
00:05:12.810 --> 00:05:15.151
<v Speaker 2>overnight and then go to sleep and then </v>
<v Speaker 2>you'd wake up the next morning and your </v>

84
00:05:15.151 --> 00:05:18.100
<v Speaker 2>computer will solve some problem for you</v>
<v Speaker 2>whilst you were asleep.</v>

85
00:05:18.490 --> 00:05:21.100
<v Speaker 2>So this felt like a really powerful in </v>
<v Speaker 2>some ways,</v>

86
00:05:21.101 --> 00:05:21.580
<v Speaker 2>magical.</v>
<v Speaker 2>Yeah.</v>

87
00:05:23.330 --> 00:05:28.330
<v Speaker 2>Say My love of computers and my love of </v>
<v Speaker 2>games obviously came together in a,</v>

88
00:05:29.091 --> 00:05:30.930
<v Speaker 2>in a kind of obvious way,</v>
<v Speaker 2>uh,</v>

89
00:05:30.980 --> 00:05:35.980
<v Speaker 2>in the designing of video games.</v>
<v Speaker 2>And actually this is one of the reasons </v>

90
00:05:35.980 --> 00:05:37.370
<v Speaker 2>I accepted to do this lecture is I love </v>
<v Speaker 2>the idea,</v>

91
00:05:37.371 --> 00:05:42.371
<v Speaker 2>as tim said,</v>
<v Speaker 2>of the confluence of bringing together </v>

92
00:05:42.371 --> 00:05:44.870
<v Speaker 2>rts and the creative arts and the iet </v>
<v Speaker 2>and sort of engineering.</v>

93
00:05:45.180 --> 00:05:50.180
<v Speaker 2>Um,</v>
<v Speaker 2>and that's why I got into commercial </v>

94
00:05:50.180 --> 00:05:50.180
<v Speaker 2>video games.</v>
<v Speaker 2>Um,</v>

95
00:05:50.180 --> 00:05:53.890
<v Speaker 2>because at the time,</v>
<v Speaker 2>this is sort of like the early and mid </v>

96
00:05:53.890 --> 00:05:57.251
<v Speaker 2>nineties and computer games are really </v>
<v Speaker 2>pushing the cutting edge of engineering </v>

97
00:05:57.251 --> 00:06:01.340
<v Speaker 2>and even the machines that were being </v>
<v Speaker 2>built to run these games.</v>

98
00:06:01.550 --> 00:06:04.040
<v Speaker 2>So I remember the debates in the </v>
<v Speaker 2>nineties about,</v>

99
00:06:04.150 --> 00:06:09.150
<v Speaker 2>you know,</v>
<v Speaker 2>Intel is bringing out their new pentium </v>

100
00:06:09.150 --> 00:06:09.150
<v Speaker 2>processes and people were sort of </v>
<v Speaker 2>saying,</v>

101
00:06:09.150 --> 00:06:13.240
<v Speaker 2>well,</v>
<v Speaker 2>how much more power do we need to run </v>

102
00:06:13.240 --> 00:06:13.310
<v Speaker 2>our work processes and spreadsheets and </v>
<v Speaker 2>um,</v>

103
00:06:13.311 --> 00:06:18.311
<v Speaker 2>you know,</v>
<v Speaker 2>haven't we got all the computing power </v>

104
00:06:18.311 --> 00:06:18.311
<v Speaker 2>we need?</v>

105
00:06:18.311 --> 00:06:18.380
<v Speaker 2>And actually one of the answers was </v>
<v Speaker 2>that,</v>

106
00:06:18.381 --> 00:06:20.710
<v Speaker 2>um,</v>
<v Speaker 2>if we wanted more and more realistic and</v>

107
00:06:20.870 --> 00:06:25.870
<v Speaker 2>complex games,</v>
<v Speaker 2>then we would require more and more </v>

108
00:06:25.870 --> 00:06:27.260
<v Speaker 2>powerful computers with larger memory </v>
<v Speaker 2>and things like graphics chips.</v>

109
00:06:27.440 --> 00:06:32.440
<v Speaker 2>So for a long while games were actually </v>
<v Speaker 2>driving the development of a cutting </v>

110
00:06:32.541 --> 00:06:35.540
<v Speaker 2>edge hardware.</v>
<v Speaker 2>And furthermore,</v>

111
00:06:35.960 --> 00:06:40.960
<v Speaker 2>the games that I used to sort of design </v>
<v Speaker 2>and program all involved ai as a core </v>

112
00:06:41.871 --> 00:06:46.871
<v Speaker 2>gameplay mechanic.</v>
<v Speaker 2>So probably my best known game was </v>

113
00:06:46.871 --> 00:06:49.370
<v Speaker 2>called theme park and uh,</v>
<v Speaker 2>which is some screenshots of it has came</v>

114
00:06:49.371 --> 00:06:54.371
<v Speaker 2>out in 94 and was very successful.</v>
<v Speaker 2>And it was actually the first game of </v>

115
00:06:54.441 --> 00:06:57.020
<v Speaker 2>its type.</v>
<v Speaker 2>So the idea here was that,</v>

116
00:06:57.021 --> 00:07:02.021
<v Speaker 2>um,</v>
<v Speaker 2>you designed your own Disney world and </v>

117
00:07:02.021 --> 00:07:04.460
<v Speaker 2>thousands of little people would come in</v>
<v Speaker 2>to your Disney world and kind of play on</v>

118
00:07:04.461 --> 00:07:08.570
<v Speaker 2>your rides and how enjoyable they </v>
<v Speaker 2>thought your theme park was,</v>

119
00:07:08.780 --> 00:07:09.530
<v Speaker 2>would,</v>
<v Speaker 2>um,</v>

120
00:07:09.560 --> 00:07:12.470
<v Speaker 2>sort of have an impact on their emotions</v>
<v Speaker 2>and how happy they were.</v>

121
00:07:12.620 --> 00:07:16.310
<v Speaker 2>And then that fed into them and </v>
<v Speaker 2>economics model about how much you could</v>

122
00:07:16.311 --> 00:07:18.170
<v Speaker 2>charge them for the hamburgers and the </v>
<v Speaker 2>balloons.</v>

123
00:07:18.320 --> 00:07:20.220
<v Speaker 2>So the better design your,</v>
<v Speaker 2>um,</v>

124
00:07:20.270 --> 00:07:21.890
<v Speaker 2>thing park was,</v>
<v Speaker 2>um,</v>

125
00:07:21.920 --> 00:07:23.640
<v Speaker 2>the more money it made,</v>
<v Speaker 2>and then that allows you,</v>

126
00:07:23.641 --> 00:07:25.370
<v Speaker 2>of course,</v>
<v Speaker 2>to expand the theme park further.</v>

127
00:07:25.850 --> 00:07:26.550
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

128
00:07:26.600 --> 00:07:31.600
<v Speaker 2>this game and actually another game </v>
<v Speaker 2>called Sim city with the first sort of </v>

129
00:07:31.600 --> 00:07:34.301
<v Speaker 2>games that had ai as a core game play </v>
<v Speaker 2>component and really spawned a whole </v>

130
00:07:34.301 --> 00:07:36.920
<v Speaker 2>genre of management simulation games as </v>
<v Speaker 2>they're called.</v>

131
00:07:37.430 --> 00:07:41.990
<v Speaker 2>And one of the reasons these gains are </v>
<v Speaker 2>so popular is that the ai adapted to the</v>

132
00:07:41.991 --> 00:07:46.991
<v Speaker 2>way the player played the game.</v>
<v Speaker 2>So that means that every single person </v>

133
00:07:46.991 --> 00:07:49.700
<v Speaker 2>who played this game had a unique </v>
<v Speaker 2>experience.</v>

134
00:07:50.180 --> 00:07:50.660
<v Speaker 2>And,</v>
<v Speaker 2>uh,</v>

135
00:07:50.750 --> 00:07:53.300
<v Speaker 2>people used to send in our member into </v>
<v Speaker 2>magazines,</v>

136
00:07:53.301 --> 00:07:58.301
<v Speaker 2>gay magazines and write into us,</v>
<v Speaker 2>I'm showing what's the end state they </v>

137
00:07:58.341 --> 00:07:59.630
<v Speaker 2>got their theme park into.</v>

138
00:07:59.780 --> 00:08:04.780
<v Speaker 2>And there was all these amazing designs </v>
<v Speaker 2>that people are created that we had no </v>

139
00:08:04.780 --> 00:08:07.100
<v Speaker 2>idea could be done even as the inventors</v>
<v Speaker 2>of this game.</v>

140
00:08:07.510 --> 00:08:12.510
<v Speaker 2>Um,</v>
<v Speaker 2>so that really struck a chord with me </v>

141
00:08:12.510 --> 00:08:12.510
<v Speaker 2>when I was around 16,</v>
<v Speaker 2>17 years old when I wrote this game.</v>

142
00:08:12.680 --> 00:08:14.720
<v Speaker 2>And I'm thinking about,</v>
<v Speaker 2>you know,</v>

143
00:08:14.750 --> 00:08:17.600
<v Speaker 2>maybe if I devoted my career to ai </v>
<v Speaker 2>advancing ai,</v>

144
00:08:17.720 --> 00:08:20.030
<v Speaker 2>um,</v>
<v Speaker 2>what an incredible technology that could</v>

145
00:08:20.031 --> 00:08:25.031
<v Speaker 2>be.</v>
<v Speaker 2>So then after having a career and </v>

146
00:08:25.031 --> 00:08:25.640
<v Speaker 2>getting games and running my own games </v>
<v Speaker 2>companies and things,</v>

147
00:08:25.880 --> 00:08:30.290
<v Speaker 2>um,</v>
<v Speaker 2>I then went back to academia to do a phd</v>

148
00:08:30.650 --> 00:08:35.650
<v Speaker 2>in neuroscience,</v>
<v Speaker 2>which I felt was another piece of the </v>

149
00:08:35.650 --> 00:08:36.470
<v Speaker 2>puzzle that I needed before launching an</v>
<v Speaker 2>effort.</v>

150
00:08:36.471 --> 00:08:41.471
<v Speaker 2>Like deep mind.</v>
<v Speaker 2>I wanted to understand a bit more about </v>

151
00:08:41.471 --> 00:08:41.471
<v Speaker 2>how the brain,</v>
<v Speaker 2>um,</v>

152
00:08:41.471 --> 00:08:44.630
<v Speaker 2>solved a tough problems like imagination</v>
<v Speaker 2>and memory.</v>

153
00:08:44.810 --> 00:08:49.810
<v Speaker 2>And I specifically pick those topics to </v>
<v Speaker 2>do my phd on because those are things </v>

154
00:08:49.810 --> 00:08:54.671
<v Speaker 2>that at least back into mid two </v>
<v Speaker 2>thousands where were we will not very </v>

155
00:08:54.671 --> 00:08:59.250
<v Speaker 2>good at doing in computer algorithms.</v>
<v Speaker 2>So I wanted to look at the way the brain</v>

156
00:08:59.251 --> 00:09:00.390
<v Speaker 2>sold.</v>
<v Speaker 2>Somebody is very,</v>

157
00:09:00.391 --> 00:09:03.780
<v Speaker 2>very tough problems that we didn't know </v>
<v Speaker 2>yet how to imbue our machines with.</v>

158
00:09:04.710 --> 00:09:08.080
<v Speaker 2>And I'll come back to that towards the </v>
<v Speaker 2>second half of my talk.</v>

159
00:09:09.220 --> 00:09:13.090
<v Speaker 2>So all of these different experiences </v>
<v Speaker 2>then culminated in finally in setting up</v>

160
00:09:13.091 --> 00:09:14.320
<v Speaker 2>deep mind,</v>
<v Speaker 2>uh,</v>

161
00:09:14.390 --> 00:09:16.730
<v Speaker 2>in 2010 and really,</v>
<v Speaker 2>um,</v>

162
00:09:16.810 --> 00:09:19.990
<v Speaker 2>it's been a 20 year plus journey for me </v>
<v Speaker 2>to get to this point,</v>

163
00:09:20.210 --> 00:09:25.210
<v Speaker 2>uh,</v>
<v Speaker 2>and have enough of what I thought were </v>

164
00:09:25.210 --> 00:09:27.241
<v Speaker 2>the basic ingredients both on an </v>
<v Speaker 2>algorithmic level but also in terms of </v>

165
00:09:27.241 --> 00:09:31.441
<v Speaker 2>the founding scientific team and making </v>
<v Speaker 2>those contacts to actually put together </v>

166
00:09:31.441 --> 00:09:33.250
<v Speaker 2>something like the mind and,</v>
<v Speaker 2>um,</v>

167
00:09:33.370 --> 00:09:36.970
<v Speaker 2>and plausibly go after those big </v>
<v Speaker 2>emission as solving intelligence.</v>

168
00:09:38.460 --> 00:09:40.100
<v Speaker 2>So another way we look at,</v>
<v Speaker 2>um,</v>

169
00:09:40.210 --> 00:09:45.210
<v Speaker 2>uh,</v>
<v Speaker 2>the company is as an Apollo program for </v>

170
00:09:45.210 --> 00:09:48.501
<v Speaker 2>ai as sort of moonshot project that </v>
<v Speaker 2>really focuses on the very ambitious </v>

171
00:09:48.751 --> 00:09:53.751
<v Speaker 2>longterm goals.</v>
<v Speaker 2>And we've collected together a 100 more </v>

172
00:09:53.751 --> 00:09:55.530
<v Speaker 2>than $100,</v>
<v Speaker 2>knew 150 now of the world's top research</v>

173
00:09:55.531 --> 00:10:00.531
<v Speaker 2>scientists in this area.</v>
<v Speaker 2>So I think the mind is by far now the </v>

174
00:10:00.531 --> 00:10:03.120
<v Speaker 2>biggest collection of machine learning </v>
<v Speaker 2>experts anywhere in the world.</v>

175
00:10:04.430 --> 00:10:05.920
<v Speaker 2>And another thing we're experimenting </v>
<v Speaker 2>with,</v>

176
00:10:05.921 --> 00:10:10.921
<v Speaker 2>of course,</v>
<v Speaker 2>apart from trying to build ai is </v>

177
00:10:10.921 --> 00:10:12.260
<v Speaker 2>actually a new ways to organize </v>
<v Speaker 2>scientific endeavor.</v>

178
00:10:12.620 --> 00:10:16.300
<v Speaker 2>So what we've tried to do with deep mind</v>
<v Speaker 2>is really combined the best form,</v>

179
00:10:16.470 --> 00:10:19.880
<v Speaker 2>um,</v>
<v Speaker 2>silicon valley startups together with,</v>

180
00:10:20.010 --> 00:10:22.340
<v Speaker 2>uh,</v>
<v Speaker 2>the best parts of that you find in the,</v>

181
00:10:22.341 --> 00:10:24.710
<v Speaker 2>in the best academic institutes like </v>
<v Speaker 2>Mit,</v>

182
00:10:24.711 --> 00:10:25.730
<v Speaker 2>ucl,</v>
<v Speaker 2>Cambridge,</v>

183
00:10:25.731 --> 00:10:28.730
<v Speaker 2>and so on,</v>
<v Speaker 2>and see if we can infuse that into a new</v>

184
00:10:28.731 --> 00:10:33.731
<v Speaker 2>hybrid way of doing science,</v>
<v Speaker 2>which is more productive and extremely </v>

185
00:10:33.731 --> 00:10:36.380
<v Speaker 2>efficient,</v>
<v Speaker 2>but still allows for extreme creativity.</v>

186
00:10:38.680 --> 00:10:40.500
<v Speaker 2>So our mission then,</v>
<v Speaker 2>as Tim said,</v>

187
00:10:40.600 --> 00:10:43.840
<v Speaker 2>we articulate it in a kind of to step </v>
<v Speaker 2>way.</v>

188
00:10:43.930 --> 00:10:46.780
<v Speaker 2>So firstly we talk about solving </v>
<v Speaker 2>intelligence.</v>

189
00:10:46.970 --> 00:10:48.730
<v Speaker 2>Um,</v>
<v Speaker 2>and we use the word solve,</v>

190
00:10:48.850 --> 00:10:52.270
<v Speaker 2>which is a kind of ambiguous word there </v>
<v Speaker 2>because actually what we mean,</v>

191
00:10:52.271 --> 00:10:55.390
<v Speaker 2>what we're interested in is,</v>
<v Speaker 2>is understanding natural intelligence.</v>

192
00:10:56.230 --> 00:11:00.400
<v Speaker 2>So the human mind.</v>
<v Speaker 2>But also recreating that on intelligence</v>

193
00:11:00.401 --> 00:11:03.080
<v Speaker 2>artificially.</v>
<v Speaker 2>And then step two,</v>

194
00:11:03.290 --> 00:11:07.010
<v Speaker 2>we want to use that technology to help </v>
<v Speaker 2>us solve everything else.</v>

195
00:11:07.340 --> 00:11:08.340
<v Speaker 2>Now,</v>
<v Speaker 2>um,</v>

196
00:11:08.420 --> 00:11:13.420
<v Speaker 2>you know,</v>
<v Speaker 2>that might seem a little bit far </v>

197
00:11:13.420 --> 00:11:14.791
<v Speaker 2>fetched,</v>
<v Speaker 2>possibly a little bit fanciful to some </v>

198
00:11:14.791 --> 00:11:14.791
<v Speaker 2>of you,</v>
<v Speaker 2>um,</v>

199
00:11:14.791 --> 00:11:18.130
<v Speaker 2>but we really believe actually that step</v>
<v Speaker 2>to naturally follows on from step one.</v>

200
00:11:18.320 --> 00:11:21.980
<v Speaker 2>If you can solve intelligence,</v>
<v Speaker 2>and I hope by the end of this talk,</v>

201
00:11:22.180 --> 00:11:23.030
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

202
00:11:23.031 --> 00:11:25.040
<v Speaker 2>you'll,</v>
<v Speaker 2>you'll agree with this conjecture.</v>

203
00:11:26.960 --> 00:11:30.230
<v Speaker 2>So more prosaically,</v>
<v Speaker 2>how are we going to solve intelligence?</v>

204
00:11:30.410 --> 00:11:35.410
<v Speaker 2>Well,</v>
<v Speaker 2>what we're trying to do at deep mind is </v>

205
00:11:35.410 --> 00:11:37.160
<v Speaker 2>to construct the world's first general </v>
<v Speaker 2>purpose learning machine.</v>

206
00:11:38.060 --> 00:11:41.090
<v Speaker 2>And the key aspects of this are the word</v>
<v Speaker 2>general and learning.</v>

207
00:11:41.390 --> 00:11:45.020
<v Speaker 2>So we're at deep mind,</v>
<v Speaker 2>we're only interested in algorithms that</v>

208
00:11:45.021 --> 00:11:50.021
<v Speaker 2>learn for themselves,</v>
<v Speaker 2>so they learn automatically from raw </v>

209
00:11:50.021 --> 00:11:53.090
<v Speaker 2>experience or war data,</v>
<v Speaker 2>so they're not preprogrammed in any way.</v>

210
00:11:53.560 --> 00:11:57.250
<v Speaker 2>So what we're talking about here is </v>
<v Speaker 2>autonomous learning system.</v>

211
00:11:58.930 --> 00:12:01.210
<v Speaker 2>The second thing is this idea of </v>
<v Speaker 2>generality.</v>

212
00:12:01.540 --> 00:12:02.560
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

213
00:12:02.650 --> 00:12:04.930
<v Speaker 2>what we're interested in is the same </v>
<v Speaker 2>system.</v>

214
00:12:05.110 --> 00:12:10.110
<v Speaker 2>I'm actually being able to operate </v>
<v Speaker 2>across a wide range of tasks and </v>

215
00:12:10.110 --> 00:12:12.160
<v Speaker 2>environments out of the box with no </v>
<v Speaker 2>reconfiguration,</v>

216
00:12:12.940 --> 00:12:15.550
<v Speaker 2>so of course we have an example of such </v>
<v Speaker 2>a general learning system.</v>

217
00:12:15.580 --> 00:12:20.140
<v Speaker 2>It's the human mind where we're able to </v>
<v Speaker 2>apply our minds to almost endless number</v>

218
00:12:20.141 --> 00:12:24.850
<v Speaker 2>of different tasks.</v>
<v Speaker 2>Now I should say most of ai today,</v>

219
00:12:24.851 --> 00:12:28.240
<v Speaker 2>although it's a huge buzzword right now </v>
<v Speaker 2>and is very fashionable,</v>

220
00:12:28.450 --> 00:12:32.650
<v Speaker 2>most of it,</v>
<v Speaker 2>ai is not of this type of technology,</v>

221
00:12:33.010 --> 00:12:38.010
<v Speaker 2>so we call most ai actually internally </v>
<v Speaker 2>at deep mind narrow ai and what we mean </v>

222
00:12:38.010 --> 00:12:42.541
<v Speaker 2>by that is preprogrammed ai that has </v>
<v Speaker 2>been built for in a bespoke way for one </v>

223
00:12:42.971 --> 00:12:47.971
<v Speaker 2>specific task and actually most of the </v>
<v Speaker 2>Ai we interact with everyday from Siri </v>

224
00:12:47.971 --> 00:12:52.711
<v Speaker 2>on your phone to self driving cars is </v>
<v Speaker 2>actually a of this preprogram type of Ai</v>

225
00:12:55.250 --> 00:12:59.210
<v Speaker 2>and what we're interested in is what we </v>
<v Speaker 2>call artificial general intelligence.</v>

226
00:12:59.420 --> 00:13:01.580
<v Speaker 2>This idea of a general learning system</v>

227
00:13:03.120 --> 00:13:05.880
<v Speaker 2>and perhaps still the most famous and </v>
<v Speaker 2>clearest example I can give her.</v>

228
00:13:05.881 --> 00:13:09.820
<v Speaker 2>This is the famous deepblue match </v>
<v Speaker 2>against Garry Kasparov.</v>

229
00:13:10.100 --> 00:13:15.100
<v Speaker 2>Of course,</v>
<v Speaker 2>this was a watershed moment in ai when </v>

230
00:13:15.100 --> 00:13:19.161
<v Speaker 2>in the late nineties,</v>
<v Speaker 2>IBM's deep blue beat Kasparov in a six </v>

231
00:13:19.161 --> 00:13:20.250
<v Speaker 2>game chest match.</v>
<v Speaker 2>Um,</v>

232
00:13:20.370 --> 00:13:22.650
<v Speaker 2>but the interesting thing is I came away</v>
<v Speaker 2>from that match,</v>

233
00:13:22.651 --> 00:13:27.450
<v Speaker 2>actually more impressed by Garry </v>
<v Speaker 2>Kasparov mind than the deep blue machine</v>

234
00:13:27.720 --> 00:13:29.080
<v Speaker 2>because,</v>
<v Speaker 2>um,</v>

235
00:13:29.150 --> 00:13:34.150
<v Speaker 2>you know,</v>
<v Speaker 2>of course it was an impressive </v>

236
00:13:34.150 --> 00:13:35.511
<v Speaker 2>engineering feat,</v>
<v Speaker 2>but deep blue was programmed by an </v>

237
00:13:35.511 --> 00:13:39.321
<v Speaker 2>amazing team of programmers along with a</v>
<v Speaker 2>bunch of chess grandmasters trying to </v>

238
00:13:39.321 --> 00:13:42.330
<v Speaker 2>distill chest knowledge into an </v>
<v Speaker 2>algorithmic sort of construct.</v>

239
00:13:42.570 --> 00:13:47.570
<v Speaker 2>And those programmers were directly </v>
<v Speaker 2>programming in the sort of ideas and </v>

240
00:13:47.570 --> 00:13:49.830
<v Speaker 2>solutions into the machine.</v>
<v Speaker 2>And of course,</v>

241
00:13:49.890 --> 00:13:52.920
<v Speaker 2>what that meant is that deep blue,</v>
<v Speaker 2>although it was very good at chess,</v>

242
00:13:53.040 --> 00:13:56.010
<v Speaker 2>it was no use for absolutely anything </v>
<v Speaker 2>else,</v>

243
00:13:56.220 --> 00:13:59.670
<v Speaker 2>including strictly simpler things like,</v>
<v Speaker 2>for example,</v>

244
00:13:59.671 --> 00:14:04.671
<v Speaker 2>playing noughts and crosses which any </v>
<v Speaker 2>chess grandmaster you could trivially </v>

245
00:14:04.671 --> 00:14:05.520
<v Speaker 2>teach them how to play noughts and </v>
<v Speaker 2>crosses.</v>

246
00:14:05.730 --> 00:14:07.950
<v Speaker 2>But obviously deep blue,</v>
<v Speaker 2>nothing that deep blue,</v>

247
00:14:07.951 --> 00:14:10.690
<v Speaker 2>new or in its code would help it with,</v>
<v Speaker 2>um,</v>

248
00:14:10.890 --> 00:14:12.540
<v Speaker 2>even something strictly simple like </v>
<v Speaker 2>that,</v>

249
00:14:12.720 --> 00:14:13.710
<v Speaker 2>let alone,</v>
<v Speaker 2>um,</v>

250
00:14:13.910 --> 00:14:18.910
<v Speaker 2>uh,</v>
<v Speaker 2>other kinds of domains like speaking </v>

251
00:14:18.910 --> 00:14:20.931
<v Speaker 2>languages or driving cause all these </v>
<v Speaker 2>other things that of course Gary </v>

252
00:14:20.931 --> 00:14:20.931
<v Speaker 2>Kasparov could do effortlessly.</v>

253
00:14:22.930 --> 00:14:27.930
<v Speaker 2>So instead of that,</v>
<v Speaker 2>we think about intelligence in the </v>

254
00:14:27.930 --> 00:14:28.210
<v Speaker 2>framework of what's called reinforcement</v>
<v Speaker 2>learning.</v>

255
00:14:28.840 --> 00:14:33.840
<v Speaker 2>So I'm just going to illustrate what the</v>
<v Speaker 2>main basic parts of that in this little </v>

256
00:14:33.840 --> 00:14:36.430
<v Speaker 2>cartoon diagram because it's important </v>
<v Speaker 2>for what I'm going to show next in terms</v>

257
00:14:36.431 --> 00:14:37.570
<v Speaker 2>of the videos of the,</v>
<v Speaker 2>of the,</v>

258
00:14:37.630 --> 00:14:41.620
<v Speaker 2>of the algorithms working.</v>
<v Speaker 2>So you start off with your agent system.</v>

259
00:14:41.810 --> 00:14:46.630
<v Speaker 2>I'm represented by this little humanoid </v>
<v Speaker 2>character and that agent finds itself in</v>

260
00:14:46.631 --> 00:14:50.020
<v Speaker 2>an environment which could be virtual or</v>
<v Speaker 2>real world.</v>

261
00:14:50.021 --> 00:14:52.090
<v Speaker 2>If it's real world,</v>
<v Speaker 2>the agent probably be a robot.</v>

262
00:14:52.100 --> 00:14:57.100
<v Speaker 2>If it's virtual,</v>
<v Speaker 2>the agent will be an Avatar and the </v>

263
00:14:57.100 --> 00:14:57.290
<v Speaker 2>agent has some kind of goal that has </v>
<v Speaker 2>been given to,</v>

264
00:14:57.291 --> 00:15:00.020
<v Speaker 2>that is trying to achieve in that </v>
<v Speaker 2>environment.</v>

265
00:15:00.830 --> 00:15:03.680
<v Speaker 2>And the agent only interacts with the </v>
<v Speaker 2>environment in two ways.</v>

266
00:15:03.950 --> 00:15:06.380
<v Speaker 2>One is that it gets observations through</v>
<v Speaker 2>it.</v>

267
00:15:06.381 --> 00:15:11.381
<v Speaker 2>Sensory operators,</v>
<v Speaker 2>observations about the world and we </v>

268
00:15:11.381 --> 00:15:14.531
<v Speaker 2>mostly use vision at the moment,</v>
<v Speaker 2>but we're also looking to use other </v>

269
00:15:14.531 --> 00:15:14.531
<v Speaker 2>sensory modalities soon.</v>

270
00:15:14.540 --> 00:15:17.960
<v Speaker 2>And those observations are always </v>
<v Speaker 2>incomplete and noisy.</v>

271
00:15:18.290 --> 00:15:20.540
<v Speaker 2>So you never get full information about </v>
<v Speaker 2>the world,</v>

272
00:15:20.570 --> 00:15:24.310
<v Speaker 2>unlike say a game of chess where it's a </v>
<v Speaker 2>perfect state information.</v>

273
00:15:24.320 --> 00:15:26.930
<v Speaker 2>You see everything that's in the game </v>
<v Speaker 2>world,</v>

274
00:15:27.140 --> 00:15:27.770
<v Speaker 2>uh,</v>
<v Speaker 2>in,</v>

275
00:15:27.771 --> 00:15:29.120
<v Speaker 2>in the real world.</v>
<v Speaker 2>Of course,</v>

276
00:15:29.780 --> 00:15:34.780
<v Speaker 2>you don't get to see all the information</v>
<v Speaker 2>and that one of the jobs of the agent </v>

277
00:15:34.780 --> 00:15:38.951
<v Speaker 2>system is to build a,</v>
<v Speaker 2>as accurate a model as possible of the </v>

278
00:15:38.951 --> 00:15:41.810
<v Speaker 2>environment out there based solely on </v>
<v Speaker 2>these noisy,</v>

279
00:15:41.870 --> 00:15:46.870
<v Speaker 2>incomplete observations.</v>
<v Speaker 2>And the agent is doing this in real </v>

280
00:15:46.870 --> 00:15:46.870
<v Speaker 2>time.</v>
<v Speaker 2>These,</v>

281
00:15:46.870 --> 00:15:49.030
<v Speaker 2>these observations are coming in every </v>
<v Speaker 2>time step and it's,</v>

282
00:15:49.080 --> 00:15:53.510
<v Speaker 2>and the agent is continually updating </v>
<v Speaker 2>its model of the world based on this new</v>

283
00:15:53.511 --> 00:15:58.511
<v Speaker 2>evidence that it gets.</v>
<v Speaker 2>And the second job of the agent is to </v>

284
00:15:58.511 --> 00:16:02.681
<v Speaker 2>then pick a what action it should take,</v>
<v Speaker 2>what's the best action it can take in </v>

285
00:16:02.691 --> 00:16:05.420
<v Speaker 2>that particular moment in time that will</v>
<v Speaker 2>guess best,</v>

286
00:16:05.421 --> 00:16:07.270
<v Speaker 2>get it towards its goal,</v>
<v Speaker 2>um,</v>

287
00:16:07.730 --> 00:16:09.980
<v Speaker 2>from the current situation that it finds</v>
<v Speaker 2>itself in.</v>

288
00:16:10.370 --> 00:16:12.530
<v Speaker 2>And once it's decided what the actions </v>
<v Speaker 2>should be,</v>

289
00:16:12.610 --> 00:16:15.110
<v Speaker 2>an outpost that action action gets </v>
<v Speaker 2>executed,</v>

290
00:16:15.260 --> 00:16:17.600
<v Speaker 2>and that then may drive a change in the </v>
<v Speaker 2>environment,</v>

291
00:16:17.601 --> 00:16:21.680
<v Speaker 2>which will then drive a new observation.</v>
<v Speaker 2>And this goes round in a,</v>

292
00:16:21.681 --> 00:16:23.570
<v Speaker 2>um,</v>
<v Speaker 2>endless sort of cycle.</v>

293
00:16:24.950 --> 00:16:29.390
<v Speaker 2>Now this diagram is a very simple to </v>
<v Speaker 2>sort of explain,</v>

294
00:16:29.590 --> 00:16:32.090
<v Speaker 2>actually hides an incredible amount of </v>
<v Speaker 2>complexity.</v>

295
00:16:32.300 --> 00:16:36.650
<v Speaker 2>So we know that if you could solve all </v>
<v Speaker 2>the problems behind the,</v>

296
00:16:36.651 --> 00:16:38.360
<v Speaker 2>um,</v>
<v Speaker 2>the underlie this diagram,</v>

297
00:16:38.540 --> 00:16:43.540
<v Speaker 2>this representation,</v>
<v Speaker 2>then that will be enough for true </v>

298
00:16:43.540 --> 00:16:45.860
<v Speaker 2>artificial intelligence.</v>
<v Speaker 2>And we know that because this is the way</v>

299
00:16:45.861 --> 00:16:47.990
<v Speaker 2>that biological systems learn,</v>
<v Speaker 2>um,</v>

300
00:16:48.080 --> 00:16:50.770
<v Speaker 2>including humans and most mammals.</v>
<v Speaker 2>Um,</v>

301
00:16:51.020 --> 00:16:56.020
<v Speaker 2>and in fact in humans is the dopamine </v>
<v Speaker 2>system that implements a form of </v>

302
00:16:56.020 --> 00:16:56.270
<v Speaker 2>reinforcement learning.</v>

303
00:16:58.850 --> 00:17:00.520
<v Speaker 2>So we go,</v>
<v Speaker 2>we went onto,</v>

304
00:17:00.560 --> 00:17:02.540
<v Speaker 2>um,</v>
<v Speaker 2>test these kinds of systems,</v>

305
00:17:02.680 --> 00:17:07.680
<v Speaker 2>um,</v>
<v Speaker 2>and actually we chose to test the </v>

306
00:17:07.680 --> 00:17:10.061
<v Speaker 2>intelligence of our systems.</v>
<v Speaker 2>I'm on computer games now,</v>

307
00:17:10.850 --> 00:17:13.080
<v Speaker 2>a true thinking machine,</v>
<v Speaker 2>uh,</v>

308
00:17:13.100 --> 00:17:17.240
<v Speaker 2>we believe would have to be embedded in </v>
<v Speaker 2>a sensory motor data stream.</v>

309
00:17:17.480 --> 00:17:22.480
<v Speaker 2>Um,</v>
<v Speaker 2>you can't have true intelligence and </v>

310
00:17:22.480 --> 00:17:25.361
<v Speaker 2>true thinking unless you have the </v>
<v Speaker 2>ability to affect the world that you're </v>

311
00:17:25.361 --> 00:17:26.600
<v Speaker 2>in.</v>
<v Speaker 2>And the ability to sense that world.</v>

312
00:17:27.020 --> 00:17:29.110
<v Speaker 2>And uh,</v>
<v Speaker 2>and so usually the,</v>

313
00:17:29.120 --> 00:17:31.810
<v Speaker 2>so this is called embodied cognition and</v>
<v Speaker 2>um,</v>

314
00:17:31.820 --> 00:17:34.640
<v Speaker 2>usually when people subscribe to this </v>
<v Speaker 2>view of Ai,</v>

315
00:17:34.850 --> 00:17:37.910
<v Speaker 2>they normally start working on robots,</v>
<v Speaker 2>will robots.</v>

316
00:17:38.030 --> 00:17:41.120
<v Speaker 2>I'm based in obviously in real world </v>
<v Speaker 2>environments,</v>

317
00:17:41.930 --> 00:17:44.750
<v Speaker 2>but robots are very tricky to use.</v>
<v Speaker 2>They're very expensive.</v>

318
00:17:44.870 --> 00:17:49.870
<v Speaker 2>They're very slow and they break down.</v>
<v Speaker 2>So if you talk to anyone who's who's </v>

319
00:17:49.870 --> 00:17:52.050
<v Speaker 2>used or to try to develop robots,</v>
<v Speaker 2>your,</v>

320
00:17:52.070 --> 00:17:57.070
<v Speaker 2>your hair,</v>
<v Speaker 2>a lot of the work actually goes into </v>

321
00:17:57.070 --> 00:17:59.310
<v Speaker 2>fixing the mechanics of the robot,</v>
<v Speaker 2>the motors and the sensors and so on.</v>

322
00:17:59.490 --> 00:18:01.500
<v Speaker 2>And actually we didn't want to be </v>
<v Speaker 2>distracted by that.</v>

323
00:18:01.501 --> 00:18:04.920
<v Speaker 2>We wanted to focus on the intelligence </v>
<v Speaker 2>algorithms themselves.</v>

324
00:18:05.760 --> 00:18:10.020
<v Speaker 2>So what we decided to use was video </v>
<v Speaker 2>games in the first instance.</v>

325
00:18:10.260 --> 00:18:15.260
<v Speaker 2>And of course it's a little bit to do </v>
<v Speaker 2>with my background where it came in </v>

326
00:18:15.260 --> 00:18:15.350
<v Speaker 2>useful here in video games,</v>
<v Speaker 2>um,</v>

327
00:18:15.540 --> 00:18:20.540
<v Speaker 2>and use it.</v>
<v Speaker 2>And we purpose the games as a platform </v>

328
00:18:20.540 --> 00:18:23.490
<v Speaker 2>for testing the intelligence and the </v>
<v Speaker 2>capabilities of our Ai Algorithms.</v>

329
00:18:24.710 --> 00:18:29.210
<v Speaker 2>Now Games are really good because </v>
<v Speaker 2>obviously you can run them in the cloud,</v>

330
00:18:29.300 --> 00:18:32.000
<v Speaker 2>you can run them much faster than real </v>
<v Speaker 2>time,</v>

331
00:18:32.570 --> 00:18:35.060
<v Speaker 2>you can run millions of experiments in </v>
<v Speaker 2>parallel,</v>

332
00:18:35.250 --> 00:18:40.250
<v Speaker 2>um,</v>
<v Speaker 2>and it's very easy to measure progress </v>

333
00:18:40.250 --> 00:18:41.780
<v Speaker 2>because most games fortunately have game</v>
<v Speaker 2>scores,</v>

334
00:18:41.870 --> 00:18:46.870
<v Speaker 2>so you can see very conveniently if your</v>
<v Speaker 2>algorithmic tweaks are gaining you an </v>

335
00:18:47.091 --> 00:18:52.091
<v Speaker 2>advantage and whether you're heading in </v>
<v Speaker 2>the right direction based on the </v>

336
00:18:52.091 --> 00:18:56.321
<v Speaker 2>performance in those environments.</v>
<v Speaker 2>And that's something that's very </v>

337
00:18:56.321 --> 00:18:59.741
<v Speaker 2>important,</v>
<v Speaker 2>especially for a very long time mission </v>

338
00:18:59.741 --> 00:18:59.741
<v Speaker 2>like we have,</v>
<v Speaker 2>um,</v>

339
00:18:59.741 --> 00:19:02.000
<v Speaker 2>and very ambitious mission is to be able</v>
<v Speaker 2>to break down a,</v>

340
00:19:02.040 --> 00:19:07.040
<v Speaker 2>an ambitious mission into smaller chunks</v>
<v Speaker 2>that are very easy to measure the </v>

341
00:19:07.040 --> 00:19:07.610
<v Speaker 2>progress on.</v>

342
00:19:09.490 --> 00:19:14.490
<v Speaker 2>The other key thing about games is that </v>
<v Speaker 2>obviously they were designed by other </v>

343
00:19:14.490 --> 00:19:18.301
<v Speaker 2>people and other other engineering teams</v>
<v Speaker 2>and they weren't designed specifically </v>

344
00:19:18.301 --> 00:19:20.020
<v Speaker 2>for ai testing.</v>
<v Speaker 2>And uh,</v>

345
00:19:20.021 --> 00:19:25.021
<v Speaker 2>so what that means is that you have to </v>
<v Speaker 2>deal with all kinds of interesting </v>

346
00:19:25.021 --> 00:19:27.841
<v Speaker 2>problems that you would never have dealt</v>
<v Speaker 2>with a designed yourself as an ai </v>

347
00:19:27.841 --> 00:19:28.990
<v Speaker 2>designer.</v>
<v Speaker 2>Um,</v>

348
00:19:29.050 --> 00:19:34.050
<v Speaker 2>and I think that's actually makes sure </v>
<v Speaker 2>that there isn't any bias in the types </v>

349
00:19:34.050 --> 00:19:38.461
<v Speaker 2>of problems that you apply your ai to.</v>
<v Speaker 2>So one of the big problems of in ai </v>

350
00:19:38.461 --> 00:19:41.020
<v Speaker 2>research that has been over the last few</v>
<v Speaker 2>decades is that generally speaking,</v>

351
00:19:41.140 --> 00:19:46.140
<v Speaker 2>is the ai designers that also designed </v>
<v Speaker 2>the problems are and subconsciously </v>

352
00:19:46.140 --> 00:19:51.001
<v Speaker 2>whether you like it or not,</v>
<v Speaker 2>you end up designing problems that you </v>

353
00:19:51.001 --> 00:19:51.310
<v Speaker 2>know,</v>
<v Speaker 2>your air go isms are well suited to.</v>

354
00:19:53.340 --> 00:19:58.340
<v Speaker 2>So what we started off with was actually</v>
<v Speaker 2>Atari Games from the eighties,</v>

355
00:19:58.500 --> 00:20:03.500
<v Speaker 2>which were really the first iconic </v>
<v Speaker 2>platform that had a lot of very popular </v>

356
00:20:03.570 --> 00:20:06.690
<v Speaker 2>challenging games on it and we decided </v>
<v Speaker 2>to start with that.</v>

357
00:20:06.890 --> 00:20:10.920
<v Speaker 2>And what we did is we started with an </v>
<v Speaker 2>open source emulator for Atari Games and</v>

358
00:20:10.921 --> 00:20:11.670
<v Speaker 2>we,</v>
<v Speaker 2>um,</v>

359
00:20:11.910 --> 00:20:16.910
<v Speaker 2>uh,</v>
<v Speaker 2>a souped it up and made it more robust </v>

360
00:20:16.910 --> 00:20:19.551
<v Speaker 2>and made it run faster.</v>
<v Speaker 2>And then we plugged it in our ai </v>

361
00:20:19.551 --> 00:20:19.551
<v Speaker 2>algorithms into the system.</v>

362
00:20:19.970 --> 00:20:24.970
<v Speaker 2>Now I'm going to show you a couple of </v>
<v Speaker 2>videos of the AI system working and </v>

363
00:20:24.970 --> 00:20:25.490
<v Speaker 2>then.</v>
<v Speaker 2>But before I do that,</v>

364
00:20:25.491 --> 00:20:28.460
<v Speaker 2>I always wanted to explain to you what </v>
<v Speaker 2>it is you're going to see.</v>

365
00:20:29.600 --> 00:20:34.130
<v Speaker 2>So the AI system here,</v>
<v Speaker 2>I'm only gets the raw pixels as inputs,</v>

366
00:20:34.280 --> 00:20:37.160
<v Speaker 2>so it's almost as if we'd set up a video</v>
<v Speaker 2>camera,</v>

367
00:20:37.310 --> 00:20:39.770
<v Speaker 2>a observing the screen,</v>
<v Speaker 2>and I'm,</v>

368
00:20:39.830 --> 00:20:44.830
<v Speaker 2>the only information that he gets is the</v>
<v Speaker 2>raw pixels so it doesn't know anything </v>

369
00:20:44.830 --> 00:20:44.830
<v Speaker 2>about,</v>
<v Speaker 2>uh,</v>

370
00:20:44.830 --> 00:20:48.100
<v Speaker 2>what it's controlling.</v>
<v Speaker 2>It doesn't know what the of the game is.</v>

371
00:20:48.220 --> 00:20:53.220
<v Speaker 2>Um,</v>
<v Speaker 2>it doesn't know how to get points and </v>

372
00:20:53.220 --> 00:20:55.610
<v Speaker 2>all it's been told is that it needs to,</v>
<v Speaker 2>it's goal is to maximize the score and </v>

373
00:20:55.610 --> 00:21:00.180
<v Speaker 2>everything else is learned from scratch.</v>
<v Speaker 2>And then there's a sort of generality </v>

374
00:21:02.050 --> 00:21:07.050
<v Speaker 2>component comes in again where we </v>
<v Speaker 2>require a single system to play all the </v>

375
00:21:07.050 --> 00:21:11.241
<v Speaker 2>different games out of the box.</v>
<v Speaker 2>And there's obviously dozens and dozens </v>

376
00:21:11.241 --> 00:21:12.390
<v Speaker 2>of very different Atari Games.</v>

377
00:21:13.390 --> 00:21:13.820
<v Speaker 3>Okay.</v>

378
00:21:13.930 --> 00:21:15.780
<v Speaker 2>So the first thing you're going to show </v>
<v Speaker 2>you is space invaders,</v>

379
00:21:15.790 --> 00:21:18.450
<v Speaker 2>probably the most iconic game that </v>
<v Speaker 2>they're,</v>

380
00:21:18.451 --> 00:21:19.510
<v Speaker 2>you know,</v>
<v Speaker 2>there's ever been.</v>

381
00:21:19.780 --> 00:21:23.560
<v Speaker 2>And I'm going to show you sort of two </v>
<v Speaker 2>parts of this video.</v>

382
00:21:23.760 --> 00:21:24.830
<v Speaker 2>Um,</v>
<v Speaker 2>so in the beginning,</v>

383
00:21:24.831 --> 00:21:29.831
<v Speaker 2>as I roll the video now you know,</v>
<v Speaker 2>you'll see what the agent looks like </v>

384
00:21:29.831 --> 00:21:31.480
<v Speaker 2>when it first encounters this </v>
<v Speaker 2>environment.</v>

385
00:21:31.650 --> 00:21:36.650
<v Speaker 2>Now,</v>
<v Speaker 2>as controlling the rocket at the bottom </v>

386
00:21:36.650 --> 00:21:38.101
<v Speaker 2>of this screen,</v>
<v Speaker 2>obviously it's trying actions randomly </v>

387
00:21:38.101 --> 00:21:40.951
<v Speaker 2>because it has no idea what it's </v>
<v Speaker 2>supposed to be doing and it loses its </v>

388
00:21:40.951 --> 00:21:41.770
<v Speaker 2>three lives almost immediately.</v>
<v Speaker 2>Now,</v>

389
00:21:41.771 --> 00:21:46.771
<v Speaker 2>if you leave the machine training </v>
<v Speaker 2>overnight and you come back the next </v>

390
00:21:46.771 --> 00:21:46.771
<v Speaker 2>day,</v>
<v Speaker 2>um,</v>

391
00:21:46.771 --> 00:21:48.290
<v Speaker 2>the,</v>
<v Speaker 2>the machine now is superhuman at,</v>

392
00:21:48.870 --> 00:21:49.950
<v Speaker 2>at the,</v>
<v Speaker 2>at the,</v>

393
00:21:50.010 --> 00:21:52.600
<v Speaker 2>at the game.</v>
<v Speaker 2>So every single shot it,</v>

394
00:21:52.660 --> 00:21:54.430
<v Speaker 2>it,</v>
<v Speaker 2>fires hit something,</v>

395
00:21:55.470 --> 00:21:57.290
<v Speaker 2>it can't be killed anymore.</v>
<v Speaker 2>Um,</v>

396
00:21:57.310 --> 00:21:59.520
<v Speaker 2>it's,</v>
<v Speaker 2>it's worked out that the pink mothership</v>

397
00:21:59.530 --> 00:22:04.530
<v Speaker 2>of the top of the screen is worth a lot </v>
<v Speaker 2>of points that does these amazing </v>

398
00:22:04.530 --> 00:22:04.810
<v Speaker 2>accurate shots.</v>

399
00:22:05.050 --> 00:22:07.810
<v Speaker 2>And you can see that the model is built </v>
<v Speaker 2>of the world is,</v>

400
00:22:07.860 --> 00:22:11.530
<v Speaker 2>is extremely accurate.</v>
<v Speaker 2>So those you play space invaders back in</v>

401
00:22:11.531 --> 00:22:13.000
<v Speaker 2>the eighties wall,</v>
<v Speaker 2>remember that the,</v>

402
00:22:13.020 --> 00:22:13.460
<v Speaker 2>the,</v>
<v Speaker 2>the,</v>

403
00:22:13.480 --> 00:22:14.920
<v Speaker 2>as there's less of them,</v>
<v Speaker 2>they get faster.</v>

404
00:22:14.921 --> 00:22:19.921
<v Speaker 2>If you just watched the last shot,</v>
<v Speaker 2>you'll see that they sort of predicted </v>

405
00:22:19.921 --> 00:22:20.020
<v Speaker 2>where,</v>
<v Speaker 2>um,</v>

406
00:22:20.050 --> 00:22:25.050
<v Speaker 2>where that is going to wear that term.</v>
<v Speaker 2>Space invaders going to end up and far </v>

407
00:22:25.050 --> 00:22:28.951
<v Speaker 2>as the shortest shots ahead of time.</v>
<v Speaker 2>So I'm going to show you a second video </v>

408
00:22:28.951 --> 00:22:30.460
<v Speaker 2>now,</v>
<v Speaker 2>which is the game of breakout.</v>

409
00:22:30.580 --> 00:22:34.360
<v Speaker 2>It's my favorite video where they show a</v>
<v Speaker 2>few more gradations of the agent getting</v>

410
00:22:34.361 --> 00:22:36.600
<v Speaker 2>better and more capable.</v>
<v Speaker 2>Um,</v>

411
00:22:36.601 --> 00:22:39.160
<v Speaker 2>so in this game,</v>
<v Speaker 2>the agent is controlling the,</v>

412
00:22:39.180 --> 00:22:40.870
<v Speaker 2>the,</v>
<v Speaker 2>the pink bat and ball.</v>

413
00:22:41.020 --> 00:22:44.860
<v Speaker 2>And the aim of the game is to break </v>
<v Speaker 2>through this rainbow colored brick wall,</v>

414
00:22:44.920 --> 00:22:45.700
<v Speaker 2>brick by brick.</v>

415
00:22:47.120 --> 00:22:49.220
<v Speaker 2>So to start off with,</v>
<v Speaker 2>after 100 games,</v>

416
00:22:49.430 --> 00:22:50.580
<v Speaker 2>um,</v>
<v Speaker 2>the,</v>

417
00:22:50.610 --> 00:22:52.730
<v Speaker 2>the AI system has,</v>
<v Speaker 2>you know,</v>

418
00:22:52.731 --> 00:22:57.731
<v Speaker 2>it's not very good.</v>
<v Speaker 2>You can see it's missing the ball most </v>

419
00:22:57.731 --> 00:23:00.161
<v Speaker 2>of the time,</v>
<v Speaker 2>but you can see maybe you can convince </v>

420
00:23:00.161 --> 00:23:02.201
<v Speaker 2>yourself.</v>
<v Speaker 2>It's starting to get the hang of the </v>

421
00:23:02.201 --> 00:23:02.201
<v Speaker 2>idea that it should be moving the bat </v>
<v Speaker 2>towards the ball.</v>

422
00:23:02.201 --> 00:23:03.530
<v Speaker 2>Now,</v>
<v Speaker 2>after 300 games,</v>

423
00:23:04.060 --> 00:23:09.060
<v Speaker 2>you can see that the,</v>
<v Speaker 2>the system has now got pretty much as </v>

424
00:23:09.060 --> 00:23:12.431
<v Speaker 2>good as any human complainants and </v>
<v Speaker 2>almost always gets the ball back even </v>

425
00:23:12.431 --> 00:23:13.880
<v Speaker 2>when it's coming back at very vertical </v>
<v Speaker 2>angles.</v>

426
00:23:14.240 --> 00:23:16.130
<v Speaker 2>So we thought that was pretty cool,</v>
<v Speaker 2>but we thought,</v>

427
00:23:16.131 --> 00:23:21.131
<v Speaker 2>well,</v>
<v Speaker 2>what would happen if we left the agent </v>

428
00:23:21.131 --> 00:23:21.890
<v Speaker 2>running for longer and playdoh another </v>
<v Speaker 2>200 games?</v>

429
00:23:22.010 --> 00:23:27.010
<v Speaker 2>And then this unexpected thing happened,</v>
<v Speaker 2>it discovered the optimal strategy was </v>

430
00:23:27.010 --> 00:23:30.371
<v Speaker 2>to dig a tunnel around the site and send</v>
<v Speaker 2>the ball around the back of the wall.</v>

431
00:23:30.890 --> 00:23:31.870
<v Speaker 2>And um,</v>
<v Speaker 2>you know,</v>

432
00:23:32.000 --> 00:23:37.000
<v Speaker 2>it's doing that again with sort of super</v>
<v Speaker 2>human accuracy in terms of the motor </v>

433
00:23:37.000 --> 00:23:38.700
<v Speaker 2>control then and strategy.</v>
<v Speaker 2>I wonder,</v>

434
00:23:38.730 --> 00:23:42.110
<v Speaker 2>the funny things is,</v>
<v Speaker 2>is that although the researchers on that</v>

435
00:23:42.240 --> 00:23:45.170
<v Speaker 2>are amazing,</v>
<v Speaker 2>programmers and engineers,</v>

436
00:23:45.930 --> 00:23:49.700
<v Speaker 2>they're not so good at playing Atari </v>
<v Speaker 2>Games so they didn't actually know about</v>

437
00:23:49.701 --> 00:23:51.100
<v Speaker 2>that strategy.</v>
<v Speaker 2>So it's,</v>

438
00:23:51.110 --> 00:23:51.710
<v Speaker 2>I think,</v>
<v Speaker 2>you know,</v>

439
00:23:51.711 --> 00:23:56.711
<v Speaker 2>an example of a system that you've </v>
<v Speaker 2>created actually teaching you something </v>

440
00:23:56.711 --> 00:23:58.790
<v Speaker 2>which is quite an a watershed moment for</v>
<v Speaker 2>us.</v>

441
00:23:59.510 --> 00:24:01.450
<v Speaker 2>So efficient in that work.</v>
<v Speaker 2>Uh,</v>

442
00:24:01.490 --> 00:24:06.490
<v Speaker 2>we,</v>
<v Speaker 2>this was then fully published in nature </v>

443
00:24:06.490 --> 00:24:09.221
<v Speaker 2>and the front cover earlier this year </v>
<v Speaker 2>and we actually even released the code </v>

444
00:24:09.231 --> 00:24:10.130
<v Speaker 2>as well.</v>
<v Speaker 2>So you can,</v>

445
00:24:10.220 --> 00:24:12.290
<v Speaker 2>you can have a look at that and play </v>
<v Speaker 2>with that yourselves.</v>

446
00:24:12.770 --> 00:24:16.490
<v Speaker 2>Um,</v>
<v Speaker 2>so now we're moving onto three d games,</v>

447
00:24:17.090 --> 00:24:21.650
<v Speaker 2>go a robot simulators and of course we </v>
<v Speaker 2>are interested in robots,</v>

448
00:24:21.770 --> 00:24:25.460
<v Speaker 2>but as a developed as a sort of </v>
<v Speaker 2>application rather than as a development</v>

449
00:24:25.670 --> 00:24:26.210
<v Speaker 2>platform.</v>

450
00:24:27.500 --> 00:24:30.500
<v Speaker 2>Now I'll just show you one thing on the,</v>
<v Speaker 2>a three d stuff,</v>

451
00:24:30.740 --> 00:24:32.540
<v Speaker 2>um,</v>
<v Speaker 2>so we'll have a lot more announcements,</v>

452
00:24:32.541 --> 00:24:35.000
<v Speaker 2>new announcements to make her in the </v>
<v Speaker 2>next year.</v>

453
00:24:35.240 --> 00:24:36.170
<v Speaker 2>Um,</v>
<v Speaker 2>but we,</v>

454
00:24:36.171 --> 00:24:41.171
<v Speaker 2>we,</v>
<v Speaker 2>I'll show this sort of run this little </v>

455
00:24:41.171 --> 00:24:41.171
<v Speaker 2>video of,</v>
<v Speaker 2>um,</v>

456
00:24:41.171 --> 00:24:43.930
<v Speaker 2>the same agent that you saw playing the </v>
<v Speaker 2>Atari Games actually now driving a </v>

457
00:24:43.930 --> 00:24:46.070
<v Speaker 2>racing car around the track in a three d</v>
<v Speaker 2>game.</v>

458
00:24:46.490 --> 00:24:47.210
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

459
00:24:47.211 --> 00:24:50.120
<v Speaker 2>again,</v>
<v Speaker 2>the only inputs here are the pixels,</v>

460
00:24:50.121 --> 00:24:54.020
<v Speaker 2>the raw pixels and the steering wheel </v>
<v Speaker 2>controls and um,</v>

461
00:24:54.050 --> 00:24:57.560
<v Speaker 2>it's learned just from your experience </v>
<v Speaker 2>driving the car around how to drive,</v>

462
00:24:57.730 --> 00:25:02.730
<v Speaker 2>um,</v>
<v Speaker 2>and even do things like it's overtaking </v>

463
00:25:02.730 --> 00:25:03.020
<v Speaker 2>the other cars that sort of 200 </v>
<v Speaker 2>kilometers an hour.</v>

464
00:25:03.320 --> 00:25:04.460
<v Speaker 2>Um,</v>
<v Speaker 2>and again,</v>

465
00:25:04.461 --> 00:25:09.461
<v Speaker 2>just from the raw pixel data.</v>
<v Speaker 2>So we're now moving towards much more </v>

466
00:25:09.891 --> 00:25:13.460
<v Speaker 2>advanced three d environments where </v>
<v Speaker 2>we're looking at May's problems,</v>

467
00:25:13.630 --> 00:25:14.360
<v Speaker 2>uh,</v>
<v Speaker 2>and,</v>

468
00:25:14.361 --> 00:25:15.230
<v Speaker 2>uh,</v>
<v Speaker 2>all kinds of,</v>

469
00:25:15.260 --> 00:25:16.750
<v Speaker 2>a much more complex,</v>
<v Speaker 2>uh,</v>

470
00:25:16.810 --> 00:25:18.230
<v Speaker 2>a path finding problems.</v>

471
00:25:19.490 --> 00:25:24.490
<v Speaker 2>Now,</v>
<v Speaker 2>I spoke about neuroscience at the </v>

472
00:25:24.490 --> 00:25:25.340
<v Speaker 2>beginning of the talk and just want to </v>
<v Speaker 2>come back and touch on that now.</v>

473
00:25:25.341 --> 00:25:27.270
<v Speaker 2>So we talk a lot about,</v>
<v Speaker 2>um,</v>

474
00:25:27.380 --> 00:25:32.380
<v Speaker 2>the Ai that we build it.</v>
<v Speaker 2>The mind has been neuroscience inspired </v>

475
00:25:32.380 --> 00:25:35.800
<v Speaker 2>and in fact,</v>
<v Speaker 2>many of the other research areas that </v>

476
00:25:35.800 --> 00:25:38.201
<v Speaker 2>we're looking at now,</v>
<v Speaker 2>we're looking to neuroscience very </v>

477
00:25:38.201 --> 00:25:38.350
<v Speaker 2>closely for inspiration about,</v>
<v Speaker 2>um,</v>

478
00:25:38.590 --> 00:25:40.280
<v Speaker 2>uh,</v>
<v Speaker 2>for new types of algorithms,</v>

479
00:25:40.460 --> 00:25:42.110
<v Speaker 2>uh,</v>
<v Speaker 2>as to how the brain works.</v>

480
00:25:42.350 --> 00:25:44.720
<v Speaker 2>So we're looking at memory,</v>
<v Speaker 2>attention,</v>

481
00:25:44.840 --> 00:25:49.310
<v Speaker 2>concepts,</v>
<v Speaker 2>planning a navigation and imagination.</v>

482
00:25:50.570 --> 00:25:52.010
<v Speaker 2>Now because this is a,</v>
<v Speaker 2>you know,</v>

483
00:25:52.011 --> 00:25:55.120
<v Speaker 2>each one of those areas we'd probably </v>
<v Speaker 2>need a whole talk to,</v>

484
00:25:55.150 --> 00:26:00.150
<v Speaker 2>to sort of get into.</v>
<v Speaker 2>So I'm just going to focus on </v>

485
00:26:00.150 --> 00:26:00.770
<v Speaker 2>imagination because I think that's most </v>
<v Speaker 2>relevant for the audience here.</v>

486
00:26:01.070 --> 00:26:03.440
<v Speaker 2>Um,</v>
<v Speaker 2>and it's also what I did for my phd.</v>

487
00:26:03.980 --> 00:26:08.980
<v Speaker 2>Now it turns out the imagination is </v>
<v Speaker 2>quite dependent on an area of the brain </v>

488
00:26:08.980 --> 00:26:10.250
<v Speaker 2>called the hippocampus,</v>
<v Speaker 2>which is actually here,</v>

489
00:26:10.340 --> 00:26:14.150
<v Speaker 2>this area and pink hair at the center of</v>
<v Speaker 2>your brain in this,</v>

490
00:26:14.210 --> 00:26:15.800
<v Speaker 2>um,</v>
<v Speaker 2>in this diagram of,</v>

491
00:26:15.830 --> 00:26:16.670
<v Speaker 2>of the human brain.</v>

492
00:26:17.780 --> 00:26:19.970
<v Speaker 2>Now the hippocampus,</v>
<v Speaker 2>it's very important,</v>

493
00:26:19.971 --> 00:26:22.100
<v Speaker 2>right?</v>
<v Speaker 2>It's quite a small part of the brain,</v>

494
00:26:22.250 --> 00:26:27.250
<v Speaker 2>a small brain region,</v>
<v Speaker 2>but it's very critical problem brain </v>

495
00:26:27.250 --> 00:26:27.530
<v Speaker 2>region and it's been known for,</v>
<v Speaker 2>you know,</v>

496
00:26:27.770 --> 00:26:31.400
<v Speaker 2>more than 50 years now that if you </v>
<v Speaker 2>damage the hippocampus,</v>

497
00:26:31.600 --> 00:26:33.680
<v Speaker 2>um,</v>
<v Speaker 2>then you um,</v>

498
00:26:33.681 --> 00:26:38.681
<v Speaker 2>how you become amnesic.</v>
<v Speaker 2>So it's well known that the hippocampus </v>

499
00:26:38.681 --> 00:26:42.230
<v Speaker 2>is vital for episodic memory.</v>
<v Speaker 2>But what wasn't known was,</v>

500
00:26:42.290 --> 00:26:44.640
<v Speaker 2>what else was the hippocampus useful </v>
<v Speaker 2>for?</v>

501
00:26:44.800 --> 00:26:45.960
<v Speaker 2>Um,</v>
<v Speaker 2>for example,</v>

502
00:26:46.020 --> 00:26:51.020
<v Speaker 2>was it involved with imagination now?</v>
<v Speaker 2>I suspected that it might be because </v>

503
00:26:53.250 --> 00:26:57.060
<v Speaker 2>when I started reading the literature on</v>
<v Speaker 2>memory and hippocampus when I started my</v>

504
00:26:57.061 --> 00:27:02.061
<v Speaker 2>phd,</v>
<v Speaker 2>I sort of came across this literature </v>

505
00:27:02.061 --> 00:27:04.521
<v Speaker 2>that was talking about memory as being a</v>
<v Speaker 2>reconstructive process rather than like </v>

506
00:27:04.561 --> 00:27:06.780
<v Speaker 2>something like a video tape.</v>
<v Speaker 2>So,</v>

507
00:27:06.781 --> 00:27:11.781
<v Speaker 2>uh,</v>
<v Speaker 2>and that's actually the way that memory </v>

508
00:27:11.781 --> 00:27:11.781
<v Speaker 2>works when you,</v>
<v Speaker 2>if you remember this lecture tomorrow,</v>

509
00:27:11.781 --> 00:27:12.930
<v Speaker 2>it won't,</v>
<v Speaker 2>it's not kind of like a store,</v>

510
00:27:12.931 --> 00:27:14.910
<v Speaker 2>like a video tape somewhere in your </v>
<v Speaker 2>mind.</v>

511
00:27:15.120 --> 00:27:20.120
<v Speaker 2>Actually,</v>
<v Speaker 2>you will be combining it from all sorts </v>

512
00:27:20.120 --> 00:27:20.250
<v Speaker 2>of components of things and experiences </v>
<v Speaker 2>that you've had before.</v>

513
00:27:20.251 --> 00:27:25.251
<v Speaker 2>Other lectures,</v>
<v Speaker 2>perhaps other visits to the British </v>

514
00:27:25.251 --> 00:27:27.510
<v Speaker 2>Museum as well as specific pieces of </v>
<v Speaker 2>content that are to do with this evening</v>

515
00:27:27.511 --> 00:27:32.511
<v Speaker 2>specifically,</v>
<v Speaker 2>and what your brain does in the </v>

516
00:27:32.511 --> 00:27:32.511
<v Speaker 2>hippocampus is always is reconstructing </v>
<v Speaker 2>that,</v>

517
00:27:32.511 --> 00:27:34.650
<v Speaker 2>pulling all those parts together into a </v>
<v Speaker 2>coherent whole,</v>

518
00:27:34.770 --> 00:27:39.770
<v Speaker 2>which then is recognized by the rest of </v>
<v Speaker 2>your brain as a actually an episodic </v>

519
00:27:39.770 --> 00:27:40.740
<v Speaker 2>memory.</v>
<v Speaker 2>So I was thinking,</v>

520
00:27:40.741 --> 00:27:45.741
<v Speaker 2>well,</v>
<v Speaker 2>if memory works as a reconstructive </v>

521
00:27:45.741 --> 00:27:47.751
<v Speaker 2>process,</v>
<v Speaker 2>then if we think about imagination as </v>

522
00:27:47.751 --> 00:27:51.381
<v Speaker 2>being a similar process,</v>
<v Speaker 2>but in this case is a constructive </v>

523
00:27:51.381 --> 00:27:54.020
<v Speaker 2>process.</v>
<v Speaker 2>If we think of memory as trying to put </v>

524
00:27:54.020 --> 00:27:57.261
<v Speaker 2>your components that you have together </v>
<v Speaker 2>in a way that your brain thinks looks </v>

525
00:27:57.261 --> 00:27:59.050
<v Speaker 2>and judges as familiar,</v>
<v Speaker 2>perhaps creativity's,</v>

526
00:27:59.070 --> 00:28:04.070
<v Speaker 2>that is the converse of that.</v>
<v Speaker 2>You're still bringing together those </v>

527
00:28:04.070 --> 00:28:06.651
<v Speaker 2>components,</v>
<v Speaker 2>but now you're trying to create </v>

528
00:28:06.651 --> 00:28:07.380
<v Speaker 2>something novel that actually your brain</v>
<v Speaker 2>judges as unfamiliar.</v>

529
00:28:08.010 --> 00:28:09.060
<v Speaker 2>Um,</v>
<v Speaker 2>so I was thinking,</v>

530
00:28:09.061 --> 00:28:14.061
<v Speaker 2>well,</v>
<v Speaker 2>if memory is heavily depend on the </v>

531
00:28:14.061 --> 00:28:16.071
<v Speaker 2>hippocampus,</v>
<v Speaker 2>then maybe imagination is also a very </v>

532
00:28:16.071 --> 00:28:19.050
<v Speaker 2>heavily dependent on the same brain </v>
<v Speaker 2>structure and the same processes.</v>

533
00:28:20.310 --> 00:28:23.490
<v Speaker 2>So the way we decided to test this was </v>
<v Speaker 2>actually by getting,</v>

534
00:28:23.670 --> 00:28:24.730
<v Speaker 2>um,</v>
<v Speaker 2>uh,</v>

535
00:28:24.870 --> 00:28:29.870
<v Speaker 2>going around the country to interview </v>
<v Speaker 2>patients who had damage to the </v>

536
00:28:30.301 --> 00:28:35.301
<v Speaker 2>hippocampus,</v>
<v Speaker 2>but only the hippocampus and there's </v>

537
00:28:35.301 --> 00:28:38.601
<v Speaker 2>very rare sorts of diseases that cause </v>
<v Speaker 2>that although things like Alzheimer's </v>

538
00:28:38.601 --> 00:28:41.730
<v Speaker 2>actually do attack the hippocampus,</v>
<v Speaker 2>but also other brain structures,</v>

539
00:28:41.880 --> 00:28:46.880
<v Speaker 2>but what we needed were patients that </v>
<v Speaker 2>had only specific damage only to this </v>

540
00:28:46.880 --> 00:28:50.721
<v Speaker 2>one brain region and we tested those </v>
<v Speaker 2>patients on their imaginative abilities </v>

541
00:28:50.820 --> 00:28:55.820
<v Speaker 2>rather than their episodic memory.</v>
<v Speaker 2>And what we did is gave them fairly a </v>

542
00:28:55.820 --> 00:28:57.480
<v Speaker 2>kind of simple,</v>
<v Speaker 2>imaginative task.</v>

543
00:28:57.730 --> 00:29:01.080
<v Speaker 2>We would give them a word cues like the </v>
<v Speaker 2>following.</v>

544
00:29:01.290 --> 00:29:04.680
<v Speaker 2>Imagine you're lying on a white sandy </v>
<v Speaker 2>beach in a beautiful tropical bay.</v>

545
00:29:04.920 --> 00:29:09.420
<v Speaker 2>Describe in as much detail as you can,</v>
<v Speaker 2>what you can see and hear and experience</v>

546
00:29:09.421 --> 00:29:12.060
<v Speaker 2>around you.</v>
<v Speaker 2>And what happened was,</v>

547
00:29:12.061 --> 00:29:15.480
<v Speaker 2>is when we compared and broke down their</v>
<v Speaker 2>descriptions,</v>

548
00:29:15.570 --> 00:29:20.570
<v Speaker 2>we scored it a in a very complex scoring</v>
<v Speaker 2>system to break that how rich that </v>

549
00:29:20.570 --> 00:29:25.311
<v Speaker 2>description was.</v>
<v Speaker 2>And we compared it to age and educated </v>

550
00:29:25.311 --> 00:29:29.220
<v Speaker 2>an ICU matched control subjects.</v>
<v Speaker 2>So they were actually in every way,</v>

551
00:29:29.221 --> 00:29:33.270
<v Speaker 2>except obviously they had intact and </v>
<v Speaker 2>healthy hipaa campuses.</v>

552
00:29:33.510 --> 00:29:35.240
<v Speaker 2>We found that,</v>
<v Speaker 2>um,</v>

553
00:29:35.410 --> 00:29:40.410
<v Speaker 2>on our richness measure experiential </v>
<v Speaker 2>index measure that the imagine scenes </v>

554
00:29:40.990 --> 00:29:45.990
<v Speaker 2>that be hippocampal patients with </v>
<v Speaker 2>describing what hugely impoverished </v>

555
00:29:45.990 --> 00:29:50.020
<v Speaker 2>compared to the healthy controls.</v>
<v Speaker 2>And you can see that in these two.</v>

556
00:29:50.110 --> 00:29:53.230
<v Speaker 2>Then if you can see this laser pointer </v>
<v Speaker 2>in these two bar charts.</v>

557
00:29:53.300 --> 00:29:56.230
<v Speaker 2>So on the left hand side here is the </v>
<v Speaker 2>patients,</v>

558
00:29:56.290 --> 00:30:01.290
<v Speaker 2>the five patients,</v>
<v Speaker 2>and then here are the 10 match controls </v>

559
00:30:01.290 --> 00:30:04.951
<v Speaker 2>to these patients.</v>
<v Speaker 2>And you can see this is the sort of </v>

560
00:30:04.951 --> 00:30:04.951
<v Speaker 2>richness index,</v>
<v Speaker 2>if you like,</v>

561
00:30:04.951 --> 00:30:09.810
<v Speaker 2>of the described seeing and you can see </v>
<v Speaker 2>that the patients are massively </v>

562
00:30:09.810 --> 00:30:11.950
<v Speaker 2>deficient compared to the,</v>
<v Speaker 2>um,</v>

563
00:30:12.100 --> 00:30:13.270
<v Speaker 2>to compare to the controls.</v>

564
00:30:14.860 --> 00:30:15.850
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

565
00:30:15.900 --> 00:30:20.900
<v Speaker 2>so it seems indeed that the hippocampus </v>
<v Speaker 2>is very important for imagining the </v>

566
00:30:20.900 --> 00:30:22.000
<v Speaker 2>future.</v>
<v Speaker 2>And,</v>

567
00:30:22.001 --> 00:30:27.001
<v Speaker 2>uh,</v>
<v Speaker 2>actually the new scientists reported on </v>

568
00:30:27.001 --> 00:30:27.001
<v Speaker 2>this,</v>
<v Speaker 2>uh,</v>

569
00:30:27.001 --> 00:30:27.001
<v Speaker 2>work,</v>
<v Speaker 2>uh,</v>

570
00:30:27.001 --> 00:30:27.490
<v Speaker 2>and it became quite a big study.</v>
<v Speaker 2>Um,</v>

571
00:30:27.700 --> 00:30:32.050
<v Speaker 2>that was also listed in sciences or as </v>
<v Speaker 2>one of the big breakthroughs with 2007.</v>

572
00:30:32.320 --> 00:30:37.320
<v Speaker 2>And the new sites has had quite a nice </v>
<v Speaker 2>headline talking about Hipaa camp or </v>

573
00:30:37.880 --> 00:30:41.050
<v Speaker 2>patients being stuck in the present.</v>
<v Speaker 2>So the idea was,</v>

574
00:30:41.080 --> 00:30:46.080
<v Speaker 2>you know,</v>
<v Speaker 2>they know they can't remember the past </v>

575
00:30:46.080 --> 00:30:46.840
<v Speaker 2>very well and now it turns out they </v>
<v Speaker 2>can't imagine the future either.</v>

576
00:30:47.050 --> 00:30:47.780
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

577
00:30:47.830 --> 00:30:49.240
<v Speaker 2>but yeah,</v>
<v Speaker 2>if you were to talk to them,</v>

578
00:30:49.360 --> 00:30:50.260
<v Speaker 2>they seem,</v>
<v Speaker 2>you know,</v>

579
00:30:50.290 --> 00:30:55.290
<v Speaker 2>for a few minutes they would seem </v>
<v Speaker 2>completely normal to you and you'd be </v>

580
00:30:55.290 --> 00:30:58.681
<v Speaker 2>able to converse with them completely </v>
<v Speaker 2>normally because they're processing the </v>

581
00:30:58.681 --> 00:31:02.071
<v Speaker 2>present.</v>
<v Speaker 2>I'm in the same way that a healthy </v>

582
00:31:02.071 --> 00:31:02.071
<v Speaker 2>person.</v>

583
00:31:02.071 --> 00:31:02.071
<v Speaker 3>What.</v>

584
00:31:02.071 --> 00:31:07.070
<v Speaker 2>So we then follow this up in Mri and we </v>
<v Speaker 2>found out of course the hippocampus </v>

585
00:31:07.070 --> 00:31:09.150
<v Speaker 2>doesn't support imagination on it's own.</v>
<v Speaker 2>It's part of a,</v>

586
00:31:09.151 --> 00:31:14.151
<v Speaker 2>it's a critical ct solar core part of a </v>
<v Speaker 2>much larger brain network that includes </v>

587
00:31:14.250 --> 00:31:18.660
<v Speaker 2>all sorts of other brain regions from </v>
<v Speaker 2>the been or to the medial frontal Cortex</v>

588
00:31:18.790 --> 00:31:23.790
<v Speaker 2>to the medial temporal lobe,</v>
<v Speaker 2>lateral temporal cortex and parietal </v>

589
00:31:23.790 --> 00:31:27.261
<v Speaker 2>cortex.</v>
<v Speaker 2>So all these regions reliably come on </v>

590
00:31:27.261 --> 00:31:30.741
<v Speaker 2>when you scan somebody in a brain </v>
<v Speaker 2>scanner and you'd get them to imagine </v>

591
00:31:30.741 --> 00:31:31.350
<v Speaker 2>scenes.</v>
<v Speaker 2>Um,</v>

592
00:31:31.380 --> 00:31:32.020
<v Speaker 2>and,</v>
<v Speaker 2>and the,</v>

593
00:31:32.040 --> 00:31:34.950
<v Speaker 2>this network is the imagination network,</v>
<v Speaker 2>if you like.</v>

594
00:31:36.440 --> 00:31:38.180
<v Speaker 2>So they're much more recently I was </v>
<v Speaker 2>thinking,</v>

595
00:31:38.181 --> 00:31:39.080
<v Speaker 2>well,</v>
<v Speaker 2>okay,</v>

596
00:31:39.081 --> 00:31:41.360
<v Speaker 2>so,</v>
<v Speaker 2>so this is how humans imagine.</v>

597
00:31:41.500 --> 00:31:42.570
<v Speaker 2>Um,</v>
<v Speaker 2>but um,</v>

598
00:31:42.620 --> 00:31:45.170
<v Speaker 2>what about animals?</v>
<v Speaker 2>Can they imagine as well,</v>

599
00:31:45.260 --> 00:31:47.330
<v Speaker 2>for example,</v>
<v Speaker 2>kind of rat imagine.</v>

600
00:31:47.620 --> 00:31:48.660
<v Speaker 2>Um,</v>
<v Speaker 2>uh,</v>

601
00:31:48.680 --> 00:31:49.040
<v Speaker 2>we,</v>
<v Speaker 2>you know,</v>

602
00:31:49.041 --> 00:31:51.350
<v Speaker 2>again,</v>
<v Speaker 2>we know that rats have memory,</v>

603
00:31:51.470 --> 00:31:53.200
<v Speaker 2>very good memory in fact.</v>
<v Speaker 2>Um,</v>

604
00:31:53.390 --> 00:31:56.360
<v Speaker 2>but can they do things like imagine the </v>
<v Speaker 2>future?</v>

605
00:31:57.320 --> 00:31:57.650
<v Speaker 3>Yeah.</v>

606
00:31:57.750 --> 00:32:02.340
<v Speaker 2>So before I show you the study that we </v>
<v Speaker 2>did to investigate that,</v>

607
00:32:02.520 --> 00:32:07.020
<v Speaker 2>I just need to take you through a couple</v>
<v Speaker 2>of things about that we know about rats,</v>

608
00:32:07.180 --> 00:32:07.990
<v Speaker 2>um,</v>
<v Speaker 2>um,</v>

609
00:32:08.160 --> 00:32:11.790
<v Speaker 2>and we know that rats can do.</v>
<v Speaker 2>So the first thing to tell you about his</v>

610
00:32:11.791 --> 00:32:16.791
<v Speaker 2>place sells.</v>
<v Speaker 2>Now I'm play cells are you can really </v>

611
00:32:16.791 --> 00:32:20.130
<v Speaker 2>think of them as the GPS coordinates in </v>
<v Speaker 2>a rat's brain about where they are.</v>

612
00:32:21.000 --> 00:32:24.930
<v Speaker 2>So if we imagine a box that a rat might </v>
<v Speaker 2>be in a box.</v>

613
00:32:24.931 --> 00:32:27.210
<v Speaker 2>So here we're looking top down on this </v>
<v Speaker 2>environment,</v>

614
00:32:27.540 --> 00:32:30.750
<v Speaker 2>then the rat might be roaming around </v>
<v Speaker 2>this box.</v>

615
00:32:31.050 --> 00:32:32.550
<v Speaker 2>And uh,</v>
<v Speaker 2>you know,</v>

616
00:32:32.551 --> 00:32:37.551
<v Speaker 2>in these experiments you record directly</v>
<v Speaker 2>from the rat's brain while they're </v>

617
00:32:37.551 --> 00:32:38.520
<v Speaker 2>roaming around.</v>
<v Speaker 2>And what you find is,</v>

618
00:32:38.670 --> 00:32:39.640
<v Speaker 2>is,</v>
<v Speaker 2>um,</v>

619
00:32:39.800 --> 00:32:44.800
<v Speaker 2>cells in the hippocampus fire,</v>
<v Speaker 2>I'm in specific places in the </v>

620
00:32:44.800 --> 00:32:46.190
<v Speaker 2>environment.</v>
<v Speaker 2>So for example,</v>

621
00:32:46.310 --> 00:32:47.180
<v Speaker 2>a cell,</v>
<v Speaker 2>a cell,</v>

622
00:32:47.181 --> 00:32:52.181
<v Speaker 2>a might fire only it when the rat is </v>
<v Speaker 2>traversing through this particular part </v>

623
00:32:52.730 --> 00:32:55.310
<v Speaker 2>of the box environment.</v>
<v Speaker 2>Conversely,</v>

624
00:32:55.340 --> 00:32:59.030
<v Speaker 2>selby be my only fire in another part of</v>
<v Speaker 2>the environment.</v>

625
00:32:59.870 --> 00:33:00.940
<v Speaker 2>Now,</v>
<v Speaker 2>the,</v>

626
00:33:01.150 --> 00:33:03.050
<v Speaker 2>the amazing person who discovered this,</v>
<v Speaker 2>John O'keefe,</v>

627
00:33:03.051 --> 00:33:06.260
<v Speaker 2>who discovered these place cells in the </v>
<v Speaker 2>seventies just around the corner at Ucl,</v>

628
00:33:06.261 --> 00:33:09.140
<v Speaker 2>won the Nobel prize for this last year.</v>
<v Speaker 2>Um,</v>

629
00:33:09.290 --> 00:33:11.590
<v Speaker 2>and I was lucky enough to have him as </v>
<v Speaker 2>my,</v>

630
00:33:11.591 --> 00:33:13.790
<v Speaker 2>uh,</v>
<v Speaker 2>on my vibe of committee for my phd.</v>

631
00:33:13.970 --> 00:33:18.170
<v Speaker 2>So I got to know him well and um,</v>
<v Speaker 2>the entire rap literature very well.</v>

632
00:33:18.440 --> 00:33:21.300
<v Speaker 2>And what I started thinking about is </v>
<v Speaker 2>since that discovery,</v>

633
00:33:21.301 --> 00:33:24.350
<v Speaker 2>a place cells,</v>
<v Speaker 2>people have found that actually,</v>

634
00:33:24.460 --> 00:33:26.600
<v Speaker 2>um,</v>
<v Speaker 2>sequences of place,</v>

635
00:33:26.601 --> 00:33:28.360
<v Speaker 2>cells fire in,</v>
<v Speaker 2>in,</v>

636
00:33:28.390 --> 00:33:31.790
<v Speaker 2>in kind of sequence when a wrap moves </v>
<v Speaker 2>through an environment.</v>

637
00:33:32.120 --> 00:33:34.660
<v Speaker 2>So for example,</v>
<v Speaker 2>let's take a new environment here,</v>

638
00:33:34.730 --> 00:33:39.730
<v Speaker 2>a linear track.</v>
<v Speaker 2>So this is like a linear box and the </v>

639
00:33:39.730 --> 00:33:39.810
<v Speaker 2>rats moving from,</v>
<v Speaker 2>um,</v>

640
00:33:40.040 --> 00:33:42.560
<v Speaker 2>from left to right here.</v>
<v Speaker 2>And what you find,</v>

641
00:33:42.561 --> 00:33:44.750
<v Speaker 2>if you record from the brains of these </v>
<v Speaker 2>rats,</v>

642
00:33:44.751 --> 00:33:47.960
<v Speaker 2>is that place cells will fire in order </v>
<v Speaker 2>a,</v>

643
00:33:47.961 --> 00:33:48.260
<v Speaker 2>b,</v>
<v Speaker 2>c,</v>

644
00:33:48.261 --> 00:33:50.990
<v Speaker 2>and d,</v>
<v Speaker 2>depending mimicking the way,</v>

645
00:33:51.120 --> 00:33:56.120
<v Speaker 2>um,</v>
<v Speaker 2>and matching the way that the rat is </v>

646
00:33:56.120 --> 00:33:57.020
<v Speaker 2>moving through that environment.</v>
<v Speaker 2>And in the nineties,</v>

647
00:33:57.140 --> 00:34:02.140
<v Speaker 2>other people's found that when they </v>
<v Speaker 2>recorded from the brains of these rats,</v>

648
00:34:02.480 --> 00:34:07.480
<v Speaker 2>while they were asleep,</v>
<v Speaker 2>after they had walked around and </v>

649
00:34:07.480 --> 00:34:12.071
<v Speaker 2>navigate it in one of these amazing like</v>
<v Speaker 2>environments that the rats would replay </v>

650
00:34:13.760 --> 00:34:17.750
<v Speaker 2>the trajectories they'd experienced in </v>
<v Speaker 2>their wake session before.</v>

651
00:34:17.900 --> 00:34:22.900
<v Speaker 2>So you could,</v>
<v Speaker 2>you could really think about this as </v>

652
00:34:22.900 --> 00:34:25.301
<v Speaker 2>rats dreaming,</v>
<v Speaker 2>so they would replay this trajectory of </v>

653
00:34:25.301 --> 00:34:27.740
<v Speaker 2>Abcd,</v>
<v Speaker 2>but now this would be just,</v>

654
00:34:27.860 --> 00:34:32.860
<v Speaker 2>um,</v>
<v Speaker 2>they will be sleeping soundly and it'll </v>

655
00:34:32.860 --> 00:34:32.860
<v Speaker 2>be just their,</v>
<v Speaker 2>their brains replaying this.</v>

656
00:34:32.860 --> 00:34:33.950
<v Speaker 2>And what's interesting is that the </v>
<v Speaker 2>brain,</v>

657
00:34:33.990 --> 00:34:36.350
<v Speaker 2>so these rats actually replay these </v>
<v Speaker 2>trajectories,</v>

658
00:34:36.780 --> 00:34:41.480
<v Speaker 2>an order of magnitude faster than they </v>
<v Speaker 2>actually experienced it in real life.</v>

659
00:34:41.930 --> 00:34:46.930
<v Speaker 2>So if you think about dreaming as maybe </v>
<v Speaker 2>helping the rats learn about the </v>

660
00:34:46.930 --> 00:34:49.140
<v Speaker 2>environment that they're in,</v>
<v Speaker 2>then they actually,</v>

661
00:34:49.410 --> 00:34:54.410
<v Speaker 2>I'm learning from this much more </v>
<v Speaker 2>efficiently than they can experience it </v>

662
00:34:54.410 --> 00:34:55.580
<v Speaker 2>when they are awake.</v>
<v Speaker 2>So that's,</v>

663
00:34:55.660 --> 00:35:00.660
<v Speaker 2>uh,</v>
<v Speaker 2>shows that rats have memory and perhaps </v>

664
00:35:00.660 --> 00:35:03.431
<v Speaker 2>they dream,</v>
<v Speaker 2>but it's not showing that they actually </v>

665
00:35:03.431 --> 00:35:05.720
<v Speaker 2>imagine new experiences that they </v>
<v Speaker 2>haven't experienced while they're awake.</v>

666
00:35:06.200 --> 00:35:11.200
<v Speaker 2>So we wanted to show that unequivocally </v>
<v Speaker 2>and recently we published a study with </v>

667
00:35:11.200 --> 00:35:15.491
<v Speaker 2>some colleagues of mine at Ucl in ie </v>
<v Speaker 2>life that I think a unequivocally shows </v>

668
00:35:16.251 --> 00:35:17.480
<v Speaker 2>that rats do imagine.</v>

669
00:35:18.770 --> 00:35:20.690
<v Speaker 2>So we designed this simple but,</v>
<v Speaker 2>um,</v>

670
00:35:20.960 --> 00:35:24.560
<v Speaker 2>I think quite elegant design to test </v>
<v Speaker 2>this hypothesis out.</v>

671
00:35:24.860 --> 00:35:27.650
<v Speaker 2>So what we had here is a teammate is </v>
<v Speaker 2>this time.</v>

672
00:35:27.651 --> 00:35:29.810
<v Speaker 2>So again,</v>
<v Speaker 2>we're looking top down on the,</v>

673
00:35:29.830 --> 00:35:32.570
<v Speaker 2>on the environment,</v>
<v Speaker 2>and the team is,</v>

674
00:35:32.660 --> 00:35:34.370
<v Speaker 2>has a barrier.</v>
<v Speaker 2>So,</v>

675
00:35:34.371 --> 00:35:37.320
<v Speaker 2>um,</v>
<v Speaker 2>and this barrier here stops the rat.</v>

676
00:35:37.710 --> 00:35:40.460
<v Speaker 2>The rat starts off in the stem of the </v>
<v Speaker 2>teammates,</v>

677
00:35:40.630 --> 00:35:45.630
<v Speaker 2>um,</v>
<v Speaker 2>and it stops the rat moving to the arms </v>

678
00:35:45.630 --> 00:35:45.630
<v Speaker 2>of the teammates,</v>
<v Speaker 2>but it's safe.</v>

679
00:35:45.630 --> 00:35:49.230
<v Speaker 2>Lou the barrier so the rat can see past </v>
<v Speaker 2>to the arms and see what's on the arms.</v>

680
00:35:50.640 --> 00:35:55.640
<v Speaker 2>So the rise initially in the first </v>
<v Speaker 2>session running up and down the stem of </v>

681
00:35:55.640 --> 00:35:59.601
<v Speaker 2>the t mates.</v>
<v Speaker 2>And what we do to make the rat really </v>

682
00:35:59.601 --> 00:36:01.650
<v Speaker 2>interested in the arms is we put some </v>
<v Speaker 2>food,</v>

683
00:36:01.860 --> 00:36:05.200
<v Speaker 2>uh,</v>
<v Speaker 2>rice pellet on one of the arms here,</v>

684
00:36:05.520 --> 00:36:10.520
<v Speaker 2>depicted by this yellow dot and on the </v>
<v Speaker 2>right hand arm and the rack can see this</v>

685
00:36:11.850 --> 00:36:15.450
<v Speaker 2>when it gets to the barrier,</v>
<v Speaker 2>but it can't reach the rice pellet.</v>

686
00:36:15.660 --> 00:36:20.660
<v Speaker 2>So obviously he's very motivated to </v>
<v Speaker 2>think about a to try and get the rice </v>

687
00:36:20.660 --> 00:36:20.790
<v Speaker 2>pellet,</v>
<v Speaker 2>but it can't get past the barrier.</v>

688
00:36:21.750 --> 00:36:23.970
<v Speaker 2>So then after it's experienced that </v>
<v Speaker 2>environment for a while,</v>

689
00:36:23.971 --> 00:36:26.370
<v Speaker 2>we let the rat go to sleep and that </v>
<v Speaker 2>will,</v>

690
00:36:26.371 --> 00:36:31.371
<v Speaker 2>of course,</v>
<v Speaker 2>we recording from the rat's brain while </v>

691
00:36:31.371 --> 00:36:31.371
<v Speaker 2>this is going on.</v>
<v Speaker 2>Um,</v>

692
00:36:31.371 --> 00:36:34.050
<v Speaker 2>and then we wake up again and now we put</v>
<v Speaker 2>it back in the environment.</v>

693
00:36:34.230 --> 00:36:35.570
<v Speaker 2>But this time,</v>
<v Speaker 2>um,</v>

694
00:36:35.730 --> 00:36:40.530
<v Speaker 2>we remove that barrier.</v>
<v Speaker 2>So now it's free to run around the whole</v>

695
00:36:40.531 --> 00:36:43.110
<v Speaker 2>teammates.</v>
<v Speaker 2>So it does that happily,</v>

696
00:36:43.170 --> 00:36:44.800
<v Speaker 2>it moves around,</v>
<v Speaker 2>uh,</v>

697
00:36:44.820 --> 00:36:45.400
<v Speaker 2>the,</v>
<v Speaker 2>the,</v>

698
00:36:45.430 --> 00:36:48.930
<v Speaker 2>the stem and the arms,</v>
<v Speaker 2>both the left arm and the right arm,</v>

699
00:36:49.120 --> 00:36:54.120
<v Speaker 2>uh,</v>
<v Speaker 2>and it fully explored this whole </v>

700
00:36:54.120 --> 00:36:56.031
<v Speaker 2>environment.</v>
<v Speaker 2>So obviously as I've just told you with </v>

701
00:36:56.031 --> 00:36:57.000
<v Speaker 2>the place cells,</v>
<v Speaker 2>what we can do is we find that there are</v>

702
00:36:57.001 --> 00:36:59.670
<v Speaker 2>play cells,</v>
<v Speaker 2>let's say so a and sell DDI.</v>

703
00:36:59.850 --> 00:37:03.900
<v Speaker 2>That fire,</v>
<v Speaker 2>I'm on the arm section of the maze.</v>

704
00:37:05.280 --> 00:37:10.280
<v Speaker 2>Now what we can do is then go back to </v>
<v Speaker 2>look at the data we collected when the </v>

705
00:37:10.410 --> 00:37:15.410
<v Speaker 2>rat was asleep and see if the rack was </v>
<v Speaker 2>imagining about those trajectories </v>

706
00:37:16.621 --> 00:37:20.670
<v Speaker 2>towards the rice pellet before it ever </v>
<v Speaker 2>had experienced it in reality.</v>

707
00:37:20.910 --> 00:37:25.530
<v Speaker 2>So they forget when it was sleeping in </v>
<v Speaker 2>the rat had never experienced walking on</v>

708
00:37:25.531 --> 00:37:27.980
<v Speaker 2>this or a that.</v>
<v Speaker 2>Only seen that all.</v>

709
00:37:28.590 --> 00:37:31.100
<v Speaker 2>And what happens is we find our </v>
<v Speaker 2>conjectures,</v>

710
00:37:31.101 --> 00:37:34.650
<v Speaker 2>we're sort of proven that actually you </v>
<v Speaker 2>get,</v>

711
00:37:34.740 --> 00:37:37.470
<v Speaker 2>we find if we go back and analyze the </v>
<v Speaker 2>sleep data,</v>

712
00:37:37.620 --> 00:37:41.220
<v Speaker 2>you get this replay or pre play if you </v>
<v Speaker 2>like,</v>

713
00:37:41.370 --> 00:37:43.430
<v Speaker 2>of this trajectory,</v>
<v Speaker 2>abcd.</v>

714
00:37:43.740 --> 00:37:47.700
<v Speaker 2>And what's more is this is not just </v>
<v Speaker 2>random pre play.</v>

715
00:37:47.940 --> 00:37:52.940
<v Speaker 2>You actually get more significantly more</v>
<v Speaker 2>prepared to the right hand arm then to </v>

716
00:37:52.940 --> 00:37:57.171
<v Speaker 2>the left handle,</v>
<v Speaker 2>which is exactly what you would expect </v>

717
00:37:57.171 --> 00:37:57.171
<v Speaker 2>if it's behaviorally consequential.</v>

718
00:37:57.171 --> 00:37:58.090
<v Speaker 2>Right?</v>
<v Speaker 2>So you can.</v>

719
00:37:58.170 --> 00:38:00.360
<v Speaker 2>I mean,</v>
<v Speaker 2>of course this is anthropomorphizing the</v>

720
00:38:00.361 --> 00:38:05.361
<v Speaker 2>rat,</v>
<v Speaker 2>but you could imagine the rats really </v>

721
00:38:05.361 --> 00:38:08.360
<v Speaker 2>wanting to get to that rice pellet and </v>
<v Speaker 2>is imagining plans of how could it get </v>

722
00:38:08.360 --> 00:38:08.360
<v Speaker 2>there,</v>
<v Speaker 2>right?</v>

723
00:38:08.360 --> 00:38:11.340
<v Speaker 2>Almost imagining yourself walking to the</v>
<v Speaker 2>writer Paler and then eating it.</v>

724
00:38:11.870 --> 00:38:16.870
<v Speaker 2>And so,</v>
<v Speaker 2>and then it just dreaming about imagine </v>

725
00:38:16.870 --> 00:38:16.870
<v Speaker 2>experiences.</v>
<v Speaker 2>Right?</v>

726
00:38:16.870 --> 00:38:17.190
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

727
00:38:17.220 --> 00:38:19.230
<v Speaker 2>so,</v>
<v Speaker 2>and that's really what's going on here.</v>

728
00:38:19.231 --> 00:38:20.040
<v Speaker 2>I think,</v>
<v Speaker 2>uh,</v>

729
00:38:20.120 --> 00:38:25.120
<v Speaker 2>and of course we're now going to look </v>
<v Speaker 2>into this further and we have a number </v>

730
00:38:25.120 --> 00:38:26.310
<v Speaker 2>of plans to look at a follow on studies </v>
<v Speaker 2>from this,</v>

731
00:38:26.440 --> 00:38:28.440
<v Speaker 2>um,</v>
<v Speaker 2>with more complex environments.</v>

732
00:38:29.760 --> 00:38:30.690
<v Speaker 2>So,</v>
<v Speaker 2>you know,</v>

733
00:38:30.691 --> 00:38:32.700
<v Speaker 2>humans imagine rats.</v>
<v Speaker 2>Imagine.</v>

734
00:38:32.820 --> 00:38:34.560
<v Speaker 2>So what about,</v>
<v Speaker 2>um,</v>

735
00:38:34.720 --> 00:38:36.250
<v Speaker 2>uh,</v>
<v Speaker 2>machines.</v>

736
00:38:36.490 --> 00:38:40.540
<v Speaker 2>So this is something that's key </v>
<v Speaker 2>imagination to planning for the future,</v>

737
00:38:40.541 --> 00:38:43.000
<v Speaker 2>making plans,</v>
<v Speaker 2>good plans about the future.</v>

738
00:38:43.180 --> 00:38:46.360
<v Speaker 2>So this is obviously something that we </v>
<v Speaker 2>also want our machines to be able to do.</v>

739
00:38:47.140 --> 00:38:47.900
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

740
00:38:48.040 --> 00:38:49.540
<v Speaker 2>you know,</v>
<v Speaker 2>I've been titled this slide do,</v>

741
00:38:49.660 --> 00:38:54.660
<v Speaker 2>do androids dream of electric sheep,</v>
<v Speaker 2>which is of course is a reference to </v>

742
00:38:54.660 --> 00:38:57.901
<v Speaker 2>Philip K,</v>
<v Speaker 2>Dick [inaudible] famous book and one of </v>

743
00:38:57.901 --> 00:38:57.901
<v Speaker 2>my favorite,</v>
<v Speaker 2>one of my favorite films,</v>

744
00:38:57.901 --> 00:38:58.840
<v Speaker 2>blade runner.</v>
<v Speaker 2>And um,</v>

745
00:38:59.050 --> 00:39:04.050
<v Speaker 2>and this is really,</v>
<v Speaker 2>I'm just going to give you a very short </v>

746
00:39:04.050 --> 00:39:05.380
<v Speaker 2>excerpt here with this video of which is</v>
<v Speaker 2>a little bit of an insight into the mind</v>

747
00:39:05.381 --> 00:39:09.280
<v Speaker 2>of the machine that you saw earlier </v>
<v Speaker 2>playing space invaders.</v>

748
00:39:09.490 --> 00:39:14.490
<v Speaker 2>So I told you that one of the purposes </v>
<v Speaker 2>of the agent system is to build a model </v>

749
00:39:14.490 --> 00:39:16.570
<v Speaker 2>of the world so they can predict the </v>
<v Speaker 2>future of what's going to happen in that</v>

750
00:39:16.571 --> 00:39:17.950
<v Speaker 2>game world.</v>
<v Speaker 2>And here,</v>

751
00:39:18.190 --> 00:39:23.190
<v Speaker 2>what I'm going to show in this sort of </v>
<v Speaker 2>ten second video is the machine getting </v>

752
00:39:23.190 --> 00:39:24.490
<v Speaker 2>an initial input from space invaders </v>
<v Speaker 2>like this.</v>

753
00:39:24.520 --> 00:39:29.520
<v Speaker 2>This is the game position and then </v>
<v Speaker 2>freely imagining or dreaming about what </v>

754
00:39:29.520 --> 00:39:33.710
<v Speaker 2>might happen over the next 10 seconds.</v>
<v Speaker 2>So you can see it's,</v>

755
00:39:33.750 --> 00:39:35.150
<v Speaker 2>it's dream out moving.</v>
<v Speaker 2>It's,</v>

756
00:39:35.210 --> 00:39:36.160
<v Speaker 2>it's,</v>
<v Speaker 2>uh,</v>

757
00:39:36.210 --> 00:39:41.210
<v Speaker 2>the rocket and it's dreaming about </v>
<v Speaker 2>getting points and shooting some of the </v>

758
00:39:41.210 --> 00:39:45.251
<v Speaker 2>space invaders.</v>
<v Speaker 2>Now it's quite fuzzy because there's </v>

759
00:39:45.251 --> 00:39:45.251
<v Speaker 2>uncertainty about what might happen in </v>
<v Speaker 2>the world.</v>

760
00:39:45.251 --> 00:39:46.280
<v Speaker 2>It's all probabilistic.</v>
<v Speaker 2>So,</v>

761
00:39:46.281 --> 00:39:51.281
<v Speaker 2>um,</v>
<v Speaker 2>it's not as certain as seeing an actual </v>

762
00:39:51.281 --> 00:39:51.281
<v Speaker 2>screen.</v>
<v Speaker 2>Um,</v>

763
00:39:51.281 --> 00:39:54.140
<v Speaker 2>but it's the beginnings,</v>
<v Speaker 2>I think of imagination based planning.</v>

764
00:39:55.890 --> 00:39:57.690
<v Speaker 2>Now I'm just going to end by talking a </v>
<v Speaker 2>little bit about,</v>

765
00:39:57.691 --> 00:40:00.720
<v Speaker 2>so that's imagination.</v>
<v Speaker 2>So once you start thinking,</v>

766
00:40:00.721 --> 00:40:02.430
<v Speaker 2>well,</v>
<v Speaker 2>could machines have imagination?</v>

767
00:40:02.431 --> 00:40:07.431
<v Speaker 2>What about creativity?</v>
<v Speaker 2>I just something I get asked about all </v>

768
00:40:07.431 --> 00:40:08.400
<v Speaker 2>the time and of course is very relevant </v>
<v Speaker 2>to a lot of the work that people in this</v>

769
00:40:08.401 --> 00:40:10.650
<v Speaker 2>room do.</v>
<v Speaker 2>And um,</v>

770
00:40:10.710 --> 00:40:15.710
<v Speaker 2>you know,</v>
<v Speaker 2>I think we're a long way away from </v>

771
00:40:15.710 --> 00:40:17.880
<v Speaker 2>machines being truly creative,</v>
<v Speaker 2>but I don't think it's impossible and I </v>

772
00:40:17.880 --> 00:40:22.731
<v Speaker 2>think that um,</v>
<v Speaker 2>when we start to understand what this </v>

773
00:40:22.731 --> 00:40:25.191
<v Speaker 2>process is,</v>
<v Speaker 2>this mysterious process of creativity </v>

774
00:40:25.191 --> 00:40:25.191
<v Speaker 2>is,</v>
<v Speaker 2>um,</v>

775
00:40:25.191 --> 00:40:28.820
<v Speaker 2>I think it will become actually more </v>
<v Speaker 2>obvious how to implement that in an </v>

776
00:40:28.820 --> 00:40:33.531
<v Speaker 2>algorithm.</v>
<v Speaker 2>So I just want to show a couple of </v>

777
00:40:33.531 --> 00:40:33.531
<v Speaker 2>little hints of things that might </v>
<v Speaker 2>surprise you.</v>

778
00:40:33.531 --> 00:40:37.930
<v Speaker 2>Um,</v>
<v Speaker 2>so let's just take a picture of the </v>

779
00:40:38.670 --> 00:40:40.950
<v Speaker 2>British Museum,</v>
<v Speaker 2>the front of this building and uh,</v>

780
00:40:40.951 --> 00:40:45.510
<v Speaker 2>if we then say to the machine,</v>
<v Speaker 2>and this is a new type of algorithm that</v>

781
00:40:45.511 --> 00:40:50.511
<v Speaker 2>was actually first a very recently </v>
<v Speaker 2>invented at Max Planck Institute in </v>

782
00:40:50.521 --> 00:40:50.970
<v Speaker 2>Germany.</v>

783
00:40:50.970 --> 00:40:53.610
<v Speaker 2>And then we've implemented our own </v>
<v Speaker 2>version of this internally.</v>

784
00:40:53.910 --> 00:40:58.910
<v Speaker 2>And what you can do is you can give it a</v>
<v Speaker 2>autistic picture like this van Gough </v>

785
00:40:59.311 --> 00:41:02.370
<v Speaker 2>picture and say you wanted to,</v>
<v Speaker 2>you want the,</v>

786
00:41:02.390 --> 00:41:07.390
<v Speaker 2>that photo redrawn in the style of Van </v>
<v Speaker 2>Gough Rights and um,</v>

787
00:41:07.730 --> 00:41:12.730
<v Speaker 2>and actually so you ends up with outputs</v>
<v Speaker 2>that I like this where you can actually,</v>

788
00:41:12.841 --> 00:41:15.210
<v Speaker 2>it's not ready yet to be hung at the </v>
<v Speaker 2>Louvre,</v>

789
00:41:15.390 --> 00:41:20.390
<v Speaker 2>but you can sort of start thinking it's </v>
<v Speaker 2>pretty surprising when I saw these </v>

790
00:41:20.390 --> 00:41:23.850
<v Speaker 2>things like how a actually coherent the </v>
<v Speaker 2>output can be.</v>

791
00:41:24.380 --> 00:41:25.750
<v Speaker 2>And then,</v>
<v Speaker 2>you know,</v>

792
00:41:25.830 --> 00:41:30.830
<v Speaker 2>we can look at other examples.</v>
<v Speaker 2>So actually this is a concept piece of </v>

793
00:41:30.830 --> 00:41:32.190
<v Speaker 2>concept art for um,</v>
<v Speaker 2>uh,</v>

794
00:41:32.240 --> 00:41:37.130
<v Speaker 2>a new google that's been built in,</v>
<v Speaker 2>in Silicon Valley and we give it a syrup</v>

795
00:41:37.131 --> 00:41:40.820
<v Speaker 2>painting and then we ask it's output in </v>
<v Speaker 2>is one of my favorite ones.</v>

796
00:41:40.970 --> 00:41:41.990
<v Speaker 2>And you know,</v>
<v Speaker 2>producers,</v>

797
00:41:41.991 --> 00:41:44.780
<v Speaker 2>pretty good version of the,</v>
<v Speaker 2>um,</v>

798
00:41:44.840 --> 00:41:46.120
<v Speaker 2>of the original,</v>
<v Speaker 2>but in,</v>

799
00:41:46.260 --> 00:41:47.420
<v Speaker 2>in the start of syrup.</v>

800
00:41:47.750 --> 00:41:50.000
<v Speaker 2>And this isn't true creativity,</v>
<v Speaker 2>right in,</v>

801
00:41:50.001 --> 00:41:55.001
<v Speaker 2>in some senses is a politic because what</v>
<v Speaker 2>we're doing here with deconstructing </v>

802
00:41:55.001 --> 00:41:55.001
<v Speaker 2>the,</v>
<v Speaker 2>the,</v>

803
00:41:55.001 --> 00:41:59.780
<v Speaker 2>the,</v>
<v Speaker 2>the features of both the original photo </v>

804
00:41:59.780 --> 00:41:59.780
<v Speaker 2>and the,</v>
<v Speaker 2>um,</v>

805
00:41:59.780 --> 00:42:02.570
<v Speaker 2>the painting.</v>
<v Speaker 2>And then we're swapping those features,</v>

806
00:42:02.720 --> 00:42:07.720
<v Speaker 2>a overwriting of the photo features with</v>
<v Speaker 2>the painting features and that gives </v>

807
00:42:07.720 --> 00:42:07.720
<v Speaker 2>this,</v>
<v Speaker 2>uh,</v>

808
00:42:07.720 --> 00:42:09.440
<v Speaker 2>this,</v>
<v Speaker 2>these kinds of outputs.</v>

809
00:42:09.710 --> 00:42:14.710
<v Speaker 2>But the surprising thing here is that </v>
<v Speaker 2>there isn't much sort of what you would </v>

810
00:42:14.710 --> 00:42:18.400
<v Speaker 2>regard as creativity here and yet you </v>
<v Speaker 2>get these kind of very interesting </v>

811
00:42:18.400 --> 00:42:22.661
<v Speaker 2>outputs.</v>
<v Speaker 2>So it may be that creativity isn't as </v>

812
00:42:22.661 --> 00:42:24.740
<v Speaker 2>mysterious as it seems to us when we </v>
<v Speaker 2>have ultimately find out what it is</v>

813
00:42:26.280 --> 00:42:31.280
<v Speaker 2>now I'm just going to end by talking a </v>
<v Speaker 2>little bit about the bigger picture and </v>

814
00:42:31.280 --> 00:42:32.670
<v Speaker 2>sort of the impact that ai might have in</v>
<v Speaker 2>the future.</v>

815
00:42:32.970 --> 00:42:34.230
<v Speaker 2>And uh,</v>
<v Speaker 2>so,</v>

816
00:42:34.290 --> 00:42:39.290
<v Speaker 2>you know,</v>
<v Speaker 2>I think some of the big problems are </v>

817
00:42:39.290 --> 00:42:40.671
<v Speaker 2>facing us as a society or information </v>
<v Speaker 2>overload and system complexity.</v>

818
00:42:41.280 --> 00:42:42.240
<v Speaker 2>So,</v>
<v Speaker 2>you know,</v>

819
00:42:42.241 --> 00:42:45.450
<v Speaker 2>everywhere we go now it daily use by </v>
<v Speaker 2>inflammation.</v>

820
00:42:45.630 --> 00:42:47.100
<v Speaker 2>So things like,</v>
<v Speaker 2>um,</v>

821
00:42:47.190 --> 00:42:49.080
<v Speaker 2>obviously genomics,</v>
<v Speaker 2>big data in general,</v>

822
00:42:49.081 --> 00:42:51.420
<v Speaker 2>but in the world of TV know </v>
<v Speaker 2>entertainment.</v>

823
00:42:51.421 --> 00:42:54.720
<v Speaker 2>I mean there's so many TV channels now </v>
<v Speaker 2>and modes of watching things.</v>

824
00:42:54.721 --> 00:42:57.360
<v Speaker 2>How can you really find what it is that </v>
<v Speaker 2>you're interested in?</v>

825
00:42:57.750 --> 00:43:00.990
<v Speaker 2>And personalization is one kind of </v>
<v Speaker 2>technology that might help,</v>

826
00:43:00.991 --> 00:43:05.991
<v Speaker 2>but it doesn't really work because it's </v>
<v Speaker 2>really based at the moment on quite </v>

827
00:43:05.991 --> 00:43:09.381
<v Speaker 2>primitive sort of wisdom of the crowds,</v>
<v Speaker 2>collaborative filtering technology and </v>

828
00:43:09.381 --> 00:43:12.300
<v Speaker 2>that doesn't give you unique </v>
<v Speaker 2>recommendations that are unique to your,</v>

829
00:43:12.360 --> 00:43:14.340
<v Speaker 2>what I would call long tail of </v>
<v Speaker 2>interests.</v>

830
00:43:14.880 --> 00:43:19.880
<v Speaker 2>And then in terms of system complexity,</v>
<v Speaker 2>the kinds of systems we would like to </v>

831
00:43:19.880 --> 00:43:19.880
<v Speaker 2>master,</v>
<v Speaker 2>you know,</v>

832
00:43:19.880 --> 00:43:21.210
<v Speaker 2>climate disease,</v>
<v Speaker 2>energy,</v>

833
00:43:21.211 --> 00:43:26.211
<v Speaker 2>macroeconomics,</v>
<v Speaker 2>even particle physics are becoming so </v>

834
00:43:26.211 --> 00:43:29.301
<v Speaker 2>complex now that even teams of the,</v>
<v Speaker 2>of the best and brightest human experts </v>

835
00:43:30.090 --> 00:43:35.090
<v Speaker 2>are having difficulty comprehending the </v>
<v Speaker 2>implications are of these systems and </v>

836
00:43:35.281 --> 00:43:37.080
<v Speaker 2>actually making useful predictions about</v>
<v Speaker 2>them.</v>

837
00:43:38.290 --> 00:43:43.290
<v Speaker 2>So I think solving intelligence,</v>
<v Speaker 2>solving ai is potentially a kind of </v>

838
00:43:43.290 --> 00:43:44.830
<v Speaker 2>metal solution to all these problems.</v>
<v Speaker 2>If we can solve intelligence,</v>

839
00:43:44.980 --> 00:43:47.860
<v Speaker 2>then maybe we can use it to help us,</v>
<v Speaker 2>um,</v>

840
00:43:48.010 --> 00:43:49.900
<v Speaker 2>as human experts,</v>
<v Speaker 2>uh,</v>

841
00:43:49.930 --> 00:43:52.300
<v Speaker 2>get a better handle on all these other </v>
<v Speaker 2>systems.</v>

842
00:43:52.570 --> 00:43:57.570
<v Speaker 2>And my dream really the thing I'd like </v>
<v Speaker 2>to use a January ai for is to build ai </v>

843
00:43:57.570 --> 00:44:00.550
<v Speaker 2>scientists or to make ai assisted </v>
<v Speaker 2>science possible.</v>

844
00:44:02.480 --> 00:44:04.760
<v Speaker 2>And of course,</v>
<v Speaker 2>if we have something this powerful,</v>

845
00:44:04.970 --> 00:44:08.040
<v Speaker 2>then obviously we need to think about </v>
<v Speaker 2>the ethics of that,</v>

846
00:44:08.041 --> 00:44:13.041
<v Speaker 2>of the use of it.</v>
<v Speaker 2>And as with all new powerful </v>

847
00:44:13.041 --> 00:44:13.970
<v Speaker 2>technologies.</v>
<v Speaker 2>And I think ai is no different from many</v>

848
00:44:13.971 --> 00:44:15.770
<v Speaker 2>other technologies in the past in this </v>
<v Speaker 2>regard.</v>

849
00:44:16.010 --> 00:44:21.010
<v Speaker 2>We have to be a very cognizant about </v>
<v Speaker 2>using these technologies ethically and </v>

850
00:44:21.010 --> 00:44:23.690
<v Speaker 2>responsibly.</v>
<v Speaker 2>And although human level Ai,</v>

851
00:44:23.691 --> 00:44:26.150
<v Speaker 2>I think general ai is there many decades</v>
<v Speaker 2>away,</v>

852
00:44:26.300 --> 00:44:29.820
<v Speaker 2>I think we should start the debate now </v>
<v Speaker 2>and when we,</v>

853
00:44:29.920 --> 00:44:34.920
<v Speaker 2>that's what we're doing,</v>
<v Speaker 2>both is our own internal ethics </v>

854
00:44:34.920 --> 00:44:36.210
<v Speaker 2>committees,</v>
<v Speaker 2>but also by supporting academic work and</v>

855
00:44:36.211 --> 00:44:41.211
<v Speaker 2>academic conferences on these topics.</v>
<v Speaker 2>And then finally with a nod to </v>

856
00:44:41.430 --> 00:44:43.710
<v Speaker 2>neuroscience,</v>
<v Speaker 2>I think building Ai,</v>

857
00:44:43.830 --> 00:44:45.330
<v Speaker 2>uh,</v>
<v Speaker 2>actually in this way,</v>

858
00:44:45.331 --> 00:44:50.331
<v Speaker 2>this neuroscience inspired way now help </v>
<v Speaker 2>us better understand the mysteries and </v>

859
00:44:50.331 --> 00:44:53.400
<v Speaker 2>the workings of our own minds.</v>
<v Speaker 2>And I think in the future,</v>

860
00:44:53.530 --> 00:44:58.530
<v Speaker 2>you know,</v>
<v Speaker 2>I think we're on part of the journey </v>

861
00:44:58.530 --> 00:45:00.021
<v Speaker 2>we're on,</v>
<v Speaker 2>is that as we try to distill </v>

862
00:45:00.021 --> 00:45:00.021
<v Speaker 2>intelligence into an algorithmic </v>
<v Speaker 2>construct,</v>

863
00:45:00.021 --> 00:45:02.490
<v Speaker 2>if we then compare that with the </v>
<v Speaker 2>capabilities of the human mind,</v>

864
00:45:02.670 --> 00:45:07.670
<v Speaker 2>I think we'll better understand about </v>
<v Speaker 2>what's unique and special about our own </v>

865
00:45:07.670 --> 00:45:11.271
<v Speaker 2>minds,</v>
<v Speaker 2>like dreaming creativity and perhaps </v>

866
00:45:11.271 --> 00:45:11.271
<v Speaker 2>even the great consciousness question.</v>

867
00:45:11.271 --> 00:45:12.180
<v Speaker 2>Um,</v>
<v Speaker 2>and there's firemen said,</v>

868
00:45:12.181 --> 00:45:15.120
<v Speaker 2>one of my all time scientific heroes,</v>
<v Speaker 2>what I cannot build,</v>

869
00:45:15.300 --> 00:45:17.760
<v Speaker 2>I do not truly understand.</v>
<v Speaker 2>Thanks for listening.</v>

870
00:45:24.100 --> 00:45:27.670
<v Speaker 4>Thank you.</v>

871
00:45:30.340 --> 00:45:32.560
<v Speaker 1>That was brilliant.</v>
<v Speaker 1>If we get the lights up,</v>

872
00:45:32.561 --> 00:45:36.970
<v Speaker 1>I'm going to ask one question but not </v>
<v Speaker 1>hog the limelight here.</v>

873
00:45:36.971 --> 00:45:39.100
<v Speaker 1>And I'll hand over to the audience.</v>
<v Speaker 1>We're going to have 20 minutes.</v>

874
00:45:39.101 --> 00:45:44.101
<v Speaker 1>So I'm having have a little pause.</v>
<v Speaker 1>Have a think about what you want to ask </v>

875
00:45:44.101 --> 00:45:46.900
<v Speaker 1>Dennis because they're probably provoked</v>
<v Speaker 1>a so much kind of thinking.</v>

876
00:45:47.220 --> 00:45:49.300
<v Speaker 1>One question I've got very simple one </v>
<v Speaker 1>actually is.</v>

877
00:45:50.990 --> 00:45:52.170
<v Speaker 1>Well,</v>
<v Speaker 1>I was amazed by,</v>

878
00:45:52.190 --> 00:45:53.610
<v Speaker 1>was that what you,</v>
<v Speaker 1>what your details,</v>

879
00:45:53.611 --> 00:45:54.970
<v Speaker 1>your 20 year plan,</v>
<v Speaker 1>you know,</v>

880
00:45:55.560 --> 00:45:58.240
<v Speaker 1>get your chest skills sorted,</v>
<v Speaker 1>you know,</v>

881
00:45:58.470 --> 00:46:00.750
<v Speaker 1>in terms of those virtual environments </v>
<v Speaker 1>in gaming.</v>

882
00:46:00.751 --> 00:46:02.010
<v Speaker 1>Then,</v>
<v Speaker 1>then you needed the nude,</v>

883
00:46:02.310 --> 00:46:05.860
<v Speaker 1>but that was the first 20 years and you </v>
<v Speaker 1>just talked about decades away because I</v>

884
00:46:05.870 --> 00:46:10.870
<v Speaker 1>think people are pretty obsessed with </v>
<v Speaker 1>taking that raw data in building the </v>

885
00:46:10.870 --> 00:46:12.630
<v Speaker 1>picture of the environment where we're </v>
<v Speaker 1>at Atari Games.</v>

886
00:46:13.050 --> 00:46:15.000
<v Speaker 1>But I knew that breakout trick,</v>
<v Speaker 1>but anyway,</v>

887
00:46:15.880 --> 00:46:20.880
<v Speaker 1>we're Atari Games and then the other end</v>
<v Speaker 1>of the spectrum is the AI scientists </v>

888
00:46:20.880 --> 00:46:21.880
<v Speaker 1>taking raw.</v>
<v Speaker 1>What's,</v>

889
00:46:21.940 --> 00:46:26.940
<v Speaker 1>what.</v>
<v Speaker 1>So just give us a sense in the </v>

890
00:46:26.940 --> 00:46:29.580
<v Speaker 1>generation you'll read what's a </v>
<v Speaker 1>realistic moon landing in your term?</v>

891
00:46:30.130 --> 00:46:33.300
<v Speaker 2>Yeah.</v>
<v Speaker 2>I touched on some of those things.</v>

892
00:46:33.301 --> 00:46:35.550
<v Speaker 2>Um,</v>
<v Speaker 2>in that neuroscience slide of the things</v>

893
00:46:35.551 --> 00:46:39.000
<v Speaker 2>with big things I think are important to</v>
<v Speaker 2>solve that beyond like the Atari Games,</v>

894
00:46:39.001 --> 00:46:44.001
<v Speaker 2>of course,</v>
<v Speaker 2>we're sort of on the first rung of the </v>

895
00:46:44.001 --> 00:46:45.561
<v Speaker 2>ladder that the Atari thing was </v>
<v Speaker 2>significant because it was the first </v>

896
00:46:45.561 --> 00:46:46.470
<v Speaker 2>time anyone built what we call an end to</v>
<v Speaker 2>end agent.</v>

897
00:46:46.650 --> 00:46:50.400
<v Speaker 2>So something that took data and then </v>
<v Speaker 2>make decisions.</v>

898
00:46:50.430 --> 00:46:52.890
<v Speaker 2>And did that in one big cycle.</v>
<v Speaker 2>Um,</v>

899
00:46:52.920 --> 00:46:57.920
<v Speaker 2>obviously I think the next big </v>
<v Speaker 2>breakthroughs will be kainate really </v>

900
00:46:57.920 --> 00:46:58.150
<v Speaker 2>learn abstract concepts,</v>
<v Speaker 2>um,</v>

901
00:46:58.220 --> 00:47:03.000
<v Speaker 2>and go beyond just perceptual inputs and</v>
<v Speaker 2>have a wheel underlying understanding of</v>

902
00:47:03.001 --> 00:47:05.070
<v Speaker 2>the semantics of the world it finds </v>
<v Speaker 2>itself in.</v>

903
00:47:05.370 --> 00:47:06.240
<v Speaker 2>So that's,</v>
<v Speaker 2>I think,</v>

904
00:47:06.390 --> 00:47:07.350
<v Speaker 2>um,</v>
<v Speaker 2>you know,</v>

905
00:47:07.351 --> 00:47:08.890
<v Speaker 2>for us is our big kind of thing.</v>

906
00:47:09.350 --> 00:47:11.790
<v Speaker 1>I mean,</v>
<v Speaker 1>is this going to be exponential like the</v>

907
00:47:11.791 --> 00:47:14.070
<v Speaker 1>way computers developed that we're gonna</v>
<v Speaker 1>be in 20 years,</v>

908
00:47:14.071 --> 00:47:15.370
<v Speaker 1>be bowled over by the,</v>

909
00:47:15.700 --> 00:47:17.720
<v Speaker 2>the speed of progression?</v>
<v Speaker 2>I think it's hard to</v>

910
00:47:17.900 --> 00:47:20.060
<v Speaker 1>because we've only got one of you and </v>
<v Speaker 1>you're not going to be here forever.</v>

911
00:47:20.960 --> 00:47:22.610
<v Speaker 1>We want to know how much we can do.</v>

912
00:47:23.890 --> 00:47:26.500
<v Speaker 2>I think it's hard to predict because,</v>
<v Speaker 2>um,</v>

913
00:47:26.540 --> 00:47:31.540
<v Speaker 2>you know,</v>
<v Speaker 2>we need at least a dozen really huge </v>

914
00:47:31.540 --> 00:47:31.570
<v Speaker 2>breakthroughs and uh,</v>
<v Speaker 2>I think to get all that way and,</v>

915
00:47:31.571 --> 00:47:32.000
<v Speaker 2>and,</v>
<v Speaker 2>and,</v>

916
00:47:32.001 --> 00:47:37.001
<v Speaker 2>and research breakthroughs are </v>
<v Speaker 2>notoriously hard to putting the </v>

917
00:47:37.001 --> 00:47:37.001
<v Speaker 2>timescales off.</v>
<v Speaker 2>So I think we'll,</v>

918
00:47:37.001 --> 00:47:37.170
<v Speaker 2>we'll have,</v>
<v Speaker 2>you know,</v>

919
00:47:37.180 --> 00:47:39.730
<v Speaker 2>several very surprising things over the </v>
<v Speaker 2>next few years.</v>

920
00:47:39.870 --> 00:47:41.350
<v Speaker 2>Um,</v>
<v Speaker 2>but you know,</v>

921
00:47:41.351 --> 00:47:43.230
<v Speaker 2>as to how far we'll get all the way.</v>
<v Speaker 2>I think it's,</v>

922
00:47:43.231 --> 00:47:48.231
<v Speaker 2>it's too hard to say from here,</v>
<v Speaker 2>I'm being a personalized timescales for </v>

923
00:47:48.231 --> 00:47:48.231
<v Speaker 2>that.</v>

924
00:47:48.231 --> 00:47:52.460
<v Speaker 1>Brilliant.</v>
<v Speaker 1>I'm going to open it up because it's </v>

925
00:47:52.460 --> 00:47:52.460
<v Speaker 1>easy for me.</v>
<v Speaker 1>I could be here all night,</v>

926
00:47:52.460 --> 00:47:53.450
<v Speaker 1>but why don't we start there?</v>
<v Speaker 1>We'll get a mic to you.</v>

927
00:47:53.490 --> 00:47:56.970
<v Speaker 1>That gentleman there with me,</v>
<v Speaker 1>then we'll come down to the front of how</v>

928
00:47:57.040 --> 00:47:58.260
<v Speaker 1>many we've got going.</v>

929
00:47:59.740 --> 00:48:00.960
<v Speaker 5>Hmm.</v>

930
00:48:03.670 --> 00:48:05.660
<v Speaker 6>Tim Marshall.</v>
<v Speaker 6>If the squeamish,</v>

931
00:48:05.670 --> 00:48:07.080
<v Speaker 6>we'll just close their eyes for a </v>
<v Speaker 6>second.</v>

932
00:48:07.081 --> 00:48:09.450
<v Speaker 6>A few weeks ago I was at a conference,</v>
<v Speaker 6>uh,</v>

933
00:48:09.451 --> 00:48:14.451
<v Speaker 6>where a robot was performing a prostate </v>
<v Speaker 6>operation a more than just performing </v>

934
00:48:14.451 --> 00:48:19.131
<v Speaker 6>the operation there,</v>
<v Speaker 6>could actually understand the tumor and </v>

935
00:48:19.131 --> 00:48:19.131
<v Speaker 6>make a decision whether to proceed or </v>
<v Speaker 6>not.</v>

936
00:48:19.590 --> 00:48:22.890
<v Speaker 6>Today we've seen in the news the </v>
<v Speaker 6>challenges of providing healthcare.</v>

937
00:48:23.460 --> 00:48:24.630
<v Speaker 6>Uh,</v>
<v Speaker 6>where do you think,</v>

938
00:48:24.631 --> 00:48:29.631
<v Speaker 6>what role do you think ai can play in </v>
<v Speaker 6>diagnosis and treatment in health </v>

939
00:48:29.631 --> 00:48:30.450
<v Speaker 6>because,</v>
<v Speaker 6>uh,</v>

940
00:48:30.480 --> 00:48:33.900
<v Speaker 6>the way we practice medicine at the </v>
<v Speaker 6>moment is a 19th century paradigm.</v>

941
00:48:34.420 --> 00:48:36.060
<v Speaker 6>So I'd be interested in your thoughts on</v>
<v Speaker 6>that.</v>

942
00:48:36.150 --> 00:48:36.720
<v Speaker 2>Yeah,</v>
<v Speaker 2>it's great.</v>

943
00:48:36.721 --> 00:48:38.880
<v Speaker 2>Actually,</v>
<v Speaker 2>a healthcare is actually one of the main</v>

944
00:48:39.260 --> 00:48:41.340
<v Speaker 2>application areas we're focusing on.</v>
<v Speaker 2>First,</v>

945
00:48:41.490 --> 00:48:42.800
<v Speaker 2>I think,</v>
<v Speaker 2>um,</v>

946
00:48:42.960 --> 00:48:47.130
<v Speaker 2>we could probably revolutionize the sort</v>
<v Speaker 2>of quality of the care and efficiency of</v>

947
00:48:47.131 --> 00:48:48.280
<v Speaker 2>it,</v>
<v Speaker 2>um,</v>

948
00:48:48.380 --> 00:48:49.170
<v Speaker 2>you know,</v>
<v Speaker 2>as you say,</v>

949
00:48:49.171 --> 00:48:52.710
<v Speaker 2>we're still using kind of 19th century </v>
<v Speaker 2>methods and uh,</v>

950
00:48:52.711 --> 00:48:53.670
<v Speaker 2>I think,</v>
<v Speaker 2>uh,</v>

951
00:48:53.700 --> 00:48:58.700
<v Speaker 2>having this sort of latest information </v>
<v Speaker 2>available in a digestible,</v>

952
00:48:58.711 --> 00:49:01.770
<v Speaker 2>actionable way to surgeons and gps and </v>
<v Speaker 2>so on.</v>

953
00:49:01.990 --> 00:49:02.760
<v Speaker 2>Um,</v>
<v Speaker 2>you know,</v>

954
00:49:02.820 --> 00:49:05.310
<v Speaker 2>I think we'll must really help that </v>
<v Speaker 2>whole,</v>

955
00:49:05.370 --> 00:49:06.060
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

956
00:49:06.061 --> 00:49:11.061
<v Speaker 2>the whole healthcare space.</v>
<v Speaker 2>So it's something we're looking to get </v>

957
00:49:11.061 --> 00:49:12.270
<v Speaker 2>heavily involved with in the next few </v>
<v Speaker 2>years.</v>

958
00:49:13.760 --> 00:49:13.880
<v Speaker 5>Okay.</v>

959
00:49:15.490 --> 00:49:20.490
<v Speaker 7>Why did you decide to publish the code </v>
<v Speaker 7>and were you ever worried or concerned </v>

960
00:49:20.490 --> 00:49:22.940
<v Speaker 7>that when the ethics that might get into</v>
<v Speaker 7>the wrong hands?</v>

961
00:49:23.400 --> 00:49:28.400
<v Speaker 2>Yeah,</v>
<v Speaker 2>I mean we try to be as open as possible </v>

962
00:49:28.400 --> 00:49:29.370
<v Speaker 2>about what we're doing.</v>
<v Speaker 2>So we generally publish.</v>

963
00:49:29.430 --> 00:49:32.880
<v Speaker 2>I'm almost everything that we do and </v>
<v Speaker 2>where we can,</v>

964
00:49:32.881 --> 00:49:36.630
<v Speaker 2>we do open source things as well.</v>
<v Speaker 2>So actually our neural network libraries</v>

965
00:49:36.631 --> 00:49:38.050
<v Speaker 2>called torch that we,</v>
<v Speaker 2>um,</v>

966
00:49:38.070 --> 00:49:42.120
<v Speaker 2>build our algorithms on top of that.</v>
<v Speaker 2>That's open source and uh,</v>

967
00:49:42.121 --> 00:49:47.121
<v Speaker 2>we felt and there was a demand for some </v>
<v Speaker 2>of the nature of reviewers and editors </v>

968
00:49:47.121 --> 00:49:47.700
<v Speaker 2>that,</v>
<v Speaker 2>um,</v>

969
00:49:47.730 --> 00:49:52.730
<v Speaker 2>you know,</v>
<v Speaker 2>it'd be nice if we could release our </v>

970
00:49:52.730 --> 00:49:52.730
<v Speaker 2>code.</v>
<v Speaker 2>So we thought about it and we decided in</v>

971
00:49:52.730 --> 00:49:54.570
<v Speaker 2>that case that was fine.</v>
<v Speaker 2>Um,</v>

972
00:49:54.600 --> 00:49:55.470
<v Speaker 2>but,</v>
<v Speaker 2>uh,</v>

973
00:49:55.471 --> 00:49:57.330
<v Speaker 2>you know,</v>
<v Speaker 2>that that may not always be the case for</v>

974
00:49:57.331 --> 00:50:02.331
<v Speaker 2>the stuff we do a and we'll obviously </v>
<v Speaker 2>have to consider that on a case by case </v>

975
00:50:02.331 --> 00:50:02.910
<v Speaker 2>basis,</v>
<v Speaker 2>but in general where we can,</v>

976
00:50:02.911 --> 00:50:07.911
<v Speaker 2>we like to engage and support the </v>
<v Speaker 2>general academic community and we think </v>

977
00:50:07.911 --> 00:50:11.460
<v Speaker 2>it's important that knowledge is shared </v>
<v Speaker 2>and I think that's the way that humanity</v>

978
00:50:11.461 --> 00:50:13.380
<v Speaker 2>can advance as quickly as possible.</v>

979
00:50:15.290 --> 00:50:20.290
<v Speaker 6>And the second road,</v>
<v Speaker 6>you're one of the largest brains on the </v>

980
00:50:20.290 --> 00:50:23.260
<v Speaker 6>planet and I'm good now bought here and </v>
<v Speaker 6>um,</v>

981
00:50:23.580 --> 00:50:28.580
<v Speaker 6>I'm gonna ask you that question,</v>
<v Speaker 6>which I'm sure you're expecting Stephen </v>

982
00:50:28.910 --> 00:50:28.910
<v Speaker 6>Hawking</v>

983
00:50:28.940 --> 00:50:33.940
<v Speaker 8>thing that the concern about ai that um,</v>
<v Speaker 8>once you let the genie out of the </v>

984
00:50:34.011 --> 00:50:35.500
<v Speaker 8>bottle,</v>
<v Speaker 8>um,</v>

985
00:50:36.160 --> 00:50:41.160
<v Speaker 8>we're all fucked.</v>
<v Speaker 8>What are you doing to try?</v>

986
00:50:45.820 --> 00:50:46.900
<v Speaker 8>This is the regular.</v>

987
00:50:47.530 --> 00:50:48.370
<v Speaker 2>Yes,</v>
<v Speaker 2>sure.</v>

988
00:50:48.410 --> 00:50:49.310
<v Speaker 2>I mean,</v>
<v Speaker 2>I,</v>

989
00:50:49.400 --> 00:50:51.480
<v Speaker 2>I've actually spoken,</v>
<v Speaker 2>um,</v>

990
00:50:51.630 --> 00:50:56.630
<v Speaker 2>uh,</v>
<v Speaker 2>I had a long chat with Stephen Hawking </v>

991
00:50:56.630 --> 00:50:58.250
<v Speaker 2>about this a few months ago and um,</v>
<v Speaker 2>I think he was,</v>

992
00:50:58.730 --> 00:50:59.340
<v Speaker 2>well,</v>
<v Speaker 2>he was,</v>

993
00:50:59.341 --> 00:51:01.300
<v Speaker 2>I think he lives very enjoyable and I </v>
<v Speaker 2>think he,</v>

994
00:51:01.301 --> 00:51:02.730
<v Speaker 2>he,</v>
<v Speaker 2>we spent hours together.</v>

995
00:51:02.731 --> 00:51:04.350
<v Speaker 2>We only spend half an hour,</v>
<v Speaker 2>but he was,</v>

996
00:51:04.351 --> 00:51:09.351
<v Speaker 2>he had so many questions and I think he </v>
<v Speaker 2>was quite reassured after we talked </v>

997
00:51:09.351 --> 00:51:11.250
<v Speaker 2>about how we will,</v>
<v Speaker 2>we specifically were approaching it.</v>

998
00:51:11.580 --> 00:51:12.780
<v Speaker 2>Um,</v>
<v Speaker 2>and I think,</v>

999
00:51:12.781 --> 00:51:13.260
<v Speaker 2>look,</v>
<v Speaker 2>you know,</v>

1000
00:51:13.261 --> 00:51:15.360
<v Speaker 2>there are big,</v>
<v Speaker 2>big issues here,</v>

1001
00:51:15.361 --> 00:51:19.500
<v Speaker 2>very big issues about um,</v>
<v Speaker 2>autonomous learning systems.</v>

1002
00:51:19.501 --> 00:51:22.110
<v Speaker 2>What goals should we give them?</v>
<v Speaker 2>What value system should we give them?</v>

1003
00:51:22.111 --> 00:51:27.111
<v Speaker 2>How can we make sure that,</v>
<v Speaker 2>that those are exactly what we want and </v>

1004
00:51:27.111 --> 00:51:28.320
<v Speaker 2>there are very tough pieces of research </v>
<v Speaker 2>that needs to be done.</v>

1005
00:51:28.670 --> 00:51:30.780
<v Speaker 2>Um,</v>
<v Speaker 2>there hasn't been much work done in that</v>

1006
00:51:30.781 --> 00:51:35.781
<v Speaker 2>area yet,</v>
<v Speaker 2>partly because there'd be no systems to </v>

1007
00:51:35.781 --> 00:51:35.781
<v Speaker 2>really try this out on.</v>

1008
00:51:35.781 --> 00:51:36.570
<v Speaker 2>So it's all been thought experiments and</v>
<v Speaker 2>I think if you,</v>

1009
00:51:36.571 --> 00:51:37.380
<v Speaker 2>do,</v>
<v Speaker 2>you know,</v>

1010
00:51:37.410 --> 00:51:42.410
<v Speaker 2>mostly the people thinking about this </v>
<v Speaker 2>and worrying about this to that extent </v>

1011
00:51:42.410 --> 00:51:45.860
<v Speaker 2>or not in the AI field right there.</v>
<v Speaker 2>Either philosophers or there other very </v>

1012
00:51:45.860 --> 00:51:50.450
<v Speaker 2>famous scientists or,</v>
<v Speaker 2>or industrialist but not actually </v>

1013
00:51:50.450 --> 00:51:51.780
<v Speaker 2>working on ai themselves.</v>
<v Speaker 2>And if they were working,</v>

1014
00:51:51.781 --> 00:51:54.810
<v Speaker 2>I think they would see that the problems</v>
<v Speaker 2>are much more prosaic at the moment.</v>

1015
00:51:55.200 --> 00:51:56.120
<v Speaker 2>And it's easy,</v>
<v Speaker 2>I think,</v>

1016
00:51:56.160 --> 00:51:58.920
<v Speaker 2>to get carried away with science fiction</v>
<v Speaker 2>scenarios that are,</v>

1017
00:51:58.950 --> 00:52:00.150
<v Speaker 2>you know,</v>
<v Speaker 2>many decades away.</v>

1018
00:52:00.420 --> 00:52:01.860
<v Speaker 2>My,</v>
<v Speaker 2>I have confidence that,</v>

1019
00:52:01.970 --> 00:52:06.970
<v Speaker 2>um,</v>
<v Speaker 2>as we get bill more powerful systems </v>

1020
00:52:06.970 --> 00:52:09.470
<v Speaker 2>will have much better ideas about the </v>
<v Speaker 2>answers to these questions that I just </v>

1021
00:52:09.470 --> 00:52:10.680
<v Speaker 2>talked about,</v>
<v Speaker 2>value systems and so on.</v>

1022
00:52:10.860 --> 00:52:12.120
<v Speaker 2>Uh,</v>
<v Speaker 2>and um,</v>

1023
00:52:12.240 --> 00:52:17.240
<v Speaker 2>you know,</v>
<v Speaker 2>mathematical proofs of empirical work </v>

1024
00:52:17.240 --> 00:52:17.240
<v Speaker 2>that will,</v>
<v Speaker 2>um,</v>

1025
00:52:17.240 --> 00:52:19.950
<v Speaker 2>allow us to have much better idea of how</v>
<v Speaker 2>to keep these systems on the control</v>

1026
00:52:20.230 --> 00:52:21.910
<v Speaker 8>when I'm pleased to see that you've got </v>
<v Speaker 8>the,</v>

1027
00:52:21.911 --> 00:52:26.911
<v Speaker 8>um,</v>
<v Speaker 8>the ethics committee that onboard and </v>

1028
00:52:26.911 --> 00:52:26.911
<v Speaker 8>you're thinking about these issues </v>
<v Speaker 8>issues,</v>

1029
00:52:26.911 --> 00:52:29.730
<v Speaker 8>but you have taken the Yankee dollar.</v>
<v Speaker 8>And I'm,</v>

1030
00:52:30.010 --> 00:52:35.010
<v Speaker 8>I am worried about this because you are </v>
<v Speaker 8>so smart and I hope that everything you </v>

1031
00:52:35.010 --> 00:52:38.590
<v Speaker 8>do actually improves the society route </v>
<v Speaker 8>kills us off.</v>

1032
00:52:39.090 --> 00:52:40.020
<v Speaker 2>Well,</v>
<v Speaker 2>so do I.</v>

1033
00:52:40.210 --> 00:52:40.930
<v Speaker 2>But uh,</v>
<v Speaker 2>but,</v>

1034
00:52:40.931 --> 00:52:41.690
<v Speaker 2>uh,</v>
<v Speaker 2>um,</v>

1035
00:52:41.920 --> 00:52:42.440
<v Speaker 2>you know,</v>
<v Speaker 2>I,</v>

1036
00:52:42.441 --> 00:52:43.540
<v Speaker 2>I think ai,</v>
<v Speaker 2>you know,</v>

1037
00:52:43.541 --> 00:52:46.720
<v Speaker 2>it could be the greatest thing for </v>
<v Speaker 2>humanity and the sense of if we build it</v>

1038
00:52:46.721 --> 00:52:51.721
<v Speaker 2>right,</v>
<v Speaker 2>we'll solve all these big issues that </v>

1039
00:52:51.721 --> 00:52:56.520
<v Speaker 2>corporate responsibility versus showing </v>
<v Speaker 2>through.</v>

1040
00:52:56.621 --> 00:52:58.270
<v Speaker 2>I think that's a big one,</v>
<v Speaker 2>isn't it,</v>

1041
00:52:58.271 --> 00:53:00.820
<v Speaker 2>in terms of where power lies in.</v>
<v Speaker 2>Sure.</v>

1042
00:53:00.850 --> 00:53:03.280
<v Speaker 2>I mean I should probably make a little </v>
<v Speaker 2>bit about that.</v>

1043
00:53:03.281 --> 00:53:07.060
<v Speaker 2>So obviously we spent a long time doing </v>
<v Speaker 2>due diligence ourselves on Google.</v>

1044
00:53:07.090 --> 00:53:12.090
<v Speaker 2>Right.</v>
<v Speaker 2>And we had a lot of other options </v>

1045
00:53:12.090 --> 00:53:13.531
<v Speaker 2>including stay independent and we </v>
<v Speaker 2>decided to join forces with them partly </v>

1046
00:53:13.531 --> 00:53:16.741
<v Speaker 2>because the people higher up at Google </v>
<v Speaker 2>agreed with things like the ethics </v>

1047
00:53:16.741 --> 00:53:19.741
<v Speaker 2>committee and thought it was a good idea</v>
<v Speaker 2>that governed the use of the technology </v>

1048
00:53:19.741 --> 00:53:21.430
<v Speaker 2>of deep mines technology.</v>
<v Speaker 2>We've already out ruled out things,</v>

1049
00:53:21.431 --> 00:53:25.060
<v Speaker 2>obvious things like military or </v>
<v Speaker 2>intelligence applications.</v>

1050
00:53:25.090 --> 00:53:26.130
<v Speaker 2>Um,</v>
<v Speaker 2>so,</v>

1051
00:53:26.131 --> 00:53:28.590
<v Speaker 2>you know,</v>
<v Speaker 2>the by default deep mind staff doesn't,</v>

1052
00:53:28.620 --> 00:53:31.320
<v Speaker 2>cannot be used for those things.</v>
<v Speaker 2>And then obviously we,</v>

1053
00:53:31.321 --> 00:53:36.321
<v Speaker 2>you know,</v>
<v Speaker 2>we've had our inaugural meeting of the </v>

1054
00:53:36.321 --> 00:53:37.560
<v Speaker 2>committee ethics committee.</v>
<v Speaker 2>There are very big illuminaries on that,</v>

1055
00:53:37.740 --> 00:53:42.740
<v Speaker 2>many of whom are some of the people that</v>
<v Speaker 2>you've mentioned who are worried about </v>

1056
00:53:42.740 --> 00:53:43.890
<v Speaker 2>this stuff,</v>
<v Speaker 2>not just the people who think positively</v>

1057
00:53:43.891 --> 00:53:48.891
<v Speaker 2>about it.</v>
<v Speaker 2>And a big part of that actually because </v>

1058
00:53:48.891 --> 00:53:48.891
<v Speaker 2>you know,</v>
<v Speaker 2>we are decades away,</v>

1059
00:53:48.891 --> 00:53:53.181
<v Speaker 2>is to just start educating everyone on </v>
<v Speaker 2>what the real issues are and separate </v>

1060
00:53:53.181 --> 00:53:54.660
<v Speaker 2>sort of fact from science fiction.</v>
<v Speaker 2>Um,</v>

1061
00:53:54.750 --> 00:53:59.750
<v Speaker 2>and I think that's the first time point </v>
<v Speaker 2>and then we can actually get to the hub </v>

1062
00:53:59.750 --> 00:54:01.440
<v Speaker 2>of the really core technical difficult </v>
<v Speaker 2>questions there are.</v>

1063
00:54:02.280 --> 00:54:03.250
<v Speaker 2>And there are some,</v>
<v Speaker 2>but I,</v>

1064
00:54:03.260 --> 00:54:06.960
<v Speaker 2>I'm very confident if we apply enough </v>
<v Speaker 2>brainpower onto it with enough time,</v>

1065
00:54:07.200 --> 00:54:08.730
<v Speaker 2>uh,</v>
<v Speaker 2>will solve those problems.</v>

1066
00:54:09.090 --> 00:54:10.430
<v Speaker 6>Right.</v>
<v Speaker 6>You,</v>

1067
00:54:11.390 --> 00:54:13.560
<v Speaker 6>you've been in Google now for about a </v>
<v Speaker 6>year.</v>

1068
00:54:13.850 --> 00:54:14.610
<v Speaker 6>Um,</v>
<v Speaker 6>can you,</v>

1069
00:54:14.640 --> 00:54:19.640
<v Speaker 6>can you give us a couple of examples or </v>
<v Speaker 6>anecdotes about how deep mind has </v>

1070
00:54:19.741 --> 00:54:24.741
<v Speaker 6>changed the company?</v>
<v Speaker 6>I'm taking over some processes changed </v>

1071
00:54:24.741 --> 00:54:29.481
<v Speaker 6>the way the company works your going </v>
<v Speaker 6>forward and just to tag onto the ethics </v>

1072
00:54:30.031 --> 00:54:32.490
<v Speaker 6>committee.</v>
<v Speaker 6>Why haven't you publicized or published?</v>

1073
00:54:32.491 --> 00:54:33.780
<v Speaker 6>Who's,</v>
<v Speaker 6>who's on it?</v>

1074
00:54:34.690 --> 00:54:35.340
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

1075
00:54:35.470 --> 00:54:40.470
<v Speaker 2>first question is I'm almost,</v>
<v Speaker 2>nothing's changed and that's the whole </v>

1076
00:54:40.470 --> 00:54:40.780
<v Speaker 2>point of it.</v>
<v Speaker 2>That was one of the main agreement.</v>

1077
00:54:40.781 --> 00:54:41.480
<v Speaker 2>So we,</v>
<v Speaker 2>we,</v>

1078
00:54:41.610 --> 00:54:46.610
<v Speaker 2>our,</v>
<v Speaker 2>our headquarters is still in the UK and </v>

1079
00:54:46.610 --> 00:54:46.960
<v Speaker 2>tinkering around King's cross.</v>
<v Speaker 2>We've built,</v>

1080
00:54:46.961 --> 00:54:51.961
<v Speaker 2>invested in the research team there,</v>
<v Speaker 2>so the whole of the minus still UK side </v>

1081
00:54:52.180 --> 00:54:53.560
<v Speaker 2>and uh,</v>
<v Speaker 2>you know,</v>

1082
00:54:53.561 --> 00:54:58.561
<v Speaker 2>we're very,</v>
<v Speaker 2>we work as a kind of semi autonomous </v>

1083
00:54:58.561 --> 00:55:01.410
<v Speaker 2>type of unit.</v>
<v Speaker 2>The plus size are the amount of compute </v>

1084
00:55:01.410 --> 00:55:01.430
<v Speaker 2>power that we have access to,</v>
<v Speaker 2>uh,</v>

1085
00:55:01.450 --> 00:55:04.560
<v Speaker 2>has really accelerated our progress and </v>
<v Speaker 2>obviously the other resources that.</v>

1086
00:55:04.880 --> 00:55:06.290
<v Speaker 6>Sorry,</v>
<v Speaker 6>I meant the other way around.</v>

1087
00:55:06.291 --> 00:55:09.200
<v Speaker 6>How is deepmind to,</v>
<v Speaker 6>to Google as a come?</v>

1088
00:55:09.260 --> 00:55:09.860
<v Speaker 2>Oh,</v>
<v Speaker 2>I see.</v>

1089
00:55:09.980 --> 00:55:11.180
<v Speaker 2>Um,</v>
<v Speaker 2>well,</v>

1090
00:55:11.181 --> 00:55:11.980
<v Speaker 2>so,</v>
<v Speaker 2>um,</v>

1091
00:55:12.080 --> 00:55:14.050
<v Speaker 2>that's harder to say.</v>
<v Speaker 2>I mean Google is very big,</v>

1092
00:55:14.580 --> 00:55:19.580
<v Speaker 2>but I think that we have actually a </v>
<v Speaker 2>effect to that in some senses a the way </v>

1093
00:55:20.001 --> 00:55:22.910
<v Speaker 2>that some other parts of Google research</v>
<v Speaker 2>do that work.</v>

1094
00:55:23.030 --> 00:55:26.550
<v Speaker 2>So there's actually thousands of people </v>
<v Speaker 2>in Google research and there's thousands</v>

1095
00:55:26.551 --> 00:55:28.870
<v Speaker 2>of people working on machine learning.</v>
<v Speaker 2>Um,</v>

1096
00:55:28.970 --> 00:55:33.970
<v Speaker 2>but we were sort of have a more coherent</v>
<v Speaker 2>a specific mission than the more applied</v>

1097
00:55:35.301 --> 00:55:37.070
<v Speaker 2>machine learning against done elsewhere </v>
<v Speaker 2>and google.</v>

1098
00:55:37.220 --> 00:55:42.220
<v Speaker 2>So I think we bring,</v>
<v Speaker 2>we bring together a kind of longer term </v>

1099
00:55:42.220 --> 00:55:42.450
<v Speaker 2>research focus that,</v>
<v Speaker 2>um,</v>

1100
00:55:42.470 --> 00:55:47.470
<v Speaker 2>I think maybe google wants more of now </v>
<v Speaker 2>and that requires quite different </v>

1101
00:55:47.470 --> 00:55:49.520
<v Speaker 2>organizational structures and management</v>
<v Speaker 2>processes,</v>

1102
00:55:49.521 --> 00:55:50.230
<v Speaker 2>which,</v>
<v Speaker 2>um,</v>

1103
00:55:50.480 --> 00:55:51.350
<v Speaker 2>you know,</v>
<v Speaker 2>some of,</v>

1104
00:55:51.370 --> 00:55:56.370
<v Speaker 2>uh,</v>
<v Speaker 2>some of which has been adopted over in </v>

1105
00:55:56.370 --> 00:55:56.370
<v Speaker 2>mountain view in Silicon Valley.</v>
<v Speaker 2>Now.</v>

1106
00:55:56.370 --> 00:55:58.220
<v Speaker 2>I'm,</v>
<v Speaker 2>so your second question was about the,</v>

1107
00:55:58.221 --> 00:55:59.360
<v Speaker 2>why don't we publicize stuff?</v>

1108
00:55:59.540 --> 00:56:02.290
<v Speaker 2>Well,</v>
<v Speaker 2>firstly I'm a,</v>

1109
00:56:02.360 --> 00:56:04.760
<v Speaker 2>you know,</v>
<v Speaker 2>we're very early days and uh,</v>

1110
00:56:04.800 --> 00:56:07.070
<v Speaker 2>there's a lot of scrutiny on this and </v>
<v Speaker 2>um,</v>

1111
00:56:07.120 --> 00:56:11.100
<v Speaker 2>there's nothing at the moment,</v>
<v Speaker 2>it's about simply about educating people</v>

1112
00:56:11.120 --> 00:56:13.460
<v Speaker 2>are ever getting everyone up to speed </v>
<v Speaker 2>with the issues.</v>

1113
00:56:13.790 --> 00:56:16.190
<v Speaker 2>Um,</v>
<v Speaker 2>once you start making things public,</v>

1114
00:56:16.310 --> 00:56:18.890
<v Speaker 2>then immediately that changes,</v>
<v Speaker 2>that can change the debate.</v>

1115
00:56:19.070 --> 00:56:24.070
<v Speaker 2>And I wanted to have a period of um,</v>
<v Speaker 2>sort of quiet behind the scenes,</v>

1116
00:56:25.060 --> 00:56:26.170
<v Speaker 2>a calm,</v>
<v Speaker 2>calm,</v>

1117
00:56:26.171 --> 00:56:31.171
<v Speaker 2>collected debate before we additionally </v>
<v Speaker 2>on ourselves this additional sort of </v>

1118
00:56:31.241 --> 00:56:36.241
<v Speaker 2>public scrutiny.</v>
<v Speaker 2>So at some point I think we will </v>

1119
00:56:36.241 --> 00:56:36.241
<v Speaker 2>announce who,</v>
<v Speaker 2>you know,</v>

1120
00:56:36.241 --> 00:56:40.530
<v Speaker 2>these people are,</v>
<v Speaker 2>and also a little bit about what the </v>

1121
00:56:40.530 --> 00:56:40.900
<v Speaker 2>issues are that are being discussed.</v>
<v Speaker 2>Having said that,</v>

1122
00:56:40.901 --> 00:56:45.901
<v Speaker 2>we already do lots of public things.</v>
<v Speaker 2>So that was a big conference in Puerto </v>

1123
00:56:46.540 --> 00:56:51.540
<v Speaker 2>Rico that was talking about ai ethics </v>
<v Speaker 2>and safety as another one at New York </v>

1124
00:56:51.540 --> 00:56:56.490
<v Speaker 2>University in January that we're </v>
<v Speaker 2>sponsoring and I'm keynoting and I'm on </v>

1125
00:56:56.490 --> 00:56:56.920
<v Speaker 2>a program committee of,</v>
<v Speaker 2>along with Facebook,</v>

1126
00:56:57.100 --> 00:56:59.980
<v Speaker 2>uh,</v>
<v Speaker 2>the heads of ais there and Microsoft and</v>

1127
00:56:59.981 --> 00:57:04.981
<v Speaker 2>some of the other companies.</v>
<v Speaker 2>So I think probably the next stage next </v>

1128
00:57:04.981 --> 00:57:05.290
<v Speaker 2>year will be to create a cross industry </v>
<v Speaker 2>panel,</v>

1129
00:57:05.510 --> 00:57:08.410
<v Speaker 2>um,</v>
<v Speaker 2>and bring together all the big companies</v>

1130
00:57:08.411 --> 00:57:13.411
<v Speaker 2>and academic labs that are working on </v>
<v Speaker 2>this in addition to our own internal </v>

1131
00:57:13.411 --> 00:57:14.030
<v Speaker 2>committee with your list.</v>
<v Speaker 2>Let's correct</v>

1132
00:57:14.090 --> 00:57:15.560
<v Speaker 1>for a few more.</v>
<v Speaker 1>We've got about 10 minutes.</v>

1133
00:57:15.561 --> 00:57:18.660
<v Speaker 1>So I think someone's got a mike here </v>
<v Speaker 1>though and then will go up to mother.</v>

1134
00:57:19.100 --> 00:57:19.800
<v Speaker 1>Thank you.</v>
<v Speaker 1>Yes,</v>

1135
00:57:19.830 --> 00:57:22.490
<v Speaker 1>that was a brilliant presentation.</v>
<v Speaker 1>Thank you very much for that.</v>

1136
00:57:22.960 --> 00:57:26.480
<v Speaker 1>I'm a was an engineer.</v>
<v Speaker 1>I'm now a slightly aged academic.</v>

1137
00:57:26.930 --> 00:57:31.930
<v Speaker 1>Um,</v>
<v Speaker 1>we work on the general a video gaming </v>

1138
00:57:31.930 --> 00:57:34.040
<v Speaker 1>machines,</v>
<v Speaker 1>so I appreciate that very much.</v>

1139
00:57:34.041 --> 00:57:36.950
<v Speaker 1>But when you go the next day up to </v>
<v Speaker 1>imagination,</v>

1140
00:57:37.240 --> 00:57:41.900
<v Speaker 1>then that must be so many individual </v>
<v Speaker 1>random coordinates,</v>

1141
00:57:41.901 --> 00:57:46.901
<v Speaker 1>if you like,</v>
<v Speaker 1>because I think we all imagined </v>

1142
00:57:46.901 --> 00:57:46.901
<v Speaker 1>differently,</v>
<v Speaker 1>um,</v>

1143
00:57:46.901 --> 00:57:50.260
<v Speaker 1>that you'll spend an infinite amount of </v>
<v Speaker 1>time trying to analyze these to actually</v>

1144
00:57:50.631 --> 00:57:53.750
<v Speaker 1>make machines if you're like,</v>
<v Speaker 1>imagine implant fashion.</v>

1145
00:57:53.751 --> 00:57:56.330
<v Speaker 1>So how do,</v>
<v Speaker 1>how do you cope with these coordinates?</v>

1146
00:57:56.331 --> 00:58:01.331
<v Speaker 1>You can't build it as well because a lot</v>
<v Speaker 1>of the audience and for the television </v>

1147
00:58:01.331 --> 00:58:01.331
<v Speaker 1>audience here,</v>
<v Speaker 1>I can see,</v>

1148
00:58:01.331 --> 00:58:03.520
<v Speaker 1>I suspect there was a bit of a shudder </v>
<v Speaker 1>around east kidding.</v>

1149
00:58:03.521 --> 00:58:05.480
<v Speaker 1>He's the creative,</v>
<v Speaker 1>which is,</v>

1150
00:58:05.490 --> 00:58:06.440
<v Speaker 1>yeah,</v>
<v Speaker 1>that's a bit clunky.</v>

1151
00:58:06.441 --> 00:58:11.030
<v Speaker 1>We should kind of merging the course </v>
<v Speaker 1>versus when the first director,</v>

1152
00:58:11.660 --> 00:58:13.230
<v Speaker 1>the first writer,</v>
<v Speaker 1>when those,</v>

1153
00:58:13.310 --> 00:58:15.040
<v Speaker 1>the invite the points in the </v>
<v Speaker 1>environment,</v>

1154
00:58:15.060 --> 00:58:18.640
<v Speaker 1>the choices become financial versus a </v>
<v Speaker 1>space invaders.</v>

1155
00:58:18.900 --> 00:58:21.570
<v Speaker 1>Exactly.</v>
<v Speaker 1>It's like the rice on the chess board.</v>

1156
00:58:21.930 --> 00:58:22.920
<v Speaker 2>Yeah.</v>
<v Speaker 2>So I think,</v>

1157
00:58:22.921 --> 00:58:27.921
<v Speaker 2>uh,</v>
<v Speaker 2>I think most people's jobs in here safe </v>

1158
00:58:27.921 --> 00:58:29.770
<v Speaker 2>for a long time ago is quite hard.</v>
<v Speaker 2>So I don't think it's going to be any </v>

1159
00:58:29.770 --> 00:58:30.030
<v Speaker 2>directors,</v>
<v Speaker 2>you know,</v>

1160
00:58:30.031 --> 00:58:31.440
<v Speaker 2>directing something,</v>
<v Speaker 2>you know,</v>

1161
00:58:31.441 --> 00:58:33.210
<v Speaker 2>the quality of Ridley Scott or </v>
<v Speaker 2>something,</v>

1162
00:58:33.500 --> 00:58:34.770
<v Speaker 2>you know,</v>
<v Speaker 2>that's probably going to be one of the,</v>

1163
00:58:34.771 --> 00:58:37.070
<v Speaker 2>if,</v>
<v Speaker 2>if ever one of the last things that that</v>

1164
00:58:37.110 --> 00:58:42.110
<v Speaker 2>competes will be able to do.</v>
<v Speaker 2>So we asked talking about very </v>

1165
00:58:42.110 --> 00:58:42.110
<v Speaker 2>constrained things where,</v>
<v Speaker 2>um,</v>

1166
00:58:42.110 --> 00:58:47.000
<v Speaker 2>you know,</v>
<v Speaker 2>that's a very difficult thing that </v>

1167
00:58:47.000 --> 00:58:47.280
<v Speaker 2>humans of course do better than,</v>
<v Speaker 2>than way better than computers is we,</v>

1168
00:58:47.281 --> 00:58:52.281
<v Speaker 2>you know,</v>
<v Speaker 2>they can have this rudimentary kind of </v>

1169
00:58:52.281 --> 00:58:53.940
<v Speaker 2>brute force imagination.</v>
<v Speaker 2>But one of the big things that humans do</v>

1170
00:58:53.970 --> 00:58:56.040
<v Speaker 2>is they have aesthetic judgment,</v>
<v Speaker 2>right?</v>

1171
00:58:56.220 --> 00:59:01.220
<v Speaker 2>They know that I'm not,</v>
<v Speaker 2>all Paul's are equal and some of them </v>

1172
00:59:01.220 --> 00:59:02.790
<v Speaker 2>are likely to be more fruitful than </v>
<v Speaker 2>others.</v>

1173
00:59:02.850 --> 00:59:07.850
<v Speaker 2>Even if you compare chess,</v>
<v Speaker 2>grandmaster playing the chess compared </v>

1174
00:59:07.850 --> 00:59:08.220
<v Speaker 2>to a computer,</v>
<v Speaker 2>they,</v>

1175
00:59:08.240 --> 00:59:08.910
<v Speaker 2>they,</v>
<v Speaker 2>you know,</v>

1176
00:59:08.911 --> 00:59:12.030
<v Speaker 2>computer might look at millions of moves</v>
<v Speaker 2>to make that one decision.</v>

1177
00:59:12.180 --> 00:59:15.570
<v Speaker 2>Whereas a transplant not only look at a </v>
<v Speaker 2>few hundred but judicial ones,</v>

1178
00:59:15.720 --> 00:59:18.970
<v Speaker 2>and they in some sense our brains even </v>
<v Speaker 2>filter out a,</v>

1179
00:59:19.020 --> 00:59:24.020
<v Speaker 2>our low level power brain or any of the </v>
<v Speaker 2>kind of moves or trajectories that are </v>

1180
00:59:24.410 --> 00:59:26.780
<v Speaker 2>not going to yield anything useful.</v>
<v Speaker 2>Um,</v>

1181
00:59:26.810 --> 00:59:28.040
<v Speaker 2>and uh,</v>
<v Speaker 2>you know,</v>

1182
00:59:28.050 --> 00:59:28.300
<v Speaker 2>the,</v>

1183
00:59:28.420 --> 00:59:30.100
<v Speaker 1>when you do that filtrate,</v>
<v Speaker 1>are you working on.</v>

1184
00:59:30.300 --> 00:59:35.300
<v Speaker 1>Well,</v>
<v Speaker 1>we are talking that filtration part of </v>

1185
00:59:35.300 --> 00:59:35.300
<v Speaker 1>that is,</v>
<v Speaker 1>is to do with how well you</v>

1186
00:59:35.300 --> 00:59:39.060
<v Speaker 2>model of the world that you're in.</v>
<v Speaker 2>So if you're better at modeling the </v>

1187
00:59:39.060 --> 00:59:42.031
<v Speaker 2>world,</v>
<v Speaker 2>then what that means is you should make </v>

1188
00:59:42.031 --> 00:59:44.460
<v Speaker 2>better predictions about what are going </v>
<v Speaker 2>to be useful things to spend your </v>

1189
00:59:44.460 --> 00:59:45.760
<v Speaker 2>compute time,</v>
<v Speaker 2>uh,</v>

1190
00:59:45.790 --> 00:59:48.390
<v Speaker 2>imagining or thinking about a and at a </v>
<v Speaker 2>moment where,</v>

1191
00:59:48.391 --> 00:59:49.900
<v Speaker 2>you know,</v>
<v Speaker 2>we're still very early stages of that.</v>

1192
00:59:51.270 --> 00:59:52.940
<v Speaker 9>Sorry.</v>
<v Speaker 9>Hi,</v>

1193
00:59:53.250 --> 00:59:55.030
<v Speaker 9>David Abraham from Channel Four.</v>
<v Speaker 9>Um,</v>

1194
00:59:55.530 --> 00:59:58.530
<v Speaker 9>you touched on the challenge of,</v>
<v Speaker 9>um,</v>

1195
00:59:59.160 --> 01:00:04.160
<v Speaker 9>how many choices people have,</v>
<v Speaker 9>an entertainment and something that we </v>

1196
01:00:04.631 --> 01:00:06.900
<v Speaker 9>in our industry is spending a lot of </v>
<v Speaker 9>time thinking about.</v>

1197
01:00:07.570 --> 01:00:09.210
<v Speaker 9>Um,</v>
<v Speaker 9>are you,</v>

1198
01:00:09.250 --> 01:00:14.070
<v Speaker 9>um,</v>
<v Speaker 9>working more specifically on the area of</v>

1199
01:00:14.100 --> 01:00:18.180
<v Speaker 9>recommendation engines and are you going</v>
<v Speaker 9>to be,</v>

1200
01:00:18.420 --> 01:00:23.420
<v Speaker 9>as it were,</v>
<v Speaker 9>capturing the power of that algorithm </v>

1201
01:00:23.420 --> 01:00:23.420
<v Speaker 9>and behalf of Google?</v>

1202
01:00:23.530 --> 01:00:25.780
<v Speaker 2>Yeah,</v>
<v Speaker 2>we are looking at recommendation systems</v>

1203
01:00:25.840 --> 01:00:27.640
<v Speaker 2>and um,</v>
<v Speaker 2>you know,</v>

1204
01:00:27.910 --> 01:00:30.670
<v Speaker 2>uh,</v>
<v Speaker 2>in all forms actually all sorts of forms</v>

1205
01:00:30.910 --> 01:00:33.100
<v Speaker 2>and a,</v>
<v Speaker 2>I think it's a very interesting area and</v>

1206
01:00:33.101 --> 01:00:35.590
<v Speaker 2>it's something that our technology is </v>
<v Speaker 2>quite,</v>

1207
01:00:35.740 --> 01:00:37.300
<v Speaker 2>uh,</v>
<v Speaker 2>quite sort of applicable to.</v>

1208
01:00:37.720 --> 01:00:39.130
<v Speaker 2>Again,</v>
<v Speaker 2>it's about,</v>

1209
01:00:39.190 --> 01:00:44.190
<v Speaker 2>you know,</v>
<v Speaker 2>can you model a user journeys and </v>

1210
01:00:44.190 --> 01:00:44.980
<v Speaker 2>trajectories through things and in a way</v>
<v Speaker 2>that,</v>

1211
01:00:44.981 --> 01:00:45.700
<v Speaker 2>um,</v>
<v Speaker 2>you know,</v>

1212
01:00:45.701 --> 01:00:49.480
<v Speaker 2>then delivers much more compelling </v>
<v Speaker 2>content or recommendations and I think,</v>

1213
01:00:49.720 --> 01:00:50.740
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

1214
01:00:50.741 --> 01:00:52.690
<v Speaker 2>the current systems we have are not good</v>
<v Speaker 2>enough.</v>

1215
01:00:52.850 --> 01:00:54.370
<v Speaker 2>Um,</v>
<v Speaker 2>and you know,</v>

1216
01:00:54.371 --> 01:00:55.630
<v Speaker 2>we're,</v>
<v Speaker 2>we're experimenting in that.</v>

1217
01:00:55.631 --> 01:00:56.240
<v Speaker 2>Again,</v>
<v Speaker 2>we don't,</v>

1218
01:00:56.280 --> 01:01:01.280
<v Speaker 2>we're,</v>
<v Speaker 2>we're quite early days with that and </v>

1219
01:01:01.280 --> 01:01:01.280
<v Speaker 2>we're looking at that for things both </v>
<v Speaker 2>internally at Google and external</v>

1220
01:01:02.270 --> 01:01:07.270
<v Speaker 1>dcx external because I think that will </v>
<v Speaker 1>be deeply intriguing to a number of us </v>

1221
01:01:07.270 --> 01:01:11.081
<v Speaker 1>in the room who are working in the media</v>
<v Speaker 1>business about how to serve up stuff in </v>

1222
01:01:11.081 --> 01:01:11.750
<v Speaker 1>a world where choices.</v>
<v Speaker 1>Yeah.</v>

1223
01:01:11.780 --> 01:01:15.290
<v Speaker 1>Exploded.</v>
<v Speaker 1>And the general application of those few</v>

1224
01:01:15.290 --> 01:01:17.840
<v Speaker 1>years know,</v>
<v Speaker 1>think it'd be announcing stuff,</v>

1225
01:01:17.870 --> 01:01:22.870
<v Speaker 1>products coming out.</v>
<v Speaker 1>I think maybe it might be the wrong </v>

1226
01:01:22.870 --> 01:01:22.870
<v Speaker 1>word,</v>
<v Speaker 1>forgive my ignorance,</v>

1227
01:01:22.870 --> 01:01:25.430
<v Speaker 1>but systems by which the likes of </v>
<v Speaker 1>channel for the BBC,</v>

1228
01:01:25.431 --> 01:01:30.431
<v Speaker 1>other broadcasts in the room,</v>
<v Speaker 1>independent companies conserve their </v>

1229
01:01:30.431 --> 01:01:30.431
<v Speaker 1>content that we think that's not far </v>
<v Speaker 1>away.</v>

1230
01:01:30.431 --> 01:01:30.431
<v Speaker 1>Yeah.</v>

1231
01:01:30.431 --> 01:01:34.560
<v Speaker 2>Yeah.</v>
<v Speaker 2>I think in the next couple of years </v>

1232
01:01:34.560 --> 01:01:35.060
<v Speaker 2>you'll start seeing under the hood a </v>
<v Speaker 2>algorithms helping the,</v>

1233
01:01:35.061 --> 01:01:40.061
<v Speaker 2>these kinds of recommendation systems </v>
<v Speaker 2>and then maybe four or five years our </v>

1234
01:01:40.061 --> 01:01:43.201
<v Speaker 2>actual hope,</v>
<v Speaker 2>totally new systems that you might </v>

1235
01:01:43.201 --> 01:01:43.201
<v Speaker 2>interact with in a different way than we</v>
<v Speaker 2>do now.</v>

1236
01:01:43.201 --> 01:01:43.440
<v Speaker 2>Personally.</v>

1237
01:01:44.530 --> 01:01:46.570
<v Speaker 1>We got,</v>
<v Speaker 1>we're coming towards the last few,</v>

1238
01:01:46.571 --> 01:01:48.190
<v Speaker 1>but we'll get through as many as I can</v>

1239
01:01:49.530 --> 01:01:54.530
<v Speaker 9>from IBM.</v>
<v Speaker 9>I think it the other big investors in </v>

1240
01:01:54.530 --> 01:01:55.220
<v Speaker 9>Ai,</v>
<v Speaker 9>and I liked your comments around the big</v>

1241
01:01:55.221 --> 01:01:57.990
<v Speaker 9>breakthroughs is probably takes more </v>
<v Speaker 9>than one player to go to,</v>

1242
01:01:57.991 --> 01:01:59.690
<v Speaker 9>is to,</v>
<v Speaker 9>to the future space.</v>

1243
01:01:59.710 --> 01:02:00.970
<v Speaker 9>Um,</v>
<v Speaker 9>uh,</v>

1244
01:02:00.980 --> 01:02:04.430
<v Speaker 9>had a couple of questions in treatment </v>
<v Speaker 9>in your talk.</v>

1245
01:02:04.720 --> 01:02:07.070
<v Speaker 9>One was go.</v>
<v Speaker 9>So,</v>

1246
01:02:07.100 --> 01:02:12.100
<v Speaker 9>so years ago,</v>
<v Speaker 9>I think there was a big effort around </v>

1247
01:02:12.100 --> 01:02:12.110
<v Speaker 9>going who was the big one that was hard </v>
<v Speaker 9>for computers to solve.</v>

1248
01:02:12.111 --> 01:02:13.880
<v Speaker 9>It might be a bit esoteric for this </v>
<v Speaker 9>audience.</v>

1249
01:02:14.690 --> 01:02:16.820
<v Speaker 9>And then the second question,</v>
<v Speaker 9>just to bring this to the point,</v>

1250
01:02:16.821 --> 01:02:19.260
<v Speaker 9>is a,</v>
<v Speaker 9>for rts,</v>

1251
01:02:19.320 --> 01:02:24.320
<v Speaker 9>how can ai be used not to supplant </v>
<v Speaker 9>creativity but to enhance and support it</v>

1252
01:02:24.730 --> 01:02:27.510
<v Speaker 9>and allow us to do more creative things </v>
<v Speaker 9>as humans,</v>

1253
01:02:27.511 --> 01:02:28.460
<v Speaker 9>not as computers.</v>

1254
01:02:28.520 --> 01:02:33.520
<v Speaker 1>Let's do a quick one on the first one </v>
<v Speaker 1>because you might wanna do that </v>

1255
01:02:33.520 --> 01:02:33.520
<v Speaker 1>afterwards.</v>
<v Speaker 1>And it's really.</v>

1256
01:02:33.520 --> 01:02:33.520
<v Speaker 2>Yeah.</v>
<v Speaker 2>So go,</v>

1257
01:02:33.520 --> 01:02:38.400
<v Speaker 2>go for it.</v>
<v Speaker 2>As you don't know is it is an oriental </v>

1258
01:02:38.400 --> 01:02:40.520
<v Speaker 2>board game,</v>
<v Speaker 2>which is probably the most complex game </v>

1259
01:02:40.520 --> 01:02:42.771
<v Speaker 2>there is.</v>
<v Speaker 2>This is what they play in China and </v>

1260
01:02:42.771 --> 01:02:42.771
<v Speaker 2>Japan instead of a career instead of </v>
<v Speaker 2>chest.</v>

1261
01:02:42.840 --> 01:02:47.840
<v Speaker 2>And um,</v>
<v Speaker 2>one reason it's been so hard for </v>

1262
01:02:47.840 --> 01:02:47.840
<v Speaker 2>computers to crack is that the branching</v>
<v Speaker 2>factor,</v>

1263
01:02:47.840 --> 01:02:51.830
<v Speaker 2>the number of choices you have in each </v>
<v Speaker 2>booth is the order of 100,</v>

1264
01:02:51.930 --> 01:02:55.200
<v Speaker 2>whereas in chat is more like 20.</v>
<v Speaker 2>So as you start planning that branch,</v>

1265
01:02:55.201 --> 01:03:00.201
<v Speaker 2>in fact explode.</v>
<v Speaker 2>So if you're going to do it in a brute </v>

1266
01:03:00.201 --> 01:03:00.201
<v Speaker 2>force way,</v>
<v Speaker 2>there aren't enough.</v>

1267
01:03:00.201 --> 01:03:02.230
<v Speaker 2>I think atoms in the university describe</v>
<v Speaker 2>how many go positions there are.</v>

1268
01:03:02.240 --> 01:03:04.020
<v Speaker 2>For example,</v>
<v Speaker 2>bet you're good at.</v>

1269
01:03:04.021 --> 01:03:06.620
<v Speaker 2>Go on.</v>
<v Speaker 2>I'm reasonably good at go where you will</v>

1270
01:03:07.640 --> 01:03:09.890
<v Speaker 2>champion champion.</v>
<v Speaker 2>But,</v>

1271
01:03:09.960 --> 01:03:10.940
<v Speaker 2>but,</v>
<v Speaker 2>but um,</v>

1272
01:03:11.270 --> 01:03:14.700
<v Speaker 2>and then the second problem is that uh,</v>
<v Speaker 2>in chess,</v>

1273
01:03:14.701 --> 01:03:16.820
<v Speaker 2>because chess is a very materialistic </v>
<v Speaker 2>games,</v>

1274
01:03:16.821 --> 01:03:18.930
<v Speaker 2>so the queen is worth more than a real </v>
<v Speaker 2>console.</v>

1275
01:03:19.110 --> 01:03:24.110
<v Speaker 2>It's quite easy to hand program and </v>
<v Speaker 2>evaluation function to tell you whether </v>

1276
01:03:24.110 --> 01:03:27.660
<v Speaker 2>your program is winning or losing or how</v>
<v Speaker 2>well it's doing in that position.</v>

1277
01:03:27.900 --> 01:03:30.720
<v Speaker 2>Whereas in go,</v>
<v Speaker 2>all the pieces are worth the same.</v>

1278
01:03:30.721 --> 01:03:35.721
<v Speaker 2>They're just,</v>
<v Speaker 2>there's just one piece and so whether </v>

1279
01:03:35.721 --> 01:03:36.390
<v Speaker 2>you're winning or not as much more about</v>
<v Speaker 2>the overall pattern of the board.</v>

1280
01:03:36.630 --> 01:03:38.460
<v Speaker 2>So it's a much more beautiful game in </v>
<v Speaker 2>some sense,</v>

1281
01:03:38.461 --> 01:03:43.461
<v Speaker 2>very aesthetically pleasing,</v>
<v Speaker 2>but it's much harder to hand code and </v>

1282
01:03:43.461 --> 01:03:45.060
<v Speaker 2>evaluation function.</v>
<v Speaker 2>So,</v>

1283
01:03:45.061 --> 01:03:45.660
<v Speaker 2>um,</v>
<v Speaker 2>yeah,</v>

1284
01:03:45.661 --> 01:03:50.661
<v Speaker 2>we have,</v>
<v Speaker 2>we're going to have some very big </v>

1285
01:03:50.661 --> 01:03:50.661
<v Speaker 2>announcements to make ongoing.</v>
<v Speaker 2>I mean,</v>

1286
01:03:50.661 --> 01:03:53.781
<v Speaker 2>it's sort of been the holy grail for the</v>
<v Speaker 2>AI research community for the last 20 </v>

1287
01:03:53.781 --> 01:03:55.280
<v Speaker 2>years since the blue actually be cast </v>
<v Speaker 2>off.</v>

1288
01:03:55.530 --> 01:03:56.080
<v Speaker 2>Um,</v>

1289
01:03:56.720 --> 01:03:57.200
<v Speaker 1>sorry.</v>

1290
01:03:58.880 --> 01:03:59.750
<v Speaker 2>Yeah,</v>
<v Speaker 2>sure.</v>

1291
01:03:59.990 --> 01:04:00.800
<v Speaker 2>So,</v>
<v Speaker 2>uh,</v>

1292
01:04:00.830 --> 01:04:01.820
<v Speaker 2>yeah,</v>
<v Speaker 2>and then so then,</v>

1293
01:04:01.850 --> 01:04:02.630
<v Speaker 2>then the,</v>
<v Speaker 2>the,</v>

1294
01:04:02.631 --> 01:04:07.631
<v Speaker 2>the,</v>
<v Speaker 2>the last question was on a train that's </v>

1295
01:04:09.500 --> 01:04:12.320
<v Speaker 2>really the same thing I'm thinking about</v>
<v Speaker 2>in science to write and,</v>

1296
01:04:12.500 --> 01:04:17.500
<v Speaker 2>and with doctors and with one reading as</v>
<v Speaker 2>ai surfacing the right information for </v>

1297
01:04:17.671 --> 01:04:22.671
<v Speaker 2>you in a much more digestible way so you</v>
<v Speaker 2>can just leverage that for whatever it </v>

1298
01:04:22.671 --> 01:04:22.671
<v Speaker 2>is</v>

1299
01:04:23.130 --> 01:04:28.130
<v Speaker 1>we took the recommendation area.</v>
<v Speaker 1>Is there anything else in your head you </v>

1300
01:04:28.130 --> 01:04:30.540
<v Speaker 1>might just springs to mind in terms of </v>
<v Speaker 1>the creative process,</v>

1301
01:04:30.541 --> 01:04:31.830
<v Speaker 1>the creation of media?</v>

1302
01:04:32.170 --> 01:04:37.170
<v Speaker 2>I think that's a lot tougher.</v>
<v Speaker 2>So I think the recommendation is the </v>

1303
01:04:37.170 --> 01:04:37.720
<v Speaker 2>obvious one.</v>
<v Speaker 2>We are looking at things like music,</v>

1304
01:04:37.721 --> 01:04:42.721
<v Speaker 2>which is a,</v>
<v Speaker 2>a kind of more constrained domain for a </v>

1305
01:04:42.721 --> 01:04:42.721
<v Speaker 2>computer than visuals.</v>
<v Speaker 2>I mean,</v>

1306
01:04:42.721 --> 01:04:43.690
<v Speaker 2>which is incredibly hard,</v>
<v Speaker 2>right?</v>

1307
01:04:43.990 --> 01:04:48.990
<v Speaker 2>And uh,</v>
<v Speaker 2>this is a very interesting work being </v>

1308
01:04:48.990 --> 01:04:48.990
<v Speaker 2>done in music,</v>
<v Speaker 2>music composition,</v>

1309
01:04:48.990 --> 01:04:50.230
<v Speaker 2>a music analysis,</v>
<v Speaker 2>uh,</v>

1310
01:04:50.260 --> 01:04:55.260
<v Speaker 2>which I think is pretty promising.</v>
<v Speaker 2>So I would imagine that would be the </v>

1311
01:04:55.260 --> 01:04:55.260
<v Speaker 2>next place.</v>

1312
01:04:55.260 --> 01:04:59.030
<v Speaker 1>Very good.</v>
<v Speaker 1>I'm going to take three more because </v>

1313
01:04:59.030 --> 01:04:59.030
<v Speaker 1>we're really running out of time.</v>
<v Speaker 1>I'm sorry,</v>

1314
01:04:59.030 --> 01:05:03.510
<v Speaker 1>because we could just keep going.</v>
<v Speaker 1>We're not here to take you guys weren't </v>

1315
01:05:03.510 --> 01:05:03.510
<v Speaker 1>here.</v>
<v Speaker 1>Is there,</v>

1316
01:05:03.510 --> 01:05:06.691
<v Speaker 1>and got a microphone on them because </v>
<v Speaker 1>we'll just get the nice gentleman in the</v>

1317
01:05:07.110 --> 01:05:08.240
<v Speaker 1>back.</v>
<v Speaker 1>Want to have A.</v>

1318
01:05:08.240 --> 01:05:11.490
<v Speaker 1>Because I've been very front focus that </v>
<v Speaker 1>we don't want to be on the road right at</v>

1319
01:05:11.491 --> 01:05:12.030
<v Speaker 1>the back there.</v>

1320
01:05:13.470 --> 01:05:15.510
<v Speaker 9>IBM,</v>
<v Speaker 9>we've been sheep.</v>

1321
01:05:15.511 --> 01:05:18.100
<v Speaker 9>The from the search of pain,</v>
<v Speaker 9>pleasure during</v>

1322
01:05:18.160 --> 01:05:22.480
<v Speaker 6>our own cultural history and it's shaped</v>
<v Speaker 6>the way that we're thinking,</v>

1323
01:05:22.520 --> 01:05:26.530
<v Speaker 6>the way we are behaving.</v>
<v Speaker 6>How can you teach a pain and pleasure to</v>

1324
01:05:26.531 --> 01:05:27.070
<v Speaker 6>a machine?</v>

1325
01:05:28.950 --> 01:05:30.100
<v Speaker 2>Well,</v>
<v Speaker 2>one question is whether we,</v>

1326
01:05:30.101 --> 01:05:32.850
<v Speaker 2>whether we need to,</v>
<v Speaker 2>but it's also,</v>

1327
01:05:33.090 --> 01:05:35.490
<v Speaker 2>or whether we should and um,</v>
<v Speaker 2>uh,</v>

1328
01:05:35.500 --> 01:05:40.500
<v Speaker 2>but there is sort of,</v>
<v Speaker 2>this speaks to this idea actually that </v>

1329
01:05:40.500 --> 01:05:41.100
<v Speaker 2>we look at internally of intrinsic </v>
<v Speaker 2>motivation.</v>

1330
01:05:41.101 --> 01:05:41.940
<v Speaker 2>We call it.</v>
<v Speaker 2>So,</v>

1331
01:05:42.180 --> 01:05:44.460
<v Speaker 2>you know,</v>
<v Speaker 2>there are emotions and other things that</v>

1332
01:05:44.461 --> 01:05:47.160
<v Speaker 2>drive human behavior,</v>
<v Speaker 2>not just external rewards.</v>

1333
01:05:47.400 --> 01:05:48.480
<v Speaker 2>Um,</v>
<v Speaker 2>so,</v>

1334
01:05:48.660 --> 01:05:49.230
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

1335
01:05:49.231 --> 01:05:51.570
<v Speaker 2>and at the moment our machines don't </v>
<v Speaker 2>have anything like that.</v>

1336
01:05:51.840 --> 01:05:52.500
<v Speaker 2>But,</v>
<v Speaker 2>um,</v>

1337
01:05:52.530 --> 01:05:55.450
<v Speaker 2>maybe to do more complex tasks or you </v>
<v Speaker 2>know,</v>

1338
01:05:55.500 --> 01:06:00.010
<v Speaker 2>where the mobile working in game worlds,</v>
<v Speaker 2>where there is conveniently a score most</v>

1339
01:06:00.060 --> 01:06:05.060
<v Speaker 2>most of the time,</v>
<v Speaker 2>but even if you start going to more </v>

1340
01:06:05.060 --> 01:06:07.431
<v Speaker 2>complex games,</v>
<v Speaker 2>mope all open ended things like </v>

1341
01:06:07.431 --> 01:06:07.920
<v Speaker 2>minecraft.</v>
<v Speaker 2>Now there isn't a score anymore,</v>

1342
01:06:08.130 --> 01:06:13.130
<v Speaker 2>right?</v>
<v Speaker 2>So how are you going to decide what you </v>

1343
01:06:13.130 --> 01:06:13.130
<v Speaker 2>should do?</v>
<v Speaker 2>What is,</v>

1344
01:06:13.130 --> 01:06:14.400
<v Speaker 2>what's useful,</v>
<v Speaker 2>what's good that you're making progress?</v>

1345
01:06:14.401 --> 01:06:16.020
<v Speaker 2>And I'm talking about the agent system </v>
<v Speaker 2>here.</v>

1346
01:06:16.320 --> 01:06:17.550
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

1347
01:06:17.610 --> 01:06:22.610
<v Speaker 2>and of course that's more like the real </v>
<v Speaker 2>world for us as as humans and yet </v>

1348
01:06:22.610 --> 01:06:26.271
<v Speaker 2>somehow we have our own internal drives </v>
<v Speaker 2>probably that had been evolved to that </v>

1349
01:06:26.271 --> 01:06:31.251
<v Speaker 2>help influence our behavior.</v>
<v Speaker 2>So I think it's interesting to think </v>

1350
01:06:31.251 --> 01:06:31.251
<v Speaker 2>about.</v>
<v Speaker 2>Um,</v>

1351
01:06:31.251 --> 01:06:31.770
<v Speaker 2>and you know,</v>
<v Speaker 2>we have,</v>

1352
01:06:31.771 --> 01:06:36.771
<v Speaker 2>neuroscientists are experts in these </v>
<v Speaker 2>areas who work with us as consultants </v>

1353
01:06:36.771 --> 01:06:37.200
<v Speaker 2>and it's something I'm very fascinated </v>
<v Speaker 2>by.</v>

1354
01:06:37.620 --> 01:06:38.430
<v Speaker 2>Um,</v>
<v Speaker 2>but,</v>

1355
01:06:38.490 --> 01:06:39.030
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

1356
01:06:39.031 --> 01:06:40.890
<v Speaker 2>we don't have a definite answer on that </v>
<v Speaker 2>yet.</v>

1357
01:06:41.460 --> 01:06:42.810
<v Speaker 1>Thank you.</v>
<v Speaker 1>Two more.</v>

1358
01:06:42.870 --> 01:06:44.860
<v Speaker 1>So we'll take the gentleman at the back </v>
<v Speaker 1>of it.</v>

1359
01:06:44.870 --> 01:06:47.360
<v Speaker 1>You almost don't want to have a question</v>
<v Speaker 1>about,</v>

1360
01:06:48.410 --> 01:06:50.190
<v Speaker 1>I got hand up the.</v>
<v Speaker 1>Yes,</v>

1361
01:06:50.191 --> 01:06:51.840
<v Speaker 1>there is rather back there.</v>
<v Speaker 1>I just feel,</v>

1362
01:06:52.730 --> 01:06:57.720
<v Speaker 1>and then we'll take the gentleman in the</v>
<v Speaker 1>red as the last question.</v>

1363
01:06:58.530 --> 01:06:59.010
<v Speaker 1>No pressure.</v>

1364
01:07:00.850 --> 01:07:02.510
<v Speaker 6>My,</v>
<v Speaker 6>my question leads on quite well from the</v>

1365
01:07:02.511 --> 01:07:04.160
<v Speaker 6>last.</v>
<v Speaker 6>Actually I was thinking,</v>

1366
01:07:04.161 --> 01:07:06.830
<v Speaker 6>have you thought about generalizing the </v>
<v Speaker 6>goals?</v>

1367
01:07:06.860 --> 01:07:09.590
<v Speaker 6>So you talked about how the,</v>
<v Speaker 6>the uh,</v>

1368
01:07:09.920 --> 01:07:11.760
<v Speaker 6>observations and you have,</v>
<v Speaker 6>um,</v>

1369
01:07:12.290 --> 01:07:15.560
<v Speaker 6>actions that you take,</v>
<v Speaker 6>but presumably you define the goal.</v>

1370
01:07:15.561 --> 01:07:19.310
<v Speaker 6>Then you tell the system how to measure </v>
<v Speaker 6>its goals and if we're thinking about ai</v>

1371
01:07:19.311 --> 01:07:22.370
<v Speaker 6>as something which is a servant to,</v>
<v Speaker 6>to a human intelligence,</v>

1372
01:07:22.790 --> 01:07:27.790
<v Speaker 6>then have you thought about ai which can</v>
<v Speaker 6>derive its goals from the environment.</v>

1373
01:07:28.480 --> 01:07:29.440
<v Speaker 6>Can,</v>
<v Speaker 6>can also,</v>

1374
01:07:29.450 --> 01:07:31.490
<v Speaker 6>and also as humans,</v>
<v Speaker 6>we segment our goals.</v>

1375
01:07:31.491 --> 01:07:36.491
<v Speaker 6>We might have life goals,</v>
<v Speaker 6>but we focused on sub goals to get </v>

1376
01:07:36.491 --> 01:07:36.960
<v Speaker 6>there.</v>
<v Speaker 6>And also I'm not just know,</v>

1377
01:07:36.980 --> 01:07:39.680
<v Speaker 6>I'm sort of imagining a human saying to </v>
<v Speaker 6>a system,</v>

1378
01:07:40.010 --> 01:07:45.010
<v Speaker 6>can you help me with this and that and </v>
<v Speaker 6>the ai being able to derive its goal </v>

1379
01:07:45.010 --> 01:07:48.680
<v Speaker 6>from the things that it hears,</v>
<v Speaker 6>but also going further than that,</v>

1380
01:07:48.710 --> 01:07:52.340
<v Speaker 6>being able to derive goals before </v>
<v Speaker 6>they're specifically instructed.</v>

1381
01:07:52.700 --> 01:07:53.500
<v Speaker 6>So,</v>
<v Speaker 6>um,</v>

1382
01:07:54.020 --> 01:07:57.130
<v Speaker 6>being able to anticipate goals that </v>
<v Speaker 6>people might want that to ai.</v>

1383
01:07:57.140 --> 01:07:57.850
<v Speaker 6>So we realize it</v>

1384
01:07:57.930 --> 01:07:58.800
<v Speaker 1>go to high school.</v>

1385
01:07:59.090 --> 01:07:59.930
<v Speaker 2>That's fine.</v>
<v Speaker 2>I mean,</v>

1386
01:07:59.931 --> 01:08:00.710
<v Speaker 2>that's very,</v>
<v Speaker 2>you know,</v>

1387
01:08:00.711 --> 01:08:03.230
<v Speaker 2>that's a great question.</v>
<v Speaker 2>And actually it's a fascinating research</v>

1388
01:08:03.231 --> 01:08:05.720
<v Speaker 2>areas.</v>
<v Speaker 2>Can the machines learn their own goals?</v>

1389
01:08:05.950 --> 01:08:08.430
<v Speaker 2>A bite through observation of,</v>
<v Speaker 2>you know,</v>

1390
01:08:08.450 --> 01:08:10.910
<v Speaker 2>learn what it is you like through </v>
<v Speaker 2>observing you for example.</v>

1391
01:08:10.911 --> 01:08:12.650
<v Speaker 2>Right?</v>
<v Speaker 2>And then trying to,</v>

1392
01:08:12.670 --> 01:08:14.810
<v Speaker 2>you know,</v>
<v Speaker 2>maybe even be able to preemptively guess</v>

1393
01:08:14.811 --> 01:08:18.080
<v Speaker 2>what is that you need before you even </v>
<v Speaker 2>ask for it.</v>

1394
01:08:18.470 --> 01:08:19.580
<v Speaker 2>Um,</v>
<v Speaker 2>so I think,</v>

1395
01:08:19.730 --> 01:08:20.600
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

1396
01:08:20.601 --> 01:08:25.601
<v Speaker 2>those systems are very interesting.</v>
<v Speaker 2>I mean even there you will still have </v>

1397
01:08:25.601 --> 01:08:26.990
<v Speaker 2>some kind of top level goal which is to </v>
<v Speaker 2>satisfy the user,</v>

1398
01:08:26.991 --> 01:08:29.330
<v Speaker 2>right?</v>
<v Speaker 2>Although it may learn what the sub goals</v>

1399
01:08:29.331 --> 01:08:34.331
<v Speaker 2>are and that's another very active area </v>
<v Speaker 2>of research is how do you break down a </v>

1400
01:08:34.331 --> 01:08:36.290
<v Speaker 2>large go into,</v>
<v Speaker 2>into automatically into sub goals.</v>

1401
01:08:36.500 --> 01:08:38.660
<v Speaker 2>And of course that's something our minds</v>
<v Speaker 2>do effortlessly.</v>

1402
01:08:38.890 --> 01:08:41.540
<v Speaker 2>You know,</v>
<v Speaker 2>if you're going to plan to um,</v>

1403
01:08:41.541 --> 01:08:43.660
<v Speaker 2>you know,</v>
<v Speaker 2>a trip to Paris from hair,</v>

1404
01:08:43.920 --> 01:08:48.920
<v Speaker 2>um,</v>
<v Speaker 2>your brain is not going to plan over </v>

1405
01:08:48.920 --> 01:08:49.340
<v Speaker 2>your muscle fiber movements all the way </v>
<v Speaker 2>from here to Paris,</v>

1406
01:08:49.400 --> 01:08:49.630
<v Speaker 2>right?</v>

1407
01:08:49.650 --> 01:08:51.830
<v Speaker 2>It's the yet.</v>
<v Speaker 2>That's how robotics works.</v>

1408
01:08:51.831 --> 01:08:54.650
<v Speaker 2>And it might feel like they have no </v>
<v Speaker 2>defining of hierarchy,</v>

1409
01:08:54.800 --> 01:08:56.410
<v Speaker 2>well your act,</v>
<v Speaker 2>but it's actually going to do is like,</v>

1410
01:08:56.420 --> 01:09:01.420
<v Speaker 2>you know,</v>
<v Speaker 2>at high level you need to get to the </v>

1411
01:09:01.420 --> 01:09:01.420
<v Speaker 2>Eurostar terminal and then take a train </v>
<v Speaker 2>there and so on,</v>

1412
01:09:01.420 --> 01:09:04.040
<v Speaker 2>and then only at the point where you get</v>
<v Speaker 2>up off that chair,</v>

1413
01:09:04.100 --> 01:09:07.790
<v Speaker 2>does your brain then go and unpack the </v>
<v Speaker 2>muscle fiber movement of get,</v>

1414
01:09:07.791 --> 01:09:10.190
<v Speaker 2>you know,</v>
<v Speaker 2>get up off the chair and uh,</v>

1415
01:09:10.191 --> 01:09:11.780
<v Speaker 2>and walk.</v>
<v Speaker 2>So,</v>

1416
01:09:11.840 --> 01:09:13.100
<v Speaker 2>um,</v>
<v Speaker 2>whereas at the moment,</v>

1417
01:09:13.101 --> 01:09:18.010
<v Speaker 2>because we haven't solved this problem </v>
<v Speaker 2>of automatically generating subgoals I'm</v>

1418
01:09:18.170 --> 01:09:19.100
<v Speaker 2>a robot,</v>
<v Speaker 2>for example,</v>

1419
01:09:19.101 --> 01:09:24.101
<v Speaker 2>trying to do that task,</v>
<v Speaker 2>we'd have to plan over the primitive </v>

1420
01:09:24.101 --> 01:09:26.531
<v Speaker 2>action movements all the way to Paris.</v>
<v Speaker 2>And of course this is not feasible and </v>

1421
01:09:26.531 --> 01:09:27.040
<v Speaker 2>therefore not tractable.</v>
<v Speaker 2>Um,</v>

1422
01:09:27.080 --> 01:09:28.760
<v Speaker 2>because it ends up becoming,</v>
<v Speaker 2>you know,</v>

1423
01:09:28.761 --> 01:09:33.761
<v Speaker 2>speaks to the other gentleman's question</v>
<v Speaker 2>about you imagine all those paths from </v>

1424
01:09:33.761 --> 01:09:34.280
<v Speaker 2>here or muscle muscle fiber movements.</v>
<v Speaker 2>There's an infinite,</v>

1425
01:09:34.330 --> 01:09:35.660
<v Speaker 2>there's basically an infinite number of </v>
<v Speaker 2>them.</v>

1426
01:09:36.110 --> 01:09:37.610
<v Speaker 2>So,</v>
<v Speaker 2>um,</v>

1427
01:09:37.700 --> 01:09:42.700
<v Speaker 2>so we need,</v>
<v Speaker 2>that's one of the key things we need to </v>

1428
01:09:42.700 --> 01:09:42.700
<v Speaker 2>solve is the sub goal problem.</v>

1429
01:09:42.700 --> 01:09:43.870
<v Speaker 1>The last question.</v>
<v Speaker 1>Oh,</v>

1430
01:09:44.470 --> 01:09:46.750
<v Speaker 1>sorry.</v>
<v Speaker 1>Get that across.</v>

1431
01:09:48.420 --> 01:09:49.700
<v Speaker 5>Hmm.</v>

1432
01:09:51.060 --> 01:09:56.060
<v Speaker 1>Malcolm have a broadcast engineer </v>
<v Speaker 1>following off from an earlier one and </v>

1433
01:09:56.060 --> 01:09:56.400
<v Speaker 1>your list of memory,</v>
<v Speaker 1>navigation,</v>

1434
01:09:56.430 --> 01:09:57.750
<v Speaker 1>imagination,</v>
<v Speaker 1>etc.</v>

1435
01:09:58.200 --> 01:10:03.200
<v Speaker 1>You didn't have emotions and that's </v>
<v Speaker 1>where we're going to be dealing with an </v>

1436
01:10:03.200 --> 01:10:06.800
<v Speaker 1>interacting with humans.</v>
<v Speaker 1>How explosive is that with Your </v>

1437
01:10:06.800 --> 01:10:08.100
<v Speaker 1>conflicts of ethics and parameters?</v>

1438
01:10:08.660 --> 01:10:09.230
<v Speaker 2>Yeah,</v>
<v Speaker 2>I mean,</v>

1439
01:10:09.231 --> 01:10:09.790
<v Speaker 2>again,</v>
<v Speaker 2>this,</v>

1440
01:10:09.800 --> 01:10:10.630
<v Speaker 2>this,</v>
<v Speaker 2>um,</v>

1441
01:10:10.670 --> 01:10:14.450
<v Speaker 2>relates to the question identifying down</v>
<v Speaker 2>here about emotions.</v>

1442
01:10:14.490 --> 01:10:16.010
<v Speaker 2>We currently.</v>
<v Speaker 2>I'm,</v>

1443
01:10:16.360 --> 01:10:16.970
<v Speaker 2>uh,</v>
<v Speaker 2>you know,</v>

1444
01:10:16.971 --> 01:10:19.190
<v Speaker 2>there is no equivalent of that in our </v>
<v Speaker 2>systems.</v>

1445
01:10:19.460 --> 01:10:20.360
<v Speaker 2>Um,</v>
<v Speaker 2>but,</v>

1446
01:10:20.440 --> 01:10:23.030
<v Speaker 2>uh,</v>
<v Speaker 2>if you think of inch in emotions,</v>

1447
01:10:23.031 --> 01:10:27.590
<v Speaker 2>and probably this is too simplistic,</v>
<v Speaker 2>but part of emotions are internal drives</v>

1448
01:10:27.770 --> 01:10:32.770
<v Speaker 2>a give us internal drives,</v>
<v Speaker 2>then that's something we do need to </v>

1449
01:10:32.770 --> 01:10:32.770
<v Speaker 2>explore,</v>
<v Speaker 2>um,</v>

1450
01:10:32.870 --> 01:10:37.870
<v Speaker 2>and try and work out what ones might be </v>
<v Speaker 2>needed and it might be we need similar </v>

1451
01:10:37.870 --> 01:10:40.370
<v Speaker 2>ones so that these systems can empathize</v>
<v Speaker 2>with humans.</v>

1452
01:10:40.610 --> 01:10:41.810
<v Speaker 2>Um,</v>
<v Speaker 2>you know,</v>

1453
01:10:41.811 --> 01:10:43.340
<v Speaker 2>obviously there's a great channel for </v>
<v Speaker 2>series.</v>

1454
01:10:43.341 --> 01:10:45.650
<v Speaker 2>I think that people,</v>
<v Speaker 2>some people in the audience with humans,</v>

1455
01:10:45.651 --> 01:10:47.720
<v Speaker 2>which I really love and that's </v>
<v Speaker 2>interesting.</v>

1456
01:10:47.721 --> 01:10:52.721
<v Speaker 2>You know,</v>
<v Speaker 2>they're trying to empathize with the </v>

1457
01:10:52.721 --> 01:10:52.721
<v Speaker 2>humans that they serve.</v>
<v Speaker 2>Alternatively,</v>

1458
01:10:52.721 --> 01:10:56.360
<v Speaker 2>you might want to have systems that have</v>
<v Speaker 2>no a very different types of drives that</v>

1459
01:10:56.361 --> 01:10:59.930
<v Speaker 2>help them be complimentary to what </v>
<v Speaker 2>humans are good at,</v>

1460
01:11:00.110 --> 01:11:02.930
<v Speaker 2>so I could imagine we might need both </v>
<v Speaker 2>types of daily,</v>

1461
01:11:03.410 --> 01:11:07.070
<v Speaker 1>so motion.</v>
<v Speaker 1>Just want to fish on the using essential</v>

1462
01:11:07.071 --> 01:11:12.071
<v Speaker 1>that you're going to have to cope with </v>
<v Speaker 1>emotion as a driver of if you'd like </v>

1463
01:11:12.071 --> 01:11:12.390
<v Speaker 1>some types of emotions,</v>
<v Speaker 1>relations,</v>

1464
01:11:12.490 --> 01:11:16.170
<v Speaker 2>so there's two reasons you might want </v>
<v Speaker 2>the one so that we can see these systems</v>

1465
01:11:16.171 --> 01:11:18.870
<v Speaker 2>can empathize and work better.</v>
<v Speaker 2>Hand in hand with humans.</v>

1466
01:11:18.940 --> 01:11:20.720
<v Speaker 2>Yeah.</v>
<v Speaker 2>The other thing is if they.</v>

1467
01:11:20.730 --> 01:11:22.350
<v Speaker 2>It turns out the environments they're </v>
<v Speaker 2>in,</v>

1468
01:11:22.380 --> 01:11:24.690
<v Speaker 2>there aren't many external reward </v>
<v Speaker 2>signals.</v>

1469
01:11:24.870 --> 01:11:28.740
<v Speaker 2>They have to have some internal drive to</v>
<v Speaker 2>get them going in the right direction.</v>

1470
01:11:30.300 --> 01:11:35.300
<v Speaker 2>It was a privilege.</v>
<v Speaker 2>I'm going to hand to nomi climate from </v>

1471
01:11:35.300 --> 01:11:36.210
<v Speaker 2>the president,</v>
<v Speaker 2>the iet in a second,</v>

1472
01:11:36.211 --> 01:11:38.520
<v Speaker 2>but dennis has been one year.</v>
<v Speaker 2>Thank you.</v>

1473
01:11:41.790 --> 01:11:46.790
<v Speaker 4>Thank you</v>

1474
01:11:53.380 --> 01:11:55.420
<v Speaker 10>dennis.</v>
<v Speaker 10>As the president of the iet,</v>

1475
01:11:55.660 --> 01:12:00.660
<v Speaker 10>we're absolutely delighted to have co </v>
<v Speaker 10>hosted this lecture with the royal </v>

1476
01:12:00.660 --> 01:12:03.871
<v Speaker 10>television society and delighted to have</v>
<v Speaker 10>someone of your extraordinary caliber </v>

1477
01:12:03.871 --> 01:12:07.870
<v Speaker 10>miss events like today for fill,</v>
<v Speaker 10>part of the iet charitable remit,</v>

1478
01:12:07.871 --> 01:12:09.160
<v Speaker 10>which is to inspire,</v>
<v Speaker 10>inform,</v>

1479
01:12:09.161 --> 01:12:11.710
<v Speaker 10>and influence people and I don't know </v>
<v Speaker 10>about you,</v>

1480
01:12:11.711 --> 01:12:16.711
<v Speaker 10>but you sure as hell have inspired,</v>
<v Speaker 10>informed and influenced me on a topic </v>

1481
01:12:16.711 --> 01:12:17.350
<v Speaker 10>that I believe is going to change the </v>
<v Speaker 10>world.</v>

1482
01:12:17.650 --> 01:12:22.650
<v Speaker 10>I love the idea that your ai journey </v>
<v Speaker 10>started with games and the machine </v>

1483
01:12:22.650 --> 01:12:27.421
<v Speaker 10>learning is done through play.</v>
<v Speaker 10>Pretty mucH the same as it is for </v>

1484
01:12:27.421 --> 01:12:29.590
<v Speaker 10>humans.</v>
<v Speaker 10>I've enjoyed the way that you've made it</v>

1485
01:12:29.591 --> 01:12:34.591
<v Speaker 10>all sound pretty straightforward </v>
<v Speaker 10>actually from our hippocampus to </v>

1486
01:12:34.591 --> 01:12:38.290
<v Speaker 10>imagining rats to the quest for machine </v>
<v Speaker 10>creativity and it just sounded quite </v>

1487
01:12:39.611 --> 01:12:43.060
<v Speaker 10>logical that your journey to the to the </v>
<v Speaker 10>point to have your mission,</v>

1488
01:12:43.061 --> 01:12:47.710
<v Speaker 10>which is use ai to solve everything else</v>
<v Speaker 10>seems quite reasonable.</v>

1489
01:12:47.950 --> 01:12:52.950
<v Speaker 10>Your quest for the ai scientist to </v>
<v Speaker 10>really tackle some of those big </v>

1490
01:12:52.950 --> 01:12:54.100
<v Speaker 10>important challenges.</v>
<v Speaker 10>So listening to you,</v>

1491
01:12:54.101 --> 01:12:56.800
<v Speaker 10>it all sounds incredibly real and </v>
<v Speaker 10>feasible.</v>

1492
01:12:56.801 --> 01:13:01.801
<v Speaker 10>That ai can make a positive difference </v>
<v Speaker 10>to humanity and even if it's not going </v>

1493
01:13:01.811 --> 01:13:06.040
<v Speaker 10>to be directing any movies anytime soon.</v>
<v Speaker 10>So once again,</v>

1494
01:13:06.070 --> 01:13:08.520
<v Speaker 10>please join me in thanking dennis </v>
<v Speaker 10>hassabis,</v>

1495
01:13:08.800 --> 01:13:11.920
<v Speaker 10>founder of deep mind for an absolutely </v>
<v Speaker 10>fantastic.</v>

1496
01:13:12.150 --> 01:13:17.150
<v Speaker 4>Sure.</v>
<v Speaker 4>Thanks and I will do.</v>

1497
01:13:25.280 --> 01:13:28.730
<v Speaker 10>I'd like to thank our feisty chair.</v>
<v Speaker 10>You did an excellent job.</v>

1498
01:13:28.731 --> 01:13:32.660
<v Speaker 10>Tyndale be the ceo of bbc worldwide.</v>
<v Speaker 10>I think we've all been inspired,</v>

1499
01:13:32.661 --> 01:13:33.790
<v Speaker 10>informed,</v>
<v Speaker 10>and influenced,</v>

1500
01:13:33.800 --> 01:13:36.260
<v Speaker 10>so it's been very nice for me to be part</v>
<v Speaker 10>of this.</v>

1501
01:13:36.560 --> 01:13:41.560
<v Speaker 10>Thank you very much for coming here.</v>
<v Speaker 10>We did like to to hear that drinks are </v>

1502
01:13:41.560 --> 01:13:41.560
<v Speaker 10>now served outside.</v>
<v Speaker 10>Thank you.</v>

1503
01:13:41.560 --> 01:13:43.870
<v Speaker 4>thank you.</v>

