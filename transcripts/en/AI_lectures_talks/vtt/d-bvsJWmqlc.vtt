WEBVTT

1
00:00:00.790 --> 00:00:04.100
<v Speaker 1>Our distinguished speaker this evening,</v>
<v Speaker 1>Dennis Hassabis</v>

2
00:00:05.620 --> 00:00:10.620
<v Speaker 1>cofounded,</v>
<v Speaker 1>the artificial intelligence lab deep </v>

3
00:00:10.620 --> 00:00:13.391
<v Speaker 1>mind,</v>
<v Speaker 1>and it's recognized worldwide as one of </v>

4
00:00:13.391 --> 00:00:17.101
<v Speaker 1>the smartest thinkers in his field.</v>
<v Speaker 1>He was nicknamed the superhero of </v>

5
00:00:18.881 --> 00:00:23.881
<v Speaker 1>artificial intelligence by the Guardian.</v>
<v Speaker 1>He's a former chess prodigy with degrees</v>

6
00:00:25.450 --> 00:00:29.500
<v Speaker 1>in computer science and cognitive.</v>
<v Speaker 1>This is making me sweat.</v>

7
00:00:29.560 --> 00:00:31.930
<v Speaker 1>He's so.</v>
<v Speaker 1>He's so clever.</v>

8
00:00:32.350 --> 00:00:34.690
<v Speaker 1>Anyway,</v>
<v Speaker 1>this evening's topic,</v>

9
00:00:34.840 --> 00:00:39.840
<v Speaker 1>creativity,</v>
<v Speaker 1>an ai draws on his eclectic experiences </v>

10
00:00:40.120 --> 00:00:42.310
<v Speaker 1>as an artificial intelligence </v>
<v Speaker 1>researcher,</v>

11
00:00:42.640 --> 00:00:47.640
<v Speaker 1>neuroscientists,</v>
<v Speaker 1>and video game designer to discuss the </v>

12
00:00:47.640 --> 00:00:51.091
<v Speaker 1>implications of cutting edge research </v>
<v Speaker 1>for creativity and scientific discovery.</v>

13
00:00:52.750 --> 00:00:55.690
<v Speaker 1>There'll be an opportunity for questions</v>
<v Speaker 1>at the end.</v>

14
00:00:55.691 --> 00:00:56.370
<v Speaker 1>I think,</v>
<v Speaker 1>um,</v>

15
00:00:56.410 --> 00:00:58.570
<v Speaker 1>I think tim was probably handling that </v>
<v Speaker 1>as a writer.</v>

16
00:00:59.380 --> 00:01:00.970
<v Speaker 1>Anyway.</v>
<v Speaker 1>Without further ado,</v>

17
00:01:00.971 --> 00:01:05.020
<v Speaker 1>I'd love you to give a big welcome to </v>
<v Speaker 1>Dennis [inaudible] office.</v>

18
00:01:05.110 --> 00:01:10.110
<v Speaker 2>Thank you.</v>

19
00:01:17.740 --> 00:01:22.740
<v Speaker 3>Thank you Chris for that introduction.</v>
<v Speaker 3>So it's a great honor for me to be here </v>

20
00:01:22.740 --> 00:01:27.511
<v Speaker 3>at the academy to give this inaugural </v>
<v Speaker 3>Rothschild's lecture in this wonderful </v>

21
00:01:27.511 --> 00:01:29.680
<v Speaker 3>and inspiring amphitheater that we're </v>
<v Speaker 3>sitting in today.</v>

22
00:01:30.680 --> 00:01:35.680
<v Speaker 3>I always love visiting there all academy</v>
<v Speaker 3>and I think it's great to have these </v>

23
00:01:35.680 --> 00:01:38.971
<v Speaker 3>kinds of dialogues between the sciences </v>
<v Speaker 3>and the arts and I think it's actually </v>

24
00:01:38.971 --> 00:01:42.991
<v Speaker 3>going to become increasingly more vital </v>
<v Speaker 3>as we rush headlong into the modern </v>

25
00:01:42.991 --> 00:01:47.851
<v Speaker 3>technological world.</v>
<v Speaker 3>So today I'm going to explore a theme </v>

26
00:01:48.011 --> 00:01:50.380
<v Speaker 3>that's the heart of everything at the </v>
<v Speaker 3>wall academy,</v>

27
00:01:50.650 --> 00:01:55.650
<v Speaker 3>namely creativity,</v>
<v Speaker 3>and I'm going to examine it through the </v>

28
00:01:55.650 --> 00:01:59.251
<v Speaker 3>lens of science and also more </v>
<v Speaker 3>specifically through the lens of the </v>

29
00:01:59.251 --> 00:02:02.590
<v Speaker 3>latest advances advances in artificial </v>
<v Speaker 3>intelligence.</v>

30
00:02:04.560 --> 00:02:09.560
<v Speaker 3>So as all of you will know,</v>
<v Speaker 3>ai is the science of making machines </v>

31
00:02:09.560 --> 00:02:10.140
<v Speaker 3>smart.</v>
<v Speaker 3>And as Chris mentioned,</v>

32
00:02:10.290 --> 00:02:15.290
<v Speaker 3>we found a deep mind in 2010 with the </v>
<v Speaker 3>goal of trying to advance artificial </v>

33
00:02:16.291 --> 00:02:21.291
<v Speaker 3>intelligence.</v>
<v Speaker 3>And we thought of AI and deep mind as a </v>

34
00:02:21.291 --> 00:02:26.151
<v Speaker 3>kind of an Apollo program.</v>
<v Speaker 3>Efforts to advance ai as quickly as </v>

35
00:02:26.151 --> 00:02:28.140
<v Speaker 3>possible.</v>
<v Speaker 3>And what we mean by that is try to bring</v>

36
00:02:28.141 --> 00:02:31.680
<v Speaker 3>together the world's greatest research.</v>
<v Speaker 3>Scientists and engineers.</v>

37
00:02:31.900 --> 00:02:34.140
<v Speaker 3>Give them all the resources they </v>
<v Speaker 3>require,</v>

38
00:02:34.141 --> 00:02:39.141
<v Speaker 3>compute power and other things in order </v>
<v Speaker 3>to see how much progress we could make </v>

39
00:02:39.141 --> 00:02:44.090
<v Speaker 3>towards solving ai.</v>
<v Speaker 3>And we had an ambitious roadmap that </v>

40
00:02:44.090 --> 00:02:44.310
<v Speaker 3>we're carrying out to this day.</v>

41
00:02:46.380 --> 00:02:51.380
<v Speaker 3>The other big thing,</v>
<v Speaker 3>idea behind deep mind and vision behind </v>

42
00:02:51.380 --> 00:02:52.980
<v Speaker 3>it was to try and organize scientific </v>
<v Speaker 3>endeavor in a new way.</v>

43
00:02:53.760 --> 00:02:58.760
<v Speaker 3>So the way I can kind of summarize that </v>
<v Speaker 3>is we try to fuse together the best from</v>

44
00:02:58.900 --> 00:03:01.870
<v Speaker 3>academia,</v>
<v Speaker 3>blue sky thinking and ambitious thinking</v>

45
00:03:01.871 --> 00:03:03.730
<v Speaker 3>that you get in the best place with </v>
<v Speaker 3>academia,</v>

46
00:03:04.030 --> 00:03:08.290
<v Speaker 3>with the best from the startup world.</v>
<v Speaker 3>So the kind of focus and energy and pace</v>

47
00:03:08.470 --> 00:03:10.300
<v Speaker 3>that you get at the world's best </v>
<v Speaker 3>startups.</v>

48
00:03:10.690 --> 00:03:15.690
<v Speaker 3>And we didn't see why those two types of</v>
<v Speaker 3>environments had to be mutually </v>

49
00:03:15.690 --> 00:03:19.411
<v Speaker 3>exclusive.</v>
<v Speaker 3>And we thought that we could advance </v>

50
00:03:19.411 --> 00:03:20.710
<v Speaker 3>science more quickly if we could combine</v>
<v Speaker 3>the best from both of those worlds.</v>

51
00:03:23.570 --> 00:03:28.570
<v Speaker 3>Now mission at deep mind,</v>
<v Speaker 3>we articulated as a kind of to step </v>

52
00:03:28.570 --> 00:03:28.640
<v Speaker 3>mission.</v>
<v Speaker 3>So step one,</v>

53
00:03:28.880 --> 00:03:33.880
<v Speaker 3>fundamentally solve intelligence.</v>
<v Speaker 3>So we'd like to understand what </v>

54
00:03:33.880 --> 00:03:34.820
<v Speaker 3>intelligence is and we create it </v>
<v Speaker 3>artificially.</v>

55
00:03:35.810 --> 00:03:39.320
<v Speaker 3>And then we believe if you do step one </v>
<v Speaker 3>and a general enough way,</v>

56
00:03:39.650 --> 00:03:43.220
<v Speaker 3>then step two naturally follows.</v>
<v Speaker 3>We should be able to use this technology</v>

57
00:03:43.221 --> 00:03:48.221
<v Speaker 3>to solve almost everything else.</v>
<v Speaker 3>And that might sound a little bit </v>

58
00:03:48.221 --> 00:03:51.971
<v Speaker 3>fanciful,</v>
<v Speaker 3>but I hope that by the end of the talk </v>

59
00:03:51.971 --> 00:03:55.900
<v Speaker 3>of hope to have convinced you to at </v>
<v Speaker 3>least think that maybe this is not so </v>

60
00:03:55.900 --> 00:03:55.900
<v Speaker 3>far fetched after all,</v>
<v Speaker 3>uh,</v>

61
00:03:55.900 --> 00:04:00.670
<v Speaker 3>perhaps actually it's a logical next </v>
<v Speaker 3>step after we have general artificial </v>

62
00:04:00.670 --> 00:04:05.141
<v Speaker 3>intelligence.</v>
<v Speaker 3>So more prosaically we plan to do this </v>

63
00:04:06.461 --> 00:04:09.880
<v Speaker 3>by building the world's first general </v>
<v Speaker 3>purpose learning system.</v>

64
00:04:10.940 --> 00:04:13.010
<v Speaker 3>So what do those words mean?</v>
<v Speaker 3>General and learning?</v>

65
00:04:13.310 --> 00:04:18.310
<v Speaker 3>Well,</v>
<v Speaker 3>let me take you through two main </v>

66
00:04:18.310 --> 00:04:20.231
<v Speaker 3>approaches.</v>
<v Speaker 3>Two main approaches to building ai kind </v>

67
00:04:20.231 --> 00:04:23.651
<v Speaker 3>of falls between two schools of fault.</v>
<v Speaker 3>So in the early days of artificial </v>

68
00:04:23.651 --> 00:04:25.980
<v Speaker 3>intelligence,</v>
<v Speaker 3>the main approach was,</v>

69
00:04:25.981 --> 00:04:29.720
<v Speaker 3>is what's called expert systems.</v>
<v Speaker 3>Sometimes it's called good old fashioned</v>

70
00:04:29.721 --> 00:04:33.230
<v Speaker 3>ai.</v>
<v Speaker 3>These days I'd go fly or traditional Ai,</v>

71
00:04:33.231 --> 00:04:35.780
<v Speaker 3>you could think of it.</v>
<v Speaker 3>And on the left hand side here,</v>

72
00:04:36.350 --> 00:04:39.170
<v Speaker 3>that's what what's involved is that we,</v>
<v Speaker 3>you know,</v>

73
00:04:39.200 --> 00:04:44.200
<v Speaker 3>teams are programmers and researchers </v>
<v Speaker 3>hardcode knowledge in the form of rules </v>

74
00:04:44.200 --> 00:04:49.060
<v Speaker 3>that they express in complex databases.</v>
<v Speaker 3>And you can imagine this sort of series </v>

75
00:04:49.251 --> 00:04:54.251
<v Speaker 3>of thousands of if then rules trying to </v>
<v Speaker 3>encapsulate the solution to whatever </v>

76
00:04:54.251 --> 00:04:55.790
<v Speaker 3>problem the program is supposed to be </v>
<v Speaker 3>dealing with.</v>

77
00:04:57.260 --> 00:04:57.680
<v Speaker 3>Now the,</v>
<v Speaker 3>the,</v>

78
00:04:57.681 --> 00:05:02.120
<v Speaker 3>the issue with those types of those </v>
<v Speaker 3>types of systems is they can't generally</v>

79
00:05:02.121 --> 00:05:05.270
<v Speaker 3>deal with the unexpected and they're </v>
<v Speaker 3>quite brittle because of that.</v>

80
00:05:05.630 --> 00:05:08.720
<v Speaker 3>So they're limited to the solutions that</v>
<v Speaker 3>have been pre programmed in them.</v>

81
00:05:09.440 --> 00:05:14.440
<v Speaker 3>They can't think for themselves and they</v>
<v Speaker 3>can't deal with anything that they </v>

82
00:05:14.440 --> 00:05:17.261
<v Speaker 3>weren't already prepared for.</v>
<v Speaker 3>So what this means is they're limited to</v>

83
00:05:18.170 --> 00:05:21.530
<v Speaker 3>solutions that we can express as the </v>
<v Speaker 3>programmers.</v>

84
00:05:21.830 --> 00:05:26.830
<v Speaker 3>So the program has themselves have to </v>
<v Speaker 3>understand in new detail what the </v>

85
00:05:26.830 --> 00:05:31.421
<v Speaker 3>solution is in order to handcraft </v>
<v Speaker 3>encodes the Hanco these knowledge </v>

86
00:05:32.091 --> 00:05:32.720
<v Speaker 3>systems.</v>

87
00:05:34.050 --> 00:05:37.290
<v Speaker 3>So these expert systems were inspired by</v>
<v Speaker 3>logic systems,</v>

88
00:05:37.770 --> 00:05:42.770
<v Speaker 3>logic theory.</v>
<v Speaker 3>If we now compare that to modern day </v>

89
00:05:43.471 --> 00:05:48.471
<v Speaker 3>learning systems and which is sort of </v>
<v Speaker 3>the advent of has been one of the </v>

90
00:05:48.471 --> 00:05:51.570
<v Speaker 3>reasons behind the rejuvenation and the </v>
<v Speaker 3>revolution in artificial intelligence in</v>

91
00:05:51.571 --> 00:05:55.170
<v Speaker 3>the last decade is because these </v>
<v Speaker 3>learning systems are now really starting</v>

92
00:05:55.171 --> 00:06:00.171
<v Speaker 3>to work and learning systems.</v>
<v Speaker 3>They learned solutions from first </v>

93
00:06:00.171 --> 00:06:04.931
<v Speaker 3>principles,</v>
<v Speaker 3>they learned directly from data and </v>

94
00:06:04.931 --> 00:06:07.271
<v Speaker 3>directly from experience and they learn </v>
<v Speaker 3>for themselves so they're not </v>

95
00:06:07.271 --> 00:06:10.931
<v Speaker 3>preprogrammed with solutions.</v>
<v Speaker 3>They have to figure out solutions for </v>

96
00:06:10.931 --> 00:06:14.110
<v Speaker 3>themselves and if we can build these </v>
<v Speaker 3>systems in a gentle enough way,</v>

97
00:06:14.350 --> 00:06:18.910
<v Speaker 3>they can generalize to new tasks they've</v>
<v Speaker 3>never seen before and perhaps even solve</v>

98
00:06:18.911 --> 00:06:21.250
<v Speaker 3>things that we don't know how to </v>
<v Speaker 3>ourselves,</v>

99
00:06:21.760 --> 00:06:26.760
<v Speaker 3>and that's the really amazing promise of</v>
<v Speaker 3>these systems is they could go beyond </v>

100
00:06:26.760 --> 00:06:30.301
<v Speaker 3>the knowledge that we have ourselves and</v>
<v Speaker 3>also it's of interesting domains which </v>

101
00:06:30.301 --> 00:06:34.951
<v Speaker 3>I'm going to talk about later in this </v>
<v Speaker 3>lecture and in the main learning systems</v>

102
00:06:35.631 --> 00:06:40.631
<v Speaker 3>are inspired by neuroscience and </v>
<v Speaker 3>informed by neuroscience and how the </v>

103
00:06:40.631 --> 00:06:45.611
<v Speaker 3>brain works and that's where we get a </v>
<v Speaker 3>lot of our inspiration from for the for </v>

104
00:06:45.611 --> 00:06:49.661
<v Speaker 3>building these types of architectures.</v>
<v Speaker 3>So expert systems are inspired by logic </v>

105
00:06:49.661 --> 00:06:51.110
<v Speaker 3>and learning.</v>
<v Speaker 3>Systems are inspired by the brain.</v>

106
00:06:53.760 --> 00:06:54.150
<v Speaker 3>Now,</v>
<v Speaker 3>still,</v>

107
00:06:54.151 --> 00:06:59.151
<v Speaker 3>the most famous example of an expert </v>
<v Speaker 3>system was IBM's deep blue computer that</v>

108
00:07:00.421 --> 00:07:03.570
<v Speaker 3>beat Garry Kasparov in the late nights </v>
<v Speaker 3>in the late nineties,</v>

109
00:07:04.480 --> 00:07:06.870
<v Speaker 3>who was at the time he was the world </v>
<v Speaker 3>champion of chess,</v>

110
00:07:06.900 --> 00:07:11.900
<v Speaker 3>which I'm sure all of you remember now.</v>
<v Speaker 3>This was obviously a very impressive </v>

111
00:07:11.900 --> 00:07:13.620
<v Speaker 3>technical feat.</v>
<v Speaker 3>And I remember this match very well.</v>

112
00:07:13.621 --> 00:07:18.621
<v Speaker 3>Um,</v>
<v Speaker 3>I was doing my undergraduate at </v>

113
00:07:18.621 --> 00:07:18.621
<v Speaker 3>Cambridge and we were sort of watching </v>
<v Speaker 3>this match.</v>

114
00:07:18.621 --> 00:07:18.960
<v Speaker 3>Um,</v>
<v Speaker 3>and as you can imagine,</v>

115
00:07:18.961 --> 00:07:23.961
<v Speaker 3>I was extremely interested in this from </v>
<v Speaker 3>both from the chest side and the </v>

116
00:07:23.961 --> 00:07:25.980
<v Speaker 3>computer science side.</v>
<v Speaker 3>And what I remember coming away from was</v>

117
00:07:25.981 --> 00:07:30.981
<v Speaker 3>actually,</v>
<v Speaker 3>although it's an impressive technical </v>

118
00:07:30.981 --> 00:07:33.081
<v Speaker 3>feat,</v>
<v Speaker 3>I came away from this match more </v>

119
00:07:33.081 --> 00:07:35.391
<v Speaker 3>impressed by Garry Kasparov,</v>
<v Speaker 3>mind than I was by the machine because </v>

120
00:07:35.391 --> 00:07:36.450
<v Speaker 3>he was gary,</v>
<v Speaker 3>you know,</v>

121
00:07:37.140 --> 00:07:40.080
<v Speaker 3>this amazing sort of creative genius,</v>
<v Speaker 3>uh,</v>

122
00:07:40.200 --> 00:07:45.200
<v Speaker 3>probably one of the best,</v>
<v Speaker 3>if not the best chess player of all </v>

123
00:07:45.200 --> 00:07:45.200
<v Speaker 3>time.</v>

124
00:07:45.200 --> 00:07:47.520
<v Speaker 3>And he was able to more or less hold his</v>
<v Speaker 3>own against this big brute of a machine.</v>

125
00:07:47.521 --> 00:07:52.521
<v Speaker 3>It was a huge super computer with </v>
<v Speaker 3>obviously teams are program programmers </v>

126
00:07:52.521 --> 00:07:55.491
<v Speaker 3>behind it with all these rules </v>
<v Speaker 3>programmed into it and not only was he </v>

127
00:07:55.491 --> 00:07:59.930
<v Speaker 3>able to compete on a more or less level </v>
<v Speaker 3>footing with the machine here cause he </v>

128
00:07:59.930 --> 00:08:01.560
<v Speaker 3>can do all the other things that we can </v>
<v Speaker 3>do as humans.</v>

129
00:08:01.561 --> 00:08:03.700
<v Speaker 3>He could speak three languages,</v>
<v Speaker 3>drive a car,</v>

130
00:08:03.701 --> 00:08:08.701
<v Speaker 3>or ride a bike.</v>
<v Speaker 3>All of these other things that we can </v>

131
00:08:08.701 --> 00:08:08.701
<v Speaker 3>marry out of things that we're able to </v>
<v Speaker 3>do.</v>

132
00:08:09.080 --> 00:08:13.020
<v Speaker 3>And if you compare that to deep blue,</v>
<v Speaker 3>which is obviously amazing at chess,</v>

133
00:08:13.280 --> 00:08:18.280
<v Speaker 3>I'm the blue,</v>
<v Speaker 3>could not even play a strictly simpler </v>

134
00:08:18.280 --> 00:08:21.291
<v Speaker 3>game,</v>
<v Speaker 3>say like noughts and crosses without </v>

135
00:08:21.291 --> 00:08:23.880
<v Speaker 3>being totally reprogrammed.</v>
<v Speaker 3>So nothing in the knowledge base of deep</v>

136
00:08:23.881 --> 00:08:28.881
<v Speaker 3>blue would help it do anything else.</v>
<v Speaker 3>So it was this hard coded specialized </v>

137
00:08:29.251 --> 00:08:32.820
<v Speaker 3>system that was only good for one thing </v>
<v Speaker 3>playing chess.</v>

138
00:08:33.390 --> 00:08:34.770
<v Speaker 3>And it seemed to me that,</v>
<v Speaker 3>you know,</v>

139
00:08:34.771 --> 00:08:38.010
<v Speaker 3>in terms of thinking about intelligence,</v>
<v Speaker 3>something was missing here,</v>

140
00:08:38.011 --> 00:08:39.930
<v Speaker 3>some critical things was we're missing </v>
<v Speaker 3>here.</v>

141
00:08:40.170 --> 00:08:42.570
<v Speaker 3>And what I believe was missing were </v>
<v Speaker 3>these two notions.</v>

142
00:08:42.571 --> 00:08:47.571
<v Speaker 3>This notion of learning and this notion </v>
<v Speaker 3>of generality and both of those things </v>

143
00:08:47.571 --> 00:08:50.700
<v Speaker 3>were missing from deep blue and expert </v>
<v Speaker 3>systems in general.</v>

144
00:08:51.840 --> 00:08:54.700
<v Speaker 3>And when I saw this match in after this </v>
<v Speaker 3>match,</v>

145
00:08:55.560 --> 00:09:00.560
<v Speaker 3>one of the things I resolved to do is to</v>
<v Speaker 3>one day build a general games playing </v>

146
00:09:00.560 --> 00:09:03.270
<v Speaker 3>machine that could play any game out of </v>
<v Speaker 3>the box.</v>

147
00:09:06.120 --> 00:09:11.120
<v Speaker 3>So let's look at what's been happening </v>
<v Speaker 3>with learning systems and actually the </v>

148
00:09:11.120 --> 00:09:15.771
<v Speaker 3>system,</v>
<v Speaker 3>the kind of framework we think about </v>

149
00:09:15.771 --> 00:09:16.800
<v Speaker 3>intelligence in at deep mind is a </v>
<v Speaker 3>framework called reinforcement learning.</v>

150
00:09:17.340 --> 00:09:22.340
<v Speaker 3>And um,</v>
<v Speaker 3>the idea behind reinforcement learning </v>

151
00:09:22.340 --> 00:09:22.340
<v Speaker 3>is that these systems,</v>
<v Speaker 3>these agents,</v>

152
00:09:22.340 --> 00:09:27.081
<v Speaker 3>we call them the AI systems,</v>
<v Speaker 3>that deep mind learn from first </v>

153
00:09:27.081 --> 00:09:30.471
<v Speaker 3>principles through trial and error.</v>
<v Speaker 3>So that's how they build up knowledge </v>

154
00:09:30.471 --> 00:09:34.701
<v Speaker 3>about the world.</v>
<v Speaker 3>And I'm just going to show you with the </v>

155
00:09:34.701 --> 00:09:35.310
<v Speaker 3>aid of a simple diagram how these </v>
<v Speaker 3>systems work at very high level.</v>

156
00:09:36.450 --> 00:09:38.460
<v Speaker 3>So first of all,</v>
<v Speaker 3>we start with the agent system.</v>

157
00:09:38.461 --> 00:09:43.461
<v Speaker 3>The AI system here on the left,</v>
<v Speaker 3>and the agent finds itself in some kind </v>

158
00:09:43.461 --> 00:09:48.381
<v Speaker 3>of environment.</v>
<v Speaker 3>Now the environment could be the real </v>

159
00:09:48.381 --> 00:09:48.381
<v Speaker 3>world,</v>
<v Speaker 3>in which case the agent,</v>

160
00:09:48.381 --> 00:09:52.911
<v Speaker 3>you can think of it as a robot,</v>
<v Speaker 3>a physical robot or the environment can </v>

161
00:09:52.911 --> 00:09:54.960
<v Speaker 3>be in virtual environment like a game or</v>
<v Speaker 3>simulation,</v>

162
00:09:55.250 --> 00:09:58.710
<v Speaker 3>a computer simulation,</v>
<v Speaker 3>in which case the agent would be like an</v>

163
00:09:58.711 --> 00:10:00.750
<v Speaker 3>Avatar in that game environment.</v>

164
00:10:01.500 --> 00:10:04.380
<v Speaker 3>And the agent has been given a goal by </v>
<v Speaker 3>the designers,</v>

165
00:10:04.550 --> 00:10:05.100
<v Speaker 3>uh,</v>
<v Speaker 3>to,</v>

166
00:10:05.280 --> 00:10:09.150
<v Speaker 3>to achieve within that environment.</v>
<v Speaker 3>Now,</v>

167
00:10:09.151 --> 00:10:12.360
<v Speaker 3>the agent only interacts with the </v>
<v Speaker 3>environment in two ways.</v>

168
00:10:12.840 --> 00:10:16.860
<v Speaker 3>So firstly through it sensory operators </v>
<v Speaker 3>and we normally use vision,</v>

169
00:10:16.861 --> 00:10:20.400
<v Speaker 3>but you could use other modalities like </v>
<v Speaker 3>audition and touch.</v>

170
00:10:20.730 --> 00:10:25.730
<v Speaker 3>Um,</v>
<v Speaker 3>but we use vision and you get these </v>

171
00:10:25.730 --> 00:10:27.340
<v Speaker 3>observations about the environment </v>
<v Speaker 3>through your senses.</v>

172
00:10:27.870 --> 00:10:32.870
<v Speaker 3>And the observations also include </v>
<v Speaker 3>rewards from the environment for doing </v>

173
00:10:32.870 --> 00:10:36.210
<v Speaker 3>the right things.</v>
<v Speaker 3>And the first job of the agent system is</v>

174
00:10:36.211 --> 00:10:38.940
<v Speaker 3>to build up a model of the world out </v>
<v Speaker 3>there,</v>

175
00:10:39.000 --> 00:10:44.000
<v Speaker 3>the environment now then how it works.</v>
<v Speaker 3>So it's got to figure out a statistical </v>

176
00:10:44.000 --> 00:10:45.420
<v Speaker 3>model about the environment it finds </v>
<v Speaker 3>itself in and,</v>

177
00:10:45.570 --> 00:10:50.570
<v Speaker 3>and the linkages in that environment.</v>
<v Speaker 3>And once it has a model of the world </v>

178
00:10:50.570 --> 00:10:53.280
<v Speaker 3>which is continually updating based on </v>
<v Speaker 3>your observations,</v>

179
00:10:53.440 --> 00:10:57.840
<v Speaker 3>then the second job of the agent system </v>
<v Speaker 3>is to pick the right action to take.</v>

180
00:10:58.230 --> 00:11:01.370
<v Speaker 3>So at any moment in time,</v>
<v Speaker 3>I'm the agent system,</v>

181
00:11:01.371 --> 00:11:06.371
<v Speaker 3>I have a whole array of actions </v>
<v Speaker 3>available to it and it's got to select </v>

182
00:11:06.371 --> 00:11:10.071
<v Speaker 3>the best action that will get it closest</v>
<v Speaker 3>towards achieving its goal at that </v>

183
00:11:10.501 --> 00:11:14.220
<v Speaker 3>moment in time.</v>
<v Speaker 3>And if the model of the world,</v>

184
00:11:14.221 --> 00:11:19.221
<v Speaker 3>the agent has is very good,</v>
<v Speaker 3>it can hypothesize in its mind what the </v>

185
00:11:19.221 --> 00:11:23.871
<v Speaker 3>consequences of doing certain actions </v>
<v Speaker 3>will be and what the likely change in </v>

186
00:11:23.871 --> 00:11:23.871
<v Speaker 3>the environment will be.</v>

187
00:11:25.280 --> 00:11:28.460
<v Speaker 3>And you can think of this system in a </v>
<v Speaker 3>cycle.</v>

188
00:11:28.670 --> 00:11:31.320
<v Speaker 3>So the agent,</v>
<v Speaker 3>once it runs out thinking time.</v>

189
00:11:31.321 --> 00:11:33.550
<v Speaker 3>So this is all a realtime system </v>
<v Speaker 3>outputs.</v>

190
00:11:33.560 --> 00:11:38.560
<v Speaker 3>The best action is found so far.</v>
<v Speaker 3>The action gets executed and then that </v>

191
00:11:38.560 --> 00:11:39.860
<v Speaker 3>may drive a new change in the </v>
<v Speaker 3>environment,</v>

192
00:11:39.861 --> 00:11:44.861
<v Speaker 3>which then drives a new observation.</v>
<v Speaker 3>And then the agent updates his model of </v>

193
00:11:44.861 --> 00:11:48.551
<v Speaker 3>the world and then selects a new action.</v>
<v Speaker 3>And this goes on in an incremental </v>

194
00:11:48.551 --> 00:11:52.181
<v Speaker 3>fashion until eventually through </v>
<v Speaker 3>sophisticated sort of trial error </v>

195
00:11:52.181 --> 00:11:54.070
<v Speaker 3>processes,</v>
<v Speaker 3>the agent reaches its goal.</v>

196
00:11:55.780 --> 00:11:57.850
<v Speaker 3>Now though I started com,</v>
<v Speaker 3>looks quite simple.</v>

197
00:11:58.000 --> 00:12:03.000
<v Speaker 3>There's actually a huge amount of </v>
<v Speaker 3>technical complexity behind this that </v>

198
00:12:03.000 --> 00:12:04.540
<v Speaker 3>needs to be sold.</v>
<v Speaker 3>Very complex technical challenges.</v>

199
00:12:04.870 --> 00:12:07.870
<v Speaker 3>But we know that if we could solve all </v>
<v Speaker 3>those challenges,</v>

200
00:12:07.960 --> 00:12:12.960
<v Speaker 3>this framework of reinforcement learning</v>
<v Speaker 3>is enough to give us general </v>

201
00:12:12.960 --> 00:12:14.500
<v Speaker 3>intelligence and we know that because </v>
<v Speaker 3>this is how the brain works.</v>

202
00:12:14.740 --> 00:12:15.880
<v Speaker 3>And um,</v>
<v Speaker 3>in fact,</v>

203
00:12:15.881 --> 00:12:16.660
<v Speaker 3>in,</v>
<v Speaker 3>in the,</v>

204
00:12:16.661 --> 00:12:21.310
<v Speaker 3>in the primate and human brain is the </v>
<v Speaker 3>dopamine system and dopamine neurons,</v>

205
00:12:21.430 --> 00:12:26.430
<v Speaker 3>they implement a form of reinforcement </v>
<v Speaker 3>learning and that actually allow us to </v>

206
00:12:26.430 --> 00:12:29.020
<v Speaker 3>learn using this system of reinforcement</v>
<v Speaker 3>based on rewards.</v>

207
00:12:32.660 --> 00:12:34.940
<v Speaker 3>So how did we develop this further?</v>
<v Speaker 3>Well,</v>

208
00:12:34.941 --> 00:12:39.941
<v Speaker 3>the first work we did is partly because </v>
<v Speaker 3>of my background in my previous career </v>

209
00:12:40.101 --> 00:12:44.000
<v Speaker 3>of designing video games and building ai</v>
<v Speaker 3>systems for,</v>

210
00:12:44.030 --> 00:12:45.640
<v Speaker 3>for video games.</v>
<v Speaker 3>Um,</v>

211
00:12:45.650 --> 00:12:50.650
<v Speaker 3>I realized that games would be the </v>
<v Speaker 3>perfect proving ground for developing </v>

212
00:12:50.650 --> 00:12:52.580
<v Speaker 3>and testing ai algorithms.</v>
<v Speaker 3>Normally when you work on ai,</v>

213
00:12:53.070 --> 00:12:56.600
<v Speaker 3>you often work with robotics.</v>
<v Speaker 3>But the problem with robotics is,</v>

214
00:12:56.610 --> 00:12:59.540
<v Speaker 3>and we love robotics as an application </v>
<v Speaker 3>area for ai,</v>

215
00:13:00.260 --> 00:13:05.260
<v Speaker 3>but as a development platform it's quite</v>
<v Speaker 3>tricky because you end up spending most </v>

216
00:13:05.260 --> 00:13:06.350
<v Speaker 3>of your time on the hardware,</v>
<v Speaker 3>you know,</v>

217
00:13:06.351 --> 00:13:09.860
<v Speaker 3>dealing with the server motors on the </v>
<v Speaker 3>robots and they always break and they're</v>

218
00:13:09.861 --> 00:13:11.990
<v Speaker 3>quite slow and they're very expensive to</v>
<v Speaker 3>use.</v>

219
00:13:12.240 --> 00:13:14.750
<v Speaker 3>Um,</v>
<v Speaker 3>and in fact it's much more convenient to</v>

220
00:13:14.751 --> 00:13:19.360
<v Speaker 3>use virtual simulations like games and </v>
<v Speaker 3>actually test the sophistication of your</v>

221
00:13:19.370 --> 00:13:22.940
<v Speaker 3>Ai Algorithms in,</v>
<v Speaker 3>in those simulations.</v>

222
00:13:24.280 --> 00:13:29.280
<v Speaker 3>So we,</v>
<v Speaker 3>we started with games and in fact we </v>

223
00:13:29.280 --> 00:13:31.450
<v Speaker 3>started with the most iconic,</v>
<v Speaker 3>sort of the first iconic game console,</v>

224
00:13:31.451 --> 00:13:36.451
<v Speaker 3>which was the Atari Twenty 600,</v>
<v Speaker 3>which some of you may remember from the </v>

225
00:13:36.451 --> 00:13:36.820
<v Speaker 3>eighties and we,</v>
<v Speaker 3>it was the first,</v>

226
00:13:36.821 --> 00:13:41.821
<v Speaker 3>we'll sort of,</v>
<v Speaker 3>big console game that had a big </v>

227
00:13:41.821 --> 00:13:41.821
<v Speaker 3>diversity of,</v>
<v Speaker 3>of games on it,</v>

228
00:13:41.821 --> 00:13:42.910
<v Speaker 3>very,</v>
<v Speaker 3>very different sorts of games.</v>

229
00:13:43.270 --> 00:13:48.270
<v Speaker 3>And we tested our system,</v>
<v Speaker 3>our first system back in 2013 on these </v>

230
00:13:48.521 --> 00:13:51.610
<v Speaker 3>Atari Games.</v>
<v Speaker 3>Before we show you a video that of the,</v>

231
00:13:51.611 --> 00:13:54.400
<v Speaker 3>of the system working,</v>
<v Speaker 3>I just want to explain to you what it is</v>

232
00:13:54.401 --> 00:13:57.250
<v Speaker 3>that you're going to see.</v>
<v Speaker 3>So the agent system,</v>

233
00:13:57.251 --> 00:14:01.810
<v Speaker 3>which we call Dqn,</v>
<v Speaker 3>I'm only gets the raw pixels as inputs,</v>

234
00:14:01.990 --> 00:14:04.540
<v Speaker 3>so I'm only gets the pixels on the </v>
<v Speaker 3>screen,</v>

235
00:14:04.541 --> 00:14:09.541
<v Speaker 3>the kind of values of the colors of the </v>
<v Speaker 3>pixels on the screen as inputs it isn't </v>

236
00:14:09.541 --> 00:14:12.160
<v Speaker 3>told anything else about the game.</v>
<v Speaker 3>Everything else is learned from scratch.</v>

237
00:14:12.161 --> 00:14:15.490
<v Speaker 3>It doesn't know what he's controlling.</v>
<v Speaker 3>It doesn't know how to get points.</v>

238
00:14:15.640 --> 00:14:18.040
<v Speaker 3>All it knows is here's a stream of </v>
<v Speaker 3>numbers,</v>

239
00:14:18.100 --> 00:14:23.100
<v Speaker 3>30,000</v>
<v Speaker 3>numbers per frame and the goal is to </v>

240
00:14:23.100 --> 00:14:26.761
<v Speaker 3>maximize the score,</v>
<v Speaker 3>doesn't know anything else about what </v>

241
00:14:26.761 --> 00:14:29.521
<v Speaker 3>it's supposed to do,</v>
<v Speaker 3>so it has to learn everything else from </v>

242
00:14:29.521 --> 00:14:29.521
<v Speaker 3>scratch.</v>
<v Speaker 3>And then the,</v>

243
00:14:29.521 --> 00:14:33.460
<v Speaker 3>the final sort of challenge if you like,</v>
<v Speaker 3>is this notion of generality.</v>

244
00:14:33.461 --> 00:14:38.050
<v Speaker 3>So we wanted one single system to be </v>
<v Speaker 3>able to play all the different games out</v>

245
00:14:38.051 --> 00:14:38.800
<v Speaker 3>of the box.</v>

246
00:14:42.200 --> 00:14:44.320
<v Speaker 3>So I'm going to show you my favorite </v>
<v Speaker 3>video,</v>

247
00:14:44.340 --> 00:14:48.050
<v Speaker 3>the Atari stuff working,</v>
<v Speaker 3>which is this game called breakout,</v>

248
00:14:48.290 --> 00:14:50.930
<v Speaker 3>which is one of those seminal games on </v>
<v Speaker 3>the Atari.</v>

249
00:14:51.650 --> 00:14:54.950
<v Speaker 3>And in this game you control the bat to </v>
<v Speaker 3>the bottom of the screen here.</v>

250
00:14:54.951 --> 00:14:59.951
<v Speaker 3>This pink bat that goes left and right </v>
<v Speaker 3>and you've got to bounce this little </v>

251
00:14:59.951 --> 00:15:03.491
<v Speaker 3>pink ball here,</v>
<v Speaker 3>this little pixel here on the left </v>

252
00:15:03.491 --> 00:15:06.640
<v Speaker 3>against this rainbow colored wall and </v>
<v Speaker 3>the idea of the game is you've got to </v>

253
00:15:06.640 --> 00:15:10.541
<v Speaker 3>knock out all the bricks in the wall and</v>
<v Speaker 3>you've got five lives and you can't </v>

254
00:15:10.541 --> 00:15:12.500
<v Speaker 3>allow the ball to go past the bat.</v>
<v Speaker 3>Otherwise you lose a life.</v>

255
00:15:13.100 --> 00:15:18.100
<v Speaker 3>So I'm just gonna run the video here and</v>
<v Speaker 3>you'll see the system improving over </v>

256
00:15:18.100 --> 00:15:22.481
<v Speaker 3>time as it gets more experienced playing</v>
<v Speaker 3>more games and starts to figure out </v>

257
00:15:22.481 --> 00:15:23.210
<v Speaker 3>what's happening in the game.</v>

258
00:15:24.720 --> 00:15:29.720
<v Speaker 3>So this is what it looks like after 100 </v>
<v Speaker 3>games and you can see the system is </v>

259
00:15:29.720 --> 00:15:32.100
<v Speaker 3>starting to get the hang of what is </v>
<v Speaker 3>supposed to be doing.</v>

260
00:15:32.170 --> 00:15:33.720
<v Speaker 3>So supposed to move the bat towards the </v>
<v Speaker 3>ball,</v>

261
00:15:33.721 --> 00:15:35.700
<v Speaker 3>but it's missing the ball most of the </v>
<v Speaker 3>time,</v>

262
00:15:35.880 --> 00:15:40.880
<v Speaker 3>but they're starting to get the idea </v>
<v Speaker 3>that maybe it's a good idea to move the </v>

263
00:15:40.880 --> 00:15:41.730
<v Speaker 3>bat towards the ball.</v>
<v Speaker 3>And then after 300 games.</v>

264
00:15:42.530 --> 00:15:45.570
<v Speaker 3>So now you can see it's about as good as</v>
<v Speaker 3>any human can play this.</v>

265
00:15:45.690 --> 00:15:47.400
<v Speaker 3>And it almost never misses the ball </v>
<v Speaker 3>anymore,</v>

266
00:15:47.401 --> 00:15:49.710
<v Speaker 3>even when it's coming back very fast </v>
<v Speaker 3>angles.</v>

267
00:15:50.040 --> 00:15:50.730
<v Speaker 3>So we thought,</v>
<v Speaker 3>wow,</v>

268
00:15:50.731 --> 00:15:55.731
<v Speaker 3>this is great.</v>
<v Speaker 3>But what happens if we left it playing </v>

269
00:15:55.731 --> 00:15:56.880
<v Speaker 3>for another 200 games?</v>
<v Speaker 3>And to our surprise,</v>

270
00:15:56.881 --> 00:15:58.770
<v Speaker 3>what it did is it found this optimal </v>
<v Speaker 3>strategy,</v>

271
00:15:58.771 --> 00:16:03.771
<v Speaker 3>which was to dig a tunnel around the </v>
<v Speaker 3>lefthand side and then send the ball </v>

272
00:16:03.771 --> 00:16:07.800
<v Speaker 3>behind the brick wall,</v>
<v Speaker 3>which was sort of an amazing solution to</v>

273
00:16:07.801 --> 00:16:08.730
<v Speaker 3>the problem in a way.</v>

274
00:16:08.970 --> 00:16:10.170
<v Speaker 3>And of course,</v>
<v Speaker 3>um,</v>

275
00:16:10.560 --> 00:16:11.160
<v Speaker 3>a,</v>
<v Speaker 3>a,</v>

276
00:16:11.200 --> 00:16:16.200
<v Speaker 3>you know,</v>
<v Speaker 3>it's sort of very low risk of the ball </v>

277
00:16:16.200 --> 00:16:18.411
<v Speaker 3>camp go past your bat and it's very </v>
<v Speaker 3>highly rewarding cause he hit many </v>

278
00:16:18.411 --> 00:16:20.040
<v Speaker 3>bricks with just one shot.</v>
<v Speaker 3>So when we saw this,</v>

279
00:16:20.041 --> 00:16:22.320
<v Speaker 3>this was our first have since met since </v>
<v Speaker 3>then,</v>

280
00:16:22.321 --> 00:16:27.321
<v Speaker 3>many Aha moments for us where we </v>
<v Speaker 3>actually learned something from our own </v>

281
00:16:27.321 --> 00:16:30.570
<v Speaker 3>system because the program is,</v>
<v Speaker 3>and the research is behind this,</v>

282
00:16:30.760 --> 00:16:32.880
<v Speaker 3>uh,</v>
<v Speaker 3>amazing researchers,</v>

283
00:16:32.940 --> 00:16:34.800
<v Speaker 3>but they're not so good at playing Atari</v>
<v Speaker 3>Games.</v>

284
00:16:34.950 --> 00:16:38.310
<v Speaker 3>So they didn't really know themselves </v>
<v Speaker 3>about this tactic.</v>

285
00:16:38.540 --> 00:16:43.540
<v Speaker 3>Um,</v>
<v Speaker 3>and obviously it's being executed with </v>

286
00:16:43.540 --> 00:16:43.540
<v Speaker 3>sort of incredible position from the,</v>
<v Speaker 3>from the system.</v>

287
00:16:45.120 --> 00:16:50.120
<v Speaker 3>So then we took these,</v>
<v Speaker 3>these systems and the next thing we </v>

288
00:16:50.120 --> 00:16:53.631
<v Speaker 3>worked on and applied it to was probably</v>
<v Speaker 3>our most famous program called Alphago </v>

289
00:16:54.060 --> 00:16:58.650
<v Speaker 3>and Alphago was our program using these </v>
<v Speaker 3>reinforcement learning ideas,</v>

290
00:16:59.100 --> 00:17:04.100
<v Speaker 3>scaled up even further to play the </v>
<v Speaker 3>ancient game of go and for those you </v>

291
00:17:04.100 --> 00:17:05.520
<v Speaker 3>don't know the game and I encourage you </v>
<v Speaker 3>all to learn.</v>

292
00:17:05.560 --> 00:17:08.490
<v Speaker 3>There's an amazing game that I think </v>
<v Speaker 3>you'd all like,</v>

293
00:17:08.810 --> 00:17:13.810
<v Speaker 3>this is what the board looks like.</v>
<v Speaker 3>It's a very esoteric and artistic game </v>

294
00:17:13.810 --> 00:17:18.620
<v Speaker 3>and it's played on a 19 by 19 grid and </v>
<v Speaker 3>you take turns black and white take </v>

295
00:17:18.781 --> 00:17:23.010
<v Speaker 3>turns to put stones on the vertices of </v>
<v Speaker 3>the of the board,</v>

296
00:17:23.190 --> 00:17:25.560
<v Speaker 3>and the board initially starts empty and</v>
<v Speaker 3>it fills up.</v>

297
00:17:27.380 --> 00:17:30.200
<v Speaker 3>Now the history of go is long and </v>
<v Speaker 3>storied one,</v>

298
00:17:30.380 --> 00:17:33.320
<v Speaker 3>it's over 3000 years old is invented in </v>
<v Speaker 3>China,</v>

299
00:17:33.640 --> 00:17:38.640
<v Speaker 3>has played all over Asia and in fact </v>
<v Speaker 3>it's considered in Asia to be more than </v>

300
00:17:38.640 --> 00:17:43.571
<v Speaker 3>just a game.</v>
<v Speaker 3>It's something more kin to poetry or </v>

301
00:17:43.571 --> 00:17:43.571
<v Speaker 3>art.</v>
<v Speaker 3>In fact,</v>

302
00:17:43.571 --> 00:17:47.291
<v Speaker 3>Confucius wrote about go as one of the </v>
<v Speaker 3>four great arts that any true scholars </v>

303
00:17:47.291 --> 00:17:49.130
<v Speaker 3>should master along with poetry,</v>
<v Speaker 3>calligraphy,</v>

304
00:17:49.220 --> 00:17:54.220
<v Speaker 3>music.</v>
<v Speaker 3>So it's really considered to be one of </v>

305
00:17:54.220 --> 00:17:57.021
<v Speaker 3>these sort of profound arts,</v>
<v Speaker 3>like all of these other artistic </v>

306
00:17:57.021 --> 00:17:59.550
<v Speaker 3>endeavors.</v>
<v Speaker 3>And today it's as popular as ever.</v>

307
00:17:59.551 --> 00:18:02.070
<v Speaker 3>40 million active players,</v>
<v Speaker 3>2000 professionals,</v>

308
00:18:02.460 --> 00:18:06.630
<v Speaker 3>and the game of go is incredibly simple.</v>
<v Speaker 3>I could teach you in five minutes.</v>

309
00:18:06.631 --> 00:18:10.500
<v Speaker 3>There's only two rules,</v>
<v Speaker 3>but the complexity that comes out of it,</v>

310
00:18:10.730 --> 00:18:15.730
<v Speaker 3>it was what makes it so elegant.</v>
<v Speaker 3>And one measure of that complexity is </v>

311
00:18:15.730 --> 00:18:18.240
<v Speaker 3>the fact there are 10 to the power,</v>
<v Speaker 3>170 possible board positions.</v>

312
00:18:18.330 --> 00:18:23.330
<v Speaker 3>So that's a one with 117 zeros after it.</v>
<v Speaker 3>And that's more than there are atoms in </v>

313
00:18:23.330 --> 00:18:24.390
<v Speaker 3>the universe,</v>
<v Speaker 3>right?</v>

314
00:18:24.391 --> 00:18:26.910
<v Speaker 3>So that's the level of complexity just </v>
<v Speaker 3>comes out of these tools.</v>

315
00:18:27.270 --> 00:18:28.100
<v Speaker 3>And,</v>
<v Speaker 3>um,</v>

316
00:18:28.320 --> 00:18:33.320
<v Speaker 3>and that's,</v>
<v Speaker 3>that's what makes the game so deep and </v>

317
00:18:33.320 --> 00:18:33.320
<v Speaker 3>so profound.</v>
<v Speaker 3>Uh,</v>

318
00:18:33.320 --> 00:18:33.720
<v Speaker 3>and,</v>
<v Speaker 3>you know,</v>

319
00:18:33.721 --> 00:18:38.721
<v Speaker 3>again,</v>
<v Speaker 3>sort of these ancient scholars thought </v>

320
00:18:38.721 --> 00:18:41.091
<v Speaker 3>about go is containing some of the </v>
<v Speaker 3>mysteries of the universe in it and </v>

321
00:18:41.091 --> 00:18:42.060
<v Speaker 3>therefore was worthy of this incredible </v>
<v Speaker 3>mouse study.</v>

322
00:18:43.320 --> 00:18:45.600
<v Speaker 3>And of course,</v>
<v Speaker 3>that complexity and uh,</v>

323
00:18:45.601 --> 00:18:50.601
<v Speaker 3>and the esoteric nature of the game is </v>
<v Speaker 3>one of the reasons which makes it so </v>

324
00:18:50.601 --> 00:18:53.841
<v Speaker 3>difficult for computers to play.</v>
<v Speaker 3>And the game of go proceeds one stone at</v>

325
00:18:54.481 --> 00:18:59.481
<v Speaker 3>a time,</v>
<v Speaker 3>when you place it down to the board </v>

326
00:18:59.481 --> 00:18:59.481
<v Speaker 3>fills up like this.</v>
<v Speaker 3>So this is the end of the game.</v>

327
00:18:59.481 --> 00:19:04.100
<v Speaker 3>And the way you determine the winner is </v>
<v Speaker 3>what you're trying to do with your </v>

328
00:19:04.100 --> 00:19:06.600
<v Speaker 3>stones is surround off a wall off empty </v>
<v Speaker 3>areas of territory.</v>

329
00:19:06.900 --> 00:19:08.810
<v Speaker 3>And then you count the number of,</v>
<v Speaker 3>um,</v>

330
00:19:08.880 --> 00:19:13.880
<v Speaker 3>uh,</v>
<v Speaker 3>the number of squares that you've </v>

331
00:19:13.880 --> 00:19:15.770
<v Speaker 3>surrounded compared to your opponent.</v>
<v Speaker 3>And the person that surrounded the most </v>

332
00:19:15.770 --> 00:19:16.560
<v Speaker 3>squares wins the game.</v>
<v Speaker 3>So in this case here,</v>

333
00:19:16.561 --> 00:19:19.350
<v Speaker 3>it's a very close game,</v>
<v Speaker 3>but white winds by one point.</v>

334
00:19:20.790 --> 00:19:24.030
<v Speaker 3>So why is go so hard for computers to </v>
<v Speaker 3>play?</v>

335
00:19:24.300 --> 00:19:28.920
<v Speaker 3>So after deep blue beat Garry Kasparov,</v>
<v Speaker 3>the next big challenge,</v>

336
00:19:28.940 --> 00:19:30.600
<v Speaker 3>the sort of Mount Everest,</v>
<v Speaker 3>if you like,</v>

337
00:19:30.810 --> 00:19:35.340
<v Speaker 3>of um,</v>
<v Speaker 3>computer ai research was go and go,</v>

338
00:19:35.341 --> 00:19:38.550
<v Speaker 3>is much harder than chess for computers.</v>
<v Speaker 3>One,</v>

339
00:19:38.580 --> 00:19:43.580
<v Speaker 3>because of this enormous number of </v>
<v Speaker 3>possibilities that I've just talked </v>

340
00:19:43.580 --> 00:19:44.850
<v Speaker 3>about,</v>
<v Speaker 3>this 10 to 170 possible positions.</v>

341
00:19:44.940 --> 00:19:46.860
<v Speaker 3>So the search base is,</v>
<v Speaker 3>is much,</v>

342
00:19:46.861 --> 00:19:51.861
<v Speaker 3>much bigger than it is for chess,</v>
<v Speaker 3>but the second and kind of even harder </v>

343
00:19:51.861 --> 00:19:55.740
<v Speaker 3>problem is I'm CESC per program chess </v>
<v Speaker 3>engines including deep blue,</v>

344
00:19:55.980 --> 00:19:58.170
<v Speaker 3>rely on what's called an evaluation </v>
<v Speaker 3>function.</v>

345
00:19:58.350 --> 00:20:03.350
<v Speaker 3>So this is one of these handcrafted </v>
<v Speaker 3>rules based systems that tell the </v>

346
00:20:03.350 --> 00:20:07.011
<v Speaker 3>machine which side is winning in the </v>
<v Speaker 3>current position and that's what allows </v>

347
00:20:07.011 --> 00:20:11.570
<v Speaker 3>the blue and it's a and his successes,</v>
<v Speaker 3>his descendants to figure out what the </v>

348
00:20:12.511 --> 00:20:17.460
<v Speaker 3>right move is to play the palm go is </v>
<v Speaker 3>it's such an Easter game,</v>

349
00:20:17.670 --> 00:20:22.670
<v Speaker 3>it's impossible to figure out what the </v>
<v Speaker 3>right set of rules are and encapsulate </v>

350
00:20:22.670 --> 00:20:22.800
<v Speaker 3>that in a rules based system.</v>

351
00:20:23.220 --> 00:20:25.720
<v Speaker 3>Even if you ask top go players,</v>
<v Speaker 3>you know,</v>

352
00:20:25.770 --> 00:20:30.770
<v Speaker 3>why did they make a particular move?</v>
<v Speaker 3>They'll often tell you it just felt </v>

353
00:20:30.770 --> 00:20:34.551
<v Speaker 3>right,</v>
<v Speaker 3>but they won't actually be able to </v>

354
00:20:34.551 --> 00:20:34.551
<v Speaker 3>explicitly tell you themselves why they </v>
<v Speaker 3>pick the move.</v>

355
00:20:34.590 --> 00:20:36.630
<v Speaker 3>Whereas if you ask that to a top chess </v>
<v Speaker 3>player,</v>

356
00:20:36.780 --> 00:20:39.510
<v Speaker 3>they'll almost certainly give you a </v>
<v Speaker 3>specific plan.</v>

357
00:20:39.511 --> 00:20:40.630
<v Speaker 3>They were thinking about,</v>
<v Speaker 3>you know,</v>

358
00:20:40.660 --> 00:20:43.590
<v Speaker 3>I was planning a than I thought it would</v>
<v Speaker 3>happen and I was going to answer.</v>

359
00:20:43.591 --> 00:20:47.800
<v Speaker 3>See now that plan in the end may not be </v>
<v Speaker 3>very good or may fail for some reason,</v>

360
00:20:47.801 --> 00:20:50.230
<v Speaker 3>but they normally have an explicit plan </v>
<v Speaker 3>in go.</v>

361
00:20:50.231 --> 00:20:54.310
<v Speaker 3>It's much more about feel much more how </v>
<v Speaker 3>an artist would think,</v>

362
00:20:56.710 --> 00:21:01.710
<v Speaker 3>and one way to think about that is the </v>
<v Speaker 3>goal is primarily game about about </v>

363
00:21:01.710 --> 00:21:05.941
<v Speaker 3>intuition rather than calculation,</v>
<v Speaker 3>which is more dominant in a game like </v>

364
00:21:06.101 --> 00:21:09.160
<v Speaker 3>chess.</v>
<v Speaker 3>So that's how humans players,</v>

365
00:21:09.190 --> 00:21:14.190
<v Speaker 3>professional players deal with this </v>
<v Speaker 3>enormous complexity and this evaluation </v>

366
00:21:14.190 --> 00:21:17.341
<v Speaker 3>function.</v>
<v Speaker 3>They rely on their instincts and their </v>

367
00:21:17.341 --> 00:21:17.341
<v Speaker 3>intuition.</v>

368
00:21:17.341 --> 00:21:21.690
<v Speaker 3>So we ended up taking a totally </v>
<v Speaker 3>different approach to the way that chess</v>

369
00:21:21.691 --> 00:21:26.691
<v Speaker 3>computers were built.</v>
<v Speaker 3>And we built our Alphago with these </v>

370
00:21:26.691 --> 00:21:28.170
<v Speaker 3>learning systems and we actually </v>
<v Speaker 3>created.</v>

371
00:21:28.540 --> 00:21:33.090
<v Speaker 3>We were to neural networks,</v>
<v Speaker 3>which are loosely based on how the brain</v>

372
00:21:33.091 --> 00:21:36.030
<v Speaker 3>works to deal with these complex </v>
<v Speaker 3>problems.</v>

373
00:21:36.360 --> 00:21:40.380
<v Speaker 3>We create a one your network called the </v>
<v Speaker 3>policy network that takes in the current</v>

374
00:21:40.381 --> 00:21:45.381
<v Speaker 3>ball position and learns through looking</v>
<v Speaker 3>at millions of different games and </v>

375
00:21:45.381 --> 00:21:49.431
<v Speaker 3>playing millions of different millions </v>
<v Speaker 3>of games against itself and seeing and </v>

376
00:21:49.431 --> 00:21:50.350
<v Speaker 3>experiencing millions of games of go.</v>
<v Speaker 3>Um,</v>

377
00:21:50.570 --> 00:21:55.570
<v Speaker 3>what sorts of moods are most likely to </v>
<v Speaker 3>be played in a particular position so </v>

378
00:21:55.570 --> 00:21:58.140
<v Speaker 3>you can think of it taking the current </v>
<v Speaker 3>board position and returning to you,</v>

379
00:21:58.230 --> 00:22:00.930
<v Speaker 3>like the top five most likely moves to </v>
<v Speaker 3>be made.</v>

380
00:22:01.320 --> 00:22:06.320
<v Speaker 3>So that really narrows down this </v>
<v Speaker 3>enormous search base that you need to </v>

381
00:22:06.320 --> 00:22:09.321
<v Speaker 3>explore.</v>
<v Speaker 3>We then have to look at everything </v>

382
00:22:09.321 --> 00:22:09.321
<v Speaker 3>anymore,</v>
<v Speaker 3>like a brute force system would have to.</v>

383
00:22:09.321 --> 00:22:10.260
<v Speaker 3>You can just look at them,</v>
<v Speaker 3>most likely moves.</v>

384
00:22:11.420 --> 00:22:15.710
<v Speaker 3>And then the second thing that was kind </v>
<v Speaker 3>of sort of an unknown whether this could</v>

385
00:22:15.711 --> 00:22:20.711
<v Speaker 3>be done was we built a system that could</v>
<v Speaker 3>take this to the second year network </v>

386
00:22:20.711 --> 00:22:25.181
<v Speaker 3>called the value net here on the right,</v>
<v Speaker 3>the pink network that could take the </v>

387
00:22:25.181 --> 00:22:26.320
<v Speaker 3>current board position and return a </v>
<v Speaker 3>value.</v>

388
00:22:26.321 --> 00:22:29.240
<v Speaker 3>Your probability between zero and one of</v>
<v Speaker 3>who was winning.</v>

389
00:22:29.600 --> 00:22:32.810
<v Speaker 3>So zero would be white,</v>
<v Speaker 3>100 percent likely to win,</v>

390
00:22:33.030 --> 00:22:36.320
<v Speaker 3>a one would be black,</v>
<v Speaker 3>100 percent likely to win and point five</v>

391
00:22:36.340 --> 00:22:41.340
<v Speaker 3>would mean equal position and oversee </v>
<v Speaker 3>over through a course of training of </v>

392
00:22:41.340 --> 00:22:43.190
<v Speaker 3>millions paying millions of games </v>
<v Speaker 3>against itself,</v>

393
00:22:43.400 --> 00:22:48.400
<v Speaker 3>it learns to predict from any position </v>
<v Speaker 3>who is going to win the game and how </v>

394
00:22:48.591 --> 00:22:53.591
<v Speaker 3>confident was in that prediction.</v>
<v Speaker 3>And so by combining these two neural </v>

395
00:22:53.631 --> 00:22:56.300
<v Speaker 3>networks into one system which became </v>
<v Speaker 3>the Alphago System,</v>

396
00:22:56.510 --> 00:23:01.010
<v Speaker 3>we're able to solve these two very </v>
<v Speaker 3>difficult challenges that go presents.</v>

397
00:23:02.080 --> 00:23:07.080
<v Speaker 3>And once we had this system,</v>
<v Speaker 3>we decided to challenge one of the </v>

398
00:23:07.080 --> 00:23:10.861
<v Speaker 3>greatest players ever in go history,</v>
<v Speaker 3>a genius South Korea and grandmaster </v>

399
00:23:12.310 --> 00:23:14.140
<v Speaker 3>called Lisa Doll.</v>
<v Speaker 3>He's eight,</v>

400
00:23:14.141 --> 00:23:14.770
<v Speaker 3>one,</v>
<v Speaker 3>18,</v>

401
00:23:14.771 --> 00:23:19.090
<v Speaker 3>well titles and he was considered to be </v>
<v Speaker 3>the greatest player of the past decade.</v>

402
00:23:19.480 --> 00:23:22.930
<v Speaker 3>And we had a million dollar challenge </v>
<v Speaker 3>match in Seoul,</v>

403
00:23:22.960 --> 00:23:25.300
<v Speaker 3>South Korea,</v>
<v Speaker 3>in back in 2016.</v>

404
00:23:25.630 --> 00:23:26.640
<v Speaker 3>And um,</v>
<v Speaker 3>you know,</v>

405
00:23:26.680 --> 00:23:28.240
<v Speaker 3>before that match,</v>
<v Speaker 3>everybody,</v>

406
00:23:28.241 --> 00:23:33.241
<v Speaker 3>including Lisa doll,</v>
<v Speaker 3>thought it would be a whitewash </v>

407
00:23:33.241 --> 00:23:34.510
<v Speaker 3>whitewash to Lisa doll because until </v>
<v Speaker 3>this point,</v>

408
00:23:34.690 --> 00:23:38.530
<v Speaker 3>no go program had ever even beat in a </v>
<v Speaker 3>professional player,</v>

409
00:23:38.620 --> 00:23:41.140
<v Speaker 3>let alone a world champion.</v>
<v Speaker 3>So,</v>

410
00:23:41.240 --> 00:23:46.240
<v Speaker 3>um,</v>
<v Speaker 3>so all these sort of traditional </v>

411
00:23:46.240 --> 00:23:46.240
<v Speaker 3>techniques that were being used to make </v>
<v Speaker 3>computers,</v>

412
00:23:46.240 --> 00:23:51.190
<v Speaker 3>even though they've been developed for a</v>
<v Speaker 3>further 20 years since the deepblue </v>

413
00:23:51.190 --> 00:23:54.310
<v Speaker 3>match,</v>
<v Speaker 3>they still hadn't got anywhere near to </v>

414
00:23:54.310 --> 00:23:54.670
<v Speaker 3>professional level in go.</v>

415
00:23:56.310 --> 00:24:01.310
<v Speaker 3>So we played this match and over 200 </v>
<v Speaker 3>million people across the world watched </v>

416
00:24:01.701 --> 00:24:06.701
<v Speaker 3>the five matches and I'm Alphago </v>
<v Speaker 3>incredibly won the match for one and it </v>

417
00:24:07.711 --> 00:24:12.711
<v Speaker 3>was proclaimed by many experts both in </v>
<v Speaker 3>ai and go to be a decade before its </v>

418
00:24:13.021 --> 00:24:14.110
<v Speaker 3>time,</v>
<v Speaker 3>uh,</v>

419
00:24:14.540 --> 00:24:19.540
<v Speaker 3>and you know,</v>
<v Speaker 3>it was kind of a mentor match that I </v>

420
00:24:19.540 --> 00:24:21.531
<v Speaker 3>think will go down in history in,</v>
<v Speaker 3>in sort of ai as an ai landmark and </v>

421
00:24:21.531 --> 00:24:24.300
<v Speaker 3>there's often been called since then as </v>
<v Speaker 3>a sort of sputnik event for ai,</v>

422
00:24:24.640 --> 00:24:29.640
<v Speaker 3>especially for China and Asia.</v>
<v Speaker 3>But the most important thing is </v>

423
00:24:29.640 --> 00:24:31.110
<v Speaker 3>obviously we are,</v>
<v Speaker 3>Alphago won the match and that's what we</v>

424
00:24:31.111 --> 00:24:33.420
<v Speaker 3>built it for.</v>
<v Speaker 3>But the most interesting thing about the</v>

425
00:24:33.421 --> 00:24:35.640
<v Speaker 3>match was how Alphago won,</v>
<v Speaker 3>um,</v>

426
00:24:35.720 --> 00:24:40.720
<v Speaker 3>and how it played.</v>
<v Speaker 3>So I just want to explain to you a </v>

427
00:24:40.720 --> 00:24:44.310
<v Speaker 3>little bit about Alphago's play.</v>
<v Speaker 3>Even though most of you may not know how</v>

428
00:24:44.311 --> 00:24:44.670
<v Speaker 3>to play.</v>

429
00:24:44.670 --> 00:24:49.670
<v Speaker 3>Go,</v>
<v Speaker 3>I think you can still appreciate what </v>

430
00:24:49.670 --> 00:24:52.161
<v Speaker 3>Alpha go dead.</v>
<v Speaker 3>So this is a board position from game </v>

431
00:24:52.161 --> 00:24:54.120
<v Speaker 3>too,</v>
<v Speaker 3>and this is move 37,</v>

432
00:24:54.240 --> 00:24:56.370
<v Speaker 3>which is probably the most famous move </v>
<v Speaker 3>in the match.</v>

433
00:24:56.670 --> 00:24:58.630
<v Speaker 3>And um,</v>
<v Speaker 3>Alphago is black hair,</v>

434
00:24:58.640 --> 00:25:03.640
<v Speaker 3>it says very early in the game,</v>
<v Speaker 3>at least a dollar is white and Alphago </v>

435
00:25:03.640 --> 00:25:06.060
<v Speaker 3>plays this move here on the right hand </v>
<v Speaker 3>side outlined in red,</v>

436
00:25:06.720 --> 00:25:11.720
<v Speaker 3>this stone here.</v>
<v Speaker 3>And the key thing to notice about where </v>

437
00:25:11.720 --> 00:25:12.750
<v Speaker 3>this stone has been placed is that it's </v>
<v Speaker 3>on the fifth line.</v>

438
00:25:13.170 --> 00:25:16.140
<v Speaker 3>So you can see it's on the fifth line </v>
<v Speaker 3>from the right hand side of the board,</v>

439
00:25:16.390 --> 00:25:19.650
<v Speaker 3>the board's 19 by 19.</v>
<v Speaker 3>Now in the openings,</v>

440
00:25:19.770 --> 00:25:24.770
<v Speaker 3>if you're professional,</v>
<v Speaker 3>you almost always play on the third or </v>

441
00:25:24.770 --> 00:25:27.771
<v Speaker 3>fourth lines.</v>
<v Speaker 3>And that's the most important lines to </v>

442
00:25:27.771 --> 00:25:27.771
<v Speaker 3>be,</v>
<v Speaker 3>um,</v>

443
00:25:27.771 --> 00:25:29.340
<v Speaker 3>to be disputing early on in the game of </v>
<v Speaker 3>go.</v>

444
00:25:30.180 --> 00:25:33.700
<v Speaker 3>So a play on the fifth line this early </v>
<v Speaker 3>on is kind of unthinkable.</v>

445
00:25:33.760 --> 00:25:38.760
<v Speaker 3>No professional player would even </v>
<v Speaker 3>consider this move because it seems </v>

446
00:25:38.760 --> 00:25:42.220
<v Speaker 3>suboptimal and wasteful.</v>
<v Speaker 3>And yet Alphago decided to play here.</v>

447
00:25:42.490 --> 00:25:45.580
<v Speaker 3>And then it turned out the reason the </v>
<v Speaker 3>alpha go played,</v>

448
00:25:45.581 --> 00:25:49.720
<v Speaker 3>there was 100 moves later.</v>
<v Speaker 3>These two stones here in the bottom left</v>

449
00:25:49.721 --> 00:25:54.721
<v Speaker 3>hand corner that I ringed in red,</v>
<v Speaker 3>ended up kind of fighting on the bottom </v>

450
00:25:54.721 --> 00:25:58.591
<v Speaker 3>left here with the board,</v>
<v Speaker 3>ended up spilling all the way into the </v>

451
00:25:58.591 --> 00:25:59.020
<v Speaker 3>middle of the board and moving all </v>
<v Speaker 3>across the board.</v>

452
00:25:59.080 --> 00:26:04.080
<v Speaker 3>And then 100 years later ended up </v>
<v Speaker 3>connecting up perfectly with this stone </v>

453
00:26:04.080 --> 00:26:07.861
<v Speaker 3>on the right hand side and move 37.</v>
<v Speaker 3>And that was ended up being decisive in </v>

454
00:26:07.861 --> 00:26:09.040
<v Speaker 3>that battle.</v>
<v Speaker 3>And at one Alphago the whole game,</v>

455
00:26:09.610 --> 00:26:14.610
<v Speaker 3>right?</v>
<v Speaker 3>So somehow it's as if Alphago had </v>

456
00:26:14.610 --> 00:26:16.210
<v Speaker 3>resigned,</v>
<v Speaker 3>the understood this was gonna happen and</v>

457
00:26:16.211 --> 00:26:20.020
<v Speaker 3>position that stone perfectly for 100 </v>
<v Speaker 3>moves into the future.</v>

458
00:26:21.740 --> 00:26:26.740
<v Speaker 3>So of course it will.</v>
<v Speaker 3>The interesting thing is we can all </v>

459
00:26:26.740 --> 00:26:30.820
<v Speaker 3>think about what is creativity,</v>
<v Speaker 3>and I'm going to come and talk a little </v>

460
00:26:30.820 --> 00:26:32.210
<v Speaker 3>bit more about that in the latter part </v>
<v Speaker 3>of this talk,</v>

461
00:26:32.480 --> 00:26:35.090
<v Speaker 3>but we could all play an original movie </v>
<v Speaker 3>in some sense.</v>

462
00:26:35.091 --> 00:26:40.091
<v Speaker 3>Even if we didn't add to play God,</v>
<v Speaker 3>we call just play a random move on the </v>

463
00:26:40.091 --> 00:26:40.220
<v Speaker 3>board and that will be surprising in </v>
<v Speaker 3>some sense,</v>

464
00:26:40.490 --> 00:26:45.490
<v Speaker 3>but the key thing about going is </v>
<v Speaker 3>although it's considered to be an art </v>

465
00:26:45.490 --> 00:26:45.870
<v Speaker 3>form,</v>
<v Speaker 3>it's like objective art,</v>

466
00:26:46.100 --> 00:26:51.100
<v Speaker 3>so a movie is only considered original </v>
<v Speaker 3>and creative if it ends up being </v>

467
00:26:51.100 --> 00:26:52.320
<v Speaker 3>effective and you can measure the </v>
<v Speaker 3>effectiveness,</v>

468
00:26:52.450 --> 00:26:57.450
<v Speaker 3>obviously seeing the result of the game </v>
<v Speaker 3>and then starting that afterwards and </v>

469
00:26:57.450 --> 00:27:01.071
<v Speaker 3>seeing if that move really had a </v>
<v Speaker 3>material difference to the outcome and </v>

470
00:27:01.591 --> 00:27:03.970
<v Speaker 3>you don't have to take my word for it.</v>
<v Speaker 3>You can see this.</v>

471
00:27:04.000 --> 00:27:08.510
<v Speaker 3>I'm just going to play this very short,</v>
<v Speaker 3>that funny clip from the live commentary</v>

472
00:27:08.790 --> 00:27:11.010
<v Speaker 3>stream that was going out to the </v>
<v Speaker 3>millions of players.</v>

473
00:27:11.160 --> 00:27:14.790
<v Speaker 3>There will be watching this on youtube </v>
<v Speaker 3>and I'm on the right hand side.</v>

474
00:27:14.791 --> 00:27:18.780
<v Speaker 3>Here is the strongest player the West </v>
<v Speaker 3>has ever produced.</v>

475
00:27:18.870 --> 00:27:23.870
<v Speaker 3>Michael Redmond,</v>
<v Speaker 3>who's nine damn professional and his </v>

476
00:27:23.870 --> 00:27:26.601
<v Speaker 3>reaction,</v>
<v Speaker 3>he's watching the game live and </v>

477
00:27:26.601 --> 00:27:26.880
<v Speaker 3>commentating on it to seeing this move.</v>
<v Speaker 3>Thirty seven,</v>

478
00:27:27.410 --> 00:27:28.300
<v Speaker 3>so hopefully you'll be your to here.</v>

479
00:27:28.580 --> 00:27:33.580
<v Speaker 4>The Google team was talking about is </v>
<v Speaker 4>this kind of a value?</v>

480
00:27:39.070 --> 00:27:44.070
<v Speaker 4>That's very surprising move.</v>
<v Speaker 4>I thought I thought it was a mistake</v>

481
00:27:45.390 --> 00:27:50.390
<v Speaker 3>so you can hear that he thought it was a</v>
<v Speaker 3>mistake and he goes on to say later in </v>

482
00:27:50.390 --> 00:27:51.620
<v Speaker 3>that clip that he thought it was a </v>
<v Speaker 3>misclick,</v>

483
00:27:51.680 --> 00:27:56.680
<v Speaker 3>so he thought our computer operator had </v>
<v Speaker 3>actually clicked the wrong place on the </v>

484
00:27:56.680 --> 00:27:56.830
<v Speaker 3>board,</v>
<v Speaker 3>the computer board,</v>

485
00:27:56.831 --> 00:28:01.490
<v Speaker 3>because he couldn't believe that Alphago</v>
<v Speaker 3>or would play that move.</v>

486
00:28:03.770 --> 00:28:08.770
<v Speaker 3>Then of course I must mention that Lisa </v>
<v Speaker 3>doll himself came up with his own </v>

487
00:28:08.871 --> 00:28:13.871
<v Speaker 3>incredible,</v>
<v Speaker 3>brilliant moving game for which was the </v>

488
00:28:13.871 --> 00:28:13.871
<v Speaker 3>game that he won,</v>
<v Speaker 3>almost move 78,</v>

489
00:28:13.871 --> 00:28:18.370
<v Speaker 3>which this move in the middle of this </v>
<v Speaker 3>called a wedge move and that has been </v>

490
00:28:18.370 --> 00:28:19.370
<v Speaker 3>analyzed by all the players around the </v>
<v Speaker 3>world.</v>

491
00:28:19.371 --> 00:28:22.550
<v Speaker 3>Both this move and move 37 in the two </v>
<v Speaker 3>years hence.</v>

492
00:28:22.730 --> 00:28:24.950
<v Speaker 3>And they're both being proclaimed to be </v>
<v Speaker 3>amazing moves.</v>

493
00:28:25.040 --> 00:28:27.230
<v Speaker 3>And this move here,</v>
<v Speaker 3>I haven't got time to explain about it,</v>

494
00:28:27.410 --> 00:28:32.410
<v Speaker 3>but it triggered a misvaluation in Alpha</v>
<v Speaker 3>goes networks and that's what allowed </v>

495
00:28:32.410 --> 00:28:33.470
<v Speaker 3>these adults to win,</v>
<v Speaker 3>to win that game.</v>

496
00:28:34.640 --> 00:28:35.780
<v Speaker 3>So for us,</v>
<v Speaker 3>this was a,</v>

497
00:28:36.050 --> 00:28:41.050
<v Speaker 3>an amazing sort of once in a lifetime </v>
<v Speaker 3>experience and it was full of drama for </v>

498
00:28:41.050 --> 00:28:44.621
<v Speaker 3>us and if you're interested to see a </v>
<v Speaker 3>little bit more about the kind of the </v>

499
00:28:44.621 --> 00:28:46.520
<v Speaker 3>human emotions and the spirit of human </v>
<v Speaker 3>endeavor behind this match,</v>

500
00:28:46.521 --> 00:28:51.521
<v Speaker 3>I'd encourage you to watch this </v>
<v Speaker 3>documentary award winning documentary </v>

501
00:28:51.521 --> 00:28:53.000
<v Speaker 3>that done by this brilliant director,</v>
<v Speaker 3>Greg Coast,</v>

502
00:28:53.001 --> 00:28:58.001
<v Speaker 3>which is available on Netflix and you'll</v>
<v Speaker 3>see what went into the match and the </v>

503
00:28:58.001 --> 00:28:59.390
<v Speaker 3>nuances behind it and what the goplayers</v>
<v Speaker 3>thought.</v>

504
00:28:59.780 --> 00:29:01.670
<v Speaker 3>But there's one thing I want to quote </v>
<v Speaker 3>about from there,</v>

505
00:29:01.671 --> 00:29:06.671
<v Speaker 3>which is Lisa Dell's own thoughts and </v>
<v Speaker 3>reflections on move 37 after the match.</v>

506
00:29:07.190 --> 00:29:12.190
<v Speaker 3>The director asked him what he thought </v>
<v Speaker 3>about Alphago and route 37.</v>

507
00:29:13.070 --> 00:29:18.070
<v Speaker 3>And he said,</v>
<v Speaker 3>I thought Alphago is based on </v>

508
00:29:18.070 --> 00:29:18.070
<v Speaker 3>probability calculation and it was </v>
<v Speaker 3>merely a machine.</v>

509
00:29:18.070 --> 00:29:19.850
<v Speaker 3>But when I saw this move,</v>
<v Speaker 3>I changed my mind.</v>

510
00:29:20.120 --> 00:29:25.120
<v Speaker 3>Surely Alphago is creative.</v>
<v Speaker 3>This move was really be creative and </v>

511
00:29:25.120 --> 00:29:27.140
<v Speaker 3>beautiful.</v>
<v Speaker 3>So as really amazing moment and I,</v>

512
00:29:27.141 --> 00:29:29.450
<v Speaker 3>I kind of nearly cried when I saw that </v>
<v Speaker 3>on the film.</v>

513
00:29:29.451 --> 00:29:32.000
<v Speaker 3>After said I didn't see him say that in </v>
<v Speaker 3>the live.</v>

514
00:29:32.270 --> 00:29:34.490
<v Speaker 3>And I thought it was an amazing thing </v>
<v Speaker 3>for him to say,</v>

515
00:29:34.491 --> 00:29:36.110
<v Speaker 3>and,</v>
<v Speaker 3>and very,</v>

516
00:29:36.140 --> 00:29:38.690
<v Speaker 3>uh,</v>
<v Speaker 3>deep of him to realize that.</v>

517
00:29:40.160 --> 00:29:45.160
<v Speaker 3>So I want to now just talk a little bit </v>
<v Speaker 3>about these words I've been using and </v>

518
00:29:45.160 --> 00:29:45.310
<v Speaker 3>throwing around intuition and </v>
<v Speaker 3>creativity.</v>

519
00:29:45.490 --> 00:29:49.420
<v Speaker 3>What do I mean by that?</v>
<v Speaker 3>At least in this context,</v>

520
00:29:49.480 --> 00:29:54.480
<v Speaker 3>and I should caveat this with,</v>
<v Speaker 3>and I'm sure we'll get into this in the </v>

521
00:29:54.480 --> 00:29:54.480
<v Speaker 3>q and a,</v>
<v Speaker 3>that I'm not saying this is,</v>

522
00:29:54.480 --> 00:29:56.920
<v Speaker 3>encompasses all of what we think of is </v>
<v Speaker 3>intuition and creativity.</v>

523
00:29:57.100 --> 00:30:02.100
<v Speaker 3>But I think at least want to think about</v>
<v Speaker 3>operationalizing some of these </v>

524
00:30:02.100 --> 00:30:04.210
<v Speaker 3>definitions so we can discuss it in a </v>
<v Speaker 3>scientific way.</v>

525
00:30:05.640 --> 00:30:08.250
<v Speaker 3>So intuition then the way I think about </v>
<v Speaker 3>intuition,</v>

526
00:30:08.430 --> 00:30:13.430
<v Speaker 3>it's really,</v>
<v Speaker 3>it's implicit knowledge that we have </v>

527
00:30:13.430 --> 00:30:16.340
<v Speaker 3>acquired through experience,</v>
<v Speaker 3>but it's knowledge that's not </v>

528
00:30:16.340 --> 00:30:19.320
<v Speaker 3>consciously expressible or accessible.</v>
<v Speaker 3>So we can't consciously access it and we</v>

529
00:30:19.321 --> 00:30:21.750
<v Speaker 3>can't express it to others.</v>
<v Speaker 3>And that's what,</v>

530
00:30:21.780 --> 00:30:23.760
<v Speaker 3>why it seems a little bit mysterious to </v>
<v Speaker 3>us.</v>

531
00:30:24.150 --> 00:30:26.670
<v Speaker 3>This kind of implicit knowledge.</v>
<v Speaker 3>Now,</v>

532
00:30:26.671 --> 00:30:31.671
<v Speaker 3>of course we know we have it and you can</v>
<v Speaker 3>test the existence in the quality of it </v>

533
00:30:31.671 --> 00:30:34.340
<v Speaker 3>by testing it behaviorally.</v>
<v Speaker 3>You can verify behaviorally and in a,</v>

534
00:30:34.350 --> 00:30:36.390
<v Speaker 3>in a game like go,</v>
<v Speaker 3>it's very easy.</v>

535
00:30:36.391 --> 00:30:41.220
<v Speaker 3>You can give somebody a go position and </v>
<v Speaker 3>ask them to come up with a move and then</v>

536
00:30:41.221 --> 00:30:46.221
<v Speaker 3>evaluate the quality of that move.</v>
<v Speaker 3>So I think that's what it encompasses </v>

537
00:30:46.551 --> 00:30:49.070
<v Speaker 3>more intuition is.</v>
<v Speaker 3>So what about creativity?</v>

538
00:30:49.690 --> 00:30:51.470
<v Speaker 3>Well,</v>
<v Speaker 3>I think one way you could operationalize</v>

539
00:30:51.471 --> 00:30:56.471
<v Speaker 3>the definition of creativity is the </v>
<v Speaker 3>ability to synthesize knowledge to in </v>

540
00:30:56.471 --> 00:30:57.530
<v Speaker 3>the service of producing a novel or </v>
<v Speaker 3>original idea.</v>

541
00:30:58.430 --> 00:31:03.430
<v Speaker 3>And I think under those definitions,</v>
<v Speaker 3>Africa in some sense clearly </v>

542
00:31:03.430 --> 00:31:05.660
<v Speaker 3>demonstrated these abilities during this</v>
<v Speaker 3>match or beer.</v>

543
00:31:05.661 --> 00:31:10.661
<v Speaker 3>Obviously caveated by the fact that it's</v>
<v Speaker 3>still a very constrained domain of a </v>

544
00:31:10.661 --> 00:31:14.090
<v Speaker 3>board game.</v>
<v Speaker 3>But let's think about creativity sort of</v>

545
00:31:14.091 --> 00:31:19.091
<v Speaker 3>more generally.</v>
<v Speaker 3>Here's another definition of creativity </v>

546
00:31:19.091 --> 00:31:22.451
<v Speaker 3>is I think I got out of the Oxford </v>
<v Speaker 3>dictionary the ability to use skill and </v>

547
00:31:22.451 --> 00:31:25.601
<v Speaker 3>imagination to produce something new.</v>
<v Speaker 3>And I think there were at least three </v>

548
00:31:25.601 --> 00:31:28.820
<v Speaker 3>types of creativity or three levels of </v>
<v Speaker 3>creativity if you like.</v>

549
00:31:30.500 --> 00:31:35.500
<v Speaker 3>So the first type,</v>
<v Speaker 3>if you imagine that you're given three </v>

550
00:31:35.780 --> 00:31:40.780
<v Speaker 3>or more examples in a particular topic </v>
<v Speaker 3>and let's imagine for the moment that </v>

551
00:31:40.780 --> 00:31:45.491
<v Speaker 3>the green dots are these examples and </v>
<v Speaker 3>the white box is a particular topic or </v>

552
00:31:45.491 --> 00:31:49.480
<v Speaker 3>field of endeavor and you also create </v>
<v Speaker 3>something new.</v>

553
00:31:50.570 --> 00:31:55.570
<v Speaker 3>So one way you could do that is what I </v>
<v Speaker 3>call interpolation and it's used often </v>

554
00:31:55.570 --> 00:31:59.600
<v Speaker 3>in machine learning and ai as an ai term</v>
<v Speaker 3>and it's Appalachian you can think of is</v>

555
00:31:59.840 --> 00:32:03.830
<v Speaker 3>kind of like an averaging.</v>
<v Speaker 3>So here are three trainings on Paul's,</v>

556
00:32:03.831 --> 00:32:08.831
<v Speaker 3>here are three examples of things we </v>
<v Speaker 3>would like from this world of </v>

557
00:32:08.831 --> 00:32:11.501
<v Speaker 3>possibilities and you kind of find an </v>
<v Speaker 3>average of those things and in some </v>

558
00:32:11.501 --> 00:32:13.850
<v Speaker 3>sense that orange door is new,</v>
<v Speaker 3>right?</v>

559
00:32:13.851 --> 00:32:15.200
<v Speaker 3>It's not,</v>
<v Speaker 3>it's different from the,</v>

560
00:32:15.320 --> 00:32:16.760
<v Speaker 3>from the,</v>
<v Speaker 3>from the examples.</v>

561
00:32:16.970 --> 00:32:21.970
<v Speaker 3>And it's something new,</v>
<v Speaker 3>but it's still sort of contained within </v>

562
00:32:21.970 --> 00:32:22.510
<v Speaker 3>the space.</v>
<v Speaker 3>This green dot,</v>

563
00:32:22.511 --> 00:32:25.100
<v Speaker 3>a green line,</v>
<v Speaker 3>the space that the examples cover,</v>

564
00:32:27.160 --> 00:32:28.570
<v Speaker 3>the next level of creativity,</v>
<v Speaker 3>which is,</v>

565
00:32:28.571 --> 00:32:33.571
<v Speaker 3>you know,</v>
<v Speaker 3>a higher level of creativity would be </v>

566
00:32:33.571 --> 00:32:33.571
<v Speaker 3>extrapolation.</v>
<v Speaker 3>So now you know,</v>

567
00:32:33.571 --> 00:32:36.670
<v Speaker 3>you have those examples,</v>
<v Speaker 3>but instead of just finding an average,</v>

568
00:32:36.820 --> 00:32:39.440
<v Speaker 3>you're extending the boundaries of what </v>
<v Speaker 3>you already know.</v>

569
00:32:39.920 --> 00:32:44.720
<v Speaker 3>So this will be the blue dots and you </v>
<v Speaker 3>can see those three blue dots as outside</v>

570
00:32:44.840 --> 00:32:49.840
<v Speaker 3>of the boundaries that,</v>
<v Speaker 3>that sort of marked out by the training </v>

571
00:32:49.840 --> 00:32:49.940
<v Speaker 3>examples,</v>
<v Speaker 3>the green dots.</v>

572
00:32:51.640 --> 00:32:55.840
<v Speaker 3>And then finally there's what I would </v>
<v Speaker 3>call invention or innovation,</v>

573
00:32:56.260 --> 00:32:57.070
<v Speaker 3>which,</v>
<v Speaker 3>uh,</v>

574
00:32:57.130 --> 00:33:02.130
<v Speaker 3>which is here represented by the yellow </v>
<v Speaker 3>door that's outside the white box </v>

575
00:33:02.141 --> 00:33:04.860
<v Speaker 3>completely.</v>
<v Speaker 3>And this is something completely new,</v>

576
00:33:04.990 --> 00:33:08.710
<v Speaker 3>perhaps informed in some way by what's </v>
<v Speaker 3>inside the box.</v>

577
00:33:10.750 --> 00:33:12.120
<v Speaker 3>Now,</v>
<v Speaker 3>you know,</v>

578
00:33:12.220 --> 00:33:12.860
<v Speaker 3>how,</v>
<v Speaker 3>uh,</v>

579
00:33:12.910 --> 00:33:16.270
<v Speaker 3>how we doing on the Ai Front where these</v>
<v Speaker 3>levels of creativity.</v>

580
00:33:16.271 --> 00:33:19.870
<v Speaker 3>So let's,</v>
<v Speaker 3>let's examine machine creativity and you</v>

581
00:33:19.871 --> 00:33:21.070
<v Speaker 3>know,</v>
<v Speaker 3>neural network systems,</v>

582
00:33:21.071 --> 00:33:26.071
<v Speaker 3>the kind of systems I showed you.</v>
<v Speaker 3>Sometimes the fashionable ones are </v>

583
00:33:26.071 --> 00:33:27.550
<v Speaker 3>called deep learning these days.</v>
<v Speaker 3>They're pretty good interpolation,</v>

584
00:33:27.780 --> 00:33:32.780
<v Speaker 3>you know,</v>
<v Speaker 3>they're massive statistical machines if </v>

585
00:33:32.780 --> 00:33:32.780
<v Speaker 3>you like.</v>
<v Speaker 3>And they're very good at,</v>

586
00:33:32.800 --> 00:33:37.800
<v Speaker 3>uh,</v>
<v Speaker 3>averaging things and spotting patterns </v>

587
00:33:37.800 --> 00:33:38.740
<v Speaker 3>in data.</v>
<v Speaker 3>Then you have things,</v>

588
00:33:38.741 --> 00:33:42.520
<v Speaker 3>Alphago like systems which are getting </v>
<v Speaker 3>pretty good,</v>

589
00:33:42.521 --> 00:33:44.620
<v Speaker 3>I would say extrapolation,</v>
<v Speaker 3>you know,</v>

590
00:33:44.650 --> 00:33:49.650
<v Speaker 3>finding new things beyond the boundaries</v>
<v Speaker 3>of even what the human designers knew </v>

591
00:33:50.231 --> 00:33:55.231
<v Speaker 3>about,</v>
<v Speaker 3>but still within the same general </v>

592
00:33:55.231 --> 00:33:57.960
<v Speaker 3>context.</v>
<v Speaker 3>And then you've got true invention,</v>

593
00:33:58.200 --> 00:34:02.100
<v Speaker 3>which I think no ai systems are anywhere</v>
<v Speaker 3>close to yet,</v>

594
00:34:02.700 --> 00:34:03.840
<v Speaker 3>right?</v>
<v Speaker 3>So this would be,</v>

595
00:34:03.900 --> 00:34:06.300
<v Speaker 3>instead of coming up with an original </v>
<v Speaker 3>moving go,</v>

596
00:34:06.390 --> 00:34:11.390
<v Speaker 3>it will be inventing go right on venting</v>
<v Speaker 3>chess and there's no systems that are </v>

597
00:34:11.641 --> 00:34:14.280
<v Speaker 3>able to do that.</v>
<v Speaker 3>But we can come up with,</v>

598
00:34:14.300 --> 00:34:15.600
<v Speaker 3>you know,</v>
<v Speaker 3>I think Alphago,</v>

599
00:34:15.770 --> 00:34:17.760
<v Speaker 3>uh,</v>
<v Speaker 3>definitely demonstrated extrapolation.</v>

600
00:34:17.850 --> 00:34:22.850
<v Speaker 3>It wasn't just averaging what humans </v>
<v Speaker 3>have done before or mimicking what </v>

601
00:34:22.850 --> 00:34:24.150
<v Speaker 3>humans have done before it was coming </v>
<v Speaker 3>out with genuinely new ideas,</v>

602
00:34:24.510 --> 00:34:28.110
<v Speaker 3>but it can't invent something truly new.</v>

603
00:34:30.420 --> 00:34:31.350
<v Speaker 3>So you might ask,</v>
<v Speaker 3>well,</v>

604
00:34:31.351 --> 00:34:32.700
<v Speaker 3>what's missing?</v>
<v Speaker 3>Well,</v>

605
00:34:32.701 --> 00:34:35.520
<v Speaker 3>although AI systems have been pretty </v>
<v Speaker 3>successful so far,</v>

606
00:34:35.580 --> 00:34:38.280
<v Speaker 3>there's actually a whole bunch of things</v>
<v Speaker 3>that we still need.</v>

607
00:34:38.980 --> 00:34:43.890
<v Speaker 3>I still need to crack.</v>
<v Speaker 3>And things like concepts,</v>

608
00:34:44.160 --> 00:34:45.780
<v Speaker 3>abstract,</v>
<v Speaker 3>abstract thinking,</v>

609
00:34:45.810 --> 00:34:49.410
<v Speaker 3>reasoning by analogy,</v>
<v Speaker 3>memory systems and imagination,</v>

610
00:34:49.411 --> 00:34:51.340
<v Speaker 3>which as we just saw earlier,</v>
<v Speaker 3>is in,</v>

611
00:34:51.850 --> 00:34:53.850
<v Speaker 3>in many of the definitions of </v>
<v Speaker 3>creativity.</v>

612
00:34:54.210 --> 00:34:59.210
<v Speaker 3>And a lot of these terms of these ideas </v>
<v Speaker 3>and capabilities are missing from our </v>

613
00:34:59.210 --> 00:35:04.191
<v Speaker 3>current ai systems and this is where the</v>
<v Speaker 3>cutting edge of ai researchers at the </v>

614
00:35:04.191 --> 00:35:08.451
<v Speaker 3>moment and we're working variously hard </v>
<v Speaker 3>on all these different topics are just </v>

615
00:35:08.451 --> 00:35:13.100
<v Speaker 3>mentioned and I think those things are </v>
<v Speaker 3>key to this invention or this out of the</v>

616
00:35:13.101 --> 00:35:18.101
<v Speaker 3>box thinking because I think a lot of </v>
<v Speaker 3>that comes from interdisciplinary </v>

617
00:35:18.101 --> 00:35:21.701
<v Speaker 3>thinking,</v>
<v Speaker 3>spotting unusual connections between </v>

618
00:35:21.701 --> 00:35:24.320
<v Speaker 3>different subjects and doing things like</v>
<v Speaker 3>imagining counterfactuals right?</v>

619
00:35:24.321 --> 00:35:29.321
<v Speaker 3>So imagine fantastical scenarios and a </v>
<v Speaker 3>lot of our creativity I believe comes </v>

620
00:35:30.980 --> 00:35:35.300
<v Speaker 3>from those capabilities that we </v>
<v Speaker 3>currently don't have in our AI systems.</v>

621
00:35:36.770 --> 00:35:41.770
<v Speaker 3>So where can we look for inspiration?</v>
<v Speaker 3>And I've only got time to cover one of </v>

622
00:35:41.770 --> 00:35:45.501
<v Speaker 3>those topics.</v>
<v Speaker 3>Each one of those could be a whole </v>

623
00:35:45.501 --> 00:35:45.720
<v Speaker 3>lecture in itself,</v>
<v Speaker 3>but I'm just going to talk about a topic</v>

624
00:35:45.721 --> 00:35:48.000
<v Speaker 3>that I've studied for a long time </v>
<v Speaker 3>imagination,</v>

625
00:35:48.240 --> 00:35:51.240
<v Speaker 3>which I think is one of the main keys to</v>
<v Speaker 3>creativity.</v>

626
00:35:51.840 --> 00:35:56.840
<v Speaker 3>And we can actually take our inspiration</v>
<v Speaker 3>from the brain and especially from what </v>

627
00:35:56.840 --> 00:35:58.320
<v Speaker 3>I call a systems neuroscience point of </v>
<v Speaker 3>view,</v>

628
00:35:58.500 --> 00:36:01.170
<v Speaker 3>which is a high level understanding of </v>
<v Speaker 3>the brain.</v>

629
00:36:01.350 --> 00:36:06.350
<v Speaker 3>And interested in the algorithms and the</v>
<v Speaker 3>architecture of the brain uses and I </v>

630
00:36:06.350 --> 00:36:10.941
<v Speaker 3>actually studied memory and imagination </v>
<v Speaker 3>for my phd and I was very interesting.</v>

631
00:36:10.981 --> 00:36:15.981
<v Speaker 3>The question of how do we imagine what </v>
<v Speaker 3>are the brain mechanisms behind </v>

632
00:36:15.981 --> 00:36:19.230
<v Speaker 3>imagination?</v>
<v Speaker 3>And when I started my phd,</v>

633
00:36:19.320 --> 00:36:24.320
<v Speaker 3>one of the things I've started looking </v>
<v Speaker 3>at was how memory works and I became </v>

634
00:36:24.320 --> 00:36:28.371
<v Speaker 3>convinced that memory was a </v>
<v Speaker 3>reconstructive process so you shouldn't </v>

635
00:36:28.371 --> 00:36:29.130
<v Speaker 3>think of memory as a videotape.</v>

636
00:36:29.190 --> 00:36:34.190
<v Speaker 3>It's not a perfect recording.</v>
<v Speaker 3>And if we remember tomorrow we think </v>

637
00:36:34.190 --> 00:36:34.320
<v Speaker 3>back to this lecture or what you had at </v>
<v Speaker 3>lunch today,</v>

638
00:36:34.560 --> 00:36:37.050
<v Speaker 3>it wouldn't be.</v>
<v Speaker 3>It's not really a perfect video tape.</v>

639
00:36:37.230 --> 00:36:39.840
<v Speaker 3>You're actually going to reconstruct it </v>
<v Speaker 3>from its components.</v>

640
00:36:39.900 --> 00:36:43.050
<v Speaker 3>So we reassemble our memories from our </v>
<v Speaker 3>component,</v>

641
00:36:43.051 --> 00:36:45.390
<v Speaker 3>from components and we put them back </v>
<v Speaker 3>together.</v>

642
00:36:46.590 --> 00:36:48.870
<v Speaker 3>So I was thinking if memory,</v>
<v Speaker 3>and there's a lot of evidence that's how</v>

643
00:36:48.900 --> 00:36:51.780
<v Speaker 3>memory works.</v>
<v Speaker 3>So I think if that home is as how memory</v>

644
00:36:51.781 --> 00:36:54.480
<v Speaker 3>works and you can think of memories is </v>
<v Speaker 3>reconstructed process,</v>

645
00:36:54.750 --> 00:36:57.930
<v Speaker 3>then maybe imagination which is a </v>
<v Speaker 3>constructive process.</v>

646
00:36:58.080 --> 00:37:00.630
<v Speaker 3>You're putting these components together</v>
<v Speaker 3>in a novel way.</v>

647
00:37:00.930 --> 00:37:04.770
<v Speaker 3>Maybe it relies on the same brain </v>
<v Speaker 3>mechanisms and the same brain areas,</v>

648
00:37:05.640 --> 00:37:08.430
<v Speaker 3>so we know and we've known for $50 more </v>
<v Speaker 3>than 50 years.</v>

649
00:37:08.431 --> 00:37:11.910
<v Speaker 3>That memory is reliant on an area of the</v>
<v Speaker 3>brain called the hippocampus,</v>

650
00:37:12.120 --> 00:37:15.150
<v Speaker 3>which is shown here in pink and is at </v>
<v Speaker 3>the center of your brain.</v>

651
00:37:15.540 --> 00:37:17.650
<v Speaker 3>And without your hippocampus,</v>
<v Speaker 3>your,</v>

652
00:37:17.660 --> 00:37:22.660
<v Speaker 3>you will become our music.</v>
<v Speaker 3>And that's what happens in terrible </v>

653
00:37:22.660 --> 00:37:25.611
<v Speaker 3>diseases like Alzheimer's.</v>
<v Speaker 3>And so what we thought is why don't we </v>

654
00:37:25.611 --> 00:37:27.930
<v Speaker 3>test some patients who have damage to </v>
<v Speaker 3>the hippocampus,</v>

655
00:37:27.960 --> 00:37:32.960
<v Speaker 3>but the rest of their brains intact on </v>
<v Speaker 3>imagination tasks and see if they can </v>

656
00:37:32.960 --> 00:37:37.731
<v Speaker 3>imagine.</v>
<v Speaker 3>And so what we did is quite a simple </v>

657
00:37:37.731 --> 00:37:38.370
<v Speaker 3>test,</v>
<v Speaker 3>but no one had thought to do this for,</v>

658
00:37:38.430 --> 00:37:43.430
<v Speaker 3>you know,</v>
<v Speaker 3>even though we've been researching </v>

659
00:37:43.430 --> 00:37:45.171
<v Speaker 3>memory for almost a hundred years now.</v>
<v Speaker 3>And we thought to test these patients on</v>

660
00:37:46.430 --> 00:37:51.430
<v Speaker 3>a simple imagination tasks where we got </v>
<v Speaker 3>them to imagine scenarios like imagine </v>

661
00:37:51.430 --> 00:37:55.521
<v Speaker 3>you're lying on a tropical,</v>
<v Speaker 3>a white sandy beach in a beautiful </v>

662
00:37:55.521 --> 00:37:55.521
<v Speaker 3>tropical bay.</v>
<v Speaker 3>Um,</v>

663
00:37:55.521 --> 00:37:57.240
<v Speaker 3>if describe everything you can see </v>
<v Speaker 3>around you.</v>

664
00:37:57.990 --> 00:37:59.910
<v Speaker 3>So this is no problem for healthy </v>
<v Speaker 3>people.</v>

665
00:38:00.240 --> 00:38:02.750
<v Speaker 3>And um,</v>
<v Speaker 3>and we got the patients to,</v>

666
00:38:02.770 --> 00:38:07.770
<v Speaker 3>to describe this and we got age match </v>
<v Speaker 3>than Iq match control subjects to also </v>

667
00:38:07.801 --> 00:38:08.910
<v Speaker 3>describe scenarios.</v>

668
00:38:09.090 --> 00:38:14.090
<v Speaker 3>And what we found is that the patient </v>
<v Speaker 3>descriptions were hugely impoverished </v>

669
00:38:14.090 --> 00:38:14.570
<v Speaker 3>compared to their,</v>
<v Speaker 3>um,</v>

670
00:38:14.610 --> 00:38:19.610
<v Speaker 3>their control cohort.</v>
<v Speaker 3>And you can see here on the right hand </v>

671
00:38:19.610 --> 00:38:23.631
<v Speaker 3>side,</v>
<v Speaker 3>this is a graph of the richness </v>

672
00:38:23.631 --> 00:38:23.631
<v Speaker 3>measuring the richness of their </v>
<v Speaker 3>descriptions.</v>

673
00:38:23.631 --> 00:38:28.160
<v Speaker 3>On the left hand bar is the patient's on</v>
<v Speaker 3>the right hand bar is the control </v>

674
00:38:28.411 --> 00:38:31.380
<v Speaker 3>subjects who their imaginations are a </v>
<v Speaker 3>lot richer.</v>

675
00:38:32.220 --> 00:38:37.220
<v Speaker 3>And what we found after further </v>
<v Speaker 3>investigations is that the problem they </v>

676
00:38:37.220 --> 00:38:40.531
<v Speaker 3>had was they couldn't bind together </v>
<v Speaker 3>disparate elements of a scene into a </v>

677
00:38:40.531 --> 00:38:45.451
<v Speaker 3>whole coherent hole.</v>
<v Speaker 3>So we call this spacial coherence </v>

678
00:38:45.451 --> 00:38:49.171
<v Speaker 3>problem and that's what we think the </v>
<v Speaker 3>hippocampus is actually doing for </v>

679
00:38:49.171 --> 00:38:53.131
<v Speaker 3>imagination.</v>
<v Speaker 3>It's briny together all of these </v>

680
00:38:53.131 --> 00:38:54.620
<v Speaker 3>elements into a hole.</v>
<v Speaker 3>And of course,</v>

681
00:38:54.740 --> 00:38:57.680
<v Speaker 3>you know the imagination.</v>
<v Speaker 3>What does it do for us?</v>

682
00:38:57.800 --> 00:39:02.800
<v Speaker 3>Well,</v>
<v Speaker 3>it's extremely valuable skill that </v>

683
00:39:02.800 --> 00:39:05.381
<v Speaker 3>humans have and allows us to more </v>
<v Speaker 3>accurately predict the future by </v>

684
00:39:05.381 --> 00:39:10.040
<v Speaker 3>hypothesis hypothesizing about different</v>
<v Speaker 3>plans you could do and seeing how they </v>

685
00:39:10.040 --> 00:39:11.240
<v Speaker 3>would turn out.</v>
<v Speaker 3>And also,</v>

686
00:39:11.241 --> 00:39:16.241
<v Speaker 3>I think it's the beginning of creativity</v>
<v Speaker 3>in the sense of allowing us to think of </v>

687
00:39:16.241 --> 00:39:20.290
<v Speaker 3>counterfactual situations related,</v>
<v Speaker 3>did some brain scanning work on healthy </v>

688
00:39:20.290 --> 00:39:24.650
<v Speaker 3>subjects imagining in brain scanners and</v>
<v Speaker 3>we found five different brain areas that</v>

689
00:39:24.651 --> 00:39:27.890
<v Speaker 3>were heavily involved in different </v>
<v Speaker 3>aspects of imagining.</v>

690
00:39:29.960 --> 00:39:34.700
<v Speaker 3>So most recently then we've tried to </v>
<v Speaker 3>recreate this aspect of imagination,</v>

691
00:39:34.760 --> 00:39:39.760
<v Speaker 3>so imagining scenes in our AI systems </v>
<v Speaker 3>and we've recently had some big </v>

692
00:39:40.971 --> 00:39:45.680
<v Speaker 3>breakthroughs on that front and we </v>
<v Speaker 3>created a system called generative query</v>

693
00:39:45.681 --> 00:39:49.250
<v Speaker 3>network,</v>
<v Speaker 3>the Gq n and what the system was able to</v>

694
00:39:49.251 --> 00:39:54.251
<v Speaker 3>do is amazingly kind of reconstruct a </v>
<v Speaker 3>three d model of a scene just from a </v>

695
00:39:54.891 --> 00:39:59.891
<v Speaker 3>handful of Tuesday snapshots.</v>
<v Speaker 3>So imagine giving a the AI system a few </v>

696
00:40:00.530 --> 00:40:05.530
<v Speaker 3>two d pictures of a seen a three d scene</v>
<v Speaker 3>and it recreates the whole three d scene</v>

697
00:40:05.811 --> 00:40:08.780
<v Speaker 3>just from those two stills to those few </v>
<v Speaker 3>today stills.</v>

698
00:40:10.370 --> 00:40:12.440
<v Speaker 3>So then at that point to test the </v>
<v Speaker 3>system,</v>

699
00:40:12.650 --> 00:40:16.340
<v Speaker 3>we ask the system to render the scene </v>
<v Speaker 3>from a new angle.</v>

700
00:40:16.490 --> 00:40:18.140
<v Speaker 3>It's never,</v>
<v Speaker 3>it hasn't seen before.</v>

701
00:40:18.500 --> 00:40:23.500
<v Speaker 3>So we can,</v>
<v Speaker 3>we can ask it to render from any </v>

702
00:40:23.500 --> 00:40:25.511
<v Speaker 3>arbitrary new angle.</v>
<v Speaker 3>So in computer graphics and in Ai </v>

703
00:40:27.350 --> 00:40:32.350
<v Speaker 3>Circles,</v>
<v Speaker 3>this is called the inverse graphics </v>

704
00:40:32.350 --> 00:40:32.350
<v Speaker 3>problem.</v>
<v Speaker 3>So if you imagine computer graphics,</v>

705
00:40:32.350 --> 00:40:36.790
<v Speaker 3>you know,</v>
<v Speaker 3>you have these algorithms and they </v>

706
00:40:36.790 --> 00:40:38.291
<v Speaker 3>produce all these beautiful pictures </v>
<v Speaker 3>that you see in games and in three d </v>

707
00:40:38.291 --> 00:40:42.161
<v Speaker 3>artwork and CGI and there's a </v>
<v Speaker 3>mathematical sort of equations that </v>

708
00:40:42.770 --> 00:40:46.000
<v Speaker 3>basically cre create those three d </v>
<v Speaker 3>scenes on.</v>

709
00:40:46.001 --> 00:40:48.170
<v Speaker 3>What this system is doing is doing the </v>
<v Speaker 3>inverse of that,</v>

710
00:40:48.171 --> 00:40:50.510
<v Speaker 3>the reverse of that.</v>
<v Speaker 3>Here's a three d scene,</v>

711
00:40:50.600 --> 00:40:55.600
<v Speaker 3>here's some pictures of it,</v>
<v Speaker 3>now recover the genitive equations that </v>

712
00:40:55.600 --> 00:41:00.251
<v Speaker 3>actually generate that seat.</v>
<v Speaker 3>So it's called the inverse graphics </v>

713
00:41:00.251 --> 00:41:04.181
<v Speaker 3>problem.</v>
<v Speaker 3>Has been a longstanding problem in </v>

714
00:41:04.181 --> 00:41:04.181
<v Speaker 3>computer graphics.</v>

715
00:41:04.181 --> 00:41:05.110
<v Speaker 3>So the scenes that we were able to do,</v>
<v Speaker 3>um,</v>

716
00:41:05.270 --> 00:41:10.270
<v Speaker 3>I should,</v>
<v Speaker 3>I should say are very simple scenes </v>

717
00:41:10.270 --> 00:41:10.270
<v Speaker 3>currently,</v>
<v Speaker 3>but it's kind of amazing that this works</v>

718
00:41:10.270 --> 00:41:10.940
<v Speaker 3>at all.</v>
<v Speaker 3>So what I'm doing,</v>

719
00:41:10.941 --> 00:41:12.490
<v Speaker 3>I'm just going to show you a quick video</v>
<v Speaker 3>of,</v>

720
00:41:12.510 --> 00:41:17.510
<v Speaker 3>of this working while you're going to </v>
<v Speaker 3>see is these kinds of quite toy like </v>

721
00:41:17.510 --> 00:41:19.090
<v Speaker 3>three d scenes with three,</v>
<v Speaker 3>four,</v>

722
00:41:19.100 --> 00:41:22.190
<v Speaker 3>five objects in it,</v>
<v Speaker 3>geometric objects in it,</v>

723
00:41:22.310 --> 00:41:22.860
<v Speaker 3>like,</v>
<v Speaker 3>you know,</v>

724
00:41:22.880 --> 00:41:26.120
<v Speaker 3>spheres and hemispheres and circles and </v>
<v Speaker 3>so on.</v>

725
00:41:26.121 --> 00:41:31.121
<v Speaker 3>And and,</v>
<v Speaker 3>and boxes of different colors and </v>

726
00:41:31.121 --> 00:41:33.761
<v Speaker 3>different textures.</v>
<v Speaker 3>And what we do is we give the system a </v>

727
00:41:33.761 --> 00:41:38.201
<v Speaker 3>couple of stills snapshots of the scene </v>
<v Speaker 3>and then we tell it to render that from </v>

728
00:41:38.201 --> 00:41:43.061
<v Speaker 3>any new angle.</v>
<v Speaker 3>So I'm going to show you that in this </v>

729
00:41:43.061 --> 00:41:44.570
<v Speaker 3>video here.</v>
<v Speaker 3>So you'll see the scene on the left hand</v>

730
00:41:44.571 --> 00:41:49.571
<v Speaker 3>side here.</v>
<v Speaker 3>So this little box world with these </v>

731
00:41:49.571 --> 00:41:51.140
<v Speaker 3>three objects in there and the system </v>
<v Speaker 3>only gets two snapshots,</v>

732
00:41:51.141 --> 00:41:56.141
<v Speaker 3>view one and view two and then we ask it</v>
<v Speaker 3>to render the view from this new view,</v>

733
00:41:57.801 --> 00:42:02.801
<v Speaker 3>view three coming from another angle and</v>
<v Speaker 3>we would like to see what the image </v>

734
00:42:02.801 --> 00:42:04.040
<v Speaker 3>looks like from that new angle.</v>

735
00:42:06.490 --> 00:42:11.490
<v Speaker 3>So we'll see here.</v>
<v Speaker 3>So it gets given view one that gets </v>

736
00:42:11.490 --> 00:42:14.491
<v Speaker 3>input into the neural network and it </v>
<v Speaker 3>gets processed and it gets represented </v>

737
00:42:14.491 --> 00:42:15.580
<v Speaker 3>inside your network.</v>

738
00:42:16.690 --> 00:42:18.820
<v Speaker 3>Then we give it a new camera angle view </v>
<v Speaker 3>too.</v>

739
00:42:19.660 --> 00:42:21.190
<v Speaker 3>So that's what it looks like from view </v>
<v Speaker 3>to.</v>

740
00:42:21.220 --> 00:42:24.250
<v Speaker 3>We give that to the input and it adds </v>
<v Speaker 3>that to it seemed representation.</v>

741
00:42:24.940 --> 00:42:29.940
<v Speaker 3>And then we ask it.</v>
<v Speaker 3>We queried is why it's called a janitor </v>

742
00:42:29.940 --> 00:42:32.230
<v Speaker 3>query network.</v>
<v Speaker 3>What would it look like from this third </v>

743
00:42:32.230 --> 00:42:32.830
<v Speaker 3>year and now a second year or network </v>
<v Speaker 3>outputs,</v>

744
00:42:32.890 --> 00:42:35.680
<v Speaker 3>the new prediction of what that should </v>
<v Speaker 3>look like,</v>

745
00:42:35.860 --> 00:42:37.480
<v Speaker 3>and then we compare it to the ground </v>
<v Speaker 3>truth,</v>

746
00:42:37.481 --> 00:42:42.481
<v Speaker 3>what it really looks like and you can </v>
<v Speaker 3>see that they almost matched perfectly </v>

747
00:42:42.481 --> 00:42:44.440
<v Speaker 3>and then we're able to spin round.</v>
<v Speaker 3>Um,</v>

748
00:42:44.550 --> 00:42:46.900
<v Speaker 3>we're able to take care from any new </v>
<v Speaker 3>angle,</v>

749
00:42:47.120 --> 00:42:52.120
<v Speaker 3>um,</v>
<v Speaker 3>and then we can give it a new pictures </v>

750
00:42:52.120 --> 00:42:52.390
<v Speaker 3>of new rooms with different objects and </v>
<v Speaker 3>you can see it can move around,</v>

751
00:42:52.600 --> 00:42:53.620
<v Speaker 3>zoom in,</v>
<v Speaker 3>zoom out.</v>

752
00:42:53.860 --> 00:42:58.860
<v Speaker 3>So it's just less if it was a computer </v>
<v Speaker 3>game and we'd completely built a new </v>

753
00:42:58.860 --> 00:43:03.361
<v Speaker 3>graphics engine to do that.</v>
<v Speaker 3>So it's just recovering that from these </v>

754
00:43:03.361 --> 00:43:07.471
<v Speaker 3>two d stills.</v>
<v Speaker 3>Now obviously we're now building up to </v>

755
00:43:07.471 --> 00:43:11.370
<v Speaker 3>scenes of higher complexity and </v>
<v Speaker 3>eventually we would like to get to real </v>

756
00:43:11.370 --> 00:43:15.511
<v Speaker 3>world scenes where you can recreate a </v>
<v Speaker 3>real world seen just from some two d </v>

757
00:43:15.511 --> 00:43:15.511
<v Speaker 3>pictures.</v>

758
00:43:18.310 --> 00:43:21.400
<v Speaker 3>So hopefully I've given you a good </v>
<v Speaker 3>flavor of what's happening in Ai.</v>

759
00:43:21.401 --> 00:43:23.440
<v Speaker 3>The kind of cutting edge of ai at the </v>
<v Speaker 3>moment.</v>

760
00:43:23.860 --> 00:43:28.860
<v Speaker 3>And even though I said earlier,</v>
<v Speaker 3>there are many unsolved problems too </v>

761
00:43:28.860 --> 00:43:32.760
<v Speaker 3>that we have to still tackle even the </v>
<v Speaker 3>kinds of technologies we have today </v>

762
00:43:32.760 --> 00:43:37.590
<v Speaker 3>already proving very useful.</v>
<v Speaker 3>So I'm just going to briefly mention a </v>

763
00:43:37.590 --> 00:43:41.161
<v Speaker 3>few applications.</v>
<v Speaker 3>So obviously there are a whole host of </v>

764
00:43:41.161 --> 00:43:42.430
<v Speaker 3>commercial applications that we and </v>
<v Speaker 3>others are looking at.</v>

765
00:43:42.730 --> 00:43:45.730
<v Speaker 3>So helping with healthcare,</v>
<v Speaker 3>medical diagnostics,</v>

766
00:43:45.910 --> 00:43:49.900
<v Speaker 3>we have a bunch of collaborations with </v>
<v Speaker 3>hospitals around the world are all sorts</v>

767
00:43:49.901 --> 00:43:54.901
<v Speaker 3>of different areas,</v>
<v Speaker 3>especially with image recognition with </v>

768
00:43:54.901 --> 00:43:58.680
<v Speaker 3>as work with optimization and energy.</v>
<v Speaker 3>We actually did some work for the Google</v>

769
00:43:58.751 --> 00:44:02.980
<v Speaker 3>data centers and we managed to say 40 </v>
<v Speaker 3>percent of the power the cooling systems</v>

770
00:44:02.981 --> 00:44:07.600
<v Speaker 3>used by more efficiently controlling all</v>
<v Speaker 3>the all the cooling equipment.</v>

771
00:44:08.560 --> 00:44:13.560
<v Speaker 3>I think there's lots of potential in </v>
<v Speaker 3>education for personalized education </v>

772
00:44:13.560 --> 00:44:17.040
<v Speaker 3>using these ai systems and also with </v>
<v Speaker 3>virtual assistants on your phone and </v>

773
00:44:17.040 --> 00:44:20.671
<v Speaker 3>making them a lot smarter.</v>
<v Speaker 3>So is it being used a lot in art and </v>

774
00:44:20.671 --> 00:44:21.800
<v Speaker 3>design?</v>
<v Speaker 3>Many will.</v>

775
00:44:21.801 --> 00:44:24.650
<v Speaker 3>You know about this.</v>
<v Speaker 3>So especially in architecture,</v>

776
00:44:25.220 --> 00:44:30.220
<v Speaker 3>I believe that building the Opera House </v>
<v Speaker 3>on the left hand side here was designed </v>

777
00:44:30.220 --> 00:44:34.210
<v Speaker 3>using machine learning as was the engine</v>
<v Speaker 3>block on the bottom right here for car </v>

778
00:44:34.351 --> 00:44:39.351
<v Speaker 3>engine.</v>
<v Speaker 3>And also there's be some interesting </v>

779
00:44:39.351 --> 00:44:39.351
<v Speaker 3>things in art,</v>
<v Speaker 3>art transfer,</v>

780
00:44:39.351 --> 00:44:44.221
<v Speaker 3>transferring styles between different </v>
<v Speaker 3>art styles on the same picture as well </v>

781
00:44:45.181 --> 00:44:46.970
<v Speaker 3>as creating art itself on the top</v>

782
00:44:47.010 --> 00:44:47.370
<v Speaker 5>right.</v>

783
00:44:49.040 --> 00:44:54.040
<v Speaker 3>And then for me,</v>
<v Speaker 3>my particular passion is using it for </v>

784
00:44:54.040 --> 00:44:57.401
<v Speaker 3>science to accelerate scientific </v>
<v Speaker 3>endeavor and it's been used already </v>

785
00:44:57.401 --> 00:45:01.391
<v Speaker 3>successfully.</v>
<v Speaker 3>These kinds of AI systems I've talked </v>

786
00:45:01.391 --> 00:45:03.401
<v Speaker 3>about for discovering new exoplanets,</v>
<v Speaker 3>it's being used to try and control the </v>

787
00:45:03.401 --> 00:45:06.980
<v Speaker 3>plasma and nuclear fusion reactors,</v>
<v Speaker 3>design new chemical compounds,</v>

788
00:45:07.210 --> 00:45:12.210
<v Speaker 3>um,</v>
<v Speaker 3>and detect disease and things like </v>

789
00:45:12.210 --> 00:45:15.041
<v Speaker 3>retina scans,</v>
<v Speaker 3>so whole host of areas in both medicine </v>

790
00:45:15.041 --> 00:45:16.100
<v Speaker 3>and science.</v>
<v Speaker 3>That I think was just the beginning of,</v>

791
00:45:16.280 --> 00:45:19.670
<v Speaker 3>I think we're going to see a huge </v>
<v Speaker 3>revolution over the next decade.</v>

792
00:45:21.380 --> 00:45:26.000
<v Speaker 3>So just want to kind of close now by,</v>
<v Speaker 3>by just sort of going back to my initial</v>

793
00:45:26.001 --> 00:45:29.030
<v Speaker 3>statements about our mission statement </v>
<v Speaker 3>and the way I think about that.</v>

794
00:45:29.510 --> 00:45:34.510
<v Speaker 3>So I think of ai as kind of like a Meta </v>
<v Speaker 3>solution to a lot of the other problems </v>

795
00:45:34.510 --> 00:45:38.801
<v Speaker 3>and challenges we have as a society.</v>
<v Speaker 3>So I think one of the big challenges we </v>

796
00:45:38.801 --> 00:45:41.540
<v Speaker 3>face in all sorts of domains from </v>
<v Speaker 3>science also to,</v>

797
00:45:41.630 --> 00:45:46.630
<v Speaker 3>into even things like entertainment is </v>
<v Speaker 3>information overload and system </v>

798
00:45:47.001 --> 00:45:48.980
<v Speaker 3>complexity.</v>
<v Speaker 3>There's just so much.</v>

799
00:45:48.981 --> 00:45:53.981
<v Speaker 3>We're kind of bombarded both in our </v>
<v Speaker 3>personal lives and our professional </v>

800
00:45:53.981 --> 00:45:55.010
<v Speaker 3>lives with just overwhelming amounts of </v>
<v Speaker 3>information and data.</v>

801
00:45:55.220 --> 00:45:57.980
<v Speaker 3>So how can we make sense of all of these</v>
<v Speaker 3>data streams?</v>

802
00:45:58.520 --> 00:45:59.950
<v Speaker 3>And then the other thing is,</v>
<v Speaker 3>you know,</v>

803
00:45:59.960 --> 00:46:04.960
<v Speaker 3>as a society we want to kind of </v>
<v Speaker 3>understand and master increasingly </v>

804
00:46:04.960 --> 00:46:06.950
<v Speaker 3>complex systems,</v>
<v Speaker 3>some of which are boarding,</v>

805
00:46:06.980 --> 00:46:11.930
<v Speaker 3>bordering on chaotic systems.</v>
<v Speaker 3>Things like a macroeconomics climate.</v>

806
00:46:12.110 --> 00:46:14.240
<v Speaker 3>All of these areas where,</v>
<v Speaker 3>um,</v>

807
00:46:14.330 --> 00:46:16.850
<v Speaker 3>you know,</v>
<v Speaker 3>these systems are incredibly complicated</v>

808
00:46:17.320 --> 00:46:19.100
<v Speaker 3>that we would like to try and </v>
<v Speaker 3>understand.</v>

809
00:46:20.320 --> 00:46:25.320
<v Speaker 3>And I think these are all huge </v>
<v Speaker 3>challenges that we have without </v>

810
00:46:25.320 --> 00:46:29.151
<v Speaker 3>something like ai helping us.</v>
<v Speaker 3>And for a long while sort of the,</v>

811
00:46:29.341 --> 00:46:32.580
<v Speaker 3>I guess the early two thousands,</v>
<v Speaker 3>the first decade of this century,</v>

812
00:46:33.000 --> 00:46:38.000
<v Speaker 3>big data was this huge buzzword.</v>
<v Speaker 3>And I think in a way big data is the </v>

813
00:46:38.000 --> 00:46:42.591
<v Speaker 3>problem.</v>
<v Speaker 3>You can think of an ai as the answer </v>

814
00:46:42.591 --> 00:46:45.240
<v Speaker 3>because everyone has got tons of data </v>
<v Speaker 3>now or companies do and we all have tons</v>

815
00:46:45.241 --> 00:46:47.820
<v Speaker 3>of data,</v>
<v Speaker 3>but what you do with all of that data,</v>

816
00:46:47.821 --> 00:46:52.821
<v Speaker 3>how do you make sense of it?</v>
<v Speaker 3>And I think the only way to do that </v>

817
00:46:52.821 --> 00:46:55.330
<v Speaker 3>actually at scale is to use ai and on </v>
<v Speaker 3>that level,</v>

818
00:46:55.420 --> 00:47:00.420
<v Speaker 3>you know,</v>
<v Speaker 3>in a very general way you can think of </v>

819
00:47:00.420 --> 00:47:02.401
<v Speaker 3>intelligence as a kind of process,</v>
<v Speaker 3>almost a magical process in some ways </v>

820
00:47:02.401 --> 00:47:06.960
<v Speaker 3>that converts unstructured information </v>
<v Speaker 3>or data into useful actionable </v>

821
00:47:06.960 --> 00:47:10.741
<v Speaker 3>knowledge.</v>
<v Speaker 3>That's what intelligence I think is </v>

822
00:47:10.741 --> 00:47:13.320
<v Speaker 3>fundamentally.</v>
<v Speaker 3>And Ai is a kind of way of automating </v>

823
00:47:13.320 --> 00:47:16.411
<v Speaker 3>that process.</v>
<v Speaker 3>And as I've mentioned my personal dream </v>

824
00:47:16.411 --> 00:47:19.860
<v Speaker 3>and why I spent my whole career working </v>
<v Speaker 3>on ai is to use and build it as a </v>

825
00:47:19.860 --> 00:47:23.821
<v Speaker 3>powerful tool to help the scientists and</v>
<v Speaker 3>experts and clinicians accelerate </v>

826
00:47:25.810 --> 00:47:28.180
<v Speaker 3>desperately sort of needed scientific </v>
<v Speaker 3>breakthroughs.</v>

827
00:47:29.460 --> 00:47:29.950
<v Speaker 5>Yeah.</v>

828
00:47:30.220 --> 00:47:35.220
<v Speaker 3>So I think it's an incredibly sort of </v>
<v Speaker 3>exciting time and air holds incredible </v>

829
00:47:35.531 --> 00:47:39.760
<v Speaker 3>promise for the future,</v>
<v Speaker 3>but you know,</v>

830
00:47:39.761 --> 00:47:44.761
<v Speaker 3>it must be used responsibly and safely </v>
<v Speaker 3>just like any other powerful technology </v>

831
00:47:45.280 --> 00:47:48.640
<v Speaker 3>and we have to ensure that it's used for</v>
<v Speaker 3>the benefit of everyone and the benefits</v>

832
00:47:48.641 --> 00:47:49.840
<v Speaker 3>accrue to everyone.</v>

833
00:47:51.290 --> 00:47:53.350
<v Speaker 3>You know,</v>
<v Speaker 3>I think of ai in it,</v>

834
00:47:53.360 --> 00:47:58.360
<v Speaker 3>in of itself.</v>
<v Speaker 3>It's an inherently neutral technology </v>

835
00:47:58.360 --> 00:48:01.490
<v Speaker 3>and just like with every,</v>
<v Speaker 3>any powerful technology depends how we </v>

836
00:48:01.490 --> 00:48:02.370
<v Speaker 3>decide as a society to deploy it and use</v>
<v Speaker 3>it.</v>

837
00:48:03.170 --> 00:48:08.170
<v Speaker 3>And on this topic,</v>
<v Speaker 3>I think a lot more research and </v>

838
00:48:08.170 --> 00:48:08.730
<v Speaker 3>discussions needed with a wide set of </v>
<v Speaker 3>stakeholders.</v>

839
00:48:09.390 --> 00:48:10.310
<v Speaker 3>And as I said,</v>
<v Speaker 3>as wise,</v>

840
00:48:10.311 --> 00:48:15.311
<v Speaker 3>I think it's very important to have </v>
<v Speaker 3>dialogue like this between scientists </v>

841
00:48:15.311 --> 00:48:17.370
<v Speaker 3>and technologists and artists and and </v>
<v Speaker 3>the social sciences.</v>

842
00:48:17.560 --> 00:48:22.560
<v Speaker 3>And I think that's gonna be critical if </v>
<v Speaker 3>we're going to get this right for </v>

843
00:48:22.560 --> 00:48:25.161
<v Speaker 3>everyone.</v>
<v Speaker 3>And we've started ourselves several </v>

844
00:48:25.161 --> 00:48:27.450
<v Speaker 3>efforts both internally at deep mind.</v>
<v Speaker 3>We have an ethics and society group with</v>

845
00:48:27.451 --> 00:48:30.330
<v Speaker 3>policy thinkers and philosophers and </v>
<v Speaker 3>ethicists,</v>

846
00:48:30.570 --> 00:48:32.970
<v Speaker 3>and we've also been instrumental in co </v>
<v Speaker 3>founding,</v>

847
00:48:33.510 --> 00:48:36.900
<v Speaker 3>a pan industry group called the </v>
<v Speaker 3>partnership on Ai,</v>

848
00:48:37.050 --> 00:48:42.050
<v Speaker 3>which includes nonprofits and academics </v>
<v Speaker 3>as well as the big companies trying to </v>

849
00:48:42.050 --> 00:48:44.190
<v Speaker 3>think about these topics for the benefit</v>
<v Speaker 3>of everyone in society.</v>

850
00:48:46.650 --> 00:48:48.970
<v Speaker 3>So I just want to end this talk by </v>
<v Speaker 3>thinking a little bit.</v>

851
00:48:48.971 --> 00:48:52.780
<v Speaker 3>We'll philosophy philosophically and for</v>
<v Speaker 3>me as a neuroscientist,</v>

852
00:48:52.900 --> 00:48:57.900
<v Speaker 3>one or the other really interesting </v>
<v Speaker 3>things about this journey we're on is </v>

853
00:48:57.900 --> 00:49:00.961
<v Speaker 3>that I believe that by trying to distill</v>
<v Speaker 3>intelligence into an algorithmic </v>

854
00:49:00.961 --> 00:49:05.011
<v Speaker 3>constructs like we're doing with ai and </v>
<v Speaker 3>then if we use that and compare that to </v>

855
00:49:05.011 --> 00:49:09.180
<v Speaker 3>the human brain,</v>
<v Speaker 3>I think that might help us better </v>

856
00:49:09.180 --> 00:49:09.180
<v Speaker 3>understand what's unique about our own </v>
<v Speaker 3>minds,</v>

857
00:49:09.180 --> 00:49:14.130
<v Speaker 3>including profound mysteries like the </v>
<v Speaker 3>nature of creativity that we've been </v>

858
00:49:14.130 --> 00:49:16.180
<v Speaker 3>discussing,</v>
<v Speaker 3>what dreams are and perhaps even the big</v>

859
00:49:16.181 --> 00:49:19.090
<v Speaker 3>questions like consciousness.</v>
<v Speaker 3>And uh,</v>

860
00:49:19.150 --> 00:49:23.440
<v Speaker 3>as Richard Feynman said,</v>
<v Speaker 3>is one of my all time scientific heroes.</v>

861
00:49:23.650 --> 00:49:26.440
<v Speaker 3>What I cannot create,</v>
<v Speaker 3>I do not truly understand.</v>

862
00:49:26.650 --> 00:49:29.440
<v Speaker 3>And I think about that,</v>
<v Speaker 3>about intelligence.</v>

863
00:49:29.860 --> 00:49:34.860
<v Speaker 3>And I just want to finish and give the </v>
<v Speaker 3>last word to find men actually and a </v>

864
00:49:34.860 --> 00:49:37.780
<v Speaker 3>passage from one of his books that </v>
<v Speaker 3>really inspired me when I was a child to</v>

865
00:49:37.781 --> 00:49:42.781
<v Speaker 3>think about science and arts and this is</v>
<v Speaker 3>the way I feel and it sort of echoes my </v>

866
00:49:42.781 --> 00:49:42.820
<v Speaker 3>views on the topic.</v>

867
00:49:43.390 --> 00:49:45.850
<v Speaker 3>And he said,</v>
<v Speaker 3>a fireman said,</v>

868
00:49:45.890 --> 00:49:50.890
<v Speaker 3>well though I may not be quite as </v>
<v Speaker 3>refined aesthetically as my artist </v>

869
00:49:50.890 --> 00:49:53.791
<v Speaker 3>friend is,</v>
<v Speaker 3>he was walking through a meadow with is </v>

870
00:49:53.791 --> 00:49:57.420
<v Speaker 3>a good friend of his who was an artist </v>
<v Speaker 3>and they were looking at a flower and </v>

871
00:49:57.420 --> 00:49:59.320
<v Speaker 3>they were discussing this and he said,</v>
<v Speaker 3>I can appreciate the beauty of a flower.</v>

872
00:50:00.010 --> 00:50:02.890
<v Speaker 3>At the same time,</v>
<v Speaker 3>I can see much more about the flower.</v>

873
00:50:03.340 --> 00:50:06.250
<v Speaker 3>I could imagine the cells in there,</v>
<v Speaker 3>the complicated action inside,</v>

874
00:50:06.251 --> 00:50:11.251
<v Speaker 3>which also have a kind of beauty.</v>
<v Speaker 3>The fact that the colors in the flower </v>

875
00:50:11.251 --> 00:50:15.190
<v Speaker 3>evolved in order to attract insects to </v>
<v Speaker 3>pollinate isn't is very interesting.</v>

876
00:50:15.550 --> 00:50:17.860
<v Speaker 3>It means that these insects can see the </v>
<v Speaker 3>color.</v>

877
00:50:18.820 --> 00:50:23.820
<v Speaker 3>All kinds of interesting questions with </v>
<v Speaker 3>the science knowledge only adds to the </v>

878
00:50:23.820 --> 00:50:24.970
<v Speaker 3>excitement,</v>
<v Speaker 3>the mystery and the all of a flower.</v>

879
00:50:25.570 --> 00:50:28.670
<v Speaker 3>And I think is really right about that </v>
<v Speaker 3>and that's why I love by science.</v>

880
00:50:28.671 --> 00:50:29.750
<v Speaker 3>I cannot thank you.</v>

881
00:50:31.780 --> 00:50:36.780
<v Speaker 2>Thank you.</v>

882
00:50:43.860 --> 00:50:47.000
<v Speaker 4>Dummies is an academy here waiting to,</v>
<v Speaker 4>um,</v>

883
00:50:47.580 --> 00:50:49.710
<v Speaker 4>not get at you,</v>
<v Speaker 4>but I'll ask you some questions,</v>

884
00:50:49.711 --> 00:50:52.260
<v Speaker 4>but I just want to pick up on a couple </v>
<v Speaker 4>of points.</v>

885
00:50:53.070 --> 00:50:57.660
<v Speaker 4>Your background was in gaming.</v>
<v Speaker 4>It was competitive.</v>

886
00:50:57.690 --> 00:51:00.240
<v Speaker 4>You've come here,</v>
<v Speaker 4>I think in the spirit of collegiality,</v>

887
00:51:00.241 --> 00:51:01.680
<v Speaker 4>of openness,</v>
<v Speaker 4>of a dialogue.</v>

888
00:51:02.670 --> 00:51:04.860
<v Speaker 4>It was interesting in the,</v>
<v Speaker 4>in the go game,</v>

889
00:51:05.260 --> 00:51:09.300
<v Speaker 4>Lisa Dol said that he felt he was there </v>
<v Speaker 4>defending human intelligence.</v>

890
00:51:09.720 --> 00:51:14.400
<v Speaker 4>And last,</v>
<v Speaker 4>I think we've gone past the stage,</v>

891
00:51:14.401 --> 00:51:17.160
<v Speaker 4>at least I hope we have the arts and </v>
<v Speaker 4>science are pitted against each other.</v>

892
00:51:17.610 --> 00:51:21.660
<v Speaker 4>But do you think that element of </v>
<v Speaker 4>competitiveness that humans,</v>

893
00:51:21.661 --> 00:51:26.661
<v Speaker 4>inevitable competitiveness is still </v>
<v Speaker 4>essential in developing what it is </v>

894
00:51:27.901 --> 00:51:32.901
<v Speaker 4>you're trying to develop an establishing</v>
<v Speaker 4>relationships and knowledge between ai </v>

895
00:51:32.901 --> 00:51:32.901
<v Speaker 4>and human creativity?</v>

896
00:51:33.150 --> 00:51:33.520
<v Speaker 3>Yeah,</v>
<v Speaker 3>I mean,</v>

897
00:51:33.600 --> 00:51:34.050
<v Speaker 3>look,</v>
<v Speaker 3>it's,</v>

898
00:51:34.140 --> 00:51:39.140
<v Speaker 3>it's an interesting thing because </v>
<v Speaker 3>competitiveness is obviously when you </v>

899
00:51:39.140 --> 00:51:39.580
<v Speaker 3>positively and constructively is,</v>
<v Speaker 3>is,</v>

900
00:51:39.780 --> 00:51:42.840
<v Speaker 3>can be a very powerful driving force in </v>
<v Speaker 3>a very good one for progress.</v>

901
00:51:43.950 --> 00:51:48.950
<v Speaker 3>In response to what Lisa Dole said,</v>
<v Speaker 3>I can understand why he felt like that </v>

902
00:51:48.950 --> 00:51:53.391
<v Speaker 3>because he was representing the Ngo </v>
<v Speaker 3>world and it was quite surprising for </v>

903
00:51:53.391 --> 00:51:53.490
<v Speaker 3>him.</v>
<v Speaker 3>You know,</v>

904
00:51:53.491 --> 00:51:56.550
<v Speaker 3>he's definitely at least a decade before</v>
<v Speaker 3>he was expecting that to happen.</v>

905
00:51:56.940 --> 00:52:01.230
<v Speaker 3>But one thing you gotta remember is that</v>
<v Speaker 3>of course Alphago is a human endeavor to</v>

906
00:52:01.440 --> 00:52:06.360
<v Speaker 3>and there are all sorts of amazing </v>
<v Speaker 3>programs and researchers on the team who</v>

907
00:52:06.370 --> 00:52:11.370
<v Speaker 3>were,</v>
<v Speaker 3>who spent their whole lives building up </v>

908
00:52:11.370 --> 00:52:13.641
<v Speaker 3>their skills in the way Lisa Dole had in</v>
<v Speaker 3>his art to be able to program something </v>

909
00:52:13.651 --> 00:52:18.180
<v Speaker 3>that the architecture behind Alphago,</v>
<v Speaker 3>which then went on to learn for itself,</v>

910
00:52:18.181 --> 00:52:20.340
<v Speaker 3>but it,</v>
<v Speaker 3>of course all the initial conditions was</v>

911
00:52:20.341 --> 00:52:22.710
<v Speaker 3>created by by human scientists.</v>

912
00:52:22.950 --> 00:52:27.950
<v Speaker 3>So I think the whole thing,</v>
<v Speaker 3>and if you see the film as a </v>

913
00:52:27.950 --> 00:52:31.311
<v Speaker 3>celebration,</v>
<v Speaker 3>I think of the spirit of human endeavor </v>

914
00:52:31.311 --> 00:52:31.311
<v Speaker 3>from all sides,</v>
<v Speaker 3>from the goplayers,</v>

915
00:52:31.380 --> 00:52:34.560
<v Speaker 3>the programmers,</v>
<v Speaker 3>everyone kind of collaborating together,</v>

916
00:52:34.561 --> 00:52:39.561
<v Speaker 3>including actually the journalists and </v>
<v Speaker 3>writers who were writing about the </v>

917
00:52:40.530 --> 00:52:41.400
<v Speaker 3>match.</v>
<v Speaker 3>In fact,</v>

918
00:52:41.401 --> 00:52:46.401
<v Speaker 3>that might want to.</v>
<v Speaker 3>Some of my favorite pieces of writing </v>

919
00:52:46.401 --> 00:52:46.401
<v Speaker 3>were done by a wire journalist who was </v>
<v Speaker 3>writing.</v>

920
00:52:46.401 --> 00:52:49.110
<v Speaker 3>I thought very poetically about the </v>
<v Speaker 3>whole mash as he was watching it live,</v>

921
00:52:49.410 --> 00:52:54.410
<v Speaker 3>so I think it's actually a wonderful </v>
<v Speaker 3>celebration of human ingenuity all </v>

922
00:52:54.410 --> 00:52:57.630
<v Speaker 3>around and and I think you know,</v>
<v Speaker 3>after the match,</v>

923
00:52:57.631 --> 00:52:58.830
<v Speaker 3>since then,</v>
<v Speaker 3>if you taught him,</v>

924
00:52:59.090 --> 00:53:04.090
<v Speaker 3>he ends,</v>
<v Speaker 3>he's had time to reflect on that and I </v>

925
00:53:04.090 --> 00:53:04.090
<v Speaker 3>think it's been amazing for the go.</v>
<v Speaker 3>Well they've.</v>

926
00:53:04.090 --> 00:53:07.830
<v Speaker 3>They've unleashed their own creativity </v>
<v Speaker 3>because not only are they playing what's</v>

927
00:53:07.831 --> 00:53:10.140
<v Speaker 3>called like Alphago,</v>
<v Speaker 3>like moves also,</v>

928
00:53:10.141 --> 00:53:15.141
<v Speaker 3>many of the top go players I've spoken </v>
<v Speaker 3>to has said was felt that there is free </v>

929
00:53:15.141 --> 00:53:16.140
<v Speaker 3>their minds from the shackles of </v>
<v Speaker 3>tradition,</v>

930
00:53:16.320 --> 00:53:19.890
<v Speaker 3>so they're all trying to think the </v>
<v Speaker 3>unthinkable now and they've come up with</v>

931
00:53:19.891 --> 00:53:24.891
<v Speaker 3>their own brilliant new ideas that in </v>
<v Speaker 3>the thousands of years and hundreds of </v>

932
00:53:24.891 --> 00:53:26.940
<v Speaker 3>years past,</v>
<v Speaker 3>they have been told as as junior go,</v>

933
00:53:26.941 --> 00:53:31.941
<v Speaker 3>players not to not to do and sort of be </v>
<v Speaker 3>told off for it and now they're able to </v>

934
00:53:31.941 --> 00:53:33.480
<v Speaker 3>explore their own creativity</v>

935
00:53:33.930 --> 00:53:37.080
<v Speaker 4>without peddling a stereotype,</v>
<v Speaker 4>which is always a precluding to peddling</v>

936
00:53:37.081 --> 00:53:41.580
<v Speaker 4>a stereotype.</v>
<v Speaker 4>The world loves the notion of randomness</v>

937
00:53:41.581 --> 00:53:46.581
<v Speaker 4>and chance.</v>
<v Speaker 4>He wants to harness it and possibly for </v>

938
00:53:46.581 --> 00:53:46.581
<v Speaker 4>many artists here,</v>
<v Speaker 4>certainly for me,</v>

939
00:53:46.581 --> 00:53:51.141
<v Speaker 4>and I'm not an artist.</v>
<v Speaker 4>That moment where the commentator </v>

940
00:53:51.141 --> 00:53:52.920
<v Speaker 4>thought that a mistake had been made </v>
<v Speaker 4>becomes really interesting.</v>

941
00:53:53.280 --> 00:53:58.280
<v Speaker 4>Less the resolution you saw the beauty,</v>
<v Speaker 4>but more the fact that Beckett's idea of</v>

942
00:53:58.531 --> 00:54:02.250
<v Speaker 4>failing or failing,</v>
<v Speaker 4>Metta lies at the heart of many people's</v>

943
00:54:02.251 --> 00:54:07.251
<v Speaker 4>creative vision,</v>
<v Speaker 4>see it as impossible pursuit of </v>

944
00:54:07.251 --> 00:54:09.710
<v Speaker 4>perfection.</v>
<v Speaker 4>Whereas certain scientists theaters a </v>

945
00:54:09.710 --> 00:54:09.710
<v Speaker 4>potential pursuit of perfection.</v>
<v Speaker 4>Again,</v>

946
00:54:09.710 --> 00:54:14.591
<v Speaker 4>that's a stereotyping.</v>
<v Speaker 4>Our predicates itself in certain areas </v>

947
00:54:14.591 --> 00:54:15.450
<v Speaker 4>of having no rules of wanting to break </v>
<v Speaker 4>the rules,</v>

948
00:54:15.451 --> 00:54:20.451
<v Speaker 4>that almost becomes a tedious job,</v>
<v Speaker 4>but actually at its best it offers </v>

949
00:54:20.451 --> 00:54:21.840
<v Speaker 4>endless possibilities.</v>
<v Speaker 4>At its worst.</v>

950
00:54:21.841 --> 00:54:26.010
<v Speaker 4>It's an anoxic void of meaninglessness.</v>
<v Speaker 4>And how does that play into your pursuit</v>

951
00:54:26.011 --> 00:54:27.350
<v Speaker 4>of understanding human created?</v>

952
00:54:27.450 --> 00:54:32.450
<v Speaker 3>Well,</v>
<v Speaker 3>I think that's what I was talking about </v>

953
00:54:32.450 --> 00:54:32.450
<v Speaker 3>or trying to talk about where the types </v>
<v Speaker 3>of creativity.</v>

954
00:54:32.450 --> 00:54:35.080
<v Speaker 3>So I think the breaking of all the rules</v>
<v Speaker 3>and breaking outside of,</v>

955
00:54:35.170 --> 00:54:37.060
<v Speaker 3>you know,</v>
<v Speaker 3>going beyond what the rules allow you to</v>

956
00:54:37.061 --> 00:54:39.400
<v Speaker 3>do.</v>
<v Speaker 3>That for me would be true invention,</v>

957
00:54:39.760 --> 00:54:44.760
<v Speaker 3>which I was kind of having as the yellow</v>
<v Speaker 3>door outside the box and I think our </v>

958
00:54:44.760 --> 00:54:46.180
<v Speaker 3>systems currently are not capable of </v>
<v Speaker 3>that,</v>

959
00:54:46.420 --> 00:54:48.640
<v Speaker 3>right?</v>
<v Speaker 3>They're capable of of being creative,</v>

960
00:54:48.641 --> 00:54:53.641
<v Speaker 3>but within the rules so to speak,</v>
<v Speaker 3>which is what I was sort of meaning by </v>

961
00:54:53.641 --> 00:54:57.121
<v Speaker 3>extrapolation,</v>
<v Speaker 3>so here's the rules of go come up with </v>

962
00:54:57.121 --> 00:55:00.301
<v Speaker 3>some new motifs of new strategies and </v>
<v Speaker 3>new tactics and new theories and it was </v>

963
00:55:00.301 --> 00:55:02.230
<v Speaker 3>able to do that that we're genuinely </v>
<v Speaker 3>new,</v>

964
00:55:02.440 --> 00:55:07.440
<v Speaker 3>so I think that is a genuine form of </v>
<v Speaker 3>creativity but not the highest level of </v>

965
00:55:07.440 --> 00:55:11.461
<v Speaker 3>creativity,</v>
<v Speaker 3>which would be something like coming up </v>

966
00:55:11.461 --> 00:55:11.461
<v Speaker 3>with go in the first place.</v>

967
00:55:11.590 --> 00:55:16.590
<v Speaker 4>I think there are many people in this </v>
<v Speaker 4>room who would love ai to take over the </v>

968
00:55:16.590 --> 00:55:19.870
<v Speaker 4>role of the critic and I think the </v>
<v Speaker 4>notion of criticism,</v>

969
00:55:19.871 --> 00:55:22.180
<v Speaker 4>how we judge things,</v>
<v Speaker 4>human taste,</v>

970
00:55:22.181 --> 00:55:26.350
<v Speaker 4>how we decide that something is more </v>
<v Speaker 4>interesting or better than another is an</v>

971
00:55:26.351 --> 00:55:28.060
<v Speaker 4>inexact science.</v>
<v Speaker 4>It can be a poetry,</v>

972
00:55:28.061 --> 00:55:31.690
<v Speaker 4>but it's in an exact science.</v>
<v Speaker 4>How does that play into your thinking?</v>

973
00:55:32.670 --> 00:55:37.670
<v Speaker 3>What I think some aspects of aesthetic </v>
<v Speaker 3>judgment could potentially be learned by</v>

974
00:55:38.221 --> 00:55:40.440
<v Speaker 3>these systems.</v>
<v Speaker 3>You've given enough training data,</v>

975
00:55:40.441 --> 00:55:45.441
<v Speaker 3>you know,</v>
<v Speaker 3>maybe there was some amazing art critic </v>

976
00:55:45.441 --> 00:55:47.931
<v Speaker 3>or restaurant critic that you wanted to </v>
<v Speaker 3>kind of mimic the judgment of and maybe </v>

977
00:55:49.231 --> 00:55:52.500
<v Speaker 3>given enough data.</v>
<v Speaker 3>Some of those aspects could be judged,</v>

978
00:55:52.530 --> 00:55:57.530
<v Speaker 3>could be sort of mimicked in some way,</v>
<v Speaker 3>but I think it was still go beyond that </v>

979
00:55:57.530 --> 00:55:59.520
<v Speaker 3>because when I went to an art critics </v>
<v Speaker 3>judging arts,</v>

980
00:55:59.700 --> 00:56:04.700
<v Speaker 3>one of the things that I,</v>
<v Speaker 3>I regard about human created our why </v>

981
00:56:04.700 --> 00:56:08.041
<v Speaker 3>she's.</v>
<v Speaker 3>Why I think it's higher than machine </v>

982
00:56:08.041 --> 00:56:09.831
<v Speaker 3>created are,</v>
<v Speaker 3>is the part from the technicalities of </v>

983
00:56:09.831 --> 00:56:12.771
<v Speaker 3>it is that there's always the imprint of</v>
<v Speaker 3>the artists through their artwork and I </v>

984
00:56:12.901 --> 00:56:17.901
<v Speaker 3>think some of the soul of the artist </v>
<v Speaker 3>come through that art and that's what </v>

985
00:56:17.901 --> 00:56:20.820
<v Speaker 3>we're appreciating as human viewers of </v>
<v Speaker 3>the art and where perhaps the art critic</v>

986
00:56:20.821 --> 00:56:25.821
<v Speaker 3>too.</v>
<v Speaker 3>So I always think of someone like Van </v>

987
00:56:25.821 --> 00:56:25.821
<v Speaker 3>Gough,</v>
<v Speaker 3>his,</v>

988
00:56:25.821 --> 00:56:29.240
<v Speaker 3>this sort of the tortured nature of his </v>
<v Speaker 3>soul comes for almost every brush stroke</v>

989
00:56:29.260 --> 00:56:30.160
<v Speaker 3>he,</v>
<v Speaker 3>he has.</v>

990
00:56:30.161 --> 00:56:32.710
<v Speaker 3>And that's one of the reasons why his </v>
<v Speaker 3>art so incredible.</v>

991
00:56:32.830 --> 00:56:37.830
<v Speaker 3>And I think it wouldn't be the same even</v>
<v Speaker 3>if a machine could match it technically,</v>

992
00:56:38.380 --> 00:56:43.380
<v Speaker 3>which obviously is a big f anyway in of </v>
<v Speaker 3>itself because I think part of what's </v>

993
00:56:43.380 --> 00:56:46.610
<v Speaker 3>great about artists,</v>
<v Speaker 3>the is the is the sort of the,</v>

994
00:56:46.620 --> 00:56:47.870
<v Speaker 3>the,</v>
<v Speaker 3>the imprint of what they,</v>

995
00:56:47.920 --> 00:56:50.550
<v Speaker 3>of what the artist has experienced in </v>
<v Speaker 3>creating the art.</v>

996
00:56:50.850 --> 00:56:55.850
<v Speaker 4>Well,</v>
<v Speaker 4>I mean there are many things that can </v>

997
00:56:55.850 --> 00:56:59.031
<v Speaker 4>affirm,</v>
<v Speaker 4>but one of them is the affirmation that </v>

998
00:56:59.031 --> 00:56:59.031
<v Speaker 4>I'm here,</v>
<v Speaker 4>I'm alive.</v>

999
00:56:59.031 --> 00:56:59.031
<v Speaker 4>What it is to be human wrestling with </v>
<v Speaker 4>the human condition.</v>

1000
00:56:59.280 --> 00:57:04.280
<v Speaker 4>Presumably a machine can't do that.</v>
<v Speaker 4>But presumably you're arguing that at </v>

1001
00:57:04.280 --> 00:57:04.280
<v Speaker 4>some stage in the not too distant </v>
<v Speaker 4>future,</v>

1002
00:57:04.280 --> 00:57:06.030
<v Speaker 4>it might be able to have a semblance of </v>
<v Speaker 4>that.</v>

1003
00:57:06.090 --> 00:57:07.970
<v Speaker 4>Or is that nonsense?</v>
<v Speaker 4>What's the timeframe?</v>

1004
00:57:07.980 --> 00:57:09.630
<v Speaker 4>I mean months,</v>
<v Speaker 4>years.</v>

1005
00:57:09.930 --> 00:57:14.930
<v Speaker 4>You'll obviously say not,</v>
<v Speaker 4>but is there a sense that we're looking </v>

1006
00:57:14.930 --> 00:57:16.680
<v Speaker 4>at something approaching this in the </v>
<v Speaker 4>next decade?</v>

1007
00:57:16.760 --> 00:57:17.570
<v Speaker 3>No,</v>
<v Speaker 3>I think,</v>

1008
00:57:17.670 --> 00:57:19.820
<v Speaker 3>I mean aspects of it in the next </v>
<v Speaker 3>decades.</v>

1009
00:57:19.880 --> 00:57:24.880
<v Speaker 3>But I mean,</v>
<v Speaker 3>I think this is what I mentioned at the </v>

1010
00:57:24.880 --> 00:57:27.461
<v Speaker 3>end really about what fascinates me is </v>
<v Speaker 3>both a neuroscientist and a computer </v>

1011
00:57:27.461 --> 00:57:28.210
<v Speaker 3>scientist is that,</v>
<v Speaker 3>you know,</v>

1012
00:57:28.510 --> 00:57:31.300
<v Speaker 3>what are these aspects of the brain </v>
<v Speaker 3>that,</v>

1013
00:57:31.710 --> 00:57:35.420
<v Speaker 3>that mechanism cannot be done </v>
<v Speaker 3>computationally.</v>

1014
00:57:35.540 --> 00:57:40.540
<v Speaker 3>Are there any and if they are,</v>
<v Speaker 3>what are they and what mechanisms do </v>

1015
00:57:40.540 --> 00:57:42.320
<v Speaker 3>they use can be explained or is this </v>
<v Speaker 3>something mysterious?</v>

1016
00:57:42.470 --> 00:57:47.180
<v Speaker 3>And I'm quite open minded about that and</v>
<v Speaker 3>I think what I see is part of what we're</v>

1017
00:57:47.181 --> 00:57:49.550
<v Speaker 3>doing,</v>
<v Speaker 3>which is this neuroscience inspired ai,</v>

1018
00:57:49.820 --> 00:57:54.820
<v Speaker 3>is let's see where that takes us.</v>
<v Speaker 3>And then we'll see which aspects remain </v>

1019
00:57:55.010 --> 00:57:57.520
<v Speaker 3>that only the human brain can do.</v>
<v Speaker 3>And you know,</v>

1020
00:57:57.521 --> 00:58:01.520
<v Speaker 3>I think about that for creativity.</v>
<v Speaker 3>I think about that for a dreams.</v>

1021
00:58:01.521 --> 00:58:04.940
<v Speaker 3>I think about that for consciousness.</v>
<v Speaker 3>We don't know what these things are,</v>

1022
00:58:05.480 --> 00:58:06.650
<v Speaker 3>the nature of consciousness.</v>

1023
00:58:06.800 --> 00:58:09.660
<v Speaker 3>We don't know how they manifest </v>
<v Speaker 3>themselves in,</v>

1024
00:58:09.800 --> 00:58:11.570
<v Speaker 3>in,</v>
<v Speaker 3>in the physics of our brain.</v>

1025
00:58:11.600 --> 00:58:13.280
<v Speaker 3>There are theories,</v>
<v Speaker 3>but we don't know.</v>

1026
00:58:13.490 --> 00:58:16.590
<v Speaker 3>And I think this may be one way of,</v>
<v Speaker 3>uh,</v>

1027
00:58:16.620 --> 00:58:17.290
<v Speaker 3>of,</v>
<v Speaker 3>of,</v>

1028
00:58:17.320 --> 00:58:20.360
<v Speaker 3>of,</v>
<v Speaker 3>of examining that is I'm trying to build</v>

1029
00:58:20.361 --> 00:58:24.170
<v Speaker 3>aspects of intelligence and then seeing </v>
<v Speaker 3>what was missing.</v>

1030
00:58:24.171 --> 00:58:25.690
<v Speaker 3>And some of those things,</v>
<v Speaker 3>you know,</v>

1031
00:58:25.700 --> 00:58:27.380
<v Speaker 3>maybe impossible,</v>
<v Speaker 3>although for,</v>

1032
00:58:27.440 --> 00:58:28.700
<v Speaker 3>for the moment,</v>
<v Speaker 3>um,</v>

1033
00:58:28.970 --> 00:58:33.970
<v Speaker 3>you know,</v>
<v Speaker 3>at least from a biological point of </v>

1034
00:58:33.970 --> 00:58:35.711
<v Speaker 3>view,</v>
<v Speaker 3>that doesn't seem to be anything long </v>

1035
00:58:35.711 --> 00:58:36.620
<v Speaker 3>computable in the brain,</v>
<v Speaker 3>although there's speculation about that.</v>

1036
00:58:36.621 --> 00:58:41.621
<v Speaker 3>There's a famous mathematician called </v>
<v Speaker 3>Roger Penrose who talks about quantum </v>

1037
00:58:41.621 --> 00:58:43.910
<v Speaker 3>consciousness and he thinks there are </v>
<v Speaker 3>quantum effects in the brain,</v>

1038
00:58:44.120 --> 00:58:49.120
<v Speaker 3>in which case if he's right,</v>
<v Speaker 3>then we will not be able to model those </v>

1039
00:58:50.901 --> 00:58:53.870
<v Speaker 3>on a conventional computer.</v>
<v Speaker 3>Traditional classical computer.</v>

1040
00:58:54.710 --> 00:58:59.710
<v Speaker 3>But so far,</v>
<v Speaker 3>and biologists have looked for this </v>

1041
00:58:59.710 --> 00:58:59.710
<v Speaker 3>quite hard there,</v>
<v Speaker 3>that they,</v>

1042
00:58:59.710 --> 00:59:01.550
<v Speaker 3>no one's found any quantum effects in </v>
<v Speaker 3>the brain so far.</v>

1043
00:59:01.970 --> 00:59:04.280
<v Speaker 4>I love the idea that the computer would </v>
<v Speaker 4>not,</v>

1044
00:59:04.370 --> 00:59:05.900
<v Speaker 4>it would,</v>
<v Speaker 4>we'd have to do,</v>

1045
00:59:05.901 --> 00:59:07.550
<v Speaker 4>is learn to invent,</v>
<v Speaker 4>reinvent,</v>

1046
00:59:07.640 --> 00:59:10.010
<v Speaker 4>go itself May.</v>
<v Speaker 4>Maybe in the end it will reinvent.</v>

1047
00:59:10.430 --> 00:59:13.700
<v Speaker 4>But are one of these art does,</v>
<v Speaker 4>is constantly reinvents itself.</v>

1048
00:59:14.390 --> 00:59:17.330
<v Speaker 4>You've already given us about six </v>
<v Speaker 4>potential lectures.</v>

1049
00:59:18.170 --> 00:59:23.170
<v Speaker 4>I'm not so cheeky or opportunistic to </v>
<v Speaker 4>ask you to come back and give series </v>

1050
00:59:23.170 --> 00:59:23.240
<v Speaker 4>here,</v>
<v Speaker 4>but you should do really.</v>

1051
00:59:23.780 --> 00:59:28.780
<v Speaker 4>But I'm also conscious that there are </v>
<v Speaker 4>people here in the brief time we have </v>

1052
00:59:28.780 --> 00:59:32.081
<v Speaker 4>left now,</v>
<v Speaker 4>you will have questions to make </v>

1053
00:59:32.081 --> 00:59:33.210
<v Speaker 4>questions to ask of you and I do think </v>
<v Speaker 4>there should be another forum to,</v>

1054
00:59:33.280 --> 00:59:35.330
<v Speaker 4>to,</v>
<v Speaker 4>to look through the implications of much</v>

1055
00:59:35.331 --> 00:59:38.540
<v Speaker 4>of what you said could,</v>
<v Speaker 4>could ask people to ask questions rather</v>

1056
00:59:38.541 --> 00:59:43.541
<v Speaker 4>than make long statements.</v>
<v Speaker 4>I know that's difficult because there's </v>

1057
00:59:43.541 --> 00:59:43.541
<v Speaker 4>so much that's been thrown out,</v>
<v Speaker 4>but I'd love to take some questions from</v>

1058
00:59:43.541 --> 00:59:43.640
<v Speaker 4>the floor.</v>

1059
00:59:44.060 --> 00:59:46.460
<v Speaker 4>Could you wait for the mic?</v>
<v Speaker 4>There's a hand up at the back there.</v>

1060
00:59:46.520 --> 00:59:47.810
<v Speaker 4>Thank you.</v>
<v Speaker 4>Hi.</v>

1061
00:59:47.870 --> 00:59:49.910
<v Speaker 4>Thank you.</v>
<v Speaker 4>A great lecture.</v>

1062
00:59:50.240 --> 00:59:52.670
<v Speaker 4>And following on from what you were just</v>
<v Speaker 4>discussing,</v>

1063
00:59:52.970 --> 00:59:57.970
<v Speaker 4>uh,</v>
<v Speaker 4>you said at the beginning that's a </v>

1064
00:59:57.970 --> 01:00:00.490
<v Speaker 4>reinforcement learning.</v>
<v Speaker 4>We know that that model can lead to a </v>

1065
01:00:00.490 --> 01:00:02.150
<v Speaker 4>general intelligence.</v>
<v Speaker 4>And so I was wondering if,</v>

1066
01:00:02.240 --> 01:00:02.830
<v Speaker 4>if,</v>
<v Speaker 4>uh,</v>

1067
01:00:03.080 --> 01:00:04.390
<v Speaker 4>in order to,</v>
<v Speaker 4>uh,</v>

1068
01:00:04.580 --> 01:00:09.580
<v Speaker 4>to get the general intelligence and the </v>
<v Speaker 4>higher level of creativity like </v>

1069
01:00:09.580 --> 01:00:11.660
<v Speaker 4>invention,</v>
<v Speaker 4>do you think we need to,</v>

1070
01:00:12.130 --> 01:00:17.130
<v Speaker 4>to work out consciousness and </v>
<v Speaker 4>intentionality and do you agree with </v>

1071
01:00:17.130 --> 01:00:19.140
<v Speaker 4>philosophers like John Self new say,</v>
<v Speaker 4>um,</v>

1072
01:00:19.640 --> 01:00:20.690
<v Speaker 4>that,</v>
<v Speaker 4>uh,</v>

1073
01:00:20.720 --> 01:00:22.150
<v Speaker 4>we need to understand the,</v>
<v Speaker 4>the,</v>

1074
01:00:22.210 --> 01:00:25.580
<v Speaker 4>the physical material of the brain </v>
<v Speaker 4>rather than just the algorithm?</v>

1075
01:00:27.080 --> 01:00:27.340
<v Speaker 3>No,</v>
<v Speaker 3>I.</v>

1076
01:00:27.341 --> 01:00:32.341
<v Speaker 3>So I disagree with John Cell and um,</v>
<v Speaker 3>I do think that you can make progress on</v>

1077
01:00:34.231 --> 01:00:37.570
<v Speaker 3>this question without fully </v>
<v Speaker 3>understanding the substrate and fat.</v>

1078
01:00:37.640 --> 01:00:42.640
<v Speaker 3>I,</v>
<v Speaker 3>I believe that intelligence will be </v>

1079
01:00:42.640 --> 01:00:45.921
<v Speaker 3>substrate independent in the sense that </v>
<v Speaker 3>we are forced to learning is the way </v>

1080
01:00:45.921 --> 01:00:49.491
<v Speaker 3>we're going to try and build it.</v>
<v Speaker 3>But there are probably other ways of </v>

1081
01:00:49.491 --> 01:00:49.491
<v Speaker 3>building intelligence.</v>
<v Speaker 3>They're more mathematical,</v>

1082
01:00:49.491 --> 01:00:52.200
<v Speaker 3>less neuroscience based,</v>
<v Speaker 3>and even the neuroscience based way like</v>

1083
01:00:52.201 --> 01:00:53.220
<v Speaker 3>we're doing,</v>
<v Speaker 3>you know,</v>

1084
01:00:53.221 --> 01:00:54.870
<v Speaker 3>we're really looking at the systems </v>
<v Speaker 3>level,</v>

1085
01:00:54.930 --> 01:00:58.380
<v Speaker 3>the algorithmic level,</v>
<v Speaker 3>not at the actual wetware itself,</v>

1086
01:00:58.381 --> 01:01:01.230
<v Speaker 3>the exact way that neurons work and </v>
<v Speaker 3>cortical columns.</v>

1087
01:01:01.290 --> 01:01:06.290
<v Speaker 3>Other people are doing that.</v>
<v Speaker 3>That's sometimes called whole brain </v>

1088
01:01:06.290 --> 01:01:09.111
<v Speaker 3>emulation where you're effectively </v>
<v Speaker 3>trying to reverse engineer the brain's </v>

1089
01:01:09.111 --> 01:01:10.230
<v Speaker 3>precisely and implement it in the same </v>
<v Speaker 3>way the brain does.</v>

1090
01:01:10.500 --> 01:01:14.880
<v Speaker 3>And I don't believe that will be </v>
<v Speaker 3>necessary for intelligence as to whether</v>

1091
01:01:14.881 --> 01:01:18.240
<v Speaker 3>we'll need consciousness for true </v>
<v Speaker 3>creativity and other things.</v>

1092
01:01:18.540 --> 01:01:20.400
<v Speaker 3>I'm not sure I,</v>
<v Speaker 3>I,</v>

1093
01:01:20.460 --> 01:01:21.490
<v Speaker 3>if I was,</v>
<v Speaker 3>you know,</v>

1094
01:01:21.630 --> 01:01:26.370
<v Speaker 3>I think there's a open scientific </v>
<v Speaker 3>question and we need to get further with</v>

1095
01:01:26.371 --> 01:01:31.371
<v Speaker 3>the research to understand that.</v>
<v Speaker 3>But I would say that if I was to bet on </v>

1096
01:01:31.371 --> 01:01:31.371
<v Speaker 3>it,</v>
<v Speaker 3>um,</v>

1097
01:01:31.380 --> 01:01:36.380
<v Speaker 3>I think it's likely that intelligence </v>
<v Speaker 3>and consciousness are what's called </v>

1098
01:01:36.380 --> 01:01:40.731
<v Speaker 3>double dissociable.</v>
<v Speaker 3>So I think you'll be able to have </v>

1099
01:01:40.731 --> 01:01:43.340
<v Speaker 3>intelligent systems that will,</v>
<v Speaker 3>that we fantastically intelligent in </v>

1100
01:01:43.340 --> 01:01:46.821
<v Speaker 3>terms of the capability but will not </v>
<v Speaker 3>feel conscious in any way in the way </v>

1101
01:01:46.821 --> 01:01:46.821
<v Speaker 3>that I do to you.</v>
<v Speaker 3>You do.</v>

1102
01:01:46.821 --> 01:01:48.540
<v Speaker 3>To me.</v>
<v Speaker 3>And I also think on the other end of the</v>

1103
01:01:48.541 --> 01:01:50.280
<v Speaker 3>spectrum,</v>
<v Speaker 3>if you look at animals,</v>

1104
01:01:50.281 --> 01:01:52.110
<v Speaker 3>for example,</v>
<v Speaker 3>like our pets,</v>

1105
01:01:52.111 --> 01:01:57.111
<v Speaker 3>like dogs and cats and so on,</v>
<v Speaker 3>I think it's pretty clear they have </v>

1106
01:01:57.111 --> 01:01:57.660
<v Speaker 3>fought some form of consciousness.</v>
<v Speaker 3>You see them dreaming and,</v>

1107
01:01:57.900 --> 01:02:02.900
<v Speaker 3>and they seem to have those kinds of </v>
<v Speaker 3>traits or self awareness and other </v>

1108
01:02:02.900 --> 01:02:04.920
<v Speaker 3>things,</v>
<v Speaker 3>but obviously they're not close to human</v>

1109
01:02:04.921 --> 01:02:09.921
<v Speaker 3>level intelligence.</v>
<v Speaker 3>So it seems as though maybe the </v>

1110
01:02:09.921 --> 01:02:12.410
<v Speaker 3>dissociable traits,</v>
<v Speaker 3>but um,</v>

1111
01:02:12.510 --> 01:02:13.280
<v Speaker 3>you know,</v>
<v Speaker 3>who,</v>

1112
01:02:13.350 --> 01:02:15.180
<v Speaker 3>who knows,</v>
<v Speaker 3>maybe we'll get in 20 years time,</v>

1113
01:02:15.181 --> 01:02:20.181
<v Speaker 3>we'll get to a point where we are okay,</v>
<v Speaker 3>we're sort of stuck against the brick </v>

1114
01:02:20.181 --> 01:02:23.481
<v Speaker 3>wall and actually the reason we can't </v>
<v Speaker 3>have more intelligent systems is we now </v>

1115
01:02:23.481 --> 01:02:23.940
<v Speaker 3>understand what this consciousness thing</v>
<v Speaker 3>is.</v>

1116
01:02:24.350 --> 01:02:26.870
<v Speaker 6>Thank you for questions.</v>
<v Speaker 6>Beautifully balanced systematically.</v>

1117
01:02:26.890 --> 01:02:27.080
<v Speaker 6>Yeah.</v>

1118
01:02:27.490 --> 01:02:28.280
<v Speaker 7>Gentlemen that and then.</v>

1119
01:02:32.390 --> 01:02:33.680
<v Speaker 3>Hi,</v>
<v Speaker 3>thanks for the great lecture.</v>

1120
01:02:33.770 --> 01:02:38.770
<v Speaker 3>Um,</v>
<v Speaker 3>do you think that the current speed of </v>

1121
01:02:38.770 --> 01:02:40.991
<v Speaker 3>ai research has had a negative impact on</v>
<v Speaker 3>its practices in the field and if so,</v>

1122
01:02:43.940 --> 01:02:45.110
<v Speaker 3>what do you think can be done about it</v>

1123
01:02:47.430 --> 01:02:51.500
<v Speaker 3>tag mean negative on,</v>
<v Speaker 3>on its own in terms of its applications?</v>

1124
01:02:55.220 --> 01:02:55.640
<v Speaker 3>Yeah.</v>
<v Speaker 3>No,</v>

1125
01:02:55.641 --> 01:02:58.070
<v Speaker 3>I don't think so.</v>
<v Speaker 3>I think it's mostly been positive.</v>

1126
01:02:58.071 --> 01:02:59.570
<v Speaker 3>I would say,</v>
<v Speaker 3>um,</v>

1127
01:02:59.960 --> 01:03:02.900
<v Speaker 3>I think like with any,</v>
<v Speaker 3>any hot topic and that's,</v>

1128
01:03:03.050 --> 01:03:07.430
<v Speaker 3>I think it's a bit too hyped and I think</v>
<v Speaker 3>that's caused a lot of um,</v>

1129
01:03:07.640 --> 01:03:09.860
<v Speaker 3>you know,</v>
<v Speaker 3>the sorts of bad cycles you get when,</v>

1130
01:03:10.040 --> 01:03:10.340
<v Speaker 3>when,</v>
<v Speaker 3>uh,</v>

1131
01:03:10.370 --> 01:03:15.370
<v Speaker 3>when uh,</v>
<v Speaker 3>an area gets to the top of the hype </v>

1132
01:03:15.370 --> 01:03:15.370
<v Speaker 3>cycle.</v>
<v Speaker 3>So I think there's been a lot of amazing</v>

1133
01:03:15.370 --> 01:03:19.211
<v Speaker 3>work that's happened,</v>
<v Speaker 3>but some of the promises are over </v>

1134
01:03:19.211 --> 01:03:19.400
<v Speaker 3>promising still compared to where we </v>
<v Speaker 3>are.</v>

1135
01:03:19.800 --> 01:03:24.800
<v Speaker 3>Um,</v>
<v Speaker 3>and I think that sometimes can lead to </v>

1136
01:03:24.800 --> 01:03:25.770
<v Speaker 3>some bad silence this rushed or in some </v>
<v Speaker 3>way,</v>

1137
01:03:25.890 --> 01:03:27.990
<v Speaker 3>but I think mostly the community is </v>
<v Speaker 3>actually very good.</v>

1138
01:03:27.991 --> 01:03:30.960
<v Speaker 3>The research community around Ai and </v>
<v Speaker 3>it's very open.</v>

1139
01:03:31.680 --> 01:03:36.680
<v Speaker 3>Everyone publishes everything and I </v>
<v Speaker 3>think it's pretty collegiate at the </v>

1140
01:03:36.680 --> 01:03:36.680
<v Speaker 3>moment.</v>

1141
01:03:36.680 --> 01:03:38.340
<v Speaker 3>So I would say the research communities </v>
<v Speaker 3>actually pretty solid.</v>

1142
01:03:38.610 --> 01:03:43.610
<v Speaker 3>And I actually think in order for us to </v>
<v Speaker 3>get to better practice best practices </v>

1143
01:03:43.610 --> 01:03:46.440
<v Speaker 3>and protocols that say around how these </v>
<v Speaker 3>systems are deployed,</v>

1144
01:03:46.710 --> 01:03:49.230
<v Speaker 3>I actually think we need to get further </v>
<v Speaker 3>with the systems.</v>

1145
01:03:49.320 --> 01:03:54.320
<v Speaker 3>So we have concrete systems to </v>
<v Speaker 3>experiment on and actually figure out </v>

1146
01:03:54.320 --> 01:03:58.160
<v Speaker 3>because compete science isn't,</v>
<v Speaker 3>it's not theoretical subjects in </v>

1147
01:03:58.160 --> 01:03:59.250
<v Speaker 3>engineering discipline.</v>
<v Speaker 3>So in order for us to make progress with</v>

1148
01:03:59.251 --> 01:04:04.251
<v Speaker 3>that,</v>
<v Speaker 3>I think we have to have systems that we </v>

1149
01:04:04.251 --> 01:04:06.381
<v Speaker 3>can actually test empirically test and I</v>
<v Speaker 3>think all the best science is done with </v>

1150
01:04:06.381 --> 01:04:10.641
<v Speaker 3>empirical work in tandem with </v>
<v Speaker 3>theoretical work and for us the </v>

1151
01:04:10.641 --> 01:04:12.120
<v Speaker 3>empirical work is engineering.</v>
<v Speaker 3>Yes.</v>

1152
01:04:20.750 --> 01:04:25.750
<v Speaker 6>Thank you for the lecture.</v>
<v Speaker 6>I think I need an ai to help me process </v>

1153
01:04:25.750 --> 01:04:26.650
<v Speaker 6>all the information you've just given us</v>
<v Speaker 6>in the last hour.</v>

1154
01:04:27.500 --> 01:04:30.620
<v Speaker 6>I'd like to take you back to your art </v>
<v Speaker 6>and science comment at the beginning.</v>

1155
01:04:30.621 --> 01:04:35.621
<v Speaker 6>So have you looked at using Gq n two </v>
<v Speaker 6>instead of trying to recreate three </v>

1156
01:04:36.561 --> 01:04:41.561
<v Speaker 6>dimensional computer graphics,</v>
<v Speaker 6>potentially recreate architecture or </v>

1157
01:04:41.561 --> 01:04:46.360
<v Speaker 6>environments that live longer exist,</v>
<v Speaker 6>whether it's because of war or just you </v>

1158
01:04:46.431 --> 01:04:47.840
<v Speaker 6>know,</v>
<v Speaker 6>dilapidation there's,</v>

1159
01:04:48.170 --> 01:04:53.170
<v Speaker 6>there's a lot of amazing art in the </v>
<v Speaker 6>world architecture that has been lost </v>

1160
01:04:53.180 --> 01:04:56.900
<v Speaker 6>and there are a lot of paintings and </v>
<v Speaker 6>photographic representations of that.</v>

1161
01:04:56.901 --> 01:05:01.901
<v Speaker 6>And is it something you guys had looked </v>
<v Speaker 6>at in terms of trying to help us </v>

1162
01:05:01.901 --> 01:05:01.901
<v Speaker 6>recapture some of that?</v>
<v Speaker 6>Yeah,</v>

1163
01:05:01.901 --> 01:05:06.890
<v Speaker 3>we have started to look at that.</v>
<v Speaker 3>So as I mentioned where we gq and we're </v>

1164
01:05:06.890 --> 01:05:11.031
<v Speaker 3>now trying to build up to more complex </v>
<v Speaker 3>scenes in and eventually we're world </v>

1165
01:05:11.031 --> 01:05:15.141
<v Speaker 3>architecture would be a very interesting</v>
<v Speaker 3>to try and like a room or in a </v>

1166
01:05:15.220 --> 01:05:16.460
<v Speaker 3>dilapidated room in a,</v>
<v Speaker 3>in a,</v>

1167
01:05:16.461 --> 01:05:16.990
<v Speaker 3>in a,</v>
<v Speaker 3>in,</v>

1168
01:05:17.090 --> 01:05:18.460
<v Speaker 3>in a,</v>
<v Speaker 3>in a structure.</v>

1169
01:05:18.850 --> 01:05:22.480
<v Speaker 3>Another area that's been worked on a lot</v>
<v Speaker 3>is what's called generative models,</v>

1170
01:05:22.510 --> 01:05:27.510
<v Speaker 3>which gun is an example where they're </v>
<v Speaker 3>trying to fill in pictures or even drop </v>

1171
01:05:27.510 --> 01:05:29.610
<v Speaker 3>photos and things where they try to,</v>
<v Speaker 3>um,</v>

1172
01:05:30.100 --> 01:05:31.630
<v Speaker 3>you know,</v>
<v Speaker 3>you can leave a missing part and it will</v>

1173
01:05:31.631 --> 01:05:34.570
<v Speaker 3>fill it in and they're not photo </v>
<v Speaker 3>realistic yet.</v>

1174
01:05:34.571 --> 01:05:37.270
<v Speaker 3>They're not as good as the originals.</v>
<v Speaker 3>You know,</v>

1175
01:05:37.271 --> 01:05:41.350
<v Speaker 3>you would obviously spot it immediately </v>
<v Speaker 3>as a generated by computer,</v>

1176
01:05:41.500 --> 01:05:46.500
<v Speaker 3>but they're getting better all the time.</v>
<v Speaker 3>And one of the issues is with </v>

1177
01:05:46.500 --> 01:05:50.470
<v Speaker 3>architectures are anything more complex </v>
<v Speaker 3>than our simple scenes is the system </v>

1178
01:05:50.470 --> 01:05:53.110
<v Speaker 3>still don't really understand the </v>
<v Speaker 3>semantics of a scene.</v>

1179
01:05:53.350 --> 01:05:58.350
<v Speaker 3>So they don't really understand that </v>
<v Speaker 3>these objects are separate and what </v>

1180
01:05:58.350 --> 01:05:59.060
<v Speaker 3>background is and for ground and so on.</v>
<v Speaker 3>And,</v>

1181
01:05:59.120 --> 01:06:01.780
<v Speaker 3>and how physics interacts with </v>
<v Speaker 3>structures.</v>

1182
01:06:02.020 --> 01:06:04.390
<v Speaker 3>And that's the concept part I was </v>
<v Speaker 3>talking about.</v>

1183
01:06:04.630 --> 01:06:09.630
<v Speaker 3>And I think systems like gun,</v>
<v Speaker 3>if they had abstractions and concepts </v>

1184
01:06:09.701 --> 01:06:14.701
<v Speaker 3>would start being able to pass the late </v>
<v Speaker 3>the world up into semantic meaning and </v>

1185
01:06:14.701 --> 01:06:15.970
<v Speaker 3>structure,</v>
<v Speaker 3>which then allow them to model much more</v>

1186
01:06:15.971 --> 01:06:19.120
<v Speaker 3>complicated sentence.</v>
<v Speaker 3>So I think that's what's holding us back</v>

1187
01:06:19.121 --> 01:06:20.890
<v Speaker 3>right now.</v>
<v Speaker 3>But eventually I would expect to be able</v>

1188
01:06:20.891 --> 01:06:21.880
<v Speaker 3>to do those kinds of things</v>

1189
01:06:22.000 --> 01:06:27.000
<v Speaker 8>we should say the US was always harness </v>
<v Speaker 8>technology and recently of painting was </v>

1190
01:06:27.000 --> 01:06:27.910
<v Speaker 8>made by Algorithms.</v>
<v Speaker 8>And all I can say is,</v>

1191
01:06:28.720 --> 01:06:30.460
<v Speaker 8>well it might've made it into the summer</v>
<v Speaker 8>exhibition.</v>

1192
01:06:30.580 --> 01:06:34.060
<v Speaker 8>Yeah.</v>
<v Speaker 8>Thank you very much for that.</v>

1193
01:06:34.120 --> 01:06:36.610
<v Speaker 8>I just wanted to ask you a question </v>
<v Speaker 8>about explainability.</v>

1194
01:06:37.030 --> 01:06:39.880
<v Speaker 8>So you mentioned about the move the </v>
<v Speaker 8>Alphago made.</v>

1195
01:06:39.881 --> 01:06:43.000
<v Speaker 8>That was after the fact that go experts </v>
<v Speaker 8>could say,</v>

1196
01:06:43.040 --> 01:06:44.800
<v Speaker 8>oh,</v>
<v Speaker 8>we know why it did that,</v>

1197
01:06:45.520 --> 01:06:50.520
<v Speaker 8>but you could also probably imagine </v>
<v Speaker 8>situations where it would be harder to </v>

1198
01:06:50.520 --> 01:06:52.090
<v Speaker 8>understand why a machine had made a </v>
<v Speaker 8>decision that it did.</v>

1199
01:06:52.530 --> 01:06:57.530
<v Speaker 8>Um,</v>
<v Speaker 8>do you think it's important to build </v>

1200
01:06:57.530 --> 01:06:57.530
<v Speaker 8>systems that are able to explain </v>
<v Speaker 8>themselves?</v>

1201
01:06:57.530 --> 01:07:01.440
<v Speaker 8>Or do you think it's natural that we're </v>
<v Speaker 8>going to kind of decouple away from </v>

1202
01:07:01.440 --> 01:07:01.660
<v Speaker 8>machines and will kind of lose a bit of </v>
<v Speaker 8>that agency?</v>

1203
01:07:02.200 --> 01:07:03.340
<v Speaker 3>No,</v>
<v Speaker 3>I think it's great question.</v>

1204
01:07:03.341 --> 01:07:07.150
<v Speaker 3>I think it's incredibly important that </v>
<v Speaker 3>we have interpretability and our systems</v>

1205
01:07:07.151 --> 01:07:12.151
<v Speaker 3>for a couple of reasons.</v>
<v Speaker 3>One is it's useful to advance the </v>

1206
01:07:12.151 --> 01:07:15.481
<v Speaker 3>science if the better you understand the</v>
<v Speaker 3>current systems obviously in what are </v>

1207
01:07:15.481 --> 01:07:15.481
<v Speaker 3>their,</v>
<v Speaker 3>their limitations are,</v>

1208
01:07:15.481 --> 01:07:16.450
<v Speaker 3>but for any,</v>
<v Speaker 3>uh,</v>

1209
01:07:16.480 --> 01:07:21.480
<v Speaker 3>once you start deploying these ai </v>
<v Speaker 3>systems for any safe safety critical </v>

1210
01:07:21.480 --> 01:07:25.170
<v Speaker 3>application,</v>
<v Speaker 3>of course you would need to understand </v>

1211
01:07:25.170 --> 01:07:28.110
<v Speaker 3>why the decision was made and I would </v>
<v Speaker 3>actually advocate further and always </v>

1212
01:07:28.110 --> 01:07:31.561
<v Speaker 3>have a human in the loop to make the </v>
<v Speaker 3>final decision and think of the Ai as a </v>

1213
01:07:31.561 --> 01:07:33.730
<v Speaker 3>tool that provides information to that </v>
<v Speaker 3>ultimate human decision maker.</v>

1214
01:07:34.180 --> 01:07:35.980
<v Speaker 3>Um,</v>
<v Speaker 3>and in order to do that,</v>

1215
01:07:35.981 --> 01:07:40.981
<v Speaker 3>we need to explain these black box </v>
<v Speaker 3>systems better and I don't worry about </v>

1216
01:07:40.981 --> 01:07:44.611
<v Speaker 3>that as much as other people.</v>
<v Speaker 3>So I think we're just going through a </v>

1217
01:07:44.611 --> 01:07:47.491
<v Speaker 3>phase at the moment where you can think </v>
<v Speaker 3>of it in terms of the evolution of AI </v>

1218
01:07:47.491 --> 01:07:48.220
<v Speaker 3>systems as in the last decade.</v>

1219
01:07:48.220 --> 01:07:52.030
<v Speaker 3>There's been a huge explosion of ai </v>
<v Speaker 3>systems that are really good now and can</v>

1220
01:07:52.031 --> 01:07:53.750
<v Speaker 3>do interesting things.</v>
<v Speaker 3>Um,</v>

1221
01:07:53.910 --> 01:07:56.160
<v Speaker 3>but that's very new.</v>
<v Speaker 3>And uh,</v>

1222
01:07:56.310 --> 01:07:58.240
<v Speaker 3>the,</v>
<v Speaker 3>the challenge in that they know the last</v>

1223
01:07:58.241 --> 01:08:01.180
<v Speaker 3>10 years has been can we get these </v>
<v Speaker 3>systems working at all?</v>

1224
01:08:01.360 --> 01:08:04.900
<v Speaker 3>Nevermind about interpretability now we </v>
<v Speaker 3>have the working,</v>

1225
01:08:05.020 --> 01:08:10.020
<v Speaker 3>we have something to work on,</v>
<v Speaker 3>reverse engineer and analyze now asks </v>

1226
01:08:10.020 --> 01:08:13.750
<v Speaker 3>and many other teams around the world </v>
<v Speaker 3>are concentrating on building analysis </v>

1227
01:08:13.750 --> 01:08:14.410
<v Speaker 3>tools.</v>
<v Speaker 3>So we're being analysis tools,</v>

1228
01:08:14.750 --> 01:08:16.820
<v Speaker 3>visualization tools,</v>
<v Speaker 3>all sorts of things.</v>

1229
01:08:16.821 --> 01:08:21.821
<v Speaker 3>Even doing behavioral testing like more </v>
<v Speaker 3>like you'd have in a psychology lab,</v>

1230
01:08:21.860 --> 01:08:22.450
<v Speaker 3>you know,</v>
<v Speaker 3>to look,</v>

1231
01:08:22.460 --> 01:08:25.160
<v Speaker 3>think about both behaviorally testing </v>
<v Speaker 3>it,</v>

1232
01:08:25.430 --> 01:08:28.310
<v Speaker 3>looking into the architecture,</v>
<v Speaker 3>measuring it,</v>

1233
01:08:28.340 --> 01:08:30.890
<v Speaker 3>almost like a doing brain analysis like </v>
<v Speaker 3>neuroscience,</v>

1234
01:08:30.891 --> 01:08:35.480
<v Speaker 3>but on an artificial brain.</v>
<v Speaker 3>And so with all those tools are very,</v>

1235
01:08:35.481 --> 01:08:38.930
<v Speaker 3>very embryonic right now because I've </v>
<v Speaker 3>only been in the last couple of years of</v>

1236
01:08:38.950 --> 01:08:42.110
<v Speaker 3>this being started to be worked on.</v>
<v Speaker 3>And I'm pretty sure I'm pretty confident</v>

1237
01:08:42.111 --> 01:08:45.890
<v Speaker 3>that with another sort of five years of </v>
<v Speaker 3>work on those kinds of tools,</v>

1238
01:08:46.250 --> 01:08:49.280
<v Speaker 3>a lot of these systems right now that </v>
<v Speaker 3>look quite black box,</v>

1239
01:08:50.540 --> 01:08:54.440
<v Speaker 3>black box systems will become </v>
<v Speaker 3>sustainable and adaptable.</v>

1240
01:08:54.710 --> 01:08:55.700
<v Speaker 3>So,</v>
<v Speaker 3>uh,</v>

1241
01:08:56.060 --> 01:08:57.650
<v Speaker 3>you know,</v>
<v Speaker 3>I think it's vital,</v>

1242
01:08:57.680 --> 01:09:02.190
<v Speaker 3>but I think we're just a bit on the </v>
<v Speaker 3>starting point of that and you know,</v>

1243
01:09:02.240 --> 01:09:04.430
<v Speaker 3>I wouldn't worry too much about that at </v>
<v Speaker 3>the moment.</v>

1244
01:09:04.580 --> 01:09:06.230
<v Speaker 3>A lot of these systems are quite black </v>
<v Speaker 3>box.</v>

1245
01:09:06.710 --> 01:09:09.740
<v Speaker 4>We've been rigorously program to stick </v>
<v Speaker 4>to now we've crushed through it.</v>

1246
01:09:09.830 --> 01:09:11.510
<v Speaker 4>Let's be knocking.</v>
<v Speaker 4>Take one more question.</v>

1247
01:09:11.520 --> 01:09:14.600
<v Speaker 4>You going to say one more question?</v>
<v Speaker 4>Let's take the,</v>

1248
01:09:15.040 --> 01:09:15.910
<v Speaker 7>the woman that</v>

1249
01:09:17.910 --> 01:09:21.200
<v Speaker 4>then we can carry on over a drink.</v>
<v Speaker 4>He said offering up that misty will.</v>

1250
01:09:21.520 --> 01:09:22.270
<v Speaker 4>Okay.</v>
<v Speaker 4>Thank you.</v>

1251
01:09:22.400 --> 01:09:25.840
<v Speaker 4>Last word has always been pretty fearful</v>
<v Speaker 4>of ai thing.</v>

1252
01:09:25.860 --> 01:09:28.440
<v Speaker 4>There were presentations,</v>
<v Speaker 4>things like westward and terminator,</v>

1253
01:09:28.450 --> 01:09:33.450
<v Speaker 4>etc.</v>
<v Speaker 4>And I'm very glad that you mentioned </v>

1254
01:09:33.450 --> 01:09:35.701
<v Speaker 4>ethics.</v>
<v Speaker 4>Just whAt do you think of the artworks </v>

1255
01:09:35.701 --> 01:09:38.851
<v Speaker 4>for presentation of ai and how,</v>
<v Speaker 4>how your advIse on preventing that kind </v>

1256
01:09:39.251 --> 01:09:40.360
<v Speaker 4>of future from happening?</v>

1257
01:09:41.610 --> 01:09:42.630
<v Speaker 3>Yeah,</v>
<v Speaker 3>I think the art world,</v>

1258
01:09:42.631 --> 01:09:47.631
<v Speaker 3>it would be nice if there were,</v>
<v Speaker 3>if it was a little bit more creative in </v>

1259
01:09:47.631 --> 01:09:47.631
<v Speaker 3>some sense,</v>
<v Speaker 3>right,</v>

1260
01:09:47.631 --> 01:09:51.501
<v Speaker 3>because I think it's easy to.</v>
<v Speaker 3>I mean it's obviously more dramatic to </v>

1261
01:09:51.501 --> 01:09:52.400
<v Speaker 3>have a,</v>
<v Speaker 3>you know,</v>

1262
01:09:52.470 --> 01:09:56.670
<v Speaker 3>dystopian futures and villains and so </v>
<v Speaker 3>on.</v>

1263
01:09:56.930 --> 01:09:59.040
<v Speaker 3>It's obviously creates more excitement.</v>
<v Speaker 3>Um,</v>

1264
01:09:59.190 --> 01:10:01.730
<v Speaker 3>but obviously that's a,</v>
<v Speaker 3>you know,</v>

1265
01:10:01.740 --> 01:10:04.320
<v Speaker 3>I think it's,</v>
<v Speaker 3>most of those scenarios are pure science</v>

1266
01:10:04.321 --> 01:10:06.330
<v Speaker 3>fiction and we shouldn't worry about </v>
<v Speaker 3>them too much.</v>

1267
01:10:06.660 --> 01:10:11.660
<v Speaker 3>I think that we actually need a lot of </v>
<v Speaker 3>science fiction can be very helpful in </v>

1268
01:10:12.001 --> 01:10:15.510
<v Speaker 3>terms of lots of scientists,</v>
<v Speaker 3>including myself who inspired by science</v>

1269
01:10:15.511 --> 01:10:17.610
<v Speaker 3>fiction to make some of the things they </v>
<v Speaker 3>read.</v>

1270
01:10:17.910 --> 01:10:19.920
<v Speaker 3>Certainly for me,</v>
<v Speaker 3>I read probably too much science fiction</v>

1271
01:10:19.921 --> 01:10:24.921
<v Speaker 3>when I was young to try and make that </v>
<v Speaker 3>come true and there are actually </v>

1272
01:10:24.921 --> 01:10:27.891
<v Speaker 3>brilliant books about futures which with</v>
<v Speaker 3>ais and humans in them that have really </v>

1273
01:10:28.591 --> 01:10:33.591
<v Speaker 3>interesting worlds like ian banks,</v>
<v Speaker 3>great writer his and also ask them off </v>

1274
01:10:34.320 --> 01:10:36.180
<v Speaker 3>not his robot stories,</v>
<v Speaker 3>which I've never read.</v>

1275
01:10:36.181 --> 01:10:39.210
<v Speaker 3>Actually there is that.</v>
<v Speaker 3>Things like the foundation series,</v>

1276
01:10:39.211 --> 01:10:44.211
<v Speaker 3>which is more serious scifi I think is </v>
<v Speaker 3>very interesting and it will be useful I</v>

1277
01:10:44.311 --> 01:10:46.920
<v Speaker 3>think,</v>
<v Speaker 3>to have to explore the whole spectrum of</v>

1278
01:10:46.921 --> 01:10:50.820
<v Speaker 3>possibilities with ai rather than this </v>
<v Speaker 3>sort of quite crude,</v>

1279
01:10:51.210 --> 01:10:55.440
<v Speaker 3>a narrow way of exploring it.</v>
<v Speaker 3>And I didn't particularly like westworld</v>

1280
01:10:55.441 --> 01:10:57.270
<v Speaker 3>for example.</v>
<v Speaker 3>I think it's pretty boring and obvious.</v>

1281
01:10:58.420 --> 01:11:03.420
<v Speaker 4>I think it's a good note on which to end</v>
<v Speaker 4>the scientist comes into the royal </v>

1282
01:11:03.420 --> 01:11:06.721
<v Speaker 4>academy and says that the outward needs </v>
<v Speaker 4>to be more creative and that actually </v>

1283
01:11:06.721 --> 01:11:09.301
<v Speaker 4>will accept science fiction and </v>
<v Speaker 4>hollywood films and television as part </v>

1284
01:11:09.301 --> 01:11:09.640
<v Speaker 4>of the broad visual culture.</v>
<v Speaker 4>Um,</v>

1285
01:11:09.730 --> 01:11:14.040
<v Speaker 4>we've Just finished a festival of ideas </v>
<v Speaker 4>were in the main artistic practitioners.</v>

1286
01:11:14.041 --> 01:11:16.260
<v Speaker 4>Philosophers,</v>
<v Speaker 4>theorists have come to the academy.</v>

1287
01:11:16.540 --> 01:11:20.070
<v Speaker 4>We need to expand our networks.</v>
<v Speaker 4>We need to get out more.</v>

1288
01:11:20.160 --> 01:11:25.160
<v Speaker 4>We certainly need to generate more </v>
<v Speaker 4>discussions with scientists at the </v>

1289
01:11:25.160 --> 01:11:26.580
<v Speaker 4>cutting edge of artificial intelligence,</v>
<v Speaker 4>among other things.</v>

1290
01:11:26.730 --> 01:11:31.730
<v Speaker 4>We probably need to make this place a </v>
<v Speaker 4>forum where human consciousness gets </v>

1291
01:11:31.730 --> 01:11:32.520
<v Speaker 4>debated and you'd be a great person to </v>
<v Speaker 4>do that.</v>

1292
01:11:32.521 --> 01:11:34.750
<v Speaker 4>But for this evening,</v>
<v Speaker 4>dennis hassabis,</v>

1293
01:11:35.040 --> 01:11:36.050
<v Speaker 4>thank you so much.</v>

1294
01:11:36.390 --> 01:11:40.400
<v Speaker 2>Thank you.</v>

