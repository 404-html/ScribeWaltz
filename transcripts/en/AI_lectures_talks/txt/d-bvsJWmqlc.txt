Speaker 1:          00:00:00       Our distinguished speaker this evening, Dennis Hassabis

Speaker 1:          00:00:05       cofounded, the artificial intelligence lab deep mind, and it's recognized worldwide as one of the smartest thinkers in his field. He was nicknamed the superhero of artificial intelligence by the Guardian. He's a former chess prodigy with degrees in computer science and cognitive. This is making me sweat. He's so. He's so clever. Anyway, this evening's topic, creativity, an ai draws on his eclectic experiences as an artificial intelligence researcher, neuroscientists, and video game designer to discuss the implications of cutting edge research for creativity and scientific discovery. There'll be an opportunity for questions at the end. I think, um, I think tim was probably handling that as a writer. Anyway. Without further ado, I'd love you to give a big welcome to Dennis [inaudible] office.

Speaker 2:          00:01:05       Thank you.

Speaker 3:          00:01:17       Thank you Chris for that introduction. So it's a great honor for me to be here at the academy to give this inaugural Rothschild's lecture in this wonderful and inspiring amphitheater that we're sitting in today. I always love visiting there all academy and I think it's great to have these kinds of dialogues between the sciences and the arts and I think it's actually going to become increasingly more vital as we rush headlong into the modern technological world. So today I'm going to explore a theme that's the heart of everything at the wall academy, namely creativity, and I'm going to examine it through the lens of science and also more specifically through the lens of the latest advances advances in artificial intelligence.

Speaker 3:          00:02:04       So as all of you will know, ai is the science of making machines smart. And as Chris mentioned, we found a deep mind in 2010 with the goal of trying to advance artificial intelligence. And we thought of AI and deep mind as a kind of an Apollo program. Efforts to advance ai as quickly as possible. And what we mean by that is try to bring together the world's greatest research. Scientists and engineers. Give them all the resources they require, compute power and other things in order to see how much progress we could make towards solving ai. And we had an ambitious roadmap that we're carrying out to this day.

Speaker 3:          00:02:46       The other big thing, idea behind deep mind and vision behind it was to try and organize scientific endeavor in a new way. So the way I can kind of summarize that is we try to fuse together the best from academia, blue sky thinking and ambitious thinking that you get in the best place with academia, with the best from the startup world. So the kind of focus and energy and pace that you get at the world's best startups. And we didn't see why those two types of environments had to be mutually exclusive. And we thought that we could advance science more quickly if we could combine the best from both of those worlds.

Speaker 3:          00:03:23       Now mission at deep mind, we articulated as a kind of to step mission. So step one, fundamentally solve intelligence. So we'd like to understand what intelligence is and we create it artificially. And then we believe if you do step one and a general enough way, then step two naturally follows. We should be able to use this technology to solve almost everything else. And that might sound a little bit fanciful, but I hope that by the end of the talk of hope to have convinced you to at least think that maybe this is not so far fetched after all, uh, perhaps actually it's a logical next step after we have general artificial intelligence. So more prosaically we plan to do this by building the world's first general purpose learning system.

Speaker 3:          00:04:10       So what do those words mean? General and learning? Well, let me take you through two main approaches. Two main approaches to building ai kind of falls between two schools of fault. So in the early days of artificial intelligence, the main approach was, is what's called expert systems. Sometimes it's called good old fashioned ai. These days I'd go fly or traditional Ai, you could think of it. And on the left hand side here, that's what what's involved is that we, you know, teams are programmers and researchers hardcode knowledge in the form of rules that they express in complex databases. And you can imagine this sort of series of thousands of if then rules trying to encapsulate the solution to whatever problem the program is supposed to be dealing with. Now the, the, the issue with those types of those types of systems is they can't generally deal with the unexpected and they're quite brittle because of that. So they're limited to the solutions that have been pre programmed in them. They can't think for themselves and they can't deal with anything that they weren't already prepared for. So what this means is they're limited to solutions that we can express as the programmers. So the program has themselves have to understand in new detail what the solution is in order to handcraft encodes the Hanco these knowledge systems.

Speaker 3:          00:05:34       So these expert systems were inspired by logic systems, logic theory. If we now compare that to modern day learning systems and which is sort of the advent of has been one of the reasons behind the rejuvenation and the revolution in artificial intelligence in the last decade is because these learning systems are now really starting to work and learning systems. They learned solutions from first principles, they learned directly from data and directly from experience and they learn for themselves so they're not preprogrammed with solutions. They have to figure out solutions for themselves and if we can build these systems in a gentle enough way, they can generalize to new tasks they've never seen before and perhaps even solve things that we don't know how to ourselves, and that's the really amazing promise of these systems is they could go beyond the knowledge that we have ourselves and also it's of interesting domains which I'm going to talk about later in this lecture and in the main learning systems are inspired by neuroscience and informed by neuroscience and how the brain works and that's where we get a lot of our inspiration from for the for building these types of architectures. So expert systems are inspired by logic and learning. Systems are inspired by the brain.

Speaker 3:          00:06:53       Now, still, the most famous example of an expert system was IBM's deep blue computer that beat Garry Kasparov in the late nights in the late nineties, who was at the time he was the world champion of chess, which I'm sure all of you remember now. This was obviously a very impressive technical feat. And I remember this match very well. Um, I was doing my undergraduate at Cambridge and we were sort of watching this match. Um, and as you can imagine, I was extremely interested in this from both from the chest side and the computer science side. And what I remember coming away from was actually, although it's an impressive technical feat, I came away from this match more impressed by Garry Kasparov, mind than I was by the machine because he was gary, you know, this amazing sort of creative genius, uh, probably one of the best, if not the best chess player of all time.

Speaker 3:          00:07:43       And he was able to more or less hold his own against this big brute of a machine. It was a huge super computer with obviously teams are program programmers behind it with all these rules programmed into it and not only was he able to compete on a more or less level footing with the machine here cause he can do all the other things that we can do as humans. He could speak three languages, drive a car, or ride a bike. All of these other things that we can marry out of things that we're able to do. And if you compare that to deep blue, which is obviously amazing at chess, I'm the blue, could not even play a strictly simpler game, say like noughts and crosses without being totally reprogrammed. So nothing in the knowledge base of deep blue would help it do anything else. So it was this hard coded specialized system that was only good for one thing playing chess. And it seemed to me that, you know, in terms of thinking about intelligence, something was missing here, some critical things was we're missing here. And what I believe was missing were these two notions. This notion of learning and this notion of generality and both of those things were missing from deep blue and expert systems in general.

Speaker 3:          00:08:51       And when I saw this match in after this match, one of the things I resolved to do is to one day build a general games playing machine that could play any game out of the box.

Speaker 3:          00:09:06       So let's look at what's been happening with learning systems and actually the system, the kind of framework we think about intelligence in at deep mind is a framework called reinforcement learning. And um, the idea behind reinforcement learning is that these systems, these agents, we call them the AI systems, that deep mind learn from first principles through trial and error. So that's how they build up knowledge about the world. And I'm just going to show you with the aid of a simple diagram how these systems work at very high level. So first of all, we start with the agent system. The AI system here on the left, and the agent finds itself in some kind of environment. Now the environment could be the real world, in which case the agent, you can think of it as a robot, a physical robot or the environment can be in virtual environment like a game or simulation, a computer simulation, in which case the agent would be like an Avatar in that game environment.

Speaker 3:          00:10:01       And the agent has been given a goal by the designers, uh, to, to achieve within that environment. Now, the agent only interacts with the environment in two ways. So firstly through it sensory operators and we normally use vision, but you could use other modalities like audition and touch. Um, but we use vision and you get these observations about the environment through your senses. And the observations also include rewards from the environment for doing the right things. And the first job of the agent system is to build up a model of the world out there, the environment now then how it works. So it's got to figure out a statistical model about the environment it finds itself in and, and the linkages in that environment. And once it has a model of the world which is continually updating based on your observations, then the second job of the agent system is to pick the right action to take. So at any moment in time, I'm the agent system, I have a whole array of actions available to it and it's got to select the best action that will get it closest towards achieving its goal at that moment in time. And if the model of the world, the agent has is very good, it can hypothesize in its mind what the consequences of doing certain actions will be and what the likely change in the environment will be.

Speaker 3:          00:11:25       And you can think of this system in a cycle. So the agent, once it runs out thinking time. So this is all a realtime system outputs. The best action is found so far. The action gets executed and then that may drive a new change in the environment, which then drives a new observation. And then the agent updates his model of the world and then selects a new action. And this goes on in an incremental fashion until eventually through sophisticated sort of trial error processes, the agent reaches its goal.

Speaker 3:          00:11:55       Now though I started com, looks quite simple. There's actually a huge amount of technical complexity behind this that needs to be sold. Very complex technical challenges. But we know that if we could solve all those challenges, this framework of reinforcement learning is enough to give us general intelligence and we know that because this is how the brain works. And um, in fact, in, in the, in the primate and human brain is the dopamine system and dopamine neurons, they implement a form of reinforcement learning and that actually allow us to learn using this system of reinforcement based on rewards.

Speaker 3:          00:12:32       So how did we develop this further? Well, the first work we did is partly because of my background in my previous career of designing video games and building ai systems for, for video games. Um, I realized that games would be the perfect proving ground for developing and testing ai algorithms. Normally when you work on ai, you often work with robotics. But the problem with robotics is, and we love robotics as an application area for ai, but as a development platform it's quite tricky because you end up spending most of your time on the hardware, you know, dealing with the server motors on the robots and they always break and they're quite slow and they're very expensive to use. Um, and in fact it's much more convenient to use virtual simulations like games and actually test the sophistication of your Ai Algorithms in, in those simulations.

Speaker 3:          00:13:24       So we, we started with games and in fact we started with the most iconic, sort of the first iconic game console, which was the Atari Twenty 600, which some of you may remember from the eighties and we, it was the first, we'll sort of, big console game that had a big diversity of, of games on it, very, very different sorts of games. And we tested our system, our first system back in 2013 on these Atari Games. Before we show you a video that of the, of the system working, I just want to explain to you what it is that you're going to see. So the agent system, which we call Dqn, I'm only gets the raw pixels as inputs, so I'm only gets the pixels on the screen, the kind of values of the colors of the pixels on the screen as inputs it isn't told anything else about the game. Everything else is learned from scratch. It doesn't know what he's controlling. It doesn't know how to get points. All it knows is here's a stream of numbers, 30,000 numbers per frame and the goal is to maximize the score, doesn't know anything else about what it's supposed to do, so it has to learn everything else from scratch. And then the, the final sort of challenge if you like, is this notion of generality. So we wanted one single system to be able to play all the different games out of the box.

Speaker 3:          00:14:42       So I'm going to show you my favorite video, the Atari stuff working, which is this game called breakout, which is one of those seminal games on the Atari. And in this game you control the bat to the bottom of the screen here. This pink bat that goes left and right and you've got to bounce this little pink ball here, this little pixel here on the left against this rainbow colored wall and the idea of the game is you've got to knock out all the bricks in the wall and you've got five lives and you can't allow the ball to go past the bat. Otherwise you lose a life. So I'm just gonna run the video here and you'll see the system improving over time as it gets more experienced playing more games and starts to figure out what's happening in the game.

Speaker 3:          00:15:24       So this is what it looks like after 100 games and you can see the system is starting to get the hang of what is supposed to be doing. So supposed to move the bat towards the ball, but it's missing the ball most of the time, but they're starting to get the idea that maybe it's a good idea to move the bat towards the ball. And then after 300 games. So now you can see it's about as good as any human can play this. And it almost never misses the ball anymore, even when it's coming back very fast angles. So we thought, wow, this is great. But what happens if we left it playing for another 200 games? And to our surprise, what it did is it found this optimal strategy, which was to dig a tunnel around the lefthand side and then send the ball behind the brick wall, which was sort of an amazing solution to the problem in a way.

Speaker 3:          00:16:08       And of course, um, a, a, you know, it's sort of very low risk of the ball camp go past your bat and it's very highly rewarding cause he hit many bricks with just one shot. So when we saw this, this was our first have since met since then, many Aha moments for us where we actually learned something from our own system because the program is, and the research is behind this, uh, amazing researchers, but they're not so good at playing Atari Games. So they didn't really know themselves about this tactic. Um, and obviously it's being executed with sort of incredible position from the, from the system.

Speaker 3:          00:16:45       So then we took these, these systems and the next thing we worked on and applied it to was probably our most famous program called Alphago and Alphago was our program using these reinforcement learning ideas, scaled up even further to play the ancient game of go and for those you don't know the game and I encourage you all to learn. There's an amazing game that I think you'd all like, this is what the board looks like. It's a very esoteric and artistic game and it's played on a 19 by 19 grid and you take turns black and white take turns to put stones on the vertices of the of the board, and the board initially starts empty and it fills up.

Speaker 3:          00:17:27       Now the history of go is long and storied one, it's over 3000 years old is invented in China, has played all over Asia and in fact it's considered in Asia to be more than just a game. It's something more kin to poetry or art. In fact, Confucius wrote about go as one of the four great arts that any true scholars should master along with poetry, calligraphy, music. So it's really considered to be one of these sort of profound arts, like all of these other artistic endeavors. And today it's as popular as ever. 40 million active players, 2000 professionals, and the game of go is incredibly simple. I could teach you in five minutes. There's only two rules, but the complexity that comes out of it, it was what makes it so elegant. And one measure of that complexity is the fact there are 10 to the power, 170 possible board positions.

Speaker 3:          00:18:18       So that's a one with 117 zeros after it. And that's more than there are atoms in the universe, right? So that's the level of complexity just comes out of these tools. And, um, and that's, that's what makes the game so deep and so profound. Uh, and, you know, again, sort of these ancient scholars thought about go is containing some of the mysteries of the universe in it and therefore was worthy of this incredible mouse study. And of course, that complexity and uh, and the esoteric nature of the game is one of the reasons which makes it so difficult for computers to play. And the game of go proceeds one stone at a time, when you place it down to the board fills up like this. So this is the end of the game. And the way you determine the winner is what you're trying to do with your stones is surround off a wall off empty areas of territory.

Speaker 3:          00:19:06       And then you count the number of, um, uh, the number of squares that you've surrounded compared to your opponent. And the person that surrounded the most squares wins the game. So in this case here, it's a very close game, but white winds by one point. So why is go so hard for computers to play? So after deep blue beat Garry Kasparov, the next big challenge, the sort of Mount Everest, if you like, of um, computer ai research was go and go, is much harder than chess for computers. One, because of this enormous number of possibilities that I've just talked about, this 10 to 170 possible positions. So the search base is, is much, much bigger than it is for chess, but the second and kind of even harder problem is I'm CESC per program chess engines including deep blue, rely on what's called an evaluation function. So this is one of these handcrafted rules based systems that tell the machine which side is winning in the current position and that's what allows the blue and it's a and his successes, his descendants to figure out what the right move is to play the palm go is it's such an Easter game, it's impossible to figure out what the right set of rules are and encapsulate that in a rules based system.

Speaker 3:          00:20:23       Even if you ask top go players, you know, why did they make a particular move? They'll often tell you it just felt right, but they won't actually be able to explicitly tell you themselves why they pick the move. Whereas if you ask that to a top chess player, they'll almost certainly give you a specific plan. They were thinking about, you know, I was planning a than I thought it would happen and I was going to answer. See now that plan in the end may not be very good or may fail for some reason, but they normally have an explicit plan in go. It's much more about feel much more how an artist would think, and one way to think about that is the goal is primarily game about about intuition rather than calculation, which is more dominant in a game like chess. So that's how humans players, professional players deal with this enormous complexity and this evaluation function. They rely on their instincts and their intuition.

Speaker 3:          00:21:17       So we ended up taking a totally different approach to the way that chess computers were built. And we built our Alphago with these learning systems and we actually created. We were to neural networks, which are loosely based on how the brain works to deal with these complex problems. We create a one your network called the policy network that takes in the current ball position and learns through looking at millions of different games and playing millions of different millions of games against itself and seeing and experiencing millions of games of go. Um, what sorts of moods are most likely to be played in a particular position so you can think of it taking the current board position and returning to you, like the top five most likely moves to be made. So that really narrows down this enormous search base that you need to explore. We then have to look at everything anymore, like a brute force system would have to. You can just look at them, most likely moves.

Speaker 3:          00:22:11       And then the second thing that was kind of sort of an unknown whether this could be done was we built a system that could take this to the second year network called the value net here on the right, the pink network that could take the current board position and return a value. Your probability between zero and one of who was winning. So zero would be white, 100 percent likely to win, a one would be black, 100 percent likely to win and point five would mean equal position and oversee over through a course of training of millions paying millions of games against itself, it learns to predict from any position who is going to win the game and how confident was in that prediction. And so by combining these two neural networks into one system which became the Alphago System, we're able to solve these two very difficult challenges that go presents.

Speaker 3:          00:23:02       And once we had this system, we decided to challenge one of the greatest players ever in go history, a genius South Korea and grandmaster called Lisa Doll. He's eight, one, 18, well titles and he was considered to be the greatest player of the past decade. And we had a million dollar challenge match in Seoul, South Korea, in back in 2016. And um, you know, before that match, everybody, including Lisa doll, thought it would be a whitewash whitewash to Lisa doll because until this point, no go program had ever even beat in a professional player, let alone a world champion. So, um, so all these sort of traditional techniques that were being used to make computers, even though they've been developed for a further 20 years since the deepblue match, they still hadn't got anywhere near to professional level in go.

Speaker 3:          00:23:56       So we played this match and over 200 million people across the world watched the five matches and I'm Alphago incredibly won the match for one and it was proclaimed by many experts both in ai and go to be a decade before its time, uh, and you know, it was kind of a mentor match that I think will go down in history in, in sort of ai as an ai landmark and there's often been called since then as a sort of sputnik event for ai, especially for China and Asia. But the most important thing is obviously we are, Alphago won the match and that's what we built it for. But the most interesting thing about the match was how Alphago won, um, and how it played. So I just want to explain to you a little bit about Alphago's play. Even though most of you may not know how to play.

Speaker 3:          00:24:44       Go, I think you can still appreciate what Alpha go dead. So this is a board position from game too, and this is move 37, which is probably the most famous move in the match. And um, Alphago is black hair, it says very early in the game, at least a dollar is white and Alphago plays this move here on the right hand side outlined in red, this stone here. And the key thing to notice about where this stone has been placed is that it's on the fifth line. So you can see it's on the fifth line from the right hand side of the board, the board's 19 by 19. Now in the openings, if you're professional, you almost always play on the third or fourth lines. And that's the most important lines to be, um, to be disputing early on in the game of go.

Speaker 3:          00:25:30       So a play on the fifth line this early on is kind of unthinkable. No professional player would even consider this move because it seems suboptimal and wasteful. And yet Alphago decided to play here. And then it turned out the reason the alpha go played, there was 100 moves later. These two stones here in the bottom left hand corner that I ringed in red, ended up kind of fighting on the bottom left here with the board, ended up spilling all the way into the middle of the board and moving all across the board. And then 100 years later ended up connecting up perfectly with this stone on the right hand side and move 37. And that was ended up being decisive in that battle. And at one Alphago the whole game, right? So somehow it's as if Alphago had resigned, the understood this was gonna happen and position that stone perfectly for 100 moves into the future.

Speaker 3:          00:26:21       So of course it will. The interesting thing is we can all think about what is creativity, and I'm going to come and talk a little bit more about that in the latter part of this talk, but we could all play an original movie in some sense. Even if we didn't add to play God, we call just play a random move on the board and that will be surprising in some sense, but the key thing about going is although it's considered to be an art form, it's like objective art, so a movie is only considered original and creative if it ends up being effective and you can measure the effectiveness, obviously seeing the result of the game and then starting that afterwards and seeing if that move really had a material difference to the outcome and you don't have to take my word for it. You can see this. I'm just going to play this very short, that funny clip from the live commentary stream that was going out to the millions of players. There will be watching this on youtube and I'm on the right hand side. Here is the strongest player the West has ever produced. Michael Redmond, who's nine damn professional and his reaction, he's watching the game live and commentating on it to seeing this move. Thirty seven, so hopefully you'll be your to here.

Speaker 4:          00:27:28       The Google team was talking about is this kind of a value? That's very surprising move. I thought I thought it was a mistake

Speaker 3:          00:27:45       so you can hear that he thought it was a mistake and he goes on to say later in that clip that he thought it was a misclick, so he thought our computer operator had actually clicked the wrong place on the board, the computer board, because he couldn't believe that Alphago or would play that move. Then of course I must mention that Lisa doll himself came up with his own incredible, brilliant moving game for which was the game that he won, almost move 78, which this move in the middle of this called a wedge move and that has been analyzed by all the players around the world. Both this move and move 37 in the two years hence. And they're both being proclaimed to be amazing moves. And this move here, I haven't got time to explain about it, but it triggered a misvaluation in Alpha goes networks and that's what allowed these adults to win, to win that game.

Speaker 3:          00:28:34       So for us, this was a, an amazing sort of once in a lifetime experience and it was full of drama for us and if you're interested to see a little bit more about the kind of the human emotions and the spirit of human endeavor behind this match, I'd encourage you to watch this documentary award winning documentary that done by this brilliant director, Greg Coast, which is available on Netflix and you'll see what went into the match and the nuances behind it and what the goplayers thought. But there's one thing I want to quote about from there, which is Lisa Dell's own thoughts and reflections on move 37 after the match. The director asked him what he thought about Alphago and route 37. And he said, I thought Alphago is based on probability calculation and it was merely a machine. But when I saw this move, I changed my mind.

Speaker 3:          00:29:20       Surely Alphago is creative. This move was really be creative and beautiful. So as really amazing moment and I, I kind of nearly cried when I saw that on the film. After said I didn't see him say that in the live. And I thought it was an amazing thing for him to say, and, and very, uh, deep of him to realize that. So I want to now just talk a little bit about these words I've been using and throwing around intuition and creativity. What do I mean by that? At least in this context, and I should caveat this with, and I'm sure we'll get into this in the q and a, that I'm not saying this is, encompasses all of what we think of is intuition and creativity. But I think at least want to think about operationalizing some of these definitions so we can discuss it in a scientific way.

Speaker 3:          00:30:05       So intuition then the way I think about intuition, it's really, it's implicit knowledge that we have acquired through experience, but it's knowledge that's not consciously expressible or accessible. So we can't consciously access it and we can't express it to others. And that's what, why it seems a little bit mysterious to us. This kind of implicit knowledge. Now, of course we know we have it and you can test the existence in the quality of it by testing it behaviorally. You can verify behaviorally and in a, in a game like go, it's very easy. You can give somebody a go position and ask them to come up with a move and then evaluate the quality of that move. So I think that's what it encompasses more intuition is. So what about creativity? Well, I think one way you could operationalize the definition of creativity is the ability to synthesize knowledge to in the service of producing a novel or original idea. And I think under those definitions, Africa in some sense clearly demonstrated these abilities during this match or beer. Obviously caveated by the fact that it's still a very constrained domain of a board game. But let's think about creativity sort of more generally. Here's another definition of creativity is I think I got out of the Oxford dictionary the ability to use skill and imagination to produce something new. And I think there were at least three types of creativity or three levels of creativity if you like.

Speaker 3:          00:31:30       So the first type, if you imagine that you're given three or more examples in a particular topic and let's imagine for the moment that the green dots are these examples and the white box is a particular topic or field of endeavor and you also create something new.

Speaker 3:          00:31:50       So one way you could do that is what I call interpolation and it's used often in machine learning and ai as an ai term and it's Appalachian you can think of is kind of like an averaging. So here are three trainings on Paul's, here are three examples of things we would like from this world of possibilities and you kind of find an average of those things and in some sense that orange door is new, right? It's not, it's different from the, from the, from the examples. And it's something new, but it's still sort of contained within the space. This green dot, a green line, the space that the examples cover, the next level of creativity, which is, you know, a higher level of creativity would be extrapolation. So now you know, you have those examples, but instead of just finding an average, you're extending the boundaries of what you already know. So this will be the blue dots and you can see those three blue dots as outside of the boundaries that, that sort of marked out by the training examples, the green dots.

Speaker 3:          00:32:51       And then finally there's what I would call invention or innovation, which, uh, which is here represented by the yellow door that's outside the white box completely. And this is something completely new, perhaps informed in some way by what's inside the box. Now, you know, how, uh, how we doing on the Ai Front where these levels of creativity. So let's, let's examine machine creativity and you know, neural network systems, the kind of systems I showed you. Sometimes the fashionable ones are called deep learning these days. They're pretty good interpolation, you know, they're massive statistical machines if you like. And they're very good at, uh, averaging things and spotting patterns in data. Then you have things, Alphago like systems which are getting pretty good, I would say extrapolation, you know, finding new things beyond the boundaries of even what the human designers knew about, but still within the same general context. And then you've got true invention, which I think no ai systems are anywhere close to yet, right? So this would be, instead of coming up with an original moving go, it will be inventing go right on venting chess and there's no systems that are able to do that. But we can come up with, you know, I think Alphago, uh, definitely demonstrated extrapolation. It wasn't just averaging what humans have done before or mimicking what humans have done before it was coming out with genuinely new ideas, but it can't invent something truly new.

Speaker 3:          00:34:30       So you might ask, well, what's missing? Well, although AI systems have been pretty successful so far, there's actually a whole bunch of things that we still need. I still need to crack. And things like concepts, abstract, abstract thinking, reasoning by analogy, memory systems and imagination, which as we just saw earlier, is in, in many of the definitions of creativity. And a lot of these terms of these ideas and capabilities are missing from our current ai systems and this is where the cutting edge of ai researchers at the moment and we're working variously hard on all these different topics are just mentioned and I think those things are key to this invention or this out of the box thinking because I think a lot of that comes from interdisciplinary thinking, spotting unusual connections between different subjects and doing things like imagining counterfactuals right? So imagine fantastical scenarios and a lot of our creativity I believe comes from those capabilities that we currently don't have in our AI systems.

Speaker 3:          00:35:36       So where can we look for inspiration? And I've only got time to cover one of those topics. Each one of those could be a whole lecture in itself, but I'm just going to talk about a topic that I've studied for a long time imagination, which I think is one of the main keys to creativity. And we can actually take our inspiration from the brain and especially from what I call a systems neuroscience point of view, which is a high level understanding of the brain. And interested in the algorithms and the architecture of the brain uses and I actually studied memory and imagination for my phd and I was very interesting. The question of how do we imagine what are the brain mechanisms behind imagination? And when I started my phd, one of the things I've started looking at was how memory works and I became convinced that memory was a reconstructive process so you shouldn't think of memory as a videotape.

Speaker 3:          00:36:29       It's not a perfect recording. And if we remember tomorrow we think back to this lecture or what you had at lunch today, it wouldn't be. It's not really a perfect video tape. You're actually going to reconstruct it from its components. So we reassemble our memories from our component, from components and we put them back together. So I was thinking if memory, and there's a lot of evidence that's how memory works. So I think if that home is as how memory works and you can think of memories is reconstructed process, then maybe imagination which is a constructive process. You're putting these components together in a novel way. Maybe it relies on the same brain mechanisms and the same brain areas, so we know and we've known for $50 more than 50 years. That memory is reliant on an area of the brain called the hippocampus, which is shown here in pink and is at the center of your brain.

Speaker 3:          00:37:15       And without your hippocampus, your, you will become our music. And that's what happens in terrible diseases like Alzheimer's. And so what we thought is why don't we test some patients who have damage to the hippocampus, but the rest of their brains intact on imagination tasks and see if they can imagine. And so what we did is quite a simple test, but no one had thought to do this for, you know, even though we've been researching memory for almost a hundred years now. And we thought to test these patients on a simple imagination tasks where we got them to imagine scenarios like imagine you're lying on a tropical, a white sandy beach in a beautiful tropical bay. Um, if describe everything you can see around you. So this is no problem for healthy people. And um, and we got the patients to, to describe this and we got age match than Iq match control subjects to also describe scenarios.

Speaker 3:          00:38:09       And what we found is that the patient descriptions were hugely impoverished compared to their, um, their control cohort. And you can see here on the right hand side, this is a graph of the richness measuring the richness of their descriptions. On the left hand bar is the patient's on the right hand bar is the control subjects who their imaginations are a lot richer. And what we found after further investigations is that the problem they had was they couldn't bind together disparate elements of a scene into a whole coherent hole. So we call this spacial coherence problem and that's what we think the hippocampus is actually doing for imagination. It's briny together all of these elements into a hole. And of course, you know the imagination. What does it do for us? Well, it's extremely valuable skill that humans have and allows us to more accurately predict the future by hypothesis hypothesizing about different plans you could do and seeing how they would turn out. And also, I think it's the beginning of creativity in the sense of allowing us to think of counterfactual situations related, did some brain scanning work on healthy subjects imagining in brain scanners and we found five different brain areas that were heavily involved in different aspects of imagining.

Speaker 3:          00:39:29       So most recently then we've tried to recreate this aspect of imagination, so imagining scenes in our AI systems and we've recently had some big breakthroughs on that front and we created a system called generative query network, the Gq n and what the system was able to do is amazingly kind of reconstruct a three d model of a scene just from a handful of Tuesday snapshots. So imagine giving a the AI system a few two d pictures of a seen a three d scene and it recreates the whole three d scene just from those two stills to those few today stills.

Speaker 3:          00:40:10       So then at that point to test the system, we ask the system to render the scene from a new angle. It's never, it hasn't seen before. So we can, we can ask it to render from any arbitrary new angle. So in computer graphics and in Ai Circles, this is called the inverse graphics problem. So if you imagine computer graphics, you know, you have these algorithms and they produce all these beautiful pictures that you see in games and in three d artwork and CGI and there's a mathematical sort of equations that basically cre create those three d scenes on. What this system is doing is doing the inverse of that, the reverse of that. Here's a three d scene, here's some pictures of it, now recover the genitive equations that actually generate that seat. So it's called the inverse graphics problem. Has been a longstanding problem in computer graphics.

Speaker 3:          00:41:02       So the scenes that we were able to do, um, I should, I should say are very simple scenes currently, but it's kind of amazing that this works at all. So what I'm doing, I'm just going to show you a quick video of, of this working while you're going to see is these kinds of quite toy like three d scenes with three, four, five objects in it, geometric objects in it, like, you know, spheres and hemispheres and circles and so on. And and, and boxes of different colors and different textures. And what we do is we give the system a couple of stills snapshots of the scene and then we tell it to render that from any new angle. So I'm going to show you that in this video here. So you'll see the scene on the left hand side here. So this little box world with these three objects in there and the system only gets two snapshots, view one and view two and then we ask it to render the view from this new view, view three coming from another angle and we would like to see what the image looks like from that new angle.

Speaker 3:          00:42:06       So we'll see here. So it gets given view one that gets input into the neural network and it gets processed and it gets represented inside your network.

Speaker 3:          00:42:16       Then we give it a new camera angle view too. So that's what it looks like from view to. We give that to the input and it adds that to it seemed representation. And then we ask it. We queried is why it's called a janitor query network. What would it look like from this third year and now a second year or network outputs, the new prediction of what that should look like, and then we compare it to the ground truth, what it really looks like and you can see that they almost matched perfectly and then we're able to spin round. Um, we're able to take care from any new angle, um, and then we can give it a new pictures of new rooms with different objects and you can see it can move around, zoom in, zoom out. So it's just less if it was a computer game and we'd completely built a new graphics engine to do that. So it's just recovering that from these two d stills. Now obviously we're now building up to scenes of higher complexity and eventually we would like to get to real world scenes where you can recreate a real world seen just from some two d pictures.

Speaker 3:          00:43:18       So hopefully I've given you a good flavor of what's happening in Ai. The kind of cutting edge of ai at the moment. And even though I said earlier, there are many unsolved problems too that we have to still tackle even the kinds of technologies we have today already proving very useful. So I'm just going to briefly mention a few applications. So obviously there are a whole host of commercial applications that we and others are looking at. So helping with healthcare, medical diagnostics, we have a bunch of collaborations with hospitals around the world are all sorts of different areas, especially with image recognition with as work with optimization and energy. We actually did some work for the Google data centers and we managed to say 40 percent of the power the cooling systems used by more efficiently controlling all the all the cooling equipment. I think there's lots of potential in education for personalized education using these ai systems and also with virtual assistants on your phone and making them a lot smarter. So is it being used a lot in art and design? Many will. You know about this. So especially in architecture, I believe that building the Opera House on the left hand side here was designed using machine learning as was the engine block on the bottom right here for car engine. And also there's be some interesting things in art, art transfer, transferring styles between different art styles on the same picture as well as creating art itself on the top

Speaker 5:          00:44:47       right.

Speaker 3:          00:44:49       And then for me, my particular passion is using it for science to accelerate scientific endeavor and it's been used already successfully. These kinds of AI systems I've talked about for discovering new exoplanets, it's being used to try and control the plasma and nuclear fusion reactors, design new chemical compounds, um, and detect disease and things like retina scans, so whole host of areas in both medicine and science. That I think was just the beginning of, I think we're going to see a huge revolution over the next decade.

Speaker 3:          00:45:21       So just want to kind of close now by, by just sort of going back to my initial statements about our mission statement and the way I think about that. So I think of ai as kind of like a Meta solution to a lot of the other problems and challenges we have as a society. So I think one of the big challenges we face in all sorts of domains from science also to, into even things like entertainment is information overload and system complexity. There's just so much. We're kind of bombarded both in our personal lives and our professional lives with just overwhelming amounts of information and data. So how can we make sense of all of these data streams? And then the other thing is, you know, as a society we want to kind of understand and master increasingly complex systems, some of which are boarding, bordering on chaotic systems. Things like a macroeconomics climate. All of these areas where, um, you know, these systems are incredibly complicated that we would like to try and understand.

Speaker 3:          00:46:20       And I think these are all huge challenges that we have without something like ai helping us. And for a long while sort of the, I guess the early two thousands, the first decade of this century, big data was this huge buzzword. And I think in a way big data is the problem. You can think of an ai as the answer because everyone has got tons of data now or companies do and we all have tons of data, but what you do with all of that data, how do you make sense of it? And I think the only way to do that actually at scale is to use ai and on that level, you know, in a very general way you can think of intelligence as a kind of process, almost a magical process in some ways that converts unstructured information or data into useful actionable knowledge. That's what intelligence I think is fundamentally. And Ai is a kind of way of automating that process. And as I've mentioned my personal dream and why I spent my whole career working on ai is to use and build it as a powerful tool to help the scientists and experts and clinicians accelerate desperately sort of needed scientific breakthroughs.

Speaker 5:          00:47:29       Yeah.

Speaker 3:          00:47:30       So I think it's an incredibly sort of exciting time and air holds incredible promise for the future, but you know, it must be used responsibly and safely just like any other powerful technology and we have to ensure that it's used for the benefit of everyone and the benefits accrue to everyone.

Speaker 3:          00:47:51       You know, I think of ai in it, in of itself. It's an inherently neutral technology and just like with every, any powerful technology depends how we decide as a society to deploy it and use it. And on this topic, I think a lot more research and discussions needed with a wide set of stakeholders. And as I said, as wise, I think it's very important to have dialogue like this between scientists and technologists and artists and and the social sciences. And I think that's gonna be critical if we're going to get this right for everyone. And we've started ourselves several efforts both internally at deep mind. We have an ethics and society group with policy thinkers and philosophers and ethicists, and we've also been instrumental in co founding, a pan industry group called the partnership on Ai, which includes nonprofits and academics as well as the big companies trying to think about these topics for the benefit of everyone in society.

Speaker 3:          00:48:46       So I just want to end this talk by thinking a little bit. We'll philosophy philosophically and for me as a neuroscientist, one or the other really interesting things about this journey we're on is that I believe that by trying to distill intelligence into an algorithmic constructs like we're doing with ai and then if we use that and compare that to the human brain, I think that might help us better understand what's unique about our own minds, including profound mysteries like the nature of creativity that we've been discussing, what dreams are and perhaps even the big questions like consciousness. And uh, as Richard Feynman said, is one of my all time scientific heroes. What I cannot create, I do not truly understand. And I think about that, about intelligence. And I just want to finish and give the last word to find men actually and a passage from one of his books that really inspired me when I was a child to think about science and arts and this is the way I feel and it sort of echoes my views on the topic.

Speaker 3:          00:49:43       And he said, a fireman said, well though I may not be quite as refined aesthetically as my artist friend is, he was walking through a meadow with is a good friend of his who was an artist and they were looking at a flower and they were discussing this and he said, I can appreciate the beauty of a flower. At the same time, I can see much more about the flower. I could imagine the cells in there, the complicated action inside, which also have a kind of beauty. The fact that the colors in the flower evolved in order to attract insects to pollinate isn't is very interesting. It means that these insects can see the color. All kinds of interesting questions with the science knowledge only adds to the excitement, the mystery and the all of a flower. And I think is really right about that and that's why I love by science. I cannot thank you.

Speaker 2:          00:50:31       Thank you.

Speaker 4:          00:50:43       Dummies is an academy here waiting to, um, not get at you, but I'll ask you some questions, but I just want to pick up on a couple of points. Your background was in gaming. It was competitive. You've come here, I think in the spirit of collegiality, of openness, of a dialogue. It was interesting in the, in the go game, Lisa Dol said that he felt he was there defending human intelligence. And last, I think we've gone past the stage, at least I hope we have the arts and science are pitted against each other. But do you think that element of competitiveness that humans, inevitable competitiveness is still essential in developing what it is you're trying to develop an establishing relationships and knowledge between ai and human creativity?

Speaker 3:          00:51:33       Yeah, I mean, look, it's, it's an interesting thing because competitiveness is obviously when you positively and constructively is, is, can be a very powerful driving force in a very good one for progress. In response to what Lisa Dole said, I can understand why he felt like that because he was representing the Ngo world and it was quite surprising for him. You know, he's definitely at least a decade before he was expecting that to happen. But one thing you gotta remember is that of course Alphago is a human endeavor to and there are all sorts of amazing programs and researchers on the team who were, who spent their whole lives building up their skills in the way Lisa Dole had in his art to be able to program something that the architecture behind Alphago, which then went on to learn for itself, but it, of course all the initial conditions was created by by human scientists.

Speaker 3:          00:52:22       So I think the whole thing, and if you see the film as a celebration, I think of the spirit of human endeavor from all sides, from the goplayers, the programmers, everyone kind of collaborating together, including actually the journalists and writers who were writing about the match. In fact, that might want to. Some of my favorite pieces of writing were done by a wire journalist who was writing. I thought very poetically about the whole mash as he was watching it live, so I think it's actually a wonderful celebration of human ingenuity all around and and I think you know, after the match, since then, if you taught him, he ends, he's had time to reflect on that and I think it's been amazing for the go. Well they've. They've unleashed their own creativity because not only are they playing what's called like Alphago, like moves also, many of the top go players I've spoken to has said was felt that there is free their minds from the shackles of tradition, so they're all trying to think the unthinkable now and they've come up with their own brilliant new ideas that in the thousands of years and hundreds of years past, they have been told as as junior go, players not to not to do and sort of be told off for it and now they're able to explore their own creativity

Speaker 4:          00:53:33       without peddling a stereotype, which is always a precluding to peddling a stereotype. The world loves the notion of randomness and chance. He wants to harness it and possibly for many artists here, certainly for me, and I'm not an artist. That moment where the commentator thought that a mistake had been made becomes really interesting. Less the resolution you saw the beauty, but more the fact that Beckett's idea of failing or failing, Metta lies at the heart of many people's creative vision, see it as impossible pursuit of perfection. Whereas certain scientists theaters a potential pursuit of perfection. Again, that's a stereotyping. Our predicates itself in certain areas of having no rules of wanting to break the rules, that almost becomes a tedious job, but actually at its best it offers endless possibilities. At its worst. It's an anoxic void of meaninglessness. And how does that play into your pursuit of understanding human created?

Speaker 3:          00:54:27       Well, I think that's what I was talking about or trying to talk about where the types of creativity. So I think the breaking of all the rules and breaking outside of, you know, going beyond what the rules allow you to do. That for me would be true invention, which I was kind of having as the yellow door outside the box and I think our systems currently are not capable of that, right? They're capable of of being creative, but within the rules so to speak, which is what I was sort of meaning by extrapolation, so here's the rules of go come up with some new motifs of new strategies and new tactics and new theories and it was able to do that that we're genuinely new, so I think that is a genuine form of creativity but not the highest level of creativity, which would be something like coming up with go in the first place.

Speaker 4:          00:55:11       I think there are many people in this room who would love ai to take over the role of the critic and I think the notion of criticism, how we judge things, human taste, how we decide that something is more interesting or better than another is an inexact science. It can be a poetry, but it's in an exact science. How does that play into your thinking?

Speaker 3:          00:55:32       What I think some aspects of aesthetic judgment could potentially be learned by these systems. You've given enough training data, you know, maybe there was some amazing art critic or restaurant critic that you wanted to kind of mimic the judgment of and maybe given enough data. Some of those aspects could be judged, could be sort of mimicked in some way, but I think it was still go beyond that because when I went to an art critics judging arts, one of the things that I, I regard about human created our why she's. Why I think it's higher than machine created are, is the part from the technicalities of it is that there's always the imprint of the artists through their artwork and I think some of the soul of the artist come through that art and that's what we're appreciating as human viewers of the art and where perhaps the art critic too. So I always think of someone like Van Gough, his, this sort of the tortured nature of his soul comes for almost every brush stroke he, he has. And that's one of the reasons why his art so incredible. And I think it wouldn't be the same even if a machine could match it technically, which obviously is a big f anyway in of itself because I think part of what's great about artists, the is the is the sort of the, the, the imprint of what they, of what the artist has experienced in creating the art.

Speaker 4:          00:56:50       Well, I mean there are many things that can affirm, but one of them is the affirmation that I'm here, I'm alive. What it is to be human wrestling with the human condition. Presumably a machine can't do that. But presumably you're arguing that at some stage in the not too distant future, it might be able to have a semblance of that. Or is that nonsense? What's the timeframe? I mean months, years. You'll obviously say not, but is there a sense that we're looking at something approaching this in the next decade?

Speaker 3:          00:57:16       No, I think, I mean aspects of it in the next decades. But I mean, I think this is what I mentioned at the end really about what fascinates me is both a neuroscientist and a computer scientist is that, you know, what are these aspects of the brain that, that mechanism cannot be done computationally. Are there any and if they are, what are they and what mechanisms do they use can be explained or is this something mysterious? And I'm quite open minded about that and I think what I see is part of what we're doing, which is this neuroscience inspired ai, is let's see where that takes us. And then we'll see which aspects remain that only the human brain can do. And you know, I think about that for creativity. I think about that for a dreams. I think about that for consciousness. We don't know what these things are, the nature of consciousness.

Speaker 3:          00:58:06       We don't know how they manifest themselves in, in, in the physics of our brain. There are theories, but we don't know. And I think this may be one way of, uh, of, of, of, of examining that is I'm trying to build aspects of intelligence and then seeing what was missing. And some of those things, you know, maybe impossible, although for, for the moment, um, you know, at least from a biological point of view, that doesn't seem to be anything long computable in the brain, although there's speculation about that. There's a famous mathematician called Roger Penrose who talks about quantum consciousness and he thinks there are quantum effects in the brain, in which case if he's right, then we will not be able to model those on a conventional computer. Traditional classical computer. But so far, and biologists have looked for this quite hard there, that they, no one's found any quantum effects in the brain so far.

Speaker 4:          00:59:01       I love the idea that the computer would not, it would, we'd have to do, is learn to invent, reinvent, go itself May. Maybe in the end it will reinvent. But are one of these art does, is constantly reinvents itself. You've already given us about six potential lectures. I'm not so cheeky or opportunistic to ask you to come back and give series here, but you should do really. But I'm also conscious that there are people here in the brief time we have left now, you will have questions to make questions to ask of you and I do think there should be another forum to, to, to look through the implications of much of what you said could, could ask people to ask questions rather than make long statements. I know that's difficult because there's so much that's been thrown out, but I'd love to take some questions from the floor.

Speaker 4:          00:59:44       Could you wait for the mic? There's a hand up at the back there. Thank you. Hi. Thank you. A great lecture. And following on from what you were just discussing, uh, you said at the beginning that's a reinforcement learning. We know that that model can lead to a general intelligence. And so I was wondering if, if, uh, in order to, uh, to get the general intelligence and the higher level of creativity like invention, do you think we need to, to work out consciousness and intentionality and do you agree with philosophers like John Self new say, um, that, uh, we need to understand the, the, the physical material of the brain rather than just the algorithm?

Speaker 3:          01:00:27       No, I. So I disagree with John Cell and um, I do think that you can make progress on this question without fully understanding the substrate and fat. I, I believe that intelligence will be substrate independent in the sense that we are forced to learning is the way we're going to try and build it. But there are probably other ways of building intelligence. They're more mathematical, less neuroscience based, and even the neuroscience based way like we're doing, you know, we're really looking at the systems level, the algorithmic level, not at the actual wetware itself, the exact way that neurons work and cortical columns. Other people are doing that. That's sometimes called whole brain emulation where you're effectively trying to reverse engineer the brain's precisely and implement it in the same way the brain does. And I don't believe that will be necessary for intelligence as to whether we'll need consciousness for true creativity and other things.

Speaker 3:          01:01:18       I'm not sure I, I, if I was, you know, I think there's a open scientific question and we need to get further with the research to understand that. But I would say that if I was to bet on it, um, I think it's likely that intelligence and consciousness are what's called double dissociable. So I think you'll be able to have intelligent systems that will, that we fantastically intelligent in terms of the capability but will not feel conscious in any way in the way that I do to you. You do. To me. And I also think on the other end of the spectrum, if you look at animals, for example, like our pets, like dogs and cats and so on, I think it's pretty clear they have fought some form of consciousness. You see them dreaming and, and they seem to have those kinds of traits or self awareness and other things, but obviously they're not close to human level intelligence. So it seems as though maybe the dissociable traits, but um, you know, who, who knows, maybe we'll get in 20 years time, we'll get to a point where we are okay, we're sort of stuck against the brick wall and actually the reason we can't have more intelligent systems is we now understand what this consciousness thing is.

Speaker 6:          01:02:24       Thank you for questions. Beautifully balanced systematically. Yeah.

Speaker 7:          01:02:27       Gentlemen that and then.

Speaker 3:          01:02:32       Hi, thanks for the great lecture. Um, do you think that the current speed of ai research has had a negative impact on its practices in the field and if so, what do you think can be done about it

Speaker 3:          01:02:47       tag mean negative on, on its own in terms of its applications? Yeah. No, I don't think so. I think it's mostly been positive. I would say, um, I think like with any, any hot topic and that's, I think it's a bit too hyped and I think that's caused a lot of um, you know, the sorts of bad cycles you get when, when, uh, when uh, an area gets to the top of the hype cycle. So I think there's been a lot of amazing work that's happened, but some of the promises are over promising still compared to where we are. Um, and I think that sometimes can lead to some bad silence this rushed or in some way, but I think mostly the community is actually very good. The research community around Ai and it's very open. Everyone publishes everything and I think it's pretty collegiate at the moment.

Speaker 3:          01:03:35       So I would say the research communities actually pretty solid. And I actually think in order for us to get to better practice best practices and protocols that say around how these systems are deployed, I actually think we need to get further with the systems. So we have concrete systems to experiment on and actually figure out because compete science isn't, it's not theoretical subjects in engineering discipline. So in order for us to make progress with that, I think we have to have systems that we can actually test empirically test and I think all the best science is done with empirical work in tandem with theoretical work and for us the empirical work is engineering. Yes.

Speaker 6:          01:04:20       Thank you for the lecture. I think I need an ai to help me process all the information you've just given us in the last hour. I'd like to take you back to your art and science comment at the beginning. So have you looked at using Gq n two instead of trying to recreate three dimensional computer graphics, potentially recreate architecture or environments that live longer exist, whether it's because of war or just you know, dilapidation there's, there's a lot of amazing art in the world architecture that has been lost and there are a lot of paintings and photographic representations of that. And is it something you guys had looked at in terms of trying to help us recapture some of that? Yeah,

Speaker 3:          01:05:01       we have started to look at that. So as I mentioned where we gq and we're now trying to build up to more complex scenes in and eventually we're world architecture would be a very interesting to try and like a room or in a dilapidated room in a, in a, in a, in, in a, in a structure. Another area that's been worked on a lot is what's called generative models, which gun is an example where they're trying to fill in pictures or even drop photos and things where they try to, um, you know, you can leave a missing part and it will fill it in and they're not photo realistic yet. They're not as good as the originals. You know, you would obviously spot it immediately as a generated by computer, but they're getting better all the time. And one of the issues is with architectures are anything more complex than our simple scenes is the system still don't really understand the semantics of a scene. So they don't really understand that these objects are separate and what background is and for ground and so on. And, and how physics interacts with structures. And that's the concept part I was talking about. And I think systems like gun, if they had abstractions and concepts would start being able to pass the late the world up into semantic meaning and structure, which then allow them to model much more complicated sentence. So I think that's what's holding us back right now. But eventually I would expect to be able to do those kinds of things

Speaker 8:          01:06:22       we should say the US was always harness technology and recently of painting was made by Algorithms. And all I can say is, well it might've made it into the summer exhibition. Yeah. Thank you very much for that. I just wanted to ask you a question about explainability. So you mentioned about the move the Alphago made. That was after the fact that go experts could say, oh, we know why it did that, but you could also probably imagine situations where it would be harder to understand why a machine had made a decision that it did. Um, do you think it's important to build systems that are able to explain themselves? Or do you think it's natural that we're going to kind of decouple away from machines and will kind of lose a bit of that agency?

Speaker 3:          01:07:02       No, I think it's great question. I think it's incredibly important that we have interpretability and our systems for a couple of reasons. One is it's useful to advance the science if the better you understand the current systems obviously in what are their, their limitations are, but for any, uh, once you start deploying these ai systems for any safe safety critical application, of course you would need to understand why the decision was made and I would actually advocate further and always have a human in the loop to make the final decision and think of the Ai as a tool that provides information to that ultimate human decision maker. Um, and in order to do that, we need to explain these black box systems better and I don't worry about that as much as other people. So I think we're just going through a phase at the moment where you can think of it in terms of the evolution of AI systems as in the last decade.

Speaker 3:          01:07:48       There's been a huge explosion of ai systems that are really good now and can do interesting things. Um, but that's very new. And uh, the, the challenge in that they know the last 10 years has been can we get these systems working at all? Nevermind about interpretability now we have the working, we have something to work on, reverse engineer and analyze now asks and many other teams around the world are concentrating on building analysis tools. So we're being analysis tools, visualization tools, all sorts of things. Even doing behavioral testing like more like you'd have in a psychology lab, you know, to look, think about both behaviorally testing it, looking into the architecture, measuring it, almost like a doing brain analysis like neuroscience, but on an artificial brain. And so with all those tools are very, very embryonic right now because I've only been in the last couple of years of this being started to be worked on. And I'm pretty sure I'm pretty confident that with another sort of five years of work on those kinds of tools, a lot of these systems right now that look quite black box, black box systems will become sustainable and adaptable. So, uh, you know, I think it's vital, but I think we're just a bit on the starting point of that and you know, I wouldn't worry too much about that at the moment. A lot of these systems are quite black box.

Speaker 4:          01:09:06       We've been rigorously program to stick to now we've crushed through it. Let's be knocking. Take one more question. You going to say one more question? Let's take the,

Speaker 7:          01:09:15       the woman that

Speaker 4:          01:09:17       then we can carry on over a drink. He said offering up that misty will. Okay. Thank you. Last word has always been pretty fearful of ai thing. There were presentations, things like westward and terminator, etc. And I'm very glad that you mentioned ethics. Just whAt do you think of the artworks for presentation of ai and how, how your advIse on preventing that kind of future from happening?

Speaker 3:          01:09:41       Yeah, I think the art world, it would be nice if there were, if it was a little bit more creative in some sense, right, because I think it's easy to. I mean it's obviously more dramatic to have a, you know, dystopian futures and villains and so on. It's obviously creates more excitement. Um, but obviously that's a, you know, I think it's, most of those scenarios are pure science fiction and we shouldn't worry about them too much. I think that we actually need a lot of science fiction can be very helpful in terms of lots of scientists, including myself who inspired by science fiction to make some of the things they read. Certainly for me, I read probably too much science fiction when I was young to try and make that come true and there are actually brilliant books about futures which with ais and humans in them that have really interesting worlds like ian banks, great writer his and also ask them off not his robot stories, which I've never read. Actually there is that. Things like the foundation series, which is more serious scifi I think is very interesting and it will be useful I think, to have to explore the whole spectrum of possibilities with ai rather than this sort of quite crude, a narrow way of exploring it. And I didn't particularly like westworld for example. I think it's pretty boring and obvious.

Speaker 4:          01:10:58       I think it's a good note on which to end the scientist comes into the royal academy and says that the outward needs to be more creative and that actually will accept science fiction and hollywood films and television as part of the broad visual culture. Um, we've Just finished a festival of ideas were in the main artistic practitioners. Philosophers, theorists have come to the academy. We need to expand our networks. We need to get out more. We certainly need to generate more discussions with scientists at the cutting edge of artificial intelligence, among other things. We probably need to make this place a forum where human consciousness gets debated and you'd be a great person to do that. But for this evening, dennis hassabis, thank you so much.

Speaker 2:          01:11:36       Thank you.