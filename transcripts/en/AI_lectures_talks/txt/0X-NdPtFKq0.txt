Speaker 1:          00:00:00       And welcome to the second Royal Television Society and institution of Engineering and technology public lecture. I'm Tim Davie. I'm sharing tonight and you know when we conceived of this lecture series, our aim was to hear from some of the world's finest minds who work in the spaces that bridge cutting edge science and technology with human creativity and media. The amazing response, and we were lucky to be there last year, whose those of us who saw Mike Lynch in full flow suggested we were onto something and the excitement in the room tonight speaks to the enduring appeal in my mind, a public lectures in sparking our imagination in many ways. And I really believe this. We are lucky enough to be enjoying another golden age of advancement. The demands public engagement and debate over 200 years. It was a rather precocious Humphry Davy that was wowing crowds and causing carries traffic jams with sellout lectures on the nature of human progress and scientific knowledge.

Speaker 1:          00:01:05       Noticeably as a friend of Coleridge, he was fascinated by the intersection of the subjective and the technical and the possibilities, the endless possibilities that this throws up. So tonight at this wonderful institution, we continue that tradition with our very special speaker, Dennis Hassabis, that's the best dentist, will talk for 35 minutes or so. Then we'll open up for q and a and I'll be conducting will have the lights up and were really up for a good old discussion with you guys. As you know, Dennis is acknowledged as a world leading thinker in the realm of Ai, which in recent years has become where the hottest topics dominating the media and the imagination of the public. You know my world. We run a recent and BBC survey which was looking at which jobs are at risk of computerization. We attracted two point 3 million page views. People viewing that and seeing how safe they were.

Speaker 1:          00:02:03       Liz needs little introduction, but I have to say his achievements, but even the highest achievers cv db in the shade, chess master, 30 World Games Championship winner five times running. Successful poker player, particularly impressive double first in computer science at Cambridge. A pioneering video games developer lead of numerous important pieces of research in the field of neuroscience. Notably his landmark paper on the similarities of how we shape memory and how we imagine the future was a landmark and breakthrough piece of research and then of course founder of deep mind in 2011, which was then sold to Google in 2014 with Dennis becoming vp engineering with special responsibility for ai. Deep mind has set out a goal of solving intelligence. A humble objective specifically dennis just said he is involved in building something that can expect the unexpected gracefully. I think that's probably a great brief for an audience of a public lecture. Dennis, the floor is yours.

Speaker 2:          00:03:20       Well, thanks very much tim for that very generous introduction. So it's a real pleasure to be here and I'm giving this lecture and I'm going to talk about artificial intelligence and its impact on the future. In fact, it could be the relatively near term future.

Speaker 2:          00:03:37       So Ai is really the science of making machines smart and I got into ai firstly through the medium of games and Games started for me with chess. As Tim said, I started playing chess when I was very young at the age of four and I think if you play chess seriously from such a young age and you're quite an introspective kid, which I was, then you start thinking a lot about how is it that your brain is coming up with these moves, these ideas, um, that allow you to play this game and win these games. And I started thinking a lot about this as I got into my teenage years.

Speaker 2:          00:04:16       And allied with that, um, I, uh, got into computing or actually bought my first computer, is that x spectrum here, 48 k with some winnings from a chess tournament. And uh, when I was about eight years old and I started teaching myself how to program. And I think very early on in the engineers and the audience will, I think, resonate with this. I sort of realized I'm on an intuitive level that this competed a kind of special type of machine. You know, most machines like cars and planes, they allow us to extend our physical capabilities. You know, cars allow us to move faster than we can run planes allow us to fly, um, but I think computers do that, but in the realm of our minds, um, they really extend the capabilities of the brain and this really came clear to me when I used to write my first programs and did sort of basic math calculations and other things which, um, it really struck me. You could set something running overnight and then go to sleep and then you'd wake up the next morning and your computer will solve some problem for you whilst you were asleep. So this felt like a really powerful in some ways, magical. Yeah.

Speaker 2:          00:05:23       Say My love of computers and my love of games obviously came together in a, in a kind of obvious way, uh, in the designing of video games. And actually this is one of the reasons I accepted to do this lecture is I love the idea, as tim said, of the confluence of bringing together rts and the creative arts and the iet and sort of engineering. Um, and that's why I got into commercial video games. Um, because at the time, this is sort of like the early and mid nineties and computer games are really pushing the cutting edge of engineering and even the machines that were being built to run these games. So I remember the debates in the nineties about, you know, Intel is bringing out their new pentium processes and people were sort of saying, well, how much more power do we need to run our work processes and spreadsheets and um, you know, haven't we got all the computing power we need?

Speaker 2:          00:06:15       And actually one of the answers was that, um, if we wanted more and more realistic and complex games, then we would require more and more powerful computers with larger memory and things like graphics chips. So for a long while games were actually driving the development of a cutting edge hardware. And furthermore, the games that I used to sort of design and program all involved ai as a core gameplay mechanic. So probably my best known game was called theme park and uh, which is some screenshots of it has came out in 94 and was very successful. And it was actually the first game of its type. So the idea here was that, um, you designed your own Disney world and thousands of little people would come in to your Disney world and kind of play on your rides and how enjoyable they thought your theme park was, would, um, sort of have an impact on their emotions and how happy they were.

Speaker 2:          00:07:12       And then that fed into them and economics model about how much you could charge them for the hamburgers and the balloons. So the better design your, um, thing park was, um, the more money it made, and then that allows you, of course, to expand the theme park further. So, um, this game and actually another game called Sim city with the first sort of games that had ai as a core game play component and really spawned a whole genre of management simulation games as they're called. And one of the reasons these gains are so popular is that the ai adapted to the way the player played the game. So that means that every single person who played this game had a unique experience. And, uh, people used to send in our member into magazines, gay magazines and write into us, I'm showing what's the end state they got their theme park into.

Speaker 2:          00:07:59       And there was all these amazing designs that people are created that we had no idea could be done even as the inventors of this game. Um, so that really struck a chord with me when I was around 16, 17 years old when I wrote this game. And I'm thinking about, you know, maybe if I devoted my career to ai advancing ai, um, what an incredible technology that could be. So then after having a career and getting games and running my own games companies and things, um, I then went back to academia to do a phd in neuroscience, which I felt was another piece of the puzzle that I needed before launching an effort. Like deep mind. I wanted to understand a bit more about how the brain, um, solved a tough problems like imagination and memory. And I specifically pick those topics to do my phd on because those are things that at least back into mid two thousands where were we will not very good at doing in computer algorithms. So I wanted to look at the way the brain sold. Somebody is very, very tough problems that we didn't know yet how to imbue our machines with.

Speaker 2:          00:09:04       And I'll come back to that towards the second half of my talk. So all of these different experiences then culminated in finally in setting up deep mind, uh, in 2010 and really, um, it's been a 20 year plus journey for me to get to this point, uh, and have enough of what I thought were the basic ingredients both on an algorithmic level but also in terms of the founding scientific team and making those contacts to actually put together something like the mind and, um, and plausibly go after those big emission as solving intelligence. So another way we look at, um, uh, the company is as an Apollo program for ai as sort of moonshot project that really focuses on the very ambitious longterm goals. And we've collected together a 100 more than $100, knew 150 now of the world's top research scientists in this area. So I think the mind is by far now the biggest collection of machine learning experts anywhere in the world. And another thing we're experimenting with, of course, apart from trying to build ai is actually a new ways to organize scientific endeavor. So what we've tried to do with deep mind is really combined the best form, um, silicon valley startups together with, uh, the best parts of that you find in the, in the best academic institutes like Mit, ucl, Cambridge, and so on, and see if we can infuse that into a new hybrid way of doing science, which is more productive and extremely efficient, but still allows for extreme creativity.

Speaker 2:          00:10:38       So our mission then, as Tim said, we articulate it in a kind of to step way. So firstly we talk about solving intelligence. Um, and we use the word solve, which is a kind of ambiguous word there because actually what we mean, what we're interested in is, is understanding natural intelligence. So the human mind. But also recreating that on intelligence artificially. And then step two, we want to use that technology to help us solve everything else. Now, um, you know, that might seem a little bit far fetched, possibly a little bit fanciful to some of you, um, but we really believe actually that step to naturally follows on from step one. If you can solve intelligence, and I hope by the end of this talk, uh, you know, you'll, you'll agree with this conjecture. So more prosaically, how are we going to solve intelligence? Well, what we're trying to do at deep mind is to construct the world's first general purpose learning machine. And the key aspects of this are the word general and learning. So we're at deep mind, we're only interested in algorithms that learn for themselves, so they learn automatically from raw experience or war data, so they're not preprogrammed in any way. So what we're talking about here is autonomous learning system.

Speaker 2:          00:11:58       The second thing is this idea of generality. So, um, what we're interested in is the same system. I'm actually being able to operate across a wide range of tasks and environments out of the box with no reconfiguration, so of course we have an example of such a general learning system. It's the human mind where we're able to apply our minds to almost endless number of different tasks. Now I should say most of ai today, although it's a huge buzzword right now and is very fashionable, most of it, ai is not of this type of technology, so we call most ai actually internally at deep mind narrow ai and what we mean by that is preprogrammed ai that has been built for in a bespoke way for one specific task and actually most of the Ai we interact with everyday from Siri on your phone to self driving cars is actually a of this preprogram type of Ai and what we're interested in is what we call artificial general intelligence. This idea of a general learning system

Speaker 2:          00:13:03       and perhaps still the most famous and clearest example I can give her. This is the famous deepblue match against Garry Kasparov. Of course, this was a watershed moment in ai when in the late nineties, IBM's deep blue beat Kasparov in a six game chest match. Um, but the interesting thing is I came away from that match, actually more impressed by Garry Kasparov mind than the deep blue machine because, um, you know, of course it was an impressive engineering feat, but deep blue was programmed by an amazing team of programmers along with a bunch of chess grandmasters trying to distill chest knowledge into an algorithmic sort of construct. And those programmers were directly programming in the sort of ideas and solutions into the machine. And of course, what that meant is that deep blue, although it was very good at chess, it was no use for absolutely anything else, including strictly simpler things like, for example, playing noughts and crosses which any chess grandmaster you could trivially teach them how to play noughts and crosses. But obviously deep blue, nothing that deep blue, new or in its code would help it with, um, even something strictly simple like that, let alone, um, uh, other kinds of domains like speaking languages or driving cause all these other things that of course Gary Kasparov could do effortlessly.

Speaker 2:          00:14:22       So instead of that, we think about intelligence in the framework of what's called reinforcement learning. So I'm just going to illustrate what the main basic parts of that in this little cartoon diagram because it's important for what I'm going to show next in terms of the videos of the, of the, of the algorithms working. So you start off with your agent system. I'm represented by this little humanoid character and that agent finds itself in an environment which could be virtual or real world. If it's real world, the agent probably be a robot. If it's virtual, the agent will be an Avatar and the agent has some kind of goal that has been given to, that is trying to achieve in that environment. And the agent only interacts with the environment in two ways. One is that it gets observations through it. Sensory operators, observations about the world and we mostly use vision at the moment, but we're also looking to use other sensory modalities soon.

Speaker 2:          00:15:14       And those observations are always incomplete and noisy. So you never get full information about the world, unlike say a game of chess where it's a perfect state information. You see everything that's in the game world, uh, in, in the real world. Of course, you don't get to see all the information and that one of the jobs of the agent system is to build a, as accurate a model as possible of the environment out there based solely on these noisy, incomplete observations. And the agent is doing this in real time. These, these observations are coming in every time step and it's, and the agent is continually updating its model of the world based on this new evidence that it gets. And the second job of the agent is to then pick a what action it should take, what's the best action it can take in that particular moment in time that will guess best, get it towards its goal, um, from the current situation that it finds itself in.

Speaker 2:          00:16:10       And once it's decided what the actions should be, an outpost that action action gets executed, and that then may drive a change in the environment, which will then drive a new observation. And this goes round in a, um, endless sort of cycle. Now this diagram is a very simple to sort of explain, actually hides an incredible amount of complexity. So we know that if you could solve all the problems behind the, um, the underlie this diagram, this representation, then that will be enough for true artificial intelligence. And we know that because this is the way that biological systems learn, um, including humans and most mammals. Um, and in fact in humans is the dopamine system that implements a form of reinforcement learning.

Speaker 2:          00:16:58       So we go, we went onto, um, test these kinds of systems, um, and actually we chose to test the intelligence of our systems. I'm on computer games now, a true thinking machine, uh, we believe would have to be embedded in a sensory motor data stream. Um, you can't have true intelligence and true thinking unless you have the ability to affect the world that you're in. And the ability to sense that world. And uh, and so usually the, so this is called embodied cognition and um, usually when people subscribe to this view of Ai, they normally start working on robots, will robots. I'm based in obviously in real world environments, but robots are very tricky to use. They're very expensive. They're very slow and they break down. So if you talk to anyone who's who's used or to try to develop robots, your, your hair, a lot of the work actually goes into fixing the mechanics of the robot, the motors and the sensors and so on. And actually we didn't want to be distracted by that. We wanted to focus on the intelligence algorithms themselves. So what we decided to use was video games in the first instance. And of course it's a little bit to do with my background where it came in useful here in video games, um, and use it. And we purpose the games as a platform for testing the intelligence and the capabilities of our Ai Algorithms.

Speaker 2:          00:18:24       Now Games are really good because obviously you can run them in the cloud, you can run them much faster than real time, you can run millions of experiments in parallel, um, and it's very easy to measure progress because most games fortunately have game scores, so you can see very conveniently if your algorithmic tweaks are gaining you an advantage and whether you're heading in the right direction based on the performance in those environments. And that's something that's very important, especially for a very long time mission like we have, um, and very ambitious mission is to be able to break down a, an ambitious mission into smaller chunks that are very easy to measure the progress on.

Speaker 2:          00:19:09       The other key thing about games is that obviously they were designed by other people and other other engineering teams and they weren't designed specifically for ai testing. And uh, so what that means is that you have to deal with all kinds of interesting problems that you would never have dealt with a designed yourself as an ai designer. Um, and I think that's actually makes sure that there isn't any bias in the types of problems that you apply your ai to. So one of the big problems of in ai research that has been over the last few decades is that generally speaking, is the ai designers that also designed the problems are and subconsciously whether you like it or not, you end up designing problems that you know, your air go isms are well suited to. So what we started off with was actually Atari Games from the eighties, which were really the first iconic platform that had a lot of very popular challenging games on it and we decided to start with that. And what we did is we started with an open source emulator for Atari Games and we, um, uh, a souped it up and made it more robust and made it run faster. And then we plugged it in our ai algorithms into the system.

Speaker 2:          00:20:19       Now I'm going to show you a couple of videos of the AI system working and then. But before I do that, I always wanted to explain to you what it is you're going to see. So the AI system here, I'm only gets the raw pixels as inputs, so it's almost as if we'd set up a video camera, a observing the screen, and I'm, the only information that he gets is the raw pixels so it doesn't know anything about, uh, what it's controlling. It doesn't know what the of the game is. Um, it doesn't know how to get points and all it's been told is that it needs to, it's goal is to maximize the score and everything else is learned from scratch. And then there's a sort of generality component comes in again where we require a single system to play all the different games out of the box. And there's obviously dozens and dozens of very different Atari Games.

Speaker 3:          00:21:13       Okay.

Speaker 2:          00:21:13       So the first thing you're going to show you is space invaders, probably the most iconic game that they're, you know, there's ever been. And I'm going to show you sort of two parts of this video. Um, so in the beginning, as I roll the video now you know, you'll see what the agent looks like when it first encounters this environment. Now, as controlling the rocket at the bottom of this screen, obviously it's trying actions randomly because it has no idea what it's supposed to be doing and it loses its three lives almost immediately. Now, if you leave the machine training overnight and you come back the next day, um, the, the machine now is superhuman at, at the, at the, at the game. So every single shot it, it, fires hit something, it can't be killed anymore. Um, it's, it's worked out that the pink mothership of the top of the screen is worth a lot of points that does these amazing accurate shots.

Speaker 2:          00:22:05       And you can see that the model is built of the world is, is extremely accurate. So those you play space invaders back in the eighties wall, remember that the, the, the, as there's less of them, they get faster. If you just watched the last shot, you'll see that they sort of predicted where, um, where that is going to wear that term. Space invaders going to end up and far as the shortest shots ahead of time. So I'm going to show you a second video now, which is the game of breakout. It's my favorite video where they show a few more gradations of the agent getting better and more capable. Um, so in this game, the agent is controlling the, the, the pink bat and ball. And the aim of the game is to break through this rainbow colored brick wall, brick by brick.

Speaker 2:          00:22:47       So to start off with, after 100 games, um, the, the AI system has, you know, it's not very good. You can see it's missing the ball most of the time, but you can see maybe you can convince yourself. It's starting to get the hang of the idea that it should be moving the bat towards the ball. Now, after 300 games, you can see that the, the system has now got pretty much as good as any human complainants and almost always gets the ball back even when it's coming back at very vertical angles. So we thought that was pretty cool, but we thought, well, what would happen if we left the agent running for longer and playdoh another 200 games? And then this unexpected thing happened, it discovered the optimal strategy was to dig a tunnel around the site and send the ball around the back of the wall.

Speaker 2:          00:23:30       And um, you know, it's doing that again with sort of super human accuracy in terms of the motor control then and strategy. I wonder, the funny things is, is that although the researchers on that are amazing, programmers and engineers, they're not so good at playing Atari Games so they didn't actually know about that strategy. So it's, I think, you know, an example of a system that you've created actually teaching you something which is quite an a watershed moment for us. So efficient in that work. Uh, we, this was then fully published in nature and the front cover earlier this year and we actually even released the code as well. So you can, you can have a look at that and play with that yourselves. Um, so now we're moving onto three d games, go a robot simulators and of course we are interested in robots, but as a developed as a sort of application rather than as a development platform.

Speaker 2:          00:24:27       Now I'll just show you one thing on the, a three d stuff, um, so we'll have a lot more announcements, new announcements to make her in the next year. Um, but we, we, I'll show this sort of run this little video of, um, the same agent that you saw playing the Atari Games actually now driving a racing car around the track in a three d game. So, um, again, the only inputs here are the pixels, the raw pixels and the steering wheel controls and um, it's learned just from your experience driving the car around how to drive, um, and even do things like it's overtaking the other cars that sort of 200 kilometers an hour. Um, and again, just from the raw pixel data. So we're now moving towards much more advanced three d environments where we're looking at May's problems, uh, and, uh, all kinds of, a much more complex, uh, a path finding problems.

Speaker 2:          00:25:19       Now, I spoke about neuroscience at the beginning of the talk and just want to come back and touch on that now. So we talk a lot about, um, the Ai that we build it. The mind has been neuroscience inspired and in fact, many of the other research areas that we're looking at now, we're looking to neuroscience very closely for inspiration about, um, uh, for new types of algorithms, uh, as to how the brain works. So we're looking at memory, attention, concepts, planning a navigation and imagination. Now because this is a, you know, each one of those areas we'd probably need a whole talk to, to sort of get into. So I'm just going to focus on imagination because I think that's most relevant for the audience here. Um, and it's also what I did for my phd. Now it turns out the imagination is quite dependent on an area of the brain called the hippocampus, which is actually here, this area and pink hair at the center of your brain in this, um, in this diagram of, of the human brain.

Speaker 2:          00:26:17       Now the hippocampus, it's very important, right? It's quite a small part of the brain, a small brain region, but it's very critical problem brain region and it's been known for, you know, more than 50 years now that if you damage the hippocampus, um, then you um, how you become amnesic. So it's well known that the hippocampus is vital for episodic memory. But what wasn't known was, what else was the hippocampus useful for? Um, for example, was it involved with imagination now? I suspected that it might be because when I started reading the literature on memory and hippocampus when I started my phd, I sort of came across this literature that was talking about memory as being a reconstructive process rather than like something like a video tape. So, uh, and that's actually the way that memory works when you, if you remember this lecture tomorrow, it won't, it's not kind of like a store, like a video tape somewhere in your mind.

Speaker 2:          00:27:15       Actually, you will be combining it from all sorts of components of things and experiences that you've had before. Other lectures, perhaps other visits to the British Museum as well as specific pieces of content that are to do with this evening specifically, and what your brain does in the hippocampus is always is reconstructing that, pulling all those parts together into a coherent whole, which then is recognized by the rest of your brain as a actually an episodic memory. So I was thinking, well, if memory works as a reconstructive process, then if we think about imagination as being a similar process, but in this case is a constructive process. If we think of memory as trying to put your components that you have together in a way that your brain thinks looks and judges as familiar, perhaps creativity's, that is the converse of that. You're still bringing together those components, but now you're trying to create something novel that actually your brain judges as unfamiliar.

Speaker 2:          00:28:08       Um, so I was thinking, well, if memory is heavily depend on the hippocampus, then maybe imagination is also a very heavily dependent on the same brain structure and the same processes. So the way we decided to test this was actually by getting, um, uh, going around the country to interview patients who had damage to the hippocampus, but only the hippocampus and there's very rare sorts of diseases that cause that although things like Alzheimer's actually do attack the hippocampus, but also other brain structures, but what we needed were patients that had only specific damage only to this one brain region and we tested those patients on their imaginative abilities rather than their episodic memory. And what we did is gave them fairly a kind of simple, imaginative task. We would give them a word cues like the following. Imagine you're lying on a white sandy beach in a beautiful tropical bay.

Speaker 2:          00:29:04       Describe in as much detail as you can, what you can see and hear and experience around you. And what happened was, is when we compared and broke down their descriptions, we scored it a in a very complex scoring system to break that how rich that description was. And we compared it to age and educated an ICU matched control subjects. So they were actually in every way, except obviously they had intact and healthy hipaa campuses. We found that, um, on our richness measure experiential index measure that the imagine scenes that be hippocampal patients with describing what hugely impoverished compared to the healthy controls. And you can see that in these two. Then if you can see this laser pointer in these two bar charts. So on the left hand side here is the patients, the five patients, and then here are the 10 match controls to these patients. And you can see this is the sort of richness index, if you like, of the described seeing and you can see that the patients are massively deficient compared to the, um, to compare to the controls.

Speaker 2:          00:30:14       So, um, so it seems indeed that the hippocampus is very important for imagining the future. And, uh, actually the new scientists reported on this, uh, work, uh, and it became quite a big study. Um, that was also listed in sciences or as one of the big breakthroughs with 2007. And the new sites has had quite a nice headline talking about Hipaa camp or patients being stuck in the present. So the idea was, you know, they know they can't remember the past very well and now it turns out they can't imagine the future either. So, um, but yeah, if you were to talk to them, they seem, you know, for a few minutes they would seem completely normal to you and you'd be able to converse with them completely normally because they're processing the present. I'm in the same way that a healthy person.

Speaker 3:          00:31:00       What.

Speaker 2:          00:31:02       So we then follow this up in Mri and we found out of course the hippocampus doesn't support imagination on it's own. It's part of a, it's a critical ct solar core part of a much larger brain network that includes all sorts of other brain regions from the been or to the medial frontal Cortex to the medial temporal lobe, lateral temporal cortex and parietal cortex. So all these regions reliably come on when you scan somebody in a brain scanner and you'd get them to imagine scenes. Um, and, and the, this network is the imagination network, if you like. So they're much more recently I was thinking, well, okay, so, so this is how humans imagine. Um, but um, what about animals? Can they imagine as well, for example, kind of rat imagine. Um, uh, we, you know, again, we know that rats have memory, very good memory in fact. Um, but can they do things like imagine the future?

Speaker 3:          00:31:57       Yeah.

Speaker 2:          00:31:57       So before I show you the study that we did to investigate that, I just need to take you through a couple of things about that we know about rats, um, um, and we know that rats can do. So the first thing to tell you about his place sells. Now I'm play cells are you can really think of them as the GPS coordinates in a rat's brain about where they are.

Speaker 2:          00:32:21       So if we imagine a box that a rat might be in a box. So here we're looking top down on this environment, then the rat might be roaming around this box. And uh, you know, in these experiments you record directly from the rat's brain while they're roaming around. And what you find is, is, um, cells in the hippocampus fire, I'm in specific places in the environment. So for example, a cell, a cell, a might fire only it when the rat is traversing through this particular part of the box environment. Conversely, selby be my only fire in another part of the environment. Now, the, the amazing person who discovered this, John O'keefe, who discovered these place cells in the seventies just around the corner at Ucl, won the Nobel prize for this last year. Um, and I was lucky enough to have him as my, uh, on my vibe of committee for my phd.

Speaker 2:          00:33:13       So I got to know him well and um, the entire rap literature very well. And what I started thinking about is since that discovery, a place cells, people have found that actually, um, sequences of place, cells fire in, in, in kind of sequence when a wrap moves through an environment. So for example, let's take a new environment here, a linear track. So this is like a linear box and the rats moving from, um, from left to right here. And what you find, if you record from the brains of these rats, is that place cells will fire in order a, b, c, and d, depending mimicking the way, um, and matching the way that the rat is moving through that environment. And in the nineties, other people's found that when they recorded from the brains of these rats, while they were asleep, after they had walked around and navigate it in one of these amazing like environments that the rats would replay the trajectories they'd experienced in their wake session before.

Speaker 2:          00:34:17       So you could, you could really think about this as rats dreaming, so they would replay this trajectory of Abcd, but now this would be just, um, they will be sleeping soundly and it'll be just their, their brains replaying this. And what's interesting is that the brain, so these rats actually replay these trajectories, an order of magnitude faster than they actually experienced it in real life. So if you think about dreaming as maybe helping the rats learn about the environment that they're in, then they actually, I'm learning from this much more efficiently than they can experience it when they are awake. So that's, uh, shows that rats have memory and perhaps they dream, but it's not showing that they actually imagine new experiences that they haven't experienced while they're awake. So we wanted to show that unequivocally and recently we published a study with some colleagues of mine at Ucl in ie life that I think a unequivocally shows that rats do imagine.

Speaker 2:          00:35:18       So we designed this simple but, um, I think quite elegant design to test this hypothesis out. So what we had here is a teammate is this time. So again, we're looking top down on the, on the environment, and the team is, has a barrier. So, um, and this barrier here stops the rat. The rat starts off in the stem of the teammates, um, and it stops the rat moving to the arms of the teammates, but it's safe. Lou the barrier so the rat can see past to the arms and see what's on the arms. So the rise initially in the first session running up and down the stem of the t mates. And what we do to make the rat really interested in the arms is we put some food, uh, rice pellet on one of the arms here, depicted by this yellow dot and on the right hand arm and the rack can see this when it gets to the barrier, but it can't reach the rice pellet.

Speaker 2:          00:36:15       So obviously he's very motivated to think about a to try and get the rice pellet, but it can't get past the barrier. So then after it's experienced that environment for a while, we let the rat go to sleep and that will, of course, we recording from the rat's brain while this is going on. Um, and then we wake up again and now we put it back in the environment. But this time, um, we remove that barrier. So now it's free to run around the whole teammates. So it does that happily, it moves around, uh, the, the, the stem and the arms, both the left arm and the right arm, uh, and it fully explored this whole environment. So obviously as I've just told you with the place cells, what we can do is we find that there are play cells, let's say so a and sell DDI.

Speaker 2:          00:36:59       That fire, I'm on the arm section of the maze. Now what we can do is then go back to look at the data we collected when the rat was asleep and see if the rack was imagining about those trajectories towards the rice pellet before it ever had experienced it in reality. So they forget when it was sleeping in the rat had never experienced walking on this or a that. Only seen that all. And what happens is we find our conjectures, we're sort of proven that actually you get, we find if we go back and analyze the sleep data, you get this replay or pre play if you like, of this trajectory, abcd. And what's more is this is not just random pre play. You actually get more significantly more prepared to the right hand arm then to the left handle, which is exactly what you would expect if it's behaviorally consequential.

Speaker 2:          00:37:57       Right? So you can. I mean, of course this is anthropomorphizing the rat, but you could imagine the rats really wanting to get to that rice pellet and is imagining plans of how could it get there, right? Almost imagining yourself walking to the writer Paler and then eating it. And so, and then it just dreaming about imagine experiences. Right? So, um, so, and that's really what's going on here. I think, uh, and of course we're now going to look into this further and we have a number of plans to look at a follow on studies from this, um, with more complex environments. So, you know, humans imagine rats. Imagine. So what about, um, uh, machines. So this is something that's key imagination to planning for the future, making plans, good plans about the future. So this is obviously something that we also want our machines to be able to do.

Speaker 2:          00:38:47       So, um, you know, I've been titled this slide do, do androids dream of electric sheep, which is of course is a reference to Philip K, Dick [inaudible] famous book and one of my favorite, one of my favorite films, blade runner. And um, and this is really, I'm just going to give you a very short excerpt here with this video of which is a little bit of an insight into the mind of the machine that you saw earlier playing space invaders. So I told you that one of the purposes of the agent system is to build a model of the world so they can predict the future of what's going to happen in that game world. And here, what I'm going to show in this sort of ten second video is the machine getting an initial input from space invaders like this. This is the game position and then freely imagining or dreaming about what might happen over the next 10 seconds. So you can see it's, it's dream out moving. It's, it's, uh, the rocket and it's dreaming about getting points and shooting some of the space invaders. Now it's quite fuzzy because there's uncertainty about what might happen in the world. It's all probabilistic. So, um, it's not as certain as seeing an actual screen. Um, but it's the beginnings, I think of imagination based planning.

Speaker 2:          00:39:55       Now I'm just going to end by talking a little bit about, so that's imagination. So once you start thinking, well, could machines have imagination? What about creativity? I just something I get asked about all the time and of course is very relevant to a lot of the work that people in this room do. And um, you know, I think we're a long way away from machines being truly creative, but I don't think it's impossible and I think that um, when we start to understand what this process is, this mysterious process of creativity is, um, I think it will become actually more obvious how to implement that in an algorithm. So I just want to show a couple of little hints of things that might surprise you. Um, so let's just take a picture of the British Museum, the front of this building and uh, if we then say to the machine, and this is a new type of algorithm that was actually first a very recently invented at Max Planck Institute in Germany.

Speaker 2:          00:40:50       And then we've implemented our own version of this internally. And what you can do is you can give it a autistic picture like this van Gough picture and say you wanted to, you want the, that photo redrawn in the style of Van Gough Rights and um, and actually so you ends up with outputs that I like this where you can actually, it's not ready yet to be hung at the Louvre, but you can sort of start thinking it's pretty surprising when I saw these things like how a actually coherent the output can be. And then, you know, we can look at other examples. So actually this is a concept piece of concept art for um, uh, a new google that's been built in, in Silicon Valley and we give it a syrup painting and then we ask it's output in is one of my favorite ones. And you know, producers, pretty good version of the, um, of the original, but in, in the start of syrup.

Speaker 2:          00:41:47       And this isn't true creativity, right in, in some senses is a politic because what we're doing here with deconstructing the, the, the, the features of both the original photo and the, um, the painting. And then we're swapping those features, a overwriting of the photo features with the painting features and that gives this, uh, this, these kinds of outputs. But the surprising thing here is that there isn't much sort of what you would regard as creativity here and yet you get these kind of very interesting outputs. So it may be that creativity isn't as mysterious as it seems to us when we have ultimately find out what it is

Speaker 2:          00:42:26       now I'm just going to end by talking a little bit about the bigger picture and sort of the impact that ai might have in the future. And uh, so, you know, I think some of the big problems are facing us as a society or information overload and system complexity. So, you know, everywhere we go now it daily use by inflammation. So things like, um, obviously genomics, big data in general, but in the world of TV know entertainment. I mean there's so many TV channels now and modes of watching things. How can you really find what it is that you're interested in? And personalization is one kind of technology that might help, but it doesn't really work because it's really based at the moment on quite primitive sort of wisdom of the crowds, collaborative filtering technology and that doesn't give you unique recommendations that are unique to your, what I would call long tail of interests. And then in terms of system complexity, the kinds of systems we would like to master, you know, climate disease, energy, macroeconomics, even particle physics are becoming so complex now that even teams of the, of the best and brightest human experts are having difficulty comprehending the implications are of these systems and actually making useful predictions about them.

Speaker 2:          00:43:38       So I think solving intelligence, solving ai is potentially a kind of metal solution to all these problems. If we can solve intelligence, then maybe we can use it to help us, um, as human experts, uh, get a better handle on all these other systems. And my dream really the thing I'd like to use a January ai for is to build ai scientists or to make ai assisted science possible.

Speaker 2:          00:44:02       And of course, if we have something this powerful, then obviously we need to think about the ethics of that, of the use of it. And as with all new powerful technologies. And I think ai is no different from many other technologies in the past in this regard. We have to be a very cognizant about using these technologies ethically and responsibly. And although human level Ai, I think general ai is there many decades away, I think we should start the debate now and when we, that's what we're doing, both is our own internal ethics committees, but also by supporting academic work and academic conferences on these topics. And then finally with a nod to neuroscience, I think building Ai, uh, actually in this way, this neuroscience inspired way now help us better understand the mysteries and the workings of our own minds. And I think in the future, you know, I think we're on part of the journey we're on, is that as we try to distill intelligence into an algorithmic construct, if we then compare that with the capabilities of the human mind, I think we'll better understand about what's unique and special about our own minds, like dreaming creativity and perhaps even the great consciousness question.

Speaker 2:          00:45:10       Um, and there's firemen said, one of my all time scientific heroes, what I cannot build, I do not truly understand. Thanks for listening.

Speaker 4:          00:45:24       Thank you.

Speaker 1:          00:45:30       That was brilliant. If we get the lights up, I'm going to ask one question but not hog the limelight here. And I'll hand over to the audience. We're going to have 20 minutes. So I'm having have a little pause. Have a think about what you want to ask Dennis because they're probably provoked a so much kind of thinking. One question I've got very simple one actually is. Well, I was amazed by, was that what you, what your details, your 20 year plan, you know, get your chest skills sorted, you know, in terms of those virtual environments in gaming. Then, then you needed the nude, but that was the first 20 years and you just talked about decades away because I think people are pretty obsessed with taking that raw data in building the picture of the environment where we're at Atari Games. But I knew that breakout trick, but anyway, we're Atari Games and then the other end of the spectrum is the AI scientists taking raw. What's, what. So just give us a sense in the generation you'll read what's a realistic moon landing in your term?

Speaker 2:          00:46:30       Yeah. I touched on some of those things. Um, in that neuroscience slide of the things with big things I think are important to solve that beyond like the Atari Games, of course, we're sort of on the first rung of the ladder that the Atari thing was significant because it was the first time anyone built what we call an end to end agent. So something that took data and then make decisions. And did that in one big cycle. Um, obviously I think the next big breakthroughs will be kainate really learn abstract concepts, um, and go beyond just perceptual inputs and have a wheel underlying understanding of the semantics of the world it finds itself in. So that's, I think, um, you know, for us is our big kind of thing.

Speaker 1:          00:47:09       I mean, is this going to be exponential like the way computers developed that we're gonna be in 20 years, be bowled over by the,

Speaker 2:          00:47:15       the speed of progression? I think it's hard to

Speaker 1:          00:47:17       because we've only got one of you and you're not going to be here forever. We want to know how much we can do.

Speaker 2:          00:47:23       I think it's hard to predict because, um, you know, we need at least a dozen really huge breakthroughs and uh, I think to get all that way and, and, and, and research breakthroughs are notoriously hard to putting the timescales off. So I think we'll, we'll have, you know, several very surprising things over the next few years. Um, but you know, as to how far we'll get all the way. I think it's, it's too hard to say from here, I'm being a personalized timescales for that.

Speaker 1:          00:47:47       Brilliant. I'm going to open it up because it's easy for me. I could be here all night, but why don't we start there? We'll get a mic to you. That gentleman there with me, then we'll come down to the front of how many we've got going.

Speaker 5:          00:47:59       Hmm.

Speaker 6:          00:48:03       Tim Marshall. If the squeamish, we'll just close their eyes for a second. A few weeks ago I was at a conference, uh, where a robot was performing a prostate operation a more than just performing the operation there, could actually understand the tumor and make a decision whether to proceed or not. Today we've seen in the news the challenges of providing healthcare. Uh, where do you think, what role do you think ai can play in diagnosis and treatment in health because, uh, the way we practice medicine at the moment is a 19th century paradigm. So I'd be interested in your thoughts on that.

Speaker 2:          00:48:36       Yeah, it's great. Actually, a healthcare is actually one of the main application areas we're focusing on. First, I think, um, we could probably revolutionize the sort of quality of the care and efficiency of it, um, you know, as you say, we're still using kind of 19th century methods and uh, I think, uh, having this sort of latest information available in a digestible, actionable way to surgeons and gps and so on. Um, you know, I think we'll must really help that whole, uh, you know, the whole healthcare space. So it's something we're looking to get heavily involved with in the next few years.

Speaker 5:          00:49:13       Okay.

Speaker 7:          00:49:15       Why did you decide to publish the code and were you ever worried or concerned that when the ethics that might get into the wrong hands?

Speaker 2:          00:49:23       Yeah, I mean we try to be as open as possible about what we're doing. So we generally publish. I'm almost everything that we do and where we can, we do open source things as well. So actually our neural network libraries called torch that we, um, build our algorithms on top of that. That's open source and uh, we felt and there was a demand for some of the nature of reviewers and editors that, um, you know, it'd be nice if we could release our code. So we thought about it and we decided in that case that was fine. Um, but, uh, you know, that that may not always be the case for the stuff we do a and we'll obviously have to consider that on a case by case basis, but in general where we can, we like to engage and support the general academic community and we think it's important that knowledge is shared and I think that's the way that humanity can advance as quickly as possible.

Speaker 6:          00:50:15       And the second road, you're one of the largest brains on the planet and I'm good now bought here and um, I'm gonna ask you that question, which I'm sure you're expecting Stephen Hawking

Speaker 8:          00:50:28       thing that the concern about ai that um, once you let the genie out of the bottle, um, we're all fucked. What are you doing to try? This is the regular.

Speaker 2:          00:50:47       Yes, sure. I mean, I, I've actually spoken, um, uh, I had a long chat with Stephen Hawking about this a few months ago and um, I think he was, well, he was, I think he lives very enjoyable and I think he, he, we spent hours together. We only spend half an hour, but he was, he had so many questions and I think he was quite reassured after we talked about how we will, we specifically were approaching it. Um, and I think, look, you know, there are big, big issues here, very big issues about um, autonomous learning systems. What goals should we give them? What value system should we give them? How can we make sure that, that those are exactly what we want and there are very tough pieces of research that needs to be done. Um, there hasn't been much work done in that area yet, partly because there'd be no systems to really try this out on.

Speaker 2:          00:51:34       So it's all been thought experiments and I think if you, do, you know, mostly the people thinking about this and worrying about this to that extent or not in the AI field right there. Either philosophers or there other very famous scientists or, or industrialist but not actually working on ai themselves. And if they were working, I think they would see that the problems are much more prosaic at the moment. And it's easy, I think, to get carried away with science fiction scenarios that are, you know, many decades away. My, I have confidence that, um, as we get bill more powerful systems will have much better ideas about the answers to these questions that I just talked about, value systems and so on. Uh, and um, you know, mathematical proofs of empirical work that will, um, allow us to have much better idea of how to keep these systems on the control

Speaker 8:          00:52:20       when I'm pleased to see that you've got the, um, the ethics committee that onboard and you're thinking about these issues issues, but you have taken the Yankee dollar. And I'm, I am worried about this because you are so smart and I hope that everything you do actually improves the society route kills us off.

Speaker 2:          00:52:39       Well, so do I. But uh, but, uh, um, you know, I, I think ai, you know, it could be the greatest thing for humanity and the sense of if we build it right, we'll solve all these big issues that corporate responsibility versus showing through. I think that's a big one, isn't it, in terms of where power lies in. Sure. I mean I should probably make a little bit about that. So obviously we spent a long time doing due diligence ourselves on Google. Right. And we had a lot of other options including stay independent and we decided to join forces with them partly because the people higher up at Google agreed with things like the ethics committee and thought it was a good idea that governed the use of the technology of deep mines technology. We've already out ruled out things, obvious things like military or intelligence applications.

Speaker 2:          00:53:25       Um, so, you know, the by default deep mind staff doesn't, cannot be used for those things. And then obviously we, you know, we've had our inaugural meeting of the committee ethics committee. There are very big illuminaries on that, many of whom are some of the people that you've mentioned who are worried about this stuff, not just the people who think positively about it. And a big part of that actually because you know, we are decades away, is to just start educating everyone on what the real issues are and separate sort of fact from science fiction. Um, and I think that's the first time point and then we can actually get to the hub of the really core technical difficult questions there are. And there are some, but I, I'm very confident if we apply enough brainpower onto it with enough time, uh, will solve those problems.

Speaker 6:          00:54:09       Right. You, you've been in Google now for about a year. Um, can you, can you give us a couple of examples or anecdotes about how deep mind has changed the company? I'm taking over some processes changed the way the company works your going forward and just to tag onto the ethics committee. Why haven't you publicized or published? Who's, who's on it?

Speaker 2:          00:54:34       So, um, first question is I'm almost, nothing's changed and that's the whole point of it. That was one of the main agreement. So we, we, our, our headquarters is still in the UK and tinkering around King's cross. We've built, invested in the research team there, so the whole of the minus still UK side and uh, you know, we're very, we work as a kind of semi autonomous type of unit. The plus size are the amount of compute power that we have access to, uh, has really accelerated our progress and obviously the other resources that.

Speaker 6:          00:55:04       Sorry, I meant the other way around. How is deepmind to, to Google as a come?

Speaker 2:          00:55:09       Oh, I see. Um, well, so, um, that's harder to say. I mean Google is very big, but I think that we have actually a effect to that in some senses a the way that some other parts of Google research do that work. So there's actually thousands of people in Google research and there's thousands of people working on machine learning. Um, but we were sort of have a more coherent a specific mission than the more applied machine learning against done elsewhere and google. So I think we bring, we bring together a kind of longer term research focus that, um, I think maybe google wants more of now and that requires quite different organizational structures and management processes, which, um, you know, some of, uh, some of which has been adopted over in mountain view in Silicon Valley. Now. I'm, so your second question was about the, why don't we publicize stuff?

Speaker 2:          00:55:59       Well, firstly I'm a, you know, we're very early days and uh, there's a lot of scrutiny on this and um, there's nothing at the moment, it's about simply about educating people are ever getting everyone up to speed with the issues. Um, once you start making things public, then immediately that changes, that can change the debate. And I wanted to have a period of um, sort of quiet behind the scenes, a calm, calm, collected debate before we additionally on ourselves this additional sort of public scrutiny. So at some point I think we will announce who, you know, these people are, and also a little bit about what the issues are that are being discussed. Having said that, we already do lots of public things. So that was a big conference in Puerto Rico that was talking about ai ethics and safety as another one at New York University in January that we're sponsoring and I'm keynoting and I'm on a program committee of, along with Facebook, uh, the heads of ais there and Microsoft and some of the other companies. So I think probably the next stage next year will be to create a cross industry panel, um, and bring together all the big companies and academic labs that are working on this in addition to our own internal committee with your list. Let's correct

Speaker 1:          00:57:14       for a few more. We've got about 10 minutes. So I think someone's got a mike here though and then will go up to mother. Thank you. Yes, that was a brilliant presentation. Thank you very much for that. I'm a was an engineer. I'm now a slightly aged academic. Um, we work on the general a video gaming machines, so I appreciate that very much. But when you go the next day up to imagination, then that must be so many individual random coordinates, if you like, because I think we all imagined differently, um, that you'll spend an infinite amount of time trying to analyze these to actually make machines if you're like, imagine implant fashion. So how do, how do you cope with these coordinates? You can't build it as well because a lot of the audience and for the television audience here, I can see, I suspect there was a bit of a shudder around east kidding. He's the creative, which is, yeah, that's a bit clunky. We should kind of merging the course versus when the first director, the first writer, when those, the invite the points in the environment, the choices become financial versus a space invaders. Exactly. It's like the rice on the chess board.

Speaker 2:          00:58:21       Yeah. So I think, uh, I think most people's jobs in here safe for a long time ago is quite hard. So I don't think it's going to be any directors, you know, directing something, you know, the quality of Ridley Scott or something, you know, that's probably going to be one of the, if, if ever one of the last things that that competes will be able to do. So we asked talking about very constrained things where, um, you know, that's a very difficult thing that humans of course do better than, than way better than computers is we, you know, they can have this rudimentary kind of brute force imagination. But one of the big things that humans do is they have aesthetic judgment, right? They know that I'm not, all Paul's are equal and some of them are likely to be more fruitful than others. Even if you compare chess, grandmaster playing the chess compared to a computer, they, they, you know, computer might look at millions of moves to make that one decision. Whereas a transplant not only look at a few hundred but judicial ones, and they in some sense our brains even filter out a, our low level power brain or any of the kind of moves or trajectories that are not going to yield anything useful. Um, and uh, you know, the,

Speaker 1:          00:59:28       when you do that filtrate, are you working on. Well, we are talking that filtration part of that is, is to do with how well you

Speaker 2:          00:59:34       model of the world that you're in. So if you're better at modeling the world, then what that means is you should make better predictions about what are going to be useful things to spend your compute time, uh, imagining or thinking about a and at a moment where, you know, we're still very early stages of that.

Speaker 9:          00:59:51       Sorry. Hi, David Abraham from Channel Four. Um, you touched on the challenge of, um, how many choices people have, an entertainment and something that we in our industry is spending a lot of time thinking about. Um, are you, um, working more specifically on the area of recommendation engines and are you going to be, as it were, capturing the power of that algorithm and behalf of Google?

Speaker 2:          01:00:23       Yeah, we are looking at recommendation systems and um, you know, uh, in all forms actually all sorts of forms and a, I think it's a very interesting area and it's something that our technology is quite, uh, quite sort of applicable to. Again, it's about, you know, can you model a user journeys and trajectories through things and in a way that, um, you know, then delivers much more compelling content or recommendations and I think, uh, you know, the current systems we have are not good enough. Um, and you know, we're, we're experimenting in that. Again, we don't, we're, we're quite early days with that and we're looking at that for things both internally at Google and external

Speaker 1:          01:01:02       dcx external because I think that will be deeply intriguing to a number of us in the room who are working in the media business about how to serve up stuff in a world where choices. Yeah. Exploded. And the general application of those few years know, think it'd be announcing stuff, products coming out. I think maybe it might be the wrong word, forgive my ignorance, but systems by which the likes of channel for the BBC, other broadcasts in the room, independent companies conserve their content that we think that's not far away. Yeah.

Speaker 2:          01:01:29       Yeah. I think in the next couple of years you'll start seeing under the hood a algorithms helping the, these kinds of recommendation systems and then maybe four or five years our actual hope, totally new systems that you might interact with in a different way than we do now. Personally.

Speaker 1:          01:01:44       We got, we're coming towards the last few, but we'll get through as many as I can

Speaker 9:          01:01:49       from IBM. I think it the other big investors in Ai, and I liked your comments around the big breakthroughs is probably takes more than one player to go to, is to, to the future space. Um, uh, had a couple of questions in treatment in your talk. One was go. So, so years ago, I think there was a big effort around going who was the big one that was hard for computers to solve. It might be a bit esoteric for this audience. And then the second question, just to bring this to the point, is a, for rts, how can ai be used not to supplant creativity but to enhance and support it and allow us to do more creative things as humans, not as computers.

Speaker 1:          01:02:28       Let's do a quick one on the first one because you might wanna do that afterwards. And it's really.

Speaker 2:          01:02:31       Yeah. So go, go for it. As you don't know is it is an oriental board game, which is probably the most complex game there is. This is what they play in China and Japan instead of a career instead of chest. And um, one reason it's been so hard for computers to crack is that the branching factor, the number of choices you have in each booth is the order of 100, whereas in chat is more like 20. So as you start planning that branch, in fact explode. So if you're going to do it in a brute force way, there aren't enough. I think atoms in the university describe how many go positions there are. For example, bet you're good at. Go on. I'm reasonably good at go where you will champion champion. But, but, but um, and then the second problem is that uh, in chess, because chess is a very materialistic games, so the queen is worth more than a real console.

Speaker 2:          01:03:19       It's quite easy to hand program and evaluation function to tell you whether your program is winning or losing or how well it's doing in that position. Whereas in go, all the pieces are worth the same. They're just, there's just one piece and so whether you're winning or not as much more about the overall pattern of the board. So it's a much more beautiful game in some sense, very aesthetically pleasing, but it's much harder to hand code and evaluation function. So, um, yeah, we have, we're going to have some very big announcements to make ongoing. I mean, it's sort of been the holy grail for the AI research community for the last 20 years since the blue actually be cast off. Um,

Speaker 1:          01:03:56       sorry.

Speaker 2:          01:03:58       Yeah, sure. So, uh, yeah, and then so then, then the, the, the, the last question was on a train that's really the same thing I'm thinking about in science to write and, and with doctors and with one reading as ai surfacing the right information for you in a much more digestible way so you can just leverage that for whatever it is

Speaker 1:          01:04:23       we took the recommendation area. Is there anything else in your head you might just springs to mind in terms of the creative process, the creation of media?

Speaker 2:          01:04:32       I think that's a lot tougher. So I think the recommendation is the obvious one. We are looking at things like music, which is a, a kind of more constrained domain for a computer than visuals. I mean, which is incredibly hard, right? And uh, this is a very interesting work being done in music, music composition, a music analysis, uh, which I think is pretty promising. So I would imagine that would be the next place.

Speaker 1:          01:04:54       Very good. I'm going to take three more because we're really running out of time. I'm sorry, because we could just keep going. We're not here to take you guys weren't here. Is there, and got a microphone on them because we'll just get the nice gentleman in the back. Want to have A. Because I've been very front focus that we don't want to be on the road right at the back there.

Speaker 9:          01:05:13       IBM, we've been sheep. The from the search of pain, pleasure during

Speaker 6:          01:05:18       our own cultural history and it's shaped the way that we're thinking, the way we are behaving. How can you teach a pain and pleasure to a machine?

Speaker 2:          01:05:28       Well, one question is whether we, whether we need to, but it's also, or whether we should and um, uh, but there is sort of, this speaks to this idea actually that we look at internally of intrinsic motivation. We call it. So, you know, there are emotions and other things that drive human behavior, not just external rewards. Um, so, uh, you know, and at the moment our machines don't have anything like that. But, um, maybe to do more complex tasks or you know, where the mobile working in game worlds, where there is conveniently a score most most of the time, but even if you start going to more complex games, mope all open ended things like minecraft. Now there isn't a score anymore, right? So how are you going to decide what you should do? What is, what's useful, what's good that you're making progress? And I'm talking about the agent system here. So, um, and of course that's more like the real world for us as as humans and yet somehow we have our own internal drives probably that had been evolved to that help influence our behavior. So I think it's interesting to think about. Um, and you know, we have, neuroscientists are experts in these areas who work with us as consultants and it's something I'm very fascinated by. Um, but, uh, you know, we don't have a definite answer on that yet.

Speaker 1:          01:06:41       Thank you. Two more. So we'll take the gentleman at the back of it. You almost don't want to have a question about, I got hand up the. Yes, there is rather back there. I just feel, and then we'll take the gentleman in the red as the last question. No pressure.

Speaker 6:          01:07:00       My, my question leads on quite well from the last. Actually I was thinking, have you thought about generalizing the goals? So you talked about how the, the uh, observations and you have, um, actions that you take, but presumably you define the goal. Then you tell the system how to measure its goals and if we're thinking about ai as something which is a servant to, to a human intelligence, then have you thought about ai which can derive its goals from the environment. Can, can also, and also as humans, we segment our goals. We might have life goals, but we focused on sub goals to get there. And also I'm not just know, I'm sort of imagining a human saying to a system, can you help me with this and that and the ai being able to derive its goal from the things that it hears, but also going further than that, being able to derive goals before they're specifically instructed. So, um, being able to anticipate goals that people might want that to ai. So we realize it

Speaker 1:          01:07:57       go to high school.

Speaker 2:          01:07:59       That's fine. I mean, that's very, you know, that's a great question. And actually it's a fascinating research areas. Can the machines learn their own goals? A bite through observation of, you know, learn what it is you like through observing you for example. Right? And then trying to, you know, maybe even be able to preemptively guess what is that you need before you even ask for it. Um, so I think, uh, you know, those systems are very interesting. I mean even there you will still have some kind of top level goal which is to satisfy the user, right? Although it may learn what the sub goals are and that's another very active area of research is how do you break down a large go into, into automatically into sub goals. And of course that's something our minds do effortlessly. You know, if you're going to plan to um, you know, a trip to Paris from hair, um, your brain is not going to plan over your muscle fiber movements all the way from here to Paris, right?

Speaker 2:          01:08:49       It's the yet. That's how robotics works. And it might feel like they have no defining of hierarchy, well your act, but it's actually going to do is like, you know, at high level you need to get to the Eurostar terminal and then take a train there and so on, and then only at the point where you get up off that chair, does your brain then go and unpack the muscle fiber movement of get, you know, get up off the chair and uh, and walk. So, um, whereas at the moment, because we haven't solved this problem of automatically generating subgoals I'm a robot, for example, trying to do that task, we'd have to plan over the primitive action movements all the way to Paris. And of course this is not feasible and therefore not tractable. Um, because it ends up becoming, you know, speaks to the other gentleman's question about you imagine all those paths from here or muscle muscle fiber movements. There's an infinite, there's basically an infinite number of them. So, um, so we need, that's one of the key things we need to solve is the sub goal problem.

Speaker 1:          01:09:42       The last question. Oh, sorry. Get that across.

Speaker 5:          01:09:48       Hmm.

Speaker 1:          01:09:51       Malcolm have a broadcast engineer following off from an earlier one and your list of memory, navigation, imagination, etc. You didn't have emotions and that's where we're going to be dealing with an interacting with humans. How explosive is that with Your conflicts of ethics and parameters?

Speaker 2:          01:10:08       Yeah, I mean, again, this, this, um, relates to the question identifying down here about emotions. We currently. I'm, uh, you know, there is no equivalent of that in our systems. Um, but, uh, if you think of inch in emotions, and probably this is too simplistic, but part of emotions are internal drives a give us internal drives, then that's something we do need to explore, um, and try and work out what ones might be needed and it might be we need similar ones so that these systems can empathize with humans. Um, you know, obviously there's a great channel for series. I think that people, some people in the audience with humans, which I really love and that's interesting. You know, they're trying to empathize with the humans that they serve. Alternatively, you might want to have systems that have no a very different types of drives that help them be complimentary to what humans are good at, so I could imagine we might need both types of daily,

Speaker 1:          01:11:03       so motion. Just want to fish on the using essential that you're going to have to cope with emotion as a driver of if you'd like some types of emotions, relations,

Speaker 2:          01:11:12       so there's two reasons you might want the one so that we can see these systems can empathize and work better. Hand in hand with humans. Yeah. The other thing is if they. It turns out the environments they're in, there aren't many external reward signals. They have to have some internal drive to get them going in the right direction. It was a privilege. I'm going to hand to nomi climate from the president, the iet in a second, but dennis has been one year. Thank you.

Speaker 4:          01:11:41       Thank you

Speaker 10:         01:11:53       dennis. As the president of the iet, we're absolutely delighted to have co hosted this lecture with the royal television society and delighted to have someone of your extraordinary caliber miss events like today for fill, part of the iet charitable remit, which is to inspire, inform, and influence people and I don't know about you, but you sure as hell have inspired, informed and influenced me on a topic that I believe is going to change the world. I love the idea that your ai journey started with games and the machine learning is done through play. Pretty mucH the same as it is for humans. I've enjoyed the way that you've made it all sound pretty straightforward actually from our hippocampus to imagining rats to the quest for machine creativity and it just sounded quite logical that your journey to the to the point to have your mission, which is use ai to solve everything else seems quite reasonable. Your quest for the ai scientist to really tackle some of those big important challenges. So listening to you, it all sounds incredibly real and feasible. That ai can make a positive difference to humanity and even if it's not going to be directing any movies anytime soon. So once again, please join me in thanking dennis hassabis, founder of deep mind for an absolutely fantastic.

Speaker 4:          01:13:12       Sure. Thanks and I will do.

Speaker 10:         01:13:25       I'd like to thank our feisty chair. You did an excellent job. Tyndale be the ceo of bbc worldwide. I think we've all been inspired, informed, and influenced, so it's been very nice for me to be part of this. Thank you very much for coming here. We did like to to hear that drinks are now served outside. Thank you.

Speaker 4:          01:13:41       thank you.