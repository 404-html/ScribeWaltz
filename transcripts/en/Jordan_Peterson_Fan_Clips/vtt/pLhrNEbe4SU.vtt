WEBVTT

1
00:00:00.300 --> 00:00:05.300
<v Speaker 1>Dr Peterson thank you for coming.</v>
<v Speaker 1>We appreciate it a lot.</v>

2
00:00:05.660 --> 00:00:10.660
<v Speaker 1>Uh,</v>
<v Speaker 1>I wanted to get your opinion on </v>

3
00:00:10.660 --> 00:00:11.010
<v Speaker 1>censorship that we're seeing on the web.</v>
<v Speaker 1>Uh,</v>

4
00:00:11.011 --> 00:00:13.500
<v Speaker 1>it's accelerating.</v>
<v Speaker 1>You were a very notable example.</v>

5
00:00:13.501 --> 00:00:16.500
<v Speaker 1>You were locked out of your g mail in </v>
<v Speaker 1>the interim account.</v>

6
00:00:16.690 --> 00:00:18.770
<v Speaker 1>Pardon me?</v>
<v Speaker 1>Oh yeah.</v>

7
00:00:18.780 --> 00:00:21.510
<v Speaker 1>Trump just got a deleted by an errand </v>
<v Speaker 1>person,</v>

8
00:00:21.511 --> 00:00:23.610
<v Speaker 1>you know,</v>
<v Speaker 1>now they're saying that perhaps this was</v>

9
00:00:23.611 --> 00:00:25.890
<v Speaker 1>just a contractor and,</v>
<v Speaker 1>you know,</v>

10
00:00:25.891 --> 00:00:26.960
<v Speaker 1>maybe,</v>
<v Speaker 1>uh,</v>

11
00:00:27.110 --> 00:00:32.110
<v Speaker 1>someone from twitter who's gone into </v>
<v Speaker 1>very far left direction a youtube has </v>

12
00:00:32.461 --> 00:00:34.730
<v Speaker 1>gone very far left direction.</v>
<v Speaker 1>Uh,</v>

13
00:00:34.790 --> 00:00:39.790
<v Speaker 1>I'm just wondering,</v>
<v Speaker 1>I've started an alternative to youtube </v>

14
00:00:39.790 --> 00:00:40.800
<v Speaker 1>called Pew Tube.</v>
<v Speaker 1>What kind of,</v>

15
00:00:40.880 --> 00:00:42.150
<v Speaker 1>um,</v>
<v Speaker 1>what,</v>

16
00:00:42.230 --> 00:00:46.160
<v Speaker 1>what do you see for possible solutions </v>
<v Speaker 1>and just your thoughts in general.</v>

17
00:00:47.430 --> 00:00:51.390
<v Speaker 2>Here's a crazy thought,</v>
<v Speaker 2>but I'm going to tell it to you anyways.</v>

18
00:00:51.690 --> 00:00:54.480
<v Speaker 2>So I was just reading one of Ray </v>
<v Speaker 2>Kurzweil's books,</v>

19
00:00:54.481 --> 00:00:56.130
<v Speaker 2>I think it was called how to make a </v>
<v Speaker 2>mind.</v>

20
00:00:56.190 --> 00:01:01.190
<v Speaker 2>I really liked it actually.</v>
<v Speaker 2>It helped me understand how the brain </v>

21
00:01:01.190 --> 00:01:03.660
<v Speaker 2>compresses information because the world</v>
<v Speaker 2>is really complicated,</v>

22
00:01:03.700 --> 00:01:07.380
<v Speaker 2>so you have to make a low resolution </v>
<v Speaker 2>representations of it to live in it.</v>

23
00:01:07.860 --> 00:01:12.860
<v Speaker 2>And he actually explained to me in a way</v>
<v Speaker 2>that I hadn't really understood how the </v>

24
00:01:12.860 --> 00:01:13.740
<v Speaker 2>brain might do that neurologically.</v>
<v Speaker 2>So that was cool.</v>

25
00:01:13.920 --> 00:01:18.920
<v Speaker 2>But you know,</v>
<v Speaker 2>Kurtzweil is this guy who thinks that </v>

26
00:01:18.920 --> 00:01:19.260
<v Speaker 2>he's a smart guy,</v>
<v Speaker 2>very smart guy,</v>

27
00:01:19.410 --> 00:01:24.410
<v Speaker 2>and he's invented a fair bit of high end</v>
<v Speaker 2>technical technological software and </v>

28
00:01:26.281 --> 00:01:31.281
<v Speaker 2>hardware and he's the guy that thinks </v>
<v Speaker 2>that we're heading towards the </v>

29
00:01:31.281 --> 00:01:31.500
<v Speaker 2>singularity.</v>
<v Speaker 2>And so the singularity is,</v>

30
00:01:31.730 --> 00:01:36.730
<v Speaker 2>you know,</v>
<v Speaker 2>how processing speed doubles every 18 </v>

31
00:01:36.730 --> 00:01:39.981
<v Speaker 2>months and like hard disk capacity every</v>
<v Speaker 2>year and there's a bunch of doublings </v>

32
00:01:39.981 --> 00:01:44.661
<v Speaker 2>going on,</v>
<v Speaker 2>a huge number of them and they </v>

33
00:01:44.661 --> 00:01:44.661
<v Speaker 2>accelerate exponentially.</v>

34
00:01:44.661 --> 00:01:48.570
<v Speaker 2>And so it's probably,</v>
<v Speaker 2>we're probably three years away,</v>

35
00:01:48.630 --> 00:01:53.630
<v Speaker 2>maybe even less than from building a </v>
<v Speaker 2>computer that has the capacity to make </v>

36
00:01:54.271 --> 00:01:59.271
<v Speaker 2>as many calculations as reasonable </v>
<v Speaker 2>estimates of the calculating capacity of</v>

37
00:01:59.731 --> 00:02:03.630
<v Speaker 2>the human brain are currently set out.</v>
<v Speaker 2>Eighteen months away,</v>

38
00:02:04.710 --> 00:02:06.330
<v Speaker 2>two years away,</v>
<v Speaker 2>something like that.</v>

39
00:02:08.110 --> 00:02:11.310
<v Speaker 2>And then we're 18 months away from </v>
<v Speaker 2>having one that's twice that fast.</v>

40
00:02:11.311 --> 00:02:14.190
<v Speaker 2>And then 18 months away from having one </v>
<v Speaker 2>that's twice as fast as that.</v>

41
00:02:14.191 --> 00:02:19.191
<v Speaker 2>So that's like say six years and we've </v>
<v Speaker 2>got something that's eight times as </v>

42
00:02:19.621 --> 00:02:24.621
<v Speaker 2>smart as a human being,</v>
<v Speaker 2>but there's a twist on that and this is </v>

43
00:02:24.621 --> 00:02:28.661
<v Speaker 2>Kurt swells twist,</v>
<v Speaker 2>which is as soon as you make a machine </v>

44
00:02:28.661 --> 00:02:28.661
<v Speaker 2>smart enough to make the next machine </v>
<v Speaker 2>that's smarter than it,</v>

45
00:02:28.860 --> 00:02:33.860
<v Speaker 2>which is sort of what we're doing </v>
<v Speaker 2>because computers are so fast that that </v>

46
00:02:33.871 --> 00:02:38.871
<v Speaker 2>will scale up to near infinite computing</v>
<v Speaker 2>power computing power almost </v>

47
00:02:38.871 --> 00:02:41.931
<v Speaker 2>instantaneously now me think no,</v>
<v Speaker 2>probably not.</v>

48
00:02:42.450 --> 00:02:47.450
<v Speaker 2>And Alan Gates partner has written </v>
<v Speaker 2>critiques of Kurtzweil and you know,</v>

49
00:02:48.810 --> 00:02:53.810
<v Speaker 2>you might think if something's </v>
<v Speaker 2>impossible then it won't happen even if </v>

50
00:02:53.810 --> 00:02:53.910
<v Speaker 2>you don't know why.</v>
<v Speaker 2>And there's reasons to,</v>

51
00:02:53.970 --> 00:02:58.970
<v Speaker 2>to not think that that will happen.</v>
<v Speaker 2>But Kurzweil's traced to back the of </v>

52
00:02:59.321 --> 00:03:04.321
<v Speaker 2>computing power way before the existence</v>
<v Speaker 2>of the transistor and it's been </v>

53
00:03:04.321 --> 00:03:05.830
<v Speaker 2>ridiculously stable,</v>
<v Speaker 2>crazily stable.</v>

54
00:03:06.030 --> 00:03:09.300
<v Speaker 2>So God only knows what we're coming up </v>
<v Speaker 2>with here.</v>

55
00:03:10.020 --> 00:03:15.020
<v Speaker 2>You know,</v>
<v Speaker 2>and you don't know what something have </v>

56
00:03:15.020 --> 00:03:15.020
<v Speaker 2>infinite computing power.</v>
<v Speaker 2>It might be like,</v>

57
00:03:15.020 --> 00:03:19.600
<v Speaker 2>like you seriously don't know.</v>
<v Speaker 2>And there are serious people who are </v>

58
00:03:19.600 --> 00:03:19.840
<v Speaker 2>very,</v>
<v Speaker 2>very,</v>

59
00:03:19.841 --> 00:03:21.850
<v Speaker 2>very worried about that.</v>
<v Speaker 2>They're very worried,</v>

60
00:03:21.851 --> 00:03:26.851
<v Speaker 2>for example,</v>
<v Speaker 2>that companies like facebook and Google </v>

61
00:03:26.851 --> 00:03:29.521
<v Speaker 2>will manage that first and you know,</v>
<v Speaker 2>those companies are already making </v>

62
00:03:29.521 --> 00:03:32.560
<v Speaker 2>censorship,</v>
<v Speaker 2>ai bots and that's what that smart.</v>

63
00:03:32.590 --> 00:03:35.350
<v Speaker 2>It's sorta like making really fast </v>
<v Speaker 2>robots that can shoot people.</v>

64
00:03:35.351 --> 00:03:39.190
<v Speaker 2>It's not that smart and we're doing that</v>
<v Speaker 2>to very rapidly and you know,</v>

65
00:03:39.191 --> 00:03:41.670
<v Speaker 2>I know some guys who work in advanced </v>
<v Speaker 2>Ai,</v>

66
00:03:41.940 --> 00:03:44.680
<v Speaker 2>you know how you look,</v>
<v Speaker 2>you watch the term terminator movies and</v>

67
00:03:44.681 --> 00:03:46.990
<v Speaker 2>you see the robots that miss when they </v>
<v Speaker 2>shoot at you,</v>

68
00:03:47.470 --> 00:03:52.470
<v Speaker 2>like they're not very bright because the</v>
<v Speaker 2>bright ones not only shoot at where you </v>

69
00:03:52.470 --> 00:03:56.431
<v Speaker 2>are,</v>
<v Speaker 2>but they estimate where you're going to </v>

70
00:03:56.431 --> 00:03:58.021
<v Speaker 2>be when you make your escape moves and </v>
<v Speaker 2>they shoot their simultaneously and </v>

71
00:03:58.021 --> 00:03:58.021
<v Speaker 2>their death rate is 100 percent.</v>

72
00:03:58.620 --> 00:04:02.880
<v Speaker 2>And so there's no war against the </v>
<v Speaker 2>robots.</v>

73
00:04:02.881 --> 00:04:04.170
<v Speaker 2>I mean,</v>
<v Speaker 2>when those things get going,</v>

74
00:04:04.171 --> 00:04:09.171
<v Speaker 2>they're going to be so much faster than </v>
<v Speaker 2>us that will look like we're moving </v>

75
00:04:09.171 --> 00:04:09.171
<v Speaker 2>through molasses to them.</v>

76
00:04:09.171 --> 00:04:09.600
<v Speaker 3>So</v>

77
00:04:13.500 --> 00:04:18.500
<v Speaker 2>you know,</v>
<v Speaker 2>so maybe what we're deciding now with </v>

78
00:04:18.500 --> 00:04:20.481
<v Speaker 2>all of our individual decisions about </v>
<v Speaker 2>censorship and the way that we're going </v>

79
00:04:20.481 --> 00:04:23.321
<v Speaker 2>to construct the world and all that is </v>
<v Speaker 2>exactly what kind of super intelligence </v>

80
00:04:23.321 --> 00:04:25.710
<v Speaker 2>we're going to bring into being.</v>
<v Speaker 2>And I would suggest that we try to bring</v>

81
00:04:25.711 --> 00:04:29.340
<v Speaker 2>one in that's good and moral rather than</v>
<v Speaker 2>one that's evil and demonic.</v>

82
00:04:31.050 --> 00:04:35.880
<v Speaker 2>Right?</v>
<v Speaker 2>So what can we do about that?</v>

83
00:04:39.900 --> 00:04:40.350
<v Speaker 3>The.</v>

84
00:04:40.680 --> 00:04:45.680
<v Speaker 2>There's only one answer to that.</v>
<v Speaker 2>As far as I know that that works is gay </v>

85
00:04:45.680 --> 00:04:49.671
<v Speaker 2>rock together.</v>
<v Speaker 2>You're going to be the person who's </v>

86
00:04:49.671 --> 00:04:49.830
<v Speaker 2>working in Ai,</v>
<v Speaker 2>right?</v>

87
00:04:50.520 --> 00:04:55.520
<v Speaker 2>I know some of these people,</v>
<v Speaker 2>they better be good people because </v>

88
00:04:55.520 --> 00:04:56.550
<v Speaker 2>they're going to build whatever they're </v>
<v Speaker 2>like into their machines.</v>

89
00:04:57.420 --> 00:05:02.420
<v Speaker 2>They better have their head screwed on </v>
<v Speaker 2>straight because they're going to get </v>

90
00:05:02.420 --> 00:05:05.421
<v Speaker 2>amplified like mad.</v>
<v Speaker 2>And I don't like what's happening with </v>

91
00:05:05.421 --> 00:05:08.841
<v Speaker 2>Google and facebook and youtube.</v>
<v Speaker 2>They're building censorship bots </v>

92
00:05:08.841 --> 00:05:09.760
<v Speaker 2>predicated on a certain kind of </v>
<v Speaker 2>ideology.</v>

93
00:05:09.790 --> 00:05:13.950
<v Speaker 2>The ideology that we outlined today.</v>
<v Speaker 2>It's a very bad idea.</v>

94
00:05:19.180 --> 00:05:22.790
<v Speaker 2>Hopefully good people will stop that.</v>
<v Speaker 2>So then that.</v>

95
00:05:22.870 --> 00:05:26.920
<v Speaker 2>What that means is that your moral </v>
<v Speaker 2>obligation is to be good and the way you</v>

96
00:05:26.921 --> 00:05:31.921
<v Speaker 2>do that is first by stopping being bad </v>
<v Speaker 2>and everyone can do that a little bit.</v>

97
00:05:33.280 --> 00:05:38.280
<v Speaker 2>So I hope that's what everyone does </v>
<v Speaker 2>because the consequences of not doing it</v>

98
00:05:38.710 --> 00:05:40.960
<v Speaker 2>are not going to be pleasant.</v>
<v Speaker 2>They never are.</v>

99
00:05:42.580 --> 00:05:45.580
<v Speaker 2>Thank you.</v>
<v Speaker 2>Hi,</v>

100
00:05:45.990 --> 00:05:48.220
<v Speaker 2>this question is about your biblical </v>
<v Speaker 2>lecture series.</v>

101
00:05:48.970 --> 00:05:53.970
<v Speaker 2>Um,</v>
<v Speaker 2>I like that one because it's about </v>

102
00:05:53.970 --> 00:05:56.501
<v Speaker 2>genesis,</v>
<v Speaker 2>which is usually ignored as being where </v>

103
00:05:56.501 --> 00:05:58.490
<v Speaker 2>this post enlightenment society.</v>
<v Speaker 2>We need these ancient creation myths.</v>

104
00:05:59.030 --> 00:06:04.030
<v Speaker 2>And also I thought revelations kind of </v>
<v Speaker 2>gets the same treatment as being </v>

105
00:06:04.030 --> 00:06:07.760
<v Speaker 2>dismissed because it's the crazy </v>
<v Speaker 2>hallucinogenic trip trip,</v>

106
00:06:08.280 --> 00:06:10.700
<v Speaker 2>some isolated madman in the middle of </v>
<v Speaker 2>the Mediterranean.</v>

107
00:06:11.360 --> 00:06:13.520
<v Speaker 2>So I was wondering if after you're done </v>
<v Speaker 2>with genesis,</v>

108
00:06:13.521 --> 00:06:15.440
<v Speaker 2>if you were thinking about doing </v>
<v Speaker 2>revelation's,</v>

109
00:06:15.740 --> 00:06:19.670
<v Speaker 2>not without traversing the Geo geography</v>
<v Speaker 2>in between.</v>

110
00:06:20.150 --> 00:06:21.710
<v Speaker 2>Okay.</v>
<v Speaker 2>Yeah.</v>

111
00:06:21.711 --> 00:06:24.890
<v Speaker 2>I want to walk through the whole thing </v>
<v Speaker 2>if I can do that before they expire.</v>

112
00:06:27.290 --> 00:06:31.220
<v Speaker 2>So I mean I've read it and thought about</v>
<v Speaker 2>it and it like,</v>

113
00:06:31.370 --> 00:06:36.370
<v Speaker 2>it's such a strange book,</v>
<v Speaker 2>a because it's really big among the </v>

114
00:06:36.370 --> 00:06:37.580
<v Speaker 2>evangelical Republican types.</v>
<v Speaker 2>And you'd think really,</v>

115
00:06:38.210 --> 00:06:40.240
<v Speaker 2>really,</v>
<v Speaker 2>that's the book that's.</v>

116
00:06:40.300 --> 00:06:42.380
<v Speaker 2>But you're relying.</v>
<v Speaker 2>Have you read it?</v>

117
00:06:43.100 --> 00:06:43.910
<v Speaker 2>It's,</v>
<v Speaker 2>it's,</v>

118
00:06:44.380 --> 00:06:47.270
<v Speaker 2>it's,</v>
<v Speaker 2>it's a crazy hallucinogenic trip.</v>

119
00:06:47.271 --> 00:06:49.070
<v Speaker 2>That's what revelation is.</v>
<v Speaker 2>Now.</v>

120
00:06:49.130 --> 00:06:54.130
<v Speaker 2>That's not to play it down because God </v>
<v Speaker 2>only knows about crazy hallucinogenic </v>

121
00:06:55.161 --> 00:06:57.080
<v Speaker 2>trips,</v>
<v Speaker 2>that's for sure.</v>

122
00:06:57.170 --> 00:06:59.840
<v Speaker 2>I mean there's,</v>
<v Speaker 2>there's accruing evidence.</v>

123
00:06:59.841 --> 00:07:04.841
<v Speaker 2>I would say that a tremendous amount of </v>
<v Speaker 2>the religious orientation of human </v>

124
00:07:04.841 --> 00:07:06.770
<v Speaker 2>beings,</v>
<v Speaker 2>deep mythological,</v>

125
00:07:06.771 --> 00:07:11.771
<v Speaker 2>symbolic orientation is in no small part</v>
<v Speaker 2>a consequence of humanities </v>

126
00:07:11.771 --> 00:07:13.400
<v Speaker 2>experimentation with psychedelics </v>
<v Speaker 2>substances.</v>

127
00:07:13.910 --> 00:07:18.910
<v Speaker 2>I think that's,</v>
<v Speaker 2>that the evidence for that I think has </v>

128
00:07:18.910 --> 00:07:21.521
<v Speaker 2>become virtually an overwhelming.</v>
<v Speaker 2>So anyways,</v>

129
00:07:22.521 --> 00:07:24.130
<v Speaker 2>I will get there.</v>
<v Speaker 2>Maybe.</v>

130
00:07:24.290 --> 00:07:27.740
<v Speaker 2>Probably not because at the rate I'm </v>
<v Speaker 2>going through the first stories,</v>

131
00:07:27.741 --> 00:07:30.740
<v Speaker 2>it'll take me forever to get there,</v>
<v Speaker 2>but that's okay.</v>

132
00:07:31.190 --> 00:07:32.000
<v Speaker 2>So.</v>
<v Speaker 2>All right,</v>

133
00:07:32.210 --> 00:07:32.740
<v Speaker 2>thank you.</v>
<v Speaker 2>Yep.</v>

