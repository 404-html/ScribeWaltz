WEBVTT

1
00:00:01.810 --> 00:00:05.410
Let's talk about just briefly about the PBR t or he touched her.

2
00:00:07.270 --> 00:00:12.100
Pbr t is not exactly the renderer that we are going to use.

3
00:00:12.101 --> 00:00:16.840
We're going to use luxe render but like render was built upon PBR t and

4
00:00:16.841 --> 00:00:21.841
therefore the basic structure you mean completely intact and this is a really

5
00:00:22.511 --> 00:00:27.511
good architecture that you would see that many of the rendering engines out

6
00:00:28.391 --> 00:00:31.270
there,
global illumination rendering engines out there use,

7
00:00:31.360 --> 00:00:35.740
most of them use the very same architecture.
So we have a main sampler,

8
00:00:35.930 --> 00:00:40.930
a random test that asks the sampler to provide random samples.

9
00:00:40.991 --> 00:00:44.110
So the Sampler,
you can imagine as a random number generator,

10
00:00:44.111 --> 00:00:48.370
we need a lot of different random members because the pixel that we are sampling

11
00:00:48.400 --> 00:00:52.390
some techniques choose it deterministically going from Pixel to pixel.

12
00:00:52.630 --> 00:00:54.640
Some techniques take big those randomly,

13
00:00:57.540 --> 00:00:58.330
<v 0>I mean</v>

14
00:00:58.330 --> 00:01:02.650
<v 1>which Pixel we choose to be sampled is usually deterministic,</v>

15
00:01:02.680 --> 00:01:06.760
but the displacement because we would be sampling the pixels.

16
00:01:07.400 --> 00:01:07.770
<v 0>Okay,</v>

17
00:01:07.770 --> 00:01:11.820
<v 1>not in,
not only in the mid point,
like recursive for each facing,
but you,</v>

18
00:01:11.970 --> 00:01:16.560
you would take completely random sample from nearby and you filtering to sum

19
00:01:16.561 --> 00:01:19.920
them up in a meaningful way.
Now this requires random numbers.

20
00:01:19.980 --> 00:01:24.540
They come from the sampler.
You would also send outgoing race in the hemisphere,

21
00:01:24.550 --> 00:01:29.490
have different objects.
You also need random numbers for this.
So in this sample,

22
00:01:29.520 --> 00:01:34.520
these random numbers arrive and this sample you would send to the camera

23
00:01:36.770 --> 00:01:39.050
and the camera would give back to you array.

24
00:01:39.740 --> 00:01:41.930
So you tell the camera,

25
00:01:41.931 --> 00:01:46.931
please give me a rate that points to this pixel and this camera would give you

26
00:01:47.781 --> 00:01:52.250
back array,
which starts from the camera starting point in points.
Exactly there.

27
00:01:52.520 --> 00:01:56.870
Now all you need to do is gift this rate to the integrator and the integrator

28
00:01:56.871 --> 00:02:00.650
will tell you how much radiant is coming along district.

29
00:02:02.470 --> 00:02:07.150
And what you can do after that is right into a film.
And

30
00:02:07.720 --> 00:02:08.340
<v 0>okay,</v>

31
00:02:08.340 --> 00:02:12.000
<v 1>this is not necessarily trivial because for instance,</v>

32
00:02:12.300 --> 00:02:17.300
you could just simply write it to a ppm or a PNG file and be done with it.

33
00:02:19.240 --> 00:02:19.770
<v 0>Okay.</v>

34
00:02:19.770 --> 00:02:20.590
<v 1>In contrast,</v>

35
00:02:20.590 --> 00:02:25.590
what [inaudible] does is it has a film class and what you can do is that you can

36
00:02:26.131 --> 00:02:28.620
save different,
for instance,

37
00:02:28.621 --> 00:02:31.440
different contributions in different buffers.

38
00:02:31.650 --> 00:02:33.270
So what you could do is for instance,

39
00:02:33.271 --> 00:02:36.840
separate direct and indirect illumination into different fields,

40
00:02:36.870 --> 00:02:40.140
different images.
And then you can Indian sometime up.

41
00:02:40.380 --> 00:02:43.920
But maybe you could say that I don't need costings on this image and then you

42
00:02:43.921 --> 00:02:48.570
would just pop that image so you can do tricky things if you have a correctly

43
00:02:48.571 --> 00:02:49.770
implemented from class.

44
00:02:50.790 --> 00:02:51.140
<v 0>Okay.</v>

45
00:02:51.140 --> 00:02:53.870
<v 1>Okay.
So Lux wonder,
just what I have been talking about,</v>

46
00:02:53.871 --> 00:02:56.750
it's built upon Pvr t and uses the very same architecture.

47
00:02:57.830 --> 00:02:59.000
This is how it looks.

48
00:02:59.170 --> 00:03:04.170
So it has a graphical user interface and you can also manipulate different tone,

49
00:03:06.641 --> 00:03:08.120
lacking algorithms in there,

50
00:03:08.140 --> 00:03:11.980
different denoising image denoising algorithms in there and you can even

51
00:03:12.190 --> 00:03:16.960
manipulate light groups.
This is another tricky thing with the film class.

52
00:03:17.050 --> 00:03:19.270
Basically what this means is that

53
00:03:21.200 --> 00:03:22.033
<v 0>okay,</v>

54
00:03:22.370 --> 00:03:26.780
<v 1>you saved the contributions of different light sources into different films by</v>

55
00:03:26.781 --> 00:03:31.160
themes.
You can imagine
image files.

56
00:03:31.610 --> 00:03:35.900
So every single light source has a different PNG file if you will.

57
00:03:36.380 --> 00:03:41.060
And they are saved into their,
and the final image would come up as a,

58
00:03:41.061 --> 00:03:44.540
some,
uh,
some of these individual films.

59
00:03:45.080 --> 00:03:49.430
But you could say that one of the light sources is a bit too bright.

60
00:03:50.360 --> 00:03:51.560
I would like to tone it down,

61
00:03:51.590 --> 00:03:55.790
but if you want to tone it down then you would have to render your image because

62
00:03:55.791 --> 00:03:58.310
you changed the physical properties of what's going on.

63
00:03:59.090 --> 00:04:04.070
Now you can do this if you have this light groups option because they are stored

64
00:04:04.071 --> 00:04:05.390
into individual buffers,

65
00:04:05.391 --> 00:04:10.391
so you can just dim one of these images and just add them up together and then

66
00:04:10.851 --> 00:04:15.800
you would have the effect of that light source a bit dimmer.

67
00:04:16.550 --> 00:04:17.630
You can,
for instance,

68
00:04:17.631 --> 00:04:21.590
completely turn off sunlight or television that you don't,

69
00:04:22.010 --> 00:04:25.670
that you don't want to use in the scene.
It,
it sounded like a good idea,

70
00:04:25.671 --> 00:04:28.790
but it wasn't.
You can just turn it off without we rendering the scene

71
00:04:30.360 --> 00:04:33.790
and you can operate all of these things into through the Luxor render gooey.

72
00:04:34.480 --> 00:04:38.810
Now before we go into algorithms,
let's talk about algorithm classes.

73
00:04:38.811 --> 00:04:43.010
What kinds of algorithms are we interested in?
First,

74
00:04:43.070 --> 00:04:46.250
what we are interested in is consistent algorithms.

75
00:04:46.550 --> 00:04:51.170
Consistent means that if I use an infinite number of Monte Carlo samples,

76
00:04:51.500 --> 00:04:54.470
then I would convert exactly to the right answer.

77
00:04:54.500 --> 00:04:57.350
I would get back the exact integral of the function.

78
00:04:59.590 --> 00:05:03.490
Intuitively it says,
if I ran this algorithm,
sooner or later,

79
00:05:03.670 --> 00:05:04.720
it will converge.

80
00:05:06.270 --> 00:05:11.270
It also is important to note that no one said anything about when the sooner or

81
00:05:11.551 --> 00:05:14.850
later happens.
So if an algorithm is consistent,

82
00:05:14.880 --> 00:05:18.090
it doesn't mean that it is fast.
It doesn't mean that it's slow.

83
00:05:18.091 --> 00:05:20.790
It can be anything,
absolutely anything.

84
00:05:21.030 --> 00:05:25.740
It may be that there is an algorithm that's theoretically consistent,

85
00:05:26.220 --> 00:05:30.960
so after an infinite amount of samples,
you would get the right answer,

86
00:05:31.200 --> 00:05:34.090
but it really feels like infinity.
So it,

87
00:05:34.091 --> 00:05:37.440
it may be that after two weeks you still don't get the correct image.

88
00:05:37.441 --> 00:05:41.040
Our algorithms like that,
and theoretically that's consistent.

89
00:05:41.070 --> 00:05:45.150
That's fine because you can prove that it's going to convert sooner or later.

90
00:05:47.110 --> 00:05:52.110
The more difficult class that many people seem to mess up is unbiased

91
00:05:53.801 --> 00:05:57.260
algorithms.
Now,
what does it mean?
If you just read the formula,

92
00:05:57.261 --> 00:06:02.261
then you can see that the expected error of the estimation is zero and we have

93
00:06:03.501 --> 00:06:07.940
to note that this is completely independent of n.

94
00:06:08.030 --> 00:06:10.900
N is the number of samples that we have taken.
Now,

95
00:06:10.970 --> 00:06:13.730
the expected error of the estimation is zero.

96
00:06:14.390 --> 00:06:19.340
It doesn't mean that the error is zero because it's independent of the number of

97
00:06:19.350 --> 00:06:23.960
samples.
It doesn't mean that after one sample per pixel,
I get the right result.

98
00:06:24.560 --> 00:06:26.780
It says that the expected error is zero.

99
00:06:27.050 --> 00:06:31.250
I will give you many intuitions of this for this because it is very easy to

100
00:06:31.251 --> 00:06:35.990
misunderstand and misinterpret because in statistics there's a difference

101
00:06:35.991 --> 00:06:38.930
between expected value and variance,

102
00:06:40.410 --> 00:06:42.750
and this doesn't say anything about the variance.

103
00:06:42.780 --> 00:06:46.350
This only tells you about the expected values.
So for instance,

104
00:06:46.351 --> 00:06:49.020
if you're a mathematician and and think a bit about this,

105
00:06:49.021 --> 00:06:53.880
then you could say that if I have an unbiased algorithm and I have two noisy

106
00:06:53.881 --> 00:06:56.640
images,
you're under something on your machine.

107
00:06:56.670 --> 00:06:59.550
I run something that my machine that's too noisy images,

108
00:06:59.880 --> 00:07:01.590
I could merge them together.

109
00:07:01.591 --> 00:07:05.130
I could ever judge them because they are unbiased samples.

110
00:07:05.131 --> 00:07:08.550
It doesn't matter where they come from.
I would add the samples together,

111
00:07:08.551 --> 00:07:12.870
average them and I would get a better solution and we will see an example for

112
00:07:12.871 --> 00:07:13.704
that.

113
00:07:14.640 --> 00:07:19.640
My favorite intuition is that the algorithm has the very same chance of over and

114
00:07:19.891 --> 00:07:21.430
underestimating the integrated.

115
00:07:22.140 --> 00:07:27.140
So it means that if I would try to estimate the outcome of a dice roll,

116
00:07:28.530 --> 00:07:30.170
the expected value you can,

117
00:07:30.180 --> 00:07:33.210
you can roll from one to six with equal probabilities.

118
00:07:33.270 --> 00:07:38.270
The expected value is 3.5 so this means that I would have the very same

119
00:07:38.851 --> 00:07:43.851
probability of saying for as I would have the probability for saying three.

120
00:07:45.750 --> 00:07:49.270
So it's the very same chance to under and overestimating.

121
00:07:51.110 --> 00:07:53.120
And I'll give you my other favorite intuition.

122
00:07:53.121 --> 00:07:55.460
This is what journalists tend to like.

123
00:07:55.461 --> 00:07:58.760
The best means that there's no systematic error in the algorithm.

124
00:07:58.761 --> 00:08:01.310
The algorithm doesn't cut corners.

125
00:08:02.480 --> 00:08:06.530
And if there are errors in the image than this can be all the noise.

126
00:08:06.560 --> 00:08:11.060
And this noise comes because you don't have enough samples.
And if you add more,

127
00:08:11.150 --> 00:08:12.620
you're guaranteed to get better.

128
00:08:14.220 --> 00:08:14.510
<v 0>Okay.</v>

129
00:08:14.510 --> 00:08:19.310
<v 1>Now let's take another look at this really good intuition so I can combine</v>

130
00:08:19.311 --> 00:08:21.290
together too noisy images.

131
00:08:21.710 --> 00:08:26.710
So this means that I should be able to do network rendering without actually

132
00:08:29.541 --> 00:08:30.650
using the network.

133
00:08:31.550 --> 00:08:32.030
<v 0>Okay.</v>

134
00:08:32.030 --> 00:08:34.400
<v 1>Which sounds a bit mind boggling.</v>

135
00:08:34.590 --> 00:08:37.850
I really liked the parallel to this,

136
00:08:38.090 --> 00:08:43.090
which is a famous saying of Einstein from long ago where they talked about

137
00:08:44.690 --> 00:08:48.980
sending electromagnetic waves out and they talked about the telephone and people

138
00:08:48.981 --> 00:08:52.250
could not grasp the idea of a telephone.

139
00:08:52.940 --> 00:08:57.780
And he said that we would have a super,
super long cat one.

140
00:08:57.940 --> 00:09:02.940
The tail of the cat would be in Manhattan and if you would just pull the tail of

141
00:09:03.391 --> 00:09:07.740
the cat in Manhattan,
then the front of the cat would be in New York.

142
00:09:07.800 --> 00:09:12.720
And if you pull the tail in Manhattan,
then she would say meow in New York.

143
00:09:13.650 --> 00:09:17.580
And he asked the people,
is this understandable?
Yes,
this is understandable.
Okay,

144
00:09:17.610 --> 00:09:20.970
perfect.
We're almost there.
Now imagine that there's no cat

145
00:09:23.370 --> 00:09:24.840
and this is the exact same thing.

146
00:09:24.841 --> 00:09:29.220
So this is natural trend ring without an actual network.
Well,
okay.

147
00:09:29.310 --> 00:09:33.150
Mathematical theories.
Okay,
but let's actually,
let's give it a trial.

148
00:09:33.690 --> 00:09:38.190
So what I did here is I render this interior scene and this is how it looks like

149
00:09:38.191 --> 00:09:41.490
after two minutes,
it's really noisy,
right?

150
00:09:41.940 --> 00:09:46.940
Not what I did is I ran 10 of these rendering processes and save the images 10

151
00:09:50.131 --> 00:09:54.420
times.
So I didn't run one rendering process for long.

152
00:09:54.510 --> 00:09:59.510
I ran many completely independent rendering processes for to two minutes.

153
00:09:59.880 --> 00:10:02.730
And what I did is I merge the images together.

154
00:10:02.731 --> 00:10:07.700
What it means is that I averaged images,
I added them together and average them.

155
00:10:08.460 --> 00:10:13.380
Now basically this means that you could do this on completely independent

156
00:10:13.381 --> 00:10:18.090
computers that have never heard of each other.
And now let's take a look.

157
00:10:18.091 --> 00:10:21.870
This is the noisy image that we had and now let's merge 10 of these together.

158
00:10:21.900 --> 00:10:26.490
This is what we will get.
Look closely,
look at that.

159
00:10:26.880 --> 00:10:27.780
Now one more time.

160
00:10:28.050 --> 00:10:32.690
It's just a noisy after two minutes and this is merging some of these noisy

161
00:10:32.691 --> 00:10:33.540
images together.

162
00:10:34.380 --> 00:10:37.770
So this is unbelievable that this actually works.

163
00:10:37.771 --> 00:10:40.350
So if you have unbiased algorithms,

164
00:10:40.830 --> 00:10:45.830
you can expect this kind of behavior and you don't need to write sophisticated

165
00:10:47.070 --> 00:10:51.480
networking to use your path racer for instance.

166
00:10:51.810 --> 00:10:55.290
In a network because you don't need the network at all and this is really

167
00:10:55.291 --> 00:10:56.124
awesome.

168
00:11:02.100 --> 00:11:02.790
No,

169
00:11:02.790 --> 00:11:07.790
because if you don't add any kind of seed to your computations,

170
00:11:08.880 --> 00:11:12.870
then you're computing completely independent samples and it doesn't matter if

171
00:11:12.871 --> 00:11:16.530
the sample is computed on the same machine or in a different machine.

172
00:11:16.710 --> 00:11:20.220
If you have some kind of determinism,

173
00:11:20.250 --> 00:11:24.870
then it may be possible that the same paths are computed by multiple machine and

174
00:11:24.871 --> 00:11:29.280
that's indeed wasted time.
But otherwise it,
it works just fine.

175
00:11:30.060 --> 00:11:34.300
Now let's practice a bit instead.
There's a question.
Yes,

176
00:11:35.830 --> 00:11:36.430
I was whoa.

177
00:11:36.430 --> 00:11:41.430
Biggest difference between one big feature renders 20 minutes and 10 pictures

178
00:11:42.310 --> 00:11:46.140
rendered two minutes each and then combined.
Nothing in terms of samples,

179
00:11:46.141 --> 00:11:47.100
nothing that,

180
00:11:47.101 --> 00:11:51.480
the only difference is that you actually need to fire up that scene on multiple

181
00:11:51.481 --> 00:11:54.880
machines.
So if there is like 10 gigabytes of textures,

182
00:11:55.180 --> 00:11:59.550
then it takes longer to load it up on multiple machines and,

183
00:11:59.760 --> 00:12:02.320
and maybe transfer the data together.
But if you,

184
00:12:02.321 --> 00:12:06.160
if you think only in terms of sample,
it doesn't matter where it comes from.

185
00:12:08.110 --> 00:12:09.370
Okay,
let's practice a bit.

186
00:12:09.460 --> 00:12:14.460
We have different techniques and this is how the error is evolving in time.

187
00:12:15.760 --> 00:12:20.760
Now the intuition of consistent means that the error comes to zero over time,

188
00:12:20.981 --> 00:12:24.280
so if I render for long enough than the error is going to be zero.

189
00:12:26.290 --> 00:12:28.990
Is this black one a consistent algorithm?

190
00:12:33.400 --> 00:12:34.233
<v 0>Hmm.</v>

191
00:12:38.420 --> 00:12:43.010
<v 1>Nope,
because it converges here to the dash line and not to zero.</v>

192
00:12:44.330 --> 00:12:48.800
Now what about the other two guys?
Are they consistent or not?

193
00:12:51.470 --> 00:12:52.303
<v 0>Yes.</v>

194
00:12:53.080 --> 00:12:54.240
<v 1>Okay.
Why</v>

195
00:12:57.720 --> 00:12:58.553
<v 0>Baseline?</v>

196
00:12:59.620 --> 00:13:03.700
<v 1>Okay,
so the IRS seems to converge to zero.
Okay.
Now what about these techniques?</v>

197
00:13:03.701 --> 00:13:07.720
Are they biased or unbiased?
Which is which?

198
00:13:10.580 --> 00:13:15.290
What about this one?
This is the darker gray.
Is this biased or unbiased?

199
00:13:16.850 --> 00:13:21.170
Now if we have this intuition that if you're under four more,

200
00:13:21.750 --> 00:13:26.630
the image is guaranteed to get better or at least not worse than this dark gray.

201
00:13:26.631 --> 00:13:31.631
It's definitely not unbiased because it is possible that I'm rendering for 10

202
00:13:32.211 --> 00:13:36.680
minutes.
That's this point,
for instance.
And I say,
okay,

203
00:13:36.681 --> 00:13:40.940
I almost have a good enough image and I render for another five in each and

204
00:13:40.941 --> 00:13:42.320
expected to be better.

205
00:13:42.470 --> 00:13:47.470
And then I get this maybe a completely garbled up image full of artifacts and

206
00:13:48.231 --> 00:13:53.060
theirs.
And that is entirely possible with biased algorithms.

207
00:13:53.360 --> 00:13:56.720
No one said that it's likely,
but it is possible.

208
00:13:57.200 --> 00:14:00.980
So you cannot really predict how the error would evolve in time.

209
00:14:01.370 --> 00:14:03.500
And if you take a look at the other two lines,

210
00:14:03.740 --> 00:14:08.420
you can see that they are unbiased algorithms.
So as you render for longer,

211
00:14:08.540 --> 00:14:10.640
you are guaranteed to get a better image.

212
00:14:11.350 --> 00:14:11.400
<v 0>Okay.</v>

