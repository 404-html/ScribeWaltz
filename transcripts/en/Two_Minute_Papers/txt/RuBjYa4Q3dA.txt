Speaker 1:          00:01          Now before we start the algorithms, one more time, a disclaimer. These results are coming from scientific papers and if you come up with a new method, you want to show that this method outperforms existing methods in the scenes or in the setups that you have tried. And some people are very open about the limitations of the techniques. Because if I have a technique that's better than the best technique out there on this scene, that's great, but it doesn't mean that it will be better on all possible scenes. And some people are very candid about the limitations of the algorithms and some of them are not so candidate about this, but with time, as people start to use the algorithm, these possible coronary cases or just simply difficult cases come up. So what do I mean by this? But I mean is that if you see great results, that there is an algorithm, wonderful results, it's the best thing ever. Okay. But always have a slide out. Whether this algorithm would be robust enough, would it always work? When would it not work? Because don't just extrapolate from one case.

Speaker 2:          01:20          Yeah,

Speaker 1:          01:20          that may be drawbacks that are maybe not so clear, not so clear when you first see the algorithm. Now, mathematical details again will be omitted mostly and but what we are interested in, the motivation for each algorithm, what is the key idea, what are the advantages, disadvantages, how do the results look like? Where can you access implementations? Where can you try these? And for most of them, some additional literature. If you think that, wow, this is a really great algorithm. I would like to know more than there will be links. You click them and then you can read either the paper or some writing. So far, so let's get started. Part facing from 1986 super old stuff, but this is the very first and the easiest way to wrap your head around global illumination. You'll start your race from the eye or the camera. You bounced them around the scene. If you would like to earn some style points done after every balance, you would also trace shadow race towards the light source. This is next event destination. This usually lower Sioux or variance and then you end up somewhere. You compute all these life paths and jolly good. You don't do any simplifications to the integral. You exhaustively sample all possible light paths. There's no interpolation, no tricks, no magic, so this should be an unbiased and consistent algorithm

Speaker 1:          02:49          and bias. The error is predictable. I know that if I add more samples, there's going to be less error and I know that sooner or later the image is going to converge because I am all possible light paths. There are, it is impossible that I would miss something. Now, there may be corner cases but they are really difficult but fortunately well understood. Corner cases where there are contributions that you may miss. I will discuss this during the next lecture.

Speaker 1:          03:20          What are the advantages? It's simple. It's also very easy to implement. I didn't write it therapeutic also parallelized as well. Why? Because it's a dump algorithm. It doesn't do anything tricky. It doesn't feel super difficult and super complicated data structures. You just put it on the Gpu and you just cram as many and you just dish out as many light paths per second as possible. What is a common problem that people encounter with this but for instance caustics converge very slowly because cost takes are usually light paths that are extremely improbable to be sampled and you would need to compute many, many samples in order to hit these costs many times in order to clean them up. Clean them up.

Speaker 2:          04:08          Yeah.

Speaker 1:          04:09          Onwards 1993 by directional path racing. What is the motivation behind this guy? Well, imagine a scene that this is your camera on the left and you have a light source for instance enclosed in this object which is for now for the sake of experiment, the black body. So if you hit it from anywhere, it's not a glass light bulb or anything like that. It's a black party. So whichever part of the container you hit, you won't continue your path, not you would start a part racer. What do you do? You start tracing the race from the camera and it is not too likely to hit the light source is it? So it's not a point light source. It's an area light source. It is possible to hit it but it's not my like now after the previous lecture you would say no problem. Next event estimation, what do I do?

Speaker 1:          05:02          I don't wait until I hit the light source. I would send out shadow raise after every bounce and I would get some of the energy of the light source, the direct contribution of the light source. Great. But the problem is that this also doesn't work because most of the connections would be obstructed because if I hit this very first bounce, I cannot hit the light source because there's the black body that contains it. After the second balance, I also cannot connect to the light side. It's again, even with next event estimation, most of my samples are wasted.

Speaker 1:          05:37          Yeah, tracing random race, it is very unlikely to hit the light source and even if I connect to the light source, it is very unlikely that I will see an obstructed connection. What is the solution by direction and path racing? What happens here is that I'm not starting only one light path from the I, I start to light paths one from the eye as with the regular path tracing and I also start light paths starting out from the light sources. This is called light Tracy and I tried to combine these two techniques into one framework. So what it means is that I start one or a given number of bounces from the I, I start given number of bounces from the light source and then I connect these light paths together and I pretend that I just built this life passage that and now with this I have a much better chance to sample these light sources because I would have the opportunity to get out of that small zone that is otherwise difficult to hit from the eye.

Speaker 2:          06:46          Yeah.

Speaker 1:          06:47          Now let's see the difference between the two techniques. These are taken after 10 seconds for the very same scene and you could say that there's a huge difference for this indoor scene between the two. So it's definitely worth looking into. Now what is actually difficult about bi-directional path tracing is that theoretically it's very simple. There is not one light path. There are two and I connect them in all possible different ways.

Speaker 2:          07:21          Okay.

Speaker 1:          07:22          No. What you should take into consideration is that this is actually to Monte Carlo processes. One Monte Carlo process is when you start out from the eye and you hit a diffuse or a glossy object, then you would start to important sample it important sample the BRDF. This means that I would take the likely paths more often. Now if you start a light path from the light source, then what you will be sampling is actually the distribution of the light source itself because

Speaker 2:          07:57          hmm.

Speaker 1:          07:57          Regions that are visible from the light source would be sampled extensively with light tracing because you're always hitting them. They are in front of you and that's a completely different sampling distribution. So you can imagine as if you had two different Monte Carlo processes that sample the very same integrate and one Monte Carlo process would have some variance and the other will have some other variants. So different regions of the, of the path space different and also different regions of the image would converge quicker with light precinct and different images would would converge quicker with standard path tracing. And I would like to combine these two techniques together and this is entirely not trivial variance. I've written not noise in there to be more intuitive, but we are talking about it. Variance noise comes from variance variances on a d, an additive quantity. So this means that if I have to Monte Carlo estimators have given variance and if I would just add them together and average d samples, then I would also average the error of the two. And that that doesn't give me that, that doesn't give me a great result because there are some regions that are sampled by light tracing well and there are regions that are sampled by part racing well. And I cannot just cut out the good parts from each sampling technique because the error would be averaged. And this can be solved in a meaningful way,

Speaker 1:          09:30          in a way that is actually proven to be optimal in some sense. And this technique is called multiple important sampling. Now, multiple important sampling was

Speaker 1:          09:41          brought to us by a person called Eric reach in his landmark thesis of beautiful, beautiful works by direction of path facing is one of them and he, if I remember correctly last year, he got an academy award for his work. This is basically gone. This is basically the Technical Oscar award, if you will, and in his acceptance speech, it was really funny because he, he has a daughter and his daughter had taken a look at his thesis which is hundreds of pages of, of heavy integral calculus and and she asked that, that that daddy do, do people actually read this huge tome of knowledge and he finally can say yes, people actually do read that. We read it like the Holy Bible, multiple important sampling is among one of his discoveries and it is, maybe it's a bit subjective, maybe the most powerful technique in there in all rendering. And I will show you plenty of examples to convince you that this is so, so on the left, let's, let's forget about the middle example for now. Let's just compare the left and the right. You can see that there are many artifacts and many of these fireflies that can be suppressed by this technique. So I can't unify multiple sampling techniques in a way that wherever they do really bad, I can just forget that and I would take only the best samples for each region.

Speaker 1:          11:20          Let's take another look, which is maybe even better. This is called at least, this is what we call a Veech pyramid. This is created with bi directional path tracing and the code below each image means that we have taken a different number of steps from the light source and from the eye. So in every image you'll see one give a number of bounces. So if you would have path tracing, you would get like 10 or something images and not in a pyramid. One image would be the first bounce, second image would be the second, third in will be the third bus for by directional pathway. Since you have a pyramid like that because you sub divide them to the first bounce from the I n d some bounce from the light source. So this is now the two dimensional thing and you can see that some of the effects are captured really well in some of these images. And there are some other images which are absolutely, absolutely terrible and really noisy. So for instance, if you take a look at the two sites, these two sites mean that I am hitting either the camera or the light source by accident.

Speaker 2:          12:37          Okay?

Speaker 1:          12:37          And if you have a small light source, which we actually do, look here, this is a relatively low probability event. And if there, and if this is a low probability event and most of my samples are going to be wasted and I'm going to be have a noisy image not to well converged image. So on the sides I have really low probability events and these are samples that are really don't want to use, imagined that I would add all of these images together. Average time, I would have plenty of noise from the noisy ones. Now what if I could say that if you take a look at s equals one t equals five, you can see that we have caustics in there.

Speaker 1:          13:20          And the costings is almost almost immediately converged in there. It is definitely good in a sense that I would for caustics I definitely would want to use these samples and not the ones for instance e l s equals zero equals six because there's also cost x but it's really noisy. It does not systematically looking for cost x. It just happened to hit it but it it's not good at sampling it and I don't want to leverage these guys together. What I want to, what I would want to do is I would want to give a large weight to Assick was one team was five on caustics and I would just grab it in there in my image and I would just forget about the other contributions. And this is mathematically doing this in a mathematically sound way is not easy, but Eric has proven really good and super simple technique on how to do that and now look closer to the image. This is without naive, by direction, apart Resi, without multiple important sampling. And now what you will see is if we add multiple important sampling. So look closely,

Speaker 1:          14:30          see the difference. There are many noisy images that were completely shutdown because they were not really good at sampling different parts of the space of light paths. Some images are not good at anything at all. Take a look at the two sites and there are images where I can take caustics from. For instance, like the s equals five t equals one. It seems to have been even better at sampling costs x because this ESIC was one teak was fine, was also pretty good, but it was shut down by the other technique that was even better. So this is an amazingly powerful technique in order to create even even more converged images. If you have multiple sampling strategies. Now you can also play with it. It is implemented on shader toy, the nice classical Veech scene where there is lights or sampling and BSDF BRDF sampling. And it doesn't matter if you say yes the FRB RDF in this case by the way, but your reminder so you can play with it and I encourage you to do so.

Speaker 1:          15:40          It is lots of fun and you will see what kind of light transport situations are captured well with which sampling technique and how to unify them in a way that everything looks converged almost immediately. And also what does a good engineer do? Well, a good engineer obviously is interested in the problem. So I just sat down and also implemented the same thing in a simple example in one day to make sure that everyone really understands what is going on. So this is a simple Monte Carlo sampling problem in one day I have a function that I would want to integrate. If I remember correctly, I'm integrating the Garcia and I would like to sample it with two different techniques.

Speaker 1:          16:32          So this is two different Monte Carlo sampling processes and I would want to take only the best samples in order to get an approximation, which has the least variance. And there are multiple ways of combining them together. And there's also naive averaging, which just average is the error. So it would give you back all of these images from the side and I write out what are the exact Monte Carlo estimators, four different, multiple important sampling estimators as well. So take a look, it is now part of small paint and you can run it super simple and hopefully super understandable. I think it is less than a hundred lines of code.

Speaker 2:          17:13          Okay.

Speaker 1:          17:14          Okay. So what do we now know by directional path racing? Definitely better convergence, convergence, speed, especially in scenes where you are not that likely to heat light sources. So especially in indoors scenes and you will also get quicker convergence for costs x because you will have sampling strategies that are very efficient in that. So plastics are usually visible from light sources and you will sample them very often. So there's going to be at least what estimator that captures it well. So if you use M I s multiple important sampling, you're going to have caustics covered very now it is definitely not easy to grasp and it is definitely not easy to implement. So it requires quite a bit of an effort, even if it sounds very intuitive. It is, but it is not easy. This is also a brute force method. This also samples all possible light sources, and therefore this is also unbiased and consistent. Some more literature on by direction of path tracing and even better. There is a nice comparison coded up also on shader toy. So when you at home, just fire it up and you will see the difference evolving in real time on your GPU, on an indoor scene.