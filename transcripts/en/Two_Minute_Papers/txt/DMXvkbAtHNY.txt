Speaker 1:          00:00          Dear fellow scholars, this is two minute [inaudible] here. I think this is one of the more important things that happened in AI research lately. In the last few years, we have seen deep mind defeat the best go players in the world and after open Ai's venture in the game of Dota two it's time for deep mind to shine again as they take on starcraft. Two a real time strategy game. The depth and the amount of skill required to play this game is simply astounding. The search space of starcraft two is so vast that it exceeds both chess and even go by a significant margin. Also, it is a game that requires a great deal of mechanical skill split second decision making, and we have imperfect information as we only see what our units can see. A nightmare situation for any AI. Deepmind invited the beloved pro player PLO to play a few games against our new stock f two AI that goes by the name Alpha Star.

Speaker 1:          01:05          Note that the yellow is a professional player who is easily in the top 1% of players or even better meet grandmaster. For those who play starcraft two this video is about what happened during this event and later I will make another video that describes the algorithm that was used to create this Ai. The paper is still under review so it will take a little time until I can get my hands on it. At the end of this video, you will also see the inner workings of this Ai. Let's dive in. This is an AI that looked at a few games played by human players and after that initial step it learned by playing itself for about 200 years. In our next episode, you will see how this is even possible, so I hope you are subscribed to the series. You'll see here that the AI controls the blue units and Tlo.

Speaker 1:          01:57          The human player plays red right at the start of the first game. The Ai did something interesting. In fact, what is interesting is what it didn't do. It started to create new buildings next to its nexus. Instead of building a wall off that you can see here using a Wolof is considered standard practice in most games and the AI use these buildings to not wall off the entrance but shield away the workers from possible attacks. Now note that this is not unheard of, but this is also not a strategy that is widely played today and is considered nonstandard. It also built more worker units than what is universally accepted as standard. We found out later that this was partly done in anticipation of losing a few of them early on. Very cool. Then almost before we even knew what happened, it won the first game a little more than seven minutes in which is very quick. Noting that in game time is a little faster than real time.

Speaker 1:          03:07          The thought process of Tlo at this point is that that's interesting that okay, well the AI plays aggressively and managed to pull this one off. No big deal. We'll we'll fire up the second game and the in the meantime, a few interesting details. The goal of setting up the details of the SAG rhythm was that the number of actions performed by the AI roughly matches a human player and hopefully it still plays as well or better. It has to make meaningful strategic decisions. You see here that this checks out for the average actions every minute, but if you look here, you'll see around the tail end here that there are times when it performs more actions than humans and this may enable play styles that are not accessible for human players. However, note that many times it also does miraculous things with very few actions. Now what about another important detail reaction time?

Speaker 1:          04:04          The reaction time of the AI is set to 350 milliseconds, which is quite slow. That's excellent news because this is usually a common angle of criticism for Game Ais. The Ai also sees the whole map at once, but it is not given more information than what its units can see. This perhaps is the most commonly misunderstood detail, so it is worth noting. So in other words, it sees exactly what a human would see if the human would move the camera around very quickly, but it doesn't have to move the camera, which adds additional actions and cognitive load to the human. So one might say that the AI has an edge here. The Ai plays these games independently. What's more, each game was played by a different AI, which also means that they do not memorize what happened in the last game like a human would. Early in the next game, we can see the utility of the wall off in action, which is able to completely prevent the ais early attack later that game, the AI use disruptors, the unit which if controlled with such level of expertise can decimate the army of the opponent with area of damage by killing multiple units at once.

Speaker 1:          05:16          It has done an outstanding job picking away at the army of Tlo. Then after getting a significant advantage, Alpha star loses it with a few sloppy place, and by deciding to engage aggressively while standing in tight choke points, you can see that this is not such a great idea. This was quite surprising as this is considered to be starcraft one o one knowledge right there during the remainder of the match. The commentators mentioned that they play and watch games all the time and the AI came up with an army composition that they have never seen during a professional match and the AI won this one too. After game, it became clear that these agents can play any style in the game, which is terrifying. Here you can see an alternative visualization that shows a little more of the inner workings of the Neuron Network. We can see what information it gets from the game, the visualization of neurons that get activated within the network, what locations and units are considered for the next actions and whether the AI predict itself as the winner or the loser of the game. If you look carefully, you will also see the moment when the agent becomes certain that it will win this game. I could look at this all day long and if you feel the same way, make sure to visit the video description. I have a link to the source video for you. The final result against Tlo was five to zero.

Speaker 2:          06:45          How strong the agent I actually lost every single over fire. So that's something

Speaker 1:          06:57          and he mentioned that Alpha Star played very much like a human does and almost always manage to outmaneuver him. However, Tlo also mentioned that he is confident that open playing more training matches against these agents. He would be able to defeat the AI. I hope he will be given a chance to do that. This AI seem strong but steel beatable. I would also note that many of you would probably expect the later versions of Alpha Star. It be way better than this one. The good news is that the story continues and we'll see whether that's true. So at this point the deep mind scientists said maybe we could try to be a bit more ambitious and asked, can you bring us someone better? And in the meantime pressed that training button on the AI again, incomes manner, a top tier pro player, one of the best protest players in the world.

Speaker 1:          07:49          This was a nerve wracking moment for deep mind scientists as well because their agents played against each other. So they only knew the ais wind rate against a different API, but they didn't know how they would compete against a top pro player. It may still have holes in its strategy. Who knows what will happen. Understandably, they had very little confidence in winning this one. What they didn't expect is that the new AI was not slightly improved or somewhat improved? No, no, no, no, no. This new AI was next level. This app of improved agents among many other skills had incredibly crisp micromanagement of each individual unit in the first game. We've seen it pulling back injured units, but still letting them attack from afar, masterfully leading to an early win for the AI against Manna in the first game. He and the commentators were equally shocked by how well the agent plate, and I will add that.

Speaker 1:          08:47          I remember from watching many games from a now inactive player by the name marine king a few years ago and I vividly that he played some of his games so well. The commentators said that there is no better way to put it. He played like a God. I am almost afraid to say that this micromanagement was even more crisp than that. This AI plays phenomenal games in later matches. The Ai did things that seemed like blunders like attacking on ramps and standing in choke points or using unfavorable unit compositions and refusing to change it and get this. It's still won all of those games, five to zero against a top pro player. Let that sink in.

Speaker 3:          09:38          I would consider myself a good player, right? I lost every single one. I'm just trying to digest it.

Speaker 1:          09:53          The competition was closed by a match where the AI was asked to also do the camera management. The agent was still very competent but somewhat weaker and as a result lost this game, hence the zero or one part in the title. My impression is that it was asked to do something that it was not designed for and expect a future version to be able to handle this use case as well. I will also come and Manna for his solid game plan for this game and also huge respect for deep mind for their sportsmanship. Interestingly in this match manner also started a worker oversaturation of strategy that I mentioned earlier. This he learned from Alpha Star and used it in his winning game. Isn't that amazing? Deep Mind also offered a Reddit Ama where anyone could ask them questions to make sure to clear up any confusion. For instance, the actions per minute part has been addressed.

Speaker 1:          10:47          I've included the link to that for you in the video description to go from a turn turn-based perfect information game. Let go to a real time strategy game of imperfect information in about a year. Sounds like science fiction to me and yet here it is. Also know that deep mines goal is not to create a god like starcraft two AI. They want to solve intelligence, not starcraft two and they use this game as a vehicle to demonstrate its longterm decision making capabilities against human players. One more important thing to emphasize is that the building blocks of Alpha star are meant to be reasonably general Ai Algorithms, which means that parts of this AI can be reused for other things. For instance, may Sasabe is mentioned weather prediction and climate modeling. As examples. If you take only one thought from this video, let it be this one, I urge you to watch all the matches because what you are witnessing may very well be history in the making.

Speaker 1:          11:48          I put a link to the whole event in the video description plus plenty more materials including other people as analysis, manners, personal experience of the event, his breakdown of his games and what was going through his head during the event. I highly recommend checking out his fifth game, but really go through them all. It's a ton of fun. I made sure to include a more skeptical analysis of the game as well to give you a balanced portfolio of insights. Also, huge respect for deep mind and the players who practice their chops for many, many years and have played really well under immense pressure. Thank you all for this delightful event. It really made my day and the ultimate question is how long did it take to train these agents? Two weeks. Wow. And what's more after the training step, the Ai can be deployed on an inexpensive consumer desktop machine and this is only the first version.

Speaker 1:          12:41          This is just a taste and it would be hard to overstate how big of a milestone this is and now scientists are deep, might have sufficient data to calculate the amount of resources they need to spend to train the next even more improved agents. I am confident that they will also take into consideration the feedback from the starcraft community when creating this next version. What a time to be alive. What do you think about all this? Any predictions? Is this harder than Dota two? Let me know in the comments section below and remember we humans build up new strategies by learning from each other. And of course the AI, as you have seen here, doesn't care about any of that. It doesn't need intuition and can come up with unusual strategies. The difference now is that these strategies work against some of the best human players. Now it's time for us to finally start learning from an AI GG. Thanks for watching and for your generous support. And I'll see you next time.