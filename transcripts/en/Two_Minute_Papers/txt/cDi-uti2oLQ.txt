Speaker 1:          00:00          What a wonderful day we have today and what a wonderful time it is to write a past racer so I don't we get started. What we are going to be looking at is a program called small paint, which is a small path tracer in effectively 250 lines of code and it contains everything that we have learned. During this course we're going to be able to compute soft shadows, anti-aliasing, Monte Carlo integration and defund quasi Monte Carlo sampling, which basically means low discrepancy sampling. This version of the program is going to be able to compute refractions, color bleeding and caustics and in the end the binary you can power from the cold can be compressed into less than four kilobytes. This is how the end result looks like. It has a beautiful painterly look which actually comes from a bug and you can also see that the light source up there, the whitish looking sphere is you could say perfectly anti elitist.

Speaker 1:          01:09          In order to achieve this with a recursive ray tracer and no global illumination algorithm, you would need to compute the very same image on a much larger resolution. And then scale it down to a smaller image like this. And this anti-aliasing effect you get for free if you compute Monte-carlo path tracing. So the question is how is this exactly done and now is the best time to put everything into use that we have learned so far. So let's get started. We have a completely standard vector class. It is a three dimensional vector, it has its own constructor, the classical operators that you would expect. And we also have a dog product for the vector and across product for directory. It is also obviously possible to compute the length of this factor, so nothing too exciting or important here, but we definitely need to build on a solid vector class.

Speaker 1:          02:06          Now, third presentation of array array has an origin and the direction and if you take a close look at the constructor, you can see that when you initialize the array with a direction, then this direction is normed. And the reason is that when we compute the top products between these vectors, most of these information needs to be directional information. So we are not interested in the magnitude of the vector. Only interested in the direction of the vector. A good way to get rid of problems where you would initialize your ray with directions that are not vectors of unit length but you can do is to normalize this input in the constructor so you will never have headaches about incorrect results where you have no idea what is really happening. What is the representation of an object? Well, an object has a, this is denoted by cl.

Speaker 1:          03:01          This is actually very sloppy notation and this you can imagine as lb dough but it is not a double so it's not a number. It is actually a vector and the reason for this is the fact that we need to define the LB dose, how much light in different wavelengths is being reflected and how much is being absorbed. Biotech, even object now object may also have a mission. If they have some non zero emission and they are light sources and by type we have an integer that would specify what kind of Brdf we have. It is also important to have an intersection routine and some other function that can compute the normal of the object. Now, these are of course virtual functions. We don't define them or an abstract object, but they would have to be implemented in other classes that inherit from the object. Let's take a look at the sphere, so his fear has the C and r. C is the center of the objects and R is the radius. The constructor is trivial. We have the intersection function. Now you hopefully remember all three of the elements of the quadratic function that we need to solve that. If you take a good look, then you will see that a is missing from here and the question is why is that?

Speaker 1:          04:23          The answer is we are multiplying d with d to direction vector of array with itself and if it's a vector that is normed, so it is of length one then this a will always be one.

Speaker 1:          04:39          After that we can deal with the discriminant. The discriminant is normally not B squared minus four AC. Remember a is one here, so it's submitted but it is behind a square root and the square root is completely omitted here, which looks like a mistake but it is not. It is essentially an optimization step because you will see that we are testing the discriminant if it's less than zero, if it's less than zero, then we don't need to deal with this equation because the solutions for the quadratic equation are going to exist in the plane of complex numbers and that's not a valid tea. It's not a valid distance where we would intersect the sphere. If this is not happening, then we can compute the square root for the discriminant. Why after that? Because if the discriminant is bigger than zero, then the square root is not going to make a difference. So what we can essentially do is to postpone the squire road calculation after the test note that square roots are really, really expensive so we can save up lots of computational time. If you're mid this calculation there is a really nice square root hack in the source code of quake three which is by the way, open source. Take a look at how people are trying to hack to get her functions in order to work better and faster than they should because the square roots are super expensive and there are some really interesting hacks in order to speed them up.

Speaker 1:          06:12          We have the plus and minus term and the division by two a is again postponed

Speaker 1:          06:20          and that's also another interesting question. Why is this postponed? So you can see that the soul too is divided by two and a soul one is also divided by two but only after the test. So it is possible that if we have the solution to, if it is bigger than epsilon then we have the first expression after the question mark. But if it's not then we are looking for the second expression after it, which is another test and if the answer is no for death as well, then we are going to return zero. This would mean that we don't have any hits or the hits are behind us and we are not interested in intersections that are behind our rea. There is a possibility that we encountered this and in this case, I don't want to waste my time by dividing the solutions by two because I'm not going to use them.

Speaker 2:          07:06          Yeah.

Speaker 1:          07:07          Why am I splitting hairs here? That's an important question. Why do we need to optimize so much? Because if you grab a profiler, a program that is able to show you in what functions are you spending most of your time in, then this provider would show you that more than 90% of the execution time is spent in the intersection routines. So you have to have a really well optimized intersection routine. Some programs have replaced these expressions with SMB in order to speed it up even more.

Speaker 2:          07:40          Okay,

Speaker 1:          07:40          so how do we compute the normal of his sphere? Well, very simple. What we have here is p minus c not what does it mean? So if I have a minus B, then this means a factor that points from B to a. So what this would mean, look at the figure here. If I would have a circle, then this would mean that from the center it is pointing towards the given points off the sphere. Now this is also divided by r because you could imagine you have this fear that is not of unit radius and if it's not off unit radius, then this normal vector would have a length. You could compute a normalization. We have a normalized function in our rector implementation, but it also has a square root, so it would be much better to have something that's faster. Well, if you just divide by the radius of the sphere, then you would immediately get a vector of unit length.

Speaker 2:          08:34          Okay,

Speaker 1:          08:34          so in the end we can get the correct result by just simply dividing by our,

Speaker 2:          08:39          hmm.

Speaker 1:          08:40          Excellent.

Speaker 2:          08:41          Hmm.

Speaker 1:          08:42          Now we have a perspective camera here. Hopefully you remember from the first lecture, we are basically just copy pasting this expression here. We have derived, done rigorously and analyzed how this exactly works. A simple intuition. Basically what we are doing, we have as an input and x and the y. Basically this means give me a pig solve with this displacement and what it would give you back is the world's space coordinates of these pixels

Speaker 1:          09:10          uniforms, sampling of a hemisphere. What is this for? If we are encountering a diffuse object, what we would like to do is to send array out on the hemisphere of this object. This we would need to uniformly sample. This means that the diffuse BRDF is one of our pie or roll over pie. If you take into consideration the lb dose and you need transforms in order to do it, there is a reading behind this link. How it works exactly is drawing uniform samples on a plane which is simple and then we are projecting it on the hemisphere. That's basically all there is.

Speaker 1:          09:49          What about the trace function? As you can see here in the first line, this code says that there is a maximum depth. Now clamping after a maximum depth value is not really optimal because whatever number you put in there, the higher order bounces are going to be completely omitted. Now there is a solution would be Russian roulette pass termination, which we fortunately also have after depth of an arbitrary number like five. You start to Russian roulette routine which basically says there is a probability for stopping the light path right there and we generate a random number and compare to this probability. If we don't hit this probability then we will continue our path but we will multiply the output and the contribution of this light path by this given number that we have specified in one of the previous lectures. So this was implemented by Christie and Maha check and kind thanks and you can see that later we are going to use this rr factor in order to multiply the contribution of array later.

Speaker 1:          11:03          Now what about the intersection routine? This is definitely not the best way to do it but it's sure as hell the easiest way to do it. We specify this tea which is going to be the intersection distance, how far we are from the start of the rea and how far is this intersection exactly. Id is basically which object did we hit and then we iterate through all of the objects in the scene and what we are interested in is calling the intersection routine. This will return a t how far is the intersection and what I am interested in an intersection that is the smallest number. This means the closest intersection and also something that is larger than epsilon because if I would tolerate zero then this would mean that self intersections are accepted. Therefore, every single object that I am on is going to be the first intersection. I'm not interested in this. I know where I am. I just want to know where I am continuing my path. If there's no intersection then we return. There is zero contribution.

Speaker 2:          12:06          Okay.

Speaker 1:          12:07          Why is the intersection in world space? We did notice by HP this means heat point and where we have started array, we traveled along the direction of the rea with this tea amount where the intersection is, so this is where we ended up and the origin of the new ray is going to be dis hit point. What is the normal going to be? Well, we just grabbed the object that we intersected and we are taking the normal with the given function. What is the return radiants? We simply add the emission term. This is the emission term and all three wavelengths. There is a magic multiplier. Disregard that and then we continue evaluating the second part of the rendering equation. The first part is the emission and the second is the reflected amount of light.

Speaker 1:          12:56          Let's continue with the inside of the trace function. If we hit an object with a type of one, then this is a diffuse BRDF. The next functions compute the next random number for the low discrepancy halt on sampler and the direction is going to be a random sample in the hemisphere, a completely uniform random sample in the hemisphere of the subject. What we have here is this end plus the hemisphere function. This is intuition. This is not exactly what is happening. I've just shortened the code slightly in order to simplify what is going on here. The code that you will download, we'll have the real deal in there. Now. Then we compute the cosign term very straightforward. And on the TMP we are going to instantiate a new vector and this is going to hold the recursion. So the subsequent samples that we shoot out from the hemisphere are going to be added and added to this TMP.

Speaker 1:          13:53          Now is the time for recursion. We passed the ray and the scene to the trace function. The Ray is actually not, the current one is the new one. So basically we set up the new hip point and the new direction of the deray and this is what we are going to pass to the trace function. We increment the depth variable because we have computed a bounce. The TMP is going to be a variable where we get her oldest radiants and we put every other parameter that is needed to compute one more balance. Now the color is going to contain the cosign term and all this radiance that is collected from the recursion and we multiply it with the cl that x, Y, Z, which is basically the BRDF. So this is the right side of the equation for a diffuse BRDF. This is multiplied by oh 0.1 this is just a magic constant. Now what about a specular BRDF? What if we hit the mirror? Well, very simple. We compute the perfect reflection direction. You can see the rate dot t and we again set up this variable to collect the radiants in there and we are not doing anything. We are just going to add the radiants as we get reflected off of this mirror. Then we are going to compute subsequent bounces and this is going to be stored on this DMP. So this is what we're going to add to this radiance.

Speaker 1:          15:18          And what about the refractive material? Well, we have every bit of knowledge that we need for this because essentially this is the vector version of snails law. What does it mean? Well, the origin was last law that we have computed is in one day. So it only gives you one angle. But if you're in three d you are interested in angles in two different dimensions. This is nothing but the extension of the very same law into higher dimension. Now where is this implemented exactly? You can see the cosign of data to note that n one and n two is considered differently because one of these media is always going to be air. Therefore one of the indices of refraction is always going to be one. The rest is just copy paste and again you can see that the square root is missing and we are going to postpone this after the test of cosign t too because if it is actually not larger than zero then we are not going to need this variable at all. Therefore we can postpone this after the test. Again,

Speaker 1:          16:34          what about the direction of the outgoing gray? While this is just copy paste from the formula that we have their eyes before. So simple as that. Obviously we again need dairy corrosion because if we go inside a glass sphere than we are going to compute the refraction. So we are going to be inside of the sphere. What does it mean? One that we have to invert a normal because we are inside so the normals are flipped and again we need to compute the trace function which is direct action. So we are also interested in the higher order bounces

Speaker 1:          17:08          on the worst to Frennels law. What is the probability of reflection and refraction when rays are bouncing off in different directions in different angles off of refractive surfaces implemented by Christiane Hoffner. So a big thanks for him. It is very simple. You can see that it is exactly the same as what we have learned in mathematics. So this is the zero term. This is the probability of reflection in normal incidents and we are interested in the square of that and note that you don't see the n one and then two. This is because one of them is always going to be air or vacuum. So it is going to have the index of refraction of war. Now what about final probability

Speaker 2:          17:50          of reflection? It is also coming from the formula. We have every bit of information we need. So we just put in there this term with the cosign attenuation. How does the main function look like? Well, we have some wizardry with c plus plus 11 lambda functions, but basically this is just a shortcut in order to be able to add a new sphere or a new plane to the scene. In one line of code, spheres are given by their radius position color. By color we obviously mean lb. Those emission and type type means what kind of Brd of, we have a diffuse, a specular or f refractive BRDF. Now for planes we have position, normal color emission and obviously types. So what kind of material we have. So using just one line of code, you can add a new object and specify everything, every information that you would need to it. Now we also add the light source and we specify the index of refraction for the refractive brds and we also specify how many samples per pixel would we like to compute.

Speaker 1:          19:01          Onwards to the main loop, we have two four loops that iterate through the width and the height of the image plane. Now vector see is color. It's again very sloppy. What it means is actually the gradients that we compute, we instantiate array. What is going to be the origin of the [inaudible]. This is going to be zero, zero, zero, so this is where the camera is placed. What is going to be the direction of the Ray. While we connect this way to the camera plane and we specify which pixel we are computing with I and J and then we add this weird random number to it. Now what this means is actually filtering in recursive ray tracing. What you would do is you would only send the ray through the midpoint of a pixel and that's it. You would compute one sample per pixel in Monte Carlo Path, tracing your computing many samples per pixel and they don't have to go through the midpoint of the Pixel.

Speaker 1:          20:00          You would sample the area of the Pixel and this gives you anti aliasing effects for free if you use it correctly. What is going to be the direction of Deray? This is again the same a minus B. The B is the origin of deray and a is the camera coordinates. So what does it mean that it is pointing from zero to the camera plate and we normalize this expression to have array of unit length. Now we obviously called the trace function. The number of bounces is zero and we pass every information that needs to be known in order to compute these bounces, so we provide this initial ray and the scene and everything else. Obviously we also passed the C and this is going to collect all the radiance there is in the subsequent and then after this recursion is done. We deposit all this energy, oldest radiants to the individual pixels and then we divide by the number of samples because if we wouldn't do this, then you remember the one over n multiplier everywhere in Monte Carlo integration. If you wouldn't do this, then the more samples you compute, the brighter image you would get and this is obviously not what we're looking for.

Speaker 1:          21:40          At the very end we create a file. This is the ppm file format where you can easily write all your contributions in terror. We also start a stopwatch in order to measure how long we have been tracing. All these rays, so very simple, very trivial, and when we are done, we close the file. It has the image in there and we done right how long the rendering algorithm has been running for.

Speaker 2:          22:05          Okay.

Speaker 1:          22:06          And basically that's it. That's it. This is effectively 250 lines of code that can compute indirect illumination cost takes and every global illumination effect. And it can compute images like this. This is one student submission from previous years. Absolutely gorgeous. This is the fixed version of small paint where there are no errors in the sampling. Another one from Mechelle Comma, this actually it looks like, I don't know if you are into the music band boards of Canada, but this looks exactly like one of their album covers. Love it. Really cool. And also Sierpinski triangle triangles from Christiana Kasla.

Speaker 2:          22:52          Okay.

Speaker 1:          22:53          You can find the link for the code in there and take a crack at it. Just try it. Build different scenes, try to understand what is going on in there. Try to mess the code up. I wonder what happens if I would not normalize this factor. Play with it. It's a really small, concise, and really understandable path tracer. So take your time and play with it. It's lots of fun and you can create lots of beautiful, beautiful images with global illumination. Thank you.