Speaker 1:          00:00          Okay, let's continue with even more good stuff. Metropolis slide transport straight from 97 the key idea is to seek the light. This is the thing that I always hear from the artists who use the algorithm. What we are trying to do is sampling brighter light paths more often than darker light paths. That's it. That's the basic principle. That's what we're trying to do. And educated people would immediately say that, hey, but isn't this what we have been talking about at important sampling? Isn't this conflicting with important sampling? What is important sampling? Well, it means that if I have, for instance, a glossy reflection, a glossy BRDF, which has a really high probability of sending grace out in the perfect reflection direction, so almost like a mirror with a high probability, it would behave like a mirror. That I would like to have a high probability of actually sampling that light path

Speaker 1:          01:04          proportional to the shape of the BRDF. And this we can do through important sampling. Okay? But imagine a case where you would have a glossary of flection covered from almost every direction by black bodies. So it doesn't matter if I important sample the BRDF correctly because after I important sample the BRDF and the light is coming to the next bounce, it's it's always going to hit a black body and it's going to be absorbed. I'm never going to continue my lap light path afterwards. So even though I would important sample these, this one bounce, I am not important sampling along the whole path because I have important sample. This one bounce correctly, but I didn't know that globally I'm just heading to a region that's really dark. And what metropolis like transport gives you is something that is not really referred to, but I like to call it multi bounds important sampling.

Speaker 1:          02:06          So it may take suboptimal decisions and it may send out rays in a direction that is not so likely for your BRDF if it knows that it's going to end up being a bright light path. So for instance, if you have a glossy into reflection that would be mostly sending grace out in this direction, but there is complete darkness in there, then it would, it would, well it will do is it would actually send more race towards the light source, which looks like a suboptimal decision in their in depth BRDF. But over the whole light path that is actually going to be something, right? So this is the key idea behind Metropoulos light transport. And I'd like to give you an intuitive example of that.

Speaker 2:          02:54          Okay.

Speaker 1:          02:55          So imagine that

Speaker 1:          02:58          you have the camera in this room in the scene and you have a light source only in the only in the adjacent room in the next room. And this next room is separated by a wall and the door that is slightly ajar. So it is just opened just a bit and all the light that you see is coming through that door. And if you imagine for an hour naive path tracing, what am I doing? I am sending already through the first big salt and I'm going to bounce it around the scene and it is very likely that I will never find the light source and I cannot even connect to the light source. It's in the other room. I'm going to hit the wall or the door and imagined that I'm computing thousands and thousands of samples and I finally get to hit the light path that is actually connectable to our light source.

Speaker 1:          03:55          If we are doing park racing, you can imagine that I'm starting from here. If you take a look at the Arrow in there, it's a, it gives you the intuition that maybe we are doing light tracing, we are shooting light rays of light from the light source and the finally get into this room and hit the camera. There's finally a good connection after thousands and thousands of samples. I finally have one contribution before that zero zero one zero zero zero and my CPU is basically dying on 100% load. Nothing gets out of debt. Now imagine that I finally found the light path that makes sense, that has a contribution and then I would suddenly forget about the whole thing and I would again start sampling completely random light paths and get the zero, zero, zero again.

Speaker 1:          04:46          Now it would be a crime to do that wouldn't it? What metropolis is doing is essentially trying to remember which are the parts that makes sense and if they find something like that they are going to explore nearby so they are not going to shoot out a completely random sample for the next sample. It's going to take this one sample that made sense. Finally a connection and then it's going to add very small perturbations to this slide path. What if I showed this in an angle that's just a bit changed and what you can expect is that most of the time it will give you again, some amount of contribution and you don't have to start from scratch. So basically you can use all of these knowledge into your advantage. How does the difference look like? Well, this is the scene with bi-directional path tracing after 40 samples per pixel and now if you look closely, you will see Metropoulos after the very same number of samples per pixel. So this is by directional path tracing and now metropole is the same number of samples. So if you take this knowledge into account, most of your samples are going to be useful. Just another look better action apart racing metropole this and viral action there was already a good algorithm. It's not a nice path tracer, it's, it's a good algorithm and now youth pathways and will be even worse.

Speaker 1:          06:18          Not for example some Nice volumetric caustics with my youth part racing and an equal time comparison with metropolis light transport.

Speaker 1:          06:30          How does it work? Exactly? Mathematical details, but just enough, just enough to understand the intuition. What we are trying to do is important sampling. What does it mean? It means that I am computing this great samples of f over p f is the function that I would like to integrate. P is a sampling distribution. What I'm looking for is to match the blue lines with the green bars. If you remember. So it means that if the function is large summer, it means that the image is sprite somewhere or the path, the space is bright somewhere, then I would like to put more samples in there. So if f is larger than PE, should also be large. This is what I'm trying to achieve. Now how do I actually do this? I have some high dimensional function or if I'm doing locally important something, then I have a BRDF function. How do I important sample this? The trivial solution is called rejection sampling. Basically what it means is that I would like to compute, uh, samples from a sampling distribution. So here you see something that is like almost a Gaussian. But imagine that I cannot generate samples out of this function because what do I have in my c plus plus code? Well, I can generate uniform random numbers, but this function is not uniform random numbers. So what I can do is I can sample an arbitrary distribution function.

Speaker 1:          08:14          If I end close it in a box and I throw completely uniform random samples on this box. So it is almost like drawing your function on a sheet of paper and throwing random samples at it. Now, I cannot generate random samples out of this function, but I can generate random uniformly distributed samples and the scheme is very simple. If it is under the function, I'm going to take this sample and pretend that I've generated that sample in the first place. And if it's out there, I'm just going to kick it out. So if I do this, I will have samples according to this almost Garcia. This works well, but this is not what we are doing in practice. This is very inefficient and hopefully you can see from the image why this is an inefficient technique to do so someone please raise your hand and help me out why this is not efficient. Okay, that's true. Thanks. So there's palm soft rejected samples. Most of my uniformly generated random numbers are completely wasted again. So there must be some technique that's better than this, where that is, but I guarantee that it's not going to make you any happier when you see how it is done.

Speaker 2:          09:38          Okay?

Speaker 1:          09:38          So there's lots of rejection. There's lots of rejections and this can be analytically, this problem can almost always be analytical assault by a technique called the inverse transform sampling or the Smirnoff transform. And this takes a bit of work, but I'll just briefly show you how it works and if you are really interested in the details done, please take a look at this document, Sasha. You what you have to do, you have to do all of these calculations and then you will have your sampling distribution. Okay, what do we have at the end? Let's start with the intuition.

Speaker 2:          10:19          Okay?

Speaker 1:          10:19          We have uniformly generated random numbers. This is the [inaudible] at the end and I want to do some transform to these numbers in order to get an arbitrary sampling distribution. And what they are essentially doing is you have a probability distribution function you want to sample from that. It can be like a porcelain distribution and exponential distribution or some custom BRDF. And if you integrate the PDF, you're going to have a CDF. So you integrate the probability distribution function, you will get a cumulative distribution function and this can help you in this transformation from uniform. He generated random numbers to the actual function.

Speaker 2:          11:05          Okay.

Speaker 1:          11:05          Now this is very intimidating, isn't it? Imagine that whenever you come up with a new BRDF or any kind of function that you would like to sample, you would have to compute all this.

Speaker 2:          11:18          Yeah.

Speaker 1:          11:18          And not only that, we were doing this for Brd F's. So I can important sample one bounce. Again, I emphasize that it means that if I hit the hit the table, I locally know what are the good, outgoing directions because of the material model. But it doesn't mean that it's globally a good idea because may maybe this completely black curtain next to it, which I'm going to hit, and all of the energy is going to be absorbed.

Speaker 1:          11:47          What does Metropoulos give us a solution to this? So it's, it's important to sampling not only for one BRDF, not only for all possible brds, but an optimal important sampling along the whole path. So this means that it will know that if there is a path that is 15 bounce long but it hits something that is really bright and it transfers a lot of energy, it will know that I will need to sample this slide path and nearby and it is not going to trace many race towards the shadow regions. How does it work? Again, intuitively it runs a Markov chain process and there is four Markov chains. There is a study state distribution. This means that we have been running the mark of chain for a while. And if you do that then it promises you optimal important sampling for any kind of function without doing anything.

Speaker 1:          12:49          And I hope that it is understandable how really amazing this is because it is actually a simple sampling scheme that you can write down the pseudo code in five or six lines and and it gives you optimal important sampling. So this is really amazing and I emphasize again that this is over multiple bounces, not important, something won't be RDF, but over whole light paths there are different different variants of metropolis, light transport. The original is the beach type Metropoulos. This is the one that was published in [inaudible] 97 it is a great algorithm. It has different mutations strategies. It means that it has different strategies of changing the current light path into a new one in a smart way and not random me. The problem is that almost no one in the world can implement it correctly. So it was published in [inaudible] 97 and the first viable implementation that came out was in the mid to bartender implemented by Vantaa Jaco and it was around I think 2010 so just a few years ago.

Speaker 1:          14:01          Metro. I've got the original metropole is slide transport also attributed to Eric Niche. No one in the world could implement it. I honestly don't know what was going on because he published it in [inaudible] 97 and it took the very least 13 years for the first super smart guy to implement correctly. I don't know what he was doing in the meantime. Maybe he was laughing on humanity that no one is smart enough to to deal with this and maybe we don't deserve this algorithm. I don't know. It's not for the faint of heart. It's a really difficult digress them. Yes he working for Google. That's true. But after, after the phd he did he go immediately to Google. So he's basically working on Edwards, how to get more money out of advertisements. It definitely pays well. And who knows. I mean that if Eric reaches working on it, that there's, there's gonna be some good stuff in there, I guarantee you.

Speaker 1:          15:14          But I have to say that his face looked actually quite delighted when he got the Academy award just recently for his work. That was at the very least 15 years ago. It's still used all over the industry. Multiple important sampling butter. Actually the office in metropolis, it's all over the industry now are each style metropolis is really difficult. Uh, fortunately there are also smart people at my former university, namely, uh, trouble Kellerman and lastly CMA colors. They came up with a simplified version of the algorithm, which is almost as robust, but it's actually quite trivial to implement. It has also implemented in small paint. It is called the primary sample space, metropolis. It is now implemented by one of my students from a previous year, uh, rendering course and it is in small pens so you can give it a try.

Speaker 1:          16:12          Basically it does a complicated sounding, but otherwise simple mapping from an infinite dimensional cube where I can generate infinite dimensional cube means arbitrarily long vectors of independent, randomly uniform, random generated numbers and these random numbers are somehow transformed into light paths. So what the algorithm does is there's a probability that I am computing a completely new light path and if I don't have this probability then I'm going to stay around this light path and explore nearby what does it mean practically. If I find this super difficult life path from the other room to here, then I find a really bright light path. The algorithm will know that, okay, I'm just going to add slide perturbations to this light path. I'm going to stay around here and sometimes it will start to look around for random samples. There's also a visualization video on youtube. If you take a look, you will immediately understand what is going on.

Speaker 2:          17:19          Okay.

Speaker 1:          17:20          And some literature about these algorithms. Now it is also a sampling scheme. So metropolis you can implement together with path tracing or by direction of path tracing. And therefore this is also an unbiased and consistent algorithm

Speaker 1:          17:38          and it is very robust. It is tailored for really difficult scenes. So if you have a scene with a lot of occlusions, difficult to sample light sources, difficult to reach light sources, use the metropolis. But if you have an easy scene, this is not going to give you much because the metropolis is a smart algorithm. It takes longer to compute one sample, then a path tracer. And if this smart behavior of the algorithm, it does not pay off, then there may be scenes where the metro police is actually worse than a path racer. So if you have an outdoor scene with large light sources and environment match that you hit all the time, don't use Metropoulos. It doesn't give you anything. Park racing would give you better results because it can dish out more samples per pixel because it's done and it parallelizes even better.

Speaker 2:          18:32          Okay.

Speaker 1:          18:33          And only the number of samples matter in this case.

Speaker 2:          18:38          Yeah.

Speaker 1:          18:39          And there may be algorithms that take this into consideration.

Speaker 1:          18:45          So what if we had an algorithm that could determine if we have an easy scene or a difficult scene and it would use for easy scenes, easy, a naive part, racing by direction, with path facing, or if there's a difficult scene, then it would use metro police light transport. Now this would need an algorithm that can somehow determined whether the scene is easy or hard. And that's not trivial at all to do. But behind this link, there's a work that deals with it. And I would also like to note that metropolis light transport is unbiased, but it starts out biased. So what it means is that I'm running a mark of chain that will give me optimal important sampling, but it, this mark of chain also evolves in time. So I have to wait and wait and wait and it will get better and better estimations on the where the bride paths are and where the dark paths are. And this takes time. This effect is what we call startup bias.

Speaker 2:          19:47          Okay.

Speaker 1:          19:48          Now what do we get for it? We'll see plenty of examples. So for instance, on caustics, it's even better than by direction of past facing. For caustics you will get almost immediate convergence. Now what about this scene? This scene was rendered with lux render. Here you have not glass fierce but some kind of prison materials fierce because you can see a pronounced the fact of this person and you can see volumetric caustic. So there is a participating media that we are in and these costs are going to be reflected multiple times and refracted multiple times. Let's say that this is a disgustingly difficult scene. The only light source their ears is actually this laser that comes in from the upper left. Let's try to render such a scene with the different algorithms that we have learned about. Now, if I start a path face, so this is what I will get after 10 minutes.

Speaker 1:          20:53          So the highest scoring light paths, the bright light paths are not the greatest probability light paths and therefore most of the connections will be also obstructed towards the light source. So it is very difficult to sample with path tracing. Bi-Directional for, I think it's better, but I mean if I get this after 10 minutes, I don't know how long it would take to render the actual scene and if you're on a tropple is it will find the light path that matter and find the ones that are actually needed to be sampled. And this, this is the sip already, the simplified version pssm lt and the number next to it is just the ratio of these small perturbations to large perturbations, sorry, the opposite. So a large number means that most of my life paths are going to be random. So most of the 75% probability I'm going to do by direction apart facing 25% Metropoulos. And if I pull down this probability opening quantified that most of the time I'm going to do metropolis sampling, I'm going to explore nearby. And you can see that this renders the scene much, much faster. So this is definitely a very useful technique to have. Now I've done this animation just for fun. This is a primary sample space, metropolis light transport algorithm only with small mutations, so just very small adjustments to the light paths and this is how an image would converge we these small steps and you can see that the caustics converge ridiculously quickly. Let's take a look at one more example.

Speaker 1:          22:47          Take a look at this. Most of the scene is still noisy, but the caustics are completely converged as we start out. Why? Because it is really bright and this is exactly what the metropolis is going to focus on. So it is even better around caustics. Something that takes a brutal amount of samples with a normal path racer is going to be immediately converged with the metropolis. So this is the first, I think 10 perhaps 10 minutes a friend during with the metropolis on and not so powerful machine. So it seems that we have solved everything. We're looking good, we got this, but I will show you a failure case that we actually still have problems that we couldn't solve. This is a sophisticated scene that is for some reason even harder in some sense. Then the previous scenes, and he just doesn't want to converge with the primary sample space. I'm just rendering and random and still fireflies. If I have really large, really bright, noisy spots, then this means that I have light paths that are, that have a ridiculous low probability to be visited. And that means that my sampling strategies are not smart enough.

Speaker 1:          24:08          And this is a classical, longstanding problem in global illumination.

Speaker 2:          24:14          Okay?

Speaker 1:          24:15          Metropoulos is not a solution for this. It is still not good enough, but there are techniques that can give you a really smooth results on ridiculously difficult scenes like this. And I will also explain you during the next lecture. Why is this essentially difficult? Because it doesn't seem to intuitive does it? But I will explain to you during the next lecture. Thank you very much.