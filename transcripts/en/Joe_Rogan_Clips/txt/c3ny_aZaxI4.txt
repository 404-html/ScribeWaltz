Speaker 1:          00:00          Using an algorithm though, do you not miss context? I mean it seems to me that there's a lot of people that say things in humor, you know, or, or slurs within particular communities, which is perfectly reasonable, right? So yes, there is a danger of the algorithm is missing context and that's why we, we really want to go carefully into this and this is why we've scoped it down first and foremost to doxing, which is at least first it hits her number one goal of protecting physical safety. Like making sure that nothing done online will impact someone's physical safety on offline, on our platform in this case. The second is that there are patterns around doxing that are much easier to see without having the context. There are, there are exceptions of course, cause you could docs, um, someone's public, you know, uh, uh, representatives, public, uh, office, phone number and email address.

Speaker 1:          00:52          And the algorithm might catch that, not have the context that this is a US representative and this information is already public. So essentially this just, it highlights how insanely difficult it is to monitor all of these posts. And then what, what is the volume? Like what, what are we dealing with? Like how many posts do you guys get a day? Hundreds of millions of posts a day. And how many human beings are manually reviewing any of these things? I don't have that, that number. A lot. Thousands. Hundreds of thousands. How many employees? You guys have 4,000 employees around the world. That's it. We have 4,000 employees. The reason that's crazy though, but stop and think about that. 4,000 people that are monitoring hundreds of millions of tweets. And uh, we, we have, uh, we have, uh, we have a small team who's monitoring tweets and some of them are employed by us.

Speaker 1:          01:42          Some of them are contractors throughout, throughout the world. So 4,000 employees, total, 4,000 employees who are engineers, who are designers, who are lawyers so that people actually monitoring tweets is probably less than a thousand. Uh, well the reason we don't give out specific numbers is we need to scale these dynamically, right? If we see a particular event within, uh, within country, we might hire 100 more people on contract to deal with it, whereas they may not be full and, and with us the entire time, or they have the ability to take down tweets. Uh, they have, they have the, so as we get reports, it goes into a queue and those are ranked by severity. And then we have people who look at our rules and look at the, look at the tweets and look at the behavior and the context around it. And they have the ability to go down that enforcement spectrum. The vigil talked about one, make people log in, read why it's a violation over tweet and delete it to temporary suspensions. And finally, a permanent suspension, which is the absolute last resort, which we ultimately do not want to do. We want to make sure that our rules are also guided towards incentivizing more healthy conversation and, and more, more participation. Yeah.