Speaker 1:          00:00          Thanks for having me. I listened to you on Sam Harris' podcast and I was utterly stunned. I had to listen to it twice cause I just couldn't believe it. Let's get into, let's get into this from the beginning. How did this start out? How did you start researching these, a online Russian trolls and bots and all this jazz?

Speaker 2:          00:18          Yeah, so a couple of years back in around 2015, um, I, I had had my first baby in 2013 and I was getting on these preschool lists. And what I decided to do was I started looking at, um, anti vaccine activity in California because I had a kid and I wanted to, uh, you know, put them on preschool lists or I was going to fit with the parents basically. Um, as someone who vaccinates and I started looking at the way that small groups, we're able to kind of disproportionately amplify messages on social channels. And some of this was through very legitimate activity. And then some of it was through really kind of coordinated deliberate attempts to kind of game, um, ways that algorithms were amplifying content, amplifying particular types of narratives. And I thought it was interesting and I started writing about it and I, um, I wound up writing about ways in which, um, hashtag gaming, um, ways in which people were kind of using automation to just be in a Hashtag all the time.

Speaker 2:          01:14          So it was kind of a way to really gain control of share voice and what that meant when very small groups of people could achieve this kind of phenomenal amplification and what the pros and cons of that were. And then this was, um, 2015. So the way that, that this sort of, um, awareness of social media challenges came, came about was actually when I was working on this. Other people were looking at it from the same, um, looking at the same tactics, but how they were being used by Isis, by the terrorist organization. And they're also, you had this very small group of people that manage to use bots and amplification to really kind of own a narrative, really pushed this, this brand is this digital caliphate to kind of build it on all social platforms almost simultaneously. And the ways in which information was hopping from one platform to another, um, through kind of deliberate coordination and then also just ways in which information flows, kind of contagion style.

Speaker 2:          02:06          Um, and I wound up working on thinking about how the government was going to respond to the challenge of terrorist organizations using American social platforms to spread propaganda. Uh, so what we came to realize was that there was just this information ecosystem and it had evolved in a certain way over a period of about eight years or so. And the kind of unintended consequences of that and the way that Russia kind of, uh, came into the conversation was around October, 2015 when we were thinking about what, what to do about Isis, what to do about terrorism and terrorist, uh, you know, kind of proliferation on social platforms. This was right around when Adrian Chen had written the article, the Agency for the New York Times. And that was one of the first big expos A's of the Internet research agency. The first time an American journalist had gone over there and actually met the trolls, been in Saint Petersburg and began write about what was happening over there and the ways that they had pages that we're targeting certain facets of American culture.

Speaker 2:          03:06          So while we were in DC talking about what to do about terrorists using these platforms to spread propaganda, there were beginning to be rumblings that Russian intelligence and you know, Russian entities, we're doing the same thing. And so the question became can we think about ways in which the Internet is vulnerable to this type of manipulation by anyone? And then, um, and then come up with ways to stop it. So that was how the Russia investigation began, was actually around 2015 and a handful of people started looking for evidence of Russian bots and trolls on social platforms.

Speaker 1:          03:40          So 2015 if we think about social media and the birth of social media, essentially, it had only been alive for, I mean, what was Twitter, 2007 I believe. Think so, yeah, something like that. So eight years, like eight years of social media. And then all the sudden they figured out how to game the system and then they figured out how to use this to make people argue against each other.

Speaker 2:          04:06          Yeah, I think so. There was this, if you go back to like, um, I remember like Geo cities and they all use that. Um, so we're probably about the same age. Um, so there have always been, you know, kind of the thing thing that was great about the Internet, like Internet 1.0, we can call it right, was this idea that everybody was given a platform and you could use your platform, you could put up your blog, you could say whatever you wanted. Um, you didn't necessarily get attention, but you could say whatever you wanted. And so there is this kind of consolidation as, as social platforms kind of came into existence, content creators. We're really excited about the fact that now they not only had this, um, this access to write their own stuff, but they also had access to this audience because as the network effects got more and more pronounced, more and more people came to be on social platforms.

Speaker 2:          04:54          And in originally it wasn't even Facebook. If I remember, it was like, you know, there's like Friendster and myspace and social networks kind of evolved. When I was in college, Facebook was still limited to like, you know, a handful of like Ivy League schools. And so I wasn't even eligible. And as you watch this consolidation happen, you start to have this information ecosystem really dominated by a handful of companies that grow very large because they're providing a service that people really want. Um, but there's a kind of mass consolidation of audiences onto this handful of platforms. So this becomes really interesting for regular people who just want to find their friends, reach people, spread their message, growing audience. It also becomes really interesting for propagandists and trolls and in this case terrorist organizations and state intelligence services. Cause instead of reaching the entire Internet, they really just kind of have to concentrate their efforts on a handful of platforms. So that consolidation is one of the things that kind of kicks off some of the, um, one of one of the reasons that we have these problems today,

Speaker 1:          05:53          right? So the, the fact that there's only a Facebook, a Twitter and, and a couple other minor platforms other than Youtube, I mean anything that you can tell it's an actual person like youtube, that is a problem, right? Because you could see it's an actual person. If you're of, you're narrating something, you, you know, if you're in front of the camera and explaining things and people who going to know that you're an actual human being. Whereas there's so many of these accounts that I'll go to, like I'll, I'll watch people get involved in these little online beefs with each other and then I'll go to some of these accounts. I'm like, this doesn't seem like a real person. And I'll go and it's like Hashtag Magda, there's a American Eagle in front of a flag and then you read their stuff and you're like, wow, this is, this is probably a Russian troll account. And it's strange, like you feel like you're not supposed to be seeing this. Like you've seen the wiring under the board or something and then you'll go through the timeline and all they're doing is engaging people and arguing, you know, for Trump and against, you know, whatever the fuck they're angry about, whatever, whatever it is that's being discussed. And they're, they're basically just like some weird little argument mechanism.

Speaker 2:          07:02          Yeah. So in 2016, um, there was a lot of that during the presidential campaign, right. And there were, um, there was so much that was written, you know, we can go back to the free speech thing we were kind of chatting about before. There was so much that was written about harassment and trolling and negativity and these kind of hoards of accounts that would brigade people and harass them. Of course, a lot of that is just real Americans, right? There are plenty of people who are just assholes on the Internet. Sure. Um, but there were actually a fair number of these as we began to do the investigation into the Russian operation in, uh, it started on Twitter and about, um, 2014, actually, so 2013, 2014, the Internet research agency is targeting Russian people. So they're tweeting in Russian, at Russian and Ukrainian, uh, folks, people in their sphere of influence.

Speaker 2:          07:50          So they're already on there. They're already trying this out. And what they're doing is they're creating these are these, these accounts, it's kind of wrong to call them bots because they are real people. They're just not what they appear to be. So I think the unfortunate term for it has become like Cyborg, like semi automated. You know, sometimes it's automated, sometimes it's a real person, but a sock puppet is the other way that we can refer to it. A person pretending to be somebody else. So you have these sock puppets and they're out there and they're tweeting. And in 2014 about the Russian annexation of Crimea or about mh 17. That plane that went down with Russia, you know, of course I had no idea what happened and it wasn't their fault at all. And gradually as they begin to experience what I imagine they thought of what success, that's when you see some of these accounts pivot to targeting Americans.

Speaker 2:          08:37          And so in 20, late 2014, early 2015, you start to see the, um, the strategy that for a long time had been very inwardly focused, making their own people think a certain way or feel a certain way or have a certain experience on the Internet. Uh, it begins to spread out. It begins to, uh, to look. And so you start to see these accounts communicating with Americans. And as we were going through the datasets, which the Twitter data set is public, anyone can go and look at it at this point. Um, you do see some of the accounts that are kind of, um, you know, that were, that were somewhat notorious for being really virulent, nasty trolls. I'm antisemitic trolls going after journalists. You know, some of these accounts, um, being revealed as actually being a Russian trolls now it doesn't kind of, um, exculpate the actual American trolls that were very much real and active and part of this and expressing their opinion. But you do see that they're mimicking this. They're using that same style of tactic, that harassment to, to get it real people.

Speaker 1:          09:39          Then if they do get banned, if their account gets banned, they just simply make another account. They use some sort of, uh, you know, um, what is it, a virtual virtual server, what does that call mean? Vpns are, that's, yeah, so if they do that, they can kind of do that as long as they want. They can continue to make new accounts and it probably also emboldens the actual American trolls because they're going to go out a little bit further than everybody else. A little bit crazier. And it kind of changes the tone of discourse within these communities that are arguing about a certain subject. Things get nastier and they're getting nastier because of the interference of these trolls. Like, it seems like they've, they've actually managed to not just cause a lot of discourse, but to change the way people are interacting with each other and to make it just make it more, more vicious.

Speaker 2:          10:33          Yeah. So the, what they're doing is they're operating in communities. So one of the really common criticisms of, you know, people who, um, lot of people think that this didn't have a huge impact. You know, did it swing the election? We have no idea. Um, but the, what it does do in the communities that it targets is it can change that tone. And that's where you see, um, it's, it's, I mean, think everybody's probably had this experience, you're part of a group and then a new person gets added to the group and the dynamic changes. It's very much the same kind of thing, just that these are not real people who are joining the group. Uh, and so there's this, um, opportunity to, to, to, you know, kind of expand the balance of tolerance just that little bit more or try to normalize using particular ways of communicating that maybe a group wouldn't naturally gravitate to. But then it does. So there, there are definitely a ways in which any, any type of troll doing this doesn't have to be a Russian troll, has this ability to kind of shift the language of the community, shifts the culture just a little bit.

Speaker 1:          11:36          Now, when did, why did the agency do this and do we do we know, do we have someone who's ever left there or become a whistle blower who can give us some information about what the mandate was and how it was carried out?

Speaker 2:          11:51          There've been a couple of a whistle and actually some investigative journalism in Russia that's, that's covered this. Um, they describe the, the employees of these as the Internet research agency. So it's a little bit like a social media marketing agency plus, um, tactics that we would not expect a social media marketing agency to use. Things that are a little more like what you would expect to see from an intelligence agency. So besides just making your pages in your blogs and your social posts, they're also in their kind of, uh, connecting with real people and real activists and pretending to be something that they're not to develop kind of a one on one relationship, but most of the, most of the, um, the whistle blowers who have come out, there's a woman named Ludmila savage, chuck. Um, she wrote an expos I believe on this. And it's described as being much like you would expect if you were doing social media grunt work.

Speaker 2:          12:43          Um, you have a certain number of posts per day. You, you know, you're driving, trying to get a certain amount of engagement. Um, you're trying, you've got to kind of hit your quotas. Most people are young millennials, the people that work there, um, they're well versed in trolling culture. They're well versed in internet culture. You know, they're up to speed on like popular memes and things like that. And so you do see, um, this, yeah. And then the other thing that they do is they talk about in Mueller indictment, you see some really interesting descriptions of like the standups that they have stand up as a thing you do at a tech company. Everybody kind of stands up and talk about your, uh, goals and responsibilities and blockers and things. And in the standups they would be sitting there saying things like, um, if you're targeting black LGBT people, make sure you don't use white people in your, in your image and your mean because that's going to trigger them.

Speaker 2:          13:30          Um, you know, so trying to get at the, the very niche, um, rules for, you know, for communicating authentically and an American community, which is, you know, online, you know, you sometimes, um, there are very specific ways in which a community expects a member of that community to communicate. And so they are in there and you can read in these filings by Mueller's team and by the Eastern District of Virginia. Um, the, the, the degree of granularity that they have to recognize that if you are running a black LGBT page and your meme is of white people, you're going to cause some tension and consternation and assuming that that's not necessarily what you want to be doing, you should go find the meme of black LGBT people to put in the, you know, to, to put as your meme for the day. So there's a lot of, um, there's a lot of sophistication, there's a lot of understanding of American culture and then there's a lot of understanding of trolling culture.

Speaker 2:          14:25          And so these things combined to be a rather effective, uh, you know, very effective social media agency. Then is there an overwhelming sort of narrative that they're trying to pursue? The trying to push. So what we saw, so I did the, um, I did some of the research for the Senate and the Senate data came from the platforms. So what I had was, um, the attribution was made by the platforms. It wasn't like Renee deciding this was IRA. It was, uh, the giving it to, uh, to our government and the information in there. Um, what it showed was that across all platforms, across Twitter, across Facebook, Instagram, youtube, they were building up tribes. So they were really working to create distinct communities of distinct types of Americans. And that would be, for example, there's an LGBT page that is very much about LGBT pride. There is, uh, created it and they created it.

Speaker 2:          15:22          And Dave, they curate it and they create it, curate it. Um, it has a, you know, they're just like a persona. A lot of the posts on the LGBT page were written by what sounded kind of like a millennial lesbian was the voice. Um, so it was a lot of, um, you know, memes of LGBT actresses and they would brand it with a specific brand. Market was a rainbow heart. Um, uh, LGBT United was the name of the page. It had a matching Instagram account, which you would also expect to see from a media property. Right? You would expect them to see in both places. And this, um, you know, it read like a, or like a young woman talking about, um, crushes on actresses and things. Actually, you know, it was, it was, it was really besides the sometimes walking English virtually indistinguishable from what you had read on any kind of like young millennial focused, um, social page.

Speaker 2:          16:14          It wasn't a, none of it was radical or divisive. It wasn't like, um, the way that they got the division across was they built these tribes where they're reinforcing in group dynamics. So you have the LGBT page, you have a numerous pages targeting the black community. That was where they spent most of their energy. A lot of pages targeting, um, far right? So, uh, both old far right, meaning, um, people who are very concerned about what does the future of America look like. And then young, far right, which was much more angry, much more like trolling culture. So they recognize that there's a divide there that the kinds of memes you're gonna use to target younger rightwing audiences are not the same kinds of memes are going to use to target older right wing audiences. So there's a tribe for older rightwing younger, right wing and the black community.

Speaker 2:          17:04          There's a baptist tribe, there's a black liberation tribe, there's a black women tribe, there's one for people who have incarcerated spouses. There's a brown, I'm Brown. Power I believe was the name of it page. That was very much about, um, Mexican and Chicano culture. There was native Americans United. All these are fake. All of these are fake. What are they trying to do with all these? So you build up this in group dynamic and over, and he did this over years. So this was not a short term thing. They started these pages and 20, 14, 20, 15 timeframe, most of them. Um, they started some other ones that were much more political later. And we can talk about the election if you want to, but with this tribal thing, um, you're building up tribes here saying like as black women in America, this is, um, here's posts about things that we care about.

Speaker 2:          17:54          Here's posts about black hair, here's posts about child rearing, here's posts about fashion and culture. And then every now and then there would be a post that would reinforce like as black people, we don't do this. And so, or as LGBT people we don't like this. And so you're building this report. So like me and you were having a conversation, we're developing a relationship on this page over time. And then I say like as this kind of person, we don't believe this. So it's a way to subtly influenced by appealing to an ingroup dynamic or appealing to like as members of this tribe, as LGBT people. Of course we hate Mike Pence as black people. Of course we're not going to vote because you know, we hate Hillary Clinton because we hate her husband as, um, as people who are concerned about the future of America is Texas assumptionists you know, so, so everything is presented as members of this tribe. We think this as members of this tribe, we don't think this but a lot. That's why you see the,

Speaker 1:          18:56          I had a lot of, the posts were not even political, they were just sort of affirming the standards of the tribe. Yes. So they were kind of setting up this whole long game. Yep. And then once they got everybody on board or how many followers are these, do these pages have?

Speaker 2:          19:13          So the, there was kind of a long tail. There were um, I think 88 pages on Facebook and 133 Instagram accounts. And I would say maybe 30 of the Facebook pages had over a thousand followers, which is not very many. And then, um, maybe the top 10 had upwards of 500,000 followers. So there's, you know, same way you run any social campaigns. Sometimes you have hits, sometimes you have flops. Right. And what was interesting with the flops as you would see them repurpose them so they would decide, you know, the same way if you're running a social media agency, well we've got this audience, this page isn't doing so well. It's like rebrand it a little bit, change it up, try to, um, try to make it appeal to somebody else. So you do see this, there is a, there is, um, I got this data set and I was going through these Instagram memes and you know, 130, 3000 of them.

Speaker 2:          20:05          And I was um, there was a cluster of images of Kermit the frog. I was like, what the hell is Kermit the frog doing in here? And so I, so then I go, so this, the, the way the platforms provide the data is I got like a CSV of the posts and then I got a folder of the images. And so in order to like connect the dots, I had to have the image up on one screen. And the, this I'm thinking to the CSP up on the other screens, it's like a spreadsheet. Okay. Yeah. And I, and we turned it into a database that we could track things a little bit more easily across the platforms. But, um, so I have this cost of Kermit the frog memes. And I go and I look and I realize that the, they're attributed to an account army of Jesus.

Speaker 2:          20:49          And I thought, well, that's interesting. What did you know? These are, some of them are really Raunchy is like, it was like Kermit, Miss Piggy, like, you know, I mean it was just like, like stupid, stupid, crappy memes. Um, attached to army of Jesus and what the Hell is going on here? I keep going through it. Hundreds of Kermit memes and then I get to a post where they say like, um, this page is owned by homer Simpson. Now Kermit went to jail for being like, I don't know, they made some like some joke. It was stupid. And all of a sudden the data set turns into homer Simpson memes. So again, like this kind of Raunchy homer Simpson culture, um, and again, it's attributed to army of Jesus. And then I go through all of this and realize that they didn't get to actually making army of Jesus a Jesus focused page until like 900 posts in.

Speaker 2:          21:37          So the, they just renamed the account at some point. It used to be called nuts news. And then they nuts news was what they called it when it was the Kermit the frog meme page. And then it gets repurposed when they realized Kermit's not doing it. It's not getting the audience they want homer Simpson's not getting the audience or engagement they want. And then they pivot over to Jesus and then all of a sudden they start, you know, the likes and, and things start pouring in. So what they're doing is they're actually like either deliberately or they're just creating placeholders. Um, it's kind of a red flag when a brand new account that was created yesterday suddenly starts talking about some highly politically divisive thing or whatever. But if you lay the groundwork and you do it over a period of two years, then somebody who goes and checks to see what the account was, where it came from, how old it is.