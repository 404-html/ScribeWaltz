Speaker 1:          00:00          No. Well, yeah, it's not the experience for everyone and it's not really, I don't think it's what everyone wants either. Sometimes people just like to go on there and talk shit. I mean, as someone that's trapped in a cubicle right now, it's true and they just want to go on there and get in arguments about gun control or you know, whether or not Nancy Pelosi's the devil, I mean this is, this is what you know, it, it serves a purpose for them. The thing that gets strange though is who's to decide, you know, there's this is this concept, there's a discussion I should say where, uh, some people believe that things like Twitter or Facebook or any forum where you're having a public discussion should be considered almost like a public utility. Like anyone has access to the electric power. Even if you're, you know, even if you're a racist, you still can get electricity and some people think that you should have that same ability with something like Twitter or the same ability with something like Instagram.

Speaker 1:          00:56          Obviously this is, we're in uncharted territory and you are, you are in uncharted territory. It just, no one has been there before. So who makes the distinctions when you see someone that, that it's saying something that you might think is offensive to some folks but not offensive to the person who's saying it. Maybe the person who's saying it feels like they need to express themselves. And this is important to say and how do you decide whether or not this is a valid discussion or if this is air quotes, hate speech, which is, you know, there's some things that are hate speech and there's sometimes people use the term hate speech and it's just a cheap way to shut down a conversation. Yeah. We, so the simple answer is we look at conduct. We don't, we don't look at the speech itself. We look at conduct, we look at how the tool is being used.

Speaker 1:          01:46          And you're, you're right in that. Like I think when people see Twitter, they see and they expect it to be a public square. They can go into that public square. They can say whatever they want to, can get on a pedestal. Um, and people might gather around them and listen what they have. So some of them might find it offensive and they leave. The difference is there's, there's also this concept of this megaphone in the megaphone can be highly targeted now with Twitter as well. Right? So it's not, it's not the, it's not the speech, it's how it's amplified. So what do you do? It's like say let's, let's say there's someone in the media, uh, let's say it's a prominent feminist and then you have a bunch of people or let's say just one person and their Twitter feed is overwhelmingly attacking this prominent feminist, just constantly attacking or calling her a liar, calling her this calling that when do you decide this is harassment?

Speaker 1:          02:41          When decide this is hate speech, when like how do you, I mean this is a look at the conduct, an absolute, this is a fictional account write fictional person we're talking about. But in this for instance, what, what would dictate something that was egregious enough for you to eliminate them from your platform? Well, that's a, that's a, that's a heavy action. So that's the last resort. Um, but we look at the conduct, we look at oftentimes as you said, like the, the probability of someone who is harassing one person. It's highly probable that there also harassing 10 more people. So we can look at that behavior. We can look at how many times this person is being blocked or muted or a reported. And based on all those, um, all that data, we can actually take some action. But we also have to, we have to correlate it with the other side of that because people go on and they coordinate blocks as well and they coordinate harassment and they, and they coordinate, I'm sorry, not harassment, but reporting, um, uh, reporting a particular account to get it shut down into, uh, to take the voice off the service.

Speaker 1:          03:52          So these are the considerations we have to make, but it's, it's, it all starts with conduct and oftentimes they'll see coordinated conduct, whether it be that one person opening multiple counts or coordinating with multiple accounts that they don't own to, you know, go after someone. And there's a bunch of vectors that people use retweet for that, uh, the quote tweet for that a lot as well. Like, you know, they'll quote tweet a tweet that someone finds and they'll say, look at this idiot Twitter, do your thing. And then just this mob starts and goes and tries to, uh, effectively shut that person down. Um, so there's a bunch of tools we can use. The permanent suspension is the last resort. One of the things that we can do is we can down rank the replies. So any of these, any of these behaviors and conduct that looks link linked, we can actually, uh, push farther down in the reply chain.

Speaker 1:          04:49          So it's all still there. But you might have to push a button to actually see it. You might have to see, show more replies to actually see, uh, this harassing account or what might look like harassing language. And this is manually done. This is, this is all, this is all automated. It's automated. Yeah. Yeah. But how would you, a lot of the ranking in the, and looking at amplification and looking at the network is, is automated, right? Like, in terms of down ranking, is there a discussion as to whether or not this person's reply, she'd be down ranked? Like how do you, how do you figure that out? It's, it's a machine learning and deep learning model and they just say it's Ai and they, and they learn, you know, and we, we look at, um, we look at how these things are doing and where they make mistakes and then we improve it.

Speaker 1:          05:35          It's just constantly improving, constantly learning. And does that feel like censorship to you? Like automated censorship is, I mean, who, who's to decide other than people, whether or not something is valid? Well, we're not, we're not looking at the, at the speech. In this particular case, we're looking at the conduct, the conduct, the conduct of like someone in fast philocity attacking someone else. Okay. Right. So those are the things that our technology allows. It changes the velocity changes. Uh, how, um, you know, to broadcast semesters that someone didn't really ask for and didn't want to hear. We don't touch, if I follow Joe Rogan, you'll see every single tweet. We don't touch it. Right, right. But that's an audience that you earn. But in your replies page, we have a little bit more room because this is a, this is a conversation that starts up in, some people just want to disrupt it. And all we're saying is we're going to look at moving the disruption down. Not that it's hidden, but it's still there. But you know, you just see it a little bit farther down.