Speaker 1:          00:00          My question is like, I know how much time you must be spending on your Tesla factory. I know how much time you must be spending on space x and yet you still have time to dig holes under the ground in La and come up with these ideas and then implement them. Guess

Speaker 2:          00:14          I got a million ideas. I'm sure you did. No shortage of that. Yeah.

Speaker 1:          00:18          I just don't know how you manage your time. I don't understand it. It doesn't seem, it doesn't even seem humanly possible.

Speaker 2:          00:25          You know, I do. Basically, I think we all like don't totally understand what I do with my time. They think like I'm a business guy or something like that. Um, like my Wikipedia page says business magnate, what would you call yourself? A business magnet. Kids aren't, please change my Wikipedia page two magnet. They'll change it right now it's locked. So somebody has to be able to unlock it and change it to magnets. Yeah. What did we have magnet? Um, no, I, I, I do engineering and you know, and manufacturing and that kind of thing. That's like 80% or more of my time ideas. And then the implementation of those ideas that was like hardcore engineering, like yeah, designing things, you know? Right. Structural, mechanical, electrical, software, a user interface, engineering, aerospace, engineering.

Speaker 1:          01:21          But you must understand this, not a whole lot of human beings like you. You know that, right? So you're an audit teams. Yes. Chimps like me, we're all chimps. Yeah, we are. We're one notch, one notch above a chimp. Some of us are a little more confused when I watched you do and all these things. I'm like, how does this motherfucker have all this time and all this energy and all these ideas and then people just let them do these things

Speaker 2:          01:45          because I'm an alien.

Speaker 1:          01:46          That's what I've speculated. Yes. I'm on record saying this in the past. I wonder. It's true. I mean if there was one, I was like, if there was like maybe an intelligent being that we created, you know, like some AI creature that's a superior to people. Maybe they just hang around with us for a little while like you've been doing and then fix a bunch of shit. I mean that's the way that might have some rotation or something like that. You might, do you think you do? Probably. Do you wonder like are you around normal people? You're like, hmm. You like, what's up with these boring dumb mother fuckers ever?

Speaker 2:          02:20          Not Bad for a human, but I think it will not be able to hold a candle to AI.

Speaker 1:          02:29          Hmm. You scare the shit out of me when you talk about Ai between you and Sam Harris. Oh sure. Consider it until I had a podcast with Sam once was great. He made me Shit my pants. Talking about Ai, I realize like, oh well this is a genie that wants, it's out of the bottle. You never getting it back in.

Speaker 2:          02:46          That's true.

Speaker 1:          02:48          There was a video that you tweeted about one of those Boston dynamic robots and you know like in the future it'll be moving so fast you can't see it without a strobe.

Speaker 2:          02:59          Yeah. You could probably do that right now

Speaker 1:          03:03          and no one's really paying attention too much other than people like you or people that are really obsessed with technology. All these things are happening and these robots are, and did you see the one where it, to Pete Peta put out statement that you shouldn't kick robots? It's probably not wise for retribution there. Their memory is probably good. I bet it's really good. It's really good. I bet it is. And getting better every day. It's really good. Are you honestly legitimately concerned about this? Are you, is like AI one of your main worries in regards to the future?

Speaker 2:          03:41          Yes. It's less of a worry than it used to be a mostly due to taking more of a fatalistic attitude. Mm.

Speaker 1:          03:51          So you used to have more hope and you gave up some of it and now you don't worry as much about AI you like this is just what it is.

Speaker 3:          04:03          Yeah,

Speaker 2:          04:03          pretty much. Yes. Yes. It's, it's no, it's not necessarily bad. It's just, it's definitely going to be outside of human control. Not necessarily bad. Right? Yeah, it's not, it's not necessarily bad, it's just, it's just outside of human control. Now, the thing that's going to be tricky here is that it's going to be very tempting to use AI as a weapon. That's going be a very tempting, in fact, it will be used as a weapon. Um, so the, the, the, the onramp to serious AI, the danger is going to be more humans using it against each other. I think most likely that'll be the danger. Yeah.

Speaker 1:          04:53          How far do you think we are from something that can make its own mind up? Whether or not something's ethically or morally correct or whether or not it wants to do something or whether or not it wants to improve itself or whether or not it wants to protect itself from people or from other Ai. How far away are we from something that's really truly sentient?

Speaker 2:          05:16          Well, I mean you could argue that any group of people like it, like a company is essentially a cybernetic collective of people and machines. That's what a company is.

Speaker 2:          05:34          And then there are different, there's different levels of complexity in the way these companies are formed. And then there are sort of does this or like a collective AI and in the Google sort of search, Google search, you know the, where we're all sort of plugged in as like nodes. The network like leaves on a big tree off and we're all, we're all feeding this network without questions. Announcers, rural collectively programming, Bai and that and Google plus the, all the humans that connect to it are one giant cybernetic collective. This is also true of Facebook and Twitter and Instagram and all these social networks. The giants, I haven't had a collectives

Speaker 1:          06:31          and humans and electronics all interfacing and constantly now constantly connected.

Speaker 2:          06:36          Yes. Constantly.

Speaker 1:          06:39          One of the things that I've been thinking about a lot over the last few years is that one of the things that drives a lot of people crazy as how how many people were obsessed with materialism and getting the latest greatest thing. And I wonder how much of that is, well, a lot of it is most certainly fueling technology and innovation and it almost seems like it's built into us to like what we like and what we want. That we're fueling this thing that's constantly around us all the time and it doesn't seem possible that people are going to pump the brakes. It doesn't seem possible at this stage. We'll work constantly [inaudible] newest cell phone, the latest Tesla update the newest Mac book pro, but everything has to be newer and better and that's going to lead to some incredible point. And it, it seems like it's built into us and almost seems like it's an instinct that we were working towards this, that we'd like it. Our job, just like the ants build the ant hill, our job is to somehow know the fuel. This.

Speaker 2:          07:42          Yes. Um, I mean I made those comments some some years ago but it feels like we are the biological bootloader for AI. Effectively. We are building it and then we are building progressively greater intelligence and the percentage of intelligence that is not human is increasing and eventually we will represent a very small percentage of intelligence. But the, the AI is informed strangely by the human limbic system. It is in large part our Ed Red Lodge. How so? Well you mentioned all those things, the sort of primal drives. Um, there's all whole things that we like and hate and fear. They're all there on the Internet. The projection of our limbic system.

Speaker 1:          08:57          No, it makes sense. The thinking of it as a, I mean think of thinking of corporations and just thinking of just human beings communicating online through these social media networks as some sort of an organism. That's a, it's a Cyborg. It's a combination. It's a combination of electronics and biology. Yeah.

Speaker 2:          09:18          This is, it's a, it's a measure like it's the success of these online systems is that is f is sort of a function of, of how much limbic resonance they're able to achieve with people. The more limbic resonance, the more engagement.

Speaker 3:          09:38          Mm.

Speaker 1:          09:39          Whereas like one of the reasons why I probably Instagram is more enticing than Twitter. Limbic resonance. You get more images, more video. Yes. It's tweaking your system more. Yes. Do you worry about what or wonder in fact of what the next step is? A lot of people didn't see Twitter coming that, you know, communicate with 140 characters or 280 now would be a thing that people would be interested in. Like it's going to excel, it's going to become more connected to us, right?

Speaker 3:          10:13          Yeah.

Speaker 2:          10:13          Yes. Things are getting more and more connected there. At this point, constrained by bandwidth. Our input output is low, particularly output. Awkward got worse with thumbs. You know, we used to have input with 10 10 fingers, no, we have thumbs, but images are just oral. So are there a way of communicating at high bandwidth? You take pictures and you send pictures of people, let's sends, that's, that communicates far more information than you can communicate with them.

Speaker 1:          10:43          So what happened with you where you decided or you took on a more fatalistic attitude? Like what? Was there any specific thing or was it just the inevitability of our future?

Speaker 2:          11:03          I tried to convince people to slow down, slow down AI to regulate AI. This was futile. I tried for years.

Speaker 1:          11:16          Nobody listened in a movie, nobody robots, good fucking take over and you're freaking me out. Nobody listened. Nobody listens. No one are people more inclined to listen today. It seems like an issue that's brought up more often over the last few years than it was maybe five, 10 years ago. It seemed like science fiction,

Speaker 2:          11:35          maybe they will. So far they haven't.

Speaker 2:          11:41          I think people don't like the normally the way that's regulations work. It was very slow, very slow indeed, so usually it'll be something some when your technology will cause damage or death, there will be an outcry. There will be an investigation. Years will pass. There will be some sort of insight committee. They will be rulemaking than there will be oversight. Eventually regulations. This all takes many years. This is the normal course of things. If you look at say what a motive regulations, how long did it take for seat belts to be, to be implemented? To be required. You know, the auto industry fought seat belts, I think for more than a decade, successfully fought any regulations on seat belts, even though the numbers were extremely obvious, if you had a seat belts on, you would be far less likely to die or be seriously injured. Unequivocal. And the industry fought this for years successfully. Eventually after many, many people died, regulators insisted on the belt. This is a first timeframe is not relevant to AI. You can't take 10 years from the point of which is dangerous. It's too late.

Speaker 1:          13:16          And you feel like this is decades away or years away from being too late. If you have this fatalistic attitude and you feel like it's going well, we're in a, almost like a doomsday countdown. It's not necessarily a doomsday countdown. It's, it's a out of control. Countdown out of control.

Speaker 2:          13:37          Yeah. Maybe we'll call it the singularity. And uh, that's, that's probably a good way to think about it. It's, it's a single hour. It's hard to predict like a black hole. What, what happens past the event horizon?

Speaker 1:          13:48          Right. Sort of, once it's implemented, it's very different because it, it wants to take us out of the bottle, what's going to happen and it will be able to improve itself. Yes. That's where it gets spooky. Right? The idea that it can do thousands of years of innovation, we're very, very quickly. Yeah. And then we'll be just ridiculous. Ridiculous. We will be like this ridiculous biological shitting pissing thing trying to stop the gods now stop. We like, we like living with a finite lifespan and, and watching, you know, Norman Rockwell paintings,

Speaker 2:          14:24          it could be terrible and it could be great. It's not clear. Right. But one thing is for sure we will not control it.

Speaker 1:          14:32          Do you think that it's likely that we will merge somehow or another with this sort of technology and it will augment what we are now or do you think it will replace us?

Speaker 2:          14:48          Well, that's the scenario. The, the, the merge with AI is the one that seems like probably the best for us. Yes. Like if you, if you can't beat it, join it. That's, yeah. You know? Um, so from a long term existential standpoint, that's like the purpose of neurolink is to create a high bandwidth interface to the brain such that we can be some arctic with AI because we have a bandwidth problem. You just can't communicate through your fingers is too slow. And where's neural link at right now?

Speaker 2:          15:37          I think we'll have something interesting to announce in a few months. That's at least an order of magnitude better than anything else. Probably I think better than probably anyone thinks is possible. How much can you talk about that right now? I don't want to jump the gun on that. Um, but what's like the ultimate, what's, what's the idea behind it? Like what are you trying to accomplish with it? Like what would you like best case scenario? I think best case scenario, we effectually emerge with AI where we ais serves as a tertiary cognition layer, uh, where we've got the limbic system. I'm kind of the planning of the primitive brain. Essentially. You've got the CORTEX. So you're currently in a symbiotic relationship with your cortex and limbic system or in a symbiotic relationship. And generally people like their cortex and they liked the limbic system. I haven't met anyone who wants to delete their limbic system or to lead their cortex are very seem sort of like both.

Speaker 2:          16:37          And the CORTEX is mostly in service to the limbic system if you will. May think that that, that they're, that they're thinking part of themselves is in charge, but it's mostly their limbic system that's in charge and the cortex is trying to make the limbic system happy. That's what most of that computing power is oriented towards. How can I make the limbic system happy? That's what I was trying to do. Now if we do have a third layer, which is the AI extension of yourself, that is also some biotic, um, and there's enough bandwidth between the cortex and the AI extension of yourself such that the AI doesn't de facto separate, then that could be a good outcome. That could be quite a positive outcome for the future. So instead of replacing us, it will radically change our capabilities. Yes it will. It will enable anyone who wants to have super human cognition. Anyone who wants it. This is not a matter of earning power because you're earning power would be vastly after you do it. So it's just like anyone who wants can just do it in theory. That's the theory. And, and if that's the case then and let's say billions of people do it, then the outcome for humanity will be the sum of, of human will. Some of billions of people's desire for the future.

Speaker 1:          18:20          And that deputy ends of people with enhanced cognitive ability radically enhance. Yes. Which would be how much different than people today. Like if you, if you had to explain it to a person who didn't really know and understand what you're saying, how much different are you talking about when you say radically improve? Like what do you mean? You mean mine?

Speaker 2:          18:45          It will be difficult to, to really appreciate the Dif, the difference. Um, it's Kinda like how much smarter are you with a phone or computer then without it's you're vastly smarter. Actually, you know, you can answer any question if you're, if you're connected to the Internet, you can ask her any question pretty much instantly. Any calculation that your phone's memory is essentially perfect. Uh, you can remember flawlessly for your phone, can remember videos, pictures, everything perfectly. That's the, that your phone is already an extension of you. You're already a Cyborg. You don't even, well most people don't rise. They are already a Cyborg. If that phone is an extension of yourself, it's just that the, the data rate, the rate at which there's a communication rate between you and the cybernetic extension of yourself that is your phone and computer is slow. It's very slow and and that that it's like a tiny straw of of of information flow between your biological self and your digital self and we need to make that tiny straw like a giant rower. Huge high bandwidth interface interface, problem data rate problem. I saw the data rate a problem. Then I think I think we can hang on to human machine symbiosis through the long term and then people may decide that they want to retain their biological self. We're not, I think they'll probably choose to retain their volume by electrical self

Speaker 1:          20:32          versus some sort of Ray Kurzweil scenario where they download themselves into a computer. You will,

Speaker 2:          20:37          we essentially snapshot it into a computer and anytime if your biological self dies, you could just probably just upload into a new unit that's really pass that whiskey.

Speaker 1:          20:48          This is, we're getting crazy over here. Ridiculous down the rabbit hole. Grab that. Soccer can be something that, this is too freaky. See if I was thinking about this for a long time. By the way, I believe you have, if I was talking to one more cheers by the way, cherish. Okay. This is a great whiskey. Thank you know where this came from, who brought this to us? Trying to remember. Somebody gave it to us old camp, whoever it was. Thanks. Yeah, it is good. Um, this is just inevitable. Again, going back to your, when you decided to be half of this fatalistic viewpoints, so you weren't, you tried to warn people, you talked about this pretty extensively. I've read several interviews where he talked about this and then you just sort of just said, okay, just is, let's just end you in a way by communicating the potential fee. I mean for sure you're getting the warning out to some people.

Speaker 2:          21:39          Yeah. Yeah. I mean I was really going on the morning quite, quite a lot. I was good morning everyone. I could you ever met with Obama and just put one reason like watch about AI and what did he say? So what about Hillary worry about her first he listened. He certainly listened. Um, I met with Congress, I met with, I was at a meeting of all 50 governors and talked about just AI danger. And I talked to everyone I could, the one that seemed to realize where this was going.

Speaker 1:          22:30          Is it that or do they just assume that someone smarter than them? It's already taken care of it. Cause when, when people hear about something like Ai, it's almost abstract. It's almost, it's almost like it's so, it's so hard to wrap your head around it at the time had already happens. It'll be too late.

Speaker 2:          22:46          Yeah. I think they didn't quite understand it or didn't think it was near term or not sure what to do about it. When I said like, you know, an obvious thing to do is to just establish a committee, government committee to gain insight. You know, before, before you oversight, before you do make regulations, they should like try to understand what's going on. Um, and then if you have an insight committee, then the, once they learn what's going on and get up to speed, then they can make maybe some roles. We'll propose some rules and, and that would be probably a safer way to go about things.

Speaker 1:          23:31          It's seems, I mean I, I know that it's probably something that the government's supposed to handle, but it seems like I wouldn't want the, I don't want the government to handle this. Who Do you want to have? Want you to handle it? Yeah. I feel like you're the one who could ring the bell because if, if Mike pence starts talking about Ai, I'm like, shut up bitch. You don't know anything about Ai. Come on man. He hasn't. Nobody's talking about it. I don't have the power to regulate other companies. The one who, I suppose maybe companies can agree, maybe there could be some sort of a wait. I mean there's, we have agreements where you're not supposed to dump toxic waste into the ocean. You're not supposed to do certain things. It could be terribly damaging even though there'll be profitable. Maybe this is one of those things.

Speaker 1:          24:13          Maybe we should realize that you can't hit the switch on something that's going to be able to think for itself and make up its own mind as to whether or not it wants to survive or not. And whether or not it thinks you are a threat and whether or not it thinks you're useless. Like why do I keep this dumb finite life form alive? Why, why keep this thing around? It's just stupid. It just keeps polluting everything shitting everywhere it goes. Lighting everything on fire and shooting each other. Why would I keep this stupid thing alive? Cause sometimes it makes good music, you know, sometimes it makes great movies, sometimes it makes beautiful art and sometimes you know, sometimes it's cool to hang out with Mike. Yeah. For us, those are great reasons, but for anything objective, standing outside like, oh, this is definitely a flawed system.