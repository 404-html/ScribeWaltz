Speaker 1:          00:00          Well. So, so one really important thing that needs to be stated is that Twitter by definition is a bias to platform in favor of the left period. It's not, it's not a question. I understand you might have your own interpretation, but it's very simple. Conservatives do not agree with you on the definition of mis-gendering. If you have a rule in place that specifically adheres to the left ideology, you

Speaker 2:          00:18          by default are enforcing rules from a biased perspective lets him, there are a lot of people in the left who don't agree with how we're doing our job either for sure. And those people think that we don't take enough action on it and use her ass spent far too much behavior go. And I think that's what a radical example though. I mean what he's talking about, I mean in terms of generalities, the in general things lean far more left. Would you agree to that? I don't know what that means, but in this particular case it's a hell of a speech is being used. This is a new vector of attack that people have felt that I don't want to be on this platform anymore because I'm being harassed and abused and I need to get the hell out.

Speaker 1:          00:53          Well people harassed and abused me all day and night. You don't do anything about that? I I my my notifications permanent locked at 99 you have a worse than I do. I mean you got substantially more followers and I don't click the notification tab anymore because it's basically just harassment and I even when, so this is a really funny anecdote. I was a covering a story in Berkeley and someone said if you see him attack him like it was, it was, I'm paraphrasing, they said basically to swing at me, take my stuff, steal from me and Twitter told me after review it was not a violation of their policy. Somebody made an illusion to me being a homosexual and I reported that instantly gone. So when I show, so, so for me I'm looking, I'm like, well of course, of course Twitter is going to enforce the social justice aspect of their policy immediately, in my opinion, probably because you guys have a PR constraints and you're probably nervous about that. But when someone actually threatens me with a crime and insights, their followers to do it and nothing got done and I'm not the only one who feels that way,

Speaker 2:          01:47          that's a mistake. If someone acts in that manner and threatens to hurt you, that's a violation of our rules. Right? Maybe there was a mistake there and I'm happy to go and crack that and we can do it offline so we don't fear any sort of reprisal against you. But that's a mistake. That's not an agenda on my part or in the team spark. Would this be PR constraints?

Speaker 1:          02:08          I said, why did you ban Alex Jones? We're going to get her that. You want to get into that? Absolutely. Are you ready for us? Alright. Oh, I've been ready for, um, well let, let, let me say this. The reason I bring him up is that Oliver, Darcy, one of the lead reporters covering Alex Jones and his content set on CNN, that it was only after media pressure did these social networks take action. So that's why I bring him up specifically cause it it, it sort of implies you are under PR constraints

Speaker 2:          02:34          to get rid of him. I think if you look at the Pr, that's what her went through and that incident, it wouldn't be that we looked good in it and that's not at all why we took action on it. You have to look at the full context on the spectrum here because one of the things that happened over a weekend is what Alex mentioned on your, on your podcast with him. He was removed from the Itunes podcast directory. That was, that was the

Speaker 3:          03:00          linchpin for him because it it, it drove all the traffic to what he said. Basically zero immediately after that we saw our peer companies, Facebook, Spotify, Youtube also take action. We did not. We did not because we, when we looked at our service and we looked at the reports on their service, we did not find anything in violation of our rules. Then we got into a situation where suddenly a bunch of people were reporting content on our platform, including CNN, who wrote an article about all the things that might violate our rooms, rules that we looked into. And we gave him one of the other warnings and then we can get into the actual details. But yeah, we did not follow, we, we resisted just being like a domino with our peers because it wasn't consistent with our rules in the contract we put in before our customers. So what was it that made you ban them?

Speaker 2:          04:00          So there were three separate incidents that came to our attention after the fact, uh, that were reported to us by, by different users. Uh, there was a video that was uploaded that showed a child's being violently thrown to the ground and crying. So that was the first one. Um, the second one was a video that we viewed as incitement of violence. I can read it to you. It's a, sure it's a little, it's a little bit of a transcripts, but, um, but now it's time to act on the enemy before they do a false flag. I know the Justice Department's crippled a bunch of followers and cowards, but there's groups, there's grants, juries, there's, you called for it. It's time, politically, economically and judiciously, illegally and criminally to move against these people. It's got to be dumb now. Get together. The people, you know aren't traders, aren't cowards, aren't helping their fricking bats.

Speaker 2:          04:44          Hedging their fucking bets, like all these other assholes to do. And let's go, let's do it. So people need to have there. And then there's a bunch of other stuff, but at the end, so people need to have their battle rifles ready and everything ready at their bedsides and you've gotta be ready because the media is so disciplined in their deception. So this is you, you're saying that this is a call to violence against the media. That's what it sounded like to us at the time. And there've been a number of incidents of violence against the media. And again, I take my responsibility for what happens on the platform and how that translates off platform very seriously. And that felt like it was an incitement to violence. If he only tweeted the incitement to violence, he would have been fine if he only treats, only tweeted that trans, uh, posted their transcripts saying, get your battle rifles ready, you wouldn't have deleted this account.

Speaker 2:          05:27          I, again, context matters to him. It's not about one thing. So we'd have to look at the entire context of what's going on. So I'm asking was that, was that egregious enough for you to say that alone? That wasn't, that wasn't, that was your number two. Right, right. So then I guess the question is what was the video context of the kid being thrown to the ground? Was it newsworthy? We obviously didn't think so. In depicting violence against the child is not something that we would allow on the platform, even if it's a news content. Um, if it was, uh, there are certain types of situations where if you were reporting on, um, you know, war zone and, and things that might happening, we would put an interstitial on that type of contents as graphic or violent. But we didn't feel that that was the context here.

Speaker 4:          06:03          Well there's a video that's been going around that was going around few four or five weeks ago, the one where the, the girls were yelling at that big giant guy and the guy punched that girl in the face and she was like 11 years old. I saw that multiple times on Twitter. That was one of the most violent things, overseeing this giant man, punched this 11 year old girl in the face. And that was, was that removed from Twitter?

Speaker 2:          06:25          I don't know. I would have to go see if anyone reported it to us. I think one of the issues here is too is, you know, you want me to get to the third one. The third strike, um, that week we looked at was a verbal altercation that Alex got into with a journalist. And in that altercation there, which was uploaded to Twitter, um, there were a number of statements using eyes of the rat, even more evil looking in person. He just scum, you're a virus to America and freedom smelling like a possum that climbed out of the rear end of a dead cow. You look like a possum that got caught doing some really, really nasty stuff in my view. So there was a bunch of, that's it really, that's hilarious. Pattern and practice. But it was a verbal altercation that was posted on our classrooms. So we took the totality of this having been warned that we have rules against his abuse and harassment of individuals and we saw this pattern in practice, one strike, two strike, three strikes and we made a decision.

Speaker 4:          07:20          And so that last one was on periscope. Is that what it was that he uh,

Speaker 2:          07:24          broadcast through? Um, I think it was, uh, originally on periscope, but it was also re posted from multiple related accounts onto Twitter. So we can, we can agree with you when you say these things. Like, you know, Alex said this, it sounds like a threat. He was berating this person saying awful things. But ultimately your judgment is the context. You say we have to pay attention to the context. We just trusting that you made the right decision. Well, I'm, I'm giving you as much facts as I can give you here and I think that this is the real hard part of content moderation at scale on global platforms. It's not easy and I don't think jack or I would tell you that it's easy.

Speaker 4:          08:00          That's a preposterous volume do you guys have to deal with, and that's one of the things that I wanted to get into with Jack when I first had them on because when my thought, and um, I wasn't as concerned about the censorship as many people were. My main concern was what does it like to start this thing that's kind of for fun? And then all of a sudden it becomes the premier platform for free speech on the planet earth. So

Speaker 2:          08:26          it is that, but it's also a platform that's used to abuse and harass a lot of people, and, and used in ways that none of us want it to be used by you molested. It happened. So, and I think it's an enormously complicated challenge, uh, for any company to do content moderation at scale. And that's something that we are sitting down thinking about how do we take this forward? Because this is, it doesn't scale. Yes, yes, yes.