Speaker 1:          00:01          Seattle, you must be, I mean, cause you're here, right? You feel tremor because they must say they happen all the time. Right. I've only been a few times. One time I felt them before. The, the biggest ones I ever felt was when I first moved here. I first moved here in 94 and it was right after the Northridge earthquake and uh, I was in my house and I felt, uh, I guess it was like a 5.5 where the whole thing just, it was weird, but it gave me the impression that the house that I was living in or the apartment that I was in was made out of the same stuff, like a box that a refrigerator would come in. You know how like you can move it around inside. The whole thing was just moving like easily left and right. I was like, Holy Shit.

Speaker 1:          00:41          That was my, I've only had a few times that I've, you know, felt on, I'm like, it's like it's, you know, at first I thought it was a truck. I thought a truck was rolling, you know? And I'm like, no man, that was an earthquake. And the one that I experienced was nothing. I mean baby one, the ones that they're getting right now somewhere in the world, I mean there's, there's always something that's like a five or six. Yeah. So this goes back to your point about the, uh, you know, a lot of planets, right? We'll be like way more plate tectonically active, volatile than ours. So, you know, I mean a lot to me and I think good planets are going to be like really hard to find. Yeah. So, you know, it may be, that may be the solution. The other solution is, you know, I mean, the way you guys found out about me, so I did that article about the previous civilization, you know, like what is it, how do you know whether or not there was a previous civilization?

Speaker 1:          01:26          And you know, one solution could be that, look, they were here, you know, that somebody did arrive and spent some time on earth. But if it was like half a billion years ago and they only last, right, every civilization has a finite lifetime. They only lasted for, you know, even a few hundred thousand years, they wouldn't leave. There'd be no record left to, it'd be nothing. There'd be nothing. What do you think that's possible that something's ever visited here and because that is the big question and that's the, the thing that gets the UFO dorks more jazzed up than anything is the possibility that we'd been visited. Yeah. Not In the, I'm, I'm definitely not you. Ufos. There's, there's two arguments against you. Fo's uh, one is as, as you know, a friend of mine, Jason Wright says, he's like, look as astronomers, man, you know, we're finding all those aspects.

Speaker 1:          02:07          We're finding a little chunks of rock moving. You know, nobody looks at the sky harder than we do. Right, right. And you know, if anything, unless you want to go to the conspiracy theories, we would have found something. My other argument is like, what's with the headlights? You know what I mean? People are just like, Oh man, I saw lights in the sky and then they moved around and then they disappeared. You know, but they don't really want to be seen. I'm like, why did they have headlights on? Like why just turn off the fricking roommates? It just, why would they have lights in the first place? You came from another civilization and you can't get around without your high beams. You know what the fuck are you seeing what those lights and you're not seeing shit. When was the last time you saw planes have lights or their planes don't run into them.

Speaker 1:          02:43          They don't have lights so they could see where they're going. Yeah. So what, so why do they have, right, exactly. The planes have lights so other people can see them. So they're here but they're mysterious. They don't want to be found in turn off the fricking light. So they, yeah, they wouldn't have any lines. Yeah, they always have lights. People are always saying like a hub and I saw license guy and then they moved back and forth. And the problem with human memory memories, right? Horrible and memory of events that are stunning or shocking or a nerving or you think you saw something, right. They've done all that research. Even in trials, right. Where people see things currently Ufo is, you know, I'm just kinda like, do you think it's possible that there could be life on other planets and it's possible there could be intelligent life on other planets and we send probes to Mars?

Speaker 1:          03:23          Why wouldn't I think that if they do send something here, they're going to send something without biological life inside of it. Yeah. Yeah. Well this is, you know, it's a really interesting question is like you were talking about like what will we evolve into in, you know, a million years, uh, you know, it may be possible that biology is a short period of intelligence. You build machines and the machines become, you know, download yourself into them. I mean, that's a real possibility that like, you know, silicon makes a lot more sense than wetware. While the problem is we think of artificial intelligence as artificial, right? It's definitely real, right? Yeah, no, that's exactly, it's not, it's not fake. It's right there. Right. You know, it's like there's artificial milk, you know what I mean? But it's, it's a liquid. It's an actual liquid. There's not an artificial life, silicon created life.

Speaker 1:          04:10          That's again, the idea that the biosphere, this may be that what the biosphere solution to spreading itself to getting it maybe that like, yeah, silicon that that's kind of a normal, I mean I'm, I am super skeptical about like the whole trans human thing about we're going to download ourselves into intelligent, you know, it took, are you, have you ever gone to one of those conventions dorks now there's some pretty serious dork in, well, there's geniuses in those dorks too. It's really interesting. It's like they're fully, wholly committed to this prospect of downloading themselves. You've talked to Kurt's well before. Uh, no, but I've read his stuff. I got a chance to interview him a few years back for [inaudible] smart beyond smart. But God damn is he committed to it. And then when you get to it, you realize that what he actually wants to do is recreate his father.

Speaker 1:          04:56          Yeah. He's, his father died when he was young and he wants to be able to, through memories and photographs and what he knows about his father, literally recreate his father and be able to have a conversation with them. He was talking about this, but what he's doing is he's going way, way into the future into the possibilities of, he's not seeing like, well, five years from now we're going to be able to send, you know, gigabyte pictures through the mail. Now he's saying, let's think of if you keep going exponentially electronics and technology and innovation keeps continually accelerating. We could potentially get to the point where it's the impossible. Well, you'd be able to recreate human beings based on your knowledge of them and in the end there'll be able to come up with some sort of a program. Will he'll be able to have a conversation with his father.

Speaker 1:          05:47          Yeah. See, I think that misunder I mean, I think it's, you know, it's true about like the possibility of a singularity in technological development, but you know, it's not going to be his father. That's the sad thing, you know, I think we seriously, you know, I've done some work on this as an interest of mine about mind. What is mind, you know, what's the relationship between mind and matter? And, um, I think we have like a serious misunderstood, we don't understand consciousness very well at all. So the idea that like, oh yeah, it's just got to be trivial to download your, you know, your consciousness into a computer. I think it's pretty, you know, there's like a shit load of assumptions in there about like what mind is and the relationship between like your neurons and, you know, awareness. So that's why I think those guys, it's a little bit of a religion, you know what I mean?

Speaker 1:          06:28          There's a little bit of religion and, and you know, so it's like 2045 is the new benchmark. For whatever reason. That's the new number. They get to keep going back. It's gonna be like every other, every other rapture. Ah, we thought it was 2045 we really got 2065, you know, we went to this 2045 conference. Me and my friend Ran Dunkin and we got to talk to some of these guys and it's really fascinating. And one of them had created some robot that was supposed to be him, but it didn't work well. So they never revealed that at the conference. Too many bugs in it. It's intriguing. It's like I want them to keep going cause I mean when, when do we get going to get to x? Mokena when are we going to talk about good movies? So did you like that? One of my favorite movies ever.

Speaker 1:          07:10          So smart. So like just like simple stop beating me over the head with it and cut the shit most moving moments in that movie. Yeah, the entire, I think that's one of my all time top 20 movies, which she stabs him just emotionless. It was amazing. Amazing alert. Did you like a annihilation? Yes. I didn't like it as much, but I liked it. It was very weird and the ending seemed like some producers put their urges in the soup and just like back to Pittsburgh, what's happening here? Who made this part? But I enjoyed it. Yeah. So I think like, you know, I mean the danger with anything when it comes to AI and said, so what are, you know, here's an interesting thing about Ai. Like we're, we are getting, making amazing strides with AI now. Now artificial intelligence is different from artificial consciousness, you know what I mean?

Speaker 1:          07:58          So like, but um, but the AI that, you know, what we're getting out of it is nothing like us, right? So the, you know, back in the day where people were like, oh, we're going to like model the human brain and that's how we'll do it. Well, like make programs that are, and what they've learned, it's like, oh that doesn't really work that well. So now this is the whole big data thing. Like, you know, network theory and big data and deep learning. We're like, you know, they're using statistical, you know, the power of, of having huge amounts of computing and statistical reasoning so that like, you know, get the computer. Like, you know, it'll find the picture of the cat, but you have no idea why it found the pit didn't reason. Like, Oh yeah, that was where it looks like cat and I liked cuts, you know, it was just like, oh, these kinds of lines go with that kind of thing and it has no idea what it's doing, but it'll act intelligently.

Speaker 1:          08:40          And so that's, you know, I mean that's kind of freaky deaky in a lot of ways too. I think people are, I think it's smart to think about the dangers of AI, not necessarily what additional features to us. Yeah. Not necessarily the dangerous. Just the dangers to this thing that we are this weird monkey thing that wants to keep being a monkey thing. Well you mean in the sense of like, right that it's going to replace us? Yes. Yeah. Yeah. I think it's inevitable. I mean, do you, don't you think that if you go back and interview the single celled organism before branched off into multicell, that'd be kind of a boring fuck this multi-celled bullshit. I don't want to stay a single cell at the bottom of the assholes, man with their rock and roll music metal cars. Fuck that. I don't want a car, man.

Speaker 1:          09:25          I liked staying down here. There's a real thought to that, that we are the wetware that is the problem. No, no, listen, I think it's fully conceivable. Like I'm not going to like, it would never happen, but as a, a guy knows, a philosopher says, you know, there's a certain way in which everything we do with AI right now, it's not like, you know, Watson is playing chess. It's like we're using Watson to play chess. It's our tool. You know, and I think the PR, the fear is the tool gets out of hand. Not that it like develops a thing where like I hid humans. You know, dad, I hate you, but more that it's like, you know, these things which are not actually thinking. They act intelligent but they're not thinking it can have a huge, like it'll have a really negative impact. You know, it'll, it'll, you know, what does it, there's that example of like, if you design something that is an AI system to make paper clips, it ends up consuming the entire planet making paperclips because that's what you told it to do. Right. You never told it to make a sustainable amount of. Right, exactly. So I'm, I'm more worried about that than I am of like Skynet, you know, coming over and like, you know, deciding that it's going to take a drop all the bombs on us cause you need to get rid of it.