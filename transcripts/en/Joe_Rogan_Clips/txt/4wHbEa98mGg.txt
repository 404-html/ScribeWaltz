Speaker 1:          00:00          That's important to sort of be nervous about it in that way, but it's not conducive to what do we do about it and the people that know what to do about it are the people trying to build this technology of building this future one step at a time. I know what to do about it because like let's, let's put it in terms of a Elon Musk, right? Like Ilan mosque is terrified of artificial intelligence cause he thinks by the time it becomes sentient and it'll be too late, it will be smarter than us and we'll, we'll have essentially created our successors. Yes. And let me quote Joe Rogan and say that's just one guy. Yeah. Well Sam Harris thinks the same thing. Yes. And there's a lot, lot, a few people that think that Sam Harris, I think is one of the smartest people I know. And Elon Musk intelligence aside is one of the most impactful people I know.

Speaker 1:          00:50          And he's actually building these cars. And in the narrow AI sense, if he's built these autopilot system that we've been studying, the way that system works is incredible. It was very surprising to me on many levels. It's an incredible demonstration of what AI can do in a positive way in the world. So I don't know, but I people can disagree. I'm not sure the functional value of his fear about the possibility of this philosophies. Correct. There's functional value and hitting the brakes before this takes place. The two just just to be a person who's standing on top of the rocks with a light to warn the boats, Hey, there's a rock here. Like are you, you pay attention to where we're going because there's perils ahead. I think that's what he saying that I don't think there's anything wrong with saying that and I think there's, there's plenty of room for people saying what he's saying and people saying what you're saying.

Speaker 1:          01:52          I think what would hurt us is if we tried to silence either voice. I think what we need in terms of our understanding of this future is many, many, many, many, many of these conversations where you're dealing with the, the current state of technology versus a bunch of creative interpretations of where this could go and have discussions about where it should go or what could be the possible pitfalls of any current or future actions. I don't think there's anything wrong with this. So when you say like, what's the benefit of thinking in a negative way? Well, it's to prevent our demise. So totally, I agree on a percent negativity or worry about the existential threat is really important to have as part of the conversation. But there's this level, there's this line, it's hard to put into words is it is a line that you cross when that worry becomes hyperbole. Yeah. And, and then there's something about human psyche where it becomes paralyzing for some, right

Speaker 2:          03:00          now when I have beers and my friends than Non-i folks, we actually go, we crossed that line all day and have fun with it. I talked should get you drunk right now. Maybe regret every moment of it. This, I talked to Steve Pinker, uh, enlightenment. Now this book kind of highlights that, that kind of, um, that he's totally doesn't find that appealing because that's crossing all realms of rationality and reason. What'd you say that appealing? What do you mean a crossing the line into what will happen in 50 years? What could happen? What could happen? He doesn't find that appealing. It doesn't find it appealing because he's studied and I'm not sure I d I agree with him, uh, to, to the degree that he takes it. He finds that there's no evidence. He wants there all our discussions to be grounded in evidence and data. And he, he highlights the fact that there's something about human psyche that desires this negativity. That it, once there's, there's something undeniable where we want to create an engineer, the gods that overpower us and destroy us.

Speaker 1:          04:15          We want to, or we worry about it. There's stuff we want to,

Speaker 2:          04:21          we, uh, let me rephrase that. We want to worry about it. There's something about the psyche that, but yeah,

Speaker 1:          04:26          that because you can't take the genie and put it back in the bottle. That's right. Yeah, I mean when you say there's no reason to think this way, but if you do have cars that are semi autonomous now, and if you do have computers that can beat human beings who are world go champions. And if you do have computers, computers that can beat people at chess, and you do have people that are consistently working on artificial intelligence and you do have Boston dynamics who are getting these robots to do all sorts of spectacular physical stunts. And then you think about the possible future convergence of all these technologies. And then you think about the possibility of this exponential increase in technology that allows them to be sentient, like within a decade, two decades, three decades. What, what more evidence do you need? Your, you're seeing all the building blocks of a potential successor being laid out in front of you and you're seeing what we do with every single aspect of technology. We constantly and consistently improve and innovate, right? With everything, whether it's computers or cars or anything. Everything today is better than everything. That was 20 years ago. So if you looked at artificial intelligence, which does agree Dee does exist to a certain extent, and you, you look at what it could potentially be 30, 40, 50 years from now, whatever it is, why wouldn't you look at all these data points and say, hey, this could go bad. I mean it could go great, but it could also go bad.

Speaker 2:          05:58          I do not want to be mistaken as the person who's not the champion or the impossible. I agree with you completely. It think it's impossible. It's impossible at all. I think it's inevitable. I don't, I think it is inevitable. Yes, it's the Sam Harris argument. If, if super intelligence is nothing more than information processing, uh, it's same as the argument of the simulation that we're living in a simulation that's very difficult to argue against the fact that we're living in a simulation. The question is when and what the world would look like, right? So it's like I said, a race and, and it's difficult. You have to balance those two minds. I agree with you. Totally. You and I disagree with my fellow robotics folks who don't want to think about it at all. Of course, they don't

Speaker 1:          06:49          the one to buy new houses. If they've got a lot of money invested in this adventure, they want to keep the party rolling. They don't want to pull the brakes. Everybody pulled the cords out of the walls. We've got to stop. No one's going to do that. No one's, no one's going to come along and say, Hey, we've, we've run all this data through a computer and we found that if we just keep going the way we're going in 30 years from now, we will have a successor that will decide that human beings are outdated and inefficient and dangerous to the the actual world that we live in and we're going to start wiping them out.

Speaker 2:          07:17          But that's not exactly,

Speaker 1:          07:19          that's exactly right. Now. It doesn't exist right now, but if that did happen, if someone did come to the UN and had this multistage presentation with data that showed that if we continue on the path we're going, we have seven years before artificial intelligence decides to eliminate human beings based on these data points. What do you, what do they do? What did the Boston dynamics people do well, building a house in Cambridge. What are you talking about man? I'm not going anywhere. Come on. I just bought a new Tesla. I need to finances thing. Hey, you got got credit card bills. I got student loans. I'm still paying off. Like what? How do you stop people from doing what they do for a living? How do you say that? Hey you, I know that you would like to look at the future with rose colored glasses on, but there's a real potential pitfall that could be the extermination of the human species.

Speaker 2:          08:10          Right, and obviously I'm going way far with this. Yeah, I like it. I think every one of us trying to build these systems are similar in sound to the way you were talking about the touch of death in that my dream and the dream of manual roboticist is to create intelligence systems that will improve our lives and working really hard at it, not for our house and Cambridge, not $4 billion for selling a startup paycheck.

Speaker 1:          08:45          We love this stuff. Some of you. So obviously the motivations are different for every single human being. It's involved in every endeavor.

Speaker 2:          08:53          So, and we're trying really hard to build these systems and is really hard. So whenever the, the question is, well, this is going to look at historically is going to take off, it can potentially take off any moment. It's very difficult to really be cognizant as an engineer about how it takes off because you're trying to make it take off in a positive direction and you're failing. Everybody's failing. It's been really hard. And so you have to acknowledge that there, that overnight, some Eli Musk type character might come along and you know, people with this boring company, uh, or with space x, people didn't think anybody but NASA could do what Musk is doing and he's doing it. It's hard to think about that too much. You have to do that. But the reality is we're trying to create these super intelligent beings.

Speaker 1:          09:53          Sure. But isn't the reality also that we have done things in the past because we were trying to do it and then we realized that these have horrific consequences for the human race. Like Oppenheimer in the Manhattan project. You know, when he said, I am death destroyer of worlds, when, when he was quoting the Bhagavad Gita, when he's detonating the first nuclear bomb and realizing what he's done, just because something's possible to do doesn't necessarily mean it's a good idea for human beings to do it. Now, we haven't destroyed the world with Oppenheimers discovery and through the work of the Manhattan project, we've managed to somehow or another keep the lid on this shit for the last incredible. It's crazy. Right? You know, I mean for the last 70 years, how has it been? Seven days? Sounds right. Ten thousand twenty thousand nukes all over the world right now. Crazy mean we literally could kill everything on the planet and somehow we dot somehow somehow in some amazing way we have not. But that doesn't mean we, I mean this a very short amount of time in relation to the actual lifespan of the earth itself and certainly in terms of the time human history has been around

Speaker 2:          11:02          and nuclear weapons. Global warming is another one. Sure.

Speaker 1:          11:09          That's a side effect of our actions, right? This is, we're talking about a direct effect of human ingenuity and innovation. The nuclear bomb, it's a direct effect. We tried to make it, we made it there. Ghost global warming's an accidental consequence of human civilization.

Speaker 2:          11:26          So you can't, I don't think is possible

Speaker 1:          11:30          to not be build a nuclear bomb. You don't think it's possible to not build it in terms of it because people are tribal, they speak different languages, they have different desires and needs and they were, and more so if all these engineers were working towards it, it was not possible to not build it.

Speaker 2:          11:46          Yep. And the, like I said, there's something about us chimps in a large collective where we, uh, are born

Speaker 1:          11:54          and push forward towards progress of technology. You cannot stop the progress of technology. So the goal is to how to develop, how to guide that development into a positive direction. But surely if we do understand that this has taken place and we did drop these enormous bombs on Hiroshima and Nagasaki and killed untold amounts of innocent people with these destinations, that it's not necessarily always a good thing to pursue technology. It nobody is. So then you see what I'm saying? Hundred percent. I agree with you. Totally. I'm more playing devil's advocate than anything, but what I'm, what I'm saying is you guys are looking at these things like we're just trying to make these things happen and what I think people like Elon Musk and Sam Harris and a bunch of others that are gravely concerned about the potential for AI are saying is that's, I understand what you're doing, but you've got to understand the other side of it.

Speaker 1:          12:54          You've got to understand that there are people out there that are terrified that if you do extrapolate, if you do take this are relentless thirst for innovation and keep going with it, would you look at what we can do? So what human beings can do? So far in our crude manner of two, 2018 we'll all of the amazing things they've been able to accomplish, it's entirely possible that we might be creating our successors. This is not outside the realm of possibility and all of our biological limitations might be we, we might figure out a better way and this better way might be some sort of an artificial creature. Yup. Ai began with our dream to forge the gods, and that's, I would like, I think that it's impossible to stop.