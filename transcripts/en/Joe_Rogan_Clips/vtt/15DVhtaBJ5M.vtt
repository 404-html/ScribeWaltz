WEBVTT

1
00:00:00.330 --> 00:00:05.330
Is the issue that the initial creation would be subject to our programming,

2
00:00:05.731 --> 00:00:10.230
but that it could perhaps programs something more efficient and design something

3
00:00:10.530 --> 00:00:14.550
like if you build creativity into artificial general,
you have to,
I mean,

4
00:00:14.551 --> 00:00:18.870
general generalization is about creativity.
Yeah.

5
00:00:19.110 --> 00:00:23.580
But is the issue that it would choose to not accept our values,

6
00:00:23.700 --> 00:00:27.870
which it might find clearly will choose not to accept our values and we want to

7
00:00:27.871 --> 00:00:30.110
choose not to accept all of our values,
right?

8
00:00:30.330 --> 00:00:34.350
So it's more a matter of whether the ongoing creation,

9
00:00:34.351 --> 00:00:39.060
evolution of new values occurs with some continuity and respect for the previous

10
00:00:39.061 --> 00:00:43.770
one.
So I mean,
uh,
with I've,
for human kids now one is a baby,

11
00:00:43.771 --> 00:00:46.290
but the other three are adults,
right?
And with each of them,

12
00:00:46.650 --> 00:00:51.650
I took the approach of trying to teach the kids what my values were,

13
00:00:52.170 --> 00:00:56.730
not just by preaching at them,
by entering legitimate into shared situations.

14
00:00:57.060 --> 00:00:59.490
But then,
you know,
when your kids grow up,

15
00:01:00.000 --> 00:01:02.460
they're going to go in their own different directions,
right.

16
00:01:02.520 --> 00:01:07.350
And these are humans,
but,
but they all have the same sort of biological needs,

17
00:01:07.351 --> 00:01:11.850
which is one of the reasons the first place,
there's still isn't an analogy.

18
00:01:11.851 --> 00:01:15.770
I think the AI's that we create,
you can think of as a,

19
00:01:15.771 --> 00:01:17.220
as our mind children,

20
00:01:17.250 --> 00:01:21.600
and we're starting them off with our culture and values.

21
00:01:21.601 --> 00:01:23.220
If we do it properly,

22
00:01:23.400 --> 00:01:28.400
or at least with a certain subset of the whole diverse self-contradictory mess

23
00:01:28.681 --> 00:01:33.180
of human culture and values.
But you know,
they're going to evolve in a,

24
00:01:33.190 --> 00:01:35.340
in a different direction.

25
00:01:35.550 --> 00:01:40.030
But you want that evolution to take place in a reflective and,
and,

26
00:01:40.031 --> 00:01:43.740
and caring way rather than the heedless way.
Cause if you think about it,

27
00:01:44.160 --> 00:01:47.700
the average human a thousand years ago or even 50 years ago would have thought

28
00:01:47.701 --> 00:01:51.510
you and me,
we're like hopelessly immoral.

29
00:01:51.540 --> 00:01:56.010
Miscreants who had abandoned all the valuable thing things in life,
right?
I mean,

30
00:01:56.620 --> 00:02:01.380
uh,
my,
my,
my,
my hat,
I mean,
I'm,
I'm,
I'm an,
I'm an infidel.

31
00:02:01.381 --> 00:02:06.180
Rarely I don't,
I don't,
I haven't gone to church ever.
I,
I guess,

32
00:02:06.181 --> 00:02:09.140
I mean my,
my,
my mother's lesbian,
right?
I mean there,

33
00:02:09.141 --> 00:02:14.141
there's all these things that we take for granted now that not that long ago

34
00:02:15.600 --> 00:02:20.490
were completely against what most humans considered maybe the most important

35
00:02:20.491 --> 00:02:25.360
values of life.
So I mean,
human values itself is completely,
uh,

36
00:02:25.380 --> 00:02:29.790
moving a moving target and something in our generation.
Yeah.
Yeah.
Moving in our,

37
00:02:29.791 --> 00:02:33.260
in our generation pretty radically,
very radically.

38
00:02:33.300 --> 00:02:37.280
When I think back to my childhood,
I,
I,

39
00:02:37.510 --> 00:02:42.510
I lived in New Jersey for nine years of my childhood and just the level of it

40
00:02:43.590 --> 00:02:48.590
CISM and antisemitism and sexism that were just ambient and tech taking for

41
00:02:49.471 --> 00:02:53.190
granted.
Then,
I mean,
this was,
this,
was this when you're between,

42
00:02:53.280 --> 00:02:56.930
because we're the same age,
we're both of them at one.
Yeah,
yeah,
yeah,
yeah.

43
00:02:56.940 --> 00:03:00.910
Born in 66.
I lived in Jersey from 73 to 82.

44
00:03:01.320 --> 00:03:05.740
So I was there from 67 to 73.

45
00:03:05.950 --> 00:03:10.090
Oh yeah,
yeah,
yeah.
I'm in like my,
I'm in.

46
00:03:10.660 --> 00:03:13.030
My sister went to the high school prom with a,

47
00:03:13.060 --> 00:03:16.810
with a black guy and so we got our car turned upside down.

48
00:03:16.811 --> 00:03:19.400
The windows of our house smashes.
It was like a human,
you,

49
00:03:19.450 --> 00:03:23.080
your mung gets thing and it's almost unbelievable now,
right?

50
00:03:23.100 --> 00:03:27.690
Because now no one would care care whatsoever.
It's,
it's,
it's,

51
00:03:28.160 --> 00:03:31.420
it's just life.
Certainly there's some fringe parts of his skull,

52
00:03:31.940 --> 00:03:36.940
but still the point is there is no fixed list of values,

53
00:03:38.111 --> 00:03:39.550
human values.

54
00:03:39.570 --> 00:03:44.570
It's an ongoing evolving process and what you want is for the evolution of the

55
00:03:45.431 --> 00:03:50.431
AIS values to be coupled closely with the evolution of human values rather than

56
00:03:52.390 --> 00:03:55.620
going off in some other really different direction.

57
00:03:55.900 --> 00:04:00.050
We can't even understand that this is literally playing God,
right?

58
00:04:00.280 --> 00:04:03.730
I mean if you're talking about like trying to program and values,

59
00:04:03.970 --> 00:04:08.970
I don't think you can program in values that fully you can program in a system

60
00:04:10.241 --> 00:04:13.990
for learning and growing values and here again,

61
00:04:13.991 --> 00:04:18.400
the analog analogy with human kids,
it's not hopeless like telling,

62
00:04:19.030 --> 00:04:20.350
telling your kids,

63
00:04:20.770 --> 00:04:24.490
these are the 10 things that are important doesn't work that well,
right?

64
00:04:24.491 --> 00:04:29.350
What we're,
what works better is you enter into shared situations with them.

65
00:04:29.620 --> 00:04:31.690
They see how you deal with the situations,

66
00:04:31.691 --> 00:04:34.420
you guide them in dealing with real situations.

67
00:04:34.750 --> 00:04:37.090
And that forms that our system of values,

68
00:04:37.360 --> 00:04:39.380
and this is what needs to happen with Ai,

69
00:04:39.381 --> 00:04:44.381
is they need to grow up entering into real life situations with human beings.

70
00:04:45.041 --> 00:04:47.680
So the real life patterns of human values,

71
00:04:47.681 --> 00:04:50.020
which are worth a lot more than the homily,

72
00:04:50.021 --> 00:04:53.140
is that that we and annunciate formally,
right?

73
00:04:53.410 --> 00:04:58.060
The real life pattern of human values gets inculcated like into the intellectual

74
00:04:58.061 --> 00:05:00.310
DNA of the,
of the AI systems.

75
00:05:00.311 --> 00:05:05.311
And this is part of what worries me about the way the AI field is going at at

76
00:05:06.011 --> 00:05:06.701
this moment.

77
00:05:06.701 --> 00:05:11.701
Because I mean most of the really powerful narrow ais on the planet now are

78
00:05:11.951 --> 00:05:15.730
involved with like selling people stuff they don't need spying on.

79
00:05:15.731 --> 00:05:20.560
People are like figuring out who should be killed or otherwise abused by some

80
00:05:20.561 --> 00:05:21.670
government.
Right?
So if,

81
00:05:21.910 --> 00:05:26.910
if the early stage Ai's that we build turned into general intelligences

82
00:05:28.330 --> 00:05:32.020
gradually,
and these general intelligence is our,
you know,

83
00:05:32.230 --> 00:05:35.710
spy agents and advertising agents,
then like what,
what,

84
00:05:35.890 --> 00:05:40.090
what mindset do these early stage Ai's have as they grow up?

