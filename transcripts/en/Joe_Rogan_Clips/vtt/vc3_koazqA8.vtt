WEBVTT

1
00:00:00.240 --> 00:00:03.060
Five four,
three.

2
00:00:03.840 --> 00:00:05.700
Dos Uno,

3
00:00:09.530 --> 00:00:10.770
come on.
Tri caster.

4
00:00:12.170 --> 00:00:16.790
Live well live ladies and gentlemen to my left,
uh,

5
00:00:16.850 --> 00:00:20.780
Tim Timple,
everybody knows and loves him.
Viga,
what does it,
how do you,

6
00:00:20.810 --> 00:00:23.710
how do I pronounce your last name?
Good job.
Not Vieja.

7
00:00:23.711 --> 00:00:28.711
Vigia Vigia Gadi Gadi and your position at Twitter is I lead trust and safety.

8
00:00:30.531 --> 00:00:34.940
Legal and public policy.
That's a lot.
That's a lot.
And Jack Dorsey,

9
00:00:35.150 --> 00:00:38.900
ladies and gentlemen.
Um,
first of all,
thank you everybody for doing this.

10
00:00:39.440 --> 00:00:40.580
Appreciate it.
Thank you.

11
00:00:40.660 --> 00:00:42.950
It feels the feels all of a sudden there's tension in the room.

12
00:00:44.220 --> 00:00:47.510
We're all loosey Goosey.
Just a few minutes of your attention.
Never one's like,

13
00:00:47.511 --> 00:00:52.010
oh,
this is really happening.
Here we go.
Um,
before we get started we should say,

14
00:00:52.011 --> 00:00:55.970
because there were some things that people wanted to,
uh,

15
00:00:56.090 --> 00:00:57.170
have us talk about.

16
00:00:57.530 --> 00:01:01.250
One that the cash APP is one of the sponsors of the podcast.

17
00:01:01.251 --> 00:01:05.270
It's been a sponsor for a long time and also a giant supporter of my good friend

18
00:01:05.271 --> 00:01:07.250
Justin is fight for the forgotten charity,

19
00:01:07.251 --> 00:01:08.930
building wells for the pygmies in the Congo.

20
00:01:08.930 --> 00:01:12.860
This is very important to me and I'm very happy that you guys are a part of that

21
00:01:12.861 --> 00:01:16.550
and you are connected to that.
I don't,
uh,
that's,

22
00:01:16.580 --> 00:01:20.360
I mean it's easy for someone to say that doesn't have an influence on the way we

23
00:01:20.361 --> 00:01:24.500
discuss things,
but it doesn't,
so if it does,
I don't know what to tell you.

24
00:01:24.830 --> 00:01:25.970
I'm going to mention too,

25
00:01:25.971 --> 00:01:28.250
just because I don't want people to come out and freak out later.

26
00:01:28.251 --> 00:01:32.840
I actually have like 80 shares in square,
which isn't really that much in,
but,

27
00:01:33.110 --> 00:01:36.040
but it's something,
it is,
it is.
So I don't want people to think,
you know,

28
00:01:36.260 --> 00:01:39.360
whatever you,
you're the CEO of square I think,
right?
Yup.
Yeah.
There you go.
Well,

29
00:01:39.361 --> 00:01:41.000
there you go.
We have the cash APP.

30
00:01:41.600 --> 00:01:45.740
And the reason why we decided to come together is,
um,
we had,
I thought,

31
00:01:45.770 --> 00:01:47.240
a great conversation last time,

32
00:01:47.270 --> 00:01:50.090
but there's a lot of people that were upset that there were some issues that we

33
00:01:50.091 --> 00:01:53.450
didn't discuss or didn't discuss in depth enough or they felt that I didn't

34
00:01:53.451 --> 00:01:54.284
press you enough.

35
00:01:54.830 --> 00:01:59.830
I talked to Tim because Tim and I have talked before and he made a video about

36
00:02:00.321 --> 00:02:02.960
it and I felt like his criticism was very valid.

37
00:02:03.170 --> 00:02:06.800
So we got on the phone and we talked about it and I knew immediately within the

38
00:02:06.801 --> 00:02:09.650
first few minutes of the conversation that he was far more educated about this

39
00:02:09.651 --> 00:02:11.210
than I was.
So I said,

40
00:02:11.211 --> 00:02:15.200
would you be willing to do a podcast and perhaps do a podcast with Jack?

41
00:02:15.650 --> 00:02:19.700
And he said,
absolutely.
So we did a podcast together.
It was really well received.

42
00:02:19.701 --> 00:02:23.690
People felt like we covered a lot of the issues that they felt like I didn't

43
00:02:23.691 --> 00:02:26.900
bring up.
And so then Jack and I had discussed it and we said,
well,

44
00:02:26.901 --> 00:02:31.850
let's bring Tim on and then have Vigia on as well.
I say that right?
Yeah,

45
00:02:32.010 --> 00:02:36.470
that's a hard one.
Sorry.
I'll get it right.
I promise.
Uh,
but so we're here,

46
00:02:36.650 --> 00:02:41.240
we're here,
um,
today.
Uh,
you know,
do you know who Sean Baker is?

47
00:02:41.241 --> 00:02:45.170
He's a doctor who's a prominent proponent of the carnivore diet.

48
00:02:46.280 --> 00:02:49.910
His post was,
his account was frozen today.

49
00:02:50.600 --> 00:02:52.990
I just sent it to Jamie.
Yeah,

50
00:02:53.450 --> 00:02:56.580
his count was frozen today because of an image that he had,

51
00:02:56.581 --> 00:02:58.670
because he's a proponent of the carnivore diet.

52
00:02:58.700 --> 00:03:01.690
There's a lot people that believe that this elimination diet is very healthy for

53
00:03:01.691 --> 00:03:05.950
you and it's known to cure a lot of autoimmune issues with certain people,

54
00:03:05.951 --> 00:03:09.760
but some people ideologically opposed it because they think it's bad for the

55
00:03:09.761 --> 00:03:13.810
environment or you shouldn't eat meat or whatever the reasons are.
This is huge.

56
00:03:13.811 --> 00:03:16.900
And the bitcoin community,
yes,
yes.
Yeah.
Well,
it's the,

57
00:03:16.950 --> 00:03:20.680
for a lot of people that have autoimmune issues with particularly psoriasis and

58
00:03:21.070 --> 00:03:25.480
arthritis is,
is a lifesaver.
It's crazy.
It's essentially,

59
00:03:26.200 --> 00:03:27.370
it's an autoimmune issue,

60
00:03:27.430 --> 00:03:32.430
so because he has a photo of a lion in a header eating a looks like a wheel to

61
00:03:33.001 --> 00:03:37.360
beats or something like that,
his account was locked for violating these rules,

62
00:03:37.390 --> 00:03:41.650
rules against graphic violence or adult content in profile images.

63
00:03:42.670 --> 00:03:47.530
That seems a little silly and I wanted to just mention that right away.
Now,

64
00:03:47.590 --> 00:03:50.260
whose decision is something like that,

65
00:03:50.410 --> 00:03:54.370
like who decides to lock a guy's account out because it has a nature image?

66
00:03:54.371 --> 00:03:56.410
If you know natural predatory behavior

67
00:03:57.040 --> 00:03:58.240
<v 2>on this particular case,</v>

68
00:03:58.241 --> 00:04:02.320
it's probably an algorithm that detected it and made some sort of an assessment.

69
00:04:02.350 --> 00:04:03.550
But as a general rule,

70
00:04:03.580 --> 00:04:07.810
how we operate as a company as we rely on people to report information to us.

71
00:04:08.230 --> 00:04:11.200
So if you look at any tweet and you can kind of pull down on the carrot on the

72
00:04:11.201 --> 00:04:13.990
right and you can say report the tweet and then you have a bunch of categories

73
00:04:13.991 --> 00:04:17.080
you can choose from what you want to report.
Um,

74
00:04:17.140 --> 00:04:19.510
I think this one in particular though,
it was probably an algorithm.

75
00:04:20.180 --> 00:04:21.690
<v 0>So how does,
does it,</v>

76
00:04:21.820 --> 00:04:26.380
does he have the option to protest that or to ask someone to review it?

77
00:04:26.530 --> 00:04:29.830
<v 2>Absolutely.
And I,
I,
I'm guessing that people are already reviewing it,</v>

78
00:04:29.831 --> 00:04:33.910
but there's a choice to appeal any action and that would go to a human to make

79
00:04:33.911 --> 00:04:38.560
sure that it is actually a violation of the rules.
Or in this case,
if it's not,

80
00:04:38.561 --> 00:04:41.950
then it would be removed.
Is that a violation of the rules,
that image?

81
00:04:42.250 --> 00:04:43.390
I don't think so.

82
00:04:43.420 --> 00:04:46.060
I don't think that that would be what we're trying to capture in terms of

83
00:04:46.061 --> 00:04:50.170
graphic images and an avatar.
It's more about violence towards,
uh,
humans,

84
00:04:50.171 --> 00:04:53.860
unless it was some sort of cruelty depicting the walls or something like that.

85
00:04:53.890 --> 00:04:56.350
But this seems not the intention of the rule

86
00:04:56.460 --> 00:04:57.140
<v 0>does this high.</v>

87
00:04:57.140 --> 00:04:59.100
This one of the reasons why I wanted to bring this up immediately.

88
00:04:59.101 --> 00:05:04.101
Does this highlight a flaw in the system in that people can target an individual

89
00:05:04.951 --> 00:05:07.920
cause with him,
he's uh,
he,
like I said,

90
00:05:07.921 --> 00:05:11.010
he's a doctor and a proponent of this carnivore die,
but he's also,

91
00:05:11.011 --> 00:05:15.810
he ruthless in his condemnation and mocking of vegans.

92
00:05:15.811 --> 00:05:20.430
He does it all the time and so then they get upset at him and they can target

93
00:05:20.431 --> 00:05:24.360
posts and just report them and mass.
And when they do that,

94
00:05:24.361 --> 00:05:25.470
then this becomes an issue.

95
00:05:26.210 --> 00:05:29.660
<v 2>I think this does reveal part of,
um,
you know,</v>

96
00:05:29.661 --> 00:05:34.580
the challenges that we face as a global platform at scale.
In this part,

97
00:05:34.600 --> 00:05:36.230
I don't,
I don't know what happened in this case,
sorry.

98
00:05:36.260 --> 00:05:37.370
It's hard for me to talk about it.

99
00:05:37.371 --> 00:05:41.540
But what I would say is that it doesn't really matter if one person reports it

100
00:05:41.541 --> 00:05:43.010
or 10,000 people report it.

101
00:05:43.040 --> 00:05:46.670
Like we're going to review the reports and we're going to make an assessment and

102
00:05:46.671 --> 00:05:48.260
we're never going to,
you know,

103
00:05:48.920 --> 00:05:52.730
kick someone off the platform finally and forever without a person taking a look

104
00:05:52.760 --> 00:05:55.790
and making sure that it's an actual violation of,
right.
Right.
Okay.

105
00:05:56.080 --> 00:05:58.070
So put the mob reporting

106
00:05:58.070 --> 00:05:58.910
<v 0>behavior does happen.</v>

107
00:05:59.010 --> 00:06:01.710
<v 2>Yeah,
it does.
It happens across the spectrum.</v>

108
00:06:01.890 --> 00:06:04.000
I'd have to assume it's going to be one direction.
I,

109
00:06:04.001 --> 00:06:08.040
I can't imagine he would target vegans,
but vegans would talk at him.
Right.
Well,

110
00:06:08.041 --> 00:06:09.270
he might,
I mean he does.

111
00:06:09.790 --> 00:06:12.390
Is he the kind of guy is going to want to report to vegans and get them banned

112
00:06:12.391 --> 00:06:14.250
from Twitter or is he gonna want to make fun of them?

113
00:06:14.310 --> 00:06:15.180
He's going to make fun of them.

114
00:06:15.230 --> 00:06:18.150
They're going to target him trying to get them removed by exploiting the system

115
00:06:18.151 --> 00:06:18.920
that you guys have.

116
00:06:18.920 --> 00:06:21.170
<v 0>It may not be him though.
It could also be his followers.</v>

117
00:06:21.260 --> 00:06:23.630
It's a really complicated world out there.
So you don't,

118
00:06:24.140 --> 00:06:28.510
the motivations of why people mop report are different and it's not always some

119
00:06:28.550 --> 00:06:31.930
under someone's control.
It could ease and even be other carnivores,

120
00:06:31.950 --> 00:06:35.870
dire proponents who are just jerks that don't like him because he's getting all

121
00:06:35.871 --> 00:06:38.570
the love people were weird.
Yeah,
but it's history.

122
00:06:38.960 --> 00:06:43.880
The idea though is that it does kind of highlight a bit of a flaw in that it's

123
00:06:43.881 --> 00:06:46.730
good that someone could like,
cause you might see something awful,

124
00:06:46.890 --> 00:06:50.360
someone doxing someone or something like that and then you can take that and

125
00:06:50.361 --> 00:06:54.770
report it and then people can see it and get rid of it and minimize the damage

126
00:06:55.060 --> 00:06:58.870
<v 2>that's done.
That there's another big problem here and that is the Carnivore Diet</v>

127
00:06:59.020 --> 00:07:01.120
legitimately healthy?
Is it a threat to your health?

128
00:07:01.480 --> 00:07:06.480
And if it is is what is Twitter's responsibility in controlling that

129
00:07:06.491 --> 00:07:08.650
information?
Right.
So just to clarify,
my,
my,

130
00:07:08.670 --> 00:07:11.830
my opinion is if he wants to be a proponent for the carnivore diet,
let them,

131
00:07:12.280 --> 00:07:16.030
but you've got people on Youtube who are being direct for certain beliefs about

132
00:07:16.031 --> 00:07:20.320
certain health issues that I don't agree with.
And so one of the risks then is,

133
00:07:20.560 --> 00:07:20.910
you know,

134
00:07:20.910 --> 00:07:24.220
we're coming towards a position where people think some ideas are better than

135
00:07:24.221 --> 00:07:24.851
others.
Therefore,

136
00:07:24.851 --> 00:07:27.160
as a company we're going to restrict access to certain information.

137
00:07:27.250 --> 00:07:30.060
You mean like anti-vaccine?
Exactly.
So,

138
00:07:30.061 --> 00:07:34.660
so I guess I'm trying to say is at what would you guys restrict someone from

139
00:07:34.661 --> 00:07:37.510
sharing info like false information about vaccines that could get someone hurt

140
00:07:39.170 --> 00:07:43.370
<v 0>that is not a violation of Twitter roles?
No,
I think,</v>

141
00:07:44.000 --> 00:07:47.660
I mean that'd be interesting to hear your ideas around this book or our

142
00:07:47.661 --> 00:07:51.410
perspective right now is,
um,
around this concept of variety of perspective.

143
00:07:52.110 --> 00:07:52.821
Like are we,

144
00:07:52.821 --> 00:07:57.620
are we encouraging more echo chambers and filter bubbles or we at least showing

145
00:07:57.621 --> 00:08:01.610
people other information that might be counter to what they see.
And there's,

146
00:08:02.240 --> 00:08:05.310
there's a bunch of research that would suggest that further emboldens or views.

147
00:08:05.311 --> 00:08:09.590
There's also research that suggests that it at least gives them a consideration

148
00:08:09.650 --> 00:08:13.160
about what their,
what they currently believe.
So would you guys,
oh,
go ahead.

149
00:08:13.340 --> 00:08:16.670
Sorry.
Given the dynamics of our network being completely public,

150
00:08:16.700 --> 00:08:20.810
we're not organized around communities.
We're not organized around topics.
Um,

151
00:08:21.260 --> 00:08:26.260
we have a little bit more freedom to show more of the spectrum of any one

152
00:08:26.331 --> 00:08:29.360
particular issue.
And I think that's how we would,

153
00:08:29.390 --> 00:08:33.350
we would approach it from the start.
That said,

154
00:08:33.380 --> 00:08:38.380
we haven't really dealt much with misinformation more broadly across like these

155
00:08:39.111 --> 00:08:40.160
sorts of topics.
We've,

156
00:08:40.161 --> 00:08:44.980
we've focused our efforts on elections and um,

157
00:08:45.050 --> 00:08:48.050
well mainly election trainer.
Yeah.
You thought it was a different animal.

158
00:08:48.051 --> 00:08:51.230
You know,
someone can really convince you that the earth is flat.

159
00:08:51.231 --> 00:08:55.140
If you're gullible and you watch a 45 minute youtube video right now it's kind

160
00:08:55.141 --> 00:08:55.974
of a different thing.

161
00:08:56.160 --> 00:08:56.551
<v 2>But I want to,</v>

162
00:08:56.551 --> 00:09:00.000
I wanted to just kind of get into that statement you made about misinformation

163
00:09:00.001 --> 00:09:01.110
and whether or not you'll police it.

164
00:09:01.580 --> 00:09:06.180
So I think that the tough part of this is really an love to have a discussion

165
00:09:06.181 --> 00:09:09.840
about this is do you really want corporations to police what's true and not
true?

166
00:09:09.900 --> 00:09:12.870
Absolutely not.
So really,
really tough position.
But you guys do that.

167
00:09:13.290 --> 00:09:16.560
We try not to do that.
We don't want to do that.
But please when your rules,

168
00:09:16.770 --> 00:09:19.950
but the places that we focus on is where we think that people are going to be

169
00:09:19.951 --> 00:09:24.951
harmed by this in a direct and tangible way that we feel a responsibility to

170
00:09:24.991 --> 00:09:27.880
correct,
correct ourselves rules.
Tim,
what do you mean by that?

171
00:09:28.790 --> 00:09:30.850
Gender dead naming and Miss Gender.

172
00:09:31.170 --> 00:09:34.560
That's a specific ideology that's unique to a very small faction of people in

173
00:09:34.561 --> 00:09:36.360
this world that you guys actually banned people for.

174
00:09:36.660 --> 00:09:39.960
So the way I think of it is it's behavior based.

175
00:09:39.990 --> 00:09:41.910
And I know you think of that as content and we can,

176
00:09:41.940 --> 00:09:43.170
we can disagree on this point,

177
00:09:43.440 --> 00:09:47.220
but this is about why are you doing this to a trans person?

178
00:09:47.250 --> 00:09:49.980
Why are you calling them by this name when they've chosen to go by a different

179
00:09:49.981 --> 00:09:52.170
name or why are you outing them in some way?

180
00:09:52.171 --> 00:09:57.150
Like what is your intent and purpose behind that?
But in the interest of clarity,

181
00:09:57.210 --> 00:10:01.210
I wanted to explain what deadnaming means.
Right?
Right.
So,

182
00:10:02.280 --> 00:10:06.000
so,
uh,
a transgender individual changes their name when they transition.

183
00:10:06.110 --> 00:10:08.790
A dead name would be the birth name or the name they went by before the

184
00:10:08.791 --> 00:10:11.670
transition though.
So it was my mom's probably going,

185
00:10:11.700 --> 00:10:14.340
what the text once a debt name.

186
00:10:14.550 --> 00:10:18.120
And I will clarify to your role specifically they targeted mis-gendering and

187
00:10:18.121 --> 00:10:20.920
deadnaming I believe it's correct.
Right?
So years ago we,

188
00:10:20.950 --> 00:10:24.750
we passed a policy that we call our hateful conduct policy and that prohibits

189
00:10:24.751 --> 00:10:29.370
targeting or attacking someone based on their belonging in any number of groups,

190
00:10:29.610 --> 00:10:32.310
whether it's because of their religion or their race or their gender,

191
00:10:32.550 --> 00:10:34.980
their sexual orientation and their gender identity.

192
00:10:34.981 --> 00:10:39.360
So it was something that's broad based is that you can't choose to attack people

193
00:10:39.361 --> 00:10:40.740
because of these characteristics,

194
00:10:40.741 --> 00:10:43.980
but you do have limits on what characteristics you police.
Right?
So you're not,

195
00:10:44.070 --> 00:10:48.450
you're not a banning people,
but for targeted transpi seeing others.
Right.
I will,

196
00:10:48.490 --> 00:10:50.970
we have also general abuse and harassment roles,
right?

197
00:10:50.971 --> 00:10:53.940
Which says you can't engage in abuse and harassment on the platform,

198
00:10:54.160 --> 00:10:58.590
but you can't designate someone,
but you can call them stupid.
Uh,
generally,

199
00:10:58.620 --> 00:11:00.970
I mean,
if you created an account that,
uh,

200
00:11:01.120 --> 00:11:04.860
only was there to call the same person stupid 5,000 times,

201
00:11:05.010 --> 00:11:08.790
we'd probably view that as the,
you know,
targeted,
harassed,
targeted harassment.

202
00:11:09.600 --> 00:11:10.490
It's a function of the bit,

203
00:11:10.491 --> 00:11:14.850
it's a function of behavior because people with our system can do this massive

204
00:11:14.851 --> 00:11:19.380
velocity ultimately silence you from a platform or to say like I give up,

205
00:11:19.381 --> 00:11:22.040
I don't want to deal with this thing.
Also there's a,

206
00:11:22.220 --> 00:11:26.250
so we can just get into all of the big examples.
I mean,
uh,

207
00:11:26.280 --> 00:11:27.420
starting with the to Tim,

208
00:11:27.421 --> 00:11:31.380
but can we just take a step back and try to level set of what we're trying to do

209
00:11:31.381 --> 00:11:34.980
with our policies because I think it's worth doing.
Yes.
So as,
as a,

210
00:11:35.100 --> 00:11:39.450
as a high level,
I personally,
and this is my job to run the policy team,

211
00:11:39.720 --> 00:11:43.350
I believe that everyone has a voice and should be able to use it and I want them

212
00:11:43.351 --> 00:11:45.150
to be able to use it online.
Now,

213
00:11:45.151 --> 00:11:50.151
where we draw a line is when people use their voice and use their platform to

214
00:11:50.611 --> 00:11:52.620
abusing her ass,
other people to silence them.

215
00:11:53.140 --> 00:11:56.530
Because I think that that's what we've seen over the years is a number of people

216
00:11:56.800 --> 00:11:59.770
who have been silenced online because of the abuse and harassment they've

217
00:11:59.771 --> 00:12:00.191
received.

218
00:12:00.191 --> 00:12:03.100
And they either stop talking or they leave the platform and its entirety.

219
00:12:03.280 --> 00:12:06.190
If you look at free expression and free speech laws around the world,

220
00:12:06.550 --> 00:12:08.170
they're not absolute.
They're not.
Absolutely.

221
00:12:08.200 --> 00:12:11.380
There's always limitations on what you can say and it's when you're starting to

222
00:12:11.381 --> 00:12:12.250
endanger other people.

