1
00:00:00,340 --> 00:00:03,800
You don't know if this is just
more bullshit. It's like in a,

2
00:00:03,820 --> 00:00:07,240
like you were saying earlier, if they
get you and you buy into it, hook,

3
00:00:07,241 --> 00:00:10,120
line and sinker, they win. If
they get you to think, well,

4
00:00:10,121 --> 00:00:12,820
how much else is bullshit?
They still went, Yup.

5
00:00:12,970 --> 00:00:17,050
Because you're looking at everything
with sort of this tainted lens now

6
00:00:17,350 --> 00:00:22,350
everything seemed and the sense that's
probably the ultimate goal is to disrupt

7
00:00:23,440 --> 00:00:27,910
our social media environment
and to sort of hijack the,

8
00:00:28,150 --> 00:00:31,360
the natural conversations
that are taking place.

9
00:00:31,620 --> 00:00:35,370
Yeah. And I think it's, I mean, it's
effective. There's certain, you know,

10
00:00:35,760 --> 00:00:38,130
I was in Estonia last year,
um,

11
00:00:38,520 --> 00:00:40,710
and they've been targeted by
this stuff for decades now.

12
00:00:41,240 --> 00:00:43,230
A 25% Russian speaking population.

13
00:00:43,231 --> 00:00:46,530
And most of the news that they get is
from Russian media. Right. You know,

14
00:00:46,531 --> 00:00:48,240
right on the border.
Um,

15
00:00:48,300 --> 00:00:53,300
they talk a lot about the
extreme commitment to educating
their citizens to make

16
00:00:56,431 --> 00:00:58,080
them realize that this
kind of thing does happen.

17
00:00:58,830 --> 00:01:03,500
This is what it usually looks like.
Um, don't share it here. You know,

18
00:01:03,630 --> 00:01:05,310
just ignore it.
Let it go by.

19
00:01:05,910 --> 00:01:08,700
And I don't think we're quite there yet.

20
00:01:09,210 --> 00:01:13,890
I think that there's still plenty of
people in the country who don't believe it

21
00:01:13,891 --> 00:01:15,150
happened.
Um,

22
00:01:15,660 --> 00:01:20,660
or for some reason are completely
incapable of separating the Russian social

23
00:01:22,681 --> 00:01:27,681
media influence campaign happened from
it means Donald Trump's election is a

24
00:01:27,691 --> 00:01:30,330
legitimate, or it means
Donald Trump colluded, right?

25
00:01:30,330 --> 00:01:34,230
Those are very different statements that
you don't have to collude in order for

26
00:01:34,231 --> 00:01:38,340
someone somewhere to unsolicited
go and support your candidacy.

27
00:01:39,120 --> 00:01:41,490
So you can believe two
things simultaneously,

28
00:01:41,790 --> 00:01:45,810
one that Trump did not collude and that
his election is perfectly legitimate and

29
00:01:45,811 --> 00:01:50,400
that this had no impact and to that it
still happened. And that I think is, um,

30
00:01:50,670 --> 00:01:55,670
I am consistently amazed when I read
my social media mentions it at how hard

31
00:01:57,901 --> 00:02:01,170
that ability to hold those
two ideas is for, for people.

32
00:02:01,171 --> 00:02:04,020
They just believe that if
they're supporters of Trump,

33
00:02:04,590 --> 00:02:08,880
they absolutely cannot acknowledge
that this operation took place.

34
00:02:09,540 --> 00:02:14,220
And I, or if they are passionate
supporters of the far left.

35
00:02:14,640 --> 00:02:18,570
Um, it's more of like an
equivocation, you know, well,

36
00:02:18,571 --> 00:02:21,330
we don't really know if they did it well.
The rest does bad things too well.

37
00:02:21,331 --> 00:02:25,680
How do we know? You know,
so that's where, um, it, it,

38
00:02:25,750 --> 00:02:28,830
it plays out very differently depending
on which part of the political spectrum

39
00:02:28,831 --> 00:02:29,664
you sit on.

40
00:02:30,280 --> 00:02:30,491
Well,

41
00:02:30,491 --> 00:02:35,380
it falls right into are the issue that
we have with cognitive dissonance.

42
00:02:35,840 --> 00:02:38,140
We believe in someone or
if we want someone to win,

43
00:02:38,141 --> 00:02:43,060
especially if it's our team or our person
or on our side, you know, like I, I,

44
00:02:43,570 --> 00:02:43,871
yeah,

45
00:02:43,871 --> 00:02:48,871
I saw a lot of this when Donna Brazil
released her book detailing how the DNC

46
00:02:50,201 --> 00:02:54,850
sort of rig the primaries against Bernie
Sanders and, and, and for Clinton,

47
00:02:54,851 --> 00:02:56,860
there was so many people that were Clinton
supporters that just didn't want to

48
00:02:56,861 --> 00:02:59,620
believe it. I was like, well,
why wouldn't you believe woman?

49
00:02:59,650 --> 00:03:02,470
Like you believed her before when she
was supporting Clinton and then when she

50
00:03:02,471 --> 00:03:06,100
leaves now you're now, you won't believe
her. It's because it's inconvenient.

51
00:03:06,310 --> 00:03:09,820
And we were real weird in our binary view.

52
00:03:10,150 --> 00:03:14,500
We want things to be good or
bad is one or zero. This is it.

53
00:03:14,680 --> 00:03:18,280
And this is a super complex issue.

54
00:03:18,680 --> 00:03:22,630
It seems like they've been doing this
for a long time and they've gotten really

55
00:03:22,631 --> 00:03:23,710
sophisticated at it.

56
00:03:23,950 --> 00:03:26,500
And I think there's a lot of people that
have been sucked into it that have no

57
00:03:26,501 --> 00:03:28,470
idea that it's actually
influenced the way they've,

58
00:03:28,510 --> 00:03:31,750
they've formed their own opinions.
This is where it gets really strange.

59
00:03:31,751 --> 00:03:35,920
People are so malleable and
they're so easily manipulated.

60
00:03:36,160 --> 00:03:40,960
Many people are that something like this,
like a real good solid,

61
00:03:40,961 --> 00:03:45,961
concentrated effort to try to target
these groups that have these very specific

62
00:03:46,601 --> 00:03:51,601
interests and really dig in and
form roots and then go home.

63
00:03:52,130 --> 00:03:54,750
I mean, it's so sophisticated.
They're their approaches.

64
00:03:55,500 --> 00:03:59,490
I'm on one hand horrified and the
other hand deeply impressed. Yep.

65
00:04:00,250 --> 00:04:01,083
Me Too.

66
00:04:02,070 --> 00:04:06,580
Now what was this freaking you out when
you had to like go over all these memes

67
00:04:06,581 --> 00:04:09,630
and you were actually laughing at
them and you're like, God dammit.

68
00:04:11,360 --> 00:04:14,750
Well, you know, there's the tweet
that goes around every now and then.

69
00:04:14,990 --> 00:04:18,020
You don't have to hand it to them.
And I'm always like, ah, how do I, um,

70
00:04:18,800 --> 00:04:21,980
how do I properly convey, uh, um,

71
00:04:22,640 --> 00:04:26,890
recognition for the, you know, I,

72
00:04:26,930 --> 00:04:30,080
I don't think we do ourselves any favors
by pretending it all sucked and didn't

73
00:04:30,081 --> 00:04:31,790
matter in there and competent.
Right.

74
00:04:31,940 --> 00:04:34,460
I think that you have to acknowledge that
you have this sophisticated adversary

75
00:04:34,910 --> 00:04:39,470
that is very capable. Those
very determined that is
constantly evolving. Um,

76
00:04:39,590 --> 00:04:42,530
and to treat that with the
degree of respect it deserves.

77
00:04:42,620 --> 00:04:47,150
I think that that's just
common sense actually. Um, I,

78
00:04:48,980 --> 00:04:53,930
I, I read media on both sides of
the aisle and I, I, you know, um,

79
00:04:54,500 --> 00:04:58,250
I feel I try to stay current actually
on what memes are percolating in lots of

80
00:04:58,251 --> 00:05:01,880
different spaces and part just because
I am always curious about what's organic

81
00:05:01,881 --> 00:05:06,290
versus what seems to be disproportionately
amplified or what new communities are

82
00:05:06,291 --> 00:05:07,430
popping up.
I just think it's an,

83
00:05:07,460 --> 00:05:12,140
I think the spread of information among
people is just a very interesting,

84
00:05:12,590 --> 00:05:14,240
you know, it's, it, it's
something that interest me a lot.

85
00:05:14,241 --> 00:05:16,340
I think crowd psychology
is really interesting.

86
00:05:16,520 --> 00:05:20,720
I think ways that crowd psychology has
transformed as the Internet has kind of

87
00:05:20,721 --> 00:05:21,620
come into being,

88
00:05:23,750 --> 00:05:26,960
particularly with things
like the mass consolidation,

89
00:05:27,200 --> 00:05:29,150
the ease with which we can target people.
You know,

90
00:05:29,151 --> 00:05:33,440
we didn't even really talk about that,
but the, um, one of the things with,

91
00:05:33,710 --> 00:05:35,600
there's always, you know, even
in a decentralized internet,

92
00:05:35,601 --> 00:05:39,350
there's always been propaganda.
There's always been, um,
crazy conspiracy theories,

93
00:05:39,380 --> 00:05:40,190
all this stuff.

94
00:05:40,190 --> 00:05:43,460
But it's that you can reach the people
who are likely to be receptive to it now.

95
00:05:43,930 --> 00:05:48,170
And as people self select into tribes,
particularly in this country right now.

96
00:05:48,680 --> 00:05:49,513
Um,

97
00:05:49,700 --> 00:05:53,840
one of the things that's remarkable
is the way in which once you've self

98
00:05:53,841 --> 00:05:57,470
selected into that tribe and this is
the media in your ecosystem and share it

99
00:05:57,471 --> 00:05:58,161
with your friends.

100
00:05:58,161 --> 00:06:00,860
And Facebook ensures that the people
who see it are the people who are most

101
00:06:00,861 --> 00:06:05,570
likely to be receptive to it. Where if
you run the ad targeting you directly,

102
00:06:05,600 --> 00:06:08,540
you know, send it into the feeds of
people most likely to be receptive to it.

103
00:06:09,080 --> 00:06:14,080
We have this interesting phenomenon where
consolidation targeting and then these

104
00:06:14,320 --> 00:06:19,320
gainable algorithms mean that it's
just this kind of information goes way

105
00:06:20,811 --> 00:06:23,300
farther, way faster than it
ever could have in the past,

106
00:06:23,301 --> 00:06:24,290
regardless of whether it's.

