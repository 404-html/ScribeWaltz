1
00:00:00,060 --> 00:00:03,690
So there's a point to be made. If you, I
understand you want a healthy, like you,

2
00:00:03,691 --> 00:00:05,580
you want Twitter to grow,
you need it to grow.

3
00:00:05,670 --> 00:00:08,550
The shareholders needed to grow
that advertisers need to advertise.

4
00:00:08,551 --> 00:00:09,690
So you've got all these restrictions,

5
00:00:10,230 --> 00:00:12,510
but allowing people to
say these awful things,

6
00:00:12,660 --> 00:00:16,740
make sure we stay away from them and
it allows us to avoid certain people.

7
00:00:16,741 --> 00:00:19,500
And it isn't an important to know
that these people hold these beliefs.

8
00:00:19,710 --> 00:00:21,030
If you get rid of him,
you know,

9
00:00:21,031 --> 00:00:23,480
someone could walk into a business and
you wouldn't even know that they were in

10
00:00:23,481 --> 00:00:26,550
Neo Nazi, but if they were high profile
saying there things, you'd be like,

11
00:00:26,551 --> 00:00:28,250
that's the guy at home.
Like you're absolutely right.

12
00:00:28,260 --> 00:00:30,930
This is like one of my favorite
sayings is that sunlight is the best

13
00:00:30,931 --> 00:00:34,080
disinfectant and it's so, so, so true.

14
00:00:34,140 --> 00:00:38,630
I like one of the biggest problems with
censorship is the fact that you pushed

15
00:00:38,631 --> 00:00:41,340
people underground and you
don't know what's going on.

16
00:00:41,700 --> 00:00:43,050
And this is something I worry about.

17
00:00:43,260 --> 00:00:46,410
It's not that I don't worry if
you ban people for these roles.

18
00:00:46,411 --> 00:00:50,490
I also worry about driving people away
from the platform and affecting their

19
00:00:50,491 --> 00:00:51,211
real lives.

20
00:00:51,211 --> 00:00:55,440
So what we're trying to find this right
balance and I hear you like you may not

21
00:00:55,441 --> 00:00:58,380
think we're drawing the lines in the
right place and we get that feedback all

22
00:00:58,381 --> 00:01:00,660
the time and we're always
trying to find the right places.

23
00:01:01,160 --> 00:01:06,060
But I worry as much about like the
underground and like being able to shine a

24
00:01:06,061 --> 00:01:07,890
light on these things is as anything else.

25
00:01:08,340 --> 00:01:12,990
I think it's a cost benefit analysis and
we have to constantly rehash it and do

26
00:01:13,010 --> 00:01:14,430
it.
Like we,

27
00:01:14,810 --> 00:01:19,800
we have the technology we have today
and we are looking at technologies which

28
00:01:19,801 --> 00:01:24,801
opened up the aperture even more and we
all agree that a binary on or off is not

29
00:01:28,651 --> 00:01:30,600
the right answer and is not scalable.

30
00:01:31,080 --> 00:01:36,060
We have started getting into nuance
within our enforcement and we've also

31
00:01:36,061 --> 00:01:40,110
started getting into nuance with
the presentation of, of content.

32
00:01:40,111 --> 00:01:41,400
So you know,

33
00:01:42,390 --> 00:01:47,390
one path might have been for some of
your replies for us to just remove that,

34
00:01:48,060 --> 00:01:51,240
those, you know, offensive replies
completely. We don't do that.

35
00:01:51,241 --> 00:01:56,060
We hide it behind an interstitual
to protect the original tweeter and,

36
00:01:56,080 --> 00:02:00,270
and, and also folks who don't want to
see that they can still see everything.

37
00:02:00,271 --> 00:02:03,060
They just have to do one more top.
So that's one solution.

38
00:02:03,061 --> 00:02:04,200
Ranking is another solution,

39
00:02:04,201 --> 00:02:07,320
but as technology gets better and
we get better at applying to it,

40
00:02:07,740 --> 00:02:10,230
we have a lot more
optionality whereas we don't,

41
00:02:10,320 --> 00:02:11,880
we don't have that as much today.

42
00:02:12,230 --> 00:02:16,140
I feel like, I'm just going to reiterate
an earlier point though, you know,

43
00:02:16,170 --> 00:02:19,230
if you recognize sunlight is the best
disinfectant, you're, it's like you're,

44
00:02:19,231 --> 00:02:22,320
you're chasing after a goal that
can never be met. If you wanna.

45
00:02:22,350 --> 00:02:24,900
If you want to protect all speech and
they start banning certain individual,

46
00:02:24,940 --> 00:02:27,060
you want to, you want to increase
the amount of healthy conversations,

47
00:02:27,300 --> 00:02:29,100
but you're banning some people.
Well,

48
00:02:29,101 --> 00:02:31,230
how long until this group
is now funded by that group?

49
00:02:31,231 --> 00:02:32,850
How long until you've banned everybody?
I hear you.

50
00:02:33,090 --> 00:02:37,900
I don't believe a permanent ban promotes
health. I don't believe that. But we,

51
00:02:37,901 --> 00:02:42,540
we have to, we have to work
with the technologies, tools
and conditions that we,

52
00:02:42,780 --> 00:02:43,830
that we have today.

53
00:02:43,980 --> 00:02:48,980
So and evolve over over time
to where we can see examples.

54
00:02:49,600 --> 00:02:50,910
Um, like, uh,

55
00:02:51,030 --> 00:02:55,440
this woman at the Westboro Baptist Church
who was using Twitter every single day

56
00:02:55,860 --> 00:02:59,100
to spread hate against
the Lgbtqa community.

57
00:02:59,560 --> 00:03:01,840
And over time we had,

58
00:03:01,870 --> 00:03:06,610
I think it was three or four folks on
Twitter who would engage her every single

59
00:03:06,610 --> 00:03:10,310
day about what she was doing. And she
actually left the church, Michael Phelps.

60
00:03:11,160 --> 00:03:15,040
She's amazing. And she is, she's not
pulling her family out of that as well.

61
00:03:15,041 --> 00:03:19,330
And you could make the argument that
if we banned that account early on,

62
00:03:19,720 --> 00:03:23,550
she would have never left the church. I
completely hear that. We, we get it. It's,

63
00:03:23,560 --> 00:03:24,393
it's just,

64
00:03:24,780 --> 00:03:26,820
well, so let's, let's, I just
want to make sure we had,

65
00:03:26,821 --> 00:03:29,440
we're advancing the conversation too
and not just going to go back. So, uh,

66
00:03:29,670 --> 00:03:30,391
I'll just ask you this.

67
00:03:30,391 --> 00:03:33,510
Have you considered allowing some of
these people permanently banned it back on

68
00:03:33,511 --> 00:03:36,330
with some restrictions?
Maybe you can only tweet twice per day,

69
00:03:36,331 --> 00:03:38,280
maybe you can't retweet or
something to that effect.

70
00:03:38,420 --> 00:03:40,810
I think we're very early in
our thinking here. So we're,

71
00:03:40,811 --> 00:03:42,530
we're open minded to how to do this.

72
00:03:42,560 --> 00:03:46,370
I think we agree philosophically that
permanent bans aren't extreme case

73
00:03:46,371 --> 00:03:49,500
scenario and it shouldn't be one of our,
you know,

74
00:03:49,640 --> 00:03:51,590
regular use tools in our tool chest.

75
00:03:51,950 --> 00:03:55,670
So how we do that I think is something
that we're actively talking about today.

76
00:03:55,970 --> 00:03:58,150
Is there a timeline that we can so,

77
00:03:58,151 --> 00:04:01,760
so look in all loving dad would fix
a lot of problems. I think so, yes.

78
00:04:01,760 --> 00:04:02,990
I really do.
Like,

79
00:04:03,020 --> 00:04:06,410
I'm just curious like are you thinking
like bands of a year or five years,

80
00:04:06,411 --> 00:04:08,330
10 years?
I'm just curious like what is,

81
00:04:08,360 --> 00:04:11,360
what is a reasonable ban
in this kind of context?

82
00:04:11,750 --> 00:04:14,930
I think reasonably so much enough to
state their case as to why they want to be

83
00:04:14,931 --> 00:04:19,280
unbanned. Like someone should have to
have a like, um, uh, well measured,

84
00:04:19,281 --> 00:04:22,600
considerate response to
what they did wrong. Did,

85
00:04:22,601 --> 00:04:24,110
do they agree with what they did wrong?

86
00:04:24,260 --> 00:04:28,970
Maybe perhaps saying why they don't think
they did anything wrong and you could

87
00:04:28,971 --> 00:04:32,300
review it from there. Hmm. I think,
um, you know, one of the challenges,

88
00:04:32,320 --> 00:04:35,620
we have the benefit in English common
law of hundreds of years of precedent and

89
00:04:35,621 --> 00:04:37,960
developing new rules and figuring
out what works and doesn't,

90
00:04:37,961 --> 00:04:40,990
Twitter is very different.
So I think with the technology,

91
00:04:40,991 --> 00:04:43,960
I don't know if you need permanent bans
or even, or even suspensions at all,

92
00:04:43,990 --> 00:04:46,240
you could literally just, uh, I mean,

93
00:04:46,570 --> 00:04:50,980
lock someone's account is essentially
suspending them. But, uh, I, I again, I,

94
00:04:51,020 --> 00:04:53,980
I wouldn't claim to know anything
about the things that you go through,

95
00:04:53,981 --> 00:04:57,580
but what if you just restricted most
of what they could say? You know,

96
00:04:57,581 --> 00:04:59,860
you blocked certain words in a
certain dictionary. If someone's been,

97
00:04:59,920 --> 00:05:03,280
if someone was greased hill, oh, but no,
but, but, but the thing about it this way,

98
00:05:03,281 --> 00:05:06,340
is it better that they're permanently
banned or sound better, but it's not,

99
00:05:06,670 --> 00:05:08,710
it's not good.
I don't know to think about it this way.

100
00:05:08,800 --> 00:05:11,020
Instead of being suspended for 72 hours,

101
00:05:11,110 --> 00:05:13,480
you get a dictionary block
from paid speech words.

102
00:05:13,900 --> 00:05:14,733
Right.

103
00:05:15,040 --> 00:05:17,130
That makes sense.
If people just use kind of language,

104
00:05:17,160 --> 00:05:19,520
this is what we see all
the time. Yeah. Good move.

