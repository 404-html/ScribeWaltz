1
00:00:00,480 --> 00:00:04,610
I mean, even though the reality is,
you know, Facebook is a technology,

2
00:00:04,611 --> 00:00:06,900
I'm here that the Facebook friends
are going to really hate me for this.

3
00:00:06,901 --> 00:00:11,880
But here Facebook is a technology to
exploit insecurity for the purpose of

4
00:00:11,881 --> 00:00:13,740
selling ads.
That's what it does.

5
00:00:14,100 --> 00:00:17,070
What it does is make you feel
like you've check and you're like,

6
00:00:17,190 --> 00:00:20,280
why didn't she like that photograph
or why isn't he friended me?

7
00:00:20,700 --> 00:00:25,700
And so you constantly engage because
you're constantly trying to feed this,

8
00:00:26,990 --> 00:00:31,320
you know, feedback. And
that is exploiting Tristan.

9
00:00:31,470 --> 00:00:35,580
Tristan Harris's work is really a powerful
here is exploiting your insecurity

10
00:00:35,850 --> 00:00:36,690
and severally what it is.

11
00:00:36,691 --> 00:00:40,650
Because I've always thought about it
as being a fast food version of the

12
00:00:40,651 --> 00:00:44,220
nutrients that we're missing in an
actual real community. That's so good.

13
00:00:44,280 --> 00:00:46,290
That's exactly the right
way to think about it.

14
00:00:46,320 --> 00:00:51,320
But just in the same way that fast food
companies figure out how to exploit the

15
00:00:51,871 --> 00:00:55,500
brain chemistry that makes it so
that you eat chicken wings, you know,

16
00:00:55,590 --> 00:00:59,010
barbecue chicken wings because they know
that's what's going to feed that kind

17
00:00:59,011 --> 00:01:03,430
of addiction. And just like
gaming companies figure
out how to tweak the game.

18
00:01:03,431 --> 00:01:06,480
So that they'd know how to get
the addiction out of your kids.

19
00:01:06,970 --> 00:01:11,970
This company is really great if by getting
you to like turnover as much as you

20
00:01:12,751 --> 00:01:17,310
can to them to build you into this quote
community. Why are they doing that?

21
00:01:17,670 --> 00:01:20,910
Not because Mark Zuckerberg has come
some kind of freaky guy who wants to know

22
00:01:20,911 --> 00:01:24,210
your secrets, but because the
more you turn over to them,

23
00:01:24,720 --> 00:01:28,200
the better their ads are
in feeding you information.

24
00:01:28,350 --> 00:01:33,090
So this is a technology for the
purpose of engendering advertising.

25
00:01:33,600 --> 00:01:36,930
And so that advertising gets really,
really good. And so, you know,

26
00:01:36,931 --> 00:01:39,720
you could say that Facebook
is tilted to the left,

27
00:01:39,721 --> 00:01:43,410
but the reality is there
was an extraordinary amount
of exploitation of the

28
00:01:43,411 --> 00:01:46,620
advertising inside of Facebook
to feed information to the right.

29
00:01:46,621 --> 00:01:50,700
And this last election, I mean this is
what Kathleen Hall Jamieson Book about.

30
00:01:50,700 --> 00:01:55,700
This is really quite amazing and
documenting and that's because it's gotten

31
00:01:55,861 --> 00:01:59,520
really good at being able
to segment markets on the
basis of what people know or

32
00:01:59,521 --> 00:02:03,150
care about. Again, not because anybody
planned it, nobody wrote Jew hater.

33
00:02:03,270 --> 00:02:05,700
But because the AI is smart
enough to figure that out.

34
00:02:06,150 --> 00:02:11,150
And so when you build this technology
that is driven to the purpose of making it

35
00:02:11,580 --> 00:02:16,460
easier to sell ads, you produce
this world that um, you know,

36
00:02:16,470 --> 00:02:20,010
has no necessary connection to figuring
people, figuring out what the truth is.

37
00:02:20,040 --> 00:02:21,240
Again,
think of cable television.

38
00:02:21,241 --> 00:02:24,990
Cable television is about
building really loyal community,

39
00:02:25,350 --> 00:02:27,120
building the tribal
sense of the community.

40
00:02:27,690 --> 00:02:30,300
If telling the truth did that
they would tell the truth.

41
00:02:30,930 --> 00:02:33,780
If not telling the truth does
that they will not tell the truth.

42
00:02:33,990 --> 00:02:36,570
And the question is not whether
you're telling the truth or not.

43
00:02:36,571 --> 00:02:40,590
The question is what builds the
advertising base. And so this,

44
00:02:40,620 --> 00:02:45,190
this reality that we have, these
platforms that are ad driven, um,

45
00:02:45,600 --> 00:02:50,550
distort or constructs drives that
platform to develop in certain ways.

46
00:02:51,000 --> 00:02:52,950
And that's why I think it's
important to think, well,

47
00:02:52,951 --> 00:02:56,370
what if we could create a competitive
environment where there were different

48
00:02:56,371 --> 00:03:00,220
platforms available, ones that we're
not focused on, you know, driving ads.

49
00:03:00,580 --> 00:03:04,430
And this is something that I get, I think
power. They fund those. Isn't that the,

50
00:03:04,431 --> 00:03:07,300
the the reason why something like
Google or Facebook has gotten so big,

51
00:03:07,301 --> 00:03:08,950
it's because there's so
much money behind it. Well,

52
00:03:08,951 --> 00:03:12,310
two things because they've been allowed
to get so big and because so much money

53
00:03:12,311 --> 00:03:15,070
behind would stop them. The
antitrust departments, you know,

54
00:03:15,090 --> 00:03:17,680
the people in antitrust department
would step in and say, Facebook,

55
00:03:17,681 --> 00:03:19,030
you become too successful.

56
00:03:19,080 --> 00:03:22,690
The way you're buying up competitors
is disturbing to us. Well, but again,

57
00:03:22,750 --> 00:03:25,930
the thing of the difference in that
sentence, you become so successful.

58
00:03:25,930 --> 00:03:27,010
That's one sentence.

59
00:03:27,100 --> 00:03:30,340
And what we want to do in America
encourage companies to become successful.

60
00:03:30,341 --> 00:03:34,060
I believe in, you know, innovators and
markets working that's really great,

61
00:03:34,660 --> 00:03:37,930
but you've bought your competitor
is a separate statement.

62
00:03:38,080 --> 00:03:41,230
Like you have a bunch of money because
the stock is so valuable because people

63
00:03:41,231 --> 00:03:42,640
think you're the future of money,

64
00:03:43,120 --> 00:03:47,350
but then you turn and use that
money to buy a competitors.

65
00:03:47,650 --> 00:03:49,090
What are you putting
up, Jamie? What is this?

66
00:03:49,120 --> 00:03:51,920
That's the total number of
they've spent in the last, I,

67
00:03:52,150 --> 00:03:55,390
I think it was seven years to sell the
companies they bought. Scroll back. Don't,

68
00:03:55,420 --> 00:03:58,120
don't move. Okay. Total
cost of acquisitions.

69
00:03:58,510 --> 00:04:01,300
What does that $23 trillion billion.
Billion.

70
00:04:01,330 --> 00:04:06,330
$23 billion more than the gross
domestic product of a Fiji,

71
00:04:06,820 --> 00:04:10,390
Zimbabwe and mild Deeves combined.
19 billion of that was for that one.

72
00:04:10,570 --> 00:04:14,510
What's that? Really?
Yeah. 19 billion. Holy.

73
00:04:16,270 --> 00:04:20,500
Anyway. Yeah. So, but the point is,
when you're talking about acquisitions,

74
00:04:20,560 --> 00:04:23,200
you're not necessarily talking about
companies that are succeeding because

75
00:04:23,201 --> 00:04:24,440
they're so good.
Right.

