1
00:00:00,030 --> 00:00:03,210
Using an algorithm though,
do you not miss context?

2
00:00:03,270 --> 00:00:06,960
I mean it seems to me that there's a
lot of people that say things in humor,

3
00:00:07,350 --> 00:00:10,440
you know, or, or slurs within
particular communities,

4
00:00:10,441 --> 00:00:13,560
which is perfectly
reasonable, right? So yes,

5
00:00:13,650 --> 00:00:17,010
there is a danger of the algorithm
is missing context and that's why we,

6
00:00:17,011 --> 00:00:20,850
we really want to go carefully into this
and this is why we've scoped it down

7
00:00:20,851 --> 00:00:22,350
first and foremost to doxing,

8
00:00:22,920 --> 00:00:27,030
which is at least first it hits her
number one goal of protecting physical

9
00:00:27,031 --> 00:00:27,510
safety.

10
00:00:27,510 --> 00:00:31,530
Like making sure that nothing done online
will impact someone's physical safety

11
00:00:31,531 --> 00:00:33,990
on offline,
on our platform in this case.

12
00:00:34,530 --> 00:00:39,530
The second is that there are patterns
around doxing that are much easier to see

13
00:00:40,680 --> 00:00:45,030
without having the context. There
are, there are exceptions of course,

14
00:00:45,031 --> 00:00:49,950
cause you could docs, um, someone's
public, you know, uh, uh, representatives,

15
00:00:49,951 --> 00:00:52,950
public, uh, office, phone
number and email address.

16
00:00:52,980 --> 00:00:54,960
And the algorithm might catch that,

17
00:00:55,230 --> 00:00:58,950
not have the context that this is a US
representative and this information is

18
00:00:58,951 --> 00:01:01,290
already public.
So essentially this just,

19
00:01:01,540 --> 00:01:06,540
it highlights how insanely difficult
it is to monitor all of these posts.

20
00:01:07,200 --> 00:01:09,810
And then what, what is the volume?
Like what, what are we dealing with?

21
00:01:09,811 --> 00:01:13,920
Like how many posts do you guys get a day?
Hundreds of millions of posts a day.

22
00:01:14,430 --> 00:01:19,130
And how many human beings are manually
reviewing any of these things?

23
00:01:19,490 --> 00:01:23,820
I don't have that, that number. A
lot. Thousands. Hundreds of thousands.

24
00:01:23,821 --> 00:01:28,260
How many employees? You guys have 4,000
employees around the world. That's it.

25
00:01:29,200 --> 00:01:32,010
We have 4,000 employees.
The reason that's crazy though,

26
00:01:32,011 --> 00:01:33,000
but stop and think about that.

27
00:01:33,001 --> 00:01:37,420
4,000 people that are monitoring hundreds
of millions of tweets. And uh, we,

28
00:01:37,440 --> 00:01:38,400
we have, uh, we have, uh,

29
00:01:38,430 --> 00:01:42,450
we have a small team who's
monitoring tweets and some
of them are employed by us.

30
00:01:42,450 --> 00:01:46,050
Some of them are contractors throughout,
throughout the world. So 4,000 employees,

31
00:01:46,051 --> 00:01:49,380
total, 4,000 employees who are
engineers, who are designers,

32
00:01:49,381 --> 00:01:54,381
who are lawyers so that people actually
monitoring tweets is probably less than

33
00:01:54,390 --> 00:01:55,223
a thousand.
Uh,

34
00:01:55,230 --> 00:02:00,000
well the reason we don't give out
specific numbers is we need to scale these

35
00:02:00,001 --> 00:02:04,260
dynamically, right? If we see a particular
event within, uh, within country,

36
00:02:04,680 --> 00:02:08,280
we might hire 100 more people
on contract to deal with it,

37
00:02:08,670 --> 00:02:11,720
whereas they may not be full and,
and with us the entire time,

38
00:02:11,730 --> 00:02:15,330
or they have the ability to take down
tweets. Uh, they have, they have the,

39
00:02:15,570 --> 00:02:20,310
so as we get reports, it goes into a
queue and those are ranked by severity.

40
00:02:20,730 --> 00:02:23,280
And then we have people who look
at our rules and look at the,

41
00:02:23,310 --> 00:02:25,680
look at the tweets and look at the
behavior and the context around it.

42
00:02:26,160 --> 00:02:30,660
And they have the ability to go
down that enforcement spectrum.

43
00:02:30,690 --> 00:02:33,960
The vigil talked about one,
make people log in,

44
00:02:34,110 --> 00:02:38,910
read why it's a violation over tweet
and delete it to temporary suspensions.

45
00:02:38,940 --> 00:02:43,470
And finally, a permanent suspension,
which is the absolute last resort,

46
00:02:43,471 --> 00:02:45,750
which we ultimately do not want to do.

47
00:02:45,751 --> 00:02:50,400
We want to make sure that our rules are
also guided towards incentivizing more

48
00:02:50,520 --> 00:02:53,760
healthy conversation and, and
more, more participation. Yeah.

