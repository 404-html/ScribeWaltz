1
00:00:00,060 --> 00:00:00,893
Thanks for having me.

2
00:00:01,170 --> 00:00:04,590
I listened to you on Sam Harris'
podcast and I was utterly stunned.

3
00:00:04,620 --> 00:00:08,550
I had to listen to it twice cause I just
couldn't believe it. Let's get into,

4
00:00:08,551 --> 00:00:11,340
let's get into this from the beginning.
How did this start out?

5
00:00:11,341 --> 00:00:13,440
How did you start researching these,

6
00:00:13,441 --> 00:00:17,910
a online Russian trolls
and bots and all this jazz?

7
00:00:18,010 --> 00:00:22,560
Yeah, so a couple of years
back in around 2015, um, I,

8
00:00:22,670 --> 00:00:26,650
I had had my first baby in 2013 and I
was getting on these preschool lists.

9
00:00:26,651 --> 00:00:29,760
And what I decided to do was
I started looking at, um,

10
00:00:30,190 --> 00:00:34,450
anti vaccine activity in California
because I had a kid and I wanted to, uh,

11
00:00:34,840 --> 00:00:35,081
you know,

12
00:00:35,081 --> 00:00:38,350
put them on preschool lists or I was going
to fit with the parents basically. Um,

13
00:00:38,351 --> 00:00:43,351
as someone who vaccinates and I started
looking at the way that small groups,

14
00:00:43,811 --> 00:00:48,130
we're able to kind of disproportionately
amplify messages on social channels.

15
00:00:48,640 --> 00:00:51,250
And some of this was through
very legitimate activity.

16
00:00:51,251 --> 00:00:54,280
And then some of it was through really
kind of coordinated deliberate attempts

17
00:00:54,281 --> 00:00:58,450
to kind of game, um, ways that
algorithms were amplifying content,

18
00:00:58,451 --> 00:01:00,490
amplifying particular types of narratives.

19
00:01:01,030 --> 00:01:06,010
And I thought it was interesting and
I started writing about it and I, um,

20
00:01:06,100 --> 00:01:10,270
I wound up writing about ways in
which, um, hashtag gaming, um,

21
00:01:10,271 --> 00:01:13,990
ways in which people were kind of using
automation to just be in a Hashtag all

22
00:01:13,991 --> 00:01:14,410
the time.

23
00:01:14,410 --> 00:01:17,530
So it was kind of a way to really gain
control of share voice and what that

24
00:01:17,531 --> 00:01:21,550
meant when very small groups of people
could achieve this kind of phenomenal

25
00:01:21,551 --> 00:01:26,410
amplification and what the pros and cons
of that were. And then this was, um,

26
00:01:26,440 --> 00:01:30,070
2015. So the way that,
that this sort of, um,

27
00:01:31,480 --> 00:01:33,780
awareness of social media challenges came,

28
00:01:33,850 --> 00:01:36,400
came about was actually
when I was working on this.

29
00:01:36,401 --> 00:01:40,150
Other people were looking at it from the
same, um, looking at the same tactics,

30
00:01:40,151 --> 00:01:42,670
but how they were being used by Isis,
by the terrorist organization.

31
00:01:43,270 --> 00:01:43,961
And they're also,

32
00:01:43,961 --> 00:01:47,110
you had this very small group of
people that manage to use bots and

33
00:01:47,111 --> 00:01:50,410
amplification to really kind of own
a narrative, really pushed this,

34
00:01:50,760 --> 00:01:54,640
this brand is this digital caliphate to
kind of build it on all social platforms

35
00:01:54,641 --> 00:01:55,750
almost simultaneously.

36
00:01:56,080 --> 00:02:00,170
And the ways in which information was
hopping from one platform to another, um,

37
00:02:00,190 --> 00:02:03,370
through kind of deliberate coordination
and then also just ways in which

38
00:02:03,580 --> 00:02:06,730
information flows, kind
of contagion style. Um,

39
00:02:06,760 --> 00:02:11,760
and I wound up working on thinking about
how the government was going to respond

40
00:02:12,731 --> 00:02:16,300
to the challenge of
terrorist organizations using
American social platforms to

41
00:02:16,301 --> 00:02:18,150
spread propaganda.
Uh,

42
00:02:18,220 --> 00:02:22,930
so what we came to realize was that
there was just this information ecosystem

43
00:02:22,931 --> 00:02:26,710
and it had evolved in a certain way over
a period of about eight years or so.

44
00:02:27,130 --> 00:02:32,130
And the kind of unintended consequences
of that and the way that Russia kind of,

45
00:02:32,770 --> 00:02:37,570
uh, came into the conversation
was around October,

46
00:02:37,570 --> 00:02:40,420
2015 when we were thinking about what,
what to do about Isis,

47
00:02:40,421 --> 00:02:43,540
what to do about terrorism
and terrorist, uh, you know,

48
00:02:43,541 --> 00:02:45,280
kind of proliferation on social platforms.

49
00:02:45,880 --> 00:02:48,370
This was right around when Adrian
Chen had written the article,

50
00:02:48,371 --> 00:02:50,020
the Agency for the New York Times.

51
00:02:50,470 --> 00:02:53,650
And that was one of the first big expos
A's of the Internet research agency.

52
00:02:53,710 --> 00:02:56,500
The first time an American journalist
had gone over there and actually met the

53
00:02:56,501 --> 00:02:56,891
trolls,

54
00:02:56,891 --> 00:03:01,780
been in Saint Petersburg and began write
about what was happening over there and

55
00:03:01,781 --> 00:03:05,380
the ways that they had pages that we're
targeting certain facets of American

56
00:03:05,381 --> 00:03:06,214
culture.

57
00:03:06,280 --> 00:03:11,280
So while we were in DC talking about
what to do about terrorists using these

58
00:03:11,381 --> 00:03:12,850
platforms to spread propaganda,

59
00:03:13,210 --> 00:03:17,050
there were beginning to be rumblings
that Russian intelligence and you know,

60
00:03:17,051 --> 00:03:18,940
Russian entities,
we're doing the same thing.

61
00:03:19,270 --> 00:03:23,200
And so the question became can we think
about ways in which the Internet is

62
00:03:23,201 --> 00:03:27,640
vulnerable to this type of
manipulation by anyone? And then, um,

63
00:03:27,880 --> 00:03:29,860
and then come up with ways to stop it.

64
00:03:29,861 --> 00:03:32,620
So that was how the Russia
investigation began,

65
00:03:32,621 --> 00:03:37,450
was actually around 2015 and a handful
of people started looking for evidence of

66
00:03:37,451 --> 00:03:39,760
Russian bots and trolls
on social platforms.

67
00:03:40,030 --> 00:03:44,860
So 2015 if we think about social
media and the birth of social media,

68
00:03:44,861 --> 00:03:49,420
essentially, it had only been alive
for, I mean, what was Twitter,

69
00:03:49,421 --> 00:03:54,190
2007 I believe. Think so, yeah,
something like that. So eight years,

70
00:03:54,700 --> 00:03:56,770
like eight years of social media.

71
00:03:56,860 --> 00:04:01,510
And then all the sudden they figured
out how to game the system and then they

72
00:04:01,511 --> 00:04:05,620
figured out how to use this to make
people argue against each other.

73
00:04:06,430 --> 00:04:10,330
Yeah, I think so. There was
this, if you go back to like, um,

74
00:04:10,490 --> 00:04:15,250
I remember like Geo cities
and they all use that. Um,

75
00:04:15,330 --> 00:04:20,020
so we're probably about the same age.
Um, so there have always been, you know,

76
00:04:20,021 --> 00:04:23,320
kind of the thing thing that was great
about the Internet, like Internet 1.0,

77
00:04:23,321 --> 00:04:24,080
we can call it right,

78
00:04:24,080 --> 00:04:27,310
was this idea that everybody was given
a platform and you could use your

79
00:04:27,311 --> 00:04:30,340
platform, you could put up your blog,
you could say whatever you wanted. Um,

80
00:04:30,670 --> 00:04:33,490
you didn't necessarily get attention,
but you could say whatever you wanted.

81
00:04:33,880 --> 00:04:36,950
And so there is this
kind of consolidation as,

82
00:04:36,951 --> 00:04:40,750
as social platforms kind of came
into existence, content creators.

83
00:04:40,751 --> 00:04:44,350
We're really excited about the fact
that now they not only had this, um,

84
00:04:44,410 --> 00:04:46,300
this access to write their own stuff,

85
00:04:46,301 --> 00:04:50,350
but they also had access to this audience
because as the network effects got

86
00:04:50,351 --> 00:04:54,040
more and more pronounced, more and more
people came to be on social platforms.

87
00:04:54,310 --> 00:04:56,650
And in originally it wasn't even Facebook.
If I remember, it was like, you know,

88
00:04:56,651 --> 00:05:00,100
there's like Friendster and myspace
and social networks kind of evolved.

89
00:05:00,460 --> 00:05:03,010
When I was in college, Facebook was
still limited to like, you know,

90
00:05:03,011 --> 00:05:05,950
a handful of like Ivy League schools.
And so I wasn't even eligible.

91
00:05:06,820 --> 00:05:11,460
And as you watch this
consolidation happen,

92
00:05:11,530 --> 00:05:15,880
you start to have this information
ecosystem really dominated by a handful of

93
00:05:15,881 --> 00:05:19,180
companies that grow very large because
they're providing a service that people

94
00:05:19,181 --> 00:05:20,510
really want.
Um,

95
00:05:20,560 --> 00:05:24,190
but there's a kind of mass consolidation
of audiences onto this handful of

96
00:05:24,191 --> 00:05:25,024
platforms.

97
00:05:25,030 --> 00:05:28,960
So this becomes really interesting for
regular people who just want to find

98
00:05:28,961 --> 00:05:32,890
their friends, reach people, spread
their message, growing audience.

99
00:05:33,130 --> 00:05:37,540
It also becomes really interesting for
propagandists and trolls and in this case

100
00:05:37,600 --> 00:05:39,850
terrorist organizations and
state intelligence services.

101
00:05:40,090 --> 00:05:42,400
Cause instead of reaching
the entire Internet,

102
00:05:42,430 --> 00:05:45,310
they really just kind of have to
concentrate their efforts on a handful of

103
00:05:45,311 --> 00:05:46,144
platforms.

104
00:05:46,300 --> 00:05:50,290
So that consolidation is one of the
things that kind of kicks off some of the,

105
00:05:50,740 --> 00:05:53,020
um, one of one of the reasons
that we have these problems today,

106
00:05:53,540 --> 00:05:56,990
right? So the, the fact that there's
only a Facebook, a Twitter and,

107
00:05:57,650 --> 00:06:01,640
and a couple other minor
platforms other than Youtube,

108
00:06:01,641 --> 00:06:05,670
I mean anything that you can tell
it's an actual person like youtube,

109
00:06:05,671 --> 00:06:07,940
that is a problem, right? Because
you could see it's an actual person.

110
00:06:07,941 --> 00:06:11,300
If you're of, you're narrating
something, you, you know,

111
00:06:11,301 --> 00:06:15,390
if you're in front of the camera and
explaining things and people who going to

112
00:06:15,391 --> 00:06:16,910
know that you're an actual human being.

113
00:06:17,480 --> 00:06:21,300
Whereas there's so many of these
accounts that I'll go to, like I'll,

114
00:06:21,310 --> 00:06:25,640
I'll watch people get involved in these
little online beefs with each other and

115
00:06:25,641 --> 00:06:26,780
then I'll go to some of these accounts.
I'm like,

116
00:06:26,781 --> 00:06:30,140
this doesn't seem like a real person.
And I'll go and it's like Hashtag Magda,

117
00:06:30,380 --> 00:06:35,000
there's a American Eagle in front of a
flag and then you read their stuff and

118
00:06:35,001 --> 00:06:38,270
you're like, wow, this is, this is
probably a Russian troll account.

119
00:06:38,630 --> 00:06:41,990
And it's strange, like you feel like
you're not supposed to be seeing this.

120
00:06:41,991 --> 00:06:44,720
Like you've seen the wiring under the
board or something and then you'll go

121
00:06:44,721 --> 00:06:49,721
through the timeline and all they're
doing is engaging people and arguing,

122
00:06:49,970 --> 00:06:53,190
you know, for Trump and against, you know,

123
00:06:53,270 --> 00:06:55,850
whatever the fuck they're angry about,
whatever,

124
00:06:55,851 --> 00:06:58,320
whatever it is that's being discussed.
And they're,

125
00:06:58,321 --> 00:07:02,000
they're basically just like some
weird little argument mechanism.

126
00:07:02,310 --> 00:07:05,230
Yeah. So in 2016, um,

127
00:07:05,360 --> 00:07:09,000
there was a lot of that during
the presidential campaign,
right. And there were,

128
00:07:09,480 --> 00:07:12,120
um, there was so much that
was written, you know,

129
00:07:12,121 --> 00:07:14,760
we can go back to the free speech thing
we were kind of chatting about before.

130
00:07:15,050 --> 00:07:19,170
There was so much that was written about
harassment and trolling and negativity

131
00:07:19,171 --> 00:07:23,190
and these kind of hoards of accounts that
would brigade people and harass them.

132
00:07:23,580 --> 00:07:25,710
Of course, a lot of that is
just real Americans, right?

133
00:07:25,711 --> 00:07:28,640
There are plenty of people who are just
assholes on the Internet. Sure. Um,

134
00:07:28,920 --> 00:07:32,340
but there were actually a fair
number of these as we began to do the

135
00:07:32,341 --> 00:07:35,850
investigation into the
Russian operation in, uh,

136
00:07:36,060 --> 00:07:41,040
it started on Twitter and about,
um, 2014, actually, so 2013, 2014,

137
00:07:41,041 --> 00:07:45,090
the Internet research agency
is targeting Russian people.

138
00:07:45,091 --> 00:07:49,020
So they're tweeting in Russian, at
Russian and Ukrainian, uh, folks,

139
00:07:49,021 --> 00:07:51,510
people in their sphere of influence.
So they're already on there.

140
00:07:51,511 --> 00:07:52,620
They're already trying this out.

141
00:07:52,980 --> 00:07:56,010
And what they're doing is they're
creating these are these, these accounts,

142
00:07:56,220 --> 00:07:58,710
it's kind of wrong to call them
bots because they are real people.

143
00:07:59,340 --> 00:08:01,140
They're just not what they appear to be.

144
00:08:01,500 --> 00:08:04,410
So I think the unfortunate term
for it has become like Cyborg,

145
00:08:04,411 --> 00:08:07,170
like semi automated. You know,
sometimes it's automated,

146
00:08:07,171 --> 00:08:08,400
sometimes it's a real person,

147
00:08:08,670 --> 00:08:11,640
but a sock puppet is the other
way that we can refer to it.

148
00:08:11,641 --> 00:08:13,890
A person pretending to be somebody else.

149
00:08:14,220 --> 00:08:16,500
So you have these sock puppets and
they're out there and they're tweeting.

150
00:08:16,501 --> 00:08:21,501
And in 2014 about the Russian
annexation of Crimea or about mh 17.

151
00:08:22,171 --> 00:08:23,790
That plane that went down with Russia,
you know,

152
00:08:23,791 --> 00:08:26,130
of course I had no idea what happened
and it wasn't their fault at all.

153
00:08:26,700 --> 00:08:31,700
And gradually as they begin to experience
what I imagine they thought of what

154
00:08:32,671 --> 00:08:37,380
success, that's when you see some of these
accounts pivot to targeting Americans.

155
00:08:37,770 --> 00:08:41,760
And so in 20, late 2014, early
2015, you start to see the,

156
00:08:42,270 --> 00:08:46,710
um, the strategy that for a long
time had been very inwardly focused,

157
00:08:46,711 --> 00:08:49,920
making their own people think a certain
way or feel a certain way or have a

158
00:08:49,921 --> 00:08:54,600
certain experience on the Internet. Uh,
it begins to spread out. It begins to, uh,

159
00:08:54,601 --> 00:08:59,220
to look. And so you start to see these
accounts communicating with Americans.

160
00:08:59,640 --> 00:09:03,360
And as we were going through the datasets,
which the Twitter data set is public,

161
00:09:03,361 --> 00:09:05,880
anyone can go and look
at it at this point. Um,

162
00:09:05,910 --> 00:09:10,740
you do see some of the accounts that
are kind of, um, you know, that were,

163
00:09:10,741 --> 00:09:14,730
that were somewhat notorious for
being really virulent, nasty trolls.

164
00:09:14,820 --> 00:09:18,090
I'm antisemitic trolls going
after journalists. You know,
some of these accounts,

165
00:09:18,600 --> 00:09:19,433
um,

166
00:09:20,700 --> 00:09:25,680
being revealed as actually being a
Russian trolls now it doesn't kind of, um,

167
00:09:25,860 --> 00:09:30,330
exculpate the actual American trolls
that were very much real and active and

168
00:09:30,331 --> 00:09:32,010
part of this and expressing their opinion.

169
00:09:32,580 --> 00:09:34,770
But you do see that
they're mimicking this.

170
00:09:34,771 --> 00:09:38,040
They're using that same style of tactic,
that harassment to,

171
00:09:38,320 --> 00:09:39,420
to get it real people.

172
00:09:39,840 --> 00:09:42,720
Then if they do get banned,
if their account gets banned,

173
00:09:42,721 --> 00:09:46,950
they just simply make another
account. They use some sort of, uh,

174
00:09:47,280 --> 00:09:50,730
you know, um, what is it,
a virtual virtual server,

175
00:09:50,970 --> 00:09:55,770
what does that call mean? Vpns are,
that's, yeah, so if they do that,

176
00:09:55,800 --> 00:09:58,020
they can kind of do that
as long as they want.

177
00:09:58,050 --> 00:10:03,050
They can continue to make new accounts
and it probably also emboldens the actual

178
00:10:04,501 --> 00:10:08,670
American trolls because they're going
to go out a little bit further than

179
00:10:08,671 --> 00:10:10,230
everybody else.
A little bit crazier.

180
00:10:10,231 --> 00:10:14,460
And it kind of changes the
tone of discourse within
these communities that are

181
00:10:14,461 --> 00:10:15,750
arguing about a certain subject.

182
00:10:15,751 --> 00:10:20,280
Things get nastier and they're getting
nastier because of the interference of

183
00:10:20,281 --> 00:10:22,500
these trolls. Like, it seems like they've,

184
00:10:22,530 --> 00:10:27,060
they've actually managed to not
just cause a lot of discourse,

185
00:10:27,390 --> 00:10:31,890
but to change the way people
are interacting with each
other and to make it just

186
00:10:31,891 --> 00:10:33,630
make it more,
more vicious.

187
00:10:33,980 --> 00:10:38,030
Yeah. So the, what they're doing is
they're operating in communities.

188
00:10:38,090 --> 00:10:41,870
So one of the really common criticisms
of, you know, people who, um,

189
00:10:42,380 --> 00:10:44,930
lot of people think that this
didn't have a huge impact. You know,

190
00:10:44,931 --> 00:10:48,140
did it swing the election?
We have no idea. Um, but the,

191
00:10:48,141 --> 00:10:52,610
what it does do in the communities that
it targets is it can change that tone.

192
00:10:52,910 --> 00:10:56,930
And that's where you see,
um, it's, it's, I mean,

193
00:10:56,940 --> 00:10:58,430
think everybody's probably
had this experience,

194
00:10:58,431 --> 00:11:00,950
you're part of a group and then a new
person gets added to the group and the

195
00:11:00,951 --> 00:11:03,500
dynamic changes.
It's very much the same kind of thing,

196
00:11:03,501 --> 00:11:07,070
just that these are not real people
who are joining the group. Uh,

197
00:11:07,090 --> 00:11:11,660
and so there's this,
um, opportunity to, to,

198
00:11:11,690 --> 00:11:12,710
to,
you know,

199
00:11:13,370 --> 00:11:17,390
kind of expand the balance of tolerance
just that little bit more or try to

200
00:11:17,391 --> 00:11:22,100
normalize using particular ways of
communicating that maybe a group wouldn't

201
00:11:22,130 --> 00:11:24,940
naturally gravitate to.
But then it does. So there,

202
00:11:24,950 --> 00:11:28,970
there are definitely a ways in which any,

203
00:11:28,971 --> 00:11:31,220
any type of troll doing this
doesn't have to be a Russian troll,

204
00:11:31,221 --> 00:11:34,460
has this ability to kind of shift
the language of the community,

205
00:11:34,480 --> 00:11:36,290
shifts the culture just a little bit.

206
00:11:36,760 --> 00:11:41,560
Now, when did, why did the agency
do this and do we do we know,

207
00:11:41,561 --> 00:11:45,910
do we have someone who's ever left there
or become a whistle blower who can give

208
00:11:45,911 --> 00:11:50,620
us some information about what the
mandate was and how it was carried out?

209
00:11:51,210 --> 00:11:55,150
There've been a couple of a whistle and
actually some investigative journalism

210
00:11:55,151 --> 00:11:59,020
in Russia that's, that's covered
this. Um, they describe the,

211
00:11:59,140 --> 00:12:01,780
the employees of these as
the Internet research agency.

212
00:12:01,781 --> 00:12:06,100
So it's a little bit like a social
media marketing agency plus, um,

213
00:12:06,400 --> 00:12:09,310
tactics that we would not expect a
social media marketing agency to use.

214
00:12:10,000 --> 00:12:13,390
Things that are a little more like
what you would expect to see from an

215
00:12:13,391 --> 00:12:14,320
intelligence agency.

216
00:12:15,130 --> 00:12:18,190
So besides just making your pages
in your blogs and your social posts,

217
00:12:18,191 --> 00:12:20,930
they're also in their kind of,
uh,

218
00:12:21,280 --> 00:12:24,910
connecting with real people and real
activists and pretending to be something

219
00:12:24,911 --> 00:12:29,860
that they're not to develop kind of a
one on one relationship, but most of the,

220
00:12:30,250 --> 00:12:32,560
most of the, um, the whistle
blowers who have come out,

221
00:12:32,561 --> 00:12:36,190
there's a woman named
Ludmila savage, chuck. Um,

222
00:12:36,250 --> 00:12:38,500
she wrote an expos I believe on this.

223
00:12:38,770 --> 00:12:42,880
And it's described as being much like
you would expect if you were doing social

224
00:12:42,881 --> 00:12:46,360
media grunt work. Um, you have a certain
number of posts per day. You, you know,

225
00:12:46,361 --> 00:12:50,080
you're driving, trying to get a certain
amount of engagement. Um, you're trying,

226
00:12:50,081 --> 00:12:53,410
you've got to kind of hit your quotas.
Most people are young millennials,

227
00:12:53,440 --> 00:12:57,100
the people that work there, um, they're
well versed in trolling culture.

228
00:12:57,101 --> 00:12:58,930
They're well versed in internet culture.
You know,

229
00:12:58,931 --> 00:13:02,440
they're up to speed on like
popular memes and things like that.

230
00:13:02,441 --> 00:13:06,300
And so you do see, um, this, yeah.

231
00:13:06,350 --> 00:13:09,130
And then the other thing that they do is
they talk about in Mueller indictment,

232
00:13:09,131 --> 00:13:12,730
you see some really interesting
descriptions of like the
standups that they have

233
00:13:12,731 --> 00:13:14,220
stand up as a thing you
do at a tech company.

234
00:13:14,230 --> 00:13:16,570
Everybody kind of stands
up and talk about your, uh,

235
00:13:16,600 --> 00:13:18,550
goals and responsibilities
and blockers and things.

236
00:13:18,880 --> 00:13:22,120
And in the standups they would be
sitting there saying things like, um,

237
00:13:22,870 --> 00:13:25,270
if you're targeting black LGBT people,

238
00:13:25,271 --> 00:13:27,400
make sure you don't use
white people in your,

239
00:13:27,520 --> 00:13:31,090
in your image and your mean because that's
going to trigger them. Um, you know,

240
00:13:31,091 --> 00:13:34,390
so trying to get at
the, the very niche, um,

241
00:13:34,960 --> 00:13:39,160
rules for, you know, for communicating
authentically and an American community,

242
00:13:39,400 --> 00:13:41,720
which is, you know, online,
you know, you sometimes, um,

243
00:13:42,060 --> 00:13:46,720
there are very specific ways in which
a community expects a member of that

244
00:13:46,721 --> 00:13:47,710
community to communicate.

245
00:13:48,220 --> 00:13:53,050
And so they are in there and you can read
in these filings by Mueller's team and

246
00:13:53,051 --> 00:13:57,600
by the Eastern District
of Virginia. Um, the, the,

247
00:13:57,601 --> 00:14:02,601
the degree of granularity that they have
to recognize that if you are running a

248
00:14:02,651 --> 00:14:05,290
black LGBT page and your
meme is of white people,

249
00:14:05,320 --> 00:14:09,700
you're going to cause some tension and
consternation and assuming that that's

250
00:14:09,701 --> 00:14:11,110
not necessarily what you want to be doing,

251
00:14:11,111 --> 00:14:15,150
you should go find the meme of black
LGBT people to put in the, you know, to,

252
00:14:15,151 --> 00:14:18,520
to put as your meme for the
day. So there's a lot of, um,

253
00:14:18,550 --> 00:14:19,930
there's a lot of sophistication,

254
00:14:19,931 --> 00:14:23,890
there's a lot of understanding of
American culture and then there's a lot of

255
00:14:23,891 --> 00:14:25,270
understanding of trolling culture.

256
00:14:25,270 --> 00:14:29,650
And so these things combined to be
a rather effective, uh, you know,

257
00:14:30,100 --> 00:14:31,570
very effective social media agency.

258
00:14:31,720 --> 00:14:36,010
Then is there an overwhelming sort of
narrative that they're trying to pursue?

259
00:14:36,110 --> 00:14:40,390
The trying to push. So what
we saw, so I did the, um,

260
00:14:40,450 --> 00:14:44,560
I did some of the research for the
Senate and the Senate data came from the

261
00:14:44,561 --> 00:14:48,220
platforms. So what I had was, um, the
attribution was made by the platforms.

262
00:14:48,221 --> 00:14:52,640
It wasn't like Renee deciding this was
IRA. It was, uh, the giving it to, uh,

263
00:14:52,641 --> 00:14:55,430
to our government and the

264
00:14:57,050 --> 00:14:59,330
information in there.
Um,

265
00:14:59,810 --> 00:15:04,430
what it showed was that
across all platforms, across
Twitter, across Facebook,

266
00:15:04,460 --> 00:15:08,060
Instagram, youtube, they
were building up tribes.

267
00:15:08,120 --> 00:15:12,530
So they were really working to create
distinct communities of distinct types of

268
00:15:12,531 --> 00:15:15,800
Americans. And that would be, for example,

269
00:15:15,801 --> 00:15:20,320
there's an LGBT page that is very
much about LGBT pride. There is, uh,

270
00:15:20,610 --> 00:15:25,130
created it and they created it. And
Dave, they curate it and they create it,

271
00:15:25,131 --> 00:15:29,300
curate it. Um, it has a, you
know, they're just like a persona.

272
00:15:29,301 --> 00:15:33,140
A lot of the posts on the LGBT page were
written by what sounded kind of like a

273
00:15:33,141 --> 00:15:38,090
millennial lesbian was the voice.
Um, so it was a lot of, um, you know,

274
00:15:38,091 --> 00:15:41,990
memes of LGBT actresses and they
would brand it with a specific brand.

275
00:15:41,991 --> 00:15:46,760
Market was a rainbow heart. Um, uh,
LGBT United was the name of the page.

276
00:15:46,761 --> 00:15:48,230
It had a matching Instagram account,

277
00:15:48,231 --> 00:15:50,690
which you would also expect to
see from a media property. Right?

278
00:15:50,691 --> 00:15:54,780
You would expect them to see in
both places. And this, um, you know,

279
00:15:55,540 --> 00:15:59,550
it read like a, or like a
young woman talking about, um,

280
00:16:00,080 --> 00:16:02,600
crushes on actresses and things.
Actually, you know, it was, it was,

281
00:16:02,660 --> 00:16:07,660
it was really besides the
sometimes walking English
virtually indistinguishable

282
00:16:07,821 --> 00:16:12,560
from what you had read on any kind
of like young millennial focused, um,

283
00:16:13,520 --> 00:16:15,540
social page.
It wasn't a,

284
00:16:15,560 --> 00:16:20,000
none of it was radical or divisive.
It wasn't like,

285
00:16:20,240 --> 00:16:21,073
um,

286
00:16:21,560 --> 00:16:25,970
the way that they got the division
across was they built these tribes where

287
00:16:25,971 --> 00:16:30,500
they're reinforcing in group dynamics.
So you have the LGBT page,

288
00:16:30,501 --> 00:16:33,710
you have a numerous pages
targeting the black community.

289
00:16:33,711 --> 00:16:37,520
That was where they spent most of their
energy. A lot of pages targeting, um,

290
00:16:37,550 --> 00:16:41,910
far right? So, uh, both
old far right, meaning, um,

291
00:16:42,620 --> 00:16:45,530
people who are very concerned about what
does the future of America look like.

292
00:16:45,860 --> 00:16:48,530
And then young, far right,
which was much more angry,

293
00:16:48,531 --> 00:16:50,090
much more like trolling culture.

294
00:16:50,210 --> 00:16:52,910
So they recognize that there's a divide
there that the kinds of memes you're

295
00:16:52,911 --> 00:16:57,070
gonna use to target younger rightwing
audiences are not the same kinds of memes

296
00:16:57,071 --> 00:16:59,540
are going to use to target
older right wing audiences.

297
00:16:59,930 --> 00:17:02,810
So there's a tribe for
older rightwing younger,

298
00:17:02,811 --> 00:17:05,600
right wing and the black community.
There's a baptist tribe,

299
00:17:05,630 --> 00:17:09,590
there's a black liberation tribe,
there's a black women tribe,

300
00:17:09,591 --> 00:17:12,170
there's one for people who
have incarcerated spouses.

301
00:17:12,200 --> 00:17:16,070
There's a brown,
I'm Brown.

302
00:17:16,071 --> 00:17:19,360
Power I believe was the name of it
page. That was very much about, um,

303
00:17:19,730 --> 00:17:23,510
Mexican and Chicano culture.
There was native Americans United.

304
00:17:24,220 --> 00:17:26,120
All these are fake.
All of these are fake.

305
00:17:26,920 --> 00:17:28,310
What are they trying to do with all these?

306
00:17:28,550 --> 00:17:32,990
So you build up this in group dynamic
and over, and he did this over years.

307
00:17:33,020 --> 00:17:37,310
So this was not a short term thing.
They started these pages and 20, 14, 20,

308
00:17:37,311 --> 00:17:39,680
15 timeframe, most of them. Um,

309
00:17:39,740 --> 00:17:42,500
they started some other ones that
were much more political later.

310
00:17:42,501 --> 00:17:46,350
And we can talk about the election if you
want to, but with this tribal thing, um,

311
00:17:47,090 --> 00:17:51,820
you're building up tribes here saying like
as black women in America, this is, um,

312
00:17:51,870 --> 00:17:56,250
here's posts about things that we care
about. Here's posts about black hair,

313
00:17:56,251 --> 00:18:00,900
here's posts about child rearing,
here's posts about fashion and culture.

314
00:18:01,260 --> 00:18:06,180
And then every now and then there would
be a post that would reinforce like as

315
00:18:06,181 --> 00:18:09,030
black people, we don't do this. And so,

316
00:18:09,031 --> 00:18:13,490
or as LGBT people we don't like this.
And so you're building this report.

317
00:18:13,491 --> 00:18:15,420
So like me and you were
having a conversation,

318
00:18:15,421 --> 00:18:18,060
we're developing a relationship
on this page over time.

319
00:18:18,810 --> 00:18:23,700
And then I say like as this kind
of person, we don't believe this.

320
00:18:24,000 --> 00:18:28,460
So it's a way to subtly influenced
by appealing to an ingroup dynamic or

321
00:18:28,470 --> 00:18:31,710
appealing to like as members
of this tribe, as LGBT people.

322
00:18:31,711 --> 00:18:34,590
Of course we hate Mike
Pence as black people.

323
00:18:34,591 --> 00:18:36,780
Of course we're not going
to vote because you know,

324
00:18:36,840 --> 00:18:40,740
we hate Hillary Clinton because
we hate her husband as, um,

325
00:18:40,920 --> 00:18:45,920
as people who are concerned about the
future of America is Texas assumptionists

326
00:18:46,590 --> 00:18:50,610
you know, so, so everything is
presented as members of this tribe.

327
00:18:51,090 --> 00:18:54,620
We think this as members of this tribe,
we don't think this but a lot.

328
00:18:54,700 --> 00:18:55,610
That's why you see the,

329
00:18:56,080 --> 00:18:58,850
I had a lot of,
the posts were not even political,

330
00:18:59,000 --> 00:19:03,150
they were just sort of affirming
the standards of the tribe. Yes.

331
00:19:03,200 --> 00:19:07,400
So they were kind of setting
up this whole long game. Yep.

332
00:19:08,180 --> 00:19:12,020
And then once they got everybody on
board or how many followers are these,

333
00:19:12,620 --> 00:19:13,610
do these pages have?

334
00:19:13,870 --> 00:19:17,380
So the, there was kind of
a long tail. There were um,

335
00:19:17,770 --> 00:19:21,100
I think 88 pages on Facebook
and 133 Instagram accounts.

336
00:19:21,101 --> 00:19:26,101
And I would say maybe 30 of the Facebook
pages had over a thousand followers,

337
00:19:27,341 --> 00:19:29,050
which is not very many. And then, um,

338
00:19:29,080 --> 00:19:33,130
maybe the top 10 had upwards
of 500,000 followers.

339
00:19:33,520 --> 00:19:36,150
So there's, you know, same way
you run any social campaigns.

340
00:19:36,151 --> 00:19:38,440
Sometimes you have hits,
sometimes you have flops. Right.

341
00:19:38,740 --> 00:19:42,130
And what was interesting with the flops
as you would see them repurpose them so

342
00:19:42,131 --> 00:19:46,240
they would decide, you know, the same way
if you're running a social media agency,

343
00:19:46,241 --> 00:19:48,970
well we've got this audience,
this page isn't doing so well.

344
00:19:48,971 --> 00:19:52,180
It's like rebrand it a little
bit, change it up, try to, um,

345
00:19:52,270 --> 00:19:56,770
try to make it appeal to somebody
else. So you do see this, there is a,

346
00:19:57,220 --> 00:19:58,053
there is,
um,

347
00:19:58,660 --> 00:20:02,590
I got this data set and
I was going through these
Instagram memes and you know,

348
00:20:02,870 --> 00:20:07,330
130, 3000 of them. And I was um,

349
00:20:07,810 --> 00:20:12,070
there was a cluster of
images of Kermit the frog.

350
00:20:12,580 --> 00:20:17,320
I was like, what the hell
is Kermit the frog doing in
here? And so I, so then I go,

351
00:20:17,321 --> 00:20:18,154
so this,
the,

352
00:20:18,380 --> 00:20:22,510
the way the platforms provide the data
is I got like a CSV of the posts and then

353
00:20:22,511 --> 00:20:25,210
I got a folder of the images.
And so in order to like connect the dots,

354
00:20:25,211 --> 00:20:27,670
I had to have the image up on one screen.
And the,

355
00:20:28,480 --> 00:20:32,980
this I'm thinking to the CSP up on the
other screens, it's like a spreadsheet.

356
00:20:33,160 --> 00:20:35,470
Okay. Yeah. And I,

357
00:20:36,190 --> 00:20:39,520
and we turned it into a database that
we could track things a little bit more

358
00:20:39,521 --> 00:20:43,840
easily across the platforms. But, um, so
I have this cost of Kermit the frog memes.

359
00:20:43,841 --> 00:20:45,790
And I go and I look
and I realize that the,

360
00:20:45,820 --> 00:20:49,540
they're attributed to an account
army of Jesus. And I thought, well,

361
00:20:49,541 --> 00:20:51,400
that's interesting. What
did you know? These are,

362
00:20:51,490 --> 00:20:56,230
some of them are really Raunchy is like,
it was like Kermit, Miss Piggy, like,

363
00:20:56,260 --> 00:21:01,240
you know, I mean it was just like,
like stupid, stupid, crappy memes. Um,

364
00:21:01,600 --> 00:21:03,940
attached to army of Jesus and
what the Hell is going on here?

365
00:21:04,750 --> 00:21:05,501
I keep going through it.

366
00:21:05,501 --> 00:21:09,530
Hundreds of Kermit memes and then I
get to a post where they say like, um,

367
00:21:10,120 --> 00:21:14,770
this page is owned by homer Simpson.
Now Kermit went to jail for being like,

368
00:21:14,800 --> 00:21:17,500
I don't know, they made some
like some joke. It was stupid.

369
00:21:18,100 --> 00:21:22,450
And all of a sudden the data set
turns into homer Simpson memes.

370
00:21:22,720 --> 00:21:26,560
So again, like this kind of
Raunchy homer Simpson culture, um,

371
00:21:27,280 --> 00:21:28,840
and again,
it's attributed to army of Jesus.

372
00:21:28,870 --> 00:21:32,350
And then I go through all of this and
realize that they didn't get to actually

373
00:21:32,351 --> 00:21:37,351
making army of Jesus a Jesus focused
page until like 900 posts in.

374
00:21:37,900 --> 00:21:40,510
So the, they just renamed
the account at some point.

375
00:21:40,511 --> 00:21:42,130
It used to be called nuts news.

376
00:21:42,460 --> 00:21:45,880
And then they nuts news was what they
called it when it was the Kermit the frog

377
00:21:45,881 --> 00:21:49,210
meme page. And then it gets repurposed
when they realized Kermit's not doing it.

378
00:21:49,211 --> 00:21:52,780
It's not getting the audience they want
homer Simpson's not getting the audience

379
00:21:52,781 --> 00:21:53,680
or engagement they want.

380
00:21:53,920 --> 00:21:57,700
And then they pivot over to Jesus and
then all of a sudden they start, you know,

381
00:21:57,701 --> 00:21:59,920
the likes and,
and things start pouring in.

382
00:22:00,130 --> 00:22:04,210
So what they're doing is they're actually
like either deliberately or they're

383
00:22:04,211 --> 00:22:07,090
just creating placeholders.
Um,

384
00:22:07,330 --> 00:22:11,710
it's kind of a red flag when a brand
new account that was created yesterday

385
00:22:11,711 --> 00:22:14,980
suddenly starts talking about some highly
politically divisive thing or whatever.

386
00:22:15,280 --> 00:22:18,280
But if you lay the groundwork and
you do it over a period of two years,

387
00:22:18,710 --> 00:22:22,600
then somebody who goes and checks
to see what the account was,

388
00:22:22,601 --> 00:22:24,160
where it came from,
how old it is.

