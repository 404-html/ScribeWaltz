1
00:00:00,120 --> 00:00:03,690
No. Well, yeah, it's not the experience
for everyone and it's not really,

2
00:00:03,691 --> 00:00:05,790
I don't think it's what
everyone wants either.

3
00:00:05,791 --> 00:00:08,060
Sometimes people just like to go
on there and talk shit. I mean,

4
00:00:08,061 --> 00:00:09,960
as someone that's trapped
in a cubicle right now,

5
00:00:10,050 --> 00:00:12,480
it's true and they just want to go on
there and get in arguments about gun

6
00:00:12,481 --> 00:00:16,530
control or you know, whether or not
Nancy Pelosi's the devil, I mean this is,

7
00:00:16,560 --> 00:00:19,860
this is what you know, it,
it serves a purpose for them.

8
00:00:20,130 --> 00:00:25,130
The thing that gets strange
though is who's to decide,

9
00:00:25,740 --> 00:00:27,900
you know,
there's this is this concept,

10
00:00:28,650 --> 00:00:31,110
there's a discussion I should say where,
uh,

11
00:00:31,380 --> 00:00:36,380
some people believe that things like
Twitter or Facebook or any forum where

12
00:00:36,481 --> 00:00:40,110
you're having a public discussion should
be considered almost like a public

13
00:00:40,111 --> 00:00:44,280
utility. Like anyone has
access to the electric power.

14
00:00:44,460 --> 00:00:47,970
Even if you're, you know,
even if you're a racist,

15
00:00:48,000 --> 00:00:51,750
you still can get electricity and some
people think that you should have that

16
00:00:51,751 --> 00:00:55,680
same ability with something like Twitter
or the same ability with something like

17
00:00:55,681 --> 00:00:58,320
Instagram.
Obviously this is,

18
00:00:58,440 --> 00:01:03,030
we're in uncharted territory and you are,
you are in uncharted territory. It just,

19
00:01:03,031 --> 00:01:04,680
no one has been there before.

20
00:01:05,010 --> 00:01:08,530
So who makes the distinctions
when you see someone that,

21
00:01:08,730 --> 00:01:13,730
that it's saying something that you might
think is offensive to some folks but

22
00:01:15,151 --> 00:01:16,830
not offensive to the
person who's saying it.

23
00:01:16,860 --> 00:01:19,500
Maybe the person who's saying it feels
like they need to express themselves.

24
00:01:19,501 --> 00:01:24,501
And this is important to say and how
do you decide whether or not this is a

25
00:01:24,541 --> 00:01:29,030
valid discussion or if this is
air quotes, hate speech, which is,

26
00:01:29,940 --> 00:01:30,241
you know,

27
00:01:30,241 --> 00:01:33,750
there's some things that are hate speech
and there's sometimes people use the

28
00:01:33,751 --> 00:01:37,830
term hate speech and it's just a cheap
way to shut down a conversation. Yeah.

29
00:01:38,370 --> 00:01:41,850
We, so the simple answer is
we look at conduct. We don't,

30
00:01:41,851 --> 00:01:44,100
we don't look at the speech itself.
We look at conduct,

31
00:01:44,101 --> 00:01:48,900
we look at how the tool is being used.
And you're, you're right in that.

32
00:01:48,990 --> 00:01:50,730
Like I think when people see Twitter,

33
00:01:50,731 --> 00:01:54,210
they see and they expect
it to be a public square.

34
00:01:54,930 --> 00:01:57,530
They can go into that public square.
They can say whatever they want to,

35
00:01:57,570 --> 00:01:59,820
can get on a pedestal.
Um,

36
00:02:00,030 --> 00:02:03,270
and people might gather around
them and listen what they have.

37
00:02:03,271 --> 00:02:05,670
So some of them might find
it offensive and they leave.

38
00:02:06,780 --> 00:02:10,080
The difference is there's,

39
00:02:10,110 --> 00:02:14,280
there's also this concept of this
megaphone in the megaphone can be highly

40
00:02:14,281 --> 00:02:18,720
targeted now with Twitter as well.
Right? So it's not, it's not the,

41
00:02:18,750 --> 00:02:21,960
it's not the speech, it's how
it's amplified. So what do you do?

42
00:02:21,961 --> 00:02:24,860
It's like say let's, let's say
there's someone in the media, uh,

43
00:02:24,960 --> 00:02:29,640
let's say it's a prominent feminist and
then you have a bunch of people or let's

44
00:02:29,641 --> 00:02:34,050
say just one person and their Twitter
feed is overwhelmingly attacking this

45
00:02:34,051 --> 00:02:37,950
prominent feminist, just constantly
attacking or calling her a liar,

46
00:02:37,951 --> 00:02:41,430
calling her this calling that when
do you decide this is harassment?

47
00:02:41,430 --> 00:02:44,130
When decide this is hate speech,
when like how do you,

48
00:02:44,131 --> 00:02:45,910
I mean this is a look at the conduct,
an absolute,

49
00:02:45,911 --> 00:02:49,020
this is a fictional account write
fictional person we're talking about.

50
00:02:49,021 --> 00:02:52,470
But in this for instance,
what,

51
00:02:52,471 --> 00:02:57,471
what would dictate something that was
egregious enough for you to eliminate them

52
00:02:58,411 --> 00:03:03,220
from your platform? Well, that's
a, that's a, that's a heavy action.

53
00:03:03,250 --> 00:03:06,100
So that's the last resort. Um,
but we look at the conduct,

54
00:03:06,130 --> 00:03:09,130
we look at oftentimes as you said,
like the,

55
00:03:09,510 --> 00:03:14,510
the probability of someone
who is harassing one person.

56
00:03:15,250 --> 00:03:18,820
It's highly probable that there
also harassing 10 more people.

57
00:03:19,360 --> 00:03:20,950
So we can look at that behavior.

58
00:03:20,951 --> 00:03:25,951
We can look at how many times this
person is being blocked or muted or a

59
00:03:26,800 --> 00:03:31,000
reported. And based on all
those, um, all that data,

60
00:03:31,001 --> 00:03:33,430
we can actually take some action.
But we also have to,

61
00:03:34,180 --> 00:03:38,770
we have to correlate it with the other
side of that because people go on and

62
00:03:38,771 --> 00:03:43,090
they coordinate blocks as well and
they coordinate harassment and they,

63
00:03:43,091 --> 00:03:47,030
and they coordinate, I'm sorry, not
harassment, but reporting, um, uh,

64
00:03:47,050 --> 00:03:50,090
reporting a particular account
to get it shut down into, uh,

65
00:03:50,140 --> 00:03:51,550
to take the voice off the service.

66
00:03:52,060 --> 00:03:55,860
So these are the considerations
we have to make, but it's, it's,

67
00:03:56,050 --> 00:04:01,050
it all starts with conduct and oftentimes
they'll see coordinated conduct,

68
00:04:01,451 --> 00:04:05,530
whether it be that one person opening
multiple counts or coordinating with

69
00:04:05,531 --> 00:04:10,240
multiple accounts that they don't
own to, you know, go after someone.

70
00:04:10,300 --> 00:04:13,930
And there's a bunch of vectors that
people use retweet for that, uh,

71
00:04:13,931 --> 00:04:16,750
the quote tweet for that a
lot as well. Like, you know,

72
00:04:16,800 --> 00:04:19,750
they'll quote tweet a tweet that
someone finds and they'll say,

73
00:04:20,410 --> 00:04:22,240
look at this idiot Twitter,
do your thing.

74
00:04:22,300 --> 00:04:27,190
And then just this mob starts
and goes and tries to, uh,

75
00:04:27,220 --> 00:04:29,470
effectively shut that person down.
Um,

76
00:04:29,471 --> 00:04:32,290
so there's a bunch of tools we can use.

77
00:04:32,650 --> 00:04:35,410
The permanent suspension
is the last resort.

78
00:04:35,411 --> 00:04:40,300
One of the things that we can do
is we can down rank the replies.

79
00:04:40,360 --> 00:04:45,280
So any of these, any of these behaviors
and conduct that looks link linked,

80
00:04:45,340 --> 00:04:49,270
we can actually, uh, push
farther down in the reply chain.

81
00:04:49,360 --> 00:04:53,710
So it's all still there. But you might
have to push a button to actually see it.

82
00:04:53,740 --> 00:04:57,510
You might have to see, show more
replies to actually see, uh,

83
00:04:57,580 --> 00:05:02,580
this harassing account or what
might look like harassing language.

84
00:05:03,160 --> 00:05:07,180
And this is manually done.
This is, this is all,

85
00:05:07,240 --> 00:05:10,180
this is all automated. It's automated.
Yeah. Yeah. But how would you,

86
00:05:10,181 --> 00:05:11,390
a lot of the ranking in the,

87
00:05:11,391 --> 00:05:15,400
and looking at amplification and looking
at the network is, is automated, right?

88
00:05:15,401 --> 00:05:16,840
Like,
in terms of down ranking,

89
00:05:16,900 --> 00:05:19,820
is there a discussion as to
whether or not this person's reply,

90
00:05:19,821 --> 00:05:23,320
she'd be down ranked? Like how do
you, how do you figure that out? It's,

91
00:05:23,321 --> 00:05:27,460
it's a machine learning and deep learning
model and they just say it's Ai and

92
00:05:27,461 --> 00:05:31,260
they, and they learn, you
know, and we, we look at, um,

93
00:05:31,300 --> 00:05:34,780
we look at how these things are doing
and where they make mistakes and then we

94
00:05:34,781 --> 00:05:37,510
improve it. It's just constantly
improving, constantly learning.

95
00:05:37,511 --> 00:05:39,880
And does that feel like censorship to you?

96
00:05:39,881 --> 00:05:43,420
Like automated censorship is, I mean, who,

97
00:05:43,510 --> 00:05:48,430
who's to decide other than people,
whether or not something is valid? Well,

98
00:05:48,431 --> 00:05:51,520
we're not, we're not looking at the,
at the speech. In this particular case,

99
00:05:51,521 --> 00:05:54,010
we're looking at the conduct,
the conduct,

100
00:05:54,040 --> 00:05:58,650
the conduct of like someone in fast
philocity attacking someone else. Okay.

101
00:05:58,760 --> 00:06:02,150
Right. So those are the things
that our technology allows.

102
00:06:02,151 --> 00:06:06,710
It changes the velocity
changes. Uh, how, um,

103
00:06:06,740 --> 00:06:07,220
you know,

104
00:06:07,220 --> 00:06:11,300
to broadcast semesters that someone
didn't really ask for and didn't want to

105
00:06:11,301 --> 00:06:14,360
hear. We don't touch,
if I follow Joe Rogan,

106
00:06:15,560 --> 00:06:18,640
you'll see every single tweet.
We don't touch it. Right, right.

107
00:06:18,800 --> 00:06:22,550
But that's an audience that you earn.
But in your replies page,

108
00:06:22,940 --> 00:06:25,710
we have a little bit more
room because this is a,

109
00:06:25,720 --> 00:06:29,870
this is a conversation that starts up in,
some people just want to disrupt it.

110
00:06:29,871 --> 00:06:34,190
And all we're saying is we're going
to look at moving the disruption down.

111
00:06:34,370 --> 00:06:37,550
Not that it's hidden, but it's
still there. But you know,

112
00:06:37,580 --> 00:06:39,320
you just see it a little bit farther down.

