1
00:00:00,580 --> 00:00:04,900
Well. So, so one really important thing
that needs to be stated is that Twitter by

2
00:00:04,901 --> 00:00:07,990
definition is a bias to platform in
favor of the left period. It's not,

3
00:00:07,991 --> 00:00:10,390
it's not a question. I understand you
might have your own interpretation,

4
00:00:10,660 --> 00:00:11,493
but it's very simple.

5
00:00:11,590 --> 00:00:14,620
Conservatives do not agree with you
on the definition of mis-gendering.

6
00:00:14,830 --> 00:00:18,780
If you have a rule in place
that specifically adheres
to the left ideology, you

7
00:00:18,930 --> 00:00:22,320
by default are enforcing rules
from a biased perspective lets him,

8
00:00:22,500 --> 00:00:24,960
there are a lot of people in the left
who don't agree with how we're doing our

9
00:00:24,961 --> 00:00:26,100
job either for sure.

10
00:00:26,160 --> 00:00:28,970
And those people think that we don't
take enough action on it and use her ass

11
00:00:28,980 --> 00:00:33,180
spent far too much behavior
go. And I think that's what
a radical example though.

12
00:00:33,181 --> 00:00:35,940
I mean what he's talking about,
I mean in terms of generalities,

13
00:00:35,970 --> 00:00:39,840
the in general things lean far more left.
Would you agree to that?

14
00:00:40,170 --> 00:00:41,130
I don't know what that means,

15
00:00:41,190 --> 00:00:43,950
but in this particular case it's
a hell of a speech is being used.

16
00:00:44,050 --> 00:00:49,050
This is a new vector of attack that people
have felt that I don't want to be on

17
00:00:49,381 --> 00:00:52,590
this platform anymore because I'm being
harassed and abused and I need to get

18
00:00:52,591 --> 00:00:53,000
the hell out.

19
00:00:53,000 --> 00:00:54,650
Well people harassed and
abused me all day and night.

20
00:00:54,651 --> 00:00:55,610
You don't do anything about that?

21
00:00:57,180 --> 00:01:00,980
I I my my notifications permanent
locked at 99 you have a worse than I do.

22
00:01:00,981 --> 00:01:04,490
I mean you got substantially
more followers and I don't
click the notification

23
00:01:04,491 --> 00:01:08,090
tab anymore because it's basically
just harassment and I even when,

24
00:01:08,210 --> 00:01:09,560
so this is a really funny anecdote.

25
00:01:09,590 --> 00:01:14,570
I was a covering a story in Berkeley and
someone said if you see him attack him

26
00:01:14,600 --> 00:01:18,020
like it was, it was, I'm paraphrasing,
they said basically to swing at me,

27
00:01:18,021 --> 00:01:18,920
take my stuff,

28
00:01:19,130 --> 00:01:23,180
steal from me and Twitter told me after
review it was not a violation of their

29
00:01:23,181 --> 00:01:24,014
policy.

30
00:01:24,080 --> 00:01:29,060
Somebody made an illusion to me being a
homosexual and I reported that instantly

31
00:01:29,061 --> 00:01:32,660
gone. So when I show, so, so for me
I'm looking, I'm like, well of course,

32
00:01:32,661 --> 00:01:36,590
of course Twitter is going to enforce
the social justice aspect of their policy

33
00:01:36,620 --> 00:01:38,060
immediately,
in my opinion,

34
00:01:38,061 --> 00:01:41,030
probably because you guys have a PR
constraints and you're probably nervous

35
00:01:41,031 --> 00:01:44,180
about that. But when someone actually
threatens me with a crime and insights,

36
00:01:44,181 --> 00:01:46,880
their followers to do it and nothing got
done and I'm not the only one who feels

37
00:01:46,881 --> 00:01:47,550
that way,

38
00:01:47,550 --> 00:01:48,320
that's a mistake.

39
00:01:48,320 --> 00:01:52,580
If someone acts in that manner
and threatens to hurt you,

40
00:01:52,790 --> 00:01:54,200
that's a violation of our rules.
Right?

41
00:01:54,201 --> 00:01:57,170
Maybe there was a mistake there and I'm
happy to go and crack that and we can do

42
00:01:57,171 --> 00:02:00,050
it offline so we don't fear any
sort of reprisal against you.

43
00:02:00,500 --> 00:02:04,340
But that's a mistake. That's not an
agenda on my part or in the team spark.

44
00:02:04,490 --> 00:02:07,400
Would this be PR constraints?

45
00:02:08,360 --> 00:02:11,230
I said, why did you ban Alex
Jones? We're going to get her that.

46
00:02:11,290 --> 00:02:14,620
You want to get into that? Absolutely.
Are you ready for us? Alright. Oh,

47
00:02:14,621 --> 00:02:19,420
I've been ready for, um, well let, let,

48
00:02:19,440 --> 00:02:21,970
let me say this. The reason I
bring him up is that Oliver, Darcy,

49
00:02:22,390 --> 00:02:25,840
one of the lead reporters covering
Alex Jones and his content set on CNN,

50
00:02:26,260 --> 00:02:29,860
that it was only after media pressure
did these social networks take action.

51
00:02:30,070 --> 00:02:31,830
So that's why I bring him
up specifically cause it it,

52
00:02:31,831 --> 00:02:34,150
it sort of implies you
are under PR constraints

53
00:02:34,300 --> 00:02:36,730
to get rid of him.
I think if you look at the Pr,

54
00:02:36,731 --> 00:02:38,320
that's what her went
through and that incident,

55
00:02:38,321 --> 00:02:42,010
it wouldn't be that we looked good in
it and that's not at all why we took

56
00:02:42,011 --> 00:02:42,844
action on it.

57
00:02:43,160 --> 00:02:47,830
You have to look at the full context
on the spectrum here because one of the

58
00:02:47,831 --> 00:02:52,831
things that happened over a weekend
is what Alex mentioned on your,

59
00:02:52,990 --> 00:02:54,250
on your podcast with him.

60
00:02:54,850 --> 00:02:59,020
He was removed from the Itunes
podcast directory. That was,

61
00:02:59,470 --> 00:03:00,040
that was the

62
00:03:00,040 --> 00:03:01,860
linchpin for him because it it,

63
00:03:02,060 --> 00:03:05,590
it drove all the traffic to what he said.

64
00:03:05,591 --> 00:03:10,591
Basically zero immediately after
that we saw our peer companies,

65
00:03:10,930 --> 00:03:15,430
Facebook, Spotify, Youtube
also take action. We did not.

66
00:03:16,240 --> 00:03:18,220
We did not because we,

67
00:03:18,221 --> 00:03:21,580
when we looked at our service and we
looked at the reports on their service,

68
00:03:21,581 --> 00:03:24,400
we did not find anything
in violation of our rules.

69
00:03:25,210 --> 00:03:30,210
Then we got into a situation where
suddenly a bunch of people were reporting

70
00:03:32,080 --> 00:03:35,050
content on our platform,
including CNN,

71
00:03:35,051 --> 00:03:38,860
who wrote an article about all the
things that might violate our rooms,

72
00:03:38,920 --> 00:03:40,120
rules that we looked into.

73
00:03:40,660 --> 00:03:45,660
And we gave him one of the other warnings
and then we can get into the actual

74
00:03:45,821 --> 00:03:48,730
details. But yeah, we did not follow, we,

75
00:03:48,731 --> 00:03:53,731
we resisted just being like a domino with
our peers because it wasn't consistent

76
00:03:54,281 --> 00:03:58,330
with our rules in the contract
we put in before our customers.

77
00:03:58,480 --> 00:04:00,400
So what was it that made you ban them?

78
00:04:00,980 --> 00:04:04,700
So there were three separate incidents
that came to our attention after the fact,

79
00:04:05,060 --> 00:04:08,360
uh, that were reported to us
by, by different users. Uh,

80
00:04:08,390 --> 00:04:12,740
there was a video that was uploaded that
showed a child's being violently thrown

81
00:04:12,741 --> 00:04:15,900
to the ground and crying. So
that was the first one. Um,

82
00:04:16,040 --> 00:04:20,210
the second one was a video that we
viewed as incitement of violence.

83
00:04:20,480 --> 00:04:22,250
I can read it to you. It's
a, sure it's a little,

84
00:04:22,251 --> 00:04:24,200
it's a little bit of a
transcripts, but, um,

85
00:04:24,680 --> 00:04:27,680
but now it's time to act on the
enemy before they do a false flag.

86
00:04:27,710 --> 00:04:30,680
I know the Justice Department's crippled
a bunch of followers and cowards,

87
00:04:30,681 --> 00:04:33,980
but there's groups, there's
grants, juries, there's, you
called for it. It's time,

88
00:04:33,981 --> 00:04:35,840
politically,
economically and judiciously,

89
00:04:35,841 --> 00:04:39,920
illegally and criminally to move against
these people. It's got to be dumb now.

90
00:04:40,280 --> 00:04:42,800
Get together. The people, you know
aren't traders, aren't cowards,

91
00:04:42,830 --> 00:04:45,440
aren't helping their fricking bats.
Hedging their fucking bets,

92
00:04:45,441 --> 00:04:47,810
like all these other assholes to
do. And let's go, let's do it.

93
00:04:48,110 --> 00:04:50,960
So people need to have there.
And then there's a bunch of other stuff,

94
00:04:50,990 --> 00:04:51,680
but at the end,

95
00:04:51,680 --> 00:04:54,500
so people need to have their battle
rifles ready and everything ready at their

96
00:04:54,501 --> 00:04:57,770
bedsides and you've gotta be ready because
the media is so disciplined in their

97
00:04:57,771 --> 00:05:01,510
deception.
So this is you,

98
00:05:01,520 --> 00:05:04,490
you're saying that this is a call
to violence against the media.

99
00:05:04,520 --> 00:05:06,110
That's what it sounded
like to us at the time.

100
00:05:06,380 --> 00:05:09,860
And there've been a number of incidents
of violence against the media. And again,

101
00:05:09,861 --> 00:05:12,620
I take my responsibility for what
happens on the platform and how that

102
00:05:12,621 --> 00:05:14,810
translates off platform very seriously.

103
00:05:15,140 --> 00:05:17,420
And that felt like it was
an incitement to violence.

104
00:05:17,570 --> 00:05:19,520
If he only tweeted the
incitement to violence,

105
00:05:19,521 --> 00:05:23,420
he would have been fine if he only
treats, only tweeted that trans, uh,

106
00:05:23,510 --> 00:05:25,850
posted their transcripts saying,
get your battle rifles ready,

107
00:05:25,851 --> 00:05:28,730
you wouldn't have deleted this account.
I, again, context matters to him.

108
00:05:28,790 --> 00:05:29,840
It's not about one thing.

109
00:05:29,870 --> 00:05:32,180
So we'd have to look at the
entire context of what's going on.

110
00:05:32,181 --> 00:05:35,510
So I'm asking was that, was that egregious
enough for you to say that alone?

111
00:05:35,540 --> 00:05:38,240
That wasn't, that wasn't, that
was your number two. Right, right.

112
00:05:38,241 --> 00:05:41,120
So then I guess the question is what
was the video context of the kid being

113
00:05:41,121 --> 00:05:44,630
thrown to the ground? Was it newsworthy?
We obviously didn't think so.

114
00:05:44,631 --> 00:05:47,930
In depicting violence against the child
is not something that we would allow on

115
00:05:47,931 --> 00:05:51,050
the platform, even if it's a
news content. Um, if it was, uh,

116
00:05:51,070 --> 00:05:54,980
there are certain types of situations
where if you were reporting on, um,

117
00:05:55,010 --> 00:05:57,530
you know, war zone and, and
things that might happening,

118
00:05:57,531 --> 00:06:01,130
we would put an interstitial on that
type of contents as graphic or violent.

119
00:06:01,340 --> 00:06:03,380
But we didn't feel that
that was the context here.

120
00:06:03,560 --> 00:06:07,380
Well there's a video that's been going
around that was going around few four or

121
00:06:07,381 --> 00:06:08,890
five weeks ago,
the one where the,

122
00:06:08,891 --> 00:06:11,940
the girls were yelling at that big giant
guy and the guy punched that girl in

123
00:06:11,941 --> 00:06:15,960
the face and she was like 11 years old.
I saw that multiple times on Twitter.

124
00:06:16,040 --> 00:06:19,620
That was one of the most violent things,
overseeing this giant man,

125
00:06:19,650 --> 00:06:23,640
punched this 11 year old girl in the face.
And that was,

126
00:06:23,760 --> 00:06:24,920
was that removed from Twitter?

127
00:06:25,010 --> 00:06:28,010
I don't know. I would have to go
see if anyone reported it to us.

128
00:06:28,490 --> 00:06:31,310
I think one of the issues here is too is,
you know,

129
00:06:31,410 --> 00:06:35,160
you want me to get to the third
one. The third strike, um,

130
00:06:35,450 --> 00:06:39,800
that week we looked at was a verbal
altercation that Alex got into with a

131
00:06:39,801 --> 00:06:43,750
journalist. And in that altercation
there, which was uploaded to Twitter, um,

132
00:06:43,970 --> 00:06:47,000
there were a number of
statements using eyes of the rat,

133
00:06:47,270 --> 00:06:49,790
even more evil looking in person.
He just scum,

134
00:06:50,090 --> 00:06:53,570
you're a virus to America and freedom
smelling like a possum that climbed out of

135
00:06:53,571 --> 00:06:55,490
the rear end of a dead cow.

136
00:06:55,910 --> 00:06:58,370
You look like a possum that
got caught doing some really,

137
00:06:58,371 --> 00:07:02,810
really nasty stuff in my view. So
there was a bunch of, that's it really,

138
00:07:02,811 --> 00:07:04,460
that's hilarious.
Pattern and practice.

139
00:07:04,461 --> 00:07:07,510
But it was a verbal altercation
that was posted on our classrooms.

140
00:07:08,360 --> 00:07:13,010
So we took the totality of this having
been warned that we have rules against

141
00:07:13,011 --> 00:07:16,820
his abuse and harassment of individuals
and we saw this pattern in practice,

142
00:07:17,540 --> 00:07:19,940
one strike, two strike, three
strikes and we made a decision.

143
00:07:20,430 --> 00:07:23,970
And so that last one was on periscope.
Is that what it was that he uh,

144
00:07:24,080 --> 00:07:28,280
broadcast through? Um, I think it
was, uh, originally on periscope,

145
00:07:28,281 --> 00:07:32,480
but it was also re posted from
multiple related accounts onto Twitter.

146
00:07:33,320 --> 00:07:37,430
So we can, we can agree with you when
you say these things. Like, you know,

147
00:07:37,431 --> 00:07:38,720
Alex said this,
it sounds like a threat.

148
00:07:38,810 --> 00:07:40,730
He was berating this
person saying awful things.

149
00:07:41,090 --> 00:07:44,560
But ultimately your
judgment is the context.

150
00:07:44,570 --> 00:07:45,830
You say we have to pay
attention to the context.

151
00:07:45,860 --> 00:07:49,360
We just trusting that you made
the right decision. Well, I'm,

152
00:07:49,470 --> 00:07:53,000
I'm giving you as much facts as I can
give you here and I think that this is the

153
00:07:53,001 --> 00:07:57,830
real hard part of content moderation
at scale on global platforms.

154
00:07:57,860 --> 00:08:00,400
It's not easy and I don't think jack
or I would tell you that it's easy.

155
00:08:00,470 --> 00:08:02,930
That's a preposterous volume
do you guys have to deal with,

156
00:08:02,931 --> 00:08:05,630
and that's one of the things that I
wanted to get into with Jack when I first

157
00:08:05,631 --> 00:08:08,950
had them on because when my thought,
and um,

158
00:08:09,020 --> 00:08:13,760
I wasn't as concerned about the
censorship as many people were.

159
00:08:13,790 --> 00:08:18,790
My main concern was what does it like
to start this thing that's kind of for

160
00:08:19,041 --> 00:08:19,874
fun?

161
00:08:19,880 --> 00:08:23,600
And then all of a sudden it becomes the
premier platform for free speech on the

162
00:08:23,601 --> 00:08:24,890
planet earth.
So

163
00:08:26,010 --> 00:08:27,010
it is that,

164
00:08:27,011 --> 00:08:30,440
but it's also a platform that's used to
abuse and harass a lot of people, and,

165
00:08:30,441 --> 00:08:33,920
and used in ways that none of us want it
to be used by you molested. It happened.

166
00:08:33,930 --> 00:08:37,560
So, and I think it's an enormously
complicated challenge, uh,

167
00:08:37,750 --> 00:08:40,420
for any company to do
content moderation at scale.

168
00:08:40,421 --> 00:08:44,050
And that's something that we are sitting
down thinking about how do we take this

169
00:08:44,051 --> 00:08:47,560
forward? Because this is, it
doesn't scale. Yes, yes, yes.

