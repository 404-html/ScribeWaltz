1
00:00:04,540 --> 00:00:08,030
Joining me today is the founding editor 
of clearly,

2
00:00:08,040 --> 00:00:09,190
man,
welcome to the Rubin report.

3
00:00:09,400 --> 00:00:10,900
Thanks Dave.
Thanks for having me.

4
00:00:11,000 --> 00:00:13,660
I am thrilled to finally have you here.
This has been like,

5
00:00:13,670 --> 00:00:15,200
what,
87 years in the making.

6
00:00:16,510 --> 00:00:17,343
Well,
I live a very long way away so it's 

7
00:00:19,481 --> 00:00:20,680
difficult for me to get here.

8
00:00:20,810 --> 00:00:22,100
Yeah,
well you made it.

9
00:00:22,160 --> 00:00:22,993
You made it thousands of miles.
You are part of what I would say is idw 

10
00:00:26,271 --> 00:00:27,890
Australia,
I suppose.

11
00:00:28,880 --> 00:00:30,710
Yeah,
exactly.

12
00:00:30,980 --> 00:00:31,791
Um,
okay,

13
00:00:31,791 --> 00:00:32,980
so there's a ton I want to talk to you 
about it.

14
00:00:32,981 --> 00:00:33,814
Obviously I want to focus on Colette and
the work that you're doing and we 

15
00:00:35,841 --> 00:00:36,674
obviously have a lot in common on the 
issues that we care about and things of 

16
00:00:39,291 --> 00:00:41,420
that nature,
but first off you are from Australia.

17
00:00:41,421 --> 00:00:46,421
I've only had I think a two other guests
that are Australian natives on the show.

18
00:00:47,090 --> 00:00:49,100
What's going on in Australia these days?
What,

19
00:00:49,101 --> 00:00:51,590
what is the rest of the world needed to 
know about Australia?

20
00:00:51,740 --> 00:00:55,820
I would say that in Australia we're 
pretty chilled out at the moment,

21
00:00:55,821 --> 00:01:00,821
at least politically and culturally 
compared to America and even your,

22
00:01:01,400 --> 00:01:04,100
to a large extent,
we have a,

23
00:01:04,130 --> 00:01:04,963
we've had,
um,

24
00:01:05,120 --> 00:01:09,950
25 years or more of economic growth,
so people are pretty relaxed.

25
00:01:09,951 --> 00:01:12,560
People are doing well,
the middle class is doing well.

26
00:01:13,010 --> 00:01:13,843
Um,
there's not so much of a feeling that 

27
00:01:15,741 --> 00:01:16,574
there's a zero sum competition going on,
like people are fighting over scarce 

28
00:01:19,431 --> 00:01:20,264
resources and you know,
we obviously have political correctness 

29
00:01:23,781 --> 00:01:28,781
and identity politics and a lot of 
that's being imported from America.

30
00:01:29,060 --> 00:01:31,460
Yeah.
How does that get important?

31
00:01:31,461 --> 00:01:32,294
Because I was mentioning to you right 
before we started that a 

32
00:01:33,531 --> 00:01:34,364
disproportionate amount of our patrons,
the people who support this show more 

33
00:01:37,370 --> 00:01:39,710
Australia.
So even if things are going pretty well,

34
00:01:39,711 --> 00:01:41,930
there's definitely a segment of people 
that are going,

35
00:01:42,290 --> 00:01:45,830
something's either not right or where 
we're seeing the science be coming.

36
00:01:45,940 --> 00:01:46,960
Yeah,
it's true.

37
00:01:46,961 --> 00:01:47,794
I mean it's difficult to identify 
exactly how these cultural trends get 

38
00:01:51,411 --> 00:01:53,620
imported.
But um,

39
00:01:54,010 --> 00:01:56,010
for example,
through universities,

40
00:01:56,080 --> 00:01:59,680
through social media,
through traditional medium,

41
00:01:59,770 --> 00:02:04,770
so similar narratives get picked up by 
journalists like the oppression,

42
00:02:05,411 --> 00:02:09,910
narratives and um,
and we're seeing with the,

43
00:02:09,970 --> 00:02:12,790
with the young,
younger generations how the,

44
00:02:13,150 --> 00:02:13,983
how they pick up ideology through social
media and through the echo chambers and 

45
00:02:17,231 --> 00:02:21,190
the filter bubbles that are so easily 
accessible.

46
00:02:21,610 --> 00:02:22,443
Yeah.

47
00:02:22,710 --> 00:02:23,543
Do you think that there is a geographic 
reason that some of this stuff hasn't 

48
00:02:27,000 --> 00:02:28,620
fully hit Australia yet?
I mean,

49
00:02:28,621 --> 00:02:32,430
being surrounded by water and pretty 
from the rest of us,

50
00:02:32,431 --> 00:02:35,310
there's probably a little bit of safety 
in that I would imagine.

51
00:02:35,890 --> 00:02:38,430
Although borders are changing just 
because of technology.

52
00:02:38,560 --> 00:02:40,690
Yeah.
It's um,

53
00:02:41,380 --> 00:02:42,820
yeah.
So we're more isolated,

54
00:02:42,821 --> 00:02:44,380
that's for sure.
With smaller.

55
00:02:45,070 --> 00:02:47,500
Um,
so we don't have the same.

56
00:02:47,680 --> 00:02:52,680
We're not as diverse as other places 
like Europe and the United States.

57
00:02:54,790 --> 00:02:58,900
We have less income inequality in 
Australia which makes a.

58
00:03:00,280 --> 00:03:01,450
and um,
we're,

59
00:03:01,630 --> 00:03:04,030
we're actually kind of parochial as 
well.

60
00:03:04,120 --> 00:03:06,910
I mean we do pick up cultural trends 
from America,

61
00:03:06,911 --> 00:03:07,744
but at the same time we just focus on 
cooking shows and reality TV and 

62
00:03:12,250 --> 00:03:13,390
football games.

63
00:03:13,960 --> 00:03:17,440
Yeah.
So when the article came out back in,

64
00:03:17,441 --> 00:03:21,260
was it may or so the renegades of the 
intellectual dark web,

65
00:03:21,300 --> 00:03:24,790
you were included in there and many of 
us had not even met you.

66
00:03:25,390 --> 00:03:26,223
This is actually our first time meeting 
in person even though we've been 

67
00:03:28,871 --> 00:03:29,704
chatting online for awhile.
Were you shocked about the reaction to 

68
00:03:34,781 --> 00:03:39,490
that article because it really did sort 
of level up all of the issues that we've

69
00:03:39,491 --> 00:03:40,324
been all talking about?

70
00:03:40,720 --> 00:03:42,880
No,
I wasn't shocked at all.

71
00:03:42,881 --> 00:03:47,881
I think that the general movement,
this ideas movement,

72
00:03:48,350 --> 00:03:49,183
any pushback of the sort of moral 
orthodoxy that the politically correct 

73
00:03:55,091 --> 00:03:55,924
left have at the moment.
It's been brewing for some time and 

74
00:03:58,781 --> 00:04:01,930
someone just had to put a label on it.
Someone just had to name it.

75
00:04:02,560 --> 00:04:03,393
And um,
I wasn't shocked by the groundswell of 

76
00:04:07,991 --> 00:04:12,850
reaction to it because I've been seeing 
it through my work with.

77
00:04:13,230 --> 00:04:16,930
There are just so many people who writes
me every day who say,

78
00:04:17,320 --> 00:04:21,730
I love what you're doing.
I can't write a blog myself.

79
00:04:21,731 --> 00:04:22,564
I can't put my name on it because I 
would get in trouble at work or in my 

80
00:04:24,671 --> 00:04:27,970
university where there are so many 
people who,

81
00:04:28,280 --> 00:04:31,120
um,
want to participate in these discussions

82
00:04:31,121 --> 00:04:35,200
but can't for whatever reason and um,
you know,

83
00:04:35,201 --> 00:04:39,850
they like to be now be able to put a 
label on this general movement.

84
00:04:40,080 --> 00:04:40,913
Yeah.
So tell me a little bit about your 

85
00:04:42,011 --> 00:04:42,844
personal background.
What led you to be one of the people 

86
00:04:44,531 --> 00:04:45,364
that is okay,
putting your name on this stuff because 

87
00:04:46,751 --> 00:04:48,940
I do think that's one of the huge issues
here.

88
00:04:49,450 --> 00:04:54,450
We get all this support from academics,
people in politics and regular folks who

89
00:04:54,761 --> 00:04:58,450
were like,
and I see the dangers,

90
00:04:58,600 --> 00:05:02,320
but I don't want to put my name on it.
So how did Claire Lehman ended up here?

91
00:05:02,890 --> 00:05:05,140
Willing to put your name and face to all
this stuff?

92
00:05:05,520 --> 00:05:06,120
You know,
I,

93
00:05:06,120 --> 00:05:06,953
I think I have a bit more of a risk 
taking streak in my nature and I don't 

94
00:05:12,150 --> 00:05:17,150
feel the same fear around social 
disapproval as a lot of other people.

95
00:05:18,400 --> 00:05:19,233
Um,
so I was a psychology graduate student 

96
00:05:22,560 --> 00:05:27,560
and I left my Grad program and before I 
left I sort of,

97
00:05:29,250 --> 00:05:31,680
um,
uh,

98
00:05:31,800 --> 00:05:34,860
took a few risks during,
during my program and,

99
00:05:34,861 --> 00:05:38,220
and was sort of hung out to dry by the 
university,

100
00:05:38,221 --> 00:05:39,054
so to speak.

101
00:05:39,540 --> 00:05:42,890
An example of one of those sort of lit 
up when you said it.

102
00:05:43,310 --> 00:05:44,590
Well,
I,

103
00:05:44,680 --> 00:05:45,513
I complained about the amount of unpaid 
work that psychology students had to do 

104
00:05:49,941 --> 00:05:50,774
in a clinic that was associated with the
university and they weren't happy with 

105
00:05:54,681 --> 00:05:55,514
that and I sort of received a bit 
retaliation for sort of almost whistle 

106
00:06:00,150 --> 00:06:03,860
blowing on the amount of exploitation 
this clinic was involved in.

107
00:06:04,670 --> 00:06:08,390
So I've always said the first time I 
took a risk,

108
00:06:08,800 --> 00:06:09,633
um,
I've always taken risks when I've felt 

109
00:06:11,631 --> 00:06:16,631
that my conscience demands that I do so.
And what led me to create Colette was,

110
00:06:20,151 --> 00:06:23,360
um,
when I was a graduate student,

111
00:06:23,390 --> 00:06:27,860
I was involved in a lot of online 
discussions with academics in psychology

112
00:06:28,220 --> 00:06:29,053
and we had such fascinating,
interesting discussions that were 

113
00:06:31,671 --> 00:06:35,690
completely unlike anything that you 
would see in mainstream media.

114
00:06:35,691 --> 00:06:37,310
And I thought,
firstly,

115
00:06:37,311 --> 00:06:38,144
there's a business opportunity here.
If I can bring some of these 

116
00:06:40,341 --> 00:06:43,730
conversations to a market,
and secondly,

117
00:06:43,760 --> 00:06:46,610
you know,
people need to know that there are,

118
00:06:46,640 --> 00:06:47,473
there is scientific evidence in some of 
these topics and mainstream journalists 

119
00:06:52,590 --> 00:06:55,970
and neglecting to,
um,

120
00:06:56,270 --> 00:06:59,420
inform readers about some of these 
issues or some of,

121
00:06:59,450 --> 00:07:00,350
some of this evidence.

122
00:07:00,720 --> 00:07:01,553
Yeah.
So I want to read the mission statement 

123
00:07:03,181 --> 00:07:05,550
from Colette because it's pretty 
freaking perfect.

124
00:07:05,970 --> 00:07:09,960
Colette is a platform for free thought.
We respect ideas,

125
00:07:10,020 --> 00:07:13,800
even dangerous ones.
We also believe that free expression and

126
00:07:13,801 --> 00:07:17,670
the free exchange of ideas help human 
societies flourish and progress.

127
00:07:17,860 --> 00:07:21,750
Quill that aims to provide a platform 
for this exchange.

128
00:07:22,950 --> 00:07:26,430
Everybody seems to be afraid of 
dangerous ideas right now.

129
00:07:26,431 --> 00:07:26,941
Right?
I mean,

130
00:07:26,941 --> 00:07:27,774
that's why this little crew of people 
are together for whatever our 

131
00:07:30,961 --> 00:07:31,980
differences are.

132
00:07:32,150 --> 00:07:35,240
Yeah.
I think that there's a,

133
00:07:35,360 --> 00:07:36,193
there's been a conflation between giving
a platform or exploring ideas and 

134
00:07:42,081 --> 00:07:45,260
endorsing ideas and they're not the same
thing.

135
00:07:45,620 --> 00:07:46,453
So I will publish stuff on collect that 
I don't necessarily agree with 

136
00:07:50,390 --> 00:07:52,270
politically.
Um,

137
00:07:53,000 --> 00:07:57,070
I don't see the fact of publishing and 
in a,

138
00:07:57,500 --> 00:07:58,333
necessarily as an endorsement,
I also am very clear that I'm going to 

139
00:08:03,771 --> 00:08:07,610
make mistakes as an editor.
I'm a,

140
00:08:07,880 --> 00:08:08,713
we don't want to make mistakes about 
accuracy and if we're ever called out 

141
00:08:11,571 --> 00:08:14,300
for publishing something that's not 
factually correct,

142
00:08:14,301 --> 00:08:18,100
we will own up to that mistake,
but you know,

143
00:08:18,110 --> 00:08:18,943
we're living in a time of intense 
ideological flux and to work out where 

144
00:08:24,741 --> 00:08:25,574
we're all going,
we need to be able to talk about things 

145
00:08:27,171 --> 00:08:31,820
freely and we need to be able to make 
mistakes and I think make,

146
00:08:31,821 --> 00:08:32,654
being able to make mistakes is a sign of
a healthy environment and it's a sign 

147
00:08:36,321 --> 00:08:37,101
of,
you know,

148
00:08:37,101 --> 00:08:40,170
it's part of the creative process.
Um,

149
00:08:40,250 --> 00:08:41,510
so the,
the,

150
00:08:41,870 --> 00:08:44,540
the,
the worry is who want to shut down,

151
00:08:44,541 --> 00:08:45,374
debate,
who want to shut down free speech and 

152
00:08:47,810 --> 00:08:49,430
um,
give you that.

153
00:08:49,431 --> 00:08:50,264
Giving a platform for exploring 
dangerous ideas is equivalent to 

154
00:08:53,361 --> 00:08:54,194
endorsing them.
They're basically that you can't make a 

155
00:08:56,851 --> 00:08:59,080
mistake.
And that's,

156
00:08:59,200 --> 00:09:03,450
that's really scary because the only way
we move forward is to experiment,

157
00:09:03,790 --> 00:09:05,220
test new ideas,
see,

158
00:09:05,370 --> 00:09:08,440
see what works and pick the best ones 
out of the,

159
00:09:08,690 --> 00:09:11,880
the experimentation process and move 
forward that way.

160
00:09:12,000 --> 00:09:12,833
Yeah.
So I want to discuss some of the 

161
00:09:13,441 --> 00:09:15,130
dangerous ideas.
Sure.

162
00:09:15,140 --> 00:09:15,973
That your platform.
But it's interesting that you said this 

163
00:09:18,211 --> 00:09:19,044
thing about you don't mind making 
mistakes because I feel very much the 

164
00:09:21,451 --> 00:09:22,284
same.
I will sit down with all sorts of 

165
00:09:23,011 --> 00:09:24,450
people.
I've done it before.

166
00:09:24,451 --> 00:09:27,870
People I agree with and disagree with 
some people who I really don't like what

167
00:09:27,871 --> 00:09:28,704
they're talking about,
but I try to give everybody a fair 

168
00:09:30,391 --> 00:09:31,224
shake.
And what I'm noticing is there's a 

169
00:09:31,951 --> 00:09:35,250
tremendous amount of pushback just on 
that.

170
00:09:35,251 --> 00:09:37,170
That's what you're getting to.
Like the idea that hey,

171
00:09:37,171 --> 00:09:42,000
you can sit down with someone and 
separate a human being from their ideas,

172
00:09:42,001 --> 00:09:42,834
but also that there's this sort of 
secondary thing that I'm noticing and I 

173
00:09:45,211 --> 00:09:46,044
think you,
you get it too just from the articles 

174
00:09:47,461 --> 00:09:48,294
you guys put out,
which is that if I don't ask the exact 

175
00:09:50,911 --> 00:09:55,911
question that someone wants me to ask or
I miss this or I word this this way,

176
00:09:56,640 --> 00:10:00,090
but just this,
this army that doesn't feel that organic

177
00:10:00,091 --> 00:10:03,960
to me is ready to pounce and I'm really 
trying to work through that.

178
00:10:03,961 --> 00:10:05,880
Like I don't spend too much time 
thinking about it,

179
00:10:05,881 --> 00:10:07,950
but it is a conscious thing like,
oh,

180
00:10:08,460 --> 00:10:12,060
there's going to be this group of people
that no matter what I do and really what

181
00:10:12,061 --> 00:10:12,894
they're trying to do is chill everybody 
out so that you'll only talk about what 

182
00:10:15,301 --> 00:10:16,134
they're comfortable with.

183
00:10:16,740 --> 00:10:17,171
Yeah.
Well,

184
00:10:17,171 --> 00:10:18,004
there,
there are people at the moment who feel 

185
00:10:21,021 --> 00:10:24,560
that all the important questions have 
been answered.

186
00:10:25,070 --> 00:10:30,070
All of the important moral and ethical 
dilemmas have an answer and that at this

187
00:10:32,331 --> 00:10:33,164
point in history,
everything's been worked out and anyone 

188
00:10:35,721 --> 00:10:36,554
who's I'm exploring different ideas or 
is doubtful about these moral issues is 

189
00:10:44,660 --> 00:10:45,493
evil.

190
00:10:47,010 --> 00:10:47,890
Yeah,
yeah.

191
00:10:48,600 --> 00:10:49,120
Yeah.

192
00:10:49,120 --> 00:10:51,190
Um,
so I come,

193
00:10:51,460 --> 00:10:54,760
I come from a different approach where 
like,

194
00:10:54,820 --> 00:10:55,653
I don't know it's going on,
like I'm trying to work it out with 

195
00:10:57,941 --> 00:11:01,540
other people and um,
I want the freedom to be able to explore

196
00:11:02,070 --> 00:11:03,960
in a weird way.
Does that get you the most hate?

197
00:11:04,050 --> 00:11:06,690
Because I think I really believe that's 
where most people are.

198
00:11:06,691 --> 00:11:08,400
I think that's why people appreciate 
what I do here.

199
00:11:08,401 --> 00:11:09,234
I'm just being open about my journey and
listening to people and learning all of 

200
00:11:12,461 --> 00:11:15,890
that and that.
But that opens you up from hate from the

201
00:11:15,900 --> 00:11:16,733
both sides.
It's a lot easier to just stake out a 

202
00:11:18,121 --> 00:11:20,580
position and then you'll only get hate 
one way,

203
00:11:20,850 --> 00:11:23,040
but when you're like,
I am going to hear both sides,

204
00:11:23,041 --> 00:11:23,874
you know,
it's why I love listening to Sam Harris 

205
00:11:25,801 --> 00:11:27,870
and Jordan Peterson debate,
you know,

206
00:11:27,871 --> 00:11:29,820
the biggest existential questions that 
there are.

207
00:11:29,821 --> 00:11:31,200
It's like,
it's like,

208
00:11:31,210 --> 00:11:33,960
if I've completely settled my mind on 
this,

209
00:11:34,430 --> 00:11:35,263
I don't know,
I wouldn't be that impressed with my 

210
00:11:37,050 --> 00:11:38,280
thought process or something.

211
00:11:38,410 --> 00:11:39,740
Yeah.
Well,

212
00:11:39,741 --> 00:11:41,780
you know,
I don't get a lot of hate.

213
00:11:42,590 --> 00:11:44,420
I certainly have twitter trolls,
but

214
00:11:45,200 --> 00:11:46,033
way too,
we,

215
00:11:47,660 --> 00:11:49,920
um,
I sort of don't really notice it.

216
00:11:50,250 --> 00:11:51,240
Okay.
Yeah,

217
00:11:51,570 --> 00:11:54,010
that's probably the most simple way to 
deal with this.

218
00:11:54,130 --> 00:11:54,580
All right.
So let's,

219
00:11:54,580 --> 00:11:56,350
let's talk about some of those dangerous
ideas.

220
00:11:56,351 --> 00:12:00,400
What are some dangerous ideas that have 
bubbled up from your writers that you've

221
00:12:00,401 --> 00:12:04,120
had to think about or that you're 
focused on these days?

222
00:12:04,410 --> 00:12:05,243
Yeah,
so because my background is in 

223
00:12:06,751 --> 00:12:08,620
psychology,
um,

224
00:12:09,540 --> 00:12:14,280
we tackle issues that come from the 
behavioral sciences.

225
00:12:14,340 --> 00:12:15,173
So we've looked at sex differences,
psychological sex differences between 

226
00:12:19,921 --> 00:12:24,420
men and women,
differences in interests in occupations.

227
00:12:25,050 --> 00:12:25,883
Um,
so we've published some articles on why 

228
00:12:29,851 --> 00:12:31,920
there are fewer women in computer 
science,

229
00:12:31,921 --> 00:12:34,350
for example.
And um,

230
00:12:34,470 --> 00:12:35,303
we published a analysis of Jameson was 
google memo written by four different 

231
00:12:40,471 --> 00:12:43,080
scientists who have some expertise in 
that area.

232
00:12:43,980 --> 00:12:47,370
Uh,
we've published on intelligence reports.

233
00:12:47,670 --> 00:12:49,020
What were some of the results?

234
00:12:50,690 --> 00:12:52,070
Yeah,
well they,

235
00:12:52,160 --> 00:12:52,993
you know,
they basically said that something 

236
00:12:55,551 --> 00:12:59,810
pretty similar that he was in the 
ballpark in terms of getting the science

237
00:12:59,811 --> 00:13:04,811
right and he's position is valid in 
terms of regular scientific debate.

238
00:13:06,790 --> 00:13:10,430
There are observable sex differences 
between men and women.

239
00:13:10,880 --> 00:13:15,880
The differences in interest in 
occupations is very robust and reliable,

240
00:13:17,540 --> 00:13:18,373
so women are overwhelmingly interested 
in occupations which have something to 

241
00:13:23,871 --> 00:13:26,510
do with people,
so caring professions,

242
00:13:26,511 --> 00:13:27,344
medicine,
even law whereas men have more interest 

243
00:13:31,791 --> 00:13:35,420
in occupations that are to do with 
systems and things,

244
00:13:35,600 --> 00:13:39,980
so anything mechanical,
computer science and there's no,

245
00:13:40,520 --> 00:13:41,353
there's no difference between the 
average intelligent school is between 

246
00:13:44,151 --> 00:13:44,984
men and women and the evidence around 
differences in verbal and mathematical 

247
00:13:49,760 --> 00:13:53,360
ability is somewhat mixed.
The mean you can,

248
00:13:53,390 --> 00:13:54,223
you can have debates backwards and 
forwards over the strengths of those 

249
00:13:56,991 --> 00:13:57,824
differences,
but the difference in interest is very 

250
00:14:00,201 --> 00:14:00,980
robust.

251
00:14:00,980 --> 00:14:01,813
Why are people so afraid of that?
Why is it that there is a set of people 

252
00:14:06,891 --> 00:14:11,600
out there right now that want us to add 
to be all equal in their minds,

253
00:14:11,601 --> 00:14:15,200
but it would actually force us to go 
against nature.

254
00:14:15,201 --> 00:14:17,570
I mean that's what.
That's what this really is.

255
00:14:17,960 --> 00:14:18,793
Well,
there is a fear that if you acknowledge 

256
00:14:21,561 --> 00:14:26,450
that there are differences between 
individuals or groups,

257
00:14:27,170 --> 00:14:30,110
that you're saying that one group is 
inferior,

258
00:14:30,950 --> 00:14:34,700
so there's been a,
they,

259
00:14:35,090 --> 00:14:35,923
the idea that we have to be the same to 
be equal has been a very prevalent and 

260
00:14:41,631 --> 00:14:42,464
strong idea.
I don't know who came where the idea 

261
00:14:44,751 --> 00:14:47,300
comes from,
but it's,

262
00:14:47,810 --> 00:14:48,440
it's,
um,

263
00:14:48,440 --> 00:14:52,660
it's dangerous because if,
um,

264
00:14:53,330 --> 00:14:57,380
if you argue that no true equality can 
be achieved,

265
00:14:57,440 --> 00:14:59,230
unless we're all the same,
then no,

266
00:14:59,510 --> 00:15:01,760
then we can't have a quality.
However,

267
00:15:01,761 --> 00:15:02,594
if you argue that no,
we are all morally equal and that we 

268
00:15:06,711 --> 00:15:10,640
deserve equal opportunity and uh,
the equal,

269
00:15:10,641 --> 00:15:12,710
um,
uh,

270
00:15:12,770 --> 00:15:15,140
we,
we deserve equal opportunities to live a

271
00:15:15,141 --> 00:15:17,030
happy,
flourishing life.

272
00:15:17,360 --> 00:15:19,940
However,
there are differences between us.

273
00:15:20,330 --> 00:15:24,410
Then you can preserve that ethical 
principle.

274
00:15:25,160 --> 00:15:25,993
So it's very problematic for people who 
think that there can be no equality 

275
00:15:30,321 --> 00:15:31,154
between men and women unless we're 
proven to be the same identical because 

276
00:15:36,860 --> 00:15:39,710
the evidence doesn't support the idea 
that we're the same.

277
00:15:40,970 --> 00:15:41,803
What are,
what are some of the other dangerous 

278
00:15:43,120 --> 00:15:43,941
ideas?
Okay.

279
00:15:43,941 --> 00:15:44,774
So we've

280
00:15:45,130 --> 00:15:46,230
the dangerous role.

281
00:15:46,290 --> 00:15:47,071
Yeah.
Yeah.

282
00:15:47,071 --> 00:15:47,904
Um,
we've published work on intelligence 

283
00:15:50,011 --> 00:15:52,110
research,
which is controversial.

284
00:15:52,690 --> 00:15:55,770
Uh,
we've published articles about the

285
00:15:55,870 --> 00:15:56,703
heritage.
Are you talking about intelligence and 

286
00:15:57,941 --> 00:15:58,774
race?

287
00:15:59,130 --> 00:15:59,550
Okay.

288
00:15:59,550 --> 00:16:01,700
This seems to be one of their people 
seem to be all

289
00:16:01,830 --> 00:16:03,240
that's.
Yeah,

290
00:16:03,241 --> 00:16:06,170
that's a hugely controversial issue.
And uh,

291
00:16:06,270 --> 00:16:08,120
we've published,
um,

292
00:16:08,730 --> 00:16:09,563
we published a defense of the child's 
marries the bell curve because after he 

293
00:16:15,001 --> 00:16:15,834
had his conversation with Sam Harris,
vox came out and wrote a hit piece or 

294
00:16:22,141 --> 00:16:24,870
right at some,
some kind of article that misrepresented

295
00:16:24,871 --> 00:16:27,480
what they talked about and the bell 
curve.

296
00:16:27,960 --> 00:16:28,793
And so we published a response from 
Professor Richard Hire who's the editor 

297
00:16:35,551 --> 00:16:36,384
of the intelligence journal,
so he's a preeminent expert in this 

298
00:16:39,751 --> 00:16:40,584
area.
And he defended Charles Murray's book 

299
00:16:43,170 --> 00:16:47,940
and defended the conversation that they 
had and said this is an important issue.

300
00:16:48,360 --> 00:16:53,360
It's scientifically valid and has merit 
to talk about these issues.

301
00:16:54,571 --> 00:16:55,750
And they got,
they were,

302
00:16:55,980 --> 00:16:58,740
they got the science right.
Um,

303
00:16:59,670 --> 00:17:00,503
so we,
we don't aim to be provocative for the 

304
00:17:04,501 --> 00:17:07,980
sake of just being inflammatory,
right?

305
00:17:07,981 --> 00:17:08,814
We,
we have an objective where we want to 

306
00:17:11,221 --> 00:17:12,054
protect the scientists who are having,
who are doing this work or who are 

307
00:17:15,721 --> 00:17:16,554
having these conversations we want us,
we want to protect the individuals who 

308
00:17:22,051 --> 00:17:22,884
are doing the knowledge production or 
the research we want to protect them 

309
00:17:29,521 --> 00:17:30,354
from the boxes and the journalists who 
just want to write hate pieces just to 

310
00:17:35,791 --> 00:17:40,110
get the clicks so we have a sort of a 
commitment to those people who are doing

311
00:17:40,111 --> 00:17:42,510
risky work and need that kind of 
protection.

312
00:17:42,650 --> 00:17:44,520
You're going to my soft spot today 
because as,

313
00:17:44,750 --> 00:17:48,020
as we're taking this as we're taping 
this only like an hour ago,

314
00:17:48,021 --> 00:17:51,870
vox did a piece about me about how I'm 
part of the reactionary right?

315
00:17:52,430 --> 00:17:56,580
And it's just like you guys are awful.
So when a weird way your,

316
00:17:56,590 --> 00:17:57,423
your,
your job in some respects has become 

317
00:18:00,001 --> 00:18:00,834
sort of like a force field to just allow
people to do the work that they're 

318
00:18:04,741 --> 00:18:05,750
supposed to be doing.

319
00:18:06,010 --> 00:18:06,700
Yeah.
Because.

320
00:18:06,700 --> 00:18:07,533
Right?
Because universities for all sorts of 

321
00:18:10,031 --> 00:18:11,650
different reasons,
uh,

322
00:18:12,040 --> 00:18:17,040
neglecting their duty to academic 
freedom and academic freedom is meant to

323
00:18:18,701 --> 00:18:23,701
exist to protect scientists in 
particular who are doing work,

324
00:18:23,981 --> 00:18:24,814
which contradicts the religious 
orthodoxy of the time or the moral 

325
00:18:29,621 --> 00:18:30,454
orthodoxy.
And it's quite clear to me that there 

326
00:18:31,601 --> 00:18:32,434
are scientists doing work which 
challenges politically correct dogmas 

327
00:18:37,720 --> 00:18:38,553
and I don't see universities doing a 
very good job at protecting those 

328
00:18:42,011 --> 00:18:46,780
scientists.
And so we feel like we can fill the gap.

329
00:18:47,420 --> 00:18:48,253
Where,
where do you think the gender studies 

330
00:18:49,760 --> 00:18:50,593
stuff fits into all this?
Because in a weird way it seems like 

331
00:18:52,431 --> 00:18:57,110
it's all being whittled down to that 
somehow that now,

332
00:18:57,111 --> 00:18:57,944
especially related to trans issues,
I was just talking to a fairly well 

333
00:19:01,731 --> 00:19:02,564
known public professor yesterday off the
record about how he's going into his 

334
00:19:06,530 --> 00:19:07,363
old,
even though he's factually correct and 

335
00:19:10,611 --> 00:19:11,420
it's calm,
you know,

336
00:19:11,420 --> 00:19:12,253
confident about his research.
He's going into old lesson plans to 

337
00:19:14,691 --> 00:19:18,230
change wording just because he doesn't 
want to deal with the mob.

338
00:19:18,231 --> 00:19:20,870
So things that were completely 
acceptable three,

339
00:19:20,871 --> 00:19:23,210
four years ago is now having to edit 
out.

340
00:19:23,450 --> 00:19:23,900
I mean,
that's,

341
00:19:23,900 --> 00:19:24,733
that's truly dangerous.
So what is going on with the gender 

342
00:19:26,781 --> 00:19:28,260
studies department and the rest of this

343
00:19:29,550 --> 00:19:32,550
moving so fast,
it's hard to really,

344
00:19:32,551 --> 00:19:33,384
um,
to analyze what's going on when it's 

345
00:19:36,210 --> 00:19:37,043
shifting so fast.
But certainly many of the humanities 

346
00:19:42,001 --> 00:19:46,050
departments took a turn back in the 19 
seventies and they took,

347
00:19:46,200 --> 00:19:47,040
they,
um,

348
00:19:47,430 --> 00:19:52,430
took on these fashionable theories such 
as poststructuralism and uh,

349
00:19:53,730 --> 00:19:56,520
they,
they rejected empirical methods.

350
00:19:56,610 --> 00:19:57,443
Um,

351
00:19:58,200 --> 00:19:59,033
and so then the argument,
if we were trying to give them the 

352
00:20:00,701 --> 00:20:03,670
credit that they're due,
at least in the argument,

353
00:20:03,671 --> 00:20:06,730
if you're,
if you're rejecting empirical science or

354
00:20:06,780 --> 00:20:07,613
verbal facts,
what is your argument that leads you 

355
00:20:09,281 --> 00:20:10,114
there?
Because I know people are watching us 

356
00:20:11,431 --> 00:20:12,880
go,
that's just sounds crazy,

357
00:20:13,570 --> 00:20:16,090
but they obviously believe it.
So let's try to give the devil his deal,

358
00:20:16,091 --> 00:20:16,361
right?
Yeah.

359
00:20:16,361 --> 00:20:16,610
So

360
00:20:16,610 --> 00:20:17,443
postmodernist have a good point and that
is that we are all biased and a 

361
00:20:22,551 --> 00:20:26,150
scientist looking at an issue such as,
um,

362
00:20:26,270 --> 00:20:31,270
sexuality has his or her own biases.
Right?

363
00:20:31,640 --> 00:20:35,850
And so the questions that the scientists
asks when he or her,

364
00:20:35,930 --> 00:20:39,320
he or she is designing a survey or 
designing a lab experiment,

365
00:20:39,530 --> 00:20:42,200
I'm going to have some bias embedded 
within them.

366
00:20:43,250 --> 00:20:46,700
So that's true.
And the postmodernist had that insight.

367
00:20:47,080 --> 00:20:47,913
However,
the mistake they make is getting rid of 

368
00:20:51,450 --> 00:20:52,283
an empirical and objective methods all 
together and just saying because we're 

369
00:20:56,321 --> 00:20:57,790
biased,
what's the point?

370
00:20:57,940 --> 00:20:58,773
Right?
So they're doing like a massive 

371
00:21:00,041 --> 00:21:01,040
overcorrection

372
00:21:01,130 --> 00:21:02,300
yes,
yes.

373
00:21:02,750 --> 00:21:04,280
When,
when,

374
00:21:04,340 --> 00:21:06,380
what should be done is acknowledging,
yes,

375
00:21:06,381 --> 00:21:08,980
we all have our bias.
Um,

376
00:21:09,110 --> 00:21:11,420
and if I'm a scientist designing a 
study,

377
00:21:11,421 --> 00:21:12,254
I'm going to have my bias and it might 
get embedded into the work that I'm 

378
00:21:14,901 --> 00:21:16,340
doing.
However,

379
00:21:16,640 --> 00:21:17,473
there are ways to correct that and we 
want to improve our quantitative 

380
00:21:21,200 --> 00:21:24,170
methodologies in order to correct for 
our own biases.

381
00:21:24,171 --> 00:21:27,260
So the problem that the postmodernist 
have is that they say,

382
00:21:27,261 --> 00:21:30,080
well,
the bias is there,

383
00:21:30,081 --> 00:21:30,914
so let's put it all in the bin and we're
just going to double down on the bias 

384
00:21:33,531 --> 00:21:36,470
and just talk about lived experience.
I mean,

385
00:21:36,471 --> 00:21:39,500
that is just taking the completely the 
wrong direction,

386
00:21:39,740 --> 00:21:40,131
right?
I mean,

387
00:21:40,131 --> 00:21:42,500
it's quite literally the reverse of the 
scientific method,

388
00:21:42,501 --> 00:21:46,340
so basically they're saying that that 
bias is truth,

389
00:21:46,400 --> 00:21:47,233
right?
I mean if you're saying bias that the 

390
00:21:48,621 --> 00:21:51,680
lived experience is what truth is,
then bias is true.

391
00:21:51,710 --> 00:21:52,550
You know,
I don't know if you saw it,

392
00:21:52,551 --> 00:21:55,370
but I did this,
this talk at University of New Hampshire

393
00:21:55,640 --> 00:21:59,540
and this woman was yelling at me,
this trans woman calling me all right,

394
00:21:59,541 --> 00:22:01,580
and all of this other nonsense shouting 
me down.

395
00:22:01,730 --> 00:22:03,890
I didn't realize this till two months 
later or something,

396
00:22:03,891 --> 00:22:06,770
but it turned out she was a gender 
studies professor at the school.

397
00:22:07,220 --> 00:22:11,270
So you've got a gender studies professor
trying to shout down and invited speaker

398
00:22:11,330 --> 00:22:13,700
while live tweeting that I'm alright or 
whatever,

399
00:22:13,810 --> 00:22:14,643
and it's like,
I'm pretty sure maybe I'm not right 

400
00:22:16,731 --> 00:22:18,390
about everything.
I'll concede on that.

401
00:22:18,470 --> 00:22:19,303
Even though I wanted it.
I said she should be treated with 

402
00:22:20,451 --> 00:22:21,284
respect and equality and all that,
but your bias that you're acting on 

403
00:22:26,301 --> 00:22:27,134
right now,
it definitely is not closer to truth 

404
00:22:28,250 --> 00:22:29,780
than what I was saying.

405
00:22:29,880 --> 00:22:31,950
Yeah.
So I.

406
00:22:31,950 --> 00:22:34,320
The way I think of it is that,
you know,

407
00:22:34,321 --> 00:22:35,154
there is an objective reality and the 
way we get to objective realities 

408
00:22:39,481 --> 00:22:41,380
through the scientific method,
um,

409
00:22:42,000 --> 00:22:42,833
whereas post modernists,
academics believe a lot of them believe 

410
00:22:46,681 --> 00:22:47,514
that reality is created through language
and discourse and I think that's one of 

411
00:22:52,861 --> 00:22:53,694
the reasons why they believe that words 
can be violence because if reality is 

412
00:22:57,421 --> 00:23:02,421
actually created three language and 
discourse and there's some kind of,

413
00:23:03,480 --> 00:23:04,313
there's some toxic discourse,
then they truly believed that reality 

414
00:23:07,471 --> 00:23:08,304
can be changed through words.
And so I think that's why they get so 

415
00:23:11,701 --> 00:23:12,534
upset about freedom of speech and just 
having discussions because they truly 

416
00:23:17,821 --> 00:23:21,420
believe that words can change the way 
the world is constructed.

417
00:23:21,880 --> 00:23:24,700
Right?
So for now they say it's okay to punch a

418
00:23:24,701 --> 00:23:25,570
Nazi.
Well,

419
00:23:25,571 --> 00:23:26,404
they call everybody Nazis.
Then it's okay to punch a Nazi and then 

420
00:23:29,260 --> 00:23:32,530
we can go however far down that road we 
want to go.

421
00:23:32,531 --> 00:23:34,540
And then then you're completely 
condoning mines.

422
00:23:34,930 --> 00:23:35,763
How concerned are you that these ideas 
are going to trickle up higher into 

423
00:23:39,641 --> 00:23:43,090
places of power and that once they look,
we know they're in the media.

424
00:23:43,091 --> 00:23:44,920
You've already mentioned box and a 
couple of those other,

425
00:23:46,520 --> 00:23:49,510
but that once they're really into places
of power in Australia,

426
00:23:49,520 --> 00:23:50,353
in the states or wherever else that the 
screws are really going to be turned 

427
00:23:53,691 --> 00:23:54,524
against us because we're fighting for 
free speech would mostly be concerned 

428
00:24:00,081 --> 00:24:04,400
about these ideas getting into the law.
Traditionally,

429
00:24:04,401 --> 00:24:05,234
the lore is a conservative field and 
they are pretty good at resisting 

430
00:24:11,031 --> 00:24:15,590
political fads,
but you can see with the way that law is

431
00:24:15,591 --> 00:24:16,424
taught in law schools at the moment that
there is critical legal studies and 

432
00:24:20,391 --> 00:24:25,070
often critical legal studies is a 
mandatory component.

433
00:24:25,071 --> 00:24:25,904
So they teach like the feminist 
interpretation of law and these 

434
00:24:32,060 --> 00:24:34,110
approaches,
um,

435
00:24:34,340 --> 00:24:35,173
can undermine some of the basic 
fundamentals of foundations of how the 

436
00:24:40,941 --> 00:24:42,440
Lord is meant to work.
So I,

437
00:24:42,500 --> 00:24:43,333
yeah,
I am worried that there are a lot of 

438
00:24:45,591 --> 00:24:46,424
attacks on due process at the moment,
freedom of speech and the scientific 

439
00:24:50,751 --> 00:24:51,584
method.
Those three things are foundations of a 

440
00:24:55,071 --> 00:24:59,150
civilized society and all of them are 
being attacked at the moment.

441
00:24:59,720 --> 00:25:03,590
How does me to fit into this?
Because you've been somewhat critical of

442
00:25:03,591 --> 00:25:06,350
that.
I think it's all three of those criteria

443
00:25:06,351 --> 00:25:07,880
that you just laid out there.
Look,

444
00:25:07,881 --> 00:25:08,714
you know,
obviously me to started as a really 

445
00:25:11,331 --> 00:25:16,331
legitimate and powerful movement in 
identifying the,

446
00:25:17,410 --> 00:25:20,870
the predation that Harvey Weinstein was 
engaged in.

447
00:25:20,871 --> 00:25:23,120
And,
and surely there are,

448
00:25:23,510 --> 00:25:26,740
there have been many powerful men,
um,

449
00:25:27,200 --> 00:25:28,033
in the last couple of decades working in
industries where there's a lot of young 

450
00:25:31,041 --> 00:25:31,874
women around and they have positions of 
power and they're able to exploit those 

451
00:25:36,470 --> 00:25:38,750
positions.
But,

452
00:25:38,751 --> 00:25:40,310
you know,
I'm a young woman myself,

453
00:25:40,311 --> 00:25:41,540
right?
And I,

454
00:25:41,840 --> 00:25:45,310
I don't see sexual harassment,
um,

455
00:25:45,370 --> 00:25:49,100
as being,
as pervasive as a lot of people claim.

456
00:25:49,310 --> 00:25:54,310
And I also think it's very dangerous to 
make accusations against people publicly

457
00:25:56,270 --> 00:26:00,800
because our reputations are so valuable 
and so important that,

458
00:26:01,340 --> 00:26:03,050
um,
you know,

459
00:26:03,051 --> 00:26:03,884
we,
we need to respect other people's 

460
00:26:05,570 --> 00:26:07,390
ability to have,
have their,

461
00:26:07,510 --> 00:26:11,780
their reputation and I'm making 
accusations in public,

462
00:26:11,781 --> 00:26:14,450
sort of goes against my,
um,

463
00:26:15,350 --> 00:26:20,350
my feeling that it feels indicative to 
me and it feels dangerous,

464
00:26:21,840 --> 00:26:26,540
dangerous path to go down because for 
every true accusation,

465
00:26:26,541 --> 00:26:30,050
they ease of sexual harassment and is 
going to be someone who is,

466
00:26:30,051 --> 00:26:33,080
um,
you know,

467
00:26:33,081 --> 00:26:33,914
there's,
there are going to be people who have 

468
00:26:34,641 --> 00:26:35,474
conflicts and then the conflict,
someone feels like they can resolve a 

469
00:26:38,871 --> 00:26:41,690
conflict through making an accusation of
sexual harassment.

470
00:26:41,690 --> 00:26:43,110
And that's really scary.
We don't,

471
00:26:43,140 --> 00:26:46,920
we don't want people to resolve their 
conflicts by making public accusations.

472
00:26:47,070 --> 00:26:49,010
Right?
But I definitely think there's a certain

473
00:26:49,011 --> 00:26:51,500
set of people that don't mind collateral
damage,

474
00:26:51,501 --> 00:26:51,981
right?
I mean,

475
00:26:51,981 --> 00:26:53,390
that seems to be what's happening right 
now.

476
00:26:53,391 --> 00:26:54,710
And people,
you see this public,

477
00:26:54,711 --> 00:26:56,330
people that are tweeting these kinds of 
things,

478
00:26:56,331 --> 00:26:59,870
like it doesn't matter if you can take 
down a couple of innocent people.

479
00:26:59,871 --> 00:27:00,704
That's how dangerous this thing is.
That strikes me as far more dangerous 

480
00:27:04,041 --> 00:27:04,874
and I'm not belittling any of the actual
things that some of these women have 

481
00:27:08,380 --> 00:27:09,040
gone through.

482
00:27:09,040 --> 00:27:10,390
Yeah,
it's scary.

483
00:27:10,450 --> 00:27:11,283
It's the desire for collective 
punishment and that collective 

484
00:27:17,741 --> 00:27:18,574
punishment is is is scary it.
If you look at the Geneva Convention 

485
00:27:25,301 --> 00:27:27,790
that was established after World War 
Two,

486
00:27:28,570 --> 00:27:33,570
the UN declared collective punishment,
a war crime,

487
00:27:34,270 --> 00:27:35,103
so the idea is that when there is a 
conflict between ethnic groups in 

488
00:27:39,431 --> 00:27:43,000
certain places,
if if one,

489
00:27:43,001 --> 00:27:45,880
if some people are killed in that inner 
conflict,

490
00:27:45,940 --> 00:27:46,773
you can't then go and wipe out a village
as a collective collective rich 

491
00:27:50,020 --> 00:27:53,260
retribution because that's how these war
crimes happen.

492
00:27:53,830 --> 00:27:57,700
So now we're this.
I'm like you said,

493
00:27:57,701 --> 00:27:58,534
this collateral damage,
this desire for collateral damage is 

494
00:28:01,071 --> 00:28:04,210
being normalized.
Like people don't seem to understand how

495
00:28:04,360 --> 00:28:08,200
dangerous this is and how unjust it is.

496
00:28:08,480 --> 00:28:11,740
What is part of the issue that perhaps 
they do understand it,

497
00:28:11,741 --> 00:28:16,741
but they so want to destroy the system.
I've been on tour with Jordan Peterson.

498
00:28:16,961 --> 00:28:20,290
One of the things he's been talking 
about a lot lately is yes,

499
00:28:20,291 --> 00:28:23,770
you can acknowledge that we don't have 
perfect systems and then there's perfect

500
00:28:23,771 --> 00:28:25,660
systems are probably impossible to ever 
get to,

501
00:28:26,230 --> 00:28:28,840
but now we have this new thing in the 
system,

502
00:28:28,841 --> 00:28:32,940
which is let's just freaking destroy the
whole thing to build our perfect system.

503
00:28:33,140 --> 00:28:33,973
Yeah.
I think people don't understand because 

504
00:28:37,580 --> 00:28:41,240
we're not taught anymore.
We're not taught history properly.

505
00:28:41,241 --> 00:28:42,074
We're not,
we don't learn about human nature in 

506
00:28:44,331 --> 00:28:49,331
school and how it's almost an instinct 
to want to desire retribution,

507
00:28:50,090 --> 00:28:52,190
retribution,
and vindictive justice.

508
00:28:52,191 --> 00:28:53,024
I think it's,
it's part of our nature is to want to 

509
00:28:55,101 --> 00:28:59,030
punish people and punish groups.
Um,

510
00:28:59,540 --> 00:29:04,540
and now institutions like a g process 
and the presumption of innocence,

511
00:29:04,940 --> 00:29:09,940
they sort of go against our instincts,
but that's why they say,

512
00:29:10,530 --> 00:29:11,271
yeah.
Yeah.

513
00:29:11,271 --> 00:29:12,104
Yeah.
And I think what we're seeing is just 

514
00:29:13,521 --> 00:29:16,400
sort of like a regression back to our 
more tribal,

515
00:29:16,401 --> 00:29:17,234
instinctive nature.
And because our education system is so 

516
00:29:21,050 --> 00:29:21,883
atrophied,
young people aren't being taught the 

517
00:29:24,291 --> 00:29:27,830
value and the fragility of these 
institutions,

518
00:29:27,950 --> 00:29:30,260
how they came about,
why they're so important,

519
00:29:30,261 --> 00:29:31,094
why we must protect them.
So I think there's just a basic 

520
00:29:33,621 --> 00:29:34,454
ignorance about why these institutions,
institutions exist in the first place 

521
00:29:39,050 --> 00:29:43,210
and then we're regressing to our more 
primitive natures.

522
00:29:43,390 --> 00:29:44,223
Yeah.
How do you think social media fits into 

523
00:29:45,241 --> 00:29:46,830
this?
Because I did a video,

524
00:29:46,831 --> 00:29:47,664
I think it's almost three years ago now,
that online culture is becoming 

525
00:29:50,791 --> 00:29:53,870
mainstream culture and I think that 
that's what we're seeing there.

526
00:29:53,900 --> 00:29:54,733
What used to be just relegated to the 
meme makers and peppy people has now 

527
00:29:58,291 --> 00:29:59,124
just leaked everywhere and just everyone
in public is acting sort of as their 

528
00:30:04,021 --> 00:30:07,440
worst selves over time that feeds all of
this.

529
00:30:07,441 --> 00:30:10,550
Let's either destroy the system or let's
ignore legitimate problems.

530
00:30:11,240 --> 00:30:12,073
Well,
when you don't have proper law and 

531
00:30:13,191 --> 00:30:14,024
order,
you do get more justice in vigilante 

532
00:30:15,771 --> 00:30:16,604
justice in real life.
And you can see that throughout history 

533
00:30:18,861 --> 00:30:21,200
you've got,
you get lynchings.

534
00:30:21,550 --> 00:30:23,990
Um,
you get pogroms,

535
00:30:24,650 --> 00:30:25,483
you get groups like mobs of people going
and attacking an individual who they 

536
00:30:30,201 --> 00:30:35,090
think is guilty of like a sex crime or 
some other crime and killing the person.

537
00:30:35,480 --> 00:30:37,850
So,
and then what happened was,

538
00:30:37,851 --> 00:30:42,020
is we developed legal and social norms 
that stopped,

539
00:30:42,050 --> 00:30:42,883
that kind of vigilante justice from 
taking place and if you are a vigilante 

540
00:30:46,611 --> 00:30:47,444
you can,
you can get in trouble with the law and 

541
00:30:49,880 --> 00:30:50,713
then we've developed social norms that 
prevent people from just forming mobs 

542
00:30:54,201 --> 00:30:56,060
and going attacking people in the 
street.

543
00:30:56,720 --> 00:30:57,553
But social media is this new technology 
and we haven't developed any of the 

544
00:31:01,401 --> 00:31:06,401
legal or social norms yet and so it's 
brought back this mobbing behavior,

545
00:31:06,711 --> 00:31:09,770
which is part of our nature.
It's brought it back.

546
00:31:09,771 --> 00:31:14,600
But we haven't yet developed any of the 
norms to sort of suppress it or mitigate

547
00:31:14,601 --> 00:31:15,434
against it and I think we eventually 
will develop these norms but it's gonna 

548
00:31:19,580 --> 00:31:21,010
take awhile and there's going to be a 
feat.

549
00:31:21,011 --> 00:31:24,710
Innocent people sort of metaphorically 
lynched in the process.

550
00:31:24,890 --> 00:31:25,723
Yeah.
So that's actually an interesting segue 

551
00:31:26,831 --> 00:31:28,120
to something that's been on my mind 
lately.

552
00:31:28,121 --> 00:31:28,954
So you know,
Alex Jones got booted from twitter and 

553
00:31:31,481 --> 00:31:32,314
Youtube and facebook or whatever.
I don't even want to talk about any of 

554
00:31:35,800 --> 00:31:38,350
the things that he talks about.
It does not matter,

555
00:31:38,720 --> 00:31:39,553
but.
But these tech companies basically 

556
00:31:40,811 --> 00:31:43,060
decided that this one guy is too 
dangerous,

557
00:31:43,061 --> 00:31:45,350
you know,
Erica and can be on here and Hamas,

558
00:31:45,530 --> 00:31:46,363
whoever you,
whoever else you want to pick that you 

559
00:31:47,111 --> 00:31:48,880
don't like can be on your.
But this guy,

560
00:31:48,881 --> 00:31:51,190
you know,
even paypal took them out last week.

561
00:31:51,610 --> 00:31:52,443
Um,
do you think that the free speech crew 

562
00:31:54,460 --> 00:31:55,293
for getting his ideas,
do you think we should have offered a 

563
00:31:58,211 --> 00:31:59,044
better defense of why this person,
a person should be allowed to use these 

564
00:32:03,671 --> 00:32:04,110
things?
I mean,

565
00:32:04,110 --> 00:32:06,280
should guy be allowed to make a phone 
call?

566
00:32:06,281 --> 00:32:07,114
Should he allow,
should he be allowed to have running 

567
00:32:08,141 --> 00:32:10,810
water at his house?
Where do we draw the lines for days?

568
00:32:11,070 --> 00:32:11,903
Yeah.
Well I think these tools that we use 

569
00:32:15,251 --> 00:32:18,820
such as payment processing and social 
media such as twitter,

570
00:32:18,821 --> 00:32:19,654
the instant messaging,
their tools and they should be treated 

571
00:32:23,171 --> 00:32:24,820
as,
as such,

572
00:32:24,821 --> 00:32:28,330
like having electricity or water.
And um,

573
00:32:28,650 --> 00:32:31,530
so you believe there are public good,
basically the same work,

574
00:32:31,800 --> 00:32:34,590
getting water to your house,
getting the phone line connected to your

575
00:32:34,591 --> 00:32:34,790
house.

576
00:32:34,790 --> 00:32:35,960
Yeah.
And,

577
00:32:36,410 --> 00:32:37,243
and they shouldn't be politicized.
And as soon as you politicize these 

578
00:32:40,701 --> 00:32:41,690
tools,
then it's,

579
00:32:41,720 --> 00:32:46,430
there's a slippery slope and you know,
then there's going to be arguments about

580
00:32:46,431 --> 00:32:50,690
who do we band next,
what standards do we want to sit in,

581
00:32:50,691 --> 00:32:54,530
that kind of thing.
In the context of Alex Jones,

582
00:32:54,531 --> 00:32:54,930
I,
I,

583
00:32:54,930 --> 00:32:58,370
I think there's probably more to the 
story that the public is aware of.

584
00:32:58,371 --> 00:33:01,430
So I don't want to comment on him 
specifically,

585
00:33:01,450 --> 00:33:02,570
but.
And I don't want to make it a bit.

586
00:33:02,580 --> 00:33:03,413
Yeah,
it's just the general idea that a 

587
00:33:04,660 --> 00:33:05,493
digital assassination can occur because 
we're all agreeing to terms of services 

588
00:33:09,251 --> 00:33:10,084
that I'm not sitting around with a 
lawyer every time I click accept to the 

589
00:33:12,791 --> 00:33:16,870
new service and that eventually you 
could move on.

590
00:33:16,871 --> 00:33:18,130
Anybody,
you know what I mean?

591
00:33:18,400 --> 00:33:19,233
We know the way these ideas work.
You don't get one person and then 

592
00:33:20,981 --> 00:33:22,240
suddenly be like,
oh,

593
00:33:22,241 --> 00:33:24,040
well we're good to go.
It's like,

594
00:33:24,041 --> 00:33:24,860
who do you get net?

595
00:33:24,860 --> 00:33:25,693
Yeah.
And the,

596
00:33:25,760 --> 00:33:28,790
the payment and processing is,
is scary.

597
00:33:28,791 --> 00:33:31,940
I mean the idea that that should be 
politicized is just.

598
00:33:31,941 --> 00:33:33,260
That is crazy.

599
00:33:33,530 --> 00:33:35,750
Yeah.
So what do you think the solution is?

600
00:33:35,780 --> 00:33:36,613
I mean,
I think you probably know what my 

601
00:33:37,550 --> 00:33:40,310
solution is that we need more 
competition,

602
00:33:40,520 --> 00:33:44,770
but I'm really understanding of big 
counter to that because it's like,

603
00:33:45,150 --> 00:33:46,550
where is the county?
Where is it?

604
00:33:46,560 --> 00:33:47,393
Yeah,
no,

605
00:33:47,760 --> 00:33:48,593
look,
I didn't have the onset and I tend 

606
00:33:50,371 --> 00:33:55,371
towards being um,
economically liberal.

607
00:33:55,561 --> 00:33:58,440
However,
some of these tools,

608
00:33:58,441 --> 00:33:59,274
as you said,
are public goods and perhaps need to be 

609
00:34:01,681 --> 00:34:05,310
thought of as public goods rather than 
rather than private.

610
00:34:05,340 --> 00:34:07,080
And um,
you know,

611
00:34:07,081 --> 00:34:10,230
I'm not,
I'm open to ideas of regulation,

612
00:34:10,710 --> 00:34:13,500
government intervention,
and um,

613
00:34:13,800 --> 00:34:14,633
I'm also open to ideas about breaking up
some of the monopolies because we 

614
00:34:21,600 --> 00:34:22,433
competition would be lovely,
but it's a bit difficult at the moment 

615
00:34:24,541 --> 00:34:25,374
because some of these companies have 
gotten monopolies in lots of different 

616
00:34:30,571 --> 00:34:32,310
verticals.
So Google,

617
00:34:32,311 --> 00:34:33,144
for example,
has the search engine monopoly they've 

618
00:34:35,791 --> 00:34:38,220
got that almost got the advertising 
monopoly,

619
00:34:38,430 --> 00:34:41,970
so they're leveraging their monopoly in 
one area into others.

620
00:34:42,000 --> 00:34:44,730
And that,
that just shuts down competition.

621
00:34:44,830 --> 00:34:45,663
Yeah.
Do you think it's even something a 

622
00:34:46,091 --> 00:34:48,550
little more perverse than that,
which is that,

623
00:34:48,610 --> 00:34:49,001
you know,
look,

624
00:34:49,001 --> 00:34:51,610
there's obviously I'm not blowing the 
lid on anything here.

625
00:34:51,611 --> 00:34:54,880
There's obviously tons of discussions 
with all sorts of people about how do we

626
00:34:54,881 --> 00:34:57,220
compete with youtube or how do we 
compete with any of these things,

627
00:34:57,580 --> 00:34:59,880
but I think partly what's happening,
it's not just people are going there,

628
00:34:59,900 --> 00:35:01,630
this,
this big monolith.

629
00:35:02,020 --> 00:35:05,740
I think people are actually genuinely 
afraid of what it means to go up against

630
00:35:05,741 --> 00:35:06,574
them.
It's not like it's going to just be a 

631
00:35:07,271 --> 00:35:08,104
hard work situation.
It's like what does it actually mean to 

632
00:35:11,291 --> 00:35:13,870
go up against the world's information 
leader

633
00:35:14,170 --> 00:35:17,810
can compete against the monopoly.
That's the definition of a monopoly.

634
00:35:17,811 --> 00:35:21,020
That's no competition and these.
Some of these companies,

635
00:35:21,110 --> 00:35:21,943
I'm not police and they have captured 
the market so effectively that you 

636
00:35:25,551 --> 00:35:26,384
cannot compete with them and so we 
either have to think about regulating 

637
00:35:30,951 --> 00:35:31,784
them so that they're free and open to 
everybody or I'm breaking up their 

638
00:35:38,340 --> 00:35:41,160
ability to control the market.
I mean,

639
00:35:41,790 --> 00:35:42,623
yeah,
this is the tough part for the 

640
00:35:43,341 --> 00:35:44,540
Libertarian party.
He's like,

641
00:35:44,700 --> 00:35:45,710
no,
not yet.

642
00:35:45,711 --> 00:35:49,610
I do send some being pinned into that.
That kind of answer.

643
00:35:49,730 --> 00:35:50,563
All right,
so we've been talking a bit about the 

644
00:35:51,740 --> 00:35:55,190
tech component of this grand cultural 
war.

645
00:35:55,191 --> 00:35:58,170
That's going on you guys cool that 
you're.

646
00:35:58,210 --> 00:35:59,043
You're a small company or you're funded 
on Patrion which were funded on Pedro 

647
00:36:02,691 --> 00:36:05,960
and it's pretty awesome.
You have people that voluntarily pay you

648
00:36:05,961 --> 00:36:08,330
to support your content and make you 
grow.

649
00:36:08,331 --> 00:36:12,230
I know how validating and rewarding it 
is and all that stuff,

650
00:36:12,470 --> 00:36:15,470
but you find yourself often up against 
the big boys,

651
00:36:15,471 --> 00:36:16,304
right?
Like box funded to hundreds of millions 

652
00:36:18,050 --> 00:36:20,300
of dollars by different things and 
you're being critical of them here.

653
00:36:20,890 --> 00:36:21,723
So it does get me to back to something 
that I started with before about where 

654
00:36:23,991 --> 00:36:27,290
does it come from for you to just be 
brave.

655
00:36:27,650 --> 00:36:29,870
I don't want to.
I don't want to belittle that part of it

656
00:36:29,871 --> 00:36:30,704
that there's a new internet developing 
and I think is people that are doing 

657
00:36:34,311 --> 00:36:36,710
this sort of thing.
It's not these well funded,

658
00:36:37,040 --> 00:36:40,640
well oiled machines that we're watching 
them crumble.

659
00:36:40,641 --> 00:36:42,440
You know,
you sent me this morning,

660
00:36:42,441 --> 00:36:43,274
this thing about boxes ad rev is off by 
15 percent or something and it's like 

661
00:36:46,851 --> 00:36:50,360
we've got slim trim companies and I 
think I really believe that's the future

662
00:36:50,361 --> 00:36:54,920
economically of this as well as in terms
of protecting the ideas.

663
00:36:55,230 --> 00:36:56,650
Yeah.
So we,

664
00:36:56,651 --> 00:36:57,960
uh,
a pretty.

665
00:36:58,020 --> 00:37:00,710
We have a pretty amazing story.
Um,

666
00:37:01,350 --> 00:37:02,183
we,
I started by myself and I ran the 

667
00:37:04,021 --> 00:37:04,854
website for maybe a year or even a year 
and a half before I got my assistant 

668
00:37:11,280 --> 00:37:15,690
editor onboard who's now sort of the 
managing editor and he's extraordinarily

669
00:37:15,691 --> 00:37:18,180
talented,
extremely hardworking.

670
00:37:18,480 --> 00:37:21,080
So I'm very indebted to him for all 
Jonathan,

671
00:37:21,750 --> 00:37:22,680
Jonathan Kay,
um,

672
00:37:22,681 --> 00:37:24,360
and my other editor,
Jamie,

673
00:37:25,020 --> 00:37:28,070
Jamie Palmer,
let's give credit where credit's due.

674
00:37:28,530 --> 00:37:31,650
Um,
am I contribute is also amazing,

675
00:37:32,280 --> 00:37:36,270
but we,
I hate now as of 20,

676
00:37:36,330 --> 00:37:37,830
uh,
2018 September,

677
00:37:37,831 --> 00:37:38,664
we're getting up to 1 million unique 
visitors a month with the staff of old 

678
00:37:45,890 --> 00:37:49,200
part time staff of six or the six or 
seven people.

679
00:37:50,310 --> 00:37:53,400
And we're getting almost a million 
uniques a month.

680
00:37:53,620 --> 00:37:54,453
I am aware of magazines that have a 
budget of millions of dollars that can 

681
00:37:59,421 --> 00:38:03,490
not compete with our traffic and who 
have staffs of stop,

682
00:38:03,560 --> 00:38:06,030
like staffing capacity of 30,
40,

683
00:38:06,031 --> 00:38:07,290
50 people.

684
00:38:07,740 --> 00:38:11,130
So we're extremely lane,
but we're hardworking,

685
00:38:11,700 --> 00:38:15,570
uh,
and we're nimble and innovative.

686
00:38:15,571 --> 00:38:18,210
Like I'm very,
I'm always thinking about innovations to

687
00:38:18,211 --> 00:38:21,240
the business model.
What can we do that's different?

688
00:38:21,241 --> 00:38:22,074
I think just following in the footsteps 
of the old model is probably a recipe 

689
00:38:26,581 --> 00:38:30,840
for failure and I truly believe that 
advertising is on the way out.

690
00:38:30,841 --> 00:38:33,810
I know people can still make some money 
through advertising,

691
00:38:33,811 --> 00:38:34,644
but I think out of it advertising gives 
you a vulnerability because now you see 

692
00:38:40,181 --> 00:38:41,014
these activists trying to like target 
brands if the brand is next to some 

693
00:38:46,511 --> 00:38:51,190
content that activists don't like.
So I think advertising is just,

694
00:38:51,700 --> 00:38:54,970
I think it's bone this vulnerability 
associated with it.

695
00:38:55,070 --> 00:38:55,903
And

696
00:38:55,920 --> 00:38:57,990
is it almost a fake vulnerability 
though?

697
00:38:57,991 --> 00:38:59,400
Because I always think when,
you know,

698
00:38:59,460 --> 00:39:01,590
they always try to boycott Hannity for 
example,

699
00:39:01,620 --> 00:39:04,150
and it's like all of the people trying 
to boycott him,

700
00:39:04,260 --> 00:39:06,510
putting aside whatever he said on that 
given instance,

701
00:39:06,920 --> 00:39:07,753
they don't watch him in the first place 
and yet the advertisers still feel that 

702
00:39:11,551 --> 00:39:12,384
they have to bow to the mob.
And I always find that to be a strange 

703
00:39:14,791 --> 00:39:15,624
thing.
Like there's very few people who like 

704
00:39:17,101 --> 00:39:18,020
Hannity,
who are,

705
00:39:18,120 --> 00:39:21,330
who are so shocked by something he said 
that they want to boycott him.

706
00:39:21,540 --> 00:39:24,300
It's always people who hate him in the 
first place that don't watch.

707
00:39:24,660 --> 00:39:28,560
So there's an odd piece of this that's 
like slightly disconnected from reality.

708
00:39:28,561 --> 00:39:28,850
I think.

709
00:39:28,850 --> 00:39:29,683
Well,
see corporations and companies in 

710
00:39:31,941 --> 00:39:32,774
general are skittish and conservative 
and they want to protect their 

711
00:39:37,311 --> 00:39:38,144
reputations and they,
they're afraid of any kind of 

712
00:39:42,021 --> 00:39:42,854
controversy.
And I agree with you that these 

713
00:39:48,351 --> 00:39:52,700
activists on social media who are 
targeting companies,

714
00:39:52,701 --> 00:39:55,730
they're a tiny,
tiny minority of the population.

715
00:39:55,731 --> 00:39:59,240
Most people don't care or buy into this 
stuff,

716
00:39:59,300 --> 00:40:03,170
but corporations is,
it's probably some pr person who's like,

717
00:40:03,171 --> 00:40:05,240
Whoa,
we don't want any controversy.

718
00:40:05,840 --> 00:40:08,060
Let's detach ourselves.
Um,

719
00:40:09,410 --> 00:40:10,243
but you know,
that kind of timidity and lack of 

720
00:40:16,131 --> 00:40:21,131
strength and lack of spine is not 
something that is part of that.

721
00:40:23,020 --> 00:40:28,020
So we very much a conscious of if we 
ever get mobbed and we do get mobbed,

722
00:40:29,810 --> 00:40:32,690
sometimes we don't apologize.
We don't,

723
00:40:33,230 --> 00:40:34,063
we don't,
we don't give into the heckler's veto 

724
00:40:36,111 --> 00:40:37,540
basically.
Yeah,

725
00:40:37,720 --> 00:40:38,311
I know.
I,

726
00:40:38,311 --> 00:40:41,900
I really think it's important for um,
uh,

727
00:40:42,170 --> 00:40:43,003
corporations,
company lead is anyone in a latest 

728
00:40:45,140 --> 00:40:45,973
leadership position to grow a spine in 
the era of social media and to not take 

729
00:40:52,700 --> 00:40:54,830
any of this outrage seriously.

730
00:40:55,330 --> 00:40:56,160
Yeah.
Yeah.

731
00:40:56,160 --> 00:40:58,440
Not Take it seriously or not take it.
I mean,

732
00:40:58,441 --> 00:40:59,274
I think we've sort of,
we have to take it seriously because it 

733
00:41:00,721 --> 00:41:01,554
is sort of infecting a lot of society,
but maybe not take it as if it's 

734
00:41:05,130 --> 00:41:07,620
necessarily right,
just because it's outrageous.

735
00:41:07,621 --> 00:41:08,350
Is that fair?

736
00:41:08,350 --> 00:41:08,990
Yeah.
I,

737
00:41:08,990 --> 00:41:09,823
you can say the recent example,
an editor of the New York review of 

738
00:41:14,411 --> 00:41:19,411
books in Borama was fired because he 
published an article a by Canadian radio

739
00:41:23,231 --> 00:41:27,580
journalists who was credibly accused of 
many cases of sexual assault.

740
00:41:27,581 --> 00:41:29,760
And I think the radio journalists was 
like,

741
00:41:30,740 --> 00:41:35,740
he's a bad dude,
but the editor was sacked for publishing

742
00:41:37,371 --> 00:41:41,300
his article within the space of two days
or something.

743
00:41:41,301 --> 00:41:42,134
So there was a social media outrage 
phenomenon and it's all wrapped up with 

744
00:41:47,451 --> 00:41:50,750
me too.
And then he's just fired just like that.

745
00:41:50,900 --> 00:41:52,280
And it's like,
okay,

746
00:41:53,330 --> 00:41:55,720
take some time out to consider it.
Like,

747
00:41:55,760 --> 00:41:59,480
listen to the feedback from your readers
or from people on social media.

748
00:41:59,481 --> 00:42:00,314
But when did we start making decisions?
So suddenly these important decisions 

749
00:42:04,161 --> 00:42:04,994
that affect people's livelihoods,
that's what I find astonishing that 

750
00:42:09,351 --> 00:42:10,184
people in leadership positions just sort
of throw all caution to the wind and 

751
00:42:14,451 --> 00:42:14,991
just say,
okay,

752
00:42:14,991 --> 00:42:18,080
we're going to sap someone because some 
people on twitter on happy.

753
00:42:18,150 --> 00:42:18,983
Yeah.
And also the guilt by association part 

754
00:42:20,401 --> 00:42:20,941
of this,
right?

755
00:42:20,941 --> 00:42:21,774
I mean it's,
it's possible for a slim trim operation 

756
00:42:23,341 --> 00:42:25,140
that you have,
you might find out in 10 years,

757
00:42:25,141 --> 00:42:27,450
you might find out that one of the guys 
you're working with now,

758
00:42:27,451 --> 00:42:28,284
three years ago did did something awful.
And then they'll use that to try to tar 

759
00:42:32,641 --> 00:42:33,474
you and the danger of that or that you 
sat down with somebody and now we can 

760
00:42:37,291 --> 00:42:40,230
put out a chart that links that person 
did this person to that person.

761
00:42:40,231 --> 00:42:41,064
This one,
we're in an age of the Internet within 

762
00:42:42,361 --> 00:42:43,194
six steps.
You can link anybody to Kevin Bacon or 

763
00:42:44,761 --> 00:42:45,571
Barack Obama.
Right?

764
00:42:45,571 --> 00:42:46,380
It's like,
it's,

765
00:42:46,380 --> 00:42:47,610
it's pretty ridiculous.

766
00:42:47,720 --> 00:42:52,720
Yeah.
The guilt by association is it for.

767
00:42:53,270 --> 00:42:54,410
I mean,
it's a fallacy,

768
00:42:54,411 --> 00:42:55,244
but it is powerful and we,
we do find ourselves tainted and it's 

769
00:43:00,381 --> 00:43:01,214
tricky and I think we have to.
Every situation we have to judge on a 

770
00:43:04,581 --> 00:43:07,280
case by case basis.
Um,

771
00:43:07,860 --> 00:43:09,560
and,
and you probably right,

772
00:43:09,561 --> 00:43:14,561
it probably is going to happen,
but I trust my readers and um,

773
00:43:15,210 --> 00:43:17,720
I,
I feel like they know who we are.

774
00:43:17,930 --> 00:43:18,763
They know they're aware of our values 
and they can make the appropriate 

775
00:43:22,611 --> 00:43:24,200
judgments at the time.

776
00:43:24,270 --> 00:43:24,970
Yeah.
So.

777
00:43:24,970 --> 00:43:25,803
All right.
So even though we've spent most of the 

778
00:43:27,580 --> 00:43:29,140
time here and most of the things that 
you guys are writing,

779
00:43:29,141 --> 00:43:29,974
talking about what sort of going on with
the modern left and frustrations that 

780
00:43:32,621 --> 00:43:34,210
everyone knows that I have with these 
guys.

781
00:43:34,620 --> 00:43:35,453
Um,
let's talk about the parts of their 

782
00:43:36,191 --> 00:43:37,024
right,
that,

783
00:43:37,040 --> 00:43:37,873
that you actually find a scary or 
untoward or whatever you want to call 

784
00:43:41,861 --> 00:43:42,694
it.
What do you think the alt right is at 

785
00:43:45,371 --> 00:43:46,204
this point?
Like if someone says you give me the 

786
00:43:48,731 --> 00:43:49,810
definition of,
all right,

787
00:43:49,811 --> 00:43:51,310
what does that even mean to you at this 
point?

788
00:43:51,940 --> 00:43:52,611
Uh,
well,

789
00:43:52,611 --> 00:43:57,611
I consider them to be the white 
nationalists that uh,

790
00:43:58,610 --> 00:44:03,610
um,
that one in ethno state and they,

791
00:44:03,961 --> 00:44:07,640
they're pretty morally repugnant and 
that's pretty scary.

792
00:44:07,641 --> 00:44:11,690
And they engage in some,
in quite vicious trolling.

793
00:44:12,140 --> 00:44:15,100
They send death threats.
I'm the journalist.

794
00:44:15,101 --> 00:44:16,460
Cathy Young,
for example,

795
00:44:16,461 --> 00:44:17,294
was one of the first people to write an 
article criticizing the bigotry of the 

796
00:44:21,921 --> 00:44:25,340
alt right and she had a death threat 
called into her home.

797
00:44:26,480 --> 00:44:28,370
And uh,
the,

798
00:44:28,400 --> 00:44:30,110
the,
the pretty scary.

799
00:44:30,111 --> 00:44:31,770
But I think there are a small group.

800
00:44:31,930 --> 00:44:34,450
Yeah.
How are we able to quantify that?

801
00:44:34,451 --> 00:44:35,284
Because that's one of the things that 
like I think people are just very 

802
00:44:37,271 --> 00:44:38,104
confused that they're making it seem.
The media makes it seem because they 

803
00:44:40,391 --> 00:44:44,500
call everyone all right or far right,
that there's this massive group.

804
00:44:44,770 --> 00:44:46,990
I can only talk about this in an 
American Lens,

805
00:44:46,991 --> 00:44:48,490
but maybe maybe it's a little different 
Australia,

806
00:44:48,491 --> 00:44:53,050
but that there's this massive group of 
white nationalists who are coming for to

807
00:44:53,051 --> 00:44:55,090
turn America into some sort of ethno 
state.

808
00:44:55,360 --> 00:44:56,193
Now I'm not saying there aren't racists.
Of course they are racist and of course 

809
00:44:58,811 --> 00:45:01,600
there are bad people and people using 
these tactics,

810
00:45:01,990 --> 00:45:03,740
but I believe it's just a tiny sliver 
and then.

811
00:45:03,741 --> 00:45:04,574
And then on top of that you have old 
sort of the meme makers and the shit 

812
00:45:06,821 --> 00:45:10,450
posters and the rest of those guys.
You may not like what they do,

813
00:45:10,451 --> 00:45:11,284
but they're not there.
They're having fun in their eyes and a 

814
00:45:13,451 --> 00:45:15,760
lot of ways they're not just the evil 
racist.

815
00:45:17,320 --> 00:45:22,320
I think a mistake was made back when 
Milo was around and I think he.

816
00:45:25,180 --> 00:45:26,013
He started using the term alt right and 
he might not have been aware of where 

817
00:45:30,611 --> 00:45:31,444
that term originated and it actually 
originated with the white nationalists 

818
00:45:35,950 --> 00:45:36,930
and um,

819
00:45:37,070 --> 00:45:37,903
do you think Milo was using it more in 
the way that I just laid it out or just 

820
00:45:40,551 --> 00:45:45,140
sort of these shit posting something 
without acknowledging the other person.

821
00:45:45,210 --> 00:45:49,560
I don't know if he was aware of where 
the term originated or not,

822
00:45:50,130 --> 00:45:50,963
but it was a huge era,
an era for people who are adjusting to 

823
00:45:57,780 --> 00:45:58,613
shit posting.
It was a huge era era for them to use 

824
00:46:01,351 --> 00:46:04,720
that label for themselves because unless
you're,

825
00:46:04,770 --> 00:46:07,740
what in my view,
unless you are a white nationalist,

826
00:46:07,741 --> 00:46:09,920
you are not an,
you're not an old writer.

827
00:46:09,990 --> 00:46:11,160
I mean they had,
they,

828
00:46:11,570 --> 00:46:15,600
the label I think came about in 2007 and
they,

829
00:46:15,890 --> 00:46:20,640
I think it was Richard Spencer who 
created the right journal or something.

830
00:46:20,641 --> 00:46:21,474
So it was a big mistake for people who 
just want to have fun online and he 

831
00:46:27,061 --> 00:46:28,070
wants to,
um,

832
00:46:28,860 --> 00:46:29,693
you know,
just like push back against some of 

833
00:46:32,641 --> 00:46:33,474
these pc orthodoxies.
That was a huge mistake for them to use 

834
00:46:35,731 --> 00:46:36,564
the term for themselves and that's given
license now for critics to apply the 

835
00:46:42,571 --> 00:46:47,571
term on everybody who,
who pushes back against pc dogmas.

836
00:46:47,870 --> 00:46:49,680
Um,
and that's really unfortunate,

837
00:46:50,400 --> 00:46:51,233
but you know,
we have to just say it over and over 

838
00:46:53,701 --> 00:46:57,450
again,
like these people are repugnant and we,

839
00:46:57,660 --> 00:47:01,200
we don't want to have anything to do 
with their ideology.

840
00:47:01,500 --> 00:47:04,920
The ideology is all ideologies 
authoritarian.

841
00:47:05,520 --> 00:47:07,020
It's racist.
It's,

842
00:47:07,021 --> 00:47:08,120
um,
and,

843
00:47:08,180 --> 00:47:12,170
and they engage in very scary vicious 
behaviors.

844
00:47:12,500 --> 00:47:14,190
Yeah.
So absolutely.

845
00:47:14,191 --> 00:47:17,040
I will coast side all of that.
Just for the record,

846
00:47:17,041 --> 00:47:17,874
of course,
this is a repugnant ideology and these 

847
00:47:19,651 --> 00:47:24,480
people are racist and all those things.
So I'm less concerned about that because

848
00:47:24,481 --> 00:47:29,481
I do believe it's a small sliver that 
doesn't have real institutional power.

849
00:47:29,590 --> 00:47:30,423
Now maybe it's going to gain some.
And I think there's evidence that at 

850
00:47:32,261 --> 00:47:34,960
least in eastern Europe that some of 
these ideas,

851
00:47:34,990 --> 00:47:35,823
partly as a pushback to the immigration 
immigration problems that maybe it is 

852
00:47:38,471 --> 00:47:40,730
gaining some power.
Um,

853
00:47:41,200 --> 00:47:45,010
but are you concerned that it has a 
bigger institutional power?

854
00:47:45,011 --> 00:47:45,844
Because I think the stuff that we're 
often talking about is because we're 

855
00:47:48,191 --> 00:47:51,790
worried about institutional power and 
structural power,

856
00:47:51,820 --> 00:47:55,090
not just that they were mean and bad 
people out there,

857
00:47:55,091 --> 00:47:57,810
which yes,
there are bad people out there and there

858
00:47:57,811 --> 00:48:00,220
will always be mean and bad people out 
there.

859
00:48:00,360 --> 00:48:01,193
Yeah.
Because my background is so recently in 

860
00:48:04,741 --> 00:48:05,574
academia,
I focus a lot on universities and the 

861
00:48:07,741 --> 00:48:10,590
ideologies that are popular within the 
university.

862
00:48:10,591 --> 00:48:15,591
So that makes me focus on left wing 
ideology such as critical theory,

863
00:48:17,041 --> 00:48:20,970
poststructuralism and Marxism.
Um,

864
00:48:21,480 --> 00:48:22,313
if I was in a different context,
I might focus more on right wing 

865
00:48:26,281 --> 00:48:30,290
ideologies and the effect that they have
on institutions and I'm sure.

866
00:48:30,390 --> 00:48:32,000
So you're given a little nod to the 
postmodern.

867
00:48:32,001 --> 00:48:32,834
Is there because you're showing that 
your own bias is a little part of how 

868
00:48:35,581 --> 00:48:36,050
you look at things?

869
00:48:36,050 --> 00:48:36,651
Yeah,
yeah,

870
00:48:36,651 --> 00:48:37,640
absolutely.
Yeah.

871
00:48:37,730 --> 00:48:42,730
Yeah.
I'm sure if I was closer to institutions

872
00:48:42,861 --> 00:48:45,650
that have more of a right wing 
ideological influence,

873
00:48:45,651 --> 00:48:49,580
our would be criticizing that more,
criticizing those influences more.

874
00:48:50,170 --> 00:48:51,003
I'm being Australian is a in Australia,
out out conservative or right wing 

875
00:49:02,570 --> 00:49:05,660
ideologies are quite different to 
America.

876
00:49:05,661 --> 00:49:10,661
So you probably already know this,
but we have universal healthcare,

877
00:49:11,090 --> 00:49:14,480
we have gun control,
we have a welfare state.

878
00:49:15,080 --> 00:49:18,530
So if I lived in a country where we 
didn't have those things,

879
00:49:18,830 --> 00:49:21,830
I would probably be advocating for them.
Um,

880
00:49:22,700 --> 00:49:23,533
but you know,
a lot of this is context specific and 

881
00:49:26,421 --> 00:49:27,254
you criticize what you know.
So a part of the reason why I criticize 

882
00:49:30,621 --> 00:49:31,930
the,
um,

883
00:49:31,931 --> 00:49:34,690
what Jordan Peterson calls,
um,

884
00:49:35,090 --> 00:49:38,720
postmodern near Marxism is because I've 
experienced it,

885
00:49:38,721 --> 00:49:41,420
I see it all the time in Aca,
in academia,

886
00:49:41,630 --> 00:49:43,280
academic settings,
and,

887
00:49:43,910 --> 00:49:46,250
um,
I worry about the impact that,

888
00:49:46,251 --> 00:49:50,420
that ideology is having on media,
the law,

889
00:49:51,070 --> 00:49:53,720
um,
and just the broader culture.

890
00:49:53,940 --> 00:49:54,773
Yeah.
Are you hopeful that some of the good 

891
00:49:57,361 --> 00:50:00,600
ideas that we've talked about here are 
going to win out?

892
00:50:00,680 --> 00:50:03,990
That that seems to be one of the biggest
questions I get at public events now.

893
00:50:03,991 --> 00:50:08,370
Like I think there is a sense that we've
woken up a certain amount of people,

894
00:50:08,371 --> 00:50:09,204
you know,
this Peterson towards selling out every 

895
00:50:10,651 --> 00:50:11,484
theater.
Thousands and thousands of people 

896
00:50:12,451 --> 00:50:14,880
literally all over the world will be in 
February,

897
00:50:15,110 --> 00:50:17,520
uh,
in Australia in February.

898
00:50:19,650 --> 00:50:20,483
But I think there's still a concern of 
like how much worse before it gets 

899
00:50:24,451 --> 00:50:24,960
better.

900
00:50:24,960 --> 00:50:27,150
Yeah.
And that's a question people,

901
00:50:27,470 --> 00:50:29,180
me as well,
and I the.

902
00:50:29,720 --> 00:50:33,110
I mean I don't have an oracle,
I can't see the future.

903
00:50:33,111 --> 00:50:38,111
And all I can say is that I'm doing my 
very best to counter these bad ideas and

904
00:50:38,630 --> 00:50:42,650
that it's,
it's actually anybody who's concerned.

905
00:50:42,651 --> 00:50:43,484
I mean they have some responsibility and
I think everybody should think about 

906
00:50:48,471 --> 00:50:51,020
sharing the risk.
So,

907
00:50:51,140 --> 00:50:51,840
you know,

908
00:50:51,840 --> 00:50:53,700
Charlie truly

909
00:50:53,830 --> 00:50:54,670
right?
Yeah.

910
00:50:55,150 --> 00:50:55,983
You know,
when Charlie Hebdo happened and the 

911
00:50:58,271 --> 00:51:02,560
mainstream media in Europe and the UK 
and America,

912
00:51:02,561 --> 00:51:06,010
I think didn't want to publish that 
cartoon of Muhammad,

913
00:51:06,011 --> 00:51:10,930
which got those men and women killed.
Douglas Murray came out and said,

914
00:51:11,520 --> 00:51:13,370
do it.
Share the risk.

915
00:51:13,420 --> 00:51:16,930
That's when I came aware of one of his 
best moments is incredible.

916
00:51:16,931 --> 00:51:17,490
It's on youtube.

917
00:51:17,490 --> 00:51:19,370
Yeah.
That was a,

918
00:51:19,480 --> 00:51:20,313
uh,
something that impacted me a lot as 

919
00:51:22,161 --> 00:51:24,700
well.
And you know,

920
00:51:25,010 --> 00:51:28,640
anyone who's concerned about the way our
culture,

921
00:51:28,770 --> 00:51:33,770
broader western culture is headed,
needs to think deeply about how they can

922
00:51:35,270 --> 00:51:38,120
make a little bit of difference by 
sharing the risk.

923
00:51:38,180 --> 00:51:39,013
Just speaking honestly,
in conversations with friends speaking 

924
00:51:42,081 --> 00:51:47,081
honestly and openly in the workplace,
normalizing conversations and um,

925
00:51:48,740 --> 00:51:49,460
yeah,
just,

926
00:51:49,460 --> 00:51:51,050
just taking on a little bit of risk,

927
00:51:51,450 --> 00:51:54,630
what does that tell you about the slide 
that has occurred in the West?

928
00:51:54,660 --> 00:51:55,493
Is this just a,
is it an infection of success or 

929
00:52:00,811 --> 00:52:01,644
something that we could be so successful
that even taking a little risk seems 

930
00:52:06,270 --> 00:52:07,320
awful to people.

931
00:52:07,640 --> 00:52:08,570
He,
he,

932
00:52:08,600 --> 00:52:13,280
he runs a very conformist and most 
people a cow.

933
00:52:13,281 --> 00:52:15,440
It's unfortunately,
um,

934
00:52:15,570 --> 00:52:20,370
and a lot of what we're talking about,
these bad ideas that are being promoted.

935
00:52:20,710 --> 00:52:24,000
I only promoted by a tiny,
tiny minority of people,

936
00:52:24,001 --> 00:52:27,810
but they're very noisy,
loud and aggressive.

937
00:52:28,890 --> 00:52:29,723
And the problem is simply the silent 
majority not being feeling too 

938
00:52:36,421 --> 00:52:41,421
intimidated to sort of push back.
And if we can encourage those who are in

939
00:52:42,331 --> 00:52:44,730
the silent majority to push back against
it,

940
00:52:44,740 --> 00:52:48,150
logs on both sides,
both the hard right and the hard left.

941
00:52:48,810 --> 00:52:49,940
Um,
I think,

942
00:52:49,950 --> 00:52:53,100
oh,
create a much healthier civil society,

943
00:52:53,610 --> 00:52:57,540
but it's about empowering the moderates 
to speak freely,

944
00:52:57,541 --> 00:52:59,350
speak openly and,
and,

945
00:52:59,550 --> 00:53:04,110
and not feel afraid,
like ashamed of the moderate views.

946
00:53:04,210 --> 00:53:05,043
Right?
They've also turned the words like 

947
00:53:06,611 --> 00:53:09,580
civility and moderation or thought of as
bad.

948
00:53:09,581 --> 00:53:14,020
Now you're a fence sitter.
You don't want to murder half the people

949
00:53:14,021 --> 00:53:16,080
you know,
you're not ost from avengers,

950
00:53:16,090 --> 00:53:16,400
right?

951
00:53:16,400 --> 00:53:20,930
Yeah.
I mean those people,

952
00:53:20,990 --> 00:53:23,410
that people who are gay,
that civility is,

953
00:53:23,450 --> 00:53:26,250
is a bad thing.
And um,

954
00:53:26,500 --> 00:53:29,200
we see a lot of this now by the way,
that civility is a bad thing.

955
00:53:29,260 --> 00:53:30,360
A lot of pieces about.

956
00:53:31,200 --> 00:53:34,800
Well,
I would argue that some unrepresentative

957
00:53:34,830 --> 00:53:35,663
of the broader population,
I know that media and certain parts of 

958
00:53:40,501 --> 00:53:41,334
media and universities have been 
captured by cultists in a way and they 

959
00:53:46,111 --> 00:53:46,944
have these crazy ideas.
But I would be careful about 

960
00:53:50,131 --> 00:53:50,964
generalizing those ideas to the broader 
population because I think most normal 

961
00:53:55,081 --> 00:53:57,180
people are pretty chill.
I mean,

962
00:53:57,181 --> 00:53:58,014
I haven't.
It's been not enough time in your 

963
00:53:58,831 --> 00:54:00,420
country to,
to know.

964
00:54:00,560 --> 00:54:00,911
No,
I,

965
00:54:00,911 --> 00:54:02,210
I think you are right.
I mean,

966
00:54:02,211 --> 00:54:03,044
I'm out there going across the country 
realizing that there are so many just 

967
00:54:06,380 --> 00:54:07,213
decent people that hysterics and the way
that I said earlier about how social 

968
00:54:11,451 --> 00:54:13,680
media has leaked into reality or 
something.

969
00:54:13,940 --> 00:54:14,773
It's making everyone feel crazy.
But I'm meeting these incredible people 

970
00:54:17,781 --> 00:54:18,614
all over the country.
They just want to live and let live and 

971
00:54:21,561 --> 00:54:22,394
yeah,
maybe I don't know your feelings on 

972
00:54:23,781 --> 00:54:25,220
abortion for example.
Maybe we agree.

973
00:54:25,221 --> 00:54:26,054
Maybe we don't.
It just seems that actually seems 

974
00:54:28,161 --> 00:54:30,380
irrelevant at the moment.
Yeah.

975
00:54:30,560 --> 00:54:31,393
That,
that sort of says something we touched 

976
00:54:32,931 --> 00:54:35,450
on briefly right before we started that 
politics.

977
00:54:35,690 --> 00:54:40,160
I was saying how I'm not that interested
in politics per se at the moment,

978
00:54:40,190 --> 00:54:41,023
even though this is all framed within a 
political lens that I'm much more 

979
00:54:44,091 --> 00:54:44,924
interested in culture.
Is that how you feel about this and was 

980
00:54:48,770 --> 00:54:51,350
that always how you felt about this or 
it has something shifted?

981
00:54:51,780 --> 00:54:52,613
Definitely.
I've never been particularly interested 

982
00:54:54,660 --> 00:54:55,493
in partisan politics,
but I think that politics is downstream 

983
00:54:59,641 --> 00:55:00,474
of culture.
So the ideas that are popular within a 

984
00:55:02,911 --> 00:55:06,420
culture then get reflected in your 
politics.

985
00:55:06,480 --> 00:55:07,313
So if you want politics to be a certain 
way and to be a bit healthier and less 

986
00:55:12,961 --> 00:55:13,794
dysfunctional,
you want to impact the culture first 

987
00:55:17,130 --> 00:55:19,920
because culture is bigger than politics.

988
00:55:20,030 --> 00:55:20,863
Yeah.
Is there a danger that we're just in 

989
00:55:22,071 --> 00:55:25,730
this like locked culture war now so that
our politics can never get better?

990
00:55:25,731 --> 00:55:26,564
Like we sort of have this affair 
authoritarian leftism and now we've got 

991
00:55:29,691 --> 00:55:30,650
trump.
These are,

992
00:55:30,680 --> 00:55:32,660
these are the cultural fights that we're
having now.

993
00:55:32,661 --> 00:55:34,370
There's a couple of us in this spot.
Right?

994
00:55:34,750 --> 00:55:35,583
But like that,
it's all politics is going to come from 

995
00:55:37,461 --> 00:55:38,294
those two things at the moment.
The politics sort of is almost 

996
00:55:41,571 --> 00:55:43,400
irreparably damaged.

997
00:55:43,470 --> 00:55:44,490
Yeah.
Look,

998
00:55:44,540 --> 00:55:48,270
I don't know what the future holds for 
the United States.

999
00:55:48,300 --> 00:55:49,133
From an outsider looking in it,
it does look quite scary that the level 

1000
00:55:54,271 --> 00:55:58,020
of tribalism that's,
that seems a parent.

1001
00:55:58,140 --> 00:56:03,140
Just the amount of hate and distrust 
that each side has for the other.

1002
00:56:04,350 --> 00:56:06,540
It's quite scary.
Um,

1003
00:56:07,020 --> 00:56:11,520
I just hope that if the worst happens to
the United States,

1004
00:56:11,521 --> 00:56:12,354
we will always have.
We will have outposts where western 

1005
00:56:16,651 --> 00:56:20,550
civilization survives and thrives.
New Zealand,

1006
00:56:20,610 --> 00:56:21,443
Australia.

1007
00:56:22,900 --> 00:56:24,520
Basically going back to what I said at 
the beginning,

1008
00:56:24,521 --> 00:56:27,630
it's good to be surrounded by water will
be,

1009
00:56:27,640 --> 00:56:30,970
we will be an outpost and will kill the 
extra moving your house.

1010
00:56:32,870 --> 00:56:35,310
We're going to keep you that much.
A couple of feet work.

1011
00:56:35,380 --> 00:56:38,110
Yeah.
A lot of people are going to New Zealand

1012
00:56:38,200 --> 00:56:40,810
and buying houses there in case the 
worst happens.

1013
00:56:40,940 --> 00:56:42,770
Oh God,
I don't want to end on this terrible.

1014
00:56:43,420 --> 00:56:44,900
Wait,
we've got to bring this back,

1015
00:56:45,200 --> 00:56:47,210
but all right,
so there's concern about that.

1016
00:56:47,430 --> 00:56:48,410
Of course,
like right,

1017
00:56:48,411 --> 00:56:49,244
if you want to go down that rabbit hole,
you could look at all of these ideas 

1018
00:56:52,191 --> 00:56:53,024
that I truly think are the ideas that 
could unravel western society and free 

1019
00:56:56,631 --> 00:56:59,150
thought and all of those things.
That's why I talk about them so much,

1020
00:56:59,750 --> 00:57:02,320
but there is a counter and that's what 
we got to keep doing,

1021
00:57:02,350 --> 00:57:03,210
so bring it,
bring it,

1022
00:57:03,230 --> 00:57:04,063
bring it home on a positive note please.
Before people start buying real estate 

1023
00:57:06,261 --> 00:57:09,750
in New Zealand or you were just trying 
to help them market in Australia there.

1024
00:57:10,460 --> 00:57:11,293
No,
we don't need any help in the housing 

1025
00:57:12,051 --> 00:57:12,930
market.
We.

1026
00:57:13,070 --> 00:57:13,903
I'm optimistic because I see the amount,
the positive reception that I get 

1027
00:57:19,371 --> 00:57:23,480
through quizlet,
our audience grows every month.

1028
00:57:23,900 --> 00:57:28,700
I'm more and more people are 
contributing to our website,

1029
00:57:28,701 --> 00:57:31,790
feeling brave enough to write their 
thoughts down and send it through,

1030
00:57:32,060 --> 00:57:37,060
and the thing is every individual has 
the power to change the world of ideas.

1031
00:57:38,870 --> 00:57:42,890
If you've got an idea and you can 
articulate it and write it down and send

1032
00:57:42,891 --> 00:57:47,180
it in or articulated it in in some other
fashion,

1033
00:57:47,970 --> 00:57:52,970
you do have the power to transform and 
impact this,

1034
00:57:53,570 --> 00:57:56,330
this culture,
and to make a huge difference.

1035
00:57:56,510 --> 00:57:58,760
So that's,
that's incredible.

1036
00:57:58,761 --> 00:58:01,040
And that makes me feel happy and 
optimistic.

1037
00:58:01,220 --> 00:58:02,980
All right.
That is how we can add.

1038
00:58:03,120 --> 00:58:06,790
We can end it on the seasteading.
We're going to water world kind of thing

1039
00:58:06,820 --> 00:58:07,653
for more on Claire's work.
Check out [inaudible] dot com and they 

1040
00:58:10,121 --> 00:58:11,620
are also on Patriot.

