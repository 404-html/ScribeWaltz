WEBVTT

1
00:00:09.410 --> 00:00:11.780
Hi everyone.
Uh,
I'm,
I'm Jamie,

2
00:00:11.810 --> 00:00:16.790
Jamie Jones and I'm a professor in earth system science at Stanford.
Uh,

3
00:00:16.791 --> 00:00:21.320
I'm actually trained as an anthropologist,
but I sit in the school of Earth,

4
00:00:21.350 --> 00:00:24.800
energy and the environment at Stanford in the department of Earth System
Science.

5
00:00:25.640 --> 00:00:30.640
So today I'm going to talk to you about some recent interests I've had in uh,

6
00:00:32.140 --> 00:00:36.440
in applying evolutionary and ecological ideas to economics and decision theory.

7
00:00:37.070 --> 00:00:37.760
Um,

8
00:00:37.760 --> 00:00:42.260
this interest was peaked by my attempt to understand the peculiarities of the

9
00:00:42.261 --> 00:00:45.620
human life cycle and our life cycles are really peculiar.

10
00:00:45.650 --> 00:00:50.630
I can assure you in a broad comparative context,
they're really kind of weird.
Um,

11
00:00:51.500 --> 00:00:56.060
and to understand the reason people in subsistence economies pursue particular

12
00:00:56.061 --> 00:00:58.250
types of,
of resources,

13
00:00:58.251 --> 00:01:01.220
pray and a forge food and that sort of thing.

14
00:01:01.670 --> 00:01:05.570
And so I'm going to guide you through a big picture view of some fairly

15
00:01:05.571 --> 00:01:10.130
technical fields today that include population biology,
uh,

16
00:01:10.160 --> 00:01:14.450
decision theory,
a bit of economics,
both classical and,
and,
uh,
behavioral.

17
00:01:14.810 --> 00:01:17.300
But I think the ultimate message is pretty straight forward.

18
00:01:17.420 --> 00:01:21.590
And the thing that sort of broad picture that motivates me is understanding how

19
00:01:22.490 --> 00:01:26.720
something like this,
which was,
uh,
an artist's reconstruction of,

20
00:01:26.780 --> 00:01:28.850
of Australopithecus Afarensis,

21
00:01:29.210 --> 00:01:34.210
which is essentially a one meter tall chimpanzee like thing that walked up,

22
00:01:35.331 --> 00:01:39.530
right?
Right.
It's got a 300 cubic centimeter brain,

23
00:01:39.620 --> 00:01:44.620
so about a quarter of the size of maybe a little less than a contemporary human,

24
00:01:45.470 --> 00:01:50.360
a very sexually dimorphic.
The males are much bigger than females.

25
00:01:50.460 --> 00:01:54.050
Uh,
they had enormous,
a cheek teeth,
uh,

26
00:01:54.080 --> 00:01:58.390
for meeting and very tough diet.
Um,
and as I said,
they're,

27
00:01:58.391 --> 00:02:00.920
they're really tiny.
These guys,
uh,

28
00:02:00.950 --> 00:02:05.210
lived about three and a half million years ago in east Africa and

29
00:02:06.780 --> 00:02:11.390
transitioned in,
this probably doesn't look that different,
I guess.
Um,
but it is,

30
00:02:11.391 --> 00:02:15.350
it's fundamentally different in about one and a half,
1.8 million years ago,

31
00:02:15.710 --> 00:02:19.550
and this critter called Homo ergaster.
Uh,

32
00:02:19.580 --> 00:02:23.960
for my purposes is,
is effectively modern.
You've got a large body size,

33
00:02:23.961 --> 00:02:28.700
so within the normal range of contemporary human variation,

34
00:02:29.030 --> 00:02:32.780
you've got body proportions that looked very much like people living in the

35
00:02:32.781 --> 00:02:36.500
tropics.
Today,
you've got a great reduction in sexual size.

36
00:02:36.501 --> 00:02:38.660
Dimorphism so that males and females are,

37
00:02:38.661 --> 00:02:42.140
are similarly proportion to how they are today relative to each other.

38
00:02:42.530 --> 00:02:45.500
And you've got big brains.
They're not,
they're smaller than modern,

39
00:02:45.501 --> 00:02:50.240
but they're actually within the range of variation on the low end of variation

40
00:02:50.241 --> 00:02:52.940
of contemporary humans.
Uh,

41
00:02:52.990 --> 00:02:57.990
Homo ergaster sometimes called a African homo erectus is the first of our to to

42
00:02:59.921 --> 00:03:04.630
leave Africa and to colonize the rest of the world.
Um,

43
00:03:04.690 --> 00:03:09.370
and it did so around,
you know,
1.8 million years ago,

44
00:03:09.820 --> 00:03:13.300
give or take a little bit.
And so my question is,

45
00:03:14.050 --> 00:03:16.210
how is it that a population of bipedal apes,
you know,

46
00:03:16.211 --> 00:03:20.050
they're not very impressive looking,
right?
Kind,
Kinda like we aren't,
right?

47
00:03:20.390 --> 00:03:23.530
We don't have big weapons,
we don't have antlers or horns,

48
00:03:23.531 --> 00:03:26.150
we don't have big teeth.
We don't have,
uh,

49
00:03:27.730 --> 00:03:32.560
the sort of ferocity built into us.
We have some cleverness maybe,
uh,

50
00:03:32.561 --> 00:03:34.690
but how is it that in less than 2 million years,

51
00:03:34.691 --> 00:03:39.460
which is a very rapid period of time in the broader span of evolution,

52
00:03:39.461 --> 00:03:44.461
how is it that we went from this small population of African apes,

53
00:03:44.770 --> 00:03:45.790
bipedal apes,

54
00:03:46.150 --> 00:03:50.590
and I've grown to a size of 7 billion souls in,

55
00:03:50.800 --> 00:03:54.490
as I say,
less than 1.8 million years.
Okay.

56
00:03:54.491 --> 00:03:59.440
And we've colonized and come to dominate nearly every terrestrial biome,

57
00:03:59.710 --> 00:03:59.951
right?

58
00:03:59.951 --> 00:04:04.170
It's just a picture of making the desert green and the Arabian peninsula as a,

59
00:04:04.171 --> 00:04:08.530
as a sort of indicator of the extent to which we really dominate,
uh,

60
00:04:09.070 --> 00:04:10.150
uh,
the world,

61
00:04:10.151 --> 00:04:14.710
30 to 40% of net primary productivity is captured by human actions,

62
00:04:14.770 --> 00:04:15.603
right?

63
00:04:15.640 --> 00:04:20.050
So the phenomenal growth of our species in this very short period of time

64
00:04:20.460 --> 00:04:24.580
suggest that our ancestors on average,
must've made pretty good decisions,
right?

65
00:04:24.610 --> 00:04:29.450
Because the decisions they made led them to increase,
uh,

66
00:04:29.470 --> 00:04:31.180
in,
in pretty great numbers.

67
00:04:32.290 --> 00:04:36.400
But there's a torrent of work in psychology and economics represented by just a

68
00:04:36.401 --> 00:04:40.000
few sample publications here of,
of semi popular trade books.

69
00:04:40.600 --> 00:04:44.290
So just a decision made,
the decision making software that our brains run,

70
00:04:44.650 --> 00:04:49.040
which is presumably essential to our,
our ecological domination,
uh,

71
00:04:49.060 --> 00:04:52.390
is profoundly flawed.
That in a,
in a word we're irrational.

72
00:04:53.440 --> 00:04:57.460
How's it possible that a species apparently so defective and its ability to

73
00:04:57.461 --> 00:05:01.890
generate sound decisions can be so incredibly evolutionary,
evolutionary,

74
00:05:01.920 --> 00:05:06.460
least successful?
Uh,
I'll just say as a relative outsider,

75
00:05:06.690 --> 00:05:10.990
um,
I'll make this observation about this particular body of work that I'm

76
00:05:10.991 --> 00:05:14.890
discussing here.
Uh,
in the slide.
There are lots of anomalies.

77
00:05:14.891 --> 00:05:19.360
Like we see these things that don't make sense from the way we sort of think

78
00:05:19.361 --> 00:05:22.750
about the way people should make decisions.
Um,
and,

79
00:05:22.780 --> 00:05:26.230
and you can write whole books on this,
like lots of books on this,

80
00:05:26.560 --> 00:05:28.750
but they're generally unconnected and the whole area,

81
00:05:28.751 --> 00:05:33.490
it seems to lack of sort of unifying theory.
I'm going to humbly submit that.

82
00:05:33.491 --> 00:05:37.600
I think that evolution can help us provide some of the theory that brings

83
00:05:37.601 --> 00:05:39.100
together some of these anomalies.

84
00:05:40.420 --> 00:05:42.940
There's a tendency in particular in like in,

85
00:05:42.941 --> 00:05:46.900
in the Ted talks where there's real selection for being provocative,
right?

86
00:05:47.290 --> 00:05:50.470
To suggest that that people are irrational because they don't follow the rules

87
00:05:50.471 --> 00:05:54.520
of formal.
We're actually Madec rationality theory.
However,

88
00:05:54.521 --> 00:05:57.430
every economic decision entails and optimization problem.
And,

89
00:05:57.431 --> 00:05:58.470
and I feel like I'm,

90
00:05:58.471 --> 00:06:02.720
I'm on safe ground when I'm at Google talking about optimization problems,
right?

91
00:06:02.740 --> 00:06:06.260
That,
and if you want to solve an optimization problem,
what do you need?
Well,

92
00:06:06.261 --> 00:06:08.960
you need to know who's doing the optimizing.
You need to know the actor,

93
00:06:08.961 --> 00:06:11.300
but you need to know the objective function,
right?

94
00:06:11.720 --> 00:06:14.120
And if you get the objective function wrong,

95
00:06:14.330 --> 00:06:16.700
you're going to get the solution wrong,
okay?

96
00:06:16.820 --> 00:06:21.530
And it doesn't matter what your optimization problem is,
right?

97
00:06:21.531 --> 00:06:22.880
It could be an engineering problem,

98
00:06:23.270 --> 00:06:27.020
it could be a portfolio design and investment portfolio design.

99
00:06:27.021 --> 00:06:30.800
It could be about insurance and getting the best mixture of wild foods to ensure

100
00:06:30.801 --> 00:06:34.400
growth and survival,
right?
But you need to get the objective function right.

101
00:06:34.790 --> 00:06:37.580
And I'm going to suggest that in general,

102
00:06:37.850 --> 00:06:42.740
we don't have a very solid understanding of what the objective function is that

103
00:06:42.741 --> 00:06:46.970
people are using when they're making economic decisions broadly.

104
00:06:47.990 --> 00:06:50.750
Okay?
And the results appear anomalous.
When you get,

105
00:06:50.751 --> 00:06:53.870
when you use the wrong objective function,
you get the wrong answer.

106
00:06:54.230 --> 00:06:57.500
And I think that evolution helps weave together theoretically what are otherwise

107
00:06:57.501 --> 00:06:59.690
a series of unconnected anomalies.

108
00:07:02.620 --> 00:07:06.300
Um,
so we,
we liked this coherence.
Uh,

109
00:07:06.301 --> 00:07:09.980
and I think these may be brought together if we understand what sort of problems

110
00:07:09.990 --> 00:07:14.240
the human brain is actually designed to solve.
Okay.
Um,

111
00:07:14.840 --> 00:07:17.810
get the right objective function and you have a chance,
a chance,

112
00:07:17.830 --> 00:07:21.800
I'm not 100% convinced to this.
This is fairly new for me,

113
00:07:21.801 --> 00:07:25.790
but I feel like there's a real chance that we can begin to understand,

114
00:07:26.360 --> 00:07:30.710
uh,
the,
this sort of broader theory of,
of choice.
Um,

115
00:07:32.270 --> 00:07:36.980
so the two things that we really need,
I think our evolutionary theory,

116
00:07:37.220 --> 00:07:39.560
which guides our choice of what's being optimized,

117
00:07:39.561 --> 00:07:43.340
it gives us a clue as to what the likely objective function that our brains are

118
00:07:43.341 --> 00:07:47.390
designed to solve or to optimize.
And secondly,

119
00:07:47.600 --> 00:07:51.140
it's really important that we get broad comparative data to help us understand

120
00:07:51.141 --> 00:07:53.060
the conditions that favor good decision making.

121
00:07:53.061 --> 00:07:58.061
It turns out that different groups of people make more or less good decisions,

122
00:07:58.490 --> 00:08:02.660
right?
It's not everybody who's a complete idiot and behaves irrationally.

123
00:08:03.350 --> 00:08:07.510
Okay.
And,
and we,
we sort of limit ourselves a lot in,

124
00:08:07.520 --> 00:08:12.080
in the sort of people that we inquire about,
about,
um,
decision making.

125
00:08:12.560 --> 00:08:17.000
I'm going to focus primarily on the evolutionary theory and give you just some

126
00:08:17.001 --> 00:08:18.770
hints of some work that we've done.

127
00:08:19.180 --> 00:08:21.950
A without getting bogged down in the technique,
technical details.

128
00:08:21.951 --> 00:08:26.890
But I think that the comparative data is really important as well.
Uh,

129
00:08:26.900 --> 00:08:31.900
and then use this word fitness and he used it a lot and a evolutionary success

130
00:08:32.271 --> 00:08:33.200
is determined by fitness.

131
00:08:33.201 --> 00:08:36.890
And the problem with fitness is it's one of these super fraught terms,
right?

132
00:08:36.891 --> 00:08:40.520
That that has lots of colloquial meanings that can kind of interfere with our

133
00:08:40.521 --> 00:08:45.020
rigorous understanding and analysis of it.
So when I talk about fitness,

134
00:08:45.620 --> 00:08:45.921
uh,

135
00:08:45.921 --> 00:08:49.730
I'm talking about the relative contribution that an individual makes to future

136
00:08:49.731 --> 00:08:52.850
populations.
So if you have some heritable trait,

137
00:08:53.120 --> 00:08:56.130
whether its anatomical or physiological or behavioral,

138
00:08:56.820 --> 00:09:00.270
marginally increasing the representation of its bearers and future generations,

139
00:09:00.271 --> 00:09:02.820
the population is going to evolve towards that trait.

140
00:09:03.090 --> 00:09:07.800
This is the fundamental logic of selection,
right?
And,
uh,

141
00:09:08.070 --> 00:09:11.940
and,
and fitness is the evolutionary objective function.

142
00:09:11.941 --> 00:09:14.970
It is the subject of evolutionary optimization.
Okay.

143
00:09:14.971 --> 00:09:17.940
So just wanting to get that out of the way.
I'm going to give you

144
00:09:19.470 --> 00:09:24.470
a quick preview of the approach that we use and thinking about this.

145
00:09:24.781 --> 00:09:26.310
Um,
uh,

146
00:09:26.340 --> 00:09:31.340
sort of more formally the organs that make our economic decisions right there.

147
00:09:31.411 --> 00:09:35.190
Oregon's just like our liver is just like our heart is presumably these have

148
00:09:35.191 --> 00:09:39.030
been under intense selection.
And part of the reason,
just as an aside,

149
00:09:39.031 --> 00:09:42.960
part of the reason we think that brains should be under intense selection is not

150
00:09:42.961 --> 00:09:46.710
just because they're useful,
but because they're super costly,
right?

151
00:09:47.010 --> 00:09:49.830
The brain is an incredibly costly thing to carry around.

152
00:09:49.831 --> 00:09:53.880
It entails mortality costs for,
for mothers,
right?

153
00:09:53.881 --> 00:09:56.160
Because if we get this cephalopelvic disproportion,

154
00:09:56.161 --> 00:09:59.100
big brains have to come through a limited pelvic cavity when,

155
00:09:59.101 --> 00:10:04.101
when they're born brains use 20% of of oxygen at rest right there.

156
00:10:04.801 --> 00:10:05.850
Super costly.

157
00:10:06.300 --> 00:10:09.720
The fact that they exist and that they've gotten bigger over time suggest that

158
00:10:09.721 --> 00:10:13.650
there's a reason they're there.
Right?
Um,
so,

159
00:10:14.730 --> 00:10:19.590
uh,
people with good decision making capabilities presumably in the past,

160
00:10:20.100 --> 00:10:20.491
uh,

161
00:10:20.491 --> 00:10:23.760
resulted in leaving more descendants and became disproportionately represented

162
00:10:23.761 --> 00:10:28.590
in the,
in the population to the extent that economic decisions affect fitness,

163
00:10:29.100 --> 00:10:33.390
we should expect outcomes to track fitness interests more than some arbitrarily

164
00:10:33.391 --> 00:10:37.620
defined standard form.
A standard of formal rationality.
Okay.

165
00:10:37.860 --> 00:10:42.860
So let me just walk you through a little bit of the logic here of the model and

166
00:10:42.941 --> 00:10:46.710
then I'm going to move away from it and go and,
and go on to talking about some,

167
00:10:46.711 --> 00:10:49.470
uh,
some features of the human evolutionary environment.

168
00:10:50.250 --> 00:10:53.610
So it's a hierarchical model.

169
00:10:54.360 --> 00:10:57.360
At the bottom we have economic decisions,
right?

170
00:10:57.361 --> 00:11:00.090
These are about the sorts of things you hunt for,

171
00:11:00.091 --> 00:11:02.160
the sort of things you put in your market basket,

172
00:11:02.161 --> 00:11:06.240
the decisions you're making on a day to day basis.
About your,
your livelihood,

173
00:11:06.690 --> 00:11:07.290
right?

174
00:11:07.290 --> 00:11:12.180
And these feed into what we think of as like proximate motivators.

175
00:11:12.630 --> 00:11:17.010
These are the things that you're,
you're sort of striving for,
uh,

176
00:11:17.100 --> 00:11:19.890
in approximate way happiness or,

177
00:11:20.100 --> 00:11:23.160
or sexual gratification or satiety,
right?

178
00:11:23.161 --> 00:11:26.790
The things that motivate you to eat or to have sex or to do things that are

179
00:11:26.791 --> 00:11:27.990
meaningful in your life.

180
00:11:28.920 --> 00:11:33.600
But these then presumably have an impact on,
on fitness.

181
00:11:33.930 --> 00:11:36.930
And we can think of as a fitness here as an aggregator,

182
00:11:37.110 --> 00:11:41.160
something that aggregates and averages over these different,
uh,

183
00:11:41.240 --> 00:11:45.810
than my pointer doesn't work these different,
um,
uh,

184
00:11:46.110 --> 00:11:51.000
uh,
goals which are fed into by,
uh,
these economic decisions.

185
00:11:51.000 --> 00:11:55.570
Okay.
So that's a,
a preview of the type of reasoning that we're using.

186
00:11:55.720 --> 00:11:59.560
I'll come back to this and a little bit,
but I do want to mention,
you know,

187
00:11:59.561 --> 00:12:01.030
I said that the,
the two things that we need,

188
00:12:01.031 --> 00:12:02.230
I think we need to evolutionary theory.

189
00:12:02.231 --> 00:12:06.580
I think we also need broad comparative data on the decision making of actual

190
00:12:06.581 --> 00:12:11.560
people in particularly people who are good at making decisions under tremendous

191
00:12:11.561 --> 00:12:14.020
constraints.
And this is just a selection of a bunch of people.

192
00:12:14.350 --> 00:12:15.940
They've written some books,
right?

193
00:12:16.180 --> 00:12:20.610
And it turns out that somewhat to the surprise of,
of much of the,

194
00:12:20.611 --> 00:12:25.570
the institution of,
uh,
studying,
uh,
economic decision making,

195
00:12:26.080 --> 00:12:30.280
that poor people often make incredibly savvy decisions,
right?

196
00:12:30.281 --> 00:12:34.060
They face enormous constraints.
But when you adjust for that,

197
00:12:34.061 --> 00:12:38.170
when you control for the fact that there are constraints set is very limited,

198
00:12:38.171 --> 00:12:41.260
right?
That their strategy said is very limited and they're under a tremendous

199
00:12:41.261 --> 00:12:42.094
constraint.

200
00:12:42.400 --> 00:12:46.540
Poor people tend to make very good decisions in part because it really matters

201
00:12:46.541 --> 00:12:50.860
to them.
Okay.
And so I'm going to leave that,
this is another big part of,

202
00:12:51.270 --> 00:12:55.870
uh,
the broader work that I'm doing,
but I want to focus on,
on more the,
the,

203
00:12:56.020 --> 00:12:57.730
um,
the sort of evolution part,

204
00:12:58.400 --> 00:13:02.710
the economic decisions I'm going to talk about and show you some pictures of,

205
00:13:03.250 --> 00:13:07.480
uh,
typically send her on on subsistence populations and the,
you know,

206
00:13:07.481 --> 00:13:08.800
the things look a little exotic,

207
00:13:09.070 --> 00:13:12.340
but the sorts of decisions that people make and subsistence economies are

208
00:13:12.341 --> 00:13:16.300
fundamentally no different than the types of decisions that we make on a regular

209
00:13:16.301 --> 00:13:19.900
basis.
Right?
What,
how do you fill your market basket?

210
00:13:19.901 --> 00:13:24.790
Given a fixed a budget,
right?
It may not be money,
it may be time,

211
00:13:25.150 --> 00:13:28.990
it may be political capital,
but,
uh,
you're,
you're,

212
00:13:28.991 --> 00:13:32.390
you're doing very much the same sort of thing.
And one of the,

213
00:13:32.470 --> 00:13:37.390
and basically my argument is that we have to think about humans as biological

214
00:13:37.391 --> 00:13:40.700
entities.
We've been shaped by selection,
um,

215
00:13:41.140 --> 00:13:45.730
and that our decision making capabilities have fundamentally been shaped by,

216
00:13:45.760 --> 00:13:50.680
by,
uh,
by this,
this evolutionary heritage as a to a biological entity.

217
00:13:50.681 --> 00:13:54.460
Economic decisions are not arbitrary preference orderings right there,

218
00:13:54.461 --> 00:13:57.790
which is sort of the way you typically will learn about them in a micro

219
00:13:57.791 --> 00:13:59.170
economics class,
for example,

220
00:13:59.800 --> 00:14:03.460
it turns out that the rules for living organism anchored in the present and

221
00:14:03.461 --> 00:14:08.110
subject to a force of selection that really doesn't like extinction,
right?

222
00:14:08.490 --> 00:14:12.910
Fitness is a multiplicative process,
right?
In order for your lineage to persist,

223
00:14:12.911 --> 00:14:15.850
it has to persist every generation.

224
00:14:15.880 --> 00:14:19.510
You can't get a zero in there or it's an absorbing boundary,
right?

225
00:14:20.020 --> 00:14:22.780
So you really want to avoid those zeros.
Um,

226
00:14:23.020 --> 00:14:26.170
I'll show that the all important need to avoid extinction in a world that's an

227
00:14:26.171 --> 00:14:30.940
incompletely known at best has profound implications for preferences,

228
00:14:30.941 --> 00:14:33.880
utility and nationality.
And uh,

229
00:14:33.910 --> 00:14:37.360
one of the key things I think that comes out of this,
um,

230
00:14:37.690 --> 00:14:42.690
is it ignoring the condition of existential uncertainty by doing that,

231
00:14:42.911 --> 00:14:43.810
the,
the theory of,

232
00:14:43.811 --> 00:14:48.280
of rational decision making is developed a distorted expectation of how

233
00:14:48.281 --> 00:14:53.030
organisms working in their own interest,
uh,
should behave.
Okay.
So,

234
00:14:53.280 --> 00:14:58.160
uh,
a bunch of the work I've done on this is in collaboration with my colleagues,

235
00:14:58.170 --> 00:15:00.200
Rebecca and Doug Bird.
Uh,

236
00:15:00.230 --> 00:15:04.130
and just to give you a sampling of the types of economic decisions we tend to

237
00:15:04.131 --> 00:15:07.280
think about,
do you hunt for Atlanta,
which are these,

238
00:15:07.400 --> 00:15:11.000
these monitor lizards that live in the desert of Western Australia or do you

239
00:15:11.001 --> 00:15:12.980
hunt for hill kangaroo,
right.

240
00:15:12.981 --> 00:15:15.290
There are different payoffs are different risks associated with this.

241
00:15:15.800 --> 00:15:20.800
If you're a subsistence farmer in this is in Uganda,

242
00:15:21.880 --> 00:15:22.940
another place where I work,

243
00:15:23.030 --> 00:15:28.030
do you plant maize dude plant yams or do you forego subsistence crops altogether

244
00:15:29.150 --> 00:15:33.740
and take your,
take a stab at the,
at the cash economy.
This is coffee,
uh,

245
00:15:33.741 --> 00:15:35.890
working with,
uh,
a postdoc,

246
00:15:35.920 --> 00:15:40.310
Ashley Hazel in Southern Africa in Namibia.
You know,
we're,
we're,

247
00:15:40.311 --> 00:15:42.470
we're asking the sort of questions,
how do people,

248
00:15:42.471 --> 00:15:45.530
particularly women manage social relationships to manage,

249
00:15:45.710 --> 00:15:50.710
to manage the extreme uncertainty of living in essentially a desert and trying

250
00:15:51.081 --> 00:15:55.370
to raise cattle,
trying to raise crops,
trying to raise children,
right?

251
00:15:55.371 --> 00:15:59.000
Trying to keep your yourself going in a very difficult environment.

252
00:15:59.450 --> 00:16:03.110
So these are the types of economic decisions that I tend to think about.

253
00:16:03.111 --> 00:16:07.280
But as I say,
there,
no,
they're fundamentally no different than going shopping,

254
00:16:07.550 --> 00:16:10.730
buying a house,
doing the sorts of things that economists tend to look at.

255
00:16:11.960 --> 00:16:15.090
The history of this for me,
uh,

256
00:16:15.290 --> 00:16:18.140
goes back to my former phd student like price,

257
00:16:18.141 --> 00:16:21.050
who's now a post doc at the Santa Fe Institute.

258
00:16:21.710 --> 00:16:26.370
And Mike was interested in understanding the origins of Sago,
palm farming in,
uh,

259
00:16:26.420 --> 00:16:30.860
in Southeast Asia.
Um,
Sago Palm.

260
00:16:30.890 --> 00:16:33.730
It's an amazing crop.
It's one of the,
it's one of the senators of,

261
00:16:33.731 --> 00:16:38.731
of agricultural innovation in and around New Guinea and the South Pacific,

262
00:16:39.020 --> 00:16:42.290
uh,
uh,
Southeast Asia.
Um,

263
00:16:43.770 --> 00:16:45.490
a single Sago palm tree.
We'll,

264
00:16:45.491 --> 00:16:49.940
we'll met literally millions of calories in starchy flower,
right?
That you,

265
00:16:49.941 --> 00:16:53.810
that you can make into a grill.
Um,
that's,

266
00:16:53.811 --> 00:16:58.760
that's very calorically dense that catches it takes 25 years for a Sago palm to

267
00:16:58.761 --> 00:17:02.210
develop to maturity and to the point where it can be harvested.

268
00:17:02.510 --> 00:17:05.900
And trying to understand the evolution of this remarkable horticultural system.

269
00:17:05.901 --> 00:17:07.880
Let us to think hard about,
uh,

270
00:17:07.881 --> 00:17:11.930
economic topics such as time and risk preferences,
preferences,

271
00:17:12.650 --> 00:17:14.090
and economic decisions.
Generally,

272
00:17:14.480 --> 00:17:18.860
it's hard to make a sort of standard economic model that says,
okay,

273
00:17:19.160 --> 00:17:24.160
for go the immediate reward activities you're pursuing right now and go plant

274
00:17:24.351 --> 00:17:28.280
some Sago Palm and wait 25 years.
Right?
That's a,

275
00:17:28.281 --> 00:17:32.420
that's a hard problem to solve.
But clearly it happened at some point.

276
00:17:32.810 --> 00:17:35.180
So that's where all this really started thinking.

277
00:17:35.181 --> 00:17:38.330
And Mike and I have been working together for a few years on this stuff.

278
00:17:38.900 --> 00:17:43.550
So a theme that emerged in our work is that,
is it a biological entity?

279
00:17:43.551 --> 00:17:48.551
Trying to maximize fitness will behave in ways that often really mimic the

280
00:17:49.830 --> 00:17:53.850
anomalies that you see in this behavioral economics and psychology literature.

281
00:17:54.450 --> 00:17:57.840
We weren't looking to show that,
but we found how,
you know,
people said,
hey,

282
00:17:57.841 --> 00:17:59.370
you know,
that kind of looks like prospect area.

283
00:17:59.371 --> 00:18:01.860
Is that really I that surprises me.

284
00:18:02.130 --> 00:18:06.560
So they'll do things like use non unexpected utility,
right?

285
00:18:06.780 --> 00:18:09.810
Uh,
I don't get into what that,
what that necessarily means.

286
00:18:09.870 --> 00:18:11.190
Happy to talk about it later.

287
00:18:11.400 --> 00:18:15.780
They'll frequently violate the axioms of rational choice.
Uh,

288
00:18:15.840 --> 00:18:20.450
they'll seemingly have inconsistent time preferences,
right?
They'll,
um,

289
00:18:20.790 --> 00:18:24.540
I mean from the perspective of an economic decision,
these may appear irrational,

290
00:18:24.870 --> 00:18:27.780
but these behaviors are the sort of things that keep you alive in,

291
00:18:27.810 --> 00:18:31.460
in a variable and uncertain environment.
Okay.
Um,

292
00:18:31.560 --> 00:18:36.510
so rather than the mathematicians,
a formal axiomatic rationality,

293
00:18:37.080 --> 00:18:40.130
people seem to use a procedural rationality.
And this is a point that the,

294
00:18:40.150 --> 00:18:44.970
the great in a polymath economist Herbert Simon suggested in his scissors

295
00:18:44.971 --> 00:18:46.380
metaphor,
right?
The,

296
00:18:46.381 --> 00:18:50.340
that trying to understand decision making is like trying to understand the way a

297
00:18:50.341 --> 00:18:51.330
pair of scissors work.

298
00:18:52.020 --> 00:18:55.410
You've got on the one hand the computational capacities,

299
00:18:55.860 --> 00:18:59.580
but on the other hand you've got the task environment trying to understand the

300
00:18:59.581 --> 00:19:00.930
computational capacities,

301
00:19:00.931 --> 00:19:04.990
like the logical rules of cognition without understanding the environment is

302
00:19:04.991 --> 00:19:08.970
like trying to understand half a pair of scissors doesn't work very well.
Okay.

303
00:19:11.340 --> 00:19:15.000
I said that their selection and Ted talk like environments for saying

304
00:19:15.001 --> 00:19:19.530
provocative things.
This is a slightly provocative thing,
Darwin saying it.

305
00:19:20.070 --> 00:19:24.480
Um,
economics is an actually a science,
right?
And I,

306
00:19:24.600 --> 00:19:26.520
this isn't meant as a put down,
it's,
it's,

307
00:19:26.521 --> 00:19:28.820
it's a statement of fact and it's because the,

308
00:19:28.821 --> 00:19:33.420
the preferred and overwhelmingly the dominant mode of economic theory
generation,

309
00:19:33.421 --> 00:19:37.560
it's axiomatic,
right?
And that's not the way the natural sciences proceed.

310
00:19:38.430 --> 00:19:39.850
Behavioral Economics and,

311
00:19:39.900 --> 00:19:44.250
and this great field of experimental developmental economics has changed this by

312
00:19:44.251 --> 00:19:48.930
actually measuring the way people behave rather than sort of specifying the way

313
00:19:48.931 --> 00:19:52.800
that they're expected to behave.
But I think there's still a decent amount of,

314
00:19:52.801 --> 00:19:56.370
of baggage.
What do I mean when I say axiomatic?

315
00:19:56.880 --> 00:20:01.050
Standard economic theory generation starts from a series of axioms,
right?

316
00:20:01.051 --> 00:20:03.060
Primitive assumptions that are taken to be self evident.

317
00:20:03.061 --> 00:20:07.280
Things like you shouldn't reverse your preferences if you prefer a to B and B to

318
00:20:07.281 --> 00:20:11.490
c,
you should prefer a to see that's a,
that's an axiom of transitivity.
Right?

319
00:20:11.760 --> 00:20:12.870
And that makes total sense.

320
00:20:13.140 --> 00:20:15.120
But there's nothing that guarantees that that's right.

321
00:20:15.150 --> 00:20:17.820
There's nothing that guarantees it.
That's the way the universe works.

322
00:20:18.060 --> 00:20:22.920
It's just a logical rule that we said I can live with that.
Right?
And so,

323
00:20:23.550 --> 00:20:25.020
um,
you take these axioms,

324
00:20:25.060 --> 00:20:28.590
you derive out the way you expect a rational agent to behave.

325
00:20:29.220 --> 00:20:33.270
And this is what economic theory really is all about.
It,
it's normative.

326
00:20:33.271 --> 00:20:38.070
It describes how actors should behave.
Science on the other hand is positive,

327
00:20:38.071 --> 00:20:38.281
right?

328
00:20:38.281 --> 00:20:42.720
It starts from observations about the world and attempts to explain them as

329
00:20:42.721 --> 00:20:45.630
inferred through observed data.
It's inductive,
right?

330
00:20:45.631 --> 00:20:48.190
The theory plays the role of generating hypotheses,

331
00:20:48.191 --> 00:20:52.150
which can then be confronted with additional data,
right?
And so,

332
00:20:52.930 --> 00:20:53.680
um,

333
00:20:53.680 --> 00:20:57.430
it's a common and it's a well state and critique of that neoclassical economic

334
00:20:57.431 --> 00:21:00.700
theory describes the behavior of a species other than humans.

335
00:21:01.000 --> 00:21:05.020
And it's referred to tongue in cheek,
uh,
by the fake Latin binomial,
binomial,

336
00:21:05.021 --> 00:21:07.780
homo economic us.
Right?
Uh,

337
00:21:07.781 --> 00:21:10.660
and while it's true that humans do not behave according to the classical

338
00:21:10.870 --> 00:21:15.820
expectations,
are these neoclassical expectations,
you know,
the,
the,

339
00:21:15.850 --> 00:21:20.320
the expectations weren't designed to actually explain,
observe behavior,
right?

340
00:21:20.321 --> 00:21:22.270
So we shouldn't be that surprised by it,
I think.

341
00:21:22.810 --> 00:21:26.650
So I'm going to talk to you about what,
right now for a little bit about,
uh,

342
00:21:26.651 --> 00:21:29.530
what I think the really important bits of,
of,

343
00:21:29.560 --> 00:21:34.560
of our human evolutionary legacy are for understanding the way we make decisions

344
00:21:35.081 --> 00:21:38.740
about things.
And I'm going to dive down fairly deep into,

345
00:21:38.770 --> 00:21:41.890
into my specialty area,
which is called life history theory.

346
00:21:42.400 --> 00:21:46.360
So I'm going to suggest that humans are adapted to environmental uncertainty.

347
00:21:47.170 --> 00:21:51.820
And
this is a,
I think,
a pretty telling graphics.

348
00:21:51.821 --> 00:21:54.550
So what I've got here is its temperature proxy data.

349
00:21:54.551 --> 00:21:58.770
So this is inferred temperature,
uh,
by million years before presence.

350
00:21:58.771 --> 00:22:03.340
So we're going from more ancient to more recent humans are a product of what's

351
00:22:03.341 --> 00:22:04.700
called the pleistocene,
which is a,

352
00:22:04.710 --> 00:22:09.460
a geological epoch that spans from about 1.8 million years ago to about 10,000

353
00:22:09.461 --> 00:22:10.294
years ago.

354
00:22:10.600 --> 00:22:14.770
And the two things that should be really obvious from this plot are that one,

355
00:22:14.800 --> 00:22:16.690
the earth is cooled in the last 5 million years.

356
00:22:16.691 --> 00:22:19.450
It's actually cooled considerably more in the last 25 million years.

357
00:22:19.900 --> 00:22:23.860
It's cooled and it's gotten more variable.
Okay?

358
00:22:24.070 --> 00:22:27.190
And you can't actually see it on here.
We know that in places,

359
00:22:27.191 --> 00:22:32.140
particularly in Africa,
um,
where,
where,
uh,
there's been a lot of interest in this.

360
00:22:32.410 --> 00:22:34.420
There's actually a decadal scale variation here,

361
00:22:34.480 --> 00:22:38.980
like enormous environmental variation going on that really gets amplified in

362
00:22:38.981 --> 00:22:43.690
this period,
uh,
where our genus emerged,
which is this,
this pink line here.

363
00:22:43.810 --> 00:22:48.610
Okay?
And just while I'm on the subject of temperature,
global temperature,
right?

364
00:22:48.880 --> 00:22:52.420
You'll sometimes see people say,
well,
you know,
the earth used to be much warmer.

365
00:22:52.930 --> 00:22:55.840
We can let it get warm it,
it'll be fine,
maybe.
Sure.

366
00:22:55.990 --> 00:22:59.770
But we're a cold planet species,
right?

367
00:22:59.830 --> 00:23:04.270
We are adapted to a cooler planet.
Just,
you know,
something to bear in mind.

368
00:23:06.520 --> 00:23:09.670
The origin story of the human lineage and the,
and the genus.

369
00:23:09.671 --> 00:23:14.671
Homo in particular is a story of moving from a primarily Arboreal,

370
00:23:15.580 --> 00:23:19.930
uh,
lifestyle in tropical ever moist forest.
This is a chimpanzee,

371
00:23:20.610 --> 00:23:22.060
uh,
foraging for,

372
00:23:22.090 --> 00:23:25.020
you can see the fruits up in the top of the picture there and the New England

373
00:23:25.030 --> 00:23:27.010
forest.
And in,
in Rwanda,

374
00:23:27.670 --> 00:23:32.670
we moved from these forests onto this sort of mixed scrubbed Savannah.

375
00:23:33.311 --> 00:23:36.880
This is a picture from Serengeti National Park in Tanzania.

376
00:23:37.330 --> 00:23:42.330
And moving onto the Savannah entailed a bunch of new challenges right there,

377
00:23:43.781 --> 00:23:48.320
big predators there.
There are a lot of them.
They're big and they're scary.

378
00:23:49.520 --> 00:23:50.353
Uh,

379
00:23:50.870 --> 00:23:55.400
but it also changes the way food is distributed,
right?

380
00:23:55.750 --> 00:23:59.100
And then here's a picture of a chimpanzee present,
uh,

381
00:23:59.150 --> 00:24:03.440
the Kamali National Park and,
and he's looking down at me and,

382
00:24:03.441 --> 00:24:07.880
and he's got an enormous pile of figs here.
And this tree,

383
00:24:09.200 --> 00:24:13.400
I don't want to exaggerate,
but it certainly had tens of thousands of figs,

384
00:24:13.401 --> 00:24:15.110
possibly hundreds of thousands,

385
00:24:15.650 --> 00:24:18.080
possibly well into the hundreds of thousands of things.

386
00:24:18.470 --> 00:24:22.120
These tropical things are incredibly productive.
They're asynchronous breeders,

387
00:24:22.121 --> 00:24:24.380
so they breed sort of throughout,
throughout the year.

388
00:24:24.381 --> 00:24:27.620
They fruit throughout the year.
They're not really high quality.

389
00:24:27.621 --> 00:24:30.260
Like you wouldn't want to make a Newton out of them,
right?

390
00:24:30.261 --> 00:24:33.740
You're not going to make figgy pudding with these cause they taste like crap,

391
00:24:33.741 --> 00:24:38.450
I assure you.
But when there's no good fruit in the forest,

392
00:24:38.480 --> 00:24:42.500
chimps,
we'll happily eat this and this is in general what the great apes do.

393
00:24:42.530 --> 00:24:47.150
They fall back when their preferred foods aren't there onto this lower quality

394
00:24:47.151 --> 00:24:50.720
stuff and figs are a great thing.
And any tropical forest,

395
00:24:51.590 --> 00:24:55.130
we go out into the Savannah,
there no there,
there isn't much fruit.
What?

396
00:24:55.131 --> 00:24:57.260
There are our underground storage organs,

397
00:24:58.010 --> 00:25:02.060
so these are a bunch of Hadza tubers that my former postdoc Brian would took a

398
00:25:02.061 --> 00:25:05.660
picture of and they look like sticks,
don't they?

399
00:25:05.860 --> 00:25:08.300
It doesn't that look delicious,
right?

400
00:25:08.480 --> 00:25:12.700
Try to eat that and you're going to spend like 12 hours just chewing on it.
Your,

401
00:25:12.710 --> 00:25:15.080
your,
your jaws are going to be so tired.

402
00:25:15.440 --> 00:25:19.700
You have to have fire basically in order to,
you scorch them,

403
00:25:20.480 --> 00:25:22.400
he burned them and you make them chewable.

404
00:25:23.450 --> 00:25:28.450
There's a lot of stored starch in there and it makes for a great fallback food,

405
00:25:29.330 --> 00:25:32.780
but they're very different than figs.
They're widely distributed.

406
00:25:32.990 --> 00:25:36.500
They're not at all clumped.
Right.
You're never going to find a patch,
you know,

407
00:25:36.501 --> 00:25:37.970
just start digging.
Oh yeah.

408
00:25:37.971 --> 00:25:39.560
And you've got to dig for them cause they're underground.

409
00:25:39.561 --> 00:25:43.370
But you got to start digging.
You're not going to find 100,000 tubers there,

410
00:25:43.580 --> 00:25:46.460
right?
Like you're going to find 100,000 figs in a tree,

411
00:25:46.940 --> 00:25:51.920
so you have to spread out your effort.
Right?
It changes the economics of,
of,

412
00:25:51.950 --> 00:25:56.480
uh,
foraging tremendously.
Uh,
and here's Brian,
uh,

413
00:25:56.570 --> 00:25:57.231
who's,
you know,

414
00:25:57.231 --> 00:26:01.280
one of the world authorities on the Hud's a hunter gatherers and Tanzania and

415
00:26:01.281 --> 00:26:05.180
his hair really is fascinating.
So,
uh,
he gets that a lot.

416
00:26:05.210 --> 00:26:08.270
He's now a professor down at Ucla.
Um,

417
00:26:09.320 --> 00:26:13.130
so moving from the force of the sedan and beyond increases as the variability in

418
00:26:13.131 --> 00:26:17.480
food intake,
right?
Because it's a drier environment,

419
00:26:17.481 --> 00:26:20.810
it's a less productive environment.
There are lots of opportunities,

420
00:26:20.811 --> 00:26:22.310
but there are also lots of challenges.

421
00:26:22.820 --> 00:26:27.500
And while there's certainly more sort of meat on the huff,
your,

422
00:26:27.501 --> 00:26:31.340
your ability to sort of manage your downside,
I think is a,
is,

423
00:26:31.341 --> 00:26:33.470
is much harder on the Savannah.

424
00:26:33.980 --> 00:26:37.910
And so this is why adaptation does uncertainty as a central part of being human,

425
00:26:37.970 --> 00:26:38.301
right?

426
00:26:38.301 --> 00:26:43.010
Humans move out of the forest onto the Savannah and it's a much more variable

427
00:26:43.020 --> 00:26:47.190
place.
And this,
this variability is not just,

428
00:26:48.120 --> 00:26:48.361
you know,

429
00:26:48.361 --> 00:26:53.361
you don't just like set up an experiment and measure the variability and get

430
00:26:54.091 --> 00:26:56.730
your nice distribution that you fit to it and say,
okay,

431
00:26:57.180 --> 00:27:01.050
14% of the time I'm going to have to do this and the 27% of the time I'm going

432
00:27:01.051 --> 00:27:03.480
to have to do this the way a risk manager would do it.

433
00:27:03.750 --> 00:27:04.980
There's real uncertainty here.

434
00:27:04.981 --> 00:27:08.430
You really don't know what the probabilities are in part because the environment

435
00:27:08.431 --> 00:27:10.290
is,
is very rapidly changing.

436
00:27:12.570 --> 00:27:17.520
So when I say uncertainty,
I mean uncertainty and not risk.
Um,
adaptation,

437
00:27:17.521 --> 00:27:19.020
doubt,
uncertainty is central to being human.

438
00:27:19.021 --> 00:27:21.570
There are all these things that we do that are very unusual.

439
00:27:22.470 --> 00:27:24.900
We haven't expanded diet as I've mentioned,
you know,

440
00:27:24.901 --> 00:27:29.860
that typically requires technology to extract like,
like,
uh,

441
00:27:29.861 --> 00:27:33.690
these underground storage.
Oregon's,
we are the mobile primate,
right?

442
00:27:33.960 --> 00:27:37.680
Our home ranges for like a hunter gather,
uh,

443
00:27:37.710 --> 00:27:40.230
is on the order of 10 to a hundred times bigger than a,

444
00:27:40.440 --> 00:27:43.530
than a comparable size chimpanzee group.
Okay.

445
00:27:43.860 --> 00:27:47.370
So like the Hadza range over about 2,500 square kilometers,

446
00:27:47.790 --> 00:27:50.790
whereas a chimpanzee group will range over about 20.

447
00:27:50.820 --> 00:27:54.570
Now the chimps live in a forest,
so you know,
there is that difference,

448
00:27:54.930 --> 00:27:57.890
but that's part of moving out onto the Savannah and where the,

449
00:27:57.900 --> 00:28:02.490
where the huddle live.
Humans are so mobile,
right?
When things get really bad,

450
00:28:02.670 --> 00:28:07.200
we get up and we moved continents,
right?
This is very much a timely issue,

451
00:28:07.230 --> 00:28:09.750
right?
The 21st century in the latter part of the 20th,

452
00:28:09.751 --> 00:28:14.640
first century is going to be dominated by human mobility,
right?

453
00:28:14.641 --> 00:28:15.141
We,
we,

454
00:28:15.141 --> 00:28:19.320
we see that it's breaking lots of international systems right now and possibly

455
00:28:19.321 --> 00:28:24.120
leading to the rise of right wing or right wing extremism,
right?

456
00:28:24.510 --> 00:28:28.770
Migration is part of our story from the outset.
Um,

457
00:28:29.880 --> 00:28:33.270
the other really big thing that we do that we're really known for,

458
00:28:33.271 --> 00:28:36.960
and that's very unusual,
right,
is we share food.

459
00:28:38.280 --> 00:28:39.180
And it's so unusual,

460
00:28:39.181 --> 00:28:43.020
we don't even think about how weird it is that a bunch of unrelated males

461
00:28:43.270 --> 00:28:44.340
doesn't matter.
It males,

462
00:28:44.341 --> 00:28:49.170
females can sit in a room and share food together and like not want to kill each

463
00:28:49.171 --> 00:28:51.420
other.
I mean,
I don't know.
I don't wanna speak for you,

464
00:28:51.720 --> 00:28:54.690
but I can sit in a room with people.
People are eating.

465
00:28:54.690 --> 00:28:58.920
I don't feel like I need to go,
you know,
get all dominant or something.
Right?

466
00:28:59.160 --> 00:29:00.290
This is weird,
right?

467
00:29:00.310 --> 00:29:03.780
You talk about your dog and all the unconditional love of a dog.

468
00:29:04.020 --> 00:29:04.890
I've got an idea.

469
00:29:05.220 --> 00:29:08.460
Why don't you try pulling your dog's food bowl and eating from it?

470
00:29:08.461 --> 00:29:12.900
See if that love is so unconditional,
right?
It's a weird thing that people do.

471
00:29:13.080 --> 00:29:16.320
We share food all the time and hunter gathers,
it's,

472
00:29:16.321 --> 00:29:21.321
it turns out to be a super risky and uncertain endeavor to go hunting those hill

473
00:29:21.581 --> 00:29:22.414
kangaroos.

474
00:29:22.530 --> 00:29:27.510
85% of all hunting bouts end with zero calories.

475
00:29:27.570 --> 00:29:31.230
Netted.
Okay.
85%.
So these are,

476
00:29:32.080 --> 00:29:35.700
uh,
mixed,
uh,
hunter gatherers in,
in the Canadian Arctic,

477
00:29:36.120 --> 00:29:40.710
my student Elspeth ready gather these data heroically over two years.

478
00:29:40.711 --> 00:29:45.440
It's an incredible,
incredible story.
Um,
and it's just the show.

479
00:29:45.490 --> 00:29:47.560
I mean she,
she also makes it really pretty graphics,

480
00:29:47.590 --> 00:29:51.790
but it's just to show you that,
that by having these networks of food sharing,

481
00:29:51.910 --> 00:29:56.680
right,
you insure against you failing on any given day,

482
00:29:56.681 --> 00:29:58.900
you can count on getting food from someone else.

483
00:29:59.470 --> 00:30:04.000
So this is also a very unusual thing that people do.
Right.
And,

484
00:30:04.030 --> 00:30:08.320
and this is part of the argument for this embodiment of yeah.

485
00:30:10.900 --> 00:30:15.850
Uh,
so the,
the red houses or are food insecure,
right?

486
00:30:15.851 --> 00:30:19.620
And the,
and the blue ones are food secure.
It's actually,
yeah,

487
00:30:19.840 --> 00:30:24.460
it's actually a very complicated graphic.
I just show it cause it's nice.
Uh,

488
00:30:25.600 --> 00:30:29.830
so those are a few,
few ways we manage uncertainty.

489
00:30:30.160 --> 00:30:34.570
But my main focus is on the evolution of our life cycles,
right?
How long we live,

490
00:30:35.350 --> 00:30:39.190
why we reproduce,
when we do the patterns of,
of reproduction,

491
00:30:39.850 --> 00:30:40.690
that sort of thing.

492
00:30:41.110 --> 00:30:45.940
And I would suggest uncertainties embodied fundamentally in our reproductive

493
00:30:45.941 --> 00:30:48.040
biology.
Humans are really unusual.

494
00:30:48.041 --> 00:30:50.440
I mentioned that we are peculiar in our life cycles.

495
00:30:50.980 --> 00:30:55.810
We have probably the latest age at first reproduction of any mammal.
Um,

496
00:30:56.170 --> 00:31:00.880
it's very late.
Uh,
we've got high fertility given how,

497
00:31:01.180 --> 00:31:04.390
you know,
we've got low fertility when you compare us to like a pig,
right?

498
00:31:04.780 --> 00:31:08.380
We have singletons and we spread them out pretty well.
And just pigs,

499
00:31:08.381 --> 00:31:11.860
we'll have a litter of 13 or piglets or whatever.
Right?

500
00:31:11.861 --> 00:31:16.420
But for our body size and for how late we begin reproducing,
we are,

501
00:31:16.480 --> 00:31:18.640
we are very fecund.
We,
uh,

502
00:31:18.670 --> 00:31:21.970
have a fertility rate that's about 50% higher than chimpanzees for instance.

503
00:31:21.971 --> 00:31:25.870
And natural fertility populations.
We have a super long reproductive span.

504
00:31:26.260 --> 00:31:31.260
You start reproducing at around age 20 or so and 45 50.

505
00:31:31.721 --> 00:31:35.710
That's a long time to be reproducing for any mammal.
Um,

506
00:31:35.730 --> 00:31:39.340
and we've got extensive periods of overlap of dependence.
And,
and I,

507
00:31:39.370 --> 00:31:41.950
this is another picture from Brian would among the Hadza,

508
00:31:42.310 --> 00:31:47.310
this beautiful Hadza a family with a mother with her for dependent children and

509
00:31:47.531 --> 00:31:52.531
her mother who allows her to keep these four beautiful children alive by

510
00:31:54.221 --> 00:31:58.880
subsidizing her foraging effort and her time and providing this,

511
00:31:58.910 --> 00:31:59.800
this babysitting.

512
00:32:00.160 --> 00:32:04.000
I think this picture embodies a lot of the peculiarities of the human life
cycle,

513
00:32:04.390 --> 00:32:07.960
uh,
among them include substantial post reproduction,

514
00:32:08.260 --> 00:32:09.790
post reproductive lifespan,
right?

515
00:32:09.790 --> 00:32:13.420
Which is something that most animals don't have.
So let's look a little,

516
00:32:13.421 --> 00:32:14.980
little data.
Uh,

517
00:32:14.981 --> 00:32:19.300
I've got a database of about 1400 mammal species here.
Uh,

518
00:32:19.510 --> 00:32:22.870
and I've just plotted things out as a function of body size.

519
00:32:23.590 --> 00:32:28.300
Biological things tend to scale with body size and,
and um,

520
00:32:28.720 --> 00:32:32.530
uh,
the,
the modal Mammo weighs about 50 grams,
right?

521
00:32:32.531 --> 00:32:34.720
So there are lots of little things,
there are fewer big things.

522
00:32:34.721 --> 00:32:37.030
That's one of those things that scales with body size.

523
00:32:37.390 --> 00:32:41.720
So you put these on double logarithmic axes and the red,
uh,

524
00:32:42.110 --> 00:32:43.730
points are primates.

525
00:32:44.390 --> 00:32:48.200
The black points are all other mammals and the green are humans.

526
00:32:48.230 --> 00:32:52.010
And so we can see that for,
uh,
our body mass.

527
00:32:52.011 --> 00:32:54.800
We have a very late age at first reproduction.

528
00:32:56.660 --> 00:33:01.660
We have a very long lifespan and we have low fertility,

529
00:33:02.870 --> 00:33:06.620
but we're not quite the same outlier that we are in age of first reproduction in

530
00:33:06.621 --> 00:33:07.454
lifespan.

531
00:33:07.790 --> 00:33:10.850
We're kind of in with all the other great apes in terms of our fertility.

532
00:33:11.390 --> 00:33:14.930
You don't really see how freakishly different we are,

533
00:33:14.931 --> 00:33:19.010
how weird we are until you start to combine the parameters.

534
00:33:19.011 --> 00:33:21.620
And this is also a sort of engineering kind of idea.

535
00:33:21.980 --> 00:33:25.310
You have these different parameters,
they have different,
different units on them.

536
00:33:25.520 --> 00:33:29.450
Let's combine them and make some dimensionless numbers and try to get out of the

537
00:33:29.451 --> 00:33:31.730
design features of the organism.
Okay.

538
00:33:32.150 --> 00:33:36.350
And this a life history theorist return off showed that,
uh,

539
00:33:36.950 --> 00:33:38.860
what I'm calling it's,
it's the,
um,

540
00:33:39.200 --> 00:33:43.300
it's the ratio of agent first reproduction to total reproductive lifespan.

541
00:33:43.520 --> 00:33:47.930
And I'm calling that relative lifespan is co is constant across mammals.

542
00:33:48.140 --> 00:33:52.520
Okay.
And we can see for,
I've got the four great apes here for the,
the,

543
00:33:52.540 --> 00:33:56.600
the three nonhuman grade eight eights.
You can see it's,
it's remarkably constant.

544
00:33:57.030 --> 00:34:00.110
Uh,
the same thing is true for the,
it's the product of age.

545
00:34:00.110 --> 00:34:02.000
At first we production in annual fertility,

546
00:34:02.120 --> 00:34:07.070
I've called it reproductive power here and it's a little more variable,
but it's,

547
00:34:07.071 --> 00:34:07.904
you know,

548
00:34:08.120 --> 00:34:11.870
constant enough for comparative biology considering these things are measured

549
00:34:11.871 --> 00:34:15.350
with a lot of slop.
How do humans fit in?
So our,

550
00:34:15.680 --> 00:34:19.550
our relative lifespan is really right in the ballpark of the great of the other

551
00:34:19.551 --> 00:34:22.190
great apes.
What about our reproductive power

552
00:34:24.110 --> 00:34:25.310
too?
Right?

553
00:34:25.340 --> 00:34:29.840
So way more than double what pretty much all the other mammals are.

554
00:34:30.350 --> 00:34:35.120
This is the thing that's really peculiar about humans.
So we live a long time,

555
00:34:35.270 --> 00:34:38.540
but we actually also make a lot of babies,
right?

556
00:34:38.541 --> 00:34:42.720
And those things typically don't go together.
Uh,

557
00:34:42.760 --> 00:34:46.550
I suggested that a few years back that this pattern,

558
00:34:46.551 --> 00:34:50.030
a very long life and very high reproductive powers consistent with a strategy

559
00:34:50.031 --> 00:34:54.710
known as bad hedging humans are bet hedgers the long generation length that

560
00:34:54.711 --> 00:34:59.150
comes from a late age of first reproduction and along reproductive span coupled

561
00:34:59.151 --> 00:35:02.390
with relatively high fertility means that you get the sample multiple

562
00:35:02.391 --> 00:35:06.170
environments.
Think back to the,
that plot of,
of,

563
00:35:06.200 --> 00:35:10.220
of temperature over time and you know,
zoom into a,

564
00:35:10.270 --> 00:35:14.000
a more local timescale.
It's varying quite a bit,
right?

565
00:35:14.001 --> 00:35:17.130
There's decadal scale variation that we know is going on in the place to seen in

566
00:35:17.150 --> 00:35:21.950
Africa.
And you,
if you could,
if you had great information,

567
00:35:22.220 --> 00:35:23.720
right?
You can say,
ah,

568
00:35:24.050 --> 00:35:27.470
I know that this is going to be a great year to reproduce and you could pile all

569
00:35:27.471 --> 00:35:32.030
your reproduction into it,
right?
But if you're wrong,
you're completely hosed,

570
00:35:32.031 --> 00:35:35.750
right?
Because you've put all your eggs in one basket,
right?

571
00:35:35.751 --> 00:35:38.340
Bed hedging is all about spreading out your risk,

572
00:35:39.000 --> 00:35:42.720
doing it a lot and trying to sample abroad temporal,
um,

573
00:35:42.830 --> 00:35:45.210
a series of environments.

574
00:35:46.470 --> 00:35:50.370
The essence of bed hedging is trading off the mean for reduction in fee and

575
00:35:50.371 --> 00:35:51.660
variants.
And I should mention,
you know,

576
00:35:51.750 --> 00:35:56.750
the term comes from the racetrack betting strategy where you bet at least a

577
00:35:57.121 --> 00:36:00.720
little money on every single horse in a race,
right?

578
00:36:00.960 --> 00:36:03.990
And what that means is that you're guaranteed to lose money every race,

579
00:36:04.260 --> 00:36:06.810
but you're also guaranteed not to lose it,
all right?

580
00:36:06.811 --> 00:36:10.050
Because some horse has to win and you know,

581
00:36:10.110 --> 00:36:12.090
you don't just like lay it out at random.

582
00:36:12.091 --> 00:36:14.490
Presumably you have an idea about which horse is going to win,

583
00:36:14.520 --> 00:36:19.020
but you had yourself.
Right?
And so hedging of course is,
is,
is,

584
00:36:19.530 --> 00:36:22.440
uh,
you know,
diversification in general.
It's right.

585
00:36:22.441 --> 00:36:25.110
It's the fundamental strategy for risk management.
Okay.

586
00:36:25.470 --> 00:36:30.470
But why hedge bets and why should humans in particular need to hedge

587
00:36:34.730 --> 00:36:38.850
my hedge humans inherited a legacy of slow reproduction from the Great Apes,

588
00:36:38.910 --> 00:36:39.381
right?
We,

589
00:36:39.381 --> 00:36:44.381
we come from this great apes stock and we have very low in the broader scheme of

590
00:36:44.911 --> 00:36:49.110
things,
reproductive capacity.
So under the best of circumstances,

591
00:36:49.111 --> 00:36:53.490
a chimpanzee population is going to grow at about 1% annually.

592
00:36:53.520 --> 00:36:57.870
If everything comes together just perfectly.
And the higher the growth rate,

593
00:36:57.871 --> 00:37:00.030
the less likely a population will go extinct.

594
00:37:00.900 --> 00:37:04.500
As humans moved into more variable Savannah woodland environments,

595
00:37:04.501 --> 00:37:08.780
they experience greater variance.
And you can show right the,

596
00:37:08.820 --> 00:37:12.960
that your long run expectation is essentially,
it's a function of your mean.

597
00:37:13.200 --> 00:37:14.820
That's also a function of your variance.

598
00:37:15.180 --> 00:37:17.970
Variance pushes you symmetrically around a mean.

599
00:37:18.330 --> 00:37:22.740
And when you have an absorbing boundary,
right?
That that's a bad thing.

600
00:37:22.741 --> 00:37:25.860
You want to avoid getting pushed around that mean,
right?

601
00:37:26.280 --> 00:37:29.520
So prolific reproduction is sort of the other way you do this.

602
00:37:29.521 --> 00:37:32.790
Like if you're a muscle or a sea urchin or something that lives in a highly

603
00:37:32.791 --> 00:37:35.940
variable like coastal intertidal,
right?
What do you do?

604
00:37:35.941 --> 00:37:38.460
You just produce millions of gametes.

605
00:37:39.030 --> 00:37:41.460
That's not an option for humans,
right?

606
00:37:41.461 --> 00:37:43.320
Because we inherit this legacy of the great apes.

607
00:37:43.321 --> 00:37:48.090
So we're trying to avoid us extinction given these enormous constraints on our

608
00:37:48.091 --> 00:37:50.790
reproductive biology.
And again,
another,

609
00:37:51.090 --> 00:37:53.640
another photo that I think really encapsulates so many of these,

610
00:37:54.120 --> 00:37:58.440
these challenges that humans have and the embodiment of uncertainty in our life

611
00:37:58.441 --> 00:38:03.030
histories,
uh,
is this incredible,
uh,
portrait fight by Dorothea Lange.

612
00:38:03.050 --> 00:38:06.150
It's iconic photograph of Oklahoma Dust Bowl refugees.

613
00:38:06.720 --> 00:38:10.200
And here's the mother in California with her infant son and,

614
00:38:10.290 --> 00:38:13.620
and I heard her infant and it hurts her young school age son.

615
00:38:15.480 --> 00:38:19.620
This is weird.
I,
I'm just,
I,
we take it for granted because it's,
it's humans.

616
00:38:19.621 --> 00:38:23.040
You know,
you expect it.
A young mother has,
has a bunch of young kids,

617
00:38:23.550 --> 00:38:24.361
but it's really weird.

618
00:38:24.361 --> 00:38:29.160
A chimpanzee mother birth intervals of about five and a half years in Gombe

619
00:38:29.161 --> 00:38:33.630
national park in Tanzania and other places where I've worked.
Um,

620
00:38:34.780 --> 00:38:35.770
and uh,

621
00:38:36.790 --> 00:38:41.260
she will wean her infant that starts that in her hole right at about age five,

622
00:38:41.261 --> 00:38:42.094
four or five.

623
00:38:42.460 --> 00:38:46.030
And she will then never invest in that child again and economically,

624
00:38:46.031 --> 00:38:48.370
she will never share food with that child again.

625
00:38:48.400 --> 00:38:53.320
She will never nurse that child again.
Could you imagine doing that to this?
Good.

626
00:38:53.321 --> 00:38:56.770
Sorry,
five year old,
we've got a new baby.

627
00:38:57.370 --> 00:39:01.030
You got to make it on your own.
Right?
That's not an option for human.

628
00:39:01.570 --> 00:39:04.600
Even those of you who haven't had kids probably know that,
right?

629
00:39:05.560 --> 00:39:08.290
Sometimes you wonder with Stanford Students,
right?
You have to explain that,

630
00:39:08.291 --> 00:39:12.520
that that won't work.
But you know,
I assume you guys know,
um,

631
00:39:12.880 --> 00:39:16.300
so allocation does,
uncertainty is embodied in our very reproductive biology.

632
00:39:16.630 --> 00:39:17.800
Given its central importance.

633
00:39:17.801 --> 00:39:22.630
It probably comes into our economic decision making as well.
Now I'm going to,

634
00:39:23.020 --> 00:39:27.390
I don't have much time left.
I'm going to talk about too,
um,

635
00:39:27.730 --> 00:39:30.610
specific applications very quickly.
Um,

636
00:39:31.720 --> 00:39:36.720
so here is a schematic model and I just put in the types of economic decisions.

637
00:39:36.850 --> 00:39:38.710
I tend to think about as a reminder,

638
00:39:38.980 --> 00:39:42.840
we've got these four economic decisions are lotteries in the sense that they,

639
00:39:42.841 --> 00:39:45.580
they,
uh,
they have variable payoffs,
right?

640
00:39:45.581 --> 00:39:49.420
These are decisions that have variable payoffs and we call them lotteries.

641
00:39:49.720 --> 00:39:53.410
And in the standard economic analysis,

642
00:39:53.411 --> 00:39:57.310
you have these different lotteries and they get aggregated by a thing called

643
00:39:57.311 --> 00:40:01.450
utility.
Okay?
The utility,
uh,
aggregates,

644
00:40:01.451 --> 00:40:04.210
it averages over these things.
And you're trying to maximize that.

645
00:40:04.780 --> 00:40:07.360
And when people start thinking about,
well,

646
00:40:07.361 --> 00:40:10.180
how do we mix economics and evolutionary biology,

647
00:40:10.420 --> 00:40:14.740
it's tempting to first simply substitute fitness for,

648
00:40:14.741 --> 00:40:18.430
for utility.
But that's wrong for two reasons.
First,
no one.

649
00:40:18.431 --> 00:40:21.970
But sociopath's thinks about maximizing their fitness.
You know,
you say,
Oh,

650
00:40:21.971 --> 00:40:25.840
I must have more babies.
And they,
you know,
and the,
and I must compete with,

651
00:40:25.841 --> 00:40:28.270
you know,
people don't think that way.
That's not,

652
00:40:28.690 --> 00:40:31.600
that's not something that's about,
you know,

653
00:40:31.601 --> 00:40:36.280
sort of fitting into the observations.
Again.
Uh,
but second,
and more importantly,

654
00:40:37.220 --> 00:40:39.820
it would be a terrible control variable for your,

655
00:40:39.821 --> 00:40:44.140
for your behavior because fitness is measured at a timescale that's basically

656
00:40:44.141 --> 00:40:46.210
greater than a human lifespan,
right?

657
00:40:46.420 --> 00:40:48.730
It's about your contribution to future generations.

658
00:40:49.090 --> 00:40:53.560
You can't sit there and have a real time feed of your fitness,
right?

659
00:40:53.980 --> 00:40:57.840
You need something more proximate,
uh,
to,
to,
uh,

660
00:40:57.850 --> 00:41:02.680
use fitness ends up being the arbiter of what things work and what things don't.

661
00:41:02.681 --> 00:41:04.670
But you want to have something proximate that you,

662
00:41:04.720 --> 00:41:09.310
that you can use as a control variable,
okay.
Uh,
to,

663
00:41:09.311 --> 00:41:13.810
to respond,
to adopt a adaptively to a changing environment.
All right?

664
00:41:13.811 --> 00:41:16.760
So,
uh,
utility,
uh,

665
00:41:16.850 --> 00:41:20.320
in the standard economic model aggregates over average and averages over

666
00:41:20.321 --> 00:41:23.960
different lotteries nor model that I've already shown you,
right?

667
00:41:24.250 --> 00:41:25.660
The lotteries are still there.

668
00:41:26.590 --> 00:41:29.950
We've got these aggregators that approximate level,
these are these,

669
00:41:30.040 --> 00:41:33.440
these and these sort of,
um,
uh,

670
00:41:33.620 --> 00:41:38.240
these proximate motivational systems,
satiety,
sexual satisfaction,

671
00:41:38.241 --> 00:41:41.150
love of your children,
what,
you know,
whatever,
whatever they are.

672
00:41:41.150 --> 00:41:42.740
But what matters is that they are,

673
00:41:42.890 --> 00:41:47.890
are things that you can use to guide your decisions right over how,

674
00:41:48.110 --> 00:41:52.190
how you decide to mix your,
your uh,
your market basket for example.

675
00:41:52.670 --> 00:41:57.080
And then fitness is the thing that aggregates over the top of this.
This is a,

676
00:41:57.081 --> 00:42:02.081
a model hierarchical model that Mike Price and I put together and we've done a

677
00:42:02.691 --> 00:42:03.351
bunch of things with it.

678
00:42:03.351 --> 00:42:06.710
It turns out there a system of equations that underlying us.
We can put some,

679
00:42:06.711 --> 00:42:07.160
some,

680
00:42:07.160 --> 00:42:10.670
some constraints on there and there's actually a whole talk where I talk about

681
00:42:10.671 --> 00:42:12.550
the constraints cause it's,
it's,

682
00:42:12.560 --> 00:42:15.800
it's sort of surprising and interesting where they come from.
Um,

683
00:42:16.430 --> 00:42:17.360
and we have results.

684
00:42:17.630 --> 00:42:21.570
Here are three very quickly distortion of decision weights,

685
00:42:21.790 --> 00:42:24.680
kind of like prospect theory.
If,
if the,
you know,

686
00:42:24.681 --> 00:42:28.430
the standard economic analysis when you have a risky decision to make is that

687
00:42:28.431 --> 00:42:33.020
you're trying to maximize the expected value of your utility and thinking about

688
00:42:33.021 --> 00:42:34.280
what expected value means.

689
00:42:34.280 --> 00:42:37.220
It means that you have a linear combination of some weights.

690
00:42:37.640 --> 00:42:40.710
They happen to be probabilities,
but their decision weights and,

691
00:42:40.740 --> 00:42:42.950
and some outcomes,
right?
It's a linear combination.

692
00:42:43.250 --> 00:42:48.250
It looks like people aren't putting together linear combinations of weights and,

693
00:42:48.531 --> 00:42:53.190
and outcomes.
Okay.
They're using some sort of weird curvilinear thing that,
uh,

694
00:42:53.390 --> 00:42:55.040
Kahneman and Tversky have suggested looks,

695
00:42:55.070 --> 00:42:58.400
looks Kinda like that when we use,

696
00:42:58.430 --> 00:43:02.030
when we use fitness as a,
as a criterion,

697
00:43:02.031 --> 00:43:04.340
as a objective function,
right?

698
00:43:04.341 --> 00:43:08.720
What we get is decision weights that curve like that.
Okay.
So that was cool.

699
00:43:09.060 --> 00:43:12.980
Uh,
another thing is high risk aversion among the poorest people.

700
00:43:12.981 --> 00:43:15.280
There's this idea,
it's kind of this folklore,

701
00:43:15.290 --> 00:43:19.220
I think that that poor people have nothing to lose somehow,
you know,

702
00:43:19.221 --> 00:43:22.280
in the sense that they're very resource poor and so they should be willing,

703
00:43:22.281 --> 00:43:24.020
they're natural entrepreneurs,
right?

704
00:43:24.021 --> 00:43:27.710
They should be willing to take risks because when they got to lose,
well,

705
00:43:27.711 --> 00:43:30.160
what they have to lose when you think of us as,

706
00:43:30.190 --> 00:43:33.170
as biological entities is they have everything to lose,
right?

707
00:43:33.410 --> 00:43:37.520
They're poor and just,
uh,
and,
and so if their,

708
00:43:37.550 --> 00:43:39.200
if their financial decisions,

709
00:43:39.201 --> 00:43:44.140
if their economic decisions have an impact on their survivability,
then uh,

710
00:43:44.240 --> 00:43:47.420
we should expect them to be actually risk averse.
And in this framework,

711
00:43:47.630 --> 00:43:50.690
it turns out that they're extremely risk averse.
Okay.

712
00:43:51.470 --> 00:43:53.750
And then finally,
uh,

713
00:43:53.960 --> 00:43:58.520
we can recover without any sort of active choice.
These,

714
00:43:58.521 --> 00:44:00.570
the what looked like preference reversals,

715
00:44:00.580 --> 00:44:03.320
some of the classic paradoxes of choice that came about in the,

716
00:44:03.321 --> 00:44:07.490
in the 1950s that's a little more technical,
but it's a cool result to,

717
00:44:07.940 --> 00:44:08.773
um,

718
00:44:10.910 --> 00:44:14.750
just want to remind you as I get to my last point here about the diversity of

719
00:44:14.751 --> 00:44:17.570
habitats that humans live in,
right?

720
00:44:18.470 --> 00:44:22.460
We come out onto the Savannah.
We can live in these,

721
00:44:22.610 --> 00:44:26.990
in these mixed rain forest.
Agricultural lands is in Uganda.
Again,

722
00:44:27.590 --> 00:44:31.730
we live in the Tundra,
right?
And the art inside the Arctic Circle.
Harrison,

723
00:44:31.790 --> 00:44:36.690
some Venezuela and Yanos home of swamps and big snakes.

724
00:44:36.691 --> 00:44:40.050
Right?
This is where anacondas live.
Um,
people are very,

725
00:44:40.051 --> 00:44:43.170
they're very successful hunter gatherers who live there.
We live on the,

726
00:44:43.330 --> 00:44:46.440
the coastal shore as Fisher Fisher folk.

727
00:44:46.800 --> 00:44:49.890
We live on temperate prairie's,
right.

728
00:44:50.070 --> 00:44:54.680
We have a wide variety of,
of habitats and presumably are,

729
00:44:54.681 --> 00:44:56.070
are sort of choice.

730
00:44:56.071 --> 00:45:00.120
Calculus should be a little different depending on where we're actually making

731
00:45:00.121 --> 00:45:03.540
our decisions.
So as generalists with tremendous capacity to learn,

732
00:45:03.541 --> 00:45:05.250
it seems reasonable to suppose that human,

733
00:45:05.280 --> 00:45:08.790
the human capacity to make rational decisions has an ontogeny,
right?

734
00:45:08.791 --> 00:45:12.630
Meaning it has a development,
you have to learn a little bit about it.
Okay.

735
00:45:13.660 --> 00:45:14.370
And I've,

736
00:45:14.370 --> 00:45:17.970
I've developed a simple model of learning about one's uncertain environment that

737
00:45:17.971 --> 00:45:20.550
helps understand one of the most vexing results in,

738
00:45:20.551 --> 00:45:25.500
in this irrationality literature,
which is inconsistent time preferences,

739
00:45:25.830 --> 00:45:29.580
right?
The fact that we,
we,
we value,
uh,

740
00:45:29.610 --> 00:45:33.690
like waiting a day differently,
whether it's today or whether it's next year,

741
00:45:33.810 --> 00:45:37.440
right?
We care a lot about waiting from today til tomorrow,

742
00:45:37.470 --> 00:45:40.770
but we don't care that much at all,
you know,
a year,
a year,

743
00:45:40.771 --> 00:45:43.590
and a day from now or whatever it's,
it's a year from now.

744
00:45:43.950 --> 00:45:48.030
This drives economists crazy.
Right?
It may seem common sense to people.

745
00:45:48.420 --> 00:45:52.370
I think that that's an interesting insight.
Um,
but it does drive economist crazy.

746
00:45:52.380 --> 00:45:54.840
It's one of the fundamental,
uh,
anomalies.

747
00:45:55.200 --> 00:45:59.340
So I have a simple model of,
of,
uh,

748
00:45:59.940 --> 00:46:03.060
that has basically four parts.
The first is that your time preferences?

749
00:46:03.061 --> 00:46:06.360
Why do we care about the present more than the future?
Well,

750
00:46:06.361 --> 00:46:09.270
a reasonable way to think about that is because there's,

751
00:46:09.300 --> 00:46:12.320
there's the chance that you might die before you recover.

752
00:46:12.321 --> 00:46:17.190
A reward that you delay or less dramatically that reward might go away,
right?

753
00:46:17.191 --> 00:46:21.780
Your friend might forget or it might be a resource that that,
uh,

754
00:46:21.870 --> 00:46:26.760
gets swooped on,
right?
So there's a,
there's a hazard of failure,

755
00:46:27.110 --> 00:46:27.851
uh,
of,

756
00:46:27.851 --> 00:46:32.851
of this resource and you can then have a time consistent prior,

757
00:46:33.720 --> 00:46:38.060
which is like an exponential distribution,
right?
That you value all,

758
00:46:38.390 --> 00:46:42.360
all delays,
uh,
of the same,
same amount,
by the same,

759
00:46:42.750 --> 00:46:45.930
by the same amount.
That's your prior distribution,
right?

760
00:46:45.990 --> 00:46:50.220
Consistent with the prior,
you can then go out and learn about the environment,

761
00:46:50.580 --> 00:46:54.360
but a lot of these important economic decisions,
things about like how,

762
00:46:55.170 --> 00:46:59.930
how what you plant this year yields,
you're your yield.
I,

763
00:46:59.980 --> 00:47:02.310
you know,
nine months from now,
a year from now,

764
00:47:02.640 --> 00:47:05.280
you don't have a lot of opportunities as a kid to learn about that.

765
00:47:05.281 --> 00:47:06.114
You have a few,

766
00:47:06.450 --> 00:47:09.390
so you're probably at best going to learn about it with uncertainty when you

767
00:47:09.391 --> 00:47:13.740
integrate the uncertainty of it.
So the posterior,
it looks pretty good here,

768
00:47:13.770 --> 00:47:18.440
right?
I figured,
again,
I'm on fairly safe ground Google based,
right?
Um,

769
00:47:18.810 --> 00:47:20.190
your posterial looks pretty good,

770
00:47:20.191 --> 00:47:22.810
but in fact when you integrate it to give us your personal,

771
00:47:22.811 --> 00:47:24.360
your predictive distribution,

772
00:47:25.020 --> 00:47:29.680
all of a sudden you've got all of that uncertainty that that causes this big,

773
00:47:30.470 --> 00:47:32.470
um,
plateau here.

774
00:47:32.560 --> 00:47:36.730
And it essentially turns into what's known as hyperbolic discounting,
right?

775
00:47:36.731 --> 00:47:40.450
So it's an inconsistency in time preference because you've got this fat tail

776
00:47:40.451 --> 00:47:43.840
that you have to integrate over.
So,
uh,

777
00:47:45.100 --> 00:47:47.770
uncertainly in discount rate leads to inconsistent time preferences.

778
00:47:47.771 --> 00:47:50.980
There is the exponential production,
right?

779
00:47:50.981 --> 00:47:53.590
The discount rate with no uncertainty is exponential.

780
00:47:53.680 --> 00:47:58.150
You add uncertainty and what you get is essentially the,
uh,

781
00:47:58.180 --> 00:47:59.620
this hyperbolic function.

782
00:47:59.621 --> 00:48:02.290
I was really excited when I read it because it's really simple model,
right?

783
00:48:02.291 --> 00:48:05.650
It's just a,
it's just a simple little Bayesean model.
I was like,
wow,

784
00:48:05.651 --> 00:48:08.100
I really nailed it this time.
It turns out.
Then I,

785
00:48:08.101 --> 00:48:10.870
I then went back to the literature.
It turns out a bunch of people who said it,

786
00:48:11.970 --> 00:48:15.280
this is always a bitter sweet moment.
On the one hand you're like,
damn,

787
00:48:15.310 --> 00:48:17.740
I thought it was so original.
But on the other hand,

788
00:48:17.741 --> 00:48:20.800
it means that I had the same good idea that Partha Dasgupta had.

789
00:48:20.830 --> 00:48:25.390
And that's always a good thing,
right?
So you know,
you win some,
you lose some.

790
00:48:25.750 --> 00:48:27.460
So I'm going to give you three takeaways.

791
00:48:28.270 --> 00:48:32.530
Maximizing fitness distorts economic choices,
right?
We,

792
00:48:32.531 --> 00:48:36.680
we've seen this repeatedly,
but it maximizes fitness,
right?
And that's the,

793
00:48:36.681 --> 00:48:40.330
that's the direction that selection is going to push the population.

794
00:48:41.230 --> 00:48:44.500
Uncertainty changes,
optimality predictions.
Qualitatively,

795
00:48:44.860 --> 00:48:48.250
when you put uncertainty into the game,
you get different answers.

796
00:48:49.540 --> 00:48:52.960
And that evolutionary theory has promised for providing a comprehensive theory

797
00:48:52.961 --> 00:48:55.420
of choice.
It's very much a work in progress.

798
00:48:55.840 --> 00:48:57.370
I'm excited about the potential here.

799
00:48:57.371 --> 00:49:00.100
I'm going to excited about trying to recruit some more people to work on this.

800
00:49:00.760 --> 00:49:03.730
And I had to thank you for your time and I'm happy to entertain.

801
00:49:05.050 --> 00:49:05.883
<v 2>Yeah.</v>

802
00:49:12.080 --> 00:49:16.100
<v 3>Hello.
So,
um,
I am a,
it's the question about,
uh,</v>

803
00:49:16.580 --> 00:49:19.820
the role of like social signaling and economic decisions.

804
00:49:19.821 --> 00:49:22.550
I'm thinking there's two,
there's that game economic,

805
00:49:22.610 --> 00:49:25.700
economic economist like to point to is a rational where,
you know,

806
00:49:26.360 --> 00:49:29.750
two people can split a pile of money.
It makes an offer.

807
00:49:29.751 --> 00:49:32.720
The other accepts or rejects.
Yep.
Yep.
Typically,
if it's asymmetric,

808
00:49:32.721 --> 00:49:36.380
second one will reject and no one wins anything.
Yeah.
Um,

809
00:49:36.410 --> 00:49:40.790
which to me it seems like that's because like a tribal environment,

810
00:49:40.791 --> 00:49:43.480
you're trying to teach other people,
you know,
don't try it.

811
00:49:43.600 --> 00:49:46.090
<v 0>Costly punishment.
Absolutely.
Yeah.
I mean,</v>

812
00:49:46.300 --> 00:49:51.300
so this is another area that has actually gotten a lot more attention I think

813
00:49:51.671 --> 00:49:54.450
from evolutionary anthropologists and evolutionary biologists is,

814
00:49:54.460 --> 00:49:58.060
is what's sometimes called our pro sociality,
right?

815
00:49:58.061 --> 00:50:02.110
This intense social sociality that we have that's reflected in these food

816
00:50:02.111 --> 00:50:03.310
sharing networks.
Right.

817
00:50:03.580 --> 00:50:08.110
But that we have the psychology of we don't like unfairness.
Right.

818
00:50:08.140 --> 00:50:12.460
And,
and,
uh,
and when you play the dictator game,
right,
you,
you,

819
00:50:12.461 --> 00:50:16.030
you punish people,
uh,
w w who don't give fair,

820
00:50:16.060 --> 00:50:18.760
what you perceive to be fair offers and that presumably this,

821
00:50:18.940 --> 00:50:20.140
this relates to this,

822
00:50:20.170 --> 00:50:25.170
this need for ensuring cooperation and small scale societies and punishing

823
00:50:26.351 --> 00:50:27.184
cheaters.

824
00:50:28.340 --> 00:50:30.200
<v 2>Yeah.
Thanks for that</v>

825
00:50:36.290 --> 00:50:37.950
<v 3>question.
Related question.</v>

826
00:50:37.951 --> 00:50:41.390
So if we're really concerned about comfort and survival and things like that,

827
00:50:41.780 --> 00:50:46.250
it's amazing that humans will migrate to some of the most uncomfortable places

828
00:50:46.790 --> 00:50:50.990
and will willingly venture out with why would a rational creature and go to the

829
00:50:50.990 --> 00:50:55.010
South Pole,
go to the moon,
go to Mars,
the interest,
they're not very pleasant.

830
00:50:55.630 --> 00:50:56.463
Um,

831
00:50:57.320 --> 00:51:02.320
do we as creatures is going to be rather curious that make us different from

832
00:51:02.331 --> 00:51:02.890
other animals?

833
00:51:02.890 --> 00:51:03.723
<v 2>Yes.</v>

834
00:51:04.340 --> 00:51:04.960
<v 0>You know,
there are a lot,</v>

835
00:51:04.960 --> 00:51:09.830
I think that anything that makes its living as a generalist is,
is,

836
00:51:09.880 --> 00:51:13.480
is going to be curious.
I mean,
lots,
lots of primates are super curious,
right?

837
00:51:13.481 --> 00:51:18.250
I mean,
if,
if you live around here and you have a,
like,
like French doors,

838
00:51:18.251 --> 00:51:22.600
you've possibly seen raccoons at your door to sort of like looking in like,
hey,

839
00:51:22.601 --> 00:51:27.070
what's going on in there?
Right.
So I don't know if curiosity,
we certainly,

840
00:51:27.071 --> 00:51:31.720
I think take curiosity into another level.
All of those things.
Uh,
you know,

841
00:51:31.721 --> 00:51:35.170
if you go to Mars and you come back,
that's a pretty high status thing to do,

842
00:51:35.171 --> 00:51:39.280
right?
You,
you,
you,
you have,
you have a social signaling going on right?

843
00:51:39.430 --> 00:51:43.270
If you come back now,
right.
And,
and if you think about my,

844
00:51:43.330 --> 00:51:44.890
my Bayesean model,
right,

845
00:51:44.891 --> 00:51:48.610
how many opportunities do you have to learn about what the actual hazard is?

846
00:51:49.090 --> 00:51:52.210
You know,
supposedly I have a,
like a really flat prior,
you know,

847
00:51:52.480 --> 00:51:56.980
you've never seen anyone go to Mars,
so,
you know,
it could be anything.
Right.

848
00:51:57.310 --> 00:52:01.900
Um,
so I think that that sort of explains some of the,
the,

849
00:52:01.930 --> 00:52:06.930
the unusual sort of decisions that people seem to make moving into the Arctic

850
00:52:07.211 --> 00:52:10.390
to,
to,
uh,
to live.
Right.

851
00:52:10.630 --> 00:52:13.940
It may seem uncomfortable to us,
but you know,
if you're in Yoga,

852
00:52:14.050 --> 00:52:18.880
you do pretty well in general,
right.
And,
and,
uh,
you know,

853
00:52:18.881 --> 00:52:23.860
the,
there's a living to be made there and,
and people are incredibly adaptable.

854
00:52:24.770 --> 00:52:26.780
<v 3>Question,
thanks for the talk.</v>

855
00:52:27.230 --> 00:52:32.230
Do you see any other species that have environment involved in uncertain

856
00:52:33.231 --> 00:52:36.920
environments that share a similar pattern in reproductive power or other

857
00:52:37.220 --> 00:52:37.950
characteristics?

858
00:52:37.950 --> 00:52:41.670
<v 0>Yeah,
that's a great question.
Um,
I don't really know.
There's,</v>

859
00:52:41.700 --> 00:52:46.440
there is a sort of the classic bet hedgers are there a bunch of birds?

860
00:52:46.441 --> 00:52:50.310
Like again,
local environment,
red tail hawks,
right?
So a lot of,

861
00:52:50.340 --> 00:52:51.390
a lot of the raptors,

862
00:52:51.750 --> 00:52:55.770
we'll do this thing that really kind of perplexing at face value.

863
00:52:56.130 --> 00:52:58.170
They'll lay clutches of two eggs,

864
00:52:58.680 --> 00:53:02.150
but only one will ever fledge.
Right.
And,

865
00:53:02.160 --> 00:53:04.350
and it seems incredibly wasteful.
Right.

866
00:53:04.770 --> 00:53:08.700
And it's a classic bed hedging thing.
If that first one fails,

867
00:53:08.970 --> 00:53:12.990
then the second one is there.
Right.
And,
and the cost,

868
00:53:13.230 --> 00:53:15.090
you're paying a little bit of your mean,
you know,

869
00:53:15.091 --> 00:53:18.390
you're paying out a little insurance policy,
right.

870
00:53:18.391 --> 00:53:21.270
For catastrophic to insure against catastrophic failure.

871
00:53:21.600 --> 00:53:26.150
So there are lots of birds that engage in this type of bed.
Um,

872
00:53:26.520 --> 00:53:30.750
reproductive power,
uh,
as I've called it,
I've not seen it in any mammal.

873
00:53:31.260 --> 00:53:34.590
It's possible it exists in other,
but you know,
the way the,
the,

874
00:53:34.591 --> 00:53:38.400
the churn off model works.
It,
you have to,
for this model,
you have to be a mammal.

875
00:53:38.460 --> 00:53:39.960
Like you could come up with,

876
00:53:39.961 --> 00:53:44.961
with these sort of dimensionalist design features of different life histories,

877
00:53:45.360 --> 00:53:46.680
but it only works for,
you know,

878
00:53:46.681 --> 00:53:49.800
if you have the same kind of general reproductive biology.

879
00:53:51.180 --> 00:53:53.780
<v 4>Yeah.
So in,
in light of your research,</v>

880
00:53:54.740 --> 00:53:57.470
maybe academically you wouldn't make any recommendations like this been

881
00:53:57.920 --> 00:53:58.401
personally,

882
00:53:58.401 --> 00:54:03.401
do you have recommendations on how to motivate people psychologically in

883
00:54:03.951 --> 00:54:08.430
collectively to address issues like climate change?
You know,

884
00:54:08.570 --> 00:54:12.990
we're feeling in the present now will be feeling a lot more with other,
well,

885
00:54:12.990 --> 00:54:17.040
<v 0>I have,
I have pretty strong opinions about the way we value the future.</v>

886
00:54:17.041 --> 00:54:21.600
And I think that,
um,
you know,
it,
it seems,

887
00:54:22.770 --> 00:54:27.120
you know,
like a,
it's a,
it's a bit of a moral argument.
But,
um,
when we say,

888
00:54:27.121 --> 00:54:30.300
you know,
we want to take some steps to mitigate climate change.

889
00:54:30.301 --> 00:54:33.300
Now whenever we do a cost benefit analysis,

890
00:54:33.301 --> 00:54:37.680
what's going to happen is that you're going to take a discount rate,
right?
Uh,
of,

891
00:54:37.740 --> 00:54:41.400
of the value of,
of,
of an investment today,
you know,

892
00:54:41.760 --> 00:54:44.790
a couple of hundred years in the future.
And that's,
that's the real rub.

893
00:54:44.791 --> 00:54:48.660
It's both that the fact that,
uh,
you're,
you're,

894
00:54:48.661 --> 00:54:51.480
you're valuing the president more than the future,
but you're also,

895
00:54:51.780 --> 00:54:54.750
all these things play out at very long time scales.

896
00:54:55.170 --> 00:54:59.210
So you throw in a 4% discount rate and you know,

897
00:54:59.250 --> 00:55:02.430
it's very difficult to come up with a cost benefit analysis that favors

898
00:55:02.431 --> 00:55:06.180
mitigation.
Now with a 4% discount rate that pays out,
you know,

899
00:55:06.181 --> 00:55:10.790
its benefits in 200 years.
So I think,
and I'm not alone in this,
there,

900
00:55:10.791 --> 00:55:13.080
there are a bunch of environmental economists who,

901
00:55:13.081 --> 00:55:16.260
who are engaged in a very vigorous debate on this,

902
00:55:16.530 --> 00:55:19.370
that we should use much lower discount rates,
uh,

903
00:55:19.470 --> 00:55:24.290
for thinking about cost benefit analysis with these long payoffs.
Uh,

904
00:55:24.330 --> 00:55:29.330
Martin Weitzman at Harvard is suggested using the absolute lowest discount rate

905
00:55:29.551 --> 00:55:34.050
that you can,
that you can imagine,
uh,
that that makes it tenable,
um,

906
00:55:34.110 --> 00:55:38.050
because of this problem,
right?
Um,
and because the,

907
00:55:38.051 --> 00:55:41.970
the tail risk of these outcomes are so huge,
right?

908
00:55:42.570 --> 00:55:47.310
Um,
so that's something I take away from this.

909
00:55:47.311 --> 00:55:50.280
Like,
like,
uh,

910
00:55:50.340 --> 00:55:54.510
don't overvalue the present,
but it's easy for me to do that.

911
00:55:54.511 --> 00:55:59.040
I live in Palo Alto,
right?
We all live in pretty predictable environments,
right?

912
00:55:59.400 --> 00:56:02.370
We're quite privileged people and it's easy to say,
well you know,

913
00:56:02.371 --> 00:56:04.020
we shouldn't really value the future.

914
00:56:04.520 --> 00:56:08.760
And this is some of the work that my colleagues who I showed you briefly I've

915
00:56:08.761 --> 00:56:11.370
done showing that,
you know,
if you're a poor,

916
00:56:11.610 --> 00:56:15.480
so like they're the classic marshmallow experiments that were done here at

917
00:56:15.481 --> 00:56:19.680
Stanford,
right?
And you know,
give a kid a marshmallow and walkaway,
say,

918
00:56:19.770 --> 00:56:23.130
don't eat that.
Right?
Cause if you do,
that's all you're getting.

919
00:56:23.440 --> 00:56:26.650
But if it's still there when I come back and get to right,

920
00:56:26.880 --> 00:56:30.310
and you walk away and it turns out that you know,
these kids who struggle to,

921
00:56:30.311 --> 00:56:32.110
they're looking at this marshmallow,
then I think,
oh God,

922
00:56:32.111 --> 00:56:33.640
I want eat the marshmallow.
So Dad,
right?

923
00:56:34.060 --> 00:56:36.430
It turns out that it correlates very well.
The,

924
00:56:36.431 --> 00:56:39.940
your ability to put off that reward and get the larger reward after a little

925
00:56:39.941 --> 00:56:44.080
delay predicts a lot of things about your success in,
in,
in life.

926
00:56:44.560 --> 00:56:47.980
Um,
it's really hard.

927
00:56:49.030 --> 00:56:52.940
Anthropologists have found it really hard to go into places and,

928
00:56:53.020 --> 00:56:56.440
and replicate these types of economic games that we play all the time,
including,

929
00:56:56.441 --> 00:56:58.930
you know,
that dictator games.
And these,
these,

930
00:56:58.931 --> 00:57:03.430
these things that we talked about before,
um,
in part because people are like,

931
00:57:03.520 --> 00:57:07.600
how do I know you're going to be back with your two marshmallows that you talked

932
00:57:07.601 --> 00:57:10.930
about?
I had to take that one right now.
Thank you very much.
Right?

933
00:57:11.230 --> 00:57:15.340
And so that's just a cautionary tale that it's easy for me to say we should

934
00:57:15.341 --> 00:57:18.020
value the future more because,
you know,
I,

935
00:57:18.090 --> 00:57:22.640
I have a pretty low discount rate because,
you know,
I live in Palo Alto.
Um,

936
00:57:23.800 --> 00:57:28.570
as a society I think we should be modeling,
uh,
the,
uh,

937
00:57:28.630 --> 00:57:32.620
the future,
um,
uh,
valuing the future more than we do.

938
00:57:34.030 --> 00:57:38.410
That's a really long answer to pretty straight forward question.
Um,

939
00:57:39.010 --> 00:57:39.843
yeah.
Okay.

940
00:57:40.630 --> 00:57:41.463
<v 4>Yeah.</v>

941
00:57:45.970 --> 00:57:50.440
Vietnam and get 7 million people.
Yeah.

942
00:57:53.400 --> 00:57:57.450
<v 0>Yeah.
It's really,
I mean,
that's a vexing problem,
right?
That,</v>

943
00:57:57.451 --> 00:58:00.750
that we sort of develop these,
these,
uh,

944
00:58:00.930 --> 00:58:04.920
these ingroup and outgroup identities and that they probably are very functional

945
00:58:04.921 --> 00:58:07.710
when you live in a band like society because you know,

946
00:58:07.711 --> 00:58:10.050
you're in group is really your everything,
right?

947
00:58:10.620 --> 00:58:15.410
It's maybe not so functional when,
uh,
when you're,
you're,
you make,
you know,

948
00:58:15.420 --> 00:58:19.590
the rest of the world,
your outgroup right.
And,
and you know,

949
00:58:19.591 --> 00:58:23.550
the same sort of rules of morality don't apply to them and that sort of thing.

950
00:58:23.880 --> 00:58:28.530
Um,
that's a real problem.
And,
and I,
and solving that,
you know,

951
00:58:28.531 --> 00:58:32.040
there's,
there's a prize for someone,
right?
Uh,
is,

952
00:58:32.080 --> 00:58:35.410
is if we can figure out how to really begin to address that.
Um,

953
00:58:36.150 --> 00:58:38.760
equally importantly in the world we live in,

954
00:58:40.140 --> 00:58:45.140
when you're a peasant farmer and you plant yams and,

955
00:58:46.251 --> 00:58:49.290
and you know,
some maize and whatever,
you know,
you sort of,

956
00:58:49.740 --> 00:58:53.450
you place your bet and then you tend to it and,

957
00:58:53.451 --> 00:58:57.390
and you hopefully get a big payoff,
right?
There's a direct

958
00:58:58.920 --> 00:59:03.870
causal interpretation of what you do and what you get in the world we live in,

959
00:59:04.320 --> 00:59:08.400
we have all this complexity and we don't necessarily pay the costs for bad

960
00:59:08.401 --> 00:59:09.360
decisions right away.

961
00:59:09.361 --> 00:59:13.620
And I think that makes it very hard to learn about good decision making.

962
00:59:14.160 --> 00:59:15.690
Right?
And so,
uh,

963
00:59:15.720 --> 00:59:19.080
there are a number of people who have developed sort of the curricula for

964
00:59:19.110 --> 00:59:23.180
teaching kids how to,
how to make risky decisions.
I think that,
um,

965
00:59:24.440 --> 00:59:27.980
giving kids some responsibility and getting them some skin in the game is a

966
00:59:27.981 --> 00:59:31.070
really important thing.
So that's a little off of,
of your question,

967
00:59:31.071 --> 00:59:34.580
but I think that that's another real challenge to thinking about how our brains

968
00:59:34.581 --> 00:59:38.120
were designed to make decisions and the types of environments in which we have

969
00:59:38.121 --> 00:59:41.480
to do it now.
Many of us.
Yeah.

970
00:59:42.800 --> 00:59:46.490
<v 4>If we predict greatly increased variability in the near future,</v>

971
00:59:46.850 --> 00:59:50.990
what would you predict,
uh,
with those functions,
eg longing,

972
00:59:52.140 --> 00:59:54.350
longevity or things like that?

973
00:59:57.620 --> 01:00:02.210
<v 0>Well,
first of all,
we have to get through this possible bottleneck,</v>

974
01:00:02.211 --> 01:00:04.470
right?
Um,
and,

975
01:00:04.600 --> 01:00:09.200
and I say that flippantly because I otherwise I just descend into depression.

976
01:00:09.201 --> 01:00:14.150
Right?
Uh,
I'm sure it's conceivable that,

977
01:00:14.180 --> 01:00:18.350
you know,
there could be more selection on even more spread out,
uh,

978
01:00:18.380 --> 01:00:20.940
reproduction.
I mean,
the thing is that,

979
01:00:23.750 --> 01:00:24.520
<v 2>okay,</v>

980
01:00:24.520 --> 01:00:27.760
<v 0>a really interesting observation that we make in development economics and</v>

981
01:00:27.761 --> 01:00:32.761
demography is that as soon as you can insure the more or less certain survival

982
01:00:33.911 --> 01:00:37.960
of your kids to reproductive age,
people voluntarily reduce their fertility,

983
01:00:38.530 --> 01:00:43.090
right?
They like,
and,
and so we had this model,
um,

984
01:00:43.900 --> 01:00:44.170
uh,

985
01:00:44.170 --> 01:00:48.040
called the demographic transition model and predicted the sort of timescale over

986
01:00:48.041 --> 01:00:51.370
which has happened and it seemed to explain the historical data very well.

987
01:00:51.670 --> 01:00:53.890
And then,
you know,
late in the 20th century,

988
01:00:53.891 --> 01:00:55.870
these places like a lot of places in the,

989
01:00:55.871 --> 01:01:00.040
in the Middle East and North Africa and in Asia,
you know,

990
01:01:00.070 --> 01:01:05.020
in the tiger economies,
like fertility felt like that as soon as kids,
uh,

991
01:01:05.060 --> 01:01:07.750
could be counted on to,
to survive.
Um,

992
01:01:09.670 --> 01:01:10.503
and so

993
01:01:12.510 --> 01:01:13.343
<v 2>yeah,</v>

994
01:01:14.230 --> 01:01:15.360
<v 0>if we can,
if,</v>

995
01:01:15.361 --> 01:01:19.360
if our sort of technological and social technologies can keep up with ensuring

996
01:01:19.361 --> 01:01:24.130
the child's survivorship,
right,
and,
and keeping,
uh,
the,

997
01:01:24.140 --> 01:01:27.580
the,
it,
keeping it favoring,
you know,
economic investment,

998
01:01:28.030 --> 01:01:31.270
then that sort of relaxes the selection pressure to spread everything out.

999
01:01:31.271 --> 01:01:35.750
For sure.
Uh,
and I think that that should be a goal that we have right.
If,

1000
01:01:35.751 --> 01:01:39.910
if we want to,
if we want to avoid sort of negative population consequences,

1001
01:01:39.911 --> 01:01:43.540
make sure that kids,
that kids survived to adulthood,
right?

1002
01:01:43.900 --> 01:01:47.200
Because that changes everything about people's investments.

1003
01:01:47.770 --> 01:01:52.300
And that's really what,
what,
what this,
you know,
given that you can't affect that,

1004
01:01:52.360 --> 01:01:56.050
right.
As a,
as a homicide and it,
you know,
a million years ago,
right?

1005
01:01:56.051 --> 01:02:00.280
You don't have the technology to really mitigate that.
Right?

1006
01:02:00.370 --> 01:02:02.050
So what you do is you spread everything out,

1007
01:02:03.550 --> 01:02:06.190
but if we have the chance to actually solve it right,

1008
01:02:06.191 --> 01:02:09.820
then that's the better solution probably.
And that also,
uh,

1009
01:02:10.360 --> 01:02:13.150
sort of reduces the selective pressure,
I think.

1010
01:02:14.470 --> 01:02:15.670
<v 2>Yeah.
Yeah.
Thanks.</v>

1011
01:02:16.940 --> 01:02:18.350
<v 4>[inaudible].</v>

