WEBVTT

1
00:00:06.060 --> 00:00:10.570
Thanks for coming out.
It's a,
it's good to be here.
As Eric said,

2
00:00:10.571 --> 00:00:15.480
I'm a philosopher thinking about consciousness.

3
00:00:15.481 --> 00:00:20.481
Coming from a background in the sciences and math that always struck me that the

4
00:00:21.751 --> 00:00:26.751
most interesting and hardest unsolved problem in the sciences was the problem of

5
00:00:29.011 --> 00:00:31.710
consciousness and way back 25 years ago when I was in,

6
00:00:32.640 --> 00:00:34.080
when I was in Grad school.

7
00:00:34.081 --> 00:00:39.060
It seems to be the best way to come at this from a big picture perspective was

8
00:00:39.061 --> 00:00:43.710
to go into philosophy and think about the foundational issues that arise and

9
00:00:43.711 --> 00:00:46.320
thinking about consciousness from any number of different angles,

10
00:00:46.321 --> 00:00:51.321
including the angles of neuroscience and psychology and AI.

11
00:00:52.050 --> 00:00:52.651
In this talk,

12
00:00:52.651 --> 00:00:55.890
I'm going to present a slightly different perspective on the problem after

13
00:00:55.891 --> 00:01:00.030
laying out some background,
the perspective of what I call the,
uh,

14
00:01:00.300 --> 00:01:05.050
metal problem of consciousness.
I always liked the idea that,
you know,

15
00:01:05.060 --> 00:01:08.460
you approach a problem by stepping one level up,
taking the,
uh,

16
00:01:08.461 --> 00:01:12.930
the Metta perspective.
Um,
I love this quote.

17
00:01:12.931 --> 00:01:17.670
Anything you can do,
I can do Metta.
I have no idea what the origins was.

18
00:01:17.671 --> 00:01:20.310
I liked the fact this is attributed to to Rudolph CONAP,

19
00:01:20.311 --> 00:01:23.370
one of my favorite philosophers,
but anyone who knows condoms work,

20
00:01:23.371 --> 00:01:26.520
it's completely implausible.
He would ever say anything so frivolous.

21
00:01:26.610 --> 00:01:30.870
It's also been attributed to my thesis,
advisor.
Dot.
Hofstatter author of Godel,

22
00:01:30.871 --> 00:01:34.830
Escher,
Bach,
and a big,
uh,
a big fan of the Meta perspective.

23
00:01:34.831 --> 00:01:38.220
But he assures me he never said it either.
Um,

24
00:01:38.250 --> 00:01:41.370
but the Meta perspective on anything is stepping up.

25
00:01:41.820 --> 00:01:43.440
I'm stepping up a level.

26
00:01:43.650 --> 00:01:48.480
The met a problem as I think about it is it's called the Meta problem because

27
00:01:48.481 --> 00:01:52.770
it's a problem about a problem.
And met a theory is a theory about a theory.

28
00:01:53.320 --> 00:01:55.980
Met a problem is a problem about a problem in particular.

29
00:01:56.250 --> 00:02:01.020
It's the problem of explaining why we think there is a problem about

30
00:02:01.500 --> 00:02:04.830
consciousness.
So there's a first order problem,
the problem of consciousness.

31
00:02:05.070 --> 00:02:07.080
Today I'm going to focus on a problem about it,

32
00:02:07.380 --> 00:02:11.310
but I'll start by introducing the first order problem itself.

33
00:02:11.820 --> 00:02:16.820
The first order problem is what we call the hard problem of consciousness.

34
00:02:16.980 --> 00:02:21.980
It's the problem of explaining why and how physical processes should give rise

35
00:02:22.890 --> 00:02:27.780
to conscious experience.
Um,
you know,

36
00:02:27.781 --> 00:02:31.540
you've got all of these neurons firing and you're in your brain bringing it

37
00:02:31.541 --> 00:02:34.620
about all kinds of sophisticated behavior.
Um,

38
00:02:34.800 --> 00:02:38.610
we can get to beat on explaining our various responses.

39
00:02:38.730 --> 00:02:41.670
But there's this big question about how it feels from the first person point of

40
00:02:41.671 --> 00:02:44.190
view.
That's the subjective experience.

41
00:02:44.280 --> 00:02:47.040
I'd like to see illustration of the hard problem of consciousness.

42
00:02:47.041 --> 00:02:50.910
It seems to show social show someone's hair catching fire,
but it's,

43
00:02:50.911 --> 00:02:55.911
I guess it's a metaphorical illustration of the subjective perspective.

44
00:02:56.070 --> 00:03:00.400
So the hard problem is concerned with what philosophers call consciousness.

45
00:03:00.400 --> 00:03:03.070
The word consciousness is ambiguous a thousand ways,

46
00:03:03.670 --> 00:03:05.140
but phenomenal consciousnesses,

47
00:03:05.230 --> 00:03:09.100
what it's like to be a subject from the first person point of view.

48
00:03:09.101 --> 00:03:13.630
So a system is phenomenally conscious.
If there's something that's like to be it,

49
00:03:14.050 --> 00:03:17.380
a mental state is predominantly conscious.
If there's something,

50
00:03:17.381 --> 00:03:21.010
it's like to be in it.
So the thought is there are some systems,

51
00:03:21.130 --> 00:03:23.800
so there's something that's like to beat that system.

52
00:03:23.801 --> 00:03:25.780
There's something that's like to be me.

53
00:03:25.990 --> 00:03:30.280
I presume there's something gets like to be you,
but presumably there's nothing.

54
00:03:30.281 --> 00:03:33.670
It's like to be this lectern.
As far as we know,

55
00:03:33.671 --> 00:03:38.250
the lectern does not have a first person perspective.
Ah,
this,

56
00:03:38.410 --> 00:03:43.410
this phrase was made famous by my colleague Tom Nagle at Nyu who back in 1974

57
00:03:45.280 --> 00:03:50.280
wrote an article called what is it like to be a bat and the general idea of is

58
00:03:50.381 --> 00:03:55.381
what's very hard to know what it's like to be a bat from the third person point

59
00:03:55.511 --> 00:03:58.720
of view.
Just looking at it as a human who has different kinds of experience,

60
00:03:58.990 --> 00:04:03.460
but presumably very plausibly there is something.
It's like to be a bat.
The Bat,

61
00:04:03.490 --> 00:04:04.221
his car,
it's just,

62
00:04:04.221 --> 00:04:09.221
it's having subjective experiences just of a kind very different from ours.

63
00:04:10.680 --> 00:04:13.060
In human subjective experience,

64
00:04:13.930 --> 00:04:18.930
consciousness divides into any number of different kinds or aspects like

65
00:04:19.271 --> 00:04:23.170
different tracks of the inner movie of consciousness.

66
00:04:23.171 --> 00:04:28.171
We have visual experiences like the experience of seeing these colors blue and

67
00:04:28.840 --> 00:04:32.950
red and green from the first person point of view and the depth.

68
00:04:32.951 --> 00:04:36.490
There are sensory experiences like the experience of my voice,

69
00:04:36.730 --> 00:04:40.060
experiences of taste and smell,

70
00:04:40.300 --> 00:04:42.010
their experiences of your buddy,

71
00:04:42.420 --> 00:04:47.420
a feeling pain or orgasms or hunger or a tickle or something.

72
00:04:47.741 --> 00:04:52.330
They all have some distinctive first person quality mental images like recalled

73
00:04:52.750 --> 00:04:57.500
visual images,
emotional experiences like uh,

74
00:04:57.670 --> 00:04:59.260
experience of happiness or anger.

75
00:04:59.410 --> 00:05:02.650
And indeed we all seem to have this stream of a current thought where at the

76
00:05:02.651 --> 00:05:07.090
very least we're kind of chattering away to ourselves and reflecting and

77
00:05:07.091 --> 00:05:10.990
deciding,
oh,
these are aspects of subjective experience.

78
00:05:10.990 --> 00:05:14.980
Things we experience from the first person point of view.

79
00:05:14.981 --> 00:05:19.981
And I think these subjective experiences or at least on the face of it,

80
00:05:21.071 --> 00:05:26.071
data data for the science of consciousness to explain these are just facts about

81
00:05:26.621 --> 00:05:30.370
us that we're having these subjective experiences.
If we ignore them,

82
00:05:30.580 --> 00:05:34.690
we're ignoring the data is if you catalog the data that say the science of

83
00:05:34.691 --> 00:05:36.190
consciousness needs to explain.

84
00:05:36.430 --> 00:05:39.610
There were certainly facts about our behavior and how we respond in situations

85
00:05:39.611 --> 00:05:42.970
or a fact about how brain facts about how our brains is working.

86
00:05:43.150 --> 00:05:47.710
There also facts about how subjective experiences and on the face of it their

87
00:05:48.250 --> 00:05:50.830
data and as these data,
the pose,

88
00:05:50.831 --> 00:05:55.740
what I call the hard problem of consciousness.
But this gets a contrasted move.

89
00:05:55.760 --> 00:05:59.720
The easy problems,
the so called easy problems of consciousness,

90
00:05:59.721 --> 00:06:04.721
which are the problems of explaining behavioral and cognitive functions.

91
00:06:06.320 --> 00:06:09.410
Um,
objective things you can measure from the third person point of view,

92
00:06:09.620 --> 00:06:14.480
typically tied to behavior,
perceptual discrimination,
say of a stimulus.

93
00:06:14.920 --> 00:06:18.380
Um,
I can discriminate to different things in my environment.

94
00:06:18.381 --> 00:06:21.830
I can say that's red and that's green.
I can integrate the information,

95
00:06:21.831 --> 00:06:25.340
say about the color and the shape.
I can use it to control my behavior,

96
00:06:25.520 --> 00:06:28.820
walk towards the red one rather than the green one.
I can report it,

97
00:06:29.000 --> 00:06:32.300
say that's red and uh,
and so on.

98
00:06:32.390 --> 00:06:36.350
Those are all data too for science to explain,

99
00:06:36.380 --> 00:06:39.560
but we've got a bead on how to explain those.

100
00:06:39.561 --> 00:06:42.230
They don't seem to pose as big a problem.
Um,

101
00:06:42.410 --> 00:06:47.410
why we explain those easy problems by finding a mechanism,

102
00:06:48.140 --> 00:06:53.140
typically a neural or computational mechanism that performs the relevant

103
00:06:53.600 --> 00:06:55.570
function to explain,
you know,

104
00:06:55.580 --> 00:07:00.320
how it is that I get to say there's a red thing over there or walk towards it.

105
00:07:00.321 --> 00:07:05.321
Will you find the mechanisms involving perceptual perceptual processes and

106
00:07:05.661 --> 00:07:09.470
action processes in my brain that leads to leads to that behavior,

107
00:07:09.471 --> 00:07:12.390
find the right mechanism that performs a function?

108
00:07:12.420 --> 00:07:16.880
You've explained what needs to be explained with the easy problems of

109
00:07:17.270 --> 00:07:20.720
consciousness,
but for the hard problem,
for subjective experience,

110
00:07:20.870 --> 00:07:24.380
it's just not clear that this standard method works,

111
00:07:24.381 --> 00:07:28.880
that it looks like explaining all that behavior still leaves open.

112
00:07:28.970 --> 00:07:33.950
A further question,
why does all that give you subjective experience?

113
00:07:33.951 --> 00:07:38.660
You know,
explain the uh,
the reacting,
the responding,

114
00:07:38.661 --> 00:07:42.170
the controlling,
the reporting and so on.

115
00:07:43.310 --> 00:07:44.480
It still leaves open the question,

116
00:07:44.481 --> 00:07:47.810
why is all that accompanied by subjective experience?

117
00:07:48.590 --> 00:07:53.120
Why doesn't that go on in the dark without consciousness,
so to speak?

118
00:07:53.540 --> 00:07:56.990
That seems to be what the philosopher Joe Levine is cold a gap here and

119
00:07:56.991 --> 00:08:01.010
explanatory gap between physical processes and subjective experience.

120
00:08:01.011 --> 00:08:03.260
At least our standard kinds of explanations.

121
00:08:03.710 --> 00:08:07.610
Which worked really well for the easy problems of behavior and so on.

122
00:08:07.611 --> 00:08:12.611
Don't obviously give you a connection to the subjective aspects of experience.

123
00:08:14.810 --> 00:08:18.680
And there's been a vast amount of discussion of these things over,
I mean,

124
00:08:18.800 --> 00:08:23.030
well for centuries really,
but it's been particularly active in recent decades.

125
00:08:23.030 --> 00:08:27.380
Philosophers,
scientists,
all kinds of different views.
I mean,

126
00:08:27.381 --> 00:08:31.790
philosophically you can divide approaches to the hard problem into at least two

127
00:08:31.791 --> 00:08:32.624
classes.

128
00:08:33.020 --> 00:08:37.820
One is an approach on which consciousness is taken to be somehow irreducible and

129
00:08:37.850 --> 00:08:41.270
primitive.
We can't explain it in more basic physical terms.

130
00:08:41.271 --> 00:08:42.800
So take it as a kind of primitive,

131
00:08:42.801 --> 00:08:46.100
and that might lead to dualist theories of consciousness.

132
00:08:46.101 --> 00:08:49.340
We are consciousness is somehow separate from an interacts with the brain.

133
00:08:49.640 --> 00:08:52.610
Recently,
very popular has been the class of pence,
Haikus,

134
00:08:52.611 --> 00:08:57.390
theories of consciousness.
I know Galen Strawson was here a while back talking.

135
00:08:57.500 --> 00:08:57.870
Uh,
he,

136
00:08:57.870 --> 00:09:01.560
he very much favors [inaudible] theories where consciousness is something basic

137
00:09:01.860 --> 00:09:04.080
in the universe underlying matter.
And indeed,

138
00:09:04.081 --> 00:09:08.700
there are idealists theories where consciousness underlies the whole universe.

139
00:09:08.990 --> 00:09:12.620
Um,
so these are all extremely speculative but interesting,
uh,

140
00:09:12.690 --> 00:09:14.520
views that I've explored myself.

141
00:09:14.960 --> 00:09:19.740
There are also reductionist theories of consciousness from functionalist

142
00:09:19.741 --> 00:09:22.950
approaches where consciousness is just basically taken to be a,
you know,

143
00:09:22.951 --> 00:09:27.930
a giant algorithm or computation by logical approaches to consciousness.

144
00:09:27.930 --> 00:09:31.800
My colleague Ned Block was here.
I know talking about a neuro biology,

145
00:09:31.850 --> 00:09:35.250
neuro biology based approach approaches versus not the algorithm that matters,

146
00:09:35.251 --> 00:09:37.860
but the biology it's implemented in.

147
00:09:38.010 --> 00:09:41.820
And indeed the kinds of quantum approaches that people like Roger Penrose and

148
00:09:41.821 --> 00:09:44.880
Stuart Hameroff have made famous.
I mean,

149
00:09:44.881 --> 00:09:48.360
I think there's interesting things to say about all of these approaches.

150
00:09:48.390 --> 00:09:52.920
I think that right now at least most of the reductionist approaches leave a gap,

151
00:09:52.950 --> 00:09:56.970
but the number reductions to purchase have other problems and seeing how,

152
00:09:57.690 --> 00:10:02.400
how it all works today I'm going to take a different kind of approach,

153
00:10:02.401 --> 00:10:06.780
this approach through the metal problem.
One way to motivate this,

154
00:10:07.650 --> 00:10:11.370
um,
is too,
I often get asked,
you know,
well,
okay,
you're a philosopher.
It's fine.

155
00:10:11.371 --> 00:10:13.710
You get to think about,
uh,
these,

156
00:10:13.800 --> 00:10:16.740
these things like the hard problem of consciousness.
How can I,

157
00:10:16.980 --> 00:10:21.180
as a scientist or an engineer or an AI researcher,

158
00:10:21.840 --> 00:10:26.560
how can I do something to kind of,
uh,
to contribute,
um,
to help get at this,

159
00:10:26.561 --> 00:10:30.450
at this hard problem of consciousness?
Is this just a problem for philosophy?

160
00:10:30.451 --> 00:10:33.270
I mean,
for me to work on it,
see,
as an AI researcher,

161
00:10:33.271 --> 00:10:35.950
I need something I can operationalize.
Um,

162
00:10:36.570 --> 00:10:39.540
something I can work with and try to program.
And as it stands,

163
00:10:39.541 --> 00:10:44.250
it's just not clear how to do that with the,
uh,
with the hard problem.
I mean,

164
00:10:44.370 --> 00:10:47.320
if you're a neuroscientist,
there are some things you can do.
Um,

165
00:10:47.370 --> 00:10:50.730
you can say work with humans and look at their brains and look for the neural

166
00:10:50.731 --> 00:10:53.400
correlates of consciousness,

167
00:10:53.401 --> 00:10:55.290
the bits of the brain that go along with being conscious.

168
00:10:55.291 --> 00:10:58.200
Because at least with humans,
we can take as a background assumption,

169
00:10:58.440 --> 00:11:01.800
a plausible background assumption that the system is conscious for AI.

170
00:11:01.801 --> 00:11:04.720
We can't even do that.
We don't know which AI systems we're working with.

171
00:11:04.721 --> 00:11:08.550
There are conscious,
we need some operational criteria in AI.

172
00:11:08.551 --> 00:11:10.410
We mostly work on bottling things like,
you know,

173
00:11:10.411 --> 00:11:13.410
behavior and objective functioning for consciousness.

174
00:11:13.410 --> 00:11:15.390
Those are the easy problems.

175
00:11:15.480 --> 00:11:20.480
So how does someone coming from this perspective make a connection to the hard

176
00:11:21.601 --> 00:11:26.370
problem of consciousness?
Well,
one approach is to work on certain problems.

177
00:11:26.371 --> 00:11:31.371
Among the easy problems have behavior that shed particular light on the Hud

178
00:11:31.591 --> 00:11:35.550
problem.
And that's going to be the approach that I look at today.

179
00:11:36.690 --> 00:11:39.690
So the uh,
the guiding,
the key idea here,

180
00:11:40.080 --> 00:11:44.310
is there a certain behavioral functions that seem to have a particularly close

181
00:11:44.311 --> 00:11:49.080
relation to the hard problem of consciousness in particular,

182
00:11:49.440 --> 00:11:51.990
we say things about consciousness.

183
00:11:51.991 --> 00:11:54.340
We make what philosophers call phenomenal reports,

184
00:11:54.610 --> 00:11:58.300
verbal reports of conscious experiences.

185
00:11:58.720 --> 00:12:01.330
So I'll say things like,
I'm conscious,

186
00:12:01.960 --> 00:12:05.140
I'm feeling pain right now and so on.
I mean,

187
00:12:05.141 --> 00:12:09.130
maybe the consciousness and the pain are subjective experiences,

188
00:12:09.160 --> 00:12:12.040
but the reports,
the Adrienne says,
I am conscious.

189
00:12:12.041 --> 00:12:17.041
Well that's a bit of behavior in principal explaining those is among the easy

190
00:12:17.591 --> 00:12:20.530
problems.
Subjectively measurable response.

191
00:12:20.531 --> 00:12:23.950
We can find a mechanism in the brain that produces it.

192
00:12:25.000 --> 00:12:27.040
And among our phenomenal reports,

193
00:12:27.490 --> 00:12:31.090
there's this special class we can call the problem reports,

194
00:12:31.330 --> 00:12:36.040
reports expressing our sense,
the consciousness poses a problem.
Now,

195
00:12:36.041 --> 00:12:38.320
admittedly,
not everyone makes these reports,

196
00:12:38.321 --> 00:12:40.940
but they seem to be fairly widespread among,

197
00:12:41.050 --> 00:12:43.870
especially among philosophers and scientists thinking about these things.

198
00:12:43.871 --> 00:12:46.440
But furthermore,
um,
just centered,

199
00:12:46.450 --> 00:12:51.450
it's fairly easy to find and a very wide class of people who think about

200
00:12:52.030 --> 00:12:56.600
consciousness,
people say things like,
there is a problem of consciousness,

201
00:12:56.610 --> 00:12:58.630
a hard problem on the face of it.

202
00:12:58.631 --> 00:13:01.090
Explaining behavior doesn't explain consciousness.

203
00:13:01.390 --> 00:13:03.790
Consciousness seems nonphysical.

204
00:13:03.880 --> 00:13:08.530
How would you ever explain the subjective experience of red and so on?

205
00:13:08.560 --> 00:13:12.230
It's an objective fact about us,
at least about some of us,
um,

206
00:13:12.820 --> 00:13:17.820
that we make those reports and that's a fact about human behavior.

207
00:13:19.210 --> 00:13:24.210
So the matter problem of consciousness then at a second approximation is roughly

208
00:13:24.731 --> 00:13:29.620
the problem of explaining these problem reports.
Explaining,

209
00:13:29.621 --> 00:13:34.210
you might say the conviction that we're conscious and the consciousness is

210
00:13:34.211 --> 00:13:37.960
puzzling.
And what's nice about this is that although the hard problem is this,

211
00:13:38.040 --> 00:13:41.500
you know,
airy fairy problem about subjective experience,
it's hard to pin down.

212
00:13:41.650 --> 00:13:46.420
This is a puzzle ultimately about behavior.
So this is an easy problem.

213
00:13:46.630 --> 00:13:50.320
One that ought to be open to those standard methods of explanation in the

214
00:13:50.321 --> 00:13:54.910
cognitive and brain sciences.
So there's a,

215
00:13:54.970 --> 00:13:58.390
there's a research program,
um,
as a research program here.

216
00:13:58.570 --> 00:14:01.450
So I like to think of the metal problem is something that can play that role I

217
00:14:01.451 --> 00:14:04.390
talked about earlier.
If you say an AI researcher thinking about this,

218
00:14:04.391 --> 00:14:07.180
the metal problem is an easy problem.
The problem about behavior,

219
00:14:07.470 --> 00:14:10.010
this is closely tied to the hog problem.

220
00:14:10.011 --> 00:14:13.180
So it's something we might be able to make some progress on using standard

221
00:14:13.181 --> 00:14:15.580
methods if they came out algorithms and computation.

222
00:14:15.580 --> 00:14:20.410
So thinking about brain processes and behavior while still shedding some light,

223
00:14:20.411 --> 00:14:22.150
at least indirectly on the hard problem.

224
00:14:22.151 --> 00:14:24.460
It's more tractable than the hard problem,

225
00:14:24.640 --> 00:14:27.580
but solving it off to shed light on the hard problem.

226
00:14:27.581 --> 00:14:30.550
And today I'm just going to kind of lay out the research program and talk about

227
00:14:30.551 --> 00:14:34.060
some ways in which it might potentially shed some light.

228
00:14:35.330 --> 00:14:37.690
This is interesting to a philosopher because it's a,

229
00:14:38.020 --> 00:14:40.420
it looks like an instance of what people symptoms called Genia.

230
00:14:40.421 --> 00:14:43.330
Logical analysis goes back to Friedrich nature on the,
you know,

231
00:14:43.331 --> 00:14:46.870
the genealogy of morals.
Instead of thinking about what's good or bad,

232
00:14:47.080 --> 00:14:51.800
let's look at where our sense of good or bad came from the genealogy of it all

233
00:14:51.801 --> 00:14:56.590
and evolution or in culture or in religion and uh,

234
00:14:56.610 --> 00:14:57.740
you know,
people think of Ge.

235
00:14:57.770 --> 00:15:00.710
Do you need a logical approach to God instead of thinking about does God exist

236
00:15:00.711 --> 00:15:03.710
or not?
Let's look at where our belief in God came from.

237
00:15:03.711 --> 00:15:08.430
Maybe there's some evolutionary reason for why people believe in God.

238
00:15:08.450 --> 00:15:09.890
There's Oftenly.
It's not always,

239
00:15:09.891 --> 00:15:14.540
but often leads to a kind of debunking of our beliefs about those domains.

240
00:15:14.660 --> 00:15:17.570
Explain why we believe in God in evolutionary terms.

241
00:15:18.150 --> 00:15:19.820
No need for the God hypothesis anymore.

242
00:15:19.821 --> 00:15:23.780
Explain I'll moral beliefs and say evolutionary terms.

243
00:15:24.110 --> 00:15:27.380
Maybe no need to take morality quite so seriously.

244
00:15:27.410 --> 00:15:31.910
So some people at least are inclined to take an approach like this with

245
00:15:31.911 --> 00:15:34.160
consciousness too.
If you think about the metal problem,

246
00:15:34.430 --> 00:15:38.780
explaining our beliefs about consciousness that might ultimately debunk our

247
00:15:38.781 --> 00:15:41.420
beliefs about consciousness.

248
00:15:42.300 --> 00:15:43.940
This leads to a philosophical view,

249
00:15:44.270 --> 00:15:46.760
which is recently attracted a lot of interest,

250
00:15:47.780 --> 00:15:50.030
a philosophical view called illusionism,

251
00:15:50.720 --> 00:15:54.350
which is the view that consciousness itself is an illusion.

252
00:15:54.860 --> 00:15:58.760
Or maybe that the problem of consciousness is an illusion,

253
00:15:58.790 --> 00:16:02.780
explained the illusion and we dissolve the problem.

254
00:16:03.560 --> 00:16:05.510
I take the,
in terms of the head of the Metro problem,

255
00:16:05.511 --> 00:16:08.300
that view roughly comes to solve the matter problem.

256
00:16:08.750 --> 00:16:11.330
It will dissolve the hard problem.

257
00:16:11.870 --> 00:16:15.140
Explain why it is that we say are these things about consciousness.

258
00:16:15.141 --> 00:16:19.820
While we say I am conscious,
while we say consciousness is puzzling.

259
00:16:19.821 --> 00:16:23.450
If you can explain all that in say algorithmic terms,

260
00:16:23.780 --> 00:16:27.810
then you'll remove the underlying problem because you'll have explained why we

261
00:16:27.811 --> 00:16:31.100
were puzzled in the first place.
Actually walking over here today,

262
00:16:31.101 --> 00:16:33.110
I noticed that just a couple of blocks away,

263
00:16:33.111 --> 00:16:36.460
we have the Museum of illusions so I'm going to check that out.

264
00:16:36.830 --> 00:16:40.310
That out later on we know if illusionism Israel added to all those perceptual

265
00:16:40.311 --> 00:16:43.220
illusions,
it's going to be the problem of consciousness itself.

266
00:16:43.221 --> 00:16:48.221
It's roughly and illusion thrown up by having a weird sick kind of self model

267
00:16:49.221 --> 00:16:51.690
with a certain kind of algorithm that are attributes to ourselves,

268
00:16:51.720 --> 00:16:54.230
special properties that we don't have.

269
00:16:54.230 --> 00:16:56.930
So one line on the matter problem is the uh,

270
00:16:57.740 --> 00:16:59.960
is the illusionist line solved the matter problem.

271
00:16:59.961 --> 00:17:03.350
You'll get to treat consciousness as an illusion.

272
00:17:03.460 --> 00:17:07.760
And that's actually a view that has many antecedents in the history of

273
00:17:07.761 --> 00:17:09.080
philosophy.
One way or another,

274
00:17:09.290 --> 00:17:13.310
even a manual cans is great critique of pure reason had a section where we

275
00:17:13.311 --> 00:17:17.180
talked about the self or the soul as a transcendental illusion.

276
00:17:17.181 --> 00:17:20.360
We seem to have this in the visible soul,

277
00:17:20.840 --> 00:17:24.680
but that's the kind of illusion or not by our cognitive processes.

278
00:17:24.681 --> 00:17:26.500
The Australian philosophers,
uh,

279
00:17:26.570 --> 00:17:31.570
Alan Place and David Armstrong had versions of this that I might touch on a bit

280
00:17:31.581 --> 00:17:34.340
later.
Uh,
Daniel Dennett,
um,

281
00:17:34.520 --> 00:17:39.470
leading reductionist thinker about consciousness has been pushing for the last

282
00:17:39.470 --> 00:17:39.471
couple of decades.

283
00:17:39.471 --> 00:17:43.670
The idea that consciousness involves a certain kind of user illusion.

284
00:17:43.790 --> 00:17:47.780
And most recently the British philosopher Keith Frankish has been really
pushing,

285
00:17:48.320 --> 00:17:52.770
um,
illusion.
There's as a theory of consciousness.
Here's a book,

286
00:17:53.150 --> 00:17:56.620
uh,
that,
uh,
centering around the,
uh,
uh,

287
00:17:56.690 --> 00:18:00.660
pay for by Keith Frankish on illusionism as a theory of consciousness that I

288
00:18:01.500 --> 00:18:02.281
recommend to you.

289
00:18:02.281 --> 00:18:06.120
So one way to go with the metal problem is the direction of illusionism.

290
00:18:06.121 --> 00:18:09.720
But one nice thing about that many people find illusionism completely

291
00:18:09.721 --> 00:18:13.380
unbelievable.
They find you,
how could it be that consciousness is an illusion?

292
00:18:13.680 --> 00:18:16.860
Look,
we just have these subjective experience.
It's a datum about our nature.

293
00:18:16.861 --> 00:18:21.330
And I confess,
I've got some sympathy with that reaction.
So I'm not an illusion.

294
00:18:21.331 --> 00:18:22.170
This myself,

295
00:18:22.410 --> 00:18:26.550
I'm a realist about consciousness and the philosophers sense where a realist

296
00:18:26.551 --> 00:18:30.120
about something because someone who believes that thing is real.

297
00:18:30.480 --> 00:18:33.540
I think consciousness is real.
I think it's not an illusion.

298
00:18:33.780 --> 00:18:37.890
I think that solving the metal problem does not dissolve the hard problem.

299
00:18:37.891 --> 00:18:41.460
But the nice thing about the met problem as you can proceed on it to some
extent,

300
00:18:41.880 --> 00:18:45.720
to some extent,
at least in the initial neutrality on that question,
is conscious.

301
00:18:45.720 --> 00:18:48.510
It's real or is it an illusion?
It's just,

302
00:18:48.960 --> 00:18:52.110
it's a basic problem about our objective functioning and these reports.

303
00:18:52.440 --> 00:18:54.240
What explains,
explains those?

304
00:18:54.510 --> 00:18:59.220
So there's a neutral research program here that both realists illusionists

305
00:18:59.700 --> 00:19:03.060
people of all kinds of different views of consciousness can explain and then we

306
00:19:03.061 --> 00:19:06.190
can come back and look at the,
uh,
the philosophical consequences.

307
00:19:06.191 --> 00:19:10.500
Why I'm not an illusion.
So I think consciousness is real.
They're going to say,

308
00:19:10.501 --> 00:19:15.150
if I do feel the temptation of illusionism I find as a really intriguing and in

309
00:19:15.151 --> 00:19:19.470
some ways attractive,
you just fundamentally unbelievable.
Um,
nevertheless,

310
00:19:19.471 --> 00:19:24.330
I think that the matter problems should be attractable problem solving.

311
00:19:24.331 --> 00:19:28.620
It will shed my what's at the very least we'll shed much light on the hard

312
00:19:28.621 --> 00:19:30.960
problem of consciousness even if it doesn't solve it.

313
00:19:30.961 --> 00:19:35.190
If you could explain how conviction that we're conscious somehow this sauce,

314
00:19:35.191 --> 00:19:38.760
the roots of our conviction that we're conscious must have something to do with

315
00:19:38.761 --> 00:19:43.410
consciousness,
especially if consciousness is real.
So I think it's very much,

316
00:19:43.650 --> 00:19:47.220
um,
a good research program for people to explain.

317
00:19:47.221 --> 00:19:52.140
So then I'll move on now to just outlining the research program a little bit

318
00:19:52.141 --> 00:19:56.700
more and then talk a bit about potential solutions and an impact on theories of

319
00:19:56.701 --> 00:19:58.690
consciousness before wrapping up with,
um,

320
00:19:58.930 --> 00:20:01.140
just a little bit more about illusionism.

321
00:20:03.090 --> 00:20:06.690
So there's metal problem which I've been pushing recently,

322
00:20:06.691 --> 00:20:10.800
opens up attractable empirical research program for everyone.

323
00:20:10.830 --> 00:20:14.550
Reductionists number actionists illusionists non illusionists.

324
00:20:14.910 --> 00:20:19.860
We can try to solve it and then think about the philosophical consequences.

325
00:20:21.540 --> 00:20:24.120
Um,
now what is the matter of problem?
Well,

326
00:20:25.350 --> 00:20:29.520
the way I'm going to put it is it's the problem of topic neutrally explaining

327
00:20:29.850 --> 00:20:33.870
problem intuitions or else explaining why that can't be done.

328
00:20:34.620 --> 00:20:39.480
And I'll unpack that now.
Um,
unpack all the pieces of that right now.

329
00:20:39.481 --> 00:20:43.230
First starting with problem intuitions,
what our problem intuitions.
Well,

330
00:20:43.231 --> 00:20:45.570
those are,
you know,
there are the things we say,

331
00:20:45.750 --> 00:20:49.660
there are things we think I say hi consciousness seems irreducible.

332
00:20:49.661 --> 00:20:53.020
I might think consciousness is irreducible.
People might be disposed,

333
00:20:53.140 --> 00:20:55.750
have a tendency to say or think those things.

334
00:20:55.751 --> 00:20:58.750
Problem and tuition is I'll take to be roughly that tendency.

335
00:20:58.751 --> 00:21:00.690
We have dispositions to uh,

336
00:21:00.760 --> 00:21:05.620
to say and think certain things about consciousness.
What are the core problem?

337
00:21:06.290 --> 00:21:10.000
Intuitions?
Well,
I think they break down into a number of different kinds.

338
00:21:10.450 --> 00:21:12.820
There's the intuition that consciousness is nonphysical.

339
00:21:12.821 --> 00:21:16.210
We might think of that as a metaphysical intuition about the nature of

340
00:21:16.211 --> 00:21:20.560
consciousness.
Their intuitions about explanation.
Consciousnesses,

341
00:21:20.740 --> 00:21:24.550
hard to explain,
explaining behavior.
It doesn't explain consciousness.

342
00:21:25.270 --> 00:21:27.910
There are intuitions about knowledge of consciousness.

343
00:21:27.911 --> 00:21:30.820
Some of you may know the famous thought experiment of Mary and the Black and

344
00:21:30.821 --> 00:21:35.230
white room who knows all about the objective nature of color,

345
00:21:35.231 --> 00:21:38.200
vision and so on,
but it still doesn't know what it's like to see red.

346
00:21:38.290 --> 00:21:41.140
Do you see as red for the first time she learns something new.

347
00:21:41.410 --> 00:21:44.850
That's an intuition about knowledge of consciousness through what philosophers

348
00:21:44.860 --> 00:21:48.250
called modal intuitions about what's possible or imaginable.

349
00:21:48.640 --> 00:21:51.700
One famous case is the case of,
um,
of a Zombie,

350
00:21:51.701 --> 00:21:54.640
a creature who's physically identical to you and me,

351
00:21:55.390 --> 00:21:57.310
but not conscious or maybe an AI system,

352
00:21:57.311 --> 00:22:00.400
which is functionally identical to you and me,
but not conscious.

353
00:22:00.401 --> 00:22:03.040
That at least seems conceivable to many people.

354
00:22:03.041 --> 00:22:07.930
So this is the philosophical Zombie.
Unlike the zombies in movies which,
you know,

355
00:22:08.530 --> 00:22:11.320
have weird behaviors and go after brains.
And so on.

356
00:22:11.321 --> 00:22:15.220
The Philosophical Zombie is a creature that seems at least behaviorally,

357
00:22:15.550 --> 00:22:20.080
maybe physically like a normal human,
but doesn't have any conscious experiences.

358
00:22:20.140 --> 00:22:23.310
All the physical states,
none of the mental states.

359
00:22:23.311 --> 00:22:26.650
And it seems to many people that's at least conceivable.
We're not zombies.

360
00:22:26.651 --> 00:22:30.220
I don't think anyone here is a Zombie.
I hope.
But,
um,

361
00:22:30.850 --> 00:22:33.010
nonetheless it seems that we can make sense of the idea.

362
00:22:33.011 --> 00:22:36.560
And one way to pose the hard problem is why are we not Zombie?

363
00:22:36.561 --> 00:22:38.320
So this imagine inability of zombies.

364
00:22:38.321 --> 00:22:42.550
It's one of the intuitions that gets the problem going and then you can go on

365
00:22:42.551 --> 00:22:46.090
and catalog more and more situations about the distribution of conscious,

366
00:22:46.091 --> 00:22:49.960
maybe the intuition that robots won't be conscious.
That's an optional one.

367
00:22:49.961 --> 00:22:51.190
I think,
uh,

368
00:22:51.340 --> 00:22:56.110
or consciousness matters morally in certain ways and the list goes on.

369
00:22:56.920 --> 00:23:01.630
So I think there's an interdisciplinary research program here of working on

370
00:23:01.631 --> 00:23:04.810
those intuitions about consciousness and trying to explain them.

371
00:23:05.350 --> 00:23:10.060
Experimental psychology and experimental philosophy and newly active area can

372
00:23:10.061 --> 00:23:12.430
study people's intuitions about consciousness.

373
00:23:12.880 --> 00:23:14.650
We can work on models of these things,

374
00:23:14.651 --> 00:23:18.790
computational models on neuro biological models of these intuitions and reports.

375
00:23:19.060 --> 00:23:22.300
And indeed,
I think there's a lot of room for philosophical analysis.

376
00:23:22.300 --> 00:23:25.840
And this is just starting to be a program of people doing these things in all

377
00:23:26.680 --> 00:23:28.300
these fields.
I mean,

378
00:23:28.301 --> 00:23:32.350
it is an empirical question how widely these intuitions are shared.

379
00:23:32.351 --> 00:23:33.580
You might be sitting there thinking,
come on.

380
00:23:33.581 --> 00:23:37.060
I don't have any of these integrations.
Maybe this is just you.
I mean,

381
00:23:37.061 --> 00:23:39.580
my sense is from the psychological study to date,

382
00:23:39.760 --> 00:23:42.610
it seems that some of these intuitions about consciousness or at least very

383
00:23:42.611 --> 00:23:46.640
widely shared at least as dispositions or intuitions,

384
00:23:46.641 --> 00:23:50.030
although they're often overwritten on reflection,

385
00:23:50.510 --> 00:23:52.610
but you know the current data on this is somewhat limited.

386
00:23:53.780 --> 00:23:58.780
There is a lot of empirical work on intuitions about the mind concerning things

387
00:23:59.241 --> 00:23:59.931
like belief,

388
00:23:59.931 --> 00:24:03.710
like when the kids get the idea that your beliefs about the world can be false

389
00:24:03.980 --> 00:24:06.800
concerning the way your self persist through time.
You know,

390
00:24:06.801 --> 00:24:10.970
could you exist after the death of your buddy?
Well,
consciousness is concerned.

391
00:24:10.971 --> 00:24:14.060
There's work on the distribution of consciousness.
Could a robot be conscious?

392
00:24:14.061 --> 00:24:17.340
Could a group be conscious?
He's a book by Paul Bloom,
Descartes' baby,

393
00:24:17.360 --> 00:24:17.961
the catalogs.

394
00:24:17.961 --> 00:24:22.250
A lot of this interesting work making the case that many children are intuitive

395
00:24:22.251 --> 00:24:26.630
journalists thinks they're naturally inclined to think there's something

396
00:24:26.631 --> 00:24:29.330
nonphysical about the mind.
So far.

397
00:24:29.331 --> 00:24:34.070
Most of this work has not been so much on these core problem intuitions about

398
00:24:34.071 --> 00:24:36.960
consciousness,
but there's work developing in this direction.

399
00:24:36.961 --> 00:24:41.300
Now Sarah got leave and Tonya Lombroso have a very recent article called can

400
00:24:41.301 --> 00:24:46.301
science explain the human human mind on people's judgments about when various

401
00:24:46.341 --> 00:24:49.890
mental phenomena are hard to explain and they seem to find that yes,

402
00:24:49.891 --> 00:24:53.480
subjective experience and things which have to which people have privileged

403
00:24:53.481 --> 00:24:58.160
first person access seem to pose the problem big time.

404
00:24:58.161 --> 00:25:00.230
So there's the beginning of a recess program here.

405
00:25:00.230 --> 00:25:02.750
I think there's room for a lot more.

406
00:25:03.530 --> 00:25:05.550
The topic neutrality part where we,

407
00:25:05.660 --> 00:25:09.860
when I say we're looking for a topic neutral explanation of problem
integrations,

408
00:25:10.130 --> 00:25:14.150
that's roughly just say an explanation that doesn't mention consciousness
itself.

409
00:25:14.151 --> 00:25:18.410
It's put in neutral terms is neutral on the existence of consciousness.

410
00:25:18.411 --> 00:25:22.630
The most obvious one would be something like an algorithmic explanation I get to

411
00:25:22.631 --> 00:25:24.800
here is the algorithm the brain is executing.

412
00:25:25.010 --> 00:25:29.300
That generates our conviction that we're conscious and a reports about

413
00:25:29.301 --> 00:25:32.990
consciousness.
There may be some time between an algorithm and consciousness,

414
00:25:32.991 --> 00:25:37.820
but to specify the algorithm,
you don't need to make claims about consciousness.

415
00:25:38.090 --> 00:25:42.260
So the algorithmic version of the matter problem is roughly fund the Algorithm

416
00:25:42.500 --> 00:25:47.150
that generates our problem integration.
So that's I think in principle uh,

417
00:25:47.870 --> 00:25:49.730
uh,
research program that,
you know,

418
00:25:49.760 --> 00:25:54.620
maybe in AI researchers in combination with say psychologists,

419
00:25:54.830 --> 00:25:58.740
the psychologists could help isolate data about the way that uh,

420
00:25:58.760 --> 00:26:01.960
the human beings are doing it,
how these things are generated in the humans and,

421
00:26:01.961 --> 00:26:02.721
and the I researched,

422
00:26:02.721 --> 00:26:06.950
I couldn't try and see about implementing that algorithm in machines and see

423
00:26:06.951 --> 00:26:10.490
what results and I'll talk about a little bit of research in this direction in

424
00:26:10.491 --> 00:26:12.800
just a moment,
but okay,

425
00:26:12.801 --> 00:26:16.640
now I want to say something about potential solutions to the problem.

426
00:26:16.640 --> 00:26:19.520
Like I said,
this is a big research program.

427
00:26:19.521 --> 00:26:23.030
I don't claim to have the solution to the metal problem.
I've got some ideas,

428
00:26:23.031 --> 00:26:28.031
but I'm not going to try and lay out a major solution or just to hear a few

429
00:26:28.041 --> 00:26:32.060
things,
which I think might be parts of a solution to the problem.

430
00:26:32.180 --> 00:26:35.900
Many of which you've got antioxidants here and there in scientific and

431
00:26:35.901 --> 00:26:40.820
philosophical discussion.
Some promising ideas include retrospective,
muddles,

432
00:26:40.821 --> 00:26:45.450
phenomenal concepts,
introspective capacity,
the sense of acquaintance.

433
00:26:45.451 --> 00:26:47.670
Let me just say something about a few of these.

434
00:26:47.780 --> 00:26:52.780
We one starting idea that almost anyone's going to have here as somehow models

435
00:26:53.190 --> 00:26:57.390
of ourselves are playing a central role here.
You know,

436
00:26:57.570 --> 00:27:00.820
human beings have models of the world,
um,
you know,

437
00:27:00.990 --> 00:27:05.700
naive physics and now you've psychology muddles of other people and so on.

438
00:27:05.701 --> 00:27:07.470
We also have models of ourselves.

439
00:27:07.471 --> 00:27:11.730
It makes sense for us to have models of ourselves and our own mental processes.

440
00:27:11.760 --> 00:27:16.260
This is something that the psychologist,
Michael Graziano has written a lot on.

441
00:27:16.350 --> 00:27:19.920
We have internal models of our own cognitive processes,

442
00:27:19.921 --> 00:27:22.410
including those tied to consciousness.

443
00:27:23.460 --> 00:27:27.990
And somehow something about our introspective models explains our sense a that

444
00:27:27.991 --> 00:27:31.800
we are conscious and B,
that this is distinctively problematic.

445
00:27:31.801 --> 00:27:34.140
And I think you know,
anyone thinking about the metal problem,

446
00:27:34.950 --> 00:27:37.740
this has got to be at least the first step.
We have these,
uh,

447
00:27:38.010 --> 00:27:41.280
these introspective models.
If you were an illusionist,
there'll be false modals.

448
00:27:41.310 --> 00:27:43.860
If you're a realist,
they needn't be forced models.

449
00:27:43.890 --> 00:27:48.810
But at the very least these introspective modals are involved,
which is fine.

450
00:27:48.811 --> 00:27:53.190
Okay.
But the devil's in the details.
How do they work to generate this,
uh,

451
00:27:53.191 --> 00:27:55.470
this problem and number of philosophers visit have argued,

452
00:27:55.471 --> 00:27:58.110
we have special concepts of consciousness,

453
00:27:58.111 --> 00:28:02.040
introspective concepts of these special subjective states.

454
00:28:02.041 --> 00:28:06.060
People call these phenomenal concepts,
concepts of phenomenal consciousness.

455
00:28:06.060 --> 00:28:11.060
And one thing that's special is these concepts of somehow independent of our

456
00:28:11.701 --> 00:28:15.290
physical concepts.
They explain,
you know,

457
00:28:15.330 --> 00:28:19.200
we've got one set of physical concepts of modeling the external work world.

458
00:28:19.201 --> 00:28:21.990
We've got one set of introspective concepts from modeling our own mind.

459
00:28:21.991 --> 00:28:24.660
And these concepts just by virtue of the way they're designed is somewhat

460
00:28:24.661 --> 00:28:25.740
independent of each other.

461
00:28:26.040 --> 00:28:31.040
And that partly explains why consciousness seems to be independent of the

462
00:28:31.381 --> 00:28:33.120
physical world intuitively.

463
00:28:33.360 --> 00:28:37.920
And so maybe that independence of phenomenal concepts could go some distance to

464
00:28:37.921 --> 00:28:40.590
explaining our problem reports.

465
00:28:40.591 --> 00:28:44.820
And I think there's got to be something to this as well.
At the same time,

466
00:28:44.821 --> 00:28:47.640
I don't think this goes nearly far enough because you know,
we,

467
00:28:47.670 --> 00:28:49.770
we have concepts of many aspects of the mind,

468
00:28:49.771 --> 00:28:54.060
not just of the subjective experiential pass but things we believe and things we

469
00:28:54.061 --> 00:28:58.980
desire and so on.
I believe that Paris is the capital of France.

470
00:28:59.430 --> 00:29:01.080
That's part of my internal self model,

471
00:29:01.081 --> 00:29:05.610
but that doesn't seem to generate the hard problem in nearly the same way in

472
00:29:05.611 --> 00:29:07.440
which say the experience of red does.

473
00:29:07.441 --> 00:29:12.441
So a lot more needs to be said about what's going on in cases like having the

474
00:29:12.691 --> 00:29:15.810
experience of red and having the sense that that generates a gap.

475
00:29:15.990 --> 00:29:20.870
So it doesn't generalize to everything about the mind.
Um,

476
00:29:20.940 --> 00:29:24.860
some people have thought that what we might call introspective or passively

477
00:29:24.900 --> 00:29:29.460
plays a role that when we introspect what's going on in our minds,

478
00:29:29.461 --> 00:29:32.280
we don't have access to the underlying physical states.

479
00:29:32.281 --> 00:29:34.680
We don't see the neurons in our brains.

480
00:29:34.681 --> 00:29:36.900
We don't see that consciousness is physical.

481
00:29:37.110 --> 00:29:41.800
So we see it as nonphysical.
Most recently,
um,
uh,

482
00:29:41.801 --> 00:29:44.650
the physicist Max Tegmark has argued in this direction saying somehow

483
00:29:44.651 --> 00:29:47.440
consciousness is sub straight independent.
We don't see the substrate.

484
00:29:47.740 --> 00:29:52.700
So then we think,
oh,
maybe it can flip free of the substrate.
Um,

485
00:29:52.750 --> 00:29:55.500
I'm strong,
made an analogy with the,

486
00:29:55.830 --> 00:29:58.140
the case of someone in a circus where,
um,

487
00:29:59.020 --> 00:30:01.400
the headless person illusion where you know,

488
00:30:01.401 --> 00:30:05.380
you don't see someone's there with the veil across their head,

489
00:30:06.770 --> 00:30:07.720
you don't see their head.

490
00:30:07.721 --> 00:30:12.721
So you see them as having no head here as a 19th century booth at a circus,

491
00:30:13.210 --> 00:30:16.400
so called headless woman.
There's a veil over her head.
You don't see the heads.

492
00:30:16.401 --> 00:30:19.240
So somehow it looks at least for a moment,
like the person doesn't have a head.

493
00:30:19.510 --> 00:30:23.080
So I'm strongly as maybe that's how it is with consciousness.

494
00:30:23.470 --> 00:30:27.520
You don't see that it's physical,
so you see it as nonphysical.
Um,

495
00:30:28.240 --> 00:30:30.510
but still the question comes up,
how do we make this a,

496
00:30:30.880 --> 00:30:32.650
how do we make this inference?
I mean,

497
00:30:32.651 --> 00:30:37.270
there's something that special goes on in cases like say color and taste and so

498
00:30:37.271 --> 00:30:41.620
on.
Color experience seems to attribute primitive properties.

499
00:30:41.620 --> 00:30:45.970
Two objects like redness,
greenness,
and so on.
When in fact,
in the external world,

500
00:30:45.971 --> 00:30:50.770
at the very least,
they have complex reduceable properly.
Somehow.
I'm internal,

501
00:30:50.800 --> 00:30:55.570
but our models of color treat colors like red and green as if they are primitive

502
00:30:55.571 --> 00:31:00.130
things.
It turns out to be useful to have these models of things.

503
00:31:00.131 --> 00:31:03.730
We treat certain things as primitive even though they're reducible.

504
00:31:03.731 --> 00:31:05.740
And it sure seems that when we experience colors,

505
00:31:06.010 --> 00:31:10.960
we experienced green this as a primitive quality even though it may be a very,

506
00:31:10.961 --> 00:31:15.580
very complex reduceable property.
That's something about our model of colors.

507
00:31:15.670 --> 00:31:19.930
The philosopher Wolfgang Schwartz has tried to make an analogy with sensor

508
00:31:19.931 --> 00:31:23.170
variables in say image processing.
You've got a,

509
00:31:23.620 --> 00:31:27.130
you've got some visual sensors and a camera or something and you need to process

510
00:31:27.131 --> 00:31:31.940
the image.
We've got some variables,
some sense of variables to represent.
Um,

511
00:31:31.990 --> 00:31:32.231
you know,

512
00:31:32.231 --> 00:31:35.050
the sensory inputs at the various sensors are getting and you might treat them

513
00:31:35.350 --> 00:31:38.650
as a primitive dimension because that's the most useful way to treat them.

514
00:31:38.650 --> 00:31:42.520
You don't treat them as certain amounts of lights or photons fire and you don't

515
00:31:42.521 --> 00:31:43.480
need to know about that.

516
00:31:44.040 --> 00:31:49.040
Use The sensor variables and treat them as a primitive dimension and all that

517
00:31:49.151 --> 00:31:51.670
will play into a model of these things as primitive.

518
00:31:51.970 --> 00:31:55.840
Maybe taking that idea and extending it to introspection,
you know,

519
00:31:55.841 --> 00:31:57.250
somehow these,

520
00:31:57.820 --> 00:32:01.990
these conscious states are somehow like sensor variables in our model of the

521
00:32:01.991 --> 00:32:06.991
mind and somehow these internal models give us the sense of being acquainted

522
00:32:07.450 --> 00:32:11.650
with primitive concrete qualities and of our awareness of them.

523
00:32:12.310 --> 00:32:13.330
Is it still just laying out?

524
00:32:13.331 --> 00:32:16.180
I don't think this is still the it actually explaining a whole lot,

525
00:32:16.181 --> 00:32:17.050
but it's laying out.

526
00:32:17.051 --> 00:32:21.800
It's narrowing down what it is that we need to explain to solve the major

527
00:32:21.801 --> 00:32:25.090
problem,
but just to put the pieces together.
Here's a little summary.

528
00:32:25.091 --> 00:32:29.500
One thing I like about this summary as you can read it in either an illusionist

529
00:32:29.740 --> 00:32:33.550
tone of voice as an account of the illusion of consciousness.

530
00:32:33.550 --> 00:32:38.550
All of this is how our false introspective models work or in a realist tone of

531
00:32:38.561 --> 00:32:40.370
voice as an account of our,

532
00:32:41.300 --> 00:32:45.020
our true correct models of consciousness,

533
00:32:45.021 --> 00:32:48.170
but we can set it out in a way which is neutral on the two and then try and

534
00:32:48.171 --> 00:32:52.220
figure out later what are these models are correct as the realist says or

535
00:32:52.221 --> 00:32:55.850
incorrect.
As the illusionist says,
we have introspective,

536
00:32:55.851 --> 00:33:00.851
muddles deploying introspective concepts of our internal states that are largely

537
00:33:02.631 --> 00:33:05.360
independent of our physical concepts.

538
00:33:06.020 --> 00:33:10.340
These concepts are introspectively okayk not revealing any of the underlying

539
00:33:10.341 --> 00:33:15.341
mechanisms are perceptual muddles perceptually attribute primitive perceptual

540
00:33:15.531 --> 00:33:20.531
qualities to the world and are introspective muddles attribute primitive mental

541
00:33:21.591 --> 00:33:23.750
relations to those qualities.

542
00:33:24.140 --> 00:33:29.140
These models produced the sense of acquaintance both with those qualities and

543
00:33:30.291 --> 00:33:34.250
with our awareness of those qualities.
Like I said,

544
00:33:34.251 --> 00:33:36.320
this is not a solution to the metal problem,

545
00:33:36.321 --> 00:33:39.730
but it's trying at least to pin down some some parts of the,

546
00:33:39.880 --> 00:33:44.270
of the roots of those intuitions and to narrow down what needs to be explained

547
00:33:44.420 --> 00:33:45.770
to go further.
You want,

548
00:33:45.771 --> 00:33:49.580
I think to test these explanations both with psychological studies to see if

549
00:33:50.300 --> 00:33:52.490
this is plausibly what's going on in humans.

550
00:33:52.491 --> 00:33:56.360
This is the kind of thing which is the basis of our intuitions and computational

551
00:33:56.361 --> 00:33:57.500
models to see if for example,

552
00:33:57.501 --> 00:34:00.920
you could program this kind of thing into an AI system and see if it can

553
00:34:00.921 --> 00:34:05.921
generate somehow qualitatively similar reports and intuitions.

554
00:34:06.710 --> 00:34:10.710
You might think that last thing is a bit far fetched right now.
But I knew,

555
00:34:10.730 --> 00:34:13.160
I knew of at least one instance of this research program,

556
00:34:13.161 --> 00:34:18.161
which has been put into play by a Luke Millhauser and buck sluggers,

557
00:34:18.591 --> 00:34:22.340
two researchers at open philanthropy,
very interested in um,

558
00:34:23.360 --> 00:34:27.080
in Ai and consciousness.
They actually built,

559
00:34:27.530 --> 00:34:30.800
they took some ideas about the metal problem from something I'd written about it

560
00:34:31.010 --> 00:34:36.010
and from something that the philosopher from swap camera had written about it.

561
00:34:36.360 --> 00:34:40.700
It's a couple of basic ideas about where problems situations might come from.

562
00:34:40.880 --> 00:34:44.450
And they tried to build them in to where computational model,

563
00:34:45.230 --> 00:34:47.230
they built a little a three,

564
00:34:47.240 --> 00:34:52.240
they built a little software agent which had certain axioms about cowers and how

565
00:34:52.791 --> 00:34:53.531
they work.
You know,

566
00:34:53.531 --> 00:34:57.860
there's red and there's green and certain axioms about their own subjective

567
00:34:57.861 --> 00:35:00.830
experiences of colors.

568
00:35:01.130 --> 00:35:05.300
And then they combined it with little theorem prover and,
and they saw what,

569
00:35:05.750 --> 00:35:09.230
what did this little software agent come up with and it came up with claims
like,

570
00:35:09.380 --> 00:35:10.730
Hey,
well my own,

571
00:35:11.200 --> 00:35:15.560
my experiences of color are distinct from any physical state and so on.
I mean,

572
00:35:15.561 --> 00:35:20.270
okay,
they cut a few corners.
This is not a,
this is not yeah,
to truly,

573
00:35:20.271 --> 00:35:24.980
uh,
uh,
convincing sophisticated,
uh,
model of everything going on in the,
uh,

574
00:35:25.070 --> 00:35:29.380
in the human mind.
But it,
but it shows that there's a research program here,
um,

575
00:35:29.450 --> 00:35:33.260
of trying to find the algorithmic basis of these states.

576
00:35:33.260 --> 00:35:35.960
And I think as more sophisticated models,
uh,
develop,

577
00:35:35.961 --> 00:35:40.420
we might be able to use these to kind of provide a way in for AI researchers in

578
00:35:40.421 --> 00:35:42.900
thinking about this topic.
Of course there is the question,

579
00:35:43.440 --> 00:35:47.130
you model all this stuff better and better in a machine then is the machine

580
00:35:47.160 --> 00:35:51.930
actually going to be conscious or is it Jessica [inaudible] found self models

581
00:35:52.230 --> 00:35:56.640
that replicate what's going on in,
uh,
in humans.
So,
you know,

582
00:35:56.641 --> 00:36:00.780
some people have proposed an artificial consciousness test.
Uh,

583
00:36:00.870 --> 00:36:01.730
Aaron Sloman,

584
00:36:01.740 --> 00:36:05.940
Susan Snyder at Turner have suggested that somehow that if a machine,

585
00:36:06.100 --> 00:36:10.290
it seems to be puzzled about consciousness in roughly the ways that we are.

586
00:36:10.440 --> 00:36:13.920
Maybe that's actually a sign that it's conscious.
So you know,

587
00:36:14.490 --> 00:36:19.300
if a machine actually looks to ask is if it's puzzled by conscious

588
00:36:19.570 --> 00:36:22.140
consciousness,
is that a sign of consciousness?
These people,

589
00:36:22.170 --> 00:36:25.470
this is suggested as kind of Turing test for machine consciousness,

590
00:36:25.740 --> 00:36:29.220
find machines which are conscious like we are of course the opposing point of

591
00:36:29.221 --> 00:36:31.200
view is going to be another machine is not actually conscious.

592
00:36:31.410 --> 00:36:35.460
It's just like the machine that studied up for the cheering test by reading the

593
00:36:35.461 --> 00:36:37.290
talk like a human book.
I was like,
damn,

594
00:36:37.291 --> 00:36:42.180
do I really need to confess to a convince those humans that I'm conscious by row

595
00:36:42.450 --> 00:36:43.283
by,
uh,

596
00:36:43.560 --> 00:36:47.280
by replicating a little those ill-conceived confusions about consciousness?
Well,

597
00:36:47.281 --> 00:36:50.940
I guess I can do it if I,
uh,
if I need to.
Anyway,

598
00:36:50.941 --> 00:36:52.680
I'm not going to settle this question here,

599
00:36:52.681 --> 00:36:56.800
but I do think that if we somehow find machines being puzzled,
it's not,

600
00:36:57.500 --> 00:37:00.570
it won't surprise me that once we actually have serious AI systems which

601
00:37:00.580 --> 00:37:04.470
engaging in natural language and muddling of themselves in the world,

602
00:37:05.520 --> 00:37:08.100
they might well be natural find themselves saying things like,
well,
yeah,

603
00:37:08.101 --> 00:37:11.700
I know in principle I'm just a set of silicon circuits.

604
00:37:11.730 --> 00:37:14.880
But I feel like so much more.
Um,

605
00:37:14.940 --> 00:37:18.120
I think that might tell us something about consciousness.

606
00:37:18.810 --> 00:37:23.010
Let me just say a little bit about theories of consciousness.

607
00:37:23.190 --> 00:37:27.000
I do think a solution to the metal problem and a solution to the hard problem

608
00:37:27.060 --> 00:37:31.110
ought to be closely connected.
The allusionist says,
solve the major problem.

609
00:37:31.111 --> 00:37:32.460
You'll dissolve the hard problem,

610
00:37:32.461 --> 00:37:35.280
but even if you're not an illusionist about consciousness,

611
00:37:35.730 --> 00:37:39.240
there ought to be some link.
So here's the thesis.

612
00:37:39.450 --> 00:37:44.450
Whatever explains consciousness should also partly explain our judgments.

613
00:37:44.970 --> 00:37:47.880
Now reports about consciousness.

614
00:37:47.970 --> 00:37:51.900
The rationale here is we'd just be very strange if these things were
independent,

615
00:37:52.490 --> 00:37:57.490
if the basis of consciousness played no role in our judgments about

616
00:37:58.050 --> 00:38:02.610
consciousness,
so they can use this as a way of evaluating or testing.

617
00:38:02.611 --> 00:38:07.290
Theories of consciousness for theory of consciousness says mechanism.

618
00:38:07.291 --> 00:38:09.930
M is the basis of consciousness.

619
00:38:10.470 --> 00:38:15.470
That m should also partly explain our judgments about consciousness,

620
00:38:15.811 --> 00:38:19.560
whatever the basis is,
or to explain the reports and you can use this.

621
00:38:19.560 --> 00:38:24.330
You can bring this to bear on various extant theories of consciousness.

622
00:38:24.331 --> 00:38:27.570
Here's one famous current theory of consciousness.

623
00:38:27.571 --> 00:38:31.920
Integrated information theory developed by Giulio Tononi and colleagues at the

624
00:38:32.490 --> 00:38:36.880
University of Wisconsin.
Um,
Tony says,

625
00:38:36.910 --> 00:38:40.300
integrate the basis of consciousness is integrated information,

626
00:38:40.900 --> 00:38:44.210
a certain kind of integration of information,
um,

627
00:38:44.380 --> 00:38:48.970
for which Tony has a measure that he calls fi basically when your fire as high

628
00:38:48.971 --> 00:38:53.800
enough you get,
you get consciousness.
A consciousness is high fi.
Um,

629
00:38:54.040 --> 00:38:57.370
and you know,
there's a mathematical definition but I won't go into it here,

630
00:38:57.940 --> 00:38:59.980
but uh,
it's,
it's a really interesting theory.

631
00:39:00.010 --> 00:39:03.220
So here's that basically analyzes and network property of,

632
00:39:03.530 --> 00:39:08.260
of systems of units and it's got a informational measure called five supposed to

633
00:39:08.261 --> 00:39:10.330
go with consciousness question.

634
00:39:11.140 --> 00:39:14.560
How does integrated information as the basis of consciousness,

635
00:39:14.740 --> 00:39:19.150
it ought to explain problem reports,
at least in principle challenge.

636
00:39:19.180 --> 00:39:20.110
How does that work?

637
00:39:20.190 --> 00:39:24.130
And it's at least far from obvious to me how integrated information we'll

638
00:39:24.131 --> 00:39:28.750
explain the problem reports.
It seems pretty dissociated from them.

639
00:39:29.020 --> 00:39:30.490
I mean Antonis view,

640
00:39:30.491 --> 00:39:35.491
you can have simulations of systems with high fi that have zero fi they'll go

641
00:39:36.401 --> 00:39:40.150
about making exactly the same reports,
but without consciousness at all.

642
00:39:40.151 --> 00:39:42.670
So fires at least somewhat to sociable.

643
00:39:43.060 --> 00:39:47.210
You get systems very high fi no tendency to um,

644
00:39:47.890 --> 00:39:51.250
to report.
Maybe that's less worrying anyways.
Here's a challenge for this theory.

645
00:39:51.251 --> 00:39:54.820
For other theories.
Explain not just how high fi gives you consciousness,

646
00:39:55.150 --> 00:40:00.150
but how it plays a central role on the algorithms that generate problem report.

647
00:40:00.520 --> 00:40:03.970
Something similar goes for many other theories,
biological theories,

648
00:40:03.971 --> 00:40:07.870
quantum theories,
global workspace and so on.

649
00:40:08.650 --> 00:40:13.180
But let me just wrap up by saying something about the issue of illusionism that

650
00:40:13.181 --> 00:40:16.120
I was talking about near the start.
Again,

651
00:40:16.121 --> 00:40:19.960
you might be inclined to think that this approach through the matter problem

652
00:40:20.350 --> 00:40:24.070
tens at least very naturally to lead to illusionism and I think it can be,

653
00:40:24.670 --> 00:40:25.481
it certainly provides,

654
00:40:25.481 --> 00:40:30.010
I think some motivation for illusionism the view that consciousness doesn't

655
00:40:30.011 --> 00:40:33.430
exist.
We just think it does on this view.
Again,

656
00:40:33.431 --> 00:40:37.600
a solution to the matter problem dissolves the hard problem.

657
00:40:38.740 --> 00:40:41.680
So here's one way of putting the case for illusionism.

658
00:40:42.160 --> 00:40:44.500
If there's a solution to the metal problem,

659
00:40:44.890 --> 00:40:48.610
then there's an explanation of our beliefs about consciousness that's

660
00:40:48.640 --> 00:40:50.170
independent of consciousness.

661
00:40:50.200 --> 00:40:53.380
There's an algorithm that explains I beliefs about consciousness,

662
00:40:53.381 --> 00:40:57.340
doesn't mention consciousness,
arguably could be in place without consciousness.

663
00:40:57.790 --> 00:41:02.790
Arguably that kind of explanation could debunk our beliefs about consciousness.

664
00:41:03.400 --> 00:41:08.400
The same way that perhaps explaining beliefs about God in evolutionary terms

665
00:41:08.890 --> 00:41:12.610
might debunk belief in God.
It's certainly doesn't prove that God doesn't exist.

666
00:41:12.910 --> 00:41:16.140
You might think that if you can explain our beliefs in terms of evolution and

667
00:41:16.150 --> 00:41:21.150
somehow it removes the justification or the rational basis for those beliefs.

668
00:41:21.191 --> 00:41:24.790
So something like that I think can be applied to consciousness to,

669
00:41:24.791 --> 00:41:28.780
and there's a lot to be said about analyzing the extent to which this might

670
00:41:28.781 --> 00:41:32.800
debunk the beliefs.
On the other hand,
the case against illusionism,

671
00:41:33.580 --> 00:41:36.950
is it very,
very strong for many people and the underlying worry,

672
00:41:36.951 --> 00:41:39.740
is it something like illusion doesn't miss completely unbelievable.

673
00:41:39.770 --> 00:41:44.330
It's just a manifest fact about ourselves that we have conscious experience.
We,

674
00:41:44.331 --> 00:41:48.100
uh,
we experienced red,
we feel pain and so on.

675
00:41:48.101 --> 00:41:52.010
And to deny those things is to deny the data.
No,
you know,

676
00:41:52.011 --> 00:41:55.670
the dielectric here is complicated.
The illusion will come back and say yes,

677
00:41:55.671 --> 00:41:59.510
but I can explain why it illusionism is unbelievable.
These models,

678
00:41:59.511 --> 00:42:03.110
we have these self models of consciousness as so strong that,
you know,

679
00:42:03.111 --> 00:42:05.270
they were just wired into us by evolution and they're not,

680
00:42:05.330 --> 00:42:07.220
they're not models we can,
we can get rid of.

681
00:42:07.221 --> 00:42:12.221
So my view predicts that my view is unbelievable and the question is what the

682
00:42:12.440 --> 00:42:15.590
diarrhea electrical situation is,
uh,
is complex and interesting.

683
00:42:15.591 --> 00:42:20.591
But maybe I could just wrap up with two expressions of absurdity on either sides

684
00:42:21.441 --> 00:42:24.080
of this question.
The illusionist and the,
uh,

685
00:42:24.800 --> 00:42:29.800
the anti illusionists both finding absurdity in the other person's views,

686
00:42:31.191 --> 00:42:34.860
his,
uh,
his Galen Strawson,
um,
who was here,
Galen,

687
00:42:35.000 --> 00:42:38.180
his view is very much that illusionism is totally absurd.
In fact,

688
00:42:38.181 --> 00:42:42.530
he thinks it's the most absurd view that anyone has ever held there occurred in

689
00:42:42.531 --> 00:42:46.970
the 20th century,
the most remarkable episode in the whole history of ideas.

690
00:42:47.270 --> 00:42:51.530
The whole history of human thought and number of thinkers denied the existence

691
00:42:51.531 --> 00:42:55.130
of something we know with certainty to exist consciousness.

692
00:42:55.460 --> 00:42:59.950
He thinks this is just a sign of incredible philosophical pathology.
Uh,

693
00:43:00.320 --> 00:43:02.270
here's the rationalist philosopher Eliezer,

694
00:43:02.271 --> 00:43:04.630
you'd Koski in something he wrote a few years ago on a,

695
00:43:04.970 --> 00:43:09.500
on zombies and consciousness and uh,
and the view,

696
00:43:09.590 --> 00:43:10.341
the Epi phenomenon,

697
00:43:10.341 --> 00:43:13.670
list views that consciousness plays no causal role where he was engaging some

698
00:43:13.671 --> 00:43:18.140
stuff.
I wrote,
um,
a couple of decades ago,
he said this Zombie argument,
the idea,

699
00:43:18.141 --> 00:43:20.960
we can imagine zombies physically like us,
but without consciousness,

700
00:43:21.140 --> 00:43:25.820
maybe a candidate for the most deranged idea in all our philosophy,

701
00:43:26.390 --> 00:43:30.020
the causally closed cognitive system of Traumas,

702
00:43:30.021 --> 00:43:35.021
internal narrative is malfunctioning in a way that not by necessity but just in

703
00:43:35.511 --> 00:43:39.560
our own universe miraculously happens to be correct.

704
00:43:40.280 --> 00:43:43.040
And here he is expressing this to banking idea that,
you know,
on this view,

705
00:43:43.041 --> 00:43:46.430
like there's an algorithm that generates these intuitions about consciousness

706
00:43:46.431 --> 00:43:47.630
and that's all physical.

707
00:43:47.810 --> 00:43:50.540
And there's also this further layer of nonphysical stuff.

708
00:43:50.780 --> 00:43:53.840
And just by massive coincidence,
the uh,

709
00:43:53.870 --> 00:43:58.870
the physical algorithm is a correct model of the non physical stuff.
And these,

710
00:43:58.980 --> 00:44:02.390
that's a,
that's a,
that's a form of debunking here.

711
00:44:02.391 --> 00:44:04.700
It would take a miracle for this view to be correct.

712
00:44:04.701 --> 00:44:09.620
So I think both of these views are on to these objections are onto something and

713
00:44:09.621 --> 00:44:10.760
to make progress on this,

714
00:44:10.761 --> 00:44:15.050
when I decide we need to find a way of getting past these absurdities,

715
00:44:15.051 --> 00:44:15.771
I mean you might say,

716
00:44:15.771 --> 00:44:19.670
well there's middle ground between very strong illusionism and very strong Epi

717
00:44:19.671 --> 00:44:20.504
for nominalism.

718
00:44:20.780 --> 00:44:25.780
It tends to slide back to the same problems other forms of illusionism weaker

719
00:44:26.511 --> 00:44:28.550
forms don't help much with the highest problem.

720
00:44:29.270 --> 00:44:32.350
Other forms of realism is still subject to this,
uh,

721
00:44:32.420 --> 00:44:35.700
takes a miracle for this view to be correct critique.

722
00:44:35.910 --> 00:44:40.910
So I think to get beyond absurd as he hear both sides need to do something more.

723
00:44:41.281 --> 00:44:41.751
The illusion,

724
00:44:41.751 --> 00:44:46.751
this needs to do more to explain how having a mind could be like this time I'll

725
00:44:47.030 --> 00:44:51.120
just like this.
Even though it's not at all the way that it seems,

726
00:44:51.180 --> 00:44:53.190
you need to find some way to recapture the data.

727
00:44:54.180 --> 00:44:59.180
Realists need to explain how it is that these metal problem processes co I'm not

728
00:44:59.581 --> 00:45:02.320
completely independent of consciousness.
Realistically,

729
00:45:02.340 --> 00:45:07.170
to explain how Metta problem processes the ones that generate these intuitions

730
00:45:07.171 --> 00:45:11.340
and reports and convictions about consciousness are essentially grounded in

731
00:45:11.341 --> 00:45:14.180
consciousness.
Even if it's possible somehow for them to,

732
00:45:14.290 --> 00:45:19.290
or conceivable for them to occur without consciousness anyway.

733
00:45:19.921 --> 00:45:22.530
So that's just to lay out a research program.

734
00:45:22.531 --> 00:45:27.531
I think a solution to the metal problem that meets these ambitions might just

735
00:45:27.961 --> 00:45:32.460
possibly solve the hard problem of consciousness or at the very least shed

736
00:45:32.461 --> 00:45:35.190
significant light on it.
In the meantime,

737
00:45:35.280 --> 00:45:39.330
the metal problem is a potentially tractable research project for everyone and

738
00:45:39.331 --> 00:45:41.100
mine,
I recommend to all of you.
Thanks.

739
00:45:48.070 --> 00:45:51.370
<v 3>Uh,
yes.
I just want to say I think it's very interesting,</v>

740
00:45:51.640 --> 00:45:54.700
this concept of we have these mental models,

741
00:45:55.000 --> 00:46:00.000
a collection of mental models and that this collection of mental models is con

742
00:46:01.980 --> 00:46:03.600
consciousness.
Basically.
Um,

743
00:46:03.820 --> 00:46:07.120
consciousness is defined as a collection of these mental models that we have.

744
00:46:07.480 --> 00:46:11.260
And the problem of consciousness is that we don't understand the physical

745
00:46:11.261 --> 00:46:13.770
phenomenon that,
that causes these mental models,

746
00:46:13.800 --> 00:46:17.660
models or that stimulates these mental models.
Um,

747
00:46:17.710 --> 00:46:20.660
so we just have this belief that it's,
you know,

748
00:46:21.110 --> 00:46:24.910
if femoral or not real or something like that.
Um,

749
00:46:25.600 --> 00:46:29.920
and it's,
if you take that view,
then what's interesting is that you could,

750
00:46:30.520 --> 00:46:33.500
you could simulate these mental models,
uh,

751
00:46:33.610 --> 00:46:36.790
like robot could simulate this mental models.
Um,

752
00:46:36.940 --> 00:46:41.050
and you could simulate consciousness,
uh,
as well.
Um,

753
00:46:41.230 --> 00:46:45.670
and even if the underlying physical phenomenon that fuels these mental models is

754
00:46:45.671 --> 00:46:49.450
different,
you know,
robots have different sensors,
et Cetera,
um,

755
00:46:49.540 --> 00:46:54.070
you could still get the same consciousness effect,
um,
in both cases.

756
00:46:54.520 --> 00:46:54.780
Okay.

757
00:46:54.780 --> 00:46:56.220
<v 1>Yeah,
I think that's that's right.</v>

758
00:46:56.221 --> 00:46:58.650
Or at the very least you ought to be able to get,

759
00:46:58.710 --> 00:47:00.600
it looks like you ought to be able to get the same models,

760
00:47:00.780 --> 00:47:05.780
at least in a robot if the models themselves or something algorithmic and ought

761
00:47:06.091 --> 00:47:08.910
to be,
ought to be able to design a robot that has,
at the very least,

762
00:47:09.010 --> 00:47:13.230
let's say isomorphic models and some sense that is conscious.

763
00:47:13.470 --> 00:47:15.210
Of course it is a further question at least by my lights.

764
00:47:15.211 --> 00:47:17.820
What are then the robot will be conscious.

765
00:47:17.821 --> 00:47:20.100
And that was the question I alluded to and talking about the artificial

766
00:47:20.340 --> 00:47:21.120
consciousness tests.

767
00:47:21.120 --> 00:47:24.240
You might think that would at least be very good evidence that the robot is

768
00:47:24.241 --> 00:47:27.510
conscious.
If it's got a model of consciousness just like ours,

769
00:47:27.720 --> 00:47:28.800
it seems very plausible.

770
00:47:28.801 --> 00:47:32.130
There ought be a very strong link if you're having a model like that and be

771
00:47:32.131 --> 00:47:34.690
unconscious.
I mean,
I think probably,
um,

772
00:47:35.500 --> 00:47:38.320
something like ned block who was here arguing against me,
machines consciousness,

773
00:47:38.321 --> 00:47:40.330
but say,
no,
no,
the model is not enough.

774
00:47:40.630 --> 00:47:42.250
The model has to be built with the right stuff.

775
00:47:42.260 --> 00:47:44.740
Say it's got to be built to biology and so on.
But at least by my lights,

776
00:47:45.250 --> 00:47:49.210
I think if I have found that AI system that had a very serious,
uh,

777
00:47:49.270 --> 00:47:50.920
version of our model of consciousness,

778
00:47:50.921 --> 00:47:53.530
I'd take that as a very good reason to believe it's conscious.

779
00:47:55.500 --> 00:47:57.040
In the IIT theory.

780
00:47:57.160 --> 00:48:02.160
Is there a estimate or plausible estimate for what the value of Phi is for

781
00:48:02.261 --> 00:48:06.790
people and for other systems?
Basically,
no.

782
00:48:06.910 --> 00:48:11.830
Um,
it's extremely hard to measure,
um,

783
00:48:12.520 --> 00:48:14.410
in systems of any size at all.
I mean,

784
00:48:14.440 --> 00:48:18.730
because the way is to find that involves taking a som over every possible

785
00:48:18.731 --> 00:48:22.090
partition of a system.
It turns out we a,

786
00:48:22.091 --> 00:48:25.390
it's hard to measure in the brain because you've got to involve the causal

787
00:48:25.391 --> 00:48:27.490
dependencies separate in different units on neurons.

788
00:48:27.520 --> 00:48:30.070
But even for a pure algorithmic system,

789
00:48:30.071 --> 00:48:34.210
you've got to like a neural network laid out in a,
in front of you.

790
00:48:34.480 --> 00:48:37.810
It's computationally intractable to measure the fire of one of those once I get

791
00:48:37.811 --> 00:48:41.370
to bigger than 15 units or,
uh,
also,
so he had no,

792
00:48:41.420 --> 00:48:44.170
you'd like to say this isn't empirical theory and in principle empirically

793
00:48:44.171 --> 00:48:48.940
testable.
But notice the,
in principle,
it's extremely difficult to,
uh,
to,
uh,

794
00:48:49.630 --> 00:48:53.510
to measure it by some people.
I'm Scott Aaronson.
Uh,

795
00:48:53.511 --> 00:48:57.130
the computer scientist has,
uh,
has argued,

796
00:48:57.340 --> 00:49:01.270
has tried to put forward counterexamples to the theory,
which are basically very,

797
00:49:01.271 --> 00:49:05.270
very simple systems like matrix multipliers,
uh,
that,
you know,

798
00:49:05.290 --> 00:49:07.960
multiply two large matrix.
He's turned out to have enormous fi,

799
00:49:08.320 --> 00:49:10.200
fi as big as you like.
If the Matrix,

800
00:49:10.201 --> 00:49:14.020
these are big enough and therefore by Tony's theory will not just be conscious,

801
00:49:14.021 --> 00:49:15.820
but as conscious as a human being.

802
00:49:15.821 --> 00:49:19.990
And Aronson put this forward as a reductio ad absurdum of the Iot theory,

803
00:49:19.991 --> 00:49:23.110
I think to know any,
basically we bit the bullet and said,
Yo,
yeah,
those,

804
00:49:23.111 --> 00:49:27.040
those metrics modifiers are actually having some high degree of consciousness.

805
00:49:28.740 --> 00:49:31.960
So I think Iot is probably missing at least missing a few pieces of it's going

806
00:49:31.961 --> 00:49:34.600
to be developed.
But it's a research program too.

807
00:49:36.110 --> 00:49:40.220
<v 4>You mentioned the leaf as an example of something where uh,</v>

808
00:49:40.840 --> 00:49:43.430
does another mental quality,
but people don't seem to have the same

809
00:49:45.430 --> 00:49:48.110
sense that it is very hard to explain it.
In fact,

810
00:49:49.040 --> 00:49:53.300
it almost seems too easy where people like a belief about something sorta feels

811
00:49:53.301 --> 00:49:57.620
like just how things are.
Like you have to kind of reflect on it,
I believe,

812
00:49:57.621 --> 00:50:01.160
to notice it as a belief.
Uh,
do you think there's also,

813
00:50:01.170 --> 00:50:05.570
or has there been a research kind of related to this question and two,

814
00:50:05.960 --> 00:50:07.930
why is that different?
Like,
uh,

815
00:50:07.940 --> 00:50:11.090
it seems like another angle of attack on this problem.
It was just like,

816
00:50:11.091 --> 00:50:12.890
why doesn't this generate the same hard problem?

817
00:50:13.880 --> 00:50:15.200
<v 1>Yeah.
In terms,</v>

818
00:50:15.201 --> 00:50:19.250
I'm not sure if there's been sort of research from the perspective of the metal

819
00:50:19.251 --> 00:50:22.550
problem or a theory of mine.
Suddenly people have thought in their own right,

820
00:50:22.551 --> 00:50:26.510
what is the difference between belief and experience that makes them so

821
00:50:26.511 --> 00:50:26.761
different?

822
00:50:26.761 --> 00:50:31.761
This goes way back to David Hume who philosopher a few centuries ago who said,

823
00:50:32.270 --> 00:50:35.240
you know,
I'm basically perception is vivid impression.

824
00:50:35.270 --> 00:50:40.070
Many impressions and ideas and impressions like experiencing collars are vivid,

825
00:50:40.120 --> 00:50:45.120
they have force and vivacity and ideas are merely up faint copy or something.

826
00:50:45.190 --> 00:50:46.340
But that's just the first order.

827
00:50:46.400 --> 00:50:49.010
And then there were contemporary versions of this kind of thing.

828
00:50:49.011 --> 00:50:52.250
Far more sophisticated ways of saying a similar thing.
But yeah,

829
00:50:52.251 --> 00:50:56.900
you could in principle,
um,
explore that through the metal problem.

830
00:50:56.901 --> 00:51:00.870
Why does it seem to us that perception is so much more vivid?
What,

831
00:51:01.150 --> 00:51:03.080
what about our models of the mind?

832
00:51:03.260 --> 00:51:06.590
Makes perception seems so much more vivid than belief.
It makes it vivid.

833
00:51:06.950 --> 00:51:09.890
Beliefs seem kind of structural and empty,

834
00:51:09.950 --> 00:51:12.830
whereas perception is so full of light.
But no,

835
00:51:12.831 --> 00:51:16.040
I don't know of work on that from the,
uh,
the metal problem perspective.

836
00:51:16.041 --> 00:51:20.150
Like I said,
there's not that much work on these introspective models directly.

837
00:51:20.151 --> 00:51:23.720
There is work on theory of mind about beliefs tends to be about models of other

838
00:51:23.721 --> 00:51:24.554
people.

839
00:51:26.060 --> 00:51:28.960
It may be that something I could dig through my literature on belief that that

840
00:51:28.990 --> 00:51:31.150
says something about that.
It's a good place to push.
Thanks.

841
00:51:31.730 --> 00:51:33.720
<v 5>I wanted to bring up Kurt girdle.
Uh,</v>

842
00:51:33.770 --> 00:51:37.460
you mentioned your advisor wrote Godel Escher,
Bach.
Uh,

843
00:51:37.461 --> 00:51:42.050
there's something that seems very like girdle or deleon or whatever about this

844
00:51:42.051 --> 00:51:47.051
whole discussion and that so girdle showed that a given like a set of axioms and

845
00:51:48.471 --> 00:51:52.910
mathematics,
it would either be consistent or complete,

846
00:51:52.911 --> 00:51:54.870
but not both.
Um,

847
00:51:54.950 --> 00:51:59.060
and it seems like when Daniel Dennett,

848
00:51:59.800 --> 00:52:04.580
uh,
Daniel Dennett seems to have like a set of axioms where he cannot construct

849
00:52:04.850 --> 00:52:06.500
consciousness from them.

850
00:52:06.501 --> 00:52:09.230
He seems to be very much in this sort of consistent camp.
Like he,

851
00:52:09.560 --> 00:52:12.320
he wants to have a consistent framework,
uh,

852
00:52:12.380 --> 00:52:15.590
but is okay with the incompleteness.
Uh,

853
00:52:15.610 --> 00:52:20.540
and I wonder if a similar approach could be taken with consciousness where we

854
00:52:20.541 --> 00:52:25.541
could in fact prove that consciousness is independent of Daniel dentists set of

855
00:52:26.031 --> 00:52:28.880
axioms the same way they proved after girdle.

856
00:52:28.881 --> 00:52:33.620
They prove like the continuum hypothesis was independent of Zf set theory and

857
00:52:33.621 --> 00:52:37.790
then they added the axiom of choice,
made it to the AFC set theory.

858
00:52:38.330 --> 00:52:42.830
So I wonder if we could show that like in Daniel Dennett swirled,

859
00:52:42.860 --> 00:52:47.000
we are essentially zombies or we are kind of either zombies or not.

860
00:52:47.001 --> 00:52:47.900
It doesn't matter.

861
00:52:48.140 --> 00:52:53.090
Either statement could be true and then find what is like the mini minimum axiom

862
00:52:53.091 --> 00:52:57.920
that has to be added to Dennis axioms in order to make con consciousness true.

863
00:52:58.190 --> 00:52:59.370
Hmm.
Interesting.
I thought thought

864
00:52:59.370 --> 00:53:01.980
<v 1>for a moment this was going to go in a different direction and you're gonna say</v>

865
00:53:01.981 --> 00:53:06.000
Dennett is,
uh,
is consistent but incomplete.

866
00:53:06.450 --> 00:53:09.180
He doesn't have consciousness in this picture.
I am complete.

867
00:53:09.270 --> 00:53:11.330
I've got consciousness.
Yes,
but inconsistent.

868
00:53:11.390 --> 00:53:12.710
That's why I say all these crazy things

869
00:53:14.490 --> 00:53:16.470
you're faced with a choice of not having,

870
00:53:16.710 --> 00:53:19.530
of not having consciousness and being incomplete or having consciousness and

871
00:53:19.531 --> 00:53:23.340
somehow getting this hard problem and being forced into at least puzzles and

872
00:53:23.341 --> 00:53:26.900
paradoxes.
But now the way you put was friendlier to me.
Yeah.
Um,

873
00:53:28.440 --> 00:53:32.700
um,
yeah,
I mean certainly,
um,

874
00:53:32.780 --> 00:53:36.260
ducoff tedder himself has written a lot on analogies between the good Elian

875
00:53:36.270 --> 00:53:40.380
paradoxes and the mind body problem.
Anything is always our models.

876
00:53:40.381 --> 00:53:44.580
Our self models are always doomed to be incomplete in the galleon way.

877
00:53:44.581 --> 00:53:47.460
And he thinks that that might be somehow part of the explanation of our

878
00:53:47.461 --> 00:53:49.860
puzzlement at least about consciousness.

879
00:53:49.980 --> 00:53:52.670
Someone like Roger Penrose of course takes this much more seriously and

880
00:53:52.680 --> 00:53:56.890
literally he thinks that he thinks that,
uh,
you know,
that uh,

881
00:53:56.920 --> 00:54:01.050
the computational aspects of computational systems are always going to be

882
00:54:01.051 --> 00:54:05.970
limited in the girdle way.
He thinks human beings are not so limited.

883
00:54:05.971 --> 00:54:10.200
He thinks we've got mathematical capacities to prove theorems are to know that,

884
00:54:10.320 --> 00:54:14.850
to see the truth of certain mathematical claims that no formal system could ever

885
00:54:14.851 --> 00:54:19.640
have.
So he thinks that we somehow go beyond that,
the incomplete good dealing.

886
00:54:19.641 --> 00:54:21.180
And I don't know if he actually thinks we're complete,

887
00:54:21.181 --> 00:54:25.410
but at least we're not incomplete in the way that find out computational systems

888
00:54:25.530 --> 00:54:26.760
are incomplete.
And furthermore,

889
00:54:26.761 --> 00:54:30.900
he thinks that that extra thing that humans have is tied to consciousness.

890
00:54:31.200 --> 00:54:34.470
I mean,
I never quite saw how that last step code,
even if we go,

891
00:54:34.480 --> 00:54:37.560
it was even if we did have these special non algorithmic capacities to see the

892
00:54:37.561 --> 00:54:41.910
truth of mathematical theorems,
how would that be tied to consciousness?
But,
um,

893
00:54:42.690 --> 00:54:44.480
but at the very least,
they're there at least an hour.

894
00:54:44.520 --> 00:54:48.120
There were structural analogies to be drawn between those two cases about

895
00:54:48.121 --> 00:54:51.470
incompleteness of certain theories.
How literally we should take the analogies.

896
00:54:51.480 --> 00:54:52.780
I'd have to think about.
Okay.

897
00:54:54.170 --> 00:54:58.320
<v 4>Has there been some consideration that the problem of understanding</v>

898
00:54:58.321 --> 00:55:02.160
consciousness sort of inherently must be difficult because we address the

899
00:55:02.161 --> 00:55:04.910
problem using consciousness?
Uh,
I'm,

900
00:55:04.911 --> 00:55:09.180
I'm reminded of the whole thing problem in computer science where we say that in

901
00:55:09.181 --> 00:55:09.990
the general case,

902
00:55:09.990 --> 00:55:13.560
a program cannot be written to tell whether a program will halt.

903
00:55:13.770 --> 00:55:15.240
Because what if you ran it on itself,

904
00:55:15.450 --> 00:55:19.600
it can't sort of be broad enough to include its own,
uh,
execution.

905
00:55:19.601 --> 00:55:23.640
So I wonder if there's a similar corollary in consciousness where we use

906
00:55:23.641 --> 00:55:26.940
consciousness to think about consciousness.
And so therefore,
you know,

907
00:55:26.941 --> 00:55:31.650
we may not have enough,
uh,
um,
sort of equipment there to be able to unpack it.

908
00:55:32.700 --> 00:55:33.930
<v 1>Yeah,
I mean it's tricky.</v>

909
00:55:33.931 --> 00:55:37.920
It's like get six people say it's like a use a ruler to measure or a ruler and

910
00:55:37.921 --> 00:55:39.780
all.
I can do this ruler to measure many other things,

911
00:55:39.781 --> 00:55:42.440
but it can't measure itself.
It's not a,

912
00:55:42.770 --> 00:55:46.860
well on the other hand you can measure one rule or using another ruler.
Um,

913
00:55:46.890 --> 00:55:49.430
maybe you could measure one consciousness using another,
the brain,

914
00:55:49.580 --> 00:55:51.000
what the brain kind of study of the brain.

915
00:55:51.001 --> 00:55:55.230
But the brain actually has a pretty good job of,
uh,
of studying the brain.

916
00:55:55.231 --> 00:55:59.340
So there were some self referential,
uh,
paradoxes there.
And I think that again,

917
00:55:59.341 --> 00:56:03.330
is at the heart of,
of Hofstadter's approach.
I think we'd have to look for very,

918
00:56:03.331 --> 00:56:06.990
very specific conditions under which systems can't study themselves.

919
00:56:06.991 --> 00:56:11.550
I didn't always like the idea that the mind was simple enough that we could

920
00:56:11.551 --> 00:56:15.690
understand it.
We would be too simple to understand the mind.

921
00:56:16.920 --> 00:56:19.650
So maybe something like that could be true of consciousness.
On the other hand,

922
00:56:19.651 --> 00:56:22.800
I actually think that if you start thinking of that consciousness can go along

923
00:56:22.801 --> 00:56:23.950
with simple systems,

924
00:56:24.790 --> 00:56:27.520
I think at the very least we ought to be able to study consciousness in other

925
00:56:27.580 --> 00:56:31.260
systems simpler than ourselves.
And boy,
if I could solve the hard problem,

926
00:56:31.270 --> 00:56:33.850
so even in dogs I'd be,
I'd be satisfied.

927
00:56:34.590 --> 00:56:35.530
<v 6>Hey.
Um,</v>

928
00:56:35.640 --> 00:56:40.640
so I have a question about how the Neta problem research program might proceed

929
00:56:41.161 --> 00:56:42.660
sort of related to the last question.

930
00:56:43.230 --> 00:56:48.090
So I'm certainly things we believe about our own consciousness.

931
00:56:48.360 --> 00:56:50.880
Even if we all say them,
probably some of them are false.

932
00:56:51.390 --> 00:56:55.850
Our brain has a tendency to hide what reality is like.
Um,

933
00:56:55.890 --> 00:56:57.540
if you look at like visual perception,
you know,

934
00:56:57.541 --> 00:57:01.770
there's what's called lightness constancy in our brains have tracks out the

935
00:57:01.771 --> 00:57:02.820
lighting and the environment.

936
00:57:02.821 --> 00:57:06.570
So we actually see more reliably what the colors of objects are.

937
00:57:06.990 --> 00:57:10.950
Like these viral examples of like the black and gold dress is an example of
this.

938
00:57:10.951 --> 00:57:14.040
And when you're kind of presented with an explanation every,
it's like,
Huh,

939
00:57:14.490 --> 00:57:17.590
my brain does that.
It's not something we have access to.
Yeah.

940
00:57:17.970 --> 00:57:19.800
Relate the Jani Laurel,

941
00:57:19.830 --> 00:57:23.490
Laurel illusion is like another one where like when you hear the explanation,

942
00:57:23.491 --> 00:57:25.110
you know,
the scientists that understand it,

943
00:57:25.560 --> 00:57:30.180
our own introspection doesn't include that.
So how do you kind of proceed with,

944
00:57:30.720 --> 00:57:35.490
um,
trying to get at what consciousness really is versus what our sort of,

945
00:57:35.750 --> 00:57:38.850
whatever is simplified or distorted view might be?
Okay.

946
00:57:39.240 --> 00:57:41.310
<v 1>Yeah,
I think,
well one view here would be is that</v>

947
00:57:43.020 --> 00:57:47.370
we never have access to the mechanisms that generate consciousness,

948
00:57:47.520 --> 00:57:50.340
but we still have access to the conscious states themselves.
Actually,

949
00:57:50.341 --> 00:57:52.560
the coal Ashley said this decades,
he said,

950
00:57:52.561 --> 00:57:55.050
no process of the brain is ever conscious.

951
00:57:55.350 --> 00:57:59.250
The processes that get you to the states or never conscious the states,

952
00:57:59.251 --> 00:58:02.280
they get you to our conscious to take your experience of the dress.

953
00:58:02.940 --> 00:58:07.350
For me it was,
uh,
it was about,
um,
white and gold.
Um,
so you know,

954
00:58:07.351 --> 00:58:11.820
and I knew that,
you know,
each of us,
we're certain that I am,
I was experiencing,

955
00:58:11.821 --> 00:58:13.800
I was certain that I was experiencing white and gold.

956
00:58:13.801 --> 00:58:17.600
Maybe you were suddenly you're experiencing blue and black a in Brazil.

957
00:58:17.610 --> 00:58:21.450
It was right.
You were sure that,
yeah,

958
00:58:22.530 --> 00:58:27.210
those idiots can't be,
can't be looking at this.
Right.
Um,
but each of us,

959
00:58:27.480 --> 00:58:29.780
I think the natural way to describe this,
at least it was a,

960
00:58:30.060 --> 00:58:33.240
each of us was certain what kind of conscious experience we were having.

961
00:58:33.660 --> 00:58:36.960
But what we had no idea about was the mechanisms by which we got there.

962
00:58:36.961 --> 00:58:38.820
So the mechanisms are completely opaque,

963
00:58:39.240 --> 00:58:42.980
but the states themselves where at least primary facie transparency,

964
00:58:43.000 --> 00:58:45.030
I think that would be the standard if you would even a realist about

965
00:58:45.031 --> 00:58:47.250
consciousness could go with that.
They said,
well,

966
00:58:47.251 --> 00:58:50.670
we know what conscious states where we know what those conscious states are.

967
00:58:50.671 --> 00:58:53.360
We don't know the processes by which they're generated.

968
00:58:53.361 --> 00:58:55.980
The allusionist I think wants to go much further and say,
well,

969
00:58:55.981 --> 00:58:59.820
it seems to you that you know what conscious state you're having,

970
00:58:59.821 --> 00:59:04.200
it seem to you that you're experiencing yellow and gold.
Ah,
sorry,

971
00:59:04.201 --> 00:59:07.980
yellow and white,
whatever it was,
golden golden words,
whatever.
Platinum,

972
00:59:08.370 --> 00:59:12.940
black and blue,
I think,
Ooh,
gold and white.
Um,

973
00:59:13.110 --> 00:59:15.100
it seems to you that your experiencing golden light,

974
00:59:15.101 --> 00:59:18.970
but in fact that too is just something thrown up by another model.
The,

975
00:59:19.350 --> 00:59:21.090
the yellow gold was a perceptual model.

976
00:59:21.170 --> 00:59:24.950
Then there was an introspective model that said you're experiencing gold and why

977
00:59:24.960 --> 00:59:28.280
when maybe in fact you're just a Zombie or who knows what's actually going on in

978
00:59:28.281 --> 00:59:29.061
your conscious state.

979
00:59:29.061 --> 00:59:32.180
So the illusion of the few I think has to somehow take this further and say not

980
00:59:32.181 --> 00:59:34.730
just the processes that generate the conscious states,

981
00:59:34.731 --> 00:59:38.180
but maybe the conscious states themselves are somehow opaque to us.

982
00:59:39.580 --> 00:59:40.450
<v 2>Great.
Thanks.</v>

983
00:59:42.050 --> 00:59:44.160
<v 1>It feels like,
uh,</v>

984
00:59:44.240 --> 00:59:49.020
some discussion of generality of a problem is missing from this discussion.
Yeah.

985
00:59:49.040 --> 00:59:53.000
The Matrix multiplier example of having high fi is still,

986
00:59:53.030 --> 00:59:57.140
it's not a general thing.
Is there some someone exploring space,

987
00:59:57.170 --> 01:00:00.650
the sort of intersection of generality and complexity that leads to

988
01:00:00.651 --> 01:00:04.280
consciousness as an emergent behavior?
We can just say generality.

989
01:00:04.281 --> 01:00:08.000
I mean the idea that a theory should be general that I should apply to every

990
01:00:08.001 --> 01:00:11.270
system.
You mean mechanisms of generality of the agent,
right.

991
01:00:11.271 --> 01:00:15.320
If I can write an arbitrarily complex program to play tic TAC toe and all it

992
01:00:15.321 --> 01:00:17.210
will ever be able to do is play tic TAC toe.

993
01:00:17.211 --> 01:00:20.890
It has no outputs to express anything else.
Yeah,

994
01:00:21.490 --> 01:00:26.210
that's just a general in the sense of Agi,
artificial general intelligence.

995
01:00:26.420 --> 01:00:31.040
I mean some aspects of consciousness seem to be domain general like for example

996
01:00:31.041 --> 01:00:33.770
maybe insofar as belief and reasoning as conscious.

997
01:00:33.770 --> 01:00:36.500
Those were domain general but much of perception it doesn't seem,

998
01:00:36.501 --> 01:00:39.740
especially demand Gen,
right?
Collar is very domains.

999
01:00:39.830 --> 01:00:42.830
Taste is very domain specific so it's still conscious.

1000
01:00:42.890 --> 01:00:47.890
If my agent can't express problem statements like if I don't give it an output

1001
01:00:47.930 --> 01:00:49.730
by which it can express problem statements,

1002
01:00:49.731 --> 01:00:52.370
you can never come to a conclusion about its consciousness.

1003
01:00:53.390 --> 01:00:56.720
I like to distinguish intelligence and consciousness and even be able to even

1004
01:00:56.721 --> 01:00:57.850
natural language.
And,
you know,

1005
01:00:57.920 --> 01:01:02.480
be able to address a problem statement and analyze a problem that's already a

1006
01:01:02.481 --> 01:01:06.740
very had pretty advanced form of intelligence.
Um,

1007
01:01:07.280 --> 01:01:11.210
I think it's very plausible that say a mouth has got some kind of consciousness,

1008
01:01:11.211 --> 01:01:15.590
even if it's got no ability to address problem statements and many of its

1009
01:01:15.591 --> 01:01:17.300
capacities maybe very specialized.

1010
01:01:17.630 --> 01:01:20.650
I mean it's still a much more general than say a simple neural network that it

1011
01:01:20.660 --> 01:01:24.160
can only do one thing.
I can do a mouth can do many things,
but I'm not,

1012
01:01:24.410 --> 01:01:26.190
I'm not sure that I see in a central,

1013
01:01:26.750 --> 01:01:30.280
I suddenly see a connection between intelligence in generality.
We want to say,

1014
01:01:30.290 --> 01:01:34.610
you know,
somehow a high degree of generality is required for high intelligence.

1015
01:01:34.611 --> 01:01:37.600
I'm not sure there's the same connection for consciousness.

1016
01:01:38.210 --> 01:01:43.190
Consciousness can be extremely domain specific has a taste and maybe maybe

1017
01:01:43.191 --> 01:01:45.530
vision or it can be domain general.

1018
01:01:45.560 --> 01:01:47.690
So maybe those two cross cut each other a bit.

1019
01:01:48.190 --> 01:01:49.023
<v 2>Yeah.</v>

1020
01:01:51.320 --> 01:01:55.910
<v 6>So,
um,
it seems to me like the,
the metal problem as it's formulated,</v>

1021
01:01:56.470 --> 01:02:00.840
um,
implies some amount of like separation or epiphanies nominalism tween like

1022
01:02:00.890 --> 01:02:04.370
consciousness and brain states.
And,
um,

1023
01:02:04.700 --> 01:02:09.700
one thing that I think underlies a lot of people's motivation to do say science

1024
01:02:09.741 --> 01:02:13.310
is that it has,
um,
causal import.

1025
01:02:13.340 --> 01:02:17.750
Like predicting behaviors is clearly a functionally useful thing to do.

1026
01:02:18.170 --> 01:02:22.680
And if you can predict all of behavior without having to explain consciousness,

1027
01:02:22.950 --> 01:02:26.460
their motivation for explaining consciousness sort of evaporates.

1028
01:02:26.461 --> 01:02:28.680
And it sort of feels like,
yeah,
yeah.
Well,

1029
01:02:28.890 --> 01:02:32.640
what's the point of even in thinking about that because it's just not going to

1030
01:02:32.641 --> 01:02:37.170
do anything for me.
Um,
what do you say to someone when they say that to you?

1031
01:02:37.900 --> 01:02:40.830
What is the thing that they said to me again?
That there's no,
there's,

1032
01:02:41.160 --> 01:02:43.320
maybe consciousness exists,
maybe it doesn't,

1033
01:02:43.490 --> 01:02:47.090
but if I can explain all of human behavior and all of the behavior of the,

1034
01:02:47.180 --> 01:02:50.340
the world in general without recourse to such concepts,

1035
01:02:50.760 --> 01:02:53.910
then I've done everything that there is that's useful.

1036
01:02:54.180 --> 01:02:57.990
Like explaining consciousness isn't a useful thing to do.
Um,
and,

1037
01:02:58.020 --> 01:03:01.290
and thus I'm not interested in this and it makes it not be real.

1038
01:03:01.620 --> 01:03:05.370
<v 1>I mean,
I'm certainly,
I'm not,
I mean,
I think epi phenomenon isn't,</v>

1039
01:03:05.371 --> 01:03:07.910
it could be true.
I certainly don't have any commitment to it though.

1040
01:03:07.911 --> 01:03:11.960
It's quite possible that consciousness has a role to play in generating behavior

1041
01:03:12.170 --> 01:03:13.400
that we don't yet understand.

1042
01:03:13.401 --> 01:03:18.401
And maybe thinking hard about the metal problem can help us get clearer on those

1043
01:03:18.471 --> 01:03:21.830
roles.
I think if you're got any sympathy to panpsychism maybe consciousness is

1044
01:03:21.831 --> 01:03:25.300
intimately involved with how physical processes get going and the uh,

1045
01:03:25.580 --> 01:03:28.850
in the first place.
And there are people who want to pursue interaction.

1046
01:03:28.851 --> 01:03:31.820
This ideas where consciousness interacts with the brain or if you're a

1047
01:03:31.821 --> 01:03:33.500
reductionist consciousness,

1048
01:03:33.501 --> 01:03:36.410
maybe just a matter of the right algorithm on all of those views.

1049
01:03:37.250 --> 01:03:39.710
Consciousness may have some role to play,
but just say,

1050
01:03:40.100 --> 01:03:43.580
it turns out that you can explain all of behavior including these problems

1051
01:03:43.880 --> 01:03:47.180
without,
um,
without bringing in consciousness.

1052
01:03:47.180 --> 01:03:50.390
Then does that mean that consciousness is not something we should care about and

1053
01:03:50.391 --> 01:03:52.640
not something that matters?
I don't think that would follow.

1054
01:03:52.670 --> 01:03:54.950
I mean maybe it wouldn't matter for certain engineering purposes.

1055
01:03:54.951 --> 01:03:59.870
So you want to build a useful system.
But um,
you know,
at least in my view,

1056
01:04:00.440 --> 01:04:02.600
consciousness is really the only thing that matters.

1057
01:04:02.601 --> 01:04:04.820
It's the thing that makes life worth living.

1058
01:04:05.030 --> 01:04:08.600
It's what gives our lives meaning and value and so on.

1059
01:04:08.601 --> 01:04:10.550
So it might turn out that,
okay,

1060
01:04:10.551 --> 01:04:14.120
the point of consciousness is not that useful for explaining other stuff,

1061
01:04:14.450 --> 01:04:15.181
but it's,
you know,

1062
01:04:15.181 --> 01:04:17.840
but if it's the source of intrinsic difficult significance in the world,

1063
01:04:18.110 --> 01:04:19.370
then understanding consciousness,

1064
01:04:19.400 --> 01:04:23.290
it was still be absolutely essential to understanding ourselves.
Furthermore,

1065
01:04:23.300 --> 01:04:28.300
if it comes to developing other systems like say AI systems or dealing with

1066
01:04:28.491 --> 01:04:31.340
nonhuman animals and so on,
we absolutely want to know.

1067
01:04:31.340 --> 01:04:34.340
We need to know whether they're conscious because you know,

1068
01:04:34.341 --> 01:04:37.790
if they are conscious,
they presumably have moral status.
If they can suffer,

1069
01:04:38.300 --> 01:04:42.650
then it's very bad to mistreat them.
If they're not conscious,
then you might,

1070
01:04:43.030 --> 01:04:44.000
I think it's very plausible.

1071
01:04:44.001 --> 01:04:48.230
Treat nonconscious systems we can treat how we like and it doesn't really matter

1072
01:04:48.590 --> 01:04:52.310
morally.
So the question of,
of whether say an AI system is conscious or not,

1073
01:04:52.311 --> 01:04:56.180
it's gonna be absolutely vital for how we interact with it and how we build our

1074
01:04:56.660 --> 01:04:59.070
society.
That's not a question of engineering usefulness.

1075
01:04:59.071 --> 01:05:01.940
That's a question of connecting with our most fundamental values.

1076
01:05:02.630 --> 01:05:06.780
<v 6>I completely agree.
I just,
I haven't found that formulation to,</v>

1077
01:05:06.830 --> 01:05:10.080
to be very convincing to others necessarily.
Hi.
Uh,

1078
01:05:10.210 --> 01:05:13.870
thank you so much for coming and chatting with us today.
Um,

1079
01:05:14.410 --> 01:05:18.160
I'm really interested in some of your earlier work.
Uh,
the extended

1080
01:05:18.160 --> 01:05:20.810
<v 7>mind just trying to dig a cognition.
Yeah.
And a,</v>

1081
01:05:20.830 --> 01:05:23.830
you're at a company speaking with a bunch of people who do an incredibly

1082
01:05:23.831 --> 01:05:28.300
cognitively demanding task.
Most of literature that I've read on this topic,

1083
01:05:28.630 --> 01:05:32.080
uh,
uses relatively simple examples of tying like it's,

1084
01:05:32.110 --> 01:05:36.830
it's difficult to think,
um,
just inside your head,
uh,

1085
01:05:36.910 --> 01:05:38.260
on these relatively simple things.

1086
01:05:38.290 --> 01:05:41.590
And if you take a look at the programs that we build sort of like on a Monday

1087
01:05:41.590 --> 01:05:42.251
and day to day basis,

1088
01:05:42.251 --> 01:05:46.780
there are millions of lines long I've read people in the past say something like

1089
01:05:46.781 --> 01:05:50.710
the Boeing triple seven was the most complicated thing that human beings have

1090
01:05:50.711 --> 01:05:54.910
ever made.
And I think most of us would look at that and say,
we got that beat.

1091
01:05:54.940 --> 01:05:57.670
You know,
like the,
the,
the things that large internet companies do,

1092
01:05:57.940 --> 01:06:01.600
the size of the complexity of that is staggering.
And yet if we close our eyes,

1093
01:06:01.601 --> 01:06:02.830
everyone in here is going to say,

1094
01:06:02.890 --> 01:06:06.760
I'm going to have difficulty writing a 10 line program in my head.
Okay.

1095
01:06:07.000 --> 01:06:09.010
So I've just sort of as,
as an open,

1096
01:06:09.011 --> 01:06:12.250
like I'd be very interested in hearing your thoughts,
uh,
about,
uh,

1097
01:06:12.280 --> 01:06:16.900
how the activity of programming,
uh,
connects to the extended mind ideas.

1098
01:06:17.580 --> 01:06:19.810
<v 1>Yeah.
So this is like,
this is a reference to,
um,</v>

1099
01:06:20.730 --> 01:06:25.050
something that I got to talk to them about 20 years ago with my colleague Andy

1100
01:06:25.050 --> 01:06:25.651
Clock.
We wrote an article,

1101
01:06:25.651 --> 01:06:30.180
a book called the extended mind about how processes in the mind can extend

1102
01:06:30.210 --> 01:06:34.440
outside the brain when we become coupled to our tools.
And actually I'll,

1103
01:06:34.620 --> 01:06:38.760
I'll central example back then in the mid nineties was a,
it was a notebook,

1104
01:06:38.940 --> 01:06:41.650
someone writing stuff in a notebook.
I mean,
even then we knew about the,
uh,

1105
01:06:41.970 --> 01:06:44.910
we knew about the internet and we had some,
uh,
intent examples,

1106
01:06:44.911 --> 01:06:49.080
I guess this company didn't exist yet and 95.
Um,
but,
um,

1107
01:06:49.860 --> 01:06:52.980
but now of course our minds are just become more and more extended and,
um,

1108
01:06:52.981 --> 01:06:54.720
you know,
smart phones came up,

1109
01:06:54.780 --> 01:06:58.980
came along a few years later and everyone has coupled very,

1110
01:06:58.981 --> 01:07:02.550
very closely to their phones and their other devices,
the couple of them very,

1111
01:07:02.551 --> 01:07:05.740
very closely to the Internet.

1112
01:07:05.740 --> 01:07:10.470
And now it's certainly the case that a whole lot of my memory is now offloaded

1113
01:07:10.471 --> 01:07:14.640
onto the,
uh,
the servers of your company somewhere,
uh,
somewhere or other,

1114
01:07:14.641 --> 01:07:19.070
whether it's in the,
uh,
you know,
um,
a mail systems or not,

1115
01:07:19.110 --> 01:07:23.350
or navigation mapping systems or,
or,
uh,
or other systems.
So,
yeah,

1116
01:07:23.351 --> 01:07:25.170
most of my navigation has been offloading,

1117
01:07:25.490 --> 01:07:29.260
been offloaded to maps and much of my memory for you know,
has been offloaded,

1118
01:07:29.280 --> 01:07:31.740
well maybe that's in my phone,
but,
um,

1119
01:07:32.580 --> 01:07:36.510
other bits of my memory or are offloaded into my file system on,

1120
01:07:37.350 --> 01:07:42.120
on,
um,
you know,
some cloud service.
So certainly,
um,

1121
01:07:42.900 --> 01:07:43.733
yeah,

1122
01:07:43.790 --> 01:07:48.450
a vast amounts of my mind are now existing in the,
uh,

1123
01:07:48.451 --> 01:07:51.060
in the cloud.
And if I was talking how to lose access to those completely,

1124
01:07:51.061 --> 01:07:53.760
then I'd lose an awful lot of my,
uh,

1125
01:07:54.300 --> 01:07:59.250
of my capacities.
So I think we have now,
we are now sort of extending into,

1126
01:07:59.251 --> 01:08:02.520
uh,
into the cloud,
thanks to that,
to you guys and others.

1127
01:08:02.580 --> 01:08:04.510
The questions specifically though about programming,

1128
01:08:06.930 --> 01:08:10.830
programming is a kind of active interaction with our,
our devices.
I mean,

1129
01:08:10.831 --> 01:08:12.600
I think of programming or something,
it takes a little bit longer.

1130
01:08:13.320 --> 01:08:14.370
It's a longer timescale.

1131
01:08:14.400 --> 01:08:19.400
So the core cases of the extended mind involved sort of automatic use of our

1132
01:08:19.731 --> 01:08:21.800
devices,
which are always ready to hand.

1133
01:08:22.040 --> 01:08:26.090
We can use them to get information to act in the moment,

1134
01:08:27.060 --> 01:08:29.810
which is the kind of thing that,
that the,
uh,
that the brain does.

1135
01:08:30.230 --> 01:08:32.900
So we went so far as programming is a slower process,
you know,

1136
01:08:32.901 --> 01:08:36.290
and I remember from my,
uh,
programming days,
all the,
uh,

1137
01:08:37.070 --> 01:08:41.390
the endless hours of debugging and uh,
and uh,
and so on.

1138
01:08:42.290 --> 01:08:45.920
And then as at least going to be a slower time scale for the extended mind.

1139
01:08:45.921 --> 01:08:49.350
But still,
I mean,
fine men talked about writing this way.

1140
01:08:49.700 --> 01:08:53.120
Someone looked at fine men's work and um,

1141
01:08:54.560 --> 01:08:57.650
bunch of notes he had about a physics problem he was thinking about.

1142
01:08:57.650 --> 01:08:59.000
And someone said to him,
Oh,

1143
01:08:59.001 --> 01:09:02.790
it's nice you have this record of your work and five minutes,

1144
01:09:03.260 --> 01:09:06.410
that's not a record of my work.
That's the work.

1145
01:09:06.950 --> 01:09:10.130
That is the thinking as I was writing it down and so on.
I think,
you know,

1146
01:09:10.760 --> 01:09:13.880
at least my recollection from my programming days was it is that,
you know,

1147
01:09:14.120 --> 01:09:15.720
when you're actually running a program that's not,

1148
01:09:15.870 --> 01:09:18.500
it's not like he's just do a bunch of thinking and then,

1149
01:09:19.040 --> 01:09:21.380
and then code your code,
your thoughts.

1150
01:09:21.381 --> 01:09:25.280
The programming is to have some very considerable extent your,
uh,
your thinking.

1151
01:09:25.281 --> 01:09:26.750
So is that,
is that the sort of thing here?

1152
01:09:27.680 --> 01:09:32.120
<v 7>Yes.
And uh,
the,
if we,</v>

1153
01:09:32.180 --> 01:09:35.720
I think as,
as people that program start to reflect on what we do.

1154
01:09:35.930 --> 01:09:40.820
And very few of us actually,
uh,
like if you're the tech lead of a system,

1155
01:09:40.910 --> 01:09:43.070
maybe you've got it in your head.
Okay.

1156
01:09:43.071 --> 01:09:46.130
But you would agree that most of the people on the team who've come more

1157
01:09:46.131 --> 01:09:48.020
recently only have a chunk of it in their head.

1158
01:09:48.320 --> 01:09:50.390
And yet there's some house to label to contribute.

1159
01:09:50.580 --> 01:09:53.060
<v 1>Oh yeah,
this is,
this is,
and this is now distributed cognition of,</v>

1160
01:09:53.061 --> 01:09:57.030
I mean we talk the extended mind that extended cognition like starts with an

1161
01:09:57.031 --> 01:10:02.031
individual and then extends out into extends the capacities out using their

1162
01:10:02.101 --> 01:10:04.890
tools or their devices or even other people.

1163
01:10:04.891 --> 01:10:07.020
So maybe my partner serves as my memory,

1164
01:10:07.021 --> 01:10:09.180
but it's still centered on an individual.

1165
01:10:09.181 --> 01:10:12.390
But then there's the closely related case of distributed cognition.

1166
01:10:12.391 --> 01:10:14.640
We have a team of people who are,
uh,

1167
01:10:15.060 --> 01:10:18.450
who are doing something and making joint decisions and carrying out joint

1168
01:10:18.451 --> 01:10:20.010
actions and absolutely seamless way.

1169
01:10:20.011 --> 01:10:22.740
And I take it that a company like this that are going to be any number of

1170
01:10:22.741 --> 01:10:24.840
instances of distributed cognition.

1171
01:10:24.841 --> 01:10:29.040
I don't know whether the company has as a whole as a whole has one giant Google

1172
01:10:29.041 --> 01:10:30.600
mind or maybe there's just like,

1173
01:10:31.000 --> 01:10:35.250
and a near infinite number of separate Google minds for all the individual teams

1174
01:10:35.251 --> 01:10:39.000
and divisions.
Um,
and so on.
But I think,
yeah,

1175
01:10:39.180 --> 01:10:40.900
probably some anthropologist has already done it,

1176
01:10:40.901 --> 01:10:44.580
a definitive analysis of distributed cognition in this,
in this company.

1177
01:10:44.581 --> 01:10:47.070
But if they haven't,
they certainly need to.
Thank you.

1178
01:10:48.940 --> 01:10:53.940
<v 2>[inaudible].</v>

