Speaker 1:          00:06          Please join me and warmly welcoming to Google Brendan Nyhan and Dj flame.

Speaker 1:          00:17          Well, thank you Laura for organizing this and thanks to all of you for being here. It's super exciting to be here and to talk, um, talk with you all about misinformation today. Um, so our plan is, I'm going to talk, uh, first, uh, that's the top half of the slide here about the political system today and why, um, different aspects of American politics today are conducive to creating misperceptions that influence people's attitudes and behaviors and often persist for a long period despite the provision of accurate information. So I'm going to talk about that first. Um, and then I'm going to turn it over to Brendan who's going to talk about it a little bit more specifically about the role of fake news and fake news in 2016 in particular, does a roadmap of, of my part of the talk. Today I'm going to begin by talking about some contextual elements in American politics that are conducive to misinformation as I mentioned.

Speaker 1:          01:07          Um, I'll then give some examples to give you a sense of the extent of partisan differences in factual beliefs about politics. Um, I'll talk about some institutional responses that we've seen, uh, to misinformation mostly in the United States. Um, and then I'll outline some challenges and opportunities moving forward. Um, so to begin with the contextual discussion, um, I think any discussion of American politics today has to start by acknowledging that the huge and really historic levels of partisan polarization that we see at the elite level in the United States. Um, so this is a plot showing a roll call ideology spores in Congress for members of the Democratic Party, uh, in the Republican Party over time. Um, so higher scores here are more liberal voting records in Congress and lower scores on the y axis are more conservative records. Um, and as you can see by this increasing divergence over time, we have a dramatic polarization in ideology among political elites.

Speaker 1:          02:05          That is to say Democrats are becoming more and more liberal in their roll call. Voting, Republicans becoming more and more conservative, and there's just less area of ideological agreement at the elite level. Um, which as we'll see, has important implications for how partisans in the mass public, how ordinary Democrats and Republicans a form opinions and factual beliefs about politics. Um, another, uh, really important institutional change that we've seen in recent in recent decades is the resurgence of partisan media. Um, so we now see explicitly ideological and sometimes partisan outlets providing information. Um, this is important for a huge number of reasons, but I'll focus just on one, it's relevant for the discussion today. Um, and that is that when you have a highly partisan, highly fragmented media system, um, what you have is you have people watching certain channels and coming away watching different of channels and coming away with fundamentally different understandings of the same issue or event.

Speaker 1:          03:04          Okay. So if we think about events that are in the news today and how the same event is covered by Sean Hannity on Fox, for example, in Rachael Maddow on MSNBC, um, they might be covering the same sort of larger story, like the potential link between the Trump campaign and Russia, but they cover it from very, very different angles. And so partisan viewers of each network come away with very different factual understandings of the same issue. Um, this is, uh, this is a relatively new, um, aspect of, of the media system, right? So, um, up until recent decades, we had a relatively homogeneous media system with a small number of channels, right? Not as much partisan choice. And that's important because, uh, it led to the opposite of what we have today, right? People had a smaller selection of, uh, news channels to watch and they came away with the same basic set of facts, which we increasingly no longer no longer half.

Speaker 1:          04:00          Now, one important result of this resurgence in partisan media and increase in partisanship and the mass public is a large increase in what we political scientists call an affective polarization. Um, so AFX rates just simply how you feel about a certain group, usually an outgroup. Um, so there are lots of different ways of measuring an affective polarization in politics. Um, this is one of the more clever ones on the top here. This shows the trend in the percent of people who would be upset if a member of their immediate family married a member of the other political party. Um, there are lots of measures of effect of polarization, but this is one of the more interesting ones I think. Um, and you see the pretty steady linear linear increase over the time series on the x axis and his huge spike around 2008, 2009. Okay. I'm sorry.

Speaker 1:          04:51          Um, the line might be smooth. I'm not, I'm not sure. These are my data. Yeah, I think there's a lowest smoother on the line. Another sort of more straight forward, a more straightforward measure of this, right, is just how do you feel sort of a zero to 100. Do you feel cool toward the opposing party or warm toward the opposing party? And we see pretty steady decreases among, uh, people across the partisan spectrum in terms of how they feel about members of the opposing the opposing party. And that that negative trend is especially dramatic, right? Among strong Democrats and strong Republicans. Um, now that's important, right? Because people who tend to be strongly partisan participate more, they're more likely to vote, they're more likely to contact members of Congress. And so those, um, highly politically active, influential people are more and more as effectively polarized towards members the other party.

Speaker 1:          05:41          Okay. Um, and these are some of the, these are some of the contextual changes in, in the US political system in recent years that have led to really dramatic partisan differences in factual beliefs. Okay. So I, um, I'm showing some examples here that I think many of us will recognize, but I think the data, I'm really help us understand, uh, how much factual polarization we've seen on these issues over time. Um, which is, uh, which is, uh, um, that time trend often gets, often gets lost, right. Um, in, in, in media coverage. Um, and so we see partisan differences in factual beliefs. About major social and economic problems, like, uh, beliefs about the cause of global warming. Um, and, and lots of, lots of other, a really hugely influential policy issues. Um, so this is just showing, right? The percent of people who believe that the rise of the Earth's temperature is due mostly to human activity among Democrats, Republicans and independents.

Speaker 1:          06:34          And you see this increasing divergence over time. Okay. Um, we also see these partisan differences in factual beliefs on the content of major legislation, right? Like the affordable care act or tax reform. And it's being debated now, or Aca repeal that's being debated now. Um, so this is a really a really cool a graph from a paper that Brendan Road in 2010 which I often a steal for talks like this. Um, so this shows the percent of people who believe in the left panel, um, that the Clinton healthcare reform proposal in the early 1990s would result in people losing their choice of doctor. Um, and it shows the belly, it shows belief in that, in that claim by different partisan groups, right? Democrats and Blue Republicans and red independence in green. Um, and what's even more interesting here, and maybe a little bit depressing, right? It's, you'll notice there are two, there are two points for each party corresponding, uh, down here on the x axis to people who report that they have, um, uh, two, it's too early or they don't know very much about the plan versus partisans who say they have a really good understanding of the plan.

Speaker 1:          07:36          So these are people who self report that they know a lot about the plan and we see that the more people think they know, the more misinformed they actually are in some cases, right? So we see huge partisan disagreement among partisans who claim to have a really good factual understanding of these issues. Um, and we see a similar pattern, uh, about the death panel claim and the affordable care act in 2009 on the right side. Okay. Um, this is perhaps the most famous example, right, of partisan differences in factual beliefs in recent years. This is the shows, right? Differences in the belief that Barack Obama was not born. It was or was not born in the United States. Uh, not surprisingly, right? Huge, huge differences here. Okay. Um, now, so we have, we have these, uh, this partisan disagreement and on all these different factors that play a large role in policy debates.

Speaker 1:          08:24          Um, and we've seen a lot of institutional responses to this and attempts to correct misperceptions and bring, bring partisans together and sort of their factual understanding of politics. I'm the first one that I think is really important, right, is the rise of political fact checking. Um, so there's this nice new report out by the Duke reporters' lab that shows that tracks the trend and the growth of fact checking or for the past 10 or so years, and we've seen about 150% explosion in fact checkers across, um, across the globe in the last three years in response to this, uh, this upsurge in, in misinformation and democracies across the world. Right? Um, really a related point, right? We've seen an uptick in watchdog journalism. So even as, um, a lot of newspapers, right, face financial burdens and they're shrinking their news teams, we've seen a lot of papers sort of re uh, recalibrate their, their focus and focus a lot more on, um, investigative watchdog style journalism.

Speaker 1:          09:22          Um, so these are some headlines from, from very recent months, right, about fact checking claims made by Hillary Clinton and Donald Trump played a large role, uh, in, in the campaign and still play a large role today. Okay. Um, now of course, there are still a lot of challenges ahead for fact checkers and other people who seek to mitigate misinformation in politics. Um, the first is declining trust in media over time, right? So people, uh, people, uh, self reported trust in media has declined pretty steadily in recent decades. Um, it doesn't help when you have a prominent members of both parties, frankly, who regularly make a arguments in media media, can't be trusted and can't be, can't be trusted to adjudicate these factual disputes that we see. Okay. Um, there's also this, this echo chamber problem which Brendan's going to talk about in a moment. And this is the idea that, um, given that explosion and media choice that I talked about in the beginning, um, people sometimes a expose themselves to information selectively.

Speaker 1:          10:25          That is to say, Democrats for instance, might watch MSNBC or read the Huffington Post. Republicans might watch box or read Breitbart. Um, you know, there's a lot of, uh, new research with really cool data that you're going to hear about in a second, uh, tracking the extent of this and who actually engages in this. Um, but this is, this is a challenge to be sure. Um, another, another sort of disclaimer that I just want to give before I, before I conclude is that a lot of the examples that I've focused on in the talk are highly partisan facts, right? By definition that are at the center of partisan disagreement. And you might say, Oh, well, you know, you're always going to see partisan disagreement on these sorts of issues. Perhaps that's not super troubling. Um, but I want to highlight that we see a lot of misperceptions, factual misperceptions that are widely held by members of both parties.

Speaker 1:          11:16          Okay. It means exist on really important issues like foreign aid. This is one example. Um, uh, people tend to vastly overestimate the size of outgroups like immigrants and minority groups in general. Um, there, there are huge misperceptions about, uh, tax policy, which is being debated right now, right about the percent of the budget that goes to various things like, like foreign aid, uh, defense and that sort of thing. Um, so it's, it's not just that we see, um, partisan disagreement on these highly charged issues, right? We see them broadly across lots of different issues that are coming up. Um, now there are of course opportunities to, to address some of this. Um, so I'll just, I'll just highlight two, uh, in closing here. Um, so the first potentially useful strategy for practitioners, right, who were interested in combating this information made it's to call people out, which is largely what fact checkers do and try to increase the reputational costs of false statements.

Speaker 1:          12:15          Um, so if politicians feel that they have to pay a price when they make an accurate statements, uh, we can try to attack this sort of supply side of misinformation rather than focusing on what happens sort of post, uh, post fall statement and correcting people's misperceptions after they hold them. Um, this is sort of the fact checking model, but I want to emphasize that of course you don't have to be in sort of institutionalized fact checking organization to do this. Um, uh, uh, tools, uh, at places like Google and Facebook and elsewhere. We've made efforts at flagging false claims at the point of, at the point of communication. Try this the same, the same strategy, right? Um, in the second, the second opportunity I want to highlight is there a lot of really highly credible sources, um, that can, uh, combat miss misperceptions even when they're highly polarized along political lines.

Speaker 1:          13:07          Um, one, uh, situation, which misperceptions are often a little bit easier to correct a is when you can get a partisan or ideological actors speaking against his or her own self interest, that's often highly persuasive, right? There are lots of experiments, for instance, that show that if you can get, um, a Republican to combat the plane, that there were death panels in the affordable care act, that that's a much more persuasive Q. Then if you can get somebody who is just totally in support of the affordable care act for instance to do that. And there are lots of other examples. Um, and finally, unexpected sources are often really highly persuasive in correcting this perception. So there's a neat new paper that shows, uh, that when corrected information about the human causes of global warming is provided by military organizations or defense related entities as opposed to scientists. It's just a more surprising source and it sort of disarms people and has, it has a much more powerful impact. Um, so these are just two opportunities that I wanted to flag that have sort of come up in recent research. There are certainly others. Um, uh, but with that I'll, I'll uh, turn it over to Brendan.

Speaker 2:          14:13          All right. So what I want to do now is turn more specifically to the 2016 election that what Djs don't. Hopefully it's given you an overview of why we might be especially concerned about people's vulnerability to miss perceptions in the partisan age that we live in, in this country. Um, so I'm going to talk specifically about the 2016 election focusing on fake news. But you should of course think of that. And I'm going to say what I mean by fake news in a moment, but, but you should think of that as a subset of the larger problem with misinformation. The DJ has been talking about fake news is one particular manifestation of the ways in which people's political commitments can influence what they choose to believe is true in the information they consume. But it's hardly the only one. And in some ways it's important to maybe overstated as I'll talk about the concern that a lot of people have had have expressed since the election is weather.

Speaker 2:          15:01          Uh, people are not just living in an echo chambers of opinion, but echo chambers of fact, right? In other words, it's not just that we tend to interact both online and off with people who share our political commitments, but that we may actually be only hearing from or disproportionately hearing from people who share our same understanding of the world. Right? And that's not just from your social counterparts, but from the information you consume. And that's very worrisome to people, right? Even if we disagree about opinions, uh, about what we should do, uh, you'd like to think that we could have a debate as a democracy based on some shared set of facts. And the fear that's come out of this election of course, is that that's no longer the case. So I don't want to talk about, um, fake news in 2016 election in the context of that question and help you try to get you, give you some intuition on how you might think about that problem.

Speaker 2:          15:54          Okay. So this is my technical analysis of the state of a factual discourses in the 2016 election. Right? If it seemed terrible to you, it was terrible. We studied this full time and, uh, we agree. I mean, there's no systematic way to say how factual a political debate was over time. Historically, there's no agreed upon set of standards. Uh, but I think it's fair to say a qualitative judgment, uh, is that this election was especially poor. Okay. Um, the reason for that starts with the unprecedented level of elite misinformation that came out during this campaign. There's no way around that fact. Okay. And the, you know, both candidates obviously said many things that were false or unsupported. One of them said that said it with historic frequency and was his, it was unprecedented, his unwillingness to retract or correct the record when a misstatement was made.

Speaker 2:          16:42          Okay. We'll set that aside. The question of interest for us today though, you know, in the second part of the talk is what happened with fake news. So here are five of the most widely shared fake news stories of the 2016 campaign according to a sharing data from Facebook compiled by Craig Silverman at buzzfeed. Okay. And you can see that they're often quite outlandish and over the top right. So Pope Francis Endorses Donald Trump. Hillary Clinton is disqualified from office. Hillary sold weapons to isis. Um, and the heel FBI agent involved in the email investigation is dead in a murder suicide. Okay. Um, but there are many, many more cases like this. There's a whole industry of fake news that sprung up during the campaign. Okay. Um, to give you a sense of the magnitude of this, silvermen found that the most shared fake news stories, according to the public Facebook sharing data, of course, the Facebook data science team knows more about this than than I do.

Speaker 2:          17:44          But I can tell you from the public sharing data that he, he found the most shared fake news stories were shared more often than the most shared mainstream news stories in that period before the election. Now, that doesn't mean that the audience were fake news was greater. Okay. Because there were a few viral hits and a lot of duds in the fake news, uh, in the set of fake news articles that were published, right? So it's still the case that the mainstream media was far more, uh, widely shared during that period. But it does suggest how,

Speaker 3:          18:13          uh,

Speaker 2:          18:15          quickly these kinds of stories can reach a very large audience. Right? So if you imagine this many million shares happening on Facebook and how many times people are at least passing by the headline, if not necessarily reading the article, you know, there's, these seem to have been very widespread, right? And many of you probably saw these at some point during the election campaign. Okay, now it's hard to say exactly how many, again, the Facebook data science team knows I don't, but we can try to get answered this question in some different ways. So silvermen and his colleague at buzzfeed went back and asked people, did you remember seeing or hearing about this story in the last few weeks? And they find somewhere between approximately 10 and 20% of Americans said they did. This is a survey fielded very soon after the election. Now the problem with this is you're probably thinking is, of course, it's hard to remember every new story I saw.

Speaker 2:          19:05          And that's true. Okay. So what we'd really like to have is who click through and who read this using behavioral data rather than a self reported recall measure like this, right? Some of these people may be falsely believing they saw a story and they never actually saw it and vice versa. Okay. But it gives you a sense of the approximate magnitude. And what they did find was among those folks who said they had seen or heard about these stories that somewhere around two thirds to for fis, uh, believe that they, these stories were accurate. Okay. So it seems like there was a nontrivial number of Americans who encounter these stories, remembered them and believe them.

Speaker 3:          19:43          Okay.

Speaker 2:          19:46          So similar data here, uh, from two economists, uh, Al Cotton Gins, Carol, it's a little bit small on the slide. The grouping of interests is in the middle portion of the y axis. The false stories where they asked people again, um, do you think this was true? And they showed them a bunch of false headlines as well as some true ones and simple CBO headlines they made up. And what you can see as again around 10 and 20% of Americans for any given fake news headline said they believed it was true. A very large number of those said they didn't know or they weren't sure, right. Often 50% of the public or more, which is troubling if you look at what the content of these sorts of fake news headlines was. For example, the pizzagate conspiracy theory that Hillary Clinton is involved in a pedophilia ring being run out of a pizza parlor in Washington DC, right?

Speaker 2:          20:33          So somewhere around, if you look at the, the line there that, you know, 40 to 50% of Americans are saying either that's true or they're not sure, right? So we'd really like the answer to be no, right. That it's false. Okay. Um, so these things can, again, even for those people who don't believe them, they raise questions and doubts, potentially there may be worrisome, right? Um, people may be vulnerable to, um, at least calling into question things that we wouldn't like to be called into question because they are in fact falls. So why did this happen? Okay. So I want to just identify two factors you might think about and it's obviously relevant to how people interact with Google in its various forms, right? Why were vulnerable to this, right? The first is the choice of the information we consume, which is often called selective exposure.

Speaker 2:          21:20          That in some context, in some circumstances we pick and choose the information we consume according to the extent to which is consistent with our political preferences. Okay. That's going to vary depending on the context you're in and the motivation you have to seek out that sort of information as I'll show you in his Dj suggested. It's not universal, but it's very much a threat, especially in the context, uh, of something like a campaign when people's political, uh, emotions are at a fever pitch, right? That was as, as passionate as po about politics as people get. And that was a time when people might be especially interested in something that seemed to confirm how they felt about a candidate or to disconfirm something they'd like to hear. Just the second problem is what's called directionally motivated reasoning. So all of those factors that are causing people to feel so strongly about politics and become so polarized me that when we encounter that information, our directional preferences about what's true often override our motivation to hold an accurate belief, right?

Speaker 2:          22:18          The side we'd like to be a correct, right? We often conclude they have the stronger argument, they have, the more persuasive claim. Okay. Even when that's not the case. So this raises a real challenge for fact checkers or for information providers of any sort, including, uh, everyone here. Right? So the first question you might think about in terms of fact checking as a potential response to fake news and misinformation more generally is in terms of selective exposure, do people read them? Right? And it's not just a, it's, you know, so the fact checkers will tell you and I, I should say, I know the fact checkers and they're great and they're, they weren't very hard. Okay. And they do have very large audiences now compared to where they were not very long ago. But what you might think about is are the right people reading fact checks and are they reading fact checks of the right claims?

Speaker 2:          23:03          Right? It may be the case that the people reading fact checks are the not necessarily the ones who are holding the given misperception and question, right? And it might even be the case that you read fact checks, but you read the fact check of the claim by the other side that you don't want it to be true, right? So it's not just, it's not good enough to say, well fact checks are out there and some people were reading them. You really want to think about targeting is the person who is mind you think could be changed by the fact check being reached by that fact check. Okay. The problem with fact checking, and I'm sure those of you who've worked with surfacing fact checks in Google have thought about this problem is that everyone thinks everyone else needs them, right? We don't think we need them ourselves.

Speaker 2:          23:41          We think, well, you know, I, I, I'm well informed with those other people. They really should read the fact checks more. Right? And that's been an obstacle to all sorts of technological solutions to this, right? This is something where the demand among the people we like to read the fact checks is an often as strong as we'd like. Okay. And even if they do happen to read the fact check or encounter it, will they find it persuasive? That's the next question. Right? So even if we overcome selective exposure and they, uh, choose to consume that piece of information, is it persuasive to them? Do they evaluate that factcheck and conclude, okay, this, this claim, uh, I thought was true, was actually false. Right? And that's where we were directly motivated reasoning would get in a way, when you think about fake news in 2016 election, though, I want to encourage you to go beyond the psychological factors we've been talking about.

Speaker 2:          24:29          And think about the supply side is Dj alluded to not just the demand side. Okay? Human psychology isn't going to change. All right? Political scientists can tell you polarization is not going away. Okay? So for both of those reasons, I'm trying to change the extent to which people engage in selective exposure. Indirection of motivated reasoning is going to be very difficult. Okay. There may be ways to mitigate it on the margin and Dj gave you some suggestions of how we might do that, but we also have to think about the supply side. Okay. There's a reason that people enter this market, right? There were entrepreneurs who are attracted to this market. You've all read, I assume of the mat about the Macedonian teenagers who across the Ocean said I can buy a new guitar if I write fake news stories for American audiences and sell and sell ads against them.

Speaker 2:          25:11          Right. Um, so the financial incentives played a really big role here. The partisanship that people had made it financially attractive to create content that would attract audiences you could sell ads against. Right? So the ad that works are playing an important role here. Okay. Um, the second factor is really important is, is, is distribution mechanisms. Right? And Facebook seems to have play as, I'll show you some more direct evidence for this a moment, but Facebook in particular seems to have played a key role in distributing fake news. Okay. The reporting we have about the publishers of fake news is that they would go see those articles into pro Trump Facebook groups as a distribution mechanism and, and people in those groups would then push them out. And that was part of how they would get these stories to a wide distribution. Okay. So, uh, those sorts of platforms are, you know, potentially enabling the spread of bad information, not just good.

Speaker 2:          26:06          Okay. Um, and the final factor of course, is that negative partisanship is DJ emphasize to you is so powerful now. It's not just polarization, it's not just partisanship, it's how much people don't like the other side. Right? And that's creating a demand for information about why the other side is bad or the other side is evil. Why the other side? And that's, you should obviously that's terribly destructive to the kinds of compromise and living together that we need for a democracy to work. Okay. So this is a deep and fundamental problem, but, and this is one expression of it that's especially pernicious because now we're not only potentially intensifying that negative partisanship, but we're misleading people about the facts as well. Okay.

Speaker 2:          26:45          But not, you know, I, I suggested you earlier and I want to give you a little bit more of a sense of this, that not everyone is engaging in this all the time, right? You're probably saying, well, I don't go seek out fake news that conforms to my political viewpoints at all times. And that's probably true. Okay. So this is data from my coauthor Andy guests at Nyu. I'm looking at a near representative sample of Americans who've provided an anonymous who provided consent for, uh, sharing their online web traffic data. Okay? And there's two plots here. I'm going to talk you through the differences between them. What he's doing is he's looking at the estimated slant of the media outlets they visit in terms of websites. Okay. And the slant estimate comes from the average ideology of the people who share these sites on Facebook.

Speaker 2:          27:28          Okay? So it's, uh, it's from an article by some Facebook data scientists. So what you can see in the left panel was that the average person's average media outlet is quite centers regardless of party. Okay? So the average person is not seeking out a steady diet of skewed Pars and information. Most people don't care about politics that much, especially outside of a campaign context. This is 2015 data. Okay Boys, you can see in the right panels that the distribution at the audience level in terms of where the overall set of traffic is going by party, it looks very different, right? That's what you're seeing. That big partisan polarization between, uh, the kinds of sites Democrats go to in the left, in blue, in the kind of sites it Republicans go to on the right, and that there's a smaller set of folks on both sides of the aisle who are, who are consuming large amounts of information disproportionately from likeminded media outlets.

Speaker 4:          28:20          Okay.

Speaker 2:          28:24          Uh, oh, I'm sure. Yes. From left to right, daily coast, the Huffington Post and the New York Times, CNN, just to the left of the red spike. Msn is under the middle. There's still a remarkable number of people who go to the, the, the main portals like MSN and Yahoo. And then on the right Fox News and Breitbart.

Speaker 2:          28:43          So, um, I mentioned this to you earlier about the role of Facebook. Here's some partial evidence that's consistent with that. I might or might not have more information about this that I could talk to you in a non record about an a non-recorded format. Um, the, what, uh, these economists Alcott against cofound is that fake news sites were differentially likely to have been reached via social media. Okay. So you can see in the bottom, in the bottom bar here, more than 40% of their visits originated in social media compared to only about 10% for top news sites. Okay. So it seems to have been a really important traffic driver. Um, search a smaller traffic driver relative to a top news, but a nontrivial one, right? About 22% there.

Speaker 2:          29:32          So in terms of fact checking and its role in countering fake news, um, one of the problems was that no one really expected this. And so the fact checkers weren't, uh, on top of it as a, as a target for fact checking, and they typically have focused on elite statements, statements made by politicians, party members, right? The president members of Congress, people like that. And the only exception, you know for the most part was Snopes, which focuses more on rumors and hoaxes, which fake news seem to fall more squarely within. But even still, I would say that, you know, everyone was caught off guard by this. Okay. So now there's going to be more fact checking and fake news. I think it's fair to say, and the question is how effective will it be? And I just want to raise some questions that you should think about as you think about how effective these kinds of approaches might be.

Speaker 2:          30:21          Okay. Um, the first one is, I mentioned you earlier, is that the people who read fake news may or may not actually see a fact check of it, right? It's entirely possible to have a world where those are two disjoint sets, okay. Or ones with very little overlap. Okay. And so we should worry a lot about the extent of which the fact checking of fake news that's being done right now is reaching the people we'd like it to reach. The second point is I would just encourage you to be very specific about what you mean by the effects of fake news. This is something that people talk about very loosely and I think, uh, it's often fake news is being used as it's kind of catch all term for all sorts of misinformation and people are making sweeping claims about its effects, but I don't think are well supported by the facts.

Speaker 2:          31:04          So in the case of fake news, you'll hear people say fake news affected the outcome of the election. I don't think there's any evidence for that in terms of changing who won. Okay. Um, it's, it's, it's very difficult to show that you'd have to make very strong assumptions that Alcott and gins, cow article I mentioned, uh, walks you through the kinds of assumptions you'd have to make to get to an outcome like that. Similarly, fact checking itself may not change that many votes. Right? Even if you've read a fact, I think of your own life. If you read a fact check that change your mind about something, did it change how you were going to vote on which party you preferred? Probably not. Right? So we have to be realistic about what fact checking can and can't accomplish. Right? Um, and then finally I just encourage you to think about misinformation in general and not focus on fake news to the exclusion of this larger problem, which is a much more systematic one.

Speaker 2:          31:51          Then these particular, you know, sites that have popped up that are wholly fake, non journalistic, right? The, the, the Macedonian teenager version of fake news. All right. So I want to conclude with a few, with a brief discussion to get us moving towards the Qa and your thoughts about what to do about this, uh, in terms of the policy responses that are being pursued out there and what might be effective. Okay. So the first thing is to think about ad networks. No one has any constitutional right to be part of an ad network, right? In fact, as a company, you should wish to protect your brand from any association with these terrible misleading sites. Okay. So it seems as though ad networks are starting to crack down and who has, who is allowed to be a member of them and they're starting to even be white listing policies put into place, right?

Speaker 2:          32:37          So then rather than stripping out, uh, the worst sites, they're selectively adding the best. Okay. Um, so I think that's a promising approach that's also going to be driven by the advertisers who are increasingly worried about what their ad is showing that what content or ad is showing up against. Obviously Youtube is dealing with this on a massive scale right now. Second, thinking about the algorithm, I know this, there's probably like 10 to search people here who don't want to hear my thoughts on the algorithm, but let me just say there was an announcement made that fake news was being downward in the algorithm and I think that's appropriate given the concerns about the quality of this kind of information. Right? You were not serving your users well. If you are surfacing that information up, uh, it is not high quality. Right. And then finally, the most developed response we've seen has been the fact checking partnership with the, uh, the fact checkers partnership with Facebook where they're going to identify stories that have been rated as false by established fact checkers.

Speaker 2:          33:38          They're going to give you a nudge first one. You see it. And again, if you'd like to share it saying this, just, you know, this is disputed by this fact checker in that fact checker. Okay. And that's a more deliberate kind of intervention to that provides, uh, information to people, but in it, I think an appropriately hands off way that keeps Facebook out of the business of trying to adjudicate what's true and false. Okay. Leaves that to the journalist where that's their core competency. Okay. Um, so one last point is just simply to say this is an evolving problem. Okay. So if you follow the political debate since the election, the kinds of misinformation you see out there, it looks quite different. The form it's taking, it's is different. Okay. Um, there are all these conspiracy minded folks on Twitter. Uh, writing and circulating fairly crazy things I won't get into too much of, but let me just say that I'm a, there isn't just an article about a Harvard University professor, very famous law professor as well as the senator who are citing the most, uh, you know, non-credible conspiracy sites on the left to make sweeping unsupported claims about Trump and Russia.

Speaker 2:          34:43          So this misinformation problem is evolving and changing and you should be aware of how rapidly it evolves and avoid the mistake of fighting the last war. Okay. So with that note, we, we would love your questions and I just want to say please don't give up. Right. I remember my, you know, we may not be able to put out the dumpster fire, but we can at least like bring it down a little. Okay. And it's important not to give into this temptation to say we're in a post truth and post facts society and there's nothing we can do about it. There is something we can do about it. We should defend these norms and you at the platforms Google like Google and Facebook can in some ways do more than almost anybody. So, um, I think we'd love your questions and thanks very much.

Speaker 2:          35:31          Hi. So, uh, I came to this talk, uh, part of the reason I came was because that was a little bit worried about my own personal bubble that I might be in and how would I know about this? And uh, I'm a liberal and I noticed that most of the fake news stories that you gave were aim towards Republicans. So I wanted to know is it the case that most fake news stories were aimed at Republicans or can you give some examples of fake news stories that were aimed at Democrats during the election? The fake news was overwhelmingly pro Trump. There were only a handful of pro Clinton fake news stories that took off. Some people tried it, it wasn't as successful in the marketplace. So at least in that particular format it seemed to not work. But as I'm suggesting to you, some of these dubious conspiracy sites have gotten more traction among Democrats in the time since the election when Trump is in office and creates, he's the kind of scary opponent who motivates belief and misinformation the way Clinton was drinking

Speaker 1:          36:26          campaign. Yeah, I would just, I would totally concur and I would just say that it's important to keep in mind that it's important to keep in mind that misinformation exist within this larger political context and the nature of party competition and who's in, who's in the White House and who's in control of Congress. These are all things that shift over time and are going to continue to shift over time. Right? So if we think about the demand for misinformation about just, you know, the president for example, this is the most salient, right? Political figure in the United States. Of course, you know, the, the, the partisan coalitions who are dead, who are demanding that information is going to shift over time and you're going to see the flow and the supply of, of fake news and misinformation more generally be responsive to, to sort of who to to the shift in conditions that I talked about. I'm going to hand the mic,

Speaker 2:          37:13          John, who's picking up some questions from the dory. Sure. Um, so this is from the London office. Um, do you have anything particular to say about fake science or is it all the same no matter what the subject? So I've done research on vaccine misinformation and, and that's certainly, you know, Dj mentioned climate change. So this is certainly something that's not specific to politics. It extends the health and science as well. I in vaccines is a good example where it's not an ideological or partisan issue as such. And misinformation can still be quite widespread and people can still engage in selective exposure and are actually motivated reasoning too. Um, so I think there's, there's reason to question in all of these domains where people have strong views and about an issue that seems to implicate some aspect of their identity. Uh, there's, there's a real potential to have counterproductive effects or for people to seek out information that seems to confirm their views.

Speaker 2:          38:02          All right. So just to give you an example, um, there is, uh, a measles outbreak going on right now in Minnesota, in the Somali American community predominantly. And the story that's been told by our journalists there is that there was some children had autism and the parents didn't know why that wasn't a concept that we're familiar with and people started to search and they found their way to some of the really terrible information out there and have since been tar. And as they became more interested in that, some folks invited the anti-vaccine activists who present as misleading and false science. Um, and they've cultivated that to the point that their vaccination rates from very low, um, and made them vulnerable to what is now an ongoing outbreak. And measles is a very dangerous disease. Explosive. We contagious, right? So this is a good, it's a good reminder that misinformation doesn't have to be, um, partisan and it can have very immediate and dangerous consequence.

Speaker 5:          38:55          I have a question about, uh, the sort of the psychology side of the, uh, the recipients of the fake news. I know people who love to be no at all and so, and they will happily fill in the gaps in their knowledge as they're explaining something. Uh, I wonder if any investigations be done about whether they are particularly vulnerable to, to the misinformation or, you know, because they are, it was like once they've accepted it did, they're going to tout it enthusiastically. I actually, I'm, I'm inferring that they will do that. I suppose that you should leave it to you.

Speaker 1:          39:33          Um, so the, the closest sort of individual level factor that, that I can think about there that's been studied as, um, there, there are psychological studies on the need for need for closure or the need for certainty. And there's, there's a lot of variation across people in, in, in their score on that, right? Like some people to your point need to need to know things. And need to fill in the blanks. Now to the extent that those, um, those people are, are highly partisan, highly political people. Um, directionally motivated reasoning, right? Would suggest that they're going to put, they're gonna apply their abilities to forming partisan or ideologically consistent views. And I think that's that I could definitely see that happening. I'm not aware of any studies on sort of individual the effect of individual level differences like that. Um, on, on the propensity to have misperceptions or something. I don't know if you would add yeah,

Speaker 2:          40:21          no, that's it. That sounds right. And I would just say that, um, people, you know what you were saying about people kind of filling in the gaps, right? Another thing you might think about here is conspiracy theories often have that function and kind of what you can think of as a kind of subset of misinformation or misperceptions. Sorry, my microphone is off. You can think of conspiracy theories, the kind of subset of misinformation or misperceptions where people who want to understand what's going on or think they understand what's going on right now are filling in gaps. Okay. So we don't know why, uh, we don't really understand why autism happens, right? The vaccine story provides a simple explanation, right? There are chaotic and conflicting information about what happened in nine 11. The inside job miss seems to explain what happened and you go through the list. These misperceptions, we'll often have that flavor of seeming to provide a compelling simple explanation for what's going on. And some people I think do intuitively gravitate to those. There's definitely evidence that people who are predisposed to see the world in that way will disproportionately believing conspiracy theories.

Speaker 6:          41:20          Here's another question. This one's from mountain view. There been some discussion that the issue of misinformation is exacerbated by readers not knowing how to critically be news and or navigate the overwhelming nature of the current high choice media environment. How might

Speaker 2:          41:33          this concern and be relevant to Google? Okay, that's a good point. Let me say a couple of things. There's been a lot of interest in steel action in, in news and media literacy and I think educators are thinking about this as an issue. Um, so one of the things Google might be able to do is support news and media literacy as a component of civics education, um, as something that librarians could teach. Um, there's lots of ways in which we might help equip people to become better citizens. Right. The educational approach though is, is pretty limited in the sense that, you know, you're only getting those younger folks as they, as they come through the educational system year by year. Right? But we have a very large set of adults who are not in the educational system anymore and we might think about how we could reach them more effectively.

Speaker 2:          42:20          Um, I think this is an area where libraries are probably the most effective vehicle. We have all these institutions full of books and people and Librarians are trying to repurpose themselves as helping people navigate the world of information. Right? They don't, we don't need them to help us find books anymore, but they want to be information navigator. So I think there, there might be opportunities for things like partnerships. Um, at the same time, I think we have to think about how to make it easier for people in the first place. Right. It, I worry there's too much. Uh, you know, and I don't mean to attribute this to your question, but in general, out in the world, there's too much kind of lecturing people for not being sophisticated. We need to help them make better decisions, right? In a responsible, ethical way. Well, we don't tell them we know the right answer. We're going to in a condescending way, give it to them, but that we create, you know, a kind of information architecture that helps people make better decisions and get better information. Yeah.

Speaker 1:          43:15          And this is where the, the adjustments to search algorithms and different tools that you all can offer are extremely helpful because right. We do have this proliferation of news sources, many of many, most of which are high quality and are credible. Um, and so, you know, to the extent that we're highlighting those and we're training people over time as, as they become more and more use to searching and as they increasingly rely on Google, right. For everything. In their lives, the more, the more, the better they can get a distinguishing between high and low quality.

Speaker 2:          43:45          Um, it's going to be really important. Had a quick question

Speaker 7:          43:47          about, uh, the, uh, polarization data that you showed at the beginning. Especially, you know, that climate change chart is very striking. Uh, and it's easy to read that as the same cohort if people changing their minds over time. But the set of adults voting Republicans is not the same. In 2014, I myself shifted from one of those lines to another one and [inaudible] taking my climate change beliefs with me partially because I felt more comfortable on the other line with my current set of climate change beliefs. Uh, and so do you have a feeling for how much of this is people changing minds and how much of this is mines shifting their identification?

Speaker 1:          44:26          Uh, that's a great question. I mean, so, so given the polarization, given polarization of politics today, you see for most people write a strengthening of, of party attachment and, and, um, uh, people are less likely to, to switch sides and this, and this is interesting. Um, yeah, I mean, so the, the question whenever it, whenever you see partisan changes like that, like the ones I showed, it always comes down to this question of is it persuasion or replacement? Right? Are People, people forming new coalitions? Um, in the case, in the case of climate change mean climate change has just become so politicized and how it's how it's communicated in, in media that it, it sort of is a political issue now. It's almost covered as a political issue in a sort of left versus right framework as opposed to a scientific framework that other issues are, are disgusting. Um, so yeah, I mean, I, it's hard for me to imagine a lot of, um, within party persuasion now on that issue. Right? My sense would be that it's mostly, it's mostly people, people moving to a Gi tend to adjust their views with their party

Speaker 2:          45:28          in general. In general, the evidence suggests that people do go along with their party on these kinds of cues. Right? I mean, if you think about it, right? You know, in the seventies and eighties, the idea that it was somehow part isn't what you thought about the climate with preposterous that wasn't on anyone's agenda whatsoever, right? And, but the set of elite cues that people were getting started to diverge, and then we saw this kind of tribalistic movement along those lines and people falling, right? There are those folks who might switch lines as you suggest, but I'd say far more just, you know, they just to extend that they've thought about climate change, they're taking cues from people they trust as to what they should believe.

Speaker 1:          46:05          If you think about how most people write form opinions on most issues, right? Most, most people on most issues are not very informed enough, very interested. And so it's a really easy heuristic to use if people, right. If, if, if the media just presents an issue as, as a left versus right issue, it's a very easy cue for people to take as opposed to engaging in war effort, fall sort of info search about global warming. Right? And you just go to your team. Yeah.

Speaker 5:          46:30          Hi. Um, my question's around you, you presented kind of some, some findings of how people are discovering, uh, fake news, whether it's from search or social media, but has there been any work that kind of understands how they make it into those environments ranging because I mean, things get created and there must be some strategies or, or maybe common attributes that help these things get very wide distribution because these things don't get widely distributed if just if they were just graded. There must be some strategies that, that, that might, some patterns that are emerging. And I was wondering if you had thoughts or there's some research that's on this particular topic.

Speaker 2:          47:13          The mechanism we know best is, is the seeding of these fake news articles into Facebook groups. Um, you know, as you guys know about a lot of answers don't write Facebook is orders of magnitude larger than Twitter. It's the most important traffic driver of, of, of news audiences, online, bar none. And so it seems like that was where people, how people were getting from social media to, uh, to the fake news sites was the seating happened. And that was starting a diffusion process. Now again, it's important to think about this, like this is a very skewed distribution, right? There's a very large number of fake news articles that almost no one read. And if you go to these fake news sites, there's tons and tons of these. They were really mass produced in a very slipshod way. And you know, any kind of monkeys on typewriters, fashion, every so often they hit on a big one. Right? And that one went hugely viral and seems to have disseminated often via primarily via social media. But that's certainly not the only thing is you can, as you can see here,

Speaker 8:          48:14          follow up on that one. Um, you've been, I think scrupulously neutral about, you know, the source of this stuff, you know, is it stops just out there and the Darwinian sense, you know, some of this seems to, you know, get viral and take off just because it resonates with people or is there something more purposeful going on, whether it's, you know, particular groups that have, you know, particular agendas, state actors, whatever. Do you study that?

Speaker 2:          48:41          So the state actor part is hard to assess. Um, I, you know, you should ask the intelligence community, um, the reporting on fake news specifically right now suggest a more decentralized process where people were being attracted largely by the profit motive. In some cases they might have ideological partisan motives as well, but there's very little evidence of, of, of kind of coordinated effort. Right? So I showed you that FBI agent story, uh, earlier the Hillary Clinton investigation, you died in a murder suicide. The guy who wrote that was literally unemployed, living at home, trying to figure out how to make money. He's since come forward and explained his story. Um, the Macedonian teenagers didn't have to seem to have any particular ax to grind as far as anyone can tell and so forth. So it's possible there's coordination or state actors, some of those other kinds of state sponsored misinformation online we can talk about. But in terms of the, the set of sites that were being widely distributed during the campaign, I think it's fair to say that there's not a lot of hard evidence of the record of that at this point.

Speaker 6:          49:37          So, so journalists are constantly thinking about how they can rewrite headlines or taglines to get to make their content real news. We like to call it a go viral. Um, were there particular headline structures or, um, pictures added or structures to specific Facebook posts that kind of stood out in a common thread for these posts that went viral?

Speaker 2:          50:00          I mean, I would say the common thread was mostly Hillary is evil, right? If you had to boil it down to three words, um, but there were certainly lots of stories like that that didn't resonate. Um, it does seem to have something of a Darwinian feel to it. Like there's lots and lots and lots of other, uh, articles that say Hillary is evil that didn't take off. And for whatever reason, these resonated. These five examples aren't the best. But some of these are kind of in a way that Parsons might enjoy laughing and being like, ha ha ha, look, you know, I don't really believe this bill. Look how funny it is. Right? So one of the most widely shared pro Clinton fake news stories said Ireland is taking a political asylum. Refugees from the United States because of Trump. Right. And so how many people were sharing that because they actually believed it? How many were sharing? It is a kind of expression of anti-Trump feelings or identity, right. Is less clear. Um, another one from online. So if raw fact checking doesn't convince people, uh, and might even reinforce false beliefs, are there any strategies we have evidence for that do work? You know,

Speaker 1:          51:03          there is, there is evidence in fact checking works right? So I don't want to, I don't want to be totally pessimistic here and say that this problem isn't, isn't solvable under, under any conditions. I mean, so, um, there's a lot of experimental work now looking at the, uh, the influence of information from nonpartisan fact checking organizations like politifact and, um, uh, politik track and other, other organizations, um, uh, when it comes to, but when it goes outside of that framework, when it comes to just kind of watchdog journalism and trying to correct misperceptions and more widely read formats, um, yeah, there are all sorts of best practices that, that people can engage it. And I'm so one of the most widely studied ones that I would just point out as as one example. Um, is it people, people are really bad at processing negations of planes.

Speaker 1:          51:49          Okay. So Brendan's written written on this. Um, and, uh, people, uh, over time tend to remember information. Uh, if you tell someone that something is false, they tend to remember the information over time, but they often forget that it's false, right? So this is an illusion. It's called the illusion of truth, the fact, right? So you might correct something, it might, you know, might change their factual beliefs that at the point of the correction, but then over time people are bad at processing, uh, cognitively that things are not true, right? And so they might come to actually hold that belief more over time. So avoiding negations and framing things in the affirmative, right? So the, the classic example of this from recent years is, um, Obama is a Christian versus Obama is not a Muslim. People just become, uh, especially when they're motivated, right? Like they might be with that when people, people are oftentimes susceptible to losing sight of, of, of litigation over time.

Speaker 2:          52:43          And unfortunately that's all we have time for. Thank you so much for coming to [inaudible].

Speaker 4:          52:46          Okay.