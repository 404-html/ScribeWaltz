1
00:00:06,940 --> 00:00:07,773
Yeah.

2
00:00:10,940 --> 00:00:15,620
So I'll thank you for that
lovely in production and uh, uh,

3
00:00:16,010 --> 00:00:20,150
and thank you for um, sharing lunch,
sharing your lunch hour with me.

4
00:00:20,750 --> 00:00:21,051
Um,

5
00:00:21,051 --> 00:00:26,051
so I think what I'm going to do is kind
of jump into the talk and if there are

6
00:00:26,330 --> 00:00:30,410
procedural questions you have
or questions about methods,

7
00:00:30,411 --> 00:00:34,250
I'm happy to take those questions now.
Otherwise we'll just wait till the end.

8
00:00:37,800 --> 00:00:42,510
So lots of tech companies are trying
to figure out how to detect emotion by

9
00:00:42,511 --> 00:00:44,070
reading facial expressions.

10
00:00:44,400 --> 00:00:49,400
It's a really exciting time because
the technology is a developing really

11
00:00:49,741 --> 00:00:52,710
quickly advancing really fast.
Um,

12
00:00:52,800 --> 00:00:56,130
and in fact the pace is
even seems to me anyways,

13
00:00:56,131 --> 00:01:00,870
kind of speeding up and there
was a growing economy of um,

14
00:01:01,290 --> 00:01:04,260
emotion reading gadgets
and apps and algorithms.

15
00:01:05,160 --> 00:01:07,680
But the question I want
to start today with is,

16
00:01:07,681 --> 00:01:12,681
can we really expect a machine
to read emotion in a face?

17
00:01:13,710 --> 00:01:17,940
There are plenty of companies who
are claiming to have already done it

18
00:01:19,830 --> 00:01:23,550
and their claims are
based on some fundamental
assumptions that we're going to

19
00:01:23,551 --> 00:01:28,030
systematically examined today.
And I'll just warn you,

20
00:01:28,031 --> 00:01:31,720
I'm going to maybe suggest some things
that some people might find a little

21
00:01:31,721 --> 00:01:35,410
provocative and might challenge
your deeply held beliefs.

22
00:01:36,170 --> 00:01:37,003
Um,

23
00:01:37,030 --> 00:01:41,980
because the message I'm going to
suggest today is that machines,

24
00:01:41,981 --> 00:01:45,010
it's not the case that machines
can't perceive emotion,

25
00:01:45,310 --> 00:01:49,540
but that company's currently seem to be
going about this question in the wrong

26
00:01:49,541 --> 00:01:53,680
way because they fundamentally
misunderstand the nature of emotion.

27
00:01:54,100 --> 00:01:57,130
And as a consequence,
they're missing what, uh,

28
00:01:57,250 --> 00:02:02,250
I would think of as a game
changing opportunity to
really transform the science

29
00:02:03,101 --> 00:02:05,680
and its application to everyday problems.

30
00:02:06,400 --> 00:02:11,110
So emotion reading technology usually
starts with the assumption that people are

31
00:02:11,111 --> 00:02:15,580
supposed to smile when they're
happy, frown when they're sad, scowl,

32
00:02:15,581 --> 00:02:17,470
when they're angry and so on.

33
00:02:17,680 --> 00:02:22,680
And then everyone around the world should
be able to recognize smiles and frowns

34
00:02:22,931 --> 00:02:26,350
and scowls as, uh, expressions of emotion.

35
00:02:27,340 --> 00:02:32,080
And it's this assumption that leads
companies to claim that detecting a smile

36
00:02:32,590 --> 00:02:37,510
with computer vision
algorithms is equivalent to
detecting an emotion like joy.

37
00:02:38,980 --> 00:02:43,630
But I want you to consider
this evidence. This, um,

38
00:02:43,750 --> 00:02:48,670
here on the x axis are the presumed,
uh,

39
00:02:48,671 --> 00:02:53,320
expressions for, um, the
various emotions. For anger,

40
00:02:53,321 --> 00:02:57,940
disgust, fear, happiness,
sadness, and surprise.

41
00:02:59,710 --> 00:03:03,820
And now we're going to look at
some evidence from Meta analyses,

42
00:03:03,821 --> 00:03:08,020
statistical summaries of experiments to
answer the question of how often people

43
00:03:08,021 --> 00:03:11,070
actually make these
faces, um, during emotion.

44
00:03:11,080 --> 00:03:14,140
And the answer is not so much

45
00:03:15,940 --> 00:03:20,920
the y axis represents the proportion of
times that people actually make these

46
00:03:20,921 --> 00:03:24,400
facial expressions during
actual emotional events.

47
00:03:24,850 --> 00:03:29,160
So in real life, for example, um,

48
00:03:29,260 --> 00:03:34,260
people only make a wide eyed gasping
face during an episode of fear 9% of the

49
00:03:36,581 --> 00:03:40,420
time across 16 different
studies. And in fact, that face,

50
00:03:40,421 --> 00:03:45,310
if you were in pop when a Guinea in the
Troy brand islands would be considered

51
00:03:45,311 --> 00:03:49,060
an anger face. It's a threat face. It's
a face that you make to threaten someone.

52
00:03:50,830 --> 00:03:52,750
So in real life,

53
00:03:52,751 --> 00:03:56,770
people are moving their faces in a variety
of ways to express a given emotion.

54
00:03:56,771 --> 00:04:00,510
They might scowl and anger, um, about, uh,

55
00:04:00,970 --> 00:04:05,620
30% of the time. Um, but
they might cry in anger.

56
00:04:05,680 --> 00:04:10,390
They might have a stone face stare and
anger. They might even smile in anger.

57
00:04:11,380 --> 00:04:15,580
And conversely, people often make these
faces when they're not emotion at all.

58
00:04:15,581 --> 00:04:19,190
For example,
people often scowl a,

59
00:04:19,270 --> 00:04:24,100
a full on facial scowl when they're just
concentrating really hard. Nevertheless,

60
00:04:24,101 --> 00:04:29,101
there are hundreds of studies where test
subjects are shown posed expressions

61
00:04:30,521 --> 00:04:31,151
like these.

62
00:04:31,151 --> 00:04:36,010
So post faces and then they're asked to
identify the emotion being portrayed.

63
00:04:36,640 --> 00:04:40,480
And again,
the proportions are on the y axis.

64
00:04:40,780 --> 00:04:42,610
And so you can see there's
quite a difference, right?

65
00:04:42,611 --> 00:04:46,450
Even though people only make a wide eyed
gasping pay face about 9% of the time,

66
00:04:46,780 --> 00:04:49,000
68% of the time.
Um,

67
00:04:49,210 --> 00:04:54,210
test subjects identify that as a fear
expression and so on and so forth.

68
00:04:56,260 --> 00:05:00,820
So which data are the companies using to,

69
00:05:00,850 --> 00:05:05,260
um, to, uh, as the basis
of their development?

70
00:05:06,280 --> 00:05:07,600
They're using the blue bars.

71
00:05:09,010 --> 00:05:11,710
So when software detects
someone as scowling,

72
00:05:11,860 --> 00:05:15,700
they infer that the person is
angry. And in fact, you'll hear, um,

73
00:05:15,950 --> 00:05:19,480
companies refer to a scowl
as an anger expression,

74
00:05:19,481 --> 00:05:24,481
as if there's a one to one correspondence
and frowning for sadness and so on.

75
00:05:26,230 --> 00:05:28,660
And so the question is,
well,

76
00:05:28,661 --> 00:05:32,500
if people sometimes make these
faces to express emotion,

77
00:05:32,710 --> 00:05:35,920
the d the presumed emotion,
but often not.

78
00:05:35,950 --> 00:05:40,950
Why our test subjects as perceivers
identifying emotions in these faces.

79
00:05:41,681 --> 00:05:46,300
So, um, so frequently. So why are the blue
bar so much higher than the white bars?

80
00:05:46,710 --> 00:05:48,610
Um,
and now I'm going to show you the answer.

81
00:05:49,720 --> 00:05:53,920
Here's the kind of experiment that is
almost always used in the sorts of studies

82
00:05:53,921 --> 00:05:58,210
that generate the data for those blue
bars. Test subjects are shown opposed

83
00:05:58,220 --> 00:05:59,330
face like this.

84
00:05:59,870 --> 00:06:03,380
And then there I'm shown a small set of
words and then they're asked to pick the

85
00:06:03,381 --> 00:06:07,280
word that matches the face.
So which word matches this face?

86
00:06:10,010 --> 00:06:10,843
Good job.

87
00:06:12,320 --> 00:06:16,490
When test subjects choose the
expected word from the list,

88
00:06:16,491 --> 00:06:17,990
it's called accuracy.

89
00:06:18,200 --> 00:06:22,010
Even though this person is not angry,
in fact,

90
00:06:22,011 --> 00:06:23,330
she's just posing a face.

91
00:06:23,331 --> 00:06:26,480
And in most of the faces that
are used in these experiments,

92
00:06:26,481 --> 00:06:30,140
subjects are just posing faces right
there. So it's not really accuracy,

93
00:06:30,320 --> 00:06:34,070
it's more like how much did you agree
with the experimenters expectations,

94
00:06:34,071 --> 00:06:37,730
but it's called accuracy. So that's
what we're going to call it today too.

95
00:06:38,300 --> 00:06:42,710
So hundreds of studies show pretty
high accuracy using this method.

96
00:06:43,700 --> 00:06:44,570
This is on average.

97
00:06:44,571 --> 00:06:49,500
So this is a Meta analytic average
across hundreds of studies and, um,

98
00:06:49,700 --> 00:06:51,980
emotion perception,
you know,

99
00:06:52,010 --> 00:06:55,580
feels as easy as reading words
on a page because in fact,

100
00:06:55,820 --> 00:06:58,710
that's actually what's happening
in these experiments. Um,

101
00:06:58,940 --> 00:07:03,940
when you remove the words and you merely
ask test subjects to freely label the

102
00:07:05,660 --> 00:07:09,140
faces,
accuracy drops precipitously.

103
00:07:09,860 --> 00:07:14,420
And for some emotions like contempt
and shame and embarrassment,

104
00:07:14,670 --> 00:07:17,330
uh, the rates actually
dropped to chance levels,

105
00:07:17,331 --> 00:07:20,480
which is about 17% in
most of these studies.

106
00:07:22,220 --> 00:07:26,600
And here's what happens when we add a
little bit of diversity into the picture.

107
00:07:26,601 --> 00:07:29,360
So things get a little more interesting.

108
00:07:29,361 --> 00:07:34,361
So we tested a group of hunter
gatherers in Tanzania called the Hadza.

109
00:07:35,840 --> 00:07:37,390
The Hud's, uh, um,

110
00:07:37,610 --> 00:07:42,610
have been hunting and
gathering continuously as a
culture since the pleistocene.

111
00:07:42,890 --> 00:07:46,190
They don't live in, um, you know,

112
00:07:46,220 --> 00:07:50,960
the same exact same circumstances as
ancient humans, but they are living,

113
00:07:50,961 --> 00:07:54,140
they are, you know, hunting and
gathering, uh, on the African Savanna.

114
00:07:54,141 --> 00:07:59,141
So they are living a lifestyle that
is similar to the conditions that some

115
00:08:00,140 --> 00:08:02,660
psychologists,
evolutionary psychologists believe,

116
00:08:02,840 --> 00:08:07,700
gave rise to these universal expressions.
So there a great population to,

117
00:08:07,760 --> 00:08:11,420
um, to test. And there actually
aren't that many of them left.

118
00:08:11,421 --> 00:08:14,680
It's actually really hard
to get access to these, um,

119
00:08:15,260 --> 00:08:16,610
to this group of individuals.

120
00:08:16,611 --> 00:08:20,840
You have to have special research permits
and so on. Um, so we were able to,

121
00:08:21,140 --> 00:08:26,140
with the help of an anthropologist who
we collaborated with get access to the

122
00:08:26,151 --> 00:08:30,410
Hadza and who were very generous
with their time, um, and um,

123
00:08:30,950 --> 00:08:32,600
you know,
labeled some faces for us.

124
00:08:32,601 --> 00:08:37,601
So we showed them a set of faces and we
ask them to do exactly what we ask other

125
00:08:38,930 --> 00:08:42,380
test subjects to do. Uh, and um,

126
00:08:43,130 --> 00:08:45,410
accuracy actually dropped even further.

127
00:08:45,890 --> 00:08:50,630
And this number is actually a little
high because what the huddle we're very

128
00:08:50,631 --> 00:08:55,631
good at doing was distinguishing
a smile from all the other faces,

129
00:08:56,221 --> 00:09:01,070
which were depicting negative emotions.
So when you just look at the, um,

130
00:09:01,140 --> 00:09:05,790
accuracy for, for labeling scalpels
and pouts and things like that,

131
00:09:05,791 --> 00:09:09,240
just the negative depictions
of negative emotions,

132
00:09:09,241 --> 00:09:13,830
the rate dropped even further,
pretty much to chance levels.

133
00:09:14,250 --> 00:09:19,250
And so this is what happens when you
remove the secret ingredient from these

134
00:09:19,681 --> 00:09:21,170
experiments.
Um,

135
00:09:21,240 --> 00:09:26,090
the evidence for universal
emotional expressions vanishes. No,

136
00:09:26,100 --> 00:09:30,240
I'm not saying that that means that faces
carry no information or that we can't

137
00:09:30,241 --> 00:09:35,190
look at a face and, and uh, make a
reasonable guests about how someone feels.

138
00:09:35,460 --> 00:09:39,960
But what I am telling you is that human
brains are doing more than just looking

139
00:09:39,961 --> 00:09:42,300
at a face when they make such judgments.

140
00:09:42,650 --> 00:09:45,660
That is right now when you're looking
at me or when I'm looking at you,

141
00:09:45,661 --> 00:09:49,830
some of you were smiling and nodding.
Thank you very much. Others are, you know,

142
00:09:50,010 --> 00:09:52,860
maybe looking a little more skeptical
or at least that's the guests that my

143
00:09:52,861 --> 00:09:56,850
brain is making.
My brain isn't just using your face.

144
00:09:56,851 --> 00:09:59,560
There's a whole context around us.
Um,

145
00:09:59,700 --> 00:10:02,880
but in these experiments
were just looking,

146
00:10:02,881 --> 00:10:07,110
the experimenters were looking only
for the signal value in the face alone,

147
00:10:07,111 --> 00:10:10,290
stripped away of all context
except the context that they,

148
00:10:10,291 --> 00:10:14,430
unbeknownst to them actually had provided
to the subjects, which are the words.

149
00:10:14,970 --> 00:10:18,540
So to just to confirm that,
um,

150
00:10:19,860 --> 00:10:24,330
that, you know, the experimental
context was actually,

151
00:10:24,680 --> 00:10:28,590
uh,
generating evidence making,

152
00:10:28,591 --> 00:10:32,040
making that it could make
any emotion look universal.

153
00:10:32,850 --> 00:10:37,020
We decided to test this by going back
to the original experimental method.

154
00:10:37,290 --> 00:10:41,910
And we identified six emotions from
different cultures that have never been

155
00:10:42,090 --> 00:10:43,770
identified as universal,

156
00:10:44,010 --> 00:10:48,630
that can't be translated into
English with a single word,

157
00:10:48,780 --> 00:10:53,520
which is important because all of the
presumed universal emotions happen to be

158
00:10:53,610 --> 00:10:57,810
English categories and,
um, they also don't exist.

159
00:10:57,811 --> 00:11:02,100
And the language that is spoken
by the Hadza, uh, which is, um,

160
00:11:02,400 --> 00:11:03,233
heads on a,

161
00:11:03,630 --> 00:11:08,630
and then when we did is we invented
expressions for these emotions.

162
00:11:08,641 --> 00:11:10,800
We just made them up.
Uh,

163
00:11:10,801 --> 00:11:13,980
and in this case we were
using vocalizations,

164
00:11:13,981 --> 00:11:15,600
although we have a version with faces,

165
00:11:15,601 --> 00:11:18,810
but we were using vocalizations
because it's a complicated story,

166
00:11:18,811 --> 00:11:21,710
but we were basically
replicating, uh, we're,

167
00:11:21,800 --> 00:11:26,460
we were replicating another experiment,
um, and kind of criticizing it.

168
00:11:26,980 --> 00:11:29,340
Um, so we use vocalizations.
So for example,

169
00:11:29,940 --> 00:11:33,350
the category Giggle is,
uh,

170
00:11:33,570 --> 00:11:38,280
the overwhelming urge to
squeeze or a pinch, something
that's very cute. You know,

171
00:11:38,281 --> 00:11:39,520
when you see him cute
and you just want to,

172
00:11:39,630 --> 00:11:44,280
you just want to squeeze the cheeks
of a baby. Right? Um, that's the,

173
00:11:44,310 --> 00:11:46,380
that's the emotion.
Um,

174
00:11:46,410 --> 00:11:49,860
and so we made up a
vocalization to go with that,

175
00:11:50,100 --> 00:11:51,570
which sounds something like this.

176
00:11:54,960 --> 00:11:55,793
Okay.

177
00:11:56,150 --> 00:12:01,150
We made that sound and then we
asked our test subjects again from,

178
00:12:01,730 --> 00:12:02,120
uh,

179
00:12:02,120 --> 00:12:07,010
the Hadza test subjects to match each
sound with a little story that we told

180
00:12:07,011 --> 00:12:11,350
about emotion because in remote samples,
um,

181
00:12:11,480 --> 00:12:14,260
that are, um, you know, small scale, um,

182
00:12:14,300 --> 00:12:18,530
societies that are very remote
from western cultures. Um,

183
00:12:18,680 --> 00:12:21,320
typically the way these experiments are
done is you don't give them a list of

184
00:12:21,321 --> 00:12:21,531
words.

185
00:12:21,531 --> 00:12:25,520
You tell them a little story about the
emotion that contains the emotion word.

186
00:12:25,750 --> 00:12:29,090
Uh, and then you give them two phases
or two vocalizations and you ask them to

187
00:12:29,120 --> 00:12:33,770
basically pick the expression that
matches. So that's what we did.

188
00:12:34,280 --> 00:12:38,390
Um, and then the average
accuracy actually, um,

189
00:12:38,570 --> 00:12:42,950
was pretty high. And if you
look at the individual emotions,

190
00:12:42,951 --> 00:12:47,000
five of the six of them look
universal. Um, and in fact,

191
00:12:47,001 --> 00:12:51,200
these accuracy rates are pretty similar
to what you see in many studies of Ang

192
00:12:51,201 --> 00:12:53,180
for fit, for anger,
sadness, fear, and so on.

193
00:12:54,350 --> 00:12:57,500
So this is where the blue bars come from.

194
00:12:57,650 --> 00:13:02,650
Scientists have been using really since
the 1960s and experimental method that

195
00:13:02,721 --> 00:13:06,410
doesn't discover evidence for
universal expressions of emotion,

196
00:13:06,590 --> 00:13:11,590
but it manufacturers that evidence this
method of providing test subjects with

197
00:13:15,290 --> 00:13:20,290
linguistic cues is responsible for the
scientific belief that a scowl expresses

198
00:13:21,860 --> 00:13:26,860
anger and only anger that
a smile expresses happiness
and only happiness and so

199
00:13:28,191 --> 00:13:29,024
on.

200
00:13:29,390 --> 00:13:34,390
And so if you're a company who wants to
build AI to perceive emotions in humans

201
00:13:35,870 --> 00:13:39,990
by measuring their facial movements,
then um,

202
00:13:40,160 --> 00:13:45,160
it's probably important to realize
that these famous configurations don't

203
00:13:45,290 --> 00:13:49,250
actually consistently, um,
display disgust, anger,

204
00:13:49,251 --> 00:13:50,600
and fear and so on.

205
00:13:51,080 --> 00:13:56,080
And that it's a mistake to infer that
someone who has scowling is angry.

206
00:13:57,591 --> 00:13:58,490
And in fact,
it's an,

207
00:13:58,520 --> 00:14:03,440
it's a mistake to call a scowl and
anger expression because only sometimes,

208
00:14:03,550 --> 00:14:08,300
um, it doesn't out isn't a scowl
indicative of anger. Instead,

209
00:14:08,301 --> 00:14:12,560
what we see when we look at the
data is that variation is the norm.

210
00:14:12,980 --> 00:14:15,650
And to show here,
I'll just show you what I mean.

211
00:14:15,651 --> 00:14:20,390
So if you were looking at
this person's face, um,

212
00:14:20,570 --> 00:14:23,260
how, how, how does she look to you? What,

213
00:14:23,290 --> 00:14:27,950
what emotion does she seem to be
expressing? Sadness. She's sneezing,

214
00:14:27,951 --> 00:14:29,390
not even an emotion at all,

215
00:14:32,150 --> 00:14:36,380
smelling something good.
So usually this isn't yet.

216
00:14:36,410 --> 00:14:39,120
Usually people see her as tired or,
um,

217
00:14:40,030 --> 00:14:43,430
or as I'm grieving or as about to cry.

218
00:14:43,880 --> 00:14:47,200
I'm sad. Um, actually this is, uh,

219
00:14:47,270 --> 00:14:52,270
my daughter Sophia experiencing only
what I can only describe to you is a

220
00:14:53,061 --> 00:14:57,120
profound and deep sense of pleasure,
um,

221
00:14:57,440 --> 00:15:01,350
at the chocolate museum
in Cologne, Germany. Um,

222
00:15:02,020 --> 00:15:02,260
okay.

223
00:15:02,260 --> 00:15:06,640
And this little sweetheart
is also experiencing,

224
00:15:06,870 --> 00:15:09,070
uh,
a profound sense of pleasure.

225
00:15:09,510 --> 00:15:14,510
And the lesson here is that people move
their phases in many different ways

226
00:15:15,810 --> 00:15:17,760
during the same emotion.

227
00:15:20,670 --> 00:15:21,240
Now,

228
00:15:21,240 --> 00:15:26,240
if we were to only look at this
little guy's eyebrows up to his,

229
00:15:26,431 --> 00:15:29,610
you know, eyes and nose, um, this,

230
00:15:29,790 --> 00:15:32,850
these facial actions actually are,
um,

231
00:15:33,120 --> 00:15:36,960
very reminiscent of the
presumed expression for anger.

232
00:15:37,750 --> 00:15:40,750
So for example,
um,

233
00:15:43,850 --> 00:15:48,350
this face is often seen as angry.
Does anybody actually know who this is?

234
00:15:49,370 --> 00:15:50,030
Jim Webb,

235
00:15:50,030 --> 00:15:55,030
this is actually Jim Webb when he
won the senatorial race in Virginia,

236
00:15:56,360 --> 00:15:59,910
which returned the Senate
to democratic control, um,

237
00:15:59,970 --> 00:16:03,630
this victory return the Senate
to democratic control. Sorry,

238
00:16:03,631 --> 00:16:06,960
I was just having a moment there.
Uh, and so without context,

239
00:16:06,961 --> 00:16:10,850
we see his face as communicating
anger because actually, um,

240
00:16:10,920 --> 00:16:13,650
this face symbolizes anger in our culture.

241
00:16:14,430 --> 00:16:19,430
So people don't just move their faces in
different ways during the same emotion.

242
00:16:19,471 --> 00:16:21,810
They also moved, yeah, their faces, um,

243
00:16:21,900 --> 00:16:25,440
in the same way during different emotions.

244
00:16:27,620 --> 00:16:31,610
So when in real life,
a face doesn't speak for itself,

245
00:16:31,611 --> 00:16:33,260
when it comes to emotion,
right?

246
00:16:33,261 --> 00:16:38,261
People usually see this guy a the fittest
face as smug or pride or confidence.

247
00:16:39,120 --> 00:16:39,350
Um,

248
00:16:39,350 --> 00:16:44,330
actually it's at the supposedly
universal expression for discussed.

249
00:16:44,630 --> 00:16:48,110
And what's really interesting is that
when you stick a presume, you know,

250
00:16:48,111 --> 00:16:53,111
the presumed expression for discussed
on a body or in any kind of context that

251
00:16:55,161 --> 00:17:00,161
I'm suggests a different
emotion perceivers actually
track the face differently.

252
00:17:03,071 --> 00:17:06,670
They're scanning of the face has a
completely different pattern suggesting

253
00:17:06,671 --> 00:17:11,080
they're making different meaning of that
face on the road by virtue of the, um,

254
00:17:11,680 --> 00:17:14,830
the context it's in. And I'll just
tell you as an aside in every,

255
00:17:15,300 --> 00:17:18,880
well maybe that's an
exaggeration in most studies, um,

256
00:17:18,970 --> 00:17:21,610
where you pit a face against a context,

257
00:17:21,940 --> 00:17:26,830
the face always loses faces are inherently
ambiguous without contacts to make

258
00:17:26,831 --> 00:17:31,570
them meaningful.
So what's up with these expressions?

259
00:17:31,780 --> 00:17:33,220
Where did they come from?
Well,

260
00:17:33,221 --> 00:17:38,200
it turns out that they were not discovered
by actually observing people as they

261
00:17:38,201 --> 00:17:42,340
moved their faces, expressing
emotions in real life. In fact,

262
00:17:42,341 --> 00:17:44,470
these are stipulated expressions.

263
00:17:44,740 --> 00:17:49,030
So a handful of scientists just
anointed these as the expressions,

264
00:17:49,140 --> 00:17:53,580
emotion as universal truths, and then
people built a whole science around.

265
00:17:54,570 --> 00:17:58,100
So basically their stereotypes.
And um,

266
00:17:58,110 --> 00:18:02,850
what we have is a science of
stereotypes or you know, emojis,

267
00:18:04,260 --> 00:18:08,970
which by themselves I should tell you also
are highly ambiguous. It turns out, um,

268
00:18:09,660 --> 00:18:11,680
without context.
Uh,

269
00:18:12,030 --> 00:18:16,680
so obviously we don't want to
build a science, uh, of, uh,

270
00:18:16,681 --> 00:18:18,960
artificial intelligence on stereotypes.

271
00:18:18,961 --> 00:18:22,890
We want to build them on emotional
episodes as they occur in, in real life.

272
00:18:23,250 --> 00:18:27,900
And in real life, an emotion
is not an entity, right?

273
00:18:27,901 --> 00:18:32,730
It's a category that's filled
with variety. When you're angry,

274
00:18:33,150 --> 00:18:38,070
your face does many things and your body
does many things and it turns out your

275
00:18:38,071 --> 00:18:42,690
brain also does different things depending
on the context that you're in. Now,

276
00:18:42,691 --> 00:18:47,040
for those of you who build classification
systems, you know about categories,

277
00:18:47,520 --> 00:18:51,710
right? So for example, if
you were building a category,
uh, if you're building a,

278
00:18:51,711 --> 00:18:55,380
a recognition system for cats,
a cat recognition system,

279
00:18:55,770 --> 00:18:59,370
you would develop a classifier that could
learn the features that cats have in

280
00:18:59,371 --> 00:19:04,371
common that distinguished them from other
animals like dogs and birds and fish

281
00:19:04,381 --> 00:19:08,400
and so on.
And this cat Aghori get it.

282
00:19:08,550 --> 00:19:12,690
My daughter made me say that. Okay.
This category, thank you for laughing.

283
00:19:12,691 --> 00:19:15,430
Now I can tell her that you
thought it was funny. Um,

284
00:19:15,550 --> 00:19:19,590
is a collection of instances that
has similar features, but you know,

285
00:19:19,591 --> 00:19:24,591
there's actually plenty of variation in
these instances of this category too,

286
00:19:25,020 --> 00:19:29,550
right? Some cats are
big, some cats are small.

287
00:19:30,180 --> 00:19:34,670
Oh. Some cats have, um, you know,

288
00:19:34,680 --> 00:19:38,840
cats have different eye colors.
Some cats have long first,

289
00:19:38,841 --> 00:19:40,980
some have short for some have no fur.

290
00:19:42,750 --> 00:19:43,583
MMM.

291
00:19:44,070 --> 00:19:49,070
But the human brain tends to ignore this
variation in favor of what cats have in

292
00:19:50,041 --> 00:19:54,900
common. And the interesting
thing is that, um,

293
00:19:55,020 --> 00:19:59,430
humans also have the capacity to
make other kinds of categories,

294
00:19:59,431 --> 00:20:01,250
categories where,
um,

295
00:20:01,920 --> 00:20:06,420
there are no physical similarities where
the category is not based on physical

296
00:20:06,421 --> 00:20:11,010
similarities of the instances. Um, and
this is something we do all the time.

297
00:20:11,220 --> 00:20:14,820
For example, here's a category.
This is a category that every,

298
00:20:14,821 --> 00:20:17,700
I'm sure everyone in this room knows.

299
00:20:18,630 --> 00:20:19,300
Yeah.

300
00:20:19,300 --> 00:20:23,640
You want to take a guess what it is,
human made objects.

301
00:20:24,510 --> 00:20:27,390
I suppose if you treat the elephant
like a picture of an elephant,

302
00:20:27,391 --> 00:20:31,290
then that would, that
would be true. Yeah. Okay.

303
00:20:31,320 --> 00:20:36,210
Well these are all objects that you
can't bring through airport security.

304
00:20:39,090 --> 00:20:43,400
Actually, the last time I did this one
clever person actually said they're all,

305
00:20:43,700 --> 00:20:48,700
um, instances of things that you can
squirt water of. And I thought, well,

306
00:20:48,701 --> 00:20:49,301
actually yeah,

307
00:20:49,301 --> 00:20:53,470
if you think of the gun as a water
pistol then that that could work. Right.

308
00:20:54,610 --> 00:20:55,443
Um,

309
00:20:55,570 --> 00:21:00,560
this is a category that's
not made of instances that
chair physical features. Um,

310
00:21:00,580 --> 00:21:03,160
instead they share a common function.
In this case,

311
00:21:03,460 --> 00:21:06,430
squirting water through them or not
being able to take some through airport

312
00:21:06,431 --> 00:21:09,280
security. Um, uh,

313
00:21:09,400 --> 00:21:14,400
this category though exist inside our
heads and in the head of every adult who

314
00:21:15,131 --> 00:21:19,540
has ever flown on an airplane. Um,
it's a category of social reality.

315
00:21:21,400 --> 00:21:24,990
So for objects to belong
to this category, um, they,

316
00:21:25,050 --> 00:21:28,960
they belong not because they all
share the same physical features,

317
00:21:28,961 --> 00:21:33,460
but because we impose a similar function
on them by collective agreement,

318
00:21:34,420 --> 00:21:39,420
we've all agreed that it
is not okay to take water,

319
00:21:39,730 --> 00:21:40,270
uh,

320
00:21:40,270 --> 00:21:45,270
through the water bottle
through security or a gun or a,

321
00:21:45,580 --> 00:21:48,520
we're an elephant.
And in fact,

322
00:21:48,521 --> 00:21:53,521
it turns out that most of the categories
that we deal with in civilization are

323
00:21:55,630 --> 00:21:56,980
categories of social reality,

324
00:21:56,981 --> 00:22:00,520
who's instances don't necessarily
share physical features,

325
00:22:00,521 --> 00:22:05,260
but we've imposed the same function on
those features by collective agreement.

326
00:22:05,830 --> 00:22:09,220
Can you, can you think of
any that might come to mind?

327
00:22:09,221 --> 00:22:13,060
Things that we treat as similar,
but um, but are actually,

328
00:22:13,061 --> 00:22:15,370
their physical features
actually vary quite a bit.

329
00:22:19,150 --> 00:22:22,810
Money. Exactly. Money is the
money is a great example.

330
00:22:22,960 --> 00:22:27,340
So throughout the course of human
history and actually even right now, um,

331
00:22:27,520 --> 00:22:32,520
there's nothing about what humans have
used as currency that defines those

332
00:22:33,430 --> 00:22:34,750
instances as currency.

333
00:22:34,751 --> 00:22:38,950
It's just a group of people decide that
something can be traded for material

334
00:22:38,951 --> 00:22:43,120
goods and so they can, um, and
you know, little pieces of paper,

335
00:22:43,150 --> 00:22:46,780
pieces of plastic shells,
salt,

336
00:22:46,810 --> 00:22:51,160
big rocks in the ocean, which
are immovable, um, mortgages.

337
00:22:51,700 --> 00:22:55,300
And when we remove our
collective agreement,

338
00:22:55,900 --> 00:22:59,020
those things lose their value,
right?

339
00:22:59,021 --> 00:23:03,870
So one way of thinking about the
mortgage bubble is that, uh, mortgages,

340
00:23:03,910 --> 00:23:07,560
the value of mortgages is based
on collective agreement and, uh,

341
00:23:07,570 --> 00:23:09,250
some people removed their agreement.

342
00:23:10,320 --> 00:23:13,920
Anything else?
Yeah,

343
00:23:15,310 --> 00:23:19,150
that's true. You have to
work really hard to, uh,

344
00:23:19,210 --> 00:23:24,160
accept the collective agreement, uh, of
driving on the wrong side of the road.

345
00:23:25,150 --> 00:23:29,680
Oh, come on. Beauty. How about

346
00:23:29,970 --> 00:23:34,440
citizenship of a country?
How about a country?

347
00:23:36,140 --> 00:23:39,450
Right? If you go for example, into, um,

348
00:23:39,720 --> 00:23:44,720
if you look at a map from a
1940s or before the 1940s,

349
00:23:44,880 --> 00:23:48,170
the map of the world looks very different.

350
00:23:48,200 --> 00:23:50,360
The map of the earth is
pretty much the same.

351
00:23:50,361 --> 00:23:54,560
The physical features of the earth are
more or less the same. Um, but, uh,

352
00:23:54,590 --> 00:23:59,330
but the countries are, that are
drawn, are, are different. Um,

353
00:23:59,331 --> 00:24:03,560
so we could go on and on like this.
We can talk about, um, social roles,

354
00:24:03,561 --> 00:24:05,120
like being married.

355
00:24:05,121 --> 00:24:10,040
Marriage actually turns out is also
a category of social reality. Um,

356
00:24:10,280 --> 00:24:14,120
the presidency of any
country is, uh, you know,

357
00:24:14,450 --> 00:24:18,080
people don't have power because
they're endowed by nature, with power.

358
00:24:18,081 --> 00:24:21,620
They have power because we all agree
that certain positions give you power.

359
00:24:22,250 --> 00:24:26,330
And if we revoked our agreement,
then they wouldn't have power anymore.

360
00:24:27,640 --> 00:24:32,200
Um, that's called the revolution. So, um,

361
00:24:34,230 --> 00:24:39,230
the emotion categories are
our categories like this,

362
00:24:40,050 --> 00:24:44,340
anger and sadness and fear
and so on. Um, our, um,

363
00:24:45,200 --> 00:24:50,180
categories that exist because,
uh, by of collective agreement,

364
00:24:50,570 --> 00:24:53,840
just in the same way that
we had to impose, um,

365
00:24:53,990 --> 00:24:58,310
a function on the elephant that,
uh, that wasn't there before.

366
00:24:58,640 --> 00:25:03,230
Um, in order for it to be
belong to this category, um, uh,

367
00:25:03,260 --> 00:25:07,790
we also, um, impose meaning
on a downturn, mouth,

368
00:25:08,000 --> 00:25:08,840
a scowl.

369
00:25:09,530 --> 00:25:13,790
We impose meaning on that scowl as anger,
right?

370
00:25:13,791 --> 00:25:18,200
So a scowl isn't inherently a
meaningful as anger. In this culture.

371
00:25:18,201 --> 00:25:19,930
We've learned,
um,

372
00:25:20,180 --> 00:25:25,180
to impose that meaning based on our
shared knowledge of anger and in um,

373
00:25:26,150 --> 00:25:28,880
the Trobriand islands, they would
impose a different meaning. Um,

374
00:25:28,910 --> 00:25:33,020
they post impose the
meeting of um, sorry, I've,

375
00:25:33,350 --> 00:25:37,730
they impose a meeting on a different face
for anger, for the stereotype of anger.

376
00:25:37,731 --> 00:25:41,630
It's a wide eyed, um, face,
a wide eyed gasping face.

377
00:25:42,410 --> 00:25:47,410
And this is also what allows us to see
other expressive movements as anger,

378
00:25:47,660 --> 00:25:47,991
right?

379
00:25:47,991 --> 00:25:52,760
So what we're doing is imposing meaning
on a smile or on a stone face stare or

380
00:25:52,761 --> 00:25:57,740
on a cry as anger in a particular
situation. It transforms,

381
00:25:57,741 --> 00:26:01,910
mirror physical movements into
something much more meaningful,

382
00:26:01,940 --> 00:26:05,210
which allows us to predict
what's going to happen next.

383
00:26:06,020 --> 00:26:11,020
So if you want a machine to
perceive emotions in a human,

384
00:26:14,000 --> 00:26:18,860
then it has to learn to
construct categories on the fly.

385
00:26:19,550 --> 00:26:22,280
Perceiving emotions is
not a clustering problem.

386
00:26:22,281 --> 00:26:27,281
It's a category construction problem and
it's a category construction problem.

387
00:26:27,561 --> 00:26:32,240
Whether you're measuring facial movements
or bodily movements or the acoustics

388
00:26:32,270 --> 00:26:33,680
of someone's voice,

389
00:26:33,890 --> 00:26:38,810
or whether you're measuring the changes
in their autonomic nervous system or

390
00:26:38,840 --> 00:26:42,950
even in the neural activity of the
brain or even all of those, right?

391
00:26:42,990 --> 00:26:47,990
All of these things are physical changes
that aren't inherently meaningful as

392
00:26:49,070 --> 00:26:54,030
um, emotions. Someone or something
has to impose meaning on them,

393
00:26:54,560 --> 00:26:56,730
um, to make them meaningful, right?

394
00:26:56,731 --> 00:26:59,940
So an increase in heart
rate is not inherently fear,

395
00:27:00,490 --> 00:27:03,600
but it can become fear when it is,
um,

396
00:27:03,840 --> 00:27:08,370
it's pressed into service to serve a
particular function in a particular

397
00:27:08,371 --> 00:27:09,204
situation.

398
00:27:10,890 --> 00:27:13,920
So emotions are not built
into your brain from birth.

399
00:27:13,950 --> 00:27:17,820
They are just built as as you need them.

400
00:27:18,810 --> 00:27:22,860
And this is really hard to understand
intuitively since you know,

401
00:27:22,861 --> 00:27:27,360
your brain categorizes very automatically
and very effortlessly without your

402
00:27:27,361 --> 00:27:28,200
awareness.

403
00:27:28,860 --> 00:27:33,860
And so we need special examples to kind
of reveal to us what our brains are

404
00:27:35,611 --> 00:27:37,010
doing,
um,

405
00:27:37,470 --> 00:27:41,470
kind of categorizing very continuously,
um,

406
00:27:41,670 --> 00:27:45,140
and effortlessly. And so, um,

407
00:27:45,240 --> 00:27:47,910
what I'd like you to do right now is
we're going to go through one of these

408
00:27:47,911 --> 00:27:50,970
examples so I can, um, I
can explain it to you. So

409
00:27:52,760 --> 00:27:56,570
here's a bunch of black and white blobs.
Um,

410
00:27:57,320 --> 00:28:00,320
tell me what you see. Sorry, person,

411
00:28:01,400 --> 00:28:02,750
person kicking a soccer ball.

412
00:28:04,860 --> 00:28:05,420
Yeah,

413
00:28:05,420 --> 00:28:08,890
an octopus.
One I'd octopus.

414
00:28:14,060 --> 00:28:17,930
Okay. So, um,

415
00:28:18,950 --> 00:28:23,950
right now what's happening in each of
your brains is that billions of your

416
00:28:24,741 --> 00:28:28,790
neurons are working together to try
to make sense of this so that you see

417
00:28:28,791 --> 00:28:31,010
something other than
black and white blobs.

418
00:28:31,670 --> 00:28:35,510
And what your brain is actually doing
is it's searching through a lifetime of

419
00:28:35,511 --> 00:28:40,160
past experience, issuing thousands
of guesses at the same time,

420
00:28:40,370 --> 00:28:44,810
weighing the probabilities, trying to
answer the question, what is this like?

421
00:28:44,840 --> 00:28:47,270
Not what is this,
but what is this like,

422
00:28:47,990 --> 00:28:52,670
how similar is this to um,
past experiences?

423
00:28:53,030 --> 00:28:55,640
And this is all happening
in the blink of an eye.

424
00:28:56,870 --> 00:28:57,140
Okay?

425
00:28:57,140 --> 00:29:01,100
Now, if you are seeing
merely black and white blobs,

426
00:29:01,160 --> 00:29:05,090
then your brain hasn't found a good match
and you're in a state that scientists

427
00:29:05,091 --> 00:29:07,190
call experiential blindness.

428
00:29:08,890 --> 00:29:12,490
So now I'm going to cure you
of your experiential blindness.

429
00:29:12,600 --> 00:29:15,040
This is always my
favorite part of any talk.

430
00:29:20,530 --> 00:29:21,363
Should I do that again?

431
00:29:24,690 --> 00:29:25,523
Yeah.

432
00:29:25,720 --> 00:29:30,720
Now many of you see a B and the reason
why is that now as your brain is

433
00:29:31,811 --> 00:29:33,490
searching through past experiences,

434
00:29:33,491 --> 00:29:36,970
there's new knowledge there from the
coat color photograph that you just saw.

435
00:29:37,180 --> 00:29:41,860
And the really cool thing is that
what you just saw a moment two ago,

436
00:29:42,140 --> 00:29:42,400
um,

437
00:29:42,400 --> 00:29:47,400
that knowledge is actually changing how
you experience these blobs right now.

438
00:29:48,880 --> 00:29:53,880
So your brain is now categorizing this
visual input as a member of the category

439
00:29:55,271 --> 00:29:57,370
B.
And as a result,

440
00:29:57,610 --> 00:30:01,510
your brain is filling in lines
where there are no lines.

441
00:30:01,511 --> 00:30:06,511
It's actually changing the firing of its
own neurons so that you see a B where

442
00:30:06,851 --> 00:30:08,860
there is actually no be present.

443
00:30:09,430 --> 00:30:14,080
This kind of category induced
hallucination is pretty
much business as usual for

444
00:30:14,081 --> 00:30:14,561
your brain.

445
00:30:14,561 --> 00:30:18,520
This is just how your brain works and
your brain also constructs emotions in

446
00:30:18,521 --> 00:30:21,760
exactly this way.
And here's why.

447
00:30:22,600 --> 00:30:23,740
Here's why it happens.

448
00:30:23,741 --> 00:30:28,741
Because your brain is actually in tuned
in a dark silent box called your skull.

449
00:30:31,510 --> 00:30:36,510
And it has to learn what is going
on around in the world by scraps of

450
00:30:36,581 --> 00:30:41,170
information that it gets through
the sensory channels of the body.

451
00:30:42,730 --> 00:30:47,730
Now the brain is trying to figure out
the causes of these sensations so that it

452
00:30:48,701 --> 00:30:52,810
understands what they mean and it knows
what to do about them to keep you alive

453
00:30:52,811 --> 00:30:53,644
and well.

454
00:30:53,650 --> 00:30:57,160
And the problem is that the sensory
information from the world is noisy,

455
00:30:57,161 --> 00:31:01,390
ambiguous. It's often incomplete.
Like we saw with the blobby B example.

456
00:31:01,900 --> 00:31:06,900
And any given sensory input like a
flash of light can have many different

457
00:31:07,301 --> 00:31:11,440
causes.
So your brain is,

458
00:31:11,441 --> 00:31:16,441
has this dilemma and it doesn't just
have this dilemma based on sensory inputs

459
00:31:17,411 --> 00:31:21,630
from the world. It also has
this dilemma to solve, um, uh,

460
00:31:21,760 --> 00:31:26,320
regarding the sensory inputs
from your body. Um, so,

461
00:31:26,680 --> 00:31:30,460
uh, there are sensations
that come from your body,

462
00:31:30,461 --> 00:31:35,080
like your lungs expanding and
contracting and your heart beating. And,

463
00:31:35,380 --> 00:31:35,800
um,

464
00:31:35,800 --> 00:31:40,720
there are sensations from moving your
muscles and from metabolizing glucose and

465
00:31:40,721 --> 00:31:44,830
so on and so forth. And, um, the, um,

466
00:31:44,920 --> 00:31:46,240
the same,
uh,

467
00:31:46,300 --> 00:31:51,300
kind of problem that we faced with having
to make sense of information from the

468
00:31:51,851 --> 00:31:55,690
world. We also face from having
to make sense of our own bodies,

469
00:31:55,691 --> 00:31:59,770
which are largely a mystery to
the brain or more or less. Um,

470
00:31:59,771 --> 00:32:02,430
so an ache in your gut for example,
um,

471
00:32:02,530 --> 00:32:06,280
could be experienced as hunger if
you were sitting at a dinner table.

472
00:32:06,400 --> 00:32:11,380
But if you were in a doctor's office
waiting for test results, you, that gut,

473
00:32:11,650 --> 00:32:14,650
that ache in your gut would
be experienced as anxiety.

474
00:32:14,800 --> 00:32:17,350
And if you were a judge in a courtroom,

475
00:32:17,530 --> 00:32:22,530
that ache would be experienced as
a gut feeling that the defendant,

476
00:32:23,090 --> 00:32:24,910
um,
can't be trusted.

477
00:32:25,570 --> 00:32:30,070
So your brain is basically constantly
trying to solve a reverse inference

478
00:32:30,071 --> 00:32:35,071
problem because it has to determine
the causes of sensations when all it

479
00:32:35,261 --> 00:32:37,900
actually has access to or the effects.

480
00:32:39,350 --> 00:32:44,120
And so how does it do this?
How does the brain resolve this,

481
00:32:44,540 --> 00:32:46,400
this reverse inference problem?

482
00:32:46,700 --> 00:32:50,690
And the answer is by remembering past
experiences that are similar in some way.

483
00:32:53,430 --> 00:32:58,430
So it's remembering past experiences
where physical changes in the world and in

484
00:33:00,751 --> 00:33:05,130
the body are functionally similar
to the present conditions.

485
00:33:06,390 --> 00:33:07,060
Okay.

486
00:33:07,060 --> 00:33:09,940
Similar,
it's creating

487
00:33:11,490 --> 00:33:12,900
basically categories.

488
00:33:15,700 --> 00:33:20,700
So your brain is using past experience
to create ad hoc categories,

489
00:33:22,600 --> 00:33:27,600
to make sense of sensory inputs so that
it knows what they are and what to do

490
00:33:29,831 --> 00:33:30,664
about them.

491
00:33:31,630 --> 00:33:36,630
And these categories represent the causal
relationships between the events in

492
00:33:36,761 --> 00:33:40,360
the world and in the body
and the consequences,

493
00:33:40,420 --> 00:33:42,280
which is what the brain actually detects.

494
00:33:43,060 --> 00:33:46,150
And this is actually how
your brain is wired to work.

495
00:33:46,600 --> 00:33:50,540
It's wired to work this way.
It's metabolically efficient
to work this way. Um,

496
00:33:50,740 --> 00:33:54,160
and this is how your brain constructs
all of your experiences and guides all of

497
00:33:54,161 --> 00:33:54,994
your actions.

498
00:33:55,810 --> 00:33:59,530
Your brain begins with the initial
conditions in the body and in the world.

499
00:33:59,531 --> 00:34:04,531
And then it predicts forward in time
predicting what's about to happen next by

500
00:34:05,321 --> 00:34:10,321
creating categories that are candidates
to make sense of incoming sensory inputs

501
00:34:12,640 --> 00:34:15,520
to make them meaningful so that
your brain knows what to do next.

502
00:34:15,760 --> 00:34:19,600
And the information from the world and
from the body either confirms those

503
00:34:19,601 --> 00:34:22,670
categories or it, um, it, uh,

504
00:34:22,780 --> 00:34:25,030
prompts the brain to um,
to,

505
00:34:25,170 --> 00:34:28,850
to learn something and
try again at updates. Um,

506
00:34:28,970 --> 00:34:31,990
and then the brain makes another
attempt at categorization.

507
00:34:33,370 --> 00:34:37,360
So emotions are not,
you know,

508
00:34:37,361 --> 00:34:41,350
reactions to the world. They are
actually your constructions of the world.

509
00:34:41,560 --> 00:34:44,170
It's not like something happens in the
world and then you react to it with an

510
00:34:44,171 --> 00:34:45,280
emotion.
In fact,

511
00:34:45,281 --> 00:34:50,281
what's happening is that your brain is
constructing an experience and an an

512
00:34:51,371 --> 00:34:54,520
episode or an event, um, where it's,

513
00:34:54,730 --> 00:34:59,730
what it's trying to do is make sense of
or categorize what is going on inside

514
00:34:59,891 --> 00:35:04,180
your own body, like an ache in relation
to what's happening in the world.

515
00:35:04,210 --> 00:35:05,710
Like being in a doctor's office.

516
00:35:06,910 --> 00:35:10,120
So emotions are basically,
um,

517
00:35:10,150 --> 00:35:14,050
brain guesses that are forged by
billions of neurons working together.

518
00:35:17,300 --> 00:35:22,300
And so the emotions that seem to
happen to you are actually made by you.

519
00:35:27,650 --> 00:35:32,270
And categorization is also how your
brain allows you to see emotions in other

520
00:35:32,271 --> 00:35:33,104
people.

521
00:35:33,680 --> 00:35:38,680
So your brain remembers past experiences
from similar situations to make meaning

522
00:35:39,210 --> 00:35:43,800
of the present. You know, to make
meaning of the rays of an eyebrow or,

523
00:35:43,970 --> 00:35:44,803
um,

524
00:35:44,910 --> 00:35:49,410
the movement of the mouth and so on.

525
00:35:50,100 --> 00:35:52,350
So to perceive emotion in somebody else,

526
00:35:52,351 --> 00:35:57,351
what your brain is actually doing is
it's categorizing that person's facial

527
00:35:57,361 --> 00:36:02,361
movements and their body movements and
the acoustics of their voice and the

528
00:36:02,551 --> 00:36:06,930
surrounding context and actually stuff
that's happening inside their own bodies,

529
00:36:07,950 --> 00:36:10,200
all conditioned on past experience.

530
00:36:11,490 --> 00:36:13,530
So even though when we're
talking to each other,

531
00:36:13,531 --> 00:36:17,490
we're mainly looking at each other's faces
and we're aware of each the movements

532
00:36:17,491 --> 00:36:21,270
of each other's faces and we might
be maybe aware of the tone of voice.

533
00:36:21,660 --> 00:36:21,971
We're now,

534
00:36:21,971 --> 00:36:25,740
our attention is not given to the rest
of the sensory array that the brain has

535
00:36:25,741 --> 00:36:30,120
available, including what's going
on inside your own body. You know,

536
00:36:30,121 --> 00:36:34,020
your body inside your own body is a
context that you carry around with you.

537
00:36:34,021 --> 00:36:35,220
Everywhere you go,

538
00:36:35,370 --> 00:36:40,200
that is involved in every single
action and experience that your brain,

539
00:36:40,360 --> 00:36:43,050
um, creates. Largely,

540
00:36:43,080 --> 00:36:46,170
you are lord and you are
largely unaware of it actually.

541
00:36:47,250 --> 00:36:49,200
And this is how,
um,

542
00:36:49,320 --> 00:36:53,570
a scowl can become anger
or confusion were, uh,

543
00:36:53,670 --> 00:36:56,010
indigestion or even amusement.

544
00:36:56,700 --> 00:37:01,700
So that emotions that you seem to detect
and other people are partly made inside

545
00:37:02,161 --> 00:37:02,994
your own head.

546
00:37:05,270 --> 00:37:08,580
So when one human perceives
emotion and another person,

547
00:37:08,581 --> 00:37:10,980
she is not detecting emotion,

548
00:37:10,981 --> 00:37:15,981
her brain is guessing by creating
categories for emotion in the moment.

549
00:37:18,270 --> 00:37:22,230
And this is how a single physical
feature can take on different emotional

550
00:37:22,231 --> 00:37:26,850
meanings in different contexts.
So for a machine to perceive emotion,

551
00:37:26,851 --> 00:37:30,000
it has to be trained on
more than stereotypes.

552
00:37:30,150 --> 00:37:33,900
It actually has to capture
the full high dimensional,

553
00:37:35,130 --> 00:37:38,100
the high dimensional
detail of the context, um,

554
00:37:38,130 --> 00:37:43,050
not just measuring a face or a face and
a body which is inherently ambiguous

555
00:37:43,051 --> 00:37:45,000
without the context.

556
00:37:45,300 --> 00:37:50,060
So perceiving emotion means learning
to construct categories, um,

557
00:37:50,160 --> 00:37:55,020
using the features from biology, um,
like faces and bodies and brains.

558
00:37:55,050 --> 00:37:57,480
But in a particular context.
And I,

559
00:37:57,481 --> 00:38:00,390
the thing I want to point out here is
that I'm using the context of the word

560
00:38:00,391 --> 00:38:04,410
context pretty liberally here because
context also often includes the,

561
00:38:04,620 --> 00:38:06,720
the actions of other people,
right?

562
00:38:06,720 --> 00:38:11,460
So we are social animals and other
humans make up important parts of our

563
00:38:11,461 --> 00:38:16,350
context, which suggests that when you
want to measure a, when you want to,

564
00:38:16,351 --> 00:38:16,921
I'm sorry,

565
00:38:16,921 --> 00:38:21,921
detect emotion in a person you want to
build AI and you measuring the context,

566
00:38:23,580 --> 00:38:28,410
you might consider also measuring the
physical changes in the people who are

567
00:38:28,411 --> 00:38:32,580
around that person because
that can give you a clue, um,

568
00:38:32,760 --> 00:38:36,910
about uh, about what the physical
changes in the target person really need.

569
00:38:38,440 --> 00:38:41,590
So measuring the features of other people,
um,

570
00:38:41,620 --> 00:38:45,640
that is there physical changes and actions
that are contingent on the biological

571
00:38:45,641 --> 00:38:49,810
changes in the person of interest is uh,
an extension of the con,

572
00:38:50,230 --> 00:38:53,230
the idea of, of um, context
which is really important.

573
00:38:54,760 --> 00:38:55,720
And the last few minutes,

574
00:38:55,721 --> 00:38:59,890
what I'm going to do is switch gears here
and I'm from perceiving emotion to ask

575
00:38:59,891 --> 00:39:03,340
whether it's possible to build machines
who can actually experience emotion

576
00:39:05,170 --> 00:39:06,250
the way that humans do.

577
00:39:07,690 --> 00:39:11,590
And this is a question I think that
interest AI people who work in AI often

578
00:39:11,591 --> 00:39:14,140
because they are interested in,
in questions about empathy.

579
00:39:15,470 --> 00:39:19,870
And so if emotions are made by
categorizing sensations from the body,

580
00:39:20,860 --> 00:39:23,500
um,
and from the surrounding context,

581
00:39:23,530 --> 00:39:28,530
using past experience than machines would
need all three of these ingredients or

582
00:39:29,051 --> 00:39:32,860
something like them. And so we're
gonna just take this really quickly,

583
00:39:32,861 --> 00:39:35,620
one at a time.
So the first this past experience,

584
00:39:35,980 --> 00:39:38,830
can machines actually recall
past experience? Well,

585
00:39:38,950 --> 00:39:43,240
machines are really great at storage
and retrieval. Unfortunately,

586
00:39:43,300 --> 00:39:45,580
brains don't work like a file system.

587
00:39:45,670 --> 00:39:49,270
Memories aren't retrieved like files.
They are.

588
00:39:49,300 --> 00:39:51,850
Memories are dynamically
constructed in the moment.

589
00:39:52,210 --> 00:39:56,860
And brains have this amazing capacity to
kind of combine bits and pieces of the

590
00:39:56,861 --> 00:40:01,630
past in novel ways. Their brains
are generative. They are, um,

591
00:40:01,690 --> 00:40:05,200
information, uh, gaining structures.

592
00:40:05,440 --> 00:40:09,910
They can create new content,
not just merely reinstate old content,

593
00:40:10,180 --> 00:40:13,540
which is necessary for
constructing categories on the fly.

594
00:40:14,950 --> 00:40:19,000
To my knowledge, and maybe you
know, which might be out of day,

595
00:40:19,001 --> 00:40:19,930
but to my knowledge,

596
00:40:19,960 --> 00:40:24,910
there are no computing systems that are
powered by dynamic categorization that

597
00:40:24,911 --> 00:40:29,680
can create abstract categories by grouping
things together that are physically

598
00:40:29,710 --> 00:40:32,040
dissimilar. But because they, um,

599
00:40:32,080 --> 00:40:35,740
they are all in that particular
situation serving a similar function.

600
00:40:36,610 --> 00:40:40,550
So an important challenge for computers,
um,

601
00:40:40,780 --> 00:40:42,610
to experience emotion is to,

602
00:40:42,760 --> 00:40:46,420
to be able to develop a computing
systems that have that capability.

603
00:40:47,350 --> 00:40:49,660
The second ingredient is context.

604
00:40:50,050 --> 00:40:54,460
So computers are getting better and
better at sensing the world. Um,

605
00:40:54,850 --> 00:40:57,680
though there are advances
in computer vision and um,

606
00:40:57,950 --> 00:41:00,970
in speech recognition
and so on, um, but uh,

607
00:41:00,971 --> 00:41:04,840
system doesn't just have to
detect information in the world.

608
00:41:04,841 --> 00:41:09,841
It also has to decide which information
is relevant and which information is

609
00:41:10,451 --> 00:41:14,800
not. Right. This is the signal
versus noise problem. Um,

610
00:41:14,980 --> 00:41:17,650
and uh,
this is what scientists call value.

611
00:41:18,190 --> 00:41:22,480
So value is not something
that's detectable in the world.

612
00:41:22,510 --> 00:41:26,710
Value is not a property of, um, uh,

613
00:41:26,890 --> 00:41:30,850
sights and sounds and so on or the
information that creates sights and sounds

614
00:41:30,851 --> 00:41:32,590
and so on from the world.
Um,

615
00:41:32,660 --> 00:41:37,660
value is a function of that information
in relation to the state of the organism

616
00:41:38,361 --> 00:41:40,250
or the system that's doing the sensing.

617
00:41:40,490 --> 00:41:43,250
So if there's a blurry
shape in the distance,

618
00:41:43,550 --> 00:41:48,260
does it have value for you
as food or can you ignore it?

619
00:41:48,380 --> 00:41:50,960
Well,
partly that depends on what the shape is,

620
00:41:50,961 --> 00:41:54,260
but it also depends on when you last ate.

621
00:41:54,650 --> 00:41:56,680
And even more importantly,
uh,

622
00:41:56,990 --> 00:42:00,590
the value also depends on whether
or not that shape wants to eat you.

623
00:42:01,130 --> 00:42:04,560
And so to solve this problem,
it turns out that, you know, um,

624
00:42:04,670 --> 00:42:08,870
the brain didn't start off Britain.
If you look at brain evolution,

625
00:42:08,871 --> 00:42:13,871
it didn't start off with systems that
allow creatures to compute value.

626
00:42:14,570 --> 00:42:19,570
Those evolved in concert with sensory
systems in concert with the ability to see

627
00:42:20,061 --> 00:42:24,020
and hear and so on. Um,
for exactly this reason.

628
00:42:24,650 --> 00:42:25,483
Um,

629
00:42:25,760 --> 00:42:30,760
and so the evolution basically gave us
brain circuitry that allows us to compute

630
00:42:32,571 --> 00:42:37,460
value, which also gives us our mood
or what scientists call an effect,

631
00:42:37,490 --> 00:42:40,850
which are simple feelings of feeling
pleasant, feeling unpleasant,

632
00:42:40,851 --> 00:42:45,770
feeling worked up, feeling calm,
um, affect or mood is not emotion.

633
00:42:46,160 --> 00:42:50,690
It's just a quick summary of the state
of what's going on inside your own body.

634
00:42:50,810 --> 00:42:55,160
Like a barometer and aspect is a signal
that something is relevant to your body

635
00:42:55,161 --> 00:42:58,670
or not. Whether that thing
has value to you or not.

636
00:42:58,850 --> 00:43:00,590
And so for a machine
to experience emotion,

637
00:43:00,591 --> 00:43:05,480
it also needs something that allows it
to estimate the value of things in the

638
00:43:05,481 --> 00:43:08,570
world in relation to a body,

639
00:43:09,350 --> 00:43:12,780
which brings us to the third ingredient.
Um,

640
00:43:13,010 --> 00:43:18,010
brains evolved for the purposes of
controlling and balancing the systems of a

641
00:43:18,801 --> 00:43:19,634
body.

642
00:43:19,940 --> 00:43:24,110
Brains didn't evolve so that we could
see really well or here really well or

643
00:43:24,111 --> 00:43:28,670
feel anything. They evolved
to control the body, um, to,

644
00:43:28,820 --> 00:43:31,700
to keep, uh, the systems
of the body in balance.

645
00:43:31,701 --> 00:43:36,140
And the bigger the body gets with the
more systems, the bigger the brain gets.

646
00:43:37,080 --> 00:43:37,850
Um,

647
00:43:37,850 --> 00:43:42,740
so a disembodied brain has
no bodily systems to balance.

648
00:43:42,741 --> 00:43:45,140
It has no bodily sensations
to make sense of.

649
00:43:45,170 --> 00:43:48,590
It has no effect to a signal value.

650
00:43:48,740 --> 00:43:52,400
So a disembodied brain would
not experience emotion,

651
00:43:53,210 --> 00:43:57,410
which means that for a machine to
experience emotion like a human does,

652
00:43:57,470 --> 00:44:00,890
it needs a body or something like a body,

653
00:44:01,850 --> 00:44:06,110
a collection of systems that it has to
keep in balance with sensations that it

654
00:44:06,111 --> 00:44:10,700
has to explain. And to me, I think
this is the most surprising insight,

655
00:44:11,140 --> 00:44:13,430
um,
about AI and emotion.

656
00:44:13,580 --> 00:44:18,580
I'm not saying that a machine has to
have an actual flesh and blood body to

657
00:44:19,191 --> 00:44:23,930
experience emotions, but I am suggesting
that it needs something like a body.

658
00:44:24,470 --> 00:44:25,281
And,
um,

659
00:44:25,281 --> 00:44:29,720
I have a deep belief that there are
clever engineers who can come up with

660
00:44:29,721 --> 00:44:32,190
something that is enough like a body,
um,

661
00:44:32,370 --> 00:44:37,020
to provide this necessary ingredient
for emotion. Now these ideas, uh,

662
00:44:37,021 --> 00:44:40,600
and others, uh, the science
behind them, um, and,

663
00:44:40,640 --> 00:44:43,860
and related ideas can be found in my book.
How emotions are made,

664
00:44:43,861 --> 00:44:46,200
the secret life of the brain.
Um,

665
00:44:47,370 --> 00:44:51,350
and there's also additional
information on my website. And, uh,

666
00:44:51,360 --> 00:44:55,050
even though this is not strictly speaking,
I'm not throwing tons of data at you.

667
00:44:55,051 --> 00:44:59,650
I do. I'm always at the end of
talks like to thank my lab. Um,

668
00:44:59,700 --> 00:45:04,170
really are, they're the ones who
actually do all the really hard work. Um,

669
00:45:04,530 --> 00:45:08,700
uh, you know, scientists like me just get
to stand up here and talk about it. Um,

670
00:45:08,730 --> 00:45:10,800
so, um, uh,

671
00:45:10,830 --> 00:45:14,190
I just want to thank them as well and
thank you for your attention and I'll take

672
00:45:14,191 --> 00:45:14,330
it

673
00:45:14,330 --> 00:45:15,163
questions.

674
00:45:20,270 --> 00:45:25,270
I am wondering how someone who has say
blind from birth will perceive emotion

675
00:45:26,031 --> 00:45:29,780
because they don't, um, they
cannot depend on visual cues,

676
00:45:29,781 --> 00:45:32,270
whether it's facial
expression or body language.

677
00:45:32,540 --> 00:45:36,500
So I'm guessing they
usually go off of, um, um,

678
00:45:36,830 --> 00:45:39,760
vocal tones or lack there off.
Um,

679
00:45:39,920 --> 00:45:44,920
have you looked into their accuracy of
predicting emotions and is that better or

680
00:45:45,351 --> 00:45:48,080
worse than people who rely on visual cues?

681
00:45:48,800 --> 00:45:50,300
So,
um,

682
00:45:50,360 --> 00:45:55,360
people who are born congenitally blind
have no difficulty experiencing emotion

683
00:45:56,120 --> 00:45:59,480
and they have no difficulty perceiving
emotion through the sensory channels that

684
00:45:59,481 --> 00:46:03,620
they have access to because their brains
work largely in the same way that a

685
00:46:03,621 --> 00:46:06,590
sighted person's brain works at birth.

686
00:46:07,040 --> 00:46:11,600
The brain is collecting patterns,
statistical patterns,

687
00:46:11,910 --> 00:46:15,860
um, and so, uh, it's just vision
isn't part of that pattern.

688
00:46:16,220 --> 00:46:19,760
And what's really interesting
actually is that, um,

689
00:46:20,030 --> 00:46:24,680
so for someone who is, is
congenitally blind, um, they, um,

690
00:46:24,710 --> 00:46:28,280
they're learning patterns
that include, you know, uh,

691
00:46:28,760 --> 00:46:33,560
changes in sound pressure that
become hearing changes, um, in,

692
00:46:33,590 --> 00:46:37,730
um, the pressure on the skin, which
becomes touch. Um, they have taste,

693
00:46:37,850 --> 00:46:40,730
they have sensations from the
body which become an effect.

694
00:46:40,910 --> 00:46:43,430
So they can do multimodal
learning just like the rest of us.

695
00:46:43,431 --> 00:46:47,960
And they can learn to
experience and express emotion
and perceive it through the

696
00:46:47,961 --> 00:46:52,790
channels they have access
to. What's really interesting
is that when adults have,

697
00:46:52,791 --> 00:46:57,730
um, let's say who are congenitally
blind because they have cataracts, um,

698
00:46:57,890 --> 00:47:01,820
have those cataracts removed for
the first time, they can see,

699
00:47:03,460 --> 00:47:04,293
yeah.

700
00:47:04,440 --> 00:47:05,730
Or they should be able to see.

701
00:47:06,420 --> 00:47:09,630
But actually it takes them
a while to learn to see.

702
00:47:10,650 --> 00:47:14,850
And when they finally learned to see they,
their experience,

703
00:47:14,851 --> 00:47:17,560
if you talk to these people,
what they say is that they're,

704
00:47:17,570 --> 00:47:22,570
they feel like they're always guessing
what faces mean and what body postures

705
00:47:22,981 --> 00:47:27,060
mean. They find faces
in particular hard. Um,

706
00:47:27,480 --> 00:47:32,230
for example, even as I'm one,
there's one person, um, Michael May,

707
00:47:32,231 --> 00:47:36,140
who's been studied really extensively
over a number of years and even a couple

708
00:47:36,140 --> 00:47:41,080
of years, years after his cataracts were
replaced, um, is corneal, uh, sorry,

709
00:47:41,081 --> 00:47:44,770
he had corneal abrasions that a,
so as cornea were replaced, um,

710
00:47:45,010 --> 00:47:47,020
he was still guessing,

711
00:47:47,021 --> 00:47:52,021
consciously guessing at whether a face
was male or female before someone spoke.

712
00:47:52,150 --> 00:47:53,770
He just couldn't,
it was really hard for him to do.

713
00:47:54,190 --> 00:47:59,190
And he experienced his vision as
separate from everything else,

714
00:48:00,641 --> 00:48:05,020
like us, like a second language that
he was learning to, to speak, um,

715
00:48:05,290 --> 00:48:08,530
which had no effect to
it. Right. So, um, so,

716
00:48:08,630 --> 00:48:12,280
but the answer to your question
is, um, so you critique it,

717
00:48:12,281 --> 00:48:15,460
ask a bunch of questions, like, so do
blind people who are congenitally blind,

718
00:48:15,610 --> 00:48:18,400
do they actually make facial expressions,
you know,

719
00:48:18,401 --> 00:48:23,050
the way that a sighted person
does and the answer is, um, they,

720
00:48:23,051 --> 00:48:25,360
uh,
their facial movement,

721
00:48:25,361 --> 00:48:29,530
they don't make the stereotypic
expressions when they're angry or sad or

722
00:48:29,531 --> 00:48:30,250
whatever,

723
00:48:30,250 --> 00:48:35,250
but they do learn to make sur deliberate
movements in a particular way.

724
00:48:36,580 --> 00:48:41,200
Um, for example, um, when they are, there
are these studies showing that when,

725
00:48:41,230 --> 00:48:46,120
um, congenitally blind athletes
win an award and they, uh,

726
00:48:46,210 --> 00:48:48,780
they know they're being filmed,
um,

727
00:48:49,120 --> 00:48:53,980
they will make a body movements
that indicate being really thrilled.

728
00:48:54,310 --> 00:48:58,600
Um, uh, what they don't, but they're doing
it because they've learned it in the,

729
00:48:58,601 --> 00:49:03,601
in the same way that if you
test a congenitally blind
person on the meaning of

730
00:49:04,151 --> 00:49:05,050
color words,

731
00:49:05,170 --> 00:49:09,160
they're mapping of color words largely
as the same as a sighted person because

732
00:49:09,161 --> 00:49:09,730
they've stuttered.

733
00:49:09,730 --> 00:49:13,330
They've learned from the statistical
regularities in language which words are

734
00:49:13,331 --> 00:49:16,780
more similar to each other and which
ones aren't. So their abilities,

735
00:49:16,781 --> 00:49:21,340
that emotion perception and emotion
expression largely look the same as a

736
00:49:21,341 --> 00:49:23,560
sighted person's in what without the,

737
00:49:23,590 --> 00:49:27,250
without the visual component was really
interesting is that people who are

738
00:49:27,251 --> 00:49:30,970
congenitally deaf, who don't, who,

739
00:49:31,030 --> 00:49:35,260
who tend to learn mental state language,

740
00:49:35,261 --> 00:49:40,261
they develop concepts for mental states
later also are delayed in their ability

741
00:49:40,841 --> 00:49:44,500
to perceive emotion in
other people. So, um,

742
00:49:44,710 --> 00:49:48,410
that literature suggests
a coupling between, um,

743
00:49:48,500 --> 00:49:53,500
emotion words and the ability to learn
to form emotion categories in childhood.

744
00:49:55,150 --> 00:49:58,940
So, so you said that an essential
component in recognizing an emotion is the

745
00:49:58,941 --> 00:50:03,710
context. I would never say
recognizing, but yeah, yeah. Um,

746
00:50:05,000 --> 00:50:05,480
um,

747
00:50:05,480 --> 00:50:10,480
if we didn't have the context and we could
monitor whatever's happening inside a

748
00:50:13,071 --> 00:50:16,460
person's body and the brain really well,
uh,

749
00:50:16,610 --> 00:50:21,610
would we be able to recognize emotions
and what specifically would it take?

750
00:50:22,761 --> 00:50:24,530
What would we want to monitor?

751
00:50:24,730 --> 00:50:26,440
Yeah, so it's interesting
that you, I mean,

752
00:50:26,470 --> 00:50:28,100
when I was originally thinking
about giving this talk,

753
00:50:28,101 --> 00:50:32,630
I thought I might start with, um,
machine learning, uh, attempts to,

754
00:50:32,660 --> 00:50:37,340
um,
identify emotion with neural activity,

755
00:50:37,341 --> 00:50:41,810
patterns of neural activity. And it
turns out that you can, in a given study,

756
00:50:42,640 --> 00:50:47,510
uh, if you, um, if you
show people films, say,

757
00:50:47,770 --> 00:50:50,930
uh, and you try to evoke
emotions by showing them films,

758
00:50:51,200 --> 00:50:55,730
you can actually build a pattern
classifier that can distinguish, um,

759
00:50:55,970 --> 00:50:59,540
uh, anger from sadness, from fear, um,

760
00:51:00,380 --> 00:51:05,150
meaning you can distinguish when
people are watching films for that.

761
00:51:05,151 --> 00:51:08,090
Will that presumably evoke anger
versus sadness versus fear?

762
00:51:08,390 --> 00:51:12,020
The problem with those studies is that,
uh,

763
00:51:12,110 --> 00:51:16,460
that classify or can't be used in another
study. Like it doesn't generalize,

764
00:51:16,461 --> 00:51:20,730
right? So you're what you're
building is your building, um, uh,

765
00:51:20,890 --> 00:51:25,160
a set of classifiers at work
in a specific context. Um,

766
00:51:25,580 --> 00:51:26,810
but when you generalize,

767
00:51:26,811 --> 00:51:31,160
try to generalize to another
sample of subjects maybe.

768
00:51:31,370 --> 00:51:34,130
Um,
so let me say it this way.

769
00:51:34,131 --> 00:51:38,780
If you have the same subjects
in the same study, watch movies,

770
00:51:38,781 --> 00:51:42,200
and so you've voke anger by watching a
movie and you've voke anger by having

771
00:51:42,201 --> 00:51:46,930
them, let's say, remember a prior
anger episode, um, you get, um,

772
00:51:47,630 --> 00:51:52,340
you can classify the emotions
and distinguished from
one another and you can,

773
00:51:52,341 --> 00:51:57,140
you get a little bit of carry over from
one modality of evoking to another.

774
00:51:57,500 --> 00:51:59,420
But if you go to a
completely separate study,

775
00:52:00,440 --> 00:52:02,150
the patterns look completely different.

776
00:52:03,230 --> 00:52:07,570
And this is true across hundreds of
studies. So reasonable. We developed a,

777
00:52:07,580 --> 00:52:12,290
we have a, I published a
pattern classification paper
where we use 400 studies,

778
00:52:12,610 --> 00:52:13,443
um,
uh,

779
00:52:13,520 --> 00:52:17,630
and we developed these classifiers based
on this metta analytic database that,

780
00:52:17,631 --> 00:52:21,770
that those classifiers are not
successful at classifying any new set of

781
00:52:21,771 --> 00:52:25,160
instances. I mean, they show
really good. Um, you know, I mean,

782
00:52:25,161 --> 00:52:28,430
we used a leave one out method.
We used, uh, um, you know,

783
00:52:28,431 --> 00:52:30,200
multivariate Basie and
a me, you know, there,

784
00:52:30,201 --> 00:52:33,300
there are no problems with the
statistics. The issue is that, um,

785
00:52:33,950 --> 00:52:37,960
when scientists do this, they believe
that what they're discovering, um,

786
00:52:38,060 --> 00:52:41,480
in these patterns is actually a
literal brain state for the motion,

787
00:52:41,481 --> 00:52:42,950
the literal brain state for anger.

788
00:52:42,951 --> 00:52:46,730
And then they think it should generalize
to sell to every brains to every

789
00:52:46,731 --> 00:52:47,840
instance of anger.

790
00:52:48,170 --> 00:52:52,670
And they don't generalize usually
outside of their own studies. Um,

791
00:52:53,270 --> 00:52:56,510
this is also true for
physiology. Um, where it,

792
00:52:56,511 --> 00:53:01,400
so we just published a Meta analysis where
we examined the physiological changes

793
00:53:01,401 --> 00:53:05,260
in people's bodies, like their
heart rate changes or breathing, um,

794
00:53:05,380 --> 00:53:08,070
their skin conductance and so on. And, um,

795
00:53:08,270 --> 00:53:13,270
you see that these physical measures
can distinguish one emotion,

796
00:53:13,520 --> 00:53:17,180
sometimes one emotion category
from another in a study,

797
00:53:17,181 --> 00:53:19,430
but they don't generalize across studies.
And in fact,

798
00:53:19,431 --> 00:53:23,630
the patterns themselves really
changed from study to study. Um,

799
00:53:23,690 --> 00:53:27,510
and so there's, uh, when you look
at it in a Meta analytic sense,

800
00:53:27,530 --> 00:53:31,230
it looks like all in all for all emotions,

801
00:53:31,231 --> 00:53:34,410
heart rates would go up or go down or
stay the same depending on what the

802
00:53:34,411 --> 00:53:35,340
situation is.

803
00:53:36,480 --> 00:53:41,130
So there's so far no one has
done a really high dimensional.

804
00:53:41,400 --> 00:53:44,190
Nobody's made a really high
dimensional attempt at this.

805
00:53:44,230 --> 00:53:48,630
Meaning they haven't tried to measure the
brain and measure the body and measure

806
00:53:48,631 --> 00:53:52,070
the face and measure
aspects of the context. Um,

807
00:53:52,620 --> 00:53:54,480
that's actually what I
think needs to be done.

808
00:53:54,481 --> 00:53:56,040
So I think this is a solvable problem.

809
00:53:56,041 --> 00:53:59,450
I just think we have not been going
about it in the right way. Um,

810
00:53:59,490 --> 00:54:03,720
and I think that this is a
real opportunity, uh, for, um,

811
00:54:04,600 --> 00:54:05,090
okay

812
00:54:05,090 --> 00:54:08,180
for any company that is
serious about doing this.

813
00:54:08,840 --> 00:54:13,270
I love the way you mentioned in the
book that, and then the talk as well,

814
00:54:13,360 --> 00:54:15,910
how we perceive emotions based on context.

815
00:54:16,720 --> 00:54:19,600
So we look at the context
and then we for emotion.

816
00:54:19,601 --> 00:54:21,420
And one of the examples that
you have in the book and,

817
00:54:21,421 --> 00:54:26,421
and you have here as well was a Serena
Williams winning a grand slam and you

818
00:54:26,921 --> 00:54:29,340
have her here,
you have the versions.

819
00:54:29,640 --> 00:54:32,840
Why I switched it out because
people were starting to say, oh,

820
00:54:32,841 --> 00:54:35,540
that's Serena Williams. I'm like,
okay, well that's right. Yeah.

821
00:54:35,770 --> 00:54:39,040
So, but there's something that is
troubling to me at least in that,

822
00:54:39,220 --> 00:54:40,790
in that example.
Um,

823
00:54:41,440 --> 00:54:44,650
well I think that's, that's certainly
possible. And what I would say,

824
00:54:44,710 --> 00:54:47,790
what I would say to that
though is, um, that um,

825
00:54:47,860 --> 00:54:51,270
there are studies particularly
by a Hillel Fvs are,

826
00:54:51,280 --> 00:54:53,950
who's actually done work
with you? No, he didn't.

827
00:54:54,220 --> 00:54:58,000
I published the picture of
Serena Williams and I'm 2007.

828
00:54:58,240 --> 00:55:01,120
I published that example and um,
hello,

829
00:55:01,121 --> 00:55:05,450
came out with a great set of experiments
in 2008 and then again in 2012 and he

830
00:55:05,620 --> 00:55:10,620
proceeded to continue where he
knows he has the reports of people,

831
00:55:12,820 --> 00:55:17,110
people's subjective experience
and he has their facial movements.

832
00:55:17,410 --> 00:55:21,550
Um, and in fact there are
Meta analyses which, uh,

833
00:55:21,580 --> 00:55:25,510
have the subjective reports of people
and their facial movements and in

834
00:55:25,511 --> 00:55:29,930
sometimes also the reports of people
interacting with the people whose faces,

835
00:55:30,020 --> 00:55:33,340
but, and there is um, no evidence

836
00:55:33,410 --> 00:55:38,400
that, um, that the, that,

837
00:55:38,760 --> 00:55:39,950
that the

838
00:55:40,570 --> 00:55:45,490
variability is due to a series of
quick emotions being evoked over time.

839
00:55:45,880 --> 00:55:49,930
So what, you know, but I want to
back up one step and say this when,

840
00:55:50,230 --> 00:55:51,910
when you asked the question,
um,

841
00:55:52,450 --> 00:55:56,290
well maybe Serena Williams
is really experiencing,

842
00:55:56,320 --> 00:56:00,040
maybe she really is in a state of anger
in that moment or in that case it's

843
00:56:00,041 --> 00:56:03,260
actually looks like fear
more or terror more.

844
00:56:03,740 --> 00:56:05,390
Um,
uh,

845
00:56:06,710 --> 00:56:10,310
when you say really that implies that
there's some objective criteria and that

846
00:56:10,311 --> 00:56:13,700
you could use to measure the state
that Serena Williams has really in.

847
00:56:14,180 --> 00:56:18,200
And there is no objective criteria for
any emotion that's ever been studied ever.

848
00:56:20,070 --> 00:56:20,330
Okay.

849
00:56:20,330 --> 00:56:25,180
So what scientists use is agreement.
They use collective agreement essentially.

850
00:56:25,510 --> 00:56:30,370
So you can ask, does the face,
does it face match her report?

851
00:56:30,520 --> 00:56:35,520
Does the face match somebody else's report
due to people agree on what they see.

852
00:56:37,150 --> 00:56:42,150
So you're using all kinds of
basically a perceiver based agreement,

853
00:56:42,400 --> 00:56:45,180
which is basically consensus,
um,

854
00:56:45,280 --> 00:56:47,560
because no one has found the,

855
00:56:47,920 --> 00:56:51,940
there is no ground truth when it comes
to emotion that anyone has ever found

856
00:56:51,941 --> 00:56:55,480
that replicates from study
to study. Um, and so,

857
00:56:56,350 --> 00:56:57,640
so there's a part of me that wants to say,

858
00:56:57,641 --> 00:57:00,160
I can't even answer your question because
I think it's not even a scientific

859
00:57:00,161 --> 00:57:03,930
question that's answerable, but, but
we can answer it in other ways by see,

860
00:57:04,000 --> 00:57:05,950
by looking at various forms of consensus.

861
00:57:05,951 --> 00:57:09,580
And while I can't say anything about
Serena Williams and what she experienced,

862
00:57:09,790 --> 00:57:13,750
I can say that in other studies it's
very clear that people are scowling.

863
00:57:13,780 --> 00:57:17,080
Absolutely. When they are
not angry. My husband,

864
00:57:17,081 --> 00:57:20,410
this is my husband Dan Barrett
who works for Google. Sorry honey,

865
00:57:20,411 --> 00:57:25,030
I'm going to out you. Um, you know, key
Scott, he gives a full on facial scowl,

866
00:57:25,370 --> 00:57:27,730
uh,
when he's concentrating really hard.

867
00:57:28,060 --> 00:57:31,420
And it was only after I learned that,
that I,

868
00:57:31,421 --> 00:57:34,570
and I was telling my students actually
like, can you believe? And they're like,

869
00:57:34,571 --> 00:57:35,351
can we believe it?

870
00:57:35,351 --> 00:57:38,950
We experience it every time we give a
presentation in front of you. Right?

871
00:57:38,951 --> 00:57:41,260
So I'm sitting there are,
you know,

872
00:57:41,261 --> 00:57:45,340
paying a lot of attention to every
single thing they say and they think,

873
00:57:45,341 --> 00:57:50,020
oh my God, she hates it.
And the whole, uh, you know,

874
00:57:50,021 --> 00:57:54,420
emotional climate and my lab changed
the moment that I realized that. So,

875
00:57:54,740 --> 00:57:56,980
so that, you know, that's an anecdote,

876
00:57:56,981 --> 00:58:00,010
but it's an anecdote that reflects
what is in the literature,

877
00:58:00,490 --> 00:58:04,840
which is that people are making a variety
of fish. I'm not saying it's random,

878
00:58:04,841 --> 00:58:06,370
I'm saying there's a pattern.

879
00:58:06,400 --> 00:58:08,920
There are patterns there that
we haven't really yet detected.

880
00:58:08,921 --> 00:58:13,210
And I think it's in part because we are
measuring individual signals or we think

881
00:58:13,211 --> 00:58:16,900
we're doing really well if we measure
the face and the body or we measure the

882
00:58:16,901 --> 00:58:21,490
face and acoustics or measure the face
and something about, you know, uh,

883
00:58:21,610 --> 00:58:23,030
maybe heart rate that we pick,

884
00:58:23,380 --> 00:58:27,100
we pick up two channels instead of
doing something really high dimensional.

885
00:58:27,101 --> 00:58:31,680
I'm not saying there's no meaning there.
If there was, if that were true, we,

886
00:58:31,690 --> 00:58:32,020
you know,

887
00:58:32,020 --> 00:58:35,980
you and I couldn't have a conversation
right now I'm saying that it's probably

888
00:58:35,981 --> 00:58:40,981
something high dimensional and it might
be quite idiographic meaning there could

889
00:58:41,771 --> 00:58:46,540
be different, different brains
may be have the capacity to do um,

890
00:58:46,870 --> 00:58:51,700
a different number of categories to
make different number of categories.

891
00:58:51,910 --> 00:58:54,940
And um, that's also something
I discuss in my book actually.

892
00:58:55,190 --> 00:58:57,340
So when you listed all the,
uh,

893
00:58:57,440 --> 00:59:02,390
the sort of pre qualifications for maybe
emotion forming, um, I was thinking, um,

894
00:59:02,391 --> 00:59:05,690
you know, a lot of vegetarians say,
oh, you know, all animals have feeling,

895
00:59:05,691 --> 00:59:09,140
have this ability to,
to emote and to feel emotion.

896
00:59:09,410 --> 00:59:13,140
And a lot of mediators are
like, no, no, no, no, no, no,
that's impossible. They don't.

897
00:59:13,330 --> 00:59:17,240
Um, do you have any opinion? Yeah,
here's my opinion. I think that, um,

898
00:59:18,380 --> 00:59:22,880
I think everybody has to stop
calling affect like many, many,

899
00:59:22,881 --> 00:59:26,390
many problems disappear.
They just completely dissolve.

900
00:59:26,391 --> 00:59:31,340
When we understand that every
waking moment of our lives,

901
00:59:31,970 --> 00:59:35,450
there's stuff going on inside
our bodies and we can't,

902
00:59:35,510 --> 00:59:39,470
we don't have access to the small,

903
00:59:39,660 --> 00:59:44,330
every little small change in our
bodies that gives that sense sensory

904
00:59:44,331 --> 00:59:47,030
information to the brain.
If we did,

905
00:59:47,330 --> 00:59:50,450
we would never pay attention to anything
outside our own skins ever again.

906
00:59:51,290 --> 00:59:53,840
So instead,
evolution has given us an effect.

907
00:59:54,620 --> 00:59:58,820
So we sense what's going on inside
our own bodies by feeling pleasant or

908
00:59:58,821 --> 01:00:01,310
unpleasant feeling worked
up or feeling kind of calm,

909
01:00:01,311 --> 01:00:04,490
feeling comfortable or uncomfortable.
That's not emotion,

910
01:00:04,640 --> 01:00:09,640
that's an affect or mood that's with us
always every waking moment of your life

911
01:00:10,431 --> 01:00:12,080
you have some effect,

912
01:00:12,081 --> 01:00:16,100
there are some aspect of features to
your experience and it's very likely also

913
01:00:16,101 --> 01:00:19,820
true of of nonhuman
animals. Um, I, you know,

914
01:00:19,821 --> 01:00:23,960
I can say this circuitry is,
is,

915
01:00:24,050 --> 01:00:28,520
is very similar, similar enough that
I think you could go down all the way,

916
01:00:28,730 --> 01:00:30,530
uh, to, um,

917
01:00:31,190 --> 01:00:34,610
certainly all vertebrates and I
would even guess that there are some

918
01:00:34,611 --> 01:00:37,910
invertebrates, um, actually maybe
all invertebrates, I don't know,

919
01:00:38,030 --> 01:00:41,750
even insects potentially
could actually have an effect,

920
01:00:41,751 --> 01:00:42,800
although I think that's drawing.

921
01:00:42,890 --> 01:00:45,330
I mean I might draw the line at
like flies or something, but,

922
01:00:45,360 --> 01:00:48,890
but recently there was a study that came
out that suggested maybe they do have

923
01:00:48,891 --> 01:00:52,610
ethics. So in my feeling about
this is I guess two fold.

924
01:00:52,611 --> 01:00:57,611
One is I think we have to stop conflating
an affect and emotion aspect is with

925
01:00:57,891 --> 01:01:02,090
you always, even when you, you
experience yourself as being rational,

926
01:01:02,180 --> 01:01:06,290
even when you experience yourself as
just thinking or just remembering,

927
01:01:07,010 --> 01:01:09,650
it's just that one aspect is super strong.

928
01:01:10,100 --> 01:01:12,230
Our brains explain it as emotion.

929
01:01:12,590 --> 01:01:15,920
Once we make that distinction and
we understand that distinction,

930
01:01:15,921 --> 01:01:18,380
that emotions and an effect maybe effect,

931
01:01:18,381 --> 01:01:21,290
you could think of it
as a feature of emotion.

932
01:01:21,291 --> 01:01:23,450
It's actually a feature of consciousness.

933
01:01:24,050 --> 01:01:27,350
Then I think we can
say without hesitation,

934
01:01:28,610 --> 01:01:32,870
we don't know for sure whether
nonhuman animals, uh, feel an effect.

935
01:01:33,290 --> 01:01:38,220
Um, but they probably do and we should
probably treat them as if they do. Um,

936
01:01:38,440 --> 01:01:42,530
that that solves a lot of problems.
It actually doesn't matter really. Um,

937
01:01:42,710 --> 01:01:47,030
from a moral standpoint,
whether an animal feels emotion,

938
01:01:47,180 --> 01:01:51,200
it matters whether they can feel pleasure
and pain. That's enough. Actually,

939
01:01:51,710 --> 01:01:55,100
it's an interesting scientific
question whether or not they can,

940
01:01:55,130 --> 01:01:57,200
they can see their brains
can create emotion.

941
01:01:57,290 --> 01:01:59,000
That's a whole different conversation.

942
01:01:59,001 --> 01:02:01,820
But I think the answer to your
question isn't really about emotion.

943
01:02:01,821 --> 01:02:06,060
It's about an effect. And I think
there, it's really obvious that, um,

944
01:02:06,320 --> 01:02:09,440
if you're going to the smart thing to do,

945
01:02:09,620 --> 01:02:13,790
you just want to do things where you
do the least amount of damage if you're

946
01:02:13,791 --> 01:02:18,650
wrong. Right. And so that means
including animals in our moral,

947
01:02:18,900 --> 01:02:21,000
um, circle, right. They can feel,

948
01:02:21,120 --> 01:02:23,130
if you just assume they
can feel pleasure and pain,

949
01:02:23,340 --> 01:02:25,860
that solves a lot of problems.
Yep.

950
01:02:26,180 --> 01:02:30,870
Thank you so much for your time. So
you mentioned at the end, I guess, um,

951
01:02:31,460 --> 01:02:34,820
to answer the question,
if machines can experience emotion,

952
01:02:34,821 --> 01:02:38,310
the three things and then body was
one of them. And then earlier on,

953
01:02:38,311 --> 01:02:39,560
or you also mentioned,

954
01:02:39,620 --> 01:02:44,510
I guess one purpose to have to create
emotions is like to know what to do next.

955
01:02:45,290 --> 01:02:48,800
So my question is if a
being without a body,

956
01:02:48,890 --> 01:02:52,190
like a machine really
need that body element.

957
01:02:52,220 --> 01:02:56,690
If the purpose of that being is
different than just, you know,

958
01:02:56,691 --> 01:02:58,280
knowing what to do next,

959
01:02:58,900 --> 01:03:03,860
therefore can be tagged that body out of
the one of the three requirements based

960
01:03:03,861 --> 01:03:05,720
on a different purpose of that beam.

961
01:03:06,340 --> 01:03:10,840
That's a great question.
That is a great question. So

962
01:03:12,370 --> 01:03:17,110
if the,
so can you give me an example?

963
01:03:17,510 --> 01:03:18,343
It would be help me,

964
01:03:18,440 --> 01:03:19,910
well,
I don't have an example by the way,

965
01:03:19,911 --> 01:03:23,370
I'm thinking amendment when I went
to meet and I hear machines. Yeah.

966
01:03:23,480 --> 01:03:27,680
And you're modeling all based on in
humans and we have your body and then you

967
01:03:27,681 --> 01:03:31,550
had a purpose or if you have a rule. Yup.
Yup. We have a purpose to have emotions.

968
01:03:31,551 --> 01:03:35,380
Like we are creating them maybe
at the beginning for survival.

969
01:03:35,400 --> 01:03:39,300
Maybe it's different social elements
that, yeah, but if you take the body of,

970
01:03:39,301 --> 01:03:42,250
you can still have a brain octane
oil intelligence. We thought nobody,

971
01:03:42,260 --> 01:03:46,040
which is a different bean or elements,
Darfur,

972
01:03:46,041 --> 01:03:48,920
I'm questioning that model
of three things needed. Yep.

973
01:03:49,980 --> 01:03:52,810
You know, here's the thing
you need to have. Um,

974
01:03:53,530 --> 01:03:58,530
so you'd need to have something that could
tell the machine what it needs to pay

975
01:04:03,971 --> 01:04:08,860
attention to in the world and what it
can ignore. So value. Right. So, I mean,

976
01:04:08,890 --> 01:04:11,140
let me back up and say it this way.
I mean,

977
01:04:11,380 --> 01:04:15,040
I don't know how else to think about
it except in organic terms, right?

978
01:04:15,070 --> 01:04:17,830
But for example,
if you were to look at brain evolution,

979
01:04:18,430 --> 01:04:21,580
if I were to say it really
simply like super simplistically,

980
01:04:21,581 --> 01:04:24,340
so I'm just glossing over
like a ton of detail.

981
01:04:25,650 --> 01:04:29,190
Organisms first developed a motor,

982
01:04:29,340 --> 01:04:34,340
a sort of a rudimentary motor system
with just a tube for like a gut.

983
01:04:35,710 --> 01:04:36,340
That's it.

984
01:04:36,340 --> 01:04:39,850
They used to just float around in
the sea and kind of like filter food.

985
01:04:40,750 --> 01:04:43,720
And it wasn't until the Cambrian
explosion when there was a,

986
01:04:43,721 --> 01:04:47,470
like a lot of oxygen and other things.
And so a lot of, um, uh, you know,

987
01:04:47,471 --> 01:04:52,471
an explosion of diversity of life that
predation developed and predation was a

988
01:04:53,471 --> 01:04:56,350
selection pressure for the
development of two things.

989
01:04:57,940 --> 01:04:59,200
Sensory systems.

990
01:04:59,290 --> 01:05:02,980
So these little like floating
tubes had no visual system.

991
01:05:03,010 --> 01:05:06,810
They had no rudimentary visual system
where auditory system or they had not,

992
01:05:06,820 --> 01:05:11,380
no sensory systems, they didn't really
need them. And they also had no internal,

993
01:05:11,890 --> 01:05:14,980
uh, uh, nervous system to control any,

994
01:05:15,040 --> 01:05:19,930
any systems inside because they didn't
have any systems really inside except the

995
01:05:19,931 --> 01:05:23,340
motor system and a gut.
And that was it. Um,

996
01:05:23,410 --> 01:05:27,460
so they had to develop sensory systems,

997
01:05:27,760 --> 01:05:32,080
whether they're a Predator or prey, you,
most predators, also our PR, our pray,

998
01:05:32,081 --> 01:05:33,870
right so that they could stay,

999
01:05:33,880 --> 01:05:38,650
could sense they have to develop distance
census so they could detect what was I

1000
01:05:38,651 --> 01:05:40,930
going to, what was out there. Um,

1001
01:05:40,931 --> 01:05:45,200
but they also had to figure out
what was meaningful and what wasn't.

1002
01:05:45,220 --> 01:05:50,220
What was valuable because it's expensive
to run a system and learn the two most

1003
01:05:52,361 --> 01:05:57,361
expensive things that any other humans
or any Oregon ganache system can do is

1004
01:05:57,551 --> 01:06:01,930
move and learn. And so, um, it needs,

1005
01:06:01,960 --> 01:06:05,200
and so the development of the
systems of the body sort of serve,

1006
01:06:05,500 --> 01:06:10,500
serve the purpose of helping to
determine the value to the organism.

1007
01:06:10,990 --> 01:06:13,510
Now, it turned out that, you know,

1008
01:06:13,900 --> 01:06:18,790
along the way that those systems
also developed Sensei, you know,

1009
01:06:18,820 --> 01:06:21,970
develop the capacity to sensation
sensations to the brain,

1010
01:06:21,971 --> 01:06:26,140
which had to be made sense of if you
completely demolished that and you say,

1011
01:06:26,410 --> 01:06:31,330
okay, well you have a um,
um, a machine that um,

1012
01:06:32,290 --> 01:06:33,123
um,

1013
01:06:33,490 --> 01:06:38,490
it's purpose isn't to sense things in
the world and make sense of them then,

1014
01:06:39,400 --> 01:06:42,280
um,
so that it can predict what to do next.

1015
01:06:42,310 --> 01:06:45,520
Then maybe you don't need a body but
then you're not even talking about

1016
01:06:45,521 --> 01:06:47,080
something that is,
I don't even know.

1017
01:06:47,110 --> 01:06:49,450
I mean you'd have to give me an example
for me to kind of reason through it in

1018
01:06:49,451 --> 01:06:51,060
terms of the energetics and the,

1019
01:06:51,230 --> 01:06:56,060
I wonder if maybe body is throwing
me off because yeah, like a AI,

1020
01:06:56,490 --> 01:07:00,230
it's purpose can be also survive to
exist and can be an they just very

1021
01:07:00,231 --> 01:07:03,560
simplistically he needed it needs electric
city or its connection to the cloud

1022
01:07:03,561 --> 01:07:05,670
or something.
But that can be its body.

1023
01:07:05,720 --> 01:07:07,850
But what's its function?
What does it do?

1024
01:07:09,090 --> 01:07:10,740
Yeah, what do you mean? Like what? Like,

1025
01:07:11,360 --> 01:07:14,300
it doesn't just, you plug it in and it
doesn't just sit there, it does something.

1026
01:07:14,301 --> 01:07:15,830
What's its function?
What does it do?

1027
01:07:16,920 --> 01:07:20,110
Uh, do you mean dots? Full
intelligence? What does it do well,

1028
01:07:22,370 --> 01:07:26,210
so you're saying, um, okay, it gets
its energy from a plug. I, I get that.

1029
01:07:26,211 --> 01:07:30,220
But what is it actually attempting to
recognize or do or what's its function?

1030
01:07:30,330 --> 01:07:31,890
I mean we can use it for,

1031
01:07:31,891 --> 01:07:35,550
I don't know if some industrial experience
or maybe so southwest driver car AI

1032
01:07:35,551 --> 01:07:38,290
for example. And then
what I'm saying is, okay,

1033
01:07:39,010 --> 01:07:41,800
okay, so it's driving a car.
It's driving a car for you.

1034
01:07:41,801 --> 01:07:43,530
It has to sense things in the world.

1035
01:07:43,600 --> 01:07:45,380
Right. And then the question is Ken, Ken,

1036
01:07:45,390 --> 01:07:49,330
it experience emotion and
then your three model.

1037
01:07:49,331 --> 01:07:50,710
I agree the two of two.

1038
01:07:50,711 --> 01:07:54,040
And then I was questioning about
the body and then maybe the body is,

1039
01:07:54,041 --> 01:07:55,840
what is it reflecting body is,

1040
01:07:56,080 --> 01:07:59,370
is survival to create that value they
thing we're talking about the second one.

1041
01:07:59,371 --> 01:07:59,480
Yeah.
I would

1042
01:07:59,480 --> 01:08:01,760
say, here's what I would say.
I would say, okay, well let's,

1043
01:08:01,761 --> 01:08:03,530
let's take this as an example.
I don't know.

1044
01:08:03,531 --> 01:08:05,750
I'm just doing this off the top of my
head, but let's take as example, so,

1045
01:08:06,260 --> 01:08:09,950
so sure you can just plug it in and it
can get its energy from an electrical

1046
01:08:10,010 --> 01:08:10,700
outlet,

1047
01:08:10,700 --> 01:08:15,700
but still you want to have an
efficient machine that uses electricity

1048
01:08:15,771 --> 01:08:20,630
efficiently. Otherwise that would be
like more expensive than it needs to be.

1049
01:08:20,930 --> 01:08:22,410
And so,
um,

1050
01:08:22,460 --> 01:08:26,090
that means that you'd want it to do things
predictively because that's actually

1051
01:08:26,091 --> 01:08:27,410
more energy efficient.

1052
01:08:27,411 --> 01:08:30,980
That's why the human body doesn't
care or actually any at all.

1053
01:08:30,981 --> 01:08:34,880
Brains are structured to work efficiently,
not because of the, the, you know, the,

1054
01:08:34,940 --> 01:08:39,170
the energy source there is glucose
and other, other, um, organic sources.

1055
01:08:39,171 --> 01:08:43,340
So it's the same principle basically,
in fact, electrical machines. In fact,

1056
01:08:43,341 --> 01:08:46,070
the whole idea of predictive coding,
which is what I'm talking about,

1057
01:08:46,340 --> 01:08:48,520
comes from cybernetics.
Um,

1058
01:08:48,770 --> 01:08:51,890
and then human research researchers
who were studying humans were like, oh,

1059
01:08:51,891 --> 01:08:55,010
wait a minute. That actually could be
really useful for explaining things here.

1060
01:08:55,460 --> 01:08:57,950
So you'd still want it
to be super efficient.

1061
01:08:58,370 --> 01:09:03,080
Presumably if it's driving a car,
it has to determine what's,

1062
01:09:03,110 --> 01:09:07,490
what it has to pay attention to. And
what it doesn't, it can't be energy.

1063
01:09:07,491 --> 01:09:11,540
It can't be frivolous and it's
a and its energy use, right?

1064
01:09:11,541 --> 01:09:15,320
So it's gotta be predictive and it has
to basically not pay attention to some

1065
01:09:15,321 --> 01:09:20,321
things and it probably has a bunch of
systems that it has to keep in balance so

1066
01:09:20,841 --> 01:09:23,300
that it's working efficiently.
Um,

1067
01:09:23,750 --> 01:09:28,750
that's so far counts as there's nothing
in there that actually violates anything

1068
01:09:28,761 --> 01:09:32,120
that I've said. I think I was, I was
trying to be really careful to say,

1069
01:09:32,121 --> 01:09:36,170
when I say a body, I don't literally
mean a flesh and blood body.

1070
01:09:36,350 --> 01:09:41,350
I mean one of your brain's basic jobs
is to keep the systems of your body in

1071
01:09:42,381 --> 01:09:46,760
balance and that requirement,
which is called allostasis,

1072
01:09:47,030 --> 01:09:52,030
that requirement forces a lot of other
things to be true about how the system

1073
01:09:52,341 --> 01:09:54,740
works.
Um,

1074
01:09:54,770 --> 01:09:58,190
so if you want,
um,

1075
01:09:58,490 --> 01:10:03,140
if you want an AI to do
anything like a human,

1076
01:10:03,590 --> 01:10:07,280
it has to be put under the same
selection pressures as a human,

1077
01:10:08,180 --> 01:10:11,930
not literally with flesh
and blood. If, however,

1078
01:10:11,960 --> 01:10:16,400
you're talking about a function that a
human can't do or that isn't relevant to

1079
01:10:16,401 --> 01:10:20,420
humans then any, Nah, nothing
I've said is relevant to you,

1080
01:10:20,421 --> 01:10:25,421
probably I at all right because we're
only talking about about humans,

1081
01:10:25,670 --> 01:10:30,670
but could a car he could of could of
computer that drives a car feel emotion.

1082
01:10:32,520 --> 01:10:34,020
Maybe if

1083
01:10:35,240 --> 01:10:35,970
it

1084
01:10:35,970 --> 01:10:39,660
had sensory inputs that
it had to make sense of.

1085
01:10:40,470 --> 01:10:45,470
But the problem is that I don't know that
I would call that emotion because for

1086
01:10:46,771 --> 01:10:51,771
human we make a distinction between the
brain makes a distinction between the

1087
01:10:54,311 --> 01:10:58,600
sensations from the body and the
sensations from the world. If I were,

1088
01:11:02,340 --> 01:11:05,150
if there, if you didn't have
sensations from your body, you,

1089
01:11:05,160 --> 01:11:08,580
you wouldn't have an effect.
And so it just wouldn't be the same.

1090
01:11:08,581 --> 01:11:09,840
But I don't know.
I mean,

1091
01:11:09,841 --> 01:11:14,050
may I maybe I can't really answer but um,

1092
01:11:14,730 --> 01:11:16,020
maybe,
maybe

1093
01:11:16,080 --> 01:11:20,810
actually can I try to kind of offer
one idea that my combining both. Yeah.

1094
01:11:20,820 --> 01:11:24,480
So what if emotionally just
kind of characteristic for
how your body feels like

1095
01:11:24,481 --> 01:11:29,481
you don't have enough computing power to
process ever since you summarize it and

1096
01:11:30,020 --> 01:11:32,940
machine in that regard?
Would neither Sam curistics.

1097
01:11:33,090 --> 01:11:35,370
If it's not allowed from
then it would be a motion.

1098
01:11:35,870 --> 01:11:38,870
So like either heuristics will
tell like substance Bra, Ronan,

1099
01:11:39,360 --> 01:11:40,440
oh my view was an off.

1100
01:11:40,530 --> 01:11:45,530
That can be in a way seen as emotions and
for us it would be like Samsung is all

1101
01:11:46,521 --> 01:11:49,920
from me. I feel pain. You don't
really know her pain is, but yeah,

1102
01:11:49,980 --> 01:11:52,500
that's a signal food for
deeper investigation. Right.

1103
01:11:52,740 --> 01:11:55,560
And might be one of the causes is,

1104
01:11:56,100 --> 01:12:00,590
I mean I don't believe our brain is a
pinnacle of engineering at least and

1105
01:12:00,640 --> 01:12:04,830
causes, no, no. Like I
correct me if I'm wrong,

1106
01:12:04,831 --> 01:12:08,970
but let's say it's a frequency of our
neurons was like hundred hertz. A second.

1107
01:12:09,450 --> 01:12:13,440
So it was a band is you really like
limited and is only thing that gives us a

1108
01:12:13,441 --> 01:12:18,441
life is that you kind of like candid
billions and machine might not need that

1109
01:12:18,541 --> 01:12:20,700
because the frequency was I calling it.

1110
01:12:22,780 --> 01:12:25,950
Right. But I think it's,
maybe I'm wrong, but it means,

1111
01:12:25,960 --> 01:12:29,110
I think it comes down to a
philosophical question, like, okay, so,

1112
01:12:29,230 --> 01:12:31,720
so a machine that's
driving a car would have,

1113
01:12:31,721 --> 01:12:34,870
since we'd have sensory inputs that it
has to make sense of and it would have to

1114
01:12:34,871 --> 01:12:37,930
do it predictably and all of that,
but so it would have to have category,

1115
01:12:37,960 --> 01:12:41,950
would have to do ad hoc categorization
and it would have to, um,

1116
01:12:42,910 --> 01:12:45,670
or maybe not. But I think that would
probably be the efficient way to do it.

1117
01:12:45,850 --> 01:12:49,390
So it's making categories
and it's perceiving things,

1118
01:12:49,730 --> 01:12:52,600
but so when does that become an
emotion and when doesn't it, I mean,

1119
01:12:52,601 --> 01:12:57,430
you could also ask that of um,
uh, humans, right? I mean, we,

1120
01:12:57,760 --> 01:13:00,850
I mean, you know, nobody asked
me this question, but yeah.

1121
01:13:00,910 --> 01:13:04,090
Like what is the difference between an
emotion category in any other kind of

1122
01:13:04,091 --> 01:13:07,000
category that emit human [inaudible]
can develop, you know, any kind of,

1123
01:13:07,390 --> 01:13:12,050
any other kind of category that is of
this sort, which is ad hoc and, um,

1124
01:13:12,130 --> 01:13:16,420
of social reality. And the answer
is nothing. Nothing is different.

1125
01:13:17,250 --> 01:13:20,950
Um, so I, you know,

1126
01:13:20,951 --> 01:13:25,390
in some ways it's a not a question I
think that science can answer because in

1127
01:13:25,391 --> 01:13:27,460
this culture we've drawn a
boundary and we've said, well,

1128
01:13:27,461 --> 01:13:29,410
these things are emotions and
these things aren't there.

1129
01:13:29,560 --> 01:13:33,370
They're wrapped their thoughts and in
half the world people don't make that

1130
01:13:33,371 --> 01:13:37,540
distinction.
So is it possible to um,

1131
01:13:37,600 --> 01:13:40,240
to develop category, you know,
to do ad hoc categorization?

1132
01:13:40,241 --> 01:13:43,920
Do you do it predictively to make
sense of the world or sensations,

1133
01:13:44,210 --> 01:13:47,800
sensory input from the world
without a body? Sure, sure.

1134
01:13:47,801 --> 01:13:48,880
You could do it without a body,

1135
01:13:48,940 --> 01:13:53,770
but then it probably wouldn't be what we
would call human emotion or what feels

1136
01:13:53,771 --> 01:13:58,600
to us like human emotion, but, but
of course, you know, it, it would be,

1137
01:13:58,630 --> 01:14:00,130
it could be similar,

1138
01:14:00,370 --> 01:14:05,050
I guess to the experiences
that our brains can make. Um,

1139
01:14:06,420 --> 01:14:09,610
but I, I don't know. I have to
think about it more. Actually,

1140
01:14:11,080 --> 01:14:12,520
my iPad is speaking to me.

1141
01:14:12,970 --> 01:14:17,580
Yeah. Thanks Lisa for a great, a great
presentation. I had a followup question.

1142
01:14:18,180 --> 01:14:22,410
Do we believe that if the human brain
and consciousness, good process,

1143
01:14:22,830 --> 01:14:25,530
all of the intraceptive signals
everything from the world,

1144
01:14:25,560 --> 01:14:28,320
all the persons in real time,
so there's no bandwidth issue,

1145
01:14:28,350 --> 01:14:32,190
supposedly human brain could just process
everything. The first question is,

1146
01:14:32,191 --> 01:14:36,540
do you believe we would still have an
effect like this sort of simple state of

1147
01:14:36,630 --> 01:14:40,620
where we are supposedly
could just represent every
piece of information coming.

1148
01:14:41,310 --> 01:14:45,240
And the followup question
is that depending on their
answer to that is how, how,

1149
01:14:45,600 --> 01:14:48,210
how that relates to our notion
of emotional experience.

1150
01:14:49,350 --> 01:14:53,400
So in order though, for us, so
for us to have high dimensional,

1151
01:14:55,650 --> 01:14:59,340
in order for us to have, let me, let
me think about this for a second.

1152
01:15:00,450 --> 01:15:05,310
So if we could sense everything,
all of the neurons, everything,

1153
01:15:05,370 --> 01:15:07,740
every, so our wiring
changed, right? Because we,

1154
01:15:07,741 --> 01:15:10,950
the reason why we can't is that
we don't have the wiring to do it,

1155
01:15:10,951 --> 01:15:14,220
but would we have an effect that's sound?

1156
01:15:14,610 --> 01:15:19,230
Everything was at the same time, I
think. Yes. I think we still would.

1157
01:15:19,231 --> 01:15:23,700
And I'll tell you why we would,
because the way the brain is structured,

1158
01:15:23,970 --> 01:15:28,970
it's structured to do dimension
reduction and compression of information.

1159
01:15:29,340 --> 01:15:34,340
So if you were to look at the cortex and
you were to sort of take the cortex off

1160
01:15:36,661 --> 01:15:41,100
the subcortical parts of the brain and
just lifted off like a and stretch it out

1161
01:15:41,101 --> 01:15:44,640
like a Napkin and you were to
look at it in cross section,

1162
01:15:45,150 --> 01:15:50,150
what you would see is that you go from
primary sensory regions like primary

1163
01:15:50,371 --> 01:15:53,220
visual cortex or primary
and Tara Septic Cortex,

1164
01:15:53,230 --> 01:15:55,680
which is where the information
from the body goes to.

1165
01:15:56,550 --> 01:16:01,410
There are a lot of little pyramidal cells,
um,

1166
01:16:01,530 --> 01:16:04,290
with few connections,
which,

1167
01:16:04,830 --> 01:16:09,830
and the information cascades to the
front of the brain where there are fewer

1168
01:16:10,951 --> 01:16:15,150
cells, which are much bigger with
many, many, many connections.

1169
01:16:15,430 --> 01:16:20,310
But the brain is doing with all sensory
inputs is it's doing compression,

1170
01:16:20,311 --> 01:16:23,910
it's doing dimension reduction.
Um,

1171
01:16:25,470 --> 01:16:29,010
that's how multimodal learning hat,

1172
01:16:29,040 --> 01:16:32,880
that's how really all learn
learning happens essentially. Um,

1173
01:16:32,881 --> 01:16:37,380
so I think it happens in vision.
It happens with audition.

1174
01:16:37,470 --> 01:16:39,330
And so I think even if we could have,

1175
01:16:39,360 --> 01:16:42,490
even if we had higher
dimensional access to what's the,

1176
01:16:42,580 --> 01:16:44,130
the sensory changes in the body,

1177
01:16:44,131 --> 01:16:47,400
I still think given the way
that the cortex is structured,

1178
01:16:47,401 --> 01:16:49,830
we would still experience,
we would still have an effect,

1179
01:16:50,040 --> 01:16:54,300
which basically effect is just a low
dimensional representation of the stuff

1180
01:16:54,301 --> 01:16:55,590
going on inside your body.

