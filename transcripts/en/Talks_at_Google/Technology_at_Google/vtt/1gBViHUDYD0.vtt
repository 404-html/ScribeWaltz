WEBVTT

1
00:00:06.090 --> 00:00:09.060
I'm very pleased to have sat and Steven's Davidowitz here.

2
00:00:09.330 --> 00:00:11.400
He has used data from the internet,

3
00:00:11.401 --> 00:00:15.030
particularly Google searches to get new insights into the human psyche.

4
00:00:15.330 --> 00:00:17.760
Today we'll be discussing his book and research.

5
00:00:17.761 --> 00:00:22.761
Everybody from everybody lies a SF has used Google searches to uh,

6
00:00:22.830 --> 00:00:26.850
measure racism,
self induced abortion,
depression,

7
00:00:26.970 --> 00:00:31.020
child abuse,
hateful mobs,
humor,
sexual preference,

8
00:00:31.021 --> 00:00:35.220
anxiety and sexual insecurity among many other topics.
Um,

9
00:00:35.270 --> 00:00:38.370
some a little less depressing then some of those,
right.
Um,

10
00:00:38.520 --> 00:00:43.330
Zach worked for one and a half years here as a data scientist at Google.
Uh,

11
00:00:43.370 --> 00:00:47.190
so that's really exciting and is currently a contributing op ed writer for the

12
00:00:47.191 --> 00:00:51.520
New York Times.
Uh,
he's designing and teaching a course at the Wharton School,
uh,

13
00:00:51.540 --> 00:00:54.000
where he like,
he will be a visiting lecturer,
uh,

14
00:00:54.020 --> 00:00:59.020
south received his Ba in philosophy from Stanford and a phd from Harvard in

15
00:00:59.131 --> 00:01:01.920
economics.
So please,
let's give Seth a warm welcome.

16
00:01:02.150 --> 00:01:02.983
<v 1>MMM.</v>

17
00:01:07.190 --> 00:01:10.770
<v 2>All right.
Thanks everybody for attending.
Thank you.</v>

18
00:01:10.771 --> 00:01:13.800
Megan is an introduction and it's great to be back here.

19
00:01:13.801 --> 00:01:16.940
I did work for one and a half years in mount and do Google.
Uh,

20
00:01:16.950 --> 00:01:21.810
but I did come by here a while ago and,
uh,
I forgot how spectacular it is here.

21
00:01:21.811 --> 00:01:26.550
So it's a nice reminder,
but,
uh,
it's,
it's,
it's,
it's,
it's nice to be,

22
00:01:26.551 --> 00:01:29.250
I'm talking about my book,
everybody lies.
Uh,

23
00:01:29.251 --> 00:01:33.780
which is how we can use data from the internet to understand who we really are.

24
00:01:34.200 --> 00:01:38.850
So for the last eight years,
if you want to know what people want,

25
00:01:38.930 --> 00:01:42.570
a why people did the things they do,
what people will do in the future,

26
00:01:42.780 --> 00:01:46.680
you had one main approach.
You ask them,
right?
You conducted a survey,

27
00:01:46.860 --> 00:01:51.860
a Gallup or pew or Quinnipiac would go around and say,
uh,
what,
what do you,

28
00:01:51.870 --> 00:01:53.190
what do you want?
What are you going to do?

29
00:01:53.970 --> 00:01:58.380
And a main problem with this is that people have been shown to lie to surveys,

30
00:01:58.930 --> 00:02:02.610
particularly on sensitive topics.
They try to make themselves look good.

31
00:02:02.611 --> 00:02:06.210
They tell surveys what they think the survey or wants to hear and not

32
00:02:06.211 --> 00:02:07.200
necessarily the truth.

33
00:02:07.800 --> 00:02:11.850
So a classic example of this is if you ask people before an election or are you

34
00:02:11.851 --> 00:02:14.940
going to vote in the election?
A huge percentage.

35
00:02:14.941 --> 00:02:17.940
The overwhelming majority of Americans say,
sure,

36
00:02:17.941 --> 00:02:20.790
of course I'm going to exercise my civic duty and vote.

37
00:02:21.690 --> 00:02:25.390
And then when the election comes around,
about 55% of Americans both.

38
00:02:25.391 --> 00:02:28.050
So people don't want to say that they're not voting.
Uh,

39
00:02:28.051 --> 00:02:32.220
one of my favorite examples is the general social survey asks Americans how

40
00:02:32.221 --> 00:02:36.300
frequently they have sex,
uh,
and how frequently they use a condom.

41
00:02:36.810 --> 00:02:41.010
So according to woman,
they have sex about on average,
about once a week,

42
00:02:41.520 --> 00:02:44.630
uh,
and use a condom 20% of the time.
Uh,

43
00:02:44.760 --> 00:02:48.450
so they say that they're using 1.1 billion condoms every year.

44
00:02:48.480 --> 00:02:51.930
And then they also will say whether it's gay or straight is they're using 1.1

45
00:02:51.931 --> 00:02:54.840
billion condoms every year and heterosexual sexual encounters.

46
00:02:55.710 --> 00:02:58.230
And then they asked men the same questions.
According to men,

47
00:02:58.231 --> 00:03:00.890
they're using 1.6 billion condoms every year.
Uh,

48
00:03:00.910 --> 00:03:02.800
in heterosexual sexual encounters.

49
00:03:03.270 --> 00:03:06.250
I hope everyone realizes those by definition have to be the same,
right?

50
00:03:06.251 --> 00:03:10.750
So we already know that someone's lying.
Someone's not telling the truth here,
uh,

51
00:03:10.770 --> 00:03:14.590
about how much sex they're having.
And,
uh,
I got data from Nielsen.

52
00:03:14.591 --> 00:03:17.080
They track every condom sold in the United States.

53
00:03:17.110 --> 00:03:19.510
Only 600 million condoms are sold every year.

54
00:03:20.530 --> 00:03:23.090
So basically now everybody's lying about sex.
Uh,

55
00:03:23.210 --> 00:03:25.590
just men are lying even more than woman.
Uh,

56
00:03:25.720 --> 00:03:28.600
and this doesn't mean this could just be,
they're lying about using a condom,

57
00:03:28.601 --> 00:03:30.010
not necessarily how much sex they have.

58
00:03:30.490 --> 00:03:34.330
But if you see how much unprotected sex woman of fertility age say they're

59
00:03:34.331 --> 00:03:36.730
having,
if they really were having this much sex,

60
00:03:36.790 --> 00:03:40.190
they basically more pregnancies every year in the United States.
So,
uh,

61
00:03:40.200 --> 00:03:42.280
I think in our sex obsessed culture,

62
00:03:42.330 --> 00:03:46.210
there is now a pressure both on men and woman to say they're having more sex

63
00:03:46.211 --> 00:03:47.230
than they actually are hoping.

64
00:03:48.990 --> 00:03:49.823
<v 1>Yeah.</v>

65
00:03:49.860 --> 00:03:52.090
<v 2>All right.
Digital Truth Serum.
Google.</v>

66
00:03:52.091 --> 00:03:53.800
The thesis of my book basically on a thesis,

67
00:03:53.801 --> 00:03:58.480
my research for the last five years is that people are much more honest on

68
00:03:58.481 --> 00:04:01.700
Google than they are to basically any other source of thing.

69
00:04:01.960 --> 00:04:05.730
People tend to feel comfortable typing things into Google,
uh,

70
00:04:05.770 --> 00:04:09.700
that they might not tell anybody else.
And,
uh,

71
00:04:09.760 --> 00:04:11.740
this data of course is all anonymous and aggregate.

72
00:04:11.741 --> 00:04:15.580
So nobody knows the searches that any particular person makes.

73
00:04:15.850 --> 00:04:18.850
But by aggregating it all and putting it all together,

74
00:04:18.940 --> 00:04:23.940
we can see different patterns in human behavior and human wants.

75
00:04:24.820 --> 00:04:28.030
So like the example people are on it do tell things,
Google,

76
00:04:28.031 --> 00:04:30.700
they might not tell anyone else.
There are more searches on average.

77
00:04:30.870 --> 00:04:33.790
This is using Google trends for pour.
And then for weather though,

78
00:04:33.791 --> 00:04:36.490
if you ask people if they watch porn,

79
00:04:36.491 --> 00:04:40.210
only about 20% of men and 4% of women say they watch porn.

80
00:04:40.211 --> 00:04:41.320
So that's hard to reconcile.

81
00:04:41.321 --> 00:04:44.200
But people are clearly typing things into Google that they might not be

82
00:04:44.201 --> 00:04:48.060
comfortable telling to a survey.
Uh,

83
00:04:48.061 --> 00:04:52.830
so we can learn really,
uh,
lots of,
uh,
so,
so why are people so honest on Google?

84
00:04:52.831 --> 00:04:55.410
Well,
one thing,
they're alone.
They're online.

85
00:04:55.411 --> 00:04:57.120
That tends to make people more honest,

86
00:04:57.570 --> 00:05:01.260
but they also have an incentive to tell the truth to Google.
So you,

87
00:05:01.290 --> 00:05:04.050
there's no reason for any person to tell a story,

88
00:05:04.500 --> 00:05:08.910
to tell a survey that they're voting about their voting behavior,

89
00:05:08.911 --> 00:05:11.120
whether they're actually voting or not voting.
Uh,

90
00:05:11.260 --> 00:05:14.160
there's no reason to tell it to,
to be honest about that.

91
00:05:14.430 --> 00:05:16.470
But if you're someone who doesn't always vote,

92
00:05:16.500 --> 00:05:18.540
or I just kind of a marginal voter,

93
00:05:18.660 --> 00:05:22.080
you may not know where the polling places are.
So you have to tell Google,

94
00:05:22.081 --> 00:05:25.080
you have to say where to vote or how to vote or search,
something like that.

95
00:05:25.260 --> 00:05:25.570
And it,

96
00:05:25.570 --> 00:05:29.910
it is clear in the data that this predicts turnout in different parts of the

97
00:05:29.911 --> 00:05:30.271
country,

98
00:05:30.271 --> 00:05:33.300
that when people aren't making a lot of searches for where to vote and how to

99
00:05:33.301 --> 00:05:36.240
vote,
uh,
people are much more likely to turn out to vote.

100
00:05:36.630 --> 00:05:38.250
And if you're not having a lot of sex,

101
00:05:38.280 --> 00:05:40.590
you don't have a reason to tell that to a survey.

102
00:05:40.591 --> 00:05:42.000
There's no reason for you to do that.

103
00:05:42.180 --> 00:05:45.330
But you might have an incentive to search for this on Google.

104
00:05:45.331 --> 00:05:48.840
And the number one complaint about a marriage on Google by far is that it's a

105
00:05:48.841 --> 00:05:53.070
sexless marriage.
Much more common than love lists are unhappy marriage.

106
00:05:53.870 --> 00:05:54.120
Uh,

107
00:05:54.120 --> 00:05:58.370
and we also start seeing in this data some things that maybe counterintuitive or

108
00:05:58.371 --> 00:06:03.140
surprising.
Uh,
the number one complaints about a partner on Google for husband,

109
00:06:03.141 --> 00:06:07.100
wife,
boyfriend,
or girlfriend is that the partner want to have sex with me.

110
00:06:07.850 --> 00:06:08.360
Uh,

111
00:06:08.360 --> 00:06:11.990
ease easily beats a second place complaint that the partner won't text me back.

112
00:06:12.410 --> 00:06:16.480
Uh,
but,
uh,
the,
the,
the,
the,
they're,

113
00:06:16.540 --> 00:06:19.970
they're actually twice as many complaints on Google that my boyfriend won't have

114
00:06:19.971 --> 00:06:21.980
sex with me then that my girlfriend won't have sex with me,

115
00:06:22.340 --> 00:06:26.750
which goes completely against conventional wisdom about,
uh,
about,
uh,

116
00:06:26.780 --> 00:06:29.070
who's avoiding,
who's avoiding sex.
Uh,

117
00:06:29.071 --> 00:06:31.550
so I think there are definitely surprising things in this data.

118
00:06:34.190 --> 00:06:37.790
We can also use this search data to answer big,
big questions.

119
00:06:37.860 --> 00:06:41.070
Now that I've kind of puzzled researchers for awhile.
Uh,

120
00:06:41.120 --> 00:06:45.170
one of them that I've done a lot of research on is on racism.

121
00:06:46.100 --> 00:06:49.610
So this is kind of a classic area where it may be difficult to find the truth by

122
00:06:49.611 --> 00:06:54.320
using surveys.
And for example,
after the 2008 election,

123
00:06:54.560 --> 00:06:58.700
uh,
one of the big questions was,
would voters,
did voters care that Barack Obama,

124
00:06:58.760 --> 00:07:02.480
the first major party,
general election candidate who was African American,

125
00:07:02.810 --> 00:07:06.900
did they care that he was black?
And if you ask in surveys,
uh,

126
00:07:07.100 --> 00:07:12.020
the overwhelming majority of Americans,
98%,
99% of Americans said,
no,

127
00:07:12.021 --> 00:07:13.910
I didn't care at all that Obama was black.

128
00:07:13.911 --> 00:07:16.610
It was not a factor in my voting decision.
Uh,

129
00:07:16.611 --> 00:07:20.910
but of course this may be misleading because,
uh,

130
00:07:20.990 --> 00:07:24.230
people may lie and not want to admit that they carried that Obama was black.

131
00:07:25.760 --> 00:07:26.690
So what I did,
uh,

132
00:07:26.691 --> 00:07:31.280
this is kind of the first study I did with this research is I studied racist

133
00:07:31.281 --> 00:07:36.050
searches that people make on Google.
And,
uh,
this is obviously disturbing.

134
00:07:36.470 --> 00:07:40.430
Uh,
this is,
uh,
a search for a very,
very nasty,
uh,

135
00:07:40.440 --> 00:07:43.790
worried about African Americans that you can kind of guess probably what it is

136
00:07:44.120 --> 00:07:48.610
or look at or read my book if you want to learn more.
But,
uh,
it's,
this is,
uh,

137
00:07:48.770 --> 00:07:53.180
basically people searching for discharging jokes and mocking African Americans.

138
00:07:53.530 --> 00:07:55.880
Uh,
so really,
really,
uh,
nasty searches.

139
00:07:55.881 --> 00:07:58.790
And the first thing that struck me out about the searches was how frequent they

140
00:07:58.791 --> 00:08:02.060
were.
Uh,
in the time period I was looking a,

141
00:08:02.290 --> 00:08:06.020
this search was about as common as searches for Lakers and economist and

142
00:08:06.021 --> 00:08:10.670
Migraine.
And daily show.
So not by any stretch of imagination of fringe search.

143
00:08:11.540 --> 00:08:15.260
And,
uh,
the other thing that was striking about this,
uh,

144
00:08:15.470 --> 00:08:19.430
when I first saw this data is that the Mac looks very different than the map

145
00:08:19.431 --> 00:08:23.870
that I would have guessed.
So if you had asked me before I did this research,

146
00:08:23.930 --> 00:08:28.320
whereas racism highest in the United States,
I would have said south,
right?

147
00:08:28.340 --> 00:08:31.130
Deep South,
like that's when you think of the country's history.

148
00:08:31.131 --> 00:08:34.070
You think Mississippi and Louisiana and Alabama and South Carolina,

149
00:08:34.580 --> 00:08:38.460
and those areas definitely are among the highest,
uh,

150
00:08:38.510 --> 00:08:40.820
but also among the highest,

151
00:08:40.850 --> 00:08:45.320
our West Virginia and western Pennsylvania and eastern Ohio and upstate New York

152
00:08:45.470 --> 00:08:48.290
and parts of Industrial Michigan and Rural Illinois.
Uh,

153
00:08:48.291 --> 00:08:52.880
the real divide this map reveals and racism to a these days in the United States

154
00:08:53.120 --> 00:08:56.130
is not south versus north.
It's east versus West.

155
00:08:56.490 --> 00:08:58.250
So which it's much higher resolution,

156
00:08:58.290 --> 00:09:01.860
much higher east of the Mississippi River in west of the Mississippi River.

157
00:09:02.790 --> 00:09:03.310
<v 1>Okay.</v>

158
00:09:03.310 --> 00:09:07.930
<v 2>So how can you use this map to,
uh,
detect how much racism cost Obama?</v>

159
00:09:08.560 --> 00:09:09.071
Basically,

160
00:09:09.071 --> 00:09:13.540
I compare it Obama to previous Democratic candidates such as John Kerry.

161
00:09:13.541 --> 00:09:16.990
The white candidate who was symbol of liberal in the previous candidate in the

162
00:09:16.991 --> 00:09:19.750
previous election.
And you see a very,

163
00:09:19.751 --> 00:09:23.140
very clear relationship that in parts of the country that are making the most

164
00:09:23.141 --> 00:09:26.290
racist searches in western Pennsylvania and eastern Ohio and western Michigan,

165
00:09:26.530 --> 00:09:30.610
you see a clear relationship that Obama just does worse than previous Democratic

166
00:09:30.611 --> 00:09:33.860
candidates did.
And you try to explain it by any other,
uh,

167
00:09:33.940 --> 00:09:35.080
any other variable you have.

168
00:09:35.081 --> 00:09:39.400
And nothing else can really explain this relationship a except,
except racism.

169
00:09:40.300 --> 00:09:41.111
So I think it was really,

170
00:09:41.111 --> 00:09:43.770
really clear in this data that despite what people were saying,
uh,

171
00:09:43.771 --> 00:09:47.650
a significant fraction of Americans,
I say about four percentage points overall,

172
00:09:47.651 --> 00:09:48.191
he lost.

173
00:09:48.191 --> 00:09:52.750
And about 10% of Americans and white Americans would not support a democratic

174
00:09:52.751 --> 00:09:55.800
candidate just because he was black.
I think that's,
that's,

175
00:09:55.830 --> 00:10:00.340
that's what I picked up in this data.
And then I kind of,
uh,
I kind of let this,

176
00:10:00.341 --> 00:10:03.030
this kind of languished and academic journals for a while,

177
00:10:03.070 --> 00:10:04.990
people weren't really paying much attention to it.

178
00:10:05.410 --> 00:10:07.420
But then in this recent election,
uh,

179
00:10:07.450 --> 00:10:12.400
Donald Trump started saying some nasty things about,
about black people,
right?

180
00:10:12.550 --> 00:10:14.020
And we're still getting a lot of support.

181
00:10:14.021 --> 00:10:16.870
And this was kind of puzzling to a lot of people who thought that,
uh,

182
00:10:16.871 --> 00:10:18.910
you're not really allowed to say those things,
uh,

183
00:10:18.940 --> 00:10:22.960
in the United States these days.
Uh,
so not me,
but actually,
uh,

184
00:10:23.380 --> 00:10:28.360
Nate cone at the New York Times,
a stats guy there,
uh,
he asked for this data.

185
00:10:28.361 --> 00:10:29.980
I said,
can I see your racist search data?

186
00:10:29.981 --> 00:10:32.650
I have data on how Trump is doing in the primary,

187
00:10:32.651 --> 00:10:34.060
in all different parts of the country,

188
00:10:34.390 --> 00:10:38.920
and I want to see if it correlates with your racist search data.
And he founds,

189
00:10:39.010 --> 00:10:43.900
uh,
that it was the single highest variable that he could find,
uh,
that,
uh,

190
00:10:43.901 --> 00:10:45.540
the,
you know,
for that I,

191
00:10:45.600 --> 00:10:50.090
it was higher than age and education and economic conditions and trade and

192
00:10:50.770 --> 00:10:54.490
policy positions and gun ownership.
Basically nothing could explain,
uh,

193
00:10:54.491 --> 00:10:58.350
support for Trump in the primary to the same degree as this racist search.
Uh,

194
00:10:58.480 --> 00:10:59.160
did.

195
00:10:59.160 --> 00:11:04.160
So I think what happened is the same hidden racism that was hurting Obama but

196
00:11:04.871 --> 00:11:09.871
not being picked up in the data also helped carry a Trump to victory.

197
00:11:13.480 --> 00:11:17.500
So I think,
yeah,
this is the digital truth serum and I'm,
Megan is right.

198
00:11:17.501 --> 00:11:20.800
My book is,
it's kind of depressing I think a little bit

199
00:11:22.540 --> 00:11:25.670
because yeah,
like if you ask people what they're like a,

200
00:11:25.730 --> 00:11:30.310
they're going to give you one more positive view of,
of themselves than they,

201
00:11:30.670 --> 00:11:33.760
than they unnecessarily really are.
So I,
yeah,

202
00:11:33.761 --> 00:11:37.990
I talk about racism and I talk about child abuse and do it yourself.
Abortion,

203
00:11:37.991 --> 00:11:40.960
I think America is a do it yourself abortion crisis that isn't being picked up

204
00:11:40.961 --> 00:11:45.940
in the traditional data sources.
So a really,
yeah,
dark,
horrifying,

205
00:11:45.970 --> 00:11:48.820
terrifying,
um,
disturbing material.
Uh,

206
00:11:48.821 --> 00:11:53.821
but I put jokes in it so you won't really notice just how miserable,

207
00:11:54.220 --> 00:11:57.310
uh,
all the findings are.
But,
uh,
I think there actually,

208
00:11:57.520 --> 00:12:02.520
so I think there actually is a lot of value to knowing some of this stuff,

209
00:12:03.461 --> 00:12:04.450
to knowing the truth,

210
00:12:05.830 --> 00:12:10.310
even if it is sometimes depressing and sometimes disturbing.
Uh,

211
00:12:10.450 --> 00:12:12.160
and I'll give you a couple of examples of that.

212
00:12:12.280 --> 00:12:17.280
So one of the studies I did is I just compared the searches that the Google

213
00:12:19.001 --> 00:12:23.200
searches that people make about sons and daughters.

214
00:12:24.520 --> 00:12:26.390
And I would have thought or hoped,
uh,

215
00:12:26.510 --> 00:12:30.250
in the United States today that parents treated their sons and daughters the

216
00:12:30.251 --> 00:12:32.000
same way.
Uh,

217
00:12:32.560 --> 00:12:36.280
but if you look at everybody's search data together and you see very,

218
00:12:36.281 --> 00:12:41.281
very different patterns where when American parents start a search is my son,

219
00:12:42.020 --> 00:12:46.270
there are about twice as likely to complete it with gifted or a genius.

220
00:12:46.300 --> 00:12:49.780
Then if they start a search is my daughter and they start a search is my

221
00:12:49.781 --> 00:12:50.570
daughter.

222
00:12:50.570 --> 00:12:54.460
There are much more likely to complete it with is my daughter overweight or even

223
00:12:54.461 --> 00:12:55.690
is my daughter ugly?

224
00:12:56.320 --> 00:13:00.580
So despite what I think parents might think,
uh,

225
00:13:00.820 --> 00:13:04.000
there's clearly when you put together everybody's data,
uh,

226
00:13:04.030 --> 00:13:08.190
parents on average are much more excited about the intellectual potential if

227
00:13:08.191 --> 00:13:12.730
their sons and much more concerned about the physical appearance of their

228
00:13:12.731 --> 00:13:16.090
daughters.
And I think that's one finding.
So you talked about the racism thing.

229
00:13:16.120 --> 00:13:19.880
It's not clear that the people who are making these racist searches,
uh,

230
00:13:20.530 --> 00:13:22.390
if you just tell them,
they're going to be like,
oh,
okay,

231
00:13:22.391 --> 00:13:25.900
I didn't realize I was racist.
Sorry about that.
I'm going to stop making these,

232
00:13:25.960 --> 00:13:29.410
you know,
uh,
terrible searches,
jokes,
searches and stuff.

233
00:13:29.740 --> 00:13:31.180
But I think with his parenting finding,

234
00:13:31.181 --> 00:13:34.300
I think a lot of parents don't even realize that they're doing that.

235
00:13:34.870 --> 00:13:38.430
It's maybe a subconscious prejudice that they're not aware of.
And if that,

236
00:13:38.540 --> 00:13:41.920
that's one where maybe just the information itself can actually help to change

237
00:13:41.921 --> 00:13:46.630
behavior.
Where if we tell parents,
oh,
you know,
you might not think so,
but look,

238
00:13:46.631 --> 00:13:49.000
when we put together everybody's data,
even in,
you know,

239
00:13:49.001 --> 00:13:50.860
throughout the United States,
there is this,

240
00:13:51.330 --> 00:13:54.250
there are these prejudices like think twice.
Are you,

241
00:13:54.251 --> 00:13:57.030
are you paying enough attention to the report card that your daughter's bringing

242
00:13:57.050 --> 00:14:01.630
home?
Uh,
are,
are you paying enough attention to her intellectual interests?
Uh,
I,

243
00:14:01.720 --> 00:14:05.230
and I think a lot of parents have told me that,
that has made them think twice,

244
00:14:05.520 --> 00:14:06.353
uh,

245
00:14:06.720 --> 00:14:09.310
about some of the questions they ask and some of the ways they treat their sons

246
00:14:09.311 --> 00:14:12.880
and daughters.
So there is a lot of value in knowing things,
knowing the truth,

247
00:14:12.881 --> 00:14:14.650
not what people think or what people say.

248
00:14:15.180 --> 00:14:19.780
And another example that I'm going to give,
uh,
is about Islamophobia.

249
00:14:21.490 --> 00:14:25.870
So if you can go back to the San Bernardino attacks in December,
2015,

250
00:14:25.871 --> 00:14:30.070
if people remember that it was two people with a Muslim sounding name,
uh,

251
00:14:30.071 --> 00:14:34.330
shut up,
basically one of the guys,
coworkers.
And uh,

252
00:14:34.331 --> 00:14:37.840
it was kind of a big,
many,
many people died.
It was a big news story.

253
00:14:38.560 --> 00:14:42.340
And right after this,
there was an explosion of Islamophobia.

254
00:14:43.480 --> 00:14:44.650
And you saw that really,

255
00:14:44.651 --> 00:14:49.651
really clearly in the Google searches where the number one search with the word

256
00:14:49.901 --> 00:14:53.630
Muslims in it immediately after the tech was kill Muslims.

257
00:14:54.500 --> 00:14:57.680
And these are people just kind of,
they're maniacs to some degree.

258
00:14:57.681 --> 00:15:00.110
These are kind of just not the most sane members of society.

259
00:15:00.111 --> 00:15:03.210
It's not even clear what exactly they're saying,
but they're saying,
ah,

260
00:15:03.290 --> 00:15:05.600
but they're,
they're very angry and kind of just want to,

261
00:15:05.930 --> 00:15:09.830
I want to do something bad.
And they also make searches like I hate Muslims.
Uh,

262
00:15:09.890 --> 00:15:14.620
or you know,
Muslims must die or really,
really nasty,
nasty,
horrible,
uh,

263
00:15:14.780 --> 00:15:15.613
searches.

264
00:15:15.800 --> 00:15:19.940
And these searches we've shown can predict hate crimes in the United,

265
00:15:19.941 --> 00:15:23.300
in the United States against Muslims.
They're not,
even though they're weird,

266
00:15:23.301 --> 00:15:25.850
they definitely contain,
um,
meaningful information.

267
00:15:27.410 --> 00:15:30.500
So a few days after the San Bernardino attack,
uh,

268
00:15:30.501 --> 00:15:33.920
Barack Obama gave a talk to the nation.

269
00:15:34.700 --> 00:15:38.600
And the theme of this talk was both that we had to protect ourselves against

270
00:15:38.601 --> 00:15:41.930
terrorism,
but also we had to fight this Islamophobia.

271
00:15:42.020 --> 00:15:46.670
We couldn't really allow ourselves to give into this hatred that some,

272
00:15:46.820 --> 00:15:50.520
a small,
a small purse,
but dangerous percentage of people are,
we're at,

273
00:15:50.530 --> 00:15:55.030
we're letting themselves get into.
And,
uh,

274
00:15:55.110 --> 00:16:00.050
the speech was nationally televised.
It got a lot of attention.
And it was a,

275
00:16:00.080 --> 00:16:03.230
one of the more beautiful speeches I'd heard Obama give.
Uh,

276
00:16:03.500 --> 00:16:04.970
it was kind of classic Obama,

277
00:16:04.971 --> 00:16:08.720
but even better than classic Obama where he talked about,
uh,

278
00:16:08.960 --> 00:16:13.960
how it's our responsibility to not give into fear and to appeal to freedom and

279
00:16:14.750 --> 00:16:18.830
how it's our responsibility to not reject someone just because of the religion

280
00:16:18.831 --> 00:16:22.250
they practice.
And,
uh,

281
00:16:22.580 --> 00:16:25.700
it got great reviews from all the serious sources,
right?

282
00:16:25.701 --> 00:16:28.580
The New York Times said it was a great speech and the La Times said it was a

283
00:16:28.581 --> 00:16:32.970
great speech.
And,
or the Boston Globe said it was a great speech.
Uh,

284
00:16:33.050 --> 00:16:37.220
sews the kind of all the conventional wisdom was that Obama had given this great

285
00:16:37.221 --> 00:16:39.220
speech about the rest of our,

286
00:16:39.230 --> 00:16:43.190
our responsibility to treat our neighbors a kindly,
uh,

287
00:16:43.191 --> 00:16:44.750
our Muslim American neighbors kindly.

288
00:16:45.980 --> 00:16:50.510
So Google breaks down minute by minute,
their search data.
And I wanted to see,

289
00:16:50.540 --> 00:16:53.720
did this beautiful speech,
do it,
serve its purpose.

290
00:16:53.721 --> 00:16:56.660
Did it calm down these Islamophobes.

291
00:16:58.160 --> 00:17:03.160
And I looked at the data and I found that not only did these crazy searches kill

292
00:17:04.401 --> 00:17:07.370
Muslims,
hate Muslims,
I hate Muslims.
Thai Muslims,

293
00:17:08.090 --> 00:17:11.810
they didn't drop,
they didn't even stay the same.

294
00:17:12.170 --> 00:17:17.090
They went way off.
They exploded basically every time Obama was saying,

295
00:17:17.420 --> 00:17:20.450
uh,
you know,
all these responsibility,
the,
the,
the,

296
00:17:20.451 --> 00:17:24.410
the importance of responsibility and this beautiful sermon just seems to

297
00:17:24.411 --> 00:17:29.411
backfire completely on all the bios on its main purpose.

298
00:17:30.950 --> 00:17:34.910
But there was one line that Obama gave at the speech that seems to have a

299
00:17:34.911 --> 00:17:35.930
different response.

300
00:17:36.620 --> 00:17:40.700
So he said that we had to remember that Muslim Americans are our friends and

301
00:17:40.701 --> 00:17:42.180
neighbors.
Uh,

302
00:17:42.230 --> 00:17:46.640
there are athletes and they're our sports heroes and they're the men and women

303
00:17:46.641 --> 00:17:51.630
who will die for this country.
And right after he said that line,

304
00:17:52.160 --> 00:17:55.020
uh,
for the first time in the last five years,

305
00:17:55.080 --> 00:18:00.080
the top word search with Muslims was not Muslim terrorists are Muslim refugees.

306
00:18:01.230 --> 00:18:06.010
It was Muslim athletes fall by Muslim soldiers.
So,

307
00:18:06.030 --> 00:18:08.250
and that,
these stayed up for about a week afterwards.

308
00:18:08.251 --> 00:18:09.720
And you saw throughout the Internet,

309
00:18:09.721 --> 00:18:12.390
people were talking about Shaquille O'Neal's,
a Muslim,

310
00:18:12.391 --> 00:18:14.310
I didn't know she killed him,
yell it.
So it was a Muslim.

311
00:18:15.630 --> 00:18:17.790
And I think that does,

312
00:18:17.820 --> 00:18:21.600
you can kind of compare most of the speech versus what that line was.

313
00:18:21.601 --> 00:18:24.620
So the first part,
the most of the speech,
uh,

314
00:18:24.810 --> 00:18:29.430
was basically a lecture telling people not everything they'd heard a million

315
00:18:29.431 --> 00:18:31.050
times before and nothing new,
right.

316
00:18:31.080 --> 00:18:35.670
Lecturing them that to be better people than they,
than they were.

317
00:18:36.150 --> 00:18:37.920
And that seemed to totally backfire.

318
00:18:38.310 --> 00:18:43.310
But the line about the athletes and sports heroes was provoking their curiosity,

319
00:18:43.351 --> 00:18:44.550
giving them new information,

320
00:18:44.551 --> 00:18:47.550
changing what they might think of as the Muslim American.

321
00:18:48.000 --> 00:18:49.710
And that seemed to be more successful.

322
00:18:50.810 --> 00:18:54.420
So we wrote this up in the New York Times and a column in the New York Times.

323
00:18:54.421 --> 00:18:57.600
And I don't think,
uh,
it's totally crazy though,

324
00:18:57.601 --> 00:18:58.920
when you're right in New York Times column,

325
00:18:58.921 --> 00:19:03.921
powerful people see that because a couple of weeks later Obama gave another

326
00:19:05.041 --> 00:19:09.750
speech.
Uh,
this time it was in a Baltimore mosque and again,

327
00:19:09.751 --> 00:19:11.490
it was on national TV.
And again,

328
00:19:11.491 --> 00:19:16.491
it got a lot of attention and the content of the speech was totally different.

329
00:19:17.580 --> 00:19:21.060
Uh,
basically he stopped with all this sermon,
all the lectures,

330
00:19:21.061 --> 00:19:23.400
all the talk of responsibility,

331
00:19:23.580 --> 00:19:27.270
and he just doubled down or even quadruple down on the curiosity.

332
00:19:27.690 --> 00:19:32.670
So they said that Muslim Americans are not just our sports heroes and our

333
00:19:32.671 --> 00:19:35.670
soldiers.
There are farmers and our merchants.

334
00:19:35.671 --> 00:19:40.671
And he talked about how Thomas Jefferson had a copy of the Qur'an and how Muslim

335
00:19:41.551 --> 00:19:43.890
Americans built the skyscrapers of Chicago.

336
00:19:44.160 --> 00:19:49.140
So it was all these new images of Muslim Americans that we didn't previously

337
00:19:49.141 --> 00:19:51.600
have.
And we look,

338
00:19:51.750 --> 00:19:55.230
I looked at the search data again after this speech and the in the hours

339
00:19:55.231 --> 00:19:59.610
following this speech and this time the searches for kill Muslims and I hate

340
00:19:59.611 --> 00:20:02.550
Muslims dropped.
So I think,
uh,

341
00:20:02.560 --> 00:20:05.390
that's only two speeches and I don't want to say that,
uh,
that,

342
00:20:05.490 --> 00:20:08.100
that we've solved the problem of,
of hatred.

343
00:20:08.610 --> 00:20:11.820
But I do think that this is a radically new tool.

344
00:20:11.821 --> 00:20:14.880
And I think people don't realize just how revolutionary this data from the

345
00:20:14.881 --> 00:20:19.800
Internet is that we can actually peer into an angry mob and turn that into a

346
00:20:19.801 --> 00:20:24.210
science.
Right?
You can't,
uh,
in a survey of all Americans,
you're not going to get,

347
00:20:24.500 --> 00:20:28.830
uh,
necessarily these,
uh,
you know,
these,
uh,

348
00:20:28.890 --> 00:20:30.300
these people.
And even if you do,

349
00:20:30.301 --> 00:20:34.080
they may not be honest and they're not going to agree to participate in a lab

350
00:20:34.081 --> 00:20:36.300
experiment at Princeton or Harvard.
Uh,

351
00:20:36.420 --> 00:20:39.780
but because Google searches contains everybody's information,

352
00:20:40.280 --> 00:20:44.050
they're going to be on there and we can actually see,
uh,
what,
you know,

353
00:20:44.070 --> 00:20:48.220
how they respond to big national events,
uh,
and maybe

354
00:20:48.220 --> 00:20:51.730
<v 3>learn a,
you know,
a lot of the things that we thought worked don't work,</v>

355
00:20:51.731 --> 00:20:53.260
but here are things that actually work.

356
00:20:54.040 --> 00:20:59.040
So I think that kind of shows that this window into some parts of the psyche

357
00:20:59.141 --> 00:21:02.710
that are just starving but are usually missed,
uh,

358
00:21:02.830 --> 00:21:06.970
can really serve a useful purpose where knowing the truth is maybe the first

359
00:21:06.971 --> 00:21:11.350
step towards improving the world.
Uh,
I think so.
Uh,

360
00:21:11.351 --> 00:21:13.180
that's all I have to say.
I'm going to now,

361
00:21:13.181 --> 00:21:17.050
I think we're going to take questions from Megan and other people about the
book.

362
00:21:17.520 --> 00:21:18.353
All right.

363
00:21:18.550 --> 00:21:21.600
<v 0>I sat and that was great.
The book's awesome.
Um,</v>

364
00:21:21.680 --> 00:21:25.220
it's really cool if you work at Google because you can see sort of what's going

365
00:21:25.221 --> 00:21:29.900
on here and,
uh,
sort of a different variation of,
uh,
what we do here every day.

366
00:21:29.901 --> 00:21:32.390
So I highly recommend it.
Um,

367
00:21:32.630 --> 00:21:35.270
and that was just a few of the topics that you cover.

368
00:21:35.271 --> 00:21:38.970
You cover so many topics in the book,
but I thought I'd start,
uh,

369
00:21:39.110 --> 00:21:43.010
asking you a little bit about your experience working here and how that sort of

370
00:21:43.040 --> 00:21:47.510
led you to become a writer and if there's anything you miss about being here.

371
00:21:48.000 --> 00:21:49.080
<v 3>Yeah,
no,
I,
I,</v>

372
00:21:49.110 --> 00:21:53.580
I didn't miss it until I just had like the food right before I got here.

373
00:21:53.581 --> 00:21:58.540
I'm like,
aw man,
what was I thinking?
Uh,
and the views of all,

374
00:21:58.710 --> 00:22:01.710
they have a new floor here in the New York office where you can see the river

375
00:22:01.711 --> 00:22:06.300
and it's just like,
oh,
am I,
and like the,
all the furniture is so comfortable.
Uh,

376
00:22:06.390 --> 00:22:10.910
so yeah.
And like,
yeah.
And the people are all really smart.
So I definitely,
uh,
I,

377
00:22:10.950 --> 00:22:13.200
uh,
you know,
you don't appreciate,
appreciate what,

378
00:22:13.830 --> 00:22:16.440
what's the Song Joni Mitchell Song?
You don't know what you got until it's gone.

379
00:22:16.500 --> 00:22:19.750
Yeah.
Yeah.
So that's,
that kind of happened a little bit.
Google,
although I are,

380
00:22:19.760 --> 00:22:21.560
I'm enjoying the writing thing as well.
But,

381
00:22:22.200 --> 00:22:24.960
and what was it like when you were working here and what were you working on?

382
00:22:24.961 --> 00:22:27.000
Can you give a little bit of color around?
Yeah,

383
00:22:27.010 --> 00:22:30.450
so I was working under how there and the chief economist at Google,

384
00:22:30.451 --> 00:22:32.530
he was the guy who initially hired me and then,
uh,

385
00:22:32.540 --> 00:22:36.630
I was on his team and also in quantitative marketing,
uh,

386
00:22:36.680 --> 00:22:38.820
how to out in mountain view.
So,
uh,

387
00:22:39.690 --> 00:22:42.540
kind of like a lot of in house data consulting,
uh,

388
00:22:42.600 --> 00:22:46.620
but also some advertising effectiveness studies.
Uh,
and,

389
00:22:47.120 --> 00:22:49.770
and then also some research because I think Google was kind of getting

390
00:22:49.771 --> 00:22:52.050
interested in all this information we have.

391
00:22:52.051 --> 00:22:54.930
That's kind of one of the original reasons that hell hired me.
Uh,

392
00:22:54.960 --> 00:22:57.950
that looked like that there is this powerful data and kind of how,
how,

393
00:22:57.951 --> 00:23:00.210
how should we be using this information.

394
00:23:00.320 --> 00:23:03.620
<v 0>And that was sort of part of the inspiration for this book.
Yes.</v>

395
00:23:03.700 --> 00:23:06.400
<v 3>Yeah.
I think,
uh,
I think the,
yeah,
I think,
uh,</v>

396
00:23:07.270 --> 00:23:09.850
I mean it's just the more I studied this data,
the more I'm like,
wow,

397
00:23:09.851 --> 00:23:13.570
this stuff is really important and there is a lot of important information so I

398
00:23:13.571 --> 00:23:15.250
kind of want it to get that message out.

399
00:23:15.680 --> 00:23:17.720
<v 0>Cool.
So,
so in talking about the information,</v>

400
00:23:17.930 --> 00:23:22.400
sometimes you get an answer and you go,
wow,
that totally makes sense.

401
00:23:22.401 --> 00:23:27.080
And sometimes you get an answer that is sort of contrary to what you would think

402
00:23:27.710 --> 00:23:32.320
the data would predict.
And so there's a lot of psychology involved in this can,

403
00:23:32.350 --> 00:23:36.910
can you talk a little bit about how often that sort of happens that,
um,

404
00:23:36.950 --> 00:23:40.430
the answer is what you would expect and how do you kind of come to your

405
00:23:40.431 --> 00:23:44.570
conclusions when you get an answer that's totally different than what you,

406
00:23:44.600 --> 00:23:45.470
you thought would be?

407
00:23:46.820 --> 00:23:49.980
<v 3>Yeah,
I think,
uh,
frequently things,</v>

408
00:23:51.350 --> 00:23:53.780
things are just different than I expected.
So I did,

409
00:23:53.781 --> 00:23:58.040
I've done a lot of research and anxiety and I thought anxiety was highest in New

410
00:23:58.040 --> 00:24:02.090
York City.
Like,
cause I'm from New Jersey,
right?
Like I'm from New Jersey,

411
00:24:02.480 --> 00:24:04.610
right outside New York City.
I'm like Jewish.
It was always like,
oh,

412
00:24:04.611 --> 00:24:08.090
you're like a neurotic woody Allen type.
I always thought I was really anxious,

413
00:24:08.091 --> 00:24:11.300
neurotic type in it.
That was like a normal,
uh,

414
00:24:11.900 --> 00:24:14.570
and that that would be like when we were all way more anxious than everybody

415
00:24:14.571 --> 00:24:17.780
else.
But then you see in the search data,
uh,
that is not true at all.

416
00:24:17.781 --> 00:24:20.400
That anxiety is highest in Kentucky in you,

417
00:24:20.720 --> 00:24:24.830
upstate and Maine and rural areas way more than urban areas and places with

418
00:24:24.831 --> 00:24:28.670
lower levels of education more than higher levels of education.
Uh,
so I don't,

419
00:24:28.671 --> 00:24:32.060
yeah,
I think it just,
just over and over again the data,
I think we're,

420
00:24:32.070 --> 00:24:33.410
we're just basically blind to the world.

421
00:24:33.410 --> 00:24:36.530
I think a lot of times we think whatever's going on in our own head is much more

422
00:24:36.531 --> 00:24:41.120
general than it is a,
or we just like,
we jumped to conclusions very,
very fast.

423
00:24:41.490 --> 00:24:43.370
Uh,
so that's why I think tradition.

424
00:24:43.400 --> 00:24:46.550
I think the data is usually different than I expect.
I mean,

425
00:24:46.551 --> 00:24:48.980
sometimes it's not like if you search where,
uh,

426
00:24:49.220 --> 00:24:52.700
where do people search for Lakers?
It's like Los Angeles and you probably didn't.

427
00:24:53.330 --> 00:24:56.900
Okay.
That makes sense.
It's like,
I'm not going to like,
uh,
like,
yeah,

428
00:24:56.901 --> 00:24:57.651
shock the world,

429
00:24:57.651 --> 00:25:01.040
like the Lakers and more popular in Minneapolis then Los Angeles,

430
00:25:01.041 --> 00:25:01.874
like that's not true.

431
00:25:02.730 --> 00:25:05.010
<v 0>So is that,
helps control your anxiety because you're like,
wow,</v>

432
00:25:05.011 --> 00:25:07.800
those people in Maine,
they've got to like way worse than I have it here.

433
00:25:08.240 --> 00:25:11.690
<v 3>Yeah,
no,
I think it,
I,
it just,
it's just like changed how I thought about things.</v>

434
00:25:11.691 --> 00:25:15.050
I'm like,
Oh wow,
that's not,
yeah,
it's just an even like,

435
00:25:15.620 --> 00:25:18.290
and that it's even like very particular types of anxiety,

436
00:25:18.291 --> 00:25:21.560
like anxiety about death.
People make searches anxiety about death.
And I'm like,

437
00:25:21.561 --> 00:25:25.340
oh,
that's like the woody Allen neurotic like intellectual thing.

438
00:25:25.341 --> 00:25:26.001
But it's not true.

439
00:25:26.001 --> 00:25:29.150
It's like there are more of these searches and Kentucky and Alabama and

440
00:25:29.151 --> 00:25:30.560
Louisiana.
So it's,
uh,

441
00:25:30.590 --> 00:25:34.070
it's just kind of interesting and I definitely do to kind of go through the

442
00:25:34.071 --> 00:25:35.840
world differently than I did before.

443
00:25:36.270 --> 00:25:39.480
<v 0>That's super interesting.
So,
so you ask a lot of questions.
I mean,</v>

444
00:25:39.481 --> 00:25:42.630
we just talked about,
you know,
how many Americans are really racist,

445
00:25:42.631 --> 00:25:45.480
who cheats on their taxes,
does advertising work.

446
00:25:45.481 --> 00:25:48.480
But I'm sure there are a lot of things that got left out in the book.

447
00:25:48.660 --> 00:25:52.170
So can you talk a little bit about sort of how you go about choosing your topics

448
00:25:52.440 --> 00:25:55.620
and if there was anything interesting that maybe didn't make the cut because

449
00:25:55.621 --> 00:25:57.960
there's so many interesting sort of factoid.

450
00:25:59.020 --> 00:26:02.970
<v 3>Yeah.
Uh,
I don't,
I don't really,
there's not a science to,</v>

451
00:26:03.610 --> 00:26:06.820
to choosing a topic and just kind of go around the world and talks a lot of

452
00:26:06.821 --> 00:26:10.030
people and read a lot of things and then one thing sparks a question or you play

453
00:26:10.031 --> 00:26:14.980
around with data and it goes in a totally other direction.
Uh,
so I don't,
so,
uh,

454
00:26:15.670 --> 00:26:17.410
so I think that didn't make it,

455
00:26:17.470 --> 00:26:21.400
I have like all this stuff and anxiety that's just not like ready for prime time

456
00:26:21.401 --> 00:26:22.810
that got caught.
Like I could have had,

457
00:26:22.840 --> 00:26:25.270
I wanted to have like three chapters on anxiety cause I just find it really,

458
00:26:25.271 --> 00:26:26.104
really interesting.

459
00:26:26.170 --> 00:26:29.370
So that's like a whole other book that we can look forward to.
Yeah.
Yeah.
That's,

460
00:26:29.440 --> 00:26:34.060
that's,
that's,
that's maybe my next book,
but,
uh,
but,
uh,
yeah,
like,

461
00:26:34.190 --> 00:26:38.500
so I've done this research on if you break down the minute by minute when people

462
00:26:38.501 --> 00:26:41.110
make searches for panic attacks,
uh,

463
00:26:41.320 --> 00:26:43.560
and it's not surprising when do people make search for panic attack?

464
00:26:43.560 --> 00:26:47.070
Like 2:00 AM 3:00 AM right there like in a cold sweat in the middle of the
night.

465
00:26:47.550 --> 00:26:51.000
Uh,
but like what,
what this basically means is that now,

466
00:26:51.001 --> 00:26:53.640
because this data we know on every given night,

467
00:26:54.420 --> 00:26:57.690
we have a pretty good estimate of how many people are having panic attacks in

468
00:26:57.691 --> 00:27:01.950
New York City and Boston and Los Angeles and Indianapolis.

469
00:27:01.980 --> 00:27:03.750
And we can basically say,
okay,

470
00:27:03.751 --> 00:27:06.600
why are on some nights a lot of people having panic attacks or like,

471
00:27:06.601 --> 00:27:08.370
is there something that happened three days before,

472
00:27:08.371 --> 00:27:09.840
two days before the day before.

473
00:27:10.170 --> 00:27:14.220
So there's really just so much information here that it's,
yeah,

474
00:27:14.221 --> 00:27:15.690
I think it's revolutionary,

475
00:27:15.691 --> 00:27:18.120
but there's some people criticized me for being too grandiose.

476
00:27:19.550 --> 00:27:22.860
<v 0>That's great.
You got to sell it.
Right.
Um,
yeah,</v>

477
00:27:22.861 --> 00:27:26.240
I think that data is totally fascinating.
I agree with you and,

478
00:27:26.241 --> 00:27:31.230
and that it applies to so many things.
Um,
so back to the election a little bit,

479
00:27:31.231 --> 00:27:31.680
you talked,

480
00:27:31.680 --> 00:27:35.070
you talked a little bit about that and you kind of out smarted Nate silver.

481
00:27:35.071 --> 00:27:38.460
Would you say that,
that,
that might be correct,
and in some ways,

482
00:27:40.910 --> 00:27:43.860
um,
are you especially,
so I'm trying to get him to agree to,

483
00:27:43.861 --> 00:27:48.110
let me write a column for is,
are you a,

484
00:27:48.130 --> 00:27:50.020
are you looking at data now and what,

485
00:27:50.021 --> 00:27:53.430
what are you seeing in terms of trends in politics now that Trump is in office?

486
00:27:53.431 --> 00:27:58.230
Like what's the followup to what we heard you say about this sort of wave of

487
00:27:58.231 --> 00:28:01.290
populism and the thing about the election?

488
00:28:01.380 --> 00:28:04.680
So there's a question just starting with politics.
Can you predict,

489
00:28:05.180 --> 00:28:09.230
<v 3>uh,
elections with Google searches?
Because if he locked it,
the survey,
uh,</v>

490
00:28:09.260 --> 00:28:12.120
surveys this year,
they didn't really work so well,
right?
Every,

491
00:28:12.240 --> 00:28:16.070
the surveys told us that Hillary Clinton was gonna win and then Donald Trump
won.

492
00:28:16.071 --> 00:28:19.700
So is there a way to use all this information on the Google where people are so

493
00:28:19.701 --> 00:28:24.440
honest to predict elections and it's not so simple?

494
00:28:24.650 --> 00:28:27.470
Uh,
the top white,

495
00:28:27.471 --> 00:28:32.430
most people have tried to do it initially was,
uh,
you just see are you,

496
00:28:32.720 --> 00:28:34.520
are people searching for a candidate more.

497
00:28:34.820 --> 00:28:37.370
So if people are searching for Trump war,
they're going to go Trump.

498
00:28:37.640 --> 00:28:40.010
And if people are searching for Clinton more and they're going to go Clinton.

499
00:28:40.520 --> 00:28:44.330
And you can probably think like yourself why that wouldn't really work,
right?

500
00:28:44.331 --> 00:28:47.330
Because you're not saying whether you like the candidate or you hate the

501
00:28:47.331 --> 00:28:47.730
candidate.

502
00:28:47.730 --> 00:28:50.780
You could search for Trump because you like it or because you hate them.

503
00:28:51.290 --> 00:28:53.420
So one of the indicators,
uh,

504
00:28:53.421 --> 00:28:56.180
I've found with Stuart Gabriel who is a professor at Ucla,

505
00:28:56.720 --> 00:29:00.980
we found there is an indicator that has surprising the predictive power and it's

506
00:29:00.981 --> 00:29:04.640
the order in which people search candidates,
which is pretty interesting.

507
00:29:04.700 --> 00:29:06.140
It's basically,
uh,

508
00:29:07.010 --> 00:29:11.030
if people like 25% of the searches people make with Clinton also include the

509
00:29:11.031 --> 00:29:13.190
word Trump.
So people search for Clinton,

510
00:29:13.191 --> 00:29:17.740
Trump polls or Clinton Trump debate or Clinton Trump election.
But,

511
00:29:18.510 --> 00:29:21.410
but if people search Clinton before Trump,

512
00:29:21.560 --> 00:29:24.850
they're much more likely to go Clinton.
And if they search Trump before Clinton,

513
00:29:24.870 --> 00:29:27.500
they're much more likely to go Trump.
So it's like selling subconscious.

514
00:29:27.501 --> 00:29:29.690
If you're a Trump supporter,
you're much more likely to,

515
00:29:29.820 --> 00:29:32.690
to think of it as a Trump Clinton election.
If you're a Clinton supporter,

516
00:29:32.691 --> 00:29:35.960
you're much more likely to think the reverse.
And then you could see that,
uh,

517
00:29:35.961 --> 00:29:37.390
in general,
uh,

518
00:29:37.430 --> 00:29:41.060
Trump came before Clinton more and then this was more true,

519
00:29:41.690 --> 00:29:45.520
a key Midwest battleground states,
uh,
which,
which he,
where he,
he got,

520
00:29:45.550 --> 00:29:47.410
he got victorious.
But I think it's going to take many,

521
00:29:47.411 --> 00:29:51.000
many more years of analyzing this data before we know exactly how to weight in

522
00:29:51.010 --> 00:29:54.230
and stuff.
But there definitely is a lot of information in this data,
uh,

523
00:29:54.231 --> 00:29:56.440
that will be missed by other sources.

524
00:29:56.830 --> 00:29:59.400
<v 0>That'll give you something to do for a long time to come.
Yeah.</v>

525
00:29:59.460 --> 00:30:02.260
There's no shortage of things to do with this data.
Cool.

526
00:30:02.261 --> 00:30:06.430
I'm going to invite everyone here to start lining up at the mic if you have

527
00:30:06.431 --> 00:30:11.010
questions.
So please come on up.
Um,
and in the meantime,
I'll,

528
00:30:11.011 --> 00:30:15.730
I'll ask you one more question.
Um,
so some of the data it gets personal,
right?

529
00:30:15.731 --> 00:30:19.150
You talk about being a mets fan or,
um,
or

530
00:30:21.530 --> 00:30:26.400
just,
just a little,
um,
or you know,
like you talk about,
um,

531
00:30:26.680 --> 00:30:30.460
what women should do on a day to like get a second day.
Um,

532
00:30:30.490 --> 00:30:35.440
so how much of this like came from sort of your own personal life and uh,

533
00:30:35.890 --> 00:30:40.490
you know,
is,
is that like a big way that you sort of select topics and,

534
00:30:40.540 --> 00:30:44.710
and does that make it feel like more justified in your everyday experiences?

535
00:30:45.510 --> 00:30:50.010
<v 3>Uh,
no,
no,
a few.
A few of the topics where my personal interests,</v>

536
00:30:50.011 --> 00:30:51.690
a lot of the sports stuff.
Oh,

537
00:30:51.691 --> 00:30:56.090
it was my personal curiosity to be a baseball player.
Yes.
Basketball player.

538
00:30:56.140 --> 00:31:01.020
I would have settled for a baseball,
but uh,
yeah,
but I think,
uh,
I think,

539
00:31:01.050 --> 00:31:02.310
but like the racism stuff,

540
00:31:02.340 --> 00:31:05.430
I don't think I'm particularly racist or I did stuff on gay.

541
00:31:05.460 --> 00:31:07.290
There are a lot of closeted gay man.
I'm not gay,

542
00:31:07.291 --> 00:31:11.100
but I thought that was really interesting too.
So I don't know.
That's not all.
Uh,

543
00:31:11.690 --> 00:31:14.620
it's a,
it's probably like 20% personal face,
but

544
00:31:15.310 --> 00:31:18.180
<v 0>fair enough.
Okay.
I'm going to turn it over to you guys</v>

545
00:31:18.390 --> 00:31:19.970
<v 4>at the mic and</v>

546
00:31:22.760 --> 00:31:26.720
just be
okay.

547
00:31:27.710 --> 00:31:29.420
<v 0>So I was struck by something you said,</v>

548
00:31:29.421 --> 00:31:34.190
which was that people are partially more honest online and with Google searches

549
00:31:34.191 --> 00:31:35.510
because they have an incentive,

550
00:31:35.511 --> 00:31:38.110
they're trying to get something from their search.
Um,

551
00:31:38.150 --> 00:31:41.810
but then some of the searches that you cited with,
you know,

552
00:31:41.890 --> 00:31:46.520
the racism research and some of the others,
like I hate Muslims and you know,

553
00:31:46.521 --> 00:31:48.770
things that didn't seem to be a question,

554
00:31:48.771 --> 00:31:52.070
which you would think as the incentive with a search to what do you attribute

555
00:31:52.071 --> 00:31:55.190
that type of honesty because it sounds like those,

556
00:31:55.280 --> 00:31:59.300
those people are not at the very least seeking additional information on a
topic,

557
00:31:59.301 --> 00:32:01.940
which is our usual definition of a search.

558
00:32:02.530 --> 00:32:05.970
<v 3>Yeah,
that's a great question.
That's a so,
yeah.
So there,</v>

559
00:32:05.980 --> 00:32:09.070
there are two reasons that Google is honest.
The one is the incentive thing.

560
00:32:09.071 --> 00:32:13.870
So if you're talking about a sexless marriage or racist jokes or information on

561
00:32:13.871 --> 00:32:15.880
voting where they're sensitive topics,

562
00:32:15.881 --> 00:32:19.270
but you need the information and then there's this other class of searches,

563
00:32:19.271 --> 00:32:21.080
but totally shocked me.
Uh,

564
00:32:21.220 --> 00:32:23.200
like it was one of those surprising things in the data,

565
00:32:23.230 --> 00:32:27.220
but it happens in big numbers.
People just confess things to Google,

566
00:32:28.240 --> 00:32:33.070
so they say,
I hate my boss,
or like I'm sad or I'm drunk.

567
00:32:33.071 --> 00:32:38.000
And it's just like,
okay,
like why are you,
why are you,

568
00:32:38.390 --> 00:32:41.660
why are you telling?
And I think it is,
I think a lot of it is a,

569
00:32:42.350 --> 00:32:47.180
I think a lot of it is,
uh,
it's kinda similar to the confessional,

570
00:32:47.181 --> 00:32:49.650
right?
The Catholic and p like you don't just somethings about it.

571
00:32:49.660 --> 00:32:52.970
I think people treat it as like,
like a confessional.
You don't,

572
00:32:53.120 --> 00:32:54.500
there's no purpose to sang things,

573
00:32:54.501 --> 00:32:57.110
but there's something about saying things that you wouldn't tell anybody else.

574
00:32:57.500 --> 00:33:01.930
Uh,
and it's,
it,
it's,
people seem to use it in that way.
Uh,
and yeah,
it's,

575
00:33:01.931 --> 00:33:05.900
it's really surprising.
My favorite example is,
uh,
that,
uh,

576
00:33:06.590 --> 00:33:11.280
what I talk about how men are insecure about their bodies.
Men.

577
00:33:11.330 --> 00:33:14.600
So what we usually think that woman a w they'd like.

578
00:33:14.601 --> 00:33:17.600
Bali insecurity is predominantly a female thing and it is majority female.

579
00:33:17.601 --> 00:33:20.870
But if you look around the web,
like it's close,
it's like 55,

580
00:33:20.871 --> 00:33:25.360
45 a woman versus men and men are really insecure about their bodies as well.
Uh,

581
00:33:25.670 --> 00:33:30.020
and a lot of it is insecurity,
not surprisingly focuses on one particular body,

582
00:33:30.021 --> 00:33:31.570
part in the size of it in particular.

583
00:33:32.450 --> 00:33:37.270
Like men asks more questions about their whatever then then,

584
00:33:37.580 --> 00:33:39.040
and then any other body part.

585
00:33:39.080 --> 00:33:43.370
But then one of their top questions they ask about this body part is how big is

586
00:33:43.371 --> 00:33:44.204
my penis,

587
00:33:46.790 --> 00:33:50.720
<v 0>which is the strangest search engines.
Right.
Understand.
Yeah.
So it's a straight,</v>

588
00:33:50.721 --> 00:33:51.330
so it was a stranger.
Yeah.

589
00:33:51.330 --> 00:33:53.700
<v 3>Search ever.
So people make like the weirdest searches on Google.</v>

590
00:33:53.701 --> 00:33:54.534
It's very bizarre.

591
00:33:54.700 --> 00:33:58.420
<v 0>Follow up question if it,
if I may.
Um,
have you done any sort of,</v>

592
00:33:58.421 --> 00:34:02.890
or is there a data correlation analysis between,
you know,

593
00:34:02.891 --> 00:34:03.491
for example,

594
00:34:03.491 --> 00:34:08.491
people confessing on various forums and reddit and sort of places where you

595
00:34:08.501 --> 00:34:13.480
would confess?
I think with,
uh,
an expectation of other people like saying Oh,

596
00:34:13.481 --> 00:34:17.320
me too.
Um,
and like searches.

597
00:34:17.740 --> 00:34:22.600
Like do they spike at the same time maybe,
or are they localized in the same way?

598
00:34:22.601 --> 00:34:23.440
Geographically?

599
00:34:23.600 --> 00:34:25.100
<v 3>I haven't seen it.
It's a good,
it's a good question.</v>

600
00:34:25.101 --> 00:34:28.190
I think that some of the Google searches,
I think that is it that you kind of,

601
00:34:28.820 --> 00:34:32.780
if you type on sad you might get message boards where people are saying,

602
00:34:32.781 --> 00:34:34.150
oh I'm sad too.
Uh,

603
00:34:34.190 --> 00:34:38.000
so it might be that you're looking for people who are feeling the same way as

604
00:34:38.001 --> 00:34:42.830
you are in just by saying it in that way you get that information.
Thank you.

605
00:34:44.660 --> 00:34:47.360
<v 2>Hi,
thanks for coming in today.
So when I do a search,</v>

606
00:34:47.390 --> 00:34:49.820
often I'll have one thing in mind,
but as I'm typing this search,

607
00:34:49.821 --> 00:34:51.350
I'll see the auto complete suggestion.

608
00:34:51.680 --> 00:34:53.780
And even though it's like not at all what I've meant to search,

609
00:34:53.781 --> 00:34:58.280
I might out of curiosity,
complete that and just have that search anyway.

610
00:34:59.720 --> 00:35:02.510
I'm wondering how you account for that or how do you know that's true Vo,

611
00:35:02.511 --> 00:35:04.100
if a lot of people do that,
you know,

612
00:35:04.160 --> 00:35:06.000
cause you don't want to count those like double count,
right.

613
00:35:07.060 --> 00:35:09.460
<v 3>It's not great.
You don't like downtown.
I think it makes like a,</v>

614
00:35:10.150 --> 00:35:13.960
I don't know what percent of searches somebody Google probably knows what

615
00:35:13.961 --> 00:35:17.410
percent of searches are you use auto complete.
I don't know that number.

616
00:35:17.500 --> 00:35:21.020
I don't think it's publicly available,
but uh,
I think uh,

617
00:35:21.370 --> 00:35:25.060
it makes small differences.
It could like magnify small,

618
00:35:25.061 --> 00:35:27.400
different magnify initial differences,
right?

619
00:35:27.430 --> 00:35:30.880
If people initially have to search something to get there but then the winner

620
00:35:30.881 --> 00:35:34.030
will get potentially a more and more popular.

621
00:35:34.031 --> 00:35:38.580
So I don't think it totally changes the level of like the ranking of things,

622
00:35:38.581 --> 00:35:42.090
but it can make a bigger difference between the top and the other ones.
Okay.

623
00:35:42.091 --> 00:35:45.840
So overall you're saying that,
um,
when you do look at the top search results,

624
00:35:45.870 --> 00:35:49.320
you do keep in mind to like scale down a little bit just to account for that?

625
00:35:49.620 --> 00:35:51.750
Yeah,
and I think the regional ones are pretty,

626
00:35:51.780 --> 00:35:53.960
the regional differences are still pretty meaningful,
uh,

627
00:35:54.120 --> 00:35:57.300
since from my understanding,
they don't,
uh,
they don't get,

628
00:35:57.420 --> 00:36:01.410
they don't on average get very different.
Autocompletes Nicolas,
thank you.

629
00:36:03.530 --> 00:36:04.363
<v 1>Right</v>

630
00:36:04.720 --> 00:36:09.280
<v 5>on your early chart that you had the comparison with racism and correlation to</v>

631
00:36:09.281 --> 00:36:10.114
Donald Trump,

632
00:36:11.020 --> 00:36:14.920
my question would be what was that compared to Hillary?

633
00:36:14.980 --> 00:36:19.090
Because was that a flip or was it very similar in the two charts?

634
00:36:19.980 --> 00:36:23.140
<v 3>Uh,
so that was the primary voting.
Yes.
So it wasn't,</v>

635
00:36:23.170 --> 00:36:25.600
so you're saying what happened to general election?
Yes.
Yeah.

636
00:36:25.601 --> 00:36:28.570
I think the general elections a little more complicated because,
uh,

637
00:36:30.290 --> 00:36:33.890
it's like Democrats and Republicans differ,
differ in general.

638
00:36:33.891 --> 00:36:36.800
So it's not the most of the,
well,

639
00:36:36.830 --> 00:36:40.310
the reason that one area it goes Democrat in one area goes Republican,
it's just,

640
00:36:40.311 --> 00:36:43.190
it's more Democrat and Republican area in general.

641
00:36:43.540 --> 00:36:45.650
So you can really want to compare it to previous elections.

642
00:36:46.140 --> 00:36:49.700
And that's also a little complicated because then Obama had this racism problem

643
00:36:49.701 --> 00:36:54.130
and then Trump,
I think what it's basically that Trump,
uh,
an,
uh,

644
00:36:54.140 --> 00:36:58.490
not a Republican candidate who didn't appeal to,

645
00:36:58.880 --> 00:37:01.960
uh,
w who did an appeal to,
uh,

646
00:37:02.210 --> 00:37:07.210
racism and the way that I think Trump did a would have lost a lot of votes in

647
00:37:07.221 --> 00:37:11.480
park quite in places relative to Obama in parts of the country with a lot of

648
00:37:11.481 --> 00:37:13.670
racist searches.
But Trump didn't lose those votes.

649
00:37:13.940 --> 00:37:16.490
So places like West Virginia and western Pennsylvania and eastern Ohio,

650
00:37:16.491 --> 00:37:20.210
if it was a norm,
if it was a different Republican candidate,
those areas,

651
00:37:20.211 --> 00:37:23.130
they didn't like Obama,
but they would have come.
Uh,
but,

652
00:37:23.160 --> 00:37:26.150
but they would have necessarily,
they would have maybe come back to a democrat.

653
00:37:26.210 --> 00:37:28.370
But because Trump appealed to that same,

654
00:37:29.240 --> 00:37:31.520
those same feelings that made them mad about it,
Obama,

655
00:37:31.521 --> 00:37:32.720
they went Trump's way again.

656
00:37:33.400 --> 00:37:37.580
<v 5>Okay.
Because of the variation between the primary and the general election then</v>

657
00:37:37.581 --> 00:37:39.750
probably has a great deal of effect

658
00:37:41.500 --> 00:37:45.190
that wouldn't have been in that,
the correlation between that,

659
00:37:45.260 --> 00:37:48.350
those two charts might have been quite different if they were done at the same

660
00:37:48.351 --> 00:37:49.184
time.

661
00:37:49.280 --> 00:37:50.390
<v 3>Yeah.
Well,
like I said,</v>

662
00:37:50.391 --> 00:37:55.220
the general elections a little more complicated because most of it is the map of

663
00:37:55.340 --> 00:37:59.090
any particular general election is very similar year to year.

664
00:38:00.230 --> 00:38:02.480
So really you just want to see the changes in behavior,

665
00:38:02.500 --> 00:38:05.990
the changes and votes in a general election.
Okay.
Very good.
Thank you.
Dot.
Thanks.

666
00:38:07.940 --> 00:38:08.773
<v 1>Okay.</v>

667
00:38:08.930 --> 00:38:10.940
<v 6>Yeah.
Let's go on a quick question.</v>

668
00:38:10.941 --> 00:38:14.300
You mentioned earlier how people lie on surveys and we have the product,

669
00:38:14.301 --> 00:38:15.470
Google consumer surveys.

670
00:38:15.650 --> 00:38:20.000
So I was wondering if there's any type of techniques or things you've seen from

671
00:38:20.001 --> 00:38:22.140
data collection via surveys like Okcupid,

672
00:38:22.190 --> 00:38:24.320
answer publicly versus answer privately.

673
00:38:24.590 --> 00:38:28.130
Have you seen anything that either yielded more consistent or reliable results?

674
00:38:28.340 --> 00:38:29.870
Uh,
from a survey based format,

675
00:38:31.100 --> 00:38:35.410
<v 3>so they're all right.
So I'm mine surveys 10 feet better than phone surveys,</v>

676
00:38:35.411 --> 00:38:37.750
for example,
because I think talking to someone,

677
00:38:38.120 --> 00:38:42.430
it makes people that much more dishonest.
Uh,

678
00:38:42.431 --> 00:38:47.260
I think I,
there are all these,
there are all these games that,
uh,

679
00:38:47.650 --> 00:38:51.640
uh,
that scholars have been vented to try to trick people into telling the truth.

680
00:38:52.080 --> 00:38:57.010
Uh,
and you can kind of look them up.
It's random digit,
a random digit,

681
00:38:57.070 --> 00:38:59.180
uh,
examples or,
uh,

682
00:39:00.370 --> 00:39:02.290
I list list experiments.

683
00:39:02.291 --> 00:39:06.130
They basically ask people 10 questions like one of them is,
is embarrassing,

684
00:39:06.131 --> 00:39:09.670
and the other RN and ask how many is true are true yes or no,

685
00:39:09.880 --> 00:39:12.700
and then can kind of back out and then ask another group that except the

686
00:39:12.701 --> 00:39:16.200
embarrassing one.
Kind of come back out the difference,
if that makes sense.
Uh,

687
00:39:16.210 --> 00:39:20.130
but my understanding is that these don't really work.
Uh,

688
00:39:20.140 --> 00:39:23.120
although a lot of papers have been written about it that,
uh,
that,
that,

689
00:39:23.320 --> 00:39:24.101
that they don't really work.

690
00:39:24.101 --> 00:39:27.010
I think Google consumer surveys has another pretty huge problem,

691
00:39:27.680 --> 00:39:32.110
which is that people just answer randomly.
Uh,
because,
uh,

692
00:39:32.140 --> 00:39:35.590
like at least if you're answering a phone survey or you've gone through the time

693
00:39:35.591 --> 00:39:39.110
to not in it,
not hang off right away,
uh,
you,

694
00:39:39.150 --> 00:39:41.410
you might give a take it somewhat seriously,

695
00:39:41.411 --> 00:39:44.890
but I think a Google consumer surveys,
a big percentage of the people don't know,

696
00:39:45.610 --> 00:39:47.810
don't give a serious answer.
Yes.
Sorry.

697
00:39:47.910 --> 00:39:49.530
<v 6>Or for the APP,
the screener questions,</v>

698
00:39:49.531 --> 00:39:52.800
they always answer whatever they think that we want to screen it.
Yeah,
exactly.

699
00:39:52.810 --> 00:39:56.550
Yeah.
Then also by the way,
the buck amplification study you worked on,

700
00:39:56.700 --> 00:39:57.690
the clients really liked it.

701
00:39:58.060 --> 00:40:02.330
<v 3>Oh yeah.
That was another thing that I,
I work,
yeah.
Oh,
okay.</v>

702
00:40:04.290 --> 00:40:08.580
<v 6>Are you concerned at all about the Hawthorne effect by talking about what we can</v>

703
00:40:08.581 --> 00:40:09.960
learn from the Google search results?

704
00:40:09.961 --> 00:40:13.500
Maybe people won't be as willing to put their dirty laundry out on Google.

705
00:40:15.630 --> 00:40:17.430
<v 3>Yeah.
I don't know if it's what we can learn.</v>

706
00:40:17.640 --> 00:40:19.800
There definitely are changes in behavior.

707
00:40:19.801 --> 00:40:23.160
So this is all based on the idea that people will tell anything to Google.

708
00:40:23.850 --> 00:40:28.850
But someone did a paper where they compared Google searches before and after a

709
00:40:29.041 --> 00:40:34.041
Snowden leak and they found that there was a big drop in searches that were

710
00:40:35.191 --> 00:40:40.170
either sensitive.
So like,
uh,
you know,
on sensitive topics or embarrassing topics.

711
00:40:40.410 --> 00:40:40.621
Actually,

712
00:40:40.621 --> 00:40:44.010
my favorite thing from the paper is that they had a list of them that they,
uh,

713
00:40:44.070 --> 00:40:46.470
they had to figure out what an embarrassing search.

714
00:40:46.770 --> 00:40:50.550
So they asked people in Mechanical Turk like to rag the embarrassment of

715
00:40:50.551 --> 00:40:53.700
searches and one of the them they got classified is embarrassing,
uh,

716
00:40:53.701 --> 00:40:54.600
was Nickelback

717
00:40:58.290 --> 00:41:01.990
and they found that those types of surgeons did drop including Nickelback after,

718
00:41:04.020 --> 00:41:08.250
after a Snowden Snowden's revelation.
So yeah,
I don't think,
yeah,

719
00:41:08.251 --> 00:41:10.140
it may be that,
uh,

720
00:41:10.380 --> 00:41:14.370
that this is a brief period of time where we can really see until the human

721
00:41:14.371 --> 00:41:19.260
psyche and uh,
and then it will all die down or something.
I hope not.

722
00:41:19.261 --> 00:41:23.820
But,
uh,
I think I always emphasize that like,
everyone's like,
have you,

723
00:41:23.821 --> 00:41:27.660
has your search behavior changed since you've done this research?

724
00:41:28.080 --> 00:41:31.910
And it hasn't at all because I'm like,
like nobody knows my sir.
Like,

725
00:41:32.480 --> 00:41:35.630
I don't,
don't,
I don't see why it,
why it should affect me.

726
00:41:35.631 --> 00:41:40.520
If they know that someone in,
uh,
Brooklyn is making a search or something,

727
00:41:40.521 --> 00:41:41.750
it doesn't seem like a,

728
00:41:42.520 --> 00:41:43.353
<v 7>okay,</v>

729
00:41:43.370 --> 00:41:44.340
<v 8>if I was a racist,</v>

730
00:41:44.341 --> 00:41:48.180
I might not want to give my state of bed named by doing lots of racist searches.

731
00:41:48.480 --> 00:41:50.190
I don't know if I felt bad about being raised.

732
00:41:50.450 --> 00:41:55.000
<v 3>Yeah.
So it could be like,
yeah,
that's like kind of a subtle,
I'm,</v>

733
00:41:55.100 --> 00:41:57.440
that's definitely bad.
Definitely.
It would be a,
I mean,

734
00:41:57.441 --> 00:42:00.920
a problem in polls as well.
So,
uh,
but I don't know if that's,

735
00:42:01.650 --> 00:42:02.760
<v 7>yeah.
Thanks.</v>

736
00:42:06.870 --> 00:42:11.130
<v 8>I,
um,
have you thought about comparing the Google search results?</v>

737
00:42:11.140 --> 00:42:14.580
Was there like a,
uh,
uh,

738
00:42:14.610 --> 00:42:17.850
social network resolves or posts,
um,

739
00:42:18.390 --> 00:42:23.390
are the social network results tend to be more or as honest as Google search

740
00:42:24.510 --> 00:42:29.340
terms or even more honest because people use that as a way to express themselves

741
00:42:29.640 --> 00:42:33.740
and not necessarily,
uh,
uh,

742
00:42:34.050 --> 00:42:34.740
exposing,

743
00:42:34.740 --> 00:42:39.740
exposing their true identity or people stay at all who was such as ours tend to

744
00:42:42.121 --> 00:42:42.954
be more on his,

745
00:42:43.280 --> 00:42:45.930
<v 3>no,
I've done no question.
Google searches are more,</v>

746
00:42:45.931 --> 00:42:47.880
are more honest than social media.

747
00:42:47.881 --> 00:42:52.881
So I think that social media data you can't really trust because it's even in

748
00:42:54.301 --> 00:42:57.840
some sense worth than surveys because you have an incentive to make yourself

749
00:42:57.841 --> 00:43:02.690
look good to impress your friends.
Uh,
so if you compare,
for example,

750
00:43:03.500 --> 00:43:07.440
one example I talk about is the popularity of the national enquirer versus the

751
00:43:07.441 --> 00:43:11.520
Atlantic monthly that uh,
the national enquirer actually cells,

752
00:43:11.580 --> 00:43:16.440
it's kind of a low brow trashy magazine that actually sells more copies than the

753
00:43:16.441 --> 00:43:19.320
Atlantic monthly every year.
But on a social media,

754
00:43:19.321 --> 00:43:22.920
the Atlantic monthly is 45 times more popular because everyone wants their

755
00:43:22.921 --> 00:43:25.590
friends to think they're really,
really intellectual.
Right.
Uh,

756
00:43:25.620 --> 00:43:28.720
and then it actually is interesting if you compare the,
uh,

757
00:43:28.750 --> 00:43:33.440
the social media posts in Google search post,
uh,

758
00:43:33.540 --> 00:43:35.070
Google searches.
It's a,

759
00:43:35.071 --> 00:43:39.780
so if you look at the top ways people describe their husband on social media,

760
00:43:40.110 --> 00:43:44.550
the top five descriptors.
My husband is a,
it's my husband is amazing.

761
00:43:44.551 --> 00:43:47.310
So cute,
awesome.
The best and my best friend,

762
00:43:48.360 --> 00:43:52.140
which is probably misleading view of marriage to some degree at least.

763
00:43:52.560 --> 00:43:55.450
And then if you do Google the top five complete,

764
00:43:55.680 --> 00:43:58.260
my husband is on Google with salsa.
Kind of like a weird search to make,

765
00:43:58.261 --> 00:44:02.370
but people do make,
my husband is uh,
one of them is also awesome.

766
00:44:02.670 --> 00:44:07.650
So that checks out.
But the other ones are gay.
A jerk meaning annoying.

767
00:44:08.690 --> 00:44:11.680
So it's really a,
yeah,
it's kind of interesting.
I think you got,

768
00:44:12.240 --> 00:44:16.410
I'm not sure how if one of them's right or wrong on marriage otherwise,
but uh,

769
00:44:16.470 --> 00:44:19.020
it's definitely very different because I'm one year trying to impress your

770
00:44:19.021 --> 00:44:22.580
friends and in one year not,
thank you very much better.
Just

771
00:44:25.980 --> 00:44:26.761
looking at that map,

772
00:44:26.761 --> 00:44:31.530
is there a way to tell or do you tell the difference between two regions where

773
00:44:31.531 --> 00:44:32.364
like

774
00:44:32.700 --> 00:44:36.560
<v 0>there are like one where there's a lot of people doing those?
For example,</v>

775
00:44:36.580 --> 00:44:40.860
racist searches or another area where it's like fewer people doing a lot of

776
00:44:40.861 --> 00:44:43.260
searches per person.
Like do you account for multiple switches?

777
00:44:44.190 --> 00:44:49.020
<v 3>Uh,
yeah.
No,
it's a good question.
No,
I,
well that data is just not made available.</v>

778
00:44:49.100 --> 00:44:53.100
Uh,
I dunno if anyone at Google hazard,
but uh,
it's,
it's uh,

779
00:44:53.101 --> 00:44:55.610
it's not made available except what Google does in the end.

780
00:44:55.611 --> 00:44:58.560
Google trends and they take out if someone makes a lot of searches in a short

781
00:44:58.561 --> 00:45:03.090
period of time,
it just counts as one search.
So it's not like someone just,

782
00:45:03.270 --> 00:45:03.811
you know,
in a,

783
00:45:03.811 --> 00:45:06.960
in a half hour search this thing over and over again that it's driving the

784
00:45:06.961 --> 00:45:09.300
results.
I think it is,
it is an interesting comparison.

785
00:45:09.301 --> 00:45:13.570
I think in some ways it's an advantage of this data relative to surveys because

786
00:45:13.571 --> 00:45:15.990
I think surveys that we usually think of,
not always,

787
00:45:15.991 --> 00:45:18.900
but usually think of as yes or no as binary.

788
00:45:18.901 --> 00:45:22.980
Either you are racist or you are and racist,
but there clearly are degrees of it.

789
00:45:22.981 --> 00:45:26.220
Right?
You're more,
you're more or less likely.
Uh,

790
00:45:26.660 --> 00:45:29.220
so it's on something that is an advantage that includes people who've done it a

791
00:45:29.221 --> 00:45:33.990
lot of times because they're probably even more even more racist.
So,
uh,
yeah.

792
00:45:36.010 --> 00:45:40.660
<v 0>Cool.
Okay.
I just have a few more.
Thank you everybody.
Um,</v>

793
00:45:41.200 --> 00:45:42.460
those were great questions.

794
00:45:43.120 --> 00:45:47.530
So I know you spent a lot of time thinking about naming your book and went

795
00:45:47.531 --> 00:45:49.270
through a bunch of sort of different names.

796
00:45:49.271 --> 00:45:52.780
Can you talk a little bit about the process of naming a book and how you came to

797
00:45:52.781 --> 00:45:53.680
everybody lies?

798
00:45:54.420 --> 00:45:59.040
<v 3>Uh,
well,
so yeah,
so that's why I initially brought up the,</v>

799
00:45:59.520 --> 00:46:01.790
that ridiculous question than men asked,
uh,

800
00:46:01.920 --> 00:46:03.720
because that's what I wanted to call my book.

801
00:46:06.960 --> 00:46:09.750
It's called how big is my penis?
What Google search I was going with that,

802
00:46:10.470 --> 00:46:14.220
what Google searches or feel about human nature,
but then on my is like,

803
00:46:14.640 --> 00:46:18.780
people would be embarrassed to buy that in an airport.
Uh,
so I,

804
00:46:19.740 --> 00:46:23.450
I couldn't,
I couldn't title with that,
but,
um,
I think,
uh,

805
00:46:23.670 --> 00:46:26.490
I though I still kind of think it,
that was a better title,

806
00:46:27.630 --> 00:46:28.470
although I do like this,

807
00:46:28.471 --> 00:46:31.710
this title I didn't think of that was this was that they came up with this
title.

808
00:46:31.830 --> 00:46:36.360
And I think it's good.
I like it.
I like it.
I think it gets to,

809
00:46:36.420 --> 00:46:37.260
gets a lot of the point.

810
00:46:37.870 --> 00:46:40.210
<v 0>What about some of the other data sources you look at?</v>

811
00:46:40.211 --> 00:46:44.860
I mean obviously you look at Facebook,
you look at porn hub,
you look at,
you know,

812
00:46:44.920 --> 00:46:46.990
a variety of different sources.

813
00:46:47.650 --> 00:46:50.380
How do those rank compared to Google and,
uh,

814
00:46:50.381 --> 00:46:54.760
are you planning on looking more at other sources or is Google for you sort of

815
00:46:54.761 --> 00:46:55.594
the old tough

816
00:46:56.490 --> 00:46:57.323
<v 3>place to be?</v>

817
00:46:57.490 --> 00:47:02.020
I think Google's just way better than all the other ones because the honesty and

818
00:47:02.021 --> 00:47:05.920
then it just Kinda,
it's so universal.
A lot of these data sources,
Twitter,

819
00:47:05.921 --> 00:47:08.080
like who uses Twitter?
It's a very selected sample,

820
00:47:08.081 --> 00:47:12.010
but pretty much everybody uses Google.
Uh,
and then just any topic,

821
00:47:12.460 --> 00:47:13.630
there's information there,

822
00:47:13.780 --> 00:47:18.750
like can be a music or race or sexuality or you know,

823
00:47:19.010 --> 00:47:22.450
any,
any,
anything.
There's probably at least some insights.
Uh,

824
00:47:22.510 --> 00:47:25.830
[inaudible] pornhub is pretty specific.
Yeah.
And like,
you know,

825
00:47:25.831 --> 00:47:27.610
or like they're kind of more one offs.

826
00:47:27.611 --> 00:47:31.310
You can find something interesting I in the,
in the,
in the Dataset,

827
00:47:31.330 --> 00:47:35.200
but it's not as comprehensive with googling and find something interesting on

828
00:47:35.201 --> 00:47:39.010
any topic or thing.
So it's more of a,
I think it's a,
a more,
uh,

829
00:47:39.090 --> 00:47:43.000
more like orders of magnitude better than the other data sources.

830
00:47:43.100 --> 00:47:45.440
<v 0>Well they like to hear that that keeps us in business.</v>

831
00:47:45.441 --> 00:47:49.330
So what you mentioned before that you kind of have,

832
00:47:50.220 --> 00:47:50.610
<v 3>okay.</v>

833
00:47:50.610 --> 00:47:55.020
<v 0>Grandiose,
I actually think it's,
it's um,
are really sort of enlightening,</v>

834
00:47:55.080 --> 00:47:55.913
um,

835
00:47:56.100 --> 00:48:00.420
kind of sense of where data science is going for both philosophy and medicine,

836
00:48:00.421 --> 00:48:04.290
sort of how it can be used to really help people in the future.

837
00:48:04.530 --> 00:48:07.080
And so I was sort of wondering if you had any advice,

838
00:48:07.081 --> 00:48:09.030
I know we have a lot of data scientists out there,

839
00:48:09.031 --> 00:48:11.280
both at Google and in the world.

840
00:48:11.490 --> 00:48:14.430
What advice would you give them in terms of data science,

841
00:48:14.431 --> 00:48:16.050
what they should be doing and where it's going?

842
00:48:17.070 --> 00:48:20.130
<v 3>I think it's,
I,
well,
I got credit.
I just think it's a really,</v>

843
00:48:20.131 --> 00:48:22.890
really exciting area because,
uh,

844
00:48:22.980 --> 00:48:26.640
just because of all this new data that's out there that,
uh,
you know,

845
00:48:26.641 --> 00:48:30.450
I think like the insights that are coming are going to be huge.

846
00:48:30.451 --> 00:48:34.830
I would say that some of that,
uh,
obviously if people work at Google,

847
00:48:34.831 --> 00:48:38.300
part of their job is probably going to be a lot of,
a decent percentage of,

848
00:48:38.380 --> 00:48:41.400
of Google employees,
uh,
have to get people to Click on ads,

849
00:48:41.401 --> 00:48:45.930
which is not necessarily the most,
uh,
interesting,
uh,
in my opinion,
uh,

850
00:48:45.990 --> 00:48:49.080
use of data,
but a is important for Google's business.
But like,

851
00:48:49.081 --> 00:48:53.520
I definitely think,
I definitely think the health stuff is,
uh,

852
00:48:53.790 --> 00:48:58.590
is really valuable.
There's a,
there was a study,
how much time do we,
you're fine,

853
00:48:58.630 --> 00:49:01.580
I'll go ahead.
So,
uh,
so there was this study,
uh,
that,
uh,

854
00:49:02.100 --> 00:49:06.120
was done by Microsoft researchers in collaboration with Professor at Columbia

855
00:49:06.600 --> 00:49:10.710
and they,
uh,
study,
uh,
pancreatic cancer.
I talk about in the book,

856
00:49:10.980 --> 00:49:14.870
they cite pancreatic cancer and they basically could figure out that they,
they,

857
00:49:15.120 --> 00:49:18.930
they studied individuals whose a anonymized deidentified individuals,

858
00:49:18.960 --> 00:49:21.750
their search behavior over time.
And they said that,

859
00:49:21.770 --> 00:49:25.680
and they could guess based on someone searches that they maybe got a diagnosis

860
00:49:25.681 --> 00:49:28.410
of pancreatic cancer cause people titling like duck just diagnosed with

861
00:49:28.411 --> 00:49:31.290
pancreatic cancer.
What do I do?
Or like very,

862
00:49:31.291 --> 00:49:33.120
very clear searches that they get pancreatic cancer.

863
00:49:33.460 --> 00:49:38.460
And then what they did is they compared these people to another group of users

864
00:49:39.091 --> 00:49:41.250
who are similar and never had such a diagnosis.

865
00:49:41.740 --> 00:49:46.210
And then they looked at the searches in the months leading up to that diagnosis,

866
00:49:46.250 --> 00:49:49.050
the symptoms that people were searching and they said,

867
00:49:49.051 --> 00:49:54.051
what symptoms do people search that tells us in two or three months they're

868
00:49:54.391 --> 00:49:57.510
going to have a diagnosis of pancreatic cancer.
And the key to that,

869
00:49:57.520 --> 00:50:00.830
the reason this study's potentially powerful is if you get the earlier you get

870
00:50:00.831 --> 00:50:05.310
it,
pancreatic cancer diagnosis,
the higher your chances of survival.

871
00:50:05.730 --> 00:50:09.330
So I,
uh,
so they,
and they using this data,

872
00:50:09.331 --> 00:50:13.470
they found really subtle patterns to the point that if you search for

873
00:50:13.471 --> 00:50:16.140
indigestion before abdominal pain,

874
00:50:16.650 --> 00:50:19.080
that's a risk factor for pancreatic cancer.

875
00:50:19.380 --> 00:50:21.810
Whereas if you search just indigestion alone,

876
00:50:21.900 --> 00:50:25.050
that's not a risk factor for pancreatic cancer because they had so much data,

877
00:50:25.051 --> 00:50:26.730
they could pick up these really subtle patterns.

878
00:50:27.200 --> 00:50:30.000
I'm kind of scared whenever I hear the story as like whenever I,

879
00:50:30.050 --> 00:50:33.260
right after I read that paper I thought,
I thought I had indigestion fall,

880
00:50:33.261 --> 00:50:36.080
but abdominal pain that's going to be in the anxiety.
But yeah,

881
00:50:36.680 --> 00:50:38.900
so I don't want everyone to go home and be like,
Oh crap,

882
00:50:39.220 --> 00:50:41.780
I've got pancreatic cancer.
But,
uh,
I think,

883
00:50:41.900 --> 00:50:46.900
I think that's like a really impressive way to do medicine relative to what we

884
00:50:47.181 --> 00:50:50.080
usually do.
That that's a pattern that I talked to the researchers.

885
00:50:50.090 --> 00:50:53.470
Doctors don't know that series of symptoms,
like if,
you know,

886
00:50:53.490 --> 00:50:56.870
thank half of the way that doctors now diagnose diseases,

887
00:50:56.871 --> 00:51:01.010
it's not as sophisticated as like a time series of people symptoms over time and

888
00:51:01.011 --> 00:51:04.610
a huge sample to pick up patterns like that.
So like,

889
00:51:04.640 --> 00:51:08.220
so I'm kind of a lot of people after that said,
uh,

890
00:51:08.600 --> 00:51:10.160
so what are the HEPA building implications?

891
00:51:10.161 --> 00:51:14.570
Should a search company like if they know this information,
should they tell you,

892
00:51:15.020 --> 00:51:16.200
you know,
right below your button,

893
00:51:16.220 --> 00:51:20.450
I feel lucky you have pancreatic cancer or you might have pancreatic cancer.

894
00:51:20.451 --> 00:51:24.770
Like that's kind of a depressing thing to see on a search engine.
But I think so.

895
00:51:24.771 --> 00:51:27.020
I think that they,
they should,
but they also,

896
00:51:27.050 --> 00:51:29.660
but that you should be able to opt into it.
Say if I,

897
00:51:29.661 --> 00:51:33.680
if I'm the type that wants information,
like you should be able to say,
hey,

898
00:51:33.681 --> 00:51:37.880
like if you can mind these patterns and potentially if I have some series of

899
00:51:37.881 --> 00:51:42.710
symptoms that tell me that I'm at risk of a disease and if I am told that I'll

900
00:51:42.711 --> 00:51:45.860
increase my odds,
I want to be told that.
But I go even further.

901
00:51:45.920 --> 00:51:49.940
I think that these businesses now have an obligation to be researching this,

902
00:51:50.360 --> 00:51:52.820
to be Tensley find patterns of symptoms,

903
00:51:52.821 --> 00:51:56.810
because I'm kind of pissed that there may be diseases that just because not

904
00:51:56.811 --> 00:52:01.160
enough data scientists,
uh,
at the,
at these companies are looking into it.

905
00:52:01.400 --> 00:52:05.140
They may be able to pay,
they may be picking up patterns and by symptoms,
uh,

906
00:52:05.190 --> 00:52:07.370
that could potentially saved my life.
So I think that,

907
00:52:07.400 --> 00:52:09.230
like I go even more extreme,

908
00:52:09.231 --> 00:52:13.820
and I think that there's an ethical obligation of companies who have this data

909
00:52:14.000 --> 00:52:18.080
to be really figuring out the health,
the health,
the health stuff there.

910
00:52:18.550 --> 00:52:21.690
<v 0>So big implications.
And with that,
uh,</v>

911
00:52:21.910 --> 00:52:24.700
let's give a round of applause.

