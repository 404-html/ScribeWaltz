1
00:00:10,960 --> 00:00:14,020
Thank you. Thanks for the
invitation to say come here. Um,

2
00:00:14,740 --> 00:00:19,280
so I'll just talk to you
about the company's soapbox.
Loves to start with. Um,

3
00:00:19,720 --> 00:00:22,630
we do children's speech
recognition technologies,

4
00:00:23,560 --> 00:00:27,280
so that way.
Um,

5
00:00:27,370 --> 00:00:32,370
so 2017 and 2018, we're like
huge years for voice assistance.

6
00:00:32,420 --> 00:00:34,110
Um, across the world. The stars,

7
00:00:34,210 --> 00:00:39,210
you can say 2015 when Amazon first release
the Alexis to the u s market and it's

8
00:00:39,251 --> 00:00:42,190
taking a long time to get to this
side of the ocean. I said the same.

9
00:00:42,191 --> 00:00:45,740
We've seen newcomers come on, but
more recently we know that, you know,

10
00:00:45,850 --> 00:00:50,650
Google came on the heels
of Alexa apple this year,

11
00:00:50,710 --> 00:00:54,190
uh, Facebook or talking about a device. By
the end of this year, they postponed up.

12
00:00:54,191 --> 00:00:56,640
It's still a flexes coming out.
Um,

13
00:00:57,790 --> 00:00:59,430
what's changed over the
last couple of years,

14
00:00:59,680 --> 00:01:02,850
people are beginning to see the
utility of voice assistance, um,

15
00:01:02,980 --> 00:01:07,060
a couple of years ago, um, you know,
speech recognition technologies,

16
00:01:07,080 --> 00:01:11,040
we're probably working
on the 80% accuracy. Um,

17
00:01:11,440 --> 00:01:14,560
so it meant they're still
quite frustrating to work with,

18
00:01:14,561 --> 00:01:18,610
so people begin just to kind of doubted
we would ever really take off. But, um,

19
00:01:18,670 --> 00:01:21,760
myself has been working in this area for
over 20 years and was kind of a case of

20
00:01:21,761 --> 00:01:26,710
one steep learning, a vast volumes of data
and gps and all that came together. Um,

21
00:01:26,740 --> 00:01:29,550
we could see the scale of us and
we could see the utility. Um,

22
00:01:29,860 --> 00:01:33,160
I spent some time working
on IBM a long time ago. Um,

23
00:01:33,220 --> 00:01:37,510
IBM research and back in 2004 we actually
saw a demo of the voice assistant.

24
00:01:37,840 --> 00:01:38,520
But how,
you know,

25
00:01:38,520 --> 00:01:42,160
the idea of somebody would be driving
in the car and they want to go to a

26
00:01:42,161 --> 00:01:44,080
restaurant and the car would ask them,
you know,

27
00:01:44,081 --> 00:01:49,081
the system would ask about what kind of
restaurant did you want to go to and get

28
00:01:49,211 --> 00:01:52,900
some feedback on realtime feedback
on traffic and direct them to or go.

29
00:01:53,050 --> 00:01:55,870
And it was 2003,
I think it has an a four.

30
00:01:56,710 --> 00:02:01,270
So when I was there and I was research
assistant at the time that was imminent,

31
00:02:01,330 --> 00:02:03,940
you know, this is what they were
going to put in cars and you know,

32
00:02:04,240 --> 00:02:07,810
are stunned with a year or two and it's
actually taken this long to get real

33
00:02:07,811 --> 00:02:11,470
voice assistants. I've really utility
and what's happened there, it's accuracy.

34
00:02:11,680 --> 00:02:13,180
It's actually less frustrating.

35
00:02:13,380 --> 00:02:15,970
So if you tried it a few years
ago was extremely frustrated.

36
00:02:15,971 --> 00:02:18,790
They've got it wrong too often.
That's all it wasn't though.

37
00:02:18,791 --> 00:02:20,620
It's getting them all the time,
but just too often.

38
00:02:20,770 --> 00:02:24,730
That was a frustration experience and
that's what's changed in recent years.

39
00:02:25,380 --> 00:02:27,850
But it's not just the voice assistance,
right?

40
00:02:28,630 --> 00:02:33,520
It's there's any number of these companies
that are doing seriously doing speech

41
00:02:33,521 --> 00:02:34,890
recognition technologies.
Right.

42
00:02:35,200 --> 00:02:40,200
So I think tech crunch things late 2016
said there was like 29 companies in the

43
00:02:40,660 --> 00:02:43,030
u s and learned in speech recognition
stuff. Not Counting in Asia.

44
00:02:43,240 --> 00:02:43,841
It's not Canton,

45
00:02:43,841 --> 00:02:47,020
European companies and snuff cans
and what's happening in 2018 right.

46
00:02:47,070 --> 00:02:48,190
That was a year and a half ago.

47
00:02:49,120 --> 00:02:51,290
But all these companies are
doing spectacular things.

48
00:02:51,291 --> 00:02:55,180
So you're seeing voice assistance.
You know, when we had the first,

49
00:02:55,181 --> 00:02:58,990
it was Siri and it was okay Google
and it was on your personal device.

50
00:02:59,140 --> 00:03:02,140
They've taken a leap from the
personal device into the home.

51
00:03:02,660 --> 00:03:06,250
And that's really interesting from my
perspective what's happened there. Um,

52
00:03:06,280 --> 00:03:07,113
you know,

53
00:03:07,120 --> 00:03:11,350
it's something we all have to pay close
attention to because it's just the tip

54
00:03:11,351 --> 00:03:13,240
of the iceberg. I mean, people think, wow,

55
00:03:13,241 --> 00:03:15,970
look at this amazing technology and
what's going to do for fun. You know,

56
00:03:15,971 --> 00:03:19,450
to my mind, this is just the
start. It would be, you know,

57
00:03:19,660 --> 00:03:22,330
even from our own experiences
of the last couple of years,

58
00:03:22,800 --> 00:03:25,450
it'd be on your fridge,
your TV,

59
00:03:25,451 --> 00:03:28,210
your car to be in a vending machine.
It's,

60
00:03:28,390 --> 00:03:30,430
it's not just that it's a voice assistant.

61
00:03:30,460 --> 00:03:34,270
It's actually going to be the
stage that speech technology,

62
00:03:34,271 --> 00:03:39,100
voice technology has gone to replace
keyboards, touch a swipe gesture,

63
00:03:39,390 --> 00:03:42,850
all of these things because
it's the natural interface
is how humans communicate.

64
00:03:42,851 --> 00:03:45,670
So it only makes sense that of
technology can do it. So that stage,

65
00:03:45,880 --> 00:03:48,250
why are we all still typing and clicking?
And you know,

66
00:03:48,290 --> 00:03:52,600
we have to do that because of the
technology wasn't there to begin with. Um,

67
00:03:53,260 --> 00:03:56,630
but what happens with that is when we
actually start replacing interface and the

68
00:03:56,631 --> 00:03:58,660
voice becomes the norm,

69
00:03:59,140 --> 00:04:03,730
you have to recognize the fact that you've
put it in the home and children will

70
00:04:03,731 --> 00:04:07,030
use it. I'm industrial city given
it's not about what you want,

71
00:04:07,031 --> 00:04:11,240
whatever you bought, you volunteer to take
something and put it into the home. Um,

72
00:04:12,940 --> 00:04:16,600
it will engage children because
number one, it's fun. You know what?

73
00:04:16,601 --> 00:04:18,550
Child isn't going to try
it the moment you do it,

74
00:04:18,560 --> 00:04:21,130
they're going to do it
immediately after you. Um, what?

75
00:04:21,131 --> 00:04:24,260
It's also easier for them than clicking
and typing cause la times or even free

76
00:04:24,340 --> 00:04:26,830
illiterate or they're
struggling with dexterity.

77
00:04:27,430 --> 00:04:30,640
It's actually a great interface for
children as well. And it's already there.

78
00:04:30,641 --> 00:04:33,080
So the question is how do we handle it?
What's the utility?

79
00:04:33,081 --> 00:04:37,030
So in every place that you could see
an adult using speech technology,

80
00:04:37,060 --> 00:04:39,640
other than dictating
your business documents,

81
00:04:39,970 --> 00:04:42,490
you're going to see that
children one years or two lights,

82
00:04:42,491 --> 00:04:44,580
especially when you take it
outside of the office environment,

83
00:04:45,510 --> 00:04:46,750
you're going to see that they're using it.

84
00:04:47,320 --> 00:04:51,520
Other application areas we see
for it in particular is, um,

85
00:04:52,630 --> 00:04:55,720
and what we started with actually soapbox
loves originally our mission statement

86
00:04:55,721 --> 00:04:58,300
back in 2013 was more around education.

87
00:04:58,720 --> 00:05:01,910
So if you think about how
a child learns to read, uh,

88
00:05:01,990 --> 00:05:06,400
the most effective way a child learns
Sweden's one to one oral guided reading,

89
00:05:06,401 --> 00:05:10,960
right? So that means, um, and helpful
adult working alongside a child.

90
00:05:11,170 --> 00:05:12,360
And if you think, do you ever watch, uh,

91
00:05:12,370 --> 00:05:16,270
a parent or a teacher teaching
a child to read? They listen.

92
00:05:16,720 --> 00:05:19,870
They correct their prompt thing,
courage in the assess, right?

93
00:05:19,871 --> 00:05:23,770
And it's that one to one that actually
it's a bit more than 10 minutes of the

94
00:05:23,770 --> 00:05:27,320
day, but between 10 and 20 minutes a day
is recommended for a child to get to, um,

95
00:05:27,400 --> 00:05:31,180
you know, to accelerate the truant
decent level. But in the world today,

96
00:05:31,750 --> 00:05:36,430
literacy levels of stagnated over the
last 10 years in the u s 60% of kids at

97
00:05:36,431 --> 00:05:41,080
age eight are not reading at a proficient
level and a child that doesn't read at

98
00:05:41,081 --> 00:05:44,710
a proficient level at age eight, it's a
key indicator of their future success.

99
00:05:44,740 --> 00:05:48,760
It's quite a key moment because that's
when most kids stuck learning to read and

100
00:05:48,761 --> 00:05:53,380
start reading to learn.
So if you are struggling before that,

101
00:05:53,920 --> 00:05:57,070
it's going to get harder and harder
to catch up with your peers. Um,

102
00:05:57,140 --> 00:06:02,140
so one of the ways when we'd been looking
at this over the years is that if you

103
00:06:02,691 --> 00:06:06,920
know the one way to increase the region,
it's one to one engagement.

104
00:06:07,160 --> 00:06:10,850
You're not suddenly going to find funding
to stick more teachers into homes or

105
00:06:10,880 --> 00:06:15,020
suddenly free your parents' time or get
private tutors or you can do is provide

106
00:06:15,680 --> 00:06:19,190
a scalable cost effective solution that
speech technology that can actually act

107
00:06:19,191 --> 00:06:23,090
as that helpful adult listening.
As a child reads the cat sat on the mat,

108
00:06:23,510 --> 00:06:27,500
I cracked in prompting and assessing and
do that personalized learning journey

109
00:06:27,501 --> 00:06:28,334
for them.

110
00:06:28,350 --> 00:06:31,760
And the same goes for English language
learning or other language learning

111
00:06:31,761 --> 00:06:35,000
depending on where you're
from. Um, the same thing.

112
00:06:35,001 --> 00:06:37,430
It's guided or reasons
for personalized learning.

113
00:06:37,431 --> 00:06:39,980
Personalized education is a
huge area in the world today,

114
00:06:40,190 --> 00:06:43,340
but actually nobody has a solution really
for reading and they can do it from us

115
00:06:43,341 --> 00:06:45,380
and science and junk food for the cat.
Do it for reading.

116
00:06:45,630 --> 00:06:46,880
And you can't do it
from language learning.

117
00:06:47,320 --> 00:06:51,650
And the statistics if I for
reading is actually masking a big,

118
00:06:52,070 --> 00:06:55,100
much worse problem for a
disadvantaged children,

119
00:06:55,101 --> 00:06:57,770
an immigrant children because those
kids are actually two years behind their

120
00:06:57,771 --> 00:07:02,060
peers, um, in in studies
piece of studies. Um,

121
00:07:02,510 --> 00:07:04,880
so there are the kids who actually want
me would benefit the most from these

122
00:07:04,881 --> 00:07:06,810
type of technologies
that are cost effective.

123
00:07:06,811 --> 00:07:11,060
They're scalable and all their required
as a cheap android device on it means to,

124
00:07:11,061 --> 00:07:15,980
um, I mean it's one of those devices. So
that's one of the areas we're focused on.

125
00:07:16,300 --> 00:07:16,730
Um,

126
00:07:16,730 --> 00:07:19,880
another area that we've had a huge amount
of inbound interest in social robots.

127
00:07:19,881 --> 00:07:22,880
It's called a robotics for fun and
entertainment. Get them to move front,

128
00:07:22,881 --> 00:07:25,520
but also social route robots engaged,
um,

129
00:07:25,710 --> 00:07:28,850
engage them in an educational way
or lots of times kids with learning

130
00:07:28,851 --> 00:07:31,640
difficulties as well. Um, but again,

131
00:07:31,670 --> 00:07:35,330
voice technology to all
to have that meaningful
interaction is really important.

132
00:07:35,610 --> 00:07:38,990
Um, the more fun stuff like in Vr, which
also can, you know, can be education,

133
00:07:38,991 --> 00:07:43,340
but what else can we just
pure entertainment and then
just pure gaming as well.

134
00:07:43,520 --> 00:07:46,810
I mean, where you see voice
technology like for adults coming in,

135
00:07:47,060 --> 00:07:48,830
the solutions for children's while.
Makes Sense.

136
00:07:50,540 --> 00:07:54,950
So I'm just going to show you a quick
video here on this is one of the reasons

137
00:07:54,951 --> 00:07:59,210
why are focusing the last five
years have been somewhat different.

138
00:07:59,450 --> 00:08:03,200
Um, I'll just play this for you
and you'll understand what I mean.

139
00:08:03,290 --> 00:08:08,290
So this is when you stick
a voice assistant into the
hall and what can go wrong?

140
00:08:14,790 --> 00:08:19,490
I can't find the song to good Tucker
outreach,

141
00:08:19,580 --> 00:08:22,010
Huh?
Laughter.

142
00:08:24,840 --> 00:08:25,673
Oh

143
00:08:27,090 --> 00:08:27,923
Wow.

144
00:08:30,710 --> 00:08:31,543
Oh

145
00:08:32,020 --> 00:08:33,390
Mommy,
can you talk to play wheel?

146
00:08:33,420 --> 00:08:37,270
You want to hear a station for porn
detected porno region, the hot chick,

147
00:08:37,271 --> 00:08:41,850
amateur girl pussy. Anal dildo wrinkles.

148
00:08:43,420 --> 00:08:44,830
So it's a funny, cute video, right?

149
00:08:44,831 --> 00:08:49,660
But it actually indicates kind of more
serious problems they have with when you

150
00:08:49,661 --> 00:08:53,900
put advice into Tom, where's the filter?
All right. You know, you, you can say I,

151
00:08:53,980 --> 00:08:57,360
it's not designed for, not marked as a
kid, but I didn't put it there for kids,

152
00:08:57,361 --> 00:08:59,460
but kids are going to use them then
we have to face up to that. Right?

153
00:09:00,420 --> 00:09:04,230
So some of the folks of our company over
the last five years has been accuracy

154
00:09:04,231 --> 00:09:05,370
for children's voices.

155
00:09:06,500 --> 00:09:07,230
Okay.

156
00:09:07,230 --> 00:09:09,840
Systems environments that are
fit for kids on data privacy.

157
00:09:11,610 --> 00:09:15,940
So accuracy. Why his speech
technology difficult for children. Um,

158
00:09:17,280 --> 00:09:21,420
most systems be built with adult
data modeling, adult behaviors,

159
00:09:22,050 --> 00:09:26,760
physical and otherwise. Um, but children
are physically different from adults,

160
00:09:27,330 --> 00:09:29,550
particularly in the focal trough there.
Tenor and shorter.

161
00:09:29,910 --> 00:09:33,270
So where men's voices might be lower,
women's are overlapping but higher.

162
00:09:33,271 --> 00:09:37,680
And then that's a tween teenager is that
kind of overlap on women as they get

163
00:09:37,681 --> 00:09:38,514
younger,

164
00:09:38,670 --> 00:09:43,670
the physical differences get further
and further away from an adult.

165
00:09:43,981 --> 00:09:47,940
And that happens right? At Age 12, on
the younger you get, the more different,

166
00:09:47,941 --> 00:09:51,660
it is not actually just visiting causes
confusion about what actually has been

167
00:09:51,661 --> 00:09:56,280
said. The behavior is on the other hand
are just wildly different kids or was the

168
00:09:56,281 --> 00:10:00,570
unpredictable, the, you know, they
stole her, they repeat the shape,

169
00:10:00,571 --> 00:10:04,140
they whisper this thing like,
you know, you know, they um,

170
00:10:04,590 --> 00:10:09,150
they punctuate their words and no fluff
more than that done. They're more fluent,

171
00:10:09,180 --> 00:10:13,170
older, uh, siblings and
other children and adults.

172
00:10:13,530 --> 00:10:16,080
That actually is a real problem for end
point detection if anybody's ever worked

173
00:10:16,081 --> 00:10:19,500
in that way. Um, you know, because
they don't just behave the same way.

174
00:10:19,501 --> 00:10:24,240
And what you end up doing is seeing
that a system that has been designed for

175
00:10:24,241 --> 00:10:26,910
adults are using out of date
or modeling of behavior.

176
00:10:26,940 --> 00:10:29,400
It's extremely frustrating for a
child and the younger the child,

177
00:10:29,401 --> 00:10:30,480
the more frustrating it is,

178
00:10:30,720 --> 00:10:34,110
has a negative effect on brand in some
ways because people associate that

179
00:10:34,111 --> 00:10:35,250
technology.
They don't,

180
00:10:36,090 --> 00:10:38,810
a lot of people don't process the fact
that it's just different voices different.

181
00:10:38,880 --> 00:10:41,220
They just think the public doesn't
working very well. And, you know,

182
00:10:41,221 --> 00:10:45,080
I had a pain in my head for my
youngest son asking me to, uh,

183
00:10:45,160 --> 00:10:49,860
can you ask Alexa? And when
we got our first store, you
know, for the first one. So

184
00:10:51,360 --> 00:10:55,440
what we've done is spend the last five
years concentrating on, excuse me,

185
00:10:56,510 --> 00:10:57,343
mmm.

186
00:10:58,040 --> 00:10:59,840
Pacific Child Pacific models.

187
00:10:59,841 --> 00:11:04,720
So what we did was look at data from a
children's young was for but the day.

188
00:11:04,721 --> 00:11:09,330
So it was a conversational
prompted red, um, spontaneous,

189
00:11:09,600 --> 00:11:13,350
um, and build models that were
very specific to young children.

190
00:11:13,440 --> 00:11:17,250
We spend time studying
how children converse, had
children's speak to technology,

191
00:11:17,780 --> 00:11:20,400
um, the variants and not, and how
do you cope with that? And Heidi,

192
00:11:20,401 --> 00:11:23,140
you build the system specifically
designed for children. Uh,

193
00:11:23,310 --> 00:11:26,550
we collected data in real
world environments. So
that meant, you know, when,

194
00:11:27,090 --> 00:11:31,000
you know where children are and they're
in their homes and their schools and um,

195
00:11:31,560 --> 00:11:35,640
you too. So you can actually understand
the children don't, um, you know,

196
00:11:35,700 --> 00:11:39,900
they don't use technology in
a quiet lab like environment.

197
00:11:40,650 --> 00:11:44,880
And if you build your speech technology
on data, that's my techs in our lab,

198
00:11:44,881 --> 00:11:48,750
like a quiet environment. It will only
ever work in those environments. Um,

199
00:11:48,751 --> 00:11:49,980
so to move away from that,

200
00:11:49,981 --> 00:11:52,920
you have to be able to get away from the
headset and likes and get away from all

201
00:11:52,930 --> 00:11:53,141
that.

202
00:11:53,141 --> 00:11:56,430
And then I let children just be natural
with how they want to interact with the

203
00:11:56,470 --> 00:11:57,303
technology.

204
00:11:57,310 --> 00:12:01,210
And then it's more up to us to change
our technology and then the charge to

205
00:12:01,211 --> 00:12:04,650
change their behaviors because you won't
find a five year olds go modify their

206
00:12:04,651 --> 00:12:06,250
behavior as much as an adult will.

207
00:12:06,490 --> 00:12:08,450
And that's how we've been
getting away with a lot with um,

208
00:12:09,190 --> 00:12:12,360
voice technology and the assistance that
we know that adult sometimes modify the

209
00:12:12,361 --> 00:12:16,420
behavior is to get a response. Children
are less, uh, less likely to do so.

210
00:12:18,670 --> 00:12:23,650
So another issue is, is the system fit for
children? Um, and are they appropriate?

211
00:12:23,651 --> 00:12:27,610
So two examples.
I can give you this as um,

212
00:12:28,180 --> 00:12:29,390
Sarah Huckabee Sanders,

213
00:12:29,430 --> 00:12:34,090
the press secretary for
Donald Trump recently tweeted
that I, her three year old,

214
00:12:34,360 --> 00:12:38,160
um, ordered, uh, Batman on
Amazon. Alexa be compelled,

215
00:12:38,161 --> 00:12:40,550
she showed it is trying to show to us up,

216
00:12:40,670 --> 00:12:43,460
man up that device three times and
suddenly got ordered. So, you know,

217
00:12:43,780 --> 00:12:46,300
I call that somewhat in question
that the Ui works like that,

218
00:12:46,690 --> 00:12:48,940
but it kind of did flag up an issue.

219
00:12:49,540 --> 00:12:54,220
If a child uses a device that has
access to purchasing power, why is that?

220
00:12:54,270 --> 00:12:55,210
I linked to do it.

221
00:12:55,630 --> 00:12:58,570
That's not appropriate behavior for a
child interacting with a device in the

222
00:12:58,571 --> 00:13:03,460
home. Similarly, my daughter
was, she's eight now.

223
00:13:03,810 --> 00:13:08,200
Um, she was using my phone and,
and you know, I had it locked,

224
00:13:08,201 --> 00:13:11,220
but she got onto the Siri thing and she
was just, you know, sitting with me and,

225
00:13:11,221 --> 00:13:15,760
and using Siri task questions. Siri
misunderstood the, he said, bitch,

226
00:13:15,820 --> 00:13:19,510
she didn't, but my, my daughter was
shocked and showed me the phone,

227
00:13:19,511 --> 00:13:23,170
what the word is printed to
screen. And Syria replied with, oh,

228
00:13:23,171 --> 00:13:25,840
there's no need for that,
which is very amusing and nice,

229
00:13:25,841 --> 00:13:30,160
but why didn't it recognize that as a
child voice and not print them to screen?

230
00:13:30,780 --> 00:13:35,440
Um, so I think, you know, when you
consider the fact of the, you know,

231
00:13:35,620 --> 00:13:39,340
the first video with the
child's potentially accessing
inappropriate material,

232
00:13:39,610 --> 00:13:44,230
inappropriate lyrics, songs, uh,
purchasing power, um, you know,

233
00:13:44,290 --> 00:13:48,580
inappropriate words at potentially active
access in your contact list and doing

234
00:13:48,581 --> 00:13:49,640
video calling or wherever.

235
00:13:50,260 --> 00:13:52,960
What needs to happen is when we've
been working with clients to do is to

236
00:13:52,961 --> 00:13:57,280
recognize that the point
of the voice interaction,

237
00:13:57,281 --> 00:14:00,130
whether it's a child or whether
it's an adult and act appropriately,

238
00:14:00,310 --> 00:14:03,580
route the child to a
different environments, safe
child, safe environment,

239
00:14:03,840 --> 00:14:07,990
enough to the world wide web where they
can do an open search and such things.

240
00:14:08,140 --> 00:14:11,950
And that's important when we put these
devices in their homes and in the cars

241
00:14:11,951 --> 00:14:16,390
and then all the places that children
will access them. So data privacy,

242
00:14:16,391 --> 00:14:18,280
the really thorny issue of data privacy.

243
00:14:18,310 --> 00:14:22,120
This is obviously such a hot
topic in the last few weeks. Um,

244
00:14:22,510 --> 00:14:26,080
but interestingly the US are
way ahead of Europe on this.

245
00:14:26,100 --> 00:14:31,100
I'm going back to 2012 the US have a
cup of laws explicitly stated that voice

246
00:14:32,980 --> 00:14:37,090
was personally identifiable information,
much like video and images were.

247
00:14:37,450 --> 00:14:42,430
And therefore you needed to have explicit
permission from the parents to collect

248
00:14:42,431 --> 00:14:44,640
data. Right now, explicit,
it's very explicit.

249
00:14:44,641 --> 00:14:49,540
It's like using a credit card to make a
micropurchase or having the parent put

250
00:14:49,541 --> 00:14:51,420
in their email address,
email sent to parents.

251
00:14:51,421 --> 00:14:53,510
The parents have to thick consent
and then you have to remind them.

252
00:14:53,511 --> 00:14:57,450
But they could send like an written in
language that they can understand and um,

253
00:14:57,500 --> 00:15:00,950
it was very explicit and weren't right.
Um,

254
00:15:01,430 --> 00:15:05,240
both with the advent of, um, the, uh,

255
00:15:06,380 --> 00:15:11,250
uh, these voice assistance
in the home, the FTC, um,

256
00:15:11,270 --> 00:15:14,000
relaxed the rules only very
recently and said, okay,

257
00:15:14,660 --> 00:15:17,390
we understand that these
devices are in the home.

258
00:15:17,660 --> 00:15:22,490
So therefore if it replaces the voice,
replaces what they would have been typed,

259
00:15:22,850 --> 00:15:26,990
it's okay to use it. Um, for
only that purpose and songs,
it's deleted immediately.

260
00:15:27,260 --> 00:15:30,380
So it was great. So they, you know,
that meant in most people's minds, okay,

261
00:15:30,381 --> 00:15:31,320
we're good to use it in the home.

262
00:15:32,540 --> 00:15:37,220
But what was not considering was a
couple of issues is, um, you know,

263
00:15:37,940 --> 00:15:40,550
what happens on the backend.

264
00:15:41,570 --> 00:15:45,950
You collect data from a child, um,
is the data deleted immediately,

265
00:15:45,951 --> 00:15:49,310
which meant you need to get
for a child or not child data?

266
00:15:49,550 --> 00:15:51,230
Is the data to delete immediately?

267
00:15:51,231 --> 00:15:54,560
Is there a data extractor for that as
the data extract used for other purposes?

268
00:15:54,800 --> 00:15:56,180
What's that data used for?

269
00:15:56,450 --> 00:16:01,450
So while we can somewhat say that
we're addressing some of these issues,

270
00:16:02,510 --> 00:16:06,110
it has been very unclear to date
exactly what data has been collected,

271
00:16:06,111 --> 00:16:09,770
exactly what, when the data has been
deleted and what's the data used for.

272
00:16:09,950 --> 00:16:14,150
And that is because it's an exploding
area and the area's growing so quickly,

273
00:16:14,360 --> 00:16:16,580
it's often hard for the,
the laws.

274
00:16:16,581 --> 00:16:20,950
And the FTC did really struggle with
this and kind of came up very short, um,

275
00:16:21,350 --> 00:16:22,101
about what to do,

276
00:16:22,101 --> 00:16:26,000
what happens if you've can permission
to your child to use the device and the

277
00:16:26,001 --> 00:16:29,000
dick data's been collected with the
child's friend visits the house. You know,

278
00:16:29,001 --> 00:16:31,760
what happens to that data
that had been addressed. Um,

279
00:16:31,761 --> 00:16:34,980
what have you just take the device out
of the box and put it here. Um, you know,

280
00:16:35,300 --> 00:16:39,890
is everybody being sure that the data
has been deleted immediately and that's

281
00:16:39,891 --> 00:16:42,380
really a thorny issue.
So the FTC relaxed the room.

282
00:16:42,770 --> 00:16:46,450
So a lot of people now in gray water
gone. They think we were okay. We,

283
00:16:46,520 --> 00:16:51,380
the public or who are put that device
in the home are unsure when the data has

284
00:16:51,381 --> 00:16:55,730
been deleted. Exactly. The EU in the GDPR,

285
00:16:56,140 --> 00:17:00,070
the much fear Gdpr and 20, May,
2018 have not relaxed the room.

286
00:17:00,760 --> 00:17:01,220
Um,

287
00:17:01,220 --> 00:17:05,030
that means that data is not allowed to
be collected without explicit permission.

288
00:17:05,031 --> 00:17:07,190
So you take a device,
you put it out and put it in your home,

289
00:17:07,191 --> 00:17:08,960
you plug it in a child who uses it.

290
00:17:09,470 --> 00:17:13,610
Whereas the responsibility is
everybody immediately reacting,

291
00:17:14,450 --> 00:17:17,630
recognizing that a child has spoken
versus an adult and we're reacting

292
00:17:17,631 --> 00:17:20,630
appropriately.
So if people are got the problem here,

293
00:17:20,631 --> 00:17:25,631
is that because the FTC kind of took a
bit of a back step on the blind eye for a

294
00:17:26,210 --> 00:17:28,010
couple of years and
then it got sorted out.

295
00:17:29,120 --> 00:17:33,880
Ma is the idea that that you would
do the same as a little bit? Um,

296
00:17:33,920 --> 00:17:34,880
less clear.

297
00:17:35,460 --> 00:17:39,940
One reason why I would say that is
because last year the Cayla doll was, um,

298
00:17:40,580 --> 00:17:45,090
are recalled from the market in Germany
and not just what's a recalled was the,

299
00:17:45,180 --> 00:17:49,620
what Cambridge was that parents should
destroy the style because the DOL is

300
00:17:49,621 --> 00:17:54,360
listening to your children at all times
and sending the voice data to a company

301
00:17:54,361 --> 00:17:59,310
that has links to the u s military.
Yeah. That company was nuance, which,

302
00:17:59,311 --> 00:17:59,551
you know,

303
00:17:59,551 --> 00:18:02,040
it's a very reputable voice technology
company around for a long time and they

304
00:18:02,041 --> 00:18:04,680
have done Darpa projects.
So technically it was correct,

305
00:18:04,681 --> 00:18:07,560
but who the reaction from Germany was.

306
00:18:07,561 --> 00:18:12,260
So put off sets what we've seen already
in the FTC in the u s that I think it

307
00:18:12,450 --> 00:18:15,000
should give us all pause to say,
how are we doing this?

308
00:18:15,000 --> 00:18:16,170
How are we doing this appropriately?

309
00:18:16,500 --> 00:18:20,760
And I don't think that they're going
to see a blind eye. So in that case,

310
00:18:21,300 --> 00:18:25,520
so what we have to re envision how people
are using these technologies apart.

311
00:18:25,560 --> 00:18:29,220
What we do is we have a voice companies
and we have solutions to bed to help

312
00:18:29,221 --> 00:18:33,240
companies better comply with a
global data privacy regulations.

313
00:18:33,660 --> 00:18:35,550
So this is just on the company.
I mean I can,

314
00:18:35,610 --> 00:18:38,430
we can chat more about in a little while
before just just on what's happened

315
00:18:38,431 --> 00:18:41,540
with the company.
We don't start back in 2013 and 2018.

316
00:18:41,550 --> 00:18:44,640
We've raised a couple of
rounds of funding from um,

317
00:18:44,670 --> 00:18:47,620
privately and from the EU as well.
Um,

318
00:18:47,700 --> 00:18:50,820
and we've got some great coverage from
tech crunch and wires on the next Webinar

319
00:18:50,850 --> 00:18:55,350
in recent months as well.
So we were 10 at the end of the year.

320
00:18:55,351 --> 00:18:59,130
We're 13 as him from this month and then
we're scaling quite rapidly this year

321
00:18:59,131 --> 00:19:03,270
like you know, so I can leave it
there and thank you for listening.

322
00:19:11,560 --> 00:19:13,690
Thank you. Patricia. Overview.

323
00:19:13,720 --> 00:19:17,380
You talked a lot of both your company
as I want to take a few minutes talking

324
00:19:17,381 --> 00:19:19,630
with you. Yeah. Your,
your journey to the share,

325
00:19:19,870 --> 00:19:22,970
how you've gotten to where you've
gotten to here. Um, phenomenal here.

326
00:19:22,971 --> 00:19:27,580
The story 2013, um, pure
tech built in Ireland,

327
00:19:27,940 --> 00:19:31,240
a scaling company, so, so well
done on that, but maybe give some,

328
00:19:31,241 --> 00:19:34,300
a bit of your background.
I mean the,

329
00:19:34,301 --> 00:19:37,450
the journey today wrote up the,
the start to soapbox labs.

330
00:19:37,540 --> 00:19:38,690
Yeah, sure. Um,

331
00:19:38,950 --> 00:19:43,950
so I qualified as a software engineer
back in 97 some while ago and I spent a

332
00:19:45,550 --> 00:19:48,250
couple of years working as a software
engineer and worked on but on the signal

333
00:19:48,251 --> 00:19:53,251
processing if I 2000 I went back to
college to do a phd in speech recognition

334
00:19:53,381 --> 00:19:56,470
technology because, you know,
it was that, it was new.

335
00:19:56,471 --> 00:19:59,800
I mean we've been doing speech to
text since the 70s properly. Um,

336
00:20:00,280 --> 00:20:02,090
but it was so different what we do it,

337
00:20:02,110 --> 00:20:05,320
how we do it now and the volumes we do
it with an a on the approaches are so

338
00:20:05,321 --> 00:20:09,880
different than the ambition was
different. Um, but I spent time,

339
00:20:09,881 --> 00:20:12,220
I started a new CD but I
spent time I had in New York,

340
00:20:12,560 --> 00:20:17,560
I'm in Columbia University but then in
also in IBM research and the Yorktown

341
00:20:17,830 --> 00:20:20,590
Heights research facility.
And then when I finished my phd,

342
00:20:20,591 --> 00:20:24,310
I started in a bell labs,
which is now Nokia bell labs.

343
00:20:24,640 --> 00:20:29,080
And I spent seven years there
kind of working on research
for them more and more.

344
00:20:29,081 --> 00:20:33,070
As time went on into the commercialization
of research innovations. Um,

345
00:20:33,160 --> 00:20:37,840
I'm trying to, I was always
kind of pushing for new
technologies or new research.

346
00:20:37,841 --> 00:20:42,100
We should do a new products we
could bring to market. I'm saying,

347
00:20:42,610 --> 00:20:46,470
um,
in some ways kind of pitching ideas and,

348
00:20:46,471 --> 00:20:48,150
and value propositions.

349
00:20:48,160 --> 00:20:53,080
I'm trying to get resources and funding
to fund projects within the organization,

350
00:20:54,060 --> 00:20:57,640
but by 2013,
identify the fairly significant gap,

351
00:20:57,970 --> 00:20:59,530
which was children's speech recognition.

352
00:20:59,540 --> 00:21:04,540
But I felt like I needed
to invest time in a,

353
00:21:04,551 --> 00:21:08,070
and I'm trying to figure out what the
problem was and it was something we need

354
00:21:08,080 --> 00:21:09,310
to do myself.
So I,

355
00:21:09,550 --> 00:21:14,440
I quit for labs to start to just
find a soapbox labs in 2013.

356
00:21:14,770 --> 00:21:18,890
And was that an Aha moment or was this
one of these kind of you build up the,

357
00:21:18,891 --> 00:21:21,590
see the problem and identified the gap?
How exactly did you,

358
00:21:21,620 --> 00:21:23,390
did you come up with
this specific problem?

359
00:21:23,680 --> 00:21:28,670
Um, it was all my experience up to
that point led me to the Aha moment.

360
00:21:28,671 --> 00:21:30,990
And you want like that, you know,
I was here, I was working with,

361
00:21:30,991 --> 00:21:34,710
my daughter was three at the
time, have Asian, um, you know,

362
00:21:34,800 --> 00:21:38,710
downloading apps and web services and
kind of look the way I think I was trying,

363
00:21:38,720 --> 00:21:40,290
you know, phonics and
getting her, you know,

364
00:21:40,291 --> 00:21:44,580
read enough stuff like that could be
acutely maths apps and that kind of like,

365
00:21:44,581 --> 00:21:47,220
it's fun. It's still from the reading
and stuff. And it was just, she was,

366
00:21:47,490 --> 00:21:48,570
it was always multi choice.

367
00:21:48,680 --> 00:21:51,210
Anything student reading and language
learning was always a little to choice

368
00:21:51,211 --> 00:21:54,210
because I kind of figured out what they
have no way of assessing whether she

369
00:21:54,211 --> 00:21:58,470
could get this right or not.
So she's playing these beautiful games,

370
00:21:58,471 --> 00:22:00,300
they're all done.
You don't want to be a pedagogy.

371
00:22:00,300 --> 00:22:02,160
It was great in the middle of that,
but they have no way of assessing.

372
00:22:03,380 --> 00:22:08,360
I remember asking her, she completed
a level or whatever it was, um,

373
00:22:08,730 --> 00:22:11,370
you know, I was offering you just
finish that and then, you know,

374
00:22:11,550 --> 00:22:14,250
I'd ask her what to say and was,
what the word I don't know.

375
00:22:14,430 --> 00:22:15,390
And I started watching what you do.

376
00:22:15,391 --> 00:22:17,520
She was just gaming them cause
she got it wrong the first time.

377
00:22:18,090 --> 00:22:21,240
She just knew the next time I to do the
other one and she had no clue what they

378
00:22:21,241 --> 00:22:22,840
were. You know, she didn't
know what the sand she'd know.

379
00:22:22,890 --> 00:22:26,640
Village to reculture wasn't even
read the sand or the word. Um,

380
00:22:27,000 --> 00:22:30,450
and to my mind that meant there was, you
know, why isn't anybody doing things?

381
00:22:30,510 --> 00:22:30,990
Because,
you know,

382
00:22:30,990 --> 00:22:34,080
I'd been working on speech recognition
for so long at that point and I knew

383
00:22:34,081 --> 00:22:36,980
where we were going without adult
speech recognition, you know,

384
00:22:37,080 --> 00:22:40,200
the writing was on the wall and we think
we'd be at these voices listening stage.

385
00:22:40,560 --> 00:22:44,160
Um, so it's just baffles me that
nobody had actually put anything. Nope,

386
00:22:44,190 --> 00:22:48,750
not that 10 would African they have,
they just hadn't got to the same stage.

387
00:22:48,751 --> 00:22:50,550
You know,
and you know,

388
00:22:50,551 --> 00:22:53,430
it's why I spent quite a bit time for
trying to figure out what the problem was,

389
00:22:54,180 --> 00:22:56,640
why don't not.
Um,

390
00:22:56,760 --> 00:23:00,660
so it was definitely my experience
coupled with sitting with my daughter and

391
00:23:00,670 --> 00:23:03,960
going Ah, right there and then realize
it was actually bigger than I thought.

392
00:23:03,990 --> 00:23:04,823
Like the problem.

393
00:23:05,450 --> 00:23:09,430
Okay. And in the last five years, I
mean, you spend a lot of time, uh,

394
00:23:09,710 --> 00:23:13,730
working with some of the biggest
names. So I mean, Ibm and bell labs,

395
00:23:13,790 --> 00:23:18,160
you're now in a startup environment. What
have you taken from, from that time, Eh,

396
00:23:18,190 --> 00:23:20,450
in the corporate environment.
So as many of us here,

397
00:23:20,451 --> 00:23:21,650
I were working in big companies,

398
00:23:21,980 --> 00:23:25,440
we like to think where to start up a
in many ways in Google and, but what,

399
00:23:25,441 --> 00:23:28,670
what have you taken and what are you
applying in your current role today that,

400
00:23:28,671 --> 00:23:30,580
that you've, you've,
you've learned in your,

401
00:23:30,830 --> 00:23:34,700
so we're, we're B to B, so we don't
bring products to market ourselves.

402
00:23:35,180 --> 00:23:37,550
We license our technology.
So it was one of my learnings,

403
00:23:37,730 --> 00:23:41,480
hobby for my bell labs days that, you
know, it's such a big ecosystem, you know,

404
00:23:41,481 --> 00:23:43,820
to possibly say I was going
to do everything myself.

405
00:23:43,821 --> 00:23:47,630
I went from every bit of funding it with
a raised would've gone way too thin and

406
00:23:47,631 --> 00:23:51,840
I realized that to in order to
develop the technology we need it.

407
00:23:51,850 --> 00:23:55,370
And I actually realized slowly over
time have bigger problem was and how

408
00:23:55,371 --> 00:24:00,371
difficult a problem was that the minute
we started going to the end user and we

409
00:24:00,501 --> 00:24:01,490
started going B to c,

410
00:24:01,850 --> 00:24:05,360
we have to invest a huge amount of
technology in that end of it as well.

411
00:24:05,420 --> 00:24:09,710
I started funding and resources. So part
of it when we were in Belarus, we still,

412
00:24:09,770 --> 00:24:11,930
you know, one of the thinking
was part of the corporate things,

413
00:24:12,080 --> 00:24:13,930
you don't have to do everything,
you know,

414
00:24:13,940 --> 00:24:17,810
you kind of partner and you can actually
just decide and laser focus on this

415
00:24:17,811 --> 00:24:19,910
problem and then find partners.
Because you know what,

416
00:24:19,911 --> 00:24:23,420
that's what big companies do with partner,
where it makes sense.

417
00:24:24,560 --> 00:24:28,210
But also what, what I learned
also was that how, um,

418
00:24:28,910 --> 00:24:32,600
to talk to girls and to know what their
problems were and their pain points and

419
00:24:32,601 --> 00:24:35,720
realize actually sometimes the left
hand doesn't know what the right hand is

420
00:24:35,721 --> 00:24:38,880
doing. So you know what we've described.
Sometimes we go to big organization,

421
00:24:38,900 --> 00:24:40,340
get a contact in top someone.

422
00:24:40,341 --> 00:24:45,341
They might not think they have a problem
realizing they have a problem or a no,

423
00:24:45,740 --> 00:24:47,840
that person is just
too busy or they don't,

424
00:24:47,870 --> 00:24:49,040
they haven't put it as the prior to that.

425
00:24:49,041 --> 00:24:50,620
But you might actually talk
to a different per person,

426
00:24:50,640 --> 00:24:55,490
the organization and this is their pain
point and they will talk to you and then

427
00:24:55,491 --> 00:24:57,960
you start engaging. So I think
sometimes people, you know,

428
00:24:58,040 --> 00:25:00,740
you talked to him corporate, you get
one, they'll though their own way to,

429
00:25:00,741 --> 00:25:03,330
and you think that's it and you
walk away. Um, but you know,

430
00:25:03,470 --> 00:25:05,570
realizing that very big corporations,

431
00:25:05,690 --> 00:25:08,330
it's just not possible to know what every
part of the organization is doing and

432
00:25:08,331 --> 00:25:09,600
served as well.
Um,

433
00:25:09,620 --> 00:25:13,520
and then realizing where in the
organization to try and get contacts into,

434
00:25:13,521 --> 00:25:14,354
you know,

435
00:25:15,440 --> 00:25:18,290
it's definitely relationship building
over the last couple of years and we kind

436
00:25:18,291 --> 00:25:22,060
of use a lot of our professional contexts
over the last 20 years and to help

437
00:25:22,070 --> 00:25:24,370
getting to talk to the right people.
And that's what,

438
00:25:24,850 --> 00:25:28,100
okay.
Any big surprises mentioned 2013 to today.

439
00:25:28,430 --> 00:25:30,830
I'm sure it's been lots of ups and
downs of the journey, but what,

440
00:25:30,831 --> 00:25:32,480
what's going to surprise you most that,

441
00:25:32,510 --> 00:25:35,900
that you weren't thinking before you
took the leap into starting a company?

442
00:25:36,240 --> 00:25:41,000
Um, I was full sure at the start
that'd be, I'd have more competitors,

443
00:25:41,610 --> 00:25:44,370
but I then had made two, three
years, four years until I went, oh,

444
00:25:44,371 --> 00:25:48,900
that's why this is TRRS, you know,
all, there's people, you know,

445
00:25:48,901 --> 00:25:51,070
we'll go fry bigger fish like
before they'll do this by,

446
00:25:51,071 --> 00:25:55,180
but we've been very focused on the shared.
But yeah, I think two things happened.

447
00:25:55,570 --> 00:25:58,790
I was surprised it took as long as it
did for the voice systems to take off.

448
00:26:00,000 --> 00:26:04,470
But that's right now if
that's, there's always many
factors for that. Um, and then,

449
00:26:04,490 --> 00:26:05,640
you know,
in the child speaks to you.

450
00:26:05,641 --> 00:26:08,460
I definitely think people are waking up
to the fact that it's a problem today.

451
00:26:08,461 --> 00:26:12,210
Again, taught that would have
happened earlier, but you
know, that's fine. You know,

452
00:26:12,211 --> 00:26:16,670
we're, we're in a great position at
the moment. It's not a bad problem.

453
00:26:16,780 --> 00:26:19,780
Yeah. Um, in terms of your
self, your own time, was the,

454
00:26:19,781 --> 00:26:23,560
one of the things that we talk a lot
about work life balance and trying to

455
00:26:23,561 --> 00:26:26,500
figure out how you prioritize. I
mean, you've got a lot on your plate,

456
00:26:26,501 --> 00:26:30,190
you've got the tech side, you've got
the vision, you've got the business. Um,

457
00:26:30,280 --> 00:26:32,610
how do you determine your priorities on a,

458
00:26:32,611 --> 00:26:36,250
on a given week or a given month in
terms of what you specifically are doing

459
00:26:36,251 --> 00:26:37,870
versus your team?
Uh,

460
00:26:37,930 --> 00:26:41,070
given the opportunity from what
you've described earlier on was just,

461
00:26:41,200 --> 00:26:42,040
just so vague.

462
00:26:42,420 --> 00:26:44,320
I wish had said,
I

463
00:26:44,340 --> 00:26:48,360
know how I do that. I don't want to be
just parked. We prioritize on the fly. Um,

464
00:26:48,361 --> 00:26:53,190
you know, I mean, my job is CEO and isn't
that just changes by the day? I mean,

465
00:26:53,400 --> 00:26:57,150
honestly, you know, I'd be
walking the painter, you know,

466
00:26:57,151 --> 00:26:59,850
because we just moved into a new office,
you know, where I'll be, you know,

467
00:27:00,480 --> 00:27:04,830
talking to legal or talking to a Canon
C or flying into San Francisco or you

468
00:27:04,831 --> 00:27:09,670
know, to New York and, um, every week is
completely different and just that's it.

469
00:27:09,671 --> 00:27:12,840
It is just, you know, you're
just constantly just weighing
up stuff in your head,

470
00:27:13,470 --> 00:27:15,110
dynamically priorities,

471
00:27:15,210 --> 00:27:18,300
what you're told was pros last week
suddenly drops because something else just

472
00:27:18,301 --> 00:27:22,050
happened. Um, but just having
a good team and everybody,

473
00:27:22,260 --> 00:27:26,610
I think what helps priorities is always,
you know, having the division of mind.

474
00:27:26,611 --> 00:27:29,680
And one thing we've never
changed his last name.

475
00:27:29,700 --> 00:27:34,080
Does he know the voice technology getting
the best possible platform that serves

476
00:27:34,090 --> 00:27:37,910
until, you know, our, our, our
different verticals. Um, that,

477
00:27:37,940 --> 00:27:41,790
that is a system that everybody can
use and we don't have to customer for

478
00:27:41,791 --> 00:27:45,350
everybody. That all those things have
been a focal point for us. So, you know,

479
00:27:45,390 --> 00:27:47,940
we have a number of different clients
and they're all looking for different

480
00:27:47,941 --> 00:27:52,080
things. We actually see Noah,
um, that helps, you know,

481
00:27:52,320 --> 00:27:55,560
not being afraid to say no because,
you know, just cause you want it.

482
00:27:55,561 --> 00:27:59,010
If nobody else what the client wants on
thoughts, probably not a priority for us.

483
00:27:59,050 --> 00:28:02,330
Like, you know, um, you know, so
we try and build something that's,

484
00:28:02,370 --> 00:28:05,610
that's a useful product to as many people
as possible. And then things like that.

485
00:28:05,611 --> 00:28:07,440
Like,
so always having that in mind when you're

486
00:28:09,510 --> 00:28:14,230
making your party list for the week
or, yeah. Okay. Pivoting into the, um,

487
00:28:14,270 --> 00:28:17,210
back into the business, you presented
a whole bunch of logos at the very,

488
00:28:17,211 --> 00:28:21,110
very start, some of the biggest companies
in the world and all in this space, um,

489
00:28:21,620 --> 00:28:24,910
commercialization of, of voice,
technology. You important,

490
00:28:24,940 --> 00:28:26,810
where do you see five,

491
00:28:26,811 --> 00:28:30,770
10 years and what's your perspective on
the revenue streams that are going to

492
00:28:31,070 --> 00:28:33,410
come out of these technologies for it,
for all these companies?

493
00:28:34,710 --> 00:28:39,420
I think a lot of conversation
now is about winning the home.

494
00:28:39,990 --> 00:28:43,570
Um, you know, I think that's what's a
driver for most people. I mean, you know,

495
00:28:43,571 --> 00:28:46,500
they're not charging for it.
Um, but you know, you know,

496
00:28:47,640 --> 00:28:50,700
when you see what people are trying to do,

497
00:28:50,701 --> 00:28:55,590
I think is to draw you into an ECO
system and how that you ecosystem be as

498
00:28:55,591 --> 00:28:59,040
useful as possible to, um, and that's
where I think there's, you know,

499
00:28:59,250 --> 00:29:01,530
it's not about the
voice technology per se,

500
00:29:01,531 --> 00:29:05,010
it's about you using one device over
another, a pain for the hardware.

501
00:29:05,040 --> 00:29:09,050
Or maybe maybe you do your buying there,
or maybe you're, um, you're, you're,

502
00:29:09,170 --> 00:29:13,320
you're sitting your services that you
and this are like who's giving you the

503
00:29:13,321 --> 00:29:14,280
best experience.

504
00:29:14,820 --> 00:29:19,820
And that's where you go in what most of
these bigger companies have realizes,

505
00:29:20,520 --> 00:29:24,930
Gosh, you know, you know, I'm an
apple fan. I've got an Iphone,

506
00:29:24,931 --> 00:29:26,650
I've got a Mac book, I've
got, you know what I mean?

507
00:29:26,700 --> 00:29:29,910
And I will probably get the home. But
if they ever fixed Eric, you know,

508
00:29:29,911 --> 00:29:32,400
those types of things, um, you know,

509
00:29:32,401 --> 00:29:35,970
so all those things I think
make you, um, there'd be no,

510
00:29:35,971 --> 00:29:37,930
it was kind of like being in
Mcdonald's lifer, you know,

511
00:29:38,020 --> 00:29:41,870
that's why I kind of see where
people are viewing the utility, uh,

512
00:29:41,910 --> 00:29:46,320
and revenue streams. But that's not
to say it's not going to change. I do.

513
00:29:46,321 --> 00:29:47,020
I think,

514
00:29:47,020 --> 00:29:51,280
I think it's going to be case if your
product will look less for not having good

515
00:29:51,281 --> 00:29:55,150
to voice technology as an interface,
you look like antiquated technology.

516
00:29:55,270 --> 00:29:57,820
If you don't have good and that means
it's going to be on, you know what I mean?

517
00:29:57,821 --> 00:29:59,780
There's, there's cars that are, you know,

518
00:29:59,830 --> 00:30:04,030
partnering with some pretty big speech
technology companies, um, you know, to,

519
00:30:04,210 --> 00:30:04,991
to bring it into,
you know,

520
00:30:04,991 --> 00:30:09,991
if there's no way you're like the Tesla's
got a pretty good speech recognition

521
00:30:10,181 --> 00:30:13,980
technologies go, you can't bring out a
quality product without users. Again,

522
00:30:13,981 --> 00:30:18,050
you know, over time it's going to just
become more of the norm. Um, you know,

523
00:30:18,130 --> 00:30:21,190
on everything you sell,
the majority of it will be done by voice.

524
00:30:21,650 --> 00:30:25,200
And how has that evolution changed your
thinking on how soapbox approaching the

525
00:30:25,201 --> 00:30:29,250
market over the last five years?
Things have moved very, very fast in,

526
00:30:29,430 --> 00:30:31,500
in the market.
Have you had to pay a bit?

527
00:30:31,501 --> 00:30:35,070
Have you had to twist to be at the change
or is your, your approach to the same?

528
00:30:35,260 --> 00:30:39,520
Um, what can we started using
the word skills in the last year?

529
00:30:39,521 --> 00:30:44,140
I think that's a change on a
voice device. Like so, you know,

530
00:30:44,141 --> 00:30:46,210
but no,
not in some ways.

531
00:30:46,230 --> 00:30:49,160
We always designed to be an underlying
technology that would serve into

532
00:30:49,180 --> 00:30:53,950
education, gaming. Um, you know, we
always have the utility box they're like,

533
00:30:53,951 --> 00:30:56,980
which is like things that whole
advisement talk about voice control in a

534
00:30:56,981 --> 00:31:01,570
robotics, the AI or Vr, all that.
Like toys is a big one as well. Um,

535
00:31:02,440 --> 00:31:06,910
what changed a lot for us is over
the years that we, you know, we put,

536
00:31:06,911 --> 00:31:07,701
start putting a stronger,

537
00:31:07,701 --> 00:31:09,800
a stronger focus on data
privacy and data protection and,

538
00:31:09,801 --> 00:31:12,990
and what that means and we want to
be sure that we were leaving field.

539
00:31:12,991 --> 00:31:13,570
Now we know,

540
00:31:13,570 --> 00:31:16,810
we know how it works and we want to
make sure that we can help other people.

541
00:31:16,811 --> 00:31:20,980
It can be, to be compliant to my mind was
knowing that was going to be a problem.

542
00:31:21,410 --> 00:31:26,080
Um, and you know, you better hit
those things head on early on. Okay.

543
00:31:26,560 --> 00:31:29,240
Maybe going to be more specific
on, on the offering. Um,

544
00:31:29,380 --> 00:31:32,800
so sitting underneath tilt black
labs, there's, there's up to some Ip.

545
00:31:32,940 --> 00:31:34,180
And in terms of development,

546
00:31:34,930 --> 00:31:38,110
how have you gotten there in terms of
like really getting something unique and

547
00:31:38,111 --> 00:31:41,740
something different that not
available America base? So the, the,

548
00:31:41,800 --> 00:31:45,630
the idea is that tall, it's
the technologies, what exactly
is under the hood. Okay.

549
00:31:45,910 --> 00:31:50,740
Um, I was like kind of puts it in the
bud and the talk was about the data.

550
00:31:50,770 --> 00:31:54,870
I mean, you know, we use stage of the
art deep learning technologies. Um,

551
00:31:55,140 --> 00:31:57,010
we have a team that's,
you know,

552
00:31:57,011 --> 00:32:00,430
I think we've over eight years experience
in the team and speech recognition

553
00:32:00,431 --> 00:32:04,510
technology that's actually growing. I
got, might have to Abdullah. Um, you know,

554
00:32:05,320 --> 00:32:09,160
we concentrated on quality
data first. Um, you know,

555
00:32:09,161 --> 00:32:14,161
I recognize that problem after my
experience in bell labs in actually it was

556
00:32:15,191 --> 00:32:20,100
Google back in the early two thousands
that started a really clever of data

557
00:32:20,101 --> 00:32:22,690
collection program.
These goop for one,

558
00:32:22,691 --> 00:32:25,660
one that you bring in us
for advice and um, you know,

559
00:32:25,661 --> 00:32:29,590
you get a free information call if you
use voice technology back in the early

560
00:32:29,591 --> 00:32:33,160
two thousands. And it was actually very
effective where techs and data, um,

561
00:32:33,280 --> 00:32:36,040
you know, there's good stars in
a long time before anyone else.

562
00:32:37,120 --> 00:32:38,050
But my own experience,

563
00:32:38,051 --> 00:32:43,051
I worked in a number of different in
the bell lab stays where love like data

564
00:32:43,281 --> 00:32:46,910
versus real world data, actually an
IBM as well. What's that? You know,

565
00:32:47,090 --> 00:32:50,750
you can collect all the data in the
world and build very efficient system,

566
00:32:50,780 --> 00:32:54,960
but if it's not represented in a
book where you expect to use, um,

567
00:32:55,820 --> 00:32:59,600
the voice technology, it won't
work. Um, and that's, you know,

568
00:32:59,780 --> 00:33:04,780
all those learnings have led us to do
things in a different order though.

569
00:33:05,001 --> 00:33:09,410
The people who were doing it, you know,
we were concentration on, on quality data,

570
00:33:09,500 --> 00:33:13,700
understanding the problem, understanding
the application areas. Um, and then Larry,

571
00:33:13,701 --> 00:33:18,260
not state of the art technology or cloud
based API and making it available and

572
00:33:18,261 --> 00:33:18,831
all those things.

573
00:33:18,831 --> 00:33:22,280
So there's this kind of multiple
layers of expertise from the team.

574
00:33:22,700 --> 00:33:26,290
And our own experience as well, like you
know, come people who came to the we,

575
00:33:26,291 --> 00:33:29,810
you know, how we do it, how we
dress, behaviors, all of that.

576
00:33:29,811 --> 00:33:32,690
That's like as well as the Tysons,
the virus of data that

577
00:33:35,990 --> 00:33:37,070
maybe opened up to the floor.

578
00:33:39,370 --> 00:33:43,840
Questions for Tricia. Thanks
for the talk. Very interesting.

579
00:33:44,350 --> 00:33:47,260
Um,
I was wondering if you could share some,

580
00:33:47,261 --> 00:33:52,261
some information about a effect at a
thousand children to especially on their

581
00:33:52,750 --> 00:33:57,250
behavior. Right. So with the, with the
products that are on the market now,

582
00:33:57,280 --> 00:34:01,930
it's very often that all is that is
needed is a command or an order basically.

583
00:34:02,410 --> 00:34:05,350
So you say like, hey, Google, do this,

584
00:34:05,770 --> 00:34:09,850
but you never say please or thank you
or anything like that. So what kind of,

585
00:34:09,880 --> 00:34:11,600
what kind of impact does that have on,

586
00:34:11,601 --> 00:34:15,640
on the behavior of a child that
they think that that's normal. Um,

587
00:34:15,700 --> 00:34:17,250
and when they ask someone else to someone,

588
00:34:17,300 --> 00:34:19,570
some something else it do someone else,

589
00:34:19,571 --> 00:34:23,710
like are they going to copy that
behavior as well or do they realize that

590
00:34:23,711 --> 00:34:25,300
they're not talking to technology

591
00:34:28,080 --> 00:34:30,460
as a parent? Um, you know,

592
00:34:31,290 --> 00:34:33,750
I would always advocate you
safely as regards. It's so,

593
00:34:33,751 --> 00:34:35,890
I mean it comes from the parents.
I mean there's lots as the child,

594
00:34:35,891 --> 00:34:38,010
it could be rude to another human.

595
00:34:38,970 --> 00:34:42,540
I think you're teach those behaviors in
some ways the fact of Alexa will do or a

596
00:34:42,541 --> 00:34:46,860
Google home and do it
regardless. You know, maybe
that's a little like, you know,

597
00:34:46,861 --> 00:34:51,120
a little add on or a little like opt in
that you got do she won't do it unless

598
00:34:51,121 --> 00:34:55,560
you say please push that back in
Google to do, address that issue.

599
00:34:58,200 --> 00:35:00,020
My question is about the product.

600
00:35:00,410 --> 00:35:04,260
Is it more like Nicholas fire
for kids voice or is it um,

601
00:35:04,310 --> 00:35:09,310
speech cognition including
kids classifier or four kids,

602
00:35:09,621 --> 00:35:13,850
four kids voice for instances is you're
trying to predict if this kid's speaking

603
00:35:13,851 --> 00:35:17,600
or his children's speaking or is it
more speech recognition including kids

604
00:35:17,601 --> 00:35:18,950
trying to understand what they say?

605
00:35:19,100 --> 00:35:23,090
We do both. So we recognize adult
versus child with classification.

606
00:35:23,270 --> 00:35:25,060
And then there's also speed
tracking those as well.

607
00:35:25,200 --> 00:35:28,980
And for the classifier. How
do you classify, how do you,

608
00:35:29,010 --> 00:35:34,010
what is the threshold for being at
voices or children or adult voice?

609
00:35:35,080 --> 00:35:36,480
So traditionally you know,

610
00:35:36,680 --> 00:35:41,680
it's kind a well recognized problem
under the age of 12 is when you find the

611
00:35:41,821 --> 00:35:43,710
voice starting to differentiate the most.

612
00:35:44,190 --> 00:35:47,370
So that depends on the
client let's say or you know,

613
00:35:47,460 --> 00:35:50,400
coming to Austin by what their
specification is. Would they rather,

614
00:35:50,430 --> 00:35:52,530
what would they rather it happen?
It's not going to be binary,

615
00:35:52,531 --> 00:35:53,390
somebody black or white.

616
00:35:54,030 --> 00:35:57,330
So you're not going to be able to say
I've cut off at 13 cause you're gonna have

617
00:35:57,331 --> 00:36:00,080
some 11 year olds are going to speak like
a 13 year old and 13 year olds how to

618
00:36:00,081 --> 00:36:03,210
speak like 11 year olds.
So you will have that I a grayer area.

619
00:36:03,211 --> 00:36:05,860
There was definitely,
yeah, you get to see it.

620
00:36:05,910 --> 00:36:10,010
It's quite clear once you start going
anyway, younger friends, who can I ask?

621
00:36:10,011 --> 00:36:12,270
I can receive of

622
00:36:12,800 --> 00:36:14,320
off classification.

623
00:36:14,500 --> 00:36:18,160
I've seen this is kid's voice or
legitimate kid's voice and for the age,

624
00:36:18,840 --> 00:36:21,450
if I could share more
information about it after,

625
00:36:21,451 --> 00:36:23,790
but it would very much 10 months,
that's, I don't have all the,

626
00:36:24,240 --> 00:36:26,930
I think like say you're going to say,
can I recognize a four,

627
00:36:26,940 --> 00:36:28,280
five year olds from an adult's,

628
00:36:28,310 --> 00:36:31,350
I'll say a hundred percent accuracy if
you're going to start saying to kind of

629
00:36:31,351 --> 00:36:35,370
recognize a 12 year old from an adult,
that gets harder. So it depends on it.

630
00:36:35,400 --> 00:36:39,060
It's very easy to separate
the young children with
models. I'll say that for me.

631
00:36:40,420 --> 00:36:41,253
Thank you.

632
00:36:41,620 --> 00:36:44,520
Since you have an Alexa at home,
do you have any other voice assistant?

633
00:36:46,140 --> 00:36:46,580
No,

634
00:36:46,580 --> 00:36:51,260
I don't have a big fee in a
cereal on home devices and stuff.

635
00:36:52,080 --> 00:36:52,570
And uh,

636
00:36:52,570 --> 00:36:56,130
is it purely out of a professionally
dressed that you have it at home or do you

637
00:36:56,131 --> 00:36:57,390
actually use it for,

638
00:36:57,640 --> 00:37:00,070
um, queries? Yeah,

639
00:37:00,071 --> 00:37:02,830
it was definitely bullied as
a research piece of equipment.

640
00:37:02,831 --> 00:37:05,260
So really I think it bought it from the
u s because I wanted to have it back in

641
00:37:05,261 --> 00:37:09,550
2015 or 2016 and then, um, I, you
know, I have access to a Google homes.

642
00:37:09,551 --> 00:37:12,780
We've been testing that as
well. Um, I, yeah, we use it.

643
00:37:12,950 --> 00:37:17,320
We definitely use it like as a,
yeah, these are old timers, alarms,

644
00:37:17,860 --> 00:37:21,450
you know, play music is a big
one in our eyes. Um, yeah.

645
00:37:21,820 --> 00:37:23,470
How do you spell this butts,
you know,

646
00:37:25,390 --> 00:37:27,990
general knowledge just for fun sometimes,
like I think,

647
00:37:28,090 --> 00:37:31,030
I think the utility can be better. I
think we haven't quite seen it. Yes,

648
00:37:31,031 --> 00:37:34,300
I think it's quite limited. And then
sometimes on the, on an Amazon though,

649
00:37:34,301 --> 00:37:37,660
could you actually see you're working in
somewhere like the u s where or London

650
00:37:37,661 --> 00:37:39,950
where you got Uber and you've got your
deliveries and you've got all the,

651
00:37:39,951 --> 00:37:42,800
you know, the way he goes,
call me an Uber. I'll see.

652
00:37:42,890 --> 00:37:44,200
That's what I want to be
able to do. Like, you know,

653
00:37:44,201 --> 00:37:45,310
we can't do that here in Ireland.

654
00:37:45,311 --> 00:37:49,720
So I think in our were somewhat limited
because they only just released it for

655
00:37:49,850 --> 00:37:53,200
Ireland. It's depends on what it's
connected to and what apps you enable.

656
00:37:54,190 --> 00:37:57,030
I think we're somewhat limited here.
I've definitely seen better utility.

657
00:37:58,870 --> 00:38:00,430
And from your personal experience,

658
00:38:00,431 --> 00:38:03,100
which one do you find more accurate
that Alexa or the Google home?

659
00:38:05,540 --> 00:38:10,340
I would say Google in the natural
language. Understanding for sure. Um,

660
00:38:10,920 --> 00:38:15,260
uh, I would say you get to way too
many. I don't know what that means,

661
00:38:15,740 --> 00:38:20,360
uh, on Alexa, but I think that's an
understood problem. Um, I think, you know,

662
00:38:20,361 --> 00:38:21,480
and then there's problems,
flights first.

663
00:38:21,481 --> 00:38:23,390
So I think both of them
have their strengths.

664
00:38:23,670 --> 00:38:26,450
Has what your linkedin to
friends of what you need as well.

665
00:38:26,690 --> 00:38:28,240
I think on accuracy people wouldn't do,

666
00:38:28,241 --> 00:38:31,380
you never really hear one side can
be that strong with the other. Um,

667
00:38:31,910 --> 00:38:33,680
I think when it comes to kids speech,

668
00:38:33,770 --> 00:38:37,090
I won't say we've done our own
particular research online.

669
00:38:38,810 --> 00:38:39,643
Thank you.

670
00:38:40,450 --> 00:38:44,530
You took a, you talk about the speech
recognition of course, but have you ever,

671
00:38:44,531 --> 00:38:49,150
or is there a lot of um, focus us on the
other side? So I mean for me it's, it's,

672
00:38:49,180 --> 00:38:53,290
it's really weird to that you have this
advanced speech recognition everywhere.

673
00:38:53,650 --> 00:38:57,730
But a system that asks you, especially
in this IVR system is very clunky,

674
00:38:57,731 --> 00:39:01,460
still like very robotic and very,
if you want vola pastors.

675
00:39:01,870 --> 00:39:05,940
So is there anything going on, especially
for kids on the how this is surf,

676
00:39:05,980 --> 00:39:10,630
like this is a fun assistant and he
doesn't ask and answer in a way that he

677
00:39:10,631 --> 00:39:12,850
might expect some that
more human like you know,

678
00:39:12,851 --> 00:39:16,420
like maybe throwing a joke in or like
presenting it in a different way as this

679
00:39:16,460 --> 00:39:21,450
completely, are these two separate
feeds us the same kind of the same

680
00:39:22,700 --> 00:39:23,720
type thing with voice.

681
00:39:24,340 --> 00:39:27,790
Yeah. Like those are the assistant
being more like I'm not the person then,

682
00:39:27,791 --> 00:39:31,060
then just a piece of technical like,
you know, I can relate to that person.

683
00:39:31,061 --> 00:39:34,750
He has some city jokes in that program
and the personality, that kind of thing.

684
00:39:35,560 --> 00:39:37,930
There's nothing really on the
market that's blown us away,

685
00:39:38,230 --> 00:39:40,690
but we know that's a huge amount
of companies looking at this.

686
00:39:41,410 --> 00:39:44,950
I'm not a huge amount of research done
on, it's actually, funnily enough, we've,

687
00:39:44,951 --> 00:39:47,680
we've looked and we've been
asked about a recently, um,

688
00:39:47,740 --> 00:39:52,600
if I've thought exactly what would that
voice assistant or chop off a child,

689
00:39:52,630 --> 00:39:54,880
you know what makes more sense because
the kids use different language.

690
00:39:54,881 --> 00:39:56,340
They have their concepts of symptoms.

691
00:39:56,800 --> 00:40:00,430
You can't use a lot of what you would use
for an adult with a child because they

692
00:40:00,431 --> 00:40:02,740
won't get it and it's not appropriate.

693
00:40:02,741 --> 00:40:05,010
Sometimes even the concepts can
be just too much. Like you know,

694
00:40:05,020 --> 00:40:07,720
they don't get the subtleties. And then
again, it depends on the age group.

695
00:40:07,721 --> 00:40:11,030
You took my four to seven are
you talking about nine to 12?

696
00:40:11,710 --> 00:40:15,690
There's a lot of very little, very little.
It's been done but, but then again,

697
00:40:15,710 --> 00:40:18,400
you think about the whole chat Bot,
that kind of automated system,

698
00:40:18,401 --> 00:40:21,000
that natural language understanding
is still quite new for adults.

699
00:40:21,001 --> 00:40:22,870
We're only getting better at it now.

700
00:40:23,950 --> 00:40:27,870
What I've seen is quite a gun
law book. Kids, it will up.

701
00:40:28,480 --> 00:40:29,760
We've seen a lot of people working on,

702
00:40:32,690 --> 00:40:36,470
oh hi. Thanks a lot for that presentation.
Because of the nature of your company,

703
00:40:36,471 --> 00:40:41,471
I guess you have collect out of access
still to a lot of data and voice samples

704
00:40:41,661 --> 00:40:44,080
of little kids.
So if you could share it,

705
00:40:44,081 --> 00:40:48,080
like how do you approach gathering this
data, collecting this or buying this,

706
00:40:48,081 --> 00:40:51,400
getting access to it and how do you make
sure it is compliant with all of the

707
00:40:51,420 --> 00:40:53,360
privacy regulations
that you just mentioned?

708
00:40:53,510 --> 00:40:56,900
Yeah, so we, we just do
it ourselves. We don't,

709
00:40:57,360 --> 00:40:58,640
we don't talk too much about how we do it,

710
00:40:58,641 --> 00:41:03,641
but we've from the Gecko in 2013 we've
been fully compliant with Karpov and made

711
00:41:04,041 --> 00:41:07,240
sure I was quite, cause I started
with company myself like that.

712
00:41:07,241 --> 00:41:09,830
So I made sure I was engaged with,
you know,

713
00:41:09,980 --> 00:41:11,810
privacy lawyers and
understanding this and,

714
00:41:11,811 --> 00:41:15,470
and more so understanding that we didn't
really have an obligation to do it in

715
00:41:15,471 --> 00:41:16,730
the beginning,
but you know,

716
00:41:17,060 --> 00:41:21,200
it was one of those things I really told
was going to be an issue and it should

717
00:41:21,201 --> 00:41:24,380
be an issue and it should be addressed.
So, you know, for a small company,

718
00:41:24,381 --> 00:41:26,840
I don't think it's worth taking
risks on something like that.

719
00:41:27,050 --> 00:41:31,190
So we've done everything ourselves. Um,
um, and I'm glad about that as well. Um,

720
00:41:31,220 --> 00:41:32,100
because you know,

721
00:41:32,450 --> 00:41:36,260
it actually wasn't to buy data because
there isn't anything equivalent out there

722
00:41:36,261 --> 00:41:40,250
and not, and not real world
data, not tacked on a mobile
device, not on, you know,

723
00:41:40,460 --> 00:41:43,580
in a real environment, not an
uncontrolled ways. And, and to my mind,

724
00:41:43,581 --> 00:41:47,010
everything else was used because, you
know, again, like I said, if you get that,

725
00:41:47,011 --> 00:41:51,550
that the only days you could buy it was
fairly lab like environment, um, you know,

726
00:41:51,560 --> 00:41:55,060
controlled by an adult or a parents
in there making a child read something

727
00:41:55,280 --> 00:41:58,820
that's not real world
stuff. So, um, we've,

728
00:41:58,821 --> 00:42:03,140
we've been very careful to
do it ourselves. We've been
careful to be compliant,

729
00:42:03,260 --> 00:42:08,030
um, globally. Um, and, and to that
end, that's a lot of value to us.

730
00:42:08,031 --> 00:42:09,590
Like in the middle,
we can stand over what we've done.

731
00:42:10,990 --> 00:42:14,530
That's a lot of five,
I guess to my part of the company.

732
00:42:15,410 --> 00:42:19,450
One follow up question then, uh, do
they take into consideration the, um,

733
00:42:21,220 --> 00:42:24,680
and make sure you, you, you, you collect
the samples from different countries,

734
00:42:24,681 --> 00:42:27,510
different cultures,
just to avoid the cultural country buyers.

735
00:42:27,650 --> 00:42:30,860
Yeah, we've dated from over
170 countries now. You know,

736
00:42:32,120 --> 00:42:35,000
tens of thousands or more
than that though. Yeah. Um,

737
00:42:36,200 --> 00:42:39,770
that was huge as well actually, to be
honest, because what am I, you know,

738
00:42:39,771 --> 00:42:43,190
I lived in the US for quite a bit
in the drain in different areas.

739
00:42:43,191 --> 00:42:45,990
And one of the things I always noticed
about is if you live in New York or a of

740
00:42:46,040 --> 00:42:47,600
you drop a panel at school in New York,

741
00:42:47,620 --> 00:42:51,590
I'm sure you're not going to get off
or 20% New York accents, you know,

742
00:42:51,591 --> 00:42:55,370
so why just build a system with
us accents, like, you know,

743
00:42:55,371 --> 00:42:59,000
and that was really key that if a
system has gone to work everywhere you,

744
00:42:59,210 --> 00:43:02,060
the world's just working with that all
year, you know, you've got such, you know,

745
00:43:02,061 --> 00:43:04,310
flow of people, whoever, and to be honest,

746
00:43:04,311 --> 00:43:07,280
like deep learning and all
those technologies have,

747
00:43:07,430 --> 00:43:12,140
the advantage is that that's allowed us
to be able to add multiple variations

748
00:43:12,141 --> 00:43:16,080
and pronunciation to the system.
Whereas when I started this back two days,

749
00:43:16,081 --> 00:43:18,310
we were, you'd have like,
you know, Midwestern,

750
00:43:18,370 --> 00:43:21,890
you probably have a marble from Midwestern
us and you know, small brush, like,

751
00:43:21,980 --> 00:43:23,630
you know,
and even even at that,

752
00:43:23,631 --> 00:43:26,180
you probably have to break it out into
different dialects in that sense and

753
00:43:26,181 --> 00:43:30,400
stuff like that because the systems could
cope with the variation where we can

754
00:43:30,410 --> 00:43:31,250
now,
which is amazing.

755
00:43:36,700 --> 00:43:38,960
Uh, thank you for the talk.
And really interesting.

756
00:43:39,260 --> 00:43:43,030
I actually got interested in the
topic because of the Ad Week and uh,

757
00:43:43,250 --> 00:43:45,470
talk about that as well
on the future of search.

758
00:43:45,770 --> 00:43:50,540
So it had a lot of similar implications
in terms of what happens if a child is

759
00:43:50,541 --> 00:43:54,300
in the room and also what does that
mean for advertising invoice? Serge,

760
00:43:54,440 --> 00:43:58,460
do you have any take on the combination
of advertising in voice search in the

761
00:43:58,461 --> 00:44:02,240
future and children being in the room
because there's a lot of regulations and

762
00:44:02,241 --> 00:44:03,320
problems with that too.

763
00:44:03,910 --> 00:44:06,720
Yeah, I think we much like I said about
the appropriateness, like, you know,

764
00:44:06,730 --> 00:44:09,850
I mean dot. Um, you know,

765
00:44:11,410 --> 00:44:13,150
it's probably, you know, for advertisers,

766
00:44:13,151 --> 00:44:18,040
I think you don't want to waste time
advertising to children because they're

767
00:44:18,041 --> 00:44:20,560
not, they're not the buyers.
So, you know what I mean?

768
00:44:20,561 --> 00:44:25,090
As much as you sh you ethically need
to be able to make it an appropriate

769
00:44:25,091 --> 00:44:29,410
experience for a child.
Um, you also, you know,

770
00:44:29,530 --> 00:44:34,130
commercially shouldn't wasting advertising
dollars on advertising to a chance.

771
00:44:34,131 --> 00:44:35,910
So I think, you know, again, the simple,

772
00:44:36,090 --> 00:44:38,940
I don't try and classifiers for
different age groups as well,

773
00:44:38,941 --> 00:44:42,670
is it's appropriate. You know, even
on us, no these days, you know,

774
00:44:43,230 --> 00:44:46,760
those are quite strict regulations on no
regulation for by guidelines as well as

775
00:44:46,770 --> 00:44:50,250
they've, what you should advertise
to children. So it was free.

776
00:44:50,610 --> 00:44:54,750
You can slot in static guards, put her,
she'll be up an nod on Lego or Barbie,

777
00:44:54,751 --> 00:44:57,810
but it shouldn't be an add on
something inappropriately. Um,

778
00:44:58,380 --> 00:45:02,490
and I think that's just, you know,
it's a sense really as well as just,

779
00:45:02,491 --> 00:45:03,090
you know what I mean?
The,

780
00:45:03,090 --> 00:45:05,850
there's one side that's regulation is
going to force us all to do these things

781
00:45:05,860 --> 00:45:10,620
correctly and it's by time. Um, but on
the other side there's definitely just,

782
00:45:10,710 --> 00:45:12,500
just good sense of actually,
you know, you know,

783
00:45:12,510 --> 00:45:16,820
as much as you target your
ads to different demographic
demographics, I think.

784
00:45:16,880 --> 00:45:17,713
Yeah.

785
00:45:19,940 --> 00:45:21,350
Great. One more, one more

786
00:45:22,410 --> 00:45:23,243
question.

787
00:45:25,100 --> 00:45:27,710
Oh, I'll take the last one. Uh, you,

788
00:45:27,730 --> 00:45:29,970
people who've stopped running at five
times to get their next meetings,

789
00:45:29,971 --> 00:45:32,760
I'm guessing a lot of people here will
be doing that and we've talked a lot

790
00:45:32,761 --> 00:45:33,900
about the hard work to date,
uh,

791
00:45:33,980 --> 00:45:37,350
the problems you're solving and things
are going after. That's at, in 10 years.

792
00:45:37,420 --> 00:45:41,880
Your hope for soapbox labs for
you'll be what you'll be doing. Yeah.

793
00:45:42,080 --> 00:45:44,610
We would like to share
on the air the future.

794
00:45:44,710 --> 00:45:48,370
Yeah. I mean we don't, we know initially
are for the next few years anyway.

795
00:45:48,400 --> 00:45:51,940
We've got a big focus on multilinguals.
Um, I think that's a huge thing.

796
00:45:51,941 --> 00:45:54,250
You know what I mean? We can't
just continue to expect, you know,

797
00:45:54,251 --> 00:45:57,400
it's been such a hard slog to get
anything quality out there in English,

798
00:45:57,401 --> 00:46:00,790
but we've learned so much. We've
got, we've got our pipelines,

799
00:46:00,791 --> 00:46:03,110
we've got our processes,
we can accelerate now.

800
00:46:03,280 --> 00:46:05,350
I didn't languages and
that's what we raise.

801
00:46:05,351 --> 00:46:08,620
Do you funding for actually we raised
quite considerable funding at the end of

802
00:46:08,620 --> 00:46:13,300
last year, um, to take
our opera multilingual. So
that's going to be a massive,

803
00:46:13,330 --> 00:46:15,990
um, you know, focus of the company. Um,

804
00:46:16,060 --> 00:46:19,390
and eventually does lots of
different variations of speech,

805
00:46:19,420 --> 00:46:22,810
all types of voice technology where
voice comes into it and it's kids.

806
00:46:22,811 --> 00:46:23,644
That's where we'll be.

807
00:46:23,930 --> 00:46:26,710
And we're already building up expertise
in a number of different areas, you know,

808
00:46:26,980 --> 00:46:29,610
doing more natural language
understanding as well around children,

809
00:46:29,630 --> 00:46:31,330
things like that that we think,

810
00:46:31,420 --> 00:46:33,910
and we listened a lot to what our clients
were saying to us and what they want,

811
00:46:34,330 --> 00:46:37,620
um, to be able to bring to
market. Like No. So you know,

812
00:46:37,630 --> 00:46:40,570
as much as we will do certain
amounts of much lower limbs,

813
00:46:40,780 --> 00:46:43,610
but we're listening all the time
to what they want. Um, you know,

814
00:46:44,440 --> 00:46:48,280
going into too much detail that, you
know, we're responding to that. Uh,

815
00:46:48,320 --> 00:46:52,020
and right now we have a great position
in the market because we have, you know,

816
00:46:52,260 --> 00:46:55,900
quite an lead. Um, and because we
focus, we focus solely on that.

817
00:46:55,901 --> 00:46:58,920
We haven't diversified over the
last five years on kids. Uh,

818
00:46:59,170 --> 00:47:01,030
but there are so many
opportunities globally.

819
00:47:01,031 --> 00:47:03,890
There's so many opportunities in this
like, so. Yeah, we'll just keep building.

820
00:47:04,240 --> 00:47:06,640
Yup. Well, great space, great company.

821
00:47:06,880 --> 00:47:09,600
Thank you very much for taking the
time coming in to talk to us here,

822
00:47:09,640 --> 00:47:11,740
sharing your journey,
sharing the soapbox,

823
00:47:11,741 --> 00:47:14,660
that journey at best wishes
for the future. I mean, uh,

824
00:47:14,710 --> 00:47:17,680
I know pretty much you have
an was probably excited
about where voice is going

825
00:47:18,030 --> 00:47:20,440
and where the is going.
And it's great to see an Irish company,

826
00:47:20,441 --> 00:47:23,530
Indigenous Company, uh,
doing real tech work here,

827
00:47:23,700 --> 00:47:27,790
but an ambition to go global as well.
So thank you very much.

