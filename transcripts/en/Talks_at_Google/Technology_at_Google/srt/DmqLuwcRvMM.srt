1
00:00:06,190 --> 00:00:07,360
Um,
so first off,

2
00:00:07,361 --> 00:00:10,740
I mean it's an honor to be able to sit
here and with you and a and asking you

3
00:00:10,741 --> 00:00:13,810
questions. Um, I think that a lot
of people in this room, you know,

4
00:00:13,840 --> 00:00:17,710
probably owe their existence, their jobs.
Uh, t two what you've done in the past.

5
00:00:18,130 --> 00:00:22,210
Um, I also speaking of somebody who's a
lot funnier in text form, um, thank you.

6
00:00:22,870 --> 00:00:26,710
Uh, and uh, you know, I
think that uh, this being la,

7
00:00:27,040 --> 00:00:28,620
I figured we should open with a question.

8
00:00:28,630 --> 00:00:31,660
I think everyone is wondering right
now, which is a, who are you wearing?

9
00:00:34,380 --> 00:00:38,000
Who are you wearing? What am I
wearing? Well, I hope it'll be obvious.

10
00:00:39,000 --> 00:00:40,590
I don't know how many
layers deep do you want?

11
00:00:41,760 --> 00:00:44,430
There is a story behind this though,
if you haven't heard it.

12
00:00:45,060 --> 00:00:50,060
I was at Stanford University doing the
Internet design work and I was asked by

13
00:00:50,641 --> 00:00:55,641
Arpa back in 1976 to come to Washington
to go run the program for them.

14
00:00:56,970 --> 00:00:59,640
And my wife was from Wichita,
Kansas,

15
00:00:59,970 --> 00:01:03,240
said Washington d c three piece suits.

16
00:01:03,270 --> 00:01:07,650
And so she went off to a Saks fifth
avenue at the Stanford shopping center.

17
00:01:07,651 --> 00:01:09,300
And bought three,
three piece suits,

18
00:01:09,600 --> 00:01:13,110
one of which was a seersucker
outfit because she knew
that during the summertime

19
00:01:13,111 --> 00:01:16,230
it was horrible, hot and Muggy
in Washington. So anyway,

20
00:01:16,231 --> 00:01:21,231
I show up at Darpa in my three piece
suit and a few weeks later I'm asked to

21
00:01:22,051 --> 00:01:24,900
testify before a some committee,

22
00:01:25,440 --> 00:01:28,370
and I don't even remember
which one now, but, uh,

23
00:01:28,380 --> 00:01:31,640
I wore my serious sucker
three piece suit and, uh,

24
00:01:31,690 --> 00:01:35,880
did my testimony came back, you
know, nothing interesting happens.

25
00:01:35,880 --> 00:01:40,200
And then if I get a request to
show up in the director's office,

26
00:01:40,230 --> 00:01:43,590
the director of art, but not just the
information processing techniques office.

27
00:01:43,591 --> 00:01:46,860
So I show up thinking, oh my God,
I did something wrong. You know,

28
00:01:46,861 --> 00:01:49,440
it's the end of my
government career. And, uh,

29
00:01:49,441 --> 00:01:51,150
he's got a letter in front
of it and then he says,

30
00:01:51,151 --> 00:01:54,090
I don't let her hear from the
chairman. Uh, and he says,

31
00:01:54,091 --> 00:01:57,300
thank you very much for doctor
service testimony, by the way,

32
00:01:57,301 --> 00:01:59,460
he's the best dressed guy
we've ever seen from ARPA.

33
00:02:00,680 --> 00:02:03,030
And I thought I took that
as positive feedback.

34
00:02:03,031 --> 00:02:04,900
So I've been wearing
three pieces ever since.

35
00:02:08,280 --> 00:02:09,880
Well, I, for one, uh, you know,

36
00:02:09,930 --> 00:02:12,540
had a very similar interaction plan
away from it would have left work.

37
00:02:12,600 --> 00:02:16,160
I left home this morning where she said,
no, you can't wear a hoodie. Uh, so,

38
00:02:16,550 --> 00:02:21,090
so at least I can fit in. Um, so I
mean, let's start, uh, we're in La.

39
00:02:21,240 --> 00:02:24,000
Um, I understand you have a, a
personal relationship with La.

40
00:02:24,060 --> 00:02:27,690
I'd love to hear more about that. I'm
sorry. A personal relationship with La.

41
00:02:28,510 --> 00:02:32,980
Yes, I do. In fact, although I
started out, you can do the math.

42
00:02:32,981 --> 00:02:37,570
I started out at the Yale Hospital
in 1943 in new haven, Connecticut.

43
00:02:38,050 --> 00:02:40,930
But after World War II,
my parents moved to Los Angeles.

44
00:02:40,931 --> 00:02:44,840
So I grew up here in the
San Fernando Valley. Uh,

45
00:02:44,950 --> 00:02:49,950
I moved around from North Hollywood
to Van Nuys and attended van Nuys High

46
00:02:50,530 --> 00:02:51,580
School.
Uh,

47
00:02:51,581 --> 00:02:55,930
and what's very interesting about that
school is that there were some other

48
00:02:56,140 --> 00:02:59,980
people who turned down to be important
to the history of Internet who went to

49
00:02:59,981 --> 00:03:04,690
that same school at nearly the same time.
So Steve Crocker,

50
00:03:05,080 --> 00:03:09,810
who was my was and still is,
my best friend was in the client.

51
00:03:09,811 --> 00:03:11,200
It's just behind mine.

52
00:03:11,260 --> 00:03:14,870
He and I started the math
club and we both got to uh,

53
00:03:15,070 --> 00:03:19,870
get access to computers at Ucla when
we were still a high school seniors.

54
00:03:20,610 --> 00:03:22,390
Uh,
John Pastel,

55
00:03:22,391 --> 00:03:26,710
who's another name I hope most of you
recognize also went to van Nuys high.

56
00:03:26,710 --> 00:03:29,560
He was in the class after Steve's.
Um,

57
00:03:29,620 --> 00:03:31,570
there were some other
interesting and then we all, we,

58
00:03:31,571 --> 00:03:34,450
we didn't know John very well.
Steve and I were very close.

59
00:03:34,660 --> 00:03:39,660
We all went off to college and then we
reassembled miraculously it UCLA and lend

60
00:03:40,481 --> 00:03:43,540
Klein knocks a network
management lab and that's where,

61
00:03:43,541 --> 00:03:48,100
of course a lot of the uh, arpanet
development took place, uh,

62
00:03:48,110 --> 00:03:50,220
at least the host protocols,
space event.

63
00:03:50,260 --> 00:03:55,190
And eventually those same people became
part of the, uh, Internet story. Uh,

64
00:03:55,390 --> 00:03:58,570
it turns out there are some other
notable people who went to that same high

65
00:03:58,571 --> 00:04:00,340
school, uh, before we did.

66
00:04:00,410 --> 00:04:04,540
Then people like Robert Redford and
Marilyn Monroe and Don Drysdale,

67
00:04:04,541 --> 00:04:06,700
and you can look it up if you
go look at advantage is high.

68
00:04:07,420 --> 00:04:10,360
I had dinner with David
Skorton a few months ago.

69
00:04:10,361 --> 00:04:12,760
He's now the secretary of the Smithsonian.

70
00:04:12,761 --> 00:04:16,180
And we got to talking and he said
he grew up in La and he said, well,

71
00:04:16,181 --> 00:04:19,420
where did you live? He said,
Sherman Oaks. And uh, I said,

72
00:04:19,421 --> 00:04:21,580
what high school did you go
to? He says, Van Nuys High.

73
00:04:21,640 --> 00:04:25,600
So about six years after I left,
but, but you know, so this is,

74
00:04:25,601 --> 00:04:29,470
there must've been something interesting
going on in that neighborhood back in

75
00:04:29,471 --> 00:04:31,840
the late fifties and early sixties.

76
00:04:32,350 --> 00:04:36,520
So I have very strong
positive feelings about a,

77
00:04:36,521 --> 00:04:40,530
about Los Angeles. Uh, and
right. Many of you, uh,

78
00:04:40,540 --> 00:04:44,140
I scratch my head a little
bit about, uh, the, uh,

79
00:04:44,170 --> 00:04:48,000
technical enterprise here. I mean,
we all know about Hollywood, uh,

80
00:04:48,070 --> 00:04:51,640
the same head scratching goes
on further south in San Diego,

81
00:04:51,641 --> 00:04:56,060
which is where I'm headed after
I finished my work here at, uh,

82
00:04:56,061 --> 00:04:58,690
at Google in La.
Uh,

83
00:04:58,930 --> 00:05:01,750
so I think we need to
do something to make,

84
00:05:01,820 --> 00:05:05,140
I'm probably jumping into other
questions that you have, but,

85
00:05:05,440 --> 00:05:10,440
but I think we need to do something to
make the La technical seen more visible

86
00:05:11,790 --> 00:05:16,180
to people. There's a lot of
capacity here, uh, last June.

87
00:05:16,210 --> 00:05:21,010
At the end of June, I went down to San
Diego and spent two and a half days there.

88
00:05:21,070 --> 00:05:23,200
We called it surf's up in San Diego.

89
00:05:23,610 --> 00:05:27,310
And I know bad puns minus two.
Uh,

90
00:05:27,340 --> 00:05:32,340
but the idea was to have meetings with a
little round tables of 20 people coming

91
00:05:32,501 --> 00:05:35,890
from different, um,
interested disciplines.

92
00:05:35,891 --> 00:05:40,480
So a lot of it was biotech, some of it
was, you know, uh, quantum computing.

93
00:05:40,481 --> 00:05:44,320
Some of it was advanced, a high
speed processing, networking,

94
00:05:44,321 --> 00:05:47,920
and some of there were about 10 or 12
different topics that we picked on.

95
00:05:47,921 --> 00:05:50,650
And then populated the round tables in.

96
00:05:50,920 --> 00:05:53,500
My purpose was to find out
what was going on down there.

97
00:05:54,010 --> 00:05:56,470
And then at the end of those two days,
uh,

98
00:05:56,500 --> 00:06:01,500
I made it public lecture at Qualcomm
auditorium summarizing what I had learned.

99
00:06:03,530 --> 00:06:05,580
And one thing that really surprised me,

100
00:06:05,581 --> 00:06:10,530
it was there were 850 bio tech companies
in San Diego, most of them startups,

101
00:06:10,640 --> 00:06:12,350
but some of them very big like scripts.

102
00:06:13,010 --> 00:06:15,710
I haven't done that in Los
Angeles in a long time.

103
00:06:15,711 --> 00:06:19,970
I was out here many years back and we did
something called surfs up in Hollywood.

104
00:06:20,610 --> 00:06:25,070
Um, but I haven't returned to do
that. And that your, even your,

105
00:06:25,860 --> 00:06:29,960
your line of questions make me think
that would be a timely thing to do.

106
00:06:30,290 --> 00:06:33,500
The important part being to report what,

107
00:06:33,680 --> 00:06:38,680
what was discovered in some way that's
visible to the venture community.

108
00:06:39,320 --> 00:06:44,210
Some of you will know that Bill Maris,
uh, who used to run our Google ventures,

109
00:06:44,530 --> 00:06:48,290
uh, has now started a
southern California, uh,

110
00:06:48,320 --> 00:06:50,680
fund specifically to,
uh,

111
00:06:50,720 --> 00:06:55,370
to focus on southern California
r and d activities. And so, uh,

112
00:06:55,670 --> 00:06:57,560
I think that we should
take advantage of that.

113
00:06:57,590 --> 00:07:01,070
We could certainly use your platform
as a way of making things more visible.

114
00:07:02,100 --> 00:07:04,710
Well, I mean, I'm glad to say
that we do have an la office now,

115
00:07:04,740 --> 00:07:06,720
so it's very exciting.
Um,

116
00:07:06,870 --> 00:07:10,890
I'm wondering if is there any particular
area in tech that you see being

117
00:07:10,891 --> 00:07:13,320
particularly suited to the La area?

118
00:07:13,950 --> 00:07:18,480
So this is a really good question because
the answer is I don't know for sure,

119
00:07:18,481 --> 00:07:20,310
which means that like many others,

120
00:07:20,311 --> 00:07:24,090
I'm not sure what's going on in
Los Angeles or ignore, you know,

121
00:07:24,100 --> 00:07:29,010
something in the San Fernando Valley
and La Proper or out here, you know,

122
00:07:29,100 --> 00:07:32,880
in mountain view mountain
view. I know Santa Monica, uh,

123
00:07:33,090 --> 00:07:36,060
historically there have been some
very important things going on here,

124
00:07:36,100 --> 00:07:38,340
like rams for example.
Um,

125
00:07:38,640 --> 00:07:41,310
but that was important to
specifically to the air force.

126
00:07:41,311 --> 00:07:45,210
There's the jet propulsion
laboratory, which I spend time at, uh,

127
00:07:45,211 --> 00:07:50,190
on the interplanetary Internet. So I know
a little bits and pieces, but not much.

128
00:07:50,670 --> 00:07:54,180
In fact, one of the most visible
technical activities going on now,

129
00:07:54,240 --> 00:07:59,240
and I won't say southern
California because Santa
Barbara isn't exactly southern

130
00:07:59,371 --> 00:08:00,031
California,

131
00:08:00,031 --> 00:08:03,990
but that's a place where there's some
deep work going on in quantum computing at

132
00:08:03,991 --> 00:08:08,310
UC Santa Barbara and at
Google in that location. Um,

133
00:08:08,460 --> 00:08:10,530
so I'm feeling,

134
00:08:10,590 --> 00:08:15,590
I'm so glad that you're asking these
questions because I'm feeling this void of

135
00:08:16,051 --> 00:08:21,051
knowledge that I suspect is actually
full of some pretty interesting stuff.

136
00:08:21,511 --> 00:08:21,721
I mean,

137
00:08:21,721 --> 00:08:25,350
we wouldn't have such a big office here
if there weren't a lot of interesting

138
00:08:25,351 --> 00:08:29,730
things going on with a lot of very
smart people wanting to do something.

139
00:08:29,910 --> 00:08:32,670
But I actually don't have a
good answer to that question.

140
00:08:33,600 --> 00:08:36,300
I will argue that,
um,

141
00:08:36,570 --> 00:08:39,120
given the fact that Hollywood is here,

142
00:08:39,780 --> 00:08:44,780
that there is a lot of technology that's
bubbling up well past the old computer

143
00:08:45,871 --> 00:08:49,800
graphics stuff, uh, that may
turn out to be very relevant.

144
00:08:50,100 --> 00:08:54,170
One of them is magic leap, except
that's going on out in Florida. Uh,

145
00:08:54,210 --> 00:08:59,210
but there are places including aerospace
that could potentially make use of some

146
00:09:00,121 --> 00:09:03,470
of these new technologies,
but I haven't,

147
00:09:03,840 --> 00:09:08,170
haven't had a chance to sit down
and actually probe what's going on.

148
00:09:08,190 --> 00:09:12,120
So that's a really useful
idea. Uh, you mentioned, uh,

149
00:09:12,121 --> 00:09:16,990
quantum computing and speaking
as a recovering physicist,
uh, it feels like, uh,

150
00:09:17,250 --> 00:09:19,800
we've been talking about quantum computing
for a very long time and not making

151
00:09:19,801 --> 00:09:21,240
much headway.
Uh,

152
00:09:21,330 --> 00:09:24,840
do you think we'll see
something approaching quantum
computing in our lifetime?

153
00:09:25,140 --> 00:09:27,290
I think there's no doubt about it.
Uh,

154
00:09:27,330 --> 00:09:31,950
let me offer maybe two or three
observations. The first one is that,

155
00:09:32,380 --> 00:09:34,270
uh, an early, uh,

156
00:09:34,590 --> 00:09:37,470
computer that took advantage
of quantum effects.

157
00:09:37,471 --> 00:09:42,270
I'm wording this very carefully is
the D-Wave system. Uh, in Canada,

158
00:09:42,271 --> 00:09:46,140
there were huge arguments among
the physicist about, well,

159
00:09:46,141 --> 00:09:48,960
this wasn't really quantum computing.
It was addy,

160
00:09:49,010 --> 00:09:53,200
a bad luck and it was a
relaxation method. And so on, uh,

161
00:09:53,270 --> 00:09:57,600
we acquired one of these
together with Nasa Ames, uh,

162
00:09:57,610 --> 00:10:01,110
and began exploring algorithms
that we could use on that system.

163
00:10:01,140 --> 00:10:05,850
And we found several algorithms
that offered a optimization of,

164
00:10:05,851 --> 00:10:10,020
of things that we cared about that were
useful to us. In the meantime, however,

165
00:10:10,050 --> 00:10:14,460
a Hartman, Nevin whose company we
acquired, uh, and turn it into Picasa,

166
00:10:15,040 --> 00:10:16,820
uh,
here in Santa Monica,

167
00:10:16,830 --> 00:10:21,630
got very interested in quantum computing
and was the reason we bought the d wave

168
00:10:21,631 --> 00:10:24,270
machine. A hunt mode is now, uh,

169
00:10:24,271 --> 00:10:28,470
the point guy on our quantum effort
in quantum development effort.

170
00:10:28,800 --> 00:10:30,570
This is serious quantum computing.

171
00:10:30,900 --> 00:10:33,990
We've had a seven cubit
system in operation.

172
00:10:33,991 --> 00:10:36,990
We are shooting for a 49 cubits system.

173
00:10:37,560 --> 00:10:41,460
There's an unfortunate term called
quantum supremacy, which sounds, you know,

174
00:10:41,461 --> 00:10:43,380
like we want to dominate
the world or something.

175
00:10:43,700 --> 00:10:48,150
We had really speaks to the number of
cubits that you need in order to carry out

176
00:10:48,151 --> 00:10:50,240
computations.
That would be uh,

177
00:10:51,400 --> 00:10:55,470
either too time consuming or maybe even
nearly impossible using conventional

178
00:10:55,471 --> 00:10:57,420
methods. Uh, I think they are,

179
00:10:57,450 --> 00:11:01,140
they were shooting to get that actually
in operation by the end of the year.

180
00:11:01,141 --> 00:11:05,680
I'm now, I suspect they hope to
get some sometime this year. Uh,

181
00:11:05,790 --> 00:11:10,790
so this is an important effort because
there are certain kinds of computations

182
00:11:11,071 --> 00:11:14,670
that lend themselves to this
kind of rapid computing.

183
00:11:15,030 --> 00:11:18,360
One of which everybody here might
know is called the shores. Algorithm.

184
00:11:18,780 --> 00:11:22,830
Shores Algorithm is a way of,
of a factoring very,

185
00:11:22,831 --> 00:11:27,831
very large products with primes or in
factory numbers to determine whether they

186
00:11:27,991 --> 00:11:32,940
are prime or non. Uh, it turns out
that a lot of the security systems,

187
00:11:32,941 --> 00:11:37,770
including public key algorithms like Rsa
are in fact based on the difficulty of

188
00:11:37,771 --> 00:11:39,690
factoring products of large primes.

189
00:11:40,230 --> 00:11:44,130
So if shores algorithm could be
run in a real quantum machine,

190
00:11:44,550 --> 00:11:49,550
then you could in fact break some of
the cryptography by a good fortune.

191
00:11:51,121 --> 00:11:55,660
There are other branches of mathematics
that can be adapted to a cryptog

192
00:11:55,780 --> 00:11:58,960
cryptographic purposes.
One of which is lattice mathematics.

193
00:11:59,380 --> 00:12:03,890
And so there's already a parallel
effort to do post quantum, uh,

194
00:12:03,910 --> 00:12:08,530
security and cryptography
using an alternative. Uh,

195
00:12:08,560 --> 00:12:09,900
nonetheless,
uh,

196
00:12:09,970 --> 00:12:14,970
there are other much more valuable
algorithms that maybe feasible with the

197
00:12:15,401 --> 00:12:17,680
quantum systems,
with enough cubits in them.

198
00:12:18,220 --> 00:12:22,580
So I'm now persuaded that we will
see a serious and useful, uh,

199
00:12:22,600 --> 00:12:26,140
quantum calculations being done.
Certainly before the end of this decade.

200
00:12:26,920 --> 00:12:29,020
I was up at bell labs,
um,

201
00:12:29,050 --> 00:12:33,550
just last week and had a look at
another quantum system that they've been

202
00:12:33,551 --> 00:12:38,200
working on and, uh, I'm not an
expert in this space, so, uh,

203
00:12:38,210 --> 00:12:42,640
I'm not sure I will be
able to capture very well,

204
00:12:42,970 --> 00:12:44,710
um,
what they were doing,

205
00:12:44,711 --> 00:12:49,711
but to suffice it to say that quantum
calculation depends on maintaining,

206
00:12:50,850 --> 00:12:55,540
uh, the, uh, entangled
state of the cubits.

207
00:12:55,900 --> 00:13:00,900
And if you can maintain that
entangled state for long enough,

208
00:13:01,240 --> 00:13:04,690
then you can actually do a
computation and get some answers back.

209
00:13:05,230 --> 00:13:10,230
But typically the duration of a quantum
state manipulation is on the order of

210
00:13:11,711 --> 00:13:15,400
milliseconds, tens of
milliseconds, things like that. Um,

211
00:13:15,760 --> 00:13:20,760
and this particular thing that the guys
at bell labs are doing could have more

212
00:13:23,140 --> 00:13:26,230
like seconds to minutes of a
persistence of quantum state,

213
00:13:26,800 --> 00:13:30,610
in which case they would have the ability
to do much more serious computations.

214
00:13:31,290 --> 00:13:35,750
Uh, so there I think
there is a is real. Um,

215
00:13:35,830 --> 00:13:40,060
I have real expectations that we
will be applying quantum methods,

216
00:13:40,540 --> 00:13:44,350
uh, within a few years
time, uh, at Google.

217
00:13:44,380 --> 00:13:46,460
Some of you will know that we've,
uh,

218
00:13:46,630 --> 00:13:50,680
invested in a variety of different
computational platforms. The CPU,

219
00:13:51,190 --> 00:13:55,840
Gpu, yes. Now TPU for the tensor
processing units for machine learning.

220
00:13:56,020 --> 00:14:00,010
And I fully expect that CUPE use
will be there at some point as well.

221
00:14:02,620 --> 00:14:05,040
I mean in another one
of those, uh, you know,

222
00:14:05,290 --> 00:14:09,340
harbingers of doom and our industry
is always talking about AI and the

223
00:14:09,341 --> 00:14:10,180
progression of Ai.

224
00:14:10,210 --> 00:14:13,120
And that's also seems like
up until recently that was
something that was in the

225
00:14:13,121 --> 00:14:16,570
distant future. How do you see the
development of AI in recent years?

226
00:14:17,610 --> 00:14:20,560
Well, I was around, uh, Ian,

227
00:14:20,930 --> 00:14:23,400
it's in the 1960s,
which,

228
00:14:23,430 --> 00:14:27,710
which sounds like it was sometime near
the civil war, even though that that's,

229
00:14:27,870 --> 00:14:29,220
you know,
a hundred years later

230
00:14:31,580 --> 00:14:35,960
here's were actually a
series of Tutsis. So, um,

231
00:14:36,420 --> 00:14:39,420
at Stanford there was a
great deal of excitement. Uh,

232
00:14:39,450 --> 00:14:43,200
John McCarthy and Ed Feigenbaum
and others were founders of,

233
00:14:43,260 --> 00:14:44,670
of artificial intelligence.

234
00:14:45,120 --> 00:14:50,120
They were thinking mostly general
artificial intelligence where a computer

235
00:14:50,611 --> 00:14:55,611
program would learn to reason about
a world model that it formed from its

236
00:14:57,261 --> 00:15:00,540
interactions with the real
world. Uh, but I remember, uh,

237
00:15:00,590 --> 00:15:04,350
an early attempt at machine
language translation. Uh,

238
00:15:05,060 --> 00:15:06,440
we naively,

239
00:15:06,441 --> 00:15:09,650
I didn't participate in this so that
I'm just giving you the observer's

240
00:15:09,651 --> 00:15:10,281
perspective,

241
00:15:10,281 --> 00:15:15,281
but they naive laid it just loaded a
Russian English dictionary a into the

242
00:15:15,441 --> 00:15:19,460
computer in the hope that it
would just do natural translation.

243
00:15:19,730 --> 00:15:21,350
So then they fed in a,

244
00:15:21,370 --> 00:15:25,190
and an English language
expression out of sight,

245
00:15:25,490 --> 00:15:30,140
out of mind, and they translated it
interruption through this dictionary.

246
00:15:30,160 --> 00:15:34,100
Then they translated it back and
it came back invisible idiot.

247
00:15:36,530 --> 00:15:39,830
And that's when they realized there was
probably more to this translation thing.

248
00:15:39,831 --> 00:15:42,050
And then just the dictionary.
Well,

249
00:15:42,140 --> 00:15:46,970
a series of evolutions occurred in
this natural language translation,

250
00:15:46,971 --> 00:15:51,200
one of which was a statistical methods
where you have a large corpus of

251
00:15:51,201 --> 00:15:56,170
documents that are the same documents
in multiple languages and you use a

252
00:15:56,180 --> 00:15:56,930
simple,

253
00:15:56,930 --> 00:16:01,490
relatively simple statistical way of
saying this phrase and this language is

254
00:16:01,491 --> 00:16:04,100
frequently associated with
that phrase in this language.

255
00:16:04,430 --> 00:16:07,310
And you use these statistics
in order to do the translation.

256
00:16:07,610 --> 00:16:12,610
This got us a fairly significant
improvement in the quality of translation.

257
00:16:12,801 --> 00:16:16,310
And then we sort of flattened
down, uh, subsequent to that,

258
00:16:16,730 --> 00:16:20,960
the development of large
high, you know, what's right,

259
00:16:20,990 --> 00:16:25,340
large numbers, large numbers
of layers, multilayer networks.

260
00:16:25,810 --> 00:16:30,470
Um, we're talking about hundreds
of layers, for example, uh,

261
00:16:30,471 --> 00:16:35,270
allowed us to do even better
translations at what surprised me,

262
00:16:35,530 --> 00:16:36,110
uh,

263
00:16:36,110 --> 00:16:40,790
about this particular kind of machine
learning is that instead of having a

264
00:16:40,791 --> 00:16:44,870
different neural network
for each language pair,

265
00:16:44,900 --> 00:16:48,380
which is what I imagined
would be necessary. So if
we do a hundred languages,

266
00:16:48,381 --> 00:16:52,430
that's 10,000 different pairs in
both, you know, each direction.

267
00:16:52,940 --> 00:16:53,773
Um,

268
00:16:54,230 --> 00:16:59,000
we ended up building one gigantic neural
network and feeding it all language

269
00:16:59,030 --> 00:17:03,470
pairs. And I thought, well,
this is hopeless, you know,
how could that possibly work?

270
00:17:03,800 --> 00:17:07,340
But with enough layers
in a neural network,

271
00:17:07,850 --> 00:17:11,500
my little cartoon model,
this is my understanding of this is,

272
00:17:11,501 --> 00:17:15,650
is fairly superficial than
my little cartoon model says
that the more layers you

273
00:17:15,651 --> 00:17:20,600
have in the neural network, the more
state information you can remember.

274
00:17:21,440 --> 00:17:22,820
And so the,

275
00:17:22,940 --> 00:17:27,290
as you feed these systems more and
more examples and you train them, yes,

276
00:17:27,291 --> 00:17:30,260
you've got to right or no,
you got it wrong. Uh, this,

277
00:17:30,650 --> 00:17:35,630
this experience is encoded in the
various weights that show up in different

278
00:17:35,631 --> 00:17:38,030
places in the layers
of the neural network.

279
00:17:38,510 --> 00:17:43,510
So we discovered that by allowing
multiple languages to be trained on this

280
00:17:44,690 --> 00:17:48,560
single neural network, that we get
improvement in all language pairs.

281
00:17:49,020 --> 00:17:53,310
Something interesting is going
on there. Uh, on the other hand,

282
00:17:53,311 --> 00:17:55,800
there are also places
where mistakes happen.

283
00:17:56,340 --> 00:18:00,180
So here we are in 2018 we still
don't have perfection. Uh,

284
00:18:00,181 --> 00:18:04,500
I was in Heidelberg last
year and I was looking up,

285
00:18:04,910 --> 00:18:09,120
uh, the weather report to see what was
the weather going to be for that day.

286
00:18:09,510 --> 00:18:12,690
And so since I was in Heidelberg
doing going little Google search,

287
00:18:12,930 --> 00:18:16,200
it directed me to what
was a German website.

288
00:18:16,260 --> 00:18:20,640
I didn't actually notice that because
it was translated so quickly that I was

289
00:18:20,641 --> 00:18:24,660
seeing English. And so I thought it
was a, an English language website.

290
00:18:25,110 --> 00:18:26,670
And I was looking at the report,

291
00:18:26,671 --> 00:18:31,671
it said it was zero chance of rain and a
zero chance of fog and there was also a

292
00:18:32,241 --> 00:18:36,900
zero chance of ice cream.
And you know,

293
00:18:36,960 --> 00:18:40,800
I looked at that and so I took
this to my German friends and says,

294
00:18:40,801 --> 00:18:45,040
you have ice cream storms here.
Well, it turns out that, uh,

295
00:18:45,080 --> 00:18:49,980
that the word ice EIS in German could
be interpreted either as ice cream or as

296
00:18:49,981 --> 00:18:50,814
hale.

297
00:18:51,090 --> 00:18:55,640
And the natural language processing system
didn't have enough context apparently

298
00:18:55,650 --> 00:18:58,530
to figure out which one it was,
though it said ice cream.

299
00:18:58,800 --> 00:19:02,670
So of course I took a screenshot of that
and he sent it to our natural language

300
00:19:02,671 --> 00:19:06,750
processing guys, uh, to remind them
that we had not achieved perfection yet.

301
00:19:08,580 --> 00:19:10,250
But I can say with,

302
00:19:10,251 --> 00:19:15,251
with some assurance that our machine
learning methods are becoming incredibly

303
00:19:16,411 --> 00:19:21,210
powerful. Uh, just to
remind you a year or so ago,

304
00:19:21,250 --> 00:19:21,930
uh,

305
00:19:21,930 --> 00:19:26,930
the deepmind team built the Alpha goal
system and taught him how to play go at

306
00:19:28,261 --> 00:19:29,460
grand master level.

307
00:19:29,520 --> 00:19:34,230
We had contests in South
Korea and in China,

308
00:19:34,710 --> 00:19:39,060
the machine one, almost all of the
contests with these grand masters,

309
00:19:39,061 --> 00:19:40,170
I think except for one,

310
00:19:40,171 --> 00:19:44,190
which at least at all manage to
get one out of five successfully.

311
00:19:44,640 --> 00:19:49,530
But that in itself was not
the most dramatic example
for me of what is happening

312
00:19:49,531 --> 00:19:54,000
with that technology. Uh, the most
dramatic example is called Alpha zero.

313
00:19:54,570 --> 00:19:58,880
And in this case, uh, instead
of spending weeks, uh,

314
00:19:59,040 --> 00:20:02,880
training the programs and,
and letting them play each other,

315
00:20:03,150 --> 00:20:06,780
different versions of the program,
playing each other millions of games, uh,

316
00:20:06,781 --> 00:20:10,290
over a period of three days
starting only with the rules of go,

317
00:20:11,010 --> 00:20:15,480
they got Alpha zero to learn how
to play a grandmaster level go,

318
00:20:15,780 --> 00:20:19,410
which is astonishing to make matters
even more than salmon mushing.

319
00:20:19,470 --> 00:20:22,740
Starting with the rules of chess.

320
00:20:23,070 --> 00:20:28,070
Alpha zero learned in a few hours to
play better than any of the known,

321
00:20:28,360 --> 00:20:31,710
uh, computer based just
plain systems. You know,

322
00:20:32,110 --> 00:20:34,920
this is not to say that that particular,
uh,

323
00:20:35,010 --> 00:20:37,820
three hour learning system would produce,
uh,

324
00:20:37,860 --> 00:20:41,010
w could be an international
grandmaster human player,

325
00:20:41,250 --> 00:20:45,310
but the fact that a few hours that
they could train it to play chess, uh,

326
00:20:45,360 --> 00:20:47,560
that well who is really quite astonishing.

327
00:20:47,560 --> 00:20:52,150
So that tells you that there is great
power in machine learning in many,

328
00:20:52,151 --> 00:20:53,470
many different applications.

329
00:20:53,740 --> 00:20:58,090
We still don't entirely understand all
the things that are going on in the

330
00:20:58,091 --> 00:21:01,390
machine learning space. So in
these neural networks, for example,

331
00:21:01,780 --> 00:21:06,580
if you train it to distinguish
the classical cat from a dog, um,

332
00:21:06,610 --> 00:21:06,960
it's,

333
00:21:06,960 --> 00:21:11,960
it's then possible to alter a small
number of pixels in the challenge picture

334
00:21:14,170 --> 00:21:16,440
and have the system.
Ms Is,

335
00:21:16,510 --> 00:21:20,800
this is the small number of pixels is
not distinguishable to you. Human being,

336
00:21:20,830 --> 00:21:22,840
it's still looks like a dog to us,

337
00:21:23,350 --> 00:21:27,040
but the machine learning system
could say it's a kangaroo.

338
00:21:28,060 --> 00:21:31,840
And so there is something
going on, uh, with the,

339
00:21:32,200 --> 00:21:34,180
the weight of the Pixel,

340
00:21:34,181 --> 00:21:37,810
each pixel in the image
as it's being processed,

341
00:21:37,840 --> 00:21:42,130
working through this neural network.
There's little places somewhere in the,

342
00:21:42,160 --> 00:21:47,160
in the chain that are particularly
sensitive to those pixels.

343
00:21:47,650 --> 00:21:52,270
And if you change those pixels, it causes
the system to make their own decision.

344
00:21:52,480 --> 00:21:54,520
This is a little bit like chaos theory,

345
00:21:54,521 --> 00:21:58,120
and I'm not trying to draw more than
just a superficial analogy here,

346
00:21:58,420 --> 00:22:02,900
but in chaos theory, you know that a
chaotic system will produce very, uh,

347
00:22:03,100 --> 00:22:06,940
widely varying outputs based on very,

348
00:22:06,941 --> 00:22:11,080
very small changes in the input.
And so it's not continuous.

349
00:22:11,440 --> 00:22:15,970
And so we're seeing a similar
kind of thing going on now
that's machine learning.

350
00:22:16,450 --> 00:22:21,070
Some of it's spectacularly good, like
being able to detect, uh, um, uh,

351
00:22:21,210 --> 00:22:24,070
a problem that diabetic retinopathy,
for example,

352
00:22:24,400 --> 00:22:28,870
we trained a neural network to
look at images of people's retinas.

353
00:22:28,990 --> 00:22:30,910
And then we had a ophthalmologists,

354
00:22:30,911 --> 00:22:35,830
something 85 of them assess whether or
not this image demonstrated or did not

355
00:22:35,831 --> 00:22:39,580
demonstrate, uh, the diabetic
retinopathy syndrome.

356
00:22:39,880 --> 00:22:43,180
Then we trained a neural network on
the basis of that data and the neural

357
00:22:43,181 --> 00:22:47,860
network did a better job than the,
uh, uh, ophthalmologist did, uh,

358
00:22:47,861 --> 00:22:50,380
on, uh, new subsequent examples.

359
00:22:50,500 --> 00:22:53,170
So we clearly have a
very powerful technology.

360
00:22:53,380 --> 00:22:58,150
None of this is what I would call
general purpose, artificial intelligence.

361
00:22:59,020 --> 00:23:04,020
The thing that you and I do that machines
don't right now is to take from a

362
00:23:04,241 --> 00:23:05,950
small number of samples,

363
00:23:06,490 --> 00:23:11,490
the ability to model what we are
experiencing and then to reason about that

364
00:23:12,131 --> 00:23:16,750
model. And so the example here,
this thing is a table. Why do we,

365
00:23:16,751 --> 00:23:21,670
what is the main property of table?
Well, it's a sort of a flat surface. Uh,

366
00:23:21,700 --> 00:23:23,410
and the,

367
00:23:23,720 --> 00:23:26,950
the thing that we quickly understand
is that there are many things.

368
00:23:26,951 --> 00:23:29,460
It could be a table, could be, uh,

369
00:23:29,770 --> 00:23:32,590
an orange crate could be
anything with a flat surface.

370
00:23:32,591 --> 00:23:36,370
And the other thing we've understood
implicitly is that if something has a flat

371
00:23:36,371 --> 00:23:37,204
bottom,

372
00:23:37,360 --> 00:23:41,350
then it can be placed on a table and
the table will support it if it's not a

373
00:23:41,351 --> 00:23:43,750
flat bottom and may fall over,
roll off the table.

374
00:23:44,080 --> 00:23:47,840
So we very quickly get
this idea very quickly,

375
00:23:47,841 --> 00:23:52,841
but machines don't because at the moment
they don't formulate models that you

376
00:23:53,361 --> 00:23:54,320
can reason about.

377
00:23:54,380 --> 00:23:59,090
And I think that's the
next big breakthrough is
understanding how to present

378
00:23:59,450 --> 00:24:02,330
information to assist them.
That can reason about it.

379
00:24:02,400 --> 00:24:04,120
Now if you look at a self driving car.

380
00:24:04,140 --> 00:24:07,350
So I'm really answering the hope
you don't mind. I mean it's,

381
00:24:07,400 --> 00:24:08,150
this is what happened.

382
00:24:08,150 --> 00:24:12,800
It's a big question for former former
Stanford professors can rattle on for 50

383
00:24:12,801 --> 00:24:15,620
minutes on any topic even if
they know nothing about it.

384
00:24:17,060 --> 00:24:19,670
So I promise I won't
do 15 minutes on this,

385
00:24:19,671 --> 00:24:23,570
but the self driving cars of course
had been in the headlines partly as a

386
00:24:23,571 --> 00:24:24,290
consequences,

387
00:24:24,290 --> 00:24:28,970
that very sad accident that happened
to a new Uber self driving car. Uh,

388
00:24:29,000 --> 00:24:33,590
what's interesting about the Waymo
effort at Google or at Alphabet,

389
00:24:34,050 --> 00:24:35,630
uh, is the, uh,

390
00:24:35,631 --> 00:24:40,631
amount of image recognition
and inference that the systems,

391
00:24:41,050 --> 00:24:45,050
uh, exercise. And so there's
a classification effort.

392
00:24:45,070 --> 00:24:49,370
These are the field of view is
gathering data visually with Lidar.

393
00:24:49,820 --> 00:24:52,700
Uh, and of course a detailed
knowledge of where our,

394
00:24:52,730 --> 00:24:56,780
where am I and what are the streets
that I should be on and so on. Uh,

395
00:24:56,840 --> 00:24:59,660
these systems classify images in the,

396
00:24:59,661 --> 00:25:04,661
in the field and then make predictions
about what those classified objects might

397
00:25:06,171 --> 00:25:10,400
do. So this is somebody on a bicycle.
This is a pedestrian. This is a truck.

398
00:25:10,401 --> 00:25:12,510
This is a car.
Um,

399
00:25:12,950 --> 00:25:17,950
the modeling that goes on is very
important because the system is predicting

400
00:25:18,081 --> 00:25:22,850
possible future outcomes of the,

401
00:25:22,870 --> 00:25:25,430
uh,
of what those objects might do.

402
00:25:26,120 --> 00:25:31,120
And it's planning what to do if any
of those particular things eventuate.

403
00:25:32,150 --> 00:25:35,630
And that is a form of model building.

404
00:25:36,170 --> 00:25:37,340
And so we're,

405
00:25:37,430 --> 00:25:41,480
I think we're edging into some
interesting territory now that is not done

406
00:25:41,481 --> 00:25:44,300
exclusively by machine
learning neural networks.

407
00:25:44,300 --> 00:25:48,030
It's also done by very deliberate
programming. Uh, again,

408
00:25:48,031 --> 00:25:50,600
with my knowledge of this
is relatively superficial,

409
00:25:50,601 --> 00:25:55,520
so I can't quite tease apart for you
which parts are deliberate programming and

410
00:25:55,521 --> 00:25:58,220
which parts are inferred
learning from machine learning.

411
00:25:58,670 --> 00:26:03,470
But the mix is quite
powerful. Uh, finally, uh,

412
00:26:03,770 --> 00:26:06,200
everyone who sees some of these results,

413
00:26:06,201 --> 00:26:11,201
whether it's a self driving car or a
impressive a game playing board plane

414
00:26:11,600 --> 00:26:14,630
skills, uh, or uh, or, uh,

415
00:26:14,720 --> 00:26:16,670
medical image analysis,

416
00:26:17,420 --> 00:26:21,380
everyone should appreciate that
these are extremely narrow, uh,

417
00:26:21,860 --> 00:26:25,220
behaviors. These are very powerful
but very narrow behaviors.

418
00:26:25,640 --> 00:26:30,640
And human beings exhibit an incredibly
broad range of abilities to abstract from

419
00:26:34,670 --> 00:26:38,720
the real world that they sense
build models in reason about them.

420
00:26:39,170 --> 00:26:43,770
And so we're a long ways away I think
from having that capability in place.

421
00:26:45,180 --> 00:26:48,210
So, uh, I have to thank you again for, uh,

422
00:26:48,211 --> 00:26:52,680
for the name because I think if we do
have a reddit skunkworks AI project,

423
00:26:52,710 --> 00:26:54,540
we'll have to call it invisible an idiot.

424
00:26:57,210 --> 00:27:01,350
Um, you know, we talk a lot
in tech about the future.

425
00:27:01,770 --> 00:27:05,040
Uh, I'm wondering if there's any, uh,

426
00:27:05,160 --> 00:27:09,000
technologies that you've seen in your
career that never really caught on, uh,

427
00:27:09,001 --> 00:27:11,940
and what,
what those were that should have maybe,

428
00:27:12,860 --> 00:27:16,630
well, there are, are several that
have, uh, of course it's clearly the,

429
00:27:16,631 --> 00:27:21,590
the machine learning, uh, TPU
stuff is pretty dramatic. Uh,

430
00:27:21,650 --> 00:27:26,650
recently I was just at the open networking
summit this morning in downtown La.

431
00:27:27,630 --> 00:27:30,920
Um, and been, I had been looking at, um,

432
00:27:31,940 --> 00:27:33,410
switching hardware,

433
00:27:34,100 --> 00:27:39,100
which is programmable now I had for a
long time essentially dismissed software

434
00:27:41,691 --> 00:27:46,691
defined networking as a kind of
marketing buzzword because after all,

435
00:27:47,661 --> 00:27:51,290
all the routers that I'd ever encountered
or the ones that we used to call

436
00:27:51,291 --> 00:27:54,770
gateways, cause we didn't know they
were supposed to be called routers. Uh,

437
00:27:54,800 --> 00:27:58,760
we're all software. I mean, they're
programmed to do stuff. And so I thought,

438
00:27:58,761 --> 00:28:00,470
what's the big deal?
Well,

439
00:28:00,471 --> 00:28:04,160
there is a big deal here because
some of these platforms are very,

440
00:28:04,161 --> 00:28:08,330
very powerful switching engines and
all they know how to do is switch,

441
00:28:08,331 --> 00:28:11,510
but they don't do anything unless you
explain to them what they're supposed to

442
00:28:11,511 --> 00:28:15,710
do. And so they are more
programmable, uh, in the,

443
00:28:15,711 --> 00:28:19,280
in a very fundamental way
than a classic switch,

444
00:28:19,281 --> 00:28:23,990
which is using software in almost
exclusively to do the switching.

445
00:28:23,991 --> 00:28:28,580
Whereas this is hardware that does the
switching in accordance with a software

446
00:28:28,581 --> 00:28:33,581
program that tells it how it should
evaluate the bits in the packet to decide

447
00:28:33,651 --> 00:28:34,550
where they're supposed to go.

448
00:28:34,551 --> 00:28:36,830
But it uses the hardware to
do the actual forwarding.

449
00:28:37,880 --> 00:28:42,880
So I'm now persuaded that
that is a paradigm shift in,

450
00:28:42,970 --> 00:28:47,150
uh, in the implementation of switching
systems for community communications.

451
00:28:47,151 --> 00:28:51,170
And now I'm persuaded there's some
very interesting horsepower, uh,

452
00:28:51,260 --> 00:28:54,500
to be applied there. So
that's one technology. Uh,

453
00:28:54,520 --> 00:28:58,910
there is another one about which
I know, again, very, not much, uh,

454
00:28:58,940 --> 00:29:03,380
but the magic leap guys, uh, in Florida,

455
00:29:03,500 --> 00:29:05,930
uh,
had written an article in wired.

456
00:29:05,931 --> 00:29:09,110
I think if some of you may have
already seen it, uh, if you haven't,

457
00:29:09,111 --> 00:29:12,230
you might take, if you're curious about
this, you might take the time to look.

458
00:29:12,560 --> 00:29:16,730
They've been able to, uh,
produce images for us, you know,

459
00:29:16,731 --> 00:29:20,030
by wearing
glasses,

460
00:29:20,360 --> 00:29:23,390
not Google glass in the classic sense,
but something which,

461
00:29:23,570 --> 00:29:28,250
which is computer controlled, which
puts relatively opaque images, uh,

462
00:29:28,460 --> 00:29:32,510
in front of you embedded
in the actual visual scene.

463
00:29:32,511 --> 00:29:35,480
So we're talking about, um, not, uh,

464
00:29:35,540 --> 00:29:37,730
not purely virtual reality,

465
00:29:37,731 --> 00:29:42,731
but augmented reality where these virtual
objects injected into the field of

466
00:29:42,851 --> 00:29:46,990
view and you can walk towards them and
into them and they'd be there quite

467
00:29:46,991 --> 00:29:51,250
realistic. Um, I don't know
where that's all going to end up,

468
00:29:51,730 --> 00:29:55,510
but I'm persuaded that our ability to,
um,

469
00:29:56,350 --> 00:30:01,350
take the real world as it looks and
then present information about it,

470
00:30:02,580 --> 00:30:03,920
uh, is a, uh,

471
00:30:04,000 --> 00:30:08,630
a powerful and not yet
well exploited idea. Uh,

472
00:30:09,250 --> 00:30:12,850
imagine being able to stand down,
you know, the top of the building,

473
00:30:12,851 --> 00:30:16,480
looking out over the field of view
and ask a question, what's that?

474
00:30:17,090 --> 00:30:21,400
And get back useful information. Or
if you're navigating in a, in a city,

475
00:30:21,401 --> 00:30:26,230
you've never been to, uh, the ability
to get guidance, uh, in real time.

476
00:30:26,660 --> 00:30:30,700
It's pretty attractive. Now I have
to admit to you though that, um,

477
00:30:31,480 --> 00:30:35,410
I've seen a lot of these, um, things
that you hang on your head for,

478
00:30:35,440 --> 00:30:39,040
for virtual reality that make
you look like Darth Vader. And,

479
00:30:39,220 --> 00:30:40,570
and I remember thinking,

480
00:30:41,020 --> 00:30:45,520
I wonder how video conferencing is going
to work if everybody is wearing this

481
00:30:45,521 --> 00:30:46,354
thing.

482
00:30:46,600 --> 00:30:50,110
Then what do you look like to the other
people who are part of the conference?

483
00:30:50,111 --> 00:30:51,950
And of course you don't want
to look like Darth Vader.

484
00:30:51,951 --> 00:30:56,470
So suddenly there's a whole new business
to be made where you're virtual avatar

485
00:30:56,920 --> 00:31:00,820
that is presented in lieu of you because
you're wearing this weird thing on your

486
00:31:00,821 --> 00:31:05,020
face. Um, I'm not sure
where that's going to go,

487
00:31:05,021 --> 00:31:09,590
but I can imagine me wanting to
have more hair, for example. Uh,

488
00:31:10,270 --> 00:31:13,150
so there could be a whole
new set of businesses. This,

489
00:31:13,151 --> 00:31:18,151
this stuff is reminiscent of what's also
happening with the Internet of things

490
00:31:19,480 --> 00:31:22,960
and automation in general. Everybody's
worried that all these jobs go away.

491
00:31:22,961 --> 00:31:27,640
The robots are coming. Uh, the robots are
coming. There's no question about that.

492
00:31:27,641 --> 00:31:32,350
But I see them as partners
and not as threats.

493
00:31:32,770 --> 00:31:37,770
It is true that some work that it is
classically done by people today will end

494
00:31:38,021 --> 00:31:41,200
up being done by machines and robots.

495
00:31:41,800 --> 00:31:46,150
Some of that work by the way, we'll
be done without physical involvement.

496
00:31:46,630 --> 00:31:50,830
Too many people misunderstand
robot as only thing which you know,

497
00:31:50,831 --> 00:31:54,220
can affect the real world by
physically interacting with it.

498
00:31:54,550 --> 00:31:59,550
But a program trading system in the
stock market is as much a robot as a,

499
00:31:59,831 --> 00:32:03,100
as your favorite, a Boston
dynamics, a big dog.

500
00:32:03,720 --> 00:32:08,260
It should be obvious that those programs
are taking input from the real world,

501
00:32:08,290 --> 00:32:09,550
the stock transactions,

502
00:32:10,090 --> 00:32:14,650
analyzing it and taking actions was
have a real world effect on your bank

503
00:32:14,651 --> 00:32:17,620
account, for example, or on the economy.

504
00:32:17,890 --> 00:32:21,130
That's as much a robot as anything else
and we should be thinking along those

505
00:32:21,131 --> 00:32:23,080
lines. So, um,

506
00:32:23,170 --> 00:32:28,170
I'm strongly persuaded that we
will see a robotic technology,

507
00:32:30,180 --> 00:32:33,610
uh,
becoming increasingly useful to us,

508
00:32:34,510 --> 00:32:39,100
including the kinds of things
that involve, um, for example,

509
00:32:39,170 --> 00:32:44,170
a smart search where more semantics are
injected into the search process then

510
00:32:47,211 --> 00:32:48,830
has been the case in the past.

511
00:32:48,831 --> 00:32:52,400
So it used to be that we would just look
for search terms and tell you here's

512
00:32:52,401 --> 00:32:54,230
all the pages,
have those terms in them.

513
00:32:54,560 --> 00:32:56,690
Now we use something
called the knowledge graph,

514
00:32:56,720 --> 00:33:01,400
which contains a great deal of semantic
information so that the terms that you

515
00:33:01,401 --> 00:33:06,401
use are run through the knowledge graph
in order to get a better semantic depth

516
00:33:07,970 --> 00:33:12,500
before we actually do the, uh, the
search in the index of the worldwide web,

517
00:33:12,970 --> 00:33:17,420
uh, attempting to get a better
semantic response for you. So those,

518
00:33:17,450 --> 00:33:20,930
those are all examples of tools that are,

519
00:33:20,931 --> 00:33:25,470
I am persuaded will become more and
more common place. We do have, uh,

520
00:33:25,490 --> 00:33:29,690
an interesting problem and that is how
do we take care of people whose jobs have

521
00:33:29,691 --> 00:33:34,660
been superannuated, uh, by
automatic techniques or program, uh,

522
00:33:34,700 --> 00:33:35,990
methods.
Uh,

523
00:33:36,160 --> 00:33:40,370
and the answer to that clearly is better
education or more education retraining.

524
00:33:40,371 --> 00:33:45,260
And things like that. Uh, not to sound
like this is too much of a nostrum.

525
00:33:45,530 --> 00:33:48,430
I would like to point out to you that,
uh,

526
00:33:48,680 --> 00:33:53,680
the historical trend for humans is to
live longer because of improved medical

527
00:33:53,751 --> 00:33:57,410
care, sanitation, diet
and everything else. Uh,

528
00:33:57,590 --> 00:34:02,330
that means that kids that are born today
may very well easily live to a hundred

529
00:34:02,330 --> 00:34:05,990
years old, which of course it puts them
into the 22nd century. My science fiction,

530
00:34:06,050 --> 00:34:09,080
uh, you know, bulb over here is
sending, wow, that's amazing.

531
00:34:09,081 --> 00:34:13,680
Imagine being alive in the 22nd century.
What's that going to be like? Um,

532
00:34:13,730 --> 00:34:18,200
but what that does is force you to think
a little bit about careers that might

533
00:34:18,201 --> 00:34:19,430
last 80 years.

534
00:34:20,330 --> 00:34:23,810
And you realize that over an 80
year period or a 70 year period,

535
00:34:23,811 --> 00:34:26,090
lots of technology changes will occur.
I mean,

536
00:34:26,091 --> 00:34:29,640
all we have to do is look back 11 years
and realized that we didn't have smart

537
00:34:29,641 --> 00:34:34,220
phones until 2007.
So over that period of time,

538
00:34:34,221 --> 00:34:37,190
watts is going to happen
and it's unlikely to,

539
00:34:37,191 --> 00:34:39,360
anyone's job is going to stay purse,
you know,

540
00:34:40,070 --> 00:34:45,070
persistent over that period of time will
be forced to have to learn new things.

541
00:34:45,920 --> 00:34:50,900
So maybe we should just start out on the
premise that we are going to be working

542
00:34:50,901 --> 00:34:54,080
in learning and working and learning
and working and learning for our entire

543
00:34:54,440 --> 00:34:59,440
careers and start out not by trying to
jam everything that you're possibly could

544
00:34:59,481 --> 00:35:03,390
need to know for a 50 year career in uh,
you know,

545
00:35:03,391 --> 00:35:04,520
a 20 year period.

546
00:35:04,850 --> 00:35:09,500
But instead make it normal
to keep learning new things,

547
00:35:09,680 --> 00:35:14,680
teaching kids how to want to
learn how to learn and how to,

548
00:35:15,230 --> 00:35:19,760
how to feel comfortable with the idea
that they will go to work, go to school,

549
00:35:19,761 --> 00:35:24,470
go to work, go to school is
a normal part of their lives.

550
00:35:25,100 --> 00:35:29,060
That's just that four year colleges and
jamming everything into four years may

551
00:35:29,061 --> 00:35:33,590
not be the right model. You've seen
college expenses going up dramatically.

552
00:35:34,070 --> 00:35:37,890
Maybe we need to rethink how we do
this. How are we distributing, learning,

553
00:35:37,920 --> 00:35:42,600
distributing, learning over a
lifetime. And that suggests to me that,

554
00:35:42,680 --> 00:35:43,710
uh,
our,

555
00:35:44,340 --> 00:35:48,210
our society will look pretty different
in a few years talking to as a result of

556
00:35:48,211 --> 00:35:49,044
that.

557
00:35:49,770 --> 00:35:54,300
It's a, it's a great segway into talking
about the people centered Internet,

558
00:35:54,330 --> 00:35:55,690
which I know is something that you've,

559
00:35:55,720 --> 00:35:59,490
you've co founded and started putting
a lot of, uh, of time into. Um,

560
00:35:59,520 --> 00:36:00,480
could you tell us about that?

561
00:36:01,220 --> 00:36:04,060
So, uh, one of my colleagues, um,

562
00:36:04,760 --> 00:36:08,810
they're not at Google but elsewhere
Malin phones who used to be at Oracle and

563
00:36:08,811 --> 00:36:13,430
it's one of the founders of customer
relationship management. Uh,

564
00:36:13,460 --> 00:36:17,540
and I got together and started this
small little thing called people centered

565
00:36:17,541 --> 00:36:22,250
Internet. And the focus of
attention frankly is on, um,

566
00:36:22,550 --> 00:36:27,160
making the internet useful for people.
And I confess to you that, uh, Oh yes,

567
00:36:27,170 --> 00:36:30,100
I don't know what it is that a
signal that I should stop or a,

568
00:36:31,730 --> 00:36:35,480
I think there's a hook ready to
go if we had to get off stage. Um,

569
00:36:35,930 --> 00:36:37,740
my job at Google,
uh,

570
00:36:37,880 --> 00:36:42,860
as the chief Internet evangelist is
often to deal with policy questions,

571
00:36:42,861 --> 00:36:46,340
some of which are, uh, how to
get more internet out there,

572
00:36:46,341 --> 00:36:50,060
how to create an environment
where investment is welcome, uh,

573
00:36:50,080 --> 00:36:54,020
how to get governments to encourage
competition and investment.

574
00:36:54,620 --> 00:36:59,420
But it malins point,
which I took very seriously,

575
00:36:59,421 --> 00:37:03,620
is that it's not enough just to get the
internet out there is the question is

576
00:37:03,770 --> 00:37:08,770
what can you do with it is materially
beneficial that improves people's lives in

577
00:37:09,021 --> 00:37:12,260
a way that you could
really point to, uh, in,

578
00:37:12,261 --> 00:37:15,680
in a quantitative way
and a qualitative way.

579
00:37:16,430 --> 00:37:21,430
So our focus of attention
is how to improve the use
of Internet for the benefit

580
00:37:23,510 --> 00:37:25,670
of the population that has access to it.

581
00:37:26,000 --> 00:37:30,170
Whether that's better knowledge for
healthcare, learning for a job change,

582
00:37:30,590 --> 00:37:35,510
a variety of other, uh, kinds of uses.

583
00:37:35,990 --> 00:37:40,100
And so our focus is to try to make sure
that as we are pushing hard to get more

584
00:37:40,101 --> 00:37:40,881
internet out there,

585
00:37:40,881 --> 00:37:44,720
which we need to do because only half
the world's population has got access to

586
00:37:44,721 --> 00:37:45,170
it.

587
00:37:45,170 --> 00:37:50,170
We're also thinking hard about a local
content content in local languages.

588
00:37:51,030 --> 00:37:55,020
Nobody would find it very
useful. Living in Quito, uh,

589
00:37:55,070 --> 00:37:58,700
looking for a plumber and
getting the answer. There's
a plumber in New York City.

590
00:37:58,720 --> 00:38:01,070
I mean, you need to get an
answer this locally useful.

591
00:38:01,430 --> 00:38:06,200
So we care a great deal about that.
To be honest. This same effort,

592
00:38:06,201 --> 00:38:10,340
this people centered Internet is edging
into another category which you may

593
00:38:10,341 --> 00:38:11,810
already have questions about.

594
00:38:12,350 --> 00:38:17,150
It has to do with the emergence
of a fake news of, uh,

595
00:38:17,210 --> 00:38:21,820
you know, botnets and echo chambers
and all these other things, uh,

596
00:38:21,950 --> 00:38:26,950
which are very troubling and which we
are going to have to deal with because we

597
00:38:27,111 --> 00:38:32,111
can't around a society to disintegrate
simply because of the arrival of some of

598
00:38:32,601 --> 00:38:37,350
these effects. You may have
questions that, so I won't
go any further on there. Uh,

599
00:38:37,600 --> 00:38:42,280
but I am prepared to talk at more
length on that topic if necessary.

600
00:38:42,410 --> 00:38:44,870
It's doing my job for me. Yeah. Um,

601
00:38:45,040 --> 00:38:48,090
well actually I'd like to hear more about
what you think are the current set of,

602
00:38:48,091 --> 00:38:50,330
of challenges and the
barriers to actually, uh,

603
00:38:50,760 --> 00:38:54,130
I'm more continuing to
grow the open Internet.

604
00:38:55,420 --> 00:38:58,680
So it's funny, some people ask
me, chief Internet evangelist,

605
00:38:58,800 --> 00:39:01,810
why do you need to evangelize the
Internet? Isn't it obvious? You know,

606
00:39:01,811 --> 00:39:06,140
that everybody should have access to
it. Uh, and of course the answer is, uh,

607
00:39:06,190 --> 00:39:07,600
even if it were obvious,

608
00:39:07,601 --> 00:39:12,030
it's not always true that you in every
place in the world where Internet isn't

609
00:39:12,570 --> 00:39:16,130
a, there is an appreciation
and an understanding of, um,

610
00:39:16,450 --> 00:39:19,660
the value of implementing and,
uh,

611
00:39:19,661 --> 00:39:23,140
and of course with the negative things
that are showing up in the news now

612
00:39:23,141 --> 00:39:28,090
there's even a pushback saying maybe this
isn't the right thing to do at all. Uh,

613
00:39:29,230 --> 00:39:34,230
this was an example of a kind of
emergent property that it's common for

614
00:39:36,521 --> 00:39:40,490
engineers to miss and they,
this is a apology I get,

615
00:39:40,491 --> 00:39:42,390
did I miss this?
Uh,

616
00:39:42,391 --> 00:39:46,660
so this is my way of trying to
escape too much culpability. Um,

617
00:39:47,320 --> 00:39:52,320
I thought it was very important to
push the barrier to access to this

618
00:39:52,601 --> 00:39:53,351
capability,

619
00:39:53,351 --> 00:39:58,351
this computer mediated communication
to nearly zero so that everybody could

620
00:39:59,110 --> 00:40:01,180
afford to get into the system,

621
00:40:01,181 --> 00:40:04,630
could afford to get access
to information and services,

622
00:40:04,631 --> 00:40:09,631
could share knowledge in the system to
try to just get those barriers down to

623
00:40:09,731 --> 00:40:11,260
zero.
Uh,

624
00:40:11,261 --> 00:40:15,340
what I didn't appreciate at
the time is that in so doing,

625
00:40:15,930 --> 00:40:16,763
uh,

626
00:40:16,840 --> 00:40:21,840
all of the bad elements of our society
benefited from this same reduction in

627
00:40:23,411 --> 00:40:24,244
barrier.

628
00:40:24,970 --> 00:40:28,810
And so before we had internet
and the worldwide web,

629
00:40:29,260 --> 00:40:31,570
your ability to reach a large audience,

630
00:40:31,571 --> 00:40:35,270
depending on your ownership of the
television station or radio station,

631
00:40:35,290 --> 00:40:39,070
a newspaper publishing empire
magazines or something, uh,

632
00:40:39,460 --> 00:40:42,310
access to mass media was
not available to everyone.

633
00:40:42,880 --> 00:40:47,830
Internet makes it possible for people to
make use of this enormous distribution

634
00:40:47,831 --> 00:40:51,760
engine, uh, virtually
anybody with a smartphone.

635
00:40:52,510 --> 00:40:54,550
And the side effect of that,
of course,

636
00:40:54,551 --> 00:40:58,180
is that there are people out there
who deliberately want to pollute the

637
00:40:58,181 --> 00:41:00,580
information environment
for their own purposes,

638
00:41:00,820 --> 00:41:05,820
who want to build botnets and use them
to pollute the system to a launch denial

639
00:41:07,151 --> 00:41:12,151
of service attacks to create
false reinforcement of,

640
00:41:12,400 --> 00:41:15,200
uh, of false information, uh,

641
00:41:15,340 --> 00:41:19,620
to reinforce or maybe
exacerbate and disturbed, um,

642
00:41:20,650 --> 00:41:23,280
isolated groups of people
who, you know, who,

643
00:41:23,290 --> 00:41:28,290
who think alike about certain things
and are resistant to any other ideas.

644
00:41:28,660 --> 00:41:33,400
These echo chamber effects simply
amplify that and reinforce,

645
00:41:33,890 --> 00:41:37,400
this is called confirmation
bias, uh, in, in some circles.

646
00:41:37,910 --> 00:41:42,290
So we now have a problem because
everybody, including these bad elements,

647
00:41:42,291 --> 00:41:43,880
have access to the system,

648
00:41:43,910 --> 00:41:48,910
which they it with which they can amplify
their information in a very funny way.

649
00:41:50,511 --> 00:41:54,650
This creates a big asymmetry.
Uh, what used to be,

650
00:41:54,930 --> 00:41:55,763
uh,

651
00:41:55,790 --> 00:42:00,790
available only to a nation state is
suddenly available to a small groups of

652
00:42:01,731 --> 00:42:06,650
people, even individuals. So the question
is, what do we do about that? Uh,

653
00:42:07,010 --> 00:42:12,010
in other infrastructure where we
have discovered that there is abuse,

654
00:42:12,640 --> 00:42:16,580
uh, we typically ended up saying, well,
the following things are unacceptable.

655
00:42:16,581 --> 00:42:19,670
In our society. Now,
sometimes if we're lucky,

656
00:42:19,671 --> 00:42:24,671
we can actually do take technical
measures to inhibit some of the bad side

657
00:42:25,011 --> 00:42:28,550
effects. So for example,
uh, seatbelts in cars,

658
00:42:29,000 --> 00:42:33,050
we try to big persuasive campaign showing
teenagers who were about to get their

659
00:42:33,051 --> 00:42:36,710
licenses. This is what you look like if
you drive badly, get drunk and you know,

660
00:42:36,711 --> 00:42:39,080
kill yourself or your friends.
Uh,

661
00:42:39,081 --> 00:42:42,860
and so this is why it's important
to learn how to drive safely,

662
00:42:42,861 --> 00:42:46,130
how not to drink and drive and so on.
As much as,

663
00:42:46,131 --> 00:42:51,050
as we would teach that we also put
laws in place that said, by the way,

664
00:42:51,051 --> 00:42:54,470
if we catch you driving without your
seat belt, there will be consequences.

665
00:42:54,710 --> 00:42:58,790
So we have these technical means.
We have these post-talk posting,

666
00:42:58,850 --> 00:43:02,900
post hoc enforcement, uh,
in, in the Internet case,

667
00:43:02,930 --> 00:43:06,620
we're starting to see more
of the post hoc stuff,

668
00:43:06,650 --> 00:43:09,530
which is we track people
down who've done a bad thing.

669
00:43:10,010 --> 00:43:15,010
It's hard to figure out how to do this
in an international setting because we're

670
00:43:15,021 --> 00:43:19,760
crossing boundaries that the
legal regimes don't cross.

671
00:43:19,761 --> 00:43:23,300
And so this Internet, which knows nothing
about international boundaries at all,

672
00:43:23,710 --> 00:43:27,230
um, creates hazards that we
didn't normally experience.

673
00:43:27,230 --> 00:43:30,560
So somebody in one country can
attack somebody in another country.

674
00:43:30,980 --> 00:43:34,070
And unless there are agreements between
those two countries and may be very

675
00:43:34,071 --> 00:43:34,904
difficult,

676
00:43:34,910 --> 00:43:39,910
even if we know who the perpetrator is
to actually go after them and exercise

677
00:43:39,981 --> 00:43:41,000
those consequences.

678
00:43:41,450 --> 00:43:46,400
So those are two of the mechanisms that
you can see evolving. You can see, uh,

679
00:43:46,730 --> 00:43:48,800
an interest in treaty arrangements.

680
00:43:49,040 --> 00:43:52,500
There is one called the mutual
legal assistance treaty or MLS,

681
00:43:52,820 --> 00:43:55,990
which turns out to be
incredibly slow and clumsy. Uh,

682
00:43:56,090 --> 00:43:58,250
it may take weeks to months in order to

683
00:43:59,750 --> 00:44:04,520
get access to information that you
need to track down a perpetrator it,

684
00:44:04,521 --> 00:44:07,250
whereas these things happen in
the Internet in mental seconds.

685
00:44:07,520 --> 00:44:10,740
So there's a lot of attention
being paid now to, uh,

686
00:44:10,820 --> 00:44:15,650
how to improve our ability to do
cross border, uh, law enforcement.

687
00:44:16,130 --> 00:44:21,130
There is a third thing that you can do
and that's a moral suasion that don't do

688
00:44:21,711 --> 00:44:23,480
that. It's just bad. It's wrong.

689
00:44:23,990 --> 00:44:26,750
And what's interesting of
course is that sounds very weak,

690
00:44:27,440 --> 00:44:31,560
but I would draw your attention to
one of the important forces of nature.

691
00:44:31,561 --> 00:44:35,370
Your gravity.
It's the weakest force in the universe.

692
00:44:35,970 --> 00:44:39,930
And yet when you have large
mass gravity is pretty powerful.

693
00:44:40,000 --> 00:44:43,050
It's what keeps us from falling
off the planet, for example.

694
00:44:43,440 --> 00:44:48,000
So you can imagine the a social analogy
where there is a common and broad

695
00:44:48,001 --> 00:44:52,600
agreement on the following, things
not being acceptable socially. Uh,

696
00:44:52,620 --> 00:44:57,450
we may actually get a certain amount
of social pressure to inhibit those bad

697
00:44:57,451 --> 00:44:58,284
behaviors.

698
00:44:58,320 --> 00:45:02,760
But like every other infrastructure we've
ever designed and built a internet can

699
00:45:02,761 --> 00:45:06,450
be abused. It's like people would
get drunk and drive their cars.

700
00:45:06,780 --> 00:45:10,230
We can't stop them,
but we can tell them if we catch you,

701
00:45:10,260 --> 00:45:11,640
there will be consequences.

702
00:45:12,030 --> 00:45:17,030
So that's the sort of thing which I
think we are now faced with is how to,

703
00:45:17,520 --> 00:45:22,520
how to use this tool to its best advantage
and how to respond when people abused

704
00:45:24,461 --> 00:45:27,000
the tool in a very funny way.

705
00:45:27,001 --> 00:45:32,001
This reinforces my enjoyment
of Shakespeare because,

706
00:45:32,070 --> 00:45:32,610
you know,

707
00:45:32,610 --> 00:45:37,610
Shakespeare wrote his plays 400 years
ago and yet they're still popular today

708
00:45:37,771 --> 00:45:39,480
because there's still relevant.

709
00:45:39,870 --> 00:45:44,870
All the bad things they are about human
beings are reflected in those plays and

710
00:45:45,661 --> 00:45:49,290
there's still relevant to the
situation we find ourselves in today.

711
00:45:50,750 --> 00:45:54,590
So we actually a source some questions
from the reddit community and some of

712
00:45:54,591 --> 00:45:58,220
them are actually really pertinent
to this topic. Um, and uh,

713
00:45:58,221 --> 00:46:02,960
one actually that comes up here is a
doctor Huna on our technology asks.

714
00:46:03,550 --> 00:46:06,380
Uh, okay, so net neutrality, uh,

715
00:46:06,381 --> 00:46:10,010
what needs to be done to preserve our
free flow of information but also to

716
00:46:10,011 --> 00:46:12,190
enable businesses to flourish with it.
Okay.

717
00:46:12,450 --> 00:46:16,800
So this is a, this is question
number 105 being it comes up a lot.

718
00:46:17,370 --> 00:46:20,910
Number one on one is did you have any
idea that this was going to get this big

719
00:46:21,720 --> 00:46:23,480
unequal? Yeah. So, um,

720
00:46:23,880 --> 00:46:27,540
I won't pull the graduate student trick
on you by answering question one on one

721
00:46:27,541 --> 00:46:30,900
instead of one oh five. And most
graduate students when asked a question,

722
00:46:30,901 --> 00:46:34,440
we'll try to distort the question around
to the point where they can answer it.

723
00:46:35,240 --> 00:46:36,073
Um,

724
00:46:36,160 --> 00:46:39,240
I hope I haven't insulted in any graduate
students here was once a Grad student.

725
00:46:39,840 --> 00:46:44,370
So the answer on the net
neutrality side, um, I think,

726
00:46:44,371 --> 00:46:48,450
I hope a lot of you recognize
how we ended up here. Uh,

727
00:46:48,540 --> 00:46:52,890
I'll try to make this not too long.
There is a fairly long chain here.

728
00:46:53,420 --> 00:46:57,270
Um, in the 1990s, mid 1990s,

729
00:46:57,271 --> 00:47:02,271
there were 8,000 Internet
service providers in the
u s because Internet was a

730
00:47:02,761 --> 00:47:04,050
dial up service.

731
00:47:04,320 --> 00:47:09,320
And so you just had to rent a bunch of
modem banks in order to be an Internet

732
00:47:09,601 --> 00:47:13,980
service provider. Uh, and if you as
the consumer didn't like the service,

733
00:47:13,981 --> 00:47:16,770
you could go to somebody else
by dialing a different number.

734
00:47:17,340 --> 00:47:20,560
And so the switching back and
forth between this, the, uh,

735
00:47:20,700 --> 00:47:25,080
service providers was quiet very easy and
therefore this is a highly competitive

736
00:47:25,081 --> 00:47:28,950
thing. When broadband technology
came along and cable modems,

737
00:47:29,350 --> 00:47:32,830
fiber modems and a DSL,
for example,

738
00:47:33,220 --> 00:47:37,000
the number of providers
you telescope down to,

739
00:47:37,030 --> 00:47:41,110
very few for any individual,
there was a choice of zero,

740
00:47:41,111 --> 00:47:44,650
one or two really a telco or a cable co,
uh,

741
00:47:44,680 --> 00:47:46,890
or if you were in the
rural parts of the country,

742
00:47:46,920 --> 00:47:49,450
nobody was offering new
broadband service at all.

743
00:47:49,900 --> 00:47:52,120
So we didn't have a
highly competitive market.

744
00:47:53,260 --> 00:47:58,250
And as these companies began to
verticalize as they began to, um,

745
00:47:59,050 --> 00:48:04,000
not only offer their original things like
telephone calls and in the case cable

746
00:48:04,001 --> 00:48:08,860
companies, uh, video, uh, as they
started to also offer Internet service,

747
00:48:08,861 --> 00:48:12,820
broadband, Internet service,
uh, you start to run into, uh,

748
00:48:12,870 --> 00:48:14,230
April cancel hazard.

749
00:48:14,920 --> 00:48:19,920
Let's take a cable company that was
offering video services plus high speed

750
00:48:20,531 --> 00:48:21,364
Internet,

751
00:48:21,580 --> 00:48:25,720
noticing that his customer is using the
high speed Internet service to look at

752
00:48:25,721 --> 00:48:28,700
somebody else's videos. And so, you know,

753
00:48:28,720 --> 00:48:33,720
the temptation is a potential temptation
there to go mess up the Internet

754
00:48:35,171 --> 00:48:39,190
service enough so that the competitor's
videos won't work and force your

755
00:48:39,191 --> 00:48:41,410
customer to only
subscribe to your service.

756
00:48:41,890 --> 00:48:46,360
I'm not suggesting that anybody would
actually do that, although there were,

757
00:48:47,930 --> 00:48:51,890
there, there were some
cases along these lines, uh,

758
00:48:52,420 --> 00:48:53,860
or blocking for that matter.

759
00:48:53,861 --> 00:48:57,730
Like voiceover Ip was blocked by some
telephone companies even though they were

760
00:48:57,731 --> 00:49:02,260
also offering Internet
service. So at some point, um,

761
00:49:02,440 --> 00:49:07,440
the cable companies and the telcos
complained to the FCC that they were each

762
00:49:08,861 --> 00:49:12,760
offering internet service, but they
were regulated by different regimes.

763
00:49:12,761 --> 00:49:17,761
Cause in the telecom act there's a cable
telecom regulation in title six and

764
00:49:18,131 --> 00:49:19,500
there's a,
uh,

765
00:49:19,580 --> 00:49:24,250
a telecommunications regulation
for roughly to left knee
speaking into entitled

766
00:49:24,251 --> 00:49:24,640
to.

767
00:49:24,640 --> 00:49:29,440
So they were whining to the FCC that they
had different regulatory regimes even

768
00:49:29,441 --> 00:49:34,390
though they were both offering Internet
service. And so the FCC decided,

769
00:49:34,391 --> 00:49:37,000
well,
let's fix that by not regulating internet.

770
00:49:37,030 --> 00:49:39,550
So they moved into call
what's called title one,

771
00:49:39,880 --> 00:49:44,710
which is an unregulated information
service that did not pay any attention to

772
00:49:44,711 --> 00:49:47,500
the fact that the Internet is
in fact the layered structure.

773
00:49:47,501 --> 00:49:52,210
And there is a telecommunications
component to it. But
then at the same time,

774
00:49:52,240 --> 00:49:55,660
this same FCC said, well, but
let's institute some rules,

775
00:49:56,020 --> 00:49:58,510
we'll call them the net neutrality rules.
Don't block,

776
00:49:58,511 --> 00:50:00,430
don't interfere with
other people's traffic,

777
00:50:00,431 --> 00:50:05,140
don't stop your customer from going to
any legitimate place on the net. Uh,

778
00:50:05,350 --> 00:50:07,630
so the subsequent FCC,

779
00:50:07,900 --> 00:50:12,900
when it encountered abuses trying to
enforce the net neutrality rules and said,

780
00:50:15,190 --> 00:50:19,060
you can't do that, either we will
find you or a cease and desist.

781
00:50:19,420 --> 00:50:23,770
And the, uh, one of the
abusers basically said,

782
00:50:23,771 --> 00:50:26,490
you don't have any grounds for finding or,

783
00:50:26,491 --> 00:50:30,260
or otherwise interfering because you
said this is an unregulated service.

784
00:50:30,261 --> 00:50:32,360
You have no regulatory authority.

785
00:50:33,020 --> 00:50:36,380
This went all the way up to the Supreme
Court and the Supreme Court and said,

786
00:50:36,410 --> 00:50:40,000
Yup. Uh, the, uh, the, the, uh,

787
00:50:40,070 --> 00:50:45,050
provider information in Internet service
provider was correct because the FCC

788
00:50:45,051 --> 00:50:49,340
had essentially said, this is not
regulated. You have no authority.

789
00:50:49,760 --> 00:50:53,540
So the subsequent FCC said,
well, that sucks. So they,

790
00:50:54,800 --> 00:50:58,250
well, I'm sure they said it
in a little more delicate way,

791
00:50:58,460 --> 00:51:03,460
but then they voted to move this back
to title to say move Internet service to

792
00:51:03,561 --> 00:51:07,700
title two and say it
is a regulated service,

793
00:51:07,910 --> 00:51:12,910
but we will forbear from regulating or
from applying all the regulations of

794
00:51:13,191 --> 00:51:15,890
title two,
which include all the price controls.

795
00:51:15,891 --> 00:51:20,240
And all kinds of other things in
the historical telephony world.

796
00:51:21,260 --> 00:51:25,400
The more recent FCC decided
they didn't like that very much.

797
00:51:25,401 --> 00:51:27,160
And so they voted on,
um,

798
00:51:27,560 --> 00:51:32,560
party learnings to rescind the decision
that the Internet is a regulated title

799
00:51:33,291 --> 00:51:37,220
to service. So it's now back to
being an unregulated service.

800
00:51:37,580 --> 00:51:42,580
The side effect of that is that we are
no longer protected by any ability of the

801
00:51:44,091 --> 00:51:46,140
FCC to,
um,

802
00:51:46,940 --> 00:51:50,480
respond to various kinds of
potential harms to consumers.

803
00:51:51,080 --> 00:51:53,840
Now to be accurate about it,

804
00:51:53,841 --> 00:51:57,920
the theory is that the federal
trade commission can now engage,

805
00:51:58,460 --> 00:52:02,900
but the way the federal trade
commission and gauges is a case by case

806
00:52:03,830 --> 00:52:08,810
adjudication of, uh, what it
is thought to be an abuse of,

807
00:52:08,870 --> 00:52:11,030
uh,
or consumer harm.

808
00:52:11,600 --> 00:52:16,600
And I'm not persuaded this gives
much guidance to the Internet service

809
00:52:16,791 --> 00:52:17,361
providers.

810
00:52:17,361 --> 00:52:22,160
So I confessed to you that I would
prefer to see an FCC component to it.

811
00:52:22,850 --> 00:52:25,430
Um,
I was split this into two parts.

812
00:52:25,430 --> 00:52:29,720
One of them is making sure that the
basic infrastructure and access to the

813
00:52:29,721 --> 00:52:34,721
Internet is neutral in the sense that it
doesn't interfere with consumer choice.

814
00:52:34,761 --> 00:52:39,380
It doesn't interfere with the quality
of the service, doesn't permit, uh,

815
00:52:39,410 --> 00:52:43,000
kinds of, um, uh, special, uh,

816
00:52:43,040 --> 00:52:47,330
favors to somebody who pays you
to do a better job for them. Um,

817
00:52:48,860 --> 00:52:49,970
at the same time,

818
00:52:49,971 --> 00:52:54,770
if there are consumer abuses that have
to do with content or fraud or other

819
00:52:54,771 --> 00:52:56,210
kinds of consumer harm,

820
00:52:56,211 --> 00:52:59,940
that's perfectly reasonable to
show up as an FTC proceeding.

821
00:52:59,941 --> 00:53:03,860
So I would split this into two
parts with regard to the FCC part.

822
00:53:03,861 --> 00:53:05,480
I would not leave it entitled to,

823
00:53:06,290 --> 00:53:09,230
I think a separate title
is appropriate for, uh,

824
00:53:09,231 --> 00:53:14,150
for Internet regulation of very
lightweight, uh, regulation.

825
00:53:14,360 --> 00:53:17,240
The problem is that in order
to achieve such an objective,

826
00:53:17,270 --> 00:53:19,700
we would need the congress to pass a law.

827
00:53:20,660 --> 00:53:24,320
And the moment it tends to pass gas,
but not much law.

828
00:53:25,050 --> 00:53:29,400
So until we have a congress,
it's capable of actually doing something,

829
00:53:29,730 --> 00:53:33,090
the likelihood that we
will have a suitable, uh,

830
00:53:33,150 --> 00:53:37,530
regulatory framework for Internet
is remote. So that's where we stand

831
00:53:39,480 --> 00:53:43,560
on the later side. Yeah. You, Dante asks,

832
00:53:43,950 --> 00:53:47,310
what is the best thing you've seen
come from the Internet? Alternatively,

833
00:53:47,340 --> 00:53:51,570
what's the worst? I will add the addition.
They don't have to be different. Okay.

834
00:53:52,430 --> 00:53:55,800
Oh, that's interesting.
Uh, well in, in some sense,

835
00:53:55,801 --> 00:53:59,760
just an honest response to your,
your last observation.

836
00:54:00,180 --> 00:54:03,510
The thing which is wonderful about
the internet is its openness.

837
00:54:04,020 --> 00:54:07,620
The thing which is terrible about
the internet is its openness. Uh,

838
00:54:07,790 --> 00:54:11,250
there another formulation of that is the
wonderful thing about the internet is

839
00:54:11,251 --> 00:54:12,360
everything is connected.

840
00:54:12,810 --> 00:54:16,200
The worst thing about the internet
is everything is connected. Uh,

841
00:54:16,201 --> 00:54:19,950
this is particularly visible as you start
thinking about the Internet of things.

842
00:54:19,950 --> 00:54:22,720
All of these devices that
we're surrounded with. Uh,

843
00:54:22,890 --> 00:54:27,890
I used to joke that the headline I was
fearful of is 100,000 refrigerators

844
00:54:28,921 --> 00:54:30,180
attack.
Bank of America,

845
00:54:31,170 --> 00:54:35,370
I no longer tell that
because as you all know,

846
00:54:35,670 --> 00:54:39,750
500,000 webcams attack
the dining corporation.

847
00:54:39,810 --> 00:54:42,960
So it's not funny at all.
Um,

848
00:54:43,860 --> 00:54:48,540
so we talked a little bit about
the side effect of the freedom,

849
00:54:49,200 --> 00:54:50,490
uh, that, uh,

850
00:54:50,640 --> 00:54:55,340
has been given to all of us to both
inject information into the net,

851
00:54:55,341 --> 00:54:57,000
into finding information back.

852
00:54:57,450 --> 00:55:01,720
And it is in fact a Yin
and Yang kind of thing, uh,

853
00:55:01,721 --> 00:55:04,020
that we now have to
learn how to cope with.

854
00:55:04,840 --> 00:55:09,840
I still think on balance that the reduced
barriers to the sharing of knowledge

855
00:55:12,210 --> 00:55:16,020
is a gift to our society.

856
00:55:16,560 --> 00:55:21,560
And that in a way we have to learn how
to use that gift more effectively and to

857
00:55:22,771 --> 00:55:24,570
deal with the potential side effects.

858
00:55:24,600 --> 00:55:28,710
I would not want to go back to a
world that has no internet in it.

859
00:55:28,860 --> 00:55:32,310
And I hope that's true for
everybody else in this audience.

860
00:55:32,820 --> 00:55:37,560
So those are the immediate
thoughts that come to mind. Um,

861
00:55:37,590 --> 00:55:41,730
the other thing which I love
about the Internet, he is,

862
00:55:41,820 --> 00:55:46,820
it's architecture has invited new ideas
should be injected into the system.

863
00:55:50,970 --> 00:55:55,970
If you didn't like the set of services
that were available and you thought new

864
00:55:56,401 --> 00:55:57,690
protocols where you needed,

865
00:55:58,320 --> 00:56:02,910
you were always free and you are still
free to invent new protocols and they can

866
00:56:02,911 --> 00:56:07,860
be lodged into the architecture
wherever they're needed or desired. Uh,

867
00:56:08,260 --> 00:56:12,260
it even at the Ip layer, which
is really hard to change. Uh,

868
00:56:12,360 --> 00:56:15,750
there has been the significant injection
of change and that's what the Ip

869
00:56:15,751 --> 00:56:17,530
version six, uh, it's,

870
00:56:17,640 --> 00:56:22,640
we're still pushing on that wet noodle
is that it's taken this since 1996 to get

871
00:56:23,020 --> 00:56:25,780
to where we are now,
which is about 30% penetration.

872
00:56:26,290 --> 00:56:29,350
I am fairly convinced that
between mobile phones,

873
00:56:29,351 --> 00:56:32,920
smart phones and Internet of things
that everyone will recognize.

874
00:56:32,921 --> 00:56:37,810
It's important to move to IPV six so that
we'll have enough address space to do

875
00:56:37,811 --> 00:56:39,820
all the things that we hope to do.

876
00:56:40,390 --> 00:56:45,370
I have to admit to you that there was a
time once when I said, uh, that IPV six,

877
00:56:45,371 --> 00:56:49,900
which has 3.4 times 10 to the 38th
addresses, uh, should be enough.

878
00:56:49,901 --> 00:56:53,120
So wherever you electron in the
universe can have its own web page.

879
00:56:54,130 --> 00:56:59,130
And I got an email from
somebody to caltech shortly
after that same dear doctor

880
00:57:00,041 --> 00:57:03,050
serve you jerk.
They're there,

881
00:57:03,150 --> 00:57:08,150
they're 10 to the 88 electrons in the
universe and you're off by 50 orders of

882
00:57:08,621 --> 00:57:12,160
magnitude.
So I don't tell that story anymore.

883
00:57:13,480 --> 00:57:14,313
Well.
Thank you all

884
00:57:14,580 --> 00:57:18,690
[inaudible].

