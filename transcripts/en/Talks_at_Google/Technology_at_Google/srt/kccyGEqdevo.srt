1
00:00:08,530 --> 00:00:13,210
Well, it is great to be here and excited
to do this and thank you Armand for,

2
00:00:13,450 --> 00:00:14,900
for putting that talk together.
Um,

3
00:00:14,901 --> 00:00:16,900
I think we're going to have fun
together for the next hour. That's,

4
00:00:16,901 --> 00:00:21,220
that's the goal is to learn, but also to
sort of have some fun together. So, um,

5
00:00:21,280 --> 00:00:25,900
over the course of the today's our
conversation, we'll attend to do this.

6
00:00:25,901 --> 00:00:28,030
We'll try to define urban technology,

7
00:00:28,420 --> 00:00:31,750
explain really what we can achieve from
it and the really sort through some of

8
00:00:31,751 --> 00:00:33,040
the challenges.
So in my mind,

9
00:00:33,280 --> 00:00:36,280
I think we're thinking about this question
of how will it influence quality of

10
00:00:36,281 --> 00:00:40,780
life? Why do we care, how do we measure
success and then how do we implement it?

11
00:00:41,240 --> 00:00:43,930
Um, so most importantly,
our esteemed panelists, uh,

12
00:00:43,931 --> 00:00:45,280
which we'll introduce here in a second.

13
00:00:45,281 --> 00:00:48,550
We'll introduce how technology is
really sort of shaping their fields.

14
00:00:48,551 --> 00:00:50,820
I think we've got an interesting
group of panelists, uh,

15
00:00:50,960 --> 00:00:53,650
both representing sort of
community and development and arts,

16
00:00:53,920 --> 00:00:57,090
a real estate development and obviously
technologist. So let me do this.

17
00:00:57,110 --> 00:00:59,790
Let's introduce and welcome our panelists.
Um,

18
00:00:59,860 --> 00:01:03,900
you have Google's very own Greg
Neville manning. Welcome. Uh,

19
00:01:06,770 --> 00:01:07,110
Greg

20
00:01:07,110 --> 00:01:09,330
is the CTO of sidewalk labs.
As you,

21
00:01:09,390 --> 00:01:11,730
many of you probably know
sidewalk labs is an alphabet,

22
00:01:11,731 --> 00:01:15,470
so bitaray applies people
centric to urban design. Um,

23
00:01:15,471 --> 00:01:18,170
and really frankly is one of the,
the talks of the,

24
00:01:18,330 --> 00:01:21,630
a really sort of one of those things
that people like myself, urban,

25
00:01:21,660 --> 00:01:25,380
urban real estate developers and urbanists
or really sort of thinking about, um,

26
00:01:25,381 --> 00:01:25,921
in terms of,

27
00:01:25,921 --> 00:01:29,880
in terms of technology and how it will
have an impact really on our field and

28
00:01:29,881 --> 00:01:32,640
what that means for us going forward.
Yeah,

29
00:01:32,641 --> 00:01:35,910
I would jump in for those of you who
are fairly new, if you don't know,

30
00:01:35,911 --> 00:01:40,500
Craig actually started the
Google New York City campus. Ooh,

31
00:01:41,030 --> 00:01:45,900
that's why you're all here.
We also have Jonathan Rose.

32
00:01:46,140 --> 00:01:48,820
Jonathan is the CEO of the rose companies.
Um,

33
00:01:48,840 --> 00:01:51,960
which is a development company which
finds new ways to improve communities.

34
00:01:52,200 --> 00:01:56,940
You know, both environmentally, socially
and economically. Um, rose companies have,

35
00:01:56,970 --> 00:02:00,960
has developed a more than a hundred
projects, um, across the United States.

36
00:02:00,961 --> 00:02:05,400
It is the 10th larger owner of
affordable housing across the country.

37
00:02:05,760 --> 00:02:08,400
Um, in addition, Jonathan, um, is a,

38
00:02:08,401 --> 00:02:10,890
is a recent author wrote
a really terrific book,

39
00:02:10,891 --> 00:02:13,410
which I would recommend for
all of you to take a look at.

40
00:02:13,411 --> 00:02:16,990
It's called the well tempered city. It's
a, it's a wonderful, wonderful book. Um,

41
00:02:17,010 --> 00:02:19,740
so please take a look.
So join me in welcoming Jonathan as well.

42
00:02:24,000 --> 00:02:25,290
We also have Elizabeth Goldstein,

43
00:02:25,291 --> 00:02:29,430
who's the president of the municipal
art society, uh, here in New York. Uh,

44
00:02:29,520 --> 00:02:33,840
the arts society has helped
New York advocate for
thoughtful and inclusive urban

45
00:02:33,841 --> 00:02:37,830
design, uh, for almost 125
years or over 125 years.

46
00:02:38,130 --> 00:02:41,280
And I will tell you that as we talk
about the ideas of displacement and

47
00:02:41,281 --> 00:02:44,940
gentrification, a lot of the challenges
that cities like New York is facing,

48
00:02:45,300 --> 00:02:47,990
the role of your team, your
organization, and what, uh,

49
00:02:48,210 --> 00:02:51,840
the municipal arts society
does is critically important.

50
00:02:52,090 --> 00:02:54,890
On prior to becoming the
president of that organization,

51
00:02:54,910 --> 00:02:58,470
she was also the president of the
California State Parks Foundation and most

52
00:02:58,471 --> 00:03:01,450
importantly has worked inside
government for really long time.

53
00:03:01,451 --> 00:03:06,400
So as we talk about this
idea of implementing
technology into government and

54
00:03:06,401 --> 00:03:07,930
getting government to sort of adopt this,

55
00:03:08,080 --> 00:03:10,570
you'll have some great
insights for us as well.

56
00:03:10,571 --> 00:03:14,590
So please join me in and also welcoming
Elizabeth to the conversation.

57
00:03:18,500 --> 00:03:19,333
Yeah.

58
00:03:19,650 --> 00:03:24,450
So you heard everything Steve's Steven
said and he's going to run the show.

59
00:03:24,451 --> 00:03:26,010
But so many of you reached out saying,

60
00:03:26,011 --> 00:03:28,860
you want to ask Craig and everybody
questions. I will have a dory going.

61
00:03:28,980 --> 00:03:32,970
If you've got to go ask the panel, I'll
try to squeeze in a couple, no promises,

62
00:03:32,971 --> 00:03:35,910
but uh, that, that's what I'll be doing
over here. So if you want to take it.

63
00:03:36,170 --> 00:03:36,770
Sure.

64
00:03:36,770 --> 00:03:40,430
So I think what's it start with an
opening panel cup question for all of the

65
00:03:40,431 --> 00:03:44,330
panelists. And that is this, as
we think about urban technology,

66
00:03:44,540 --> 00:03:49,540
how are you seeing technology factor in
to the longterm sort of vision and work

67
00:03:50,361 --> 00:03:53,870
of your organizations? And maybe just
provide a really specific example for us.

68
00:03:53,960 --> 00:03:54,920
Elizabeth,
we'll start with you.

69
00:03:55,330 --> 00:03:58,380
Sure. I'd be delighted to do
that. I mean, I think, uh,

70
00:03:58,420 --> 00:04:03,420
technology both has an extraordinary
ability to change and make our lives in

71
00:04:03,461 --> 00:04:05,050
cities much better.

72
00:04:05,051 --> 00:04:09,970
But it also poses some very significant
public policy challenges. Um,

73
00:04:09,971 --> 00:04:14,100
if you just think about the sharing
technology and the controversy that's

74
00:04:14,120 --> 00:04:17,350
existed around Airbnb, for instance. Um,

75
00:04:17,370 --> 00:04:19,360
and even some of the carshare programs,

76
00:04:19,361 --> 00:04:24,361
to what extent the city should yield a
spaces that normal people park in two

77
00:04:25,480 --> 00:04:27,490
shared car services,
for instance,

78
00:04:27,491 --> 00:04:32,410
is a question that wouldn't have
been posed a number of decades ago.

79
00:04:32,411 --> 00:04:36,340
It just would never have come up right?
Cause the technology drove the ability,

80
00:04:36,341 --> 00:04:40,220
forgive the pun, drove
the ability to, to um,

81
00:04:40,510 --> 00:04:44,170
engage in that way. Uh, and
the sharing economy, um,

82
00:04:44,320 --> 00:04:48,700
is obviously posting lots of challenges
from a public policy perspective,

83
00:04:48,701 --> 00:04:51,160
both in a really strong and positive way,

84
00:04:51,161 --> 00:04:53,770
but also in some ways that
are really challenging.

85
00:04:54,310 --> 00:04:56,980
So, Jonathan, what about the work
that you do with your company?

86
00:04:56,981 --> 00:05:00,700
How is technology impacting what you
all are doing out the communities across

87
00:05:00,701 --> 00:05:01,830
the u s got it.
Okay.

88
00:05:01,900 --> 00:05:02,970
So, first of all, we're,

89
00:05:03,050 --> 00:05:07,480
we have a vast technological rethink
project going on now where we're committed

90
00:05:07,481 --> 00:05:12,370
years and millions of dollars to thinking
about how we upgrade our systems and

91
00:05:12,371 --> 00:05:15,250
data. And so I want to start with an
analogy and then I'll talk about how we're

92
00:05:15,251 --> 00:05:17,440
applying. Okay. So the amazing, to me,

93
00:05:17,441 --> 00:05:22,370
the model for everything is
nature and nature is, has a, uh,

94
00:05:22,371 --> 00:05:25,170
you know, uses DNA is this
basic data system. But with the,

95
00:05:25,250 --> 00:05:27,940
with nature actually does,
has an incredible ability to heal.

96
00:05:28,150 --> 00:05:31,100
So imagine if there was a forest fire,
um,

97
00:05:31,240 --> 00:05:34,840
nature knows exactly the small plans
to the medium sized planets and the big

98
00:05:34,841 --> 00:05:38,110
plants in it. It knows how to
grow back a whole ecosystem.

99
00:05:38,380 --> 00:05:42,010
And what's phases to do that
and the way we build cities,

100
00:05:42,011 --> 00:05:45,580
we don't know how to heal.
So the question is, um,

101
00:05:45,730 --> 00:05:48,900
and since we're tiered primarily working
in low income parts of cities and with

102
00:05:48,901 --> 00:05:49,930
low income residents,

103
00:05:50,290 --> 00:05:55,290
our question is how can we use data to
turn our static dumb ways that we run

104
00:05:56,171 --> 00:05:58,100
cities and buildings and people and

105
00:05:58,100 --> 00:06:02,000
systems now to make them dynamic
and responsive and reactive.

106
00:06:02,270 --> 00:06:06,050
And ultimately co-evolving.
Great. What about you Craig?

107
00:06:06,300 --> 00:06:08,120
The work that you all are
doing with sidewalks? A lot.

108
00:06:08,210 --> 00:06:10,750
So there's a tiny bit of background,
sidewalk labs,

109
00:06:10,770 --> 00:06:15,170
a form with express idea
of taking advantage of, of
technology in the cities and,

110
00:06:15,390 --> 00:06:19,820
and figuring out how we might take a big
leap in terms of technology that cities

111
00:06:20,090 --> 00:06:22,610
aren't maybe taking it completed on a job.

112
00:06:22,820 --> 00:06:26,570
So one example of a technology that we
think this is slightly future looking,

113
00:06:26,690 --> 00:06:30,050
we'll have a big impact and will come as
no surprise to you as his self driving

114
00:06:30,051 --> 00:06:34,100
vehicles. Um, not just from the way
they will help people get around,

115
00:06:34,280 --> 00:06:38,330
but actually even more so as their
impact on how urban planning gets done.

116
00:06:38,480 --> 00:06:42,590
So just if you think about self driving
cars reducing or probably eliminating

117
00:06:42,591 --> 00:06:43,550
the need for parking,
right?

118
00:06:43,550 --> 00:06:46,370
Cause they'll drop people off and pick
them up and if they need to recharge,

119
00:06:46,371 --> 00:06:48,960
they can go up to somewhere
where the people aren't. Um,

120
00:06:49,460 --> 00:06:50,840
what do we do with that space?

121
00:06:50,870 --> 00:06:54,020
Either an existing cities that's now kind
of along the sides of all our streets

122
00:06:54,021 --> 00:06:57,990
and in our parking lots. Uh, how can we
use that space better for people? Um,

123
00:06:58,130 --> 00:07:01,910
and if we're designing a
place from scratch, how wide
should the streets be? Um,

124
00:07:01,970 --> 00:07:05,570
how should the space be allocated that
might've previously been diverted to

125
00:07:05,571 --> 00:07:06,800
vehicles.
Um,

126
00:07:07,430 --> 00:07:11,330
and so I think that has a number of really
far reaching consequences beyond just

127
00:07:11,331 --> 00:07:14,600
my ability. It's, is this whole
idea of being able to reclaim,

128
00:07:14,601 --> 00:07:16,130
I've been in the public
space, right. I mean,

129
00:07:16,131 --> 00:07:18,260
that in my mind is one of
the exciting things about,

130
00:07:18,261 --> 00:07:22,130
a little bit about exciting things about
autonomous vehicles is that for for

131
00:07:22,131 --> 00:07:26,210
such a long time we've lost a big piece
of the public realm and we're going to

132
00:07:26,211 --> 00:07:29,570
essentially be able to hopefully
claim some of that space back. Right.

133
00:07:29,780 --> 00:07:33,530
So as we think about what you guys are
doing in Toronto, um, particularly,

134
00:07:33,531 --> 00:07:35,720
maybe talk a little bit maybe about,
um,

135
00:07:35,780 --> 00:07:39,790
as you think about the design of
the space in Toronto in a, of the,

136
00:07:39,791 --> 00:07:43,190
of the project in Toronto,
what, what sort of other,

137
00:07:43,220 --> 00:07:48,050
beyond autonomous vehicles do you see
technology playing a role to improve

138
00:07:48,051 --> 00:07:50,780
living standards? Maybe you know,
from an environmental standpoint,

139
00:07:50,781 --> 00:07:54,020
from even from just a traditional quality
of place standpoint. Absolutely. Yeah.

140
00:07:54,021 --> 00:07:57,800
So, so this is a tiny bit of background
and sidewalk labs is really focused on

141
00:07:57,920 --> 00:08:00,530
building a place, a brand new
place from scratch and Toronto,

142
00:08:00,770 --> 00:08:04,530
right on the waterfront. It used to
be deport area of, of uh, Toronto, um,

143
00:08:04,970 --> 00:08:07,640
over some amount of time and we're
still in the planning process and the,

144
00:08:07,641 --> 00:08:11,630
and going through getting permission
from the city and the province of Ontario

145
00:08:11,900 --> 00:08:15,360
and the, and the federal government
of Canada to go ahead and do that. Um,

146
00:08:15,710 --> 00:08:18,110
but I hope for that area,
which has really undeveloped right now.

147
00:08:18,111 --> 00:08:22,370
So it's almost Tabula Rasa is to
think about, as you mentioned,

148
00:08:22,371 --> 00:08:24,110
sustainability sort of
environmental things.

149
00:08:24,111 --> 00:08:26,390
How can we make this
place kind of positive,

150
00:08:26,450 --> 00:08:31,290
so not just reduce the use of carbon
but reduce it to below zero, um,

151
00:08:31,460 --> 00:08:32,300
through,
um,

152
00:08:32,480 --> 00:08:36,950
clever applications of technology to make
heating and cooling more efficient to

153
00:08:36,951 --> 00:08:41,300
non digital technologies like heating dis,
district heating and cooling,

154
00:08:41,301 --> 00:08:45,830
which is often used on some campuses, but
expand that to a whole neighborhood. Um,

155
00:08:45,950 --> 00:08:47,780
we think about mobility,
which I already mentioned.

156
00:08:47,781 --> 00:08:50,480
There's a whole bunch of
really interesting things
even beyond self driving

157
00:08:50,481 --> 00:08:55,380
vehicles there. Um, when we think about
buildings themselves, um, you know,

158
00:08:55,381 --> 00:09:00,360
there are lots of technologies that will
enable and some already exist in some

159
00:09:00,361 --> 00:09:03,570
form as to make buildings
much more flexible,

160
00:09:03,600 --> 00:09:05,820
so able to adapt to
different users over time,

161
00:09:06,090 --> 00:09:10,710
but also cheaper to build at the same
or high quality than we have existing

162
00:09:10,750 --> 00:09:13,590
buildings. So the buildings
themselves and as you referenced,

163
00:09:13,610 --> 00:09:15,560
the quality of the public realm,
uh,

164
00:09:15,570 --> 00:09:18,630
each of these things contributes
to quality of life in the city.

165
00:09:18,631 --> 00:09:22,140
And those are our goals. Um, but
in particular in the public realm,

166
00:09:22,141 --> 00:09:24,750
if you think about it,
not just as parks, um,

167
00:09:24,780 --> 00:09:27,810
but once you think about sidewalks and
streets and maybe start erasing the

168
00:09:27,811 --> 00:09:32,450
boundaries between sidewalks and streets
and say these places are for people, um,

169
00:09:32,520 --> 00:09:37,080
how do we make them much more usable for
a whole bunch of different activities

170
00:09:37,170 --> 00:09:39,450
beyond what people use in for now?
Uh,

171
00:09:39,451 --> 00:09:43,200
and really almost create a public realm
that's an extension of your living room

172
00:09:43,740 --> 00:09:45,720
to make the whole place much more livable.

173
00:09:45,870 --> 00:09:49,440
We think about also ways of supporting
more community and health and human

174
00:09:49,441 --> 00:09:53,250
services. Um, and then sort
of underlying all of that,

175
00:09:53,251 --> 00:09:56,910
how do we actually build
the digital technology that,
that ties us all together.

176
00:09:57,060 --> 00:09:58,250
And there are opportunities there to,

177
00:09:58,251 --> 00:10:01,950
to create less siloed systems than
currently exist within cities.

178
00:10:02,010 --> 00:10:06,270
So what I'm hearing is this idea about
how we use technology really to really

179
00:10:06,271 --> 00:10:09,040
push the envelope on sort of
people centric design, right?

180
00:10:09,120 --> 00:10:12,060
Designers and urban developers
and people and mice are space.

181
00:10:12,061 --> 00:10:14,550
I've been thinking about this a long
time but had been constrained by this.

182
00:10:14,700 --> 00:10:17,730
But one of the things with,
with technology pushing the
boundaries a little bit,

183
00:10:17,850 --> 00:10:20,670
we're maybe able to push the envelope
so to speak on this a little bit more

184
00:10:20,671 --> 00:10:24,840
perhaps. Yeah, absolutely. And you know,
there are many things that, um, that,

185
00:10:24,890 --> 00:10:29,790
that the main, the cities move more slowly
than technology does. Um, one of those,

186
00:10:29,791 --> 00:10:32,880
for example, cities have
the responsibility to take
out the trash, you know,

187
00:10:32,881 --> 00:10:37,830
on a regular basis. And if
that's, um, that's a, that's
a significant problem. Uh,

188
00:10:37,831 --> 00:10:42,330
and so cities are unwilling to take big
risks and technologies, you know, at,

189
00:10:42,331 --> 00:10:45,380
at Google and elsewhere. We build little
prototypes, we throw them out there,

190
00:10:45,410 --> 00:10:48,540
we say, this is in Beta. If it
works, great, we will do more of it.

191
00:10:48,541 --> 00:10:51,920
If it doesn't work, we'll shut it down.
Cities don't have that luxury. Um,

192
00:10:51,960 --> 00:10:56,670
and so we hope that by creating a place
where we can actually experiment with

193
00:10:56,671 --> 00:11:01,590
some of these technologies, um, and
prove that some of them do work, um,

194
00:11:01,620 --> 00:11:02,640
then other cities,

195
00:11:02,641 --> 00:11:06,240
it turns out that once CDC and other
city doing something successfully,

196
00:11:06,360 --> 00:11:08,790
they're much more likely to follow along.

197
00:11:09,000 --> 00:11:12,210
There might be some sort of leading cities
that we'll try it initially and once

198
00:11:12,211 --> 00:11:14,580
there were a few than than,
than the way it happens.

199
00:11:14,760 --> 00:11:18,150
And so our hope is to kind of bootstrap
that. I love that idea of replication,

200
00:11:18,151 --> 00:11:21,450
right? This idea that you can take ideas
and sort of take it and put it in other

201
00:11:21,451 --> 00:11:23,070
cities.
And that's why the project,

202
00:11:23,071 --> 00:11:26,370
what you all are doing in Toronto I
think is really important. So Jonathan,

203
00:11:26,371 --> 00:11:29,730
I want to go back to what you originally
said about this idea of thinking about

204
00:11:29,731 --> 00:11:33,810
cities as organisms and particularly
why data is so important to us.

205
00:11:33,990 --> 00:11:38,990
So tell us a little bit more about how
you sort of see data and syncing syncing

206
00:11:39,330 --> 00:11:43,410
and scenario planning playing a role
to make us a much more dynamic planning

207
00:11:43,411 --> 00:11:45,150
system,
maybe to make things more efficient.

208
00:11:45,650 --> 00:11:48,980
So we plan in a 19th century way,

209
00:11:49,070 --> 00:11:53,310
essentially maybe early 20th century
and then kind of, I feel, um,

210
00:11:53,740 --> 00:11:57,550
distorted by in 1970 we passed
something called Neba and we have an

211
00:11:57,551 --> 00:11:59,050
environmental impact statement process,

212
00:11:59,051 --> 00:12:01,750
which just screws everything up as far
as far as I'm going and I'm going to

213
00:12:01,751 --> 00:12:03,810
deepen environmentalist. So, uh,

214
00:12:03,820 --> 00:12:07,180
and the reason is we can't
dynamically respond to anything.

215
00:12:07,181 --> 00:12:10,090
So here's what I recommend
is that number one,

216
00:12:10,330 --> 00:12:13,030
cities set visions and goals
for what they want to become.

217
00:12:13,330 --> 00:12:16,930
And you can turn those into what are
called community health indicators and

218
00:12:16,931 --> 00:12:19,180
community health indicators
are hundreds of measurements.

219
00:12:19,181 --> 00:12:23,440
You can measure things like uh,
vehicle miles traveled and, and uh,

220
00:12:23,441 --> 00:12:25,480
amount of walkability,
amount of affordability,

221
00:12:25,780 --> 00:12:29,900
your climate impacts and how well kids
are doing in school and suicide rates in

222
00:12:29,901 --> 00:12:34,810
the rest rates and all kinds of thousands
of measurements that measure your,

223
00:12:34,840 --> 00:12:38,170
your vision of,
of what community health is.

224
00:12:38,770 --> 00:12:42,820
Governments have tools and the tools
are basically regulations such as zoning

225
00:12:42,821 --> 00:12:45,250
codes and building codes
and things like that.

226
00:12:45,610 --> 00:12:49,120
Incentives and tax breaks and things
they can do to encourage people to do

227
00:12:49,121 --> 00:12:52,630
things. And regulations discourage people
from doing bad things and they make

228
00:12:52,631 --> 00:12:54,700
investments in things like infrastructure.

229
00:12:55,780 --> 00:13:00,070
They can use those cool tools I believe
in a continually dynamic process.

230
00:13:00,250 --> 00:13:01,510
So I'll give you an example.

231
00:13:01,511 --> 00:13:04,720
We have a subway station and
we say we want higher density,

232
00:13:04,721 --> 00:13:07,510
mixed use mixed income because we
want people to be able to walk to it.

233
00:13:07,780 --> 00:13:09,700
And today we would come
up with some zoning,

234
00:13:09,770 --> 00:13:13,060
but all these experts would figure out
what it should be and then they'd fix it

235
00:13:13,240 --> 00:13:16,370
and to be there for 20 years.
And I suggest instead,

236
00:13:16,390 --> 00:13:20,620
it'd be dynamic now with sensing we can
with big data and direct sensing and all

237
00:13:20,621 --> 00:13:22,390
that,
we can actually see you,

238
00:13:22,450 --> 00:13:26,740
the first building happens and you see
what it does and you keep adjusting. Um,

239
00:13:26,980 --> 00:13:28,930
and so for example,
you create more,

240
00:13:28,931 --> 00:13:30,820
let's say it doesn't look
like it's affordable enough.

241
00:13:30,821 --> 00:13:34,570
So you create more incentives
for affordability and
let's say it's not that you

242
00:13:34,571 --> 00:13:39,190
don't feel like people are walking in
offer and you can make higher uses of

243
00:13:39,191 --> 00:13:42,250
retail uses that have encouraged
people to stay in the area.

244
00:13:43,060 --> 00:13:45,400
There's a million tools that we have,
but we can be,

245
00:13:45,520 --> 00:13:49,650
so we're dynamically continually
evolving towards our vision. Uh,

246
00:13:49,740 --> 00:13:51,640
we have no capacity to do that right now.

247
00:13:51,930 --> 00:13:52,051
Yeah.

248
00:13:52,051 --> 00:13:55,440
Cause all of the data that we use in
this process is always looking backwards.

249
00:13:55,441 --> 00:13:57,420
Right? I mean, right. For the
most part, we look backwards.

250
00:13:57,660 --> 00:14:01,230
What happened over over time and
not really looking to the future.

251
00:14:01,440 --> 00:14:04,350
I mean we tried to do that as as
as it's folks in the data space,

252
00:14:04,351 --> 00:14:05,700
but we don't do a very good job of it.

253
00:14:05,750 --> 00:14:09,590
So there's a new program developed by
an architect named Peter Calthorpe.

254
00:14:09,591 --> 00:14:13,130
He's my brother in law. I got to reveal
that called urban urban footprint.

255
00:14:13,280 --> 00:14:16,010
But what urban footprint
is a future casting system.

256
00:14:16,520 --> 00:14:18,510
And so it's a scenario planning system.

257
00:14:18,511 --> 00:14:21,620
So what I think you needed to be doing
is not only collecting this real time

258
00:14:21,621 --> 00:14:25,280
data, but at the same time always
scenario, future casting forward.

259
00:14:25,580 --> 00:14:28,940
You'll never be 100% right.
But the future casting,

260
00:14:28,941 --> 00:14:32,420
the scenario planner give you a sense of
where to go and it'll give you a sense

261
00:14:32,421 --> 00:14:35,030
of the implications.
And with artificial intelligence,

262
00:14:35,031 --> 00:14:38,930
in essence you can use your
scenario planning and your
real time data collection

263
00:14:39,110 --> 00:14:42,860
and keep fine tuning yourself towards
outcomes and just recognize we'll never be

264
00:14:42,861 --> 00:14:45,470
perfect.
It's always evolving and it's dynamic.

265
00:14:45,680 --> 00:14:46,513
So Elizabeth,

266
00:14:46,640 --> 00:14:50,090
let's talk about inclusion and talk
about this idea of protection of local

267
00:14:50,091 --> 00:14:50,551
characters.

268
00:14:50,551 --> 00:14:54,860
As many of you as we talk about the rise
of technology in cities on particularly

269
00:14:54,861 --> 00:14:59,100
cities like our, our hometown of New
York. Um, the question of inclusion and,

270
00:14:59,101 --> 00:15:02,690
and displacement and really trying
to maintain neighborhood identity and

271
00:15:02,691 --> 00:15:07,691
authenticity with technology coming and
fastly coming even more so in the urban

272
00:15:08,271 --> 00:15:08,620
space.
It's,

273
00:15:08,620 --> 00:15:12,050
it's interesting that we've been a
slow adopter in the urban space to see

274
00:15:12,051 --> 00:15:15,500
technology, but as it comes,
how do we maintain the balance?

275
00:15:15,501 --> 00:15:17,830
How do we make sure that we're
sort of protecting, you know,

276
00:15:17,840 --> 00:15:22,120
that local character and being inclusive?
How do we do that?

277
00:15:22,260 --> 00:15:25,880
Right. Well, I think, you know,
this is a huge challenge and um,

278
00:15:25,980 --> 00:15:28,980
I want to reiterate something
that you said Jonathan, uh,

279
00:15:29,010 --> 00:15:32,910
around the environmental process because
the environmental process in New York

280
00:15:32,911 --> 00:15:37,911
City is one of the mechanisms that the
public is allowed to touch big planning

281
00:15:38,011 --> 00:15:39,790
projects.
And it is,

282
00:15:40,080 --> 00:15:43,920
I couldn't agree with you more about how
deeply flawed it is among other things.

283
00:15:44,100 --> 00:15:45,960
We don't learn from that process.

284
00:15:45,961 --> 00:15:50,961
So we gather all this data that the public
has interacted with in the course of

285
00:15:51,451 --> 00:15:55,980
one planning project or
another or a particular project
that's coming forward in

286
00:15:55,981 --> 00:15:56,814
a community.

287
00:15:56,940 --> 00:16:01,920
And yet we don't ever learn whether that
environmental document wasn't effective

288
00:16:01,921 --> 00:16:05,850
at establishing mitigations that
actually worked. So, you know,

289
00:16:05,851 --> 00:16:10,480
humans fundamentally don't like
change. You know, we, we all, you know,

290
00:16:10,500 --> 00:16:10,891
we all,

291
00:16:10,891 --> 00:16:13,650
and I'm sure all of you live in New
York or where were you living around the

292
00:16:13,651 --> 00:16:15,600
world?
You moved into a neighborhood,

293
00:16:15,601 --> 00:16:18,540
you kind of had a sense of
what that was going to be like.

294
00:16:18,570 --> 00:16:22,230
You chose it deliberately. Hopefully
you were able to, do you have the,

295
00:16:22,260 --> 00:16:25,470
the privilege of being able to do that.
And you know,

296
00:16:25,471 --> 00:16:30,120
the idea of that we could continually
change that without understanding what it

297
00:16:30,121 --> 00:16:34,880
is, it's probably going to freak out
most, uh, most, uh, New Yorkers and,

298
00:16:34,881 --> 00:16:39,150
and citizens. So the question is, how
do you create that level of engagement?

299
00:16:39,390 --> 00:16:42,840
That data actually means
something to the citizenry.

300
00:16:42,841 --> 00:16:47,841
So in New York City we collect a ton of
data and I'm sure everyone in this room

301
00:16:49,171 --> 00:16:54,171
understands the concept of a government
Gov 2.0 and the fact that government is

302
00:16:55,681 --> 00:17:00,660
not always the best provider of data
back to the public in a way that they can

303
00:17:00,661 --> 00:17:01,494
understand it.

304
00:17:01,620 --> 00:17:05,700
So one of the things that we need to
do and really in a very global way,

305
00:17:05,701 --> 00:17:10,470
and my organization is confronting this
every day because we're trying to figure

306
00:17:10,471 --> 00:17:14,160
out, well where is growth likely
to happen in New York? Um,

307
00:17:14,220 --> 00:17:18,330
where does preservation efforts
need to be out in front? You know,

308
00:17:18,331 --> 00:17:20,520
all those kinds of things.
It's really hard to figure that out.

309
00:17:20,521 --> 00:17:24,450
And if you're an average citizen looking
at the data that's collected in New

310
00:17:24,450 --> 00:17:27,750
York, it's very hard to get a
handle on what you're looking at.

311
00:17:28,080 --> 00:17:31,330
So this interface between,
uh,

312
00:17:31,350 --> 00:17:33,850
the collection of data and the,
uh,

313
00:17:33,960 --> 00:17:38,730
purveying of that data so that
communities can actually engage in it is a

314
00:17:38,731 --> 00:17:41,160
really, really, really important thing.

315
00:17:41,430 --> 00:17:44,340
And it involves capacity
building in the community.

316
00:17:44,341 --> 00:17:48,120
And this is a very human engagement.
It's not really about technology.

317
00:17:48,121 --> 00:17:53,010
It's really about getting there and
helping communities understand what tools

318
00:17:53,011 --> 00:17:57,570
they can reach for and how they can
educate themselves about how the system

319
00:17:57,571 --> 00:18:00,000
works,
how they can engage that system,

320
00:18:00,001 --> 00:18:04,020
where are the pressure points that they
can engage with and encouraging them to

321
00:18:04,021 --> 00:18:08,340
do that and making sure that
in a governmental level though,

322
00:18:08,370 --> 00:18:10,860
the playing field is as level as a can.

323
00:18:11,040 --> 00:18:13,740
So whether you come from a poor
community or a rich community,

324
00:18:13,741 --> 00:18:16,470
is your voice heard
equally in the process?

325
00:18:16,740 --> 00:18:19,590
We all probably know what the
answer to that question is,

326
00:18:19,680 --> 00:18:21,810
but that's probably for
later in the discussion.

327
00:18:22,260 --> 00:18:25,630
So when we think about urban
planning, one of the, one of the law,

328
00:18:25,710 --> 00:18:27,900
one of the biggest things that we
use to sort of dictate the way we,

329
00:18:27,901 --> 00:18:30,600
that we offer, you obviously use
land. It's our, it's our zoning code.

330
00:18:30,870 --> 00:18:34,880
Hi. Uh, there's industrials, there's some
land that's zoned for industrial use,

331
00:18:34,881 --> 00:18:38,630
some that's zoned for commercial use
and some that is zoned for residential.

332
00:18:38,930 --> 00:18:42,530
And generally speaking, cities
like to separate uses, right?

333
00:18:42,531 --> 00:18:46,670
We like to separate uses because frankly
we like to keep things nice and tidy a

334
00:18:46,671 --> 00:18:50,150
little bit. Right. That's sort of the
ideas for how we did it. That's right.

335
00:18:50,180 --> 00:18:52,880
First Place. Um, so that said,

336
00:18:53,030 --> 00:18:56,780
one of the questions that I have for you
all as we think about technology, um,

337
00:18:56,781 --> 00:18:59,060
and this is a bit of a geeky question,
but it is,

338
00:18:59,150 --> 00:19:04,150
how is the role of technology going to
allow us to really think about how we,

339
00:19:05,510 --> 00:19:08,870
we rethink zoning in our,
in our cities and our communities crank.

340
00:19:08,871 --> 00:19:11,630
You're probably thinking about this
really specifically in Toronto.

341
00:19:11,631 --> 00:19:12,380
Some thoughts on that.

342
00:19:12,380 --> 00:19:15,590
One of the specific things we're thinking
about is outcome based codes. So,

343
00:19:15,591 --> 00:19:16,340
so to your point,

344
00:19:16,340 --> 00:19:21,200
zoning and building codes tend to be
fairly prescriptive and static and say,

345
00:19:21,500 --> 00:19:25,790
ah, you know, we know that in New York
City, uh, cast iron pipes for plumbing,

346
00:19:26,040 --> 00:19:30,440
uh, what 20 while I'm already
safe. So that's, that's
everybody has to do that. Um,

347
00:19:31,200 --> 00:19:33,380
and of course,
as technology improves,

348
00:19:33,381 --> 00:19:36,470
there are probably a bunch
of other solutions that
maybe achieve the same goals

349
00:19:36,471 --> 00:19:39,110
at lower cost store,
more flexibility and so on.

350
00:19:39,290 --> 00:19:41,990
But because that sort of not on the
list of approved construction materials,

351
00:19:41,991 --> 00:19:45,520
et Cetera, that are not an option. Um,

352
00:19:45,620 --> 00:19:50,060
now with sensors and to your point
Jonathan, um, we can start saying, uh,

353
00:19:50,090 --> 00:19:53,440
potentially, uh, let's monitor
it. Let's think about it.

354
00:19:53,460 --> 00:19:56,180
Maybe an example of noise and one of
the issues around kind of having light

355
00:19:56,181 --> 00:19:58,700
industrial next to residential as
maybe you're going to just do it.

356
00:19:58,701 --> 00:20:00,900
People with noise, let's say that, um,

357
00:20:00,950 --> 00:20:04,900
you can use the space for whatever
you like as long as the noise level as

358
00:20:04,910 --> 00:20:07,520
monitored by some sense so that
it doesn't recall people talking,

359
00:20:07,521 --> 00:20:09,050
but just the sound pressure level,

360
00:20:09,200 --> 00:20:12,990
as long as it doesn't go above a certain
amount. And so you have to provide a,

361
00:20:13,000 --> 00:20:17,690
a building and a set of uses
that dampens the sound and so on.

362
00:20:17,930 --> 00:20:21,650
Uh, and that's monitored on
a dynamic, active basis. Um,

363
00:20:22,310 --> 00:20:24,020
rather than saying there's just a set of,

364
00:20:24,050 --> 00:20:27,680
of ways you have to build a building
because we know that that goes above and

365
00:20:27,681 --> 00:20:31,980
beyond the standard. Um, and that's
true about all kinds of things, um, uh,

366
00:20:32,030 --> 00:20:34,370
around odor,
around activities and so on.

367
00:20:34,371 --> 00:20:38,930
So can you actually define building
codes based on the outcomes you want to

368
00:20:38,931 --> 00:20:43,931
achieve and then allow
innovation to provide a new,

369
00:20:44,031 --> 00:20:47,980
sort of a clever ways of achieving
those outcomes, um, and be

370
00:20:47,980 --> 00:20:51,370
less prescriptive or about the way that
the codes are written. And Jonathan,

371
00:20:51,371 --> 00:20:54,580
that's where that dynamic data plays
an important role to allow you to think

372
00:20:54,581 --> 00:20:55,870
about those outcome metrics.
True.

373
00:20:56,400 --> 00:20:59,580
Exactly. So the other thing is that
our culture has changed enormously.

374
00:20:59,581 --> 00:21:01,470
If you think about it or
when America was founded,

375
00:21:01,710 --> 00:21:05,550
I believe 90% of people lived on farms
whereby by the way, they were living,

376
00:21:05,551 --> 00:21:09,420
working, manufacturing in effect,
doing everything all in one place.

377
00:21:09,690 --> 00:21:14,040
And then we became more segmented in
industrialization was a very dirty process

378
00:21:14,041 --> 00:21:17,370
and you didn't want to live near it and
it was to protect people. But today,

379
00:21:17,371 --> 00:21:21,000
if you think about how most of us live
in work, it's in a very integrative way.

380
00:21:21,260 --> 00:21:23,260
And,
and um,

381
00:21:23,400 --> 00:21:26,970
although you may want to Madden a separate
significant heavy duty manufacturing

382
00:21:26,971 --> 00:21:31,380
out, um, we really, the way people
naturally want to live now is,

383
00:21:31,381 --> 00:21:35,010
is in a much more integrated way. And we
need communities that will reflect that.

384
00:21:35,320 --> 00:21:39,640
So this week there've been three
articles alone about the rise of modular

385
00:21:39,641 --> 00:21:40,580
construction,
right?

386
00:21:40,780 --> 00:21:45,250
Modular housing construction as I sort
of technology and the development space.

387
00:21:45,490 --> 00:21:46,241
Thoughts on that.

388
00:21:46,241 --> 00:21:50,440
And you see that as an
innovative technology or
trend that will change how we

389
00:21:50,441 --> 00:21:54,160
sort of think about affordability or even
the construction space as we developed

390
00:21:54,161 --> 00:21:55,000
cities for the future.

391
00:21:55,110 --> 00:22:00,090
Yes. So we're going to go near term part
term. Yeah. Okay. So in the near term, uh,

392
00:22:00,250 --> 00:22:03,090
we've thought about manufactured
housing is creating chunks.

393
00:22:03,091 --> 00:22:07,740
Basically boxes that you add up
and there's some advantage of that.

394
00:22:07,741 --> 00:22:11,010
But then some also in flexibility, but
there's a company now, for example,

395
00:22:11,011 --> 00:22:12,570
named dirt,
which is based in Canada,

396
00:22:12,780 --> 00:22:16,080
which has a d I r t t is not
an advertisement for them,

397
00:22:16,081 --> 00:22:20,940
but they have a system in which you do
three d design of the space that you want.

398
00:22:21,120 --> 00:22:24,540
You put on cargoes and you can actually
walk and see through the space.

399
00:22:24,750 --> 00:22:28,440
It's in real time giving you back
the pricing information. You're,

400
00:22:28,630 --> 00:22:31,770
you're picking finishes, zero doing all
kinds of stuff. And then when you're,

401
00:22:31,771 --> 00:22:32,590
you want to order,

402
00:22:32,590 --> 00:22:37,590
you push order and then the factory
builds it exactly as it is and it gets

403
00:22:37,681 --> 00:22:39,930
delivered to you and
never installation teams.

404
00:22:40,080 --> 00:22:43,470
So you're really integrating design,
uh,

405
00:22:43,560 --> 00:22:48,270
pricing and delivery. Uh, and it's much
more by the way, material efficient,

406
00:22:48,271 --> 00:22:52,200
which is environmentally efficient.
Okay. But that's still at the, that's so,

407
00:22:52,201 --> 00:22:55,170
and so those are walls and pieces.
So there's less than the chunk level,

408
00:22:55,171 --> 00:22:58,830
but we're really want to go is member.
I started with the analogy of DNA.

409
00:22:59,400 --> 00:23:02,100
So from an environmental point of view,
we have to move from,

410
00:23:02,101 --> 00:23:05,010
we currently build out of
concrete, steel, glass, copper,

411
00:23:05,250 --> 00:23:07,950
and all these we mined from the earth
and all have very negative environmental

412
00:23:07,951 --> 00:23:09,990
impacts.
The true solution,

413
00:23:10,290 --> 00:23:13,170
at least in the next hundred to 200
years to the environmental issues,

414
00:23:13,171 --> 00:23:16,500
we have to start building out of timber
and organic materials cause timber

415
00:23:16,501 --> 00:23:19,750
captions. Carbon has much
lower embodied energy, um,

416
00:23:19,920 --> 00:23:23,040
and it's a regenerative material.
And for example,

417
00:23:23,041 --> 00:23:27,510
we can already begin to grow fungus, like
kind of mushroom, like installations.

418
00:23:27,870 --> 00:23:32,630
So the issue is we had the
move from mining in inorganic
materials to turning to

419
00:23:32,640 --> 00:23:37,070
biological buildings if to start growing
our building materials. So to me, the,

420
00:23:37,240 --> 00:23:41,520
the future step is where we're designing
our buildings in three d and then we're

421
00:23:41,521 --> 00:23:43,200
turning that not into plans,

422
00:23:43,201 --> 00:23:47,480
but we're turning that into DNA and we're
actually growing the components that

423
00:23:47,481 --> 00:23:49,730
we need,
high tech components for our buildings.

424
00:23:50,030 --> 00:23:53,630
And then when it's time to recycle
them or disassembled them, you can,

425
00:23:53,840 --> 00:23:56,840
because they're the, they have a
basic code that we have created.

426
00:23:56,841 --> 00:24:01,100
We can decode them and read and
repurpose them. And that's really does.

427
00:24:01,260 --> 00:24:03,590
So it's following nature's cycle
as to how we're going to solve our

428
00:24:03,591 --> 00:24:06,160
environmental issues and create a
much more affordable though. Right?

429
00:24:06,520 --> 00:24:09,730
So let's just recap some of the things
that we've heard so far about technology.

430
00:24:09,731 --> 00:24:13,240
We've heard that number one, technology,
the rise of technology and Everett space.

431
00:24:13,241 --> 00:24:15,250
It's going to give us more
back of the public round back.

432
00:24:15,251 --> 00:24:17,740
Perhaps it's going to make
us more climate sensitive,

433
00:24:17,741 --> 00:24:20,140
really thinking about how
we think about the, uh,

434
00:24:20,141 --> 00:24:23,830
the environment going in the future,
maybe more affordable housing. Uh,

435
00:24:23,860 --> 00:24:25,390
may help with the inclusion piece.

436
00:24:25,570 --> 00:24:29,200
One last thing we haven't touched on
enough is this engagement piece. So let's,

437
00:24:29,201 --> 00:24:33,080
with what I know that you wrote a
terrific piece about, about how, um,

438
00:24:33,200 --> 00:24:36,700
technology government is disconnected
a bit from the citizen jury.

439
00:24:36,910 --> 00:24:39,910
How do you see us using technology,

440
00:24:39,911 --> 00:24:43,960
particularly how can government use
technology to really engage with its,

441
00:24:44,080 --> 00:24:48,680
with its community base at a much more um,
really authentic way?

442
00:24:48,990 --> 00:24:51,600
Yeah, so I'm just going to tell
a little bit of a personal story,

443
00:24:51,601 --> 00:24:55,080
which is that when I was in
government in San Francisco,

444
00:24:55,320 --> 00:25:00,320
I often would hear from my employees
who had seen me on the cable channel.

445
00:25:02,240 --> 00:25:07,240
I'm testifying before the
board of supervisors about
the budget or some policy

446
00:25:07,951 --> 00:25:10,890
issue. That was before the
recreation park department,

447
00:25:10,891 --> 00:25:14,670
which is the one I was
running at the time. And, uh,

448
00:25:14,671 --> 00:25:18,930
I recently went down to a
BSA hearing, um, uh, sorry,

449
00:25:18,931 --> 00:25:23,750
the board of standards and appeals,
um, in New York City. And uh,

450
00:25:23,790 --> 00:25:28,790
not only is there no closed circuit TV
so that if you can't get in the room you

451
00:25:30,031 --> 00:25:33,690
absolutely do not know what's going on
in that room unless someone comes out

452
00:25:33,691 --> 00:25:37,920
with a Bull Horn and tells you in
the outer room what's going on.

453
00:25:38,310 --> 00:25:42,420
There is no computer screen
that even says what items the,

454
00:25:42,450 --> 00:25:47,250
the commission is, is on.
I mean literally we are in,

455
00:25:47,251 --> 00:25:51,210
what is that 1980s technology
in terms of public engagement.

456
00:25:51,630 --> 00:25:56,630
It also means that if you were a
citizen who radical new idea works,

457
00:25:57,600 --> 00:26:02,340
you can't get to those hearings and
can't engage in the democratic process in

458
00:26:02,341 --> 00:26:05,760
any substantive way. You have to take
time off, you have to get a babysitter,

459
00:26:05,761 --> 00:26:10,761
you have to show up in a room where you
may or may not ever be able to interact

460
00:26:10,891 --> 00:26:14,880
with the policy makers who are making
decisions. That is, you know, we are,

461
00:26:14,881 --> 00:26:18,840
we are very, very far away from
the ideal let's just say but,

462
00:26:19,020 --> 00:26:23,220
but let me just talk about a couple of
ways in which technology actually changes

463
00:26:23,221 --> 00:26:26,760
very fundamentally.
So technology voting machines,

464
00:26:26,770 --> 00:26:31,770
ability to do rank order
voting for instance is the
difference between us having

465
00:26:33,901 --> 00:26:38,610
a walked in two party system and the
possibility of more minority views.

466
00:26:38,610 --> 00:26:43,530
And I don't mean diversity views, but
just any kind of minority view, um,

467
00:26:43,680 --> 00:26:48,210
beginning to percolate up in our
political system. So there is, and that's,

468
00:26:48,211 --> 00:26:48,451
you know,

469
00:26:48,451 --> 00:26:52,950
voting is the thing that New Yorkers
are not doing today that they should be.

470
00:26:53,250 --> 00:26:57,540
Um, uh, and so we need to figure
out how that happens. This is,

471
00:26:57,570 --> 00:27:02,220
this is the fun, most fundamental way
in which we engage with our government.

472
00:27:02,670 --> 00:27:07,230
But when you move into these much more
complicated city planning and land use

473
00:27:07,231 --> 00:27:10,380
decisions that are being made
and talked about, I mean,

474
00:27:10,381 --> 00:27:15,381
I've been following the Toronto project
and the initial level of suspicion about

475
00:27:16,531 --> 00:27:21,420
what your very thoughtful planning
process was really going to be about.

476
00:27:21,600 --> 00:27:23,350
It's kind of understandable
because there's,

477
00:27:23,430 --> 00:27:27,120
we live in a world where there's a
lot of distrust between government and

478
00:27:27,121 --> 00:27:27,930
citizens.

479
00:27:27,930 --> 00:27:31,410
And part of it is the sense that decisions
are being made behind closed doors.

480
00:27:31,620 --> 00:27:36,480
So the question is how you open those
doors and how do you create a level

481
00:27:36,481 --> 00:27:38,670
playing field so people
can engage in the dialogue.

482
00:27:38,850 --> 00:27:43,410
There's a lot of technology tools to
do that. You know, people are using,

483
00:27:43,620 --> 00:27:47,130
um, uh, you know, the ability
for people, for instance,

484
00:27:47,131 --> 00:27:52,131
just to interact on a website or whatever
to put in their opinions and views on

485
00:27:52,651 --> 00:27:55,440
a particular policy
decision that's being made.

486
00:27:55,680 --> 00:28:00,680
But there's also opportunities in the
local community to really think about how

487
00:28:01,111 --> 00:28:04,380
do we allow policymakers
to engage on a much,

488
00:28:04,560 --> 00:28:07,560
much more incremental level
with their own constituents.

489
00:28:07,770 --> 00:28:10,170
And I don't think that's what we're doing.
I mean,

490
00:28:10,171 --> 00:28:14,040
tweeting is not a substitute
for real political dialogue.

491
00:28:14,220 --> 00:28:16,830
I don't think anyone in
the room would doubt that.

492
00:28:16,831 --> 00:28:21,010
And certainly in the last year and
a half, am I counting right? Um, uh,

493
00:28:21,120 --> 00:28:25,260
we've seen how that's just
a destructive force in,

494
00:28:25,300 --> 00:28:28,290
in a democratic dialogue rather
than a constructive one. So,

495
00:28:28,590 --> 00:28:33,450
so really giving folks a mechanism for
having a true voice at the table. Exactly.

496
00:28:33,680 --> 00:28:34,513
Sort remind you something

497
00:28:34,710 --> 00:28:39,160
Austin's about yeah. About transportation.
Yes. Everyone's very excited. Um,

498
00:28:39,210 --> 00:28:43,950
about the, the, the futuristic cities.
But I'm getting, tell me about my commute.

499
00:28:44,230 --> 00:28:44,720
Oh yeah.

500
00:28:44,720 --> 00:28:48,670
And I'm hearing like ride sharing services
have helped bike sharing services.

501
00:28:48,690 --> 00:28:52,920
Like we have a few docs outside in
California and our offices there,

502
00:28:52,921 --> 00:28:57,780
there's now a doc with scooters.
So how are we going to get around cities?

503
00:28:57,781 --> 00:29:01,560
How will that be changing and mixed use
zoning helps in regards to the commute,

504
00:29:01,561 --> 00:29:03,900
which we all talked about, but
what, what else is in store?

505
00:29:05,110 --> 00:29:08,950
Well, I can I speak a little bit to where
we are in New York City at the moment

506
00:29:08,951 --> 00:29:12,160
because I think this is a really
interesting question about technology.

507
00:29:12,161 --> 00:29:17,161
So we are an environmentally strong
city because we use mass transit.

508
00:29:18,490 --> 00:29:19,660
Um,
uh,

509
00:29:19,661 --> 00:29:24,661
and our carbon footprint is much lower
because we do yet we have a subway system

510
00:29:26,861 --> 00:29:30,580
which is in a state of,
depending on which day it is,

511
00:29:30,581 --> 00:29:33,310
one might say total collapse
or partial collapse.

512
00:29:33,730 --> 00:29:37,860
We have a brilliant new leader who
actually came from Andy, Andy Bideford,

513
00:29:37,900 --> 00:29:41,050
who came from Toronto
actually who I have been.

514
00:29:41,110 --> 00:29:46,110
I was very pessimistic about this and
he's been really causing my optimism to,

515
00:29:47,200 --> 00:29:50,140
to rise.
He is deliberately picking a tool,

516
00:29:50,190 --> 00:29:55,190
a tool for fixing our subway system
that is not the most cutting edge of

517
00:29:56,681 --> 00:29:57,514
technology.

518
00:29:57,670 --> 00:30:02,380
And it's very much to this point you
made a little bit earlier about does

519
00:30:02,381 --> 00:30:06,910
government want to risk being
on the absolute front edge,

520
00:30:07,060 --> 00:30:08,590
which many of,
you know,

521
00:30:08,591 --> 00:30:12,610
governor Cuomo has been making an argument
that we ought to try a new technology

522
00:30:12,611 --> 00:30:17,530
and our subway system and any bifurcate
to his enormous credit is saying not

523
00:30:17,531 --> 00:30:22,531
until it's proven because I have to
deliver this fast and well and um,

524
00:30:23,670 --> 00:30:28,080
I'm going to use the technology that's
been effective in other cities, right? Uh,

525
00:30:28,210 --> 00:30:31,840
much better than the technology which is
now almost a hundred years old and our

526
00:30:31,841 --> 00:30:36,720
subway system, but, but nonetheless
not at the cutting edge. Um,

527
00:30:36,940 --> 00:30:41,320
and that gets to this dynamic about
whether governments can really truly adopt

528
00:30:41,440 --> 00:30:44,700
the most cutting edge tool. I think, um,

529
00:30:44,770 --> 00:30:48,640
we want him to actually make our subway
system work better in the next five

530
00:30:48,641 --> 00:30:51,340
years,
which he says he is able to do.

531
00:30:51,640 --> 00:30:55,960
If that's a trade off against a dream
of a technology that might take us a

532
00:30:55,961 --> 00:30:59,500
little bit further. I don't know.
That's a hard trade off to make.

533
00:30:59,710 --> 00:31:01,980
I think I want my eat train
to run faster sooner. Okay.

534
00:31:02,300 --> 00:31:06,080
More thoughts on sort of the future of
technology and transportation as we look

535
00:31:06,081 --> 00:31:07,610
to the future for,
for cities,

536
00:31:07,790 --> 00:31:11,420
both from planning and maybe even
towards implementation. Jonathan hurt.

537
00:31:11,500 --> 00:31:16,210
So, uh, the, the dream of autonomous
vehicles has an economics to it,

538
00:31:16,211 --> 00:31:18,740
which we don't discuss much
and that is utilization, right?

539
00:31:18,820 --> 00:31:21,250
So the car that's 24 hour utilized.
So by the way,

540
00:31:21,251 --> 00:31:24,010
I've said to several of autonomous
vehicle makers and they've all ignored me,

541
00:31:24,250 --> 00:31:25,750
that if I were going to roll out a system,

542
00:31:25,751 --> 00:31:29,110
the number one place I do it is
in Las Vegas and the sunset strip,

543
00:31:29,111 --> 00:31:32,980
because the weather's great
and the utilization is 24
hours is a very small rate

544
00:31:32,981 --> 00:31:35,770
you've got to map at all is a very small
range that I would think that would be

545
00:31:35,771 --> 00:31:38,860
like the most profitable street
in the world to do. But anyway,

546
00:31:39,420 --> 00:31:43,370
um, but something, yeah. So, uh,

547
00:31:43,650 --> 00:31:46,830
so maybe the mayor's listening,
hopefully, right. At any rate,

548
00:31:47,430 --> 00:31:48,860
the point is all about you utilization.

549
00:31:49,040 --> 00:31:53,420
So, uh, so when you, you guys
are too young to remember,

550
00:31:53,421 --> 00:31:56,540
but when cable TV first got rolled out,

551
00:31:56,870 --> 00:32:00,620
all the taboo cable TV sees it's covered.
He said to cities,

552
00:32:00,860 --> 00:32:04,610
it's too expensive to go everywhere.
We are just going to start,

553
00:32:04,611 --> 00:32:05,540
we want a franchise,

554
00:32:05,541 --> 00:32:10,280
we just want to start in the places that's
most profitable and then over decades

555
00:32:10,281 --> 00:32:13,400
literally they are ultimately
forced to do universal service,

556
00:32:13,640 --> 00:32:15,170
which they don't really get away anyway,

557
00:32:15,230 --> 00:32:17,330
try and get fire out in the
Bronx or something. But anyway,

558
00:32:17,540 --> 00:32:21,200
which they theoretically you
know, have, have risen too.

559
00:32:21,620 --> 00:32:23,930
So I see this as the issue that uh,

560
00:32:24,000 --> 00:32:25,730
the autonomous vehicle
companies are going to say,

561
00:32:25,731 --> 00:32:28,550
we want to be where it's most profitable.
And so you're going to be,

562
00:32:28,551 --> 00:32:30,560
either you're on the loop
or you're in the system,

563
00:32:30,561 --> 00:32:33,170
you were outside of the
system and rural America.

564
00:32:33,170 --> 00:32:38,170
And does it mean a whole parts of
places in which there's in essence this,

565
00:32:38,341 --> 00:32:42,290
this is the systems going to be biased
against because of profitable utilization.

566
00:32:42,630 --> 00:32:44,570
And so if you really
want an equitable system,

567
00:32:44,720 --> 00:32:48,190
the subway system is a really
equitable system. So I think, you know,

568
00:32:48,500 --> 00:32:49,940
putting on a government hat in,

569
00:32:49,941 --> 00:32:53,510
would franchise agreements you have to
franchise with a bias towards equity?

570
00:32:53,780 --> 00:32:57,320
Are you suggesting that we have to sort
of think about the role of technology,

571
00:32:57,380 --> 00:33:00,200
the future of transportation
even more as a public good,

572
00:33:00,290 --> 00:33:03,180
continue to sort of think about it as a
public good even as we sort of mix and

573
00:33:03,380 --> 00:33:07,010
mix and match the delivery,
a delivery vehicle.

574
00:33:07,610 --> 00:33:11,540
So you have to think about as a public
good and you have to think about and and

575
00:33:11,541 --> 00:33:16,370
so as a,
just as a founding premise of,

576
00:33:16,371 --> 00:33:20,010
of all my another founding premise am
I thinking America is hugely zipcode

577
00:33:20,090 --> 00:33:22,610
biased.
So if you live in the healthiest zip code,

578
00:33:22,611 --> 00:33:26,390
you are 20 years statistically you are
likely to live 20 years longer than the

579
00:33:26,391 --> 00:33:28,520
least healthy zip code.
And if you go,

580
00:33:28,521 --> 00:33:32,810
if you grew up in the best public school
district or one of the top 20 school

581
00:33:32,840 --> 00:33:33,850
public school districts,

582
00:33:33,990 --> 00:33:36,800
you're a chance of getting into college
is literally a hundred times greater

583
00:33:36,801 --> 00:33:39,290
than if you grew up in the worst,
maybe more than a hundred times greater.

584
00:33:39,620 --> 00:33:43,490
So we have these enormous zipcode biases
in my theory about public policy is to

585
00:33:43,491 --> 00:33:47,690
always, always overcome those biases
and equally distribute the landscape of

586
00:33:47,691 --> 00:33:49,940
opportunity.
So in transportation,

587
00:33:49,941 --> 00:33:53,210
which is the connectivity system
is one of those prime functions.

588
00:33:53,211 --> 00:33:57,070
I basically say uh,
information, uh, healthcare,

589
00:33:57,260 --> 00:34:01,010
education and transportation are the
places where you want the ground of

590
00:34:01,011 --> 00:34:04,140
equality to begin.
Yeah.

591
00:34:04,460 --> 00:34:07,610
Well I was going to say on the, on, on
the mobility side first I think, you know,

592
00:34:07,670 --> 00:34:11,030
I've been sort of making the assumption
and I think the panel has in general

593
00:34:11,031 --> 00:34:12,530
that self driving cars are coming.

594
00:34:12,740 --> 00:34:14,750
I just want to just double
check that with the audience.

595
00:34:14,780 --> 00:34:16,250
This is probably a
slightly biased audience,

596
00:34:16,251 --> 00:34:20,510
but who thinks in 20 years there'll
be a lots of self driving cars sort of

597
00:34:20,511 --> 00:34:24,050
everywhere. Okay, fine. So what,
so you guys are mostly bought in,

598
00:34:24,051 --> 00:34:28,400
which is kind of what I suspected. Um,
one of the, I think the impacts of,

599
00:34:28,401 --> 00:34:32,210
of self driving vehicles other than kind
of the mobility we already talked about

600
00:34:32,211 --> 00:34:34,280
in the urban planning or
safety, you know, and,

601
00:34:34,290 --> 00:34:38,990
and because these are computing devices
that are looking at older records at

602
00:34:38,991 --> 00:34:43,550
once, you know, have lots of
redundancy. So you know, the
team at Waymo for example,

603
00:34:43,670 --> 00:34:47,720
which was spun off from Google is has
got, you're working on very, very safe,

604
00:34:47,721 --> 00:34:50,540
redundant computing, you know,
paying attention all of the time,

605
00:34:50,630 --> 00:34:53,630
which is something that human drivers
just don't have the capacity to do, right.

606
00:34:53,780 --> 00:34:56,880
And often choose not to do actively.
Um,

607
00:34:57,140 --> 00:35:02,140
and so one impact of that is that we
have the opportunity to give streets much

608
00:35:02,901 --> 00:35:04,910
more back to pedestrians and cyclists,

609
00:35:05,000 --> 00:35:07,820
like actual people sort of wandering
around under their own steam.

610
00:35:08,060 --> 00:35:11,570
And so I think one of the
other implications of self
driving vehicles is in fact

611
00:35:12,350 --> 00:35:16,310
more walking, more cycling, more,
more healthy ways of getting around.

612
00:35:16,810 --> 00:35:18,860
Another couple of implications are,
you know,

613
00:35:18,861 --> 00:35:23,861
right now we have a vehicle fleet where
somebody buys a car for themselves

614
00:35:24,351 --> 00:35:26,960
sometimes when they're commuting on their
own and then on the weekends they have

615
00:35:26,961 --> 00:35:29,750
the whole family. And so thereby
sort of a larger vehicle than need.

616
00:35:29,751 --> 00:35:30,950
Most of the time.
Um,

617
00:35:31,100 --> 00:35:34,250
you would imagine a fleet of autonomous
vehicles might come in a whole bunch of

618
00:35:34,251 --> 00:35:35,210
sizes.
In fact,

619
00:35:35,211 --> 00:35:38,190
most of them will be relatively small
because it will be for individuals which

620
00:35:38,191 --> 00:35:42,810
will also make things safer cause
sort of less mass moving around.

621
00:35:43,030 --> 00:35:47,070
Um, but also less congested because
there are sort of smaller vehicles.

622
00:35:47,250 --> 00:35:49,500
But there is,
there are some challenges.

623
00:35:49,501 --> 00:35:51,900
I think this was not
an analog allied good.

624
00:35:52,110 --> 00:35:54,600
You can imagine if it's super comfortable
to be on your autonomous vehicle

625
00:35:54,601 --> 00:35:58,020
commuting and you can read the paper, you
can watch a movie, you can catch a nap.

626
00:35:58,320 --> 00:35:58,560
Uh,

627
00:35:58,560 --> 00:36:03,180
people might be happy just sort of being
in congested traffic a lot and kind of

628
00:36:03,181 --> 00:36:04,260
just getting other stuff done.

629
00:36:04,261 --> 00:36:08,370
And we might end up with cities completely
choked by vehicles. And you know,

630
00:36:08,371 --> 00:36:09,750
it's not clear that that will happen.

631
00:36:09,751 --> 00:36:13,680
But it seems like a high likelihood
that we need to think about the kinds of

632
00:36:13,860 --> 00:36:18,000
policies and regulations around these
and maybe the kinds of market forces that

633
00:36:18,001 --> 00:36:21,360
would not create that,
that dystopian future. Um,

634
00:36:21,450 --> 00:36:25,410
and so I think there's some
really interesting challenges
ahead that aren't just

635
00:36:25,411 --> 00:36:27,830
technological challenges but also,
like I said,

636
00:36:27,831 --> 00:36:29,970
some sort of policy and
regulation challenges.

637
00:36:30,070 --> 00:36:30,431
So Craig,

638
00:36:30,431 --> 00:36:33,310
you were hit on a really important point
and that is public policy needs to be

639
00:36:33,311 --> 00:36:35,800
thinking about these,
these challenges. Now this,

640
00:36:35,860 --> 00:36:36,700
you had something that you wanted to,

641
00:36:36,820 --> 00:36:38,270
no, no, I was going to go,

642
00:36:38,271 --> 00:36:41,600
I was going to talk a little bit
about this dystopian view that he,

643
00:36:41,601 --> 00:36:43,010
that you began with.
I mean,

644
00:36:43,070 --> 00:36:47,030
Americans tend to think about
our cars as our personal thing.

645
00:36:47,630 --> 00:36:50,600
Even in New York. And even
with car shoring, sharing,

646
00:36:50,601 --> 00:36:52,760
we think about these
as our personal thing.

647
00:36:53,030 --> 00:36:55,400
And if autonomous vehicles
are actually going to a treat,

648
00:36:55,410 --> 00:36:59,180
achieve a utopian vision
and not a dystopian vision,

649
00:36:59,330 --> 00:37:01,760
we need to let go of that idea.
Right?

650
00:37:01,970 --> 00:37:06,500
Because it can't be one for
one or even one for four.

651
00:37:06,530 --> 00:37:08,420
We just don't have the room for it.

652
00:37:08,660 --> 00:37:12,970
And if we're going to garner back the,

653
00:37:12,971 --> 00:37:17,900
the street and the sidewalk,
um, for the public,

654
00:37:18,020 --> 00:37:22,520
we need not to have people believe that
they're an autonomous car is going to be

655
00:37:22,521 --> 00:37:25,400
sitting outside their apartment building,

656
00:37:25,430 --> 00:37:28,070
waiting for them whenever they want to go.
Right.

657
00:37:28,280 --> 00:37:31,640
And that's exactly the public
policy challenge, um, uh,

658
00:37:31,670 --> 00:37:36,220
that we have to confront is
against our, um, you know, our,

659
00:37:36,280 --> 00:37:41,270
our other side, which is selfish and
once the maximum convenience we can get.

660
00:37:41,480 --> 00:37:42,313
And so those,

661
00:37:42,350 --> 00:37:46,730
those two things have to be balanced by
public policy and can they be balanced

662
00:37:46,731 --> 00:37:50,180
by public profit policy
fast enough that the,

663
00:37:50,390 --> 00:37:54,920
that the use of autonomous cars hasn't
said into a pattern that we then have to

664
00:37:54,921 --> 00:37:58,820
break. And that's the, that's I
think the challenge of the timing.

665
00:37:59,000 --> 00:38:03,470
How do we think through the public policy
issues soon enough that we're actually

666
00:38:04,250 --> 00:38:08,400
implementing them along with autonomous
cars as opposed to after a po.

667
00:38:08,450 --> 00:38:11,270
Autonomous cars have begun
to set patterns. Okay. It

668
00:38:11,290 --> 00:38:12,310
cause that's an important point.

669
00:38:12,311 --> 00:38:16,450
Public policy always tends to be reactive
instead of proactive are moving or

670
00:38:16,451 --> 00:38:18,550
changing it. Which I think gets
to the point of why we need data.

671
00:38:18,910 --> 00:38:21,280
Let's just shift the
conversation just a bit.

672
00:38:21,310 --> 00:38:25,690
I want to talk about data privacy and
why we collect data. So Craig, you all,

673
00:38:25,691 --> 00:38:26,770
what sidewalk labs may be,

674
00:38:26,771 --> 00:38:29,170
thinking about how you're going to
look at data of your residents and the

675
00:38:29,171 --> 00:38:30,640
businesses that are in your district,

676
00:38:30,970 --> 00:38:34,060
what types of data do you think are you
going to be collecting and how are you

677
00:38:34,061 --> 00:38:35,980
going to think about privacy?
You as you as you

678
00:38:36,010 --> 00:38:37,180
mitigate these? Yeah, this is a,

679
00:38:37,181 --> 00:38:38,740
this is an issue that lots
of people are concerned.

680
00:38:38,741 --> 00:38:41,800
This is the issue of when we talk about
the planning and Toronto a little bit.

681
00:38:41,801 --> 00:38:42,010
Yeah.

682
00:38:42,010 --> 00:38:45,610
So the way we think about it as is we
always start at sidewalk labs with the

683
00:38:45,611 --> 00:38:48,970
quality of life goals that we have and I
kind of listed things like mobility and

684
00:38:48,971 --> 00:38:51,460
sustainability and public
realm and buildings and so on,

685
00:38:51,670 --> 00:38:55,510
as kind of some of the things we want
to improve on in terms of public life.

686
00:38:55,840 --> 00:38:57,820
And that's where we start.
When we think about data,

687
00:38:58,060 --> 00:39:02,110
at least we don't think about data until
we've identified that we need data to

688
00:39:02,111 --> 00:39:04,330
achieve certain goals.
So for example,

689
00:39:04,360 --> 00:39:07,540
if you work through a goals
around sustainability,

690
00:39:07,541 --> 00:39:12,070
around air quality and water quality and
energy usage for heating and cooling,

691
00:39:12,490 --> 00:39:16,420
it turns out that the list of kinds of
data that you need like the flow of water

692
00:39:16,421 --> 00:39:19,300
through pipes,
the flow of sewage through pipes,

693
00:39:19,301 --> 00:39:22,810
the amount of energy consumed
by a building, uh, the,

694
00:39:22,820 --> 00:39:25,330
the amount of heating and
cooling district wide and so on.

695
00:39:26,080 --> 00:39:29,610
These don't seem like things that have
privacy implications. And in fact, when,

696
00:39:29,611 --> 00:39:32,200
when you go down the list of
these quality of life goals,

697
00:39:32,500 --> 00:39:35,270
it's not really clear to me where,
uh,

698
00:39:35,350 --> 00:39:40,120
privacy invasive data at plays
a plays a role. Um, you know,

699
00:39:40,121 --> 00:39:42,070
there will be other systems
somewhere else. You know,

700
00:39:42,071 --> 00:39:45,550
obviously we all use devices
that in some ways, uh, you know,

701
00:39:45,780 --> 00:39:49,750
asked war and gather our private data,
but it's not at all clear to me that,

702
00:39:49,751 --> 00:39:54,010
that the city and the public realm should
be gathering personally identifiable

703
00:39:54,011 --> 00:39:55,100
data.
Um,

704
00:39:55,180 --> 00:39:59,230
it seems to me that we can achieve most
of the big leaps without doing that.

705
00:39:59,530 --> 00:40:00,191
And furthermore,

706
00:40:00,191 --> 00:40:03,400
I think there are ways that technology
can improve people's privacy.

707
00:40:03,401 --> 00:40:05,680
So at the moment,
there's a bit of a silly example,

708
00:40:05,681 --> 00:40:10,150
but if I go to a bar and I want to buy a
drink, not me personally. Uh, you know, I,

709
00:40:10,310 --> 00:40:13,570
I was about to say, you know, the
bartender wants to check, uh, that I'm,

710
00:40:13,571 --> 00:40:16,060
that I'm of drinking age,
I'm fine. But you know,

711
00:40:16,120 --> 00:40:19,510
if somebody does ask for my driver's
license, I hand over to them my name,

712
00:40:19,600 --> 00:40:22,750
my address, my actual, you
know, exact date of birth. Uh,

713
00:40:22,751 --> 00:40:26,620
and there are technologies based
on cryptographic signatures,

714
00:40:26,770 --> 00:40:28,960
essentially proofs of, of, uh,

715
00:40:28,961 --> 00:40:33,961
of claims that allow me
that to demonstrate to the
bartender that I'm a drinking

716
00:40:34,001 --> 00:40:38,380
age as certified by the DMV or some other
organization, but they can verify in a,

717
00:40:38,381 --> 00:40:40,970
in a technological, logical way, uh, that,

718
00:40:40,971 --> 00:40:44,740
that don't reveal any data apart
from the fact that I'm over 21. And,

719
00:40:44,770 --> 00:40:46,840
and that's maybe a
slightly contrived example,

720
00:40:46,841 --> 00:40:49,740
but there are many of these
cases where in fact we think, uh,

721
00:40:49,780 --> 00:40:53,620
in cities you should be able to reveal
much less about yourself as you're going

722
00:40:53,621 --> 00:40:56,830
about your daily life than you
currently are required to. So, Jonathan,

723
00:40:56,831 --> 00:41:00,340
you've given a lot of thought to how
data should play a role in planning and

724
00:41:00,341 --> 00:41:02,950
development. What about the privacy
issue from your perspective?

725
00:41:03,190 --> 00:41:06,190
So it's a little more complicated
because one of the things we're really

726
00:41:06,191 --> 00:41:06,910
focusing on now,

727
00:41:06,910 --> 00:41:11,170
and we had this big partnership we put
together with the Harvard School of

728
00:41:11,170 --> 00:41:12,280
Public Health,
Columbia School of public health,

729
00:41:12,281 --> 00:41:16,510
Dartmouth and others to try and do a
baseline assessment of our residents and

730
00:41:16,511 --> 00:41:19,360
see if certain interventions we're doing
on health and education to actually

731
00:41:19,361 --> 00:41:20,194
make a difference.

732
00:41:20,350 --> 00:41:24,100
And you can do that on a population level
and you can do it by measuring things

733
00:41:24,101 --> 00:41:26,860
like hospital emergency room,
via ambulance, ambulances,

734
00:41:26,861 --> 00:41:28,510
visiting your property
and stuff like that.

735
00:41:28,750 --> 00:41:31,690
But what I really want to know is cortisol
levels and what are you known for as

736
00:41:31,691 --> 00:41:34,550
measures of stress and what
really it is this stuff. You know,

737
00:41:34,551 --> 00:41:37,580
I really want to know am I,
am I individually, you know,

738
00:41:37,581 --> 00:41:38,870
how many people is diabetes,

739
00:41:38,871 --> 00:41:42,440
have we reduced insulin levels
are improved or whatever. Um,

740
00:41:43,010 --> 00:41:44,780
and that's complicated.

741
00:41:45,050 --> 00:41:47,930
So I'll tell you the most interesting
technology we've come across.

742
00:41:47,931 --> 00:41:49,490
We are not using this yet,

743
00:41:49,491 --> 00:41:54,260
but we just discovered this is
there's a guy who measures um, uh,

744
00:41:54,860 --> 00:41:56,120
basically human waste.

745
00:41:56,210 --> 00:42:00,350
He did goes to city sewer systems that
he measures the level of cortisol in it.

746
00:42:00,351 --> 00:42:04,100
There a batch of metal lights that show
how well you're digesting what you've

747
00:42:04,101 --> 00:42:07,340
been eating and show whether you've
been exposed to environmental toxins,

748
00:42:07,341 --> 00:42:11,480
et cetera. And that's a way we think
to be or we, so we need to find,

749
00:42:11,510 --> 00:42:13,190
if not that system,
some system,

750
00:42:13,370 --> 00:42:17,090
where are we going to actually
get human health real data,

751
00:42:17,330 --> 00:42:19,310
but an an anonymous way.

752
00:42:19,690 --> 00:42:23,740
That'd be a cleaner way to do it. Maybe
you were talking about cleaning your gun,

753
00:42:23,910 --> 00:42:25,440
right? Yeah, for sure. I'll lose.

754
00:42:25,450 --> 00:42:27,970
What should the community be concerned
about privacy as we think about data?

755
00:42:27,971 --> 00:42:31,060
What's your, what's your thought from
the, Oh, I think the answer is, of course,

756
00:42:31,061 --> 00:42:35,170
and you know, the, the issues
that we've just talked about,

757
00:42:35,200 --> 00:42:40,200
both of Jonathan and Craig
have just talked about are
our examples of how it can

758
00:42:40,511 --> 00:42:44,830
work in our favor, but without thinking
proactively about that, it doesn't,

759
00:42:45,010 --> 00:42:49,810
it doesn't have to come out that way.
Right. And, um, you know, we, we,

760
00:42:49,830 --> 00:42:50,590
um,

761
00:42:50,590 --> 00:42:55,590
need to find ways to not only
create data that is an automized,

762
00:42:56,800 --> 00:43:00,880
but useful for these
bigger societal goals,

763
00:43:01,180 --> 00:43:06,180
but we also need to create data that is
accessible to the public so that they

764
00:43:07,031 --> 00:43:08,620
know what everyone else is seeing.

765
00:43:08,770 --> 00:43:12,060
Because part of the issue here
is transparency, right? Um,

766
00:43:12,160 --> 00:43:16,300
is that it's doesn't feel good if
somebody else's collecting a bunch of data

767
00:43:16,450 --> 00:43:19,930
about my community and I don't get to
see it and I don't understand what the

768
00:43:19,931 --> 00:43:21,010
implications of it are.

769
00:43:21,250 --> 00:43:25,300
Whereas if we can begin to
think about as we go along,

770
00:43:25,510 --> 00:43:30,190
how do we make that data, which
will be largely innocuous, right?

771
00:43:30,460 --> 00:43:35,110
Transparent so that people understand
where it is innocuous and where it isn't.

772
00:43:35,440 --> 00:43:39,660
Um, uh, and then able
to intervene I think is,

773
00:43:39,710 --> 00:43:42,700
it's a really interesting dynamic
that we need to think about.

774
00:43:42,940 --> 00:43:46,270
But I also just want to
point out that that, uh,

775
00:43:46,280 --> 00:43:51,280
a lot of the data that we're collecting
now isn't useful to government or the

776
00:43:51,881 --> 00:43:55,900
private sector or to individuals at
all. You know, we sort of collect it,

777
00:43:55,901 --> 00:43:56,471
but we don't,

778
00:43:56,471 --> 00:44:00,670
we're at that stage when we don't know
quite what to do with it yet and how to

779
00:44:00,671 --> 00:44:05,080
analyze it and how to make it
useful. And I think that, um,

780
00:44:05,480 --> 00:44:10,190
uh, you know, we, we have been, we
met with a city council person, uh,

781
00:44:10,210 --> 00:44:12,040
not too long ago when
he said, well, you know,

782
00:44:12,041 --> 00:44:15,460
there's this phenomenon going on in my
neighborhood and it's only everybody

783
00:44:15,461 --> 00:44:19,720
tells us it's only in our neighborhood
of these illegal conversions of housing

784
00:44:19,721 --> 00:44:23,710
units. And we went to the public
sector data that afternoon,

785
00:44:23,920 --> 00:44:27,580
pulled a big map of complaints that
are coming in all across the city.

786
00:44:27,581 --> 00:44:30,970
And guess what,
it's not just happening in his,

787
00:44:31,440 --> 00:44:35,820
it's happening all across the city.
And part of that is just the very simple,

788
00:44:36,030 --> 00:44:36,863
um,
uh,

789
00:44:36,900 --> 00:44:41,610
learning how to express that data in a
way that it's useful to policy makers.

790
00:44:41,880 --> 00:44:45,700
So before we came out, Jonathan, you, you
post a really interesting question and,

791
00:44:45,701 --> 00:44:50,370
and um, about this idea about enhancing
data to make us is enhancing data,

792
00:44:50,371 --> 00:44:53,490
making us better consumers
are better citizens.

793
00:44:53,610 --> 00:44:56,010
Talk a little bit more about that and
your thoughts and your thoughts on that

794
00:44:56,250 --> 00:44:56,860
question.

795
00:44:56,860 --> 00:44:59,110
So as you know,
you know,

796
00:44:59,800 --> 00:45:04,800
my sense is the use of data by all of
the for profits and companies such as

797
00:45:05,111 --> 00:45:06,130
Google's and many,

798
00:45:06,131 --> 00:45:09,760
many others is all being used for
income optimization of the company.

799
00:45:10,180 --> 00:45:13,990
And that essentially looks at
individuals as consumers and asks,

800
00:45:14,500 --> 00:45:18,370
what can I either sell them or
facilitate the sales to them and,

801
00:45:18,490 --> 00:45:20,440
and where is there money
to be made in that?

802
00:45:20,620 --> 00:45:23,690
And that's the function of the
data and what's happened in,

803
00:45:23,691 --> 00:45:27,550
in America and actually I'm seeing
globally is that people are, are,

804
00:45:27,880 --> 00:45:31,840
are thinking much less about
their roles as citizens as there.

805
00:45:31,890 --> 00:45:34,240
You mentioned the roles as,
as even voting.

806
00:45:34,241 --> 00:45:37,620
And he does a really depressing article
in the New York Times this weekend about

807
00:45:37,630 --> 00:45:40,840
it. A guy trying to do voter registration
and had Randall's island at a music

808
00:45:40,841 --> 00:45:44,800
festival. And the, the, I hope everybody
in this audience has registered.

809
00:45:44,980 --> 00:45:46,450
And if you're not registered to vote,

810
00:45:46,690 --> 00:45:50,740
please register to vote and tell your
friends to register each hugely important.

811
00:45:51,160 --> 00:45:51,993
Um,

812
00:45:52,850 --> 00:45:57,490
and we are beginning to get the kinds of
governments that happened when we don't

813
00:45:57,491 --> 00:46:01,340
care. Uh, or we don't care
enough citizen engagement.

814
00:46:01,360 --> 00:46:05,170
So there's a measure of how you knew
what a really healthy community is.

815
00:46:05,171 --> 00:46:08,950
And it turns out it's called collective
efficacy is whether people in that

816
00:46:08,951 --> 00:46:12,100
community feel that acting together
they can make a difference and then

817
00:46:12,101 --> 00:46:16,470
experienced the actual making
of a difference. And, and
that, by the way, it is,

818
00:46:16,480 --> 00:46:17,800
it can be very data enabled.

819
00:46:17,801 --> 00:46:20,050
We can use it to gather people
together to create movements,

820
00:46:20,051 --> 00:46:23,380
to create information,
areas of interest. Um,

821
00:46:23,650 --> 00:46:26,050
it's very different than
turning people into consumers.

822
00:46:26,910 --> 00:46:29,370
Other thoughts? Yeah. And
well I also think there are,

823
00:46:29,400 --> 00:46:33,830
there are big problems that
take big data and big, uh,

824
00:46:33,840 --> 00:46:37,220
policy, uh, results. So, uh,

825
00:46:37,230 --> 00:46:40,380
we were talking a little bit before
about climate change and I've been very

826
00:46:40,381 --> 00:46:45,180
concerned about heat island in particular
because I think our, um, most of the,

827
00:46:45,220 --> 00:46:47,340
the tools that are being used
at the governmental level,

828
00:46:47,400 --> 00:46:50,850
certainly here in New
York or are very low tech,

829
00:46:50,940 --> 00:46:55,170
they're white paint and trees. I
love trees. White paint is fine,

830
00:46:55,200 --> 00:46:57,300
but it's not exactly a high tech solution.

831
00:46:57,660 --> 00:47:02,660
Whereas if we were beginning to model the
natural wind patterns of New York and,

832
00:47:02,790 --> 00:47:04,170
and zoning,

833
00:47:04,171 --> 00:47:09,171
creating zoning and policy
implications for maximizing that,

834
00:47:09,810 --> 00:47:12,300
we wouldn't be doing just a thing.
You know,

835
00:47:12,301 --> 00:47:17,301
heat island means that we pump our air
conditioning and our cooling and all

836
00:47:17,521 --> 00:47:22,470
those systems up, which of course makes
the problem worse. So I, in that case,

837
00:47:22,471 --> 00:47:26,640
we've got an relatively old school
technology that's actually exacerbating a

838
00:47:26,641 --> 00:47:28,290
problem rather than making it better.

839
00:47:28,500 --> 00:47:33,500
Whereas if had combinations of scientists
and planners working together with

840
00:47:35,501 --> 00:47:36,940
data to really think about,

841
00:47:36,941 --> 00:47:39,730
well what are the changes we need to
make in New York City to really take

842
00:47:39,731 --> 00:47:43,780
advantage of our natural systems
to cool the city in a better way.

843
00:47:43,930 --> 00:47:47,680
We might actually be preventing
people from dying every summer,

844
00:47:47,681 --> 00:47:50,860
which is what happens in New York. I
want to get a question from the audience,

845
00:47:52,160 --> 00:47:56,290
right. I'll, I'll just put these
clothes anyway and on, on a,

846
00:47:56,291 --> 00:47:57,310
on community engagement.

847
00:47:57,311 --> 00:48:01,000
I think one opportunity is is you know
we talk about all politics being local,

848
00:48:01,120 --> 00:48:02,290
but how about high political,
you know,

849
00:48:02,291 --> 00:48:05,300
if I want to have a block party
and shut down my block, you know,

850
00:48:05,301 --> 00:48:07,600
on the weekend and, and invite,
you know, you have some,

851
00:48:07,780 --> 00:48:11,860
some folks along and play some music is
a big pulmonary process that the Mip d

852
00:48:11,880 --> 00:48:15,550
it's, it's complicated and it said it
doesn't happen very often. You know what,

853
00:48:15,551 --> 00:48:18,340
if it were possible for me to
say I live in this neighborhood,

854
00:48:18,520 --> 00:48:19,900
who around me you sort of thumbs up,

855
00:48:19,901 --> 00:48:23,710
thumbs down about having a block party
if you know the, if if things turn out,

856
00:48:23,760 --> 00:48:27,190
you know if people liked the idea then
maybe there's an automated process for

857
00:48:27,191 --> 00:48:32,020
that permit to be granted at as long as
there's no extenuating circumstances and

858
00:48:32,250 --> 00:48:36,550
and the you make it much easier for those
things to happen and start by having

859
00:48:36,760 --> 00:48:40,960
like a tiny bit of sort of low risk
democracy happening at a hyperlocal level

860
00:48:41,140 --> 00:48:45,550
and sort of build up from there because
sort of that the stakes are lower and

861
00:48:45,580 --> 00:48:48,550
things can happen a little bit
more quickly and and things,

862
00:48:48,790 --> 00:48:51,130
there's more of maybe
instant gratification there.

863
00:48:51,250 --> 00:48:54,130
I think there might be some opportunities
to start there and grow them to do

864
00:48:54,131 --> 00:48:55,180
something more impactful.

865
00:48:55,210 --> 00:48:59,330
I'm not sure if I liked that idea of my
neighbors will always say no question

866
00:48:59,350 --> 00:49:00,160
from the audience.

867
00:49:00,160 --> 00:49:00,431
Yeah.

868
00:49:00,431 --> 00:49:05,431
So somewhere with that Jason has asked
re outcome based zoning rules at what

869
00:49:05,951 --> 00:49:07,840
granularities do you plan to try this?

870
00:49:07,870 --> 00:49:10,780
One could envision a mixed use
building where multiple tenants have to

871
00:49:10,781 --> 00:49:13,350
collectively share a limit
on noise, odor, et cetera.

872
00:49:13,600 --> 00:49:17,470
Do you expect to see new cap and trade
economies evolve within and or across

873
00:49:17,471 --> 00:49:18,304
properties?

874
00:49:18,470 --> 00:49:20,840
I think there's lots of interesting,
I've been questions with the idea of,

875
00:49:20,841 --> 00:49:22,430
of of outcome based codes.

876
00:49:22,460 --> 00:49:25,760
So I think we need to stop
by demonstrating that the
data can be collected.

877
00:49:25,761 --> 00:49:27,020
And then I think yeah we,

878
00:49:27,021 --> 00:49:29,600
there probably is some experimentation
about like what does it mean?

879
00:49:29,601 --> 00:49:32,330
There are certain things that
I held that the life safety,

880
00:49:32,600 --> 00:49:33,880
those are kind of nonnegotiable.

881
00:49:33,890 --> 00:49:36,020
Those can't be sort of
negotiated within a building.

882
00:49:36,170 --> 00:49:39,860
There are other things that are around
comfort and maybe our negotiated within a

883
00:49:39,861 --> 00:49:41,960
building. Um, but um,

884
00:49:42,140 --> 00:49:45,740
I think it's a new enough idea that
there's probably a number of iterations to

885
00:49:45,741 --> 00:49:49,880
go through in a sort of a safe environment
before I think we understand exactly

886
00:49:49,881 --> 00:49:50,780
what they should look like.

887
00:49:50,960 --> 00:49:54,740
And of course it's in the end
it's a city regulation question.

888
00:49:54,741 --> 00:49:57,950
And so the city has to be convinced
and that's a pretty high bar,

889
00:49:57,951 --> 00:50:00,620
that this is a better solution
than the current fixed.

890
00:50:01,380 --> 00:50:06,090
They also have to be able to
respond to that data, right?

891
00:50:06,091 --> 00:50:06,481
I mean it's,

892
00:50:06,481 --> 00:50:11,160
it's not just a question of the public's
willingness to engage in that data and

893
00:50:11,161 --> 00:50:14,100
have it dictate a way,

894
00:50:14,101 --> 00:50:16,770
an approach in a particular place,

895
00:50:16,950 --> 00:50:21,950
but it's also the city's ability to
understand all that incrementality and how

896
00:50:24,181 --> 00:50:28,040
it comes together and to be able to
regulate it in a way that's, that's

897
00:50:28,070 --> 00:50:32,660
responsive to that. And um, when
you look in some our city agency,

898
00:50:32,661 --> 00:50:35,300
it's one doesn't really think
that's going to happen tomorrow.

899
00:50:35,600 --> 00:50:37,700
I just want to add,
go Jason.

900
00:50:37,701 --> 00:50:42,050
That idea of a cap and trade economy from
the building level is a fantastic idea.

901
00:50:42,051 --> 00:50:44,600
It could be an amazing marketplace
for environmental. Good.

902
00:50:45,520 --> 00:50:48,350
One question before you wrap.
Kind of a question from Philip.

903
00:50:48,351 --> 00:50:50,030
I think everyone is going
to be excited to hear this.

904
00:50:50,450 --> 00:50:53,900
The panel talked about getting people
to think as citizens and get involved.

905
00:50:54,020 --> 00:50:57,680
Could there be a 20% like project
for citizens to get involved?

906
00:50:57,950 --> 00:51:01,280
What would that look like? How could, how
could they do that? It's a great question

907
00:51:01,980 --> 00:51:05,370
from for the technologists in the room,
head down to city, that civic hall,

908
00:51:05,580 --> 00:51:08,670
it's an old great organization here in
New York City where there's a physical

909
00:51:08,671 --> 00:51:12,000
gathering of people thinking about these
problems and get involved in a project.

910
00:51:12,940 --> 00:51:13,480
Uh,

911
00:51:13,480 --> 00:51:16,940
we were actually trying to
do an initiative to get a
million low income voters

912
00:51:17,180 --> 00:51:20,810
registered. Uh, I go back
to voter registration, but
once we get them registered,

913
00:51:21,100 --> 00:51:25,520
uh, we need to inform them about issues
and it'd be great to do a 20% project to

914
00:51:25,521 --> 00:51:30,050
figures out how you really inform people
about issues. So one of the things I

915
00:51:30,130 --> 00:51:33,070
here, I mean hearing, just wrapping
up the conversation a bit, is it,

916
00:51:33,071 --> 00:51:35,980
if we're linking about the role of
technology and the impact of the impact on

917
00:51:35,981 --> 00:51:38,080
the future,
it's going to involve the engagement.

918
00:51:38,081 --> 00:51:40,120
It's engagement from the technology side.

919
00:51:40,121 --> 00:51:41,590
It's engagement from the development side,

920
00:51:41,591 --> 00:51:45,100
but also engagement from the community,
right? That it can't just be top down,

921
00:51:45,101 --> 00:51:48,820
that this idea that we have to look
to get our provide mechanisms for the

922
00:51:48,821 --> 00:51:52,450
community to engage as well
as is it critically important
piece to this as well.

923
00:51:53,140 --> 00:51:55,390
Please join me in thanking our panelists.
We are at time.

924
00:51:58,660 --> 00:51:59,380
Thank you,
Steven.

