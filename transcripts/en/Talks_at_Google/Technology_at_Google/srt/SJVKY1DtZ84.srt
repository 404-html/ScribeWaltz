1
00:00:09,260 --> 00:00:13,850
So, um, I just finished
the book over the weekend.

2
00:00:14,330 --> 00:00:19,220
Um,
and I really appreciated all the stories,

3
00:00:19,221 --> 00:00:23,900
right? Like you, you have been, you know,
a firsthand participant and talk to,

4
00:00:24,190 --> 00:00:28,430
uh, lots of other people who were about
like the evolution of this from, you know,

5
00:00:28,431 --> 00:00:30,770
kind of a crazy idea that,
you know,

6
00:00:30,771 --> 00:00:34,780
a handful of small teams
worked on and, and, uh, it's,

7
00:00:34,810 --> 00:00:38,920
I really loved all the stories and just
getting to know the peoples, you know,

8
00:00:38,930 --> 00:00:42,530
someone you might hear about in the news
and I just love the way he's told the

9
00:00:42,531 --> 00:00:47,240
story. So I thought, um, since
you know, this is where at Google,

10
00:00:47,241 --> 00:00:49,040
this is a book about the driverless car.

11
00:00:49,070 --> 00:00:54,070
Maybe a fun story to jump into would be
to tell everybody a little about your

12
00:00:54,381 --> 00:00:56,600
first ride in the chauffeur car.

13
00:00:57,440 --> 00:01:00,970
Happy to do that. And thanks everybody
for coming today. It's a real pleasure.

14
00:01:01,340 --> 00:01:05,600
It's a pleasure to be part of your
team. Actually. Um, I was, um, uh,

15
00:01:05,630 --> 00:01:08,170
General Motors until 2009,
um,

16
00:01:08,510 --> 00:01:12,910
we had competed in the Darpa
urban challenge in 2007. You know,

17
00:01:12,920 --> 00:01:17,920
that was a race of robotic cars and the
first prize was $2 million and Jim was

18
00:01:17,991 --> 00:01:20,540
starting to hit the wall at that time.
So I figured we needed the money,

19
00:01:20,541 --> 00:01:22,100
we better go out and win this race.

20
00:01:22,850 --> 00:01:27,850
But we sponsored a Carnegie Mellon's team
and Chris Urmson who subsequently led

21
00:01:29,540 --> 00:01:33,100
this program for Google self driving cars,
um,

22
00:01:33,140 --> 00:01:34,900
reached out to me after I left Gm.

23
00:01:34,950 --> 00:01:38,360
They were looking for a gray
beard auto executive that could,

24
00:01:38,361 --> 00:01:42,880
could help them out. So
I came out in 2010. Uh,

25
00:01:42,890 --> 00:01:46,250
the deal was I'd come out and talk to
them if I could ride in the car and they

26
00:01:46,251 --> 00:01:48,570
had 13 Prius's.
Um,

27
00:01:48,680 --> 00:01:52,100
and it was remarkable progress
because at the urban challenge,

28
00:01:52,101 --> 00:01:57,101
we had a Chevy Tahoe sport utility vehicle
that was just loaded with hardware.

29
00:01:57,800 --> 00:01:58,430
I mean,
you could,

30
00:01:58,430 --> 00:02:02,810
you could barely squeeze one person into
the vehicle and by the time they were

31
00:02:03,050 --> 00:02:06,940
doing the testing in 2009 and 10,
they had it in a press.

32
00:02:06,950 --> 00:02:09,680
Most of all the hardware was
in the trunk of the Prius,

33
00:02:09,681 --> 00:02:11,180
plus the sensors on the outside.

34
00:02:11,690 --> 00:02:15,740
So at that time you could write
on one on one in the vehicle. Um,

35
00:02:15,830 --> 00:02:19,310
and it's a basically an expressway.
So I drove the car out.

36
00:02:19,370 --> 00:02:23,510
I had a technician next to
me in the passenger seat
and I had an engineer in the

37
00:02:23,511 --> 00:02:27,710
back seat and I had a big red panic button
on the council. So this is, you know,

38
00:02:27,711 --> 00:02:32,030
too late 2010 early
2011 and they said okay,

39
00:02:32,031 --> 00:02:34,250
just to engage it like
you would cruise control.

40
00:02:34,310 --> 00:02:37,910
I was in the Middle Lane of the freeway
and my hands are shaking over the

41
00:02:37,911 --> 00:02:41,960
steering wheel. My feet are shaking, I
think, and this is crazy, but you know,

42
00:02:41,961 --> 00:02:44,450
once I engaged it,
within about a couple minutes,

43
00:02:44,451 --> 00:02:48,380
Jeremy has started feeling natural.
The car was intuitive.

44
00:02:48,381 --> 00:02:52,100
Even at that point in time a Volkswagen
beetle came up on my left and cut in

45
00:02:52,101 --> 00:02:54,740
front of me and I
realized the car I was in,

46
00:02:54,741 --> 00:02:58,910
it already backed off and started to
create a gap for that vehicle to get into.

47
00:02:58,960 --> 00:03:01,210
And you would never be able
to do that as a driver.

48
00:03:01,600 --> 00:03:04,930
This technology has like eagle eye vision
with eyes in the back of your head.

49
00:03:04,940 --> 00:03:05,411
Later on,

50
00:03:05,411 --> 00:03:09,070
a big semi truck came up on my right and
sure enough my car was nudging over a

51
00:03:09,071 --> 00:03:09,850
bit.

52
00:03:09,850 --> 00:03:14,830
But when I found so fascinating was after
the first 10 minutes it was so relaxed.

53
00:03:14,831 --> 00:03:17,740
I wasn't even worried about weather
traffic backed up in front of man.

54
00:03:17,741 --> 00:03:21,340
I never thought about jumping to the
right lane or left lane to get in front of

55
00:03:21,341 --> 00:03:24,880
someone. It just took all the road
rage and stress out of driving.

56
00:03:25,000 --> 00:03:29,560
So I was sold and that that was a
remarkable accomplishment and just a real

57
00:03:29,561 --> 00:03:33,040
testament to how good this team was
that you had a Google self driving cars.

58
00:03:33,440 --> 00:03:36,650
Yeah, it was, it was really
striking to hear the, the I,

59
00:03:36,651 --> 00:03:40,580
there's a story you tell about I think
riding in one of the early Carnegie

60
00:03:40,580 --> 00:03:41,570
Mellon cars.
Yeah.

61
00:03:41,670 --> 00:03:43,470
Yeah. Well, I, um,

62
00:03:43,500 --> 00:03:47,820
because general motors was the
sponsor of the Carnegie Mellon boss,

63
00:03:47,821 --> 00:03:51,450
we call the boss of the Chevy Tahoe.
And I thought it was important that I,

64
00:03:51,720 --> 00:03:55,830
being head of R and d go out and put in
an appearance and get to know the team.

65
00:03:55,831 --> 00:03:58,200
We had some of our engineers
embedded with the team.

66
00:03:58,860 --> 00:04:02,670
And so I went out and they had it
out on a test track, which was, um,

67
00:04:03,030 --> 00:04:05,790
a real old like steel plant that it,

68
00:04:05,791 --> 00:04:08,700
then they sort of just sort of
grabbed it and started using,

69
00:04:08,701 --> 00:04:10,230
I don't even know if they
had permission to do it,

70
00:04:10,231 --> 00:04:12,330
but it was rutted roads and everything.

71
00:04:12,331 --> 00:04:16,020
And they were showing me how the vehicle
would operate autonomously. And I said,

72
00:04:16,021 --> 00:04:19,290
well, I'd like a ride in it. And he
kind of looked at me and it's found,

73
00:04:19,920 --> 00:04:23,550
they didn't say no, but I said, yeah,
I really would like to write on it.

74
00:04:23,550 --> 00:04:27,030
So they squeezed me in that one other
area that you could fit into. Well,

75
00:04:27,510 --> 00:04:30,360
this vehicle wasn't designed for a human,

76
00:04:30,361 --> 00:04:32,960
this vehicle was designed to
win a self driving car race.

77
00:04:32,961 --> 00:04:35,340
So it accelerated very aggressively.

78
00:04:35,670 --> 00:04:39,870
Stopped very aggressively cornered very
aggressively and within about 30 seconds

79
00:04:39,871 --> 00:04:44,760
I'm getting so carsick and they're all
laughing about this because they really

80
00:04:44,761 --> 00:04:48,080
put one over on me. But that
was an important point. Um,

81
00:04:48,180 --> 00:04:52,140
the Carnegie Mellon team felt that
by being an aggressive driver,

82
00:04:52,141 --> 00:04:55,080
we were more like an x games
athlete in this competition.

83
00:04:55,380 --> 00:05:00,380
We knew Stanford was going to be more
like I'm a figure skater and they were

84
00:05:01,051 --> 00:05:04,890
going to have a really
smooth, nice, precise vehicle.

85
00:05:05,370 --> 00:05:08,580
But we knew enough about the race that
we thought we could pick up six minutes

86
00:05:08,581 --> 00:05:12,780
but accelerating hardened braking hard
and we won the race by 20 minutes.

87
00:05:12,781 --> 00:05:14,180
So that was an important part of our,

88
00:05:15,050 --> 00:05:19,590
yeah. You mentioned a writing in the
chauffeur car the first time you,

89
00:05:19,770 --> 00:05:20,850
you pretty quickly,

90
00:05:21,090 --> 00:05:24,840
we're relaxed and not worried about
things and you sorta comment that they're

91
00:05:24,841 --> 00:05:25,930
actually, you know, there,

92
00:05:26,430 --> 00:05:30,300
there are different strategies being
pursued in the marketplace today about,

93
00:05:30,301 --> 00:05:32,550
you know, like how do, how
do we deploy this technology,

94
00:05:32,551 --> 00:05:34,290
how do we bring it to a mass audience?

95
00:05:34,291 --> 00:05:38,490
And one is kind of this
driver assist version that um,

96
00:05:39,170 --> 00:05:43,890
and, and the other is more of a service
and he kind of observed that. Um,

97
00:05:44,220 --> 00:05:45,900
what'd you say?
I think that uh,

98
00:05:46,470 --> 00:05:50,820
the driver assist version says you
don't need to pay attention to the road

99
00:05:50,940 --> 00:05:52,470
except that because it's an assistant,

100
00:05:52,471 --> 00:05:56,520
it also says you need to be paid paying
attention at all times in order to take

101
00:05:56,530 --> 00:05:59,030
over. And I want, if you want
to comment a little, yeah,

102
00:06:00,560 --> 00:06:05,100
no, the Google self driving car team
I think may two really big decisions.

103
00:06:05,220 --> 00:06:06,390
They've made a lot of great decisions,

104
00:06:06,391 --> 00:06:11,391
but early on they made the decision that
they wanted to create a car that didn't

105
00:06:11,581 --> 00:06:15,030
rely on what's called vehicle to
vehicle or vehicle to infrastructure

106
00:06:15,031 --> 00:06:15,930
communication.

107
00:06:16,290 --> 00:06:19,920
So a lot of people on this field thought
that if you get cars talking to each

108
00:06:19,921 --> 00:06:21,750
other,
they could avoid each other.

109
00:06:22,290 --> 00:06:25,710
But I think the Google self driving car
came realize that you'd have to have all

110
00:06:25,711 --> 00:06:28,770
cars capable and would take
forever to get to that point.

111
00:06:29,130 --> 00:06:33,870
They also believe because of your
background mapping and because of their

112
00:06:33,871 --> 00:06:37,680
knowledge of the sensors that they could
actually do a standalone self driving

113
00:06:37,681 --> 00:06:40,980
car. And, and, and that
was critically important.

114
00:06:41,350 --> 00:06:44,970
They began to develop this technology
that I experienced on the freeway and they

115
00:06:44,971 --> 00:06:48,360
thought maybe they could do an initial
product called the highway assist.

116
00:06:48,690 --> 00:06:53,190
And they did a dog fooding a exercise
with the local mountain view.

117
00:06:53,310 --> 00:06:57,030
Google employees ask them to
use the vehicle on weekends.

118
00:06:57,031 --> 00:06:59,310
They had a promise to pay
attention to their driving,

119
00:06:59,311 --> 00:07:01,950
but they could take you to lake
Tahoe and stuff alone. And behold,

120
00:07:01,951 --> 00:07:06,951
within the first few weeks we realized
that that these people were totally

121
00:07:07,021 --> 00:07:07,854
distracted.

122
00:07:08,010 --> 00:07:12,390
One individually even fell asleep and you
would never been able to reengage them

123
00:07:12,391 --> 00:07:16,530
if something came up. Uh, and uh,
the Daniel Fairfield on the team,

124
00:07:16,531 --> 00:07:20,010
he reached an important conclusion, I
think shared with all of us. He said,

125
00:07:20,580 --> 00:07:22,500
you know,
if we always keep the driver in the loop,

126
00:07:22,501 --> 00:07:24,390
we're never going to be
safer than the driver.

127
00:07:24,600 --> 00:07:27,450
90% of the crashes are due to human error.

128
00:07:27,960 --> 00:07:30,340
So they concluded these driver assist.

129
00:07:30,360 --> 00:07:33,210
Jeremy was not consistent with their goal,

130
00:07:33,211 --> 00:07:37,890
which was to eliminate car crashes all
together and made the second really

131
00:07:37,891 --> 00:07:42,630
important decision that their commitment
was to totally autonomous where a

132
00:07:42,631 --> 00:07:44,610
person would never be asked to take over.

133
00:07:44,611 --> 00:07:49,280
Now you can imagine what a challenge
that is because you have to discover all

134
00:07:49,300 --> 00:07:53,700
those really unusual things that happen
in everyday driving or every year

135
00:07:53,701 --> 00:07:55,950
driving that long tail.

136
00:07:56,310 --> 00:08:00,480
And that's part of what's going on
right now is this continued learning.

137
00:08:00,840 --> 00:08:04,140
But it's also part of the reason why
Waymo has such a head start on everyone

138
00:08:04,141 --> 00:08:04,830
because they,

139
00:08:04,830 --> 00:08:08,880
they've been doing this a long time and
they've accumulated a lot of experience.

140
00:08:10,270 --> 00:08:14,080
I was curious, you know, as far as
reducing the fatality rate, I checked,

141
00:08:14,081 --> 00:08:15,940
it sounds like,
um,

142
00:08:16,390 --> 00:08:21,390
there's little over one fatality per
hundred million miles driven or something.

143
00:08:22,890 --> 00:08:26,140
So to get a sense on whether really safer,

144
00:08:26,170 --> 00:08:28,240
does that mean we need to get
a few hundred million miles?

145
00:08:28,720 --> 00:08:31,230
These cars you have have two or,

146
00:08:32,190 --> 00:08:37,190
and I would say an supplement that
with AI and machine learning and great

147
00:08:37,201 --> 00:08:39,930
simulation models.
So you know,

148
00:08:39,931 --> 00:08:42,420
this isn't about any one sensor.

149
00:08:42,510 --> 00:08:47,250
It's not about anyone enabling technology.
It's this combination of maps,

150
00:08:47,850 --> 00:08:50,460
sensors,
onboard processor of software,

151
00:08:50,640 --> 00:08:54,960
and then in the development process to
be able to go out there and capture a lot

152
00:08:54,961 --> 00:08:57,390
of, when you encounter
something unusual on the road,

153
00:08:57,391 --> 00:09:02,391
bring that back to the lab and simulate
it virtually simulate it in reality and

154
00:09:03,900 --> 00:09:07,200
learn about the edge cases and
get confident that you've dealt,

155
00:09:07,201 --> 00:09:11,280
not just with the unusual thing that
you observed. So take traffic circles,

156
00:09:11,281 --> 00:09:15,210
for example. We've all, you've all
probably been in a traffic circle.

157
00:09:15,540 --> 00:09:19,490
Have you been in two lane traffic circles
or three lane traffic circles and do

158
00:09:19,491 --> 00:09:23,970
you have to capture everything about all
of those in the real world or can you

159
00:09:23,971 --> 00:09:27,630
model that and get to the edge
cases and move yourself forward?

160
00:09:27,850 --> 00:09:31,420
Yeah, I hadn't thought about that. So
it's a part of it is real world driving.

161
00:09:31,421 --> 00:09:35,740
Part of it is taking the data you've
collected from strives and simulating and

162
00:09:35,741 --> 00:09:38,260
that gets us closer to
those hundred millions.

163
00:09:38,350 --> 00:09:42,160
So, so you say, why am I my,
my Google get into this? Um,

164
00:09:42,810 --> 00:09:44,350
I think because we're not a car company,

165
00:09:44,351 --> 00:09:49,050
but extraordinary deep knowledge
of computer science, uh,

166
00:09:49,120 --> 00:09:53,710
and um, and robotics, you know,
the best surfers in the world,

167
00:09:53,711 --> 00:09:57,250
the best mapping system in the world,
great AI teams,

168
00:09:57,610 --> 00:10:00,280
and it's really a shift,
fundamental shift.

169
00:10:00,281 --> 00:10:04,270
And what are the core
competencies required to be a
leader and transportation in

170
00:10:04,271 --> 00:10:07,720
the future versus the historic
once in the historic ones,

171
00:10:07,721 --> 00:10:09,340
which recover quite a bit on the book.

172
00:10:09,880 --> 00:10:14,880
Really like 130 years of
history of combustion based
vehicles that are energized

173
00:10:16,361 --> 00:10:21,010
by oil that are human controlled
with the controls being hydraulic and

174
00:10:21,100 --> 00:10:22,690
electronic primarily.

175
00:10:22,720 --> 00:10:27,720
And those competencies were
about combustion and the
driver interface to get the

176
00:10:28,961 --> 00:10:30,310
ultimate driving machine.

177
00:10:30,760 --> 00:10:33,700
And we're going to have in the future
of the ultimate writing machines,

178
00:10:33,701 --> 00:10:35,080
not the ultimate driving machine.

179
00:10:35,081 --> 00:10:40,081
So this is a profound shift and the
fundamental competencies to be a leader in

180
00:10:40,811 --> 00:10:41,680
transportation.

181
00:10:41,890 --> 00:10:43,920
Yeah, yeah. I think you, you know,

182
00:10:43,930 --> 00:10:47,260
you sort of explained that there are
three trends that are coming together,

183
00:10:47,261 --> 00:10:52,250
right? There's the, the software
and the driverless technology, um,

184
00:10:52,390 --> 00:10:55,650
and there's electric vehicles
which have some advantages.

185
00:10:55,820 --> 00:10:59,290
They're much easier for software
to control then all mechanical one.

186
00:10:59,291 --> 00:11:04,120
And then there's this idea of
transportation as a service rather than,

187
00:11:04,140 --> 00:11:05,410
you know,
personal ownership.

188
00:11:05,411 --> 00:11:08,920
And those are like the three factors
that are all coming together.

189
00:11:09,010 --> 00:11:10,690
Yeah. Yeah. They bought come together.

190
00:11:10,691 --> 00:11:14,440
Two of them are really technology enabled
on the other one has a business model

191
00:11:14,510 --> 00:11:17,800
innovation. So again,
it's not about one thing,

192
00:11:17,801 --> 00:11:20,740
it's about several things
combining at the same time.

193
00:11:20,741 --> 00:11:23,920
I'd like to call that the power of
an that's the connecting of the dots.

194
00:11:24,340 --> 00:11:28,330
And here's Kinda how this, this logic
goes. When you have an autonomous vehicle,

195
00:11:29,620 --> 00:11:34,450
suddenly you don't need to pay a person
to drive the vehicle and reposition it.

196
00:11:35,200 --> 00:11:39,760
And um, that makes selling
transportation as a service,

197
00:11:39,761 --> 00:11:43,870
a pretty compelling opportunity because
you've lowered the cost then of getting

198
00:11:43,871 --> 00:11:46,960
high utilization out of the vehicle.
So it can pick me up,

199
00:11:47,380 --> 00:11:51,130
take me to my destination, dropped me
off, and then without any labor costs,

200
00:11:51,820 --> 00:11:55,780
go a couple blocks and pick up and take
you to your destination or drop you off

201
00:11:55,781 --> 00:11:56,950
and keep doing that throughout the day.

202
00:11:56,950 --> 00:12:00,460
And you get very high utilization
of that fleet. Uh, today,

203
00:12:00,461 --> 00:12:02,810
most cars are used about
12,000 miles a year,

204
00:12:02,811 --> 00:12:06,850
or these transportation service business
model suggested would be 75,000 miles a

205
00:12:06,851 --> 00:12:10,870
year.
The cars are parked 90 to 95% of the time.

206
00:12:11,140 --> 00:12:14,680
What I just described means the vehicle
is in route to pick you up rather than

207
00:12:14,681 --> 00:12:16,510
being parked,
but what you,

208
00:12:16,540 --> 00:12:20,740
what you do then is because it's
autonomous and it's a service you want to

209
00:12:20,800 --> 00:12:22,570
optimize the cost per mile.

210
00:12:22,990 --> 00:12:27,100
The car industry has been focused on
optimizing the price of a new car at a

211
00:12:27,101 --> 00:12:30,040
dealership when you go there and
fall in love with it to buy it.

212
00:12:30,520 --> 00:12:32,110
When you optimize the cost per mile,

213
00:12:32,111 --> 00:12:37,111
it turns out electric drive is a really
good deal because of fleet optimized

214
00:12:37,541 --> 00:12:38,374
costs per mile.

215
00:12:38,380 --> 00:12:42,460
You want the vehicle last about 300,000
miles and electric drive can save you

216
00:12:42,461 --> 00:12:43,930
five to 10 cents a mile.

217
00:12:44,230 --> 00:12:47,560
That's 15,000 to $30,000
over the lifetime,

218
00:12:47,561 --> 00:12:51,670
which is more than enough to pay
for the electric drive still.

219
00:12:51,671 --> 00:12:54,400
The funny thing about this
is it's autonomous vehicles.

220
00:12:54,401 --> 00:12:58,390
I think that's going to get us past the
tipping point for electric vehicles,

221
00:12:58,420 --> 00:13:00,250
not to make this story even better.

222
00:13:00,970 --> 00:13:04,990
80% of the trips we make as Americans
are one and two person trips,

223
00:13:05,020 --> 00:13:05,860
but our cars aren't.

224
00:13:05,880 --> 00:13:09,670
Trucks are designed way over
designed for the occasional trip.

225
00:13:10,180 --> 00:13:13,510
When you tailor designed this
autonomous electric vehicle for this

226
00:13:13,511 --> 00:13:16,330
transportation service and
the most typical trips,

227
00:13:17,110 --> 00:13:21,940
it probably wants to be a two
person vehicle is probably
going to have about one

228
00:13:21,941 --> 00:13:24,550
10th as many parts in it
as a conventional car.

229
00:13:25,210 --> 00:13:29,620
And that is really important to
understand if you're in the car industry.

230
00:13:29,780 --> 00:13:33,550
So it's, it's, it's the
simplicity of electric drive.
You don't have transmissions,

231
00:13:33,551 --> 00:13:36,220
you don't have exhaust systems,
you have gasoline tanks,

232
00:13:36,221 --> 00:13:39,580
you don't have all those mechanical parts
in the engine moving and you get rid

233
00:13:39,581 --> 00:13:43,840
of all the parts with a driver interface.
So boom, it's really transformational.

234
00:13:44,680 --> 00:13:47,570
One of the stories that actually it
was one of my favorite in the book,

235
00:13:47,920 --> 00:13:49,610
I think it was when,
uh,

236
00:13:49,640 --> 00:13:53,570
Byron Mccormick brought you out to
the vehicle assessment center and he,

237
00:13:53,571 --> 00:13:53,751
you know,

238
00:13:53,751 --> 00:13:57,200
he sort of showed you that maybe you want
to describe what that was like. Yeah,

239
00:13:57,350 --> 00:13:59,390
yeah. Um, and in 1988,

240
00:13:59,391 --> 00:14:04,391
I was asked to lead an initiative at
GM called design for manufacturing and,

241
00:14:04,670 --> 00:14:05,331
um,
you know,

242
00:14:05,331 --> 00:14:09,710
we had a lot of different products and
our cars just seem like they were harder

243
00:14:09,711 --> 00:14:11,600
to put together than our competitors.

244
00:14:11,601 --> 00:14:14,690
And so we decided to tear
apart or competitors, cars,

245
00:14:15,100 --> 00:14:19,730
lay out all the parts and then conceive
of how they're building their cars.

246
00:14:19,731 --> 00:14:22,790
And Lo and behold,
we were way a uncompetitive.

247
00:14:23,300 --> 00:14:26,960
So this tear down sooner
became an important place
for a lot of the leaders at

248
00:14:26,980 --> 00:14:31,980
GMB begin to visualize what was going
on by Ren Maccormack who reported to me

249
00:14:32,211 --> 00:14:36,850
was one of the best technologists
I've ever worked with. He had, uh, uh,

250
00:14:37,100 --> 00:14:39,860
ran the battery plant for GMC [inaudible].

251
00:14:39,920 --> 00:14:44,460
He was one of the pioneers of what's
now called stability control. Um,

252
00:14:44,510 --> 00:14:47,300
but very importantly he led
our fuel cell program as well.

253
00:14:47,750 --> 00:14:52,290
And Byron and his team conceived of what
we call a vehicle called [inaudible]

254
00:14:52,310 --> 00:14:56,900
flux, which was based on these principles
of electric motors in the wheels,

255
00:14:56,901 --> 00:15:00,560
energy storage and the platform,
almost like a skateboard.

256
00:15:01,010 --> 00:15:05,060
And then by wire steering,
by wire breaking and really
optimized around software.

257
00:15:05,600 --> 00:15:09,980
And you went ahead and prototyped that
and laid out all the parts in a torn down

258
00:15:09,981 --> 00:15:10,814
way,

259
00:15:10,940 --> 00:15:15,940
in the same place where he took apart a
Chevy Malibu and they took about a Prius

260
00:15:16,071 --> 00:15:17,840
and lay those parts out with a Prius,

261
00:15:17,841 --> 00:15:19,970
had more parts than a Malibu
cause it was a hybrid.

262
00:15:20,570 --> 00:15:22,790
But the flex have radically fewer,

263
00:15:22,820 --> 00:15:26,960
I mean you could really see where the
industry was going to had when it was

264
00:15:26,961 --> 00:15:29,660
going to be an electrical and
electronically controlled.

265
00:15:30,170 --> 00:15:34,220
So we brought my boss Rick Wagner and
who is the chairman and CEO of GM.

266
00:15:34,400 --> 00:15:36,230
He had to see this and he,
he got it.

267
00:15:36,231 --> 00:15:40,490
He understood it wasn't just all the fewer
parts because the parts that you have

268
00:15:40,491 --> 00:15:42,860
to design,
engineer released manufacturer tool,

269
00:15:42,861 --> 00:15:45,110
they drive the cost
structure of a car company,

270
00:15:45,530 --> 00:15:49,550
but it was also was the software
and that was just so important.

271
00:15:49,551 --> 00:15:53,210
And it's I think a lesson out of that as
when you have an idea and you're trying

272
00:15:53,211 --> 00:15:54,110
to communicate it,

273
00:15:54,111 --> 00:15:58,760
getting to rapid prototyping and making
it visible for a lot of people I think

274
00:15:58,761 --> 00:16:00,590
really helps get your idea communicated.

275
00:16:00,940 --> 00:16:04,240
Yeah. Yeah. I love, I love the
visual of seeing, you know, the,

276
00:16:04,530 --> 00:16:08,030
the car exploded and all the
parts of the Malibu and then, uh,

277
00:16:08,340 --> 00:16:10,880
the electric vehicle with
radically fewer parts.

278
00:16:10,890 --> 00:16:15,390
That's just a great way
to get your point across.

279
00:16:16,080 --> 00:16:20,210
Um, that, uh, one of the other things I
found fascinating and I said, you know,

280
00:16:20,260 --> 00:16:23,670
it sounds like maybe 2010,
2011,

281
00:16:23,671 --> 00:16:27,180
I think you were at Columbia and you
were kind of modeling how this would work

282
00:16:27,181 --> 00:16:30,710
and I think you picked Ann Arbor and a
few other cities and found that, you know,

283
00:16:30,870 --> 00:16:35,870
like you can offer this
service with actually not
that many cars relative to the

284
00:16:36,151 --> 00:16:37,980
number of cars that people actually,
you know,

285
00:16:37,981 --> 00:16:40,140
park in their driveways in Ann Arbor.

286
00:16:40,640 --> 00:16:40,881
Yeah.

287
00:16:40,881 --> 00:16:45,410
There was a famous economics professor
at Columbia named Jeff Sachs and he had

288
00:16:45,411 --> 00:16:49,820
written the book end of poverty and he
was running an institute called the Earth

289
00:16:49,820 --> 00:16:53,940
Institute. And when GM was going
bankrupt, he came and visited us. And um,

290
00:16:54,050 --> 00:16:57,680
I gave him an overview of some of the
thinking we have longer term and Jeff and

291
00:16:57,681 --> 00:17:01,850
I hit it off and when I left GM he asked
me if I would leave Columbia's program

292
00:17:01,851 --> 00:17:04,970
for a sustainable mobility,
which, which I decided to do.

293
00:17:05,390 --> 00:17:09,050
And what we were really interested in is,
no kidding.

294
00:17:10,220 --> 00:17:15,220
What would city looked
like if you combined tailor
designed vehicles for the two

295
00:17:16,821 --> 00:17:17,654
person,

296
00:17:17,720 --> 00:17:21,830
one person trip with electric drive that
are autonomous and importantly shared,

297
00:17:22,430 --> 00:17:26,420
how many would you need to meet all the
transportation requirements of a city

298
00:17:26,960 --> 00:17:28,610
and how much would it cost?

299
00:17:28,860 --> 00:17:32,480
And so we decided to model this and
at that time there was a really neat

300
00:17:32,481 --> 00:17:37,310
database. It was a 2009 a household travel
surveys from the federal government.

301
00:17:37,520 --> 00:17:41,870
And it gave us a good idea of how many
cars were in cities like Anarbor Austin

302
00:17:41,871 --> 00:17:46,530
or Columbus, Ohio, Rochester,
New York, Manhattan, uh,

303
00:17:46,580 --> 00:17:51,390
Palm Beach County, Florida. So we
sat down and started to model this.

304
00:17:51,780 --> 00:17:55,140
And um,
there were 200,000 cars in Anarbor,

305
00:17:55,141 --> 00:17:58,830
about 120,000 of them stayed
within the metropolitan area.

306
00:17:59,520 --> 00:18:03,210
And our modeling came back and said we
could get all of the trips that those

307
00:18:03,211 --> 00:18:08,130
cars are making done with 15,
18,000 shared vehicles,

308
00:18:08,670 --> 00:18:11,760
just 15% of the cars that were there.

309
00:18:12,360 --> 00:18:16,350
We thought we had to be wrong because at
the same time we concluded we could get

310
00:18:16,351 --> 00:18:18,450
to the customers quickly within minutes.

311
00:18:18,870 --> 00:18:21,930
And that the fleet would be highly
utilized. And we kept studying this,

312
00:18:21,931 --> 00:18:23,730
convinced we didn't have it right,

313
00:18:24,240 --> 00:18:27,780
but finally we understood the population
density of places like Ann Arbor was

314
00:18:27,781 --> 00:18:32,700
high enough such that the trip frequency
throughout the 14 busy hours of the day

315
00:18:32,701 --> 00:18:36,630
was high enough such that just after
they'd drop me off somewhere in Anarbor.

316
00:18:37,020 --> 00:18:40,650
Sure enough there was a high probability
someone a couple blocks away was

317
00:18:40,651 --> 00:18:44,510
requesting a ride. And that's
how the math worked out and that,

318
00:18:44,580 --> 00:18:48,780
that was the moment. And then when we
said what would this cost, you know,

319
00:18:48,781 --> 00:18:51,570
the electricity costs, the
insurance, the cost of the vehicle,

320
00:18:51,571 --> 00:18:54,450
d being depreciated finance costs,

321
00:18:54,451 --> 00:18:56,700
both your time cost and
out of pocket costs.

322
00:18:57,210 --> 00:19:00,360
We thought we could get to something
on the order of 20 cents a mile.

323
00:19:00,390 --> 00:19:05,390
And that's compared to
owning and operating a card
about a dollar 50 including

324
00:19:05,521 --> 00:19:07,740
your time cost.
So you,

325
00:19:07,741 --> 00:19:11,820
but you bounced that against
the 3 trillion miles a
year that Americans drive.

326
00:19:11,821 --> 00:19:16,580
And that's a $4 trillion disruption.
And that, that was a pretty big Aha.

327
00:19:17,100 --> 00:19:20,670
And we went about getting that
story told and it was a lot of fun.

328
00:19:20,910 --> 00:19:21,743
Yeah.
Yeah.

329
00:19:21,830 --> 00:19:26,830
And so how much did that for four and a
half trillion dollars is spent on fossil

330
00:19:28,001 --> 00:19:28,834
fuels?

331
00:19:29,330 --> 00:19:31,300
Well, um, uh, it's,

332
00:19:31,580 --> 00:19:36,230
we use about 180 billion gallons
of gasoline a year. So, you know,

333
00:19:36,720 --> 00:19:40,040
three bucks, I'd say
about a 500, 500 billion.

334
00:19:40,230 --> 00:19:44,790
Yeah. Yeah. So, you
know, if this works out,

335
00:19:44,791 --> 00:19:46,200
it's going to really significantly.

336
00:19:46,460 --> 00:19:50,840
Very significantly. Yeah. And an
interesting irony is sad irony about that.

337
00:19:50,841 --> 00:19:54,630
As the year General Motors went bankrupt,
um,

338
00:19:55,550 --> 00:19:58,310
embarrassingly we lost $32 billion.

339
00:19:58,840 --> 00:20:02,360
Exxon Mobil may $45 billion that year.

340
00:20:02,420 --> 00:20:07,190
Oil prices has gone to a
dollar 60 a barrel. I'm sorry,

341
00:20:07,191 --> 00:20:12,020
I'm sorry, $160 a barrel and come
to 160 and they made $45 billion.

342
00:20:12,021 --> 00:20:15,230
That was the highest profit ever made
by a company at that point in time.

343
00:20:15,950 --> 00:20:20,270
And the sad thing about that oil
consumption is when you refine it to make

344
00:20:20,271 --> 00:20:23,720
gasoline and you burn it
in a combustion engine,

345
00:20:23,810 --> 00:20:27,280
about 75% of that energy is 70.

346
00:20:27,320 --> 00:20:29,120
Let's say 75 to 80%,

347
00:20:29,450 --> 00:20:33,800
it gets lost as heat and friction
and sound, that kind of a thing.

348
00:20:34,250 --> 00:20:39,050
So about 20 to 30% crates torque
that turns the wheels of the car,

349
00:20:39,590 --> 00:20:44,360
the car's way, three to 4,000 pounds and
people were, you know, 120 to 200 pounds,

350
00:20:44,660 --> 00:20:45,021
Jeremy.

351
00:20:45,021 --> 00:20:48,970
The bottom line is just one to 2% of
the energy and that gallon of gasoline

352
00:20:48,971 --> 00:20:50,140
moves you the driver.

353
00:20:50,980 --> 00:20:54,250
And here's this company
that makes $45 billion. Uh,

354
00:20:54,430 --> 00:20:56,530
and the only way Exxon
Exxonmobil could have done that.

355
00:20:56,531 --> 00:21:00,550
That's because GM was in the business
of building and selling cars that relied

356
00:21:00,551 --> 00:21:01,290
on oil.

357
00:21:01,290 --> 00:21:03,240
Yeah, yeah. That's a,

358
00:21:04,120 --> 00:21:06,370
it's a disruption in a lot of ways.

359
00:21:06,480 --> 00:21:08,190
Well, it's a huge, it's a huge disruption.

360
00:21:08,191 --> 00:21:12,310
It's a disruption to the people
who drive for a living and,

361
00:21:12,440 --> 00:21:15,540
and uh,
I understand that and I respect that.

362
00:21:15,541 --> 00:21:18,000
If my professional was
being disrupted by this,

363
00:21:18,001 --> 00:21:21,360
I don't think I would feel
comfortable about that. But,

364
00:21:21,361 --> 00:21:24,900
and also it's a disruption to the auto
industry because far fewer parts mean far

365
00:21:24,901 --> 00:21:28,620
fewer employees, um, in the supply base.

366
00:21:28,740 --> 00:21:32,430
And at the original equipment
manufacturer and base,

367
00:21:32,431 --> 00:21:35,790
but also far fewer engineers cause
you have to design fewer parts.

368
00:21:36,240 --> 00:21:40,500
It's a disruption to the
corner gas station operator
because these vehicles will

369
00:21:40,501 --> 00:21:43,260
be supplied probably through fleets.
By the way,

370
00:21:43,261 --> 00:21:45,150
you could have one for your dedicated use.

371
00:21:45,151 --> 00:21:49,590
Please don't think the only solution
here is a shared vehicle like an Uber

372
00:21:49,591 --> 00:21:50,430
without our driver.

373
00:21:50,431 --> 00:21:54,300
You certainly can subscribe to one and
have it for your own personal dispatch

374
00:21:54,510 --> 00:21:58,440
desires. But at the end of the day, you're
not going to want to stop to refuel it,

375
00:21:58,441 --> 00:21:59,340
a recharge it.

376
00:21:59,430 --> 00:22:03,030
So this recharging is going to be done
at a depot and out of the corner gas

377
00:22:03,031 --> 00:22:03,331
station.

378
00:22:03,331 --> 00:22:07,440
And the beauty of that is that lets us
introduce alternatives to oil without

379
00:22:07,441 --> 00:22:09,750
having to have 170,000 gas stations.

380
00:22:10,230 --> 00:22:13,230
So you pull that string
parking gets impacted,

381
00:22:14,000 --> 00:22:18,060
dealers get impacted, land, juice
and real estate gets impacted.

382
00:22:18,120 --> 00:22:20,580
The entire economy gets
impacted quite frankly.

383
00:22:21,480 --> 00:22:23,700
Yeah, it's uh, it's,

384
00:22:24,140 --> 00:22:28,440
it's fascinating to sort of enter
into that analysis in the book.

385
00:22:28,770 --> 00:22:32,180
I was also thinking we're
here in New York City. Uh,

386
00:22:32,370 --> 00:22:37,370
so I think the recent news is that the
city is considering putting a limit on

387
00:22:37,531 --> 00:22:42,000
the number of Uber and Lyft
drivers. Uh, and, and sort of,

388
00:22:42,001 --> 00:22:42,631
I'm like,

389
00:22:42,631 --> 00:22:46,380
I wonder what your take on that sort
of policy issue in the short term is,

390
00:22:46,381 --> 00:22:47,214
you know what?

391
00:22:47,750 --> 00:22:50,380
Well, I, you know, I, I believe, um,

392
00:22:51,470 --> 00:22:54,710
it's an important issue because you have
an awful lot of people out there trying

393
00:22:54,711 --> 00:22:55,790
to make money as a,

394
00:22:55,791 --> 00:23:00,590
as an Uber driver and there needs to be
this balance between supply and demand.

395
00:23:01,010 --> 00:23:05,510
And if you have too many people out there
and not enough customers are going to

396
00:23:05,511 --> 00:23:09,380
have more cars on the road, not really
creating value. So that's problematic.

397
00:23:09,860 --> 00:23:13,850
I do worry about governments thinking
they can regulate that rather than the

398
00:23:13,851 --> 00:23:18,140
market finding that right balance.
So I am concerned about that.

399
00:23:18,590 --> 00:23:21,140
When you do get to driverless cars,
um,

400
00:23:21,240 --> 00:23:25,010
your whole goal will be to have high
fleet utilization because that's key to

401
00:23:25,011 --> 00:23:25,844
making money.

402
00:23:26,120 --> 00:23:29,480
You're going to optimize the size
of your fleet so that you have high

403
00:23:29,481 --> 00:23:34,430
utilization, low empty miles and
fast response times. And, um,

404
00:23:34,431 --> 00:23:38,420
so I don't think that carries over to
the driverless discussion. Fortunately,

405
00:23:38,421 --> 00:23:43,421
the regulators at the local state and
federal level for driverless cars have

406
00:23:45,620 --> 00:23:45,801
that.

407
00:23:45,801 --> 00:23:50,600
The only way we're going to get to this
goal of fully driverless is to learn on

408
00:23:50,601 --> 00:23:54,650
public roads. So they haven't stepped
up and said, you can't do this.

409
00:23:54,800 --> 00:23:58,310
And that's by the way, that's
a big difference between
general motors and Google.

410
00:23:58,730 --> 00:24:01,940
Um, uh, Sebastian Thrun and
Chris Urmson in their team,

411
00:24:02,390 --> 00:24:06,200
when they started their project,
they wanted to learn on public roads.

412
00:24:06,201 --> 00:24:10,340
And so they wondered if they could do
it in the law in California said you

413
00:24:10,341 --> 00:24:12,050
needed to have a driver
in the driver's seat.

414
00:24:12,051 --> 00:24:14,330
It didn't say you needed to
touch the steering wheel,

415
00:24:14,540 --> 00:24:17,630
the brake feller or the accelerator.
So they just went off and did it.

416
00:24:18,000 --> 00:24:22,250
My General Council term owners would
say, no way, you can only test in a,

417
00:24:22,400 --> 00:24:27,050
in a proving ground. So they had
to get on public roads and this,

418
00:24:27,051 --> 00:24:28,160
this is a technology,

419
00:24:28,161 --> 00:24:31,490
you think about that you eliminate
90% of the crashes in the world.

420
00:24:31,820 --> 00:24:36,530
There's 1.3 million people a year dying
on the world's roadways that is epidemic

421
00:24:36,531 --> 00:24:40,460
and scale. Get rid of 90% of that.
That's a million lives a year.

422
00:24:40,850 --> 00:24:44,510
Divide that by 365.
That's 3000 lives a day.

423
00:24:44,511 --> 00:24:47,870
If we get to this end goal one day sooner,

424
00:24:48,140 --> 00:24:49,970
we're going to save 3000 lives.

425
00:24:50,390 --> 00:24:53,960
So I think the biggest risk is not
moving fast enough and the regulators

426
00:24:54,290 --> 00:24:57,020
fortunately haven't said stop,

427
00:24:57,580 --> 00:25:01,490
haven't said you can't learn on public
roads and, and we're making good progress.

428
00:25:01,491 --> 00:25:06,080
We need to be open,
share the data and uh,

429
00:25:06,200 --> 00:25:09,360
learn together. But I think we'll take
the journey and we'll get there, Jeremy.

430
00:25:09,650 --> 00:25:10,360
I really do.

431
00:25:10,360 --> 00:25:14,910
Yeah. It reminds me of a, of
another funny story in the book. Um,

432
00:25:15,460 --> 00:25:19,570
I think from early on with the Carnegie
Mellon team that they were posting

433
00:25:19,571 --> 00:25:20,970
videos,
uh,

434
00:25:20,980 --> 00:25:25,840
on their blog of testing the
vehicle stopping and someone
somewhere on your team,

435
00:25:25,841 --> 00:25:27,940
a middle manager saw it and thought,
oh my God,

436
00:25:27,941 --> 00:25:31,120
I can't believe GM is funding this.
We got to put an end to it.

437
00:25:31,220 --> 00:25:33,020
Yeah. Very, very different cultures. We,

438
00:25:33,320 --> 00:25:37,220
we had a sad stretch in the late
eighties and early nineties of too many

439
00:25:37,221 --> 00:25:40,580
fatalities in our plants.
These were our employees.

440
00:25:41,030 --> 00:25:45,000
Maybe they had to do maintenance on
a robot and they didn't lock, lock,

441
00:25:45,170 --> 00:25:49,100
lock out the robot and they got in there
and gotten electrocuted or something.

442
00:25:49,101 --> 00:25:52,670
So we said, enough is enough. So we went
and benchmark the best in the world,

443
00:25:53,000 --> 00:25:57,650
I'll call dupont. And we wanted to be the
benchmark, safest company to work for.

444
00:25:57,651 --> 00:26:02,540
So safety was really ingrained
into everybody at GM. So
in this individual who,

445
00:26:02,541 --> 00:26:07,010
who reported to me, so how our Carnegie
Mellon's team was just in the vehicles.

446
00:26:07,011 --> 00:26:12,011
He felt it was way outside the
envelope on our safety culture and um,

447
00:26:12,390 --> 00:26:15,140
felt we needed to shut down the program.
We worked through that.

448
00:26:15,141 --> 00:26:18,730
Chris Urmson did a good job
with some diplomacy and a,

449
00:26:18,770 --> 00:26:23,770
but really I can't overemphasize that
safety has to be the overriding priority

450
00:26:23,871 --> 00:26:25,810
for, for any organization. And,

451
00:26:25,811 --> 00:26:30,590
and I so admire what the Google self
driving car team has accomplished and

452
00:26:30,591 --> 00:26:34,430
they've done it with a tremendous
safety culture. They've got this group,

453
00:26:34,431 --> 00:26:35,960
we call it the ops group.

454
00:26:36,020 --> 00:26:40,130
And the every morning they
shake down all of the cars,

455
00:26:40,670 --> 00:26:44,100
make sure the curves physically
ready to go out on the road,

456
00:26:45,000 --> 00:26:47,040
put their cell phones in their locker,

457
00:26:47,070 --> 00:26:51,040
they go out and they're
highly trained people, um,

458
00:26:51,240 --> 00:26:54,480
following standardized
processes and they really,

459
00:26:54,481 --> 00:26:56,280
really take their job seriously.
Whenever,

460
00:26:56,400 --> 00:26:59,620
if I ever have a chance to be in
the area where they work, you,

461
00:26:59,621 --> 00:27:04,290
you almost feel like it's the same
discipline you would see and the military

462
00:27:04,291 --> 00:27:07,110
operations, it's that serious
and it's paid off for us.

463
00:27:07,111 --> 00:27:12,060
Waymo has had one APP for fault. Crash
was a two mile per hour fender bender.

464
00:27:12,390 --> 00:27:14,730
We've had some others and,
and all those other cases,

465
00:27:14,731 --> 00:27:17,490
it was the other driver with
the human driver that caused it.

466
00:27:18,930 --> 00:27:23,220
Yeah. I'm curious about
it. Like, yeah. What,

467
00:27:24,750 --> 00:27:26,660
what the limits of,
um,

468
00:27:27,240 --> 00:27:31,050
unexpected things you can plan for our,
um,

469
00:27:31,730 --> 00:27:36,690
uh, um, thinking to a story from
the urban mobility challenge.

470
00:27:36,691 --> 00:27:36,841
You know,

471
00:27:36,841 --> 00:27:41,480
what happens if you're a autonomous
vehicle pulls up next to the jumbo tron in

472
00:27:41,481 --> 00:27:41,740
that,

473
00:27:41,740 --> 00:27:46,000
yeah. Staples, the GPS. This
was one of these, these moments,

474
00:27:46,001 --> 00:27:50,200
the Carnegie Mellon and team, um,
had some challenges along the way.

475
00:27:50,201 --> 00:27:53,740
The first race was in the desert
and part of their development work,

476
00:27:53,741 --> 00:27:55,390
they rolled their homer,

477
00:27:55,391 --> 00:27:59,830
which was her development vehicle
over and that caused some problem with

478
00:27:59,831 --> 00:28:03,520
sensors. And we think that's why it only
went seven miles. And the second race,

479
00:28:03,521 --> 00:28:05,320
Lo and behold,
they have the same thing happened.

480
00:28:05,321 --> 00:28:07,000
They had two vehicles in that race,

481
00:28:07,420 --> 00:28:12,420
the one that really was probably the
best vehicle and had a, a fuel, um,

482
00:28:12,610 --> 00:28:17,290
or actually an electromagnetic
interference since we
found out later on damaged

483
00:28:17,291 --> 00:28:21,660
and it was causing strange
things with the fuel. And um,

484
00:28:22,120 --> 00:28:26,190
so the uh, lost my train of
thought. I can term it was okay.

485
00:28:26,860 --> 00:28:29,150
I was thinking about the and
then in the urban mobility.

486
00:28:29,260 --> 00:28:33,640
Oh yeah, yeah. And then in the
actual Darpa urban challenge,

487
00:28:34,010 --> 00:28:38,410
um, we were the favorite. We thought
we were going to win this race.

488
00:28:38,440 --> 00:28:43,440
We felt real good about all of our
tests and through the preliminary hates,

489
00:28:43,691 --> 00:28:47,800
they sorted down to 14 finalists
and we were in the pole position.

490
00:28:48,790 --> 00:28:53,790
And that meant we got to go out on the
track first and we couldn't get the gps

491
00:28:54,761 --> 00:28:59,590
to calibrate something just
wouldn't lock in. And um,

492
00:28:59,620 --> 00:29:04,620
everyone's panicking and they go to get
another GPS unit and it turns out ESPN

493
00:29:05,291 --> 00:29:10,270
was covering the event and they had a
huge jumbo tron located right next to our

494
00:29:10,271 --> 00:29:14,230
vehicle. And the person from the defense,
advanced research projects agency, Darpa,

495
00:29:14,231 --> 00:29:16,900
who sponsored at Tony Tether said,

496
00:29:17,110 --> 00:29:19,870
turn off the jumbo tron in
Cerner as they turned it off,

497
00:29:20,440 --> 00:29:25,030
gps calibrated and we were back
in the race. So yes, there are,

498
00:29:25,420 --> 00:29:27,490
those are learning things. Yeah. You know,

499
00:29:27,520 --> 00:29:32,050
I dedicate this book to engineers
who make what's possible real.

500
00:29:32,051 --> 00:29:36,010
How many of you here today or are
engineers or computer science or technical

501
00:29:36,011 --> 00:29:39,310
backgrounds? I mean, that's
really what we do. And,

502
00:29:39,330 --> 00:29:42,700
and I'm an engineer from the top of my,
to the tips of my toes.

503
00:29:42,701 --> 00:29:47,350
And as long as the principles
of science are followed,

504
00:29:47,800 --> 00:29:51,340
I think an engineer can accomplish almost
anything if you give them the right

505
00:29:51,341 --> 00:29:55,750
learning cycles. But who would have
thought we would've had this interference?

506
00:29:55,751 --> 00:29:59,800
But now we know. And, and
that's what this is all about.

507
00:29:59,830 --> 00:30:03,700
Learning way out on the tail of the
distribution on, on learning cycles.

508
00:30:04,120 --> 00:30:06,160
And that was one of those
great examples of learning.

509
00:30:09,210 --> 00:30:13,330
Great example of what's going to
go wrong in the real world when we

510
00:30:13,560 --> 00:30:16,800
yes, yes, things will go wrong
in the world, real world.

511
00:30:17,520 --> 00:30:22,100
Sadly they go wrong and kill 40,000
Americans a year right now. And um,

512
00:30:22,530 --> 00:30:24,600
I, I, I have to be really candid with you.

513
00:30:24,601 --> 00:30:28,800
Every time I read about someone going
in the wrong way on the interstate and

514
00:30:28,801 --> 00:30:32,220
having a head on killing four or five
people and just breaks my heart because I

515
00:30:32,221 --> 00:30:35,400
know the technology
exists to prevent that.

516
00:30:35,401 --> 00:30:40,050
And my daughters are 30 and 27 so I took
them through a driver's training and it

517
00:30:40,051 --> 00:30:44,520
was an absolute nightmare to see
an inexperienced driver. I mean,

518
00:30:44,521 --> 00:30:47,340
next time you do go through dry
through a busy intersection,

519
00:30:48,420 --> 00:30:49,620
you're an experienced driver.

520
00:30:49,621 --> 00:30:54,621
Think of what you're sorting out all of
the visual clutter that's there and what

521
00:30:54,901 --> 00:30:57,930
you really have to pay attention to to
get through that intersection safely.

522
00:30:57,931 --> 00:31:01,410
And now you take a 15 year old
kid who has never done it before.

523
00:31:01,770 --> 00:31:06,600
It's learning curve. Jeremy and W
we've got to do better than this.

524
00:31:06,601 --> 00:31:09,210
We absolutely have to do
better than those fatalities.

525
00:31:09,590 --> 00:31:14,200
Yeah, yeah. I did like the,

526
00:31:14,260 --> 00:31:19,090
the way you can contrast the sort of
the engineering cultures in Detroit and

527
00:31:19,091 --> 00:31:21,060
Silicon Valley through the book and they,
you know,

528
00:31:21,070 --> 00:31:23,440
and they each have their
strengths. And I think you, uh,

529
00:31:23,620 --> 00:31:27,970
I'm pretty sympathetic to the, uh, the
Google software engineering culture,

530
00:31:27,971 --> 00:31:30,790
but you pointed out how, um, you know,

531
00:31:31,000 --> 00:31:33,220
maybe some of the Googlers
needed to come to terms with it.

532
00:31:33,221 --> 00:31:34,950
The thing is Detroit is good at too.

533
00:31:35,220 --> 00:31:36,053
Yeah.
Yeah.

534
00:31:37,950 --> 00:31:42,330
The original title of the book was
the race to build the driver's car.

535
00:31:43,230 --> 00:31:48,090
And um, uh, Alco who's our publisher or
the Dcis, who's the editor of surgeries,

536
00:31:48,150 --> 00:31:52,290
he made one raise her hand, but she said,
maybe you are right at about the quest.

537
00:31:52,560 --> 00:31:56,700
And that was really an important moment
for myself and Chris Shogun because

538
00:31:56,701 --> 00:32:01,530
suddenly we realized, you know, maybe
this isn't silicon valley versus Detroit.

539
00:32:01,560 --> 00:32:06,520
Maybe it's a bigger story than that.
Early on when I first arrived as the,

540
00:32:06,550 --> 00:32:11,310
the gray haired executive
at Google self driving cars,

541
00:32:11,311 --> 00:32:12,150
there was,
um,

542
00:32:12,210 --> 00:32:16,320
I would say an arrogance and the team
about Silicon Valley being able to handle

543
00:32:16,321 --> 00:32:20,940
these great world challenges at light
speed and the auto industry had lost its

544
00:32:20,941 --> 00:32:25,290
way on innovation and really,
really was no longer imaginative.

545
00:32:25,291 --> 00:32:27,970
It's the same time when
Chris Urmson and Anthony's,

546
00:32:27,990 --> 00:32:32,610
I've endoscopy first went to Detroit
looking for car companies and suppliers to

547
00:32:32,611 --> 00:32:35,490
collaborate with.
They basically threw them out the door,

548
00:32:36,060 --> 00:32:39,030
thought they were irresponsible with
developing cars on public roads.

549
00:32:39,110 --> 00:32:43,550
There's this tension between the silicon
valley culture and the Detroit culture

550
00:32:44,000 --> 00:32:47,780
where the story stands now where
this quest stands now it's an end.

551
00:32:47,781 --> 00:32:52,430
It's not an or. Um, I think by hiring
John Craft Chuck to lead Waymo,

552
00:32:52,460 --> 00:32:56,960
it was a recognition by
alphabets leadership that
they needed somebody with a

553
00:32:56,961 --> 00:33:00,580
lot of car experience to take this
forward and commercialize it. And,

554
00:33:00,970 --> 00:33:04,940
and John was really, really
deepened his car experience. And at,

555
00:33:04,941 --> 00:33:06,230
at at the same time,

556
00:33:06,231 --> 00:33:09,530
I think Ford and General Motors realize
that they're going to have to reach out

557
00:33:09,531 --> 00:33:13,910
to silicon valley to outsource that our
research and development and autonomous

558
00:33:13,911 --> 00:33:14,711
vehicle system.

559
00:33:14,711 --> 00:33:19,711
So GM acquired cruise automation and
then Argo AI was acquired by Ford.

560
00:33:20,990 --> 00:33:22,580
So they've come together.

561
00:33:22,640 --> 00:33:25,790
It's a Silicon Valley and Detroit
that will lead this forward.

562
00:33:26,400 --> 00:33:28,240
Yeah,
quite fascinating.

563
00:33:28,241 --> 00:33:32,860
I think another thing that kind of move
the story along with some, you know,

564
00:33:32,861 --> 00:33:36,910
some combination of visionaries and,
and um,

565
00:33:37,090 --> 00:33:39,250
and setting really audacious goals,
right?

566
00:33:39,251 --> 00:33:43,870
These challenges both Darpa's
challenges and then, uh, uh, you know,

567
00:33:43,871 --> 00:33:48,340
I guess Larry and Sergei
setting challenges with
Sebastian Thrun and others,

568
00:33:48,341 --> 00:33:51,160
you know, like what, what
can you make happen here?

569
00:33:51,900 --> 00:33:54,870
That's a great management principles,
setting stretch goals.

570
00:33:54,871 --> 00:33:58,240
And when you're the person who has
to reach the stretch, stretch goal,

571
00:33:58,241 --> 00:34:01,830
sometimes it can be a little bit
frightening, but think about it this way.

572
00:34:01,831 --> 00:34:05,210
You could say your, um, you,

573
00:34:05,240 --> 00:34:09,780
you want to accomplish something
on a scale of 10 and um,

574
00:34:09,870 --> 00:34:11,430
you can set your,

575
00:34:11,610 --> 00:34:15,690
your goal is six and get to
seven and feel good about it.

576
00:34:16,200 --> 00:34:20,670
Or You could have set your goal at nine
and get the eight and not get there.

577
00:34:21,420 --> 00:34:25,530
You'd rather be at eight than seven.
So stretch goal is an important principle.

578
00:34:26,070 --> 00:34:28,590
The defense, advanced research
projects, agency, Darpa,

579
00:34:28,591 --> 00:34:32,420
set stretch goals for the desert
challenge, which of which were two.

580
00:34:32,490 --> 00:34:36,660
And then the goal for the urban challenge
with 60 miles in a city setting with

581
00:34:36,661 --> 00:34:38,640
no one in the car,
no remote control,

582
00:34:38,850 --> 00:34:43,530
obey all traffic laws and get it done
in six hours and nobody thought it could

583
00:34:43,531 --> 00:34:47,070
be done.
So the Darpa challenge ends,

584
00:34:47,190 --> 00:34:50,910
everybody's feeling great about it.
Tony Tether, the head of Darpa says,

585
00:34:50,911 --> 00:34:53,610
mission accomplished.
Your guys have proven this can be done.

586
00:34:53,850 --> 00:34:56,010
It's up to the commercial
sector to run with it.

587
00:34:56,460 --> 00:35:00,090
And we all thought people would be falling
all over themselves wanting to take

588
00:35:00,091 --> 00:35:02,940
the next step to make it commercial.
And nothing happened.

589
00:35:03,360 --> 00:35:07,980
Caterpillar reached out and started
doing some work for mining applications.

590
00:35:08,010 --> 00:35:11,220
But we wanted to change the
whole world of automobiles.

591
00:35:12,030 --> 00:35:16,530
Larry and Sergei, we're the only
two leaders that stepped up.

592
00:35:16,560 --> 00:35:19,810
Larry and Sergei, they
were at that race. Uh,

593
00:35:19,811 --> 00:35:24,811
they had a passion for this subject
and Larry had a great conversation with

594
00:35:25,261 --> 00:35:28,790
Sebastian Thrun and said,

595
00:35:28,800 --> 00:35:33,390
Sebastian told Larry, we can't do this. We
shouldn't do it, Sebastian, until Larry,

596
00:35:33,391 --> 00:35:37,140
I'm the best in this field. I know what
I'm talking about. We shouldn't get into.

597
00:35:37,230 --> 00:35:38,063
And Larry said,

598
00:35:38,430 --> 00:35:42,390
I have to tell Eric and Sergei a
real reason why we can't do it.

599
00:35:42,390 --> 00:35:45,570
So he sends the bash and back the third
time and finally sabbatical came back,

600
00:35:45,610 --> 00:35:49,920
said, well, maybe we can, and
then they set these stretch goals.

601
00:35:49,921 --> 00:35:51,960
Think about this as a form of leadership.

602
00:35:53,190 --> 00:35:56,160
Larry wanted it to go on
every road in California.

603
00:35:56,460 --> 00:36:00,780
So they negotiated that they would
pick ten one hundred mile routes,

604
00:36:01,420 --> 00:36:04,890
you know, who laid out the
routes, Larry and Sergei,

605
00:36:06,110 --> 00:36:09,840
and they put a bonus in place for the
team to get this done in two years.

606
00:36:10,140 --> 00:36:14,010
So to Sebastian negotiates another goal
a hundred thousand miles on public roads

607
00:36:14,011 --> 00:36:15,840
because they want to at least
get a little bit of payment.

608
00:36:16,320 --> 00:36:18,600
This is really impressive leadership.

609
00:36:18,601 --> 00:36:22,050
And then they stuck with the
team and the team got a done.

610
00:36:22,620 --> 00:36:24,570
And so there's a management lesson here.

611
00:36:24,571 --> 00:36:28,950
You have to set it far enough out
where it's really hard to get there,

612
00:36:28,951 --> 00:36:31,380
but not so far out that it's impossible.

613
00:36:31,860 --> 00:36:35,850
And they've subsequently put additional
goals on the Waymo team that they're

614
00:36:35,851 --> 00:36:39,840
working really, really hard on
right now in Chandler, Arizona,

615
00:36:39,870 --> 00:36:44,730
tied to do people like riding in
these cars. Can you do it safely?

616
00:36:44,790 --> 00:36:46,710
Is there a business here?
All of that stuff.

617
00:36:46,711 --> 00:36:49,050
But it's really a good
lesson in management.

618
00:36:49,180 --> 00:36:51,980
Yeah. And I guess, uh, um,

619
00:36:52,130 --> 00:36:54,200
Tony and Darpa had the,

620
00:36:54,670 --> 00:36:57,680
the sort of the most challenging when he
really had to stick to his guns, right?

621
00:36:57,681 --> 00:37:00,800
Because after the first urban challenge
or the first desert challenge was

622
00:37:00,801 --> 00:37:04,150
supposed to be 150 miles and the
best card did what, seven. Yeah.

623
00:37:04,810 --> 00:37:05,260
Miles.

624
00:37:05,260 --> 00:37:08,880
And he had all this media stacked up at
the finish line and nobody got there.

625
00:37:09,210 --> 00:37:11,580
So Tony goes to the finish line,
he says,

626
00:37:11,581 --> 00:37:16,581
I got great news the next race and he
is on this date and the prize is $2

627
00:37:17,630 --> 00:37:18,463
million.

628
00:37:18,780 --> 00:37:23,760
He really driven it and this is a lot
of money for these young teams competing

629
00:37:23,761 --> 00:37:24,490
for it.

630
00:37:24,490 --> 00:37:27,620
Yeah. Yeah. I thought that was
a great story. Like, you know,

631
00:37:27,621 --> 00:37:32,000
stick with this approach. Um, I was,

632
00:37:32,210 --> 00:37:34,130
I was also curious as need to like the,

633
00:37:34,490 --> 00:37:38,420
the engineering cultures are
coming to appreciate the, you know,

634
00:37:38,421 --> 00:37:41,210
like what they have to offer each other.
But you also,

635
00:37:41,390 --> 00:37:44,680
I think kind of made a point,
at least in Detroit, right? The,

636
00:37:45,170 --> 00:37:47,570
there's actually a hierarchy
of engineering teams, right?

637
00:37:47,571 --> 00:37:51,710
So that parts manufacturers and some of
the parts manufacturers are as big as

638
00:37:51,711 --> 00:37:55,430
the, the auto companies
know, sell the brand name.

639
00:37:55,910 --> 00:38:00,440
And so I sort of wonder what
kind of hierarchy are we
going to see in the future?

640
00:38:00,441 --> 00:38:04,790
I, you know, is um, is Uber the brand
we're going to know or you know,

641
00:38:04,791 --> 00:38:08,420
or lift or Waymo is it going
to be Toyota? Uh, you know,

642
00:38:08,690 --> 00:38:10,640
is there gonna be a lot
of competition about that?

643
00:38:11,080 --> 00:38:13,450
Oh, yes. There's going to be
competition. First of all,

644
00:38:13,451 --> 00:38:16,300
there's a lot of different
use cases for these brands.

645
00:38:16,301 --> 00:38:19,330
There's the use case of
Uber's lifts without drivers.

646
00:38:19,331 --> 00:38:24,190
There's the use case of you basically
leasing an autonomous vehicle and having a

647
00:38:24,191 --> 00:38:27,760
subscription service so that you're
controlling it. So think about that. You,

648
00:38:28,150 --> 00:38:28,421
you say,

649
00:38:28,421 --> 00:38:32,110
I want one of these for 12 months and
then I'm going to subscribe for 30,000

650
00:38:32,111 --> 00:38:34,630
miles. It takes you to
work, drops you off,

651
00:38:34,631 --> 00:38:37,690
you then it to go pick up your spouse,

652
00:38:38,170 --> 00:38:42,610
take him or her to work and drops them
off and your spouse dispatches it to go

653
00:38:42,611 --> 00:38:46,810
pick up your kid at school for soccer
practice and then mother-in-law for meals

654
00:38:46,811 --> 00:38:47,291
on wheels.

655
00:38:47,291 --> 00:38:52,160
So you may use this one dedicated vehicle
to the point where you don't need that

656
00:38:52,161 --> 00:38:55,810
second and third car, but you're still
going to have that control that you have.

657
00:38:55,810 --> 00:39:00,670
So you've got that use case. Don't forget
goods movement over the road trucking,

658
00:39:00,940 --> 00:39:03,520
there's shortage of truck
drivers or truck drivers,

659
00:39:03,700 --> 00:39:07,750
64 cents a mile and benefits and wages.
And um,

660
00:39:07,751 --> 00:39:10,250
it's a tedious job.
It takes people away from their home.

661
00:39:10,251 --> 00:39:12,520
So there's real value to be created there.

662
00:39:12,521 --> 00:39:15,970
And then finally that last mile
of delivery, and I goodness,

663
00:39:15,971 --> 00:39:17,320
I work out of my Home Office.

664
00:39:17,321 --> 00:39:22,150
I've had two times where the ups truck
and Fedex truck where my driveway at the

665
00:39:22,151 --> 00:39:26,980
same time I came home from golfing two
weeks ago I had nine boxes on my porch.

666
00:39:26,981 --> 00:39:29,350
My wife has been busy.
She's a hairstylist.

667
00:39:29,351 --> 00:39:33,430
She likes to get all this stuff over
the internet. But that last mile,

668
00:39:33,431 --> 00:39:37,000
if you can get the driver out
of the local delivery system,

669
00:39:37,001 --> 00:39:40,900
whether it's with drones or you name it,
so a wide range of use cases.

670
00:39:40,901 --> 00:39:43,660
How are you going to
brand that is important.

671
00:39:43,660 --> 00:39:46,810
What are the experiences you're going
to deliver is not just about going from

672
00:39:46,811 --> 00:39:49,780
point a to point B and
getting there safely.

673
00:39:49,810 --> 00:39:53,160
It's does a pick me up on my precise
location and drop me off precisely.

674
00:39:53,161 --> 00:39:57,940
Is the ride so nice that when I get out
of the vehicle I feel better than when I

675
00:39:57,941 --> 00:40:02,560
got into it. Can I get to more
places with brand a versus brand B?

676
00:40:02,830 --> 00:40:04,750
That's going to be a basis of competition.

677
00:40:05,170 --> 00:40:09,550
But the one place I think you want to
be beyond anything else in this future

678
00:40:09,551 --> 00:40:14,410
ecosystem is to have the world's best
driver because that world's best driver

679
00:40:14,411 --> 00:40:16,630
can plan every one of those use cases.

680
00:40:17,260 --> 00:40:22,260
And it's typically more than half the
cost per mile that we incur today.

681
00:40:22,930 --> 00:40:24,330
So that's a big opportunity.
Now,

682
00:40:24,370 --> 00:40:28,510
does this play out in a Microsoft kind
of a business model or an intel inside

683
00:40:28,511 --> 00:40:32,830
business model or an arm business model?
Those decisions haven't been made yet.

684
00:40:32,860 --> 00:40:36,250
There's still a lot of work to
do before you start scaling.

685
00:40:37,330 --> 00:40:39,460
I think the experiences are get branded.

686
00:40:39,550 --> 00:40:42,640
I personally think the car companies
are going to have a tough time saying

687
00:40:43,180 --> 00:40:46,840
Chevrolet is the right brand
for a mobility service.

688
00:40:46,841 --> 00:40:48,490
I think that's going to
be a bit of a stretch.

689
00:40:48,520 --> 00:40:51,760
So I think you're gonna see some
rebranding going on. It's going to be fun.

690
00:40:53,000 --> 00:40:55,540
All right. It's a, it's
been great talking to you.

691
00:40:55,541 --> 00:40:58,420
I think I have to let everyone else
ask them. Well thank you. Thank you.

692
00:40:58,450 --> 00:41:01,450
Thank you for reading the book or
questions were excellent. And, um,

693
00:41:01,720 --> 00:41:06,490
certainly when you're an author you love
it when someone will give you some of

694
00:41:06,491 --> 00:41:10,470
your time over the weekend. It's really
nice, Jeremy, that he did that. The,

695
00:41:10,600 --> 00:41:14,390
I had great fun to read. Great Story.
It just one thing for the Q and a. Um,

696
00:41:14,950 --> 00:41:16,660
I lost my hearing 20 years ago.

697
00:41:16,661 --> 00:41:21,460
I hear with cochlear implants and at
the same technologies, autonomous cars,

698
00:41:21,461 --> 00:41:25,900
it's batteries and sensors and
software and all of that stuff.

699
00:41:25,901 --> 00:41:29,170
I think I'll hear you fine, but if not,
Jeremy, oh, help me with the questions.

700
00:41:29,171 --> 00:41:32,140
Go ahead. Hey Larry, thanks
for coming to talk to us.

701
00:41:32,840 --> 00:41:34,220
I have a three year old at home

702
00:41:34,220 --> 00:41:38,420
and uh, you know, I think
about in 13 years is going
to get his driver's license.

703
00:41:38,750 --> 00:41:40,850
What are the odds that he's going
to get his driver's license?

704
00:41:42,020 --> 00:41:44,400
No,
I think the odds are pretty low.

705
00:41:44,401 --> 00:41:47,870
There's a lot of people who are
enthusiastic about driving and you know,

706
00:41:47,880 --> 00:41:49,950
a hundred years ago there are
a lot of people enthusiastic,

707
00:41:49,951 --> 00:41:54,900
a lot of horses and um, you
know, there's still horse racing.

708
00:41:54,910 --> 00:41:56,160
There's still equestrian.

709
00:41:56,670 --> 00:42:01,670
The important message right now is not
that we're going to say you can't drive,

710
00:42:02,191 --> 00:42:05,700
but for a lot of people were going to say
you're going to get the accessibility,

711
00:42:05,701 --> 00:42:09,630
mobility benefits of owning and
operating a car and not have to drive.

712
00:42:09,960 --> 00:42:11,310
So your, your, your,

713
00:42:11,311 --> 00:42:16,050
your child is going to be able to make
a choice by the time they're 15 or 16.

714
00:42:16,530 --> 00:42:20,010
There's a lot of negatives with owning
and operating a car beyond the safety

715
00:42:20,011 --> 00:42:22,720
rest, having a staff to a
gas, having to find parking,

716
00:42:22,740 --> 00:42:25,210
having to get your car maintained,
having a shop for,

717
00:42:25,780 --> 00:42:30,120
I'll have an insured and finance it and
you put all that together and you say,

718
00:42:30,121 --> 00:42:33,420
man, that's a real hassle and this
industry has existed for a century,

719
00:42:33,421 --> 00:42:37,740
assuming you're willing to do that
and pay 35,000 bucks for a car.

720
00:42:38,030 --> 00:42:41,770
So I think that world's going to change
quite a bit. Thank you. Thank you.

721
00:42:42,490 --> 00:42:43,323
Over here.

722
00:42:43,570 --> 00:42:45,610
So I actually have two questions.

723
00:42:46,600 --> 00:42:50,510
The first one is a big downside of
electric vehicles has always been distance

724
00:42:50,511 --> 00:42:51,970
per charge.
Uh,

725
00:42:51,971 --> 00:42:55,270
what about taking a trip in the world
that you are describing here? Uh,

726
00:42:55,271 --> 00:43:00,040
how would I go from New York City to
buffalo to get some buffalo wings for the

727
00:43:00,040 --> 00:43:04,390
weekend? How does that play into what
you're talking about, which is more, uh,

728
00:43:04,480 --> 00:43:06,650
you know, daily travel,
commuting, they et cetera.

729
00:43:06,790 --> 00:43:09,590
Yeah,
that's an exciting question.

730
00:43:09,591 --> 00:43:12,890
The range of the batteries has
increased significantly. Lay,

731
00:43:12,891 --> 00:43:16,820
the Chevrolet Bolt for example,
has about 230 mile range.

732
00:43:16,821 --> 00:43:21,320
So we think the battery is sufficient
for the everyday community kind of usage

733
00:43:21,321 --> 00:43:24,950
in this shared model going
between communities. Um,

734
00:43:25,340 --> 00:43:26,850
you may have like a,

735
00:43:27,140 --> 00:43:31,730
a range extender that you
could associate with this.

736
00:43:31,731 --> 00:43:35,120
I'm almost like a pod
that snaps on the back,

737
00:43:35,121 --> 00:43:39,110
that's extra battery just when you need
to make that trip that can extend your

738
00:43:39,111 --> 00:43:41,870
range and extend your power to do that.
Uh,

739
00:43:41,871 --> 00:43:44,480
I wouldn't totally rule out
hydrogen and fuel cells.

740
00:43:44,510 --> 00:43:47,120
I wish I never uttered
the word fuel cell cars.

741
00:43:47,121 --> 00:43:50,030
This is just a hydrogen batteries
and other kind of a battery.

742
00:43:50,450 --> 00:43:53,660
But that's its real advantage as you
can fill up with hydrogen and have

743
00:43:53,690 --> 00:43:57,540
significant range. I do think when
the, when the market's there, um,

744
00:43:57,650 --> 00:44:02,360
we're going to have the solutions in place
to get you from a buffalo to New York

745
00:44:02,361 --> 00:44:05,570
City if that's where you want to go.
One way ticket to buffalo though.

746
00:44:06,740 --> 00:44:08,940
Ah, that's right. We can
plug it in when we get,

747
00:44:10,230 --> 00:44:13,500
so we saw in the late nineties,
early two thousands with the Evie one.

748
00:44:13,501 --> 00:44:17,670
For example, as you mentioned, the
effect of the oil and gas lobbies. Um,

749
00:44:17,730 --> 00:44:18,600
and what,

750
00:44:18,930 --> 00:44:21,930
and their effect on the saturation of
the electric vehicle as a whole in the

751
00:44:21,931 --> 00:44:24,450
United States.
Has that changed at all?

752
00:44:24,451 --> 00:44:29,451
Are we at the point where we're ready
to see a gas and oil cars off road or

753
00:44:32,700 --> 00:44:34,110
are we still fighting that same battle?

754
00:44:34,820 --> 00:44:39,650
I certainly can see a pathway to not
need oil any longer in the transportation

755
00:44:39,651 --> 00:44:44,110
sector. I hesitated a bit. Um, diesel
is a really good way to move. Hey,

756
00:44:44,240 --> 00:44:47,360
80,000 pound load.
So there may be some applications there,

757
00:44:47,361 --> 00:44:52,100
but I think for about 80% of the
oil we can get off of that. Will we,

758
00:44:52,670 --> 00:44:55,220
um, the thing that keeps me
up at night, quite honestly,

759
00:44:55,221 --> 00:44:58,790
I think what's going to gate all of
those are those very powerful voices that

760
00:44:58,791 --> 00:45:03,200
have a vested interest in the hundred
and 30 year old automobile roadway

761
00:45:03,201 --> 00:45:08,150
transportation system. The easiest
thing to do in Washington DC is say no.

762
00:45:08,210 --> 00:45:13,190
And these companies who have something
to lose from this are very good at

763
00:45:13,191 --> 00:45:16,160
knowing how to say no.
So that does concern me.

764
00:45:16,161 --> 00:45:19,070
But technologically I think we're there.

765
00:45:19,071 --> 00:45:23,150
I think in terms of value proposition for
all of us living in our everyday lives,

766
00:45:23,151 --> 00:45:26,040
I think where their business model,
uh,

767
00:45:26,041 --> 00:45:29,840
investors wanting to put the money in
this new future rather than where we've

768
00:45:29,841 --> 00:45:31,810
been,
I think we're there now.

769
00:45:31,811 --> 00:45:35,780
It's just a matter of almost like
the baseball movie field of dreams.

770
00:45:35,781 --> 00:45:40,340
If I build it, they will come and that's
why I'm so proud to be part of Waymo, uh,

771
00:45:40,341 --> 00:45:43,970
as an advisor because that's what they're
doing in Chandler has approving this

772
00:45:43,971 --> 00:45:45,270
thing out.
Cool.

773
00:45:45,840 --> 00:45:47,870
Thank you. Thank you. Yes. Hi.

774
00:45:48,360 --> 00:45:53,030
You mentioned that you view as sort of
this market is being very competitive and

775
00:45:53,031 --> 00:45:57,170
I was just wondering how you think about
like network effects have like Uber and

776
00:45:57,170 --> 00:45:57,171
Lyft.

777
00:45:57,171 --> 00:46:00,560
Basically their entire business model
is just if you have all the drivers then

778
00:46:00,561 --> 00:46:05,060
you have all the passengers and you
can, you know, be a monopoly I guess.

779
00:46:05,061 --> 00:46:08,480
How do you think about what
the market will look like,

780
00:46:08,481 --> 00:46:11,630
whether you've used a transportation
is centralizing and what,

781
00:46:11,631 --> 00:46:13,220
like regulatory or other options.

782
00:46:13,760 --> 00:46:15,050
Very important questions.

783
00:46:15,051 --> 00:46:18,860
And one of the interesting part of
results from the work I did at Columbia,

784
00:46:18,861 --> 00:46:22,610
not only did we get this 20 cent
per mile opportunity identified,

785
00:46:23,210 --> 00:46:28,210
it turns out scale economies are reached
at about 10% of the miles driven in a

786
00:46:28,941 --> 00:46:29,774
community.

787
00:46:29,900 --> 00:46:34,310
What I mean by that as if I had a shared
fleet that I was running in Anarbor and

788
00:46:34,311 --> 00:46:39,311
I had 10% market share and then I went
to 11% my cost per mile wasn't going down

789
00:46:39,801 --> 00:46:43,060
anymore. The suggests that, um,

790
00:46:43,160 --> 00:46:47,330
you don't need to have the entire market
in order to, to have scale and be,

791
00:46:47,331 --> 00:46:51,350
and be competitive. With that said,
there's definitely network effects there.

792
00:46:51,351 --> 00:46:54,650
There's definitely scaling
affects those learning affects.

793
00:46:54,651 --> 00:46:56,600
I talk about having the
world's best driver.

794
00:46:56,601 --> 00:47:00,320
One of the best ways to do that is to
be learning for more and more and more

795
00:47:00,321 --> 00:47:05,090
vehicles on the road every day.
And when the beauty of a driverless cars,

796
00:47:05,091 --> 00:47:07,790
when I learned something from one car,

797
00:47:08,210 --> 00:47:11,000
I can put it on all the other
cars and make all of them safer.

798
00:47:11,540 --> 00:47:14,870
When I learned something as a human
driver about how to do something better,

799
00:47:14,871 --> 00:47:17,930
I have no mechanism for transferring
that to other human driver.

800
00:47:17,931 --> 00:47:20,870
So these things are real important and
I think they're going to have to be

801
00:47:20,871 --> 00:47:23,450
watched,
certainly not a reason not to go forward,

802
00:47:23,451 --> 00:47:25,980
but they're going to have to
be managed for sure. Yeah.

803
00:47:26,780 --> 00:47:30,250
Yes. Yeah. I'm very excited
about driverless cars

804
00:47:30,250 --> 00:47:33,430
and the certainly there's
tremendous, uh, uh, future.

805
00:47:33,730 --> 00:47:38,730
There's one thing that worries me about
its impact on freedom because a car was

806
00:47:40,240 --> 00:47:44,070
the greatest vehicle for
freedom and opportunity. Uh,

807
00:47:44,140 --> 00:47:49,140
ability to go someplace is
a great boon for humans.

808
00:47:49,960 --> 00:47:54,880
With now the way the driverless cars are
being actual designed and implemented

809
00:47:54,881 --> 00:47:59,881
means we depend on cloud services and
on provider of cloud services desired to

810
00:48:02,230 --> 00:48:03,430
enable my trip.

811
00:48:04,480 --> 00:48:09,480
Google decides not to map
certain area in the car as well,

812
00:48:09,550 --> 00:48:11,830
not go to their Dra,
uh,

813
00:48:12,310 --> 00:48:17,310
Google or better yet the government
decides that certain event is not good.

814
00:48:18,970 --> 00:48:22,030
They can easily make cars
not go to that event.

815
00:48:24,220 --> 00:48:29,080
And this is because we have no other way
of doing things other than through the

816
00:48:29,081 --> 00:48:31,740
cloud servers. We don't
treat, we will, uh,

817
00:48:32,320 --> 00:48:36,640
we will not really own anything
even if we buy the, uh,

818
00:48:36,641 --> 00:48:38,200
the car.
Yeah.

819
00:48:38,700 --> 00:48:41,850
So yeah, I mean, first of all,

820
00:48:41,851 --> 00:48:45,180
the title of my book has autonomy
because I believe this future is going to

821
00:48:45,181 --> 00:48:47,130
bring more freedom.
Um,

822
00:48:47,190 --> 00:48:51,660
there was a lot of people today that
can't benefit from an owning and operating

823
00:48:51,661 --> 00:48:53,390
an automobile.
There are two younger driver,

824
00:48:53,400 --> 00:48:56,340
they're too old or they're not
capable physically to do it.

825
00:48:56,730 --> 00:48:59,220
They can't afford it or
whatever it might be.

826
00:48:59,221 --> 00:49:02,580
So we really think we're going to bring
more freedom to a lot more people with

827
00:49:02,581 --> 00:49:05,040
this.
If the concern that you raised,

828
00:49:05,041 --> 00:49:07,740
which is really kind of beyond
my area of expertise. I,

829
00:49:07,741 --> 00:49:08,820
if you're concerned about that,

830
00:49:08,821 --> 00:49:12,210
I encourage you to go out
and start working on it
because we want this to be an

831
00:49:12,211 --> 00:49:16,830
enabler of much greater freedom
rather than a constraint or a freedom.

832
00:49:17,220 --> 00:49:19,950
I think when you look at the hundred
year history of the auto industry,

833
00:49:19,951 --> 00:49:22,140
a lot of that stuff was
playing out as well.

834
00:49:22,140 --> 00:49:25,140
Where were you going to build the road
and where are we going to build a parking

835
00:49:25,141 --> 00:49:28,380
lot? And um, who pays for
the roads and all of that.

836
00:49:28,381 --> 00:49:33,381
And I think we have created an extensive
amount of uneven access and inequality

837
00:49:35,850 --> 00:49:37,320
in our mobility systems.

838
00:49:37,440 --> 00:49:41,010
I live north of Detroit in
our neighborhoods in Detroit,

839
00:49:41,011 --> 00:49:44,940
still have a lot of poverty and these
people can break out of the cycle of

840
00:49:44,941 --> 00:49:48,210
poverty because we don't
have any transportation
alternatives other than than a

841
00:49:48,211 --> 00:49:51,060
car. And the car insurance
is off the charts expensive.

842
00:49:51,061 --> 00:49:53,910
So all of this has to be
managed and talked about.

843
00:49:54,420 --> 00:49:59,070
And I'd encourage that dialogue to
continue, I think. Great observation. Yes.

844
00:49:59,650 --> 00:50:00,130
Hey,

845
00:50:00,130 --> 00:50:04,570
I was wondering if you thought that the
influx of autonomous vehicles in cities,

846
00:50:04,630 --> 00:50:08,560
uh, will result in cities becoming
more multimodal, more walkable,

847
00:50:08,770 --> 00:50:11,740
bikeable more mass transit with first,
last mile,

848
00:50:11,770 --> 00:50:15,370
or if you thought it would just increase
car dependence and creased the widening

849
00:50:15,371 --> 00:50:16,300
of roads,
et cetera.

850
00:50:17,130 --> 00:50:19,350
I think it's going to be the f the former.
I mean,

851
00:50:19,351 --> 00:50:23,250
there's three parking spaces dedicated
to every car in the United States and

852
00:50:23,251 --> 00:50:25,290
there's, you know, 250 million cars.

853
00:50:25,291 --> 00:50:29,810
So that's a lot of parking and
that parking, um, constraints,

854
00:50:29,811 --> 00:50:33,500
densification. Um, I do
want to make a point though,

855
00:50:33,770 --> 00:50:36,500
only 26% of Americans live in cities.

856
00:50:36,501 --> 00:50:41,480
53% of Americans live in suburbs and
that parking issue is even more severe

857
00:50:41,481 --> 00:50:42,730
there.
Um,

858
00:50:42,800 --> 00:50:46,490
I on the board of a real
estate development company
in Florida and we had a

859
00:50:46,491 --> 00:50:51,470
parcel of land that we are developing
along eyes 75 south of Tampa,

860
00:50:51,471 --> 00:50:56,300
St Petersburg.
And they ended up putting a,

861
00:50:56,301 --> 00:50:59,330
um, um, Walmart on that site.

862
00:50:59,810 --> 00:51:04,490
But the amount of land for parking was
twice the amount of land for the building.

863
00:51:04,940 --> 00:51:05,960
And this is nuts.

864
00:51:05,961 --> 00:51:10,490
And so I think this is an opportunity
to really drive densification.

865
00:51:10,550 --> 00:51:11,660
And secondly,

866
00:51:11,661 --> 00:51:16,100
the vehicles are dramatically
better at detecting pedestrians,

867
00:51:16,101 --> 00:51:17,600
detecting bicyclists,

868
00:51:17,930 --> 00:51:22,930
and taking a lot of the risk out of the
system for vulnerable road way users.

869
00:51:23,600 --> 00:51:27,140
I sometimes talk about this. You've
heard the concept of secondhand smoke.

870
00:51:27,141 --> 00:51:29,900
I'd like to talk about secondhand
physics for some reason.

871
00:51:30,320 --> 00:51:34,940
There's a belief that somebody can drive
a 5,000 pound Cadillac as escalate I

872
00:51:34,941 --> 00:51:38,480
one of the streets in Manhattan
and go 45 miles an hour.

873
00:51:38,481 --> 00:51:42,770
And it's that second hand physics.
I mean, it's just kinetic energy.

874
00:51:42,771 --> 00:51:44,250
So we've got to work through it.
But I,

875
00:51:44,251 --> 00:51:46,970
I'm in the camp where I think we're
going to make cities more livable,

876
00:51:46,971 --> 00:51:50,000
but very importantly, I think we're
going to improve suburbs a lot too.

877
00:51:50,430 --> 00:51:52,950
So the whole driverless car thing seems,

878
00:51:53,070 --> 00:51:56,440
reminds me a lot of the Internet
in the 1980s nineties, 90s,

879
00:51:56,900 --> 00:51:58,560
a lot of innovation and exciting things.

880
00:51:58,980 --> 00:52:02,220
One of the things that happened sort of
after that time in the Internet is we

881
00:52:02,221 --> 00:52:07,110
discovered there's a lot
of malefactors out there.

882
00:52:07,470 --> 00:52:08,640
And,
um,

883
00:52:08,760 --> 00:52:11,850
one of the things that I haven't heard
anyone in this industry really talking

884
00:52:11,851 --> 00:52:16,200
about too much is how do you defend,
uh,

885
00:52:16,230 --> 00:52:20,010
and make secure your driverless car,

886
00:52:20,011 --> 00:52:23,880
not only against the kind of attacks
that are already taking place against,

887
00:52:23,970 --> 00:52:26,790
you know,
automated but driver full cars,

888
00:52:27,210 --> 00:52:31,650
but against jamming or other kinds of
attacks on the sensors and things like

889
00:52:31,651 --> 00:52:35,610
that, which, you know, nobody is
doing that now. It's wonderful.

890
00:52:35,611 --> 00:52:40,020
Everybody's cooperating mostly, but
you know, that doesn't last forever.

891
00:52:40,410 --> 00:52:44,410
Yeah. Yeah. Low cybersecurity area again,

892
00:52:44,420 --> 00:52:46,060
is not my expertise.

893
00:52:46,061 --> 00:52:50,290
I talked to people who understand a
better than I do and we've got a lot of

894
00:52:50,291 --> 00:52:54,040
people working on that hard. It's not an
issue that's unique to driverless cars.

895
00:52:54,041 --> 00:52:59,041
It also exists in human driven cars or
current curves are very vulnerable to be

896
00:52:59,620 --> 00:53:03,880
hacked. It's, it's part of other
systems we use in our daily lives.

897
00:53:03,881 --> 00:53:08,800
They are airline system and other things.
And so I assure the concern.

898
00:53:09,190 --> 00:53:13,180
Um, but not to the, and I'm not
implying you're suggesting this,

899
00:53:13,181 --> 00:53:17,770
but not to the point where it says we
shouldn't be pushing this opportunity to

900
00:53:17,771 --> 00:53:18,700
its full extent.

901
00:53:18,760 --> 00:53:23,500
I believe the way to go at this is to
think big and certainly Google self

902
00:53:23,501 --> 00:53:27,180
driving cars and Google alphabet
are thinking very big in this space.

903
00:53:27,420 --> 00:53:31,620
Start small. 13 Prius says, get out
and start learning on public roads.

904
00:53:31,950 --> 00:53:32,910
Learn fast.

905
00:53:32,940 --> 00:53:36,840
We've been learning fast now for almost
a decade and it's been extraordinary

906
00:53:36,860 --> 00:53:39,750
insights and then scale smart.

907
00:53:40,350 --> 00:53:43,230
I don't think anyone's going to
want to scale a system that has the

908
00:53:43,231 --> 00:53:45,840
vulnerabilities that,
that you're concerned with.

909
00:53:45,841 --> 00:53:47,550
We're going to have to
have solutions to that.

910
00:53:47,880 --> 00:53:51,420
Should that be the first problem
to fix? I don't know. I, you know,

911
00:53:51,460 --> 00:53:56,430
I don't think solving snow storms on
Loveland pass at nighttime was the first

912
00:53:56,431 --> 00:53:59,670
thing to work on. And driverless
cars, we may never solve that one,

913
00:53:59,950 --> 00:54:02,790
but I think we've got to get out there
and learn. So I have one more question.

914
00:54:03,510 --> 00:54:04,343
One more please.

915
00:54:04,770 --> 00:54:09,700
Oh, okay. So just where does it
start in a big way. I mean, uh,

916
00:54:09,720 --> 00:54:12,510
you know,
of course it makes sense to focus on the,

917
00:54:13,020 --> 00:54:17,730
the desired end state of, of changing
the car experience for Americans.

918
00:54:18,090 --> 00:54:22,530
But uh, it does it actually start in
some more limited domain, I dunno,

919
00:54:22,590 --> 00:54:27,590
long haul trucking or enthusiasts or
early adopters or CD centers where there's

920
00:54:29,970 --> 00:54:32,580
restricted access for other
kinds of vehicles or what?

921
00:54:32,840 --> 00:54:36,320
Yeah, I think those use cases are
very exciting places to start.

922
00:54:36,350 --> 00:54:40,580
A gated communities, campuses,
those speed applications.

923
00:54:40,940 --> 00:54:45,350
The interesting thing about over the road
trucking is not all freeway links are

924
00:54:45,440 --> 00:54:49,120
created the same. Some are flat, um,

925
00:54:49,820 --> 00:54:52,910
straight, nice weather,
low traffic density,

926
00:54:53,360 --> 00:54:56,810
much easier to get started with his
business. Then some of the curve,

927
00:54:56,811 --> 00:55:00,710
you're a higher traffic area
so it's not going to be just,

928
00:55:00,711 --> 00:55:05,030
we suddenly take it and deploy it on a
large scale in a major metropolitan area.

929
00:55:05,031 --> 00:55:09,390
I think you're going to see a whole
bunch of these smaller plays done. Uh,

930
00:55:09,520 --> 00:55:14,120
as we work hard. No one's saying we're
ready to commercialize this at scale.

931
00:55:14,600 --> 00:55:18,740
What we are saying is we believe that
technology is reaching a point where

932
00:55:18,741 --> 00:55:21,500
there's commercial
consumer value to be had.

933
00:55:21,980 --> 00:55:25,160
And I think with any startup,
you want to get to that point.

934
00:55:25,161 --> 00:55:29,000
You want to get real customers want to
get real money coming in that that's what

935
00:55:29,001 --> 00:55:32,770
we're in the business to do. But I think
these opportunities to talk about are,

936
00:55:32,830 --> 00:55:37,260
are there. Great. Okay. Thanks
so much. Thanks everybody.

937
00:55:37,710 --> 00:55:42,710
[inaudible].

