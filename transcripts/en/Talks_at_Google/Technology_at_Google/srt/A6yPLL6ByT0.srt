1
00:00:06,710 --> 00:00:09,290
So welcome everybody.
Thanks very much for joining us today.

2
00:00:09,320 --> 00:00:13,930
We are lucky to have two distinguished,
uh, coauthors of the, uh,

3
00:00:14,000 --> 00:00:18,680
great recent book or coming out very
shortly, machine platform and crowd crowd.

4
00:00:19,110 --> 00:00:19,550
Uh,

5
00:00:19,550 --> 00:00:24,550
let me introduce Andy Mcafee and Erik
Brynjolfsson who are both distinguished

6
00:00:24,741 --> 00:00:29,540
professors at the Sloan school at Mit
and Co directors of the Mit Initiative on

7
00:00:29,541 --> 00:00:30,440
the digital economy.

8
00:00:31,070 --> 00:00:34,970
I thought we'd start off by asking them
to tee up the thesis and the main themes

9
00:00:34,971 --> 00:00:36,260
of their books for a few minutes.

10
00:00:36,530 --> 00:00:39,770
I've got a few questions to ask about
both this book and their prior book,

11
00:00:39,771 --> 00:00:40,760
the Second Machine Age,

12
00:00:41,060 --> 00:00:45,710
and we'd love to open it up to all of you
both in the room and, and, uh, in, uh,

13
00:00:45,711 --> 00:00:47,690
offices around the country.
So with that,

14
00:00:47,691 --> 00:00:51,920
let me turn it over to you guys for a
quick overview of the book. Uh, the, uh,

15
00:00:52,070 --> 00:00:55,370
we've known each other for some years
at a variety of, of different sessions.

16
00:00:55,520 --> 00:00:58,070
And my favorite description of all the
wonderful things that can be said about

17
00:00:58,071 --> 00:01:01,610
Andy and Eric. Eric is that the
FDA review called them the Pinup,

18
00:01:01,730 --> 00:01:06,050
the pinup boys for the Davos crowd.
So I'm not sure if you can outdo that,

19
00:01:06,051 --> 00:01:07,940
but think about what that says

20
00:01:08,060 --> 00:01:12,020
about the rest of the Davos crowd. Just
ponder that for a sec. Jakks waiting on,

21
00:01:12,021 --> 00:01:16,430
right. We would only be talking for
this session now just to get your,

22
00:01:17,090 --> 00:01:18,860
get your expectations set properly.

23
00:01:20,030 --> 00:01:21,470
So tell us a little bit about the book,

24
00:01:21,471 --> 00:01:23,480
what you coming off
the second machine age,

25
00:01:23,481 --> 00:01:26,480
which is a lot about the economic
transitions, the United States.

26
00:01:27,350 --> 00:01:30,380
What's the next chapter in that story
that you wanted to tell with this book?

27
00:01:31,120 --> 00:01:35,280
So coming off the last book, I think
we heard a lot of people saying, okay,

28
00:01:35,580 --> 00:01:38,100
we get what you're saying,
that the world is changing.

29
00:01:38,101 --> 00:01:40,900
There are these things
happening with technology, um,

30
00:01:41,010 --> 00:01:43,410
and the economy is being effected.
What now?

31
00:01:43,411 --> 00:01:45,810
What should we be doing
to take advantage in?

32
00:01:45,811 --> 00:01:48,480
A little bit more about
how businesses can react.

33
00:01:48,810 --> 00:01:51,960
And we saw a really three
big rebalancing is happening.

34
00:01:52,200 --> 00:01:54,270
One of them was between mind and machine.

35
00:01:54,540 --> 00:01:57,000
One of them was between
product and platform.

36
00:01:57,360 --> 00:01:59,550
And the third one was breeding
the core and the crowd. First.

37
00:01:59,551 --> 00:02:01,140
We thought we'd put all
those words in the title,

38
00:02:01,141 --> 00:02:03,840
but then our names wouldn't
fit in 18 point type.

39
00:02:03,841 --> 00:02:06,180
So we had to reduce the
number of words a little bit.

40
00:02:06,450 --> 00:02:09,180
So the first one is what you
guys are all very familiar with,

41
00:02:09,181 --> 00:02:13,050
this rebalancing between mind and
machine that machine's first off,

42
00:02:13,140 --> 00:02:16,770
helping with a lot of humans make better
decisions, data driven decision making,

43
00:02:16,771 --> 00:02:21,200
whether it's helping the Golden State
Warriors use analytics to understand that

44
00:02:21,201 --> 00:02:25,440
three point shots are worth more than two
point shots and other things like that

45
00:02:25,500 --> 00:02:27,570
or where we think you
need analytics for that.

46
00:02:28,140 --> 00:02:31,610
Well apparently I wasn't well
understood until recently. Um,

47
00:02:31,700 --> 00:02:35,290
and there may have been some more subtle
things that they pulled out as well. Um,

48
00:02:35,610 --> 00:02:38,710
and of course before that it was the,
their neighbors, the Oakland, uh,

49
00:02:38,760 --> 00:02:43,320
Oakland A's and the Boston Red Sox who
won a series of three world championships

50
00:02:43,321 --> 00:02:46,280
between them. Um, and then, um,

51
00:02:46,740 --> 00:02:48,450
it's coming to more and more businesses.

52
00:02:49,050 --> 00:02:54,050
We've got about a three times increase
in the use of data driven decision

53
00:02:54,781 --> 00:02:55,800
making.
By the way,

54
00:02:55,801 --> 00:03:00,610
we've measured it across American
plants and even in our own history, uh,

55
00:03:00,790 --> 00:03:01,930
tenure analytics,

56
00:03:01,960 --> 00:03:06,820
we're using analytics to try to predict
who's going to get tenure at top

57
00:03:06,821 --> 00:03:08,620
universities,
who is going to get prizes.

58
00:03:08,621 --> 00:03:11,890
And then it turns out that it can help
predict the tenure committees in terms of

59
00:03:11,891 --> 00:03:16,300
who does better performance. That just
the first part of that. More and more,

60
00:03:16,360 --> 00:03:20,620
as you guys know, artificial intelligence
is making decisions on their own.

61
00:03:20,620 --> 00:03:23,800
And I won't even go into all that because
you guys are very familiar with that.

62
00:03:23,950 --> 00:03:27,730
The third, the second big rebalancing
is between products and platforms.

63
00:03:28,150 --> 00:03:33,080
Five of the biggest companies by
market cap are platform companies. Uh,

64
00:03:33,100 --> 00:03:37,570
Google alphabet here,
Facebook, Amazon, apple,

65
00:03:37,870 --> 00:03:39,370
and Microsoft.
But it's a,

66
00:03:39,371 --> 00:03:42,550
lots of smaller companies that
are coming up and growing,

67
00:03:42,551 --> 00:03:45,550
sometimes almost out of nowhere
becoming multibillion dollar companies,

68
00:03:45,820 --> 00:03:49,060
leveraging platforms and trying to
understand that trade off between products

69
00:03:49,061 --> 00:03:52,690
and platforms and why those are so
much more powerful now. And thirdly,

70
00:03:52,780 --> 00:03:57,550
between the core and the crowd.
Um, tapping into the, uh, millions,

71
00:03:57,551 --> 00:04:01,030
actually billions of brains around the
planet is something that we can do now

72
00:04:01,031 --> 00:04:05,410
because we have a global interconnected
digital network that allows people to

73
00:04:05,411 --> 00:04:08,860
communicate that way in a way that they
couldn't have previously and not just to

74
00:04:08,861 --> 00:04:11,800
access information but
to contribute to it.

75
00:04:12,220 --> 00:04:15,880
So this helps us understand to make sense
of some of the weird things that are

76
00:04:15,881 --> 00:04:18,700
happening in the economy,
the companies that are being destroyed,

77
00:04:18,701 --> 00:04:20,050
new companies being created.

78
00:04:20,290 --> 00:04:23,350
And there's some underlying economic
principles in each of these areas of

79
00:04:23,351 --> 00:04:24,850
product, uh, of,

80
00:04:24,851 --> 00:04:29,851
of a machine platform and crowd and laying
out the phenomena that are happening

81
00:04:30,791 --> 00:04:34,240
with lots of case studies. And then
the economic principles. In each case,

82
00:04:34,540 --> 00:04:38,980
it turns out there's some Nobel prize
winning economics that drive each of these

83
00:04:38,981 --> 00:04:41,980
changes and that can help
us make sense of that.

84
00:04:41,981 --> 00:04:45,580
So that was the basic strategy of
what we were trying to do with machine

85
00:04:45,610 --> 00:04:47,620
platform and crowd. And, uh,

86
00:04:47,650 --> 00:04:50,680
and we're hoping that we continue
to have this kind of dialogue.

87
00:04:50,681 --> 00:04:53,650
We're looking forward to some questions
and comments from all of you to see what

88
00:04:53,651 --> 00:04:56,410
the challenges are that you're facing,
the opportunities you're facing,

89
00:04:56,620 --> 00:05:00,090
and see how well we can map them into
the framework that we've developed. And

90
00:05:00,900 --> 00:05:04,560
yeah, what he said. First of all,
can't thank you for hosting us.

91
00:05:04,670 --> 00:05:06,570
It's a pleasure and a real
privilege to come back.

92
00:05:06,571 --> 00:05:08,490
We've learned a lot from
Google over the years.

93
00:05:08,491 --> 00:05:10,710
It's always a pleasure to come
back and talk with you all.

94
00:05:10,980 --> 00:05:14,850
I want to also thank Andrew
and your team@google.org uh,

95
00:05:14,910 --> 00:05:18,420
Google dog over and is a supporter of our
inclusive innovation challenge back at

96
00:05:18,421 --> 00:05:22,620
MIT where we're trying
to reward innovators and
entrepreneurs who are improving

97
00:05:22,621 --> 00:05:27,621
economic prospects for average income
and below average income workers.

98
00:05:27,870 --> 00:05:31,050
A lot of us in this room know that the
narrative these days is that technology's

99
00:05:31,051 --> 00:05:35,460
killing jobs and it's not too far from
that narrative to therefore technologies

100
00:05:35,461 --> 00:05:38,820
and bad thing. We think that's a
really harmful road to go down.

101
00:05:38,970 --> 00:05:40,440
So we're trying to,
with the IIC,

102
00:05:40,441 --> 00:05:44,070
we're trying to celebrate organizations
that are using technology to bring

103
00:05:44,071 --> 00:05:45,360
economic opportunity.

104
00:05:45,480 --> 00:05:48,540
We're really happy to have
google.org on board with us for that.

105
00:05:48,690 --> 00:05:50,460
And then finally,
thank you all for showing up today.

106
00:05:50,461 --> 00:05:54,000
I know you probably have a lot of things
to do. It's a pleasure to have you here.

107
00:05:54,210 --> 00:05:56,940
I want to tell the origin
story of this book, uh,

108
00:05:57,020 --> 00:05:59,870
because Eric and I wrote the second
machine age together and you know,

109
00:05:59,871 --> 00:06:04,220
we kind of thought we were maybe thought
we were done writing books about this

110
00:06:04,310 --> 00:06:07,430
period of crazy tech
progress that we were in.

111
00:06:07,730 --> 00:06:11,870
And we noticed as soon as we finished
that book that people who run companies

112
00:06:11,871 --> 00:06:15,470
kept on approaching us in the hallways,
honestly, of places like Davos.

113
00:06:15,800 --> 00:06:20,060
And they kept on saying,
essentially, I believe your story.

114
00:06:20,420 --> 00:06:21,860
Now what do I do?

115
00:06:22,280 --> 00:06:26,420
And in some cases I got the impression
that there was actually some desperation

116
00:06:26,421 --> 00:06:29,810
behind the question that they were asking.
The people were successful,

117
00:06:29,811 --> 00:06:32,060
they were running large,
successful organizations.

118
00:06:32,270 --> 00:06:34,580
And I started to get the
impression that they were at sea.

119
00:06:34,581 --> 00:06:38,330
They were really floundering
or foundering, uh, about,

120
00:06:38,420 --> 00:06:40,790
about what this technology
surge that they,

121
00:06:40,791 --> 00:06:42,760
that they understood at some level the,

122
00:06:42,761 --> 00:06:46,790
they didn't have a great way to think
about what this was going to do to their

123
00:06:46,791 --> 00:06:48,950
business,
to their organization or their industry.

124
00:06:48,951 --> 00:06:52,520
And that became kind of this
recurring conversation that we had.

125
00:06:52,700 --> 00:06:56,330
And I found it profoundly interesting
because I didn't understand at first why

126
00:06:56,331 --> 00:07:00,320
they were so lost. These were
smart, successful, experienced,

127
00:07:00,321 --> 00:07:05,300
well educated executives and they felt
really just just deer in headlights with

128
00:07:05,301 --> 00:07:08,210
what was coming at them.
And then as Eric and I did the work,

129
00:07:08,211 --> 00:07:11,960
I realized that I should have been less
surprised by that because the mantra

130
00:07:11,961 --> 00:07:16,010
about technology that I'm repeating to
myself these days is that tech progress

131
00:07:16,011 --> 00:07:18,320
rewrites the business playbook.

132
00:07:18,590 --> 00:07:21,890
And we're in one of those stages right
now where the two of us believe the

133
00:07:21,891 --> 00:07:26,300
playbook for how you run a successful
business is being substantially rewritten

134
00:07:26,600 --> 00:07:28,910
by the kinds of new
technologies that we're seeing.

135
00:07:29,060 --> 00:07:32,930
The last time I think this happened
was just about a century ago when

136
00:07:32,931 --> 00:07:37,070
manufacturing went from being steam
powered to being electric powered.

137
00:07:37,280 --> 00:07:39,650
And there was a naive
way to think about that,

138
00:07:39,651 --> 00:07:42,260
which was take out the big steam
engine in the basement of the factory.

139
00:07:42,360 --> 00:07:45,260
We replaced it with a big electric
motor in the basement of the factory.

140
00:07:45,290 --> 00:07:49,370
And a lot of companies did that. That
was kind of a no brainer. Um, people who,

141
00:07:49,460 --> 00:07:53,900
what we learned from business history
is that the companies and leaders and

142
00:07:53,901 --> 00:07:56,660
business leaders who grew
up in the era of Steve,

143
00:07:57,260 --> 00:07:59,660
it's not that they are unwilling
to invest in electricity.

144
00:07:59,810 --> 00:08:03,680
It's not that they thought electricity
sucked. It's that honestly they could not,

145
00:08:03,681 --> 00:08:08,681
their minds did not admit the possibility
of an overhead crane or a conveyor

146
00:08:09,171 --> 00:08:13,070
belt or an assembly line.
These things did not make sense.

147
00:08:13,190 --> 00:08:16,520
If you had a factory powered by belts
and shafts and pulleys and steam in the

148
00:08:16,521 --> 00:08:18,650
basement.
This was just crazy talk.

149
00:08:18,860 --> 00:08:21,950
And you can go back and read
the literature from those
early decades of the 20th

150
00:08:21,951 --> 00:08:22,610
century.

151
00:08:22,610 --> 00:08:26,900
And there are these vicious debates about
should we put a motor on every machine

152
00:08:26,901 --> 00:08:29,900
in the factory?
Like that was nutty for decades,

153
00:08:30,050 --> 00:08:32,210
even though it's completely
obvious in retrospect.

154
00:08:32,360 --> 00:08:35,480
So the homework that Eric
and I had for ourselves, um,

155
00:08:35,930 --> 00:08:37,550
wants to think of these days.

156
00:08:37,551 --> 00:08:41,300
What are the equivalents of overhead
cranes and assembly lines and conveyor

157
00:08:41,301 --> 00:08:45,080
belts that forward thinking
companies are on top of.

158
00:08:45,440 --> 00:08:49,790
And that ones who are trapped in previous
mindsets and previous ways of thinking

159
00:08:49,940 --> 00:08:53,610
are just not going to see. And that
led to our three part answer. We,

160
00:08:53,611 --> 00:08:55,980
I see a lot of companies
underestimating the power of

161
00:08:55,980 --> 00:08:56,813
machines.

162
00:08:56,940 --> 00:09:00,450
A lot of companies underestimating the
power of platforms and a lot of companies

163
00:09:00,451 --> 00:09:03,150
not doing a great job of tapping
into the crowd out there.

164
00:09:03,990 --> 00:09:04,280
Yeah.

165
00:09:04,280 --> 00:09:05,540
So if a company like ours,

166
00:09:05,541 --> 00:09:08,840
we feel very much in the middle
of a lot of these phenomena. They,

167
00:09:08,940 --> 00:09:13,130
you start your blog with example of
Alphago with deep mind, the platform.

168
00:09:13,131 --> 00:09:15,860
Obviously we have a number of
different things that a platform like

169
00:09:15,861 --> 00:09:18,950
characteristics, android and a
lot of others. And even on crowd,

170
00:09:18,951 --> 00:09:22,250
you can argue that Google search is the
greatest man machine collaboration in

171
00:09:22,251 --> 00:09:26,000
history as people will use our systems
and and improve the systems through their,

172
00:09:26,001 --> 00:09:28,730
their clicks. Right. So what
would be your advice for Google?

173
00:09:28,731 --> 00:09:29,690
What do you think we're getting wrong?

174
00:09:29,720 --> 00:09:31,220
What do you think we should
be doing differently?

175
00:09:33,890 --> 00:09:36,530
And I see we're just about out of time.
Thank you all for coming.

176
00:09:37,740 --> 00:09:41,340
You do it. A lot of things
right. And so I think that it,

177
00:09:41,460 --> 00:09:44,580
one of the risks is that in a way
you may become too successful.

178
00:09:44,760 --> 00:09:47,460
And I think one of the things that we
don't talk that much about in the book,

179
00:09:47,461 --> 00:09:51,900
but I think we're going to see is
that as we get more of a winner take,

180
00:09:51,901 --> 00:09:56,730
most economy and very successful companies
are able to use these technologies to

181
00:09:56,731 --> 00:09:57,890
dominate market after market.

182
00:09:57,891 --> 00:10:01,530
Cause they understand those three
platforms and other companies are just

183
00:10:01,531 --> 00:10:04,800
beginning to get them.
Then there can be a backlash.

184
00:10:04,830 --> 00:10:09,190
And I'm in a push back against that. And
one of the questions is, you know, um,

185
00:10:09,240 --> 00:10:11,580
what kind of economy
are we in going forward?

186
00:10:11,600 --> 00:10:15,610
Is it one where there's a monopoly
capitalism or is it, what is,

187
00:10:15,640 --> 00:10:16,600
we've talked about in the book,

188
00:10:16,601 --> 00:10:21,090
got more of a shipper Tyrian creative
destruction where there's always the risk

189
00:10:21,091 --> 00:10:25,850
of a, of one platform being displaced
by another. But understanding this, uh,

190
00:10:25,870 --> 00:10:29,220
the economics are a little bit different
in a world where there are very strong

191
00:10:29,221 --> 00:10:32,070
network effects or even
two sided network effects.

192
00:10:32,310 --> 00:10:37,080
And there were some big scale economies
and very rapid technological change and

193
00:10:37,081 --> 00:10:39,170
that's something that I know
that you very much on top of him,

194
00:10:39,171 --> 00:10:42,300
he was understanding and those
kinds of dynamics. And uh,

195
00:10:42,390 --> 00:10:45,660
and relatedly,
something we touched on the last book,

196
00:10:45,900 --> 00:10:48,150
is this winner take all or
where did it take most dynamic?

197
00:10:48,260 --> 00:10:51,570
It doesn't just apply to companies,
they can apply to individuals as well.

198
00:10:51,571 --> 00:10:55,370
So we're seeing growing inequality on
a lot of different dimensions in it.

199
00:10:55,371 --> 00:10:59,820
It's great as Andy mentioned
that google.org is helping to,

200
00:11:00,110 --> 00:11:00,943
um,

201
00:11:00,990 --> 00:11:05,990
identify business models that can
create more broadly shared prosperity as

202
00:11:06,250 --> 00:11:10,780
mother counterweight against a
world where all of the other, uh,

203
00:11:11,070 --> 00:11:13,890
wealth and perhaps political
power gets more concentrated.

204
00:11:14,220 --> 00:11:15,660
I can't,
I think this is a great question.

205
00:11:15,661 --> 00:11:18,000
I want to answer not
specifically about Google.

206
00:11:18,240 --> 00:11:21,570
What about companies full of smart people
and at the risk of flattering people

207
00:11:21,571 --> 00:11:23,430
in this room and watching us.
Okay.

208
00:11:23,431 --> 00:11:25,230
There are a lot of smart
people working at Google.

209
00:11:25,700 --> 00:11:30,300
The single biggest failure mode that I've
observed related to the content of the

210
00:11:30,301 --> 00:11:32,970
book when it, when I talk to
audiences are very smart people,

211
00:11:33,210 --> 00:11:38,190
is that smart people tend to have an
exaggerated version of a failure mode that

212
00:11:38,370 --> 00:11:39,480
everybody has,

213
00:11:39,810 --> 00:11:44,810
which is to be too fond and too
confident and too reliant on their own

214
00:11:45,000 --> 00:11:49,680
intuition, judgment,
experience, intelligence,

215
00:11:50,040 --> 00:11:53,980
and they are there. They're very often
guilty of some of these cognitive

216
00:11:53,980 --> 00:11:55,810
biases that Eric mentioned,

217
00:11:55,811 --> 00:12:00,790
Nobel prizes that Danny Conoman got a
Nobel prize for figuring out the failure

218
00:12:00,791 --> 00:12:05,080
mode among really smart people is to
trust themselves too much and one of the

219
00:12:05,081 --> 00:12:08,470
points we make, the broad point we make
in the first section of the book is look,

220
00:12:08,471 --> 00:12:09,790
your intuition is awesome.

221
00:12:10,390 --> 00:12:15,390
It is demonstrably buggy and failure
written and it's got all kinds of really

222
00:12:16,211 --> 00:12:18,490
powerful,
pretty bad news failure modes.

223
00:12:18,700 --> 00:12:23,470
The fact that your Iq is well above the
average does not insulate you from that

224
00:12:23,471 --> 00:12:24,970
and in some ways it can make that worse.

225
00:12:24,971 --> 00:12:29,680
Overconfidence bias tends to be worse
among really smart people to the point we

226
00:12:29,681 --> 00:12:32,350
make in the first section of the book
is to hammer that point home and make

227
00:12:32,351 --> 00:12:35,080
people feel bad about themselves.
But then to say, look,

228
00:12:35,081 --> 00:12:39,340
we have these awesome colleagues now
called machines that have very different

229
00:12:39,341 --> 00:12:44,020
failure modes than people do. They're not
inconsistent. They're not overconfident,

230
00:12:44,050 --> 00:12:46,120
but they're really stupid about the world.

231
00:12:46,360 --> 00:12:48,460
There's a wonderful
concept from linguistics.

232
00:12:48,461 --> 00:12:51,230
It's called the intuition
of the native speaker. Um,

233
00:12:51,250 --> 00:12:53,530
I can recognize a faulty,

234
00:12:53,531 --> 00:12:57,820
I'm grammatically fall to English
sentence just in the blink of an eye

235
00:12:57,850 --> 00:12:58,683
immediately.

236
00:12:58,900 --> 00:13:01,780
And people who don't speak English
as a first language can't do that.

237
00:13:02,030 --> 00:13:06,250
The reason I bring that up, we have
native speaker intuition about the world,

238
00:13:06,520 --> 00:13:10,450
or even with all the work you guys are
doing, our machines don't have that yet.

239
00:13:10,690 --> 00:13:14,440
So one of the broad points we try to make
is let's bring together the strengths

240
00:13:14,500 --> 00:13:17,860
of p of minds and machines.
We, if we do that correctly,

241
00:13:17,861 --> 00:13:21,940
I think we can cancel out each other's
failure modes. The big homework,

242
00:13:21,941 --> 00:13:25,480
especially for smart people is to become
more aware of the failure modes of

243
00:13:25,481 --> 00:13:30,370
humanity and more willing
to question yourself. Second
guessed yourself, use data,

244
00:13:30,371 --> 00:13:34,930
use machines to buttress the fee,
the mistakes that are wet ware has.

245
00:13:35,440 --> 00:13:38,860
And there are lessons from the other two
sections of the book as well. I mean,

246
00:13:38,980 --> 00:13:42,580
you guys know joy's law that no
matter what company you work for,

247
00:13:42,880 --> 00:13:45,220
most of the smart people in the
world don't work for your company.

248
00:13:45,221 --> 00:13:49,180
And it's probably even true for Google.
That may be the edge case.

249
00:13:50,110 --> 00:13:51,740
And um,
so it,

250
00:13:51,741 --> 00:13:56,500
it's great that we were just last night
with Anthony Goldbloom co founder of

251
00:13:56,770 --> 00:14:01,360
Kaggle and it's great to
see Google tapping into the
power of the crowd and all

252
00:14:01,361 --> 00:14:04,720
of those smart PFLs or
they're not contributing and
the AI initiatives that are

253
00:14:04,721 --> 00:14:08,710
allowing people to contribute in different
ways and use a tensorflow and other

254
00:14:08,711 --> 00:14:10,500
things to,
to uh,

255
00:14:10,610 --> 00:14:15,220
tap into that crowd knowledge
and on platforms. I mean, yes,

256
00:14:15,221 --> 00:14:18,430
Google has not just one,
but multiple great platforms,

257
00:14:18,431 --> 00:14:20,950
but as we described in the book,
those are constantly evolving.

258
00:14:20,951 --> 00:14:24,430
As the technology changes. There's
always a risk of them being displaced.

259
00:14:24,610 --> 00:14:28,480
And of course there's new ones rising
up as you go from a, as a Syndra pick,

260
00:14:28,481 --> 00:14:32,800
I said a mobile first to an AI first
world, that kind of transition, you know,

261
00:14:32,801 --> 00:14:37,330
Microsoft kind of bottle that going
from desktops to uh, to mobile.

262
00:14:37,480 --> 00:14:40,290
And there's these constant risk. So, um,

263
00:14:40,360 --> 00:14:43,240
because of the rapid change that
that we were just talking about,

264
00:14:43,600 --> 00:14:46,780
you can't sit back and feel like,
okay, we've got the problem solved.

265
00:14:46,781 --> 00:14:49,890
We just had to, we can just
relax. I think the lessons,

266
00:14:49,910 --> 00:14:52,830
all three sections of the
book, um, apply to Google.

267
00:14:53,490 --> 00:14:56,780
Let's talk a little bit about timescale.
We get very excited about this.

268
00:14:56,781 --> 00:14:59,630
We feel it. It's the
ocean we swim in. And yet,

269
00:14:59,750 --> 00:15:02,180
and to your example about electrification,
I,

270
00:15:02,181 --> 00:15:07,181
it took 50 years to disseminate the
effects of electrification through society

271
00:15:07,251 --> 00:15:08,060
and Broadway.

272
00:15:08,060 --> 00:15:12,980
If you look at something like the cell
phone was conceived of in 1947 demoed in

273
00:15:13,280 --> 00:15:18,280
1973 sold in 83 and it really wasn't until
the turn of century or later until it

274
00:15:18,921 --> 00:15:20,330
became widely adopted.

275
00:15:20,600 --> 00:15:24,050
So are we overestimating how quickly
all this is coming along or do you think

276
00:15:24,051 --> 00:15:24,980
this is right around the corner?

277
00:15:25,340 --> 00:15:30,290
I think especially the geekier set is
overestimating how quickly things are

278
00:15:30,291 --> 00:15:31,011
going to happen,

279
00:15:31,011 --> 00:15:34,550
how quickly the cars are going to drive
themselves and we talked to AI in our

280
00:15:34,551 --> 00:15:36,920
homes and everything happens
in the drones deliver stuff.

281
00:15:37,040 --> 00:15:39,680
I think we are overestimating that.
However,

282
00:15:39,681 --> 00:15:43,880
I do think that a lot of people are
underestimating that and there and the

283
00:15:43,881 --> 00:15:46,200
communities that Eric and I tried
to be part of this is an extreme.

284
00:15:46,220 --> 00:15:50,480
There's a super active debate about how
soon as x going to happen and a lot of

285
00:15:50,481 --> 00:15:53,390
people rely on those historical examples
that you just brought up and say, look,

286
00:15:53,391 --> 00:15:55,160
this is a decades long process.

287
00:15:55,370 --> 00:15:58,430
My favorite counter to that
is how old was Facebook?

288
00:15:59,750 --> 00:16:04,750
2000 fourish Facebook has 1.9
billion users around the world,

289
00:16:05,661 --> 00:16:10,661
like close to a third of humanity has
adopted this technology in the space of 15

290
00:16:11,421 --> 00:16:13,880
years.
We have never ever seen this before.

291
00:16:14,060 --> 00:16:19,060
So in a world that is interconnected with
pretty powerful devices and where the

292
00:16:19,071 --> 00:16:22,110
cloud is available on demand more,

293
00:16:22,130 --> 00:16:25,790
almost everywhere and we're really
powerful tools are being put up into the

294
00:16:25,791 --> 00:16:28,790
cloud. The timescales can be
quicker than we're used to

295
00:16:28,920 --> 00:16:31,990
and I would make a distinction
between those two examples you gave.

296
00:16:32,230 --> 00:16:34,930
I think Andy's exactly
right that the technology,

297
00:16:34,931 --> 00:16:38,230
I think it's evolving a lot faster
than than the cell phone did,

298
00:16:38,890 --> 00:16:42,970
but what does it seem to be moving a
lot faster is our ability to adapt the

299
00:16:42,971 --> 00:16:45,940
business process change and
that's what held back electricity,

300
00:16:46,220 --> 00:16:51,220
electricity was the technology was there
for a good several decades before the

301
00:16:52,031 --> 00:16:55,960
factory's reinvented their
business processes and
reinvented their organizations

302
00:16:56,380 --> 00:16:59,010
and there are some technologies
that can be adopted. You know,

303
00:16:59,020 --> 00:17:02,950
without a whole lot of business processes
change like a consumer facing product

304
00:17:02,951 --> 00:17:03,784
like Facebook,

305
00:17:03,820 --> 00:17:08,820
but a lot of the ones that really have
big societal changes are going to require

306
00:17:09,371 --> 00:17:11,650
a lot more adjustment
in self driving cars.

307
00:17:11,651 --> 00:17:15,100
It's going to be not just a matter
of having them navigate the vehicles.

308
00:17:15,101 --> 00:17:19,440
There's a whole set of
laws, ethics customers

309
00:17:20,350 --> 00:17:22,730
keep you up at night
thinking about barriers,

310
00:17:23,900 --> 00:17:26,730
all that ad at Moore's law,
types of speed.

311
00:17:27,120 --> 00:17:31,980
One of the big reasons we really like
geological time, they go backwards.

312
00:17:33,150 --> 00:17:34,710
Hopefully that we can,
we can move it

313
00:17:34,760 --> 00:17:38,330
the dial a little bit in that I think if
people understand how to take advantage

314
00:17:38,331 --> 00:17:41,660
of these technologies, they understand
the process change necessary,

315
00:17:42,330 --> 00:17:44,860
we can make it happen a little bit faster.
Um,

316
00:17:45,200 --> 00:17:48,580
once we give them a bit of a playbook
about what works and what does more,

317
00:17:48,720 --> 00:17:53,280
and it's true that the progress is really
going to be piecemeal, so nationwide,

318
00:17:53,281 --> 00:17:57,360
fully autonomous cars that
that might be a bit off.

319
00:17:57,540 --> 00:18:01,260
We were talking to every node Coachella
yesterday and he brought up that one

320
00:18:01,261 --> 00:18:06,000
company that he's aware of is trying
to just think about automating driving

321
00:18:06,001 --> 00:18:10,560
trucks between what was a Dallas,
Phoenix and Dallas and La. He said,

322
00:18:10,561 --> 00:18:15,060
let's just do that. There's $1 billion of
commerce has, that's $1 billion market.

323
00:18:15,061 --> 00:18:18,180
Just driving trucks back and
forth between those two cities.

324
00:18:18,420 --> 00:18:22,440
Can we get regulatory approval for the
states on the route and can we w w that's

325
00:18:22,441 --> 00:18:22,981
one route.

326
00:18:22,981 --> 00:18:26,580
We know how to map that pretty easily so
that can happen pretty quickly and part

327
00:18:26,581 --> 00:18:31,581
of it was not do all the little side
street onto the highway and then tech some

328
00:18:31,951 --> 00:18:33,360
person to show up and drive it.

329
00:18:33,870 --> 00:18:37,980
It's going to take a while to completely
rewire and put sensors all over the

330
00:18:37,981 --> 00:18:41,310
electric grid and get the efficiencies
that we, that we're hoping for with that.

331
00:18:41,550 --> 00:18:42,690
At the same time,

332
00:18:42,810 --> 00:18:46,590
the thought experiment that I run is how
much work would it be for some kind of

333
00:18:46,591 --> 00:18:49,620
industrial facility to
slap sensors on everything,

334
00:18:50,010 --> 00:18:53,670
give it to tensor flow and
maybe get the kind of um,

335
00:18:53,700 --> 00:18:58,230
15 ish percent step change improvement
that the Google data centers saw when

336
00:18:58,231 --> 00:19:02,520
they turned over operations to a
cousin of the Alphago Technology.

337
00:19:02,610 --> 00:19:04,860
So they're are going to be,
they're going to be relatively quick,

338
00:19:04,861 --> 00:19:08,040
big wins happening all over the economy,
I think.

339
00:19:08,700 --> 00:19:11,220
Now let's talk a little bit about
the social implications of that.

340
00:19:11,520 --> 00:19:14,460
Something that you covered in depth in
second machine age but continues to be

341
00:19:14,461 --> 00:19:17,250
very relevant when you're talking
about driverless cars immediately.

342
00:19:17,280 --> 00:19:21,540
There's concern about employment
transition and displacement.
Uh, they're sort of,

343
00:19:21,541 --> 00:19:25,680
the standard response is more
more training and perhaps
either earned income tax

344
00:19:25,681 --> 00:19:27,450
credit or a universal basic income.

345
00:19:27,840 --> 00:19:31,500
Your training has been kind
of a mixed success rate.

346
00:19:31,501 --> 00:19:35,700
They're not a lot of great case studies
there. People trying to do new things, uh,

347
00:19:35,701 --> 00:19:38,340
online training and the like
interested in your thoughts on that.

348
00:19:38,341 --> 00:19:42,030
And we're generally on the balance between
our need for growing productivity as

349
00:19:42,040 --> 00:19:46,620
our workforce ages and potential impacts
on social structures and implement.

350
00:19:47,490 --> 00:19:48,510
There's no silver bullet.

351
00:19:48,940 --> 00:19:51,610
Um, and I think there are a lot of
people, you know, it was wonderful.

352
00:19:51,640 --> 00:19:52,970
You'd be looking far enough ahead.

353
00:19:53,090 --> 00:19:55,100
It's going to be very hard
for education to keep up.

354
00:19:55,160 --> 00:19:58,520
But I think where we are right now in
2017 and as far as I can come in the next

355
00:19:58,521 --> 00:20:02,870
five, 10 more years of training
and education is probably the,

356
00:20:02,871 --> 00:20:07,790
at the top of my list. And I think most,
most economists list, not mine. Okay.

357
00:20:08,690 --> 00:20:10,910
So Andy can end.
It can weigh in on that,

358
00:20:11,060 --> 00:20:12,980
but there's different kinds
of training education.

359
00:20:12,981 --> 00:20:16,560
So some of them give very specific
tasks. You know what? What's a bashing?

360
00:20:16,570 --> 00:20:18,020
Throwing a couple of doing it you Udacity,

361
00:20:18,140 --> 00:20:22,040
you know you can learn some skills quite
rapidly. Add a great deal of value.

362
00:20:22,041 --> 00:20:25,880
Tom Kahleel described something that
Darpa did call it the education dominance

363
00:20:25,881 --> 00:20:28,380
program that in 90 or
120 days when people,

364
00:20:28,400 --> 00:20:32,120
people some very concrete skills
that massively increased their value,

365
00:20:32,450 --> 00:20:36,740
the more lasting skills are going to be
the ones around interpersonal skills,

366
00:20:36,741 --> 00:20:39,470
creativity, teamwork, persuasion,

367
00:20:39,471 --> 00:20:42,560
some of the softer skills that
machines aren't very good at.

368
00:20:42,620 --> 00:20:46,190
I don't think our schools are doing a
very good job of teaching those are or

369
00:20:46,250 --> 00:20:49,900
worst yet. I think many of we're actually
crushing, crushing them, crushing them,

370
00:20:49,901 --> 00:20:51,490
and making them less salient.

371
00:20:51,760 --> 00:20:54,670
So if how many of us feel like we had
some of the love of learning crushed on of

372
00:20:54,671 --> 00:20:58,080
us by your education? Just honestly
show hands, way up in the air.

373
00:20:58,081 --> 00:21:01,000
Please look around the
room. Yeah, this is a crime.

374
00:21:01,030 --> 00:21:04,280
This is a crime because I think most
kids actually, they love being, you know,

375
00:21:04,281 --> 00:21:06,100
to put a pile of blocks in
front of a three year old,

376
00:21:06,101 --> 00:21:09,700
the first thing they'll do
is stop building something
or, or crayons, kit kids,

377
00:21:09,730 --> 00:21:14,560
humans love creating. And if we could
nurture that and let that flourish,

378
00:21:14,740 --> 00:21:16,680
that is what machines are not very good.
Uh,

379
00:21:16,870 --> 00:21:18,670
playing and interacting with other people.
Teamwork.

380
00:21:18,671 --> 00:21:20,280
That's what machines aren't very good at.

381
00:21:20,470 --> 00:21:23,230
So it's not just a matter of
spending more and educational,

382
00:21:23,231 --> 00:21:24,760
but I don't think that would hurt.
I think it would help,

383
00:21:24,940 --> 00:21:27,940
but it's a matter of more
fundamentally reinventing education.

384
00:21:28,180 --> 00:21:32,170
There are so many tasks in our
economy still that only humans can do.

385
00:21:32,171 --> 00:21:34,360
And that's the way it's
going to be for a while.

386
00:21:34,450 --> 00:21:36,790
So I'm not ready to
write off human skills.

387
00:21:36,791 --> 00:21:40,210
I think we should invest and make people
ready to do all those different kinds

388
00:21:40,211 --> 00:21:44,950
of human tasks in healthcare, education,
childcare, um, creative works.

389
00:21:45,060 --> 00:21:47,620
And, and that's going to be
the way that we, I think we,

390
00:21:47,830 --> 00:21:50,490
one of the ways we create more shared
prosperity. But you may disagree.

391
00:21:50,590 --> 00:21:54,240
I agree with everything you just said.
Here's why I disagree with um,

392
00:21:54,310 --> 00:21:58,270
with an education reform first
approach to fixing things.

393
00:21:58,420 --> 00:22:01,150
My thought experiment is let's say there
is a pot of money available and you

394
00:22:01,151 --> 00:22:03,430
could do only one thing with it.

395
00:22:03,570 --> 00:22:06,430
And I have three kind of
prime candidates in my mind.

396
00:22:06,550 --> 00:22:09,730
Number one is reform education and let's
say it's going to cost something didn't,

397
00:22:09,980 --> 00:22:13,650
what number was that? What the, the amount
of money, you know, what number was that?

398
00:22:13,651 --> 00:22:17,610
That was number one. Not In,
not in descending order. Okay.

399
00:22:18,180 --> 00:22:21,010
A is perform education.

400
00:22:21,100 --> 00:22:25,030
Option B is to figure out
why entrepreneurship in
America has been on a long

401
00:22:25,031 --> 00:22:25,421
slow,

402
00:22:25,421 --> 00:22:30,421
steady decline and reverse that option
c is to bring our infrastructure up from

403
00:22:31,391 --> 00:22:34,420
a grade of d plus two,
maybe a solid B.

404
00:22:35,080 --> 00:22:38,530
I would actually take either
option B or c over option A.

405
00:22:38,531 --> 00:22:42,370
I'm not saying that I'm right and I'm not
saying it's a no brainer, but I would,

406
00:22:42,371 --> 00:22:45,100
I would love to solve either
of those latter two problems.

407
00:22:45,101 --> 00:22:49,140
First I fall back on something
that Larry Summers says, um,

408
00:22:49,210 --> 00:22:52,840
in his inimitable fashion, whenever
somebody brings up education, he said,

409
00:22:52,841 --> 00:22:57,580
education reform is kind of a dodge,
and unless we grow the economy faster,

410
00:22:57,760 --> 00:23:00,400
we're not going to be doing
a lot for jobs and wages.

411
00:23:00,460 --> 00:23:03,970
That's a very strong way to say it.
But to grow the economy faster,

412
00:23:03,971 --> 00:23:07,840
I would love to figure out
why entrepreneurship is
sucking in America and I

413
00:23:07,841 --> 00:23:09,340
would love to fix our infrastructure,

414
00:23:09,341 --> 00:23:11,410
which is just the biggest
no brainer out there.

415
00:23:11,560 --> 00:23:14,170
But the good news is we don't have
to choose just, it's one of those,

416
00:23:14,200 --> 00:23:16,920
I think that there is no
silver bullet. As I said, it's,

417
00:23:16,990 --> 00:23:20,230
we should be doing all of these
things simultaneously and some of them

418
00:23:20,260 --> 00:23:23,260
government can help with a lot of these
we can do without having government

419
00:23:23,261 --> 00:23:26,350
involvement and maybe, you know, depending
on which way the winds are blowing,

420
00:23:26,410 --> 00:23:29,170
it may be that we have to take more
responsibility as individuals or as

421
00:23:29,171 --> 00:23:32,860
organizations to step out some up on
some of these other dimensions. Yeah,

422
00:23:32,890 --> 00:23:35,380
I completely agree with that.
Without a reservation this time.

423
00:23:35,381 --> 00:23:37,150
And one of the really encouraging things,
sorry,

424
00:23:37,930 --> 00:23:40,960
one of the really encouraging things in
education as the rise of these really

425
00:23:40,961 --> 00:23:45,410
alternative ways to get really powerful
skills to get credentials and designal

426
00:23:45,411 --> 00:23:46,100
signal how good

427
00:23:46,100 --> 00:23:47,300
you are at stuff.

428
00:23:47,330 --> 00:23:51,620
That's a case where the government has
been lagging in many cases and in fact

429
00:23:51,621 --> 00:23:54,860
because student loans are only
given two accredited institutions,

430
00:23:55,010 --> 00:23:58,010
in some ways the government is
impeding progress in these areas.

431
00:23:58,011 --> 00:24:00,710
Now I don't think I'm a frothing
at the mouth libertarian,

432
00:24:00,711 --> 00:24:03,140
but I would like to see
that situation change.

433
00:24:04,490 --> 00:24:08,780
So let me ask one more question then
open it up to questions from all of you.

434
00:24:08,781 --> 00:24:09,950
We don't have mics around the room,

435
00:24:09,951 --> 00:24:12,980
so please just shout out the
question will repeat it back.

436
00:24:12,981 --> 00:24:14,840
So we catch that on the
mic and for people remotely

437
00:24:15,580 --> 00:24:17,510
a desk SAS question two
is your way to get it?

438
00:24:17,570 --> 00:24:20,780
Yes. So I was going to say, so
Andrew has the dory available,

439
00:24:20,870 --> 00:24:23,750
which is running a constant number of
questions and actually voting on those

440
00:24:23,751 --> 00:24:26,570
questions. So then you have
a retinal implant. Exactly.

441
00:24:27,800 --> 00:24:30,940
Solid tensorflow with lumps.
Questions will surface the top, but,

442
00:24:31,100 --> 00:24:33,680
but let me step back before
we open it up to everybody.

443
00:24:33,800 --> 00:24:35,570
And that's about the global
implications of this.

444
00:24:35,571 --> 00:24:40,130
I mean there've been some have
argued that the growing use of robots

445
00:24:40,140 --> 00:24:44,180
industrialization is blocking paths to
development of tradition that available

446
00:24:44,181 --> 00:24:46,720
for evolving countries.
During that,

447
00:24:46,740 --> 00:24:50,450
some old glue argues that every time you
employ a robot you don't employ three

448
00:24:50,451 --> 00:24:53,330
to five people. Uh, what,
what's your take on that?

449
00:24:53,331 --> 00:24:54,680
How do you see this playing out globally?

450
00:24:54,800 --> 00:24:57,080
Well, it's such in the global
one first. Those are Andy and I,

451
00:24:57,081 --> 00:24:58,190
along with Michael Spence,

452
00:24:58,191 --> 00:25:02,900
one of our friendly Nobel prize winning
colleagues wrote an article about some

453
00:25:02,901 --> 00:25:04,920
of the implications for globalization.
And,

454
00:25:05,180 --> 00:25:09,260
and that was a couple of years ago in
foreign affairs and we talked about this

455
00:25:09,261 --> 00:25:11,090
challenge that in many ways,

456
00:25:11,091 --> 00:25:14,480
although technology has been one
of the best things that happens,

457
00:25:14,481 --> 00:25:16,040
it happened to have open.
As you probably know,

458
00:25:16,041 --> 00:25:19,550
there are a lot fewer people in poverty
now than there were 20 years ago.

459
00:25:19,551 --> 00:25:21,230
And the tr a lot of the
trends are very good.

460
00:25:21,400 --> 00:25:23,180
If you look a little
further into the future,

461
00:25:23,420 --> 00:25:27,620
there's some storm clouds and in
particular countries that are right now,

462
00:25:27,621 --> 00:25:31,520
depending on manufacturing have to be
that engine to lift them out of poverty

463
00:25:31,820 --> 00:25:34,550
are very much in the bullseye
of a lot of the automation.

464
00:25:34,551 --> 00:25:39,551
You go visit new China and you see
thousands of people working side by side

465
00:25:39,831 --> 00:25:41,720
doing very routine simple tasks,

466
00:25:41,721 --> 00:25:45,680
tasks that a lot of you
guys could probably write
up some code to get in about

467
00:25:45,681 --> 00:25:49,160
20 minutes to do those tasks.
And you know,

468
00:25:49,220 --> 00:25:53,060
those workers were able to compete very
effectively against American or German

469
00:25:53,061 --> 00:25:54,950
or Swiss workers by lower wages.

470
00:25:55,160 --> 00:25:58,190
But you don't want to be competing on
the basis of wages against a robot.

471
00:25:58,430 --> 00:26:02,090
And so that means that that middleclass
that's been created in a lot of

472
00:26:02,091 --> 00:26:05,660
developing countries is not going to
have to compete with robots that can work

473
00:26:05,661 --> 00:26:09,020
for $4 $2 $1 an hour equivalent.

474
00:26:09,350 --> 00:26:11,060
And that's not a good place to be.

475
00:26:11,061 --> 00:26:15,470
They need to leap frog to a situation
where they're doing more of that creative

476
00:26:15,471 --> 00:26:17,900
and interpersonal work. You
know, for better or worse,

477
00:26:17,960 --> 00:26:21,980
there's not that many manufacturing
workers in American factors anymore.

478
00:26:22,040 --> 00:26:24,950
I mean it's less than 10% of
the workforce you go into.

479
00:26:24,951 --> 00:26:26,540
Most factories it's kind of lights out.

480
00:26:26,780 --> 00:26:31,780
So we are in some ways less going to be
less effected by that kind of automation

481
00:26:32,420 --> 00:26:35,690
of factory work.
Then those developing countries,

482
00:26:35,691 --> 00:26:38,570
and it may make it harder for
them to make that transition.

483
00:26:38,780 --> 00:26:42,740
Some countries like China, they have a
very sophisticated tech economy as well,

484
00:26:42,741 --> 00:26:47,250
so they're got a good chunk of the people
on the other side of that curve. Uh,

485
00:26:47,251 --> 00:26:50,710
other countries like Vietnam,
the Philippines, I'm going
to have a harder time

486
00:26:50,920 --> 00:26:53,740
metro position.
The way I look at your question,

487
00:26:53,741 --> 00:26:56,110
there are two unmistakable big,

488
00:26:56,111 --> 00:27:00,170
big global trends related to the things
that we're talking about. One is,

489
00:27:00,171 --> 00:27:02,380
is betterment has improvement
in the human condition.

490
00:27:02,381 --> 00:27:05,920
We've had the largest declines in dire
poverty that we've ever seen around the

491
00:27:05,921 --> 00:27:06,191
world.

492
00:27:06,191 --> 00:27:09,310
We've had the biggest increases in human
health in recent decades that we've

493
00:27:09,311 --> 00:27:12,490
ever seen around the world. Do you all
know if the site, our world and data,

494
00:27:12,960 --> 00:27:15,100
this is, this is my favorite
side, cause you walk away,

495
00:27:15,101 --> 00:27:18,640
just happy after you go look
at almost any aspect of it.

496
00:27:18,910 --> 00:27:21,850
So the first one is that the
world almost without exception,

497
00:27:21,910 --> 00:27:24,610
is getting better in the areas that
we care about. That's the first trend.

498
00:27:24,820 --> 00:27:26,380
The second one is concentration.

499
00:27:26,500 --> 00:27:30,370
And when it gets to this notion that we
are doing more and more manufacturing

500
00:27:30,371 --> 00:27:32,500
and a smaller and smaller
geographic footprint,

501
00:27:32,650 --> 00:27:34,660
a smaller and smaller
employment footprint,

502
00:27:34,720 --> 00:27:37,480
a smaller and smaller number of companies,
footprint,

503
00:27:37,660 --> 00:27:40,870
wealth is getting more concentrated,
income is getting more concentrated.

504
00:27:40,930 --> 00:27:44,740
It almost doesn't matter where you look.
This trend is really pronounced. Now,

505
00:27:44,770 --> 00:27:48,520
I don't know if those two trends are
going to continue to interact kind of

506
00:27:48,760 --> 00:27:49,593
happily,

507
00:27:49,720 --> 00:27:53,710
or if there's kind of a clash of the
titans that's coming when these costs

508
00:27:53,711 --> 00:27:55,600
declines.
Implicit in Moore's law,

509
00:27:55,690 --> 00:27:59,260
meet rising wages in Bangladesh
and China and places like that,

510
00:27:59,320 --> 00:28:02,380
those two trends could run kind
of headlong into each other.

511
00:28:02,410 --> 00:28:04,000
I don't know that's
what's going to happen,

512
00:28:04,150 --> 00:28:07,570
but that's something to keep our eyes on.
Okay.

513
00:28:07,571 --> 00:28:11,230
So let's open it up to the room and is
ready if we're going to have questions.

514
00:28:11,231 --> 00:28:13,060
But first,
so the question

515
00:28:13,690 --> 00:28:18,690
on one hand we see increasing returns to
scale and perhaps more concentration of

516
00:28:18,941 --> 00:28:23,020
wealth. Uh, certainly we have seen that
and the other hand we see this decline in

517
00:28:23,021 --> 00:28:27,850
productivity and are those
two not a client productivity,
let me be more precise,

518
00:28:28,240 --> 00:28:31,390
a slower rate of political creativity,
growth. It's still growing. Um,

519
00:28:31,400 --> 00:28:33,220
and are these possibly connected?

520
00:28:33,430 --> 00:28:36,160
And I think there are some
people who are making that case,

521
00:28:36,161 --> 00:28:40,060
Joe Stiglitz and others that there's
this in Grice of a rentier economy,

522
00:28:40,061 --> 00:28:43,270
people a red seeking.
I don't see it quite yet.

523
00:28:43,271 --> 00:28:46,630
It's something I'd like to keep
my eyes open and take a look at.

524
00:28:46,970 --> 00:28:50,110
I think that some of the areas
where you're seeing these, uh,

525
00:28:50,200 --> 00:28:53,380
increasing returns to scale actually
some of the more dynamic parts of the

526
00:28:53,381 --> 00:28:55,060
economy.
So I would look elsewhere.

527
00:28:55,061 --> 00:28:57,640
If you look at the part where
there's been less entrepreneurship,

528
00:28:57,760 --> 00:29:00,010
where there are fewer a young new firms,

529
00:29:00,220 --> 00:29:03,270
they're not in those parts of the
economy where we're seeing, uh,

530
00:29:03,460 --> 00:29:07,030
the network effects and so forth.
So I would look to other things.

531
00:29:07,031 --> 00:29:09,880
There's issues around
occupational licensing,

532
00:29:09,970 --> 00:29:11,590
there's just the aging of the workforce.

533
00:29:11,591 --> 00:29:15,370
And I see everyone here is pretty young
but, but sadly when people get older,

534
00:29:15,371 --> 00:29:18,430
they don't get to be as entrepreneurial
as there are old people working in

535
00:29:18,431 --> 00:29:18,881
America.

536
00:29:18,881 --> 00:29:22,040
I know that's weird for you all and most
of them are not starting companies. Um,

537
00:29:22,260 --> 00:29:27,220
and so, so that's part of it. Um, it is,
it is obviously a little bit of a mystery.

538
00:29:27,221 --> 00:29:29,320
The people who've studied this
like John Hall to Ang and other,

539
00:29:29,500 --> 00:29:32,710
they're not quite sure what's
going on there in terms of that,

540
00:29:32,890 --> 00:29:36,460
that effect in terms of the other
drivers or productivity growth,

541
00:29:36,461 --> 00:29:39,190
why I think we see, we'd be
talking about these wonders things.

542
00:29:39,520 --> 00:29:42,760
The other thing we have to bear in mind
is most of them haven't really hit the

543
00:29:42,761 --> 00:29:44,950
marketplace yet. You know,
Andy and I rode in a,

544
00:29:44,951 --> 00:29:47,980
in a self driving car the first book
and, and again, you know more recently,

545
00:29:48,520 --> 00:29:52,420
which is a lot of fun, but they're not
a whole lot of them out there on the,

546
00:29:52,421 --> 00:29:56,500
on the highways or most of the other
amazing technologies. We're excited,

547
00:29:56,501 --> 00:30:00,550
I think folks in Silicon Valley excited
cause we can see what's in the pipeline.

548
00:30:01,090 --> 00:30:05,020
But in terms of measurable effects on
Productivity Right now we are really

549
00:30:05,021 --> 00:30:09,160
harvesting more what happened in
the 1990s in terms of technology.

550
00:30:09,310 --> 00:30:11,080
I mean back in 1997,

551
00:30:11,470 --> 00:30:14,500
the same Silicon Valley folks
who are excited about ecommerce,

552
00:30:15,020 --> 00:30:17,530
but did it really make a dent
on traditional retailing?

553
00:30:17,560 --> 00:30:19,600
Not until 2017 and you know,

554
00:30:19,601 --> 00:30:22,300
the past couple of weeks you've
been reading a lot about that.

555
00:30:22,450 --> 00:30:26,200
So there's a pretty significant lag
between when you see these wondrous

556
00:30:26,201 --> 00:30:30,040
technologies and when they're going to
show up in the productivity statistics.

557
00:30:30,280 --> 00:30:35,050
And um, that I think is probably more of
the explanation behind some of those two

558
00:30:35,051 --> 00:30:35,890
trends.
You describe it.

559
00:30:35,970 --> 00:30:40,380
We have a rockstar colleague back in
MIT named John Van Reenan who dove into

560
00:30:40,381 --> 00:30:44,160
exactly the question that you're asking
and he documented that in industry after

561
00:30:44,161 --> 00:30:48,240
industry there are the superstar firms
that are appearing a small number of them.

562
00:30:48,450 --> 00:30:50,490
They're sucking up a lot of the revenue,

563
00:30:50,940 --> 00:30:55,020
lots and lots of the profits in industry
after industry, not just in high tech.

564
00:30:55,260 --> 00:30:59,100
And he says that might explain some
of the trends that you brought up.

565
00:30:59,101 --> 00:31:00,900
So the interesting thought experiment,

566
00:31:00,901 --> 00:31:04,710
is Amazon good or bad for
overall retail productivity?

567
00:31:05,640 --> 00:31:08,790
And the initial, my initial answer
is going to be awesome for it. Well,

568
00:31:08,791 --> 00:31:13,230
if all the other companies in retail
are seeing slowly eroding revenue and

569
00:31:13,231 --> 00:31:15,480
they're not laying off
people in droves yet,

570
00:31:15,690 --> 00:31:19,590
then overall productivity for that
sector could actually be a slowing down,

571
00:31:19,591 --> 00:31:23,640
are declining because of Amazon's
sucking all the energy up into one really

572
00:31:23,641 --> 00:31:26,190
concentrated place.
So the data,

573
00:31:26,220 --> 00:31:29,160
we got to dive deeper in it since
a fundamentally important question.

574
00:31:29,310 --> 00:31:32,750
And there are a couple of
different promising lines
of, of uh, of research and,

575
00:31:32,950 --> 00:31:35,460
or to just touch on briefly that
the Amazon one reminds me of is,

576
00:31:35,520 --> 00:31:37,570
is this a measurement issue as well?

577
00:31:37,600 --> 00:31:42,310
That our GDP statistics are
just horrifically bad at
capturing the value of free

578
00:31:42,311 --> 00:31:43,144
goods like

579
00:31:43,180 --> 00:31:46,900
Google, basically a lot of others. You
all shrink GDP. Did you realize that?

580
00:31:47,060 --> 00:31:51,010
Stop it when you take Britannica. I
turned into Wikipedia. GDP goes down.

581
00:31:51,010 --> 00:31:51,910
Wow.
But welfare,

582
00:31:51,911 --> 00:31:56,911
it goes up and Amazon is providing
a lot more product variety choice,

583
00:31:57,640 --> 00:31:59,750
timeliness. Um, and,

584
00:32:00,000 --> 00:32:02,650
and none of those shorts in
the GDP statistics either.

585
00:32:02,651 --> 00:32:04,540
So we have a bit of a mismatch.

586
00:32:04,590 --> 00:32:07,120
You go back to Simon Kuznets
who invented the GDP,

587
00:32:07,121 --> 00:32:10,330
one of the great inventions of the 20th
century, uh, Paul Samuelson said, um,

588
00:32:10,600 --> 00:32:12,700
one of the first things he said was,
please,

589
00:32:12,701 --> 00:32:16,540
please do not use this as a measure of
welfare. It is a measure of production.

590
00:32:16,570 --> 00:32:18,190
It's not a measure of
how well we're doing,

591
00:32:18,430 --> 00:32:22,390
but of course the first thing everybody
started doing was assuming GDP equals

592
00:32:22,391 --> 00:32:25,170
welfare. And, and that's just
mathematically wrong. Yeah.

593
00:32:25,270 --> 00:32:28,530
We should cut over to the Bhutanese
model of gross national happiness.

594
00:32:28,620 --> 00:32:29,680
If you go too far,

595
00:32:29,710 --> 00:32:33,730
I mean I think one of the problems is
that the nice thing about GDP is you can

596
00:32:33,731 --> 00:32:36,130
measure it to like nine
significant digits and it's very,

597
00:32:36,131 --> 00:32:40,280
very satisfying to be able to
each quarter and you can decompose

598
00:32:40,280 --> 00:32:41,330
it for other things.

599
00:32:41,840 --> 00:32:45,990
It went up to quite low. Sorry,
it was 2.4% and that and you know,

600
00:32:46,020 --> 00:32:47,520
gross national happiness,
you know,

601
00:32:47,580 --> 00:32:49,650
I'd be lucky if they get the first
significant digit, right? Yeah.

602
00:32:49,950 --> 00:32:50,190
You,

603
00:32:50,190 --> 00:32:53,790
you're coming about the aging population
and productivity reminds me of a most

604
00:32:53,791 --> 00:32:54,870
astonishing statistic.

605
00:32:54,871 --> 00:32:59,580
I've seen perhaps this year that within
three decades if taking out Africa and

606
00:32:59,581 --> 00:33:02,370
population growth there for the rest
of the world within three decades,

607
00:33:02,371 --> 00:33:06,810
the average age of humans on the planet
earth will be 60 years old. Wow. Wow.

608
00:33:07,140 --> 00:33:11,160
That is a dramatic change in the ratio
of productive people in the workforce

609
00:33:11,161 --> 00:33:15,750
unless they useful the time and workforce
changes dramatically and requires an

610
00:33:15,751 --> 00:33:18,010
awful lot more productivity to help adjust

611
00:33:18,340 --> 00:33:20,650
and there that there may
be a good thing to know.

612
00:33:20,651 --> 00:33:22,720
Rod Brooks and others have
really emphasized this,

613
00:33:22,721 --> 00:33:26,260
that let's bring on the robots as fast
as we can so they can help take care of

614
00:33:26,261 --> 00:33:27,190
us at our old age.

615
00:33:27,330 --> 00:33:28,090
Yep.

616
00:33:28,090 --> 00:33:29,760
So Andrew,
question from the Dory.

617
00:33:32,030 --> 00:33:35,140
All right, so we have a question from
Miguel who's in New York and he asks,

618
00:33:35,290 --> 00:33:37,390
given your research and the
rates of technological change,

619
00:33:37,391 --> 00:33:39,310
what are your thoughts on
universal basic income?

620
00:33:39,610 --> 00:33:41,550
Reeducating everyone should be legal,

621
00:33:41,580 --> 00:33:45,550
but at this can take years or not happen
given the emergence and multiple pilots,

622
00:33:45,551 --> 00:33:47,800
do you think of ubi as
a potential solution?

623
00:33:48,600 --> 00:33:49,433
Uh,

624
00:33:50,140 --> 00:33:52,660
absolutely.
People should be researching ubi.

625
00:33:52,661 --> 00:33:55,660
I think the experiments that are happening
in Finland are really interesting.

626
00:33:55,661 --> 00:33:58,840
I think what y Combinator is doing is
pretty interesting. By all means, let,

627
00:33:58,930 --> 00:33:59,980
let's do the research.

628
00:34:00,190 --> 00:34:03,910
Let me tell you why I'm skeptical
about a universal basic income and it's

629
00:34:03,911 --> 00:34:08,320
extremely straight forward.
A UBI in its most classic form,

630
00:34:08,500 --> 00:34:11,770
provides no direct incentive,
no direct encouragement to work.

631
00:34:12,100 --> 00:34:15,820
And as Eric and I have gone on with
the work, I've become a, with our work,

632
00:34:16,000 --> 00:34:18,190
I become a fanatic about work,

633
00:34:18,191 --> 00:34:22,240
about the value of the importance
of something like a job,

634
00:34:22,660 --> 00:34:25,960
not for some kind of old
fashioned Protestant work
ethic reason I don't think.

635
00:34:26,020 --> 00:34:29,800
But because the evidence is overwhelming
that when work leaves a community,

636
00:34:30,220 --> 00:34:33,040
bad things happen. Not
good things. There's,

637
00:34:33,190 --> 00:34:35,500
the research is just overwhelming on this.

638
00:34:35,740 --> 00:34:39,700
You see marriages fall apart,
you see couples not getting married,

639
00:34:39,701 --> 00:34:41,530
you see kids not being
raised in nuclear homes.

640
00:34:41,530 --> 00:34:44,740
You can think so what you see
crime going up. No, that's pretty,

641
00:34:44,741 --> 00:34:47,210
that's pretty unambiguous. So what, um,

642
00:34:47,680 --> 00:34:52,680
a lot of us know that an Deaton and Ann
caissons and Angus Angus Deaton and Ann

643
00:34:53,560 --> 00:34:54,090
Case,
uh,

644
00:34:54,090 --> 00:34:58,750
highlight of this crazy phenomenon that
we were unaware of until recently that,

645
00:34:58,770 --> 00:35:01,360
uh, death rates, mortality
rates among white,

646
00:35:01,361 --> 00:35:05,170
middle aged Americans are actually
increasing instead of decreasing.

647
00:35:05,440 --> 00:35:09,340
And the reason they're
increasing is because of what
they call deaths of despair,

648
00:35:09,730 --> 00:35:14,680
suicide, chronic liver disease,
alcoholism and drug overdoses.

649
00:35:15,070 --> 00:35:17,830
I can't tell a happy story about that.
Those vessels,

650
00:35:17,860 --> 00:35:21,880
the spirit really strongly concentrated
in exactly the kinds of communities and

651
00:35:21,881 --> 00:35:24,070
demographics that are
least likely to be working.

652
00:35:24,340 --> 00:35:26,080
So I think about that and I think what,

653
00:35:26,230 --> 00:35:30,310
which of those social problems will
be fixed by a magical check from the

654
00:35:30,311 --> 00:35:31,600
government showing up every month?

655
00:35:31,601 --> 00:35:34,540
And my answer and that thought
experiment is basically none.

656
00:35:34,880 --> 00:35:39,130
And our friend Bob Putnam really helped
educate us about the these issues. But,

657
00:35:39,131 --> 00:35:40,890
but I want to underscore the first
thing. And he said, you know,

658
00:35:40,891 --> 00:35:42,900
we're all for experiments and let's,

659
00:35:42,901 --> 00:35:46,670
let's try some different things because
we can sit here in our chairs and,

660
00:35:46,671 --> 00:35:49,500
and say, Hey, this is what
we think motivates people.

661
00:35:49,620 --> 00:35:53,520
But the truth is there haven't been
that many real tests of some of these

662
00:35:53,521 --> 00:35:56,010
theories. I think we'd
done in different ways. Uh,

663
00:35:56,040 --> 00:35:59,160
Norway has been faculty six
successful with the oil wealth,

664
00:35:59,220 --> 00:36:01,080
giving people a longer vacation.

665
00:36:01,081 --> 00:36:04,560
There's a lot of childcare taken care
of people and maintaining a pretty high

666
00:36:04,561 --> 00:36:05,640
level of satisfaction.

667
00:36:05,970 --> 00:36:09,780
Other oil rich countries have had not
been as successful in navigating that

668
00:36:09,781 --> 00:36:12,750
level of wealth.
So I think that there's clearly some,

669
00:36:12,780 --> 00:36:16,350
some devil's in the details in terms
of how you structure things and how you

670
00:36:16,351 --> 00:36:19,440
help people that can lead to
very different kinds of outcomes.

671
00:36:19,530 --> 00:36:22,460
The other thing to say on this point,
this is a really fundamental question.

672
00:36:22,640 --> 00:36:26,740
Another reasons I'm not a fan of the UBI
is because it might be a solution in a

673
00:36:26,741 --> 00:36:31,640
w n a post work world and a world where
we just don't need a lot of human labor.

674
00:36:31,910 --> 00:36:35,840
There was nothing in the evidence that
says we're heading into that world yet.

675
00:36:36,110 --> 00:36:39,500
We've added net jobs in America
month by month four I believe,

676
00:36:39,501 --> 00:36:41,030
75 months straight,

677
00:36:41,420 --> 00:36:45,620
and you can go graph the number of hours
of labor required to generate America's

678
00:36:45,621 --> 00:36:46,640
economic output.

679
00:36:46,820 --> 00:36:51,820
It has gone up in lock step with GDP ever
since the end of the great recession.

680
00:36:52,250 --> 00:36:53,600
So when you're looking at the trend lines,

681
00:36:53,690 --> 00:36:57,410
you don't see any plateauing or leveling
off. You don't see the end of work.

682
00:36:57,650 --> 00:37:00,350
I'll become a lot more
excited about a ubi when,

683
00:37:00,351 --> 00:37:04,460
when the amount of labor hours needed
to generate economic output starts to

684
00:37:04,461 --> 00:37:08,180
level off. So America has
high rates of labor mobility.

685
00:37:08,390 --> 00:37:11,520
Is that something that we should be
encouraging or discouraging earning high

686
00:37:11,521 --> 00:37:14,600
rates, relatively speaking.
Well actually, yeah.

687
00:37:15,020 --> 00:37:17,960
One of the concerns is it actually that
number has been falling quite a bit,

688
00:37:17,990 --> 00:37:18,410
but go ahead.

689
00:37:18,410 --> 00:37:22,340
So is it a good thing to encourage people
to go with a job sooner or does that

690
00:37:22,341 --> 00:37:24,560
risk hollowing out the communities
that Andy's talking about?

691
00:37:25,350 --> 00:37:28,880
It's that it's better than trying to will
those communities back into existence

692
00:37:28,881 --> 00:37:29,990
if the,
if that's not going to work.

693
00:37:30,240 --> 00:37:30,661
Absolutely.

694
00:37:30,661 --> 00:37:35,661
I think that one of the most misguided
policies is trying to target lander

695
00:37:37,321 --> 00:37:38,790
geography rather than people.

696
00:37:38,850 --> 00:37:43,470
What we want to do is help the people
and if we can get them to match jobs to

697
00:37:43,471 --> 00:37:45,360
jobs better matched to work better.

698
00:37:45,450 --> 00:37:49,080
Mobility is one of our best
tools and America, as you said,

699
00:37:49,370 --> 00:37:53,100
has historically been one of the most
mobile societies and it's becoming more

700
00:37:53,101 --> 00:37:57,750
and more stagnated, ossified, and that
is exactly what we want to lean against,

701
00:37:57,751 --> 00:38:00,090
seen as some of our policies I
think have a little backyard a bit.

702
00:38:00,091 --> 00:38:03,390
We have big subsidies for home ownership,
which sounds like a good thing,

703
00:38:03,510 --> 00:38:05,730
but it can lock people in to homes.

704
00:38:06,390 --> 00:38:09,630
And there are a lot of other barriers in
terms of land use regulation that have

705
00:38:09,631 --> 00:38:11,130
made it harder for people to move.

706
00:38:11,131 --> 00:38:13,300
And maybe there's some
cultural things as well as,

707
00:38:13,340 --> 00:38:17,610
as communities have become more
uh, uh, balkanized and stratify.

708
00:38:17,850 --> 00:38:20,340
So, um, you know, if, if a,

709
00:38:20,400 --> 00:38:24,590
a group of people can find better work
somewhere else, I say, hey, great, let's,

710
00:38:24,620 --> 00:38:27,300
let's find a way to make it easy
for them to find that magic.

711
00:38:27,480 --> 00:38:30,420
And there are lots of places in
America that have shortage of labor.

712
00:38:30,510 --> 00:38:32,910
There are other places that
have surplus, um, you know,

713
00:38:32,911 --> 00:38:35,440
whether it's go west young
man or whatever the is,

714
00:38:35,441 --> 00:38:39,460
it's been something that's been part of
the DNA of America to be dynamic in that

715
00:38:39,461 --> 00:38:44,140
way. It's weird that morbility just
moving around the country is again,

716
00:38:44,141 --> 00:38:45,590
on the decline in America.
It's,

717
00:38:45,820 --> 00:38:49,180
I think it's really hard to see
when you sit in either Cambridge,

718
00:38:49,181 --> 00:38:51,280
Massachusetts or silicon valley,

719
00:38:51,460 --> 00:38:55,630
but almost any measure of
business dynamism that you
would care about is heading

720
00:38:55,631 --> 00:38:58,110
the wrong direction in America
and has been for awhile.

721
00:38:58,240 --> 00:39:01,560
How many of the people in this
room were born in Silicon Valley?

722
00:39:01,560 --> 00:39:06,330
And just kind of curious. Okay.
Three, five hands. Yeah. Yeah.

723
00:39:06,640 --> 00:39:11,050
So, uh, so that you know, at that, and
it's great that not just silicon valley,

724
00:39:11,051 --> 00:39:15,760
but America has been a magnet for
talent and that's part of the,

725
00:39:15,920 --> 00:39:18,910
I wouldn't call it a secret sauce
cause it's not really a secret that's,

726
00:39:18,911 --> 00:39:21,520
you know, attracts the best and the
brightest from around the world.

727
00:39:21,760 --> 00:39:25,240
And one of the things that really saddens
me just to be very like specific to my

728
00:39:25,510 --> 00:39:29,440
area is when we get these brilliant Grad
students that come from other countries,

729
00:39:29,441 --> 00:39:30,970
China,
India or wherever,

730
00:39:31,240 --> 00:39:34,510
and then they're finished their phd and
they want to stay and the government

731
00:39:34,511 --> 00:39:37,750
says, no, you have to go back.
We don't want you anymore.
And they're like, no, no,

732
00:39:37,751 --> 00:39:40,660
we want to stay. And they were like, okay,
go, go, go back. And like, well, okay,

733
00:39:40,661 --> 00:39:44,060
I guess I have a cousin working in
Bangalore. I guess I'll go work with,

734
00:39:44,110 --> 00:39:46,420
with him or her. And uh, you know,

735
00:39:46,480 --> 00:39:49,690
eventually they're not even gonna want
to come here anymore and we'll have to

736
00:39:49,691 --> 00:39:54,220
beg them. And I think that's, uh, that's
bad for the war for the United States.

737
00:39:54,280 --> 00:39:57,220
And I think maybe bad for the world
because you're not getting the optimal

738
00:39:57,970 --> 00:40:01,120
allocation of talent to where it
can paid value. And I'll speak,

739
00:40:01,310 --> 00:40:03,230
you know,
for the home team for America,

740
00:40:03,260 --> 00:40:07,280
this Koffka esque nightmare that we've
created that we put in the way of some of

741
00:40:07,281 --> 00:40:11,000
the world's most talented and ambitious
people who want to come to this country

742
00:40:11,001 --> 00:40:14,690
and build their lives and careers. I, that
that's what our enemies would do to us.

743
00:40:14,691 --> 00:40:15,830
It makes no sense to me.

744
00:40:16,310 --> 00:40:18,800
The majority of the people working in
silicon valley who were actually born

745
00:40:18,801 --> 00:40:19,940
outside the United States.

746
00:40:19,970 --> 00:40:23,810
So we're working to prove that a
question in front and then in back,

747
00:40:25,660 --> 00:40:26,493
ah,

748
00:40:28,270 --> 00:40:31,080
got Mike's Technology improves and well,

749
00:40:31,360 --> 00:40:34,480
and let me back to the developing world.
For a second.

750
00:40:34,690 --> 00:40:39,320
You mentioned how automation may be
more dangerous in manufacturing reliant

751
00:40:39,321 --> 00:40:41,830
countries and Indiana state of course,

752
00:40:42,850 --> 00:40:47,800
I wanted your take on what strategies
does countries should try and develop to

753
00:40:47,801 --> 00:40:48,730
anticipate that's,

754
00:40:48,910 --> 00:40:52,900
and specifically if you think services
can be an interesting path for growth at

755
00:40:52,901 --> 00:40:55,270
an enduro when the trade of services,
uh,

756
00:40:55,290 --> 00:40:57,730
I think of a passage of the
trade in goods these days.

757
00:40:58,600 --> 00:40:59,031
Yeah,
it's,

758
00:40:59,031 --> 00:41:03,490
it's a super tough question because the
path to prosperity or the path to being

759
00:41:03,491 --> 00:41:08,180
a middle class country was pretty clear
in the 20th century. And to uh, to,

760
00:41:08,181 --> 00:41:10,900
to speak a little bit bluntly,
you went through a sweatshop phase.

761
00:41:10,901 --> 00:41:13,000
He went through a phase of
heavy industrialization,

762
00:41:13,210 --> 00:41:16,760
a decent portion of the population
worked in manufacturing, uh,

763
00:41:17,050 --> 00:41:18,550
in factories in sweatshops.

764
00:41:18,640 --> 00:41:22,180
And then over time you developed a
more robust economy, more diverse one,

765
00:41:22,660 --> 00:41:25,930
a civil institutions came along with that.
They became pretty healthy countries.

766
00:41:25,931 --> 00:41:28,090
We saw that playbook and the 20th century,

767
00:41:28,750 --> 00:41:32,680
Danny Roderick is a really good economist
who is documented that that playbook

768
00:41:32,681 --> 00:41:37,400
is looking less and less likely in the
21st century. Mainly because of, you know,

769
00:41:37,640 --> 00:41:38,510
we believe,
um,

770
00:41:38,720 --> 00:41:42,620
robots and to a lesser extent the
fact that we have tons of capacity in

771
00:41:42,621 --> 00:41:46,280
countries like America and China
and Germany. So your question,

772
00:41:46,281 --> 00:41:49,970
which I'm really stalling on is
what's the new path to prosperity?

773
00:41:49,971 --> 00:41:53,120
And the reason I'm stalling is it's,
I don't think it's clear at all.

774
00:41:53,360 --> 00:41:57,620
I don't know about the template for
the 24th century path to prosperity.

775
00:41:57,800 --> 00:42:02,620
That doesn't include either a phase of
industrialization or a or a, um, uh,

776
00:42:02,680 --> 00:42:06,380
a resource endowment. Aye. Aye.
What you say sounds right to me,

777
00:42:06,381 --> 00:42:09,950
it has to do with human capital and
services that can be delivered over a

778
00:42:09,951 --> 00:42:13,040
distance. I don't know the
shining example of that yet,

779
00:42:13,530 --> 00:42:16,090
for better or worse, I think,
I think, uh, unfortunate.

780
00:42:16,100 --> 00:42:19,310
I think it has to be a playbook that
more and more similar to what developed

781
00:42:19,311 --> 00:42:22,490
countries have because we could be
coming globally and interconnected,

782
00:42:22,491 --> 00:42:26,300
which means you have to have an educated
workforce that can deliver some kind of

783
00:42:26,301 --> 00:42:30,530
value that's greater than,
than that other people are delivering.

784
00:42:30,800 --> 00:42:33,230
And getting people up to speed on that.
It's hard.

785
00:42:33,500 --> 00:42:38,500
There are some digital tools that
can speed that process a bit.

786
00:42:38,900 --> 00:42:42,290
And so that's going to be part of it.
There may be options in,

787
00:42:42,300 --> 00:42:44,570
in services that can help a little bit.

788
00:42:44,630 --> 00:42:48,130
Personal services tend to be localized
so then they are somewhat insulated from,

789
00:42:48,190 --> 00:42:51,260
from globalization. But
it's a, it's a tough,

790
00:42:51,740 --> 00:42:53,720
it's a tough question and one that

791
00:42:53,840 --> 00:42:54,560
we should worry about.

792
00:42:54,560 --> 00:42:57,800
The clearest example I think
is the Indian high tech sector,

793
00:42:57,890 --> 00:43:00,920
which is a fairly small industry
in a very, very big country.

794
00:43:00,921 --> 00:43:02,630
So I don't know how well that scales,

795
00:43:02,990 --> 00:43:06,050
but my playbook for the 21st
century will be kind of, you know,

796
00:43:06,051 --> 00:43:09,740
bathe your country in bandwidth,
get cheap devices to the people,

797
00:43:09,980 --> 00:43:11,780
help point them the way toward these,

798
00:43:11,810 --> 00:43:15,440
these amazing educational resources
online and entrepreneurial is we'll find

799
00:43:15,441 --> 00:43:19,490
that human capital and put it to work.
That's easy to say and really hard to do.

800
00:43:19,680 --> 00:43:23,350
Another example is a little bit like
that is that burgeoning o two o sector in

801
00:43:23,360 --> 00:43:27,740
places like China online to offline where
these technologies have allowed lots

802
00:43:27,741 --> 00:43:31,380
of entrepreneurs to create
many, many services, uh,

803
00:43:31,640 --> 00:43:35,240
new kinds of products and services that
wouldn't have been possible before.

804
00:43:35,241 --> 00:43:39,080
It's you have a uh, an explosion
of small scale entrepreneurship.

805
00:43:40,020 --> 00:43:40,171
All right,

806
00:43:40,171 --> 00:43:43,420
so we're running up on time or two
questions and back but so many speed round

807
00:43:43,421 --> 00:43:45,690
unless you both through your questions
out there and I'll let you and we'll

808
00:43:45,691 --> 00:43:46,524
answer it quickly.

809
00:43:46,550 --> 00:43:47,580
Good.
Okay.

810
00:43:49,030 --> 00:43:53,140
I was wondering when you said that
there are a lot of jobs being created,

811
00:43:53,560 --> 00:43:56,650
are the autumn in manual labor or are the,

812
00:43:56,651 --> 00:44:01,651
the print can have jobs and what do you
think the average person is going to do

813
00:44:02,140 --> 00:44:07,140
in 30 or 50 years or whenever every
manual labor already is fully out and made

814
00:44:07,861 --> 00:44:10,120
it like,
do you have any thoughts or ideas on that?

815
00:44:10,790 --> 00:44:12,410
I'll try to do that when super quickly.

816
00:44:12,590 --> 00:44:16,460
The engine of job creation in America
has downshifted from classic middle class

817
00:44:16,461 --> 00:44:20,150
jobs to lower middle class jobs.
They tend to be service sector jobs.

818
00:44:20,210 --> 00:44:22,970
They tend to be jobs that involve
doing work in the physical world.

819
00:44:23,120 --> 00:44:27,050
So home health aide, gardener,
short order cook kinds of things.

820
00:44:27,110 --> 00:44:30,890
The robots can't do those jobs yet.
Your question is what does,

821
00:44:31,190 --> 00:44:35,820
what does the world or world of work
look like in 30 or 50 years of continued

822
00:44:35,821 --> 00:44:39,810
tech progress? I want to
be clear. I have no idea.

823
00:44:40,640 --> 00:44:43,880
Let me just depend, uh,
to Andrew's answer. Um,

824
00:44:44,450 --> 00:44:47,870
there's a big chunk of growth at one end,
there's been kind of polarization.

825
00:44:47,960 --> 00:44:51,530
There's also been some very high end
jobs who's been created the middle that's

826
00:44:51,531 --> 00:44:53,270
been hollowed out the worst.

827
00:44:53,271 --> 00:44:55,370
So there's high end jobs like
the ones people in this room,

828
00:44:55,371 --> 00:45:00,030
a lot of people who have
creative technical skills can
command much higher wages.

829
00:45:00,090 --> 00:45:03,740
There's probably no better time in human
history to be somebody with those kinds

830
00:45:03,741 --> 00:45:05,990
of skills or talent or luck.

831
00:45:06,110 --> 00:45:09,560
And there's no worst time to be somebody
with just routine middle Scott middle

832
00:45:09,561 --> 00:45:12,440
class, uh, skills that are
increasingly automated.

833
00:45:13,370 --> 00:45:13,620
Okay.

834
00:45:13,620 --> 00:45:17,210
Okay. Uh, one last question. The very
back, I promise. I'm sorry, please.

835
00:45:18,720 --> 00:45:19,120
Um,

836
00:45:19,120 --> 00:45:24,120
I wanted to ask about like labor and
capital and how this is affecting,

837
00:45:24,550 --> 00:45:28,420
so do you think this trend plays into
that where like corporate profits are at

838
00:45:28,421 --> 00:45:33,421
an all time high and the weight share
of the economy has been dropping and do

839
00:45:33,821 --> 00:45:37,690
you think that like there's this u shaped
curve in labor where like low skill

840
00:45:37,691 --> 00:45:38,441
jobs are safe,

841
00:45:38,441 --> 00:45:43,120
very high school jobs are safe and middle
skill jobs are kind of taking the fall

842
00:45:43,240 --> 00:45:46,810
or do you think it's like all of labor
as a whole is going to take a fall

843
00:45:46,811 --> 00:45:49,780
compared to like the capital
of the corporate profits?

844
00:45:50,320 --> 00:45:52,900
The recent trend is fairly
clear and you pointed it out.

845
00:45:52,930 --> 00:45:54,700
It's increasing share of GDP,

846
00:45:54,701 --> 00:45:57,700
going to capital and a
decreasing share going to labor.

847
00:45:57,880 --> 00:46:01,270
For a lot of the postwar
decades we thought that
capitalism was going to lend to

848
00:46:01,570 --> 00:46:05,860
lead to greater quality of have
in common or financial outcomes.

849
00:46:06,050 --> 00:46:09,490
I don't believe that anymore. I think
that the trend, like I said earlier,

850
00:46:09,610 --> 00:46:12,910
is toward concentration.
There were things we can do about that.

851
00:46:13,030 --> 00:46:15,940
It's called redistribution.
It's called tax and transfer.

852
00:46:16,060 --> 00:46:17,320
It's called wage subsidy.

853
00:46:17,321 --> 00:46:22,180
This is not an insolvable problem at
all and I'm less bothered about that

854
00:46:22,181 --> 00:46:27,120
problem and some other people. Um,
but, but refusing to address it is,

855
00:46:27,130 --> 00:46:28,690
is the cardinal mistake.

856
00:46:29,040 --> 00:46:30,580
And looking to the future,

857
00:46:30,910 --> 00:46:33,610
we have to really be careful about just
extrapolating what happened the past.

858
00:46:33,760 --> 00:46:37,810
A lot of what happened the past couple
of decades was sort of the first wave of

859
00:46:37,811 --> 00:46:41,800
computerization, uh, automating
routine work, repetitive work,

860
00:46:41,830 --> 00:46:43,840
looking forward to what
artificial intelligence can do.

861
00:46:43,841 --> 00:46:47,670
There are a lot of other types of tasks.
So I want to mention manual tasks. Um,

862
00:46:47,710 --> 00:46:51,870
some very creative work last night be
node was talking about, uh, cardiologists,

863
00:46:52,270 --> 00:46:57,120
oncologists and radiologists as Josh
at me and very highly paid jobs, right?

864
00:46:57,160 --> 00:46:58,870
So we may see different than going on.

865
00:46:58,930 --> 00:47:03,370
I think the only sure thing is that the
pace of change is increasing and we need

866
00:47:03,371 --> 00:47:05,110
to have a lot more flexibility.

867
00:47:05,111 --> 00:47:09,370
We need to be able to sense and respond
and be active in how we do that and not

868
00:47:09,371 --> 00:47:11,410
just sit back passively and thinking,
well,

869
00:47:11,411 --> 00:47:14,950
I hope it works out for us because we
think there's a lot of things that we can

870
00:47:14,951 --> 00:47:17,560
do as individuals,
as organizations,

871
00:47:17,561 --> 00:47:21,820
as a society to help shape the path
we're going towards and we do this right.

872
00:47:22,030 --> 00:47:25,390
This is going to be the best thing
that's ever happened to humanity.

873
00:47:25,391 --> 00:47:28,390
We're going to have a lot more wealth,
a lot less need for work.

874
00:47:28,450 --> 00:47:29,830
We're going to have people,

875
00:47:29,950 --> 00:47:34,120
but there's absolutely no guarantee that
we will hit on all of those dimensions.

876
00:47:34,121 --> 00:47:38,320
It's quite possible we can have a much
more dystopian scenario where there's a

877
00:47:38,321 --> 00:47:42,640
tremendous concentration of wealth and
other outcomes that we aren't as happy

878
00:47:42,641 --> 00:47:45,330
with, but ultimately it's
not the choice of technology.

879
00:47:45,331 --> 00:47:48,460
It's going to be the our choices that
determine that and the reason we wrote

880
00:47:48,461 --> 00:47:52,060
these books was to help provide a little
bit of guidance on what some of our

881
00:47:52,061 --> 00:47:55,720
options are and then we have to apply
our values and see if we want to go in

882
00:47:55,721 --> 00:47:59,320
that direction. This is the headline to
end on, and this is awesome. Overall,

883
00:47:59,321 --> 00:48:03,520
human prosperity is about to increase
even faster than it's been doing.

884
00:48:03,521 --> 00:48:07,210
We're heading into a different chapter.
If we blow the distribution,

885
00:48:07,211 --> 00:48:10,630
the sharing of that
prosperity, shame on us. Andy,

886
00:48:10,690 --> 00:48:15,340
Eric Machine Platform, crowd cloud
crowd at your guide to the 21st century.

887
00:48:15,370 --> 00:48:16,070
Thank you very much,

888
00:48:16,070 --> 00:48:18,130
Ken.
Thanks a lot.

