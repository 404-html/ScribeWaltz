Speaker 1:          00:06          Welcome to toxic Google and Cambridge, Massachusetts. Uh, today I'm very pleased to have here, uh, on by Gund speaking on data for the people. A topic that's a very close to us, very familiar to us, of course, and, you know, very broadly speaking, does it, there's a couple of ways to go with this topic. Obviously we are very generous with our data and both explicitly and, uh, and just in the normal course of living in the modern world. And we get back a lot for that. And some people might argue that we don't get back enough or, or, or whatever. And so one way to go is kind of the, the negative direction of controlling it, uh, privacy, micropayments, all that sort of thing. The other direction is to be much more open and positive, um, to embrace this and then see we can maximize the benefit we get from data.

Speaker 1:          00:55          I think a ladder is broadly, uh, on today's his approach. But of course, you know, there are dangers, uh, uh, there are things we can do to make this work as well as possible for our, for us as individuals. And, uh, um, that'll be the topic for today and stuff. Something that had done the is there's a lot of experience with, um, but, but rather than doing a conventional, um, uh, introduction I think will make this a little bit more interactive and dynamic. Like let's talk in general. So a, so please contact us, welcome to Google and welcome to the social data revolution because ultimately, not only is this the title of my Youtube Channel, but ultimately really that is the amazing world we live in. So reading the book, you started life actually as a, as a physicist. And so how did you come to be what you are today?

Speaker 1:          01:50          So I got my phd in physics at Stanford and I've always been a data person. I was at soon as an undergraduate. It was really amazing to be logged in to other computers and that was way before the web was invented. And, uh, then I went to my phd advisor, my initial Phd Advisor at slack, the Stanford Linear Accelerator Center, and told him, Jonathan, you know, I really thought about it and I'm more interested in newer networks that in particle physics. So he said, okay, what is that? And he thought, you know, poking Alec Tours in new monkeys or something. No, no, it's about learning from data and that, you know, he could live with. And uh, he was super generous to then next year you still support me for a while. And then my phd with Dave rumor heart who are some people you know, really think was the one who pushed the idea of neural networks.

Speaker 1:          02:45          And uh, that's what my phd and so machine learning as would call it now, lots of people in the world and know about it now. Those days were just a few of us. [inaudible] Facebook's neuronetworks stuff now was one of my friends. So, um, it was a very smooth transition. The transition from, you know, doing physics, which I still love and I will say once if it's just always visits. If you think like a physicist, then you have actually a couple of attributes. One is you don't run away from data but you run towards data. So sometimes when I talk to people from the tend to intelligence community, they would tell me that I would be terrible agent because when I see something sketchy I always, you know, want to see what's happening there. Like sketchy data for instance, where you need to interpret the data and fill in some meaning. Second thing physicists do is that they're pretty good in what I call data literacy. So for me, data literacy is that, you know, order of magnitude calculations, you know, what can be the case in what can't be the case as opposed to my brothers. I was a physicist and he says when there's computer science Grad students, they always come and say, oh, the algorithm is already converging with the least significant digit.

Speaker 1:          03:59          So physicists, they know about numbers, they love data. And the most important thing is I think they love experiments. So, uh, at some stage 2001, 2002, a phone rang and the headhunter was on the line and he said that Jeff Bezos would like to have a chief scientist. And I try to figure out why I'd never worked in a real company and why would I want to work leave university. We're going to company. And so it turns out the Jeff, of course, a new from previously being a de show how important data is, but what he can do in retail of course, as opposed to in finance where it can be expensive as experiments. So just like Google, we, when I was at Amazon and of course afterwards have done tens of thousands of experiments and you probably all know many stories and maybe I leave some for the Q and a if we still have time.

Speaker 1:          04:56          Um, I was also wanted to be a bit more interactive in that. So then after Amazon I went back to teaching. I love teaching and I have to say I teach one course a year at UC Berkeley called social data revolution. And, uh, it is just amazing to have the opportunity to basically have the university is a platform where once a week for 10 weeks or so, very smart students sit there and they actually listen to you and the debug your thoughts and then you see when it's really painful for them. If you don't know how to do something on Facebook, like then, you know, they just help you out and they explain it to you. So I think it's a great deal as a wonderful way to spend your life. And then however it doesn't scale. So scaling is important. And that's when I got the idea to actually write the book about three years ago, a little bit more than three years ago.

Speaker 1:          05:51          And the book I then want you to write has been compressed into the chapter seven, which is my favorite chapter in this book, which has all of the examples and the different verticals which are look at unfortunately, you know, when I talked to my editor said, you know, you need to prepare them for this. You can't expect every reader to, you know, be at Google or Amazon or Facebook. So if we had these sort of six chapters leading up to it, um, and one of them is data to a ca as I just mentioned it. So actually this book data for the people is really meant for the people. And I don't only teach at Berkeley, I also teach in China. And um, I'm not sure how dubious honor it was that people's daily had a long interview with me, published on the front page about data for the people.

Speaker 1:          06:42          I don't switch Annie's, I don't know what it really says. I can only feel the worst, but uh, you know, people's Daily and data for the people sounds on the surface structure at least kind of similar. So why did a write the book? I wrote the book because I realized when I was at Amazon and each and every one of you, I'm sure it has the same utilization. He had Google that the refineries, as I call them, the data refineries like Google, that they, without even trying hard, no so much about us, about us as individuals that I think it is a wrong battle to fight. The wrong battle is to try to plug the holes and maybe being a good year. A good story for this is Google maps from the early days where I was told from Salford involved in that meeting that somebody hacked Google maps and immediately idea came well rather than plugging that hole, how couldn't we make back to feature?

Speaker 1:          07:48          How can we make it possible for people to actually amend data? So that thinking that you don't try to really stop the in stoppable but you see what can we create of it? That is the underlying thought which I very much embraced and I hope that the readers of the book will also get a feeling about why. I think embracing the data and being empowered by the data is what I think are better choices rather than the romanticizing the view of how good it was when we could have control of our data. And you know, taking back these all these metaphors, taking back control, I mean we never had control of our data. So hey, we can't possibly have control. Imagine a week without Google. You know, you could stay home, you wouldn't have to come into work, but boy, how would you get stuff done?

Speaker 1:          08:51          I mean, what would staff be? So for me, when I see Sue's later revolution, that really is a revolution which is affected billions people's lives. No question. We of course think about information differently. Google, we think about stuff, we buy it differently. Amazon, I mean who of you would not look at a review before they choose a certain item? By the way, if anybody wants to review the book, Amazon is open off or reviews and I think it's a very important ingredient. Thirdly, in everything about who you are, there's potentially take Google plus or maybe Facebook or if you're in China, we chat that has changed the way a billion people think about who they are. I would argue. So the general framework is how can we work together the refineries and the individuals to figure out what can we create for the individuals. So Google of course has the longterm you that if you have the choice, but making a quick buck now or having a consumer in the long term, you of course go for the long term.

Speaker 1:          10:06          So in some way I'm preaching to the choir here, but I still want to go back to the question and the thing, it's a question worth asking people. What would you do if you didn't have access to Google for a day? And then people realize just how much would break and it wouldn't even find him staying with a friend of mine who works for me, diamonds, I wouldn't even find the place without Google maps. And then I was trying to really get out to people that necessity that it is, I need to tell Google where I want to go. Otherwise Google cannot tell me turn left at the the next, the next intersection. So I really part of data literacy, hope that we can upgrade the conversation from people that those logical things that you know in the restaurant and oh I pay after I eat or whatever. Better examples you might have that those also applied to data and if you go into a cab and not sure where the Nfu straight it and the Cabbie asks you where are, can I take you and said, oh I'm not telling you that would be probably invading my privacy and is not going very far. And now what I think by first of the six rights I wanted to talk about is it is a right to access your data.

Speaker 1:          11:31          Now I see all of you nodding and a former president Obama also set, this is the right to access your data as an important right. It is not as trivial as it sounds because it clearly isn't just access to the bits and the bytes. So I was in Shanghai, actually these people, People's Daily was at my place interviewing me and I showed them location history on Google. So I shoot them, you know, you go into history and location and it has to pick a date. And they said, Oh wow, that is so amazing. Wow. That was something beyond, they could believe that a company giving back or is returning to the user in exchange to, you know, showing me more relevant nets. And I by the [inaudible] I used to show Google latitude on my webpage on viagen.com and yes, indeed there were a situation that Remming one dinner where ours, you know, traffic is something, I was chairman of the bay area pretty late and a tool to the other parties and you know, I'd be there five minutes is that you won't, I know you are still in one oh one.

Speaker 1:          12:44          So, uh, that right to access to data is very important. One building tools that allow people to get meaning out of the acts of the data is where I think the most important part comes from just raw here is all the data out of Facebook, doesn't help anything. Building an awesome tour likes Google location history. Um, search history. I think it's about, for me at least the last thing you know, I would be willing to share my search history and honestly I don't think anybody who thinks about it would think differently. You can have all my text messages and have all my email but my searches.

Speaker 1:          13:28          But you have them already. So I mean, um, eh building tools that help people understand that data. Since this is an educated crowd here, one of my favorite sayings is to make the implicit explicit. The two meanings to it. One is in all the data which I look at all the searches I do, making implicit patterns, showing them to me, I think that at least is fun and might actually help me also make some decisions like the hours of the day when I searched or the days of the week, things like that. The topics. Topics are always very hard to classify it, but making implicit patterns explicit is part of giving somebody access to their data. The second part or the secondary mutation of make the implicit explicit is that as a company you write down a function for this search, right? Events where you figure out what are the ways to evaluate whether if we do this kind of eyewear them or that kind of, I would, you know, this primary a treat versus that primary trick, which one actually do we believe is better in the long term.

Speaker 1:          14:42          So into this with a called equation of business, you bake in an incredible amount of assumptions, but you make explicit, and Amazon, I spent probably 50 hours who stiff visas for each group to figure out what is the which quoted fitness function that they should be evaluated by and has have a buy in. And they're all, those are mistakes. You always forget something. And then of course smart people go and optimize for that. And he said, Oh yes, right? But that of course we didn't mean. So, for example, if someone says, you know, we want to increase conversion rates, so you turn after the first sale of the year, you turn your service off. No more sales, but a hundred percent conversion rate. So you know, it's, it's a constant process and make it explicit. It's something which I think is super useful for the company and it really condenses the thinking and reasonable people absolutely can disagree on things. But then once you have it, you know, and the new crank, the handle, whether this experiment or that experiment is better.

Speaker 1:          15:50          So the first ride is right to access your data. Let me throw another wrench into it. Your data. So let's say a Facebook. So today, uh, I am on NPR marketplace tech and there are lots of comments. Now if I change the post, I have my Facebook a Vegas. If I change the post summit, if I change it a lot, then suddenly, you know, some of the comments people make don't make sense anymore. You know, I might be learning from some of the comments I might incorporate into my Facebook post. Now they look really stupid. So whose data is this? So our ownership concept that you know, works for apples or even for, for physical books here, that ownership concept clearly breaks down for data. So I don't have a solution which I a, you must do it this way, but I do see a couple of directions how people should think about it differently.

Speaker 1:          16:48          And it clearly, you might've heard the example last year, which I think is a beautiful one off fed monkey that took a picture of himself, that Selfie and you know, then the photographer sued uh, Wikimedia or whoever published the picture because they said, you know, it was not taken by human. So these are just very interesting topics which I love for us as society to discuss. And the ownership of data from me and images. Data is one of the examples where I really feel, let's actually no, not run away from it and please let's not run away and say, oh, the lawyer's a hundred years ago they wrote down how to treat it. They had no fricking idea of what we have now is a good starting point. But let's work together and actually make it better.

Speaker 1:          17:35          Um, access to my data. I have one more story. It's not in the book. Um, there is a German paper which is called [inaudible] and it's the largest paper in the western hemisphere would do is have dd publication and not particularly the lecture shall we say. And the head, the editor and chief, um, came to class in Brooklyn and uh, we had dinner and someone took a picture and post it in Facebook. I was barely starting on the bay bridge when my phone rang and the tats and more left wing paper called me up and said, we saw a picture. We need to do interviews. It absolutely. And what happened was then they said, we just have one question. Who has the most power over you as a consumer?

Speaker 2:          18:33          Apple. Amazon, Facebook, Google. What do you think?

Speaker 1:          18:45          Anybody would not say? Google. Raise your hand. Oh yeah. Who Do you think your friends, we talked about companies. Okay. Uh, I don't know whether Google has more power over me than my friends because you know, let's say Google wants to let me disappear or remove me from the index. Yeah, we knew this guy, Andrea says, not even any trace left of him. Not a problem. And I actually, you all are familiar with the right to be forgotten. The de linking, which by the way in terms of raw numbers is nothing compared to copyright things. Google has to deal with by, you know, companies complaining that something was used illegally. I want not a right to be forgotten. I want to write to be remembered. So for me, the right to access for data means also the right to remember some suicidal agreement that hey and who is doing a very good job in that, that you know, I want my old emails to not sort of random disappear.

Speaker 1:          19:52          Big Difference to China. So I gave a talk at a company in December and I wonder to pull up on we chat, which is sort of Tencent's version of Facebook. It's a communication tool. I want to put up on Richard a picture. Somebody else had posted with me and Jack Ma maybe two weeks prior, not thinking anything of at this, this picture is no longer available. It might've been removed by the whatever the portion is posted. Of course all in Chinese, you don't know what it means to us with what does it mean. And I felt really violated that there something which I do to, you know, get them good traffic and then two weeks later I give this nebulous message by this picture is no longer available. Now of course it's a question a hundred years probably. I have no problem with that. Two weeks I do have a with that.

Speaker 1:          20:48          So I really brought that up in that crowd and was quite annoyed. I mean sort of happens in real time. I want to show them somebody is no longer there really pushing what company would you want to have taken care of? Your data it company that really has very good service, that agreement and says the uptime versus a company which, you know, random delete stuff. And then they say, oh, it's too expensive to, you know, half a serve. I mean that's as ridiculous as cost of storage is not what difference it would make for anybody. How much, how much can you produce it? A hundred bucks a yet very most. And the Chinese said, oh we would prefer that second company and that is what really brought these cultural bias is very much up to the forefront of my thinking. I'm familiar with Europe's, I gave you the example right here before gotten versus what we think here, but the adage do was your data and that they they embrace in a femoral nature.

Speaker 1:          21:42          Whereas I, I grew up in a world where you know, I could fix these things are there and you can attach them who can access them. So sometimes our biases might just be representing us well and other people in the word think about it differently. And two nights ago I had dinner with Dan economen and I asked him, why do you think that's the case? And he thought maybe it is that the attitude was accountability is different in the US compared to China. That they are very happy not to blame it on the computer, which is not an excuse. Probably any of us would accept if somebody says, you know a Checkin, I'm sorry the computer made a mistake. No it's not the computer, which made me see somebody made a mistake, not the computer. The other point I want to make, and that's the last one on this right here to access your data is uh, in comparison with your tie in the US, this huge experiment of running Facebook for an a billion people and running.

Speaker 1:          22:40          We chat for B and people and uh, I don't know who of you has been on Wechat or too few people in that case. Let me just say very generally that the assumption for instance, that if you are friends you usually can see the friends we have in common, which seems that get perfectly good thing for me. That after all, you know, if we have friends in common, if if mutual friends, then why would I hide my mutual friends from you? I think this data symmetry as Jordan Novat wrote it in a wonderful article a few years ago. This data symmetry is the way I think fantasist built. No way we should would ever show you any buddies, friends. So it's a bit like my PR agent that they don't give me his number because you know I might disintermediate them, not think that you know, when we meet I could actually ask you for a number so they might as well make it frictionless and make it easier and you know, see for some potential there be, this connects off saying hey be introduced and you take it from here.

Speaker 1:          23:48          So that wrong notion about having power booth withholding data, it's the notion of how the word used to work. Companies got big by erecting barriers to inflammation and that's how money used to be made. Like used car dealers as an example. Now, if you're thinking about the companies who know and love, they got big by removing barriers to information and I just love as far as, I love when the sign flips and another sign, flip example in this world is when I was an Undergrad in Germany, we were not allowed to unplug our phones. So the role of the government was to protect the network from the consumer. And luckily at least under the previous administration, there have been moves to actually produce a proactive consumer from the network. So signed flips is something I'd love to talk about more. I have a few examples in the book.

Speaker 1:          24:48          I think just very interesting when something doesn't change by 10% but changes aside from plus to minus or minus or plus five more rights to go. The second right is the right to inspect the refineries. So when you buy a car or fridge or whatever, typically there are some things like stickers on it that help you make a decision. For instance, the fuel efficiency or how loud the fridges, no, these are numbers which EPA or other groups agree on how to measure it. So it's not just one person just, you know, puts Niya and says, oh, you know that fridges out. That would be the current administration's that's true to this. But no, they had scientists and they actual fig out without being gagged how they can actually come up with this number. So you as a consumer can compare them.

Speaker 1:          25:45          I would the same for refineries for data refineries have not, of course not fuel efficiency, but you know how secure is my data. So it has no question when you know, people not easily come and say, oh, I would not put the data up in the cloud if she goes in Shanghai. When I heard that argument, what do you like using docs here from China? What if Google can see what you're writing? Say, you know, they see anyways, besides there's the Chinese government, so don't fool yourself. Don't live the illusion that they don't know. But we have extremely strong economic constructs that companies do not want to be broken into. Because as you saw in Sony's example, for instance, it can be very expensive. And if there ever was a security issue, which affected consumers at that say one of the top companies that said Google versus Amazon, that really would I think be an extraordinary, terrible thing for the company if suddenly seems that you did it safely. Voice is absolutely aligned of interest of the consumer and the company against the hackers and the criminals.

Speaker 1:          26:54          Um, I was for my birthday last year, I was in Moscow November 10, and then met with Putin and uh, I spent the day with the head of spare bank, which is the largest bank there, which he owns a certain part off. And uh, the head of that bank, how on graph, very smart individual. Um, he was caught out half halfway through and he came back in town. I said, what happened while we had an attack on our service and I was thinking, you know, if any would tax it would be the Russians or maybe the Tony is so awesome. So where did it come from? Of course when the United States, I mean like where else would recovering from that it makes you think, Huh, we do have a certain word who here? It makes sense once you start thinking about, so a part of this right to inspect the refineries means that you can look in what is being done to use two factor authentication for email.

Speaker 1:          27:51          You know, do you, I mean there's now these things we did applied to Google, but not all companies are as good as Google. So that is stickers not for your fridge, but stick us for your refinery. Allowing users to make decisions of whether the rather more convenience like when his passwords, you know, you can just direct, you know, we do email versus a more security. Let people make the trade off. The remaining four rights are the right to amend. That means I believe, I believe in democracy. I believe in, you know, giving people a voice. I believe in empowering people and not by controlling how the truth would be. Alternative facts should be. So that means let anybody annotate anything. So if you think x about y make a link on y where you are saying x and then you as the hundred billion dollar machinery of relevance ranking, whether it's Google or whether it's Amazon recommendations, Netflix use that hundred bend or I machinery, which she was very well for ads use that for amendments.

Speaker 1:          29:08          So basically anybody should be able to say anything and quickly things that actually seem to be right or interesting maybe you know, interesting more than right. They will bubble up and uh, that is very short. The right to amend. Next one, the second off fees. Action Rights is the right to blur, blur judications the best example but it also works for searches of a products you buy that you should be in charge of the radius of the granularity, the resolution in which data that concern you can be processed. In all cases. It was very, very important to me is that people understand the trade offs they are making. The world is not black or white. So if you say, I am going to Burma, geolocation to one kilometer, don't expect the pizza delivery man to bring it to your door. So Hey, if you really want this, then you can't want that and just live up to it.

Speaker 1:          30:20          But don't live that illusion of these lottery inconsistencies that you don't want anybody to know where you are, but you would like to pizza to be devoted to one and assess the super trivial example. But this right to blur your data is important for me and the illusion people have is that they can sort of blur data at the source. I don't believe in that. I think the carriers for instance, Google of course knows to the resolution of less than a meter where I'm pretty much 24, seven. It of course knows what time waking up it of course knows what I'm interested in. All these things. You can't do anything at the source. That's why I think having the right where you are in charge of figuring out how precisely you want the things to be known, that really should be your choice. Now there is, um, there are some interesting things from psychology.

Speaker 1:          31:25          So for instance, weren't up, uh, wonder to figure out 20 years ago, who of you knows what differential privacies Soso okay. It's a very important concept that if I tell you something, so you can, let's say as a government for instance, make it better policy discussion. I wanted to be protected that you can't use it against me. So my belief really is data off the people, data by the people, but data for the people. So if let's say somebody asks, um, you know, as we had with the previous pride president who took something but he didn't inhale, so, uh, did you smoke pot last month? And let's say you are in a state where it's illegal smoke point. So if you say, I did, and then the next day the police shows up and says, you said you smoked pot after prison. I mean, it's not that bad.

Speaker 1:          32:24          But think about other things, which would be this way that would suck that you try to have some policy to help them understanding. So that die guy called Werner had the idea that I'd asked you a question about, don't not say it, he is a coin and uh, you flipped the coin and I don't want to know what would you feel if you get heads, you say yes, irrespective of what you really did. If you get tails, you have to say the truth. That's pretty cool because more than half of the people say yes. So, uh, it's clear to any prosecutor that they can't go after these people. And if we have enough statistics, you know, any of you can do the math about how to figure out the signal given that 50% of the people only say the truth and the other cs irrespectively of what actually happened. So I encourage you to look a bit into this differential privacy ideas, which help us get data for the people where we set it up in a way that you can't use it against them. Who would does it? When you need chrome, where you are looking at what people do, where you try to spend a malware on people's computers. It's a similar concept where smart people came up with ways finding out things about the population which cannot be used against the individual.

Speaker 2:          33:46          The fifth right

Speaker 1:          33:50          is the right, I wanted to quite have the right to play and my editor said that is, you know, maybe not serious enough. So who we call it the right to experiment. In 1989, I started a company called logic it little startup with the purpose of music recommendations. It was an interesting time also with the founding media of Pandora and they went different routes. Um, how did a company got bought by or media which would gold by the, by another company. So the idea was we want to first of all figure out not from the metadata part, from the usage pattern of how people skip between songs, what we should recommend and then, and I really haven't seen that elsewhere. We want to make explicit to people

Speaker 1:          34:52          the trade off between exploration and exploitation. So in machine learning, one of the things where you can just hope the system will, you know, come up with a solution is whether you should explore more. I mean you can try out new things that you don't know where they're good or bad that you know this one armed bandit problem in Vegas. You know, if one machine once gave you some money, will you spend the rest of the day on that one machine, POCs, POCs, or are you going to still explore some other machines might be bad, better or might be voice exploration versus exploitation. So that is a knob which I think should be headed to the consumer, to the user goes, I know whether I had a stressful day and all I wanted to some soothing music or like an airplane, you know, we'll check in three hours, delay every 10 minutes.

Speaker 1:          35:47          Yeah, update the departure by 10 minutes and you don't sit anywhere. You really just want something which is now a quiet or am I in the mood to explore new stuff? Let me listen to things I've never listened to before. Chances are hated, but she has also are that or discover something new. So that's one example is when I say do right to play or the right to experiment is think how you can expose to the user some of the knobs where you don't know the answer as well as use it does. So exploration expert is one example. In search advanced search you have a few options which are a step in the right direction, but I think they can read more by helping people to actually set the privatest they way they want to set them on their terms, any given point in time.

Speaker 1:          36:45          And then we have all the data, we've got to look at them. But that's not enough for me. I want to be able to take the data to of ips. So I call this the right to port. I would put my data and eh, we know, we all know PGP and API closes up. So just implement it in a reasonable way that if some other company would offer a better search product, then make it easy for me to actually take my data in a secure way. Telling them here is what the data is. And I think it helps the ecosystem because those companies which are good people will come back, make it easy for people to actually put the data on trial. Something else you can always learn from who is coming back. It's another feedback loop in experiments you're doing. So that's what I wanted to say about those six rights which are wrote about in the book. And I thought she only dodge to book you on to two days ago. I have not. We talked about it yet and I've never really spent as much time except in class on those rights. So I want to end with the couple of things which I do not have answers for. Great. So,

Speaker 3:          38:12          uh, questions. Hi. Thank you for coming. Thanks for having me. So, uh, when you talk about the right to blur in particular, that made me think of one of the current problems is that a lot of us who come from fairly privileged backgrounds thinking about, oh, this is a great, I can just share my information, what could possibly go wrong? But the immense power of doxing has been shown to be a force against people. And what's worse is the farther we go towards the default us sharing all your information. Oh, but maybe you, we'll blur your location for safety and can't get pizza. You start to create like a digital underclass, right? You can force people out of this glorious data world for their own safety. Do you, do you have any thoughts on that?

Speaker 1:          39:02          Um, I think it was a lunch when we talked about that there was a time when, for instance, Harvey Milk was shot. There was a time when, you know, the first gay bar in San Francisco, they didn't have windows. Um, so people could look in. Um, and I think that social norm norms ultimately is what determines our attitude towards many things. Let me twist it slightly. Hine who used to be at Google now runs data for snapchat and a B, then a couple of weeks. And I think that's quite interesting that on the surface you have things being a femoral, of course, the deep structures so that the data is there. Is that ultimately helping or hurting? And you knew the story, which was reporting in the Guardian that it, one of the services. It was a thing secret. Ehm, you know, not everything was a s s s Ephemera as they claimed it was. [inaudible].

Speaker 1:          40:03          So, I don't know. Do you have any suggestion? Nope. Still working on that? Yeah. Um, I um, right after my phd, um, I wanted to teach in Thailand at the university for half a year, so when to cheer on corn. And, um, two things I learned from that one is that my friends told me that his scientific suicide, if you are as three things, one is Peter Norvig. Andrew knew at the time already scientific suicide if you are going to be out of touch for half a year. And you know, it was a different time. Um, so when I came half a year later back to us to know, most people had noticed that actually Wisconsin, um, uh, those days, the underclass email go deliver to Thailand twice a day by dialing taka, Taka, Taka. We one connection to Melbourne from the Asian Institute of Technology in Bangkok to Mebane and getting the email for the country back and forth. And there was two weeks when we didn't have email and then some dude showed up at my office too long gone.

Speaker 1:          41:29          I think I do only Spock station at the university should up with uh, you know, I'm not sure whether, you know, these cartridges they used to have sure shows up to the coverages. This is the email for the country for the last two weeks. Uh, so I, uh, I had never, you know, doubt with SMTP every note we can learn anything. So I've posted the obvious thing, which just I grabbed for my name and like the first 10 things were other people talking about me at that stage. I said, this is not a profit I'm going to solve. I don't want to know what people are talking about me, basically, you know. Uh, I didn't expect that to be able to, I thought I just see where I'm the two line and out as quickly scan through those. And the search thing too was that I had hoped that the digital divide would get bridged with those days, the Internet then you know, later the web and I am not sure about it.

Speaker 1:          42:34          Um, what I am sure about is that another comparison between the US and China is of course the great firewall. It clearly makes my life worse. Every time I go to China. It is last time the Latin male, they're like six weeks a year and asked time was less happy than ever because things which used to be easy, just becoming incredibly hard. And even things like using apps in China like dd which is you are the lifts equivalent. If you don't read Chinese, you got us host. Another question. Uh, you talked about uh, the right to annotate the right to a man, but what about the truth? Uh, should they not have the right to read FECC based? Very tricky. I totally agree. And I was sort of halfway mentioned fake fake news before. I believe, as I said, that be $100 billion engine, which we have figured out for search relevance that that can also figure out the truth if we wanted.

Speaker 1:          43:44          Yeah, that's my believe in if we have enough data sources, if you have the identity of people who postings, if you know that desk person thinking about Wikipedia who gets reverted and stuff, I guess I think we can build pretty good models. It will never be perfect, but what is the alternative? So it is not that. The alternative is that we have Donald Trump telling us how it really is, but the alternative is that you know, some random stuff, what happened, I believe in, in in masters and intelligent machines and editors or freaking out what actually is a more likely version of the truth. Then one person dictating it. But that brings me to one of the two heart problems at the end, which is the question of identity. So underlying here is that you have your Gmail account or you have your Amazon account. So when you write those reviews about my book to dimension reviews them, when you write those reviews, then your identity is there.

Speaker 1:          44:46          And actually I went as an Amazon, we had very good discussions with Jeff basis where I was wrong. I believe juice ref pseudonyms because I did not want actually, you know, a colleague if I write a bad review about his book, knowing that that is undress and you know, that would not, you know, really further our relationship or that much. I really believe to pseudonyms and Jeff says, no, we need real names. So Facebook probably gave him right that, you know, real names. It's an open question. I don't have no, I just want to say the question about should one institution hold, uh, the identity, what should that institution be? In my last class I had in Brooklyn in November, I had two wonderful guest speakers. One former NSA employee and a lawyer for the Acru David Holtzman. He wrote a wonderful book called privacy loss 10 years ago.

Speaker 1:          45:48          He knows what he's talking about and Nicole Ozar, wonderful person went to Berkeley Law who really, Austin knows what she knows. And she busted a few operations where, you know, Facebook for instance, handed over via some third party company, um, data to the law enforcement so they could, you know, use your spare resources better. You know, so we had the conversation ended accumulate in the question, which I asked. So it was my youtube channel, youtube.com/social data revolution and the repeated in Moscow for Putin in front of that audience. Who Do you think will be around longer? The oldest states of America or Google? Almost all the students believed Google.

Speaker 1:          46:38          But then in the bigger picture, to come to my last point, you know, good or played on 2000 years ago, he talked about the allegory of the cave. And the idea was that people in his case, prisoners, I don't like that matter metaphor much, but prisoners for him, we're sitting, they couldn't move their heads for the entire lives and they were only looking at the wall of a cave. And that ball had shadows, as we would call them, had dark things projected. There was a light source behind them. You know, like you don't denied somebody if they didn't have that concept cause all this or where the shadows on the wall, no shadows were puppets. Maybe some holes Kang Round, or maybe were people behind them. They didn't know. And there were certain laws which they figured out, for instance, not tool or nonfat fatty Altus seem to the Romans who would've said later, which means nature doesn't jump around. So there was continuity in those shadows in there, had their, would you, they pat their stories about that. They couldn't turn their heads, but, and then one of the prisoners were set free. So he left war. There was all that light out there and it hurt him. He, he, and he went back and said, that's it. No, not doing that again. So the word we live in is the world according to Google.

Speaker 1:          48:18          The word we live in the West is the word according to Facebook. So all I can say is use that responsibility wisely.

Speaker 2:          48:31          Thank you.