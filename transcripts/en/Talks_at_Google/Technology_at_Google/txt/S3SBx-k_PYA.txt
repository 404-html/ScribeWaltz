Speaker 1:          00:06          Thank you all for coming to our latest NASA Google talk. I'm very, very pleased to welcome Keon Brad who is going to talk today about reducing the cost of impact her VNV for flight critical systems. As you can see, the mouthfeel and it is, it is. Um, so it was your bio. So Keon comes Ross from ut Austin where he has his phd. He is the area lead for robust software engineering in the intelligence systems division. He's also a technical lead for autonomous system assurance in the safe and autonomous systems operation project and for air traffic and vehicle software and system assurance research. Thanks so much for your scale.

Speaker 2:          00:47          Thanks for coming. So

Speaker 3:          00:49          I mean I wasn't expecting that many people, especially if we're talking about VNV usually done doesn't draw a crowd. Um, so as Mary said, I'm, I'm, I'm leading a team at NASA ames that's about between 30 and 40 researchers and developers. We have about 20, 25 researchers that do mostly research on formal methods and their application to software verification and about between 10 to 15 engineers, depending on the time that are really focusing on developing. What do we call it? Flight critical systems. So those could be a controlled system. So spacecrafts mostly, uh, on the space side, the research I'll talk about is mostly, uh, uh, done on aeronautics. So it's not so much applied anymore. On the space side, we'll try to infuse in on the space side, but it's really targeting at a civil aviation. Okay. Basically about six years ago, um, and as I was told by, uh, by, uh, OMB, the White House to start addressing the cost, what they see as the cost, the high cost of VNV in the civil aviation.

Speaker 3:          02:07          So basically that's the manufacturers like Boeing and Breyer. I know those guys and the Oems, and I'm working as a subcontractor to those. We are complaining that the VNV for software is becoming more and more of a cost for them and basically heating their lunch. Um, so they wanted somebody to address it and basically that man that was passed onto us at NASA to try to address it. Um, so we set up for a, it was backed up by, uh, several surveys that have been done by the dod, by external a Sayville, uh, agencies. Uh, you can see at the top there is the [inaudible] survey for Saving Civil Arrow and it's pointing out to the fact that, uh, uh, uni new methods and models for assuring safety. So when we talk about VNV safety is the most, is the biggest target for us at NASA. Okay. Um, then there was the integrated plan for the implementation of next Gen, next gen stand for the next generation of fair traffic systems.

Speaker 3:          03:17          And they also pointed out that there was a lack in Vnv, a lack of methods to really address those types of systems. Um, the, the air force did also, um, their study and they actually identified the same need. There's not enough VNV, uh, techniques that are available to, uh, to very, very fine the type of systems that we're building. So we actually, since then, we've been kind of in lock step with them. The research was doing is we are doing is feeding into the program. Okay. So, as I mentioned a bit earlier, so they, that was passed on to us by OMB and the White House Congress, all those big, you know, uh, governmental agencies. But really what's happening is behind the scenes you have the CEOs of companies like Boeing, Rockwell, Honeywell going to really say going to achieve an RMD and says, you know, it really, it really is costing us way too much money to do the envy.

Speaker 3:          04:23          And the specialty VNV for software and software is becoming an increasing a larger part of the cost of developing a plane. So what you're seeing here, a pie chart that tells you pretty much, um, how much it costs to develop a new plane that's going from a major manufacturer, the biggest manufacturer of airplanes in this country, which I won't name, but you can just, uh, and if you see software is taking software and software, VNV is taking him like almost 70% of the cost. Now, the part about, you know, the design of the plan and those kinds of things, it's 30% these days. I explained to you, if you want to quit Google, you can get a job in the aviation industry. They are hiring a lot of software engineers these days. Okay. You just have, Java is not the language that they will use. But so, um, so really what we've been asked to address is that cost, especially for the, what we call the flight critical systems.

Speaker 3:          05:29          So that includes the flight management system, the flight control system, the software that controlling engines and all the system integration on the plane. Right? Because, uh, that part of the system integration is important to consider because, uh, before Boeing for example, was building everything end to end. Nowadays they rely on, on a lot of subcontractors and, and did the integrating a lot of cuts in their systems. So this is a new business for them and they don't know quite how to deal with it in terms of, uh, of VNB. So what drives the cost of VNV is mostly driven by, uh, this, uh, certification standard. That software has to go through four airplane, which is called [inaudible] 78. Um, we add the, uh, third interration of Don 78. Now it's d one, one 78 C M and a deal once every ta B was all about doing the VNV through testing deal when 78 c now now allows you to take advantage of what's called formal methods and model based development to actually do some of the VNV upfront.

Speaker 3:          06:50          Okay. So, um, we are in 2010 we started to build a, uh, a program that we're supposed to address it. There's the software aspect, but there are many aspects, especially when you want to take into account also what's happening in terms of computer systems in their air traffic management part of this equation. So we had four foundational research elements. I'm going to start with the top left and this one, it's got argument based safety assurance. So we were in that one. We're looking at different ways of doing certification than deal one 78. Um, if you're talking about applying for more methods, the um, it's, it's really formal methods. When they're applied, they're retiring a specific risks and you software deal one 78 is all about building quality in new software rather than addressing a specific risk. Okay. So we want it to change that and it's a move that has been done in Europe or at least parts of Europe.

Speaker 3:          08:00          The UK in the UK, they're using a safety cases, which are really argument based. They're addressing specific risks, um, for almost all the defense contracts nowadays. Okay. It's not used so much in the u s uh, except for when you want to introduce what they call an experimental plane. And this is where you guys might be a bit interested because a drone, for example, a UAV is an experiment, experimental plane. There is no really a, a, a good guideline on how you go about doing the assurance of, uh, of Jones these days. So, uh, right now, DFA is requiring a safety case to, to be able to operate any a UABs. Okay. Um, now did the other four elements, I'll, I'll about those two together. Um, all those planes are parading and what we call the nest and national air space. Uh, for, uh, for the u s so think of it as the whole air traffic system within the US.

Speaker 3:          09:08          Um, when we were got that mandate, it was saying that the traffic would be basically multiplied by three by a factor of three within five years. They since then back down from that, but there's still a forecasting, a huge increase in traffic, which means more density, which means the safety margins are going to be reduced a lot in a, in your traffic. So they wanted us to also look at that aspect of civil aviation. Um, and if you look at the Nas and the way it's operating, it's basically a huge distributed system. It's a huge distribution system where you have automation, you have computers interacting with all kinds of humans. That includes controllers, pilots, um, the airline management operation center. So it's really a mix of computer systems and humans interacting with all the confusion that can arise from that mix. And we decided that the human element was so important that we pulled it in a separate element that we call authority and autonomy.

Speaker 3:          10:21          So the attorney part is about increasing automation for those, uh, air traffic systems. And the authority is as we introduce more and more automation, more and more autonomy, we transforming the role of the human in that system. And the fundamental question in the end is woo, as the authority to make the decision. Do we leave it to the machine or do we still have the human that pushes a button and says, okay, go, the machine was right. This is what we should be doing. Okay. Um, so, uh, and, and the distributed same stem part, we kept focusing mostly on the complexity that's increasing within aircraft's. Aircraft's I've gone through a change. Uh, they, this used to be when they used to use what we call the federated architecture, meaning by, you had one box per function for the software, which means that everything was well separated and there was a move to what's called now, uh, an Ima architecture, which is going stands for integrated modular avionics, which actually is a way of putting everything on the same boxes.

Speaker 3:          11:39          But now the FAA has to, requires you to show that those functions are residing on the same physical boxes are separated from each others, either in terms of the memory they access or in of time. They're running at different times and they can interact. They can not interfere with each other's. And that's, that's a lot trickier in terms of verification, this type of, uh, architecture. Um, so they also have a tendency to put a lot more thing on the, on the plane. It used to be that most of the decisions were done on the ground and then you upload the, you know, the, the sequence of factions to the pilot. You tell him them what you do nowadays, there's a lot of functions are Mig migrating from ground to air born. And that means the software on board in the end plane is a, is a lot more complicated.

Speaker 3:          12:30          Um, that goes beyond that. If you look at the Boeing 787, um, it has like a, something that made everybody nervous because they went from having two or three physical networks that were completely physically separated on the plane to one physical network where the, the separation between the, the functions are controlling the airplane and the functions are controlling. Your entertainment system aren't using the same bus, but they basically a walled off by uh, virtual, uh, uh, mechanisms. So that made DFA extremely nervous because they think you can hack and then crossover. Um, and there is a famous guy that keeps sending that he's hacked into the control system for several United flights and kind of, uh, frankly it's a myth, but that makes the FAA nervous and they want better, better verification techniques to address those things. Okay. So that's the setup one. The part I'm going to con concentrate on is the software intensive part.

Speaker 3:          13:38          So really what are we doing about the software intensive system and mostly the part that's about airborne systems mean mean all the software that's on board the aircraft. Okay. And hopefully by the end I'll make the, I'll make the transition to the new, uh, things we suppose to address, which is autonomy, complex system. Okay. So most people say VNV costs too much money. Actually that's what the manufacturers I telling or management, it's not really VNV let's be clear. It's not a VNV per se or doing the Vegan v that's costing you a lot of money. That's where you, you're doing it. So if you look at the v Diagrams and um, the, the phases of development are using in a, in a deviation industry goes for requirements, very careful requirement developments, then design, then coding, then you move on to testing, you know, unit testing, integration testing, acceptance testing.

Speaker 3:          14:43          Finally, you deploy very long cycles and all the VNV and traditional innovation is done here on the right side, on the testing part. So the problem with this is that not only it costs a little more to do it there, but all the faults I found here when actually the falls are being introduced way before. So when you do this, that means that every time you want to fix a bug that you found, you have to go back to some of those earlier phases. If you go back only to coding but it doesn't cost you that much. If you go back to design or requirements, then that goes to a lot of money and it's usually where the cost is coming from and a in the additional costs that's coming from in Vietnamese. So the whole program was geared towards pushing the VNV to the left side of the v.

Speaker 3:          15:40          Make it available as soon as possible. And I want to be careful here. It doesn't mean that we get rid of testing. It means that what we want is fly through testing and not find any bugs. Okay. There shouldn't be anything left when we run the tests so that we don't have to go back to that of an that designer. Okay. To give you two to really hammer the point. NTSB is the board in the u s that's investigating all the incident and accidents in aviation. And I'm more than that in transportation actually. But innovation in particular, they've traced that 90% of the accidents are due to requirement problems. So really the, the pot of gold is right here. We really need to be able to address this. Okay. So our whole program was to try to push the VNV to the left. Okay. Um, what we started to do is, is by giving them better techniques in terms of testing, then we moved down to giving them techniques they could use during coding and that's mostly static analysis type of things. And then to design. And it's like for you two guys are uh, familiar with from our metals, this model checking type of technology. And then what can you do at requirements? I'll save this, I don't have a slide on this, but if I skip it, Mary flagged me because I need to talk about it a little bit. Um, so it can go all the way to using theory, improving to formalize and proof formally that an algorithm is correct.

Speaker 3:          17:24          Um, so those, that's what I, I just mentioned and those are the tools that we have developed at ames. You get to know that most of the 50% of the work in VNV and under that program is done here at Ames next door to you guys. I can see your buildings. I'm kind of surprise. I'm not in the building now. I sit directly from my office, but uh, and uh, the other half is done at Nasa Langley in, uh, Virginia and saw some invention. Um, but we, we are, I would say a little better than Langley and developing tools that are practical for use in a coding Monell checking and requirements. Okay. So let me start with the, uh, with the first one. What did we do to improve testing? Um, most of the testing is very well done. It's really very well done. What, uh, my killers and what we see sipping through is really the outliers.

Speaker 3:          18:37          The defense that are extremely rare. And I'm, Mike still cost you tons of money. Okay. So we went after this and we went after this using statistical learning. The way it works is basically you use your typical test cases, you run them, and then you do a statistical analysis on your output to see if you have outliers in your data. So an outlier is not necessarily something bad but it could be indicative of a bug. Okay. So there is a human making that discriminate determination. Is that an outlier that's indicative of a safety issue or not? If it is a safety issue, what we want to do is try to learn all the other, the, because it's not just one single data point, it's actually a region that's unsafe. So we want to learn what inputs can drive to that unsafe region. We want to identify that and safe region and find the inputs are going to drive there.

Speaker 3:          19:39          What that gives you is that after that, uh, way of, uh, of telling I shouldn't operate my, uh, my plane at that type of a, in that type of situation, avoid this because of probably my children. So if you don't believe that's a problem or it's a way of solving problems. Innovation. Um, Airbus I had a, uh, an incident at one point where basically, um, there, um, uh, they were data that was accumulating and creating overflow errors. Okay. And they found that they couldn't find it for the longest time because on sure it was happening only after 24 hours of flight basically. So for the longest time they couldn't find this and then he was showing up in some cases. So they decided that to fix this rather than redoing, redesigning the software, revalidating it there inside the fix is easy. Now before we reached the 24 hour period, we reboot the system completely clean.

Speaker 3:          20:42          Right. Is Effects. It's still in the system, but they won't show up. Right. But that was one that was extremely rare to find. It was, it wasn't in very particular conditions. So this technique is trained to go after this kind of stuff. Every time you go, every time you identified a problem, then you use statistical learning to refine your test cases and try to drive to this, to this region. That could be unsafe. Okay. Um, and was done on single imperson we moved it to time series because when you try to apply it to air traffic control then you don't reason about single input. You rezone about trajectories. So you need a time series, something that allows you to reason about time series and inputs and outputs. Okay. Um, there is a second use of this. Very often when you use formal methods and new applied to the verification of software, it's too complex and sometimes you want to be able to drive to a specific region of behaviors that you want to explore fully. You can use this type of technique to actually find a point, uh, much quicker. The point I will allow you to just focus on one single region. Okay? So you will use this first and then once you have identified the region, you do an exhaustive search using some kind of formal methods.

Speaker 3:          22:04          All right, so that was the testing. Like I said, after that we tried to give them tools that they could use at the code level. So I'm sure you guys are aware is plenty of static. Analyze a commercial static analyzers that are out there these days. Um, to name a few tools. There is grandma tech. Um, the uh, there is covering the, um, there's been some consolidation. The names might have changed three years ago, but those are the kinds of tools that are out there. Um, here's the problem with those tools. They're extremely fast. They can deal with really big software. We took in million lines of code very quickly, but all they are giving you are warnings because to be fast they have to cut corner and there unsound. They cannot tell you for sure that you have a bag or that you don't have a bug in part of your software.

Speaker 3:          23:01          Okay. Um, so what you end up doing when you're using this is that you get lots of warnings for one thing and then you have to review every one of those to see if it's really a bug that you knew you should be addressing or not. So that means very, a lot of manual work. So what we went after, it was the type of static analyzer that could tell you exactly for sure that you have a bag. That's what we call as opposed to warnings or have mornings that can turn into false positives. Okay. And the added benefit is this type of tool can also tell you when they are sure that you have no bugs on that instruction. So it doesn't tell you that for every type of bugs that you can have, it goes for what's called rent time errors. So the typical ones are buffer overflow, uninitialized variables and initialize pointers, division by zero.

Speaker 3:          24:02          It can catch some, uh, floating point errors in terms of rounding golf and those kinds of things. Okay. So we created a tool and I'm surprised, I thought, I don't know, would show up, but because the guy who helped me create this tool was actually, it's actually working here now doing that for you guys. But we were doing it for CNC plus plus because those are the languages used in, uh, in flight critical systems. Okay. And that we showed in in all the applications that we've done, of those tools that we could go to a, what we call it, precision rate of 98 to 99%, meaning that we had only one or 2% of the checks that we were making where we couldn't tell you for sure that you had a bug or we couldn't tell you for sure that it was safe in terms with respect to the classes affairs that we were tracking.

Speaker 3:          25:00          Okay. Uh, which is much higher than any of the commercial tools. One that's coming close to doing this is a tool that used to be called police space. There he fire, which is now called, has been bought by the math work. I can't remember the name, but it's folded into the met work, uh, suite of tools. Um, and typically why I used it, for example, on space, on the control systems that are close to the avionics, but they were on the space side, I had between 20 to 50% of warnings. So imagine on 1 million lines of code, you almost have a check per line that gives you 200 to 500,000 checks that you have to go through and say, is it really a bag when he's not a buck? It was the main reason for that why for the longest time people were trying out static analysis tools and web frying them away because it really wasn't getting enough useful information.

Speaker 3:          25:58          So what do we want it to show? We didn't set out to build a tool that we can sell and said we better than anybody else, but the goal is to show the industry in our building this type of tools that you can do it. It's possible air the techniques and we using use that in year two and then you can do better. Okay. Uh, if you guys are interested in using it, it's been open source since 2014 we still work on it, trying to refine it. If you download it and use it and find problems, please send us feedback because we relying on the external community to, uh, uh, to make the tool better.

Speaker 3:          26:39          Hi. So that was at the code level. Now let's move to the, uh, the design phase. Um, and they had, the goal is to try to enable model checking on the models are used at design time. Okay. There we could have gone the way of picking a formal, uh, formal language to represent models and use the model checkers and are built for this. The problem is that most of those formal languages are not used in industry. And our mandate is to really to have an impact on industry. Um, it turns out industry for flight control systems and four engine control system at least are using mostly something called simulink or SCADE. Skate is a little bit more popular with engine control. Simulink is more prevalent with the flight control systems. Okay. So we decided to provide something that could go from those languages that could, that could apply model checking on those languages.

Speaker 3:          27:44          So when I say model checking, that means I'm writing safety properties about my system that should hold on my system. That could be, uh, the, uh, landing gears should not be deployed while I'm in flight, for example. That's a typical one. Okay. Um, and then it checks that property if that property holds on the models or not. So basically you get something like this, you get either a true, yes, it's true if you go with this design or it's false and here is why it's false and it's going to be violated. It's giving you a trace to, to show how that property would be violated. Okay. Um, so we try to enable that from simulink and skate, but obviously we don't want to try to address every language that is used on there and with different language. So we actually hooked up amount of bunch of model checkers to a or own internal representation that's using the loosest lung language.

Speaker 3:          28:52          So it turned out that makes it easy because for example, SCADE the underlying foundation for SCADE is list list is a data flow language that was developed in Europe for embedded systems. Okay. And it turns out that simulink can also be mapped to that data flow language fairly easily. So what we have is that a bunch of translators that go from seem willing to lose, um, from simulink or scaled to loose. And then we apply all those types of Mughal checker on it. And this part is extensible. You can add your own, all you have to do is be able to map the representation of uh, to our intermediate representation. For example, Boeing is asking us to add new SMV, which is one of the fastest and most efficient model. Check her out there to this list. Okay. So, um, we didn't want to stay here because the, the typical one when you use simulink is you develop your models in simulink and then you auto code and two C or c plus plus.

Speaker 3:          30:03          Okay. So what we wanted to provide also is a way to doing that at the c c plus plus live on than was generated. So we have another tool called Seehorn on the, on the bottom right there that actually can do this. It's, it, think of it as a sort of static analyzers as static analyzer that can check on see assertions. And those assertions are representing the properties that you verified on the model. So why do we do this? You get, you get to most people that are looking at it as like you are already very fine on design level. Why are you doing it at the code level? Because the FAA doesn't trust anything. They require you to check it at the design level and they're going to want to know that you'd done it on the code. And if we were listening to them, they would require us to do it on the executive board.

Speaker 3:          30:53          But as way too many target for us to, to chase. Okay. So again, this one is available as available, um, open source. Uh, it's been developed partly at NASA, partly at Cmu, under a what's called an NRA. Okay. And we're redoing a version of it that would be only NASA to make sure that we have a very clean license on it. Same thing, and be released open source. And what we want to do is make sure that we have clinic pis so that anybody that wants to add to it can add to it. Okay. Um, and, and one of the main reasons we're doing this is because we have on this work, we have partners in France at an era when working on this type of, uh, of system. Okay.

Speaker 3:          31:42          Um, well before going to safety cases, I'm going to talk a little bit about requirements because the next step really should be an analysis of the requirements. Okay. So air is the analysis we've done when we tried to see what we should be doing and that level, there are plenty of formal languages that have been created in the last 20 years to formulize requirement and to do analysis on requirement. Nobody, absolutely nobody in aviation I using totally nobody because they don't like the language because it's too mathematical because they have to learn something new. The way it's done in industry is still, I'm writing a natural English sentences to describe my requirements and I put that in the best tool that's available that's called doors, which is a glorified spreadsheet. That's it. There's no formalization behind it. Okay. So the question is, do we go and pick did in one of those languages and trying to convince industry to use those or do we do something that allows them to go from natural English to form on requirements?

Speaker 3:          32:58          And that's what we're trying to do. We tried to provide the part that goes from natural English to uh, uh, requirements. There are a number of ways that have been investigated. One of them that's popular and that's post at the air force with our partners at the air force, which is using English patterns. So using new brightening almost English, but you using only some patterns of English that can very, very easily translated into some kind of formal language. Okay. It works up to a point. Uh, may really, when we tried to use it, they will like plenty of requirements. We could and we could and formalize that way. Okay. Um, on the other hand, you guys can give us hope with all the advances in natural language processing where like, wow, maybe we can, uh, we can deal with it not being an expert as the round.

Speaker 3:          33:57          And they told me, now you're dreaming. We're not there yet. So we had to kind of, um, you can tell me different if you can tell me different and I'd be happy to take your inputs. Um, but we went for an intermediate way where basically we feel that, um, first to write requirements that will be from analyzable. You have to make sure that those requirements are not ambiguous. So you need an interaction and the dialogue between the tools that's going to formulize analyze and the people are actually writing the requirements. And that's what we're working on. And we're using some kind of a pattern language pattern, a domain specific pattern language to do this. So when I'm describing is the dream, it's not, it's what we're working on for the next two or three years. We had the very beginning of this. I don't know when it's a, it's going to be available.

Speaker 3:          34:57          Okay. But I've been told that you guys are not working so many requirements, so it might not be useful to you. All right. So now we, uh, you know, what techniques we shooting for each phases of the lifecycle. Okay. Um, I said at the beginning deal one 78 is a process that builds quality and safety and new programs, but really it doesn't demonstrate that you are addressing a specific risks and that's what we want to do. So we advocating the user safety case where you can have really uh, evolved to specify your risk explicitly and provide evidence says that you've written a retired those risks. Okay. So the reason they went with their one 78 is that it's mostly enforced by a set of standards. You know, I provide traceability throughout from requirements to testing. Um, I do quality reviews, those kinds of things. And then you get a checkmark, nobody's really checking what you've done and if you follow the process, you're done, you're good.

Speaker 3:          36:12          Right? Um, in a safety case, now if I, um, if I really list off my risks and I'm gathering evidence is to retire those risks, it can be huge. Okay. Now I cannot have a guy at the FAA does this checkbox and says, well, you follow this process. Okay, you're good. I have to have a guide that actually goes through the safety case and make sure that everything has been addressed properly. Right? So building one, inspecting one so that you get your certification at the end are the biggest, biggest obstacles to using this type of technology. So that's why you guys set up to actually try to work on this and build a tool that allows you to visualize, to create safety cases and visualize them and inspect them easily. It does some checking for you, but you can guide it and the human can use it to go very efficiently through it. Okay. Uh, for example, to just to give you a flavor, if you manage to formalize your requirement, then they can build the skeleton of the safety case automatically from your safety requirements. Okay. It's not complete, but it gives you the big, like 60 let's say 60 70% of it. Okay. Ultimately, all the results of those tools I have talked about before, the results produced by those two should feed into that safety case. So that safety case is really the nexus point where everything is integrating. Okay.

Speaker 3:          37:51          And why? I'm going through this, even though the FAA is not using this at the moment is because when I talk about autonomy, there's going to be a central piece. Okay. So let me step back. And what I talked about was mostly about addressing this bottom one, okay. Addressing the, uh, the cost of VNV inflight critical systems and then helping DFA, um, have the right processes and the right training for their people so that they can actually accept what's coming out of those tools because they are one 78 C is not developed by DFA, is developed by a consortium under our, our uh, agency called Itca, which has people from DFA, people from a vacation and people from governmental agencies or the governmental agencies and all those guys are coming to a consensus, um, writing a document and then the FDA says, yes, we had done this as the new standard or not.

Speaker 3:          38:54          Okay, but that doesn't mean they're setting fires. I actually know what to do with that new documents. So a huge part of our, what our colleagues at Langley are doing is to try to help DFA, um, build the training materials. And educate, there's certifiers so that they can actually accept what's coming out of those tools. Um, the next thing is, uh, like I said, we were asked to look at their traffic management systems. So I don't know if you guys have ever seen an embedded system for uh, for, for an airplane and a system for our traffic management from a software engineering, uh, point of view, those are completely different beasts. So, um, for example, the use of pointers and those kinds of things in an embedded system is very restricted. Anything dynamic is extremely restricted in an embedded system. Air traffic control, everything goes.

Speaker 3:          39:57          So if you think just of static analysis, then suddenly what you have that's efficient for embedded system might not be efficient for air traffic system. So that's going to require us to actually do some adjustments in the tools that we have. And if you're talking about using a model based approach to building a traffic system, it's not going to be with simulink is not going to be with Kate is going to be most probably with [inaudible] or at the most. Okay. So that's an or maybe a DL, but that means that you have to build translators to or loose language so that we can actually do the analysis of it. Okay. And at the very top is what they want us to shoot for eventually is addressing autonomy. So one thing when you're talking to Arrow people and NASA about autonomy, um, it can mean anything from automation to actually autonomy. Okay. It is not necessarily that you using AI in the system could be that you're automating a function. So we have to address anything in between, uh, in between those. Okay. Um, oh, one point before I go to, it's an me, um, this is not in the pie in the sky research, the days where we can play with the mouse checker and show it on a small system and say, victory. It worked. It's gone. Now we have a mandate that we have to infuse doors, any industry, those tools and actually demonstrate that we impacting the custom VNV the in the right way. Okay. So that's why we working with Boeing, GE, Rockwell, Collins, Honeywell and all the, and all of those.

Speaker 2:          41:54          Okay.

Speaker 3:          41:57          Um, and if you guys have any systems we can work with you. So that gives you a sense of what was accomplished in terms of tools. I've talked about a few things that I haven't mentioned is that when you starting to talk about complex systems, then model checker is going to explode unless you use some kind of compositional reasoning behind it. Okay. Um, and then at the top it shows you that, um, industry is starting to actually implement those tools, pick up those tools, build on them, and use them on real projects.

Speaker 2:          42:31          Okay.

Speaker 3:          42:34          No, like I said, um, we have to address autonomy. Why? Because no. So in its, in its infinite wisdom, um, at least the Irm d part decided we should have six strategic thrust that we need to address. And if you look at the bottom, I assured autonomy for innovation. Transformation is a big one. Okay. The other ones, and you might've had a talk by Kai goalball before is what's called real time system wide safety assurance, which is more about using data and analytics, real time on data to try to prevent or, or predict possible accidents. Okay. Um, so that means we have to adapt what we do in Vnv or charter right now is the flight critical systems. But this is going to ram down at one point. I was going to say you're done with this, you created the tools, you went as far as you could in infusion, move on to complex systems and autonomous systems and we have to start planning this. So

Speaker 2:          43:42          okay.

Speaker 3:          43:42          Um, like I said, the guys are working on safety cases and their tools and we're going to build on them. There have already been using them and building the safety case to get what's called [inaudible], which are the certificates you need to be able to operate and a flight the Jones to fund any kind of operations. Um, and then we built on another work that we've done for the, for DFA, which is kind of fun. The side which is trying to do v And v 40 classics. That's an interesting one for us for a very specific reason is because it's a very new way of building software for aviation and it hasn't been used before. What's happening at cast sex is, is, is the next generation for, um, collision avoidance. So right now the ones that all the Aircrafts are using is called t cass. And if you look at the way tickets look inside, it's just a bunch of, if then else rules, if this happened, then you do this.

Speaker 3:          44:47          If this happened, you do that. Okay. It's, it's the reasoning is explicit in it, but it's a monster. It's software. Okay. And they never quite sure they haven't missed a case. So in the next generation they want to do it completely differently. They basically build a probabilistic model of all the collisions that happen or the whole possible collisions that happen given the history called data. And then they had, and then they do optimization on it for some specific parameters. And the typical one is called an Mac, which is minimizing the number of possible, uh, collision. Basically mid hair, near mid air collision is what it stands for. Exactly. Okay. So they solve this and that gives you a big table and they put that in a big table. And where if you have the state of bureaucrats and the state of the aircraft that might be in collusion with, do you feed that to the table and pops out an advisory and that's what's going to be on board pretty much.

Speaker 3:          45:50          So what you have is a very simple software because really what it does is just reading off the table, that's it. Right? But all the intelligence or the rational behind the advisory is actually done in the model and in the optimization that was done to go from the model to the table. Okay. So in terms of VNV, that's completely different. You can still apply testing. That's still works. All right. But uh, the space for testing is extremely huge when you're talking about collision systems. So if you want to do anything smart or in thing that's like a bit clever, then you have to do the reasoning on the model and how the transformation from the model to the table is done. Okay. And if you look at it with, I mean the past experience on one was done at NASA in autonomy. I mean it's new for Arrow, but on the space side, it's been worked on for the past 15, 20 years.

Speaker 3:          46:51          Terry, give a talk. No, no, it should, you should ask him with the history of how engine. Well, it, when it goes way back, Julian could testify to this. Uh, so we, if you look at what was on Howard that was and was done, Deuteronomy, there's almost always some kind of a model based execution that's at play there. It could be a model, could be a physics model of the spacecraft so that you can do health monitoring. You compare the data to that physics model. When you have a mismatch, then you get an advisory or it could be using a planning and scheduling system or it could be new techniques like machine learning or reinforcement learning type of techniques. Then your model is more in your reward or utility functions, right? But the bottom line is that it's not in the code anymore. So that's why this type of work was a good stepping stone for us to think of what can be used in autonomy, uh, these days.

Speaker 3:          47:53          So when you talk about autonomy, most people tell you, well, but what do I do about unknown nouns? You know? And that's very true. I mean there is no way with the type of autonomy that's being discussed now that we'll be able to predict all the risks at design time. The environment is changing, completely can, can throw you off completely. There is no way you're going to be able to predict. So you're gonna still have to do some a design time, some VNV like the classical we've seen, but you're going to have to be able to do something at execution time. So most people are thinking, when we think about this, about rent, time assurance, what's going on in time assurance, which is rent, time monitoring and being able to, uh, basically a monitor a system and, and, and do something in real time. The where it doesn't work with DFA is that you still have to kind of certified that you're doing the right thing.

Speaker 3:          48:58          So you can certify the runtime monitoring system. But proving that your mum, you have enough money turns to catch all the possible problems. It's not possible. So somehow we'll have to come up with a system, especially if we're talking about drones all over the place, delivering packages and flying in urban environment. We'll have to have a sort of a very fication loop in real time that can provide you some insurance in it. So to do this quickly and to have a really time tight loop, I can't tell you when I tell that story to the traditional aviation, they look at me like you're nuts, but I'm hoping you guys would be more receptive if you're telling me you're nuts, the numbness. But to get really a tight loop there that can do some kind of certification, that means behind it. You have to be able to reason about risks.

Speaker 3:          49:55          Um, even though you have an identified those risks. So this is where we look at the safety case as something right now. Safety cases done a design time. I check it, I get my certification, it goes into a drawer and nobody looks at it anymore. Right? Or, um, or a thesis is you keep this, and this is a live document throughout the life of the system all the way until it's retired. Okay. And you use this to actually reason about risks. You add risks to it, but that means that you're able to reason and identified risk about your domain, your application domain. So this is what I'm not gonna I'm not expecting you guys to go for that whole picture, but this is pretty much what this is saying in here. Okay. And like I said, the traditional industry is looking at us. I think you guys are nuts.

Speaker 3:          50:52          This, you'll never get there, but that's what we're going to probably shoot for in the next, uh, five years. Okay. And this is the research foundations. I will do a lot of form of domain theory, uh, semantics driven safety. And then he says big one by directional transformations between the arguments in the artifact because DFA always wants traceability between everything. Okay? Uh, probabilistic analysis and, uh, and systems to actually help, uh, provide the information. And this is it. This is all I have today. I'll be happy to entertain questions. If it dives deep into a technology and I don't know know enough, I'll provide you the information of the guilty party. Okay.

Speaker 4:          51:44          Uh, so, uh, how much of the problem of verification, especially at the requirements level, is modeling the system and how much is modeling the environment?

Speaker 3:          51:59          Uh, truthfully in terms of the requirements, you don't have that much about the environment. It's mostly a bad the system. So yes, that means that there is a part that's missing in there. And, and that part, especially if I'm talking about addressing all the risks and the possible risk and as to come from your safety case because the beauty of the safety case. Um, so I should say that, um, when I talk about certification Idfa, and when you do dear one 78, it gives you what you call what's called the air worthiness certificate. Okay. It's not on the software. It's on the system that's using the software. But you get air worthiness. That means you worthy to go in the air. That doesn't mean that gives you the right to a period. There is a second stage that looked at year, uh, operational part and how it's been one environment is going to be operating. If the beauty of the safety case is all of this is in the same place, the operational environment and the airworthiness part of it. So this is where the safety case, we'll have to help us. There it is. This is a problem because the current industry is not using when a reasoning in those terms, they're usually separate teams

Speaker 4:          53:16          in the part of the coalition, like a new system that basically you change the system from this bunch of easels to like a pre calculate data table that you upload and then, and then the system uses. Huh. Um, as you said, the system and that was much easier to verify because it's a much simpler system, but how can you verify that the actual data that you're producing, the table that you're uploading, um, is correct. I mean, and now these actually is better than the other system. I was

Speaker 3:          53:49          no more formally, you're mixing two concepts I'm doing and say that was easy. That's actually a challenge. The challenge is exactly what you stated. How'd you very far that what's in the table is actually what should be in the table. Okay. So it's, it's multiple thing when you um, the first part is the model is built and we remembered that model will be frozen out. Uh, I'd execution time. It wasn't a happy appear, right? It's, it's just used. The model again is produced from historical data and then it's going to be solve in terms of using some kind of optimization engine for certain criteria. That result of the optimization is what's causing to the table. Okay, so you're right. The model is at the core of the verification problem there. The first problem is I do you have the right data? This is the first bad part because it's all based on historical data.

Speaker 3:          54:48          Okay. I haven't seen anything that says we're going to keep in pre running the mile to make sure that we have the right, the right model for the current density of traffic, for example. Okay. The second part is when you do the, the, the optimization and the model, you have to discreet ties that model. That's a model that's actually continues in, in nature. Um, eight has to be discreet. And the first verification question is what is the right, uh, discretization a level for this. Okay. And after that is I did you optimize for the right actually for the right power meters and your mom. So it, it's a very different way of looking at the problem and, and I'm not going to claim we solving the whole thing. We've provide parts we provided part of the solution, not the whole solution to it. And if you have suggestions, I'll take them.

Speaker 3:          55:57          I don't know. I'm not sure. I mean this might be showing up in, um, um, well I live in mountain view right across the highway, literally from Google. So I see d autonomous car going from my neighborhood. Um, I don't have many details about, uh, what's happening, but for one, I've been gathering your guys every time are collecting about the current, right? Right. And all goes down to a huge database that have like huge amount of scenarios and then you analyze those and that's how you modify whatever the software is doing. Right. Um, in some sense it's a little bit the same problem. It's like you probably have a step where you look at then all that data, then you have to model it and then come up with the software after that that does it. Okay. I very much doubt that you have if Denelle's type of software going through all the scenarios. So I don't know enough about that part, but it's probably a similar problem that you have to, to solve there.

Speaker 4:          57:08          I used to these kind of tools in particular in Missouri followed the safety moods interaction with modeling especially well. Um, but like does this give you a new perspective on how you would validate that your controllers responded appropriately to the dynamics that you're like crafting safety cases that say, like in this situation the controller should do this particular thing or not do this particular other things.

Speaker 3:          57:30          So that touches has a different area than we haven't really addressed. Um, that touches is how you come up with your risks given new system. In this case you're putting in, in the system and control system, uh, uh, framework. Um, they're like a lot of techniques that can be done for this. I mean the traditional me ea type of stuff, but you can be a lot more refined. Truthfully. We have an address. This part we haven't touched that part. We asked him that there is an end of tools to do this out there. Um, the closest we've been doing, and this is work that we're doing with Oni in France where we looking at the code, implementing the controller and trying to prove controlled types of properties like stability and those kinds of things, which is extremely hard to do. Uh, our static analysis is based on abstract interpretation, which means to give you an answer but something we building an abstraction around the data points. Okay. We as opposed to a static analysis where you would go, uh, explore every path which is called the past sensitive or, or flow sensitive analysis. Um, because that doesn't scale that one. So if you reason about abstraction, then it starts scaling. But when you want it, it's too rough. The ones that we have right now is too rough for a, um, like stability properties for control theory. So we have to go to techniques that are much heavier, um, and, and truthfully, we haven't implemented those in the tools yet. Okay.

Speaker 2:          59:12          Thanks. [inaudible].