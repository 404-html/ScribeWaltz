Speaker 1:          00:00:05       Thanks again for coming and please join me as we give a warm welcome to Kate on. Yo.

Speaker 1:          00:00:15       Thank you Tom. Thank you everyone. Hello, fellow humans. Wait, actually, I guess I should check and make sure. Are there any robots here? Any robots? I raise your hand if you're a robot in the audience. Yeah, I don't see any, so I think we're safe to proceed. But you know, I asked this question every once in a while cause I figured one of these days there's going to be kind of a little spindly mechanical arm that comes up when I asked that question. I'm not really sure what I'm supposed to do at that moment if I'm supposed to invite the robot, come to come up here and take my job. Because that's kind of how we talk about robots and automation and AI and everything these days is like with this fear, this dread about what it's going to mean for human jobs, for humanity, for kind of existential reality as we know it.

Speaker 1:          00:01:05       So my premise has been to think about how we can make technology better for humanity, better for our future. And of course better for serving business purposes. But in doing so, I think we have to start back from one of the square, sort of one of the foundations. And that is to think about what it is that makes us human. What is it that makes humans human? So I'll ask you to indulge me and just think for a moment of a word or a characteristic that you feel like really captures the human experience. Like what one characteristic is it? And I won't have you call it out or anything, but just hold it in your head for a moment. What do you feel like it is that really makes humans human? And so let me ask, how many of you by a show of hands thought of something like creativity or problem solving or innovation or something like that?

Speaker 1:          00:01:57       Anyone who one? Okay. A couple people in the room. Good. Okay. So that's a pretty common answer. Um, how about, this is a more common answer, I think empathy or love or compassion? Anyone? Yeah. Okay. A few more hands. Those are both great. I think great characteristics and admirable qualities of humans. I didn't necessarily specify that these needed to be uniquely human attributes. But if you think, if we think about those, they don't feel like they are uniquely human, right? Like we've seen creativity and problem solving and nonhuman animals like Otters, Bang, Mollis fun rocks to open them and Ravens use tools and we've seen a compassion and love from a elephants and dogs and other other species. So we know that those are exhibited by other animals. And I don't think it's too far fetched to imagine that in the not too distant future, we might see at least superficial indications of machines exhibiting those kinds of qualities in their behavior, interactions with humans and maybe even eventually everyone machines, which will very interesting at a surface level.

Speaker 1:          00:03:02       But how many of you, when you think about what that most human of characteristics is thought of checking a box? Anyone by show of hands? Of course you didn't cause it's absurd. But this is the sort of premise. The problem that we encounter in technology a lot of the time is that we don't necessarily think through this kind of foundational experience and we are presenting absurdities as if they are sort of foundational truths. Uh, and besides which, if we were to try to claim that this is a uniquely human characteristic, we get beat out anyway by machines can also do this characteristic. Uh, so I don't know how many of you have seen this little goofy guy but he's kind of fun.

Speaker 1:          00:03:53       So I have come to be known as, as Tim mentioned, the tech humanist and I take this, uh, this sort of moniker a pretty seriously cause I feel like there is this, this area around which technology does have the capacity to solve human problems. It also has the capacity to scale. Like we are experiencing automation and AI and all kinds of other emerging technologies bringing scale to the types of solutions we create. Like never before. And so I think it behooves us to really think about what the human experience around that scale is going to be and what the human experience around technology is going to be. And how we can make technology better, solve business problems and solve human problems at the same time. So as I talk about being a tech humanist, and as I think about solving those challenges, I'm excited that you all are in this room and on the live stream and watching on the video later.

Speaker 1:          00:04:48       I hope, uh, and then I want to offer that perhaps that that is also you, that you may be also our attack humanist. And I'd like to offer that term to you so that when you see my book, uh, as Tim mentioned just came out September 24th tech humanist, uh, that you will see that title and think I'm describing you as well because that is the truth. I'd like to see us all sort of join hands in this movement to create more human technology and more wide scale human experiences that are more meaningful and more integrated and more dimensional with the technology we create. So the premise there is how can we both make technology better for business to solve business challenges and make it better for humans? Uh, and I think that, that, that both and framing is the key to the whole thing. We need to understand how to, uh, accept that these things do need to be integrated together.

Speaker 1:          00:05:44       And I would propose that the way to accomplish this at scale is to focus on creating more meaningful human experiences at scale. So how do we focus on getting meaning into the human experiences? So the way that that looks in the model that I proposed is this, on one hand, how can we think about scaling business meaningfully through data, through strategic alignment and automation? How can we think about using the tools at our disposal to make business more effective while also creating more meaningful human experiences and scaling those through data and automation? I've had the opportunity to test this idea with a lot of different companies that have consulted with, spoken, with, advised, worked with on different projects over the years. And I'm excited to say that it works in almost every industry I've encountered. Uh, it, it's, it's sort of provides great results no matter who you are or what you're trying to accomplish.

Speaker 1:          00:06:42       Every company is trying to achieve profit, right? Every company is trying to achieve revenue based metrics in, in what they're going about. Even if you're a nonprofit organization, you still have to be accountable to some sort of profit and loss scenario. There's some sort of breakdown of the financials that you need to be accountable for. And I'm happy to tell you that the work of creating meaningful experiences actually does lead to increased employee retention, decreased customer acquisition costs, increased loyalty, and all kinds of other directional metrics that lead to more profit. Of course, it's also the right thing to do. It also creates a better experience for all of us. And I want everybody to be motivated by, you know, kind of this, uh, this aesthetic of wanting the world to be better and creating more meaningful experiences being its own end. But if we have to be motivated by profit, we can be.

Speaker 1:          00:07:31       And that's all a good thing too. So let's unpack this just a little bit. What I mean when I talk about creating meaningful human experiences at scale, what does that entail? So first let's think about what meaningful really is. So the example of the, uh, click the box to confirm your humanity. I mentioned, I think that that's an absurd example and they had this kind of running a hobby of appreciating the tension between meaning and absurdity in the world. But I feel like anywhere there is a lack of meaning, it sort of opens up this void into which absurdity can flow. So where we don't create enough meaning, where are we don't describe enough meaning we allow absurdity to flourish. So there's enough opportunity for that in technology as it is. And business really. I think you all probably have this experience. I'm guessing that there are areas where, let's say you talk about work things in ways that you wouldn't talk about with your friends outside of work.

Speaker 1:          00:08:34       You use language or terminology that your friends who don't work with you wouldn't, would not understand, uh, or there are things that you do at work that just don't, that are kind of like, that's the way we've always done it. But anytime you think to yourself, this doesn't make sense, that's a really big clue because making things make sense is what meaning does. So we have an opportunity to step back and assess absurdity and recognize that that we can infuse meaning into those structures and create more opportunity to avoid meaning. Two, to keep away from meaning. So the, the reason that that works, I believe is because humans crave meaning more than any other characteristics. So if you were to ask me what I think makes humans human, this is what it is, is that we seek meaning in, in all areas of life. We are compelled by meaning.

Speaker 1:          00:09:21       If you offer us a meaningful answer or solution, we are compelled by it. How many of you are a Douglas Adams fans? Anyone? A few? Okay, so you already know where I'm going to go with this in life and the hitchhiker's guide to the galaxy series. The answer to the great question of life, the universe and everything was 42 of course. So Douglas Adams wrote per set in interviews that he chose 42 because it was not too high and not too low of a number. And because it was just funny and it is, but I don't know if you know this, but in, in uh, on reddit you can find this and a few other places a collected around the web, there are, uh, kind of collections of alternate explanations for why 42 actually kind of makes sense as the explanation of meaning in the world. So for example, there are 42 characters in the phrase, it's the answer to life, the universe and everything. So, right. You're convinced now, right? No. Are also, there's like 42 dots on a pair of dice. So that answers everything. Uh, which I thought was just kind of a throwaway explanation, but my husband said, well, life has kind of like a roll of the dice. So I thought, well, all right, fair enough. Others, this, my favorite of them is this 42 is apparently the unicode character can unicode value for the asterisk character, which as you may know, is a wildcard symbol. Often in computing, which means it can mean anything, right?

Speaker 1:          00:10:53       But okay, so in the end it's obviously it just a coincidence because Douglas Adams didn't mean it that way. But that's the important point is that, uh, even though Douglas Adams didn't mean it that way and it is just a coincidence, it is an absurd and poetic and beautiful coincidence, but we always make meaning the way we have always done and always will, which is by a scribing different significance to different events based on how and how much we value them or in other words, by making it up as we go along. And I think that's the encouraging thing about this is that even though we talk about robots and automation and AI in the broad mainstream in a scary way, what this suggests is that there is this kind of open interpretation to the future. We get to make meaning for the future as we go along, we get to decide the future as we go along. You get to decide the future as you go along. And that's really incredible because right now the, the possibilities, the power of what's happening within technology and within the scale of emerging technologies means that we have the capacity to create the best futures for the most people. There's really this Po, this potential, and I think even an ethical responsibility to think about how solutions can scale to that sort of level.

Speaker 1:          00:12:20       So let's go back to unpacking. Create meaningful human experiences at scale and what is it that human experience is really describes.

Speaker 1:          00:12:30       We talk a lot in business about customer experience, user experience, or depending on your industry and maybe patient or gastro visitor experience of student experience. We don't often in many industries talk about human experience in this integrated way and this way that brings all of those roles together and appreciates the fact that there is this kind of holistic, a human experience that that transcends any of those roles that you are, we are all of those roles at any given point in time. And so even though you may be performing as a customer and a customer experience, you are still a human coming into that customer experience. And the important thing about that is the transcendent empathy that can come from understanding the baggage, the context that someone brings to that interaction. So there's an opportunity to create these more dimensional interactions, these more integrated than interactions.

Speaker 1:          00:13:21       And so to create more meaningful human interactions, it turns out we need to design more integrated human experiences. You'd think about how to blend all of those roles and understandings together and bring an understanding of where someone has been, where are you meeting them in the world, and how you can create these kinds of senses of dimension, uh, and wholesome. So I promised a venn diagram to a friend earlier and I have it the best venn diagram in the entire world. I'm sure you all have seen this. If you haven't, you'll want to rush out and get this tee shirt right away. A tensile graphics makes this Venn Diagram. But the illustration here really I think gets at the point then when you think about what is possible on one side of an equation, such as the best technology or the technology to make business better and what's possible and that other side of equation, like what's possible to make technology better for humans.

Speaker 1:          00:14:18       It's only by really thinking about the intersection of those things that you really come at the best solutions like platypus. Kutar or you don't get platypus Kitara until you're doing some serious both ending. So that's, that's the opportunity. And really what we're talking about is augmenting human experience with data and context. So the broader opportunity in a technology science is to really think about where does somewhat, where are you meeting someone in the world? What data do you have to understand and appreciate where they come from, what their preferences are, what their tastes are, and how can you create context that, that addresses the objectives that you have as a business and the objectives they have as a human and the role that you're meeting them in and the alignment of those objectives. Well, how can we come at that in a way that, uh, that provides that?

Speaker 1:          00:15:07       And so I actually kind of think of this in a way as being meaning as a service in a sense. And so an opportunity to think about offering up in meaningful construct that aligns your objective and their objective and providing the, the uh, the hooks in a sense to be able to expand upon that. And I really mean any meaning of meaning. So meaning as we talk about it could be at any level. We talk about meaning as it relates to communication. So I'm a linguist by education, so I think about the semantic layer, you know, how we communicate with one another, what we convey across our, our communications with one another. But it can be all the way through. You know, you probably spend a lot of your time if you do a lot of development or engineering in patterns and significance, that's probably a layer that you spend a lot of time in.

Speaker 1:          00:15:53       But it could be all the way out to sort of the existential and cosmic layer. And what is it all about? Alfie, you know, that sort of thing. I think in a sense it's almost like Api thinking for everything. You can really sort of think about how one idea integrates with another and how, what does it, what does meaningful on one side, like the business side can be meaningful on the human side of the equation. How do you provide, you know, sorta hooks and intelligence across those different parts of the experience and make sure that that meaning is being transferred through that layer.

Speaker 1:          00:16:27       The integration that most brought me to this realization is thinking about how the design of experiences online now regularly intersects with the design of experiences offline. But more and more as we think about physical experiences, they come with some sort of digital component or some sort of trackability or traceability with that, that physical experience or when we think about digital experiences, we have to think about the physical context somebody might be in as they encounter those interactions. So I wrote about this in my last book, pixels in place. So thinking about things like the Internet of things and wearables and beacons and sensors and all kinds of connected smart devices and how are those bring that sort of connective layer of between those two worlds. But the important point about that is that just about everywhere interesting that the physical world and digital world connect, that connection layer happens through us, through humans, through our human experience.

Speaker 1:          00:17:23       It's our movements. That's our behavior. It's our patterns, it's what we want, what we do, what we indicate that really creates that connection. So again, it comes back to sort of thinking about that integrated human experience. So I proposed this model in pixels in place, uh, which is integrated human experience design. Thinking about how to blend those online and offline contexts, thinking about how to kind of come across all the different levels and roles of humanity that you might encounter. Thinking about how to think about experience in an integrated way, interactions and transactions across all the different touch points that you might have. And know it the way I'm defining the word design, which is the adaptive execution of strategic intent. So you know, you have an intention, you have a purpose to what you're trying to do with any given design initiative and you know that you're going to probably not get it exactly where you want it to be on the first go.

Speaker 1:          00:18:25       So we need to build an adaptive iterative process to this. And the more we do this around a framework of creating that meaningful interaction and that dimensional relationship between business entity and human that's consuming that experience, the more we stand a chance of conveying some sort of meaningful truth. So the elements of integrated human experience design as described in pixels in place, I'll go through it really quickly because what I want to get to is that with tech humanist, I've actually built out upon this to a more automated understanding of experience, but within integrated human experience design in pixels in place, we look at integration. Of course, that kind of comes along for the ride. So we're already talking about all these layers that are being integrated, the online and offline contexts. Uh, we're talking about dimensionality. So how does something come to life across different sort of touch points or ways in which you interact with people?

Speaker 1:          00:19:23       How does, how did the metaphors and cognitive associations come to life? What sorts of intentional things are you communicating through all of the choices that you're making about the language that you use, the iconography you use, and the cognitive assertions you're bringing along with that cognitive associations. Uh, you're bringing along with that intentionality and purpose. So how have you defined what it is you're trying to accomplish? And that comes into play at a, at a more holistic macro level as well, which we'll get to in just a moment and a value and emotional load. Like where are you meeting someone in the world? How challenging is that context? If you're designing for an encounter in a hospital, for example, it's going to be a very different type of a valuer emotional load than if you encounter somebody, uh, at a, at a children's museum where they're having fun.

Speaker 1:          00:20:07       Uh, hopefully having fun alignment is of course that that sort of foundational principle of understanding what the business objective is and understanding the human objective and making sure that they are as tightly aligned as possible. And then adaptation and iteration being of course, that that process of making sure that we are building upon what we've learned, we're using experimentation and, and that, that mental model of building our learnings as we go. There's also this premise that experience has a sort of to in a sense two layers to it. Um, if you think about human nature as this sort of ongoing truism, like we all have throughout time needed to drink water for example. But then there's the shape of that experience and how it kind of gets packaged up and dimensionalized. And so you can see this bottle of water a is an example of saying, well, if I were to put that water into sort of a heavy glass bottle and label it with some sort of minimalistic type face sort of brands and you know, create that whole aesthetic and it has this kind of hipster vibe to it.

Speaker 1:          00:21:18       Maybe I feel like I'm being a more aspirational version of myself because I'm drinking maybe even the same water out of this cool bottle and I feel like a better version of who I am. Uh, then if I just drank it out of the tap water tap glass or whatever. But so there's this kind of ongoing way in which, uh, shapes evolve. And it's important I think to recognize that as we create these integrated experiences that human experiences do evolve with the shapes will always change more readily than the nature and helps us get into contact and sort of create this continuity across time with the human nature that persists throughout the experiences that we're designing for and yet be ready to adapt to the changing shape of experiences. So with that, that leads us into this, this opportunity to think about how machine led experiences can actually be more meaningful.

Speaker 1:          00:22:12       The more we're thinking about automated experiences and artificially intelligent experiences, how can we think about making sure that the humans that interact with those are having as much of a sense of meaning and significance and uh, and dimension to those. So what I proposed in tech humanist is, uh, that we don't just automate the meaning menial, we automate the meaningful, I'll go through each one of these in detail of course, uh, that we automate empathy, that we use human data respectfully and that we reinvest the gains in efficiency that we get in business from automation back into humanity and human experiences at least at some level. And so we'll talk about each one of these. I'll start with this. I think a lot of times when we talk about automation are our, our base understanding is that we should automate menial, meaningless things so that humans can do higher order tasks, which is a nice enough premise until you start thinking about that at scale and start imagining a world in which all kinds of functions have been automated.

Speaker 1:          00:23:12       And most of our world is automated and most of our interactions are with machines and they've all been automated to the meaningless. So I think it's a, it's a yes and a both and sort of scenario. We do need to think about automating the menial, meaningless functions to free ourselves up to think about higher order things. What we also need to think about what's working, what are human interactions that conveys some level of empathy and nuance that create some sort of significance and dimension and how can we kind of work to automate those as well? How can we capture some of that significance in those automations? So in this way, we're talking about using data and technology to scale, not just for efficiency, but from meaning to think about ways that we can actually create a sense of dimension in the world around us. One way that that works is I like to think about this model of this relationship between metaphor and metadata.

Speaker 1:          00:24:05       And I think the easiest way to explain this is a, is a slide I stole from Brian Chesky, the CEO of Airbnb, when he was demoing a couple of years ago, the new campaign that they were launching at the time, which was the, don't go there, don't go there, live there campaign. Anybody familiar with that? Because we run across that at all. So the idea was, you know, even if it's only for one night, go to every place you visit as if you're a local, you know, treat that city like you're a local. And this slide was an illustration of how you could experience a different type of, um, of approach on TripAdvisor versus with the airbnb approach of trusting the local experts. But note that extend. So this is obviously Paris and note that every thing on each list is different except for one, which was the Luxembourg garden, which is my favorite place in Paris.

Speaker 1:          00:24:59       So yay me. Uh, but the, he, each of the other things on the TripAdvisor list, it's really just a popularity contest, right? It's all just what are the most sort of bucket list items that someone would associate with Paris? And on the Airbnb side, it's who has, who has the most significant understanding of the city of Paris? What did they recommend as being the places that you'd sort of must visit and must experience in Paris? And what I think is interesting is when you think about the metaphor that's really underlying this, it's clear that the TripAdvisor metaphor is much more about this kind of a casual tourist experience of the world. This kind of conventional understanding, right? Whereas the airbnb thing is that sort of don't go there, live there, this knowledge of the expertise and then the metadata clearly is it's like the same city.

Speaker 1:          00:25:51       These are all the same landmarks. They exist in either case but it's one is being rated for popularity and one is being ranked for this expertise where authority. So the way that these two sort of dimensions interact with them, then a creates this more meaningful understanding of uh, of what the company is trying to achieve and how it brings it to dimensional life for, for the person that's interacting with it because that meaning and forms the purpose that the company is bringing to life in their experiences and the purpose of the company that they're trying to bring. The life sort of fosters the meaning that the person is going to experience when they interact with, with the touch points that the group for the company creates if they've done it well. And the Nice thing about this when you think about how this really comes to life in an automated machine led way, is that humans really, I think when you think about what, what the, uh, the research shows what we most thrive on is a sense of meaning and common goals and a sense of fulfilling something bigger than ourselves.

Speaker 1:          00:26:54       Whereas machines thrive on this sense of clear instruction, right? And what leads to both of those things is purpose. I'm not talking about perfect purpose, like in this kind of touchy feely, you know, spiritual sense necessarily. I'm talking about purpose as a set of clear instructions or as a sense of clarity about what it is you're trying to achieve. And what that does is leads to this ability to kind of bring all your resources to bear in a very efficient way and to align all those resources to set priorities very effectively and make sure that everybody's kind of rowing in the same direction. My favorite example of this, of companies setting a strategic purpose and really using it to operationalize around is Disney theme parks. Uh, and you know, from a digital transformation perspective than my magic band program. How many of you then to Disney world or one of the Disney theme parks since they've introduced this, it is pretty magical, right?

Speaker 1:          00:27:51       Like so they have articulated their purpose statement as create magical experiences. It's really just those three words create magical experiences. And so you think about cross the organization just about anyone in any function can understand how they can solve problems relative to their scope of their work as it relates to creating more magical experiences like a problem that's brought to them. They can just go along. I know how to solve this. As long as the company actually sort of gets in line behind that and allows them the autonomy to solve the problem the way they need to. But think about that as it relates to digital transformation and deploying $1 billion program, which this was that investment scale for the company. And you can do that with complete confidence knowing that this magic band is going to allow people to be able to go around the park and use it as payment, use it as access, uh, use it as a sort of preferences and all kinds of information that are tracking that certainly gives a lot of useful information to the company as they sort of merchandise more effectively and so on.

Speaker 1:          00:28:56       But that, that, that ability to translate the purpose into a deployment at $1 billion scale is very clear from, from that that program. So we can design experiences that are aligned with strategic purpose so that we could actually see that understanding of purpose, scale to massive levels and purpose is the shape meaning takes in business. So that's how we get that meaning to, to be felt and understood at a human level. By the way, I keep talking about scale and so I want to unpack that a little bit too. So when we think about creating meaningful experiences at scale, normally when we talk about scale and like a startup, we're a corporate business, a corporate, uh, growth sort of scenario. We are talking about like removing hard limits so that growth opportunities can flourish. And usually we're talking about that in terms of multiples, let's say, right, like three x or four x or five x or 10 x if you're very, very lucky. Um, but what happens when a notion meets nearly unlimited expansion possibility when data can model it and software can accelerate it and automation can amplify it and culture can adopt it. And that's what really we're talking about with machine let experiences, and that's why it's so important that we think about creating these in a more meaningful way. Because if we don't create the meaning into the system, what are we doing? We are allowing absurdity to encroach, right? And we don't want absurdity to scale.

Speaker 1:          00:30:26       So my favorite example of absurdity, it's scale. It's one that I, I don't mean to knock the program or the product because I think it's incredible. The Amazon ghost or how many of you have experienced it in person. It's pretty cool, right? Like the idea that you can actually just walk into a grocery store, you scan your app as you go in and uh, and just pick up whatever you need and walk right out. And there's no, you know, sort of checking out process. It just kind of knows it. But through cameras and sensors and so on, it knows what you've picked up and what to associate with your account and you're good to go. So obviously we have to talk about a cashier jobs and what that means for the future of human work as that goes to scale. But let's leave that set aside for just another moment because right now what I'm focused on is something else. What, what happens when you open the APP for the first time and you get this onboarding that explains that as you pick things up off the shelf, the sensors, no. You know what you've picked up and as you put it into your basket or in your bag that you'll be charged for it. So it says, don't pick up anything for anyone else.

Speaker 2:          00:31:35       Okay.

Speaker 1:          00:31:36       Which is fine except that you start thinking about, I don't know about you, but I get asked all the time to help people in stories. You seem pretty tall. You probably get help ask for that. Uh, you know, you get asked and, and now it's like, okay, well I can't really help that person get the thing off the shelf cause it might charge me for it. And there's a way to get it charged back. And, and Amazon might fix this before it goes to scale, but really like 3000 Amazon go stores have been announced before 2021 so if this doesn't get fixed, and if it is, it's something that we all start adjusting our behavior and not helping other people in the Amazon go store. Well that's the future of retail. We're talking about 3000 Amazon go stores by 2021 is going to mean that retail environments are going to be this cashier list environment before too long.

Speaker 1:          00:32:24       And so we won't help each other in any stores. And how long is it before we don't help each other at all. And I know that sounds like hyperbole at some level, but what I mean to suggest is that the idea that experience at scale does change culture. And I that's important to recognize because really experienced that scale is culture. What we sort of all collectively agreed to do with each other and how we agree to interact with each other is culture and are all of the work that we do. Creating human experiences sets that context and creates that, that modality. So that understanding is, is super, super important. So I do have a slide here and if anybody needs these slides, I'm happy to share them. Uh, but, but a slide that asks questions and it's in the book as well. If we were to try to, uh, the program, the absurdity of not helping each other, we could ask some questions to step back from that and think like, how do we not create experience at scale?

Speaker 1:          00:33:23       That's going to be absurd. How do we make sure that the brand isn't going to be impacted if we create products or solutions that might scale in ways that are unexpected? How do we, how do we pivot to deal with that? You know, what does that look like? So there's some questions we can ask to anticipate that. But primarily I think the challenges or the opportunity is to think about meaning and to think about keeping absurdity from scaling. This is a comic that was drawn from me by my friend Rob Cottingham, uh, to illustrate the sort of opposite of tech humanism. I don't know if you can read it. It says it's getting harder and harder to hold onto my humanity, but wow, is it easy to track my Amazon deliveries? So of course that's absurd, but it's the idea that we aren't thinking about what do we really want meaningful experiences to look like?

Speaker 1:          00:34:11       What do we really want our future humanity to look like? How do we create technology solutions that amplifier humanity and don't get in the way of humanity? I think that's really what we're talking about. The second, uh, premise of machine lead machine, uh, meaningful human experiences as to automate empathy, which again may sound like it's a contradiction, but I think there's an opportunity to think about the ways that any kind of experience that we design creates some kind of connection and to, to create as meaningful a connection as possible. So how many of you remember the Seinfeld episode where Kramer got a new phone number and it was one digit off from movie phone? Anybody remember this? So anybody remember? Moviefone I know the APP just sort of ended as of like a week ago, but um, but in the eighties and nineties or whatever, we all had to pick up the phone and actually call a service to tell us what movies were playing.

Speaker 1:          00:35:10       And in this episode, Cramer had gotten a new phone number. It was one digit off or move your phone. And, uh, it was a obviously touch tone service. So he couldn't understand the touchstones that he decided that he was going to impersonate movie phone, uh, but he couldn't understand the touchstones. So he ends up just saying, why don't you just tell me what movie you want to see? And I always find this to view such a prescient example of how we think about machine driven interactions and how we think about human based interactions look like the, the sort of relationship between those two. So I think of the movie phone Kramer model as a sort of agile deployment of emerging technology that you can think about the uh, the robotic interaction and the human interaction as being somehow interchangeable with one another so that you can actually use human interaction to gather patterns that you will encode as a chat bots or other types of automation.

Speaker 1:          00:36:07       And not just suggest that you would lie, that you would print, present a human a and have it be posing as moviefone or, or whatever your equivalent is, but rather that you would have some kind of agile human based interaction that gives you the insights to be able to create scripts and create patterns that develop or help you develop frameworks for automation. And of course you're starting with if then statements, but you're quickly trying to work beyond the if then to get to the nuance. So if that is easy to anticipate, right? And in the kind of a frequently asked questions model of automation, if you're saying like that, if you're automating, let's say a chat Bot for a bank, you know that a lot of your interactions are going to be about how to change your password, for example, or how to set up a new account.

Speaker 1:          00:36:53       So if someone wants to create a new account, then here's the answer and here's the, the sort of flow diagram that you can walk them through. But the nuance beyond that is I need to change my password because my ex is stalking me. And it's a dangerous situation and there needs to be some human interaction. There needs to be some human nuance to that experience. So that's more where the empathy gets automated into the process is finding those types of interactions and finding the opportunity to build out the relationship between the automated and the human. And also when we're looking for patterns that we're not just looking for arbitrary patterns and encoding those arbitrary Venus is also sits in opposition to meaningfulness in much the same way that absurdity sets an opposition to meaningfulness. So we want to make sure that we're finding meaningful patterns and automating those.

Speaker 1:          00:37:44       Because in all of the work that we do with this, we cannot leave meaning up to machines. Machines won't do meaning. That's just not something that machines are really equipped for. So it has to be humans that determine what, what is meaningful and that, I love this example. I know many of you probably work around image recognition or AI and so you know this dilemma very, very well. It's, I know a lot of algorithms have advanced since this day, but you know, the puppy versus muffin sort of a problem is one of my faves and that it always gets a chuckle. I see some smiles in the audience. Uh, but, but it's true that subtle nuances aren't really where AI signs and many cases at this point, at least not at a meaningful recognition level, not being able to say that, uh, the muffins are, have this certain meaningful characteristic and the human, the puppies, I'll have this certain meaningful characteristic.

Speaker 1:          00:38:38       Whereas I believe many of you are probably able to determine which ones a muffin in which one's a puppy pretty well. Here's some more. And by the way, uh, you know, which one's a barn owl and which one's an apple and not have any trouble with that. I bet which one's a croissant. But I think this an introduces an idea that there may be, there may be opportunities for humans to work alongside machines in ways that I add nuance and empathy and understanding to the machine lab processes, uh, cause humans generally do nuance pretty well. That's something that we are encoded for. We get meaning. That's what we're about. So we're able to add that into the value proposition. So when we think about the relationship between machines and humans, as we move into the, the, uh, the future of work and the future of that sort of economy, I think we're going to add the most value by being human and understanding meaning and nuance and understanding value and understanding each other and adding that layer to those interactions. So the third tenant of the machine led meaningful experiences is to use human data respectfully.

Speaker 1:          00:39:49       It comes from this idea that when we talk about digital transformation, I kind of feel like that's a little bit of a misnomer at some level because we already made a digital transformation at the moment. We started spending all of our time in front of screens transacting in front of, in bits and bytes with each other. So that's kind of a done deal. And what's really more meaningful than that is the data transformation. The fact that all of this is happening with a data layer behind it. That business has all kinds of data, visibility and transparency through the supply chain, through logistics, through operations and everything has this kind of clarity and transparency about what kind of trackability is going on, what's, what's measurable and all that. So it's a really interesting, uh, layer to work with. But when we talk about digital transformation, including automation and digitization and all of that, all of the many nuances of that, fundamentally what we're talking about is agility with data.

Speaker 1:          00:40:44       As companies become more digitally writing in, digitally transformed, are becoming more agile with database decisions. And that data that we're talking about is really our data. It's human data for the most part. Business data is largely about people. It's our purchases, it's our movements through space. It's our preferences. It's are, you know, all of our tastes and indications that we've made. And it really, what I'm saying is analytics are people, right? At some level, for the most part, when we are looking at graphs and reports and so on, we're generally looking at the needs and interests and motivations of real people that are, they're buying from our companies and interacting with them. And driving all of these decisions for us. And I think the flip side of appreciating that and treating that data with respect is understanding that what we encode into machines is really about us, that we are putting ourselves and our biases into, into the, the encoding, into the algorithms and everything that we create.

Speaker 1:          00:41:51       So the opportunity I think as we look at this tech humanist future is to encode the best of ourselves, is to think about how we can create our most egalitarian viewpoints and our most evolved understandings into the data we model, into the algorithms we build and into the automated experiences that we design and create. So we can use our data, our human data to make more meaning in the world. And we can recognize that the more we create relevance, uh, in those, in the alignment between business objectives and cumin objectives, the more we are creating a form of respect. But that also, the sort of caveat to that is that discretion is a form of respect to that we're also allowing people to say, be forgotten by us and allowing them to take their data with them. And that we can not make people feel like we're creeping them out by knowing so much about them and that we protect human data excessively, that we make sure we're being very, very, very careful with the data that we collect and use and business decisions because we recognize that it is human data.

Speaker 1:          00:43:02       The last point, and it's a quick one because this may or may not be within scope for many of you, but that as we think about, uh, the, the gains that we make in our businesses through automation and machine led experiences that we think about reinvesting some of those gains into how to create more meaningful human experiences at scale. Uh, and I don't think it's really a mystery why that's so important. Uh, there was a study done, a couple of versions of, of a study done on what jobs are potentially considered automateable and this is one visualization of the data from that study that shows the, the different cities in the United States and how likely you, the jobs that are there are to be automated over the coming years. I zoomed in on New York, which is where I'm from, and you see 55% of jobs are considered potentially automate automateable and you have to think about the socio economic impacts of that.

Speaker 1:          00:43:55       You have to think about the psychological impact of that, that humans have had a very deeply connected experience to work that we've derived a lot of our sense of meaning and identity from work. We say who we are in terms of what we do, and we've had names like butcher, a baker, a Tanner carpenter, and so on that derived from ancestral jobs that have been carried down through our, through generations of our family. And that's true across cultures. So it's a really important thing to understand that jobs are kind of going to change. There's going to be job displacement augmentation and replacement by automation. And we don't yet know what means for human meaning. And we don't yet know what that means economically. We don't yet know what that means, you know, sort of socio politically. And so there's a huge opportunity for us to take the gains that we make an automation and have this ethical contribution back into society, back to humanity and say like, what can we do to foster a sense of meaning and a sense of community in a sense of connectedness and a sense of more humanity with that, with those games.

Speaker 1:          00:44:57       So I think we can also think about repurposing human skills and qualities into higher value roles. So as we automate that, uh, one of my, the executives, it was another strategic workshop. I led a round on utilities company in South America and he found through our work and opportunity to automate a customer service function, uh, that was their most heavily access customer support question and function. And once he saw that opportunity, he saw that there was a way to take the humans that were working in that job and create oversight positions for them so that they can continue training the algorithms that we're going to, to create that automation. So obviously I'm very straightforward kind of replacement. It may not be a one for one. We may see job loss anyway, but some of that the investment is going to uh, offer up human, human, higher, higher value human roles.

Speaker 1:          00:45:46       So here are those uh, four tenants again. And uh, I think the summary of this really comes back to as you think about the work you're trying to do and how to create these more meaningful experiences through automation and through artificial intelligence and so on, it really comes down to this question of what is it that you are trying to do at scale? So that's the purpose statement. How can you articulate what it is your company is trying to do, your team is trying to do, you are trying to do at scale. And for me, the answer to that question is create more meaningful human experiences. It's just as simple as that. But the way that I can do that is by speaking with groups like yourself, working with executives, working with leaders, and being able to help them hone in on that purpose and really get clearer on how to create those more meaningful experiences that do align the business objectives with the human objectives that do bring the business results and that create a better future for humanity. So because business will have to scale through digitization and automation, business won't be successful longterm without it. It's table stakes, but humanity won't be successful without meaning. So in for that, I thank all of you for the work that you do. Thank you very much.

Speaker 2:          00:47:03       Thanks Kate.

Speaker 3:          00:47:05       We have a dory. There are no questions on it right now so we can ask a few local questions and if anything shows up then we'll, we'll get those included too. But I see a hand right here. And can we get a mic over here? Up The mic test, test, test. Okay, sounds good.

Speaker 2:          00:47:19       Okay.

Speaker 3:          00:47:23       Hi. Thank you for the top. First off. So for the rhetorical question you asked at the very beginning of talk, I know

Speaker 4:          00:47:30       a lot of people, if not most people I know would answer a soul. What makes humans human is a soul. So what advice would you give about how to automate religion?

Speaker 5:          00:47:40       Hmm,

Speaker 1:          00:47:41       that's a very interesting question. I actually have talked with a few people about the work that they're doing around automation and creating experiences for people at scale around religion. And I don't feel like I'm a in a really good position to be an expert on that. Uh, it's not the work that I do, but I do think that religion is fundamentally offering meaning, right? So really we're talking about the same principles we're talking about being able to offer people a lens into what is meaningful and then helping to scale that. So if, if there is a solution that someone is trying to build that is some sort of technology product for, uh, creating like a religious experience or a religious outlet for people or a community. And I think it really comes down to the same principles. It's just like religion as the industry in that sense. And we're trying to offer meaning through those experiences. I would be, uh, probably my best to take on that, but I think it's a, it's a more interesting question than that at some fundamental layer. And it sounds like a discussion over beers or something like that. So do we have another, another question? Yes. To your,

Speaker 5:          00:48:50       Yup. Hi. Thanks for the talk. I was really struck by your point about shared experiences forming culture and um, obviously, um, we in the technology world have a lot of, we sh increasingly kind of shape, shared experience. Um, so in the Amazon go and Amazon go a point about like people not helping you try there. That's something we can all probably agree as a net negative and even Amazon I'm sure would agree. Um, but there's a lot of cases where we have, uh, the potential to shape culture where the answer really isn't clear what is the right thing to do. A filter bubbles being like one controversial idea of whether they're a good thing or a bad thing. Um, so I'm wondering what's your take on how we should approach these problems? Like what principles should we use in deciding how to shape culture or what processes are institutions maybe we need to make these decisions.

Speaker 1:          00:49:44       Yeah, thank you. It's a really good and big question. Uh, I'd like to, to cop out and say that the entire book tech humanist sort of addresses that, but at some level, um, what it comes down to is trying to understand that that sort of strategic purpose, that alignment between business objective and human objective. Uh, and I think if you're looking at a, at a filter bubble type of example, for instance, as one example of something where a, like a social platform or um, or an online community is fostering or are a media company is fostering through algorithmic content filtering and so on, the sense of disparity between people's collective of what is truth. Um, I think you can probably come to some understanding at some level of, of view of that, that the business objective, which may be advertising or something along those lines and the human objective aren't aligned there.

Speaker 1:          00:50:43       So I do think that there, there is still a useful framework there. Um, but I do offer some additional ones in, in tech humanist as well. Um, it is a really good and important question and it's an important point for us all I think to, to consider in the work that we're doing. Um, because there's so many met positives and net goods that come out of let's say with the social media and the connectedness we have with each other, uh, and the way we're able to maintain relationships with such ease versus, you know, 20 years ago. But of course it does come with these, these sort of associated, uh, difficulties and the challenges of making sure that we're all sort of speaking the same language, which at the moment I believe were not, we were having that question or that discussion beforehand. Uh, so I'm going to leave it at that. I think there's a lot in the book, which I'll just keep pointing back to that, uh, that, that does unpack that a little further. But I genuinely think that that framework of understanding what it is the business is trying to accomplish and what it is that's good for humanity, how those things can be in line and it doesn't, it doesn't have to come down to a humanitarian purpose. It just has to mean that we're not accelerating something that is not ultimately good for humanity. That that I think is where the alignment comes back to.

Speaker 6:          00:52:04       Right. There's a question on the dory and it's sort of similar to a question that I had, so I'm going to try to merge them together. Um, the question is on the dory, it starts like this scale tends to force humans to reduce their variety to adapt to machines instead of the other way around. So further, what about ways to reduce scale that are compatible with business? Um, you mentioned distributism decentralization or something else and I'll add that. I think that a lot of this technological change is really coercive. Meaning either you get with it or you get left out, particularly around the job changes that you talked about and like how much is our responsibility to bring people along. Like to offer the lifeboat. Okay. And how much do people really need to get in the boat?

Speaker 1:          00:52:56       Yeah, I think that's a, that's a really difficult thing to be able to break down in one, one side or the other, right? Like I think that the change is coming no matter what. What we find though is the change is going to be disproportionately, uh, felt. So jobs that are most likely to be automated, our jobs like truck driver, cashier, um, these types of things. And uh, what know is that statistically those jobs are disproportionately how by people of Color, uh, so that, that uh, not fair, not equal distribution is happening. So we, I think we do have an obligation if we're trying to create the best futures for the most people, which is what I would say is one of the underpinning ideas or underlying ideas of tech humanist that we have to be thinking about how to create a more equitable distribution of opportunity and how to make sure that the, the impact of automation is not going to destroy one set of humans potential.

Speaker 1:          00:54:02       And while the increases the potential for enrichment of another so that that inequity is going to become even more extreme than we've already experienced. So I think it's, it's an, it's in our best interest as humans to think about how to sort of shift that and how to, how to level that out. Not that people can't become wealthy, but that we don't end create this even more extreme distribution then we already have. So I think to some extent it's, it's a imperative for anyone who's creating experiences, which is pretty much everyone that works in technology that works around, um, most fields that I've worked around, healthcare, entertainment and so on. To think about that, the, to change that's coming and how to make sure that it is, uh, that we are creating as much opportunity there as possible. But yes, I think there's also, there's also this kind of new emerging space around opportunities to retrain people and repurpose, you know, get people to understand the new skills that they, that they might have a, they, I saw, I shared some really great stats in tech humanist about, um, programs that were taking, let's say, prisoners who were, uh, who would come out of, of sort of prison programs and been able to retrain them into, uh, into communities, the jobs that they could keep.

Speaker 1:          00:55:20       And there was a 0.1% recidivism within this program. Uh, so I, I urge you to look into that example. There's, there's just so many ways that I think an ecosystem of answers is really what's going on here. We have to own the responsibility as content creators and experience creators. And we also have to recognize that, you know, this is going to be a broadly distributed, broadly felt thing, uh, that is going to have inequitable inequitability inequity to ways.

Speaker 6:          00:55:48       So to bring back a word that Paul put in his question, decentralization, how does maybe decentralization help with this by spreading power around or control around? Maybe just talk about the centralization for a bit?

Speaker 1:          00:56:02       Well, I think the idea of spreading power runs kind of spreading control around is interesting. I'm certainly, we have seen, um, you know, through user generated content, user, uh, communities and platforms like meetup for example. We were talking about earlier as one way that they're sort of tools that we can in the hands of people that allow people to kind of create communities amongst themselves, create more human connection. A, those are going to be I think increasingly important. And the technologies are there to, to sort of foster that and allowed discovery within those communities, allow people to sort of find, you know, find each other and, and um, connect more deeply. But I think, you know, we just have to be thinking mindfully about the, the challenge of not, um, you know, uh, amplifying those sort of net negatives as your question was alluding to earlier with the, the filter bubble and sign. Uh, so I, I'd love to hear more specifically, what about decentralization might be the, what's sort of nagging my med, the person's mind that's ans asking the question or on your mind there. Uh, so whoever's asking that, feel free to ask a secondary goal and if there's any other,

Speaker 7:          00:57:17       or maybe for the sake of time we look for one more question in the room before we wrap up. Anything else? Yes. So I have a kind of a thought about some of this stuff, um, in terms of, you know, do you ever take your, your work and look at it as a lens of looking at humanity through the lens of what technology is revealing about people?

Speaker 1:          00:57:42       Yeah, I have looked at that, but I'm very curious as to what is occurring to you as you think about that.

Speaker 7:          00:57:48       Well, I mean, I used to do a lot of community management and so I came out of, um, you know, be on the bbs is back in the late eighties, early nineties. And so it's this kind of thing where I realized that a lot of what happened online was just what happened offline. But at a different scale and at different localities. Yeah. And that was sort of a an Aha moment for me when I was a part of these little communities back in the bbs days. So it's, it's just kind of like as as technology has become more and more prevalent in our lives, it's something that I kind of look at almost flip, flip the conversation a little bit in my own head of like, oh, what does it mean? What does it say about people given how we're using?

Speaker 1:          00:58:37       Yeah, that's what I mean it does kind of a little bit of that points back to the decentralization discussion as well. But I liked the aspect that you brought up. Um, one of the aspects of this that I have looked at is that it turns, it seems to me that our digital selves, that sort of aggregate set of characteristics that gets collected through our movements, through our connections, through our interactions in social spheres, that digital self is really our aspirational self. Most mostly that we are saying who we most want to be. And it seems ironic to me that that digital self is the self, the version of ourselves that is most commodified by business and most capitalized upon and manipulated by by business. I think in our physical manifestations we are a much less prone to that kind of manipulation and over capitalization. Yet this digital south, which is our aspirational self is prone to that.

Speaker 1:          00:59:36       So I think this is the opportunity for us to kind of merge that understanding and say, well, it, it is a human that we're looking at in that digital, you know, sort of, uh, collected aggregate data points. And so we need to be respectful about that too. So I think that's flipped version is to say and others this way that we're interacting with each other in a way that represents who we most want to be and who we most feel we are. So it's all the more reason why we need to be respectful with the data that we collect and monetize and use within business to inform our intelligent decisions in our systems. So I'd say that that's exciting to me.

Speaker 6:          01:00:13       Thank you Kate. And thanks Google for being great audience for cake. Um, and I guess we owe us all a round of applause. So thanks Kate. Especially.