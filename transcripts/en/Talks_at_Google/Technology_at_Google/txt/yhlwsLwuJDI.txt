Speaker 1:          00:06          Hello,

Speaker 2:          00:10          that's a good start.

Speaker 1:          00:13          So we're Zach and Kelly Wiener Smith and we wrote a book called Soonish 10 emerging technologies that'll improve and our ruin everything. Uh, I'm a parasitologist. I study parasites that manipulate the behavior of their hosts a, and I work for Rice University

Speaker 2:          00:28          and I draw, I draw comics and stuff. Yeah.

Speaker 1:          00:33          Uh, so we decided to write a book on technology. And in 2011, a group of policy students at Hamilton College wrote a book called, uh, what did they bring? A paper, sorry, called our talking head's blowing hot air. And essentially they were looking at the predictive abilities of 26 really popular pundants that were on lots of TV shows. And these pundits ranged from being mostly right to mostly wrong, but importantly, they all still had their jobs. And so we were like, we should write a book about tech where like, it doesn't matter if we're right or wrong because apparently that doesn't impact your ability to have a job. But actually we're, we're not really interested in this book and making predictions because we think that what's interesting isn't necessarily figuring out how many years out of technology is so much as talking about what the amazing challenges that people are working on right now are.

Speaker 1:          01:22          And so we talked a lot more about the technical hurdles that still need to be overcome. And then we talk a little bit about how these technologies could make everything awesome but also maybe horrible. And so we give you a little bit of a taste of one of the chapters in the book and a little bit, uh, on one of the note to Ben A's. What did you want to say? Yeah. Oh, okay. Uh, so the 10 topics we cover in the book, let's see if I can remember them all. Are a cheap access to space, asteroid mining, fusion, brain, computer interfaces, bioprinting, augmented reality, um, robotic construction, programmable matter, BCI, brain computer interfaces. I thought I said that already. And then bioprinting. Bioprinting, didn't I say bioprinting? Yeah, I said both of those already. So we're still at eight now, Huh? That's fine. Wait by the book, you'll see, you'll find out the rest.

Speaker 1:          02:11          That's our page. Um, and at the end of a lot of the chapters, we like, we uncovered all sorts of crazy stuff while we were doing the research for this book. And that's like a ton of a big part of why this book was so much fun to write. And so at the end of some of the chapters, we talk about these weird things that we encountered and we include these in our [inaudible]. And so we're going to discuss, one of the Nota Bene is that we wrote in the book as well. It's not this one, but this is that. This was really awesome. And then we got to talk to this, but we've got to talk to so many amazing people while doing this book. Uh, but anyway, so we, uh, we've been told that talking instead of talking about cheap access to space, programmable matter would probably go over best with this audience. So we're doing the programmable matter chapter. Uh, so how about you start? Oh, I'll start. Okay, sure. Um, so

Speaker 2:          02:57          I feel like I needed to not talk as, because it's Google, so I don't need to explain like what are, what are computers I guess? Right. You all know about those. Um, yeah. So the idea in general with programming will matter a is that you in the same way that a computer is universal, you can make stuff that's universal. Um, and there are a lot of different approaches to how you might do that. I think we go through a couple of them here, the books who lot more extensive, but when we say programmable matter, we're kind of condensing together a bunch of different fields, like self reconfiguring matter. There's a, there's a book called Morpho genetic engineering and I wish that gone with that. That was really cool. Um, I'm gonna just stop. That can reconfigure itself in different ways. So we're going to go through a few ways.

Speaker 2:          03:35          Um, it's a little wordy. Um, so this is, um, my drawing of Skylar Tibbets, Skylar Tibbets guy at Mit. He does what he calls 40 printing. Uh, which just means it's, it's three d printing, but the stuff does more once it's printed. So, um, there are a bunch of examples of this, but when we thought it was cute was, um, was he made the straw and it's just made so that the joints are printed so that when they intake water, they bend in a way that you quote unquote program into the materials. So he made one where you program we're programming. So you dropped the stick and water in spells at MIT cause he's at Mit. But what's cute about that we thought is you could, you could like really creep people out. It, they didn't know what it was like you can make programmable spaghetti and it just says like find help or something.

Speaker 2:          04:18          I don't know. Um, but yeah, so that's sort of like, uh, oh, this one of the ones that's theoretically more functional. I don't, I don't think the, the, the wood thing was his right. That was, um, right. Yeah. So it's just one project where it's essentially would, that was designed to respond to humidity. And so it was like you can give a building basically poured so that they can open out a close up depending on ambient conditions. Um, so there a couple of projects working on that. And then in addition to just kind of looking awesome, uh, you have the potential for zero or low energy environmental regulation mechanism. Uh, but mostly it looks really cool. It looks like you're looking at it like a giant dead alien. Uh, so that's neat.

Speaker 1:          04:55          Well, so one of the things, uh, that, that Skylar Tibbets pointed out was that the hard thing about this technology right now is that there isn't really good software written that programs in information about joints and how they respond to environmental conditions. And I know you guys have like 20% of time that you get to spend on anything else. So Fyi, you want to? Sure. So then the next category that we talked about our origami robots and we got really excited about Origami and robots. And so we had this guy, Jason Koon, a design an origami. Uh, what does that robot, robot robot. But, but anyway, so, so if you're interested in our origami robot, you can download the design, uh, here and you can see our origami robot. So Origami and you know, I'm sure you're all familiar with Origami. You have a sheet of paper and you follow like some rules for how you fold it and you make it be this different shape.

Speaker 1:          05:44          Well, if you also put actuators in there, you can get the paper to fold itself so that you don't have to do it on your own, right? Because why spend the time doing that? It's really frustrating. I know some people think it's beautiful. That's probably not me. Uh, and so anyway, you can put these actuators in there and you can get them be with these actuators. You can get the robots to like walk around and pick stuff up and do all sorts of crazy stuff. What were you going to say? Oh, okay. So, uh, one of the cool things that they're working on getting these robots to do is, is have medical applications. So doctor Daniella roots at MIT made this Origami robot out of sausage casing and you essentially folded up, you stick it in ice, the person swallows the ice, and then the Origami bought when the ice dissolves pops out, and then you can control it with a magnet. And apparently this number blew my mind. Apparently 3,500 people every year swallow those batteries that you find in watches and having a three and a half year old and a one year old, I'm guessing that they're all people under five

Speaker 2:          06:47          children, but that was mostly children. People would certain tastes.

Speaker 1:          06:51          Sure. Okay. Uh, and so what this robot does is like, so some, some percent of those 3,500 people end up with the battery lodged and part of their stomach and they can't get it out. And then you have problems. If it passes, you're fine. But if it gets stuck, you have problems. So this robot goes in, opens up, and then you control it with a magnet. It connects to the battery, it yanks it out to dislodge it, and then it passes with everything else and leaves naturally. Uh, and so we're hoping that, that, that little robot never really developed the ability to consider its life objectively because it, it might be a little depressed, but again, it's sausage casing. So it's going to dissolve away and it's going to go away so you don't have to worry about however it feels about things cause it'll be dead.

Speaker 1:          07:31          And so, so anyway, that's one use. But, uh, Daniella, is it helping? It was hoping that first of all, at some point you won't be able, you won't have to like control it remotely. It'll work on its own. And then she's also working on other things like can you get these bots to deliver medicine to very particular areas? And so she's thinking about the medical applications, but you can also make these things big enough that it could be like a table that if someone's disabled the table, you know, puts itself together and then walks over to you so you don't have to go to it or a chair that can just fold up together and go to where it needs to go. And so you can see that or can imagine lots of cool applications for that.

Speaker 2:          08:08          Yeah. But go ahead. Do we do it? Okay. So the, the sort of, uh, uh, the, the, the, the Super Advanced, uh, paradigm that may never happen is, is called the bucket of stuff paradigm, which is something like this. Uh, perhaps, um, but, but the basic idea is it's kind of like having a t 1000, but like fix his stuff in your house or it, uh, instead of killing you, um, or you know, but if it's truly universal, should be able to turn to anything. It can be a range, it could be a phone. Um, you can even be, you know, if you can command it, uh, uh, and it's, you know, on your side, um, you know, you can, you can just tell it to globe over and do something for you. Um, so there are a lot of problems with this paradigm and the privacy thing is one action they will probably get to in a little bit.

Speaker 2:          08:54          Uh, but, um, we had a couple of people actually working on this. The big problem is the, I think the smallest one was like a cubic centimeter. You have to have these little quote unquote Adams, uh, that, um, can move consent's a little bit, can talk with each other. That's important. Um, and then after that, some of the stuff is like luxury. You, you might want a battery on board each one. Um, so miniaturizing this is a really tough problem. And then get into the math thing a little bit. Uh, that's right now. It's right now. Oh God. Yeah. So that, one of the really interesting things we found out is that one of the difficulties of building a t 1000 to serve you is the math. Uh, because, um, I think the way we say it is if you imagine you have a, a, a marching band that's got to shape from say a star and do a, like the university logo.

Speaker 2:          09:39          And so you only have a hundred people. That's not that hard a problem. Plus each atom of that system as a human brains. That helps. Um, but, but yeah, it's just not that hard problem. But you imagine each time you add another individual, the problem doesn't just get one person hard to write it scales. Uh, and so if it's a thousand net comes a really hard problem. People knowing where to go, what to do if someone falls over. And then if you scale, you know, 10,000 or a million, or I guess the t one doesn't want to have a billion and they're in three dimensions and, and presumably there are all sorts of like physical constraints at each point. Like, you know, along the equivalent of a bone, you have to all be docked with each other a certain way. What happens is calculating what everybody needs to do to like make your hand into a giant knife to kill, uh, that, that one guy in the movie, I shouldn't be talking about the two months, but, uh, so if you want to do that, it's actually a pretty tough math problem, right?

Speaker 2:          10:24          Is that you have to expand just the right amount of atoms. They all have to go to the right place. And crucially, if you really want to kill a human, they have to go fast. Um, so like there's a version of super preliminary version of this called kilobytes, which if you want to visualize it, it's like a little, almost a size of a watch battery canister with three little legs and just kind of moves by juggling. Um, and they're called Keela bots because the original system had 1,024 of them and not a thousand, cause it's nerd town. Um, but uh, yeah, so thousand 24 of these and they, um, being aware of this certain problem, they wanted it to have a relatively simple algorithm that each of them were using. And so they did get a tour. They could shape like a wrench, like not when you could ever use it like a three or a two d shape of a wrench and then change into say a star or something.

Speaker 2:          11:05          The problem was, I think it was like, it took six hours to go from one to the other. They say they're really a sort of simple perimeter crawling algorithm. Uh, and you know, again, we want to kill somebody or do you know, have a phone instantly appear in your hand. Um, and then have a kill somebody, uh, uh, you're going to have a problem unless you solve this math problem. I don't know. It might not even be solvable a or at least not sellable in the sense of getting a way to do it quickly and properly. But yeah, but this audience consultant 80% of your time to the robot. Yeah. Murderer. Yeah.

Speaker 1:          11:38          So there, there were a lot of reasons why a bucket of stuff could be a problem. So an ideal bucket of stuff would be able to become like a camera or receiver and it could transmit information. And if these get really tiny, you could imagine that it'd be very easy to spy on someone. You know, you just put some of these in all hotel rooms and then you can spy on everyone and transmit that information anywhere. And then additionally, if you can get this bucket of stuff to look like anything, you could make it look like your clothes and then you could bring it on a flight and then you could turn it into something more dangerous. And so presumably, you know, the TSA would be trying to keep the bucket of stuff out, but it's hard to know how they would be able to do something like that. Uh, so then you talked about there's, there's privacy concerns and then there's patenting concerns. So if you have a bucket of stuff that can become anything, then why buy anything else? You can just tell your bucket of stuff to become that thing. Uh, so it's hard to know how that problem is going to be solved. Although Three d printing is sort of starting to deal with those problems now. Uh, kind of

Speaker 2:          12:32          no. A little bit. Yeah. Like, like there's this issue of can you three d print a gun? Uh, and that's, that's a tough one cause it's like more importantly, like it's like people can't make gun laws if you can always three d printed gun. Uh, but, and if you have programmable matter, it's like you have a permanent anything device that includes all sorts of band things. Uh, so yeah.

Speaker 1:          12:50          Well then another problem is who is to blame when something goes wrong. Right. And of course this is, you know, this self driving car problem. If your self driving car gets into an accident, who do you blame? And so there are proposals that you could use, you know, so the 40 printing stuff that we was talking about, so maybe you could use that to change the way airplane wings work, depending on the speed that you're going at. Or maybe you could use it to change your tires depending on the conditions. Uh, but what happens if one of those things goes wrong at the wrong moment and you die? Who's to blame for that? You know, is it the person who designed it? And so anyway, these decisions, these sorts of problems need to get worked out. Um, any other negatives that I'm,

Speaker 2:          13:27          I think Skylar Tibbets talked about a certain general negative of offloading our personal autonomy to like machines that just make decisions for us. We've already done that. Okay.

Speaker 1:          13:37          That's not a problem. Yeah, that's true. Yeah, they're the, yeah. Uh, so, no, I'm kidding. But, uh, so anyway, so then there's a number of different benefits if you had this kind of stuff. So one, presumably we could really cut down on waste. So if you had a bucket that could become anything, then you could own a lot less stuff because that bucket could become your ranch and your plunder. So you don't need a big tool kit. You've got this thing that could become anything. Uh, we already talked a little bit about how if you have stuff on your home that changes in response to ambient conditions, you could maybe control internal conditions with very low energy input, uh, which we think is pretty exciting. Uh, then we talked about the programmable matter, like those little origami robots, which could help deliver medicine to very particular locations or dislodge batteries. Uh, anything else?

Speaker 2:          14:20          Uh, any more awesomeness. Yeah, there's, there's tons. I don't know. Mostly I want a toy origami thing. I Dunno. Yeah,

Speaker 1:          14:28          yeah. No, it's origami thing would be pretty awesome. Thanks.

Speaker 2:          14:34          Is this whole like, so one version we don't really talk about in a second and think is the swarm robots a version of how you might do this? And we kind of, it's kind of related to how, um, how a team 1001 work. I keep coming back to that. But like, you know, they're, they're, they're like practical utilities to having like a large swarm of robots that can reconfigure it with each other because if want to say send a bunch of robots into a disaster zone, a swarm might be preferable to just one because if something breaks down it would be okay. Uh, and also by being able to break apart and come back together, they can navigate a little more effectively. So we looked at one group is trying to design, it'd be something like, you'd have 10 robots about this big, and one of the tricks they could do is navigate through, say like, um, like a dip in the ground by latching onto each other.

Speaker 2:          15:14          And so they had this really cute algorithm where one robot realizes that there's a big dip and then it has, I think, I think on that one is a lighting system. So it's signaled, hey, someone doc with me. And then the other robots would get the signal, they back up until they had a train of the appropriate size and then they could go over the gap. Um, and there, there are all sorts of similar things you can program and like they could effectively tight rope walk or at least across a narrow passage by having two side by side going the right way. Um, we asked her, can I talk about the evolving robots thing and I was not Germane to the topic.

Speaker 1:          15:43          Yeah, well we got a guitar and all right, so, so anyhow, maybe at the end someone can ask about that. Uh, so, but, but in general, if you have this swarm that can solve its own problems as it, as it goes, you can send it into hazardous areas like New Jersey and have it solve problems and, and fix, you know, fix things. But to be honest, we were most excited about was like, imagine you go to Ikea and you buy like that table and the table just unfolds itself and you don't have to put it together. That would save like a billion human hours if you didn't have to put together your Ikea stuff. So, um, we're going to talk about the Nota Bene on how it will end for all of humanity. Yeah. So we were, we came across a lot of really awesome stories about human robot interactions that made us not particularly optimistic about humanity's ability to persist in the face of smart robots. Uh, so do you want to talk about Promo but first? Uh, sure, sure. Um, so private, it's just a,

Speaker 2:          16:35          I'm, and I'm, I'm definitely pronouncing it wrong. It's, it's a rush Shabbat. I'm not going to try the Russian robot company. Uh, and this was, this is just a little survey was skewed. There's this robot, uh, and it's designed to be like a robot assistant. You can do things like remember human faces and learn things about its environment and apparently keeps trying to escape.

Speaker 1:          16:53          Uh, I said they had, what was it, two incidents where like got out and like random on the street and it ran out of batteries in the middle of the road. So instead of helping the elderly, like I think it was supposed to be doing it instead died in the middle of the street and stop traffic. Uh, so we, we need our robots to stop trying to escape because they're not very helpful there. Uh, but then our favorite robot was named Gaja. So there was a Harvard undergrad named Serena booth and she wanted to know how much people trust robots. And so she lived in the dorms and there were, there are a number of different reasons why if you live in Harvard dorms, you shouldn't be letting anything or anyone into the dorms. So first of all, apparently, and this totally creeps me out, apparently at Harvard, tourists like to take photos of dorms, so no side of the inside of doors. So they'll like come up to the dorm window. You're shaking your head. Did that happen to you? Where you at? Harvard.

Speaker 2:          17:43          Just a lot of universities. Google too.

Speaker 1:          17:46          What the heck is wrong with people? It's okay. So anyways, so they come up to the window and they put the camera up and they take a photo, right. So like people are trying to intrude on privacy all the time if you're in these dorms. Uh, and then additionally, the Harvard dorms had had bomb threats somewhat recently. So everyone had been written recently and told do not let anyone into the dorms. They didn't specify no robots, but they probably assumed you shouldn't be letting anything in. And then finally, a, there were a bunch of thefts so the students knew you shouldn't be letting anyone to the dorms. So what, what Serena did is she created a robot that she could operate remotely. So she was sitting at a table pretending to do her work, but she was really operating this robot. And it would come up to people first by themselves and say, Hey, can you let me into the dorm?

Speaker 1:          18:29          And I think something like 21% of the time they'd say yes, but usually they'd be like, no, you can't get in the dorms. But if the robot approached groups 71% of the time, they let it in. So notes to any robots out there. Humans are real dumb and groups. And then additionally, if she gave the robot cookies, almost everyone let it it and, and so that it was carrying a box from like a fancy local cookie chain, but it actually only had grocery store crummy snickerdoodle cookies in there. And so apparently, yeah, for the price of like dollar snickerdoodles people will put their entire dorm at risks to let the cookies in a and do you want to talk about the emergency robots or do you want me to, okay. So, uh, finally there was a phd student named Paul Robinette and he was at Georgia Institute of Technology and he wanted to know how much people would trust robots in an emergency situation.

Speaker 1:          19:21          So first he started off with sort of like low stakes. There were some undergrads who thought they were doing a survey. So they came in and the robot brought them to the survey room and they did the survey and then the experimenters released smoke and set off the fire alarms. And a lot of the undergrads, instead of going out the door that they just came in. So like they knew how to get out of the building, followed the robot, which like it. At first we were like, well that's weird. And then we watched the video and it was really weird because that is a slow moving robot. It was just like crawling along and so okay. But it gets, but it gets worse. Okay. So then they had a situation where the robot went to the wrong room and circled the wrong room and then went to the survey room again, moving real slow.

Speaker 1:          20:04          And then they did the thing again. And still most of the undergrads followed that robot instead of going out the door that they knew. And then finally there was a last treatment with I think only six students. So it's a small sample size. But the robot went into a corner and started going like this. Like this is where the surveys, uh, and an experimenter came out and said, I'm sorry, this robot is broken. They use the words, this robot is broken. And then they went to a different room to do the survey and they set off the smoke alarm and some students followed it. And then I think, I think Paul was like, I'm just going to see how far I can push this. And so in one situation he had the robot go to a room that was blocked by a couch. All the lights were shut off and there was no exit sign.

Speaker 1:          20:46          And the robot started pointing at the dark room. And there were students who had to be retrieved eventually by the experimenters because they would not leave the robot. And so there's a so and so anyway, this blows my mind. So this robot looks really like, not, not human. Like it was a very dumb looking slow robot. Paul did a great job, but it looks like a trash can on wheels. So the point is you don't need a t 1000 to trick humanity to their doom. It just needs to be a trash can on wheels that's carrying cookies and humanities in a lot of trouble. And so if the robots ever rise up, we're, we're, we're done for perhaps. Uh, but so anyway, that's just like a taste of one of the chapters in the book. And one of the Nota Bene is that we did, uh, we did 10 chapters, eight of which we've told you about. Uh, maybe we'll remember more if you ask us a question about it. We only spent two years on this asteroid mining.

Speaker 3:          21:37          Yeah.

Speaker 1:          21:38          I said, bitch, yeah. Synthetic biology and precision medicine 10. Anyway. Right. Shouldn't have been so excited about that. So, uh, so anyway, that is the book. Uh, and we, we hope you enjoy it, those of you who decide to read it and we would be happy to answer questions now so that if you want to line up at the microphone, uh, we would love to hear what you would like to ask us about.

Speaker 3:          22:01          Oh,

Speaker 1:          22:01          or we can tell you about cheap access to space for humans. Okay.

Speaker 3:          22:10          Hello?

Speaker 4:          22:11          Hi. Is it on, out of the, uh, the comment. Oh, thank you. You're a patient.

Speaker 2:          22:20          Yeah. What he's dressed right now, which I make him feel in public.

Speaker 4:          22:29          So I, I pre ordered the book and I didn't finally received them yesterday and it accidentally received two book plates. So if you want went back to give it to purchase, um, actually it was a curious, Ellen got through the first chapter and it was a little disappointed to see that the, um, the space elevators were already in the first chapter because I was looking for, with that the climax of the book. But do you talk about in the, Oh, could you talk about is how some of these things interact. So like the, the bucket of Goo with the bucket of stuff could also be used in the space exploration. You wouldn't have to bring every possible tool.

Speaker 2:          23:03          That's actually, I don't remember we talked about that, but there was one of the things brought up, like actually the space comes up surprisingly often in the book and we were trying to figure out why. And I think our general realization was that space is also part of the universe and well, yeah. So it's like you're, you're still gonna need most of the same stuff once you're in space. Um, but yeah, you'll need it much more efficiently. Um, so I think we, we talk a little about it. There's a little section in the book on Three d printed food, which they care about for space, kind of for the same reason. It's like a fishing food packing mechanism. Um, can we talk a little bit about recouping, where they're trying to figure out how to, it's our to use pcs and turn it back into food and three d print food. The best part to be efficient. The, the, the project about three phase project, uh, about using human waste, uh, to feet. Humans contains the phrase closing the loop.

Speaker 3:          23:52          Uh,

Speaker 2:          23:54          Jeff, he's like give it gives you an insight into food scientist. They're like, we need to solve this. It's gone on too long. Um, yeah. So did I answer your question? I don't know where it went in a weird tangent. Yeah. This is a question just for Zach. Are you intentionally low key cause plain shaggy. Oh my gosh.

Speaker 3:          24:16          Oh my God.

Speaker 2:          24:28          Uh, I'm embarrassed.

Speaker 2:          24:32          Shouldn't have another question. Like, I thought she was going to say, I like your shirt by the way. So what was the thing you wanted to talk about with the robots? The robots city? So, okay, so this is this, um, Chimera, we talked about it like Heather's a one centimeter version of the bucket of stuff paradigm. There's a just slightly more currently PauseAble version called room butts, um, which is totally worth looking up. I use the search engine called Alta Vista and uh, um, uh, we're talking about the one guy at all to be stood next. That's our next step.

Speaker 3:          25:13          Uh,

Speaker 2:          25:15          um, no, but it just needs these robots and you can kind of visualize like a thing about this big, that's really two hemispheres. They're, they're not like, it's not literally spiritual. It's kind of like between us as fear in a cube. But they can, why they do that as an individual, one can kind of roll along and all they do that can detect things that can transmit and receive signals and they can dock. And so, um, so, uh, the, the idea with it is, is you basically have these little things that can roll around and stick to each other and they can turn into light. It's called room bots because the idea is to make furniture. So for example, you could have like 20 of these, they make the legs of a table and then one literally would go grip a tabletop maybe and then just sort of carry it up cause they can climb walls and have the appropriate gripper type A and form a table.

Speaker 2:          25:56          And then best of all the table could walk over to you, probably would roll over to you, but if you could get it to walk, that'd be really cool. Um, it's a nice idea with this, uh, is you'd be good for like elder care, uh, uh, for people who, who, who can't do for themselves as well as others. Uh, but there's this really cool project and I don't think I have, no, this has been done in a, in, in real life has been done in simulations. But you know, the way genetic algorithms work, right? As you, you, you would say to say a pilot of robots configure somehow and go as fast as you can across the room. And then you could, uh, once having done that you can, you can mutate it. And so people tried this. Uh, and so it's like, what's really cool is you can create a system that's in real life made of these individual robots and you can tell them, hey, mutate based on your last, a couple couple of versions that worked and maybe you, you arrive at new design configurations that you hadn't thought of is just kind of neat cause it's like, it's like genetic algorithms but they're actually having to interface with reality instead of a simulation, which is, I don't know.

Speaker 2:          26:49          To me that's really cool. I know we have to talk about the swarm worth video. Swarthmore.

Speaker 1:          26:53          So, so there was another group that was doing genetic algorithms to try to get, uh, they're like similar blocks to solve problems. And we did not think that this was necessary at all. But someone directed us to a video where before they would try a new configuration, they would come together and then they would like rub against each other for a while as though they were meeting. And we were. And if this went on for like 25 seconds, that's right. It sounded like from like administration person had said make them mate and they're just taking it too literally. Right. And then they essentially just send directions to a three d printers. So it was not at all necessary, but it was not a necessary component of the process, but it still did anyway. We took great joy in watching that video. Yes. Anyway, well I'll never forget.

Speaker 2:          27:41          Thank you both for coming. Huge fan of the comic strip a fairly often. Uh, there's a, an extra, I guess bonus comic panel that appears when you hover over the vote, the button, I assume this has some historical import. I'm very much so, uh, and uh, actually fairly often in that popup panel, it, it shows Kelly disapproving, often holding one of your children who's also disapproving, uh, of the content of the comic strip. So I wonder if you could speak a little bit about the collaborative aspects, you know, does she, do you every comic? Would there be even more offensive jokes if a, if she wasn't there at backstopping? You guys are. Good question. Well, you know, now and then, so I always said Kelly, my jokes and she makes notes on them and noun now. Then there's one I think is really good and that you like, Hey, uh, and so I always do those. Uh, because uh, because if it, if it does well, it's just like such a, like when and

Speaker 1:          28:31          the marriage, the single use monocles was the, the number one example of that. I was like, that project's never going to work. Then I know what it is. And he sold tons of them. Go ahead. We sold them in 25 pegs of, if you don't know if you've got a single use

Speaker 2:          28:47          monocles.com it's a real thing you can actually buy it to, it's like a rapper. Uh, with one monocle.

Speaker 1:          28:53          I still don't get it. I don't get it. But I'm glad about the money. It brought it up so that this is the nice thing when that when it's a project like this, so I might lose, but we make money and that's fine. So I kind of, I'd rather win actually. There's no way. There's no price that I, that's as important as winning, but it's all right. The money brings me some solace. But what's interesting is that a, I have met people who have expected me to be super grumpy and not a happy person. And that is not me at all. I'm actually very, I'm actually actually very upbeat and anyway, people expect me to be kind of grumpy and I don't think I'm back grumpy, but maybe I am here. Thank you.

Speaker 2:          29:37          Thanks. [inaudible] you're getting both for coming. Um, just out of curiosity,

Speaker 5:          29:42          you know, I wonder what the process was starting with a fan base that was formed from single use monocles there once was a man from and Maria touch them on the penis style jokes and transitioning them in, which I've loved and got me into your comic many, many years ago and transition them into much more science and theory and intelligence. Did you find any friction there or what was the thought process going from that style of humor to this?

Speaker 2:          30:04          Yeah, yeah. So I, yeah, so I'm, part of it was just, um, well part was probably just maturing a bit, but also just, uh, Ooh, I know, I know. Uh, but, uh, I think I mistakenly thought on the Internet if you got nerdy people didn't like it too much. Like I tried to keep it a little like don't want to send people to Wikipedia and it just turns that's totally wrong. Um, uh, it seems like the Dorky or the comment got the more sizable the audience became. So I kinda just kept going in that direction and I don't know, I started just as I got to do it full time. I just had more time to read and get well up on things and that's been helpful. So yeah, I'm, but what's nice is I've had a lot of people will say like, you know, I started reading your comic in high school and it's sort of grown with me. Uh, so that's been very gratifying. Yeah. Thank you.

Speaker 1:          30:49          With everything that's about to ruin everything. How do we prepare the next generation to survive?

Speaker 6:          30:54          Hmm.

Speaker 2:          30:56          We prepare them to survive. I think they're just doomed. Then you just let him go. I did. You just teach them that privacy doesn't matter because that's something they're going to have to deal with. Uh, we're not at Facebook. You shouldn't, Whoa, whoa. I don't have a good answer for that. What do you yeah, I get it would be kind of topic pending. So you know, there are 10 different topics and kind of each presents issues. So she mentions privacy, which um, we talked about a bit more extensively in a chapter on brain computer interfaces, which are kind of like the final end of privacy. Right? Cause now we can extract, you know, brain states from a computer, but

Speaker 1:          31:32          you got to go into more detail. Do you want me to go into more detail? Sure. Yeah. Okay. So, so the apparent, so we bring computer interfaces are a little machines that talk to your brain. If they have, you know, they read your brain waves and they figure out what it is you're thinking and what you want to do. And right now they're being used to like make prosthetics that will like reach out and grab the thing you're thinking about reaching out and grabbing. And we thought that the end goal was to like make it so that someone who was a quadriplegic could have all their abilities back. And you know, just by thinking about it they could do, they could do anything. And so that's the answer I expected when I asked Gerwin Schalk what is the end goal of brain computer interfaces? And his answer was one day all of our brain, all of our thoughts, we'll be able to get uploaded to one cloud and will become one big super organism that shares all of our thoughts.

Speaker 1:          32:14          And I was like, that is horrible. I don't, our marriage works cause that doesn't happen. And so like, and I think that's why society works in general. And so he, he, he admitted that there could be negatives to that. He's like, you know, so if you're sitting on the couch and you think I want to leave my wife, she would know that and that and he said, and that wouldn't be so great. And I was like, that would absolutely not be so great. And so, so anyway, this is like the ultimate of privacy if that ever happens. And I mean it is fascinating to think about like humans are a totally different thing if all of our brains are connected like that. Like it's anyway, it's, it's crazy. But we personally kind of hope that future never comes to pass. And then I asked other people in the brain computer interface world, is this actually was, is this just Gurwin or does everybody know that this is the end goal? But like in interviews you just talk about like being able to move your arm if you couldn't before. And they're like, well yeah, you know when the interviews, we talk about the arm thing, but like at the conference we all know that we're going to brain to the cloud and I was like, we need to stop funding this field. I'm very sorry for the amputees, but like, no, anyway, it's going to get quoted somewhere. Oh, I hope that would be very bad. And it was good. It's funny, I was just talking

Speaker 2:          33:27          Google Seattle and somebody brought up, what if there's like, instead of one, there's like three and now there's like the three roommate problem, you know, there's like three super brains when like two or more down with each other, then the other super brain.

Speaker 1:          33:38          Oh, got it. Well, so anyway, uh, uh, so privacy, they really need to not care about privacy. If the future is going to work then yeah. Yeah. Because we're all going to be one big super. Hi.

Speaker 2:          33:54          Hi. Uh, I've been reading SMBC since I had to load it up on a dial up modem. Oh my God. And that was a big deal because black and white comics loaded a lot faster. That's right. And uh, I just was curious what your favorite comic was. My favorite of mine. I don't know. I kind of go through phases, uh, probably one of the long story ones or something, but I don't, I didn't really have a favorite. I like XKCD.

Speaker 1:          34:20          Yeah. Can I

Speaker 2:          34:23          not grumpy? I can I, can I ask about the a giraffe hooker, the drive her go, uh, for those who don't know, there's a, that's a good start that this is in reference to, I think there's an x case city where he made a joke about, I don't actually remember what the context was, but the clear implication was that I needed to draw a sexy, derive a, as a bonus panel.

Speaker 1:          34:45          You're not aware of this. I forgot. Yeah.

Speaker 2:          34:47          Um, so if you want to see a sexy, you're F I'm one of your options.

Speaker 1:          34:54          It's funny. And so in Grad School, a lot of them, so I, so I, it was a frenzy at race for a while and a lot of the people I encounter, I'd be like, oh, my husband's a cartoonist. And everyone was like, is it the XKCD guy? No, no, no, no, no. The Phd Comics Scout. No, not that either. The SMBs? Oh, no, no, no, no, no. Plenty of times. Yes. Thanks for your question. Yeah, thank you. Thank you. I find it inspirational that you're, you're able to have a relationship where the two view can be so collaborative and creative. Um, I was wondering if you had any tips when I tried it, they collaborate always, uh,

Speaker 2:          35:38          like tips to avoid ending up on each other's nerves or avoid having one person taking ownership of the project. Uh, uh, well, uh, so the, the background is that when we started dating, our favorite thing to do was spend all day in the library and then go on walks and talk about what we had learned. And so our relationship hall, so our relationship started as like, we'd like to go on walks and talk about stuff. And so this project, essentially the topic that we talked about on our walk, yeah, it was always soonish. And so we were just, anyway, it was kind of Nice to know. We were talking about different papers. We had red on the same topic and anyway, so that worked well. But additionally, we got kind of lucky because our personalities are such that we wanted to tackle different parts. So I did all of the interviews.

Speaker 2:          36:20          Uh, he did a lot of the background reading, although some of the chapters that was me doing the background reading. Um, he, he's the funny one. And so he did a, the jokes in the comics. Yeah. Uh, and then I am the detail oriented one. So I went through every single sentence in this book and made sure we had a citation for every single sentence. This was when we, we didn't actually think that we were going to write a bibliography, which was real dumb of us to not expect that was gonna happen. And then Jenny, who's here with like, oh, hey guys, your bibliography. I was like, so, so I went through every sentence and made her a bibliography, but, and that was something that would have killed Zack. Yes, he would. He would have cried. And so, so I guess to be honest, we good.

Speaker 2:          36:59          We got lucky that we're interested in diff, different parts of it. Uh, and that we rarely just like talking about nerdy stuff for a long time and sending chapters back and forth, it's really important to not get your feelings hurt. Uh, and I mean I feel like in any collaboration that's really important, but it's particularly important when it's your spouse who was like, no, no, we have to trash the synthetic biology chapter. You wrote his junk, we got to start over again. And so you really need to like have a thick skin. Um, which we both do. Neither one of us cares what the other one thinks. So it's really important. It's really important. Um, do you have another answer for his one? Just a little to add to that? Yeah. Like I, I do a decent amount of collaborating and sometimes it goes well and sometimes it doesn't.

Speaker 2:          37:37          And the two things that are really important is um, one you have separate magisterial as much as possible. You have separate roles and in your domain you have like more veto power or if not absolute veto power. And the other thing, and this is hard to know in advance, like if the person you're working with communicates well, that makes a big difference because people don't communicate well end up sort of storing up their anger and then releasing it on you at some point. And I've, you know, so, so if you have like a relatively mature person, uh, who talks about when they're having a problem, it doesn't just try to tough it out. That can, that can be really helpful.

Speaker 7:          38:08          Yeah. Thank you. Yeah, sure. Thanks. One of the previous questions reminded me that one, my favorite SMBC comic is the one about how it takes seven years to master a new skill and that leads to many lifetimes and you can be an artist and a writer and a [inaudible]. So can you talk about the left times you've had in where that idea yeah.

Speaker 2:          38:27          From It, the [inaudible] perhaps some of you have read. There's a somewhat famous speech by hamming from I think 1986 that that sort of talks about, it's actually written for four programmers about like how you're going to have your career. Um, and so he talked about it, it kind of a related concept where he talked about how he likes switching fields a lot. And I think, I mean, he was, he was pretty nerdy guy, so I think he was talking about switching from software to hardware. He wasn't talking about like becoming a poet. Um, but, but I found that idea really interesting and I, you know, to, to keep you from going stale. Um, so this, this project is kind of one of those. Um, and another one we started doing five years ago is called [inaudible] fest, the festival of bed ad hoc hypotheses, which gives you a pretty good sense of how nerdy hit is.

Speaker 2:          39:09          Um, which, uh, we, we had was and remains a pretty big challenge. It's a live event, um, which is sort of an Improv game, I guess I'd say. It's like fake science talks that you have to defend against, like actual scientists. Um, right. Um, and, uh, um, so yeah, I kinda, I, I, you know, it's funny, every time we do a project like this, at some point I had the same thought, which is why didn't I just keep writing comics? Uh, um, but yeah, so I tried to, I'm on the regular do something that like makes me really uncomfortable. Like I don't, you know, uh, I don't quite have the luxury to completely switch careers at any moment because, you know, we have babies and babies like to eat. Um, and uh, but, but yeah, I try to regularly doing new experiment. So at another one I'm doing probably in 2019 I have a, this is already been announced, so I can, it's not a private info.

Speaker 2:          39:56          You, I'm doing a project. We've got named Brian Kaplan who's an economist about, um, sort of, I don't want to give away too much I guess, but it's sort of like a nonfiction, pro-immigration graphic novel, trying to explain some statistics and stuff. Um, so that, this has been a totally different challenge because I'm just the illustrator on it. I, uh, I can chat a little with them about stuff, but mostly I'm just illustrating his words. Um, so that's been a completely different challenge for me. Um, so yeah, I guess you went and I tried to say is you should do something that makes you feel stupid at least like once every two years. Um, yeah. Yeah, it's very important. It's very important. Yeah.

Speaker 8:          40:29          I feel like maybe you kind of just answered my question, but I guess when I was going to say is, you know, you're both really great communicators on complex issues and complex topics. Now. I was wondering if like you thought you might move more in a direction of like public advocacy or public information, which kind of sounds like you're already

Speaker 2:          40:45          a little bit. Um, yeah, yeah. I'm also working on another comic project I shouldn't say too much about, but about sort of explaining, um, like political norms, which suddenly people are very interested in like, uh, what are the things used to be like? Um, but like, um, a little bit more. Although I, I really do enjoy fiction and, and like storytelling, sorry, I don't want to get too far away from that. Uh, but, but yeah, I do. It's part of the nice thing about having a job explaining stuff cause you get to learn stuff all day long, which is a pretty good deal. But most of the time sometimes it gets a little, a little thick. But, uh, most of the time it's pretty awesome. So for us it's kind of a lifestyle choice. I guess.

Speaker 1:          41:19          One thing that was also nice about working as a team is that one of us would start doing the background research, would write a draft and then we'd send it to the other one. And so sometimes when you get too thick into something, it's easy to write it and forget what you didn't know when you started. But, so if the other comes at it fresh, they can tell you where you haven't explained something clearly. And so we tried to work the chapters like that. And so that's one way we tried to make everything clear, which hopefully we did well. Yeah.

Speaker 1:          41:46          Hi Kelly. I'm curious about what some of the other ideas sacs, how'd that you thought were the worst ones? Uh, that made it in the book that I thought were particularly bad are the ones that detergent a well. So one of the, one of the really interesting things about writing this book was that I went from thinking some technologies were just awesome across the board to thinking they were awesome but also kind of scary. So asteroid mining for example, uh, first of all, that one, we were totally wrong about what asteroid mining was. We thought the ideal was to like go out, get tungsten, bring it to earth and now have a ton of tungsten that you can sell on earth. But it turns out economically that just doesn't work because you're going to bring a ton of tungsten here. You're going to crash the market. And then that was a waste of billions and billions of dollars.

Speaker 1:          42:27          And so the point now is you go out there, you get the tungsten, you build a space based, and then you go and explore the world or you bring it to the space station. You get water from the asteroids, blah, blah, blah. But anyway, so we became really excited about cheap access to space and asteroid mining. But the scary thing is once you get the ability to wrangle asteroids and you can bring them anywhere, you can also fling them at the earth, which would could be worse than any nuclear bomb we've ever set off. And so like when people get cheap access to space, for example, if the space elevator works, we suddenly, we'll have tons and tons of people in space. Maybe we'll have colonies on Mars and you'll suddenly have people with the ability to be able to move giant objects and fling them at Earth, potentially.

Speaker 1:          43:08          And so it's a great technology, but now you have to trust that human beings aren't horrible. And I don't know if our history totally warrants that. And so it's a little bit scary. It's an awesome technology that now has something that could be really negative. And a lot of these technologies are like that. So our book originally had a advanced nuclear reactors, a fission reactors, and that's another technology where it's like, well, if you can trust everyone, then that's great because we have this greenhouse gas problem that we want to get rid of. We don't, you know, climate change is obviously a bad thing we're all dealing with right now, but can you trust people with it? Hard to say. Does that Kinda answer your question? Yeah. Okay, great. Thanks. Thanks. Anything else? Okay. Thank you very much for your time.

Speaker 3:          43:56          [inaudible].