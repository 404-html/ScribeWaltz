Speaker 1:          00:06          Today, I'd like to welcome Richard Harris to come up and speak with us about his new book rigor Mortis. Um, I've always had a kind of passing curiosity as to, uh, why we're not getting, um, you know, it's the same kind of super advancements in medicine that, um, kind of expected us to have by this century. And, uh, it turns out Richard's written an excellent book to explain some of the reasons why and, uh, I'm excited to welcome here to Google to talk to us today.

Speaker 1:          00:43          I thank you all very much for coming in. Uh, having lunch over a topic that's a little bit uncomfortable maybe for some people, but maybe not. The people in this crowd, a biologist are not always happy to hear this news, although I think a lot of them acknowledged that this is a significant problem and they're in there worrying about. So, uh, let me, uh, uh, spend a few minutes sort of just giving you a sense of, of, of how the book came about and, and some of the highlights of the book. And, um, this, I've been at NPR for coming up 31 years now and I've covered practically everything in science and in medicine and related fields, environment I had over that time. And in 2014 my boss said, hey, we want to switch things around a little bit. Would you mind going back and covering biomedicine for awhile again?

Speaker 1:          01:28          And I said, oh, that's fine, I'm happy to do that. And I realized I was a little bit out of touch with what had been going on since I last paid attention in the, around the 2000 [inaudible] late 1990s. So the first thing I did was I said, well, let's see how, let's, let's take a look at the broader trends in biomedicine. And one thing, the first thing I discovered was a money is a problem. Uh, this, the, the lower graph there shows how much funding has decreased in, in inflation adjusted terms since the year 2003 for NIH funded research. Uh, but this graph actually only tells half the story because if you actually look back before 2003, between 1998 and 2003, the NIH budget had doubled. And so there was a huge cash infusion for the increase of vibratory space in this country, about 50% for this kind of research in academia.

Speaker 1:          02:17          Just enormous growth. And then Congress said, okay, we've taken care of biomedicine, we'll hold the dollars more or less flat. But in terms of, uh, terms of spending power, uh, it was declining rather substantially. So a whole bunch of more mouths to feed and less and less money to do it. So, so I thought that's going to have some sort of negative consequence for sure. The second thing I fairly quickly came across was this paper which was published in nature. Actually in 2012. Uh, Glenn Begley and Lee Ellis, uh, wrote a paper that caught a lot of people by surprise or certainly caught their attention. And what they had done was a lowly Alice, I'm not leaving Ellis Glen Begley a was head of cancer research for Amgen. Big Company out in, in the La area. And uh, they rely very heavily on the output of academic labs to get leads for new drugs.

Speaker 1:          03:07          And over the years, lots of stuff had come across the transom and most of it didn't pan out. And Begley was sort of saying, okay, I'm kind of wrapping up my time here, but I want to go back one more time and look at some of the most promising studies and take one more run at them and see if I can get them to work. And so he selected 53 studies that he thought if these studies were really panned out, these were, these would be very strong leads for new drugs. So he tried to retest them in his own labs. Uh, most often he couldn't get them to work. He even took them back to the original academic labs to say, we couldn't get this to work, can you? And, and very often the, the scientists there couldn't get it to work either. So in the end of these 53 studies, you only got six to work.

Speaker 1:          03:49          It's about 11%. Right? Very, very poor success rate of just replicating a study that had been published in the literature that people hadn't paid a lot of attention to. One of these papers had 2000 citations people saying, look at this great result. And he couldn't replicate it. It was a similar study done the previous year by scientists at bear in, in Germany. And they also came up with a pretty low success rate, about 25% of the studies that they were able to replicate. So this led to this idea of the reproducibility crisis, uh, that was just bubbling up as a result of these papers and similar work. So I realized I've got a book in this and, uh, uh, and I decided to, um, uh, to take some, take a year off of NPR and dig into these issues to really try to understand the consequences of this.

Speaker 1:          04:37          And, uh, one of the first things I was worried about was we'll anyone want to talk to me about this, uh, in the answer, surprisingly, was people were completely happy to talk to me about this. And, uh, for example, this is a, uh, Janet Woodcock who's the number one person at the FDA in charge of drug approvals. And she said, I'm happy to talk to you. This is a big problem. And I sat down with her and we had a long conversation and she said, you know, the stuff we get from pharmaceutical companies is reasonably good. We can rely on a fairly heavily, but if academics come directly to the FDA with studies that it's, the, the quality of those studies is very, very poor. And the quote that she has is, uh, uh, she says it's like nine out of 10 airplanes we designed fell out of the sky, or nine out of 10 bridges we build failed to stand up.

Speaker 1:          05:21          I mean, this is the failure rate she's talking about for the academic studies trying to lead to drug development in a fairly advanced area because they're already at the FDA at that point. [inaudible] you know, she, she sort of laughed and disbelief and said, we need rigorous science. We can rely on another person who was quite surprisingly, uh, engaged in this topic. Oh, should is Francis Collins, who's the director of the National Institutes of health. And to his credit, he recognized this as a problem early on and said, you know, we can't sweep this under the rug. It's clearly, it's an embarrassment to the enterprise that he's funding. But his take was we got to fix this and we can and we will, we'll try to engage on these issues as opposed to saying, oh, nothing to see here, move along. Uh, and he engaged his top deputy, uh, Larry Tabak to be the point person for this issue.

Speaker 1:          06:12          They both, they worked on it together a lot and, and among other things they wrote in, in one of the, one of the journals, uh, uh, Collins explained. Yeah, of course science is self correcting. That's the beauty of the scientific method is that things that you don't get everything right the first time. It shouldn't be expected. But there's a process that eventually things are, you know, mistakes are discovered. You know, blind blind alleys are identified and the process corrects itself. And so he says in the long run, science of self correcting, but, and here's the quote in the shorter term, the checks and balances that once ensured scientific fidelity have been hobbled. Pretty strong words for the, uh, to come out of the mouth of the head of the National Institutes of health. And, uh, but you know, he is engaged on this topic and he's taking it very seriously.

Speaker 1:          06:57          And I think that is that that probably helped me talk to a bunch of other people who were also very concerned about it. And, uh, and, and I think that's a good sign that people are engaged in that way. So what difference does this make? This is a, uh, you'll appreciate this graph. It's called e rooms law of the inverse of Moore's law, uh, because this is the shows that drug development, unlike microchips, uh, costs more and more to develop and you get less and less bang for the buck as time goes by. You can see in the 1950s at the beginning of that graph, uh, it was relatively inexpensive. That's a log scale, uh, to develop, uh, drugs. But you know, by 2010 things where, you know, costing a huge amount of money for, to yield a single drug. And as we know, a lot of those drugs are fairly marginally effective.

Speaker 1:          07:40          So even if they pass muster, a lot of these anticancer drugs are, uh, so modest and what they achieve a, that if you look at the national statistics for cancer mortality, you actually don't, you can't even see the effect of all of these new cancer drugs on, on cancer mortality trends in this country as yet. You know, maybe, maybe we will eventually, but at this point for all the, all the great talk about, uh, how much all this cancer research is panning out. The reality is it's costing a lot of money and it's not yielding a whole lot of results. And that's a serious problem. This is not necessarily driven by reproducibility, but the, but it underlines the fact that we really need to make sure that we are being as effective as we can in, in working on these underlying science projects to make sure that, that actually to inflect this curve so it doesn't get worse and worse and worse.

Speaker 1:          08:33          So how bad is it? Well, what nature nature asked, is there a reproducibility crisis and a f and in a survey last year and a 52% said yes, there is a significant reproducibility crisis and other 38% yet said there's a yes, there's a slight crisis. Not exactly sure what a slight crisis is, but, but we can't say it's only 10% said, I don't know. I don't care. And I don't think that this is a real issue. So, so clearly scientists recognize this is, this is a real, as very significant issue and something that they need to deal with and they're thinking about it. Uh, uh, this, I, this plays out in news coverage as well. This is a paper that was in, uh, uh, one of the plos journals, uh, published just a couple of months ago after, after my book went to press. This is a team of scientists at the University of Bordeaux that asked the question, uh, how, how much can we rely, for example, on, on newspaper reports of, of scientific discoveries.

Speaker 1:          09:34          And these did a survey of a database of almost 200 English language newspapers. And they said, how well do these uh, newspapers cover these results and how accurate does it turn out to be in the long run? And they identified 156 studies that, uh, that had been reported on sometime in the past. And they went back and they said, okay, uh, did these studies can out? And there are things like, you know, linking pesticides to Parkinson's disease or suggesting a mechanism for Adhd or looking at, you know, potential new genes or putative new genes for breast cancer and various other, you know, things that you see. We opened up the paper new gene for breast cancer. Well, it turns out that if that's 156 studies that had actually had enough followup that there was a, a reasonable amount of data till sort of be able to look back.

Speaker 1:          10:24          About half of them were, uh, uh, stood the test of time and the other half turned out to be ephemeral. They, the bubble burst and the idea went away. Uh, and if you look at these sort of those for the first time kinds of studies where people are just looking at the exciting new first time anyone has seen this, only about a third of those who are confirmed in these further studies. So I started thinking, I the bottom of my stories, I should, if I'm doing stories of this nature, I should say, by the way, about half the time to two thirds of the time these studies turn out not to be true. So are you feeling lucky today as a sort of a warning to, to, to readers that these are not necessarily reliable, uh, findings and it's, it's pretty, it's pretty sobering. And journalists also tend not to report the, Oh, by the way, that study who told you about three years ago, it turned out not to be true.

Speaker 1:          11:13          Partly because, uh, those sort of follow on studies tend to be published in journals that are lower ranked. They're not the big flashy journals that send out press releases and draw attention to themselves. So we don't necessarily even see those followup studies or if we do, it is kind of a funny storyline to say, Hey, do you remember s stretch way back in your memory? And remember three years ago we were talking about genes for, for autism. Well, nevermind that wasn't right. So, so these, so you don't hear the, the, the, the studies that they come along and take. Yeah. Nevermind. Nothing to see here. So at any rate, what's going on here? I'm going to go give you a quick survey of the sorts of things that are happening and going to focus in this, talk on for them, bad ingredients, a dubious design of experiments, statistical errors, uh, that, that are the crop up quite commonly.

Speaker 1:          12:00          And then some of the funding pressures, as you might imagine from looking at the initial graph, you could appreciate that, uh, that's creating a bad culture in, in science. And I want to talk first about, uh, uh, bad ingredients in this case cells, a cell lines. This is a book that was actually written in 1986. Uh, about, uh, a woman named Henrietta lacks familiar name, the issues. She was a, she's now a featured in an in new HBO story. Her cervical cancer cells were or isolated and cultured in a, at the Johns Hopkins Hospital in 1951. And they became the first human cell line of, uh, uh, that are used as a tremendous tool for studying cancer, cervical cancer in particular, but used in generally just as perpetual cancer cells. And, uh, this book is about the fact that those cells actually ended up getting a very widely distributed.

Speaker 1:          12:58          And, and, uh, as far as the 19 set back as the 1970s, a scientist started to realize that they were contaminating all sorts of other cell lines that grew like weeds. Nobody could quite tell. They had thought they had isolated other cell lines, but in fact very frequently they were, they were studying, he lost cells. Uh, and there's now a list of 451 contaminated cell lines. And if you go to the list of says, you think you're studying this, if you're using this cell line, guess what? You're studying something else. And sometimes you're not even studying human cells. You may be studying rat cells. But if the of this list of 450 plus cell lines, more than 100 of them are Hilo cells. Actually. So this, this thing has just spread like crazy. And this book is about the frustrating efforts of one particular science scientist named Walter Nelson Reese to go out and tell his colleagues, hey, watch out.

Speaker 1:          13:48          You're not studying what you're thinking. You're studying. Be careful. Take a look at yourselves, make sure you're, you're know what you're doing. And he died in a, it's in frustration because scientists said, yeah, yeah, yeah, whatever. And they continue to use these contaminated cell lines. And there, there are many, many others. One of the favorite stories that I have all along this lines is a cell line that came out of MD Anderson Hospital in 1976. It's called MDA MB four 35. And it was a cell line that the scientists had. I isolated from a woman who had breast cancer, 31 year old woman who uh, uh, and, and they collected the cells and they grew up the cell line. It became one of the most celebrated cell lines. It was the national cancer institute sort of has a list of 60 critical cell lines that are sort of archetypal sell ons, the for cancer of all of all varieties.

Speaker 1:          14:38          And this was on that list of 60, and I'm considered a really important saw line for studying breast cancer. And uh, in the year 2000, uh, some scientists at Stanford said, let's take a close look at the NCI 60 a and s and look at gene expression in these cells, which is seeing, look at each so on and say what genes are turned on and turned off in each of these cell lines and see if we see some patterns. And Lo and behold, they found that the lung cancer cells all had the same sort of set of genes, certain set of genes turned on or there's turned off. Same was true of melanoma cells. They were, you know, there was a, a nice pattern of gene expression in these cells. And when they got to this breast cancer cell, it was like, wait a second, that gene expression pattern does not match the other breast cancer cells.

Speaker 1:          15:24          It actually has the same gene expression pattern as in fact one of the other melanoma cell lines in, in the collection. And they put a notice up on the, on the NCI website saying, Hey, attention folks, uh, this is, this was misidentified cell line. This is, it looks like a melanoma, not a, uh, not a breast cancer at all. And since, since the year 2000 Iu, uh, there's still have been hundreds and hundreds of papers published of this cell on referring to it as a breast cancer cell line. People haven't been paying attention. Uh, they're, they're not finding or paying attention to the warnings that this is a misidentified cell line. So it's a, it's a crazy, it's a crazy circumstance out there. And now there are a effective tests that are inexpensive. You can take your cell lines, mail them off to a lab and have them to have them verified to find out if they are what, what you think they are.

Speaker 1:          16:14          And, uh, it was only last year that the NIH said, if you're getting NIH funding, we expect you to do that. So let's hope this problem is being resolved. But, uh, uh, remains to be seen how many people are following through on that dictum. So that was bad ingredients. This is bad. This illustrates bad experimental design. This data actually comes from, uh, from, uh, the outfit called the als therapy development institute, which is in your neighborhood right around the corner. And what they did was they noticed that many, many drugs for als, Lou Gehrig's disease weren't working in, in people. And the question is why. And so some years ago they went back to look at the original underlying mouse studies that had been done to that, that suggested that these drugs were good. And the blue bars show increased survival in the mouse studies for these original studies. But the folks at als Tdi recognize that a lot of these studies were very poorly designed.

Speaker 1:          17:10          That is very few mice. They, uh, the, the results were, uh, you know, really there's so much noise that they weren't really believing what they were seeing. So they ran all of those experiments with substantial number of mice watching them, making sure they got the sex of the mice right, that the genetics were correct and so on. And the black bar show what they ended up with. And as you can see almost nothing, uh, it worked at all in, in mice, uh, when the mouse tests were done correctly. And this is this, there's, this is a very common problem in, in biomedicine. And one reason is that the, uh, the als TDI studies each cost well over a hundred thousand dollars to run. And if you're a university lab, you don't have that kind of money to run a single experiment. So you run a small experiment. You say, this is a pilot study.

Speaker 1:          17:58          Fingers crossed. It means what it would mean if we actually did it with, you know, 32 mice in a, in a, in a cohort as opposed to five or 10, which is what the universities tend to use. So, so this is a, uh, this is, uh, an issue that is driven both by financial pressures and just by, you know, people hoping for the best when they're doing experiments. But I think it's one of the grave concern about how much, uh, we're really getting out of these, uh, biomedical research labs if they're, you know, trying to do the best they can on the cheap. It doesn't necessarily pan out. And the, and you know, these, these experiments cost many millions of dollars to run once they got to human beings. And essentially none of these drugs work, uh, that the top drug has a very minor effect, but it's nothing to get excited about.

Speaker 1:          18:44          And all the rest of them, you know, tens of millions of dollars have been spent on each of those studies or many of those studies at any rate. And they were all bused. So, uh, so, uh, the folks at als Tdi are now trying to say, let's do the careful experiments first. Let's run these, let's spend the couple of hundred thousand dollars upfront. And if we find good stuff, then we can move forward. But let's, let's, let's be a little bit more cautious with our preclinical research before we take it into human beings. Uh, this guy, I've got lots of stories about Keith Bagherli, his a biostatistician at MD Anderson in Houston, but I'll just tell one story about a ovarian cancer tests that he discovered was a rather inappropriately put on the market. Uh, it had been discovered by, uh, actually the scientists at the NCI and at the FDA. They, instead of looking for sort of your standard molecule that would indicate the presence of ovarian cancer, uh, they said, let's try a different approach because that had, that had failed.

Speaker 1:          19:48          And what they did was they used a mass spectrometer, which sort of looks at the masses of various part of particles. And we'll look at the spectrum of mass of these, uh, of these proteins in the blood from women with ovarian cancer. And women who don't have ovarian cancer and see if we can see some sort of different in that could be a powerful new test. And they announced, hey, we found something that's really works great. Uh, actually, uh, folks in Congress passed a resolution saying this is fabulous work, keep it up in 2002 and a, and Keith Bagley and his colleagues at MD Anderson tried to do it, couldn't get it to work. And finally back, uh, Bagherli said, let me go back and look at the original data. And what he noticed was all of the women with ovarian cancer had their tests run on one particular day and the controls were run on a different day.

Speaker 1:          20:33          And then she was just tuned differently on what from one day to the other. So this was, this is a example of what scientists called the batch of fact. And this is another problem that that keeps cropping up in biomedical research. Uh, and uh, and that's pretty, pretty shocking that, uh, that that test got so far along before people realized, Oh, this is just, you know, completely false lead. Uh, another, uh, statistical problem is called Harking, which is hypothesizing after the results are known, it sounds like fairly innocent thing to do. You Run an experiment, you don't get the results you expect, but you say, oh, but that's an unexpected result. I'm going to say that was my hypothesis. And, uh, you know, that this gene is associated with the cancer that I wasn't expecting it to be. It turns out most of the time those results are wrong.

Speaker 1:          21:18          And, uh, uh, just, just by nature of the kind of statistics that people apply to those, the, the p values and so on, the whole statistical mechanism, it's perfectly good to, to do an experiment like that and to say, uh, I've generated a new hypothesis in the study and now I'm going to go test it in a new one. But it's really inappropriate and unfortunately very common for scientists to say, look at the results I found. This is, this is, here's my new hypothesis and here's data that support it. So it's another reason that, uh, there's actually a famous paper written by a guy named John John Ian eds, who's at Stanford, who, who has a paper titled Why most published research findings are false. And this is, uh, this is fundamentally part of the reason for that. Uh, also, uh, behavior in, in, in science because of this funding pressures.

Speaker 1:          22:08          Uh, scientists are pressured to cut corners. They know that if they don't publish their papers in the, in the, in the top journals, they're unlikely to get more grants or promotions and so on. So there's huge incentives for people to, you know, leave out the data that doesn't quite help them tell their story or to, to, you know, to just to nudge things around here. And this is a study from the national academies. It just came out a couple of weeks ago, uh, looking at these issues more broadly about scientific integrity. And this is a follow up from a study that was done 25 years ago where the focus was on scientists who, uh, sort of the bad apples, if you will, looking at the actually fairly rare cases of outright fraud and misconduct that, uh, that is, uh, responsible for some of these cases, but not all that many.

Speaker 1:          22:57          And they said, we're, we're looking differently at this. Now. When I talked to one of the panelists, a CK can sailors who said we'd been fond of the bad apple narrative, and now we're talking about switching to the barrels and the barrel makers. In other words, trying to understand the system that is setting people up to, to act appropriately, to, you know, to shave, to, to make, to do questionable research practices. These are not outright fraud, but there are things that you know, that are, that are, that are questionable and that are detrimental to the progress of research. So that's a, that's another very significant and hard to measure a problem. But, uh, but there have been a couple of surveys and exploration's of that and uh, it's clearly part of the underwrite an underlying problem here. So solutions validating ingredients. I already mentioned that now there's this easy test for example, to send off your cell lines and get them tested.

Speaker 1:          23:49          Scientists are expected to do that. It's only a year old. I'm really interested to see whether people are following up on that and I hope I've hoped to find out, but I don't know yet. Transparency of making your data and your code available. I think this is an idea that's getting a lot of traction. We'll talk a little more about that. Better training for scientists. Very often scientists just learn from the mentors and they don't necessarily realize that what they're doing is, is detrimental to their, uh, to their, to what they're doing. And uh, and if they had better training, maybe they would know more. And finally finding some way to use this financial crunch because that's the underlying pressure that's driving a lot of, this is my favorite story about transparency. Uh, this is a paper published. The, the, the, the first draft of the human genome published in nature in February, 2001 this was a, you know, a milestone in biological research, uh, in, in science in general.

Speaker 1:          24:43          And, uh, and instead of publishing the entire 3 billion base pair code of DNA and in a, in nature, what they did was to say, well, we're highlighting about a dozen or so sort of exciting and unexpected findings. And one of them was they reported finding dozens of genes that were bacterial genes right in our human genome. And they thought, that's weird. How could that be? It's really interesting how, how could bacterial genes jumped into the human genome? And the answer was they didn't, uh, Steven Salzberg, who was at the Institute for Genome Research, uh, at the time, and some of his colleagues said, I don't believe this is true, but the genome data were all publicly available, a completely transparent and Salzburg and his colleague said, let's do our own analysis. They pulled it the same day to sit down. They looked it over and they had a completely different explanation for those apparently microbial genes in the genome.

Speaker 1:          25:34          And they said, false alarm guys, this isn't, this didn't happen. So, and this is, this was in June of 2001. It was just a few months later. It was really quite a remarkable, uh, uh, uh, feedback loop for, for getting results either verified or, or not verified in this case. And I think this is an incredibly powerful example of how transparency can, can work and can really help resolve these questions much more rapidly. Scientists of course, guard their data jealously. They are concerned that there'll be scooped, that their intellectual property will be whisked away by other scientists. And so those are very real issues. And I don't mean to minimize them, but it is also true that to the extent that you can get people to put their data up, their code up and to, and to share their ingredients when asked than other scientists can, can rapidly come around and say, this is working.

Speaker 1:          26:22          Is this right? Is this right? Is this wrong? And I also think that if you know that any that you have that much transparency in what you've done, maybe just take a little more time to, to fact check it yourself and make sure that if there are problems that you find it before your, before your, uh, your, uh, your colleagues do. So I think that's a really powerful idea. And I think the new culture, the culture of, of, uh, that comes out of your world of open source and so on, I think has really led, uh, I think the younger generation to appreciate this and to be less resistant to sharing. And I, I think that's a positive long term trend in, in biomedicine. But, uh, it will, it will not just sweep through the field overnight, but I think it would be very salutary in terms of education.

Speaker 1:          27:06          This is a wonderful scientist named Arturo Casa Duvall, who's at Johns Hopkins now and, uh, and it's his view that basically the educational system needs to be reformed. And, uh, there are essentially no growth, good methodology classes anywhere in biomedicine. Uh, you sort of learn from your mentor and if your mentor is Great, you learned a great technique and if your mentor is not so good, well maybe you learn good laboratory technique but you don't necessarily learn how to think, how to, how to sort of think through problems and how to, how to deal with some of these broader issues. So constant of all is uh, trying to think about how to retool a science education and he's by far not alone. There are lots of other people thinking about that. Want to just end the talk talking about four people who I think have really interesting ideas.

Speaker 1:          27:50          Uh, these are, uh, the first two are Carolyn Compton and Anna Barker who are, we're both at the national cancer institute and are now at Arizona State University. And Dr. Compton is a pathologist and she noticed that, that that uh, tissues collected either for blood or organ cancer tissue and so on is collected in a very willy nilly manner. And, and everyone does it differently. No one thinks very much about how long it has to sit around, how quickly it gets preserved, when it gets frozen, when it gets or, or, or preserved with, fix it over, whatever. And uh, and she realized that as we're moving into the world of personalized medicine, if you're not doing collecting that material in a very uniform way, you're going to end up with a lot of variation that is going to be misleading. And so she's been working really hard with pathologist to get them to develop and use uniform standards for tissue collection so that when we start diving into this data, we can actually have some faith that there's at least that, that, that very important source of, of, uh, variation is limited by careful collecting of tissue.

Speaker 1:          28:56          Uh, her colleague and a barker is sort of taking the whole idea of reproducibility and, and a very rigorous approach to, she's applying to, uh, studies of Glioblastoma, a very difficult to treat brain cancer. And she sort of starting from the very beginning and going all the way through clinical trials of Glioblastoma to say we're going to do every single step as rigorously as we possibly can. And I said, why did you choose Glioblastoma? It's one of the hardest cancers to cure brain cancer. That that essentially is as a death sentence almost always. And she said, well if I can make it work with Glioblastoma, people will have to sit up and pay attention. So that experiment is, it was just going into the clinical trials right now and it could be very interesting to see whether, I think it's an uphill battle for her, but if she can make work that would be really quite remarkable.

Speaker 1:          29:43          The final two guys I want to talk about our Steve Goodman and John Ian who are at the Meta research innovation center at Stanford metrics. And their idea basically is we need to study how science is being conducted. This is the metal research of research in order to understand why all of these things come up and, and what kind of solutions we can come up with to resolve them. And they were both veterans of actually addressing this very similar set of issues that came up with a human based medicine in the 1990s. Many of the clinical trials that were done back in that era or done, uh, with very poor record, they were, they were not put together with s with as much care and caution as they are today by no means perfect, but w but scientists are now thinking much more carefully about sample sizes, about controls, about making sure that they're avoiding bias as much as possible and, and avoiding things like, uh, like hypothesizing after the results are known, which is a huge problem in biomedical research and one tool that has been put to use and it's quite successful, um, at least in addressing some of these issues as a website called the clinical trials.gov if you're a scientist and you want to develop a new drug and do a clinical trial on human beings, you have to put your data or you have to register in advance on clinical trials.gov you have to say in advance what your hypothesis is.

Speaker 1:          31:06          So if you come up with findings that support some other hypothesis, you have to admit that wasn't my hypothesis and these results are not to be taken literally. But, uh, and you also need to post your results once you've finished your study, uh, to make sure that you're not just sort of hiding results that are disappointing cause the biomedical literature is, uh, is skewed in terms of results that are, that are positive results. People who find things that aren't, that don't work out tend not to spend the time to publish them. They'd may not, it may just be the effort involved in putting it together or whatever. But the, uh, but a lot, but the, as a result, when someone goes to survey the literature and say, well, how many studies show this is true and how many don't they get a very skewed sample.

Speaker 1:          31:48          And, and so, uh, this, a website is designed to, to, to at least encourage scientists to publish their results, uh, to get a more, a more well rounded sample of that. Many scientists unfortunately still are not publishing a posting. The results in here as is required by law. But at least you know that when you go there and say no results found, uh, that you can see, you can at least know that there, there was a study, there were results and uh, and if you really care about doing a Meta analysis or something, uh, you better track him down. Uh, so at least you know that they exist even if you, even if they aren't public. So at any rate, um, I wanted to end on that note because I think that it really is, um, I mean there are things that can be done and there are patterns.

Speaker 1:          32:34          There are examples from the past of taking similar issues in reproducibility and finding ways to, to improve the systems. And it's, you know, the scientists who are doing this don't want to spend their careers, you know, wasting their time and coming up with results that aren't, that aren't pushing science forward. So I think the best news is that scientists would like this problem to be solved. And the problem is with the financial pressures and all the rest of that, the system is still not set up to help them succeed. And so, uh, and those are hard problems to solve. Obviously you, you're, you can't double the amount of money in it, the Nh again, or are, you can't ask half the people who are, uh, who are currently doing this kind of research to leave and find some other kind of line of work. So they're very difficult issues to solve, but that people are thinking about at least how to make some improvements along along the way. And, and there's still a group of people thinking about how we can solve the underlying problem. I think that's the hardest one of all. But I think, uh, I think that the fact that people want to do good work, I think really helps, uh, helps us move forward with this and having the support, at least current of the current leadership of the Nih, I think also really helps provide a path forward, at least for, for some of these. So, yeah, at any rate at this point would be delighted to Dick Questions. Thanks for your attention.

Speaker 2:          33:58          Okay.

Speaker 1:          34:00          So I, I have a quick, uh, kind of something that I thought of as you were giving the talk that, uh,

Speaker 2:          34:08          okay,

Speaker 1:          34:08          much, uh, in, in the Internet pass there was always this a question of like, if you go look for a particular reseller, do you know that they're actually like providing hue? The things are advertising and a, it was an early problem and uh, some clever people put together a site that collected stories about each reseller. So if you found someone, you kind of had to go to sites and says, okay, was there ever any follow up on this? You know, was this happen? Is there something like that going on maybe for, you know, this backlog of research papers, cause I know there's not a lot of retractions that ever reached the light of day, but if you're searching in the past for, you know, some promising research,

Speaker 1:          34:56          it's kind of hard to follow the trail of, you know, how did that ever Pan out? It is difficult. And I, and one example I encountered in my book is there was a study that was linking gene expression, uh, and comparing it between races and uh, and, and it was a paper that the asserted that there was a very large difference in gene expression between Caucasians and Asians and other scientists looked at the data and we're were highly critical of it. And they were able to publish a paper in a completely different literature. I think it was nature methods or something like that, which is not the human genetics literature, but it was, you know, in the scientific literature. And they said, we found these flaws. The scientists sort of responded and said, yeah we did screw up a little bit, we, you know, whatever.

Speaker 1:          35:38          But that whole discussion took place off to the side. If you want to go and find it in the medical literature you can. But there's still like hundreds and hundreds of papers that site the original research and have no idea that this discussion has taken place cause they were just looking in the, in the genetics literature or whatever. So it's a, it's a very big problem of sort of hide and seek if you will. There's actually a tool that has, that has come up that is helping this a little bit, which is a, um, uh, called pub here, which is a basically an open comments site that if you, and you can post comments about anything you read in the literature and, uh, and I have an APP on my browser that lets me, that alerts me. If I go to a page that has, this, has this paper, it'll alert me.

Speaker 1:          36:23          There are six comments about this paper on pub pier. So, so there are tools that are starting to be used to do that, but it's a, or if there's some similar system in a, in, if you go to the NIH, the National Library of medicine's database, they have a pub Med and comments at pub med. And so you can see comments there. The difference being the pub med comments are not anonymous, so people are a little bit more, uh, a little less likely to engage their pub. Here. You can be anonymous so it can also be, you know, be a little spicier as you can imagine for anonymous comments. But yeah, it is a, it is a huge information flow problem that, that scientists are starting to chip away at. But there's a huge room for improvement for sure.

Speaker 3:          37:13          So one of the points he made, or a couple I guess you said one is that some of this bad science is being shaped by pressure from a lack of funding. And so I think by implication if funding were more readily available than maybe there'd be less bad science. And at the same time you said, well I can't ask, you know, if you can't double the budget, you also can't ask caps the people to leave. But I really want to question that because it seems that we can either trust and reverify that the public money we put into science now is generating genuine science. A lot of it's bogus and we don't even know which parts are how much. And there are certainly bad actors. Some of them are very, very influential in fact. And some of them are known in the community and some of them have, have concealed themselves, you know, more effectively so far.

Speaker 3:          38:04          And that's a huge problem. So the idea that putting more money in to as a, it's a situation that's generating bad science, it seems like throwing good money after bad. And at the same time saying, well, we can't ask half the people to leave. Well if half of them are bad actors, maybe we should. Except I would argue with it. I wouldn't, let me push back. Oh go. I'm sorry. But let me, let me go on to the people at large, the public at large who elect the officials. You know, the, the government that sets the public policy around this are furthermore not well informed because of the media celebrates splashy findings even when they turn out to be bogus. And there are many famous example of, for example, step is often talked about here, um, and does not pursue with the same sort of vigor, the sort of investigative journalists love finding scandals at City Hall. But as you point out, there are these studies done in humans with hundreds of millions of dollars and so on and so forth where there was some really shady or shaky, let's say preclinical work beforehand and this waste doesn't seem to be exposed to the same kind of vigor. So I'm sort of curious about your response to those thoughts.

Speaker 1:          39:10          Yeah, good. Good questions. And I think first of all, uh, there are, I think if you look at actual cases of outright fraud, the really bad actors, they're fairly, they're fairly small number of people who are clearly just gaming the system who are, who are doing, who are deliberately misleading and so on. I think the vast majority of these problems are well meaning scientists who, uh, who ended up taking shortcuts that they shouldn't have the using too few mice or, or, or not really following their procedures and so on. And so you can't say get rid of all the bad apples. Cause many of you know, I have a story in the book about a Nobel laureate scientist who made it, who has a paper that was wrong. And she was like, I was a pressure to publish situation, but you wouldn't want to tell her, sorry, you're out of science now.

Speaker 1:          39:54          She, you know, she was, has contributed a lot since then. So everyone can make these mistakes and missteps in the end depending on the pressures and the circumstances. So it's not just a simply a matter of weeding out the bad actors. It's changing the culture and telling people maybe you should publish, you should be rewarded for publishing less and making, taking more time to make sure what you do. Publish is right. The pressure's right. Now actually there's a paper that suggests that uh, the, the evolutionary pressures in science are the favor of the labs that churn out the most stuff the fastest. And, and, and, uh, and they replicate these, these, these labs then spin off, uh, you know, their Grad students going, postdocs go on start labs that use the same, you know, you know, fast matters most and in generate large volumes of paper. So, so you can change the culture too to discourage that without, you know, firing the people who are, who are, who are doing things that you know, are, are, are clearly wrong, but they are clearly not helpful either. So it's, it's a hard problem how, how to get at it for sure.

Speaker 4:          40:58          Thanks for coming today. Um, so I know that in manufacturing specifically there's a large focus on quality control. Um, and again, healthcare isn't my field personally. Um, so maybe there's an obvious answer to this, but I'm curious to know if there's anything to be learned or if there's any surveying that you did have the business community on how they've improved quality control, whether it's actually assigning quality control officers or empowering individuals to take a closer look at quality. Um, are there any lessons there?

Speaker 1:          41:28          There are for sure. Cause I think industry, the drug industry and Pharma and so it tends to do much better at these problems because they, their incentive structure is completely different if they do something, if you're in, if you're in academia, you're reward is getting a paper in a, you know, big name journals. That's, that's your reward. It doesn't matter so much if it's right or wrong. If you're at a drug company that does it, that's nice, but, but what you really want to do is have a product you can sell. And so the drug companies care a lot more about making sure that the quality is high. And there are some people who argue that you should take that degree of rigor that already exists in, in Pharma and tell people in academia we expect you to follow something like this or have some similar set of standards to do that.

Speaker 1:          42:11          And it would slow them down. It would, you know, uh, it's, it's a little bit more cumbersome, but I think you get, you get better output, you get better results for doing that. And there's some universities that have sort of found a middle ground, pardon me, they are, uh, letting the academics be academics, but before the science goes forward, they then bring it into a lab where we're s we're scientists who are sort of like, look at it from the standpoint of drug development and say, let's see if we can validate these results. If we can reproduce them before we start sending them out, uh, to, to Pharma and so on. So some, there are some fairly inexpensive ways that universities can create these research units that help, uh, sort of crank up the quality. But clearly, I mean, Pharma knows how to do this, uh, but it's, you know, it's a different, different world in academia.

Speaker 4:          43:04          Hi. So earlier you mentioned how a pipe paper can be published, it can make a big splash and they're turning out to be problems with the paper. Maybe it's, you know, its conclusions aren't as true as they look and it can be very hard to find those sorts of, the criticisms of it. What can a tool like Google scholar do to make those sorts of things, those like those followup easier to find?

Speaker 1:          43:28          Hmm. Um, a lie. If I would look at the, the pub pier example, because I think that's a, I think that is a useful tool. Uh, just for, cause you have to, you rely on individuals who flagged a paper and either have published something that's kind of contradictory or at least published a comment someplace that says, I don't think this is right and raises questions about it. Uh, I don't know how Google scholar could, could sort of index those, those cautions in a, you know, in a fruitful way, but as opposed to just reporting it 842 citations. Well that doesn't, that is not as informative to me as it would be 842 of which 30 strongly disagree and you know, and the others we don't know about. So, so a tool like that that would help not only say who is cited it, but what they have, uh, what they have observed about those papers in a general sense I think could be very useful.

Speaker 2:          44:23          Okay.

Speaker 4:          44:25          Thank you very much. I just had a quick question at looking at these studies from a different angle. I know a lot of, we've talked about here are the tests to try to find cures and what works and what doesn't work. And the other side is, is the test to either prove what is happening or what's causing these in the first place to find it, how to prevent the disease from coming. Um, and, and I went through work, I guess going through a personal scenario where I found out my, my house is gonna be on the corner of a high voltage power line with two, I have two little kids in the house. So I dove into every single study on EMS and the links to charter leukemia. And it started to, to see that anytime that you found a promising study that showed this land corp even didn't show us link, it's very easy for the other sides are poking holes in it because the sample size and, and I'm just wondering from your opinion, how do you look at the other side from like we started looking at the precautionary principle and stuff like that, but to actually prevent these when you have other, what they were calling hired scientists to kind of poke holes in these studies that there very well may be actual holes in the study, but then it's going to prevent us from ever taking that step to actually prevent some of these diseases from taking form.

Speaker 1:          45:28          Yeah. And unfortunately those are all, most of those studies are epidemiological studies, which are much harder to get to try to ground truth because you have so many variables you're working with. It's not working in a laboratory situation where you can reproduce these experiments and so on. So yeah, that's uh, that's, I mean the quality, just the outright quality if to begin with is fairly low on those. So a, and that confidence should be, yeah, it should be low in those, uh, it's uh,

Speaker 2:          45:58          yeah.

Speaker 1:          45:59          How does, how to sort through that and find the truth is, is tough. I mean the IOM in the case of the EMS and power lines, there was a big national research council, a National Academy of Science's report I think some years ago where they took, they took another run at these issues and based on the first decade or two of us of studies on this and they said there doesn't really seem to be anything here. Uh, and I think in that case we stepped back and when we rely on expert opinion as opposed to a really expecting that the science will yield us a completely concrete and believable answer, it's not totally satisfactory, but, um, but eh, but I, that's, I think given the, given the realities of that kind of science, I think that that's kind of what, where we're left with is what, what is the expert opinion on this?

Speaker 2:          46:48          Yeah.

Speaker 4:          46:49          Concerning reproducibility. I have thought that reproducing results is theoretically important for science to work, but unlikely to be actually done in practice very much because I doubt that anyone gets a Nobel prize or even tenure at the lower train switch community college for redoing something as someone already didn't publish. You've told a few stories of people actually trying to reproduce results. So clearly this happens at least sometimes. Do you have any general observations concerning the cases when it actually happens? If someone tries to reproduce the result, what were the motivations typically? What's the distribution of reasons that caused someone to actually bother to do this? Yeah, I think most common motivation

Speaker 1:          47:30          is a, if you're working in a, in a rival lab and you're a postdoc or graduate student and your professor says, Hey, there's an exciting finding there, see if you can build on that result, but before you build on it, make sure it's correct. And so that's where I think a lot of the reproducibility these attempts to reproduce happen is at the bench. People saying, I want to, I want to take this on and I want to see if it actually works. And uh, and so this people can waste, you know, six months or a year of their career chasing something that, that that doesn't pan out, but at least they've done the attempt to reproduce. And sometimes that gets published and people realize, oops, this didn't really work. And sometimes it doesn't. I mean, for some big results, you were mentioning the report of be at some amazing new way to produce stem cells.

Speaker 1:          48:17          That was such a big finding that, um, that everyone realized if that's a, if that's for real, that's an incredibly important laboratory tools. So, you know, dozens and dozens of blabs dived into that to see, can we make this work and can we start using it ourselves? So, uh, so, so there are some very strong motivations and they tend to be motivated to do those studies that are the most interesting. So that, I'm sure there's tons of stuff in the literature that somebody publishes. It just becomes a line on their CV and that's it. Nobody ever looks at it again. And it's kind of just disappears into the, uh, into the dust and nobody really notices. And those are some ways, it doesn't matter if those ones work or not, but the exciting and interesting finding sis suggestions of a new direction and so on, those studies do get attention and people do sit down and try to reproduce them.

Speaker 1:          49:04          Sometimes it can take a long time though. I've a story in my book, um, about, uh, example of this was a discovery 1999, 2000 called, uh, it was regarding a phenomena they called trans differentiation, which was a couple of labs reported that they discovered they could take blood cells, uh, uh, bone marrow cells and transform them into any other kinds of cells they wanted, which was like sort of, that would be incredibly powerful laboratory tool. And people took off on this idea of the, of trans differentiating these blood cells, uh, to do it. And they, uh, and there were quite a number of studies published before somebody at Stanford finally said, wait a second, all these studies that are reporting on it and people are doing this and so on. But no one has really done the careful reproduction of this experiment or, or really tried to get to the bottom of whether it's a really correct phenomenon.

Speaker 1:          49:55          And they did a series of very time consuming, elaborate, technically challenging and really careful experiments and concluded the whole thing was, was a mirage. It was actually not really happening. And uh, and there's a, and so, and this was, it only took about three or four years I guess, before they published this paper and said, guess what? The fluorescent marker you're seeing means something completely different. It has nothing to do with the cells changing cell types. It's just moving around. And, uh, and the entire field sort of disappeared like a soap bubble. But there were, there were many, many studies that had been published, reporting seemingly validated in this phenomenon before this lab at Stanford said, wait a second, no one's really done the careful validation here it is. And guess what? It doesn't work. So, so sometimes it, sometimes it takes a little while to sort out.

Speaker 1:          50:47          Uh, I just had one question. You mentioned you had looked at medicine earlier on in your career. Like in the early two thousands, was any of this stuff on your radar then? No, actually. And uh, I mean a lot of the problems in clinical medicine with clinical trials and so on, uh, that had been regarded as significant problems at that time got very little attention in the media. I think a lot of this sort of happened below the radar. I mean, I, there was maybe some of it written up in some of the technical journals, but this was not an issue that really garner public attention. And, uh, and I think some of these, these, these new stories were, were surprising to people, but because the results were so eye-popping and a lot of the, a lot of the clinical research stuff was much more along the lines of, well, we know that the drug companies always like to look at their results in the best possible light to try to get their FDA approval. And so there's always this element of, of, of knowledge that things are always being interpreted in, in ways that are, uh, not necessarily just completely straight forward. But I don't think there was an awareness about how, uh, how much improvement was needed in the world of clinical research, at least not in the lay press.

Speaker 2:          52:06          All right.

Speaker 1:          52:07          Thank you all for coming.