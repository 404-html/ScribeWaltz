Speaker 1:          00:06          Good afternoon everyone. Uh, today it's my pleasure to introduce our speaker, Jared McLean. Uh, Jared and I actually did our phd in the same lab and during Grad School, Jared was somewhat of a pioneer in the field of developing algorithms for quantum computers to simulate materials and chemistry. In particular, he's the inventor of one of the most sort of popular approaches to using near term quantum computers for this purpose, which is known as the variational quantum Eigen solver. Jared is now the, um, Louie c Alvarez fellow at Lawrence Berkeley national labs. And lately he's been working closely with our, uh, with the [inaudible] AI team at Google in order to develop software which compiles chemistry problems, uh, two instructions that can be run on near term quantum computers. In fact, he's a founder of the open source package from you live, which we just released earlier this week. So, uh, without further ado, I'd like to introduce cheered McLean.

Speaker 2:          01:07          Okay,

Speaker 3:          01:10          thanks a lot for the introduction, Ryan. And it's my pleasure to be here to talk a little bit about both what I'd been doing and quantum computing in general. So just a few words about kind of the level of this talk and content of this talk. So I, I asked around that is to what level that these talks are generally given at. And they told me, well it might go on youtube, so it would be useful if at least some part of it appealed to a more general audience. Some part appealed to say computer scientist or more general a computational folks and some part was geared towards specialist at the end. So I hope there's a little bit of a gradient on this talk that there's a little something for everyone. So if you're not so familiar with quantum, maybe it's a good start for you, but you might be off to a little bit of a slow start if you're an expert.

Speaker 3:          01:54          So just that caveat is I began talking. So what I want to talk about is quantum computation, both in a general sense and for this problem that we think it's going to be very, very good for, which is the discovery of new materials and chemistry. So I think it's appropriate these days to start almost any talk in quantum computation with a discussion of line now. So if you're like anyone else in the field, you've probably been looking around and seeing news about quantum computer is seeing a talk about it for probably close to two decades. If you've been around for any amount of time. And if you kind of graph the amount of quantum excitement over time that you might've seen, you'll, you'll see a brief peek here at around 1994, even though it was conceived of in the 80s by Richard Fiman, uh, were Shor's factoring algorithm came out.

Speaker 3:          02:42          And if you don't know what this is, it was an algorithm that promise to essentially break Rsa encryption and got everyone in the government scared enough that they started pouring money into it and the tension came. And so people started looking at this technology saying, wow, this can do incredible things. And you'll notice there is a brief dip after that when people figured out that, wow, these devices are actually a little bit hard to make. So there was a little bit of a decline as people went back to their labs, refine their ideas of what they might want to build these things from. And you'll see that there's been a pretty big, uh, increased recently. And if you've been looking around at the news from different companies, from different universities and other places, you'll see that there's pretty big increase starting to happen right here, which is related to the fact that our cubits are getting much better and they're getting much more manufacturable.

Speaker 3:          03:28          And people are starting to think, wow, this is a, this is something I need to be ready for it because this is coming. And there's already been predictions by this group, especially the Google group is a leader in this, a quantum information field that by the, by the end of perhaps this year or 2018, that will reach a landmark known as quantum supremacy. And what this means is that there will be some well-defined computational tasks that a quantum device can do much faster than all of the combined a classical resources on earth today. And that will be a true milestone that says, wow, these devices are really capable in practice of something that we could not do with the classical resources we have. And after that there'll be some kind of rush to move from quantum supremacy to practical applications. And that's kind of where I'm going to focus on is getting over this perhaps post supremacy chasm and really pushing this technology forward by showing in the short term what practical applications, what useful technologies and algorithms we can bring out of this.

Speaker 3:          04:26          And of course after that, sometime in the future we're going to move towards an error corrected quantum computation regime. And I'll talk a little bit more about what all these things mean as the talk goes on. But really this is what I want to focus people on is that if we can put these practical quantum algorithms out there on near term devices, then this is really going to post, give us new tools and push us forward in the technology. So where do we expect to win? So the other thing you might be interested in is, okay, great, you've delivered me a quantum machine. Where do these machines, where do we expect them to you useful and how useful will they be? So some of the problems that people have talked about, and I'll focus only on a few of these are perhaps the simulation of different reactions.

Speaker 3:          05:07          And what I mean by that is perhaps knowing whether a drug will work or not before you actually do the experiment in a lab or knowing which drug will be produced by that particular catalyst. Or another one I'll talk about a little bit is calculating radar cross radar cross sections of perhaps planes are machines you might be interested in or pattern matching or machine learning. And of course breaking RSA encryption if you're at three letter agency and you're worried about that kind of thing. And there's a few images of what people might have conceived these look like and what is the advantage that we actually expect. So what a quantum computer is not is just a machine that runs everything you have at the moment faster. It's a new way of looking at problems that we'll talk a little bit about the can get you real complexity theoretic speedup.

Speaker 3:          05:52          So people talk about polynomial speedups or exponential speed ups. So I just wanted to give you a feel for what that might look like if you achieved a polynomial or an exponential speed up. So if you had a quadratic speedup for a certain instance of a problem that might be in a reduction of say a year down to two weeks or something on that magnitude, depending on the underlying factors. And the really exciting one is if you can get an exponential speed up, which has the potential to reduce some problems down from something like 10 to the 82 years to something more like 300 seconds. So what is 10 to the 82 years even mean while the age of the universe is something like 14 times 10 to the nine years. So you've really made something that was essentially impossible routine and that's the kind of goal of a quantum device.

Speaker 3:          06:38          That's why we're so interested in it is the potential for these speedups to make the impossible. And every day occurs. So now backtracking to kind of what this technology means. So I've already used the word quantum a lot and you've probably heard it any number of times if you've been at all interested in this field, but a backup and say, what is quantum? What do we mean by that? So if you, if you're biased at all by a media marketing or anything like that today, you might conclude that it's a buzzword that you attach to any product you might want to sell a few more of or have it be a little bit cooler. Uh, I'm going to take a more physics oriented approach and say that, you know, everything is quantum in a way. So the universe is governed by quantum laws. But why haven't you seen any of that in reality?

Speaker 3:          07:24          So something that's in reality that we've kind of observed from day to day life, we often characterize as classical. So classical objects have very predictable behavior from your intuition because that's what you're used to. So take these beanbag holes, for instance, you just throw a bean bag through, you watch its trajectory and it goes through the whole as you might expect. So there's nothing terribly hard about that prediction. But if you took that same object and in fact people have done experiments on things quite large up to kind of Bucky balls, which granted as much smaller than a bean bag and you cooled it down enough and you had a precise enough instrument to measure it, you would find out that if you put one particle through that, so if you kept throwing that beanbag towards these two holes, you would find that the beanbag was interfering with itself, which is kind of a strange effect to have.

Speaker 3:          08:11          So this is a classical double slit experiment, which, uh, are a quantum double slit experiment, rather, that showed some of the original properties of why we started to think, wow, we need a theory beyond just balls rolling down hills and these effects that we see. So a particle interfering with itself. And as a result it starts to occupy only discrete levels and looks like a very different type of particle than you had otherwise. And when people started to try to simulate and predict these reactions or effects, they said, wow, this is really hard. What if we could actually use this tool to our advantage instead? What if we could use this difficulty as kind of the power of our computation? But I'll get them into to that more later. But effectively when I wanted to find for you in a very loose sense is that a quantum system is some physical system operated in a regime where we actually need effects like discrete energy levels and particles interfering with themselves to accurately describe it in practice. That often means something that's very cold and very well controlled.

Speaker 4:          09:11          Yeah.

Speaker 3:          09:11          So I'm going to talk also about quantum simulation and I think it's interesting to go back to the roots of simulation, which are actually in these devices called Auris that are uh, have been dug up from sites as earliest one 25 BC. So the simulation in some general sense is that you have a model you're interested in and you'd like to push it forward in time and ask what that model predicts. So in the cases of Auris, these are models of solar systems that you build and you crank forward either by hand or by a clock, and you say, does the, do the orbits of these fake planets match the orbits of my real planets? And if the answer is yes, then in some sense the model that you've constructed is somehow more correct. So it would be very difficult for those particles that I just described, which need to interfere with each other to be built with just classical balls.

Speaker 3:          10:02          So a idea that originated kind of the field of quantum simulation and thus quantum computing. Was it Richard Fineman? Famous physicists said, well, if you want to do a quantum simulation, you probably need to do it with quantum particles. And I'll describe it a little bit what that means. But these blue balls here are kind of just any particular quantum system you might have in your ability, these puppeteers strings on top or the ability to experimentally control those much better than you could in a different physical system. And we'll use that to kind of examine what quantum particles might do.

Speaker 4:          10:36          Okay.

Speaker 3:          10:37          And what are examples of quantum systems? So I have a few pictures here of ones that people have proposed for the use and computation and generally these meet the requirement that they're in this regime that you need interference effects and things like that. And they're also highly controllable systems so that you can do things that you wouldn't be able to do in nature. And I've pictured a number of machines, like super conducting cubits, one here from the Google Group, one from the Sidiki group, quantum photon setups and ion trap setups. Basically any number of controllable systems that you can bring to this particular level, our potential building blocks for these quantum devices, each with their strengths and weaknesses that might exhibit as you start to manufacture them.

Speaker 4:          11:17          Okay.

Speaker 3:          11:18          And quantum simulation of course was the first idea of, you know, if you want to study the effects of a quantum system and this is a very hard thing, then perhaps you can just use another analogous quantum system, much like the planets and the oratory of the example that I gave before and this simulation idea led almost immediately, well, not almost immediately, uh, into a more abstract concept that I'll start to introduce now, which is kind of Cubans. So it's a very big leap to say I've taken some amount of some lasers and pushed around ions in a trap to, towards an algorithm that talks about factoring products have two large primes. There's a big leap there. It's very hard to, to imagine how ions resemble these types of systems. But as similar leap was made in the original systems is we moved from say, models of planets all the way to digital computing. So it's of course very hard to imagine how a planet fits in a digital computer. But we've managed to come up with abstractions and encodings and discriminations that have made this possible. And really the leap from quantum simulation to quantum computation is this abstraction, this model of universality that allows us to code problems we're interested in and to the sophisticated devices and leverage those powers of interference, entanglement and all of these hard to describe physical effects to utilize them in a more computational way.

Speaker 4:          12:40          Okay.

Speaker 3:          12:40          And so just to talk about this quantum computing abstraction, you've probably heard of it many times. So if you imagine one of these quantum systems that I've described, so if physical system in this low controllable energy space and it occupies only the first two discrete energy levels that it's allowed to, then we typically are calling this a cubit. So the cubit is a quantum generalization of a classical bit. You may have heard this explanation many times, and I'll actually debunk a little bit of that in a second, which is a classical bit is zero or one and a quantum bit. It's something like zero one or anything in between. So you can have super positions of these objects. You can have entanglement between them, which are truly important. Quantum effects and operations on these bits are just called gates. And we typically denote this with these gate diagrams. So you can read down the lines for example, and just say, well, cubit one gets acted on by these gates cubit to gets acted on by these gates and so on. So the details of understanding exactly what these operations are are not terribly important at this juncture. But just to know that we have this model of computing that we fit in our arbitrary problems to that much like the modular digital computing, which we've built so much on in the past.

Speaker 4:          13:56          Okay.

Speaker 3:          13:56          And just to give you notational, uh, familiarity, we often call these generic state PSI. So you'll notice with the cubit, I've put these brackets around the zero and one. And with generic states, I'll often put a bracket around some state side. It just means some number of cubits. Some number of these physical systems put together, uh, to make my quantum computer. So I'm going to consider a quantum computer, uh, a collection of one or many of these cubits put together that I can control in any way that I'm interested in within a feasible resources.

Speaker 4:          14:28          Okay.

Speaker 3:          14:29          So it behooves us for a moment to kind of debunk a lot of the things that get written in popular science articles on quantum computing. So I just like to highlight some of these for people that are in computing, uh, to kind of help you understand that there's a little bit more to the speed ups than meets the eye when people discuss these algorithms. So one thing that gets said a lot is it's faster or better because it can use an exponential number of states. So this is a kind of nebulous statement cause you don't really know what it means. Use, you don't really know what, uh, what you know, popular science writers mean by this. And I'd like to point out that set of classical in bits can also be in an exponential number of states. So if you take it at a very face value that he can just have zero one or many things in between, then there must be something a little bit missing from that statement and little clarifications that are needed such as entanglement or such as the number of states that can be occupied per given resource.

Speaker 3:          15:27          Another myth is that it's faster or better because bits can be zero and one at the same time. So it's in fact a little bit nebulous even to say bits are zero and one or zero or one quantum mechanics off often requires actually a different theory of logic. And more importantly, what people often mean by this is that when you can dial between zero and one, that somehow occupying all those states in the middle is more powerful. But if that were the only case that an analog bit might serve just as well as a quantum one and a collection of analog bits would be just as powerful as classical, uh, quantum device. But that's not true. And a lot of these things are covered in a very interesting comic, which debunks. The third myth, which is that work is done by computing all the answers in massive parallel.

Speaker 3:          16:12          And so I want to highlight this SMBC comic, which is co-written by Scott Aaronson, which I think highlights many of the aspects of bits. It's called the talk, where a mother explains to her child the important caveats to the magic of quantum computing and a thing they right here is the important thing for you to understand is that quantum computing isn't just a matter of trying all the answers in parallel. So if you actually thought that was the case, you can look into this comic and see some of the details of why. If you perform measurements, you would then only get one answer. And really you get the speed up when all of these inputs combine and just the right way to give you just the right answer. And so this is a kind of delicate matter, but if you read through many pop science articles on quantum, you'll encounter these arguments over and over again. So it helps to know that they're not completely true or not the whole story.

Speaker 3:          17:04          So what are the challenges in quantum computing form an both an algorithmic and a design standpoint. So these algorithms tend to follow a simple pattern if you look at many of them. So you prepare some state of your cubits, meaning I manipulate the cubits in a particular way with laser or microwave pulses or things like that. I evolve them forward under my given set of gates sequence and I performed some measurement at the end and I'm measuring out a particular piece of information. I'm not characterizing the entire quantum state otherwise there's no way I would get out a speed up from this particular process in each one of these steps has a number of challenges. For example, in preparing the state, I'm often limited by the number of cubits on my device. When I think of a 64 bit classical, that doesn't mean the largest problem I can fit in my processor.

Speaker 3:          17:52          64 cubits are 64 bits. I have some ability to take problems by chunks and move along and compute on them. That's often not the case with quantum algorithms where you depend on the entanglement between all parts to get your speed up and chunking problems becomes much, much harder. So we need larger devices than we would conceive a otherwise. There's also issues of coherence time, which mean the amount of time essentially that a cubit is good for as you're acting on it before you'd like to move on or you need to refresh that particular device and it sets a time limit on the number of operations that you can actually perform. And finally, information extraction can be a fundamentally different, which I'll highlight in a particular example after this. And one solution to all of these problems is of course better hardware. Um, but what I like to say is that we have to meet hardware designers halfway.

Speaker 3:          18:43          We need to codesign better algorithms as well. And what this means is that in the past, like this BQE algorithm, we've designed coherence, time, flexible algorithms that work with the coherence time of device. And I think in the future we need to worry about how to mill cubit, number flexible algorithms and to improve this kind of halfway point where we couple quantum and classical devices together because we really do have well a well defined classical resources today that hopefully we can leverage in that process. So this information extraction extraction point, I want to get back to you with one particular example of a quantum algorithm got written down. So this algorithm thinks about solving linear systems of equations. So if you're not familiar with this, you can just think of this as how do I solve for x in this particular problem? Uh, appears in any number of say, logistics problems, machine learning, everyday optimizations, things like this.

Speaker 3:          19:38          And classically, when I say I want to solve this problem, it essentially amounts to I want to write down all the entries of x. And that seems like a reasonable thing to do. A quantum algorithm came out, which was exponentially faster, which is that enormous speed up I talked about before, which is exponentially faster at delivering the solution. But it changed the definition of solution a little bit. It, notice the brackets around the x and the B now. And what it meant was the solution translates to preparing a state x from which one can efficiently sample. And so that's not exactly the same thing as writing down all the entries because if you wrote down all the entries, you would lose that advantage necessarily. And so I want to say is that's not not a bad thing necessarily. What it really is, is it solving the problem, not reproducing the classical algorithm.

Speaker 3:          20:24          So if I'm out and I'm bowing and I'm looking at my uh, plain and I'm trying to make a stealth aircraft, do I really care about all of the entries of where every single radar bounces or do I care about an aggregate cross section as fast as possible? And if the answer is that I care about this cross section, then really what I've done is use a new tool to solve this problem rather than just translate an old classical algorithm and this step was necessary in order to achieve this quantum speed up. And it's one that I think you have to conceptualize moving forward as what quantum computers are good at. Quantum computers are not about taking an old classical algorithm and running it faster. There are about using a new set of tools to solve the problem that you're interested in in a fundamentally new day.

Speaker 3:          21:06          And I think that's highlighted very well by this particular a comparison between the classical and quantum version of solving a system of linear equations. So where do we think early applications are going to be highlighted for these particular devices? We think some of the earliest problems perhaps will not be breaking codes or you know, bringing down the world financial system or something like that. Uh, there'll be an areas like a optimization, so say quantum approximate optimization of logistics or other multivariant surfaces that you might find in any kind of problem. They might be in some kind of relational representation. So you can think of different kinds of quantum neural networks that link together variables in a way you didn't know how to do before. Uh, and the one that I'm interested in, and I'm going to talk a little bit more about is quantum simulation.

Speaker 3:          21:53          So this idea of how you perform experiments that should have gone, that would have needed to go and do a laboratory on a computer beforehand and areas like chemistry or perhaps even high energy physics where you can predict what catachesis would happen inside the fusion of a nucleus. Or perhaps you could look at what drugs are disease preventing are the types of simulations that we want to look at. And I'm going to focus in on quantum chemistry in particular. So why do we want to simulate quantum chemistry or why do we want to simulate chemistry in general? What is the dream of this field? Essentially the dream is that some someone gives you an idea of what a molecule or a protein or something in someone's body looks like or a material. And just from that, I would like to understand many things about it.

Speaker 3:          22:39          I'd like to understand how it absorbs light, like to understand how it complexes with other species. I like to understand how that molecule likes to talk to surfaces and move around. And from that understanding, I'd like to develop some level of control. So if I know why a molecule absorbs light, what functional groups of fact that maybe I can design new photovoltaics, new solar cells to put on my house. If I know why certain species complex within a protein or why a protein folds are misfolds, maybe I can design an inhibitor that prevents the onset of certain types of diseases. And if I know why molecules complex with these catalytic surfaces, maybe I can get platinum out of my catalytic converters and understand how to lower the energy consumption of these processes. And these are things that are all made possible only by very high accuracy simulations, which are the kind that we're going to be aiming for.

Speaker 3:          23:29          And this problem is also an interesting one because you might say, well all those things you just described sound like very lofty goals, but where are you even going to start from? And it's an interesting problem because the underlying laws, physical laws necessary for the mathematical theory of a large part of physics and the whole of chemistry or that's completely known. And the difficulty is only that the exact application of these laws, we do equations much too complicated to be soluble. So it said by physicists, Paul Dirac, and what he essentially meant was that you can, if you could just solve equations large enough. So this very innocuous equation that I have written on the right hand side here essentially represents all of those things that I was just talking about. If I can find a way to code a molecule into these equations and solve this linear eigenvalue problem, then I'm going to start to understand, you know, how these molecules absorb light, how they complex with other species, what are the rates of chemical reactions and do everything that I just talked about.

Speaker 3:          24:26          And so that's kind of the exciting dream of of quantum chemistry. And it's one I think we can achieve with quantum computers. And one problem that I want to highlight for this in particular. So you say that's a very general type of argument that you've made. What specifically are you going to look at? And I want to highlight for you one particular problem, which is the production of fertilizer from nitrogen. This is a process that goes on all over the world all the time. It's how do you take into and make it into ammonia says nitrogen fixation problem. And humans currently do this at massive scales. We do it for crops all around the world. And we use a process called the harbor process, which happens at 400 degrees Celsius and 200 times atmospheric pressure and currently uses one to 2% of all energy on earth today.

Speaker 3:          25:11          And then we look over at our, our friends in the plant kingdom and the, uh, animal kingdom and fun guy. And we say, well, how do these guys do it? They existed long before we had fertilizer plants building all of this chemical processes and they managed to do it at 25 degrees Celsius and one atmospheric pressure. So Room temperature and atmospheric pressure essentially. And people have managed to boil down in one particular area in nitrogenase where the action is happening to this kind of for Moco cores they call it. And people have tried to study this with current methods. And it's beyond the reach of all current classical methods to really understand even where the substrate attachment happens, what the electronic structure processes and how we can move forward on this problem. And what I want to propose is that while there's no clear path, classically I think quantum mechanically with something like 150 to 200 logical cubits, there's kind of a straight path forward to studying the electronic structure of this problem.

Speaker 3:          26:09          And so why is this problem so difficult? So I talked about the fact that I only needed to solve this one very simple looking equation in all of these properties would come to me as I, I imagined. So the problem is not in the the setup, it's in the dimension that you need to solve. So if you imagine that the, another way of phrasing this problem that I want to solve is that I would like to know where I should put all the electrons in my system. So this is called the electronic structure problem. And if you imagine that I disagree ties things as I always need to do for a computer and put down m sites, I can ask how many ways can I arrange each of these, number of electrons. And if it's just one, I can arrange them m number of ways.

Speaker 3:          26:49          And if it's too, it's m squared, making some course arguments about anti symmetry. And if I go to just say a hundred sites and say 80 particles. So you can see that this grows as em to the end and that's about the size of molecule you might expect for something like a hundred sites that I've pictured, they're much smaller than a protein. The dimension of this problem that I need to solve becomes 10 to the hundred and 60 so this is a number that's very hard to get a feeling for a, so I've given you a barometer for that, which is the number of particles in the universe is estimated to be roughly 10 to the 80 so that's as if every particle in the universe had another universe within it. And I needed to account for all of the particles in those and I need to solve a problem. It's on the dimension of that scale, which seems totally intractable. But I want to remind you that this same difficulty is the power that we're harnessing when we use a quantum computer. So we've essentially turned our lemons into lemonade in a way.

Speaker 4:          27:45          Yeah.

Speaker 3:          27:45          So I just want to draw back and aside for everyone who might not be familiar with quantum to understand another exponential object that you might be more familiar with in the relation between that and this problem. So you might be more familiar with probability distributions where you say if you have say 16 different places that you might like to look for lunch and you have your own set of preferences, p one for each store that you go to and someone else has their own set of preferences. If the two of you don't know each other, these probability distributions factorized. So even though this joint distribution on the left has a lot of size, the structure allows you to kind of simplify this problem. So you only need a linear amount of information. However, if the two of you definitely know each other, whether your friends or enemies, then a correlation gets introduced between those two things.

Speaker 3:          28:32          And that no longer factor rises. And you can imagine if there's, you know, and if these are many, many of these stores and many, many of these people keeping that joint probability distribution is horribly complex. And the key caveat of why quantum is different from these types of probability distributions is that classically we know how to sample from even these large spaces using things like Monte Carlo methods. But that interference phenomenon that I talked about and entanglement mean that we can't use some of these methods. It's unheard of in classical probability that two people would interfere with each other and not be in a store, for example. And having to account for these effects makes it very hard to simulate classically,

Speaker 4:          29:13          okay,

Speaker 3:          29:13          so how do we actually simulate these problems on a quantum computer? So I've told you that there's a lot of promise for doing so and I want to show you how we actually start to build these things. So if we go way back to say high school chemistry, you might've seen a model that looks like some electrons rotating around, uh, a proton and a neutron. And then if you continue taking chemistry, you learn very quickly that perhaps this model is not so accurate. It doesn't make many predictions at all. And if you entered chem hundred one and say something in university, you might've found the molecular orbital model, which is often pictured as the last vestige of these things. And I want to tell you that this molecular orbital model, which predicts things like bond order and where the spins are is exactly like that factorized probability distribution that I had before.

Speaker 3:          29:58          It assumes no explicit correlation of the electrons. It's like a naive Bayes model. If you're doing machine learning and it's not a, it's not a good enough model, so it's simple but it's not good enough. And to give you a picture for what that might mean, it's so if I have some, I wrote down that same picture for the simplest molecule like h two which is a hydrogen molecule and I try to pull it apart, which is this picture that I have over to the right. Then I would find that while the shape is generally okay, what I would predict is this top dotted line up here, which is seems to be quite a bit off from the exact line underneath it. So you come to the conclusion that if chemistry is anything at all to do with the making and breaking of bonds, which you feel it might be, then this is not a sufficiently good a model.

Speaker 3:          30:43          And the reason for this is electrons actually care a lot about where the other electrons are. These correlation effects make the wave function very much non separable in these types of regions. And you have to figure out a way to build that into your model. So how do we put these, these things in? So I don't want to Belabor the the symbols here too much, but essentially we take some model of space and we chopped that model of space up. So in much the same way, if you drew a line on a computer, you would eventually have to go down to the pixels and discreetly draw each one of them on your screen. We have to do the same thing here. So we divide the space up and we put it down on some type of grid. We choose a specialized grid, but this is essentially the same.

Speaker 3:          31:24          And the output of this is this problem Hamiltonian that you get here. And the only thing I want to emphasize about that is that we classically precomputed and it tells us everything about the problem that we'd want to solve. We often then go ahead and solve that mean field problem that I took told you about to get a decent starting point for where we want to go. And this defines this concept of molecular orbitals for us, these different levels that things can fill that are these uncorrelated motions of electrons and how do we build in the correlations. And the simplest possible way is that I could go back and ask about that sort of joint probability distribution by could just enumerate every single possibility of filling. Then that would be one way to solve it. It would of course scale horribly like this universe size solution that I had before, but conceptually it's the simplest way of doing so.

Speaker 3:          32:11          And it's often called exact diagonalis operation or full configuration interaction in chemistry. And of course there's been many methods between this mean field uncorrelated and the exact solution developed over the years. And I won't Belabor this slide too much, but the gist of it is many of the classical methods for those problems that we're interested in are either too costly or they don't capture the correlations that we need enough. So what we'd like is kind of this exact level description, but for a cost of a method that something more like density functional theory here or perhaps Qmc or Monte Carlo or something like that. So exact solutions of the quality we need, but for the price that we can afford to pay. And so why do we think quantum computers might be good at this? So a paper that came out in 2005 by Alon Esper Guzik, who's now at Harvard and was my phd advisor as well as Ryan's, uh, showed that for some instances of chemical problems, I will, if you put in a say under certain assumptions, then computing that energy, which I just told you about only costs a time that scales polynomial in the system rather than this universe sized object.

Speaker 3:          33:17          And a key portion of this is that you prepare the state, you have look, do some evolution, but your measurement only extracts a little bit of information. It doesn't read out that whole state because you don't care about that whole state. There are pieces of that state and you'd like to know things about. But your quantum computer has allowed you a way to zoom in on the information you want without being burdened by the information that you don't need. And this, this led people this see that classically this might have an exponential costs and quantum mechanically it seemed like a modest polynomial costs. The challenge when we went to put it on experimental devices was that it often required many more resources than were available in the lab. So we tried to look towards a different approach and we took a codesign perspective. So what do I mean by that?

Speaker 3:          34:03          So if you imagine the previous perspective as someone kind of sits down with a problem, they try to write down a circuit specification that optimally solves this problem. And then there's a big question mark because of this Cuban coherence time problem of does it fit in my quantum blue Jean Queue? And if it does, it gives me the answer to life and everything. If it doesn't, then perhaps it's simply doesn't run, which isn't very useful. So what we wanted to do instead was considered the tasks and the current architecture and try to find the best solution possible. So what this means is kind of combining the problem and the architecture that we have, getting a circuit sequence, it's compatible with these two and doing kind of a classical feedback loop. So the answer we get back out might not be perfect. So it might only be close to the answer to life and everything.

Speaker 3:          34:49          For a lot of chemical applications say, does this react or not? Is this a valid drug or not? Where you're only interested in some course answer that depends on an accurate energy that might be better than you can do. Classically, it might be good enough to make that prediction that you're interested in. And to do this, you need to ask, okay, so I have a quantum computer with limited resources. How do I build to that device? What does this device best at doing? What? What are kind of the minimal specifications for which I can call this a quantum computer? And one is I would like to be able to do an operation, which if I've done all of my state preparation, I'd like it to be able to look at a cubit and ask, is this cubit a zero or a one? And I'd like to do that over and over again until I've, I've decided what the average value of that might be.

Speaker 3:          35:35          And I'd also like to look at many cubits at the same time. And I'd like to ask what those correlated values are. So this is something that's efficient to do on any prepared quantum state. But in general it might be very hard to calculate this expectation value on a classical device depending on the state that I've prepared. So I've really boiled down to some essence, at least one simple operation for a prepared state that would be very hard for me to do classically. So how am I going to use this on my chemistry problem? So I'm going to switch formulations a bit. And so that problem that I showed you before was written as an eigenvalue problem. And it turns out that for exterior eigenvalues you can play a little bait and switch and you can always write a eigenvalue problem as a minimization over this kind of constrained unit vector.

Speaker 3:          36:21          And so I'm going to switch over into that formulation and say, now the problem, I would like to solve it some minimization of an average quantity. And if I decompose my Hamiltonian and the the way that standard for some of these systems, then essentially by linearity I get a problem that this expectation value that I'd like to minimize over that is equivalent to my eigenvalue problem. I have two tasks, one which is easy for a quantum computer. So I need to compute a bunch of these little averages here. So repeatedly looking at each cubit and telling me if it's zero or one. And then I have those inputs that I got from the discretization. I chose how I divided my problem up and my classical computer is very good at adding a lot of numbers together. So why wouldn't I use that resource for this particular problem?

Speaker 3:          37:07          So I perform a bunch of measurements on my quantum computer, which are easy. I feed those to my classical computer and ask it for an update step. So this kind of suggests the hybrid scheme, right? Parameterize my quantum state with some classical experimental parameters and I compute averages using a quantum computer and I update that state, uh, passively and pictorially. This algorithm kind of looks like this where I have a quantum module where I prepare some state and feed it in these expectation values that I read out and I add them together on my classical computer. And then I just looped that algorithm back and back and back until I've reached some level of convergence, which I think represents how good that device can do. So again, the answer might not be the best at absolutely possible because you're constrained by the device itself, but it's perhaps better than you could do on a classical device.

Speaker 3:          37:58          So this is interesting because if I showed you the algorithm before just briefly, which was this quantum circuit, I just described, an algorithm that looks effectively like this, which is that I've removed all of this interior part without the millions and millions of quantum gates in it. Uh, and so where is the advantage coming from? It has to come from that state that I've input. So it really begs the question of what are the interesting quantum states to look at? If you imagine the, they, the space of all possible states, somewhere inside it's the ones I can reasonably make on my quantum computer. And within that there's the ones that are easy to model on a classical computer. So I'm really looking at this part in the blue space, which is not covered by the yellow here and where, where do those states live. And I think that's one of the most interesting questions that a quantum computer is going to be able to answer for us.

Speaker 3:          38:45          And kind of conveniently for that is that I can then define what states I want to explore by the device that I have. So if you call it a quantum hardware on sites are sometimes sub logical onsets, then you can imagine that that parameter space you explore is any of the knobs that you can repeatedly turn on your device. So that if you can do that operation twice, you can call that some quantum state you're interested in and you use the complexity of the device to your advantage. And the coherence time requirements are going to be set by the device instead of the algorithm. It won't be that case that you get, I need 10 million gates. Why can't do till million gates? And you get nothing. It's I have this amount of time and you get the best answer you can within that window of time.

Speaker 3:          39:28          And of course we have some theoretical constructs that I won't go too deeply into, but, uh, we like to be able to design these particular onsites as as well in a logical formalism. So of course, I haven't really talked about what happens with quantum errors yet. So you can imagine that these devices are not perfect. I've alluded to this many times, and if you look at the level of the device, you might imagine that there are certain areas called coherent errors. So imagine if I, an example of this, if I want to rotate by some angle, but every time I rotate by little bit too far, then that's going to be a type of coherent error. And this quantum device also lives in a larger environment. So it's always seeing electromagnetic waves coming in. Maybe it's even feeling the effects of temperature from bleeding in from the outside.

Speaker 3:          40:14          And this is going to cause kind of random errors that look more like a third or more incoherent. So these are types of defacing EHRs. So how does this algorithm perform in the presence of these types of types of noise? And one of the things we conjectured is it because of this classical feedback loop that certain types of coherent errors would be corrected by this procedure? And we're lucky enough to have, uh, participated in experiment and collaboration here with the Google group actually that showed that this was, this was in fact the case. So let me describe briefly what this image shows. So it's actually a good depiction of what a quantum quantum algorithm looks like in practice, or at least a small scale one. So to your left you have the picture of both the hardware at the top and the software at the bottom.

Speaker 3:          40:59          So the hardware at the top are of course sees a transplant cubits that come from John Martinez, his lab, and you see that the software on the bottom labels them as just cubit zero in Cuban one. And as I apply these quantum gates or just operations to cubits, you can see how that corresponds to pulse sequences at the top. And this goes through and you measure out just the expectation values that I was talking about over here. And a quantum feedback loop goes to change our one parameter z here in the middle. So we use this kind of circuit to study this bond association. So what this is a picture of is if you take hydrogen atoms and you pull them apart, what's the energy? What's the resistance to this pulling? And we've studied it by that algorithm and buy another called Bayes estimation. What we found was that that feedback loop really gave us something to the tune of a some type of coherent error correction.

Speaker 3:          41:49          And we feel that the smoking gun for this was this plot that essentially took this problem. So this is the same problem, but I'm only plotting the errors now. Uh, and the green dots, whoops, the green dots here are if I took the exact solution of this problem. So it's relatively small at the moment, and I can check what the exact angle of that z in the middle of the circuit should have been the CIF data. And I plug this into my device, which if my device was perfect, then this is, I would have gotten the exact result. And what we found was these green dots instead. And then on the red is if you run this kind of variational feedback loop, you find that the error is dropped in some cases by over an order of magnitude and you get much better in consistent results across the curve.

Speaker 3:          42:35          And this is kind of indicative to us that it's coming back to fix these types of over rotation errors. Because if you want to rotate by some angle and you did it by data plus Delta, this is really just a labeling error in some regard. What you care about is the quantum state you've produced rather than the particular labels that you've given it at the end of the day. So this is our, our smoking gun for this type of a quantum error suppression. But we also wanted to look at kind of generalizations to this. Could we tackle incoherent errors? Could we look at other states? And one thing that, uh, you look to when you look classically if these types of problems, so I can value problems are defined in these linear spaces. And what we have here is instead of parameterization kind of explore something that looks a little bit nonlinear.

Speaker 3:          43:20          So if you imagine that this is my parameter space, this like gray manifold here, and I'm walking around that space, it looks curved. You know, similar to the way you might have a neural network parameterized by some weights or something like that. It's not exactly linear. So if you want to learn something about the distribution and you want to leverage the power of Linear Algebra that we've always used in quantum mechanics to tell us things like excited states, interior eigen values. Now other things, you want to cast this back into a linear space, but one that's relevant to the problem that you're interested in. So you can imagine that it might be possible to look at this point that you're at and expand, adjust around that particular point. Build a little flat plane where I can do my analysis, even though for that point, this is both one that I don't know much about and can't prepare classically, but I can build this little flat plane and learn something about the action of an operator within it.

Speaker 3:          44:13          So what I'm going to do to do that is I'm going to act this set of operators. I'll choose a set that determines my little flat space and I'll act the Hamiltonian on that because these are where the energy eigen values are coming from. And I'll probe with states also within that space. So this will tell me how any state within this little flat plain that I've built moves to another state within that space. And I'll do this to build a matrix representation of that, which will tell me how it acts on all of these states. Even though the states, I don't actually know exactly what they are. And moreover I have to build some representation of the identity, which is also the local metric. But in doing so, I build now an offline classical, generalized eigenvalue problem. So this is again a coupling between quantum and classical.

Speaker 3:          44:59          I've built some offline problem based on the measurements I took on my quantum device to kind of improve what I could've done without the classical computer. And this gives me some estimate of my excited state energies and also something a little more. So how does this look for a real problem kind of pictorially. So if you imagine that this is the curve that I got before, if my hydrogen bond breaking to him, I got it, uh, equally, well at each point on this curve, I'm going to do this expansion that I talked about. And this expansion only corresponds to extra measurements on my system. There's no additional coherence time required and it looks kind of like if my system went through this deep cohering channel over here and I prepare the state, then these expansion sometimes actually let me go outside the original set of states that I was able to prepare and I solve this problem and I get out these excited state energy and properties.

Speaker 3:          45:53          But what I also find is it because of that expansion outside this kind of cone that I'm allowed to occupy from decoherence, that I can sometimes improve the energies, even of my ground state and correct for some of these quote unquote incoherent errors that are in my system. And to see how this works, you can build a very simple one cubit example to do this. Um, so if I just make some one cubit Hamiltonian up and I imagine too characteristic errors. One is this side pure here, which corresponds to no matter what angle that I give this thing, it always gives me back the zero state. So it's a nonfunctional control essentially. And the other is my machine is so bad that it gives me back zero or one essentially randomly. And this is how you define these kinds of operators within this space. And I'm going to choose these sets of operators that build my little planes.

Speaker 3:          46:43          Uh, and the first one is the identity. So that's just the original algorithm. And then in the second set I'm going to include only bit flips. And then the third set are set to, as I'm calling it, you do essentially full tomography on this Cuban. And what you find if you look at the error and the lowest eigen value when you do this, you'll at the initial outset, so this is just the original unexpanded version. You have quite bad error. So this is logged 10 error in the lowest eigen value. If you add bit flips, you perfectly fixed this case of a nonfunctional control and you moderately fixed the mixed state error. And if you do full tomography, you correct both cases with just the measurements from the device. So we went out and we did an experiment based on this, uh, in collaboration with the Sidiki group at Berkeley.

Speaker 3:          47:30          And we found that if we did both that type of expansion, which I'm characterizing as like the linear response or lowest level expectations plus a few select ones from the next level. So a few to cubit flips as well. Then what you get out are much improved, uh, ground states and also the excited states. So the excited state curves are just the ones you get out from these extra measurements that you do. And I'll highlight that the yellow points down here with the larger error bars or the uncorrected values and the other ones with very small error bars or what you got as corrections to those. So improved both the energies and the spreads of the energies that we got out in the experiment. So we're very happy about this because we feel like it's evidence that for some problems there are application specific error correction modules, which you can consider building rather than a general purpose error correction.

Speaker 3:          48:20          And that quantum simulation might be a very fruitful area for working in this. So I want to just kind of close with slides saying this is an exciting time for quantum. Uh, this is just a short picture of all of the different companies and different groups and, uh, that have started to do research in this area. And if you looked at this list even save five or 10 years ago, it would have been not even a fraction of this list. It's taking off a dramatic speed. We're having more and more cubits every day that are better and more and more groups getting interested in our government is finally getting on board, assuming that the current administration doesn't, you know, mess things up. But, but I think it's an exciting time to be in this field, both on algorithmics and superconducting cubits. Um, I hope that I convinced you that there's at least one key problem we're really driving towards that we can work on for this.

Speaker 3:          49:11          And with that I'd like to, to just kind of recap the things that I've said, which are, if you go back, uh, what was quantum computing? Quantum computing was looking at these particles while they're in this state that requires interference and discrete energy levels. Asking what happens if we use those to simulate other particles and what happens if we build a computing abstraction on top of that. Can we do different or new interesting algorithms that look nothing like their classical counterpart? And we saw some examples of where that was true. For example, this linear solution of equations or this ability to propagate Ford chemistry problems in time. I hope I convinced you that in some ways coupling classical and quantum devices lets you do a little bit more than you would have just running on the quantum device at least for the short term. So we have very well developed classical computers and I think it's a mistake to cut them out of the problem entirely at the moment. And that we did this interesting expansion that I hope you're, you're excited about and that we're really moving towards real problems now that we have devices in the pipeline. I think we finally exited the time of quantum computing. When you imagine, you know, you work on algorithms with the MA in your imagination that no device will ever exist. Now's the time to work towards real problems and real applications and I think we're not that far away. So with that, I'd like to thank you all for listening and I'm happy to take any questions.

Speaker 5:          50:39          Thanks Sarah for the nice talk. Maybe a little addendum. I know you guys have been working on a new algorithm. Um, again, there's a spirit of a variation, a credit demogra Isms, but it uses, um, uh, well adapted basis, had songs that we have a chance of running it on one of the upcoming year term devices. Can you talk a little bit about that?

Speaker 3:          51:02          Yeah, definitely. So when I talked about originally the chemistry problem, I talked about how you cut that problem up much in the same way. If you wanted to draw a line on a computer you need to or ties it. So there's a lot of choices you can make in that regard. And um, some of the ones that we've made previously have just been, I guess I would say carry over were heritage from classical computing. And in fact some of those basic sets are so old, they were inspired by the need to do them with a hand crank calculator. And so the question comes as was that really the optimal way to slice it up, especially if now you're dealing with an entirely new type of computing technology. So some work that I'd been doing in collaboration with Ryan Babish here has said that they're in fact better basis sets.

Speaker 3:          51:43          It looked like these kind of plain wave dual basis sets. And we'll have the paper out on that soon, which make an interesting trade off. So the DIS discretization is perhaps a little bit less compact, but the circuit depth needed to run them as much is expected to be much, much smaller, almost linear in the system size. And so what that means is that if you have a device with a lot of cubits, but perhaps a modest gate depth available or a modest coherence time, then you have a really good chance of doing an early important problem with that architecture rather than one that focuses on compacting the cubits, but requires a very long run time. And I think that's got a good opportunity to be one of the first applications that runs on one of these real devices.

Speaker 2:          52:24          Okay.

Speaker 1:          52:25          So at the end here you mentioned, uh, the, your, your feeling that we shouldn't sort of cut classical computers out of the picture and we should develop some way of using classical computers and quantum computers together. So here at Google, a obviously one of our strengths is machine learning. And there are even some people at Google on the Google accelerated sciences team who are actively thinking about how they can use machine learning to accelerate, say, electronic structure calculations. So my question for you is, um, you know, do you think that there is any role that, say neural networks and sophisticated machine learning can play to accelerate, uh, quantum approaches to electronic structure? You, sir, any sort of interplay between say the variational algorithm and, you know, machine learning paradigms that might be interesting.

Speaker 3:          53:13          Yeah, so I think there's a lot of interplay that you get that can happen here. And one of the one interesting connection is of course that neural networks don't look so different from certain types of quantum circuits, but that's kind of a, a different topic than using a classical neural network to accelerate this type of computation. And so for example, some areas that I could see these, these being beneficial in is perhaps even choosing the basis set that you might be interested in. You might be able to learn what disc realizations are best for a particular problem. You might be able to optimize kind of the, the search procedure of this particular problem. So, for example, I did that subspace expansion at the end, which told me something about this, uh, this excited states that are nearby this ground state. So I can imagine that a neural network might be able to learn a different optimal set of operators, which corrects both for which not only looks at the excited states but also hopefully learn something about the errors in my real physical system. Cause if you can create just the right perturbations, you can reduce the air quite a bit in that particular model. So I think there's a wealth of unexplored areas as to how Quanah, uh, say classical machine learning could hook up to a real quantum experiment, especially ones with classical feedback loops in both kind of accelerate it and push it forward to new levels that we haven't seen before.

Speaker 1:          54:30          So I have a question about the cubits, the actual numbers. So you hear companies like IBM, they say they have 16 cubic computers yeah. In DYF has thousand cubic computers. I guess all cubits are not the same or how do these numbers compare?

Speaker 3:          54:43          Yeah. So there's a lot of important facts that you have to consider when you look at comparisons on number of cubits. In fact, I think IBM has even started, uh, proposing some metric that includes both the cubit number, uh, and their coherence time and the quality of operations that you can perform on it. I think they call it the quantum volume. Uh, so, and what that really captures is that it's important to look at a lot of other factors as well. For example, some machines don't have arbitrary couplings. So even if you wanted to solve certain problems on say the thousand or 2000 cubits that you have, you just cannot fit that problem into your device. And so it's important to look at both the co cubit number, the coherence time, their connectivity, and all of these other factors when comparing across the this regime. And I think by introducing something like quantum volume, I think IBM started a good trend in that regard. And we need more evaluations of that metric and developments on that metric and free people to actually report what that metric. So we can do comparisons to say this quantum device, you know, it outperforms this one in some meaningful way. So it's a good question.

Speaker 1:          55:49          Okay.

Speaker 6:          55:50          Slightly going a little further. A field here. Uh, I don't know if people are interested in this or not, but I was wondering, so, so there are all these like different interpretations of quantum mechanics, right? Which are sort of, as far as I know, they're all observationally the same that I've heard some people claim that maybe some of them aren't. Exactly. But for a first approximation there obvious observationally the same, right? So you've got the Copenhagen, you've got many worlds, you've got the wheel or transactional interpretation. I'm wondering is, is there one of these that sort of more fruitful, more perspicacious for thinking about quantum computing than the others? Is there as opposed to like just your personal preference, is there one that that you make progress better if you think of it that way?

Speaker 3:          56:35          So I have to admit that I'm not a leading expert on kind of what I would call quantum fundamentals or interpretations. And I know many people make arguments in terms of say the many worlds theory for you know, the super position overall inputs and you need all of the many worlds to come together and agree in just the right way. I personally haven't really delved deeply into which interpretations aid in the kind of development of algorithms. I've always, I guess prescribed to this Copenhagen argument that, you know, you can build a model that predicts how the hands on a clock move, but that might not tell you anything about how the gears are constructed behind it. So I, yeah, I don't think I have a great answer for your question

Speaker 6:          57:15          because I mean it sounds like you were saying with this Scott Aaronson cartoon, right? So, so the, the idea that, that, that these things are massively parallel. It's not exactly right, but it's not exactly wrong. Yeah, that's right. Yeah. And the, the mini worlds kind of Wa it seems like it's the natural way of, of thinking of it as parallel, but maybe it makes it too easy to think of it as bad. I don't know.

Speaker 3:          57:37          Yeah. It's certainly, well, the many worlds is certainly the most exciting from a science fiction standpoint. I've always liked it for that reason, but in terms of interpretation, I agree that it has many appealing aspects, at least in terms of computations agreeing, but it's hard as to like the specifics of your question. I've never found one more helpful than the other for constructing an algorithm. Okay, sure.