Speaker 1:          00:06          I assume since you're here, uh, that most of you know who I am, but just for a little bit of context setting, I am going to talk a little bit about the background of my company and why that's relevant. Because the book that I've written a is a combination of a memoir about my time in the technology industry, a business book, and an economic call to action now on the economics. How was my thesis advisor? Uh, the book was, it was, it was, uh, uh, really, uh, uh, uh, I don't really know that much about economics, although a couple of people said, well, but your instincts are good. Uh, but how, uh, corrected my instincts in many, many cases, uh, but any errors in the economics portions are not house responsibility, but he definitely would, it would read a passage he read multiple times and he would say, no, you have to go read this paper.

Speaker 1:          00:58          Oh, you have to go read this paper. Oh, you have to read, go read this paper. It was a wonderful education and, uh, I hope to continue it as I go further down this path. Anyway, so I'm the founder and CEO of O'reilly media. Uh, you know, most of you probably maybe first, uh, new of us, uh, as a publisher of the iconic animal books. This book now, I think it's still in its sixth edition, VI and Van, the first edition was in 1985 was one of the first books I ever published. Uh, I think it was in an addition of 100 copies a, it's gone on to sell probably a million copies since then. It's still in print. Uh, you know, however many years later, 32 years later. Uh, but you know, we continue to be a publisher with this. Here's a book that we did recently with Google on site reliability engineering, another book on, on a hands on machine learning with psychic learn and tensor flow.

Speaker 1:          01:50          You know, these are kind of the thing that a lot of people in the computer industry learned of us from. It's now only about 20% of our business. Uh, but the thing I'm kind of the proudest of is the role that I've had in spreading big ideas about where the industry is going and what it ought to do. Um, so very early in the nineties, uh, my company created the first commercial website, the site called the global network navigator was sort of before Yahoo. It was the first web portal. It was also the first, uh, advertising supported site on the worldwide web. The Internet was still noncommercial and did a lot of activism for, uh, uh, the commercial internet and, uh, also for the open commercial internet in the very early days. For those of you who weren't around then the Internet was a research network. And I still remember a conversation I had with Steve Wolff, who at the time was the NSF overseer, National Science Foundation, overseer of the Internet.

Speaker 1:          02:47          And he said, uh, I said, well, here's what we're planning on doing. We're going to build this website and they will have ads. But the thing that's different about the web is that people come to you. So we're not going to be sending out anything unless people ask for it. So it's very different. And he said, well, you know, the Internet is about research and education and if you guys aren't research and education, I don't know who is, so go for it. And it was a wonderful moment. Anyway, later I organized a meeting where the term open source software was, it was widely adopted and promoted it and particularly told a story about it that was bigger than the political movement about free software, a being against Microsoft by bringing in the story of why the Internet was also built on top of open source software.

Speaker 1:          03:31          And that was probably my first experience of the power of ideas to change people's minds. You know, I remember when I first, I held this press conference at the end of this day that came to be called the open source summit. And I had all these guys up on a stage and people who nobody had ever heard of, uh, most of them, you know, and, and the story I told was so different, you know, which had been this story of free software is this rebel movement that wants to bring down commercial software. Commercial software is evil. And I said, hey, you know, if you guys have uh, you know, are on the internet and you have a domain name, yeah. You from the New York Times, you from the Wall Street Journal or whatever, you know, this guy over here, Paul Vicksey wrote the software and gave it away so that that domain name, uh, you know, it can be recognized.

Speaker 1:          04:19          Uh, oh, if you send email, this Guy Eric Almont wrote, send mail the program that routes at that point about 70% of all the email on the Internet, Oh, if you have a website is probably a patchy. This guy, Brian Behlendorf started that. So it kind of, and it was interesting because I did about two weeks worth of interviews and in the beginning what the Internet is based on free software. And it was this disbelief and it felt a little bit like you're trying to push, you know, something really heavy and it doesn't move and then it starts to move. And within two weeks it was just the accepted wisdom and that, uh, in in a way is a backdrop to the story of the book because I'm trying to change the accepted wisdom again with this book. So I did it again with web two. Dot. O uh, which is really the story for me of what came back after the s the.com bust.

Speaker 1:          05:07          What was the second coming of the web? And they come to the conclusion from thinking about open source in a very different way than other people had that uh, the west, something very different about the companies that survived. And of course this led me down the path that we're really moving out of the world of, uh, that we knew in the PC era where software was an artifact to where software was increasingly a business process that is, were these vast cloud applications that actually had people inside of them. And that data was going to be the source of competitive advantage. And that was the heart of what I talked about. Web Two. Dot. Oh, we also launched something called the maker Movement with a magazine in 2004 called make and maker faire. I spent a lot of time in the last seven or eight years talking about how government also needs to learn about platforms from the technology industry.

Speaker 1:          05:57          And most recently I've been talking a lot in the same way about how to think differently about AI and what I called the next economy. It's a technology and the future of work. So we also, you know, a big part of our business today or conferences we just had last week, the O'Reilly Ai Conference this week in New York, this strata of the business of data. We doing a conference on Jupiter. We've, our original very first conference started in [inaudible] 97, the O'Reilly open source software summit. We run makerfair, uh, something called bootcamp, which Hal talked about, which is an unconference. And then we have a platform of our own, which we started in 2000, uh, it's called Safari was originally an ebook platform, but it's increasingly a platform. Uh, yes, 40,000 plus Ebooks, tens of thousands of hours of video training, live training, millions of customers. It's really a platform for knowledge exchange.

Speaker 1:          06:47          And that's really the heart of our business. We're about 20% books, 30% events, and 50% this, this online learning platform. So I spent a lot of time thinking about platforms because that really is the heart of my business. And I think that Google also obviously is a platform company, but I want to spend a lot of time, I spend a lot of time in the book thinking about digital platforms and what they teach us about economies. I said, I'm going to come back to that. So the title of the Book Wtf, you know, uh, now I actually use this and the White House frontiers conference and I was really proud that I got the White House comms team to sign off on a talk called WTF. Uh, but I, and I did it by kind of saying, well, it's stands for what's the future of course. But really the reason why I wanted to use the term WTF is because it's a term of astonishment that can be the astonishment of delight or the astonishment of dismay.

Speaker 1:          07:43          And I think that really encapsulates the state of our dialogue about technology today is this source of enormous astonishment and wonder. And it is also a source of fear. And I started worrying about this, uh, probably two or three years ago, I started a, an event called the next economy summit because I was trying to get ahead of this issue. How do we think about technology and the economy? How do we get technologists to think about it and to talk about it in a way that doesn't make people afraid? How do we get business plans that are focused on empowering people and building wealth for everyone rather than simply, well, we're just going to disrupt, you know, we're going to break things. You know, we're going to make ourselves really, really rich and we're not gonna really worry about what happens to everybody else. And that's how the rest of the world is starting to see Silicon Valley.

Speaker 1:          08:38          And a lot of ways the book is an attempt to address that narrative head on and to change it. Uh, and, and to change it by actually inspiring, uh, software developers and entrepreneurs to act differently, to talk differently, but also to persuade policy makers to think and act differently. So I'm going to try to give you a few sampling of some of the ideas from the book anyway, back to this WTF of amazement or dismay. This is the world of techno optimism that we all live in. That's a chart of life expectancy, life expectancy at birth, pretty much flat. I mean, there's a few really bad times you can kind of see where it really dropped, but then suddenly this magical thing happened in the mid 18 hundreds when it started to climb. And then you see additional countries sort of come on stream. This is the modern world that we have every reason to be so proud of, you know, that we, you know, there's a wonderful site, our world and data, which is really, it's this incredible collection of graphs and narratives about the way that technology is making the world better.

Speaker 1:          09:46          I'm standing in front of this, sorry about that guys. Um, so I guess I'll be back over here. Uh, so, you know, but everyone is not equally happy. We see all Brett's Brexit, the rise of Trump. And here's, here's this WTF, you know, on the Daily Telegraph, you know, um, and you know, the question is this is not the first time when we have had this kind of upset and worry about technology. This is a, you know, an etching about the luddite rebellion. Now, one of the things I learned that many of you may not know is that Ned Lud did not actually exist. Uh, he, he was not the leader of the Luddites. He was a mythical figure that this particular revolution in 18, 11, 18, 12 cited. He was somebody who had apparently had smashed Allume 30 years before. And it went down his story and they kind of carried the banner of Ned Lud.

Speaker 1:          10:36          Uh, but here's the point. These guys were right to be afraid because the ensuing years were pretty bad. You know, and you think about the early years of the industrial revolution and, uh, you know, William Blake's description of the dark satanic mills, uh, you know, this was not a good time, but you know, those weavers could not imagine the wealth of modern society. They couldn't imagine that their descendants would, you know, this production is mass production of fabric, you know, would produce a world in which their grandchildren and great grandchildren would have more clothing than the kings and Queens of Europe. Did, you know, the turn of the 18th century or the 19th century rather, you know, they couldn't imagine, you know, their descendants would have, you know, fruit in the middle of winter. They couldn't imagine that we would actually build skyscrapers half a mile high. That we dig a tunnel under the English Channel to France, that we'd go into space, that we'd fly through the air.

Speaker 1:          11:42          All these things are amazing and they couldn't imagine that their descendants would find so much meaningful work bringing all these things to life. And so one of the questions I'm asking in the face of today's world of AI and all of these new technologies that were being told again, again, are going to destroy jobs. What does our failure of imagination, what are we not able to imagine and what world are we not able to paint for our grandchildren of the world to come? And so, you know, one of the things that I start the book with is a little excursion into this idea of fitness landscapes. Now, you know, in evolutionary biology is this idea that genes contribute to survival and organism, that you can think about this as kind of a landscape of peaks and valleys and organisms evolve towards the peaks which are adapted to their environment or they die out.

Speaker 1:          12:36          And so there's this concept of a local maximum. And you know, a lot of what happens is society and companies get comfortable with this local maximum and they don't know how to move on. And often the only way to move off of it is actually to go backwards. You know, you have to go down. And that's why we have this cycle sometimes of, of revolutions of, of, you know, companies you know, fall apart anyway. But, uh, you know, fitness landscapes are, you know, dynamic. You know, when conditions are stable, you can kind of just stay there. But if things are changing, uh, not, not so, so good. And of course we have, uh, you know, radically changing conditions. You know, climate change is a great example. If you look at the failure of many civilizations in the past, they were driven by climate change. We may face a great deal of pressure on our fitness landscape today as a result of that.

Speaker 1:          13:28          Uh, and technology also as a fitness landscape, you know, uh, you know, in my career I watched, you know, this fitness landscape of the personal computer, uh, you know, the big data and AI world, uh, that, that, you know, Google lives in the smartphone, a landscape dominated. That was, yes, a really broken open by apple and now it was sort of a subject of fierce competition between Google and apple. And you know, what's really interesting and when you think about what happened, why was it hard for Microsoft to get to the big data world? Well, they had too much, you know, this is a perfect illustration of the fitness landscape. They had a business model that really worked for them and they fought. Yeah. There were people who were saying, no, we got to get with the Internet. And they were kind of like, no, we have to preserve windows.

Speaker 1:          14:14          And that was their priority. And I think it's something that we always have to, to uh, to think about the, this. Dot. The dominant companies tend to be slow to adapt. So, um, you know, the, the thing is that one of the problems is that those dominant companies tend to extract too much of the value from the ecosystem for themselves. You know, Microsoft basically put other companies out of business. They would come down to silicon valley, meet with vcs and say, you can't invest there because we're going to do that. Uh, and, and this is a real risk, I think for Google as well. You know, it, it, it's really, I think a mistake to think, uh, just value for users, you know, because Google will make a case what we're doing this thing and it's better for our customers. But you actually have to think about the whole ecosystem.

Speaker 1:          15:04          And in particular, you have to think about the ecosystem of developers. You know, the people you know, went to Lennox and the worldwide web because there was no room left in the Microsoft ecosystem. So they went somewhere, they didn't think they were going to go make a lot of money over on the web. They just went, this is cool, this is interesting. And it's free and open. And, and that sort of free and open was what gave birth to the new fitness landscape. You know, the, the, the small mammals coming out from the valleys into this new fitness peak. So again, it's always something to worry about if you're as dominant as Google, uh, is, is to think about, you know, are we making enough value for these developers who are part of our ecosystem, these people who are creating on top of our platform and making it a rich, stable ecosystem?

Speaker 1:          15:48          Or are we basically saying, no, no, we're, you know, we, we have to do that for ourselves. You know, I had that experience many times with Microsoft, you know, it's like, oh, that's a great idea. We have to do that. Sorry. Uh, so in our, in our political landscape, we're seeing this same thing. You know, we've had this idea that by making a small number of people very, very, very wealthy, uh, it would trickle down to the rest of the society has an entirely work that way. And guess what, you know, the people are moving somewhere else. They're saying, we don't like that consensus about how to run the world. Uh, we're going to do it differently. They may even be wrong. And maybe, you know, well, not in my opinion, I even a May, but, uh, you know, uh, uh, there's a real serious risk that the conditions that we have know that we silicon valley have used to thrive, are going to change radically because of the political environment.

Speaker 1:          16:46          And so, you know, one of the key pieces of advice I give him my book is, is just to remember the successful ecosystem creates opportunity for everyone. And, and this obviously was brought into the, you know, the political discourse by Thomas Piketty's book capital in the 21st century where he really addressed this question of inequality and got everybody talking about it. There had been other people, you know, Joe Stieglitz had written about the 99% versus the 1% before picket aid come out. But, and that, that almost caught, but you know, you know, when [inaudible] book came out, it was like everybody started talking about it. And so I decided to take a technological angle on all of this to kind of tell the story from the point of view of the tech industry. Because a lot of people talking about it as economists and I was so in a lot of ways, the heart of the book is, is a series of stories about what the great technology platforms have to tell us about the future of business and the economy.

Speaker 1:          17:45          And the first is this point I've already made. The platforms have to work for all of their participants, not just for the users or the platform owner is also the point that platforms today are no longer just about the digital right there in mashed in the real world. You know, you think about Uber or Lyft, you know, this is really this system. You think about this huge algorithmic system. And sure, there are people at the end points of all the touch points of Google. You know, people are uploading youtube videos or they're clicking on links are there, they're submit, you know, creating webpages. But boy, it becomes really obvious that human beings are a, as this, uh, Sean McMullan, the science fiction authors are our souls in the great machine. You know, when you have these cars dispatched by algorithm with drivers, you have the swarming marketplace where people are doing things in the, in the real world.

Speaker 1:          18:41          You're at the Beck and call of algorithms. So, uh, so, you know, we have to start thinking about, you know, this interpenetration of the digital into all of our business processes, into all of our world. Uh, you know, as, uh, as we effectively take the principles that we've been practicing in the purely digital realm for, uh, the last couple of decades and start to see them show up everywhere in the real world. So it becomes even more important. And the third key point is that the fundamental function of every technology is that it augments people so they can do things that were previously impossible. You know, we couldn't fly through the air and now we can. And so when you think about, you know, what AI is going to do, there's a strong narrative that it's going to put people out of work. And instead, I think the narrative, we need to be seeking out the narrative of what will it let us do that we can't do today, that will be wonderful, that will make us full of that WTF of delight.

Speaker 1:          19:48          And we have to tell that story powerfully and we have to believe it. And we have to build products and startups that deliver on that promise. So, um, you know, and there is kind of this interesting thing that of course the WTF of delight becomes banal. I still remember once, uh, landing in Sydney airport in Australia and they had this giant mural, and I wish I could find the name of the photographer because it's long gone now. But it was thousands of people turned out to see the first airplane come to Australia, you know, and it was just this, these faces looking up in wonder. He has been a voyage of, you know, many months, you know, for many of, you know, people that emigrate and then it's like they're connected to the world and it's like, oh my God. And now you think about, you know, Airlines, oh my God, you know, you know, so the WTF of wonder actually later became the WTF of dismay and we have to watch out for that.

Speaker 1:          20:43          But the, um, uh, you know, that, that source of wonder is so important, but this idea of augmentation, let me kind of come back to Uber and Lyft. You know, when you think about that experience, there's a couple of things. The first is this magical experience, which goes away because you get used to it. Wow, I can, you know, I don't have to call a taxi company and hope they show up. I don't have to stand out on the street corner and wave another all full. Or there's nobody there. I can summon a car, I get an estimate of when it's going to be there and I walk out and it just comes magic, you know, realizing the capability that was hidden in our phones, uh, to, to match people in a real time matching marketplace. Right? But also, and this is one of the things a lot of people don't understand about Uber and Lyft, you know, it's like taxi companies go, well we have to have an APP, but we hate this idea of part time drivers who just, you know, show up and don't have licenses.

Speaker 1:          21:43          And you go, well guess what? All the parts of that business model work together. Uh, because it's because you have those part time drivers that you can have three minute pickup times, uh, all of the time. You don't run out of cabs, right? Cause they're harnessing the marketplace in this new algorithmic way. And the reason they can do that is because the drivers are augmented with this new cognitive augmentation called Google maps or ways or you know, it's built now into, into the APP. You know, it's like people don't have to have the knowledge of the streets and monuments of London. They can just turn on the APP and it says, turn right here. Right. And you know, the, the, literally the knowledge is a test where you are a human gps. You're like a men tat out of Frank Herbert's Dune. You know, where you literally, they give you two points in London and you have to recite the turn by turn to get from one to the other.

Speaker 1:          22:34          And you know, now you don't have to do that. So that, that cognitive augmentation also is going to make new things possible. Just like the steam shovel or the, you know, steel girder or the steel beam in the physical world. Cognitive augmentation allows people to do new things that they couldn't do before. So, um, I also talk a lot about the fact that these systems are algorithmic systems, at least today infused with AI, but these algorithmic systems have a sort of a fitness function or an objective function. And I want to talk about that in the context of the economy in a bit because I think the real, uh, Israel's significance for society, the economy and the future of the human race in the algorithms that we are building into our future. Then we're going to talk about that in a minute. So there's a bunch of my writing on the topic of it's not in the book.

Speaker 1:          23:21          You can find out the site WTF, economy.com as well as some content that's in the book anyway and come back to this notion of platform must create more value than it captures. And that's been, uh, kind of the heart of what we try to do it or Riley, um, uh, you know, we invited in our biggest competitors into our platform when we launched it. We continue to think about how do we make money for them as well as for us. Uh, and I think Google should, I, I've loved what Hal has done with the Google economic impact reports because it's starting to tell a story which should be told by every business in America, every business in the world, which is how are we creating value for other people, for others, not just for ourselves, all of his financial reporting. That's just about, wow, look how well we're doing.

Speaker 1:          24:09          Great. I go, well, how, you know, there are companies that are doing well by making other people do badly and we have to actually have a system wide accounting of what people are putting in and what they're taking out. In the alternative, if you are a Google like company where you are a systematic platform companies, you'd become a regulated utility because if people say, wow, you are not uh, you know, looking after your ecosystem, well we'll look after it for you. So I think that's something you guys should be very worried about weight. I want to kind of come back, I've talked about a lot of this already, but this is something that out of the book, this notion of a, I call a business model map business model is the way that all the parts of a business work together to create customer value.

Speaker 1:          24:57          And uh, I first was introduced to this concept by some consultants called Dan Meredith being back in 2000. And they actually used the example of southwest airlines versus hub and spoke airlines. And they kind of went through how all the parts of, of southwest, uh, business actually make them very different than the other airlines, even though they're all in the airline business, you know, so they don't forward baggage. They don't have assigned seats. This actually is different. And so Google and Facebook, both in the advertising business, but you have very different parts of your business model. So for example, uh, with, with Google, right? Somebody, your customer succeeds when they come to Google, get what they want and go away, right? So your success is aligned with people leaving Google coming and leaving Facebook. Success is aligned with having people come and stay. And that's a huge difference in your business model and a huge lever if you are competing with Facebook for example, because you have to say, Oh wow, we have to find more reasons to get people to go away and not to get people to come and stay with us because then you're, you're, you're playing on Facebook's uh, uh, you know, turf.

Speaker 1:          26:10          And as Sun Tzu says, attack your enemy where he is strong and you are weak. I mean, we're here as weekend. You are strong. So anyway, back to this, I tried to draw a model of Uber because it seemed to me to be a kind of a, uh, a kind of a template for what starting to happen in the economy. You know, you have these companies that are platforms, they're not just sort of traditional companies, you know, they're replacing ownership with access, you know, and they've got this, this marketplace managed by an algorithm, you know, with passengers matching up passengers and drivers. And there's a bunch of things, know workers supplying their own cars, independent contractors, you know, that are really part of this, uh, you know, this story. And, uh, you know, this augmented workers idea that we talked about magical x user experience. So all of these things go together.

Speaker 1:          26:59          And one of the things we have to understand this, we think about technology and the economy is what things go together in our business model. What things belong and what things to fight against it. And so, for example, at a Riley, one of the things that we've, you know, realized that made us able to transition from being a publishing company to be a conference company in an online learning company, was that we realized we were, we were really a company that was about connecting people who knew something with people who wanted to learn it from them. And so we were able to evolve how we did that because we really understood that. Whereas a lot of our competitors, uh, you know, most of them no longer really in the business very much. They just thought their job was to capture knowledge into books and put it on shelves.

Speaker 1:          27:44          So anyway, so, uh, I, you know, I spent some time really trying to think through business models and how they work and how the changing in the age of the platform. Uh, I've talked a little bit about this thick marketplace idea. A house, uh, uh, student Jonathan Hall, who's the chief economist at Uber turned me onto this book. Alvin Roth. So who gets what and why, uh, which is really about, uh, you know, how do you make a successful matching marketplace, which is at the heart of so many of the great platforms today. And so that kind of led me to this, you know, this path of, of, of thinking about marketplaces. But then again, I talked about this augmented in a worker concept, but this is a really key part of it. Uh, and that is really something I call the arc of knowledge. You know, when we think about how do we communicate knowledge, we first, you know, we, we, we spoke it to each other and then we wrote it down, you know, things like maps and, and you thinking about the first iterations of online maps and they were kind of reproductions of printed maps just online, which was kind of Nice.

Speaker 1:          28:49          And then you got maps and directions and you go all the way up to automated vehicles and you see that the knowledge disappears into a service. And that's, it seems to me to be a key point to remember when you think about how are we augmenting workers, we're basically building these cognitive augmentations that will just disappear in the services where you don't necessarily need to know in advance things, you know, this is already so true. You know, we were talking over lunch about how, oh yeah, yeah. Some technique. How do you learn it? You go to youtube and you watch the video and before long maybe we will be in the place like trinity in the Matrix where we can say, I need to know how to fly a helicopter. And I remember she downloads the knowledge, you know, but even without that, we're going to have these augmented devices that capture and share human knowledge.

Speaker 1:          29:37          So when I think about, you know, AI, that's my starting point is that it's a tool for human augmentation. It isn't this radical in a discontinuity. You know, this machine from the future that's going to make humans obsolete any more than, you know, uh, machines in our, of the industrial era were somehow going to make humans obsolete, you know? Sure. Yeah. We're not as strong probably as most of our, uh, you know, uh, even if we work out a lot, we're probably not as strong or as fit as, as someone who worked every day on the farm or doing, you know, prayer work. I still remember going to Hawaii once and huffing and puffing up over some hill and it was like, oh yeah, the ancient Hawaiians took him about 20 minutes to open over to the other, you know, waterfall and we took us two hours, you know, um, yeah, you know, we're not, you know, as fit, but we are more capable if you've ever read guns, germs and steel, you know, it opens through this wonderful passage yet Yalies question, you know, guy in, in, in New Guinea saying, you know, you guys are so stupid.

Speaker 1:          30:39          You know, if I took you in the jungle he'd be dead in two weeks. I'll come. You have all the cargo. Yeah. And you know, and that is in fact the question of our civilization. You know, it's like we are making, you know, a ourselves smarter, stronger, faster, better. And that should be how we frame and how we think about what we're doing with technology. It's not disruptive. It's not destroyed. It's not eliminate, it's empower, it's lift up, its make things possible. So, you know, technology is our superpower. You know, and this is another one of the charts from, um, you know, our world and data of, uh, you know, the number of people in the world living in absolute poverty and you wash that incredibly steep decline and that's wonderful. But inequality is our Kryptonite. And we have, you know, this is a, you know, from the, we are the 99% story we have to confront that.

Speaker 1:          31:29          We have to think about it as a, particularly as a, as a society, but also as an industry. So one of my interesting questions, uh, is, uh, that I tried to explore in the book is what keeps us from creating prosperity for everyone. And here's the answer. And this is the connected taxicab circuit. 2005. Uh, you know, it's like, wow, we had connected taxicabs. What'd we do? We put a screen in the back where people could look up information where they can watch ads, you know, and we totally missed, you know, even though actually Sunil Paul in 2000 had written a series of patents about what would be possible, uh, if you, you know, you tried to connect, you know, cars with smartphones and it actually, they weren't really even smartphones, but with gps and phones, it was just too early, right? So there was this sort of cognitive filter, this cognitive blindness, you know, you kill actually sort of framing blindness, maybe the right way to sit where we framed the world in a particular way and we couldn't see what was possible.

Speaker 1:          32:35          And I think this is a critical problem. And I've watched it throughout my career. You know, when I, in 2000 I had to lead this a protest against, uh, uh, Jeff Bezos is one click patent. And we went and we looked, uh, you know, Jeff kind of worked with me to try to, uh, you know, turn it around from a PR point of view. I, one of the things we did was we, we started a us, we funded a startup called bounty quest, which looked for prior art on, you know, one click shopping and we couldn't find it because basically it was sort of unthinkable of the time people were afraid to put their credit cards online and they had the Shah, the shopping cart metaphor, they kind of understood the world. It was very much like this connecting taxi cab circa 2005. So I, the reason I tell you that story actually, and then here's another one.

Speaker 1:          33:21          You know, it's like I asked Tony Fidel, why didn't, you know, uh, you guys do the connected speaker and he says, well, can you imagine, you know, if, if, uh, people had had thought Google is listening to me, you know, somebody had to make that possible first. You know, because there was just this, you know, because of Google's particular position in the market, you couldn't be the first mover, but you still have to understand that these cognitive shifts do happen where people believe that something else is possible. But more than that, I want to actually take that thinking to the political and the economic realm. And this is where I start to get out of my depth in the book and, but uh, but I, I, this is maybe it's just a thought experiment, but maybe just maybe it's something that's really worth thinking about. And this is the beginning of, of actually an argument that runs through a central section of the book and it's about sort of AI and algorithmic systems and their relationship to human society.

Speaker 1:          34:19          And I asked the question, you know, what is strong AI bears the same relationship to today's narrow AI as multicellular life does to a single celled forebears. Now, right now we keep thinking that we're going to create a strong AI. Maybe, you know, maybe it will be 1520 years from now, maybe 50 maybe it will be a hundred but it will be like us, you know, a single self aware being. And, you know, I wonder if instead, you know, it's a collective being, and it turns out that that is what happened in this prokaryotic to eukaryotic cell transition because it turns out that this is thing that Lynn Margulis in 1967 actually it was, I think it was originally in, in, uh, uh, again, uh, constant and marriage choskey in 2019 oh five at first proposed it, but she picked it up at 67 and it actually proved it over, uh, you know, a lot of years of being ridiculed and pushed back.

Speaker 1:          35:16          And it was this idea that, uh, that multicell organisms actually incorporated bacteria into them. You know, so it turns out it was latest substantiated by genetic evidence that Mitochondria in our body are actually bacteria that came and lived inside of us. Right? Uh, same thing with chloroplasts in plants. They're there. They have totally different genetic material than the nucleus of the cell. And so in a similar way, I started thinking, well, what if we are somehow like that with our computers? And of course, biological symbiosis doesn't start with that. Symbio Genesis that Lynn Margo was talked about this also this increasing knowledge of the microbiome, how we are really a colony organism. Ed Young in his wonderful book I contain multitudes, has all zoology, is really ecology. You know, when we look at beetles and elephants, sea urchins and earthworms parents and friends, we see individuals, you know, uh, driven by a single brain and operating with a single genome.

Speaker 1:          36:18          And this is a pleasant fiction. You know, we're legion, you know, he says he'd Walt Whitman, I am large. I contain multitudes. So think about this in humans too. You know, when we talk about, uh, you know, unsupervised learning as the holy grail of Ai, I go, yeah, you know, humans have some amount of unsupervised learning. We have a shit ton of supervised learning. You know, we learn our language from our parents. Uh, everything we, you know, we know that makes us able to, you know, to do the kinds of things that we do here at Google. We were taught by somebody. And then on top of that, yes, we're able to do unsupervised learning, but we have a long way to go. Uh, you know, I think in, in the supervised learning of this new organism before we can kind of even expect to see it start to do on supervised.

Speaker 1:          37:03          Not like you start necessarily there, but, um, you know, so, so thinking about this as a metaphor, I started thinking about, I've been really thinking about this for the last, you know, 10, 15 years, you know, how increasingly we're, all, all of humanity is being woven into this new global mind, the Super Ai, you know, and we're seeing in things like fake news, kind of the equivalent of our neuroses, you know, the equivalent of, of, uh, of, of bad ideas, you know, the spread incredibly quickly now and are adopted by, you know, millions of people and then encoded further into the systems that we build. You know, so we're this really interesting phase of symbiosis and we have to come and understand it. And, uh, so, and we think that our emergent Prodo AI's are also compound being. It's just like, we are, what would we do differently?

Speaker 1:          37:57          How would we think about them and what do we know about them today? And, uh, you know, there's a lot of fear of some kind of future hostile AI. And I go, well, if there is one, we are already training it. We already teaching it and what are we teaching it? So, you know, when you think about this further, you know, we, we're seeing, you know, this compound being, you know, this, we see the rise of specialized chips, which actually, uh, you know, is actually a pretty interesting imitation of neuroscience. But here it is a great one. You're here. Here's one of the, uh, you know, the Mitochondria inside the Google brain, right? Uh, and, uh, you know, it, here's this thing we've even defined in our legal system starting in 1888 we said that there's this thing called a corporate person. It's really just this collective organism that was the case called consolidated silver mining versus Pennsylvania.

Speaker 1:          38:51          It's like under the designation of person. There's no doubt that a private corporation is included in the 14th amendment, such corporations, Emilia associations of individuals who United for special purpose, right? So, you know, special purpose organism, you know, and guess what, we now have these special purposes of organisms are increasingly digital, increasingly quick, increasingly algorithmic. We're making these special purpose organisms. Uh, uh, and, and what are we asking them to do? And I believe that one of the things that we have to come to grips with is that in some ways these ais, that our children are already ruling human society. And we have to ask ourselves, what is the motivation of this new species? And this is obviously, you know, kind of out there, but think about it, you know, how does Google decide what it's going to do? Well, we actually, we collectively, you know, starting with Larry and Sergei and, uh, you know, all the early founders, but people like Hal and all of you have actually put thoughts into this, you know, shared Google brain, you've trained that, you've taught it and you've taught it that it should optimize for relevance.

Speaker 1:          40:04          And this is this sort of master organizing, objective function of everything that Google does, whether it's in search or advertising, it's like find the thing that people are looking for. So you've kind of built this special purpose organism that has, you know, these, these goals built into it, baked into it. And those goals actually now exist independently of any of the people who created it. Like again, they, they, they will, you know, it will die just like, uh, you know, uh, you know, a biological organism will die under certain conditions, but it doesn't actually depend on any individual cells to remain. You know, we've all been told that our bodies can completely recycle the completely different cells. Uh, yeah, every seven years I think it is. And, you know, same thing, all the people can cycle out and this organism would continue with the same programming, with this continually adapting program.

Speaker 1:          40:59          So think about that. So Google relevance, Facebook engagement, and we saw with Facebook and fake news how that can go wrong, you know, and it basically reminds me, I guess, a of the story of Mickey Mouse in the broomsticks. And fantasia, you know, I mean, all of these systems, we tell them what to do when we set them going and they do what we told them to do, but we don't necessarily quite understand it. And this is the story that comes out again and again in Arabian mythology, you know, with genies and uh, you know, you, you told them, uh, this is actually an illustration by Edmund Dulac from the thousand and one nights. Uh, but it's sort of a rising of great power, but what's it going to do is going to do what we told it. But we made, we didn't understand and we didn't tell it quite right.

Speaker 1:          41:44          Mark thought that by building this social platform that was focused on engagement and you know, he would build real community and then he found instead that we've created this monster, which he is now trying to bring back under control. You know, that's actually part of the experience. So, uh, many years ago, a friend of mine said to me, this is in the early days of mackintosh programming. He said, the art of debugging is figuring out what you really told you programmed to do rather than what you thought you told it to do. And we are right now engaged in that process with these, these new digital gin that we have created. We are saying, are they doing what we meant? Are we doing? Are they doing, you know what we told them to do? But it wasn't quite what we had asked. And how do we fix that? That's what you do every day at Google.

Speaker 1:          42:32          You try to actually go, yes, is it doing what we really meant it to do? And now my question is, are we doing that same thing in our broader society? You know, because here's the data that we see that is at the heart of this economic unease that we're facing, which is that this wonderful gift, the WTF of amazement is that productivity has continued to go up. You know, if you look, this is from 1945 up through 2015 is pretty, my God, it's a graph that ray Kurzweil would be proud of. It's just up until the right, right? And then you see this divergence starting around 1970s, a real family income. Somehow that productivity was not getting through, not being distributed to ordinary people. Now it's a lot of reasons why that may have gone wrong is you know, people like Hal study this, uh, and, and, and his, his, his, uh, his ill cause is what economists do.

Speaker 1:          43:31          Uh, and I'm not saying what I'm proposing is the only cause, but I think it is one of them. And that is this, here's another one of these ais, these pro ais, you know, that we tell it what to do and is it really doing what we think and this is the Equinix and why for data center, which is sort of one of the hearts of the, of our financial trading system. And this is kind of the skynet of the story because ultimately we told these are financial system what its objective function should be. Milton Friedman in 1970 wrote an article in the New York Times called the social responsibility of business is to increase its profits. The businesses should not think about anything other than that. And if they did that, they would pass along the profits to the shareholders and the shareholders could make up their own mind.

Speaker 1:          44:26          This is a perfectly reasonable thesis, just like some of the theses that you put into your code. But when you build code and you watch it, you do, you actually do that debugging process. You say, did it do what I asked it to do? And we have to ask ourselves when we said, you know, optimize for share price, you know, in particular optimized for profits and the profits. This proxy is the share price of companies optimize for that, not for people, you know? Yeah. If it makes sense, you know, outsourced to factories. If it makes sense. Got that community, you know, because you know, your, your master fitness function, the thing that we, the wish that we expressed to the genie we built was make my share price go up. And uh, you know, this is actually, there are a lot of people in the financial industry who are starting to take note of this.

Speaker 1:          45:19          I mean, you know, uh, Larry Fink, who runs blackrock, the largest asset manager in the world, has been railing about stock buy backs, uh, Warren Buffet questioning. And then there's a number of books. This one makers and takers is really good other than the golden passport about how Harvard business school kind of wreck the economy. But, so this idea that the financial markets, which are really meant to support the human economy and become this extractive platform that basically says, no, no, no, gives the money to us. You know? And, and we have to actually reverse that. And that's what I want to come back to this story about the, a little screen in the back of the taxi cab and the failure of imagination because it's very hard for us to imagine a completely different world, you know, so when we talk about tax reform will, it's like, we'll push this rate up in that rate down.

Speaker 1:          46:12          You know, that's not how it happens. The great revolutions are ones where you really imagined the world in new. And we're good at that in technology and we think about that all the time. And we need to do it also in the world of politics and the economy. And we have done that before. You know, when the founders of this country, you know, got together and said, we're going to try to build a new country with a new set of ideas, you know, oh my God. You know, there's that famous story about King George when George Washington stepped down, you know, uh, basically originally and he won the war. You know, all the Europeans expected that George Washington would become the king of America. And, and George the third is reported reporter said, yeah. And he went back to his farm and said, and then George King George said, if he has done that, now he has the greatest man in the world has ever seen.

Speaker 1:          47:10          It was this unthinkable thing, you know, so much more on thinkable than Uber was to a taxi company. Or that one click was through, uh, an ecommerce site. And it was amazing, you know, and we can do that, you know? So if we are entering a world where AI can do so much more of the jobs that we do today, you know, we should not be content to say, well, we'll just kind of keep feeding the current system. You know, I have Cory Doctorow, the science fiction writer had this great, uh, uh, statement on social media recently where he said, a economists use equations to justify the divine right of capital. The way that corridor astrologers used, uh, the stars to justify the divine right of kings. And yeah, whether it's true or not, it's true in the spiritual world. This idea that, you know, we, we basically justify the system as it is rather than imagining the system as it could be.

Speaker 1:          48:02          And I see this enormous opportunity to make a more prosperous world with all of these technologies we have, you know, so, you know, uh, the what makes me hopeful is first of all, that when we build these algorithmic systems, we can start to see ourselves better bias and coded and taken to scale becomes visible. You know, when, you know, when we have been, uh, arresting blacks at a much higher rate and not seeing it, it's just kind of in the woodwork. You know, we'd go wells, human bias, you know. Sure. But then all of a sudden when you're going, wow, we're baking it into the end of the algorithms because we're using these training datasets that are based on decades of bias policing. We can suddenly see it, we can fix it. We can debug our society. You know? So that's the first thing, you know, it's like this whole engagement, this digitalization of our world is going to help us understand our world and make it better.

Speaker 1:          49:02          And the second thing, you know, AI is going to help us to understand more deeply what is human and it can create new kinds of beauty. And I love this, uh, this a statement from the 37th move of the second game. Uh, it was a fan. Who are you talking about? He says it's not a human move. I've never seen a human play this move so beautiful. You know, this idea that something new that we have not imagined can be beautiful, that it can not be something you'd be afraid of. That it can be something wonderful that's the world that I think we and the technology industry should be committed to creating. And finally, just want to remember that it isn't technology that wants to eliminate jobs. Uh, my friend Nick Hanauer or said technology is the solution to human problems. We won't run out of work until we run out of problems. So like, I think we all in our industry have to commit ourselves to solving human problems, make it work, make the world a better place. So that's the master design pattern of technology and really the message of the book, you know, our job is to augment people so they can do things that were previously impossible. Thanks.

Speaker 2:          50:18          Well Tim, thanks so much for coming. I'm really excited to read your book. Uh, I was just curious, you know, as someone who's been in the publishing and content industry for the past 20 years, why, when you think about it sort of like transmitting these ideas about the future, why you chose to do it in the form of a book, when there's like, there's lots of different tools out there today and like, so as someone who's thought a lot about this, I'm just kind of curious, like what, like why do you choose to, cannot close it?

Speaker 1:          50:44          That's really good point actually. In a, probably the trigger was that I had, I've been running this event called the next economy summit and I was trying to get on Michael Crafts, uh, you know, show the local PBS show and I just was having a lot of trouble. And then somebody who'd written a book that I really didn't respect, sort of, you know, appears on the show. And I'm like, Damn, you know, it's like, it's free for a certain kind of intellectual discussion. It is still, uh, you know, the, the little entry card, you know, like I couldn't get in this room without the Google entry card. And you know, writing the book gets you discussed by the policymakers because that's the thing, you know, all of these people who shouldn't be deeply involved in the digital because it's the center of our world, you know, I mean this is a book that I can send, I can put in front of a policymaker, have them read, uh, have the think tanks in DC. Talk about, I can give talks there because I wrote a book, you know, and otherwise I'm some weird new media guy. And of course you've been a publisher for 30 years. Yeah. Which is ironic. And, and actually I didn't publish it myself. I actually went to one of the traditional business publishing, uh, you know, companies because again, it's sort of, it's, it's just this credentialing function,

Speaker 3:          52:04          excellent set of hypotheses. But one of them is the, who are the actors of change. Obviously we talk like break big things. Like Uber today has started as very small things. Do you have any conclusions you draw with this? Whether innovation is possible as they can to get more and multicellular at the small stage garage date and rural startup stage? Or would you be thinking that as data gravity of its own that we're going to see a return to bigness for its own sake and that potential for startups in this world?

Speaker 1:          52:30          Well, I do think first of all, the power of ideas is profound. Uh, you know, uh, even, you know, if a startup doesn't survive, it can actually place a new idea into the world and that idea can be taken up. And um, you know, that's, that is, you know, why create more value than you capture is sort of part of my motto. You know, I just believe, yes, you know, in the end we're all going to fail. You know, and I, I've often quoted this wonderful poem of Roca. What we fight with is so small and when we win, it makes us small. What we want is to be defeated decisively by successively greater beings. He's talking about wrestling with the angels. And I think that, so yes, that may be a risk of bigness, but I think actually if you follow the job of doing something that needs doing, you know, like one of my, one of the companies they talked about at the end of the book where I kind of try and give some, hopefully it's companies zip line, right?

Speaker 1:          53:36          So here's a company that's using drones and on demand and they're not like, we're going to be the Uber of dry cleaning there. They're like, uh, you know, we're going to be the Uber of blood delivery in co in a country where, uh, people, you know, with the leading cause of death in women is postpartum hemorrhage. You know, it was no developed hospital infrastructure. There's, uh, you know, bad roads, but you can get a drone anywhere in the country and 20 minutes, you know, and Bang, you know, it's like, that's astonishing. You know, that's like, wow, we can solve a problem that's a real problem with this magical technology. And guess what? They're kind of not, they're in there, you know, in that normal competitive landscape. Because they've actually found this green field of opportunity, which is solving a real problem. And I think, uh, you know, if, when, you know, sure, the [inaudible] space pretty crowded.

Speaker 1:          54:36          And if you want to go, yeah, can I make another social network kind of hard, you know, problem. But there's another piece to it too, which I've been, I had a debate with Reid Hoffman recently cause he's got a book coming out on blitz scaling. And I was like, look, read it. If, you know, it's like you got to raise lots of money because you have to grow faster than your competitors and so on and so forth. It's still a winner. Takes all somebody going to win and somebody's going to lose. And one of the things I want to hear more is, uh, um, like how are these platforms enabling an ecosystem? You know, it's kind of goes back to this sort of platform thinking, you know, and you look at, uh, you know how Google has been an enabler, how youtube is an enabler. You know, there's people getting work from this. And I think, uh, one of the things that I think in a world of winner takes all platforms, the platforms themselves have to think more about how are we going to enable a network of small business

Speaker 4:          55:32          [inaudible].