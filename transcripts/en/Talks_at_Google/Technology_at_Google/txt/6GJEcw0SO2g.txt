Speaker 1:          00:05          Hello everybody. I'm so excited to be here with you today. A couple of things. One to make sure we have a dialogue because if all I do is talk to you about maybe a few nightmares, maybe a few scary things, tell you a few White House stories and that's all that happened, then I only did half my job. So I want to make sure that you feel like you can ask me questions. And for those of you that are live streaming in your questions are going to be moderated by Heather. And we were talking about making sure everybody's questions get answered. We're going to find a way to do that even if we run out of our time together. And then for those of you that are in the room, your incentive plan is to ask a question and the first one to ask a question, you get a signed copy of my book, which my mother says is a must read.

Speaker 1:          00:52          And uh, and then if you don't ask questions and you're too shy to ask questions, then I ask random people random questions. So that's your incentive plan for asking me a question. I really want to make sure we have a dialogue. I'm really honored to be here with all of you. For those of you who are live streaming in as a view who were here in person. Uh, Google is one of the power brokers of the world and I'm a big fan of Google. I've also held Google, uh, accountable. I'm in talking about privacy and security, but I'm a big fan. As a matter of fact, I power our company's infrastructure. A big part of it is on the Google cloud. So big fan of Google and I want to push you out of your comfort zone. So when I talked to the people putting on this event, one of the things they said is try out some new concepts and new ideas and I'm going to do that today.

Speaker 1:          01:41          Uh, disagreement is always welcome so you don't have to agree with me. I'm, the only way I'm going to learn is for people to share alternative points of view and idea. So your questions can be anything, any topic, and feel free to push back on anything that you hear me talk about today. A couple of quick pictures from the family scrapbook. So you'll see in the family photo, I've got my two sons, Kiran and Aiden. I'm actually seven months pregnant with my little girl made there and the gentleman next to me with his arm around me, that's President Bush and the dude next to him. That's actually my husband. Um, then you have another picture of, uh, the White House press briefing room, podium. And you can probably tell I'm actually holding up my son and decking behind him. And I love that picture because, you know, it's one of those things where my, um, I commuted every week for two and a half years.

Speaker 1:          02:30          I don't know if you know this, but the shelf life of a political appointee CIO is roughly 12 to 14 months. I did it for two and a half years. So that either says I'm crazy or determined and stubborn or maybe a little bit of all of the above. Uh, but sometimes instead of me commuting home, my family would actually come to see me and the senior staff really encouraged for them to come and experience the White House as I experienced it. And so on this particular day, actually, kids were like, mom, you have the coolest job in the world. And they were right. And I still have the coolest job in the world. It's just a different job. But this particular day they saw the president land on the South Lawn and Hmx one the helicopter. Then they saw the president's dogs, Bernie and Ms. Beasley. And Barney was outfitted with a camera.

Speaker 1:          03:16          So you could see the White House from Barneys point of view, I'm Barney can then people were handing them presidential mnms everywhere they went. And they're like, this job is amazing. You helped the president with this computer. You get to watch helicopters land, play with dogs and eat m and m's kind of sounds like Google, doesn't it? Right. And so, uh, we went into the press briefing room, which is one of the few places where I could actually talk about my job. And we were doing this major modernization effort in the press briefing room. And behind that podium, which is the president had been there, they'd actually be a presidential seal on the podium and its nickname is called the blue goose. But behind that is almost its own little city of cables and wires and uh, programs running things from the blue goose. My kids are bored at this point.

Speaker 1:          04:01          So my oldest turns to me, those were getting ready to leave. And he says, Mama, I really want to tell the news. And so as I ducked down so my husband could take that picture of him telling the news, it dawned on me, wouldn't it be great if we let four year olds give the press briefings in the White House? I mean, think about the honesty we would get. Right. Um, and then down at the bottom there's a picture of me in front of one of the jets in the Air Force One fleet. And this is where the job that you have and the job that I had are actually not too different. So if you think about the White House for starters, the 3000 staff that worked for the executive office of the president, they're barely ever at the White House. We don't all fit in the White House. It was built for kinder, gentler, smaller time in our US government.

Speaker 1:          04:46          They're mobile, they're global, they deserve and in some cases demand the latest and greatest technology. How do you give them the latest and greatest technology to enable them to do their jobs without, for me anyways, putting a homing beacon and the president's pocket was not an ideal thing to do for you. It might be a little different what you're worried about, but you're still worried about the security and the privacy in addition to the functionality. And so if you think about it, our jobs are not too dissimilar, right? And the challenges we face every day. And we're at this really exciting time in computing. And Heather and I were talking about just how amazing it is and we don't even know what quantum computing is going to bring for all of us. And it's exciting and scary at the same time. And we now have a point where, you know, devices are collecting and interacting with each other on our behalf without human intervention.

Speaker 1:          05:41          It is an amazing time of innovation and the technology that's being deployed is so cool. So I don't know about you. When you think about commercial travel and you think about elegant, classy service, do you think flying on airlines these days? Maybe, maybe not. Probably not. I mean I think Air Force One, but I don't fly on that as much anymore. And so I think you kind of as second best is virgin airlines. I think they do a pretty good job whether you're in first class are in coach. And so how do they do that? And I looked into what virgin airlines was doing. The first thing they did was they've outfitted every plane with Internet of things, devices from nose to tail wing to wing, inside and outside. Now, that's not to say while they're flying, they're all communicating with the Internet. But the devices are collecting information and that information is used to think about safer flying or their mechanical issues, more economical flying.

Speaker 1:          06:34          So how do I give you elegant, classy service while having it be economical at the same time and being on time. So on time records, how much data are they collecting? One plane, one flight is a half a terabyte of data. Now I know this group knows what a half a terabyte of data is, but if your mom and dad asks you what it is, it's the equivalent of binge watching 250 hours of your favorite shows. One plane, one flight, Virgin Airlines. That is a massive amount of data, but it's really cool how it's being used. Now, in some cases where we're headed with technology can even save lives. So in the UK they actually have internet of things, lamps and these lamps actually detect glass breaking, yelling, banging, loud noises, and the lamps actually glow brighter and brighter. In some cases a camera will turn on and they could deploy physical security if they need to.

Speaker 1:          07:35          These are really cool and interesting uses of technology. And then of course Google, not to leave out Google, we have Google helmet, my house, that was actually the employee gift last year for Christmas for everybody in our company. Now everything has to be gold. That's given us the employee gift. So we had to search for the gold rappers, which came out later, but long story about that. But if you think about sort of the integration of some of this technology, it's almost to the point where we don't even realize it's there anymore. And the opportunity is huge. When you look at the economic value for the world, we're looking at possibly $11 trillion positive impact and we've now outnumber humans with the number of Iot devices around the world. So where do we go from here? Well, one of the first things I want you to be thinking about since it's internet safety awareness month, right?

Speaker 1:          08:29          So national cybersecurity awareness month, it's also international cyber security awareness month. And this is the 13th year that we're doing this. Do you guys feel safer? I don't know about you. I don't. I'm so 13 years in lucky 13 first thing I want you to think about changing is how many of you have heard the conventional wisdom that the human is the weakest link in security? Right? So, uh, we all say it. We all say, I want to change the dialogue. So I want to push back on everybody here and ask you to question why do we still, after over a decade, we're lie on the human and say they're the weakest link. Maybe just maybe I'll push this idea out to you. The maybe given the hockey sticks we have in Cybercrime, the maybe given the geopolitics of the world, and I don't know about you if you're a history buff, it's never felt more tense than it has for me based on what I've read of ancient history and modern history. It feels pretty tense to me. Maybe it's because I'm living in it. Maybe it's because we're all, you know, living in it. It feels more intense to us that maybe world war one or World War II or the Cold War, right?

Speaker 2:          09:36          Okay.

Speaker 1:          09:37          But maybe we should be thinking about, no, the weakest link is actually us. I started off as a developer. Maybe there is a moral imperative that when we talk about feature and functionality, the first thing we should be talking about is let's not depend on the weakest link, the human. So I'm going to push that out as something I want each of you to consider is we need to change that dialogue because if we keep relying on a human, we're going to keep failing and we can't afford to fail. Cyber criminals have never been, uh, kind of more organized, more talented, um, and in some cases more scalable. So we're seeing the attacks cost a lot of money, so you don't even have to be technical anymore. You can buy your way into attacking companies.

Speaker 1:          10:27          And so it all starts with designs. I really want to push hard on this concept of how do we think differently about design? And maybe some of it starts with thinking about ethical hacking. So before you even build that piece of functionality and maybe you bring the ethical hacker in, not for them to throw a wet blanket on your fire, on the great idea that you're trying to innovate, but to turn to them and say, so how would you break this before I even build it? How would you break it? How would you take advantage of the human that's using it? How do we not be relying upon the human that's the weakest link?

Speaker 1:          11:03          And for me, I have to tell you what am I tipping points when I first got to the White House, you know, I used to work in the financial services industry and so every time bad things would happen, the financial services industry, I think to myself, if I could just get to every user and if I could just talk to you for a little bit and train you a little bit better and write the policies a little bit better, like life would be so much better. And that's all it is. It's communications, it's training. We just got to do this better. And when I got to the White House and I realized, okay, wait a minute, cause there's 3000 people here, they're global, they're mobile, just like our banking customers were. So I didn't think that was two different. But the threats that we're targeting, the White House were ever changing. And I thought if I'm going to try and brief everybody every day on what I'm learning is different and I'm going to hold them accountable for understanding how to protect themselves, I'm going to fail.

Speaker 1:          11:53          And that's when I realized I wasn't always designing for the human. And I'll talk to you in a little bit about how to think about designing for the human. And one of my Aha moments at the White House. But I've had a second Aha moment lately and this really happened to me in the last year. And it really came to the forefront with the discussion around the election cycle, not just in the u s but over in Europe and the potential for Russia, possibly other countries to use propaganda to change people's minds and opinions and potentially have them change how they vote. And that domain is, we were so focused on, okay, the humans weakest link and we need to protect the servers and we need to protect the data and we need to protect the devices that we forgot to protect crowdsourcing and crowd thinking. And so when that effort to be thinking about how do we reach people and how do we stay interconnected and how do we get information in a way that we want to receive it, that's the most beneficial to us in that moment that we receive it.

Speaker 1:          12:54          Right? So if you order something on Amazon, it tells you what other people who ordered that ordered. And a lot of times you think that's pretty cool, I'd probably need that too. And that's helpful. But at the same time, is that technology matured. It also created unintended echo chambers, which I'll talk about in a moment, but I want you to be thinking about the domain of security has now added a new domain. So it's not just data, it's not just devices, it's not just the humans, but it's actually the social media content as well that needs to be protected. And if you read a security briefing, I don't know how many of you have the soul crushing pleasure of reading security reports on a regular basis, but they all pretty much sound like this. The Sky is falling. Data's at risk attacks or worsening, and the silly user, it's their problem.

Speaker 1:          13:47          They pretty much all sound that way. Now I'm going to show you a couple of clips from hunted to show you why it's really not something that the user can always prevent. And so what are you going to see in this first clip? In a couple of caveats on hunted, when you see the command center, none of us are actors and actresses were just working cases. We're trying to forget. The cameras are there, it's not scripted. And so everything you see that we're doing, if we're trying to hack into an account or get information, it's all in real time. So in this first one I'll show you the video and then I'll explain to you what,

Speaker 3:          14:19          what's going on. Concrete Intel on David and Emily's whereabouts did mark NSA analyst, Landon Stewart attempts to break into David's online accounts. And when does your [inaudible] dot com I'm going to get into Gmail. Which message? Lumberjack downtown one. A fugitive goes on the run. And Mike Pearse thing, because I'm a cyber guy, I want to know how to leverage technology against them. One of the security questions for a reset is his favorite sports team. So what is his favorite sports team? Charles, let me see here. All right, Alana is Instagram, which, which sport? The Lakers. He's seeing in the Atlanta Braves, but that's pumping his favorite Miami heat as photos up. Tracy. He's from Miami, right? Miami Heat. That would be my bet. My only concern is do store best not to lock him out. That's why I won't have it verified by more than one source. Oh, of course. You guys are saying he too. Yeah, he's at the game three weeks ago. Let me see. Mark. Screw skirt. Screw it. Let's try it.

Speaker 3:          15:24          Got It. It's the heat. Oh, you rock. We'll ask a question. When did you create this Google account? Okay, let's, let's try and be smart about it. Um, let me Google the account and see about when it appears. Just gimme a second. Let me see here. Here's the oldest one. I see it's January of 2014. It might be the best shot your gun. This is a crude way of doing, but it's the best one. I could be that one. That's no guarantee. Oh my God, it worked. We've got all his contacts. Oh, we have everybody do it. That's awesome.

Speaker 1:          16:10          Okay, so a couple of things about what you just saw there. And first of all, whenever we heard that the fugitives had a Google account, we would just grown because we were like, oh, based on Google Security and privacy settings, they're the hardest ones to get into. And so we would actually have to file, um, I'd have to send a written thing to a judge. I never got to meet with who always said no. Pretty much everything. So I'd always have to justify what our techniques, we're in the cyber and Intel group and I finally got a yes, David winded. Sure. Used to be a criminal. He's now a defense attorney. He was a formidable opponent as a fugitive on the run. Just really, really smart at what he was doing. And we had actually recovered his laptop from the scene at which he fled, but he had logged out of his account, didn't have two factor authentication on.

Speaker 1:          16:56          And so we finally got the okay from the judge to hack into the account and we knew if we messed up those questions too many times when we knew we would be locked out and the judge said we'd be on our own and those clues were critical to us. I won't give you a spoiler alert, but they were critical to the case. Oh, and by the way, land and who also works for my company, I joked with him, he's the only one that throughout the show would get some titles and it's because he's from Pittsburgh. So I'm like, I guess because you speak Pittsburgh, could they have to do subtitles for you and not everybody else? All right, so we'll go to the next video

Speaker 4:          17:31          team. I'm going to assign this to Steve, former naval intelligence officer. Steve Masterson begins to build a profile on Troy and Shelly crosscheck public records. Who are they? What do they do? We've been married, their high school sweethearts. Did they seem to be best friends? I don't think they're going to separate it. I'll tell you obviously can stand hours together. Yup. Kids, no kids. Okay.

Speaker 1:          17:53          So in this particular one, again just from a, and realize the bad guys do this too to your customers. Right? So they, we were trying to figure out Troy and Shelly, I had the suspicion they were hiding out in the swamp. They actually had an airsoft business. They had done a lot of camping as part of their air soft business and the airsoft community was not talking to us. They literally, and that that's, that's their friends and family was the Airsoft community. So we were trying to figure out from a social media profile like do they have kids? Like would the kids be a clue? No kids. But we did find out they had a pet who meant a lot to Shelly. And so we had a lot of rules of things we couldn't do to lower people. And, but one of the things I wanted to do was just have the vet call Shelley's mom just to check in and to see when Shelley was going to check in on the pat.

Speaker 1:          18:35          Not to say the pet was sick cause I'm a pet lover myself or anything. Um, and at that point I was told, I know it's not written the rules but you're really cold person and we're ready to get into the rules that you can't talk about pets. So anyways, pets were taken off the table. Uh, but you could see how just using a social media profile, we were trying to get a feel for where they would be. They had a hundred thousand square miles they were allowed to hide in. And just by studying them on Airsoft, I knew they weren't going to, they were airsoft. I'm enthusiastic. I'm looking at their air soft websites that they would participate in as well as the two of them got along so well. Most likely they weren't going to argue they were going to be a good support network for each other. All right. One more video

Speaker 4:          19:18          I can command center. The cyber teams. Facebook wanted poster is widening the circle of associates for fugitives. Troy and Shelly guys don't pay attention to this post. It is not Shelly postings. Snitches get stitches, snitches get stitches. So month to figure out who J D is. I love the results of what's happening on this Facebook wanted poster. We're getting new names and context we didn't have access to before. It's incredibly helpful.

Speaker 1:          19:46          So in this particular one, again, the community was not talking to us and so we got permission from the judge to actually flip their social media profile to a wanted poster and I knew that they weren't going to, nobody was going to turn them in. I knew that, but what I knew was this, whoever seemed to defend them the most was probably somebody I wanted to put under surveillance. And that actually ended up helping us out a lot. In that case, if somebody who spoke up a lot and told people not to talk to us and not to help, we actually went to her house. Um, and we are actually ended up in 24 hours apprehending them with the tips and nobody outdid them. But it was just the way people behaved on social media. It gave us a clue that they might be their lifeline.

Speaker 1:          20:30          And so what does that mean? So we still have, not only do we have sort of this new brave world of social engineering where it's never been easier to do for the bad guys, but we've got these old school breaches that are coming up in the headlines, whether it's one or cry pet ya not pet the SCC Edgar database, Equifax. And I'm not picking on these companies. I mean the way I look at it, is there a victim of a cyber crime? You may like what they did before and after and how they handled the breach. You may agree or disagree, but they are victims of a crime. But we've got these new school problems to deal with now, right? So we've got misinformation, we've got the social engineering and what I call covert crowdsourcing. So trying to get people into those echo chambers on the different social media platforms and trying to incite basically either positive or negative emotions around certain topics.

Speaker 1:          21:20          And then we also have this misplaced faith in technology. So I don't know how many of you spend time in security operations center. I've spent more hours than I care to and security operations center, I know Heather as as well. And so these statistics are pretty staggering given the amount of money we have spent on security technology. So let's kind of just peel back a little bit on these 56 56% of all alerts that go into a security operation center or investigated, which means the 44% or not even looked at it at all because there's just not enough time and talent to be able to run those down. Then of those 56% alerts that were actually looked at, only 28% are deemed legitimate. So the rest are just noise. 72% are just noise. And then out of that smaller subset now, so remember we went from 56% to 28% so out of that 28% only 46% of those actually get remediated.

Speaker 1:          22:25          Do we wonder why we have the data breaches? We do. Do we wonder why our infrastructure, our cybersecurity resiliency for companies is at risk? Do we wonder why it's time to start naming the human as any something else other than they're the weakest link we have to change how we focus on this case in point. The elections that better had been our tsunami warning and I feel like a lot of times the data breaches that we have, we get excited about it. Sort of like waking up really early in the morning to go do something and then somebody hits the snooze alarm and it goes back to sleep. We're all out of snooze alarms and if Equifax it and do it for you. The early warning signs that tsunami bell going off with the elections absolutely should because it's not just in America, it's in other places. So let's talk about kind of my point of view on how I look at this and I welcome any questions, comments on this during the Q and a portion.

Speaker 1:          23:26          So I look at this and kind of three components and the first one being is the voter registration databases. We know for a fact that those were targeted by hackers. We know that Chicago, not Chicago, the state of Illinois had to take their voter registration database offline for weeks during the summer leading up to presidential election cycle. They had had an incident and they felt the best thing to do was to take it offline to remediate the incident before they came online. Did that impact anybody's ability to vote? I don't know if it did or not, but I know during those weeks getting a voter registration and if you were somebody new to Illinois was not hasty to do while that was down. So you have the voter registration databases, you also have the polling booths themselves. Now, nobody has said that they have found evidence of somebody went in and voted for one person and on the back end a different person was voted for.

Speaker 1:          24:21          Nobody has said that yet, but ethical hackers at black hat this year said, if I have proximity and I have time, I can absolutely do just that and you may or may not know this, but at the state level, not, not only does every state get a chance to do this differently, the counties and precincts within those states may also do it differently and up until this election cycle, there was a race to go to to the electronic only with no paper trail for audit. I don't know about you. I think that sounds like a really bad idea. I think we need a trust but verify process here and really smart people are working on this problem to make sure from a voter registration database perspective, our data is more secure, but this has to be solved at the state level. Lots of really smart people are working on the actual polling booths themselves and making sure that we don't allow proximity and we don't allow time because somebody with motive could do that.

Speaker 1:          25:18          And then the third piece is what I talked about, which is our new domain. We need to be worrying about insecurity, which is the whole social media and our inner connectedness on the internet domain that needs to be thought about differently. And I'm just going to show you a couple of quick headlines that have been in the news recently. So and it, and it's every company. There is no one company at fault here, but this better be our wake up call for how we think about what happened during the selection cycle. Now don't get me wrong, political espionage has been around since they were two human beings on earth. Okay? So that's recorded history. We know that propaganda has been around for all of mankind. But what happened, this particular cycle, both overseas and here in America, was being able to produce propaganda to push propaganda, leverage these social media platforms that have been designed to serve me and to give me things that help me and assist me, which means they know my likes and preferences and because they do that, the social media platforms were taken advantage of and they were able to at a speed, never seen before in the history of pushing political propaganda.

Speaker 1:          26:34          Not only push it out that to be able to see in real time whether or not they had an impact on you and me based on likes, based on shares, based on posts. They never had that before. They didn't know if it was working or not. They to put boots on the ground and they had to see whether or not they're grassroots campaign was working. So we have never seen what was done at the speed and scale in which it was done, not only to us but the elections going on overseas. And Google has recently come forward and said, you've done your own research and you are taking this very seriously. There's actually a proposed law, and I always say be careful about new proposed laws because they typically are not going to stop bad things from happening and in some cases they're going to create a situation that's so expensive for you to comply with that it kind of loses the spirit in which it was men.

Speaker 1:          27:24          But there's a law around sort of the, you know, the safety of ads in the political cycle act that's being looked at on the hill right now. Let's bring it back to the humans though. So if you remember wanna cry, which was really bad, especially for the UK, I was actually in London, the day one a cry hit. And what struck me was this was different because typically ransomware is all about how much bitcoin can I get out of the victim and how much have it can I wreak on them. In the meantime, this was different. People showed up for surgery and more told, I can't operate on you today because we're under a ransomware attack. People showed up sick and needing prescriptions and they were told, we can't write you a prescription today. That to me is that, that's where, this is not about how much bitcoin did these guys get away with.

Speaker 1:          28:23          But at this point, I think human safety trumps security. And this is where we have to be thinking about design a lot differently. And so for my Monte Python fans, um, this is where I'm throwing the holy hand grenade because we've been doing security wrong and we need to fix how we're focusing on this. So what are some lessons learned? Um, and I don't know if you know this, this is actually a picture of the White House flower shop, isn't it beautiful? So after all that dark talk, it's time for a zen moment. And this is the beautiful White House flower shops. So if you, any Downton Abbey fans, uh, it's very much like that sort of the ushers office underneath the White House that keeps that sense of history and protocol and class and elegance. And I remember when I went into the White House and I did my walkabouts. So there's 13 components that make up the executive office of the president.

Speaker 1:          29:14          And I went into the White House flower shop in is just so beautiful. And I noticed that as she was making these flower arrangements, they had bar codes on every single flower and she would scan the flour with the Barcode. She would cut it off and putting the flower arrangement. And I thought, well that's interesting. Not really sure what that's all about. So I go into the kitchen and they're getting ready to make a big dinner. And I noticed that the chicken breasts and the pork chops and the paper towels, they're all barcoded. And before they get used, they're scanned, barcodes are removed and they move on with what they're doing. I'm like, okay, I've read a lot of Brad Thor novels and Vince Flynn novels. I think I know what's going on here. It's like to make sure there's no anthrax poisoning and everything. Right. So it's not like with love from Russia or something like that.

Speaker 1:          29:57          So I go up to somebody and the ushers office and I said, what's going on here with the barcodes? I think I know. And he says, what do you think it is? And I said, it's, you know, make sure it's not poisoned. And he said, no, it definitely helps with that, but that's not why. And I said, okay, well I know like if Queen Mum, we're here, you wouldn't want to run out of pork chops. Right? That'd be embarrassing. He can't run to the closest grocery store and get pork chops. So that's what it is. It's to make sure from a supply chain standpoint. And he said, well, it helps with that, but that's not the reason why. And I said, well, what is it? And he said, well, it has to do with appropriations because you see who's ever going to eat that pork chop if it's a political dinner versus an international head of state visiting, it's a different bucket of money and we have to charge it to the right bucket of money and hey, this is your tax dollars at work for those of you who are Americans here.

Speaker 1:          30:45          Okay, not making this up. And so they had to scan it against the buckets of money. So whoever was enjoying the flower arrangement, we had to make sure the right bucket of money went to pay for those flowers. Now I ask you, so we were doing the right thing there, but I asked you, when you think about the humans and the humans involved in this and you think about the data and all data is not created equal. So if you think about protecting data and putting stricter standards on some, an easier standards on other, when you compare the number of chicken breasts and baby's breath scan that day versus the president's schedule, which has everyone, he's meeting with the secret service agents down to the second where he's going to turn a corner, which one's more valuable president's schedule. The other thing I want you to be thinking about too is that in my walkabouts, I went and met with one of the other components and one of these components traveled with the president a lot and most of what they did was not on the classified systems, but we had a rule that more than two pieces of unclassified data basically created a classified situation.

Speaker 1:          31:52          You know, just very sensitive. Everything at the White House is very sensitive information. And so as a meeting with them, I said to them, I was just asking everybody, is there anything we do that's not working for you? And so I asked them, I know you're under a lot of tight deadlines when you're on the road with the president, is there anything we ask you to do in the name of security or in the name of logistics that makes it hard for you to do your job? And they said sure. And I said, well what do you do because you have these really tight deadlines. And they said, oh it's really simple. We either take a picture of it or we print screen it and we take it with us to foreign countries. And to which I kind of like had that moment like that pit in your stomach moment.

Speaker 1:          32:30          And the old me from financial services who was all about, it's about training and it's just about explaining to you wanting to come back to the top. But the new me who said, I'm not going to blame the human anymore, I'm not going to say the human is the weakest link. I'm going to say I am. These are my designs. Okay, this is our team doing the development. I own this. And so the new me listened and the new me said, why don't we get together and why don't you show us what's going on here? Because I realized I lost sight of data because I had a bad design. And so I want to push back on you a little bit of always be thinking it's not just feature and functionality from the user experience. Never lose that. Always have that at the front of your mind.

Speaker 1:          33:18          But I need to push back and I need to say the weakest link is actually in development. We need to stop relying on the human for this. It's failing us every single time. And then the last thing that I've learned is you really need a kill switch. And so Barbie, I dunno how many of you know about talking Barbie, but a Barbie when she first came out, all her, most of these issues are fixed. I'm going to talk to you about. But when she first came out, she computer viruses and she also talked to any wifi network, not just your home network but any that said Barbie in it, like wicked Barbie Evil Barbie, like networks you shouldn't talk to. And I was having one of those moments. I was in the kitchen and I heard my little girl may have say to her older brothers, I think I'm going to ask Mama for a talking Barbie for my birthday.

Speaker 1:          34:02          And so my middle one says, well how does she work? Mave and she says, well, according to the commercial, I will talk to her, she will listen to me and she'll actually answer me back like in real time, like no pause. She'll answer me back. And my oldest one says, I don't think mom was going to let you have that because I'm assuming she's probably talking to the cloud. You're probably talking to someone in the cloud. And My middle one says yen, some Rando and so if you don't have millennials in your life, you know what Aramco is, right? It's a random people rent. So some random Joe who's going to help the artificial intelligence interpret everything you said to give you a good answer back. And she said, yeah, you're probably right. I'm going to ask her an easy bake oven instead. But my point in bringing up talking Barbie is with when she had those computer viruses, when she was talking to Wifi network, she shouldn't be talking to because you don't know if they're trusted or not.

Speaker 1:          34:52          You could turn off her Internet connection and still play with Barbie. Just like I remember reading when the nest had a software glitch and it wasn't charging the battery. And so people on the local news where like, oh my gosh, it's getting cold. What am I going to do? My nest thermostats not working and I'm thinking, you do know you can walk to the furnace and flip it on, right? You do know that like the thermostats just to help with thing. And so that kill switch to me is so vitally important with what's going on today. If you think about the incidents like wanna cry or Equifax, and the other piece you need to be asking yourself though is when do I flip a kill switch? Right? So when do I flip it with limited functionality will be left. What are the rules of engagement for this, this kill switch and how do I educate people to know it's there? So the next time if somebody says, look, there's an internet of things, botnet rights, we were talking about reaper last week or whatever it is, that you have an easy seamless way with your customers, whether they're your business customers or your consumer customers to communicate with them, everything's going to be okay. Here's the kill switch in case it's not.

Speaker 1:          36:03          So if you admit all securities defeatable if you think about sort of the adversarial targeting like we did on hunted, because the bad guys do this too. If you have this aggressive offensive and you're thinking ahead about how do I have a kill switch, how do I design for you? So you're not having to worry about this and plan ahead, you're going to be so much better off. So I want to leave you with some new rules. And the first one is, you probably have never heard a security person say this, but I want you to think about your development where you're putting a warm hug around the user for security, right? So we're, it's almost like they don't even have to think about it. That's my timer to get into our Q and a here. New Domains to protect. So it's not just the data, the devices, the hardware, the software, it's also social media and then the fact that there is no perimeter to secure. Uh, also for those of you who are interested in, um, kind of diversity in stem, we do have a linkedin conversation called help us sister up if you're interested in it. It's just up there a few if you want to reach out to us that way. And there's my contact information with that. Let's go to our Q and a

Speaker 5:          37:09          session. Create. So for those of you in the audience, do you think of your questions, but we're going to take a dory question first. And that question is, could you tell us more about how you became interested in this kind of work in your journey into the field

Speaker 1:          37:23          or, um, and this is something Sarah and I were talking about a little bit, which I say I'm very blessed that security actually came and found me. Uh, when I first came out of graduate school at University of Virginia, my vision was I was going to work on cutting edge technology, innovative things that hadn't been dreamed of yet and that's what I was going to do. And uh, then I married somebody who was in the navy and we got stationed in Jacksonville, Florida. And I went to work in banking and I actually got to be a, I got hired into a group. They kind of made a role around me and I was able to, in addition to my day duties as a programmer, I'm in trouble support and helping people with kind of their end user computing. I was allowed to work on innovative technologies.

Speaker 1:          38:10          And in doing that for anybody who's worked with a financial services industry, when you're on the leading edge of technology are on the leading edge of cybercrime and money launderers and terrorists. And that's really what got me kind of passionate and fired up around cybersecurity. But at the same time creating it in such a way that you still love doing business with the bank, but that we were fighting on your behalf to keep the fraudsters of your account. And it really just cemented for me. Um, when I got the opportunity to work at the White House and the briefings, you know, the classified briefings, you walk into that thinking you've kind of seen it all in financial services and you walk into these briefings and realized I was looking into a keyhole in a tiny room and I had no real idea about the capabilities of the adversary. And so that's when I made my commitment that however many years I had left on this earth to work, that I would use it to fiercely defends people and companies and the government and our allies from bad people.

Speaker 6:          39:12          Yeah.

Speaker 7:          39:13          Hey, um, and you get a book for asking the first you can ask and I already get that. This is an exciting thank you. So the question actually relates directly to the title of your book. Um, I'm on the federated identity team here at Google. So I think a lot about people's identities on the Internet and something your demo tape made me think about was that a lot of the ways that when people strengthened their internet identity, like when we think of the early days of the Internet, people had very anonymous identities. Um, and now more and more, especially with Google products, we are giving you a stronger and stronger presence online. Um, and on the product side we think of a lot of ways that that can be helpful for you. And then this video reminded me that two people, uh, ed, particularly law enforcement, there are a lot of ways that having a stronger identity is really great for being tracked or censored or any of these other really bad security related issues. So I was wondering if you had any ideas for addressing that or any examples that you've seen in your career where having a stronger internet identity can actually make you safer from something malicious? Maybe not a valid police investigation, but a, uh, not so valid police investigation.

Speaker 1:          40:28          Yeah. We, I think, uh, well for example, we have, we have had situations with mistaken identity where because of that kind of lack of clarity around identity, you've had people wrongly accused and handling nuclear, their name, you know, police knocking at their door and they're like on, it really wasn't me. You've got the wrong person. And so I do think you're creating, what I would say is, and I think there's a lot in the product development that Google's doing right on this, which is you're informing people on what to opt in and opt out on, on kind of the identity management. And I think it can be a really good thing. At the same time, it does create a little bit of, um, I'm in a conundrum about it myself because when I think about especially the generation coming up, they're questioning and learning and they're treating it all as a conversation online and there's a generation ahead of them, maybe multiple generations ahead of them that once it's written, it's now almost like that's a fact about you versus a conversation around the dinner table.

Speaker 1:          41:37          And so I worry for people who want to leverage the Internet to reach out to other people who don't think like them, to challenge their own intellectual thought process on different topics that it's going to be held against them. And, and that's unfortunate. And so that, I think, to me that's the conundrum I'm in, which is I would like to see stronger identity online. I'd like to see, um, you know, better kind of identity access management for more security and privacy based on opting in and opting out. But at the same time I'm hesitant because I'm worried that, and kind of having that identity that follows you, you don't get to choose what people see and don't see. And, and that's a conundrum for me and I, I don't actually have a good answer for you on that except for keep pushing, keep pushing and your product design and the developers around what are the longterm impacts on people, um, for the, for things potentially following their identity. Can you get a new identity? Can you decide like, I've grown up now and that's not me. And can you leave that behind? And for many of us who are digital immigrants and not digital natives. Yeah, I'd like to think I'm a digital native, but technically based on birth year, I'm not a, but you know, I started programming in school. So for me I think that way. But when you think about true digital natives, there's no on and off the web. And so for them that, that's what I worry about. Great question. Awesome. Thank you.

Speaker 5:          43:08          Great. And our next question is what do you think the, or what do you see as the biggest challenge right now with the Internet of things?

Speaker 1:          43:14          Uh, um, you know what's interesting on the Internet of things I've noticed there tends to be in the security industry, they're so focused on we need to make sure that that device itself that's going to be secure. And that's the problem. And I am actually pushing back on that and saying, if you think about, I had a picture in the presentation, the Tacoma Narrows Bridge for the 1940s the Tacoma narrows bridge, if you look it up, it was built out of concrete and steel independently, very strong materials. We didn't think about the enterprise architecture enough and it literally looked like a piece of taffy pulling. Thankfully nobody lost their lives that day, but the bridge collapsed under I think 40 mile an hour wind shears. And so the Internet of things, to me, I think that the biggest concern for me is we're so focused on how do I get that component secure.

Speaker 1:          44:06          We're not actually thinking about how has that component part of a bigger enterprise architecture and how do we know when that component is behaving badly either because of bad guy took it over or there's something wrong with it. And how do we know when that technology is obsolete and because it's so embedded in what we're doing, we don't even know it's there. So kind of another story. It's not internet of things, but there a house where the phone started dialing a random number several times a day for six weeks and nobody could figure out why the phone was doing that. And what they realized was, is the previous owners had announced, not used oil tank and technology had been fitted on the oil tank, that when it went under a certain level of being full, it would automatically dial the oil company, which is now no longer in business owners changed hands on the house.

Speaker 1:          45:04          So when the new owners come in, they reconnect the line for the house and all of a sudden the oil tank is now calling the now defunct and now that number belongs to somebody else. And it took them six weeks to figure it out. And everybody can have a big laugh. But at the time people were just like, I don't understand. Like is there a ghost in this house? Like what is going on? And I worry about that for the Internet of things is that we've had them so embedded that as that technology becomes obsolete, are we going to remember it's there and what happens when it, they think actually a lightening strike is what turned everything back on. So it's almost like it rebooted the program. And so what happens when we forget they're there? Yes,

Speaker 5:          45:49          I thank you for your talk. I work in user experience for Security and privacy, so I appreciate it. A lot of what you said. Um, what are the top pieces of advice you would give a consumer today to protect themselves online?

Speaker 1:          46:01          Or a couple of things. I mean, one is never use free Wifi and it's one of those things, you know. So I took, uh, our intern Steven to a coffee shop in Charlotte, which is a huge banking town. And I told him, take your pineapple, take your Mac. I'm going to take my pineapple on my Mac and I'm going to hack you and see how you do and then you're going to hack me back and see how you do. And because we have this whole moral ethics code at four Dulles where we say, just because you can doesn't mean you should. He said to me, ma'am, how are we going to make sure we don't accidentally hack other people in the coffee shop? I said, it's very simple. What we're gonna do is we're going to name our wifi hotspots, something nobody would ever connect to.

Speaker 1:          46:41          So we're not going to name at the coffee shop name, we're going to name it something ridiculous. So I named the first iteration, I named it and I named it fake Wifi and five people connected within minutes. And so people's traffic are coming by and Steven's getting upset and I said that's okay. Well I'm plugging it, Steve, I'm going to let you name it. So he says no one will ever connect to this network and it calls it data stealer and 10 people connected. And so my point in bringing this up is it's like you have people who, I know data plans are really expensive and so they're trying to use free wifi everywhere they go and they don't really realize that they need to be using a virtual private network in addition to using that free Wifi to help. Not that doesn't block 100% of all bad things, but it sure helps a ton.

Speaker 1:          47:26          So that would be the first thing is get a really good VPN that you're really comfortable with. Use that everywhere you go, especially when you go overseas on vacation. Cause that's a really popular time for people to get hit. Uh, don't use free Wifi. But if you have to have that Vpn, I also say segment your life. So just like we talked about network segmentation and data segmentation. Really briefly segment your life. Have one email address that you use with your bank that you don't use anywhere else. Have one with your health care because health insurance fraud is really high right now. Have one that you use for sensitive confidential emails. I hate email but sometimes the person on the other end of the line, the only thing they want to do is send me this confidential email. And so I personally for that use a whole different email platform, a two factor authentication that is annoying to most consumers.

Speaker 1:          48:16          Just understand that they don't like it, they don't want to do it. But if you're somebody who's um, on line and you've got that particular email tied to other things, you need two factor authentication. Uh, and then kind of the last thing would be, you know, as it relates to any of the major issues that are going on in the world and in this country, do your homework. Don't allow things that are posted on your friend's walls and on your wall. Don't allow that to create extreme emotions for you. Whether those are highs or lows, do your homework, pick out your own news organizations that are on both sides of different arguments and don't react to what you're seeing right now and make sure you, you do your own homework and things so that you can really think and make up your own mind for yourself. So those would be some of the bigger things that I would advise. Yup. Great question.

Speaker 5:          49:14          Great. Our next question is, um, you mentioned being cautious of new laws in this space. What steps should lawmakers and or the government in general, it'd be taking to keep us safe online, especially when we consider one a cry and the impact that it had on the health sector?

Speaker 1:          49:29          Yeah, it's a very fair question and uh, you know, it's interesting. I, if anything actually gets passed on the hill. So that's kind of the first big one, which is they're not getting along. I don't know if you've noticed and not, not a lot has been passed in recent years, but if anything were to pass, given what's happened in the past with OPM, with some of the credit card breaches. But when you look at Experian, that's permanent data. So the last breaches were credit cards. You get a new credit card basically after a year you should be fine experience. You're never getting a new mothers may name social security number, date of birth, they can wait 10 years. And that data's still golden until America as a government figures out what our new identification Schema is going to be for the different parts of your life, whether it's the IRS or a security or whatever it is.

Speaker 1:          50:20          And so I'll, I would be a big fan of seeing some type of a consumer bill of rights around data and data privacy. But I am hesitant to push for something like that because I worry that by the time it's inaccurate, it's out of date. And then two, I worry that, well meaning well-intended, but not technical people will be dictating for companies how to technically take care of that. But, uh, but if you were to ask the hill for anything, I would ask the hill, uh, for things that are incentive based. So for example, I would love to see companies that invest in security and privacy get an r and d tax credit for that. How about the fact that you're being a good citizen and you're investing money and thinking about this problem differently. Why not give you a tax break for doing that? So why don't we think instead about sort of onerous regulatory burdens, why don't we think of incentives and saying for companies who do right by this, let's give them a break for, you know, designing differently and designing for the human instead of designing and saying the humans the weakest link.

Speaker 5:          51:32          And, um, we'll take one more question again. Um, this is, I think the most fun one. Oh, what was the most difficult fugitive strategy to figure out on hunted or otherwise? What were some of the most creative and effective disappearances?

Speaker 1:          51:47          Wow, that's a good way. I mean, candidly, I'll give, try and Shelly some real props. Uh, so what, what you need to know for those of you, if you haven't watched the show yet, you can binge watch it on. And again, my mom says it's a must march show, but uh, you can binge watch it on CBS on demand and I think it's on Hulu and Amazon. You can download the series. And one of the things about Troy and Shelly, um, it, well for you to know about all the fugitives, I had no idea what they went through other than the capture and they didn't let me see it until the show aired. So I learned with everybody at home where people really were and the near misses that we had. And so Troy and Shelly, they were actually in the swamp for 14 days, straight canoeing past alligators.

Speaker 1:          52:28          I don't know if you've spent any time in the Florida swamp. It is not a pretty place to be. And so I give them total props for doing that. And uh, it was really their friends commenting on there, they're wanted page, uh, that really kind of helped us figure out who would be in the local area that might be helping them. Uh, another kind of creative thing that David and Emily did was David had actually, uh, when in that first hour before they're given a full hour ahead of us knowing who they are to do anything they want to do to get ready, but they have to show their getting ready and that they weren't a prepper in advance. And one of the things he did was he called different people to have them be lifelines in line over the course of the 20 days.

Speaker 1:          53:17          And he set up, basically they were three degrees of separation away from him and they did all the coordination for him. And so even though we're trying to surveil him and his family and Emily and her family really, he had gone way out of his circle of trust. And so that made it harder for us to figure out who, cause you can only surveil so many people in 28 days and convinced the court too. You have to have just cars to put people under surveillance. You have to have a really well written warrant for that. I was, that was another really good strategy. And then you know, it was interesting, the boys will and miles would, they basically did was they just lived off of the kindness of strangers, which really was going to work for them until I'm one of the, one of the people who was helping them out.

Speaker 1:          54:05          Um, the, the friend wanted to go to a movie and they didn't want to leave the boys alone in the vacation rental. And so she actually called our tip line and turn them in because she was tired of them hanging out. So it's like when you do on the kindness of strangers and they had no digital footprint. The only, only thing I thought was when I read their profile, I said they're going to go to the beach and cause the hundred thousand square miles was the southeast for season one. So I said, they're going to go to the beach because they can blend in. They kind of, you know, they're young men, they're going to blend in at the beach. They like to have a good time. That's a great place to hide. And so, but there's myrtle beach and there's Florida beaches and there's all kinds of beaches. And a, that's really was their undoing, was living off the kindness of strangers and one of them got tired of them and turn them in.

Speaker 5:          54:51          Excellent. Well this has been really fascinating and we do appreciate you joining us today. I'm so a big round of applause for chase everybody. Thank you.