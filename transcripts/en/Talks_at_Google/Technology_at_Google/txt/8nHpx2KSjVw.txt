Speaker 1:          00:06          Here's Jose. He is the lead of the NASA International Space Station spheres and astro be program. The spears facility is one of the most used and popular ISS national labs with over 80 on board test sessions and 400 plus hours of on orbit activities. Today. Jose has a bachelor's and a master's in electrical engineering from Arizona State University. Please help me welcome Jose

Speaker 2:          00:34          [inaudible].

Speaker 3:          00:36          Thank you very much. It's my privilege to be here and share with you some really exciting work I get to work on. And Nasa Ames. Uh, as mentioned, I lead a small team at Nasa Ames that's a help support these fears and Acerbate facility, uh, to be more accurate. We're, we're the team that keeps that platform operating on the space station and supporting research that occurs on, on this platform, uh, for, for, uh, several years now in operation for over 10 years on the space station and then a what I'm here today and it's actually appropriate. That's a five years after, uh, mark ms series talk. He led this effort, um, before I did and uh, I'm here to present what we've been doing since then. I also our recover some, some of the work done in the past as well, including his work. So you'll, you'll actually see his face and in this presentation as well. Um,

Speaker 2:          01:29          yeah,

Speaker 3:          01:29          so that's, that's very appropriate and really excited to share this work with you today.

Speaker 3:          01:37          So in this talk, I will cover the ordnance story of how we got started. Uh, first with some initial free flowers at NASA has worked on in the past, starting in the late nineties, um, even earlier than that. And then spheres as the, uh, uh, platform that ended up, I ended up outlasting a lot of other free flowers, top rate on the space station. Um, some of the really cool work we've done with that over the 10 years. It's been in operation on space station. Um, certainly the free flower that, uh, that could and um, and then get into, well, why are we looking at free flying space robots? Uh, no question about it. That, that sounds cool, right? But, uh, there's a lot of really good reasons for doing that. Um, and then, uh, going into the next generation of free flying space, robots that were or were not working out at Nasa Ames, uh, to be delivered to space station early next year. Um, so some really exciting capabilities coming online and there our guest scientist program where we have some processes set up to enable guests, researchers from academia, private industry, uh, commercial industry, uh, academic, uh, universities, companies all over the world, not just us, but all over the world to use this platform on the space station to do some really cool research and to enable a future, uh, autonomy on, uh, in space.

Speaker 3:          02:57          And then I'm just going to touch on some future free flour and research that we're looking at, how we're already working with people who have ideas for how to use asked to be on the space station, uh, and then touch on stem outreach. So Science, technology, engineering and mathematics. And that's a big part of what we do with these free flyers. Um, and some exciting work that we've been doing with spheres. And now continuing with the Astros, free flowers for spheres got started. And like I said in the late nineties, originally with this first project called, uh, the, um, Psa, uh, an adjustable autonomy spacecraft free flying robot. So as you can tell, it looks very sleek, very capable, and it was a great project. They did a lot of work in the field. Um, and let me jump straight to a video here. Uh, this is one of the early prototypes, uh, on display at ames.

Speaker 3:          03:46          Um, certainly looks a lot like a certain a droid from, from uh, Star Wars. Uh, certainly we get a lot of inspiration from science fiction as a, as I'll get to as well. Um, here's a, a rendering of the real thing in a mock up of what the PSI PSA looked like. Um, personal satellite assistant as what PSA stood for. Um, and some really cool video that I was able to dig up about. It's operation in our micro gravity test facility. This is a lab we have at Ames that a, it's basically the world's greatest crane game. I tell Ya, cause I've, I've worked with this and uh, it's this gantry and a room set up to simulate what you might see on the space station. And this gantry allows us free flour to move in a full six degree of freedom motion across the module, uh, in much the way it would, uh, in space.

Speaker 3:          04:40          So the gantries canceling out the gravity, um, and allowing this to move under its own proportion, um, and navigate across this mockup of the space station. You can tell this, uh, back in the late nineties, there were looking at vision based navigation that a fiduciary on the screen there. Um, and then this, uh, uh, rendering of what the PSA model looked like. I thought this was some really cool video to share. Uh, late nineties through 2003, I want to say this, this project was going, um, but ultimately did not end up on space station. This project got canceled early. Um, but, uh, they certainly made a lot of advances. So certainly looking at becoming an assistant to crew right. Back then there were working with the PDAs. Right. And, uh, how do you provide the functionality of a PDA to an astronaut on the space station? So they were looking at vision based navigation, um, scheduling, uh, identifying, uh, faults and anomalies on space station and notifying crew.

Speaker 3:          05:42          So all kinds of really cool functionality that you'd want out of a free flying space robot on the space station. But unfortunately that did not get a continued. Uh, here's another free flying project that operate in the late nineties. Uh, the video here you're seeing is of air cam let out of a group at JSC that did an actual eva free flying a experiment outside the space shuttle in 1997. Um, and so they were successful in getting a lot of flight time with that or at least a limited amount of flight time, um, and as opposed to PSA or spheres are now asked to be, uh, Eric Cam was designed to operate outside, uh, as it on its own and an EBA ex external vehicle activity versus Iba internal vehicle activity. So again, a lot of advances there, but ultimately that did not continue

Speaker 3:          06:36          really cool picture of PSA. Uh, or, I'm sorry, Eric Cam operating outside the space shuttle together with crew. There were two people operating outside of the spacial there. Another video of, uh, Eric Cam doing some, a navigation there. It was fully, uh, um, remote controlled from a crew member inside the space station. Look, hanging out the window. You'll, you can tell from some of this video, there was some colored markers outside Air Cam, and that was actually how the astronauts, uh, identified its motion as it rotated, right? They, they're handing a joystick and trying to control from inside the space shuttle. Uh, it's, uh, uh, pan tilt rotation and so forth using those indicators, uh, painted onto air cam.

Speaker 2:          07:20          Okay.

Speaker 3:          07:21          And so along come along comes a spheres, which was a, a student build project, ultimately a very smart team of students and researchers at MIT funded by Darpa to look at, uh, in space, um, satellite work and building a facility where you can do, uh, some risk tolerant research, uh, in space. And, uh, it's this scrappy little project that could, and ultimately I went on top rate for over 10 years on the space station.

Speaker 2:          07:53          MMM.

Speaker 3:          07:57          Uh, it started in 2006, first operated, um, and then transitioned to Nasa Ames in 2010 to be operated as, as facility. So first operated by MIT, um, under Darpa funding. Um, it was decided that a NASA operated as a full full fledge facility on space station offering. It's used to researchers all over the country and all over the world. Um, and again, one of the big benefits of this kind of facility inside the space station is it's very risk tolerant. You can do advanced, uh, research and, uh, testing, rapid iteration type work in a environment where you can afford to fail. You can afford a different bugs. For example, put up a new algorithm, run into a bug, and, uh, we can just call up to the astronauts, say, Hey, push the reset button and try again. That's not something you can do with a dedicated space system or satellite operating a all by itself. So it provides us a very comfortable of lab to operate in. You can think of ISS as an orbiting lab, except it's in space, right? Uh, were you can do experiments, iteration, uh, and very fast development.

Speaker 2:          09:00          Yeah.

Speaker 3:          09:00          And I would argue that's one of the big reasons for its success over the last 10 years where one of them was operated facilities on space station. Uh, as mentioned earlier, over 80 a hundred, we're closing in on a hundred test sessions, operate on the space station, over 600 hours of crew time spent on, on space station operating all kinds of research and I'm going to cover some of that research done over the 10 years. Um, and I would argue one reason for that is, uh, our rapid iteration pushing the boundaries of what NASA can do on the space station. As you can imagine, uh, NASA has, has in the past had this mindset of failure is not an option, right? We've, we've learned some hard lessons in that regard and certainly with regards to crew safety, that's very important. But a, together with the ISS program, we've transitioned into this idea where we can do very rapid iteration and high risk type of research on, on space station, at least in regards to a machine success. Here's that small team out of MIT doing some, a vomit comet testing with MIT. And, uh, here's a picture of his fears, uh, on the ground. This is a affectionately referred to as blue. Uh, there are three in operation on the space station three and are at least three and operation on the ground that can simulate exactly what we do up on space station.

Speaker 2:          10:22          Okay.

Speaker 3:          10:23          Uh, spheres is operated by a CEO to compress the o two tanks, a lot like the paintball guns. If you ever gotten paintballing put in a tank, a little swollen lines open up and there are 12 different thrusters that give you four holonomics motion, uh, across the space station. A very much like the, that droid on space station, uh, or join in star wars I should refer to as the origin story for spheres goes. Uh, there was that MIT professor that a challenge is senior design team, uh, by showing them that very clip out of star wars from uh, uh, where you see that the trainer droid, right shooting lasers at Luke Skywalker. And he challenged them to build that exact thing. And, and that's what they went on and did.

Speaker 2:          11:03          Yeah,

Speaker 3:          11:04          some cool pictures of what's inside a very jam packed a about the size of a volleyball, uh, spheres is for the avionics and it's a fully enclosed satellite system. And that's what they initially set out to build with a satellite like spacecraft where they can test out a satellite algorithms, formation flight, um, in space, uh, construction, automated docking, all kinds of really cool research. And here's some videos showing their operation on the space station. This is from one of the earlier, uh, test sessions. Uh, and this video is better for time, so they don't actually move around this fast. Uh, but it gives you an idea for how they move around up in space station and just the type of maneuvers they capable of doing.

Speaker 3:          11:51          Uh, it's, it's no wonder that, uh, this one of the favorite payloads for the restaurants and be working on, uh, they, they certainly do have dark hair maintenance and, and, uh, uh, other science. But these things are all out toys that they get to pull out. And in fact, uh, in one a occurrence and astronauts requested to use these spheres on his weekend time. I asked me, I still get a free time on the weekends and he was so enthralled with using these spheres, uh, um, uh, free flyers that you wanted to pull them out on a weekend and look at some interesting research on how these things can be useful for crew, uh, uh, on a day to day basis. And with the Mike Hopkins, I believe it was, uh, on the space station. And so a certainly a favorite payload on, on space station. And, uh, as I said in over 10 years, we've done a lot of really cool research, um, on space station in both foundational fundamental research and uh, uh, the move moving up slash, and let me just jump into some of these right away, but this like kind of gives you an outline of where a PSA, I'm Eric Cam a sphere is over 10 years and now I asked her B, it's going to take over next year in 2018 and how they can feed into allow the technology areas that NASA is identified as being important for advancing space technology and exploration.

Speaker 3:          13:12          We made this special from national geographic

Speaker 4:          13:15          what you're working on in this lab. Yeah. This is an experiment called fears and do you see a satellite Robert that's specifically designed to function in the micro gravity? They contained the software that the scientists are testing and eventually these will be used to create robots that can go outside of the space station and perform it used affection, a repair and other tasks. You space,

Speaker 3:          13:42          yeah. Only payload during that entire hour, uh, to be operated live, uh, for that special as a full hour long special national geographic did where they were interviewing crew and going through the day in the life of crew. And certainly, uh, doing a lot of education on what we do on the space station. The vast amount of research that gets done on the space station. And we were fortunate enough to be a operated, uh, live during that a tape and not taping but, uh, streamed live to the public. Um, and, and, and we were actually left operating for a good several minutes after that as he went on talking about other, other, the research and we've kept the operating in the background and it made for some not great backdrop to that. Special rings was, uh, an interesting investigation, uh, where they looked at, uh, electromagnetic, um, formation flight where they're trying to figure out, can you navigate free flowers using just electricity, electromagnetic formation flight where you're trying to control the distance between two objects using big rings, generating a electromagnetic field.

Speaker 3:          14:47          And certainly one of the concepts they're looking at for a wide aperture, um, type telescopes where you want to keep a lot of different things, uh, in synchronous operation, in, in orbit, uh, without using fuel. And so this is, uh, uh, one way to, one approach to that. And in addition, they were looking at wireless power transfer, um, and trying to transfer power from one item to the other. And this is another example of where we set out to do one thing. Um, and then we kind of adapt to what we end up with. As you can tell if you look closely at this video, uh, the ring unit on the left is tied down by Bungee cords. The original concept was do some initial characterization and they should be able to navigate with respect to each other using just the rings. Um, but they ran into some issues with the algorithm and we pulled what we resources we had on the space station, uh, tied one down on the left and uh, restricted that, uh, freedom, uh, of the left unit and allowed the other unit to control itself with respect to the other one.

Speaker 3:          15:54          Um, so, uh, just another way where we've had to come up with some creative solutions to get research done on, on space station. Uh, even repairing the fears unit. Um, when they break over 10 years, they do break. Um, and we've had to bring them down, repair it, and very quickly put it back in operation on the space station. Um, Vertigo was, uh, an investigation where MIT is looking at vision based navigation using stereoscopic vision. Much like the eyes are eyes, consensus, distance, uh, with the things around us because we have two eyes that have a fixed distance from each other. And a stereoscopic vision is trying to do the same thing here where it's like trying to identify, um, a, an unknown target, right? You're approaching a us, uh, an asteroid or a, um, a dead satellite and you want to identify not only where it is and where I am, but also its mass and it's inertia.

Speaker 3:          16:48          So you know how to circumnavigate around it or approach it to Deorbit Deorbit it, um, or anything you want in mind want to do. So this is an investigation looking at that, uh, where they were able to attach those goggles on to spheres and navigate around, uh, another spheres unit. Um, uh, again, one of the big reasons for sphere success is its extensibility, right? It's got an expansion port, we add new hardware. It's very modular, allows us to expand those capabilities over time. Halo, another MIT lead a effort where they're adding additional expansion ports on his fears. One wasn't enough. They're not looking at in space servicing in space construction, uh, automated docking where you've got not just two, three, but even more units trying to, uh, operate together. And how do you dock them with each other? How do you navigate with respect to each other? So they're, they're adding more expansion ports on there to support things. Like a, these rigid docking ports, right? How do you dock with each other, um, and rigidly attached to each other in multiple locations, uh, to form a bigger space craft in space, right? That's a lot of what we're going to need to do. If we go to Mars or other deep space, does he uh, um, designations, destinations a is try to do assembly in space and that's a lot of the technology they're looking at advancing with, uh, with spheres here

Speaker 3:          18:08          slash this is a particular favorite of mine where they're looking at the performance of fluid in space and more specifically fuel in an upper stage rocket, right? We have software, we have CFD algorithms that can predict the kind of forces and upper stage rocket might see in micro gravity. But believe it or not, those have never been validated, right? Even I with aeronautics in wind tunnels, you test out that kind of stuff that validates your codes. Uh, but with the fuel in opera stage rockets in microgravity, that's a very difficult thing to do anywhere on earth, right? We've got this pesky gravity vector gone on around here. So inside the space station, it's a, a great environment for testing out this type of thing where basically a pill shaped tank of dye colored, uh, water, uh, can be slashed around an HD cameras on both sides can take video of it's movement and respond to controlled movement from this fears, right?

Speaker 3:          19:03          You have two spheres originally attached to this pill on two sides. Um, and it'll move it [inaudible] known ways. There's an IMU on, they're measuring the exact forces being applied. And then with AC cameras you're taking video of the fluid movement and is it moving as you expect, as your software predicts it to operate in. And um, as I get to later, a lot of the results from this, um, went directly and supported the efforts by all the major launch providers. They were very interested in the results of this. And, uh, the crew certainly got, uh, um, had a lot of fun with this. Uh, you, you may have seen other videos where crews doing experiments using water, coffee, all these different really cool things you can do in microgravity while with these things. You have a, a nice, uh, a controlled experiment where you can see how fluid moves inside of a tank and you end up getting some really cool behavior. Here. You're seeing little bubbles form that orbit each other and thyre round inside the tank, but they're resistant to becoming part of the bigger blob. Right. And in microgravity, the surface tension of water is a lot greater and counts for a lot more of, it's a motion, which is why it's, it's so different than how it operates. I here on the ground.

Speaker 2:          20:17          Okay.

Speaker 3:          20:18          I think there's a little more to this where he brings this a little closer to the camera and

Speaker 3:          20:23          yeah, I spent a long time looking at these. Are there a that's so much fun and especially as a crew, you can tell they're this other crew member in particular was just laughing the whole time cause he, uh, he had fun with these. Uh, and again, this, this was not originally intended, uh, the platform you saw earlier with what, uh, this big plastic thing that was holding the cameras between the two spheres of units. And as he discovered the crew member moving around, you'll do a lot better science. And then here was yet another audition where they're duct taping these things together and seeing what they can do with these tanks all by themselves. So just getting more bang for the buck using a hardware for a recent up there. And yet another investigation is now being conducted later this year where they've attached, um, this, these pills to spheres using tethers.

Speaker 3:          21:13          There was another investigation tethering to, uh, spheres together. Um, and looking at the tethered dynamics, right? How do you deorbit space junk in space. There's companies looking at exactly how to do that. So they're looking at, you tell the two objects were kind of dynamics, can you expect, can you talk one down out of outer space? And, um, after that investigation was conducted really good stuff from that. And then at the end of that, uh, we get together every quarter and, and users as fears and astro. And we came up with this idea of putting a, the tether investigation together with fears is hardware already on station. All the hard work's already done. It turns out they work really well together together with um, uh, Airbus, uh, actually led that investigation. And, um, and again, when we hope to get some more interesting video later this year of tethered, uh, slash tanks moving around space station.

Speaker 3:          22:03          So, uh, some other really cool research. Now we're getting into a little bit of what a, a previous talk given here, uh, talked about with smart spheres, um, where they at basically attached an android powered smartphone, uh, on s fears to look at more robotic type applications of, uh, spheres, right. Spheres of it was initially designed to be more of a satellite, but with us with a smartphone, with all the capabilities that it has a camera processing, a order of magnitude better than what was in spheres, right? 10 years ago, the state of the art was this tea I DSP that the ends up running the its operating system with this a smartphone. They were able to do a lot more with that and stream and tele operated from the ground. Um, and in fact I think I'm going to get to some video here that describes, yeah,

Speaker 2:          22:48          Sadie mortgage reinsurance up and burning one zero lift off the final lift off of it. Shoulders of the space shuttle America will continue to drink.

Speaker 5:          23:08          We're working towards is a future in which we can have robots that will take over a lot of the menial tasks that asked her not to do. Our first goal for our project is to have ground controllers driving the sphere around on the space station. The sphere, we'll take data and pictures and sensor readings and send that back to the user.

Speaker 6:          23:30          She hooks it to the front and at that point the phone will be able to tell the sphere of where it needs to go. The processor, the camera and all of the sensors that are in the next assess become the brains of the robot and told the sphere where it wants to fly.

Speaker 2:          23:46          The wifi on the phone connects to the station Wifi that gets linked down to the ground and then hopefully we're going to be able to control it from the ground

Speaker 5:          23:55          because the nexus ass, because the phone is very easy to take apart. Android is easy to program. We're familiar with it and we needed to make a lot of customizations that are easier to make. With android.

Speaker 2:          24:08          Google was also working on an open source data logger and it met our use case requirements. You can download this application for your android device and US exact same application. That's what NASA is using. The more time that the astronauts

Speaker 5:          24:21          Ben doing science, the more value we're getting out of that

Speaker 2:          24:25          best men. Our goal is to provide enough value to crew and enough value top operations that they'll be able to keep it up there for a long time. Roger ran with Atlanta, Houston now

Speaker 3:          24:42          android in space. Got To love it. I'm so smart. Spheres to went on to do a better smart phones and in fact utilized a, uh, advanced project tango smartphone that got attached onto his fears, which did even better as sensing and three d imaging of its environment. Um, and that was a really cool investigation where for the first time spheres was operated outside its comfort zone. Spheres navigate a space station, you using a combination of ultrasound and infrared and a very fixed two meter by two meter volume inside one of the modules, that space station and that's how it knows where it is and where it's going. With that cat. With that, uh, project tango smartphone attached to it, it was able to generate three d maps of its environment and then venture outside its comfort zone and a navigate using just the camera. So very exciting research being done there.

Speaker 3:          25:30          And a lot of the same technology developed on, uh, this platform went on to be used in not android or asked to be. So why look at free flyers? I think I've covered a lot of the foundation foundational research being done using free flowers like slash rings, all these things advancing our knowledge of how things operate in space. And a again, benefits, uh, payoff. Uh, uh, even in the short term with some of the large providers that have all, uh, utilize some of the results from that investigation. But then, um, uh, that just pays dividends down the road. And then of course, as a robotic platform, how can we support crew members in a spacecraft to, uh, do more things in an automated way and not have to, uh, use crew to do all the maintenance on space station, right? These are just some numbers looking at how much time can be saved.

Speaker 3:          26:22          We're crew can spend more of their time doing the important research and less of their time maintaining the spacecraft and turning very important to if we're going to start looking at deep space applications where, um, it's important that a spacecraft be a lot more automated, uh, and not as a complicated to operate frankly because there's only so many crew members that are going to be on a, on a deep space, spacecraft and along communication delay from, from Earth. So now I get to ask to be some of the really exciting stuff we're working on today. Uh, just a overview, there will be three attributes on the space station and I'll get to some videos showing some demos of them in operation in our lab. Um, uh, to be operated in 2008. We're going to launch it hopefully by summer next year, uh, commission and installed on space station and then fully operational by late 2018, um, where it's then available for guests research and for all kinds of people to use it as a robotic platform on, on space station.

Speaker 3:          27:17          Six total cameras, uh, unlike spheres asked to be, will be entirely vision based navigation, um, to operate anywhere in the u s o s section of Iss. So that's basically anywhere but the Japanese, uh, or, uh, Russian segment of, of space station. So that really opens up what it can do on space station and supporting what it can do. One of its big goals being a, again, replacing spheres as a research platform on space station, but also serving as a mobile camera platform because it has a lot of really great cameras on it. It can automate the camera views and, uh, a lot of the mobile camera tasks that astronauts actually have to do every time they repositioned cameras that were crown control can get good views of what's going on on space station as well as being a, a mobile sensor platform. With this little free flying robot, we can not take measurement all across ISS measurements like Co2, radiation, all kinds of things, uh, audio type sensing. These are things, crew spend a good amount of time going around in space station, taking measurements and something that a robot can do instead. Uh, one comparison I like to make is, is uh, asked to be as a lot like the Roomba of this space station, right? We have little robots that can automate a lot of these menial tasks, um, uh, and asked her, we can do down on the space station.

Speaker 2:          28:33          Yeah.

Speaker 3:          28:34          Some of the design drivers, uh, designed to be a multifunctional in a lot of different scenarios. Um, general navigation across space station, darking perching, uh, conducting a science, um, a platform, something we learned from spheres was it's important to be modular, extensible, a new thing can get it add added onto it.

Speaker 3:          28:58          Current or robot design. Um, 12, roughly 12 by 12 by 12 inches, 12.5 inches cubed. Uh, targeting 10 kilograms is actually as little outdated. A 10 kilograms in mass is a target, uh, for its size and mass. And here are different, um, aspects of Astra be, uh, unlike spheres. Uh, it moves around using a blower. So it's fear as you compress here to ask, he's using a blower to second error in its sides and um, uh, expel the air out different vents. You can see different events on different sides of a [inaudible] where it lets out the air, the a two boxes on both sides. That sandwich has to be a pressure up to about 0.1 psi and generate the force that way where the flaps on the, uh, on the sides there open up and allow variable thrust in any given direction, which is what really gives it a Tom holonomics emotion. It does have a purchasing arm which allows it to perch on the hand rails inside of space station and really gives it its pan until it functionality for his camera. So we can then in a very automated way, uh, uh, perch anywhere on space station and get great angles and visibility into what's going on in space station.

Speaker 2:          30:13          Yeah,

Speaker 3:          30:14          a basic pack packaging, uh, looks like this, the colorings can be a bit different. Um, we're, we're not working on the actual flight units that don't end up flying next year. And these are a lot of renderings and basic concepts, uh, showing where the batteries going turn signals with something that moves around in a full high anomic motion. How do you convey to crew where it's going, what it's doing with cars were used to turn signals that go left or right, but it's something that can go up, down, left, right forward after, you know, how do you communicate these intentions to crew? So this is a whole area of, uh, research where people are looking at human robot interaction and how do you communicate these things to each other? How do you optimize that relationship of crew and robots working together to achieve greater things?

Speaker 2:          31:03          Yeah,

Speaker 3:          31:03          some of the indicators, it will have a touch screen on the front, uh, together with a speaker, a microphone, a laser pointer, a indicator lights, a lot of different other elements that make asked to be a lot more interactive and certainly a lot more robotic in nature so it can interact with crew and be a true, uh, assistant on the space station

Speaker 3:          31:25          proportion. I mentioned it uses this impeller, um, that, uh, as it turned out was a more efficient means of propulsion inside of the space station. Um, not so great for outside the space station though. Um, some of the nozzles and their location, there is a preferred direction. Uh, you can tell the nozzles on the front and back are a little bit bigger and then you've got more of them in that direction so you can get bigger, uh, forces and motions and forward or aft. Um, as well as better sensing, we have some different cameras, uh, that, um,

Speaker 2:          31:59          [inaudible]

Speaker 3:          32:06          there you go. Some, a video of a concept of how the turn signals are going to operate, uh, on the, uh, aster be computing. Uh, it, unlike spheres, it's going to have three Co uh, cell phone class processors, arm architecture processors capable of doing a lot of competing, uh, uh, high level, mid level and low level processor. Um, that, uh, we'll do all the computing, the low level process or doing a lot of the low level control, allow the GNC work of navigation, the mid level processor doing allow the vision based navigation processing camera, video, um, and then the high level process or dedicated almost entirely to get science research. And it's that high level processor that so running an android operating system where guests, scientists can design apps basically that get the up thing to space station and can operate Astra be in any custom way.

Speaker 3:          32:56          They they like uh, power systems. Uh, it does recharge. It does have a docking station, um, power system, 14 volt batteries for them. That gives it a roughly two to four hour operating time inside the space station, a avionics stack. A lot of these things, uh, as we've learned have been designed to be modular and replaceable. Right? Things break, things get upgraded. Uh, we're close to launching these on space station and the avionics are already outdated, right? So there'll be come a time when we want to update a lot of the avionics, uh, and a hardware. I mentioned a lot of cameras. There are cameras pointing forward and aft, uh, has cam perching cam. Our Three d imaging sensor is very similar to connect or some of the uh, previous smartphone cameras that can give you three d mapping maps of your environment and those are used for purchasing onto hand rails as well as docking onto the a docking station.

Speaker 3:          33:50          Um, psych cam HD camera for visualizing things on the ground that gives, does get stream to a ground, a gooey external sensors, uh, that gives it the imu, the speed Cam. Uh, these actually are all the cameras and their capabilities as I mentioned, flight software. Um, the, uh, the architectures is largely based on Ros, the robot operating system. It's an open source software platform for doing this kind of our robotics research and certainly why they use in, in academia for robotics. And it's what ties together a lot of five software that operates on, on Astro. B.

Speaker 3:          34:30          As I mentioned, uh, all three processors, uh, are running the mid level, low level running Linux, a high level of what running android, um, low level control loop barbering at 100 Hertz, uh, in, in tune with the IMU and a lot of the high rate information, um, uh, system data flow diagram, talking about the way the different processes inside the, uh, Astro beat communicate with each other over an internal network. Um, and then together with the other three units, uh, I will highlight the names as, as the project is called Honeybee, the unique names for each unit. I have been picked out to be a queen bee, a honeybee and Bumblebee. Uh, so riffing on that, a whole team there. Um, and then we've got a whole other set of interesting name for the ground units as well. And I can get into that if you ask.

Speaker 3:          35:20          Um, so here just also showing communication, uh, with ground control stations, uh, both at uh, JSC where they have the mission control center as well as Marshall where they do a lot of the payload commanding. Um, and then our mission operation center here at Nasa Ames. Uh, and then in addition to that, we can ground control stations at guests science facilities. So whether that's at a university, a school, uh, your garage, we can operate Astra beef from a lot of different unique locations. Um, really enabling some rapid design and testing on space station. Again, covering a lot of communication over the network interfaces on space station, the purchasing arm, two degrees of freedom there. Um, that allows it to pan and tilt, uh, its view on a space station.

Speaker 3:          36:08          Uh, more renderings of the purchasing arm. I'm going to go ahead and skip through a lot of these payload layout. Uh, again, very extensible. We've got three, a what we referred to as one, you a payload bays where external hardware can be attached on to spheres and to expand his capability. So you want to put special sensors better as bitter or better audio equipment that can be done using expansion ports as well as its mechanical loading bays there, uh, where you can even utilize more than one for one unit. If you add, if you need more space to do that, does have a docking station where it can I go back just like a Roomba, go back, recharge and then go back out and carry on operations. Uh, that's where it can recharge, communicate, uh, over a hard link down to the ground. Um, uh, you can see a little air tags on, on the uh, uh, docking station there.

Speaker 3:          36:58          One thing I didn't touch on with different approaches to vision based navigation, one is a general sparse mapping where it's looking at different features it sees across ISS, mapping that against a known map, uh, a priori where it matches up different features and that gives it a decent navigation across ISS when it comes to docking onto the docking station. However, it uses a different approach utilizing ar tags, which gives it the better accuracy, uh, of being able to calculate. It's posed and its position with respect to those ar tax on the, on the dock. And in fact we have concepts of being able to put those ar tags in different parts of space station where I guessed scientist might want that a centimeter level accuracy of knowing where the attribute is, um, and different research that calls for that. Uh, and then yet another third approach.

Speaker 3:          37:44          The vision navigation is those three, uh, hazard cameras that can generate three d maps of its environment, um, and do the, uh, uh, docking onto the dock as well as the, uh, uh, hand rails when it comes to purchasing a control station, a gooeys being designed that can operate, uh, not just up the mission control center, but also at our, uh, mission operation center. Um, that gives users access to ask to be on space station. And one of the key features is being able to vary the level of autonomy, right? We can do anything from RC control these things on space station, even with the delay involved with communications, a space station or in a completely automated way kickoff, uh, plans and different things. Uh, uh, where they operating all by themselves on, on space station. So we can vary that, the level of autonomy from beginning to end.

Speaker 3:          38:35          A quick little video of to be operating in our lab. What you're seeing here is actually our granite table, uh, where we can do this kind of testing in our lab were asked to, we can move around in an almost friction free environment. Very similar to how it operates on up on a space station. Um, and like I was talking about earlier with our Gantry Michael Gregory test facility, we have the world's greatest a crane game. While here we have the world's greatest air hockey table. If you guys have played air hockey at the arcades basic same basic concept, we have an air carriage with compress CEO two that forms that cushion of air between that our carriage and there's very flat, very smooth, a granite table that's less than the papers with difference from corner to corner that allows us bias free motion across the table just like you would experience on a space station. And so what you're seeing here is asked to be using its vision based navigation to navigate, uh, across this volume, um, using it's a cameras. You see the camera from, uh, the uh, top a ceiling, uh, giving us an outside observation of where it is in the volume so that we can better characterize, it's built in a navigation. There you see a camera views, uh, from uh, onboard and a what it seen.

Speaker 3:          39:53          Dan's doing a basic eight maneuver there.

Speaker 3:          40:04          And, and one thing you're not hearing on this video is the flapping and the worrying of its motors. And that was actually what a big challenge in designing a free flyer that operates using a blower is keeping its noise level down. As you can imagine, operating on space station could get kind of noisy and you don't want to be living and working in a place that sounds like a factory all day, every day. So they do keep strict limits on the amount of noise you can generate on, on space station. And so, uh, we, uh, from the get go, uh, looked at designing the blowers to operate at certain speeds. And then the flaps not to generate a undue amounts of noise. Um, but certainly a challenge with this type of propulsion. And here you can see it to executing a docking maneuver, uh, using those ar tags I was referring to earlier.

Speaker 2:          41:06          Okay.

Speaker 3:          41:10          I'm going to speed this up a little bit. Get to another section. Ah, I, I talked about the macro gravity test facility, the, the road graders crane game. This is it. So we have this gantry moving around just like you saw earlier with the PSA free flour. We've revamped that facility to be able to test up the, uh, asked to be avionics unit. And this is very important for testing out that vision based navigation on the ground, right where we can have a camera in the loop. Um, when, uh, navigating across a, a environment that's visually similar to a space station. Uh, we do have a simulator that's a now released an open source that has a, a lot of the flight software involved, but uh, it's hard to replace doing a lot of hardware in the loop. Uh, in particular with the camera, uh, in a full six degree of freedom motion, uh, across the volume there.

Speaker 2:          41:58          Yeah.

Speaker 3:          41:58          How do you use aster be? So it's not limited to NASA government agencies. It's available to you guys as, as tax paying citizens. Uh, you have access to this facility on the space station and if you have interesting research, uh, uh, please let me know. We're open to new research. So there is an API being designed that would allow that a guest science to operate on a high level processor as well as anywhere in the ass, Ruby and none of the software being designed on asked to be, um, is deemed safety critical, which allows us to very quickly iterate on the software on Astro B so we can come up with new ideas, updates, pushed them up to the hard Ron space station, uh, with in very little amount of time with um, uh, because it's not safety critical, right? We can iterate, we can afford to fail, we can afford to have mistakes, uh, uh, occasionally.

Speaker 3:          42:46          And so this describes some of the API features, uh, the simulator now released on gay. How about I encourage you guys to check it out? Um, being a facility open to, uh, researchers, uh, we're trying to release as much documentation and a software as possible for other people to take advantage of it. Here's some architecture talking about what the simulator does. Um, simulating a lot of the fights offer stack built into the answer B unit. Uh, and then this shows it talking to the ground control station. Uh, here's some video of it in operation to go with Gazebo, the three d animation. Um, this video unfortunate isn't too detailed. You can kind of see, uh, the code and then a, uh, android emulator operating words, operating the, uh, uh, uh, very hello world type APP, communicating to the rest of the flights after has to be, and then communicating motion commands to the Astro B unit in, in a moment. If I speed it up a little bit, you'll see it motion there on the bottom. It's a little hard to see, but there it is traversing the three d environment there.

Speaker 3:          43:54          Uh, as I said, we have a guest scientist program. Uh, we have a lot of experience from spheres and supporting people using this facility on space station. So fast tracking the process, um, and navigating the ISS payload process of getting real research done on, on space station, uh, different, uh, phases of that kind of a good scientist program. Uh, invite you guys to check it out later on. Just some overview of the different testing facilities we have at NASA ames. We've covered the granted table, the uh, MTTF, the flight line where we built flight hardware, environmental testing, and then of course our mission operations center, which is a, a nice computer lab where we are, uh, interact with the astronauts during the test session on, on the space station. So that's a really cool part of this facility. We get to interact with the astronauts on the space station.

Speaker 3:          44:43          So what are we doing in the future? We're already looking at, uh, a lot of interested users wanting to you as an aster beyond space. You to do some really cool research. Our, there's a group at JSC and looking at RFID logistics tracking. Uh, you can think of ISS as a five bedroom house where the family changes out every six months, right? I certainly lose stuff in my house. It's uh, they do lose things on space station. So logistics, tracking, tracking of different things on space stations that are very important thing. It's something they spend a lot of time on doing. If asked to be, can be designed with a RFID tracker along with tagging of different objects on space station, that can be a big help in that regard. Deep audio analytics, we're working with a bionic Bosh and Astrobotic, uh, at looking at custom Bosh, um, uh, audio sensing that can try to characterize the audio environment and then perhaps even a diagnose and identify off nominal conditions on the space station.

Speaker 3:          45:36          A very useful for a continued operation of, of space station, but certainly an area of research and something. Um, uh, they're very interested in a o two monitors as I referred to earlier. There's people at JC looking at, um, uh, crew radiation exposure, uh, CO2, a three d camera payloads. People want to do three 60 vision, all kinds of really cool research. They're different companies looking at, uh, not just RFID sensors but are afraid the applicator's how'd he go around, uh, uh, tagging different things on space station, uh, advanced a manipulators gimbals arms. How can we build a free flour that's more interactive and more manipulative on its environment, right? How can you get them to doc or a manipulative? And things on, on space station and do and do some real active work. Uh, with advanced docking interfaces. Uh, there's some, uh, researchers looking at Deco, inspired a appendages that can attach onto different things, move things around and affect things in a microgravity environment.

Speaker 3:          46:36          I do some other areas of research that people are looking at formation flight again at dancing, uh, the state of the art in that area. Robotic manipulation, human robot interaction, things I've touched on in the past. And so that, let me first preface this next video. As I mentioned earlier on a stem outreach is a big part of, uh, what we do as well. And uh, right now the, the, the greatest game in town is called zero robotics, led by MIT first operated on this on spheres. Uh, this is a program, well, actually, let me just jump to the video because it does a lot better job explaining this than the Nivea.

Speaker 6:          47:14          A real engineer doesn't answer. Why not? I really engineered answers how we're running these educational playgrounds where kids are getting an experience. Even in middle school of working in a team where they really care about what happens. This is an incredible competition. They got teams all around the world involved programming satellites. We can have kids on the ground, send their codes up to the space station and we can run contests on the space station.

Speaker 2:          47:52          Okay.

Speaker 7:          47:53          You don't have anybody else you can turn to except each other. Welcome to Mit, El Jaleo.

Speaker 2:          48:02          Pardon?

Speaker 6:          48:17          We've got half of high school students grade whatever software they want and it's very risk tolerant. You don't say that normally with a space system. Since we have multiple versions of our code running, it's very important to us to know all the cases. What will work in each and every scenario. Um, I'm a sophomore in high school, so I'm 15 years old. Actually, my birthday was in December, so he's 10 15. When we'd go to Mars, one of the things we would want to do is set up a GPS system. So in this year's game we had them deployed three satellites that would be able to triangulate, just like GPS triangulate. Once these spheres were in space. The only thing going up and down,

Speaker 7:          48:59          let's go ahead for the rock. Okay.

Speaker 8:          49:02          In the game they have to position the GPS system and then grab the things and bring them to an assembly area so that they could actually be control in our strategy is that utilize our quick movement speed to get an early lead and we spend the rest of the game guarding our zone or blocking the o team from putting items in their zone to keep our lead and hopefully win the game. They be crashing into their height.

Speaker 7:          49:26          Sam's that they're supposed to pick up the ones they crashed the eye to move around

Speaker 6:          49:31          the large items which returned the most points. That's the first thing that we started to boring.

Speaker 7:          49:35          We'd the orange defending its space and are running out. If I look at it. Deal. Yeah.

Speaker 6:          49:40          No, never had this brand because a, it's not like one particular thing went wrong. Basically the thing stopped working.

Speaker 7:          49:46          Did teams, it's given some challenges. I address all of that, my code. So I'm not sure what happened to you. We get the final score, Lou one 81 and orange. The greatest part was working with different teams from around the world. I'm from Mexico. Sound no, you know, sister represent and the western of mine you got through language barriers, you got your cultural barriers and you work together to get here. And that is such an amazing accomplishment. And such an example for our world institute global can you did for 40 years or

Speaker 2:          50:30          these are the kids that are going to rock the future.

Speaker 3:          50:42          All right. So, uh, that's zero robotics operating twice a year in the summer with middle school students and uh, in the fall where time with the high school students. Really great program. Um, check it out. Uh, these are our links, more information about spheres and he can be found here. Um, and uh, I'm open to questions.

Speaker 2:          51:04          [inaudible]

Speaker 9:          51:10          um, had a question about the propulsion system. So spheres had CO2 propulsion. Astra B has a compressed well slightly compressed air propulsion propellers. Um, and, uh, obviously, uh, astro be can't be used outside in the space environment where spheres, Ken, which gives it some interesting things. Now Mars is an environment which sort of is a compromise between them, right? It's low g and it's very low atmospheric pressure. Has there been any thinking about, uh, the applicability of an astro be like platform or spheres on Mars, Mars 2020, I understand there's going to have a drone get deployed. Um, it'd be even more cold to deploy it. Uh, spheres or, or an attribute type of platform.

Speaker 3:          51:54          Absolutely. Quick corrections fears can actually operate outside, but you're right, the, uh, compress HIA to, uh, it gives you that thrust or like a behavior that's and very similar to what you would see in a set dedicated satellite, right. That would, that could operate eva, but spheres as they are don't actually operate outside. Um, and they'd actually have some issues operating outside.

Speaker 9:          52:15          Once it was that clip with it, uh, in the Open Bay door of, of the Atlantis was, was that outs,

Speaker 3:          52:23          that was Eric [inaudible]. That was a project out of JC where, uh, they did operate a very similar type of free flour outside of the space shuttle in, in 97. Um, so different project, but certainly a, a similar approach. I think they used a, uh, a different type of code, gaffer proportion, but that wasn't quite spheres. Uh, but you're right with the blower, it's very much limited to Iva type, uh, uh, motion. And um, and so with these iva type free flyers allowed, the future work as far as her box is concerned, is looking at continued iva type behavior. So whether that's I assess a deep space gateway or other deep, deep space spacecraft where we need these kinds of robots to enhance what we can do inside of spacecraft and maintain the space craft for long duration space travel. Um, and that said, there are some technologies that can be advanced here that the benefit, uh, eva type free flowers.

Speaker 3:          53:18          So the navigation, the, um, uh, the algorithms, the vision based navigation, uh, or just some of the technologies that do have some transfer, uh, into, uh, other areas that could part Uva. And then even these types of drones that could operate on Mars. Uh, some of the technology that some of these lenders use to narrow and find where they're going to land on, on, on Mars or another planet, um, are have some very similar algorithms to operate inside of, uh, Astrobotic, uh, doing a lot of these advanced common filter tap awkward and second dd sensor fusions and very quickly, very rapidly fuse together. I'm used vision, uh, uh, satellite information, any information it can, uh, to uh, get accurate and better results. As far as navigation goes,

Speaker 10:         54:06          you said that, uh, all these beers are supposed to be operating in either autonomous mode or RC Moore. So how autonomous is dark is more like, do you specify just point a to point B and then it goes from point a to point B hardware to give the route from 40 to go from point a to point B?

Speaker 3:          54:24          Depends on the researcher. It depends on what you're trying to do on space station. So spheres has had all kinds of algorithms tested out where they have been our c controlled by crew, by ground controllers, but they've also had algorithms on there that does intelligent path planning. Right. How do you, how do you, uh, in real time, uh, learn what kind of obstacles are in front of you and plan out what your trajectory and your, what your path is going to be. A, there's this one really cool video of spheres and operation. Uh, it's on youtube. You can check this out where you have two spheres orbiting each other. Um, uh, and in a perfect, um, uh, uh, formation right there. They're across from each other. And then you have this third, third spheres unit looking like he wants to jump in on, on the hopscotch, right?

Speaker 3:          55:09          And then, uh, and then it jumps in and then now you have three spheres in orbit around each other, perfectly equal distance from each other. And that's showing how you can do real time planning of your trajectory and motion, uh, using completely automated Builtin, um, algorithms, uh, without any control from the outside. So, uh, advancing some of the algorithms needed to do that. And then even more intelligent type, uh, automation algorithms that try to do a lab diagnostics, a lot of, um, identifying the environment, giving crew, uh, advanced warning on different things. Just trying to be a good citizen as far as, uh, being a, a little robot on, on space station. So, and then giving, giving a face to a smart environment. That's another big area of research is trying to generate these smart habitats where, uh, you're trying to get a lot of information from not just, uh, the, uh, environment and built in sensors, but also sensors on this free flour and then interact with crew, right? So, uh, you can generate an environment that's very intelligent and I can do a lot of things without a hands on maintenance.

Speaker 10:         56:17          Oh, the propulsion of us. Here's this compressed you to, uh, does ISS has the ability to co create

Speaker 11:         56:24          and compress and recharge or does it have to those kinds of sites or do they have to come up from the ground?

Speaker 3:          56:29          Uh, so the ability to recycle CO2 and to a way that's then compress and reuse the boys. Actually an area of research. I know there are researchers looking at doing exactly that. It's not a routine thing, at least not yet on, on space station. I'm not something spheres utilizes a with spheres. Uh, over the last 10 years, my team's gotten pretty good at a refilling the Sio two tanks. As it turns out, there's a certain set of tanks we use, uh, that are, uh, safety rated and then, uh, they get brought back from space station refilled here at our facility. And we relaunch, I'm, every time I talk to a consumable resource that gets you stop, we'll go through maybe two or three tanks during a test session. Um, and, uh, so it's a consumable, uh, and uh, the [inaudible] to expel as it turns out, uh, isn't a too harmful to, to crew, hey, it's, it's well within limits of what can get scrubbed out of the environment. So it turned out to be a really great that proportion for spheres. And, uh, but yeah, I have heard there are other researchers looking at recycling and pulling the CO2 from the environment back into a way that's then we usable. Um, certainly in situ resource utilization is a very big area that we're going to need to make advances in. I had to go to Mars and other deep space destination

Speaker 11:         57:44          [inaudible].