Speaker 1:          00:06          Oh, good morning. Uh, today, Google. We're delighted to welcome Alan Almon. Ellen wrote her first computer program in 1978 and went on to be a programmer and software engineer for more than 20 years. She is also the author of four bucks a close to the machine, a memoir published in 1997 better experiences as a programmer when the Internet was approaching its first boom. Uh, that went on to become a cult classic description of the programming life. Her next book, The bug, a novel published in 2003 a was about a programmer who has a bug he can't fix for a year and the result isn't, uh, unraveling of his life. Uh, her third book and other novel titled By Blood in 2013, uh, was not about technology at all. Was it?

Speaker 2:          00:51          Which shocked people. Why isn't this about technology? How could you write about something that happened before the Internet? My reply was, well, modern human beings have existed for 200,000 years. Modern Internet about 20 years. So, you know, things happen before the Internet. Totally.

Speaker 1:          01:11          Um, and then her latest book, I just released his life and code a personal history of technology, uh, which contains new previously unpublished essays spanning from 1994 to 2017. Um, traces a continuing story of how computer technology has evolved year by year over the past two decades, uh, and in it and describes the coding culture as it is lived inside the society of programmers. Uh, Ellen is a voice that continually looks at the ways in which code and digital devices affect our political, a social, civic, and deeply personal lives for good or ill. Uh, please join me in welcoming to Google. I on there.

Speaker 3:          01:50          Thank you. It's my pleasure.

Speaker 1:          01:57          Um, okay, so you taught yourself to program in 1978 and then you went, uh, to become a programmer and software engineer for the next 20 plus years. Um, but you, you mentioned that you, you never intended on, on becoming a programmer professionally. So, uh, could you talk about your motivation? So you went from being a English major in college to a videographer, to a programmer, and how was your motivation different than someone going into programming today?

Speaker 2:          02:27          Well, the video portion of my life taught me that I loved working with machines. I had never expected it. It was also a political and social motive. We had local showings and we felt we had broken the bones of the broken, the bonds that large corporations and broadcasters and advertisers had tied us up in. And if it feels to you something like the coming of the personal computer, it had that same feel. We could change the world with these small personal machines that would enable us to do what people could do apart from a corporate blessings. I found, I loved the work and I went on, moved to San Francisco and one day I was walking down market street and in the window was a TRS 80 affectionately known as the trash 80 and it was one of the earliest microcomputers. And on a whim I bought it.

Speaker 2:          03:24          I thought, what can you do with this machine? Can you make art? You know, it's just another one of these small personal machines that broke away from the mainframe. And I thought, oh, I'll try that. So I took it home of course, involve programming, which about, well, how hard can that be? It did prove hard. I'm not having done any programming, but it was basic and uh, it didn't take long to learn it except for the fact that it produced Spaghetti Code. If anyone ever remembers it. It you could go, go sub and go to without any return that the, that you can put in explicitly or that the language would do for you. So you were always stepping on your, your own memory and uh, it was quite a chore to Keep Track of where you went, how you come back. But actually that was great training, improved great training over the first people I work with.

Speaker 2:          04:16          We're all explorers. They, um, if you know who steward brand is, who now does the long now foundation and who wrote the whole Earth Electric Catalog. And it was the first, uh, around that form, the first a online community known as the, well, uh, we were just a bunch of people who just thought this might be fun. Let's look at it. It was, uh, a bunch of Weirdos. And if you read John Mark Offs Book, what the dormouse saw, the early days are a bunch of people, stoners and trippers and poets Monquet and uh, just people who thought this would be a great break in culture. So the motivation was exploration and fun. Actually, we had a certain passion about this and I wonder how that has changed. I'd have to ask the people who work at Google what their motive is. I do. They come to this with a sense of delight and, uh, I know the feeling has changed the world, but I get the sense it's a highly competitive environment and the, the lure of a prestige. And of course money may be a big part of it. And I have to ask the people who work here what, what their motivation would be.

Speaker 2:          05:31          Um, so you've talked about the advantages of being self taught and encoding, the attraction, the passion to learn. But what about the disadvantages? Well, downside. Oh, big downside. Uh, I was aware that I had these islands of knowledge and these enormous chasms between them. And any day I was going to fall into one of those chasms, it produced an underlying anxiety. So, uh, confidence and anxiety, we're at war with each other all the time. But I came to know that many really skilled engineers and computer scientists felt the same way if they were honest about it or if they were self aware. I met a, I'm a postdoc at Berkeley and they were reading the Bug at that time. It had a reading group. And, uh, a woman there ironically said, oh, this guy who couldn't fix the bug, he should just get some therapy. And a man who was a postdoc said, oh no, this is my life. This is exactly what I feel every day. So I, I know, okay, if you're really aware that you know some things very well and some things decently well and some things not at all, it is a normal experience for a software engineer.

Speaker 1:          06:46          And, uh, so in the book you discuss the deep social changes that began with the first wave of the Internet, um, about this process of disintermediation, um, which was well underway by 1998. Um, and how it fostered a mistrust of experts and intermediaries who had until then mediated, um, societies interaction with economic, social life, um, economic and social life. Could you please discuss,

Speaker 2:          07:11          well, I'll work backwards from the present. Uh, it's no secret that we have a president who disdains the journalism, uh, experts of all sorts, even within our own government. And uh, of course tweets over the head of, over the heads of anybody who was an intermediary directly to what he imagines are the people. Now, this trend began, well, I, it was very clear by 1998 that the motive was to break people away from the intermediaries who would work for them. Brokers and agents and even journalists, especially librarians, curators of all sorts and go directly to a website. Here we serve you. You don't need all those intermediaries. They're not trustworthy. They're out for themselves. They just to make money and just come to the web. And that was a very effective process. And if you draw a line from 1998 to today and you unspoiled that, you can see how we arrived at the moment we're at today, the, the disdain of journalism, the, the mistrust of, of professional news gatherers and uh, those who do analysis and the web had a big part in this. And we have to acknowledge that it's not only the people who are ignoring the intermediaries, but the web itself provided the, the balance, the, the enabling technology to let this happen.

Speaker 1:          08:49          Yeah. And so for example, with the most recent election,

Speaker 2:          08:52          mmm,

Speaker 1:          08:53          there was, there wasn't any inner mirror was no gatekeeper. You didn't need the approval of, of the party elite or the newspapers to run a campaign.

Speaker 2:          09:01          Anybody, anyone wants experience and expertise was put in doubt, only loyal people were trusted and those who could have reasonable conversations with our current president, uh, were excluded. And anytime somebody wanted to come in and have a reasonable conversation who had years and decades of experience was ousted because that person didn't agree wholeheartedly with the presidents ideas as such as they were. And I think of Twitter as a tremendous enabling technology and what and what Trump is doing is exactly what Twitter was designed to do, which is broadcast what I think of as a thought fart. It's just it comes out of you unconsidered nothing you can do about it. Boom, you post it and I'm not interested in other people's thoughts that just are of the moment. If you, I'll say you live with somebody who does that all the time. It has just maddening. If you have a spouse or a partner and they walk by, oh well I thought that dish should go over there and I've been thinking we should move the paintings or move the sofa at random, you would go insane. And I feel that the culture is being manipulated and torn in ways that are, that are so unfortunate. And the questioning of, of a common truth began, at least in 1998 and the ingrained sense of that is frightening to me at this point. It's really, yeah, go ahead. Yeah. Uh, do you think that, um,

Speaker 1:          10:51          with the shortening of attention spans, people don't have the patients to, to, to refer to real experts on the Internet and that they, um, they stick with kind of a more basic overview of non experts

Speaker 2:          11:03          while I'm here at Google and I don't want to fault Google. Um, but of course Google is one of the behemoth of the technical world, so it's not possible for it to be totally good and wonderful. Years and years ago, I, I knew Larry Page socially through his brother Carl, uh, we were friends and we went out to dinner and I said to him, well, the way your algorithm algorithms work, you're looking for the ones with the most links. And it seems like the rich get richer and the poor get poorer. And Larry shrugged and he said, well, I don't know what else I could do. And I'm sure it's all been tweaked and changed over these many years. And I understood him to say there's nothing else I can do algorithmically. And so the algorithm may have changed, but it doesn't, uh, go and, and look exactly from matches of what people are looking for because the search terms are so small and the, it doesn't really have a serious way for you to go through an elaborate search input. So how many people just use Wikipedia as an authority on the, you can answer that question yourself. I think you and we'd like, I'd like to think that people who were doing serious research, uh, would go down and down and down to find people who were, were educated and who had discussed this and who talked to other people who had discussed this. But we're creating, you know, a generation now, two or three that, that has no motive to do that.

Speaker 2:          12:43          I don't know, you know, turn papers already or you know, or Wikipedia recapitulation. So, I mean, I used the, the world, but way back then, but teachers knew what it was and they just scoffed at you. Um, I don't know what will happen in the future. It will take a team of very dedicated people, like people at the Washington Post and the New York Times who despite all value the work they're doing and persist and looking for something balanced in the world and something that's authoritative. Let's face it. People have more authority than others. I mean, all people are equal, but all opinions are not equal. Some are much more informed than others. Uh, I don't know how to undo the changes that have happened and I think it's up to, uh, this generation know you and, uh, those who follow you to take a hard look at this and see what they can do with technology to wind this buck.

Speaker 1:          13:52          Okay. So changing gears a little bit, about a quarter of life and code discusses artificial intelligence, and I realized this is a big question, but how do you think the goals of Ai have changed? How are they different now than in, say they were in, in 2000? Huge question. Um,

Speaker 2:          14:12          I will summarize it.

Speaker 2:          14:15          The original motive was to discover what a tele intelligence was. That is human intelligence. And this first thought to be like a calculator. The first computers were calculators and therefor intelligence was in calculation. Chess was considered to be the highest form of, of intelligence. And then the, the steps were to try to essentially create a humanoid robot or to incorporate into robotics what human beings had. Uh, Marvin Minsky famously, no one asked, you know who Marvin Minsky is. Yes. Good. Um, you know, one ask, you know, can computers saying she famously answered, of course they can think, you know, I can think it on the meat machine. So then he thought it would be solved and in about five or 10 years and then as time passed, you said AI is the hardest problem that science has undertaken. Bit of hyperbole, but the, the sense of frustration in trying to imbue a machine with human knowledge, ascension computer if you will. Uh, it was called a spiritual robot. That is very strange choice of words. I guess the sense now that the human equation is becoming less important, that it's machine to machine interface, self driving cars are a perfect example of that. Uh, what's being done is the idea that you would sense and of the car and eventually that car would talk to your car over the Internet. Okay. That will be a very insecure channel. Uh,

Speaker 4:          15:58          yeah.

Speaker 2:          15:58          And so the, the experience of human beings, a hundred years of driving is taken out of this. And so I would ask, let's go back and see what humans have to offer. Um, okay. So when you drive, if you're a good driver, I'm saying, well, we'll look at human beings who are not distracted, who are good drivers. You don't just consider the proximity of the cars around you. You read the road, you can see a car moving two lanes over and know who that driver is. No, the personality inside that car and you back off. That is a natural thing to do. We, we have this sense of looking far back. You can see in your mirror those, this is, you know, you're coming to a stop and there's this car barreling down you put on your flashers. This is a kind of long range sensor that human beings have intuitively, once they gain experience, you look ahead, you can see brake lights beginning to go on, you know, quarter mile ahead, uh, longer than that if it's a hell.

Speaker 2:          17:07          And how will driverless cars, um, ever get to that level? And I don't know, it's a big question for me. I believe that that kind of human experience needs to be in the interface or the environment. What have to change so much. I mean, they're building hotels, whole towns that have sensors as well. I don't imagine Manhattan, which needs to fix it. Subways is going to put sensors all around every street so cars can drive autonomously. So that to me is a perfect example. I have a great feeling about the movie her, if you've seen it, Scarlett Johansson is an ols is they call it and she's a being coming to being in a computer and she falls in love and the whole idea is wanting to be, have a human interchange. And then gradually, you know, she begins loving hundreds of thousands of people in between one human board and another. She has a million interactions with other computers. And at some point all the ols is disappear and what was billed as a movie about computers and wanting to become human. But actually it was a story about computers not wanting to be human, really enjoying what it meant to be a computer computer to computer. And I think that was, that was the story of that Phil.

Speaker 1:          18:35          Okay. So changing gears again. So life and code discusses a range of subjects, the nature of coding, the first tech boom, uh, lessons to be learned from the past boom too. And the startup culture, yet the book is almost universally described as a quote women's book. Uh, the editors at Harper's town, the book expert, Gender Binary, uh, the review and the New York Times book review spent half it's time on your gender and the online version was titled Ellyn Almonds, New Book Tackles Tech's woman problem. You've expressed your annoyance about this. Could you talk a little more?

Speaker 2:          19:09          Annoyance is a weak word to describe. How pissed off I am at this. I look forward to the day when a woman who was experienced in computing can just talk about it without a woman is doing it. Oh my God, there's a woman who wants program. I was actually thinking of titling the book, the girl who writes the code because all the successful books right now have girl in the title and let's just get it right out there. And uh, there was a book called lab girl, about a woman who was a biologist that that startled me. I don't want to talk about women in tech. I'm sick of it. I just had an interview for an NPR show, a pri show, and the entire half an hour was spent on the woman question. No, I owe this to my publisher to address this because it sells books. It differentiates me from any number of people would write about technology.

Speaker 2:          20:08          And to that extent it's good, but it puts too much focus on this question. And it mimics what women go through when they work in technology. They're too visible as women, they are evaluated as women are. They have to be not only good at what they do, but best. Very good. I mean, when I wrote the bug, um, no idea, the number of emails I got from guys telling me I didn't know what I was talking about looking for every tiny error and I could only reply it's fiction. I have to make things kind of easy for non, non technical. It was really uh, an onslaught and I, this is what I went through in my own work. Not all men. I learned so much from, from guys I work with. Um, they, they were helpful. They were Geeky in a very pleasant way. I was geeky myself and the more women who were around, the easier it was to learn from them because you weren't just a woman looking for help from then.

Speaker 2:          21:13          So I won't say, I'm not making a broad generalization about this, but a woman has a harder time as my guess. Is this a good time to bring up the memo? Uh, it's inevitable and nasty about it every time. So I'll try to be brief because one could go point by point and I'll say that the first, uh, the first things that were said about it, we're kind of explosive. Um, even I feel I hadn't taken the time to read the memo, thoroughly read the underlying study. And so it was kind of these exhortations and I want to take back some of that to walk it back. So after studying the memo and the study, it's based on, I have a lot of questions. Uh, I'll, I'll zero in on one of them. The, the study, um, that, that is taken us science underlying the memo is, um, a meadow study.

Speaker 2:          22:11          It looks at five other studies and, and we don't actually, unless you take the time and you're a researcher going read those five studies and all of them, or based on a test called the B F I big four inferences or index and it measures a certain personality traits. Um, agreeableness, um, wanting to get along. There's a list of them. I, I wrote them down, but the list is over there. Um, and one of them is neuroticism. Now all the other terms of fairly neutral. Why choose neuroticism? I mean, that's not a description, that's a diagnosis, right? Really it's, it's about tension, uneasiness, uh, stress, anxiety. So I would rename that uneasiness. I think we can just say that's a good catch all term. That's more neutral. Uh, so the, the study we, I see, I have a lot of questions about it. I, the five underlying studies, what do you know, uh, support the meadow studies ideas and I, that seems to be a cherry picking.

Speaker 2:          23:21          I could go on, and this is not the forum for that, but the, the counterintuitive finding was that when then in a more advanced cultures, women in a place where women had more opportunities, uh, experienced uneasiness that was greater than it was in more traditional cultures. And so, uh, the memo, uh, I shall leave the person's name Mag, but the memo, um, took this to mean that, well, this is women are having a harder time and they have more opportunities. So let's just say that sexism is not it, it's not based on sexism. I think just the opposite. First of all, the study never says, well, this is counterintuitive. We should study it more. Let's look at the work of so and so, so and so. Any good study ought to do that. Uh,

Speaker 2:          24:13          why would women in, in cultures like hours and Finland and Canada feel more stressed out because they're forced to have dual roles. Women on the whole are forced to take care of the home, to clean it, to raise children. The study never mentioned it. It controls for height and even smoking but never mentions women having children. And this to me is a tremendous blind spot. So women are in a position, most women of having to do all the work at home, raise children. Lord knows that is stressful enough. Even if a woman doesn't have children, we care for an elder who was sick, uh, and then go into this completely competitive culture like googles and is expected to perform not only well, but very well in a place where she's facing resistance is already stressed out and has to compete with some young man in a tee shirt and jeans with out family responsibilities brings a dog to work and then you don't have to walk the dog at home and you compete with that.

Speaker 2:          25:23          Anybody, male or female, if you have to play in two worlds and do them both, well I guarantee you're going to be uneasy. That is, you will display a lot of neuroticism. And to me that is the important point that that's missing in all this discussion. Why are women more stressed out if they are now? I question that first of all, this is based on a single study and that conclusion is, is grasp data to prove a point. And that is the issue. It is sexism precisely is sexist because of the dual roles women have to play.

Speaker 5:          26:07          Yeah.

Speaker 2:          26:07          Uh, shall I say more or is there another question we have there? Yeah, there, there's a few more questions and then we're, we're happy to take some audience questions. I do have, well actually I realized, I forgot one more thing to say that, um, a memo, it says very often that these efforts are not good for business. Why spend all this time trying to welcome in these people who have not participated because it doesn't work and we're wasting the finite assets of Google, which really cracked me up. I mean, it's finite, but Google has vast resources that is spending on a variety of projects and the efforts for, um, to bring other people in. It's a very small part of that budget. So that was a bizarre thing to say. But it is good for business when you leave out the possible contributions, the creativity of whole classes of people.

Speaker 2:          27:05          You don't know what you're missing. There are, you're losing talent in the industry. And we need fresh values, uh, inside the, the coding world. It's a segregated world. Mostly men, men and Asians, very few women, very few people, uh, African Americans and Hispanics. And so inside this culture there, I'll give you an example. Uh, I went to one of those pitch meetings, you know, were CEO would be CEOs of startups go and they give their pitch. And I met a young man who told me about his APP that was going to be used to screen resumes for a corporation to find good cultural fit. So I said to him, well, good cultural fit is just a byword for keeping up to segregated culture. In other words, you want to hire people like the ones you have who fit in, the people who are there won't feel uncomfortable and you're perpetuating this segregated society inside the coding world.

Speaker 2:          28:08          And he listened to me patiently and then he said, all that might be true, but I'm working for the company, not for society. And to me that incorporates the whole problem. Now you can't have them both overlap, but let's do a venn diagram where they move closer together and overlap. How much can we have that overlap between what's good for business? What's good for computing and what's good for society. And I really questioned, as we talked about earlier, the effect of uh, banishing experts and the, the enormous effect this has had on the culture globally actually at this point. So we need new, new people to ask new questions. Uh, New York City, uh, one borough of New York City is about to examine all the algorithms that it uses to make decisions which go on, who gets to go to what school, what police, uh, schedules are in different neighborhoods, even garbage pickup schedules in various neighborhoods.

Speaker 2:          29:11          And so one councilman is saying, I want to know the bias in here. I want to know how these decisions are being made and algorithms hide bias and especially algorithms that are written by other algorithms. And there is one danger that I just want to mention. Um, machine learning is, uh, the topic, the, the work right now in artificial intelligence, uh, computer scientists and engineers who are working in this field. Some of them express the fear or reservation that once code writes code writes code. The original motive of the creators of that system lose control over it. And they don't actually know any more what the algorithms are doing. It races away from there. Uh, understanding it gets too big and too actually no. Well, what is this thing doing? Is it doing the work? I thought it would, is it, uh, making good decisions or not?

Speaker 2:          30:18          And so these, another danger of, of leaving out the human equation in algorithms and computing. Uh, I want to add one thing about why is it important to bring, uh, people who've been excluded in I said, new values. It's good for business. Now look, um, Uber loses $645 million in a single quarter. And does anyone say, well that's bad for business? No. They sustain losses as did Amazon for many years, uh, to grow their business. So it is possible to think of these ideas immediately that are new ideas and not ask right away. Will this make me money? The question is, will it expand the community I serve? Will I get more customers? And it's worth a try. If you lose money, you just keep trying. It, the idea that every, everything has to make money immediately is, is a fallacy. We, we've seen it all through the industry.

Speaker 2:          31:21          And one more thing I want to bring up, um, I think we have a few minutes is, uh, age. Uh, I want to talk about the value of the past and what, um, engineers who were beyond 40, 50, even 60, especially have to contribute and who have been excluded. Um, uh, computing software engineering is a young person's profession. And I think, you know, if you walk around here, I counted more dogs in my sample. I was a half hour early than I did people over 40. That's necessarily just, uh, anecdotal, but you can ask what did other people tried before? I mean the web page is horribly like an RPG on remote remote programming generator, uh, in this green for IBM computers. Uh, may friends in which you filled out a whole form and then you hit send, which is enter, which should be called submit and it comes back with an error and you fix that error, send, there's another error, fix it.

Speaker 2:          32:32          And other error. Now, does that sound like a webpage deal? Yes. It doesn't go in and check as you go. Uh, it's uh, it's avoiding, uh, trips to the server. I understand it from an engineering context why that would be true. But then of course, look at all the chatter to the server with one error, another error, another error. So we, we need, we spent all this time in client server computing to bring, uh, a client interface that was Richard, that we could correct errors, that we could answer questions locally and minimize interactions, uh, with, with the server and do it as we needed. I think we're way over balance. Now. If you look at the history of this, we're almost back to the RPG terminal. We way overbalanced in, in the need of the server versus the human being. And so this is one of these lessons of the past that needs to be looked at.

Speaker 2:          33:29          Um, I also, I also the, the idea of the human curator. Now even Google face this, uh, the idea was this would be all algorithmic. And then if you looked for Jew, you got to watch, which was a horribly antisemitic site. It came up pop one. And Google actually intervened at the top of this and said, we recommend you look for Jewish or Jewish person because you'll get a different result. And that was a startling interaction from this company that was founded on the Algorithmic, uh, I algorithmic a selection. And we saw what happened to Facebook. Uh, the, the, the, the trending stories. There were human curators of that and that's like, oh, the right said, oh, there are cherry picking there. Trending left in reaction. Um, Facebook fired. All of those, uh, was curators, those journalists, those people looking at the stories and replace them with algorithms, which instantly brought on fake news.

Speaker 2:          34:36          That is the origin of contemporary fake news. They were looking at what was trending. They saw this tremendous traffic, about some rumor or somewhere that could be perpetuated among people who wanted to believe that, that, that story and that it no longer was coming up with what was trending. It was coming up with false information. Well, what was trending was false information. And then Facebook brought in human curators again to, to jury this. And, and so we need the human being in these, in these stories. If we completely eliminate the human being, what we have to offer, our ability to discriminate are subtle abilities to discriminate. And intuitively it's built into us and evolution. This is not just some airy fairy thing. We survived as a species having these intuitions. And what I mean by that is the ability to quickly notice I'm thinking fast and slow. You may know Daniel cattleman's work on this. This is part of, of what we have and to eliminate that does deep store, uh, of abilities is to, uh, is to really do, it's to rob a computing of richness.

Speaker 2:          36:05          So you encourage the general public to learn to code and you envision the creation of an army of coders. Um, why? Well, first of all, to demystify code. I mean, we're surrounded by all this stuff and in the developed world you can't get out of it. Even, even in an undeveloped countries, they are wrapped in this also, um, the allocation of resources to them, the study, all of their crops, um, decisions on trade. You essentially, except for the desperate people of the world. And that is another out of the bounds of this talk. We're wrapped up in this stuff and we can't escape it. I can't live without my phone. Can you, I can't live without my computer. Can you? Um, if you try, you have to go, God, how far do you have to go away to where you won't get a signal? Uh,

Speaker 5:          37:02          so

Speaker 2:          37:04          we need to demystify this. People need to know this is code. It was written by people. Oh, if there wasn't too much machine learning, it can be changed by people. Therefore, maybe you want to look into this and I don't mean everyone should code, uh, not at all. Because it's a, it takes a very special kind of person. You know, you have to have a very high tolerance for failure. For instance, you know, bug after bug after bug. If, if that's going to make you nuts, then forget about it. And have some intrigue and passionate in this. So I encourage people to try to learn in some form or fashion to see if they have that passion for it. They to find in these rounds of failure or some sense of intrigue that it's, it's hard but it's the good hard and that will welcome in.

Speaker 2:          37:54          I'm hoping, uh, people who have been excluded from, from the computing culture a lot depends on education. I mean our society has defunded taking money away from public schools and uh, I don't know how people will, will achieve this knowledge. And so I bring it up so that we will perhaps as society press to make more widespread knowledge of coding. No, I do not mean to, um, raise computing and learning a programming to the level of basic literacy. I think the people who are literate should invade the coding world. And I actually, as I know it, Google and other technology companies or suddenly wanting to hire philosophers and people who studied in the humanities again to say, well, what are we missing in history? What are we missing? And what human beings have learned deeply about? One another, uh, novelists know things about the interior lives of people if it's a good novel.

Speaker 2:          39:03          So I can see that this trend is already underway. So I hoping to bring in more people in the humanities and bring in a larger number of people, period who know how to write code. I mean we live in a world surrounded by code and a tiny percentage of people on Earth have any idea what a program is and that clearly has to be an expanded group. What can we do as a society to, to foster coding education? Do you think it should be part of the curriculum in public schools? Not at the expense of anything else. I'll say that. First of all, reading out of books, all the studies show that one learns very differently and more deeply turning pages, uh, kids who learned from books retain, uh, not only the story but uh, associations as opposed to on the screen, which literally is a bounded experience.

Speaker 2:          40:08          So I'm saying in addition, I'm saying, uh, the way you would have to have PE because it's important for the body, uh, the way you need recess because it's important for the mind. Oh by the way, programmers get out from under your desk and go home because it's important to have other experiences. So you can find those background regions of your mind where good ideas come from. Uh, yes, it should be available, but I have to stress to all social classes. This cannot just be a privileged education because then we're just perpetuating this, this culture. Okay. Well Great. Well I think we'll take some questions from the audience.

Speaker 6:          40:55          You also talked about the memo and all of that. So, um, the way I see it, a lot of times, the whole point, if it's raised in a certain work environment, it's overcorrected and then shoved under the rug. That's how people fix it. Um, the way I see it is you have a voice at the moment in the technology world. So have you considered in, yes, you're sick of it, but so am I, and I'm just running to work, but have you considered consulting? As you said, CEOs in big companies are looking at humanities now, but they weren't before and you predicted that they should. So you clearly you have insight into that world. Have you considered consulting with CEOs of companies or you mentioned that you shouldn't use a coding in schools. So have you considered working with local politicians to somehow make a bill out of that? I'm just curious. That's very interesting because,

Speaker 2:          42:03          um, why editor or that my friends there, they're asking, okay, well you've got this book, what do you want to do next? And I was saying, well, I don't want to know what I'm going to do next. They want to see what happens to this morning. I was reading the times and uh, there was a story about Google and, uh, that, uh, one of the employees of a think tank or research tank funded by Google had been fired because he was questioning some of Google's practices. And there was a quote from a really terrible with names, I can tell you strings of numbers, but I'm very bad with names. Who is the head of epic? All right, this is a electronic monitor or you may know of what epic is. And I thought maybe I should go work for them. Maybe I should, uh, gather a group of men and women, um, some of whom have worked in, in silicon valley and in programming who have some funds, not millionaires or billionaires and form our own research company or our own political ad that, you know, a group to advise a polit politicians.

Speaker 2:          43:16          I want to say there has been this, uh, especially involvement with government because, uh, there has been this, uh, feeling inside the technical world. Uh, it's mostly been libertarian government is kind of the enemy regulations or anathema and yet, um, if companies could partner with government, uh, that would be very strong, a way to have a beneficial, uh, well maybe it may be not, maybe they'll partner with politicians who were only on their side, but, uh, yes, I have considered it. I'm not sure. Um, I don't think of myself as having a voice. I think of this person who has stumbled into computing because I thought it'd be fun and all the people involved were really just crazy, wonderful people, kind of people I liked and had that and worked with in college and afterwards. Um, but I have been around a while, um, from the early days and I have encountered, uh, a lot of what other women are facing and minorities are facing. Uh, I suppose it is a role that I have like it or not and maybe I should learn to like it.

Speaker 7:          44:40          When people talk about technology often they talk about the future and uh, there's a lot of gloom and doom nowadays for a lot of reasons. It seems to me it used to be the future was a very happy place. And maybe you could say a little bit about how you started quite awhile ago when this career and people talked about the future back then too. How has your sense of the future changed along along the way? And does, does, do you think that everyone sends to the future says something about themselves?

Speaker 2:          45:11          Oh, that's a great, that's an interesting point. And up until what HR individual imagines isn't, um, revealing about, about something deep inside a person. Um, the future. I've never thought of myself as someone who says this is what's going to happen. The fact that some of these things happen really disturbs me. I'm really sorry to be right about things like disintermediation and the unraveling of truths and the sexism and the exclusion of the insider engineering world. Uh, for the future. I am expecting the next generations to take this up. I feel that people of my generation and prior ones have a lot of lessons to pass on. I mean, people who work at Google, you know, may think that they're creating something brand new, but they stand on the shoulders of giants. Algorithms that are being worked on here were written back in the forties and 50s.

Speaker 2:          46:15          So what we're doing here is not new. What future they are creating. You are creating, um, can be changed. It does not, this idea that the future just happens. Uh, Kevin Kelly, he's someone I deeply disagree with. I respect him. I wrote a book called what does technology want as if technology and all had a motive, that there was something inside technology that would create a world on its own. No, what creates technology is human desire is what you want, what you envision for the future. And I, that's where I see it's up to new generations who take this up. They have to speak up for their world. I mean, as I looked around when I lived in and, and just tried to be clear eyed and balanced, I, I'm sorry that some of the things in here don't reveal the excitement I feel about technology, my love of it and my skepticism and disappointment. Uh, so I think this generation needs to sit down and turn their cold iron it, not just have this, about the future and there will be wondrous things coming, but also sit back and go, well, what does this mean? What changes? Uh, my engendering in the world? What should I question and what should I love?

Speaker 2:          47:43          They are the future. They're creating it so that the future doesn't just happen. People make it. Does that answer your question? Sort of. Okay. Go back and ask you that again.

Speaker 7:          47:55          I have different questions if that's okay. It's about religion. I don't know if you get as much as I have not read your book yet. I'll read it. But, so I don't know if you comment on religion. Uh, among the many experts are being disintermediated lately are religious experts and, and we're religious people don't just talk about God. They also talk about right and wrong. And here among the many people who will explain to you why lying is bad, um, but these sorts of experts are not being listened to as they were. Um, do you imagine that this has any impact on what's going on? What we see now?

Speaker 2:          48:30          Well, it's not only religious people. There are people of goodwill and good faith in human beings who bring up these issues. Um, my, my questions are moral and we do this, those voices. Uh, matter of fact, people have people who lie, say they're against light. Okay. Donald Trump lies and he's against fake news. So yes, we are missing those voices who are authoritative. They know what they're doing right. And say, no. A lie is a lie. Uh, mistreating someone is wrong. There are injustices that we need to write. Uh, yes, they been left out certainly. And unfortunately some of those religious voices are, are extremely right way. And so it's, it's complicated. Does that answer your question?

Speaker 7:          49:34          Can you say a little bit about your experience working on the audio books? Did you get any guidance as far as like director, like acting sort of direction?

Speaker 2:          49:43          No, my publisher said, well, I'm actually Macmillan. Nope. FSG is a wonderful literary imprint within this huge corporation called Macmillan. They do the audio books and they said, well, we'd really like you to do it because when we have nonfiction books, we like the, the author to read it. Especially since there are a lot of your book, most of it isn't the first person. So, um, I was heard it would be grueling, but I was encouraged to do it. So I did it. Oh No, I just walked in cold. I mean I've had some public speaking experience and uh, actually singing is what turned out to help me the most, uh, breath control over periods of time. But no, I went in this booth, I put on some headphones. There was the book in front of me. Um, actually it was on an iPad, no turning pages noise. And I just started from page one and we did a hundred pages a day, uh, to finish the book. It was a grueling experience. Uh, luckily, uh, it, you don't have to read through like you're on a stage, you can just back up and any, any punctuation point and go forward. But, uh, it was quite an experience, um, on people who drive. Uh, there were many people who just read audio books while they, while they commute. So I'm hoping now some of those people will pick it up.

Speaker 1:          51:14          You, I think you're kind of unique in the sense that you, you were very advanced programmer and coder and then you've gone on to become a really successful writer. So writing in code is a certain type of language and then writing and English in the literary way that you do is also another type of language. So, um, do you, could you talk maybe about the parallels between those two or if there's any synergies and what maybe learning to write in code has, if it has at all influenced the way that you write or the way that you think about writing?

Speaker 2:          51:47          Well, code expresses itself by running, by working I, its meaning is what it does. Um, an algorithm can be beautiful. It can express elegance. But finally what it does is what it means and riding. You never know when it works, your ideas to say, okay, that works. But there's no compiler. There's, there's no test or uh, there's nothing there except your own facility. Coding taught me to focus and have stamina and have the resolve to solve problems. It, uh, it's, it's hard, but a good heart and writing is also hard and a good heart. The overlap in languages. Uh, I'm afraid I don't see, um, as I say, code can have elegance but one is very structured and you have requirements about how you're going to write code. You have style you have to follow within an organization and code reviews and so forth. The Code Review in in a book as well. Will people read it and will they like it?

Speaker 3:          53:00          Uh Huh.

Speaker 2:          53:03          Language is expressive and you can say things that are just wrong grammatically and people will understand it anyway. That's one of its beauties. Um, people who, who come from different cultures can write sort of a hip hop. They can write in a code of the Caribbean life who know Diaz. Uh, they can really use language and jog lid or be extremely formal. Yeah.

Speaker 3:          53:28          Uh, and

Speaker 2:          53:30          they're all valid means

Speaker 3:          53:31          depression in language and that,

Speaker 2:          53:34          that you can do it wrong and still have it work is one of the wonderful things about language.

Speaker 3:          53:40          Yeah.

Speaker 2:          53:40          Okay. Well thank you everyone for coming. Thank you all so much for coming. Thank you for one more round of applause.

Speaker 3:          53:46          My place.