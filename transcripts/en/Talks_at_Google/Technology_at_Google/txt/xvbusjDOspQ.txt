Speaker 1:          00:00:05       Thank you very much. It's a pleasure to be back here. Thank you for coming. Why don't you start by telling us about about the book. I mean, they're, in some ways, my, um, my 2017 therapeutic writing Trump mishegoss stories. They, I didn't plan any of them. They, they, uh, all just sort of blurted out. Uh, so unauthorized bread is a story about people. I'm refugee housing where all the appliances are designed to have DRM, to lock them into a vendor ecosystem so you can only toast, authorize breading, your toaster. You can only store authorized groceries in your fridge and so on. And um, it, it, that is bad enough. But then the hedge fund that owns the backend for all this stuff financially engineer's itself into bankruptcy and so everything stops working. And so, uh, they learn to jailbreak their appliances out of necessity and then out of sheer joy of, of seizing the means of information.

Speaker 1:          00:01:01       But then they learned that the companies are being rebooted out of bankruptcy and that very soon their telemetry is going to detect that the devices were jailbroken and then they're going to face the MCA criminal liability. And because they're all in refugee housing, that will mean being deported and possibly killed. And so it becomes this like very high stakes fight where this woman who has created this kind of, you know, youth brigade of kids who go around and jail break everyone's devices now has to convince these kids who are completely foursquare against it to go and restore everything to factory defaults without scaring the pants off of them. They end up working with friendly texts and trying to figure out if there's a way that they can use vms to cheat the telemetry and so on. So it's a, it's a novel about, about the kind of class dimension and surveillance dimension, a vendor Lockin, uh, and the way that that plays out depending on what kind of privilege you have in the world.

Speaker 1:          00:01:53       Um, and then the next story is a story called radicalize the title story. And it's about, um, super entitled Middle Class White Dudes who watched their loved ones die preventable illnesses because their insurers won't cover therapies and who find themselves on these darknet message boards where they're radicalized into being suicide bombers who kill healthcare executives. And in the end, a lot of it is about whether or not America will ever call a white due to terrorist. Uh, and, and some of it is about how just the cause actually turns out to be and, and, and so on. And also this very toxic observation that many have made about the incell movement that, um, in normal support message boards, you know, if you're, if you're a recovering alcoholic and you're in a, an an online community, all the elder states, people of that community are people who, who beat the thing you're struggling with and are now staying alive, staying around to guide people.

Speaker 1:          00:02:47       But people who recover from being in cells don't hangout an insult message board. So all the elder states, people have the incell message. Communities are the most toxic, most broken people. And they're the ones saying, yeah, a van, and drive it through the streets and kill as many people as you can. They deserve it. Right? And so these communities don't get better over time. They get worse. And, and that's the kind of community that I'm exploring. Um, the third story is called model minority. And it's about a thinly veiled analog to superman intervening in a, um, a beating by the same cops who killed Eric Garner on Staten Island, uh, who then discovers that the fact that he's viewed as both a white and a human are super contingent and that there are some things that America won't tolerate, uh, from the people who are honorarily, white and human.

Speaker 1:          00:03:33       And it takes the form, uh, in large part of Socratic dialogues with Bruce Wayne, who's a military contractor who provides predictive policing software to, uh, the end YPD and who's in fact basically responsible for all of this. And then the last story is a story called the mask of the red death named after the Edgar Allan Poe story. And it's about, um, preppers who build a luxury bunker just outside of Phoenix and repair to it as soon as the, the catastrophe hits and, um, uh, you know, fancy themselves living at a kind of boy's own adventure of the elite surviving while all the useless takers a die in Phoenix because they didn't have the wisdom to prepare these bolt holes, but who in fact ended up dying of cholera because they, the useful people are the people who stay behind in Phoenix and got the sanitation working again.

Speaker 1:          00:04:22       And these Uber mentioned have, have to discover that you can't shoot germs. I was originally going to be called, you can't shoot terms, but I think masque of the red death has got the appropriate gravitas. So it's these four novellas, they're all linked. They, they, they, they wrap around a lot of the same themes. They touch in a lot of the same geographic locations. Um, some of the details Ricoeur writes. So some of the op sec that superman uses to avoid being, having his, his secret identity added by the NSA, he's got like a randomizer that tells him where to take off from so that you can't draw a map to see where superman is always cited by, you know, ground radar. Uh, so he know he runs very quickly to somewhere else and then takes off. Um, and this prepper has also got a randomizer that makes him get in his disguise, armored up, uh, uh, like F-150 with a camper bed, uh, that is full of all of his prepper gear and put some fishing rods in the front and just drive it off of his gated community at this randomizer is interval so that there isn't someone who goes, hey, that's weird.

Speaker 1:          00:05:21       Why is that guy driving his F-150 out of this gate guard a community? Now he must be going to his prepper hidey hole. We'll follow him there and kill him and take his stuff. So you know, a lot of those, a lot of the same things kind of repeat and repeat and the things wrapper and each other. It's, we're not using the word collection, uh, for it. It's a, it's just a fiction book. Um, and it's, uh, it's been likened by my publisher to the book that Stephen King wrote. Um, where that, that the body, the story that became a standby me comes out of four seasons. That's just for thematically connected but not continuity connected. Uh, Tales.

Speaker 2:          00:05:58       Had any of the story's been published previously?

Speaker 3:          00:06:01       No, this is all original stuff. Uh, and as I say, wasn't planned. I, I, you know, the unauthorized bread, originally I sent it to my editor because it was such a weird and awkward length that I didn't think, I didn't know what to do with it when it was done. It's 30,000 words long. And I thought that he was going to say, well, we don't know what to do with this. And instead he sent me an email like the next day saying, oh my God, this is amazing and timely. We want to publish it in two months as a standalone book. And I said, well that's great. Let's do that and we want to pay you more than you got for your first three novels for, which was also great. And then, and then I sent him the next one, I sent him the model minority. It was like, this is also awesome. We'll do it the next month as a standalone. And I'm like, I've got two more in the works. So that's how we came to weight about seven months to do it and, and publish them all in one go topic. Who are the, the TV and movie studio associated with the same company that owns the intercept. A have bought the TV rights for this inner developing and

Speaker 2:          00:06:54       now, and you mentioned timeliness and reading unauthorized bread. It seemed very much of the now and in the book also struck me as being more political, which is kind of a funny thing to say. Your work has always been political in one way or another. Uh, freedom of access to information, doing it yourself. But this one seems a little more pointedly political.

Speaker 3:          00:07:14       Two things have happened. One is that politics would be just become more salient, right? Like we are just in a moment where you can't not talk about politics, you know, for better or for worse. The other thing is that the political dimension of information has now become much more obvious, right? Like I don't know if any of you work in like Ux or or or Ui design. There's this thing that happens with Ui design UX where like when you start, you're trying to convey a bunch of ideas that are really novel to the people who you're conveying them to write. Like you know, if you think about it early gooeys like just the idea that there is a file and then that a file is a thing that you save, right? And that you have reversion and you have control z and like all of those things are kind of novel ideas.

Speaker 3:          00:07:56       Undo is not a thing that you just know about if you've never used a computer and do as like it's a weird idea. And over time we got better at conveying with those ideas mean but also the urgency of conveying them is diminished, right? Because people are meeting you halfway right now. Like just everybody, people who don't know what a floppy disk is, knows that oh no, that a floppy disk means safe. Right? And that just that icon like doesn't, it doesn't need a tool tip anymore the way it used to. And in the same way like writing political fiction about information doesn't require nearly so much handholding. You can just like jump right in because you know, in an age of black lives matter and mimetic warfare and um, uh, you know, questions about, um, uh, whether or not our power grid is vulnerable to a cyber attack and so on, like talking about inflammation as being this like important dimension to our politics is, is not a radical idea anymore. And that means that you can dig into like more nuance, right? Like more the can be centered

Speaker 1:          00:08:56       more because the information dimension is just obvious. That's interesting. It. It also made me remember that it struck me while reading the story that seems slightly more educational than past fiction has been there several sections. Uh, it's not overly heavy exposition but you go pretty detailed into digital copyright kind of aside how to jailbreak DRM. It, it seems like you were educating through the story as well. So I think there's two dimensions to that. One is like I think people are tolerant of exposition when it's news you can use, right? Like oh that's how that works now a whole bunch of stuff in my life suddenly makes sense. Like here's what a VM is or whatever. The other thing though is that there is a longevity that comes from writing fiction where the technology is rigorous. Like we've had a certain amount of technological breakthrough in all of our careers and lives, but there are some like fundamentals that remain pretty fundamental like you know, complexity and [inaudible] and our understanding of complexity theory and things at scale and order and squared and things that scale in polynomial time and so on.

Speaker 1:          00:09:58       Like those are things that are just semi immutable. Right. And so like talking about the kind of problems we can solve and the kind of problems we can't solve. If you make the plot turn on them, the plot doesn't get old in the same way that it does. If the plot turns on how much Ram your phone has, right? Like that's a moving target. But like Turing completeness, not a moving target, right? Like writing about the fact that if you try to design a computer that can run all the programs except one you are trying to do something that runs counter to the really the only functional widespread architecture we have for computers, which is the one that runs all the programs. And so there will, uh, it will always be this like weird mashed up Rube Goldberg under the hood. If you've got a computer that doesn't, that, that runs everything except one.

Speaker 1:          00:10:44       And it's always going to have like certain recurring characteristics, right? Like if you design a computer that has a mode that sits below super user mode, right? Like a ring minus one where programs execute that even the administrator of the computer isn't supposed to be able to inspect or terminate, then that will always be a zone that if someone who is an attacker gets access to it, that they'll be able to operate with total impunity and undetectable. He against you because it's a computer design not to, not to introspect about processes that are running in some ways and so like this just keeps coming up, right? We keep designing computers that have as part of their security model, oh, there are programs that the user, even if the user is the administrator and owns the device, can't terminate her inspect and inevitably someone who's a bad actor starts running code in it.

Speaker 1:          00:11:29       Like maybe the politburo orders apple to run processes that seek out and terminate VPNs that it can't spy on for Ios devices in China, which is like a thing that happened, right? Like the, you know, this is, this is the world's most predictable outcome of putting that gun on the mantle piece in act one. But we're going to continue to put that gun on the mantle piece in act one. And so if you write science fiction that turns on the actual characteristics of computers like our theoretical understanding computers that science fiction remains futuristic for so long as we continue to make dumb policy choices about computers, which you know, uh, to to my great dismay probably means that the fiction will remain current in some way forever, right? Like little brother is still being taught and read it. I wrote it 13 years ago now and like the question of whether or not subjecting whole populations to surveillance are using machine learning to make inferences about guilt or, or any of these other things creates a bunch of path pathologies.

Speaker 1:          00:12:30       Those, those facts are like still totally in evidence. They show no sign of, of going away. We have totally failed to learn the lessons of them. The stakes only get higher and every year there's another news hook that that makes people read little brother. And then come back to me and say, oh, this is just like that thing that you and you know, how did you anticipate 13 years later that we'd be doing this? And I'm like, I didn't, we were doing it 13 years ago. We, we just, we have like our literally still beating our heads against that wall. We will are figuratively still beating our heads against that wall and we will never stop. And so little brother will remain current and relevant for so long as we are stupid about technology policy. You mentioned the word route. What was the initial idea for the story?

Speaker 1:          00:13:13       Like did it start with the phrase unauthorized bread or did it come from somewhere else? Yeah, it actually, it started with a short story. I wrote it as part of my guardian column, so I'd been arguing for a long time with people about Ios and the APP store business model. And uh, there was this, it just works. And I trust them element to, to people saying I want to work within an ecosystem. And I, I d I d I trust apple and I don't care, uh, if they have made choices about what I can and can't use because I think those choices are good ones. They're good proxies for my interest. And I would, and I was trying to tease out the difference between having a checkbox in your [inaudible] that says, I would like to do something that the manufacturer has an approved and having legal liability attached to figuring out how to reconfigure eos to do something that that hasn't been approved and what kind of bad things crop up if it's actually a felony to modify your oh, to do things at the manufacturer doesn't like.

Speaker 1:          00:14:17       And so I wrote a little story called if dishwashers where I phones and it was in the form of an open letter from a, from a Steve Jobs, the and CEO of a next generation Iot dishwasher company called disher who make an appearance in this story. And he was explaining that like foodborne illness has killed more people than any other killer in human history. And how can you expect your dishwasher to be truly effective at keeping you safe and making your dishes clean with the least amount of water in an age of scarce resources. If you are able to put any old dish that you want in your dishwasher. And that is why you shouldn't be bending the prongs of your dishwasher or trying to take the RFIDs out of the dishes that you bought from the disher store and putting them in grandma's China and so on.

Speaker 1:          00:15:06       Because like you could buy a different dishwasher if you wanted that. And, and if you, uh, and, and the deal that you got when you bought this dishwasher was that you would only wash dishwashers from the kitchen store. And the kitchen store works only with licensed partners who make high quality gear and they, they, you know, anyone who wants can buy a $99 kitchen store license and they can, they provided, they comply with the terms of service. They can make pottery that you can put in your dishwasher, but it's not dishwasher. The fact that it says dishwasher safe doesn't mean it's dishwasher safe, right? They, it's only when they're in our developer program that we can tell you that you truly won't die of Listeria. Uh, if you, if you use their dishes and like these are all like taken individually, not unreasonable statements, but they gang up to inkjet printers for everything, right?

Speaker 1:          00:15:54       Everything is tied into some ecosystem where you can't, you, you know, it's not that you, you do trust them, it's that you must trust them. And if they ever make a decision that you don't like, um, you are out of luck. And the longer you go inside the ecosystem, the more sunk costs you have. And the harder it is the, you know, the more you have to give away, the more the switching cost is. If you decide that you no longer trust them. And so you end up being beholden to a series of commercial decisions being made in board rooms that you have no insight into. And you just have to trust that no one in the firm will ever do anything that runs counter to your interests. And you know, like, I'm not, uh, on anti-apple person. I actually have a sad mac tattooed on my arm from when I used to be a CIO and I used to order $1 million worth of APP apple gear a year.

Speaker 1:          00:16:42       But you know, as someone who's bought a fair number of Apple Lemons and written pos for a fair number, a low number of apple lemons over the years and seeing how the company can be wildly imperfect and will be wildly and perfect again, I think the idea that you are trusting them in this way that requires that you trust them and that you can't transfer your trust out actually invites future leaders of the firm to make choices because in the knowledge that if they, that they can be, uh, uh, they can betray your trust and you're not gonna be able to leave, right. That you'll be, that, that they, they've got a lot of headroom in terms of betrayed trust before you get to the point where people are going to give up a whole ecosystem of devices and replace all of it. And certainly in some customers may be never.

Speaker 1:          00:17:28       And I saw this not being looked on with horror by the rest of the world, but being looked on as kind of a, uh, an excellent idea. So you know, you have for example, Johnson and Johnson getting approval for an artificial pancreas. This is a uh, closed loop, a continuous glucose monitor and a, an um, an insulin pump with some machine learning to try and time the insulin dosing to keep your blood sugar within a safe range. Um, and it uses proprietary insulin cartridges, right? And you know, it making a tool to refill those cartridges is a potential DMC a violation with a $500,000 fine and a five year prison sentence and revealing a defect in it if that defect would help someone bypass the DRM is also a potential felony under the DMCA. And one of the things we know is that security researchers are killed from coming forward with reports of defects when they just, when there's a potential DMTA overlap or computer fraud and abuse act overlap.

Speaker 1:          00:18:28       And so now you have this spreading attack surface of devices that because they're designed to be extractive of their users are also off limits to independent scrutiny and they are much more, they're more and more intimately connected to our bodies. And so, you know, your car is a robot you put your body into that then goes down the road at 60 miles an hour or if it's like the five that goes out into five miles an hour. But you know, it's still like, you know, and I'm not talking about a self driving car, I'm just talking about like a car, right? Because you take all the informatics out of a car and it becomes a nerd, right? The most salient feature of that car is it's informatics. Compromising those informatics allows the, the a compromiser to wreak havoc on the person whose body is trapped inside this fast moving robot and on the people around it.

Speaker 1:          00:19:18       Uh, and so I wanted to illustrate this idea that as our property interest in the things that we own is being eroded and as our ability to independently scrutinize them are being eroded, that we are also magnifying all of the imbalances and inequalities in our world and that it happens first to the poorest and least powerful among us. But it spreads to everybody, right? You know, the, the user adoption curve for controlling technology is like refugees, prisoners, children, poor people, uh, blue collar workers, white collar workers, right? Like that's the, that's the adoption curve. And like, if you want to know what your life is going to look like in 20 years, just look at what we're doing to refugees today. And that's the technology that people will expect you to use. You know, when people didn't have CCTVS recording them, non consensually operated by third parties, unless they were in prison in our lifetime right now, it's ubiquitous. Illustrating that and using this specific group of people to illustrate it, uh, was, was an intervention in that. A way to try and interrupt that. Well, let's dig a little deeper into that idea of inequality. It's a, a major part of this story. The main character Selema it's an immigrant or refugee. Uh, the people that surround her are largely poor and underclass. Um,

Speaker 3:          00:20:48       what do you think that brings the work? One of the most salient facts of our moment is inequality. Uh, in part because it, it breaks apart the story that we've told about markets, which is that markets are dying, odd dynamic way of finding people whose ideas would create more general prosperity and allocating capital to them so that they can do it. And when you see widening inequality and stagnation in our, um, social relations, you're left with either one of two conclusions, right? Either markets aren't working the way they're supposed to or eugenics is real. And there is a 1% of people who are so smart that they should just own everything. And if we would just give them all the stuff, they will allocate capital so wisely that we will get richer and richer and richer. And you know, the history of antitrust is full of counter examples, right?

Speaker 3:          00:21:41       Like when we broke up the phone company into six companies, they got bigger and aggregate than they were as one from right when they broke up the railroad and to, you know, the railroad monopoly institute companies, each one within a few years was as big as the parent company had been. You know, the disaffection of scale are, are actually pretty well understood. But you know, as Upton Sinclair said, it's impossible to get someone to understand something when their paycheck depends on them not understanding it. And if you are someone who benefits from the concentration of wealth and a single firm, uh, the fact that we as a society will benefit more if that firm, we're broken up into smaller pieces and each of them was allowed to compete and, and grow is not very relevant to you because it means that you get a lot fewer ivory handled back scratchers.

Speaker 3:          00:22:31       And so, um, I think that like one of the corrosive effects of inequality is that it drives rich people into believing that they have good blood, right. And to believing in eugenics. Um, you actually heard this in the last election cycle. Trump repeatedly talked about his good blood, right? It's like, it's like, it is like, uh, uh, for, for people who remember the horrors of the Holocaust or, uh, who've, who are Tuskeegee or, you know, the eugenics movement, good blood is like a, it's a, it's a scary thing to hear someone talk about, right? Uh, it is like, it is, um, it's like the smoke from a, from a horrible fire that is smoldering. Uh, and I think that, you know, we're, we're blowing on those coals. And so by writing about people who have, uh, who would be really efficient capital allocators, right, who are doing really interesting, dynamic, exciting things that benefit other people, but who have, who are denied access to capital, one of the things that you do is you start to change the narrative we have about, about whether capital allocation as efficient and whether inequality means that we are actually, um, just

Speaker 1:          00:23:46       taking random lottery winners and heaping enormous riches on them to the detriment of their soul and to the detriment of our society. Your Twitter handle currently is son of an asylum seeker, father of an immigrant. Yeah. Do you feel a personal connection to that experience? I do. You know, I, um, I lived in England until three years ago, so I was, I was in the UK until in the run up to Brexit. And, uh, I would end up in a lot of cabs and lung cab drivers are a notoriously right wing and notoriously Gabby. And given that the, the impending crisis was about migration in this debate was going on about migration, like at least on a weekly basis, someone would start talking to me about asylum seekers and migrants. And my dad was born when his parents were living in a displaced persons camp in Azerbaijan.

Speaker 1:          00:24:36       They were Red Army deserters. Um, my grandmother had been a child soldier in the siege of Leningrad. They came to Canada as asylum seekers. And then I'm an immigrant, right? I'm a Canadian who then lived in the United Kingdom and now I live here on my daughter is an immigrant. And, and I found that, like, it gave me a place, a way to enter that conversation. Right. And say like, I am, that's who I'm, I'm the person you talking about. Right. I, that's, that's me. Uh, one generation that it, they'd say, oh, but you're the right kind of your high skill to your, you know, whatever your white, uh, and I would say like, so my grandparents were not high skills, right? My grandmother stopped her formal schooling at 12. My grandfather stopped his at 14. Um, they came to Canada without marketable skills. They learned skills when they got there.

Speaker 1:          00:25:19       And this is the, and you know, they had to display an awful lot of plucking, get up and go to get from Azerbaijan to Canada. Right. Like that, that they have the winnowing function they went through was not passing a standardized test or displaying a credential. It was crossing Europe. Right. Like that is, uh, that, that is an awful lot of gumption. Right? By the time you get to the port of Hamburg and you present yourself to a Canadian immigration official, you are like, you have already demonstrated an enormous amount of pluck. Uh, and, you know, they were traumatized and they had lots of problems in their lives, but they were also, they were also people who came to contribute and whose families contributed through the generations. And so as the debate about migration and asylum seekers and immigrants took off here, I felt like, uh, you know, my passing privilege, I have an accent that sounds like it could be from America. I have a skin tone that makes me look like I could be white, even though the people I come from, we're not thought of as white when they got to Canada. They certainly are, are, are white now. Uh, and, um, and, and so you could, you could think that you were talking to someone who wasn't an asylum seeker, who wasn't, uh, the, uh, the father of a migrant, you know, as they say, Canadians are like serial killers. They're everywhere and they look just like everybody else.

Speaker 3:          00:26:44       Uh, I wanted to wear it on my sleeve, right. To make people confront that they were among people who were the kind of people they were demonizing. In the beginning of the talk, you mentioned how the stories and radicalized aren't connected. Yeah. But you said that the, the role of place mattered in the stories. This story takes place in suburban Boston. Why Boston? Although it touches Phoenix, right? Phoenix isn't all the stories. So Boston in part because I I knew at reasonably well, uh, I'm a MIT research, uh, MIT media lab research affiliate. Um, you and I hung out in Boston. I stayed on your living room in Boston once. Uh, and Boston's a really interesting town in that it's like, it's a crossroads for a bunch of different kinds of industry and activity. So it's obviously an academic hub. It's a tech hub. It's now biotech hub, but it's also a light industry town.

Speaker 3:          00:27:37       It's a port. Um, it has, it has all of these different contradictions and it at similar to La, right. It's not just, it's not like the bay area, which although the bay area has a bunch of industries and its history, it has been completely eclipse. Now. There's just like one thing that it's known for now, whereas Boston still is this very diverse place. Um, and Arizona I, I'm really interested in, because like on the one hand, it's a place that is not going to survive climate change gracefully, right? It's like, it's really in the crosshairs of climate change, but it's a red state. So it's also a state where climate is officially denied, but it's also a state that is majority minority. Um, and, but for a little bit of Gerrymandering here in a little bit of voter suppression there, um, it would be a place that that would have a very different politics.

Speaker 3:          00:28:25       And it's also a retirement hub. So it's a place that's full of people who aren't Arizona's making claims about their native rights right there. They're indigenous rights as Arizona's, even though they're all transplants. And so like the contradictions of, of Arizona are so, are so vivid. And I, I'm, I'm an advisor to a center at Asu that does science fiction to talk about, um, other disciplines. And so I go to Phoenix periodically, uh, and, and also it's my hub because I fly to Burbank airport, I live in Burbank and so everything starts Phoenix and then somewhere else. So I really was interested in the role that Arizona plays in the kind of the future of our politics. And it's interesting leveling effect if you talk about, you know, kind of redefining who we presumed to be a refugee or an immigrant both places. Both of those places are also places that despite their diversity, we don't necessarily think of as an immigration.

Speaker 3:          00:29:19       Yeah, yeah. I think we'll see more places like that. And I mean, Greenpoint Brooklyn is still predominant Polish entry point in the country, uh, grilling among population in Wisconsin. What do you think that means kind of to the, to the sense of place and then the diversity of those communities? So this is a really interesting question. We have a story about America, about kind of something between assimilation and ladder kicking, right? Like once there were poles who were not thought of as as white or American or Italians, and then they assimilated and then they became respectable and then they kicked the ladder away and they turn on the people who came after them. And there's a certain amount of truth to that. Some of that though is associated with economic dynamism. So one of the things that, um, that made people go from being other to being, uh, accepted as fully paid up Americans.

Speaker 3:          00:30:09       It was an extraordinary degree of social mobility at various times in America's history. Uh, and Tom Piketty and his book capital in the 21st century talks about America's dynamism and he chalks it up to these, uh, reset events that America had in terms of its wealth distribution. So in, before manumission, the vast majority of American wealth was in people who were claimed as slaves by people who had enslaved them, right? Like the, the, the, the gross national wealth of America was primarily in human bodies. And so manumission in addition to doing a lot of other things, politically had this huge economic, what was this huge economic moment in that the greatest concentrations of wealth in America sees to be considered as assets and became human beings, at least as a legal fiction, not withstanding Jim Crow and whatever. But one of the effects of that is that the grip that wealthy people had on political outcomes completely changed as after the civil war because they just didn't have as much money to spend, right.

Speaker 3:          00:31:11       That the, the, their wealth was like radically diminished. And then it happened again during the crash. And so the, the, the 30 the warriors and also the echo and the crash after the gilded age completely leveled out the wealth distribution. So the amount of wealth control by the top decile of Americans just, just like nosedives twice in American industrial history. And it only happens once in Europe, right? It only happens with the, with the, um, with the warriors, with the two wars in the interwar years. And, uh, that when, when the capital is more widely distributed, you have more pluralistic choices, more pluralistic decisions. Um, which creates things like, um, a better social safety net, a better quality of schools, cheaper and wider access to education and so on. And this lifts up lots of people, right? It helps people, um, uh, enter a kind of middle spot.

Speaker 3:          00:32:02       Middleclass respectability. Uh, and as we know from the crisis of 2008, the first people who get jettisoned when the economy starts to sink are the last people who got in. And of course there was still historic problems with this in terms of red lining that denied access to African Americans to, to that shared prosperity. But nevertheless, you got people who became officially American instead of others instead of perpetual immigrants. And so there's this story that goes, if you come to America and you just hang out, your kids or their kids will be Americans. They'll see thinking themselves as Polish Americans are Italian Americans. But really what we're saying is there'll become middle class, right? And

Speaker 1:          00:32:40       right now it's looking like that's ended right? That you don't become middle class. If you show up in America with you know, nothing but nothing but the shoe leather on your, on your feet, you just, you just stay outside of wealth accumulation and instead of social mobility, because all of the policy levers that we're used to, to allow people who had aptitude to gain access to education and capital and to start businesses and so on. Those have, those have been snuffed out one after another. As the concentration of wealth of the top has grown. And as the Paula, they have more policy levers to yank on to increase their, their, the concentration of their wealth at the expense of everyone else. And if you think about it, you know, the law of large numbers, the law of small numbers, making the wealth of someone who, who, who owns almost everything grow by even 1% is hard.

Speaker 1:          00:33:31       Uh, making the wealth of someone who owns almost nothing double is easy. Right? That's why I like startups have incredible growth, right? We went from one user to two. That is a very impressive growth, uh, number expressed as a percentage. It will take a lot longer for Google to double its users, right? Then the startup that goes from one to two, and so if you're making the rich, the super rich richer, even even a little bit richer, measurably richer, it has to come at the expense of nearly the total net worth of a huge number of people. That's why that Oxfam, number of the number of billionaires in a bus it would take to represent half the world's wealth is so shocking because it, it doesn't just mean that they got richer, it means that giant number of people had to get much poorer. Right?

Speaker 1:          00:34:16       And so anytime you see the wealth of of the top decile of the top percentile or the top 10th of a percentile increasing measurably, you know that, that you know, it's not coming from growth. I mean there's some growth but it's not coming primarily from growth. It's coming through through redistribution and that redistribution is upwards and it's vastly asymmetrical. Everything you own going to make a tiny difference to someone who already owns nearly everything. We've long thought that technology will help where away the differences between class, between race and in the story the poor have access to technology, but they don't have a choice of the technology that they can access. And there's a moment in the piece when, when I laughed where when, when asked what kind of toaster the startup employee had, he said, well not that kind of toaster. And so the better off could choose what tools they use your, could you talk a little bit about, about that element of choice? Yeah, I mean I think that there's a, there's a common pathology among technologists, especially those who work on restrictive technologies, which is that we never imagined ourselves using them. Uh, we imagine them being deployed on others. We, we will always have root, right? We will always, like this is, we were just talking before we came in about this story today about youtubers being extorted by fraudsters who register fake copyright strikes the fraudulent copyright strikes against their youtube accounts and then

Speaker 3:          00:35:38       say, give me $150. I'll put a third strike on you because everybody knows you can't get anyone at Youtube on the phone when you've had a copyright strike against you. Because like literally anyone who gets a copyright strike against them, things that they, that, that it's illegitimate, right? So like youtube doesn't have any great way to triage it and you just get stuck in these support email loops and there isn't a support choice for, I'm being extorted by a petty grifter who wants a millionth of a bitcoin to get away to get my, my, my copyright strikes removed. And so since that doesn't exist in the email loop, you can't get help. But if you are me and you know, Googlers like that would never happen to me. Right? I would just call a Googler friend Fred von Loman who runs copyright for Google with, with a couple other people used to work with me at eff.

Speaker 3:          00:36:22       I could just call him and he would sort it out for me. So, you know, when we're in these situations, when we design these systems, we always know that like, they're not going to bind us. You know, I worked on this DRM standard trying to fight it a for digital television called the broadcasting broadcast flag. And it's the crazy idea, and I don't want to go into the whole thing, but part of it was that all general purpose computers would have to only have outputs that were approved by movie studios. Uh, and uh, but, um, there was a professional tools exemption, right? And so there were like people from all the big tech companies and people from all the big movie studios and people from all the big like consumer electronics companies in the room. And as soon as they said it, but there'll be a professional tools exemption.

Speaker 3:          00:37:03       Everyone like, yeah, of course there'll be a professional tools exemption. You think I'm going to use this stuff? No Way. Right? Like, I'm going to have, I'm going to have the version of this that isn't, you know, terrible. Right? The terrible version is for other people. Um, and so, you know, trying to like kind of tease that out, right? This, this idea that like when we make technology that we would never want to use, we're a dooming lots of other people to using it, right? Uh, you know, the, a recurring version of this as every time people says, well, you know, all those people who work in Silicon Valley don't let their kids on phones, uh, you know, or watch youtube or whatever, you know, use it on a or are they all have ad blockers installed or you know, all the other things that we know about technologists and I'm guilty of a to uh, that, that um, you know, civilians don't have access to or don't, don't get to do.

Speaker 3:          00:38:00       And also reminds me of that when we were talking about before the talk in terms of just how beautiful it is when something just works. The book also addresses kind of functionalism and there's a couple of neat lines in the story. This was a new kind of toaster, a toaster that took orders rather than giving them. And then also if someone wants to control you with the computer, they have to put the computer where you are and they are not. So you can access the computer without supervision. Can you talk a little bit about functionalism and how we might be moving away from that are closer to that. So the nexus of control is the key thing, right? All that, the difference between Utopian dystopia is who's got their finger on the button, right? Like having a, a fitbit that tells you how many steps you've walked, leaving aside the problems with the sensor and the fact that it might think you've walked 1500 steps before you get it a bed.

Speaker 3:          00:38:45       Um, but having a, a fitbit that helps you track your own fitness levels. Maybe you could have a pathological relationship with it, but there's no, there's nothing wrong with you knowing more about yourself. Having your boss put a fitbit on you and say, if you don't get your 10,000 steps in, we're going to, we're going to take you out of the company health plan. It's lit. It's the same technology. It's just a different nexus of control, right? And if there's, like, if there's a mechanism in the fitbit that detects spurious sensor events in order to stop the fitbit from telling you that you've walked 10,000 steps when you've really only just gotten out of bed, that's great. If that same sensor is used to stop you putting your fitbit and a sock and stick it in the tumble dryer to fool your boss into thinking that you've done your 10,000 steps, that's terrible.

Speaker 3:          00:39:33       Right? So the best example of this, Doug Rushkoff just wrote this column about going to this um, um, hedge fund conference and one of the panels was on what to do in the event, right? The, when the collapse comes and the poorest come to eat you. And um, they, they, they, they were talking about this problem that they would have when currency collapsed, which is how do you stop your guards from killing you if they don't need you to pay their paychecks? They said, well, we've got it sorted out. We're going to have these like two factor biometric and, and a secret, um, food lockers. And so they'll have to keep me alive to unlock the food lockers so they don't starve to death. And that's going to be the thing that like keeps my guards in line. And you know, I know people and I have been on many diets and sometimes those diets involve not eating certain things.

Speaker 3:          00:40:19       And if I put a lock on my fridge that I can control, that didn't open until it was lunchtime. Literally the same technology. And the only difference is who's pushing the button, right? The difference between Utopian dystopia is who gets to decide. It's, it's where the choices. Um, and so these, these people are moving from a situation where the technology that they're in is a stricture and it becomes an enabler. And I think that there's a story that like going back to the dishwashers and, and, and the Steve Jobs figure, there's a story that we tell about technological inevitability, right? Like we have to make it impossible and illegal for you to reconfigure your devices or they won't work or they won't keep you safe. And we talk about it as though it, it, it, like someone came down off a mountain with two stone tablets that said that, right?

Speaker 3:          00:41:07       Like, you know, when we talk about, um, uh, online surveillance ad tech and, and predictive markets and machine learning, right? Like I am old enough to remember when we rotated our server logs instead of mining them for market intelligence, right. There's like no reason. Like nobody will take away your cs degree if you start rotating your logs again, right. Instead of saving them, right? Like that is a choice someone made, but we disguise it as a technological inevitability. And so by like showing that when the nexus of control changes, the nature of your relationship to the technology changes and the thing that you didn't like about the technology turns out to be a thing you didn't like about the nexus of control. That is, I think, again, a powerful lesson to encourage people to understand stem and there and, and to become masters of their technology.

Speaker 3:          00:41:58       We talk about stem education as though it's just part of the like normal grift of like if you don't get your kids to do this and give me money to teach your kids to do this, your kids will be economic roadkill. And there's certainly an a certain element of that. But again, like I think the origins of the stem education movement are about digital self defense. Not about, not about like creating an industrial workforce right program or be programmed, learn how to use the technology or the technology we'll use you. And that empowering message of technology is one that I really firmly believe in. Right? I don't want to get rid of computers. I just want to change how we use them. I want to talk a little bit about the audio book. So this novella came out yesterday. Yeah, there's stories are coming out in March 19 and the voice actor who did this one's pretty interesting, just herself and so on.

Speaker 3:          00:42:47       Ask you about her. Uh, let me see. SOC is a Palestinian American actress and playwright and founded a production company dedicated to Middle Eastern theater arts. How did you connect with her and get her involved in the project? I'm lucky enough that I've been really involved with the production of my last several audio books. We record them at a studio near me in there in Hollywood, uh, called sky boat media. So they consult me on casting choices and so on. And my hard and fast rule with them was that I wanted a voice actor who was of Arab origin. Uh, and I wanted a woman because the narrator is a woman of Arab origin. And um, you know, I have a friend Lexi Alexander who's a very interesting person. She's a director now, but she was a world champion. Kickboxer. She's a German Palestinian woman who was brought here by Chuck Norris to help train the army.

Speaker 3:          00:43:36       Uh, she became a stunt woman, then became a director. She directed punisher. She directed a couple of super girls. She does all kinds of stuff. And one of the things that she's always on about on Twitter is all of the talented Arab American woman actors and other actors of color who could be doing the roles that for reasons that completely baffled me, are not going to people who they would be suited for. And so, um, I asked her for some names, none of them could do it. Uh, but I, then I went to the, to the directors and I said, we really need to cast an Arab American, a woman for this and um, or a woman of Arabic origin. And we got the demo reels for four or five of them and let me was the best one. And she was available. And the arrest happened there. I was in the studio everyday when we were recording. She did an amazing job and it's a wonderful listen as well as a wonderful read. Yeah. Questions from the audience. If we can alternate between people who identify as women and identify as men or nonbinary and can go at any time. But, um, that way it's not just, um, dudes.

Speaker 4:          00:44:37       Uh, so a lot of science fiction writers, um, I'm thinking of, uh, like Ray Bradbury and Isaac Asimov and so on, kind of like, right. A lot of stories that, that sort of come to imagine a quart of shared world of the future, right? That, and they build up this kind of consistent world of the future. Uh, uh, uh, Ray Bradbury did what they did that with Martian chronicles and, and, uh, asthma for the foundation and so on. And just kind of curious if you see yourself stumbling toward that or, and you might be doing that on purpose or that kind of thing. I liked the way Brad

Speaker 3:          00:45:05       free did it more than the way asthma affected because it's, they're not all in the same continuity, right? There are things that like, there are things that happen on Mars in one story that if they happen, then the next story doesn't make sense, right? But where it makes sense to overlap them, he does. And another writer who does that really well as John Farley, who has this whole long cycle of stories that he's been writing since the 70s, they're amazing. Uh, about, um, I think they're called the six world stories. Uh, earth becomes uninhabitable, are living everywhere except earth. Uh, and when the, when continuity makes sense, he's got continuity and when it doesn't, it doesn't. And I love that because, you know, uh, there, these aren't alternate history, right? Or like these aren't history. They're not, they're not instructions. They're not predictions. They're artistic works. Who's effect is, yeah, there's some like continuity is, is part of the effect of it.

Speaker 3:          00:45:57       But, um, the themes of the characters and the kinds of characters they are and the kinds of things they get up to are more important than, you know, making sure that if someone does something in one story and then they appear as a big character in another story, that it's still crosses over. Uh, you know, I think of the way that the reboots of the shared worlds of the comic book companies have worked where when it makes sense, it makes sense. And when it doesn't, it doesn't, and they, they, they can have multiple parallel timelines. Like, does anyone think Batman would be better if, if we were all in continuity since the first detective comics, you know, uh, the, the reinvention is actually super important and part of the way that we tell stories anyways, right? Like if you look at say the all the different versions of the Icelandic stories, right? In the north stories, they're like they are, there are multiple irreconcilable versions of what the nurse did. There's two versions of genesis in the Bible, right? Like the first two chapters of, of, of genesis tell completely opposite, non reconcilable, mutually exclusive stories of where the earth came from.

Speaker 4:          00:46:59       Right? So you see yourself as, as kind of interested in thematically consistent culture but not necessarily a logically consistent. You can't quite say it that way.

Speaker 3:          00:47:05       And I'm a Pantser, not a plotter, right eye. I'm not someone who does a lot of card tricks in the dark to try and figure out how the plot's going to work. I figured out as I go. So it doesn't really lend itself to that kind of continuity. Who's next,

Speaker 4:          00:47:17       what you were saying about digital self defense? Um, I was wondering, do you see that as actually being doable? Because I'm pretty tech savvy and you know, at home I run Linux and I have a, I have my hard drives are encrypted with locks and so on and, but there is no way I could possibly run down all the attack vectors even on my own machine. Sure, sure.

Speaker 1:          00:47:42       Yeah. And I think that um, there is a story we have about like what the early days of the Internet Liberation Movement or a unit, techno, techno politics movement was that I think is wrong, but it's got a little kernel of rightness. The wrong version is we used to think that technology couldn't be possibly used to do harm and so we wanted everyone to use technology and we didn't care how it was used because we were sure that it would just make everyone's life better. That's clearly not true. Right? Like you don't found electronic frontier foundation because you think everything's going to be great. You found it because you're worried about how terrible it will go if it doesn't turn out great. Right. You, you, you see on the one hand, the promising, on the other hand, the peril, but the cypherpunk movement particularly did have this idea that you could throw encrypted communications, create a parallel universe where even if you lived in a totalitarian are unaccountable system where people could operate with impunity and do terrible things to you.

Speaker 1:          00:48:37       That because the ciphers worked and the keys couldn't be brute forced, that you, that you could in some way resist the state kind of indefinitely. Like you could have a demi moaned that, that existed alongside of it. And I think that not every, not every cyber cypherpunk felt that way, but a lot of them did. And I think that that's wrong. But I think that what we've learned about encryption and its relationship to unaccountable authority and illegitimate authority is that encryption is, it's it, it's like a stop gap, right? The technology is a stop gap that you can use to organize and to resist a coercion while you figure out how to make the power structures that you're organizing about and that you're worried about coercion from more accountable. Um, but that, you know, technology alone can't do it. But if you try to imagine the inverse, right?

Speaker 1:          00:49:34       Imagine creating a political movement that holds power to account and demands accountable at legitimate exercise of authority. But that doesn't use computers, right. That would like you find each other by like, I dunno, stapling photocopied posters to, to telephone poles and imagine how easily you would be outmaneuvered by the force that you're trying to resist. It seems like obvious to me that that's, that, that the power relationship dynamic that we're in now is using technology to open a space to make a political change that gives us the space to make technology that opens the space to make political change, lather, rinse, repeat. And you don't always win, but not, uh, you know, not, not to just create this Debbie Monde. And you know, the, the good news is that people's direct experience of the way technology can, a force for liberation and the way that technology, when abused can be a force of terror means that people are actually caring about the problems a lot more.

Speaker 1:          00:50:38       It's, you know, you can make an analogy here like climate change, right? Like if you are the world's greatest recycler, it wouldn't stop climate change. There is nothing you can personally do that changes climate change, that that will change the facts of climate change. But you and everyone else, you know, and everyone they know all working together can do something about climate change, including collectively recycling and making a lot of other choices, including choices about how we invest in maybe a green, new deal and so on. Um, and for a long time our biggest problem was convincing people that climate change was a problem. And you know, we see today that even among the people who've been historic climate deniers, that's not really a problem anymore. We're way we are like past the point of peak indifference. But the reason we're past the point of peak indifference is that the number of people for whom the reality of climate change is undeniable because they, or someone they love has had their lives harmed or destroyed by climate change is only growing, which means that we move from the problem of convincing people to that that climate change is a problem.

Speaker 1:          00:51:37       Now we have to convince them that it's not too late to do something about it. And I think we are, we've gone through that same trajectory with technology, right? Convincing people that how we regulate technology matters that's taken care of itself, right? We just the the largest petition and Internet history is the one to overrule the electoral college and make Hillary president trailing it by like 1% is the petition from the European Union to not pass the copyright directive that would mandate content id for all public platforms. Right. And like that's crazy, right? Like the number of people who pay attention to American presidential politics versus people who care about whether or not we're going to have upload filters is now nearly a parody. Right? So now we just have to convince them that it's not too late to do something about it. And, and, and the doing something about it is the making the power accountable and so on. Not that, not that we should ever be storing passwords in the clear because everyone's accountable, but that, um, we can store passwords in an encrypted form and also assume that the secret police aren't going to show up and make you put it back door in to decrypt those passwords so they can man the middle or otherwise disrupt the communications of your users. Right. And that's like the, that's the cycle that we're in. Thank you.

Speaker 5:          00:52:54       So obviously the, the, you know, this country has corporations organized based on a profit motive. Like corporations have to be accountable to their shirt, shareholders in peace, profits, et cetera. We've had, we've been lucky and unlucky with the results of that. And in the grand scheme of things, obviously, you know, from my perspective, and I'm sure a lot of people that are your googles on the good side of that, hopefully, um, we'll see. You know, I guess

Speaker 1:          00:53:20       a lot of the time it is, I think you're right.

Speaker 5:          00:53:22       Um, but uh, but there's nothing stopping, uh, you know, kind of the way things are going for it going badly as well even for this company. Sure. Um, do you think there's a way to realign the incentives like at a high level to, to make that less likely to make the good outcomes more likely, let's say. Okay.

Speaker 3:          00:53:42       I want to talk about that European Union copyright directive because it's a good example of firms that are generally good firms or firms that have done a lot of good that are doing bad and doing it in a weirdly dysfunctional way. So one of the things that's weird about the copyright directive is that the record labels are super in favor of it. And the movie studios are super opposed to it, but they're the same companies like literally universal music wants it and universal pictures doesn't, and they're both sending open letters to the commission of the European Union demanding that they be heated. Right. So this is actually a pretty common problem in the theory and history of antitrust that beyond a certain scale there are massive disaffiliate nccs of scale. And you probably encountered them working in a large firm. Like there's a thing that's good for the firm as far as you can see.

Speaker 3:          00:54:34       But at Gore is the ox of someone who's got a lot of power within the firm. I, uh, I had a personal relationship with, with flicker when it was founded. I, um, was, uh, an Alpha Tester for the game that it came out of game never ending. And I was carrying on a long distance relationship with a woman who's now my wife, who lived in San Francisco and London. I lived in San Francisco. We are both Alpha testers and Stewart Butterfield and Caterina fake who created the gang, came to San Francisco and we had lunch and they said, how's it going? And I said, it's great, but we have trouble sharing our images. And they said, we've got that coming in. The game will just accelerate and product road map. And three months later they shut the company down and called it [inaudible] and renamed it flicker just around that one photo sharing thing.

Speaker 3:          00:55:10       So I feel really close to flicker and I watched really carefully what happened when Yahoo bought it and flicker was the first mobile social photo sharing APP. And so it had the power to be a really big money spinner for Yahoo. But Gord, the ox of Yahoo's nascent mobile division. Yeah. Who's nascent social division, Yahoo's nascent, um, a photo division and so on. And the great beasts of Yahoo who had the ear of the senior management who had assembled power structures around them, we're able to head off and starve flicker. So then now it limps along. It's just been popped by smug mug and remains to be seen what its future is, but it represents this like failed promise. And this is a really common disaffiliate NC of scale, right? It's it, you know, these firms get got bought up by other firms who then just poison them or do terrible things with them.

Speaker 3:          00:55:57       You know, as I say, I think Google has done a lot of good in this world, but I think that really effectively burying the Deja News Archive of early use net, it's something between a crime in a shame. You know, those are, that's, that's a really important piece of history and it's like a disaffiliate NC scale. Like someone just felt like it just wasn't important to the core business. Well then why did you buy it? And, and so on. And eventually it was just kind of starved off and vanished in a, down the memory hole. And so, um, one of the ways that you make firms better is by making the amount of harm that they can do less, right? Because then they can't then, then the bad things they do aren't as important. And one of the ways that you make the f the harm that they can do less is by mandating that they be smaller.

Speaker 3:          00:56:40       And historically, anytime we had an industry that was dominated by a few firms or anytime a firm tried to buy a competitor or anytime affirm, tried to buy, um, people in its vertical supply chain to dominate it's vertical supply chain, we looked askance at that, we struck, we subjected it to very close scrutiny and we often blocked it. Sometimes we over blocked it. There's an argument that the, one of the ways that we got here was that there was a constituency for this story that antitrust had been overused because it had been, and they were willing to hear arguments for why it should be dialed down. But, uh, you know, I think that like,

Speaker 3:          00:57:17       so I have a friend who went to work for Facebook and then he quit a year later and came to talk to me and said, you know, you're right. I didn't, I didn't like it very much. And one of the things that I realized when I got there that maybe makes me sleep better is that no one there is any smarter than I am. They're just as dumb as I am. They're not superheroes. Um, and I'm like, but of course they are right there. They're just like you and me. And the reason that Facebook is a bad custodian of 2 billion people's social lives is because nobody has a good custodian of 2 billion people's social lives. Right? Like, how do you, how do you minimize the harm that Facebook has in the toxic ways that an enables people lives? Don't make it in charge of 2 billion people. Socialize, break it up, make it into different pieces, make it sell off Instagram, make it, um, you know, make it split out.

Speaker 3:          00:58:03       The two functions that has one is like helping you find people to talk with and the other one is helping you talk with them. Make it, split those into two pieces because it really sucks at like letting you talk to people. Uh, and it's really good at helping you find people to talk to, you know, whether those are people that want to carry Tiki torches to Charlottesville or people who want to, you know, uh, like Joe form a little league with you or whatever. It's really good at finding those people or people who have the same rare diseases you, it's really good at that. It just sucks as a place to carry on the conversation afterwards mostly because like there's not a lot of engagement to be had. If you have a rare disease, right? You check in every day, things are okay, things are okay.

Speaker 3:          00:58:37       There aren't blockbuster blockbuster news that keeps you hanging out on the rare disease message board all day. So to you know, up your engagement level. Facebook's to sufficiency of scale as they take people who have gathered to talk about a rare disease and they throw clickbait at them so that they stay engaged because their KPI and their bonus is on engagement minutes, not whether or not you're successfully managing your rare disease, make them split those two functions up. You solve the problem. Right now you have a business that just gets monotonically better at helping you find people to talk with and a business that rises or syncs on its ability to get you to talk with them there and, and then you limit a lot of the harm.

Speaker 5:          00:59:11       It is a bit of a counter example. So at Google for example, the primary income is, is ads. Sure. Was historically, now it's changing, but um, you know, that has resulted in, you know, things like Gmail and docs and drive essentially operating at a loss, right? And being subsidized by the successful parts of the business. Yeah. Yeah.

Speaker 3:          00:59:35       But Google's not a breakeven function, right? You've probably, you probably have some like a stock options as an employee. So you've noticed that the company pays dividends and also declares a profit every year and it, and so that tells you that even if the ad business were curtailed by a breakup, it would still not necessarily mean that the company was unable to run those other, those other, uh, uh, loss leaders. Right. It just might mean that the shareholders took a, took a haircut. Um, and you know, one of the, there are lots of formal definitions of corruption, but one of the formal definitions that corruption is when you have privatized gains and socialize losses, right. You know, it's, it's cheap for me to pollute. It's expensive for you to get the pollution out of your tap water. Uh, but that, that expense is diffused across everyone who's, who's putting filters on their tap water and the gains are concentrated in my hands.

Speaker 3:          01:00:26       Well, you know, like if the costs of surveillance, which are real, uh, are widely diffused and the games are concentrated, um, it may be that, uh, making the firm's internalize some of those costs dial down some of the other things that they can do, but it also reduces this drag that the rest of us are feeling. So maybe with the surplus that we gain from being lifted out of the costs of surveillance or market domination or whatever, or the, all the other things that, that come as a result of it, um, that that surplus can be allocated to make up for the losses that we get. You know, it's totally true that iPhone locked ecosystems allow us to gain, got some benefits that would be eroded if we unlock that ecosystem by forced mature. But I'm willing to make that trade. It's totally true that our printers are cheaper because our inkjet cartridges are designed to charge us more than vocally co for water in town, you know, water and pigment.

Speaker 3:          01:01:27       Right. Um, I'm willing to like roll the dice on that one. Right. And find out what happens if it turns out that like we no longer charge for carbon toner as though what we're plutonium tone. But do you have an eyeball on your sock? I was trying to figure out, whoa. No, it's clockwork orange. Uh, okay. Yeah, yeah. We're at like peak bookstore sock. So I don't know if you've been into a bookstore, but like that's where all the margins are now. You talk about ad subsidy, like the entire literary world is being subsidized by the fact that we can now programmatically map bitmaps maps onto socks using weaving machines and China and I went on a couple of book tours in the last two years. I'm about to go on another one. I spent a lot of time in indie bookstores and I have all the socks. Are their Doctorow socks a no. Someone should make those and then I can sue them for my right of publicity. Thank you. Thank you. And if you'd like socks, there's a great sock store not far from here near Angel City books. That's in that, that's in the Venice beach sock district. It's in the old elk's lodge. All right. Thanks again guys.

Speaker 6:          01:02:37       [inaudible].