Speaker 1:          00:06          So without further ado, the first speaker today is a professor, Peter Baylor's from the neighborhood from Stanford University. He, uh, joined Stanford from Berkeley, um, uh, other buy tea, right. You were a postdoc into MIT phd at Berkeley Postdoc at Mit. He joined Stanford last year and a is a rising star in the, in the area of database, uh, applied machine learning, large scale machine learning. And today he's going to share with us his, his recent work, which I've seen once, but not enough. It's really exciting. I love what they're doing. So welcome Peter. Great, thanks.

Speaker 2:          00:53          Okay.

Speaker 3:          00:54          Uh, it, it's really wonderful to be here. Thank you all for showing up and for the untold number of you on Gvc, uh, as well. Um, uh, and thanks to the wonderful intro, uh, really excited, uh, this opportunity to come speak with you. Um, so I'm a new faculty member, uh, at Stanford, um, and with some new faces on campus. Uh, we've actually started a, a large scale initiative we call dawn, uh, of which this macro based product is a, is it subcomponent a geared around infrastructure and tools for large scale machine learning and AI. So, so I'm coming here, uh, under the guise of the Stanford dawn projects, data analyst for what next, what's next? If myself, I studied largely stream processing data management, uh, my colleague Chris Ray, a certified genius by the Macarthur Foundation. So he's database and machine learning. Um, and on the bottom half we actually have some systems in architecture folks.

Speaker 3:          01:44          So Coonley Lakotan built some of the first multi core chips with a Sun Niagara and my Haria. Yeah, you may be familiar with as the cocreator of spark and may sauce. Um, so essentially this dawn project, uh, we're interested in, uh, what's a, what's a fairly exciting set of advances in day to day and that we've seen these really wonderful breakthroughs and amazing breakthroughs and conventionally difficult task spanning image recognition and LP planning, information retrieval. And we're starting to see both in the private sector, in the public sector, um, really society scale impact, uh, things like autonomous vehicles are now becoming a reality. Uh, some of our work on personalized medicine shows that we can beat, you know, Stanford doctors at their own game with enough training data. Um, and some of Chris's work has even been used to make arrests and commonly, uh, sort of in some sort of challenging tasks like a combating human trafficking.

Speaker 3:          02:36          So, so, you know, I come today with a message of optimism that I think we all share in this room, which that there's no end in sight for Vance and machine learning, uh, but also with a recognition that this is a bit of a, uh, of a fairy tale right now. There's a bit of an asterisk next to this golden era of data and that it's really the golden era of data for the best funded in best train engineering teams. Right? So even within an organization like Google, you know, AI and ml capabilities remain a fairly scarce commodity whereby to build a world class production quality data product requires a team of tens to hundreds of data engineers, data scientists, machine learning researchers, and ultimately ops people to put these things into prod. So our goal in this five year dawn project is to enable anyone with domain expertise to build their own production quality machine learning projects.

Speaker 3:          03:27          Products without requiring that phd in machine learning are hiring, are wonderful students without becoming an expert in databases and systems and without understand the latest hardware to do so at scale and to run these models in a cost effective manner. Right. And the reason why we think this is feasible is for two reasons. Okay? The first reason for why we, why we're so excited about this is that, and if we look to you, all right, are some of your colleagues here at Google and one of our favorite papers from the last several years, hidden tactical debt, machine learning systems. First of all, only a fraction of real world machine learning systems are actually composed of machine learning code, right? That is, there's a large amount of work that goes into building predictive data products that that goes beyond just, you know, scribbling equation on a whiteboard and come in with a new loss function in new neural network architecture, right?

Speaker 3:          04:10          It's about a configuration and data collection and then all the way to serving and monitoring. And there's these missing pieces like vast missing pieces in the machine learning life cycle that essentially not addressed by today's data management infrastructure. And the second reason why we think that this question is actually tractable is that, you know, if we look to history, similar advances have actually happened before, right? My favorite example of this is the building where we're in today, right? So search isn't that great example of a sort of core technology being democratized through both better systems and better interfaces. So the core algorithms, uh, before page rank, things like TF, IDF, and inverted indices and distributed query processing date back as early as 1950s. Right? So TF IDF indices are from the night literally 1950s from IBM. And what it took was sort of concerted effort by a large number of folks, including the folks and this organization, but also a lot of folks in the developer community to make it so that today we can add search to any application simply by linking a library like slowly Stoller, leucine and essentially getting searched.

Speaker 3:          05:14          That kind of works or in most cases works relatively well. Sort of out of the box. And perhaps more importantly everyone that is these non expert users. You know, my, my siblings and my parents who are, who have never heard of distributed query processing or an inverted index, they can make use of search technology like Google and voice assistant that enables search, uh, without actually understanding the underlying concepts. And so we're asking this dawn product is why isn't machine learning the same way? Well, what we think is necessary and what we're placing our bet over the next five years is that we need to fill out the remainder of that stack. Those tools required for building these production quality data products, going beyond just better models and better cost functions and loss functions to actually providing systems and tools that assess assistant all layers and all stages of the machine learning life cycle from left to right from data acquisition and feature engineering to model training and productionized productionization and then all the way from sort of new interfaces for non not expert users all the way down to new hardware that can exploit the statistical imprecision in these algorithms.

Speaker 3:          06:15          Do things like relax coherency, memory in order to make sure we can run these sorts of algorithms efficiently on modern hardware. So this is our vision and broadly where I'm coming to you today from. We think we have a huge opportunity to build systems and tools and make it radically easier and cheaper to build production quality data products. We're building an open source stack as part of this dawn project. In fact, we're very excited about the potential. Having Google involved in our journey here. And there's a whole website online. You can take a look at to learn more about the stack that we're putting together for this specific talk. I'm going to Skype just one slice of this dawn vision, which is a new system we're building called macro based design to make it easier to extract value and performed classification and aggregation tasks over large scale telemetry streams.

Speaker 3:          06:58          Okay. So I'm missing the zoom in and we're going to give a deep dive into one narrow slice through the stack of work going on at Stanford. And this is joint work with a large number of students and faculty, both my pis who occupy spaces below and say compilers and hardware and also spaces above in terms of new interfaces as well as a wonderful team of Grad students who's actually, you know, building out large part of this, which is all available as open source. So I'd encourage you, uh, how have links in the talk to actually go and download systems like snorkel and weld as well as macro base. Okay. So, where are we coming from? Essentially after the era of, of big data, right? Big Data sorta convinced every CTO on the planet that data had value. We should store this stuff and the cost of value went down precipitously.

Speaker 3:          07:41          So instead of paying, say $100,000 a terabyte for data, we can afford a store it for cents on the dollar and uh, uh, commodity data warehouse like HDFS or s three or, you know, maybe Google big query. Uh, and what we've seen is that there's, you know, a huge, uh, ramp up and the collection of, of streaming telemetry largely driven by increases in automated data sources, right? So it'd be easier and cheaper than ever to instrument complex applications on the server, uh, on mobile phones and also tracking user behavior. And we're generating huge amounts of logs. Okay. So at least publicly, right? The public numbers we hear from our friends down the street, Facebook, Twitter, linkedin, they're collecting over 12 million events per second. Um, I would be a shocked at the number, wasn't higher, uh, internally at Google. And that sort of resulting challenge here as these data volumes continue to rocket is that, you know, for you and I, um, you know, we're not getting any, any smarter, right?

Speaker 3:          08:33          We're not going any faster and picking up this data, right? So fundamentally human attentions, relatively scarce compared to these data volumes and you know, our friends over beers, we'll report that for their, you know, observability platforms that are sucking in all of this telemetry from say mobile devices and servers and so on. Less than 6% of the state has ever actually read, right? You might ask, well, why is this being stored? Well, it turns out that when something goes wrong, you want to go back to the data and actually try to figure out what happened. But the question is, you know, can we do better in order to increase the amount of data that we're, that we're actually looking at in these, in these sort of live to amateur teams and decrease the time from sort of event to detection and remediation. So motivating example of a, of a company we work with very early on in this project.

Speaker 3:          09:17          This was during some of my time at MIT that Faye mentioned. Cambridge mobile telematics is a spinoff from the MIT cartel project. Their products basically collects and analyzes telemetry and the form of driving behavior from end user devices. So they sell an APP that runs up predictive model and says, are you a good driver or not? And we'll give you actually sort of suggestions for how to improve your driving behavior. Okay. The CMT applique application operators who are included, you know, two MIT professors, Sam Madden, Hardwell Christian, great guys, incredibly smart wanna answer. Simple question. Is the application behaving well on every platform? Well, if any of you work on Android, you won't be surprised that this is a difficult question to answer, right? So if we look at the android device ecosystem, this is the device ecosystem. In 2015 we see that there are over 24,000 different android device types and the number has doubled since 2013 okay.

Speaker 3:          10:05          So, so we have to understand, for instance, how our APP is behaving on each and every one of these hardware platforms and also each and every one of our releases of our application in each, every one of the android device releases. Okay. So let's do a little bit of like mental math. Um, if we were going to try to analyze the 24,000 different devices, android device in the wild and just the 25 different android API releases, just spending one second per combination here to check this right manually would require seven continuous days of effort. Okay. Now this is clearly not going to work as we're releasing new versions of our application every day, um, or possibly multiple times a day. And it's actually important that we do inspect these things because in the rare combinations of say, application version and um, and uh, hardware version where there is some problematic interaction.

Speaker 3:          10:53          For instance, there's a buggy accelerometer or that a problem with the connection, especially when people were building sort of android soc for, um, you know, a couple cents or maybe tens of cents these days. Um, we want to understand that these things matter. And in fact, at Cmt, we found, you know, for instance, uh, one problem with us, fortunately not, not an android problem found other android problems, but, uh, for the, for the Ios problems we found, you know, Ios 9.0 Beta one dash five but not 9.0 0.1 had a buggy Bluetooth stack that prevented these ios devices from connecting to the incar car sensors. Okay. So for a very small portion of the population that was running this particular, um, thing, essentially one very small cell, uh, in the deployment and the deploy base for CMT application, there was actually a significant, uh, degraded sort of performance, right? So what we want to do broadly in this work with this macro based engine is to enable us to take all of this sort of high dimensional streaming telemetry and actually, uh, automatically prioritize a end user attention.

Speaker 3:          11:51          And specifically if you were going to do so by combining a large number of, or a small number of highly powerful statistical operators for classification and aggregation that we'll able to pop out these sorts of combinations automatically. Okay. So little bit of a roadmap here for the remainder of the talk. I mean motivated dawn and the challenge of what we're calling a sort of fast data, more telemetry than you can steak shake a stick at and certainly more telemetry than you ever want to look at manual in your own. I'll spend a little of time describing, you know, what's missing, what's missing from streaming machine learning systems today, right? Why do we need a new system like macro basis? I'll describe our approach in the macro based engine to building end to end model cascades that are able to filter and aggregate the stream. And I'll spend most of my time at, towards the end describing sort of how putting these operators together and an end to end system can enable new optimizations that essentially aren't, uh, aren't possible, or it would never be sort of feasible if we just studied this statistical operators in isolation, right?

Speaker 3:          12:47          So basically by putting things end to end, we can suddenly optimize entire pipelines and I can give us orders of magnitude speedups I'll discuss this as a form of, uh, unsupervised density estimation and because everyone loves neural networks all to talk about some more people doing on accelerating inference over a video streams. Okay. So moving right along, what's missing with today's sort of streaming a ML systems? Well, you know, in theory we have really wonderful infrastructure, right? It's 2017. We can pat ourselves on the back that we have a large number of choices for deploying sort of functions on streams, right? So one of my favorite articles from the last, uh, year is this article, all the patchy streeting projects and exploratory guides. There are over 20 different a data flow engines in the Apache software foundation on loan that we can run and download, including one of my favorites from, from you all that sort of the the beam project.

Speaker 3:          13:39          Right. Um, so this is really great. We can basically run a function over a bunch of streams on a bunch of servers. So we kind of have half of the equation required to be able to sort of winnowed down these streams. Uh, the problem here is that, uh, the stream processing engines aren't exactly batteries included for a lot of these tasks. As I mentioned in the dawn question we're trying to address, there's a lot of work that goes into actually building production quality data pipelines and a machine learning products. And so today if we wanted to say query for outlying device readings in a data stream, right, in telemetry stream using Apache spark, you know, we sort of asked the Apache spark creators, including Latte, you know, spark would say, well, you know, sure we can do that. Just write your own user defined function for kernel density estimation.

Speaker 3:          14:20          You know, read a textbook, implement colonel NC estimation and you're fine. And what we find, uh, you know, by and large that although this is a valid answer, uh, the actual implementation of these statistical operators at scale remains a rarely completed a exercise for the end user, right? What we essentially see as people by and large have the stream processing and use but ultimately rely on fairly brittle but relatively fast to execute sort of static rules instead. So a lot of the goodness we could get from stats, uh, essentially remains, uh, in the textbooks. Okay. So we've got a lot of data flow engines you use got to implement their own functionality. You can't just do the stuff with, uh, with a joint or a selector project operator. There's a lot of stuff from statistics, but it's unclear, you know, what we should deploy and how it can compose and combine these things into an end to end engine.

Speaker 3:          15:08          So you sort of need a really rare combination of disciplines in order to be able to build these types of, of pipelines today. You need not just that domain expertise to know, hey, I'm an application builder. I know what my ios application, you know, what normal activity looks like, but I also need to know, you know, statistics and machine learning and he know how to write a bunch of spark code, which essentially in our experience does not really exist in anyone or, or if it does, it's, it's going to be the highest value organizations within sort of the most impressive companies like Google. Okay. So I'm gonna make it easier to do this. And to do so we're building essentially a new stream processing engine specifically designed to accelerate these sort of streaming ml workloads. And, and here's where I'm gonna Start to drop down and abstraction to give you a little bit of insight into what we're actually doing a under the hood here.

Speaker 3:          15:56          So the core questions we're asking in macro basis as part of dawn's, there's a five year project, incidentally, you know, five years corresponds to the end of my tenure clock. So it's a good sort of a timeline there. Um, so I'm betting pretty big on these questions. Um, so firstly we want to know is, you know, what should we actually run in this operator in this engine, right? So, so we knew from like sequel data warehouses, select project joint are really useful and we can, we can kind of string these operators together to build some pretty cool and interesting applications, right? We can do business analytics, we can do customer segmentation and so on. So what's the analog of these operators for this type of sort of fast data analysis where if I gave you like a data cube operator of the streams, you'd have way too many results, right?

Speaker 3:          16:39          So what should we run instead? And then the second question is, you know, how can we use techniques from sort of conventional database systems and sort of large scale data processing engines and the design of these operators that can actually achieve the scale we need to get up to say millions of events per second. Okay. So those are the sort of two questions we're grappling with in this project. Um, towards the first question of semantics, uh, the way that macro based works is we actually combine a three core operators. Okay. So we essentially execute cascades of statistical operators that sort of transform, filter and aggregate the stream. So just for a show of hands, and I read it, I can't see people on the GVC, but who here has sort of um, uh, familiar with the statistical classification or unsupervised classification? Okay. So maybe, maybe half, which is great.

Speaker 3:          17:27          Okay. So I'll give kind of the higher level over you and then a lower level overview. Right? Um, so the way to think about how we're going to process these streams, and I'll illustrate this through a demo, is that we're going to, first of all, taking these data streams and, and using sort of domain specific information. This could be a neural network, this could be a set of rules or transformation functions. We're going to extract the features we're looking for from the stream. So if we're looking for say, oscillations in a time series, well employee, a sort of feature transformation operator that will pick out and record over the last say five minutes of the stream where the oscillations line will subsequently apply what's called classification or statistical classification to segment the stream into examples, often of good behavior and bad behavior for instance, and say this is our, these are abnormally high oscillations are abnormally low oscillations.

Speaker 3:          18:13          And finally, instead of simply reporting all of the raw streams, the users, let's say we're getting 10,000, 10 million events per second, we don't want report 10 million points to the end user. We're going to roll these things up by essentially aggregating them to give her a results like reading some android galaxy s five devices running application version 52 are 30 times more likely than others to have abnormally high frequency. Okay, so illustrate this through it through a quick example. Um, as I mentioned, macro basis, a stream processing engine, uh, so it's essentially a, um, a data flow engine, kind of like spark or um, or storm or beam. But we've also using this data flow engine essentially built a couple of front ends on top of it. Okay. So, so what I'm demonstrating here is a front end. We've built just a simple rest server that's going to call the core stream processing operators that will essentially enable us to run over historical data, right?

Speaker 3:          19:05          So you need, this is kind of exploratory console that's going to exercise the core, um, uh, cascade functionality, uh, that I described earlier. So what does this look like? I've got a postgrest server running on my local machine. Um, it's got a bunch of data from mobile devices. This is a simple or similar to what we saw with the CMT data. And if we just look at a sample of this, uh, for instance from the database is what we might look at if we did a select is actually running a select star and dumping the results, um, on, uh, in the Ui, right? So we've got a bunch of records from giving users and state make model firmware version, APP version, and we have some metrics like temperature, battery drain, trip time. Okay. So, you know, if you and I have say a SQL database or we have something like Tablo or a bi tool, this is probably what we're working with, right?

Speaker 3:          19:53          And maybe we can identify some roses having say hi Tripp time or high battery drain. Um, there's a lot of rows in this table in particular. So, um, actually if we scroll through all of these, we'd probably here be here till um, sometime tomorrow. Um, and, and you know, the challenge here is first of all, identifying, you know, which of these rows is abnormal compared to the population. And second of all, when we have this sort of proliferation of make and model and so on, it's going to take us a long time sort of piece together. Are there significant behaviors going on in the street? So to give an example of this type of functionality we're supporting in macro base, um, what we've enabled is basically automating a process. And a lot of people do today when something goes wrong. So let's say we, let's say we are key performance indicators.

Speaker 3:          20:34          Here's battery drain. So we care about say, abnormally high battery drain. Um, macro based can automatically apply a unsupervised density estimation. So here I'm just an apply a robust estimator of basically mad here if you're familiar with this, but I'm going to find the weirdest battery points with battery drain and the Stream. Instead of reporting all of these individual points, macro base, we'll do a roll up according to you particular attributes that I'm looking for. So, so I can say find me a APP application version and make and model, uh, that, that are unduly or highly correlated with, with, with extreme battery drain. Okay. So basically I've done some really simple feature selection here, uh, expressing a metric of interest and some attributes that I'd like to sort of roll up by this specifies a query. Am I kicking analyze? I actually kick off the stream processor under the hood, right?

Speaker 3:          21:21          So this basically, uh, in this little, little bit less than a second, uh, sort of sucked in about a hundred thousand rows from the postgres database and, uh, applied classifier and an aggregation function and spit out a result as follows. So this combination of application version hardware make and hardware model was a 472 times more likely to result in a abnormally high battery drain than the overall population. Okay. Which seems somewhat problematic. There are 849 records match this particular filter. And if we look at the actual plot of these battery drain readings, the overall distribution of the population is here in blue. And this particular subgroup I identified by this sort of conjunct have app version harder making harder model has a distribution that significantly different than the overall population, which indicates there's something possibly going on with this particular, uh, a subgroup and we can go in and we can drill in this exact data or we can generate a SQL query to dump this into a, um, uh, you know, downstream, uh, engine like Tab Tablo in order to drill deeper or we just go and get the CSV and go play with this thing in pandas.

Speaker 3:          22:24          Okay. But the idea here is that essentially by highlighting a small number of target metrics and explanatory attributes, we can sort of sift through these very large data volumes. And actually get out of much smaller set of explanations or summaries that described the most unusual or abnormal behavior. Okay. So you can think of this as sort of, um, doing what, similar to what, uh, from the sort of users productive. This is sort of similar what people do in root cause analysis, right? You want to find out, okay, some alarm went off. What's common among what distinguishes the things that are, you know, firing alerts versus things that are not right here. We're just automating that process. When the ML side of the house, we're applying unsupervised density estimation, uh, here in a univariate setting and we're applying essentially, um, common tutorial, a feature selection routines over the explanatory attributes in order to pull out these high level summaries that had non expert user can go and sort of dig into.

Speaker 3:          23:14          Now they're sort of cool part of the, about this, about doing this in a unified engine. As I said, we're kind of running a streaming query under the hood, right? So when I actually run this through the Ui, I also get a config file, which can then be used as a seed in a streaming job. So you can basically take the output of the exploratory you, we can basically get the config, like if you say I liked that result, please keep it up to date and we can now run a stream processing job that will continually ingest the data and we'll keep this thing up to date. Okay. So, um, benefits of having sort of a unified a system here. All right, so great. So what are we doing? Um,

Speaker 4:          23:55          okay,

Speaker 3:          23:56          under the hood, right? So, um, we're applying this transformation rule. In the case of the, of the, of the relational data I showed, we're basically just having users select columns, like subsets of columns, uh, for use it in downstream analytics. I'll show some examples of images and videos later. But for instance, uh, if you want, this is what we did. We did a test with satellite imagery where, you know, clearly don't want to look for abnormal pixels, but you can extract, you know, domain specific features like human luminosity. So we were able to pick out, you know, the bit using time varying satellite imagery. You know, if we look at year over year differences in Hue, right? You can pick out things like um, uh, the bay area wasn't a drought in 20, was it 2014 here, right? Um, this is pretty straight forward for time series, right?

Speaker 3:          24:42          If we don't want to just feed in each point as it comes in, we can run sort of an FFT or, or segment the stream into, into windows. Okay. Um, then we sort of apply once we have these sort of data points that, that specify what we're looking for in terms of KPIs or abnormal behavior. We apply a classifier, right? So our default behavior, because most users don't have labels for a lot of their streams, we apply what's known as sort of unsupervised tensey estimation. So we essentially over the stream, um, learn what the distribution of, of data points looks like, um, and essentially find points in the tail. So we measure, you know, basically a a mean and standard deviation. Then find things that are fairly far away from the mean. This is a bit of a cartoon picture and that, you know, in practice, some of our distributions look much stranger, right?

Speaker 3:          25:25          So we'll use something like a kernel density estimator. But the basic idea here is that, you know, with relatively simple classifiers that have no information about the sort of, um, labels, we can actually pick out these sorts of abnormal, uh, events. Um, and finally, instead of simply returning all of these points that we think are sort of, uh, anomalous or unusual and asking users, hey, figure this out for us. Right? And this is actually pretty important, right? It's really a pain to actually go in and say, is there something going on with HTC devices? There's something going on. TCT devices. Are there combinations here? Like humans are terrible combinations. Nothing wrong with us, but we should let already know, you know, you know, robot overlords, do the work for us. Um, macro basis essentially lets us, you know, roll up the stream. So if we get a a stream of say errors and non errors, um, that looks like this, we can ask you to what makes the air is different than the non era.

Speaker 3:          26:12          So this is sort of like running lasso over the, um, uh, two classes, but, but the, but the basic sort of interpretation of this is we say, what, what, what makes these two different? Right? So if we look and we just say, well, I phone six occurs three times and the errors and it occurs one, two, three, four cars many times. And the Non Eris, uh, maybe not that interesting. If we look at Canada, uh, we see her three times in the errors and doesn't care at all and the non errors. So we could say, you know, looks like Canada may have a problem, right? And we can sort of use this measure of co-occurrence with this risk ratio as a measure of severity, right? Where we can say, okay, this is the most severe. A sort of combination of attributes it causes is problematic behavior. So, so what we're doing is we're getting away from results that look like this right and tabular form and we're getting to results look like this where we're highlighting correlated attributes and uh, also sort of, you know, differences in distribution.

Speaker 3:          27:13          So user select our key performance metrics, metrics that are explanatory attributes. We classify a metrics and points that behave at that belong in the tails and then we generate sort of classifications or sorry, we generate explanations using these attributes by doing sort of hypothesis testing. Okay. Any questions so far? Okay. So, uh, one thing that I'll point out that's kind of interesting here. Um, we've, we've essentially combined three different operators. This is a different view of the same pipeline I showed before a transformation classification explanation. And we found that by changing the transformation function and also change the inputs to each stage, uh, we can actually do quite a bit with this with these three operators. Right. Um, so you know, in terms of production uses, I mentioned this is all sort of, um, open source and publicly available. Um, you can use a couple of different ways.

Speaker 3:          28:00          You can use the Ui as I showed in the demo, you can use our prebuilt sort of pipelines where we combine these things into sort of a recipes for you. Or you can just take the individual operators like our fast, uh, explanation operators and plugged them into existing stream processing of them. So, so we've, we've sort of found people using this, this technology, it's all available on get hub for different things. So, so in automotives, uh, one of these engineers who works with me on, on electric car batteries looked at the fleet telemetry and, uh, just you just use the Ui in order to augment their existing CQL queries for their daily reporting in order to identify a problematic interaction with a new firmware version and a subset of the vehicle making models that were in the fleet. Okay. So this was kind of like a, a cubing on steroids style approach.

Speaker 3:          28:46          Um, in online services, uh, we're actually running this, uh, or we, we run this to identify slow containers. Okay. So this is like, you know, you have, imagine you have a process that's spitting out huge amounts of telemetry and you want to know, does landing on a given container, uh, in my data center making me more or less likely to be considered an outlier for my job? Okay. Um, we've used as industrial manufacturing. Maybe the most interesting one coming back to our mobile application setting is, um, you know, if, if you have say, um, exception data coming back from an application, right? So, um, in, in one scenario we have someone who's running an application, uh, live on, um, at least a couple of million devices. Um, whenever they get an exception, they want to know, you know, is there something you know, correlated going on? Right? So let's say you try to open an asset in their mobile application asset fails a load.

Speaker 3:          29:32          Is it a problem with the user is a problem for users? ISP is a problem with it. That cache server the acids located on is a problem with the, uh, hardware may Carter model, application version, so on. So we essentially do automated rollups, uh, for them using this explanation operator. And for these guys, it's pretty interesting. They don't even use the first half of the stack, right? They already have a stream processing engine set up. It's all JVM based. So they can, they can basically take their stream of exceptions. They run them through the macro based operator for explanation, which is the aggregation. And if there's a correlation in the stream that's particular severity, let's say this app version of this, this hardware make, uh, provide say three times or five times higher than usual exception rates. Someone gets page. Okay. So, um, pretty cool love open source.

Speaker 3:          30:19          Like I said, all this stuff we're doing is open source. It's a great way to get sort of feedback on these types of tasks. And you know, at Cmt, which is when I can talk about particularly public, um, you know, we were able to find some pretty crazy device, civic battery problems and an issue with the application on startup that we're basically, you know, unknown to these users. Okay. So we think this is a really cool sort of combination of physical operators where today you'd have to implement all of this yourself. And we found is that, you know, for these non expert users who are really fantastic, like they know everything about their mobile application, I know everything about their sort of data center deployment or know everything about um, say automotive's uh, you know, they don't have the background or the time to go and build up the streaming infrastructure so much.

Speaker 3:          31:01          So providing sort of batteries included, um, you know, you wise or pipelines or even the ability to deploy new custom data flow operators. It's actually a fairly useful, I'm a piece of software and of course on the research side, like I said, I got to get tenure. Uh, there's a lot of things that we're able to do under the hood when we put these operators together that are really not possible, uh, in isolation, right? So we're able to speed up conventionally a highly optimized operators for say classification by taking advantage of the fact that we're not running over say arbitrary data points, but that we're running over a particular user stream with a particular set of properties. So I'm going to give kind of three examples of this type of optimization that I think are particularly exciting. So this brings us from the semantic side, uh, down to the implementation.

Speaker 3:          31:48          So how can we use techniques from systems in order to, um, sort of speed up the execution of this, of these types of operators? And the cool part, or the thing I'm most excited about right in the students are like just, you know, not only crushing a bunch of papers, pushing a bunch of papers out, but they're also sort of finding these things can really lead to quantify qualitatively different user experiences. Um, is it by bringing these teams together, we get new sort of opportunities for end to end optimization. I'll just give you sort of three quick examples. In new, we're going to get to the neural networks as the third example. Okay. So as promised, uh, you thought you knew everything about, um, modeled distillation, turns out you can go even faster. Okay. All right. There's a teaser for those of you and owners in the audience.

Speaker 3:          32:25          Okay. So symbol warmup. Okay, this one's for, this one's pretty cool. So let's say we wanted this explanation thing and macro based, we want to say what makes the good stuff different from the bad stuff. Let's say we have a bunch of bad bad stuff in red and a bunch of good stuff in green and the green probably goes all the way down until you know the center of the core. Cause there's a lot more good stuff going on. Applications and bad stuff, right? If your application is on fire, you probably know about it. Okay. Um, so, so, so what sort of the canonical way that we go about doing this? Well, we're sort of trying to look at what are highly correlated members of each of each class here. So what makes the red or red and what makes the green and green? Okay.

Speaker 3:          33:00          So in this setting, you know, we could very easily sort of compute correlations within each class independently, right? So we go over the red and say a occurs 80% of the time be occurs. 20% of the time we'd go over all the Greens and say, okay, the A's occur 0.1% of the time, uh, bees occur 46% of the time and so on. Okay. Um, this would work. Uh, but to be fairly expensive because if we want to compute not just individual element correlations, we want to compute pairwise order three or order for combinations. How often is ABCD occur? Often is Abe occur, you know, all of these sort of rare sort of combinations that may in fact be correlated with a bug. This can be really, really slow. Okay. So, you know, think about this for a second. You know, how can we go faster than simply running some sort of correlation, you know, mining or detection procedure over each individual group?

Speaker 3:          33:50          Well, the answer's a little bit, you know, it, it's, it's sort of implied on the slide. No, there's not that many red things. Yeah. There's not much on the left. And so we found is that if we exploit this sort of what we call it, conventional database engineer, the cardinality, imbalanced Phoenix classes, we can go much faster. It's almost like when you're running a join, if you want to join a with B and a is much, much, much, much, much smaller than B, you start by building a Hashtag on a and then you only go and touch the parts of B that you actually need to go look for, right? So we do the same thing in macro base. We first detected sort of meaningful correlations and the red class and only once we, once we come up with a candidate set of correlations for elements that are highly correlated, like, hey, then we go and actually touch the, the green stuff, the in liars, right?

Speaker 3:          34:36          So basically, um, we can avoid processing, you know, the Bs and the Cs and the ds and also avoid processing, you know, higher order combinations of these things without actually the full expense. Um, I'm doing this not usually. So by knowing the fact that one stream is much bigger than the other, we can go much, much faster. And, and you know, you can read the papers if you want to see this, but you know, it's like orders of magnitude faster. Uh, it's like, you know, two orders of magnitude faster than running a decision tree and three orders of magnitude faster than doing a lot of other stuff like building a data cube over your data here. Okay. Um, one of the cool things here from the stats side that I geek out about, um, you know, when we're testing all of these hypotheses, right? Um, you might wonder, are you going to get false discoveries?

Speaker 3:          35:16          Right? So in medicine we sort of freak out. Most medical studies are false because people, okay, so let's say you're a Grad student. You finished five years of, of work on a clinical trial and you find out, oh, you know, bubble gum doesn't cause cancer. Shoot. Uh, what am I gonna, what am I going to do? I have a negative result. No one likes negative results and science. So if you're a Grad state with your aunt equals 30 cohort, you're gonna say, well, I wonder if anyone eight seller, oh, nope. Celery's not correlated. I want everyone to carrots. Carrots aren't correlated. Artichoke. Oh, artichokes. I find that significant correlation, which we artichokes and cancer in my population of size 30. Right? So if you test those hypotheses, just like the birthday paradox, you're going to get some false discoveries, okay? So essentially in a conventional statistical setting, you have this problem where with limited sample size, you can only afford a testis limited number of hypotheses like these explanations for generating without getting due to random chance, something going wrong in the macro base setting, right?

Speaker 3:          36:08          With all this fast data coming in, we have the opposite problem. Our problem is not that we are going to run out of some statistical budget, uh, by testing too many hypotheses. Our problem is that we have so many, uh, hypotheses or we start, we have so much data coming in, we need to use our limited computational budget as intelligently as possible, right? So by essentially being able to scale up and process a 500,000 events per second on a single core as we can with us optimize explanation operator, we can afford to test many, many, many more possible hypotheses without compromising statistical validity. That is with simple corrections. So if you're a stats nerd, it was simple corrections like the Bonferroni correction, right at 500,000 samples and a 1% sort of baseline, um, uh, exception rate. You can afford to a test many, many, many different, many more hypothesis than you could with a sample size of say 30.

Speaker 3:          36:59          Okay. So, so sort of surprising result. Um, this was one example of how we can sort of explore this end to end process note that if we didn't have this class, if I operator and we just try to explain arbitrary sub arbitrary groups, we wouldn't have this card Nalley and balance. We'll, because we know we're looking for sort of rare events and many pipelines, we need to exploit this aggressively to improve both result quality and scalability. Right? So, and, and to be, to be clear, like three orders of magnitude of the difference between, you know, waiting for the result, um, you know, all day versus being able to that interactive response in a browser. So this does qualitatively change, uh, one the, the sort of exploratory user experience, but also the ability to alert in real time. Okay. So it's a pretty big deal despite a simple trick.

Speaker 3:          37:41          Um, moving up the pipeline, uh, we've been looking a lot at classification as well and how we can make this faster for more complex distributions. So I'll give another quick example. Um, so I mentioned earlier, we sometimes have distributions looking like this. This is a distribution from, uh, the, uh, UCI Dataset or UCI repository. It's temperature and carbon dioxide, um, in a, a, a building. And you might ask, well, how would I model this? How do I find the data and the tails for this particular distribution? And a, if we apply something like a simple Gulshan, uh, we're not going to fit this fine grain structure particularly well. Right? Um, it turns out that each of the white dots, if you can see them on a screen corresponds to a location or a time in which someone was in the room. Okay. So the outliers actually are statistically at least correlated with, with um, uh, human activity.

Speaker 3:          38:29          Um, but we're not gonna pick that up at all if we use a simple but easy to compute model like a Gulshan I showed earlier, we use something like a Gaussian mixture model, right? And say pull out 10 different Gaussians and plop them in space. We sort of start to resolve this finer grain structure a little bit better, but it's still pretty ugly, right? It's not really capturing all of the sort of structure out in this tale and so on. And we actually get pretty bad classification accuracy. Uh, if we, if we rely on this simple model. So what we want, it's kind of the granddaddy of all unsupervised density estimators, which is this thing that looks like this. It's called the kernel density estimator where we can basically get a really nice heat map of the, of the distribution by essentially performing the following step.

Speaker 3:          39:11          For each data point in our Dataset, we kind of drop a Gao Shin on top of it, right? And if we want to query the density of the Dataset at any given point, like let's say right here, we some of the contribution from all of the individual Gaussians and our dataset. Okay. So it's like every single point contributes a little bit like a little bump to the overall estimate. And this is wonderful because it's, you know, provably ASM tonically optimal and we can essentially approximate for, you know, on a very mild condition socially any distribution or an encounter in practice. Uh, the problem here is that this is actually a [inaudible] squared operation, right? To compute the exact density of each of these, you know, points on the curve requires, uh, for a 500,000 point Dataset, two hours on a 2.4 gigahertz CPU. So this thing is clearly not going to scale as I mentioned, by essentially optimizing end to end here.

Speaker 3:          40:00          By taking advantage of the fact that we're running over a full pipeline, uh, we can do considerably better. And so we asked how can we take advantage of the fact that we're looking for, um, uh, data and the tails to basically run faster? And the answer is we can essentially apply it. You've got another favorite technique of mine from database systems to essentially prune computation. So the idea is that if we're just trying to identify whether or not appoint is above or below some cutoff to say, is this a rare point or not, we don't need to waste our time computing density estimates for all of the stuff above the threshold illustrated. Graphically. If you've got a distribution like this, uh, we don't need to compute the exact color reading for each of these parts in blue. We need to compute are we in the blue set or out of the blue set?

Speaker 3:          40:44          And so we showed him a recent sigma paper that by essentially, uh, computing exact estimates or bounds on densities as opposed to the exact densities. We can take this kernel Nancy estimator, which takes two hours to run on a 2.4 gigahertz CPU and speed up by almost three orders of magnitude simply by recognizing that in the downstream analytics task, we only want to compute above or below. And so now this brings us KTE from the realm of sort of Nice to have statistically, but way too slow to run empirically to nice to have statistically and fast enough to run over over real data sets. All right, one final example before I conclude, and I think this might be pretty exciting for some of the folks who are working on video and image processing here. Um, we've recently been interested in asking how far can we, can we take these ideas and apply them to other domains beyond just streaming telemetry from say devices?

Speaker 3:          41:35          What do we have richer data types like images and videos? So we have a project it'll appear in VLDB shortly called no scope. And we essentially said there are a large number of these neural networks are gonna run to basically feed in, say webcam feeds like the one I'm depicting here essentially extract. Um, you know, occurrences of objects in the world. So here we're taking a bus and some people and you know, if he smoothed the labels well enough, the sort of state of the art does pretty well. And actually extracting, you know, reasonable features that we could use sent downstream analytics tasks. So for instance, we can ask at what times was traffic heaviest of this intersection and Taipei. Okay. Now the problem here is that uh, the state of the art neural networks run about 30 frames per second on $1,000 Gpu. Okay.

Speaker 3:          42:20          And that's going to be incredibly expensive. We want to monitor large numbers of, of data streams specifically, you know, tagging images with these deep nets doesn't scale the popular models that would, that, that are sort of uh, available, are trained on still images. So, you know, work like face image net, that was fantastic. And letting people increase the, the, the quality of their neural networks is only labeled labeled frames, right? It's, you know, bunch of individual images. And so if we want to run this on video, we essentially treat this video as a sequence of images and run it one, one, one, one, one, one image after the other. And so as I mentioned for Yolo Vt, which is one of the fastest models on a p 100, which is an $8,000 Gpu, it's 80 frames per second. A titan x Gpu, which is about $1,200, maybe a little cheaper.

Speaker 3:          43:02          Now it's 50 frames per second. So for, uh, you know, a thousand cameras just in Gpu costs alone, it's about a million dollars. So we want to know, you know, how can we do better here? It might be cheaper with tps. Okay. So we can talk about that, but, um, but it's definitely expensive. So he said, how can we do better? And I'll just leave you with one idea here. Um, if we have a query like this, I want to know when buses passed by an intersection in Taipei using Yolo Vitu. So run Yolo Vitu over, you know, possibly historical data from this, from this scene. Alternatively, live as, as data feeds arrive. Well, Yolo v is amazing cause it can pick out these buses. The problem is it's, it's also good at picking out a lot of other stuff. So, you know, Yolo Vitu can detect things like toilets and cats and skis.

Speaker 3:          43:48          These are literal examples from the training data that Yolo is used to identify. And Moreover, you know, even for things like buses here, there's a bus here, the bus here, because we're looking at this particular video feed, we don't necessarily care about, uh, sort of different orientations, right. When I want to know is, again, I want to know when buses pass by this intersection, right? Uh, in Taipei, right? Uh, so I have a fixed angle and a fixed class and the buses are fairly similar from this video feed, right? I mean, these are five different buses and they all look relatively relatively similar. So the idea is that we can essentially exploit this observation by training a just in time, sort of specialized neural networks where we, the big CNN over the, over the, uh, stream of interest in order to generate a large amount of training data.

Speaker 3:          44:36          So we run that in real time and then we train a surrogate model or a specialized CNN, uh, that can run much faster. Okay. So if you'll OVT runs on 80 frames per second, we use a much smaller network that achieves the same accuracy as Yolo. Uh, but Ron's at 15,000 frames per second. Okay. And the key idea here compared to things like modeled distillation is that we're throwing away the generality of the parent network. This network that we learn, the specialized network will not run accurately on anything but the Webcam that we've trained it on. And it also won't run on anything but buses, right? We're extending this to multi-class and counting and so on. But really it's, it's, it's, it's taking this incredibly powerful network in saying, what if I want to squeeze it down to the minimum network size required for a particular query.

Speaker 3:          45:22          So it's like lossy compression where we can't tell the difference between the original and the, um, and the, uh, the, the new model. Um, so this is pretty cool. And by cascade in these models. In the interest of time, I'll skip over how we handle differences in um, in time. Instead of feeding the video directly to Yolo Vitu, we cascade a thing that tells us if something changed the specialized models with Yolo v two and we have wood running Yolo Vitu as much as possible. So when we run this on things like looking for buses and Taipei or cars and Amsterdam or a cars and Jackson hole bunch of stuff, you can find the paper. We find that we can get speedups um, you know, depending on the accuracy level that you'd like to maintain compared to Yolo Vitu, um, of up to 10,000 decks. So if you want a 1% loss and accuracy, you can often get a 100 x speedup just for free.

Speaker 3:          46:13          I'm by training a specialized model and not calling Yolo v two as much. And then if you're willing to go really, really fast or you can't afford to run over, uh, uh, you can't afford to run Yolo over all the study historical data, you can sacrifice even more. So sort of our, our, our thought here is that instead of just obsessing over, you know, 99.5% accuracy and going a little bit lower, we can train a much specialized model for a given task at hand and actually achieve dramatic speedups that actually make these type of large scale video analytics actually feasible at scale. So, uh, those were three examples of how we can use techniques from systems design of sort of efficient operators, uh, for online training and inference. Um, I'm running out of time, so I'll just leave you with, with a couple a things to think about.

Speaker 3:          46:59          Um, macro basis as I said is, is, is sort of a new open source engine, lots of projects going on inside of here around making it easier to make use of and derive value from online streaming data sources. And it's been really exciting to see what the open source community has done with this. And I'd love to talk with you all about possible, uh, use cases and extensions for this. Uh, and we, we spent a lot of time talking to developers and engineers actually valid and stuff in the field. So that actually really drives the whole of dawn. Uh, our sort of strategy is, is really informed by current use cases, uh, both on campus and off campus and sort of high volume, a high value, um, machine learning pipelines. Uh, there's a ton of work on macro ways you can find on my website. Uh, I think two of these are now in, in Vldb if you're interested. Um, and the, the, the message that I come to you with in conclusion is very optimistic that we have a lot more data than we know what to do with. We can do a lot of cool stuff with systems in order to make this data useful. Thanks for your time.

Speaker 1:          48:04          So for speeding up Yolo that work, um, did you care what kind of error, if you're willing to be faster and sacrifice performance a little bit. Did you, can you elaborate on, do you get more recall or the precision? What type of error?

Speaker 3:          48:19          It's a great, yeah. So good question. So, um, two things about our current experiments. So right now we set a, you can we up? So okay. We basically let use or specify a false positive false negative rate. And currently I think we're doing 50, 50 split on both. So I think this is like, you know, I say 1% would be 50% or 0.5% false positive 0.5% false negative. Um, but uh, we like the code that we have basically in the optis optimizer we have lets you basically tune those parameters. So certainly if I, if I have like no buses in the scene and I allow 100%, you know, false negative rate, then I'm fine. But, but it's kind of configurable. So I think with what the results I presented were from 50, 50. One thing also point out compared to your a Yolo and we're working on this right now is we're doing binary classification bus, no bus. We're not doing bounding boxes. So, um, one of the summer interns of summers, it has extended no scope to do the bounding boxes, but you don't get the same speed up. You still get up, I don't want to quote numbers, but it's still going to be more than like a two x speed up for this. Yeah.

Speaker 1:          49:20          Okay. Does that mean, so if you really, if we want total recall, are you still gonna going to get that kind of a good speed up?

Speaker 3:          49:29          Yeah. If you want total recall, um, you won't, you'll definitely get some speed up. Well, okay. It depends. Right? So there's some cases like some of these sort of filtering steps. You can totally do like a one thing I didn't talk about what we do. We train a temporal, you know, different detectives says, did this frame change? So what this looks like is basically I did my frame compared to the last thing I ran Yolo on and I basically, uh, tray, you know, run an LR over the differences and logistic regression over the disturbances that says this thing. Yeah. Something likely changed. So if I'm running at 30 frames per second, you know, it's highly likely that the label change rate is much lower than the frame change. Right. So, you know, that's a way to get, um, you know, 10 plus x speedup basically for free for the specialization task.

Speaker 3:          50:14          I believe it is possible to actually get, um, substantial speedups. I don't want to say, you know, three orders of magnitude, but, um, you know, we've been, we've been benchmarking things like, um, if I just train, um, resonates on say cat versus dog versus cat versus insect and various forms of sort of restricted input classes and restricted output classes, you can still get a five to 10 x performance increase right? Now note that this is not going to be a recall on the entire set of the, you know, uh, images but basically specializing forest fixed out of classes. Our preliminary results suggest you can get, you know, much more than you can get from doing like training with quantitation and training of pruning. Right? So, so, and this is just because essentially w w well, yeah, we can take it offline, but, but I think the cool idea here is that if you restrict the, you can even like to, you know, the, the manifold of things that you're looking for, you can train a much simpler classifier to distinguish between these, um, if you restrict the, the test data. Yeah. Thanks. Yeah.