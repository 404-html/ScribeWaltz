Speaker 1:          00:00:06       So, uh, the book is called the sentient machine and it really is, um, uh, varied book. You know, it starts off with, um, some philosophical ponderings on what the advent of Ai really means for us. There are, as you know, some existential concerns regarding the advent of more and more powerful Ai, uh, Agi. And then Asi and lots of very worthy scholars have written volumes, uh, about these, for example, Nick Bostrom's superintelligence, which I'm sure many of you have heard of if not red. And then beyond that, there's also discussion around, uh, essentially these two fears that keep sort of a rearing their head in, in different ways, but one that AI will take away all our jobs and it might render us useless when it gets to a certain level of complexity and capability. And the other is that it might kill us. And of course that has many different, um, aspects and, and situations under which that fear manifests itself.

Speaker 1:          00:01:19       But, uh, in a nutshell, those are two real conversations that are happening these days. And for this audience, I'll also tell you that these are not just hypothetical or philosophical quandaries. And questions anymore. They are now being played out at the highest levels of government. Uh, so spark cognition works in three principle areas, national security industry and Energy and finance. And as a concept, and I won't talk much about our own work, this is, this is a talk about the book. This is not a talk about spark cognition on my work per se. But, uh, because of that background, I ended up meeting with and having some pretty interesting discussions with, uh, the senior most military leadership, not just in this country but also for example, in allied states in Europe about two weeks ago, I addressed the NATO counsel on their adapt Taishan a report that was about to come out and how, believe it or not, AI will play a great role in the new adaptation report that was just released based on the writings that a general John Allen, who's my collaborator and also on the spark cognition board and I, uh, published earlier this year.

Speaker 1:          00:02:37       So that's just one example to say that artificial intelligence is becoming real in many, many ways and perhaps in narrow domains initially. But the capabilities are widening. And for some of these existential concerns that people have expressed, um, for example, that it will take jobs away. Realize that we don't need commander data, Agi level capability for those sorts of things to be threats. Eni Capability implemented in many different areas can lead to 30%, 40%. God knows what percent unemployment remains to be seen. And that's for developed countries. On the other hand, for undeveloped countries or developing countries, they have invested a lot in there, a burgeoning what they call their demographic dividend. You know, people that have been brought out from, uh, conditions of, uh, sort of, uh, you know, underprivileged and are now being educated and are being made available to do complex tasks in the economy.

Speaker 1:          00:03:51       Well, some of those complex tasks might be subsumed before those generations get an opportunity to really make a mark. So there's that, uh, emerging sense of the fallacy of the, uh, burgeoning middle class in developing countries and whether they'll be able to play the role that we once thought they would be able to play. We don't know. We'll see. At what rate these technologies progress. But my point here is that all ready, we are at a point where the discussion around artificial intelligence is partly technology, but it's also partly policy. And, uh, in my own case, I've tried to bring these things together. And in the book you see, uh, the science, the philosophy as well as elements of policy because ultimately we have to do something about this. Um, and I'll tell you later on as we get into this, uh, for example, some of the discussions around bands and autonomous weapons, I've been quite deeply involved in all of those debates and have, um, met with, uh, a lot of folks that really do matter in that, in that debate.

Speaker 1:          00:05:01       So we'll, we'll go through that. Um, the way I would structure the talk is I'll start off with a very brief reading. Uh, and you know, the beginning of all of these sessions ends up being different just based on what chapter you choose. So here we were talking about autonomous weapons. Maybe I'll start with, uh, the beginning of a chapter called warfare in Ai. Um, and then we'll talk about more broadly some of the content in the book, but I've also structured a presentation that takes us a little bit beyond the book. There are some concepts here which for accomplished computer scientists that are in the audience might seem to be very basic and you, you may be familiar with them and I'll go over those quickly if they become boring, but then we can get into some of the other issues. Um, and some of the problems that I think we still need to solve. So that's how I'll go. And of course I'm open to questions at any time and comments. I would welcome that. Okay. So for those of you who do have the book on page 87, I'll start with a very brief reading of this chapter is titled Warfare and Ai.

Speaker 1:          00:06:11       Join me for the thought experiment originally published in the U S Naval Institutes Proceedings Journal and conceived off by my friend and collaborator General John Allen of the United States Marine Corps, a four star general and pass deputy commander of US Central Command. It is January two 2018 and a captain is contemplating damage to his ship after a surprise attack. This however, was no ordinary attack. He is about to discover that this was a massive widespread strategic surprise. Our captain and his crew had not anticipated the incoming swarm because neither he nor his ship recognize that their systems were under cyber attack. The undetected cyber activity not only compromise the sensors, but locked out defensive systems leaving the ship almost entirely helpless. The kinetic strikes came in waves as a complex swarm of drones door into the ship. It was attacked by a cloud of autonomous systems moving together with purpose, yet also dynamically reacting to one another and to the ship.

Speaker 1:          00:07:31       More than anything, the speed of the attacks stunned and overwhelmed. The sailors though the ID specialists on board the ship, we're able to release some defensive systems from the clutches of the cyber intrusion. The rest of the crew simply did not have enough decision making time to react mere seconds. And in these few seconds, some of the sailors ascertained with their limited situational awareness that the enemy's autonomous cyber and kinetic systems, we're collaborating. But in a matter of minutes, the entire attack was over. The captain survived and courageously remained on the bridge, but he was badly wounded. As we're, as much of his crew fires were burning out of control and the ship was already listing badly from flooding because of the damage the captain was unable to communicate with the damage control assistant who was herself badly wounded. It appeared that some of the autonomous platforms knew exactly where to strike the ship, both to maximize the damage and reduce the chances of survivability. The captain's ability to command his ship was now badly compromised and the flooding was out of control. After surveying the entire situation, he realizes he must make a call that no American skipper has made for generations. He issues the order to abandon ship.

Speaker 2:          00:09:08       Okay,

Speaker 1:          00:09:11       so going through this, um, you might wonder if this is a fiction. It is. You might wonder if this is entirely imagined fiction with no grounding in truth. It is art. Um, it was very interesting, uh, this past year I had the opportunity to travel through the Middle East. And as you know, there are many numerous active conflicts going on in the Middle East and many of them are conflicts that are taking an asymmetric, uh, sort of, uh, uh, tilt where you've got somebody like the who theories as an example in Yemen or you've got isis terror organizations and Syria and some parts of Iraq and you've got then on the other side for the most part, well armed military forces with sophisticated radars and Patriot missiles and so on and so forth. And um, let me just tell you that, uh, I know for a fact that much of what is described here, maybe not with this level of nation states sophistication, you know, because here what we described is a swarm of a improvised you calves coming in with pretty sophisticated vision and other recognition capabilities going forward. Well-Protected asset, but similar scenarios have actually played out in the current conflict in the Middle East. The DIY AI improvised flying IED is already here

Speaker 1:          00:10:49       two weeks ago. Uh, the Convention for Conventional Weapons, which is a little awkwardly named, but CCW at the UN got together I think for the third or fourth time over three or four years. And they're 107 member states of this organization and the UN. And every year they've gotten together and expressed their dire concern over the potential spread of autonomous weapons and what they must do. And of course, you may remember the famous what's called the Elan Musk letter, which was really not Elon Musk's letter. It was the most recent one was written by Professor Toby Walsh, uh, from the University of New South Wales in Australia. He's an AI professor there. And of course, Elon Musk was a signatory, and then the letter was presented as a desire or a request for a band, which it was not. It was a request for a discussion. And at the end of this most recent session, 107 countries even get together after four years of debate and agree on what the definition of an autonomous weapon is.

Speaker 1:          00:12:01       In the meanwhile, the clashing cove bureau, which many of you may have heard of, which is the Russian weapons manufacturer announced that they were testing a UGV and unmanned ground vehicle, which in field tests had already shown better than human performance. Now, you may doubt these claims. You may think these are oversold, but wait a year or two. Similarly, China announced that they were fielding AI powered cruise missiles and the Mig bureau announced that the new next gen meg aircraft would have AI autopilot operating, uh, to control the flight envelope at hypersonic speeds. So this is just one vignette. This is just one side of Ai, which is it is a technology that brings or distributed autonomy at large scale to the field of battle. It is a strategic level up, if you will, in terms of capability and no significant player, no significant military is going to ignore this.

Speaker 1:          00:13:09       Uh, and just to give you further evidence of this, of the hundred and seven countries that were at the CC w session, there were only 22 that came out and said, uh, we are in favor of a ban of all the nuclear states. There was only one which supported the band and of all significant militaries in the world, all states with significant militaries in the world, only to supported the band, the largest militaries, the countries with the largest number of nuclear weapons all argued for further discussion. Let's push this off to next year. So that's where we are. That's just one vignette. But with that, uh, let me start talking about sort of some of the things that we, that we cover in the book. So what's quite clear to me now is that we've made enough progress in several areas where a new form of intelligence really is coming.

Speaker 1:          00:14:08       I mean, it's no longer sort of the wizard of, uh, the wizard of Oz, a man hiding behind the curtain. It's no longer just large numbers of if then else statements. And while we keep uncovering every now and then company x and company y outsourcing some activity that they call intelligent Petrolia, it's going out to uh, you know, the uh, Amazon Mechanical Turk type situation. Really aside from all of those things, intelligence in an increasing level of intelligence is being built. And we've had, with deep learning in particular, we've had great impact on perception tasks. You know, where we want to, for example, classify, we want to perceive something and extract complex patterns and even patterns across the moral boundaries. We've been able to do that very well with deep learning and now we're sort of running forward with reinforcement learning with lots of new innovations. And, uh, the, the, the key thing to take away there is where moving from the domain of perception to the domain of action and even within reinforcement learning, now we have the ability to um, train systems up maybe in simulated environments and with some of the break break break throughs that are taking place and transfer learning.

Speaker 1:          00:15:26       We take the, uh, learning that's done in a simulator and, and translate that to the real world. So this is not a talk about the current state of the art in all three of these areas, but just a couple of minutes to say that this is becoming quite real and indeed a new form of intelligence if not sanctions is coming. Sanctions I think is far away. Um, so with this, just a quick background, uh, one of the things that you know, I think I do differently in the book is simply a consequence of my own background. So I'm a serial entrepreneur and I've been based in Austin and I went to school at ut Austin computer science and have done a number of software companies since then and spark cognition a, it was a company I founded back in mid 2013 the company focuses, as I mentioned on national security finance in industry.

Speaker 1:          00:16:25       In fact, we are a Google partner on a number of different things and, and the company's grown really, really fast. In fact, it's the fastest growing company in Austin. Now with that being said, that's the business side of things, right? How you actually take this technology and make it work and make it solve problems for the largest companies in the world. But the other side of this is that I come to this not just purely from a business background. I am a computer scientist by training. I love computer science. I love computer science. And, uh, I serve on the board of advisors of ut CS, which is one of the great, uh, really pleasures, um, when I'm, when I'm able to spend much time there. So it brings sort of the business aspect, the practicality of making these things work with the science and attempting to advance the science.

Speaker 1:          00:17:12       And then finally, the center of new American security is one of the premiere think tanks in DC. And I serve on their advisory board for artificial intelligence. In fact, about two or three weeks ago, I was in DC. We were, we had a scene as conference on AI and what this would mean for autonomous weapons. And there were lots of generals and a serving and otherwise and, and many, uh, policy policymakers in the audience. But we also had Eric Schmidt there. And a, I had an interesting discussion with a, with Eric and one of the topics that came up was, well, uh, how long given the China just announced their 20, 30 AI plan, which many of you may have seen, it's an investment of $150 billion of government spending. Uh, over the next five years. In 2015, the u s government spent one point $1 billion on AI.

Speaker 1:          00:18:09       And in 2016, we spent a whopping one point $2 billion on AI. Again, the Chinese government has committed just governmental spending, $150 billion over five years. And if you read the 2030 AI report, it says by 2030, we will be the dominant AI player. In addition to that, they also talk about all the applications of Ai. And a big chunk of that is military application. So here we were in DC at this conference and I asked Eric, I said, Eric, um, you know, I have a view, but what's your view? How soon do you think China will be able to overtake the U S in Korea? I capability? And it's on video and then they will a lot a lot of articles written about it, but he said five years, I don't disagree with them, it sounds very aggressive, but the rate at which progress is being made, the rate at which, um, you know, just if you look at face plus plus send the rate at which they're improving their vision algorithms.

Speaker 1:          00:19:11       And a few years ago I remember people used decide, well, you know, AI papers and China show, they are publishing a lot of AI papers but they're not as good as good as us. Well now that's really not the case anymore. And it sort of reminds me of the whole, um, the, the reaction that we've had too many other countries that have been catching up, it probably just copied it. Oh, it's kind of like a fake, uh, you know, sort of, kind of there, but it isn't the same thing. And then suddenly, very quickly you realize that, that folks are catching up. And where we are in our current situation as a country is that we're doing things like preventing the spouses of h one B immigrants from working, which means that fewer smart people will be able to come in. Uh, we're trying to ban entry from a number of countries and uh, limiting the number of smart people that we'll be able to bring into the u s so while you have a near peer competitor putting a 150 billion to your 1.2 billion, you're also then strangling, uh, some of the core elements of a innovation that have historically been so useful.

Speaker 1:          00:20:24       A useful for you. That I think is a bad timing.

Speaker 1:          00:20:30       So moving onto another element in a lot of these stocks, people ask just the simple question of, well, what does it mean for a machine to think? This is obviously a very complex question and there's many, many different ways in which a machine can think. And we tend to describe things in the context of a neural, where you take a neural network, you give it a lot of data, and then you can ask it a question about what you've trained it on. And it leads to classify or in a regression sense, give you some sort of an answer. But I figured that from a visual perspective, no, there's many ways machines can think and AI isn't just machine learning. There's many other things in AI as well. Uh, for example, a search based optimization. So here, one way that you can think in a problem domain is let's just take the simplest example of tictactoe.

Speaker 1:          00:21:16       Uh, given just a couple of rules. You can pre generate all the possible outcomes and then what is perceived by the human player to be a smart move is simply a goal seeking behavior where I know what a win looks like and I've generated the tree or the graph. And I'm trying to traverse the graph to find the most efficient path to what I know to be a win. And that's one way in which you can make machines, uh, appear to think. But we also know that not every problem has such a small state space. So there are problems. I mean even games taken other game like Batman where uh, you know, whereas miss pacman quite at this moment and how many of the golden nuggets have been consumed and what's the direction of each one of the photos? And did you eat the berry or not?

Speaker 1:          00:22:10       I mean, there's a lot of variability in that state space. So that's the kind of thing that you wouldn't want to just encode in this way. So then now we try to do things like a reinforcement learning where this start off and start playing the game and you end up and you've die pretty quick, but maybe you made 50 points and what you are trying to remember is what sequence of tasks got you to those 50 points. The first ones that you took are pretty much worth the 50 points because they lead to you getting the 50 points. But as you move further along in that stack of moves, you realize that the closer you get to 50 the less valuable. Each one of those more recent moves were because goddammit, the last one got you killed. So that can't be very valuable. And so you can have this sense of, well let me feel, and there's again many, many different approaches to this, but you can have an element of randomness to where, let me try and get the maximum reward.

Speaker 1:          00:23:11       But when the level of reward goes below a certain threshold, I'm going to try different things and maybe I find something that's more interesting. So this is sort of like a self pruned search, you know, in reinforcement learning and just layman's terms. It's sort of like a self pruned search where you start off with something and you don't abandon that, but you just look for improvements where you can, you can find them. And we've seen great progress with this. Now another thing that I will point out is that even in this, uh, idea where you are generating entire states, by the way, stuff that's not fashionable people stop thinking about. But there's a lot of problems that can be smartly pruned to where these sorts of solutions are still pretty good solutions. I mean you don't hear a star search much now, but if you apply data properly to a star search and you come up with clever heuristics on how to prune what gets generated and what gets searched, there's a lot of problems that you can solve pretty cleverly with a star search.

Speaker 1:          00:24:14       But anyway, uh, in this particular case where you see the full tree, one thing to note is that generating the states sometimes can be incredibly simple. Can, that's one concept that I'll build on here. So here, what you had to know to generate this whole tree is that for every progression you can only change or add one symbol at a time, right? So if you've got knots and crosses, either it can be, uh, you know, you can add one not or one cross, you can't add two knots in one go. Um, you need to know what the winning state is and that sort of, we all know a diagonal or line or a horizontal bar. And then with, with every step here, as you step through the tree, um, in every layer you are alternating symbols. So first you get a knot, then you get across, then you get a knot and so on.

Speaker 1:          00:25:05       That's all. That's all that you need to know in order to generate something like this. And so, uh, is that, you know, sort of this mind altering fact in the context of knots and crosses? Not really, but it does go to say that very, very simple things when iterated upon when, uh, when, uh, dealt with with recursion can create tremendous complexity that can be useful. Okay. So a seed of specification can, can create something that is very, very large, very, very useful and sometimes a little unexpected. These are concepts that at least in two different places, and we know we talk about the game of life briefly in the sentient machine, but, uh, what I cover is just the basic introduction. Uh, Stephen Wolfram, who's the creator of Mathematica and somebody that I followed for many years, very interesting thinker in his book, a new kind of science.

Speaker 1:          00:26:09       He spends, you know, almost 200 pages just going over different forms, different variations of the game of life. And these, again, if you, how many of you are familiar with the game of life? All of you. Okay. Almost. Uh, and so again, these are really, really very simple rules. And what from shows is that you can have these incredible levels of complex non repeating patterns that come from very, very basic rules. Uh, and other sort of more in lines of sort of a continuous mathematics is this notion of, of fractals. And there's two things that I wanted to quickly say. So one, uh, since you are familiar with the game of life, I'm sure you've seen simulations like this, but to me, every time I see stuff like this, I'm amazed, you know, it's a, there's these creatures would like distinct behavior that, that evolve every time.

Speaker 1:          00:27:07       And they, some of them find stability and others oscillate between two states. And then you have some movement. You have this, uh, you know, artifact called a glider that just sort of walks across diagonally. Usually you have these blobs that can combine. And then what comes out of that is at least not visually, immediately predictive. And these can be very complex sort of behaviors. And looking at that, you know, does seem to be like there's something going on here. And of course we know what's going on here is just very simple. Three simple rules. But the manifest complexity is far more than those three simple rules. Uh, an initial reading of those three simple rules would imply the same as the case really when you start thinking about fractals because, uh, I mean this one is the Mandelbrot fractal and Belvoir Mandelbrot came up with an expression, which is Yay long.

Speaker 1:          00:28:08       I mean, that's it, right? That's the, the amount of math that's being generated into the structure. And the reason why we're going into this is that a, I mean, again, for those of you who've read Ender's game, the book and not the movie, uh, you'll, you'll, you'll realize or recognize or remember that there's one comment in there that was made where ender was at this training facility and he was given access to a large computer and somebody pulls him away and says, what are you doing? And he says, I'm traveling through the fractal. And now the fractal is larger than the known universe. So when I read that as a teenager, it sort of stuck in my head. I don't think that when the book was written that computers had actually generated a fractal that was larger than the known universe, but now, uh, that have many examples of this.

Speaker 1:          00:29:01       So to think that this much math, this much specification, this much code can generate something with unending complexity that is a unpredictable actually, uh, and unique at so many different levels. Um, to me is pretty amazing. And the two ingredients of that of course are the specification and the iteration and the recursion. And that gets me to one of the points that I make in the book also about the universe being computable in a different way. So you've heard, um, Elon Musk recently talk about how the universe might be a simulator actually came across that concept of in my youth, a gentlemen by the name of Ed, Fred Kin had written extensively on this. And then when I started digging deeper, I realized that Conrad, sir, even back in the forties, had talked about these concepts and add, Fred can, um, you know, this article my father gave it to me. It was published in a magazine whose God is the universe of computer. And the idea there was not so much Elan's mosque idea, which is that we're all living inside the simulation, which is one type of simulator inquiry. But the other idea was, is the universe fundamentally computable? Like everything we see, is it a consequence of computation?

Speaker 1:          00:30:24       Many years later, my sister became a string theorist and um, I tried to get, uh, at least, uh, uh, a workable understanding of string theory and my many conversations with her. And one day she sort of lost a patients with me and said, listen, all of what we write in, in words in English, it's just a sort of 0.2 roughly in the right direction. If you want to understand any of what we are really saying, you have to work through the math. None of this really translates in, uh, in, in language. And the one thing of course from string theory, which is very interesting, is the, the, the rediscovery potentially of what the Greeks called the atom, you know, ah, Tom, that which cannot be cut. They were in search of that final particle that was truly in divisible. And perhaps with the Planck length, it's not so much the particle, but it's the fact that we know how small a particle can be.

Speaker 1:          00:31:27       We have, if the universe is Minecraft, we know the smallest size of the Pixel of the block, right? Within which there can be nothing else other than just one symbol contained. And what does that symbol, that symbol can be a configuration of a string. So in that sense, I started thinking, well, if that's the case, then you essentially can model the universe as a data structure that has these fixed size cells that are planned class size cells, which have a number of these, uh, symbols in them. And in that sense, it's computable, right? So who knows? Lots of different people are thinking about this in different ways. Uh, Max Tegmark has his book. Uh, and he talks about some of this, uh, of course, ed, Fred, Ken and Conrad Zeus, or like I said, have been thinking about this for many decades. Um, and, uh, Stephen Wolfram has his take on it, but there's something here. There's something here about the fact that computational constructs on very, very small, um, recipes can create this sort of a useful emergent complexity.

Speaker 1:          00:32:43       And now as we know, you know, computers can create computational realities. I can today basically build my own world. I start the book off by saying that I got into computers because at the age of four I ran into a commodore 64. I saw hang man laying on the screen and it blew my mind because I had never seen a TV screen play out what I wanted it to play out. And yet there was a keyboard which I could touch and suddenly everything was fungible. This notion of programmability for a four year old mind was, was completely mind blowing. And from there it went to, well, what can I not create? And now of course we know we can pretty much create what we want. And even the physical dimensions of all of this are not gated in any way by by reality. These are some just fundamental things from computer science that we ought to realize that, uh, the, the basic constructs of computer science, the magnification, it'll constructs the iteration, the recursion and so on and so forth.

Speaker 1:          00:33:42       Applied to very basic specifications can yield a lot. And then if you start thinking about the mind of a machine, which any such, uh, thinking is partial because we don't know, we, you know, there's a lot to be done. There's a lot of questions to be answered, but think about things just in terms of differences with us. Well, one thing we know pretty well is that, you know, our brain fits into a relatively small cranium and consumes about 20 watts. It's very, very efficient. It has a very large number of neurons. It has a very large number of connections. But, uh, for all of its efficiency and size, etc. It's not really substantially going to consume more than 20 watts in its present form. Um, while we don't have a computer that's as efficient as a brain yet, we do know that our computers can consume much more than 20 watts.

Speaker 1:          00:34:38       They don't have to sit inside a physical cranium. That's the, the size of ours. Uh, perfect recall, which is that, and this is interesting because you know, we tend to sort of live in the moment. We get what we need from that experience and we tend to forget. And in many ways this is good for us. It's good for us actually because it avoids overload. And this is common with another thing that we do, which is very aggressive pruning. So we tend to go down certain solutions and we tend to discard things that sound ridiculous to us. So the reason why that move that Lisa Dole and others found so magical, even all the commentators that were great practitioners of go was because it just was one of those things that they were willing to discard. Nobody's done this before, I've never done this before in this situation.

Speaker 1:          00:35:31       Why the hell would you ever do this before? It becomes sort of common sense. It becomes the kind of thing that is system one thinking in a few go back to [inaudible] and his teary about how we think, thinking fast and slow and we start pruning things. But in machine intelligence can actually be in a place, can take everything in, can learn what it can at the time, but the original experiences entirely preserved. So if its ability to extract more knowledge from that experience improves over time. The original data and full fidelity is still available. In fact, uh, my colleague, Professor Bruce Porter, who's the chairman of the ut computer science department is working on a long running project that does something like this, which is that he's developing machine. Um, so natural language understanding software and he's been working in that area for 35 plus years.

Speaker 1:          00:36:25       And his approach is that what I can't understand what my current algorithms in the corpus will get tagged in a special way. And every iteration of the algorithm will go back and look at what the previous iteration was not able to understand. So this sort of constant learning with the availability of the fully preserved information. That's not how we usually think about things. We filter out a lot of stuff. And then of course there's other things like being disembodied. I mean there's no need to protect a physical a body at all. There's no need to comply with a size limitation. And of course we know about the faster processing. So, uh, you know, the question here is if human beings are devolved with an eye also on the back of our head, would we be fundamentally different? Probably. Probably. I mean, a lot of the Amygdala driven response that we have now in situations of fair where, you know, uh, we, we are aware that there could be something pretty close behind us that's got to keep us, uh, that could get us and therefore we have to keep at a high state of readiness.

Speaker 1:          00:37:34       Well, uh, maybe that we would be less, I'm neurotic, you know, with an eye at the back of our head. Who knows. Uh, so these are all the kinds of things that, of course in, um, machine intelligence, we get to experiment with. One other element, very practical element of what's happening right now, um, is, you know, so, so we're talking about AI of the future and the mind of a machine and so on. But what's happening right now, you know, and in the valley, everybody knows, Marc Andreessen said awhile ago that software's eating the world and that sort of a euphemistic thing. But for me it's a, it's a very real physical thing. So this is, uh, you know, traditional, uh, combustion engine and you've got an electric motor onto the right hand side and you've got valves and, and, uh, uh, spark plugs and efs and carburetors, and you've got a block and you've got all of things going on here.

Speaker 1:          00:38:36       And each one of them has a specific function. Each one of these mechanical elements performs a specific function. And then you've got an electric motor where most of the capability of the mechanical elements has been transformed into software. The Efi, for example, how you gate energy is now all software. So the reduced number of physical components in that picture on the right is when you subtract that from the picture on the left. That is the amount of physical stuff that software just eight. Okay. And there are similar pictures like this across a whole host of areas. We work very closely with Boeing. Um, I can tell you that the future of aviation, even though it's not going to be very imminent, but Boeing's invested in a company that's doing electrical engines for proper commuter aircraft. You're not the size of a triple seven yet, but you know, multi seat commuter aircraft, short haul a electric, that changes a lot of things.

Speaker 1:          00:39:40       If you look at what companies like [inaudible] he hang hangar doing the Chinese company, he hang with autonomous drones. Uh, the city of, uh, um, actually the country of UAA appointed an AI minister recently and they've expressed their, their desire to build the world's first autonomous flying a taxi service. And they in fact even signed a contract with a Chinese company and they're now looking to move that to somebody else. But they are committed to doing that. So these things, uh, even in the narrow context are happening and uh, the, they're, they're certainly coming to, to, to bear last point here I'll make and then we will kind of stop for questions. Um, important thing is not so much, uh, whether AI will do everything. The important thing I think is what all can a, and I do in a given period of time. And if you look at the right there, that's a study that was done recently, a poll. Many AI experts and you may agree or disagree with

Speaker 3:          00:40:48       those and some of them may be optimistic and some of them may be pessimistic, but for example, the ability to assemble any lego right in the next 10 years or so. Now we know that when you can assemble any Lego, you're not just assembling Lego. It's a fairly general purpose capability that you have a manufacturing robots have been increasing in huge ways. If you look at warehouse management just five years ago and what we have now in terms of warehouse management capability, it's tremendous. And nobody's going to want to discuss, you know, the poetry of Robert Froster roomy with a warehouse management robot. But it is going to take a, it is going to have an impact on, on jobs. And so part of what my uh, push really has been a particularly on the policy side has been, look, we hear it all the platitudes that uh, you know, people say the machines are coming, the machines are coming, but really it's like any other revolution.

Speaker 3:          00:41:46       It's like any other technological area of progress, era of progress rather where there'll be new jobs and all these people that are displaced here, we'll find things to go do there. And I think that's just complete hogwash. I think that's nonsense. I think the two things that we've done, one, we've replicated human muscle with the steam engine, which basically we got ourselves out of every job that requires a muscle. And now by replicating, not the entire mine, but even parts of the mind, slivers of the mind that are good enough to form a, to perform a function. We are at a point where we can automate much of what we do in, in many, many professions. And that's all we are. We are muscle and mind. I mean that's what, that's what it is. So there's no third thing to go and replicate. And with this, the impact may not be us in Barka loungers you know, Allah, Wally, but it might be 30, 40% unemployment.

Speaker 3:          00:42:49       And who needs to start thinking about this? The people that need to start thinking about this are the people who make policies. And there are some countries where, for example, they've gone and they've started experimenting with them. Uh, things like, uh, you know, a minimum wage of essentially minimum guaranteed income. Um, there are countries like France, which are progressively reducing the number of workers so that automation can pick up the slack and people can get time back. I don't know, Bill Gates has proposed a tax on robots. I am not proposing a specific solution, but what I am saying is that the level at which this discussion is happening with the inevitability of the impact right ahead of us. I think that level of discussion is uh, in significant and insufficient. And I started the stock about, uh, you know, talking about autonomous weapons and sharing with you the rate at which the CCW UN is making progress on even defining what an autonomous weapon is.

Speaker 3:          00:43:58       While at the same time autonomous weapons are being deployed. And here again, we might find ourselves in a, in a situation where more and more automation will make it into factories, into retail spaces. Uh, we're working on an engagement with a large company in Dubai to do concierge intelligence based on natural language processing in retail stores. It's going to start off being interesting and sort of like a, you know, how do you get people in into the shop and you would track them with something that's a new and shiny, but it'll get pretty good pretty quickly. So, uh, that's kind of where we are in my, my hope is that we can, with all of the work that we're doing and all the conversations we're having in Brussels and DC and elsewhere, is to get, uh, the leaders of our nation and frankly, the leaders of the Western world to take notice and to truly focus themselves in developing policies that can sustain this AI powered world of the future. So with that, I'll stop, um, see if there are any questions.

Speaker 4:          00:45:15       Thank you for your, uh, your talk. Um, my question was mostly about like, you know, the ending, the last thing you talked about, right? Um, I often hear about, um, the need for more discussion policy, policy changes, right? But it really alarms me because when you see the kind of discourse that our elected representatives often have about even like really basic technological issues, you realize they have no idea what they're talking about. Right. And like, it really worries me when they might be having discussions about things like this, which are potentially very complex and nuanced. Like, is there a solution to this? Like, you know, you, you mentioned even that like, you know, they're having discussions about defining things that are already happening, right? Like, what, what can we do about this?

Speaker 3:          00:46:01       That's a very difficult question. I think one thing that we should do is to not give up. So what I'm personally doing, uh, is that I try to the best of my ability to insert myself into every forum where I can impact policymakers, where we can go and share the story and explained to them the quantum of impact that is coming. Uh, two weeks ago I was speaking at the Texas CEO Summit, which is an economic summit. So they talk about how the state's growing and what the future of work will be, but you have leaders, the state leadership, economic leaders, and so on present day. And I taught that what I said may have been surprising, but it was well received. People were willing to listen. Um, I brief pretty much everyone at the Pentagon. Uh, and uh, I told you I met with Eric Schmidt.

Speaker 3:          00:46:53       Uh, you know, that was also in connection with a seniors event. So that's the one thing I know how to do, which is to be out there and keep repeating the message over and over. And then as a consequence of doing that, you find allies, you find kindred spirits you find in an exchange. I didn't know how Eric was going to answer that question, but he happened to answer that question in a way that supported the basic thrust of what we were talking about. And that became 25 media articles, you know, uh, General Allen, I recently wrote in foreign policy that got reprinted in the national newspaper of the UAE. It showed up in Canada, showed up everywhere. So again, we got forced change physically, but what we can do is influence huge numbers of mines. And in doing that we can find allies. You know, this is a mind shift. So I don't expect people that have no grounding and no interest in this area to suddenly see the light. But I do hope that we'll be able to find around them, influencers and shapers that can at least carry the day and move them forward in the direction that the country, the world needs them to move in. It's a, it's not an easy process and it's not a direct answer but that's the best I know how to do.

Speaker 2:          00:48:16       Thank you. Thank you.

Speaker 5:          00:48:22       I the title of the Book and the talk is the sentient machine and we haven't talked much about sentients. Yeah, right here. But that is a goal of many of the teams working towards this self aware machines with morality and ethics of their own real viewpoints and perspectives. Now that might be five years away, 40 years away, but it would be a good idea to have some kind of idea of how to deal with that when it gets here before it gets here. So in the circles that you talk in, is there any discussion about ways to manage, regulate and interact with AI other than as property?

Speaker 3:          00:48:58       That's a very good question. And by the way, I completely concur with your original observation that the title of the book is the essential machine in this stock. We didn't really get into what ascension's and so on. The book does cover that. My view of it. And just to give you a very quick, uh, sort of response to that in my view, uh, you know, intelligence and a lot of people agree with this, but not all. Uh, intelligence is about goal directed behavior and the larger your goals, usually the more intelligent we assess that entity to be. And dummy sanctions is a combination of intelligence and self awareness. So what I talk about in the book is sort of, I think therefore I am that school of thought of the principal, um, proof even to myself that I exist is that I can externalize my, my myself and then observe myself thinking and then say, Aha, I must be. And then from there we go. We go on. But that being said, um, you know, your question really is, uh, whether in these practical, you know, domains, whether, um, there's a realization, uh, that so, so the trust of your really is managing sanctions or, uh, not the, not creating sentients in these machines. So there is nothing,

Speaker 5:          00:50:34       no. So the government manages and interacts with people, right? But the government does not manage us as though we are property. Right. All of the talks that I've heard are about managing ais property. Are there any alternative talks going on that you've observed? Yes. I mean, I'm part of that alternative doc myself.

Speaker 3:          00:50:51       What I say in this book is that even if you go back to our, uh, religious traditions, not to take them literally, but if you go back to our religious traditions, what made Adam great was the fact that he could take action on his own and up until the creation of Adam in our Abrahamic system of, uh, religions, uh, the angels et Cetera, could do just what they were told to do. Uh, and the, the fact that Adam could do what he, what he wanted to was what made him great. If we now are after millennia and millennia of evolution, poised at the juncture where we can be the kind of creator that can create something that has its own with two whatever limited degree, because we haven't figured out how much free will we have, but to whatever limited degree, I don't think that that's an automatic, um, uh, you know, a dampener on, on this process. And I don't think we should stop. I also think there's a long ways to go, a lot to learn. There's a lot to do with ethical systems and safe AI and so on and so forth. So, um, uh, a new form of, of life. If it truly is sentient, should we treat it as property? No.

Speaker 3:          00:52:07       Thank you. Yeah.

Speaker 6:          00:52:11       I have another question. Uh, in your book, um, you, you talked a lot about, um, opportunities and dangers of AI in all sorts of different aspects. And again, I want to encourage everyone to read the book because it covers so much more subject matter then, uh, this darkening, uh, one of the things they found the missing was, uh, when you, um, write about mine hacking, um, both on like on a personal level and on a national level, right? Is there any like solution that, that you see, like how to defend against that? Like sort of like an antivirus that will say your mind is being hijacked or your democracy is being hijacked? Yeah.

Speaker 3:          00:52:53       Yes. Uh, so in the book there's a section called AI shields and that talks about how, uh, you would want to use, uh, AI, uh, to, to fend off that kind of Ai, uh, because basically what's happening now is that we will know once this investigation into the Russian involvement in an outer election is full liter veal, but a tens and tens of thousands of bots were using very simplistic NLG technology. Do not just retweet, but come up with messages that were targeted. And the indent was to shift the prevailing sentiment in the, in the election. So, uh, we've developed systems, others have developed systems that can look at that kind of generated activity and a identified as distinct from what somebody actually wrote. And even otherwise, looking at the pattern of post behaviors and profiles and so on to detect what is might be a very sophisticated part. But ultimately this is sort of a, uh, um, you know, sort of, uh, a cycle.

Speaker 3:          00:53:59       They build a better bar. Then you've got to find out ways to detect that better bought and so on and so forth. But I think that is very critical. The other thing which you may like or not like given that this is Google, uh, is in my view, there's too much control of Algorithms in the cloud. I think that, uh, just just to give you the very simple, basic example is that I want to control what I see. I've made a conscious decision now that it is not good for a social media service and I won't name any specific one. All of them do this for a social media service to decide what they want to show me, regardless of how good their machine learning algorithms are. And regardless of how good the collaborative filtering is and regardless of what they think my cousin likes or what my younger brother, you know, clicked on yesterday.

Speaker 3:          00:54:52       Um, I want to be an active participant in the filtering of my feed. And in fact, what I would like is I would like all of my posts from my network, totally raw feed and on my end I get to decide what I want to see and what I don't want to see. If we don't do that, we're in trouble. And if we don't do that, then you know, US engineers and builders, etc. Should go to that. Um, I think having this notion of your own AI shield and your own AI filter, that's very, very important. Having the convenience of multiple data centers all over the world and having the convenience of not having to buy and configure computers and having the convenience of being able to get to them from any point, uh, you know, on the world. Uh, is one thing, but then also not controlled.

Speaker 3:          00:55:45       Not even knowing what the, today I can't even tell what the hell the raw feed is that I'm supposed to get. There's just no way to get to that. It's such a glaring omission. That to me is ridiculous. And I think that's another area where the algorithms need to be controlled more by us. Even if the cloud platforms provide the data and now to say, Oh, you know, don't worry, you don't have the compute power to filter your own feet. Nonsense. Come on. That's how many, how many posts will I get in my feed? 10,000 a day. I could probably do that on her ass, but he buy, you know, so all of us can do that, Frederick. So the technical arguments no longer apply. It's a control argument and it's very important to let people manage the information the way they want to manage it.

Speaker 7:          00:56:39       So in the last slide where we talk about a lot of STI, the loss of jobs and those jobs potentially not replaceable as has been in the past. Uh, see there, there's sort of the, the muscle where you're, you're talking about labor moving to steam engines and those innovations at the factory innovation that came out of it. But nowadays the first level of AI implementation that we are looking at like self driving cars. So in some ways they seem sort of muscle plus plus there is a little bit of intelligence on top. Where do you see that heading to in the next 10 to 20 years where uh, that muscle plus plus really becomes as capable as, as an infant's mine for example. And what will be the impact of that on unemployment. So there's, if you can, um, if we can look into the future five years, 10 years and maybe even 50 years and see where we end up at

Speaker 3:          00:57:37       in terms of AI researcher directions. I'll answer that question in two ways. One of the things that I'm actually very, very curious about and have been very curious about for a long time is this whole idea of intrinsic motivation, hierarchical reinforcement learning and intrinsic motivation. There are many challenges with this because I mean ultimately if you, if you, if you, if you say this simply, it sounds simple, it's not very simple to go do, but the idea is, well you can have a reinforcement learning pickup, one task and then you can have it pick up another task and then one can be the sub task for the other end. So you can have this hierarchical tree and if you keep building all these tasks, then you'll have a pretty big coverage. But the, the, the challenges with that is whether you can really do that and whether you can have these independent tasks and so on.

Speaker 3:          00:58:26       And second, it's intrinsic motivation. That's another topic that I do cover in the book. Um, Andrew Bartow wrote about this father of reinforcement learning. Andrew Barber wrote about this as well, but that is a, where does that flame come from? Where does that, so when you talk about a three year old child, to me it's not so much that we can't build a machine that does what a three year old child does lift the amount of weight or can be driven to where a three year old child can be driven in that very mechanistic kind of sense. The thing about a three year old child is that that three year old child is born with a flame. And that flame of intrinsic motivation is something that we need to figure out. Actually, some people have hypothesized things like, well, you know what that flame really is, is uh, emergent.

Speaker 3:          00:59:14       And I talk about that in the, in the, in the book as well, emergent purpose. I went looking in philosophy for what that purpose is. Somewhere along my life I thought I knew what I was supposed to do. And then one day I felt, what the hell am I supposed to do now? And so I started reading philosophy and you know, at that point I realized that, you know, even even people like Camou Alphabet, the French philosopher and writer, he said things that were, you know, the existential, the Hilus movement. He said things like, well, uh, that leap of faith is, um, philosophical suicide, intellectual suicide because you, you accept that there came a time when your knowledge couldn't take you over the humps. So you just assumed, in other words, you did away with that gift, which was your biggest gift. So I don't know whether I'm that extreme, but I do think that that, that internal flame, that intrinsic motivation would still be something that's missing.

Speaker 3:          01:00:21       I think narrow systems that have, uh, not a flame, but a set of criteria that they are going to go and optimize. You'll see that much of, I mean, all of our system one type stuff, you can pretty much mechanize. And now if you look at your day and you say, well, how much system to type stuff too? I do. Uh, depending on who you are, it's going to be variable. But I think for a lot of jobs, the job itself is a lot of system one stuff, and that then goes away, three year old child, everything. Other than that intrinsic motivation, I don't think we have an answer to that. Intrinsic motivation. Thank you. Thank you so much. I'm here. Thank you very much.

Speaker 2:          01:01:06       [inaudible].