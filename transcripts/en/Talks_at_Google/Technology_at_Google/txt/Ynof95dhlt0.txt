Speaker 1:          00:06          Yeah, go ahead. I need that energy

Speaker 2:          00:10          coast. I'm from New York and I'm like this, that your collapse. Help wake me up. Uh, so this is my talk, the Golden Hour. This talk could save the Internet. I know, I was looking for a low bar there. Um, the secret role you play in the digital safety and health of the entire Internet. And when I was talking to Kat, Kat said, you know, it's like, you know, cybersecurity awareness month in like, there's a lot of stuff going on here. And I was trying to come up with what's a talk that can reach a lot of different people regardless of whether they're like super double o seven Jane Bond, James Bond or whether they're like marketing and stuff. So this is my attempt and this talk, uh, goes out to my fam. Thanks you so much. Okay. All right. So, um, these slides I'll give to cat so other people can have, it's like a pretty chill license and you can like share them with your friends.

Speaker 2:          01:00          All right. So, um, I used to work for this group called dgs. And ggs security is a hostile environment, training and support group and there are risk mitigation company. And if you are a journalist and you're about to cover a war zone or a hurricane, uh, if you are an NGO worker and you're going to help a village of people in a place where it politically unstable, you need to know how to get back home. Okay? You need to know how to protect the person to your left or right because there's not always an ambulance or a cab or a hospital even to go to. And that's what ggs specializes in. And they do something called risk induced to learning. Uh, sorry. Uh, so what they do is they kind of like create a simulation of a threat. So you will know whether you are someone who locks up or laughs or runs.

Speaker 2:          01:50          All those things are not good, but they need to reach you where you are and teach you how to balance that out and get to safety. And a, that's my hand there. When it was covered in fake blood Hollywood blood, they had someone with like a blood pack and like it was like meant to pump like a heart and it was warm and I was learning how to suture and take care of an artery and it was very stressful, but it was designed to be sell. Right. Um, what was I doing for Gjs is I would do like a digital thread. So it's one thing to say you should use signal or a, you know, it's important that you cover your laptop camera, but it's another thing to see a laptop that is compromised and you can see the what's going on through the camera.

Speaker 2:          02:27          It's another thing to actually like see what it's like when your text messages or strung up on a screen. So we would get a confirmation and permission from people and then create that lab environment and they can simulate that and then walk backwards. And now let me tell you, everyone is like, that's it. I'm using signal or whatever secure thing is after that. Right? So, uh, what does this have to do with my talk? I'm it forward. Um, the golden hour and a, there's this thing that this guy doctor are Adam's Crowley. And uh, his first name really is the letter R, which is awesome. And he says there's a golden hour between life and death. If you're critically injured, you have less than 60 minutes to survive. You might not die right then in may be three days or two weeks later. But something has happened in your body that is air repairable, right? And the idea is that there's a golden hour this moment of time and what people do, right, whether they tilting your head or lifting your legs or puts a blanket on you or whatever in those first 60 minutes has to do with what your life will be like afterwards, whether you'll have a full recovery and this will be a scary memory or maybe you'll have permanent damage or you're no longer with us.

Speaker 2:          03:40          Cool. So let's talk about our, so our Adams Crowley is the father, they say of American Trauma Care Systems and uh, organized trauma care that saves lives. Before this, there was this idea that if you go to a hospital that's close, you have a pretty good chance it's filled with doctors and nurses and it's filled with drugs and medicine, you'll be okay. But he is someone who had experience with shock and trauma. And even in the 50s when he was in the army realized that that's not how it worked. He had a lab at first we just four beds and they called it the death lab. And they would, people would just bring him, the doctors just bring him patients. And they were like, there's no hope for this patient. And through trial and error and through real scientific method, he found a way to kind of rural outlook as much as possible and bring those patients to a place where they can be stabilized. Really amazing individual, by the way. Right? And in Maryland is where the first shock trauma center is, and the same day after him.

Speaker 2:          04:35          Okay, so here's the idea of what the golden hour looks like. You have the things that kill you the first, right? Hypothermia, blood loss, your heart stopping. Those are major things, right? And, uh, there's her amount of time and there's a chart and it's important that you learn it. And if you work in an EMS like an ambulance and you learn a, B, c, d, and each letter is something you should do. And if you were trauma care, like the, the work that I did with gcs and you learned something called March because, uh, some things don't apply when you're the middle of nowhere. Okay. The concept of the golden hour is things like treat the greatest threat to life first treat despite lack of definitive diagnosis, treat despite complete history, like a medical history. And the thing there was just treat, treat, treat it like your first on the scene. You jump in, do something.

Speaker 3:          05:25          Yeah.

Speaker 2:          05:26          So, uh, there's this other concept which is kind of making you go like, wait, I'm in the wrong room. No, you're in the right room. Okay. So that's called Internet health. And, um, I had a fellowship for 10 months with this group call Mozilla. They make a browser, but I can't remember the name. I said, that's where the chrome people. Okay. And, um, and, uh, they have a report every year, which is like, what is the Internet health like? And they have different parts in or when they try to talk about what if we were able to walk around, like we had a hospital chart and we were like, okay, the Internet's legs are like this, the Internet's heartbreak is like that and we can measure the health of the Internet. So how has the Internet doing? You're probably asking, well, I'm sorry, my friends, those here in attendance and those watching from their air condition, uh, you know, awesome offices and homes, uh, not doing so well. I'm going to walk through what I call the trauma and shock of the Internet. So let's, uh, this is kind of like a digital trigger warning.

Speaker 2:          06:25          Uh, we have an online retailer that built an AI recruiter, which seems like a really good idea. Something to help you go through the insane number of awesome candidates if you have an opening or open rec for a position in a company. And it's especially those entry level once you're just does a day Lucia of resumes and amazing people applying. How could one person do this? Let's get a robot to do it. But in this case, the robot turned evil and was throwing out resumes that mentioned the word women's, which basically any woman's resume, not good Internet, right?

Speaker 3:          07:00          Yeah.

Speaker 2:          07:01          We had that same online retailer that was working on a really cool way to do like facial recognition and using that in images and apps and all kinds of stuff. But the first candidates in the first clients, we're testing it, we're law enforcement agencies, uh, who at first said, we're not doing this anymore. We're going to stop. And then as of a couple of days ago, it was like, we're in phase two, we're back red. That is not a good thing because I don't know about you, but when I chose to just hang out in a dark basement with my computer instead of playing with all the other boys and girls and gender nonconforming folks, right. Uh, I wasn't envisioning working on death machines. I wasn't envisioning on hurting people. I was just thinking of like, you know how to get a light saber and everybody's hands.

Speaker 3:          07:47          Okay.

Speaker 2:          07:47          Speaking about lightsabers, we have this cool sounding thing called Gemini, but there's nothing cool about it at all. Where that same online retailer is probably now one of the only people trying to get a $10 million bid from the Department of Defense, a bid that they say is a program, a truly about increasing the lethality of our department. I know you thought your department was rough, right? Uh, and providing the best resources to our men and women in uniform where death is the key performance indicator or the KPI.

Speaker 3:          08:21          All right?

Speaker 2:          08:24          We have a maker of friendly productivity software that is somehow embroiled in this kind of, uh, immigration debate that's shaking our country to its core and dividing dinner tables. Uh, good luck on thanksgiving. Those of you who celebrate that, right? Uh, around the country, we have lead generation CRM software, right? Just keeping track of that contact and see if they want to buy something that's also now working on border issues and I'm finding themselves in huge amounts of debates here in California. That's where I am right now.

Speaker 2:          09:04          Friendly chat APP. How could that be wrong? That's somehow used weaponized to not just, uh, convince people that they should vote one way or another or to polarize, uh, there are political viewpoints, but actually to create physical harm, not just to one individual, but a genocide against an entire group, an ethnic group, uh, identity, right? Um, none of these things where what we as developers and HR people and accounting people, and none of this was on my job description. None of this is what I envisioned for the future. So how exactly did we get here? Well, I will tell you, uh, that it's not out of malice. It is not out of some crazy hell bent, you know, uh, evil comic book character that wants to create this stuff. It's out of good intentions, but these good intentions are not counterbalanced by our own. What could possibly go wrong thinking, right?

Speaker 2:          10:10          So you know, you're going to Costa Rica and you're about to jump on a zip line. Something in your body says, I don't know if this is for me, right? Because one thing that I've learned in the risk business is risk is personal and something that you might say it's super risky might be to your friend. Totally good idea on Saturday morning. But, uh, when that is taken out of the equation, when your agency is taking out of the equation and you're calming, tend to take it out of the equation, good intentions go bad very quickly.

Speaker 2:          10:38          Why are you listening to me? Well, hopefully it's because of that awesome glamour shot of a photo that you saw on the paper outside. Or maybe you got a cold email from when your friends. Thank you. Um, but who am I to tell you about this golden hour of the Internet and who am I to tell you what I think you should or should not be involved in doing, right? Or this is what you came for. Everybody. We're still, you're still with me. Okay, let's go. Just check. Okay. It's, uh, well I'm a hacker and I'm a security researcher and I'm giving you the slides. You can read about all this other stuff, but um, you know, some of you I've had fellowships with in the audience. Thank you. Those are awesome opportunities. Uh, currently I worked with a group called tactical tech and I'm the director of Digital Safety and privacy.

Speaker 2:          11:20          Okay. Uh, I work with the umbrella organization called the Movement for black lives, 60 organizations about working for improvement of black bodies inside the United States, keeping them alive and healthy. Right. Um, some of the groups are well known, like black lives matter and some of the groups you might not have heard of like black youth project 100, each of them different. Trying to help. I do digital work advising them. I do digital work advising, a civil rights group called color of change where I had a fellowship for 10 months, helping them change the trajectory of their organization from one that was an awesome nonprofit to a not awesome nonprofit that was aware of digital threats and doing something about it. Kind of like how you all do with your amazing digital hygiene.

Speaker 2:          12:01          And currently I'm an advisor to the Internet Freedom Festival, which is an advantage in Valencia, Spain that happens every year, which I invite you all to, which is an amazing place where you can meet people who were creating amazing technologies but also individuals in country on the front line so to speak, who are using those technologies to better themselves. Uh, I'm an advisor to the open technology fund, which is a group that hands out financial awards and support. Maybe you need a red team to make sure your APP is okay, right? To anyone who has a great idea and they want to see it happen in the real world, you don't need VC funding. You just fill out a web form and if they think this is awesome, they will give you a financial award. It could begin it like 200 to 300,000 it can go up to millions of dollars. Some of the apps that some of you might use like signal or tour are people who are recipients of this funding year of a year.

Speaker 2:          12:50          I'm an advisor to the National Association of Criminal Defense Lawyers. Sometimes someone's freedom is in the balance over a lawyers understanding of what an Ip addresses and things like that. But let me tell you, it's probably not as strong as you might think. So, uh, I'm here to tell them like, hey, if you see this in a case pushed back a little bit, maybe that can help you. And to a group called the human rights foundation, which has an amazing event in Oslo, Norway, where I attend to help dissidence in human rights defenders. Uh, it's kind of like a Ted talk and you could watch their videos on youtube, right? And, um, and you can see amazing folks talking about what they face every day. And I work with technologists there assisting those folks on their digital hygiene and their health because they face like they're very high risk.

Speaker 2:          13:35          And of course I tell you about my time with Gjs who are, uh, I still consider them friends and I'm always there for them when they need help. Well no matter what continent they're in or who they're assisting, always great journalists, nonprofits, Ngos, one of the few progressive outfits that does this work. A lot of these people who do this work are, uh, intelligence and military and uh, it's important to have folks like them. Okay. And a tactical tech where I work right now, three things. Our data ourselves, please learn about that. Exposing the invisible, which is teaching you to be an investigator and the glass room experience, which is a physical, kind of like a black mirror type situation where you walk in and you see real things that might shock you, but they're actually real well researched and you learn more about this stuff.

Speaker 2:          14:19          Uh, it's happening in New York and London and the next one's coming up soon. Keep an eye on where it's going to drop. Okay? So what can we do? I've talked about this moment. I said there was a golden hour. I explained why I should have some authority and steering you your focus, right? Well, I'm not going to tell you to install tor and second home, but those are important. You should do that, right? I'm not going to tell you to have a password manager or about fuzzing or all kinds of cool stuff about application security. Um, but yeah, please learn that if you write code, I'm not going to tell you that there's a weakest link. Like these doors only have one handle on each one. And if one person doesn't wash their hands, we all get sick. And that's what digital hygiene is, right? I'm not going to tell you about that. There's amazing people here. I can tell you about that. I'm going to tell you that it's our job to fix it because we're the best minds around this world. Uh, that's what working at this company does. It collects these amazing people who you only have one thing in common with, which was that you both got through the interview process, but you see them more than you see anyone, including yourself in the mirror.

Speaker 2:          15:23          And there's no one else coming, which is something that we learn every day when I'm working in real world environments. You're, it's so you volunteered. That's it. There's no one who's a doctor on site on the scene. No, that's is you, right. Take action. Do something now. Right. So I will say a detective and find the source of the bleeding, which is local spaces, offline spaces. You have a friend and that friend is an activist because they wrote a letter to their congressman, right? Or maybe they're an activist cause they're marching at a protest. But you have a friend that is the activist in out of all your friends, right? You have a family member that is like, hey, should I click on this link and just get my complete internet world taken, take time out of this hard work that we do to speak to them about the internet that we know and unlearned from them.

Speaker 2:          16:08          Not just talk to them, but like listen twice as hard. Right? I'll play this video five time. That's what I do. Um, the patient needs air to survive. You have to breathe in new and innovative fresh ideas. But these new and innovative fresh ideas aren't the normal fail fast ideas that you come up with their ideas where you're holding onto what was the good intention that led this idea and you're counter balancing it with what is the negative side effect for all people, which means there's someone in a village somewhere on this planet and the tool that I'm making will somehow be used to hurt them or kill them because of their identity. It has such a far stretch and it's a really hard challenge for me to tell you to do this. But just thinking like how could this go horribly wrong in like insane scenario because unfortunately for some strange reason, that's the world we're in.

Speaker 2:          17:02          And uh, with like for example, hypothermia, um, don't let the cold and I'm going to set in, right. It seems like these ideas and these concepts of these things that are happening are bigger than all of us, but find small and large ways that you can contribute to, uh, fighting these vulnerabilities. Right. And, uh, for example, don't spread fake news because you went to full fact.org and you learned about how to fact check on the Internet and you can have a 10 hour conversation because someone hit you at the wrong moment where you're like, ah, on Facebook or some other app that you do not use. Right? And um, and instead of coming at them with your full, uh, hey, that's wrong, maybe you can say, let's fact check that together. Check out this link. Let's go through this. Oh, wow. So strange. I thought that at one point this is what's really going on.

Speaker 2:          17:50          Okay, okay, boom. Um, but most of all we have to hope for the best because recovery is not guaranteed. There's no one telling you that this is going to be a magic, wonderful ending, right? I've worked with people who I don't see anymore because they've disappeared or they're incarcerated or the company, the country, they're in this taken away. There are means to travel, right? Um, but you have to know that you did your best and you have to know that you were there and you tried. And that is what keeps you going. That's what keeps me going. Okay. So here's my contact info. Please follow me on Twitter. I'm just a little egg. I'm rushing through my slides cause I really want to do Q and a with the people online and the people in this room. Right.

Speaker 4:          18:31          One trend that I think a lot of us we're seeing in technology is and users, um, requests to kind of adapt their experience in terms of sharing location, maybe including payment details. What's a good balance between providing users that agency and not having a common editorial explosion of how can my piece of software handle all these different cases based on what people are interested in doing and sharing?

Speaker 2:          18:59          Yeah. The question is basically it's like, you know, how can we gave users agency and power over their privacy and security settings without creating road bumps and, and difficult, you're even scaring them away from the core thing that we're trying to delight them with, which is this app or tool or something like that. Does that sound good? Okay. So, um, there's a UX checklist which is something that, uh, you know, I was at this, uh, event called rights con. It happens in a different country every year. Last year it was in Toronto, but when I was at writes Khan in Brussels, uh, which is the center of the EU, uh, there was this idea like, you know, when in my work we have a checklist for everything we do. It's literally like a laminated piece of paper with boxes on it and take it a black crayon and you just put xs through.

Speaker 2:          19:42          Do you ever read the checklist manifesto? It's because you as a human being cannot be trusted to do high security things because tactical tech teaches us in some of the books that you know, that group has researched and done is that holistic security is real. When you're stressed out and you think Tongans horrible is happening or someone's banging on the door, all your amazing skills get dropped. You become a nine year old rant. So what if there was a UX checklist? Just something lightweight that as you design your tools and your working with Qa and the core devs and people do interface and design, you all can meet and just be like, well, are we really thinking about this users, this or that? Right? And also what is something that's like a, a dark pattern in new eyes that could be wrong here. What is something that, um, as a, as a person using this in a at risk environment, I would need to use this still and not have it hurt me.

Speaker 2:          20:29          Um, those are really basic questions and uh, this checklist like exist, it's on get hub and I will tweet it out. Right? And uh, anyone who wants to add things to it, please do because that's what it's all about open source. Right? Um, but I would say there was a time when there were no privacy security settings. I use using apps and tools and building stuff has developer and it just was not a thing at all. It was maybe something on the server. Right? Um, slowly we brought that to the front end and we actually gave users control over those things. And right now it's like, you know, like my friend Martins Prius, really simple buttons, but one day it'll be more nuanced controls and dials as the need comes. But we have to meet people when they need them. And you know, there are other tools out there like this app signal where it's designed to have no advanced mode, no settings because it itself is designed to beat the most high risk setting. And that's another way that you can blow past having a problem. Right. Um, so yeah. Anyway, next question. Thank you. First question, I will find a prize for you. Yeah.

Speaker 5:          21:32          John Asks, Matt, what are your thoughts on the current state and potential of automation and detection slash my mitigation of threats during the Golden Hour and how that approach be integrated with human expertise for maximum effectiveness and, okay,

Speaker 2:          21:47          thank you. This is a great question and it's about my thoughts on how we can leverage computers to assist us in responding faster in this most delicate and dangerous time. Right. And we ready, uh, anyone out there who's a bug bounty person who's, you know, it was like spends nights and weekends looking for software flaws and getting gift cards or tee shirts or maybe 50 bucks here or there. Um, we'll understand and tell you that you can no longer just sit there and do this stuff by yourself. These apps and tools are not built by one person. And so you're not going to tech your way in. No hacker, no nation state hacker works that way. We use fathers, we use computers, we use all kinds of different things, right? Those are the tricks of the trade. If you're a capital a flag person and you're, you know, playing the Games where your red team, blue team or purple team, or if you don't even understand what I'm talking about, uh, computers are used now by the most elite of people in Infosec and cyber to do that.

Speaker 2:          22:41          And the only good thing about this is that the adversary is mostly human led and computer assisted. But in the future and in what my friends who are telling me from like different parts of the world, they're seeing more are completely automated threats, like very dumb Roomba level intelligence. But a hacker that's persistent and hammers at things all day and knows like the off the top 10 and is already doing that stuff right? But that hacker is not a human being is scanning the internet or scanning a particular place like a industrial controls and Ukrainian and just looking for a way in one day that hacker is going to be on some terminator two level of intelligence. And we only can stop it with automated help, but we have to have that counterbalance and we have to always have some human level. Well this is just why, like if you look at the most dangerous of weapons, whether their nuclear missiles or something that can completely disrupt, uh, political events, there's usually a human involved and not just one human in case our compromise or something happens, right? So we know about this nuclear football and I think like that is how we can move it moving forward. I'm happy to tweet out examples of things that we could be using right now. Just make our code safer to make our stuff safer, to just scan stuff and just look for code smells and weird, weird things that we might not have thought. Right.

Speaker 6:          23:58          Thanks for joining us. Thank you for being here. I'm really glad to have you. Um, I had a question about the golden hour in the context of climate change. So obviously computing is very resource intensive and we have no shortage of fun ways to abuse the hell out of a CPU is like bitcoin and stuff like that. Um, and to the point where it might even take up resources a greater than entire countries. I wonder, do you have any thoughts about the intersection between, um, this sense of urgency behind, uh, being an active person in the technology space and climate change? What we can do?

Speaker 2:          24:41          Okay. Well, if you're living on the planet today and your breathing, you really should read climate change studies that just been dropped by the UN and other environmental groups has, um, you're an intelligent person. You're probably one of the smartest people in your friend circle. And you need to be, you need to understand what's going on, right? So there's questions about how do us, the people who like, you know, where the team here, we're working on computers and technology and those computers and technology. One thing I teach people that Crypto Harlem is every website you go to is a box with a cable going into it and a power cord. Like that's it. You go to all these amazing digital tools, they live on this planet. They create and consume heat and electricity and they are damaging this planet that we live on. And because of the surge of things like, you know, Dan, you know, uh, their economic conditions that create people needing to do crypto mining, whether it's Bitcoin, I'm a narrow or, or other things, right?

Speaker 2:          25:29          So, um, what are we doing to offset that? And honestly, we're not doing enough. You can take a flight across country for a corporation and you can offset that carbon footprint by saying, hey, I'd like to check this box and let plant some trees. But you can't say, Hey, what does it measure of my team and my work that's damaging the environment? And how does the corporation I worked for use that money that they might support a 10K or my nonprofit stuff. By the way, if you work anywhere, uh, please understand the company you work for, we'll pay you to get a day off in like help a nonprofit or we're helping good group, right? Or run a 10 K but one day we'll take that funding and also offset the work of our keyboard tapping and our servers and all our labs and the Qa costs.

Speaker 2:          26:12          Um, there are some people, for example, this group green host, which is an ISP and a data center that is completely designed to be environmentally friendly, right? And there are people who are pushing for open hardware initiatives, which will do this. We need to get behind this. Otherwise there's literally like blood on our hands. And when our, uh, you know, the younger generation of people on this planet are coughing and wheezing and asking what we did, we're going to say, we actually created problems for you, right? And we need to say we were coding a better future, but we are not destroying the planet while we're doing that. Right. So, um, thank you. I hope that, does it feel like a good answer? Uh, but yes, I'm on person. Real world person. I know the questions inside of you. Let it out.

Speaker 5:          26:56          What do you think about the prospect to sort of increasing the futility of op sec and hygiene? You know, we, even if you opt out of virtually everything and all the advantages at town technology offers, everybody around you is engaging in that you could be mapped and tracked and identified even without opting in.

Speaker 2:          27:21          Yeah. I mean, um, sometimes I'm working with folks who need to go underground. They just need to be safe. Whether you're an investigative reporter or someone who's a source that helped an NGA do an Ngo do amazing work, but you're living in country at risk and you cannot be like on the grid at that moment. It's too hot. You need to just go somewhere and it's hard cause there's shadow profiles. It's hard because your phone going off as an indicator that like you're missing from this pattern and a computers and AI are looking at those patterns, not sleepy security guards. Right. So, um, there's this idea, cause I believe your question is what about op sec in this increasingly digitize the world, right? And I tell people this security nihilism, like they can see everything anyway. There's nothing we can do here. And I work with people who are working and operating and doing amazing, like they're heroes doing amazing things in the most authoritarian totalitarian regimes.

Speaker 2:          28:13          Right? They still get up every morning and try and it's I think like disrespectful to them to even think like, Eh, I don't need my YubiKey today. Like it's because the actual threats has different levels of skill and your life shouldn't be ruined by a board 12 year old, right? Uh, you should have earned like, yeah, like that high level nation state, uh, you know, advanced persistent threat. They're the ones that got you. There are the ones that ruined your day because you know, we have this idea of defense in depth. You know, you build a moat, then you get the archers, then you have the drawbridge. And only the most like agile and persistent attacker or, or threats is going to get through all of that to touch you. And most of the time, people who work nine to five to hurt someone, they're never going to win against someone who's living, working all day for liberation of their people or advancement of an amazing cause. And so, um, if I had this idea creeping in my mind, I wouldn't be able to do anything. So it definitely shake it off. Most of the time it's a quote unquote fake news and you'd be amazed what amazing stuff you can do and what these people do every day. Right. So thank you. Great question, John.

Speaker 5:          29:20          Yes, we will get to that. Stay tuned. Scott asks, could you describe some new threads that you see on the horizon as a result of these new threats? Where should companies be investing to mitigate these risks?

Speaker 2:          29:31          Yes. Okay. It's really weird and this is kind of why I'm talking about this this way. Like when you, we think about digital threats and digital hygiene and cyber, we don't think about like sociopolitical issues and economic issues and things like that, but that is where these threats live now, right? So there's this idea of an insider threat and that threat is you, you will be compromised at one day, one point maybe some silly piece of unverified, fake news is making you think something that is not true, right? Maybe you got a gambling debt and there's a bag of cash conveniently left to your front door. You pick it up, you're like, that's weird. And then the next day they're like, Hey, I saw you use the bag of cash to no questions asked. When it gets to three, it's like, I'm going to tell everyone that you been working with me, which is, you know, this is weird, but it's true in a weird way, and now you're, you're owned, right?

Speaker 2:          30:21          So the threat is going to be these weird curve ball threats. They're not things like, oh, spare fishing's up. It's more things like this person who I work with every day, he was disaffected and disassociated and sad. They're going to be compromised. I myself, I'm that person, I will be compromised because the thing you love will be used against you. You love chocolate cake, you love Oreos. I love Oreos. I'm never eating another Oreo could be the thing that makes you, you know, just look the other way. Or maybe it's helping someone you care about, you know, maybe it's your friends and your family. And it's weird because this is the new age that we're in and our corporations and our organizations and our friend circles are ill equipped and prepared to deal with this right now. Right. Um, and these are some examples of the threats that are coming for us, right?

Speaker 2:          31:09          Or random threats where I'm a a well spoken individual on social media and all of a sudden there's an amassed troll farm that's being paid. And I've seen these places where it's a small village or a town where a teenager can make, um, uh, what is equivalent of someone's annual salary, right. For working there and just creating and sending hate mail at you or something like that. Like, um, but it's all not random. There's something or someone behind this, right? Um, I always tell people when there's a small win and awesome space is something that stayed in changing the status quo for a grade that we all are happy about. Someone's experiencing a small loss, right? And when there's those rare headline grabbing, big wins, someone's experiencing a big loss and this is their game they've never lost and you become very, very popular to them. You don't realize it, but you're the thorn in someone's side because of a tweet. Right? And that is the, what the new threat looks like and now you have personal attacks against you. So anyway, uh, more questions. Thanks.

Speaker 7:          32:11          Hey man, thanks for taking the time to be with us today. Yes. When, when you're conducting your crypto Harlem sessions, what are the protections that you find that people are most receptive to? Uh, and then what are some of the tactics that you find people are more resistant to adopting?

Speaker 2:          32:27          Okay. Well, you know, I'm lucky because I'm working with, uh, like, uh, a high risk group, which is marginalized people, right? In this case it's like black folks in the inner city. So they're kind of like looking for an antidote to the poison of what's going right. Uh, in Harlem there's like a, it's like a petri dish of all kinds of weird, a new crime fighting technologies and surveillance technologies and you know, uh, a municipality or city, they don't need to always pay for this stuff. Like the company is like, we need year over year data here, take it for free, right? Like why you'd be full. Like why would we turn this down? We're basically getting free stuff that might help, right? And then all of a sudden you have an area of your city or your town or province in your country where it's different from everywhere else where there's almost like checkpoints were almost like everyone lives in a different life and because you don't always there, you don't see it.

Speaker 2:          33:14          So maybe that might be Oakland for people who live in this region. Maybe there's one street that's so weird, but you don't experience it. And people there don't ever leave it. And that's where this is growing and the things people are receptive to our stuff that just immediately solves that problem. And when you're dealing with people who are marginalized and they're therefore pushed to the margins, whether it's Lgbtq, uh, gender nonconforming folks, uh, whether it's people who are not, you know, don't have a US passport privilege, right? And they're hustling and just trying to make this American dream happen. They're susceptible to all kinds of strange things that we're not always aware of because we're not seeing it every day. And they will grab at setting up two factor, you bet. Using secure comms on their phone. They got three APPS, they're like, I want to download that.

Speaker 2:          33:56          The more resistance I find is that people who are less directly affected, maybe they love someone or care about someone who's directly affected and then the least is someone who these things seem so obscure. And even the idea when I tell people this stuff was happening and I show them my research or show them photos of it, it just seems so bizarre. It just can't wrap your mind on it. And that's where the resistance is. And that is actually the by design, right? So by the time this stuff reaches them, it's done right. Like when they're directly affected, we lost. So my goal and my hope is try to do stuff you wouldn't normally do and really empathize the folks around you. They're living a different world that you might not realize. Anyway, that's it. Right? Um, the question was like, what do people who are marginalized or Crypto Harlem pacifically use more than other things, but mobile phones, everyone in the inner city has got a mobile phone. They don't always have laptops. They can consume technology and they can use stuff, but they can't create and their innovative folks, they can't create. It's really weird. So they're purposely consumers and I try to read them. They're on their phones. Okay.

Speaker 5:          34:58          You mentioned that young people share their thoughts in online platforms and then are affected or compromised when a friend and their circle is accused of a crime quote, black people have two degrees of separation. Can you explain more about that

Speaker 2:          35:10          care? First of all, I get that question is I talk about how black people have two degrees of separation. I talk about how young folks online or sharing gives their lives, but then not everyone has the same price for that chair. Right. Um, the Dj of Crypto Harlem is Dj blackout, right? Um, but his name is Jelani. Henry and Jelani lives around the corner from me and he spent 14 months in Rikers island prison, which might not mean anything to you, but in New York, it's one of the worst places you could ever be. Like, there's a huge initiative to shut this place down. He was spending his time waiting for his day in court in one of the worst prisons in the United States with murderers and killers and horrible people, but also with awesome people who just have been like on the wrong side of the law. Or was it people who couldn't pay $10 bail and are now spending a year in prison.

Speaker 2:          35:58          And um, he was one of those people, if you read, if you go to the verge, which is a, a website, which is not a Google website, I don't know why, but um, and they talk about reviews and electronics and technology. But this story resonated with them and they wrote about it. So if you type in Nyp d Harlem youth, you can read the story, no fake news, you can get the details and it's a lot richer than what I can explain. But that's just one case of a real person. If you, um, there is a blog called the intercepts, which is Glenn Greenwald and Laura portraits and a bunch of other folks and a bunch of my friends shout out to y'all. Um, and uh, they had an article on this thing of gang conspiracy charge and a gang conspiracy charge is a charge excuse to stop gangs and it doesn't require a large amount of evidence.

Speaker 2:          36:40          The evidence could literally be you click the thumbs up on a post, right? The evidence literally is in these cases, your phone number is in my cell phone, right? And places like Anaheim in California, there's these things called gang injunctions. Another thing to stop gangs where, uh, you can sue a gang. The gang obviously does not show up to court, right? And you win. And what happens is in certain parts of the Co of this neighborhood, it's illegal to have more than four or five people meet. It's illegal to wear certain colors and worked to an outfit or even stop at a corner or bring tools or bags with you. If you want to learn more about this. Um, there's an Al Jazeera documentary called Anaheim or it's called fault lines cause it's a series Anaheim, California. And you'll learn about this and it'll blow your mind and uh, you know, get the details. I want you to be really critical and pushback and everything I'm saying because the hard truth is actually harder behind the stuff. And a, I know these people and they're amazing human beings who still fight against this stuff, right? And it's happening to people you might see on the Caltrain or, uh, on the Bart. Right? And you don't even realize it.

Speaker 2:          37:44          Great question. Anonymous and dope for being anonymous. Respect

Speaker 6:          37:51          so much for your talk is very enlightening. Um, one of the questions I have is that you talked about kind of, uh, considering the, uh, uh, the negative side effects that can come from the products or technologies that we create. Um, and I think you also mentioned, uh, someone what's going on Myanmar with their political situation. Um, and when I've heard about that, um, one of the concerns that I always had was that, you know, as a sheltered silicon valley bubble American, it's really hard for me to conceptualize the, uh, social and ethnic challenges than many other places encounter. And so it's really hard for me to be able to conceptualize the negative side effects of the products that I create. And so I'm really curious as to what strategies you might have in mind for being able to, uh, to consider these neg negative side effects for other cultures or societies that I'm not necessarily familiar with. Thank you for asking this question.

Speaker 2:          38:51          All right. So, uh, again, this question is, listen, I'm here in my bubble and I, I'm trying to do this thing you told me. Think about the negative consequences of this amazing product or tool. I'm working on, but like Mine Amar has really far and I've got like five days, maybe 10 of vacation, you know. So what's going on? Um, we do user testing for our products internally and externally, whether it's Starbucks gift cards or people who are part of it, you a testing group in house, do user testing for this challenge that I've given you. And that might be finding out if there's a place where we're hanging, gather in your most immediate, maybe like five mile radius. If you have a American passport privilege and you're in this amazing country, you'll find that these people are actually like living, oh, right here you'll be like, oh wow, this delivery person who just brought me my food is a row.

Speaker 2:          39:40          Hanga right. And um, they just do just living in a community center and with his family right down the street from me. And they will love to tell you their story. They will love to share and you can anonymize your tool and app and be like, how could this be maybe not good for you? And they go, Oh yeah, you're right here when you ask this question right here. Yeah. That [inaudible] know that they use this to get us right. That's all it takes. It's just this weird paradigm shift and then all of a sudden you see a completely different world around you. So, um, if you spend, I challenge you to spend 60 minutes on a little bit of search engine and a little bit of social media. Hey, hive mind, does anyone know anyone who's from Imr? Right? You will immediately be face to face with someone who can help you take on the math challenge.

Speaker 2:          40:24          Right? So, um, thank you. And like, you know, at the end of the day, another thing is, you know, I'm directly affected myself. I'm part of a marginalized group. Hat's off to people who aren't because you could actually choose any issue and say like, you know what I guess identify with this. I read it and then you say it bear, that's my thing. I'm just adopting that thing and just do that. Maybe just for a year, maybe for two. Right. Um, you know, I told myself that I always say I have the luxury of having a lot of these issues directly at my doorstep. I wouldn't do this. Maybe if I could opt out, if I can sneak out the back door, but there are people who'd be like, Nah, I'd rather when you're doing, you know, you forgot us. Right. So, um, so much easier when you're not directly affected. Just give up the next year or maybe three years in. So, um, rotate, cycle out, pick an issue, jump in. Uh, I don't know if I would do it. I will never know if I would do it if I wasn't. And thank you for caring. All right. Um, next question. We have time person.

Speaker 6:          41:17          How would you approach the tradeoff between pushing for a stronger overall security? For example, browsers requiring https and breaking things that at risk users might depend. For example, surfaces that aren't updated. Both sides seem important.

Speaker 2:          41:30          Yes. Okay. So this is how do we balance pushing, but we feel it's better for the people, right? This is better for you. Come here, lineup take this shot is better for you, right? Https everywhere or breaking a service that we know people depend on, right? That might be like, you know, there might be life saving aid behind a website that's not secure and when that site doesn't load in like chrome browser, which is the only browser that you know, people use, um, that might be like, they can't, they can't get that aid. That decision is a difficult one. But like any good rapid response person, you're not making it on your own, right? If I unfortunately have to make a decision to amputate somebody's arm or their leg or their finger on their hand, I don't just be like, yeah, this looks pretty bad.

Speaker 2:          42:14          Bite on this leather strap. Right? I can say, listen, here's what's going on, right. Are stay with me. Hold my hand. I'm with you. Right? This looks pretty bad. I think we might have to suture this or put a tourniquet here and that might mean you lose it, but a, we'll definitely get you alive outta here. They will tell you don't do it. I'm a runner. I love my legs, right? Or they will say, I want to get home to my boyfriend, my girlfriend, my romantic partner. Right. Let's do this. So you don't make the decision on your own. It's too heavy a decision, but elicit as many minds as you can. And then you got to do it right. Cause a lot of this stuff is, I'm going to take a pen and stick it in your windpipe and just showed you can breathe.

Speaker 2:          42:57          You gotta make that decision. You're the only one around. Don't be afraid, step forward and take it and own it because you're trying to help and trying to help is a lot better than most people. So if it means that that side is blocked and messed up, people who are directly affected and marginalize, they'll lose that sight for a week, that he'll build all, get together and read whatever they need to read and let's encrypt that thing and cert bought that thing and they'll have https the next day. Someone will, they'll find a nerd, I guarantee you. Um, so I hope that helps you. It's a great question. I think we see a lot, I'm trying to figure out how to best formulate this question. This is a fundamental distrust of large institutions. Many of us working right institution and there are people who want to make change, but we don't want to be perceived as bias toward one side or the other.

Speaker 2:          43:46          And then there are people who are doing great work on the ground to try and make this change. How do we, how do we engage in a way that can still enable trust with other people as people who are part of a large institution? Um, and then also how do you get people to trust you as, is it because you're not necessarily affiliated with large institutions? Do you do purposeful things to, um, to try to mitigate that or do you find it, it's just like the nature of the information that you're bringing that gives you that, that kind of credibility. Okay. So this is a great question and it's about how do you deal with being associated with a large institution and the lack of cross that people have of those institutions, especially when you're just trying to do one small good thing, right? Is that a good way to, okay, so I'm part of a large institution, many of them, some of these groups and names, maybe you've heard it for the first time, but in my world they're huge.

Speaker 2:          44:35          Ready to go map, right? So when I talked to me about OTF funding and I'm like, listen, you're making this amazing app, this cryptography is awesome and you're working with a group that's like marginalized. This is great and you're doing it with three of your friends over bubble tea every other weekend. You can get money to do this. No strings attached. Like you can properly keep this going. Because a lot of the awesome tools that we use may point people to are barely holding it together. It's a person who was nights and weekends and you don't realize, but they just broke up with their partner and their landlords like, Yo, what's up with the rent? Like it's so scary when you look at some of the tools that we point to what's actually running behind it. People who don't understand what it's like to work with project managers or with code that's always updated and has comments and commits and, and you can get blamed like any hour of the day with all these different developers touching it.

Speaker 2:          45:20          That's not how most of these tools are built. Most people would be, but just two seconds of your time on how they could work would blow it this thing like, you know, sky high and making them awesome. Right? Um, but they wouldn't trust me cause they'd be like, Yo, I heard the State Department runs tour or something weird like that. Right. Or Yo, the feds make signal or something like that. Right. None of that's true, by the way. Um, and what I do is how you build trust with anyone, right? Your institution is always going to be hated because haters want to hit right, but people who need help, they immediately want your help. Like no matter who you are, like let's say like a Neo Nazi is choking on a hotdog, trust me, he wants behind it from me, right? Because they want to live. So preservation rules out above all things so you're not worried when it comes to the door, the directly effected people.

Speaker 2:          46:08          If you're in the right place, that help is appreciated. I guarantee you, right? Because it was needed yesterday. Now if you're in the place where it's a little bit yellow, not red, like traffic site and like light, right? Then you got to build trust and trust is earned, not granted. So it begins by just being like, listen, I worked for let's say Google or something, right? But I'm a person. I'm a human being and like a bank teller has a picture of their loved one facing you. That's because they're trained. That was keeps you alive. When you're humanized, that's what keeps you alive. When we work with journalists and NGO workers and nonprofit people and we're like, look, this is how you survive imprisonment. This is how you survive kidnapping. It's by being humanized, right? It becomes difficult when you're, uh, when you're, uh, people who are holding you see you as a person, right?

Speaker 2:          46:56          They know that song you like, you told them, oh, whatever. They don't stop punching you, but they pull back on those punches, right? They don't stop giving you horrible food, but maybe they give you, you know, to two meals when no one's looking right. You build that trust slowly cause it's earned and it'll be zero the next, soon as you push too far. Right? And that is a long game. So when I work with a lot of communities are a lot of people where I'm not have this built in trust, I just show up and I'm like, listen, I'm unpacking my thing that you hate. Yeah, we did some bad stuff. Yeah. That's horrible too. But let me tell you about my auntie. You know. Hi Auntie. There's a little black panther that joke. Okay. So, um, uh, but you could be like, oh, let me tell you about my family.

Speaker 2:          47:38          Right? And, um, that humanizes you. You're like, hey, let's eat. Eating is key. Everyone needs to eat. Meet them where they eat, love their favorite food, bring them some more of that the next time it's a long game. Like I'm talking about months before you even start. Then all of a sudden they're like, when they smile, when they see you and their eyes light up a little bit, almost like you're their friend, but there's still suspicious. That's your moment. That's when you start. So we need to temper back that will and that wants, I want to do good right now. If you really do, you have to wait. You got to build that trust and understand that, that trust that when people see you coming and they're like [inaudible], that's real. That's not for no reason. They're rights. Okay? But you're good. And this is bigger than that, right? So hope that helps. Thank you, Googlers for the work you do in this place. Delighting people and changing the future of technology in this world. Right? The work you do outside as human beings whose families are so proud of you because of who signs your check. Right. Um, understand the power that you wield. It's amazing. And I'm so proud and humbled to be in front of you. Right. Okay. Thank you.

Speaker 3:          48:49          [inaudible].