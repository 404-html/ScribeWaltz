WEBVTT

1
00:00:08.220 --> 00:00:12.250
Thank you for having me here at Google and for coming to my talk today.
Uh,

2
00:00:12.270 --> 00:00:15.090
I'm a fan of many of the things that you're doing.

3
00:00:15.120 --> 00:00:20.120
I'm a huge fan in particular because the company is data driven in many ways and

4
00:00:21.661 --> 00:00:26.661
also in the ways that I particularly care about its work on diversity and

5
00:00:26.671 --> 00:00:29.820
inclusion and generally in is talent management.

6
00:00:30.450 --> 00:00:33.570
So with that kind of,
I hope this is going to resonate with you.

7
00:00:33.571 --> 00:00:38.571
What I was trying to do with the book was really bringing data and evidence to

8
00:00:38.971 --> 00:00:43.971
bear on a question on which many people are very passionate about and I shared a

9
00:00:44.401 --> 00:00:45.234
passion.

10
00:00:45.870 --> 00:00:50.280
But what I'm trying to argue is that we have to bring the same kind of rigor

11
00:00:50.580 --> 00:00:55.320
that we use to analyze unemployment or inflation to questions of gender

12
00:00:55.321 --> 00:00:59.750
equality.
So here's what I want to do,

13
00:00:59.751 --> 00:01:04.380
what I want to start out by kind of talking a little bit about why we might want

14
00:01:04.381 --> 00:01:05.214
to care.

15
00:01:05.610 --> 00:01:09.900
Then I want to talk about what we're up against and I know you all are,

16
00:01:09.901 --> 00:01:13.710
many of you have gone through unconscious bias training so you will be familiar

17
00:01:13.711 --> 00:01:14.544
with much of that.

18
00:01:14.820 --> 00:01:19.820
And then I want to spend most of the talk discussing how we can redesign our

19
00:01:20.191 --> 00:01:25.191
organizations to level the playing field and making it easier for all of us to

20
00:01:25.411 --> 00:01:30.290
do the right thing.
So some of you might be here because they care about um,

21
00:01:30.330 --> 00:01:34.920
this pyramid here because you care about the absence of women in leadership.

22
00:01:35.550 --> 00:01:40.550
And then some others might be here because you care about even bigger questions.

23
00:01:41.611 --> 00:01:46.080
And I would actually suggest to you that this slide is a slide that you shoot

24
00:01:46.081 --> 00:01:48.750
most care about even more so than the pyramid.

25
00:01:49.500 --> 00:01:54.500
The UN in fact now estimates that about 200 million women and girls are missing

26
00:01:54.961 --> 00:01:59.200
because of gender side gendercide because of sex,

27
00:01:59.201 --> 00:02:02.550
selective abortion or neglect in the first five years.

28
00:02:04.080 --> 00:02:06.000
Now this in itself,
of course it's tragedy,

29
00:02:06.001 --> 00:02:11.001
but I'm starting with it because a problem that many thought was too difficult

30
00:02:11.461 --> 00:02:15.690
to even address led to some really inspiring research.

31
00:02:16.010 --> 00:02:18.810
A colleague of mine,
Rob Jansen,
who's now at Wharton,

32
00:02:19.320 --> 00:02:21.750
went into India and exploded.

33
00:02:21.751 --> 00:02:26.700
The fact that many call centers have morphed into India in the nineties and day

34
00:02:26.701 --> 00:02:30.600
often hired women.
So what he did was he ran an experiment,

35
00:02:30.601 --> 00:02:35.601
a field experiment where he had treatment villages and control villages and in

36
00:02:36.321 --> 00:02:41.321
the treatment villages he offered service and changing for women to go and work

37
00:02:42.241 --> 00:02:44.340
in call centers.
And yes,

38
00:02:44.341 --> 00:02:48.900
he was interested in where did that would affect the likelihood that this women

39
00:02:48.901 --> 00:02:50.640
would go and work in the call center.

40
00:02:50.641 --> 00:02:55.641
But more importantly he was interested in where did this affect how parents

41
00:02:56.190 --> 00:02:58.650
treat their zero to five year old daughters.

42
00:02:59.250 --> 00:03:03.340
Do we even deported the deport care about returns on investment?

43
00:03:04.150 --> 00:03:07.900
And that's what you found.
So he measured survival chances.

44
00:03:07.901 --> 00:03:12.220
He measured body mass index.
He and his team,
of course,

45
00:03:12.460 --> 00:03:15.700
he measured whether these girls said would be in school.

46
00:03:15.820 --> 00:03:20.820
And we try to understand what a parents started to treat her daughters better

47
00:03:21.190 --> 00:03:23.440
when there was a future for the daughters.

48
00:03:24.070 --> 00:03:28.300
And that's what he found was a long experiment of over about 10 years.

49
00:03:28.330 --> 00:03:33.330
And he could show that economic opportunity actually can change her parents

50
00:03:34.871 --> 00:03:38.890
think about the value of having daughters without negatively affecting their

51
00:03:38.891 --> 00:03:42.310
sons.
And I think that's why we should care.

52
00:03:42.850 --> 00:03:44.950
We should really care because for some,

53
00:03:45.190 --> 00:03:48.040
this quite literally is a matter of life and death.

54
00:03:49.150 --> 00:03:52.510
But bringing you back to somebody who I think many of you know,

55
00:03:52.540 --> 00:03:53.740
this is Heidi Roizen.

56
00:03:54.100 --> 00:03:57.430
If you have gone through the unconscious bias training at Google,

57
00:03:57.431 --> 00:04:00.700
you might have encountered her.
She is an entrepreneur,

58
00:04:00.730 --> 00:04:05.730
a venture capitalist in Silicon Valley and she was famous before a case study

59
00:04:07.301 --> 00:04:08.560
made her even more famous.

60
00:04:08.560 --> 00:04:13.000
And the case study in an interesting way made her famous because some colleagues

61
00:04:13.001 --> 00:04:13.361
of ours,

62
00:04:13.361 --> 00:04:18.361
a Columbia business school use this case to teach their students about bias in

63
00:04:19.601 --> 00:04:20.434
the moment.

64
00:04:21.100 --> 00:04:25.750
How does this down now across really this country and some other schools around

65
00:04:25.751 --> 00:04:29.770
the world is that half of the students would get the case of the protagonist

66
00:04:29.771 --> 00:04:34.120
being called Howard and the other half would get the case with the protagonists,

67
00:04:34.210 --> 00:04:38.200
having her real name,
Emily,
Heidi,
and then students read the case,

68
00:04:38.201 --> 00:04:40.000
everything identical and then rape powered.

69
00:04:40.001 --> 00:04:44.590
And Heidi and again you will have been there if you have done the training.

70
00:04:45.130 --> 00:04:50.130
We generally do think that both Heidi and how do a good job and are competent,

71
00:04:51.400 --> 00:04:56.380
but we do not like Heidi and do not want to hire Heidi because Heidi violates

72
00:04:56.530 --> 00:04:57.580
gender norms.

73
00:04:58.840 --> 00:05:03.840
That's what we're up against when we try to overcome some of these patterns that

74
00:05:04.811 --> 00:05:06.430
affect our thinking.

75
00:05:07.970 --> 00:05:11.270
But let me ask you to take a look at the pattern here that you see.

76
00:05:12.800 --> 00:05:15.410
Why don't you compare squares a and B for me?

77
00:05:16.130 --> 00:05:21.130
I presume most of you see square B as being lighter than square a.

78
00:05:22.670 --> 00:05:26.810
It turns out that this is an illusion and what I'm going to do next is I'm going

79
00:05:26.811 --> 00:05:29.330
to cover the surroundings here.

80
00:05:30.290 --> 00:05:35.290
And I presume that most of you now see the squares as having identical color.

81
00:05:36.350 --> 00:05:40.130
I'm going to go back just quickly because you look at me puzzled.

82
00:05:42.350 --> 00:05:44.180
So here's what happened in your minds.

83
00:05:44.181 --> 00:05:49.181
Your mind made immediately sent up the pattern that it saw a checkerboard and

84
00:05:49.760 --> 00:05:54.320
your mind knows that the light square has to be next to a dark square and you

85
00:05:54.321 --> 00:05:57.890
also take a bit the shadow into account to correct that shadow.

86
00:05:59.720 --> 00:06:03.050
So the question being in front of us is the following.

87
00:06:03.470 --> 00:06:06.830
What kind of patterns do we see in the world out there,

88
00:06:07.460 --> 00:06:12.460
which keep us from seeing square B for what it really is.

89
00:06:13.930 --> 00:06:15.320
Another dark square.

90
00:06:16.660 --> 00:06:17.110
<v 2>Okay,</v>

91
00:06:17.110 --> 00:06:21.190
<v 1>so some creative interventions built quite directly on this,</v>

92
00:06:21.820 --> 00:06:25.990
and you might have heard of orchestras,

93
00:06:26.020 --> 00:06:31.020
the larger orchestras in this country introducing blind auditions in the 70s

94
00:06:31.180 --> 00:06:35.260
many major orchestras in the United States introduced the curtains and had the

95
00:06:35.261 --> 00:06:40.261
musicians audition behind curtains that increased the likelihood that women

96
00:06:40.451 --> 00:06:45.451
would be hired by 50% or put differently.

97
00:06:46.720 --> 00:06:50.140
Blind auditions played a huge role and increasing the fraction of female

98
00:06:50.141 --> 00:06:55.141
musicians from 5% to now almost 40% on the major orchestras in this country.

99
00:06:57.190 --> 00:07:01.660
This is quite different from the roughly 10% female musicians,
for example,

100
00:07:01.900 --> 00:07:06.070
in Berlin or under the end.
Now symphony.

101
00:07:07.980 --> 00:07:12.980
So blind auditions are an attractive tool that in fact many organizations now

102
00:07:14.101 --> 00:07:17.550
increasingly rely on.
Of course,
not in terms of auditions,

103
00:07:17.551 --> 00:07:21.720
but in terms of blinding themselves to demographic characteristics of the top

104
00:07:21.750 --> 00:07:22.583
applicants.

105
00:07:24.210 --> 00:07:29.210
But I want to use the blindness primarily as a metaphor for us because what

106
00:07:29.821 --> 00:07:34.821
we're trying to do here is really learned from these curtains for other types of

107
00:07:35.251 --> 00:07:36.780
design interventions,

108
00:07:36.930 --> 00:07:40.770
which could make it easier for all of our minds to get things right.

109
00:07:42.130 --> 00:07:45.900
And that's where I want to take you today.
In fact,
before I talked about gender,

110
00:07:45.901 --> 00:07:50.490
I want to leave you with another metaphor which surely must be familiar to many

111
00:07:50.491 --> 00:07:51.324
of you.

112
00:07:51.390 --> 00:07:56.390
Most of you must have been in a hotel room where the room key card did not only

113
00:07:57.151 --> 00:07:59.160
serve the purpose to open and close the doors,

114
00:07:59.161 --> 00:08:01.830
but also to turn lights on and off.

115
00:08:02.760 --> 00:08:06.780
This is another little bit of technology a little bit of design would make,

116
00:08:06.810 --> 00:08:11.810
which makes it easier for all of us who actually think that we care about the

117
00:08:12.331 --> 00:08:17.331
environment to follow through and leave the room when the lights are off.

118
00:08:18.420 --> 00:08:22.020
So that's where I'm going,
trying to make it easy for us to do the right thing.

119
00:08:22.920 --> 00:08:24.510
And this,
of course,
it's very,

120
00:08:24.511 --> 00:08:29.400
very different from other types of things that we have been doing and could be

121
00:08:29.401 --> 00:08:32.550
doing.
It's different from diversity training,

122
00:08:32.820 --> 00:08:37.230
not clearly diversity training is important for raising awareness,

123
00:08:38.160 --> 00:08:39.510
but as we all know,

124
00:08:39.540 --> 00:08:44.540
it is often hard to follow through because by definition these biases are

125
00:08:45.001 --> 00:08:45.870
unconscious.

126
00:08:46.290 --> 00:08:51.290
And even though I now realize that I will treat the male kindergarten teacher or

127
00:08:52.891 --> 00:08:57.540
the male nurse differently from their steer typical counterparts who happened to

128
00:08:57.541 --> 00:09:02.190
be women,
I can't guarantee that tomorrow when I see a male nurse,

129
00:09:02.460 --> 00:09:06.960
I will object to fully evaluate that person.
Seeing really is believing.

130
00:09:08.130 --> 00:09:10.770
So diversity turning is a start,

131
00:09:11.070 --> 00:09:15.810
but I'm arguing that to be really advanced the needle and make a difference,

132
00:09:16.050 --> 00:09:20.490
we have to go deeper and do more.
And yes,

133
00:09:20.670 --> 00:09:21.361
trainings,

134
00:09:21.361 --> 00:09:26.361
enabling traditionally disadvantaged groups to succeed have been shown to have

135
00:09:26.611 --> 00:09:28.410
some impact.
But again,

136
00:09:28.650 --> 00:09:33.650
I don't think the solution can be to fix women or people of color or other

137
00:09:35.611 --> 00:09:37.500
underrepresented underrepresented groups,

138
00:09:37.800 --> 00:09:40.710
but eventually we have to move to fixing the system.

139
00:09:41.280 --> 00:09:45.930
So that's where I want to take you want to talk about three different topics

140
00:09:45.931 --> 00:09:50.460
that I touched upon in the book.
The first one is time management.

141
00:09:50.461 --> 00:09:55.461
Something that everyone in this room and everyone across the globe really,

142
00:09:56.250 --> 00:10:00.190
uh,
that is listening to my talk today has been involved in in some form,

143
00:10:00.210 --> 00:10:01.020
shape or form.

144
00:10:01.020 --> 00:10:04.170
Either because you've interviewed for a job or because you were one of the

145
00:10:04.171 --> 00:10:05.550
people evaluating others.

146
00:10:06.480 --> 00:10:11.190
Then I want to talk a little bit about redesigning school and work and give you

147
00:10:11.191 --> 00:10:15.000
some examples of how that might be done.

148
00:10:15.240 --> 00:10:20.240
And then finally I'll talk about possibly the hardest topic and that is how to

149
00:10:20.401 --> 00:10:24.780
design diversity,
how to make diversity really work.
Okay.

150
00:10:25.410 --> 00:10:30.410
So any talent management of course starts by attracting the right kinds of

151
00:10:32.131 --> 00:10:34.860
people.
And curiously enough,

152
00:10:35.340 --> 00:10:38.040
we have been thinking about,
for example,

153
00:10:38.041 --> 00:10:42.780
gendered advertisements for a very long time,
not as Coca Cola,
not just Pepsi.

154
00:10:42.820 --> 00:10:46.260
Now,
not just other soft drink companies,
but all of us,

155
00:10:46.320 --> 00:10:50.640
we are kind of aware of the fact that some colors,
for example,

156
00:10:50.641 --> 00:10:51.331
some shapes,

157
00:10:51.331 --> 00:10:55.920
some names appeal more to women than to men or vice versa.

158
00:10:56.220 --> 00:10:59.010
In coax case,
it was their word,

159
00:10:59.011 --> 00:11:04.011
diet coke and other soft drink companies realized that men don't seem to be

160
00:11:05.341 --> 00:11:08.460
buying diet.
Coke of course,
could have lots of reasons.

161
00:11:08.490 --> 00:11:11.700
Either men don't care about the calories they take or they don't have an issue

162
00:11:11.701 --> 00:11:16.530
with calories.
I didn't run more along the Charles River or diet is not the word,

163
00:11:16.980 --> 00:11:21.980
so they replaced diet by coke zero which was for men.

164
00:11:22.810 --> 00:11:24.660
The Pepsi did the same thing.

165
00:11:24.690 --> 00:11:29.690
Pepsi Maxi instead of Diet Pepsi and of course Gillette it to reverse when

166
00:11:30.391 --> 00:11:32.010
introducing Venus,
Gillette,

167
00:11:32.040 --> 00:11:35.250
that comes in colors that resonates to people like me in pink.

168
00:11:37.050 --> 00:11:41.010
I argue that I want,
I don't want to defend this in any way,

169
00:11:41.011 --> 00:11:42.960
I'm just describing that this is happening,

170
00:11:43.020 --> 00:11:47.310
but what I do want to argue is that we should use the same kind of scrutiny in

171
00:11:47.311 --> 00:11:48.720
our job advertisements.

172
00:11:49.350 --> 00:11:53.770
So here is an APP that a school posted which wanted to increase the fraction of

173
00:11:53.771 --> 00:11:56.620
its male teachers.
So probably know when the United States,

174
00:11:56.621 --> 00:12:00.880
we now have about 10 to 15% male teachers in our elementary schools,

175
00:12:00.881 --> 00:12:05.500
which increasingly poses a problem for our boys because they no longer have male

176
00:12:05.501 --> 00:12:06.334
role models.

177
00:12:06.790 --> 00:12:11.410
So this ad looked like this looking for a warm and caring teacher with

178
00:12:11.411 --> 00:12:15.160
exceptional pedagogical and interpersonal skills to work in a supportive

179
00:12:15.161 --> 00:12:16.900
collaborative work environment.

180
00:12:17.440 --> 00:12:22.300
The adjectives that we highlighted of course are gendered and typically

181
00:12:22.301 --> 00:12:23.920
associated with women.

182
00:12:24.520 --> 00:12:29.520
And research suggests that this will in fact substantially decreased the

183
00:12:29.531 --> 00:12:32.200
likelihood that men will apply to these jobs.

184
00:12:32.650 --> 00:12:36.100
So an alternative ad could have looked something like this looking for an

185
00:12:36.101 --> 00:12:38.980
excellent teacher with exceptional pedagogical skills.

186
00:12:39.490 --> 00:12:41.470
Now of course the school might say,

187
00:12:41.500 --> 00:12:44.500
but we really care about the caring

188
00:12:46.180 --> 00:12:48.160
and if they do that is okay,

189
00:12:48.820 --> 00:12:52.150
I'm not prescribing what schools or any organization for that matter should be

190
00:12:52.151 --> 00:12:55.090
doing.
But what I am arguing is that we should do it consciously,

191
00:12:55.510 --> 00:13:00.510
but we should understand what messages we send and send the messages that we do

192
00:13:01.811 --> 00:13:06.790
want to send and that are important to us in a conscious way.

193
00:13:07.180 --> 00:13:10.090
And that of course often means that we have to measure that.

194
00:13:10.091 --> 00:13:13.390
We have to collect the data and evaluate the impact of what what we're doing.

195
00:13:14.290 --> 00:13:17.710
Now,
let me move on to somewhat higher hanging fruit.

196
00:13:18.790 --> 00:13:22.900
This is a hard one and I know Google and new people,

197
00:13:23.020 --> 00:13:25.870
analytics groups have worried about this for quite a long time.

198
00:13:26.830 --> 00:13:31.830
Of course what we're up against in evaluating people is that most of us believe

199
00:13:31.991 --> 00:13:36.280
that we are particularly good interviewers and those of you who've read the book

200
00:13:36.281 --> 00:13:41.281
by Laszlo Bock will recall that among all the Googlers there is this one outlier

201
00:13:41.830 --> 00:13:46.830
who is an amazing interviewer and everyone else is just average and that's kind

202
00:13:46.961 --> 00:13:51.550
of true for the world that we all think are very good and will feel whether you

203
00:13:51.551 --> 00:13:52.930
belong or not,

204
00:13:53.320 --> 00:13:58.320
when in fact what we're building our assessments on are the stereotypes and are

205
00:13:59.770 --> 00:14:03.850
these implicit assumptions that we often even can't articulate.

206
00:14:04.120 --> 00:14:05.500
In my case,
for example,

207
00:14:05.501 --> 00:14:10.501
a real moment of a wake up call was when a job candidate is a real story,

208
00:14:11.381 --> 00:14:12.011
a job candidate,

209
00:14:12.011 --> 00:14:16.840
and I started to talk about the fact that we both had been synchronized swimmers

210
00:14:17.140 --> 00:14:19.390
and I felt immediately that,
oh my God,

211
00:14:19.391 --> 00:14:21.880
that will make her an amazing Harvard professor.

212
00:14:23.770 --> 00:14:26.950
Now we can't keep that from happening at,
that's the problem of interviews.

213
00:14:26.951 --> 00:14:28.540
It's not that everything's just bad,

214
00:14:28.780 --> 00:14:33.780
but it's hard for us to distill the useful information from noise.

215
00:14:34.450 --> 00:14:37.780
And so I have this summer cheesy stock photo up here to suggest to you that

216
00:14:37.781 --> 00:14:39.580
almost everything that you see here is wrong.

217
00:14:40.480 --> 00:14:44.290
So the first thing that is wrong is that we shouldn't do panel interviews.

218
00:14:45.430 --> 00:14:50.140
We shouldn't do panel interviews because the sample size of a panel interview is

219
00:14:50.200 --> 00:14:55.040
basically one d three people will not come up with independent assessments and

220
00:14:55.041 --> 00:15:00.041
is of course much better to have three separate interviews with three separate

221
00:15:00.380 --> 00:15:02.960
evaluations going on independently.

222
00:15:03.810 --> 00:15:08.810
Is Second myth is that diversity on the evaluation committee itself will solve

223
00:15:09.740 --> 00:15:11.750
our problems.
Now,

224
00:15:11.751 --> 00:15:16.751
diversity can be helpful in that we might reach out to different networks and

225
00:15:17.181 --> 00:15:19.820
invite different people to apply to the jobs,

226
00:15:20.330 --> 00:15:22.640
but it doesn't protect us from implicit bias.

227
00:15:23.030 --> 00:15:27.980
Seeing really is believing and if you don't see female engineers or male

228
00:15:27.981 --> 00:15:28.910
kindergarten teachers,

229
00:15:28.911 --> 00:15:33.230
we don't naturally associate those jobs with men or women respectively.

230
00:15:34.280 --> 00:15:38.180
So diversity itself can be the solution.
Then thirdly,
and now of course I'm in,

231
00:15:38.230 --> 00:15:41.030
um,
uh,
reading a bit much into this picture here.

232
00:15:41.900 --> 00:15:46.900
What's really important is that we always try to calibrate our judgments but

233
00:15:47.831 --> 00:15:50.480
forcing our minds to make comparisons.

234
00:15:50.870 --> 00:15:55.310
So why am I saying this very basic insight in behavioral sciences that

235
00:15:55.340 --> 00:15:56.810
everything that you judge,

236
00:15:56.870 --> 00:16:00.800
everything that you evaluate the coffee that you now drink or the water that you

237
00:16:00.801 --> 00:16:05.120
have in front of you has something to do with the kinds of coffees that you

238
00:16:05.121 --> 00:16:09.140
normally drink.
That is your reference point of view,

239
00:16:09.141 --> 00:16:12.410
reference coffee that helps you evaluate whether that's good or bad coffee.

240
00:16:13.130 --> 00:16:15.560
Of course,
we do the very same thing when we evaluate people.

241
00:16:16.160 --> 00:16:21.160
We tend to evaluate them compared to what we're used to in these specific

242
00:16:22.641 --> 00:16:24.080
professions or jobs.

243
00:16:24.590 --> 00:16:29.330
And so what we're trying to do is to overcome that need to rely on this internal

244
00:16:29.331 --> 00:16:33.320
little reference person sitting in our head who looks like the stereotype.

245
00:16:33.920 --> 00:16:38.210
And what we've been showing with a number of experiments is that when I forced

246
00:16:38.211 --> 00:16:41.090
you to compare at least two,
probably more,

247
00:16:41.091 --> 00:16:44.720
but at least two job candidates at the same time,

248
00:16:45.320 --> 00:16:49.400
you will be able to overcome your stereotypes and are much more likely to focus

249
00:16:49.460 --> 00:16:53.300
on these people's individual characteristics.
Um,
their ability,

250
00:16:53.301 --> 00:16:56.750
what they bring to the table rather than the groups that they belong to.

251
00:16:57.230 --> 00:17:02.120
So comparisons can be a powerful tool to calibrate your judgments.

252
00:17:03.860 --> 00:17:08.270
All of this of course hints at the fact that what we really should do is use a

253
00:17:08.271 --> 00:17:12.800
more structured process and it was very happy to learn that Google uses many of

254
00:17:12.801 --> 00:17:16.910
these insights already in that you predetermined the questions that you want to

255
00:17:16.911 --> 00:17:17.361
ask.

256
00:17:17.361 --> 00:17:20.750
You ask all of your job candidates the same kinds of questions you asked in the

257
00:17:20.751 --> 00:17:25.751
same order in ideally what we should also do as we should rate every question,

258
00:17:25.881 --> 00:17:29.060
every answer that we get after we've asked the question.

259
00:17:29.180 --> 00:17:33.020
And then move on to the next question so that we're not biased by whatever the

260
00:17:33.021 --> 00:17:36.050
candidate responded to.
The first question that we asked,

261
00:17:37.160 --> 00:17:40.490
there's a number of these tools that are discussed in the book and I'm actually

262
00:17:40.491 --> 00:17:45.491
quite excited because there are now these startup companies using some of these

263
00:17:45.681 --> 00:17:48.200
insights and translating them into the technology,

264
00:17:48.350 --> 00:17:53.350
which will make it easier for all of us to use more structured approaches to our

265
00:17:53.551 --> 00:17:55.680
hiring and evaluation processes.

266
00:17:56.910 --> 00:18:00.720
But of course we have our insights shouldn't stop at the entry level and many of

267
00:18:00.721 --> 00:18:05.721
you will argue going back to the pyramid that the really big challenges start

268
00:18:05.880 --> 00:18:07.980
once you are in an organization.

269
00:18:08.730 --> 00:18:13.260
Let me give you kind of three quick thoughts on the kind of things that we might

270
00:18:13.261 --> 00:18:14.240
want to change their,

271
00:18:14.710 --> 00:18:19.710
the first one is super trivial and I'm won't be one month strike you as

272
00:18:20.581 --> 00:18:25.581
surprised at all and that is just measure the support that we give our employees

273
00:18:27.451 --> 00:18:30.690
to help them succeed.
So just down the road here,

274
00:18:30.691 --> 00:18:34.680
MIT was one of the first institutions whereas the first academic institutions I

275
00:18:34.681 --> 00:18:35.490
should,

276
00:18:35.490 --> 00:18:40.490
I should say actually measuring the support that people got and given that the

277
00:18:42.211 --> 00:18:45.360
MIT of course the data spoke for itself.

278
00:18:45.390 --> 00:18:48.530
They literally used a measuring rod to measure people's office spaces,

279
00:18:48.540 --> 00:18:52.260
the laboratories that had available to support staff,
research assistance,

280
00:18:52.261 --> 00:18:54.360
resource resources,
et Cetera,

281
00:18:54.361 --> 00:18:58.290
and they found what then later was called performance support bias,

282
00:18:58.530 --> 00:18:59.790
which disadvantage to women.

283
00:19:00.720 --> 00:19:04.680
Now that of course again is low hanging fruit that we can fix right easily.

284
00:19:04.920 --> 00:19:09.140
It gets a bit more complicated when we think about performance appraisals at

285
00:19:09.141 --> 00:19:09.451
first.

286
00:19:09.451 --> 00:19:14.451
Insight is that whenever I work with organizations I typically find by is not so

287
00:19:14.611 --> 00:19:18.210
much when organizations evaluate the past performance,

288
00:19:18.211 --> 00:19:20.700
which many organizations literally do on the x axis.

289
00:19:21.060 --> 00:19:26.060
But typically when organizations also evaluate the potential because potential

290
00:19:27.210 --> 00:19:31.980
by definition is forward looking and by definition is very hard to measure.

291
00:19:32.640 --> 00:19:34.860
And that's where the high d bias,

292
00:19:34.861 --> 00:19:39.861
the leadership bias kicks in because we cannot imagine that women or other

293
00:19:40.711 --> 00:19:44.910
underrepresented groups who are not typically in the leadership positions would

294
00:19:44.911 --> 00:19:46.650
want to climb up the career ladders.

295
00:19:46.860 --> 00:19:51.420
So potential is certainly something that you should be worried about.

296
00:19:51.770 --> 00:19:55.560
And if you want to use potential,
what I typically try to argue is we try,

297
00:19:55.620 --> 00:19:59.640
we should try to define as precisely as you possibly can,

298
00:19:59.940 --> 00:20:04.940
what we really need with potential and force ourselves to quantify it as much as

299
00:20:05.211 --> 00:20:08.980
it possibly can.
And then thirdly and finally,
um,

300
00:20:09.630 --> 00:20:13.710
we should stop sharing self evaluations of our managers.

301
00:20:14.310 --> 00:20:19.310
Many organizations ask their employees to self evaluate themselves often on a

302
00:20:21.181 --> 00:20:22.014
rating skills,

303
00:20:22.020 --> 00:20:27.020
let's say from one to 10 and then asked the employees to share these evaluations

304
00:20:27.660 --> 00:20:29.670
with their supervisors.
Now,

305
00:20:29.680 --> 00:20:33.570
little bit of behavioral science already suggests to us that this will anchor

306
00:20:33.870 --> 00:20:37.580
the manager's assessments because any numbers that I throw at you or whether in

307
00:20:37.590 --> 00:20:41.940
a negotiation or in performance appraisal will affect your judgements.

308
00:20:41.970 --> 00:20:46.460
And if people differ in their self confidence that will affect developed

309
00:20:46.500 --> 00:20:48.010
evaluations they end up with.

310
00:20:49.060 --> 00:20:54.060
These are just some ideas of how we can kind of fix and improve how we do our

311
00:20:54.611 --> 00:20:58.630
talent management.
But let me go to some bigger questions.

312
00:20:58.960 --> 00:21:01.930
And this one might resonate with you in particular.

313
00:21:02.320 --> 00:21:06.040
Now I don't see too many people have recently taken the sat in this room,

314
00:21:06.041 --> 00:21:08.560
but most of you will have taken it at some point.

315
00:21:08.920 --> 00:21:13.840
And I remember that part of the sat is a multiple choice questionnaire.

316
00:21:15.130 --> 00:21:18.160
Now think about the following thought experiment.

317
00:21:18.820 --> 00:21:22.690
If in fact people differ in their willingness to take risk,

318
00:21:24.700 --> 00:21:29.700
some people will be more willing to guess or volunteer an answer and others will

319
00:21:30.551 --> 00:21:35.080
be more willing to skip the question.
So generally,
much,

320
00:21:35.081 --> 00:21:39.730
much research suggests that women tend to be more risk averse than men and

321
00:21:39.820 --> 00:21:42.280
former doctor schools,
doctoral student of mine,

322
00:21:42.281 --> 00:21:47.281
Katie Baldyga Kaufman in fact took this to heart and wanted to check whether

323
00:21:47.891 --> 00:21:52.891
that might cost the skippers points on the sat because they weren't willing to

324
00:21:54.371 --> 00:21:58.870
guess.
So she brought a large number of subjects to the laboratory.

325
00:21:59.350 --> 00:22:04.270
They participate in sat but only in the multiple choice part of the sat.

326
00:22:04.510 --> 00:22:06.430
And then given that this was the laboratory,

327
00:22:06.431 --> 00:22:10.780
she could force everyone to answer every question so she could take out the

328
00:22:10.781 --> 00:22:15.140
skipping option and thereby measure what people would have known.
Happy,

329
00:22:15.170 --> 00:22:16.690
answered all the questions.

330
00:22:17.110 --> 00:22:22.110
And what she found that was that equally able people controlling for ability,

331
00:22:23.020 --> 00:22:28.020
women are much more likely to skip and men are more likely to guess which costs

332
00:22:28.481 --> 00:22:31.030
women do yearly on the sat.
Now,

333
00:22:31.031 --> 00:22:35.230
the happy ending of the story is that this month,
last month,
it's already April,

334
00:22:35.440 --> 00:22:39.790
March,
2016.
Um,
as you probably have read in the news,

335
00:22:39.791 --> 00:22:44.791
the sat has been redesigned and one of the new design features is to [inaudible]

336
00:22:45.880 --> 00:22:50.560
the sat to gender device.
Gsat really in many ways,

337
00:22:50.800 --> 00:22:52.240
the first time in a hundred years,

338
00:22:52.720 --> 00:22:57.720
the sat now is trying to provide a level playing field and it could have done

339
00:22:57.941 --> 00:22:58.990
many different things.

340
00:22:59.230 --> 00:23:04.230
The college board ended up choosing to take away the penalties for guessing

341
00:23:04.541 --> 00:23:07.000
wrongly,
completely and the all the sat,

342
00:23:07.120 --> 00:23:11.050
you got a point for every right answer and a quarter point deduction for wrong

343
00:23:11.051 --> 00:23:13.780
answers.
So a little bit of math,
um,

344
00:23:13.781 --> 00:23:16.870
suggested to people that if you hard five possible answers available,

345
00:23:16.990 --> 00:23:20.410
you can exclude one than it is the dominant strategy to guests.

346
00:23:20.740 --> 00:23:23.260
But if people differ in their willingness to take risk,

347
00:23:23.261 --> 00:23:26.500
of course there is Glover's will be more likely to guests and the risk avoiders.

348
00:23:26.770 --> 00:23:29.680
So the new tests takes the penalty completely away.

349
00:23:30.160 --> 00:23:33.820
At which point the critiques of course said,
Oh my God,

350
00:23:33.821 --> 00:23:37.870
you're an enabling guessing now and you're inviting wild guessing by everyone,

351
00:23:38.180 --> 00:23:41.080
Eh,
at which point the answer must be,
well,

352
00:23:41.081 --> 00:23:46.081
we have been inviting guessing by 50% of the population for about a hundred

353
00:23:46.290 --> 00:23:51.080
years.
Now we're making it legal for everyone to do so.
So that's design.

354
00:23:51.081 --> 00:23:53.900
Design can be powerful,
can really change.

355
00:23:53.901 --> 00:23:58.170
How we do things and level the playing field quite dramatically.
Uh,

356
00:23:58.250 --> 00:24:00.080
here's another example.
Uh,

357
00:24:00.230 --> 00:24:04.100
that can be quite powerful and that is literally the power of role models

358
00:24:04.370 --> 00:24:07.100
leaving the u s for a moment because interestingly enough,

359
00:24:07.101 --> 00:24:08.720
and unbeknownst to many people,

360
00:24:09.290 --> 00:24:13.490
the longest run in quota experiment has in fact been run in India,

361
00:24:13.760 --> 00:24:17.810
not in Norway or some other countries which recently have introduced quotas on

362
00:24:17.811 --> 00:24:20.630
its corporate boards.
India men have this constitution,

363
00:24:20.631 --> 00:24:25.430
1993 have to provision that a third,
a village heads had to be female us.

364
00:24:25.520 --> 00:24:27.140
Beautiful from a research point of view.

365
00:24:27.620 --> 00:24:32.180
The third was literally picked out of a hat allowing researchers to evaluate

366
00:24:32.181 --> 00:24:36.680
what difference difference really makes and a number of papers have been written

367
00:24:36.681 --> 00:24:38.450
in those 22 years roughly,

368
00:24:38.750 --> 00:24:42.350
but the one that I want to particularly focus on here was recently published in

369
00:24:42.351 --> 00:24:47.351
science suggesting that if a village has been exposed to two female leaders in

370
00:24:47.541 --> 00:24:48.770
those 22 years,

371
00:24:49.190 --> 00:24:54.190
mindsets are starting to change and parents and girls are starting to associate

372
00:24:54.920 --> 00:24:58.880
political leadership with women.
That's pretty dramatic.

373
00:24:59.360 --> 00:25:04.360
Again suggesting that seeing really is believing and that if we see counter

374
00:25:04.611 --> 00:25:06.770
stereotypical people in those jobs,

375
00:25:06.771 --> 00:25:09.320
we can actually imagine ourselves in those jobs.

376
00:25:09.770 --> 00:25:12.830
And it has quite real implications.
So I'm sad to say this,

377
00:25:12.860 --> 00:25:14.630
my own institution to Harvard Kennedy School,

378
00:25:14.930 --> 00:25:19.930
that only 11 years ago we realized that all the portraits on our walls of

379
00:25:21.921 --> 00:25:26.810
leaders were of men.
50% of our students are female.

380
00:25:27.320 --> 00:25:31.700
And it wasn't our conscious intention to suggest to our female students that

381
00:25:31.701 --> 00:25:33.290
they were not made to be leaders.

382
00:25:33.890 --> 00:25:37.610
So we've changed that since this is Ellen Johnson Sirleaf the president of

383
00:25:37.611 --> 00:25:40.880
Liberia,
also graduate after school.
We commissioned a portrait of hers,

384
00:25:40.910 --> 00:25:42.430
Abigail Adams,
uh,

385
00:25:42.830 --> 00:25:47.830
a number more to change the face quite literally of the Kennedy School and make

386
00:25:49.071 --> 00:25:50.810
it a more inclusive environment.

387
00:25:51.140 --> 00:25:56.140
Very serious research suggests that even what we see in our walls can affect our

388
00:25:56.361 --> 00:26:01.310
beliefs.
And then of course there is some really happy news that,

389
00:26:01.311 --> 00:26:01.970
uh,

390
00:26:01.970 --> 00:26:06.970
recently we've had a female protagonist Rey in star wars.

391
00:26:07.850 --> 00:26:12.850
And of course that does matter in what we think is possible for ourselves.

392
00:26:15.110 --> 00:26:18.170
Sadly enough.
And you probably have read about this a,

393
00:26:18.180 --> 00:26:19.910
it didn't transpire everywhere.

394
00:26:20.270 --> 00:26:24.920
Monopoly created a special version of monopoly based on this particular episode

395
00:26:24.950 --> 00:26:29.840
of Star Wars and forgot to include the female characters.
Now,

396
00:26:29.841 --> 00:26:33.890
monopoly I should say,
has a fixed this since.
Um,

397
00:26:33.920 --> 00:26:37.730
but it's still remarkable that something like this is still possible.

398
00:26:38.840 --> 00:26:42.290
Now,
let me move on to our last topic and how to design diversity,

399
00:26:42.291 --> 00:26:46.590
which I already announced is a really sore knee topic.

400
00:26:47.040 --> 00:26:47.880
On the one hand,

401
00:26:47.881 --> 00:26:52.881
much evidence suggests stat diverse groups outperform homogenous groups.

402
00:26:53.850 --> 00:26:58.850
But the tricky part is that when you ask people who participated in a diverse

403
00:26:59.341 --> 00:27:00.174
team,

404
00:27:00.240 --> 00:27:04.980
how well they think the team performed and how enjoyable the task was,

405
00:27:05.460 --> 00:27:09.150
they will time and again report that they probably,

406
00:27:09.300 --> 00:27:11.220
the team probably didn't do so well.

407
00:27:11.760 --> 00:27:16.380
And it wasn't really fun because diversity is hard work.
And of course,

408
00:27:16.381 --> 00:27:21.381
because what we're trying to achieve by having diverse perspectives represented

409
00:27:22.081 --> 00:27:25.680
in a group is exactly what makes people uncomfortable.

410
00:27:25.950 --> 00:27:27.300
You want people to disagree.

411
00:27:27.330 --> 00:27:31.620
We don't want people to fall into group think and just run in the same direction

412
00:27:31.830 --> 00:27:34.770
because somebody said a,
what's the right answer?

413
00:27:35.280 --> 00:27:37.590
And that makes diversity so hard.

414
00:27:38.310 --> 00:27:42.450
So let me give you kind of a few thoughts.
So some is VT,
old news.
Yes,

415
00:27:42.451 --> 00:27:43.980
critical mass does matter.

416
00:27:44.400 --> 00:27:48.870
It does matter whether you're the only one of x,

417
00:27:48.900 --> 00:27:53.760
the only woman,
the only Swiss German economist,
whatever it might be in a team,

418
00:27:53.880 --> 00:27:54.660
it does matter.

419
00:27:54.660 --> 00:27:58.080
You will be turned into a token and you are also much more likely to perceive

420
00:27:58.081 --> 00:27:59.580
yourself as a token.

421
00:28:00.150 --> 00:28:05.150
So having three of x in a team or roughly 30% in many cases is helpful.

422
00:28:06.570 --> 00:28:09.030
But diversity is not just a numbers game.

423
00:28:09.360 --> 00:28:13.320
And I just want to end by highlighting this.
It goes beyond numbers.

424
00:28:13.321 --> 00:28:16.170
Numbers themselves are very helpful and important,

425
00:28:16.440 --> 00:28:20.820
but we have to think about the decision rules and rules of engagement,
uh,

426
00:28:21.090 --> 00:28:22.560
on our teams as well.

427
00:28:22.800 --> 00:28:26.630
And here's one that was a personal surprise to me and that is political sub

428
00:28:26.640 --> 00:28:29.970
correctness.
So I came from Switzerland to the US.

429
00:28:30.600 --> 00:28:33.690
And the Germanic culture is not a culture known for PC.

430
00:28:34.290 --> 00:28:38.100
And I have to tell you that initially I am used all my stereotypes about

431
00:28:38.101 --> 00:28:42.360
Americans thinking,
Oh God,
this is a very superficial,
this whole PC thing.

432
00:28:42.870 --> 00:28:47.070
Now it turns out really serious research suggests it's actually working.

433
00:28:47.460 --> 00:28:51.240
Why,
let me show you a picture here and ask you the following question.

434
00:28:51.870 --> 00:28:56.870
Where would you be more likely to drop a piece of paper probably on the dirty

435
00:28:57.181 --> 00:28:58.014
beach.

436
00:28:58.410 --> 00:29:03.410
So what we see or what we hear signals something about the prevalent norms and

437
00:29:05.370 --> 00:29:07.770
the question for us,
they're for Villiers,
where would we,

438
00:29:07.950 --> 00:29:11.610
where would we be more likely to drop a dirty joke,

439
00:29:12.540 --> 00:29:16.890
not in a PC environment.
So norms can matter.

440
00:29:16.980 --> 00:29:20.910
And how we present information can matter.
And I have,
um,

441
00:29:21.360 --> 00:29:25.710
one of my favorite slides up here,
which shows that,

442
00:29:26.260 --> 00:29:29.880
you know,
on the happy note learning really is possible.
On a sad note,

443
00:29:30.210 --> 00:29:35.210
we have been using this pyramid for decades in this country to help us make more

444
00:29:35.491 --> 00:29:39.860
educated food choices.
Now here is the deep insights.

445
00:29:40.740 --> 00:29:43.030
We do not eat off pyramids.

446
00:29:44.860 --> 00:29:47.860
This is the new image.
It's a plate.

447
00:29:48.580 --> 00:29:53.260
And I'm sure it resonates with you that immediately you can see whether you eat

448
00:29:53.470 --> 00:29:57.250
too much dairy,
too little dairy,
too little protein,

449
00:29:57.251 --> 00:29:59.620
too much protein,
things of that sort.

450
00:30:00.100 --> 00:30:04.600
All of us probably have some reflection,

451
00:30:04.630 --> 00:30:08.590
some reaction to what they see.
For me,
it's a dairy,
dairy lover,

452
00:30:08.620 --> 00:30:11.050
and I'm still disputing the fact that this is so small.

453
00:30:12.760 --> 00:30:13.630
But anyway,

454
00:30:14.080 --> 00:30:19.080
so here's some how we've used this information to reshape some of the norms in

455
00:30:19.571 --> 00:30:23.860
the gender diversity space.
This is a cover from the UK.

456
00:30:24.160 --> 00:30:29.160
Some of you might be familiar that the U K decided in 2011 to increase gender

457
00:30:29.741 --> 00:30:34.741
diversity on corporate boards to 25% by 2015 without the introduction of quotas,

458
00:30:36.040 --> 00:30:38.410
but instead by relying on behavioral insights.

459
00:30:38.680 --> 00:30:42.550
So we've worked a bit with the various groups involved.
Specifically for us,

460
00:30:42.551 --> 00:30:45.050
it was Vince cable,
the secretary of business.
Uh,

461
00:30:45.070 --> 00:30:47.830
in thinking about how behavioral insights could be helpful,

462
00:30:48.370 --> 00:30:50.590
and this is the brochure that they show to us.

463
00:30:50.591 --> 00:30:55.591
In 2013 when we were first approached showing that 17% of board members were

464
00:30:57.190 --> 00:31:00.250
female.
Here's what concerned us.

465
00:31:00.940 --> 00:31:05.830
Sometimes descriptive norms can turn into prescriptive norms,

466
00:31:06.430 --> 00:31:10.750
not just describing how the world is,
but suggesting how the world should be.

467
00:31:12.280 --> 00:31:17.280
And so we were nervous about this depiction of reality because it might suggest

468
00:31:17.711 --> 00:31:19.150
to us that yes,

469
00:31:19.390 --> 00:31:23.770
the right thing to do is to have small fraction of women on boards.

470
00:31:24.010 --> 00:31:27.670
So we designed the cover page and uh,

471
00:31:27.700 --> 00:31:32.700
focused instead on the organization which already have diverse sports,

472
00:31:32.990 --> 00:31:34.120
the same sample,

473
00:31:34.121 --> 00:31:38.320
the 100 biggest companies that put you on a hundred companies in the UK.

474
00:31:38.590 --> 00:31:43.590
But what we were focusing on was who and what fraction of the $100 companies are

475
00:31:46.061 --> 00:31:48.160
already diverse.
And at that time,

476
00:31:48.161 --> 00:31:53.161
that was 94% signaling that the thing to do was to join the club and be diverse.

477
00:31:56.050 --> 00:31:59.590
So if you're interested in learning more about some of these findings,

478
00:31:59.800 --> 00:32:03.730
we've created an online platform,
the gender action portal,
uh,

479
00:32:03.790 --> 00:32:06.130
which is searchable,
where people can find more,

480
00:32:06.350 --> 00:32:10.630
find out more about what works to close gender gaps in economic opportunity,

481
00:32:10.631 --> 00:32:13.450
but also in health education and political participation.

482
00:32:18.610 --> 00:32:21.700
I'm happy to take questions,
comments,
thoughts?

483
00:32:22.860 --> 00:32:25.680
<v 3>Hi.
Hi,
my name is Marta.
I have a question about,</v>

484
00:32:25.681 --> 00:32:28.470
I just want to hear your thoughts on motherhood because I'd been reading a lot

485
00:32:28.471 --> 00:32:32.040
about how,
you know,
we can do a lot up front to recruit more women,

486
00:32:32.310 --> 00:32:36.150
but there's a lot of bias associated with women once they get to a point where

487
00:32:36.240 --> 00:32:39.090
they're considering having children.
Um,
I myself have not,

488
00:32:39.130 --> 00:32:40.700
and thinking I might not want children,

489
00:32:40.701 --> 00:32:43.730
which is a whole nother conversation about the reactions that I get for that.

490
00:32:43.731 --> 00:32:47.150
But there's an immediate assumption right after a woman gets married,

491
00:32:47.151 --> 00:32:48.860
I feel even here,
um,

492
00:32:48.890 --> 00:32:52.580
that their productivity might decrease because their priorities will change.

493
00:32:52.610 --> 00:32:55.610
And I'm trying to reconcile that with women.
I hear saying,

494
00:32:55.640 --> 00:32:58.910
in fact their priorities do change along with fathers who say the same.

495
00:32:59.000 --> 00:33:00.320
So just love to hear your thoughts on that.

496
00:33:01.230 --> 00:33:03.000
<v 1>Thank you for the question.
Um,
in fact,</v>

497
00:33:03.001 --> 00:33:06.750
I'm going to draw on some of your own research at Google.
So as you can tell,

498
00:33:06.751 --> 00:33:10.110
I mean,
I,
uh,
am a fan,
lost the LaBox book work rules.

499
00:33:10.170 --> 00:33:13.150
And when Google realized that,
uh,

500
00:33:13.500 --> 00:33:15.570
women were more likely to leave than men,

501
00:33:15.630 --> 00:33:19.340
they analyze the data and the data told them that it wasn't actually women who

502
00:33:19.350 --> 00:33:20.190
are more likely to quit,

503
00:33:20.191 --> 00:33:25.140
but it was young mothers and Google being Google then could increase it's

504
00:33:25.141 --> 00:33:28.470
parental leave and uh,
both in fact,

505
00:33:28.471 --> 00:33:31.140
not just for mothers but also for fathers,
young fathers.

506
00:33:31.560 --> 00:33:36.510
And now apparently it doesn't have a gender gap in a likelihood of leaving

507
00:33:36.511 --> 00:33:39.630
anymore.
So that's um,

508
00:33:39.690 --> 00:33:44.400
I think the power of data and the power of something that is more clearly more

509
00:33:44.401 --> 00:33:49.401
than behavioral design and that is kind of taking into consideration that people

510
00:33:49.561 --> 00:33:54.561
have lives out of outside of their jobs and that we have to accommodate those

511
00:33:54.751 --> 00:33:56.380
lives and those needs,
um,

512
00:33:56.640 --> 00:34:00.150
to make sure that the employees can also thrive in our organizations.

513
00:34:00.450 --> 00:34:04.410
So parental leave policies,
again,
this is beyond cable design decisions,

514
00:34:04.460 --> 00:34:08.880
just not economists speaking based on economic evidence on that a parental leave

515
00:34:08.881 --> 00:34:13.881
policies are quite possibly the most powerful tool we can use to decrease the

516
00:34:18.120 --> 00:34:22.650
motherhood penalty that you allude to.
Now what?

517
00:34:22.651 --> 00:34:27.651
Of course it doesn't correct for our devices that we have the stereotypes that

518
00:34:28.921 --> 00:34:32.940
go with seeing,
for example,
a pregnant woman.

519
00:34:33.450 --> 00:34:37.350
And there isn't a lot of research suggesting that there is something like a

520
00:34:37.351 --> 00:34:40.810
motherhood penalty and that yes,
um,

521
00:34:40.820 --> 00:34:45.660
modern stew earn less than fathers and that in fact the correlation goes the

522
00:34:45.661 --> 00:34:49.200
other way around.
That man tend to make more money,

523
00:34:49.230 --> 00:34:52.230
money when they have children and women tend to make less money when they have

524
00:34:52.231 --> 00:34:55.150
children.
Um,
so I do think the,

525
00:34:55.170 --> 00:34:59.310
the bias is the stereotypes are absolutely,
you know,
well and alive.

526
00:34:59.400 --> 00:35:03.090
And by becoming aware of them,

527
00:35:03.750 --> 00:35:07.500
we won't solve the problem.
But in fact,
I plop Google,

528
00:35:07.501 --> 00:35:09.810
I'm not just saying this year,
I say this in my book also,

529
00:35:10.020 --> 00:35:15.020
I applaud Google for going to the data and really trying to understand what is

530
00:35:16.531 --> 00:35:21.360
happening here and then trying to fix what's actually broken.
So generally,

531
00:35:21.361 --> 00:35:24.900
by the way,
a bigger answer to your question is I am,

532
00:35:24.901 --> 00:35:29.901
I'm skeptical that we will ever be able to overcome our biases as human beings

533
00:35:35.280 --> 00:35:39.750
until we see something different.
So,
for example,

534
00:35:39.780 --> 00:35:41.760
let me around a following thought experiment with you.

535
00:35:42.090 --> 00:35:46.720
Maybe orchestras could the major orchestras in this country.
Cool.

536
00:35:46.721 --> 00:35:48.000
Did we move the curtains now?

537
00:35:48.540 --> 00:35:52.430
Because now that we have almost 40% fee and musicians,

538
00:35:52.950 --> 00:35:56.490
maybe we're starting to associate building on to India evidence,

539
00:35:56.491 --> 00:35:58.920
we're starting to associate,
um,

540
00:35:58.980 --> 00:36:02.490
playing music with women and maybe we don't need the curtains anymore.

541
00:36:02.790 --> 00:36:06.330
Now of course I might be wrong,
right?
This is an experiment yet to be run.

542
00:36:06.780 --> 00:36:10.320
But the evidence that we have so far from an particular,

543
00:36:10.321 --> 00:36:13.650
from India with numbers have changed very quickly because of quo does.

544
00:36:13.651 --> 00:36:18.000
Makes me kind of optimistic that when we see the change,

545
00:36:18.510 --> 00:36:22.350
eventually our mindsets can change.
But I don't think by just being aware,

546
00:36:22.380 --> 00:36:24.270
for example,
that there's a motherhood penalty,

547
00:36:24.780 --> 00:36:29.530
we will perceive mother's differently.
Okay.
Oh No.

548
00:36:29.560 --> 00:36:31.820
One more question.
I can't

549
00:36:32.160 --> 00:36:35.230
<v 4>Catlett only one question happened here,
um,</v>

550
00:36:35.410 --> 00:36:40.300
about the resume bias.
Uh,
that's pretty well known by now.

551
00:36:40.301 --> 00:36:45.040
Plenty of research on that,
especially with both minorities and women.
But,

552
00:36:45.070 --> 00:36:47.500
um,
my understanding is that there's,

553
00:36:47.710 --> 00:36:50.830
there may be similar bias at the interview stage.

554
00:36:50.831 --> 00:36:55.831
And I was reading an article recently about this and apparently there are

555
00:36:56.380 --> 00:37:01.380
companies now that have sprung up to essentially what they do is to do

556
00:37:02.020 --> 00:37:02.681
screening,

557
00:37:02.681 --> 00:37:07.681
but the way they do screening is they give tests that are designed by the hiring

558
00:37:08.681 --> 00:37:13.681
companies and submit the test results to the company and how,

559
00:37:15.870 --> 00:37:16.150
you know,

560
00:37:16.150 --> 00:37:20.650
without any sort of identifying information with them at all and have the

561
00:37:20.651 --> 00:37:25.360
company's first select candidates that they will interview based only on these

562
00:37:25.361 --> 00:37:27.900
test scores.
And then,
um,

563
00:37:28.030 --> 00:37:30.610
apparently according to what I've read,

564
00:37:30.940 --> 00:37:35.940
this tends to also increase the number of women who eventually get hired because

565
00:37:36.490 --> 00:37:40.180
they don't get screened out at an individual interview stage.
And I,

566
00:37:40.450 --> 00:37:42.280
I wish I remembered more of the details of this,

567
00:37:42.281 --> 00:37:44.790
but I'm wondering what you know or think about.

568
00:37:44.950 --> 00:37:46.960
<v 1>Yes.
This part of it.
Thank you for the question.</v>

569
00:37:46.961 --> 00:37:51.190
I discussed it at great length in the book.
So,
uh,
absolutely.
Um,

570
00:37:51.220 --> 00:37:55.090
the best predictor of future performance and hats,
again,
not rocket science,

571
00:37:55.150 --> 00:37:56.500
is a work sample test.

572
00:37:57.220 --> 00:38:00.220
So when I hired a research assistant that is not very hard for me.

573
00:38:00.580 --> 00:38:04.090
I can give the person a problem,
ask her to do some data analysis,

574
00:38:04.091 --> 00:38:06.130
run some regressions,
write a short report,

575
00:38:06.490 --> 00:38:09.850
and that's a very good predictor of how well the person is going to perform in

576
00:38:09.851 --> 00:38:12.400
the future.
So a work sample test,

577
00:38:12.440 --> 00:38:15.580
he is the best predictor of future performance.
Full Stop.

578
00:38:16.090 --> 00:38:20.200
One of the worst predictors of future performance are unstructured interviews.

579
00:38:21.010 --> 00:38:24.400
Now,
social scientists,
it's actually not new.

580
00:38:24.410 --> 00:38:27.590
No social scientists have been trying to convince the world that unstructured

581
00:38:27.591 --> 00:38:31.700
interviews are bad predictors of future performance for about 50 years.

582
00:38:32.360 --> 00:38:33.680
So being a behavioral scientist,

583
00:38:33.710 --> 00:38:37.840
I actually don't believe that we'll ever people to give up to interviews,
right?

584
00:38:37.841 --> 00:38:41.260
If 50 years each year we are bad communicators in that might be part of it.

585
00:38:41.440 --> 00:38:44.510
Who knows?
But in any case,
I think this,

586
00:38:44.720 --> 00:38:49.120
we're clinging to interviews and even so I started as academic dean of the

587
00:38:49.120 --> 00:38:49.990
Kennedy School for a few years.

588
00:38:50.290 --> 00:38:53.440
I could not imagine hiring a new faculty member without having talked to them.

589
00:38:53.800 --> 00:38:56.680
So I'm totally guilty of that.
At least I use a structured interview.

590
00:38:56.890 --> 00:38:58.210
So that's why I,

591
00:38:58.240 --> 00:39:03.240
my recommendation would be to combine a work sample test with a structured

592
00:39:04.091 --> 00:39:04.924
interview,

593
00:39:05.080 --> 00:39:08.740
which at least is using a structure process and structured interviews are

594
00:39:08.741 --> 00:39:12.580
actually better,
better able to predict future performance.
Um,

595
00:39:12.700 --> 00:39:15.880
but there are companies now and it's super exciting.

596
00:39:15.881 --> 00:39:20.881
Super interesting to see which do away with resumes completely and instead just

597
00:39:21.341 --> 00:39:24.650
to the work sample tests and it's exactly right.
That's exactly right.
Um,

598
00:39:24.660 --> 00:39:27.850
and then only the very last stage of the process,

599
00:39:27.851 --> 00:39:32.851
they actually see people face to face interview the last 10 or the last five and

600
00:39:33.401 --> 00:39:36.790
but using structured structured protocols.
So I think it's very,

601
00:39:36.791 --> 00:39:38.700
very appealing to think,
um,

602
00:39:38.890 --> 00:39:43.430
of the kinds of tests that you could use.
And uh,

603
00:39:43.750 --> 00:39:46.120
two in fact predict future performance.

604
00:39:46.540 --> 00:39:50.890
Here's one thing when the interview is helpful and that is of course you will

605
00:39:50.891 --> 00:39:54.340
probably sink that right now.
And you're of course right in an interview,

606
00:39:54.341 --> 00:39:56.260
we're not just evaluating a job candidate,

607
00:39:56.261 --> 00:39:59.620
but we're also telling something about our companies or our organizations,
right?

608
00:39:59.650 --> 00:40:04.150
So it's sounds a bit of a sales pitch on my end and that's okay.

609
00:40:04.150 --> 00:40:07.240
As long as you're done with your evaluations,
right at the end.

610
00:40:07.360 --> 00:40:09.280
I'm very comfortable and I did that too.

611
00:40:09.400 --> 00:40:12.160
I'm very comfortable to have an unstructured part and talk about synchronized

612
00:40:12.161 --> 00:40:15.130
swimming and talk about the teaching load at Harvard and you know,

613
00:40:15.190 --> 00:40:17.790
our wonderful students or whatever else it might be.
Um,

614
00:40:17.890 --> 00:40:21.790
that is different from me trying to evaluate a job candidate.

615
00:40:22.540 --> 00:40:26.680
Um,
just one more thing and then I'm going to call it the next question.
But,
um,

616
00:40:26.860 --> 00:40:30.800
the best evidence if you need evidence on kind of,
you know,

617
00:40:30.810 --> 00:40:32.410
what interviews made the best,

618
00:40:32.411 --> 00:40:36.310
but one of the one that kind of drove the point home to me was a bit of an

619
00:40:36.330 --> 00:40:39.640
eyeopener comes out of Texas.
So a few years back,

620
00:40:39.730 --> 00:40:43.420
the state of Texas realized that didn't have enough physicians.

621
00:40:43.960 --> 00:40:47.350
And so what they did is they went back to the medical schools and told them that

622
00:40:47.351 --> 00:40:52.000
they have to increase the intake of new students by about a quarter.

623
00:40:52.540 --> 00:40:54.910
So this one medical school,
um,

624
00:40:54.970 --> 00:40:59.970
that analyze the data at Houston had already admitted 150 students,

625
00:41:00.220 --> 00:41:05.220
the top ranked students and now may at the very late in the academic year had to

626
00:41:05.531 --> 00:41:10.450
go back to the rejected applicants and admit 50 of the initially rejected
people.

627
00:41:10.810 --> 00:41:11.241
In fact,

628
00:41:11.241 --> 00:41:15.100
the people that have to admit at that point we're ranked between 700 and 800.

629
00:41:15.460 --> 00:41:17.670
These are basically all people who nobody else wanted.

630
00:41:18.790 --> 00:41:22.960
And they thought initially of course catastrophe,
catastrophe,
you know,

631
00:41:23.560 --> 00:41:27.280
now anyway,
they will never make it here.
And um,

632
00:41:27.310 --> 00:41:31.060
but if of course it's turned out into being a quasi experiment,

633
00:41:31.270 --> 00:41:36.270
allowing research to follow the 150 top ranked students and to 50 lowly ranked

634
00:41:36.831 --> 00:41:41.390
students over many years to see where did that initial evaluation system

635
00:41:41.510 --> 00:41:44.570
correlated in any way we've had to perform your medical school and post medical

636
00:41:44.571 --> 00:41:48.590
school.
You know,
I wouldn't tell you of course,
if you know where I'm going,

637
00:41:48.591 --> 00:41:50.260
correlation nonexistent.

638
00:41:50.470 --> 00:41:54.230
It doesn't matter whether you were initially 788 or number two,

639
00:41:54.860 --> 00:41:57.950
you did quite equally as well in medical school and post medical school.

640
00:41:58.340 --> 00:42:00.890
So something clearly was wrong with the evaluation system.

641
00:42:00.920 --> 00:42:03.900
So then they're going back to delegation system,
which heavily,

642
00:42:03.901 --> 00:42:07.760
it turns out it was heavily based on interviews,

643
00:42:08.120 --> 00:42:12.650
about a third of the final score was due to more quantitative measures such as

644
00:42:12.651 --> 00:42:14.810
previous grades,
letters of recommendation,

645
00:42:15.170 --> 00:42:17.750
a work experience before you went to medical school.

646
00:42:17.930 --> 00:42:20.750
And two thirds were based on these interviews.

647
00:42:21.200 --> 00:42:23.330
So if you take out to into your score,

648
00:42:23.510 --> 00:42:26.990
then at least you get a little bit of a correlation between the quantitative

649
00:42:27.170 --> 00:42:31.820
scores and future performance.
But to interview was just making things worse.
Um,

650
00:42:32.030 --> 00:42:33.570
in fact,
the,
uh,

651
00:42:33.630 --> 00:42:38.000
the authors of the research paper can call it at the end that a better mechanism

652
00:42:38.001 --> 00:42:41.810
would be to just use a lottery rather than interviews.

653
00:42:42.110 --> 00:42:44.660
So that's just one study.
There's many of those,

654
00:42:44.690 --> 00:42:49.690
but truly unstructured interviews are kind of viewed discredited in a social

655
00:42:50.451 --> 00:42:51.890
science.
Yes,
please.

656
00:42:53.440 --> 00:42:53.760
<v 5>Well,</v>

657
00:42:53.760 --> 00:42:57.050
I'd like to start with saying that I do a lot of interviewing myself and if we

658
00:42:57.051 --> 00:43:01.220
could talk at Google into,
you know,
dropping interviews,
I'd be,
I'd be thrilled.

659
00:43:02.600 --> 00:43:07.330
Um,
so there's,
uh,
what are the issues that we have in,

660
00:43:07.331 --> 00:43:12.170
uh,
in the hiring women for engineering?
Is the,
is the pipeline,

661
00:43:12.171 --> 00:43:16.970
I'm mean,
we're here right now.
Just the resumes coming in.
It's,

662
00:43:16.971 --> 00:43:20.000
it's,
you know,
male,
male,
male,
male,
male,
female movement.
You know,

663
00:43:20.300 --> 00:43:24.530
it's just very hard.
So I'm wondering if you thought for me,
you know,

664
00:43:25.100 --> 00:43:29.240
behavioral psychology standpoint of how do we address that?

665
00:43:29.270 --> 00:43:34.270
Is there something that we can do to persuade all the young women out there that

666
00:43:35.490 --> 00:43:40.350
the computers are fun?
It's a good job as well,
you know,

667
00:43:41.030 --> 00:43:42.860
join us,
come,
come on in.
The water's fine.

668
00:43:43.060 --> 00:43:47.830
<v 1>Yes.
Yeah,
no,
absolutely.
Um,
and pipeline issues are real.
Um,
and I,
you know,</v>

669
00:43:47.831 --> 00:43:50.920
again,
what the,
when I work with organizations,
I quite literally look at,

670
00:43:50.921 --> 00:43:54.460
you know,
what is the pipeline and when do we start to see,
for example,

671
00:43:54.490 --> 00:43:57.130
on the proportional or over proportional promotions,

672
00:43:57.530 --> 00:44:00.340
which then would suggest that maybe there's some bias going on,

673
00:44:00.460 --> 00:44:04.810
but the pay managers are real.
So last week I spoke at two different conferences.

674
00:44:04.811 --> 00:44:09.250
One was a women in stem and that I was actually a,
a chair.

675
00:44:09.251 --> 00:44:13.680
The panel and we had a number of very interesting,
I'm NGLs and startups,
uh,

676
00:44:13.780 --> 00:44:17.410
working with schools and the kind of things I learned there were,
you know,

677
00:44:17.500 --> 00:44:18.940
astonishing to me as well.

678
00:44:19.060 --> 00:44:24.060
That Algebra tool is not taught at most of our public schools in the United

679
00:44:24.160 --> 00:44:25.570
States that,
uh,

680
00:44:25.600 --> 00:44:30.310
most of our teachers are not equipped to teach Algebra tool.

681
00:44:30.760 --> 00:44:33.360
Um,
so many of the,
so first of all,
you know,

682
00:44:33.370 --> 00:44:36.990
many of our students aren't even equipped at the kind of tools that companies

683
00:44:36.991 --> 00:44:39.910
like Google for example,
needs.
That doesn't explain the gender bias here,

684
00:44:40.110 --> 00:44:41.070
but just more generally.

685
00:44:41.400 --> 00:44:46.020
And so what they're doing is they go into school and many of them versions off

686
00:44:46.290 --> 00:44:48.060
providing kind of help to teachers.

687
00:44:48.061 --> 00:44:52.020
So one project was a science from scientists.

688
00:44:52.440 --> 00:44:55.470
I've just getting scientists into schools,
helping teachers,
teaching science.

689
00:44:55.710 --> 00:44:59.000
Many of them were focused on a girls,
uh,

690
00:44:59.160 --> 00:45:03.150
primarily or exclusively.
I'm also providing mentoring,

691
00:45:03.151 --> 00:45:06.780
sponsorship support systems.
Um,
so that's kind of one thing.

692
00:45:06.810 --> 00:45:09.450
The other conference I just spoke with wasn't Saturday.

693
00:45:10.070 --> 00:45:14.550
It was the women in math at Harvard.
And again,

694
00:45:14.551 --> 00:45:17.580
I learned some interesting things and some are kind of VD ripe for some design

695
00:45:17.581 --> 00:45:18.890
changes.
Um,

696
00:45:19.050 --> 00:45:23.850
some of you might have studied math and mathematics and we'll remember that it's

697
00:45:23.851 --> 00:45:28.851
super competitive to get into the best schools like Harvard or Mit.

698
00:45:29.640 --> 00:45:33.120
Um,
apparently you need to participate in lots of competitions already in high

699
00:45:33.121 --> 00:45:36.270
school.
And it turns out that,
uh,

700
00:45:36.360 --> 00:45:39.170
match research suggests that women do not like competitions.

701
00:45:39.450 --> 00:45:43.980
It's a bit similar to,
you know,
willingness to take risk,
uh,
self confidence.

702
00:45:44.130 --> 00:45:44.940
We also tend to,

703
00:45:44.940 --> 00:45:49.940
we tend to want our work to be evaluated for what it is and not necessarily a

704
00:45:50.430 --> 00:45:52.410
participant in hyper competitive environments.

705
00:45:52.830 --> 00:45:56.460
So lots of m research suggesting that that might actually

706
00:45:57.000 --> 00:45:57.280
<v 0>yeah,</v>

707
00:45:57.280 --> 00:46:00.220
<v 1>decreased the Laika that a women will choose those kinds of fields.</v>

708
00:46:00.460 --> 00:46:05.460
So I think it's a combination off enabling boys and girls to do the work.

709
00:46:07.150 --> 00:46:11.770
And it hit me hard teachers to teach the kinds of subjects of providing role

710
00:46:11.771 --> 00:46:14.180
models,
mentorship,
same sex teachers,

711
00:46:14.181 --> 00:46:18.120
a lots of evidence suggesting that same six teachers in particular counter

712
00:46:18.170 --> 00:46:20.080
stereotypical subjects matter.

713
00:46:20.140 --> 00:46:23.560
So this of course for girls would be math and science for boys reading and

714
00:46:23.561 --> 00:46:28.300
writing.
So equally as serious.
Um,
so all of those,
um,
kind of we need,

715
00:46:28.330 --> 00:46:29.690
we need to attack.
Um,

716
00:46:29.740 --> 00:46:34.630
and then think about kind of 50 signs that people are in,
such as,

717
00:46:34.660 --> 00:46:38.740
you know,
the hypercompetition that seems to be a parent in mathematics and do,

718
00:46:38.741 --> 00:46:42.730
I did ask sweetie necessary for people to succeed and become good
mathematicians.

719
00:46:44.250 --> 00:46:49.030
<v 0>Okay.
Hi.
We were taught,</v>

720
00:46:49.740 --> 00:46:53.100
we were lucky enough to have Jean and David's talk at our headquarters in

721
00:46:53.101 --> 00:46:55.500
mountain view a couple of weeks back.
That all right.
You know,

722
00:46:55.501 --> 00:46:56.580
where I'm going to sack her,

723
00:46:56.880 --> 00:47:01.710
her take on how the media can help make the world better.
Bay.

724
00:47:01.711 --> 00:47:01.921
You know,

725
00:47:01.921 --> 00:47:05.190
you talked about changing out the portraits in the hallway and she's talking

726
00:47:05.191 --> 00:47:10.191
about can we change the things that we see in movies and TV to help solve this

727
00:47:10.381 --> 00:47:13.830
issue.
Um,
I was curious what your thoughts on that.
I know whether you,

728
00:47:14.510 --> 00:47:19.490
<v 1>yeah.
Um,
so she and I were at the same place in California in October,</v>

729
00:47:19.491 --> 00:47:21.760
spoke at the same place and um,
uh,

730
00:47:21.890 --> 00:47:24.650
she might have told you that as well as some research it,

731
00:47:24.651 --> 00:47:28.310
I wasn't actually aware of that.
When we represent groups of people,

732
00:47:28.640 --> 00:47:33.490
then the typical croup is like one third or a quarter female and two thirds or

733
00:47:33.491 --> 00:47:37.810
three quarters male.
Um,
so yes,
I'm completely agree with her.
Um,

734
00:47:38.080 --> 00:47:43.080
I think the evidence on seeing is believing is really overwhelming and the kinds

735
00:47:43.811 --> 00:47:45.250
of book goes back to the early question.

736
00:47:45.251 --> 00:47:49.930
Also the kinds of books that our kids read,
the kind of cartoons that they watch.

737
00:47:49.960 --> 00:47:54.520
And that's why ray,
I mean was,
you know,
half a joke,
but taf serious.

738
00:47:54.820 --> 00:47:59.350
It does matter what we see,
what people were,
how we,
you know,

739
00:47:59.770 --> 00:48:02.080
we present different characters,

740
00:48:02.081 --> 00:48:06.160
whether on the screen or in a book or on our walls.
So I,
yes,
I am completely,

741
00:48:06.161 --> 00:48:07.420
completely aligned with her.
Yeah.

742
00:48:11.770 --> 00:48:16.480
Okay.
I just got the time.
Um,
I think behalf to wrap up.
Thank you very much.

