WEBVTT

1
00:00:04.080 --> 00:00:04.913
Okay.

2
00:00:05.480 --> 00:00:06.313
<v 1>Hi.</v>

3
00:00:11.970 --> 00:00:12.601
<v 0>Hi everybody.</v>

4
00:00:12.601 --> 00:00:17.601
I'm Allen West and I am beyond thrilled to be here on the stage with um,

5
00:00:18.060 --> 00:00:22.090
Katie Kirk.
And we're so happy to have Katie here with us,
um,

6
00:00:22.740 --> 00:00:27.740
beyond just so many accomplishments and o l and no,

7
00:00:28.771 --> 00:00:32.220
I mean seriously as someone who,
um,
you know,

8
00:00:32.221 --> 00:00:36.900
watched Katie literally on the world's longest running today show fan,

9
00:00:36.930 --> 00:00:37.650
which,
um,

10
00:00:37.650 --> 00:00:42.030
but 15 years is co anchor of the today show where I think she showed that,

11
00:00:42.450 --> 00:00:44.640
um,
you know,
being a tough,

12
00:00:44.670 --> 00:00:48.960
insightful journalists was not incompatible with being,
um,

13
00:00:49.530 --> 00:00:52.200
you know,
a human being and responding to the people who,

14
00:00:52.230 --> 00:00:56.970
the wide variety of people who came in front of her with kindness and empathy.

15
00:00:56.971 --> 00:00:59.310
And that's just been a real inspiration to me.

16
00:00:59.311 --> 00:01:00.990
And I know to lots of other people,

17
00:01:01.530 --> 00:01:06.530
the first woman to anchor an evening news programs solo at CBS evening news

18
00:01:07.021 --> 00:01:10.440
starting in 2006 in 2014,

19
00:01:10.441 --> 00:01:14.790
she joined Yahoo is the global news anchor.
But in addition to all of that,

20
00:01:15.210 --> 00:01:17.700
I'm a bestselling author.

21
00:01:17.970 --> 00:01:22.970
I'm a producer of documentaries and also,

22
00:01:23.780 --> 00:01:28.020
um,
amazingly an incredible health care advocate and cancer advocate.

23
00:01:28.021 --> 00:01:33.021
And I was just blown away when I was looking through Katie's bio that as a

24
00:01:33.151 --> 00:01:38.070
cofounder of stand up to cancer and the National Colorectal Cancer Research

25
00:01:38.070 --> 00:01:38.760
Alliance,
um,

26
00:01:38.760 --> 00:01:43.710
that over $370 million has been pledged to stand up to cancer.
So

27
00:01:44.160 --> 00:01:45.900
<v 2>closer to 500 million now.</v>

28
00:01:46.140 --> 00:01:51.090
<v 1>Wow.
I think
just really phenomenal.
But,</v>

29
00:01:51.200 --> 00:01:52.020
um,

30
00:01:52.020 --> 00:01:55.560
<v 0>that bringing that to people's attention in such advocacy,</v>

31
00:01:55.561 --> 00:01:57.570
which is of course something we tried to do here at,

32
00:01:57.930 --> 00:02:01.480
at Google and those are Google size numbers.
Um,

33
00:02:01.770 --> 00:02:05.160
so I think the obvious question to start out with,

34
00:02:05.161 --> 00:02:07.140
and we were talking about this,
um,

35
00:02:07.380 --> 00:02:12.380
I listened to your podcast with Doris Kearns Goodwin earlier this week on the

36
00:02:12.871 --> 00:02:16.500
election.
Um,
what are your thoughts?

37
00:02:17.100 --> 00:02:19.960
What happened?
How much time do we,

38
00:02:21.390 --> 00:02:25.350
<v 2>hi everyone.
I'm really excited to be here.
Thank you all for coming.
And Ellen,</v>

39
00:02:25.351 --> 00:02:28.110
thank you for,
for doing this.
Um,

40
00:02:28.111 --> 00:02:31.620
and thanks for mentioning my cancer work and I'd love to explain stand up to

41
00:02:31.621 --> 00:02:34.410
cancer maybe at some point during this interview because I think it's an

42
00:02:34.411 --> 00:02:36.640
interesting and,
um,

43
00:02:36.720 --> 00:02:41.720
very novel sort of paradigm for how we're tackling cancer research and helping

44
00:02:42.121 --> 00:02:46.680
scientists,
um,
and supporting scientists.
But what was the question?

45
00:02:46.681 --> 00:02:51.180
What happened?
My feeling,
um,
I think like everyone,
my head is spinning.

46
00:02:51.660 --> 00:02:56.040
I think it's a very anxiety producing time because there's so much uncertainty.

47
00:02:56.520 --> 00:03:00.970
Um,
I think probably everyone in this room and everyone watching this and however

48
00:03:00.971 --> 00:03:02.260
they watch it,
um,

49
00:03:03.010 --> 00:03:08.010
had they've been reading all these postmortem pieces and what happened?

50
00:03:08.170 --> 00:03:12.850
How did this election turn out this way?
What were the forces that,
uh,

51
00:03:13.330 --> 00:03:17.680
convalesced or came together to make Donald Trump our next president?

52
00:03:17.680 --> 00:03:19.990
Which is just really,
I mean,
it's almost,

53
00:03:19.991 --> 00:03:22.630
it blows your mind even say it because it just,

54
00:03:22.660 --> 00:03:27.340
it's such an unlikely situation.
And the polls,
as we know,

55
00:03:27.341 --> 00:03:29.110
we're not very accurate,

56
00:03:29.111 --> 00:03:33.280
although the national polls had her ahead three points and within the margin of

57
00:03:33.281 --> 00:03:36.580
error.
So it turns out they weren't as wrong as people have said.

58
00:03:36.581 --> 00:03:41.170
I think some lesser state polls swing state polls might've been more inaccurate,

59
00:03:41.590 --> 00:03:45.430
but I think,
you know,
it's,
everyone has seen,
um,
this was as,

60
00:03:45.431 --> 00:03:47.860
as David Axelrod,
I think so aptly put it,

61
00:03:47.861 --> 00:03:52.861
a primal scream across the country by group of disenfranchised Americans who

62
00:03:52.901 --> 00:03:57.130
feel as if the American dream has left them out or left them behind.

63
00:03:57.550 --> 00:04:01.720
Um,
I think there are so many contributing forces.

64
00:04:01.750 --> 00:04:04.320
The economy,
blue collar workers,

65
00:04:04.321 --> 00:04:08.830
a manufacturing base that has been eroding for many decades now.

66
00:04:09.400 --> 00:04:09.880
Um,

67
00:04:09.880 --> 00:04:14.880
I think globalization has winners and losers and I think perhaps we were too

68
00:04:15.970 --> 00:04:20.790
kind of intellectually based on what globalization would mean for the future in

69
00:04:20.791 --> 00:04:21.940
the,
in the big picture,

70
00:04:21.941 --> 00:04:26.320
but maybe didn't think enough about the people who would be disadvantaged by

71
00:04:26.321 --> 00:04:30.220
globalization and by automation,
you know,

72
00:04:30.221 --> 00:04:31.380
for a fact that I,

73
00:04:31.381 --> 00:04:34.630
I think I read in the economist that I quoted a lot during the course of this

74
00:04:34.631 --> 00:04:39.631
campaign is between 2000 and 2010 only 13% of the manufacturing jobs in this

75
00:04:42.281 --> 00:04:44.920
country were actually lost a trade.
The Mat,

76
00:04:44.950 --> 00:04:47.380
vast majority have been lost to automation.

77
00:04:47.560 --> 00:04:51.160
So I think we're in the midst of this massively changing economy.

78
00:04:51.161 --> 00:04:53.830
And if you step away and look at the big picture,

79
00:04:54.010 --> 00:04:57.910
it's not unlike going from an agrarian to an industrial society where no,

80
00:04:58.000 --> 00:05:01.480
now going more from an industrial to a technological society.

81
00:05:01.481 --> 00:05:03.490
And I don't need to tell her one at Google that.

82
00:05:03.700 --> 00:05:07.570
So I think it's all these different forces at work.
I think Hillary couldn't,

83
00:05:07.571 --> 00:05:11.770
could click Clinton failed to galvanize some of the,

84
00:05:11.790 --> 00:05:16.790
the voting blocks that Barack Obama did so effectively in 2012 and I think

85
00:05:18.431 --> 00:05:21.100
there's a big disconnect between the,
uh,

86
00:05:21.160 --> 00:05:26.160
ex urban voters and rural voters and people who live in urban centers.

87
00:05:27.070 --> 00:05:29.140
Um,
so I think there are a lot of,

88
00:05:29.290 --> 00:05:33.700
a lot of reasons why things turned out the way they did.

89
00:05:33.730 --> 00:05:34.600
And,
um,

90
00:05:34.601 --> 00:05:39.601
I think we're kind of still dealing with what this means.

91
00:05:39.760 --> 00:05:40.690
How do we get here?

92
00:05:40.691 --> 00:05:45.691
What does it mean and the uncertainty about what Donald Trump will actually do

93
00:05:46.330 --> 00:05:50.230
as president.
Um,
you know,
a friend of mine,
Brian Goldsmith,

94
00:05:50.231 --> 00:05:53.620
who I cope post or whatever you call it,
my podcast with,

95
00:05:53.621 --> 00:05:58.580
he's just an incredibly smart guy.
And I've worked with him since was at CBS.

96
00:05:59.040 --> 00:06:03.290
Um,
we actually worked on this Sarah Palin interview and that was a very bonding

97
00:06:03.291 --> 00:06:06.800
experience for both of us.
Um,
but,
um,
you know,

98
00:06:06.801 --> 00:06:11.570
he talks about it was a change election,
you know,
people really just,

99
00:06:12.290 --> 00:06:15.260
Haley Barber told me when I interviewed him on Yahoo,

100
00:06:15.261 --> 00:06:20.261
basically America was giving the middle finger to Washington and people wanted

101
00:06:20.421 --> 00:06:21.990
change.
And I think,
uh,

102
00:06:22.260 --> 00:06:27.260
Donald Trump's message of change resonated more than Hillary Clinton's message

103
00:06:27.530 --> 00:06:30.680
of Donald Trump is too big a risk for America.

104
00:06:30.920 --> 00:06:35.420
And even though in exit polls people said that they worried about his competence

105
00:06:35.421 --> 00:06:37.910
and if he was qualified to be president,

106
00:06:37.911 --> 00:06:42.911
I think most people said he wasn't the change notion and the change message

107
00:06:43.550 --> 00:06:46.760
resonated much more with voters.

108
00:06:46.761 --> 00:06:50.150
So despite the fact that they worried about is competence,

109
00:06:50.180 --> 00:06:52.370
they were ready to give Washington the middle finger.

110
00:06:53.110 --> 00:06:56.920
<v 0>So one other thing that obviously is being hotly debated at the moment is the</v>

111
00:06:56.921 --> 00:07:01.800
role of the press and the shift to the role of the social media.
Right.
Um,

112
00:07:01.870 --> 00:07:04.320
in the selection.
And I'm just wondering,
um,

113
00:07:04.630 --> 00:07:09.630
what was your take on how both of the candidates interacted with traditional

114
00:07:10.451 --> 00:07:15.451
press versus social media and what do you think the presses responsibility is

115
00:07:16.451 --> 00:07:19.450
and where we've ended up?
Wow,
that's great.

116
00:07:19.700 --> 00:07:21.550
<v 2>Three part question.
So I'm,</v>

117
00:07:21.560 --> 00:07:25.130
there's an excellent piece in the Times that I was reading about how social

118
00:07:25.131 --> 00:07:30.131
media has really transformed the country in terms of how we get information,

119
00:07:30.381 --> 00:07:35.300
how we formed communities,
how we share information,
how we influence,
uh,

120
00:07:35.330 --> 00:07:39.470
the hearts and minds of voters everywhere.
So I think,
uh,

121
00:07:39.471 --> 00:07:44.471
this article posits that Donald Trump could not have been elected without social

122
00:07:44.661 --> 00:07:48.170
media,
which called dis and disintermediation,
you know,

123
00:07:48.560 --> 00:07:52.010
just directly talking to voters through his Twitter account,

124
00:07:52.011 --> 00:07:56.510
which has been quite active apparently this morning about the New York Times.
Um,

125
00:07:56.720 --> 00:08:00.470
and so,
um,
I think social media played a huge,

126
00:08:00.471 --> 00:08:01.970
huge role and as a result,

127
00:08:01.971 --> 00:08:05.720
I think it made traditional mainstream media are lame stream media,

128
00:08:05.721 --> 00:08:06.770
if you want to call us that.

129
00:08:07.070 --> 00:08:10.370
I don't even know if I'm considered lame stream still at Yahoo if someone can

130
00:08:10.371 --> 00:08:13.220
help me with that.
But I think,
uh,
you know,
it's,

131
00:08:13.221 --> 00:08:18.221
it's made that that entity or the media as an institution in terms of

132
00:08:19.701 --> 00:08:23.780
traditional media less and less relevant.
David Brooks,
I think,
set on Sunday,

133
00:08:23.781 --> 00:08:25.940
you know,
we were completely irrelevant.

134
00:08:25.941 --> 00:08:29.490
So you have all these different narratives that are floating around that a

135
00:08:29.900 --> 00:08:31.640
traditional media is irrelevant,

136
00:08:31.880 --> 00:08:36.880
that traditional media is culpable for Donald Trump's rise to power.

137
00:08:37.550 --> 00:08:42.470
And I think we're still sorting it out.
I think every after every election,

138
00:08:42.471 --> 00:08:44.120
and I've been doing this a long time,

139
00:08:44.300 --> 00:08:49.250
there's a lot of hand wringing that media outlets focus too much on the horse

140
00:08:49.251 --> 00:08:53.870
race and not enough about issues and not what these candidates would actually do

141
00:08:54.050 --> 00:08:58.780
if they're elected.
Not really taking a deep dive into those things.
Um,

142
00:08:58.800 --> 00:09:00.840
and I think this one is no different,

143
00:09:00.841 --> 00:09:04.920
and I think the cult of personality in this particular campaign was so strong

144
00:09:05.280 --> 00:09:06.090
and I,
and,

145
00:09:06.090 --> 00:09:10.290
and I think it was often dictated by Donald Trump's outrageous statements.

146
00:09:10.290 --> 00:09:13.950
They would sort of dominate the news coverage and suck all the oxygen out of the

147
00:09:13.951 --> 00:09:18.120
room that he sort of,
he was kind of a one man.

148
00:09:18.450 --> 00:09:23.190
Um,
uh,
uh,
how would you see,
I don't know how to describe it.

149
00:09:23.191 --> 00:09:27.780
So he was,
you know,
setting the agenda for the media himself.
You know,

150
00:09:27.781 --> 00:09:31.920
when we used to do the today show when there wasn't as much media,

151
00:09:32.280 --> 00:09:35.460
we used to say,
we like to set the agenda for the day,
you know,

152
00:09:35.461 --> 00:09:39.210
talk about the important stories that everybody else was going to be covering

153
00:09:39.211 --> 00:09:42.540
that day.
But I think Donald Trump kind of usurped that.

154
00:09:42.541 --> 00:09:47.541
And he was actually setting the agenda and he was incredibly proficient at it.

155
00:09:49.170 --> 00:09:53.550
And I think often people followed his lead.
You know,

156
00:09:53.970 --> 00:09:56.880
it's a very,
it's a highly competitive landscape.

157
00:09:56.881 --> 00:10:01.800
More so more than ever before because there are so many different outlets and I

158
00:10:01.801 --> 00:10:05.970
think people,
we're often afraid.
For example,
you know,

159
00:10:05.971 --> 00:10:09.630
I've talked to friends of mine in morning television and you know,

160
00:10:09.631 --> 00:10:14.100
we would have probably never allowed a candidate to call on the phone and to do

161
00:10:14.101 --> 00:10:16.770
an interview with that,
that individual.

162
00:10:16.800 --> 00:10:21.800
But Donald Trump did that and people were too afraid not to do it because they

163
00:10:23.791 --> 00:10:25.920
thought we'll,
if their competitors were doing that,

164
00:10:26.190 --> 00:10:30.780
that would give them an advantage in the ratings.
And you know,
let's face it,

165
00:10:31.050 --> 00:10:34.950
it's still,
television is very much about ratings.
You know,
it's,

166
00:10:34.980 --> 00:10:39.810
it's a profit driven business.
And so,
you know,

167
00:10:39.811 --> 00:10:44.640
I think that people made a lot of deals with the devil.
I think,
you know,

168
00:10:44.641 --> 00:10:47.250
initially there was too much,
um,

169
00:10:47.910 --> 00:10:52.560
open coverage of his rallies without any critical analysis,

170
00:10:52.590 --> 00:10:53.071
which is,

171
00:10:53.071 --> 00:10:57.630
I think the New York Times talked about one point $7 billion in free advertising

172
00:10:57.631 --> 00:11:00.960
or something that he got in the early stages of the campaign.

173
00:11:01.110 --> 00:11:04.910
I think there was a lot of self correction later in the election cycle and

174
00:11:05.250 --> 00:11:08.100
outlets like the Washington Post and the New York Times.
Really,

175
00:11:08.101 --> 00:11:11.970
I would salute the Washington Post even more than the times because I think they

176
00:11:11.971 --> 00:11:14.580
were a little late to the party,
the New York Times on,

177
00:11:15.000 --> 00:11:19.650
on really analyzing these candidates and really doing some serious investigative

178
00:11:19.651 --> 00:11:23.820
reporting of,
of their foundations,
et cetera.
Um,

179
00:11:24.120 --> 00:11:28.650
but,
and I think that that television outlets sort of self corrected to,

180
00:11:28.651 --> 00:11:30.210
to the extent they could,
you know,

181
00:11:30.211 --> 00:11:34.770
there's not a lot of long form serious reporting done on television these days.

182
00:11:34.771 --> 00:11:36.720
If you look at,
you know,

183
00:11:36.721 --> 00:11:41.660
very short pieces on the evening news and the morning shows,
um,
I think have it,

184
00:11:41.760 --> 00:11:42.690
you know,
short,

185
00:11:42.810 --> 00:11:46.980
short segments as well and are a little less serious possibly than they used to

186
00:11:46.981 --> 00:11:51.360
be back in the day.
So I guess the bottom line is,

187
00:11:51.960 --> 00:11:56.230
you know,
I think there's going to be,
uh,
this period of reckoning,

188
00:11:56.590 --> 00:11:58.930
figuring out what went wrong,
what went right.

189
00:11:58.930 --> 00:12:03.930
And I just hope the commercial forces that influence these decisions won't drown

190
00:12:04.631 --> 00:12:09.160
out the sort of journalistic principles that we need to adhere to.
And I thought,

191
00:12:09.161 --> 00:12:13.900
you know,
I was saying to Ellen before we came,
came on,
um,
you know,

192
00:12:13.901 --> 00:12:17.650
it was frustrating for me.
I,
Donald Trump wouldn't do an interview with me.

193
00:12:17.651 --> 00:12:20.470
I mean,
I didn't think,
I don't think he's soup.

194
00:12:20.471 --> 00:12:24.090
I think television is his main source of information.
And,
um,

195
00:12:24.100 --> 00:12:28.420
I don't think he was aware of the power of the online community in terms of,

196
00:12:28.421 --> 00:12:32.500
I mean,
he was,
and he wasn't right.
I mean,
he obviously utilize Twitter to,

197
00:12:32.950 --> 00:12:35.110
to great effect,
but,
um,

198
00:12:35.410 --> 00:12:39.770
so I was frustrated that he wouldn't sit with me and frustrated and surprise

199
00:12:39.771 --> 00:12:44.180
that Hillary Clinton wouldn't sit down.
Uh,
and I think,
um,
you know,
I,

200
00:12:44.240 --> 00:12:47.260
I'm not sure what Mr Trump's explanation might be.

201
00:12:47.261 --> 00:12:50.830
Maybe he didn't understand the platform.
Maybe,
you know,

202
00:12:50.831 --> 00:12:54.940
it's the ghost of Sarah Pailin in my case.
I don't know.
But,
um,
you know,

203
00:12:54.941 --> 00:12:56.200
I think for Hillary Clinton,

204
00:12:56.201 --> 00:13:00.970
I think her campaign was so cautious that she wanted to hold onto her support at

205
00:13:00.971 --> 00:13:05.350
anything.
You know,
I think they looked at everything as a risk benefit,
uh,

206
00:13:05.560 --> 00:13:07.770
situation.
And I,
you know,

207
00:13:07.900 --> 00:13:12.010
I did her first interview when she became first lady in the early nineties,

208
00:13:12.070 --> 00:13:16.870
and I,
you know,
I've been around her,
I know her,
she is a very different person,

209
00:13:17.440 --> 00:13:18.130
um,

210
00:13:18.130 --> 00:13:22.990
in person and in a more intimate setting than she is on the campaign trail.

211
00:13:23.230 --> 00:13:27.640
But I,
I believe they didn't provide people with an opportunity to see her.

212
00:13:28.090 --> 00:13:32.210
Um,
and,
and as a result,
I think she was character,
caricature,

213
00:13:32.260 --> 00:13:36.250
characterize caricatured character,
whatever.
You know what I mean?

214
00:13:36.760 --> 00:13:41.760
She became a caricature as somebody who was just sort of brittle and shrill,

215
00:13:42.161 --> 00:13:45.760
which I think is a very sexist word by the way.
Um,
uh,
and,

216
00:13:45.761 --> 00:13:50.761
and somebody who did not have this ability to connect us as a real person and I

217
00:13:52.031 --> 00:13:55.810
think it really hurt her in the end.
Um,
so I want to translate,
sorry,

218
00:13:55.811 --> 00:13:59.590
I'm giving such long answers.
I'll try not to do that.
I think we're all,

219
00:14:00.040 --> 00:14:03.620
am I talking too much?
Blah,
blah,
blah.
No.
Okay.
We've

220
00:14:03.620 --> 00:14:07.730
<v 0>all been wrestling with this here as well.
And so these are,
I think these are,
um,</v>

221
00:14:08.000 --> 00:14:12.560
helpful,
uh,
remarks for all of us is we're all trying to come to terms with,

222
00:14:12.590 --> 00:14:13.730
with what's happened.

223
00:14:14.060 --> 00:14:17.990
I want to transition slightly just shocked about women in journalism because you

224
00:14:17.991 --> 00:14:21.950
touched on just the use of the word shrill with Hillary Clinton.

225
00:14:21.951 --> 00:14:25.640
And I remember my husband even saying to me after the first debate,

226
00:14:25.641 --> 00:14:29.570
and he's more on the conservative end of the political spectrum,
but he said,

227
00:14:29.571 --> 00:14:34.571
I never understood until today the penalty that intelligent women there for

228
00:14:35.481 --> 00:14:37.730
being intelligent in command of the facts,

229
00:14:37.731 --> 00:14:40.580
that that was turned by the other side into a negative,

230
00:14:40.581 --> 00:14:44.120
that somehow she was rehearsed and robotic,

231
00:14:44.510 --> 00:14:48.890
whereas she was thoughtful,
prepared,
experienced.

232
00:14:49.250 --> 00:14:54.170
Um,
and so I just wanted to ask what being a woman in,
in journalism,

233
00:14:54.260 --> 00:14:58.880
um,
the news about Gwen Ifo,
which we spoke about this week,
I think again,

234
00:14:58.881 --> 00:15:02.930
just brings home,
we've made some progress,
but there's,

235
00:15:03.560 --> 00:15:04.070
um,

236
00:15:04.070 --> 00:15:09.070
pretty rare for women to break the glass ceiling in journalism still all these

237
00:15:10.670 --> 00:15:11.150
years later.
Um,

238
00:15:11.150 --> 00:15:14.450
how do you feel about the current state of journalism is journalism as a

239
00:15:14.451 --> 00:15:16.610
profession for women?

240
00:15:16.730 --> 00:15:21.140
We've got lots of young women here who work in media and related industries.

241
00:15:21.141 --> 00:15:25.030
Is this,
what does it look like to you?

242
00:15:26.120 --> 00:15:28.190
<v 2>Well,
um,
you know,</v>

243
00:15:28.191 --> 00:15:31.670
I think they're your first point about a criticism of her.

244
00:15:31.671 --> 00:15:36.671
I think that speaks to this anti intellectual sentiment that's kind of

245
00:15:37.521 --> 00:15:41.840
pulsating,
not only across our country but across the world.
Kind of.

246
00:15:41.841 --> 00:15:44.600
I remember hearing someone when the Brexit vote,

247
00:15:44.900 --> 00:15:47.510
before the Brexit vote was happening and saying something like,
you know,

248
00:15:47.511 --> 00:15:51.230
what do experts know as if it's,
it's actually,
uh,

249
00:15:51.290 --> 00:15:56.290
a character flaw to be a proficient and educated and well versed in a particular

250
00:15:57.561 --> 00:16:00.830
subject area.
So I think that's,
that's going on as well,

251
00:16:01.130 --> 00:16:04.550
which I think is very disturbing and upsetting.
Um,

252
00:16:05.000 --> 00:16:08.150
but I think with,
with women,
uh,
so

253
00:16:09.840 --> 00:16:14.830
I mean,
I think there's good news and bad news for,
for women in media.
One,

254
00:16:14.850 --> 00:16:19.650
the good news is there are so many outlets and so many opportunities.
You know,

255
00:16:19.651 --> 00:16:23.430
it used to be,
you used to be so limited in terms of,

256
00:16:23.610 --> 00:16:25.800
I'll speak about just television news,

257
00:16:25.801 --> 00:16:30.480
working at a local station and can going from market to market.
And you know,

258
00:16:30.481 --> 00:16:35.310
I worked at ABC as a desk assistant where basically my biggest jobs were getting

259
00:16:35.311 --> 00:16:38.370
coffee and ham sandwiches for the anchor at the time.

260
00:16:38.371 --> 00:16:41.570
Frank Reynolds and answering the phone and Xerox Sane.

261
00:16:41.571 --> 00:16:45.750
And do they still xerox anywhere,
by the way?
Probably not.

262
00:16:45.990 --> 00:16:48.540
Well are you going to have to change like the teletype ribbons,

263
00:16:48.541 --> 00:16:52.110
which were purple with a little white gloves?
I mean that's how ancient I am.

264
00:16:52.530 --> 00:16:55.230
But um,
you know,
so there are many,

265
00:16:55.260 --> 00:17:00.090
many outlets and I think if you work hard and you,
you know,

266
00:17:00.091 --> 00:17:04.290
can can get your foot in the door at a whole host of places,

267
00:17:04.291 --> 00:17:08.520
you have an opportunity to rise at the top.
And I've seen just some great,

268
00:17:08.940 --> 00:17:13.160
fantastic work by a lot of young journalists and you know,

269
00:17:13.230 --> 00:17:15.330
online publications.

270
00:17:15.331 --> 00:17:19.770
I'm obsessed with the Vanity Fair newsletter,
which is called the hive,

271
00:17:19.800 --> 00:17:24.800
which a lot of young women are doing really well there and clearly and outlets

272
00:17:25.831 --> 00:17:29.790
like the Huffington Post.
We have a lot of young women on our staff at Yahoo.

273
00:17:29.791 --> 00:17:33.510
So I think there are,
as I said,
many,

274
00:17:33.511 --> 00:17:38.400
many more opportunities.
Um,
having said that,
I,
I'm,

275
00:17:38.460 --> 00:17:42.540
I'm chagrin that there aren't more women in leadership positions.

276
00:17:42.780 --> 00:17:46.110
Certainly at the networks.
If you look at,
you know,

277
00:17:46.111 --> 00:17:48.750
in some cases there are some women in leadership,

278
00:17:49.350 --> 00:17:53.280
but I believe almost every network,
the president of the news division is male.

279
00:17:53.730 --> 00:17:57.750
Um,
I think if you look at all the Sunday public affairs shows,
uh,

280
00:17:57.810 --> 00:18:02.160
I think they're all anchored by by men.
Um,

281
00:18:02.220 --> 00:18:06.330
and I think,
you know,
there's still sort of a double standard.

282
00:18:06.330 --> 00:18:11.160
I think women,
uh,
on television have to be hot.
You know,

283
00:18:11.161 --> 00:18:15.750
there's this kind of,
I don't know if it's the Fox influence where it's,
you know,

284
00:18:16.050 --> 00:18:20.400
sort of a shine more a shiny object.
I think,
you know,
you can be both,

285
00:18:20.401 --> 00:18:25.401
but there seems to be a much greater emphasis on women's appearances.

286
00:18:25.650 --> 00:18:30.480
Then on men's,
I'm just just dying for the day when someone is oldest,

287
00:18:30.540 --> 00:18:34.350
a woman is old,
is Bob Schieffer can get on and talk about the election.

288
00:18:34.470 --> 00:18:39.240
Can you imagine?
I mean,
it just wouldn't happen,
would it?
Because we'd be like,

289
00:18:39.270 --> 00:18:43.800
oh my God,
she's so old.
Do you,
you know,
and,
and,

290
00:18:43.801 --> 00:18:47.580
and I think that,
I think when I watched that,
I think,
hey,

291
00:18:47.581 --> 00:18:50.070
Bob Schieffer has a lot of interesting things to say.

292
00:18:50.071 --> 00:18:51.690
He's incredibly experienced.

293
00:18:51.930 --> 00:18:56.190
Wouldn't it be great if there he had a female counterpart who was also,

294
00:18:56.550 --> 00:19:00.000
I don't know,
81 years old,
I'm not sure.
But you know,
I,

295
00:19:00.001 --> 00:19:01.620
I can't imagine the day but I'm,

296
00:19:01.680 --> 00:19:06.680
I'm hopeful that we will have a day where you don't have to be hired because the

297
00:19:08.641 --> 00:19:11.130
boss would like to sleep with you.
You know?

298
00:19:11.160 --> 00:19:15.390
So I think there's still that kind of element in,

299
00:19:15.450 --> 00:19:17.280
in the news business.

300
00:19:17.640 --> 00:19:22.320
So I think we need to get a lot more women in as I said,

301
00:19:22.321 --> 00:19:27.321
leadership positions because I think they judge and hire people very differently

302
00:19:27.810 --> 00:19:32.810
than men do and that that will go a long way in giving women more opportunities.

303
00:19:34.580 --> 00:19:34.960
Great.

304
00:19:34.960 --> 00:19:35.321
<v 0>Thanks.</v>

305
00:19:35.321 --> 00:19:39.970
And I just want to follow up cause we're here also to talk about your podcast,

306
00:19:39.971 --> 00:19:44.200
which again when we were talking just a really refreshing change to actually

307
00:19:44.201 --> 00:19:46.450
hear someone dig into the news.
And again,

308
00:19:46.451 --> 00:19:48.310
I was listening to the one about the election,

309
00:19:48.311 --> 00:19:53.311
which I just found therapeutic listening to you and Doris really tease and go

310
00:19:53.831 --> 00:19:57.550
back and forth on an issue instead of reducing something to with two and a half

311
00:19:57.551 --> 00:20:00.010
minute segment on the evening news.

312
00:20:00.760 --> 00:20:05.710
What are you trying to achieve in your work with the podcast and at Yahoo

313
00:20:06.160 --> 00:20:09.160
compared to mainstream media?
Um,

314
00:20:09.370 --> 00:20:11.650
what are you hoping to push forward?

315
00:20:11.860 --> 00:20:14.120
<v 2>Well,
with the podcast,
you know,
um,</v>

316
00:20:14.320 --> 00:20:18.310
one in five Americans I think listened to a podcast this month.

317
00:20:18.311 --> 00:20:22.390
So there are increasingly popular way for people to get information and stay

318
00:20:22.391 --> 00:20:24.940
informed and be entertained really.

319
00:20:25.420 --> 00:20:27.840
So it was appealing to me,
uh,

320
00:20:27.880 --> 00:20:31.870
because I think it can provide a much more intimate format.

321
00:20:31.930 --> 00:20:33.630
People can,
um,

322
00:20:33.730 --> 00:20:37.480
I think feel more comfortable expressing themselves.

323
00:20:37.481 --> 00:20:38.950
It just feels more relaxed.

324
00:20:38.951 --> 00:20:42.760
There's something about television I think that makes people feel a little

325
00:20:42.761 --> 00:20:46.660
nervous and uncomfortable and have to kind of mind their p's and q's in a way

326
00:20:46.661 --> 00:20:50.860
that you have on a podcast.
And it's just a little more free form.

327
00:20:50.861 --> 00:20:52.720
You can really,
I think,

328
00:20:52.721 --> 00:20:57.721
let the conversation be your guide rather than having sort of six questions you

329
00:20:57.881 --> 00:21:01.780
have to get done in eight minutes.
And these days,
I mean the segments,

330
00:21:01.781 --> 00:21:05.890
at least in morning television on evening newscasts are much,
much shorter.

331
00:21:05.890 --> 00:21:08.530
So I,
you know,
I'm interested,

332
00:21:08.531 --> 00:21:11.380
I'm endlessly curious about a lot of different things.

333
00:21:11.410 --> 00:21:15.790
And so for me it just provides just another platform.

334
00:21:15.791 --> 00:21:19.240
I think also because the media landscape is so fragmented,

335
00:21:19.510 --> 00:21:23.930
I feel like I drank like eight cups of coffee.
I only drank,

336
00:21:24.820 --> 00:21:29.770
I think I,
I'm sorry,
I'm just like,
I think maybe everybody's feeling this way.

337
00:21:29.771 --> 00:21:33.380
So thank you for letting me kind of bent.
Um,

338
00:21:33.430 --> 00:21:37.630
but I think that the media landscape is so fragmented that you have to be on

339
00:21:37.631 --> 00:21:40.300
multiple platforms,
I think to reach an audience.

340
00:21:40.600 --> 00:21:44.200
So for me it was just sort of all of those reasons,

341
00:21:44.201 --> 00:21:48.310
being able to have a more in depth conversation,
that intimacy.

342
00:21:48.610 --> 00:21:52.750
And you know,
at this point,
I've been in this business a long time,

343
00:21:52.751 --> 00:21:55.690
so I know you know,
in that fake way sometimes.

344
00:21:55.691 --> 00:21:59.350
But I do know a number of people and you know,

345
00:21:59.351 --> 00:22:03.790
I've worked with Doris when I was at NBC and I just,
I adore her and,

346
00:22:04.090 --> 00:22:09.000
um,
and I think she's so interesting and smart and so I could call her,

347
00:22:09.010 --> 00:22:13.450
email her and,
um,
because of a preexisting condition,

348
00:22:13.480 --> 00:22:17.800
but relationship,
um,
you know,
people like that are willing to come on.

349
00:22:17.800 --> 00:22:22.800
So Samantha Bee came on who I've gotten to know a little bit and Julia Louis

350
00:22:23.290 --> 00:22:27.670
Dreyfus and Larry Wilmore that a podcast is going to be released tomorrow and he

351
00:22:27.671 --> 00:22:29.980
was just,
I don't,
I didn't know him very well,

352
00:22:30.010 --> 00:22:33.910
but he was just so great and interesting and you know,
like,

353
00:22:33.911 --> 00:22:38.710
did you know he was the executive producer of blackish and he also created the

354
00:22:38.711 --> 00:22:42.610
east ray show on Hbo with Esra,
which I thought,

355
00:22:42.730 --> 00:22:45.190
I didn't even know that about Larry.
I just thought,
you know,

356
00:22:45.191 --> 00:22:48.640
he tried the nighttime thing after the daily show and it didn't really work out,

357
00:22:48.641 --> 00:22:52.330
but he's super smart and super thoughtful.
Um,

358
00:22:52.570 --> 00:22:55.480
and so I've just really enjoyed it.
And I do it with my,
uh,

359
00:22:56.110 --> 00:22:58.900
afer mentioned colleague Brian Goldsmith,

360
00:22:59.170 --> 00:23:03.910
who is like a walking,
talking dictionary of politics.

361
00:23:03.970 --> 00:23:07.090
Um,
I always turn to him whenever I'm like,
Brian,

362
00:23:07.091 --> 00:23:11.710
what percentage of voters and you know,
Scranton,
Pennsylvania did such and such.

363
00:23:11.710 --> 00:23:14.570
And he's like,
oh,
Katie,
I'll tell you.
And he got,
um,

364
00:23:14.860 --> 00:23:19.750
he got grounded in high school for sneaking out of his bedroom to watch c span.

365
00:23:19.930 --> 00:23:24.610
So that's how that,
that,
that is how Geeky Brian is.

366
00:23:24.640 --> 00:23:27.880
But I,
I just,
I think he,
he's,
he's like,
Eh,

367
00:23:28.090 --> 00:23:31.120
have become a very close friend.
Um,
you know,
he's,

368
00:23:31.180 --> 00:23:34.000
he's much younger than I am and a,

369
00:23:34.001 --> 00:23:38.410
I really enjoy working with him and honestly,
I think he's so great.
I wanted,

370
00:23:38.740 --> 00:23:43.060
I wanted to help launch him a little bit too.
And so when we're at Yahoo,

371
00:23:43.061 --> 00:23:47.600
I try to make sure I include him in our coverage because as I said,

372
00:23:47.601 --> 00:23:52.400
he's just so smart and has such an interesting perspective.

373
00:23:52.430 --> 00:23:54.350
And,
um,
you know,

374
00:23:54.650 --> 00:23:58.660
I really want to do more mentoring before I go to the grapes

375
00:24:01.000 --> 00:24:05.270
or I'm in the nursing homes.
Cool.
You know,
curled in a corner,
you know,

376
00:24:05.271 --> 00:24:07.790
talking incessantly like I'm doing today.

377
00:24:07.791 --> 00:24:12.791
But I really want to help young people kind of find their way.

378
00:24:12.921 --> 00:24:15.920
And so that's one of the reasons I wanted to do this podcast.

379
00:24:15.921 --> 00:24:19.610
I wanted to introduce Brian to a larger audience.
Cool.

380
00:24:19.850 --> 00:24:24.160
<v 0>To let everyone know it is available on Google play music and on iTunes.</v>

381
00:24:24.250 --> 00:24:26.810
<v 2>No,
no,
no.
Yeah,</v>

382
00:24:26.820 --> 00:24:31.380
please subscribe because we need to get more subscribers even if you don't

383
00:24:31.381 --> 00:24:32.214
listen.

384
00:24:35.470 --> 00:24:37.760
<v 0>I wanted to talk a little bit about your work,
um,</v>

385
00:24:37.810 --> 00:24:41.680
with documentary film making because you've taken on some pretty tough

386
00:24:41.800 --> 00:24:46.030
challenges and some of the films that you've produced fed up looking at the

387
00:24:46.031 --> 00:24:51.031
obesity epidemic under the gun on the history of gun violence in America and

388
00:24:51.521 --> 00:24:55.380
you're new,
um,
project for the National Geographic Channel,
uh,

389
00:24:55.410 --> 00:24:59.080
gender revolution,
a journal with a journey with Katie.
Correct.

390
00:24:59.260 --> 00:25:04.260
How did that project come about and what did you learn that surprised you?

391
00:25:04.331 --> 00:25:08.260
Since we've been talking a lot about gender and it's clearly on everyone's
minds,

392
00:25:08.261 --> 00:25:10.150
and I also want to remind people there are microphones.

393
00:25:10.151 --> 00:25:11.440
I could talk to Katie forever,

394
00:25:11.441 --> 00:25:16.230
but we'll let her talk about her a new documentary and um,

395
00:25:16.540 --> 00:25:17.373
take it from there.

396
00:25:17.460 --> 00:25:19.080
<v 2>Um,
well,
you know,</v>

397
00:25:19.081 --> 00:25:24.081
I think for the same reasons that I was describing this fragmented and siloed

398
00:25:24.751 --> 00:25:27.870
media environment where,
you know,
Gosh,

399
00:25:27.900 --> 00:25:32.190
I'm sure you all have read it and reading a lot about fake news and you know,

400
00:25:32.191 --> 00:25:36.300
these fake news sites and I know Google is taking a close look at that,

401
00:25:36.301 --> 00:25:41.301
which I really commend Google for as well as Facebook because I think there was

402
00:25:42.721 --> 00:25:46.190
so much misinformation.
Hi Erica.
Uh,

403
00:25:46.350 --> 00:25:48.270
there was so much misinformation.

404
00:25:48.271 --> 00:25:52.140
Erica actually convinced me to get on Twitter when I was at CBS News.

405
00:25:52.141 --> 00:25:56.790
Damn you Erica.
Um,
but anyway,

406
00:25:56.820 --> 00:26:00.310
um,
just on that subject,
uh,

407
00:26:00.360 --> 00:26:03.160
Brian was telling me you a funny story and I,
I,

408
00:26:03.370 --> 00:26:06.960
I don't know if you guys obviously probably got a lot of fake news and your

409
00:26:06.961 --> 00:26:10.260
Facebook feeds or you were,
you know,
familiar with that.

410
00:26:10.261 --> 00:26:14.790
I really get most of my news from newsletters and good old fashioned newspapers.

411
00:26:14.820 --> 00:26:16.800
But,
um,
uh,

412
00:26:17.580 --> 00:26:20.220
a friend of mine emailed me or texted me,

413
00:26:20.430 --> 00:26:25.140
did you see this piece about huma and her connections in Saudi Arabia?

414
00:26:25.141 --> 00:26:28.980
And I said,
Dana,
where did you see that?
Where did you get that?
And she said,

415
00:26:28.981 --> 00:26:33.360
I'm not sure,
but it's all over social media.
And I'm like,
it's bullshit.

416
00:26:33.390 --> 00:26:37.950
You can't listen to some of this stuff that is being fabricated to influence,

417
00:26:38.370 --> 00:26:40.770
you know,
the voters across the country,

418
00:26:40.771 --> 00:26:43.290
you have to go to more legitimate sources.

419
00:26:43.710 --> 00:26:46.950
And Brian had a waitress at a diner,

420
00:26:46.951 --> 00:26:50.850
he said a couple of days ago and said,
she said something like,
you know,

421
00:26:51.120 --> 00:26:54.450
Houma and Hillary are lesbian lovers,
Houma,

422
00:26:54.990 --> 00:26:59.520
Houma Converted Hillary to Islam and blah,
blah,
blah.

423
00:26:59.550 --> 00:27:02.640
And Brian said,
well,
where are you getting this?
And she said,

424
00:27:02.641 --> 00:27:04.110
it's all over the news.

425
00:27:04.320 --> 00:27:09.320
So I think a lot of people cannot differentiate credible news sources from fake

426
00:27:09.331 --> 00:27:13.110
news.
And I think it's very scary and dangerous.

427
00:27:13.111 --> 00:27:17.340
Not to mention the fact that people are living in their own silos.

428
00:27:17.341 --> 00:27:21.810
And as a friend of mine said,
looking for affirmation,
not information.
So,

429
00:27:21.840 --> 00:27:22.171
you know,

430
00:27:22.171 --> 00:27:27.171
that's another I think vaccine issue that the media is going to have to deal

431
00:27:27.511 --> 00:27:29.700
with and the country's going to have to deal with.

432
00:27:30.210 --> 00:27:35.210
And especially at a time where that trust in institutions is so low,

433
00:27:35.641 --> 00:27:40.190
including the media.
What was the question?
Sorry,

434
00:27:41.770 --> 00:27:45.590
I'm sorry.
My documentary.
So real quickly,
sorry,
real quickly,
sorry.

435
00:27:46.490 --> 00:27:50.930
Objects in a much more in depth way you could touch on that but also the,

436
00:27:50.960 --> 00:27:55.080
the new one that the gender revolution.
Well,
real quickly,

437
00:27:55.081 --> 00:27:59.370
I just overall why wanted to get into the documentary space is I think it was my

438
00:27:59.371 --> 00:28:01.560
frustration with the cursory treatment.

439
00:28:01.561 --> 00:28:04.620
A lot of these subjects get in the mainstream media.
Um,

440
00:28:04.650 --> 00:28:07.290
the fact that it's very hard,
you know,

441
00:28:07.291 --> 00:28:10.650
there used to be white papers when I was growing up back in the day where there

442
00:28:10.651 --> 00:28:12.300
would be our,
you know,

443
00:28:12.301 --> 00:28:17.301
specials on a certain topic or Edward r Murrow would do harvest of shame and

444
00:28:17.341 --> 00:28:19.530
talk about migrant workers and you know,

445
00:28:19.560 --> 00:28:24.560
they took a look at some of these big looming social issues and really kind of

446
00:28:24.601 --> 00:28:29.220
unpack them and dissected them and tried to understand why it was happening,

447
00:28:29.221 --> 00:28:33.680
how we got here and what we can do about it.
And I thought there was such a,

448
00:28:33.681 --> 00:28:36.950
a dearth of those kinds of stories.

449
00:28:37.000 --> 00:28:41.070
It's sort of an add on media in general or in media in general.

450
00:28:41.550 --> 00:28:45.570
And I was interested in,
for example,
childhood obesity.

451
00:28:46.380 --> 00:28:48.360
I thought,
I've been covering this for 30 years.

452
00:28:48.361 --> 00:28:50.160
I don't know if anybody here watch that up.

453
00:28:50.161 --> 00:28:55.161
But I've been covering this childhood obesity for 30 years and it keeps getting

454
00:28:55.201 --> 00:28:56.034
worse.

455
00:28:56.070 --> 00:29:00.540
And I wanted to really understand the underpinnings of this social ill.

456
00:29:00.780 --> 00:29:05.700
So I really explored it in a,
in a very full way.

457
00:29:05.730 --> 00:29:09.720
And I,
I found it very gratis,
ratifying and satisfying to do that.

458
00:29:09.870 --> 00:29:11.640
Similarly with the gun issue,
you know,

459
00:29:11.641 --> 00:29:15.720
I think we hear all these terms like gun show loophole or um,
you know,

460
00:29:15.721 --> 00:29:20.220
all kinds of things about,
you know,
whether it's a background check or whatever.

461
00:29:20.221 --> 00:29:21.690
And I think in,

462
00:29:22.110 --> 00:29:27.110
we hear so many fragments of news that I wanted to be able to connect the dots

463
00:29:29.040 --> 00:29:33.690
to give people the information they needed so they could have an intelligent and

464
00:29:33.691 --> 00:29:38.610
less polarizing conversation about gun violence in America.
That was my goal.

465
00:29:39.060 --> 00:29:42.160
And with the gender,
you know,

466
00:29:42.161 --> 00:29:46.660
my daughter is a junior at Stanford and she is very,

467
00:29:46.661 --> 00:29:49.840
very socially conscious and uh,
she's worked,

468
00:29:49.841 --> 00:29:52.390
she wants to work for the southern poverty law center this summer.

469
00:29:52.390 --> 00:29:57.070
She's very upset about the state of the world.
And she,

470
00:29:57.071 --> 00:30:00.040
um,
she told me at Stanford and discussion groups,

471
00:30:00.041 --> 00:30:03.760
everybody goes around in the circle and they introduce themselves by their name

472
00:30:03.761 --> 00:30:08.200
and their,
uh,
not,
it's no longer even called preferred pronoun but Pronoun.

473
00:30:08.560 --> 00:30:12.010
And I thought,
that's really interesting.
And then every day it seemed to me,

474
00:30:12.011 --> 00:30:16.510
I was reading about whether it was gender nonconforming people and of course

475
00:30:16.750 --> 00:30:21.200
trans,
uh,
uh,
people have gotten a lot more attention.
Um,

476
00:30:21.280 --> 00:30:24.790
I think in part because of Caitlyn Jenner and you know,

477
00:30:24.880 --> 00:30:29.470
celebrity can actually really be very influential and,
and I think,

478
00:30:29.650 --> 00:30:33.190
um,
advancing a conversation or,
or a cause.

479
00:30:33.640 --> 00:30:37.770
And so I wanted to understand it better because let's face it,
I'm a 59,
five,

480
00:30:37.930 --> 00:30:42.730
59 year old CIS gender woman.
So cool right now.

481
00:30:42.731 --> 00:30:45.130
But you know,
and so I was like,
I,

482
00:30:45.160 --> 00:30:50.160
this is very new to me and even some of my very progressive friends who are more

483
00:30:50.760 --> 00:30:55.090
of my generation were having a hard time kind of understanding all this.

484
00:30:55.570 --> 00:30:56.560
And I thought,
you know,

485
00:30:56.561 --> 00:31:01.300
the only way we can be more appreciative and more tolerant and more

486
00:31:01.301 --> 00:31:04.600
understanding is if we are better educated.

487
00:31:04.601 --> 00:31:09.601
So I set out on this little gender journey and I interviewed people,

488
00:31:11.140 --> 00:31:13.270
transgender people of different ages.

489
00:31:13.570 --> 00:31:18.570
I interviewed intersects people to try to understand sort of the origins of

490
00:31:18.761 --> 00:31:22.750
gender and the biological factors that,

491
00:31:23.020 --> 00:31:28.020
that may have us be one gender or another or neither or somewhere in between.

492
00:31:28.780 --> 00:31:33.450
And um,
I went to Yale and I talked to a lot of,
uh,

493
00:31:33.460 --> 00:31:38.290
Lgbtq kids about kind of how young people see gender.

494
00:31:38.620 --> 00:31:43.200
And I noticed there was quite a generational divide.
And so I,

495
00:31:43.320 --> 00:31:46.000
you know,
I'm just,
I,
I'm one of those crazy people.

496
00:31:46.001 --> 00:31:49.630
I just am very curious about the world even now.
And,

497
00:31:50.230 --> 00:31:54.460
and I think I'm very curious,
most importantly about the changing world.

498
00:31:55.030 --> 00:31:58.660
And transitions are really difficult.

499
00:31:58.661 --> 00:32:00.790
I'm not talking about gender churches into,
but you know,

500
00:32:00.791 --> 00:32:05.791
the way the country is transitioning is I think very confusing for a lot of

501
00:32:06.341 --> 00:32:11.341
people and I think they may be more traditional or have more,

502
00:32:13.360 --> 00:32:17.020
you know,
and I had been conditioned to see things a certain way.

503
00:32:17.290 --> 00:32:22.290
So I'm trying to help myself be educated and continue learning and as a result

504
00:32:23.530 --> 00:32:25.720
hopefully help other people as well.

505
00:32:26.420 --> 00:32:26.661
<v 0>Great.</v>

506
00:32:26.661 --> 00:32:31.650
And I think it probably couldn't come at a better time for people to educate
and,

507
00:32:31.700 --> 00:32:35.270
and learn more.
Um,
Erica,
the cursive era.

508
00:32:36.260 --> 00:32:40.430
<v 2>Erica America.
Yeah.
Katie,
thank you so much for here.
Um,</v>

509
00:32:41.000 --> 00:32:45.050
<v 3>so I just want to comment first on your mentorship.
Um,
you know,
you do,</v>

510
00:32:45.120 --> 00:32:47.060
you put your,
your money where your mouth is.

511
00:32:47.061 --> 00:32:49.610
Like you helped my time at CBS evening news.

512
00:32:49.670 --> 00:32:53.060
I'm launching my career to go to spend four years at Twitter or helping them

513
00:32:53.061 --> 00:32:55.550
shape the way they think about news and now it Google news lab team.

514
00:32:55.551 --> 00:32:58.340
So thank you for giving me the opportunity.
Um,

515
00:32:58.670 --> 00:33:03.670
my question for you is obviously technology companies to to that I've worked for

516
00:33:03.891 --> 00:33:07.100
now at Google are really grappling with their role in,
in news,

517
00:33:07.101 --> 00:33:10.690
in the news ecosystem and um,
having worked for you,

518
00:33:10.700 --> 00:33:13.970
one of the most important things I learned about his sharp news judgement and

519
00:33:14.000 --> 00:33:17.330
the amount of time you think about an editorial teams.
Think about,
um,

520
00:33:17.450 --> 00:33:21.230
what makes it is the gatekeeper,
um,
to,
to the front porch.

521
00:33:21.260 --> 00:33:26.180
And so I'm curious what kind of advice,
candid advice you would offer to,
um,

522
00:33:26.290 --> 00:33:27.920
if folks at Google,
at Facebook,

523
00:33:27.921 --> 00:33:31.850
at Twitter executives who are or non executives who are thinking about the

524
00:33:31.851 --> 00:33:36.851
responsibility and grappling with the UN defining it undefined manner and role

525
00:33:38.210 --> 00:33:41.900
in which they play in this new somewhat unbalanced information ecosystem?

526
00:33:42.470 --> 00:33:42.681
<v 2>I mean,</v>

527
00:33:42.681 --> 00:33:47.681
that's a huge question and I think one that really is going to take some soul

528
00:33:47.841 --> 00:33:52.841
searching on the part of these companies and media outlets and tech companies.

529
00:33:53.390 --> 00:33:58.250
You know,
um,
you know,
it's,

530
00:33:58.251 --> 00:33:59.750
it's such a balance,
right?

531
00:33:59.751 --> 00:34:04.751
You want people to see the content sometimes to get them to see the content in

532
00:34:05.991 --> 00:34:09.110
this incredibly flooded space,
right,

533
00:34:09.170 --> 00:34:12.650
is to make very click baity headlines.
Now,

534
00:34:12.651 --> 00:34:16.830
sometimes click baity headlines actually are,
uh,

535
00:34:16.910 --> 00:34:20.930
do represent what the article is saying.
I talked to Fred Ryan,

536
00:34:20.931 --> 00:34:24.200
who's a friend of mine who publishes The Washington Post and they've been very

537
00:34:24.201 --> 00:34:28.400
successful with their digital news.
And he was talking about,

538
00:34:28.520 --> 00:34:30.520
they had an article about Sussex.

539
00:34:30.950 --> 00:34:33.170
I'm having a hard time talking about the succession.

540
00:34:33.230 --> 00:34:37.820
I have always had a hard time with six session and Saudi Arabia.
And they,

541
00:34:38.330 --> 00:34:42.740
they headlined it one particular way and it didn't get much traffic.

542
00:34:42.740 --> 00:34:45.530
But when they wrote game of Thrones and Saudi Arabia,

543
00:34:45.950 --> 00:34:49.550
a lot of people clicked on it.
So I think there's,
you know,

544
00:34:49.551 --> 00:34:53.480
it's all nuanced and it's all judgment and it's all,

545
00:34:53.810 --> 00:34:55.790
when do you go too far?
When,

546
00:34:55.940 --> 00:35:00.110
when is it appropriate with these new tools and technology?

547
00:35:00.580 --> 00:35:02.870
Um,
and so listen,

548
00:35:03.080 --> 00:35:06.830
I think part of the reason that,
you know,

549
00:35:06.831 --> 00:35:11.540
some people would say we're in the situation we're in,
is because there was no,

550
00:35:11.630 --> 00:35:15.860
there weren't enough gatekeepers.
You know,
anybody who did road,

551
00:35:15.861 --> 00:35:20.090
anything could put it out there.
And you know,

552
00:35:20.120 --> 00:35:23.000
it could be seen as news that,
you know,

553
00:35:23.480 --> 00:35:27.350
Hillary Clinton and Bill Clinton had killed all these people,
you know,

554
00:35:27.351 --> 00:35:29.000
and that got pushed out.

555
00:35:29.001 --> 00:35:34.001
And for some people who may not be as well informed or use to really getting

556
00:35:34.671 --> 00:35:37.470
their news and information from a variety of sources,

557
00:35:37.950 --> 00:35:40.500
they may in fact believe these things,
you know,

558
00:35:40.501 --> 00:35:43.410
some that are written in Macedonia,
who knows?

559
00:35:43.830 --> 00:35:48.600
And so I think we've started to see,
uh,
uh,

560
00:35:48.660 --> 00:35:53.660
an evaluation of the roles and responsibility that these tech companies and

561
00:35:55.531 --> 00:35:59.490
media organizations have.
Um,
and,

562
00:36:00.690 --> 00:36:05.640
and dispensing and dispersing accurate information.
You know,

563
00:36:05.641 --> 00:36:09.630
it's interesting you mentioned Gwen.
I fall who I just,
you know,

564
00:36:09.631 --> 00:36:12.960
was a really wonderful person.
I didn't know her that well,

565
00:36:13.380 --> 00:36:18.380
but I had spent some time with her and I was reading a piece and the the Poynter

566
00:36:18.660 --> 00:36:23.250
Institute,
um,
that does sort of journalistic integrity and responsibility.

567
00:36:23.760 --> 00:36:24.630
And they said,
you know,

568
00:36:24.631 --> 00:36:29.400
it's interesting and all these obituaries and tributes to Gwen,

569
00:36:29.401 --> 00:36:34.350
they talked about how reasonable and fair and accurate where she was and how

570
00:36:34.351 --> 00:36:39.090
those attributes have just not become,
um,

571
00:36:39.180 --> 00:36:44.180
celebrated in our media culture that it is much better these days to be

572
00:36:44.911 --> 00:36:48.380
provocative.
Right.
And rather than,

573
00:36:48.430 --> 00:36:51.960
than fair and accurate cause who wants fair and accurate,
that's so boring.

574
00:36:52.470 --> 00:36:55.860
You know,
you want to have an edge,
you want to have a point of view.

575
00:36:56.250 --> 00:36:57.900
So I think we have to be very,

576
00:36:57.901 --> 00:37:02.901
very careful that the pendulum hasn't swung too far too provocative and,

577
00:37:03.871 --> 00:37:08.400
and isn't at the expense of being accurate.
And,
and,

578
00:37:08.401 --> 00:37:13.170
right.
Thank you.
Thank you Erica.
I planted her.

579
00:37:13.590 --> 00:37:18.270
Not really.
I didn't really,
I was surprised to see you're actually,
hi.

580
00:37:18.570 --> 00:37:19.890
Should we take more?
Yeah,
yeah.

581
00:37:20.700 --> 00:37:23.040
<v 4>Well,
first off,
thanks so much for coming.
Um,</v>

582
00:37:23.070 --> 00:37:27.680
but someone who has been watching you for most of my life,
I vote,
uh,

583
00:37:27.960 --> 00:37:30.300
respect you tremendously and I trust you.

584
00:37:30.301 --> 00:37:32.700
And so I've been so depressed about the election,

585
00:37:32.701 --> 00:37:35.760
but I finally felt comforted when I heard you talking about it.

586
00:37:35.761 --> 00:37:40.761
So can I just purely selfishly ask you to say something hopeful or optimistic

587
00:37:41.530 --> 00:37:43.230
and the wake of this whole,
and about,

588
00:37:43.510 --> 00:37:44.343
<v 5>that's how</v>

589
00:37:47.890 --> 00:37:49.660
thinking about women and politics

590
00:37:49.710 --> 00:37:54.480
<v 4>ticks and it's so deeply depressing and I just want to have something positive</v>

591
00:37:54.481 --> 00:37:55.020
to think of.

592
00:37:55.020 --> 00:37:59.220
<v 2>Well,
you know,
there are some great things.
Carla Harris,
Tammy Duckworth,
you know,</v>

593
00:37:59.221 --> 00:38:03.460
I think for,
uh,
women were elected,
uh,
uh,

594
00:38:03.510 --> 00:38:07.930
more diverse women.
I think,
you know,
um,
I,

595
00:38:08.160 --> 00:38:09.390
I want to be helpful.

596
00:38:09.391 --> 00:38:14.391
I think it's so unclear the path forward for the country right now that I don't

597
00:38:15.871 --> 00:38:20.190
want to be,
you know,
falsely optimistic.

598
00:38:20.430 --> 00:38:22.140
Um,
I mean I think,

599
00:38:22.470 --> 00:38:26.100
I think the good democracy will survive and the country will survive.

600
00:38:26.101 --> 00:38:31.101
But I think we're going through some very painful and intense growing pains.

601
00:38:31.350 --> 00:38:34.920
And I think,
um,
you know,
I,

602
00:38:35.170 --> 00:38:38.920
this is unchartered territory.
Having said that,
I,

603
00:38:38.921 --> 00:38:43.921
I also believe there are many likeminded people who hold certain values very

604
00:38:43.931 --> 00:38:48.370
dear of social justice and equality and,
um,

605
00:38:48.940 --> 00:38:52.030
that somehow,
you know,
what I worry about is just how,

606
00:38:52.480 --> 00:38:56.500
how far apart these two Americas seem to feel and seem to be.

607
00:38:57.240 --> 00:38:58.540
Um,
and how,

608
00:38:58.750 --> 00:39:02.920
how can we have this venn diagram where we overlap on some things.

609
00:39:03.550 --> 00:39:08.350
Um,
I also want to believe that there are not even with Republican controlled

610
00:39:08.530 --> 00:39:10.030
everything,
uh,

611
00:39:10.031 --> 00:39:14.950
in Washington that there are enough checks and balances that things will

612
00:39:14.951 --> 00:39:19.780
stabilize.
Um,
but it's interesting,
a woman in the Atlantic,
I think it's a woman,

613
00:39:19.870 --> 00:39:20.230
uh,

614
00:39:20.230 --> 00:39:25.230
but a writer in the Atlantic wrote about voters should not take Donald Trump.

615
00:39:25.810 --> 00:39:30.070
Literally,
voters took Donald Trump,
sorry.

616
00:39:30.370 --> 00:39:34.990
The media took him literally and not seriously.
And voters took him,
uh,

617
00:39:35.080 --> 00:39:37.570
did not take him literally,
but took him seriously.

618
00:39:38.020 --> 00:39:43.020
And so I think it really remains to be seen what he's going to do.

619
00:39:43.240 --> 00:39:45.580
Visa VI,
immigration,
you know,

620
00:39:45.581 --> 00:39:49.780
you hear different things every day about the wall or the deportation force.

621
00:39:49.781 --> 00:39:50.920
And you know,

622
00:39:50.921 --> 00:39:55.000
I think it sounds like the transition team is in some significant disarray at

623
00:39:55.001 --> 00:39:57.580
this,
at this juncture.
So I think,

624
00:39:57.610 --> 00:40:02.140
I think the most optimistic thing I could say is we have to be patient,

625
00:40:02.650 --> 00:40:06.820
you know,
don't freak out yet.
And just sort of,

626
00:40:07.210 --> 00:40:11.170
I do think what Hillary Clinton said and her concession speech of we need to

627
00:40:11.171 --> 00:40:15.430
give,
have an open mind to give him a chance to lead.
Um,

628
00:40:15.460 --> 00:40:19.060
so we'll just have to see where that takes us.
But I do believe,
you know,

629
00:40:19.061 --> 00:40:24.061
we're doing a series on ya who called American goodness because I thought we

630
00:40:24.461 --> 00:40:29.461
need to celebrate what's happening at the grassroots level in communities all

631
00:40:29.741 --> 00:40:34.120
across the country and we're celebrating these programs and these individuals

632
00:40:34.121 --> 00:40:35.830
who are doing amazing things.

633
00:40:36.100 --> 00:40:40.060
I just interviewed a man yesterday named Karen's coffee,

634
00:40:40.330 --> 00:40:44.840
who was in and out of prison for 20 years and he went through the,

635
00:40:44.841 --> 00:40:47.470
the doe fund.
I don't know if you all have ever heard of the doe fund.

636
00:40:47.471 --> 00:40:50.200
You might've seen the guys out on the street with their ready,

637
00:40:50.201 --> 00:40:55.120
willing and able jackets clean,
cleaning up a trash with their buckets.

638
00:40:55.180 --> 00:40:58.130
And it's a program where,
uh,

639
00:40:58.630 --> 00:41:03.630
recently incarcerated individuals go through and they give training and housing

640
00:41:04.570 --> 00:41:09.520
and expertise and really a hand hand up as he said,

641
00:41:09.521 --> 00:41:14.260
not a handout.
And Terrence coffee went through the program after,
as I said,

642
00:41:14.261 --> 00:41:18.160
being incarcerated in and out of jail for prison for 20 years.

643
00:41:18.730 --> 00:41:22.900
He ended up going to Bronx community college,
graduating.

644
00:41:22.901 --> 00:41:25.270
He said five Theta Kapp.
I'd never heard of that.

645
00:41:25.271 --> 00:41:28.630
But I guess for community colleges,
that's the equivalent of five Beta kappa.

646
00:41:28.930 --> 00:41:32.500
He then went on to Nyu,
transferred there,
uh,

647
00:41:32.750 --> 00:41:36.440
I graduated with a degree in social work and now he's getting his master's at

648
00:41:36.441 --> 00:41:38.930
Nyu and helping other,
uh,

649
00:41:39.170 --> 00:41:41.900
people who have been just released from prison.

650
00:41:42.440 --> 00:41:46.910
And he was so eloquent and so inspiring.

651
00:41:47.210 --> 00:41:50.750
And you look at a program like that,
which is really helping people,

652
00:41:50.960 --> 00:41:52.760
decreasing the recidivism rate,

653
00:41:52.761 --> 00:41:57.230
helping people make a transition into a positive life.

654
00:41:57.230 --> 00:41:58.580
And it was so inspiring.

655
00:41:58.820 --> 00:42:02.150
And so I'm trying to put a spotlight on people who are doing just these

656
00:42:02.151 --> 00:42:06.200
incredibly important and impactful,
that's not really a word,

657
00:42:06.201 --> 00:42:10.820
but it that became more but impactful things in their local communities.

658
00:42:11.240 --> 00:42:15.320
And I mean it really does renew your faith in the human spirit.

659
00:42:15.680 --> 00:42:20.390
So I think maybe think a little more micro cosmically and get involved in

660
00:42:20.391 --> 00:42:21.950
things.
I saw that um,

661
00:42:22.010 --> 00:42:26.990
contributions to the Adl have gone up I think 80% because of the increase in

662
00:42:26.991 --> 00:42:29.990
hate crimes across the country.
So,
you know,
get involved.

663
00:42:29.991 --> 00:42:32.240
I'm very upset that a lot of people didn't vote.

664
00:42:32.540 --> 00:42:36.080
Right now they're saying 46% of registered voters did not vote.

665
00:42:36.260 --> 00:42:40.790
I mean that number isn't a definitive but turnout was that a 20 year low?

666
00:42:40.791 --> 00:42:43.220
And I think that's disgusting and embarrassing.

667
00:42:43.550 --> 00:42:47.090
And I feel like if you're protesting,
you better damn well have voted to,

668
00:42:49.220 --> 00:42:49.840
oh,
sorry.
Yeah,

669
00:42:49.840 --> 00:42:51.630
<v 0>it,
I got all down or</v>

670
00:42:55.320 --> 00:42:56.800
most of that before I go to bed.

671
00:42:58.750 --> 00:43:02.440
I wanted to circle back Katie to something we talked about when they introduced

672
00:43:02.441 --> 00:43:05.050
you,
which is your work on cancer and health care.

673
00:43:05.051 --> 00:43:10.051
And in terms of finding inspiration and forging a path forward where maybe we've

674
00:43:10.111 --> 00:43:14.530
felt less hopeful in the past cause I think stand up to cancer and some of the

675
00:43:14.531 --> 00:43:16.050
other initiatives you've been involved in.

676
00:43:16.090 --> 00:43:17.830
I'm hoping you could tell us a bit more about what,

677
00:43:18.160 --> 00:43:20.200
what new approaches are being tried there.

678
00:43:20.201 --> 00:43:24.910
What makes you hopeful that maybe there is a new way forward in,
um,

679
00:43:25.090 --> 00:43:26.110
cancer treatment?

680
00:43:26.290 --> 00:43:28.840
<v 2>Well,
I'm really thank you for asking it and I mean,</v>

681
00:43:28.841 --> 00:43:31.340
I'm really hoping that we're,

682
00:43:31.380 --> 00:43:36.380
we're paving a new way and sort of establishing a new paradigm just very quickly

683
00:43:37.600 --> 00:43:41.710
what the whole approach of stand up to cancer is.
Laura Ziskin,

684
00:43:41.711 --> 00:43:45.010
who a Hollywood producer who passed away from breast cancer,

685
00:43:45.011 --> 00:43:48.280
she produced Spiderman and other big movies.
Uh,

686
00:43:48.310 --> 00:43:50.530
she joined forces for Sherry Lansing,

687
00:43:50.531 --> 00:43:55.120
me and six other crazy type a women.
And we said,
you know,

688
00:43:55.121 --> 00:43:58.150
the pace of the pace of research is just too slow.

689
00:43:58.450 --> 00:44:03.430
We have to support our scientists to in a much stronger,

690
00:44:03.431 --> 00:44:07.420
more palpable way.
And so we started raising money.

691
00:44:07.421 --> 00:44:12.130
We do a telecast every two years and we are actually,

692
00:44:12.131 --> 00:44:15.640
our whole approach is collaboration.
Not Competition.

693
00:44:15.641 --> 00:44:20.020
So we have established dream teams of scientists who are all working together

694
00:44:20.021 --> 00:44:24.820
from different institutions,
from pharmaceutical companies,
from biotech firms,

695
00:44:25.090 --> 00:44:29.560
and are all focusing their time and energy on once a pancreatic cancer,

696
00:44:29.561 --> 00:44:30.810
when his cancer Epi,

697
00:44:31.380 --> 00:44:36.380
which is a relatively new field and they're all collaborating and sharing their

698
00:44:36.481 --> 00:44:40.860
resources,
their brainpower,
the grants,
the tissue samples,

699
00:44:40.861 --> 00:44:44.130
whatever it takes.
So we can move science forward faster.

700
00:44:44.370 --> 00:44:48.270
And I think right now we have two FDA approved drugs and you know,

701
00:44:48.271 --> 00:44:50.970
I think there we're making progress.

702
00:44:50.971 --> 00:44:54.210
I also think it's been a big shot in the arm to the cancer community,

703
00:44:54.480 --> 00:44:55.650
to Hollywood.

704
00:44:55.680 --> 00:44:59.100
The Entertainment Industry Foundation is the umbrella organization of stand up

705
00:44:59.101 --> 00:45:04.020
to cancer and Hollywood has come out to support these scientists in a big way.

706
00:45:04.320 --> 00:45:05.700
And so I think I hopefully,

707
00:45:05.820 --> 00:45:10.290
hopefully it's elevated their standing and their status in society because to me

708
00:45:10.291 --> 00:45:14.700
they are the unsung heroes and heroines of,
of,
of the world.

709
00:45:15.090 --> 00:45:16.740
And we're able to,

710
00:45:16.741 --> 00:45:20.490
with the money that we pledge and raise and get from great corporate sponsors,

711
00:45:20.491 --> 00:45:23.280
like Major League baseball and Mastercard Fund,

712
00:45:23.281 --> 00:45:28.140
their research because only one in 10 promising research proposals is actually

713
00:45:28.141 --> 00:45:30.360
funded by the federal government.
We have a lot of,

714
00:45:31.130 --> 00:45:36.090
a lot to make up for in terms of,
you know,
giving the scientists the,

715
00:45:36.240 --> 00:45:39.090
the resources they need.
So,
you know,

716
00:45:39.091 --> 00:45:43.260
it's been a really exciting opportunity for me to,

717
00:45:44.070 --> 00:45:48.660
to spread the word about the need for cancer research dollars.

718
00:45:49.020 --> 00:45:49.421
You know,
I,

719
00:45:49.421 --> 00:45:53.760
I initially focused on colon cancer because maybe you guys are too young to

720
00:45:53.761 --> 00:45:54.181
remember,

721
00:45:54.181 --> 00:45:59.181
but my husband died of colon cancer when he was 42 in 1998 and I,

722
00:45:59.820 --> 00:46:01.590
you know,
did a colonoscopy on TV.

723
00:46:01.591 --> 00:46:03.960
You all are probably still too young to remember that,

724
00:46:03.961 --> 00:46:07.920
but it was kind of a big deal,
very big deal.
And uh,
and,
and,

725
00:46:07.921 --> 00:46:12.720
and colonoscopies went up.
20% is results.
So I've been a big advocate and a big,

726
00:46:13.430 --> 00:46:16.580
um,
proponent of prevention.
Um,

727
00:46:16.940 --> 00:46:20.730
but I felt like I was giving all my attention to the colons and not enough

728
00:46:20.731 --> 00:46:24.270
attention to all these other cancers that badly needed funding.

729
00:46:24.271 --> 00:46:29.271
So it's been really gratifying for me to be involved with stand up to cancer.

730
00:46:30.180 --> 00:46:34.290
And the scientists are so remarkable.
I mean,
if you just want to be blown away,

731
00:46:34.291 --> 00:46:39.291
just talk to the selfless scientists who spend hours and hours with very little,

732
00:46:40.290 --> 00:46:40.621
uh,

733
00:46:40.621 --> 00:46:45.600
attention and very little positive feedback and they're just working their asses

734
00:46:45.601 --> 00:46:49.170
off trying to figure out and unlock the mystery of cancer.

735
00:46:49.171 --> 00:46:53.670
And it's such an important time for cancer research because of big data because

736
00:46:53.671 --> 00:46:56.910
of,
you know,
genomics and uh,
you know,

737
00:46:56.911 --> 00:47:00.480
this whole confluence of things that are coming together that make it,

738
00:47:00.570 --> 00:47:05.040
that makes this an incredibly exciting time.
And you know,

739
00:47:05.260 --> 00:47:08.610
I just want,
want people to have more options,

740
00:47:08.640 --> 00:47:12.210
even if it's means managing cancerous,
if it's a chronic disease.

741
00:47:13.200 --> 00:47:16.440
<v 0>Great.
Thank you.
Again,
just incredibly inspirational.</v>

742
00:47:16.441 --> 00:47:19.020
And I was one of the people who watched your colonoscopy

743
00:47:21.750 --> 00:47:24.240
and it was,
it was inspirational.
It was groundbreaking.

744
00:47:24.241 --> 00:47:28.530
And I think it just removed a lot of the taboos about talking about our bodies

745
00:47:28.531 --> 00:47:30.100
and what we could do to take care of them.

746
00:47:30.100 --> 00:47:34.930
<v 3>And Katie also did a mammogram on air,
which again,
for young women in particular,</v>

747
00:47:34.931 --> 00:47:37.000
these are just drew the line at a pap smear.

748
00:47:39.840 --> 00:47:42.010
People take our next audience question.

749
00:47:42.620 --> 00:47:47.390
So before I became a Googler,
I want it to be Katie Couric on the show.
True.

750
00:47:47.410 --> 00:47:51.090
It's not what it's called.
No,
but you know,

751
00:47:51.091 --> 00:47:55.580
you showed that as a woman in a career you could be serious and respected but

752
00:47:55.581 --> 00:47:59.990
also funny and warm.
And um,
unfortunately as you've mentioned today,

753
00:47:59.991 --> 00:48:04.520
a lot like we've seen this shift on the morning shows from less serious to more

754
00:48:04.521 --> 00:48:05.520
fluff.
Um,

755
00:48:05.570 --> 00:48:08.900
and so I'm just curious how much you had to grapple with that when you were on

756
00:48:08.901 --> 00:48:13.901
air and what as viewers we can do to kind of demand more serious,

757
00:48:14.020 --> 00:48:14.810
um,
coverage,

758
00:48:14.810 --> 00:48:17.660
knowing that the morning shows are still where a lot of people just get their

759
00:48:17.661 --> 00:48:18.494
news.

760
00:48:18.890 --> 00:48:21.230
<v 2>Well,
you know,
I think,
um,
you know,</v>

761
00:48:21.231 --> 00:48:24.980
obviously I'm still very friendly with a lot of people on the today show.

762
00:48:25.280 --> 00:48:26.930
And I think you'll see,

763
00:48:27.030 --> 00:48:31.760
I think you've seen a return to more serious news during this political season.

764
00:48:31.761 --> 00:48:36.740
I think for awhile,
uh,
the today show was trying to emulate good morning America,

765
00:48:36.741 --> 00:48:39.000
which is a little more,
uh,

766
00:48:39.530 --> 00:48:42.020
lighthearted and um,

767
00:48:42.230 --> 00:48:44.900
but then I think they returned to sort of,

768
00:48:44.901 --> 00:48:49.880
they're more journalistic roots center now a bit more serious.
Um,

769
00:48:50.570 --> 00:48:52.730
you know,
I think it's hard because again,

770
00:48:52.731 --> 00:48:56.600
they're feeling the pressure of competition with people getting information on

771
00:48:56.601 --> 00:49:01.310
their phones and little bits and pieces and they're trying to,

772
00:49:01.400 --> 00:49:04.880
to maintain the audience as well.
Um,

773
00:49:04.910 --> 00:49:09.290
but I still think a lot of great work is done in the morning.
I think,
you know,

774
00:49:09.291 --> 00:49:14.270
cvs has done some really good work and as a little more slower paced,

775
00:49:14.300 --> 00:49:18.620
um,
and a little,
a little harder probably.
Um,

776
00:49:18.650 --> 00:49:22.070
but you know,
I'll tell them you said that.

777
00:49:23.180 --> 00:49:27.590
And you know,
I used to,
I used to push for certain things and uh,

778
00:49:27.591 --> 00:49:31.580
I was kind of a squeaky wheel on that show and I would be like,

779
00:49:31.610 --> 00:49:36.110
I am not doing another story on Lacy Peterson today unless something actually

780
00:49:36.111 --> 00:49:40.280
happened in the case.
Um,
and so I think,
I think,

781
00:49:40.730 --> 00:49:44.540
let them know how you feel and write to them and communicate.

782
00:49:44.541 --> 00:49:47.630
And when you see something you like that you appreciate,
you know,

783
00:49:47.631 --> 00:49:52.400
let them know and give them positive feedback because I think a lot of people

784
00:49:52.401 --> 00:49:54.200
feel the same way you do.
I mean,

785
00:49:54.201 --> 00:49:59.120
I think the great thing about when I did the today show that I loved is you

786
00:49:59.121 --> 00:50:02.270
could do a hard hitting interview in one half hour,
you know,

787
00:50:02.630 --> 00:50:07.070
with someone like Lee Iacocca or I even interviewed David Duke back in the day.

788
00:50:07.340 --> 00:50:12.170
And then,
you know,
later on in the show you could do something really fun.

789
00:50:12.171 --> 00:50:14.600
And then there was always those in between segments,

790
00:50:14.601 --> 00:50:18.500
which I thought were really important too about health.
You know,

791
00:50:18.550 --> 00:50:21.560
that's not so much about science,
but you know,

792
00:50:21.561 --> 00:50:24.050
maybe about the,
you know,

793
00:50:24.200 --> 00:50:27.740
how often you should see your doctor when you should be for this,

794
00:50:27.741 --> 00:50:28.431
that and the other thing,

795
00:50:28.431 --> 00:50:32.810
really important sort of news you can use and things that I thought were a real

796
00:50:32.811 --> 00:50:35.300
public service.
So,
um,

797
00:50:35.360 --> 00:50:39.260
I'll let my friends at the today show know that you appreciate the harder stuff

798
00:50:39.530 --> 00:50:41.420
as well on that.
You'd like to see more of it.

799
00:50:42.420 --> 00:50:45.000
<v 6>Okay,
great.
Thank you.
Last audience.</v>

800
00:50:45.310 --> 00:50:48.290
<v 7>All right,
thank you for being here.
So the one related to the previous question,</v>

801
00:50:48.291 --> 00:50:51.410
you mentioned earlier that a lot of news networks are driven by ratings and

802
00:50:51.411 --> 00:50:54.320
ultimately profits even though it's sometimes conflict to the journalistic

803
00:50:54.321 --> 00:50:55.154
ideals.

804
00:50:55.400 --> 00:50:58.610
Do you think there's value to having a BBC style at Guttman funded news network?

805
00:50:58.640 --> 00:51:01.340
What journalism really is the first,
second and third priority?

806
00:51:01.750 --> 00:51:06.010
<v 2>Yeah,
I did get there one day.</v>

807
00:51:06.360 --> 00:51:11.050
Um,
I don't know,
you know,
I think,
I think it's all up for grabs.
I mean,

808
00:51:11.051 --> 00:51:16.030
I think,
uh,
I think,
well,
you know,
we have PBS,

809
00:51:16.060 --> 00:51:20.660
right?
And so news hour I think,
did you,
you watch news hour?
Yeah.

810
00:51:21.310 --> 00:51:25.960
And um,
you know,
I think for a lot of people they think it's,

811
00:51:25.990 --> 00:51:27.010
it's um,

812
00:51:28.070 --> 00:51:28.600
<v 6>okay,</v>

813
00:51:28.600 --> 00:51:33.600
<v 2>it's maybe too old fashioned or boring or you know,</v>

814
00:51:34.210 --> 00:51:38.800
not splashing enough.
But I'm really hoping that after all this,

815
00:51:39.040 --> 00:51:39.401
you know,

816
00:51:39.401 --> 00:51:43.840
people are going to want to eat their vegetables and not eat cotton candy and

817
00:51:43.841 --> 00:51:47.770
brownies all the time that they're going to Wa that they'll have more of an

818
00:51:47.771 --> 00:51:49.750
appetite for longer form.

819
00:51:49.751 --> 00:51:54.730
Stories aren't even on their phones and that,
you know,
we're always,

820
00:51:54.780 --> 00:51:57.280
oh,
we can't,
we can't make things too long.

821
00:51:57.281 --> 00:52:01.390
And I appreciate that and I think there's a balance but that people will stay

822
00:52:01.391 --> 00:52:02.740
engaged with,
with,

823
00:52:02.830 --> 00:52:07.830
with longer material that attention spans won't have been destroyed forever from

824
00:52:08.711 --> 00:52:13.270
some of these social media platforms.
So I'm optimistic that,

825
00:52:13.870 --> 00:52:17.890
that people really care about these issues and they want to understand them and

826
00:52:17.891 --> 00:52:22.180
you can't understand complicated issues in 140 characters.

827
00:52:23.800 --> 00:52:24.520
<v 6>Yup.</v>

828
00:52:24.520 --> 00:52:26.360
<v 0>Great.
So I want to close out with,
um,</v>

829
00:52:26.470 --> 00:52:30.760
one of our traditions here at Google that we do an internal interviews with

830
00:52:31.150 --> 00:52:35.260
folks is the Proust queries,
which was a parlor game,
um,

831
00:52:35.320 --> 00:52:40.320
that was popularized by Marcel Proust and it's just thought to give insight into

832
00:52:40.510 --> 00:52:43.540
a person's true nature.
Ro Ro,

833
00:52:46.280 --> 00:52:50.590
I think about these.
Which historical figure do you most identify with?

834
00:52:50.660 --> 00:52:52.190
<v 6>Hi,
with,
yeah.</v>

835
00:52:52.320 --> 00:52:53.760
<v 2>Well,
I think that's a ridiculous question</v>

836
00:52:55.920 --> 00:52:58.620
because I mean really,
what are you supposed to say?

837
00:52:58.621 --> 00:53:03.540
I mean it's so narcissistic.
Um,
so Gandhi,

838
00:53:03.930 --> 00:53:08.640
I mean,
I don't know Betty boop,
but I have no idea.

839
00:53:08.700 --> 00:53:10.620
Honestly,
next I'm not answering that.

840
00:53:10.760 --> 00:53:13.990
What I want to know what other people have answered all

841
00:53:14.530 --> 00:53:15.000
<v 6>okay.</v>

842
00:53:15.000 --> 00:53:18.720
<v 0>Over the map.
I mean,
people pick sports figures,</v>

843
00:53:18.721 --> 00:53:22.590
they pick entertainment figures.
Yes.
This is why it's,
you know,
giving insight.

844
00:53:22.591 --> 00:53:26.010
Okay.
So we can,
we can pivot a little bit.

845
00:53:26.011 --> 00:53:30.540
So who is your favorite hero of fiction or history?
Not that you identify with,

846
00:53:30.541 --> 00:53:31.740
but I guess who do you

847
00:53:32.330 --> 00:53:36.830
<v 2>most admire in fiction or in real life?
You can pick either one.</v>

848
00:53:36.950 --> 00:53:40.490
I have one in fiction and one real okay.
Give,
give us,

849
00:53:40.810 --> 00:53:45.200
and they're both honestly so boring,
but I'll tell you anyway.
Um,

850
00:53:45.560 --> 00:53:50.480
I think in real life it's Eleanor Roosevelt because she had to put up with so

851
00:53:50.481 --> 00:53:55.481
much crap and did so much and cared about inequality and injustice and

852
00:53:57.111 --> 00:54:02.111
underserved Americans long before it was fashionable to do so.

853
00:54:02.990 --> 00:54:05.600
And,
uh,
I admire her so much.

854
00:54:05.601 --> 00:54:08.720
Her commitment to public service throughout the course of her career.

855
00:54:09.260 --> 00:54:13.220
The fact that she worked on expanding women's roles in the workplace,

856
00:54:13.610 --> 00:54:17.360
this was a long,
long time ago.
And the fact that,
you know,

857
00:54:17.361 --> 00:54:21.290
she was mocked and paraded in the early stages of her career and universally

858
00:54:21.291 --> 00:54:26.240
admired and was considered one of the most esteemed women,
uh,
of her,

859
00:54:26.420 --> 00:54:29.750
of her day at the end of her life.
Um,

860
00:54:30.050 --> 00:54:33.800
I really admire her so much.
Um,
fiction.

861
00:54:35.540 --> 00:54:40.220
Uh,
this is so boring too and so like predictable,
but I don't care.
Um,

862
00:54:40.250 --> 00:54:43.430
Atticus finch in to kill a mockingbird,
uh,

863
00:54:43.490 --> 00:54:47.840
not in to kill a mockingbird less so and go set a watchman if you all read the

864
00:54:47.841 --> 00:54:50.900
second book.
Um,
although I wasn't as critical,

865
00:54:50.901 --> 00:54:52.850
I think go set a watchman was a,

866
00:54:53.120 --> 00:54:57.920
was a fairly true reflection of what Harper Lee was writing about at the time.

867
00:54:57.921 --> 00:55:00.610
She did write to kill a mockingbird,
um,

868
00:55:00.830 --> 00:55:05.830
just because he is just the epitome of decency and courage and compassion and

869
00:55:10.010 --> 00:55:14.960
love.
And he was a great father.
And I,
you know,
I just,

870
00:55:15.020 --> 00:55:18.050
I just really long for those kinds of people.

871
00:55:18.170 --> 00:55:22.580
I don't know why I'm getting a little foot the here and I had a huge thing for

872
00:55:22.581 --> 00:55:25.960
Gregory Peck.
Cool.

873
00:55:26.430 --> 00:55:30.300
<v 0>Leave it there.
And thank you so much.
Um,
I think I speak for everyone here.</v>

874
00:55:30.301 --> 00:55:33.450
It was wonderful to have you here on any day,

875
00:55:33.480 --> 00:55:37.530
but particularly at this point in our country's history and given what we're all

876
00:55:37.531 --> 00:55:41.640
trying to come to terms with,
um,
it's just one ACO with Betsy said,
um,

877
00:55:41.670 --> 00:55:46.320
particularly impactful to hear from you today.
Thanks so much.
Thank you.

