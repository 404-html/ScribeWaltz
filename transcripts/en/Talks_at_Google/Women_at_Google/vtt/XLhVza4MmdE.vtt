WEBVTT

1
00:00:05.730 --> 00:00:09.170
All right.
Hello everybody.
Thank you so much for coming today.

2
00:00:09.171 --> 00:00:10.400
My name is Brian Wiley,

3
00:00:10.730 --> 00:00:13.850
timing people operations and one of the teams that I lead is the people

4
00:00:13.851 --> 00:00:17.210
innovation lab where we happen to know that social sciences like the coolest

5
00:00:17.211 --> 00:00:18.044
thing ever.

6
00:00:18.230 --> 00:00:23.230
So it is my sincere pleasure to welcome Dolly Choate to Google.

7
00:00:23.640 --> 00:00:28.490
You talk about a fantastic book that she just wrote called how good people fight

8
00:00:28.491 --> 00:00:33.110
bias.
The person you mean to be?
Dolly is a social psychologist.

9
00:00:33.140 --> 00:00:38.140
She's a professor of management at Nyu and she is writing about things that so

10
00:00:38.691 --> 00:00:43.691
many of us at Google care desperately about and articulate the journey that I

11
00:00:44.271 --> 00:00:46.460
feel like we as an organization are on today.

12
00:00:46.461 --> 00:00:50.060
So it is such a pleasure to have him here too.
It's such an honor to be here.

13
00:00:50.061 --> 00:00:54.200
Thank you so much to everybody for coming,
especially after a long weekend.
Well,

14
00:00:54.201 --> 00:00:57.140
I have to start by confessing something.
Oh,

15
00:00:57.560 --> 00:00:59.690
I have known to say,
uh,

16
00:00:59.691 --> 00:01:02.570
after reviewing all of the unconscious bias literature,

17
00:01:03.020 --> 00:01:06.290
helping to put together trainings and workshops and talking to Google is about

18
00:01:06.291 --> 00:01:07.550
it.
At the end of all of this,

19
00:01:07.551 --> 00:01:12.170
I often say social scientists have been great at demonstrating that we have a

20
00:01:12.171 --> 00:01:15.620
problem.
Yes.
But they had been terrible at telling us how to fix it.

21
00:01:16.130 --> 00:01:19.580
And I thought that was true until I read your book and you had done

22
00:01:21.680 --> 00:01:26.300
such a wonderful job at piecing together a narrative across lots of different

23
00:01:26.301 --> 00:01:30.380
studies and taking the results of those studies and translating them into

24
00:01:30.381 --> 00:01:34.490
practical advice for those of us who want to be better.
So I appreciate that.

25
00:01:34.491 --> 00:01:34.610
Yeah.

26
00:01:34.610 --> 00:01:36.260
<v 1>Thank you,
Brian.
I,
I,</v>

27
00:01:36.310 --> 00:01:41.310
I think part of my motivation to write this book was that I'm as confused as

28
00:01:41.961 --> 00:01:46.961
everyone else and trying to navigate the confusing space and trying to be as

29
00:01:47.481 --> 00:01:48.980
good a person as I want to be.

30
00:01:49.430 --> 00:01:53.780
And it occurred to me that there is some stuff and these dusty academic journals

31
00:01:53.781 --> 00:01:56.750
that no one reads that could be helpful.

32
00:01:56.751 --> 00:01:59.960
And my goal was a lot of the research isn't mine,
but I thought I could share,

33
00:01:59.961 --> 00:02:03.970
rate it,
throw mine in,
add some fantastic stories and interviews.
And

34
00:02:05.590 --> 00:02:10.510
<v 0>you definitely did do that.
Thank you.
So I have so many questions.
Oh my gosh,</v>

35
00:02:10.530 --> 00:02:14.200
she had the chance to have lunch before and,
and for Dolly,
that's it.
She's like,

36
00:02:14.230 --> 00:02:16.250
I need to go to the restaurant.
We didn't

37
00:02:17.810 --> 00:02:20.970
just getting a rest for my questions.
Scott,

38
00:02:21.620 --> 00:02:26.620
here's some that I thought our audience would like to hear the answers to.

39
00:02:27.250 --> 00:02:27.830
And by the way,

40
00:02:27.830 --> 00:02:32.830
we'll have a Q and a for about 40 minutes and then we will open up the mics to

41
00:02:32.991 --> 00:02:34.900
your questions as well.
Um,

42
00:02:34.901 --> 00:02:39.901
so at first I want to start with something that is so central to your book that

43
00:02:40.811 --> 00:02:43.210
if you don't get this concept and agree with it,

44
00:02:43.211 --> 00:02:44.950
it's like you shouldn't even read the rest of the book.

45
00:02:44.980 --> 00:02:47.830
That's not a good sales pitch.
All that's a terrible sales transfer.

46
00:02:47.831 --> 00:02:51.100
I believe we can all be there,
but I thought we had to start there.

47
00:02:51.320 --> 00:02:55.270
And that is with the concept of bounded ethicality.
Ah,
yeah.

48
00:02:55.360 --> 00:02:56.870
I'm going to quote something from your book.
Okay.

49
00:02:57.040 --> 00:03:01.720
Founded ethicality is the psychology of goodish people.
Good Ish.

50
00:03:01.721 --> 00:03:04.330
People are sometimes good and sometimes not,

51
00:03:04.720 --> 00:03:08.290
sometimes intentionally and sometimes not like all of us.

52
00:03:08.650 --> 00:03:11.140
This model of bounded ethicality challenges,

53
00:03:11.141 --> 00:03:15.640
ways of thinking and talking in which you are either a good person or not are

54
00:03:15.641 --> 00:03:18.580
racist or not and unethical human or not.
Yeah,

55
00:03:18.730 --> 00:03:23.230
we argue that this binary notion is seductive but misleading and scientifically

56
00:03:23.231 --> 00:03:27.670
inaccurate.
So this seems obvious when it's spelled out this way,
at least to me,

57
00:03:28.090 --> 00:03:31.930
but what does it mean to internalize like founded ethicality for ourselves?

58
00:03:31.931 --> 00:03:33.340
And why is it so hard to do so?

59
00:03:33.580 --> 00:03:35.680
<v 1>Yeah.
Thank you so much.
Um,</v>

60
00:03:36.310 --> 00:03:41.310
so we've got a really tight corner that we put ourselves in when we think about

61
00:03:42.370 --> 00:03:44.560
who we want to be.
Um,

62
00:03:45.880 --> 00:03:48.730
research shows that on us one to seven scale,

63
00:03:48.880 --> 00:03:53.530
most of us put the importance of thinking of ourselves as a good person above a

64
00:03:53.531 --> 00:03:57.100
sex.
It's really important to ask that like mother Theresa,
good.

65
00:03:57.101 --> 00:04:01.870
But just having an identity where we think of ourselves as the kind of person

66
00:04:02.050 --> 00:04:03.790
that we would call a good person.

67
00:04:03.970 --> 00:04:07.240
It doesn't your definition and your definition and your definition may be

68
00:04:07.241 --> 00:04:10.450
different of what a good person is,
but whatever your own definition is,

69
00:04:10.690 --> 00:04:15.040
that is something that most of us hold dear to us and we feel really threatened

70
00:04:15.430 --> 00:04:19.960
when there's anything that suggests we're not hitting that good person bar some

71
00:04:19.961 --> 00:04:23.740
minimum threshold of like being a good person.
Um,

72
00:04:24.340 --> 00:04:29.260
I know I feel that way.
I got an email from a student,
uh,

73
00:04:30.130 --> 00:04:35.130
telling me that I had assigned a sexist reading to class and it was a female

74
00:04:35.231 --> 00:04:39.820
student and I'm,
I consider myself a feminist.
I have two daughters.

75
00:04:39.970 --> 00:04:44.440
I am trying hard to raise them as feminists and to get an email like this feels

76
00:04:44.441 --> 00:04:47.980
very threatening.
Like this is,
Oh my God,

77
00:04:47.981 --> 00:04:52.210
you've totally threatened my good person bar.
Um,
my good person identity.

78
00:04:53.080 --> 00:04:56.050
But the truth is when I reread the reading I was like,
Ooh,

79
00:04:56.940 --> 00:04:58.880
it's a little like wow.
I,

80
00:04:58.970 --> 00:05:01.990
what is the whole thing about like women just love to shop.
Like there,

81
00:05:01.991 --> 00:05:05.350
there was some stuff in that article and it really should have caught my eye.

82
00:05:05.620 --> 00:05:08.920
But I had,
I had my own blind spots and it just went right by me.

83
00:05:09.310 --> 00:05:12.640
And the problem is if as a good person,

84
00:05:12.641 --> 00:05:16.870
if I have to be in a super tight corner where there was no room for blind spots

85
00:05:17.080 --> 00:05:20.560
and no room for mistakes,
I will not grow from that mistake.

86
00:05:20.590 --> 00:05:22.840
I will dismiss that email from that student.

87
00:05:22.900 --> 00:05:25.240
I will not learn from what she's helped me see.

88
00:05:25.390 --> 00:05:29.950
I will keep assigning that reading cause I won't see the value in her critique.

89
00:05:30.460 --> 00:05:32.530
And as a result,

90
00:05:32.560 --> 00:05:37.480
my desire to be a good person is going to hold me back from being a better

91
00:05:37.481 --> 00:05:42.430
person.
Our research on bounded at the quality and when I say our research,

92
00:05:42.431 --> 00:05:44.020
I mean our field like,

93
00:05:44.110 --> 00:05:49.110
like psychologists for the last 40 years have shown in so many different ways

94
00:05:50.050 --> 00:05:52.900
that we do have blind spots,
that we do have lapses,

95
00:05:52.901 --> 00:05:57.620
that we do make mistakes and the,
we do have unconscious bias.

96
00:05:57.650 --> 00:06:01.190
We do or we are prone to conflicts of interest outside of our awareness.

97
00:06:01.970 --> 00:06:06.080
And every one of those examples,
the question is for me,

98
00:06:06.110 --> 00:06:09.860
are we just going to deny that or are we going to grow from it?

99
00:06:09.920 --> 00:06:14.270
And so what I'm proposing is given that the research on bounded at the county's

100
00:06:14.271 --> 00:06:18.800
clear,
let's break out of that corner that's super tight,

101
00:06:18.830 --> 00:06:23.240
either or either I'm a good person or I'm not corner and give ourselves room to

102
00:06:23.241 --> 00:06:26.360
grow.
And what that means is setting a higher standard.

103
00:06:26.361 --> 00:06:30.860
Being a goodish person instead of a good person is someone who doesn't

104
00:06:30.861 --> 00:06:34.070
necessarily make more mistakes,
but they do acknowledge more mistakes.

105
00:06:34.071 --> 00:06:36.560
They do own more mix,
makes mistakes,

106
00:06:36.680 --> 00:06:40.400
and they do learn from your mistakes than someone who simply is in that tight

107
00:06:40.401 --> 00:06:43.040
good person corner.
Yeah.
When I read this,

108
00:06:43.130 --> 00:06:44.780
<v 0>uh,
that portion of your book,</v>

109
00:06:44.870 --> 00:06:49.870
it called to mind all the ways that we reinforced the binary in how we talk

110
00:06:50.031 --> 00:06:54.710
about other people.
Like we'll talk about,
uh,
people as evil or that's,

111
00:06:54.770 --> 00:06:58.490
this person is such a great person or this person's a criminal.

112
00:06:58.491 --> 00:07:02.210
It's almost like we've created the boundaries already and then you exist within

113
00:07:02.240 --> 00:07:03.073
it doesn't,

114
00:07:03.140 --> 00:07:06.350
it doesn't lend itself to a growth mindset which you talk a lot about.

115
00:07:06.440 --> 00:07:10.700
<v 1>Exactly and that growth mindset is that work in progress mindset is everyone</v>

116
00:07:10.730 --> 00:07:14.360
here is familiar that where it's not either or good.

117
00:07:14.361 --> 00:07:18.050
We are always getting better no matter where our starting point is and one of

118
00:07:18.051 --> 00:07:22.880
the things that I learned the most from in writing the book was the people I

119
00:07:22.881 --> 00:07:23.481
interviewed,

120
00:07:23.481 --> 00:07:28.481
some of whom are like icons like Joe McNeil of the Greensboro Four 1960

121
00:07:30.381 --> 00:07:34.310
Woolworths lunch counter sit ins like led the sit in movement.

122
00:07:34.670 --> 00:07:36.920
Someone who's truly a civil rights giant.

123
00:07:36.921 --> 00:07:41.810
Speaking candidly about his efforts to have a growth mindset about gay rights,

124
00:07:42.080 --> 00:07:46.880
like a really moving story to me that says this either or binary is going to

125
00:07:46.881 --> 00:07:50.390
hold us back.
We have to find the work in progress inside.

126
00:07:51.900 --> 00:07:56.830
<v 0>You use concepts in your books that were like seeing old friends to me because</v>

127
00:07:56.831 --> 00:08:00.340
they're concepts that are very important to us at Google and ones that we have

128
00:08:00.341 --> 00:08:03.730
been doing our own research on it and have found to be internally important.

129
00:08:04.030 --> 00:08:06.670
So growth mindset versus a fixed mindset,

130
00:08:06.671 --> 00:08:11.560
which is this notion that um,
uh,
we all have things to learn.

131
00:08:11.710 --> 00:08:14.050
Uh,
we can all grow,
we can get better.

132
00:08:14.051 --> 00:08:17.530
We should be incorporating feedback is so important to how we tried to engage

133
00:08:17.531 --> 00:08:18.850
with our work and with each other.

134
00:08:19.390 --> 00:08:24.190
There's another concept of psychological safety and that is creating

135
00:08:24.191 --> 00:08:28.560
environments where it's safe to express yourself,
to admit mistakes,
to learn.
Uh,

136
00:08:28.570 --> 00:08:32.110
we have done our own research on teamwork and we found psychological safety is

137
00:08:32.111 --> 00:08:36.530
the number one predictor of whether teams are successful in their endeavors.
How,

138
00:08:36.820 --> 00:08:41.590
what I loved about your book is that you actually showed a pathway from growth

139
00:08:41.591 --> 00:08:46.570
mindset to psychological safety,
to uh,
fighting bias.

140
00:08:46.571 --> 00:08:48.310
Can you talk about those connections?

141
00:08:48.570 --> 00:08:53.100
<v 1>Sure.
And this is where I took the liberties that you can't take within science.</v>

142
00:08:53.101 --> 00:08:58.101
Where in science we would all been in a very narrow silo that Carol Dweck is a

143
00:08:59.101 --> 00:09:02.040
psychologist,
her and her colleagues who've done the work on growth mindset.

144
00:09:02.070 --> 00:09:03.390
Amy Edmondson is,
uh,

145
00:09:03.450 --> 00:09:06.630
the organizational behavior scholar with psychological safety,

146
00:09:06.631 --> 00:09:10.530
unconscious bias monitoring,
Banaji and,
and they're each doing really deep,

147
00:09:10.531 --> 00:09:13.590
deep work in those areas along with their labs and colleagues.

148
00:09:14.070 --> 00:09:19.070
But what that means is that connecting those doesn't happen within science.

149
00:09:19.350 --> 00:09:23.260
Those things sit separately within our journals.
Um,

150
00:09:23.270 --> 00:09:27.000
and so what I tried to do was step outside of the science a little bit.

151
00:09:27.300 --> 00:09:28.920
I say in the beginning of the book,

152
00:09:28.921 --> 00:09:32.880
like I'm going to step outside the science because I feel like we don't have

153
00:09:32.881 --> 00:09:37.881
time to wait 50 years before somebody is going to actually run the studies that

154
00:09:38.641 --> 00:09:39.840
connect all those things.

155
00:09:40.110 --> 00:09:43.170
I think we can use our common sentence to see the connections,

156
00:09:43.500 --> 00:09:47.190
growth mindset on an individual level.
Seeing yourself as a work in progress,

157
00:09:47.191 --> 00:09:48.060
seeing someone,

158
00:09:48.180 --> 00:09:52.620
seeing yourself as someone who can grow from mistakes rather than when you hit

159
00:09:52.621 --> 00:09:56.220
an obstacle and make a mistake,
you shut down,
you cheat,
you quit.

160
00:09:56.670 --> 00:09:58.020
That's what happens in a fixed mindset.

161
00:09:58.320 --> 00:10:02.070
Well that's the psychological safety is the same concept in a team.

162
00:10:02.490 --> 00:10:06.180
Do we shut down as a team?
Do we not talk about mistakes?

163
00:10:06.181 --> 00:10:10.830
Do we not verbalize vulnerability or do we create a space where we can talk

164
00:10:10.831 --> 00:10:14.190
about,
I think I messed that up.
I think I dropped the ball.

165
00:10:14.370 --> 00:10:16.410
I'm really scared about what's coming next.

166
00:10:16.860 --> 00:10:20.550
That's growth mindset to me on a team level.

167
00:10:21.090 --> 00:10:25.180
And I think that then sets the stage for things.

168
00:10:25.200 --> 00:10:28.250
Topics like unconscious bias.
Um,

169
00:10:28.650 --> 00:10:30.870
it's tough to,

170
00:10:31.080 --> 00:10:34.230
I think we've gotten to the point where we believe the science and unconscious

171
00:10:34.231 --> 00:10:35.064
bias,

172
00:10:35.100 --> 00:10:38.940
but it's still tough to believe that it might sometimes leak into our behavior

173
00:10:38.941 --> 00:10:42.420
that we might sometimes enact harm.
Um,

174
00:10:42.510 --> 00:10:47.510
and so that's where that psychological safety in a team where you can talk about

175
00:10:47.611 --> 00:10:52.440
it,
growth mindset within the individual sets us up to do the work on unconscious

176
00:10:52.441 --> 00:10:54.870
bias.
The thing that makes me sad,

177
00:10:54.871 --> 00:10:59.871
it's about the way the public dialogue has moved on unconscious bias is that we

178
00:11:01.531 --> 00:11:05.430
sometimes seem to be saying,
well,
because it's unconscious,

179
00:11:05.431 --> 00:11:07.530
I'm no longer accountable.

180
00:11:08.020 --> 00:11:10.770
Well that's like saying because I was drunk,

181
00:11:10.980 --> 00:11:15.980
I'm not accountable for the harm I did when I was behind the wheel.

182
00:11:16.230 --> 00:11:18.690
Absolutely.
It's,
you are still accountable.

183
00:11:18.691 --> 00:11:22.680
The question is how are we going to take ownership and learn from it?

184
00:11:22.710 --> 00:11:24.050
Especially when a scientist,

185
00:11:24.051 --> 00:11:27.060
we have not cracked the code on how to de bias our brains yet.

186
00:11:27.061 --> 00:11:30.750
So in the meantime we're going to have to use the growth mindset and

187
00:11:30.751 --> 00:11:32.640
psychological safety as our tools.

188
00:11:33.300 --> 00:11:36.630
That is definitely a theme I saw throughout the book,
which is noticing,

189
00:11:38.210 --> 00:11:41.370
noticing,
noticing and being aware.
Exactly.

190
00:11:41.371 --> 00:11:44.760
Being a first class noticer is a big part of it.

191
00:11:44.761 --> 00:11:48.180
And then starting to think about if we can't de bias the brain,

192
00:11:48.181 --> 00:11:51.900
how can we deep rise process the team,
the system,
the structures.

193
00:11:52.350 --> 00:11:54.130
A story you were telling me

194
00:11:54.130 --> 00:11:56.850
<v 0>earlier,
just stuck with me about,
um,</v>

195
00:11:57.670 --> 00:12:02.230
being willing to not just notice,
but to acknowledge when we have,

196
00:12:02.350 --> 00:12:07.330
when each of us has had a stereotype thought or expressed on unconscious bias

197
00:12:07.331 --> 00:12:11.070
and we made it conscious and it had to do with your work with,
uh,

198
00:12:11.140 --> 00:12:13.210
in prisons and people who are incarcerated.

199
00:12:13.211 --> 00:12:16.690
Can you talk a little bit about what you're doing with prison population and how

200
00:12:16.691 --> 00:12:20.440
you felt when you first went into that environment and how that affected you?

201
00:12:20.710 --> 00:12:25.690
<v 1>Yeah,
so I've had this really wonderful opportunity to get involved with the Nyu</v>

202
00:12:25.691 --> 00:12:27.310
prison education program.

203
00:12:27.850 --> 00:12:31.690
And during the year I spent working on this book,

204
00:12:31.691 --> 00:12:33.460
I had two priorities.
Uh,

205
00:12:33.490 --> 00:12:37.060
I took a sabbatical to work with that prison education program and to write the

206
00:12:37.061 --> 00:12:41.680
book.
And what that meant is I was teaching a four co for college credit course.

207
00:12:42.040 --> 00:12:46.810
Really similar to the one I teach Mba students at stern on leadership management

208
00:12:46.811 --> 00:12:48.280
and negotiation skills.

209
00:12:48.610 --> 00:12:53.380
And I was going to do it in a prison in upstate New York.
And

210
00:12:55.750 --> 00:12:58.240
what I realize now,
and I look back,

211
00:12:58.270 --> 00:13:02.440
is that one of the traps I describe in the book that I was probably like writing

212
00:13:02.441 --> 00:13:07.441
that chapter while I was actually displaying the behavior was I talk about the

213
00:13:08.291 --> 00:13:13.210
savior trap,
about having this vision of yourself as being a do gooder,

214
00:13:13.211 --> 00:13:18.211
who's going to save the day and have that feel good feeling that that warm glow

215
00:13:18.491 --> 00:13:21.190
that comes from saving someone else.
And I,

216
00:13:21.670 --> 00:13:26.500
I can now see how that was motivating me into wanting to do the teaching in

217
00:13:26.501 --> 00:13:30.100
prison.
But the problem with the savior trap,
it said,

218
00:13:30.101 --> 00:13:33.460
it's still kind of puts me like above,
right.

219
00:13:33.461 --> 00:13:36.640
And otherwise is the people I'm engaging with.

220
00:13:37.150 --> 00:13:42.010
And I saw that in the first couple of classes when I was teaching that I was

221
00:13:42.011 --> 00:13:44.470
like super scared of my students.

222
00:13:44.530 --> 00:13:49.530
And I definitely not view was not viewing them as individuals,

223
00:13:51.040 --> 00:13:56.040
but within a couple of classes it was sort of weirdly normal to teach in a

224
00:13:56.231 --> 00:13:58.810
prison.
Like they,
my students were just like,

225
00:13:58.811 --> 00:14:02.450
and I know there's some alums in the room,
but they would just think,
you guys,
um,

226
00:14:02.920 --> 00:14:03.380
they,

227
00:14:03.380 --> 00:14:07.120
they were funny and they were quiet and they were serious and they were more

228
00:14:07.121 --> 00:14:08.720
prepared and they were less prepared.
I mean,
they,

229
00:14:08.721 --> 00:14:13.721
they had a whole range of personalities and they were just individuals who were

230
00:14:15.731 --> 00:14:18.880
super motivated to learn.
Um,

231
00:14:18.940 --> 00:14:23.020
now do I know that some of them did things,
uh,

232
00:14:23.290 --> 00:14:27.820
that created real harm for people that led to them being in prison.

233
00:14:27.821 --> 00:14:32.440
Some of them did.
There is all sorts of injustices in the system as well.

234
00:14:33.070 --> 00:14:37.180
And is that confusing to me and does it create all sorts of like,
oh my God,

235
00:14:37.181 --> 00:14:38.980
the long drives home from the prison.

236
00:14:38.981 --> 00:14:43.981
We're like real confusing mental a times for me.

237
00:14:45.280 --> 00:14:49.480
But what I realized by the third class was I had dehumanized my students.

238
00:14:49.481 --> 00:14:52.250
I came in thinking I'm going to teach a group of felons,

239
00:14:52.251 --> 00:14:53.630
I'm going to redeem them.

240
00:14:53.660 --> 00:14:58.660
And that in of itself created this savior mentality where I was never going to

241
00:14:59.151 --> 00:15:02.060
be useful to them because I wasn't seeing them as human beings.

242
00:15:02.480 --> 00:15:07.480
And so it sort of clicked into place by class three that I had like a bunch of

243
00:15:09.741 --> 00:15:12.350
just individuals that I was going to interact with.
And,

244
00:15:12.710 --> 00:15:16.850
and one of them had read 106 books of the year before and showed me the list of

245
00:15:16.851 --> 00:15:21.290
his books and the other one cried when we role played difficult conversations

246
00:15:21.291 --> 00:15:24.380
because he was thinking about his son and they were people.

247
00:15:24.381 --> 00:15:28.310
And now about three quarters of my students have been released from prison.

248
00:15:28.340 --> 00:15:33.290
And when I encounter them and interact with them in the city and there in normal

249
00:15:33.291 --> 00:15:34.160
clothes,

250
00:15:35.180 --> 00:15:38.570
I truly realize that I had created this image,

251
00:15:38.571 --> 00:15:43.571
this uniformed image of an imprisoned to person that was absent of any humanity

252
00:15:46.820 --> 00:15:48.350
<v 0>talking about prisons.</v>

253
00:15:48.351 --> 00:15:53.240
And the criminal justice system actually brings up another aspect of your book.

254
00:15:53.270 --> 00:15:57.200
Now,
the first portion of your book is about,
uh,

255
00:15:57.230 --> 00:16:02.060
taking social science and helping us understand how each of us can notice and

256
00:16:02.061 --> 00:16:05.630
change our behaviors and to relate to people and have a growth mindset.

257
00:16:05.990 --> 00:16:09.470
But there's another thread through your book,
which is about systems.

258
00:16:10.060 --> 00:16:12.030
And so sometimes being,
uh,

259
00:16:12.130 --> 00:16:17.130
the biases that we encounter are byproducts of systems that we've created.

260
00:16:17.390 --> 00:16:20.570
And you talk about this in terms of headwinds and tailwinds.
I'm wondering,

261
00:16:20.571 --> 00:16:21.950
can you tell,
tell me what,

262
00:16:21.951 --> 00:16:26.951
what do those terms mean and is there any research that you can tell us,

263
00:16:27.110 --> 00:16:30.380
uh,
about that demonstrates how that happens?
Sure,
absolutely.

264
00:16:30.680 --> 00:16:35.670
<v 1>So I stole the metaphor of headwinds and tailwinds from Debbie Irving and she</v>

265
00:16:35.671 --> 00:16:38.700
talks about forces like,
okay,
so imagine,

266
00:16:38.701 --> 00:16:43.701
I'm like jogging so slowly that I do it really slow,

267
00:16:44.960 --> 00:16:46.600
but,
but,
okay.
But on,

268
00:16:46.850 --> 00:16:50.100
if I'm jogging and I've got a good tailwind going,

269
00:16:50.101 --> 00:16:54.510
I might improve my time from like,
it's usual 10 minute,

270
00:16:54.511 --> 00:16:56.880
32nd mile to like a 10 minute,

271
00:16:56.881 --> 00:16:59.730
15 second mile because I've got that tail and pushing me along.

272
00:17:00.150 --> 00:17:03.600
But I don't get a sense that I'm got a tailwind.

273
00:17:03.601 --> 00:17:05.550
You don't even feel tailwinds really,
right?

274
00:17:05.551 --> 00:17:08.400
You just feel like you're kind of racking it that morning and you're just like,

275
00:17:08.430 --> 00:17:13.260
I don't know.
It was maybe those,
those eggs I,
I'm just really like,
right.

276
00:17:13.500 --> 00:17:16.890
But then when you turn or you'd make that run and then you do the u turn to come

277
00:17:16.891 --> 00:17:20.700
back and now you've got the headwind and it,

278
00:17:20.790 --> 00:17:25.770
you feel every bit of it and it does slow you down and your time shows it and

279
00:17:25.771 --> 00:17:28.590
your fatigue shows in your motivation shows it,

280
00:17:29.220 --> 00:17:33.270
that headwind is much more visible to us then the tailwind,

281
00:17:33.271 --> 00:17:35.190
much more feelable to us.

282
00:17:35.580 --> 00:17:40.580
And what a systems approach is about is what are the ways in which we create

283
00:17:41.250 --> 00:17:44.220
very visible,
um,
uh,

284
00:17:44.310 --> 00:17:49.050
headwinds and less visible tailwinds.
What are the ways those are built?

285
00:17:50.010 --> 00:17:54.600
How we operate.
Um,
so I,
I,

286
00:17:54.840 --> 00:17:59.070
when I sent this book proposal off to publishers,

287
00:17:59.430 --> 00:18:01.770
I literally didn't have the word system in it.

288
00:18:01.800 --> 00:18:05.190
I didn't have system or systemic anywhere in the proposal.

289
00:18:05.550 --> 00:18:09.780
I thought this was going to be a book purely on the individual level about

290
00:18:09.781 --> 00:18:10.980
unconscious bias.

291
00:18:11.790 --> 00:18:16.470
And it was as I started talking to people and looking at the research that it

292
00:18:16.471 --> 00:18:20.880
became clear to me that even if I somehow like one of the Nobel prize and was

293
00:18:20.881 --> 00:18:23.840
the one who figured out how to divide this unconscious bias look like,

294
00:18:23.850 --> 00:18:28.020
say that was my claim to fame,
right?
Wave the magic wand.

295
00:18:28.380 --> 00:18:32.370
I still would not have solved the problem because our systems would still have

296
00:18:32.371 --> 00:18:36.840
so much bias built in the way we were.
Um,
for example,

297
00:18:37.170 --> 00:18:40.620
I used to work in professional services firms like investment banking and

298
00:18:40.621 --> 00:18:43.230
consulting.
And when we would interview,

299
00:18:43.470 --> 00:18:47.250
a big part of the way we would interview would be,
we would look for fit,

300
00:18:47.430 --> 00:18:51.000
cultural fit.
Like,
oh,
is this the person we've the classic,

301
00:18:51.600 --> 00:18:55.740
do you wanna um,
go on a long plane ride sitting next to them.

302
00:18:56.070 --> 00:19:01.070
What'd you want to be sitting next to them on a flight to Asia cultural fit and

303
00:19:01.501 --> 00:19:05.580
I was part of that system.
I interviewed people using those criteria,

304
00:19:05.790 --> 00:19:10.790
but now when I look back and I understand better what see how systems work,

305
00:19:12.540 --> 00:19:17.540
I realize I created a huge headwind for people who didn't go to the same alma

306
00:19:17.881 --> 00:19:22.680
mater as me who didn't have the same hobbies as me because those were the kinds

307
00:19:22.681 --> 00:19:27.450
of questions that like where the fit conversation could we banter about common

308
00:19:27.480 --> 00:19:32.480
interests and in fact Lauren Rivera sociologists did an in depth ethnography

309
00:19:32.790 --> 00:19:36.900
where she looked at hiring practices at elite firms and that's exactly what she

310
00:19:36.901 --> 00:19:41.901
found was that what we call fit that's meant to capture performance aspects of

311
00:19:42.811 --> 00:19:46.920
the job was in fact capturing things like passion,
hobbies,

312
00:19:47.250 --> 00:19:49.800
and shared academic backgrounds,

313
00:19:49.801 --> 00:19:53.880
things that weren't necessarily tied directly to the job.

314
00:19:54.210 --> 00:19:59.130
That's an example of a headwind where were people from a whole bunch of schools

315
00:19:59.131 --> 00:20:02.370
who could do the job,
who aren't going to get a chance at it.

316
00:20:02.580 --> 00:20:06.800
There's people who have varied interests,
are very cultural backgrounds,

317
00:20:06.801 --> 00:20:08.400
are very family backgrounds,

318
00:20:08.520 --> 00:20:12.840
who weren't going to fit the mold of the kind of banter that we would do in

319
00:20:12.841 --> 00:20:15.330
interviews.
And um,

320
00:20:15.710 --> 00:20:20.250
and people like me benefit from that tailwind because I did go to those schools

321
00:20:20.251 --> 00:20:22.650
and I do kind of have those hobbies.
I mean,

322
00:20:22.651 --> 00:20:26.820
I can talk about marathon running,
I just don't say my time.

323
00:20:29.060 --> 00:20:33.470
<v 0>It was very interesting that you and your collaborator Katy Milkman Yeah.</v>

324
00:20:33.640 --> 00:20:37.490
Um,
took these notions and applied it to your own academic community,

325
00:20:37.491 --> 00:20:40.850
which I think many universities

326
00:20:41.330 --> 00:20:41.640
<v 1>yeah.</v>

327
00:20:41.640 --> 00:20:45.780
<v 0>Would like to believe that they are probably the most egalitarian,
uh,</v>

328
00:20:45.840 --> 00:20:47.980
institutions you can be a part of.
Um,

329
00:20:47.980 --> 00:20:50.520
<v 1>but she did a study that showed otherwise I,</v>

330
00:20:50.560 --> 00:20:54.020
Katy Milkman who's at Wharton and do back and Nola,
uh,

331
00:20:54.130 --> 00:20:57.040
who's at Columbia business school is three of us went to Grad school together.

332
00:20:57.460 --> 00:21:02.260
And it really common practice before you apply to a phd program is,
uh,

333
00:21:02.310 --> 00:21:03.430
well I say really common,

334
00:21:03.460 --> 00:21:07.630
really common if you're on the inside and someone tells you to do this.

335
00:21:07.780 --> 00:21:11.380
So it's not so common is to email faculty.

336
00:21:11.381 --> 00:21:15.820
At the PHD program you're interested in and signal that you're interested and

337
00:21:15.821 --> 00:21:18.250
ask if they'd be willing to tell you about their research.

338
00:21:18.251 --> 00:21:20.770
And you do all this before you send your application in.

339
00:21:20.771 --> 00:21:25.540
So it's totally outside the official formal process.
And,

340
00:21:25.570 --> 00:21:29.410
um,
all three of us as Grad students had been advised to do that by people in our

341
00:21:29.411 --> 00:21:29.831
network.

342
00:21:29.831 --> 00:21:33.130
And we did that and we did get into Grad school and we did get great mentors and

343
00:21:33.131 --> 00:21:35.260
everything worked out happily ever after for us.

344
00:21:35.650 --> 00:21:40.600
But we were wondering what happens to people who aren't as network disaster or

345
00:21:40.601 --> 00:21:43.990
maybe people who do get this advice but,
um,

346
00:21:44.020 --> 00:21:49.020
don't quite match the profile that unconsciously maybe faculty despite three

347
00:21:49.450 --> 00:21:53.620
Galitary names might be looking for.
So we did something kind of sneaky,
sneaky.

348
00:21:53.621 --> 00:21:55.030
It was a sting operation,

349
00:21:55.090 --> 00:21:59.290
which as social scientists we call an audit study or a field experiment.

350
00:21:59.610 --> 00:22:02.710
And you know,
I know like Google,
you're very familiar with field experiments.

351
00:22:02.711 --> 00:22:07.060
So what we did was we created email addresses using people's names.

352
00:22:07.061 --> 00:22:10.660
We pretested these names,
either be male or female sounding,

353
00:22:10.661 --> 00:22:15.100
please forgive the gender binary.
Um,
and then white sounding,
black sounding,

354
00:22:15.101 --> 00:22:19.390
Hispanic sounding Chinese sounding or Indian sounding.
So those were five racial,

355
00:22:19.391 --> 00:22:24.190
ethnic identities to gender identities.
We cross them,
we have 10 identities now.

356
00:22:24.700 --> 00:22:28.030
We created multiple names for each identity so we don't have any sort of

357
00:22:28.330 --> 00:22:30.610
particular name effect for an identity.

358
00:22:31.390 --> 00:22:35.440
And then we created an email address for every one of those fictional students.

359
00:22:36.250 --> 00:22:41.250
We took the u s news and World report rankings of the top 260 schools for every

360
00:22:41.681 --> 00:22:44.590
phd granting department in those schools.

361
00:22:44.591 --> 00:22:47.080
We randomly pick the name of one professor.

362
00:22:47.081 --> 00:22:49.510
And you remember it is as I'm in academia,

363
00:22:49.511 --> 00:22:53.970
all our information is on the Internet were really easy to find slash stock and,

364
00:22:54.250 --> 00:22:58.510
and so,
um,
so it was really easy to do this.

365
00:22:58.900 --> 00:23:01.840
It was a lot of work,
but it was,
it was simple.
Um,

366
00:23:01.841 --> 00:23:05.680
so now we've got our fictional students and we've got one professor from every

367
00:23:05.681 --> 00:23:07.030
phd granting department.

368
00:23:07.031 --> 00:23:12.031
And what we did was we said what every professor received one email from one of

369
00:23:12.251 --> 00:23:16.720
those identities.
And our dependent variable was with the professor,

370
00:23:16.721 --> 00:23:18.070
right back to a cold call,

371
00:23:18.071 --> 00:23:21.370
email from a stranger saying they were interested in learning more about this

372
00:23:21.371 --> 00:23:25.180
phd program.
There's a little more nuance I'm going to skip,

373
00:23:25.181 --> 00:23:29.560
but if you're ever interested,
we've got some papers that get into the details.

374
00:23:29.561 --> 00:23:32.410
But if I,
if I cut to the chase,
um,

375
00:23:32.440 --> 00:23:35.740
we were comparing with the white male identity to all those,

376
00:23:35.741 --> 00:23:40.060
not why male identities and,
uh,
the students.

377
00:23:40.090 --> 00:23:44.470
And what we found was that if you were a white male student,

378
00:23:44.471 --> 00:23:45.670
you were,
um,

379
00:23:45.740 --> 00:23:50.000
you had about an 87% chance of getting a response to your email.

380
00:23:50.360 --> 00:23:51.950
And if you were not a white male student,

381
00:23:51.951 --> 00:23:55.400
you had a 62% chance of getting a response to your email.

382
00:23:55.940 --> 00:24:00.940
And this is identical emails being sent in identical time with an identical

383
00:24:01.430 --> 00:24:02.300
request.

384
00:24:02.780 --> 00:24:07.340
And so even in our world of academia where we,
you know,

385
00:24:07.341 --> 00:24:11.200
if anything,
we're stereotyped as being,
you know,
how we're stereotyped,

386
00:24:11.201 --> 00:24:15.920
like being sort of bleeding heart liberals.
Um,

387
00:24:15.950 --> 00:24:20.570
we were seeing what I have to assume was mostly unconscious bias.
It,

388
00:24:20.600 --> 00:24:24.020
they're very well is probably some conscious in there as well.

389
00:24:24.560 --> 00:24:27.920
But I think there was at least some unconscious bias at work.

390
00:24:28.800 --> 00:24:33.800
<v 0>Sobering.
Um,
I'd like to shift focus to work organizations.
Yes.</v>

391
00:24:33.810 --> 00:24:38.430
You happen to be sitting in one and ask you for some advice here.
Um,
uh,

392
00:24:38.431 --> 00:24:42.570
you devote a portion of your writing to what happens within organizations and

393
00:24:42.571 --> 00:24:47.220
for good reason because we spend much of our lives here and a lot of what we uh,

394
00:24:47.550 --> 00:24:52.020
get,
uh,
money status Doroty comes to work.

395
00:24:52.240 --> 00:24:54.930
So first of all,
I found your,

396
00:24:55.050 --> 00:24:58.710
your definition of diversity and inclusion.
Very interesting.

397
00:24:58.711 --> 00:25:00.800
So you define each of them differently.
Uh,

398
00:25:00.930 --> 00:25:04.950
let's start with how you view diversity and how you view inclusion.

399
00:25:05.390 --> 00:25:09.380
<v 1>Yes,
thanks.
Um,
and these words are often bundled together.
Diversity,
inclusion,</v>

400
00:25:09.410 --> 00:25:12.470
Dni.
Sometimes we throw in a B for belonging,
right?
But the,

401
00:25:12.471 --> 00:25:15.890
but they actually do mean different things.

402
00:25:15.891 --> 00:25:19.310
And if we're really to measure success,
we're going to need to know what we mean.

403
00:25:19.660 --> 00:25:24.650
Um,
the metaphor I've been using for diversity is I think of it is the gateway,

404
00:25:24.730 --> 00:25:29.360
the,
the getting of the job,
the getting into the school,
the getting on the team,

405
00:25:29.361 --> 00:25:33.470
the getting the promotion.
So it's,
it's a formal process.

406
00:25:33.500 --> 00:25:37.270
It's got,
it's often got some legal um,

407
00:25:37.950 --> 00:25:41.720
kind of guidance over what appropriate process is.

408
00:25:42.080 --> 00:25:47.080
It is relatively easy to measure and it sets someone up to get through the entry

409
00:25:50.091 --> 00:25:50.420
point.

410
00:25:50.420 --> 00:25:55.420
The gateway inclusion I think of as the pathway and the pathway is what leads up

411
00:25:57.591 --> 00:26:00.350
to that gateway and what comes after that gateway,

412
00:26:00.351 --> 00:26:04.340
what comes before it comes after.
So this,
this study I just described,

413
00:26:04.341 --> 00:26:08.030
the audit study is an example of a pathway study,
right?

414
00:26:08.210 --> 00:26:12.350
It was not the formal application process and to the PHD program.

415
00:26:12.620 --> 00:26:15.080
It was this informal.
If you were in the know,

416
00:26:15.081 --> 00:26:19.970
you sent the email and kind of started this little banter with a professor.

417
00:26:20.130 --> 00:26:20.570
Um,

418
00:26:20.570 --> 00:26:25.570
that is very much a pathway process and pathway processes we don't measure,

419
00:26:25.881 --> 00:26:30.830
they're hard to measure.
They can be as fluid as who interrupts who at a meeting,

420
00:26:31.190 --> 00:26:35.260
who goes to drinks with,
who,
who gives eye contact to who,

421
00:26:35.290 --> 00:26:37.040
who sits next to who.

422
00:26:37.430 --> 00:26:42.430
These are the every day moments that can have a real influence on how people

423
00:26:44.700 --> 00:26:46.530
experience an organization,

424
00:26:46.950 --> 00:26:51.360
but we're not as equipped to measure them as we go.

425
00:26:51.600 --> 00:26:53.700
And that falls into the inclusion side.

426
00:26:54.030 --> 00:26:55.530
<v 0>So if you think about inclusion this way,</v>

427
00:26:55.531 --> 00:27:00.000
there are hundreds of these moments that occur every single day,
right?

428
00:27:00.030 --> 00:27:04.290
You devote a portion of your book on meetings,
which I found fascinating.

429
00:27:04.291 --> 00:27:08.520
So if I work an eight hour day,
yes,
it feels like I spent 10 hours a day.

430
00:27:09.500 --> 00:27:12.270
So that's I think the culture that we have here at Google,

431
00:27:12.271 --> 00:27:17.250
but gave some tangible,
and
you're very optimistic.

432
00:27:17.310 --> 00:27:21.180
I will say I have throughout your book,
which made it a pleasure to read.
Um,
uh,

433
00:27:21.181 --> 00:27:25.410
but I think that the,
uh,
title of this section of your book was,
um,

434
00:27:25.830 --> 00:27:30.240
meetings,
present opportunities.
That was great.
So,
um,

435
00:27:30.241 --> 00:27:35.241
if you think about meetings is opportunities to be inclusive and to check your

436
00:27:35.341 --> 00:27:36.990
unconscious bias,
what are the,

437
00:27:37.110 --> 00:27:40.380
what are the tangible pieces of advice you would have for all of us who are

438
00:27:40.381 --> 00:27:41.110
spending?
Yeah,

439
00:27:41.110 --> 00:27:45.790
<v 1>yeah,
absolutely.
Thank you.
Um,
for,
for letting me share that.</v>

440
00:27:45.791 --> 00:27:46.810
The uh,

441
00:27:46.900 --> 00:27:49.960
the October fest conference room that we were in before you walked in here,

442
00:27:49.961 --> 00:27:51.400
I noticed had an

443
00:27:52.990 --> 00:27:56.020
run inclusive meetings placard up there,

444
00:27:56.021 --> 00:27:59.650
which was fascinating and it mirrored some of the ideas in the book.

445
00:27:59.920 --> 00:28:04.300
So Tony Prophet is the chief quality officer@salesforce.com and I interviewed

446
00:28:04.301 --> 00:28:08.260
him for the book and you know,
when you have a title like chief quality officer,

447
00:28:08.261 --> 00:28:11.890
I thought,
Oh okay,
let's find out what the chief quality officer recommends.

448
00:28:11.891 --> 00:28:16.891
And I'm expecting some really like big plans and I'm sure Tony has big plans.

449
00:28:17.531 --> 00:28:20.950
I'm not in any way suggesting he doesn't.

450
00:28:20.951 --> 00:28:25.951
But what struck me is what his first answer was to my question of what do you

451
00:28:26.141 --> 00:28:27.310
think is most important?

452
00:28:27.311 --> 00:28:31.840
He said run better meetings and like run better meetings.

453
00:28:31.841 --> 00:28:33.880
I mean everyone knows meeting suck.

454
00:28:33.881 --> 00:28:38.160
Like what she's like sort of like part of organizational life.

455
00:28:38.540 --> 00:28:43.330
Um,
and he said no,
he said your meetings mirror your organization,

456
00:28:43.570 --> 00:28:47.830
whatever the headwinds and tailwinds are in your organization are happening in

457
00:28:47.831 --> 00:28:51.580
your meetings,
but your meetings are a little easier to like,

458
00:28:51.880 --> 00:28:54.550
you can get a grip on that.
You can start somewhere.

459
00:28:54.551 --> 00:28:57.760
You can think about who should be in the room and who isn't in the room,

460
00:28:57.761 --> 00:29:02.410
who should be,
you can think about are we balancing airtime?
I mean,

461
00:29:02.411 --> 00:29:06.220
that's like a measurable thing you can think about.
Uh,

462
00:29:06.250 --> 00:29:10.330
did we interrupt people or not?
You can think about,
uh,

463
00:29:10.750 --> 00:29:15.340
did we create an environment in which people disagreed with each other or did we

464
00:29:15.460 --> 00:29:18.580
have a meeting which I,
I use when I,

465
00:29:18.640 --> 00:29:22.870
when I teach about meetings to my students,
um,
in our managerial skills class,

466
00:29:22.871 --> 00:29:27.871
I call it the most precious real estate that we treat meetings like it was,

467
00:29:28.811 --> 00:29:32.590
it's some little piece of desert land and a in a,

468
00:29:32.591 --> 00:29:35.790
in an area that nobody wants that land,
that there's,
they're,

469
00:29:35.800 --> 00:29:39.100
they're paying you to take that land.
That's how we treat meetings.

470
00:29:39.101 --> 00:29:42.870
We just throw them together.
Not here.
I mean like other companies.
Um,

471
00:29:43.980 --> 00:29:48.790
but but the truth is meetings are like fifth avenue real estate.

472
00:29:48.850 --> 00:29:52.690
You getting multiple people in the room at the same time thinking about the same

473
00:29:52.691 --> 00:29:57.010
thing.
That's fifth avenue real estate and that's how we should treat it.

474
00:29:57.011 --> 00:30:00.970
That's the end.
You wouldn't just throw any old thing on fifth avenue,
right?

475
00:30:00.971 --> 00:30:04.990
You would really put a lot of thought into designing it and that's in fact what

476
00:30:04.991 --> 00:30:09.850
we do want to do in meetings is put that level of thought into it and if you're

477
00:30:09.851 --> 00:30:12.340
going to put that level of thought into it and if you're going to use that level

478
00:30:12.341 --> 00:30:13.390
of precious real estate,

479
00:30:13.570 --> 00:30:16.480
what is the point of having a meeting where everyone agrees with each other?

480
00:30:17.350 --> 00:30:21.700
Like did you actually need the meeting for everyone to agree with each other or

481
00:30:21.701 --> 00:30:25.540
could you have just agreed to agree and not have the meeting?

482
00:30:25.960 --> 00:30:30.340
So if you're not running a meeting where there's room for disagreement,

483
00:30:30.370 --> 00:30:32.830
then the question is why did you have the meeting?

484
00:30:33.220 --> 00:30:38.110
Some of the benefits of diversity and inclusion are a range of perspectives are

485
00:30:38.111 --> 00:30:42.180
a range of opinions.
Is this a meeting where you can actually do that?

486
00:30:42.970 --> 00:30:47.890
<v 0>One of the dynamics that we know can happen in meetings is that,</v>

487
00:30:48.190 --> 00:30:48.940
uh,

488
00:30:48.940 --> 00:30:53.770
people who you would not expect to have a legitimate point of view on any

489
00:30:53.771 --> 00:30:56.470
particular topic are marginalized.

490
00:30:56.910 --> 00:31:01.300
So you can have wonderful things being expressed that are simply not heard.
And,

491
00:31:01.330 --> 00:31:03.580
uh,
in the Book You Talk About Your Dissertation Research,

492
00:31:03.581 --> 00:31:07.120
which actually I demonstrated in a really profound way,

493
00:31:07.121 --> 00:31:10.660
I thought with some like actual statistics behind it.
Can you tell us?
Yeah.

494
00:31:10.700 --> 00:31:12.550
That was that research.
And what did you find?

495
00:31:13.500 --> 00:31:18.300
<v 1>Yeah,
that that takes us back.
Um,
so in my dissertation,
here's what I did.</v>

496
00:31:18.930 --> 00:31:23.190
I,
I asked people to like be in a game show,
but it wasn't really a game show.

497
00:31:23.191 --> 00:31:26.610
It's just me and my laptop walking around south station in Boston asking

498
00:31:26.611 --> 00:31:28.200
strangers to play this game with me.

499
00:31:29.670 --> 00:31:33.270
There were different times you could do that.
Um,
so,

500
00:31:33.330 --> 00:31:36.150
so the game I would ask him to play is I would say,
Hey,

501
00:31:37.070 --> 00:31:41.220
I'm going to show you photographs and I want you to guess how many jelly beans

502
00:31:41.221 --> 00:31:44.160
are in the jar,
how much this huge piece of machinery,
ways,

503
00:31:44.161 --> 00:31:48.090
like questions that would be kind of hard to know the answer to without some

504
00:31:48.091 --> 00:31:49.110
special knowledge.

505
00:31:49.590 --> 00:31:54.120
And I'm going to pay you for how well you guess the closer you get,

506
00:31:54.121 --> 00:31:56.700
the better you do.
But it's going to be like,

507
00:31:56.701 --> 00:32:00.200
I forget which game show was the Hollywood squares.
It does this where you,
uh,

508
00:32:00.360 --> 00:32:04.290
you first get to gas and then you get to listen to someone else's point of view

509
00:32:04.291 --> 00:32:07.050
and then you get to revise your guests.
So the question is,

510
00:32:07.051 --> 00:32:10.170
do you use the advice that someone else gives you or not?

511
00:32:10.980 --> 00:32:15.030
And um,
the thing I vary,
the questions were the same for everybody,

512
00:32:15.031 --> 00:32:17.700
but the thing I varied is whose advice they heard.

513
00:32:17.710 --> 00:32:19.950
And they would just listen to it and little headphones.

514
00:32:20.490 --> 00:32:25.170
And so the advice might be someone with a Hispanic accent,

515
00:32:25.500 --> 00:32:28.080
it might be someone with a white sounding.

516
00:32:28.081 --> 00:32:31.020
I realize those are not mutually exclusive but white sounding accent.

517
00:32:31.320 --> 00:32:35.460
It might be someone who sounds African American,
male,
female,

518
00:32:35.461 --> 00:32:39.030
like she had a bunch of different voices and um,

519
00:32:39.110 --> 00:32:42.950
of course I rigged the whole thing so that all the advice was a hundred percent

520
00:32:42.951 --> 00:32:43.731
correct.
Right?

521
00:32:43.731 --> 00:32:48.530
So everybody heard the correct answers and it was just a matter of,
you know,

522
00:32:48.531 --> 00:32:52.040
whether you trusted the advice from this unknown voice.

523
00:32:52.640 --> 00:32:57.590
And what I found was I called it a stereotype tax that the people for example,

524
00:32:57.591 --> 00:33:02.591
who had a female advisor in their ear or less likely to take that advice,

525
00:33:02.601 --> 00:33:07.601
I think they made 669 cents on the dollar for people who had a male advisor

526
00:33:08.390 --> 00:33:12.860
because they were so much less likely to take the advice of the female advisor.

527
00:33:13.370 --> 00:33:13.911
And I,
you know,

528
00:33:13.911 --> 00:33:18.350
I tried to standardize a whole bunch of things like the tone of the voice and

529
00:33:18.351 --> 00:33:21.350
like everything that would sort of make something sound different other than

530
00:33:21.351 --> 00:33:26.000
just the gender.
Um,
and so my dissertation,

531
00:33:26.270 --> 00:33:30.530
the idea there was to show even in these really fluid moments like in meetings

532
00:33:30.531 --> 00:33:31.161
for example,

533
00:33:31.161 --> 00:33:34.970
when somebody throws an idea out and we have to make that split second of do we

534
00:33:34.971 --> 00:33:37.220
keep going with it or do we,
you know,

535
00:33:37.221 --> 00:33:40.400
move on those little quick moments.

536
00:33:40.401 --> 00:33:42.650
We are potentially discounting

537
00:33:42.890 --> 00:33:46.850
<v 0>points of view and I know it can be difficult to counteract that.</v>

538
00:33:46.851 --> 00:33:48.110
If there were an easy solution,

539
00:33:48.111 --> 00:33:51.050
we would implement it right now and have meetings would be amazing if you would

540
00:33:51.051 --> 00:33:55.570
take a all points of view into account that were good points of view.
Um,

541
00:33:57.870 --> 00:34:01.550
I had demonstrated problematic thinking right there.

542
00:34:02.720 --> 00:34:07.100
Uh,
but it,
it,
uh,
in your book you are prescriptive about things that we can do.

543
00:34:07.101 --> 00:34:12.101
One of the things that I noted was for if you walk into a setting and you have

544
00:34:14.061 --> 00:34:15.210
ordinary privilege,

545
00:34:15.211 --> 00:34:19.700
you are walking in with this stereotype that operates on your behalf and you are

546
00:34:19.701 --> 00:34:23.690
a person with a growth mindset.
Someone who is on the journey,
uh,

547
00:34:23.691 --> 00:34:28.220
to being a better person and you hear ideas using your ordinary privilege to

548
00:34:28.221 --> 00:34:30.500
stand up for someone else's idea.

549
00:34:30.501 --> 00:34:33.970
Was One way of amplifying any,

550
00:34:33.971 --> 00:34:37.570
any other tangible advice,
advice to help us,
uh,

551
00:34:37.700 --> 00:34:40.160
really hear good ideas.

552
00:34:40.270 --> 00:34:44.120
<v 1>Yeah.
I mean,
I also sometimes do the thought experiment in my head of,</v>

553
00:34:44.121 --> 00:34:47.440
of when I'm,
I can feel myself dismissing someone.

554
00:34:47.441 --> 00:34:51.310
I imagine that the same idea coming out of someone else.
Like,
you know,

555
00:34:52.150 --> 00:34:54.940
I'm not gonna say who,
but right now I'm picturing two colleagues in my mind,

556
00:34:54.941 --> 00:34:56.980
in my,
in my work world.

557
00:34:57.370 --> 00:35:02.140
And like if I take the idea out of one person's mouth and I put in another do,

558
00:35:02.170 --> 00:35:05.980
would I be listening more carefully or what I be tuning out in the meeting right

559
00:35:05.981 --> 00:35:08.590
now and,
and the truth is with the two people I have in mind,

560
00:35:08.591 --> 00:35:12.370
I might be tuning out less if it was coming from someone else.

561
00:35:12.700 --> 00:35:16.060
And so I think while it's hard to de bias the brain,

562
00:35:16.061 --> 00:35:20.800
it isn't so hard to do the noticing to actually just kind of put yourself in

563
00:35:20.801 --> 00:35:23.380
that counterfactual of what if,

564
00:35:24.690 --> 00:35:26.990
<v 0>um,
I'm gonna ask you another question,</v>

565
00:35:27.020 --> 00:35:30.860
but I will take audience questions in just a minute.
So if you have one,

566
00:35:30.890 --> 00:35:34.430
there are two mics and please make your way up there and you can ask you a

567
00:35:34.431 --> 00:35:37.280
question.
Um,
so uh,

568
00:35:38.670 --> 00:35:42.180
what you've described in your book is a process that we can all go through and

569
00:35:42.181 --> 00:35:45.450
many people are,
are engaged in that journey but many are not.

570
00:35:45.540 --> 00:35:48.450
And based on some research that you had reviewed,

571
00:35:48.510 --> 00:35:52.770
you sort of summed up three kinds of people that 2060 twenties,

572
00:35:52.830 --> 00:35:54.300
you've got the easy twenties.

573
00:35:54.301 --> 00:35:58.170
These are people who are intrinsically motivated to be unbiased,

574
00:35:58.200 --> 00:36:00.300
they're really working and you know,

575
00:36:00.301 --> 00:36:05.010
you can talk to them and you'll have a kindred spirit and then you've got sort

576
00:36:05.011 --> 00:36:08.820
of this middle 60 who's really nowhere.
Like they're silent,

577
00:36:09.480 --> 00:36:13.920
they're not really paying attention and these issues just have not surface for

578
00:36:13.921 --> 00:36:14.754
them yet.

579
00:36:14.850 --> 00:36:19.850
And then you've got this stuck 20 this is a 20% of people who are on really set

580
00:36:21.690 --> 00:36:26.520
and entrenched in their ideas.
They are not willing to listen or to change.

581
00:36:26.610 --> 00:36:30.390
And I think we all probably have some people like that in our lives.

582
00:36:30.930 --> 00:36:35.930
The thing that struck me about that is your advice for this stock 20 is you can

583
00:36:36.061 --> 00:36:38.790
choose to engage or not engage with them.
Um,

584
00:36:38.820 --> 00:36:40.830
it's important to make your points of view known,

585
00:36:40.860 --> 00:36:43.860
but don't expect necessarily that they're going to change along the way.

586
00:36:44.100 --> 00:36:44.933
It's sort of a,

587
00:36:45.100 --> 00:36:49.090
an agreement and that you come to with yourself and with them and workplace,

588
00:36:49.110 --> 00:36:54.110
that's problematic because let's presume that a portion of those 20% are working

589
00:36:54.211 --> 00:36:55.250
here with us.
Yeah.

590
00:36:55.410 --> 00:37:00.150
We are in an organization that is trying very hard to have bias free systems and

591
00:37:00.151 --> 00:37:03.750
processes to hold ourselves up to higher standards to make sure we all have

592
00:37:03.751 --> 00:37:05.850
growth mindsets.
Um,

593
00:37:06.210 --> 00:37:11.210
what advice do you have for organizations that have portions of these 20% in

594
00:37:11.701 --> 00:37:15.690
there?
Um,
and we want them to thrive and add value,

595
00:37:15.720 --> 00:37:20.720
but we also need them to be operating in a way that is living up to the cultural

596
00:37:20.791 --> 00:37:21.850
standard.
We're trying to set it.

597
00:37:21.920 --> 00:37:23.390
<v 1>Yeah,
absolutely.</v>

598
00:37:23.840 --> 00:37:27.230
So the 2060 20 rule can be applied to anything.

599
00:37:27.231 --> 00:37:30.810
It's not specific to bias.
In fact,
I learned it from um,

600
00:37:31.010 --> 00:37:35.660
organizational change consultant,
Susan and Nunzio who I used to work with.

601
00:37:36.620 --> 00:37:38.420
Academia is a second career.
Uh,

602
00:37:38.900 --> 00:37:41.930
consulting banking was first career and when I worked with her,

603
00:37:41.960 --> 00:37:46.220
she would use this as an approach to any cultural change in an organization.

604
00:37:46.670 --> 00:37:51.560
And,
um,
the,
the,
the 2060,
20,

605
00:37:51.620 --> 00:37:56.540
what it does is not say that we have to forget about the 20,
uh,

606
00:37:56.541 --> 00:37:57.530
the stuck 20.

607
00:37:57.830 --> 00:38:02.830
But it does say to be really careful of how you use your energy there because

608
00:38:03.380 --> 00:38:08.380
that stuck 20 tends to be vocal and the middle 60 tends to be quiet.

609
00:38:09.320 --> 00:38:14.320
And so what we can easily have happened is that all of our energy and focus goes

610
00:38:14.601 --> 00:38:15.710
to the stuck 20.

611
00:38:15.920 --> 00:38:20.210
And you find yourself in those arguments that nobody's listening to,

612
00:38:20.240 --> 00:38:22.550
but you're doubling down and they're doubling down.

613
00:38:23.060 --> 00:38:28.060
And the middle 60 is tuning out because this has gotten pretty boring.

614
00:38:28.640 --> 00:38:32.050
Um,
and you've missed the opportunity to,

615
00:38:32.460 --> 00:38:35.030
to either engage with the stuck 20.

616
00:38:35.590 --> 00:38:39.760
You have a hidden audience in the middle 60.
So if you're getting engaged here,

617
00:38:39.761 --> 00:38:44.320
at least know the middle 60 is listening or could be listening if you could be

618
00:38:44.321 --> 00:38:48.250
engaging.
So rather than it being a,
you're trying to convince this person,

619
00:38:48.460 --> 00:38:53.460
think of it as I'm trying to actually shape a larger groups perspective.

620
00:38:54.280 --> 00:38:57.980
And in doing that you are going to shift norms,
right?

621
00:38:57.990 --> 00:39:01.150
So when you move the middle 60,
which could go this way or could go this way,

622
00:39:01.330 --> 00:39:05.560
you're shaping the norms and those norms are going to do the work on your stock.

623
00:39:05.561 --> 00:39:08.560
20 norms are incredibly power,

624
00:39:08.620 --> 00:39:11.080
powerful shapers of behavior.

625
00:39:11.350 --> 00:39:15.910
And so you may not be able to convince the stock 20 but you are able to shape

626
00:39:15.911 --> 00:39:19.210
norms and influence the views of people around you.

627
00:39:19.630 --> 00:39:22.820
And that will do the work.
That's a powerful lever.

628
00:39:23.030 --> 00:39:25.270
<v 0>I found it,
uh,
amazing to,</v>

629
00:39:25.330 --> 00:39:30.330
to read about how you interact over social media with people who have contrarian

630
00:39:31.660 --> 00:39:36.660
points of view and you write that you will engage with them knowing that the 60%

631
00:39:36.911 --> 00:39:37.391
right,
you're reading.

632
00:39:37.391 --> 00:39:41.470
So you're really engaging them for the 60% and not with any expectation of

633
00:39:41.471 --> 00:39:42.304
changing the person.
Yeah,

634
00:39:42.550 --> 00:39:44.320
<v 1>exactly.
So I don't,
I don't,</v>

635
00:39:44.620 --> 00:39:48.640
I know when I'm not going to get anywhere in one of those social media things

636
00:39:48.641 --> 00:39:51.160
that we all find ourselves in.
Um,

637
00:39:51.250 --> 00:39:55.530
but what I do do is speak to the lurkers cause I know,
cause I learned too,

638
00:39:55.540 --> 00:40:00.100
I know there's a whole bunch of people lurking and like waiting for the fight to

639
00:40:00.101 --> 00:40:03.070
begin and instead of like going into the fight,

640
00:40:03.080 --> 00:40:07.480
now that I've got their attention,
I just use it as an opportunity to speak.

641
00:40:07.481 --> 00:40:11.200
And sometimes I literally just speak past the person arguing with me.
Like,

642
00:40:11.740 --> 00:40:13.630
I mean I'm respectful,
I'm always respectful,

643
00:40:13.631 --> 00:40:17.560
but I don't even worry about like getting into what they're saying.

644
00:40:17.590 --> 00:40:22.510
I just say what I wish the middle 60 new and use it as that,
that moment.

645
00:40:22.511 --> 00:40:27.220
Now that I've got this sort of the fight,
uh,
their attention on the fight.

646
00:40:27.520 --> 00:40:27.870
Yeah.

647
00:40:27.870 --> 00:40:31.980
<v 0>There was a powerful moment,
uh,
in your interview with Joe McNeil.
Yeah.</v>

648
00:40:32.130 --> 00:40:36.120
And you had asked him whether in hindsight he would have done anything

649
00:40:36.121 --> 00:40:38.520
differently when you were sitting at that counter at Woolworth's.

650
00:40:38.660 --> 00:40:42.980
<v 1>Yeah,
exactly.
Joe McNeil,
Greensboro for who we talked about earlier.
He said,</v>

651
00:40:43.380 --> 00:40:48.140
first I asked him,
would you have done anything differently?
Looking back?

652
00:40:48.141 --> 00:40:52.220
He's in his mid seventies now and me first.
He's like,
no,
I think,

653
00:40:52.430 --> 00:40:54.170
I think we did it right.
You know,

654
00:40:54.171 --> 00:40:58.640
and then he kind of took a sip of his coffee and he said,
you know,

655
00:40:59.210 --> 00:41:00.350
you know what I would've done,

656
00:41:00.680 --> 00:41:04.580
I would've spoken more to the people who were silent.

657
00:41:04.581 --> 00:41:06.290
Basically he was saying the middle 60,

658
00:41:06.950 --> 00:41:09.530
I would have given them a chance to be a better person too.

659
00:41:10.340 --> 00:41:11.420
That's what I would've done.

660
00:41:12.110 --> 00:41:16.790
And I just thought that was such a powerful insight from somebody who was really

661
00:41:16.791 --> 00:41:21.330
on the front lines,
risking everything has life,
everything.
Um,

662
00:41:21.770 --> 00:41:24.770
any questions from any of you?

663
00:41:28.660 --> 00:41:31.090
All right,
I've got more.
Good.
Huh.

664
00:41:31.370 --> 00:41:35.860
<v 0>So I,
the growth mindset that you described in the book,
uh,</v>

665
00:41:36.650 --> 00:41:41.030
will lead us to ask a lot more questions than we're probably asking today.

666
00:41:41.530 --> 00:41:42.140
Um,

667
00:41:42.140 --> 00:41:46.550
it will lead us to take seriously the things that people tell us that we may

668
00:41:46.551 --> 00:41:48.980
have dismissed.
Our old self may have dismissed,

669
00:41:48.981 --> 00:41:52.580
but the new self is actually reflecting on it,

670
00:41:52.850 --> 00:41:55.230
see if there's some truth to it.
Um,

671
00:41:55.490 --> 00:41:58.760
in the process of having this growth mindset and being on this journey,

672
00:41:59.330 --> 00:42:03.620
you're asking the people who may be most disadvantaged,

673
00:42:03.680 --> 00:42:05.620
most marginalized,
um,

674
00:42:05.810 --> 00:42:10.250
the ones who are the negative recipients of the unconscious bias and do a lot of

675
00:42:10.251 --> 00:42:12.890
educating and engaging.
Right?
Is that fair?

676
00:42:13.710 --> 00:42:17.790
<v 1>I don't want to put that burden of education.
Um,</v>

677
00:42:17.820 --> 00:42:21.330
so this is where those of us who have ordinary privilege,

678
00:42:21.331 --> 00:42:23.070
ordinary pillages a piece of your identity,

679
00:42:23.071 --> 00:42:27.810
you think least about we all have multiple facets or identity.
Um,
street.

680
00:42:27.900 --> 00:42:30.930
I can go weeks and months without thinking amount of fact that I'm straight.

681
00:42:30.980 --> 00:42:33.970
It's the whole,
the world is set up for me,
right?

682
00:42:34.070 --> 00:42:37.530
Someone asked what I did this weekend,
it's easy to just share my,

683
00:42:37.590 --> 00:42:39.480
my husband and I did this or whatever.

684
00:42:39.720 --> 00:42:44.720
I can put pictures of my family and I don't worry about being a panelized in

685
00:42:45.001 --> 00:42:46.100
some conscious or unconscious wait.

686
00:42:46.110 --> 00:42:49.710
Work ordinary pillar does a piece of your identity you think least about cause

687
00:42:49.711 --> 00:42:51.240
that's where you have the tailwinds.

688
00:42:51.570 --> 00:42:55.530
And that's also where you have surprising influence.

689
00:42:55.560 --> 00:43:00.000
And so studies show that let's say a black person says something about a racist

690
00:43:00.001 --> 00:43:03.270
joke versus a white person saying something about the same racist joke.

691
00:43:03.630 --> 00:43:06.120
The black person is perceived as being whiny,

692
00:43:06.240 --> 00:43:09.150
whereas the white person will have more influence and make spec.

693
00:43:09.151 --> 00:43:12.030
They're going to have in that moment and there's been multiple studies that have

694
00:43:12.031 --> 00:43:16.260
basically shown that same pattern that in the piece of your identity where you

695
00:43:16.261 --> 00:43:19.200
have ordinary privilege,
you also,

696
00:43:19.230 --> 00:43:22.230
what ordinary privilege brings is unexpected influence.

697
00:43:22.260 --> 00:43:26.850
And so this is where we were.
So many of us feel helpless right now.

698
00:43:27.180 --> 00:43:31.980
We actually have a reason to be optimistic that we have more influence than we

699
00:43:31.981 --> 00:43:35.700
realize not to speak over or for someone else,

700
00:43:36.210 --> 00:43:41.210
but to take some ownership so that the same people aren't doing the same work.

701
00:43:41.250 --> 00:43:44.070
Educating others time and time again.

702
00:43:45.090 --> 00:43:48.090
The other thing I really liked is I interviewed Subha Barry,

703
00:43:48.091 --> 00:43:52.950
who's held a number of senior roles in financial services and is now I think the

704
00:43:52.951 --> 00:43:57.900
president of working mother media and she's kind of been fighting a bunch of

705
00:43:57.901 --> 00:43:59.220
fights for decades,

706
00:43:59.221 --> 00:44:03.810
trying to create more equity and equality in organizations.

707
00:44:04.110 --> 00:44:06.990
And I asked her how she sustains herself in that.

708
00:44:07.020 --> 00:44:12.000
And She described flipping channels on the TV once and running across this

709
00:44:12.001 --> 00:44:14.490
national geographic special about birds.

710
00:44:14.880 --> 00:44:18.400
And it was all about the v formation that some birds fly in.

711
00:44:18.410 --> 00:44:21.360
Do you ever notice that?
And what she didn't know,

712
00:44:21.361 --> 00:44:22.920
and I didn't know until she told me,

713
00:44:22.921 --> 00:44:27.180
is that when you see that v formation in the sky and it looks like it's just

714
00:44:27.181 --> 00:44:28.020
static,

715
00:44:28.030 --> 00:44:32.820
the same birds that what's actually happening as the lead rotates to the back,

716
00:44:32.880 --> 00:44:35.370
that there's this constant rotation.

717
00:44:35.760 --> 00:44:39.690
And that's because the lead bird is the one who's taking the headwinds right

718
00:44:39.691 --> 00:44:43.050
time.
That's the hardest job to break the wind up front.

719
00:44:43.620 --> 00:44:45.420
And so most exhausting.

720
00:44:45.450 --> 00:44:50.400
So the way the birds are able to sustain this is by not always having the same

721
00:44:50.430 --> 00:44:51.300
lead bird.

722
00:44:51.630 --> 00:44:55.570
And I think that's another piece of this is when in the areas in which we have

723
00:44:55.571 --> 00:44:59.610
ordinary privilege,
how can we step into that lead bird role?
Again,

724
00:44:59.611 --> 00:45:01.530
not speaking over four people,

725
00:45:01.830 --> 00:45:06.120
but taking some ownership for trying to create the kind of environment,
culture,

726
00:45:06.121 --> 00:45:10.870
workplace that we value.
Oh,
hi,

727
00:45:10.871 --> 00:45:12.790
professor.
Hey,

728
00:45:13.550 --> 00:45:16.940
<v 3>um,
so in your amazing class at Stern,</v>

729
00:45:17.210 --> 00:45:19.820
you taught us that there were a lot of different types of cultures that could be

730
00:45:19.821 --> 00:45:21.140
successful.
Um,

731
00:45:21.260 --> 00:45:25.310
but building off the conversation about bias in hiring practices,

732
00:45:25.550 --> 00:45:26.870
how do you,
um,

733
00:45:26.930 --> 00:45:31.930
have a hiring practice that gets the right person for culture without sort of

734
00:45:32.570 --> 00:45:36.600
culture fit being synonymous for some sort of implicit bias in that?

735
00:45:36.730 --> 00:45:41.410
<v 1>Yeah,
absolutely.
So we think it's a matter of thinking about where,
um,</v>

736
00:45:41.770 --> 00:45:45.880
what it is about that cultural fit that's going to enhance performance and

737
00:45:45.881 --> 00:45:49.530
actually getting into what the behavioral indicators are.
So if,

738
00:45:49.740 --> 00:45:52.120
if what's needed is it,

739
00:45:52.121 --> 00:45:55.600
we need to be able to spend long periods of time together without driving each

740
00:45:55.601 --> 00:45:56.680
other crazy.

741
00:45:56.890 --> 00:46:00.520
We can do that without necessarily having to have gone to the same cluster of

742
00:46:00.521 --> 00:46:03.760
colleges.
It's more a matter of maybe what you do and your um,

743
00:46:04.030 --> 00:46:07.990
your interviewing or hiring process is you actually screen for what is it like

744
00:46:07.991 --> 00:46:11.860
to spend time with this person or how do they react under stress as opposed to

745
00:46:11.861 --> 00:46:15.910
relying on the more informal banter that makes assumptions that just because we

746
00:46:15.911 --> 00:46:19.870
went to the same schools we would have the same comfort level and,

747
00:46:20.120 --> 00:46:23.020
and I realize it's not that explicit,
you know,
the processes.

748
00:46:23.021 --> 00:46:27.480
I was part of an advanced,
we were never that explicit that that's what we were,

749
00:46:27.490 --> 00:46:30.850
we were looking for the same schools,
but those sort of what we ended up doing.

750
00:46:31.690 --> 00:46:35.950
Thank you.
Thank you.
Nice to see you.
Hey.

751
00:46:36.070 --> 00:46:39.300
<v 4>Hi.
Thanks for coming here and having this conversation.
Thank you for having me.</v>

752
00:46:39.630 --> 00:46:43.260
I was wondering what your advice is for like when you make a mistake,

753
00:46:43.680 --> 00:46:46.380
particularly in the workplace,
like how,
how do you recover from that?

754
00:46:46.381 --> 00:46:47.700
How do you make sure you've

755
00:46:49.240 --> 00:46:51.720
repaired the harm that you've done and and like how does that work?

756
00:46:52.400 --> 00:46:53.050
<v 1>Absolutely.</v>

757
00:46:53.050 --> 00:46:57.940
So I think it's like an all other parts of our life when we have some sort of

758
00:46:57.941 --> 00:47:02.740
pho par or error that creates negative impact on others.

759
00:47:03.100 --> 00:47:07.540
The ways in which we know taking accountability works here too.

760
00:47:07.720 --> 00:47:12.280
So,
um,
you know,
we'll use an example.
It's not,

761
00:47:12.700 --> 00:47:17.380
I'm sorry you were offended by that,
right?
It's,

762
00:47:17.800 --> 00:47:20.080
I'm sorry that I did harm.

763
00:47:20.140 --> 00:47:24.670
I'm sorry for my error in judgment.
I'm sorry for my ignorance.

764
00:47:25.060 --> 00:47:30.060
And then where you can go with that is you can ask if the person is interested

765
00:47:30.341 --> 00:47:32.860
in educating you about the harm you've done,

766
00:47:33.250 --> 00:47:38.080
but you don't expect them to do it because that is putting labor on the other

767
00:47:38.081 --> 00:47:41.590
person to then go through,
not only have this harm been done,

768
00:47:41.591 --> 00:47:45.310
now it's my job to educate you about your blind spots and deal with all your

769
00:47:45.311 --> 00:47:48.730
emotional reactions and not offending you and all that sort of stuff.

770
00:47:49.060 --> 00:47:51.190
So I think it's first the apology,

771
00:47:51.220 --> 00:47:54.970
or is it you can make an invitation if the person's into it,
great.

772
00:47:55.000 --> 00:47:58.240
If they're not,
it's your job to go figure out how to educate yourself.

773
00:47:59.380 --> 00:48:03.940
<v 0>Thank you.
Thank you.
Uh,
in your book,
you read a bit about,
um,</v>

774
00:48:04.660 --> 00:48:09.100
uh,
events that traumatic events that have been happening in the United States,

775
00:48:09.101 --> 00:48:14.101
whether it's the shooting in Orlando at a gay nightclub or um,

776
00:48:15.250 --> 00:48:17.830
uh,
the police shootings that have happened.

777
00:48:17.831 --> 00:48:20.770
And we know people who are members of the communities that would have been

778
00:48:20.771 --> 00:48:25.771
affected and your profile a different people and how they've processed that or

779
00:48:25.871 --> 00:48:30.871
how they've provided support on what is a lesson that you learn from them and

780
00:48:31.510 --> 00:48:34.690
you would pass on to us.
Oh my gosh.

781
00:48:35.590 --> 00:48:39.610
So psychologists call this hidden grief that at any given moment,

782
00:48:40.720 --> 00:48:45.720
<v 1>pleading now one out of four of us is sitting here in this room with real hidden</v>

783
00:48:46.001 --> 00:48:49.420
grief,
whether it's the loss of a loved one,

784
00:48:49.450 --> 00:48:51.550
whether it's a traumatic event in your life,

785
00:48:51.880 --> 00:48:56.880
whether it's something happening in the news that feels very personal to you,

786
00:48:58.090 --> 00:49:00.190
that there is something,

787
00:49:00.280 --> 00:49:05.020
there's a lot of work you're doing just to hold it together at any given moment.

788
00:49:05.800 --> 00:49:10.570
And in what I read about and learned about with hidden grief and thinking about

789
00:49:10.571 --> 00:49:14.740
it in the context of national events and international events and how they

790
00:49:14.741 --> 00:49:19.300
affect,
for example,
my students.
So,
you know,
I teach at Nyu,

791
00:49:19.301 --> 00:49:23.530
I deal with students,
um,
on,
not on a daily basis,

792
00:49:23.531 --> 00:49:28.270
but like on,
on a flowing basis where I see them over the,
the,

793
00:49:28.271 --> 00:49:29.390
the,
the,
um,

794
00:49:29.410 --> 00:49:33.130
stretch of an entire semester and things happen in the world during that time.

795
00:49:33.670 --> 00:49:37.120
And it used to be that I kind of just,
I didn't know what to say.

796
00:49:37.120 --> 00:49:39.310
I'd say nothing and I have to confess it,

797
00:49:39.370 --> 00:49:42.010
there's still a portion of times when that's exactly what happens.

798
00:49:42.011 --> 00:49:46.900
But I think what I learned from the hidden grief research was just the noticing

799
00:49:46.901 --> 00:49:51.901
that someone's grief is there and the acknowledging that you see it,

800
00:49:52.391 --> 00:49:57.190
the bearing witness of it,
not inserting myself,
not making myself the savior,

801
00:49:57.191 --> 00:49:59.230
not cookie seeking,

802
00:49:59.231 --> 00:50:03.460
meaning a cookie seeking is like looking for their validation and how awesome it

803
00:50:03.461 --> 00:50:08.110
was that I checked in on them.
Um,
but just saying,
hey,

804
00:50:08.111 --> 00:50:09.070
how are you holding up?

805
00:50:09.071 --> 00:50:13.240
And that's actually a phrase that I learned from one of my former students.

806
00:50:13.270 --> 00:50:14.290
The how are you holding up?

807
00:50:14.950 --> 00:50:19.570
It allows the other person to go in any number of directions.
They can say,

808
00:50:19.630 --> 00:50:23.920
Oh my God,
I'm falling apart.
I need to tell you everything.
Or they can be like,

809
00:50:23.950 --> 00:50:25.990
oh,
you know,
good,
everything's great.
You know,

810
00:50:25.991 --> 00:50:30.290
like they can use that question to go as deep or as lightly as they want,

811
00:50:30.291 --> 00:50:35.020
but they know that they're seen.
And so I think,
um,

812
00:50:35.790 --> 00:50:36.171
they didn't,

813
00:50:36.171 --> 00:50:38.810
grief piece is one of the places where I'm trying to do the most work of

814
00:50:38.811 --> 00:50:43.811
figuring out how to not allow silence to look like indifference to others.

815
00:50:44.061 --> 00:50:46.760
And that is how it's often perceived in the workplace.

816
00:50:48.890 --> 00:50:49.420
Hi.

817
00:50:49.420 --> 00:50:52.630
<v 3>Hi there.
First of all,
I wanted to say,
Brian,
thank you so much.</v>

818
00:50:52.631 --> 00:50:54.460
You ran the I'm biasing video.

819
00:50:54.461 --> 00:50:58.480
I'm a noogler so I saw an hour and a half of them by a sane training and now I'm

820
00:50:58.481 --> 00:51:00.550
having a little Google crush.
You're doing a great job.

821
00:51:02.430 --> 00:51:04.730
Thank you for putting together these programs.
Um,

822
00:51:04.780 --> 00:51:09.780
I'm definitely brush at 20 slash 20% here in part because I want to be a better

823
00:51:10.960 --> 00:51:14.150
person and I want to be a better coworker.
Um,

824
00:51:14.200 --> 00:51:16.090
and I'm a sociologist,

825
00:51:16.091 --> 00:51:20.890
so I'm constantly thinking about the group and the systematic biases.

826
00:51:21.280 --> 00:51:25.540
And I think being at Google has really challenged me to see where I fit at the

827
00:51:25.541 --> 00:51:29.680
individual level and really like what's going on there.
And you said,
ah,
you know,

828
00:51:29.681 --> 00:51:34.390
changing the unconscious biases in our brain is really hard.
Um,

829
00:51:34.391 --> 00:51:37.660
and then you kind of move on and I want to open that up a little bit.

830
00:51:38.020 --> 00:51:43.020
What is it that I could do or anybody could do to really push ourselves to find

831
00:51:44.231 --> 00:51:49.060
the blind spots?
Because naturally our brain doesn't want to find them.
Um,

832
00:51:49.090 --> 00:51:53.610
how do we push ourselves to become more comfortable with these truths that maybe

833
00:51:53.680 --> 00:51:55.600
we didn't want to acknowledge before?
What,
you know,

834
00:51:55.601 --> 00:51:58.180
are there exercises or they're great podcasts?
I mean,

835
00:51:58.181 --> 00:52:00.480
where would we start to unpack?
Well,
that might be,
I don't know.

836
00:52:00.830 --> 00:52:02.100
You only thought Sarah would be.
Yeah,

837
00:52:02.350 --> 00:52:06.550
<v 1>absolutely.
Thank you.
Um,
so you may have already done this,</v>

838
00:52:06.551 --> 00:52:08.470
but I'll just throw out ideas for Fairview.

839
00:52:08.680 --> 00:52:13.180
So there's the implicit association test,
which is called the IAT.

840
00:52:13.340 --> 00:52:16.670
It would,
they have done that through the training.
Okay.

841
00:52:17.320 --> 00:52:21.340
So implicit.harvard.edu is the site where you can find it.

842
00:52:21.770 --> 00:52:23.410
You can do it completely anonymously.

843
00:52:23.411 --> 00:52:27.520
It's about a 10 minute test on the Internet.
It is not a perfect test.
It is.

844
00:52:27.670 --> 00:52:32.590
It is,
uh,
an in progress scientific method that we are trying to improve.

845
00:52:32.620 --> 00:52:35.010
We meaning we the field.
Um,

846
00:52:35.140 --> 00:52:38.860
but it will give you a sense of where your blind spots are.

847
00:52:38.861 --> 00:52:43.030
You can pick different topics.
There's at least 20 tests up there,
race,
gender,

848
00:52:43.031 --> 00:52:47.470
skin tone,
physical ability.
It goes on and on.
Sexual orientation,
religion.

849
00:52:47.950 --> 00:52:50.920
Um,
so that's one place to start.
The second thing you can do,

850
00:52:50.921 --> 00:52:54.610
there's a great story in the book about Rick Clough who some of you may know at

851
00:52:54.611 --> 00:52:58.240
Google ventures,
um,
who I met at the same conference.

852
00:52:58.240 --> 00:53:02.040
I met you at Brian at the rework conference a few years ago,
uh,

853
00:53:02.080 --> 00:53:06.080
ago when you wrote in the book that there was that moment of awkwardness or

854
00:53:06.140 --> 00:53:10.660
trying to get your taxi back.
It made me feel bad.
It made you feel bad.

855
00:53:10.661 --> 00:53:11.560
I was like,
Dolly,

856
00:53:11.561 --> 00:53:16.561
I'm so glad you didn't get your attack saying like they had the open dinner for

857
00:53:16.571 --> 00:53:17.740
the conference and you know,

858
00:53:17.741 --> 00:53:22.600
when you arrive at something and like there's going to be that networking thing

859
00:53:22.630 --> 00:53:24.630
and you get there and like for,

860
00:53:24.631 --> 00:53:28.290
there's that where you have nobody to talk to and you're just standing there and

861
00:53:28.291 --> 00:53:30.960
I just like want it to run and get my taxi back.
Um,

862
00:53:31.030 --> 00:53:33.630
and I could still see it like sort of out of the corner of my eye.

863
00:53:33.631 --> 00:53:38.570
And then Rick Clough has saved the day and said,
hi,
I'm Greg.
Yeah.

864
00:53:38.910 --> 00:53:39.870
So,
um,

865
00:53:39.900 --> 00:53:43.560
so I ended up having what we would have been a small talky conversation at the

866
00:53:43.561 --> 00:53:48.120
entrance of what was a fantastic conference in every way,
um,
with Rick Clough.

867
00:53:48.120 --> 00:53:51.930
And when did things he talked about was after he took the IAT,

868
00:53:52.200 --> 00:53:56.660
he got a gender result that he wasn't happy with and didn't match his perception

869
00:53:56.661 --> 00:53:58.160
of some self.
Um,

870
00:53:58.230 --> 00:54:01.770
as I'm putting this in quotes because he cringes every time I say it,

871
00:54:01.771 --> 00:54:06.120
but like as one of the good guys,
meaning someone who hires women,
promotes women,

872
00:54:06.390 --> 00:54:09.180
um,
creates opportunities for underrepresented groups.

873
00:54:09.600 --> 00:54:13.740
He really saw himself as the current person who didn't need the unconscious bias

874
00:54:13.741 --> 00:54:17.070
training,
who didn't need to take the IAT.
And then when he got the result,

875
00:54:17.370 --> 00:54:21.240
he was taken aback and he thought,
well,
Huh.

876
00:54:22.110 --> 00:54:25.230
I don't know.
I don't think that's true.
And so we decided to start,

877
00:54:25.231 --> 00:54:29.370
he's very active on social media and I think in his particular role at Google

878
00:54:29.371 --> 00:54:29.791
ventures,

879
00:54:29.791 --> 00:54:33.900
social media is a really important part of the platform and influence he has.

880
00:54:34.380 --> 00:54:36.480
So he's like,
I don't know what they're talking about.

881
00:54:36.480 --> 00:54:40.830
And he starts going through and like running some algorithms on who he follows

882
00:54:41.100 --> 00:54:43.920
on Linkedin,
on Twitter,
who he retweets,

883
00:54:43.950 --> 00:54:48.570
who is connected with things like that.
And he kept getting that he was,

884
00:54:48.780 --> 00:54:49.613
uh,
his,

885
00:54:49.650 --> 00:54:54.650
his network was 80% male and this was not what he expected at all.

886
00:54:55.200 --> 00:54:57.540
And it was consistent across all the platforms.

887
00:54:57.541 --> 00:55:01.860
Then he started noticing on his calendar that he had been sitting on all male

888
00:55:01.861 --> 00:55:03.540
panels.
Again,

889
00:55:03.570 --> 00:55:07.950
an important place where his voice and platform have influence.

890
00:55:08.220 --> 00:55:11.910
And so he realized through this little self audit he did.

891
00:55:11.911 --> 00:55:14.880
And so that would be the second thing I would suggest is a self audit.

892
00:55:15.210 --> 00:55:19.380
In his case,
he felt like these net,
this network was an important place for you.

893
00:55:19.381 --> 00:55:20.214
It might be.

894
00:55:20.430 --> 00:55:24.390
Who are the last 10 people you had coffee chats with to network about Pete?

895
00:55:24.420 --> 00:55:27.630
I'm sure you all have friends who want to work at Google.
You know,

896
00:55:27.631 --> 00:55:31.410
who are the people that you're having those informal conversations with?

897
00:55:31.620 --> 00:55:36.240
If you're a big movie person or,
or,
um,
both person.

898
00:55:36.241 --> 00:55:39.480
What are the last 10 books or movies you consumed?

899
00:55:39.720 --> 00:55:43.860
How different were the voices and experiences and those books and movies from

900
00:55:43.861 --> 00:55:47.820
your own versus how similar were they to each other?
Um,

901
00:55:48.120 --> 00:55:50.370
what associations are you?

902
00:55:50.400 --> 00:55:54.540
We're not just dealing with our implicit associations that we've built over our

903
00:55:54.541 --> 00:55:57.150
lives until now.
We're creating new ones right now.

904
00:55:57.151 --> 00:56:01.620
Which ones are you creating right now?
Those are things we can actively change.

905
00:56:01.621 --> 00:56:05.160
You can change who's in your network,
you can change what you're consuming,

906
00:56:05.161 --> 00:56:08.160
what you're feeding your brain with.
Um,
I think that's like,

907
00:56:08.161 --> 00:56:11.540
those are immediate steps we can take where we don't have to do the,

908
00:56:11.830 --> 00:56:14.820
the bigger work of systemic change.

909
00:56:16.050 --> 00:56:20.520
Thank you for your question.
All right,
we're coming at the end of time.
Uh,
Dolly,

910
00:56:20.730 --> 00:56:24.430
thank you so much for spending time with us today.
Uh,
as,

911
00:56:24.510 --> 00:56:28.030
<v 0>um,
our noogler mentioned,
we have an unconscious bias curriculum.</v>

912
00:56:28.330 --> 00:56:31.930
All new hires are invited to watch this video to learn about it.
And uh,

913
00:56:31.960 --> 00:56:36.340
we'll get emails every single week after the video goes out in the most common

914
00:56:36.341 --> 00:56:40.210
email is I want to learn more and I want to know what I can do.

915
00:56:40.680 --> 00:56:42.490
And from this point forward,
I'm going to say,

916
00:56:42.850 --> 00:56:45.760
read your book because there a lot of practical advice there.

917
00:56:45.761 --> 00:56:48.620
So thank you for [inaudible].

918
00:56:49.310 --> 00:56:49.940
<v 2>Thank you so much.</v>

