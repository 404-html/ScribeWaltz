Speaker 1:          00:07          Yeah,

Speaker 2:          00:08          it's great to be here today. And, uh, it's a tremendous honor to get to chat with Jimmy Wales. So Jimmy, why don't you come on? Um, so

Speaker 1:          00:17          first of all, everybody knows [inaudible]

Speaker 2:          00:22          if you go on, if you go to Wikipedia, you'll notice that his, a drawing of him or a picture of him appears asking you to give money. So if you're one of the hundreds of millions of people who go to Wikipedia practically every day, um, you'll know his face. This is him. It's not like Colonel Sanders. He actually exists. Uh, so just by a little bit of background. So Jamie started Wikipedia in 2001, uh, he launched with Kia in 2004, which is much more focused on entertainment and games and is one of the top 20 websites worldwide. And in 2015, he started the Wikipedia foundation and most recently this year he started something called Wiki Tribune with the goal to fight fake news. And, um, you described it as news by the people and for the people. And the first time that professional journalists and citizen journalists will work side by side. So, uh, let's go back. Let's rewind back to when you started. You've described, um, the initial group that helped you start Wikipedia is a, I'm quoting here, rag tag band of volunteers. If you can remember back, what was it like to start something that has become such a worldwide phenomenon?

Speaker 3:          01:47          Yeah, well, I mean this was in the very, very early days of Wikipedia. We were just a, you know, a really a small group of people. And, uh, you know, before Wikipedia had a project called new PDF, which has the same goal to have a free encyclopedia for everyone. But I didn't really understand online communities. I didn't have any idea about the concept of a Wiki. And so we organized a very top down system with [inaudible] as a review to get anything published. Uh, and that was a failure. It was a failure mainly because it was really intimidating for anybody to get involved. Um, and uh, we have the course of a year, uh, we had created about two dozen entries. Um, I joke, I still keep them by my bed and read them every night. I thought, we'll get my money's worth someday. What were, what were some of the, to do death.

Speaker 3:          02:40          They were just very eclectic. Uh, but I mean there were so few that and there were very academic and so forth. Um, and then, you know, really realized that that wasn't working and, uh, decided to pivot, although nobody called it pivot back then, but nobody should call it that anymore. Yeah, exactly. I'm about done with that word. Um, and launched the Wiki. Uh, and in two weeks we had as much work done as we had, uh, in, well it was actually nearly two years. So, uh, so that was the, the very beginning. And the truth is in the, in the very early days, I mean, the software was in no kind of state. Um, I had downloaded a used model Wiki, which was a pearl, um, script, very simple wiki package. Uh, it was so simple in fact that there were, there were no passwords. So you could create a user name, but you didn't have a password.

Speaker 3:          03:30          So anybody could pretend to be anybody, um, which clearly doesn't scale very well. Um, so one of the first things I did was sort of right, you know, a password, uh, sort of, uh, ability to have a password and uh, but still what was great about Wikis is, is the word Wiki. It comes from a Hawaiian word Wiki Wiki meaning quick, quick collaboration. Like people were able to just turn in because although we had been going for about two years and hadn't gotten much done, there were a lot of people who were super interested in super excited about this concept of a free encyclopedia for everyone. Um, and so we were able to pretty quickly move forward, but we were able to do it. I mean, there was no, like again, people didn't say minimal viable product back then. It was just like this crappy perl script and we were just in sort of doing stuff on a day to day basis to try and make it better.

Speaker 2:          04:21          When you take apart Wikipedia as you really founded an invented it, there's a couple of unique things. One of them is that practically, but anybody can post one of the others that that isn't so parent is this massive community of people who totally unpaid and a lot of cases totally anonymous who edit and make sure that every entry fits to really tip to you to Wikipedia standards.

Speaker 3:          04:55          Yeah, I mean I think there's a few elements of that that are really important to understand. So first of all, I, you know, the word community, a online community as much abused and oftentimes what people mean by that, it's just the general public. But for me, when I use the word community, it's people who actually know each other. Uh, and they're discussing and debating. They're actually making decisions. Uh, and so it, if your mental model of how Wikipedia works is 100 million people adding one sentence each and it magically becomes an encyclopedia, that isn't the case. It's really a core group of volunteers who enforced the rules, who decide what the rules are, um, who put into place organize procedures and processes to monitor things, to update things. Uh, just as one example is the concept of a wiki project. So one of my favorite wiki project is wiki project bridges. So this is a group of people who are really interested in bridges, the architecture, the history, and they go through all of Wikipedia and they find all the articles having easier

Speaker 2:          05:54          experts, interested amateurs.

Speaker 3:          05:56          Um, a mix actually. So I, one of the guys who I met who was one of the leaders of the Wiki project bridges is an architect. Um, but many of the people aren't, they're just interested hobbyists. Uh, and so they go through all these articles and they come up with checklists of, okay, what does a good bridge article look like? What does it mean to have included which ones don't have those elements and can we research and find that? And so there's a lot of that kind of work that goes on beneath the surface and it really is small groups who know each other, who say, okay, well we're going to take on this particular topic. Another fantastic one, a particularly strong in English. Wikipedia is wiki project medicine. Uh, and they are quite fearsome in there. Uh, demands that the rules be followed because the medical topics or, you know, people rely on it.

Speaker 3:          06:41          It's really important that I be, uh, are very, very careful about things that could mislead the public and so forth. So, uh, yeah. So, and why do people contribute? Is it you talked about a community of people that know each other. Is it a dedication to it? Is it prestige among the other people that they know in this community? So, so it's, uh, it's a couple of things. Um, so first of all, the vision of free encyclopedia for every single person on the planet in their own language is exciting. Uh, people think that's worth spending time on. So, you know, if you're someone you could have, you know, you could spend the weekend playing grand theft auto, uh, and then, you know, late Sunday night you realize you've just wasted two days of your life, uh, that you'll never get back and you haven't improved the world. Very productive.

Speaker 3:          07:30          Uh, or you can, you know, work on Wikipedia and whatever may come of it. You, you come away thinking, Hey, you know what? The world's a little bit better now than it was when I started. So that Grand Vision, uh, is important, but also it has to be fun. People have to find it interesting. You have to meet other Nice, interesting people who are, uh, you know, you're learning things and you're meeting people and you're having quality debates, uh, which is hard to come by on the Internet. There's plenty of places to have sort of raging flame wars, uh, but to actually have an interesting discussion or debate around the quality of sourcing around some particular topic, um, people enjoy that. And so it's gotta be both of those gotta be, you know, that, that we feel like we're doing something productive and we're also are enjoying it.

Speaker 3:          08:13          And so, yeah, it does have something to do with not prestige. So if you want to become a well known famous person, uh, on the Internet, I would recommend being a blogger or something like that. You know, uh, spend your time on social media. Uh, but so within the Wikipedia community though, we aren't particularly at anonymous with each other. People do know each other and people have respect and people don't know each other virtually, or do they actually know each other in person? Mostly virtually. But it depends. Uh, it actually, that depends very much on the language. So if you think about, uh, for example, uh, Lithuanian Wikipedia, virtually everyone who speaks Lithuanian lives within a train, right, of each other. Uh, and so they tend to have and they get together for a beer and they actually know each other pretty well. Uh, other languages like English of course, is spread all around the world. And so often has people talking to each other, but people do meet up, they meet up locally, uh, they meet up all over the world. We have our conferences and things like that.

Speaker 2:          09:09          Of course, one of the topics and putting aside the, the, the last election board and the topics overall is, is verifying information. And, uh, everybody's a aware of some of the famous Wikipedia hacks. So for example, uh, I used to run MTV networks and one of our companies is Nickelodeon and there was the Wikipedia page for both mnm and sponge. Bob said that m and m was the voice of Spongebob. Now I can assure you that was not the case or Steven called bear from comedy Central, um, convinced his audience to change Wikipedia to say that elephants were not endangered. What, what needs to happen to ensure that these entries, whether it's about popular culture or about medicine or about architecture, what happens to make sure that, that they're verified?

Speaker 3:          10:06          Yeah, just as an example. So they, uh, when Colburn made this joke on the air, literally within 30 seconds of him saying the joke, the page was locked, uh, because the Wikipedia is actually watched Kobe or two. So the Admin is just winning to lock the page immediately, uh, and vandalism. And then we had to cope with it for like three weeks as people kept trying to put it in. But we just kept the page lock. Um, I didn't have time. You mentioned the Eminem when I had not heard that one. I'm guessing that probably only lasted in, in Wikipedia for again, a few minutes. Um, I think I know why there's actually, I saw it on youtube. There's a, uh, spongebob and, uh, lose yourself mash up on youtube has like 4 million views. So that's probably where it came from. That probably became a meme and then people thought it was funny to, to have that.

Speaker 3:          10:58          Uh, so, and that sort of thing, it does happen. Uh, usually it's very, very short term. Uh, and you know, sometimes it isn't. Sometimes you can have vandalism in Wikipedia that lasts much longer than we would like, so it isn't perfect. Um, but the way it works that we have to have, you know, if you, again, if you have the model of Wikipedia is 100 million people all randomly putting stuff in, it would just be, that's all it would be is just nonsense. Um, but we have a whole bunch of different, uh, policies, procedures, uh, people become admins, they're elected by the community, and then, uh, they have the ability and admins are not like in most sites. So like if you're on youtube and you do something, it's the rules of youtube in your page gets taken, your video gets taken down and you're locked out.

Speaker 3:          11:45          You actually have no idea who did that. Somebody's mysterious, deepen, uh, Google somewhere. Did it. Whereas in our community that the admins are all members of the public, they're all volunteers and they monitor each other. And there's always debates about, oh, was this a valid block? Why don't you block this person? Uh, et Cetera, et cetera. So they're more like a police. Um, you know, they're not judge, jury and executioner. They have certain abilities to block. People are like pages, but they have to justify that. And there are ways that those decisions can be reviewed and overturned and so forth. So it's, it's like managing a good municipal government really. So we have 100 million,

Speaker 2:          12:22          uh, users of Wikipedia is how many people, I mean, this number, we, we, we want to know how many people are actually editing today.

Speaker 3:          12:31          Yeah. So if you, if you take a look at the number, so the, the, the best number we have right now is, uh, for the number of unique devices, the access Wikipedia and a month is about 1.4 billion. So that's a lot of people. It's not 1.4 billion people because probably most people in this room, for example, access Wikipedia in a month on at least two or three devices. But it's a huge audience. And then just to give the numbers for English Wikipedia, there's probably, um, about 70 to 80,000 people who make at least five minutes in a month, uh, and there's about 3000 people who make a at least a hundred edits in a month. So it's that 3000 who are the really active community who really oversee and manage things. And then there's lots of people who just add one thing, which then is reviewed by the community and so forth. It's pretty, pretty extraordinary. It's 3000. Yeah.

Speaker 2:          13:22          People who, who really make the really changed the world for the, for the rest of us you've talked about.

Speaker 3:          13:28          Got, you know, it's funny, I was, uh, a few years back, it just struck me. I was at Wiki mania as our annual conference and I had a dinner. I just, you know, my tray. I went and sat and I was, okay, look, here's the, the English arbitration committee. So this is the, like the Supreme Court of English, Wikipedia. Um, and we're having dinner and discussing this, that, and the other policy. And I left the table and I thought, you know, I get to meet a lot of important people, but this is probably some of the most powerful people in media in the world is the English, Wikipedia, arbitration committee. I mean, they make really big decisions and they're like a bunch of geeks and nobody, nobody stick. Nobody outside their community knows them. Not really. No. I mean, occasionally you'll get a news article about, uh, somebody who's had the most number of edits and that sort of thing. And oftentimes the people who, if you've had the most number of edits, oftentimes they're running a Bot. A, that's how you get up. Very high edit count is to spell checking or something like that. Not always. Um, and they're generally known in the community, but they aren't always necessarily the most influential or powerful within the company. They're just like really busy as the main thing. So in general, now nobody really knows who they are. I mean we do, but yeah.

Speaker 2:          14:40          But you've also talked a lot about AI machine learning. What role will that play in verifying information in the future? So,

Speaker 3:          14:52          I mean, what's interesting about this is sometimes people ask it this way, or when do you think AI will be able to write Wikipedia articles? And I say it's a very long time or, anyway, it's one of the highest human activities is to write a good Wikipedia entry is really quite a fan. I mean, once we're there, we're, we're at full general AI. It's the singularity and let's just hope they're nice to us. Um, and, but before that, um, I do think there's some interesting things. Uh, we have a partnership with the Jigsaw, uh, where we, uh, it's AI looking at edits and, and machine learning. I don't actually know very little about it except it's really cool. Um, so on Wikipedia, if you're logged in, you can go to recent changes in now you can filter the recent changes and you can save whatever filter and there's different things you can select.

Speaker 3:          15:38          So what I do, this is just my favorite way of filtering. I want to see edits that are very likely bad, that are likely in good faith by new users. So this is somebody new to the site. They've made an edit, which is probably bad, but it was probably made in good faith and it actually is pretty good at finding those. And then you what you do. Then the reason I picked those as, that's the kind of people that just go say hi, like, hi, thanks. You know, it looks like you're trying to do this. Uh, let's, you know, and, uh, that's kind of amazing. So being able to, I think what is interesting here is the idea of AI basically just, you know, raising the hand, raising the flag for a human to review something because it often gets it wrong. You wouldn't really want AI policing this sort of thing.

Speaker 3:          16:21          So it's assisted review, it's assisted review. Um, and I think that's very useful, uh, to, and I think this is an area we will pursue more in various ways. And Ai is a very broad term, but the idea of using much more algorithmic approaches to bring things to the attention of people, uh, that you're probably interested. So just as an example to, um, interest new editors, what we could do is notice what you're reading. And so if we see, okay, every day you're reading about World War II and we have over here on article that we have algorithmic signals is not very good. We could say, Hey, you've been reading a lot about World War II, would you like to help out? Here's an article that leads to improvement in recruitment. Yeah, exactly. Um, and, or if you're editing, you know, in an area, then we can say, oh, here's some similar things that you might want to edit that, that need help and that sort of thing.

Speaker 3:          17:10          And we've been very, very human about all that sort of thing. We don't have much in the way of algorithms to look at that sort of thing, but I think there's huge opportunities there. Um, and, and the great thing about assisted review or prompting people, it doesn't have to be perfect to be a lot better than nothing. Um, you know, if, if it, if we can start suggesting things to me that I should edit and I think half of them are useless and half of them are actually kind of interesting, that's better than suggesting zero to me. So how does the community feel about, um, AI did not feel that they should put some standard around the ta? Yeah, yeah. They're very, they're very, um, protective of, uh, of their turf in a certain way. But they're also very, these are, these are quite geeky people.

Speaker 3:          17:55          They're interested in technology. They're open to saying, yeah, there's a lot of stuff that humans aren't very good at that machine, like very tedious, boring stuff. If we can get that machines do that stuff and raise it to our attention, then our work is more effective. Because as I said in the beginning, one of the reasons people want to edit Wikipedia is at the end of an hour editing Wikipedia, if you feel like you did something useful, that's important. And so if I go to Wikipedia and I picked some obscure article and try to improve a couple of sentences, I'm never quite sure, is anybody even going to read that or whatever. But if you show me like, Oh, here's a popular article that is in poor state, okay, that I'll have an impact if I do that. So I think people like that sort of idea. Um,

Speaker 2:          18:35          let's shift gears. Let's talk about education itself. I have a personal experience. I have two 18 year olds, uh, uh, boy and girl, and they've gone through school. Um, and one is already in college and their entire time through school, their teachers have said, Wikipedia is not a source. You can't use Wikipedia. You have to go. And by the way, the first place that they go for anything is Wikipedia, but it's never disclosed. Um, and

Speaker 3:          19:04          you can tell kids, don't listen to rock and roll music, but we're well,

Speaker 2:          19:10          well past that, right? No, it's actually more important. It's what you, you, you protect your parents from doing, uh, and it's your responsibility. So, but coming back to what's, what is it that we could pedia and other organizations that are around information, what, what, what's their responsibility? What's the opportunity?

Speaker 3:          19:30          So for us, I mean, we, we feel a very heavy burden. Um, if we think about, uh, well 18 year olds, right? So Wikipedia is now 16 years old. So from the time they were learning to read Wikipedia existed, it's certainly in the last five years, a five to 10 years when they were old enough to start doing homework and looking online or following their own intellectual interests, whatever that might be, they go to Wikipedia. And so it's just part of the infrastructure of the world as far as their concern, which means we have a responsibility to make it as good as we possibly can. And when I say we, I include everyone in this room. I mean, this is a, it's a public resource. Um, and uh, but what, but it's important to, to know, we don't consider it to be a goal for Wikipedia, that we be sizable source.

Speaker 3:          20:20          Um, for 18 years old, uh, entering college any more than when I was at university, if I cited Botanica, that would have been considered ludicrous. That's something, you know, and encyclopedia, that's not the role they should play in the research process in secular media is the starting point, not the ending point. Particularly at the college level. It's like, Hey, if all you're going to do is look, read Wikipedia and write a paper, I mean, come on, this is ridiculous. Read Wikipedia to get oriented, but then go to the original sources and doing more interesting intellectual work. Now, of course, if a 13 year old writes something and adds a footnote and sites Wikipedia, I'm like, hey, you know, progress. At least they've written something and they put it in a footnote. That's okay at a certain age, but later on, I don't think that it's not something we aspire to. Um,

Speaker 2:          21:04          you know, said. Do you think Wikipedia or other organizations with Wikipedia have more of a role in education? I mean, education is a huge challenge for sure. Not, not every kid in this country is going to get to go to college. Uh, what, what, what, what can we could PD and other organizations do to, to solve our education problem?

Speaker 3:          21:24          Well, I mean, I think one of the things that's going on, if you look at the trends in formal education, so what percentage of people are going to college? That moves around a very little bit, but it's pretty stable and nothing dramatic is happening there. A few more people are going to college, a few lessons, certain places and certain things. But in general, that's a pretty well understood area. But what is completely changed in the last 10, 15 years is the amount of informal learning that people do that, you know, if, if you hear of directed self directed, uh, even just ordinary thing. So if you here, um, oh, I dunno, blah, blah blah, there's something going on called bitcoin. I don't really know what that is. Uh, you know, if it was 25 years ago, you would go, I don't know, I read this article in the paper.

Speaker 3:          22:12          I don't really get it now. People dig deep and we see this in our traffic. You know, people can dictate all the information's there. Um, and that's really important and it doesn't result in more degrees and so forth. But people can learn about anything they want to learn about very easily. And that is a huge impact on education. I do think there's a lot to think about. So for us, one of the biggest things that we are interested in is the growth of Wikipedia in the languages of the developing world. Because of course there are places in the world where people have very limited access to information. So what was the way I think about this is if you're an English speaker, one of the things is the solution to is just narrowing down a place to go to find basic information. So if I type Queen Victoria into Google, I'm going to get, I dunno, millions of pages, the number one, it's probably going to be Wikipedia.

Speaker 3:          23:04          That's probably what I wanted. I just wanted to get the basic story of Queen Victoria, her life and times. It's all there. And this is because we have a glut of information. But if you're a, you know, if you're speaking, um, a, an obscure language, uh, with only a million speakers and Africa in your language, there's going to be like the role of Wikipedia is, hey, it's the only source I have for Queen Victoria. Uh, it's the only place I can go for that information. And not yet in many cases, we're just really getting started in a lot of those languages. So there's a lot of work left to do, but it's interesting how that impact will be different, uh, because instead of being saying, oh, we've got a glut of information, let's summarize it in an encyclopedia article. Like we have no information. So let's share it with, uh, you know, people, uh, in this way.

Speaker 2:          23:50          Um, the, the nature of how people interact with the web is changing dramatically. And so we, everyone's aware of the voice interface, but the reality is the digital assistant, whether it's Alexa, Google assist or a well or okay Google or Siri, um, the, these are one of the ways in which people will access information. How will Wikipedia adapt to those new interfaces?

Speaker 3:          24:20          So, uh, it is very interesting. I mean, we are an important part of those interfaces already. Um, you know, if you ask Alexa a question, 99% of the time she's just going to read Wikipedia to you or get a fact from Wikipedia. Obviously Google relies a lot on Wikipedia for the knowledge graph. Uh, I don't actually use the Google assistant because I have Alexa at home. Uh, assume it's very similar, although I heard that if you ask Google a question, it says according to Wikipedia, thank you. Whereas Alexa just acts like she knows everything even though she's just reading it out of Wikipedia. So, uh, so there's that. I need to email Jeff and it's about that. But, um, but what's interesting for me to ask you the question, I don't know. I tried Siri, didn't understand what I was saying. So, so, uh, in any event, basically what we're, um, what's interesting to us about that is w and one of the areas that we, we do slightly worry about it, but we don't have firm evidence yet. One of the words we have is, and we're not a business, we're a charity, so we don't think much about business model and we've never been very good at thinking about business model. Um, we just are a group of people who are enjoying making this encyclopedia and we're really happy that everybody likes it. But realistically we do have to think about that. And so right now, uh, the way Wikipedia gets money to survive is you come to the website and there's a little banner. Um, very rarely, but yes,

Speaker 2:          25:48          you know, once a year you see your photo does very well.

Speaker 3:          25:52          Yeah, we haven't been using it in recent years. I'm very happy we found this ugly yellow banner that no one on Madison Avenue would think would work, but it works beautifully. Uh, and actually we are, we are more and more our fundraising is through the email campaign because our, our donors are very loyal and if you donate to Wikipedia a year later, you get a message from me, which I may or may not have actually written a that says, hey, it's been a year of time to cough up again. And, and it, and it gets a really good response. Um, but, and so that's a good, that's a good news. What we worry about is, I call it the, the, the, how old is Tom Cruise problem. So five years ago, 10 years ago, if you typed, how old is Tom cruise into Google? The first link was Wikipedia and you go there and you find out how old was Tom Cruise.

Speaker 3:          26:37          Now the first link is still Wikipedia, but up above that it tells you how we'll talk this because Google understands the much better Google read Wikipedia for one thing. And uh, and so we think, okay, well does that mean we're not seeing that traffic and does that mean we're not going to get the donations from people? So far we don't have any evidence of that. Uh, and in fact, because the knowledge graph does link to Wikipedia, I mean, we see a lot of traffic from that, so it hasn't yet heard us. But when we think then about a voice assistant, um, if people are just saying, uh, who is Tom Cruise? And you get three sentences from Wikipedia and people don't know you're concerned about attribution, concerned about attribution and epit even if there is attribution, are people going to donate? We don't know. So far so good.

Speaker 3:          27:17          But that is one thing and our view is again, the, the fundamental, you know, the Vision Statement for Wikipedia is imagine a world in which every single person on the planet has given free access to the sum of all human knowledge. That's what we're doing. And so in that front and the community's view on this sort of thing is it's fucking fantastic. Like amazing. We compete as part of the infrastructure of the world. All these new technologies are coming out. The knowledge that we've carefully stewarded and written is now helping people, you know, um, you know, when did Fred Astaire die? Right? You have that thought in your kitchen for two seconds. You can ask Alexa and she tells you amazing, right? We don't need to get paid for that. That's where a charity for, we want everybody to have access to knowledge. But there is a little bit of a question about, okay, how does our business model work if in 20 years, you know, as technology changes, we don't want to let Wikipedia get left behind.

Speaker 3:          28:12          So, but so far we're, I mean we're, we're doing great financially, so we always run in a very conservative way. Um, we asked for money, sometimes we were getting criticism, uh, from I think rather stupid press outlets who say, why is Wikipedia begging for money? They have 100 million in the bank. Um, and it's like, well, you know, our annual budget's about 70 million. So we have about 18 months reserve. That's considered to be a healthy level of reserves for a nonprofit. We're not apologetic about that. Um, but you know, every year we've been, last year, well, thanks to the president, um, it was not necessarily big fan of us, but who has motivated people to care about knowledge? Uh, in a roundabout way. Um, the day from the day after the election, we saw a massive increase in donations. Um, which was very heartwarming to see because, uh, you know, and, and we'll, we'll get onto fake news in a bit when we, when we're talking about a Wiki Tribune, but, um, but we've decided we are also raising an endowment fund, um, because we do think of ourselves not so much as a, I mean we're not a.com.

Speaker 3:          29:17          We're not a tech startup. We're a charity sharing knowledge and we try to think in the long run. And so one of the things we say is, look, while we're, while we're not in desperate financial situation, we should be thinking about the longterm future. So we've now got, we're raising a hundred million dollar endowment fund, um, and we're, I think we've got pledges for about 17 million so far. And it's really the first time that we've really tried to have more of a major donor campaign because the vast majority of the money for Wikipedia comes from those, you know, you see the banner and you give 20 bucks and you know, that's the vast majority of money. And we've never been really good at doing major donor stuff. But this is, we think this is an interesting product. You might call it for a major donor to site, don't just fund our annual budget.

Speaker 3:          30:01          Think about the future. We want, we keep PD and the idea of be to be safe in the long run. So we won't have this fund for any future emergencies or any future opportunities. And we've done it all the right way. We've got a separate board. So there's another layer of governance. So it's not just a big bank account for some future profligate CEO and so forth. So, so far so good. Um, I'm going to ask everybody for questions a little later, so please start thinking about them. But in the meantime, I'd like to welcome or eat cuts of health. Use Your, um, your cofounder of Wiki. Truebeam yes. So Ori, you were somewhere.

Speaker 1:          30:39          Okay.

Speaker 3:          30:41          Hi. So welcome. So what should we know about Wiki Tribune? Um, do, let's start. I'll have to let her start because I'm terrible about just, I could sit here and talk.

Speaker 4:          30:52          Uh, how many of you have heard of wicked driven? Oh, that's great. Okay. It's Google here. So, um, it's a new inventive, a news platform which evolves generally's him in a way that has never been done before by bringing together a Wiki based community of volunteers and hired professional journalist in an effort to create a collaborative new space and high quality open platform, which is genuinely community controlled and have the bay, the backbone of professional journalists. And so we practically, I attend the community volunteers and the hire journalists as equals and it is a wiki based platform so everyone can edit every article on our website.

Speaker 3:          31:35          So, um, but how do you ensure freedom of expression? And this is not just, this isn't just journalists, these are individuals who are today posting to social media. First of all, what do we need to protect them from? Yeah, so I think we ensure expression. Yeah. One thing I wanted to explain because there was a little error in the introduction in 2015, uh, I didn't set up the Wikipedia foundation. The Wikimedia foundation has been around for a long time. In 2015, I set up the Jimmy Wales, uh, Jimmy Lewis Foundation for freedom of expression, which is a nonprofit based in the UK. When what we do is we, we fight for mainly for social media users, so people who aren't covered. So reporters without borders does a fantastic job of working to a highlight cases of journalists being arrested. But a lot of times ordinary people who say something and get themselves arrested, a political speech to get a bit ignored.

Speaker 3:          32:28          And so we try to campaign for those people and so forth. And we'll re uh, is the CEO of the Jimmy Wales Foundation. Uh, and that's a separate piece of work, uh, from Wiki attribute, which is a project. Uh, Jimmy was foundation that, that what happened there, I went to Dubai, uh, to give a speech as I do. And when I landed they said, oh, congratulations. Uh, the leader of Dubai has decided to give you a half a million dollars as the knowledge award. Uh, and I was like, okay, fine. It sounds all right. But then I went back to my room and I was like, you know, I'm, I'm like super critical of Dubai on human rights issues, a freedom of expression and so forth, so I can't in good conscience take this money and buy a boat. Um, and so that was when I said, okay, I'm going to take the money, which is from a bad source in my opinion.

Speaker 3:          33:19          I don't want to give it back to him so he can, you know, hire more people to beat bloggers. Um, instead I'll use it to fight for freedom of expression. So that's when we started working together on that. Um, and so that's been great fun. Okay. So then explain Wiki Tribune please. All so we can Tribune. Uh, so we contribute and we just started this year, uh, or you get the basic concept of it. A little of the history. We, um, we decided to launch using a crowdfunding campaign. Uh, and I really am a big fan of crowd funding as you know, as a, as an entrepreneur starting something new. Um, I could have easily gone in and raise money in silicon valley to do it, but I don't know if the public is interested. Do they want this? And so saying to people, Hey, will you sign up to contribute?

Speaker 3:          34:03          Uh, and the business model is, um, we, we asked people to become monthly supporters. Uh, we have no paywall and no advertising. So a series of bad business decisions, but it's how I built my career so far. Um, and, uh, but I didn't know. I'm like, well, that even work when people would be interested. So we did a crowdfunding campaign, not on Kickstarter or anywhere like that. We just did it sort of independently. Um, and we've got a great, you know, I said, look, I need enough money to hard 10 journalists, uh, had some tech people. And so we managed to do that. Uh, we also got a, a lovely grant from Google, Google Digital News Initiative in Europe, uh, to develop the software. Uh, we've got, we're using, we're taking wordpress as a platform and turning it into a Wiki. And it, as it turns out, wordpress doesn't want to be a Wiki a.

Speaker 3:          34:48          So there's a lot of eating on it to make that, uh, more, uh, uh, useful in that regard. Um, and we went into like closed Beta for a while and then now, just two weeks ago we've opened, you can go and sign up and you can start editing things. And we've got now 13 journalists hired, some of them are part time, but 10 full time equivalents, um, around the world, but mostly in London, which is where I live. And that's, that's where we are today. And we were publishing stories. So go to, we contributed and you can see it. So what is just for this group to understand what is the problem that Wiki Tribune solves versus what we can meet? We compete. We can pdf death today. Yeah. So, um, so Wikipedia is not news. There's a page and Wikipedia, this is not news. We're not news.

Speaker 3:          35:36          Now, of course, Wikipedia quite famously does update very quickly when news events happen. But it doesn't cover every single thing as it's happening. And also in Wikipedia, uh, one of the fundamental rules is no original research. And so everything in Wikipedia should have been published in a high quality third party source. But to do journalism, journalism by definition is original research. Um, it's actually going out and getting new stories, new information. What, what I'm hopeful for. And the, and the concept behind this is to say, look, if we can find a way for a community to usefully and productively help out, uh, with the process of journalism, it lowers the cost significantly. And by lowering the cost significantly, that means of the money we get from readers, more of it can be spent on journalists. Um, you know, if I was on the board of the Guardian and the Guardian has lots and lots of journalists, it's a fantastic paper, but they've got a lot of people doing things inside the Guardian that I know people would enjoy doing themselves.

Speaker 3:          36:33          There's no reason to pay staff to do something that people would enjoy doing, um, if they're invited to do it. And one of those things, uh, for example, is policing for neutrality, which is something that most newspapers these days are very, very bad at. Um, so explain to you, what do you mean by neutrality? Neutrality? Well, you're familiar with it from Wikipedia. A Wikipedia tries very hard to be quite neutral, um, and succeeds for the most part. And, uh, most media outlets these days don't even try. I mean a few do good quality papers, still try to be neutral. Um, and I think if we think of neutrality, I mean we, we had, uh, we've been criticized on the neutrality front from both the right and the left applicant reviewed already. So, uh, Breitbart had a really nasty article about a weekend should be in. And I was like, great.

Speaker 3:          37:30          They're not living up to their standard of nutrient and living to Breitbart standard of neutrality. No. It basically saying we're obviously a bunch of lefties and so on. Uh, and then when I left wing journalists saying, obviously there's no such thing as truth, so, um, I'm exaggerating, but, uh, but basically everybody that the simple way to understand it philosophically is everybody knows what bias looks like. You know, if we mentioned Breitbart and neutrality, the same sentence, we all chuckle a, because we know they don't even try to be neutral. Same with the Daily Mail for example. Um, and frankly the same with the Guardian. I love the Guardian, but they're, they're not a neutral newspaper. They come from a particular liberal position. Um, and the idea is to say, look, actually you should try to just report the facts in a very neutral manner and it's important to really truck will you get there perfectly. Of course not, not every time, but one of the ways that you can get there is if you do have a healthy community who aren't just people screaming at each other who are saying, yeah, actually we've got some diversity in the community to make sure that, you know, we're not just focusing on one side of the issue. We're actually taking into account the best arguments of the other side, et Cetera, et cetera.

Speaker 2:          38:37          So please get your questions ready. I have one more question for Jimmy and, or a read and then, um, and then we'll open it up. So, um, you, there are 3000 people in the Wikipedia world who are probably the most important and they're the important for everybody. There's also us and they're known to each other. There's also a set of people in the world who are maybe equally or more important in those are the people who create the algorithm for Google. What should Google takeaway from what you've been able to accomplish and the way you see the world going forward in terms of information?

Speaker 3:          39:12          Oh, I don't know. I mean, that's a really, it's a really tough problem. I mean, so one of the things that I think, I dunno, I have no idea. That's a really tough question. I, I'll just, I'll comment in a somewhere near that. So I was part of a group, um, that Google asks to help and be advising, uh, about the right to be forgotten in Europe, which was a huge deal in Europe. This is a written out, we're working together sort of a, she was helping me write stuff for Google and so forth. And the issue there is that, uh, in Europe, the, the, the state of the law isn't, is really, it's a disaster for freedom of expression. Um, it's really not, not appropriate. Uh, and the problem is the law that has been applied by the courts is actually older than Google.

Speaker 3:          40:02          Um, the, the, the particular case that went through was a lawyer in Spain had had some sort of a tax problem and his house had been taken from him and had to be auctioned and he, and this was covered in the papers. It was actually an official notice from the courts that was in the, in the papers. It's still published in that paper, but Google is not allowed to link to it, um, on the grounds that it's out of date, irrelevant, et cetera. Not, to me, that's not irrelevant at all. If my lawyer has at his house taken for tax reasons, that's probably important thing about, no. Uh, but so there you have it. So it's, it's, it's really a bad thing, but there are other cases where you can be a little more sympathetic, uh, you know, some, um, revenge porn, uh, things like that where if Google is linking to it, that's it's problematic.

Speaker 3:          40:52          No, my, my belief is that any demand to take down content or a link to content should go through a judge. Uh, it shouldn't be the way it is now. Google is mandated to be judge, jury, and executioner on these things. And there's not, for publishers, there's not a really clear right of appeal and Google's shouldn't have that responsibility. And Google, I think takes it seriously to try to do the right thing, but it's just not, the public policy was, is not the right answer. But one of the things I said to, uh, to Eric Schmidt when we were going around and doing this, as I said, I, we were doing hearings around, you're hearing from all kinds of experts on all sides of the issues. I said, I wish we were doing these hearings two years ago before it became a legal court because I actually think this is a search quality issue that for Google you don't really want to be linking to revenge porn and you really want to have a well understood and well developed editorial policy.

Speaker 3:          41:44          And of course Google traditionally has kind of been a little reluctant to, to say we choose to link to things we think are quality, where like the New York Times, we have a right of freedom of expression. Instead Google has preferred to go. It's the algorithm. Uh, and I think that may have been, I'm not a lawyer, so I don't know, you know, why that approach was taken. I think it may have been a mistake because I do think for a lot of the kinds of things that Google is linking to or shouldn't be linking to, rather than having the law dictated most of, most of the time, I think Google should just make those decisions to say, yeah, we're not going to link to revenge porn. So if there's a revenge porn link out there and we're notified, we're going to take that link down, which I think they do now. But great. Well this is a good transition to questions. Uh, if you, if your questions, there are two microphones on either side and since, uh, since we need to to this to go on video, um, questions, does anybody have questions? Yes, please.

Speaker 5:          42:43          Hi. I was wondering what the relationship was between a Wiki Tribune and Wikipedia'd or what the intended goal relationship is.

Speaker 3:          42:50          Yeah, so we can do view it as a completely new organization and there is no relationship at all. Uh, I'm on the board of both, but that's it. And the reason I did it that way, it's one of the things that's fantastic about the world of Wikipedia, uh, is that all decisions get made through a very long process of community consultation and deliberation, which means we're very slow and making decisions, but we tend to make very good decisions. Uh, this is a startup where I'm going to have to change the website like 10 times quite radically as we figure out what's working, what isn't. And it wasn't really possible to even launch something like this. It'd be a massive sort of two year consultation and I wanted to just move quickly. So that's what we're doing it this way. Other questions

Speaker 5:          43:37          and Jimmy are both, thanks very much for an interesting conversation. Um, you mentioned that when you were, you live in London and I think the foundation is based in the UK. The UK also has famously restrictive and gruesome libel laws that massively restrict freedom of expression. Is there any kind of risk for the foundation for that or is this, I'm going to irony in there to basically right there.

Speaker 3:          43:59          Okay. So the Jimmy Wells Foundation is based in the UK, a completely separate organization. And we get to have too many organizations we contribute is based in the UK. Uh, and then the Wikimedia foundation, which runs Wikipedia is in California. Um, so on the, on the libel law front for Wiki Tribune, the law has changed recently in the UK. Uh, it's become a lot better, but it's still by no means as good as a in the US. Uh, but I, I'm not that worried about it because we want to be really like very high quality, very neutral, very fact based. Obviously there's always a risk of a lawsuit of course. Uh, but if the daily mail can survive without being sued out of existence, I imagine we'll be all right. Right here please.

Speaker 6:          44:49          What's your plans for a scope and scale of the first year? How many stories, like on an average day would you want to happen?

Speaker 3:          44:57          Wiki Trivia, um, don't really know. Uh, we want to have just as much as possible, but without compromising quality. So there are a lot of interesting open question. So right now because we've just launched, um, basically what we say is that the community and the staff are equals, but that doesn't mean that everybody is the editor in chief. Um, and so we do have editors who approve things before they're published and they treat the journalists and the staff is equal in that regard. So right now we're being a little bit slow about what we're putting out because we want it to be good quality. Part of that is I wouldn't do it this way if, if I weren't a well known personal ready, but I know that a lot of people who at the Daily Mail for example, are just waiting for us to publish some error to just sort of take us down a notch and we'd rather be battered, held to high standard from day one.

Speaker 3:          45:48          Whereas Wikipedia was not held to high standard from day one, uh, because nobody knew what we were doing. Nobody cared. They were like very tiny little group of people on an obscure corner of the Internet. Eventually though, I think we want to open it up to have stories published quite quickly. A lot of open ended things. I'm happy to have short little stub articles that are just like quick updates rather than a fully composed piece. So, but to be determined to be determined. So I'm going to take another one here. We have two more here and I just want to make sure everyone gets their questions answered because we're going to run at a time.

Speaker 6:          46:17          Hey Jimmy. I used to do some work on the Wikipedia signposts and I was wondering to what extent that may have influenced Wiki Tribune, that Wikipedia signposts as, I don't know, when is say an on Wikipedia sort of newspaper that's been around for at least a decade, probably a decade and a half.

Speaker 3:          46:32          Um, to some extent. Yeah. Because it's uh, uh, I mean obviously I read the signpost, uh, and sort of goes into my thinking about what communities can do a and the sign posts generally, uh, generally or reports on internal goings on at Wikipedia as well as things that would be of interest to the community outside and tries to be neutral and fair and so on. And I think it's quite good. Uh, I can't say it directly inspired me, but honestly it's just a part of my world yet. Here please.

Speaker 7:          47:03          Hi. So I'd like to go back on fact checking in on Wikipedia. If you could comment a bit more, what happens when somebody added sort of obscure, difficult to check facts? Like, uh, for example, you have census data for some small county in us let's say, which is not easy to check and maybe does that trigger a signal, an email to the moderators or do you have a minimum amount of edits that are needed be done before that triggers an alert that perhaps somebody is making significant changes? Um, you know, I specifically liked on the same how you check the numbers because I use that to my project.

Speaker 3:          47:39          Yeah. Um, so generally there's not much algorithmic signaling of people. Um, so editors have a watch list and they can flag the things that are interested to watch and then they're notified when something changes there. Normally what we would say is we will ask for the source. So then you have to link to the source and then you know, it, it may be hard to find the source, but once you found the source and you link to it, it's quite easy for other people that go and evaluate it and say, oh, well this is from, uh, the government of this area. Uh, it was published at the state. It seems like legitimate formation and that sort of thing. It's quite old fashioned, really. There's nothing, sometimes these resources aren't online though. So like, since was data from the 18 hundreds? Yeah. Yeah. So for sources that aren't online, uh, we consider that to be valid.

Speaker 3:          48:25          Uh, there's, there's no rule there. I actually sometimes get caught in, I find it incredibly annoying. Uh, I get quoted and people love to make like these beautiful kind of pluck cards with this quote saying, if it isn't in Google, it doesn't exist. Um, okay. Those words came out of my mouth only to make fun of that view of the world. Uh, and so I'm like, that's not really fair to quote me as saying that. Um, so it's basically the, um, uh, it's, it's, it's, there's no, nothing special, no nothing. I can really tell you if, if you're a well known contributor and you're known to be someone who works in that area and you're trusted by the community, that would be completely accepted if the information you're putting in seams in some way. Surprising. So you're, you're saying the population of uh, uh, Miami, Florida was 43 million people in 1870, we'd probably go, yeah, probably not.

Speaker 3:          49:20          And challenge it. Um, and then in between, I think we would tend to trust if it's obscured, like what motive would you have for making up population numbers? That's a question that we go through people's minds and the, the source there, there will be people in Wikipedia who their hobby is population figures in the 18 hundreds, and they will have some idea as to whether it corroborates with the General Dadada nothing magical about it. Um, it's just trying to do the best job we can. Kids or I want to just get your through the rest of the questions. Please go ahead and trying to throw. So this relates to the previous question on scope, but it's a good way in which news source success bias is not only the two of the articles, but also which stories that she used to cover and what prominence they choose to assign them.

Speaker 3:          50:04          So is there any way that would get your billing plans to address this issue? I think this is, this is where having a healthy on diverse community is very helpful. Um, because community members can start stories about anything they want. And so the problem of a small team of an editorial board who have a certain perspective on the world, even if they're trying to be neutral, obviously one the, you know, one of the facts about biases, oftentimes we are biased in ways that we don't even notice because that's what bias is. Right? Um, and so having a diverse community who says, hey, we need to write about this. This is an important story that's not being covered elsewhere. And they couldn't rally volunteers to do that, then then they should. And I think we have to be very introspective, always about our internal staff processes to say, are we just choosing stories?

Speaker 3:          50:53          Um, you know, so like in today's political environment, you might only choose stories about Donald Trump and Russia and not true stories about Hillary and her emails. That's just one simple example, which is, I know what you've always got to challenge yourself and say, right, we need to make sure we're looking at things. It's actually one of the, I have a whole little rant about Fox News and I haven't lived in the u s in a long time, uh, for eight years. And even before that, I wasn't a big watcher of Fox News because I don't watch much television. But one of the things I think a lot of people missed when they thought Fox News was incredibly biased, which of course it is in certain ways, is most of the shows people talked about. Our opinion shows it's bill O'Reilly pontificating and having guests in, but they're straight news segments.

Speaker 3:          51:36          Uh, we're actually quite high quality, but they often covered stories that people in the heartland cared about. The people in New York and California weren't that interested in and that was one of the reasons they became very popular. They would cover a story, uh, that just seemed like, you know, whatever factory workers out of work somewhere, you know, maybe we near comes covers it. But they were like really in there in a way. And I think that's important is one of the reasons I think we've had this huge drop in trust in the media is a lot of people read, followed immediate and they're like, well, this, I don't know, this has nothing to do with my life. Nobody's really covering it. And when we look at the incredible devastation has happened to local newspapers everywhere, you can actually see why people feel like, Hey, journalism doesn't care about me.

Speaker 3:          52:23          They're basically, all they do is rant about Trump. Nobody's like concerned about our problems here. Um, so I, I'm, we have like two speed dating questions. So let's take the two questions here and if we can, we'll just take one more. I'm really concerned about time. They're, they're starting to like, I would love to, yes. Every question. Like they say Jimmy. No, no, no. [inaudible] and thank you. Thank you. This question is for four week explicitly. Um, it seems to me part of the success of Wikipedia is the quality of the community. How are you going about building the community and making sure it is? Thank you.

Speaker 4:          53:03          And so first of all, and we're welcoming everyone and we're welcoming all of you. And we're lucky to have Jamie to have experience of building an online community of contributors. So we are also aware of all their possible problems that might occur. We don't want it to be UK based or US based or you're just, you know, West centric. And that's why we plan to launch in as many languages as possible in as many regions as possible to start dissolving. You know, they're all, I'm focused on, on, on, you know, you were talking about Trump and Hillary. There are so many more stories around the world were happening. You know, we have Tara taxing Egypt and so on that people do talk about maybe an oddly enough maybe you know, a lot of corruptions in different new on Columbia in different countries that I don't think they get enough focus.

Speaker 4:          53:58          That's why am personally I have the background, a few in rights law. So personally I'm very interested in having a very diverse community and from big different background for gender, you know, gender wise, I know that Wikipedia has some problem with not enough women, um, editing the entries. So we are very aware of the palms that war or still existing, they Wikipedia and we're trying to avoid them or sold them before they happened. And, and so it is a challenge. Of course I don't have all the answers yet, but um, we, we can adopt some of the solutions that were already farmed in Wikipedia and maybe we will find new once a diversity. I think it's a very important for the neutrality part of Jimmy spoke about a, but for many more things, um, that are important for very sustainable use side. That's going to, and I turned all issues and relate to as many people as possible. We want to change journalists and we don't want to replicate what already exists. Yeah.

Speaker 3:          55:08          So we're going to, I know I'm running over time, they're going to like get the hook soon, but I want to make sure we get out the answers. Questions. Amazing. Duck sweater. Please go ahead.

Speaker 7:          55:17          So I guess bringing it back to a Wikipedia question, you've mentioned how important the community is and you kind of just mentioned some of the maybe biases or differences about that. Um, a specific question I had is, do you think that the community of contributors is going to be aging over time with Wikipedia or are you seeing a lot of kind of newer, younger people come in common? I guess if you have any insight into other trials of any kind of diversity there?

Speaker 3:          55:42          Yeah, in terms of Wikipedia, the, uh, the, it's a, it's a concern, but it's not an overwhelming concern. So we do see, we've got a, uh, a very large cohort of very active, very powerful users who've been around for a long time. Uh, but we also have new contributors would come in all the time. Uh, if we don't have good data on the aging. My feeling is that the Wikipedia community has been aging. Uh, sort of the average age has been going up about a quarter of a year every year or something like that. Uh, so we are aging, but it's not like we're all, we're not going up by one year per year. Uh, so there is that. Um, and yeah, final question please. Yeah. So my question is just around, uh, she can use and you know, large by the fake news problem is that people are just consuming news, an echo chamber. So I'm just curious about how Wiki Tribune plants to tackle that and any thoughts you have right now. Yes,

Speaker 4:          56:40          I think I was just talking about that, that we are going to attend to more communities. It also going to local communities as well. Uh, we're searching for a lot of models to get as many diverse people and communities and backgrounds and involved.

Speaker 3:          56:56          Yeah. I think one of the, one of the key elements here, one of the reasons we're launching with no ads is like the, the advertising model drives a certain sameness to the stories that are covered. If you're chasing clicks, you need to have a headline about something that people are already excited about and know about. So you're going to get a lot more clicks. Our business model, what I need, I need you to read to the bottom of a piece and say, wow, I didn't see that anywhere else. I understand the world better than I did before. This deserves to exist. I should ship in a, I should, I should pay for this. Um, versus if I were at driven, I just need you to come and look. And that means it doesn't drive you in the direction of trying to wow people with like, oh wow, I didn't know about that. And how did I miss that? This is something new. So I think that's a part of the answer, uh, is to set up the business model so that the organization's internal focus is on something different from what everybody else is doing. So this has been a great conversation we could go on for a long time, and, uh, and I'm sure the folks at Google really appreciate it, so thank you both. Yeah.

Speaker 1:          58:03          Okay.