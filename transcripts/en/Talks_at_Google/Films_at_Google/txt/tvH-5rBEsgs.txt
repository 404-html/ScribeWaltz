Speaker 1:          00:06          Hi everyone. Welcome to toxic Google. We're very excited today to welcome Alex Garland. He is the director of the, depending on when you see this upcoming film x Maki, uh, which was awesome and we screened it yesterday and we were very excited to have you here because technology and AI or something that we're kind of interested in just a little bit. Uh, I should probably have said, well, welcome to blue book, but a lot of people here, I haven't seen it yet. Um, so let's, let's talk a little bit about first your background. Um, you started mostly as a writer, um, and then producer and director of some things as I'm a writer, you're a writer. Um, so what was it about this subject matter in this film that made you go, this is the one I want to direct.

Speaker 2:          00:52          Oh, uh, uh, nothing.

Speaker 1:          00:55          All right. Then

Speaker 2:          00:56          it was a, I keep having this conversation and I realize why, I guess, and it's because we kind of dignify the role of a director and it seems like a really big deal. I've been working for them for about 15 years. A lot of it with the same group of people. For me, this is just part of a continuum. It's just another film with the same group of people largely. And, um, there was no really significant difference between this and the one before and the one before that. And, uh, it, it's because we, the question stems from the fact that we overstate the role of the director. But that's what I would say.

Speaker 1:          01:29          But at the same time, I think you, depending on the relationship you have with someone who's directing your own material, like you, you have to have a lot of trust in them to be true to whatever you're an original intention was there. And that that applies to the editor and you know, the actors as well. But, but by being both the writer and director, you do have an extra sort of level of control.

Speaker 2:          01:48          Yeah. But now you've shifted the presupposing onto the other directors and assuming I gave them that level of control, if you see what I mean. And the, uh, uh, and really what it is, the key thing you said is that the editor, the dop, the actors film is, is broadly a color. It is a collaborative process. Having come from books, which is not a collaborative process for the most part, uh, I can stay film is, I think it would be fair to say, and, and, and all of the people in that film have a real insignificant role and it's not just paying lip service to it. They really, really do. That's why production companies fight like crazy over who the dop is or who the production designer is. If it was just observing the sort of, the vision of the director, what difference, you know.

Speaker 1:          02:34          Fair enough. Right. Um, okay. Well then what were some of your influences for this particular story? Uh, sort of cinema about cinematically and maybe I'm visually, uh, you know, the history of artificial intelligence in cinema has definitely been something that's been portrayed in many different ways. Yes. Um, so what were some of the things that you drew from

Speaker 2:          02:55          well, uh, uh, or that may not look it from the stories I've sort of Zombie movies and stuff I've worked on previously. I tried to draw as much from real life observation as possible. Um, I had got involved with a long running argument, a good natured argument, but still an argument with a neuroscientist friend of mine who comes from that very respectable position that exists within a theory of mind about humans, but also AI research, which basically says machines and ever going to be conscious. There's something particular about human consciousness that hasn't been understood yet. And when we do understand it, we will see why machines are precluded from ever being sent in. And um, uh, I think on an instinctive level, I disagreed with him and then we, we sort of argued over years and mainly this film comes out of that argument. Uh, I finally came across a book written by the professor of cognitive robotics at imperial, which is like our version of Mit. And it was about the relationship between consciousness and embodiment. And he has a really sort of beautiful, elegant argument in it, which, which combats I think quite effectively. Some of the arguments I would hear. And so, uh, and while I was reading that book and I have to stress very hard for me to read that book and I could only read sections of it, it's like mountain climbing for me. But, um, uh, while I was reading that book, the idea for this film kind of arrived.

Speaker 1:          04:18          Um, so you, you definitely delve into some of the, the headier ish, you know, issues of what is, what is humanity, but his personality, what is, you know, what is it, uh, Centene creature. And so what were sort of some of the challenges of, of getting this heady topic material of like subject matter and it has a lot of scientific implications to translate to a cinematic story as well as something that is also a human story. And like not getting too bogged down in the science but still convey it was a challenge. You picked a big challenge, right? Your subject matter. Um,

Speaker 2:          04:55          um, yeah, it was a, yeah, the guest there was a challenge involved. Um, I was just trying to be, I was trying to be fair to the subject matter I guess, and tried to be respectful about it and really try to understand it within my own limitations as best as I could before writing it. Um, uh, partly because I think it's interesting and uh, um, it, it's an area where this is true of lots of area of science at the moment where there's a, there's a kind of increasing vacuum between the people who are actually doing this stuff and the, and the rest of us who were trying to understand it. And so some of it's about trying to bridge that vacuum as best as possible, but it's, it's really tough to do that. Um, the thing about it is, is that any look strong AI also becomes a look at human consciousness that the two are related. The problems of one a kind of the problems of the other to an extent. Um, only to an extent. I don't personally think that when a strong AI arrives, it will necessarily be like us. In many ways. It may be completely different from in almost always, but, but the issues and the conversations in this current state of not understanding are very related. So, uh, yeah.

Speaker 1:          06:05          Okay. Um, let's, let's talk about the more human factors in your, you've had a really wonderful cast. Um, I thought that, uh, Alicia, you see it. Yes. Uh, she brought just this really great quality of sort of inhuman but human to the character of Ava and I'm sure that's exactly what you wanted to had, uh, wanted her to bring to it. Were there things that you worked on to kind of, uh, get her to telegraph that sort of human but not

Speaker 2:          06:38          she, she arrived with it? Um, um, I mean we had, I'd seen her in other movies and we had various conversations and stuff, but when she arrived, she had this site there. She's a ballerina by training, so she has a terrific control over her physicality as well as being a very, very good at. She was very grateful. She was very gracious, almost unsettling in a character way, but, well exactly. So do you know the VF that you know, the Vfx team, cause you used to work in Vfx uncanny valley. Yes. So what she did was a kind of uncanny valley version of human motion. She said, I'm not, I'm not going to act like a robot, what I'm going to do as human actions, but I'm going to do them perfectly. And that perfection will create a sense of otherness. Cause like when I'm sat on this chair actually your rather sort of graceful by not and I sort of slouch and uh, if I get up I have to sort of, you know, shove myself up and come back my middle age and all that kind of stuff. And so, uh, whereas she does it with this amazing sort of dance, has poise and it's hard to look at it and say anything she does is sort of quote unquote wrong, but together it creates this uncanny valley, slightly unnatural quality.

Speaker 1:          07:44          Yes. Uh, so you wrap the end, came to valley. And I thought I was almost afraid seeing the trailers that, you know, all the footage was, it was beautiful. And I was like, okay, I don't think they're going to hit it. And you didn't, you didn't fall into that, which was amazing. But it's a challenge, especially considering the, the anatomy of the main character for the majority of the film. You know, we see her in this kind of robotic hybrid synthetic like with a human face and it's a little unsettling. And at times she's just so perfect looking that, you know, but there's the, you've managed to still capture like a human ish elements so it didn't hit, you know, the, the too cartoonish and to humanoid. Um, it, yeah, that'll be great. Congratulations on that.

Speaker 2:          08:26          Thank sort of, I mean, the, um, the funny thing is about people is that we, we are urges to project human like qualities and to almost everything, it, it's, it's almost an effort to stop it happening. Um, I mean there is, there's incredibly beautiful VFX and there's beautiful production design and it's beautifully shot and it's beautifully lit and all those kinds of things. But, uh, um, that thing of making this strange machine believing that it has the qualities that we have, that's actually really quite easy. I, the that is to say you could take it with a child who, you know, it's probably quite hard to find children that don't, uh, attribute sentience to they're cuddly toys. Right. In, in some ways. And, and that's where I guess it begins when in fact it probably begins because it's sort of semi coded into us in some respects. Um, I was driving not that long ago with an adult who is feeling pissed off with their car and kind of critical event and, um, but didn't want to say so in front of the car in case it hurt the cause feelings right. Now that that's a grownup. Right. Um, and, uh, so, um, uh, and cause don't look much like us pretty, you know, more or less. Um, so, uh, so yeah. Um, I mean, I know you're being kind about the films, I'm not trying to be combative.

Speaker 1:          09:46          It's your film is, it's a collective, right? Yeah, sure. I, I, you know, I think there are a lot of, of times when, you know, we see these sort of representation of humanity but not humanity and, and you really want to project onto it. And what you had to do is kind of combat that a little bit. You like a lot of the plot of it kind of hinges on us accepting this artificial element to it. True. Um,

Speaker 2:          10:14          true. So, so initially what you do is in a very kind of upfront way, you say this is a machine and there's no ambiguity. It's a machine, right? And there's all sorts of things to force you to think that way. There's cavities where they shouldn't be cavities and you can see through her in a way that, uh, sort of removes her being like us, a girl in a suit, you know? And then the, the, the task of the film, Mr Gradually have that machine quality fall away. Right? Even though she looks kind of the same. And, and to show just by behavior, we will, we will forget the thing that's right in front of us.

Speaker 1:          10:51          Yup. Um, so the, the VFX team behind this did an amazing job, you know, it was, it was fantastic and a shout out to them. Uh, can you talk about working with them, especially having basically one of your protagonist characters be mostly CG for a good portion of the movie?

Speaker 2:          11:06          Yeah. Um, uh, well they were run it, it's a company called DNA, uh, or double negative, which, uh, based in London where I live and work and our team was run by a guy called Andrew Whitehurst. And, um, in the course of my life, every now and then I've met some really, really smart people and I think he may be the smartest guy I've ever met. I mean, he may or may not. It's, uh, but, but he's certainly going to be in the top tier. Um, the, the thing about him that is so interesting is he's got a real gift for sort of poetry in a way, you know, that beauty and things like that. So I remember one day he said, look, I've got this great idea, which is to uh, hang plastic strips inside her form, which will diffuse the light in a particular kind of way and make us slightly more mysterious even though you can see the machinery.

Speaker 2:          11:52          And so that's, that's a lovely kind of poetic idea. And then another day we ran into this massive quality control issue. It's kind of technical and I will fail to explain it properly, but basically we were getting, because of the way the images on the Sony cameras, we'd use it being sort of processed or something. I Dunno, we were getting these weird straight pixels and I'm in big flat areas of color. Suddenly there'd be these straight pixels. And we had a problem because we were going to fail a quality control thing to do with the distributor when we handed the film over and he said, ah, don't worry, I'll fix that. And he wrote some piece of code over like a week and it reprocessed all of the imagery and it fixed it and made it go away. So I'm thinking, I don't know how to talk to this guy now. He's just like such got a range of abilities. It's just unreal. So thanks.

Speaker 1:          12:38          That's impressive. Um, what, what, uh, what sort of mixture of it was working with that team and working with the actors in terms of, you know, integrating this character because if it had gone wrong, the movie, we would have been lost as an audience. You know, you would've been in snap out of it and it would have probably hit that weird uncanny valley in the wrong way. In the wrong way. Yeah.

Speaker 2:          12:59          Yes. So, uh, yeah, I mean, my, my approach to filmmaking in my approach very much played out in this film is about, uh, this is gonna sound like corporate speak, right? But it's about these different departments having a lot of communication between each other and also a lot of autonomy. Um, and that would include the actors and it would clean the VFX team and the composers and, and so on. So it's not, it's not separate group. It's, it's sort of roughly like what you'd imagine anarchy would be like ideally where you have autonomous groups not kind of chucking bricks but uh, but kind of agreeing about a common goal. I think that's the key is agreeing about a common goal and then, and then having a lot of independence and autonomy within it. And uh, um, uh, any department you could mention that would have been the approach.

Speaker 1:          13:55          Hmm. Well, so speaking of the subject matter that I'm working with technical technically challenging things, a lot of your sort of subject matter is this sort of futuristic, but I want to do like a little bit apocalyptic in terms of like 28 days later and sunshine was the, like if we have to restart that sun and apocalypse, uh, uh, they're, they're sort of very challenging things that, uh, to accomplish. I think visually, you know, you need to have a lot of trust in the teams that are taking these to task. Um, has that ever like the challenge of it ever influenced you? Have you ever thought, oh, maybe I want to do this? Or you just go with the creative process and just trust the trust your teams to make it work.

Speaker 2:          14:37          Well, you've got to aim high. Right. And, uh, and I think one of the things is that broadly speaking, if people feel like they're aiming high and they're having to work slightly outside of their comfort zone, they raise their game. And, uh, that, that's just kind what happens. And, uh, um, it, the, the key is the vibe in a way. You know, it's, it's like the atmosphere of it where, um, uh, it, it's not, it's very easy with collaboration to have it work with lip service. You sort of say, yeah, yeah, we're collaborative and just would you mind doing it this way? You know, and then we'll be really collaborative slightly later and so on. Um, but I think if you in almost in four set, uh, provided you've got the right people at works great. I have to say, I've worked on films where it's been just the most miserable experience and it's been completely horrified. It is. It is down to the people you're working with. The collaboration can turn into mush really easily if you're working with a no, I'm going to stop talking, but um, but yeah.

Speaker 1:          15:36          Well tell me you want to be in the trenches with, you know, it's, it's, yeah, when it comes down to the can feel like editing and stuff like that, like who is going to be a positive influence on the creativity as opposed to just doing decent typically. Yeah. Is the main thing. It's okay. It's a good metric. Um, what, what are some of the experiences that you've had previously that you brought to this filmmaking experience that you thought really, you know, I, it sounds like you've worked for some of the team before. Like what were some of the things that you thought, I really need to bring this to the table, uh, when approaching this, this film?

Speaker 2:          16:08          Well actually a lot of it, I don't know if it it in a way it's of interest to anyone by I'd worked in science fiction that would have been stemmed originally from some kind of science conceit by entropy, heat death or something like that. And um, uh, and, and had sacrificed at a certain point, uh, anything resembling rationality for story concerns about adrenaline or, or, you know, perceived story concerns about a journaling and what would I really felt. My main goal with this form was, uh, I may never get to do this again for all sorts of reasons. I may never get to do this again. So I'm just going to try as in my sphere in this table with many legs to just do it right, to do it as right as I can. Not compromise on anything at all by literally nothing in my sphere. And, um, uh, so I guess that was the main thing. Film has terrific influences to compromise, built into the fabric of how they get made and how they get distributed in finance and all sorts of things. And in this instance, it was to step away from that.

Speaker 1:          17:13          That's it's having, it's great that you were able to do that. Uh, I think that's something that a lot of directors strive for. And then when it comes down to then making the decision, they, they end up having to compromise through whatever set of circumstances they might be the guys requiring the compromise. But that that's also very possible. Um, what, uh, actually speaking of the collaboration element of it, um, can you talk about working with rob hardy or cinematographer because if even the film was very like beautifully shot. Yeah. Um, and I think it, it just all sort of tied visually together with this beautiful artificial creature and, and then this beautiful setting. And um, yeah. How did you work with him to

Speaker 2:          17:57          rubs just an artist? He did. It's very important. It's, it's quite interesting. You can put any camera in his hands and he will just find a way to frame the thing. And, um, uh, it, if you, it's like not knowing how to play guitar, I guess it's kind of, if you don't know how he's doing it, but you can see how good he is. It's truly mysterious. There's something really, uh, kind of weird about it. Um, he's, he's just a very, very talented dop and, uh, uh, he's, he's known in the scene, I guess for being very good anyway. And, um, uh, he, he, he and I, uh, been close to working together before on a movie, never let me go with about four years ago. And he was, uh, one of the dops in the frame for that film, but it didn't work out for various reasons. Um, but he was, he was just like the perfect choice for this because he's kind of sense your and warm and, uh, Scifi can be quite antiseptic and clinical. It sort of goes to the, the hospital and you know, Saifai and his instinct is about almost like dropping a gauze over everything and being soft and zen like, and so I, he was perfect for it.

Speaker 1:          19:10          Yeah, I think, I think zen is a great adjective to describe the second setting of the film. You know, it's this beautiful retreat and woods and waterfalls and rivers and it's like, it's somewhere I'd want to vacation. Yeah. It's available. Rent gets it now. Um, it might have an extra guest in it still.

Speaker 2:          19:34          It's a hotel. Oh, we showed it and I tell in Norway, um, uh, it's a really core eco hotel and um, the landscape is absolutely stunning. I, one of the funny things about film is that it both loves and hates familiarity, you know, and uh, finding a landscape that has not been well used in film, it's quite difficult. I've noticed there's been like tons of movies recently that I've used. Icelanders are location. Yeah. And once you get sort of zoned into that Iceland Vibe, you think, oh, we're back here again even, or are you thinking consciously or unconsciously? Actually and um, uh, Norway had something special about it. There's a kind of bleakness in it. It's beautiful and very majestic, stunning skies and mountains and waterfalls, as you said. But there's something a bit kind of hard to bed kind of bleak.

Speaker 1:          20:22          Um, was it, I'm going to assume it was at a point to justice position, kind of the nature of factor with the natural elements, maybe not a natural next evolution elements of

Speaker 2:          20:35          highly, highly contained, controlled environment created by a man, a completely uncontrolled environment created by no one, those two arguably.

Speaker 3:          20:49          And uh, um, I taught this in detail.

Speaker 1:          20:53          Uh, speaking of the kind of control element, everything did feel very even plot wise and, and behavior wise of the characters. Everything felt very planned in a, in a good way in a keeping the audience on their toes and like what, who is in charge of what, who's making the decisions, who is, you know, who's playing, who was the puppet master, kind of a in a lot of ways. And was it tough to kind of keep the, the audience's trust for some of that and say like, no, go with me. Like you'll figure out who and, or, or did you want to kind of keep people a little disoriented the whole time?

Speaker 3:          21:26          Um, what are the,

Speaker 2:          21:31          the thing that, there's a funny thing about film, which is that you can assume literacy on the part of the viewer. It's not necessarily true in books. You could write a book which alludes to heart of darkness, but you would not be able to assume they'd read Conrad and read heart of darkness. Whereas with a film viewer, you can pretty much assume, for example, they've seen blade runner, right? Uh, and in fact you might even be able to assume they've seen apocalypse now, which is based on hard in some respects. But so, so that is this funny thing about the wave film works and what it, it's, it's kind of a free gift in terms of what you were talking about in terms of that relationship with the audience because some of these things have been well established and then you can use them to your advantage.

Speaker 2:          22:11          So in the case of this film, a smart literate film viewer is very quickly, almost immediately you're going to be thinking she's not the robot. He is. It's just going to be an automatic assumption. They're just going to do it. And then what you can do is use misdirection and nudge them a little bit further towards that because he's got oddly symmetrical scars on his back, which has for justification within the narrative about a car crash. But you're thinking, yeah, that's not why. And, and the, uh, and so, you know, so you use that stuff to your advantage. It's, it's, uh, it's very useful. But the basic function of this film is to, is, is it's intending to set up a series of questions. Some of the questions it's setting up it like where does gender reside, for example, it doesn't then necessarily have an answer to it. And in fact, it might be saying it is impossible to present a clear answer to some of these questions about consciousness or gender or AI or whatever it happens to be at this moment in time. We're not able to do that. But that doesn't negate the reason to ask the question and have the conversation. And it's basically an idea's movie. It's, it's to provoke conversation and, and to hopefully do it in a sort of respectful and thoughtful way. What would be the intention? Yeah,

Speaker 1:          23:23          I think, I think it absolutely accomplished that. And you know, you mentioned the scars on the back and that was one of the things that immediately after the movie was talking about, it's like, wow, I wonder if that was part of something else or do you, are we meant to thank you so robot and, um, but it, you know, it's, it's exactly where you want the audience to go with it, which is misdirection. Right? But it's still, it, it helped it frame. I'd try to talk about without spoiling anything, you know, it helped, it helped frame later events in the film, uh, and, and create this sort of tension until the end, which, and I won't say exactly what happens in the end, but the ending was just fantastic and thank you for, thank you for kind of not, not giving us what we expected.

Speaker 1:          24:07          I think it kept true to the sort of the, the, the feeling and plot you'd set up prior to the very ending. And, uh, I think if you'd gone with this sort of cliche route, uh, we might have been a little disappointed. Yeah, it wouldn't, no, it would have been, it still would have been satisfying. But I think the, the sort of way that I can I just say it. You say what you like, I'm going to spoiler alert warning here. Um, so, uh, no, at the end. Oh yeah, sorry. Um, but if, if you know, the, the way that the robot, sorry, maybe I won't, he's shaking his head. Oh nevermind. I was, spoiler alert. It's great. Go see it. I'm okay. Either way. The ending is fantastic. Thank you. Um, and it's unexpected and I think it really does like service to your audience and trusting them and saying like, here are all the points and I trusted you to come up with this unable reward that with keeping true to the characters. Thank you. I'm sorry for almost point linkage. Um, let's see what else. Uh, I want to talk to a little more about, about the actors, sort of what was the process? Cause it's a very limited cast. Yeah. Um, Donald Gleason was a great and sort of charming in this almost innocent way. Um,

Speaker 2:          25:23          I'd worked with him twice before. So, uh, I knew donor would be really good for this and, uh, actually just simply called him up one day and said, hey, look, I'm going to send you a script. What he'd do it. Uh, I mean obviously if he didn't want to do it, I can make it. Uh, so, so yeah. Uh, try as I might. So, so that, that was donut. And then with the other two, um, uh, the thing about actors is, and I really think this is a fair statement, is that there's no mystery to good actors. When you see it, you just know it. When you see it. It, it's, it's hard to find somebody who would say, Phillip Seymour Hoffman was a bad actor. He was sort of evident in the, an incredibly good actor. That tends to be the case with good ones. You don't need to be an expert.

Speaker 2:          26:02          This film required the costing of good actors, uh, that there is a kind of actor who isn't necessarily a good actor, but they have an enormous amount of charisma. And that can be fantastic for certain kinds of films. Charisma is just what you want to make it function. Uh, but this particular film, they needed to be act as a of a certain type really. And, um, so, so that was, that was the pool we were drawing from Oscar Isaac. Uh, I'd seen them in lots of stuff actually. Uh, and um, he's one of those guys who within the industry is incredibly buzzy and uh, and very, very well respected and Elisia for candor. I'd seen her in a Danish movie called a royal affair. Um, right. I'm going to guess she was in her early twenties or maybe even late teens when she shot that she's acting opposite mads Mikkelsen who's a fantastically experience charismatic and terrific actor as well. And despite that, you, your eye just goes, she's got that magnetic ability that some people have. And uh, so she was, she was perfect that that was essentially the, the roots I suppose. I think she did such a lovely job move. Yeah. She's, she's

Speaker 1:          27:12          shouldering this interesting kind of dead lucky with that cost. And, and going back to Oscar, Isaac, um, you know, thinking, Oh yes, that the dancing was just so unexpected and phenomenal. Um, but he, uh, he had his sort of charisma of his own and you know, not necessarily the sort of big boisterous Hollywood personality charisma, but the character itself had a very interesting kind of draws you in, makes you want to, you know, find out what he's doing. And I think that was sort of integral to the plot of it, you know, is having this guy who makes you want to find out more. Um, yeah. Is that part of the reason you cast him or is that something you saw in him or is that something that kind of came out later in the process?

Speaker 2:          27:55          No, no, no. I mean that, that was the intention of the story. I mean he, he's a, it's a tricky thing because he's the CEO of a big Tech Company and immediately that leads people to think he's kind of aimed at somebody. But it wasn't really that at all. I mean, in a way I was thinking more about people like Oppenheimer. There's lots of red because AI as we know, because we're informed by Stephen Hawkins and Elon Musk and people like that is, has, has latent potential for being extremely dangerous. And, uh, and I think that has to be true. It is, it is potentially dangerous. But I also think it's reasonably analogist with nuclear power, which is also dangerous, but it doesn't stop us using it. And, um, uh, and, and I'm basically in favor of Ai. I think it's terrific and I'm fascinated by it and sort of all power to it.

Speaker 2:          28:40          What, maybe not all but a lot of power to it. Um, and, uh, so, so the thing with, with Oscar's character was to be a kind of Oppenheimer like character who's conflicted about what he's doing as he's doing it. And, and it's up to the audience in a sense to, to understand where he's really coming from because he presents himself as being, uh, incredibly kind of misogynistic and predatory and then actually violent. And then you have to decide, is this an act he's putting on for the purposes of this experiment? Or is it real? Or is it something in himself that he's helplessly amplifying for the experiment? Like w there's all sorts of, uh, things that it could be an Oscars are very kind of liquid actor and that kind of set of challenges of where you, where are you at this moment in a scene is, is exactly what kind of turns him on really and get some going. So yeah,

Speaker 1:          29:37          I think it's, it's also a testament to the writing of the character and the portrayal by the actor. But it was, it was one of the more sort of complex characters that I didn't know if how you want it to like, you know, identify with him or support him or just be like, oh, you're horrible.

Speaker 2:          29:53          Well, you were invited. Clearly to think that is horrible. There are several stages of the film where it, where it is almost instructing the viewer to say, feel deeply suspicious and uncomfortable with this guy. Um, however, there's another thing as well, or at least I hope there is, which is that sometimes the things he's saying, even though he sounds like he's wrong or actually true. Um, and so it, it's the ability to hear past what's something sounds like it is to actually what it is, right. It was

Speaker 1:          30:23          vehicle that's delivering it as opposed to the actual message. Um, yeah, he's an interesting vehicle to deliver it. We'll try it. Yeah. Yeah. Um, so yeah, you say you're in favor of artificial intelligence and to a degree,

Speaker 2:          30:36          yeah. Which I mean, like strong. I mean these AI sort of conflate so many different things. This AI and phones and video games and I mean, do you know, we're talking about strong AI, right? To use that term, generally.

Speaker 1:          30:50          What, what was it like working with the science advisors on this? Um, just because I didn't know, you mentioned this conversation with your ongoing discussion that led to a movie with that and your neuroscience scientists. Right. And, and I'm, I'm, I'm going to go ahead and guess that there were a lot of science advisors involved because the,

Speaker 2:          31:07          there were three particular in advisors. There was a lady called GM, Milena vetch, and there was a geneticist to also fronts, uh, uh, a radio show actually, which is sort of trying to disseminate scientific discussion on radio four BBC thing, uh, called Adam Rutherford. But there was this guy, Murray Shanahan, and, uh, he was, um, he works at imperial and, uh, he was the guy, all of these people, what I said is, look, I, I've attempted to write this thing as best as I can understand it from the literature and from a youtube videos of lectures and stuff like this. Check it, be really, really tough on it. If it seems wrong, if this is an inaccurate representation of Mary and the black and white room or whatever it happens to be as a thought experiment or whatever, tell me now, obviously it's got two big conceits in it. There's, there's a robot that has a level of robotics that clearly doesn't exist yet. Uh, yeah, sure. Yeah. But, but doesn't, and there's also a machine that really does seem to be sent to you, and that also doesn't exist. Um, uh, I, I'm probably yet, um, so, uh, so there's a limit to how much you can advise on something which is fiction, right. But, but to be reasonable about the subject was the key thing I think.

Speaker 1:          32:25          Um, and have, have you sort of applied the same thing to your, your password? Because I mean they've,

Speaker 2:          32:31          no, no, I haven't. I haven't and that's why I did it with this because, uh, I felt like I had let down the subject matter previously. And, um, so when I'm talking about earlier, when we were chatting about not compromising, that's basically what I'm talking about. Um, uh, I feel frustrated with some of that stuff. So yeah,

Speaker 1:          32:52          I think it puts you in a sort of position where you, you might be given, you know, if he'd come back and say Xyz doesn't work because of this, you know, puts you in a tough position where you might have to compromise on your own work. So,

Speaker 2:          33:03          no, because then I wouldn't have done it, but, but the, but the key was a, you make it cheaply that if you want creative freedom, make it for less money.

Speaker 1:          33:12          Oh, I, I meant plot wise and stuff like that. Okay. All right. All right. Nevermind that in any terms

Speaker 2:          33:19          you can think of, the less money you make it for them, more freedom you got.

Speaker 1:          33:23          Yeah. Um, so what, uh, what are some of your, you know, what, what other subjects would you like to delve into going forward? Um, um, what are some of the other things that interest,

Speaker 2:          33:33          well, I'm trying to, I've just finished the script a have a really fascinating novel called annihilation written by a guy called Jeff and Amir Mirror. And I'm going to, I'm trying, I've tried to adapt that and I'm going to wait. I'm in the process now what I'm out here in the states of trying to set that up and hopefully we'll succeed. And, um, uh, um, I came across this very interesting argument that talked about how well the all life on the planet is cellular and um, and it has, there's an argument which is, has actually some evidence attached to it incredibly, which is the, all of those cells are derived from one cell, which actually makes logical sense when you start to think about it. But I never had stopped to think about it and um, that is a truly extraordinary idea. That's one of the reasons I liked science and I liked science fiction is because I think it puts these really fundamental, fascinating, uh, sort of ideas into your head. And so, um, I guess that's what I'm fixated on at the moment.

Speaker 1:          34:31          That's a very interesting subject to you. You kind of approach the starch macro things that make us, I feel like examine when she like it is to be human almost, isn't it? Yeah. It makes you think

Speaker 2:          34:43          good about the future in the past and where you are in it.

Speaker 1:          34:47          But there's, I guess there's an approach to it also that is a sort of looking at it from the human standpoint on it as opposed to like just a purely scientific because there's a way to tell those stories and explain like, you know, like, oh well we became from one cell as opposed to being like, think about the ramifications of this. Um, and, and exploring that as opposed to just how to presenting scientific evidence. Yeah. Um, well, uh, I'll ask what's, um, what's one piece of advice that you wish you could've given yourself before going into this project? What, this one? Yes. And then going to your next one. No, nothing.

Speaker 2:          35:21          It was all cool. It was great. It was a good bunch of people and it worked out in the way it was supposed to. I've never been able to say that before, but I can say about this.

Speaker 1:          35:30          What's that? What's one thing in particular that you draw from this experience that you'd like to bring into the next one? Is it the not compromising is with most people work with nice people. I think that's a great thing. Um, I think we cool. We cool. Thank you so much for joining us. Uh, eczema keynote will be out in theaters. Uh, got it. Thanks so much.

Speaker 4:          35:53          Okay.