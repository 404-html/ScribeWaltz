1
00:00:06,540 --> 00:00:08,470
Hi everyone.
Welcome to toxic Google.

2
00:00:08,650 --> 00:00:11,170
We're very excited today
to welcome Alex Garland.

3
00:00:14,740 --> 00:00:19,400
He is the director of the, depending on
when you see this upcoming film x Maki,

4
00:00:19,640 --> 00:00:19,990
uh,

5
00:00:19,990 --> 00:00:22,750
which was awesome and we screened it
yesterday and we were very excited to have

6
00:00:22,751 --> 00:00:26,800
you here because technology and AI or
something that we're kind of interested in

7
00:00:27,430 --> 00:00:30,640
just a little bit. Uh, I should probably
have said, well, welcome to blue book,

8
00:00:30,641 --> 00:00:35,170
but a lot of people here, I
haven't seen it yet. Um, so let's,

9
00:00:35,171 --> 00:00:37,640
let's talk a little bit about
first your background. Um,

10
00:00:37,660 --> 00:00:41,050
you started mostly as a writer,
um,

11
00:00:41,080 --> 00:00:45,670
and then producer and director of some
things as I'm a writer, you're a writer.

12
00:00:45,780 --> 00:00:49,960
Um, so what was it about this subject
matter in this film that made you go,

13
00:00:49,961 --> 00:00:51,310
this is the one I want to direct.

14
00:00:52,020 --> 00:00:54,240
Oh, uh, uh, nothing.

15
00:00:55,540 --> 00:00:56,373
All right.
Then

16
00:00:56,940 --> 00:00:57,890
it was a,

17
00:00:59,130 --> 00:01:03,360
I keep having this conversation
and I realize why, I guess,

18
00:01:03,361 --> 00:01:06,630
and it's because we kind of dignify the
role of a director and it seems like a

19
00:01:06,631 --> 00:01:09,780
really big deal. I've been working
for them for about 15 years.

20
00:01:10,080 --> 00:01:12,810
A lot of it with the same group of people.
For me,

21
00:01:12,811 --> 00:01:14,100
this is just part of a continuum.

22
00:01:14,101 --> 00:01:18,360
It's just another film with the same
group of people largely. And, um,

23
00:01:18,510 --> 00:01:22,140
there was no really significant difference
between this and the one before and

24
00:01:22,141 --> 00:01:24,870
the one before that. And,
uh, it, it's because we,

25
00:01:25,410 --> 00:01:28,320
the question stems from the fact that
we overstate the role of the director.

26
00:01:28,410 --> 00:01:29,340
But that's what I would say.

27
00:01:29,950 --> 00:01:31,510
But at the same time,
I think you,

28
00:01:31,870 --> 00:01:34,240
depending on the relationship you have
with someone who's directing your own

29
00:01:34,241 --> 00:01:35,590
material,
like you,

30
00:01:35,591 --> 00:01:39,100
you have to have a lot of trust in
them to be true to whatever you're an

31
00:01:39,110 --> 00:01:42,480
original intention was there. And that
that applies to the editor and you know,

32
00:01:42,490 --> 00:01:45,580
the actors as well. But, but by
being both the writer and director,

33
00:01:45,581 --> 00:01:48,280
you do have an extra
sort of level of control.

34
00:01:48,820 --> 00:01:49,120
Yeah.

35
00:01:49,120 --> 00:01:53,320
But now you've shifted the presupposing
onto the other directors and assuming I

36
00:01:53,321 --> 00:01:57,770
gave them that level of control, if
you see what I mean. And the, uh,

37
00:01:58,160 --> 00:02:02,470
uh, and really what it is, the key
thing you said is that the editor,

38
00:02:02,500 --> 00:02:06,850
the dop, the actors film
is, is broadly a color.

39
00:02:06,880 --> 00:02:09,580
It is a collaborative process.
Having come from books,

40
00:02:10,060 --> 00:02:14,290
which is not a collaborative process for
the most part, uh, I can stay film is,

41
00:02:14,320 --> 00:02:16,590
I think it would be fair to say, and, and,

42
00:02:16,720 --> 00:02:21,130
and all of the people in that film have
a real insignificant role and it's not

43
00:02:21,131 --> 00:02:23,230
just paying lip service to
it. They really, really do.

44
00:02:23,590 --> 00:02:27,610
That's why production companies fight
like crazy over who the dop is or who the

45
00:02:27,611 --> 00:02:30,550
production designer is.
If it was just observing the sort of,

46
00:02:31,020 --> 00:02:34,110
the vision of the director,
what difference, you know.

47
00:02:34,800 --> 00:02:37,760
Fair enough. Right. Um, okay.

48
00:02:37,761 --> 00:02:41,900
Well then what were some of your
influences for this particular story? Uh,

49
00:02:41,930 --> 00:02:46,850
sort of cinema about cinematically
and maybe I'm visually, uh, you know,

50
00:02:46,990 --> 00:02:50,870
the history of artificial intelligence
in cinema has definitely been something

51
00:02:50,871 --> 00:02:53,150
that's been portrayed in
many different ways. Yes. Um,

52
00:02:53,151 --> 00:02:54,920
so what were some of the
things that you drew from

53
00:02:55,580 --> 00:02:57,980
well, uh, uh,

54
00:02:58,040 --> 00:03:02,290
or that may not look it from the stories
I've sort of Zombie movies and stuff

55
00:03:02,291 --> 00:03:03,940
I've worked on previously.

56
00:03:03,941 --> 00:03:07,900
I tried to draw as much from real
life observation as possible. Um,

57
00:03:07,930 --> 00:03:12,220
I had got involved with a long running
argument, a good natured argument,

58
00:03:12,221 --> 00:03:15,820
but still an argument with
a neuroscientist friend of
mine who comes from that

59
00:03:16,210 --> 00:03:21,210
very respectable position that exists
within a theory of mind about humans,

60
00:03:21,791 --> 00:03:23,110
but also AI research,

61
00:03:23,111 --> 00:03:25,540
which basically says machines
and ever going to be conscious.

62
00:03:25,900 --> 00:03:29,800
There's something particular about
human consciousness that hasn't been

63
00:03:29,801 --> 00:03:31,900
understood yet.
And when we do understand it,

64
00:03:31,901 --> 00:03:35,950
we will see why machines are
precluded from ever being sent in.

65
00:03:36,340 --> 00:03:41,200
And um, uh, I think on an instinctive
level, I disagreed with him and then we,

66
00:03:41,440 --> 00:03:46,210
we sort of argued over years and mainly
this film comes out of that argument.

67
00:03:46,460 --> 00:03:46,740
Uh,

68
00:03:46,740 --> 00:03:51,250
I finally came across a book written by
the professor of cognitive robotics at

69
00:03:51,251 --> 00:03:53,470
imperial,
which is like our version of Mit.

70
00:03:53,710 --> 00:03:56,620
And it was about the relationship
between consciousness and embodiment.

71
00:03:56,621 --> 00:04:00,340
And he has a really sort of beautiful,
elegant argument in it, which,

72
00:04:00,520 --> 00:04:03,730
which combats I think quite effectively.
Some of the arguments I would hear.

73
00:04:03,731 --> 00:04:05,140
And so,
uh,

74
00:04:05,230 --> 00:04:09,370
and while I was reading that book and I
have to stress very hard for me to read

75
00:04:09,371 --> 00:04:11,470
that book and I could
only read sections of it,

76
00:04:11,710 --> 00:04:16,000
it's like mountain climbing for me. But,
um, uh, while I was reading that book,

77
00:04:16,001 --> 00:04:17,740
the idea for this film kind of arrived.

78
00:04:18,570 --> 00:04:23,130
Um, so you, you definitely delve into
some of the, the headier ish, you know,

79
00:04:23,880 --> 00:04:27,300
issues of what is, what is humanity,
but his personality, what is, you know,

80
00:04:27,301 --> 00:04:30,690
what is it, uh, Centene creature.

81
00:04:30,691 --> 00:04:33,990
And so what were sort of
some of the challenges of,

82
00:04:34,080 --> 00:04:38,250
of getting this heady topic material of
like subject matter and it has a lot of

83
00:04:38,251 --> 00:04:43,200
scientific implications to translate to
a cinematic story as well as something

84
00:04:43,201 --> 00:04:45,150
that is also a human story.

85
00:04:45,151 --> 00:04:49,470
And like not getting too bogged down in
the science but still convey it was a

86
00:04:49,471 --> 00:04:54,470
challenge. You picked a big challenge,
right? Your subject matter. Um,

87
00:04:55,270 --> 00:04:59,380
um, yeah, it was a, yeah,

88
00:04:59,381 --> 00:05:02,560
the guest there was a challenge
involved. Um, I was just trying to be,

89
00:05:02,980 --> 00:05:05,710
I was trying to be fair to
the subject matter I guess,

90
00:05:05,711 --> 00:05:09,790
and tried to be respectful about it and
really try to understand it within my

91
00:05:09,791 --> 00:05:14,190
own limitations as best as I
could before writing it. Um, uh,

92
00:05:14,260 --> 00:05:17,590
partly because I think it's
interesting and uh, um, it,

93
00:05:17,750 --> 00:05:21,730
it's an area where this is true of lots
of area of science at the moment where

94
00:05:21,731 --> 00:05:22,061
there's a,

95
00:05:22,061 --> 00:05:25,600
there's a kind of increasing vacuum
between the people who are actually doing

96
00:05:25,601 --> 00:05:28,570
this stuff and the, and the rest of
us who were trying to understand it.

97
00:05:28,900 --> 00:05:32,350
And so some of it's about trying to
bridge that vacuum as best as possible,

98
00:05:32,380 --> 00:05:35,950
but it's, it's really tough to do
that. Um, the thing about it is,

99
00:05:35,951 --> 00:05:40,951
is that any look strong AI also becomes
a look at human consciousness that the

100
00:05:43,661 --> 00:05:44,441
two are related.

101
00:05:44,441 --> 00:05:48,600
The problems of one a kind of the
problems of the other to an extent. Um,

102
00:05:48,910 --> 00:05:52,780
only to an extent. I don't personally
think that when a strong AI arrives,

103
00:05:52,990 --> 00:05:55,780
it will necessarily be like us.
In many ways.

104
00:05:55,781 --> 00:05:58,730
It may be completely different
from in almost always, but,

105
00:05:58,820 --> 00:06:02,690
but the issues and the conversations in
this current state of not understanding

106
00:06:02,960 --> 00:06:04,950
are very related. So, uh, yeah.

107
00:06:05,930 --> 00:06:07,750
Okay. Um, let's,

108
00:06:07,840 --> 00:06:11,600
let's talk about the more
human factors in your,

109
00:06:11,620 --> 00:06:16,310
you've had a really wonderful cast.
Um, I thought that, uh, Alicia,

110
00:06:16,540 --> 00:06:17,570
you see it. Yes. Uh,

111
00:06:17,590 --> 00:06:22,590
she brought just this really great quality
of sort of inhuman but human to the

112
00:06:24,851 --> 00:06:29,790
character of Ava and I'm sure that's
exactly what you wanted to had, uh,

113
00:06:30,040 --> 00:06:33,700
wanted her to bring to it. Were there
things that you worked on to kind of, uh,

114
00:06:33,910 --> 00:06:37,660
get her to telegraph that
sort of human but not

115
00:06:38,820 --> 00:06:42,160
she, she arrived with it?
Um, um, I mean we had,

116
00:06:42,190 --> 00:06:45,310
I'd seen her in other movies and we
had various conversations and stuff,

117
00:06:45,311 --> 00:06:49,090
but when she arrived, she had this site
there. She's a ballerina by training,

118
00:06:49,091 --> 00:06:52,900
so she has a terrific control over her
physicality as well as being a very,

119
00:06:52,901 --> 00:06:55,590
very good at. She was very
grateful. She was very gracious,

120
00:06:55,600 --> 00:06:59,980
almost unsettling in a character
way, but, well exactly.

121
00:07:00,010 --> 00:07:02,380
So do you know the VF that you know,
the Vfx team,

122
00:07:02,381 --> 00:07:05,320
cause you used to work in
Vfx uncanny valley. Yes.

123
00:07:05,530 --> 00:07:10,180
So what she did was a kind of uncanny
valley version of human motion.

124
00:07:10,181 --> 00:07:12,880
She said, I'm not, I'm not
going to act like a robot,

125
00:07:12,881 --> 00:07:16,000
what I'm going to do as human actions,
but I'm going to do them perfectly.

126
00:07:16,390 --> 00:07:19,390
And that perfection will
create a sense of otherness.

127
00:07:19,391 --> 00:07:23,450
Cause like when I'm sat on this chair
actually your rather sort of graceful by

128
00:07:23,480 --> 00:07:27,580
not and I sort of slouch and uh, if
I get up I have to sort of, you know,

129
00:07:27,581 --> 00:07:32,050
shove myself up and come back my middle
age and all that kind of stuff. And so,

130
00:07:32,140 --> 00:07:34,930
uh, whereas she does it with
this amazing sort of dance,

131
00:07:34,931 --> 00:07:39,400
has poise and it's hard to look at it and
say anything she does is sort of quote

132
00:07:39,401 --> 00:07:42,670
unquote wrong, but together it
creates this uncanny valley,

133
00:07:42,910 --> 00:07:44,320
slightly unnatural quality.

134
00:07:44,940 --> 00:07:46,980
Yes. Uh, so you wrap
the end, came to valley.

135
00:07:47,010 --> 00:07:50,880
And I thought I was almost afraid
seeing the trailers that, you know,

136
00:07:50,881 --> 00:07:53,280
all the footage was, it was
beautiful. And I was like, okay,

137
00:07:53,281 --> 00:07:55,890
I don't think they're going to hit it.
And you didn't, you didn't fall into that,

138
00:07:55,891 --> 00:07:59,550
which was amazing. But it's a
challenge, especially considering the,

139
00:07:59,700 --> 00:08:03,270
the anatomy of the main character for
the majority of the film. You know,

140
00:08:03,271 --> 00:08:08,271
we see her in this kind of robotic hybrid
synthetic like with a human face and

141
00:08:09,601 --> 00:08:13,620
it's a little unsettling. And at times
she's just so perfect looking that,

142
00:08:13,980 --> 00:08:14,930
you know,
but there's the,

143
00:08:14,931 --> 00:08:18,270
you've managed to still capture like
a human ish elements so it didn't hit,

144
00:08:18,660 --> 00:08:23,420
you know, the, the too cartoonish
and to humanoid. Um, it,

145
00:08:23,790 --> 00:08:25,530
yeah, that'll be great.
Congratulations on that.

146
00:08:26,860 --> 00:08:29,340
Thank sort of, I mean, the, um,

147
00:08:29,640 --> 00:08:32,520
the funny thing is
about people is that we,

148
00:08:33,030 --> 00:08:38,030
we are urges to project human like
qualities and to almost everything,

149
00:08:38,720 --> 00:08:43,110
it, it's, it's almost an effort to
stop it happening. Um, I mean there is,

150
00:08:43,111 --> 00:08:46,620
there's incredibly beautiful VFX and
there's beautiful production design and

151
00:08:46,621 --> 00:08:49,950
it's beautifully shot and it's beautifully
lit and all those kinds of things.

152
00:08:50,250 --> 00:08:51,930
But, uh, um,

153
00:08:51,960 --> 00:08:56,960
that thing of making this strange machine
believing that it has the qualities

154
00:08:57,241 --> 00:09:00,170
that we have, that's actually
really quite easy. I,

155
00:09:00,270 --> 00:09:03,930
the that is to say you could take
it with a child who, you know,

156
00:09:03,931 --> 00:09:06,500
it's probably quite hard to
find children that don't, uh,

157
00:09:06,570 --> 00:09:11,090
attribute sentience to they're cuddly
toys. Right. In, in some ways. And,

158
00:09:11,091 --> 00:09:14,670
and that's where I guess it begins when
in fact it probably begins because it's

159
00:09:14,671 --> 00:09:17,760
sort of semi coded into
us in some respects. Um,

160
00:09:17,970 --> 00:09:22,350
I was driving not that long ago with
an adult who is feeling pissed off with

161
00:09:22,351 --> 00:09:25,410
their car and kind of critical event and,
um,

162
00:09:25,530 --> 00:09:29,550
but didn't want to say so in front of the
car in case it hurt the cause feelings

163
00:09:29,551 --> 00:09:34,440
right. Now that that's a
grownup. Right. Um, and, uh, so,

164
00:09:34,620 --> 00:09:39,540
um, uh, and cause don't look much like
us pretty, you know, more or less.

165
00:09:39,930 --> 00:09:44,900
Um, so, uh, so yeah. Um, I mean, I
know you're being kind about the films,

166
00:09:44,910 --> 00:09:45,990
I'm not trying to be combative.

167
00:09:46,740 --> 00:09:51,480
It's your film is, it's a
collective, right? Yeah, sure. I,

168
00:09:51,560 --> 00:09:54,760
I, you know, I think there are a
lot of, of times when, you know,

169
00:09:54,970 --> 00:09:59,020
we see these sort of representation
of humanity but not humanity and,

170
00:09:59,320 --> 00:10:01,810
and you really want to project onto it.

171
00:10:01,811 --> 00:10:05,390
And what you had to do is kind of
combat that a little bit. You like

172
00:10:06,970 --> 00:10:11,970
a lot of the plot of it kind of hinges
on us accepting this artificial element

173
00:10:12,971 --> 00:10:14,050
to it. True. Um,

174
00:10:14,290 --> 00:10:18,400
true. So, so initially what you do
is in a very kind of upfront way,

175
00:10:18,430 --> 00:10:22,250
you say this is a machine and there's
no ambiguity. It's a machine, right?

176
00:10:22,980 --> 00:10:25,180
And there's all sorts of things
to force you to think that way.

177
00:10:25,181 --> 00:10:28,930
There's cavities where they shouldn't be
cavities and you can see through her in

178
00:10:28,931 --> 00:10:33,400
a way that, uh, sort of removes her
being like us, a girl in a suit,

179
00:10:33,650 --> 00:10:37,420
you know? And then the,
the, the task of the film,

180
00:10:37,421 --> 00:10:41,110
Mr Gradually have that machine
quality fall away. Right?

181
00:10:41,890 --> 00:10:45,340
Even though she looks kind of the same.
And,

182
00:10:45,400 --> 00:10:48,310
and to show just by behavior,
we will,

183
00:10:48,610 --> 00:10:51,100
we will forget the thing
that's right in front of us.

184
00:10:51,820 --> 00:10:56,710
Yup. Um, so the, the VFX team behind this
did an amazing job, you know, it was,

185
00:10:56,740 --> 00:10:58,970
it was fantastic and a shout out to them.
Uh,

186
00:10:59,290 --> 00:11:00,430
can you talk about working with them,

187
00:11:00,431 --> 00:11:05,320
especially having basically one of your
protagonist characters be mostly CG for

188
00:11:05,321 --> 00:11:06,340
a good portion of the movie?

189
00:11:06,600 --> 00:11:11,100
Yeah. Um, uh, well they were run
it, it's a company called DNA, uh,

190
00:11:11,120 --> 00:11:12,770
or double negative, which, uh,

191
00:11:12,900 --> 00:11:17,460
based in London where I live and work
and our team was run by a guy called

192
00:11:17,461 --> 00:11:21,480
Andrew Whitehurst. And, um,
in the course of my life,

193
00:11:21,481 --> 00:11:23,010
every now and then I've met some really,

194
00:11:23,011 --> 00:11:27,090
really smart people and I think he may be
the smartest guy I've ever met. I mean,

195
00:11:27,160 --> 00:11:31,850
he may or may not. It's, uh, but, but he's
certainly going to be in the top tier. Um,

196
00:11:32,020 --> 00:11:32,230
the,

197
00:11:32,230 --> 00:11:36,530
the thing about him that is so interesting
is he's got a real gift for sort of

198
00:11:36,540 --> 00:11:39,390
poetry in a way, you know, that
beauty and things like that.

199
00:11:39,391 --> 00:11:43,690
So I remember one day he said, look,
I've got this great idea, which is to uh,

200
00:11:43,770 --> 00:11:46,560
hang plastic strips inside her form,

201
00:11:46,561 --> 00:11:50,310
which will diffuse the
light in a particular kind
of way and make us slightly

202
00:11:50,311 --> 00:11:53,290
more mysterious even though you can
see the machinery. And so that's,

203
00:11:53,320 --> 00:11:55,450
that's a lovely kind of poetic idea.

204
00:11:56,260 --> 00:11:59,980
And then another day we ran into
this massive quality control issue.

205
00:11:59,981 --> 00:12:02,710
It's kind of technical and I
will fail to explain it properly,

206
00:12:02,711 --> 00:12:07,480
but basically we were getting, because of
the way the images on the Sony cameras,

207
00:12:07,481 --> 00:12:10,450
we'd use it being sort of
processed or something. I Dunno,

208
00:12:10,510 --> 00:12:15,370
we were getting these weird straight
pixels and I'm in big flat areas of color.

209
00:12:15,490 --> 00:12:17,230
Suddenly there'd be these straight pixels.

210
00:12:17,470 --> 00:12:20,680
And we had a problem because we were going
to fail a quality control thing to do

211
00:12:20,681 --> 00:12:24,010
with the distributor when we handed the
film over and he said, ah, don't worry,

212
00:12:24,011 --> 00:12:24,821
I'll fix that.

213
00:12:24,821 --> 00:12:29,800
And he wrote some piece of code over
like a week and it reprocessed all of the

214
00:12:29,801 --> 00:12:32,440
imagery and it fixed it and made
it go away. So I'm thinking,

215
00:12:32,740 --> 00:12:34,380
I don't know how to talk to this guy now.

216
00:12:34,390 --> 00:12:38,260
He's just like such got a range of
abilities. It's just unreal. So thanks.

217
00:12:38,350 --> 00:12:42,690
That's impressive. Um, what, what, uh,

218
00:12:42,960 --> 00:12:47,040
what sort of mixture of it was working
with that team and working with the

219
00:12:47,041 --> 00:12:48,750
actors in terms of,
you know,

220
00:12:48,870 --> 00:12:51,680
integrating this character because
if it had gone wrong, the movie,

221
00:12:51,810 --> 00:12:53,250
we would have been lost as an audience.
You know,

222
00:12:53,251 --> 00:12:56,400
you would've been in snap out of it and
it would have probably hit that weird

223
00:12:56,401 --> 00:12:59,040
uncanny valley in the wrong
way. In the wrong way. Yeah.

224
00:12:59,090 --> 00:13:03,300
Yes. So, uh, yeah, I mean, my,

225
00:13:03,990 --> 00:13:08,990
my approach to filmmaking in my approach
very much played out in this film is

226
00:13:09,031 --> 00:13:13,110
about, uh, this is gonna sound
like corporate speak, right?

227
00:13:13,200 --> 00:13:18,200
But it's about these different departments
having a lot of communication between

228
00:13:18,571 --> 00:13:21,720
each other and also a lot of autonomy.
Um,

229
00:13:22,050 --> 00:13:25,470
and that would include the actors and
it would clean the VFX team and the

230
00:13:25,471 --> 00:13:30,340
composers and, and so on. So it's
not, it's not separate group. It's,

231
00:13:30,350 --> 00:13:35,350
it's sort of roughly like
what you'd imagine anarchy
would be like ideally where

232
00:13:35,761 --> 00:13:40,620
you have autonomous groups not
kind of chucking bricks but uh,

233
00:13:40,770 --> 00:13:43,140
but kind of agreeing about a common goal.

234
00:13:43,710 --> 00:13:46,680
I think that's the key is agreeing
about a common goal and then,

235
00:13:46,860 --> 00:13:51,300
and then having a lot of independence
and autonomy within it. And uh, um,

236
00:13:52,130 --> 00:13:55,530
uh, any department you could mention
that would have been the approach.

237
00:13:55,660 --> 00:13:57,050
Hmm.
Well,

238
00:13:57,100 --> 00:14:01,490
so speaking of the subject matter that
I'm working with technical technically

239
00:14:01,520 --> 00:14:02,360
challenging things,

240
00:14:02,361 --> 00:14:05,990
a lot of your sort of subject
matter is this sort of futuristic,

241
00:14:07,190 --> 00:14:10,820
but I want to do like a little bit
apocalyptic in terms of like 28 days later

242
00:14:10,821 --> 00:14:15,740
and sunshine was the, like if we have
to restart that sun and apocalypse,

243
00:14:15,770 --> 00:14:20,570
uh, uh, they're, they're sort
of very challenging things
that, uh, to accomplish.

244
00:14:20,600 --> 00:14:21,590
I think visually,
you know,

245
00:14:21,591 --> 00:14:26,240
you need to have a lot of trust in the
teams that are taking these to task.

246
00:14:26,300 --> 00:14:30,740
Um, has that ever like the
challenge of it ever influenced you?

247
00:14:30,741 --> 00:14:32,810
Have you ever thought, oh,
maybe I want to do this?

248
00:14:32,811 --> 00:14:36,080
Or you just go with the creative process
and just trust the trust your teams to

249
00:14:36,081 --> 00:14:36,914
make it work.

250
00:14:37,100 --> 00:14:40,130
Well, you've got to aim
high. Right. And, uh,

251
00:14:40,350 --> 00:14:43,070
and I think one of the things
is that broadly speaking,

252
00:14:43,100 --> 00:14:46,610
if people feel like they're aiming high
and they're having to work slightly

253
00:14:46,611 --> 00:14:50,320
outside of their comfort zone, they
raise their game. And, uh, that,

254
00:14:50,370 --> 00:14:54,290
that's just kind what
happens. And, uh, um, it, the,

255
00:14:54,291 --> 00:14:57,820
the key is the vibe in
a way. You know, it's,

256
00:14:57,821 --> 00:15:02,510
it's like the atmosphere of it
where, um, uh, it, it's not,

257
00:15:02,660 --> 00:15:07,580
it's very easy with collaboration
to have it work with lip service.

258
00:15:07,640 --> 00:15:08,660
You sort of say, yeah, yeah,

259
00:15:08,670 --> 00:15:11,780
we're collaborative and just would
you mind doing it this way? You know,

260
00:15:11,781 --> 00:15:15,540
and then we'll be really collaborative
slightly later and so on. Um,

261
00:15:15,680 --> 00:15:18,760
but I think if you in almost in four set,
uh,

262
00:15:18,980 --> 00:15:21,830
provided you've got the right people
at works great. I have to say,

263
00:15:21,831 --> 00:15:24,800
I've worked on films where it's been just
the most miserable experience and it's

264
00:15:24,801 --> 00:15:28,640
been completely horrified. It is. It is
down to the people you're working with.

265
00:15:28,850 --> 00:15:33,850
The collaboration can turn into mush
really easily if you're working with a no,

266
00:15:34,120 --> 00:15:36,560
I'm going to stop
talking, but um, but yeah.

267
00:15:36,660 --> 00:15:39,330
Well tell me you want to be in the
trenches with, you know, it's, it's, yeah,

268
00:15:39,360 --> 00:15:41,820
when it comes down to the can feel
like editing and stuff like that,

269
00:15:41,821 --> 00:15:45,720
like who is going to be a positive
influence on the creativity as opposed to

270
00:15:45,750 --> 00:15:49,960
just doing decent typically. Yeah.
Is the main thing. It's okay.

271
00:15:50,160 --> 00:15:52,030
It's a good metric. Um, what,

272
00:15:52,050 --> 00:15:55,200
what are some of the experiences that
you've had previously that you brought to

273
00:15:55,201 --> 00:15:59,100
this filmmaking experience that
you thought really, you know, I,

274
00:15:59,101 --> 00:16:01,260
it sounds like you've worked
for some of the team before.

275
00:16:02,190 --> 00:16:03,630
Like what were some of the
things that you thought,

276
00:16:03,631 --> 00:16:07,890
I really need to bring this to the table,
uh, when approaching this, this film?

277
00:16:08,250 --> 00:16:09,540
Well actually a lot of it,

278
00:16:09,600 --> 00:16:13,380
I don't know if it it in a way it's
of interest to anyone by I'd worked in

279
00:16:13,381 --> 00:16:17,250
science fiction that would have been
stemmed originally from some kind of

280
00:16:17,251 --> 00:16:21,840
science conceit by entropy, heat
death or something like that. And um,

281
00:16:22,140 --> 00:16:26,310
uh, and, and had sacrificed
at a certain point, uh,

282
00:16:26,340 --> 00:16:31,340
anything resembling rationality for
story concerns about adrenaline or,

283
00:16:31,651 --> 00:16:32,160
or,
you know,

284
00:16:32,160 --> 00:16:36,780
perceived story concerns about a
journaling and what would I really felt.

285
00:16:36,960 --> 00:16:39,480
My main goal with this form was,
uh,

286
00:16:39,660 --> 00:16:43,170
I may never get to do this
again for all sorts of reasons.

287
00:16:43,171 --> 00:16:44,520
I may never get to do this again.

288
00:16:44,521 --> 00:16:49,521
So I'm just going to try as in my sphere
in this table with many legs to just do

289
00:16:50,341 --> 00:16:52,230
it right,
to do it as right as I can.

290
00:16:52,440 --> 00:16:56,820
Not compromise on anything at all
by literally nothing in my sphere.

291
00:16:57,180 --> 00:17:00,360
And, um, uh, so I guess
that was the main thing.

292
00:17:00,570 --> 00:17:05,040
Film has terrific
influences to compromise,

293
00:17:05,250 --> 00:17:09,830
built into the fabric of how they get
made and how they get distributed in

294
00:17:09,831 --> 00:17:12,000
finance and all sorts of things.
And in this instance,

295
00:17:12,001 --> 00:17:13,170
it was to step away from that.

296
00:17:13,540 --> 00:17:16,960
That's it's having, it's great
that you were able to do that. Uh,

297
00:17:16,970 --> 00:17:19,830
I think that's something that
a lot of directors strive for.

298
00:17:19,831 --> 00:17:24,170
And then when it comes down to
then making the decision, they,

299
00:17:24,171 --> 00:17:27,840
they end up having to compromise through
whatever set of circumstances they

300
00:17:27,841 --> 00:17:32,010
might be the guys requiring
the compromise. But that
that's also very possible.

301
00:17:32,100 --> 00:17:34,380
Um, what, uh,

302
00:17:35,370 --> 00:17:39,090
actually speaking of the
collaboration element of it, um,

303
00:17:39,150 --> 00:17:42,590
can you talk about working with rob hardy
or cinematographer because if even the

304
00:17:42,600 --> 00:17:45,680
film was very like beautifully
shot. Yeah. Um, and I think it,

305
00:17:45,681 --> 00:17:50,340
it just all sort of tied visually
together with this beautiful artificial

306
00:17:50,341 --> 00:17:54,850
creature and, and then this
beautiful setting. And um, yeah.

307
00:17:54,900 --> 00:17:56,010
How did you work with him to

308
00:17:57,660 --> 00:18:01,390
rubs just an artist? He did. It's very
important. It's, it's quite interesting.

309
00:18:01,430 --> 00:18:06,280
You can put any camera in his hands and
he will just find a way to frame the

310
00:18:06,281 --> 00:18:10,450
thing. And, um, uh, it, if you,

311
00:18:10,900 --> 00:18:14,260
it's like not knowing how to play guitar,
I guess it's kind of,

312
00:18:14,261 --> 00:18:17,680
if you don't know how he's doing it,
but you can see how good he is.

313
00:18:17,681 --> 00:18:21,820
It's truly mysterious. There's something
really, uh, kind of weird about it.

314
00:18:22,150 --> 00:18:26,810
Um, he's, he's just a very,
very talented dop and, uh,

315
00:18:27,020 --> 00:18:31,810
uh, he's, he's known in the scene, I
guess for being very good anyway. And,

316
00:18:31,811 --> 00:18:35,510
um, uh, he, he, he and I, uh,

317
00:18:35,740 --> 00:18:37,900
been close to working
together before on a movie,

318
00:18:37,910 --> 00:18:40,940
never let me go with about
four years ago. And he was, uh,

319
00:18:41,140 --> 00:18:43,180
one of the dops in the
frame for that film,

320
00:18:43,181 --> 00:18:46,330
but it didn't work out for
various reasons. Um, but he was,

321
00:18:46,360 --> 00:18:50,920
he was just like the perfect choice for
this because he's kind of sense your and

322
00:18:50,921 --> 00:18:53,200
warm and,
uh,

323
00:18:53,290 --> 00:18:57,630
Scifi can be quite antiseptic and
clinical. It sort of goes to the,

324
00:18:57,740 --> 00:19:00,070
the hospital and you know,

325
00:19:00,120 --> 00:19:05,120
Saifai and his instinct is about almost
like dropping a gauze over everything

326
00:19:05,950 --> 00:19:10,030
and being soft and zen like,
and so I, he was perfect for it.

327
00:19:10,170 --> 00:19:10,680
Yeah,
I think,

328
00:19:10,680 --> 00:19:14,640
I think zen is a great adjective to
describe the second setting of the film.

329
00:19:14,641 --> 00:19:14,851
You know,

330
00:19:14,851 --> 00:19:19,851
it's this beautiful retreat and woods
and waterfalls and rivers and it's like,

331
00:19:21,390 --> 00:19:25,350
it's somewhere I'd want to
vacation. Yeah. It's available.

332
00:19:25,700 --> 00:19:30,230
Rent gets it now.
Um,

333
00:19:30,330 --> 00:19:32,580
it might have an extra guest in it still.

334
00:19:34,000 --> 00:19:38,070
It's a hotel. Oh, we showed it
and I tell in Norway, um, uh,

335
00:19:38,360 --> 00:19:43,310
it's a really core eco hotel and um,
the landscape is absolutely stunning. I,

336
00:19:43,311 --> 00:19:48,311
one of the funny things about film is
that it both loves and hates familiarity,

337
00:19:48,570 --> 00:19:53,410
you know, and uh, finding a landscape
that has not been well used in film,

338
00:19:53,560 --> 00:19:54,393
it's quite difficult.

339
00:19:54,580 --> 00:19:57,610
I've noticed there's been like tons
of movies recently that I've used.

340
00:19:57,611 --> 00:19:59,140
Icelanders are location.
Yeah.

341
00:19:59,310 --> 00:20:03,520
And once you get sort of zoned into
that Iceland Vibe, you think, oh,

342
00:20:03,521 --> 00:20:06,970
we're back here again even, or are you
thinking consciously or unconsciously?

343
00:20:06,971 --> 00:20:11,410
Actually and um, uh, Norway
had something special about it.

344
00:20:11,411 --> 00:20:15,460
There's a kind of bleakness in it.
It's beautiful and very majestic,

345
00:20:15,461 --> 00:20:18,040
stunning skies and mountains
and waterfalls, as you said.

346
00:20:18,280 --> 00:20:21,940
But there's something a bit kind
of hard to bed kind of bleak.

347
00:20:22,340 --> 00:20:25,970
Um, was it, I'm going to assume it
was at a point to justice position,

348
00:20:25,980 --> 00:20:30,630
kind of the nature of
factor with the natural

349
00:20:32,520 --> 00:20:35,400
elements, maybe not a natural
next evolution elements of

350
00:20:35,860 --> 00:20:38,380
highly,
highly contained,

351
00:20:38,410 --> 00:20:41,080
controlled environment created by a man,

352
00:20:42,290 --> 00:20:46,300
a completely uncontrolled
environment created by no one,

353
00:20:46,990 --> 00:20:48,160
those two arguably.

354
00:20:49,690 --> 00:20:51,800
And uh, um, I taught this in detail.

355
00:20:53,000 --> 00:20:55,580
Uh,
speaking of the kind of control element,

356
00:20:55,581 --> 00:21:00,310
everything did feel very even plot wise
and, and behavior wise of the characters.

357
00:21:00,320 --> 00:21:02,510
Everything felt very planned in a,

358
00:21:02,511 --> 00:21:06,170
in a good way in a keeping the
audience on their toes and like what,

359
00:21:06,171 --> 00:21:10,730
who is in charge of what, who's making
the decisions, who is, you know,

360
00:21:10,731 --> 00:21:14,090
who's playing, who was the puppet
master, kind of a in a lot of ways.

361
00:21:14,091 --> 00:21:16,920
And was it tough to kind of keep the,

362
00:21:16,921 --> 00:21:20,780
the audience's trust for some of
that and say like, no, go with me.

363
00:21:20,781 --> 00:21:23,030
Like you'll figure out who and,
or,

364
00:21:23,031 --> 00:21:26,780
or did you want to kind of keep people
a little disoriented the whole time?

365
00:21:26,940 --> 00:21:29,630
Um,
what are the,

366
00:21:31,420 --> 00:21:33,130
the thing that,
there's a funny thing about film,

367
00:21:33,131 --> 00:21:36,050
which is that you can assume
literacy on the part of the viewer.

368
00:21:36,730 --> 00:21:38,860
It's not necessarily true in books.

369
00:21:39,070 --> 00:21:42,850
You could write a book which
alludes to heart of darkness,

370
00:21:43,270 --> 00:21:46,390
but you would not be able to assume
they'd read Conrad and read heart of

371
00:21:46,391 --> 00:21:50,650
darkness. Whereas with a film viewer,
you can pretty much assume, for example,

372
00:21:50,710 --> 00:21:53,740
they've seen blade runner, right? Uh,

373
00:21:53,770 --> 00:21:56,740
and in fact you might even be able to
assume they've seen apocalypse now,

374
00:21:56,741 --> 00:21:59,630
which is based on hard in some respects.
But so,

375
00:21:59,631 --> 00:22:02,920
so that is this funny thing about the
wave film works and what it, it's,

376
00:22:02,921 --> 00:22:06,340
it's kind of a free gift in terms of
what you were talking about in terms of

377
00:22:06,341 --> 00:22:08,950
that relationship with the
audience because some of
these things have been well

378
00:22:08,951 --> 00:22:11,230
established and then you can
use them to your advantage.

379
00:22:11,230 --> 00:22:12,550
So in the case of this film,

380
00:22:13,270 --> 00:22:18,220
a smart literate film
viewer is very quickly,

381
00:22:18,221 --> 00:22:21,640
almost immediately you're going to be
thinking she's not the robot. He is.

382
00:22:21,730 --> 00:22:24,190
It's just going to be an automatic
assumption. They're just going to do it.

383
00:22:24,580 --> 00:22:27,730
And then what you can do is
use misdirection and nudge
them a little bit further

384
00:22:27,731 --> 00:22:30,730
towards that because he's got oddly
symmetrical scars on his back,

385
00:22:30,970 --> 00:22:34,030
which has for justification within
the narrative about a car crash.

386
00:22:34,031 --> 00:22:38,740
But you're thinking, yeah, that's not
why. And, and the, uh, and so, you know,

387
00:22:38,741 --> 00:22:42,220
so you use that stuff to your advantage.
It's, it's, uh, it's very useful.

388
00:22:42,490 --> 00:22:45,190
But the basic function of this film is to,
is,

389
00:22:45,240 --> 00:22:48,070
is it's intending to set
up a series of questions.

390
00:22:48,430 --> 00:22:52,810
Some of the questions it's setting
up it like where does gender reside,

391
00:22:52,870 --> 00:22:57,430
for example, it doesn't then
necessarily have an answer to it.

392
00:22:57,880 --> 00:22:58,520
And in fact,

393
00:22:58,520 --> 00:23:03,070
it might be saying it is impossible to
present a clear answer to some of these

394
00:23:03,071 --> 00:23:07,420
questions about consciousness or gender
or AI or whatever it happens to be at

395
00:23:07,421 --> 00:23:09,340
this moment in time.
We're not able to do that.

396
00:23:09,341 --> 00:23:13,690
But that doesn't negate the reason to ask
the question and have the conversation.

397
00:23:13,691 --> 00:23:18,490
And it's basically an idea's movie.
It's, it's to provoke conversation and,

398
00:23:18,790 --> 00:23:21,730
and to hopefully do it in a sort
of respectful and thoughtful way.

399
00:23:22,090 --> 00:23:23,560
What would be the intention?
Yeah,

400
00:23:23,570 --> 00:23:26,090
I think, I think it absolutely
accomplished that. And you know,

401
00:23:26,120 --> 00:23:29,780
you mentioned the scars on the back
and that was one of the things that

402
00:23:29,781 --> 00:23:32,210
immediately after the movie was
talking about, it's like, wow,

403
00:23:32,211 --> 00:23:34,250
I wonder if that was part
of something else or do you,

404
00:23:34,270 --> 00:23:38,750
are we meant to thank you so robot
and, um, but it, you know, it's,

405
00:23:38,751 --> 00:23:42,230
it's exactly where you want the audience
to go with it, which is misdirection.

406
00:23:42,710 --> 00:23:45,650
Right? But it's still,
it, it helped it frame.

407
00:23:45,710 --> 00:23:49,010
I'd try to talk about without spoiling
anything, you know, it helped,

408
00:23:49,610 --> 00:23:53,430
it helped frame later
events in the film, uh, and,

409
00:23:53,431 --> 00:23:56,570
and create this sort of
tension until the end, which,

410
00:23:56,600 --> 00:23:58,820
and I won't say exactly
what happens in the end,

411
00:23:58,821 --> 00:24:03,500
but the ending was just fantastic and
thank you for, thank you for kind of not,

412
00:24:04,150 --> 00:24:08,780
not giving us what we expected.
I think it kept true to the sort of the,

413
00:24:08,781 --> 00:24:13,670
the, the feeling and plot you'd set
up prior to the very ending. And, uh,

414
00:24:14,030 --> 00:24:17,380
I think if you'd gone with
this sort of cliche route, uh,

415
00:24:17,410 --> 00:24:21,530
we might have been a little disappointed.
Yeah, it wouldn't, no, it would have been,

416
00:24:21,531 --> 00:24:23,420
it still would have been satisfying.
But I think the,

417
00:24:23,690 --> 00:24:28,300
the sort of way that I can I just say it.
You say what you like,

418
00:24:29,630 --> 00:24:34,370
I'm going to spoiler alert warning
here. Um, so, uh, no, at the end.

419
00:24:35,370 --> 00:24:39,830
Oh yeah, sorry. Um, but if, if you
know, the, the way that the robot,

420
00:24:40,160 --> 00:24:44,600
sorry, maybe I won't, he's shaking his
head. Oh nevermind. I was, spoiler alert.

421
00:24:44,630 --> 00:24:49,150
It's great. Go see it. I'm
okay. Either way. The ending
is fantastic. Thank you. Um,

422
00:24:49,310 --> 00:24:53,450
and it's unexpected and I think it really
does like service to your audience and

423
00:24:53,451 --> 00:24:54,590
trusting them and saying like,

424
00:24:54,591 --> 00:24:58,400
here are all the points and I trusted
you to come up with this unable reward

425
00:24:58,401 --> 00:25:01,210
that with keeping true to the characters.
Thank you.

426
00:25:01,430 --> 00:25:03,860
I'm sorry for almost point linkage.

427
00:25:05,810 --> 00:25:10,010
Um, let's see what else. Uh, I want
to talk to a little more about,

428
00:25:10,130 --> 00:25:13,820
about the actors, sort of what was the
process? Cause it's a very limited cast.

429
00:25:13,940 --> 00:25:15,020
Yeah.
Um,

430
00:25:15,050 --> 00:25:20,050
Donald Gleason was a great and sort of
charming in this almost innocent way.

431
00:25:21,260 --> 00:25:22,093
Um,

432
00:25:23,770 --> 00:25:26,730
I'd worked with him twice before. So, uh,

433
00:25:26,950 --> 00:25:29,680
I knew donor would be really
good for this and, uh,

434
00:25:29,710 --> 00:25:31,960
actually just simply called him
up one day and said, hey, look,

435
00:25:31,961 --> 00:25:33,790
I'm going to send you a
script. What he'd do it. Uh,

436
00:25:33,791 --> 00:25:38,470
I mean obviously if he didn't want to do
it, I can make it. Uh, so, so yeah. Uh,

437
00:25:38,510 --> 00:25:43,210
try as I might. So, so that, that was
donut. And then with the other two, um,

438
00:25:43,510 --> 00:25:47,800
uh, the thing about actors is, and I
really think this is a fair statement,

439
00:25:47,801 --> 00:25:51,220
is that there's no mystery to good
actors. When you see it, you just know it.

440
00:25:51,221 --> 00:25:54,190
When you see it. It, it's, it's
hard to find somebody who would say,

441
00:25:54,191 --> 00:25:57,070
Phillip Seymour Hoffman was a bad actor.
He was sort of evident in the,

442
00:25:57,071 --> 00:26:00,550
an incredibly good actor.
That tends to be the case with good ones.

443
00:26:00,700 --> 00:26:02,020
You don't need to be an expert.

444
00:26:02,470 --> 00:26:06,560
This film required the
costing of good actors, uh,

445
00:26:06,600 --> 00:26:09,460
that there is a kind of actor who
isn't necessarily a good actor,

446
00:26:09,461 --> 00:26:11,410
but they have an enormous
amount of charisma.

447
00:26:11,710 --> 00:26:14,170
And that can be fantastic
for certain kinds of films.

448
00:26:14,171 --> 00:26:18,520
Charisma is just what you want to make it
function. Uh, but this particular film,

449
00:26:18,521 --> 00:26:23,320
they needed to be act as a of
a certain type really. And, um,

450
00:26:23,590 --> 00:26:24,850
so,
so that was,

451
00:26:24,880 --> 00:26:29,280
that was the pool we were
drawing from Oscar Isaac. Uh,

452
00:26:29,440 --> 00:26:32,560
I'd seen them in lots of
stuff actually. Uh, and um,

453
00:26:32,650 --> 00:26:36,910
he's one of those guys who within the
industry is incredibly buzzy and uh,

454
00:26:36,970 --> 00:26:39,750
and very,
very well respected and Elisia for candor.

455
00:26:39,760 --> 00:26:43,140
I'd seen her in a Danish movie
called a royal affair. Um, right.

456
00:26:43,200 --> 00:26:47,130
I'm going to guess she was in her early
twenties or maybe even late teens when

457
00:26:47,131 --> 00:26:52,131
she shot that she's acting opposite
mads Mikkelsen who's a fantastically

458
00:26:52,770 --> 00:26:56,310
experience charismatic and
terrific actor as well.

459
00:26:56,490 --> 00:26:59,960
And despite that, you, your eye just goes,

460
00:27:00,240 --> 00:27:05,160
she's got that magnetic ability that
some people have. And uh, so she was,

461
00:27:05,161 --> 00:27:08,370
she was perfect that that was
essentially the, the roots I suppose.

462
00:27:08,430 --> 00:27:11,620
I think she did such a lovely
job move. Yeah. She's, she's

463
00:27:12,150 --> 00:27:16,910
shouldering this interesting kind of
dead lucky with that cost.

464
00:27:17,420 --> 00:27:22,180
And, and going back to Oscar, Isaac,
um, you know, thinking, Oh yes,

465
00:27:22,220 --> 00:27:26,540
that the dancing was just so
unexpected and phenomenal. Um,

466
00:27:27,110 --> 00:27:29,720
but he, uh, he had his sort of
charisma of his own and you know,

467
00:27:29,721 --> 00:27:32,810
not necessarily the sort of big
boisterous Hollywood personality charisma,

468
00:27:32,840 --> 00:27:36,800
but the character itself had a very
interesting kind of draws you in,

469
00:27:36,801 --> 00:27:39,950
makes you want to, you know,
find out what he's doing.

470
00:27:39,951 --> 00:27:43,040
And I think that was sort of
integral to the plot of it, you know,

471
00:27:43,041 --> 00:27:47,730
is having this guy who makes you
want to find out more. Um, yeah.

472
00:27:47,900 --> 00:27:52,670
Is that part of the reason you cast him
or is that something you saw in him or

473
00:27:52,671 --> 00:27:54,980
is that something that kind of
came out later in the process?

474
00:27:55,050 --> 00:27:59,460
No, no, no. I mean that, that was the
intention of the story. I mean he, he's a,

475
00:27:59,910 --> 00:28:04,350
it's a tricky thing because he's the CEO
of a big Tech Company and immediately

476
00:28:04,351 --> 00:28:08,070
that leads people to think
he's kind of aimed at somebody.

477
00:28:08,160 --> 00:28:10,410
But it wasn't really that at all.
I mean,

478
00:28:10,411 --> 00:28:12,500
in a way I was thinking more
about people like Oppenheimer.

479
00:28:12,520 --> 00:28:16,770
There's lots of red because AI as we know,

480
00:28:16,771 --> 00:28:20,730
because we're informed by Stephen Hawkins
and Elon Musk and people like that is,

481
00:28:20,910 --> 00:28:24,810
has, has latent potential for
being extremely dangerous. And, uh,

482
00:28:24,811 --> 00:28:27,900
and I think that has to be true.
It is, it is potentially dangerous.

483
00:28:27,901 --> 00:28:31,050
But I also think it's reasonably
analogist with nuclear power,

484
00:28:31,080 --> 00:28:35,820
which is also dangerous, but it doesn't
stop us using it. And, um, uh, and,

485
00:28:35,821 --> 00:28:37,320
and I'm basically in favor of Ai.

486
00:28:37,321 --> 00:28:41,180
I think it's terrific and I'm fascinated
by it and sort of all power to it. What,

487
00:28:41,181 --> 00:28:45,810
maybe not all but a
lot of power to it. Um,

488
00:28:45,900 --> 00:28:48,960
and, uh, so, so the thing with,

489
00:28:49,020 --> 00:28:52,100
with Oscar's character was to be a kind
of Oppenheimer like character who's

490
00:28:52,110 --> 00:28:54,820
conflicted about what he's
doing as he's doing it. And,

491
00:28:55,050 --> 00:28:57,810
and it's up to the audience in a sense to,

492
00:28:58,050 --> 00:29:02,730
to understand where he's really coming
from because he presents himself as being,

493
00:29:02,920 --> 00:29:07,440
uh, incredibly kind of misogynistic and
predatory and then actually violent.

494
00:29:07,710 --> 00:29:08,880
And then you have to decide,

495
00:29:08,881 --> 00:29:12,120
is this an act he's putting on for
the purposes of this experiment?

496
00:29:12,330 --> 00:29:14,040
Or is it real?

497
00:29:14,130 --> 00:29:18,950
Or is it something in himself that he's
helplessly amplifying for the experiment?

498
00:29:19,190 --> 00:29:21,040
Like w there's all sorts of,
uh,

499
00:29:21,360 --> 00:29:26,360
things that it could be an Oscars are
very kind of liquid actor and that kind of

500
00:29:28,381 --> 00:29:33,150
set of challenges of where you, where
are you at this moment in a scene is,

501
00:29:33,380 --> 00:29:37,530
is exactly what kind of turns him on
really and get some going. So yeah,

502
00:29:37,960 --> 00:29:38,510
I think it's,

503
00:29:38,510 --> 00:29:42,370
it's also a testament to the writing of
the character and the portrayal by the

504
00:29:42,371 --> 00:29:43,180
actor.
But it was,

505
00:29:43,180 --> 00:29:48,040
it was one of the more sort of complex
characters that I didn't know if how you

506
00:29:48,041 --> 00:29:51,670
want it to like, you know, identify with
him or support him or just be like, oh,

507
00:29:51,680 --> 00:29:52,513
you're horrible.

508
00:29:53,040 --> 00:29:56,450
Well, you were invited. Clearly
to think that is horrible.

509
00:29:56,680 --> 00:29:58,340
There are several stages
of the film where it,

510
00:29:58,360 --> 00:30:01,250
where it is almost
instructing the viewer to say,

511
00:30:01,251 --> 00:30:06,080
feel deeply suspicious and uncomfortable
with this guy. Um, however,

512
00:30:06,830 --> 00:30:09,020
there's another thing as well,
or at least I hope there is,

513
00:30:09,021 --> 00:30:11,240
which is that sometimes
the things he's saying,

514
00:30:11,241 --> 00:30:16,070
even though he sounds like he's
wrong or actually true. Um,

515
00:30:16,250 --> 00:30:16,881
and so it,

516
00:30:16,881 --> 00:30:20,990
it's the ability to hear past what's
something sounds like it is to actually

517
00:30:20,991 --> 00:30:22,320
what it is, right. It was

518
00:30:23,030 --> 00:30:26,770
vehicle that's delivering it as opposed
to the actual message. Um, yeah,

519
00:30:26,771 --> 00:30:31,420
he's an interesting vehicle to deliver
it. We'll try it. Yeah. Yeah. Um,

520
00:30:31,880 --> 00:30:36,300
so yeah, you say you're in favor of
artificial intelligence and to a degree,

521
00:30:36,500 --> 00:30:38,540
yeah. Which I mean, like strong.

522
00:30:38,580 --> 00:30:41,870
I mean these AI sort of conflate
so many different things.

523
00:30:41,880 --> 00:30:45,290
This AI and phones and video
games and I mean, do you know,

524
00:30:45,291 --> 00:30:48,950
we're talking about strong
AI, right? To use that term,

525
00:30:49,900 --> 00:30:50,733
generally.

526
00:30:50,890 --> 00:30:54,310
What, what was it like working with
the science advisors on this? Um,

527
00:30:54,390 --> 00:30:55,260
just because I didn't know,

528
00:30:55,261 --> 00:30:59,550
you mentioned this conversation with your
ongoing discussion that led to a movie

529
00:30:59,551 --> 00:31:03,120
with that and your neuroscience
scientists. Right. And, and I'm, I'm,

530
00:31:03,150 --> 00:31:05,820
I'm going to go ahead and guess that
there were a lot of science advisors

531
00:31:05,821 --> 00:31:06,780
involved because the,

532
00:31:07,620 --> 00:31:12,440
there were three particular in advisors.
There was a lady called GM, Milena vetch,

533
00:31:12,441 --> 00:31:16,640
and there was a geneticist to also
fronts, uh, uh, a radio show actually,

534
00:31:16,641 --> 00:31:21,641
which is sort of trying to disseminate
scientific discussion on radio four BBC

535
00:31:22,030 --> 00:31:26,750
thing, uh, called Adam Rutherford. But
there was this guy, Murray Shanahan, and,

536
00:31:26,900 --> 00:31:31,130
uh, he was, um, he works
at imperial and, uh,

537
00:31:31,850 --> 00:31:35,570
he was the guy, all of these
people, what I said is, look, I,

538
00:31:35,660 --> 00:31:39,290
I've attempted to write this thing as
best as I can understand it from the

539
00:31:39,291 --> 00:31:43,820
literature and from a youtube videos
of lectures and stuff like this.

540
00:31:44,060 --> 00:31:47,300
Check it, be really, really
tough on it. If it seems wrong,

541
00:31:47,540 --> 00:31:51,530
if this is an inaccurate representation
of Mary and the black and white room or

542
00:31:51,531 --> 00:31:55,730
whatever it happens to be as a thought
experiment or whatever, tell me now,

543
00:31:55,731 --> 00:31:58,200
obviously it's got two big conceits in it.
There's,

544
00:31:58,370 --> 00:32:03,370
there's a robot that has a level of
robotics that clearly doesn't exist yet.

545
00:32:04,530 --> 00:32:06,950
Uh, yeah, sure. Yeah. But, but doesn't,

546
00:32:07,160 --> 00:32:10,790
and there's also a machine that
really does seem to be sent to you,

547
00:32:11,000 --> 00:32:15,990
and that also doesn't exist.
Um, uh, I, I'm probably yet, um,

548
00:32:16,280 --> 00:32:17,300
so,
uh,

549
00:32:17,420 --> 00:32:20,540
so there's a limit to how much you can
advise on something which is fiction,

550
00:32:20,590 --> 00:32:25,130
right. But, but to be reasonable about
the subject was the key thing I think.

551
00:32:25,920 --> 00:32:30,270
Um, and have, have you sort of applied
the same thing to your, your password?

552
00:32:30,271 --> 00:32:31,080
Because I mean they've,

553
00:32:31,080 --> 00:32:35,940
no, no, I haven't. I haven't and that's
why I did it with this because, uh,

554
00:32:35,970 --> 00:32:40,760
I felt like I had let down the
subject matter previously. And,

555
00:32:41,010 --> 00:32:43,460
um,
so when I'm talking about earlier,

556
00:32:43,461 --> 00:32:45,560
when we were chatting
about not compromising,

557
00:32:45,620 --> 00:32:48,470
that's basically what I'm
talking about. Um, uh,

558
00:32:48,480 --> 00:32:51,290
I feel frustrated with some of that stuff.
So yeah,

559
00:32:52,190 --> 00:32:56,520
I think it puts you in a sort of position
where you, you might be given, you know,

560
00:32:56,521 --> 00:32:59,820
if he'd come back and say Xyz doesn't
work because of this, you know,

561
00:32:59,830 --> 00:33:02,820
puts you in a tough position where you
might have to compromise on your own work.

562
00:33:02,821 --> 00:33:03,460
So,

563
00:33:03,460 --> 00:33:07,000
no, because then I wouldn't have done
it, but, but the, but the key was a,

564
00:33:07,001 --> 00:33:11,710
you make it cheaply that if you want
creative freedom, make it for less money.

565
00:33:12,430 --> 00:33:17,120
Oh, I, I meant plot wise and stuff
like that. Okay. All right. All right.

566
00:33:17,150 --> 00:33:19,180
Nevermind that in any terms

567
00:33:19,270 --> 00:33:22,080
you can think of, the less money you
make it for them, more freedom you got.

568
00:33:23,850 --> 00:33:28,060
Yeah. Um, so what, uh, what are
some of your, you know, what,

569
00:33:28,061 --> 00:33:32,340
what other subjects would you like
to delve into going forward? Um, um,

570
00:33:32,370 --> 00:33:33,600
what are some of the other
things that interest,

571
00:33:33,790 --> 00:33:35,050
well,
I'm trying to,

572
00:33:35,051 --> 00:33:39,610
I've just finished the script a have
a really fascinating novel called

573
00:33:39,611 --> 00:33:42,230
annihilation written by a guy called
Jeff and Amir Mirror. And I'm going to,

574
00:33:42,320 --> 00:33:45,130
I'm trying, I've tried to adapt
that and I'm going to wait.

575
00:33:45,190 --> 00:33:48,460
I'm in the process now what I'm out here
in the states of trying to set that up

576
00:33:48,461 --> 00:33:53,060
and hopefully we'll
succeed. And, um, uh, um,

577
00:33:53,110 --> 00:33:58,110
I came across this very
interesting argument that
talked about how well the all

578
00:33:58,241 --> 00:34:03,010
life on the planet is cellular and um,
and it has,

579
00:34:03,340 --> 00:34:04,840
there's an argument which is,

580
00:34:04,870 --> 00:34:08,470
has actually some evidence attached
to it incredibly, which is the,

581
00:34:08,530 --> 00:34:10,960
all of those cells are
derived from one cell,

582
00:34:11,320 --> 00:34:13,720
which actually makes logical sense
when you start to think about it.

583
00:34:13,721 --> 00:34:16,250
But I never had stopped
to think about it and um,

584
00:34:16,360 --> 00:34:18,610
that is a truly extraordinary idea.

585
00:34:18,640 --> 00:34:22,150
That's one of the reasons I liked science
and I liked science fiction is because

586
00:34:22,151 --> 00:34:26,570
I think it puts these really
fundamental, fascinating, uh,

587
00:34:26,710 --> 00:34:29,190
sort of ideas into your head. And so, um,

588
00:34:29,470 --> 00:34:31,300
I guess that's what I'm
fixated on at the moment.

589
00:34:31,690 --> 00:34:33,870
That's a very interesting subject to you.

590
00:34:34,340 --> 00:34:37,850
You kind of approach the starch
macro things that make us,

591
00:34:38,120 --> 00:34:42,930
I feel like examine when she like it
is to be human almost, isn't it? Yeah.

592
00:34:43,010 --> 00:34:43,600
It makes you think

593
00:34:43,600 --> 00:34:47,600
good about the future in the
past and where you are in it.

594
00:34:47,740 --> 00:34:48,160
But there's,

595
00:34:48,160 --> 00:34:53,160
I guess there's an approach to it also
that is a sort of looking at it from the

596
00:34:53,381 --> 00:34:56,470
human standpoint on it as opposed to
like just a purely scientific because

597
00:34:56,471 --> 00:34:59,050
there's a way to tell those stories
and explain like, you know, like,

598
00:34:59,080 --> 00:35:01,360
oh well we became from one
cell as opposed to being like,

599
00:35:01,361 --> 00:35:04,580
think about the ramifications
of this. Um, and,

600
00:35:04,590 --> 00:35:08,440
and exploring that as opposed to just
how to presenting scientific evidence.

601
00:35:08,530 --> 00:35:12,030
Yeah. Um, well, uh, I'll ask what's, um,

602
00:35:12,100 --> 00:35:15,460
what's one piece of advice that you
wish you could've given yourself before

603
00:35:15,461 --> 00:35:20,210
going into this project? What, this one?
Yes. And then going to your next one. No,

604
00:35:20,890 --> 00:35:21,723
nothing.

605
00:35:21,830 --> 00:35:24,080
It was all cool.
It was great.

606
00:35:24,140 --> 00:35:26,850
It was a good bunch of people and it
worked out in the way it was supposed to.

607
00:35:26,870 --> 00:35:29,840
I've never been able to say that before,
but I can say about this.

608
00:35:30,610 --> 00:35:31,151
What's that?

609
00:35:31,151 --> 00:35:34,540
What's one thing in particular that you
draw from this experience that you'd

610
00:35:34,541 --> 00:35:35,410
like to bring into the next one?

611
00:35:35,411 --> 00:35:38,910
Is it the not compromising is with
most people work with nice people.

612
00:35:38,970 --> 00:35:42,180
I think that's a great thing.
Um,

613
00:35:43,050 --> 00:35:48,030
I think we cool. We cool. Thank
you so much for joining us. Uh,

614
00:35:48,070 --> 00:35:52,080
eczema keynote will be out in
theaters. Uh, got it. Thanks so much.

615
00:35:53,650 --> 00:35:53,780
Okay.

