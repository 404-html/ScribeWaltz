Speaker 1:          00:00          Hello world, it's a Raj. And today we're going to build a support vector machine to classify two classes of data. I've already recorded this video before, but I'm rerecording it because the sound quality and the video quality was not good. And we have a standard to keep on this channel. So listen up. Here we go. We're going to build a support vector machine to classify two classes of data, right? And the way we're going to optimize the support vector machine, this type of machine learning model is to use gradient descent. Okay? So that's what we're going to do. And this is what it looks like it, it looks like this. So say we've got two classes. We have one class that's going to be denoted by red dots and the other class is going to be to noted by blue dots. So if we were plucked both classes on a two d graph, an x y graph, then we could draw a line, a decision boundary that best separates both of these classes.

Speaker 1:          00:58          And that line is called a hyperplane. And our support vector machine helps us create it. Okay? That's what are support vector machine helps us do and we're going to talk about all the details of how this thing works, but this is at a high level what it looks like and we're going to build it with just num Pi and nat plot libe okay to graph it. So no tensorflow or any of that. All right, so I hope you're as excited as I am for this because we are going to go into the theory as well as the code as well. Okay, here we go. So to start off with, what are some use cases for an Svm? So classification is one which we're going to do and that is in fact the main case that svms are used for. That is the most popular case, but they can also be used for other types of machine learning problems.

Speaker 1:          01:46          Regression, that is if we have some set of data points and we're trying to predict the next point in that set of data. So to stock prediction would be a good example. And also type Oracle also called time series prediction. There's also outlier detection. So say you have a security system and you're tracking all of your users and all of your users have a set of metrics I set of features that identifies them like the time that they've logged in and what they're doing. There could be an anomaly and you anomaly could be or bad guy, the guy who's trying to break into your security system and the spms help you detect who that person is. And there's also clustering but we're not going to talk about which, which is also um, which is a form of unsupervised learning learning as his outlier detection. But we are going to do supervised classification.

Speaker 1:          02:33          That is when our data has labels, right? We are trying to learn the mapping between the labels and the data. And if we learn the mapping, that is a function. The function represents the mapping, the relationship between these variables. If we learn this function, then where machine learning model has done its job, then we can use this function to plug in some new input data and it's going to output the prediction, right? And this is all of machine really. So let's look at the toe. In this example, we're going to use toy data, right? Because it's more, it's, it's about the, it's about the math and the algorithms. But I have these two other examples for you just in case you want to do something a little more useful. So the first one is for handwritten digit classification, right? You have are we have a set of digits and they all had their labels and we want to learn the mapping between the labels and the digits.

Speaker 1:          03:27          And so that's what this repository will help us do. And the great thing about this repository is it's using psychic learn, which is a very popular machine learning library. In one line of code, you could implement an Svn, but we're going to implement it from scratch because we want to learn how this thing works. But once you've done that, then you can go on to using something easier, something simpler like this. Okay? And it's a real world use case. I've got one more example here that I've, that I have for you guys. And that's where pulse classification. So the idea is that for a human given, some metrics like their age and their eye, what was the other one? Their pulse rate. Obviously we can predict what their emotions will be. So it's emotion classification and we're using an SVM in this repository as well as well as psych yet learned to implement that STM.

Speaker 1:          04:15          So check out those two repositories once you really understand the math behind support vector machines from this video and from the associated code. Okay. So, uh, yeah, so those are two other examples. So how does this thing compare to the other machine learning algorithms? And there are so many of them. There are random forests, there are neural networks. Well, as a rule of thumb, svms are great if you have small datasets. So I'm saying like a thousand rows or less of data, right? 1,000 data points or less. If we have that, then svms are great for classification and they are very popular. However, other algorithms, random forests, deep neural networks, et Cetera, require more data, but almost always come up with a very robust model. And the decision of, of which classifier to use depends on both your problem and your data. And as you build this mathematical intuition, all of these choices will become very clear to you.

Speaker 1:          05:16          So we're starting off with the support vector machine. Okay? And so I also have this quote by this famous a computer science professor, Donald Knuth, who now I know the chaos silent Donald Knuth who said that premature optimization is the root of all evil or at least most of it in programming. And what does he mean by that? That means if you can make a performance gain by using something way more complicated, like a deep neural network, but it's only going to be like it's only going to be by like 0.1% then it's unnecessary. Your time as a programmer is very valuable and you will only want to do the minimum amount of work that you have to, to get the results that you want. So if you're trying to use a neural network for problem that only requires something very simple, like a support vector machine, you should use the support vector machine, not the deep neural network, just because it's hot and it's outperforming everything else almost all the time because it requires more computing data and way more, uh, it requires more computing power and way more data, right?

Speaker 1:          06:17          Two things, um, which if you don't have, don't use it, use a support vector machine, right? These are all methods of intelligence. This is all about the math of intelligence. And there are many ways to approach it. So what is a support vector machine? So this thing can be used for both classification is that this is it, this is it. This and regression got these points. What's the next point in a series? So given two or more labeled classes of data, remember we are using supervised learning. It can create a discriminative classifier that is a classifier that can discriminate between different classes. Is it this, is it this is it this? Right? And the opposite to discriminative, by the way, is generative. Where we generate new data. We take some training data variated very it in some way using our model and that output is very similar to the train data but it's novel data.

Speaker 1:          07:11          But that's for later on anyway. So the way we build this hyperplane and we'll talk about that term, but the way we build this hyper plane or line, this decision boundary between the classes is by maximizing the margin that is the space between that line and both of those classes. What do I mean by that? When I say both of those classes, what I actually mean are the points in each check out this image or the points and each of those classes that are closest to the decision boundary and these points are called support vectors. Okay. We call them support vectors because they are vectors. They are data point vectors that support the creation of this hyperplane that are support vector machine. We'll create, right? So we are maximizing the margin. And why do we do that? Because we want to draw a line that is in the absolute perfectly, that perfect middle spot between both of these sets of data such as, so that when we plot a new data point, if, if it is of a certain class, it will have the maximum likelihood of falling on that side of the decision boundary where it should.

Speaker 1:          08:20          And the only way to do that, to maximize the space with which a new data point can fall into its correct class category is to maximize the space between data points and put a line right in the middle of that space. You see what I'm saying? I can't get feedback, but I'm just going to assume that, that, that that was intuitive, right? So right, so small margin, we're maximizing the margin and we're Tryna draw a decision boundary, a line of best, not a line of best fit, but align of best classification between both of those. And we call this line a hyperplane. Okay. So what is a hyperplane? Well, I hyperplane is a decision surface. So given end dimensions, right? So let's say our data is end dimensional, where n is the number of features that you have length with high tongue color, tongue color.

Speaker 1:          09:10          Where did that come from? Tongue color and skin color and whatever other colors. And so, um, a hyperplane is n minus one dimensions. So if you have a two dimensional graph where, just like this on the left, right here where I'm pointing my mouse, we're with this, our symbol with a two exponent denotes a two dimensional graph. A hyperplane would then be two minus one, right? And minus one. So one dimension. So it would be a lie, right? But if, if we are in three dimensional space or are two the three, then a hyperplane is going to be two dimensional because it's three minus one, which is to, right? So we have a plane and so you, we can extrapolate this to many dimensions. So if we had a 400 dimensional space, which we often do in machine learning, our data doesn't just have two or three features.

Speaker 1:          10:01          It has many, many features, right? It's not so neatly packaged for us to visualize. And that's where techniques like dimensionality reduction and all this come into play, which we'll talk about. But right now if we have a 400 dimensional space, a graph of points than a hybrid plan would be 399 dimensions, which we can't really visualize. I mean, think about it, humans, we are not that good at visualizing or in fact it's impossible for us to visualize anything and more than three dimensions. But for machines it's very easy. It's very intuitive and that's all that matters. As long as our machine is able to draw this decision boundary of n minus one dimensions, then given some new data point, if we put it into that model, that functions, that functions, um, if we put it into that function, if we plug it in and it's going to output the correct class of whatever it is.

Speaker 1:          10:55          Okay, so, and this actually comes from geometry. So I guess there is a little bit of geometry in machine learning, right? So nonlinear versus linear. Well, we're only going to talk about linear classification because nonlinear classification is more complicated and we'll get to that. But the idea here is that let's say you have some, uh, some sets of data, some, some two datasets, right? Two classes of data, the best, let's say the best, uh, the line that best separates these two classes of data isn't linear. Let's say it's got curves like in this, in this example right here, how are we supposed to build a hyperplane like that? It would, well, it would be more complicated and there is actually a trick to do this called the kernel trick and we'll talk about that later. But there's a way to take that map, that input space into a feature space such that the hybrid plan that you draw is linear even though it wouldn't be otherwise.

Speaker 1:          11:49          And so that's called the kernel trick and we'll talk about that later, right? So we're only talking about linear classification for support vector machines, supervised linear classification, right? As opposed to unsupervised. Anyway, there's so many different ways that we can frame this problem, right? There's so many different ways we can frame the learning process and more will be discovered. He was a very exciting time to be in this field. Okay. So let's get, let's go ahead and uh, get to building shall we? But first of all, I also want to say a one more thing. So no matter what model you're using, a random forests and support vector machine, a deep neural network, in the end we are approximating, we are guessing, uh, iteratively close. We are getting, we're educated guests. I'm trying to think of a different word for approximation, but we are approximating a function, right?

Speaker 1:          12:39          We are trying to find what is the, what is that optimal function and that function represents the relationship between all the variables in our data, right? That function is, that is that is that relationship. It's that mapping and if we can find that function then we have learned, we have learned from our data and so every machine learning model under the hood is just a function that we are trying to approximate and it's coefficients are, it's weights and they are being updated over time, through some optimization technique. Be that gradient descent usually or Newton's method, which we'll learn about or you know, whatever it is. Okay. So, yeah, so whatever it is, we're just trying to approximate a function, right? This is a way of thinking approximating a function, whatever we're using, decision forest, whatever we're using, it's all about approximating a function. Decision. Trees.

Speaker 1:          13:28          All right, so let's go ahead and get and get to building, right? So first we're going to uh, important num pi and so num Pi is going to help us perform math operations, matrix math and then we're going to plot our data using map plot line. Okay, so this first step is for us to define our data. So our data is going to be of this form x, y bias. So the first, so they're five data points here, right there, five data points and we've got the x coordinate the y coordinate and we've just input our bias into our data to make things easier later on. But we can, for all intensive purposes, ignore this bias term, but we are basically just ha we had these set of x, y coordinate Paris that we can plot on a graph and each of these data points has an associated label, an output label.

Speaker 1:          14:17          That output label is either a negative one or a one. Okay. So for the first two, they're going to be negative one. And for the last three they're going to be one. So these last three, so what we can do is we can plot these examples on a two d graph. Okay? So we can say, let's plot the, let's plot the first two with the negative marker and let's plot the last three with the positive marker. Okay? And so when we plot, it looks like this. And what we're also going to do is we're going to print as, we're going to plot a possible hyperplane that is a hyperplane that is just the line. And we don't know, it's just our naive guests. We don't know if it's the optimal hyperplane. In fact it's not, but it just so happens to perfectly separate our training data classes.

Speaker 1:          15:02          Just so for us to just see what it looks like, right? This is just for that example. Okay, so that's that. So now what we can do is get into the math. So I hope you're ready for this. All right, so let's get into our calculus. All right, so right machine learning machine learning is all about optimizing for an objective function. And the way we optimize for an objective function is by minimizing a hope. You said loss or error function, because that is the correct answer. We are minimizing a loss for air function. So let's go ahead and first define our loss function. Our loss function in this case is going to be called the hinge loss. So the hinge loss is a very popular type of loss function for support vector machines. Okay. And the class of algorithms that support vector machines fall under our maximum margin classification algorithms, right?

Speaker 1:          15:52          We are trying to maximize the margin that is the distance between classes such that we can draw the best, uh, decision boundary between those classes that best separates both of those classes. Okay, so this is what it looks like. This is what the hinge loss looks like. The hinge loss looks like this with the word. See, that's how we did note the hinge loss. Given these three terms, the three terms are going to be x, Y, and f of x, where x is the sample data. Why is the true label and f of x is the predicted label, right? So it's going to be one minus y times F of x, and this little plus sign down here just means that if this result, if the result of this op, these sets of operations is negative, then we're going to just set it to zero because we always want the results to be positive, okay?

Speaker 1:          16:44          So what this means is that we can break this down into this equation right here where my, where my mouse is now over where we can say if y times F of x is greater than or equal to one, which would make this come out to be one minus a number that's greater than one, which would be zero or a negative number, then set the result to zero because we want it to be positive. And if it's not, then it's going to be some non negative number greater than zero. Okay? So that's our loss. That's how we define our loss. And remember these, this why and this f of x. Both of these values, the scalar values, these single values are going to be a single number, right? And that's what, that's why we can multiply them. And so our objective function then is going to consist of the loss function, which noticed how it looks a little different, but it's, it's really the same thing.

Speaker 1:          17:32          This one minus y times x, uh, XW. It's the same as this lost up here. It's just a different way of denoting it. And we can say the sigma term means that we are we to take a sum of terms where the number of terms is n and n is the number of data points that we have. So for all five data points, we'll find the loss of each of those data points using this, this loss function, the hinge loss, and we'll sum them all up together. And that that total sum will represent our total loss for our data, right? That's a single number. It's going to be a single number. And then once we have that, we're going to define our objective function. So our objective function, in this case, it's going to be denoted by this men lambda w okay, with the square sign. And so what is this? All right, so our objective function is going to be denoted by the loss plus this regular riser term, which is denoted right here with this men and the lambda. So a regular riser is, is a tuning knob. And what the regular riser does is it tells us

Speaker 1:          18:33          how best to fit our data. So if the regular riser term is too high, then our model will be over fit to the training data. And it's not going to generalize well to new data points. It's going to be over fit, but at the regularize or term is too low, then our model is going to be under fit. So that means going to be to generalize and it will have your large training error. So we need the perfect regularize or term two for our model to be as generalizable as possible and fit to our training data. It's that balance term, right? And it says it's also, it's also comes out to be a single scalar. So given our weights are we square that? Um, and then we use this lamp, lend the term here. Uh, we multiply by the, by this slime to term. Okay.

Speaker 1:          19:15          So, um, right? So that's our objective function or objective function consists of our regular riser and our loss function. We add them both together. So what we wanna do is we want to optimize for this objective. And by optimizing for this objective, we're going to find the optimal regularize their term, and we're going to, uh, minimize a loss. So we're going to do two things by optimizing for this objective. And so the way we're going to optimize is we're going to perform gradient descent, right? And so the way we're going to perform gradient descent is by taking the partial derivative of both of these two terms of both of these terms. We're going to take the partial derivative of the regular riser, and we're going to take the partial derivative of the, um, of the loss term. Okay? So this is what it looks like, right? So remember from the power rule for partial derivatives, all we have to do is move the power to the coefficient and then subtract one from the coefficient. And then for the other term we do the, we do the same thing. And so for the last term we do the same thing and it comes out to this and so it's, it's going to be zero or it's going to be negative y times x. So there's a, there's a case for both of them.

Speaker 2:          20:33          Okay.

Speaker 1:          20:33          Okay. So then what we, what we then have is a misclassification condition. Any classification condition. So we can, so we can, so basically we can say if it's misclassified, so if we miss classify our data depending on these partial derivatives, then we can update our weights a certain way. And what I'm, what do I mean by certain way? I mean we can update our weights by using both the regular riser term and the loss function term. Okay. Because this isn't zero, it's going to be negative y times x, but else, yeah. If, if we, if we have correctly classified, then this value is going to be zero. It's going to be a zero. So we don't need to update our loss. We only update our reg. We only update our weights using our regular riser term. And so this term right here is a learning rate, by the way.

Speaker 1:          21:19          So it's weights plus learning rate times the regular riser term. The learning rate, by the way, is how we, um, it's our, is another tuning knob for how we, uh, how fast we learn. So if the learning rate is too high, as our model is learning, it could just, it could just miss, it could just overshoot that minimum entirely. You could just keep going, but if it's too low, you can take way too long to converge, or in fact, a good, just never converge. So we want to have that optimal learning rate. Okay? So those are our terms. And so now,

Speaker 3:          21:53          mmm,

Speaker 1:          21:56          now let me plug into some power here. Okay, so then, so now let's get into the code for this, right? We've talked about the math. Let's get into the code. So for the code part, we can say, all right, well, we want to initialize a support vector machine. We're going to perform stochastic gradient descent, by the way, but we're going to initialize a support vector machine with a set of wage factors and he's weight factors are the coefficient of the model that we're trying to approximate. There are three values that we initialized with a set of Zeros. Then we have a learning rates, which has won a number of epox, which is a number just iterations to train for over the Dataset over the entire Dataset. And then a list of errors we're going to store all of our errors in. Okay. So basically we could say, and now here's the machine learning part.

Speaker 1:          22:43          Here's all of that math that we just did. We can fit into these 10 lines of code, right? We are literally just taking those equations and converting them into code right now. So we'll say for the number of epochs for, so for 100,000 times we'll set up an error to initially zero let's iterate through every single data point that we have. So for all five data points, so we have five data points. We're going to iterate through all of them 100,000 times. Okay. And so then we have our first case, which is the misclassification case. So in the misclassification case, let's see what that was. Y times x w is less than one. This is exactly what it comes out to programmatically. Why Times the dot product of acts in w is when it's less than one. So if it's less than one, then we have misclassified our data so we can update our weights using that full.

Speaker 1:          23:36          A equation that we saw were right up here, right up here where we're using both our regular riser and our loss function to update weights, right? Because this is non zero, it's going to be negative y times x using our partial derivatives. And our Parkville derivatives are the gradient, right? They are the, they are the gradient value that so that we can update our weights in a direction such that such that the such that the error is minimized. That's what they're going to help us do. Okay. And so we'll update our weights doing that and then we'll say, well we got an error, so let's make our error account one else. If we've correctly classified, then we update our weights using just the regular riser term, which is one over the number of epochs. By the way, are regularize a term. I think I might've forgotten to say that our regular riser term is one over the number of epochs.

Speaker 1:          24:27          So it's inversely correlated so that the regular riser parameter will decrease as a number of epochs increase. And so the update rule for correct classification looks like this. We're only using the regular riser term. All right? So we've got that. And so once we have that, we can plot it out and we'll also, uh, add all those errors to this list of errors. So we just have that, you know, we want to see how the error frequency decreases over time during training. That's the actual machine learning. And so when we plot that, we'll see that the error decreases over time. The air value decreases over time, and that's what we want, right? So we've trained our model, right? We've trained it on those five toy data points. And so now what we can do is we can now plot this model. We can plot this model and uh, we can, we can add testing data as well.

Speaker 1:          25:24          Bright. But we have it, we had a misclassification case and we had a correct classification case and depending on whether he was misclassified or classified correctly, we updated or weights using a different strategy. Okay. And the whole goal is to make those weights the optimal values that they should be such that our error value is minimized. And we have the equations for that right here. And the reason we took the partial derivative derivative is so that we can best up there weights to optimize for our objective function, which consists of these two terms, minimizing the loss and optimizing the regular riser term such that our data is best fit to both our training data and any novel data points we give it. That is, it's generalize ability, right. So hopefully that all makes sense. That's essentially what we just did. If you, if you understood like 80% of that, pat yourself on the back because you are a boss.

Speaker 1:          26:18          All right. We are all bosses. All right. So machine learning bosses. Okay. So back to this. Okay. So now we're going to plot this data. All right, so let's plot it. So if we have less than two sample exam samples, then we'll apply it again. So this is the same thing that we did before. So we'll do, we'll do it again and then we're going to add our test samples. So our test samples are going to be just two points and they're also going to be two toy data points. But just assume that we know what class this data points, you know, consist of until add our two test samples, plot our hyperplane that train on the training data and hopefully it classifies both the training data and the testing data accurately such that they all lie on the perfect, uh, side of the decision boundary so that they are correctly classified.

Speaker 1:          27:08          And so when we plot it, we'll see that that is the case. All the positive labeled data points are on one side of the line and all the negative label data points are on the other side of the line. We have correctly classified both our training and our testing data by optimizing for our objective. And by doing so, we are minimizing our hinge loss so that we maximize the margin or the space between the two data classes so that we can draw the optimal hyperplane and we use a regular riser term that we also, uh, found the optimal value for it by including it in the objective function so that our model was best fit to both the training and the testing data. All right. So that in a nutshell is how support vector machines work. So, um, two to go over, uh, this again, let me just say that.

Speaker 2:          28:06          Okay.

Speaker 1:          28:07          Right. So the gradient is a vector whose components consist of the derivative. So in all of Calculus we have derivatives. And so the reason we take the derivative is because calculus is this is the math of the rate of change. We want to know how something changes and the way we, we study how it changes. We use it in physics a lot to write for moving bodies. The derivative is how we is, is, is how we is, how we understand which direction and something is moving in, right? It's, we derive the direction from it. And there's several ways of representing the derivative. In Calculus, we use the, obviously the derivative, which is the derivative operator, but then we also use the gradient operator. And so the gradient, and so you hear these terms a lot, you hear gradient and you hear derivative a lot, but they're really the same thing in that the gradient is a vector whose components consist of the partial derivatives of whatever coefficients of whatever function that we're trying to approximate.

Speaker 1:          29:06          Okay. And so that's the gradient and the derivative and [inaudible]. In the next week's lesson, we're going to talk about the Jacobian, which is a matrix of first order partial derivatives and also the Hessian, which is a matrix of the second order partial derivatives. And these are all words that represents how we organize and represent change in data in in functions, right? And we, the reason we want to represent change is so that we can minimize her loss, we can optimize for an objective, we can iteratively get closer and closer to approximating to educatedly guessing what the optimal function is. So that we learned the mapping between data points. Okay. So, hopefully that all made sense. All right, so that's it for this lesson. Please subscribe for more programming videos, and for now I'll get to go invent a new type of Svm. So thanks for watching.