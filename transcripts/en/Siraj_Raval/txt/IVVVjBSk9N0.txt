Speaker 1:          00:00          Been trying to nets and down in losses. Men, I feel just like a rock star. Hello world, it's arrived and lost functions are a crucial part of the machine learning pipeline, but knowing which one to use can be kind of confusing. I'll explain how and when to use six popular loss functions by using two examples, a music genre classifier and a budgeting app for hospitals. The process of learning from data to find a solution to a question is machine learning. Ideally the Datas that we find has labels making it a supervised problem. The learning process is all about using the training data to produce a predictor function. This is a function that takes inputs x and tries to map them to labels why we went the predictor to approximately work even for examples that it hasn't yet seen before in the training data that is, we want it to be as generalized as possible and because we want it to be general, this forces us to design it in a principled mathematical way, which would delight three blue one brown for each data point x, we start computing a series of operations on it.

Speaker 1:          01:15          Whatever operations our model requires to produce a predicted output, we then compare that predicted output to the actual output to produce an error value and that error is what we minimize during the learning process. Using an optimization strategy like gradient descent. The way we're actually computing that error value is by using a loss function. It quantifies how wrong we be if we use the model to make a prediction on x when the correct output is why we're trying to minimize it. Unfortunately, there is no universal loss function that works for all kinds of data. It depends on a lot of factors like the presence of outliers, the choice of machine learning algorithm, the time efficiency of gradient descent and the confidence of predictions. The idea behind our loss functions originates from the mathematician Claude Shannon's information theory, which he proposed in 1948 like a boss. The goal is to reliably and efficiently transmit a message from a sender to a recipient.

Speaker 1:          02:26          Digital messages are composed of bits and bits either equals zero or one. Not all bits are useful though. Some can be redundant, so when we communicate a message we want as many relevant bits to be sent as possible. In Shannon's theory to transmit one bit of information means to reduce the recipients uncertainty by a factor of two. For example, say that two teams are playing against each other in the World Cup with a 50 50 chance of either team winning. If a prediction service tells us that one team will win, they've reduced our uncertainty by a factor of two. There were two equally likely outcomes. Now there's just one. The prediction service sent us a single bit of useful information. That bit could be a string, an image. It could consist of many bytes of data, but he can still be represented as one bit of useful information.

Speaker 1:          03:28          Suppose there were eight possible teams that could win the World Cup all equally likely. If the service tells us the likely team to win, they're dividing our uncertainty by a factor of eight, which is two to the power three so they sent us three bits of useful information. We can compute the number of bits that were communicated by computing the binary logarithm of the uncertainty reduction factor, which is eight in this example, let's say though that the possibilities are not equally likely, say one team has a 75% chance of winning and the other 25% if the service says the less probable team will win, then the uncertainty has dropped by a factor of four which is two bits of information. The uncertainty reduction is the inverse of the events probability. The log of one over x is equal to the negative log of x, so the equation to compute the number of bits comes out to minus the binary log of the probability 25% we can compute the same for the other team.

Speaker 1:          04:41          We can sum up these values to compute an average number of bits. The service will tell us, and this is considered the entropy, it measures the average amount of information that we get from one sample drawn from a given probability distribution. P it tells us how unpredictable that probability distribution is. The more variation in the data and the larger the entropy. The Cross entropy is the average message length. We can express this as a function of both the true probability distribution key and the predicted distribution cue. If our prediction is perfect, then the cross entropy is equal to the entropy, but if the distributions differ than the cross entropy will be crater than the entropy of by some number of bits. This amount that the cross entropy exceeds the entropy is called the relative entropy also called the back Leibler divergence. We can write this out several ways, so in the context of ml we can categorize loss functions very broadly into two types classification and regression loss.

Speaker 1:          05:56          Let's start with classification. Assume we have a problem where we have a music dataset. It's a bunch of songs in the form of MP, three files with labeled genres, no mumble rap. Thankfully when we make a prediction using are trained the model, it'll output a bunch of class probability values, one for each genre in question for our loss. Let's try using cross entropy. Also called log loss. Sometimes it's the equation we saw earlier and it measures the performance of a classification model whose output is a probability value between zero and one the cross entropy loss increases as the predicted probability diverges from the actual label, so predicting a probability of say 0.024 when the actual observation label is one would be bad and it would result in a high loss value. The ideal model would have a log loss of zero. If we were to graph out the range of possible loss values given a true observation like he's rock music equals one we can see that as the predicted probability approaches one the log loss slowly decreases, but as the predicted probability decreases, the log loss increases pretty fast.

Speaker 1:          07:19          This log loss penalizes both types of errors, but especially those predictions that it's confident are inaccurate. We can denote it using sigma notation, so we'll sum up the negative logs of all the predicted probabilities multiplied by y for as many classes as there are and that will give us our error. It uses the negative log to give us an easy metric for comparisons. That's because the positive log of numbers less than one returns negative values, which can be confusing to work with when comparing the performance of two different models. There's also another commonly used type of loss function in classification tasks called the hinge loss. Usually in support vector machines, it penalizes predictions not only when they are incorrect, but even when they are correct but not confident. It penalizes predictions that are really off in a big way. Those that are just slightly off, a little less but confidently correct predictions are not penalized at all.

Speaker 1:          08:27          We can formalize this by writing it out. In the case of binary classification here, our labels, why are either one or negative one so the loss is only zero when the signs and match an age of x is greater than or equal to one for example, if our score for a specific data point was 0.3 but the label was negative one we get a 1.3 penalty. If our score was negative 0.8 as in this instance was predicted to have labelled negative one we'd still get a penalty of 0.2 but if we predicted negative 1.1 we'd get no penalty. Hinge loss is easier to compute than the cross entropy loss. It's faster to train via gradient descent since a lot of the time the gradient is zero so you won't have to update the weights if you need to make real time decisions with lesser accuracy.

Speaker 1:          09:20          Depend on the hinge loss over cross entropy, but if accuracy over speed matters, go with cross entropy. It's a trade off the colback lie blurred divergence. We'll still measure the difference between probability distributions p and Q, but the difference is that in information theory it focuses on the extra number of bits needed to encode the data. That means when applied to our data, the KL divergence will never be less than zero. It is only equal to zero if p equals Q. Now let's switch to a regression problem. We'll try to find the relationship between two variables, the amount of maintenance costs for housing a patient at a hospital versus the number of days they stick. A popular loss function for regression is to use the mean squared error, also called the l two loss. This measures the average amount that the models predictions very from the correct values, so we can think of it as a measure of the model's performance.

Speaker 1:          10:24          On the training set, we calculate the difference between the predicted output and the actual output square it. Do that for every data point. Add them all up and divide by the total number of them. The reason the square is in there is because it lets our results be quadratic or convex. When we plot a quadratic function, it'll have a u shape with only one minimum. So when we use an optimization strategy like say gradient descent, we won't get stuck in a local minimum. We'll find the global minimum, which will ultimately help us find the ideal parameter values to optimize the objective function. Another popular loss function for regression is called the mean absolute error, also called El one loss. This measures the average magnitude of the errors in a set of predictions without considering their direction. We take the average over the test sample of the absolute differences between our prediction and the actual output were all individual differences have equal weight in squared hair, we are penalizing large deviations more square, a big number and it becomes much larger relative to the others, which means that mean absolute error is more robust to outliers than mean squared error, so use it if you have a lot of anomalies in your dataset.

Speaker 1:          11:49          M a d assigns equal weights to the data, whereas ms he emphasizes the extremes. The square of a very small number is even smaller and the square of a really big number is huge. Lastly, a loss, very similar to m. A E is called the Huber loss. It's also less sensitive to outliers. Then the mean squared error. It's a quadratic for small values and linear for large values. If we graph out all three of these work, Russian loss functions, it will look something like this. So depending on if your problem is a regression problem or a classification problem, you can use one of several loss functions. Then you can pick a loss function that optimizes for either accuracy or speed. Hope this video was useful. I've got some great informational links for you in the video description. Check them out.

Speaker 2:          12:45          It is a loss if you don't hit the subscribe button. I've got so much more where that came from. For now, I'm going to upgrade tensorflow, so thanks for watching.