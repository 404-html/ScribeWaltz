Speaker 1:          00:00          Hello world. It's a Raj and the question I get asked the most by far is how do I get started with deep learning and it makes sense to ask that there are so many different learning paths and tools you could use. It's hard to just pick one and roll with it. In this video, I'm going to explain why you should use a deep learning library called Ross to build your first deep neural networks and compare it to other options. Then we'll use carrots to build an APP that generates text in the style of any given author. Deep learning only started getting really popular a couple of years ago when Hinton's team submitted a model that blew away the competition for the large scale visual recognition challenge. They're deep neural network was significantly better than all benchmarks. Illuminati confirmed because it used lots of GPU computation and data. Others began to take notice and implemented their own deep neural networks for different tasks resulting in a deep learning renaissance.

Speaker 1:          01:05          Deep learning plays a huge part in the biggest AI success story of 2017 how Fuego Google's algorithm that mastered the game of go. Previously thought near impossible. Similar improvements were made in fields like vision texts and speech recognition. Wave Net for example, was a model that massively sped up improvements to speech to text and text to speech resulting in lifelike pregenerated audio. Piano was really the first widely adopted deep learning library. It was maintained by the University of Montreal but in September of last year they announced that they would stop developing for the piano in 2018 yes, different open source python deep learning frameworks have been introduced the past couple of years and some got lots of traction. As of now, tensorflow seems to be the most used deep learning library based on the number of Github stars and forks as well as stack overflow activity, but there are other libraries that are growing passionate user basis as well.

Speaker 1:          02:11          Pi Torch is a great example. It was introduced in January, 2017 by Facebook. They basically ported the popular towards framework which was written in Lua to python. The main driver behind Pi Torch, his popularity was the fact that it used dynamic computation graphs. That means they are defined by run instead of the traditional defined and run. When inputs can vary, like if we're using unstructured data with text, this is super useful and efficient. When it comes to static graphs. We first draw the graph, then inject the data to run it. That's defined Andra for dynamic graphs. The graph is defined on the fly via the forward computation of the data that's defined by row, but in addition to TensorFlow's mainframe work, several companion for libraries were released including tensor flow fold for dynamic computation graphs and tensorflow transform for data input pipelines. The tensorflow team also announced a new eager execution mode, which works similar to Pi Torches, dynamic computation graphs, but wait.

Speaker 1:          03:14          Other tech giants have also been getting in on the game. Microsoft launched it's cognitive toolkit. Last year, Facebook launched cafe to Amazon, launched mx net deepmind released to Sonnet. There's also Deeplearning four j d live, h two o. Dot. Ai and spark. Oh and Facebook and Microsoft announced the Onyx Open format to share deep learning models across frameworks. For example, you can train your model in one framework but then serve it in production in another one. I know, I know, I know deep AAF overload, but look, the best way to learn how some AI concept works is to start building it and figure it out as you go. And the best way to do that is by first using a high level library called care os curiosity. Effectively an interface that wraps multiple frameworks. You can use it as an interface to tensorflow, fianno or CNTK. It works the same no matter what back end you use.

Speaker 1:          04:11          Francoise Sholay, a deep learning researcher at Google created it and maintains it. Last year, Google announced it was chosen as the official high level API of tensorflow. When it comes to writing and debugging custom modules and layers, Pi torch is the faster option. While Care Os is definitely the fastest track when you need to quickly train and test a model built from standard layers using care. The pipeline for building a deep network looks like this, you define it, ComPilot fit it, evaluated, and then use it to make predictions. Consider a simple three layer neural network with an input layer, hidden layer and output layer. Each of these layers is just a matrix operation input times weight at a bias and activate the result. Repeat that twice and get a prediction. Deep networks have multiple layers. They can have three, four, five, whatever. That's why they're called deep, and these layers don't have to use just one type of operation.

Speaker 1:          05:11          There are all sorts of layers out there for different types of networks, convolutional layers, dropout layers, recurrent layers. The list goes on, but the basic idea of a deep neural network is applying a series of math operations in order to some input data. Each layer represents a different operation that then passes the result on to the next layer. So in a way we can think of these layers as building blocks. If we can list out all the different types of layers, we can wrap them into their own classes and then reuse them as modular building blocks. That's exactly what care os does. It also abstracts away a lot of the magic numbers you'd have to input into a deep network written in say pure tensor flow. When we define a network, they're defined as a sequence of layers using the sequential class. Once we create an instance of the sequential class, we can add new layers where each new line is a new layer.

Speaker 1:          06:07          We could do this in just two steps or we could do this in one step by creating an array of layers beforehand and pasting it to the constructor of the sequential model. The first layer in the network must define the number of inputs to expect. The way that this is specified can differ depending on the network type. Think of a sequential model as a pipeline with your raw data fed in at the bottom and predictions that come out at the top. This is helpful in carrots as concept that were traditionally associated with the layer can also be split out and added as separate layers. Clearly showing their role in the transform up data from input to prediction. For example, activation functions that transform a sum to signal from each neuron in a layer can be extracted and add it to the sequential class as a layer like object called activation.

Speaker 1:          06:55          The choice of activation function is most important for the output layer as it will define the format that predictions will take. Once we defined our network, we'll compile it. That means it transforms a simple sequence of layers into a highly efficient series of matrix transformed intended to be executed on a GPU or CPU depending on our configuration setting. It's a precompute step for the network. It's required after defining a model compilation requires a number of parameters to be specified, specifically tailored to training our network. The optimization algorithm we use to train the network and the loss function used to evaluate it are things that we can decide. This is the art of deep learning. Once the network is compiled, it can be fit, which means adapting the weights on a training dataset. Fitting the network requires a training data to be specified. Both a matrix of input patterns x and an array of matching output patterns.

Speaker 1:          07:47          Why the network is trained using the back propagation algorithm and optimize according to the optimization algorithm and loss function specified when compiling the model. Finally, once we are satisfied with the performance of our fit model, we can use it to make predictions on new data. This is as easy as calling the predict function on the model with an array of new input patterns for our text generation sample. We'll see that it generates texts in the style of our favorite author just as we fed it in three points to remember. There are lots of new competitors that showed up in 2017 for deep learning libraries, but care os is still the easiest way to get started. Pi Torch is getting really popular and is the best way to build models next to Carol Ross and deep networks are a series of math operations in the form of layers, just mix and match them to get different results every time.

Speaker 1:          08:39          The coding challenge winner from the war robots. Video is Alberto Garcia says he used a proximal policy optimization algorithm to train an AI to balance a pendulum using the open AI gym environment. Top notch work, Alberto and the runner up is Sven near Berger who landed a simulated space x rocket using PPO. Such a cool use case. This week's coding challenge. It's a used care os to build your own deep neural network, get help links go into description and coding challenge. Winners will be announced next week. Please subscribe for more programming videos. And for now, I've got to not use anything made by Microsoft, so thanks for watching.