Speaker 1:          00:00          Hello world. It's the Raj and dynamic programming. It's one of the most important concepts in computer science. It's used all over the place in artificial intelligence. It's used in security, it's used in distributed systems, it's used everywhere. And in this video, I'm going to teach you how it works by going through several examples. But before I go through those examples, before I go over the abstracts, before I go over the theory, let's look at this demo I've got here. And what this demo is, is it's a visual way for you to see dynamic programming in action. What it's doing is it's aligning DNA sequences into this matrix and it's a table, right? With rose and with columns. And what we can do is we can type in a sequence like a, let's say, let's say sequence one is going to be a c, G, and they're all some variant of HCG GCA, right?

Speaker 1:          00:47          Those are the three letters. And then we say, hey, GC, AGC, and the for sequence too, we could say, you know, Gac, g, a, C, a, c, and so forth, so on and so forth. So notice how as I'm constructing these sequences, the table and the values in that table are getting filled in. What it's using is what's what's called a top down approach. There's two types of techniques we can use and dynamic programming, a top down approach, and a bottom up approach. And we're going to talk about each of these in detail. So what I wanted to do was just kind of show you this, this a visual demo before we go into the code, you can find the get hub link in the description of this video if you want to look at the code. But, uh, it's a good way to visually see what's happening here and it's all written in javascript.

Speaker 1:          01:29          Okay, so what is dynamic programming? Right? What is this? Well, there's this really famous quote by, I don't know who, it's not by de dynamic programming the concept because concepts can't speak yet. Those who cannot remember the past are condemned to repeat it. That's some sage advice for you and for me as well. Geez. Oh my God. Anyway, anyway, so bellman bellman was the dude. Bellmen made the bellman equation, which is used all over the place in reinforcement learning. It's used for the Mark Haub decision processes for responsible for some of the famous winds off ago. For example, in Ai last year, but he had this very famous quote in the 50s when he created the concept of dynamic programming, and I'll quote him, he said, dynamic programming amounts to breaking down an optimization problem, Ding, ding AI into simpler sub problems and storing the solution to each sub problem so that each sub problem is only solved once, right?

Speaker 1:          02:24          So it's taking a big optimization problem. What is an optimization problem? It's a problem that looks to minimize or maximize some value iteratively, right? All, all of machine learning is an optimization problem, right? All of machine learning is trying to optimize to fit a curve. It's glorified curve fitting to some data in dynamic programming is taking that optimization problem and breaking it down into simpler sub problems. Okay, so that each sub problem is only solved once. Once we solve all of those sub problems, we can concatenate them or put them together to find the optimal solution. For the larger initial problem. So what I've got here is this funny little, uh, uh, it's like an XKCD, but it's not. It's just a clip. But what I'm gonna do is I'm going to just animate the dialogue here too, just to give you some, you know, a little bit of fun before we get into the harder stuff.

Speaker 1:          03:13          So there's a woman in a man, okay, so here's how it goes. Oh, what to wear, what to wear. It's such a vast wardrobe. How will I ever find the right combination? Perhaps I can help. Who are you? I'm here to tell you about dynamics, the new selection optimization software from algorithmic anomaly. How does it work? Well, we use dynamic programming to recursively create an outfit that you'll look just stunning in. Now, if we want to do this in end squared time, we'll have to hurry. Let's begin that shirt and those pants that you're holding, how good they look together, how, how would you rate them on a scale of one to 10 and so she says seven. He says, excellent. I'll enter that into our array. And then he keeps asking her these questions. How about those shoes? With that necklace? She says, three how about those other shoes with that shirt?

Speaker 1:          04:03          She says, six. He keeps asking me these questions, this necklace with those pants, that shirt with those pants to six, right? Three hours later there, I've told you everything, and now in a few seconds the paradigm will have worked its magic Wallah all done. So what do you want to, where are these exact pants, this shirt, those shoes and that necklace later that night, darling, you look absolutely dynamic. Somehow. I knew he was going to say that, right? So what's happening here is we took this larger problem, which is what is the optimal outfit to wear that's going to impress this dude at the end, right? And what this, what this a programmer did was he broke it down into sub problems. What's the optimal shoe and necklace to wear together? What's the opposite? Optimal pants and a shirt to wear together. And then he combined all those solutions to form the perfect larger problem, which is that larger outfit, right?

Speaker 1:          04:52          So dynamic programming can be used to solve problems that would take exponential time and it can solve them in end squared timer and cube time. And so it's very similar to the divide and conquer approach. Recall that in divided and conquer or taking a problem, we're subdividing into smaller problems, right? We're dividing it and conquering each of them. But the difference between divide and conquer and dynamic programming is that in dynamic programming, some of these sub problems can overlap. And what I mean is let's say this, uh, you know, shirt, necklace, a dressing example, we can have one of the sub problems, B, what is the optimal combination of a necklace and a shirt. And another one could be what is the optimal combination of a necklace, shirt and shoes. Notice how the necklace shirt and shoes is kind of a sub problem of this other or a not a sub problem but a super sect problem of this sub problem.

Speaker 1:          05:42          But they're both sub problems in the larger scale of things, right? But they overlap is what I'm saying. So the basic idea is that in dynamic programming, we're breaking the problem up into sub problems and we use the optimal solutions to those sub problems to give us the optimal solution to the larger ones. It's okay if they overlap, that's, that's okay. And it's basically recursion plus using some common sense. So recursion allows you to express the value of a function in terms of other values of that function where common sense tells you that if you implement your functioning in a way that the recursive calls are done and store it for easy access, it will make your program faster. So what we're doing with dynamic programming is we're essentially trading, we're trading space for time, right? So instead of calculating all the states taking a lot of time, but no space, we do take up space to store the results of all those sub problems to save time later.

Speaker 1:          06:33          Right? So it's a, it's a trade off. We're storing some values so we don't have to recompute everything all over again. So it's faster. But the trade off is we're saving more data so we're taking up more space complexity. A good time to use this is check out this, uh, well, here's a, here's an example by the way. So the, the algorithm here is repeat the others word, add your word and pass it on to the next one. And if you're wrong, then you have to drink one beer and we start over again. So this is called dynamic drinking. It's just a joke, but it's like another way of understanding this. The first guy says while drinks, or the first guy says, while the next guy says while Bob, and next time it says while Bob Eight. So at every iteration we've saved the previous states, right?

Speaker 1:          07:12          While while Bob think of it as an array, right? So we're storing all of these previous states rather than having to recompute everything all over again. And eventually this guy at the end, he's so drunk, he forgets what the other said. And so we start over again. So all of these dynamic programming problems have four steps. First we show that the problem can be broken down into optimal sub problems, right? So you have to think about it like right with in the case of dressing someone up or in the case of some larger problem that we can sub divided into sub problems like designing the optimal uh, layout of the room, right? We could, we could split the room up into subsections, right? And they all had their individual and unique features, right? The Wall is kind of curved at this end, but it's like this and Oh, Hey, this sofa would fit perfectly into this subsection of the room, right?

Speaker 1:          08:00          So we divided into sub problems. Then we recursively defined the value of the solution by expressing it in terms of optimal solutions of this smaller sub problems. So the optimal solution to this room design problem would be such that each of these spaces in terms of square meters or square feet are filled at the, at their maximum value. Because the optimal solution for the larger problem is to feel as as many square meters or feet as we can, such that the room is completely fitful, right? We compute the value of the optimal solution in a bottom up fashion. I'll talk about that in a second. And then lastly, we construct an optimal solution from the computed information, right? So, okay, so here we go. With this, there are two key attributes that we must have for any problem in order to apply dynamic programming to it. The first is it has to have an optimal substructure. What that means is an optimal solution to a problem. An instance contains optimal solutions to solve problems. And then we have to have overlapping sub problems, meaning a recursive solution contains a small number of distinct sub problems repeated many times. So let's, let's talk about this, right? So we have, so every problem has to have two of these features. It's got to have an optimal substructure such that for each of these sub problems, if we find the optimal solutions to them, we can combine them and then find the optimal solution to the larger problem. That's the first. The second is it's got to have overlapping sub problems, right? Like shirt, shoe tie, and then short tie for it, right? For example, those are overlapping.

Speaker 1:          09:37          So how do we solve this prop? Once we've identified a problem that has those two key features, how do we solve it? Well, we have two approaches. The first, and these are fancy words, is the tabulation approach. The second is a memo position approach and what this really means are a bottom up approach and a top down approach. So here's the bottom up approach. Let's say I want to become an amazing coder, right? That's, that's the goal to the bottom up approach would be step one, I'm going to learn programming step two. Then I'll start practicing step three. I'll take part in contests. Step four I'll practice even more and try to improve step five after working hard like crazy. Step six, I'll be an amazing coder. That's bottom up, right? We're starting at the very bottom. Sorry, from the bottom. Now we're here, right?

Speaker 1:          10:19          We're sorry. I'm on the very bottom like Drake and we're going to the top. Now top down is the opposite. We start with that final solution. I will be an amazing coder. How? I'll work hard like crazy. How I'll prices more and more and more. How I'll take part in contests all the way down to the bottom. I'm going to learn how to program. Okay, now I've got this table that shows some of the, you know, key differences and similarities between these two, which I'm not going to go into right now because there's a lot. Let's just get into an example, shall we? Okay, so four overlapping sub problems. Let's take the FIBONACCI sequence as an example. You've heard of the FIBONACCI sequence, right? It's, it's a sequence of numbers where, where every number in the sequence is the, some of the previous two numbers, right?

Speaker 1:          11:03          So the first one would be one. There's nothing before it. So it's zero. The next one is one. So one plus one or one plus zero is one. The third one is two because one plus one is two, and the fourth one is three because one plus two is three, right? It's just that there's just that chain, right? It's a recursive chain. We can solve it. Recursively so that's the FIBONACCI sequence. So how do we solve this? How do we write, how do we write a programmatic algorithm for this? Well, one solution is to do it recursively, right? So doing it recursively does not mean doing it. The dynamic programming. Wait, there's a distinction here. So let's look at the recursive solution. The recursive solution looks like this in python. Now let's go over this function here. The functions is interfered with the parameter and end, right?

Speaker 1:          11:47          So we, we input the amount of numbers in the sequence, we want it to compute and then we have a base. The base case is if an is less than or equal to one return that return what n is and then return fib, n minus one plus and minus two which are both the, the, some of the previous two numbers. So what this looks like is if f is one, then we're just going to return one. So then it would construct one. If F is zero, then we're going to turn zero, right? But then if f is two is going to be this, it's going to be, look at this, look at this recursive tree that's going to be computed. It's going to be f of one plus F of zero, which is two if f of three, if it's f of three it's going to be f of three is going to be f of two plus f of one and then four f of two we have to then compute recursively the solution for f one and F of zero.

Speaker 1:          12:37          Now if we do it like this will totally solve FIBONACCI. However, we're going to have to call f three two times. If we do f of three we could have stored the value of ff three instead of computing it again, and we could have reuse that old stored value. We're not storing anything in memory here. We're recomputing this entire tree. So notice if f if, if it was at, when I say APP, I'm talking about fib. IfF was like, let's say 200 we would have to continually recompute all the branches of this tree of execution. Whereas if we saved some of these values iteratively, then we wouldn't have to do that. So right? It's a trade off between time, complexity and space complexity. So how can we do this and that dynamic programming way? Well, the dynamic programming way looks very similar to the recursive version with a small modification in that it uses what's called a lookup table before computing solutions.

Speaker 1:          13:30          How do we do this? First, we initialize that lookup table as nil. There's no values in here. Whenever we need a solution to a sub problem, we first look into this lookup table. If the precomputed value is there, then we returned that value. Otherwise we'd calculate the value and put the result in the lookup table so that it can be reused layer. This is the dynamic version of it's the memos version. For this function we have our base case which is the lookup table initialize as nil. If the value is not calculated previously, then calculate it. Notice that here is the recursive part fib and one with the lookup as its parameter and in fib and to uh, with the look of as this parameter. Again, we only add those up if the value in the lookup table is empty and that at the very end we returned the lookup table.

Speaker 1:          14:17          So notice how it is recursive. However, we're adding in this extra a lookup table which acts as a store for the precomputed values in that Fibonacci sequence. And it's still a top down approach, right? Memorize approach because we're starting, we're starting at the top. The top is what is the last value in that Fibonacci sequence. And then let's go to the smaller sub values right now and now instead of doing top down, let's do bottom up. So the tabulated or bottom up approach is building a table in a bottom up fashion and returning the last entry from that table. So for the same FIBONACCI number we calculate first it was zero, then they've won, then fifth to then fifth three and so on instead of the opposite way, right? And so like (535) 025-0150 we're doing it bottom up Lou, we are literally building the solutions of sub problems bottom up.

Speaker 1:          15:07          So in this example for the tabulated version, we are starting with F of zero, right? Zero Times n plus one and we are adding not subtracting from end because end starts at that. At that minimum value and then we have our base case assignment and then we'll end is going to be how many numbers we want that that the perimeter is the same. However, the way we're computing it is different. We're starting at the, we're starting at the smallest value and we're adding them up iteratively. Like in this four loop we're calculating the FIBONACCI and storing those values inside of this array that we declared or earlier. So both of these solutions store the sub problems, right? The in the memos version, the top down version, the table is filled on demand. While in the tabulated version we start from the first entry in all entries are filled one by one, but unlike the tabulated version, all entries in the lookup table or not necessarily filled in the memory wise version, right?

Speaker 1:          16:00          So that is the overlapping sub problems feature that each of these dynamic programming problems can have. Now here's the other feature, the optimal substructure feature. Now this also applies to the FIBONACCI problem we just looked at, but I'm going to look at a different problem now, which really exemplifies this feature of dynamic programs. So the problem here is the shortest path Algorithm, right? We know about shortest path dykes, stress. There's a bunch of the traveling salesman, Tom, there's a bunch of shortest path algorithms out there, but we're going to talk about one in particular that's called the Bellman Ford Algorithm. So let's say we have a graph, right? We have some, a graph, a graph with, with nodes, with edges, and we want to find the shortest path between two, two notes, right? So how do we do this? So this is an example of, of a problem that has an optimal substructure.

Speaker 1:          16:50          Check this out. I'm going to read this out. All right, here. Here we go. If a node x, right, we've got to note x lies in the shortest path from a source node. You right? We have no tax source source node, you and a destination node v. That's it. That's all we have to remember. Three nodes, node x, a node, you and then node z. Then then the shortest path from you to the is a combination of the shortest path from you to x and x to V. Makes Sense, right? We have three notes. X is in the middle, you ex the, the short, what all it's saying is the shortest path from you to x and X. V is equal to the shortest path from you to be. So if we solve these two up a sub problems, optimally we will get the optimal solution to the larger problem.

Speaker 1:          17:36          What's the shortest path from UTV? Right? So that's an example. And we can use the Bellman Ford Algorithm to find the shortest path. So here's how it works. So we're given a graph and a source for techs I SRC in that graph, we want to find the shortest path. Here's how we do it. First we calculate the shortest distances, which I have at most one edge in the path. Then we calculate the shortest path without most two edges and so on. Three edges for I just five edges, et cetera. After the ice iteration of the outer loop, the shortest paths would that most I edges are calculated and there can be at maximum B minus one where vias that highest threshold edges in any simple path. And that is why the outer loop runs a B minus one times, right? So here's an example. We're basically, we're computing all of these sub sub, uh, paths, and then we're finding the optimal solutions for those.

Speaker 1:          18:30          And then when we find them, we can just add them together. And that gives us the optimum path from a to B, which are going to be our parameters to this model. So here's the code version of this. These are our initialization steps. We don't have to look at these, but here's where it really the meat of the code where this is happening. The Bellman Ford equation finds a shortest distances from source to, uh, the initial note that were happening that were we were at. So step one is to initialize a distances from the source to all of the other vertices. Then we relax all the edges. The minus one times I see a simplest, shortest path from source to any other vertex can have at most that many edges. So we have this nested loop where we're updating the distance values and the parent index of the adjacent vertices of the picked vertex. So consider only those vertices, which are still in the queue. And then we check for negative weight cycles and remove them. So then we are left with the optimal solutions to that larger sub problem. And then we have us constructing the graph with all of its edges and vertices and then we print the solution. But what I bought, what I mean there's, there's a ton, there's literally a ton of dynamic programming problems out there. There's like 40 50 60 on the sites out there, you know, like dynamic programming problems, problems cause a million. And one of these,

Speaker 1:          19:50          which I was looking@gigsforgeeks.com check out gifts for Geeks Dotcom. He's got so many of these dynamic programming problems. But anyway, we're, where were we? Oh, okay. So what do we know about dynamic programming? It's, well, any problem that dynamic programming can be applied to has two key features. It's got an optimal substructure, meaning if we can find the optimal solutions to the sub problems, we can find the optimal solution to the larger problem and it's got overlapping sub problems, meaning some of those problems will overlap. Sure. Choose tie tie shoes, right? They overlap and now where do we apply this? Well, in deep learning, the work horse of deep learning is the backpropagation algorithm. This is how supervised learning works, okay, let's take a look at some, some code here for this,

Speaker 1:          20:41          right? So here's a, here's a code for a simple feed forward neural network that's trying to, the pattern match between these inputs and outputs, right? We have zero zero 1111101100 and then we have it's associated labels zero one zero zero zero. We want to find the pattern here is such that we give this network some input like one zero one arbitrarily and it will know exactly, oh, the label is going to be zero or one after training on this very small four point dataset. So how do we do this? Well, in this training step, we say we first, we initialize our weights as a matrix, right? We only have one sets of weight. This is a perceptron and very simple neural network. We have our activation function, which allows us to learn nonlinearities and then I'm not going to go into the total details of backpropagation.

Speaker 1:          21:29          Now I've done this many, many times a look in my intro to deep learning series. In fact, I can just, you know, rap about it a little bit right now. Uh, my ones and knows map to oes in one's inputs, add weights, update gets sums past that shit too. Must sigmoid function, get that error. What's real in prediction? And that's what I use. Gradient descent. It gives predictions and it doesn't pretend update weights and repeat 10,000 times outputs are lit. I'd be doing just fine if you want to see that actual rap, a check on my intro to deep learning a playlist and I think it's um, number two, how to make a neural network where I actually wrapped that but to, anyway, what we're doing here is we are calculating a gradient value, right? We're calculating a gradient value, which is, which is also called a partial derivative with respect to our weight values.

Speaker 1:          22:19          It's one single value and we are doing that recursively for every weight going backwards so we feed forward, we calculate some input data, applying operation, right input times, wait, activate. We send it to the next layer, input times wait activates and it's the next layer. We get an output. We, we calculate the difference between the expected output in the actual output, the label. That's our error. We use that air to then compute a gradient with respect to the weight's going backward right back where we compute a gradient, we get that gradient update, well we update the waste at the very end. Then we use that creating to compute the grading for the next layer and recursively for the next layer. That is dynamic programming because we are storing that grading value to update our weights later on. Okay. That is dynamic programming. In principle, we could calculate the partial derivative of the function with respect to any weight simply by tracing out the nodes downstream from it and calculating the longer derivative chains manually, but we're not doing that.

Speaker 1:          23:16          We're using the chain rule and dynamic programming to do it in a much more efficient way and that is backpropagation. It would be very tedious to do it the other way. The key idea is that we can reuse results for an efficiency increase just as we do for dynamic programming in general. So it's used in deep learning. Where else is it used? It's also used in reinforcement learning and reinforcement learning. I've got a whole playlist on reinforcement learning as well to search reinforcement learning playlist Saroj on youtube, but dynamic programming solved for the optimal false policy or value function by recursion. So if we look at the landscape of reinforcement learning algorithms, we've got policy optimization and we've got dynamic programming and two of the most important techniques in mark hub decision process optimization or policy iteration and value iteration and from them spring cue learning and actor critic method methods.

Speaker 1:          24:14          So dynamic programming is used heavily to find the optimal mark off decision process. And this if you, if you don't, you know, if you want to know what a mark of decision processes, it's a way of framing an environment where an agent can learn from. Right? We have a set of states, we have a set of actions that the agent can take. We have some transition function. We have some starting say distribution, a discount factor if we want to get fancy and then some reward for completing the correct action, whatever that objective is. Lastly, let's go over some runtime analysis. How do we analyze the runtime of a dynamic programming problem? Well, it always takes this kind of formula, the preprocessing run time plus the loop, tons of recurrence plus the post processing, so it's a runtime of all of these preprocessing or any of the initial steps you have to take.

Speaker 1:          25:02          Just find the time. Complexity of that for the loop is how many times is a Lupron? Is it a, is it a single loop? Is it a nested loop? Is it a nested, nested, nested loop, and then recurrence? How much time does it take? The recurrence run in one four loop iteration. We multiply those two together, add the post processing, and that's going to be our overall runtime analysis for a dynamic programming problem. I hope that video helped you and if you want to learn more, please subscribe for more programming videos. For now, I've got to find 99 sub problems, so thanks for watching.