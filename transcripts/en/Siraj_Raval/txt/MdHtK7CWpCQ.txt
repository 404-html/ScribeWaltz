Speaker 1:          00:01          I bring you the light of statistics. Hello world, it's a Raj and understanding statistics is a really important part of data science. There are entire textbooks and graduate level programs dedicated to mastering this branch of mathematics. So to give you a brief but relevant overview, we're going to learn about just three major concepts in statistics that all data scientists should understand for context. We'll apply them to a Dataset of loans that were issued to people between 2007 and 2015 to figure out the type of people that received loans, whether or not they're given credit score was appropriate and whether or not we can create a model to better predict their credit score. Using machine learning. It's hard to understate how crucial statistics is in data science. In fact, in 96 the term data science was used for the first time in the title of a statistical conference called IFCs.

Speaker 1:          01:02          The title was data signs, classification and related methods. Data Science started with statistics and has evolved to include concepts like machine learning and artificial intelligence. Statistics is a collection of procedures and principles for gaining information in order to make decisions when faced with uncertainty. I shouldn't have used it in my last relationship. It's an extremely valuable skill to understand so much so that's that institutions can work in virtually any field from business to social science to medicine in the context of data science. Think of a data scientist as a person who's better at statistics than any programmer and better at programming than any statistician. We can use statistics for so many problems like identifying the risk factors for a type of cancer or customizing a spam detection system or establishing the relationship between salary and demographic variables in population survey data. So let's focus on a very specific problem.

Speaker 1:          02:05          In 2008 there was a sub prime mortgage crisis in the United States, which was terrible for many companies like when Lehman brothers went down, down, down, down, down. But it did create opportunities for new players in the retail credit field following the credit scarcity that took place briefly during those times peer to peer lending companies thrived. According to PWC, US peer to peer lending platform volumes have grown an average of 84% per quarter since 2007 lending club is one example of a popular p to p lending marketplace and we can use readily available data from them to help us figure out if credit scores for a given set of people are accurate and if we can create more optimized ones ourselves. The lending club Dataset contains 887 loan applications over a period of eight years and we can download it directly from their website. As you can see, there are a lot of columns meaning features in this dataset.

Speaker 1:          03:10          For every person we have the amount they were loaned various details about their background, like whether or not they own a home, where they live and of course their credit score. Using statistics, we can gain deeper insight into how this data is structured. And then based on this structure, we can optimally apply other data science techniques to get even more information. So let's start with the first statistics concepts we can use here. Statistical features, this is probably the most used statistics concepts in data science. It's usually the first stats technique we would apply when exploring a Dataset and includes concepts like bias variants, mean median percentiles, and many others. All of them are easy to understand and implement in code, but it'll take a while to define every single one of them and you can't download them into your brain yet. So I've linked to a detailed cheat sheet in the video description to visualize some of these statistical features.

Speaker 1:          04:13          Let's create what's called a box plot to examine the relationship between income and loan amount. Box plots are a standard way of displaying the distribution of data based on a few statistical features. In order to do that, we'll look at a subset from our data where income is less than 120 k per year. The reason being that applications with income above this threshold are not statistically representative of our population. Out of 880 k loans, only 10% have annual incomes higher than that. If we didn't cap our annual income, we would have a lot of outliers and our box plot wouldn't look as insightful. Using our box plot, we can easily visualize some statistical features. The line in the middle is the median value of the data. The median is used over the mean since it's more robust to outlier values. The first quartile is the 25th percentile, meaning 25% of the points in the data fall below that value.

Speaker 1:          05:14          The third core tile is a 75th percentile, meaning 75% of the points in the data fall below that value. The Max and Min values represent the lower and upper ends of our data range. Box plots are awesome because they demonstrate how we can utilize a sticks, his physical features instantly. If a box plot is short, it means that our data points are generally similar. Many values are in a small range. If it's tall, it implies that our data points are different since the values are more spread out. If the median value is closer to the bottom, we know that most of the data has lower values. If the median value is closer to the top, we know that most of the data has higher values. If the median line is not in the middle of the box, it means we have skewed data. We could keep going here.

Speaker 1:          06:06          If the whiskers are super long, it means our data has a high standard deviation and variance, which means our values are spread out in highly burying. As you can see, we can get a lot of information from just a few simple statistical features that are all easy to calculate. My friend said he made it up to Taggle is top spot and all the maid was a brand new box plot. We'll notice that the core tile distribution of fully paid is very different from the core tile distribution of charged off, but it's similar to current ingrained period and issued. This means that lending club has been more selective with its newer loans. Also charged off and default statuses hold similarities in terms of the core tile distribution differing from all the others. This lets us know that the income variables are important for predicting loan grades.

Speaker 1:          07:03          If we add another dimension to the analysis by generating the box plots for income versus loan grade, we'll find that a graded loans have a median income that superior to other grades, but we can't say the same about the other core tiles. Notice though that f g and be graded loans hold a similar income core tile distribution lacking consistency. Maybe income actually isn't that critical when determining lending club's loan grades. We'll have to keep investigating here to learn more. The second important concept from statistics to know is the probability distribution. We can define probability as the percent chance that some events will occur. Usually this is quantified in the range of zero to one where zero means we are sure that it won't occur and one means work. Totally sure it will occur. We can think of a probability distribution as a function that represents the probabilities of all possible values in an experiment.

Speaker 1:          08:06          There are many different types of distributions, so much interesting theory here. For example, a uniform distribution has a single value which only occurs in a certain range while anything outside of that range is solely zero. Think of it as an on or off distribution. A normal distribution is specifically defined by its mean and standard deviation. With this, we know the average value of our Dataset as well as how spread out it is that boys soon distribution is like the normal but with the edit factor of skewness. When skewness is high, then the spread of the data will be different in different directions. One direction can be very spread. While the other could be very concentrated. There are more distributions. I just wanted to give you an overview of three important. If we generate a distribution plot for annual incomes from single applications, we'll find that it's heavily skewed, heavily peaked and has a long right tail.

Speaker 1:          09:06          These points are regularly observed in distributions that are fit by a power law. A power law is a functional relationship between two quantities or a relative change in one quantity results in a proportional relative change in the other quantity independent of the initial size of these quantities. Basically one quantity berries as a power of another. We can informally say that we have a power law candidate distribution here. Most applications are coming from the lower end of the income spectrum. An interesting observation. The third concept to know about his Basie and statistics to understand and stats, we have to first understand frequency stats. Everyone, everyone stay calm. No gang wars please. Frequency statistics is the type of stats that involves applying math to analyze the probability of some event occurring where specifically the only data we compute on his prior data. If we had a die and were asked what the chance of rolling a six was, most people would say it's one and six but what if someone were to tell us that the specified die given to us was loaded to always land on six frequency stats only takes into account prior data.

Speaker 1:          10:18          That new evidence that was given to us about the died being loaded is not being taken into account Bayesians statistics. However, it does take into account this evidence. We can illustrate it by taking a look at base there from where he is. The evidence and h is the hypothesis, the probability of the hypothesis given the evidence is equal to the prior probability multiplied by the likelihood of the evidence. He, if the hypothesis is true divided by the priority probability that the evidence itself is true Bayesians stats takes everything into account, we use it whenever we feel that our prior data will not be a good representation of our future data and results based there I'm simple buys complex concepts. It explains a lot using a few simple variables. It supports the concept of conditional probability meaning if a occurred, it played a role in the occurrence of B. Base theorem can help us predict the probability of someone having a specific disease, knowing their age.

Speaker 1:          11:21          It can let us know if an email is spam based on the number of words it's used to remove uncertainty. It was even used to help predict the configurations of the enigma machine to translate the German codes in World War II. So how do we utilize Basie and statistics here? One way is to build a Bayesian classifier algorithm, one that will predict credit scores given other features in the Dataset. Naive Bayes is a family of algorithms that takes advantage of base theorem to predict a target variable. This type of classifier assumes all features are unrelated to each other. Using a few features we select, we can predict whether a loan applicant should be accepted or rejected. The accuracy looks all right. I'm sure we can try several other classifier models here to find a better predictor, but this is a great first step. As you can see, statistics is supremely useful in data science and we only covered three key concepts from statistics.

Speaker 1:          12:22          There are so many more like upsampling and downsampling and dimensionality reduction. There's more, but there are just three things to remember from this video. Statistical features like bias variants and many others help us explore a dataset to gain valuable insights. Probability distributions defined the percent chance that some event will occur and we can use them to understand the spread of data and hazy and Statistics expresses probability as a degree of belief in an event which can change as new information is gathered rather than a fixed value based on frequency. The coding challenge for this week is to use statistics to perform exploratory data analysis on this lending club Dataset in the form of a Jupiter notebook. The top two most detailed reports when I'll give them a shout out next week, post your get hub links in the comment section. Details will be in their get hub. Read meat in the video.

Speaker 2:          13:21          What's one thing you like about statistics? Let me know in the comments section and please subscribe for more programming videos. For now, I've got to predict the target, so thanks for watching it.