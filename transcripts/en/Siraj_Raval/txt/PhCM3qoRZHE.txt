Speaker 1:          00:00          Is this a real picture or a fake one? It's fake hello world. It's Saroj and there's a new paper from nvidia research that details an AI model that can generate images that are more realistic than any previous model. It's called a generative adversarial network or again for short, but not just any. Again, it's again that can progressively grow over time during the training phase, which is such a cool idea. Gans were invented by a researcher at the University of Montreal three years ago and its potential is huge because it can learn to mimic any distribution of data. That means it can be taught to create worlds that are eerily similar to our own in any domain. Images, music, speech writing. They're like robotic artists and their outputs are pretty impressive. Speech synthesis systems are using them image to image translation techniques, use them and image in painting is another popular use case.

Speaker 1:          01:03          Gans are a type of generative algorithm. The other class of models being discriminative algorithms, discriminative algorithms try to classify input data given some set of features predict a label or category to which that data belongs to. If we have all the words in an email. For example, a discriminative algorithm could predict whether the message is spam or not. Spam, spam being one of the labels, the bag of words we gather from the email or the features that constitutes the input data. When we express this mathematically, the label is called y and the features are called x. The formulation probability of y given x translates to the probability that an email is spam given the words it contains. So discriminative algorithms map features to labels. They're only concerned with correlations. One way to think about generative algorithms though is that they do the complete opposite. Instead of predicting a label, given some features, they try to predict features given a certain label, like assuming this email is spam, how likely are these features? Discriminative models care about the relation between y and X. Generative models care about how you get x. This allows us to capture the probability of x given why it learns the distribution of individual classes, not the boundary. Dan's consist of two neural networks, a generative network that generates new data instances and the discriminator that evaluates them for authenticity. The discriminator, we'll decide whether each instance of data, it reviews belongs to the actual training Dataset or not. Let's say we're trying to generate new types of Pokemon.

Speaker 1:          02:58          I just had play that for a second. Okay. Using an image Dataset of existing Pokemon, the goal of the discriminator when shown a Pokemon is to recognize it as authentic. Meanwhile, the generator is creating new images that it passes to the discriminator. It's trying to fool the discriminator, trying to pass it off as authentic, even though it's fake. The goal of the generator is to generate passable Pokemon to lie without being caught. The goal of the discriminator is to identify images from the generator as fake or real. The steps again takes are as follows. The generator takes in randomly generated numbers and returns an image. This generated image is fed into the discriminator alongside a stream of Pokemon. From the actual Dataset, the discriminator takes in both real and fake Pokemon and returns probabilities. A number between zero and one with one representing a prediction of authentic and zero representing fake.

Speaker 1:          04:00          So there's this double feedback loop going on. The discriminator is in a feedback loop with the ground truth of the images, which we know the generator is in a feedback loop with the discriminator. Think of it like a counterfeiter and a cop in a game of cat and mouse where the counterfeiter tries to print fake money and the cop is trying to detect it. Both are learning at the same time. The discriminator is a standard convolutional network that can classify images fed to it. It's essentially a binomial classifier labeling images as real or fake. The generator is an inverse convolutional network or deep convolutional network. A CNN takes an image and down samples it to produce a probability and a DNN takes a vector of random noise and up samples it into an image. Both networks tried to optimize a different and opposing loss function, so gans are awesome, but they're really hard to train.

Speaker 1:          05:02          Usually the loss function for gans looks something like this instead of what it should look like, which is something like this. And that's what makes them an active area of research. The idea that Nvidia had was to grow again progressively. It wasn't a new idea. There was a paper that presented a cascaded reinforcement approach that brought small generated images up to mega pixel size step by step. Another paper built an intermediate low dimensional representation than improved it on another again, but these methods made their progressive improvements separately. The next level of progressive improvement just took a result of the previous layers and has paper use a system where they trained a few layers, then added a few more and so on. It turns out that this type of execution was the most straightforward, fastest to train and provided the best results. The authors begin with a small network able to produce only four by four images.

Speaker 1:          06:07          Then they train it until it works well. Then add another set of layers to both the generator and the discriminator. Moving from four by four to eight by eight train the new layers and so on. Doing this, they were able to grow again, able to generate really convincing 10 24 by 10 24 images of much better quality than before. One tweak I found particularly interesting was that they implement it a way to help their Gan increase its variation. Dan's have this tendency to capture only a subset of the variation found in the training data. One solution was to compute features, statistics not only from individual images but across a mini batch. This encouraged many batches of generated and training images to show similar statistics. It's implemented by adding a mini batch layer towards the end of the discriminator where the layer learns a large tensor that projects the input activation to an array of statistics.

Speaker 1:          07:09          A separate set of stats is produced for each example in a mini batch and concentrated to the layers output so the discriminator can use those stats internally. They sampled this approach by first computing the standard deviation for each feature in each spacial location over the mini batch. Then the average, all of those estimates over all features and spatial locations to get a single value. The value was replicated and contained to all spatial locations and over the minibatch which yielded one additional feature map. They inserted it towards the end of the network and it turns out doing that helped again learn more of the variation inherent in the training data. They trained their network on a single and video Tesla Gpu for 20 days and after that there was no real difference in the qualitative difference between the results of training iterations. It's pretty incredible the images they were able to generate not 100% photorealistic, but really close the fakes dense pose and now progressively growing gans.

Speaker 1:          08:18          We are heading towards some unpredictable and exciting times. Three things to remember from this video. A generative adversarial network consists of two neural networks of generator and a discriminator. The generator creates fake images. The discriminator tries to discern if it's real or if it's fake. Over time, both get better through a training phase and and video found that by progressively adding layers to both networks, it improved the quality of the outputs and sped up the training time. This week's coding challenge is to generate some photorealistic images using a progressively growing gan details and code are in the video description. Submit your get hub link in the comments section. I'll review them and announce the top two entries in a week. Was this video itself generated? Maybe it's a tried to keep up with the latest in AI and block chain technology. For now, I've got to generate a website, so thanks for watching.