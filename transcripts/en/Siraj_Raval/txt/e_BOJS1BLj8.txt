Speaker 1:          00:00          Hello world, it's Saroj and neuroscience and machine learning to different fields that are actually very much connected. Today I'm going to talk about how neuroscience and machine learning are very connected. I'm going to talk about how recent advances in neuroscience will move machine learning forward. And before I talk about that, I want to show you a demo. In this demo is an interactive network visualization tool for exploring functional brain connectivity. It's called spectrum is. And after this video you're probably going to want to look at more neuroimaging techniques and this is a great way to get started. I found this repository on hub and basically what it allows you to do is simulate a brain in Silico, but it's a very, you know, it's, it's, it's not the full brain obviously, but it's a, it's a good model of how neuroimaging tools can be simple and it was created using d three dot.

Speaker 1:          00:51          Js Very cool visualization library. You can hit start and you can see the network just, you know, move it gets, it's, it's very, it's very cool. But, uh, I just wanted to show you that really quickly and you can, you know, switch the timing, the frequency of connections, all these different things you get, you get all of these different mappings of, of how the neurons are moving, how they're interacting in the network. Uh, it's pretty cool. So check out that after this, the link to that is going to be in the video description. But let's get started with this. I've divided this talk into three different parts, the history of neuroscience in Ai, the contemporary neuroscience and AI and the future of neuroscience and AI. Okay, so let's start off with the history and obviously I've got this super generic image that is shown everywhere, but it's the idea of this image is saying, Hey, we've got this neural network.

Speaker 1:          01:36          And what it was inspired by is the human brain. Okay? So at the dawn of the computer age, when computer science was, was invented, when it was starting up, all of AI research was neuroscience. Everything was based off of neuroscience. It was the same thing. Every single discovery came from neuroscience when it came to AI. And the early pioneers of this field straddled both neuroscience and AI. It was, they were, they were connected to both collaborations between all of these different fields was highly productive. So let's, let's look at some examples here. How can I talk about computer science without talking about touring? Right? Touring was the man Turing test. Okay. He's, he invented the Turing test. You've ended a bunch of stuff. But he's in a lot of ways the father of computer science. But the idea behind the Turing test was, let's see if a human can tell if he's talking to either a human or a machine, and if he can't tell, then the computer has passed the Turing test.

Speaker 1:          02:32          Right. Touring was very, very, very much into the brain. He said, we are not interested in the fact that the brain has the consistency of cold porridge. That was his quote. But what he meant was he was very interested in how the brain worked. He was very certain that it was a very complex organ and his view is shared by many in that we cannot represent the brain using anything but math because it's such a complex system, right? Think about the brain has a graph, right? Think of that. Think of it as a graph. And if you think about as a graph, you have these neurons nodes connected to each other. It's this common tutorial explosion, right? In terms of a search space. When you take a signal and you probably get it forward, it's going to be split up into hundreds if not millions of different signals for different neurons.

Speaker 1:          03:16          And this is a common tutorial explosion, right? There's no way to describe this via colors or you know, regions other than by sheer beautiful math, right? And if you think about math, right? There's this idea of this, this mythical book, the book of math that when you die, God is able to show you this book and it has all of the theorems for everything listed out, right? And so when you die, you are able to see, oh, this was a theorem, this was the theorem. And over time we humans have been able to discover some of those theorems. But there are a lot more we haven't discovered. Now imagine a book of Ai, right? In a book of Ai Neural networks. And deep learning would be one of those theorems. But there are way more that we still have to understand and to to find, right to discover neuroscience is a great way to do that too.

Speaker 1:          04:02          Right? So touring, he had this computer program that he invented at the University of Manchester that accepted a single input, right? A single numbers input and output, a single number. And he wagered, and this is another famous thing by touring the tourings wager, that it would take someone a thousand years to figure out how that blackbox worked, how that number converted from one from one integer integer to another. And then he said he, he extrapolated from that idea and he said, well, if you think about the brain as that black box, it's going to take a really, really long time to figure out how that works. And he's, so he was very skeptical that we would be able to figure out how the brain worked, even though most of his work involved trying to recreate the, the brain in Silico. But if turning could have just seen the modern Sukkot supercomputers that we have, the advances in neuroimaging techniques that we have, he would have been blown away, right?

Speaker 1:          04:53          So, uh, yeah, it's, it's definitely possible to recreate the brain in, in, in Silico. But let's keep going here. So Nicola can pits two other neuroscientists, right? They invented the model of the single neuron. Now this is where it all started. They, they wanted to create some sort of mathematical model that represented how a neuron works. And this was a very basic model. The model said this, let's take some inputs, right? Some, some set of numbers x like this represented here. Let's apply some sort of function to that. And output is one single integer, right? That is something like what a neuron does. It's accepting these inputs, these signals, right? It's doing something to those signals and then it's out putting a signal and that signal propagates to other neurons. And that creates this network, this neural network of neurons, right? And then they kept going, right?

Speaker 1:          05:42          So then hop deal took, took this idea and he said, let me take them a call. It pits neuron, let me combine them together. So the outputs of one neuron are fed as the inputs of the next neuron and let's just keep doing that over and over again. And so this was called the hot dealed network, right? So this was the first recurrent artificial network. He connected Macola pits, neurons together, then came Hinton, right? So Hinton said, okay, we've got these layers of neurons. What is the best way to optimize these neurons so that it can complete its objective? Right? And so he invented with his colleagues the back propagation technique, which said, we've got some output prediction, let's compute the error based on what their label is. That's the era value. Let's computer gradient. The gradient says, how much do you update the weights of the network over time and what to update those weights incrementally backwards in the, in the, in the reverse direction as we forward propagated the input data. And this is called backpropagation.

Speaker 1:          06:36          And Hinton was also a huge proponent of a neuroscience level of thinking when applied to neural networks and machine learning, right during the AI winter when everyone said he was crazy, he stuck to the idea of neural networks being a way forward in AI. And it turned out and you know, as seen in the deep learning revolution of late that he was right. He was also a big proponent of neuroscience inspired ideas like dropout, turning neurons on and off randomly to pro to increase the generalization ability of a network of nonlinearities to allow a network to learn both linear and nonlinear functions, the idea of hierarchical and layered networks, et Cetera, et cetera. And so all of this leads up until now. The problem with now is if you were to ha, if you were to learn machine learning right now, if you were to learn about all the different types of models, support vector machines, random forest decision trees, it's not very clear that all of this, these things are inspired by neuroscience.

Speaker 1:          07:32          And in a lot of ways they're not. So there's this disconnect between neuroscience and AI that didn't exist before. And, uh, what's, what's happened is because the discoveries in neuroscience have just grown and grown and the discoveries in AI have grown and grown over time, these two fields have become so complex that it's hard for any one person to become an expert in both fields, let alone one. So it's hard to make any discoveries that, that intertwine these two. But the human brain is the only proof we have that this type of intelligence works. So it's, it's, it's, yes, it's hard, but it's essential. It's essential to do so. Um, Maher, uh, this other, this, this, this scientist had this idea of describing a biological system in three different parts. So one part was the implementation, the hardware of how you know this, this software is running this wet where you can call it.

Speaker 1:          08:25          Then there's the algorithmic part, what representations can implement such computations. And on top of that is the computational park. Why do things work the way they do equations on top of those initial algorithms? It's hard for us to work on the implementational part because creating hardware requires a lot of capital, right? Not everybody's got that money. So we need to focus on the algorithmic and the computational parts and anyone with a laptop and Gpu in the cloud. So this is being democratized can do that. So now let's talk about neuroscience. Okay. And and how it's played into Ai. So there are four key areas in AI that had been affected by contemporary neuroscience. The first is attention. Okay. So the brain does not learn by implementing a single global optimization principle within a uniform and undifferentiated neural network. What I mean by that is it's not like we have some giant LSTM network running everywhere, right?

Speaker 1:          09:18          It's not some giant recurrent network. We have different modules that are good for doing different things. So one part of the brand could be doing something like a hot build network and another one could be an LSTM network. And another one could be, you know, a self organizing map. And so there are different modules that are good for different things. And so up until now, for convolutional networks in particular, which are networks that are good for working with images, the, they worked directly on entire images or video frames with equal priority given to all the image pixels. But we learned that the primate visual system works differently rather than processing all the inputs in parallel. Visual attention shifts strategically. That's the key point here. Strategically among locations and objects, centering processing resources and represents [inaudible] coordinates on a series of regions in turn. And so recent Ai, um, discoveries have implemented this idea of an attention mechanism, uh, focusing on the parts that are most specific.

Speaker 1:          10:15          And usually the way they do this is by having some weights for this attention mechanism that are updated via gradient descent over time. And so there are differentiable weights and so the network learns where best to, to focus its attention on, in whatever the input data is as it updates over time. Another key area is episodic memory. So the difference between semantic and episodic memory is this semantic memory is very concrete. It's like, you know, this is an apple. I know that this is a, you know, this is a bad, this is a, you know, whatever episodic memory is more continuous. It's about an event that has happened in the past. And we have that, you know, we've, we've learned this from neuroscience that we have both types of memory. It's one of the canonical, uh, themes in neuroscience that we have that are intelligent behavior, relies on multiple memory systems.

Speaker 1:          11:04          It's not just one type of memory and a so deep mind recently, you know, created this deep cue learning algorithm, right? So this is the reason that Google bought them. What they did was they were inspired by the idea of episodic memory and they created this algorithm called deep to that used, experienced replay directly inspired by the idea of episodic memory. And here is the pseudo code for that, right? So we initialize some replay memory d and this can be considered a data store, like think of it as an array. Okay. And then we initialize some action value function that we update over time. And then during the training process, the agent selects a, an action from some probability distribution. It executes that action, it gets a reward and then it, it stores that transition inside of the episodic memory and then it performs grading the to update its waits and it repeats and every time it, it re re does this for a new episode.

Speaker 1:          11:57          It's sampling not just from this random distribution but from the episodic memory that it's stored over time. And so the, so this replay memory episodic memory is same thing. In this case it's kind of like this external memory store, right? And so it was, it was inspired by it and it was critical to his success over time. This thing was able to succeed in like 16 or more a different Atari Games. The same algorithm, which is incredible if you think about it, the same algorithm, 16 different novel environments. All it was fed was the pixels of the game. That is very incredible. The third is working memory, right? It operates over a few seconds. Temporary storage manipulates information and focus his attention while you're working on something, you're, you're using some memory on that, right? This is very similar to episodic memory. We know from neuroscience that we can maintain and manipulate information with an active store.

Speaker 1:          12:51          No one has working memory. So one way that we've implemented that in AI is through the idea of long, short term memory LSTM cells, right? These are cells that have certain gates and implicate a forget gate. And what these gates actually are our perceptrons, there are many, uh, neural networks that have weight values. And as we differentiate the LSTM network, these weights are also updated over time. And what happens is the gradient is trapped in these weights. So when, when we're, when we're, when a recurrent network is reading in some sequence, whether that be text or numbers, over time, the gradient slowly vanishes as it goes more and more back in the network. And the problem with this is it's not updating the weights at the end, at the input of the network, as much as is updating the weights at the end of the network.

Speaker 1:          13:38          And this is a problem if there's gotta be an equal update. So LSTM networks help prevent that from happening by storing, by locking in that memory over time. And this was directly inspired by neuroscience, the idea of working memory. But the problem with LSTM cells are they take the function of sequence control by controlling what to do next and memory storage and stores them together. When we know that the brain working memory in the brain separates these two concepts, so updated an updated version is called the differential neural computer. Okay. So the idea is that there is an external memory store, which is essentially a matrix and we have some input data and then it outputs a prediction. And in the middle it's updating not just the weights of the network but the external memory store. So normally the weights of the network or the memory, but if we, if we take that memory and we create, uh, uh, you know, we, we create an external memory store, we can separate these storage of memory from the processing of the network itself.

Speaker 1:          14:39          And this let it do things that an LSTM could not do. A wide range of complex memory and reasoning tasks like finding the shortest path through a graph, like structure, like a subway map for example. The fourth and last thing from contemporary neuroscience is continual learning, right? We are constantly learning things, right? We're learning how to record youtube videos. We're learning how to read a book. We're learning how to run, we're learning how to do karate. We're able to learn how to do all these things. We're able to learn how to do all these different things with one brain. But there's this problem in neural networks called catastrophic forgetting, where if we take a neural network and we say, learn how to do x, right? Whatever that objective is. And then we take that same neural network and we say, okay, now learn how to do y.

Speaker 1:          15:25          What? Whatever it's learning for that second training iteration is going to overwrite the weights. Eight learned for the, for the first one. And this is a problem, right? We don't want that to happen. So there is this synaptic consolidation were connections between neurons are less likely to be overwritten if they have been important in previously aren't tasks. So, uh, one way to prevent that is this idea of elastic way consolidation, right? We can use, first of all, by the way, we can use advances in neuroimaging to further study how these, these, um, connections are happening in the brain. The idea behind elastic wait, consolidation is that it's, it's slowing down. Learning in a subset of network weights identified as important to the previous task, thereby anchoring these parameters to previously found solutions. So it, it, it allows the network to learn multiple different tasks. And I'm not saying it does it perfectly, but it's one step inspired by neuroscience that lets a neural network learn different tasks over time.

Speaker 1:          16:28          So now let's get to the future, right? Five areas of AI that neuroscience will improve. And I've got this image here, symbolic concepts, computation and there's a lot of ways to divide all this stuff up. You know, there's, there's, there's a lot of ways but uh, okay. So the first thing is understanding physical reality. Okay. Human infants we have learned are able to interact with the physical world in a way. They have these core concepts built in like space and number. Like how did the concept of space and object, Nis, all these things. Now, if you think about robots, right? If you think about robots in simulations, they work great, right? If you, if you have a robot pick up an object in a simulation, it works great. Just try to take those learnings and apply them in a real robot and the real world, exact same setting.

Speaker 1:          17:12          I promise you it won't work. Okay? Almost all the time it never works because when it comes to the physical world, our current models are just not good for some reason. So we've got to figure out how, why, why that is happening, right? Why does it work so well in simulation? If we, if we have all of those variables together, you know, in, in, you know how the arm is moving, the physics, the inverse kinematics, the gravity, yet it just doesn't work in real life. Why? We got to figure that out. And that's a way that neuroscience can help. There's this idea of the interaction network. It's very recent. It's a very recent model that I want to learn how this bowl is bouncing, right? And so what it does is it separates relational reasoning with object reasoning. And that's, that's as much as I'm going to get into on that cause there's a whole video I can make on how that works.

Speaker 1:          18:00          The larger point I'm trying to make here is that any task that seems very simple, if you really think about that problem for a while, you realize that there are so many different sub problems there, right? So if you think about a problem a lot, there are sub problems, right? It's not just reasoning, it's relational reasoning, it's object reasoning. And as we study this, more and more will realize what those sub problems are, which will help us in the larger scheme of things. No what the overarching solution to those problems are. Okay. So check out this interaction network paper as well. I've got a link to it in the description. Um, efficient learning, right? Building Metadata, Meta knowledge, right? We are able to look at something and after only a few examples know exactly what to classify it as, right? You show me a picture of something I've never seen before and very, very likely.

Speaker 1:          18:47          Show me another picture of something similar and I will know exactly. However, with deep learning, we've got to show this deep neural network, hundreds of thousands of sometimes millions of images for to be able to classify. And this is not how the human brain works, arguably. And so the idea of metal learning is very important and it will be more important in the future of AI, which is also very closely related to transfer learning, right? So normally we would say, okay, here's a neural network to learn this. Now here's a neural network to learn this and here's the neural network to learn this. But what if we could have the same neural network apply what is learned from some previous task to this task? That's the idea of transfer learning, which we're really, really good at. So there was a recent report from this paper, uh, from two years ago that said that neural code is thought to be important in the representation of nap.

Speaker 1:          19:35          Like spaces might be critical for act trek reasoning in more general domains. Uh, aloe centric means map like spaces in this context. But the idea is that aloe centric coding systems and code the location of one object or its parts with respect to other objects, egocentric is in relation to the self to other things. But what this finding was was that the location information that we encode about objects and how they relate is important for abstract reasoning in general domains. And this is a very new finding and we can apply that to AI and a lot of ways, uh, right. So lastly, I'm going to talk about imagination. Well actually two more things I want to talk about imagination and planning, right? So deep Q was awesome, right? But the problem with the Deq was it was reactive. It was seeing how the environment reacted to what his actions were and then it reacted to that.

Speaker 1:          20:30          It wasn't proactive, it wasn't sitting there planning out all these different trajectories. But what we've learned is that the h that is that we do this, right? Humans plan out things, whether it's consciously or subconsciously, we plan out how things are going to happen in her head before we execute that action. And so we have this imagination, right? This is essentially imagination happening. Uh, there's this great architecture by deep mine, very, very recent. It's called [inaudible]. Um, but, uh, I could also make an entire video on how that works. I've got the link to the paper here if you, if you'd like to see it. But, uh, the idea is that it's using this external module for imagination and in a single rollout, it's making these predictions. So for neuroscience, for Ai, the idea of imagination is going to be very, very important in the future.

Speaker 1:          21:15          And we can learn a lot about how this works by looking at how humans plan out and simulate actions in their head before they actually execute those actions. Now, last thing I want to talk about our virtual brain analytics. So deep learning has been thought of as being a black box and that makes sense. Deep neural networks are very complex with sometimes a millions of parameters, right? All these different numbers in the matrices. If our weights, how are we supposed to visualize that? Right? And there've been, you know, people who've said, okay, we've cracked open the black box, but let's be real. In a lot of ways we haven't, there's so many different types of neural architecture is that it's hard to say. We have just totally figured out how neural networks work. It's not true. We still have a long ways to go, but what we can do is we can apply findings in neuroscience to that too, to help with that problem.

Speaker 1:          22:02          The idea of two photon imaging, for example, allows us to noninvasively mapped out how neurons are interacting in our, in our, in our brain. And this is very, very recent. If we can take that and then we can apply that in Silico that idea of neuroimaging, we can better understand how our neural networks are working, uh, on our computers. Visualizing brain states through dimensionality reduction is commonplace in neuroscience and it can be applied more in AI research. So this is going to be very important as the complexity of neural networks increases over time. And as soon as we create this, it's going to be not just good for AI research, for AI ethics, for Ai Productivity. Why is this AI doing this? What, why did I come up with a solution that I did? It's going to be important for both business, for ethics, for research, for everything, so more explainable solutions. And we can look at neuroscience and neuro neuroimaging as a way to help with that. So that's the end of this video. I want it to go over some things that you know could, could get you thinking about how the brain inspires AI and how it will inspire AI in the future. Check out this spectrum is a repository. Link to it in the description and hope you like this video. Please subscribe for more programming videos. And for now, I've got to study my brain. So thanks for watching.