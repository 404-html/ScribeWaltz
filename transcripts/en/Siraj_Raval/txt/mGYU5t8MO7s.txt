Speaker 1:          00:00          Yes, you too. Again, soccer one day I'm going to make a Bot that beats you in any game you're telling yourself. That's right. Hello world. It's Saroj and let's make an amazing video game bought and just 10 lines of code that can play a huge variety of games. Could you games have been around since the 50s when Joseph Kate's publicly demos tic TAC toe at the Canadian National Exhibition that bought you simple scripted actions that ran the same way every time regardless of whatever move the player made his demo. Got People hype though because no one had ever seen a computer play a game before and they were lining up off the block to check it out. The game bots that were invented afterwards for games like Nim and space where we're similar, but along came Polly. I mean pawn the pawn bots paddle had to make decisions based on the human players actions and that made it feel more realistic.

Speaker 1:          00:51          Pong mark, the beginning of using Kirstik's sticks to create game bots. Heuristics are educated guesses and pretty much every single video game bought since punks has used them. A Bot. We'll map out a possible set of decisions as a tree of possibilities. Then use one of many techniques to pick the best one, but it's cool as that sounds. It's still always boiled down to a bunch of, if then statements, if pac man moves this way, then the blue goes should move this way. If master chief sees a grunt, then it should run in circles like my Facebook newsfeed. If Captain Falcon is being annoying Aaf, then your team bought should help you pawn him. Squad goals, but yeah, video game bots are pretty much always sucked because there are only so many edge cases that a programmer can predict. Like if the human in fallout three has a pistol and isn't moving and there are no enemies nearby, run into each other, we need to think about this problem differently.

Speaker 1:          01:43          When you or I start playing a game, we don't know anything about its environment beforehand. The hallmark of intelligence, it's our ability to generalize, but can we make artificial intelligence that can generalize to solve any task? A team of researchers at deepmind recently got close by creating one bot that could be almost any Atari game. Knowing literally nothing about the game beforehand. No gain specific hard coded rules at all. It was just fed the raw pixels of the game and it's controls using those two things. It learned how to be almost any Atari game it was given. It did this using a technology called deep learning. If you take a deep neural network and feed it lots of data and compute, it can learn to do a whole lot of incredible things. The field of deep learning right now is where physics was in the early 19 hundreds the state of the art in a huge number of subfields like vision and speech is being broken almost every other day.

Speaker 1:          02:38          It's a very exciting time right now and Marie curies and Albert Einstein's of computer science are all alive right now and newcomers are coming in every day. Deepmind is awesome and they keep a good chunk of their code private since Google uses it to outperform its competitors. But then Elon Musk came along and it was all like, I think it's important if we have this incredible power of AI that if not be concentrated in the hands of a few. And so he co founded a nonprofit called open AI, whose goal is to democratize AI so anyone can use it. And just today they released something called universe. Universe is a platform that lets you build a Bot and test it out in thousands of different environments from games as simple as space invaders to grand theft auto to protein folding simulations that could cure cancer. You can create a Bot and the better you make it, the more games it'll learn to become amazing at. You can compete with other Bot developers to see who's bought beats. The most games and universe has other environments to or web interface tasks like managing emails and booking flights. If you create a Bot that's able to defeat any environment, you're not only the dopest coder of all time, you just solved intelligence. We could then use your bot to solve literally everything from global warming to poverty to all known diseases.

Speaker 1:          03:53          So with that, let's create our first simple bot in just 10 lines of python code. In our first two lines of code, we'll import Jim and universe. Gym Is Open Ai's original code base. That universe builds on and extends to include way more environments and features. Those are the only two dependencies will need. Now we can select our environment. We'll define an environment variable called ENV and use. Jim's make method to define our environment parameter. There's so many to choose from. It's hard to pick, but let's go ahead and pick the popular flash game coaster racer. Universe lets us run as many environments at the same time as we want, but for now let's just use one. Our next step is to initialize our environment. With the reset method, it will return a list of what we call observations. For every environment we've initialized an observation is an environment specific object that represents what the agent observes, like Pixel data of what it sees and the state of the game.

Speaker 1:          04:49          Initially we'll just have an empty set of observations since the game hasn't started yet. Now that we've initialize our environment. Let's go ahead and create a while statement so our agent will just keep running indefinitely. We're just going to have our Bot do one simple thing. It's going to hit the up Arrow. This is formatted by first specifying the type of event, the key then true, which means press it and we'll do this for each environments observation. We'll call this an action and store it in our action variable. Now we'll call our environment step method to move forward one time step and use the action as a perimeter. This is our implementation of reinforcement learning are Bot will take an action in our case pushing the up arrow. Then it will observe the result and may or may not receive a reward if that action was beneficial to its goal, which in our case is increasing the game score.

Speaker 1:          05:36          Open AI uses a custom image recognition module here to read the game score in order to return. A reward is module is included in the environment, so we don't need to worry about it. If it doesn't receive a reward, we could update our Bot to do similar actions in the future so it gets better over time through trial and error. So the step method returns for variables and observation of the environment or reward a yes or no value if the game has done and some info like performance timings and latencies for debugging, and it'll do this for all the environments you train your Bot in simultaneously. Lastly, it will render the environment so it's visible to us. Let's demo this baby. I'll run the code and terminal and it'll connect to our VNC server in our local docker container running a flash enabled chrome browser.

Speaker 1:          06:20          The pre scripted mouse will click through the necessary screens to get the game started. Then our Bot, we'll start programmatically controlling the game remotely. Yeah, our Bot really sucks, but how dope is this? We can do this for as many games as we'd like and to make it better, we can try different strategies like random search or he'll climbing or just replicate what deepmind did. They fed the observations that they're bought received into a neural network that updated its connections to get better if it received a reward. Open Ai already has a starter bot that uses deep reinforcement learning via tensorflow that I'll put a link to in the description. And so to break it down, open AI's universe is a platform that lets you train and test bots or thousands of games and other environments. Reinforcement learning is the process of using trial and error.

Speaker 1:          07:04          Similar to how we learn to improve a bot. And if you create one Bot that can succeed in any environment, it's given you just solved intelligence. The coding challenge for this video is to create a Bot or just Kosta racer that is better than this is demo code posts. You'll get humbling in the comments and I'll give a shout out to the winner in my video one week from today and I'll do a one on one Google hangout with them just to say hi and talking about whatever. For now I've got to make a laundry folding robot, so thanks for watching.