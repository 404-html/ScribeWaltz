Speaker 1:          00:00          Hello world, it's a Raj and Numenta. Today I'm going to talk about new mentees. Hierarchical temporal memory system sounds super complicated and it's not actually. So this video is going to be me explaining how it works and how it compares to the hottest technology of today, which is deep learning, right? We hear a lot about deep learning. I make a lot of videos about deep learning. Everybody talks about deep learning and the machine learning community, right? That is the set of algorithms that it's outperforming everything else on a specific set of benchmarks. But there is this other technology called hierarchical temporal memory that this company called Numenta is working on that I think deserves some light and some attention. And especially now as back propagation we found is starting to face some limits and we have to create new algorithms and entirely new architectures and ideas to continue to progress the state of the art.

Speaker 1:          00:54          So I want to talk a bit about how this works. We're going to go over the code at the end, but before that we have a lot of theory to cover. Okay, so let's just, let's go. So, uh, Numenta is this company slash research organization based in Redwood City and it was started by a guy named Jeff Hawkins. So if you don't know who Jeff Hawkins is, he's the guy behind the palm pilot, uh, which was that phone with, with the pen. And he sold it for a lot of money back in the day. And basically the dude had a lot of money and he had decided to put all of that money into Numenta, which is this research organization. He also published his book in 2004 called on intelligence. So I've got this timeline right here of, you know, the all the milestones and it's a great book.

Speaker 1:          01:36          So you should definitely read that book. I read that book. It's essentially a pop neuroscience book that explains some of his high level ideas of how the brain must work. And uh, Andrew Ang, the popular Stanford professor behind the machine learning course by core. Sarah also admits that he was one of his influences. So definitely read that book on intelligence. It's a good book, but okay. So from there he published the book. He started a new mentor in 2005 and since then they've been working on this system that they call the hierarchical temporal memory system that aims to replicate the human neocortex. We're going to go into all of that in a second, but the goal, Jeff Hawkins goal and his team's goal in making this system was to study the human neocortex and establish it's working principles. How does it work? What are its rules? Forget about current machine learning techniques, forget about mathematical optimization when it comes to second order optimization or gradients are derivatives, et cetera.

Speaker 1:          02:35          Let's just start with the neocortex and go from there. And He published the book. He opens doors, they open sourced this new pic platform, which is the new [inaudible] platform for intelligent computing. And there are really four ways to get started with our technology that they've released. So they've got some research and theory. So there there are resource or organizations, so they're publishing papers and from those papers they have some technology that they developed. And there are four ways to get into this. The first is called Grok. So Brock is an actual product that uses the new pick technology for stock market stuff, but I'm not going to talk about that. There's also the anomaly detection engine which is licensed. There are some sample apps and then there's new pick itself, which is that's what we're going to go into this new pick technology. They all serve their own purposes.

Speaker 1:          03:21          And uh, for the, for the data scientists slash high level programmer like good programmers, new pig is the way to go, which is who we are. So of course we're going to go into that. We are the coolest people on the planet ever, ever by the way. We are. So cool. Don't, don't, don't get me on this tangent of how cool we are right now. But seriously, man, I, I, I've been reading your comments. I'm just looking into the discussions and the slack channel and the Youtube comments on Twitter, on Facebook and man, I mean, you guys are so smart and I'm just so honored to have you guys as an audience and I'm going to continue to make content for you just to short, you know, Love, love tirade from me to you. But, uh, yeah, you guys inspire me that I just wanted to say that, but back to this.

Speaker 1:          04:03          So how is HCM different from deep learning? Right? Deep learning works. Why are you talking about this? Saroj what's the point, right? The machine learning sub reddit laughs at this technology half the time. It's true. They do. But uh, that's, you know, it's okay. We need to give them some love, some light. Look, they're trying to solve AGI. Okay. There's trying to solve it and show them some love. Okay. So the idea is that AI 1.0 was all about hand coded systems, right? Heuristics, things like that. Custom engineering. But then AI 2.0 was learning from data sets instead of hand coding rules and so deep learning, artificial neural networks and also in, you know, in a lot of ways support vector machines and a whole bunch of other machine learning models. All of those fit into this category. But AI 3.0 in the way that Numenta views it is using html, which is true machine intelligence.

Speaker 1:          04:52          So, okay, so the difference here is that the one really key difference is that the HCM technology uses online unsupervised data. So you can't compare it to deep learning. So here's what I mean. So when we're using deep learning, we are training it on some static data set, right? We're saying, okay, here's a bunch of images like the CFR data image, image net or something like that. And we're saying learns from all these images. Okay, you've learned it, okay, now it's time for inference. It's time to use this predicted model in the real world. So the way HTM works is it's using streams of data, it's learning in real time. Online means in real time. Offline means like beforehand, right? So that is really cool. 10 portal streams, right? So streams that are continuous that are sequences of data, which is how we learn, right?

Speaker 1:          05:38          We are constantly getting these temporal streams through our eyes, through our senses, through our mouth, knows all of our five senses. This is, this is sequential data that our brain is learning from online or in real time. So the closest comparison to what the HTM is is the LSTM network. So recurrent networks are all about using sequential data, right? It's sequential data. So our recurring net when at every time step, it feeds in not just the, the, the input data. It also pre feeds in the previous Laurent hidden state. That encoding that it learned itself so that it can learn sequences of data because you know the, the, the ordering matters of data, right? That's why it's feeding in the previous hidden state sequences in sequences, the order matters. However, what happens is for recurrent networks, what happens is over time it, it, the gradient can't back propagate enough.

Speaker 1:          06:32          The grading gets smaller and smaller and smaller as it goes from the last layers to the first layers. And this is a problem, right? Ideally the gradient doesn't vanish, right? This is called the vanishing gradient problem. So the first layers aren't updated as know as, as much as they should be. So the way to prevent that is to use what's called an long short term memory or Lstm cell. And you use that Lstm cell and it's got this input gate, he's got an output gate, it's got to forget gate. Uh, but basically it's job is to kind of trap in memory over the longterm. And so when using this LSTM architecture, we're able to it on longer term sequences, like entire books, entire novels. And so we can have, you know, someone, uh, an AI output, the writing of Nicha after a reading, thus folks are Giustra or, um, beyond good and evil.

Speaker 1:          07:17          Great book by the way, beyond good and evil is such a great book on another tangent, but back to this. So anyway, so let's keep thinking of entirely new architectures guys. Like we can't just say, all right, deep minds, deep deep Q network. Oh, it beat Atari. It'd be like 20 different Atari Games. Great. Feed it more processing powers and you know, Agi, there we go because look back propagation is not the end. Okay. I am not a neuroscientist, but I'm pretty sure that our brain is not back propagating gradients. Okay. There's gotta be something more to it than that. So let's keep thinking of new architecture. So let's keep this, uh, this, this pace of innovation going well. You know, we, we've got the hype train started so, so let's keep it moving here. So the ATM is directly based on the New York neocortex. While deep learning is slightly inspired by neuroscience, right?

Speaker 1:          08:02          So it's, you know, input times wait, activates, right? Their Matrix operations and you know, sometimes they'll, researchers will incorporate ideas from neuroscience, like replay memory for example, but it's not like just directly, you know, neocortex inspired like what these guys are trying to do, which I commend. I think it's a great idea. It's not giving them great results obviously right now, but the idea is good and, and eventually it will keep in mind people laughed at deep learning in the early days, right? Deep learning in the 90s. And before that was a joke. And now it's the hottest technology. So you know, sometimes it's just that little tweak, that little innovation that sparks a revolution. So the Hem, the hen M can learn complex temporal structure with several orders of magnitude, fewer examples, dozens rather than millions and can also be easily configured to do reliable one shot learning learning from a few examples in specific cases, not all over la, not not in every type of data, right?

Speaker 1:          08:57          This is sequential data for specific types of sequential data. But the idea is that we have some hierarchy, right? We have some level of stacks cells and it's, it's temporal in that it operates over time series data in an unsupervised manner. And Colin's themselves decide to activate based on input previous states of connected neighbors. So there, so you might be thinking, well it sounds kind of like convolutional networks, but the only way that the HCM is like a convolutional network is that it is a tree like structure with locally connected, Aka sparse weights. But unlike convolutional nets, it doesn't use shared weights. Okay. So in a way, it's basically like an auto encoder. It's like a recurrent auto encoder that doesn't use doc propagation. It uses what's called heavy and learning or a variant of heavy and learning. It is an auto encoder that is recurrent and uses heavy and learning.

Speaker 1:          09:53          That's the Tldr of HTM right there. Okay. So, but for me, if the really the main thing that interests me about HTM is the fact that it uses online data, like real time data and in terms of algorithms that can do that from real time data streams, I can't think of any that don't use experience replay. And it does this quite well. Like you can learn a sheet of music for instance, after as little as 26 iterations. And uh, you know, I've got this video here, it's a shadow of a demo of someone who built in, hey, I drum composer,

Speaker 2:          10:28          check this out.

Speaker 1:          10:35          Yeah. So anyway, uh, check out this video as well as in the description. But uh, there are, there are some really cool applications that have been made with the HTM. Didn't, you know, they have these hackathons and they have people make things. So there are definitely, um, cool applications that have been made using little data. So it definitely deserves more exploration.

Speaker 2:          10:54          Okay.

Speaker 1:          10:55          Okay. Anyway, so hierarchical temporal memory explained, it's all starts with the NEO Cortex, right? Who you are, your identity, your memories, how you think, how you move, how you create, how you learn, how you talk, all of that you are stored. It's all stored in your neocortex. That is this central part of the brain right here. It's very wrinkly. But if you, if you flattened it, it would look like a, like a dinner Napkin. It's, it's very, it's very small, but the rest of the brain, the mid brain is about remember, remembering things, interacting with others, and then you've got the reptilian brain in the back that's all about, you know, basic bodily instincts like survive, react, repeat, repeat, repeat. Right? So, but the NEOCORTEX is really the seat of intelligence and that's what they're trying to replicate here, right? So reptiles don't have one. Only we mammals do.

Speaker 1:          11:43          Um, and uh, it makes you, you, so what the cortex does is the neo cortex learns a model from fast changing sensory data through our eyes, nose, mouth, ears, and the model generates predictions, anomalies and actions. And most of the sensory changes are due to your own movements, right? So the neocortex loans a sensory motor model of the world, the motor part is from movement, right? So, and what we know is that the regions are linked together in a hierarchy. So ideas become more abstract and permanent up the chain as we go up that hierarchy. So recall from deep learning, neural nets do this as well, right? They formed this hierarchy of features, especially, you know, when you think about image classification and classifying the canonical example, which is, which are dogs and cats, right? You've got your, you've got your low level shapes and then higher level and high level, and then a face of a dog from an eye all the way up to a face and an hierarchy.

Speaker 1:          12:34          And this is similar, right? It's all very similar to how the NEOCORTEX works in terms of hierarchies. But there are some principles that they're following here. So that the one principle is that there is a common algorithm everywhere in the neocortex. There's one algorithm to rule them all. They also operates on sequential memory and online learning, right? So the input and output of the neo cortex or our sensory input and motor commands and what it acts as our sensory organs, axis encoders. So what they do is they turn these input values that this raw data that we're being fed in into what are called sparse distributed representations, some kind of encoding, right? Some kind of encoded representation. And so there are a lot of different types of encoders out. Their gps in a way is an encoder, but which doesn't have a biological counterpart. It encodes all sorts of, you know, traffic data and map data and encodes it into something readable that we can look at.

Speaker 1:          13:26          But uh, so they have this idea of what's called a sparse distributed representation. And in this, the idea is it's just a series of ones and Zeros. There are different ways of representing data. Okay. In deep learning. We use this a lot as well. One hot encoding, there's all these different types of encoding models, but this is what they call them, right? So one example would be this, right? So zero one one zero, zero and so these ones and Zeros are what? What are encoded. And so neurons in in this system also use ones and Zeros to represent on and off states. And this is the data structure of the brain, right? Sparse, distributed representations. Everything is an SDR, right? It's used for every aspect of cognitive function. It's how memories are stored. It's how data is interpreted. It's how data is encoded. It's all using this SDR and neurons received them from other neurons and from everywhere else, right?

Speaker 1:          14:17          So it's from all over the place and you're on their side and you're on the top and they can overlap. I eat that. You can form sets and unions combining SDRs. So let's say we have two different scrs, right? Zero one zero and then other one is like zero one zero, zero, just a different set of numbers. How do we combine them? Well, we can use some form of addition of multiplication. There are different types of ways that we can combine different Sdrs. And so the idea of using an encoder is to take that data, numbers, dates, temperatures, gps coordinates, what have you, and convert them into an encoded SDR, right? So we have some raw data and encode it. And now we have this SDR. And then the temporal memory is this algorithm that learns, transitions, uh, patterns from this Sdr. And it learns continuously as well as input data is changing in real time.

Speaker 1:          15:08          The HTM model is updating itself, so it builds this predictive model of the world. So every time it receives an input, it attempts to predict what is going to happen next. So this is great for anomaly, a anomaly detection for life. Say The stock market for realtime stocks. It's good for musical data. It's good for, you know, you know, traffic lights and predicting, you know, traffic, et cetera. But anything that's real time. Uh, but they've got a part of the new pick platform. They've got this very cool visual editor that lets you encode data and look at what the different types of encoding looks like a, but basically you could say, okay, I have this date. How would I encode it? You could say the day of the week is going to be this set of squares, the weekend's gonna be this time of day season. And then combine that all and it looks like this. And then depending on what the date is, these blue squares change, like where the squares are are highlighted, highlighted. And this all comes out to a set of ones and Zeros. But there are certain principles to how, uh, this, this should operate. The encoder is the outermost system of the HTM. It's how data is, is encoded. It's how it's structured before it's fed into this 10 poral, um, memory algorithm. So, uh, the similar data should be highly overlapping, right? So same, the same input should create the same output. So it's deterministic data. The output should have the same dimensionality as the input and the output should have similar sparsity to the input. Okay. So

Speaker 1:          16:36          once that data is encoded properly, then it's using this spatial pooling algorithm. So the idea is that for pooling in general, it's all about what parts of this input that I'm getting from this data are the most relevant. And let me feed that forward. Right? So you know, in, in terms of convolutional networks, we have max pooling men pooling. They also use this idea of spatial pooling, right? So what its purpose is is to normalize sparsity of encoded representations. So it accepts an input vector and it outputs an output vector. And it's important when talking about sequential memory, it's maintaining that fixed sparsity is the goal, right? So the idea for Tim poor memory is that it learns sequences and it predicts outcomes.

Speaker 1:          17:20          So the idea behind the neuron itself. So in deep learning, the neuron either has an active state where it has an inactive state, but what they use as, they call this, the peer Middle Neuron, which has an active state on inactive state and a predictive state, and they, they consider. So now we're getting into this territory that kind of resembles a Hinton's capsule network paper. That was recently released. So the idea of neurons having layers and columns, right? So there, the idea is that in the neo cortex there are columns and layers and inside of these layers and columns are the neurons themselves. So in short, Hinton's capital network paper said instead of having this two dimensional neural network, right, instead of having neurons in two dimensions, let's have them as three dimensions. So it added a third dimension. And in a lot of ways to HCM is already doing that. They're adding three dimensions to this neural network architecture,

Speaker 1:          18:14          right? So the idea is that weak AI is not going to produce intelligence. We need to incorporate movement of some kind. I he interacting with an environment. So I he reinforcement learning. And you see that a lot from, you know, the, the breakthroughs that are happening out of deep mind or open Ai. They're heavily using reinforcement learning and so better neurons, I like the peer. Middle Neuron has have layers and they have columns. So there are three dimensional and it has both an active in an inactive state as well as a predictive state. And Dana doesn't, doesn't just flow feed forward. There's lateral inputs, so from other neurons in, in that layer. And then it's apical who so, so data is flowing down from the higher layers as well. So it's not just feed forward, it's happening apical, feedforward and then uh, laterally.

Speaker 1:          19:01          So in terms of similarities to hidden Hinton's capsule network, both systems are defined by the relative locations of features. And there's a voting process that figures out the most consistent represent interpretation of sensory data. But the big difference is that HCM models movement, it explicitly models how information changes as we move our sensors, like our eyes around and how to integrate that information quickly to recognize objects. So there's also a great blog post by Numenta on how HTM and Hinton's capital network paper are similar. I'll link to that in the description. Lots of awesome links are going to be in the description, by the way. Okay, so now I want to go into some of the code here. So,

Speaker 2:          19:41          okay,

Speaker 1:          19:42          here's their get hub repository. It's a, it's a really big project. They've got 434 issues, lots of, uh, great commits. It's, it's been around for awhile. This, this a repository. They've been working on it for years. So it's, it's, it's, it's, it's pretty well developed, but in the end you can install it with the simple pip install, like for Python, pip install, new pick and, and you're good to go. But what I want to do is I want to look at this example that kind of incorporates all of these concepts that I've been talking about together and they've got this great Pi Python Notebook here that I'm going to go into right now. Okay.

Speaker 2:          20:21          So,

Speaker 1:          20:26          right. So, okay, so we are, we're going to go ahead and get started with the num py. So let's, let's take a look at what's happening here. So we're going to import their encoder library called scalar and Coder, right? So we have some data like three, four, five equals right? And we want to encode deck and we can use this in co scalar and coder a class to do that until what happens is it encodes these numbers into their own unique representation. These are SDRs. All of these are sparse distributed representations, right? We can do that for a hundred we can do that for a thousand whatever number we want. And we can encode them different ways. There are different ways that we can create these representations in general. And there's a whole theory behind how we should best represent data, but right, so there are different ways we can do it for numbers.

Speaker 1:          21:13          We could do it for, we can do it for words as well, right? So for that we have the category encoder and then we have this spacial pooler. So for the spatial pooler we can initialize the spacial pooler, give it some parameters, like what are the dimensions of the input column dimensions, potential radius, just like deep learning. These are, these are hyper parameters that can be optimized right there. It's kind of like this, these magic numbers that researchers just kind of tweak and then different amazing results come out of that's, it's just like that. So we can say, okay, so for all of this input data, we're going to feed it through this spatial pooler and it's going to output the most relevant features from that data.

Speaker 1:          21:55          Right? So now that you know, once we have said this raw data, we've encoded into an SDR, we fed it through pooling, then we can apply the, the temporal memory, a algorithm to it. So it takes the form of this backtracking t m a function right here, which is, which is the optimization algorithm. We can call this the optimization algorithm right here. So we give it the number of columns, you know, the hyper parameters. We initialize it and then we say, okay, so we have our input data, it's going to be this set up one's and zero's. Each of these represents a different letter. And then we're going to, this is really the learning step right here. This is the, this is the training step, so to speak. So we can say for 10 iterations, uh, we're going to say, send each letter in the sequence in order.

Speaker 1:          22:39          We'll use the compute function of the TM, the, the, uh, temporal memory class to do that. And then we'll reset it at the end. And then at the very end, it's going to output how it's learning to predict the, it's, it's learning to predict what state it's going to be in and the numbers are going to get closer to the input data, that stream of input data over time, the learning process. So it's, it's very similar. You might be thinking, okay, so this training process looks very similar to um, backpropagation, right? So all of deep learning pretty much uses backpropagation, but they're not using backpropagation here. Uh, it's, it's more similar to what's called heavy and learning. Uh, it's, it's hidden inside of this compute function, but let's just go over heavy and learning as well. So basically a synaptic between two neurons is strengthened when the, when the neurons on either side of the synapse, but the input and the outputs have highly correlated outputs.

Speaker 1:          23:34          So in essence, when an input neuron input neuron fires, if frequently leads to the firing of the output neuron. So the synapsis strengthened. So, uh, heavy and learning is used in, um, what are called self organizing maps. So self organizing maps are a type of unsupervised learning technique that could come from neural networks that use heavy and learning like this. So it's kind of like whatever's closest in terms of like there's some measure of closeness, right, between input and output data. And so if, if, if, if the next data point is similar to what has already been learned in the encoded representation, then it's clothes, then go ahead and add some value there. So it's kind of like this map, so you get hotter, hotter, hotter, colder, colder, colder, right? And so then, uh, it's like clustering in a way. You can even think of it as clustering, right?

Speaker 1:          24:24          So heavy and learning helps do that. It helps, it helps group similar data together. So then when we have some new data points, it'll say, oh, it's, it's close to this cluster prediction, classification, whatever it is. Here it is. Right? So it's kind of like that. But, um, in terms of a, um, an equation for heavy and learning, we have this, right? Where is it here and then that Dah, Dah, Dah. Well, I just had it. I was okay. It's like that. So it's, it's, it's still a matrix operation. It's still map. It's still just matrix, multiplication and addition. There's, there's nothing magically different here. There, there are different types of wording or different terminologies, but the basic ideas are similar. It's just that they've architected it a bit differently from other types of neural networks. But remember, in essence, the HTM is very similar to a recurrent network. It uses heavy and learning and its uses online, continuous unsupervised data, data streams. So if you want to learn more about it, check out all the links in the description. And I hope you enjoyed this video. Please subscribe for more programming videos. And for now I've got to go call Hinton. So thanks for watching.