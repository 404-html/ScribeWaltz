Speaker 1:          00:00          Oh world. It's to Raj and today we're going to learn how backpropagation works in five minutes. Gradient descent is a popular optimization technique and can be used in many different types of machine learning models. It's used to optimize or improve the accuracy of our models. Predictions. One implementation of it that is particularly popular is for neural networks. A neural network is eight learning model that can make predictions. We give it some input data. The x values represent the input and the y values represent the expected output. Labels are networks. Job is to learn this mapping so that given some arbitrary input, it can correctly predict its output label. So our three layer neural network will first have an input layer. Each neuron represents a different row from our input data. Then it has a hidden layer. Data will flow in one direction from our input layer to our output.

Speaker 1:          00:49          And the way it does this is by having weights that connect each neuron in one layer to every neuron. In the next layer, we can initialize these weights as matrices with random values to start off with. Well multiply each row of the input by each column of our weight Matrix. The resulting values from this operation results in our hidden neuron values. We'll take each of those values and convert them to a probability value that is a value between zero and one by applying an activation function to it. The type will use in this example is a sigmoid, so each neuron receives a set of inputs, performs a dot product, and then applies an activation function to it. We'll just repeat this same process again. To calculate the output prediction, we compute the dot product of the hidden layer neurons and the next weight matrix between the hidden layer and the output layer.

Speaker 1:          01:35          Then we once again apply our activation function to it. This resulting value is our prediction and this process that we just completed is called forward propagation. If we compare this to our expected output, we'll see that our prediction is incorrect. We went to find the absolute best wait values that given any input, they would help calculate the correct output. To do this well, first went to calculate an error value. You want to minimize this error. If we were to create a simple graph of the error value versus some random weight from our network, it would look like this to smaller weight value in our hair is high but too big and our error becomes high. Again, we want an optimal value for each weight in our network where our hair is smallest starting at some random weight value, we went to take a step in the direction towards the minimum error.

Speaker 1:          02:19          This direction is the opposite to the gradient. If we take many steps descending down the gradient, eventually the weight will find the minimum of the error. We call this process gradient descent. So how do we do this? Well, we'll need to use calculus. Let's do a little refresher on three terms from calculus. We'll need to know the derivative is a term that means the slope of the tangent line to occur at a specific point in measures the rate of change of a function, a derivative of a function f of x gives you another function that returns the slope of f of x at a point x. For example, the derivative of x squared is two x. So at x equals to the slope is for a partial derivative of a function of several variables is it's with respect to one of those variables with the others held constant and the chain rule is the process we can use to compute derivatives of composite functions.

Speaker 1:          03:09          A composite function is a function of other functions that is we might have one function that is composed of multiple inner or nested functions. Say you have some function f of x and another function g of x using them, you form some composite function f of g of x. The chain rule states that the derivative of f of g of x is equal to the derivative of g of x times the derivative of f of x. A neural network is essentially a massive nested composite function. Each layer of a feed forward neural network can be represented as a single function who's inputs are a weight vector and the outputs of the previous layer. The purpose of backpropagation is to figure out the partial derivatives of our air function with respect to each individual weights in the network so we can use those in gradient descent.

Speaker 1:          03:51          It gives us a way of computing the air for every layer and then relating those errors to the quantity of real interest, a partial derivative. With respect to any weight in the network. We can use the chain rule to compute the partial derivatives. That is the gradient of the error with respect to each weight. Backpropagation at its core simply consist of repeatedly applying the chain rule through all the possible paths in our network. Our ultimate goal in training a neural network is to find the gradient of each weight with respect to the output. We do this so that we can update the weights incrementally using gradient descent. We reuse multiple values as we compute the updates for weights that appear earlier and earlier in the network. After we have the error for the output layer, we calculate an error for each neuron in the hidden layers going backwards layer by layer.

Speaker 1:          04:38          The air for a neuron in a hidden layer is the some of the products between the errors of the neurons in the next layer and the weights of the connections to those neurons multiplied by the derivative of the activation function. We will use those errors to calculate the variation of the weights. As a result of the current input pattern and ideal outputs. The variation or Delta of a weight is the product that the input neuron output value with the air of the output neuron for that connection. This process is repeated for all the input patterns and the deltas are accumulated at the end of a learning iteration. We changed the actual weights with the accumulated deltas for all the training patterns, and we multiply it with a learning rate, which states how fast network converges to a result. When we run our code, we can see this process in action as our prediction gradually increases inaccuracy. Please subscribe, and for now I've got to go derive the meaning of life, so thanks for watching.