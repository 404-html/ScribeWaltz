Speaker 1:          00:00          And Spacey. I love this combination of Siphon and spacey. This is one of my favorite combinations for machine learning. All right. Hello world. It's Saroj and welcome to my live stream on natural language processing in. See now I know a lot of you might be thinking why see write python works well enough. It's a great introductory language to bring a lot of people into the field, but there is a problem. And let me tell you what that problem is. The problem is that sometimes we want really fast implementations of machine learning algorithms. We want machine learning algorithms that are going to work very, very well, very, very fast. And, uh, you know, I'm talking about health care, I'm talking about life or death situations. I'm talking about times when milliseconds matter for both inference and for training. So what see allows us to do as a language is to manually allocate memory and manually deallocate memory.

Speaker 1:          01:02          So what's happening in python and the python runtime environment is a process called garbage collection. Okay. And a lot of you might be familiar with this, but garbage collection is a runtime process that automatically looks for, um, that looks for objects in memory that have not been deallocated. And if, if it, if it, depending on the type of interpreter we're using it, if it feels like it's time to deallocate that object, it will deallocate it for us. Now this is great because we don't want to have to spend our time dealing with memory, right? Allocating objects, d allocating them. We just want to worry about the algorithms.

Speaker 2:          01:40          Okay?

Speaker 1:          01:40          So, uh, that's why we use python, but sometimes it's necessary. So in this livestream, what I'm gonna do is I'm going to first demo how [inaudible] works. [inaudible] is by the way, is it's a bunch of sea extensions for python. So we could literally write c code inside of Python. And I want you to do this with me in a Google colab. So go to colab.research.google.com and once we've done that, we will, uh, we'll first coat out a python implementation, then we'll do a site on implementation. We'll benchmark both of them. And then we're going to use it for natural language processing, specifically using a library called spacey. And then after that we're going to demo it for a little bit more deep learning after that. All right, so we've got a lot of things to do in this live stream. Um, I will marry you Conrad. Thank you very much. I will marry all of you because you guys matter to me a lot, like a lot. So, okay, so let's get into this. I want you to do this with me in the browser. Yes, we can code, see inside of the browser. Okay. I'm going to show you what the deal is with this, but before we do anything, what I want you to do is installed two dependencies with me. Okay. Ready? So the first dependency we're going to install is sites on itself. It's acts just like a regular python package.

Speaker 2:          02:55          Okay.

Speaker 1:          02:56          Uh, but, uh,

Speaker 1:          03:00          so we have po, we have siphon, and then we're going to use spacey, which is spacey is an Nlp Library, the fastest and LP Python Library that exists currently that uses carefully constructed Siphon Constructs for memory management to allow for rapid, um, p part of speech tagging and, um, you know, tokenization and word two VEC [inaudible] and all of those little NLP techniques that we need. Okay. So these are the two libraries that we're going to install and this is going to take like probably two minutes to run. So just let's let these dependencies installed while we talk about, uh, the rest of this. Okay. So spacey takes a little time to install. So as you can see, spacey is installing right now, by the way, because of Colab, I just want to, you know, I gave, I gave Colab a shadow on, on Twitter, but really amazing tool. No longer can anybody use the excuse. Well, it doesn't work for my windows environment or my whatever environment. Now you can do it in the browser. All right, so back to this, right. So, um, python, it's great. Like I said, uh, but when it comes to execution speed necessarily, it's not that good necessarily. Okay, so,

Speaker 1:          04:10          right, so here's a little image we can see of, of what's happening here. When we writes out some Siphon code, it's going to be compiled by the siphon compiler. Now this is a specific compiler made to work with the python compiler is going to create two. Uh, it's going to create two different, uh, files, a c file and N. Dot. S O file. And both of them are going to be able to be launched from a python file later. Now what is the difference between C and Python? Now, not, not everybody knows. See, not everybody has been able to um, write spacey. Spacey is a very cool library. I really like spacey. So not everybody's able to has, has had experience with c. But what is the real difference between both of these languages? Well, there's one, um, besides the memory management stuff that I talked about, um, there is one thing that is a big difference and that is, uh, the, the idea of strong versus weak typing. As you can see in this image right here, right? So C has strong typing, meaning the type must be known by the compiler and Python has week typing. And this is for, this is, this is also for memory management reasons that it always comes back to memory when it comes, when it comes to the sea versus python debate. Uh, but

Speaker 1:          05:22          let's go ahead and write out a simple example first. So what I want to start off with in this example is some basic python. Okay. Let's see if our dependencies installed. By the way. See it's still running. It's gonna take a little a little while. But um, well, okay. So while this is, this is a download, let me, let me just answer some questions in the comment section. Someone, uh, is very happy that I use spacey. And why see though? Well, like I said, Mitch, mission critical applications need, uh, the, the maximum speed that we can, we can, we can utilize what were the two imports? The two imports are Siphon and spacey. Okay. So Siphon is the set of see extensions for python that we will use and spacey is built directly on top of scythe on. So it's like, it's not, it's not pure siphon but it's very close to it. And it's made specifically for Siphon. Which laptop do you have? I have a Mac book pro 2016 I think or 2017. I don't like the touch bar at all. Uh, and in fact, I, I envy people who don't have a touch bar. Can you please explain about both dependencies? Like I just did, I love, see, I love C as well. How much of see should I know? Great question. So if you're doing anything in robotics, right? So a mobile robots, factory, robots, um,

Speaker 1:          06:49          robots, then you're going to need to know some, see why? Because when it comes to hardware, what you're dealing with when it comes to robotics specifically is a bunch of integration issues, right? You've got to get the arm connected to the, uh, the body connecting to the wheel base, connected to the other arm or whatever it is. And all of these are drivers. Usually they're written in c plus plus or c. And this can be annoying, right? It's because we have to integrate all of these and ideally it was all written in python, but that's not the case. So we need to know some, see if we're going to do anything in robotics. Meanwhile, this is still loading. Have you tried Gpu Laptop? I have. I have. Yeah. Um,

Speaker 2:          07:30          yeah,

Speaker 1:          07:30          but you know what, overall I liked the form factor of the Oh, of Osx. I liked the fact that I can use final cut pro and uh, that's why so c is so much faster. Yes, it is.

Speaker 1:          07:42          I'm just going to, I'm just going to start typing this wild while this loads, by the way. So let's create these rectangles, right? So what are we going to do right now is we're going to create a big bunch of rectangles, right? In Python, pure python, no siphon. And then we're going to count how many rectangles we have. Okay? And so this is going to be a speed test. So let's just do this right now. So the first thing I'm going to import is this. Uh, and this is not going to require scythe on, so I can go ahead and just start coding this right now. So we want to create a random, a bunch of randomly size rectangles. That's why imported this pseudo random number generator called random. Now, inside of our rectangle class, good object oriented programming practice. We're going to have an initialization function. This, this is the initialization function for the rectangle. The rectangle is going to take two parameters. It's going to be the height and the width. So I'm going to have the height and the width, right? So though, because rectangles can have any different, the, the width and height of rectangles are different. That's why I have two parameters for those ELLs. It would not be a rectangle. Now I'm going to write out the formula for defining the area of a rectangle. What is, can anybody tell me the formula before I type it? It's going to be yes, it's going to be the weight or the width times the height. Very simple, very simple area formula. Now,

Speaker 1:          09:06          okay, so we have those two initialization functions. Now we can say, let's check out these rectangles. It's let's see what's what's happening here. So in this we're going to check to see if it's area is within our thresholds. So we're going to have some threshold value. Yes, this video will be available later on Youtube and I will answer questions periodically as I'm coding this. What we're going to have is a function that's going to check the, the um, area of each of the rectangles that I create. Now this counter variable in is going to start at zero. Now what we're going to say is for every rectangle that we have in our list of rectangles, which is our parameter, we're going to check,

Speaker 2:          09:55          yeah,

Speaker 1:          09:55          we're going to check if I just want to make sure this is proper. Um, right.

Speaker 2:          10:08          Nope. Yup.

Speaker 1:          10:15          Good.

Speaker 1:          10:18          Zoom. I'll zoom in a bit. Let me zoom in more. Okay. So for each of the rectangles that we have, we're going to say, we're going to check if that, if the right, if the area of the rectangle is greater than our threshold value. Now if it is greater than our threshold value, then we're going to say, let's increment our counter because that's what we're looking to count. And then at the end of all of that will return the number of rectangles that we have, number of rectangles like that. Okay. And I made the screen bigger. Cool.

Speaker 2:          10:49          Okay.

Speaker 1:          10:49          It could be less than, but let's just say greater than. Okay. So now we're going to say, let's, uh, let's have this main function and we'll call it slow because we're going to speed it up in a second. And we're going to say the number of rectangles is 1 million rectangles, 1 million. We want a million of these things, rectangles.

Speaker 3:          11:14          And

Speaker 1:          11:16          we're going to initialize this rectangles. Object to list that we're going to input. Yes. Move 37 is free. That we're going to input into the,

Speaker 2:          11:28          yeah,

Speaker 1:          11:29          a previous function that I just wrote.

Speaker 3:          11:32          Okay.

Speaker 1:          11:34          For every rectangle in the range of the number of rectangles that we have,

Speaker 3:          11:41          and then, and

Speaker 1:          11:42          closed that, and now I can perform the check. So now I'll perform the check and I'll say, check those rectangles. Check every single one that we have and just see, just see, like, uh, I'll call this check reg rectangled pie

Speaker 1:          12:03          or check rectangles pie now just to see if, how, how many rectangles we have. And now we can finally define that's 10 million, isn't it? 10. Oh, you're right. That's 10 million rectangles. That would have been a lot. Uh, it doesn't matter actually. They're really very small. The footprint is small and we can now print out everything that we have now. Okay, now let's see if this compiles. Good. Now let's time. Oh, let's see if our dependencies installed. By the way, are you serious? Oh No. Okay, great. Great. The dependencies installed. Yo See us coming. Relax. One step at a time. This is a process, my friends, this is a process. You can't start running until you start walking. Okay? You gotta walk before you crawl. That's not how it works. Okay? So let's run this thing. We'll say, let's run this. We have our function. Let's run it. Time it. What do we got here? Okay, this is creating a bunch of rectangles and it's okay. So there are 400 Oh let's see, there are 403,987 rectangles that were within our threshold, okay? And that took a CPU time of 2.23 seconds to do all of this. Now let's see how much we can speed this up using Psiphon.

Speaker 1:          13:28          Okay, so now here's how we're going to use C in the browser. Get ready for this. By the way, let me make sure everything's good. Here's how we're going to use see in the browser. Okay, so here we go. I'm going to say low. The extension on

Speaker 1:          13:45          this just told Colab to load a site on extension. Now let's do this. Okay, so now what we're going to do for this faster site on implementation is we're going to say, here, get ready for this. We're going to use a siphon flag like this. That's all we have to do. Now this, this, this code block is going to use Psiphon, okay? So the first Siphon, a file that I'm going to import, it's called PSI men and what this is, and I'm going to use the word [inaudible] specific keyword seat important. Instead of just pure import. Now what this is is it is, it is a memory management helper for python specifically poor, the poor object. We're going to use it to allocate and we can also use it to deallocate memory. Now in the case of this program, we're going to use pool to allocate a bunch of rectangles. Yes, the scream, the stream is recorded and you're going to get to see it later.

Speaker 1:          14:40          Okay? So that is our first tool. And then we're going to have some good old python as well. For our random number generator, we can use both sides on and python in the same code block under um, what's it called? Magic cell. Uh, magic sell keyword or something that this, uh, this thing up here. Okay, so now let's, let's do this again. So we're going to create the statement called see death. Okay, so what seed def is it to stay? It's a site on specific statement that's used to declare, see variables, types, functions, anything see related, we can use c deaf for that, right? So what we can do in c is create a struct. Our type rectangles. This is our type and now we can use pure see variables. A float for our with a float for our height. Okay, so that's our see deaf for our struck. Now it's just like Malaak. Exactly. It's just like Malak. Good question. Keep them coming. So now let's write our new check rectangles method. Okay, so check rectangles.

Speaker 2:          15:43          Okay,

Speaker 1:          15:44          cy instead of Pie. Now what are we going to give this thing? What are the first parameter is going to be of course, or a rectangle, but we're not just going to give it a plain rectangle. We're going to give it a pointer. Hold on. Pointer, pointer, rectangle. Because, because what is a point? Or can anybody tell me what a point or does a point or points to a space in memory? Why? Why do we use a point or why don't we just call that object as a whole? Because, uh, we can avoid making a duplicate of that object if we can just point to where it is in memory. We don't have to make a duplicate. That saves a space and that makes things faster. So that's where we're going to use a pointer to, to the memory. Yes. You need commas.

Speaker 2:          16:29          Okay.

Speaker 1:          16:30          So I'll call this rectangles and I'm going to have a number of those rectangles. Right.

Speaker 2:          16:39          Okay.

Speaker 1:          16:40          And I'm going to have of course, my threshold.

Speaker 2:          16:42          Yeah.

Speaker 1:          16:43          We want to save memory. Exactly. What's one of the core values that our community has? Can anybody tell me that's related to saving? Saving memory, saving money, saving time, saving energy. Unnecessary stuff.

Speaker 1:          16:59          What is it? So someone can tell me, well, like while I typed this, be frugal by the way. Okay, back to this, I forgot it for a second. Oh my God. I've forgotten one of my own core values. Our own core core value. All right, so see deaf that, that's that. Okay. So now we're going to continue. Like I said, we can you see that for declaring functions for variables as well. And so we're going to have this see variable int that. We'll use that for. Okay. So now we're going to do the same loop that we did before just like before except uh, s c arrays contained no size. So no size information that is, so we need to state it explicitly, which is what we're doing right here.

Speaker 2:          17:40          Yeah,

Speaker 1:          17:47          you guys are hilarious. By the way. You guys say the funniest things in the chat. Java is a robust and secure language. All caps. That is what needs to be said. You know, like completely random stuff like that is the greatest man. You guys are hilarious. Back to this. So what, what are we going to do here? Well, we're going to do exactly what we did before. We're going to take our weights. We're going to multiply by our height, and that's not our weight. I'm to machine learning mode right now. Our width by our height, that's going to be greater than our threshold. And then we can say increment that and we'll return the number number of them. Okay. Make sure that's all good. It's all good. Yup. It's all good. Yep. Now back to our main method. Now let's do this main rectangle. Don't worry, we're getting to the machine learning. We're getting to the machine learning. I just want to demo some scythe on. Just just show you the performance gains that we get from this thing and prove that we can code, see inside of this Colab as well, which I had to get working myself. This, it took a while, but really it's a, you know, it's easy.

Speaker 1:          19:02          Thank you. The area of the rectangle is initialized randomly for all of them. There are a bunch of them. It's not just one rectangle. So how many are we going to have? We're going to have, like I said before, a million. Okay. We have a million rectangles. We have this threshold value just like before, it's gonna be 0.25. Now let's use pool. Get ready for some python people or some seat. Now here, here we go with pool, by the way. Okay, so the pool object is going to save, is going to save memory addresses internally. And so then in the F it's not like garbage collection is not happening. It's still happening. Okay? Garbage collection is still happening. However, we can manually allocate and deallocate memory. In addition to that, which is going to save us some runtime resources. So I'll say four rectangles. Typo.

Speaker 2:          20:01          Where? Four rectangles. Uh Huh.

Speaker 1:          20:09          We'll see. We'll see where the typo is. So we're going to initialize our rectangles right now. This is our list of rectangles and this bracket is going to typecast r w w the object that we allocate here into a rectangle. So here is us using this pool object has men to allocate all of these rectangles just like that in memory. Now what's the size is going to be, this is some pure Seaver by the way. The size is going to be the size of the rectangle that we just defined.

Speaker 1:          20:46          All. All right Matt, this is going crazy with Java by the way. I don't know why you guys are mentioning Java. This is about c and Python. So get that job of talking about here. Yes, Java is lame. I agree. Java is lame. I'm just going to say that. All right. Back to this. Okay. Java. So old John was like computer science classes in like like 10 years ago. Um, I know I'm going to get some hate for that. I don't care. Anyway, I'm just kind of trolling. No, I mean it's true. I don't like Java anyway. I mean there is deep learning for J. I don't want to get too into this right now. I'm, I'm coding something. This is like an all out war of programming languages happening. Okay? So, so let's do this now. Okay. So we're gonna do the exact same thing we did before. So for every rectangle we have, we're going to initialize book it's WIC with and its height randomly that and that's why we imported that random, uh, that random important. Okay. So we'll do that for the width. We'll do that for the height. Oh my God. That's hilarious. Okay. So, um, so now we've randomly allocated all of these with all of these heights and now we can use our check rectangles function that we just defined and give it the number of rectangles and the threshold and we're good. Right? Right, right. Yes. Good. Print them out. Print them all out. Okay, everybody good?

Speaker 1:          22:34          Where's the extra parentheses? Gimme Line numbers people. Okay, let's see what's going on here. Is this going to work? Who knows?

Speaker 2:          22:46          [inaudible] [inaudible]

Speaker 1:          22:48          I see, I see. Okay, so it's got an error. Okay.

Speaker 2:          23:03          Okay,

Speaker 1:          23:04          Gotcha, Gotcha, Gotcha. Gotcha. This rectangle opulus. Let's check this out. Oh yeah. Right. Duh. All right, let's get back to this if rectangle. Right? Where's that? If rectangle dot w what does it say? What's the error? Okay, let's see what, let's see what I did here for rectangle. It's like one of these typing errors.

Speaker 2:          23:46          I'm like doing multiple things here at once. See that rectangle?

Speaker 1:          23:57          Yup. Yup. I see. So it's four rectangle in rectangles and that's how that goes. I know I should have enabled line numbers. Oh yeah. How do I do that? Enabling line numbers. Four rectangles. Let's see here. Okay. I'm just going to go through this siphon. All right. You guys are, you guys are distracting me. Hold on. I'm just going to put you in the corner for a second from, they've got cy thon imported the pool. I'm just going to go over, this could be cause necessarily. Anyway, we, we imported the pool for memory allocation and then we created our structure. Our struct are type a rectangle type. And then we said, let me just see, let's just do this. Okay, let's just compile that. Okay. This proves that we can compile, see colab. Okay, so that was the first part. Now let me do the same thing over here. I'm just going to break this up. Break it up. Okay. There we go. In valid syntax. Oh, you know what? It's gotta to be inside of a, I've got to have this magic thing going on. Uh, Sai Thong. Oh, okay. We, okay. We got some, we've got a lot of NLP NLP to cover. By the way, I have this code on get hot by the way, so definitely check it out. It's the latest repository that I have. Definitely check it out.

Speaker 1:          26:23          We've got other things to cover here. These are my comments, by the way. Some amazing comments. I have to say myself. What? Wait, we'll wait. Oh, okay. This one away. Okay, cool. I was, I was about to say like, wait a second. Okay, now let's time it. Let's see the difference in timing. Main rectangles fast. Good. Okay. Milliseconds. 842 milliseconds compared to what it was before.

Speaker 1:          26:53          Yeah. Control ml. Okay, thank you. 2.3 2.23 seconds versus 842 milliseconds. That is a two x. How many milliseconds are there in a second? 1,000 how many times were there 2000 so yeah, it's like a two x speed up for the same thing. Okay, so there we go. Rule number one, do not do a live demo. See, that's how exactly. If you, if you can't code it, sometimes you got a copy paste. You got to keep going. I'm a human, you know, so that's how that goes. All right, so now we've timed it. No. Okay. So that's it for [inaudible], straight to machine learning. Now we've got that out of the way. So when we're doing natural language processing, we're dealing with strings, right? We're dealing with strengths and see isn't necessarily all of these like, um, numerical functions aren't necessarily made for strings. But what's so what we need is to kind of intermediary solution that allows us to use the fine grain control over memory.

Speaker 1:          27:57          That c allows a, which allows for a faster execution environment but also a high level interface that lets us deal with strings. So what spacey is, is it's this great library. I love this. Uh, I love this branding by the way. Industrial Strength, natural language processing, fastest in the world, big claim, big, big claim. And look at this, look at this beautiful, oh man. As, as a technical writer, I just, I love their documentation. Um, I love their design, especially at like of the terminal window and the colors and stuff are very cool stuff. So when it comes to natural language processing, we have to do a bunch of, um, preprocessing steps before we feed any kind of text data in to a deep learning or machine learning model, whether it's a neural network or a support vector machine, right? This includes tokenization, part of speech tagging. Part of, let me slow down part of speech tagging, dependency parsing, a named entity recognition. What is this word? It? Well, it's a, it's a person. It's, it's a place, right? So,

Speaker 1:          29:02          so I really think like if we took this comment section and we just, I think the birth of all programming means memes come from the wizards in this common section. By the way, like we are the, we are the source of all programming means God is html. Exactly. Exactly. Okay. So all right, so that spacey, so let's, let's code some spacey right over 400 times faster than an t k which I've done videos on before, which is amazing. It's a newer, it's a newer lie. It's newer than El Nltk. NLTK is pretty old. So we gotta get, we gotta get with the Times. And the, and the coolest part I think is this idea word vectors, right? So before we input words into a machine learning model, we have to convert them into vectors. Okay. We have to convert them into vectors. And vectors are a representation that is easily possible by function.

Speaker 1:          29:56          Approximators like neural networks. So, so what does, what specifically is spacey doing two strings? Well, what it's doing is, what it does is it stores every string in a single Beta structure called string store. Okay. This is a, this, this, and then this is a c, this is a c object. And then all of these strings are indexed by a 64 bit sea level hash, right? So Hash is the same idea behind bitcoin. You know, this, this long string of characters like numbers and numbers and letters. And what this allows us to do is very fast lookup, constant time look up and constant time a storage, right? So retrieval and storage are both constant time, which is awesome. And this is very fast. But so that's what it's doing under the hood. It's converting every string into this, uh, in this, into the string store object, uh, it storing it and then it's you were indexed by this hash. So whenever we need it, we can, we can, um, pick it up. So,

Speaker 2:          31:00          okay.

Speaker 1:          31:00          Uh, yeah, so there's that. And so there's a bunch of things that we need to do tagging. So we're going to do a few of those examples right now. And the great thing about spacey is it integrates with all of these major deep learning libraries very easily. There are so many examples on get hub of this happening, right? Here's one example by the, here's the spacey a repository. By the way, they've got a bunch of great examples. If we just go under the examples folder, uh, we've got oh care os nice deep wanting care, Ross. All right, so what, let's see what they're doing here. They're doing an LSTM sentiment classification model, right? So they're trying to detect, you know, what the sentiment of some words are, right? This is natural language processing or a part of it,

Speaker 2:          31:41          okay?

Speaker 1:          31:42          So notice in their training loop before they, here's their LSTM model, before they give, uh, the, the, the Corpus, the text to the model to train, they are turning it into a bunch of vectors. Word vectors, right? Like I said before, how are they doing this? Well, what they imported spacey up there and then they said spacey don't load English vectors. So they've got a bunch of English factors preloaded just like that. And then we can take this NLP object and we can say, well, make it into sentences, get those word embeddings and then input those to the model. So this is a preprocessing step. Works very well with deep learning models. Let's do a bunch of those things right now. Okay. So the first thing we'll do is we'll set up spacey, right? So we can say import Spacey Dot Cli Spacey Dot Cli. Dot. Download. We want the English a corpus. And um, we'll say load

Speaker 2:          32:40          it right here. Yeah. And it's for English.

Speaker 1:          32:46          All right.

Speaker 1:          32:51          Yeah. Okay, we've got that. And now we want some test data. Okay. So let's, let's think of some test data. Um, I'm going to say, what do I want there to be for test data. Um, build it, train it, test it. Makes it be all day. Train it tests. It makes it smarter. Better, faster. No, no, no, no, no, no. What was it? What was it? Oh my God, I'm forgetting my own music. Oh my God. Okay. We got to see this for a second. Smarter Saroj how does this go? This was like build a train it test. It makes it denser or deeper. Faster or smarter, but, but at that the, okay. That's what it was. Makes it denser, deeper, faster, smarter. I got to read papers to try and make me smarter. I train my models into, cause my takes longer. Oh man, that's, that's a sick song by the way. Sometimes I'm like listening to that. Like, just like walking, like I'm listening to my own music. Okay. We're talking about spacey, not my smarter Song. All right. Where were we? All right. Yes, I know Hindi, by the way. I know Hindi. I know Spanish. I know [inaudible]. I know a little bit of Russian. I'm learning Chinese. I need to learn some Chinese. And uh, yes. So don't even question what the deal is, you know, like I know, I know, I know Hindi. Okay. So,

Speaker 2:          34:24          mmm.

Speaker 1:          34:26          I got to read papers to try and make me smarter. I train my models. Okay. That's the second line.

Speaker 2:          34:38          Okay.

Speaker 1:          34:39          In the cloud now, because my laptop takes longer, I parse through data like a one more line and then we're done.

Speaker 2:          34:51          Okay.

Speaker 1:          34:53          Like, like a boss now. Back then mock code was wronger subscribe if you want to learn. Now let's spread this AI power. Okay, so four lines. Do you know English? No, actually I'm still learning English. I don't know English. So maybe someday. I hope. I hope someday I'll learn how that works. Okay, so we have our, um, we have our test sentence that will input just like this. And now we have our parsed data. Let's see if this works. Oh, right. Space Spacey. Breve yet. Breve yet my friend. I will wrap. Don't tell me don't wrap because that's gonna make me wrap even harder. Okay. That's how this works. You know what I mean? That's how this works. Let's see where we are time wise.

Speaker 2:          35:55          Okay.

Speaker 1:          35:56          35 minutes. Good. I'll definitely wrap now. No, I was going, I'm, I'm Delfin Rob. All right. Here we go. Space. He's not defined. I did. Oh, right. See, I can't even spell my own thing. All right, here we go. I don't speak Tamil. Aldo. I should, there's this hilarious like Tom Hill movie, which is like all these robots, like hundreds of them or something or it's like this. It's hilarious. Uh, Parse multisense yeah, I did define it. Oh, right.

Speaker 2:          36:23          Yeah.

Speaker 1:          36:24          You can now load it. Yes. Okay. There we go. I loaded the model. Right? So here we go. Let's do some part of speech tagging. So what we're gonna do is we're going to look for the part of speech of each of these words in my test corpus. Okay. So I'm going to say,

Speaker 2:          36:41          okay.

Speaker 1:          36:41          Parsed data. I, so that's all of those words that I just defined. Yeah. I speak, I speak Dutch as well. Wholehearted. I speak some Dutch. I mean it's a hard language. I just spent a year in Amsterdam, by the way. I spent an entire lifetime in a year. That was some pretty

Speaker 2:          37:13          mmm.

Speaker 1:          37:15          Incredible stuff. Don't want to get too reminiscent. I don't want to reminisce. Reminisce about things like Tupac. Okay. I'm feeling like a joker today on this live stream, man. Alright, back to this. I'll reminisce. Alright. Part of speech tagging or was that okay, what are we doing here? So we're going through each of those words in the parse data and we're saying where does it start, where does it end? And then for each of those words, we're going to, we're going to tag it. Okay. So each of those, should I, I should say tokens, we're going to say print the the word as well as it's part of speech and you'll see exactly what I mean right now.

Speaker 2:          38:02          [inaudible]

Speaker 1:          38:04          break is invalid syntax.

Speaker 2:          38:08          Really?

Speaker 1:          38:11          You Go, you go. No, no, no. Okay. Well I'd be attending these conferences. Look after slush. Okay. Slush in Helsinki. Nothing can compare. A slush was the most epic. And I know I'm really promoting slash by saying this right now and their applications are gonna go up. But slush was the most epic, um, conference ever. I mean, okay. Let me just give you guys a little secret. Okay. So like I go to this, okay. There's this like speaker's dinner. Okay. This too. There's too much to like talking about right now. We've got to get the coat on.

Speaker 2:          38:53          Okay.

Speaker 1:          38:54          Close the brackets, right? That's what it is. Of course,

Speaker 2:          39:01          right?

Speaker 1:          39:04          Yup. Yup. Porkin. Where's Torkan? Toke and orth and then underscore, get Joe brackets, right.

Speaker 4:          39:22          Boom. Oh,

Speaker 1:          39:24          verbs. Nouns, punctuation marks, build it, train it. Tested. Makes it denser. The Berg faster. Smarter. I got to read. Okay. So that was one part we can do more dependency tagging named entity recognition where we at time wise, 39 minutes, we were still good torque and exactly. That's how we roll torquing. All right. So, uh, that was one thing that we could do. Let's, let's do another thing. We can do some dependency tagging. Now. What is this? I am 27 years old. Helsinki's in the house. Um, how to reach you right here. Here I am. Kim Show means how are you in Gujrati? I'm good. Uh, that's some Russian right there. It says in Sylvia Tura. No, I'm just kidding. Rap. Got to read them papers. All right, so dependency tagging is when we have a bunch of words that depend on each other. What specifically do I mean? Uh,

Speaker 2:          40:20          yeah,

Speaker 1:          40:21          there's a tree of words that depend on each other. So it's actually, I should have had a slide for the dependency. Tagging on image speaks a thousand words. There we go.

Speaker 1:          40:35          So it's just like this right submitted. Who submitted the bill? Well, bills were submitted by who? That's the preposition. What's the object? As senator, what is his description? Republican of Kansas, whatever, et cetera. Right? So it's just like that. Now let's do this in our example. Let's, let me, let me do another wrap line of mine. Uh, what was my latest rap? Uh, it was like, this model is taking too long. I need addenda. And then it's like when they update the weights, they call it, they call it back propagate. They call it back propagate. Find that in your dictionary back propagate. And they want it the waste, they call it back for per day. That's what every single section of these new papers say. That's what, let's just leave it at that. Okay? So that's our example. And now that we have our example, we can say put it into our English. And now for every token that we have in our parsed example, now that it's been formatted properly, let's print out both the original, um, tag for it as well as its dependency. So notice how all of these attributes of the token keyword is what we're using here.

Speaker 2:          41:54          Okay,

Speaker 1:          41:55          head. And this is using scythe on under the hood. So notice the hell I'm not specifically typing out to sea, but it's very close to it.

Speaker 2:          42:10          Okay.

Speaker 1:          42:14          They're not in text form. They're just somewhere in my head and on the internet in terms of videos. Okay. Now. Okay, so for each of those files I want to show what the tree looks like. So that's why I'm going to say what's on the left and then what's on the right of the tree. Right. So,

Speaker 2:          42:34          okay.

Speaker 1:          42:35          T dot. Worth for t n token dot. Rights.

Speaker 2:          42:46          Let's see what happens here. Good.

Speaker 1:          42:51          When they update the wait, they, okay, so that's dependency tagging. There we go. Like I said before and now for the, okay, so next time I will do line numbers. Okay. So Hola, Como Estas? [inaudible] Raj, Yo Hablo Espanol. Tambien which means my name is Raj and yes, I speak Spanish very well. And I was just listening to deaths by, oh by the way, cause I'm going to la in an hour and I always listened to desk pasito before I go to La because this is how we do it down in Puerto Rico. That, that makes sense. Okay. The thing about named entity recognition is it. So, um, it's not as relevant, but basically it's like

Speaker 1:          43:40          w w it just comes down to us using this token, these attributes of the word token. Right? But, um, I think that's it for this video. Yeah, this is a good amount. This is a good amount of prostate, but definitely check out these docs, these doc, this documentation for spacey. It's some great stuff. Um, I want to see more people using c implementations, more wizards using both scythe on to speed up implementation that their models for data preprocessing, especially when it comes to NLP. I will be very impressed by that. Um, and you can expect us to go more low level in the future. And uh, that's it for this livestream. Now I'm going to do a rap part. Let me do a wrap here and then we're done. We're done. Someone say a word and then I'm going to freestyle to that to say a word ideally about machine learning. Okay. Let me just pull up an instrumental, Julia. I guess it's going to be,

Speaker 1:          45:07          I try to use NLP. Don't you see all of these word vectors? I think it's three down, man, king woman, Aubrey, where I'm trying to add these up and subtract. Damn, don't you care? You can add them. Multiply it. You can divide. You can use all of these operations, man. It's all in your mind. Think of these words is numbers that you can add into the track. Try to think of them as something more as they go back to bat. You can line them up, you can put them in a dictionary, you can put them in any data structure. It's history. Yo. Okay. That's it for this rap Ganz this next time, but that was my short wrap. Thank you everybody for coming. I love you guys and for now I've got to go to la, so thanks for watching.

Speaker 2:          45:49          All right, that's it for this stream.