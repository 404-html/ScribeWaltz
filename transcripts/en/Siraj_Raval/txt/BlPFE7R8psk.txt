Speaker 1:          00:00          Ai In 2019 hot dog, not hot dog at the same time hello world, it's Saroj and 2019 is going to be an incredible year for the Ai Community. I'm going to briefly recap some of the major highlights in the field from 2018 then use some of those highlights to make 10 predictions on what's going to happen in 2019 the subset of AI deep learning has accounted for the majority of the public discourse on Ai in 2018 we've seen some incredible new applications of it so far, but let me start by stating something that might shock you. Even though I'm ethnically Indian, my mom was born in Kenya, which technically makes me an African American, but besides that, a substantial fraction of the biggest developments in deep learning. We're more akin to tuning existing techniques versus creating qualitatively new ideas. It's been a year of refining existing algorithms and the ones that received the most press combined deep learning and reinforcement learning together.

Speaker 1:          01:01          This technique, deep reinforcement learning enabled open AI's Bot to defeat the world's best dota players. It enabled deep mind spot to beat the world's best go player and enables Uber's bots to beat Montezuma's revenge. The idea is that made up these algorithms were all at least a decade old. They just been combined in novel ways to defeat these games. The idea is that if an AI can learn how to optimize its score in a game world, it could possibly also learn how to optimize any function in the real world, which deep minds Alpha fold actually did later in the year by predicting the three d shapes of proteins, enabling scientists to design new cures for diseases much more efficiently in terms of global developer activity. The two hottest areas of AI on good hub centered around NLP and generative modeling. It was a successful application of transfer learning applied to NLP that brought such incredible results.

Speaker 1:          01:58          Transfer learning is the art of being able to apply pretrained models to data. The pretrained image net model help accelerate the development of computer vision algorithms a few years ago and in 2018 fast that AI's Ulm fit the Allen Institute Elmo open AI's transformer and Google's Bert did the same thing for NLP. These pretrained models help accelerate development. Google's Bert stands for by Directional encoder representation from transformers come down, optimist, not you. It was a model that was built on the ideas of the other pretrained models and redefine the state of the art for 11 different NLP tasks, even surpassing human performance. And the challenging area of question answering it made learning from text data far easier for any developer since it meant instead of lengthy training times only minimal changes needed to be made to the existing model, which made training processes more like fine tuning. The other area with lots of activity was generative models, models that create novel data like video or text, specifically around generative adversarial networks.

Speaker 1:          03:07          So many variations of gans were released, big gans, aggressively growing gans and video even used again to generate an entire three d world, which they demoed at the most popular Ai Conference of the year. No rips. Their paper was titled Video to Video Synthesis. We also saw a massive growth in the size of the Ai community across all metrics. In 2018 number of students enrolled in AI at universities, new online offerings like school of Ai, developer activity on get hub, conference attendance, number of AI businesses. Ai means global interest in this technology increased massively and although tensorflow flow is still the most popular machine learning library overall, academia started to prefer the Pie Torch Library. Lastly, in 2018 we saw much more of an intersection between governments and AI. Palentier helped city governments implement predictive policing. Technology defined the likelihood that certain individuals would commit a crime in the future.

Speaker 1:          04:07          Tesla's autopilot crash caused lawmakers to consider the implications of self driving cars more deeply. Google employees protested against project Maven, which was aimed at using AI to help the u s military improve its efficiency. Cambridge Analytica came under fire after it was reported that Facebook gave them access to the private data of more than 50 million users, which they used for political purposes. Zuckerberg had to testify in front of Congress which showed how embarrassingly inept lawmakers were at understanding this technology that EU enacted Gdpr, which required businesses to protect the personal data and privacy of EU citizens. Many other countries followed and China supercharged. It's economic growth by applying AI to, well everything. 2018 was quite a wild ride and I'm expecting 2019 to be an even wilder one. My first prediction is that client side training will become a linchpin of AI model learning within edge mobile and robotic process automation applications.

Speaker 1:          05:10          Several Ios apps have already started using the device side AI training, ensuring that face id recognizes users consistently at people's pictures or accurately grouped in the photos app and that the keyboard can predict what you'll type. We'll see the pendulum in AI shift from a focus on the cloud to the edge cost. Drivers for this trend are firstly bandwidth, meaning semi connected environments and expensive cellular considerations as well as storage, which reduces the amount of data sent to the cloud. This means that the dominant AI development frameworks will be re-engineered for superior cloud to edge performance optimizing its runtime for whatever platform it's running on Intel's popular deep learning USB stick demonstrated one step in this and whether at the cloud or at the edge Coobernetti's orchestrated containers will become an integral part of the AI pipeline. Coobernetti's is an open source project for automating deployment, scaling and management of containerized applications.

Speaker 1:          06:13          Containers gained traction in AI because there are a lot more space efficient than virtual machines. In 2018 lots of AI tool vendors started supporting the deployment of containerized statistical models inside of cloud native computing environments. In 2019 even more, we'll support deployment of containerized AI models for orchestration across Kubernetes clusters and increasingly heterogeneous pipelines. Cuba flow by Google is one project that does this well and it will be a likely target that tool vendors will implement and as AI gets deployed everywhere, upskilling non AI professionals to work with AI will become an even more crucial part of any workforce strategy. Literally keep calm and learn AI. Thus a new class of tools like auto ml, which streamlines and automates part of the process for creating AI models will democratize AI even further for these people. In 2019 auto ml will improve such that any supervised learning task, meaning one where a label is involved, we'll be able to have algorithmic selection and hyper parameter optimization confidently automated by a computer.

Speaker 1:          07:23          It won't be a replacement for the ML toolbox. Just another tool to include in it. Supervised learning is currently the dominant approach and AI, but it often requires the labor intensive and time consuming process of getting humans to manually annotate data. There are also limits on what it can do. We need a better way to bridge the gap between representation, learning and causal reasoning. In 2019 research attention will turn away from supervised learning and towards unsupervised and reinforcement learning. For example, a recent paper titled Unsupervised Neural Machine Translation showed that unsupervised learning can help solve language translation. The problem with supervised translation is that you need parallel sentences to show an algorithm to directly not words from a source text and say English into a target. Texts like Hindi. The paper showed that by training a joint embedding space between an Incode or model and a decoder model, a weak form of unsupervised translation could be learned.

Speaker 1:          08:29          This was an inspiring step in the right direction and we'll see more of that this year. We'll also see more of a popularization of reinforcement learning techniques until coach ray RL Google. Dopamine will start to see more of these are l libraries being incorporated into enterprise environments. We'll see more on the use of imitation learning where agents learn directly from the human supervisor and we'll also see evolutionary strategies in use to solve challenges faced in our l expect much more data efficient RL algorithms. Since all of us don't have hundreds of GPS like deep mind does except for this guy training alpha go on, a single GPU will likely become a reality in 2018 the deep fakes algorithm awakened the public to just how powerful generative models could be. Even the Hollywood reporter reached out to interview me about the potentials last year. This technology will mature in 2019 and we'll likely see the first major political scandal that uses it occur.

Speaker 1:          09:32          We'll also see a company use a generative model to automatically create digital walkthroughs for how Spiers museum tours or even generate content for video games. Basically, the tools for generative modeling, we'll continue to improve and all of these incredible learning algorithms can be sped up by certain types of hardware. Quantum processors are one great candidate for this. D-Wave released it's quantum API. Ibm and Righetti invited more developers to use their quantum API and we'll start seeing at least a few examples of enterprise applications using quantum computing to speed up their machine learning algorithms. There's a lot of promise around using quantum chips to speed up training time for certain ml algorithms like variational auto encoders and quantum won't be the only hardware we'll see progress on. All sorts of AI systems on chips will dominate the hardware accelerator wares. In 2019 we'll see a steady stream of fresh hardware innovations in gps, tensor core processing units, field programmable gate arrays, and so on.

Speaker 1:          10:42          They'll come to market and support faster and more efficient. Ai Processing and companies will increasingly uses technology for social good after the dark cloud that Cambridge Analytica casts on the community last year, society is demanding that companies have a higher social purpose. In 2019 we will see an increase in initiatives like Google's Ai for social good program and Microsoft's Ai for good initiative companies will have to adapt not just morally but their business models as well. They'll either become more data driven in their decision making or not and be disrupted by those that do. Lastly, Ai will create more jobs than it takes according to gardener. At 1.8 million jobs will be lost to automation with manufacturing in particular singled out, but 2.3 million will be created primarily in education, healthcare, and the public sector. That totally makes sense as the vast troves of health data, the need for personalized education and various societal problems, all points in this direction.

Speaker 1:          11:44          There is so much to be excited for in 2019 three things to remember. Ai In 2018 was characterized by fine tuning architectures in deep reinforcement learning, natural language processing and generative modeling. Ai In 2019 will be characterized by more client side training tools, advances in unsupervised learning, reinforcement learning, and much better AI hardware. Oh, and prepare for more data regulations to be enacted across the globe. We're all waking up to the power and potential of data. I and the rest of the school of AI wish you a very happy new year. Wizards 2019 will be our time to shine. What's one goal you have this year? Share it with me in the comment section and please subscribe for more programming videos for now. I've got a course plan, so thanks for watching.