Speaker 1:          00:02          Okay.

Speaker 2:          00:17          Okay.

Speaker 1:          00:19          All right,

Speaker 1:          00:33          Raj, good to see you guys. Good to see everybody today. How's everybody doing a, I'm going to list some names today. All right. Shifts against apartheid. Dean Sumit. Spencer, how's everybody doing today? Yo, good morning or good night, wherever you are. Uh, so good to see you guys today. This livestream. I'm excited to do this livestream today. We're going to use open CV to detect a strawberry and an image and it's going to use no deep learning. It's gonna use no straight up machine learning. It's all open CV. Um, all right. So that's what we're going to do and I'm hearing a coworking space, so that's why the environment is different. Uh, so okay. Okay, so I'm going to start off with a five minute Q and a and then we're going to get into the code. All right, so here we go. Five minute Q and A. Hello. Hi. How is everybody doing tensorflow versus I can learn, uh, so tensorflow for like 95% of anything you want to do, but for like the most simple type of machine learning that has nothing to do with neural networks, it's like a linear regression, psychic learn. There's also TF learn. But even that leader linear regression, you just deep a deep neural net to do that. Um,

Speaker 1:          02:09          they're both the same amount of code, but like, you know, just for like that line of best fit y equals mx plus B. Like what even is any machine learning so I can learn. But then for everything else, tensor flow, what's your book about decentralized applications? It's about building apps that are, that no central entity controls and everybody gets paid for their data. Do you think Google's Tpu is, we'll take off. Absolutely. Absolutely. And we're going to see more hardware focused on neural networks in the future. Google's just ahead of the curve. All right. Are you going to show how to set open CV up? Um, yeah, I can do that as well. Yeah, I can do that as well. Are Your models deep? So deep that I'm not going to say that. [inaudible] versus care us TF learned for sure. Um, which I'll go are we gonna use, uh, uh, for this one we're going to use other several, uh, they're, they're all open CV algos. Um, and I'll explain them as we go. Um, a rap, a song in Hindi, maybe at the end. Um,

Speaker 1:          03:09          and I'll probably get an English just to be accessible to as many people as possible. How, how are self driving cars going to cope with three Third World Msci roads? That's a great question. We need like a one great example would be Hindia like trying to think about self driving cars in India is like, this is like never going to happen, but it has to happen. And the way it's going to happen is just better, better out rhythms and better, better data because that's what we use, right? We have a great algorithm and we've got great data here. Um, what we see, um, what's the best network for image classification? Supervise, been trying convolutional neural network, uh,

Speaker 1:          03:48          image classification. Uh, probably, uh, well, yeah, convolutional nets for anything image related. How high should we, should I be for Friday? Really high. I've been working with a team on this. I'm so high up. I mean we've been working on the weekend, uh, to bring what's coming out on Friday. So really high. Did I miss anything? Not yet. Uh, he's detection included, uh, not face detection. We're going to detect strawberries. Uh, but this, this applies, I mean the same kind of logical apply tensorflow performance on mobile versus open CV. Um, uh, performance wise, uh, open CD is probably more performance and not, it is more performance, uh, because you're not using the computation that deep learning requires. We're not doing deep learning right now. There's a trade off here. Will it be realtime opposite? Object recognition. I mean, live video feed, not real time. It's going to be an image. We're going to read it and then write it. Okay. Uh, thanks Brian. Uh, one more question and then we'll get started.

Speaker 1:          04:48          Are you going to build a strawberry feature descriptor? Yes. Are you going to be using heart cascade know? Is this still image recognition? Yes. Are you a part of the Linux community? Yes. Okay. So that's it for our five minute Q and. A. Let's get started. We're going to use open CV to detects strawberries. Okay. It's going to be an image of strawberries. We're going to use open CV hello to detect it. It's going to be a hundred lines of code. We're going to do it in 45 minutes. Uh, and uh, I'll explain things as we go. There's no deep learning coming out. Um, and there's no deep learning that we're doing right now. So let's get started. I'll start screen sharing and then we're just going to get right into the code. All right, here we go. Screen share time. Okay. I've got two monitors so I can move this one over. Yay. Two monitors. I don't have to switch back and forth, so that's great. Okay. Let me move everything as I need to. It's sober so I can see what you guys are saying. All right, cool. So let me test that. Yeah, everything works. Okay. So let's get started with this. Um, make myself smaller so we can see me and the code. Okay. So here we go. So we're going to start off by importing our dependencies. And then, so this is gonna be about a hundred lines of code and then we're going to get right into it. All right? So

Speaker 1:          06:16          step one is to the important of dependencies. Okay? So let's get started with this. So the first thing we're going to do is import. Um, let's see what, what do we want to import here? We want to import open TV, right? I said I would help you guys install opiod CD, right? Okay. So let me just, uh, let me just get this open CV installation. Uh, so it depends on what operating system you're using, but if you're using a [inaudible], it's just much easier if you're using Linux, like open CV is just like made to install on Linux. You can just use apps get, and there's like three of these. If you're using Mac, I would recommend homebrew to install open CV or, or Anaconda. Uh, and if you're using windows. So I've actually never installed open, open CV on windows. Uh, but I assume it's going to be pretty easy. There might even be a binary for it. Um, maybe not on this page, but, um, but yeah. Okay. So, uh, anyway, let, okay, let's just get to the code. So we're gonna so the first thing we're gonna do is port open CV cause that's the library we're going to use for computer vision. And then we're going to import Maxalt. Lied because Matt thought life is going to help us show our animated. We're not going to do any actual like graphing. We're just going to try to show our image. Okay. And we're going to call gets PLT.

Speaker 1:          07:36          Um, so there's that. And so now we're going to important to apply because we're going to do some matrix multiplication. Uh, pretty much anytime we're doing any kind of computer vision, machine learning, deep learning, we're going to be important. [inaudible] it's like the library for, because everything is really just made sure multiplication in the end, right? We're just multiplying matron seats. Okay. Okay.

Speaker 1:          08:00          So, uh, okay. So we're going to important math in math cause because we're going to use some, uh, things that are not related to, we're going to do some math that no, hi, just doesn't have a, and I'm going to import division for some more math. Okay. So that's it for our dependencies. And we're going to just go ahead and write our high level method and then we'll write our helper methods. Okay. Uh, so let's go ahead and write our highest level method. Okay. And we'll call it find strawberry. Okay. So let me show you guys the image that we're going to be using for this. Okay. So the image we're going to be using for this is, uh, let's see, it's called, uh, it's called very dot jpg. Okay. This is it. And we're going to add, I'm going to ask you guys to just throw out a strawberry image and then we'll detect it that as well.

Speaker 1:          08:45          Okay. So I'll ask you that later and we will see if, if our code can detect that random one as well. Okay. So this is the strawberry and the idea is we want to be able to segment that. We want to draw an ellipse around it. Uh, and then we want to distinguish it from this background. So I'll show you guys what this looks like. Um, and we're going to be able to apply this to many other images, not just this one. This is just an easy image. Okay? Okay. So, and we're going to talk about the map as well. So this is our first method. It's our main function and we're gonna use our helper functions of do this. The first line of code I'm going to write is I'm going to convert our image and into the color scheme that we want. Okay?

Speaker 1:          09:19          So that is where it's open to CBS, uh, convert color function comes in. We're going to take our image and our image is that strawberry image. That could be our input parameter. We're going to take that image and we're going to apply this conversion to it. It's called Color Egr two. RGB. No. I'm going to explain what this is doing, but I want to ask you guys, does anybody know, uh, what the differences between BGR and RGB? I'll be actually very impressed because this took me quite a bit of googling to figure out why we do this in the first place. I remember when I first started doing this, so if anybody knows, let's check the shot that out in the next 10 seconds. All right, interesting. The two color Bgr to car. Cheapy. Okay. So anybody,

Speaker 2:          10:02          okay.

Speaker 1:          10:03          Going once, going twice

Speaker 1:          10:06          and, okay. So what happens is that, so yes, order it is one of them. Is that yes. Blue, green, red and readability. Exactly. The channels or reverse, right. So, right. So RGB stands for, uh, so okay, so RGB is red, green, blue and PDR is, BGR is um, blue, green, red. So what's the difference here? You said it's how it's, how the colors would store the memory Schema of the colors, right. And, and, and the ordering, it's all about the ordering. And when, whenever we are, we're applying some sort of transformation to an image or whenever we're playing some kind of, we're trying to morph an image in some way. The order of the colors matters depending on what's what technique we're using. So it depends. So for the techniques we're about to use, um, RGB, RGB, the RGB color scheme is better than BGR.

Speaker 1:          10:58          And I'm like, I'm going to explain why this is, but it's basically the order of, of the colors in memory. So greed, so like, uh, in, uh, so, uh, blue occupies the least significant area. So a bites in a 32 or 24 bits a format. Uh, so it's, it's just about bites and memory and ordering. Okay. And so that, so that's that. So that's our first step. We want to convert, convert to the correct colored scheme after our first day. Once a young guy, it's the same image. It doesn't look any different. It's just not the college scene and how it's ordered in memory is different. Okay. So that's our first step. Um, and so now that we've converted to the correct color scheme, uh, we're gonna, we're gonna make sure that it's the correct sides. So we'll say, okay, we want to get the size of this. Okay. So we're going to say we're going to use python builtin Max function. Then you take that image and get a shape. Okay? So that the shape of that image is, uh, you know, the signs of it, but window songs and we want it to be, um,

Speaker 1:          11:58          we want it to be, to write a science. So to do that, we're going to get the, we're going to scale it. So we're going to say, okay, let's kick the scale of it, cause we're going to recite it in a second. So we won't say out of 700 kickback, uh, divide what we just got by 700. Why are we doing this? Because the maximum window size, uh, that we're going to use is 700 by 660 pixels. So we want to make, are we want to make our, uh, a strawberry that you fit in that image. So it's gonna be 700 divided by what it already is. So it's smaller than that. Okay. So we're going to scale it like that. And then finally we're going to resize it. Okay. So all three lines of code here, or to reset the r two s, uh, sale our image properly.

Speaker 1:          12:41          Okay. So this is step, let me just say step one and then step two, write step one. Step two. That's step one step. Okay. So, um, so we're going to use open CV, very handy, resize function for this. Okay. Um, so we're going to pick out an image and then we're going to say, um, uh, so this Allie is going to be none of that. This is, uh, this isn't, this is an optional value, which we're not going to deal with right now. But, um, so, so the s but we want to make the width and the height the same scale. So it's going to be a square instead of a rectangle. So what's, so what's the length of the x? So what's the link? So we're going to say that's going to be scale. And then whatever the 700 divided by that, uh, Max mentioned is, and the f y is going to be scale, right?

Speaker 1:          13:25          So it's, uh, it's the same with the square, the same length, same what? Okay. So we've scaled our image and it's square and it's, it's, it's ready to be, uh, uh, it's ready to be a, uh, we're going to apply, are open to be techniques to it. Okay? So that's step two. And so now step three is we want to clean aren't image. So what do I mean by that? Or what do I mean by that? So let's say step, grievous, clean aren't image, okay? So I'm going to say, uh, let's blur argument's, right? So I'm going to say image blur equals, and I'm going to use open to use function called gals. Gaussian blur. What is this? So gutsy employer is whenever we want to eliminate noise from an image, we want to, we want to smooth the colors. So like, think about a strawberry, right?

Speaker 1:          14:09          Strawberry can have, uh, you know, it's got those, what are those little yellow dots on the strawberry? Like the kind of seed like things, whatever they are. We want to, we want to remove that cause we just want to see the Upshur clean read image. And sometimes when we take an image and we convert it to a different color scheme, it's got like little black dots in it. We don't want that. We want to have a clean, smooth color across the image so we can just say boom, this is what it is. So that's what, that's what, that's what this is doing. That's what this is the Golf Sian Blur Desk. It takes the color scheme across the Gospel in distribution and it and it, and it smooths the image across the distribution. Um, so,

Speaker 1:          14:48          uh, you're risking detention to watch a stream live spark chicken. Thank you so much. I appreciate it. All right. Um, so, but we're going to, we're not applied for an image and we're going to, uh, uh, so that's the input image and we want the kernel side, what the kernel size is going to be. Well, it's going to be seven by seven because you know, 700 by 700. And so like with the size of the image and then, uh, how much do we want? And then the last one is the left side is going to be zero, which is, uh, how, how much, uh, we want to filter it, which, uh, we don't really need right now because we've, the blurred like by default already does that. Um, so the last, the last time we're just going to leave Europe because that's an optional value. We don't have to deal with that. Um, so we've, so we've got our image and we blurred it, but there's one more thing we have to do. We have to convert the color scheme. Get again, why is that? We're going to convert it to what's called HSV format. Okay. Um,

Speaker 1:          15:48          all right. So, mmm.

Speaker 1:          15:55          Okay. So we're going to convert it, the HSC. And uh, so we're going to use a convert color again, and we're going to take that blurred image and then we're going to add, so then we're going to have the CV has a bunch of these like conversion, uh, attributes. We're going to say take the RGP and now convert the HSP. So we converted it to Rgb so that we could scale it. And now we're going to convert it to another format called HSD. Uh, so that, uh, so once it's blurred, because now we're going to filter by the color. Okay. So what is HST? So HSD format is a different color scheme, but basically it separates two things. It separates the, uh, the Luma or the image intensity from the chroma or the color information. Okay. Um, so we're separating the color from the, uh, from the, from the brightness of it. So we just want to focus on color. Right? So that's one per segments to did these things. RGB and Bgr, they don't really separate the, the, the, the Luma or intense color intensity from the color itself. It's just one, it's just one thing. So that's what HSC is going to help us with. So we're going to separate these two and we're going to filter it based on that. Okay. Yeah, exactly. Two saturation down. Okay. So, um, so that's what we're gonna do for that. Uh, and

Speaker 1:          17:15          now that we've converted it to HSV, um, we're going to do what we do best. He would. Agent's fee is best for which is to define a, we're defining a, what are we defining here? We're defining our filters, defined our filters. Okay. So define our filters.

Speaker 3:          17:39          MMM.

Speaker 1:          17:41          Oh, no worries, Paulo. Thanks for, thanks for saying that. Okay. So, uh, we're going to filter by the color so that we're going to filter by the color filter by the color. That's the first one. We got to fill so many color. Um, so called, remember color is separate from the brightness. Color is separate from the brightness. The intensity of the color is separate from the intensity of the brightness. And, and so we wanted the tech strawberries get a certain color range, right? So there's a certain redness have a strawberry. If it's, if it's more red than that, then it's not, it's less for it than that, then it's not as structured. But it's in a, in a particular range. And generally for this, we would get some check what this is. So I've got, I've gotten this, it looks a minimum amount of red and this is where we're using num Pi because remember colors, uh, computers we colored as uh,

Speaker 3:          18:29          thank you. Want it?

Speaker 1:          18:31          Okay. So, so we're going to use none pies for ray function to, to do this, right. So remember colors or like, you know, like if, if, if we, if you guys do CSS before for anything, right to 55, 55, these are hex values. And so we're gonna use none pies or right function to define these hex values. They're going to say, okay, so this is the minimum minimum red value. It's cause it's, it won't say zero. 108. Okay. Uh, and then,

Speaker 2:          18:54          okay,

Speaker 1:          18:54          that's the minimum amount of redness. Then the Max amount of redness is going to be, again, another nub higher rate. Am I going to define, so this, these are bounding colors. So this is the maximum brightness that we want. So we'll get, we'll say it's 10 56 and then if it's six that is read as we want to get. So anything in that range of redness? Um, no, I did get a new on shutout. Uh, yeah, I mean it's, it's all good. Yeah, I mean it's not a big deal. I mean, I, I'm, I'm gonna I'm going to hit eventually, you know, do more stuff with him and stuff. No, but I was just speaking with Subash and third

Speaker 1:          19:32          recently anyway. Okay. So, um, uh, okay. So, okay, so we're filtering by color and now we're going to create a layer with this. Okay. Okay. So we're going to create what's called a a mask mask. We could call it a mask. Would you call it a filter masking filter or about the same thing? So we'll call it a mask. And this mask is like, um, if we were to take an image and we just focused on one color and we just blackout or blur everything else, like we don't care about everything else. Okay. So that's, that's the mass and it's just applying by the color value. Okay.

Speaker 3:          20:02          MMM.

Speaker 1:          20:05          Uh, okay, so this is, so that's a mask in range. Uh, so we're gonna say, okay, so what does that value would just fine image blur. It's just the minaret and then Max Richter. Okay. So minaret and metric. Uh, so those are our values weren't image blur, right? So that, so that's our first and we want one more mask and that's why we converted the HSP because we're filtering by not just color but by intensity. Okay.

Speaker 1:          20:33          Um, I did a, I did a video for open AI, which is Ilan squad, AI squad. And Ilan watched it and liked it. And so like now, you know, he knows about, you know, what's good and know with me and stuff. So, okay. Um, so minimum. Uh, so okay, so we're going to focus on the brightness now, right? So this is why it can radiate Jesse. So minimum read. I've got to focus on the code here. So we're going to say minimum read too, right? Cause we already find it one called minimum written. And again, we're going to do another array. So this is going to be one 7,100 and then, and this is focused on the brightness. Okay? So we have a minimum value in a max value and Max read to you wholesome and quite dark gray. And what their Max brightness we wants to 56 six. Okay. That's our, that's our Max value made sure I've got my comments there. Okay, cool. So let's see. This is filter five rightness. Okay.

Speaker 1:          21:29          Hunter by Brendan's. Okay. So that's that. And so now we're going to clean our second Max. We have two masters to make and we're going to click on a second master's going to just focus on the brain. So we're going to say what my CT has this in writing function that we've, we can use for colors for, for Hugh, for at Saturation, for buck of ranges that we wanted to find. Okay. And we'll say image, we're HSV. That's this, the same dimension. Uh, and this time we're going to bound it by, uh, our, our uh, call if our brightness variables. Okay. So now we have our two masks. Does anybody know what we're going to do with these two masks? Uh, I'll be impressed who, who knows? Okay. So shout out if you know what we're going to, um, uh, do what these two maps take these two masks and we're going to, we're going to do something with them.

Speaker 1:          22:27          Okay? So what we're going to do with the suit and and them note mass close Nastigal double mass spark chicken. Exactly. We are going to do double math, double rainbow, double math. We're going to combine our mess. We're going to combine both of them. Okay? So we'll say mask equals math, one plus next to it. That's it. We've combined our mass. How easy was that? Okay, so we've, we've done that for a mask and now we're going to, um, we've combined our masks and now we're going to, uh, do some, uh, step four. And then step five is a, we're going to segment segment, step by is segmentation. We're going to segment the image. What does that mean? Step five is segmentation. We're going to, we're going to use those maps to separate the strawberry from everything else. Okay? That's step box segmentation. So we'll call this a colonel and let me explain that in a second.

Speaker 1:          23:19          But so, okay, so a colonel is, we're going to use open cvs, get structuring element method, and let me define what that is. And you write this stuff more lips and we'll say this is going to be 15 by 15. Uh, okay. So, um, we want to circle our strawberries. So we'll circle it with an elixir, which is like a circle, but you know, not as not a perfect circle with s with the shape of 15 by 15. And that's, that's why we use it the more polyps function because we're going to get that structuring elements. Basically colonel is going to have an Alexa. Okay. And we wanna, we wanna make that ellipse fit around our strawberry. So we will still, we'll segment. All right. Um,

Speaker 1:          24:08          okay, so we've got segmentation and uh, now we're going to say, now we're going to do some what's called morphology. Let me explain that in a second. Massa clothes more fall Gi exam X. We'll take our mask, we'll take our more clothes and then our colonel. Okay. And then I'm colonel. Um, okay, so what is this before I find it somewhere right about one more line. But this one's gonna be called mass clean because these are both related to each other. So let me write this last one out. Morphology x, and this is a lowercase x gotta be perfect about the syntax here. Mass closed CD to more open. And then one more thing, the colonel. Okay. So what is, what am I doing here? So we want to work the image. So, uh, we wouldn't add that lips around the strawberry. So, uh, we're going to first, uh, perform, uh, closing operation.

Speaker 1:          25:10          What does that mean? Uh, uh, closing operation is dilation followed by erosion. It's, it's, it's a process called dilation followed by erosion. What is this? It's useful for closing small holes, small holes inside the foreground of objects, like small black points in the objects. It helps further refine that, um, that, that, that smoothness, it helps. It's like another, it's like an, it's like another safety check to make sure that it's a smooth, uh, in this case, red lake. And then, uh, uh, and then mask. And then more open is taking is, is the opposite. It's erosion followed by dilation. So the first one is dilation, followed by erosion. And the next one is erosion, followed by dilation. Okay.

Speaker 1:          25:55          Um, yeah, definitely. Uh, thanks Sam for helping me answer the questions as well. Uh, okay. And so it's useful for removing doors. So, uh, both, uh, it's not that they reversed each other. They both add to each other. Okay. So, um, so we got that. So now we're going to find the biggest strawberry. So sex, sex is a client. The biggest strawberry we don't want, we don't just want to detect all strawberries. We want to find the biggest strawberry. So if we have a bunch of them, we only want to circle the biggest ones. Okay. So we'll say what's the big strawberry concert and contour is the shape. Okay. So we're going to get that. And so, and so we want to get, and we're going to get the masters as well. So this is the method that we're going to. Um,

Speaker 1:          26:39          okay. So we're going to say, uh, and we're write this method out, but it's going to be a fine, the biggest con for the, and that is find the biggest conflicts. So, so what are, what our album's going to do is it's not going to differentiate, just going to say, oh, strawberry to, oh, it's got very drawn to Lipo, strawberry draw an ellipse, and then this method find the biggest contour is going to find the biggest. The lips can say, that's the strawberry we want out of all of that. So that's what this is going to do it. And we don't, we're going to write that in a second. Um, and we're going to use a mask clean parameter, which, uh, to, to, to do that. Okay. So that's going to find the biggest strawberry. Uh, and now we're going to, um, step seven is to overlay.

Speaker 3:          27:18          MMM.

Speaker 1:          27:21          We're going to do that, uh, to do this. And Oh yeah. Short History of Columbia wrote a book, traveled around the world for a year, went to San Francisco, work at Tulio, has built for educator best technical writing team on the planet. Uh, works, you know, some contract work here and their mobile development did a lot of independent research, um, with a couple of, um, uh, distributed systems research than some AI researchers that I just knew, you know, it's just like, you know, moving around and figuring things out. Uh, and by the way, these centralized applications was the best selling software engineering book on Amazon, uh, 20, 2016. So, but I'm not, I'm not like super happy with it even though it was because it wasn't my best work and the reviews weren't like as good as I want. I want like perfect by star use. So I'm going to write another AI book in the future. Probably this here, I'll write another book and I wrote that book before I had any following. And so now it's going to be awesome to write a book, uh, but I've got to make time for it anyway to get back to the subject.

Speaker 3:          28:15          MMM.

Speaker 1:          28:17          Uh, okay, so, so, so, so step seven is to overlay the Max that we created. We created on the image that's the next, that sets of it. So when we look, say, overlay. So we've created these masks for color, for brightness, and we're going to overlay them on her image. And we're going to write this function, right? So we're going to say mass clean and anemic. Okay. Um, and so now we're going to find the be a strawberry. And now a step eight is to circle the biggest one cause we differentiated which one it is. And then we're going to circle the biggest, uh, strawberries. Okay. Circle the biggest strawberry, um, to do this. And, um,

Speaker 3:          29:02          uh,

Speaker 1:          29:03          parents born in India. I was born in Houston, Texas. Um, but I've been to India. It was a lot of fun. Uh, fun is a, yeah. And it's more like a really hard adventure to travel through India. Like I went to like see where my parents are from and see what my culture was like. And it's a beautiful experience. And it was, uh, India is, is, is an adventure to, it's, it's, it's anyways, uh, I really like Mumbai though. Great City. Okay. Um, uh, someone was at doing, so I'm going to circle the biggest strawberry. It's, I'll say circled circle, come tour. Um, and we'll Overlake big strawberry.

Speaker 1:          29:48          Cool. Cool. A big strawberry contour. Uh, and then we circled it. Uh, we'll show it now and we'll write the show function to show it, uh, and that the show functions going to show are circled, essential, more final result. And the last step, step nine, last step is to convert our image back to the original convert, convert back to provisional. Oh, excuse me. Thanks Robert. Thanks for [inaudible]. Uh, okay. So, so converted act to, um, our original color scheme to be two colored circles two, and now it's opposite method, RGB to BPO. Okay. That's our last step and we convert it back and we'll, we're just returned that, uh, reconverted value. Okay. So that's our main method. Now we have to write our helper methods. Okay. We've written our main method and now let's write our helper methods. All right. So,

Speaker 1:          30:55          um, so that's our main method. Now let's write her helper methods and I'll sort of at the very, very top. Okay. So, um, the first thing I'm going to do is define the color green with, I'm going to use it a second and I'll define it as a global. So we'll say zero to 55, zero and that's just defines green. Okay. Um, I'm 25 years old. So, um, the first thing we're doing is right that show method, right? I'm sorry. That's show function. Remember that show function. How are we going to show our image? So we're going to say take that image it and you clicked get the finger size and speeches and Ben were going to, and this is where we're actually using that pump library. This is, this is this the reason we incorporate math life because we're going to show images with it.

Speaker 1:          31:37          It's a metal halide. He's in fish is good for plotting. It's also good for showing images easily and typed them. Um, we can do it in one or two lines of code. So 10, 10, uh, and then show the image. So I, I've got the finger size and now I can show him a image and then the interpretation is near us percolation people's nearest. That's, that's, that's shorthand for nearest neighbor interpolation. Um, uh, okay. Thanks. The 13th. Um, I've been streaming for 30 minutes now, but PLT does show nearest. Okay, that's fair. That's fine. For a nearest neighbor installation, that's going to help us shore image. Uh, okay. So that's our show function. And now remember the overlay mask function. Okay. So let me show you guys where I defined that. Oh, and what that's going to do. So remember the show him itch was down here and now be uh, overly masculine edge.

Speaker 1:          32:35          Where was that was here. And that's going to overlay the mass we created on the unit. So we're going to take that cleaned Basque and we're going to apply it to the image. And this is what the actual application process of applying the masks, uh, to the, the process. Okay, so overlay mask on the image. So let's make the, make the mask RGB. Um, so let's say RGB mask equals CD, two dogs a convert to the color. I'm going to think I'm at and we're going to convert it to a gray scale just for this, a conversion process. So there's a lot of, as you can see, there's a lot of colored skinny conversion happening here. Um, and, and in, in this case, we're converting it to gray scale, uh, because, well, let me, let me write this up and then let's think why we're converting it.

Speaker 1:          33:21          Great skill, but the second blind as to, um, add the weighted sum of jewel race. Uh, and let me clean on a second. Uh, can we just try to sell and then we'll return to you? Okay. So what's happening here? So, but so what ad way it is doing is this calculate the weighted sum of two arrays. All right? In this case is going to be our imager rates. We can think of our images as a race. Um, and so if we just think of a t, uh, both images and his rate, well, a raised, when we add and we add them together, we're adding the weight. It's some of the of the image values, like the sheer, the numerical value of images. If we just think of images is just raw numbers that just build up into an image that you can see. If we add the weight that some of those of the mask and the original image, we'll get the mask overlaid on top of the image and we're converting it to um, uh, uh, the, the mask to Rgb, uh, because uh, the original image is in heart GP.

Speaker 1:          34:17          So we'll just, well because the mass is going to be in grayscale convert to hard to be, so they're both sort of are both going to be, they're going to be there. Hard to be too great. Uh Right. Cause it's cause we're not going to read the image. We're converting the, the mask from greater RGB. Okay. And then we're going to return the image. So that's that. How many helper functions do we've got? We've got, we've got two more helper functions and then we're good to go. Okay. So those were our first two and now we're going to do our next to hub functions. So the next one is going to be fine. The biggest concert, right? So we've got our contours or ellipsis and we're going to protect the biggest one out of politics. And we defined this function, right? Shear. Where did I define it?

Speaker 1:          34:56          Right here. Find the biggest strawberry. It's going to return the biggest ellipse for that shop very as well as the mask for those strawberries. Okay? So let's do that right now. So to find the biggest contour first, we're gonna make a copy of the image, right? We want to, we want to retain the original image. Um, and we're going to retain the original image, but we want a copy of it so we can modify it. And this is, this is where it opens cds, images, coffee, uh, function comes really handy. Come to confirm is really handy because copied the image, but then keep the other ones separate. So now we're going to, we're going to get those concourse. So how do we do this? Well, luckily for us, open CD has a function called fine contours. So given unpainted given image, um, and these two values that kind of find this conference, I'm going to explain to these I in a second. So the first is retrieve lists, r, t r, e t r list, which is shorthand for retreat place. And the next one is called chain. Approx. Simple, it's a chain across simple. But what, what, what are we doing here? Okay. So what we're doing here is what this, what this function does is it gives us all the contours and the contour a approximation to come.

Speaker 1:          36:08          And we want to, uh,

Speaker 1:          36:12          uh, so we're going to use the retrieve list to get the contour approximation that compresses the horizontal, vertical and diagonal segments and leads only what their end points. And so that's what the approx approximation, approximation, simple function does. We only want the, the, the ones that get, we only want their end points. We don't want all the contours, so it limits what we're contouring. So for example, for an upright, rectangular con contour, it's encoded with four points. Um, and we're going to get a list of those contours. So that's what the retrieved list does. It's, it's, we want to elicit those contours. Okay? Um, uh, okay. So, so that's what that does. And we're going to get, we're going to get the conference, I'm gonna get in a hierarchy of those, uh, which is, uh, the, the, the chain of contracts from the, from the greatest to least so that front, you know, the size of all these contours or ellipsis. Okay. Um, and so now we want to isolate the largest one. Now that we have a list of them, let's isolate. So we get just the largest guns post a contract sizes. We want to get a list of all the sizes and we're going to use, um, uh, we're going to use open cvs function to do this. Um, contours the find the contour area and our rights, um,

Speaker 1:          37:40          contour, contour, or come to work in concert. Okay? So for every Conduent Elixia contours, get the area of the, of that and then store it in our cohort sizes. A array. Okay. That's what that does. Let me make sure I had this syntax correct here. I do have the correct syntax. Okay, cool. So now we want to get the biggest one. We've got a size of all of them. And so now how do we get the biggest one? Luckily for us,

Speaker 1:          38:04          luckily for us, quite fun has that built in Max function. We'll just get the Max value of our array, which will automatically detect the biggest value in our era of concourse. And uh, let me see this. Let me write this out. Lambda x and x zero. And then we went that first value for key. We just want that. So once we've, um, we've got the w we want the Max value, uh, suddenly write down around Max. Um, and what's the order we want them. We want them the contour in the first position. That's where that, that's where that one value comes from. A, and then we're just going to be, cause it's ordered, right? So we'll get the biggest one at the beginning of the array. Uh, and then let me say, let me see what this says. We're isolating the contours for isolating the, sorry, I sitting the largest contour. Okay. Um, uh, okay, so that's isolating the largest contour. Um, and

Speaker 1:          39:14          uh, so then our last step is to return the biggest one for return. The biggest, the biggest contour line 25. What do we got here? Contour. Hierarchy. CBQ to find contours. Image to good. Yeah. We're good here, right? Oh yes. Come towards. Thank you asha. Contours hierarchy and then uh, okay, cool. We're now is your turn the biggest on fourth, fifth. Let's get that mask. We'll take it as zeros and then if the shape of the image and then you and taste. So we're going to get that, the mask of the, of the shape and they were going to draw those contours and then we're going to return it, right? This is where we actually draw the con, the Ilitches honored strawberry. Uh, and then I'm going to, I'm going to demo this so hard for you guys in a second. It's gonna be Alex. We're going to drag this multiple images. We're going to all the beautiful, uh, come towards to get work to, to show up. Okay. So we're going to draw those contours. We'd arrange from using the mask from the biggest cons. Uh, you see the biggest contour in the range up til two 55. Uh, in terms of the color scheme. And then we're going to return it. Return biggest contours mask. We have one more method director. Okay.

Speaker 1:          40:40          Circle Contour. This is where we actually defined. Um,

Speaker 1:          40:48          this is where we define, uh, the actual contoured stuff. So we'll take, we'll say image contour. Okay. Um, this is, okay. So this is where we, um, uh, this is where we define the shape of that ellipse. This is where we define the shape of that contour. Um, so we'll say, okay, so get the bounding. If the bounding of lips first, it's our last function. It took me about five more lines and we're having that. We're done. We'll say we'll get our bounding, the lips, the image with the lips, and then I'll do, I'll demo it and then I'll do my last five minutes minutes. And I'm going to use a copy of the image because we want two copies of the image we're going to, right? So then, um, we'll say the ellipse is, we're going to fit, our lips are a contour and then we're going to add it.

Speaker 1:          41:41          And by added, I mean think back function to think the image with your lips. So we're going to pick an image with the width on it. Um, and then at our fitted ellipse, so it's a, a size, a better size. We're going to say I want to be lifted to be green. Um, uh, with a guy you have to, because we want, uh, but that's the size of the bill, the length of the, the, that, the width of that, that contour lines. Um, and then TV two dots, CV a, um, and then we to it. Okay. And then, um, they manage with polyps. Okay. So

Speaker 1:          42:25          let's file this baby and see if it works. We'll just compile. Okay. So, uh, let me, let me just get it that this works. Oh, no, no, no. I forgot something guys. I forgot something. We've got to actually write that, that last code to read, reading the image. I never did that. So it's three lines, three the image in three lines. So what does that, we'll get an image using open CV imagery function. And w the image is called Yoda jpegs, which is the image of the strawberry actually. Did you guys put together? We'll take a result.

Speaker 1:          42:57          Um, all right. Child. Carmen, Carmen, Carmen, what do you see what I'm saying? Uh, find a strawberry and then using that image and then write it. That's it. Okay. So now we're going to demo our code and I'll write it using open CPS image, right function, no two. Dot jpeg. We'll call it the old to the new image. And a result as the perimeter for that because that's our, you'll leave it. Okay. So let's, let me open the berry. So this is our initial strawberry, right? This is our initial strawberry. And now once we up run this code, which I've called fund up pie, once we run this code, which I've called fun dot pie. Okay, let's see. We've got an Arrow here. Fine. Strawberry image. So online 100. I said fine. Strawberry image. Uh Oh, what am I doing here? Oh right, equal sign. Yes. Here it comes guys. Here it comes. So, uh, let's, from Future Vision, oh, future important have to happen at the beginning of a while. I forgot about that. Okay. So we move that are out of there. Let's try that. Um, okay. So this says, okay, so the problem with that is

Speaker 3:          44:14          mmm,

Speaker 1:          44:16          okay. So this is a weird error, so, okay. Hold on, let me make this bigger. So you guys can see, um, so python on hand up high, right? Oh right. It's not very, it's a a high, right? Oh yeah. So, um, interesting. Okay. And See, you should have called her a BGR to RGB and find strawberry. Okay. No, no, no, that's definitely correct. Um, which just remember what the deal is. Oh, right. We've got to convert Barry, not Yo, we'll call this very too, so it was a wrong image. Right. Okay. So that, that's what it was. All right, so let's, let's run this. This is going to work. Bubble named biggest is not defined. Okay. Let's see what that is. Um, the bugging time. Exactly. Debugging is fun as hell sometimes. Um, it's starting to become more fun even when one live, because I'm getting more used to this. Okay. So what does so biggest, let's find the biggest, biggest, it's not defined. What are you talking about? I defined biggest, obviously I didn't because it's not there, but, okay. So I said biggest, um, and right. So where should I define biggest? So biggest, um, oh, biggest contour. Not Biggest. Uh, that's, it's biggest contour. Contour. Okay, let's try that.

Speaker 1:          45:45          Okay. Interpolation online. 14.

Speaker 1:          45:51          Unexpected Keyword interpolation. Image interpolation. Nearest PLT up in both image show, not show human show. Okay, let's try that. Oh, okay. That works. Let me, well, let's see. To work. So it's called very too. Okay. Yes. How cool is that? So this is our original Barry and this is the one that it detected. Okay. So how the hell did it do this? Okay. It detected it, right? So to do this, we, here's what we did. Here are the steps and that, and now I want you guys to find a strawberry image on the net and just post it in, uh, in the, in the chats. So I'll try it on that image as well. While I explained this, what we did was we first converted the color scheme too from BTR to RGB so that we could have so that we could scale our image properly. The next step is we scaled our image so it fits in the window size.

Speaker 1:          46:47          That map club life requires, uh, which is, you know, under 700 by 700. And it's a square image. We turned our strawberry into this word, then we cleaned our image using the golf seem to blur function, which smooth the image so that it's a, it's a, it's it's uh, one, uh, one color scheme, uh, that we can just focus on like red instead of a, you know, little black holes and yellow and all that. And so then we define our filters. What's, what's the minimum read, what's the maximum read, um, and then what's the minimum brightness in the maximum brightness. So I use two filters. We combined them, we applied them to the image, we segmented the strawberry from the rest. We've got a list of strawberries. In this case we only had one, but this would apply to multiple strawberries. As we added a mask, we overlaid the mask and then we circled the biggest one, and then we showed it, and then we convert our original image back. And that wasn't necessary, but we just, let's just convert it back to Bgr so that we can perform other, um, processing tasks on it. So, okay, so that's the code for that. Let me try it out. One more image. Okay. Strawberry image.

Speaker 1:          47:54          Uh, and we'll do several. Let's pick a, let's pick this one. Okay. And we'll save that and we'll go to our, um, we'll move that to this, uh, here and we're going to rename. So then we'll open this file and we'll say, well, what's it called? Was it called? It was called

Speaker 1:          48:27          Yo. Test Dot jpg. We'll read them at Yo Tessa Jaytag. We'll use jpeg. And then in our code we're going to, uh, exactly. Yo, test dot jpg. And then we'll say go test two dot jpeg. And let's see what happens. Well, I've never tested on this code in particular. Uh, let's see what happened to your fund up high. Okay. And now we'll open test two dot jpegs. He would hit these. Okay, so we just circled the entire thing. Uh, but it's because he's, the strawberries were bunched together so, well, we can further improve on this to make sure that it only right. Um, segment the best one. Our Code is ideal at the strawberries aren't touching, but these are tough. These are touching. So that's that. Um, uh, and there's, there's one more thing I want to say about this. So let me, let me start screen sharing again. Let me stop the screen share and you get back to, um, stop screen sharing. Okay. So, so yeah, I mean, open CV, it's been used for so long, you know, there's so many built in methods, transforms, different types of, you know, all sorts of research has gone into open CV, um, to, to do that. But deep learning now is slowly taking over. So if we had, and let me just show this right here. So it's like, it's like, it's like

Speaker 1:          49:44          if this is deep learning, can you guys see this? Oh my God, it's backwards, right? I forgot about that. Um,

Speaker 1:          49:50          how does shift and do it where it's like not backwards. Interesting. Uh, okay. So I can just do it with my hands guys. I do that anyway. So it's like deep learning with like, uh, open CV was everything. It was all a computer vision, but then deep learning showed up and now the point is slowly taking over. So right now you can use a little bit of open CV, can a little bit of deep learning, but eventually you'd want it will just take over and they'll all be deported. Uh, so like right now what our need for that. By that it's like, well we can use open CBQ segment a strawberry and then we could use deep learning to identify it as a struggle. So we can say, okay, this is a strawberry in a picture. Write a circle around it and then use deep learning institute of text.

Speaker 1:          50:24          Well, what is the name of that thing? Okay. So we said we define the shape and color and some of something and then we can say, well, you see 0.2 to recognize what that is. Um, and also deep learning is computationally expensive, right? So sometimes you want a quick and dirty solution. You just want to segment an image and you don't want to have to, and uh, although deep learning learns features, you just want to encode with features yourself because it's something said, well, you're doing open CV is great for that. Um, so yeah, so that's that. And let me do a five minute Q and a at the end and then more and then that definitely live stream. Any, any other questions? Oh, it's only backwards for me. You're right. You're right. I forgot about that. Yeah, she admin is awesome. Uh, will you make a series B series where you make build a robot using AI?

Speaker 1:          51:04          Yes. That's coming up. I'm going to use a drone. Uh, will you make it a Google search algorithm? That's a great idea. That's a great idea. A poor, I'd never thought about that. I should do a search algorithm. Um, what was your big announcement last Friday? Wait, two days. It's coming out dead height. It's coming out this Friday. Come hell or high water is coming out this Friday. Um, is your release more videos? I am on that. The thing is I don't want to, I don't want to, I'm never, I'm never going to let anyone else write the script for my videos. I don't care who it is. I don't care who pays me, how much I, every single word that I speak will come from my heart, my soul, my mind. So if that doesn't scale, it doesn't scale, but I will never speak the words that someone else tells me to speak.

Speaker 1:          51:51          Okay. I promise you that, uh, make a search arguments. I would find the most complete come complete answer to any question. Um, then yeah, I'll add that to the search algorithm video admitted. Please make a dedicated video for Q and a section. Hashish. I'll do that in the future. Can I get a shout out? How Jd can you recommend? Can you recommend CNTK? Um, I, I wouldn't recommend CNC actually. I would recommend tensorflow. Uh, yes. Police Department with patriotic. I'm not for sale. Exactly. Thank you. Jay D is there a simple way and open CV to get the total variation or for Hue and saturation? Um, uh, yes, there is. Uh, and I, um, yes there is, but I don't have time to show exactly that. Uh, thank you. And so, uh, how do use neural net and open CV? I'll do more on this stuff later.

Speaker 1:          52:40          Uh, two more questions and then we're good to go. Okay, two more questions. Uh, can you make a video on motion tracking in open CV? That's a great idea. That's a great idea. I can do that. Other hundred. One more question. Um, where did you learn all these from? How much swollen do you drink? Uh, I stopped drinking soylent. I used to drink it a lot. Um, where did you learn all these guys? Um, so I think a lot of us are bounded by the idea of we have to learn a certain way and it has to be in this exact format for us to tell ourselves that we now know this. But look, if you, if you like, you know, read, if you really take a day to read, like, I dunno Andre Carpathians, that famous Lstm blog posts from start to finish and you're in, every time you see a word or phrase or equation that you don't understand, you can Google that and then you go back to him.

Speaker 1:          53:30          And if you complete an article like that, like a very heavy article, you now understand at a high level how an LSTM works. You don't necessarily need, you know, like a four year degree to say, now I know how else the important. So we have to, we have to shift how we think about learning. It's not so much about about having to do a certain structure, it's about telling yourself and believing in yourself that you can't, you can know this, you do know this and you can build something with it. And so that's what I'm here to help you with. I'm here to inspire you guys, guide you guys on this journey that we are all on. Okay? We're all learning. Okay. So, um, one more we into a super interesting chicken and startup. Uh, that's a great question. It depends on what you're doing at the start for doing research stuff.

Speaker 1:          54:13          Uh, me personally, I would do a research internship just because I'm interested in research. Um, cool. So that's it. Reddit, Ama, that's coming up. Someone has to like request me, right? Like requesting you to do it, man. Just to say, Hey, I'm, I want to do an amen. Okay. So right in context, me or somebody's going to say, well, I know the CEO. He's a cool guy. Okay. Um, so that's it for this Q and. A and for this last session. I love you guys so much. Thank you for watching. Um, uh, something cool. It's coming out on Friday. It's, it's happening this Friday. Come hell or high water. I, I made, I'm making this promise you guys, it's going to be awesome. Um, and thank you so much for, uh, for doing this, for, for being here. Okay. So for now, I've got to find a place with better lighting because I love natural lighting, so thanks for watching. [inaudible].