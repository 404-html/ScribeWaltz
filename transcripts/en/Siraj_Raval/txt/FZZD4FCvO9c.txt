Speaker 1:          00:00          Cloud or edge. Why not? Both.

Speaker 2:          00:04          Okay.

Speaker 1:          00:05          Hello world, it's Saroj and until recently released a toolkit for developers called open Vino to help build computer vision applications that can be used at the edge or in the cloud. Open Beano stands for open visual inference and neural network optimization. The toolkit is available for both windows and Linux platforms and it enables us to use convolutional neural networks for computer vision at the edge. It also supports heterogeneous execution across Intel's computer vision accelerators using a common API for the CPU Intel integrated graphics, the Intel Mobidius neural compute stick, which I already made a video about. An FPGA basically develop once, deploy anywhere and since computer vision can be difficult to master, it includes an easy to use library of CBE functions and pre optimized kernels. This can be applied to a whole range of applications like face detection, object detection and license plate recognition, which we'll demo in this video.

Speaker 1:          01:13          Using these dependencies. It's inference engine can run deep learning models easily and its model optimizer imports converts and optimizes models that were trained in standard frameworks into a format and usable by Intel tools. Like the inference engine. If you don't feel like training your own model, the toolkit comes with a bunch of different pretrained models you can use at the low level. The toolkit includes support for both the open CV and open VX computer vision libraries, especially optimized for Intel hardware. It also has an included media SDK that offers us access to hardware, accelerated video codecs and frame processing, and it enables the use of the popular open cl library on the GPU or CPU for Intel processors. Optimizing and deploying one of these models is relatively easy. First, we just configure the model optimizer for whichever framework we're using, including tensorflow on x, mx net and cafe.

Speaker 1:          02:17          Then we can convert a trained model to produce an optimized intermediate representation of the model based on the trained networked apology weights and bias values. We can then test the model in the intermediate representation format using the inference engine in the target environment via either the provided inference engine validation application or one of several sample applications. Lastly, we can integrate the inference engine into our application to deploy the model in the target environment. So let's demo the example of using open Beano to perform vehicle detection, which will detect a car and it's licensed plate. We'll want to use a pretrained model for this, specifically the faster or CNN model. This is actually to neural networks eight regional proposal network that generates region proposals and a network using these proposals to detect objects. The output of the RPN is a bunch of boxes that will be examined by a classifier and regressor to eventually check the occurrence of objects.

Speaker 1:          03:25          The RPN thus predicts the possibility of a box being background or foreground and refines it in the first step. The input image goes through the convolutional network, which will output a set of convolutional feature maps on the last convolutional layer. Then a sliding window. It's run spatially on these feature maps. For each sliding window. A set of nine anchor boxes are generated, which all have the same center, but with three different aspect ratios and three different scales. Lastly, the spatial features extracted from these convolutional feature maps are given to a smaller network, which has two tasks, classification and regression. The output of the regressor decides the predicted bounding box. The output of the classification sub network is a probability p indicating whether the predicted box contains an object or it's from a background. We can download the weights, metadata, and model weights directly from Github and Dropbox respectively.

Speaker 1:          04:26          It's a cafe model so we can run it through the model optimizer using the following command in terminal. This will create an intermediate representation that our inference engine can serve when we run the application will receive an output file labeled zero dot BMP. When we opened that file, we'll see the detected car and closed in rectangles. It outputs the list of classes of the detected objects along with the respected confidence values and the coordinates of the rectangles and the standard output stream. As you can see, this high performance library makes computer vision really simple for anyone to try. I've linked to some great resources to learn more in the video description, including a link to the free download on the open VNL website. Please subscribe for more programming videos, and for now I've got to keep it open source, so thanks for watching.