Speaker 1:          00:00          Can we learn to learn to learn hello world. It's a Raj and what if neural networks could learn how to learn the process of learning to learn. We're a top level AI optimized as a bottom level AI or several of them is considered metal learning and it's currently a very popular topic in Ai. The reason being metalevel AI algorithms generally make AI systems learn faster, adapt to changes in their environments in a more robust way and generalize to more tasks and they can be used to optimize a models architecture. It's parameters, the type of Dataset it uses or some combination of all of them. If we look at the literature, there are some pretty hilariously named metal learning papers that demonstrate these techniques like learning to learn by gradient descent by gradient descent, got to love it and darts or differential architecture search algorithm. But in this video I want to focus on a specific metal learning technique called neuro evolution.

Speaker 1:          01:05          This is the process of using what's called an evolutionary algorithm to learn neural architectures. The reason this technique piqued my interest is because justice year Google published some research detailing their effort. At using an evolutionary algorithm to learn the architecture of a neural image classifier and it ended up becoming the state of the art, which was somewhat surprising to many in the research community. Since evolutionary algorithms haven't shown nearly as much promise for real world use cases as supervised and unsupervised methods have so far and don't forget, brute forcing neural networks can perform tasks that would be difficult for humans if they're given large amounts of training data. But discovering the optimal architectures for these networks is nontrivial and takes researchers a lot of trial and error. Image classification is a well known problem in the community. As deep learning researchers established the state of the art.

Speaker 1:          02:04          A couple of years ago, researchers worked hard on developing newer architectures that progressive Lee brought the state of Vr to newer levels. Year. After a year, ambitiously, Google decided to try an evolutionary algorithm to try to learn what a neural architecture would look like for image classification instead of hand designing it and it outperformed the rest, and it wasn't just Google. Neuro evolutionary strategies have started to see more adoption as popular tech companies like Uber have started adopting them to help improve the performance of their products. Uber's dispatch algorithm has to analyze thousands of features in real time to generate more than 30 million Ryder driver match pair predictions per minute and neuro evolution helps them speed up this crucial process. They've got a great blog post on this as well that list several examples. So why applied evolution to neural network design? Well, to quote the contemporary poet Marshall Mathers, we ain't nothing but mammals and nature demonstrates this.

Speaker 1:          03:11          When the evolutionary biologists, Charles Darwin visited the Galapagos Islands decades ago, he noticed that some birds appeared to have evolved from a single ancestral flock. They shared common features, but we're characterized by their unique beak forms, which sprung from their unique DNA. We can think of DNA as a metal level construct. It's a blueprint that guides the replication of cells, a longterm memory store that captures instructions necessary to recreate biological systems that transcend their death. His hypothesis was that the isolation of each species to a different island caused this diversity. Eventually he turned this hypothesis into his now famous theory of natural selection. This process is algorithmic and we can simulate it on silicon processors. By creating evolutionary algorithms, an evolutionary algorithm creates a population of randomly generated members. Each of these members are represented by some algorithm. It could be any kind, not just a machine learning algorithm, even blockchain, no.

Speaker 1:          04:20          Then it will give each member a score based on an objective function. This score is called the fitness function. It's a measure of how well a member did in relation to the goal. Once all members are scored, the algorithm will select the highest scoring members by some predefined threshold and breed them to produce more members like them. Breeding involves some interpolation of each member's features that is application specific. In addition to breeding, will mutate some members randomly to attempt to find even better candidates. The rest of the members die off in a very Darwinian survival of the fittest way. This process repeats for as many iterations as necessary. Actually in this context, we'd call them generations as we defined at the end. The idea is that we'll be left with the very best possible members of a population. The steps are all inspired by Darwin's theory of natural selection.

Speaker 1:          05:18          We can think of them as optimizers searching the possible space of solutions for the right one. They're all a part of the broader class of algorithms called evolutionary computation. If we again look at the animal kingdom, we'll observe that there is a complex interplay in two intertwined processes, interlife learning and intro life learning. We can think of interlife learning as a process of evolution and natural selection traits. Epigenetics and microbiomes are passed on between animal generations and intro life. Learning relates to how an animal learns during its lifetime. That is, this is conditioned on its interaction with the world. Things like recognizing objects, learning to communicate and walking. Both of these natural approaches are mirrored in computer science. Evolutionary algorithms can be considered interlife learning, whereas neural networks can be thought of as intro life learning or any gradient based optimization strategy really where specific experiences results in an update in behavior.

Speaker 1:          06:22          So how do we perform neuro evolution using both of these processes to complete a goal? Let's say we have a very simple fully connected neural network. Our goal will be to find the best parameters for image classification. There are four main ones, the number of layers, our network, we'll have the number of neurons and each layer what the activation function will be and what the optimization algorithm will be. To start, we'll initialize our neural network with random weights, but not just one neural network like we usually do. Let's initialize several. To create a population will need to train the weights of each network using an image data set. Then benchmark how well it performs at classifying test data. We'll use its classification accuracy on the test set as our fitness function. If we sort all of our networks by their accuracy, we can see which ones are the lowest performing and remove them.

Speaker 1:          07:18          Will only select the top scoring networks to be a part of. The next generation will also select a few of the lower scoring networks since it could potentially result in us not getting stuck in a local maximum. As we optimize, we can also randomly mutate some of our network parameters as well. Both of these methods are like an evolutionary way of preventing overfitting. Now we're going to breed our top picks. In our neural network case. We'll create a new network or child by combining a random assortment of parameters from its parent networks so a child could have the same number of layers as one parent and the rest of its parameters are from another parent. Another child could have the opposite. This mirrors how biology works in real life and helps our algorithm converge on an optimized network. If we test out our algorithm and compare it to a brute force search will find that our algorithm gives us the same result as brute force, but in seven hours of training instead of 63 as the parameter complexity of the network increases.

Speaker 1:          08:24          Evolutionary Algorithms provide exponential speed ups. Google did this as well, but with lots more data and computing power, they use hundreds of Gpu and TPU is for days they initialized a thousand identical convolutional neural networks with no hidden layers. Then through the evolutionary process, networks with higher accuracies are selected as parents copied and mutated to generate children. While the rest die out. It progressively discovered better and better network architectures. In a later experiments, they used a fixed stack of repeated modules called cells. The number of cells stayed the same, but the architecture of each cell mutated over time. They also decided to use a specific form of regularization to improve the network's accuracy. Instead of letting the lowest scoring networks die, they removed the oldest one's regardless of how well they scored, and it ended up improving the accuracy because their networks didn't utilize wait inheritance and they all needed to train from scratch.

Speaker 1:          09:27          This technique selects for networks that remain accurate when they are retrained. So only architectures that remain accurate through each generation survive in the long run, which means we'll get networks that we trained really well. They called their model Amoeba net and it's the new state of the art in image classification. So what have we learned here? Metal learning is the process of learning to learn where an AI optimizes one or several other ais. Evolutionary Algorithms used concepts from the evolutionary process, like mutation and natural selection to solve complex problems and a metal learning technique called neuro evolution uses evolutionary algorithms to optimize neural networks. Specifically, please subscribe for more programming videos. And for now, I've got to find a gradient, so thanks for watching.