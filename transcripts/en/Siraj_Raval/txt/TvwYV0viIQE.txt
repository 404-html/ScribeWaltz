Speaker 1:          02:14          He won't work in the go live. Are we ready? All right. Hello world. It's Saroj and welcome to this live stream. I'm so excited to see everybody here. What I'm going to be doing in this livestream is I'm going to be solving this Kaggle challenge. It's called the invasive species monitoring challenge. There's a lot of plants that are possibly going to destroy the ecology of this area and what we can do is we can identify those images with those invasive plants. And the way I'm going to do this is using Pi torch. Okay, so Pi Torch is a shout out to all the Pi Torch lovers in the house right now. Pi Torch is a neural network library and it was invented by Facebook's AI research lab and it's been gaining a lot of traction, especially in the research community. Now, tensor flow is the leading, you know, neural networks, deep learning library out there, and most people use tensorflow.

Speaker 1:          03:05          However, when it comes to research, I'm seeing a lot of Pi torch happening, and in this video I'm going to describe some of the unique features of Pi Torch. We're going to code some pie torch. We're going to solve this challenge. We're going to learn about resonance, a res residual networks, which is a type of neural network that has this really cool idea of skip connections. So I'm going to talk about that. There's an identity mapping. There's some math, there's a little bit of everything. You know, you guys know, you guys know what the deal is. Okay, so let's get started with this. Thank you everybody for coming here today. I've got a little, yeah, yeah. Pi Torch is amazing, right? All right, so here we go. So Pi Torch versus tensorflow, right? I've got this little graph of like research use cases versus production, Google versus Facebook, but let's talk about some of the unique features, right?

Speaker 1:          03:49          So we're going to just compare it with tensorflow just because tensor flow is the, you know, the, the most used in terms of developer activity on get hub library out there. If we look at the documentation, I think tensorflow clearly wins here. I mean the tensorflow documentation is massive because a, it's been around so long. B, they really putting an effort into it. And when I, when I say documentation, I'm not just talking about the API docs on the website, I'm talking about good hub. I'm talking about number of, of examples. I'm talking about video content. I'm talking about a lot of different documentation, whether it's on youtube, you know, whatever tension flow clearly wins. Whereas if you go to the Pi torch documentation as I, as I am right now, um, let's make me a little smaller on the corner so we can see this documentation.

Speaker 1:          04:35          If we look at the, the Pi Torch Documentation, uh, if you look at any of the functions, well these are, these are like guides, but let's look at some of the functions like Auto Grad for example. They usually just a single page for a function, whereas I feel like there should be more here. Uh, but yeah, I think tentraflow wins in, in, in terms of documentation. But we're a Pi. Torch wins is when it comes to the graph itself, the computation graph. So this is an image of a neural network that was built in tensorflow that we're visualizing intense or board, which is the visualization tool. And if you think about it, neural networks are computation graphs. There are just chains of operations applied to variables. And it's just the, just the chain of that over and over and over again, right? Whether it's a dot product operation, whether it's an identity mapping, whatever it is, you have a variable apply operation and just keep doing that until you get an output.

Speaker 1:          05:27          So there's a difference here, right? So what Pi Torch does, and this is what I believe is the really the key feature of Pi Torch. What really sets it out from the, from the, um, competitors here or the other libraries, is the fact that you can create a dynamic graph. So it's a graph is created at runtime dynamically. So just like this, as you're saying in this gift here at runtime, the graph is built, whereas with tensorflow, it's a static computation graph. Okay. So at runtime, the graph already was at compile time and now it's just static right there. So why, why did tentraflow do this? Well, first of all, for for production use cases, it's very valuable to have a static computation graph and their speed reasons for that. There's distributed training reasons for that. But a lot of the newer neural network architectures in research, especially any of the recurrent models, right?

Speaker 1:          06:17          Where there's this recursion happening, it's better to have that graph be allocated dynamically at runtime. So the graph is built as it's being run. And the reason for this is because a lot of times new operations are applied that wouldn't be applied before. So that's the whole idea behind a dynamic graph, right? You can make changes to it. There's no static nus status to city, what's the word for what, what's like the Noun for static? Well adjective. Anyway, it's more static and a, and so when it comes to these newer recurrent architectures with attention mechanisms, with um, you know, LSTM networks, gru networks, uh, and now with the new one, which I have an amazing video coming out on by the way now Lou, um, which, um, you know, Trask released a paper on. I know you guys are waiting for that. I've been waiting for that but don't worry, it's coming on Sunday.

Speaker 1:          07:09          It's a sick video. I have so many videos coming out this weekend. You have no idea. Open AI five, it's, it's going to be literally social media will light up when these videos come out. By the way. Now back to this, the computation graph is different. You have a static versus dynamic graph. So Pi Torch wins in this case. However, I want to note that, uh, that Nalo exactly. I want to note that tensorflow did like kind of tack this on later with the imperative graph and that works too. So there is a way, however it's not native and the way that it was with Pi Torch for visualizations tensor board clearly wins. Pi Torch has got nothing, at least from the Pi Torch team. I don't know about any like random rogue hacker on get hub who created some this library. But tensor board is king here. Tensorflow wins for debugging.

Speaker 1:          07:59          Okay. Pi Torch wins. Okay. Pi Torch wins for debugging because there's a TFD bugger called TF DBG. Um, but a lot of people, there's a lot of github issues about it, not working about it, not properly documenting things that are going wrong, whereas people just tend to generally loved Pi. Torch is built in debugger. So Pi Torch wins there, right? So rather than like, you know, just saying, print, print, print, print prints, you can actually use these, uh, you know, set trace functions that say PDB has, which is beautiful. And it gives you a very detailed stack trace about what you need. And lastly, interoperability, right? So sometimes we can't just do everything natively in those languages. We have to switch to c plus plus or Kuta. And we need a language that can talk to those in a very easy to use way. And in terms of interoperability, I think Pi two are twins here because it's all about writing code that among the different versions of CPS and gps and as you can see here, um, it's very easy to have an interoperable graph. Okay. So that's, those are just some of the features that I wanted to talk about. And now, uh, before I actually,

Speaker 1:          09:12          before I actually, um, I so guys I want to say I'm not the Messiah by the way because I had been watching wild, wild country on Netflix and I don't want to be that guy. I am not a god. I'm one of you. I'm a developer and don't worship me as a god. Okay. Cause that's not what we're doing here. I am just another developer and we don't want that to be the case. Okay. So anyway, let's code outs in pie charts. If you want to call me a god, that's fine though. No, I'm just kidding. Anyway, so if, lets, let's just coat out some simple pie torch here. So all we have to do is say import torch and we have some pilots going on. See I just compiled that. Okay, so now what I want to do is I want to build a simple neural networks so we could just see like how this works. Okay. So I'm going to do this really quickly. I'm going to, I'm going to hack out a script here using Pi torch. And once we do that, uh, then we're going to have our neural net. Okay? So simple to layer network. Okay? So, so far the torch class has a module and I'm going to show you exactly what that module is going to let us do. We can build a linear layer very easily.

Speaker 1:          10:21          Uh, right, exactly. Yeah, you guys are hilarious. Okay. So, right, we've got to have the super function as in any like initialization. We've got to have our super function and once we have our super function to initialize our constructor, we can say, now, after I build this, we're going to start looking at some, we're going to do some exploratory data analysis, but I first want to just write out the script. So we have, um,

Speaker 1:          10:51          we have something there for us. Okay? So in my initialization script, I'm going to be using the input, I'm going to have it hidden states, and I'm going to have an output, right? So d, n h, a n, d out. That's my input, the hidden state and my output. And once I have that, now I can create this super function. And so inside of this, I'll have my first linear layer. So torches neural net module allows us to create linear layers just like this. Now the inputs to the linear layer is going to be the input data, and then its output is going to be the hidden state. Okay? And I see that some people say that I have a battery issue. Well, that the battery issue is gone. All right, so back to this. So for our linear layer, and we want to make sure the code is very readable.

Speaker 1:          11:35          So what I'm gonna do is I'm going to put it right here and I hope it's very readable to you. Okay. I hope you can zoom in a little bit. Let me see how much I can zoom in. I can't really, uh, please do into the code. All right. Let's see. You know what? Let's just, let's just strip this out and like sublime or something so you guys can really see what the, that's some Nalo Code. Don't look at now Lou guys, I was just making this totally look at this sick code by the way. I was, uh, anyway, uh, where were we? Right? So let me make this bigger and we make it in python and then we're good. We're good to go. So that way, cause sometimes with, you know these like, okay, no, I'll just call it torch dot pie, but around, on the desktop, boom.

Speaker 1:          12:21          Torched. Okay, so torched by Board Yon Lacuna on Twitter. Okay, so now we have the hidden state and now we're going to have the output, right? So the input to the new hidden state is he the input to the next layer is going to be the output from the previous layer. We know that. Okay, so very simple stuff. Now what else do we need? We need a forward methods. So for some reason, Pi Torch code, usually names there, forward propagation method as forward instead of just like build model. Usually this is called build model, but a lot of Pi Torch code uses, um, forward. And I think the reason for that is because forward propagation is dynamic is right. It's happening at runtime. So people who are writing Pi Torch Code want to be very specific about what they are doing and to be specific and to be real, uh, it is better

Speaker 2:          13:16          call, you know, whatever.

Speaker 1:          13:22          It's better to call it forward because that's what it is. Okay. So we've got the forward code. Now I need to have my, um, what else do I need? A batch size. So that's an n is batch size. I'm going to have our input, my hidden states and my output. And then it's going to be called 64 1,110 so these are going to be, my name's from my number, my batch size. So now I can create some random tensors. So the great thing about torch is it's got, it's kind of like num Pi is built into torch, so we don't actually have to use num py, num pies basically built into torch. So any kind of like matrix multiplication that we want to do, uh, it, it's all happening inside of Pi Torch. Okay. And let me just see what else people are going to hear.

Speaker 1:          14:09          Jupiter is fun. Cool. Zooming. Yeah, great. Much love to everybody as well. Of course, of course. By the way, Dean applications, I'm, we're, we're, um, we're almost done reviewing everything and uh, that's coming out this weekend. So there's a lot. That's a lot that's happening. I also have my masterpiece that's coming out, but I can't talk about that right now. My masterpiece is, is, is coming out soon. Don't worry about it. Uh, right. So, so we created random tensors to hold inputs and outputs. So what are tensors tensors or end dimensional vectors, right? So you have one dimension. So that's just a group of numbers. You have two dimensions. It's uh, you know, two dimensional. It's a, it's an XL spreadsheet, three dimensions, four dimensions, you know, et cetera. So the generalization of the vector format for end dimensions, which is what we need because we don't know how many dimensions are input data is going to be.

Speaker 1:          15:00          And so now that we have our model, we can just build it just like this, using our input, our hidden state in our output as the, uh, the values. By the way, if you're new here, hit the subscribe button to stay up to date with my latest AI content. Okay? All right. So, um, and tell your friends because I'm not going anywhere. I'm going to be doing this until I will never stop. So get ready for this. We have our loss function, our loss function. We can choose between multiple loss functions. Can anybody guess what I'm going to use, right? We have cross entropy. We have what's, what's the most simple loss function that we could use here? You should know this. If you've watched at least three of my videos, you should notice the answer is the mean squared error loss. Why? Because it's the most simple of them all for uh, for demo purposes. So that's the one, right? We're going to find the mean squared error. We're going to find a different between our output in our, um,

Speaker 3:          15:59          yeah.

Speaker 1:          16:00          What is Pi Torch useful for? For Research, for research, not for necessarily for production, but for resort, for research. Now what's our optimizer going to be? We all should know this. Every single person, even if you've never seen one of my videos, you'll notice the answer is to castic gradient descent, the most important algorithm in machine learning. If you don't know how gradient descent works, my friend, you need to know because it is the most important to machine learning model that you need ever in, in machine learning. Okay? Right? Our Algorithm now. Okay, so we've got that. I think this is supposed to be, yeah, right. No.

Speaker 3:          16:45          Okay.

Speaker 1:          16:46          Now lastly, we're going to have our training loop and then we're good. So

Speaker 3:          16:51          yeah.

Speaker 1:          16:51          Uh, so for 500 iterations we're going to perform our forward pass. So why predict

Speaker 1:          17:00          RMSC Adam? I see we have some opinionated wizards in here, which I love to see. I love to see that. Uh, so that's gonna be our forward pass. We're going to compute the predicted y and once we have our prediction, what are we going to do? Guys? We know how supervised learning works, right? We've done this so many times. If we don't know how supervised learning works, this is the first step. If you're new to machine learning, focus on supervised learning, which is what I'm doing right now. Once you finish supervised learning, then you move on to unsupervised learning. And what do you do when you finish? Uh, what, what do you do when you finish unsupervised and supervised learning? Who's, who's got the answer for me? I'm going to wait for in the comments. Someone is going to say the answer to what you do after you, um, learn both supervised and unsupervised learning because I know somebody is going to know exactly what it is. Okay. So now I'm going to and I, okay, cool. That's it. Dah, Dah, Dah, Dah. Now what did I call this? So in my desktop I called this torch dot pie

Speaker 1:          18:12          module attribute has no attribute. Exactly. Reinforcement learning. Yes. Good job. Everybody. Reinforcement learning module has no attribute. Nn Yes. Okay. Okay. Okay. Okay. Let me see what's up. Uh, let's see here. Oh, Gotcha. Gotcha. Torched dot nn module. Let's see here. Let me, hmm. I wonder if I do this in Colab, what the deal is. Well, actually I need to, we just paste it in here. This usually

Speaker 3:          19:01          goes for it.

Speaker 1:          19:02          Oh, right. Spaces and indentations and stuff. Right? Right. The forward, oh my God. D learning. Exactly.

Speaker 3:          19:20          Let's try that out.

Speaker 1:          19:23          Oh my God. See? And now you're going to watch me do debug in real time guys, because I've got some Kaggle to do. I've got some capital to do. Oh my God. [inaudible] this is not okay guys. I'm talking about high torch Pi Torch.

Speaker 3:          19:52          [inaudible] [inaudible]

Speaker 1:          19:54          Pi torch examples, not colab. See, I was just searching that you can see a bit of things that I was searching. Dah, Dah, Dah. I'm looking now for do you want people to do Q and a in the meantime, just ask some questions that I'm going to answer while I, while I get this up and running. So just, uh, we've got some great examples, by the way. I mean, look at the amount of examples. Pi Torch has forced some of the most advanced models out there. I'm talking about variational auto encoders. My favorite, uh, supervised model variational audit encoders. It's a, it can actually be unsupervised as well. Um, see what Pi Torch has here. A 60 minute blitz. What is Pi Torch? Damn. Look at that. Uh, neural networks. Yes.

Speaker 3:          20:49          Right.

Speaker 4:          20:55          Oh, right. Duh. That's what it was. I just needed that, right. No module name nn no module. Important torch done in it.

Speaker 3:          21:14          Oh my God.

Speaker 4:          21:18          Exactly. In Soviet Russia. That's what I like to hear. We've got a lot to do, guys. I wanted to give a very basic pie torch example before stepping into the exploratory data analysis. We've got a lot packed in for the session. Seriously. What am I missing here? Let's see. Oh my God. Okay. Let's see. Let's see. Let's see.

Speaker 3:          21:44          Hmm. Seriously.

Speaker 1:          21:52          See, this is that demo thing where it's like the code is working and then right when you get to the demo, everything just kind of, I'm going to reinstall Pi Torch. I mean, if that's what it's got to be, I'll reinstall pipe

Speaker 3:          22:04          torch. Okay. All right. Check, check the chat. How did you lost the last one that the reference to is that

Speaker 1:          22:25          Oh, is the torch for object you created a struck with the reference or a num py or ray or does it use it's own vectors to create an array? It's using, uh, it's using num Pi under the hood. I'm pretty sure it is actually. Actually that's what I assumed.

Speaker 3:          22:40          Okay.

Speaker 1:          22:40          I assumed it was using its own version of num Pi,

Speaker 4:          22:44          but

Speaker 1:          22:46          no, no, it's its own thing. Nd Arrays are similar,

Speaker 4:          22:50          but it's not an empire. That's very cool. Okay. Um, what I wanna do you know what

Speaker 3:          23:04          okay.

Speaker 1:          23:04          Is check out

Speaker 4:          23:08          colab and inside of Colab Your A. Dot. Py File.

Speaker 3:          23:18          Really? Oh, right. That could help, right? Fund out Pie. Yeah.

Speaker 4:          23:35          Nope. All right. Let's see.

Speaker 1:          23:41          All right, so we're going to use a new colab. So Google Colab, check it out. If you haven't, by the way, we can install Pi torch like this into colab. Now anybody can do this. So we just installed Pi Torch and once we install pie towards, we're going to install, um, we're going to see if we can,

Speaker 3:          24:06          okay.

Speaker 1:          24:07          You are seeing some real time debugging by the way. Uh, let's see on a Gpu. This is definitely gonna work. There we go. We are in sandbox. Let me answer some questions while we're waiting here. Uh, rename towards a pie. Colab is the best, isn't it? Do you want the questions? Yeah. Questions. While we're, while we're waiting for this to load. Tech guy asked, what is one shot learning against someone else else you to talk about the school of Ai.

Speaker 1:          24:36          Okay. Uh, so what is one shot learning? So one shot learning is the dream is the dream of all machine learning to be able to learn from little small datasets. And um, what has been done in that on that front memory? Augmented neural networks, man ends, I think Facebook was probably not the first, but the most successful in marketing as a, as a research lab. I have one shot learning algorithm. It's called the memory augmented neural network. It came out about two years ago and they did it with what I think, not theM and ist Dataset. They did it with, um, the Omni gloss data set, which they proved that they could classify images with only like, I think under a 50 samples. So if you want to learn more about one shot learning, check that out. What does this school of AI next week? So that's what I have to say about that. Seriously, check this out. See guys sometimes, sometimes, you know, in real time you got some issues and you gotta just like, exactly. I think that worked. Did that work? Maybe that worked. Let's see now. So now we're going to have some pie torch happening. Yes. Good, good. Oh my God. Yes. All right. So let's

Speaker 1:          26:01          see. Anyway. Okay, we got, we got to keep going guys. We have a lot more thanks to code, which are not going to fail by the way. So I wanted to give you that. This is going to work. Check that out. No Gpu, seriously. No GPS available. Oh, we've got to activate the GPU torch dot double two CPU. Oh, there's also this thing called Kaggle kernels, which I'm going to talk about as well. Uh, okay. Let me just, uh, placed this in here. Let's see now.

Speaker 3:          26:47          Okay,

Speaker 4:          26:51          so you choose GPU notebook setting. Oh, right, right, right. No book selling. Where's that change? Runtime to GPU.

Speaker 1:          27:05          Oh, cool. There we go. Thank you. Okay, so what I'm gonna do is I'm like determined to make this work now. Like I don't even care. I'm like, I actually have a vendetta against this because like it was totally working and now it's not. Okay. So

Speaker 4:          27:22          where were we?

Speaker 1:          27:26          I literally,

Speaker 4:          27:30          where'd I get this from? Where did I get this from? There we go. This is the deal.

Speaker 3:          27:39          No,

Speaker 4:          27:45          no. Module name. Torch installed torch. Yes, we installed torch. We did that.

Speaker 3:          27:55          Okay.

Speaker 4:          27:55          And now once we've installed torch in a new code snippet, we're going to have our code run while this is installing,

Speaker 1:          28:05          answering some questions here, changed the python for perfect, perfect advice. There's no python for uh, okay.

Speaker 4:          28:19          Important torch dot. Well, I did that important torch and then as an and I did that, that was literally like,

Speaker 1:          28:31          while this is compiling, we've got to keep going here. Let us do some exploratory data analysis. Guys. We have our data set. Let's, let's look at our problem and we're going to get back to torch. We're going to get back to torch while this is running. So what do we have here? Let's look at our data and then we're going to look at kernels as well. We have our data, which is going to be a set of images of different plants. We have labels for each, and I went ahead and downloaded these. And so what we can do is look at our data. So let's see if we can do this. Let's start off doing this locally and then we're gonna,

Speaker 4:          29:04          we're going to, uh, go further.

Speaker 1:          29:09          So, um, let's write out a read image function. Okay. So we want to read images and show them right here. So that's the first thing I'm gonna do. So I'm going to say, uh, using open CV and I got to, I have to open CV, I have to import open CV, which is called CVT. Open CV can be kind of a pain to install. Um, so if you don't have this installed locally, uh, I would recommend using either colab or Kaggle colonels to do this in the browser. But if you do have it locally, then things can be easy. Her, uh, for this. Okay, so that's a read image file. And I'm going to have a show image. I mean function. Now I have a show image function and once I do that,

Speaker 3:          29:57          okay,

Speaker 1:          29:58          then I can show the image and I'm going to have to import Matt Oh Matt plot live for that import. Um, map plot, live.py plot as PLT. And I have both of those and this is going to be a little percentage marker that makes sure that it's in line. Okay, so now let's show some images. So let me see if that works in valid syntax. CVT color. Okay, good. Now let's see, sample pick equals. Let's take one of our samples from our local directory, which I have and call, let's just pick one. Let's say maybe like number one, the first jpeg. Let's see if we can show this in the browser. Image is not defined right? So the image is going to be,

Speaker 3:          30:57          MMM,

Speaker 1:          31:00          no, not that sample picked show image. Uh, sample pick. Okay. And now we can see it. Yes. Okay. So here's our first sample and now we can, we can kind of browse and see what we have in our dataset. Uh, right, there's a bunch of images here. Okay, let me, let me look at some more images, right? Um, and these images have an associated label that we're going to now, um, we're going to now look at, okay, so let's see. Um, how many invasive versus noninvasive images do we have? Right? So let's, let's, let's draw a graph of that. So, uh, we're our label. So our labels using a pandas data frame, let me import Pantos as well. Import pandas as PD. Okay. So our data frame also, let me answer some questions. What do we have here? Um, document clustering. A LDA latent dear Schley allocation. Perfect method for that. It's a part of Andrew [inaudible] machine learning course. What is auto ml? It is Google's a hyper parameter tuning framework in the browser on Google cloud. Pillow is all pill is better. Your rights. Do you think nowadays python is sufficient to use ml for robotics or do we also need c plus plus and c? That's a great question.

Speaker 3:          32:28          Okay.

Speaker 1:          32:29          I mean when it comes to robotics, you're dealing with a lot of hardware and uh, unfortunately at the lowest level when it comes to reading like these, these, these drivers and these like hardware inputs manually, a lot of that, a lot of those libraries are still in c or c plus plus. So if you're doing robotics specifically like physical robots, not even in simulation. And I think you need some c plus plus knowledge to be real. Just don't think you would get through the whole thing with python. That would be a dream. It's happening. We're not there yet. Okay. So we have our training labels and now we want to see how much of each, do we have a right? So we need to import a seaborne. Seaborne is gonna help us visualize this. It's another data visualization library.

Speaker 4:          33:16          Okay.

Speaker 1:          33:19          So what am I going to have this style be? Let's have it be a dark grid and we're going to say the x axis is going to be the invasive plants that we have and the data is going to be our labels that we just imported into a pandas data frame. And now using a map plot live, we can give a title to this graph. Just like if we had to like do a report or something on this, we'll say invasive versus noninvasive images. Um, yeah. Then we're have our x label B are invasive. I guess we can specify a font size, let's say like 20 and then our why label is going to be of course the number, right? So the images versus the number and we'll make it the same font size. I know I misspelled font size there and uh, okay. So let's see what that looks like. Of course there's a,

Speaker 4:          34:22          Oh, okay. Okay. Okay. Okay. Right. There we go.

Speaker 1:          34:31          Yes. Good. Okay,

Speaker 4:          34:34          good.

Speaker 1:          34:35          So what do we have here?

Speaker 4:          34:38          Okay.

Speaker 1:          34:38          Count invasive versus noninvasive.

Speaker 4:          34:42          [inaudible] good.

Speaker 1:          34:46          So clearly, clearly we have much more invasive images where one is invasive. So that's, that's a good thing to note. Okay, good. That this is what we want. Um, you know, ideally it's like half and half. So we can see like what, what has an ideal, ideally, ideally we have a lot of data, but you know, whatever, uh, I think this is, no, this is enough data because this is an older competition. And if we look at some of the kernels, we can see that, um, on Kaggle we can see that it's been, it's been done a comma, right?

Speaker 1:          35:23          Right. So what kind of models should we build here? Right? So using Pi torch, what kind of learning models should we build, build here to build a classifier. And now there's a lot of different convolutional nets out there. There's, you know, Alex net inception resonant, uh, VGG 16, BGG 19. There's like a million of them and there's not a million. There's like 10 ish, like, but dense net. What we can do is we can try them all out, but one that I have not talked about before, and I'm going to take this opportunity to talk about it, is resonant. So residual networks. Okay. So let me talk about that really quickly and then we'll build that. Okay. We'll build a, a resonant architecture. So, um, if we, if when we're using recurrent networks, uh, there's this, there's a problem that occurs called the vanishing gradient problem. Now if you want to learn more about that, just Google vantage and gradients to Raj at least through videos will show up on youtube.

Speaker 1:          36:17          But a Tldr when we are back propagating a neural network using some kind of um, gradient descent based optimization strategy like Adam, you know, stochastic gradient descent, all sorts of great in a sense, um, variations, the gradient gets smaller and smaller and smaller as that value is back propagate its right. So back propagated means, you know, this is the value that's going to tell our weights, how to update to be better at predicting the output, the, the, the, the, the real output. And so we are using calculus to optimize. Remember neural networks are our models created with linear Algebra and they are optimized with calculus. So that's where you need calculus, you need calculus to optimize and you need linear Algebra to build the models. And to perform those operations on them. So during, so the reason we your calculus and because uh, we're, we're computing the partial derivative of the output with respect to the weights, the partial derivative of the error with respect to the weights.

Speaker 1:          37:22          And we keep doing that for every layer. So the problem is that this gradient vanishes. And this image right here shows how you notice how it's getting more and more translucent over time. That gradient gets smaller and smaller, smaller. So these, so to, to be real that, so the gradient is actually a vector of the partial derivatives that are computed, right? That's the gradient. And those values get smaller and smaller and smaller. So they diminish over time. So this is a problem because the network is not, it needs that gradient value. You can even think of the gradient as a kind of memory, right? So LSTM networks solve this for a recurrent networks, but how do we do this for convolutional networks, for, for image based networks. So some researchers had this, I think it was a genius idea to literally just skip over some of the intermediary layers.

Speaker 1:          38:10          And have the by skip over, I'm talking about have the gradient skip over intermediary layers. And by doing that you're, it's not going to diminish. You literally just skip them over. What do, I mean? Let's talk about this mathematically. So in the Resnick architecture, we have a bunch of what are called convolutional blocks. These are standard convolutional blocks, right? So convolution pooling activation that's inside of a block and you repeat that convolution pooling operation. And then activation function and repeat, repeat, repeat, repeat. But what if we can add what's called an identity mapping. So what you're seeing on the left here is the, the novelty of resonate where we took Afa backs and we modified it by adding an extra, um, dot product operation to it. And this is called the identity mapping. So what better way to explain the identity mapping then saying, well first of all, we have our function f of x and we are changing it to f of x plus x, where x is the identity mapping and this modifies the original operation such that the gradient will not diminish over time.

Speaker 1:          39:16          So in care, Ross, here's a very simple example programmatically of what I mean by a residual block. So in the residual network, we are renaming a convolutional block two eight. By the way, don't leave, I'm going to wrap at the end. By the way, we are renaming the convolutional block tweet residual block by adding in this identity mapping. So normally we would just say this right here, right? So in our block we would say convolution, you know, normalization activation function, which is really Lou, you know, in this case, which helps, um, with the vanishing gradient problem for other reasons. There's so many like little explanation tangents that could be going on here. By the way, there's so much here, but we are, what we're doing here is we're adding this part right here. So what I have highlighted is the identity mapping. It's what is added to the, um, initial set of operations.

Speaker 1:          40:07          So notice here that the shortcut is actually, if, first of all, we have to specify that we want this to be a shortcut, right? So we're going to say true if we want this to be a true residual block. And if we do this, this, this adds this shortcut operation to it right here. And then we just, and then once we've completed that, then we add it to the what was initially the, the chain of operations and then we returned that block as a whole. So notice that it's not necessarily that something is being replaced here, it's an extra operation that's added to the existing chain of operations. But what this does is we can think about it as skipping over because it's it, because it's not a zero mapping, it's actually adding value to it because it's, the reason it's like skipping over is because whereas the value would diminish over time because we're adding value to that existing chain of operations. It's a non zero value, which is what we want. We don't want a zero value for our gradient. So that's the idea behind a residual network. Uh, the original mapping F of x is recaps into f of x plus X. And it's, the theory was that it's easier to optimize a residual mapping then to optimize the original unreferenced snapping.

Speaker 1:          41:25          And that is the, the paraphrasing of what I've just said. Okay. So, uh,

Speaker 1:          41:32          it is a good place. Start Learning Ai. Yes. Now, um, in terms of hints about what's up to what's coming up, I would say of reinforcement learning, but that's all I can say right now. So Eda, we did that resonate. Okay. So let's, let's do this now, right? So the, first of all, let's see what Kaggle has for us. So Kaggle recently released, well, they kind of renamed what already existed, but they recently released this idea of a kernel. Okay. So a colonel is basically like Google Colab, but it's built into casual, by the way, Google bought Kaggle. So it makes sense that they're using the same infrastructure. So if we look at a kernel here, let's, let's, let's see what they have here for kernels. This is the most, uh, upvoted ker kernel for this, uh, for this Dataset is saying, use carrots. Pretrained VGG 16. So if we open up this kernel, I'll go ahead and forth the notebook.

Speaker 1:          42:22          It's got literally everything I need to run this in the browser. Okay. So what this is doing is it's in the browser, it's got a notebook, it's got a python compile a, it's got a python interpreter in the browser. It's got all the dependencies I need for this specific datasets. It's got, um, the data set itself is important right here that you could see as input right here with all of those, which is Super Handy, right? We don't have to download test.seven Z, we don't have to unzips tested seven Z, then we don't have to combine it with the labels. It's all already there, which is super useful. Now this is very cool, but we are not doing care os right? We are doing Pi torch. So let's go back and let's look for a [inaudible] 20. If we can find one. Can anybody see a chart? Here we go. Pi Torch starter 0.98. That looks pretty good. So let's click on that one and see what we got here.

Speaker 1:          43:14          Fork notebook. This guy went ahead and did this in Pi Torch, which is super awesome. And uh, how are we doing on time? Cool. Wow. Time flies when you're, when you're debugging. All right. So, uh, 48 minutes. Okay, we got to end this before it's too late. All right, so now what we can do is we can just run it in the browser. Notice this just compiled in the browser num Pi Pan does. We imported that. Okay. What about torch? Notice how I was having a problem before. A No problem anymore. It is all there. I'm compiling this code. Compiling, compiling. Now what is he using here, by the way? Okay, so he's transforming the data. Great. He's loading up the data. Cool. Uh, LR scheduler. That means I'm learning rates scheduler. He's deciding what type of learning rate to use here based on the number of, looks like a predefined, predefined threshold of number of epochs.

Speaker 1:          44:13          He's got a pretrained weight file that he is. So he's doing transfer learning. Cool. And he's using dense net. Okay. Dense. Now that's cool. And he's our sample submissions. Submit and train the network. Okay, cool. Well, this is going to take a while because training neural networks is not something that just happens, right? It's so anyway, check that out. So that's Pi Torch in the browser. Everything you need preloaded with the Dataset. A super useful. Now what are we going to do here? Well, we, well, we need to replace dense net with a resonates, but an IX also explain what dense that is and how that works. Uh, but it looks like we've run out of time. Go ahead and answer, ask some questions. I'm going to end this with a rap, but ask some questions.

Speaker 4:          45:01          Okay.

Speaker 1:          45:02          DGG is yes, but we, but we need to understand how resonant works. Okay. Lua is awesome.

Speaker 4:          45:12          Love you too.

Speaker 1:          45:13          What is unit net unit? Great idea. Joe Unit is interesting because it's, it's kind of a reflection of itself and the later layers we'll talk about that. Pooling is a great example. Pooling is not all of the data and the input is relevant to the output. So what pooling does is it chooses what's the most relevant. So what does most mean? Well, most in the case of Max pooling can be what has the most, um, what's just the biggest number in some, um, region of the input. And then we do that. So that's Max pooling. And that's generally the most used pulling operation in neural networks. There are other kinds as well. Um, can you talk about learning rate schedule or Api? Um, four Pi torch. I'll talk more about Pi torch. Where can we learn more about Pi Torch guys? So what I do when I'm learning about any kind of code is I don't look at anything but get hub, right? I just go straight to get hub and I look at some example code and hopefully the example code is well documented. This is the repository to look at. A reinforcement learning is probably what I look at cause that's what I'm most interested in right now. Uh, this is cool. Okay. I mean it could have better documentation but that works. Now I'm going to end this with a rap and I'm going to just pick some random word from there, from the comments.

Speaker 4:          46:29          Oh, let me see here. For alphabet, alphabet acrobatics rep by Blackalicious. Okay. Two people said that.

Speaker 1:          46:36          How forbid acrobatics

Speaker 4:          46:39          alphabet aerobics. Okay.

Speaker 1:          46:44          Alpha alphabet aerobics. Okay. Um, cool. I have, I found it. Never heard this before

Speaker 5:          46:55          given,

Speaker 4:          46:58          are you serious guys? You guys in trolling me, aren't you? All right, let's do this. I'm waiting for the beats. Seriously. Is this even a rap like,

Speaker 5:          47:11          okay.

Speaker 4:          47:13          Okay, fine. Alright, wrap on cue on monster. Golang.

Speaker 5:          47:18          Okay.

Speaker 4:          47:21          I like Gold Lang. I do it. No, no, no. Let me restart. I like gold. Lame. No, no, no. See, hold on. This

Speaker 1:          47:30          is just the most Wac beat I've ever heard. Like how, how is anybody supposed to wrap over this?

Speaker 3:          47:34          Okay.

Speaker 1:          47:36          It's getting faster as well. There's not even like a set tempo here. It's just I'm out. I'm going to just do it anyway. Here we go.

Speaker 1:          47:45          I like Golang. I'm slow. Maine. I like do it like I'm Ilan Musk made. It's going faster and faster. I like concurrently. See, I keep my go. Routines running. You see? Yeah, go routines. This is so wack dude. This seriously like, I'm not even going to, I'm just going to talk about, I'm just going to acapella dis. I like Gold Lang. It's got concurrent model. It's got concurrent sub routines. That's how it goes. You see what I mean? I do. One, two, three is distributed. Can't you see? I do it across different TPU then Gpu. Yes. I do it on my CPU. I do it on my, all right. That's it for this, for this live stream, guys. That's is how we do it. We don't, we literally don't care if we succeed, if we fail, if we do both, because we just keep on going. No matter what, nothing will stop us. We are going to do so much good for the world, and thank you for tuning in. Uh, for now I've got to make some videos, so thanks for watching.

Speaker 3:          48:47          Okay. Ooh.