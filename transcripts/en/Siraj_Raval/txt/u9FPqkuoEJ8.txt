Speaker 1:          00:00          Hello world, it's Saroj and let's make our own speech. Recognizer using tensorflow, speech recognition has gotten so much better in the past few decades. In the 50s the general consensus amongst computer scientists was that speech signals needed to first be split into little phonetic units. Then those units could be grouped into words, but even though this seems like it would work well, this approach did not give us good results. The first ever speech recognizer was called Audrey by bell labs in 1952 it could only recognize spoken numbers between one and nine and was built with analog electronic circuits. The renowned scientist and BP at Bell Labs, John Pearce, Dan speech recognition research because the results weren't promising enough, but a small group of visionaries at a newly formed team called Darpa, went against popular opinion and created a system called heartbeat. It used 15,000 interconnected nodes and each represented all of the possible utterances within the domain.

Speaker 1:          00:54          That youth a brut force search algorithm to map the speech to the right notes to get the text. This approach was slightly better, but then it blew, invented something called the hidden Markov Model. Hmms represented utterances as states and probabilistically predicted what a word was given the phenoms it was made up of when words like you are pronounced, they can have different durations like you or you and h and m's captured the plasticity of words by using a probabilistic approach. The hmm pretty much maintained its position as king of speech recognition throughout the eighties and nineties as researchers improve them more and more, and some Weirdos kept trying this dumb technique called artificial neural networks, but of course it didn't get good results. One of them, this Guy Geoffrey Hinton kept on trying out neural networks until all of a sudden, a couple of years ago, it started outperforming everything. Did people tell you, Jeffrey, you're wasting your time many times and would you say back, give me another six months and I'll prove to you that it works.

Speaker 1:          01:53          The key was to give it more data and computing power. This is deep learning. Now. These deep neural nets are how services like Siri and echo and Google now hear you speak, and with Google's machine learning framework tensor flow, we're going to build our own deep neural network that learns to recognize spoken numbers. We're going to download a labeled Dataset of people saying numbers, build a neural network, train it on that data, then test it out. See if we can recognize other spoken numbers. It'll be 20 lines of python code and I'll explain things as we go. Ready? Let's first import TF Lauren. Tia Florent is a high level library built on top of tensorflow that is easier to read and great for the past prototyping. Our other import is a helper class we've created called speech data. This will help fetch data from the web and format it for us.

Speaker 1:          02:39          Now that we have our libraries, let's define our hyper parameters or tuning knobs. We have three of them. The first one is the learning rate. The learning rate is what we apply to this weight updating process. The greater the learning rate, the faster our network trains, the lower the learning rate, the more accurate our network predicts. So it represents a tradeoff between time and accuracy. Next, we'll define how many steps we want to train for 300,000 we have our hyper parameters. Now we can batch our data. This is where we'll use our help a class speech data specifically, it's batch generator function. This function will download a set of Wav files. Each weight file is a recording of a different spoken digit like and each is labeled with a written digits. It will return the list of labeled speech files as a batch. Then we can split our batch into training and testing data with pythons built in next function. We'll use the same data for testing for simplicity, so it'll be able to recognize a speaker we trained it on, but not other speakers. Now that we have our training and testing data, it's time to make our neural network, so what kind of neural network should we use for this? I'm going to wrap the answer to this.

Speaker 2:          03:45          Did you drop out? Turn it up once a one problem is classifying images, input, image, output, label. Ain't no sequences. I want to many problems. Gives them image, captions, input image, output sequence, and all of them abstractions. A many to one problem is sentiment analysis and puts sequence output positive ain't no accident a problem that's many to many is a sequence of waves output sequence of words. Then our model saves

Speaker 1:          04:11          since spoken words are a sequence of sound waves. We want to use a recurrent neural network since they're capable of processing sequences, so we'll initialize our net by calling TF Lauren's input data function. This initial input layer will be the gateway. That data is fed into the network and the parameter will help define the shape of our input data or as tensorflow calls it our input tenser and tenser is a fancy word for a multidimensional array of data are two parameters will be the width and the height. The width is the number of features that are extracted from our utterances in our speech. Data help reclass and the height is the Max length of each utterance. For our next layer we use tee up learns Lstm or long short term memory function in a recurrent net. The output data, its contents is influenced not only by the input we've just put in, but by the entire history of inputs through our recurring loop.

Speaker 1:          05:00          Lsts are the type of recurrent net that can remember everything it's fed and because of that they outperform regular recurrent nets consistently. We'll use our previous layer as our first parameter it since we are feeding tensors from one layer to the next and the number of neurons. There's not really a rule for knowing how many neurons use in a layer. Two few will lead to bad predictions and too many will overfit to our training data, meaning it won't generalize well let's pick one 28 and then aren't dropout value, which says how much dropout do we want? Dropout helps prevent overfitting by randomly turning off some neurons during training, so data is forced to find new paths between layers allowing for more generalized model. Our next layer will be fully connected, meaning every neuron in the previous layer will be connected to its neurons and our number of classes are 10 since we are only recognizing 10 digits, we'll set the activation function to softmax, which will convert numerical data into probabilities.

Speaker 1:          05:54          Lastly, we'll create our output layer as a regression, which will output a single predicted number four our utterance. We're using the popular Adam optimizer to minimize our categorical cross entropy loss function over time so we get a more accurate prediction. Now we can initialize our network using TF learns, deep neural net function and set tensor board verbose to three which means we want a detailed visualization, will initialize our training loop, then fit our model to the training and testing data for 10 epochs with our specified batch size. Then we'll predict a spoken digits value from our training data. We also make sure to save our bottle for later use and print our results. Let's run this thing. Tf Learn has a nice log of important training variables built in just from running the fit function, so we don't have to specify what things to print after.

Speaker 1:          06:40          It's done training, it'll predict the digits. And if we wanted to we could just record ourselves saying a number and place it in the data directory, then predict that. So to break it down, LSTM neural networks are using state of the art speech recognition. We can use TF, learn to quickly build and train a deep neural network to recognize speech and good hyper parameters like the learning rate are those that are balanced between trade offs like time and accuracy. The winner of the coding challenge from the last video is mic. Then Holst. The challenge was to generate text in the style of Lord of the rings is NTF learn mic trained an LSTM network on again devilfish language, then headed out, put new Gandel fish like yellow to low, tease her, refer that ass of the week. No new coding challenge for this video is the challenge from the make a video game. But video is still running. You haven't watched it yet. Check out the link to it in the description and the due date is Thursday, December 15th at noon pst, which is one week from today. Please subscribe. And for now, I've got to get tickets to ICLR next year, so thanks for watching.