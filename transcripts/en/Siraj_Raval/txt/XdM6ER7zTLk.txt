Speaker 1:          00:39          Hello world. It's the Raj, welcome to this live stream. Uh, if for those of you who are in my previous life stream and doing one again, because why not? Uh, thank you guys for coming today. What we're going to do is we're going to find the relationship between student test scores and the amount of hours studied. Now to us, clearly there must be some kind of relationship, right? The more you study, the better your test score will be. But let's prove that mathematically by using a strategy called linear regression. So linear regression is a very simple machine learning technique. And the way we're going to optimize it is by using probably not probably the most popular optimization method there is gradient descent. So in this live stream you're going to learn about gradient descent and linear regression. So this is going to be awesome. So get ready for this.

Speaker 1:          01:33          I'm glad to see that there are some cool people in the room right now. What I'm going to do is I'm going to first talk about conceptually how we're going to do this and then we're going to implement it mathematically and programmatically. It's really the same thing in the yet. So let's pull up what we need to pull up. A great guy, good number of people in here. So let's go ahead and do this. So the first thing we want to do, so what I have up here is uh, is a, uh, visualization. It's an animation of what this looks like. Okay. And uh, it's going to start off as a horizontal line. We want to find the line of best fit, we want to find the line of best fit so that using this line we can then predict what a student's test score will be given the amount of our studied or vice versa.

Speaker 1:          02:22          But how do we get that line of best fit? We'll we're going to use gradient descent to do that. And so this is just a visualization of what the gradient descent process will look like to get there. Okay. And gradient descent is used everywhere in machine learning and deep learning. Okay. We think about everything in terms of optimization where we have some loss function that we want to minimize overtime. And gradient descent is the technique we use to do that. Okay. And so we're going to talk about that. So let me start off by answering, uh, um, I'll do a two minutes worth of Q and a for questions and then we'll get right into the code. So, hey, how's it going? Okay, we've got some, any questions? Questions about deep learning, AI, machine learning, uh, waiting for the wrap we'll see was well, yes. Questions. Questions really are the, the great thing to have in the beginning.

Speaker 1:          03:23          Do Ama with other people. Okay. So I'll give it, I'll give it 10 more seconds. Ten nine, eight, seven. We're about to get into this. We are about to get into it. Once I started there was no stopping. I'm like an Oreo that really has no relationship to what I just said. Can we do Q and a after the end of the session? Yes we can. So we're going to do Q and a every 15 minutes. So right now there are no questions because no one knows what the hell is going on. Is there any other method to get leased? Square error? Yes. The method we're using here is the sum of squared error. There are plenty of methods to do it, but this is the most used one. And one more question is, is linear regression like this ml or DL? Now that is a great question. Linear regression is just ml. It's machine learning. There is no neural network, but the reason I'm doing this is to demonstrate gradient descent because you're going to use this in almost every neural net that you built. You're going to use this all over the place. Okay, so that's it for the questions. Save your questions every 15 minutes I'm going to be answering questions and this livestream will be an hour long, more or less. So let's get started with the code, shall we? And thanks to you Udacity for hosting this. By the way, here we go.

Speaker 1:          04:41          So

Speaker 2:          04:42          yeah,

Speaker 1:          04:43          to do this, let's look at our data first. What is the data that we have? How do we, this is the Dataset that we have by the way. So the data set is a collection of test scores and amount of our study. So the x values are on the left hand side and those are the amount of hours studying. So right here, 53 a 61. These are the amount of our study and the y values are the test scores. Let's prove this relationship. That's our dataset. It's in a data dot CSV file. You can find it on my get hub. It is at the very top. It is the most recently updated code repository. It might be the description as well. Uh, I'm not sure if it's not. I would appreciate it if it is. So let's get it. Go ahead and get started with the code. So the first thing I'm going to do is I'm going to define the, let's see, the main function. I hope the code is, uh, it is visible for you guys. You guys are going to code. Yes. But what I want you to do is I want you to pull up an editor, a text editor, and I want you to code with me. So pull up sublime text, pull up Adam and start coding with me. Okay. So

Speaker 1:          05:52          let me get everything all set up here are great. So the first thing we're gonna do is we're going to say we're going to find our main function. And

Speaker 2:          06:01          okay,

Speaker 1:          06:02          it's just a standard thing. We always do this, don't we? Sometimes you just have to do things that you,

Speaker 1:          06:10          it's not really necessary, but we'll go ahead and write that out. So that's it for our main function. And now we're going to define the real main function, which is it our run function. This is the highest level. So let's define our steps here. The first thing we want to do, and this is what we do in machine learning, is we pull our Dataset, we parse our dataset into memory so that we can then run our algorithms on it. So the data set is going to be a collection of points on an x, y plane. So we're going to say Jen from text. And the way we even have this method available, Jen from taxed is by pulling from num Pi, which is, are very, are very much used machine learning library. Almost almost every, uh, machine learning repository is going to import num py in some way. And if it doesn't directly, it's going to happen under the hood. Num Pi is the matrix multiplication library for machine learning. Okay. Uh,

Speaker 1:          07:13          I have paid version of sublime. I'm working on a different laptop than mine. We had some issues, so, uh, I just, I just downloaded this version was flying it and don't worry about it. So what we're gonna do is we're going to say Jen from tax, I'm gonna make this a little smaller because this line is going to be kind of big. We're going to say data dot CSV. So that is our CSE file that we just, uh, used. And now I'm going to say delimiter. So this is just basic data parsing and this method is from num py by the way. And that star little symbol, it's a cow. Let's US pull it without having to say NP or num py every time. So let's get our delimiter value and that's going to be a comma. So the comma just means let's split it by the comma and the comma is what's in between these values.

Speaker 1:          07:56          If we were to look at it in terms of a raw txt file, there'll be a common with common between the hour study and the test scores. So it splits them both into, uh, uh, a set of points, x, y value pairs. So that's our, those are our points. Okay. And so the next part is the learning rate. The learning rates is going to be 0.01. What the hell is this? So learning rate is a hyper parameter. This is a hyper parameter. And hyper parameters in machine learning are what we use as tuning knobs for our model. So we have a bunch of these, and right now this is the only one we have. The learning rate defines how fast our model Lawrence. So you might be thinking, well, why don't we just set the learning rate to a million? Well, the reason is like all things in machine learning, it's a balance.

Speaker 1:          08:47          It's kind of like a bell curve. So, uh, if the learning rate is too low, our model will never converge. And if it's too high, then the model will, uh, take, sorry. If the learning rate is too low, our motto will be, uh, too slow to converge. Whereas if it's too high, our model will never converge. So we want that balance, that optimal learning rate. And in this case it's going to be 0.01 in general in machine learning, we don't always know off the top of our head what the best hyper parameters are going to be. So we have to guess and check now in the bleeding edge of machine learning and deep learning right now is to learn what those hyper parameters, uh, we'll be okay. So

Speaker 1:          09:33          that's it for that part. And let's just keep going here because we were on a roll. So that's our, our, that's it for our learning, right? And then we have our initial B value, which is going to be zero. And then we have our initial m value, which is going to be zero. What is this? Well, this is our y equals mx plus B function from, from Algebra. We have the slope formula, so that, so the B is our y intercept and the m is our slope. It is the, the ideal slope that we want. So we're going to start off with zero because we're going to learn these values over time. Right now it's just be an m there's zero, but we're going to learn them over time. So that's, that's our initial values for art. So this is the slope formula. That's it to start off with.

Speaker 1:          10:16          And now we have our number of iterations. So how many, how many iterations do we want to run our, uh, our training? Step Four. So we're going to say a thousand. Why a thousand? Well, because we have such a small data set. If the data set was bigger, then we would have to do 10,000 or 100,000 start incorporating gps and stuff like that. But we'll start off with just a thousand. Okay. So there is that. And now I want to print out the starting grow. Well, we'll forget the prince step. We don't really need that right now. Okay. So, so now we're going to say, uh, let's get those ideal bnm values. Let's get the ideal bnm values by using the gradient descent runner step. Now this is where the logic is going to happen, which we're going to define now, right? So this is the highest value. And then we're going to print out what, what be Nmr. So print, uh,

Speaker 1:          11:16          print B, and then print him depending on what the, the, those are going to be the optimal value. So this step is going to output the optimal values for each of them. So what we're going to feed it is we're going to feed everything we've just defined. We defined our points, we define that initial p value. We defined the initial m value, we defined the learning rate, we defined a number of iterations, we defined a couple of things. And so we're going to speed this all into the model. Okay? So that's it for the highest level. And okay, so now what we're gonna do is we're going to get into the gradient

Speaker 2:          11:54          descent runner step. So the gradient descent runner step is going to be defined now. Okay, so let's look at what this looks like. Given our values that we defined, which were the points and the starting be value and the starting value and the learning rate and the number of iterations. Okay, so let's do this. Okay, who's with me? We've got the B values. The B value to start off with is going to be what we gave it, which is zero and the m value as you can guess is also going to start off as zero. They'll both start off at zero. We've got to learn these things. This is machine learning. It's not machine define it statically, so for I in range number of iterations, which is which are a thousand we're going to say, well, let's get those values. Okay? Using something called the step gradient. Now that is where the real good stuff happens. That's where it's at. Okay? We're going to define that, but given what we start off with that B, which is zero in the m and the array of points, so we're going to take those points. The x y value pairs and feed it in as an array, we can convert that to an array by using this function array. And then the learning rates, which is a static value. It's a constant value. Okay?

Speaker 1:          13:17          All right. And I will answer questions in three minutes. So we have that for our learning rate and then we're once we're done with that. So for all of those iterations, once we have that, those optimal values for Bnm, we'll return them and then we can print them in that, that highest level function. Okay? So that's for bnm. That's our grading, the samp runner step. Now, now it's time to define this a step. Great in function. So now we're going to define the step radiant function. Step gradient is going to be we given the current B and given the current ham,

Speaker 2:          14:01          yeah.

Speaker 1:          14:02          Uh, we're going to give it the points and then the learning rates.

Speaker 2:          14:07          Okay,

Speaker 1:          14:11          so now we're going to define how gradient descent works. All of it is going to happen in this step, but before we do that, before we do that, let's write another function. So let's put this on hold for a second. We're going to get to this, but let's write another very important function. So we have two functions left in this code really, but it's the, the real meat of it is going to be explaining what they are. It's the step radiant and we have one more function, which is the compute error for given points function given B m and the points. So this, we're going to write this one first. Let's talk about what this is. Okay, so I have great visualization here and we're going to talk about what this is. So

Speaker 1:          15:00          when we start off with this slope, it's going to be zero, right? It's just a horizontal line. And then you see this is what's happening in the code. You see that it's going up like that. I love how the code is behind me. I can just do this. You see it going up. So how does it get up? Well, for us, what we want to do is we want to compute an error value. And what does that error value? How do we, it's a way of for us to estimate how bad our line is so we can update it every time, every step, every in machine learning, we call it time step, every time step. We want you to improve our model's prediction. And to do that we need an error die you in this. Sometimes they call it error. Sometimes they call it loss error loss. It means the same thing we went to minimize error. We want to minimize loss. And the way to do that is to compute what that error is. And depending on the use case, it could be different things. In this case, simple linear regression. We have a set of points we want to,

Speaker 1:          15:56          we want to uh,

Speaker 1:          15:59          define what that error is. So here's what it is we have, we start off with the line and we have a set of points. And what we want to do is we want to measure the distance between each of those points at a certain time step. So just imagine the line is static. So for each time step, the line is static. It doesn't move. We want to measure the distance from each point to the, um, to the line. So we want, it's called the sum of squared errors. Okay? So a sum of squared errors is the name of this. And so what this looks like is if we were to look at an image, it looks like this,

Speaker 1:          16:37          given some points, let's measure the distance from each of those points to the line that we have drawn and then square them and then sum them all together and then divide by the number. So it's divide by the total number of points. And that is our error value. And you can, and we want to minimize that error value. So just think about minimizing this error. How are we going to minimize it? That's the next step, gradient descent. But right now, this is how we calculate our error. This is how we calculate our air. And, uh,

Speaker 2:          17:11          okay,

Speaker 1:          17:11          so now let's, uh, take some questions for five minutes and then we're going to get back into the error value. Why am I so stupid? So let's stop this self deprecation. Okay. No one is stupid. It's just about who knows? These facts. These are static facts. Who has spent the time and energy to study this stuff. Okay. No self deprecation. You guys are awesome for even being here. This stuff is the most important stuff in the world. Okay.

Speaker 1:          17:48          Can we use machine to not for nonlinear equations? Yes. This is a linear equation but yes we can use it for non linear equations for very, very high dimensional data. Yes. 400 dimensional data but we will get there when we get there. Could you make the font smaller? Yes, I can do that. Okay. Two more questions and then we're going to get right back into computing this error value programmatically and mathematically could. Why is python better except for the object oriented programming? Python is as my friend who works on the tensorflow team at Google says the Lingua Franca of machine learning. It is the language and why is it? Well, there's a couple of reasons. One, it just had that headstart that people who were the first to to to do machine learning algorithms decided that they wanted to use python and we just kind of build from there.

Speaker 1:          18:41          That's one. Two is the amount of libraries that we now have four and three is because it's just a dope language. Python is awesome if you've coated in it for a while, you realize, wow, this, this does a lot of things that other languages should do in a lot less code. It's more efficient. And if you've come from a, uh, an ios background with objective C, if you've come from a c black background, a c plus plus background, we don't have to deal with deadlocks. We don't have to deal with memory leaks. All of this is done by our interpreter. And we can just focus on what matters, which is the algorithms. And so that's why python is used because we can focus on the algorithms. One more question. Can you make a video about different layers in a neural network? Uh, we'll see. We'll see.

Speaker 1:          19:26          I don't know exactly what you mean by that. That's why I said that. So, okay. So now let's get back to computing this error. So how do we compute this? So get ready for some math and I'm gonna explain what's happening here. So this is the error equation. Okay. So this is how we compute that sum of squared errors. So get ready for this. Okay, a little refresher on on this. This is, this is Algebra, okay? We have our y value, which is uh, the y value for a point, okay? And then we have minus mx plus B. Well, what is mx plus B? Will it just turns out that y equals mx plus B, right? So y equals mx plus B is the same. Mx Plus B is the same thing as y. So we have two points. We have the y point from our, uh, from the Dataset and then we have the wide point on our line and we want to minimize the distance between both of those points.

Speaker 1:          20:15          And so that's why we are subtracting them. So we subtract the point from our data set from the point on our line and then we square it. Well, why do we square it? Well, for two reasons. One is because, uh, we want the value to be positive. We don't want to have to deal with negative values. Why? Because we are going to summit in a second and two is because we don't actually care about the, the value itself, we just care about the magnitude from. So we're looking at it from a more abstract perspective. We just care about the magnitude of these values. We went to minimize magnitude. So that's going to give us odd that the, the difference between r a y intercepts and then little refresher on this e that means sigma, that's a, that's a notation for that is called sigma notation.

Speaker 1:          21:00          And what it does is it defines a set of values that we want to iterate over. So what we're saying here is for when I equals one up to n where n is the number of points. So for all of those points we went to uh, measure the squared error values for all of the points against our line. And then one over n means we want, you find the average of those and that's going to give us one value. And that one value is the error value. This, some of this squared errors. And every time step we want to minimize its value using gradient descent. Okay? Okay. So let's define this programmatically, the sum of the squared errors.

Speaker 1:          21:48          So we'll start off with error being zero. It's just there is no area we have to calculate it. So what we're gonna do is we're going to iteratively a compute this for every point that we have. Okay? So we're going to say four. I in range zero. So we start off with zero until bill. The, the ending point is the number of points we have. So that's the length of the points given those points. Okay? So for all the points, we're going to do this, we're going to compute the air. So get ready for this. We're going to programmatically in code or we're going to programmatically, uh, complete that math, that equation that we just saw. So we'll start off by saying, well, what are the x values? And we can find those x values by saying I where I is zero. So for the first column and in the, in our Dataset, and then, oh, sorry, in our array, right? Cause they're their points. And then we're going to say, well, what are our y values? Okay, for one, so x, y value. So right now we have one x value and one y value. And the four loop is because we're going to continuously do this every time.

Speaker 1:          23:02          So let's compute that total error. And so this line is going to represent that equation that we just saw. Okay? This is, this line will represent that equation programmatically. So we're going to say the total air value is going to be a why. Remember it's y minus. We can literally just word for or character by character. Say what this is going to look like m times x Plus B, okay. And then this means squared. So we're going to square that and then we're going to add it every time. And so that's the sum of the squared errors. And uh oh well this part is just going to give us the sum of the squared errors. And then we have to, we went to average it would that, that one over n that we had here, that's that next step. So once we have all of these, we'll divide it by the total number that we had. Return. Total error value to the, Oh yes. Thank you for saying that. I did miss an eye. You got it. Total error divided by float over length times points. Okay. It makes sense, doesn't it? Anthony, I appreciate you being here. Shout out to Anthony Cooper. Uh, okay. So, um,

Speaker 1:          24:31          we've got total error divided by float length might have won. So that's it. That's what we had. That's our computing error for our given points. Okay. Even God's make errors. Everybody makes errors.

Speaker 2:          24:42          Oh,

Speaker 1:          24:46          let's see. Let's see, let's see. Okay, so now, and I'll answer questions in six minutes. So every 15 minutes. So let's keep going here. That's it for our compute hair function. So where were we? We were in that last function and the most important function because it's talking about grading dissent. Listen Up, because this is going to be used almost every time when you're using deep neural networks all the time. No, this like the back of your hand grading dissent. Let's go, let's go tales. I got some, see, I got some of my homies in here at. Cool, so let's go with this. We've got gradient descent. Let's do this. So for B, gradient starts off at zero and a four m gradient. It's also a source of a zero. All right, before we even code this, let's explain what this is doing, what the word gradient means. Let's look at this. Not that. Let's look at this.

Speaker 1:          25:49          What is this? This is a very colorful rainbow period. Let's get back to this. No, I'm just kidding. What this is is it's a graph that shows three dimensions. The three dimensions are, and it's the same graph. It's just looking at these two images are the same graph. It's just looking at it from a different angle. So let's just focus on this one to not make it confusing. We're just looking at one graph right here and it's going to make the whole thing smaller because that's how math works. We have our y intercept, we have our slope, and we have our error. Okay. So what this is, it's, it's a graph of all the possible wine or steps, all the possible slopes and all the possible error values. So remember that era value that we calculated. And so if we were to map all of those triplets so they could, we can think of them as triplets of x are of slope y intercept and error value pairs, it would make this graph.

Speaker 1:          26:43          What we want to do is we want to find that point where the error is smallest. We want to find the point where the error is smallest. And if we look at this graph, we can see what that point is visually. It's going to be at the bottom of the curve. Now we call this in machine learning, the local minima. Now the reason we say local as opposed to nonlocal, uh, is because we have a very simple graph here. So sometimes there are many minimum and we want to find, um, which minimize. So that's that second order optimization. Right now we're focused on first order optimization. So let's find that smallest point because that smallest point at the very bottom of this graph is going to give us the ideal y intercept and slope. So if we find the minimum error, the minimal error, the smallest error possible, we'll also get the ideal y intercept and the ideal slope, the ideal bnm.

Speaker 1:          27:39          And what do we do with those ideal bnm values while we plugged them into our y equals mx plus B equation. And what happens when we plugged them into our y equals mx plus B equation. We get the line of best fit. Now I want to say, by the way, this is not the optimal way of doing linear regression. We could compute these bnm values. Uh, you think simple Algebra, uh, it doesn't really require us to do creating the descent. We're only doing this strategy because it's a way to learn gradient descent. There are easier ways to do this, but we want to do this the dope way. Okay? So that's what that is. And so we're going to compute this using grading dissent. Okay? So greatest sense. So that was the first part of the explanation. And so if the reason I show this graph is because the way we get that smallest point is by calculating what's called the gradient.

Speaker 1:          28:32          The gradient is also considered the slope. Okay? Not to be confused with the, uh, with the m value, we're talking about a slope in the direction of getting us to that gradient value. So we have some why value, we have some B value and we want to iteratively every iteration. We have a thousand iterations when it iteratively move our point where we are in space in this three dimensional space, down to that smallest point. And the way we do that is by calculating the gradients. And the gradient gives us a direction. It means slope, it means direction. And we need to talk about this for a second. This is important. Listen Up. So gray and values are used all over the place and machine learning. So I was talking to Ian Goodfellow, right? He's the guy who invented generative adversarial networks. And he was saying that some, some, uh, problems we can't do, we can't solve because we don't have the gradient.

Speaker 1:          29:26          So clearly gradients are used across machine learning. Sometimes in machine learning we call functions differentiable it, that's another word for, uh, can we compute the gradient from it using what's called a partial derivative. So to compute this gradient value a direction, it's a tangent line. Essentially a, a gradient descent is essentially a tangent line. It's going to give us a direction. Direction means positive or negative. Do we, do we move up, do we, do we move down? And so it gives us that line that, that direction that we want to move. And this is another example of, of grading dissent. It's essentially a bowl like curve, a bowl I curve. And this is also

Speaker 2:          30:10          okay,

Speaker 1:          30:10          an example of

Speaker 1:          30:16          bad internet connection or bad a server. So this would probably be better. So, so yeah, it's a bowl. It's a bowl. We could think of this entire process as a bowl and the ball are, our x are the points that we are, that we have, whether that be the slope or the y intercept and an even more complex problems. The features and the numbers and the words for natural language processing. It's all abstracted to a bowl like problem where we are trying to find the optimal point for that bowl. It's going to give us to optimal values that we need to make our model amazing. Okay, amazing. Slash. Optimal. Should we go up? Should we go down? That's what the gradient gives us. And to calculate that gradient. And let me say this, let's last thing and then we're going to get right into the code to calculate that gradient. We're going to compute what's called the partial derivative in calculus with respect to our values and our values, our B, and m. So this is the equation for the partial derivative. Okay? For that that we're going to, we're going to take this, these equations, these two equations, and we're going to programmatically encode them. No, this is the last part, but it's also the most important part because that is gradient descent. So we start off with why minus mx plus B, which is why, okay. And we compute the partial derivative. So what that means is we differentiate, uh, this is from calculus. So we take the V, the value, whatever it is. So little refresher. So if we have, um,

Speaker 1:          31:54          let me just write this out actually. So if we had an equation that was x squared, what is a derivative of this? We take the exponent, this is a two, and we move it to the, uh, in front of the variable. So it'd be two X. Okay. So that's a driven it, but we are calculating the partial derivative with respect to B and m. So what does that, what do you mean by partial? By partial, I mean we're only using, uh, the values that we, uh, we're calculating a derivative using only B, and then we're calculating a respective or a different partial derivative using just m. Okay. So let's, so this little symbol over here, this little squiggly just means partial may play. Find the squiggly. Okay. And then let me also answer some questions cause I think it's time to answer some question. This, this little squiggly means partial derivative. Okay. So it's going to make a lot more sense when we, uh, and code code this programmatically. If, if, if you aren't as familiar with the math terms. So questions. Okay. Why are there two equations? There are two equations because we are Tau collating respected derivatives for both B and. M. Those are the two values that we are trying to find and we're going to look at this programmatically. So two more questions and then we're going to code this last step.

Speaker 1:          33:22          Nice. So gray and sent helps us to put rainbows at the, okay. Hey that's not okay.

Speaker 1:          33:31          Exactly. Best use of time and money. Will there always be one low point in the error function? We can work to using gradient descent when we have a linear function? Yes, because it is our local minima but sometimes we have very, very complex data. We have data that has hundreds of features. We have data that is unlabeled. We have data that uh, we don't, sometimes we run unsupervised algorithms. That means, uh, algorithms that the delay, the data is not labeled and we try to find something from it. So sometimes it clusters in certain points and we say, oh, this cluster there, there must be some relationship here in, in, in more complex cases. No. In more complex cases. There are, um, there are, there could be low there, there could be several local minima and uh, we want to find the ideal one, but we'll get to that. Right? It's, it's just another set up. We want to learn where to do gradient descent and that's, that's later steps. Um, one more question to start off with ml and AI, do you recommend starting with the Mln d followed by note? Are there

Speaker 1:          34:47          why the gradient gives the minimum that that is a mathematical question? Yes. So why does the gradient give the minimum? Because it doesn't give us the minimum to start off with the gradient. Just skip tells us how to update our value. Should we update them with a positive? Should we update them with a negative? Should we multiply them by, you know, how do we modify our values to make them closer and closer to the optimal values where the error is the smallest and once we're finally there, that is our minimum. Okay. It doesn't directly give us a minimal, all it does is it gives us a direction to minimize our error or loss. Okay. If we can compute a gradient. So that mean if a function is differentiable, then we know that we can optimize it. So let's write this out. Let's write out this step grading function. Okay? So we are, so we, we, we call this function in our grading dissent runner. Recall that we were weak, we called it right here, given the B m points and learning rates. So now we're going to ride this out. You have are, okay, so let me make this a little smaller so we can really see what's going on here. And uh,

Speaker 1:          36:18          zero m equals m gradient equals zero n equals float length points.

Speaker 2:          36:29          Okay?

Speaker 1:          36:30          These are our initial gradient values for B for further be great and the embryo and we're going to update them over time and it's going to be the number of points. Okay? That's just the number of points. And now we're going to calculate the gradient steps. So, uh, okay. So for each of the points, we're getting great and values for each of the points and we're going to put them all together and it's gonna give us one, uh, uh, optimal bnm for each time step or a more optimal bnm had each time separate member. This alone isn't going to do it. We have to iteratively do it. And that's what we did beforehand. Yes. Oh, you're right. Yes you are right. Yes. Oh guys, you, you got me. I already defined it over here. That's what's up.

Speaker 1:          37:22          I did define it here. Yes. Great. Where was I moved down there. There we go. Okay, so a grain of sand runner. And then we have the yes, the plot points and the n value is the number of points. Okay. So now let's, uh, we're going to iterate through all of those points that we just defined, right? The points, the length of the points, and then, uh, so for each of those x and y. Dot. U Paris. So for points where I is zero, where y is not where I is, zero for each of those. X, Y, Paris, hi one.

Speaker 1:          38:13          Let's calculate the gradient. So how do we do that? Well, let me look back at this equation and see what that was is, okay? So what we're doing here to calculate this gradient or this partial derivative, okay? A is what we are doing is we are going to take y mx plus B and then multiply it by the x value. Okay? Um, and then at a negative sign and then do that for every point and then multiply it by two over the number of points. Okay? We can do that. Let's do that. Remember, these are laws. They are constant. The partial derivative is the same every time. It is a law is a fundamental law. It is a beautiful law because it's always the same. It is predictable and predictability is great sometimes when you need it to be. So let's calculate that value native to end. That's what we had negative two over n times. Why? Remember, we are just writing it out just like we just saw it in the equation. It's the same thing. Am current times x

Speaker 1:          39:42          Plus B, current y minus mx plus B times two over the end. Uh, negative. And then we're continuously adding that. Right? So that's it for our grading for B, that's going to give us a direction, aren't positive or negative that we should update via. Okay. And then we want to do the same thing for em. So in fact, I'll just paste it because it's very similar, but it's a little different and I'll, I'll show why it makes you, make sure you guys can see it all. For our m gradient, it's going to be negative two n times x Times y minus m current times x Plus B current. Yes. Okay. So we're doing this for every point and we're going to see, we're going to concatenate all of those values together using this plus equals function to get that, uh, be gradient in the m gradient. Okay. And so once we have those values, we're going to use them. Now it's time to use those values.

Speaker 2:          40:52          Okay.

Speaker 1:          40:52          To use those values, we're going to update the real bnm values using them. And how do we, how do we use them? All we say for let's say for B for example, we take what we have currently for B, whatever it is at every step, because we're running this every time, step, every of a thousand minus the learning rate times the B gradient. This is why we define our learning rates because we multiply it by the gradient and it's going to, uh, it's going to convert it into a value that we can then, uh, it can either make it convergence slower, it could never converge, but this learning rate is going to give us, uh, a good a convergence, uh, uh, rate of convergence is gonna give us a good rate of convergence. And then we have the new M, which is going to be m current, same deal, minus the learning rates. And I'll answer questions in four minutes. So keep them ready, times the gradients return, and then we'll return them

Speaker 2:          42:10          just like that. Okay.

Speaker 1:          42:12          So what did we just do here? Let me answer some questions. Oh, okay. I it is the learning rate. It is the same thing. I just defined it differently in the, uh, the step. Okay. So, yeah, so that's for our gradient.

Speaker 1:          42:49          Okay. Can you please explain again why we are doing Newbie and knew him? So we had an initial bnm right. Those words zero value, they were to zero, we had nothing. We want it to update them using the gradient. So the gradient will tell us how should we update them. Should it should be be zero, should be one, should it be negative one should be be 0.5. The gradient is a value that we uh, use to update the BNN value, the initial bnm value to get the new bnm value. To do that, we're going to calculate the partial derivative with respect to B and respect to m, which are these two respective lines right here given all of our points. Okay. Given all of these points were calculating, that will sum them all up and then we'll multiply it by the learning rate and subtract that from what we have currently. And that's going to give us our new bnm values.

Speaker 1:          43:49          Okay. So can you explain why do you multiply the learning rate times the gradient? Again, what's that value? So, okay, so the learning rate, if we, so in a Dataset this small with only a thousand data points, we don't really need a learning rate more or less. I mean we don't really, our model is going to converge. This is just good practice to always think about a learning rate because we use learning rates in deep learning, right? We use them in deep neural networks. It's about a balance. You'll find that all of this stuff is all about a balance time versus computing. If a power versus efficiency versus amount of code, it's always a balance I'll learning rate does is we are predefining how fast we want our model to train. And if we do it too fast then we'll never converge. That means we'll never, going to convergence means finding the optimal, uh, values for our function.

Speaker 1:          44:45          Whatever it is. If we do it too slow, then it will be too slow to converge. So it's about time and balance. We've set 0.0001 for our learning right here, statically ourselves manually. But you know, ideally we can learn what that value is. The part where we sum it all up. This is the last question someone asks, what is the part where we sum it all up? Is it in the four loop? Uh, yes, it is in the for loop. We are summing it all up right here. Plus equals. We're summing it all up. Okay, so, so yeah. So yeah, let's run this code. That's it for the code. Actually let's run this thing. We've got python hundred percent is going to be an error.

Speaker 2:          45:29          Okay. Of course.

Speaker 1:          45:32          If name

Speaker 2:          45:37          hold on.

Speaker 1:          45:45          Oh yes. Two equal signs because that's how we roll in Python. What are you talking about here? Deep learning is a subset of machine learning. You are correct. It is a subset. And what we have here is a space that, there we go. Okay. So let's get to questions.

Speaker 2:          46:25          Oh my God. Wow.

Speaker 1:          46:27          Oh, you know what it is is because does this computer, so I'm using a new computer by the way, so it might not num Pi might not be installed. We can install with pit. Oh my God. Okay, so here's what it is. Here's what it is. So let me look back at this. What does that, so I actually don't have an empire and so on this computer I'm using a different computer. This was a last minute thing. Don't worry about it. The code works. I just come, I had a compiled earlier. Look at the values here. Uh, we've got the ideal after a thousand iterations, B m and D, error value. This happens in milliseconds because we have such a small data set. And also, um, no, no, no. Actually I do have num py. Nevermind. I, cause I just compiled it. What am I thinking? Hold on. So let's see what we've got here.

Speaker 2:          47:42          Okay.

Speaker 1:          47:43          I'm going to do some debugging because we've got some time. So why not? Let's, let's debug Jen from tax is not defined because we've defined it. Right.

Speaker 2:          48:08          Interesting.

Speaker 1:          48:14          Also, this is the, this is the code that I'm, that I'm reading it from. There it is. Okay. So there it is. So I'm actually curious what, what the error was or was it, it was Jen from text, but it wasn't defined because, because, oh, I misspelled it. That's why de, okay. Anyway, it's because I misspelled it. Uh, but yes, I misspelled the gen from text, so I've heard a thousand iterations. We get the ideal be we get the ideal and values both of them and we can plug them into our equation and it's going to give us the optimal line of best fit for our values, which we can then use to make a prediction given a test score or given a right. That's what's up. Yes. That's what it was. Jen from txt, not Jen from t e x. T. That's, that's exactly what it was. Thank you. Okay. Can't confirmed Illuminati confirmed. So questions, any questions guys? This is going to give us the, this is that. This is what this code is going to do right here. Exactly right. When, when it's all about winning. Okay, so we've got any questions? How many people do we have in here? We have a good number to 42 that's a good number. Okay. Single closed set of double how to use the momentum technique in order to find not only the local minima momentum is something that,

Speaker 2:          50:17          okay,

Speaker 1:          50:19          we don't really use in linear regression. We use that for a nonlinear models with high dimensional data. We'll talk that later. Uh, can we use a dynamic learning rate? That's a great question. Yes. Actually. Um, if the learning rate adapts, ideally, that's honestly, that's I get, that is what we should do. We should have a dynamic learning rate. We should not not just have a dynamic learning rate. We should have dynamic. All of our hyper parameters be dynamic and they're all learning in real time and responding to feedback and optimizing themselves. This is actually, um, what's like on the bleeding edge of machine learning right now. How do we learn to learn? So it's kind of like a metal learning. Three more questions and then we're out of here. Is it possible to overshoot the minimum? Yes. And so that's why we have a learning rate so we don't overshoot it. Um, for larger datasets, yes, we can absolutely overshoot our minimum. Our model could just be training forever and never converge to more. Are you going to implement Lstm from scratch? Uh, yeah. I actually have a video where I do that. It is a generates Wikipedia articles. Check that out. And then one more question.

Speaker 1:          51:32          How large can our dataset be with this technique? What if we had billions of data points, uh, with this technique? This, okay, so this technique will scale this. We'll scale, uh, and it's a linear, no pun intended, relationship to the amount of data that you have. So the more data, the longer the training time, but this will work for larger datasets that, that, that are linear. So that means that there's, you know, an x, y value pair, two values, uh, that you want to find the optimal form. Okay, I'll take one more question.

Speaker 1:          52:11          Is the feedback related to backpropagation? This is not backpropagation. So backpropagation is a form of gradient descent. This is not backpropagation. This is gradient descent for linear aggression. If we take gradient descent and apply it to deep neural networks, that's when it becomes backpropagation. So grading dissent is the big is a big boy. And then backpropagation is an implementation of grading the scent where we are descending or gradient by propagating an error backwards across all of our layers. So we go forwards and then we go backwards. That's it for the questions. Thanks guys for showing up and for learning this stuff. This is the good stuff. Okay. It's only going to get better. It's only going to be a cooler from here on out. Okay. So for everything that you learn, moving on from this is going to be awesome. So thanks guys for showing up. Uh, for now, I've got to go descend my own gradients in life, so thanks for watching.