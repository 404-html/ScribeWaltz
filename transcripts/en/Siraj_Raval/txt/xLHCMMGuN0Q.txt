Speaker 1:          00:00          Hello world, it's Saroj. And today we're going to be talking about evolutionary algorithms in the context of building a tetris AI. So I've only made one video on evolutionary algorithms ever and it was like three months ago. So I'm really excited to make this video. We're going to use evolution, we're going to use an evolutionary approach to build a tetris AI. And this is going to be using javascript. I know javascript for once. So, uh, let's get started. And you might be asking why javascript? Well, the reason is, well, two reasons. One, javascript is the language of the web. It's not going anywhere. It is a very messy language. It's a beast. People are always tacking on different components to it. Uh, but regardless, it is the language of the web. And second of all, why not? Because we, I want to see more machine learning happening in the browser.

Speaker 1:          00:47          And yes, we could make a python shell and then call it from some front end, you know, like, uh, angular or something. But to do it all in Java script just seems cleaner. And even Andre Car Pafi has made a javascript library called called comnet dot. Js. So let's just do some javascript and just see what it's like. If you've never done javascript before, that's okay. The code is totally readable. It's in the description. And I've made sure to comment every single line of code so it's very readable. So don't even worry if you've never done javascript before cause this is going to be awesome. And plus it's more visual. See like we could see it in the browser right now. We can compile it as we go and see the changes we make. Uh, but yeah, anyway, so that's what we're going to build. And this is the little demo that you see here of what we're going to build.

Speaker 1:          01:31          Okay. So, um, so I'm going to start off with a presentation and the presentation is in an Ip phone notebook, not that we're using python. I just, I think it's a good format to talk about what we're going to do. Okay. So, uh, we're gonna be building an evolutionary algorithm for tetris. So the code in total is like a thousand lines of Java script. So it's like a lot of javascript. We're not going to be coding at all in this video. What we will do is we'll code the first 100 lines and the first 100 lines constitute the highest level approach. So the initialization function, and we're going to call all the help, all the helper methods inside of that initial 100 lines. So you'll be, you'll get to see exactly what the structure of the high level architecture is and a very dense amount of code.

Speaker 1:          02:14          And then we'll talk about the helper functions. Okay? So get ready for this. Uh, but we're going to go over all one, 1000 lines. So what is, what are evolutionary algorithms? So one thing I want to clarify is that evolutionary, it means genetic. They're the same thing. Evolutionary Algorithms, genetic algorithms, they're the same thing. And there are three parts to an evolutionary algorithm. There's selection, crossover, and mutation. So the idea is to replicate Darwinian evolution, evolutionary algorithms, right? Evolutionary Algorithms are based on Darwinian evolution. And just like in Darwinian evolution, we have a population and the population breeds and only the fittest survive. So let's talk about that a little more in detail. So for one step one is called selection. So what happens is we create a population of genomes and genomes, they're also called chromosomes sometimes, but I like to call them genomes. Genomes can be anything.

Speaker 1:          03:10          There are some entity that you want to improve over time. So let's say we were creating some kind of like three d simulation, uh, and we wanted to create a bipedal robot. Let's, we would probably have a bunch of like bipedal spiders or you know, quadro Quadro peds or whatever they're called. But we would have a lot of them and they would be our genomes because we want them to improve, to breed and improve over time. And the, the idea is that each genome has multiple genes and the genes are akin to parameters. They mean the same thing. Each genome has a set of genes or parameters. And what happens is we use a fitness function to select what the best ones are. And so the fitness function can be whatever we decide, you know, it could be like whoever is able to walk for a certain threshold, like let's let's say two meters, if you, if you can walk past two meters, you get to breed.

Speaker 1:          04:02          Congrats. Congratulations. So something like that, right? And that's the selection part. We select through a fitness function who is fit to breathe. And once we get done with selection and we move on to step two and step two is crossover. It's a crossover means reproduction. So the fittest, uh, genomes get to reproduce and reproduction can mean different things. But we have some sort of a merging computation that mean that is a kin to reproduction. So it could be like we take both of those winning spiders or the ones that are fittest and then we, we vectorize them or turn them, find some way to convert them into a scaler and then take those two scalers and multiply them together. And then we get some output scaler and an output scaler. And then from that scalar we reverted back into a, like a three d spider.

Speaker 1:          04:49          You know what I mean? So it's, it's, it's breeding and we'll, we'll talk about what this crossover function is, but it's entirely application dependence and that's going to create a set of offspring and the offspring are the next generation there. There are a new population and once we have these set of offspring, when the fittest genomes breed, then we performed the last step and the last step is mutation and mutation is just randomly editing the genes or parameters in some way in the hope of creating more beneficial features in the future. So we have a set of genomes, they try out whatever the task is, the objective and the fittest ones that are defined by a fitness function get to breed. And then which just crossover and then we take that new population and we mutate it using some mutation function, which could just be, it could just be like multiplying the scaler by a random value or something.

Speaker 1:          05:45          And then we just continue that process. So this is a map of what it looks like, right? We initialize a population and then of genomes we performed selection, crossover, and then you mutate them and then we repeat the process for as many generations as we want or as many generations as it takes to reach the objective, whatever that objective is. And so you might be asking, well why haven't we been using this? Right? Evolution is all its nature. We should be using this more often. Well, let me talk about why we don't use this more often. So one use case is neuro evolution, right? So neuro evolution is this really cool idea. And this, this game is a great example of it. But the idea is that we have a neural network, right? Like always, we have a neural network and it's, it's up to, it's optimizing for an objective function.

Speaker 1:          06:32          And in this case, in the case of Super Mario, this is an example of neural evolution. The, the idea is to, the objective is to beat the game and the shortest amount of time, like minimizing the time spent for a lap is the objective function. And we use an a neural network to do that. And so normally we would use backpropagation to find the optimal weight values, right? But we could also use neural evolution so we could think of the weight values as genomes. And then we performed the whole evolutionary process instead of back propagating where we take some input data, we propagate it through each layer, and then we have an output value, and then we take that output value and then we have our expected value. Hopefully it's labeled data, and then we find a difference between the two to get an error value.

Speaker 1:          07:18          And then we use that error value to calculate the partial derivative with respect to each layer going backwards and then multiply it by the weights to update our network instead of doing that. That's the, that's the normal way with backpropagation. Instead of doing that, we use an evolutionary algorithm so that we evolve the weights through crossover and mutation. And so why you might be asking which one is better. So in most cases, in most cases, backpropagation is still the most popular. It's still given the best results, but evolutionary algorithms are promising. I mean, they've been around since the 80s right? It's not like, it's not like there's something new. They, I mean it's a very intuitive idea, but they can give really good results intuitively speaking. Like I feel like they can, and open AI released a paper recently, um, what was it called? But it was about like evolutionary algorithms for open AI evolutionary algorithms.

Speaker 1:          08:17          But it was a cool paper evolution strategies as a scalable alternative to reinforcement learning. That is the one. So definitely check out that blog post if you want to learn more about a evolutionary algorithms. I mean, I'm going to be talking about it in this video, but that's another, that's another resource to check out. Um, but anyway, the thing is gradient descent is great at optimizing a neural networks, but sometimes grading dissent doesn't converge to the global minimum. It converges to the local Minima, which is like, if, if we consider like the optimization options as a, uh, you know, like a very bendy curve, it will find the local minimum instead of the global minimum, which means the actual lowest points. And so as a search strategy, it could sometimes be beat by evolutionary algorithms. But we, I just haven't seen it very compelling use case for it.

Speaker 1:          09:04          But there is promise. I think it's a great technique and I think as we not, I think as we improve our algorithms, we will see evolutionary algorithms play more into machine learning in general. That's what, that's what, that's what I believe will happen. So and, and also like, uh, there, there are also able to discover entire neural networks. So instead of just discovering the hyper parameters, it would discover the entire neural network. What do I mean? So you know how we have like multiple neural networks like neural networks, zoos, and each of these networks is optimized for a different use case, right? Some networks are used for feet up for time series data and then some networks are used for scalar data. Some networks are used for binary data and we have so many different types of networks. What if we could learn what the optimal neural network architecture is for a use case?

Speaker 1:          09:53          And so this is a great example of when evolutionary algorithms would be great. And this is what something that backpack, verdict backpropagation can't do. Backpropagation is about optimizing a single neural network. But evolutionary algorithms can, can optimize for the entire type of neural networks. So a lot of promise there. Okay, so enough about that. So what is it in the context of Tetris? Because then the contents of Tetris, this is how it works. We initialize a population of 50 genomes. Okay? So what our genomes in our case, so notice right here, let me make this bigger. So 50 genomes in our case are these, hold on. These values right here, not all. They see like these seven values right here in these brackets. So these are weights values, okay? And we'll talk about what each of them mean. But these, this set of weights is our single genome.

Speaker 1:          10:44          That's what we consider a genome. A genome isn't an AI like a Bot. A genome isn't a block that's falling. A genome is this set of weight values that we improve over time, that the, that the agent that the AI uses to decide how to play the game. So the agent makes decisions based on these values based on this genome value. And if we can improve that genome value, these wait values of and over time and these values tell the AI where to move, then we're going to have some interesting results, right? So we initialize a population of 50 of these, right? 50 of these sets of values, these seven parameter values, and it was right. So each of them, each genome has seven parameter values. Our Ai will make a move based on them and so it's going to try out all the possible moves based on each genome and the current population to make a single move.

Speaker 1:          11:34          So each genome is going to help the AI make a bunch of possible moves and it's going to pick the absolute best one for that genome using some, uh, value or measure that we decide that I'll show you. And then it'll keep doing that and then the best genomes will evolve. So we'll take both sets of parameters and we'll combine them through some processed crossover that we'll talk about and we'll create a new set of genomes and we'll keep going until we get our AI to get to the high score of 500. Okay. And this, this has been running for a while, so we're already up there and we could speed this up as well. But, um, that's the idea. And so in terms of Tetris, I'm hoping you know how to play Tetris. You probably do, but each time a block moves down, the is incremented by one and when a row is cleared, what do I mean by cleared?

Speaker 1:          12:20          Like when all of the values like going across from left to right are filled, then that row disappears. And then we get, we gain a certain amount right to the score. So there's two ways to gain points. One is to, uh, make the block move down without reaching the ceiling. And the second is to have a row clear and the goal is to get to 500 without the blocks stacking up over the ceiling. And the ceiling is this top row up here. Okay? So that's the basic idea. So let's go ahead and, uh, right out the first part of this code. Okay. So we're going to write out the high level code and then I'm going to talk about the helper functions. Because we've got about a thousand lines of Java script to get through. So let's get started. Okay. So, um, the first step is for us to create a 10 by 20 grid, right?

Speaker 1:          13:01          That grid that you saw right here, we want to create decorative, so right, it's just a, it's just a matrix. Create a 10 by 20 grid, create the game grid, which is 10 by 20. And let me make this bigger. Uh, there we go. All right. And so let me pay status cause it's quite a lot. Okay. So here we have our grid and our grid is that 10 by 20 matrix that we just saw. That's our game grid. And then we're going to define what our block shapes look like. There's, there's an eye shaped block, there's a j shape, there's an l shaped block, right? What are these blockchain is going to be and we define them as a set of, um, nested arrays, right? And these are basically, these are coordinates on the grid that we want to fill and notice how this is how it looks like.

Speaker 1:          13:45          Right? Right. So one is like a, you know, like just straight across. And then one is like a z. One is like an l, but it's rotated, right? So these are, these are our block shapes that we defined. So we defined our grid, then we define our block shapes, and then we define our block colors. So, and these are just a hex values, hexadecimal values that define the color code, right? Good old javascript. So those are our initial function. So let's keep on writing them. We have, we have quite a few, uh, global variables here to it to write out. But, uh, we want to seed our, um, we want to seed our code so that it's reproducible. And this is four d. This makes our code deterministic. What does this mean? This means that we're going to have a lot of randomness in our code, like we're going to call the random function, uh, quite a bit.

Speaker 1:          14:29          And what this means is that whenever we compile the game over and over again, it's going to start off from the same point. So the generated values, the randomly generated values are going to be the same every time. And that's good because we want to debug our code and we want to make sure that we have certain values. So it's good for debugging. That's what we see at our code. We do that a lot in machine learning in general. So now we're going to define a set of parameters and these perimeters are going to be the block shapes. Let me just write that out in all caps. Block shapes, block shapes. Okay, so what are these block shapes? So we want our current shape, we want to keep track of the current block that we're on. So we'll say well for its x value is going to be zero and then it's why value is going to be zero.

Speaker 1:          15:11          So these are its initial coordinates that we're going to update over time and then we have its shape, which is going to be undefined that we're going to update as well. Right? Like which, which of these, you know, Ij l is, is it going to be, and then we have our upcoming shape. So we have our current shape and then we want our upcoming shape. We want our AI to know what's coming up. Okay. And so where are we going to store all of these blocks? What we're going to create what's called a bag. We'll just call it a bag, but it's going to store all of the upcoming shapes or blocks, whatever you want to call it, shapes, block, same thing. Uh, we'll store both of them. So we have that. And then, uh, once we have that will define an index. So this is going to define where we are in the bag.

Speaker 1:          15:52          Like what, what position block are we or shape are we using? And then, yeah, that's it for our block shapes. And now we can define our next set of parameters, which are the game values and the game values are going to be, are going to our more global there. They're going to be used throughout the code they're going to use throughout the code. Uh, we're going to use him quite frequently. So that's why I called him gain values. Okay. So, uh, we'll start off with the score. That's the most obvious one. What is the score that we want to keep? Remember we want to reach 500 and then we're going to start off with a speed for the game so we can actually change the speed of the game through. Like by doing this, like check this out. I can toggle the speed by saying speed up.

Speaker 1:          16:34          Is He? So he see how it speeds up and like it slowed down again. That was my sound effect for speed. Okay. So then we slid back down again. But um, yeah, that's the idea for the speed. We can increase it or decrease it. And then we have our, a boolean like do we want to even change the speed? Like what's the deal here? And I'm going to say, well let's, let's keep it false at first. We don't want to change the speed right now and then we want us to save the state of the game, right? So what is the, this, the state of the game and the state of the game. We're gonna use that. So as a, as a way to save it and then reload it later. If we want to our genomes, wherever we are. In a way it's kind of like model checkpoints, right?

Speaker 1:          17:11          In tensorflow. So we want to save the state of the game and then we want to store the current state of the game. Right? So we have a safe state and then a current state which we'll call the round states. Okay. And then what else do we got here? So we have our speed index. So we have a speed array of of values. Like, cause we're going to have several speeds like preset speeds. It's not like it's some kind of like counter where we can just like, you know, like increment by like intervals of one. It's going to be like 400, 500, 1,015 hundred like force feed values. So we have an index and the speed value array that we're just going to sit here and we'll set it to zero. And then we have our, uh, what else, what else do we have here? We have our speeds, we have our stuff right? And so this should be an array. What am I, what am I thinking? This should be a set of values. It'd be 500, one and zero. Okay. And then we have those. And so now it's took time to define our AI as in do we want an AI or not? So we'll say yes, we want an AI because we could turn the AI off and then we could just play like that. See, like, check this out. Hold on.

Speaker 1:          18:23          Uh, where was I? Toggle. AIA, right? And then I could just play instead of the Ai, but I'm not going to do that anyway. All right, so it's going crazy. Okay. So then we have our AI and then we have a draw. A boolean was, which says, do we want to draw the game or do we want to update the algorithm? We can do one or the other. And so this, this is a boolean for like letting our algorithm know when to do that. And then how many moves do we want to take? Uh, like do we want to take, we want to keep track of how many moves we've taken so far so that we can take our next set of moves. Okay. And then what we want to limit of moves. So we don't write the, the limit that we're going to set is 500, just because, uh, more than that is going to definitely, uh, don't over the ceiling.

Speaker 1:          19:08          Okay. Or ideally for efficiency's sake, we can limit it like officially like this, so that it's going to optimize for that 500 number. Like that score by doing 500 moves or less, which would be ideal, right? You don't want to do be having do it in like a thousand moves or less. You want it to do it in a 500 or less. So we have that and then we have our, uh, move algorithm and our move algorithm is going to say it's going to consist of the seven move parameters, which are those values in the genome, right? Those seven parameters that we're going to talk about, what, like what each of those are. So, uh, so we have that. And then, uh, we're going to inspect, move selection. Uh, so this is just, you know, a Boolean for whether or not we want to inspect which moves we're going to play next.

Speaker 1:          19:55          So this is going to be set to true pretty much all the time. And in fact, we don't actually even need this value. We could just have the true always. But anyway, uh, yeah, so that's it for that. And so we have one more set of values, which are the genetic algorithm values. These are the actual like evolutionary value. Let me just say, it's evolutionary to keep it, uh, keep the terms straight. Okay. So w so in terms of, in terms of evolutionary algorithms, we have a population which we're going to say 50, let's just say 50 genomes to start off with. And once we have that, we'll say, well, let's store our genomes in and right then, right? So we'll, we'll initialize that array that we want to store our genomes in and then we'll get, we'll keep track of where we are currently.

Speaker 1:          20:34          What is the current genome that we're focusing on? And we're going to say a one which is the first index or you know, not one, but negative one, which is the index we want to start off with and we're going to, we're going to iterate through that genome array as we try out different things. So, right. What else? We've got a generation and what's the first generation called? It's the Zeroth generation, right? It's the zero with generation. And then we want an archive. So this is, uh, this is for us to store. What are values are for each generation. And what we're going to do is we're going to use JavaScript's built in local storage function, which is supreme. What useful and what local storage does is it allows us to store some set of values in a short term memory and Ram, right? Which is amazing because it's just super useful. Like we don't have to use a database, we can just store it in memory. And that's super useful. Not computationally expensive. We'll have a set of elites, which are the, uh, which are the genomes that we selected to reproduce. And then we have all of our genome. So we want to keep track of boats. So what are the elite genomes like the fittest ones that we define and then what are the, um,

Speaker 2:          21:53          what

Speaker 1:          21:54          are the

Speaker 1:          21:58          general genomes like all of them. Okay. So we have that and then two more, two more parameters and then we're good to go. So we have our genomes, we have our population digital to make sure I typed that. All right. And so then we have our mutation rates. So this is going to be our value that we use to mutate the children. And we're going to say 0.05 and we can tune this just like we would hyper parameters in a neural network. We can tune this to make it better, but we'll start off with 0.05, right? It's kind of like the learning rate, right? When it comes to backpropagation. Uh, but this is the mutation rate. The, the similarity is definitely there. And then we have a mutation step, which is going to also, it's kind of like, um, momentum in this case, but what is the race that we want to mutate?

Speaker 1:          22:36          And then the step is, uh, what is the interval that we want to apply that mutation rate too. You'll see what I mean when I, when we look at the code for this. But okay, that's it. That's it for our global variables. That's a lot. I know, right? It's a, it's quite a lot of global variables, but hey, it's javascript and a welcome to js world. So let's go ahead and write out our first function. So this is the highest level function. So this is what I was talking about when I was saying that we're going to write out the highest level part and then we'll talk about the helper functions, right? So it's all going to happen in this initialized function. All the, all the, uh, high level magic. So the first part is for us to initialize our population size. So assuming that we have it in our archive, like in local memory, which we do, we'll say like, okay, let's start, let's, well, we're going to store it in the archive.

Speaker 1:          23:23          We're going to store the population size 50 in our local memory, which is the archive that we defined here. So that's our first part is initializes the population size. And then we want to get a shape, right? So we'll say next shape. So this function is going to give us the next shape from the bag that we have of what is the next shape that we want the AI to play. So we have our next shape and then we want to apply that shape to the grid. So we have that shape, which is an l or oh or whatever. And we want to apply it to the grave. But, and what do I, what do I mean by apply? We want to, we want to stick it in the grid so it stays in one place, right? When it falls down and then it, it becomes a part of the grid, right?

Speaker 1:          23:58          So we have that and that's what applies shape does. So we've initialize our population goddess shape, applied into the grid, and then we want to save where we are. So we'll say, let's save where we are by using the gets state function to get our, our safe state, which are those values, those, uh, those genome values. And then we want our current state as well. So we'll get both using these getter functions, get state. And so we'll have to uh, clones. These are clones in the same state. One we'll save and then one we'll set to our current state. And then we'll go ahead and create the initial population. We've defined our initial parameters. So now we can just create what that initial population will be. And then we can define the game loop. So we created our initial population of genomes, 50 genomes, which are randomly generated values for these seven weights.

Speaker 1:          24:48          And then we can, uh, start up, go ahead and start the game loop. So the game loop, we'll, we'll call it loop is going to be a nested function. And this is where the, this is where the actual, you know, the, the logic happens. So then for the logic will say, okay, so let's say, let's see if someone said changed speed, that which of the bullying, if someone wanted to change the speed, we'll go ahead and do that for them. And the way we'll do that is to use JavaScript's built in functions. So it's clear interval, given an interval value, it's going to clear the, the, the timers. We have a game timer and we want to clear it. And once we do that, then we can say, okay, so the new interval is going to be set interval given our loop and it's given speed.

Speaker 1:          25:29          This is going to go some new timer. Let's go ahead and say change interval equals false. So we don't change it. So we stopped at a time and then we don't change it here. Okay? So that, that's the first, uh, if statement. So we have one more if statement. So we say if speed equals zero. So if there is no speed, so the game has stopped, we need to say, well, don't draw anything. I mean we, we stopped the game, so there's no need to draw anything, right? So we say dry equals false. And then we say, now it's time to update the game, right? So regardless of whether or not we're drawing, we, we want to update. And so this is why I said that we want to either draw or we want to compute our, uh, evolutionary algorithms. We could do both actually, but we're going to keep this simple.

Speaker 1:          26:21          We could do both asynchronously. You think some kind of concurrence, a library, but then there's like callback hell and there's a way around that with like promises. But we'll focus on the evolutionary algorithms right now. Okay. So, um, so we have that and let's go ahead and say, okay, so that's our if statement. So then else, uh, let's go ahead and draw the, so if the speed is not zero, then we need to keep drawing. We tell the game that we need to keep drawing. So I'll say draw the elements and the elements are going to be true though. So we'll set, draw to true. That's going to tell our game to draw the elements. And so by the way, the update function is going to update the game. If that means it's going to update a fitness, make a move and evaluate the next move.

Speaker 1:          27:03          There's going to update the fitness function, make a move. The AI will make a move, like, you know, what road, what shaped, what block to play, how to rotate it. Uh, and then until it goes to the bottom, and then it's going to evaluate the next move using that previous mood. And we'll update it three times to do that. Uh, we could update it just twice, three times or four times, but, uh, we'll just update it three times. Just, uh, so we have some kind of updating happening. So then we're going to do an update in general, right? So regardless of anything, whether or not the player, and so this is all about changing speed. So regardless of whether or not to play or change speed, we want to update the game anyway. So we'll update it, right? And then we'll say, um, what else?

Speaker 1:          27:43          We got? Uh, one more value. So, so then, uh, oh, this should be a part of the game loop. What am I thinking? Blah, blah, blah, blah, blah. So then we'll update this update regardless, and then we'll say one more time. So if speed equals zero, then we're going to draw the elements and then we're going to update the score. Okay. Okay. So then we're going to initialize it with a document onload function. Uh, and so the document onload function is going to uh, initialize our, our initialization function, right when the dom loads up for javascript, write the html elements and all of those things. Whenever you load up the webpage, run this function, that's what it means. Okay? So that's the gist of it. But the idea here is that we are going to initialize the population, right? So we initialize a population of genomes, which are those sets of values.

Speaker 1:          28:43          And then we run a game loop. And then whether or not the player has decided to change the speed, we're going to reset, we're going to reset the timer for the game and then we're going to iteratively update the game. And then if the speed is zero, then we update the score. Okay. So that's the high level code. And now we'll talk about the a helper functions. Cause we've got a lot to go through her. So let's talk about them. Okay. So we probably want to start off with looking at this create initial population function and then just move on from there. So we'll go in order, like in order of what we eat to look at, cause we have a lot of functions and I actually have them here at the bottom. Let me just move this hold on. Phone, phone, phone. Okay, well let's get started.

Speaker 1:          29:24          Okay. So move this out of the way. Okay. So the first thing we want to look at, because this is the function, this is the main function, right? This is an initial of function. So let's look at this. Create initial population function. So for create initial population, this is our key down function. This is just like, you know, depending on what key you press, run one of these functions like you know, if you press w a s or d, which are these key codes, move down, move left and fry, uh, saved the state. If you press Q, load up the previous date, if you've suppressed w, change the speed. If you press e, uh, turn the AI on or off. He's a bunch of, just a bunch of key precedent. So we can just skip this function. Key presses, right? This is our, this is our code.

Speaker 1:          30:07          So let me, let's talk about this. This is the, this is the fun part. Okay. So for our create an initial population function, we're going to initialize a genome array, which we're going to store all of our genomes in. And then we're going to say, okay, so given a population size, so it's going to be 50, right? We defined it as 50. So given 50 genomes, let's say each genome, we'll initialize it just like this. So these are the seven values that you saw right up, right over here, right? These are the weight values that improve over time. Let me slow this AI down. It is moving so fast that it can't even draw fast enough. And so that's why we need async more asynchronous code. So we could do that, right? But we have a, we have a suboptimal code in terms of synchronization and concurrency, but that's okay. Let's see. So watch these white values, improve, watch them improve, they're gonna improve once this, uh, once we move on to the next generation,

Speaker 1:          31:02          yeah, there we go. They improved. Okay. So that's how they, so they're like, wait, values, their weight values. Okay, so let's talk about each of them. So we have an ID. So each genome gets its own unique identifier that will initialize randomly and then we have our rose cleared a parameter or gene. These are genes, right? The genome has genes which are parameters. And so what roads cleared means it's the weight from each row cleared by the given move. The more roads that are cleared, the more this weight increases. So it's a way of quantifying how much, how many rows we clear it and clearing a row. It's a good thing, right? The road disappears. It means all that row is filled to our score, our score increases. So we create a weight value that represents how many rows are cleared. You might be asking, well, why don't we just have the um, the s the direct value of the absolute value?

Speaker 1:          31:48          Why don't we just say, well, two roads have been cleared or three roads have been cleared because the weight value, it's kind of like a weight that you were in a neural network where these weight values are, they look unrelated to the input data and the output data. But in actuality they're like, they are measurements that we use as scalar values essentially. One more whenever we're matrix multiplying to compute an output. So these values change there. They looked like they're unrelated but they're updated so that we can reach that optimal output. In the end they're used to optimize for our objective, whatever that objective is. And in this case that objective is to get a score of 500 and so we use rose cleared as we use a weight value that represents the roads cleared and we initialize it randomly, right? Minus 0.5 and you'll see more about this when we, when we actually uh, use the amount roads cleared to calculate this weight value, it all plays into it, right?

Speaker 1:          32:42          But we initialize that as random and that we use the amount of rows clear to update it. And then we obviously then we use crossover to update the wait values in general, like all of them. Okay. So, so here, our seven way values, we have rose clear, then we have weighted height, which is the absolute height of the highest column two, the power of 1.5. So the highest column that we've reached when in an intergeneration is the weighted heights and it was added so that we can detect if the blocks are stacking too high. And then we have a cumulative height, which is the sum of all the column Heights. So we add all of them together and we use that some. And then we have a relative height, which is the highest column minus the lowest column and the holes, which are the sum of all the empty cells to have a block above them.

Speaker 1:          33:24          So whenever we have a, our game, like the holes would be right here, right here at the bottom. Like these are no, these are no, these bottom values right here. Our holes right where my mouse is and check those out. Those are holes. So we want to, we want to minimize for those holes, right? And then we have a roughness, which is that some of the absolute differences between the height of each column, right? So just like wait values in a neural network, we don't know what these optimal value should be, right? That's why we're going to optimize for them. And the way we'll optimize, it's through a evolutionary algorithms to selection, crossover and mutation. That's how these way values learn what, what the optimal value is. Like we don't know that we have to minimize the amount of holes, right? But we, but I mean we know, we intuitively know that we should minimize the holes, but we haven't told the algorithm that it will learn to minimize for the amount of holes it will learn to minimize for the relative height and the weighted height.

Speaker 1:          34:22          Right? Cause we want the smaller heights are good because it means that our block, our rows are clearing that are, are our blocks or shapes are fitting together, right? So those are the genes for each genome and we'll take each of them and push them to our genome array that we initialized and then we'll evaluate the next genome. Okay. So right, so speaking of evaluate next genome, let's look at this next function, right? We created our initial population of genomes and then we're going to evaluate the next genome. So let's see what that looks like. Okay. So let me make sure that we're, yeah. Cool. So this is the actual selection part. Now that we've evaluated, now that we've created that initial population, we want to select for the best genomes, right? So how do we do that? So we say, okay, well first of all, let's increment where we are in the GMO genome array.

Speaker 1:          35:11          So cause we were going to do this to each genome, right? What is the next gene? And let's evaluate it in the context of, of Tetris. So we say, okay so if there is none, then we're going to evolve the population. And so that is the crossover step. If there is no next genome, it's time to move on to the next generation, right? And that means like start breeding. But if there is one, then we want to use it to evaluate what the next move is. So we'll load up where we are in the game, we'll reset the amount of moves cause we're going to try out a bunch of moves for this genome and then we'll make the next move. Okay. So, uh, so that's our selection steps. So now let's talk about crossover. So when it comes to crossover, so let's say that we've tried all of them out, like we've tried all the genes out and now we're going to evolve.

Speaker 1:          35:57          So let's talk about what evolution looks like in this case. Given a set of genomes. So this is the art evolve function and this is where the step two of evolutionary algorithms happens. This is where the, the, the, uh, mating step happens. Don't worry if not rated R or rated x. It's totally rated g. Okay. Yeah. Okay. So yeah, it's rated g. So anyway, okay, so, uh, we're going to say evolve and then we're going to evolve this genome. So how does this work? So we say, okay, so we're going to reset the current genome for this generation and then we're going to increment the generation. It's time to move on to the next generation, reset the game. Because every time we had our new generation, we want to reset all the block values, right? So it's empty. The grid is empty again. And then we say, okay, so let's get the current state of the game, like where we are in the game.

Speaker 1:          36:44          And then this is our way of seeing who has the best fitness. So we use this function. We haven't actually defined what the fitness value is, but we're saying like assuming that we've calculated it, which we will in a different function that I'll talk about, assuming we've calculated what the fitness will be, we can then sort all of our genomes in order of fitness and that's what this function do. This, that's what this function does. It's going to sort the genomes in that array in order of fitness. And then once we have those, we'll push each of them into our elites. Uh, remember our, our, our archive array had this elites, um, value right up here or was it that Addenda C, this one? These elite values are the ones that are fit to breed, right? These are the ones that are fit to breed.

Speaker 1:          37:28          They had the most fitness of all the genomes and we can say, ah, let's add them to this array because we're going to then use those to crossover to breed. So then we'll say, okay, so then we'll remove the rest. So the tail end. So the population size divided by two. If the length is greater than that, pop it off the list like, like a stack, right? Pop it off and don't need it anymore. So we're only going to focus on the the fittest genomes and then we're going to say, okay, let's sum the total of the fitness of each of those genomes together to get the total fitness. Okay? And then we're going to get a random index from the genome array, which says, okay, let's, let's get a random weighted numbe between zero and the genomes length minus one. And we're going to use that genome as our, this is our selection function, right?

Speaker 1:          38:13          This is selection right here. This line is essentially selection. We're basically randomly selecting, okay. And that is our fitness in this case. So it's a very brute force and not proved for us but of air. It's a very primitive, a fitness function. I mean, we could do other things, but it is fitness function. It is a fitness, it is a fitness function, right? It is better than nothing. So that's how we choose which the which genomes are going to be fit to breed randomly. Okay. So then we have a children array that we were going to populate with our children and we're going to push the fittest genomes to that array. So we already have those fitness genomes that we defined and we're going to push those finished genomes theory because we popped off the bad ones or the not fit ones. And so then once we have that, we're going to say while the length of the children is less than the population size, we want to push all the, um, now it's time to actually make the children too that children are ready.

Speaker 1:          39:14          So we'll say, okay, so push the children. And the way we do this is we take two random genomes. That's how we select our parents. And then we, and then we do some dot. Some computation that's defined in this make child function that we're going to, I'm going to talk about. And then we're going to get a child, a child, Gino, and we'll push that to this. Children are right. Okay. So that's that step. And then we're going to create a new genome array and then we're going to store all the children in there. And then we're going to store that in our archives. So we saved it, right? And then we'll say, okay, so now this is the current generation. So we have our past generation and our current generation. And then this is the local storage part. This is where we saved the archive.

Speaker 1:          39:55          Thanks. Show javascript, short term memory, kind of like a differentiable neural computers, uh, external memory bank. Now that's too advanced for this. That was pretty awesome. That wasn't it if you saw that video. Cool. Okay. So, um, all right. So how do we make our children? Well, kids, well boys and girls, this is how we make children here. We, I'm skidding, uh, what am I doing? Okay. This is how we make children. We make children by, uh, I had so many jokes didn't happen here. Focus here. Raj focused on them. That child function, we are going to say, okay, so we have a child. So we have a mom and a dad. So, right. The Mom and the dad are two genomes from the previous generation with those seven parameter values. So we'll first initialize a child using both mom and dad's re uh, values for those seven parameters.

Speaker 1:          40:45          And we'll pick a random choice. We'll pick a random value. That's how the actual reproduction happens. Okay, so that's the reproduction stuff. That's the crossover step. Step to crossover is happening here. So we say for roads cleared for all those values, we're going to just pick a random one between both between either mom or dad. And then once we have that child with it's seven parameter values that have been decided by crossover, which is actually just randomly picking between the two, then we can mutate each of them music our mutation step. So this is step three. This is the mutation step, the last step of evolutionary algorithms, right? So we'll say if the mutation rate is greater than some random value, then set that the child's value, that that parameter value that gene for each of the genes to, uh, its own parameter value plus some random value times are mutation step times two minus r mutation steps.

Speaker 1:          41:37          So this part right here is yes, magic number territory, but recall from hyper parameter search, it's very similar to hyper parameters. You know, we have to kind of guess and check what these values are and then whatever works best. That's, that's what it is. And you know, we can learn to learn and we can just have everything be, um, not magic numbers and then use evolutionary algorithms even for the, uh, these parameters. But you know, that's a step further. But right now we're going to set a two times two, right? And then our mutation step and we'll do that for each of the values. And at the end we'll have our mutated child, we'll have our mutated child, but yeah, so we'll have our mutated child that we can then return. Okay. So, uh, yeah, so that was, those are the three steps. That's, that's, that's the logic for an evolutionary algorithm, right. Um, selection, crossover and mutation. So, but let's keep going. Right? So

Speaker 1:          42:29          make next move is the next thing I should be talking about. So back to this, back to this and evaluate next. Gino, let me go back. There's a lot of code here, so, so it's so keep, keep track with me. I know there's a lot of code, but remember that first step creating an our initial population and then we said, okay, well we created our genome, we define what those parameters would be. And then we evaluated the next genome, right? And we talked about what the evolved function was and then we went down that chain, that hierarchy of what what was next. And that was basically all of evolutionary algorithms. But let's talk about this. Make next move step, right. This is right. So

Speaker 2:          43:05          okay,

Speaker 1:          43:05          they got some move, right? Yeah. It makes a nice move and then get all possible moves. Yes. So let's go to that. Make the next move step. What does it, what does it take to make a next move? And so that is how does our AI decides to make a next move based on those wait values? So this is how it happens. Let's go down there.

Speaker 1:          43:21          So here's our make next move step. So here's how it happens. So we increment the amount of moves taken and then we say if it's over the limit, then we want to update the genomes fitness value using the game score and then evaluate the next genome. But if it's not over them, next moves limit, then we're going to make the next move for this genome. So we're going to say, okay, so we'll store the old drawing. So we just have that stored and then we'll say let's get all the possible moves and we'll talk about what this function is. But basically this function is going to define all the different possible moves that a genome can make an a game state. So he's going to rotate a block this way, this way, this way we've up down left, right all the possible moves that you can make for a, for one genome.

Speaker 1:          43:59          And then we're going to store that in a list and then we're going to get the state of the game because we're going to update it. And then what's the next shape to play? We wanted to find that. So here's how it goes down. We say for each possible move. Let's get the best move. So we're checking all the possible moves and then we're gonna get the highest rated move. The best move, move, move section is what I called it. So we get the best possible move and we saw that in a next move function. Okay? And so that's what the best move will be. And then

Speaker 1:          44:31          we're going to say, we're going to add that rating to an array of the highest rated moves, right? Then we'll load the current state and we'll say, well, let's get the highest rated move and store that didn't move and then rotate the shape as it says to. So for the amount of rotations and move, that's how many times we're going to rotate the shape and then move left as, as many times as it says to translate and then move right as it says as well. So this is like, it's decided what the Mooc should be based on those wait values based on those, uh, on those genes for genome. And now we, it's like we got that back. So, and this get highest rate and move and get all possible moves. Uh, these two functions, that's where the actual, um, wait values play into the move, the move that we're going to make.

Speaker 1:          45:15          So we'll go into those functions in a second. We just keep diving in deeper and deeper. So once we've made the move, then we went to update our move algorithm and then we went to draw the old drawing output, the state to the screen and update the score. Okay, so let's talk about what this get all possible move function is and then this get highest rated move function. So, uh, so we'll say, okay, so forget all the possible moves will initialize the last state. The possible moves, the ratings, and then the number of iterations. So it's basically a bunch of nested statements. So here's, here's how the weights play into the, the genes or weights play into the move that the each player is going to make. So we say for each iteration, so we have in between negative five and five, so 10 iterations.

Speaker 1:          45:58          We're going to load the last state up and then we're going to say rotate the shape for as many rotations as, uh, we defined a beer up here. So for each possible rotation, move left as many times as we can. Move Right for as many times as we can. And then if the shape has moved at all, then move it down. That means like if it's able to move this so it's not blocked, then move it down. And while the results are, and if it, if it has, if it's able to move, then move it. So here, here's the step right here. This, this part is how the weights, how the genomes, how the genes play into the move. We set the seven parameters of a genome right here. Okay? So these are the seven parameters. We set them, uh, using these get functions and then we rate each of them.

Speaker 1:          46:48          So given our algorithm, we rate for the current genome, all of these values by multiplying them together. And we just concatenate all those values together to get a scalar rating value. And if the move loses the game, then we went to lower that rating. So if there's, if it's a, you know, boolean value, if the move lost, then we want to lose the game, then we want to, I mean lower trading. So then we push all the possible moves with their associated ratings and perimeter values to an array. So we've tried out all these possible moves using this, using these, um, parameter values. And so these get, get her values are getting these, uh, wait values from the state of the game. So whatever they are currently, it'll get them. And then we'll use them to rate each of the

Speaker 2:          47:32          yeah,

Speaker 1:          47:32          uh, parameter values in our current genome and, but for every single one that we try out, so each genome is going to try out a bunch of moves and then we'll use those parameter values to rate each of them. Okay. And so then once we have all the possible moves, we'll update the position of the old x value for that shape and then push that to the old x ray and then load the last date and return that array. So then given that a right, well how do we get the highest rated move? Right? So this, the next function, so we'll start off these days is very small. So we, so we have an initial Max rating that we want to update an a max move, um, variable as well as ties, which we'll talk about. Okay. So, uh, so I will say also, so let's iterate through the list of Moose, however many removes we have.

Speaker 1:          48:15          And then we'll say if the current moves rating is higher than our Max rating, which it will be at the start because this is a very, very small number. Then we'll update our max value is to include this moves value and then we'll store the index of this mood of this move in our ties. Hooray else. Okay. So else if the current moves writing is not higher than our Max Rating, then add the index. Then if it ties with the Max Rating, then we're going to just push it to this, uh, ties array. Okay. So then eventually we're going to set the highest move value to this move value, and then set the number of ties right here, and then we're going to return the move.

Speaker 2:          48:52          Okay?

Speaker 1:          48:52          Okay. So that's how we decide what the, uh, highest rated movie will be. Given those all the, all the possible moves we can play. So, and then one more function that I want to talk about it over here is the update function. So where did we call the update function while we call the update function, right? Where was it? [inaudible]

Speaker 1:          49:21          did score? Oh, we call it up here. So at the highest level, right? So we went down through all of what create an initial population means, right? We went down through all of that. Now we want to talk about the update function and clear interval is just like native javascript. But we went through all of that logic and remember this is the highest level of function. So this is what matters. And we went through all of this. And so now it's time to go through the update function, right? So how do we update the game? Okay? So let's, let's see what that looks like. And I have painstakingly comments at every single line here. So definitely check out the code on get hub, but um, or refer update.

Speaker 1:          50:05          Okay. So here's how we update the game. So it's, this is pretty, it's pretty readable code. I like it. So if we have our AI turned on and the current genome is non zero, so we have it, we have a genome and it's the Ai, then make a move. And so we moved the shakedown and if that didn't do anything, if we, and if we lost then update the fitness function and move on to the next genome. But if we didn't lose that, make the next move. Pretty simple, right? Uh, so, and if so, then we have another l statement. So if the move didn't do anything, then just move down, right? So if, if the move didn't rotate, then we moved down and then we output the state to the screen and then update the score. So let's look at this update score function.

Speaker 1:          50:45          What does update score mean? Right? So this just updating score just means drawing it to html, like outputting the, the score value to html after we've used the seven gene values to help rate each possible move for each possible genome. And then we pick it and then we picked the highest one or the, the, the fittest one. Because we randomly cross crossover, we randomly select children via a crossover. And then when you take those children via our mutation rate, once we do that, then we can update the score and the score just means updating the score to the, to html or to the, to the, to, to the dom to be more technically accurate. Okay. So, and then the rest of these helper functions or just get her and instead or functions, uh, that was really the main logic of this code. These are just scattering cetera functions like get cumulative cumulative heights and get holes.

Speaker 1:          51:36          Like it basically goes through the grid and then just like, you know, calculates like how many zeros versus how many ones, what's filled in versus what's not. That's what this part does. And then, uh, yeah, that's basically it. But it's a, it's, it's about a thousand lines of code. Uh, but it's all, it all fits in this js file and it's all readable. So, uh, I def, I hope you check it out. It's going to be awesome if you do. I want to see more people using evolutionary algorithms. And let me end this with answering, uh, just two questions randomly from the comments. Okay. So let me answer some questions from the comments. Here we go. All right, here's a question. We needed blockchains to distribute and decentralize our systems. So no single entities like governments or organizations can overpower us. Absolutely. I think there's, I mean there is a huge opportunity to combine artificial intelligence with blockchain technology to create entirely autonomous organizations and corporations and all sorts of organizations that live, uh, in a distributed system that no one has control over.

Speaker 1:          52:41          And it just, it self improves itself and it has its own rules embedded in smart contracts. And Yeah, there's a lot of possibility for using blockchains. And one idea that I think is really great is, uh, the idea of tensor coin. So a distributed system where you're using a cryptocurrency to pay people for compute, peer to peer compute. So there's my answer to that, like it's not really a question, it was a statement. But one more question. And the question is, can you please make a tutorial on handling multi-variate time series data using LSTM and care os? So yes, I've made a video on that. How to predict stock prices easily and also, uh, what else? Yeah, that's the main one. Okay, cool. Please subscribe for more programming videos. And for now I've got to go evolve. So thanks for watching.