Speaker 1:          00:00          Hello world. It's Saroj and what does the Anti Facebook look like? Snapchat, no. Facebook's newsfeed Ai Algorithm is causing some serious problems and in this video we'll learn how it works technically. Then discuss some solutions to the problems that it presents. Facebook uses AI for pretty much all of it's products, whether it's showing you the most relevant comments, fighting, spammers or summarizing trending news this year they've reached over 2 billion monthly active users making it the biggest social network in the world. It makes sense. They provide users with free services. They can use messaging store as much of their data on Facebook servers as they'd like. Host live streams all for free. The way users actually pay for Facebook is not what their money but with their data. Anytime we use Facebook, it learns about us. Facebook knows which of its users have depression, which ones are full of hate, which ones are recently married, where they live, et cetera.

Speaker 1:          01:04          This is very valuable information for companies who have products or services they would like to sell. Facebook's business model centers around giving advertisers access to a very targeted audience. Advertisers can choose the type of person they'd like to promote their brand too in detail, and Facebook facilitates that process. They pay Facebook for your data, which means that when you use Facebook, you, and specifically your attention is the product. This materializes in the way Facebook's flagship product, the newsfeed works. Let's imagine we're Facebook and we want to show a user the most optimal content in their newsfeed such that they keep their eyes on it as long as possible. We've got a list of activities that users have performed in the past called events. An event can be a post made by a friend, a conversation between two friends on new group being created, things like that, and different users will interact with these events in different ways.

Speaker 1:          02:08          One might like an event, the other could ignore it, the other could reshare it, and we can represent all of these actions as numerical values and we can represent all of this as a matrix. The roads would be all the unique users and the columns would be all the possible events for Facebook. This matrix would be bigger than Apple's evaluation and we're making two assumptions here. The first is that users who interact with events in a similar way share one or more hidden preferences. For example, liking the same posts or viewing the same article. The second is that users with shared preferences are likely to respond in the same way to the same events. Thus we are relying only on observed user behavior here to make recommendations, which is considered collaborative filtering and a popular way to this is by using a technique called Matrix factorization.

Speaker 1:          03:03          Every entry in our matrix captures a user's reaction to a given event. That rating could be explicit directly generated by user feedback or implicit based on features like time spent interacting with set events. If a user has never rated an event, the Matrix entry is zero. Often in these type of matrices, the majority of the entries are at zero. We're assuming that there's a set of features common to all of these events and events differ in how they express these features. Each user has their own reaction to each feature. Independent of the events are users. Events rating can be approximated then by summing the users strengths for each feature weighted by the degree to which the event expresses this feature. These features are hidden factors we'll need to transform the matrix to represent these hidden factors using linear Algebra. This is called low rank approximation.

Speaker 1:          03:59          It's the process of compressing the sparse information in our matrix into a much lower dimensional space. Then we can calculate the rating of a given user for a given event by taking the dot product of two vectors, which we're going to do in the context of a neural network so that we can leverage the fact that we have so much data and computing power as Facebook. The added terms like the weight matrix will help us optimize our predictions over time. The output will be the combination of both vectors. This output represents a prediction of a user's rating for a given event. We can then define a loss function to measure the accuracy of this approximation. It sums the square difference between the approximate rating and the actual rating from the training set. Lastly, we can perform gradient descent to use that computed error to update our weights and every iteration that error will get smaller.

Speaker 1:          04:58          While our predicted user ratings, we'll get better. Ai optimized ads are different than regular ads because it's no longer a one way relationship. It's two way you view the ad, but the ad also views you and how you react so they can manipulate you subtly. Facebook decided to not only perform surveillance on literally everything you do to advertise to you. They also decided to perform direct behavior modification. Human survival has necessitated that our brains pay more urgent attention to possible bad outcomes than to good ones. Facebook's attention optimizing AI has learned to exploit this and to keep us engaged and manipulate our behavior. For example, making people argue leads to more engagement which leads to more attention, which leads to more ad revenue, human decency, kindness, empathy. These things are not profitable for companies like Facebook all operating under the business of a tension maximisation.

Speaker 1:          05:59          This has resulted in a much more polarized society globally where existing opinions are reinforced endlessly and arguments are encouraged by AI optimized content. It's tearing apart. The fabric of human society. Never before has one entity been so powerful to manipulate the psyche of 2 billion people. The initial founders of Facebook, including Sean Parker and Chamath Palihapitiya have both stated that they regret the effects on society that their business model has caused, especially on children. The short term solution to this problem is awareness. The more people that know just how good Facebook's AI is at manipulating them in ways they don't even fully understand yet, the more likely they'll be to protect themselves. The center for humane technology has a list of ways to take back control of your attention from these social networks. Some suggestions include turning off all notifications except from people and going gray scale to avoid the positive reinforcement that colorful icons are designed to unlock in our heads.

Speaker 1:          07:08          A more ambitious solution is to build the anti Facebook, a social network that uses a different business model. [inaudible] is one example of this. Their business model is facilitating users sending funds to other users, not advertising. That's an optimization objective that can be much more easily aligned with the users wellbeing than eyeball seconds. Another thing to note about [inaudible] is that you can peep and tweet at the same time, which is an effective way to erode the network effects that protect more popular social networks. You can even easily sync your followers from Twitter to p path. It's features like that that show us that it doesn't have to be inconvenient for users to find an alternative to Facebook. Another example is mastodon. This is a Twitter clown that anyone can host instead of one provider in charge of the newsfeed. There are several. It's a federated network, more decentralized than Facebook.

Speaker 1:          08:08          It provides the same resources, but with the added ability to exit it. Commoditizes feed providers. If one provider is starting to put too many ads on their feed, a user can just switch to another. There are some technical challenges to building decentralized applications and I tell them all in my past course and in my pass book on the topic, there's also the possibility of Facebook be centralizing itself. Facebook's original mission was establishing an Internet identity. That's what made them different from my space. It seems like a natural continuation for them to try and position themselves to be the root of human identity on the Internet and having a unique crypto address not owned by anyone would do just that. Just a few months ago, they announced their biggest ever management reshuffling, which included the launch of an exploratory blockchain group that reports directly to the company's CTO. If Facebook released their own crypto currency, they could pay their users for engaging with their platform, say one face coin per uploaded photo.

Speaker 1:          09:14          This would also give equity to all of its users, which would retain them and get them to help grow the platform. Because right now that growth is stagnating as users wake up to Facebook's problems. It could even give them voting rights as to how Facebook is run, which would increase their brand reputation. This would be profitable for Facebook and it would help solve their alignment problem because through this new business model, they'd be more inclined to show users content that would benefit them and paying over 2 billion people globally for their data starts to look like a universal basic income which would offset some of the effects that automation technology will have on labor based jobs. Speaking of a new class of jobs, linear envisions that who start seeing mediators of individual data or mids start forming as well. This is a nonprofit organization that negotiates data royalties for groups of people with similar interests.

Speaker 1:          10:14          For instance, a botanist who likes to hike could join a mid for people who compiled useful photographs and data about trees in certain regions of the world. That data would be valuable to certain companies and a protocol like open mind could facilitate this exchange of data and capital in a decentralized way. So even though Facebook's business model is bad for the human psyche in the short term, we can protect ourselves by adopting anti addiction techniques so that we get as much of the good from social media as we can. While avoiding the bad along the way, we can build other social apps that use different business models to provide people with alternative options. And who knows, maybe Facebook will become the anti Facebook ushering in a new era of data transparency with the focus on human wellbeing instead of attention. What do you think? What is the Anti Facebook look like? Share your thoughts in the comments section. Please subscribe. And for now I've got to use Twitter, so thanks for watching.