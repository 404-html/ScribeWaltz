Speaker 1:          00:00          Hello world, it's Saroj and today we're going to build a machine learning model called logistic regression to predict if someone has diabetes or not given three other features, their weight, their height and their blood pressure. Using those three features are going to predict if they have diabetes or not. Okay, so in this video we're going to go over to really two key concepts. We want to go over logistic regression, which is a machine learning model and we want to go over the optimization technique, Newton's method. So we've already talked about nudes method, but we want to really reinforce that idea in our head of how it works. And the medium that we're going to use to help reinforce that idea is this machine learning model called logistic regression. So before we start, I just want to say one thing to to really understand how logistic regression works, we're going to have to go over some terms from all four or actually five pillars of machine learning, old, all five disciplines that I talked about at the beginning of this course.

Speaker 1:          01:01          Calculus, linear Algebra, probability theory and statistics. So actually four pillars, not five. We have to talk about little bits and pieces from each of them. So the reason I say that is don't worry too much if you don't understand every single detail of why something is the way it is. We're going to talk about all of these concepts in the, in the direction or in the, in the context of learning about logistic regression. Keep in mind, I have entire videos coming out on all of these subjects. So for example, we'll talk about Matrix transposes uh, but, and I'll tell, I'll say one reason why we would use a matrix transpose, but I'm not going to say all the reasons, but I do have a video on matrices in general and linear Algebra coming out in a few weeks, right? So just don't worry too much if you don't understand every single detail.

Speaker 1:          01:49          There's so many mathematical dependency chains that we can, that we can follow conceptually, right? When we think about these things. But we want to have a very specific chain of a very specific chain or bear to specific train of thoughts because there are so many that we can go over, right? We only want to learn how logistic regression works and to reinforce our knowledge of Newton's method. And if we do that and if we get how it works and we're going to end and I'm going to define all the terms that we're going to use, right? So you're going to get the definitions, you're going to understand how the equations works and work. But if, if you don't understand every single detail, don't worry. I have entire videos coming out on it and I have it all planned out. So don't worry. Okay, so I just wanted to say that there's, cause there's a lot that we're going to coat that we're going to go over in this video.

Speaker 1:          02:34          Okay. So, okay, now that I've said that, let's go ahead and start. So that's, so our task is to compute is to predict if someone has diabetes or not given their weight, height and their blood pressure. And this is toy data. So we're actually going to generate this feature, these features. Okay. These three features. Uh, okay. So let's start off with defining what logistic regression is. So logistic regression compared to linear regression is a, so let's compare to linear regression, right? So the key difference between logistic regression and linear regression is that linear regression, a predicts a continuous outcome. What does that, so versus logistic Russian, which computes a discrete outcome. So continuous is a means that we can have values that range from, um, from negative infinity to infinity or just an infinite possible set of values, right? So if you have some series, some number series, the next value could be any, any, you know, it could be any one of a set of numbers out of infinity, but for a discrete outcome, it's either one thing or it's another, right?

Speaker 1:          03:40          We have you kind of, you box it into some, some, some container. So a discrete outcome would be is it blue or is it red? Whereas a continuous outcome would be, um, what is the value? What is the next value in the series of house prices? Right? You can have two values. It be one or two, it can be some number between, they're like 1.5. It could be a number between that. Like 1.25 and an infinitely small in that, in that direction. Do you see what I'm saying? It could be an infinite number of possibilities. And so linear aggression is great for that. But what if we want to predict an outcome, like say if someone has diabetes or not? Well that is a discrete outcome and he's a binary outcome. Either they do, yes or they don't know. And so logistic regression is basically our way of modeling a discrete outcome, right?

Speaker 1:          04:30          Uh, and so the outcome it was, which is the dependent variable a is going to be continuous in the case of linear regression and discrete in the case of logistic regression. And so why do we call it logistic regression? Well, it all comes from that key function called a logistic function that underlies, uh, how that underlies the model. It is really the core functionality of the model. And we also call the logistic function, the sigmoid function. So if you've done deep learning before or if you've done your own networks before and it's okay if you haven't, it's used a lot. Okay, so this is what the function does. Sigmoid or logistic function looks like it's one over one plus e to the negative x. Okay. And so why do we use e? So, uh, so there's a lot of reasons. I mean, there's entire textbooks on y e the natural number, uh, or EULAR is number is used up.

Speaker 1:          05:24          But one great reason is because when you take the derivative of e to the x, uh, you're going to get either the x again and it's the only fun, only known function that does this where if you derive it, it's going to give you the exact same results. And of course, this goes for all, um, all versions of versions of either the x where you can have any number of coefficients. So five e to the ax or three e to the x, the same thing applies. And so the, the point of that is that it makes it computationally convenient or mathematically convenience, right? So you can see from a high level how having a function that if you drive, uh, did you the same value is unique. And in that uniqueness, uh, can help, uh, with other computations. Okay. So, so, right, so, so that's, that's why we use eat.

Speaker 1:          06:11          That's one of the reasons why we use he anyway. He is a part of the sigmoid or logistic function is an s shaped curve. So given any number of values, it's going to output a value between zero and one and that is a probability value. And that's what we want, right? We want the probability that this person has diabetes, diabetes or they don't have diabetes. And then based on some threshold, like let's say it's above 70%, we could just say, oh well if it's above 70%, yes they have it or below. No they don't. Right? So we can define our threshold or we could just outputs that probability value, but we want a discrete outcome. Write a Boolean, yes or no. So that's at the heart of the algorithm. And so logistic regression, uh, uses an equation as its representation. Okay? It is an equation value, and I'm going to show you what the equation looks like, but the central premise of logistic regression and when you want to use it is when you have an assumption that your data is linearly separable.

Speaker 1:          07:13          And that means that given end dimensions where n is the number of features in your data, you could separate it linearly. So you could draw a line that acts as a decision boundary between all of your data points. So in a two dimensional space, this would be an n minus one. So one dimensional line in a three dimensional space, it would be a three minus one or two dimensional plane. And this goes on for infinity, right? For where n is the number of dimensions. And so that would be a hyperplane. So basically you're under the assumption that your data is in fact linearly separable. And if it is, then you can use logistic regression as a way to model what the class is given the feature set. Okay, so, so let's, let's talk about this. So what is the function for logistic regression look like?

Speaker 1:          08:01          So let's say we had the following function right here to noted by these Beta Beta coefficients here, right? So it starts with Beta zero and Beta one Beta two and then you have these variables, x one x two. Now all of these are our unique variables, right? So just think of it like y equals, well skip the why but mx plus B, right? And so you can, you can have an infinitely long equation of this forum where you can have B plus B, three x three plus B, four x four [inaudible] of this for. And so we're ex, we're where B is Beta, which these are the coefficient values, which are the weights, right? That we want to learn. We want to learn what the optimal weights are that's going to output what we want it to output. And so if we had this function and we plugged in some point, so let's just say it's this function alone, if we were to plug in some point a, B or x, y, whatever you want to call it, into that is a coordinate pair.

Speaker 1:          08:53          If we were to plug it into this, it could either give us a positive result, it could give us a negative result, or it could give us a a a zero, which is a point that lies right on the decision boundary. So assuming that if it's assumed that if it's positive, it's going to be of one class. If it's negative, it's going to be of the other class. And if it's zero it's going to be right in the middle. So it's of neither class. And so what we want is to set this equal to some, to some probability value or some probabilistic value, right? So, so we could do one of several things. Well one is, let me just skip this for a second. Let me, let me go down here. So one thing we could do is we could set this equation not to just why like we did with linear aggression, but set it equal to the probability of x given the function, right?

Speaker 1:          09:43          So given this, given this function, we plug in the coefficients and it's going to output a probability value. So we could use the probability or we could use the odds and the difference between the probability. And the odds is that the odds is this is this expression right here, which is the probability of x over one minus the probability of x. So note that probability of acts and the odds of x essentially denote the same thing, which is the pro, the ratio of the probability of the event happening versus it not happening. So why do we use the odds? So here's why. So given, you know, so given for possible values that we could set our equation to probability the log of the probability, the odds, and the log of the odds. If we set the uh, equation equal to, as you see right here, the log or logic or la la gets of the, of the odds, then it's going to let us have the greatest range of values such that it's going to map to between zero and one.

Speaker 1:          10:48          Let me explain that. So that means that we can have any value for our coefficients. So the the right hand side of this equation right here, which is this, this equation right here can be between negative infinity and an infinity and the left hand side will be equal to some probability value between zero and one. And so what this means is we can have any number of values that we can use for our coefficients. So it allows the widest range of coefficients to be used for our function such that the probability output is going to be between zero and one. And when it comes to reasons of why do we use the log probability versus the other three, they're like the probability, the why do we use a log odds versus just the logs versus just the odds alone, uh, and uh, versus the probability versus the log probability.

Speaker 1:          11:38          Well, to sum it up, it makes it easier. Uh, it can be extremely complicated if we were to just use the probability alone because we would have to, uh, fine. I set of constraints on the regression line, uh, for the regression coefficients because basically, I mean the, the log put, getting our computing, the log of the probability makes it easier for us because the value is going to be between negative infinity and infinity for what's whatever's on the right hand side. And there's a lot more theory here, right? So there's a lot of probabilistic theory here, but let's just say like, this is what I said at the beginning. Let's just for all intensive purposes of all the things that we could set our equation too, we're going to set it to the log odds. We're going to set it to the log odds and that's it.

Speaker 1:          12:25          Okay. So givens, whatever regression equation we have on the right hand side, we're going to send it to a log odds and that's going to give us the optimal relationship between any number of values that we could use for our coefficients and a probability value, right? So the general model for logistic regression looks like this where we have some, uh, log odds, probably log odds on the left, uh, and then some cof. And then some function on the rights, right? So, so in this case you could say the probability of having a disease, uh, is p. So we say the log probability of having that disease over one minus the, or sorry, the log of the probability of the disease over one minus the probability of the disease is going to be equal to our function. And these coefficients are the effects of the genetic factors.

Speaker 1:          13:15          And so each of these coefficients are going to be basically tune, these are wait values that will be learned as we learn as we train our model. And then these x values are going to be the variables for those genetic factors. So they'll, each of those will represent one of the features that that results in the probability that an individual has a particular disease. Okay. So, right. So, so this whole process that we're doing here that this whole process of, of finding the ideal values for the coefficients to, uh, to, to find the ideal probability values. There are the ideal probability values is called maximum likelihood estimation or MLE. So maximum likelihood estimation is a general approach to estimating parameters and statistical models by maximizing the likelihood function. So in deep learning we call this back propagation. So there's a difference here between NLE and optimization.

Speaker 1:          14:15          Okay. So Newton's method is, is an optimization algorithm. Okay? So you can use this algorithm to find the maximum or minimum of many different functions including the likelihood function. You can obtain ml, you can obtain maximum likelihood estimates using different methods. And using an optimization algorithm is one of them. Okay, so the, so let's talk about the word maximum likelihood estimation. We are maximizing the likelihood that our model classifies some novel data point as the correct class. That's why we call it maximum likelihood estimation. We are trying to maximize the likelihood that our model estimates or predicts the correct class for a novel data points. And so optimization is one technique we could use to perform an ele. Uh, but there are other techniques, but we don't have to worry about that. Okay. So like I said, we are focused right now we are focused on logistic regression and Newton's method.

Speaker 1:          15:12          And we're trying to form, we're trying to perform NLE and we're using new method as our optimization technique to perform an Ellie. Okay. Um, right. So, so why use Newton's method? Right? So we, we talked about logistic regression, uh, that what, what the general equation for it looks like. And we talked about that. We talked about how the process of US training our logistic regression model is called maximum likelihood estimation. And in machine learning or in deep learning, it's called backpropagation, right? So that's why you never hear the term MLE and deep learning because we just call it backpropagation for supervised learning where they are, whether it's a label, but in general, machine learning, the word, the phrase maximum likelihood estimation is used quite a bit. So anyway, why Newton's method? Well, it usually converges faster then gradient descent when maximizing logistic regression log likelihood.

Speaker 1:          16:08          So it's faster when it comes to logistic regression. And, but the one thing to note, and this is not a reason, but one thing to note is that each iteration is more expensive computationally than gradient descent because we are calculating the inverse of the Hessian. And the Hessian, and we'll talk more about this in a second, is a matrix of second order partial derivatives. And those are derivatives with respect to each of our coefficients or each of our weights in our function, but it's not just the derivative of them. That would be the Jacobean. It's the derivative of the derivative. Okay. And so let me say another thing. So, uh, the Hessian is going to be used quite a bit in this video. Uh, and we're also going to use some matrix terms that we're not, that we've never used before, but we'll learn about them as we go and yeah.

Speaker 1:          17:02          Anyway, so yeah, we're, we're going to learn some matrix operations as well here anyway. So as long as the data points are not very large, Nunes method is preferred. It's a preferred method. So, okay. So if we have a few data points and we're using logistic regression, Newton's method, great for optimization to perform maximum likelihood estimation. Okay. So one more thing before we get to the code and that thing is, what are some other good examples of logistic regression and Newton's method? Remember, although the utility that we're trying to perform is the testing, if someone has diabetes or not given some features, the data is in fact generated is in fact toy data. And the way to improve your understanding of this is to, uh, let me remove this anyway, is to look at other examples. So I've got one example here that uses a psychic learn a little bit for data preprocessing, but more or less it's using, it's very mathematically a legible.

Speaker 1:          18:02          So check out this one and it does something similar using Newton's method and it'll just horrible Russian board spam classification. So that to the idea is that you can detect if an email is spam or it's not spam. And then the other one is click through rate classification. You can classify based on some consumers clickthrough rates if they're going to or based on their other patterns if they're going to click through. So you can compute the click through rate. Anyway, these are two great examples. Definitely check them out to improve your understanding of both Newton's method and of logistic regression. Anyway, so yeah, so that's it for our examples. We've defined logistic regression, we've defined Newton's method both at a high level. And now let's get to the code. All right, so for the code part, we've got our dependencies here and our dependencies are importing num Pi for matrix math, pandas for data manipulation.

Speaker 1:          18:56          So a lot of data, a lot of data scientists use pandas a lot. In fact, there's some when asked, what tool do you use? They'll just say does, they won't even say python because it's that ubiquitous. But basically pen does is a really popular library for manipulating data. And what it does is it takes some Dataset, whether it's an excel spreadsheet or something else, and it will put it into an object, a native object in the, in the, in the dependency that is called a data frame. And once your data is in a data frame, you can perform a whole bunch of really easy getters and setters on that data. So you could specify the column and then the row and you could delete that data, that data point or you know, whatever. But it's basically very convenient for data manipulation. Uh, and so then we have important warnings for error logging.

Speaker 1:          19:40          And we do have one single, very, very, very thin wrapper on top of num Pi. But we're only gonna use it for one line. And I'll talk about the details here, but basically it is a, it, it fits our data into a matrix anyway. Don't even worry about it for all intensive purposes. This is not using any, uh, you know, heavy libraries. It's all very thin libraries. All the logic is going to be there anyway. Okay? So the first thing we're gonna do is we're going to, uh, we're going to define the sigmoid function, right? So the, the function that talks about before that s shaped curve and what the sigmoid function does is it outputs a probability between zero and one. Okay? That's it. Which is one over one plus e to the negative acts. So now I have this right here, this, this, uh, but let's skip this for now.

Speaker 1:          20:31          I'm going to come back to this. So we defined our sigmoid function, which is that key function that is the core of logistic regression. We defined that function on its own, and we're going to use a later, but now let's define our hyper parameters, right? And these are the, these are in machine learning, we call them hyper parameters, and these are the parameters of the model that we're building. So the first thing we're going to do is we're going to set the seed and the seed is used for anytime you're using any kind of randomly generated data. If you have a seed, then what? Whenever you rerun that program, it's going to output the same random numbers. So why is this useful for reproducibility? Which is good for debugging, right? You always want the same values to be generated so you can test your code.

Speaker 1:          21:15          So it's basically for reproducibility for debugging. And then we're going to define a convergence tolerance as this very, very small number right here. Basically this is the minimum threshold between the predicted output and the actual output is going to tell our model when to stop learning, right? So when the difference between our predicted output in our actual output reaches this threshold, then we're going to say, okay, that's good enough. As opposed to just saying, well, whenever we finished the number of iterations, we're also adding this threshold, which we're going to call the convergence tolerance and we'll use it and you'll see why later. But basically it's a threshold for when we can stop learning. I had this other term here called the l two regularization term, which is going to help us regularize. So now I'm going to go back up here and talk about what regularization is.

Speaker 1:          22:07          So regularization is a very important technique and machine learning to prevent over fitting. We use it all over the place and deep learning in general, machine learning, we used to everywhere. Basically it's a technique to prevent over fitting. And what do I mean by overfitting? That means when your model is to trained on the training data and it's not going to generalize well for new data. So if you give it some new data, it's not going to be able to make proper predictions because the training data that you tested it that you train the data that you trained it on is too similar. It's too homogenous. So if you give it some very different Dataset, it's not going to be, it's not gonna predict that. Well. So what regularization does is it is, it's a technique to help prevent this. And we have several techniques to prevent overfilling, but regularization is a very popular and important one.

Speaker 1:          22:57          And so mathematically speaking, it adds a regularization term. So there are two types of regularization right here that we're going to talk about. One is called the l one regularization and the other is called the Lt regularization. So the difference is l two is the sum of the square of the weights, while l one is just the sum of the weights, right? And so we have, uh, the, the actual output minus the predicted output and then squared plus our regularization term, which is the sum of the weights versus the sum of the square of the weights times this lambda term, which is the regularization term. Okay. And that's going to give us, and what that, so adding this, this edition is basically, this helps our model, not, uh, get over fit to the data. And so when should you use l one versus l to, well here's a list of when you should use them and when you shouldn't.

Speaker 1:          23:54          There are, there's actually a bigger list out there, but at a high level we are, the reason we use it is use case specific. So if you have, um, if you have a small datasets and you don't care about computational efficiency because it's a very small Dataset, then you would likely use l one. Whereas if you don't, you could use l two. And then it also relates to the sparsity of your data, which means how many Zeros this does the data have, how sparse is it? If it's, if there's a lot of zeros and it's very sparse. Okay. So, uh, and there's a lot more reasons, but basically, uh, in this video we're going to be using the l two regularization term. And so anyway, yeah, so that, so there's that. Anyway, so, uh, we're going to use LTE regularization and then we're going to have 20 iterations for training.

Speaker 1:          24:42          Okay. So now, so these variables are used to help create our data. Okay. And so these terms come from linear Algebra. So the first term defines a, the covariance between x and Z. Covariants is a measure of how two variables move together. So it measures whether the to move in the same direction, which would be a positive covariance or in the opposite direction, which would be a negative covariants. So we have two of those. And so, uh, we want to set it 2.95. So we have a positive a covariance. We want these very, we want, uh, to have our variables to be related very closely and that would be our height and our weight and blood pressure can be kind of off. We're, we're actually creating this data right now so we can define what the, uh, what these terms are. Whereas a normal data, we wouldn't define it.

Speaker 1:          25:35          They would just exist, right? And then we would have to discover these relations. But we're defining these relations right now, right now. So then we have a number of ops or observations, which is a thousand and a thousand is the number of data points. We have, data points, observations, same thing. And then we have a sigma turn, which is the variance of the noise, which is how spread out is this data. Okay? So again, we're going to get back to these terms. We have a lot of probability to go over in the future, but at the high level, that's what those terms mean. The spread of these, the spread of numbers, uh, the relationship between two variables and the number of data points that we have. All right, so now we're going to define our model settings. So we have a set of true Beta coefficients. So let's just assume that we know what the ideal coefficient should be for our model.

Speaker 1:          26:21          Okay, so we have those true Beta coefficients and then we're going to have our predicted Beta coefficients. And we're going to s we're going to, we're going to, uh, use the true Beta coefficients to help us calculate, uh, our predicted Beta coefficients. And then we have a set of variances for each of these inputs. And that is how spread out each of the inputs are. And remember we are manually defining these as well as our model will manually define what our model looks like, the shape of our model, given our three uh, features, right x CNV, which are the height, weight and blood pressure. Okay. So we've defined our model hyper parameters and now we can generate an organize our data, right? So to generate this data. Now this is assuming we don't have real data, so we're going to generate it. And so I'm going to introduce a few uh, statistical terms here, specifically the distribution, right?

Speaker 1:          27:14          So what is the distribution at a high level of distribution is a function that provides us all the probabilities or provides us the probabilities of all possible outcomes of a sucky castic process. That is a process that cannot be predicted. A stochastic process is one that cannot be predicted and it deterministic process is one that can be predicted. Okay? So it looks like a bell curve usually. And there's all these different types of distributions out there. You've got Bernoulli by no meal normal. You have a whole bunch of different distributions that represent all the probabilities of a possible outcome. For a specific outcome. And so that's it at a high level. And we have, I have an entire video on distributions coming out later, but for now know that that's what a distribution is. And we're going to use a distribution to generate our data.

Speaker 1:          28:04          We're going to use what's called a multivariate normal distribution to generate values for x and z. So we're going to use the same distribution to generate values for x and z because remember they are closely correlated height and weight and uh, there are, and we also define their covariance, right, has very high 0.95. So X and Z are very, are very closely related. And then the is going to be our variable for our blood pressure and we'll, and we'll generate that using a normal distribution. So a multivariate distribution, normal district. So we used a multivariate normal because we had multiple variables, x andZ and just a plain old normal because we only had one variable it's generated from. Okay. And we're going to compute what's called the transpose of the results. And the results of these are going to be in a matrix. And the transpose is when we take the rows and the columns of the Matrix and we flipped them right?

Speaker 1:          28:55          So that, that's just what, that's a definition of a transpose. Okay. And that's gonna make it, um, more neatly formatted for us for future operations that were going to perform on it. Okay, so we have our variables. So let's create a pandas data frame. Remember I said how in pandas, a data frame is a very neat object and neatly package object that lets us manipulate our data very easily. So we'll put all those variable, all three of those variables in our pandas data frame object. And then we're going to compute the log odds for our three independent variables using the sigmoid function. So we're going to take the sigmoid of, let's take these three functions times or the dot product since it's technically a matrix. And so just saying times, we're going to say the dot product cause we're multiplying two matrices together, the Matrix of our features times or by competing the dot product with that.

Speaker 1:          29:51          And these, uh, these ideal coefficients that we defined before, plus sigma, which is the, which is the, uh, what was it? It was the variance of the noise. How spread out our data is times a normal distribution between zero and one for each of our data points. And, and so that's gonna give us the log odds, which we can denote up here. Okay. And once we have that, then we could say, okay, so those, that's, those are the log odds and we want to compute the probability sample from a binomial distribution. Okay. So a binomial random variable is a number of successes. X has an end repeated trials of a binomial experiment. A probability distribution of a binomial random variable is called a binomial distribution, right? So we have some y output value and it's going to be between zero and one. And so we'll just compute all those probabilities, like using this, so randomly generated probability values.

Speaker 1:          30:51          Okay. So then we can create a data frame that's going to encompass our input data, our model formula and our outputs, right? Just like this. So these are our expected output. So we generated these outputs randomly, but they are expected outputs. So compare the expected outputs to our predicted outputs and want to minimize, uh, the difference between them. Okay. And that is our learning process. All right. And so if we were to print this out, we would get all these randomly generated values and notice how we don't just, we don't just have, um, we don't just have values for our three variables are our, sorry, our three features. We also have values for each of the acts and then, uh, uh, the squared plus Z. Okay. And so, which is all a part of our model, our formula, our function that we're trying to learn here.

Speaker 1:          31:41          Okay. And so we have that now we've defined our data and we defined what a logistic regression is, how we optimize it, Newton's method, we've defined our data. And now we can have this helper function, which is going, which is just going to catch matrix errors. That's it. It's not even, I wouldn't even really need it anyway. So now it's time for us to, for us to learn our model and the way we learn our model is by performing Nunes method for optimization. And so the way for us to perform Nunes method is, is like, so okay for logistic regression, here's how Newton's method works. So recall that Nunes method from maximizing or minimizing a given function f of its coefficient. So function given the Beta value iteratively computes the following estimate. Okay. So the ideal coefficient is going to be whatever the current coefficient is minus the Hessian, uh, the Hessian of our function or the inverse of our Hashan Times the gradient of our function.

Speaker 1:          32:45          And so that's, uh, how we, that's the high level of Newton's method for logistic regression. Okay. So the Hessian, how do we compute the Hessian of the log likelihood for logistic regression? The way we do that is like, so we say the Hessian of our function is equal to the negative transpose of n times p plus one, which is what x represents n times p plus one times end times. And a, an end times end diagonal matrix of weights where each of these weights is p times one minus p times x against, we already defined X. So, so multiply again. Okay. So I know there was a lot to take in, but that's the formula. That's the formula for computing the Hessian. That's the formula for our Hessian and then the function. Then the formula for our gradient is much simpler. It's our gradient is the transpose of acts, uh, times a column vector minus n vector of probabilities.

Speaker 1:          33:48          By the way, n is the number of data samples samples we have. And the gradient is a vector of comp whose components are the partial derivative with respect to each coefficient we have in our function. Whereas the Hessian is a vector where it's competing, not the partial derivative but the, but the partial derivative of the partial derivative. So it's a derivative of the derivative. It's a second order derivative. So if you were to say, um, uh, x cubed is your function, the derivative would be power rule three x squared and but, and then the derivative of the derivative would be six x. Okay. So that's how that works. And so by the way, and so this is what, uh, that w looks like it's a diagonal, which is if you were to have a matrix of values, you would just take the diagonal of that of p times one minus p where pure the predicted probabilities computed at the current value of the coefficient that you have. Okay. So and so you can connect this to something called iteratively reweighted at least squares, but we're just not going to do that. That's, that's, that's for a separate time has just for it more understanding, but in fact I think it would be more confusing because we haven't talked about that right now anyway. Right? So to perform Newton's method, which is a second order optimization technique on logistic regression, we're going to compute both the Hessian and the gradient and we'll use both of those values to help find the optimal, uh, coefficients for our function.

Speaker 1:          35:26          And logistic regression is basically on one side, it's a gem. It's a generic regression function. You know where you have some set of coefficients for any number of parameter values for any number of features or dimensions. And on the left hand side, you're not trying to equate it to a single scalar that maps directly to that, that output. But instead a probability value that is the log odds, the log of the probability over one minus the probability, and this is going to come out to an s shaped curve. So you can then predict the outcome of some event or the class of what something is going to be, which is going to be a discreet, a single value. Yes, no, or even multivariate, uh, or even a multivariate output like red, blue or green. Okay, so right now let's talk about the implementation here. So we've talked about the equations.

Speaker 1:          36:23          So let's look at the code part now. Okay. So the first thing we're going to do is we're going to compute the probability value. And to do that we're going to compute the dot product of our coefficients are ideal coefficients. And our w are coefficients that are, that are to be learned, the coefficients that we're learning. And then we'll squash those values with a sigmoid function. Squashing means we're converting them into value between zero and one. And then we're only gonna do that for two dimensions. So that's why we have the MDM NDM men equals to a parameter. And then we're going to take the transpose of that. And so for, for major CS competing, the transpose means taking the rows and the columns and flipping them so the columns become the rows and vice versa. And that's just one of many matrix operations that we do, uh, to keep it simple right now it just makes things easier.

Speaker 1:          37:16          It makes it more organize and format it for, for the next operations that we're going to do. We'll talk way more about matrices later on anyway. So that's how we compute our probability, which is going to be an array of values. And then we're going to use that probability to help compute our weights, which are, as we set up here, right up here, the diagonal of the probability times one minus p. Okay. And so we'll have that here. And that's our weights. Those are our weights and we'll use our weights to derive our Hessian. So remember this was a formula for the Hessian. The negative negative x x is transpose times w times x again, right? So in the case of logistic regression, that's how we compute the hash. And you can see variable by variable. That exact equation is then mimicked here programmatically to compute that Hessian.

Speaker 1:          38:06          And the same case would be for our gradient, right? So our gradients is going to be x, x is transpose times, we're going to take the transpose of backs and compute the dot product of it. And then y minus P, right? We're why are predicted outputs and then PR probability values. And that's gonna give us our gradient value. And this, remember, this is all phrase single step. So this is for a single a collection of data points, right? And we have a, we have to go through all those rows and columns, right? But there's a very single step and we have multiple steps during training, okay? So that's our gradient, our Hessian, our weight values, and our probability values, okay? And we're going to use all of those. We're going to use them, Paul, to help us. Well, we, we use a Pete, we use P to help us compute w which we used to compete our Hessian and our gradient as well.

Speaker 1:          38:59          But basically we're going to use both our Hessian and our gradient to compute what the optimal weights should be. Right? So to compete, to do that, we're going to take the least square solution. Um, but actually, so, okay, so I, okay, so we do this twice. We do, it's once this Newton step, and this is basically a copy of what we just did before, except for one thing. And that's this line right here. Notice how right here I have Lynn alledged. Dot. Inthe versus Lin alledged. Dot. Ella lst, LSTs s Q, which is least squares. So the reason that it's here twice is because right now we're computing, uh, the, the announced or the scalar that we're going to use to update all of our coefficients, but we're doing it using the full Hessian. Right? And so the reason that we did it two ways is if we use the full Hessian, it can be computationally expensive because there's a lot of values.

Speaker 1:          40:05          But we can get around that by using a, by not computing the full Hessian but using a solution called lease squares. And that's called the, so if we don't have to compute the full Hessian, then that's computationally less expensive, right? And so there are methods for doing this and these are called quasi Newtonian methods, or we don't compute the full Hessian, but we don't actually have to talk about that. We'll just assume that we have to compute the full Hessian right now. Okay. So that's what this line does. And it uses the regularization term we defined before to make sure that this data is not overfit. Okay. So that's what those into a Newton step. And it's going to return this scalar value, this Beta value that we can use to update the coefficient of our function that we're trying to learn. And yeah, so then we have a convergence steps.

Speaker 1:          41:00          So remember how we defined a threshold. That threshold is when we want to stop learning, right? So given our old Beta values, our new Beta values, and then our tolerance get an a number of iterations, we'll check the change and the coefficients by taking the difference and making him performing absolute value because we wanted it to be a positive value. And if the change is greater than our threshold and we still have less iteration and we have, um, a certain number of iterations still to go, then we'll return true or false? False. Okay. So that's our way of stopping training. Okay. So then to the real meat of our code, right? So we'll go ahead and define our initial set of coefficients. And these are our wake values, right? That we want to learn. If they're all going to be Zeros rights for the number of columns that we have, which are the number of features, or they'll, they'll, they'll start off at zero and we'll learn them over time given some number of iterations and, uh, a boolean value that tells us if we've reached convergence or not.

Speaker 1:          41:59          So this is our way of saying should we keep training or not and that that's what this is going to do. So we'll say while not coefficients have converged. So if we haven't reached convergence, then go ahead and begin training using Newton's method began optimizing. So we'll say we'll set the old coefficients to our current values, perform a single step of Newton's optimization on our data. And once we have that, we'll then take our coefficients and it's going to output the updated a Beta values. Okay. And so then once we have our updated Beta values, then we can increment the number of iterations that were going through and then check if we've reached convergence yet where our Beta values are the coefficients for the model that we're learning. And we can say, hey, if these values are at this certain threshold, we're good. We're done here.

Speaker 1:          42:52          Okay. So then when we print out the results, it's going to tell us the number of iterations and then the Beta values over time. And ideally they become closer and closer to our predefined Beta values for our dataset. I know that's a lot to take in, but if you've got the basic idea of a logistic regression being different from a linear regression and that it's trying to predict the probability of a certain outcome, not just some strict linear mapping between x and y and that we use Newton's method as a way to optimize logistic regression and the w the way we compute Newton's method is to compete the second derivatives with respect to each weight in our, in our function, the coefficients, the weight values. If you got that part, that's all that's really necessary for this video. There's a lot of terms that we still have to go over a lot of probabilistic terms like variances, very NCS and and noise values. There's so much more, so don't worry about it. There's a lot, and we're going to go over that and then the rest of this series, so that's it. Please subscribe for more programming videos. And for now I've got to Ryan Beta with Alpha and Beta, so thanks for watching.