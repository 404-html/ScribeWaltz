Speaker 1:          00:00          Starting broadcast. All right.

Speaker 1:          00:07          Live stream is starting soon. We got people in the house. Hello world. It's Raj. Good to see everybody. We are here or I am here in Portland, Oregon. Uh, just for a week just to check it out, see what it's like here. It's actually pretty cool up here in the Pacific northwest. Hi everybody. I'm going to list some names. Uh, everybody who's here. Alexandros Radu Marco Max. David said to Raphael for Ya. Sausa hi everybody. So Yasha um, today we are going to, uh, make a bot for the game of asteroids and we're going to, uh, have it get better and better at the game until it's able to beat it. And it's going to use a technique called neuro evolution. It's called neuro evolution. Okay. Uh, that's the name of this technique. And uh, we're going to do this in javascript. Okay. And this is a part of a collaboration with another youtuber named Daniel Shiffman, uh, that I am excited to do. Okay. So that's what we're going to do. I'm going to start off with a five minute Q and a like always. And then we're going to get started with the code. All right, here we go. Five minute Q and. A. Let's do this. I'm doing pretty well. I'm excited to be here in Portland. I'm going to make an experimental video here.

Speaker 1:          01:36          Is Dan joining live? Know which tool do we have to use? It's going to be just pure javascript neural evolution. Like a genetic algorithm. Yes. Hi from Israel. Did you go to nips? I didn't go to nips. I didn't go to nips. But next time I will for sure. Are you building the game to not the game, just the Ai Code. You should come on up to Seattle. I would love to. I would love to, um,

Speaker 1:          02:04          advice for upcoming computer scientists. Um, find a paper that you really like, just find a paper that you really like and then try to replicate it. And then if you need help using an advisor or someone who has a lot of experience. But I found that replicating papers has gotten me really good, really fast. Uh, add a lot of, uh, at least for ml, and I'm sure, I mean, the same can be applied to computer science theory. What do you do? Saroj I do this youtube channel fulltime. Any news about rocket AI? Guys, I'm sorry to break the news for you, but rocket AI is a total hoax. It's not real that everybody was in on it. They trolled everybody. Tim portally, recurrent optimal learning troll. Okay. That's the acronym. Are you drinking coffee? Yes. What can a high school do in machine learning right now?

Speaker 1:          02:47          Um, you can get started with TF, learn or a psychic learn. Those are two great libraries to get started with. Find a Dataset on Kaggle and then run a model on it and see what you can find. Well, you ever cover where you cover other AI concepts beyond neural networks? Absolutely. Um, tensorflow versus care Os. Um, tensorflow, which AI tool will you be using in this video? I'm not. I'm using pure javascript. Um, uh, please buster wrap on screen right now. I will say that till the end for the end. Uh, papers from where I triple e archive. Arx id.org archive is a good place. Shall I tweet you for technical help? Yes. You can tweet me at the same time. Remember we have a community guys. It's not just me. We're all here to help each other learn. So there's a slack channel with a link in all of my videos, so all remember to always ask questions there as well.

Speaker 1:          03:39          Um, two more questions and then we're going to get started. Thanks to Alexander. Uh, is that a promise about busing the wrap? Yesterday's did you please remind me though difference between Siri and Google? Uh, Siri is a worse in every way because like, wow, apple, you just totally missed the boat on AI and just now you just like publish your first paper. Congrats. Um, but Google now is just like way better. Like they're, they're the, the learning algorithms they have the data that it's trained on. It's just way more. What do you think about octave? It's not that great. How do I implement decompression by song? Hahn? Deep compression? Well, first of all, anything with compression and neural networks, it has to do with an auto encoder. So you're probably going to use an auto encoder. The word deep implies many layers. So like lots of layers and the specific one that he made, I haven't seen, but show me a Lincoln, then I might make a video on it. Okay. So those are my questions. Those are my questions. Um, now we're going to get started with the code. Okay. So I'm going to go ahead and screen share. Let's do this.

Speaker 1:          04:43          All right, so I want to start off by showing you guys a demo of this code so you can see what it looks like. Okay. I'm going to show you guys a demo of this code. So, oh, look like this. So what happens is,

Speaker 2:          05:04          okay,

Speaker 1:          05:04          uh, Amy ass playing and many different generations, many different, uh, space, uh, ships are created. Uh, this is, so, this is neuro evolution. I'm going to talk about what's happening here, but as you can see, it's just there are a lot of them that are being spawned, a lot of ships and they're all trying different moves. And the one that has the best move is the one that's going to survive and reproduce and create a better one. And so over time it's going to get better. But you can see here that the basic idea I want to show you by looking, by showing you this, uh, game is that, uh, these things get better over time and there are many of them, many of them that respond. Okay? So that's the basic idea. I'm, the link will be in the code. Okay?

Speaker 2:          05:46          Okay.

Speaker 1:          05:46          Are we lagging? We're lagging. Cool. Okay, so now let's go ahead and get started with this. Um, I'm going to go ahead and get started with the code. I'll make this bigger so everybody can see what I'm typing. So this is going to be neuro evolution. That's the technique we're using is the technique. Okay? So that's a technique that we're going to be using. And uh, yeah, so there's that.

Speaker 1:          06:11          And so, so that's what we're going to do. And so what happened? What's happening here is like what most, uh, learning methods focus on modifying just the strength of the neural connections. Uh, this doesn't, this modifies not just, uh, the neuro connections. It modifies the actual structure of the network. So adding neurons, um, it's, uh, adding connections. It's uh, and even, uh, modifies the learning rates. So a lot of hyper parameters are modified by this. It's not just the connections. So that's what makes it different from like, from regular, uh, backpropagation. Uh, okay, so bigger font, okay, let me make it a little bigger. Okay. Boom. That's a technique that we're going to be learning. Uh, and this is a type of reinforcement learning. This is a type of reinforcement learning that's we're going to be learning right now. And because it's happening through trial and error, uh, so what's going to happen is we're going to do, and the reason we're doing this is because the optimal actions at each point in time are not always known. Like, remember, this is a game. This is a game. Uh, things are random. Things are random. And neuro evolution proves to be a good technique for this because it, you're able to optimize behavior given only a sparks feedback. So as far as feedback is available is available. All right? Um,

Speaker 2:          07:35          okay.

Speaker 1:          07:36          But that's what's happening here. So, so the steps are, we're going to do this in increasing order. So we're going to go ahead and create art, neuro evolution, uh, object. But in that we're going to create increasingly larger, uh, objects. So the first one is the neuron and the next one is the layer, then it's going to be the network, then the genome, and then finally the generations. So as you can see, each of these gets bigger over time. So I'm, so we'll create new revolution as our big master object. Then we're going to create a neuron, a. And so a neuron it, there are many neurons inside of a layer of a network. And then there are many layers inside of a network. And then each network is considered a geno. A genome is another word for individual or being in a, in, in what's called a generation. Okay? So there's a generation, a generation has multiple genomes. Each genome has its own neural network. Each neural network has its own set of layers and each layer has it's own set of neurons. Okay? So it's all obstructions. Okay? Everything is, um,

Speaker 1:          08:38          all right, everything is just like this. All right? So, so that's what's happening right now in sports. Feedback means that you don't have a lot of feedback. Like you don't have a lot of data. The word sparts is applied to data. What? We don't have a lot of it. So if there's a lot of zeroes in our data, uh, that, that would be sparse. Okay? So let's go ahead and get started by doing this. Um, all right, so let's go ahead and create our first variable. It's called neuro evolution, neuro evolution. That is our big master variable and it's going to be a function and we're going to get options. So what are these options? Options are another word for hyper parameters. And I'm going to talk about what the specific hyper parameters are for this. Okay? So we're going to start off by defining defining ourself self variable.

Speaker 1:          09:16          By calling this, okay, that's the first step. Now we want to create those options. So remember, options are, are hyper parameters, um, is unsupervised learning. Indeed. Exactly. Um, options are, are hyper parameters. So we're going to start off by saying the first option we want is our sigmoid function. Let me talk about what the sigmoid function is, but first let me type it out. So sigma is an activation function, okay? Um, sigma is an activation function and it's a function that we run in every neurono bar network. Okay? So let me write, write this out. I'm going to create a variable called AP that is negative a over one. And then I'm going to return this equation. What does this equation, well, this is the actual sigmoid equation and it is a static equation. Let me explain the hyper parameters in a second. But this is a static equation and what it's doing is it's converting every number into a set up into a probability.

Speaker 1:          10:13          So this, this sigmoid is run in, this function is run in every neuron of our network, okay? And it's how we can convert our numbers into probabilities. Return. Okay, return. What are hyper printers? Hyper parameters are the tuning knobs of our network. They change over time. Okay? They are the tuning knobs of our network. We could change what they are. Okay? And I'm going to show you a list of hyper parameter in a second. The next function we want to create, it's called random clamps. Okay? Random. Uh, it's called random clamped. And what this function does is it returns a random value and we can use that to generate weights as well. So that's a different point, but we're going to use this to generate a set of weights later, okay? And

Speaker 2:          11:00          okay,

Speaker 1:          11:01          so there's that. And I want to return math dot random. We're going to use the random function. We're going multiply it by two to make sure it, that the number is big enough for us. And it's a crack by. Whoa. Okay. So there's those, there's that. Now we're going to create our list of hypochlor amateurs. The first one is going to be a population, which is the size of our population, right? How big do we want this, this population to be? The next one is called elite elitism. What? It's Alita zone. This is the, this is the number that we're going to apply to each of. So, so, so elitism is whenever, um, we are, uh, so let me give you a quick explanation of, of, of, of uh, genetic programming for a second genetic algorithms. So you, you have a population, so it's step one is a, you have a population and then what happened is they performed crossover, which is they, they, they breed together and then the end result is then you, those children and you keep going, right? There are three, right? So, so, so you select the best ones selection and then you perform crossover. You take those and you make them. And I'm going to show you guys what mate means in this context and then we're going to mutate them. And so this is what elite tourism does. Elitism is dealing with the mutation. Polytheism means we're taking how w 20%. Right? At 0.2. So we're going to take 20% of the best offspring. Okay? Um,

Speaker 2:          12:20          okay.

Speaker 1:          12:20          So that's what's going to be happening. Um, so right now we're going to say random behavior is, is going to be a 0.2. Okay. So what does random behavior, um, ran behavior is the new random networks for the next generation. So the rate, so how, how, how, how random do we want this to be? Right? The next one is the mutation rates. You Taishan rate is saying, uh, what the, the rate of the, that we're updating the synapsis, how, how much do we want to mutate them? Okay. And then we have a mutation range. Okay. Uh, why the tradeoff between 20%? Good question. Uh, 20% as opposed to something larger, like I don't know, more than 50. You want something that's less than 50, because you only want the best ones, you only want the best ones and you want to diminish the rate, uh, that, that you want to diminish the, the rate that the population is, is a breeding so that by the time your son, uh, first of all, it's faster that the network trains faster and you only have a few at the end. Okay. Um,

Speaker 2:          13:21          okay.

Speaker 1:          13:22          Okay. So there's that. So the mutation range is going to be 0.5. Then we have our actual network. So the network is going to be one. Uh, and so what is the network? Well, now I'm defining, um, now I'm defining the size of the network. What does that mean? It means, uh, uh, like the, the structure of the neural network. I want one layer. Okay. I went three of them. So this is a three layer feed forward neural network. Okay? So that's the network. And let me define that as an array. So that's an array. And so now we want another hyper parameter called historic, which saves the adult, the latest generation that's safe. That's what it's going in store. What's the last generation? Right now we'll initialize it as zero because there are no, uh, generations right now. The next one is going to be low historic.

Speaker 1:          14:07          So we're only going to save this the score, right? It's a boolean that says like, we're only going to save this score. Now we want to sort sort it, right? So we want to sort it up till negative ones. So what order do we want this sort things in? We're going to sort it right now in the sending wardrobe because it's negative one. If we wanted it to be positive, we would do positive one. Okay. This is a Bot. So now and be trialed one. All right, so this is the number of children that we want to breathe. Okay. So that's it for our a hyper parameters. Let me just move that up, that different hyper parameters and now we can go ahead and initialize. Yes. All right, so let me go ahead and move that here. I see. Okay. So now we're going initialize our are set variables to have options available.

Speaker 1:          14:55          Okay. So what is this? Now I'm going to um, behave. Oh, good call typo on behavior. Behavior. All right, great. And variables. No variable. It's not very, almost scary though. So we want to create a sense, what do I mean by a sec? We want to set up options. We're going to initialize that like this. Um, okay. So, um, so now that we've initialize our variables, we're going to say, we're going to loop, we're going to do in this loop, we're going to say for every option that we have, for every option that we have, I want you to do to, uh, say if, if, if there's nothing there right now, then I want you to fill it into our existing list of, of options. Okay. Uh, got to add those in. Okay. So I've got up my comments here. Okay. So then if the option is there and it's not defined undefined, then we are going to add it to our options are ray. Okay? So we want every option to be, uh, in my options are ray. Okay? So options up til I, alright, so now, um, so there's that. And so now let's create our neurons. We're going to create our neuron. Um, all right, so our neuron is going to be, um,

Speaker 1:          16:24          it's going to be a function to, so the neuron has an internal value and as, as it has a set of connections to every other neuron in the next layer. Okay. So we're going to define both of those to, uh, uh, uh, both of those two variables. Okay? So the first one is the value. It's going to be zero. Like what is the value of this neuron? Well, if we're going to initialize it a zero and then the weights or connections to every other node, which we were going to store in an array which is empty right now, the next step is going to be to randomly initialized our weight values. Uh, we want, we want them to be distinct. We want them to be distinct, okay? All right? So now

Speaker 1:          17:08          we want them to be distinct, right? So let's go ahead and do this. So the first one we're going to do is we're going to create a, we're going to create a neuron. It's going to be a prototype objects, which is the higher level, uh, object. And we're going to, we're going to create our population function, okay? Or we're going to populate it, but, and we're going to do this by randomly initializing wait values, okay? So let me show you what I mean by this. Well initialize a function and the perimeter is going to be n be okay, which is, uh, the number of weights that we once a why randomize the weights? Uh, because, uh, well I mean there are many, many methods of like, like how do initial initialize weights random is the most popular, but there could be a better, a more, uh, more, uh, more, uh, efficient way of doing that.

Speaker 1:          17:55          But right now, uh, and that's an area of research as well, but generally we randomly initialized our weights and then we make them better over time. But just like randomly sampling data, uh, it could be, we could do that better as well, but random is just an easy way to, to start off. Okay. So we'll initialize our, uh, weights array and uh, we're going to iterate through every week that we're given. So bar I equals to zero. I is less than the number of weights. And then I've left plus, okay. I put flux. So we're going to say add every weight to the list of weights that we have and what are we using? We're using that random clamped function to add a randomly initialized set of weights to our weights array. Okay, so that's for our neuron. Now let's do our layer. Remember we're increasing the size of, of how big we are in a of the objects that we are creating every time.

Speaker 1:          18:52          So we did our weights and now we're going to do our layer. And the layer has an ID and a number of neurons. Okay? Those are, it's too, uh, attributes, an ID and a number of neurons. So we'll start off by creating our layer. Uh, and I'll definitely do a recap at the end of the code. Uh, so we'll start off with creating a layer. And a rent a layer is going to be initialized by this index variable that is the parameter of the index parameter. And what does that mean? Well, that's going to give us our ID. That's how we initially, that's how we identified this layer, right? So it's going to be index or zero. Okay. And so then we want to initialize our neurons. How many do we have? We create a layer, none. So it's still gonna be an empty list. Okay. It's an, uh, it's going to be an empty list. Now we are going to create our layer prototype prepopulating the lake. Okay. So we're going to populate the layer with, um,

Speaker 1:          19:43          thank you for that. Uh, options. That was a typo. Now we're going to populate the layer, uh, with neurons, okay. Which we've just created. We've just created neurons, okay. Layered up prototype to populate. Uh, and we want there to be two parameters, the number of neurons and the number of inputs. What are the input going to be? It's going to be the set of actions that we take during the game. Okay? That's what we're going to update our way Twitter. So we're going to initialize an array of neurons and we're going to say, okay, so we're going to iterate through every single one of our neurons and we're going to add them all to our layer. Okay? Um, let me see this question. Can a layer be iterated or is it explicitly specified? We can, uh, we can iterate through the layer. Um, generally, uh, in machine learning, we don't update the number of neurons inside of a layer.

Speaker 1:          20:36          We don't update the actual layer itself other than the, uh, weights. But in this case, in neuro evolution as opposed to just regular backpropagation neural evolution in neuro evolution, we modify all parts of the network. We can modify the number of neurons in each layer. We can modify the number of layers, all, nothing is safe from neuro revolution. Okay? So it's not just backpropagation, we were not just updating the weights. We're updating the entire neural net, okay? So we're going to iterate through the number of neurons and we're going to say initialize our first neuron. It's going to be a new neuron object, okay? So we're going to say we want a new neuron. And this is, remember, this is a class that we've just created and we want to use that populate function that we already wrote, given the number of inputs, okay? So that's the parameter for that populate function.

Speaker 1:          21:24          And then when we're done with that, once we populated, uh, uh, the number of neurons, we can just push those neurons, uh, to this, this layers, uh, array. Okay. So we can just by using the push function, okay. So that's our layer and now we're going to go even higher. What was the next step? The network, right? We've created our neurons, we've created our layers, and the next step is the actual networking sets. Okay. And a network consists of layers. So it's initialized our network, uh, variable by saying, well, what does a network habits think about this? A network has a set of layers. That's it's though that's the activity that has. So we'll initialize a layers, a parameter. Okay. So the number of layers.

Speaker 3:          22:04          MMM.

Speaker 1:          22:05          And now that we've initialize that, let's go ahead and create a prototype for, uh, giving it the layer parameters. Okay. So we're going to call this prototype. Um, we're going to call this prototype,

Speaker 3:          22:20          uh,

Speaker 1:          22:21          perceptron generation. Okay. Because that's another word for neural net. Perceptron although it's not as sexy, like people don't use it as much. But whenever, um, you know, usually whenever genetic algorithms come into play, someone like throws around the word perceptron. Uh, but I think neuro evolution in genetic programming, it's going to make a huge comeback. Like, like it had a taytay in the 80s, and then people kind of gave up with it. But like, I think we're going to see some great results. It's actually coming out of a opening the eyes universe like this, that sandbox environment. There's a lot of possibility here. Uh, which makes me very excited about it. Okay. Anyway, so what we're doing here is

Speaker 3:          22:56          mmm,

Speaker 1:          22:57          uh, noted. If Jess, Jess is a little confusing for beginners. Noted. Okay. So we're going to create, what am I doing here? So I'm creating three variables, right? Be Index the number of previous neurons and in the layer that we're on, which we're going to initialize because we just created that using the index as a brander. Okay? So what we're about to do is, well, first of all, we want to populate the layer because we are creating a neural network. This is going to create the network itself, okay. By creating a stack of layers. Okay? Okay. So that's what we're doing.

Speaker 3:          23:28          Um, uh,

Speaker 1:          23:30          I knew there would be a Westworld reference at some point. Some of one, one of my friends was like, dude, you need to watch Westworld. Someone on your channel is going to mention it. It's going to be great for me and been references. So you need to start watching it. And Lo and behold, someone has mentioned Westworld, so I might need to check up on that show. Anyway, so, so we've created our three variables here. So let's populate the layer with the inputs that we've already created. Right up here, we have our input, we have our, um, let's see, we have our previous number of neurons. Okay. So each of our layers is going to be populated just like that. And we're going to add each layer to our existing array of layers. Okay? So later, that's that. And then we went to the index. We're going to iterate through the index and the index tells us which layer we're on. Okay? So we're going to iterate that, that index a counter variable. So now we're going to go, we're going to iterate through every single, uh,

Speaker 1:          24:25          layer in our network. And we're going to, we're going to add it to our, uh, we're going to iterate through, sorry, we're going to tech with a technical term for this is we're going to iterate through every single layer in our, a list of layers and we're going to add that to our network. Okay? So we've stored a list of layers and we want to add each of them to our network. It's, we'll initialize our first layer and this is for the number of hiddens. And what do we mean by hiddens? Hiddens is, uh, the, the, the number of hidden layers that we've, that we've specified in the parameter. So we say, so for each of these layers we went up to populate it with a number of, of kittens. Okay. Um, oh, sorry. Never, no. Let me Redo the UN. So what I just said, undo that. It's not hidden. It's not number of hidden layers. It's number of hidden neurons. Okay. Um,

Speaker 1:          25:14          to answer your question bus card, yes. I will do a much more simple neural network tutorial a, it's coming up. It's going to be, uh, it's coming up in January. Okay. So, uh, so we were going to neutralize it by using the number of hidden neurons and a number of previous neurons. And why do we want the number of previous neurons? Well, we want to wait. We want something to point to, right? Because our weights are going to be pointing. Okay. So, uh, now we want to say, well, now that we initialize that layer while replace what we have in our previous neurons with whatever we have in our hiddens, right? Because we've, we've propagated forward and we're, we're replacing the old variable with a what we've already done. Okay. So now we're going to push this layer onto the list of layers and we're going to iterate that index counter variable.

Speaker 1:          26:02          So let's look over what we've just done. What we've just done is we've iterated through a number of hidden neurons that we were given into input parameter. We have initialize a layer. We have populated it with those neurons. We've, uh, set the previous neurons to whatever we have, whatever we had now, uh, and then we've pushed that layer to the list of layers. Okay. Uh, and so now that we've done that, we'll create another layer. And why do we want to create another layer? Well, there's one, there's one more thing that we didn't think about. We didn't think about the output. Remember we, we fed this function on out a list of outputs, right? That we want. So we want to create that last layer for just the health, but right? So as, so these are our hidden layers, right? So remember we created the first layer, which is our input layer.

Speaker 1:          26:48          We create a list of, sorry, a list of hidden layers and now we're creating art output layer. Okay? So that's what we're doing and we'll create it by, uh, initializing with the number of output neurons and then the number of previous neurons. And lastly, once we've created that, we can just go ahead and push it to our list of layers. That's it. Okay. So our input neuron was created. Our list of hidden, uh, sorry, our input layer, our list of hidden layers, and then our output layer. Okay. So now we've done that. We've created our network. Um, and before we create our generation, uh, before we do that, we want to create a set of a helper functions. Okay? So the first one I want to do is, is called compute. Okay? So this is an important step. So, um, computation step. Okay. So let's do the computations step.

Speaker 1:          27:40          This is an important step and it's a part of our network. So what do I mean by computation? Well, as data flows to our network, it's not static. Uh, we're, we're actually applying, uh, uh, we're applying operations to it, mathematical operations. And I'm going to talk about what these operations are. Okay? So, so the first thing we're going to do is we're going to check if the layer and the neurons are not empty and if they're not, we're going to assign it, uh, the input value. So we're going to check, we're going to say, okay, so check each of those input values. Okay, let me check ethers, those input values. And I want to see if, uh, uh, if the initial layer, uh, and the, it's number of neurons. So I want to see if it's number of neurons is empty. That's what I'm looking for. Um, uh, what's a neuron. Dot Neurons, uh, and then wherever we are right now. And so if there's something there, then we want to add it to our, the current, uh, layer that we're on

Speaker 1:          28:49          and we're going to say, uh, so whatever layer that we're currently on, add all of those neurons to it. Uh, and then, and it's going to be those input values, right? The input values. So, okay, so that was that introductory step where we actually filled that layer with, with neurons. Okay. So now that we've done that, now that we've done that, now it's time to, now it's time to actually do the computation. Okay? So what's happening here? We're going to, the data's going to flow to the layers. I'm going to apply an activation function to it, and then we're going to return the output. Okay? So let's do that. Uh, activation function step. We're going to say, okay, let's go to start off. Um,

Speaker 1:          29:34          this step is unclear. Okay. So let me, um, let me see. Okay. So, okay, so the function, so let's, let's talk about this. So what is happening here? I am, what am I doing? I'm updating the weights. Okay. I'm updating the way to using a sigmoid function. Exactly. So someone said sigmoid. Exactly. So that's exactly what I'm doing. So what I'm gonna do is I'm going to iterate through each of my neurons. Okay. So let's, so, so let's see. Iterate through neurons in layer. Okay. So let me just say it. Iterate their neurons in a layer. Okay. So for, um, Vivar I equals one. Uh, and I is less than this, the layers, the length, and let me to, let me, when did you better check a pistol? I Lutyens it'll never change. Let's see. Outside the loop, since it'll never change. MMM. Actually, actually, um, that's a good point. That's a good point. And we could just do that if we knew the size of, right. So we could actually write that differently. You're right. That's a good point. We could, we could write that differently. It's still works, but we could've written that differently. Right? It's just a null check. Exactly. Okay. So where was I? We want to iterate through every neuron in the layer. Uh, and where was I? So length, um, and

Speaker 1:          31:10          we've got iPad plots. Okay. So what we're doing re iterate through every neuron in each of our layers. And we're going to do a double iteration. So we're going to say four bars, j four j and this dot layers. Uh, so for the length of the neuron and then for each of the layers. Okay. So, um, so for this stop layers, uh, where was I was at? This isn't layers. I, uh, dot neurons then.

Speaker 1:          31:42          Where was I? Okay, so, so the first thing, okay, so let me talk about what we're about to do. Well, before I do this, I need to initialize this variable called some, and let me talk about what some is going to do. So we're going to initialize a variable called some. And with some is going to do is, uh, that is what we're going to apply the, the activation. We're going to use to create the activation function. So the sum is going to be if we take the previous layers, neurons, if we take the previous layer neurons, wherever we are with that, um, uh, and then we take the value, we're going to multiply that by this layer a weights. So that were, that were to the layer that we're currently on. We're going to multiply it by the weights. So this salt layers, uh, I uh, doc neurons, it's not as good as gradient descent. Um, I mean we haven't seen someone do it as well as, you know, state of the art, a gradient descent with backdrop. Uh, but I mean, think about it. I mean we, we've all been a in a, in an evolutionary environment. So I think there's still hope for uh, uh, uh, genetic programming in general. Okay. So we're creating this, the sum, right? And so this psalm is what we're going to apply to the, um,

Speaker 1:          32:58          we're going to apply it to the activation function. So I've created this loop and I'm going to say for each of those layers, neurons, j. Dot. Value. I'm going to say self duck options. Okay? So here's the activation function step. So I take that activation function and then the parameter is going to be the son that I've just calculated. So what happened here, the activation function is going to take the sum, which is the combined weight of the neurons in this layer. And I'm going to, uh, I'm going to,

Speaker 3:          33:31          uh,

Speaker 1:          33:32          run the activation function on that some, and it's going to convert that number into a probability. And so the probability is going to help the data decide where to flow. Okay? It's going to decide where to flow. And finally, once I'm done with all of this, I can just say, well, now that I've iterated through that layer, make sure that the previous layer is now the current layer where I, where I work, right? Just was, okay. Okay. So we've done that, that activation step. Um,

Speaker 3:          33:57          uh,

Speaker 1:          34:00          right? Okay. So let's go ahead and write our genome now. So our genome is just another word for a being or a, you know, a, a living, a living being inside of our generation. So each genome has its own neural network, right? So if you or I, or genomes, and we have our own neural network. So we'll call this genome. Okay. This function or this variable genome and genome has a score and it has a, uh, previous layer. Dot Neurons. Dot value. Is it, is it, let's see. Let's see.

Speaker 3:          34:37          MMM,

Speaker 1:          34:39          no. Okay. So, uh, for genome we're going to say a score in the network. Those are our two printers. And okay. So now it's time to, um, Jay does exist. Jay is a part of this bar. J up here on line one 22. Okay. So for far genome, I want to say, okay. So it has a score and it has its own network, right. And the score is like where it's at in the game and that's how it's going to, that's how we are going to keep tracking internally of how well it's doing and decide whether or not we want it to breed for the next generation. Okay. Uh, so we know those are our two attributes of score and it's network. Okay. So that's a genome. And then now it's time for that highest level object. We're ready to code our generation. And what is our generation?

Speaker 1:          35:23          A generation consists of several genomes. Okay? So at generation is just a list. We can think of it as a list of genomes and that's the only parameter that we have. Uh, the number of genomes. Okay. Oh, good call. Don't capitalize genomes. Genomes to deter. Okay, great. Uh, this stuff genomes and it's an empty list, right? So it's going to be an empty list. Awesome fitness functions for the win. Okay. All right guys. So let's go ahead and create our function for adding the genome to our a generation. Okay. So add the genome at a genome torque generation. So we need a function for this ad, a genome to current generation. Hey, let me just shut this off for a second. Okay. Okay. So for our current generation, Hi guys. Hi everybody. Um, okay, so let's go ahead and do this. So for our generation, we want a prototype that point to be called add genome. That's what this is. That's what this does. Okay. And we're going to say, okay, so given a genome, which is our parameter, we want to add it to this generation, that that's our task. So, um, we're going to say, um,

Speaker 1:          36:43          well we're going to say we're going to iterate through a, wherever we are, and we're going to say, uh, I is less than, uh, the length of the genome that we're apps, which says, okay, so what we want to do right now is we want to, uh, made sure that, uh, we are, uh, we, we have sorted it, right? So that's the first thing we want to do. We want to sort it, and we don't want to add a genome if it's not sortable. So we're going to create a check for that. We're going to iterate through the list of genomes and we're going to check the score. And if the score is less than zero, so if it's a bad score, then what we want to do is we, uh, that's, that's the first check. Okay. And there are two interjects. So if there's, if it's less than zero, and if this, if the genome score is greater than what we already have in our list of genomes or rapes, remember we have one in memory and then we have one that we're looking at, uh, gets greater than that score.

Speaker 1:          37:37          Then we just want to break because it's not going to be a part, it's not going to be in order. Okay. So we want to break. What's the other breaking? Uh, what's the other edge case? There's, there's one more edge case that we want to code. And that edge case is, let me back up a little bit and let me say else if the genomes score is less than where we currently, uh, what we currently have. If the genome score is less than this genomes a score, then we also want to break. So remember, we only want it to add it if it's sorted and if it, and that this, this prevents us from adding things out of order. Uh, and what do I mean by sorted? We, we're sorting by the score. We have a list of genomes and they are sorted by their score. So now we want to add our genome. Okay. So this stuck genomes, that splice. Okay. And splice is the, uh, uh, the verb that we're using to add the genome tool to our, uh, are our array of our list of genomes. Okay. So now let's write our breeding function. Okay? So we've, we've, once we've ticked the genome that we want, the next step is to breed them. So let's, let's say, okay, it's time to breathe. Time to breed that the down time to breathe. Okay? So, um,

Speaker 1:          38:59          so that's what we're going to do. And this is our, uh, breeding function. This is our last, uh, major function that we're going to write. Okay? So time's a breed. Ah, let's go ahead and write this. Write out this function. Okay. Stick with me guys. We've got a, we're almost done. Okay. So we're going to create a breeding, uh, uh, function. Okay. And what does a breeding function going to take as his cranberry? Well, it's going to take two sets of weights, okay. The set of weights from one parent and a set of weights from the other parents. Um, okay, so we've probably got about 10 more minutes. Okay. So everybody relax, sit back, enjoy the ride. Okay, so we're going to have, um, and a number of children, right? So these are our two parents and in a number of children, okay? That's what we're going to do.

Speaker 1:          39:46          A Pan. So we're going to do breed these two. So remember, these are two good networks, okay? We've, we've identified them as good networks because the scores that they provide are over a certain threshold that we predefined, okay? So what we're gonna do is we're going to iterate through the number of children, okay? However many children we want our at least parents to have, okay? So we're going to say NB zero. As long as it's less than a number of children that you've defined, we want to iterate through all of them and we're going to of course iterate through each of them. All right? So the first thing we want to do is create our, uh, data variable. And what does our data variable, dude, well, we take, we use the Builtin, uh, uh, Jason Function, uh, Jason Builtin parts function to, uh, get the list of weights from the first parent.

Speaker 1:          40:33          And if so, the weights are going to be just a huge mishmash of numbers, right? These are just a huge list of numbers. It's a matrix of numbers, but we want it to be machine readable for readable. Right? Um, and so if we want it to be readable, then we're going to, um, you know what? Uh, so he attached, it seems complicated and I'm going to get better and making it more accessible. But you know, it all depends on the syntax and this could definitely be less complicated and it will get less complicated over time as I do more live streams. So don't give up hope. Okay. Uh, and this is definitely gonna get easier over time. So Jason. Dot. Fi and what do we string string applying? Um, this is indeed a neuro evolution. Uh, okay, so we're gonna. So we're going to string a Fye the first wait so that it's readable and we're going to store it in a data variable. Okay? So now it's time for us to say, ah, let's do a little bit of, of, uh, of mutations. So we're going to take the first parent and we're going to iterate through, uh, every single list of weights in our networks. Okay?

Speaker 1:          41:40          MMM.

Speaker 1:          41:42          All right. So let's go ahead and say, Gee, not network a ways. By the way, you guys should next time for the next live stream. I didn't tell you this time, but you should totally be a coding along with me. Okay? So maybe not this time, but next time I want you all to be coding along with me, uh, in future livestreams. Okay. Uh, but for right now, just, just, just, uh, check this out. So we're going to iterate through all of the weights that we have. Okay. We're going to iterate through every single one of those weights and we want to now perform some mutation, right? So in order to mutate, we want to say, okay, well let's arbitrarily define some threshold. So we'll rent, we'll randomly generates a number using the math dot. Random function. Okay, we'll, we'll randomly generate that and we'll say, well, if it's less than 0.5, then we want to update our, uh, our weights from our, that we sorted our data variable, right? And the data variable is just a temporary variable that's going to store our weights and rep, right? So if it's, if it's rent were arbitrarily and randomly going to update those weights. Um,

Speaker 1:          42:46          now we've created teacher.network and we're going to, we're going to add all this weight from Jeetu. Okay, blah, blah, blah, blah, blah. So there's that. And so now we're going to add some mutation to each way. And so now here's the, here's the, here's the fun part. We're going to perform to mutation. And, um, so, uh, we've, we've mutated. So what's happened? Uh, we've mutated the weights in the temporary data variable, uh, using one of the parents, the weight of one of the parents, g two, and now we want to update the weights. Um, given, uh, this other, so they're here. Here's our other arbitrarily.

Speaker 1:          43:30          Okay. So a note it. So I need to heavily, heavily comics the code. Okay. So math dot random, uh, less than or equal to. So, okay, so what do we have here? So one of our hyper parameters was called the mutation rates. Um, the mutation rate defined like how fast do we want to mutate? So that's the kind of the arbitrary think are arbitrary number we're looking at. Um, but we basically want to say like, take those weights and update them by adding a whatever, random, a random variable times whatever our mutation ranges. Um, right. So like that's going to be, and we can tune that differently and that's going to give us different results, like for the mutation rate. Uh, and then we want you subtract the range. So we want it to be within a certain range. Okay.

Speaker 1:          44:24          But we've added some mutation. And now finally we can go ahead and say we've added our mutation, go ahead. And what we've just created a list of mutated weights toward data is variable. And at the very end, which you go ahead and return. So let me, let me write a comment as well. Return the list of Brita genomes. These are the genomes that have been bred. So these are the updated, uh, uh, more advanced, stronger, more robust neural networks, and that's just going to keep going into our, each new generation and they're going to get better over time. Okay, so let's have Brita genomes and we want to return to that. Okay? So that's the, that's the winner. That's the code that we're going to do. Let me go, go, go all the way up and I'm going to do a short walk through what I've just done.

Speaker 1:          45:10          Um, and so let me, uh, so remember this is the link to the demo code. If you guys want to see it on the web. I showed at the beginning, and let me show it again, uh, for a second. It is the game of asteroids. It looks like this, right? So many of them are generated many little spaceships and they're all trying out different things every time. And you can see them all dying. And once they're all dead, new ones will spring up. Okay. So it's just like that. And so let me explain what's happening here. Okay. So we're using something called neuro evolution, neuro evolutions at technique, okay? And this is, so here's, here's how we starting off. Okay. We want to create our neuro evolution variable. Then our lists of neurons are layers. Our network, our genome and our generation's. It gets bigger and bigger.

Speaker 1:          45:51          Each member, each object gets bigger and bigger. So it's a type of reinforcement learning because we are learning in real time from what the game is giving being us. Okay? So we will initialize our neural evolution, uh, variable, well, well, all of our hyper parameters that are going into a dark going to signify of how we're going to generate these, uh, uh, new neural networks. So remember, every spaceship has its own neural network, will define our set of options. And we'll start out by initializing our net neuron, our neuron variable. Each neuron has its value and a set of weights. Okay? And we went to randomly initialized each of those weights for each of those neurons. Okay? And once we've created a neuron will create a layer and a layer has an ID and a number of neurons, which started off as zero, but then we'll populate the layer by adding every neuron, uh, uh, by however many would define like number of neurons.

Speaker 1:          46:40          Then we'll create a network. And a network consists of a number of layers, which we just defined previously, which contains a number of neurons. And we're going to generate that layer by first generating the, and let me, let me, let me add a comment here. This is, um, uh, input layer, right? The input layer. Then we create our hidden layers and then our output layer by using those three parameters that were given input hiddens and outputs. Okay. And then we have a computation step. This is where we actually apply the activation function in each neuron of every layer in our network, we turn those numbers into probabilities of the score of, and the weights of, of, uh, of, of, of the, of each of the bots. And each of those is a genome, right? That's how we define them. As each, as a genome and a generation contains a selection of genomes and we want to add a genome to the current network.

Speaker 1:          47:29          I'm making sure that it's sorted in order and you will use a splice function to add it. And lastly, we'll breed our network by taking the weights of one of our parents, uh, mutating it, and then creating an entirely new set of weights in the state of variable, uh, by mutating the other one. And then we'll return the list of those weights and what we can use those ways to up update the next generation of, uh, of neurons. Okay. So now let me end the screen sharing. Okay. All right. So we'll do a last minute, uh, last Q and a and then we're done for the day. All right, so any, any last, last questions? Go for it. Ask me anything. Um, why does it need to be thwarted? And he said it's so, it's, it's better for computational complexity. If it's foreign it, then we can, uh, it's, it's going to be a retrieval is going to be faster retrieval for this force. Um, so that's just for computational complexity. Does it make sense a change in network and put what genetic algorithm? Uh, yes, absolutely. Um, well the network input is already going to change because the Games are dynamic. Um, uh, right. So there's that. What screen sharing app do you use? I use Google hangouts. I guess you owe us a wrap now. You're absolutely right. I mean decide what to rap about. Someone said something about care Os. Uh, Yo, I'm going to do this without it being okay. Here we go. Um,

Speaker 1:          48:50          I was trying out care Roth man. My life is so lost. I'm sitting here in Portland, man, what is this? It's like,

Speaker 1:          48:58          I don't want to curse, but horror horrorlands not really. And things are going wrong. My mind is so loose that I'm going all around. Okay. So that was that. Wow Man. Got that Portland jam happening right now it's on point. It is 10:00 AM on a, on a Wednesday. Everybody, it is 10:00 AM on a Wednesday for me. So that's, that's what happened. Um, uh, so that was my impromptu rep and how am I, I'm doing good. Am I going to test it? I'm going to add the code to the, uh, link description. Okay. So remember to check it out. Um, that just happened Brian. You're absolutely right. That just happened. It is a place. Um, I'm going to shoot an experimental video here and cool. One more question and we're good to go. Is there an easy way to save the data that's created by the network, um, in order to implement, in order to implement it? Uh, yeah, no, the data is saved and the data is variable and it's just a list of weights and we can, um, we can use those weights to update other types of networks as well. And that's that, that would be a part of transfer learning. Okay. So we could learn from one game and then ideally applied those weights to any game. And that's what deepmind did for the Atari DQ learner. Okay. Um,

Speaker 1:          50:15          do you have a job? No, this is my job data set of all reddit comments available. Anything in the future? I'm sure I'm going to do something with a red, uh, comments. Uh, I'm not, uh, in India. My parents are from India. I was born in Houston, Texas, and now I live in San Francisco, California. I'm new to the channel. What languages do you use? Mostly Python and javascript and ah, cool. Okay guys. Uh, uh, Tara didn't use a neuro evolution. Uh, they use something called the DQ learner. Okay. Uh, right now I've got to go. Um, did I dye my hair? Yes. What's new for 2017? Uh, my opus magnum opus, magnum, uh, my beautiful dark, twisted fantasy, uh, which is this new machine learning course, which I'm not going to say much about, but just know that something big is coming guys. Okay. Um, cool. So yeah, that's it for this livestream. Um, uh, thank you guys so much for showing up. I'll add the coaching, the comments. I love all of you. Thanks for showing up. Uh, during Christmas. I know, you know, you have a, a lot of things that can be doing. So, uh, for now I've got to go, uh, Heiko waterfall, so thanks for watching. I love you guys.