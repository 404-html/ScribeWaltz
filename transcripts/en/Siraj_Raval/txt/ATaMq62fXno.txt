Speaker 1:          00:00          Hello world. It's a Raj and life is pretty unpredictable, isn't it? Probabilistic programming is a technique that helps us build a AI that account for real world uncertainty and we'll use Uber's newly released tool pyro to help us understand how it works. Back when the glorious Soviet Union was still around, programmers wrote everything in the assembly programming language. They used three letter commands to control which data got stored on which register, which mathematical operations the CPU executed and which memory locations got copied to where. As you can imagine, this was really tedious work but it did allow programmers to create never before possible algorithms. After a while though they wanted more, they didn't want to have to worry about manually adding register values or copying numbers from one place to another. They wanted to focus on high level ideas like functions and data flow. So along came compiled languages like c and scripted languages like python.

Speaker 1:          01:11          These higher level languages let programmers do the same task with much less code. Fast forward a couple of decades later and deep learning coupled with big data is now the cool kid on the block processor speeds and storage capacity, you have skyrocketed in capabilities. So computers can process data like never before, which means programmers can build tools like never before, like one of the many possible deep learning models. The term model can be used to describe a decision making tool or a way of representing an idea using math. We use models every day to make our lives easier. A map is a model of locations. Sheet music is a model of sounds. Even our brain is a model of every decision we make. Models can be deterministic. That means that a given input will always produce the same output. There's no randomness involved like blink one 82 but most models are going to be probabilistic.

Speaker 1:          02:16          That means they take into account uncertainty, which the real world is full of applying the same input to this kind of model twice could lead to two different outputs. There are no guarantees. Modeling. This kind of uncertainty isn't easy. So lots of machine learning models that have been built thus far have been deterministic, but consider that pretty much all real world data is incomplete or imperfect in some way. So having some kind of prior knowledge of probabilities helps us make predictions. This is what Bayesean inference helps us do. We make prior assumptions about how the world is before making predictions. We represent these assumptions as numbers and can update our model based on our observations. When programmers started to implement this kind of model programmatically, they started to realize that, hey, this is actually pretty complex to do. It's not about keeping just a few probabilities in your head.

Speaker 1:          03:20          You have to keep track of the whole probability distribution. So ideally we need the probability distributions to be at the heart of the program. Since they are what is being manipulated. All other elements should revolve around these probabilities. But with traditional programming languages, they're only used in obscure sub routines at their most basic level. Probabilistic programming languages differ from deterministic ones. By allowing language primitives to be the castic. The point of running the program is not to find out what happens at the end. It's to figure out the correct values for the variables that define our probability distributions. What do we think the world is like? What kind of distributions with which kinds of parameters have the expressive power to mimic the real world? Most probabilistic languages are built on top of existing languages, but they're distinct enough in the way they work that they can be viewed as a language instead of a library, one of the most popular ride sharing apps in the world, Uber has to match riders and drivers to get them to where they need to go as fast as possible.

Speaker 1:          04:35          This simple task requires optimization at every single step, optimal routing, sensible pool combinations, deciding optimal timings, avoiding harassment lawsuits. So in order to help solve these problems and specifically model the uncertainty of the real world, they've developed a probabilistic programming language called pyro that lets engineers and build models that use Bayesean deep learning. It's written in Python and built on top of the popular Pi Torch programming library. Pi Torch offers very fast tensor math operations and automatic differentiation, Aka gradient descent, a popular optimization strategy, both of which help make computation faster and easier to create. Pie Torch also offers dynamic graph definitions instead of static graph definitions. In tensorflow, for example, you define a graph before you run it. In Pie torch, you define change and execute nodes in the computation graph as you go at runtime, and this approach of feels more native to python. The basic unit of pyro programs is the stochastic function, which helps us explicitly compute the probability of the outputs given the inputs.

Speaker 1:          05:52          For example, if we want to draw a sample x from this unit normal distribution, then we could just do the following, define a mean and unit variants. Using variables from Pi Torch love you fast heads or math and we can compute its log probability according to a normal distribution. We can also return a sample using a named stochastic sample using the pyro sample. Primitive naming allows pyros backend to uniquely identify sample statements and change their behavior at runtime. Depending on how the enclosing the Catholic function is being used. If we had a bunch of data of daily mean temperatures and cloud cover and what to reason about how temperature interacts with whether it was sunny or cloudy, we can write out a simple stochastic function that says use pyro dot sample to define a binary random variable, cloudy, drawn from a distribution with the given parameters.

Speaker 1:          06:51          Then convert the value to a string so that a returns values of whether that are easier to parse. According to this model, it's cloudy 30% of the time and Sonny's 70% of the time we defined parameters we use to sample that temperature that depend on the particular value of cloudy. We sample in line three then we return the two values of cloudy and temp at the end, whether specifies a joint probability distribution over to named random variables, cloudy and temp. So this model helps us reason about how likely it is to be cloudy or sunny given a temperature. And because pyro is embedded in python, stochasticity can effect the control flow. For example, we can construct recursive functions that terminate the recursion randomly three summary points. Probabilistic programming is a technique that models the uncertainty of the natural world by embedding randomness into the models that we built.

Speaker 1:          07:53          Basie and inference is a probabilistic methodology that lets us use prior knowledge to make predictions and Pyro is a probabilistic language built using python and Pi Torch that lets us build Basie and deep learning models that are scalable and efficient. Last week's coding challenge winner is Shannon Code who successfully built a demo that uses a blockchain and AI together. He used open Ai's world of bits environment to train a reinforcement learning agent and the AI stores the training results on an immutable public blockchain. Great first steps to getting a fully autonomous training agent for can start his repo wizard of the week. This week's coding challenge is to use pyro to create a simple Basie and regression model on a Dataset of your choice. Details are in the read me get humbling. Go in the comment section and the top two submissions. Get a shout out for me next week, please subscribe for more programming videos, and for now I've got to go update my priors, so thanks for watching.