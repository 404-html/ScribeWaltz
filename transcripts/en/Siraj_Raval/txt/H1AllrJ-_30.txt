Speaker 1:          00:00          Hello world. It's the Raj and there are so many different neural architectures that I feel like I could just talk about them all day on Youtube. Dreams do come true. An auto encoder is a neural network that's not just really useful for a lot of tasks. It's also an easy entry point to learn more complex concepts in machine learning. Let's go over some theory and code in order to grasp this model capable of everything from image colorization to dialogue generation fully. If we've got data that's properly labeled B that images or audio or text, we're in luck. Deep learning works really well with labeled datasets. That's because there is always a function that represents the relationship between both columns. It's easy to conceptualize this if our dataset is numeric, like if our input data was a bunch of numbers and the labels defined whether or not that input data was an even number or an odd number, the function that represents the relationship between these two columns is simple.

Speaker 1:          01:03          If the input data is divisible by two, the number is even Ellis. It's odd. All data types be that video or text can be represented numerically and as such, there is always a function that maps the relationship. It's just a more complex function than the one we just discussed. So while it's kind of incredible that we can speak to our computers now and they're able to transcribe what we are saying be, that's Siri or Alexa or Google now. Okay Google, do you love me? Ha ha ha ha. No. Speech recognition is just the result of deep learning on labeled datasets. If a team of developers is trying to create a speech recognition engine, they use a Dataset of audio clips with their transcripts as the labels. Every single bite of the audio can be broken down into a series of numbers and so can the text transcripts.

Speaker 1:          01:55          Some combination of operations will convert the input to the labels and that combination is the function. Neural networks can slowly approximate or get closer and closer to this function through an iterative optimization process. Also called training. In short, it's minimizing an error value at every iteration so that given a novel audio clip, it can easily predict what the transcript for it would be. Deep learning is essentially performing a to B mappings. That's it. A more accurate way to say this is that it's performing universal function approximation, meaning with sufficient data it can approximate any function input alone application output, the likelihood a customer, we'll repay it, input an email and I'll put the possibility it's spam or not. Spam input usage patterns for a fleet of cars, an output where to send a car next like the dumpster if it was made by GM. Since there are an endless array of applications for this, deep learning has gotten really popular, but while deep learning is good at finding a function we don't already know, but have training data for it, surprisingly useful to find a function we already know and then look at how we found it.

Speaker 1:          03:09          All neural networks are composite functions. That means they are functions of functions. The more layers a network has, the more nested functions it has for a three layer network. We'd multiply the input by the first weight matrix, apply an activation function to it and repeat the process. Once again, this time, using the output as our new input input times wait, activates the result is our output. This can be represented as a composite function since we're using the output of the first function as input to the next function. But let's say our goal wasn't to find a label. Why, but instead to reconstruct the original input x, meaning if our input was an array consisting of a few numbers, our network should output that same input with those same exact numbers. After applying the series of operations to it, we can call the first part of the network that compresses the input into fewer bits.

Speaker 1:          04:03          The encoder, and we can call the second part that reconstructs the image that decode is. So why should we care about doing this? Well, we don't care about the output. It's just a replica of the input. What we care about is the hidden layer. Once a network can reliably reconstruct its input, the hidden layer must contain enough information to represent the output. If as is typical, the hidden layer is smaller than the input and output layers. What it represents is the same information in a lower density. It's a much more dense representation of the input data. One that is learned over time, although it turns out that there are better techniques for data compression. Auto encoders are still really useful for some tasks like dimensionality reduction. Once we have a more condensed representation of some multidimensional data, we can easily visualize it and just two or three dimensions for further analysis.

Speaker 1:          05:02          We can also use it for classification. The idea is that we trained an autoencoder to reconstruct its instances of a particular class. We don't train it on any instances of any other class. Then to classify new instances, we feed them to the auto encoder at the input layer, get a reconstruction in the output layer and compute the reconstruction error, which is usually a measure of distance between the reconstruction and the input. If it generalizes to a new instance and reconstructs it properly, then it's likely to be of the same class as the incidence it used to train on. Anomaly detection is another use case. We first trained it on normal instances so that if we feed it any anomalies, there'll be detected easily. If we train it to recognize anomaly instances in our training set, it would only find the ones that look like anomalies.

Speaker 1:          05:49          It's already seen in many cases. We have very few anomalies in our training that set, but when using an auto encoder, this isn't a problem. So auto encoders are just neural networks where the target output is the input. We don't actually need any new code. If we're just using a super simple psychic learn like interface. We'd simply train our model by changing a single parameter. Instead of model dot bit x and Y, we just say model.fit x and x. All the usual training strategies work with auto encoders including backpropagation and regularization and drop out. It's fun to take an existing neural network library and see what kind of low dimensional representations we can come up with. If we were to build a really simple autoencoder using the care os deep learning library to reconstruct a training set of images. Notice how a single fully connected neuro layer acts as the encoder and as a decoder, and this model is just a simple neural network.

Speaker 1:          06:45          We're only calling it an auto encoder because we're feeding it the input data as the labels. Since we don't have any labels, the reconstructed results will look very similar to the original input data. After we're done training, sometimes though the model could overfit on the input data and in order for it to be able to learn a better, more robust representation to the input data, we can manually add some noise and this is called a de noising auto encoder. The amount of noise to apply to the input usually takes the form of a percentage. There are so many different types of auto encoders we could make, but one in particular that I really like is called the variational autoencoder. This learns a latent variable model of its input data. Instead of letting the network learn some function, we're learning the parameters of a probability distribution that models our data.

Speaker 1:          07:32          Then we can sample points from this distribution and generate new input data samples meaning a Vav can be considered a generative model. This lets us create all sorts of new images and videos that have never existed before. Image colorization, chatbots, VA ease are right up there with generative adversarial networks as one of my top five favorite deep learning models. Three points to encode in your biological neural network. From this video, neural networks can slowly approximate any function that maps inputs to outputs through an iterative optimization process. Also called training. If we set the output to be the same as the input, we can call this neural network and auto encoder because it encodes a more dense representation of the input data and there are many types of auto encoders we could make. A more recent generative model is called the variational auto encoder, which learns a latent variable of its input data. This week's coding challenge is to create a simple auto encoder using the care os deep learning library. Post your get hub link in the comments section and the winners will be announced in one week. Please subscribe for more programming videos. And for now, I've got to solve AI or die trying. So thanks for watching.