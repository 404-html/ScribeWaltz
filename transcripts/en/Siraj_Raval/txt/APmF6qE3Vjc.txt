Speaker 1:          00:02          Right task this starting.

Speaker 2:          00:11          Okay.

Speaker 1:          00:14          All right. Well we got here. What do we have to do? That's what I'm trying to ask. What do we have here? We have people in the house. Every body. Yeah. Rajio convolutional network. Yeah. Okay. Hi everybody. Welcome to the livestream. Today we are going to build a convolutional neural network and we're going to build a with just tensorflow. We are not using care. We are not using anything. In fact, I'm going to take these off if we're not using anything. I'm not even using the headphone. I'm not even using my hands. Actually we are just not skating. I'm using my hands, but what we're going to do, hi everybody. We're going to build a convolutional neural network. Come just tensorflow and, okay, so what? That's what we're going to do and let me see who else is in here. We got no crafter and Simon.

Speaker 1:          01:01          We got Daniel and Anthony. We got look in some bid. An RN do. Hard mode is on hard mode is on and well we have so many Joe people here, not audible. Am I not audible? You can't hear me. Is that the case? Cause I'm gonna just turn this off. I'm gonna just, you can hear me right? Bones, jaw. Oh, we've got an international crowd. We got [inaudible], we got Paolo, we got the whole world in here guys. We have 200 we have 200 countries represented in our community. That's amazing, isn't it? So what we're going to do is we're going to build this and uh, let's start off with a five minute, two and a half. So just hit me questions. Just going to go into it because I'm excited and I hope you guys are okay. Give me what your best questions.

Speaker 2:          01:45          Okay.

Speaker 1:          01:46          When is the hangout for patriots are, it's going to be in two weeks. I'll schedule it soon. Thanks for the reminder. I know you from Daniel walked. Yes, I went to high school with him. He's a great guy. I'm doing great. Thank you. You're awesome. Too high from the Netherlands and France and Italy and India. Oh my God guys. There we have, we have just started this community and we already have people doing amazing stuff. We had someone who was, who gave a talk on, on our, uh, somewhere I think in South Africa or something. We hit someone who got their dataset teacher on the first first page of Kaggle. So we have a lot of great stuff happening and we're just getting started. So hello from grease cap. Why tensorflow? Because tensorflow is actually faster than num Pi. You heard me? Tensorflow is actually faster than num py wide because it runs on a different interpreter. Then just python. The computation graph has its own interpreter and it's not, and it can run in parallel. So it's parallel execution and we'll talk about that during the talk from Antarctica only Eskimos. Here we have Antarctica and the house. Where is the link to the Open Ai in GTA? Five. I'll make a video on that within three. Within a month.

Speaker 1:          02:50          Please explain your hidden layer. This tutorial, because in Pong live you didn't explain. I will explain the hidden layers. I'm going to explain what's happening in each of the filter maps. Okay. Three more minutes. Any application of ML and robotics? Uh, sure. There's a lot control theory specifically, like ideal ways of moving your physical arm to pick up the object and you can run a loss on June optimization function use backpropagation and everything else. Everything applies. It's just reinforcement learning m and I see exactly when to use them. An ice tea. The code is in the description. Google search bots, not yet. Uh, best resources currently available for learning about generative modeling. Uh, wow. I would say the best resources are for that Ian Goodfellow, his book because I mean he's the guy who made generative adversarial networks and so if anybody knows about it, he does.

Speaker 1:          03:36          And that's kind of the, that's still a bleeding edge. Any video coming up on Apache spark and Mli Apache's like, not that cool to me, but I mean if you send me a link, maybe I'll, maybe I'll be convinced. Uh, CNN for speech. I have a few videos on that search tension, full speech recognizer but I'll make more in the future. What is a good reference to learn about ml? My channel, watch all my videos. There is more content in my videos and most people don't recognize this. Then in the entire web I have, I have written essay after essay, week after week, all my scripts, my videos are huge, huge technical writing scripts across almost every topic at this point. And we were just going to keep going and they're more topics and there's endless topics. Two more questions and then we're gonna get started. Resources for NLP. Let me, let me talk slower resources. There's just so many questions coming in guys. By the way, let me just say that we have somebody from you, Udacity in the house. His name is Lupe. So shout out to Luke and he's going to be in here to help answer some questions because we've got a lot of people here. So any questions you have Lucas, NBN and straight. So Luke, if you're here, shout us people can see you. All right, so, okay, so two more questions. Kevin Murphy. Okay.

Speaker 1:          04:43          Any image similarity detection NTF there is. That's not what we're doing. We're not doing, we're not doing a similarity detection right now. Uh, but it is possible. And Tf as is. There's Luke right there. Okay. So one more question and then we're gonna get started.

Speaker 1:          05:01          How to practice ml in smartphone, how to practice ml in smartphone practice ml. You don't want to practice coding on a smart phone, but you can use ml on a spark phone by having a server with your, uh, with your, with your neural net. And then you just call it with an API. Don't run, don't run your deep deep model on your mobile phone because it's not going to work yet. But we need more. We need, we need better, more robust models that run on less computation before we do that. Okay, so that's it for our questions. Let's get started with, this is going to be awesome. We're going to run this code. The link to it isn't the read me. Okay. So let's start screen sharing and let's, let's get started. All right.

Speaker 2:          05:38          Okay,

Speaker 1:          05:39          here we go. Entire screen, all of it. Share all of it. Okay. Okay, so here we go.

Speaker 1:          05:52          I see. Here we go a lot. So I'm getting better at certain things. I mean, I like saying here he goes, but I'm saying I'm blessed and is a, this is a function of having to do this every or wanting to do this every week. Okay, so here's our code. Okay, let me just lay that out and then let me get these comments every year so I could see them at the same time on my different screen. Let me make this a little bigger because we are really going to dive into this. We're really gonna go into this like all the details. Okay. So,

Speaker 2:          06:20          okay,

Speaker 1:          06:22          so here we go. With this. Let me also just have my face in the corner because you got to have the face, I mean, right. He does not the screen importing the movie reporting.

Speaker 2:          06:33          Okay,

Speaker 1:          06:34          there I am. Whoa. Too Big. Too Much Raj. It's never too much around. There is for today, right now. Okay, so there we go right there. And then the code was here. Here we go.

Speaker 2:          06:42          Okay,

Speaker 1:          06:43          we're going to build an, we're going to build a convolutional neural net. We're seeing, and this is fake news. Oh my God, please don't bring politics in here. I am politics free. I am politics free. Okay, we are talking about Ai. Don't bring that in here. Okay, so we're going to CNN and why are we building a CNN? Why don't we just use open CV, right? Why don't we use open CV? It's easier, right? It's easier to understand. We can just talk about a similarity because right? Because CNNS outperform every other type of outreach them for image classification. They are the state of the art. The dataset we're going to use for this is the m n I s t dataset. Okay?

Speaker 2:          07:25          Okay.

Speaker 1:          07:26          We're going to use the M and ist Dataset and it looks like this. And why are we using this Dataset? Because it is younger. Kuhn was the guy who first used it in his 1990 remember the weekly video? He used it for his first, uh, competition on that in the 90s, which worked really good, really well. But now it works even better because we have more data and more computing power. The other thing is it's a great easy to s to start with multi-class classification problem. It's a multi-class classification problems, right? There are 10 classes here, one for every digit, one for every digit, right? So one would be one, two would be two people. I know. Ego. It is a boring Dataset, but it's not about the data set right now. We're, the interesting part is going to be this model architecture and that's going to be the interesting part. Okay. So,

Speaker 2:          08:10          okay,

Speaker 1:          08:10          five minutes to answer a question. It's not enough for 350 50 people waiting a whole week, man, that is quite the pressure. But Hey, it's all good because you know it's, it's Gucci, it is Gucci. Okay, so here we go. So that was, that's the M in ist Dataset. It's going to be multi-class classification problems. And this is better than a linear model because the best we can get with open CV,

Speaker 2:          08:30          okay?

Speaker 1:          08:31          The best we can get with open CV is

Speaker 1:          08:36          of 91% so we're gonna use molten glass classification and this is what it's gonna look like. So let's, let's, let's start off by just looking at our architecture. Now this is a fully trained architecture that we are looking at right now, man, man, you guys have the funniest comments. You guys are the funniest comments. I love you guys. Okay, so this is what it a fully trained competent convolutional net looks like. And what we're gonna do is we're going to look at this in detail before we get to the code. So let's just look at, let me blow this up a little bit. Okay, so here we go. We're going to start off with an input image like seven. Okay? We have an input image like seven and

Speaker 1:          09:12          we're going to put it into our convolutional net. And it's going to output a class. The class is going to be one of 10 different classes. Okay? So that's what we're going to do. So how does it, how does it output that class is the question, what is the magic that is happening in a convolutional net to output a class? Well, it has layers. And so this is a trained network. So we're going to talk about a train network and then we're going to talk about how it became that. Good. So when we put an input image like seven, and it's going to go to the first convolutional where like you see right here, this first convolutional layer. And in the first convolutional layer we have 16, uh, filter matrices. These are 16, five by five filters and built. Hers can be thought of as weights, okay? They can be thought of as weights in a network.

Speaker 2:          10:02          Okay?

Speaker 1:          10:03          These are 16, five by five filters. And what these, what is going to happen with these filters is we're going to take this image and we're going to multiply each of the, uh, we're going to multiply each of these filters by one pixel in the image. So it's going to go left to right. It's going to go from left to right. And what does this look like? Well, I have this very handy little, I have it very handy little, uh,

Speaker 2:          10:27          okay.

Speaker 1:          10:28          Animation here, which is also in the notes and I need to remove the parentheses. But this is what it's going to look like.

Speaker 1:          10:38          It's under his blog and somebody's blog. Where is it? Where is it? Where is it? There it is. This is what it's going to look like, right? It is involving the word convolutional, the W. And I'm going to contrast it to other architectures in a second. Okay? Hold on. But did the word convolutional comes from consulting because we are convulsing from one part of the image across all of it involving mean sliding. We take our filter and we multiply it by, uh, it's, it's, it's essentially a dot product. We are doing matrix multiplication. That's all it is. It's matrix multiplication. We're taking our filter,

Speaker 2:          11:11          okay?

Speaker 1:          11:11          We're taking our filter and we're multiplying it by every part of the input image. And it's going to, and we're going to all of those, uh, the results are going to, are going to result in an, in a feature map image. And now let's talk about what that feature map image looks like.

Speaker 2:          11:26          Okay?

Speaker 1:          11:28          So, okay, so what, we're going to multiply each of these images by one pixel in the input image and it's going to output a 16 channels. And this, each of these channels is a, is a matrix. And we can think of this whole thing as a feature map. That's what we call it. We call it a feature, or we could call it an activation. Now both words for it. And it's either a feature map or an activation map. Just 16 channels of this. And so that's the first image, right? We are multiplying one month right from left to right, left to right, left to right. Left, right. Let me show one more, a little animation of this.

Speaker 2:          12:07          Yeah.

Speaker 1:          12:08          Which one? More little animation of it.

Speaker 2:          12:13          Hold on.

Speaker 1:          12:15          There were good. So here's one more animation.

Speaker 2:          12:18          Okay.

Speaker 1:          12:18          Hey, this animation, right? And this was in the weekly video. It's sliding just like that. And the outputs, the feature map. So we can think of this feature map as one, a big ass image, right? Uh, actually there's several, there's several images and it makes one big ass feature mouth. Oh, so that's the word dress. There are several images. Okay. This is going to be uploaded to youtube right when I'm done, but it's better to walk the line. Exactly. So that's what's going to happen. So, okay, so that's what's happening in the first layer is going to create a bunch of images.

Speaker 1:          12:49          Guys. Be Nice to each other. We're going to create a bunch of images. And then on the, in the next layer, it's a little more complicated. In the next layer it's a little more complicated because we are now, we have a 16 by 36, uh, set of filters. So there's six. We don't actually see all of them here. We only have this burst 16, set the section, second 16. Set a depth to tell. We'll probably play me in a movie one day for sure. I'm sure about if somebody, well, for sure. Um, I'm convinced there's going to a movie about me one day. So we're going to have 60, my 36 a convolutional layer. And each of these is, we're gonna multiply it by each of these. So for the first, so here's, here's what's going to happen. So for this first image right up here where my, where my mouse is pointed at, let me wait. It makes us a little bigger. Does it actually didn't make it bigger? It's just made everything but this big. So, so good job man. Good job man.

Speaker 2:          13:42          Hold on.

Speaker 1:          13:44          So we're going to multiply each of these images by each of these pixels in one image. And we're going to do so all of these, and we're going to sum them all up. So for, so let's talk about this first left Corner Pixel. At the top left, we're going to multiply every single weight up here, all 16 of them by that one pixel, and we're going to sum them all together. And the sum of that makes up a single pixel right here. Then we're going to take the next 16 and multiply it by the second a pixel. And then the next [inaudible]. So we're going to take, so basically all of these feature weights, all of these filter weights are multiplied in some together to make a single image right here. And this new feature map, it's even bigger. And we're going to do that for every single image here.

Speaker 1:          14:23          So what happens is, so what happens is these channels, these 36 channels there, it's a, it's a bigger feature map and they're more dense. And what do I mean by more dense? It's, it's, it's only focused on the features that it thinks are relevant because all of the features and things are relevant are going to show up here then. Okay, so once we have that, so you have 16 yes, so we started with 16 filters and then we, we started with six 16 filters and then we get 16 by six filters and these are five by five pixels and it's just, it's just a matrix of numbers. It's a matrix of numbers. Okay.

Speaker 2:          14:59          Okay.

Speaker 1:          15:00          Real Han Pinto. Okay. So, so it's a matrix of numbers and then we think are fully connected. Layer right here are fully connected layer and we, and so what are fully connected layer does is it takes that huge multidimensional feature map and it squashes it into a two dimensional picture map. It's watches it into a two dimensional theater feature map just so we could then squash it with the sigmoid and the output layer. And what happened when we squash it with a sigmoid, it's, it's going to give us one of these 10 different probabilities and one of these 10 different probabilities. We could then convert to a class which is going to be seven. Okay? That's the very highest level that we're going to talk about right here. Um, okay, so that's the very highest level and we're going to talk about in detail as we write the code, as we write the code, we're going to talk about it in detail. Now one interesting thing about it, a convolutional nets that I really like is we can understand how they work, but we don't understand,

Speaker 2:          15:58          okay?

Speaker 1:          15:58          So well we can understand perfectly how they work. All the matrix multiplication we can get from a high level of why these series of abstractions can detect a feature or how they can detect a feature. But we don't know why it works so well. And that to me is very exciting and we'll talk about about that in a second. So that's the highest level. So let's keep going now. Now we're going to get to start building this thing. Okay?

Speaker 2:          16:21          Okay.

Speaker 1:          16:22          Before we start, let's, let's just talk about what, this is just another example of convolution that's happening in the first filter. This is one more example. So the rent. So, so here's the thing about that. So this is why it's red and black. So the red filter weights means that the filter has a positive reaction to the black pixels. While the blue filters means that culture has a negative reaction to the play back quick old pixels and why?

Speaker 2:          16:47          Okay.

Speaker 1:          16:48          And why do I, why do I talk? What do I mean by positive and negative? Positive means that it has detected something that there is, that there is something there and blue means that there is nothing there. And so what happens is it's only going to get what it considers to be relevant and this is what it considers to be relevant in the first feature map. Just this wine over here, this feature it considers to be the relevant feature in the first feature map. Okay. That's the result of the first convolution. And it does this for several. It's going to take several of these images. They're all gonna look, but for different parts of the, of the, of the number, they're all going to look like the number seven, but it's going to highlight different parts of it. Okay. Some kid. Yes, I did explain it. Next video. Thanks for calling that out. Um, okay.

Speaker 2:          17:36          Okay,

Speaker 1:          17:37          so, so that's what going to happen. So now let's start running our code. We'll start off by importing our dependencies. We got intention flow and num, py, psych it, learn. And we'll talk about each of these when we get to it. How does it determine what is relevant that that is the question. That is the question. We don't know why it determines the certain features as relevant, but we do know is it can detect what is rolling. We know how it detects relevancy by multiplying matrices together and then out putting a a binary yes or no, whereas in the feature is there or the feature is not, but we don't know why. Why? It's why. It's like why it's determining that this is the specific thing is relevant. So that's really interesting, right? So let's get started with this.

Speaker 2:          18:20          Okay.

Speaker 1:          18:21          Basically magic. No, I mean we're going to figure this out. I mean give it, give it like a few months. I'm sure someone's going to open a paper on this. So let's start building this. Now. We're going to start out by defining our hyper parameters are hyper parameters in this case are going to be the convolutional layers. Why do we define a five by five filter size for this, for this feature map. Now somebody asked me why I didn't do a uh, can I signed the difference between architecture? So let's talk about a fully connected layer for a second. Let's talk about a fully connected layer. Okay, so if you look at this image

Speaker 1:          18:52          image, it's, it's showing a box and this box represents a three d filter. It's representing a three d filtering, a three dimensional filter. And the third dimension by the way, is the depth, which is RGB values. So it has three different two dimensional matrix matrices, one for red, one for green, one for blue. And the reason we're not using a normal feed forward neural network with a fully connected layer is because there would be a combination tutorial explosion. If we multiplied a three dimensional input image by a two dimensional set of weights, it would be a huge number. Okay? Especially for big images with 10 10 80 pixels. So that's why we use a convolutional layer instead of a fully connected layer. That's why we use that because it is a, is a smaller,

Speaker 2:          19:41          okay.

Speaker 1:          19:42          It gives us a smaller result. So, so back to where we were going. So that's why we're, that's why we're creating our filter map.

Speaker 2:          19:49          And

Speaker 1:          19:53          it's three d because there are, there are three color channels, red, green and blue, red, green and blue. Okay. So that's, so we define our filter sidebar as five by five so that's going to be a specific size for all of those little filters that we saw up there.

Speaker 2:          20:10          Okay.

Speaker 1:          20:10          It's going to be a five by five cards.

Speaker 2:          20:13          MMM.

Speaker 1:          20:15          Okay. Thanks. Sorrow. So, and then we're going to find a number of filters are going to be 16 and so that's going to be in our first filter is going to be 16 of them. And then for their Burnett. So first layer it's gonna be 16 or next one, there's going to be 36

Speaker 2:          20:29          okay.

Speaker 1:          20:29          And I'll explain why we use a fully connected layer at the end because we do use a fully connected layer at the end and we'll define it as a size to be 128 here. So those are our hyper parameters for our layers. Then we load our datasets or data set is going to be the MNI ISC dataset. We said 100 to true, which means we're going to use one hot encoding.

Speaker 2:          20:51          Yeah.

Speaker 1:          20:51          One hot encoding is it is an encoding scheme that is very simple that it just, it, it converts them to binary ones or Zeros, which is great for a simple classification, which is what we're about to do. So this is our data is going to be for in the data initialization. Why there's, why these numbers? Well we could, we could try, we could try it. So choosing hyper parameters is its own field of study. Should we do big hyper parameters, small hyper parameters. Usually we test out different things for guessing checks. They're actually hyper parameter optimization methods, search strategies for our neuroleptic. Try out different sets of,

Speaker 2:          21:31          yeah,

Speaker 1:          21:32          try out different sets of thanks Luke for answering that. Try out different sets of,

Speaker 1:          21:41          of ways, uh, of, of hyper parameters. So that's where a load loading data. And so we're going to use our, we're going to load up our training test and validation data right now. Okay. And then we're going to define some more hyper parameters. So we know that those Mni is t images are 28 pixels by each dimension. So we'll define it by image size. These are, these are, we don't want to have a what, what's, what's, what's the computer science word for it? We don't want to have not magic numbers. Uh, but I think it's magic numbers, right? We don't want to have magic numbers. Those are just scattered, uh, values in our code that we don't want to think about. Ah, right. So that's all we're going to define. These features are defined these variables beforehand. Then we're going to define our image slides as flats.

Speaker 1:          22:25          Who's going to be a one dimensional array of this length and then our two bull. And so it's a tuple week because we're going to input a two pole into the, uh, this is our input. We don't have our image size. And then we're going to define the number of channels. There's going to be one because we're using gray scale. Luckily for us, this, uh, so I talked about three d convolution. When we have an Rgb, uh, we were using RGB, but in this specific case, this is gray scale. These are gray scale, uh, m and ist numbers. So there were all, you're going to find one channel, but if we're using color images, we define how many channels we're going to use. Three channels. Yes, I'm doing a time series video on Friday. It's going to be dope. You guys are gonna love, it's gonna be really popular there would have finding the number of classes, 10 of them.

Speaker 2:          23:13          Okay?

Speaker 1:          23:13          Okay. Because there are 10 numbers. Now let's plot out these images. This is a simple numb five planning code to plot out the number of images. Okay? This is not where it can be used for CFR with some modifications that I'll talk about at the end. So when we plan out these images, this is what it looks like. It's going to it all. It's not, it's not, it's not predicting anything here. It's just playing out the images and their labels. Okay. Images in their labels. Oh my God. Time series is going to go, is going to be so amazing with LSTM networks. I'm going to talk about on Friday. So that's his. Now let's talk about tensorflow. No, I talked about how tensor flow is scalable. It's scalable because it could be used on CPU and GPU. If you run it in the cloud, you can easily scale it across DPU and you can define how many gps do you want to run it off.

Speaker 1:          24:00          You cannot do that with just non pot. That's why it's better than using just non pot. Any kind of, uh, any kind of production grade machine learning that you want to do, do not do it with just on pie use tensor flow, because it is the best machine learning library that we have so far. So the first thing we're going to do before we start defining our computation graph is we're going to define helper functions for our weights and our biases. Our weights are going to be initialized at random when they're going to be initialized randomly, and we're just defining variable for them. We're not doing anything else. We're just defining variables and then our biases. Why are we using biases? What is the point of biases? So explanations for use of biases are actually really bad or cross nets. We can think of biases as we can think of them very intuitively for linear Russian models because we just think of them as the Wa. We think of them as the y intercept. Any y equals mx plus B slow formula. It's just a y intercept. But for a multidimensional array, or sorry, for multidimensional computation such as the case intenser flow.

Speaker 2:          25:07          Yeah,

Speaker 1:          25:07          youth biases as a constant value across. It's always going to be a constant value is carrying across the matrix back. And what this does is it improves convergence. It makes sure that our, it makes sure that our model is more accurate by having a constant value. That kind of a kind of anchor point to where we started off in between where we started off and what we ended. And we'll talk about biases more. Okay.

Speaker 2:          25:32          Okay.

Speaker 1:          25:32          They make it, yeah, so Heinz level, it makes it easier for the math to optimize. Um, so, okay, so those are our two helper functions. We haven't actually started building our computation graph. Yes. Right. Okay. We start building our computation graph. Didn't do the math. It's going to be all right. Uh

Speaker 2:          25:50          Okay.

Speaker 1:          25:50          You can sit back and laugh, but it's okay cause we're going to go so hard. You're going to Barf in this class. I rhymed all that by the way. So this is our convolutional layer in our convolutional layer. We're going to define our previous layer, then our input channels or filter size and number of filters. And then you're pulling two, two. Let's talk about pooling. I did not talk about Uli. So before we, we look at this, let's, let's go back to the image for a second and let's talk about two more things that we didn't talk about. Let's go all the way back up to this initial image that I showed you guys. So in the first convolutional layer and the second convolutional layer, it's not just involving, it's performing to other operations is performing. Uh, it's performing cooling and is performing Relu. Now, now we perform Relu to reduce, to increase the nonlinearity of our that makes it easier for our model to learn nonlinear functions, uh, which is, which is the case for this. Uh, it turns all of our negative values into Zeros. Okay. And then it, which improves it only unique linearity. And we'll talk about that when we, when we, when we, when we do that in a second. But,

Speaker 2:          27:04          uh,

Speaker 1:          27:05          then we're also doing max pooling. We're pooling is an operation where we just take the best parts of what we just calculated and by best, the Max values, which is those, it's kind of like involving were for every part of the Matrix. We're just saying, what is the Max value from this matrix? So if there's like six, seven, eight, nine, we'll take nine and there there's a, there's an entire field of research over pooling and we'll talk about that later on. But it's taking the Max value. So back to where we were, I just wanted it to define those two processes that we're doing.

Speaker 2:          27:37          Okay.

Speaker 1:          27:39          So back to this, the convolutional layer, we're going to have an a shape and the shape is going to consist of all those hyper, all of those parameters that we defined. What is the size of our filters, the number of input channels, which is one, because this is a gray scale image.

Speaker 2:          27:56          Okay. And the number

Speaker 1:          28:01          filters because he's our weights now that we've actually created helper functions. And this is the, this is the actual initialization a step, right? Well, for a convolutional layer, so our convolutional layer is actually a block and a consistent three operations. Remember, a convolutional layer isn't just a series of matrix multiplication and a summation of all this. It's also, it's also a right, it's also a, uh, it's also relu. And it's also, um, what else did it beside relu it's also, it's also,

Speaker 2:          28:45          uh,

Speaker 1:          28:47          using cooling. So there are three operations that are happening in a convolutional layer.

Speaker 2:          28:52          Okay.

Speaker 1:          28:56          Three operations. And so this is the default tensor flow. This is the default tensorflow, convolutional Tootie function. Okay? And we'll, we're wrapping this in our own functions so that we can add biases and we can add,

Speaker 1:          29:13          we can use biases and we can use weights. Now here's another thing. Now in this competition where we know about her input, we know about our weights, what our strides strides are. I think of striding like in real life, right? What are, what, what is a stride by the way? Like a, like a, normally a stride is when you like kind of, you take a big stride, you take a big ass step, you take a big step. And that would striding up is in internet it defines how, what are the intervals that we are creating these multiplications, right? So is it every pixel? Is it every two pixels is every three pixels? That's what we define as strides. So the smaller the stride, the more accurate it's going to be, but it's more computation. So there's a trade off, more accurate classification for more con need computation.

Speaker 1:          29:59          Then we're defining patty. It's a massive big step. And then we're going to define padding. So padding is going to be same, which means the input image is padded with Zeros. So the size of the output is the same. Okay? So that means that the difference between the input image and the filters, the matrices aren't the same size. So we'll pad to pad the smaller one with Zeros. So they're the same size. We wanted to be the same size, so it's easier to form matrix multiplication and so that, so the output is going to be the same. That's what we performed Caddick

Speaker 1:          30:33          then we're going to perform cooling. And so downsampling is what we is what we call this process of pooling. Downsampling is the name of this process. We call all sorts of pooling. Max Pooling average pooling offers the cooling, we call it a Max, we call it, uh, downsample and chancellors. Tensorflow has a built in function for this called Max pooling where we define the size of the, of, of the pool and the strides as well for the pool. So it's similar to convolution, it's similar, it's a similar process. It's a kind of like a flashlight that's shining over the image. And the part that is looking at, remember it's called the receptive field. Whatever it's focused on is the receptive field.

Speaker 1:          31:16          Okay, so now, and so then we'll define our right. So then our third operation, and this is the third operation in every convolutional block is going to be rectified linear unit or Relu, uh, which is going to calculate the Max Max value, which turns all the negative numbers, two zeroes. It's of similar to absolute value and allows it to learn more complicated functions than just linear regression. Those are the three operations that occur in a convolutional blocks and in traditional CNN, three blocks are there, right? This happens three times and then squash it and it outputs a probability. This is going to return our layer, which is what we, the resulting layer and the resulting weights. After we performed these three computations on it. Okay? Now we're going to do that three times and then then we're going to flatten the layer. We're going to find that using a fully connected layer. So, okay, so let me just talk about the steps here to flatten the layer, to flatten the layer that have some copy for a second to flatten a layer.

Speaker 2:          32:26          Okay,

Speaker 1:          32:27          well, why don't you first see the layer shape? Okay, the what is the shape of that layer? What does the, what does the dimensions that it's going by, and then we're going to say, how many features does this layer have? Okay, what are the features? And to get that, we're going to the num elements function. We're going to use those features. Those features are what we want to squash. And the word squash means reduced the dimensionality, okay? We're going to reduce the dimensionality to a two dimensional vector, which we can then reduce even further into a scaler. And that statement went to the single value is going to be our probability.

Speaker 2:          33:01          Yeah,

Speaker 1:          33:02          it's got to be our probability. I am made up of a drive to solve intelligence because I have probable and I have see all the problems in the world and it is the most important thing. The entire world. I will die for this cause I will die for this cause. So

Speaker 2:          33:19          okay,

Speaker 1:          33:19          layer flat is that last?

Speaker 2:          33:22          Okay

Speaker 1:          33:22          is that last shake. Once we reshaped that number of features play, your flight is going to be that two dimensional vector. Okay. And then we were going to return that. Okay.

Speaker 2:          33:33          Yeah.

Speaker 1:          33:34          So then so then for our fully connected layer, we're going to perform matrix multiplication and then focus, focus, focus. So hold on a second, hold on a second. Hold on. Once we find the layer, we, we input it into the fully connected layer as a dementia. And it's going to output a is going to output a, uh, the fully connected layer. A probability. That's, that's what is output. It's going to help with a fully connected layer, which they probability, okay, so, so the, so we all we did so far, we define our helper functions. Now let's build our graph using these helper functions. And because we define all of these complicated helper functions, now we can easily define our computation graph. So we start off with our placeholder value and the placeholder is going to take in that image, right? The image is going to be a two dimensional grayscale image, right? We need to be a number. So it's going to be not just the inmates, we're also going to input the delay. Okay?

Speaker 2:          34:43          Okay.

Speaker 1:          34:43          A label. So we have two placeholders for the pretty image and the label. Then we're going to input it into our convolutional layer. Yeah, I'm going to go, I'm going to do a Q and a session after this to explain things more. Okay. So, so write down your questions. Okay.

Speaker 2:          35:00          Okay.

Speaker 1:          35:00          All right. So then let me remove me so I can, yeah, so, so that's going to be that. So then, so let's define our first convolutional layer. Let's define our first convolutional layer using our helper function that we created. Our first convolutional layer is going to take the images and input and create a set of filters. And each of those filters has a width and a height equal to the filter size that we defined. And then finally, when we wish to downsample it using Max pooling, so it's going to be half the size. That's going to be our output. It's going to be that feature map that's going to be our first filter. And we can look at what happened here, right? It's a, it's a tensor flow objects. You have got tensor, we define relu on it and it's going to be a shape of size question mark 14, 14 by 16 and then the type is going to be float 32. It's the Matrix of value, right? On Matrix is a table of values of a pixel values. We'll do that again for the next convolutional layer, right? So there are two convolutional layer. We took the output of that first layer and we fed it into this next layer.

Speaker 2:          36:00          Okay,

Speaker 1:          36:00          then we're going to flatten it or would you flatten it?

Speaker 2:          36:05          MMM.

Speaker 1:          36:07          What would you flatten it using the uh, this, we're going to flatten it over here. Uh, right. It's, it's afforded Meisel, Texstar and we need to find that in 22 dimensional tents. Are you doing that? That helper, that helper function we created? Right? So if we were to then visualize that flattening layer, it would be, you see it now, it's the shape is going to be two dimensions, right? For the first time it had four, four numbers. You're right, cause he was four dimensions. Uh, and now it's just two dimensions. Okay?

Speaker 2:          36:37          Okay.

Speaker 1:          36:38          So now we're going to look at a number of features, which we have a lot of features. And so now it's not the fly knit, flattened, flattened two dimensional vector into a probability. And we're going to do this twice. So we have two fully connected layers. Okay.

Speaker 1:          36:55          We have two fully connected layers here. And uh, for each of them, yeah, we're going to define them. We already defined the helper function. Uh, so what we're gonna do is we're going to run them both on that input data and it's going to output, uh, this one. It's going to output this two dimensional vector, which we condense squash. Do you think a softmax function. Okay. The softmax function is a sigmoid function. It's going to output a probability, one of 10 classes. This probability is going to be mapped to one of 10 classes. And the way it's going to be mapped, the way our network knows where to map this is by using an optimizer and a loss function. Okay, so this is the, this is the gradient descent and an optimization step. Okay. So,

Speaker 2:          37:41          okay,

Speaker 1:          37:41          for our gradient descent and optimization step, we're going to use, okay, what is, what is that?

Speaker 2:          37:48          Okay,

Speaker 1:          37:48          what is our loss function? It's going to be called Cross entropy. Cross entropy is our loss function. Here's a great, um, Cora link for the cross. That can be function like learning about it. So basically it's similar to softmax except instead of sock in a softmax function, we're determining the type of activation layer. But in cross entropy we're using, we're using it to measure the error at the softmax layer. It's, it's similar to soft Max, but different because we're using it to measure the error at the softmax layer loss. It's a loss of function because it gets, it's going to output an error value. And we're going to use this error value to error value that it's that it's how pudding, right? Uh, between the real and expected value. So right? And so it's going to output is going to help put a prediction, right? It's gonna be like, you know, 60% chance that it's a point 70, but in reality hits a 100% chance that it's a, that is that the number is this a 60% chance that the number is seven? But in really it's 100% chance at number seven. So that difference between the 60% prediction and the 100% reality, that error value is what we want to minimize. And the way we minimize that error is using an optimization method. Now Adam is just another word for gradient descent. It's a type of gradient descent optimization function. Now gradient descent

Speaker 1:          39:13          determines the direction that we want to update our weights or weights in this case are going to be those filter values. How do we update those filter values so they are more accurate that they give us a more accurate result that these, that they, that they are more closely aligned to features that would be in the image. Can we, how can we modify those initial matrices in those filters such that the output, a more accurate prediction. Now bringing the set is going to give us that because

Speaker 2:          39:42          okay,

Speaker 1:          39:42          it is using the chain rule because, okay, so whole, I mean, so grading dissent, I mean that can be a full explanation. So let's, let's talk about it. Let's talk about grieving to send a little bit. So for grading the sound, we're using the chain rule. So what is the chain rule? We're taking the derivative of the loss function and we are, we're cursively taking the derivative of each layer back propagating our loss to each layer and then we're updating our weights using the gradient. So I've explained this a couple times in a couple of videos, but I, you know, honestly I need a video just for backpropagation and that's going to come up very soon. But it is bad propagating weights by taking the derivative recursive we across each layer. Okay. And there's probably a great image for this backpropagation recursive recursive derivative. It's all about recursion when it comes to backpropagation. I mean the chain rule is just recursively taking derivative about derivatives of derivatives, but, and that's from statistics. So knowing the chain rule is very important. You have to know how back application works because it is the, it is the optimization method that is used across all networks.

Speaker 1:          40:53          So with t tensorflow, we can basically just plug and play. It's a plug in play model to just type in whatever type of optimization function we want to use. And then it's got to minimize that loss over time. Okay. So then,

Speaker 2:          41:07          okay,

Speaker 1:          41:07          uh, well use the reduced me. So then we're going to use tensorflow has reduced mean function to measure the CALC classification accuracy. Okay. So it's a binary yes or no or no value, zero or one true or false.

Speaker 2:          41:21          [inaudible]

Speaker 1:          41:24          okay. So then we're going to run our session. We always have to run or computation graph once we built it. So then, um, so once we run our session,

Speaker 2:          41:36          okay,

Speaker 1:          41:37          so these are helped. This is us running are running our session and then we're going to plot our values after a set of iterations.

Speaker 1:          41:49          Okay. We do a set of iterations of, these are all just printing out, testing, accuracies and, and training accuracy. But really what I want to get to is we've, we've created our graph, we've run it, and now we want to see the accuracy. So after one run, so after one small set of batches, we have a 13.7% accuracy, which is very terrible. It is worse than linear regression. It is terrible. We never want a 13.7% accuracy, right? But after training it either more one optimization iteration, we have a 14.3% right? So after a hundred we have 59.8% so you see that the more we run this optimization, the more accurate. After a thousand, we have 90% okay. And so a thousand would take probably on a standard grade 2015 knack book with a two point, you know, probably a 2.7 gigahertz CPU. 1,000 iterations of this will take like 30 minutes or less. Okay? So this is all computationally, uh, possible on a, on a local machine. Right now we don't have to use the cloud for this stuff,

Speaker 2:          42:51          okay?

Speaker 1:          42:52          Okay? This is multi-class classification. That's what this is considered multi-class classification. So let's visualize those weights that we created, right? So this is, this is using not plot life to visualize those weights, okay? Because those are matrices. So we're going to visualize those matrices using map, plot wide. And if we look at those weights that we just visualize, so let's, let's look at those visuals. Okay? This,

Speaker 1:          43:16          this is an image from the test set. These, these aren't the actual visual list. These are the visualizations. So we've colored the relevant, uh, we call it the relevant parts of the matrix red and the irrelevant or the irrelevant Lou. Okay? Binary. Right? So, so why is it that that, so why is it that, you know, this line is what's considered to be a good feature? Hope. Why is it that it's considered this bottom right part to be a good feature? You don't know why, but what happens is it's going to be more and more accurate. It's, it's features are going to be more and more,

Speaker 2:          43:51          uh,

Speaker 1:          43:53          close to what we want to make the accurate prediction. So that's what it looks like. It's a matrix of pixel values that it weren't at these weights, these weights, these filters right between each of the convolutional layers. And so if we plot these, what's happening in these, this is the feature map. This is what it looks like and see it's highlighting different parts of the image. It's going to combine all of these to output a probability. Okay. And See, and so in the next convolutional layer, we have even more filters. We have 16 by 36 even more pixel features, and those are the results. And then we

Speaker 2:          44:31          closed the session, right. Always closed in when we're done. Okay. And then they're more exercises, so, okay.

Speaker 1:          44:38          So yeah, that's it for our a convolutional layer and let's let's guys stick around for a second. Sit around, sit around. Let me, let me go back to stop the screen sharing. Okay, so go ahead and ask questions guys cause we have some questions to ask. Okay.

Speaker 1:          44:57          The the notebook is in the description. I'm going to add the read me in a second. I am so proud of all of you guys for being in this live session for watching this video. It is awesome to see you guys here. This stuff is not easy. It's not easy, but it's very important and knowing this is going to put you a huge step above everybody, every other developer. Just the fact that you even recognize the little things about convolutional nets is very important. Okay. For your career, for your academic career, for your, for any startup yet you want to do, it's very important because all successful startups, all successful companies, all successful academic research in computer science, it's going to get the bleeding edge. It's going to get the most attention is going to involve deep learning at this point and then we're going to build on that later and it's going to get even better. So I'm very proud of you guys for being here. Okay, you guys are awesome. I'm honored to be a part of this community. Okay, so the room is soundproof and next week I'm going to actually improve the quality of this live stream. So I'm very excited for that.

Speaker 2:          45:57          Okay.

Speaker 1:          45:59          We are growing so fast. We have 500 developers joining this community every single day on average. We are going so fast, so it's a very exciting time to be here and I'm just going to get better at explaining and you guys are just going to get better at doing these things. I mean it's just incredible the amount of coding challenges you guys have done. It is incredible what you guys have done. It is just incredible. So, okay, can I share resources to help you grow up? I'm going to put so many CNN resources in the description. It's not even going to be funny within the hour. If you want the image to be manipulated, do I add another matrix to affect the color channels? Have it output, multichannel image, the image to be manipulated. If you want the image to be manipulated, we're going to perform eight entirely different optimization process, not gradient descent, gradient descent, and that's what's used in neural style transfer and we're going to get to that three videos for now. Have you heard about good AI AI challenge know? Can this be done with python with the same level of difficulty?

Speaker 1:          47:00          Python, this word python. Okay guys, can you do more stuff on financial subject? Yes, it's coming out on Friday. Is Max pulling across channels or a specific teacher frame? Max pulling is done across all channels. It's every Wednesday at 10:00 AM pst also tree to the next live stream because there's going to be even better quality. I'm not going to use Google hangouts. It's going to be even better, better quality. Okay, thanks coach. Your car. We have so much to do. We have so much. Did you guys remember to share your share your victories with all of us? One victory is a victory for all of us. You are a very special person for knowing neural networks. You don't even understand how important you are to the future of the human race. Even every commit counts on get up. Every commit to every repo counts because it's like the butterfly effect.

Speaker 1:          47:54          You guys are the butterfly effect. If a butterfly flaps its wings in Colombia, it's going to cause a tornado later on somewhere in a different continent. It's like that fur coat and machine learning. The rate of discovery that is happening, the fact that you even push any open source code to get up is going to be even looked at by any other developer is very important because then they're going to build and they're going to build and they're going to do it. Then other people are going to build, so it's all, it's all, it's all connected. Everything we're doing is connected here. Okay. So it's don't think that anything you do is meaningless and this field, everything that you open source, everything that you output is going to have immense value to the entire world as machine learning propagates across every industry. Okay? So let's cost tornadoes with code. Let me answer two more questions and then we're done with this livestream. Okay. Can you make a video on Gan? Aye. Have a video on gain search, generative adversarial networks. I'm going to do another one. It's gonna be even better. Any flat strip requests, we can all discuss it. Yes, I have a slack channel. It's in the description of every single video of mine joined decide channel. Okay. There's a lot of great people in there. Okay, so that was one question. One more question.

Speaker 1:          49:08          How do I learn you sides? Constant practice. How do I learn? I input of diverse set of sources. So I have, you know, if I'm learning about convolutional legs, so it's like for these past video, for example, I had Andre these of the unreasonable effectiveness of neuro neural networks, epic blog post up in one tab. And then I had another attack from I think Chris Olah great blog by the way, Chris Olah, Andre Chapati, two of my favorites blogs. And then I had other tests. And so what I'm doing is I'm going between different tabs and I'm, and I'm Max pooling. Ah, I'm, I'm, I'm taking the, the optimal information from each of these and I'm, and I'm saying every time I have a question one I took on another source. So you have to have multiple diverse sets of learning resources. Okay?

Speaker 1:          49:56          So that's how I learned and I, and I just, and I truly love what I'm doing. So I think it's very important to love what you're learning because that is such an important thing. And I believe in myself, I believe in myself. That's such an important thing. And you guys all need to believe in yourself as well because you are very, very important. Okay? You guys are awesome. I'm so honored. I'm so honored to be here every Wednesday making videos for you guys. And the community is getting better as well. Our community is getting better. People are helping each other in the comments. The number of coding submissions are going up every week and the quality of the coatings emissions are going up every week as well. So we are all getting better. It's incredible and we aren't forced to be reckoned with God. We are a force to be reckoned with. Okay. So, ah, okay. So that's it for our questions. And so now I'm going to end it with a motivational wrap. Okay. So, um,

Speaker 2:          50:48          uh,

Speaker 1:          50:49          okay. So any, uh,

Speaker 1:          50:52          by the way, there's so much money to be made here and we're going to talk about all the money to be made as well from each of us. Okay? We are all going to get very rich. Not that that should be the driving factor. That, and that is a good thing. It's good to build wealth, the driving factor, it should be to make as much of an impact as you can and as a side result, you will make money because this stuff, I'll make a video on that like waste to make money with machine learning. I know it's going to be important. So a freestyle. Okay. D three js. That's, that's, that's my freestyle d three. Dot. Js. Okay.

Speaker 1:          51:22          Yeah. When I visualize made two cs, I use d three. I do it with Java script. Can't you see I see all these mid two C's in a vector. It's like three d two d one d scaler that dirt tensor. All these words, man. I don't know. Call me Victor. I was looking at all these statistics. I was looking at linear Algebra with six. I was hitting it with my brain every day. I went back. Yo, it's going to be okay. Okay, so that was it. Everybody's on your rich. Okay. Wasn't in the section, uh, programming, uh, dash wizards that did for the video. Thanks for being here guys. For now, I've got to make the sickest a stock prediction video using LSTM networks. So thanks for watching.