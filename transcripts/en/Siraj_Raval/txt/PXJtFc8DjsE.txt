Speaker 1:          00:00          Okay Google, what would we learn? Hello world, it's Siraj and 2018 will be the year. We finally start to see chat bots go mainstream. In this video we'll build a chat bot using Google's tensorflow machine learning framework. If you've created an awesome product or service, you've got to find a way to get it out there for people to see it. Right? Content marketing is the process of creating an organic growth channel for your business using content. This could be blog posts, videos, infographics who had prank videos, content that can help attract thousands of potential customers, and since content creation is itself a very time consuming process, we need to make sure we're delivering it in the most efficient way possible. The ability to gain insights from user behavior via machine learning technologies has completely changed the marketing game. Now companies can interpret exactly what their customers are like and what they do on the Internet.

Speaker 1:          01:06          Email inboxes have become more and more cluttered, so buyers have moved to social media to follow the brands they really care about. Smart brands have moved from email marketing to social media marketing to interact with and engage their customers to maximize sales. Most people stick to using just five apps and today messaging apps have over 5 billion monthly active users, which means that for the first time people are using them more than social networks. It's fair to say users are spending more time on whatsapp and messenger than they do on Twitter and Facebook. That's because chatting is more of an engaging activity. Lol, Lma, Mayo, rof l brands need to start engaging their customers through these messaging. Mediums and chatbots are the solution chatbots or a type of program that converse with a user. They mimic humans both in conversational ability and in performing any task.

Speaker 1:          02:08          Alan terrain, one of the fathers of computer science burst spoke of the concept in the fifties and since then the concept of a chat Bot has evolved through the decades. They're gaining popularity in the implementation of real world applications since they can cater the customer experience by providing engaging support, product recommendations and conversational marketing campaigns. They never sleep, they're cost efficient and they work well enough to increase. All sorts of metrics from clickthrough rates to customer sentiment. They can function as a support agent, a lawyer, teacher, doctor toy, or even as a companion that enriches your life. Domino's pizza for example, created a chat Bot for Facebook messenger where users can order delivery through their chat Bot and get status updates on the delivery. Nick Dutch, the marketing lead at the company admitted that it didn't necessarily translate to a huge surge in sales, but it did result in an improvement in experience and as a result, sentiment towards the brand consulting groups like bought works.ai or using AI to create chatbots for brands like change.org Tony Robbins and media posts to help them engage consumers across a wide variety of platforms, tailoring the technology to each brands specific needs.

Speaker 1:          03:36          There are also tons of services that led companies build chatbots for their own needs like Amazon, Lex, Ibm Watson, a zero bought services and motion.ai. Clearly the tools and interest are there, but how are we supposed to, to choose what tools we need to build our own chat bot, brush and relay anyone we can easily use. A service that lets us set a few rules and deploy our own chat Bot in a few minutes, but rather than just doing that, let's talk about how this all works under the hood. Technically there are two major types of dialogue systems, goal oriented ones and general conversation ones. General conversation models can be divided into two types, generative and selective models. The idea is the same for both. We'll input some dialogue and it will predict the answer for that context. I mean all of machine learning follows the same basic steps for a model, build it, train it and test it, but before we even do that, we need to find some quality dialogue data.

Speaker 1:          04:42          What we need is a dialogue dataset and since labeled datasets are easiest to learn from, we'd want that. We'd call each row in it a context replied pair. The context could be one or several inputs, sentences and the reply will be to label. Sometimes there is an eos or end of sequence token at the end of each sentence in the batch. This helps machine learning algorithms understand sentence bounds and update its internal states wisely. We can find this dialogue dataset on various websites, support calls that were recorded, movie dialogues, rap battles. All of these are real human conversations that our AI can learn from. Let's start with generative models. One of my favorite machine learning papers, a neuro conversational model tackle this problem head on a couple of years ago. They use a model called sequence to sequence to model the dialogue given to them in a Dataset. This model is represented by two recurrent neural networks with a different set of parameters each while regular feed forward.

Speaker 1:          05:51          Neural networks are given a new data point at every time step during training to learn from recurrent neural networks are given both a new data points and the learned hidden states from the previous time step at each new time step during training. In this way, there is a recurrence in what it's learning. It's learning not just from the data. It's the learning from how it's learned to before a sort of recurrence or a feedback loop. Loopity loop, Scoop d dupe. This is really useful for learning from sequences of data where predicting the next word in a sequence depends not just on the previous words, but all the words that came before it. The first recurrent net is called the encoder. It's given a sequence of context tokens, one at a time and updates it's hidden state. Accordingly. After processing the whole context sequence, it produces a final hidden state which incorporates the context and uses it for generating the answer.

Speaker 1:          06:55          The other recurring net is called the decoder. It's job is to take the context representation from the encoder as input and output. An answer. The reply generation process works like this. The decoders hidden state is initialized using the final hidden state from the encoder. The Eos token is the first input to the decoder, which updates it's hidden state. A word is sampled from the last layer. It's fed in as input. The hidden state is updated and a new word is output. This process is repeated in a loop until an eos token is output or some predefined maximum answer length threshold is hit. This process is considered inference. It's the process that a chat bot model goes through in real time once it's already been trained. The training part works slightly differently in each decoding step. We use the correct word instead of the generated one as the input.

Speaker 1:          07:53          Basically the decoder consumes a correct reply sequence, but with the last token removed and the Eos token pretended. The goal during training is to maximize the probability of the correct next word on each time step. We're asking the network to predict the next word in the sequence. By providing it with a correct prefix. We minimize the error through the most popular optimization strategy in machine learning backpropagation, which I of course have a five minute video on swag. See the link in the video description. This type of model worked pretty well, but it still had some generic responses like okay, or I don't know. Another major problem was that it generated inconsistent responses like asking the same question twice and getting two different answers. A newer paper that dealt with these issues, what's called a persona based neuro conversational model. The authors used speaker ids for each utterance in order to generate an answer which learned not based only on the encoder state but also on speaker embeddings.

Speaker 1:          09:03          When it comes to selective models, instead of estimating the probability of a certain reply given a certain context, they learn a similarity function where a reply is one of the elements in a predefined pool of possible answers the network. We'll take context and a possible reply as inputs and we'll return the confidence of how appropriate they are to each other to neural networks can be used here and they can be of any given type. The first network is used for the context and the second one for the reply. These networks will take it's input and embed them into a vector representation. Then the similarity between the context and replied vector is computed using cosign similarity. During inference, we can simply calculate the similarity between a given context and all possible answers to choose the one with the maximum similarity. In order to train the model, we'll use triplet loss, which includes the context, the correct reply and the wrong reply.

Speaker 1:          10:09          By minimizing this loss. We learned the similarity function in a ranking way where absolute values aren't informative, so which type of model should we use? Generative models can generate almost any type of answer, but the con is that it's difficult to impose certain properties on model replies like no curse words or speak like a certain character. Selective models have a more restricted pool of answers, but they are more customizable. The best way to evaluate a chat bot is through human evaluation currently, but as research progresses, we'll come to a more systematic approach here. Despite a lot of work in this area, neural dialogue systems are not ready to talk with humans in an open domain and give them helpful answers, but close domain applications like technical support are a perfect fit. Three things to remember from this video. More people are using messaging apps, then social media apps in this day and age, which offers a huge opportunity for brands to engage their customers through chatbots. Chatbots can follow either a generative or selective process. Both involve neural networks and there are a ton of services that will help you build chatbots, each with varying degrees of control. Links to some in the video description. Are you pumped to build a chat by yet? You should be subscribe for more gems like this. And for now, I'm going to engage my audience, so thanks for watching.