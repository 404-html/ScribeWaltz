Speaker 1:          00:00          Hello world. It's Saroj. In this video, we're going to write a script that reads in a Dataset of movie ratings and recommends new movies for a user in 40 lines of python. We are in the midst of a new renaissance right now and the reason for it is data. In the past two years, we've created more data than in the entire previous history of the human race. Your options to learn or experience or create are limitless on the wet. This is awesome. Oh my God, I'm going to throw up, but all of this abundance presents a problem. The paradox of choice because we have so many choices, we could spend way too much time trying to pick one. We could end up not picking anything at all or worse, pick something and then get fomo or fear of missing out. If there was a way to have an abundance of options and have certainty in our decisions, that would be ideal, right?

Speaker 1:          00:47          That's how recommendation systems help us. They use machine learning to go over all of our options, learn what we like and recommend which option we would like best and they're getting insanely accurate like they know us better than we know ourselves. Sometimes Amazon recommends products we'd like. Google recommends search results. We'd like Facebook recommends friends we'd like. Pretty much every service does it. Now there are two main types of recommender systems, collaborative systems and content based systems. Collaborative systems predict what you like based on what other similar users have liked in the past. Content based systems, predictably you like based on what you've liked in the past and some services like Netflix combined both approaches to be even more accurate. So let's write our own script that recommends movies a user would like. We'll install our dependencies, then write our script. We're going to use three dependencies, both num pi and PSI.

Speaker 1:          01:37          Pi will help us do some math and lite FM is a library that allows us to perform any number of popular recommendation algorithms. We'll start by importing num py and call it NP. I'd have him as a big library, so we're only going to import the sub modules of it that we need. We'll use the from import combination to import specific methods from submodules as necessary. We'll import the fetch movie lens method from the Datasets sub module and the light FM class directly from light offense, which will later create a model for us. Now that we've imported our dependencies, we're going to fetch our dataset. Let's create a variable called data to store our data set and we use the fetch movie lens method we imported earlier from our light FM dependency that fetch our dataset. The movie Lens Dataset is a big CSV file that contains a hundred k movie ratings from one k users on 1700 movies.

Speaker 1:          02:23          Each user has rated as least 20 movies on a scale of one to five so hopefully they gave this a zero basic. See if I can track an IP address. If that's movie lens method takes in an auction parameter called Min rating. I mean writing is a minimum rating we want to include in our data. We'll send it to 4.0 which means we're only collecting the movies with a rating of four or higher. So this method will create an interaction matrix from our CSV file in story in our data variable as a dictionary. A dictionary is a way to store data just like a list, except instead of just using numbers to retrieve data, you can use anything in our case where your strengths are fetched. Movie Lens Method Splits Dataset into training and testing data and we could retrieve each by using the train and test strings as keys.

Speaker 1:          03:03          We'll print out both. Let's quickly see what this looks like in terminal. When we compile it, it'll print out both our training and testing matrices. We can see that our training day that contains 10 times more items that are testing data. We'll store our model in a variable that we call model. We'll initialize a lite FM class using a single parameter called loss loss means our loss function and it measures the difference between our model's prediction and the desired output. We want to minimize it during training so our model gets more accurate over time and its predictions. We can choose between several. We'll go ahead and choose a loss called warp, which stands for weighted approximate rank. Pairwise warp helps us create recommendations for each user by looking at the existing user rating, pears and predicting rankings for each. It uses the gradient descent algorithm to iteratively find the weights that improve our prediction over time.

Speaker 1:          03:50          This takes into account both their users' past rating history, content based and similar users ratings collaborative. It's a hybrid system. Now that we have our model, we can go ahead and train. It will use the fit method of the model object to train it. The fit method takes three parameters. The data set we want to train it on the number of epoxy we want to run the training for and the number of threads we want to run this on. For our data set, we use our data dictionary we created earlier and pointed to the training data using the train strength. We'll set the number of epochs or runs for this training session to 30 and the number of threads or parallel computations to to now we want to generate a recommendation from our model. To do that, we'll write a sample recommendation function, which takes three parameters.

Speaker 1:          04:30          Our model, our data analyst of User Ids. These are users we want to generate recommendations for. First we'll get the number of users and the number of items which are movies. In our case using the shape attribute of the data dictionary we created. Now we can create a for loop to iterate through every user id that we would input and say that we want the list of known positives for each light. FM considers ratings that are five positive and ratings that are four or below negative. To make the problem binary much simpler, we'll get the list of positive ratings from our data in compressed sparse row format. This is a suburb way inside of our data matrix, which will retrieve using the indices attribute. Next we'll generate our recommendations and store them in the scores variable. Using the predict method of our model. We'll use a user id as the first parameter and then a list of each movie.

Speaker 1:          05:15          The a range method of num py will give us every number from zero up to the number of items so we can predict the score for every movie. Then we'll sort them in order of their score. The Arg sort method of [inaudible] will return the score indices in descending order thanks to the negative sign. Let's go ahead and print them. First we'll print out the user's ID percent has, we'll convert the ID to a string. Then we'll print the top three known positive movies that the user has picked by creating a for loop ending in the third index. Lastly, we'll create one more loop for printing. The top three recommended movies that are modeled predicts, we'll call it at the end using the model data and Alyssa three random user ids as the parameters. Each user has movies that they like listed as well as movies that our system has recommended for them.

Speaker 1:          05:57          So to break it down, recommendation algorithms help us make decisions by learning our preferences. There are two main types of recommendation algorithms, content based and collaborative. And lastly, why FM is a great library to get started with building recommendation systems. The winner of the coding challenge from the last video is row Han Vermont [inaudible] went above and beyond by creating a web app where you can search a topic and it'll list a bunch of tweets on that topic with highlighted sentiments. Bad Ass of the week, and the runner up is our nod Delani, well documented and well defined methods. The challenge for this week is to modify this code so that instead of using the default fetch movie lens method, you'll write a new method that fetches and formats some other recommendation dataset. Train it on three different models, compare the results and print the best one post. You're getting humbling in the comments and I'll announce the winner in the next video. Links to everything in the description. Please share this video and subscribe for more programming videos. For now. I've got to wonder why Yahoo still exists, so thanks for watching.