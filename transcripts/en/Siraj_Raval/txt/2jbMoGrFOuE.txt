Speaker 1:          00:00          Watson, you beat me again. Can we just be friends? Yes. Hello world. It's Suraj and today we're going to use IBM's Watson discovery service to instantly analyze a modern machine learning paper so that we can find any issues encountered by the researchers. Finding useful patterns and insights in unstructured data is not easy. We've continually improve the algorithms we can use to do so from simple linear regression models to buy directional recurrent networks, but there's still a big problem. Data preprocessing meaning acquiring, normalizing, and organizing unstructured data. It's something that data scientists spend as much as 80% of their time on. If we automate this process, that frees up much more time to focus on types of models to use and analyze all the different results in a rapid experimentation pipeline. IBM's Watson Discovery Service is a great solution to this problem. It packages core Watson Api APIs like natural language understanding and document conversion with simple tooling that enables us to seamlessly upload and rich and index large collections of private or public data.

Speaker 1:          01:22          You don't even need engineering or machine learning skills. With the web interface. Anyone can analyze enormous collections of unstructured data in minutes. Discovery uses natural language processing to allow for analysis for a wide range of document types, including html, pdf, and word. We can also use it to find time based correlations in data or even identify locations and geospatial coordinates to uncover spatial correlations. It has quite a lot of capabilities that when combined together offer powerful insights. For example, if we're a payments API company, we can use Watson discovery to identify all the companies acquired by one of our competitors over a specific period of time so we can make more strategic growth decisions. If we're a pharmaceutical company, we can identify the diseases that were impacted by a target's chemical compound or if we're working at a shipping company, we can analyze which events specifically impact our supply chain or shipping routes.

Speaker 1:          02:29          This kind of data is embedded in social media, news reports, legal documents, and other public or private data as relationships and text discoveries. Ability to sift through hundreds of thousands of relationships to provide insights is a powerful tool. The way the pipeline looks is that we first give discovery our Dataset in whatever file format it's in. Then it will convert and enrich that data using several Watson Api APIs that use natural language processing to add metadata to the content, making it easily searchable as well. It will also clean and normalize the data. Once the data is normalized, it's indexed into a collection as part of our environment in the cloud. Then we can query the data to see if we get any actionable insights from the output we receive. So let's try out a demo of this service for ourselves using a machine learning paper as our input.

Speaker 1:          03:27          Our first step is to create a free IBM cloud account. This is what allows us to access the service. Then we'll create an instance of the discovery service so that we can create an environment with one or more data collections that we will add our content to and associate with the configuration. We can click catalog in the navigation bar. Then on Watson and the Watson Menu, we'll find our discovery service and once there we can click create to wait for an instance to be created. After a few seconds, our new service will be listed on the dashboard. We can click on it to open the discovery service page. We'll see a complete set of online tools here, which we can use to set up an instance of the service and populate it with data. We don't need to use API Apis to configure and populate our service. We can do it all from the web dashboard.

Speaker 1:          04:26          The content we upload is stored in a collection that's part of an environment, but before we upload our content, we need to create the environment and collection. A collection is a logical division of our data in the environment when we deliver results, each collection is query independently. We'll name our collection machine learning issues. Once created, we can upload our documents by uploading our research paper to our collection. Once the upload is finished, we'll see the document count has increased to one insights from this data will be listed on the collection page and we can already see some relevant information. Now we're ready to query the data. We can select our collection from the discovery tooling main page. At the top of the collection page, we'll click on view data schema. Then we'll click the build queries link at the top of the data schema page followed by search for documents.

Speaker 1:          05:25          We want to find out what the issues were from the paper so we can use natural language to query for the issues. We can be as vague or as specific as we want here. The more specific we are, the more targeted the results will be. When we run the query, we can click the Jason Table to see that Jason responses that were returned. We can see a passage here. Passages are short excerpts that are extracted from the full documents that our query returns. It seems like the main issue was a very training time for this type of model, which confirms my hypothesis. This is going to make reviewing papers so much easier. We can also see some generated semantic analysis such as sentiment entities, categories and concepts are document was converted to Jason, then enriched and indexed. By enrichment I mean adding Metadata as such that Watson functions like entity extraction, concept tagging and sentiment analysis can parse the data accordingly and if we want we can also access Watson discovery via the API.

Speaker 1:          06:32          Like in this example it's wrapped via the python library and we can communicate with it directly. There are three things to remember from this video. IBM's Watson Discovery Service allows developers to unlock insights hidden in unstructured data. We can use it for both public and private data sets and it uses natural language processing to help easily extract semantic elements from data like sentiment entities and concepts. I've got a coding challenge for you this week. Wizards use IBM's discovery service to build an APP that lets a user analyze the sentiment around any given topic that they searched for. Details are in the get hub link in the video description and I'll give a shout out to the top two entries in a week. Good luck. Please subscribe for more programming videos. And for now, I've got to discover a new API, so thanks for watching.