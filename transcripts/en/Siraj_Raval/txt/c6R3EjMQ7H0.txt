Speaker 1:          00:00          Directions to the nearest water source. He knows the way.

Speaker 1:          00:09          Hello world walking into your geology. In today's episode, we're going to build a chat Bot with an API. In a previous episode, we talked about how to build a generative model Chat Bot by training it on your own Dataset with no hardcoded responses whatsoever. This time we're going to go the API route because let's face it, it is the year of the chat bots in the past few months. Tell him Liz companies have released chat Bot Api Apis so that you can integrate it with their service. Chatbots are like the new apps. If you think of a startup idea, there's probably an APP for it, but no chat Bot. We're going to build a flower delivery chatbots, so I did a little Api shopping and there were four services that really stood out to me with nuance Siri Kit and API dot. Ai. Let's talk about the pros and cons of each of them.

Speaker 1:          00:48          It is a chat Bot Api that was acquired by Facebook, so they've got the benefit of the Facebook marketing machine behind them. It's free so you can spend your money on things that matter. Speech recognition is included. The thing I really like about the service was the use of open instances. If someone else designs a Bot, you can just fork it and use that fork as your new chat backend. But the problem is when I attempted to build a Bot with this, it was super annoying and buggy. The documentation isn't dense enough so there's a lot of ambiguity. I got frustrated because there was no option to create synonyms for entities and I also just didn't have time to learn how the story modeled work more time for Minecraft. Another service I looked at was nuance mix. You guys remember dragon naturally speaking from back in the day?

Speaker 1:          01:25          Yeah, these guys made that so they definitely have speech recognition as a capability right out of the box and it seems like they really pay attention to that feature because they have a bunch of Spec papers on their site detailing their speech recognition technology, 40 different languages or supported in any different texts to speech voices are available reading their docs. They use terms like literals and concepts that add another layer of abstraction or it doesn't seem necessary. I tried to sign up and they said they'd get back to me in two business days. Ain't nobody got time for that. Nuance has been known to stick to big enterprise deals. If you're an independent Dev, probably not the best fit. Then there's Siri Kit Apple announced at WWDC this year that they opened up Siri to third party developers. The extensions. Finally, it's got great documentation but that's really the only pro I found by the way WWDC this year. Apple,

Speaker 2:          02:07          what the

Speaker 1:          02:08          Siri Kit is limited to just six different APP types so you can't tell her to make you soil and just yet, and those limitations are already baked into the API with functions like in book restaurant intent and only works with apple devices. So yeah, the garden is quite waltz. Finally, there's api.ai. This was the easiest service from me to you. I built a pretty useful chat Bot with this in just two hours. The documentation and interface or just way easier to understand than any other service I've found. It's got this integrations feature where you literally just flip a switch and it'll integrate with your service provider of choice to be that slack or Twillio. You just build your boss once and then deploy it to whichever platform you want. Also, they have the most client libraries and STKs I found for a chat Bot Api. That makes me a very happy day.

Speaker 1:          02:48          Speech recognition functionality is built into the SDKS. The only con is that while it is free as you scale, there are pricing tiers, but hey, if I were going to build a production grade, service quality is the number metric I'd be optimizing for and it seems api.ai is leading the charge, so let's build this baby. We're going to build a flower delivery chat Bot using API dot. Ai is console and a python client. We'll start by writing up an ideal conversation with our box. The user, let's the BOT know they're interested in buying flowers. Then specifies the type of flowers followed by the color and then the address they'd like it to be delivered to. They can exit the conversation or ask for more flowers in the process loops. We need to codify this conversation and the api.ai console makes it relatively simple. To do this, we'll create a new agent, click on domain and turn on small talk. Now our BOT is already capable of very basic conversation. Then we'll see the intents and entities tab. An entity is a model object that you referred to in your conversation at some point. So we want three entities, flower color and address. Well, create the flower entity. We'll define three synonyms. These will be the types of flowers we want. We'll do the same for color. Then for address,

Speaker 1:          03:50          cool. Now that we have our entities, let's build our intense unintended, it's an abstraction of a specific request a user makes, which then maps it to an action and a speech response. We'll create our first intent and call it proposal. We want to think of a couple of possible statements. A user can say, the system will be able to recognize not just these hand coded possible statements, but statements that are worded differently and have the same meaning. Once the system has recognized what the user has said, it can perform an action and action is an event that fires. Once an intent has been recognized, well then type out our speech response and this will fire when it recognizes the intent of the user statements. Finally, we'll add an output context context or how the system keeps track of what is being said. It's what makes the BOT conversational.

Speaker 1:          04:29          We know that after this proposal intense, we want our chat Bot to then ask what type of flowers, so we'll set the output context to our next intent called type. Specification. For type specification are Alpa context is color specifications. We are looking for a one word answer from the user at specifies type. Our system will detect the word. If it's uptight, flour and performing yet undefined action. We'll call saved flower type well adding or speech responds asking for the color and do the same for color specification. The output context is addressed specification. The user. We'll say a one word answer, which will determine to be an entity of type. Color will perform the save color action and ask for the address. Lastly, in address specification, we'll write out an example address and they'll recognize it of type addressed by using the address system entity. It'll perform the create order action and we'll use the address variable name to repeat the address back to the user.

Speaker 1:          05:14          We can set the output context, act to the proposal in case the user wants to continue buying flowers. Now that we have our backend setup, let's write our client in python. We'll import our dependencies, adjacent parser and the api.ai python wrapper. Then initialize our agents then create functions for each of our actions will leave these blank, but you can add any kind of functionality you'd like. Then in our main method, we'll create a while loop and retreat the user input from the command line then posted to the agent and retrieved the Jason Response. Well, Parsa Jason to display the bots reply. If we detect an action will fire one of our action helper methods. Hey, what's up? I want flowers. Tulips. What color? Blue one infinite loop order created. I totally get why everybody is raving about this service on hacker news. Check out the links down below. Please subscribe for more ml videos. I've got to go fix a race condition, so thanks for watching.