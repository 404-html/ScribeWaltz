Speaker 1:          00:00          Hello world, it's Suraj and deep learning. It works so well. Why does it work so well? The answer is because it uses a technique called back propagation. And in this video I'm going to demo a newer strategy that optimizes neural networks that is better than backpropagation and it's called synthetic gradients. This technique was released by deep mind a few months ago and it just hasn't had enough attention paid to it. This is what happens in research. A lots, right? Some great ideas don't get enough attention to paid paid to them. So then some youtube or like me has to make a video about them. So what we're gonna do is we're going to take the simple feed forward neural network. It's a simple neural network that learns to predict the output of adding two binary numbers together. And first we're going to train it using backpropagation. And so I'm going to go over back propagation and then I'm going to change the code.

Speaker 1:          00:57          So instead it uses synthetic gradients. So this gift that you're looking at right here is an example of the synthetic gradient strategy. Uh, the idea behind synthetic gradients is rather than waiting for your neural network to go through a full forward and backward pass, you can just update each layer without having to wait for that using what's called a synthetic gradient. These are gradients that are not the real gradient, the true gradient, but instead an approximation of what that gradient would be. So it's a synthetic gradient. And by doing this, we can update each layer without having to wait for all the other layers to updates. It's a faster way to optimize neural networks and allows us to decouple each layer from having to wait for all the other layers. So let's start off by talking about how neural networks learn in a black box approach.

Speaker 1:          01:51          The neural network gets an input. That's the input data and some desired output, right? So it's got an input in a desired output and it uses that to update its internal state accordingly, right? We have some desired output. Those are our labels, right? All of all of that propagation centers around having some labels for our data. We've got to have the labels. If you don't have the labels, you gotta get the labels right? And so if we have our labels, we can train our model. And so once we've trained it, then we can perform prediction. And the prediction process is using just the input and the internal state to generate the most likely output according to its past training experiences. So we have some input training data, we feed it to this learning system, which is a neural network, and it Purdue, and it predicts an output.

Speaker 1:          02:39          We then compare that predicted output to the actual output and we compute some error value. We use that error to then update then learning system. So then every time it gets better and better, that's just the training process. And that updating process is back propagation. So, uh, in a more detailed sense, we have some neural network, right? We've got an input layer, we've got a hidden layer, and we have an output layer. And each of, so each of these are layers, right? These three circles are a layer. These three circles are hey layer. These last two circles are a layer and each of these circles represents a number because we are inputting, let's just say three integers, right? A one, one and a zero. That's the input. And the reason that there are these black lines is because we are multiplying the input. We are multiplying the layer by the next layer.

Speaker 1:          03:31          So we are multiplying this one value by all of these other values and the next layer, because a neural network is input times weight at a bias and then apply a non linearity to it. So that's what we just keep doing for a neural network. We take our input data, we multiply it by a weight Matrix, which is the next layer. We add some bias value and then we apply a nonlinearity to it, which is a sigmoid function or there are, there are plenty of nonlinearities that we can apply. And this is the, this is the, this is called forward propagation. This is how we take some input data and we just apply a series of operations to that input data until we get an output prediction that we denote here as y hat. And so that is a whole forward propagation process. A neural network is just a series of operations that are applied to some input data, right?

Speaker 1:          04:22          That's it. Input Times, weight added, Tobias activate, repeat that process over and over and over again until we get that output prediction. And once we have that output prediction, we could compare it to the actual output, right? And so in a very, very basic case, we can just subtract the actual output from the predicted output. And that difference is the error, right? We what we want is that error to be zero. We don't want there to be any difference. We want our predicted output to be the exact same as our actual output. But as long as there is an error, we want to minimize it so it gets smaller and smaller over time. That is the training process. And so how do we minimize that error? Well, once we compute the error, we can compute what's called the partial derivative with respect to each layer going backwards, right?

Speaker 1:          05:09          So we compute the partial derivative of the error with respect to the weights for the previous layer. And what that's gonna do is that's going to give us a gradient value. Then we take that gradient and we compute the partial derivative of the gradient with respect to the weights of the next layer or the layer before that. And we get another gradient and then we take that gradient and we compute the partial derivative of the gradient with respect to the layer before that. And so we just keep doing that. And so if we keep doing that, we get great values for every single layer. And then once we've done that for every single layer, then we could use those gradients to update the weights of each layer. So you might be asking what is a gradient? A gradient is a direction. It's a direction on how to update our weights and it comes from Calculus calculates is a study of how things change.

Speaker 1:          05:57          That's why it's used in physics, right. How do planetary bodies move over time? How do the weight matrices of a neural network change as we are trying to minimize an error? The gradient, the gradient is a value. It's a value with the direction. And what I mean by direction is if we were to, if we were to graph, uh, all the possible weight values that we could have for a single layer versus all the possible error values that we could have for that same layer, it would look like a parabola. And with the gradient is, is it, is, it is, it is. It is synonymous with the partial derivative and the partial derivative or the derivative is a slope of the tangent line to occur at a specific point, right? So that's what the gradient gives us. It gives us that slope of a tangent line.

Speaker 1:          06:40          It's anonymous and the direction that that slope is, is pointing, tells us what direction we need to move such that we can get to this point where the error is the smallest that is the minimum of the parabola. And once we get to that point, then we know immediately what the ideal weight value should be. So the error is smallest. And we do this for every single layer, right? We compute this gradient value for every single layer. And the training process process is us. Generally. It is us gradually decreasing the point that we are at for each a weight matrix until we are at this point where the error is smallest and all the weight values of that weight Matrix, a r r equal to when the error is smallest. And that is when we are finished training. That is the optimization process. And because we are descending the Parabola, it's called gradient descent. So gradient descent is a very popular optimization strategy. It's using neural networks, it's used all over the place. But in the context of neural networks, we call it back propagation because we are back propagating on error gradient across each layer. Recursively. So every layer depends on us having computed the gradient for every single layer before that, right? So every layer is coupled. It's dependent on us having computed the gradients for every single layer that hat for every single layer, uh, after that.

Speaker 1:          08:06          So what this looks like in code is if we were to look at this in num Pi is if we were to look at this in python, what I've got here is a function called generate dataset. What this function is going to do is it generates a bunch of binary numbers, right? Like one zero zero one and then one one one zero it's also going to return the outputs and those outputs are the sums of those binary or numb numbers. So if we take two binary numbers, like one zero zero one zero and then we add another binary number, like one zero zero one and it's going to have some, some value that it's also a binary number like ones, there's a one, the input for our neural network are going to be these two binary numbers, concatenate it together. So they're one big binary number and the predict and the actual output will be the sum of those two binary numbers.

Speaker 1:          08:55          So we already know what the sum is going to be, right? We've, we've already computed it in dysfunction, but what our neural networks job is is to learn what that output would be so that even if we don't have that output, we can predict what the output would be. So it's making a prediction by updating its weights and going through this backpropagation process without even having to add the numbers together, is just able to predict what the output would be. So what we have here are this, the sigmoid is the nonlinearity. And the reason we apply a nonlinearity to neural networks is because neural networks are universal function approximators. They can compute any function, whether it's linear, like as like a straight line or nonlinear, like a very curvy line, like a parabola. They can, they can, they can approximate any function. And that's why we use a nonlinear, so they can approximate both linear and nonlinear functions.

Speaker 1:          09:50          This is the, this function helped us compute the partial derivative with respect to each weight going backwards, right? So it's the, it's the derivative of the sigmoid function and that's what's going to help us compute compute backpropagation. So this class is a, is a layer class. Each layer is initialized by its input dimensions and its output dimensions, which are the, the dimensions of the numbers going into it and out of it it's got a nonlinearity, which is our sigmoid, and it's got a nonlinearity derivative, which helps us compute the gradient value. So each layer is initialized as a weight matrix of some size that we defined here. It's also got a nonlinearity and a nonlinearity derivative, right? That's how we initialize a layer. It's a glorified weight matrix. Then we've got a forward and backward forward and backward function. The forward function takes the input it's given and it takes, it takes, the input, multiplies it by the weight multiply, meaning the dot product, right?

Speaker 1:          10:50          When we multiply two major seats together, it's considered the dots product. That's why we use, that's why it's considered linear Algebra and not regular Algebra. That dot products comes from linear Algebra. Linear Algebra tells us how to multiply to groups of numbers together rather than just single integers, which is what Algebra helps us do. That's what we use, linear Algebra and deep learning. And so I do the input times the weight and we apply an activation or a nonlinearity to it and put times weight out of bias. We're not adding a bias right now, uh, for, for this simple example and then activate, right? And that's going to give us our output. So we repeatedly apply this forward, this forward function, and that's going to compute our forward propagation. And then for the backwards step, the Delta is the greatest value for the backwards step. We take the uh, partial derivative of the output value, which is the predicted output and we multiply it by the gradient, right?

Speaker 1:          11:44          And that's going to give us the, uh, the, the great value for that weight. And then we returned that. And then one more function, which is the update function, which says, okay, you've got your Delta or your grading value, multiply it by the input and that's, and then, and then subtract it from our weight values and multiply and multiply that by an Alpha value, which is the learning rate. And that's going to give us the updated wait after we computed are backward propagation process. Okay. So we start off by saying we don't want this. We want this to be a deterministic algorithms. So it's going to compute the same results every time, which is useful for debugging. We've got a number of examples, our output dimensions, how many times do we want to train a thousand? And then we generate our Dataset, right? Using the function we defined earlier for x and y.

Speaker 1:          12:31          Then we say, okay, we've got our three layers and we define them as such, right? We have our dimensions for the size of each, we have our nonlinearity and we have our nonlinearity derivative. Those are our three layers. Then for our training process, we're going to say, okay, here are our batches of our x and y, our training data and our, our training, uh, input data and our output data as well, right? The two binary numbers concatenate it together would be a s a batch or a set of our training data. And the why would be the expected output, right? So what we do is we forward propagate, taking that first input data as the input to get the output value. And then we forward get forward, propagate that output as the input to the next layer. And that's going to give us the output for that layer.

Speaker 1:          13:15          And then we take the output for that layer and we feed it, has the input for the next layer that's forward propagation. And so now we have this output prediction. When we subtract it from the expect expected outputs, and that's going to give us the error value and we use that error value to then as input to the backward propagation for the layer before that to give us a gradiance values, right? The delta, the change. And it's using the partial derivative with respect to the weights for the previous layer to compute the gradient. And we do that recursively every time. And once we have all of those gradients, then we can update every single layer and then we are done with that. And so if I compile this, noticed how the loss decreases every time. And as the number of iterations increased, the loss is slowly and slowly and slowly getting smaller and smaller.

Speaker 1:          14:07          Okay? So that is the, uh, back propagation process. So. Okay, so now let's talk about the problem with backpropagation. So backpropagation is how all of supervised deep learning works. The majority of deep learning, we have labels for our data, but there is a problem here. So check this out. This is an example of backpropagation right here at very simple example of a three layer neural network. So a layer can only be updated after a full forward and a backward pass has been made. So after layer, the first layer has processed an input. It updates after the output activations. These black lines right here have been propagated through the rest of the network, generated a loss and the error gradients, these green lines have back propagated through every single layer. And what this means is that layer one must wait for a full forward and backward pass.

Speaker 1:          14:56          Every single layer that comes after that. So layer one is locked, it's coupled to the rest of the network. So for this simple example right here, or the one that I just demoed programmatically, it's not a big deal. But when we get to more complex neural networks, that's where things start to get hairy. Right? For example, the inception network, it's a huge convolutional network with 19 layers or the differential neural computer with, it's a separate memory unit or you have the neural Turing machine or you've got bi-directional recurrent networks, just insanely complicated neural networks with all sorts of moving parts. When we get to more complex systems, the time it takes to have to wait for the gradient to be back propagated through every layer is inefficient. Ideally, uh, we don't have to wait, right? So over a big distributed network over multiple machines, this could take a very long time having to wait for every layer.

Speaker 1:          15:52          So if we decouple every layer, the connections between them so they can update independently without having to wait for the other layers to update, that would be more efficient. Right? And so that's the idea behind synthetic gradients, right? So normally a neural network compares its predictions. A data set to the side had an update. It's weights, right? It uses backpropagation to figure out how each way it should move in order to make a prediction. But we'd synthetic gradients, individual layers make a best guess an approximation of what the gradient would be. It's not the actual gradient. It's a synthetic grade, a fake gray, a predicted gradient. And so this best guess that each layer will make into synthetic rating model is called the synthetic graded. And the data is only used to help update each layers. Guesser. So how are these synthetic gradients generated? I'm going to talk about that in a second, but what this does to system of approximating gradients at every layer is that allows individual layers to learn in isolation without having to wait for the other layers which increases the speed of training.

Speaker 1:          17:04          So this is kind of what it looks like right here. So we have some input, right? We have some input data, we apply it to the first layer, so input times weight out of bias activate, and then we send the output to the next layer. Then rather than waiting for that, uh, for that data to four, propagate through every single layer, compute the error and then backward propagate the gradients again and again and again until we get that great hands. And having to wait for that full forward and backward pass before we can update it. We just take the input apply. We just take the input times weight added, bias activate, send it out, and then we use what's called this synthetic gradient generator to immediately update the, the wait for that network. So we take an input to compute and output and then update it without having to wait for, for forward and backward pass.

Speaker 1:          17:54          And we do that for every single layer. So you might be wondering, okay, how is this possible? Right? This Gif, how are, how are you able to generate a synthetic gradients without having, how are you able to do that? Well, the answer, the answer is the synthetic gradient generator is in fact another neural network. It's another neural network. It's a very, very simple single layer network, right? They, the deep mind found that even when they use a single layer linear, a layer as a neural network for the generator, it still works really well, right? So it doesn't have to be some complex neural network, but basically the synthetic gradient generator is a very simple neural network that's trained to take the output of a layer and predict what the gradient would be, the likely gradient at that layer. It's simply a neural network that predicts what the gradient would be when we perform a full forward and backward pass, then we get the correct grade.

Speaker 1:          18:52          We can compare this to our synthetic gradient so we can train our synthetic gradient networks by pretending that our true gray ants are coming from this mythical dataset. So if we look at this image right here, uh, noticed how the gradient for m I plus two back propagates through f one plus f I plus one and into [inaudible] plus [inaudible] plus one. So each synthetic grating generator is actually only trained using the synthetic radiance generated from the next layer. So for every layer, it doesn't depend on every single layer before that, right? Because back propagation is a recursive process rather than having to wait for the gradient to be computed for every single layer. It's only taking the, the, it's only taking the computer great from the next layer. Every layer only depends on the next layer. That's it. So the, the, the synthetic gradient generator is a neural network and it, it, it generates a synthetic radiance and it compare that synthetic gradient to the actual gradients and an actual gradient is a great end that's computed from the next layer and it computes an error value using that.

Speaker 1:          19:59          And then it updates its way. It's using that and it's, and it sends the s the synthetically generated gradient to that layer. And that's what updates the layer. So every single layer is using this synthetic radiant generator to update its weights. Only the last layer, Jen updates its weights using the true gradient value because there is no next gradient. It's using the true, uh, output label to compute it's gradient. And so what's happening is because every layer is dependent on the next layer, just just, just on the next layer to compute it's synthetic gradients that what happens is it doesn't magically allow for a neural network to train without having that the true gradient backpropagation the true gradient is indeed still percolating backwards. It's just slower. You see what I'm saying? So the, the true gradient is slowly percolating backwards, not like the real grading every time, right?

Speaker 1:          20:53          Because only the last layer is computing the, uh, output using the true label of the data. But every other layer only uses the, uh, only updates. It's weights using this it's own, it's own respective synthetic gradient generator, which uses the gradient from the next layer as it's, as it's true, great aunts versus it's synthetic gradients, right? So the true gradient is slowly propagated backwards. However, because we're using the synthetic radiant model to approximate and smooth over the absence of true gradients, it's faster. And so they, they found that this could be applied to any type of neural network architecture, not just feedforward networks, recurrent networks. It's an awesome strategy. I would like to see more of it, uh, integrated into major deep learning libraries. And it allows for the training of distributed networks to be faster and cleaner. So what I want to do is I want to update our code so that it's now using the synthetic grade model rather than the backpropagation model. I'll name this class the decoupled neural interface instead of a layer. Okay. And so I'm going to say, so this stuff stays the same as before. This doesn't change at all these weights, the nonlinearity and the nonlinearity derivative, they don't change.

Speaker 1:          22:12          But what changes is this, we have some new stuff here. You have some new stuff, and that's going to be the weights of the synthetic gradient generator, which we can initialize randomly, just like we would for any, uh, weight matrix for unregular neural network. And it's going to be generated using this output dimension size, just like that.

Speaker 2:          22:36          MMM.

Speaker 1:          22:40          Just like that. And we have, it's, it's going to have its own learning rate, right? So this is the synthetic gradient generator, which is its own neural network. So now we want to update this forward propagation step, right? So

Speaker 2:          22:53          okay

Speaker 1:          22:53          to update this for propagation stuff, here's what it's going to look like when I update it for synthetic gradients. Okay, so this used to be just the Ford set, but now we can update during the Ford pass using synthetic gradients. So we have some cash input, we forward propagate that input and then we generate a synthetic gradient. Be a simple linear transformation, right? So we use that weight matrix to compute the a dot product with the output. And then we get our synthetic gradient, right input times weight matrix, no bias.

Speaker 1:          23:24          Then we can update our regular weights using the synthetic gradient. So we take the partial derivative of the output times is synthetic radiant and that's going to give us the weight update that we can apply to our real weights for that layer. It's called weight synthetic gradient. And the way we apply it is by multiplying the input times the transpose of the transpose of the product of that synthetic gradient out, uh, synthetic gradient multiplied by learning rate. And that's how we update the wait for that layer. And finally we can return the back propagated synthetic gradient and the forward propagated output. So we're, we're turning the back propagated synthetic gradient and we are returning the four propagated output at the same time, right? So, uh, each layer gets an input it for propagates that input and at the same time it's updated would they synthetic gradient value, which is very cool. And so in this case, we don't even need this backward step. So we're going to replace the both of backward and the update step.

Speaker 2:          24:23          Yeah.

Speaker 1:          24:23          Uh, with this new update, synthetic weights, a method where we, this is just like the update method from before accepted operates on this synthetic weights, right? So we are updating the synthetic gradient, a generators, weights that separate neural network. We've already updated our real layers weights. Now we want to update this synthetic gradient waste, right? So what we do is we say we take the synthetic gradient minus the true gradient, which is the gradient from the next layer. And we use that to compute the, the, the Delta, the change. And then we use that Delta to update the weights of our synthetic radiant generator. So then what is the difference here? While the difference now is instead of using each delayer class to define these layers,

Speaker 2:          25:07          okay,

Speaker 1:          25:08          we'll use the decoupled neural interface class where we have our input dimensions as for the size of the input, the sigmoid and this, the the activation function, and then the derivative, and then the learning rates. And that's how we define every single layer. Generating our batches stay the stays the same, but the forward and the backward pass are changed entirely rather than it being a separate forward and a backward pass. We have instead a forward and synthetic update pass and then we can update the synthetic gradient generators after that. So

Speaker 2:          25:41          yeah,

Speaker 1:          25:42          let me just move this out of the way.

Speaker 2:          25:44          Okay.

Speaker 1:          25:45          Right. So we have, for every layer we're doing are we're for propagating the input data from that layer. And at the same time we are updating its weights using the synthetic radiant, uh, when we do that for every single layer. Okay. And so then once we have that, we want to update the synthetic gradient generators, weights. So we, we say, okay, we know what the, uh, real output is going to be. So this layer three Delta is the true gray and we only compute that for the last layer. Every other layer is updated using synthetic radiant generator. It's respective synthetic rating generator. And

Speaker 1:          26:24          then, and only then do we update. Uh, so that's the old to only the last layer is, is normally updated. It doesn't have its own synthetic gradient generator, but every other layer does. And so we use that gradient to then update, uh, the synthetic weights for each of the generators, uh, backwards. Right? And so that's going to end, so, right. And so that's how synthetic radiance work in a nutshell. And I think it's a really cool idea. I'd like to see more people looking at it. I like to see more of an applied in deep learning. Tensorflow. All the major libraries should, should have synthetic gradients as an, as a, as a Dalit optimization scheme. And I think we're gonna see more of that. If you want to learn more about artificial intelligence, about blockchain, about some of the coolest technology out there, hit the subscribe button for now. I've got to go define proof of proof of proof. So thanks for watching.