Speaker 1:          00:01          Okay.

Speaker 2:          00:07          Hello.

Speaker 1:          00:16          Okay.

Speaker 2:          00:21          Hello. Okay, wait, somebody's going to hear me right? You can hear me? I'm testing this.

Speaker 1:          00:32          Hello. Okay, wait, I'm going to hear me like, all right, I'm testing this.

Speaker 2:          00:44          All right, perfect. So, okay, cool. Here we are. Hi everybody. What's good? What's good? Welcome to this. We're about to code some stuff about to code some stuff. All right. Um, there's like an echo, which is weird. So like I can hear myself after I've typed something, so I'm just gonna lie. Mute my own voice. There we go. Okay. So yeah. Okay, here we go. We're going to code some game ais with open AI gym. Open Ai is the, uh, startup. You know, Elon Musk a startup. They want to decentralize everything. Decentralize Ai, make sure that it's not in the hands of just Google. So I'm a big fan of that. Uh, so yeah, I want to start off with like a few minute Q and. A. If anyone wants to ask me anything, we could just get on that, you know what I mean? So what's up? Everybody ask away. I will wait just a little bit and then we'll get right into the code. I've never done this before, so this is, do I think I'm a brogrammer? I, I think sometimes that happens. I think from time to time I'm a programmer, but I really try not to be like, I don't want to be a programmer, but like I, I, I think I can be sometimes. How old am I? I am 25 years old. I'm 25 years old.

Speaker 1:          02:23          Yes.

Speaker 2:          02:24          What do I do for a living? I do this youtube thing full time. Uh, I, that's, that's my living. I just through youtube full time, I'm not making that much right now. I mean, you know, it's, it's, it's getting better and better, but right now it's like, it's, you know, it's, it's still a climbing up in terms of the money I'm making. Ads are not good by the way, like that, that stuff is just not working out. So there are other methods, uh, clients approaching me and stuff to make videos for them. Uh, what ingredients do I usually put on hamburgers? I usually put a, Oh my God, these questions are really coming in. Uh, what in Greece I put on hamburgers. I put a onions. That's right. I know a lot of people hate on you, but I loved them and I like everything is spicy.

Speaker 2:          03:11          It's probably because I grew up eating spicy food because my parents are Indian and I was born in Texas, so like double spice whammy there. What is your favorite machine learning library to use? It is tensorflow. Are Your parents? Are Your pants a compressed file? Because I'd love to unzip them. Thank you. They are compressed right now. Are you an AI researcher? Not Officially. What's your qualifications? I went to school at Columbia studying machine learning there. Worked in the robotics lab, worked at Twilio, been a software engineer for two years, studying machine learning for two years on my own. Are you going to school? No. Uh, no. I'm not. School is overrated. Learn everything from the Internet. I know that's kind of like, you know, weird or whatever, but like learn everything from the Internet. Traditional school is stupid. Where do you work? I work on this youtube channel fulltime.

Speaker 2:          03:59          What's your education? My education is a college undergrad. Are we all just modifying scripts? I guess. So when did you start programming? Uh, like freshman year of college I was, uh, I was like studying finance and I was like, okay, Yo, I need to like make some money. I want to, I want to do some great things in my life. So I'm, so I took a semester off and I went to Europe for a Guy Kalscheur for three and a half months. I stayed with a guy named Alex McCall and he was awesome and he like inspired me. He wrote, he wrote the book on Java script and he has a startup now and he traveled the world for a year. So I think just meeting somebody really inspirational and person just changed me and I was like, okay, I got to do computer science stuff. So it was freshman year of college. Have you taken psychedelics substances? The answer is yes. Uh, do it in a controlled environment with someone you care about. Would you present wavenet I have in a video check out generate music with tensorflow.

Speaker 3:          04:59          Uh,

Speaker 2:          05:00          yes. I'm going to do a video on Google's do research paper, the machine machine translation once soon. A brain fuck machine learning program. That would be awesome. Uh, okay. What's your favorite computer vision project? Uh, probably um, open CV still because like, I mean, you're Europeans have like tried to make their own CV thing. Sorry. W Americans are still better as software definitively. If you learn everything on then how do you prove that what you know when you apply for a job if you have no title?

Speaker 3:          05:32          MMM,

Speaker 2:          05:34          that's a good question actually. I mean with you Udacity, there's like nano degrees, so there's that, there's projects and then there's just like presenting yourself in person. So I think like your github repository, they get hub repository, get hub profiles. Are there new resume, at least if you're in software,

Speaker 3:          05:51          I, I want to do more than youtube,

Speaker 2:          05:55          uh, to inspire and equip developers. I'm looking at other methods. This is one way I'm experiments you right now. When did you start learning ml? I would say I started learning ml two years ago is a master's degree worth it. I think that a masters degree is worth it for two reasons. You get the time to study and you don't have other obligations. If you can, if you can find the way to have the time to study without a master's degree, then I would go for that because the bureaucracies involved with graduate school are totally get in the way. So really it's just about money and time. Like if you can find a way to study, go for it. That's what I did. The best move I've come across for ml is probably that you Udacity, one by Google on deep learning. It's that one dude who works at Google and it's using tensorflow and it's like four modules and Andrew OnX course is great, but it's totally overrated.

Speaker 2:          06:52          In fact, that's one of the reasons I started my channel because, because there's not enough application specific code, it's all just like, here's this like huge, uh, algorithm in this huge equation. Like how do whatever you want with it. And so my videos are more like, here's this huge algorithm, but like, here's what you can do with it. Favorite idol. Um, my favorite idol is probably a Kanye West to pop shucker, uh, and President Obama. Um, who else? Uh, let's see. I just like, like revolutionaries. People who like just don't, they don't, they don't give a shit. They just like, you know, they have something to say and they want to say it really loud. So, yeah. And also, uh, Ian Goodfellow at open AI because generative adversarial networks are awesome. Uh, and just like, uh, everybody who works at the mind because that stuff is awesome.

Speaker 2:          07:49          Why Heran Bay died? I don't know. Kiana or tensorflow, tensorflow because it has more support for it. How easy it is to find a remote ml job. It's actually really easy compared to other types of jobs. Uh, for someone new to ml, would Khan academy cover the math you need? Absolutely. I love Khan Academy and it Kinda counted me if you're watching this for some reason, you know, contact me because I want to get on that Murphy's probabilistic tests or elements of statistical learning. Uh, I would actually not recommend reading a textbook because for me, whenever I read a textbook I'm just like super bored. I'm like, oh my God, and by the end of the day it's like okay, I learned a lot but like really I just feel like I like what do I do with all this? Like I prefer like short form articles, long form articles, videos and implementing things.

Speaker 2:          08:36          That's the best way to learn for me is just to implement. So our, our June, I would just like go to get hub search and machine learning and just like start like recoding those projects that you see another job to earn more money. I don't right now I do this full time. Hopefully it works out R or python, 100% python for NL and data analysis are is like python is just way more modular. It has way more support. I did, I saw that youtube 8 million that's saying today my plans for the future. I want to be the bill Nye of computer science. I want to be like the guy who like people look at and they're like, that guy inspired me. I want to do machine learning. I just want to get everybody to do, to do machine learning. I think it's the future. I think that's what everything will be, is to, is everything is going to like involve machine learning in some way. If you don't know python, uh, and you want to do, see no dude, you should totally like python is better than c because c involves like, you know, dealing with memory and like deadlocks. If you're, if you're new to, if you're new to programming, you should definitely start off with python.

Speaker 1:          09:40          Uh,

Speaker 2:          09:43          how did I learn coding? I started to,

Speaker 1:          09:49          uh,

Speaker 2:          09:51          what did I do? Oh, I had this idea. Okay. So I remember in college the way I learned coding was everybody went home for this, for, for winter break. And I stayed in, so I was like two weeks and I was like, what are you doing? And I stayed in for winter break and I had this idea for the iPhone app or you could just like wave your phone like a conductor's baton and it would change the tempo of the music in real time. And so I was just like, I kind of do this. So just based on the idea, I like force myself to learn ios and like it was super hard. But like by the end, like when I finally started moving the phone and the, the tempo started changing. I had to learn about fast fourier transforms. I had to learn about audio engineering by, by the end of it, it actually works and the APP was kind of bad, but like it worked. And so that success like kept me going and it kept it make, it made me want to do more and more. Thanks for saying you love my channel of no js is better for machine learning, I guess it is. Uh, yeah, the Udacity course search deep learning. You Udacity, Google. It's going to be the first link. My favorite ml podcasts would be, uh, or blog would be, um

Speaker 2:          10:58          hmm. I'm not sure. I, there's so many. I just liked the machine learning sub. Right. That's where most of my stuff comes from. Uh, build apps in real time. Okay, cool. Yeah, sure. See US faster for sure. Um, but, uh, I guess, um, with python you can wrap seashells and then call them in python so you don't actually have to write the sea. So there see happening under the hood. But like python is great for like understanding things. The best tutorial for tensorflow are my videos so far. Uh, and also Google's official ones on their website.

Speaker 2:          11:33          Uh, so what am I sources for learning about big machine learning? This, the machine learning sub reddit. The um, what else is there? There's hacker news. There's um, the futurology sub reddit. There's um, I follow a few machine learning researchers on Twitter, so like a board, Yann Macun, uh, which is not real, but it's actually hilarious. Uh, and there's one more Balaji Srinivasan on Twitter. All of the guys who work at Andreessen Horowitz are all like really on the ball when it comes to what's next. I did do the Andrew on course. I didn't remember much of it. So like I would just like, that's like part reason I started my channel. Uh, cause I just thought it was boring. Hi. Uh, do you ever yes, I'm worried about advanced AI and I think the best way to solve that is to make sure it's democratized and everybody has access to it.

Speaker 2:          12:26          And uh, I think that we should, AI should augment ourselves. So we'll have like a neural lace in our brain or some kind of chip or something or even, you know what, the iPhone seven, you just put it in your ear. You can start talking to Siri. So it is going to be less and less weird to talk to your phone. But I think AI can augment us and make us better rather than it being like a separate thing, like a god that it just like controls us. It should make us gods. So that's what I think will help us, uh, not have an evil Ai. Okay. We're going to start building the game bought in 30 seconds. Here we go. I'm going to answer any last questions. Favorite place in the world. Go hiking is a Yosemite. How do I, do I keep myself fit?

Speaker 2:          13:09          Yes. I go to the gym. Yes, I would collaborate with ml people. Game Theory and Ai. That's a long question. Uh, if you want to become an AI researcher, start learning, uh, just go to get and like, uh, go to the tensor flow, uh, get hub repository to the model section and try to re implement all of those models. Okay, here we go. We're going to start building this, this Bot. Uh, yes. I like, um, drugs from time to time. Okay, here we go. We're going to start, we're going to start building this thing. Okay. So I'm going to start sharing my screen. I just have to just get, get on this. So the first thing I'm going to do is share my screen. Okay, here we go. Desktop. All right. And here I am. I'm going to show up here. Okay, here we go. All right, so I'm going to go sublime and I'd say, and I'm going to say I'm going to make a directory and I'm going to say, let me just make sure that I'm, I'm still on here. Okay.

Speaker 1:          14:11          Okay,

Speaker 2:          14:11          here we go. We got a minimum. I'm going to minimize this so I don't have to. Okay. There we go. All right. And this is going to be minimized. Make sure it's all good. I'll put this up here and we're going to get started in a second. It's Laggy, right? It's laggy, but you guys can still hear me right? Like even though it's laggy.

Speaker 2:          14:36          Okay, so here we go. I'm going to say make directory. I'm going to make a new directory. So I'm going to start this, this spot. I'm going to say make directory, uh, test one, test two, test one that already, just make your artistry cats too. Okay, so TD tube. Now I'm in my text to directory, right? Okay, here we go. The first thing I want to do, um, okay. Make sure it's all good. There's so many windows open right now. Holy shoot. Audio is not laggy at least. Okay, cool. Green Cli is for real hackers. Well, I like whatever I like. Okay, so here we go. So first thing want to do is clone a gym. So the gym repository is the, the, the uh, reinforcement learning library creative by open Ai. We're going to quote it into this. Oh, increase the font size. Good call. Thank you. Thank you. How do we going to do this? Boom, boom, boom, boom, boom, boom, boom, boom, boom. Right?

Speaker 2:          15:30          How's that? Okay. We increase the font size. I'm in the corner over here. Boom. Make sure it's all good. Okay, so now that Jim is in here, we're going to CD at the gym. The gym is like a training for AI. It makes it better and better over time. And we want to install everything. So we're going to use PIP r python module to install literally everything. Okay? So it's literally gonna install all of our dependencies for python, for Jim. And that's it. That's all. So one one just has done, we're ready to go. Okay. So now that we've installed a gym, we're going to run our first environment. Okay. So let's, I'm going to use sublime. Sublime is my text editor of choice. And I'm going to say test, run dot pie. So it's got an open that up and sublime. So I'm going to bring that down here. Okay. And

Speaker 4:          16:21          here we go.

Speaker 2:          16:24          Here we go. Here we go. So the first thing we'll do is I'm going to import gym. Okay. That's, that's the environment. And then I'm going to create an environment. Okay. So it's going to be Jim. Um, Jim. Yeah, this is going to be on the channel at the end of the transmission. Uh, you're going to be able to view it afterwards. So yeah. Anyways, so, so, so this, so the first step is to initialize the environment. What are we going to train the agent in a, okay, so bright. So it's Kinda, it's Kinda not HD right now guys. I'm sorry about this, my first live stream, but uh, it's going to be better next time. If I do this next time, I probably will. Cause this is kind of fun. Our increased font size. Good call. Good call. Good call. Thank you. Thank you. Thank you. Here we go. I'm going to increase the font size. Let's see. Ooh, boom, boom, boom, boom, boom. Okay, that's huge. All right, so we're going to initialize our environment. It's going to be card pole. So the car pull environment is jets like a stick, right? So the carpal game is like a stick and it's just trying to balance as as a box move.

Speaker 4:          17:28          Okay.

Speaker 2:          17:29          Okay. I don't use an ide because I don't have time for that. It's just bloated. I just want a simple, you know, python just super fast. You run a script, that's it. Okay, so here we go. So we got card pole, right? And we're going to reset the environment, which means like it just makes like, let's get started. Just to me it's like initialize, like the environment is ready to go. So we're going to run this for a thousand steps. Okay. So we're going to say what salads and time steps. And for each time step we want to render the environment. So we're going to say, okay, so then we're going to be able to view it. Okay. So we're going to say, take a step and step means, uh, we're going to take a random step. So that'd be the agent. In our case, it's going to be the carp. Coal is going to move in a random direction every time. And so the, uh,

Speaker 2:          18:14          so the method of doing this is action space sample. So that's the method that says pick a random action. Okay. Okay. So let's just see how that, how that works. We're going to run that just, that's great. That's it. So we're going to say python tests, run dot. Py. Boom. What happens of python tests run stuff. Pie and valid syntax. What the hell? Okay, here we go. Oh, you're right. Yeah, that thing. Cool. Let's run this little module name requests. Oh my God. Here we go. Uh, okay. So we're going to make sure we have virtual environment. We'll create a virtual environment, right?

Speaker 5:          18:55          Uh,

Speaker 2:          18:56          all right. Thanks guys. Okay, so we have a virtual environment. We're going to source our virtual environment, which means that we can see what's going down here. Okay. And we're going to say pip install requests. Okay. And so then we're going to run it again. Oh and non pot. So, oh, I gotta re-install like that. Blah, boom, boom, boom. Let me go to reinstall Jim. One more time. I forgot. You have to, you have to uh, Redo your environment. Okay. Uh, virtue. You have to create a virtual environment so that your dependencies aren't all over the place. I always create a virtual environment for every repository that I'd mic.

Speaker 5:          19:40          Okay.

Speaker 2:          19:41          Okay. So once this is done, we're going to run this code. This is the code. One more time. We create the environment a thousand times steps render at every time step and then take a random step. That's all it does. Hey, thanks for coming to the party, Anthony. It's all good. Here we go. Test run. Let's see it. Boom. Okay. That's it. That's all I did. It just ran for a thousand times steps and then doing it. Didn't learn anything. Now we're going to add a little bit of logic to this. Okay. So the great thing about Jim is it is a reinforcement learning library. Okay? It's, it's all about learning with through trial and error. The agent is going to get better and better over time. Uh, okay. Uh, our June a virtual environment is kind of like, uh, it's, it's, it's, it's like creating a container where you say, okay, I don't want to have to deal with anything else on the, on my operating system.

Speaker 2:          20:34          I don't want to have to mess with any other dependencies. I just want to be in dislike, empty box. And in this empty box, I'm going to reinstall all of my, uh, Oh man, these, these comments are hilarious. I'm just going to install all the dependencies that I need for this specific repository. I do it every time I have a new repository. Okay. So let's, so let's make this thing smarter. Let's add some actual machine learning in here. Okay. So we're gonna keep, we're gonna keep this car pull environment. Okay? And I'm going to, I'm going to say for a number of episodes,

Speaker 2:          21:11          I'm going to say for a number of episodes, let's say I episode, each episode is like, if you know your cart falls over. So I'm going to say for a number of episodes in the range of 20 to two for 20 episodes. So for 20 episodes, I'm going to get my, an observation from my environment. And observation is different depending on whatever your environment is. Jim has like a thousand environments. You could have pac man, you can have a bunch of Atari Games, you could have even three d games do. So we're just using Karch poll because that's simple for right now. So I'm going to say, okay, so for this observation we're going to reset, which means like just get that first observation, okay? And then we're going to say I want to a hundred times steps for every, um, when a hundred times steps for every uh, episode. Okay? So we're going to render this environment at every time step and we're going to print out whatever we're observing. In our case, in the case of the card pole, it's going to be the, an array of velocities of where the car pool is moving. We haven't done any machine learning yet, I'm just rendering this thing as it moves. Okay? But we're about to, this is the machine learning part. Okay. I'm going to take an action. Okay. And this action is going to be a random, it's, it's going to be a random action and

Speaker 2:          22:33          or range. 100 okay. T and range 100 yes. Oh yes. Thank you. As he, as he, Yup. Yup, Yup. Good call. All right, cool. I'm not running on a GPU. I'm running on a CPU on a Mac book. Okay, so here we go. So for that action, we want to take a step and a step is going to complete the ancient environment. Luke. Okay. I'm going to explain that in a second, but we're going to get back an observation. So we're going to get back an observation or reward done info and we'll take a step. So what's happening here is a step function completes an action and it returned back four variables. The observation is what it sees. The reward is a, it's different depending on whatever environment you're in. In our case, it's at, the pole is still standing up. So it's going to be a set of philosophies.

Speaker 2:          23:27          Done is just a boolean. Like did, did we die or not? An Info is a bunch of diagnostics. That's it. That one line is the reinforcement learning that's happening here. Okay. So we're going to say like, okay, so if we're done, if we're done then just printout. Okay. Episode. It's finished. Windows is not life. Uh, windows is bad. The sorry window sucks. After time steps, uh, after whatever number of times, that's okay now and then we're going to say break. We're going to say break. Okay, so let's run that. Okay. This is the actual machine learning. It's important learning c agent environment loop. All right, so let's run this baby. Boom.

Speaker 1:          24:16          Yeah.

Speaker 2:          24:17          So what does printing are the velocities like as it's moving, it's learning to get better every time. Okay. And so the episode is finished so that that trains our agent and we can save those weights over time. Um,

Speaker 2:          24:33          oh, let's see. Let me answer what I miss. The old hello world. Hello world. It's Suraj. There you go. There is, there it is. Okay. What does step actually do? Step completes. An action step is a function that takes an action and actually implements it in the, in the rendered environment. Uh, make a bit for synthetic gradients. Paper that Yo, I really want to make one. I had been waiting to make one on that paper. That paper is so dope. I want to read that paper. I was like, oh my God. Back propagation is not a thing anymore. This is amazing. So yes, I will make one on that. [inaudible] to his life a true word. Word. Is there a way to run tensorflow and open AI on windows? Great question. I know there's a way to run flow. I'm not sure about open Ai. Okay. So that was the, that was a simple problem. Now I'm going to, uh, let's see. I want to do something a little more complicated. So, uh, I'm going to say we're going to, we're going to, uh, do something a little more complex. So we're going to do the same thing in the car pool environment, but we're going to,

Speaker 2:          25:41          uh, use something called hill climbing as a policy. Okay? So help climbing.

Speaker 2:          25:48          Oh, climbing means we're going to, and not just to not just try a bunch of random steps, but update our weights by, uh, making sure that, Hi Nico. Uh, yeah. All right. You guys are getting obsessed with we'd now like, all right. Just chill. You know what I'm saying? Okay. Here we go. We're, we're, we're, we're, we're focused right now, right. Okay. Here we go. We got to be focused. Let's, let's focus here. All right. So he'll, climbing is a technique where we say, ah, initialize weights randomly and we're going to initialize waste randomly and then, and then if, if the weights are are good, if the reward is like a good thing, then we want to save those weights. So we, so we incorporate memory into this as well. It's not just randomly trying things. We use our memory just like our, you know, our brains use memory as well. So utilize memory to save. Oh wait, it weights.

Speaker 2:          26:44          Yeah. Focused. Exactly. Essentially. Oh, the Arduino. Yes, there is the Japanese to come. Or farmer did, did something like that. If you go to get hub and type in tensorflow, Arduino, I promise you 100% you will find at least three repositories. Okay, so here we go. So, um, right. So, oh also I'm want to import num py cause I'm about to do some, some math magic in here. Okay, here we go. Why don't just be stuck at on local maximums? No. Okay. So, so first thing I'm going to do cause define a run episode. Okay. I'm going to say the two parameters for that are going to be the environment and a parameter. It's a parameters are going to be the weights. Okay.

Speaker 3:          27:22          MMM.

Speaker 2:          27:26          So this, hold on a second. Okay. So this isn't, this is going to be art, our implementation of the Asian environment loop. It's going to take our agent from start to finish and it's going to result in some reward value depending on whatever action. And we're going to initialize it after we've initialize our environment. Okay. So this is a function that we're going to initialize after we initialize our environment. Okay. So

Speaker 3:          27:50          mmm.

Speaker 2:          27:52          Well the stream be available to watch tomorrow. Yes, it will be. And I'm going to end it in like 10 minutes. Okay. So that's cause that cause I've got some technical writing to do and I've got other stuff to do for the channel. Okay. Here we go. So first off, first things first. Okay. We're going to get, okay. First things first. We're going to get our observation like we always do. All right. That's the first thing we do in an episode. And then we're going to get to make this total reward variable. Yeah. Contested on Mario. I'll will remember that for next time. Uh, so for 200 times steps.

Speaker 3:          28:26          Okay,

Speaker 2:          28:27          we're going to do this. Okay. So for in the range of 200, we're going to render our, you can test it on literally any game. Ameya yes, yes. I'm going to upload the sample code, Carlos. Absolutely. Absolutely. I'm going to put it into the description for this video. Okay. So we're gonna say, okay, go ahead and render and render our environment like we always do. Okay. So now we're going to initialize random weight sectors. Okay. So I'm going to say,

Speaker 2:          29:02          so I'm going to say, um, take an action. Okay. And if it's zero. So actually I'm just going like type this out cause like it's hard to do like a million things at once. Her. Now let me just type this out and I'm going to then explain it in a second. Okay. It's less than zero out swat. Okay. So what's happening here is I'm initializing random weight factors as parameters and multiplying by risk, their respective observation. And I'm going to use matrix multiplication to some of the products and if the total is less than zero, then we move left El swing move. Right? So what this is doing is it's randomly initializing wait vectors to move the pole left or right. Okay. That's all it's doing left or right. Okay. Let me see what the comments up here are. Um,

Speaker 3:          29:54          okay.

Speaker 2:          29:55          Let's see. What's the difference between range and x range? Uh, so in so rank returns a list, an x range returns an x ray and objects. We'll just kind of like an iterator and generates numbers on demand. Um, I think like I,

Speaker 2:          30:15          it's weird because in python three range does what x range used to do. An x range doesn't exist. So if you want to write code that will run on both python two and python three, uh, you shouldn't use x range. So I'm just being weird. So like don't just like use range like yeah, exactly. Mighty magic though. Yeah, exactly. So, um, can you upload where you've, Reebok has this video later? Yes. Okay. Um, let me see. Am I still okay? Cool. Everybody's in here. Everybody's good. Okay. So here we go. Where were we? So yeah, I've, I've initialized random weights, neutralize random weights. Okay. And then we got this, we can finish this guys in eight minutes are we got eight minutes left. And so I also try to squeeze in time for more questions, which you guys can also ask us. I'm doing this.

Speaker 2:          31:04          Okay, here we go. So, um, now I want to get my observation and my reward and done and info. And that's going to happen as I take the step function as always the environment, that stuff, and I took complete the action. Okay. And so now I'm going to increase my rewards. I'm going to say total reward. That variable that I initialized it for is going to get whatever is in my reward now. So if it's done, so that means if the whole tip too far, uh, if done, then break right and then return the total reward. All right, so there's that. So that is our, uh, run episode function. Okay. Hi. Read it. Yes, exactly. Exactly. So now,

Speaker 3:          31:54          MMM,

Speaker 2:          31:56          so now I'm going to do the actual train function. Okay, here we go. So training time, let's train this baby. Let's try this baby. What's the observation? The observation in this case is, uh, the, it's, it's an array of full of velocity values. So it's a set of vectors of where the pole is in space. What model does this actual use? Uh, the model is, uh, it's, it's, it's a type of reinforcement learning, uh, that is co is, it's the agent environment loop. Um, thank you Omar. I will definitely do more of these. It seems that you know, it depending on, you know, how you guys like this, which it seems like this is, this is good. This is kind of fun. This is crazy. This is like a rush right now. I'm like, I've never done this before. So I feel like I feel like I'm in the zone. Like, you know what I'm saying? All right, here we go. So, um, okay, here we go. So, so now it's time to initialize our environments. I'm going to say Jim. Dot. Make a card poll these zero. All right. And so now I've made my environment and now I'm going to say, okay, episodes her update.

Speaker 1:          33:11          Okay.

Speaker 2:          33:11          Equals five. So that's how many episodes I want. And so now I'm going to find a function called noise scaling. So noise scaling is the, is it's a value that I'm going to multiply my weights by every time so that they get better over time. So this is, this is, this is the actual hill climbing policy. So that's the name of the policies. Hill climbing, which answers your question? Um, a mighty magic. It's hill climbing. That's the type of policy.

Speaker 1:          33:39          Okay.

Speaker 2:          33:40          Uh, the environment line from above. Uh, let's see the environment line from above you. Oh, you know what? I do need to delete that. Thank you for. Thank you for catching that. Uh, his Sean. Thank you. All right, here we go. So noise scaling. All right, we did that. Total reward noise stealing. Where was I? Where am I based? Um, I will fix all that. I am in San Francisco, California. All right. Um, all right, here we go. So now I'm going to create my parameters. Why does this kind of like not like, oh, thank you. Uh, Lozier. Okay, so

Speaker 1:          34:26          yeah,

Speaker 2:          34:27          now I'm going to randomly initialized vectors of weights. We set parameters equals num, Pi dot. Random num, py dot. Random Dot whammed four times to mine. It's one that's going to neutralize I set of weights between negative one and one. Okay. That's just what that is. So then I'm going to say batch reward equals zero and that's the reward that I'm going to save later. Okay. So I'm going to run this for 2000 episodes. Okay. That's what I want to run this for. So I'm going to say in the range of of 2000 run this ish. Okay. Isn't always stealing like the learning rate in a way. Yes, yes it is. That's, that's a, that's a great question. It is. It is just like that. It is a, it is, it is something that that improves your training over time. Just like the learning rate does. Okay. So new prams equals parameters plus, um, none pied are random. And so this is going to be the same thing that that set of initialized weights between negative one and one minus one. And this is where, this is where the noise scaling goes. I'm going to say times noise scaling. This is the machine learning part right here. Okay. So it's going to update those wick, that new set of parameters every time. Okay. First Return. Not In a good place.

Speaker 2:          35:54          Oh yeah, you're right. You're totally right. Thank you. Thank you. Thank you. Thank you for that. Um, Andrea's okay, here we go. Here we go. Um, all right, so now, so now, okay. Reward is Ryan episode. We're going to get that reward. We're going to use our run episode function. Okay. That's going to complete the agent environment loop. And we're going to say environments as the parameter, the one we've just initialize and those, that new set of perimeters that we initialize. Okay. That's the, those are the two parameters that we're going to use. So that's gonna be a reward. And now we're going to print that. We're going to say prince.

Speaker 3:          36:36          Yeah.

Speaker 2:          36:37          Uh, we're going to print reward, reward.

Speaker 3:          36:41          MMM.

Speaker 2:          36:43          La. And then best, and then we're going to say, um, reward.

Speaker 3:          36:53          Okay.

Speaker 2:          36:55          Then best reward. So that's going to show us some good friends. Right? Okay. Here we go. Here we go. All right. One more like little last thing. Okay. So we're going to say if the reward, if the reward improves with noise, we went to update the reward and keep the weights. So if reward is greater than best reward, then that's reward. Well then become whatever the reward was and parameters, it's going to get what the new parameters are. And then finally, if the upper threshold of 200 is reached, which we want it set for the reward, then we break. That's it. Okay. Um,

Speaker 3:          37:36          okay,

Speaker 2:          37:37          so there's that. Um, where else are we? I'm struggling to like see anything here. Okay. So then, okay, so that's it. That's it. So now we're going to just run this, we're going to say try and we're going to run our train function with submit equals false cause we don't want it submitted it anywhere. And then we're going to say prince. Okay, so let's just run that shit. Let is, could you reduce noise over time?

Speaker 3:          38:03          MMM,

Speaker 2:          38:05          we could. We could, we could reduce it over time. Um, I think for this simple example, we're kind of keep it static, but there's a bunch of things. Yeah, no, absolutely. You could reduce it over time. You can try different, you can, you can make sure your weights aren't a random, you could try, you could try weights that, uh, our synthetic, I mean, you could look at different policies. That's the fun of it. Like open AI has totally gamified this whole process. So let's run that. Awesome. Okay. Sorry.

Speaker 3:          38:34          Yeah. Uh,

Speaker 2:          38:37          yeah. Oh my God. Okay. Uh, let's see what's going on here. Uh, what the F okay, but we'll name observations is not defined. Where is that? What line is that on? Global name observations is not defined. That is underlined 17 let's see that guys. What's going on here? Global name observation. Oh, observations is not defined observation. There we go. Run that. Oh, so, okay. So yeah, it's doing, it's doing hill climbing. It's doing, hey. Oh climbing. It's duly here climbing. Okay, cool. Okay. I'm really happy that this is working. Okay. Where's the next for the four? So it is trying a bunch of random weights and it is multiplying that noise scaling constant that we had before every time if the weights are better, it's remembering those weights instead of just continuously trying other new random ways and that way it gets better and better over time. Okay. This is going to run for probably like, isn't it so good when it works or the way it's part of a neural network? That is a great question. Mighty magic magic. It is. It is part of a neural network. Okay. It's a, it's a one layer neural network. So the best way is 11 and the old one is to the, to the best one is on the right. And the old one is on the left and

Speaker 2:          40:01          um, hopefully it's, it finishes soon. Yes, it is. It is like a genetic algorithm. Is there a way to make it deeper or change the size of hidden layers? Not with just gym. We would have to integrate tensorflow, which I can do in a future video. I actually, I think tensorflow and, and Jim go together very well. Uh, but

Speaker 2:          40:30          yeah, so, so yeah. So, so that's, that's a training. So now while I train, I'm going to answer, I'm going to give it five more minutes to answer any other questions. So I'll just like, just like go for it. Like, just the like whatever you want, I will reveal all, just go for it. You know what I mean? You guys have any questions and stuff? So let me just like a full screen this baby so there's less lag. Less lag. All right. Um, stop screen sharing. Okay. I think there's less lag now. Right? Okay. So, hi. Hi. Hi. So there's less lag. Can you show the show while, um,

Speaker 2:          41:14          the code while it's running as well? Uh, yes. I can show the code in a second. You know, I'm just going to link to it later. What is the best Linux sister to get started? The intention float. Who been to, uh, do you do more of these if you have time? I totally will. How many years until I Jarvis like AI is real? How would I would say a decade from now, uh, at, at a decade from now, seven to 10 years. Where do you start learning ml? Like fulltime? No. Period. A little. I did shit. Oh my God. I love it. You guys are so funny. Uh, where to start learning ml by channel. Start from video one. Go all the way through. Implement all the code associated with my videos. Thanks Tyler. You are awesome. I told him very well in two months for a Gig. Uh, Yo, uh, to watch my videos and also go to the machine learning sub reddit.

Speaker 2:          42:02          Go to go to it every single day. I've made it a habit of mine. I wake up, go to the machine learning, separate it, look through everything. People are super harsh in the machine learning sub. By the way, like they will just tear everything apart. Usually like skeptical people who are like super smart or like that. Anyway, if you meet one of these ml researchers, they'll just like these hyper critical people that was just like tear you down with their eyes cause you know, they're just like, hmm. You know, like scientists, right? Who is hiring for these skills? Absolutely. Everybody in fact that that nanodegree guy, you Udacity who I'm working with, oops, I just revealed that by the way, that self driving car course, like I'm an assistant instructor for that. Awesome. Uh, just cause the guy saw my videos, but uh, that guy was like, even if we had a dude, Dessi is awesome.

Speaker 2:          42:45          He's like, even if our course was full, we would still have like less than 1% of the need for self driving car engineers. So that, so who is hiring for these skills? Literally like everybody will soon start hiring for these skills. Like right now there's like a tech companies and not 10 companies, but soon every single company is going to be a tech company. Uh, awesome. Nico, you're awesome. Um, will you organize meetups as well? Actually having my first talk tomorrow at the write the docs meetup in San Francisco. Right. The docs. Cause you're asking me like how I do all this stuff. Uh, but yes, I want to organize meetups. Definitely shoot me an email with some ideas. Like I'm open to it. Uh, cool. How much math you think is needed to do real research? Yo, you, you definitely need some actual like real like cutting edge stuff.

Speaker 2:          43:36          You've then you've then you've got to know some math, I would say like linear Algebra, statistics and um, game theory. Um, and also just like, uh, like quantum physics that has nothing to do with machine learning, but like quantum physics, quantum mechanics, that's stuff is just like, it puts you in this way of thinking that I think can be applied to machine learning. Uh, Yo, I would love to come to Brazil at some point. Hi. Graph theory. Exactly. Yeah, exactly. Amazon is paying shit. Tons of gold and I would love to do, yes. I'm working with Sebastian through, uh, and uh, yeah. Wow. So everything cool. Wow. So this was a trip. All right guys. Well one more question and then I'm out. Whoever, whichever question I see first, let's see, just go for it. Just let's see it. I'm, I'm done. I'm ready for this. Yes. Anytime. How would you use ml to look at your video for example and see when the video change from just your face to the view? I'm sure. Um, uh, um,

Speaker 2:          44:53          uh, girls do think mls sexy cause we are going to make it sexy, right? Well let's make it sexy because we're awesome. Um, awesome. Do I own bitcoins? I do. I actually used to be super obsessed with bitcoins. If you guys look at my older videos you'll see like this big coin music video I made, which was actually pretty hilarious. But I definitely want to make a machine learning music videos soon. That's like more, you know, production heavy. Cause like once you get at 10,000 subscribers on Youtube and they'll let you use their studio space in La, which I'd like to use for a music video. I just don't have time cause I'm like doing this full time. Am I still a researcher or working for any company? I'm not working for anybody. I am working for me and then clients approach me. Thank you and I, no one can buy me out except for deed mine.

Speaker 2:          45:38          So yes, deep mind if you're watching you can totally buy me out. I will do anything for you. A to pocket machine learning video would be awesome. Do I program in other languages? Yeah, I mean like when I worked at Twilio, like I had to write documentation in like 10 different languages and like Ah, it's, but I just prefer python because it's just simple like you know, like this stuff is just like, I just want to get right to the good stuff. The logic, the algorithms, that's what matters is not the syntax stuff. Just pick some language and just go for it. Like, you know, and I would say it's python.

Speaker 3:          46:10          MMM,

Speaker 2:          46:12          okay. Deep learning is not going away anytime soon. It's going to evolve into something better in my opinion. We're going to start getting into one shot learning, like that's what's going to come after deep learning where you don't need like a huge amount of example to train and things. And what am I doing in my free time? I, what do I do in my free time? Yeah, that's a good question. So besides doing this, I uh, I ha I have recently started taking uh, like Bruce Lee classes to kind of be like Bruce Lee. I have freestyle rap.

Speaker 3:          46:43          MMM.

Speaker 2:          46:47          And I hang out with my uh, friends. And how did object to see break my heart. It really just, it's just when I saw swift I was like, Yo, you know, why did I, okay, I'll tell you how object to see broke my heart. I was like, uh, splitting strings let like like in like four or five lines of code in objective C. And I was like, Yo, this takes so long to do like, I just need like to do it in swift. You just do it in one line. In Python, it's just in one line. Objective c doing anything. Yes. G Cuando. Yes. That is exactly what I'm doing. I'm excited cause I met this dude. He's like his awesome. Why don't I do a freestyle rap right now and memorize my ml lyrics. Uh, I will do a quick grab a, here we go.

Speaker 2:          47:33          I mean I need a beat, but like let's just go for it. Here we go. I'm just going to freestyle you. I got back propagation. I do it for this nation. You guys see me? I'm like a hardcore fasion. Yeah, I'm from the planet. Facia. I came out here and take you synthetic south, like a geisha from Japan with all this stuff all around. It's like I'm Peter Pan. I fly in the clouds. Okay. That was it. Anyway. Uh, Yo Bayes is cool. I'm not saying anything bad about bays like basis basis. Pretty cool. A bitcoin trading bot, that would be a lot of Yo. Okay. Encore dot. Ai. That's actually my next video. Uh, I mean, nope. Thank you. A recommendation system. It's actually did build, build a recommender system. That's machine learning for hackers. Number four. Check that out. I got to Redo that video cause I used to talk way too fast and I know Anthony, I know that that was amazing. It was an okay. Okay. Um, Yo Yo yo yo. Okay. Meg Dg, let me like, I need to understand this question. Okay, thank you. I love Tunisia as well. I want to go there eventually when I go there. Okay. Kenta to flow.

Speaker 2:          48:49          Yes. I mean can it work with the video stream? I guess so. I guess I could work with the video stream. I don't know exactly what you mean by that. Like do you mean like training it on like video frames? Why no windows? Because I dunno like I switched over to Unix based systems and I never went back and I know like you know what Satya Nadella and stuff, Microsoft is trying to be all cool and stuff and like, you know, implement bash like a terminal. But um, I just, Oh also I switched to an android phone cause like Google now is way better than Siri. I think Kamiah I will be successful 100%. They're going to be bought out by probably Google A. All right guys. So that's it for now. I'm going to make more of these. Okay. Thank you for watching. I think this was a success. I'm going to hit stop broadcast and, uh, thank you all for being here and you're going to be able to see links to, to a, a bunch of things. All right. So thank you guys for watching. Um, uh, for now. All right, let's say for now, I've got to go to the bathroom to do things. Uh, so thanks for watching. Thank you. Bye. Love you guys. Okay, bye.

Speaker 1:          50:04          All right.