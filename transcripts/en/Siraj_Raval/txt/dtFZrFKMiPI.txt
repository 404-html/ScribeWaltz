Speaker 1:          00:00          Ai Is my Citi. Hello world. It's the Raj and what is the best laptop for machine learning? It's a popular question I get asked and in this video I'm going to talk about the best laptop desktop and DIY system for machine learning as well as the best cloud options when it comes to choosing the right machine for machine learning, you are usually choosing between the two factors, portability and processing power. The higher the processing power, the heavier the laptop is, thus the less portability it has and vice versa. Also, the higher the power, the lower the battery life and portability again, takes a hit. There are a few important components that you should think about when buying a laptop for ml, specifically ram, GPU processing, storage, and the operating system. When it comes to Ram, the minimum amount you need is eight gigabytes. Although 16 gigs is what I recommend for faster processing for heavy ml algorithms like neural nets or random forests.

Speaker 1:          01:06          Rams important since it significantly speeds up computation time for training AI algorithms, but no feature is more important than what GPU you're using. Deep learning. The most popular subfield of machine learning involves in neural networks. It's also the most computationally expensive. It requires calculating massive amounts of matrix operations to train and GPU is enable highly parallelized matrix operations, which speed up the process. With no GPU training, a model could take months, whereas with the right one it could take an hour. It allows you to quickly iterate over different versions of your neural network and speeds up the entire research and development pipeline by orders of magnitude. Making the right choice here is critical and video brought desktop class graphics to laptops with the g force 10 series. Picking from one of these that are in your price range are the best gps to get for a laptop.

Speaker 1:          02:12          Most deep learning libraries like tensorflow and Pi Torch use the Kuda processor, which compiles only on Nvidia cards and looks like you missed the boat buddy. If you want to use a machine powered by an AMD or Intel HD Gpu, you should be prepared to write some low level code in open cl. For a processor. The minimum requirement would be an intel I five. Also the [inaudible] seventh generation would be ideal for storage. You should have one terabyte minimum of hard disk space. Since data sets seem to be getting bigger day by day, if you're choosing to go for a machine with an SSD, make sure it has two 56 gigs of SSD storage available else you might have to purchase an external hard drive. Lastly, for an operating system, you'll want to go with Linux, although both Mac and windows can run Linux as either a virtual machine or on startup using software like bootcamp or parallels.

Speaker 1:          03:12          So when it comes to the best laptop to get at the highest end, a startup called lambda labs wins here with their or book laptop. They're using an Nvidia GTX 10 70 GPU and Intel I seven processor there. Max version looks truly remarkable and they've also taken the time to pre install a bunch of popular machine learning libraries like tensorflow and Pi Torch that includes all the relevant to Kuda libraries and video GPU drivers as well as developer tools like them, emacs and t mucks. It's made for deep learning and ready to go out of the box, but they are pretty pricey though. So for a middle range budget to Nvidia has aligned of gaming laptops called the g force GTX 10 series line powered by their pascal architecture. The 10 series dropped the distinction between desktop and mobile cards, so you won't be giving up as much peak performance as in the past by getting a laptop.

Speaker 1:          04:13          Msi is the best of the bunch packing in some serious computing power into a relatively lightweight laptop and you can buy it from a bunch of online retailers including Amazon, although they're marketing them for gaming, they are very well suited for any kind of machine learning. If you don't have the budget for one of these, I'd recommend just getting the cheapest laptop you can code on and connect to the Internet with like a Chromebook, you can then use all the money you saved for thousands of hours of compute time on one of the many AI cloud computing platforms that have GPU like AWS, Microsoft Azure, or Google cloud. A zero generally has the lowest on demand pricing. Well, AWS runs in the middle of the pack. Yes. I just endorsed a Microsoft product. Where is your God now in terms of the easiest service to use? I'd say Floyd hub wins.

Speaker 1:          05:09          It's a layer on top of AWS and the learning curve isn't steep at all. You can train models really intuitively. Also, the reason I use a Mac book pro is because I love the form factor. Final cut pro is my safe place and I use a separate desktop machine for any training tasks I have and if you want to connect an existing GPU externally to your Mac book, you can do that thanks to Nvidia's Pascal drivers for Mac. Just connect your GPU to an external enclosure like a kitty oh node then connected to the Mac book via a thunderbolt three cable. Then you'll need to run a little script to get it set up, which I'll link to in the video description, but right. Speaking of desktops, if you opt for one, the price ceiling is much higher. These can get pretty expensive at the high end.

Speaker 1:          06:00          I found that again, lambda labs make some really incredible machines. These are built specifically to train deep learning models in 2018 it's made for some serious researchers and teams of them. The Quad model is the best of the best. It allows multiple engineers to work together. The basic model starts with for Nvidia, 10 80 ti IGP use with an Intel I seven processor. The con is that it's 8,800 bucks, which is like 10 years worth of soylent. Now, a more affordable way to buy a deep learning desktop is to build it yourself. This can actually be a very fun project. In fact, you can make a really great one with just $1,700 I wouldn't recommend getting a Gpu from any company other than Nvidia. They make the best in the world and Kuda is a valuable tool. The GTX 10 80 ti, I and Titan next are similar, although the GTX 10 80 TEI is less expensive, so that one makes the most sense for a CPU and Intel high five works great.

Speaker 1:          07:02          It's cheap, but good enough not to slow things down. We also don't want to forget about the PCI. Elaine's supported by the CPU and motherboard. As Andre carpathy has pointed out, each GPU should have 16 lanes so it eats data as fast as possible. That means for two cards we need 32 PCI lanes. 32 gigs of Ram should do. You can get to 16 gig sticks. Jeremy Howard has suggested getting a fast SSD disk to keep the ols on and the current data on and then a slow spinning hard drive for the huge datasets like image net. For a motherboard, we'll need one that's capable of supporting two GTX 10 80 tis and asis has a great one called Tuf z to 70 for a power supply. The EVG a seven 50 GQ has an unbolted to give the GPU and CPU lots of power and when it comes to a case, a thermal lake end 23 will do just fine LEDs optional.

Speaker 1:          08:02          Putting it all together is a separate tutorial, but all in all it should come out to just under $1,700 I've got links to everything I've talked about in the video description. If you're going to do a lot of deep learning, it's generally cheaper to just buy your own hardware and train on that. Three things to remember from this video. The best laptop to get for machine learning in order of budget is either the lambda labs tensor book, the Nvidia Gtx 10 series or a Chromebook with cloud computing credits. The best desktop to get for machine learning is in order a budget, the lender labs, quad computer or a DIY $1,700 machine, and for cloud options, a zero offers the cheapest on demand instances, and the easiest service to use for beginners is Floyd hub. Essentially a wrapper around AWS. You made it to the end. Hit subscribe, and I'll be your GPU for Valentine's Day. For now, I'm going to run the school of Ai, so thanks for watching.