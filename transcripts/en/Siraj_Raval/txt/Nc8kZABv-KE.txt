Speaker 1:          00:00          Make javascript great again. Hello world, it's to Raj and Google recently announced the much anticipated javascript version of its popular machine learning framework, tensorflow, dubbing it tensorflow dot j s. In this video, we'll use it to build a very simple web app that can detect any object you show your Webcam. Last year, the Google brain team developed a library called deep learn dot js. That was an impressive contribution to the field, allowing developers to build machine learning models in the browser and it had a few impressive demos associated with it, like one that let any user train a model in real time for image classification. But a lot of the code was deprecated and Buggy, so an upgrade was in order. They made it faster, made the syntax more readable and added lots of new low level functions to it that let developers build very detailed models in the browser, eventually renaming the project to tensorflow.

Speaker 1:          01:09          Dot. JS If we build an AI app using tensorflow dot js, it makes predictions and trains itself entirely client's side. That means it can use the GPU of whatever user accesses the APP and it doesn't have to be an Nvidia Gpu, Jensen, you bad ass. It can be any kind of GPU from a Mac book, Gpu to an android phone, Gpu usually to consume ml models whether as a developer or as an end user we'd have to install a few packages or deal with some sort of technical issue, but because tensorflow dot js works in the browser, we don't have to install any dependencies. The library is split up into two different packages. The first is core, which is a flexible low level API. It's syntactically pretty similar to the tensorflow python library. Then there's the layers API, which is similar to care os it's higher level and makes it easier to build models at the expense of fine grain control over the details.

Speaker 1:          02:17          There's a lot of potential for using client side data to help train models. It really opens up a whole new world of machine learning. One where we can start thinking more about how server sent events can be used to feed rich data into these models in real time while operating in the browser. We can create apps that continuously learn and even if users have only a small amount of data to give, we can use the library's ability to perform transfer learning to augment an existing models capability with new data. We can even load model files trained in tensorflow, python or c plus plus directly to the browser, and because the data never leaves the client, it's privacy friendly. We can train our models on data clients side without ever seeing the actual data itself. There's a lot of potential to use tensorflow dot js to create web apps that can learn from their users.

Speaker 1:          03:19          You can crowdsource the training of a music generating AI by having the users make their own songs in the browser, have users submit articles and create an AI that learns to write in the same way they do or even learn from users browsing habits to present them with content that's most suitable for them. When it comes to installing tensorflow dot js, we don't even have to do anything. If we create a simple html file, we can access it by simply adding a script tag to our code that points to the library online. Then we can use the library right under that as a test, we can write a basic html file that simply prints out a tenser and in our javascript console in the browser, we can see that it works. No dependencies, no other scripts to run too legit to quit. Let's look at some of the core components of the library.

Speaker 1:          04:18          The reason it's called tensorflow. Dot. JS is because deep learning models are essentially a graph of computations. That is, we have some input data. This could be an image or a piece of text. All of this could be represented by a series of numbers. We feed that input data into a computing graph. At each step, we perform a series of mathematical operations on that input data, slowly transforming it and we call the data that flows through the graph tensors. Since a tensor is a group of numbers in n dimensions, that can be one dimension or a hundred dimensions. The tensors flow through the graph, eventually producing an output tensor, which is the prediction that it makes in tensorflow dot. Js. The primary unit of data is called the tensor, which we can access very easily. It's a self named a tensor instance has a shape attribute that defines the array shape.

Speaker 1:          05:22          It's found in the TF dot tents or function. We can create tensors of any size. We just have to define how many dimensions we'd like as well as the values that make up the tensor. If we want to get more specific and make the code more readable, we can use other functions like TF dot tents or Wendy or TF dot tents or Tootie that specify that the tents are in. Question is have one or two dimensions respectively. Tensors are also immutable, meaning once they're created, we cannot change their value. Instead we can perform operations on them generating new tensors, but there should be some mutability when building a machine learning model right after all the model must update itself as it learns. That's where variables come into play. Variables are initialized with a tensor of values, but unlike tensors, their values are mutable. We can assign a new tense or to an existing variable using the assigned method.

Speaker 1:          06:27          They're used to store and update values during model training. But remember that tensors are only half of the equation here. We need to perform operations on them for this to be machine learning slash for us to be cool. Operations or ops for short allow us to manipulate the tensors. The library offers a huge range of ops that allow us to perform fast matrix math on tensors easily performing calculations on groups of numbers in parallel. And because it's a changeable API, we can call ops on the result of ops on the result of ops on the result of you get the point. So what does building a model actually look like? In tensorflow dot js, we've got two options. The first is to use ops directly to represent the work the model does. This is the low level part of the API. We can define in detail every ad multiplication, subtraction, operation that's applied to our tensors in what order, how often, et cetera.

Speaker 1:          07:35          Alternatively, if we want to quickly prototype and model and don't care too much about the details, we can use the high level API using TF dot model to construct a model out of layers. These are a popular abstraction in deep learning adapted from the [inaudible] library in that a neural network consists of layers of operations and while sometimes a layer needs to be written out as multiple lines of code, a high level version of this allows the developer to define a layer as a single line of code specifying the necessary parameters right there. All right? All right. All right. Let's get to our demo of having an AI predict what type of object is on our Webcam. We'll use a popular machine learning model called Yolo or you only look once. The way it works is that it first divides a given image up into a grid of 13 by 13 cells.

Speaker 1:          08:34          Each of these cells is responsible for predicting five bounding boxes. A bounding box describes the rectangle that encloses the object. The model will output a confidence score that tells us how certain that the predicted bounding box actually encloses some object. Once it does that, it'll look something like this for each downing box. The cell also predicts a class as in what it thinks that object is. It gives a probability distribution over all the possible classes, and it does this after having been trained on a Dataset that contains a set of labeled image classes. The confidence score for the bounding box and the class prediction are combined into one final score. That tells us the probability that this bounding box contains a specific type of object. Since most of the boxes will have very low confidence scores, we only keep the boxes whose final score is 30% or more, which leaves us with a final prediction.

Speaker 1:          09:42          The architecture of Yolo is pretty simple. It's just a convolutional neural network. I have an incredibly detailed video on comp nets on my channel. See the link in the video description for more, but it's got, it's got just a couple of these layers repeated over and over and over again. We give the network an input image and in a single pass it will output a tensor that describes the bounding boxes for the grid cells. Then all we'll need to do is compute the final scores for the bounding boxes and throw away the ones that aren't above our threshold, but since we don't know how fast a user's GPU will be, we'll use a tiny version of this model called tiny Yolo, which uses fewer layers and is faster, but also a bit less accurate. We can import this model into tensorflow dot js easily. Then access our Webcam programmatically to retrieve the image frame.

Speaker 1:          10:42          We can apply each image to our Yolo model in real time and have the bounding box layered on top of the image for us to see. Since the model is already trained, we don't need to train it. We're just repurposing it for use in the browser. So now it'll tell me whatever it is that I'm putting in front of the Webcam. T three things to keep in mind from this video. Tensorflow. Dot. Js is the javascript version of Google's popular at machine learning library, consisting of both a low level core API and a high level layers API from building and training models. It uses the user's Gpu no matter what kind for both training and inference, which opens up a whole new world of possibility, including training on real time data. And we can port existing ml models to the js framework and repurpose them for browser use pretty easily. If you want to learn more, hit the subscribe button. And for now I've got to use tensorflow dot. Js so thanks for watching.