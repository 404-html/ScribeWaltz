Speaker 1:          00:00:05       Hello world, it's Saroj welcome to this live stream that, and in this livestream we're going to talk about generative adversarial networks. Okay. I've talked about it in the past in the last video, but now we're going to really dive into how they work. So get ready for this. This is some bleeding edge tech and thank you all for coming to this live session. I've got this Jupiter notebook set up and what I'm going to do is I'm going to talk about parts of the code that you know, they're basically repeats of what we've already done and I'm going to code the parts that are particularly interesting, the parts that matter a lot, that the parts that are unique to gans. So in this case it's going to be the math part, uh, specifically the loss functions and then how we train gans. Uh, so definitely check out the Jupiter notebook.

Speaker 1:          00:00:49       It's in the description for this video. And in this next hour we're going to talk about all the details of, of Gans, how they work, how you could implement them yourselves, and ways for you to think about in your, whether you're trying to create a startup or you're implementing this in production, or whether you're trying to do some kind of research around gans directions that you can move. Okay, so that's what this livestream is all about. What I'm gonna do is I'm going to start off by answering questions for two minutes and then we're going to just get into the code. All right. Code and theory. So cycled gans are coming soon. We've got cycle gans, we've got w Gannon's we got by gangs. There's a lot of guns out there. Fantastic. Gans and where to find them. That should be the name of a book by Jk Rowling.

Speaker 1:          00:01:34       So actually it is a blog post by the way, which I want you guys to check out. I'll actually pointed point to point you to it in a second. But yeah, generative models are really cool. I'm really into generative models. And if you were to ask me Saroj, what would you do? A, if you were to do research full time, I would say I would focus on improving optimization techniques for generative adversarial networks. That, or synthetic gradients or one shot learning, which I haven't even touched on yet, but that's at the end of the course. Okay. So two questions. Can you make a tutorial on loading a pretrained model like inception net? So yeah, I can do that, but the, at the same time, uh, that's, yeah, that is a, that is a very trivial tutorial because using a pretrained model is just a few lines of code, right?

Speaker 1:          00:02:19       You just load it up as a checkpoint in tensorflow and then, uh, feed your data to it. But yeah, I can do that in a second. All right. All right. So everybody is excited for Gans right now. And so one more question before we get started is, uh, what do you think about using gans to sequence length without, okay. No, no, no. Wait, what do you think about using gans to produce data sets and reinforcement learning environments? That's a great question. So I, I have never seen gans applied to reinforcement learning. Uh, although that would be a great

Speaker 1:          00:02:55       research idea. I, I don't, I don't, I don't. So have to frame that problem. Like what would that look like? So in a reinforcement learning environment, you have trial and error, you have a reward value and you're, you're trying to optimize. So your agent is, is getting the most reward for whatever your objective is. So how would again fit into that framework of thinking? Uh, generative adversarial networks are used to generate data that looks similar to training data. So you would want to perhaps generate or simulate different types of states, different environments, and have your agent or multiple agents run in all of these variations of these environments. And it would be optimizing for rewards and each of these environments. And what would happen is just by trying out all the different environments, the, the agent, the sum total of, of the, of the weights of the agents would be so good that they would be generalized to any once any one variation of those environments, if that makes sense.

Speaker 1:          00:03:51       So we're talking about simulations. So like cities, like different types of cities. So like then your agent will be able to navigate through any city because it, it's, it's navigated through multiple cities. So that's, that's a possible on the fly idea I just thought about, so anyway, so let's, let's get, let's get start with the code here. Okay. Uh, we have a lot to live up to in this livestream. Gans are very, uh, cool right now. They're also notoriously difficult to train, which we'll talk about. So what is, what is a type of gang we'll be using in this tutorial? We will be using a, uh, a deep convolutional generative adversarial network. Okay. What does that mean? That means we have to convolutional networks. Well, we have, we have a convolutional network, which is the, uh, a generator. And we have the deep convolutional network, which is the discriminator.

Speaker 1:          00:04:39       So we have a convolutional network that takes in a set of numbers and then it converts it to an image and then a d convolutional network. It takes in an image and converts it to a set of numbers. And so why do we have the generator be a convolutional net and why do we have the discriminator be a d convolutional net? Because we are going to generate a handwritten character digits that look very similar to the, to those that already exist. So the generator is going to continuously generate, uh, images that look similar to the handwritten character digits, which are these and the discriminator, we'll say, are those real, are those a part of the training data or are they not? Are they generated? So it has to answer to detect. It's going to take in that image and it's going to output probabilities if it's real or fake.

Speaker 1:          00:05:23       And both of these train with their own respective loss functions over time and eventually they both get really good at doing their job generator. We'll get really good at generating a fake digits to try to fool the discriminator and the discriminator we'll get really good at tried to detect if those images are real or fake. That's the high level and that's the high level. Okay. So what we're doing is we're building a deep convolutional Gan and the generator is going to, let's see, let's look at what this looks like. I've got a little short video for you guys here. When we're generating faces over time, this is what it looks like. See, they are, it's going to iteratively better and better. How creepy slash awesome is that. Check that out. Okay. It gets better just like that. And

Speaker 1:          00:06:07       the other thing I want to talk about is the techniques that are used for deep convolutional gans to improve on Vanilla Gans. So Vanilla Gans like the, the, the first paper by Ian Goodfellow was great, but since then there've been a lot of papers that have built on this, on this idea. Okay? So the first and so deep convolutional Gantz improve them from the vanilla gans in two ways. The first way is they used batch normalization. So this is, this is something that is very important to talk about. Bathroom lization what is this? So normally, so let me just shoot this up here. This is the algorithm for batch normalization. What is this? So, uh, recall that a very important preprocessing step for neural networks is to normalize your data so that all of your features are on the same scale, right? And so if you have weight as one feature and it's on a scale of say zero to 300 in terms of pounds as a metric versus something like, uh, I dunno, hair length, which is going to be on in the middle of the millimeter scale, it's hard for your model to converge when you have two wildly different, uh, metrics.

Speaker 1:          00:07:15       So what we do is we normalize, so they're all going to be on the same scale, be that zero to one, which is the normal normal case or zero to 10 or whatever, whatever it is. And what this does is it helps our model converge batch normalization is a technique that was invented two years ago and in 2015 which says let do normalization in mini batches. So let's just normalize all over the place. And what happened is when they did this, it improved their convolutional net. They're state of the art convolutional net by not in terms of accuracy but, but in terms of uh, computational efficiency. So it achieved the same results in 14 times, uh, this 14 times faster than it did then it would without batch mineralization. So clearly a very important technique and we'll see it implemented in this code as just one line of code.

Speaker 1:          00:08:05       Okay? And so here's what it does. It says, okay, to just go over this real briefly, we say, okay, so sigma notation means for all of our samples, m are the number number of samples in our code. Let's get the variance, okay. And so the, so this value right here is going to represent our mean value over over our, uh, all of our samples. And then we're going to calculate the variance over those samples. And so that's what this value is, that we're going to take both of those values, the mean and the variance, and we're going to, we're going to find a difference between the two. Okay? Uh, or sorry, the difference between each sample and the mean over the square root of the variance plus epsilon, which is a constant term. And that's going to give us x hat, which is the normalization term.

Speaker 1:          00:08:52       We take that and we multiply it by constants here. These are Lauren parameters. Okay. And you'll, you'll see what I'm talking about here and that's going to give us the, uh, which basically scale each of these. So this one's scales and the shifts. Okay. Scale by multiplying and then shift by adding, and that's going to give us a y. Okay. So that's batch normalization in a nutshell. The other important thing that they did was that they used Relu. Okay, so Relu as opposed to, uh, what was it? Sigmoid when it comes to deep convolutional gans, they outperformed them. That's all. Okay. So that was, those were the two main improvements that they made for, for these, for these networks. Okay. So gans are hard to train. They're not easy to train it. If you've ever raise your hand, if you've ever tried to train again, I don't care if I can't see you. Raise your hand anyway. Okay. See, so that's probably a lot of people, I'm just guessing. But, uh, there are hard to train and, and they're not easy. So what I can do is I can say generative adversarial network visualization. I want to show you guys what this looks like to train. So if we were to look at what this looks like visually, so in terms of a, a video, it would look like this.

Speaker 2:          00:10:06       Okay?

Speaker 1:          00:10:06       Convergence is nontrivial for generative adversarial networks. There's so many things that can go wrong. There's so many things that can go wrong. Okay. This, this is some really wonky looking ish. Let's see what this is, what's happening here. Okay, hold on. Let me just,

Speaker 1:          00:10:26       okay. So what we want, just look at the top left or this, look at this box right here. Okay. We want those green and blue, uh, values to merge together, okay? So they're on the same plane. Uh, just, just for the sake of a visualization. But what's happening is what happens is sometimes the discriminator, sometimes a generator fools a discriminator. By finding one value in this, in the, in the appropriate data distribution, it finds one, one value that that would fool the discriminator every time and it sticks to it and doesn't try anything else. So then you're, you think that your model is like, Hey, I've converged buddy, it's over. But actually it's just found one value. So you have to mitigate for that. The other important thing, and this is, this is what I find very interesting is when we have, uh,

Speaker 2:          00:11:14       okay,

Speaker 1:          00:11:15       these loss functions not, which I'm going to show you down here. These are our two loss functions. By the way, we'll get to these. I just, I just really want to talk about that for a second. The first loss function up here is for the discriminator. Okay? This is what we want to minimize for the discriminator. The second loss function is for the generator, and I'll talk about the details here, but just know that we have to loss function for generative adversarial networks, one for the discriminator and one for the generator. And they're not meant for generative adversarial networks. These are, this is the castic gradient descent. These are meant for convolutional networks. They're meant for feed forward and recurrent networks. But what we've done is we've applied to this adversarial approach when in fact we should be, which is more of a game than an optimization problem.

Speaker 1:          00:12:00       It's, it is, it is high level and optimization problem, but it's not a problem where we are trying to minimize the cost function of a, of one network. We have two networks and they're, you know, they, they have this very specific type of scenario that they're going through together. And, uh, we need better optimization techniques for generative adversarial networks and we need those techniques to be made for a game theoretic approach. So this is a great space for research. A lot of optimization for generative adversarial networks are that use to cast the gradient descent, which are most of them implement some kind of hacky technique, which you'll see. And I'll, and I'll even, we're actually going to do as well as you can see here, 0.5, 0.45 these magic numbers right here. Okay. Less than points 0.6. Okay. So that's, that's the high level. Okay.

Speaker 1:          00:12:50       So let's, let's, let's, let's start talking about the code here. So remember, I'm going to code the parts that I think are really relevant and then just gloss over the parts that are just standard. Like this. For example, importing am an ist. We all know how that works. The two lines of code, right? Uh, I've got 50 k training samples, uh, 50 k validation samples and 10 k testing samples. Tensorflow does this for us beautifully. It'll download the data set from the web, uh, preprocess it, and then it's set for us to use and it will sort it all in this m and ist variable we're going to be using tensorflow. Okay. And this and this tutorial num py, date, time for logging, and then map out live to show our progress during training. Okay. And so this is actually the one that I want to look at this just the same thing. This is the same exact thing. Okay. So

Speaker 3:          00:13:40       great.

Speaker 1:          00:13:44       What do we got here? Okay, so I just went ahead and just compiled that bart part. So just downloaded the data and, cool. So we've got that part and now we're going to calculate the square root of infinity. No, I'm just kidding. Now we're going to look at the discriminator. Okay. So it's a great idea to modular modularize these parts into their own functions because these networks can be pretty big and you want to do this anyway just because of several reasons. It's just good programming practice, uh, object oriented practice and, and it's also just easier because you'll find that as you're building these things don't want to latch on extra features like um, not just change tune these hyper parameters. You might want to add new layers and new techniques to it, like drop out and things like that. So having them in their own functions is just good practice. Okay. So the first thing we're gonna do is I'm going to talk about this structure a bit. So the generator and so we're going to talk about this more mathematically then just high level. The generator is receiving a z. So what is z? Z is noise. What is noise? Noise is, let me move this out of way.

Speaker 1:          00:14:53       Noise in this case means randomness, random values that we just generate from nothing just from, not from nothing from a distribution, right? The Golf, Sian Distribution. We're generating some random noise, okay? Every time. And that's what it starts off with. We're not giving it some image. So in some networks, so let's be clear here, in some networks we take for the generator, we take the original image from the, from the training data, and we generate some noise from that image. But in this case, we're generating noise from nothing. So just a, from, from just a distribution that is not an independent, that's the word I'm looking for. An independent GoSTEM distribution. Uh, and we'll talk about why we're doing that. But first, let me keep going here. We're generating noise here, which is what z represents. And then we feed that to the generator. Well, the generator will do is it will up sample.

Speaker 1:          00:15:44       What is upsampling mean? Upsampling is a term for convolutional networks where we take, uh, an image and we split it into more smaller and more numerous versions of that image, right? So if we have one image, if we upsampling it, we could have then four smaller images. And then if we up sample it again, we could have 16 smaller images and upset. Well, again, we have 32 so you see, you see what I'm saying? So we just keep up sampling. And so what happens is by the end we're going to have a law to values, but they're all very, very small images. And then we squash all those values together and then we have those output probabilities real or fake. Okay. That's where the generator does. And then the discriminator is going just taken an image and it's going to, uh, it's going to a downsample. Okay. And

Speaker 2:          00:16:34       yeah,

Speaker 1:          00:16:39       the discriminator is going to downsample. Why? Because it is a d convolutional network. And so for downsampling, it's going to take a image, a big image, and it's going to create,

Speaker 2:          00:16:50       uh,

Speaker 1:          00:16:54       it's going to take a big image and it's going to create smaller and more numerous images, uh, that will progressively get smaller and smaller. Okay. So, wow, I just realized that I got that backwards. So for the generator, it's going to take a lot of values and it's going to progressively create more, uh, fewer and US bigger images. I've actually written this down right over here when I write that down.

Speaker 2:          00:17:22       Yeah.

Speaker 1:          00:17:23       So here's the word. So I, so the reason is, let me just paste this note into my demo right here to remember this. There's a lot to remember. So the generator is going to create bigger and less images in every layer, and the discriminators going to create smaller and more images in every layer. So if we were to, the best way to really show this and to just visualize, and that's gonna take away all confusion. Convolutional network.

Speaker 3:          00:17:50       Okay? Just like that. So let me just maximize that because I ain't got time for that, right?

Speaker 1:          00:18:10       Okay. So you see this right here, see, see how we're getting more and more images. There's, but they're smaller, more and smaller images. Okay? So that's what the discriminator is doing. And so the generator doing the opposite, we literally just flip that around. And so we get a lot of values and that we can immediately convert to a lot of small images and we gen and then we'd just compress it into one big image. And that's the generated image. Okay, that's, yeah.

Speaker 3:          00:18:36       Cool. So anyway, where were we? Where were we?

Speaker 1:          00:18:41       Use the same notebooks by the way. Okay, so let's talk about the discriminator. Let me, let me answer one question.

Speaker 3:          00:18:47       Let me answer one question. Uh, or I forgot to

Speaker 1:          00:18:54       the discriminate or, so, uh,

Speaker 1:          00:19:01       hi sir. Rod. This is doc I program in Javascript c plus plus and python. Nice. I'm doing neural networks late lately and I'm 15 years old. You're a hero. What would be your best advice on getting expertise in the field? So doc, I would say don't focus on languages. Just pick one language, pick one. And I'm going to say it's python, pig python. Okay. Pick Python and then focus all of your mental energy on the algorithms. Okay. Don't focus on the syntax. And that's why it's great to use python. Focus on the algorithms and the intuition. It's a way of thinking. If you learn the way of thinking, then you can apply it to novel, novel problems, novel ideas. Okay. Try to develop an intuition around this. Given any new problem in machine learning, you'll be able to say, oh, you have to use a convolutional net and you use this many strides and you have to use uh, uh, you know, drop out in this layer and you know, if you can give it, give it a new problem, know how to, how to work it, you're good to go.

Speaker 1:          00:20:01       And how do you develop that by focusing on the algorithms, focus on techniques and look at what's trending on get hub in terms of machine learning, be active in the community post, you know, in machine learning and the machine learning sub reddit posts in my, the comments from my videos, if you're a part of the U. Dot. City curriculum, posting the and the slack channel, just talk to people. Okay, talk to people and you, you're going to learn a lot. Normally this stuff was, was a restricted to only those who went to the top universities in the world who paid large amounts of money. But because of the Internet, you can work from anywhere in the world. Uh, learn to become an expert in anything, especially machine learning. Okay. So that's my answer. Let's get back into this further. The discriminator. We have a co, we have our, uh, let me see where we are for a second. Are convolutional network. Okay. So discriminator is our convolutional network. Let me talk about all of this. So let's, let's go, let's go line by line here. So the first part is we're going to initialize weights and biases. Okay. For our first convolutional block, now the word block is a word that I've invented and it's going to become commonplace because I said so. So the, so the word block is we take,

Speaker 2:          00:21:17       okay,

Speaker 1:          00:21:18       so convolutional nets generally follow the same pattern, right? We start off with a convolutional layer and then we apply some activation function to it. And then we have added some kind of pooling layer. Okay. Or sometimes we switch to the two, but it's always the same three things over and over again. And we could think of these things as a block, right? Convolutional convolution activation pooling. So that's how you should remember it. Blocks. And so in this convolutional network, we have three convolutional blocks. We start off with the weights and biases for are a convolution and then we uh, we add them together. So for this convolutional block, this line right here, it says, okay, taking that image and we're going to feed in the image directly to our discriminator, right? And it's good to output. If the image is real or fic and we say, well what are the filters is going to be what we just defined what those filters are going to be. It's going to be this set of weights. Values. Okay, these are 32 different, five by five pixel values. And why did we define them as this? Uh, because

Speaker 2:          00:22:22       okay,

Speaker 1:          00:22:23       they are, well it's one of the things where if we, if we were going to try more like a higher value, like 33 for example, it could actually improve convergence versus 31 but there's not a specific reason. It's just this, like I said, rule of thumb, it's been implemented before and a paper with good results. Those numbers are probably going to be good. So that's for our weights. We initialize them randomly using this truncated normal function. Okay. With the standard deviation of 0.02 how far off from the mean should we be? And that's what 0.02 stands for. That's what standard deviation stands for. And then we're going to add our bias. Okay.

Speaker 2:          00:22:59       And

Speaker 1:          00:23:01       strides what our strides. So the, so strides in this case stands for batch height with and channels. Those are the four values for strides. Okay. Um, so what is a sign of our batch? Always the height of a stride was the width. And then how many channels, what are strides? Remember convolutional layers. A convolution is a, to convey, solve literally means to, to slide because it's a flashlight, it's moving. How is it moving? Because

Speaker 1:          00:23:29       well, we're not actually doing the iteration where we're saying like for every single pixel it's not like a four loop that we're writing or we're saying for every pixel in the image apply, apply, apply, apply. That's what this one line of code does. But under the hood you can bet that's what it's doing. We're saying for all of these pixels, uh, check if, uh, the multiply by the value that we're looking for. And then if there's, if there's a, if there's a result here, if it's a, if it's a non zero results, that means that there is something in the image that we're looking for. But strides means in this case, stride across the image of like what, what is the interval of that flashlight as we straight across. And then for padding, same, it just means to pat evenly left and rights. Uh, and padding is when we add zeroes to make sure that those values are the same. So if we have, if we're multiplying or dividing or performing any kind of operation on two numbers, like you know, one, two, three times one, two, three, four just for um,

Speaker 1:          00:24:28       for cleanliness we want to pad that one, two, three, so that it's got one, it's going to be one, two, three, four, zero so that it's going to be the same length. Okay. And I talked about this in my tension in my image classifier, how to build an image classifier video. So check out that video for really in depth exploration of how convolutional networks work. Uh, but really our focus right now is to focus on, um, the generative approach, the adversarial approach. Okay. So then for our bias, we're just going to add it in, right? We just add our bias in and why do we add our bias in? Because if we didn't have a bias, then if we fed some, uh, if we fed some zero value to this layer and we multiply it by whatever our weights are, it doesn't matter what our wastes are, it's the, that value is going to be zero.

Speaker 1:          00:25:13       And what does that do for convergence? It's not a good thing for convergence because it means that our ultimate value is going to be zero. So what biases do, biases are our anchor. They say that even if you have a zero value, let's add some, some preset constant to it. So it's going to be a non zero value. So there's always going to be some value in that layer and it's going to improve convergence. So that's what we add our bias and then we squash it with our nonlinear nonlinearity. Okay. So remember in a block there are convolutions followed by an activation function and then ultimately a pooling layer. So we're using average pooling in this, a discriminator in this convolutional network as opposed to Max pooling average pooling wolf downsample by dividing the input into rectangular pooling regions and computing the average of each region.

Speaker 1:          00:26:01       It's just simple, uh, finding the mean, finding the average. So take us out of numbers, add them up and divide by the number of numbers. Okay? That's what, that's all it's doing. And what is the, what is the, uh, what are those numbers? Those numbers are the values inside of the image. Like if we were to look at an image as a matrix, it's got a bunch of values like numbers, okay? Pixels, pixel values. That's what, that's what it is. Okay. And then so we just repeat that, right? That's the whole point of it being a block. We repeat the block again, uh, for the next layer. Okay. And this time, this time for the discriminator, there are going to be, let me see here,

Speaker 1:          00:26:42       they're going to be more, more images, more numerous images, but they're going to be smaller. So we, so we, so you see here that the weight matrix here is double the size of the one that came before. So this is 32, so this is going to be 64 and you see for the next one we, we really, there's a, we really explode that, that value to 10 24, so it's an exponential increase in values. Okay. Uh, and so these are going to search for 64 different five by five pixel features. So I'm really going to the details of how this convolutional network is working, but don't get too caught up in them because really just it's, it's just taking an image and then it's al putting a probability value by continuously, uh, consolving around that image, creating more smoke, crank smaller and more numerous images until, until we have an output output probability, which is going to be really bad at first because we don't, our weights aren't trained, but eventually it's gonna get really good.

Speaker 1:          00:27:36       Okay. And then at the very end, we have our two fully connected layers. So when it comes to convolutional nets, they generally have fully connected layers at the end almost every time. And Andrea [inaudible] has said this many times in his blog posts, you generally add fully connected layers at the end. Why don't we add them at the beginning? Because when you're trying to classify an image, which is essentially what the discriminator is trying to do, real or fake, it doesn't matter what all parts of the, what's in all parts of the image, what's in the bottom left corner. It just matters if that what you're looking for is inside of that image. So we don't need a fully connected layer. We need a convolutional layer that looks for that for the parts that matter. Where's it a fully connected layer which says, let's just take that, this whole thing and we're going to use all of that input for that as the all of that output from this layer as input to this next layer.

Speaker 1:          00:28:27       We don't need that at the beginning, but we need that at the end because at the end we've, uh, we've extracted all the important features. So now that we have all the good stuff, now we're going to apply a fully connected layer to it. Okay? So we do that twice and we're initializing them as random. And then eventually we do our last matrix multiplication, which is the first set of weights, times that layer value plus the bias. And, and ultimately that's going to, it's a simple binary classifier. It's going to output real or fake. Okay? Two values to values, one for real and one for fake, both of probability values. Okay? So that's our discriminator. And now I'm going to talk about the generator, which is a d convolutional net. But first let me answer two questions. Okay. So

Speaker 1:          00:29:19       here are the questions. So the questions are, how different is this from a variational auto encoder? Great question. Great question. So variational auto encoders are different in that the loss function is different. The, they're different in a couple of ways. It's, it's not just one, one way. Um, you don't have this mini Max approach to the loss function. A variational auto encoder is using a loss function for the encoder and decoder, but they're not competing against each other where one is not trying to fool the other. That's what generative networks are doing. Adversarial networks are doing. Uh, and we don't have a re parameterization tech technique like in a variational audit encoders. We separate the randomness, the stochasticity inside of the model from the values that we can then update. Our parameters are gradients with respect to these a deterministic parameters. And when we leave this randomness beside in this, uh, in adversarial networks and this particular implementation, we don't have stochasticity built into the model. It's just, it's, it's outside of the model. So we don't need a reprioritization check. A prick. Okay. Okay. I answer your question. One more question.

Speaker 2:          00:30:35       Okay.

Speaker 1:          00:30:37       Is there an equivalent of gans or auto encoders that can find the parameters of a model, for example, to find the best parameters of the latent pdf? PDF?

Speaker 2:          00:30:47       Yeah.

Speaker 1:          00:30:48       Parameters of the model is there, including with cans I parameters of a model. Oh, okay. So, so, okay. So for model parameter, uh, optimization, learning to learn metal learning, as I like to call it, there are several techniques. One of them that I to shout it out last time was great search. Um, but there are actually better techniques of doing this. Um, there's random search. There's, um, hyper hyper parameter optimization is an entire field in and of itself. And I actually have not touched on that in this course. Um, because,

Speaker 1:          00:31:23       uh, you know, I should though, I should and I will probably go into that. But yes, you can do that, but you wouldn't intuitively I wouldn't think to apply a generative adversarial network to the problem of optimizing hyper parameters. But what do I know that that that's actually a great idea that that could be a great idea. I mean, no one's ever thought of it. This is a good rule of thumb. Whenever you're thinking of research ideas, the best researchers, the people who really push the space forward are the bravest people. There are the people who are willing to go against the grain to go against the popular opinion in the community of what is what is supposed to work and what is supposed to be valid. And they try things that are considered weird or just totally out there. And what happens is these people who do this, like Ian Goodfellow end up

Speaker 2:          00:32:10       okay

Speaker 1:          00:32:10       getting fame and recognition and their models are put to great use and they provide a lot of value to society. So this idea is, you know, it could be great. So definitely try it out. Okay.

Speaker 2:          00:32:22       Okay.

Speaker 1:          00:32:22       Okay. So back to the, actually one more. This is a great question. Mohawn asks, is it possible to use Gan to generate smaller goals of a big task? Yes. So this idea of using neural networks iteratively add in layers is something that I've been thinking about a lot. So think about some, like if, if, so machine learning is going to be happening in every layer of the stack, okay. From operating systems to compilers, rendering, all of it, it's all going to be machine learning in the end. Right now, a lot of it is hard coded, but it's all going to be machine learning. So if you think about a stack, what do I mean by stack? A series of layers of abstractions, of software scaffolding, right? You have an operating system and then on top of that you have a compiler. And on top of that you have an interpreter.

Speaker 1:          00:33:10       You know, you keep going up the stack rendering and then you have whatever else. Um, and that's not even including networking. If you were to make a request, a query to this software, it would first see you. If I were to say, you know, find me, find me the best taco place in San Francisco, it would first use natural language processing to deconstruct that. So that's a recurrent network. Okay. Using LSTM cells to find the semantic meaning of what you've just said, to, to extract those vector values. And then it would take those vectors and it would say, okay, uh, find the, take the pretrained vectors of all the restaurants, uh, NSF, and then find the best routing technique to find all those closest to you. You see how there's machine learning happening everywhere. Like find the best route machine learning, find the best restaurants, machine learning, and take what you've said and convert that into vectors, machine learning.

Speaker 1:          00:34:07       And so you, you've got this, you've got this network of neural networks. So if you really think about it, it's just one big brain is we're building one big brain of just net, just one giant neural network, convolutional nets to recurrent nets to be forward nets and just general adversarial nets. It's all going to be one big huge brain that we're building. And the in the Internet is the nervous system. And I could just keep going high. There's a lot of philosophy here, but let's just keep going. So now for the generator, a ws, the ultimate super neural network, Dragon Ball, z x, Goku Goku we so cool. Okay. So for the generator, uh, we have, it's the opposite, right? It's a d convolutional net. So what do I mean by that? We just literally flipped the architecture. But what do I mean when I say flip the architecture?

Speaker 1:          00:34:57       We don't flip it line by line. We don't say, well, let's start off with the activation function this time and then let's apply pooling and then let's do convolution. No, we flip the blocks. And that's why the word blocks is very important because we have to think about them in terms of blocks because we, they, they, they, the blocks maintain the same ordering. But the, the order of the blocks themselves is what is flipped. So for the first d convolutional block, we have our weights and biases. We performed matrix multiplication, reshape it into, uh, a smaller image. Okay. Um, and or, sorry, a bigger, bigger image. And we just, these images get bigger and bigger. Okay. And so we have this vector of values that we feed it. And so for the, for the inputs here we have the batch size and the z dimentionality. So the batch size is how many images do we want to feed it at a time. The Z dimentionality is what are the dimensions for that latent space that we then want to our model to build off of what is a latent space, those random values that we want to, uh, then convert into

Speaker 1:          00:36:09       what are, you guys are hilarious that we are then going to convert into that big image. Right? Okay.

Speaker 2:          00:36:16       So

Speaker 1:          00:36:17       what do we use those values for? You can see them put to use right here in this first line. So Z is that random value from which we create an image from. And so this image, this value isn't dependent on an image. It says created from a truncated normal golf steam distribution using the batch size ends and z dimensionality as its parameters. It's not actually, it's not actually based off of anything. It's based off of an independent golf and distribution. And from this Z is we generate an image and you might be asking, how the hell do we generate an image from a set of random values based off of nothing? Because during training, as our weights improve this network, this random value will be able to, it will know exactly how to take that random value and best converted into a generated photorealistic looking image after we train. And that's the whole point of our loss functions. Okay, so we generate 50 features and then 25 features. And what do I mean by features here? Features are those images. There are less and less and less and less images. So if we, if we were to look at this,

Speaker 2:          00:37:23       yeah,

Speaker 1:          00:37:23       just flip this. Let me just say literally just d.

Speaker 2:          00:37:29       Okay.

Speaker 1:          00:37:31       What's a good event? This is a good man. No, this is not marriage.

Speaker 2:          00:37:34       This is a good image. Okay.

Speaker 1:          00:37:39       The convolutional network. Big Image. Smaller images. Okay. All right. So then we have our,

Speaker 2:          00:37:48       okay. And then

Speaker 1:          00:37:52       we are not doing batch normalization in the last layer, but we done bachelor normalization here. Okay? So remember that equation that I showed you for batch normalization at the beginning. Now it's being put to use. And so we, what we do is we apply it and these, these layers, all of these legacy once, twice, three times, but not in the last layer. Uh, but we do add at sigmoid activator to make the generated images CRISPR. Okay? So it's going to be one big cute image that we output in the end. And check this out. Maximization is using epsilon, which is that he value, what was it right here. Remember this, uh, right here, this epsilon value, uh, and this is a constant value, which is one e minus five, which just means that it's a notation for a very, very small 0.05. But I mean 0.01 with five place values after the decimal point. And then given our g one, which is that, that first layer, okay?

Speaker 2:          00:38:52       MMM.

Speaker 1:          00:38:54       Okay. So that's that. That's our generator and that's our discriminator. Okay. So now this is the part that I'm going to code. Now we're going to talk about the optimization techniques. Okay? So

Speaker 1:          00:39:08       let me go to the optimization techniques. Here they are right here. Let me ask her one question first. The question is, Hey Roger, I was going through an interesting paper called G U N, which is generative on adversarial networks. Can you talk a bit more about that too? I haven't heard of that paper. That's pretty cool. Generative adversarial networks. That's cool. The space is moving so fast, you just can't keep up with all of the papers. Good. A good a thought though. I need to check that out. So back to this, what we're doing here is we have to loss functions. The first one is for the discriminator. Okay? And I'm going to go through what each of these terms mean mathematically. Let's start with the first from the, from the top, from the, from the, and the left. My left, maybe you were left to this.

Speaker 1:          00:39:57       Just this upside down triangle means the gradients. Okay. We're trying to find the gradient values, right? That's what the loss function is all about. Let's find the greatest value for the discriminator. Okay. So we're saying one over m and then sigma, I equals one m times. What is m? M is the number of samples, which means the number of images that we are training on. So we have m images, okay? And we're gonna apply as loss function to all those images in a batch. So there are m images in a batch. So for this first term right here, we have log d x to the eye. So what do I mean by that? Well, not to the, I just ex the ex ex term. Okay. What do I mean by this? This, this term right here, log dia backs corresponds to optimizing the probability that the real data x is rated highly, okay? That will means we want to optimize to make sure that the real image that is presented to the discriminator is optimized for it. So why do we use log? Why don't we just say D of x? Okay. Because in probability,

Speaker 1:          00:41:02       if we, we are, we are constantly multiplying all of these probability values together, right? And what happens when you multiply probabilities together, they get progressive. The, the, uh, the product becomes really small. So if we were to say 0.01 times 0.01 10.01 that value that resulting product, it's going to be point a million zeros and then one that's, that's a huge number and it's going to get exponentially bigger by times a number of probabilities that we multiply by. So what we do is we use log and so what log does is it gets rid of those 0.0 ones because computers have limited digital floating point precision. And this makes up for that because those are just huge values, right? That's why we use log and probabilities. But just think of it as just a scaling term. What we really mean is just the, the D of X.

Speaker 1:          00:41:53       Okay? So we have log probability of Dax plus the log probability of one minus D of g of Z. Okay? What does this mean? So we have g of Z, which is the generators probability given the, that state that we just talked about, Z, that random, that random value. And so we take say d of GFC. So if given the value that comes out of the generator, feed it to d and then we say, okay, is this real or fake? What is the probability? So we feed the generated value entity and that's going to give us our probability that it's a fake. Okay. So this whole second term corresponds to optimizing the probability that the generated data GMC is rated poorly. And so we do one minus that value because it's 100% minus the probability that it's real or fake. And that's going to give us the probability that it's rated poorly. Okay. And so we do one minus that. So we have two terms here and we use them together to form this loss. Okay. And then,

Speaker 2:          00:42:57       yeah,

Speaker 1:          00:42:57       that's what that is. And uh, so this is the term for the generator. So for the generator, we have one over m. So we have the same one minus D of Josie. But what the generator's trying to do is up is to increase the probability that the generated data is rated highly. Okay. So we have one. So for the number of samples log probability of one minus the of g of C. Okay. And this will make sense when we look at more sense when we look at it programmatically. Okay. By alternating radiant optimization between both of these networks, we're going to on new batches of real and generated data. The gain will slowly converge to produce data that it's as realistic hasn't network is capable of modeling. So these loss functions, they are meant not meant, but they are generally used for convolutional nets feed for nets like neural nets that are not adversarial, but we are applying them to this adversarial problem, this game theoretic problem where we are trying to find the Nash Equilibrium, uh, between two networks. Okay. It's a game. It's a mini Max game. We are, we are simultaneously minimizing the probability that something is fake and also maximizing the probability that is real. So that's what that is. And so let me, um,

Speaker 2:          00:44:26       okay.

Speaker 1:          00:44:29       Two minute papers with Cardozo. I fair. I love the guy. I actually did a collab with them a long time ago. He's a, he's a cool guy. I just typed his last name, man. Uh, where was I? So what are we doing here?

Speaker 1:          00:44:43       What are we doing? Oh, I know what we're doing. We're going to say if we're going to cut this part out. So we have our tensor flow session, right? Because we're about to train our, our, our network. So we all, we need to, to our session session and then we're gonna say, okay, so the batch size is going to be 50 and then a number of dimensions is going to be 100 so z can be a lot of dimensions. And so we want to limit how many dimensions he can be in so that it's just faster for our model to, to converge. And we want 50 images in a batch. And what we're going to feed the discriminator is going to be the image and how do we feed it in. We use our gateway intention flow, the placeholder to feed that human gene and the type it's going to be is a float value. And then we're going to define the shape of that image. And the shape is going to be a 20 by 28 image, okay. With a depth of one APP, but it's a 20 by 28 image. And then we have our placeholder down. You okay?

Speaker 2:          00:45:40       Okay.

Speaker 1:          00:45:41       To feed him, put the two d. Okay. Feed image two D, image two d. Okay, so now,

Speaker 2:          00:45:50       okay,

Speaker 1:          00:45:51       we're going to define GFC. Okay. So this is g z. So remember these equations that we define, it appeared there's GMC, there's d of Goc, and then there's the events. There's three different equations and we'll talk about what each of these means. We have GMC. So GMC is going to be, we'll just call it jersey. And so we're going to initialize that generator function that we've already, um, we're going to call that generator function that we've already defined. And then we're going to give it those two printers. We justifying the batch size and the z dimensions. And GMC is going to hold the generated images. Okay? So that's GMC. The next term is d of x. So x is going to say,

Speaker 1:          00:46:32       uh, the Webex is going to say, it's going to hold the discriminators prediction probabilities for the real images. That's what d avax does. It holds the probabilities of the real images. Can we say d backs equals that discriminator that we defined, uh, given that the image which is in the place holder. So that's for the real images, probs of real images. And then lastly, we have d of g of z. So remember up in this equation up here, those were the three terms that we were dealing with. We were dealing with Dfax GFC and then d of GFC. So we're defining those right now. Okay. So, and what does the GFC hold? It holds the props of generated images. So we say [inaudible] [inaudible] called DG equals discriminator, give in GMC the word. Literally see if we're in that generate value. And we say reuse to true because well, once we use it over and over.

Speaker 3:          00:47:35       Okay. Right, right. Okay. So,

Speaker 1:          00:47:43       right. I wish we could just use a simple optimization technique like mean squared error. Right. But we can't because it's just not going to work for gans. Gans are hard to train. They are not easy to train. This is why we need better optimization techniques. Where Gans let's get to work. Let's start building better optimization techniques for gans. Okay. Think, think game theory. Think Game Theory. Okay. Think of approaches that no one has ever thought of before. Okay, so now we're going to define our loss. Our first loss. Remember we have two losses here. We have a generators, laws, and our discriminators law. So for our generators loss we're going to say let's find the mean value. So we have a set of numbers and we add them all up and divide by the number of them. What are we finding the mean value off what we're finding the mean value of the cross entropy

Speaker 3:          00:48:33       with lodge, it's what the hell are you doing, sir? Roger of DMG. And then our labels, which are ones like DMG. Okay, so,

Speaker 1:          00:48:55       so we want the generator network to create images that will generate images that will fool the discriminator. And we want the, the sort of the generator wants to discriminator to output a one which is a positive example and wants it, it wants it to discriminate and saying, okay, one means yes, this is real and zero means no, this is not real. So we want a one. Okay. So the loss function, the difference, the difference that we're trying to kick compute here is between us one, which is why I said once. So the reason I'm saying one, like the of Ge is to say the size of the FG just have a matrix of ones and the of g is going to be, uh, the actual generated values. So we're going to minimize the difference between those two. So we use cross entropy to do that. Okay.

Speaker 2:          00:49:40       MMM.

Speaker 1:          00:49:43       And so the whole point of using the width lodges, a component is because the function will operate on unscaled values. So we don't have to scale them. That's what lodge it's means. So we have a matrix of which DMG, which is the generated images. And then we have a, from the discriminator and then the, uh,

Speaker 2:          00:50:01       okay.

Speaker 1:          00:50:01       The probabilities of the generated images. Okay. So that's our gs loss. Okay? So that's our first loss. And then we have,

Speaker 3:          00:50:08       hey, can I, so we have quite a bit to go over. So I'm just gonna go over this.

Speaker 1:          00:50:19       Sometimes I can type out all the code and sometimes it's just, it's just too much. So this is one of those examples when you're, when you're dealing with cutting edge technology, sometimes you just gotta, you just gotta do what you gotta do. Okay? So that's our GI loss. And the next loss that we're going to calculate compute r is the discriminators loss. So it's one last function, but it's got two components. Remember, it's got two components. So remember up here, the generators is just this one component right here. One big component. But the discriminator had two components, right? Log of d of x plus log of one minus t of Geo. So we have to have two components and add them together to get the a song. So that's what we'll do here. Programmatically will say, uh, let me make this smaller. We want to compute the loss between Dmx and the correct label of one, which is what this first one does.

Speaker 1:          00:51:09       And then the last between DMG and the correct label of zero, which is what this align does. So we're taking the average, the mean or average value of the cross entropy between, uh, the d of x with one and then the cross entropy of d a g t of GFC with a zero. Okay. So the probability that an image is real and their probability that an image is fake, we had them together. Okay. And that's going to be our de la. So we have our GI loss and then our d loss. Okay. And then let me get through this, this, um, code block right here. And then I'll answer questions. And then we're gonna, we're gonna call our variables here. This is a, this is some great. So, uh, this is some great, uh, syntax right here. I think this is really beautiful. So

Speaker 2:          00:52:01       yeah,

Speaker 1:          00:52:01       great thing about tensorflow is we can call variables that are defined under a certain name. And this is why it's important to name your variables and to have constant values that relate variables that are related. Because we can just say for all of those variables in our tensorflow variables that already exist, which we can call using this trainable variables function. We'll say if all those variables that start with d underscore, those are all of our discriminator variables, which are the weights which we want to update, right? So we can just call them just like that. And then all of our weights for our, for our generator so we can store those weights and dvrs and store the toys and [inaudible] see how easy that was. And three lines of code. We called all of our weights so we can update them using our gradients. Okay. So then we want to train our discriminator. Okay. So this is what we're doing here. We're training our discriminator by minimizing the for discriminator. We want to, um, we're minimizing two losses here. These these two components, but we want to make sure that it is finding the, it is discriminating between real and fake and it's, it's got to make sure that the value that it looks at, if it, if it classifies it as fake, that they are fic. So that's what that first line does. And if it classifies it a real day, Israel and these two respective lines are optimizing for both of those scenarios. And we're using Adam because Adam seems to be the best optimization

Speaker 1:          00:53:26       technique for generative adversarial networks in several papers that I've looked at from Wasserstein gans to buy guns. Adam seems to work pretty well. Um, but obviously, like I said before, it can be much improved and there's a lot of potential there, uh, for greatness. So,

Speaker 1:          00:53:44       but for D and then for the g g we're doing the same thing. And so why these learning rates? Why Point Oh one first the 0.0, why 0.01 because, um, by the way, um, because it's, it was, it was tried in the, uh, original DC Gann paper, by the way. Momentum. Adam uses something called momentum, which is a great technique. This is a tangent, but it's uh, it's an important tangent. So, so check this out. Momentum is a technique for optimization that is really cool. And what I want to show you is the best blog posts I've ever seen. A momentum. Look at him. Look how beautiful this is. So you can just say,

Speaker 1:          00:54:26       you can visually interact with this, this still great publication for visually looking at math and a great opportunity for publishing. So if you want to publish some research, you're a, you're a developer, you're living, you know, you're not a part of an institution, but you still want to make a contribution to the field. This still is your, uh, should be, you are research publication of choice. Publish here. Uh, we've got all the cool kids publishing here and you can utilize some d three. Dot. Js that still has got some great instructions on how to, um, you know, publish a good paper here, but check it out. A lot of great visual stuff here. The whole point of this still has had make machine learning papers readable, right? No one wants to read PDFs that are locked away in archiver. I mean, I, I want to read them, but it's just better to have them be visually appealing. Okay. So that's that. And then we're going to save those values because we want to visualize it using tensor board. And so we're going to use this summary Scalar versus to, uh, extract the protocol buffers that we then write using the, the writer function, right? And so,

Speaker 1:          00:55:34       okay, so we have respective scalers for all of those lost function components that we optimize that we defined earlier. And then we're going to write them to tensor board in the log directory tends, or board. Slash. Gan. And you can name this whatever you want, but I'm calling attention board slash can hear. Okay. Okay. So, uh, last part here. So for the, so for that, for the, we've defined our loss functions and now we want to train this network. And so, uh, there are, uh, several things that can go wrong here. So remember I talked about how the loss functions that we use for Gans right now are not ideal. They're, they're, they're good. They work that can generate faces and a bunch of other things. But remember, gans are hard to train and these are three points that that come up when we train them.

Speaker 1:          00:56:18       One of the Ar points slash fail fail cases, failure cases, the discriminator loss is approached zero. That means that it leaves no gradients for the generators optimizer. So if the discriminators loss approaches zero, then those gradients are going to banish. They're going to w this is the vanishing gradient problem, not applied to recurrent nets, but to generative adversarial networks. So for current next, the way we solved that was by using LSTM sells for, but for dance, we don't really have, uh, a technique to, to solve it. So we have to do something a little hacky here. Um, but I think that there is some progress, some great progress to, to prevent that. And that would be in Wasserstein Ganz, Wga n, so Google that. Okay. So that's one failure case. The other is that the discriminators lost could rise unbounded by generated images. That means that,

Speaker 3:          00:57:09       uh,

Speaker 1:          00:57:13       that the gradient that their generators, training stalls and then discriminators just never going to converge. And then the divergent discriminator accuracy, it just learns a shortcut. And this is what I was talking about before, where we are, it just going to discriminate is going to classify everything as either real or everything has generated just through some, some blip in the network. Uh, so three things that could go wrong that are documented here, um, but several things could go wrong, right? So,

Speaker 1:          00:57:43       so during every iteration there'll be two updates being made, one to the discriminator and one to the generator for the generator update, we'll feed in a random z Becker, which I talked about before to the generator and pass that output to the discriminator to obtain the probability score. That's what the DG variable is we specified earlier. Okay. So let's look at what this looks like. So we define, um, those values that we want that does that mean real versus steak? So just zero means fake. Okay. And for the generator. And then for, uh, the discriminator, we have one and one, which is what we're optimizing for and the real and fake directions. So we have 50,000 trading iterations. And what we're going to say is, uh, for each of these batches, right? So for all batches we're going to say these are, so these are the random, these are the, these are the magic numbers 0.6 versus 0.5 versus 0.45.

Speaker 1:          00:58:33       And why we're saying greater than, because we want ideally what we're, where we are hard coding in here is we want to stop training each of these loss phone functions once these values are, um, less than these 0.6. So if it's greater than 0.6, then just keep training until it's less than 0.6. You see what I'm saying? And vice versa for all of these and not vice versa. Apply the same logic to all of these things. So first we trained the discriminator and then we train the generator, and then we train the discriminator, classifying real images as fake on, uh, on real values. Okay? Um, so the, so this is why we have three of these generators for the general. So the first one is for the generator. The next one is for the first one is to train the discriminator on the generated images. The next one is to train the generator. And the last one is to train a discriminator to classify we overseas fake. Okay. And then we print these out. Let me go back here and make sure that I've compiled everything to make sure that it all compiles here.

Speaker 3:          00:59:36       Yup. Yup, Yup, Yup, Yup.

Speaker 1:          00:59:41       Do have not fine. Cause they didn't find up here. Okay. So we are running out of time. So let me say this. So this is us visualizing what's what, what it's looking like. And I'm gonna wrap up in five minutes. So see here that the discriminator is getting better. It's the number is actually bigger, but it's negative. So it's, it's good. It's getting better over time and then it saving it to this pretrained a folder and then, uh, we can even display it. But here's the thing, quick thing, and then I'll ask you some questions. Um, check this blog posts out, by the way, a fantastic gans and where to find them because we're not going to have time to visualize a loss. But what I can do is I can show you the loss, what it's going to look like and why. Why said we need better optimization techniques for Gan despite the amazing results that they achieve.

Speaker 3:          01:00:32       Uh,

Speaker 1:          01:00:33       okay, check this out. This is what the loss is going to look like for both of them.

Speaker 3:          01:00:40       Hold on. There we go.

Speaker 1:          01:00:41       For the generator and the discriminary generators, green discriminators blue. Okay, check this out. What we want is the loss to minimize, right? We want to see it go down. But what's happening here is it's not minimizing, it's just going all over the place. So how do we know when to stop training? We just have to guess kind of, we kind of have to guess when it's, when it's, there's no, there's no point of a mathematical convergence. It's more of a, it's more of an intuition. You have to have an intuition behind. Okay, well just by looking at an image and saying this is, this is, um, sufficiently photorealistic but fake, which works and we've generated some really cool things, but we need better optimization techniques. And remember this, the bleeding edge, right? We are, we are at the edge of human knowledge on neural networks and deep learning. Right now we're at the end of this course. So if you were looking for a really cool idea on how to improve the space, better optimization techniques for generative adversarial networks. Okay. Because this needs to be better. And it's not that, it's some crazy hard thing. It's just no one's ever, no one's ever attempted to do this before. Okay. That's it for the, for this live stream. Let me answer some questions, some, some, uh, last questions.

Speaker 1:          01:01:53       Okay. Uh, so the last questions are, could we start the, the wrap, by the way, I'm going to wrap by the way. We have two minutes. Can you use gas for NLPs? Yes, you can. No, that's a great area of research. Yes. Yes. I want to see more of that. I actually haven't seen enough of that. And then are we optimizing for zero sum game when we are optimizing for a zero sum game? Why don't we use methods of well studied game playing algorithms for Gan? Yes. See you are thinking the exact way that I'm trying to convey. There's this entire field of research around game theory that we haven't really applied to generative adversarial networks even though it is a game theoretic problem. Right. So,

Speaker 2:          01:02:43       okay.

Speaker 1:          01:02:44       All right, so I'm going to wrap at the end. We've got two more minutes. So it's going to be to a Kendrick's new album down, which I've been listening to a lot. If you've been listening to it, you get this out. All right, so let me someone, someone throw out a topic. I'm throwing a topic when we got here. What's the topic? One more topic. I'm looking for a one word topic. Carlos as, come on. Here we go. One more topic. People first to say it versus say it gets it. Cool. Topics, rods. That's not the topic. So Dan, better

Speaker 1:          01:03:30       rap. I'm an animal. Come on, let's see a topic. I get Gan. Okay, fine. Yeah. Okay. I try to rap dance. Kazaam the man. I do it every day, man. I'm like, no cans now was a famous guy. He was living in Siberia. He came back looking at people like he was from my beer. Yeah. He was one of the best researchers. The fall time, if you want to be like him, man, you got to learn to ride, not just with words. You've got to run with math. You gotta go back to back to back to back with every single loss function that you try. Don't try and make it stop. Sit down and try to cry. If you can't get this, sit down. I don't want to listen. You've got to be the best man. Look, it's don't be just in. Okay. That's it for our route. See, that's how you know it's live. That's how you know it's live. Okay. So thank you guys for showing up and for that, I've got a research, some gans some more, and it's gonna be really exciting. So love you guys. Thanks for watching.

Speaker 2:          01:04:39       Yeah.