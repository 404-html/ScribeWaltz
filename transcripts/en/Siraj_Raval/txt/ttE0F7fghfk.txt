Speaker 1:          00:00          Hello world, it's Saroj and what hyper parameters should you use to train your model? You'll see these magic numbers a lot. They are the model values that are set before you train on any dataset. An ML model. It's just a formula with a number of parameters that need to be learned from data, but there are also parameters that can't be directly learned from the regular training process, and we call these higher level properties, hyper parameters. This could be the number of trees in a random forest, the number of hidden layers in a neural network, the learning rate for logistic regression. It's a process of trial and error and it's not very intuitive. Since we're not great at interpreting high dimensional data, legendary researchers like Oriole Vinyasa, Ilya Sutskever, consider the possibility space of hyper parameters there canvas. But what if we could have these parameters learn the optimal values for themselves that would make life easier, right?

Speaker 1:          00:59          Let's see if we can figure out a really basic strategy for ourselves and then try to improve it. I've got a Dataset here of tweets that are labeled as either positive or negative perfect for a binary classification problem, and let's say I built a support vector machine to learn this mapping so it can then classify a new tweet immediately. This is called sentiment analysis and it's a really popular task in NLP. If we mapped out these vectors in two d space, we could imagine a curvy line that separates the positive tweets from the negative ones, a decision boundary separate but equal weight. That's something else. A support vector machine can help us define this decision barrier. Since it's nonlinear, our SVM will use what's known as the kernel trick. That means instead of trying to fit a nonlinear model, we can map the data from the input space to a new higher dimensional space called the feature space by doing a nonlinear transformation using a colonel or similarity function and then use a linear model.

Speaker 1:          02:04          In the feature space, we define our kernel or similarity function between tweak vectors as the radial basis function, which takes as input to vectors and outputs a similarity based on the following function. So the more similar two tweets are the higher the output value from our function. There are two hyper parameters that govern how our line is going to be drawn. Both of these hyper parameters need to be selected very carefully. They depend on each other in unknown ways, so we can't just optimize one parameter at a time. Then combine the result. What if we just tried every single possible combination of hyper parameters to brute force? Assuming we've built our sem already, we can choose a set of possible values for both of them and create a variable to store our model's accuracy for each set. Then we'll create a nested for loop for every value of c, try every value of gamma inside our loop.

Speaker 1:          02:59          We'll initialize our SVM with the hyper parameters at that iteration. We'll train it and score it, then compare its score to our best score. If it's better, we'll update our values accordingly. This process will run for every hyper parameter value we have until it finds the optimal ones. This technique is called grid search because we've essentially made a grid of our search space and then evaluated each hyper parameter setting at the points we've introduced for as many dimensions as necessary. This was a pretty easy strategy to implement, but this scales pretty poorly. The more hyper parameters or dimensions we add, also known as the curse of dimensionality, I think we can do better than an exhaustive search. We tried every combination of a preset list of values of our hyper parameters, but what if instead we tried random combinations of a range of values for a number of iterations we define this won't guarantee that we'll get the best hyper parameter combination like grid search did, but it will take a lot less time.

Speaker 1:          04:06          So manual search, grid search and random search are all fine and dandy, but there's gotta be a more intelligent way of doing this that incorporates learning. One technique that's very popular right now is called Bayesian optimization. Last episode we talked about how base theorem is a way to determine conditional probability. It shows us how to update an existing prediction given new evidence. This forms the basis of the Bayesian way of thinking as opposed to the frequentist way of thinking. These are the two different approaches to probability. Basically it's like a mathematical gang war between applied statisticians.

Speaker 2:          04:50          How's it the cash? And Phil was my choices that keep it objective. I'm selecting, it's all about the gear. Bayesean

Speaker 1:          04:58          means probabilistic. It focuses on the probability of the hypothesis given the data. That means the data is fixed and the hypothesis is random. The frequentist approach focuses on the probability of the data given the hypothesis. So data is random as in if we repeat the study, that data might come out differently, but the hypothesis is fixed. We could apply frequentist or Bayesian methods to pretty much any learning algorithm. They have different aims in the context of hyper parameter optimization. Uh, Basie and approach takes advantage of the information our model learns during the optimization process. The idea is that we pick some prior belief about how our hyper parameters will behave and then search the perimeter space by enforcing and updating our prior belief based on our ongoing measurement. So the trade off between exploration, making sure we visited the relevant corners of our space and exploitation. Once we found the promising region of our space. Finding an optimal value in it is handled in a more intelligent way.

Speaker 3:          06:07          No, we only have few weeks left with mid serial last model. I know eventually we'll find the right hyper parameters, but how we tried to frequent this approach and it didn't work. I know, but we could try the Bayesean. Oh, so we can bank on certain in our mobile itself, like random variable. Exactly. A lot of people are, the models are using it these days. Let's go ahead.

Speaker 1:          06:28          Basie and optimization uses previously evaluated points to compute a posterior expectation of what the loss f looks like. Then it samples a loss at a new point that maximizes some utility of the expectation of f. That utility tells us which regions of the domain of f our best to sample from this two step process is repeated until convergence. For the prior distribution. We assume that F can be described by a golf Sian process. A gaussian distribution often called a normal distribution is described as a bell shaped curve. Distributions are equations that will link outcomes of a statistical experiment with its probability of occurring. The Gospel, Ian is quite popular. Half the data falls on the left of the mean half falls on the right and this is useful in many situations. A Goss IOM process is a generation of the golf Sian distribution over functions instead of random variables.

Speaker 1:          07:25          So wild gosh in distributions are specified by their mean and variance Gaussian processes are specified by their main function and covariance function. The way we find the best point to sample f next from is to pick the point that maximizes an acquisition function. This is a function of the posterior distribution over f that describes the utility for all values of the hyper parameters. The values that have the highest utility will be the values we compute the Los four next, we'll use the popular expected improvement function where x is the current optimal set of hyper parameters. By maximizing this, it will give us the point that improves on f the most. So given the observed values f of x, we update the posterior expectation of f using the GP model. Then we find that the new acts that maximizes the acquisition function, the expected improvement, and finally compute the value of f for the new X. Initially the algorithm will explore the parameter space, but it quickly discovers the region with best performance and samples points in that region.

Speaker 1:          08:31          Much smarter strategy, right? To summarize, we can optimize our hyper parameters using several strategies, but Basie and optimization looks most promising. Bayesean optimization picks a prior belief about how the hyper parameters will behave and then searches the parameter space by enforcing an updating that prior belief based on ongoing measurements. So Bayesians let their prior beliefs influenced their predictions. Frequent tests don't. And now to announce the real heroes, the wizards of the week is Noah [inaudible]. Noah built a naive Bayes classifier to distinguish rap lyrics from biggie and Tupac. He uses unigrams, bigrams and trigrams to count words and achieve the best results with unigrams. Great work. Noah and the runner up is Hammad shake his naive Bayes classifier detected spam and youtube comments. And he's a popular TF IDF technique to determine how important and word was instead of bag of words. Next level, this week's coding challenge is to write out a Bayesean optimization strategy for the hyper parameters of a linear regression model. See the get hub link in the description for instructions and poster, get hub link in the comment section. I'll announce a winner next week. Please subscribe for more programming videos, and for now I've got to update my priors, so thanks for watching.