Speaker 1:          00:01          Deep learning on three d objects. Finally, hello world. It's Saroj and geometric. Deep learning is an emerging field of machine learning that's able to learn from complex types of data like graphs and three d objects in this tutorial video will learn how to use geometric deep learning to classify groups with similar interests in a social network and apply it to 3d object classification as well. In the last decade, deep learning algorithms like convolutional neural networks and recurrent neural networks have allowed us to achieve unprecedented performance on a broad range of problems. We can now classify images, recognize speech, translate languages, generate pickup lines, and some of these metrics have incredibly already surpassed human capability. It's been incredible to see the progress that's happened, but a lot of the algorithmic techniques that have been used to achieve these breakthroughs are actually pretty old. What's been the real catalyst for the deep learning revolution so far has been the availability of new types of datasets that have been generated, whether it be the Atari Dataset for deep minds, deep cue learning algorithm, or the chess game dataset for IBM's deep blue victory.

Speaker 1:          01:20          Also gps and Hinton's blessings. The data set point is important because in the past few years, we're seeing more and more of a special type of Dataset. Three d objects, thanks to companies that have democratized tools like the connect that are able to capture three d point clouds of objects, not just two d images. We now have a wide variety of three d objects available to train models on. Once we do that, we can classify them however we'd like or even generate new objects. Graphs are another type of emerging datasets. We can consider social networks as graphs where the characteristics of users can be modeled as signals on its vertices. The sensor networks are another example. Distributed interconnected sensors have readings that can be modeled as time dependent signals on graph courtesies. In genetics, gene expression data is modeled as signals defined in the regulatory network. Graph models are also used to represent anatomical and functional structure in the brain.

Speaker 1:          02:21          You would think that we could just feed this type of data to a deep neural network and assume that it would be able to properly parse it, right? Ah, ah. Neural networks aren't that great at interpreting this type of data. The reason being deep learning generally works well on what's called Euclidean data graphs and three d objects that those are considered non Euclidean datasets. Let's break down the difference. Euclid was a Greek mathematician who wrote a book called the elements over 2000 years ago where he outlined the geometric properties of objects that exist in flat two dimensional planes. That's why Euclidean geometry is also known as plain geometry. Euclidean geometry is pretty straightforward, pun intended, lol. It has its own set of rules like the interior angles of a triangle add up to 180 degrees and two parallel lines will never cross and the shortest distance between two points will always be a straight line.

Speaker 1:          03:18          You could. Ian Geometry is still practical and has been used by modern engineers to design buildings, predict the location of moving objects, not die, and survey land. We can also use it to help us define data. For example, we can consider an image as a function over a two dimensional plane. This function can help us define the image intensity at a specific coordinate. On the two d image plane and if we need the value of the image intensity at another pixel, a certain number of units along the x direction, we can just plug that new coordinate set into our function. This property is very useful if we want to define a convolutions. Convolutions are one of the main building blocks of convolutional neural networks. The type of network as suited for image processing. The term convolution refers to the mathematical combination of two functions to produce a third function.

Speaker 1:          04:10          It merges two sets of information. In the case of a CNN, the convolution is performed on the input data with the use of a filter to then produce a feature map. We execute this convolution by sliding the filter over the input at every location a matrix multiplication is performed and some of the results onto the feature map. It's one of several operations that make these networks work really well on image data, but if we curve the image so it becomes a three d object, we can't just convert solve around the three d shape using vectors like we did for three d images. That means we need to redefine the whole notion of a convolution. Non Euclidean geometry encompasses this type of data, whether it's a sphere, a shapeless three mass like ditto in Pokemon or a graph of some kind. A lot of the most interesting data types lie in this category from protein interaction networks to knowledge graphs to the entire worldwide web.

Speaker 1:          05:05          The non Euclidean nature of this data implies that there are no familiar properties like a common system of coordinates vector space structure or shift in variants. We need a neural architecture that can learn from non Euclidean data with the kind of accuracy that CNN give us for it. Euclidean data enter the graph. Convolutional network or GCN GCS are very powerful models, so powerful in fact that even a randomly initialized to layer GCN can produce useful feature representations of nodes in a given network. We can think of a general graph based learning problem in the following way. We're given a set of nodes each with an observed a number of numeric attributes for each node. We'd like to predict an output label. We have labels for some nodes, but not all nodes were. Also given a set of weighted edges summarize by an adjacency matrix. The main assumption is that when predicting the output for a know the attributes and conductivity of nearby nodes provide useful contextual information, gcs can solve this problem.

Speaker 1:          06:08          They are neural networks that can operate on graphs. A good way to imagine what's happening is to consider a neural network that were seized as input a set of features from all nodes in the local neighborhood around a node and outputs and estimates of the associated label. The information from the local neighborhood gets combined over the layers via the concept of graph convolutions. The deeper the network, the larger the local neighborhood. We can think of it as the generalization of the receptive field of a neuron in a normal CNN. This network is applied convolutional Lee across the entire graph, always receiving features from the relevant neighborhood around each node. Let's talk more about how these graph convolutions are defined by applying a GCN to a real world graph. We have a social network dataset here, a football enthusiasts that are divided into two groups, fc Barcelona fans, and Real Madrid fans, and this is represented as a graph.

Speaker 1:          07:04          Our Selena is the better team, but that has nothing to do with this. Nodes represent members of the network and the edges are there at mutual relations. The leader of both groups is denoted by a respective letter. We can build our graph convolutional network by first initializing it at random to produce feature representations. Then we'll stack our GCN layers using the identity matrix as a feature representation. So each node is represented as a one hot encoded categoric variable. Our GCN, we'll take as input a feature matrix that includes a number of nodes and the number of input features for each note. It also takes as input the matrix representation of the graph structure. Each hidden layer of the network corresponds to a feature matrix where each row is a feature representation of a node. At each layer, these features are aggregated to form the next layers features using a propagation rule.

Speaker 1:          07:58          So features become increasingly more abstract at each consecutive layer are simple propagation rule consists of the weight matrix for a layer and a nonlinear activation function relu. So the size of the second dimension of the weight Matrix determines the number of features in the next layer. This is reminiscent of the convolutional filtering operation from regular convolutional networks. In that the weights are shared across nodes in the graph. We can easily extract the feature representations from the graph and plot it in a few lines. It cleanly separated both sides and we haven't even started the training process yet. If we start training our output graph, we'll get way more accurate and this demonstrates the power of gcs pretty dope, right? But social network graphs aren't the only type of Euclidean datasets. We can also use gcs on three d objects if we consider them as point cloud data point clouds are just a set of points represented 3-d either Xyz locations.

Speaker 1:          08:57          It's what hardware like the connect generates. It's computing not just pixel data, but depth as well. So there's a third dimension involved. If we consider the points in a point cloud as nodes in a directed graph, we can apply gcs to them. There has been several work in this space just this year. A paper titled Dynamic Graph CNNS use a GCN to improve feature extraction from point cloud data. There are several variations here of Splat net point net. There are different types of graph convolutions and different pooling architectures designed to work well with point cloud data. This space is moving fast so expect to see even more improvements in the next few months, but we can already use several of the freely available models on get hub ourselves to build products and services. There are three things to remember from this video. Deep learning generally does really well at extracting useful feature representations from Euclidean datasets. Euclidean data follows the laws of Euclidean geometry. It's grid like and follows rules involving straight lines and points, geometric deep learning models like graph convolutional networks help learn from non Euclidean data like graphs and three d objects by introducing an ordering of mathematical operators that are different than in classical convolutional layers. In this video, give you an idea for a startup, share it with us in the comment section, and please subscribe for more programming videos. For now, I've got to visit the fifth dimension, so thanks for watching.