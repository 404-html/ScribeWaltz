Speaker 1:          00:00          What happens if we predict the past? Oh Shit. Hello world. It's Saroj and I get a ton of questions about how to make predictions using time series data. So I'm going to explain eight different time series prediction techniques to predict the price of gold in this video. In order of increasing complexity, we can think of time series data as a sequence of data points that measured the same thing over an ordered period of time. Another way of thinking about it is that it's a series of numeric values, each with its own timestamp defined by a name and a set of labeled dimensions and we're seeing this type of dataset become more common. In fact, if we look at developer usage patterns in the past two years time series databases have emerged as the fastest growing category of databases. Autonomous Trading Algorithms continuously collect data on market fluctuations over a period of time.

Speaker 1:          00:59          It's like digital wolf of Wall Street, smart homes, monitored data points like the temperature number of people in the house, swag level and energy usage. Jeff Bezos, I mean Amazon monitors how it's many assets are moving across the world with a fine grained level of precision and efficiency that makes same day delivery possible. All of these applications have one thing in common. They rely on a form of data that measures how things change over time. Usually time series data sets have three home analogies. That data that does arrive is recorded as a new entry. It arrives in time order and time is a primary axis. These datasets are generally append only the data that has been recorded doesn't change since it was recorded at some point in the past time series. Data sets are different than just having a time field as a column in a Dataset.

Speaker 1:          01:54          In that when we collect a new data point for time series data, we have to create a brand new row for it. We can't overwrite what happened before. Only by doing this will we be able to track all changes to assist them over time. Recording data points over a series of time allows us to analyze how something has changed in the past. Monitor how is changing in the presence and even predict how it could change in the future. So let's say we have a Dataset of the price of gold over a period of time from many days ago up until today, we want to be able to predict the price of gold tomorrow using this datasets. How are we going to do that dark magic? Well, before we do anything, let's split our data into training and testing data. We can use the popular machine learning library called psychic learn and pandas to do this.

Speaker 1:          02:45          Let's start with the most naive approach we can. If we want to forecast the price for a given day, we can just take the last days value of our training set and use it to estimate the same value for the next day. We can represent this as the equation y hat. The price of gold of the next day is equal to y the price of gold from the previous day. That's the most basic time series forecasting equation we could make. Then we can check the accuracy of our model on the testing data set. By using psychic learns mean squared error module. It'll allow us to compute the error between our prediction and the testing data set, which are the real values for all the data points we predict. We can compute the root mean squared error and it will output a scalar value. As you can see, this value is pretty bad. We could do much better, so instead, let's try using a different method called the simple average.

Speaker 1:          03:39          Sometimes we get a Dataset that varies by a small margin through its time period, but the average at each time period remains constant. We can thus try and forecast the price of the next day using the average of all the past days. The expected value will then be equal to the average of all previously observed data points. It's not going to be exact, but it can be somewhat close, right? Actually, when we compute the error again, we'll see that this model didn't improve our score. This method works best when the average at each time period is constant, but even though the naive methods scored better than the average method, it doesn't mean the naive method is universally better. It just happened to be better. In this case. If in our graph we can see that there's a big difference in terms of the prices in the initial period and the later period.

Speaker 1:          04:31          Perhaps we could improve our simple average approach by only taking the average of the prices for the last time period only we'd call this the moving average. We just need to pick the right value for p where p is the fixed finite number of previous values. When we test this out, we can see that we are getting better at predictions, are error is smaller and our prediction line intersects much more of our test data. One thing we could possibly do to improve our model is add some weights to our values. Meaning it seems like the more recent the data points, the more it matters. If we gave different weights within the sliding window of values, which all add up to one, we can mathematically define a preference for values that came later on in the series. Notice that both the simple average and the weighted moving average are on opposite ends of the spectrum in terms of how they approach the problem.

Speaker 1:          05:29          Ideally, we can use a method that incorporates ideas from both techniques combining them like a megazord. It's clear that attaching larger weights to more recent observations and two observations from the distant past will work well, but instead of manually deciding what those weights are, let's define a smoothing parameter called Alpha. The rate at which the weights will decrease is controlled by this parameter and we can make the equation more simple and that the of y hat just turns out to be the sum of just two products. We've created a weighted moving average with two weights because the expression is recursive. This is an exponential method. Simple, exponential smoothing to be exact, but still it's not taking into account just how much variation there is in our data. Charles Holt, a professor at Carnegie Mellon noticed this problem a few decades ago and extended the idea of simple, exponential smoothing to allow for forecasting of data with a trend.

Speaker 1:          06:30          This method called Holts. Linear trend applies exponential smoothing to both the level and the trend. The trend is the general pattern of prices that we observe over a time period and the level is the average value in this series. To Express this mathematically, we need three equations, one for level, one for trend and one to combine both to get the expected forecast. The level equation demonstrates that it's the weighted average of the observation and the within sample one step ahead forecast. While the trend equation shows that it's a weighted average of the estimated trend at time t based on the other values as well as the previous estimate of the trend, this model is better but it's still not taking the variation into account as well as we'd like. So let's look at one more improvement from our buddy Holt hold notice that sometimes there are trends that depend on certain seasons.

Speaker 1:          07:25          For example, a store that sells winter clothing will usually make more sales in the winter instead of this summer and this is a pattern that repeats as the seasons change yearly, we can call this pattern seasonality and data sets that show a similar set of patterns after fixed intervals over a time period. Exhibit. This Holtz winter method takes into account both trend and seasonality to forecast prices. We apply exponential smoothing to the seasonal components in addition to level and trend, each has its own unique smoothing parameter. The level equation we'll show the weighted average between the seasonally adjusted observations and the non seasonal forecast from time t. The trend is the same as holds linear method and the seasonal equation shows a weighted average between the current seasonal index and the seasonal index of the same season. Previously, when we plot this, we get our lowest error yet and our prediction finally looks like it's fitting or testing data, but wait before you try and collapse the financial markets.

Speaker 1:          08:28          As great as that last method was, keep in mind that so far we've only looked at univariate time series data meeting. It's a series. What they single time dependent variable. Usually though in the real world there are multiple variables at play and handling all of them at the same time is a skill that can be mastered. This is instead considered multi-variate time series data. Each variable in a multivariate time series depends not only on its past values but also has some dependency on other variables. Want to use these dependencies to help forecast future values. One of the most commonly used methods for multivariate time series forecasting is called vector auto regression or or bar and the bar model. Each variable is a linear function of the past values of itself and the past values of all other variables. If we have two variables, y one and y two and we need to forecast the value of these two variables at a given time, we can represent the relation between both.

Speaker 1:          09:30          As such, we've got constant terms, coefficients and error terms here in order to use the multiple variable terms in each equation we'll use vectors, but what else could we do here? Well, we haven't yet used a learning technique. Recurrent neural networks are able to learn how to make predictions in sequences of data and a variance of recurrent networks called long short term memory networks are able to learn from even longer sequences of data. We can treat our Dataset as a supervised problem if we'd like and use an LSTM network to predict our target. We could also use reinforcement learning where we frame the market as a Markov decision process and use real time reward signals from the market to help adjust our predictions as in if our buy and sell decisions affect the price of gold, I've got videos on both of those topics. Link will be in the video description. There are three things to remember from this video for univariate time series. Data Holtz winter method works pretty well for multivariate at time series data. We can use a model called [inaudible] auto regression, and if we're feeling ambitious, we can use a learning technique like recurrent networks to help learn trends in the data rather than using a static model. I'm so proud of you for making it to the end. Please subscribe for more programming videos, and for now, I'm going to go forward in time, so thanks for watching.