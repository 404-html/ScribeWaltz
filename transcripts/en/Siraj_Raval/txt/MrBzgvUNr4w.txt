Speaker 1:          00:00          Oh world, it's Saroj. In this video we're going to create a neural network that makes images become really trippy using python and tensorflow. We humans have been using psychedelic drugs since prehistoric times that wasn't a normal mushrooms. They help manifest parts of our minds to conscious experience that wouldn't normally otherwise. One of the most common experiences from psychedelics are trippy visuals. People who've taken psychedelics repeatedly described experiences of seeing both open eye and closed I visuals, but how, what are these drugs doing in our brain that makes us see things that aren't really there? The traditional way for us to find out is to test live human subjects, tripping balls under an FMRI machine. Or recently we've got an artificial neural networks to do the same thing. Google train a neural network on a labeled data set of images, everything from squirrels to temples and as a train on these images, it built internal representations and each layer, eventually the first few layers learned low level features like lines and edges, and they got progressively more abstract.

Speaker 1:          01:03          So the last few layers when representations or faces and big shapes. So when we visualize one of the higher level representations at Bell, we can see that it contains a mixture of features like the eyes of a dog and the head of a bird, and when they gave it a novel image and ask not to classify it, but to maximize a similarity between the image and a representation at a particular layer. The result was a very trippy image. It all sounds very similar to the drug experience, which is insane. Our brains are carbon based and they use chemical signals as messengers on neural network doesn't even exist and physical space at all. It's an abstract concept being represented on finery silicon transistors. There's no reason to expect that these two systems would develop the same mechanism for processing visual information, even with existing similarities. Natural selection is very different from using gradient descent to alter weights of connections between nodes. Could it be that somehow encoded into the fundamental rules of the universe? There's this ideal way of doing object recognition.

Speaker 1:          02:05          He's beginning to believe you're damn right. Morpheus. We're getting closer to understanding it every day and we can learn a lot about the brain, including human development, treatment for cognitive disabilities and drug effects from studying artificial neural networks. After we install our dependencies, we're going to replicate Google's deep dream code in tensorflow and then test it out on a novel image num Pi will be used to perform math calculations. The partial sub module of funk tools. Let's US create new versions of functions with one or more arguments filled in. This is good for reusability, which means less code to write pillow is an imaging library and image will help us modify our images. Tensorflow is our machine learning library. You are alive will let us download data from the web. Oh s will let us use operating system dependent functionality and zip tools. Let us run three no, it'll just let us unzipped files.

Speaker 1:          02:54          Our imports are already at the top of our script, so we're going to download Google's pretrained neural network. Create a tensor flow session, pick a layer in the pretrained network to enhance our input image, apply our grading ascent to that, layer it repeatedly, and then output our newly deep dream image. Let's start by downloading Google's pretrained neural network called inception. In our main method, we'll store link to it in the URL variable. Create a data directory where we will extract it to then use the ois module to retrieve the model name and create a local zip file path. If there is nothing at that path, we can download it using the URL life module with the URL variable as a perimeter and store it in the model URL variable. We'll open our zip file with the WB flag so we can write to it in binary.

Speaker 1:          03:36          Then write the downloaded data to it. Then we'll extract that using the zip file module. Now we can create our tensorflow session. We'll load our intersection graph file into our model fn variable than initialize a graph. Using the graph function of tensorflow. Now we can initialize a session. Using that graph. We'll open our existing saved in section graph using the fast g file function and pointed to the sage grass. Once we opened it, we can read that graft and parse it accordingly. Using the parts from string method of TensorFlow's graph definition module, we need to define our input. So we'll create an input tensor using the placeholder method called input with the size of 32 bits. Then we'll define the image net mean value of pixels in an image as one 17 by removing this value from our image, it will help us with feature learning.

Speaker 1:          04:20          So we will subtract it from our input tenser and store the value in our preprocessed variable. Then we'll load the graph deaf variable we initialize with the input as newly processed tensor. So now we've got our tensorflow model we've downloaded from the web and we've loaded it into our session as a graph with a bunch of layers. It's a convolutional neural network, the type of neural net that helps recognize images. Let's load all those layers into an array and store them in our layers object. So for every tensorflow operation in our graft, if it's a convolutional layer, load it into our array. So we've got layers. Lay Lay years. Yeah, we're balling hard right now. I know. Okay, so each of our convolutional layers, I'll put tens of hundreds of feature channels to pass data in the graph and we can collect them all and store them in the feature numbs variable.

Speaker 1:          05:04          Let's print them out and visualize what we've got in terminal first. We can see our number of layers and the total number of feature channels right here. Let's now pick a layer from our model that we're going to enhance. Well, pick a lower level layer and pick one of the featured channels to visualize it's time to load our input image using the pillow image submodules open method and store it in our image variable. We'll format it accordingly. Using num py and perform deep dream on it. With our render deep dream function with a focus on the layer we selected earlier in our deep dream function, we can see a couple of our predefined hyper parameters. We'll start by defining our optimization objective, which is to reduce the mean of our input layer. The gradients function lets us compute the symbolic radiant of our optimize tensor with respect to our input tensor.

Speaker 1:          05:47          Now we can split our image into a number of octaves and say for each octave, let's resize it using num py and add it to our array of image octaves and we can generate details Optiv by OPTIV by iterating through each random shifts or applied to the image to blur tile boundaries over multiple iterations using the CALC grade tiled function. We're essentially applying gradient a sent here to maximize our loss function, which merges are saved representation in this layer with our input image. More and more every iteration. So to break it down, neural networks are a great test bed for learning about how the brain functions and responds to certain stimuli. They store increasingly abstract representations of what they learn in their layers and we can create trippy images by applying a gradient ascent process to them based on any chosen layer of a pretrained convolutional neural network.

Speaker 1:          06:36          The winner of the coding challenge from the last video is [inaudible] Tucker Party. He created a pretty cool I python notebook to demo his coach and train his neural net on both price and sentiment data using care. Awesome bad ass of the week. And the runner up is Victor Sirano. Very well documented codes that asks for user input on stock prediction. The coding challenge for this video is to modify this code so it works not just on images but video. He tells her in the read me poster, get humbling in the comments and I'll announce the winner in the next video. Also, I created a slack channel for all of us programming wizards to learn from each other, linked to sign up below. For now, I've got to say sober, so thanks for watching.