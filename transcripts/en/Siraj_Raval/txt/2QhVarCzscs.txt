Speaker 1:          00:00          Hello world. Welcome to sora geology. Let's talk about four reasons. Alphago is a huge deal. Alphago is an AI created by a team of researchers at Google designed to play the ancient Chinese game of go and go to players, take turns placing black or white stones on a board trying to capture the opponents stones or surround empty space to make points of territory. The first reason is that it beat the best human player in the world at a game that is orders of magnitude more complex than chess. Think of solving chess like painting, align and solving go like painting the Mona Lisa one is just way more complex than the other. Remember Ibm's deep blue and when it beat world champion Garry Kasparov at chess in the 90s at the time that was a huge deal because no program had ever done that before. What deep blue did was they would examine all possible moves and all the possible countermoves and all the possible counter counter moves and so on until it had searched every single possible play and then pick the best one.

Speaker 1:          00:54          This is called a brute force search and it worked, but that method wouldn't work for go because in go there are more possible plays and there are atoms in the universe. Crazy, right? So Alphago can't just try all possible plays. It has to use intuition like human players would what it felt would likely be a good play to do this. Alphago uses something called a neural network and neural network is an algorithm that tries to mimic how the brain works. Roughly. You have a bunch of neurons that are connected to each other a layers. You have an input layer, middle layers and an output layer. Each neuron performed some preset calculation on the data and outputs the result to all the connected neurons. This process continues until the data goes all the way from the input layer to the output layer. So if you input photos of Trump, which really just breaks down to a bunch of ones and Zeros, if you think about it like all data and feed it into the input layer, what it's doing is recording commonalities across all the photos.

Speaker 1:          01:46          This is called training and machine learning. So given enough Trump photos of eventually it can start recognizing Trump. When it sees a novel photo, I'll putting data that means yes, this is Trump or no, this is not Trump. The team created a neural network and input 30 million expert moves from go until it could output yes is an expert move, but it's side. Then they had to play against itself countless times until it got better and better through trial and error. This is called reinforcement learning. We do too. Whenever we practice shooting hoops or playing an instrument, practice makes perfect. This gave Alphago a sense of reflection when evaluating a move, it could look back on simulated results, but they also wanted to give it a sense of intuition. So they created another neural network that observed the moves from the simulations. So by combining these two networks together, Alphago was able to give an estimate of how good a move is by using a mixture of reflection and intuition.

Speaker 1:          02:38          So in a live game, every turn Alphago uses this move evaluator on a bunch of possible moves before deciding on the best one and playing it. It's not a full on brute force search, but a more educated and smaller search. It's called a Monte Carlo tree search. So cool. The second reason is that this took one year instead of 10 years to build leading AI experts predict that it would take a decade to build a machine capable of beating the best human player at go. It only took one year. It's just another sign of the exponential progress of technology. Think of all the trends in computing that this upholds. Moore's law states that computing power will double every two years. The law of accelerating returns by director of engineering at Google, Ray Kurzweil states that technological progress in general is exponential, not linear. 80% of the world's data was created in the last year and we are all building and creating all of each other's data at an exponential rate.

Speaker 1:          03:27          The third reason is that this creates a new field. Ai Psychology in the second game against least cdot Alpha played a move that no human would ever play. Move 37 that move represents the promise of Ai. When Alpha go played at Lisa Dole was completely baffled fan way. The other go master said it's not a huge move. I've never seen a human play this move before and later kept calling it beautiful, so beautiful Alphago things differently than the best of our species at this task. Even the creators don't understand how it happened. That's the beauty of machine learning. Programmers don't code every single rule to give it the building blocks to learn by itself and unleash it on massive amounts of data. We can study Alphago and learn new ways of thinking. The fourth reason is that this technology hasn't yet been applied to other fields. Think about the recent breakthroughs in quantum computing.

Speaker 1:          04:13          Google proved first of all that a quantum computer was possible and second of all, that it's solved a specific algorithm 100 million times faster than a classical computer. Now think of how smart Alphago would be if it ran on a quantum computer. Robotics, genetics, physics, climatology, economics. This is just the beginning of new breakthrough discoveries in these fields. Scientists have tons of data that no human could possibly sit through. Certain probably has a new particle somewhere in its data set. We just don't have the intelligence necessary to sift through the noise and find the meaningful bits. Alphago and the promise of Ai is going to help us solve some of the world's biggest problems, and we should all keep a very close eye on this space. For more information about half ago or AI in general, check out the links in the description below, and as always, thanks for watching.