Speaker 1:          00:00          Hello world, it's Saroj and if you only have a little bit of data can you still learn from it? We're going to build a model that learns to classify images using a very small dataset for training. The pointing is still very much a dark heart. It's an emerging practice in the world of machine learning that isn't well understood even by those pushing the state of the art, which is exciting because it means that there's so much potential for discovery and it's not just one algorithm. It's a collection of them. Recurrent Nets, convolutional nets, restricted ultimate machines, Barbra Streisand. These are all networks that can recognize patterns in the world and they themselves have shared patterns. One shared pattern is that they all use a hierarchy of layers. The other is using differentiable layers so that we can use gradient based optimization to improve their prediction. Design patterns are nothing new in computer science.

Speaker 1:          00:57          There are many books on design patterns for topics like object oriented programming and user interfaces. When it comes to deep learning, there's not really a definitive design pattern guide. We're all kind of figuring it out collectively right now. You might glaze over a deep learning paper and assume that there is some solid mathematical foundation behind what the researchers attempted because you see all sorts of equations for things like Hilbert spaces and measure theory. But the reality is that our collective understanding is still pretty minimal. Theories are often formulated because they are mathematically convenient. For example, the dossier and distribution is ubiquitous, not because it's some divine construct that the universe has bestowed on us, but because it's mathematically convenient. So defining standard design patterns for pattern recognition networks is a field right for discovery. In the context of machine learning, we can call it metal learning or learning to learn.

Speaker 1:          01:55          Can we design a system that learns how best to learn? That is. It learns how to perform well at an immediate task in the short term and in the longterm it learns a common structure across many tasks. We see metal level constructs in nature all the time. DNA is a great example. It carries the instructions, the blueprint to create learning systems that can expire our brains, but it acts as longterm memory by transcending death. Just like Oracle. As long as there is a mechanism for memory and one to alter behavior based on that memory and that mechanism can serve as a metal level construct. In the past few months, there have been several papers on metal learning that had been published, but I want to talk about one that uses metal learning as a tool to solve another task. One shot learning the goal of learning from one or only a few data points.

Speaker 1:          02:44          This is what we should be aiming for. Since GPU costs are too damn ha, they used a modified version of a model called a neural Turing machine. The learned declassified character images with just a few examples. The mind first raise up the idea of Mtms in 2014 it contains two components. The first is a neural network that we call the controller and the other, it's a memory bank. The controller takes vectors as inputs and outputs, vectors as well, just like all neural nets. But what makes it special is that it also interacts with a memory matrix using read and write operations. This is where the Turing machine analogy comes from, not just cause it sounds dope, but because a turning machine manipulates symbols on a strip of tape according to a table of rules. It's like having a working memory for a brain and network learns how best to use its memory when learning a solution to a given problem.

Speaker 1:          03:36          For the controller, they use an LSTM recurrent network. Since it's internal state is a function of the current state and the input to the system. It can perform context dependent computation. So a signal at a current time step can influence the network's behavior later on. We need all the components including the memory store to be differentiable so that we can incrementally update their values during training. To achieve this, they added an attention mechanism so that each read and write operation interacts to a tuneable degree with all the elements in memory. Rather than addressing a single element like a normal touring machine would. Each row in the memory matrix represents a memory location. Read and write heads use a weighting vector with a component for each location. So if there are 10 memory locations and the weighting vector with just one value at index, three would focus the attention of the memory operation on location three but a weighting vector like this spreads its attention to the memory across multiple locations. A re operation is just a combination of the memory matrix and weighting vector. A write operation though has two parts on a race operation than an ad operation. Way these read and write heads are produced is by combining two memory addressing mechanisms. The first is content based. We focus on locations based on the similarity between their current values and the controllers emitted values. The second is location based. It puts silicates iterations across locations of the memory and random access jump,

Speaker 2:          05:15          right? So

Speaker 1:          05:22          the authors of our one shot learning paper knew that Mtms, we're a subset of memory augmented neural networks and they saw the potential to improve on it so that they could learn from just a little data. They discovered that using a pure content based memory writer instead of content plus location, let them do just this. That's because there's a trade off when training man s more complex. The memory mechanism, the more training the controller requires, the data set has 1600 separate classes and only a few examples per class. Perfect for one shot learning, they randomly five classes and randomly assigned each class a label between one and five so the model gets shown. An instance of a class tries to classify it and it gets informed of what the correct label is. We'll only need tensorflow and num Pi for our model will first define our memory bank and internalizing each of the variables that make it up.

Speaker 1:          06:17          Then we can define our controller. A feedforward neural network will define each set of weights and biases layer by layer until we've reached the output layer. We can define the interaction that happens between both components under the step function, which is called every time step. During training, just like with a regular NTM, we read a vector from memory that is a linear combination of it's rose scaled, a normalized wait vector for the given input x. The read vector will produce a key. We compare each key against each row in memory using the cosine similarity as a measure. This produces the read wait vector, which tells us how much each row should contribute to the linear combination. The difference here is that there is no extra perimeter to control the read wait vectors concentration to write to memory. The controller interpolate between writing to the most recently read memory rose and writing to the least used memory recipes.

Speaker 1:          07:15          Using the read wait vector at a previous time step and the weight vector that captures the least used memory location. The controller combines the two using a scalar parameter and the sigmoid function to create a right wait vector. Each row in memory is then updated using the right way vector and the key issued by the controller. The model eventually returns the probabilities for each class as a Vectra. After we've initialize our tensorflow session, we use gradient descent via Adam to optimize our network. For every image labeled pair we feed in via a dictionary. We'll print out our results iteratively after training. We can test it out on some different recognizable characters and notice how the accuracy is surprisingly good. Normally training time would take a lot longer for similar results. These results are very promising for lunch and learning. That's all it takes. Some training folks.

Speaker 1:          08:09          Let's get down to brass tacks. A metal learning system learns how to perform well at an immediate task and also learns a common structure across many tasks. Memory, augmented neural networks like the neural Turing machine use a controller and an external memory store to perform metal learning and metal learning can be a way to achieve one shot learning, which means learning from one or a few examples. This week's coding challenge is to use a memory augmented network to learn to classify two classes of animals. He tells her and the read me get humbling. It's going to comments and winners will be announced in one week, and although this is the last video for this course, I'm still just getting started. Please subscribe for more programming videos and for now I've got to go celebrate. So thanks for watching.