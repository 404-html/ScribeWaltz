Speaker 1:          00:01          Miss your chance to blow this up.

Speaker 2:          00:04          It actually takes more than a one shot to train a model. Hello world, it's Saroj and welcome to fresh machine learning. This course is all about making bleeding edge machine learning accessible to developers. The field is moving faster than Steve Balmer at a developer conference.

Speaker 1:          00:23          It's the belt look for some pills.

Speaker 2:          00:25          We're going to learn to apply some of the latest machine learning techniques to practical examples that you can integrate into your own apps. Neural networks had been around since the 50s but we've just never had as much data and computing power as we do now. We call it deep learning these days and it deserves the press it's gotten but so many articles claim and replicates the human brain. Some even make it sound like if we give a deep neural net enough data and compute, it'll suddenly become self aware. The brain is indeed a neural network, but do we really learn the way a deep neural net does what? Let's think about it. In order for deep neural net to learn to say recognize an image off of banana. You first have to feed it hundreds of thousands of banana images. But think about the way you and I learn.

Speaker 2:          01:05          If I were to show you an image of a banana for the first time, you'd probably be able to recognize a novel banana instantly, even if it was a different shape or color. We humans don't seem to need thousands of examples just to generalize just a few. And we learn richer representations than machines do as well. We can use the concepts that we learn in other ways, like creating new examples. If we could create an algorithm to do this, to learn concepts with a few examples, wouldn't that be incredible? It would further democratize the fields so that not just the big companies like Google and Amazon with huge private internal data sets are able to train their models, but anyone can. So is there an algorithm that does this well? There was a recent paper that came out called human level concept learning through probabilistic program induction.

Speaker 2:          01:45          The authors said, let's build a model capable of what's called one shot learning one shot learning is a type of ml that learns an object category after just one or a few examples. Oh, we use something called BZ and program learning or BPL to do this Basie and refers to base theorem which attempts to use simple stochastic programming to represent concepts. The words the castic referring to the theory of probability is what Bayes theorem loosely revolves around. So by using simple the castic programs or probability algorithms, BPL can represent concepts. BPL build these simple stochastic programs compositionally from parts subparts and spatial relations. All these things exist in a hierarchy of knowledge, which a machine has game through little experience. So they trained it on a Dataset of head writing characters and it was able to recognize characters with a better error rate than deep learning or even humans.

Speaker 2:          02:32          So does that mean that BPL is a way to go? Well, it does have its flaws. It lacks explicit knowledge of certain things like parallel lines, symmetry and connections between ends of strokes and other strokes. And the learning hasn't really transferrable to other things. So it's not better than deep learning in every way. A few months later though, deep mind challenge the paper by releasing their own called one shot learning with memory augmented neural networks. The basic idea they had was that deep learning is very data intensive, but perhaps there's a way to build a deep neural net that only needs a few examples to learn deep learning without the huge datasets. So they built what's called a memory. Augmented neural network on man has two parts, a controller, which is either a feed forward neural net or LSTM neural net and an external memory module. The controller interacts with the external memory module with a number of read, write heads.

Speaker 2:          03:17          It's capable of longterm storage, be a slow updates of the weights and short term storage be the external memory module. They fed it a few examples of handwritten characters and continuously trained it thousands of times on just those examples. And guess what? It outperforms humans as well. So they proved that one shot learning can be accomplished by using a neural network architecture, which is pretty dope. So there are lots of methodologies to implement one shot learning and in this episode we're going to implement our own. We're going to build a one shot handwritten character classifier in python using the PSI Pi Library. So we've got an import our dependencies first we're going to want three libraries, num, Pi, Psi, Pi and copy. Once we have those we can define two variables, the number of runs we want to complete and a reference far for where we store our class label.

Speaker 2:          03:58          Then in our main method we can create an array of the size of runs, which is 20 we'll use this array to store all of our classification error rates, one every run. Then we'll write a four loop to train our algorithm 20 times for each run or run a classification function, which will attempt to classify a small sample set of images and store the error rate in the array. Then we'll print out the error rate to terminal and when we are done with all of our runs, we'll go ahead and get the mean error rate from the array and print it out as the last statement in terminal. So how does this classification step work? Before we answer that, we need to understand these two methods, load images, points and modified how store distance, the load images, points, function loads and image files. In our case, this will be a character image.

Speaker 2:          04:32          It then converts the image to an array and finds all the non zero values that is all of the inks pixels and store that in an array. Then it creates an array of all the coordinates of those pixels and returns that the modified house store. If distance is a metric that computes the similarity between two images by comparing their pixel coordinate erase that comes from the load images points function. It calculates the mean difference between both images and returns it the last parameter of the classification function costs just notifies a function that small values from the modified Hausdorff distance mean more similar. Lastly, let's take a look at the classification function itself and this function. We were treated both our training and testing images and load their image point major cs into memory. Then we compute the cost matrix using the modified house torque distance. After that, we compute the error rate and return it. That's all. We do this for every run and then average them all and get the average error rate, which isn't state of the art like deepmind or Bpl, but it does make for a good baseline demo of one shot. Learning one shot. Learning will only get more popular over time. Bunch of cooling's down below. Check them out and please subscribe for more videos. For now, I've got to go fix an index out of bounds there, so thanks for watching.