Speaker 1:          00:04          Oh

Speaker 2:          00:05          world. It's to Raj. In this episode, we're going to build an image classifier using tensorflow in 30 lines of python, and I don't mean a classifier that can detect handwritten digits or iris flowers. I'm talking literally anything you want, you'll be able to train this thing to classify chocolate if you want it.

Speaker 1:          00:20          Hmm.

Speaker 2:          00:24          The possibilities are endless. There's so many industries that can be disrupted by just this simple solution. A Japanese cucumber farmer built a machine to detect whether each of his cucumbers was one of nine different types. Using this thing.

Speaker 2:          00:40          Let's say we want to build a Saroj classifier. If we think about this problem in the traditional programming paradigm, we want to handcraft a bunch of features. Maybe we could do some edge detection to save the shape of my hair or use a color histogram to save the color of my teeth. The problem with that is there's so much variance in Serrano's. My hair is alive. Seriously, it's never the same. This is where a convolutional neural networks come into play. They're essentially a black box that constructs features that we would otherwise have to handcraft and these abstract features they create from training are so generalized that the account for variants, if we want it to train a CNN ourselves, we need a lot of computing power and a lot of time, both of which we don't have. I don't even have time to do my dishes, sorry, roommates.

Speaker 2:          01:21          That's why we'll want to use a pretrained CNN model called inception. Inception was trained by Google on a hundred k images with a thousand categories. Our use case. In this video, we'll be classifying Darth Vader pictures, but in sexual wasn't trained on Bader, so we're going to perform a process called transfer learning. That means applying the learnings from a previous training session to a new training session. If we look at the inception model, we can see that when we feed in an image as an input at each layer, it will perform a series of operations on the data until it output to label and classification percentage. Each layer is a different set of abstractions. In the first layers. It's basically taught itself edge detection, then shaped detection in the middle layers and to get increasingly more abstract up until the end. If we look at the last few layers, these are the highest level detectors for whole objects for transfer learning.

Speaker 2:          02:04          Well basically just want to retrain that last layer on features of Darth Vader so it can add a representation of him to its repository of knowledge. So this is going to be a seven step process and we're going to go through each step in order. Sound good? Step one is to install docker, which is a tool for creating a virtual container on your machine for running apps. The benefit of docker is you don't have to install any dependencies on your machine. So we'll eventually download a docker image that has all the necessary dependencies per tensor flow builtin. Just download a docker toolbox, go through the installation process, and then you can launch your docker container anytime easily by double clicking the docker quickstar terminal. Cool. Now that we have docker open, that brings us to step to installing the tensorflow docker image by pacing in this line.

Speaker 2:          02:44          It'll take a few minutes and once it's installed we'll move on to step three. Downloading our image data set to our local machine will stop docker with Control d and create a directory called Kia file slash star wars and our home directory. Locally we want to put a folder labeled Darth Vader that contains a couple hundred Bader pics. In here. There's this dope chrome extension I found called [inaudible] batch download image that bulk downloads all the images from your Google image search results. Just go to Google image search, type in Darth Vader and started downloading all of those images. Once we've got them, we'll just drag that folder into our TF file slash star wars folder. That brings us to step four. Now that we have our images in our TF file directory, but wanted to link them to our docker container with this command boom all linked up. Step five is to download the training script to via get to CD into the tensorflow directory, then run get pull.

Speaker 2:          03:30          This code will allow us to retrain the inception classifier with our newly linked Darth Vader image Dataset. Step six is the actual retraining part. The bottleneck directory will be used to cash the outputs of the lower layers on disk so they don't have to repeatedly be recalculated. We'll run this example for 500 iterations. The next flag asked where to store our training model, our apple craft, which we can later view intenser board our output labels, which will be that same as our training data folder name and the image directory where we stored our Bader images. Let's go ahead and run the script right from terminal will take about 30 minutes or so to train our classifier, so do something productive.

Speaker 2:          04:06          The should output a training accuracy somewhere between 85 and 99% when it's done, and this brings us to our final step, we want to write a script that we'll use our new retrained classifier to detective. A novel image contains Darth Vader. We'll write this script ourselves. First thing's first, we'll import tensorflow. Then we'll want to create a variable to store the user input image path. We'll create another variable to store the data from that image and one more to local. Label up that image from the label file. Next want to grab our model from the saved retrained graph file, store it in the graph death variable and parts it. Now that we have our image and model ready, it's time to make our prediction by feeding the image data into our retrained model to get our prediction output. In order to do this, we'll create a tensor flow session.

Speaker 2:          04:44          This will give us an environment to perform operations on our tents or data in. The first thing we'll do in a session is get our softmax function tensor from the last layer of our model. The softmax function is used in the final layer to map input data into probabilities of an expected output. We will execute our soft Max tensor function on our input image data be in a session run function. It will output our predictions as an array well next one to sort our prediction labels in order of confidence. And lastly, for every prediction we have, we can get the predicted label and the score and printed out to terminal. Let's take the script and run it on one of our Vader pictures. The result is pretty good tensorflow. It makes it much easier to classify an image. And I've got a challenge for you guys on this episode.

Speaker 2:          05:20          The challenge is to create a classifier that you think would be a useful tool for scientists to have. It can be any field of science you'd like upload your code to get hub. And in the read me write up a few sentences on how a scientist would use this poster repository in the comment section and I'll judge them based on utility and accuracy. The winner gets a shout out for me to videos from now. So in two weeks, and I'll also send you a free signed copy of my book decentralized applications. For now, I've got to go not by the iPhone seven so thanks for watching.