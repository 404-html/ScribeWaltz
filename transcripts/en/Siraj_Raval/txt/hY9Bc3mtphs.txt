Speaker 1:          00:00          Hello world. It's the Raj and drug discovery. That's the topic of this video. As part of the AI for business series. In this video, we're going to use AI to help solve the problem of drug discovery. What specifically I'm talking about is the process of finding new drugs for diseases, right? This is what researchers in biomedicine, dude, this is their full time job, right? And when I say diseases, we're talking about cancer, aids, uh, Alzheimer's. All of these major, major diseases out there that have to go through the medical pipeline, right? The clinical trial pipeline to go from research to production where these drugs are being sent out to pee real people for use. How do we do that? Right now, that pipeline takes about 12 years. That's a very long time, right? In Ai, we just published papers just left and right, right. The field is moving like this, but when it comes to biomedicine, it's a very slow process.

Speaker 1:          00:55          So we're going to learn in this video how to solve the problem of drug discovery using Ai. Specifically. The model we're going to look at is a generative adversarial network. I'll talk about how all that works. But first I want to start off with this very cool tool that was built in python. Okay? This is a tool built with python in the flask web framework. And what it does, it's a great tool if you want to try to tackle this problem. What it does is it lists out a bunch of different drugs, right? These are the molecular compounds that all of these chemicals consist of. And what we can do is we can see in this three d graph what all of these features, each of these acts, ccs are features for these drugs. And on the left you'll see the, the molecule for that drug show up, right?

Speaker 1:          01:39          Quotes, Epam, uh, tiotropium, uh, et cetera. Silicide son Tio Broma, Theo borrow mine. I'm going to, I'm going to mispronounce a lot of these, but right? So we could do that. That's one way we could visualize these molecules. And another way is for us to just type them into this dropdown, right? There's, there's a bunch, there are so many here, Dan, Dan Tro. Dantrolene right? And so we could, we could see these down here, the ones that we select, Indy dropdown, each of these chemicals, right? Each of these molecules has an associated data sheet that lists all of its features, right? There's a whole taxonomy and entire literature around how to classify these drugs into different groups, the types of drugs, their description, their chemical structure, synonyms for them, what do they consist of, what are their ingredients, and what prescription products they're in right now and how do they get into the bodies of real people, right?

Speaker 1:          02:33          So drug bank has an amazing, amazing list of these things and the, and the best way to access that, I think is through this drug explorer plot. You'll find a link to it in the video description, by the way. So I just want to start off with that as a supplementary tool. Eventually, the code we're going to look at in this video that's helping to solve this problem is a model called Chem Gan. Okay, so chemical generative adversarial network. It's off of a recent paper from last year. And these researchers applied generative adversarial networks to the problem of drug discovery, right? So it's a, it's a very, it's a very, uh, recent application of AI and we're going to get there, right? So the first thing I have here is an image of a disease and then candidates for the, for that drug, right? These are possible drugs that could cure the disease, possibly.

Speaker 1:          03:20          And then we have this label here that says discriminator. And the idea here is that we're using, again, we're going to call it Gan Gan from now on for short, again, can be used to solve this problem. The question is how, right? That's, that's the question of the video. But before we get there, we got to talk about how drugs are discovered. Right now we can't just, we can't just flip up the process without trying to, uh, you know, see what the process is, right? We can't disrupt to, to get technical. So how were these drugs discovered? Right? Right now, it's going to take anywhere from 6.5 to 12 to 15 years to get these drugs to the market, right? There's this entire pipeline. You can see here I've drug discovery, pre clinical trials, clinical trials, and then the all uh, all powerful FDA review. And then finally you get an FDA approved drug if you're in the u s different countries have different regulations around this.

Speaker 1:          04:11          So keep that in mind. So also, 90% of all, I thought this was a very interesting statistic, 90% of all chronic clinical trials in humans fail even after the molecules have been successfully to test it in animals, which is a, it's a, it's a huge number and there's a huge room for improvement there. So how does this process work? Let's just get down into it. So the first step, right? If you are a researcher in this field, you studied biomedicine, you went through your undergraduate degree, you did your graduate degree, you did your post doc and you're ready. You have studied 12 years to get to this point. By the way, I want to make one more. I want to make one more short note here. Machine learning and AI technologies are the great democratizer of our time. What I mean is, here's what I mean, that normally it would take you 12 years to get to the point where you can make a valid contribution to this field and only those researchers could make drug discoveries.

Speaker 1:          05:07          When I say democratization, I'm not just talking about special powers like classifying images and detecting a credit card fraud, and this was only limited to fraud specialists. Now anybody who understands machine learning can do it. Anybody in the future who understands machine learning, we'll be able to do literally anything as these models improve. So what I'm saying is if you're, if you haven't done 12 years in school studying to be a biomedical researcher, if you understand machine learning, you can just leap over that 12 year requirement because think of the training time for machines as a sped up version of having a human have to learn all this, right? We got, it takes us so long to learn anything, right? We got to eat food, we got to learn, we got to go to sleep, we've got to take a break, we've got to get our, you know, a special time on all this stuff.

Speaker 1:          05:55          So it's, there's a, there's a lot there and ideally we could speed all that up. And that's what machine learning is. You don't have to be a biomedical Phd. You could be some kid in Tunisia and make an incredible drug discovery using these tools. The data sets are online, they're publicly available and yeah, you got this. Basically believe in yourself. No one believes in themselves these days. People are a week. You got to believe in yourselves. Clearly. I've been watching a lot of Gary V. Oh man. Okay. I love doing this. Anyway, here we go. Step one is studying medical literature. Okay. A of this pipeline here, they have to study all the different interactions between different drugs, diseases, what, what has been done before, right? That's the initial step. That's in any kind of research what has been done before. And once they do that, they can find out what the target for the drug should be.

Speaker 1:          06:44          I, e. What proteins should this drug bind with? The next step is figuring out what all of those properties that I talked about before for the drug should be drugs, have a whole bunch of different properties and once you know what the drug is that your, that's your hypothesis. You've got to figure out what the properties of that drug should be, right? Wow. Soluble soluble, should it be, what are the specific structures for this drug? Should it treat this kind of cancer or this kind of cancer? You got to figure it out. And then step three is figuring out which molecules have those properties, right? So I know the type of drug, I know what it should be going after. Um, which molecules that exist currently have those properties, right? And Molecules are dynamic structures. They can be complex, they can consist of multiple chemicals.

Speaker 1:          07:29          It's not an easy process. So one standard, this is serious, go look this up. A standard database for drugs that you'll find publicly has over 72 million different molecules. That's a lot of different molecules complete what their formulas, some properties, et Cetera, et cetera. Does a certain molecule cure certain disease. That's the research process. Look at the space of possibility. 72 million. Don't tell me this is not a problem for machine learning. Humans aren't going to waste their time looking at 72 million different possibilities. That's just not, that's not human. It's machine learning. Okay? Step Four. Once you've got this, you, you had this basic idea of the molecule, you have to start experimenting. Now, this right now is not done in Silico. What I mean is on a computer, it's done in real life with real human or sometimes animal, uh, trials. So check this out from zero to regulatory approval to the market, eight to 12 years. That's a lot. But their ideas, these researchers called their ideas. Lead molecules are sent to the lab for experimental validation and in the lab that can test whether or not it works, right? Does it work? Does it not work? And a very small percentage of those drugs actually do work of small percentage. And we need to be, we need to be confident about what drugs will work and what drugs won't work. And right now we're not.

Speaker 1:          08:59          Eventually, ideally we can get to the point and this would speed up the entire pipeline. We're in Silico. We can decide this is the best drug for humans and just go straight to a market. We don't need to do any human clinical trial testing. We could do this in simulation. This is an open problem and someone who has the moxy or the courage to do that should just do that. I'm just saying all sorts of words today. Moxie, what is that? New York Slang? I W I lived in New York, so yeah. Anyway, the bio pharmaceutical research and development process is way, way too long. Okay. I'm just trying to drill that into both your head and my head is that it's very long and that's why there is such a room for disruption when it comes to a profitable AI startup. Anything you can do to speed up that pain point for both, for researchers, for pharmaceutical companies, for governments, for consumers, anything you can do, you can say, you know they say the best idea for a startup is one that can offer a 10 x improvement. If you could say, I can give you the results in one year instead of 10 there you go. There's your 10 x improvement.

Speaker 2:          10:05          So

Speaker 1:          10:07          check this out. Even if the goal, even if the goal is to treat cancer, there's no hope to check the entire endless variation of small molecules in the lab. 72 million is just the size of a specific database, Dah, Dah, Dah, all the way at the sounding 2 million. But the total number of molecules is estimated to be between, and this is a scientific notation, 10 to the 60th to tend to the 200th different types. That's combining all those 72 million molecules basically a lot.

Speaker 1:          10:38          So synthesizing and testing a single new molecule. Check this cell here you go in a lab make costs thousands or tens of thousands of dollars there your, there's your 10 x right there. The early guessing stage is really important and this is where machine learning can come in. We can use machine learning models to try and choose the molecules that are most likely to have the desire properties of what we think. So when you have 72 million of something, what kind of problem is it? Well, it's less of a classification problem. Which of these 72 million is the right one? Because there's 72 million, right? This is not hot dog, not hot dog. This is 72 million and it starts to becoming something more like a generation problem. What do, let's generate something from these 72 million because there's so many different classes out there. So instead of looking for that needle in the haystack, we're going to design the perfect needle.

Speaker 1:          11:35          As in we're going to design the perfect drug. So said Dr Evil Paul ha ha, we're going to design the perfect drug, right? Okay. Also, AI can be used for good. It can be used for evil. It's up to you to use it for good. All right. This is your responsibility. You are the chosen one. All right. This is like star wars where you know Obiwan was like you were the chosen one advocate. You were supposed to use the right tools of AI for solving guy. Okay, so history of ml in drug discovery. What is the history of him? What has been done here? So that's the question that I'm trying to ask. Here's this paper that used recurrent networks. Okay, I have a link to it. We're not going to go over the whole paper. We're just going to look at it a little bit. Generating focus molecule libraries for drug discovery with recurrent neural networks.

Speaker 1:          12:25          What they did was they considered this a classification problem where they had a database of drugs and whether or not they made a certain disease active or inactive, right? So in that there's a bunch of different ways that we can class this problem, right? We can say this is going to be a supervised problem. We can say this is going to be an unsupervised problem. We can say this is going to be a generative generative problem, a discriminator problem. And this case, they classified it. Metta as a classification, supervise problem with labels. So the in their drug database, they said, well we know that these certain drugs made these diseases active or inactive. So let's learn that mapping. And then given some new drug will be able to predict whether or not it would work, right? So for, for our target and what they used was a recurrent network. And the reason they use a recurrent network is because recurrent networks are really good at predicting sequences. And when we look at these drugs, the fingerprint of these drugs can be broken down into a bunch of ones and Zeros or different letters, different chemicals, right? What is a sequence of chemicals that's going to be ideal for curing this disease?

Speaker 1:          13:31          Okay? So they did that. Another effort, and I'm just going to show you this one more before we get to our, our real demo is this paper which use convolutional networks, right? So convolutional networks are good for detecting or for classifying images. They called this Adam Net, a deep convolutional network for bioactivity prediction in structure based drug discovery. So how can we flip frame this as an image classification problem, right? So if we look at this B right here, what they did was they use this network to predict the bio activity of small molecules for drug discovery applications, right? So what we can see is an image using a microscope of the bio activity of a certain drug. What are the patterns? How are these molecules moving in which direction, how are they interacting? And we can see all of that and we can classify it and we can say, well, this is how the bioactivity is and here's how it's interacting with this specific disease. Let's learn the mapping. Well, let's just keep doing that for all of these different diseases, right? And so then given a new image of a new type of drug, it can learn the mapping of always likely to solve this.

Speaker 1:          14:37          So that's what they did for that, right? They used on input layer, multiple d convolutional layers, fully connected layers and a logistic costs layer. That's just standard really when it comes to convolutional neural networks. By the way, I have an amazing video on convolutional networks. If you search convolutional networks Saroj on youtube first link, because I dominate this space on Youtube, back to generative adversarial networks. So here is our, here is our demo. Okay, so gans and I've talked about these as well, but just not in this like applicable real world use case. Gans are awesome. They were invented about two years ago by a friend of mine, Ian Goodfellow and what they are are two different neural networks and the idea is that they are adversaries, right? One network is the discriminator. The other network is the generator. Let's start with a generator. The generator job is to generate some image based on some sample data set.

Speaker 1:          15:31          Let's just say in our case it's a sample drug dataset. I'm just going to, the generation is going to generate some novel drug and say, Oh, here we go. The discriminators job is to take that output from the generator and say, is this a real drug? Is it, is it really from the database, you know, a binary input output, or is it a fake one and it'll, it'll judge it and then it'll keep going. Right? So what's happening? And they're both being updated via synth, via gradient descent, which is an optimization strategy over time. Watch my build a neural net in four minutes video to learn more about that. Also backpropagation in five minutes I have contents about every single word I'm talking about in video form. Anything you don't understand, just search Saroj and then the, the topic, the literally I am that certain I have, I have a video on everything when it comes to deep learning at this point. So,

Speaker 2:          16:21          okay.

Speaker 1:          16:21          And of tag my video as well. So you will find them.

Speaker 1:          16:25          The discriminator is learning and the generator is learning. The generator is learning to get better and better at generating images or you know, whatever drugs that look very real and the discriminator is getting better and better at detecting what's real and what's fake. So they're both getting better and better over time. It's like a mini Max game, uh, like with a Nash equilibrium to get more technical. I have a great video on gangs as well. We're not going to go into the deep, deep details here. My point is that this is, I had a high level how it works. We'll get into the code at the end. And what they did was these researchers for Chem Gan, uh, they applied this to generate new drugs.

Speaker 2:          17:02          Okay.

Speaker 1:          17:03          Right? So I didn't, I'm just, I'm just like winging it from my brain. Like how this works. Well, we've got this beautiful help her image here to add some clarification. The generator is using random noise. It, that's all it starting from as its input and then it's generating a, an output. And at first of course it's output's going to look like nothing. But because both of these, both of these networks are updated using backpropagation, the same gradient that's used to update the generator is used to update the discriminator. So that random noise, those layers that it has to go through over time, those layers are going to apply certain matrix operations to that input data such that the output is more likely to look like what the real sample data looks like.

Speaker 2:          17:47          Okay.

Speaker 1:          17:48          And the same for the discriminator. So Dan's had been used for all sorts of things from generating images of faces that look real, but they're not, they've been used for generating, um, music, all sorts of different data types. Right. So well, what about molecules? Right? What about drugs? Can we use gans to generate drugs? Well,

Speaker 2:          18:11          okay,

Speaker 1:          18:11          there's a type of Gan that we could use that the people in this paper, the researchers use called an adversarial auto encoder, right? So here's how it works. The idea is to learn to generate objects from their latent distributions, right? So with, when it comes to an auto encoder, th the, the output, their input. So you input an image and it will output that image. And you might be thinking, why, why is that useful? What's useful is not that output. It is the learned late tint representation, right? That is the compressed version of that image. It represents the same image, but in a compressed space, right? A latent space. And once we have that space, what they did was they used this light and space, the Gen generate molecules from, right? So it looks like this. So it will learn that latent love representation, which is a set of features that encode the input in such a way that afterwards, this subsequent layers can decode that object back.

Speaker 1:          19:06          So they took this conditional auto encoder and trained it to generate fingerprints. That's just the collection of drugs, of molecules using and serving desired properties as conditions. These conditions are different features that are encoded as numbers that are then applied to the input by applied, we're using some kind of matrix multiplication, right? And then eventually it's going to be able to generate drugs that look real, but they're actually fake and they're new. They're, they're novel drugs that have never been applied to any of these use cases for these diseases. And eventually we'll be able to take that drug combination and apply it in clinical trials and then people can use it and it would work. And this would speed up that whole first and second part of this process that I talked about by orders of magnitude and also also the, the deep learning community took, um, took note of this, right? So by the way, a simple screening of the database can find molecules with the fingerprints most similar to the generated ones. Yoshua Bengio, Yann Macun. These are the godfathers of deep learning. They really, really like this idea, right? So here's the, here's the most interesting part. They really liked this idea and it didn't work that well. Like it didn't really work that well because there was some tweak that was missing. So there's basically, there's a lot of opportunity in this space. Okay, so check this out. Chem Gan. Let's take a look at this in the model.

Speaker 2:          20:29          Yeah.

Speaker 1:          20:29          What do they got here? They got Ogun Dot Pie.

Speaker 1:          20:33          Again, the pie. So here's the, here's one of their mall. They had several models, but we're going to look at a few of them. Okay. So they've got hyper parameters for both the generator. Okay. We've got a number of hidden dimensions. They've got hyper parameters for the discriminator. By the way, you can download all of these models from get hub in the read me, they have instructions on how to install, how to run them and you can run them just like that. If not, if you don't want to run them on your local machine cause you don't have a Gpu, I don't have a good one. You can use a cloud service Floyd hub. It's great. I love it. It's a layer on top of AWS that takes us, it takes away a lot of the complexity so you can very, very quickly get started.

Speaker 1:          21:09          No, they didn't pay me. I just think it's very cool. So it's like Heroku for deep learning. Great tagline by the way. Um, so the, the key here is that they're both neural networks. We can build them with care os, we can build them with tensorflow. Uh, but the idea is still the same. And both of these networks, you've got a generator or you've got a discriminator we'll train at the same time, right? So in this case, they use tensor flow to do this and they said, let's define what the discriminator looks like and we're going to train the discriminator using the samples generated right here on to 70 by the generator. We're going to feed it those samples and notice that there are two loss functions, right? There is a loss function for the generator. There's a loss function for the discriminator and they're both being trained over time, right?

Speaker 1:          21:52          Both loss functions are being trained over time. And eventually once this model is trained, they're going to save it to disk as a binary file, and they could use that model, then they could serve it. They're using tensorflow here so they can serve it using tensorflow serving, which is a great tool for serving tensorflow, tensorflow, models in the cloud, right? Tensorflow serving. This is how you serve tensorflow, models in production. You can also use tensorflow. Dot. Js. It's very simple to use Eden models trained in python. You could load up in js. It's amazing. I have a video on that. By the time you see this, that video's going to be released. The check that out I to continuous training pipeline. Okay, so there's a lot of potential here. I hope you found this video useful and uh, yeah, please subscribe for more programming videos. And for now, I'm got to use tensorflow, so thanks for watching.