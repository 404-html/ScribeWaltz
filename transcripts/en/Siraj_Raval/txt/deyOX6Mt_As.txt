Speaker 1:          00:00          That's for guests. The fake go. Um, that one, they're both real. They're balls of a world. It's a Raj. And this episode we're going to talk about generative adversarial networks. Deep learning has done a lot for us, but it's most incredible. Successes have involved discriminative models. Discriminated models are great for classification tasks. They discriminate not in that way. Obviously models like neural nets support vector machines and hidden Markov chains where we map high dimensional rich sensory input to a class label. Discriminated model doesn't care about how data was generated. It just categorizes a given signal. They're the secret sauce behind tools like facial recognition and the language translation and sentiment analysis. But there's another type of model that hasn't been as successful. The generative model, generative models are harder to get right due to the difficulty of approximating some really hard probabilistic computations. A generative algorithm does care how data was generated in order to categorize a signal.

Speaker 1:          01:00          It asks the question, which category is most likely to generate the signal? Anytime you'd like to generate some novel data based on some input data, whether that be a chatbot's replies or a song or even a short story. Generative models are the way to go. So what is a generative adversarial network organic? Well, Gans were introduced by a straight gene and Ian Goodfellow who didn't give a bite. The basic idea is this, you have two models, a generative model g that generates new data and a discriminative model d that estimates the probability that whatever sample data g shows, it came from training data rather than gee itself, they're essentially playing what's called a mini Max gain. Mini Max is a well known strategy of always minimizing the maximum possible loss, which can result from a choice that one of two players can make. So Ge has fed a bunch of training data and attempts to generate new data based on that input.

Speaker 1:          01:48          Every time g generates a new sample. D We'll try to determine if the sample is from the models distribution where the training data distribution. Think of Ge as a counterfeiter and d is the police. They're adversaries. Gee, we'll keep trying to produce fake currency and use it without detection. While deed tries to detect if it's counterfeit or not, this keeps on happening and both bottles improve their methods until eventually the counterfeits are indistinguishable from the real thing. So what type of model do we use for Dng? Well, many different types of models can be used. In the original paper. The author use something called a multilayer perceptron for both to generate photorealistic images based on a training Dataset of images. But there's an even more interesting paper that came out that you scans that I want to talk about. It came out just last month and it's called generative adversarial text to image synthesis.

Speaker 1:          02:32          These guys created again, that can generate a photo realistic image based on a caption. I am dead serious. So when it was given the caption, a large blue octopus, Chi flies above the people having fun at the beach. It was actually able to generate an image of that show. Just that, so how did it do this? Well, they use a data set of images and their associated captions as the training data. First they had to encode the data before they fed it into the models. They use an encoder, which was a hybrid neural network called a character level convolutional recurrent network. It takes both the image and the caption is input and creates a joint representation of both in multimodal space. It does this for both the generator and the discriminator. Both models are a d convolutional feedforward neural network. Once they had the encoding, they fed it into both models and each generated an image, the generator, and that creates a synthetic image from the embedding an image that is close to the real image but not quite.

Speaker 1:          03:22          The discriminator net receives three inputs. The real image with the right text, the real image with the wrong text and a fake image with the right text. It encodes each of these and compares them to what the generator shows it. Looking for a similarity between its inputs and the generators outputs. Each time step, you will try to determine if the generated image was synthetic or real by doing this comparison. After the determination has been made, the weights of both the discriminator and the generator are updated so they both get better over time. By the time training is over, the generator will be pretty good at fooling the discriminator I producing photo realistic images. They looked like they must've come straight from the training data. So let's build our own game. We're going to build a simple python script that demonstrates how gangs work. Both models will be represented by learning Gaussian distribution curves that we plot using pipeline.

Speaker 1:          04:06          Once we have our dependencies in place, well, one to define our hyper parameters. These are all different activation functions that will apply to our models. At some point. We'll also want to define how much we want to train our models as well as a number of hidden layers. We want them to have, well then write for helper functions. The first two will help us visualize our golf Sian curves. In our plot, GE builds a generative network and d bills the discriminative network. We'll initialize our networks and right applauding function to plot both curves. Finally, we'll train our network using a for loop. We'll draw samples from a uniform distribution than trained both networks at different intervals. Well, plot the graph as we train our model so we can visualize the result. Let's see what it looks like as a trains, as a trains to generate or curve will look more and more like the true data distribution curve as it tries to fool the discriminator network and there you have it.

Speaker 1:          04:53          You might be wondering what are the real world use cases for gans? Well, gaming is one. It's a daunting task to create a huge three d map manually, but with gans programmers can write a part of the map and generate the rest. Another is interior design. If a designer wants to visualize what a room will look like, they can just ask the machine for a photo of, say, a living room with Beige Sofa is facing each other and for foreign is in the scene. Pretty much anytime you need help visualizing anything, Gans can help fill in the gaps and augment your own imagination. I've got some great links for you in the description. Please subscribe for more and Mel Videos for now. I've got to go picks a deadlock, so thanks for watching.