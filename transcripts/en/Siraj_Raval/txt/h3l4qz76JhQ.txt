Speaker 1:          00:02          Hello world. Welcome this raw geology. Today we're going to be building a neural net in four minutes. Let's get started there like 1,000,001 machine learning models out there, but neural nets in particular have gotten really popular recently because of two things, faster computers and more data. They'd helped produce some amazing breakthroughs in everything from image recognition to generating rap songs. They're really just three steps involved in machine learning, build it, train it, and test it. Once we build our model, we can train it against our input and output data to make it better and better at pattern recognition. So let's build our model a three layer neural network in python. We'll want to start off by importing num Pi, which is my goto library for scientific computing in Python. Then we'll want to create a function that will map any value to a value between zero and one.

Speaker 1:          00:46          This is called a sigmoid. This function will be running every neuron of our network when data hits it. It's useful for creating probabilities out of numbers. Once we've created that, let's initialize our input Dataset as a matrix. Each row is a different training example. Each column represents a different neuron, so we have for training examples with three input neurons each. Then we'll create our output dataset for examples, one output neuron each. Since we'll be generating random numbers in a second, let's see them to make them deterministic. This just means give random numbers that are generated the same starting point or seed, so that will get the same sequence of generated numbers every time we run our program. This is useful for debugging. Next we'll create our synapse major CS synopsis or the connections between each neuron in one layer to every neuron in the next layer.

Speaker 1:          01:33          Since we'll have three layers in our network, we need to snaps matrices. Each synapse has a random weight assigned to it. After that, we'll begin the training code. We'll create a for loop that iterates over the training code to optimize a network for the given data set. We'll start off by creating our first layer. It's just our input data. Now comes the prediction step. We'll perform matrix multiplication between each layer and it's sinaps. Then we'll run our sigmoid function on all the values in the matrix to create the next layer. The next layer contains a prediction of the output data. Then we do the same thing on that layer to get our next layer, which is a more refined prediction. So now that we have a prediction of the output value and layer two, let's compare it to the expected output data using subtraction to get the error rate.

Speaker 1:          02:16          We'll also want to print out the average error rate at a set interval to make sure it goes down every time. Next, we'll multiply our error rate by the result of our sigmoid function. The function is used to get the derivative of our output prediction from layer to this will give us a Delta, which we'll use to reduce the error rate of our predictions when we update our synapses every iteration. Then we'll want to see how much layer one contributed to the error in layer two. This is called backpropagation. We'll get this error by multiplying layer two's Delta by synapse ones transpose. Then we'll get layer ones delta by multiplying its error. By the result of our sigmoid function. The function is used to get the derivative of layer one. Now that we have deltas for each of our layers, we can use them to update our sinaps waits to reduce the error rate more and every iteration. This is an algorithm called gradient descent. To do this, we'll just multiply each layer by a delta. Finally, let's print the predicted output, and there you have it. Let's run this in terminal and see what we get. Awesome. We can see that our error rate decreases every iteration and the predicted output is very, very close to the actual output. There is so much we can do to improve our neural network. For more information, check out the links in the description below and please subscribe for more technology videos. Thanks for watching.