1
00:00:00,120 --> 00:00:03,000
Hello world it Saroj and do
you gotta catch them all?

2
00:00:03,030 --> 00:00:06,750
When I say catch 'em all I'm talking
about Pokemon, I've got to catch them all,

3
00:00:06,751 --> 00:00:09,870
but I've also got to train them all.
I've got to train them all.

4
00:00:09,990 --> 00:00:12,570
You can seeing a generative
adversarial network.

5
00:00:12,750 --> 00:00:17,040
What we're going to do in this video is
we're going to generate all new Pokemon.

6
00:00:17,340 --> 00:00:18,450
You heard me correctly,

7
00:00:18,540 --> 00:00:23,540
more than the original 150 shadows to
the original 150 and the 5 billion other

8
00:00:23,731 --> 00:00:24,900
ones that came after that.

9
00:00:25,170 --> 00:00:28,530
But we're going to generate all new
Pokemon using what's called a generative

10
00:00:28,531 --> 00:00:32,340
adversarial network. Now, I've done
this in one or two videos before,

11
00:00:32,460 --> 00:00:35,760
but this is probably going to be the most
clear explanation I've ever done of it.

12
00:00:36,060 --> 00:00:40,320
It's a very popular machine
learning technique popularized
just and created just

13
00:00:40,321 --> 00:00:43,350
two years ago. And uh, this
is going to be awesome.

14
00:00:43,350 --> 00:00:48,350
So this is a demo of what I've already
generated with my Gan Gan for short.

15
00:00:48,541 --> 00:00:52,860
So we'll call them gangs from now on. And
as you can see, it looks pretty funky.

16
00:00:53,040 --> 00:00:57,000
We give it some training images of
real Pokemon. And then after training,

17
00:00:57,001 --> 00:00:59,640
using this generative
adversarial approach,

18
00:00:59,790 --> 00:01:03,540
it's going to be able to generate new
Pokemon that have never existed before.

19
00:01:03,630 --> 00:01:06,480
So let's dive right out right on into it.
At the end,

20
00:01:06,481 --> 00:01:09,720
I'm going to go into the code, but first
let's talk about what these things are.

21
00:01:10,740 --> 00:01:15,480
So there's a lot of different ways that
we can classify the learning process for

22
00:01:15,481 --> 00:01:18,060
computers, right? The
machine learning process,

23
00:01:18,180 --> 00:01:21,690
we could talk about supervised
unsupervised reinforcement learning,

24
00:01:21,900 --> 00:01:26,700
but one of the most popular ways is
discriminative and generative, right?

25
00:01:26,701 --> 00:01:29,790
So for generative models,
we are learning the probability,

26
00:01:29,791 --> 00:01:34,530
the joint probability of x and y.
For discriminative models,

27
00:01:34,650 --> 00:01:39,060
we're living the probability of y given x.
So you might be thinking,

28
00:01:39,120 --> 00:01:42,030
what does that mean? Right?
So here's what it means.

29
00:01:42,031 --> 00:01:45,510
Here's a really simple example
that I found off of stack overflow.

30
00:01:45,720 --> 00:01:48,220
So let's say this is our
training data, right? The,

31
00:01:48,390 --> 00:01:53,100
it's just a four x y value pairs,
right? X, Y, x, y, x, y, x,

32
00:01:53,101 --> 00:01:56,150
Y, and they're all integers. And so the,

33
00:01:56,151 --> 00:02:00,750
the joint probability that
has a probability of x
and y is going to be these

34
00:02:00,751 --> 00:02:03,050
four values. Okay? And
then the probe bill,

35
00:02:03,240 --> 00:02:08,240
the the probability of y given x
is going to be these four values.

36
00:02:08,400 --> 00:02:11,760
So take a second to kind of just stare
at this and eventually you're going to

37
00:02:11,761 --> 00:02:13,050
get it.
But let me help explain.

38
00:02:13,440 --> 00:02:16,410
So let's say let's say y
equals zero and x equals one.

39
00:02:16,411 --> 00:02:18,090
So this top left corner here,

40
00:02:18,330 --> 00:02:22,680
what that means is what is the probability
that y is going to be zero and x is

41
00:02:22,681 --> 00:02:27,120
going to be one out of all
the possible cases. Well, if
we look up here, we'll see,

42
00:02:27,121 --> 00:02:30,750
okay, here's one case, here's
another case. These two are not.

43
00:02:30,810 --> 00:02:32,700
So out of the four possible cases,

44
00:02:32,790 --> 00:02:36,390
two of them are cases where
x is one and wise is zero.

45
00:02:36,450 --> 00:02:39,240
So that's two out of four or one half.

46
00:02:39,390 --> 00:02:42,710
And so that's how it works for
the joint probability for the,

47
00:02:42,870 --> 00:02:46,500
for the probability of y given x,
it's if,

48
00:02:46,980 --> 00:02:51,060
if x is going to be one,
how many times is why going to be zero?

49
00:02:51,180 --> 00:02:54,060
So here's x equals one.
So why zero?

50
00:02:54,090 --> 00:02:56,730
Here's x equals one y zero and
those are the only two times.

51
00:02:56,760 --> 00:02:59,040
So out of all those times
it's going to be zero.

52
00:02:59,110 --> 00:03:01,210
So that's a hundred percent probability,
right?

53
00:03:01,330 --> 00:03:04,600
So what's the probability that you're
going to get zero given every time that x

54
00:03:04,601 --> 00:03:08,230
equals one? Right? So that's the
difference between both of those.

55
00:03:08,380 --> 00:03:12,250
It still doesn't explain the difference,
but that's the mathematical explanation.

56
00:03:13,540 --> 00:03:18,340
So the idea behind generative models
is that we are trying to create these

57
00:03:18,580 --> 00:03:23,110
systems that generate new data
given some training Dataset, right?

58
00:03:23,111 --> 00:03:27,310
So the pros of this are that we have
knowledge about the data distribution.

59
00:03:27,311 --> 00:03:30,640
What that means is any kind of
training data that you have,

60
00:03:30,700 --> 00:03:35,170
any kind of training data,
we can represent all of it
as some distribution, right?

61
00:03:35,171 --> 00:03:38,920
Some curve,
either a Gaussian or a multinomial,

62
00:03:39,010 --> 00:03:42,190
all sorts of distribution and
what a distribution is. It is,

63
00:03:42,220 --> 00:03:44,290
it is a range of possibilities,
right?

64
00:03:44,440 --> 00:03:47,320
It is a range of possibilities
of what some data could be.

65
00:03:47,620 --> 00:03:51,070
And if we learn what that distribution is,
then we can say,

66
00:03:51,071 --> 00:03:55,390
let's take some point on that distribution
and generate some data from it.

67
00:03:55,570 --> 00:03:57,470
What that means is that point,

68
00:03:57,471 --> 00:04:00,310
it doesn't necessarily have to
come from our training Dataset,

69
00:04:00,400 --> 00:04:03,580
but it's a part of the range
of possibilities and thus it,

70
00:04:03,590 --> 00:04:05,350
it can be a novel data point,

71
00:04:05,500 --> 00:04:10,210
meaning a new type of data that looks or
feels very similar to the original data.

72
00:04:10,450 --> 00:04:14,740
Basically we can generate new data if
we learn what the distribution of the

73
00:04:14,741 --> 00:04:19,690
existing data is. The cons of this is that
this is very expensive to learn, right?

74
00:04:19,691 --> 00:04:24,691
Degenerative models in general are harder
to train than discriminative models

75
00:04:25,180 --> 00:04:28,840
and we need lots of data. Discriminative
models, on the other hand,

76
00:04:28,930 --> 00:04:31,930
they don't tell you to generate anything.
They're really easy to use.

77
00:04:31,960 --> 00:04:35,950
That's the pro. The con is that all
they do is they discriminate, right?

78
00:04:35,951 --> 00:04:40,210
They classify, they differentiate.
Given this dog, given this cat,

79
00:04:40,480 --> 00:04:42,100
is this a dog?
Is this a cat?

80
00:04:42,250 --> 00:04:46,840
It tries to put labels on things that
probability of y a label given some input

81
00:04:46,870 --> 00:04:51,160
x, right? So that's why he's
the probability of y given X.

82
00:04:51,160 --> 00:04:54,490
Whereas for the joint probability
it's probability of x and y.

83
00:04:54,491 --> 00:04:56,440
So given some new x,

84
00:04:56,441 --> 00:05:00,940
we can generate a why or given some new
why we can generate an x at the same

85
00:05:00,941 --> 00:05:04,780
time. Right? So that's a difference.

86
00:05:04,840 --> 00:05:08,500
So a lot of times we talk about
discriminative models, um,

87
00:05:08,520 --> 00:05:10,100
and there are a lot of popular ones.

88
00:05:10,110 --> 00:05:12,730
So logistic regression
support vector machines,

89
00:05:13,270 --> 00:05:14,740
neural networks can be discriminative.

90
00:05:14,741 --> 00:05:17,650
That can also be generative as
we're going to see here. Uh,

91
00:05:17,740 --> 00:05:22,390
but for generative models we have naive
Bayes mixture of Gaussians Hidden Markov

92
00:05:22,391 --> 00:05:26,020
models. And if you're curious
about how any of these models work,

93
00:05:26,200 --> 00:05:30,340
I would point you to my math of
intelligence playlist. I have videos,

94
00:05:30,460 --> 00:05:33,520
detailed videos on every single one
of these that you're seeing here.

95
00:05:33,670 --> 00:05:35,650
They're all in my math of
intelligence playlists.

96
00:05:35,740 --> 00:05:39,700
So take some coffee and just go through
that whole playlist if you want to learn

97
00:05:39,850 --> 00:05:41,230
how all these models work.

98
00:05:41,380 --> 00:05:45,400
But my idea right now is to just show
you that there are two types of machine

99
00:05:45,401 --> 00:05:49,450
learning models that we can,
we can, uh, think about, right?

100
00:05:49,450 --> 00:05:52,300
So again,
discriminative models,

101
00:05:52,330 --> 00:05:56,980
probability of y given x and generative
models or the probability of x and y.

102
00:05:57,020 --> 00:05:59,960
And we can use Bayes theorem
to derive that as well.

103
00:06:01,190 --> 00:06:04,640
Discriminative models learned the
boundaries between different classes.

104
00:06:04,760 --> 00:06:07,820
If it learns the boundary, then giving
some new data point, we can say, oh,

105
00:06:07,850 --> 00:06:11,180
it's on the left side. It must be a
dog, or it's, it's on the right side,

106
00:06:11,181 --> 00:06:12,020
it must be a cat.

107
00:06:12,230 --> 00:06:15,530
Whereas generative models learning the
distribution of the clashes and then once

108
00:06:15,531 --> 00:06:19,940
we have that distribution, we can say,
boom, generate this, generate this,

109
00:06:19,941 --> 00:06:22,610
generate this. Okay, so
that's kind of how it works.

110
00:06:22,730 --> 00:06:27,730
So one class of generative models is
the generative adversarial network.

111
00:06:28,460 --> 00:06:32,900
Okay. So the generative
adversarial network at a high
level looks just like this.

112
00:06:33,050 --> 00:06:34,640
Ignore the detective part for now.

113
00:06:35,000 --> 00:06:39,140
But what happens is we have
to neural networks. By the
way, I met Ian Goodfellow,

114
00:06:39,141 --> 00:06:43,190
the Creator, I interviewed him. If
you're curious, just search Saroj.

115
00:06:43,400 --> 00:06:47,960
Ian Goodfellow on Youtube.
Great interview. Anyway,

116
00:06:48,410 --> 00:06:49,820
we have two neural networks here.

117
00:06:49,850 --> 00:06:53,780
We have a generator network and we have
a discriminator network and our job is

118
00:06:53,781 --> 00:06:55,190
going to be this,
right?

119
00:06:55,760 --> 00:06:59,090
We input some random noise
into the generator network.

120
00:06:59,091 --> 00:07:02,810
That is some random group of numbers
of vector and we're going to feed it to

121
00:07:02,811 --> 00:07:05,030
this neural network,
this generator network.

122
00:07:05,240 --> 00:07:08,560
It's job is to take that input
and do it all known. That works.

123
00:07:08,561 --> 00:07:11,990
Do you apply a series of matrix
multiplication to that input?

124
00:07:12,230 --> 00:07:16,130
Until we have an output and that output,
we're going to consider a fake image.

125
00:07:16,430 --> 00:07:20,300
Now the discriminator is gonna say is
only going to look at the real training

126
00:07:20,301 --> 00:07:22,100
dataset that we have.
That is the real,

127
00:07:22,130 --> 00:07:25,310
that are the real images and
once we have these real images,

128
00:07:25,430 --> 00:07:28,850
we'll feed those into the discriminator
network and it's going to output a

129
00:07:28,851 --> 00:07:29,900
probability label,

130
00:07:29,901 --> 00:07:34,640
whether it's real or it's fake because
the discriminator takes two inputs.

131
00:07:34,790 --> 00:07:38,330
It's going to take the real image and
it's going to take the generated fake

132
00:07:38,331 --> 00:07:43,100
image and its job is to say is the
fake image real or fake? Right?

133
00:07:43,250 --> 00:07:46,190
And at first it's going to say,
obviously this is fake.

134
00:07:46,340 --> 00:07:49,730
You just took some random noise
vector and generated an image from it.

135
00:07:49,970 --> 00:07:53,030
It had nothing to do with the
training data. Of course it's fake.

136
00:07:53,330 --> 00:07:55,970
And then what's going to happen
is when it makes that prediction,

137
00:07:56,180 --> 00:07:59,540
we're going to compute an error value
like always. And then what do we do?

138
00:07:59,570 --> 00:08:02,420
We optimize moving forward
and when we optimize,

139
00:08:02,450 --> 00:08:05,120
we are optimizing to minimize
a loss function, right?

140
00:08:05,360 --> 00:08:07,070
And when we minimize a loss function,

141
00:08:07,160 --> 00:08:10,910
we're using a strategy like gradient
descent, right? With gradient descent,

142
00:08:10,911 --> 00:08:14,810
we can compute a great value to
update the weights of both networks,

143
00:08:14,811 --> 00:08:18,320
both the discriminator network
and the generator network.

144
00:08:18,350 --> 00:08:22,160
What that means is they both get
better over time. And what that means,

145
00:08:22,190 --> 00:08:25,340
what that really means is that because
they get both get better over time,

146
00:08:25,610 --> 00:08:30,610
the generator is getting
better at generating very
realistic looking data until

147
00:08:31,131 --> 00:08:34,070
the discriminator cannot decide
what's real and what's fake.

148
00:08:34,280 --> 00:08:37,550
And that's when the generator
has done its job well. Right?

149
00:08:37,551 --> 00:08:41,600
So one way to think about this is that
the discriminator is a detective is

150
00:08:41,601 --> 00:08:44,990
trying to figure out what's
real and what's fake. And
the generator is a forger.

151
00:08:45,020 --> 00:08:48,860
It's trying to say, hey, this is a real
copy of the Mona Lisa, but it's not.

152
00:08:49,070 --> 00:08:52,970
It's a fake copy of the Mona Lisa
and it's just using random noise,

153
00:08:52,971 --> 00:08:57,390
random numbers generated as its input.
And as a tweets are updated,

154
00:08:57,540 --> 00:08:59,010
it's getting better and better at this.

155
00:08:59,011 --> 00:09:04,011
Over time we can think of
the discriminator as a binary
classifier real or fake

156
00:09:05,070 --> 00:09:09,110
one or zero. And, and the way
we can do this is because we,

157
00:09:09,170 --> 00:09:12,990
we ourselves, we as programmers
know what's real and what's fake.

158
00:09:13,110 --> 00:09:16,950
So we can assign those labels
and because we can assign labels,

159
00:09:17,070 --> 00:09:20,940
it's a supervised problem.
And because it's a supervised problem,

160
00:09:21,090 --> 00:09:24,340
what is a technique that we
use? Here we go. Go for it.

161
00:09:24,360 --> 00:09:29,160
Say back propagation, right?
That's how we update our gradients.

162
00:09:29,161 --> 00:09:32,580
We use backpropagation and notice
because we have two networks,

163
00:09:32,581 --> 00:09:33,930
we have two networks.

164
00:09:34,380 --> 00:09:39,360
We are going to be back propagating
gradients for two different networks.

165
00:09:39,610 --> 00:09:44,130
That means we have two
different optimization problems
running simultaneously.

166
00:09:44,310 --> 00:09:46,500
So the model's played two distinct,

167
00:09:46,680 --> 00:09:50,310
literally adversarial roles
because they are our adversaries.

168
00:09:50,490 --> 00:09:54,480
One is trying to fool the other constantly
and the other is trying to not be

169
00:09:54,481 --> 00:09:57,870
fooled. Right? And because we are
using this optimization technique,

170
00:09:58,020 --> 00:10:02,610
they're both getting better and better
over time. So you might be thinking,

171
00:10:02,790 --> 00:10:06,840
okay, this sounds really complicated.
I don't know what this looks like,

172
00:10:07,020 --> 00:10:09,810
but let me tell you this.
There are really only four components.

173
00:10:09,811 --> 00:10:10,621
I know I put five,

174
00:10:10,621 --> 00:10:14,670
but they're really only four components
that think about here you have are the

175
00:10:14,671 --> 00:10:19,140
genuine Dataset, whatever that is,
images, videos, whatever that data set is,

176
00:10:19,410 --> 00:10:22,710
and then you have eye, which is the
random noise vector, which is trying to,

177
00:10:22,740 --> 00:10:26,400
which is the kind of starting point that
the generator uses to generate anything.

178
00:10:26,790 --> 00:10:29,790
You have g the generator and you
have d the discriminator, right?

179
00:10:29,820 --> 00:10:33,060
You know how to build a neural network.
I made a million videos on that.

180
00:10:33,330 --> 00:10:36,990
So you just build two neural networks
and then you have some training Dataset,

181
00:10:37,140 --> 00:10:40,350
you have a loss function and you go,
that's a generative adversarial network.

182
00:10:40,351 --> 00:10:44,370
The end. No, I'm just kidding. There's
more to it than that. There's more to it.

183
00:10:44,371 --> 00:10:45,204
And I'm going to show you,

184
00:10:45,360 --> 00:10:47,910
but first let's talk about the
use cases of this thing, right?

185
00:10:48,000 --> 00:10:52,950
So obviously a generating Pokemon
is a great use case. By the way,

186
00:10:53,280 --> 00:10:56,090
please,
let's just chill with the M and I s.

187
00:10:56,091 --> 00:10:59,880
T I know everybody uses them
and ist as the baseline,

188
00:11:00,000 --> 00:11:03,450
but can we just start using
Pokemon as the new M and ist?

189
00:11:03,570 --> 00:11:05,730
I'm just saying it right now.
Let me drop this right now.

190
00:11:06,030 --> 00:11:09,720
Let's start using Pokemon please.
As the baseline,

191
00:11:09,780 --> 00:11:14,780
the original 150 as the new baseline for
generative models instead of m and ist

192
00:11:15,690 --> 00:11:19,020
because as awesome as young
raccoon is, the guy who, you know,

193
00:11:19,021 --> 00:11:23,160
the godfather of convolutional nets and
his, you know, Dataset m and ISD is,

194
00:11:23,340 --> 00:11:26,130
it's just time to move on to
just to keep things interesting.

195
00:11:26,160 --> 00:11:28,770
I've made a million
videos about him and ist.

196
00:11:28,770 --> 00:11:31,440
I'm not going to rant about it
too much. Anyway, back to this,

197
00:11:31,680 --> 00:11:34,680
we can do so many things with gans.
For example,

198
00:11:35,400 --> 00:11:37,950
we can turn black and white
images to color. We can,

199
00:11:38,040 --> 00:11:41,490
we can turn maps into a digital maps.

200
00:11:41,610 --> 00:11:43,230
We can say we can turn day tonight.

201
00:11:43,410 --> 00:11:47,220
You can make a drawing of a purse and
then turn it into a real purse. Right?

202
00:11:47,510 --> 00:11:52,500
But to get really trippy, you can feed
it a, a plain text, plain English input,

203
00:11:52,650 --> 00:11:56,170
like the flour is white and pink in
color with pedals that have veins.

204
00:11:56,500 --> 00:11:59,020
And then it's going to
generate images from that text.

205
00:11:59,440 --> 00:12:03,700
Extrapolate for a second here. What that
means is as these things get better,

206
00:12:03,910 --> 00:12:08,020
we can feed them, not just texts of,
you know, pretty little flower images.

207
00:12:08,230 --> 00:12:11,920
We can say, design me a rocket,
design me, forget a rocket.

208
00:12:12,130 --> 00:12:15,970
Design me the particle
accelerator from Cern, you know,

209
00:12:15,971 --> 00:12:20,020
that $50 billion machine under
Geneva designed that for me.

210
00:12:20,080 --> 00:12:22,720
Here are all the specs.
Here's all the data go.

211
00:12:22,990 --> 00:12:27,990
What that means is the cost of the barrier
to entry to a million things becomes

212
00:12:28,001 --> 00:12:32,200
possible. Design, you know,
anything, a living group design,

213
00:12:33,160 --> 00:12:36,580
clearly there's a lot of possibilities
for design and engineering, right?

214
00:12:36,581 --> 00:12:39,910
Three d modeling. But it's not
just that, it's also for science.

215
00:12:40,090 --> 00:12:43,750
So these researchers that in
Silico medicine said, let's, uh,

216
00:12:43,780 --> 00:12:47,830
let's generate a new drug
using, uh, using Gantz.

217
00:12:47,950 --> 00:12:51,520
So the goal was to train the generator
to sample drug candidates for given

218
00:12:51,521 --> 00:12:56,521
disease as precisely as possible to
existing drugs from a drug database.

219
00:12:56,620 --> 00:12:59,110
Right?
And so what happens is after training,

220
00:12:59,111 --> 00:13:03,850
it was possible for them to generate a
drug for a previously incurable disease

221
00:13:04,060 --> 00:13:08,200
using the generator and
using the discriminator to
determine whether the sample

222
00:13:08,201 --> 00:13:10,600
drug actually cures the given disease.

223
00:13:10,780 --> 00:13:13,570
So there are a lot of use cases for this,

224
00:13:14,650 --> 00:13:16,960
and it's not just that there
are a lot of use cases,

225
00:13:17,170 --> 00:13:20,620
there are a lot of gans fantastic
gans and where to find them.

226
00:13:20,620 --> 00:13:22,150
That's a great blog post by the way.

227
00:13:22,450 --> 00:13:25,930
There are so many different types
of gangs out there, seriously,

228
00:13:26,200 --> 00:13:30,760
but one huge improvement to the
initial Gann paper in 2014 is the deep

229
00:13:30,761 --> 00:13:35,530
convolutional Gan or DC Gan. And so
the, the, the main difference here,

230
00:13:35,620 --> 00:13:39,590
the main main difference is that instead
of using feedforward networks as both

231
00:13:39,591 --> 00:13:41,650
the generator ended discriminator,

232
00:13:41,920 --> 00:13:46,920
they used a convolutional network as the
generator and a d convolutional network

233
00:13:46,990 --> 00:13:50,110
as the discriminator. So that's just
a convolutional network flipped.

234
00:13:50,590 --> 00:13:54,130
And what happened is they made
a few important discoveries.

235
00:13:54,280 --> 00:13:59,080
One important discovery was batch
normalization is a must for both networks.

236
00:13:59,380 --> 00:14:04,180
Fully kind of fully hidden, connected
layers. Not a good idea. Avoid pooling.

237
00:14:04,181 --> 00:14:06,790
Simply stride. You're
convolutions. So again,

238
00:14:06,820 --> 00:14:10,000
pooling recall from my video
about capsule networks.

239
00:14:10,120 --> 00:14:12,640
Hinton the godfather of
neural networks themselves.

240
00:14:12,790 --> 00:14:15,220
He's also skeptical of pooling.
In fact,

241
00:14:15,250 --> 00:14:17,560
he replaced it with that capsule strategy.

242
00:14:17,710 --> 00:14:20,290
So here's a great research idea for you.

243
00:14:21,250 --> 00:14:25,210
Apply capital networks to generative
adversarial networks. Boom, take it,

244
00:14:25,211 --> 00:14:27,490
run with that. Be the
first to do that. Okay.

245
00:14:27,520 --> 00:14:31,180
Capsule generative adversarial networks.
Paper of the year award right there.

246
00:14:31,420 --> 00:14:34,540
Paper of the year award. Uh, right.

247
00:14:34,541 --> 00:14:37,600
So relu activations are your
friend almost always. Why?

248
00:14:37,720 --> 00:14:42,370
Because it prevents the vanishing gradient
problem. Exactly. If you didn't say it,

249
00:14:42,371 --> 00:14:45,070
that's okay.
Vanilla Gans can work on simple data sets,

250
00:14:45,071 --> 00:14:49,030
but DC gans are far better. And if you
have some new state of the art algorithm,

251
00:14:49,320 --> 00:14:53,830
compare it with the baseline
of using a DC Gan. Another one,

252
00:14:53,840 --> 00:14:57,200
conditional gans. Now these are
really interesting because notice,

253
00:14:57,230 --> 00:14:59,840
remember that image I showed you where
it said, here's a flower with petals.

254
00:14:59,841 --> 00:15:03,320
It's white. It's pretty generated. They
use the conditional again to do that.

255
00:15:03,321 --> 00:15:08,321
What that means is what we're feeding
into the generator is not just some noise.

256
00:15:09,170 --> 00:15:14,170
We're also feeding in these strings
were were conditioning the data on these

257
00:15:14,271 --> 00:15:18,800
extra strings like male, black
hair, blonde makeup, whatever.

258
00:15:19,100 --> 00:15:21,830
And we're also conditioning the
discriminator on this as well.

259
00:15:22,040 --> 00:15:25,490
And what happens is we are
feeding both as vectors, right?

260
00:15:25,491 --> 00:15:28,310
So we're converting those strings
into numbers vectorizing them,

261
00:15:28,490 --> 00:15:30,680
we're converting the noise,
two vectors.

262
00:15:30,770 --> 00:15:34,160
We're concatenating both vectors and
feeding that in his input into the

263
00:15:34,161 --> 00:15:37,430
generator as well as a discriminator.
And when we back propagate,

264
00:15:37,600 --> 00:15:38,810
when we update our weights,

265
00:15:39,080 --> 00:15:43,220
the networks are going to be more suited
to generate data or discriminate data

266
00:15:43,280 --> 00:15:46,330
that is conditioned on those
strings because there's a,

267
00:15:46,390 --> 00:15:51,390
there's an association between those
strings and the training images because we

268
00:15:51,531 --> 00:15:52,670
have to pre label them,
right?

269
00:15:52,671 --> 00:15:56,750
We have to pre labeled the images with
these strengths and because it's learning,

270
00:15:56,910 --> 00:16:00,320
uh, to generate and discriminate
conditioned on these strings,

271
00:16:00,590 --> 00:16:04,730
we can input these strings as,
as the sole input after training.

272
00:16:04,940 --> 00:16:08,030
And then there's going to be able to
generate images like wipe pretty flower or

273
00:16:08,031 --> 00:16:12,740
whatever, which is very cool. Uh, lastly,

274
00:16:12,741 --> 00:16:14,690
there's one more type of Gan of the many,

275
00:16:14,691 --> 00:16:18,710
many guns out there that I want to talk
about. That is a very important, again,

276
00:16:18,711 --> 00:16:21,530
it's called the
Wasserstein or Wasserstein,

277
00:16:21,531 --> 00:16:25,170
however you want to say Gan
or w again and the, the dif,

278
00:16:25,230 --> 00:16:30,230
the real discovery of w Ganz was that if
you've ever tried to train again before

279
00:16:30,650 --> 00:16:35,540
and you should after this video, if you
haven't, do it, do it. If you haven't,

280
00:16:35,600 --> 00:16:39,440
it'll be great. You'll learn
a lot. Trust me. Uh, the,

281
00:16:39,650 --> 00:16:44,030
the great thing about [inaudible] is
that it improved the, the loss function.

282
00:16:44,031 --> 00:16:48,020
So if you look at a general,
again, like a generic vanilla Gan,

283
00:16:48,320 --> 00:16:50,930
this is what the loss function looks like,
or even a DC Gan.

284
00:16:51,680 --> 00:16:54,440
How do you know when to stop training?
Right? How do you know when it's,

285
00:16:54,441 --> 00:16:58,670
when it should be done? Usually this is,
this is a really ugly a loss function.

286
00:16:58,671 --> 00:17:02,870
There's, there's no idea. Uh, there's
no way to tell when to stop training.

287
00:17:02,871 --> 00:17:05,750
You just have to guess and check.
So this looks much prettier.

288
00:17:05,751 --> 00:17:07,970
Right now we know when to stop training,

289
00:17:07,971 --> 00:17:11,270
when that loss is maybe at
the 500,000 iteration mark.

290
00:17:11,420 --> 00:17:16,420
Now that loss is pretty low and everything
training afterward is going to lead

291
00:17:16,760 --> 00:17:21,560
to diminishing results.
So that's what w gans do.

292
00:17:21,561 --> 00:17:23,060
They replace the loss function,

293
00:17:23,210 --> 00:17:27,740
which is normally called the Jensen
Shannon divergence with instead the

294
00:17:27,770 --> 00:17:31,700
Wasserstein distance. They tried to
minimize the Wasserstein distance.

295
00:17:31,910 --> 00:17:34,580
So I can go into that,
but that's a lot for one video,

296
00:17:34,581 --> 00:17:38,090
but that's at a high level of
what it is, right? So that's,

297
00:17:38,120 --> 00:17:42,240
that's more of the state of the art
when it comes to Gantz. Okay. So, um,

298
00:17:42,290 --> 00:17:45,500
that's that. Now let's talk
about the code. Okay, let's,

299
00:17:45,501 --> 00:17:49,560
let's go into the code now for this
Pokemon gap. Let's take a look at it.

300
00:17:50,130 --> 00:17:55,020
So this code is about 285 lines.
So it's a lot,

301
00:17:55,021 --> 00:17:59,400
but it's not too much, right? We, we
can fit it all into a single class file.

302
00:17:59,610 --> 00:18:03,300
And I've, it's built with tensorflow.
Okay. It's built with tensorflow.

303
00:18:03,510 --> 00:18:08,490
So the training data, is this right?
These are all Pokemon images right here,

304
00:18:08,491 --> 00:18:12,240
right? We've got several Pokemon.
It's not just the original hundred 50.

305
00:18:12,360 --> 00:18:15,270
We got a lot of them.
Don't trio, whatever.

306
00:18:15,300 --> 00:18:18,720
I only know the original one 50 because
when I was a kid, that's, that's all we,

307
00:18:18,721 --> 00:18:22,860
uh, which one was this? Ticklet.
Tigger. I don't know. Anyway, no,

308
00:18:22,861 --> 00:18:27,030
I know it's not ticker. It's, I forgot
the name. Anyway, let's look at this.

309
00:18:27,031 --> 00:18:29,040
A python file. Okay.
We get ready for this.

310
00:18:29,850 --> 00:18:32,970
So we have a processing data
function that we can just skip.

311
00:18:33,060 --> 00:18:37,350
Basically what that does is
it just formats all those
images into the same size

312
00:18:37,590 --> 00:18:41,250
because we want all those images to be
the same size when we feed it into our

313
00:18:41,430 --> 00:18:44,640
networks, right? Because that's,
that's called, that's the,

314
00:18:44,670 --> 00:18:48,720
that's the vectorization process.
So we have two functions.

315
00:18:48,780 --> 00:18:51,150
Each of these functions
represents one of the networks.

316
00:18:51,330 --> 00:18:54,930
We have a generator function,
and then we have a discriminator function.

317
00:18:55,050 --> 00:18:58,800
So don't get afraid by looking at this.
This is just standard tensorflow code.

318
00:18:59,040 --> 00:19:01,950
If we wanted to, we could,
we could have used care Ross,

319
00:19:02,130 --> 00:19:04,800
and this all could have been
abstracted to 10 or 12 lines,

320
00:19:04,950 --> 00:19:08,760
but we want to be very specific about
what the details are of what this looks

321
00:19:08,761 --> 00:19:13,170
like. So remember with convolutions
convolutional networks, this,

322
00:19:13,230 --> 00:19:16,230
this Gan, by the way, is, is a w GAM.

323
00:19:16,500 --> 00:19:19,380
So what that means is it's a DC Gan.
That means today,

324
00:19:19,470 --> 00:19:22,860
convolutional and a deep convolutional
network for the generator and the

325
00:19:22,861 --> 00:19:25,890
discriminator respectively.
And for the loss function,

326
00:19:25,920 --> 00:19:30,800
it's minimizing the Wasserstein distance
and therefore that makes it a w Gan,

327
00:19:30,990 --> 00:19:33,120
right?
And so for the generator,

328
00:19:33,150 --> 00:19:35,760
we have art convolutional
network that we can see here.

329
00:19:36,090 --> 00:19:39,900
Now for convolutional networks, we
have blocks, I call them blocks, right?

330
00:19:39,901 --> 00:19:44,820
So convolution bias activation.
And then we repeat,

331
00:19:44,821 --> 00:19:48,210
that's one block convolution
bias activation repeat.

332
00:19:48,450 --> 00:19:51,480
Now a lot of times we have pooling and
that's considered in a block and we

333
00:19:51,481 --> 00:19:55,410
repeat that,
but not in this case because for DC gans,

334
00:19:55,411 --> 00:19:59,130
they found pooling was not a good thing.
So we have a convolutional layer,

335
00:19:59,280 --> 00:20:03,750
we have a bias, and then we have an
activation function, which is Relu, right?

336
00:20:03,990 --> 00:20:08,040
And then we just repeat that over and
over again. Convolution activation, bias,

337
00:20:08,041 --> 00:20:11,910
repeat convolution, convolution
bias, activation, repeat.

338
00:20:12,180 --> 00:20:16,170
And we do that for five or no,
six layers. So it's a sixth layer,

339
00:20:16,171 --> 00:20:19,800
convolutional network, and that
is our generator. And at the very,

340
00:20:19,801 --> 00:20:23,790
very end we have this 10 h function
that's going to squash the output and then

341
00:20:23,791 --> 00:20:28,230
we return the outputs of that.
Okay, so that's for the generator.

342
00:20:29,220 --> 00:20:31,700
Now for the discriminator,
we just flip it, right? It's,

343
00:20:31,701 --> 00:20:35,700
it's flipped the other way because
we are trying to discriminate,

344
00:20:35,730 --> 00:20:38,850
given an image as input.
What is the output probability,

345
00:20:38,880 --> 00:20:43,410
what that image is real or fake. So
we say convolution activation, bias,

346
00:20:43,411 --> 00:20:44,130
repeat.

347
00:20:44,130 --> 00:20:49,130
And tensorflow has these functions for
each of these operations that are apart

348
00:20:49,540 --> 00:20:53,560
of convolutional networks. Thank you
tensorflow. So then we do it again.

349
00:20:53,590 --> 00:20:58,150
Convolution activation bias, repeat
convolution activation, bias, repeat.

350
00:20:58,360 --> 00:21:02,500
And we do that for four layers, and
at the very end, at the very end,

351
00:21:04,470 --> 00:21:05,111
at the very end,

352
00:21:05,111 --> 00:21:08,860
we use a sigmoid to squash the outputs
and then return the probability values

353
00:21:08,861 --> 00:21:10,480
for real or fake.
Okay?

354
00:21:10,481 --> 00:21:14,050
So those are our functions for the both
the generator and the discriminator.

355
00:21:14,260 --> 00:21:17,620
Now in our training loop, it
looks like this. We say, okay,

356
00:21:17,800 --> 00:21:20,800
well we have placeholders
and remember intenser flow,

357
00:21:21,010 --> 00:21:24,100
we are building a computation
graph that is a graph of where,

358
00:21:24,280 --> 00:21:27,910
where data flows through, where
the tensors flow through, right?

359
00:21:27,911 --> 00:21:31,690
So a computation graph, you can think of
a neural network as a computation graph.

360
00:21:31,900 --> 00:21:33,820
You can think of a neural
network has a function, right?

361
00:21:33,821 --> 00:21:38,200
It's a glorified function. And so
it's a set up operations, right?

362
00:21:39,130 --> 00:21:41,740
So we'll create placeholders in
the placeholders are gateways,

363
00:21:41,760 --> 00:21:45,910
they're the gateways through which we
input data into the computation graph.

364
00:21:46,090 --> 00:21:48,250
So what is the type of data
that we're going to input?

365
00:21:48,400 --> 00:21:51,610
What we're going to input some
image from our training dataset.

366
00:21:51,790 --> 00:21:54,760
We're going to input some random
vector for the generator, right?

367
00:21:55,030 --> 00:21:59,620
So we need to create placeholders for
both the real image. And the random input,

368
00:21:59,830 --> 00:22:03,370
then we'll have a boolean value just
to say, should we train it or not?

369
00:22:03,400 --> 00:22:07,480
That's just for us.
Now we can say,

370
00:22:07,510 --> 00:22:11,140
take our generator and feed. It has its
parameters, the random input, right?

371
00:22:11,141 --> 00:22:13,500
So we're feeding it a
random inputs with the,

372
00:22:13,660 --> 00:22:16,810
with the random dimension of that
input, and then we're going to say, yes,

373
00:22:16,811 --> 00:22:19,630
let's train it and it's going
to output a fake image, right?

374
00:22:19,690 --> 00:22:22,210
It has nothing to do with the
training data sets, right?

375
00:22:22,390 --> 00:22:26,570
It's only going to learn
to morph, morph that, uh,

376
00:22:26,770 --> 00:22:28,180
input into,

377
00:22:28,300 --> 00:22:32,500
it's only going to learn to morph that
initial random input into something that

378
00:22:32,501 --> 00:22:35,830
looks like the training data
because of the optimization scheme,

379
00:22:36,130 --> 00:22:38,920
which is backpropagation correct?
So we're going to,

380
00:22:38,980 --> 00:22:41,980
we're going to output a fake image.
And then for the discriminator,

381
00:22:41,981 --> 00:22:45,460
we give it the real image rights and
it's going to output the real result.

382
00:22:45,610 --> 00:22:48,760
We're also going to give the discriminator
the fake image and it's going to

383
00:22:48,761 --> 00:22:51,640
output the fake results so
that the probabilities of both,

384
00:22:52,240 --> 00:22:53,530
and we're going to use those,

385
00:22:54,970 --> 00:22:58,780
the difference between the fake result
and the real result as our loss for the

386
00:22:58,781 --> 00:23:01,300
discriminator to update that.
And for our generator,

387
00:23:01,330 --> 00:23:03,520
it's going to be the fake result.
Okay?

388
00:23:03,580 --> 00:23:08,560
So remember there are two
distinct different optimization
schemes happening at

389
00:23:08,561 --> 00:23:12,250
the same time as these networks
are adversaries of each other.

390
00:23:12,700 --> 00:23:14,110
And we're going to use the,
uh,

391
00:23:14,140 --> 00:23:18,970
and we're going to use the rms prop a
optimizer for both of them to optimize

392
00:23:18,971 --> 00:23:23,510
both to rms. Prop is a type of
gradient descent. Okay? There's,

393
00:23:23,540 --> 00:23:26,860
I also have a video on all the different
types of gradient descent out there.

394
00:23:27,010 --> 00:23:29,830
It's called which activation
function should you use?

395
00:23:29,860 --> 00:23:32,530
Saroj search that on Youtube.
Okay.

396
00:23:32,531 --> 00:23:36,160
So we have two distinct optimization
schemes great into San for both of them,

397
00:23:36,310 --> 00:23:40,770
Aka backpropagation. And then we
have a bunch of, uh, you know,

398
00:23:40,771 --> 00:23:43,690
check point in restore variables,
all kind of boiler plates.

399
00:23:43,960 --> 00:23:46,340
And then let's get to the good
stuff, our training loop, right?

400
00:23:46,430 --> 00:23:49,580
So in our training loop we're going to
stay for a number of epochs and for our

401
00:23:49,581 --> 00:23:52,790
batch size that we predefined
for given number of iterations,

402
00:23:53,060 --> 00:23:57,080
let's update the discriminator and then
we'll update the generator and to update

403
00:23:57,081 --> 00:23:57,291
them.

404
00:23:57,291 --> 00:24:01,040
What we mean is that what we mean is we
have a tensor flow session and inside

405
00:24:01,041 --> 00:24:03,430
the session the graph is initialized.
We'll,

406
00:24:03,431 --> 00:24:07,820
we'll feed it both the trainer and
the loss function has, we'll feed it,

407
00:24:07,880 --> 00:24:11,530
will feed it the training noise and
the training image, right? For the,

408
00:24:11,531 --> 00:24:14,660
for the discriminator and
for the generator we're going
to feed it the training,

409
00:24:15,190 --> 00:24:17,690
the training noise for the random input.

410
00:24:18,800 --> 00:24:22,820
And so we feel when we feed both of those
in and we are, and we're also saying,

411
00:24:23,030 --> 00:24:25,730
well we know we want to
optimize both using this,

412
00:24:25,910 --> 00:24:30,910
it's going to optimize both given both
of those distinct inputs at the very end

413
00:24:30,951 --> 00:24:35,000
we can check point and save our
model every 500 epochs and that's it.

414
00:24:35,000 --> 00:24:37,820
And then I also have this testing
function here that I've commented out,

415
00:24:38,000 --> 00:24:39,470
but if you want to test it after training,

416
00:24:39,471 --> 00:24:43,130
which you should then go ahead and comment
that out and then you can start Jen,

417
00:24:43,200 --> 00:24:45,890
that's how you're going to start
generating the Pokemon after you're done

418
00:24:45,891 --> 00:24:48,590
training. So I also want to say, do not,

419
00:24:48,680 --> 00:24:52,340
do not attempt to train
this thing on your Puny Cpu,

420
00:24:52,341 --> 00:24:56,960
on your Mac book or whatever
you have. Um, I, I tried,

421
00:24:56,961 --> 00:25:01,430
it's going to take, you know, 24 to 48
hours. If you try to train on a CPU,

422
00:25:01,730 --> 00:25:05,480
use Amazon [inaudible], use
Floyd hub, use Google cloud.

423
00:25:05,630 --> 00:25:09,590
You can get free credits for this,
for a free trial, but use a GPU.

424
00:25:09,591 --> 00:25:12,380
It's a hundred x plus
times faster than the CPU.

425
00:25:12,620 --> 00:25:14,900
Deep learning is meant to be run on a GPU,

426
00:25:15,080 --> 00:25:17,180
unless of course you have a
deep learning machine, right?

427
00:25:17,450 --> 00:25:21,110
But train this thing on a GPU and
you can do it in three to five hour.

428
00:25:21,350 --> 00:25:23,870
If you like this video,
please hit the subscribe button.

429
00:25:23,871 --> 00:25:28,310
And for now I've got to go find more
gans to train. So thanks for watching.

