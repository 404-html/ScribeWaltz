1
00:00:00,070 --> 00:00:04,720
Hello world, it's Saroj. And can a
computer make better usic than you?

2
00:00:06,000 --> 00:00:08,640
Maybe it's close to doing.
So in this video,

3
00:00:08,641 --> 00:00:12,930
we're going to talk about AI to generate
music and I've got a great demo for you.

4
00:00:12,931 --> 00:00:15,510
It's using deep learning
to generate music.

5
00:00:15,511 --> 00:00:20,460
And what we can do is we can change the
genre of music by tuning these sliders.

6
00:00:20,461 --> 00:00:22,580
Let's,
let's take a little demo sample.

7
00:00:40,780 --> 00:00:41,613
All right.
All right.

8
00:00:42,210 --> 00:00:46,910
Anyway. Okay. There we go. So that's the,

9
00:00:46,950 --> 00:00:49,050
that's the demo for this video.
It's a simple web app.

10
00:00:49,051 --> 00:00:51,620
It's using a deep learning
model in the backend at to,

11
00:00:51,630 --> 00:00:56,630
to generate these sounds
that was pretrained on a
Dataset of monophonic piano

12
00:00:56,821 --> 00:00:59,170
notes. And we'll talk about
all of that, right? So we,

13
00:00:59,250 --> 00:01:03,190
we have to get to where we need to be.
That means we have to start off with, um,

14
00:01:03,480 --> 00:01:04,680
hidden Markov models,

15
00:01:04,770 --> 00:01:09,060
then moved to recurrent networks and
finally get to a generative adversarial

16
00:01:09,061 --> 00:01:09,451
networks,

17
00:01:09,451 --> 00:01:12,120
which is the demo that I'm going to
talk about at the end of this video code

18
00:01:12,121 --> 00:01:16,830
included, of course, because we love
code. If you don't code, you should code.

19
00:01:16,831 --> 00:01:20,400
All right? So anyway, so let's start
with the history. Just one little,

20
00:01:20,730 --> 00:01:24,180
one little snippet of
pre, uh, pre software.

21
00:01:24,210 --> 00:01:27,080
So before there was any
software, uh, we were,

22
00:01:27,300 --> 00:01:30,300
music is older than language and
before there was any software,

23
00:01:30,360 --> 00:01:35,280
the first automatic music
came from nature. So when
chimes, for example, or the,

24
00:01:35,520 --> 00:01:39,990
or an ancient Greek wind powered Ionian,
harp sores, Japanese water instruments,

25
00:01:39,991 --> 00:01:42,660
et Cetera, et Cetera, et
cetera. But in the 17 hundreds,

26
00:01:42,870 --> 00:01:45,780
the first automatic
music became algorithmic.

27
00:01:45,930 --> 00:01:49,470
So there was a German game that
generated short piano compositions from

28
00:01:49,471 --> 00:01:53,070
fragments, which choices made by dice.
Just want to give you a little fun little,

29
00:01:53,220 --> 00:01:56,280
you know, pre software before we get into
the good stuff, just so you know that.

30
00:01:56,281 --> 00:02:01,260
Okay, so that was then, now we're getting
into the 19 hundreds and then onto,

31
00:02:01,261 --> 00:02:04,710
onto now the Markov chain.
Very, very cool model.

32
00:02:04,740 --> 00:02:06,360
It's used in weather prediction.

33
00:02:06,510 --> 00:02:09,120
It's used and it's been
used in speech recognition.

34
00:02:09,560 --> 00:02:13,130
It's been used in a lot of fields.
It's be,

35
00:02:13,200 --> 00:02:16,800
it's been using all of the sciences
for sure. Biology, physics,

36
00:02:17,280 --> 00:02:22,020
Markov chains have been used
extensively. But anyway, um, it's,

37
00:02:22,021 --> 00:02:25,660
it's a very simple, basic idea. And I
have this little slide right here to,

38
00:02:25,670 --> 00:02:29,700
to show, uh, a little bit about Markov
chains that I'm taking from Clemson.

39
00:02:29,820 --> 00:02:33,270
But basically the
motivation is in this case,

40
00:02:33,271 --> 00:02:36,960
it's always about predicting
the next data in a sequence.

41
00:02:36,961 --> 00:02:40,770
That data could be a word, it could be
a musical note, it could be some speech,

42
00:02:40,830 --> 00:02:44,840
but it's all about predicting the next
data in a sequence. And what it is,

43
00:02:44,841 --> 00:02:45,440
is it's a,
it's,

44
00:02:45,440 --> 00:02:50,440
it's a basically a graph that shows
probabilities of going from one point to

45
00:02:50,521 --> 00:02:53,310
another and by points,
those points could be data points,

46
00:02:53,311 --> 00:02:57,600
like strings for example, right? So if
you have the word, what if I say the word,

47
00:02:57,601 --> 00:02:58,170
what?

48
00:02:58,170 --> 00:03:02,320
There's a certain that the next word will
be is there's a certain probability to,

49
00:03:02,321 --> 00:03:06,460
the next word will be the, and
based on those probabilities, this,

50
00:03:06,461 --> 00:03:11,110
the computer can traverse that graph to
maximize for the probabilities so that

51
00:03:11,111 --> 00:03:13,960
the most likely word is said or generated.

52
00:03:14,110 --> 00:03:17,410
And that's the same thing goes for music.
And these had been used, like I said,

53
00:03:17,411 --> 00:03:21,550
and whether, for example, right,
so if we have three states,
sunny, rainy, and cloudy,

54
00:03:21,760 --> 00:03:24,670
and depending on the inputs,
it could be any of those things.

55
00:03:25,090 --> 00:03:29,860
What a hidden Markov model does is it
models all of those state transition

56
00:03:29,861 --> 00:03:33,880
probabilities from sunny to, to rainy
to whatever it is, right? So let's say,

57
00:03:33,881 --> 00:03:37,840
you know, if it's rainy, then there's
a 60% chance it's going to be,

58
00:03:37,870 --> 00:03:39,100
it's going to be cloudy,
right?

59
00:03:39,490 --> 00:03:42,640
And it's going to be 60% less than it's
going to be sunny, right? So there is,

60
00:03:42,641 --> 00:03:46,750
there was some relationship between all
of these states that can be modeled as

61
00:03:46,780 --> 00:03:50,590
probability values. And that's
what, that's what it's for, right?

62
00:03:50,591 --> 00:03:53,710
And so what it comes down to is
just basic multiplication, right?

63
00:03:53,711 --> 00:03:56,980
Because when a hidden Markov model does,
is it doesn't just,

64
00:03:57,010 --> 00:03:59,860
it doesn't generate completely novel data.

65
00:04:00,190 --> 00:04:04,780
It generates data that is a subsection
of the existing data, right?

66
00:04:04,781 --> 00:04:08,980
So the best way to explain what I mean
by that is for us to look at a bit of a

67
00:04:08,981 --> 00:04:12,010
bit of code, right? So let's look at
some code. For this hidden Markov Model.

68
00:04:12,040 --> 00:04:12,820
It's right here.

69
00:04:12,820 --> 00:04:17,820
This 25 lines snippet of Python
code is a hidden Markov model.

70
00:04:18,970 --> 00:04:23,410
Okay? So in this case, we have two
words. Okay. These are strings. Um,

71
00:04:23,590 --> 00:04:26,350
what we were going to do is we're going
to create a table out of all of these

72
00:04:26,351 --> 00:04:28,840
words are, and then what we're
gonna do is we're going to say,

73
00:04:28,960 --> 00:04:31,570
let's generate some
output by learning those,

74
00:04:31,720 --> 00:04:33,820
those probability values
between those words.

75
00:04:33,821 --> 00:04:37,570
So it's a learning that the likelihood
that one word will come after another,

76
00:04:37,840 --> 00:04:40,690
and it's basically just picking
a random word from the next word.

77
00:04:40,691 --> 00:04:44,980
And we can print that out, right? So this
is a very, very simple model and it's,

78
00:04:44,981 --> 00:04:47,680
it's, it's just basic multiplication
is what it boils down to.

79
00:04:47,681 --> 00:04:50,810
Multiplication from some
existing set of data. Um,

80
00:04:50,890 --> 00:04:55,810
and then learning the
probabilities of these words.
Just one by one by one, right?

81
00:04:56,080 --> 00:04:56,913
So,
um,

82
00:04:57,820 --> 00:05:02,820
one example of an artist
that used a Markov chain to
generate music was in 1958.

83
00:05:03,101 --> 00:05:08,101
His name was Ian is Xenakis and use it
in his 1958 composition and a logic which

84
00:05:09,251 --> 00:05:12,240
we can listen to. Thanks to the
power of the Internet, right?

85
00:05:22,710 --> 00:05:26,430
Yeah. So that sounds terrible. But anyway,
uh, that was what he did. So that's,

86
00:05:26,431 --> 00:05:30,040
that's what it was. It was, it was, it
was modeling the probabilities of a,

87
00:05:30,041 --> 00:05:33,870
of a note occurring after a certain
sequence of notes. That's what it did.

88
00:05:34,230 --> 00:05:39,230
And so that basic idea of modeling the
probability of a note occurring next is

89
00:05:39,451 --> 00:05:42,810
kind of like the constant of
using AI to generate music, right?

90
00:05:42,811 --> 00:05:46,800
Because when we have some piece of
music, it's a sequence of notes, right?

91
00:05:46,830 --> 00:05:50,260
All music is sequential and there was
some likelihood that a certain note to

92
00:05:50,270 --> 00:05:53,670
will come next after a certain set
of notes have already occurred.

93
00:05:53,850 --> 00:05:55,710
And we can model that with
a hidden Markov model.

94
00:05:56,340 --> 00:06:01,160
But I hidden Markov model can only produce
sub sequences that also exist in the

95
00:06:01,161 --> 00:06:01,994
original data.

96
00:06:02,330 --> 00:06:07,190
But what if we want to extrapolate beyond
those exact sub sequences and create

97
00:06:07,191 --> 00:06:10,070
really novel, um, data that's generated.

98
00:06:10,490 --> 00:06:13,790
And that's where recurrent networks come
into play. Recurrent neural networks.

99
00:06:14,210 --> 00:06:18,530
In 1989 the first attempt to generate
music with the recurrent net was limited

100
00:06:18,531 --> 00:06:20,570
by their short term coherence.

101
00:06:20,600 --> 00:06:25,380
So someone tried to
uh, generate music, uh,

102
00:06:25,520 --> 00:06:25,971
in his style,

103
00:06:25,971 --> 00:06:30,971
a Bach using recurrent
networks in 1989 and uh,

104
00:06:31,040 --> 00:06:35,660
it was limited because it can
only grasp short term sequences,

105
00:06:35,840 --> 00:06:39,270
right? So if if Bach hat of
a huge piece with, you know,

106
00:06:39,290 --> 00:06:42,990
four different sections,
it would stop, it would,

107
00:06:43,000 --> 00:06:46,850
it would forget about the beginning part
in the beginning was very soft and the

108
00:06:46,851 --> 00:06:50,960
second part was very strong and the
third part was like mellow and right.

109
00:06:51,200 --> 00:06:56,200
What a recurrent network does normally
without any kind of variation to it is it

110
00:06:56,241 --> 00:06:57,050
will.

111
00:06:57,050 --> 00:07:01,910
So normally a neural network will learn
the hidden state based on every new data

112
00:07:01,911 --> 00:07:05,200
point that it's fed. Right? Every new data
point. That's it. And it's learning, it's,

113
00:07:05,210 --> 00:07:07,760
it's, it's like, think of it
like clay, it's like molding,

114
00:07:07,940 --> 00:07:12,940
it's internal representation to become
robust against all variations of that

115
00:07:13,041 --> 00:07:16,580
input data,
whether it's images of stop signs,

116
00:07:16,581 --> 00:07:21,320
whether it's a musical notes, it's
learning some abstraction of all of that.

117
00:07:21,500 --> 00:07:24,530
So then using that obstruction,
we can generate new notes.

118
00:07:24,740 --> 00:07:27,950
But what we're current networks
will do is in every time step,

119
00:07:28,100 --> 00:07:30,380
it's not just learning
based on the new data point,

120
00:07:30,620 --> 00:07:34,400
it's learning based on the
previously learned abstraction.

121
00:07:35,000 --> 00:07:37,550
So at every time step
that obstruction is fed,

122
00:07:37,610 --> 00:07:41,750
not just a new data point but
an older version of itself.

123
00:07:42,260 --> 00:07:43,670
So there is a recurrence there.

124
00:07:43,970 --> 00:07:48,290
And what this does is it lets it
lets it lets us learn from sequences.

125
00:07:48,440 --> 00:07:53,180
The problem is that a recurrent network
can't learn longterm sequences because

126
00:07:53,240 --> 00:07:55,610
of what's called the
vanishing gradient problem.

127
00:07:55,820 --> 00:07:57,260
I'm not going to talk about
the vanishing gradient,

128
00:07:57,261 --> 00:07:59,750
but just search vanishing
gradient Saroj on, on Youtube.

129
00:08:00,930 --> 00:08:05,050
But basically we want to wait to trap
that memory that's being back propagated

130
00:08:05,060 --> 00:08:09,960
across time to get a little technical.
And the solution to that was, you know,

131
00:08:10,150 --> 00:08:13,790
the yard, the solution was to use what's
called a long short term memory network,

132
00:08:13,970 --> 00:08:18,080
an LSTM network. And let's listen to
a bit of this. A recurrent network.

133
00:08:25,020 --> 00:08:25,853
Okay.

134
00:08:30,410 --> 00:08:34,230
Yeah. So that was better that we have
to admit that was better than before.

135
00:08:34,270 --> 00:08:37,670
Not necessarily Hans Zimmer
status, but it was better. Um, so,

136
00:08:37,671 --> 00:08:41,180
so Doug [inaudible] was
one of the first in 2002.

137
00:08:41,181 --> 00:08:42,740
Now we're like 16 years ago,

138
00:08:42,741 --> 00:08:46,340
so we're getting closer to switch from
using a standard recurrent network to

139
00:08:46,341 --> 00:08:50,060
what's called a long short term memory
network and this improve the architecture.

140
00:08:50,061 --> 00:08:53,210
It improved what the,
what the model could generate.

141
00:08:54,380 --> 00:08:57,060
Now Doug works in for the
Magenta team at Google brain.

142
00:08:57,420 --> 00:09:01,470
Magento has been developing a code for
generating music using machine learning

143
00:09:03,390 --> 00:09:05,790
and they are really on the
bleeding edge of this stuff.

144
00:09:05,791 --> 00:09:08,670
Magenta has made so many cool
different little products that we can,

145
00:09:08,700 --> 00:09:12,090
we can view in the, in the
browser. But the thing is,

146
00:09:12,300 --> 00:09:14,480
even though we're current networks
have been around for awhile,

147
00:09:14,600 --> 00:09:18,780
it wasn't very much common knowledge
until Andre carpathy posted the

148
00:09:18,781 --> 00:09:22,170
unreasonable effectiveness
of recurrent networks in May,

149
00:09:22,170 --> 00:09:23,790
2015 which was more than a decade later,

150
00:09:23,791 --> 00:09:25,140
which is incredible if you think about it,

151
00:09:25,440 --> 00:09:30,000
the power of good documentation can
move the masses to try some code.

152
00:09:30,120 --> 00:09:34,980
What Andrea used his recurring network
on was generating Shakespearian text so

153
00:09:34,981 --> 00:09:38,340
it would train on Shakespeare text and
then it would be able to generate text.

154
00:09:38,580 --> 00:09:40,920
In this style of what it had
just trained on Shakespeare.

155
00:09:43,030 --> 00:09:43,380
Uh,

156
00:09:43,380 --> 00:09:47,220
so what I have here is a very
simple LSTM network. Okay.

157
00:09:47,221 --> 00:09:51,810
So for just for us to get an idea
of what it looks like, right.

158
00:09:51,811 --> 00:09:56,400
So
we are defining our nonlinearities,

159
00:09:56,401 --> 00:09:58,230
which are our activation functions,

160
00:09:58,231 --> 00:10:02,190
which makes sure our network can learn
both non linear and linear functions.

161
00:10:02,460 --> 00:10:07,140
We then define a training datasets. We
have our hyper parameters listed up here.

162
00:10:07,290 --> 00:10:10,890
We initialize the weights of our three
layer neural network and then inside of

163
00:10:10,891 --> 00:10:12,870
our training loop we
start training this thing.

164
00:10:13,140 --> 00:10:15,150
We performed the simple addition problem.

165
00:10:15,420 --> 00:10:17,970
We then update the
deltas to show that hey,

166
00:10:17,971 --> 00:10:21,600
there's a certain change in the weight
values and now that we've co computed a

167
00:10:21,601 --> 00:10:23,700
certain change in the
weight values we can,

168
00:10:23,701 --> 00:10:28,030
we can update those weights by performing
an optimization technique called back

169
00:10:28,031 --> 00:10:30,090
propagation,
also known as gradient descent.

170
00:10:30,300 --> 00:10:32,550
See my video backpropagation
in five minutes.

171
00:10:32,730 --> 00:10:36,630
What I need is basically just like a
tree to just connect all of my videos

172
00:10:36,631 --> 00:10:39,780
across the cause. All of these topics.
By the way, if you don't understand,

173
00:10:39,781 --> 00:10:41,910
just search to Raj and then
the name of that topic.

174
00:10:41,911 --> 00:10:44,490
And I promise you I have a video on that.
So,

175
00:10:45,550 --> 00:10:46,000
okay.
And

176
00:10:46,000 --> 00:10:49,120
we're updating those weights were making
sure that the gradient is not vanishing,

177
00:10:49,121 --> 00:10:52,750
that it's trapped properly inside of each
of those synapses and it's being back

178
00:10:52,751 --> 00:10:55,600
propagated properly as well. Um, but yeah,

179
00:10:55,660 --> 00:10:59,920
so moving forward, so September, 2016,

180
00:10:59,921 --> 00:11:02,200
two years ago now, we're
getting really, really close,

181
00:11:02,640 --> 00:11:06,970
deep mind published their seminal paper
on what's what they called wavenet. Okay.

182
00:11:06,971 --> 00:11:08,770
So wave net was,
uh,

183
00:11:08,771 --> 00:11:13,771
an an architecture that generated
state of the art human sounding speech.

184
00:11:14,140 --> 00:11:18,220
Okay. So no model up to that point had
made speech that sounded so human like,

185
00:11:18,550 --> 00:11:21,700
and people who were very surprised
because no one had done that.

186
00:11:21,701 --> 00:11:24,400
And here's the real key to it.
Here's the real kicker to all of this.

187
00:11:24,720 --> 00:11:29,710
Wave Net was not a recurrent network.
It was a convolutional network. What?

188
00:11:30,040 --> 00:11:30,281
Right.

189
00:11:30,281 --> 00:11:34,120
So convolutional networks are used for
learning from images and we're current

190
00:11:34,121 --> 00:11:36,310
networks are used for,
for learning from sequences.

191
00:11:36,520 --> 00:11:40,390
But what deepmind did is they use a
convolutional network to learn to process

192
00:11:40,391 --> 00:11:44,080
images by treating time
like a spatial dimension,

193
00:11:45,040 --> 00:11:47,890
which is very interesting stuff.
Anyway,

194
00:11:47,910 --> 00:11:52,910
wave net was was it required massive
amounts of Gpu like seriously and then

195
00:11:54,071 --> 00:11:57,370
later on someone made a fast version of
Wavenet, which you can find on get hub,

196
00:11:57,580 --> 00:12:01,630
just search fast wave net.
But then fast forward a year later,

197
00:12:01,730 --> 00:12:04,900
Magenta built on top of
wavenet to create end synth,

198
00:12:04,901 --> 00:12:06,400
which we can try from the browser.

199
00:12:06,401 --> 00:12:11,110
It's basically a sound maker that lets
us try out different instruments and

200
00:12:11,111 --> 00:12:14,230
combined them together and make all new,
all new sounds out of it.

201
00:12:15,970 --> 00:12:18,130
So up to this point, there
are some, there are some,

202
00:12:18,240 --> 00:12:21,310
there are certain important questions
in this space that we have to answer

203
00:12:21,330 --> 00:12:24,670
rights. How do we decide on a
proper representation of music?

204
00:12:24,850 --> 00:12:26,800
What music data should we use?

205
00:12:26,890 --> 00:12:31,360
Whose music counts box or an Edm artist?
You know,

206
00:12:31,361 --> 00:12:35,500
do we want to learn from the entire
documented history of music with the big

207
00:12:35,501 --> 00:12:37,810
goal of producing something
similar or something novel?

208
00:12:38,020 --> 00:12:41,710
Or should we try to construct
entire compositions or,

209
00:12:42,010 --> 00:12:45,460
or to improvise with us?
Do we want this to replace us?

210
00:12:45,461 --> 00:12:49,450
Do we want it to augment
us? Right. That's, that's a
major question for us to ask.

211
00:12:50,470 --> 00:12:52,630
Well,
when it comes to startups in this space,

212
00:12:52,631 --> 00:12:55,270
and this is a part of the
AI for business series,

213
00:12:55,271 --> 00:12:59,510
this is why I'm teaching
you this stuff because we,

214
00:12:59,620 --> 00:13:03,760
there's definitely a space
to create businesses that,

215
00:13:03,820 --> 00:13:08,820
that help artists improved their sounds
using AI to help consumers be able to

216
00:13:10,091 --> 00:13:12,670
become artists in a way
that they couldn't before.

217
00:13:12,790 --> 00:13:17,020
By giving them the tools to make
orchestral sounds, for example, that were,

218
00:13:17,410 --> 00:13:20,470
that would require a hundred human
people and you know, in the past,

219
00:13:20,471 --> 00:13:21,910
and you could just do it with a web app.

220
00:13:21,910 --> 00:13:26,910
Now juke deck is one example of a
startup that lets anybody create music.

221
00:13:27,310 --> 00:13:31,690
You could select the mood style temple
in length and it uses AI to do this in

222
00:13:31,691 --> 00:13:34,690
the background. And there's a, there's
a subscription model you can pay.

223
00:13:34,691 --> 00:13:38,580
You can get your first five songs a month
free and then you pay seven USD attrac

224
00:13:39,940 --> 00:13:44,320
for 150 bucks. Creators can even buy
the exclusive copyright for those songs.

225
00:13:44,590 --> 00:13:46,690
And these are songs that
are generated by AI,

226
00:13:46,720 --> 00:13:48,700
which means their bottom line is zero,

227
00:13:48,850 --> 00:13:50,890
which means that they
are making some money.

228
00:13:50,920 --> 00:13:54,760
This is a great business model
genius. And, and there's, there's a,

229
00:13:54,761 --> 00:13:58,990
there's huge room in this space for more
of that. Eva is another example, right?

230
00:13:58,991 --> 00:14:01,660
So what they do is they
do music composition.

231
00:14:01,690 --> 00:14:06,690
It was founded last year in London and
it's taught to compose classical music,

232
00:14:08,200 --> 00:14:12,400
which they already have clients, film,
film directors, advertising agencies,

233
00:14:12,401 --> 00:14:14,860
game studios.
Ampere is another example.

234
00:14:14,861 --> 00:14:18,850
I talked about this with Taryn southern
and uh, you know, a couple months now ago.

235
00:14:19,300 --> 00:14:21,800
Uh, but that's what she used.
That was a tool that she used to,

236
00:14:21,820 --> 00:14:25,030
to help generate music.
There was started by,

237
00:14:25,031 --> 00:14:28,150
it needs to be a film composer who
wanted to make music that was more of a

238
00:14:28,151 --> 00:14:32,590
collaboration between humans and machines.
It does basically the same thing.

239
00:14:32,650 --> 00:14:36,100
IBM's Watson. So this is not a
startup. This is a big company,

240
00:14:36,250 --> 00:14:39,310
but even there are going into this
space and they're using their cognitive

241
00:14:39,311 --> 00:14:41,710
technology. By the way, Ibm guys,

242
00:14:42,040 --> 00:14:46,300
let's stop using the word cognitive.
Let's start using the word, you know,

243
00:14:46,301 --> 00:14:49,420
deep learning or AI or machine learning.

244
00:14:49,630 --> 00:14:54,320
There's nothing cognitive about what
you're doing. Anyway. Don't hate me.

245
00:14:54,321 --> 00:14:58,430
Ibm. I still love you. Okay, so
you know. Anyway, just let's stop.

246
00:14:58,490 --> 00:15:01,040
Let's stop trying to make it seem like,
you know,

247
00:15:01,070 --> 00:15:04,490
the human brain is like inside of some
server. That's not where we are right now.

248
00:15:04,580 --> 00:15:09,110
Anyway, where were we? So architecture.
Okay, so that's the history.

249
00:15:09,111 --> 00:15:10,790
Up until now,
a couple of years ago,

250
00:15:10,850 --> 00:15:14,300
Ian Goodfellow released a paper called
generative adversarial networks that

251
00:15:14,301 --> 00:15:19,160
allows for novel way to generate data.
And I think that, and this is now,

252
00:15:19,190 --> 00:15:23,800
now we're going into, now we're going from
objective to subjective, right? So I'm,

253
00:15:23,801 --> 00:15:25,430
I'm telling you my opinion now.

254
00:15:25,490 --> 00:15:30,490
My opinion is that the way forward is to
use a generative adversarial network to

255
00:15:30,651 --> 00:15:35,510
generate sounds that would give us
better results than a recurrent network,

256
00:15:35,511 --> 00:15:39,520
an LSTM network, a hidden Markov
model, a convolutional neural networks.

257
00:15:39,590 --> 00:15:44,590
Even better than wavenet because gans
are truly a new technology that they have

258
00:15:46,101 --> 00:15:47,660
not properly been harnessed.

259
00:15:47,810 --> 00:15:52,370
And video harness them pretty well for
this paper on generating faces like in

260
00:15:52,371 --> 00:15:57,260
real time was very cool. But again,
these are notoriously hard to train.

261
00:15:57,290 --> 00:16:01,730
There's a lot that can be improved
of the space is moving so fast. Um,

262
00:16:01,790 --> 00:16:05,210
and what I have here, by the
way, is this good humbling,

263
00:16:05,211 --> 00:16:06,170
you should definitely check it out.

264
00:16:06,380 --> 00:16:09,020
It's called music generation
with deep learning, huge,

265
00:16:09,021 --> 00:16:11,300
huge collection of
resources for you to use.

266
00:16:11,360 --> 00:16:14,630
If you want to learn more about this
space, papers from all across the board,

267
00:16:14,631 --> 00:16:18,290
from all sorts of countries,
blog posts, code, uh,

268
00:16:18,291 --> 00:16:22,730
conferences and workshops related to
music generation with AI applications that

269
00:16:22,731 --> 00:16:26,300
you can play with in the browser. Super
useful stuff. Definitely check it out,

270
00:16:26,750 --> 00:16:30,110
but I want to talk about it again right
now. Okay. So again, has two parts.

271
00:16:30,111 --> 00:16:33,350
It's got a generator and it's got
a discriminator. And both of these,

272
00:16:33,470 --> 00:16:37,700
most of these are neural networks.
Okay? So one's job is to generate data.

273
00:16:38,030 --> 00:16:42,140
The other job is to look at
what the generator generated
and discriminate it and

274
00:16:42,141 --> 00:16:46,520
say this is real or this is fake. It's
binary, zero or one. That's what it does.

275
00:16:47,840 --> 00:16:52,840
And so with the power and ease of care
os we can create a generator in one line.

276
00:16:53,270 --> 00:16:56,030
That's right. One Line of code.
We could create a neural network,

277
00:16:56,180 --> 00:17:00,350
define oldest perimeters and call it a
generator. Okay. So that's our generator.

278
00:17:00,680 --> 00:17:04,100
What it will do. So in this example, it's
generating an image in the style of it,

279
00:17:04,101 --> 00:17:08,150
this handwritten digits.
But we can generate music sounds right.

280
00:17:08,151 --> 00:17:13,151
So what the generator will do is
it will take in that input image.

281
00:17:14,870 --> 00:17:17,180
Okay.
It will learn some latent representation.

282
00:17:17,181 --> 00:17:20,720
That's a collection of numbers
and this in this image,

283
00:17:20,750 --> 00:17:24,170
you can see that and then it will,
it will vary it a little bit.

284
00:17:24,171 --> 00:17:28,730
So it generates something entirely new.
And this is a series of operations, right?

285
00:17:28,731 --> 00:17:31,160
And this, and it's going to
start off totally random, right?

286
00:17:31,160 --> 00:17:35,540
Like how would it know how to vary this
input data? It doesn't know. It's dumb.

287
00:17:35,541 --> 00:17:40,300
It's just like, oh, let me just multiply
by X. And then the vibe, okay, the,

288
00:17:40,390 --> 00:17:44,540
the real learning comes from this.
When it generates that new sample,

289
00:17:44,810 --> 00:17:49,160
the discriminator, we'll say that's real
or it's fake. At first, the discriminator,

290
00:17:49,170 --> 00:17:52,440
we'll be able to tell
immediately that this is real.

291
00:17:52,441 --> 00:17:56,040
And this is fake because the discriminator
has been trained on the training data

292
00:17:56,041 --> 00:17:57,750
as well. So they will know, oh,

293
00:17:57,751 --> 00:18:01,230
that's not a real sequence
of notes that's fake.

294
00:18:01,280 --> 00:18:04,830
That because I know that that sequence
of notes is a part of the training data.

295
00:18:05,100 --> 00:18:06,240
Okay.
So talking about music,

296
00:18:06,390 --> 00:18:10,350
when that discriminator makes that
a classification and says it's fake,

297
00:18:11,070 --> 00:18:15,120
then the generator will need to update
itself. So using backpropagation,

298
00:18:15,210 --> 00:18:20,160
so both networks are back propagated
so that the optimization technique will

299
00:18:20,161 --> 00:18:24,750
slowly shift those wait values. And so
the operations will slowly shift as well.

300
00:18:24,900 --> 00:18:27,660
So the next time that some data
is going through the generator,

301
00:18:27,840 --> 00:18:31,140
it's going to be more likely to generate
something that is harder to discern

302
00:18:31,141 --> 00:18:34,660
whether it's real or fake. And so the
whole point of this process, I'm not like,

303
00:18:34,661 --> 00:18:35,250
I'm not like,

304
00:18:35,250 --> 00:18:38,190
I'm like not even reading the notes
because I know gans so well now,

305
00:18:38,970 --> 00:18:43,970
but the whole point of this process
is so the generator becomes so good at

306
00:18:44,251 --> 00:18:48,510
generating something that
the discriminator cannot
tell if it's real or if it's

307
00:18:48,511 --> 00:18:51,780
fake. And you can think of it
as like a cat and mouse game.

308
00:18:52,020 --> 00:18:54,330
You can think of it as like
a police and a counterfeiter.

309
00:18:54,510 --> 00:18:57,900
Eventually the counterfeiter gets so
good that the police cannot tell if the

310
00:18:57,901 --> 00:19:00,390
money is real or fake,
and that's what we're trying to do.

311
00:19:00,750 --> 00:19:04,170
The point of generative adversarial
network is not the discriminator.

312
00:19:04,470 --> 00:19:07,530
The point is the generator.
That's what we want.

313
00:19:07,770 --> 00:19:11,400
When the whole thing is trained and
to end, we remove the discriminator.

314
00:19:11,460 --> 00:19:14,850
We take that generator and we just
start generating. In our case,

315
00:19:14,851 --> 00:19:16,800
it would be pieces of
music and musical notes.

316
00:19:18,090 --> 00:19:21,840
Once we have those pieces of music,
that is our song that we can then play.

317
00:19:22,170 --> 00:19:25,580
Now it's easier to generate music
that is monophonic. Right? So the,

318
00:19:25,581 --> 00:19:29,220
these are a single notes,
piano notes.

319
00:19:29,250 --> 00:19:33,750
We get whatever Harb notes, but most
music comes in the form of chords, right?

320
00:19:33,751 --> 00:19:37,950
Collections of notes, polyphonic and
that's a little bit harder to train,

321
00:19:38,280 --> 00:19:42,900
but I think again, these are the way
forward to to, to make that happen. Okay,

322
00:19:42,901 --> 00:19:45,030
so that's how that goes.

323
00:19:45,270 --> 00:19:49,200
I had this sample here called Gan music
and basically if you want an idea of

324
00:19:49,201 --> 00:19:51,660
what it looks like programmatically,
here's what it is, right?

325
00:19:51,660 --> 00:19:55,800
So these are our parameters for both D,
which is the discriminator and g,

326
00:19:55,801 --> 00:19:58,920
which is the generator. And these are
just wait values and bias, values,

327
00:19:59,100 --> 00:20:03,450
input times weight, add a bias activate.
That's how every neural network works.

328
00:20:03,451 --> 00:20:06,450
Just remember that. So now we have
our generator and our discriminate.

329
00:20:06,510 --> 00:20:10,260
We define them right here. Here's our
generator, here's a discriminator.

330
00:20:10,290 --> 00:20:13,620
We were using tensor flow to create
both of them. We can plot them,

331
00:20:13,640 --> 00:20:16,260
see the difference. We can
create a sample and say, okay,

332
00:20:16,261 --> 00:20:20,850
here's the real and here's the fake.
We have two loss functions,

333
00:20:20,851 --> 00:20:22,560
one for the real, one,
one with for the fake,

334
00:20:22,980 --> 00:20:24,870
and then we solved them
both using gradient descent.

335
00:20:24,900 --> 00:20:26,490
This is our optimization strategy.

336
00:20:26,880 --> 00:20:30,960
And at the end we can print it out
and we can plot is very simple.

337
00:20:30,961 --> 00:20:35,190
This was like hundred 36 lines of code
with tensorflow to create again and you

338
00:20:35,191 --> 00:20:39,860
just drag and drop your music
dataset and boom, you're good. Um,

339
00:20:41,070 --> 00:20:44,940
so yeah, this, um, this
demo, it's on get hub,

340
00:20:44,941 --> 00:20:47,260
check it out as well.
Check out my links.

341
00:20:47,261 --> 00:20:49,420
I have some great links for
you in the video description.

342
00:20:49,600 --> 00:20:53,500
There's a lot of
potential to use AI to uh,

343
00:20:53,501 --> 00:20:57,790
create services for both artists
and consumers regarding music.

344
00:20:58,060 --> 00:21:00,700
And really if you want to extrapolate
to all sorts of entertainment,

345
00:21:00,730 --> 00:21:04,480
everything I've talked about, your
can be applied to text to, you know,

346
00:21:04,570 --> 00:21:08,980
essays to songs, to poetry, to
images, to video even, right?

347
00:21:09,310 --> 00:21:10,143
All of this,

348
00:21:10,180 --> 00:21:14,350
all of this is sequential data and
because all of this is sequential data,

349
00:21:14,470 --> 00:21:17,230
we can, we can, we can generate
it, we can learn from it.

350
00:21:17,231 --> 00:21:20,590
Then we can generate new sequences
and this can help all sorts of people.

351
00:21:20,620 --> 00:21:24,640
There's a huge business use case for this
and now is the time because all these

352
00:21:24,641 --> 00:21:26,860
tools are just now starting
to be democratized.

353
00:21:27,130 --> 00:21:29,470
We now have access to a
GPU is via cloud providers.

354
00:21:29,560 --> 00:21:32,950
We now have access to algorithms.
We now have access to data sets.

355
00:21:32,951 --> 00:21:37,090
We now have access to education, right?
So all this is being democratized.

356
00:21:37,091 --> 00:21:40,420
It's your responsibility to do something
about it. Um, that Santa my Spiel,

357
00:21:40,421 --> 00:21:41,980
and I hope you found this video useful.

358
00:21:42,190 --> 00:21:44,740
Please subscribe for more
programming videos. And for now,

359
00:21:44,800 --> 00:21:48,490
I've got to listen to some music,
AI music. So thanks for watching.

