1
00:00:00,270 --> 00:00:04,980
Is this a real picture or a fake one?
It's fake hello world.

2
00:00:05,000 --> 00:00:10,000
It's Saroj and there's a new paper from
nvidia research that details an AI model

3
00:00:11,130 --> 00:00:16,130
that can generate images that are more
realistic than any previous model.

4
00:00:17,070 --> 00:00:21,090
It's called a generative adversarial
network or again for short,

5
00:00:21,360 --> 00:00:22,500
but not just any.
Again,

6
00:00:22,590 --> 00:00:27,390
it's again that can progressively grow
over time during the training phase,

7
00:00:27,570 --> 00:00:29,100
which is such a cool idea.

8
00:00:29,550 --> 00:00:34,470
Gans were invented by a researcher at the
University of Montreal three years ago

9
00:00:34,680 --> 00:00:39,680
and its potential is huge because it
can learn to mimic any distribution of

10
00:00:39,751 --> 00:00:40,584
data.

11
00:00:40,650 --> 00:00:45,650
That means it can be taught to create
worlds that are eerily similar to our own

12
00:00:45,931 --> 00:00:50,010
in any domain. Images,
music, speech writing.

13
00:00:50,220 --> 00:00:54,210
They're like robotic artists and
their outputs are pretty impressive.

14
00:00:54,480 --> 00:00:59,480
Speech synthesis systems are using them
image to image translation techniques,

15
00:00:59,701 --> 00:01:03,660
use them and image in painting
is another popular use case.

16
00:01:03,690 --> 00:01:06,600
Gans are a type of generative algorithm.

17
00:01:06,630 --> 00:01:10,200
The other class of models being
discriminative algorithms,

18
00:01:10,260 --> 00:01:15,260
discriminative algorithms try to classify
input data given some set of features

19
00:01:15,660 --> 00:01:19,830
predict a label or category
to which that data belongs to.

20
00:01:20,070 --> 00:01:23,370
If we have all the words in an email.
For example,

21
00:01:23,610 --> 00:01:28,610
a discriminative algorithm could predict
whether the message is spam or not.

22
00:01:28,921 --> 00:01:31,020
Spam,
spam being one of the labels,

23
00:01:31,260 --> 00:01:36,260
the bag of words we gather from the email
or the features that constitutes the

24
00:01:36,301 --> 00:01:39,870
input data.
When we express this mathematically,

25
00:01:40,110 --> 00:01:44,100
the label is called y and
the features are called x.

26
00:01:44,370 --> 00:01:49,370
The formulation probability of y given
x translates to the probability that an

27
00:01:50,070 --> 00:01:53,460
email is spam given the words it contains.

28
00:01:53,490 --> 00:01:57,450
So discriminative algorithms
map features to labels.

29
00:01:57,630 --> 00:02:00,240
They're only concerned with correlations.

30
00:02:00,450 --> 00:02:05,400
One way to think about
generative algorithms though
is that they do the complete

31
00:02:05,460 --> 00:02:09,540
opposite. Instead of predicting
a label, given some features,

32
00:02:09,720 --> 00:02:12,930
they try to predict features
given a certain label,

33
00:02:12,960 --> 00:02:17,580
like assuming this email is spam,
how likely are these features?

34
00:02:17,820 --> 00:02:22,350
Discriminative models care about
the relation between y and X.

35
00:02:22,350 --> 00:02:24,630
Generative models care
about how you get x.

36
00:02:24,870 --> 00:02:29,550
This allows us to capture the
probability of x given why it learns the

37
00:02:29,551 --> 00:02:33,270
distribution of individual classes,
not the boundary.

38
00:02:33,360 --> 00:02:35,760
Dan's consist of two neural networks,

39
00:02:35,970 --> 00:02:40,830
a generative network that generates new
data instances and the discriminator

40
00:02:40,860 --> 00:02:44,490
that evaluates them for authenticity.
The discriminator,

41
00:02:44,491 --> 00:02:47,310
we'll decide whether
each instance of data,

42
00:02:47,340 --> 00:02:51,420
it reviews belongs to the
actual training Dataset or not.

43
00:02:51,690 --> 00:02:54,900
Let's say we're trying to
generate new types of Pokemon.

44
00:02:58,530 --> 00:03:00,640
I just had play that for a second.
Okay.

45
00:03:00,670 --> 00:03:03,040
Using an image Dataset
of existing Pokemon,

46
00:03:03,370 --> 00:03:08,370
the goal of the discriminator when
shown a Pokemon is to recognize it as

47
00:03:08,591 --> 00:03:10,300
authentic.
Meanwhile,

48
00:03:10,301 --> 00:03:14,890
the generator is creating new images
that it passes to the discriminator.

49
00:03:15,130 --> 00:03:19,630
It's trying to fool the discriminator,
trying to pass it off as authentic,

50
00:03:19,660 --> 00:03:21,160
even though it's fake.

51
00:03:21,460 --> 00:03:26,460
The goal of the generator is to generate
passable Pokemon to lie without being

52
00:03:26,921 --> 00:03:27,754
caught.

53
00:03:27,820 --> 00:03:32,410
The goal of the discriminator is to
identify images from the generator as fake

54
00:03:32,411 --> 00:03:35,320
or real.
The steps again takes are as follows.

55
00:03:35,470 --> 00:03:40,000
The generator takes in randomly
generated numbers and returns an image.

56
00:03:40,210 --> 00:03:45,010
This generated image is fed into the
discriminator alongside a stream of

57
00:03:45,011 --> 00:03:47,680
Pokemon.
From the actual Dataset,

58
00:03:47,920 --> 00:03:52,920
the discriminator takes in both real and
fake Pokemon and returns probabilities.

59
00:03:53,380 --> 00:03:58,380
A number between zero and one with one
representing a prediction of authentic

60
00:03:58,900 --> 00:04:00,610
and zero representing fake.

61
00:04:00,910 --> 00:04:04,270
So there's this double
feedback loop going on.

62
00:04:04,600 --> 00:04:09,600
The discriminator is in a feedback loop
with the ground truth of the images,

63
00:04:10,000 --> 00:04:14,800
which we know the generator is in a
feedback loop with the discriminator.

64
00:04:15,010 --> 00:04:20,010
Think of it like a counterfeiter and a
cop in a game of cat and mouse where the

65
00:04:20,111 --> 00:04:24,970
counterfeiter tries to print fake money
and the cop is trying to detect it.

66
00:04:25,360 --> 00:04:27,610
Both are learning at the same time.

67
00:04:27,670 --> 00:04:32,530
The discriminator is a
standard convolutional network
that can classify images

68
00:04:32,531 --> 00:04:33,364
fed to it.

69
00:04:33,400 --> 00:04:38,050
It's essentially a binomial classifier
labeling images as real or fake.

70
00:04:38,350 --> 00:04:43,350
The generator is an inverse convolutional
network or deep convolutional network.

71
00:04:43,920 --> 00:04:48,920
A CNN takes an image and down samples
it to produce a probability and a DNN

72
00:04:49,990 --> 00:04:54,130
takes a vector of random noise
and up samples it into an image.

73
00:04:54,340 --> 00:04:58,720
Both networks tried to optimize a
different and opposing loss function,

74
00:04:58,930 --> 00:05:02,410
so gans are awesome,
but they're really hard to train.

75
00:05:02,710 --> 00:05:07,710
Usually the loss function for gans looks
something like this instead of what it

76
00:05:07,751 --> 00:05:10,240
should look like,
which is something like this.

77
00:05:10,390 --> 00:05:13,570
And that's what makes them
an active area of research.

78
00:05:13,870 --> 00:05:18,460
The idea that Nvidia had was
to grow again progressively.

79
00:05:18,880 --> 00:05:20,410
It wasn't a new idea.

80
00:05:20,500 --> 00:05:25,420
There was a paper that presented
a cascaded reinforcement
approach that brought

81
00:05:25,421 --> 00:05:29,680
small generated images up to
mega pixel size step by step.

82
00:05:29,950 --> 00:05:34,950
Another paper built an intermediate low
dimensional representation than improved

83
00:05:35,261 --> 00:05:36,640
it on another again,

84
00:05:36,850 --> 00:05:41,850
but these methods made their
progressive improvements separately.

85
00:05:42,640 --> 00:05:47,050
The next level of progressive improvement
just took a result of the previous

86
00:05:47,051 --> 00:05:51,640
layers and has paper use a system
where they trained a few layers,

87
00:05:51,760 --> 00:05:54,070
then added a few more and so on.

88
00:05:54,310 --> 00:05:58,700
It turns out that this type of
execution was the most straightforward,

89
00:05:58,880 --> 00:06:01,910
fastest to train and
provided the best results.

90
00:06:02,150 --> 00:06:07,150
The authors begin with a small network
able to produce only four by four images.

91
00:06:07,550 --> 00:06:09,770
Then they train it until it works well.

92
00:06:09,920 --> 00:06:14,660
Then add another set of layers to both
the generator and the discriminator.

93
00:06:14,780 --> 00:06:18,980
Moving from four by four to eight by
eight train the new layers and so on.

94
00:06:19,190 --> 00:06:20,990
Doing this,
they were able to grow again,

95
00:06:21,020 --> 00:06:26,020
able to generate really convincing 10 24
by 10 24 images of much better quality

96
00:06:27,410 --> 00:06:28,243
than before.

97
00:06:28,520 --> 00:06:33,520
One tweak I found particularly interesting
was that they implement it a way to

98
00:06:33,621 --> 00:06:36,140
help their Gan increase its variation.

99
00:06:36,170 --> 00:06:41,170
Dan's have this tendency to capture only
a subset of the variation found in the

100
00:06:41,421 --> 00:06:44,770
training data.
One solution was to compute features,

101
00:06:44,771 --> 00:06:49,771
statistics not only from individual
images but across a mini batch.

102
00:06:50,030 --> 00:06:54,770
This encouraged many batches of generated
and training images to show similar

103
00:06:54,771 --> 00:06:55,610
statistics.

104
00:06:55,850 --> 00:07:00,590
It's implemented by adding a mini
batch layer towards the end of the

105
00:07:00,591 --> 00:07:05,591
discriminator where the layer learns
a large tensor that projects the input

106
00:07:06,020 --> 00:07:09,140
activation to an array of statistics.

107
00:07:09,440 --> 00:07:14,440
A separate set of stats is produced
for each example in a mini batch and

108
00:07:15,051 --> 00:07:19,640
concentrated to the layers output so
the discriminator can use those stats

109
00:07:19,670 --> 00:07:20,503
internally.

110
00:07:20,780 --> 00:07:25,780
They sampled this approach by first
computing the standard deviation for each

111
00:07:26,150 --> 00:07:30,260
feature in each spacial
location over the mini batch.

112
00:07:30,470 --> 00:07:31,520
Then the average,

113
00:07:31,550 --> 00:07:36,550
all of those estimates over all features
and spatial locations to get a single

114
00:07:36,591 --> 00:07:37,424
value.

115
00:07:37,490 --> 00:07:42,490
The value was replicated and contained
to all spatial locations and over the

116
00:07:42,900 --> 00:07:45,770
minibatch which yielded
one additional feature map.

117
00:07:45,950 --> 00:07:49,940
They inserted it towards the end of
the network and it turns out doing that

118
00:07:50,030 --> 00:07:54,170
helped again learn more of the
variation inherent in the training data.

119
00:07:54,560 --> 00:07:59,560
They trained their network on a single
and video Tesla Gpu for 20 days and after

120
00:08:00,831 --> 00:08:04,790
that there was no real difference in
the qualitative difference between the

121
00:08:04,791 --> 00:08:06,620
results of training iterations.

122
00:08:06,860 --> 00:08:11,300
It's pretty incredible the images
they were able to generate not 100%

123
00:08:11,301 --> 00:08:12,134
photorealistic,

124
00:08:12,260 --> 00:08:17,260
but really close the fakes dense pose
and now progressively growing gans.

125
00:08:18,140 --> 00:08:22,100
We are heading towards some
unpredictable and exciting times.

126
00:08:22,370 --> 00:08:24,740
Three things to remember from this video.

127
00:08:25,040 --> 00:08:30,040
A generative adversarial network consists
of two neural networks of generator

128
00:08:30,740 --> 00:08:34,610
and a discriminator.
The generator creates fake images.

129
00:08:34,790 --> 00:08:39,320
The discriminator tries to discern if
it's real or if it's fake. Over time,

130
00:08:39,350 --> 00:08:43,400
both get better through a training
phase and and video found that by

131
00:08:43,401 --> 00:08:46,760
progressively adding
layers to both networks,

132
00:08:47,120 --> 00:08:51,560
it improved the quality of the
outputs and sped up the training time.

133
00:08:51,950 --> 00:08:56,220
This week's coding challenge
is to generate some
photorealistic images using a

134
00:08:56,221 --> 00:09:00,930
progressively growing gan details and
code are in the video description.

135
00:09:01,050 --> 00:09:03,270
Submit your get hub link
in the comments section.

136
00:09:03,330 --> 00:09:06,240
I'll review them and announce
the top two entries in a week.

137
00:09:06,390 --> 00:09:08,430
Was this video itself generated?

138
00:09:08,700 --> 00:09:12,870
Maybe it's a tried to keep up with the
latest in AI and block chain technology.

139
00:09:13,140 --> 00:09:16,440
For now, I've got to generate a
website, so thanks for watching.

