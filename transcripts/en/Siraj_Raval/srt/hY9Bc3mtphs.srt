1
00:00:00,090 --> 00:00:05,070
Hello world. It's the Raj and drug
discovery. That's the topic of this video.

2
00:00:05,071 --> 00:00:08,490
As part of the AI for business series.
In this video,

3
00:00:08,491 --> 00:00:12,300
we're going to use AI to help solve
the problem of drug discovery.

4
00:00:12,450 --> 00:00:16,980
What specifically I'm talking about is
the process of finding new drugs for

5
00:00:16,981 --> 00:00:20,770
diseases, right? This is what
researchers in biomedicine, dude,

6
00:00:20,771 --> 00:00:23,580
this is their full time job,
right? And when I say diseases,

7
00:00:23,581 --> 00:00:28,260
we're talking about cancer, aids,
uh, Alzheimer's. All of these major,

8
00:00:28,261 --> 00:00:32,850
major diseases out there that have to
go through the medical pipeline, right?

9
00:00:32,851 --> 00:00:37,851
The clinical trial pipeline to go from
research to production where these drugs

10
00:00:38,101 --> 00:00:42,060
are being sent out to pee real people
for use. How do we do that? Right now,

11
00:00:42,240 --> 00:00:47,010
that pipeline takes about 12 years.
That's a very long time, right?

12
00:00:47,160 --> 00:00:49,950
In Ai, we just published papers
just left and right, right.

13
00:00:49,951 --> 00:00:53,310
The field is moving like this,
but when it comes to biomedicine,

14
00:00:53,400 --> 00:00:55,020
it's a very slow process.

15
00:00:55,140 --> 00:01:00,060
So we're going to learn in this video how
to solve the problem of drug discovery

16
00:01:00,180 --> 00:01:01,680
using Ai.
Specifically.

17
00:01:01,681 --> 00:01:05,190
The model we're going to look at is
a generative adversarial network.

18
00:01:05,191 --> 00:01:06,690
I'll talk about how all that works.

19
00:01:06,930 --> 00:01:11,370
But first I want to start off with this
very cool tool that was built in python.

20
00:01:11,400 --> 00:01:11,641
Okay?

21
00:01:11,641 --> 00:01:16,641
This is a tool built with python
in the flask web framework.

22
00:01:16,681 --> 00:01:20,220
And what it does, it's a great tool if
you want to try to tackle this problem.

23
00:01:20,460 --> 00:01:24,150
What it does is it lists out a
bunch of different drugs, right?

24
00:01:24,151 --> 00:01:27,750
These are the molecular compounds that
all of these chemicals consist of.

25
00:01:27,990 --> 00:01:32,310
And what we can do is we can see in
this three d graph what all of these

26
00:01:32,311 --> 00:01:35,640
features, each of these acts,
ccs are features for these drugs.

27
00:01:35,641 --> 00:01:40,100
And on the left you'll see
the, the molecule for that
drug show up, right? Quotes,

28
00:01:40,101 --> 00:01:43,630
Epam, uh, tiotropium, uh, et cetera.

29
00:01:43,650 --> 00:01:47,100
Silicide son Tio Broma, Theo
borrow mine. I'm going to,

30
00:01:47,101 --> 00:01:49,620
I'm going to mispronounce a lot of
these, but right? So we could do that.

31
00:01:49,621 --> 00:01:52,470
That's one way we could
visualize these molecules.

32
00:01:52,680 --> 00:01:55,950
And another way is for us to just type
them into this dropdown, right? There's,

33
00:01:56,190 --> 00:01:59,910
there's a bunch, there are
so many here, Dan, Dan Tro.

34
00:02:00,240 --> 00:02:03,300
Dantrolene right? And so we could,
we could see these down here,

35
00:02:03,301 --> 00:02:06,900
the ones that we select, Indy dropdown,
each of these chemicals, right?

36
00:02:06,930 --> 00:02:11,160
Each of these molecules has an associated
data sheet that lists all of its

37
00:02:11,161 --> 00:02:11,994
features,
right?

38
00:02:12,030 --> 00:02:17,030
There's a whole taxonomy and entire
literature around how to classify these

39
00:02:17,581 --> 00:02:21,330
drugs into different groups, the
types of drugs, their description,

40
00:02:21,331 --> 00:02:24,930
their chemical structure, synonyms
for them, what do they consist of,

41
00:02:24,931 --> 00:02:26,070
what are their ingredients,

42
00:02:26,190 --> 00:02:30,790
and what prescription products they're
in right now and how do they get into the

43
00:02:30,810 --> 00:02:35,490
bodies of real people, right?
So drug bank has an amazing,

44
00:02:35,491 --> 00:02:38,790
amazing list of these things and the,
and the best way to access that,

45
00:02:38,791 --> 00:02:41,520
I think is through this
drug explorer plot.

46
00:02:41,521 --> 00:02:43,890
You'll find a link to it in the
video description, by the way.

47
00:02:44,250 --> 00:02:48,150
So I just want to start off with that
as a supplementary tool. Eventually,

48
00:02:48,151 --> 00:02:51,300
the code we're going to look at in
this video that's helping to solve this

49
00:02:51,301 --> 00:02:54,390
problem is a model called Chem Gan.
Okay,

50
00:02:54,391 --> 00:02:56,940
so chemical generative
adversarial network.

51
00:02:57,120 --> 00:02:59,350
It's off of a recent paper from last year.

52
00:02:59,530 --> 00:03:03,790
And these researchers applied generative
adversarial networks to the problem of

53
00:03:03,791 --> 00:03:07,190
drug discovery, right? So it's
a, it's a very, it's a very, uh,

54
00:03:07,300 --> 00:03:10,360
recent application of AI and
we're going to get there, right?

55
00:03:10,361 --> 00:03:14,950
So the first thing I have here is an
image of a disease and then candidates for

56
00:03:14,951 --> 00:03:19,090
the, for that drug, right?
These are possible drugs
that could cure the disease,

57
00:03:19,120 --> 00:03:23,050
possibly. And then we have this
label here that says discriminator.

58
00:03:23,051 --> 00:03:25,750
And the idea here is that we're using,
again,

59
00:03:25,751 --> 00:03:29,380
we're going to call it Gan Gan
from now on for short, again,

60
00:03:29,381 --> 00:03:33,040
can be used to solve this problem.
The question is how, right? That's,

61
00:03:33,070 --> 00:03:35,440
that's the question of the video.
But before we get there,

62
00:03:35,740 --> 00:03:38,740
we got to talk about how drugs are
discovered. Right now we can't just,

63
00:03:38,950 --> 00:03:42,640
we can't just flip up the process
without trying to, uh, you know,

64
00:03:42,641 --> 00:03:46,270
see what the process is, right? We
can't disrupt to, to get technical.

65
00:03:46,390 --> 00:03:49,720
So how were these drugs
discovered? Right? Right now,

66
00:03:49,721 --> 00:03:54,721
it's going to take anywhere from 6.5 to
12 to 15 years to get these drugs to the

67
00:03:55,751 --> 00:03:59,740
market, right? There's this
entire pipeline. You can see
here I've drug discovery,

68
00:03:59,990 --> 00:04:03,890
pre clinical trials, clinical
trials, and then the all uh,

69
00:04:03,920 --> 00:04:05,830
all powerful FDA review.

70
00:04:05,831 --> 00:04:09,820
And then finally you get an FDA approved
drug if you're in the u s different

71
00:04:09,821 --> 00:04:13,270
countries have different regulations
around this. So keep that in mind.

72
00:04:14,530 --> 00:04:18,910
So also, 90% of all, I thought this
was a very interesting statistic,

73
00:04:18,911 --> 00:04:23,911
90% of all chronic clinical trials in
humans fail even after the molecules have

74
00:04:24,401 --> 00:04:27,790
been successfully to test it
in animals, which is a, it's a,

75
00:04:27,800 --> 00:04:31,000
it's a huge number and there's a
huge room for improvement there.

76
00:04:31,001 --> 00:04:34,690
So how does this process work? Let's
just get down into it. So the first step,

77
00:04:34,810 --> 00:04:37,960
right? If you are a researcher in
this field, you studied biomedicine,

78
00:04:38,110 --> 00:04:41,170
you went through your undergraduate
degree, you did your graduate degree,

79
00:04:41,200 --> 00:04:42,970
you did your post doc and you're ready.

80
00:04:43,060 --> 00:04:47,050
You have studied 12 years to
get to this point. By the way,

81
00:04:47,051 --> 00:04:49,990
I want to make one more.
I want to make one more short note here.

82
00:04:50,770 --> 00:04:55,060
Machine learning and AI technologies
are the great democratizer of our time.

83
00:04:55,061 --> 00:04:56,530
What I mean is,
here's what I mean,

84
00:04:56,980 --> 00:05:01,980
that normally it would take you 12 years
to get to the point where you can make

85
00:05:02,381 --> 00:05:07,030
a valid contribution to this field and
only those researchers could make drug

86
00:05:07,031 --> 00:05:09,370
discoveries.
When I say democratization,

87
00:05:09,371 --> 00:05:14,371
I'm not just talking about special powers
like classifying images and detecting

88
00:05:14,680 --> 00:05:18,940
a credit card fraud, and this was
only limited to fraud specialists.

89
00:05:19,120 --> 00:05:21,400
Now anybody who understands
machine learning can do it.

90
00:05:21,820 --> 00:05:24,310
Anybody in the future who
understands machine learning,

91
00:05:24,550 --> 00:05:27,790
we'll be able to do literally
anything as these models improve.

92
00:05:28,090 --> 00:05:29,890
So what I'm saying is if you're,

93
00:05:29,891 --> 00:05:33,940
if you haven't done 12 years in school
studying to be a biomedical researcher,

94
00:05:34,060 --> 00:05:35,770
if you understand machine learning,

95
00:05:35,860 --> 00:05:40,330
you can just leap over that 12 year
requirement because think of the training

96
00:05:40,331 --> 00:05:45,331
time for machines as a sped up version
of having a human have to learn all this,

97
00:05:45,491 --> 00:05:49,690
right? We got, it takes us so long to
learn anything, right? We got to eat food,

98
00:05:49,810 --> 00:05:52,360
we got to learn, we got to go to
sleep, we've got to take a break,

99
00:05:52,450 --> 00:05:56,360
we've got to get our, you know, a
special time on all this stuff. So it's,

100
00:05:56,570 --> 00:06:00,410
there's a, there's a lot there and
ideally we could speed all that up.

101
00:06:00,470 --> 00:06:03,830
And that's what machine learning is.
You don't have to be a biomedical Phd.

102
00:06:03,980 --> 00:06:08,980
You could be some kid in Tunisia and
make an incredible drug discovery using

103
00:06:09,021 --> 00:06:13,100
these tools. The data sets are online,
they're publicly available and yeah,

104
00:06:13,101 --> 00:06:15,110
you got this.
Basically believe in yourself.

105
00:06:15,111 --> 00:06:18,110
No one believes in themselves these days.
People are a week.

106
00:06:18,200 --> 00:06:20,060
You got to believe in yourselves.
Clearly.

107
00:06:20,061 --> 00:06:24,800
I've been watching a lot of Gary
V. Oh man. Okay. I love doing this.

108
00:06:24,801 --> 00:06:28,520
Anyway, here we go. Step one is
studying medical literature. Okay.

109
00:06:28,521 --> 00:06:29,720
A of this pipeline here,

110
00:06:31,310 --> 00:06:34,580
they have to study all the different
interactions between different drugs,

111
00:06:34,640 --> 00:06:38,120
diseases, what, what has been done
before, right? That's the initial step.

112
00:06:38,121 --> 00:06:41,600
That's in any kind of research what has
been done before. And once they do that,

113
00:06:41,601 --> 00:06:44,750
they can find out what the target
for the drug should be. I, e.

114
00:06:44,930 --> 00:06:47,480
What proteins should this drug bind with?

115
00:06:47,840 --> 00:06:51,230
The next step is figuring out what all
of those properties that I talked about

116
00:06:51,231 --> 00:06:53,120
before for the drug should be drugs,

117
00:06:53,121 --> 00:06:56,930
have a whole bunch of different properties
and once you know what the drug is

118
00:06:56,931 --> 00:06:58,430
that your,
that's your hypothesis.

119
00:06:58,580 --> 00:07:02,060
You've got to figure out
what the properties of that
drug should be, right? Wow.

120
00:07:02,061 --> 00:07:06,200
Soluble soluble, should it be, what are
the specific structures for this drug?

121
00:07:06,260 --> 00:07:08,900
Should it treat this kind of
cancer or this kind of cancer?

122
00:07:08,990 --> 00:07:09,890
You got to figure it out.

123
00:07:10,220 --> 00:07:15,170
And then step three is figuring out which
molecules have those properties, right?

124
00:07:15,171 --> 00:07:19,000
So I know the type of drug, I know
what it should be going after. Um,

125
00:07:19,190 --> 00:07:23,090
which molecules that exist currently
have those properties, right?

126
00:07:23,270 --> 00:07:27,080
And Molecules are dynamic structures.
They can be complex,

127
00:07:27,290 --> 00:07:30,890
they can consist of multiple chemicals.
It's not an easy process.

128
00:07:30,980 --> 00:07:34,400
So one standard, this is
serious, go look this up.

129
00:07:34,500 --> 00:07:39,500
A standard database for drugs that
you'll find publicly has over 72 million

130
00:07:41,180 --> 00:07:42,710
different molecules.

131
00:07:42,890 --> 00:07:46,100
That's a lot of different molecules
complete what their formulas,

132
00:07:46,250 --> 00:07:47,630
some properties, et Cetera, et cetera.

133
00:07:48,200 --> 00:07:52,880
Does a certain molecule cure certain
disease. That's the research process.

134
00:07:53,060 --> 00:07:56,840
Look at the space of possibility.
72 million.

135
00:07:57,020 --> 00:08:00,230
Don't tell me this is not a
problem for machine learning.

136
00:08:00,590 --> 00:08:05,420
Humans aren't going to waste their
time looking at 72 million different

137
00:08:05,660 --> 00:08:10,490
possibilities. That's just not, that's
not human. It's machine learning.

138
00:08:10,520 --> 00:08:13,150
Okay? Step Four. Once
you've got this, you,

139
00:08:13,160 --> 00:08:17,690
you had this basic idea of the molecule,
you have to start experimenting. Now,

140
00:08:17,840 --> 00:08:21,800
this right now is not done in Silico.
What I mean is on a computer,

141
00:08:21,890 --> 00:08:26,590
it's done in real life with real
human or sometimes animal, uh,

142
00:08:27,020 --> 00:08:27,853
trials.

143
00:08:28,910 --> 00:08:32,210
So check this out from zero to
regulatory approval to the market,

144
00:08:32,420 --> 00:08:35,560
eight to 12 years. That's
a lot. But their ideas,

145
00:08:35,570 --> 00:08:37,160
these researchers called their ideas.

146
00:08:37,220 --> 00:08:42,050
Lead molecules are sent to the lab for
experimental validation and in the lab

147
00:08:42,051 --> 00:08:45,680
that can test whether or not it works,
right? Does it work? Does it not work?

148
00:08:45,950 --> 00:08:50,950
And a very small percentage of those drugs
actually do work of small percentage.

149
00:08:51,980 --> 00:08:52,813
And we need to be,

150
00:08:53,090 --> 00:08:56,670
we need to be confident about what drugs
will work and what drugs won't work.

151
00:08:56,671 --> 00:09:00,180
And right now we're not.
Eventually,

152
00:09:00,181 --> 00:09:03,690
ideally we can get to the point and
this would speed up the entire pipeline.

153
00:09:03,930 --> 00:09:04,980
We're in Silico.

154
00:09:04,981 --> 00:09:09,930
We can decide this is the best drug for
humans and just go straight to a market.

155
00:09:10,140 --> 00:09:12,510
We don't need to do any
human clinical trial testing.

156
00:09:12,690 --> 00:09:14,190
We could do this in simulation.

157
00:09:14,310 --> 00:09:19,310
This is an open problem and someone who
has the moxy or the courage to do that

158
00:09:19,631 --> 00:09:23,190
should just do that. I'm just saying all
sorts of words today. Moxie, what is that?

159
00:09:23,191 --> 00:09:27,030
New York Slang? I W I lived
in New York, so yeah. Anyway,

160
00:09:27,120 --> 00:09:31,380
the bio pharmaceutical research and
development process is way, way too long.

161
00:09:31,560 --> 00:09:31,921
Okay.

162
00:09:31,921 --> 00:09:35,820
I'm just trying to drill that into both
your head and my head is that it's very

163
00:09:35,821 --> 00:09:39,540
long and that's why there is such a
room for disruption when it comes to a

164
00:09:39,541 --> 00:09:40,920
profitable AI startup.

165
00:09:41,220 --> 00:09:45,510
Anything you can do to speed up that
pain point for both, for researchers,

166
00:09:45,720 --> 00:09:50,630
for pharmaceutical companies,
for governments, for consumers,
anything you can do,

167
00:09:50,640 --> 00:09:51,390
you can say,

168
00:09:51,390 --> 00:09:56,390
you know they say the best idea for a
startup is one that can offer a 10 x

169
00:09:57,001 --> 00:09:58,770
improvement.
If you could say,

170
00:09:58,771 --> 00:10:02,220
I can give you the results in one
year instead of 10 there you go.

171
00:10:02,250 --> 00:10:03,780
There's your 10 x improvement.

172
00:10:05,110 --> 00:10:05,943
So

173
00:10:07,700 --> 00:10:11,420
check this out. Even if the goal,
even if the goal is to treat cancer,

174
00:10:11,690 --> 00:10:15,830
there's no hope to check
the entire endless variation
of small molecules in the

175
00:10:15,831 --> 00:10:20,330
lab. 72 million is just the size of
a specific database, Dah, Dah, Dah,

176
00:10:20,370 --> 00:10:21,530
all the way at the sounding 2 million.

177
00:10:21,890 --> 00:10:26,330
But the total number of molecules
is estimated to be between,

178
00:10:26,331 --> 00:10:27,830
and this is a scientific notation,

179
00:10:27,831 --> 00:10:32,030
10 to the 60th to tend to
the 200th different types.

180
00:10:32,031 --> 00:10:36,890
That's combining all those 72
million molecules basically a lot.

181
00:10:38,950 --> 00:10:43,270
So synthesizing and testing
a single new molecule.

182
00:10:43,360 --> 00:10:48,360
Check this cell here you go in a lab
make costs thousands or tens of thousands

183
00:10:49,090 --> 00:10:50,950
of dollars there your,
there's your 10 x right there.

184
00:10:51,310 --> 00:10:55,840
The early guessing stage is
really important and this
is where machine learning

185
00:10:55,841 --> 00:10:56,440
can come in.

186
00:10:56,440 --> 00:11:01,420
We can use machine learning models to try
and choose the molecules that are most

187
00:11:01,480 --> 00:11:05,170
likely to have the desire
properties of what we think.

188
00:11:05,500 --> 00:11:10,240
So when you have 72 million of something,
what kind of problem is it? Well,

189
00:11:10,241 --> 00:11:12,700
it's less of a classification problem.

190
00:11:12,880 --> 00:11:16,660
Which of these 72 million is the right
one? Because there's 72 million, right?

191
00:11:16,780 --> 00:11:18,970
This is not hot dog,
not hot dog.

192
00:11:19,120 --> 00:11:24,120
This is 72 million and it starts to
becoming something more like a generation

193
00:11:24,550 --> 00:11:25,383
problem.
What do,

194
00:11:25,450 --> 00:11:29,080
let's generate something from these 72
million because there's so many different

195
00:11:29,081 --> 00:11:33,010
classes out there. So instead of
looking for that needle in the haystack,

196
00:11:33,370 --> 00:11:35,230
we're going to design the perfect needle.

197
00:11:35,350 --> 00:11:38,170
As in we're going to
design the perfect drug.

198
00:11:39,490 --> 00:11:43,360
So said Dr Evil Paul ha ha, we're going
to design the perfect drug, right?

199
00:11:44,110 --> 00:11:47,830
Okay. Also, AI can be used for
good. It can be used for evil.

200
00:11:48,220 --> 00:11:52,720
It's up to you to use it for good. All
right. This is your responsibility.

201
00:11:53,200 --> 00:11:55,000
You are the chosen one.
All right.

202
00:11:55,001 --> 00:11:59,710
This is like star wars where you know
Obiwan was like you were the chosen one

203
00:11:59,730 --> 00:12:00,563
advocate.

204
00:12:00,700 --> 00:12:05,110
You were supposed to use the
right tools of AI for solving guy.

205
00:12:05,800 --> 00:12:09,430
Okay, so history of ml in drug
discovery. What is the history of him?

206
00:12:09,580 --> 00:12:12,310
What has been done here? So that's
the question that I'm trying to ask.

207
00:12:12,490 --> 00:12:15,910
Here's this paper that used recurrent
networks. Okay, I have a link to it.

208
00:12:16,000 --> 00:12:17,530
We're not going to go
over the whole paper.

209
00:12:17,890 --> 00:12:19,090
We're just going to
look at it a little bit.

210
00:12:19,120 --> 00:12:23,050
Generating focus molecule libraries for
drug discovery with recurrent neural

211
00:12:23,051 --> 00:12:23,884
networks.

212
00:12:25,260 --> 00:12:29,820
What they did was they considered this a
classification problem where they had a

213
00:12:29,821 --> 00:12:34,821
database of drugs and whether or not
they made a certain disease active or

214
00:12:34,951 --> 00:12:35,701
inactive,
right?

215
00:12:35,701 --> 00:12:39,660
So in that there's a bunch of different
ways that we can class this problem,

216
00:12:39,661 --> 00:12:42,390
right? We can say this is going
to be a supervised problem.

217
00:12:42,660 --> 00:12:45,420
We can say this is going to
be an unsupervised problem.

218
00:12:45,720 --> 00:12:48,300
We can say this is going to be
a generative generative problem,

219
00:12:48,301 --> 00:12:51,600
a discriminator problem. And
this case, they classified it.

220
00:12:52,020 --> 00:12:55,500
Metta as a classification,
supervise problem with labels.

221
00:12:55,620 --> 00:12:57,510
So the in their drug database,
they said,

222
00:12:57,511 --> 00:13:02,070
well we know that these certain drugs
made these diseases active or inactive.

223
00:13:02,310 --> 00:13:03,930
So let's learn that mapping.

224
00:13:04,110 --> 00:13:07,200
And then given some new drug will be
able to predict whether or not it would

225
00:13:07,201 --> 00:13:11,610
work, right? So for, for our target and
what they used was a recurrent network.

226
00:13:11,670 --> 00:13:15,120
And the reason they use a recurrent
network is because recurrent networks are

227
00:13:15,121 --> 00:13:18,420
really good at predicting sequences.
And when we look at these drugs,

228
00:13:18,600 --> 00:13:22,770
the fingerprint of these drugs can be
broken down into a bunch of ones and Zeros

229
00:13:23,010 --> 00:13:25,050
or different letters,
different chemicals, right?

230
00:13:25,200 --> 00:13:30,000
What is a sequence of chemicals that's
going to be ideal for curing this disease?

231
00:13:31,390 --> 00:13:33,760
Okay? So they did that. Another effort,

232
00:13:33,761 --> 00:13:35,980
and I'm just going to show you
this one more before we get to our,

233
00:13:36,160 --> 00:13:40,210
our real demo is this paper which
use convolutional networks, right?

234
00:13:40,211 --> 00:13:44,740
So convolutional networks are good for
detecting or for classifying images.

235
00:13:45,010 --> 00:13:46,330
They called this Adam Net,

236
00:13:46,390 --> 00:13:51,190
a deep convolutional network
for bioactivity prediction
in structure based drug

237
00:13:51,191 --> 00:13:55,420
discovery. So how can we flip frame
this as an image classification problem,

238
00:13:55,421 --> 00:13:57,910
right?
So if we look at this B right here,

239
00:13:58,210 --> 00:14:02,470
what they did was they use this network
to predict the bio activity of small

240
00:14:02,471 --> 00:14:05,530
molecules for drug discovery applications,
right?

241
00:14:05,531 --> 00:14:10,531
So what we can see is an image using
a microscope of the bio activity of a

242
00:14:11,231 --> 00:14:13,150
certain drug.
What are the patterns?

243
00:14:13,240 --> 00:14:16,930
How are these molecules moving in which
direction, how are they interacting?

244
00:14:16,990 --> 00:14:20,470
And we can see all of that and we
can classify it and we can say, well,

245
00:14:20,500 --> 00:14:24,850
this is how the bioactivity is and
here's how it's interacting with this

246
00:14:24,880 --> 00:14:27,390
specific disease. Let's
learn the mapping. Well,

247
00:14:27,400 --> 00:14:30,340
let's just keep doing that for all
of these different diseases, right?

248
00:14:30,460 --> 00:14:32,890
And so then given a new
image of a new type of drug,

249
00:14:33,100 --> 00:14:35,830
it can learn the mapping of
always likely to solve this.

250
00:14:37,080 --> 00:14:40,770
So that's what they did for that,
right? They used on input layer,

251
00:14:40,771 --> 00:14:42,470
multiple d convolutional layers,

252
00:14:42,480 --> 00:14:45,180
fully connected layers and
a logistic costs layer.

253
00:14:45,181 --> 00:14:48,290
That's just standard really when it
comes to convolutional neural networks.

254
00:14:48,320 --> 00:14:52,130
By the way, I have an amazing
video on convolutional networks.

255
00:14:52,131 --> 00:14:56,060
If you search convolutional networks
Saroj on youtube first link,

256
00:14:56,360 --> 00:14:59,120
because I dominate this space on Youtube,

257
00:14:59,121 --> 00:15:01,910
back to generative adversarial networks.
So here is our,

258
00:15:02,240 --> 00:15:06,920
here is our demo. Okay, so gans and
I've talked about these as well,

259
00:15:07,190 --> 00:15:11,240
but just not in this like
applicable real world use case.

260
00:15:11,810 --> 00:15:15,500
Gans are awesome. They were invented
about two years ago by a friend of mine,

261
00:15:15,530 --> 00:15:19,520
Ian Goodfellow and what they are are two
different neural networks and the idea

262
00:15:19,521 --> 00:15:23,540
is that they are adversaries, right?
One network is the discriminator.

263
00:15:23,541 --> 00:15:26,300
The other network is the generator.
Let's start with a generator.

264
00:15:26,390 --> 00:15:31,000
The generator job is to generate some
image based on some sample data set.

265
00:15:31,010 --> 00:15:35,090
Let's just say in our case it's a
sample drug dataset. I'm just going to,

266
00:15:35,150 --> 00:15:39,470
the generation is going to generate
some novel drug and say, Oh, here we go.

267
00:15:39,680 --> 00:15:42,980
The discriminators job is to take that
output from the generator and say,

268
00:15:43,280 --> 00:15:46,520
is this a real drug? Is it, is it
really from the database, you know,

269
00:15:46,521 --> 00:15:50,060
a binary input output,
or is it a fake one and it'll,

270
00:15:50,120 --> 00:15:54,200
it'll judge it and then it'll keep
going. Right? So what's happening?

271
00:15:54,230 --> 00:15:58,280
And they're both being updated via synth,
via gradient descent,

272
00:15:58,370 --> 00:16:00,440
which is an optimization
strategy over time.

273
00:16:01,100 --> 00:16:03,800
Watch my build a neural net in four
minutes video to learn more about that.

274
00:16:03,920 --> 00:16:08,090
Also backpropagation in five minutes I
have contents about every single word I'm

275
00:16:08,091 --> 00:16:11,090
talking about in video form.
Anything you don't understand,

276
00:16:11,240 --> 00:16:16,000
just search Saroj and then the, the topic,
the literally I am that certain I have,

277
00:16:16,100 --> 00:16:20,390
I have a video on everything when it
comes to deep learning at this point. So,

278
00:16:21,620 --> 00:16:21,950
okay.

279
00:16:21,950 --> 00:16:24,200
And of tag my video as well.
So you will find them.

280
00:16:25,760 --> 00:16:28,430
The discriminator is learning
and the generator is learning.

281
00:16:28,431 --> 00:16:32,780
The generator is learning to get better
and better at generating images or you

282
00:16:32,781 --> 00:16:32,901
know,

283
00:16:32,901 --> 00:16:37,370
whatever drugs that look very real and
the discriminator is getting better and

284
00:16:37,371 --> 00:16:39,230
better at detecting what's
real and what's fake.

285
00:16:39,380 --> 00:16:43,070
So they're both getting better and better
over time. It's like a mini Max game,

286
00:16:43,540 --> 00:16:46,970
uh, like with a Nash equilibrium
to get more technical.

287
00:16:46,971 --> 00:16:49,970
I have a great video on gangs as well.
We're not going to go into the deep,

288
00:16:49,971 --> 00:16:53,690
deep details here. My point is that this
is, I had a high level how it works.

289
00:16:53,691 --> 00:16:55,010
We'll get into the code at the end.

290
00:16:55,490 --> 00:16:59,690
And what they did was these
researchers for Chem Gan, uh,

291
00:16:59,700 --> 00:17:01,970
they applied this to generate new drugs.

292
00:17:02,860 --> 00:17:03,450
Okay.

293
00:17:03,450 --> 00:17:06,180
Right? So I didn't, I'm just, I'm
just like winging it from my brain.

294
00:17:06,181 --> 00:17:07,260
Like how this works.
Well,

295
00:17:07,261 --> 00:17:10,890
we've got this beautiful help her
image here to add some clarification.

296
00:17:11,070 --> 00:17:13,680
The generator is using random noise.
It,

297
00:17:13,730 --> 00:17:18,660
that's all it starting from as its input
and then it's generating a, an output.

298
00:17:18,810 --> 00:17:21,270
And at first of course it's
output's going to look like nothing.

299
00:17:21,600 --> 00:17:24,210
But because both of these,

300
00:17:24,750 --> 00:17:27,810
both of these networks are
updated using backpropagation,

301
00:17:28,080 --> 00:17:32,100
the same gradient that's used to update
the generator is used to update the

302
00:17:32,101 --> 00:17:34,470
discriminator.
So that random noise,

303
00:17:34,560 --> 00:17:37,440
those layers that it has
to go through over time,

304
00:17:37,560 --> 00:17:42,000
those layers are going to apply certain
matrix operations to that input data

305
00:17:42,150 --> 00:17:46,890
such that the output is more likely to
look like what the real sample data looks

306
00:17:46,891 --> 00:17:47,724
like.

307
00:17:47,860 --> 00:17:48,280
Okay.

308
00:17:48,280 --> 00:17:51,560
And the same for the discriminator.
So

309
00:17:53,870 --> 00:17:57,800
Dan's had been used for
all sorts of things from
generating images of faces that

310
00:17:57,801 --> 00:18:02,180
look real, but they're not, they've
been used for generating, um, music,

311
00:18:02,210 --> 00:18:06,530
all sorts of different data types. Right.
So well, what about molecules? Right?

312
00:18:06,531 --> 00:18:10,250
What about drugs? Can we use
gans to generate drugs? Well,

313
00:18:11,160 --> 00:18:11,930
okay,

314
00:18:11,930 --> 00:18:14,690
there's a type of Gan that we could
use that the people in this paper,

315
00:18:14,860 --> 00:18:17,960
the researchers use called an
adversarial auto encoder, right?

316
00:18:17,961 --> 00:18:18,950
So here's how it works.

317
00:18:19,220 --> 00:18:23,780
The idea is to learn to generate objects
from their latent distributions, right?

318
00:18:23,781 --> 00:18:27,680
So with, when it comes to an auto
encoder, th the, the output, their input.

319
00:18:27,920 --> 00:18:31,130
So you input an image and it will output
that image. And you might be thinking,

320
00:18:31,131 --> 00:18:34,370
why, why is that useful? What's
useful is not that output.

321
00:18:34,390 --> 00:18:37,520
It is the learned late
tint representation, right?

322
00:18:37,670 --> 00:18:41,960
That is the compressed version of that
image. It represents the same image,

323
00:18:42,020 --> 00:18:46,820
but in a compressed space, right? A
latent space. And once we have that space,

324
00:18:47,030 --> 00:18:49,250
what they did was they
used this light and space,

325
00:18:49,310 --> 00:18:53,300
the Gen generate molecules from,
right? So it looks like this.

326
00:18:53,960 --> 00:18:56,510
So it will learn that
latent love representation,

327
00:18:56,511 --> 00:19:00,570
which is a set of features that encode
the input in such a way that afterwards,

328
00:19:00,571 --> 00:19:03,950
this subsequent layers can
decode that object back.

329
00:19:06,450 --> 00:19:10,410
So they took this conditional auto
encoder and trained it to generate

330
00:19:10,411 --> 00:19:12,690
fingerprints.
That's just the collection of drugs,

331
00:19:13,200 --> 00:19:16,650
of molecules using and serving
desired properties as conditions.

332
00:19:16,651 --> 00:19:20,520
These conditions are different features
that are encoded as numbers that are

333
00:19:20,521 --> 00:19:22,620
then applied to the input by applied,

334
00:19:22,800 --> 00:19:24,900
we're using some kind of
matrix multiplication, right?

335
00:19:25,410 --> 00:19:30,060
And then eventually it's going to be
able to generate drugs that look real,

336
00:19:30,870 --> 00:19:32,910
but they're actually fake and they're new.
They're,

337
00:19:32,911 --> 00:19:36,990
they're novel drugs that have never been
applied to any of these use cases for

338
00:19:36,991 --> 00:19:37,824
these diseases.

339
00:19:38,010 --> 00:19:41,610
And eventually we'll be able to take
that drug combination and apply it in

340
00:19:41,611 --> 00:19:44,580
clinical trials and then people
can use it and it would work.

341
00:19:44,760 --> 00:19:49,170
And this would speed up that whole first
and second part of this process that I

342
00:19:49,171 --> 00:19:54,040
talked about by orders of
magnitude and also also the,

343
00:19:54,320 --> 00:19:59,100
the deep learning community took,
um, took note of this, right?

344
00:19:59,101 --> 00:19:59,791
So by the way,

345
00:19:59,791 --> 00:20:03,330
a simple screening of the database can
find molecules with the fingerprints most

346
00:20:03,331 --> 00:20:07,110
similar to the generated ones.
Yoshua Bengio, Yann Macun.

347
00:20:07,230 --> 00:20:10,740
These are the godfathers of deep learning.
They really, really like this idea,

348
00:20:10,741 --> 00:20:12,990
right? So here's the, here's
the most interesting part.

349
00:20:13,140 --> 00:20:16,110
They really liked this idea
and it didn't work that well.

350
00:20:16,111 --> 00:20:19,620
Like it didn't really work that well
because there was some tweak that was

351
00:20:19,621 --> 00:20:24,300
missing. So there's basically, there's a
lot of opportunity in this space. Okay,

352
00:20:24,301 --> 00:20:27,960
so check this out. Chem Gan. Let's
take a look at this in the model.

353
00:20:29,150 --> 00:20:29,680
Yeah.

354
00:20:29,680 --> 00:20:34,320
What do they got here? They got
Ogun Dot Pie. Again, the pie.

355
00:20:34,490 --> 00:20:37,070
So here's the, here's one of their
mall. They had several models,

356
00:20:37,071 --> 00:20:39,080
but we're going to look at a few of them.
Okay.

357
00:20:39,081 --> 00:20:41,930
So they've got hyper parameters
for both the generator. Okay.

358
00:20:41,931 --> 00:20:43,490
We've got a number of hidden dimensions.

359
00:20:43,760 --> 00:20:46,160
They've got hyper parameters for
the discriminator. By the way,

360
00:20:46,161 --> 00:20:49,540
you can download all of these
models from get hub in the read me,

361
00:20:49,541 --> 00:20:51,340
they have instructions on how to install,

362
00:20:51,341 --> 00:20:54,550
how to run them and you can run
them just like that. If not,

363
00:20:54,580 --> 00:20:58,480
if you don't want to run them on your
local machine cause you don't have a Gpu,

364
00:20:58,610 --> 00:21:02,290
I don't have a good one. You can use
a cloud service Floyd hub. It's great.

365
00:21:02,320 --> 00:21:05,770
I love it.
It's a layer on top of AWS that takes us,

366
00:21:05,820 --> 00:21:09,460
it takes away a lot of the complexity so
you can very, very quickly get started.

367
00:21:09,460 --> 00:21:11,440
No, they didn't pay me. I
just think it's very cool.

368
00:21:11,980 --> 00:21:16,680
So it's like Heroku for deep learning.
Great tagline by the way. Um,

369
00:21:16,750 --> 00:21:19,390
so the, the key here is that
they're both neural networks.

370
00:21:19,630 --> 00:21:22,910
We can build them with care os, we
can build them with tensorflow. Uh,

371
00:21:23,050 --> 00:21:26,050
but the idea is still the same.
And both of these networks,

372
00:21:26,051 --> 00:21:29,230
you've got a generator or you've got a
discriminator we'll train at the same

373
00:21:29,231 --> 00:21:33,190
time, right? So in this case, they use
tensor flow to do this and they said,

374
00:21:33,191 --> 00:21:36,610
let's define what the discriminator
looks like and we're going to train the

375
00:21:36,611 --> 00:21:41,611
discriminator using the samples generated
right here on to 70 by the generator.

376
00:21:41,651 --> 00:21:45,430
We're going to feed it those samples
and notice that there are two loss

377
00:21:45,431 --> 00:21:47,680
functions, right? There is a
loss function for the generator.

378
00:21:47,890 --> 00:21:51,190
There's a loss function
for the discriminator and
they're both being trained

379
00:21:51,191 --> 00:21:54,160
over time, right? Both loss functions
are being trained over time.

380
00:21:54,700 --> 00:21:56,860
And eventually once this model is trained,

381
00:21:56,861 --> 00:22:00,970
they're going to save it to
disk as a binary file, and
they could use that model,

382
00:22:00,971 --> 00:22:02,020
then they could serve it.

383
00:22:02,050 --> 00:22:05,350
They're using tensorflow here so they
can serve it using tensorflow serving,

384
00:22:05,500 --> 00:22:09,460
which is a great tool for
serving tensorflow, tensorflow,
models in the cloud,

385
00:22:09,461 --> 00:22:13,090
right? Tensorflow serving. This is how you
serve tensorflow, models in production.

386
00:22:13,300 --> 00:22:15,130
You can also use tensorflow. Dot. Js.

387
00:22:15,160 --> 00:22:19,300
It's very simple to use Eden
models trained in python.
You could load up in js.

388
00:22:19,301 --> 00:22:21,820
It's amazing. I have a video on
that. By the time you see this,

389
00:22:21,821 --> 00:22:22,960
that video's going to be released.

390
00:22:23,140 --> 00:22:26,110
The check that out I to continuous
training pipeline. Okay,

391
00:22:26,111 --> 00:22:29,110
so there's a lot of potential here.

392
00:22:29,230 --> 00:22:31,900
I hope you found this video useful and uh,
yeah,

393
00:22:32,050 --> 00:22:34,480
please subscribe for more
programming videos. And for now,

394
00:22:34,580 --> 00:22:37,090
I'm got to use tensorflow,
so thanks for watching.

