1
00:00:00,700 --> 00:00:04,030
Did her Duh, Duh, Duh Duh
Duh Duh Duh Duh Duh, Duh.

2
00:00:04,720 --> 00:00:07,890
I've been listening to a lot
of classical, hey, my live,

3
00:00:08,910 --> 00:00:12,870
I must be live right now because I hit
the live button. I can't see myself.

4
00:00:12,871 --> 00:00:17,250
So I always have to wait like 15
seconds or so. There I am. Okay, great.

5
00:00:17,750 --> 00:00:20,820
I agree. Oh, we're all,
it's Saroj. How's it going?

6
00:00:22,020 --> 00:00:22,950
Uh,

7
00:00:22,951 --> 00:00:27,951
so today we are here live and we're
going to make some word vectors out of a

8
00:00:27,991 --> 00:00:32,190
series of books called game of Thrones.
If you know game of Thrones,

9
00:00:32,191 --> 00:00:35,580
give it a shout out in the,
in the comments. Let's see
who knows what this is.

10
00:00:35,700 --> 00:00:36,660
It doesn't matter if you don't.

11
00:00:36,661 --> 00:00:41,130
The point is we are learning about the
concept of word vectors and we want to

12
00:00:41,460 --> 00:00:46,020
take some books and make them into
vectors. And once we have these vectors,

13
00:00:46,320 --> 00:00:48,690
we're going to do a bunch of really
cool stuff with it. All right,

14
00:00:48,960 --> 00:00:51,330
so who's in the house?
Let me name some names.

15
00:00:51,331 --> 00:00:55,980
We got Jake Akash party to hair,
teddy recky party.

16
00:00:56,430 --> 00:01:00,720
Ricardo Angel got a lot of
people in the house. All right,

17
00:01:01,020 --> 00:01:02,460
so, okay. Uh,

18
00:01:02,670 --> 00:01:06,870
let's go ahead and do a five minute Q and
a and then we're going to get into the

19
00:01:06,871 --> 00:01:07,171
code.

20
00:01:07,171 --> 00:01:12,171
It's going to be an IP on notebook and
I'm going to give you guys a the data set

21
00:01:12,571 --> 00:01:15,810
as well. So a five minute Q
and. A. Let's get started.

22
00:01:30,610 --> 00:01:35,330
Glove or word to Vec. We're
using word to VEC, not glove. Uh,

23
00:01:35,380 --> 00:01:38,470
although glove is similar also.
I haven't used gloves before,

24
00:01:38,471 --> 00:01:43,260
but I've heard good things.
Another question.

25
00:01:43,410 --> 00:01:47,250
Best character in game of
Thrones. Uh, to be honest,

26
00:01:47,251 --> 00:01:50,760
I don't even read game of Thrones.
I just picked it because I thought it was,

27
00:01:50,790 --> 00:01:52,140
I thought the,
I think the idea is cool.

28
00:01:52,141 --> 00:01:56,880
I don't have time to read anything or
watch TV shows and any more I'm just

29
00:01:56,881 --> 00:02:00,330
focused on content. Uh, any
mass we are going to do. Yes.

30
00:02:00,331 --> 00:02:03,360
We're going to do some math. We're
going to use the co sign similarity, uh,

31
00:02:03,361 --> 00:02:07,260
as a measure of distance between
word vectors. It's a corpus. Yes,

32
00:02:07,261 --> 00:02:10,320
it's five different books, but we're
going to treat it as one big corpus.

33
00:02:10,650 --> 00:02:15,000
Please say my name to use. Okay. I'm okay.

34
00:02:15,001 --> 00:02:17,430
Doing the deep learning foundation
and feeling utterly lost.

35
00:02:17,431 --> 00:02:20,610
Keep pushing through or go back to
school. Okay guys, listen. Okay.

36
00:02:20,640 --> 00:02:22,290
So clearly this is,

37
00:02:22,560 --> 00:02:27,560
there's a lot of stuff in deep learning
and there's a lot of math and from what

38
00:02:29,071 --> 00:02:31,890
I've read, I have taken your
feedback into consideration.

39
00:02:32,580 --> 00:02:35,730
We need to really dive into
the math and we're going to,

40
00:02:35,760 --> 00:02:38,940
we're going to go so deep into
the math and the next video. Okay.

41
00:02:39,090 --> 00:02:42,770
So the next weekly video, get ready. We
are going to really dive into the math.

42
00:02:43,050 --> 00:02:45,750
Please say my name. Colon. What's a word?
Vector. I'll explain that in a second.

43
00:02:46,050 --> 00:02:50,820
Cleaned the camera. There's
moisture. Okay. Okay.

44
00:02:51,430 --> 00:02:55,440
Um, video isn't clear at
bro. Okay. Uh, can't help.

45
00:02:55,441 --> 00:02:58,620
That right now is opening. I
worth to explore. Yes. One minute.

46
00:02:58,621 --> 00:03:03,400
Wrap before I love you rap. I'll do
that. Um, yeah, I'll do that. Um,

47
00:03:04,030 --> 00:03:05,050
let me answer some more questions.

48
00:03:05,170 --> 00:03:08,380
How can I classify images from a live
feed and put the output in a file from a

49
00:03:08,381 --> 00:03:13,270
live feed? You'd want to, Oh
man. In a live feed. I can we,

50
00:03:13,300 --> 00:03:14,520
well we know how to do it recorded,

51
00:03:14,530 --> 00:03:19,450
but in a live feed you'd want a
live classifier to look at this,

52
00:03:19,730 --> 00:03:22,060
to look at your screen or
maybe segment the screen.

53
00:03:22,061 --> 00:03:25,940
So you'd want to use probably Java script
for that. Javascript would be easy. Uh,

54
00:03:25,960 --> 00:03:30,160
con net dot. Js Andre car, these
library would be great for that.

55
00:03:30,430 --> 00:03:33,100
The Cam looks dirty. Hey
Man, I was just at the beach.

56
00:03:33,370 --> 00:03:36,100
I'm recording some cool stuff.
Uh,

57
00:03:36,970 --> 00:03:39,400
predict who dies using word vectors
that that's gonna be possible.

58
00:03:39,570 --> 00:03:41,200
Are you going to use tensorflow for this?
No,

59
00:03:41,201 --> 00:03:45,850
we're going to use a word two VEC and
we're going to use a bunch of other

60
00:03:45,851 --> 00:03:49,360
smaller libraries. All right. Okay.

61
00:03:49,361 --> 00:03:53,260
So one more question and then
we're going to get started.

62
00:03:55,920 --> 00:03:57,270
Okay.
Here we go.

63
00:04:04,350 --> 00:04:09,240
If we increased vocab size by adding
words, will that help? Yes, yes. It helps.

64
00:04:10,110 --> 00:04:15,060
It helps if, if, well, it helps if,
um, if the words are relevant to that,

65
00:04:15,061 --> 00:04:19,450
to the problem we're trying to solve,
uh, if, if they're relevant to the, uh,

66
00:04:20,830 --> 00:04:23,730
the story which is game of
Thrones in this case. Okay.

67
00:04:23,731 --> 00:04:26,880
So that's it for the questions.
Let's get started with this.

68
00:04:26,881 --> 00:04:30,760
I'm going to start screen sharing. It's
going to be an eye python notebook. Uh,

69
00:04:30,800 --> 00:04:33,690
and then we're going to, oh,
that's right. Iraq. Uh, let's,

70
00:04:33,691 --> 00:04:37,890
let's do a little wrapper seconds.
Um, uh, let me do a wrap on vectors.

71
00:04:40,260 --> 00:04:44,420
Vectors, right. Okay. So it
starts with Troy with the
wrap. Okay. Uh, here we go. Ah,

72
00:04:45,030 --> 00:04:49,860
I rap about vectors. I do it man.
Cause I'm victor, victor, Victor.

73
00:04:49,890 --> 00:04:51,090
What?
The Vector Victor,

74
00:04:51,091 --> 00:04:55,380
I'm on a plane going crashing down
like my mind is a scalar scalar.

75
00:04:55,381 --> 00:04:59,580
Clouds going down. Stay low.
Clouds go away. No, I see one, two,

76
00:04:59,581 --> 00:05:03,510
three in the sky and it's my enemy.
No, it's not. It's just mine.

77
00:05:03,810 --> 00:05:07,320
And I'm going to fly back to this screen.
So here we go. That was it for the rap.

78
00:05:07,790 --> 00:05:09,990
And let's get started because
we are getting serious guys.

79
00:05:09,991 --> 00:05:14,070
This is all about words that gets us
an English favorite movie. The Matrix,

80
00:05:14,940 --> 00:05:17,190
the matrix.
How about that?

81
00:05:17,220 --> 00:05:19,350
I'm just going to add to the list
of people who set the matrix.

82
00:05:19,530 --> 00:05:22,020
Let's get started.
This is an NLP session.

83
00:05:22,021 --> 00:05:26,220
We're going to do some natural language
processing. Ready. Okay, let's,

84
00:05:26,221 --> 00:05:30,720
let's start screen sharing.
Let's start screen sharing.

85
00:05:45,080 --> 00:05:48,340
Okay.
Okay.

86
00:05:48,850 --> 00:05:53,560
Let me move you guys over
here. Okay. All right.

87
00:05:53,561 --> 00:05:58,280
So let's, uh, get started with this.
Let me make sure this is showing,

88
00:05:59,020 --> 00:05:59,853
hold on.

89
00:06:00,470 --> 00:06:02,090
Okay.
So,

90
00:06:03,360 --> 00:06:04,193
uh,

91
00:06:04,440 --> 00:06:07,750
we want to, let me just first
talk. Say we want to the, the,

92
00:06:07,760 --> 00:06:11,970
the goal is to create word vectors from,

93
00:06:12,450 --> 00:06:16,380
from, uh, game of Thrones, a Dataset.

94
00:06:16,530 --> 00:06:20,000
Now look guys, this is, these are just
the five books. Let me show you guys now.

95
00:06:20,001 --> 00:06:24,840
I'll just show you guys, uh,
and play with them and uh,

96
00:06:24,870 --> 00:06:28,740
and analyze them to see
semantic similarity. Okay,

97
00:06:29,460 --> 00:06:33,600
let's, let's look at what we've got here.

98
00:06:33,601 --> 00:06:38,370
So hold on. Uh, I can even show
you guys the Dataset for a second.

99
00:06:38,490 --> 00:06:42,330
So these are just the five
books for game of Thrones. Okay?

100
00:06:42,331 --> 00:06:44,400
There's literally just a
text files for the books.

101
00:06:44,700 --> 00:06:48,180
They are these huge text
files for the books. That's,
that's, that's all they are.

102
00:06:48,390 --> 00:06:52,800
Okay. And I just divided them. I
downloaded them from pirate bay.

103
00:06:52,950 --> 00:06:57,510
No regrets. Uh, you know what I'm saying?
So that's what, that's what this is.

104
00:06:57,570 --> 00:07:00,480
And that's it.
We've just got five books in the series.

105
00:07:00,690 --> 00:07:03,270
We're going to take all these books and
we're going to create word vectors from

106
00:07:03,271 --> 00:07:06,300
them. We're going to treat
it as one big corpus. Okay?

107
00:07:08,610 --> 00:07:12,050
So that's what we're going to do. So
let's just go dive right into this baby.

108
00:07:12,051 --> 00:07:12,650
All right.

109
00:07:12,650 --> 00:07:16,910
So the first thing we want to do is we
want to import our dependencies. Now,

110
00:07:17,090 --> 00:07:19,710
we've actually got a lot of
dependencies for this. Um,

111
00:07:19,820 --> 00:07:20,990
so I'm going to explain every single one.

112
00:07:20,991 --> 00:07:24,170
So the first one we want
to do is import future.

113
00:07:24,260 --> 00:07:25,730
And why do we want to import future?

114
00:07:25,731 --> 00:07:29,360
Can anyone tell me why in
the comments as I type this,

115
00:07:29,570 --> 00:07:33,200
the reason we want to import future is
because it's the missing link between

116
00:07:33,201 --> 00:07:38,000
python two and python three.
It allows us to use the syntax from both.

117
00:07:38,140 --> 00:07:40,550
It's, it's kind of like a bridge
between the two languages,

118
00:07:40,551 --> 00:07:43,340
and we're going to import three functions
that we're going to use for this. Okay?

119
00:07:43,550 --> 00:07:47,390
So that's the first step. Uh,
once we have that, we want to, uh,

120
00:07:48,290 --> 00:07:50,170
we're gonna,
we're gonna encode our words.

121
00:07:50,171 --> 00:07:54,210
So we're going to end for word and coding.
How,

122
00:07:54,240 --> 00:07:57,720
how are we going to encode our words
while we're going to use codex.

123
00:07:58,350 --> 00:08:03,350
The next one is we're going to perform
some red rejects and Reggie [inaudible]

124
00:08:03,600 --> 00:08:06,050
is basically whenever we want to,
uh,

125
00:08:08,370 --> 00:08:11,430
we went to like search and file
really fast. That's, that's,

126
00:08:11,460 --> 00:08:14,390
that's all about Red Jack's.
It's, it's uh, it's a,

127
00:08:14,740 --> 00:08:19,740
it's a way of like quickly and efficiently
searching through a large text or

128
00:08:20,281 --> 00:08:23,490
number database for what you need.
Uh, the next one is for logging.

129
00:08:23,491 --> 00:08:26,250
So actually we don't need it. We
need, we don't need to log. Oh,

130
00:08:26,520 --> 00:08:29,660
now I actually have been talking
about concurrency before.

131
00:08:29,670 --> 00:08:30,750
So this is going to be interesting.

132
00:08:31,080 --> 00:08:34,170
We're going to import this multiprocessing
library to perform concurrency.

133
00:08:34,171 --> 00:08:35,100
And if you don't know,

134
00:08:35,430 --> 00:08:40,430
concurrency is a way of running multiple
threads and having each thread run a

135
00:08:40,531 --> 00:08:42,390
different process. So it's, it's, it's,

136
00:08:42,420 --> 00:08:45,750
it's multithreading multiprocessing
it's a way of moving.

137
00:08:45,840 --> 00:08:48,720
It's a way of having your
program run faster. Okay.

138
00:08:48,750 --> 00:08:50,940
And I haven't talked about this before,

139
00:08:50,941 --> 00:08:52,710
but we're going to do
this a lot in the future,

140
00:08:52,830 --> 00:08:55,560
especially when we get to
distributed machine learning, uh,

141
00:08:55,561 --> 00:08:59,400
which is later on in this course. Okay.
So, so that's it for multiprocessing.

142
00:08:59,401 --> 00:09:02,860
The next one is dealing with the
operating system operating system. Uh,

143
00:09:02,970 --> 00:09:04,680
like we want to like reading a file,

144
00:09:04,920 --> 00:09:09,780
like reading a file and for that we will
want to use pos module and then we want

145
00:09:09,781 --> 00:09:13,410
to do some pretty printing, make it
human readable. And how do we do that?

146
00:09:13,411 --> 00:09:17,740
We were going to import pretty
cranky. Cranky for sure. Okay. Uh,

147
00:09:18,630 --> 00:09:22,790
the next one is more regular expression.
So glob was uh,

148
00:09:22,910 --> 00:09:25,350
and I think has a different tier,
but this is for,

149
00:09:25,950 --> 00:09:29,670
this is for a more granular
regular expressions. So this is,

150
00:09:29,730 --> 00:09:31,380
so this is like step one by the way.

151
00:09:31,381 --> 00:09:34,800
It's like step zero important dependencies
and I've got a few more and then

152
00:09:34,801 --> 00:09:38,280
we're going to get started with the
actual logic of the code. Okay. So, uh,

153
00:09:38,281 --> 00:09:38,761
what else do we got?

154
00:09:38,761 --> 00:09:42,600
We got the natural language tool kit
cause we're gonna be using NLTK. Okay.

155
00:09:42,720 --> 00:09:45,070
Natural language tool. Let me show
you guys an Ltk for a second. If you,

156
00:09:45,071 --> 00:09:48,640
if you don't know now, you know, let
me show you guys lck because NLP, Kay,

157
00:09:48,670 --> 00:09:52,290
I made videos about this
before is bullshit. Okay?

158
00:09:52,320 --> 00:09:56,940
NLTK is awesome. It is so easy to use.
Let me zoom in on this thing. Okay.

159
00:09:57,210 --> 00:10:00,400
Literally it can tokenize San
Francisco and single cent.

160
00:10:00,500 --> 00:10:01,680
We'll single lines of code.

161
00:10:01,681 --> 00:10:04,440
So if you have a sentence like at
eight o'clock on Thursday morning,

162
00:10:04,470 --> 00:10:07,800
Arthur didn't feel very good. You,
you feed that to NLT and boom,

163
00:10:07,830 --> 00:10:11,460
it'll give you the tokens for each
word. Why is this useful? Well,

164
00:10:11,461 --> 00:10:15,420
you can have part of speech tagging,
Pos tagging that, which means like, oh,

165
00:10:15,421 --> 00:10:19,200
is this a noun? It's a verb. Is this
a CD? How does it know these things?

166
00:10:19,201 --> 00:10:23,790
Because it has a pre trained, well,
it says it's actually two things.

167
00:10:24,060 --> 00:10:28,620
It's for some, for some of it, it's got
a pretrained model, which a trained,

168
00:10:28,860 --> 00:10:32,620
uh, and the, and another part of Nltk
is, it's got, it's, it's using the, uh,

169
00:10:33,090 --> 00:10:37,290
which I talked about in the last
video, which is the, uh, uh,

170
00:10:37,890 --> 00:10:41,550
like having that, that database, a
prerecorded sentiments. The lexicon,

171
00:10:41,551 --> 00:10:44,400
that's the word I'm looking for. All
right, so then we're going to talk,

172
00:10:44,430 --> 00:10:47,940
we're going to use word to Vec now work
to beck is the shit that is what we are

173
00:10:47,941 --> 00:10:50,610
going to use.
That is the real meat of this code.

174
00:10:50,640 --> 00:10:54,180
And I'm going to really deep dive into
what word to Vec is at a high level right

175
00:10:54,181 --> 00:10:57,170
now. Worked with that is
what Google created, uh,

176
00:10:57,270 --> 00:11:00,180
to basically they trained are,
they trained a machine,

177
00:11:00,240 --> 00:11:04,990
the their own network on a huge
dataset of word vectors for,

178
00:11:05,250 --> 00:11:08,700
and it created back and we can
use these directors in other ways.

179
00:11:08,700 --> 00:11:11,750
So it's like a generalized
collection of word vectors. Okay.

180
00:11:11,770 --> 00:11:14,040
So where I'm going to talk about,
I'll listen to a second.

181
00:11:14,041 --> 00:11:16,890
Let me just keep coming out. These
dependencies, the neck length,

182
00:11:16,891 --> 00:11:19,560
dimensionality reduction.
Once we have our word vectors,

183
00:11:19,780 --> 00:11:21,030
they're going to be multidimensional.

184
00:11:21,031 --> 00:11:24,240
They're going to be 300 plus
dimension word vectors, okay.

185
00:11:24,241 --> 00:11:28,380
Because they're so generalized and we
want to plot them on a two d graph so we

186
00:11:28,381 --> 00:11:30,950
can see them. And how are we going to
do that? Well, we're going to perform,

187
00:11:30,951 --> 00:11:33,210
I could a technique called
dimensionality reduction.

188
00:11:33,540 --> 00:11:37,440
I have a video on this called,
uh,

189
00:11:37,590 --> 00:11:41,790
visualize in a set, easily. Check it out,

190
00:11:42,480 --> 00:11:47,130
check it out. Okay. Now, so then
we're going to start our math library,

191
00:11:47,131 --> 00:11:51,990
which has none Pi. And then we're
going to import a plot thing library,

192
00:11:52,020 --> 00:11:55,750
which is going to be Matt Line.
And finally

193
00:11:57,490 --> 00:12:00,970
we're going to, uh, what's the next one?

194
00:12:02,410 --> 00:12:06,360
Arts. Well, of days that we
got one more after this. So
many libraries. But no, it's,

195
00:12:06,410 --> 00:12:09,070
it's, it's important because
right now we're talking, I,

196
00:12:09,130 --> 00:12:11,890
we want to talk about the concepts
here and we're going to dive into these

197
00:12:12,130 --> 00:12:15,130
specific processes later on. Okay? Uh,

198
00:12:15,460 --> 00:12:19,840
so import pandas as PD.
And lastly,

199
00:12:19,841 --> 00:12:21,850
here's the last one.
Visualization. Seaborne.

200
00:12:22,060 --> 00:12:26,770
Seaborne is going to help us visualize
our data set. Okay. As that's an s okay.

201
00:12:26,860 --> 00:12:31,240
That's it for our dependencies.
Boom. All right. No. Okay.

202
00:12:31,241 --> 00:12:36,020
So now that we've done that,
uh,

203
00:12:36,650 --> 00:12:39,650
we are going to, we're not using
pretrained word vectors. We are,

204
00:12:39,830 --> 00:12:44,300
we are using word vectors that we
train in real time. Uh, let's see.

205
00:12:44,330 --> 00:12:47,900
No model named pipe ply
lot. Oh, pipe plot by plot.

206
00:12:48,980 --> 00:12:52,760
No model named bananas. Oh, pandas.
So this just why I love python,

207
00:12:52,990 --> 00:12:55,970
python notebooks. Okay. So,
uh, okay, so that was that.

208
00:12:56,090 --> 00:12:59,090
Now our next step is to process our data.
Okay.

209
00:12:59,091 --> 00:13:03,660
So step one is to process our data.
What does this look like? Well,

210
00:13:03,710 --> 00:13:07,250
before we do anything, before we do
anything, we want to clean our data.

211
00:13:07,251 --> 00:13:09,230
So how do we clean our data?
Well,

212
00:13:09,300 --> 00:13:13,040
NLTK has a really handy
function for that as well.

213
00:13:13,190 --> 00:13:17,500
The first one is called punk and
the next one is called stop words.

214
00:13:17,510 --> 00:13:20,630
So what does this do?
What this does is it downloads

215
00:13:22,250 --> 00:13:25,170
punked downloads. Uh, it's a cocaine izer.

216
00:13:25,171 --> 00:13:29,140
It could pretrained tokenize or
there's a pretrained tokenize or,

217
00:13:29,160 --> 00:13:31,780
and what it's going to let
us do is tokenized our text.

218
00:13:31,780 --> 00:13:33,920
And remember I talked about
tokenization last time.

219
00:13:33,921 --> 00:13:38,480
Tokenization is where we take a
sentence or a word and we take, sorry,

220
00:13:38,600 --> 00:13:43,600
we take a piece of text and we split
it into tokens and those tokens to be

221
00:13:43,611 --> 00:13:47,150
sentences or words or even characters,
whatever we specialize.

222
00:13:47,450 --> 00:13:50,210
In this case we're going to do sentences.
Okay? So that's what punk does.

223
00:13:50,480 --> 00:13:54,740
And stop words are words
like and or sorry and, and,

224
00:13:55,730 --> 00:13:59,240
and a no of words that
don't really matter.

225
00:13:59,241 --> 00:14:01,520
They don't really have a
lot of semantic meaning.

226
00:14:01,730 --> 00:14:04,700
And we want to remove these words
and why do we want to do that?

227
00:14:04,850 --> 00:14:09,070
So that are our vectors that we create
are, are more accurate. Okay. So,

228
00:14:09,990 --> 00:14:14,060
so, so we done that and it's going
to download okay. And it says, okay,

229
00:14:14,061 --> 00:14:16,370
you've already got him. If we don't
have them, it's going to download it.

230
00:14:16,550 --> 00:14:19,280
The next step is to get the book name,

231
00:14:20,600 --> 00:14:25,200
I think the texts file. And now
like I said, we had been right here.

232
00:14:25,320 --> 00:14:29,870
So let me, let me make this bigger. Hey,

233
00:14:30,090 --> 00:14:33,490
here's our books right here today and
in textiles, so we can just say, okay,

234
00:14:33,491 --> 00:14:37,630
so get the book file
names, book file names, and

235
00:14:39,580 --> 00:14:40,580
before we use Glob,

236
00:14:40,640 --> 00:14:44,290
Robin's going to let us get those books
that just have that end in dot txt.

237
00:14:44,291 --> 00:14:47,950
Right? And it's going to print those out
for us. Make sure that we actually, uh,

238
00:14:48,300 --> 00:14:51,860
that we, that we actually
printed them. All right.

239
00:14:53,030 --> 00:14:57,680
The ends there and it
starts here. Okay, boom,

240
00:14:57,950 --> 00:15:02,150
boom. Okay. No, no, no, no,
no, no. There we go. Okay,

241
00:15:02,300 --> 00:15:06,010
so that's for our text file. And, uh,

242
00:15:06,110 --> 00:15:08,510
let me print out the books.
Let's print them out.

243
00:15:08,511 --> 00:15:11,240
Let's print them out and make
sure that we got them. File names

244
00:15:15,900 --> 00:15:20,340
sorted. glob.club. Let's
see what we got here. Dot.

245
00:15:20,341 --> 00:15:21,480
Txt.

246
00:15:24,960 --> 00:15:26,250
Um,
let's see.

247
00:15:29,540 --> 00:15:30,920
Hmm.
I,

248
00:15:31,250 --> 00:15:35,570
so we should have them
here and I guess we don't,

249
00:15:38,180 --> 00:15:42,890
then the problem is that we hold on

250
00:15:44,390 --> 00:15:46,460
sorted. Glob, duck, glob.

251
00:15:49,610 --> 00:15:53,120
Let's see. The, the,
hold on a second. So, um,

252
00:15:57,040 --> 00:15:59,230
let's see. Let's see, let's see. Uh,

253
00:16:03,040 --> 00:16:07,210
interesting. So what the,
what this is, is, um,

254
00:16:11,390 --> 00:16:13,460
fun.
Have.

255
00:16:18,280 --> 00:16:19,113
Okay,

256
00:16:23,260 --> 00:16:25,540
let's see. Let's see. Uh, okay.

257
00:16:29,770 --> 00:16:32,950
So, okay. Uh, so it seems like
they might be in the room. Yeah,

258
00:16:32,951 --> 00:16:33,784
they might be in the route.

259
00:16:40,250 --> 00:16:45,060
One second handle. What I can say is

260
00:16:50,270 --> 00:16:54,080
second
closing folder.

261
00:16:56,500 --> 00:16:57,333
Okay.

262
00:17:11,640 --> 00:17:12,473
Hold on one second.

263
00:17:15,540 --> 00:17:20,520
This is actually not,
oh,

264
00:17:20,521 --> 00:17:21,354
you're right. Right, right.

265
00:17:30,400 --> 00:17:33,390
Oh, what are people saying? Dot. Slash
okay. Hold on a second. Oh my God.

266
00:17:33,400 --> 00:17:35,990
Somebody's people saying
some shit. Hold on. Okay.

267
00:17:53,940 --> 00:17:54,860
Okay. Okay. Okay,

268
00:17:59,190 --> 00:18:03,560
so
let's get that current directory.

269
00:18:05,980 --> 00:18:10,180
Swear to God. This is so annoying
right now. Hold on. Okay,

270
00:18:14,020 --> 00:18:18,240
let's, okay, so, um,
hold on a sec. Okay. So,

271
00:18:20,630 --> 00:18:22,400
oh my God.
Okay.

272
00:18:29,500 --> 00:18:33,820
No, it's in tax book file names we talked
about. I just named them right here.

273
00:18:34,780 --> 00:18:36,700
Let's see.
Look file names.

274
00:18:40,850 --> 00:18:41,683
Oh,
that's like,

275
00:18:42,770 --> 00:18:43,603
yeah.

276
00:18:59,040 --> 00:19:00,400
Endowed Syntax.
Hold on.

277
00:19:03,800 --> 00:19:06,650
So we really don't have
time for errors like this.

278
00:19:08,180 --> 00:19:09,013
Okay.

279
00:19:09,150 --> 00:19:11,650
God.
Okay.

280
00:19:14,850 --> 00:19:15,391
Okay guys.

281
00:19:15,391 --> 00:19:19,320
So I actually had a comments with a
lot of up votes and the comment was we

282
00:19:19,321 --> 00:19:23,360
should just not spend time
actually writing out the
code and just show the code

283
00:19:23,361 --> 00:19:27,510
since I'm already reading
off of it anyway. Uh, so I
already have the code anyway,

284
00:19:27,511 --> 00:19:31,110
so why don't I just show you guys the
coat and I'm gonna explain it as we go.

285
00:19:31,111 --> 00:19:35,620
Okay. It's because seriously, I have,

286
00:19:36,270 --> 00:19:39,150
don't have time to look at why
this is not working right now.

287
00:19:42,260 --> 00:19:43,640
Prince book file names.

288
00:19:44,470 --> 00:19:45,303
Okay.

289
00:19:45,800 --> 00:19:50,180
That's exactly what it was. Okay. So we
don't, we don't have time for this. Okay.

290
00:19:50,181 --> 00:19:53,180
So let's just

291
00:19:55,110 --> 00:19:57,660
talk about this. Okay, let me,
let me move this over here. Okay.

292
00:19:59,170 --> 00:20:02,290
And I've got my notes here as well.
Okay. Hold on a second. So, okay,

293
00:20:03,130 --> 00:20:07,110
so where were we?
Let me,

294
00:20:07,320 --> 00:20:09,000
let me see if this actually works.

295
00:20:12,190 --> 00:20:16,590
Why, let me just, let me, let
me just, let me just talk.

296
00:20:16,591 --> 00:20:21,591
Let me just restart the toll I python
notebook and run this from scratch.

297
00:20:22,050 --> 00:20:24,270
Okay,
let's run it from scratch.

298
00:20:24,780 --> 00:20:28,770
I python notebook and let
me close out everything.

299
00:20:29,570 --> 00:20:30,000
Okay.

300
00:20:30,000 --> 00:20:33,220
And, okay, so here we go.
Hold on. That was I missed.

301
00:20:35,280 --> 00:20:40,200
Um, okay, so let's see,
let's have it. Give it to us.

302
00:20:41,850 --> 00:20:44,670
Okay.
And try out this one.

303
00:20:48,230 --> 00:20:51,680
Okay. So let's, let's just
run what we have here.

304
00:20:53,290 --> 00:20:57,420
I love in line populating log.
Log Log.

305
00:20:59,480 --> 00:21:00,313
Ooh,

306
00:21:01,150 --> 00:21:06,080
okay. Okay. CYL names.

307
00:21:06,650 --> 00:21:10,580
Okay. So clearly there is clearly
we're having a problem right now.

308
00:21:10,610 --> 00:21:15,380
And the point is let's just, okay, so
this is, this is pre compiled anyway and,

309
00:21:16,550 --> 00:21:18,530
and talking about what this is doing
and we're going to really deep dive into

310
00:21:18,531 --> 00:21:21,200
the important concepts here. Okay?
So we're going to keep going onwards.

311
00:21:21,201 --> 00:21:23,720
We don't have time to stop
with this right now. So okay.

312
00:21:23,721 --> 00:21:25,730
So we've got our book file names,
right?

313
00:21:25,731 --> 00:21:29,570
And we next time is to combine
the book that you want train.

314
00:21:29,571 --> 00:21:32,420
And why do we want to do this?
Because we want to have wine,

315
00:21:32,421 --> 00:21:34,970
a corpus for all those books.
And that's what this does.

316
00:21:35,210 --> 00:21:38,150
We initialize a rock
corpus, we say you, let me,

317
00:21:38,151 --> 00:21:39,960
let me make this bigger because we are,
we really want to,

318
00:21:40,570 --> 00:21:42,590
we start with you because it's Unicode,
right?

319
00:21:42,591 --> 00:21:46,400
It's a unicode string and we want
to convert it into a format that we,

320
00:21:46,430 --> 00:21:50,750
that we can read easily. And what does
that format? UTF eight right here. Okay,

321
00:21:50,751 --> 00:21:54,410
so you TFA. So this is where the
Codex library comes into play.

322
00:21:54,690 --> 00:21:58,900
We are using a codex library to read in
the book file name and convert it into

323
00:21:58,910 --> 00:22:00,260
UTF eight format.

324
00:22:00,500 --> 00:22:03,620
Now that remember that corpus raw
function we just initialize up here.

325
00:22:03,800 --> 00:22:07,550
Well now we want to add all of the
books that we see to that Corpus.

326
00:22:07,820 --> 00:22:09,440
And the way we're going to do that,

327
00:22:11,300 --> 00:22:16,300
the way we're going to do
that is we're going to add,

328
00:22:18,560 --> 00:22:21,020
we're going to add it all to this
corporate fraud. And at the end of it,

329
00:22:21,021 --> 00:22:25,310
it's going to have all of those books
in one in one variable in memory,

330
00:22:25,311 --> 00:22:29,780
corpus raw, okay. Which is
going to be a very, very, very
big Barrick variable. Okay?

331
00:22:30,200 --> 00:22:32,900
That's what we're going to do.
And so that's the first step.

332
00:22:32,930 --> 00:22:36,440
And once we have that, then we're going
to split the corpus into sentences.

333
00:22:36,650 --> 00:22:41,270
Now remember when I said we downloaded
that, uh, pumped a model right up here.

334
00:22:41,300 --> 00:22:43,680
Let me show you guys
nltk. Dot. Download punk.

335
00:22:43,970 --> 00:22:48,140
Well now we're going to actually load
that into memory that it's a trained model

336
00:22:48,141 --> 00:22:52,460
and it's, it's loaded in, it's in a byte
stream. And that's what pickle is. It's a,

337
00:22:52,640 --> 00:22:55,580
it's that file format that
we can load as a byte stream.

338
00:22:55,910 --> 00:22:58,060
Now that's what that does.

339
00:22:58,061 --> 00:23:00,520
And it's going to load it up
into this tokenize or variable.

340
00:23:00,910 --> 00:23:05,910
There's tokenized or is pretrained it
turns words into tokens and the type of

341
00:23:05,981 --> 00:23:08,380
tokens we want our sentences in our case,
right?

342
00:23:08,590 --> 00:23:11,170
So we'll use a token izer uh,

343
00:23:11,590 --> 00:23:11,850
okay.

344
00:23:11,850 --> 00:23:16,200
Well use a tokenized or to tokenize that
corpus that which is every single word

345
00:23:16,201 --> 00:23:18,750
we have, right? And let me,
let me, let me open this one.

346
00:23:18,930 --> 00:23:21,810
So every single word we have,
and this can be anything guys,

347
00:23:21,811 --> 00:23:25,380
this could be any piece of text you
want, any book, anything you download,

348
00:23:25,410 --> 00:23:29,550
any big piece of tax this same,
the same principles apply. Okay.

349
00:23:30,030 --> 00:23:31,260
Um,
and

350
00:23:32,180 --> 00:23:32,500
okay,

351
00:23:32,500 --> 00:23:35,200
we're going to put those all
into this raw sentences variable.

352
00:23:35,650 --> 00:23:37,510
Once we had that raw sentences variable,

353
00:23:37,511 --> 00:23:42,400
we're going to convert it into a wordless.
So what do I mean by a wordless? Well,

354
00:23:43,030 --> 00:23:46,000
um,
I also want a second.

355
00:23:49,660 --> 00:23:54,320
Sure. So for our word list or we want
a list of words, but, right, but,

356
00:23:54,560 --> 00:23:57,720
but, but what, what exactly
do I mean by that? Let me, um,

357
00:24:01,070 --> 00:24:05,660
so for our word list, let me, let me see
the comments. What are you guys up to?

358
00:24:06,420 --> 00:24:10,430
Uh, okay. So this is, okay. So let me,

359
00:24:10,460 --> 00:24:14,330
let me come at this as well. So I'm
going, you convert into a list of words,

360
00:24:14,580 --> 00:24:18,760
remove unnecessary characters.
We want to remove unnecessary characters.

361
00:24:18,770 --> 00:24:22,460
That's what we have. That A to Z, a to Z.
I'm going to split the split into words,

362
00:24:22,730 --> 00:24:26,960
no hyphens, you know, and, and
it's going to be a list of words.

363
00:24:26,961 --> 00:24:31,400
So that's an array. So it's a,
sorry, it's a list of words. Okay.

364
00:24:31,610 --> 00:24:34,250
Once we had that list of
words per each sentence,

365
00:24:34,251 --> 00:24:36,050
we're going to take those
words and tokenize it.

366
00:24:36,290 --> 00:24:38,300
So there's going to be a
sentence where each word,

367
00:24:39,120 --> 00:24:43,520
a sentence where each word is tokenized.
That's what this side,

368
00:24:43,521 --> 00:24:45,140
so for every sentence that we have,

369
00:24:45,550 --> 00:24:48,410
we're going to initialize an NP
sentence list and we're going to add it.

370
00:24:48,500 --> 00:24:50,840
We're going to add sentences to it.
And,

371
00:24:51,950 --> 00:24:52,783
uh,

372
00:24:57,680 --> 00:25:00,140
and then once we have that,
uh,

373
00:25:02,710 --> 00:25:05,180
all right, so I've got some comments
that I should slow down a little bit.

374
00:25:05,181 --> 00:25:08,330
I can do that. I can do that. Okay.
So let me slow down a little bit.

375
00:25:08,720 --> 00:25:11,480
There's so much I'm trying to cover,
so let me, I'll slow down. Okay.

376
00:25:11,720 --> 00:25:15,980
So we have a list of words.
Each word is tokenized. Okay.

377
00:25:16,280 --> 00:25:18,890
Each list of words is
considered a sentence.

378
00:25:19,100 --> 00:25:23,710
And we can see that when we print it out.
So we have our raw sentence, which is,

379
00:25:23,840 --> 00:25:27,290
he was an old man, passed 50. He
seen as the Lord links come and go.

380
00:25:27,530 --> 00:25:31,560
This is a sentence taking directly from
game of Thrones and it's at the, it is,

381
00:25:31,640 --> 00:25:34,320
it's at the fifth index. So if, if,

382
00:25:34,770 --> 00:25:37,560
because we combine all
of our books in order,

383
00:25:37,680 --> 00:25:40,860
this is going to be the fifth sentence
and the first book because it's one big

384
00:25:40,861 --> 00:25:42,480
corporates. Okay. And

385
00:25:45,970 --> 00:25:50,750
once we have that, uh, once we have that,

386
00:25:51,030 --> 00:25:56,030
we're going to convert it into a word
list, which is tokens and cds. You,

387
00:25:56,300 --> 00:25:57,530
uh,
characters,

388
00:25:57,531 --> 00:26:01,580
they basically help us convert them into
their unicode representations, right?

389
00:26:01,581 --> 00:26:04,160
So whenever we're dealing with words,
any kind of tax,

390
00:26:04,161 --> 00:26:07,160
we have to make sure it's in the right
format. And unicode is that format.

391
00:26:07,161 --> 00:26:10,090
We want four vectors. Okay. Uh, and,

392
00:26:10,120 --> 00:26:13,100
and UTF eight is that format
for reading from files.

393
00:26:13,370 --> 00:26:15,770
So once we have our big book Corpus,
let's print,

394
00:26:15,980 --> 00:26:20,060
print out how many tokens we have.
Okay. Um, and each sentence is,

395
00:26:20,210 --> 00:26:22,430
and what we're going to do is
we're going to consider each,

396
00:26:22,720 --> 00:26:25,090
uh, uh, uh,

397
00:26:25,200 --> 00:26:29,580
each, each sentence a token, and
we can print out a 1,000,800,

398
00:26:30,210 --> 00:26:32,430
10,000 tokens. Okay. So,

399
00:26:35,170 --> 00:26:37,210
okay, so no, we're going
to get into vectors.

400
00:26:37,211 --> 00:26:38,860
I'm gonna explain back to
you in a second in detail.

401
00:26:38,861 --> 00:26:41,020
We haven't gotten to that part.
Okay. So that's what we've,

402
00:26:41,050 --> 00:26:44,400
that's what we've just done. Now
we're going to train to VEC. Okay.

403
00:26:44,610 --> 00:26:46,530
These are our hyper
parameters. Let's, let's,

404
00:26:46,560 --> 00:26:49,200
let's talk about vectors for
a second. Like word. Okay.

405
00:26:49,201 --> 00:26:52,260
So I'm trying to find a great
image for this kind of second.

406
00:26:52,261 --> 00:26:55,230
So word embeddings are here.
So

407
00:26:57,670 --> 00:27:02,530
tensorflow probably has a
great image for this. So, okay,

408
00:27:02,531 --> 00:27:05,860
so here's a great one. Here's a
great one. Copy image address.

409
00:27:05,861 --> 00:27:09,550
Let's blow this image up. Let's get it
really big. Okay. So here are vectors,

410
00:27:09,551 --> 00:27:12,490
for example. So we'll get the one on the
left. Okay. Look at the one on the left.

411
00:27:12,491 --> 00:27:17,290
King Man, woman, Queen. These
are word vectors. So when we
have a set of words, okay,

412
00:27:17,470 --> 00:27:22,210
we have a set of words like,
so let's say, um, you know,

413
00:27:22,570 --> 00:27:27,100
um, masculine, uh, John,

414
00:27:27,670 --> 00:27:29,320
uh,
you know,

415
00:27:33,000 --> 00:27:37,620
Sarah Gay, you know, like words that
are like, like men, right? So, so,

416
00:27:37,650 --> 00:27:41,640
so where does that all have the same
semantic similarity? We can all,

417
00:27:41,670 --> 00:27:46,170
we can generalize all these words
into a vector representation.

418
00:27:46,380 --> 00:27:49,680
We also call them word embeddings.
So there's a lot of terms here,

419
00:27:49,830 --> 00:27:53,020
but we want to make sure that it's,
it's all really the same thing. It's,

420
00:27:53,190 --> 00:27:57,210
we don't want to be confused. Word
embeddings word vectors, same thing.

421
00:27:57,360 --> 00:28:00,600
So if we have a set of words, we
can generalize them into man. Okay?

422
00:28:00,601 --> 00:28:03,870
So that's what man is. Okay.
So man, woman, King, queen.

423
00:28:04,020 --> 00:28:09,000
These are generalized Decter
representations that we
have created after training

424
00:28:09,001 --> 00:28:12,540
on a very large corpus of text.
Okay?

425
00:28:12,570 --> 00:28:16,520
So when we have a new word, like
we say, like, uh, you know, what's,

426
00:28:16,521 --> 00:28:19,140
what's something manly? I mean,
this is, this is right now,

427
00:28:19,141 --> 00:28:22,080
this is a gender landline. I mean,
this example, but let's, let's,

428
00:28:22,081 --> 00:28:26,810
let's pick an example.
Like what do men have that women dotes um,

429
00:28:27,300 --> 00:28:31,600
this is like a, you know, right.

430
00:28:31,601 --> 00:28:35,890
So a penis, right? That's the
only thing I can think of it.

431
00:28:35,891 --> 00:28:40,090
It's like literally true and doesn't cross
any kind of, uh, you know, other things.

432
00:28:40,091 --> 00:28:44,400
So Penis, right? So penis would
then, uh, if we were to feed it to a,

433
00:28:44,900 --> 00:28:47,050
a trained word,
two VEC model,

434
00:28:47,230 --> 00:28:52,210
it would see that penis is closest
to man. Okay. Why does it know this?

435
00:28:52,360 --> 00:28:55,770
Because it's,
it's trained on a corpus of text to know,

436
00:28:55,800 --> 00:28:58,480
to eventually find the similarity that,

437
00:28:58,490 --> 00:29:01,630
that generalized representation
across all of these words.

438
00:29:01,631 --> 00:29:02,620
And how does it do this?
Well,

439
00:29:02,830 --> 00:29:07,270
it converts words into vectors and then
it creates vectors of vectors and he's

440
00:29:07,271 --> 00:29:09,610
vectors are, when we,
when we plot them out,

441
00:29:09,611 --> 00:29:13,330
we can see how similar different things
are. Yeah. Beard was a great one as well.

442
00:29:13,750 --> 00:29:18,190
Okay. So balls. Okay. Coz It's
attached. Right? And so then once we,

443
00:29:18,191 --> 00:29:22,390
once we have these vectors, we can
see what's similar to them, right?

444
00:29:22,510 --> 00:29:26,350
We can do all sorts of things.
Mainly, there are three
things we want to do. Okay,

445
00:29:26,470 --> 00:29:28,990
let me write that down. Write
this down. So write this down.

446
00:29:28,991 --> 00:29:31,660
This is a very important,
so once we have vectors,

447
00:29:33,750 --> 00:29:36,450
three main tasks,
there are three main tasks,

448
00:29:40,330 --> 00:29:41,163
tasks

449
00:29:42,270 --> 00:29:46,940
or some women have beard. So three main
tasks. That vector is help quit. Okay.

450
00:29:46,960 --> 00:29:51,310
Here are the three main types. Uh, the
one of them is resistance. Okay. Hold on.

451
00:29:53,260 --> 00:29:55,180
Uh,
similarity,

452
00:29:57,190 --> 00:30:00,860
similarity and ranking.
Okay.

453
00:30:00,910 --> 00:30:05,610
So those are generally what
they help us with. MMM.

454
00:30:06,690 --> 00:30:09,900
And what do I mean by that? Similarity?
Like vectors are good for things.

455
00:30:09,901 --> 00:30:14,730
Like if we want to, if we want to
think about, if we think about,

456
00:30:14,790 --> 00:30:16,260
uh,
any kind of,

457
00:30:17,570 --> 00:30:18,403
uh,

458
00:30:19,700 --> 00:30:21,590
what's the word I'm looking for?
Like if you want to see what's,

459
00:30:21,670 --> 00:30:23,120
how similar are two words are,

460
00:30:23,240 --> 00:30:25,790
which we're going to do later on if
you want to rank for something, right?

461
00:30:25,791 --> 00:30:29,450
So if you wanted to browse all the
scientific papers in the world will create

462
00:30:29,451 --> 00:30:30,410
vectors out of all of them.

463
00:30:30,620 --> 00:30:33,290
And then we want to rank them in
terms of some metric that we decide,

464
00:30:33,291 --> 00:30:38,120
like what's the one that has the most
information on say, a climate change?

465
00:30:38,660 --> 00:30:41,150
We could then rank them and semantically.
So it would say,

466
00:30:41,270 --> 00:30:45,230
here's the number one paper
that has the most, uh, verb,

467
00:30:45,290 --> 00:30:49,640
verb usage or word usage about the,
about the topic, climate change.

468
00:30:49,641 --> 00:30:52,760
And it uses vectors for that. Okay.
These are really useful. Okay,

469
00:30:52,880 --> 00:30:55,160
so let's go ahead and talk
about these hyper parameters.

470
00:30:55,490 --> 00:30:58,790
So numb features is a dimensionality
of these word vectors. Okay.

471
00:31:00,940 --> 00:31:04,340
Um, so we're,

472
00:31:04,410 --> 00:31:09,410
so number of features is
the dimensionality and we
say 300 because we say 300,

473
00:31:10,811 --> 00:31:14,950
because this we could say 400, we could
say 500, the more dementia. Let me say,

474
00:31:15,370 --> 00:31:20,300
let me cut this up. Some more dimensions.
The more complex, so more calm,

475
00:31:21,220 --> 00:31:24,580
occasionally complex expert,
sorry,

476
00:31:24,820 --> 00:31:29,470
expensive to train. Uh, but,

477
00:31:29,860 --> 00:31:33,850
uh, but also more accurate. Okay.

478
00:31:33,880 --> 00:31:35,710
So the more dimensions of vector has,

479
00:31:35,800 --> 00:31:40,330
the more general lot more
dimensions means more generalized,

480
00:31:40,480 --> 00:31:44,480
more generalized. Okay. So we're
going to say 300 for now. Okay. Uh,

481
00:31:44,560 --> 00:31:47,570
minimum word count threshold
is, uh, what is the, the,

482
00:31:47,660 --> 00:31:51,550
the smallest a set of words
that we want to recognize. Okay.

483
00:31:51,551 --> 00:31:54,940
When we convert to a vector,
the number of threads to run in parallel.

484
00:31:54,941 --> 00:31:55,810
So if we are,

485
00:31:58,230 --> 00:32:01,230
so what does the actual structure of a
vector that said it's a great question.

486
00:32:01,550 --> 00:32:05,040
Oh, the structure of a vector.
So the definition of a vector,

487
00:32:05,041 --> 00:32:06,360
and we're going to talk
about this in the next video,

488
00:32:06,600 --> 00:32:08,310
but the deaf we're going to
really deep dive into later.

489
00:32:08,490 --> 00:32:11,900
But the definition of a
vector is a, uh, it's,

490
00:32:11,940 --> 00:32:16,920
it's a set of numbers. Okay.
And, uh, in this context,

491
00:32:16,950 --> 00:32:20,910
in machine learning and physics, it's got
a different context. We talk about the,

492
00:32:21,140 --> 00:32:23,460
it talks about a direction.
In our case,

493
00:32:23,461 --> 00:32:25,410
we're just talking about a set of numbers.

494
00:32:25,411 --> 00:32:30,080
So we can think of it as a list of a
huge list of numbers. Okay. That's what,

495
00:32:30,090 --> 00:32:34,180
that's Kinda what it's represented
as. Um, okay. So and intense,

496
00:32:34,230 --> 00:32:38,660
or for weeks we use the word
tenser because attention
is an end dimensional, uh,

497
00:32:38,990 --> 00:32:42,800
array of numbers.
So I'm factor is a type of tensor.

498
00:32:43,010 --> 00:32:47,360
So Becker is a type of cancer.
So this doesn't really belong here.

499
00:32:47,361 --> 00:32:50,480
I'm just saying this right now.
Vector is a type of tensor. Okay. So,

500
00:32:52,010 --> 00:32:53,930
so then the number of
threads running parallel,

501
00:32:53,990 --> 00:32:57,140
this is where that multiprocessing
library that we imported comes into play.

502
00:32:57,170 --> 00:33:00,530
Okay. We want to say, how
many workers do we have?

503
00:33:00,830 --> 00:33:05,120
So the more we have the faster model
train more we're workers faster,

504
00:33:05,121 --> 00:33:07,100
we train context.

505
00:33:07,101 --> 00:33:12,020
Window length is the size of,
of the,

506
00:33:13,350 --> 00:33:17,990
of, of, of what we're looking at at, at,
at a time like this, the size of like,

507
00:33:17,991 --> 00:33:21,200
if we think of it as like looking
at blocks of seven words at a time,

508
00:33:21,201 --> 00:33:25,580
that's the context window down.
Downsample setting for frequent words is a

509
00:33:28,640 --> 00:33:31,340
hold on. Scalar. A vector
Matrix tensor. Exactly.

510
00:33:31,341 --> 00:33:34,430
We're going to be talking about
those in the next video. But uh,

511
00:33:34,470 --> 00:33:39,080
downtempo settings for frequent
words is uh, once we have,

512
00:33:39,110 --> 00:33:41,900
once we,
once we are trained,

513
00:33:41,901 --> 00:33:44,360
word to Vec model is noticing
a lot of frequent words.

514
00:33:44,570 --> 00:33:46,700
We don't want to have to
look at them constantly.

515
00:33:46,701 --> 00:33:51,701
So any number between zero and
one knee negative five is good.

516
00:33:52,611 --> 00:33:56,030
For this. It's the best. Generally
that's, that's what we found is a, is a,

517
00:33:56,031 --> 00:33:59,880
is a good, uh, it's,

518
00:33:59,980 --> 00:34:03,580
it's generally a good use case for this.
Basically.

519
00:34:03,610 --> 00:34:06,700
How often do we want to look at the same
word? The more frequent and where it is,

520
00:34:06,701 --> 00:34:10,720
the less we want to use it to create
vectors because it's already a part of our

521
00:34:10,721 --> 00:34:15,190
train model. Uh, so then the seed is
for the random number generator, right?

522
00:34:15,191 --> 00:34:17,170
So that's what that is.
Random number generator.

523
00:34:17,171 --> 00:34:19,060
And why do we use a
random number generator?

524
00:34:19,420 --> 00:34:22,450
We use it to pick what part of the text
we're going to look at your attorney to

525
00:34:22,460 --> 00:34:26,710
vectors. Okay. Um, and to see,
make sure that it's deterministic.

526
00:34:26,711 --> 00:34:31,450
This is good for lugging the terministic.
Good for debugging.

527
00:34:33,280 --> 00:34:36,040
Okay,
so this is our actual model right here.

528
00:34:36,600 --> 00:34:39,250
A word to Vec model we imported
from the Gen Sim Library.

529
00:34:39,251 --> 00:34:42,970
And let me tell you guys Jensen for a
second chance. And it's super useful.

530
00:34:44,830 --> 00:34:49,780
Uh, it's for topic modeling. Basically
you give it any kind of corpus like this,

531
00:34:49,960 --> 00:34:53,230
it'll create a model, it'll train it, you
can save it, you can load it later on.

532
00:34:53,380 --> 00:34:57,160
And then given some words like woman
and King, something that was in the,

533
00:34:57,190 --> 00:35:00,270
that was something that was in the
actual corpus. It'll give you words like,

534
00:35:00,370 --> 00:35:05,290
it'll give you things like the how similar
they are. Uh, uh, what does it match?

535
00:35:05,560 --> 00:35:06,640
Uh,
what's the,

536
00:35:06,670 --> 00:35:09,940
what give you the straight up directors
so you could use it later on. Jen Sims,

537
00:35:09,941 --> 00:35:14,890
a great library. Okay. So that's
going to actually train our model.

538
00:35:15,100 --> 00:35:16,060
And this is going to take,

539
00:35:16,300 --> 00:35:19,690
this is our model is relatively small
in the context of deep learning.

540
00:35:19,930 --> 00:35:22,690
This is the only going to take
30 seconds or so to train. Okay.

541
00:35:25,660 --> 00:35:26,493
MMM.

542
00:35:29,970 --> 00:35:34,350
All right. So, and it's actually not
the same definition as in physics.

543
00:35:34,351 --> 00:35:35,910
And there's a lot of
debate about this actually.

544
00:35:35,911 --> 00:35:39,780
I've been looking at a lot of stack
answers and a lot of core answers and it's

545
00:35:39,781 --> 00:35:44,000
crazy how much people are debating over
these words and machine learning. But

546
00:35:46,540 --> 00:35:50,230
the point is, it's just numbers.
It's number representations that we,

547
00:35:50,410 --> 00:35:53,020
that we create and then we
can feed into our model. Okay.

548
00:35:53,260 --> 00:35:55,570
So then we're going to
build our vocabulary and

549
00:35:58,070 --> 00:36:02,890
uh, so then we're going to
build our vocabulary, uh,
using those sentences. Okay.

550
00:36:03,100 --> 00:36:07,330
This is how we actually, uh, this is
how we load the corpus into memory.

551
00:36:07,450 --> 00:36:10,780
We haven't actually trained it. We built
our model, right? This is step three,

552
00:36:10,781 --> 00:36:14,380
build our model by which I should,
should have broken up written up here.

553
00:36:14,470 --> 00:36:19,420
So step three is built model mark.
Okay? So once we built our model,

554
00:36:19,421 --> 00:36:24,421
we have loaded our corporates that we
cleaned [inaudible] memory and we printed

555
00:36:24,531 --> 00:36:25,364
out the size of it.

556
00:36:25,370 --> 00:36:29,390
Now we can start training and it's going
to train on all of those sentences we

557
00:36:29,391 --> 00:36:33,440
gave it. It's going to take 30 or 30 or
40 seconds. And when it's done training,

558
00:36:33,680 --> 00:36:37,070
we're going to save the
file for use later on. Okay.

559
00:36:38,330 --> 00:36:42,160
And easily do that. You can get that
OSTP module great for that. We can,

560
00:36:42,190 --> 00:36:45,230
we can save it and we can, we can save
it and then we can load it later on.

561
00:36:45,410 --> 00:36:49,880
In fact, we can load it right now. We'll
load it from memory right now. Okay. Um,

562
00:36:53,770 --> 00:36:54,603
and

563
00:36:56,440 --> 00:37:00,660
once we have that, we're
going to compress those. Okay?

564
00:37:00,661 --> 00:37:03,480
So that's going to be 300 dimensional
word vectors, one of train.

565
00:37:03,630 --> 00:37:07,170
So in this Thrones to Beck, uh,
model right here that we've trained,

566
00:37:07,440 --> 00:37:08,400
it's going to have,

567
00:37:08,970 --> 00:37:12,030
it's going to contain all of those
word vectors that we just trained.

568
00:37:12,031 --> 00:37:14,130
He's going to,
everything is in memory right here,

569
00:37:14,370 --> 00:37:17,430
but these are 300 dimensional
word vectors. Okay?

570
00:37:17,700 --> 00:37:22,700
We cannot map a 300 dimensional
word vector on a plot for us,

571
00:37:23,010 --> 00:37:26,010
puny humans to see how are
we going to do that? Well,

572
00:37:26,190 --> 00:37:29,970
we're going to use a method called
[inaudible], which stands for teeth.

573
00:37:30,920 --> 00:37:31,920
What does it taste?

574
00:37:31,921 --> 00:37:36,700
The tastic distributed
Haber and embedding.

575
00:37:37,230 --> 00:37:42,070
Okay. And I have a great
day. I hear you on that. Um,
basically, let me, let me just,

576
00:37:43,360 --> 00:37:47,740
um, it's an, it's an awesome
technique. This is not useful, but

577
00:37:50,570 --> 00:37:53,300
basically a great big on that. Let me,
let me just have the video name for that.

578
00:37:53,500 --> 00:37:58,240
Uh, PCA is another, my
video. It's called a,

579
00:37:58,250 --> 00:38:02,600
what's it called? How to
visualize, I Beta set easily.

580
00:38:03,770 --> 00:38:06,920
I really dive into this,
this, this method right here,

581
00:38:07,460 --> 00:38:10,400
how to visualize the data
set easily in a nutshell,

582
00:38:10,500 --> 00:38:15,500
TSAE cooks or 300 dimensional vector and
squashes it into just two dimensions.

583
00:38:16,640 --> 00:38:20,960
Why? So that we can then plot it
and view it. How does it do this?

584
00:38:21,560 --> 00:38:24,740
It's actually a long explanation and
the video is great for that five and

585
00:38:24,741 --> 00:38:28,460
explanation. Definitely
check it out. Okay. Um,

586
00:38:29,090 --> 00:38:33,110
but uh, right, so once we,
so that's what Tsmc does.

587
00:38:33,111 --> 00:38:36,580
It's going to create those vectors
and so it's going to squash it. Okay.

588
00:38:37,030 --> 00:38:42,030
And we're going to take all those doctors
and put them in one gigantic matrix,

589
00:38:42,640 --> 00:38:46,480
right? We've initialized, yes. Any
here, but we haven't trained tsne right?

590
00:38:46,570 --> 00:38:51,340
So TSMC is a model. It's a
machine learning model and
we have to train it. Okay?

591
00:38:51,370 --> 00:38:54,850
So we'll train it on
that word vector matrix.

592
00:38:55,180 --> 00:38:57,670
And this is gonna take a
minute or two like it says and

593
00:38:58,540 --> 00:39:01,240
uh,
uh,

594
00:39:03,550 --> 00:39:06,880
so, uh, it's going to create this word
vector. It's a two D Matrix, right?

595
00:39:07,030 --> 00:39:12,030
So this is one gigantic matrix and it's
got the plots on the points with it.

596
00:39:12,760 --> 00:39:16,180
Okay? So then we're going to
plot what we've got. Okay.
So what do I mean by plot?

597
00:39:16,210 --> 00:39:20,220
Well, we want to apply to
it in to d sprays space.

598
00:39:20,221 --> 00:39:25,170
So for every word we have in that
vocab we went to, we want to have,

599
00:39:25,440 --> 00:39:29,280
we want to have three
columns. The word, the x,

600
00:39:29,340 --> 00:39:33,300
the x coordinate, and the y coordinate.
Now, how does it get these coordinates?

601
00:39:33,301 --> 00:39:38,250
Well, that's what TSN he does. Not only
does it, does it, uh, not only is it,

602
00:39:38,680 --> 00:39:42,300
uh,
so it's squashing these vectors into a

603
00:39:44,130 --> 00:39:45,210
two dimensional vectors,

604
00:39:45,630 --> 00:39:49,470
but it's also giving us the x and y
coordinates of those vectors and in two

605
00:39:49,471 --> 00:39:53,220
dimensional space, okay? So these are
all words from that Corpus, right?

606
00:39:53,221 --> 00:39:57,960
These are all game of Thrones, the
words, right? So that's what that does.

607
00:39:57,961 --> 00:39:58,794
And

608
00:40:03,050 --> 00:40:07,570
uh, once we've got that, then we're
going to plot them on a graph.

609
00:40:07,571 --> 00:40:09,970
So this is where map plot
life comes into play, right?

610
00:40:10,060 --> 00:40:13,090
We're going to plot these points,
we're going to plot them on a graph.

611
00:40:13,390 --> 00:40:18,250
And it's a lot. These are
our word vectors. There's,
there's a lot of them here,

612
00:40:18,251 --> 00:40:21,520
right? And we've, we've, we
brought it down to scale so
we could see a lot of them,

613
00:40:21,521 --> 00:40:25,300
but all of our word vectors
or word embeddings, whatever
you want to call them,

614
00:40:25,570 --> 00:40:28,600
are here in to the space. Now what
are we gonna do with them? Well,

615
00:40:28,601 --> 00:40:31,490
we can see what vectors
are close to each other.

616
00:40:33,510 --> 00:40:34,420
Let's,
let's start with that.

617
00:40:34,540 --> 00:40:38,770
Let's see what word vectors are close to
each other and what that tells us about

618
00:40:38,771 --> 00:40:42,570
the data. Okay. So, uh,

619
00:40:42,640 --> 00:40:44,530
the first thing we want to
do is zoom in on this, right?

620
00:40:44,531 --> 00:40:45,910
And that's what this function does.

621
00:40:46,060 --> 00:40:50,590
It creates a bounding box of x and y
coordinates in that graph that we have.

622
00:40:50,800 --> 00:40:54,760
And it shows just that bounding box.
That's what this function does. Okay.

623
00:40:54,761 --> 00:40:58,090
And so then we'll use that. We'll
use that to, we'll say, okay,

624
00:40:58,120 --> 00:41:02,500
so in the bounds of this and the, the
x y balance of, of these coordinates,

625
00:41:02,501 --> 00:41:04,540
and we give it, let's see
what we, what it gives us.

626
00:41:04,870 --> 00:41:09,040
This is what it gives us when we look in
this corner. Well, what are all these, um,

627
00:41:09,640 --> 00:41:14,630
these are names, Barista
and Gregor, Saigon Sander.

628
00:41:14,900 --> 00:41:19,110
These are all names and they look like
male names as well, right? They, they,

629
00:41:19,130 --> 00:41:21,110
they look pretty much
mail. Okay. So interesting.

630
00:41:21,410 --> 00:41:25,070
Just by training vectors on our,
our model,

631
00:41:25,640 --> 00:41:27,540
it created,
uh,

632
00:41:27,890 --> 00:41:30,830
just by training and creating vectors
and applying them in a two dimensional

633
00:41:30,831 --> 00:41:35,510
graph using TSMC. Uh, I remove
stop words and special characters.

634
00:41:35,810 --> 00:41:40,100
A software's been included in that
list, uh, at least in Nltk. Um,

635
00:41:42,510 --> 00:41:43,343
but

636
00:41:44,610 --> 00:41:48,610
it, it shows that these words
are all close to each other
cause it knows that, uh,

637
00:41:49,690 --> 00:41:51,640
the distance between these worlds,
it's small,

638
00:41:51,641 --> 00:41:54,280
so it grabs them very close to each
other. So it's pretty cool, right?

639
00:41:54,310 --> 00:41:55,600
So if you're looking
at a different region,

640
00:41:59,700 --> 00:42:02,730
so if you look at a different region,
we'll see that, hey, this is food, right?

641
00:42:02,910 --> 00:42:07,620
This is a totally different region.
Pepper, pickled, you know, cod all lives,

642
00:42:07,621 --> 00:42:10,080
turnips.
These are all similar words.

643
00:42:10,610 --> 00:42:14,760
And I wouldn't really stress the
importance that brevity of vectors. Okay.

644
00:42:15,420 --> 00:42:20,210
Not The brevity, the wrong word,
wrong word vector. The, the, the,

645
00:42:21,900 --> 00:42:25,980
the enormous awesomeness of vectors.
Okay.

646
00:42:25,981 --> 00:42:28,440
Word vectors are word
clusters are related.

647
00:42:29,010 --> 00:42:32,760
There's so much we can do
with this in every field in,

648
00:42:32,790 --> 00:42:37,740
in legal and law. We can, we can
train an AI judge using this thing.

649
00:42:37,741 --> 00:42:41,580
Do you think semantic similarity to see
the differences between the different

650
00:42:41,581 --> 00:42:45,330
case data or we can doctors, we
could, we could see what's similar.

651
00:42:45,331 --> 00:42:48,330
We could use this to try
new drugs. Like what is, uh,

652
00:42:49,260 --> 00:42:52,710
what is the semantic, what is the
coastline similarity or what is some,

653
00:42:52,711 --> 00:42:56,310
some similarity metrics that we defined
between a corpus of scientific hate

654
00:42:56,580 --> 00:43:00,770
papers on, uh, some problem that
we're trying to solve so we could,

655
00:43:00,960 --> 00:43:04,500
so this most similar function
it's already created for us,

656
00:43:04,740 --> 00:43:08,580
but basically we'll say, well, we'll
give it stark and then it'll show this,

657
00:43:08,660 --> 00:43:12,420
the similarity by a number.
So it ranked them.

658
00:43:12,750 --> 00:43:15,660
All of these names are similar to stark,
right?

659
00:43:16,310 --> 00:43:17,143
MMM.

660
00:43:17,880 --> 00:43:19,980
And how are we doing this?
Well,

661
00:43:19,981 --> 00:43:23,280
there's a lot of methods for
measuring semantic similarity.

662
00:43:24,000 --> 00:43:26,610
There's a lot of methods for measuring
the similarity between vectors.

663
00:43:26,611 --> 00:43:30,410
And the one we're using here is the
coastline similarity. So let me, let me,

664
00:43:30,690 --> 00:43:32,670
let me bring that up.
The code sign similarity.

665
00:43:34,940 --> 00:43:39,760
MMM,
okay.

666
00:43:40,030 --> 00:43:41,430
Co-Signs clarity.

667
00:43:42,750 --> 00:43:47,460
Possible distance metric we can use
because turning these words into Vectra,

668
00:43:47,461 --> 00:43:50,450
turning our videos into vectors,
turning our images into vectors.

669
00:43:50,650 --> 00:43:54,060
It gives us a way to mathematically
reason about these things. We can,

670
00:43:54,240 --> 00:43:58,020
we can reason about them. Just like we've
reasoned about numbers in a, in a, in a,

671
00:44:00,220 --> 00:44:05,130
in a, in a, in a mathematical
way. Right. So, uh,

672
00:44:05,170 --> 00:44:07,810
so this is the, this is the formula
for the cosine similarity, right?

673
00:44:07,811 --> 00:44:10,030
So given two vectors,
we can,

674
00:44:10,720 --> 00:44:14,140
we can use the dot product
and the magnitude of those
vectors to calculate them.

675
00:44:14,590 --> 00:44:18,730
Okay. So that's one method. There's
a lot, there's like the hostel, Ian,

676
00:44:20,170 --> 00:44:24,560
I think it's called Halcyon similarity.
Um,

677
00:44:28,770 --> 00:44:32,340
or the, sorry, the golf scions no, of
course the similarity, but it's like the,

678
00:44:33,720 --> 00:44:37,030
anyway, there's a lot. And I, and
I'll, I'll link him more into, in,

679
00:44:37,510 --> 00:44:38,800
in a different dorm.
So,

680
00:44:40,400 --> 00:44:41,233
mmm.

681
00:44:41,670 --> 00:44:45,930
Anyway, so then, uh, we'll use that to
say, okay, so given these three words,

682
00:44:45,931 --> 00:44:50,120
stark winter fell in river run, it'll
say we'll start as related to winter,

683
00:44:50,121 --> 00:44:54,500
Phil as x is related to river run and
what is x? And that's what this does.

684
00:44:54,520 --> 00:44:55,231
It says,
okay,

685
00:44:55,231 --> 00:44:59,460
so it's going to measure the similarity
between the first two parameters we give

686
00:44:59,461 --> 00:44:59,970
it.

687
00:44:59,970 --> 00:45:03,960
And then it's going to say
for that similarity would
be that like 0.5 or 0.6 and

688
00:45:03,961 --> 00:45:06,600
0.7, what is the, what is,

689
00:45:06,690 --> 00:45:09,720
what is something that similar
to that last parameter river run.

690
00:45:10,020 --> 00:45:13,440
And it'll find that from our list of
existing vectors. And in that case,

691
00:45:13,470 --> 00:45:18,200
in our case, it will be truly Tyrian
Danny, things like that. Okay. Um,

692
00:45:19,840 --> 00:45:24,310
okay, so, so there's that,
that's the end of this already.

693
00:45:24,311 --> 00:45:28,420
And I and I, because I didn't type out
the code, it went a little faster. Uh, but

694
00:45:29,730 --> 00:45:30,563
uh,

695
00:45:31,270 --> 00:45:35,800
yeah. So let's wait. Where's
my, where's my screen here?

696
00:45:36,100 --> 00:45:39,340
Let me stop screen sharing and

697
00:45:41,000 --> 00:45:45,590
go back to this. Oh Man. Okay. Hi Guys.

698
00:45:45,950 --> 00:45:46,783
Let's,
uh,

699
00:45:47,060 --> 00:45:52,060
you are ending five minute Q and a and
then we're going to end this stream.

700
00:45:53,540 --> 00:45:55,990
Okay. I have an awesome
video coming up for you guys.

701
00:45:56,000 --> 00:45:59,870
Have been working really hard to thank
you song Graham. I really appreciate it.

702
00:46:00,120 --> 00:46:02,570
Uh, I'm really excited
about this. Next video.

703
00:46:08,330 --> 00:46:09,410
I'm using a Mac book.

704
00:46:11,010 --> 00:46:11,843
MMM,

705
00:46:13,100 --> 00:46:14,030
thanks.
Vocalize.

706
00:46:15,720 --> 00:46:19,780
Uh,
what else?

707
00:46:25,310 --> 00:46:28,280
Thanks party.
Can you please elaborate on

708
00:46:29,810 --> 00:46:34,660
how is the projection of each word of
each work to the coordinator is I work to

709
00:46:34,661 --> 00:46:37,190
the coordinate. What do you mean? What?
Our real life applications of this.

710
00:46:37,191 --> 00:46:41,090
Great questions. Thanks. Iraq's, okay.
Real life applications of word vectors.

711
00:46:41,210 --> 00:46:45,590
Take any, take any, uh, piece
of texts. Take a book. Okay.

712
00:46:45,680 --> 00:46:48,170
After this live stream,
download a book. Okay.

713
00:46:48,171 --> 00:46:51,440
Download an ebook and convert it to a
text format and then use the code that I

714
00:46:51,441 --> 00:46:54,410
give you and you could easily feed it
towards the back and create vectors.

715
00:46:54,620 --> 00:46:56,690
What do you do with these
vectors? You'd, well then you can,

716
00:46:57,350 --> 00:47:01,400
besides the similarity and
the distance, um, what's up,

717
00:47:02,180 --> 00:47:05,170
what's a good application
for Bec? Like, uh,

718
00:47:05,850 --> 00:47:08,330
then when a corpus of what your
friends are saying, you could see what,

719
00:47:08,450 --> 00:47:12,110
what's what you can rank personalities
like, you know, what you know,

720
00:47:12,111 --> 00:47:16,840
chats like this guy's chance versus
this guy's chat or a disguise.

721
00:47:16,970 --> 00:47:21,710
Um, you know what he said in
a speech versus what he said.

722
00:47:21,920 --> 00:47:23,900
If you want to compare,
you know, Hitler to Trump.

723
00:47:24,140 --> 00:47:28,300
I just went political now trying to go
political anyway, but I just did, uh,

724
00:47:28,520 --> 00:47:32,770
if you want to anything we're
doctors are good for that. Um,

725
00:47:33,100 --> 00:47:34,500
ranking.
Uh,

726
00:47:36,530 --> 00:47:37,363
okay.

727
00:47:37,420 --> 00:47:40,390
Words are everywhere guys. Um,
any kind of similarity, a ranking,

728
00:47:40,391 --> 00:47:45,220
that's what it's for. And there's a lot
of, there's a lot of possibilities. Okay.

729
00:47:45,221 --> 00:47:46,054
So

730
00:47:49,690 --> 00:47:53,200
how are the words assembled into factors?
Is it just context?

731
00:47:53,230 --> 00:47:57,230
Are there any ontological network
being built? If so, how? Um,

732
00:47:58,710 --> 00:48:02,380
right, so Google released worked effect.

733
00:48:04,850 --> 00:48:08,540
Okay. So he trained neural network on
these vectors and these are labeled,

734
00:48:08,820 --> 00:48:13,510
this is,
it was a labeled corpus of words and

735
00:48:16,680 --> 00:48:19,610
well, actually we can do that. We can do
this unsupervised as well. But basically,

736
00:48:20,010 --> 00:48:22,730
uh,
we,

737
00:48:22,850 --> 00:48:27,850
we convert words to vectors and
single single words to vectors.

738
00:48:28,340 --> 00:48:32,420
And so that gives us a number. I 0.8
or 0.9 and once we have those vectors,

739
00:48:32,570 --> 00:48:36,260
then we could create even more generalized
vectors by looking at the similarity.

740
00:48:36,261 --> 00:48:40,820
And that similarly could be like, you
know, this is point 999.9 and an eight.

741
00:48:40,940 --> 00:48:43,100
And these are very similar. Okay. So,

742
00:48:44,450 --> 00:48:46,760
and that creates even more
generalized doctors. Okay. So

743
00:48:49,910 --> 00:48:52,910
anyway, the guys I've got to go,
ah, I've got some editing to do,

744
00:48:52,911 --> 00:48:57,911
some shooting to do some you Udacity
talking to do and I love you guys.

745
00:48:58,810 --> 00:49:01,550
Uh,
we're gonna and uh,

746
00:49:01,580 --> 00:49:06,510
next livestream is going to
be much more, you know, uh,

747
00:49:07,280 --> 00:49:11,750
so and not that this one wasn't there.
All Doe. Uh, I'm dope. You guys are dope.

748
00:49:11,810 --> 00:49:14,600
We're all do. Okay. So
for now, I got to go.

749
00:49:16,110 --> 00:49:16,680
Okay.

750
00:49:16,680 --> 00:49:20,580
Take a chill pill. So thanks
for watching. That'd be guys.

