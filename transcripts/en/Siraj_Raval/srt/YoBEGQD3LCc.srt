1
00:00:03,410 --> 00:00:07,350
And today we're going to build style
transfer using just tensorflow.

2
00:00:07,470 --> 00:00:12,060
Nothing else. So let's
answer some questions. Five
minutes, five minute Q and a.

3
00:00:12,061 --> 00:00:15,730
And then we're going to get
started. I need myself. All right,

4
00:00:15,731 --> 00:00:17,130
who's in this chat room right now?

5
00:00:21,120 --> 00:00:22,240
All right,

6
00:00:24,810 --> 00:00:28,050
well we got Dan Shiffman and here from
the coating train we got Fernando,

7
00:00:28,230 --> 00:00:31,770
we've got some cool people in here right
now. We've got some celebrities, guys,

8
00:00:31,771 --> 00:00:36,210
we've got some celebrities in here.
So Lao who did up Chez Jack,

9
00:00:36,930 --> 00:00:40,230
I everybody. Wow. Dan was
actually the first one in here.

10
00:00:40,830 --> 00:00:43,920
I'm honored Dan to see you here. Uh, we,

11
00:00:43,921 --> 00:00:45,900
we watch each other's
livestreams occasionally get,

12
00:00:45,901 --> 00:00:49,110
get inspiration high from Germany.
We've got a bunch of people here.

13
00:00:49,230 --> 00:00:52,470
So let me answer some questions.
Hello from Moscow.

14
00:00:53,690 --> 00:00:54,240
Okay,

15
00:00:54,240 --> 00:00:56,920
we are going to do the math
behind style transfer guides.

16
00:00:56,921 --> 00:01:00,370
It's going to be awesome and we're going
to really understand exactly what's

17
00:01:00,371 --> 00:01:03,250
happening under the hood.
No care os it's gonna be awesome.

18
00:01:03,251 --> 00:01:06,940
So check out the link in the description
to fall along with my notes. Usually,

19
00:01:06,941 --> 00:01:09,160
I wouldn't, you know, show that,
but I'm going to show it right now.

20
00:01:09,610 --> 00:01:12,490
Hello from the Netherlands.
Parvez Arvind.

21
00:01:12,940 --> 00:01:16,210
I'll say three more names and then we're
good to go. Lunchtime is perfect timing,

22
00:01:16,211 --> 00:01:19,660
isn't it? Uh, Drma a Sam
and then one more name.

23
00:01:20,070 --> 00:01:23,890
We'll guerrea a buggy out from Stockholm,

24
00:01:24,010 --> 00:01:26,290
Sweden and of course all
these other people. Okay.

25
00:01:26,320 --> 00:01:28,480
So give me up with those questions guys.

26
00:01:28,481 --> 00:01:31,390
Cause I'm so excited to
actually build this thing. Okay.

27
00:01:31,391 --> 00:01:33,910
Because I've been looking at my notes
and trying to figure out exactly how to

28
00:01:33,911 --> 00:01:36,760
explain it so it's gonna be
awesome. Uh, we got Granada. Okay.

29
00:01:37,750 --> 00:01:39,550
Questions your way.
Okay.

30
00:01:41,250 --> 00:01:41,850
Okay.

31
00:01:41,850 --> 00:01:45,640
Hit me up. What your best questions
as they say. As I say right now,

32
00:01:47,380 --> 00:01:48,220
hello from Israel.

33
00:01:48,280 --> 00:01:52,510
Is tensorflow flow a good library
for a deep learning beginner? Yes,

34
00:01:52,570 --> 00:01:54,490
because it has the most documentation.

35
00:01:54,491 --> 00:01:57,760
It's got the most headway in terms of
all the other deep learning libraries.

36
00:01:57,880 --> 00:02:01,690
There's so much content creating created
around tensorflow, not even just me,

37
00:02:01,691 --> 00:02:04,810
like other people that yes, I think it's
the best way to get started and it's,

38
00:02:04,870 --> 00:02:08,500
it's right now, right now it's the
industry standard and see how that,

39
00:02:08,501 --> 00:02:12,370
what happens in the future.
What is the meaning of style transfer?

40
00:02:12,970 --> 00:02:17,970
Style transfer means it's
we frame adding a filter,

41
00:02:18,290 --> 00:02:20,530
you know, it's like filters,
right? Instagram filters.

42
00:02:20,531 --> 00:02:23,710
But we framed this as an
optimization problem. Okay.

43
00:02:23,711 --> 00:02:27,340
In machine learning we try to frame
everything that's an optimization problem

44
00:02:27,640 --> 00:02:29,500
where we minimize a loss function.

45
00:02:29,740 --> 00:02:34,000
So style transfer is an optimization
problem where we have two images,

46
00:02:34,180 --> 00:02:35,560
we have a styled image,

47
00:02:35,561 --> 00:02:39,640
which slate say have Dan go painting and
then an image of say whatever we want

48
00:02:39,641 --> 00:02:40,570
like yourself.

49
00:02:40,870 --> 00:02:44,530
And we're trying to minimize
the difference between
these two images. Images.

50
00:02:44,980 --> 00:02:48,250
That's the transfer. We're transferring
the style of this van Gogh painting,

51
00:02:48,400 --> 00:02:53,000
all the textures and the waviness
and the colors onto this, uh,

52
00:02:53,070 --> 00:02:55,090
post painting that or this host image.

53
00:02:55,420 --> 00:02:58,330
And we're going to figure out how to do
this. Mathematically. It's not magic.

54
00:02:58,690 --> 00:03:01,990
We know to do it. All of it.
Okay. What is zero shot learning.

55
00:03:02,260 --> 00:03:05,770
We're going to talk about zero shot, one
shot learning at the end of this course.

56
00:03:05,800 --> 00:03:08,470
It's not the bleeding edge of everything.
I can't wait to get started with that,

57
00:03:08,620 --> 00:03:12,460
but it means, but it means a machine
learning with very little data.

58
00:03:12,461 --> 00:03:15,550
And that I believe is the future of
all machine learning. By the way.

59
00:03:15,551 --> 00:03:18,190
There's so much cool shit coming
out right now out of deep mines,

60
00:03:18,670 --> 00:03:20,920
my homie Oreo and yells it.

61
00:03:20,921 --> 00:03:24,060
They had this new paper that
basically beat deep queue,

62
00:03:24,880 --> 00:03:27,940
which has their own algorithm that we're
like cause because Google to buy now

63
00:03:28,090 --> 00:03:30,700
with this new model called
hierarchical reinforcement learning.

64
00:03:30,880 --> 00:03:32,560
So we're starting to see a convergence,

65
00:03:32,561 --> 00:03:37,060
no pun intended between different machine
learning ideologies like this idea of

66
00:03:37,061 --> 00:03:39,760
abstraction between layers and uh,

67
00:03:39,790 --> 00:03:43,480
the idea of reinforcement
and then combining them
together. And then this just,

68
00:03:43,990 --> 00:03:48,100
they, they, they were able
to, uh, beat Pong in like 10
minutes. It was awesome. Okay.

69
00:03:48,160 --> 00:03:50,590
Uh, let me answer three more
questions before we get started.

70
00:03:51,520 --> 00:03:54,490
How transformative it can be
done using tfs tensor flow.

71
00:03:54,730 --> 00:03:56,260
We're going to use transfer
learning right now.

72
00:03:56,261 --> 00:03:57,790
So I'll answer your question as we code.

73
00:03:58,480 --> 00:04:00,310
Would this also work with writing styles?

74
00:04:00,311 --> 00:04:03,730
I actually have a video on that called
build an AI writer. Yes, absolutely.

75
00:04:03,820 --> 00:04:08,780
And I'm going to make another video
on that literally next week. Uh,

76
00:04:09,040 --> 00:04:13,720
can you, can we make a program that
extract knowledge from story? Absolutely.

77
00:04:13,810 --> 00:04:18,670
Um, text summarization. I will have video
on that later on in this course. So Raj,

78
00:04:18,671 --> 00:04:22,270
answer my question. If the network
is possible to use it in trading,

79
00:04:23,110 --> 00:04:25,270
we're not going to use a
convolutional net and trading.

80
00:04:25,271 --> 00:04:27,700
We're going to use a recurring net
and training and we're going to,

81
00:04:28,180 --> 00:04:30,490
and I made a video on that. Not
this one. This one won't be,

82
00:04:31,080 --> 00:04:34,150
where's your girlfriend? No girlfriend.
I'm single and happy being single.

83
00:04:34,151 --> 00:04:38,460
I have too much to do today. Uh, I'm
happy being single. I am a beginner.

84
00:04:38,490 --> 00:04:42,550
Go more detailed. I will go
so detailed. Siddhartha. Don't
even don't even trip. So,

85
00:04:42,551 --> 00:04:47,080
Rod, can you recommend ml forum please?
Uh, the comments section of all my videos,

86
00:04:47,081 --> 00:04:48,560
we are essentially a community guys.

87
00:04:49,060 --> 00:04:53,020
Essentially we are a community
of 75,000 strong engineers.

88
00:04:53,021 --> 00:04:56,170
Everyone from middle school students
who are just getting started learning

89
00:04:56,290 --> 00:04:59,830
Algebra two PhDs at Google,
pushing real research.

90
00:05:00,040 --> 00:05:03,880
So we are a very large community and the
culture we set up is such that if you

91
00:05:03,970 --> 00:05:07,030
ask a question you will get it answered.
Okay.

92
00:05:07,100 --> 00:05:10,270
So we build on Google inception
for this task. Yes, you can.

93
00:05:10,330 --> 00:05:14,290
We're going to use a different
model called a DGG 16 model.

94
00:05:15,640 --> 00:05:19,210
Okay. So one more question and then
we're going to get started with this.

95
00:05:21,370 --> 00:05:26,260
What is the best area to focus
in AI? Uh, so deep learning,

96
00:05:26,261 --> 00:05:29,320
but specifically a focus.
I mean, you know, focusing,

97
00:05:29,340 --> 00:05:33,040
be taken a lot of different ways. Focus
for research, focus for production,

98
00:05:33,130 --> 00:05:37,240
focus for beginner, uh, focus means just a

99
00:05:38,980 --> 00:05:39,813
focus on,

100
00:05:41,480 --> 00:05:42,010
okay.

101
00:05:42,010 --> 00:05:44,980
Uh, I mean, I mean there's so
many things you can focus on,

102
00:05:44,981 --> 00:05:47,680
but I would say it's
such a generic question,

103
00:05:48,090 --> 00:05:51,580
a generative adversarial networks because
those are the coolest things right now

104
00:05:51,581 --> 00:05:55,180
to me. Uh, all right, so that's
it for the questions. Uh,

105
00:05:55,181 --> 00:05:59,810
and so now we're going to get started with
this. So we're going to today a combo.

106
00:05:59,840 --> 00:06:03,410
We're going to build a style transfer
and it's not that we're going to build a

107
00:06:03,411 --> 00:06:05,690
convolutional net from scratch.
We already have that.

108
00:06:05,840 --> 00:06:09,860
We're going to chop off the top layer
and then we're going to add our own layer

109
00:06:09,861 --> 00:06:13,460
on top of that to do, install a fence for
it. So let's just get started with this.

110
00:06:13,490 --> 00:06:17,330
I will explain things as
we go and remember the code
is in the description all

111
00:06:17,331 --> 00:06:20,600
along with me. It's going to
be awesome. Focus. Here we go.

112
00:06:29,770 --> 00:06:30,603
Okay.

113
00:06:31,350 --> 00:06:35,890
All right.
Okay,

114
00:06:35,891 --> 00:06:37,000
so let's see.

115
00:06:39,030 --> 00:06:39,863
Hmm,

116
00:06:41,450 --> 00:06:42,700
let's get started with this.
Okay,

117
00:06:42,701 --> 00:06:46,240
so what I'm gonna do is I'm
not going to code the parts,

118
00:06:46,450 --> 00:06:48,730
the parts that are not machine learning.

119
00:06:48,731 --> 00:06:50,560
I'm only going to code
the machine learning part.

120
00:06:50,561 --> 00:06:54,400
So what we're going to do today is
we're going to perform style transfer.

121
00:06:54,401 --> 00:06:57,640
So let's look at this image for a
second and let's go to this link.

122
00:06:57,910 --> 00:07:02,910
It's just a paper of a bunch of style
transfer images and it's just a way of

123
00:07:03,551 --> 00:07:06,640
describing what we're doing here.
So the first paper that did this,

124
00:07:06,670 --> 00:07:10,660
I talked about this in the weekly video
was, oh, let me show myself as well,

125
00:07:11,050 --> 00:07:13,570
was the uh, [inaudible] paper, right?

126
00:07:14,420 --> 00:07:17,680
A neural algorithm for artistic style.
That was much low Anton.

127
00:07:18,130 --> 00:07:21,760
That was the first paper
that did this. Okay. And we,

128
00:07:21,820 --> 00:07:25,180
and since then there've been quite a few
papers that have built on top of that,

129
00:07:25,330 --> 00:07:27,220
right? So the first one
just transferred to style,

130
00:07:27,221 --> 00:07:30,700
which is what we're going to do today.
We want to transfer the style today.

131
00:07:30,910 --> 00:07:35,290
But there were subsequent papers that
built on that idea. They did it for video,

132
00:07:35,291 --> 00:07:36,124
for example.

133
00:07:36,220 --> 00:07:39,970
And what they found when doing it for
video was that there was actually a lot of

134
00:07:39,971 --> 00:07:41,620
choppiness because think of it,

135
00:07:41,650 --> 00:07:45,490
a video is just a collection
of images and we want to,

136
00:07:45,590 --> 00:07:48,880
and what happened was there was a
lot of choppiness between frames.

137
00:07:49,000 --> 00:07:51,880
So what they did in the next paper,
it wasn't the same group,

138
00:07:51,881 --> 00:07:55,900
it was a different group, but for
video style transfer was they added a,

139
00:07:55,901 --> 00:08:00,340
another loss function called optical
flow based loss. So in minimize,

140
00:08:00,341 --> 00:08:04,330
not just three or two loss functions. They
minimize three or four loss functions.

141
00:08:04,470 --> 00:08:06,550
So they're just changing
these laws functions together.

142
00:08:06,551 --> 00:08:10,720
And what happened was this beautiful
video that we can see here, you know,

143
00:08:10,721 --> 00:08:12,110
like it's, it's very, you know,

144
00:08:12,111 --> 00:08:15,370
you can just think about all the
potential this just happened last year.

145
00:08:15,550 --> 00:08:18,460
So just think about all the
potential it has for artists,

146
00:08:18,461 --> 00:08:19,720
for Arthur to creative things.

147
00:08:19,870 --> 00:08:23,500
And snapchat now has a real time filters.

148
00:08:23,590 --> 00:08:28,000
So this doesn't even take training. You
can just do this in real time. Okay.

149
00:08:28,001 --> 00:08:31,300
So we've seen a lot of progress
starting from that initial paper.

150
00:08:32,590 --> 00:08:36,820
And so what we're going to do is
we're going to, uh, build style,

151
00:08:36,821 --> 00:08:40,330
transferred the original way,
the way that the original paper was done,

152
00:08:40,480 --> 00:08:44,230
and then we'll talk about all
the ways of improving that.

153
00:08:44,231 --> 00:08:46,870
So let's just go down to this image
and take a look at this image, right?

154
00:08:46,871 --> 00:08:50,290
Because these are the, these are the
two images that we are using right now.

155
00:08:50,530 --> 00:08:53,110
And let's talk about the
process of what we're doing.

156
00:08:53,500 --> 00:08:57,690
We're going to slice off that
top because originally the, okay,

157
00:08:57,691 --> 00:09:02,370
so the network we originally
used was called BGG 16. Right?

158
00:09:02,371 --> 00:09:06,060
This was an image classification,
convolutional network, right?

159
00:09:06,061 --> 00:09:11,061
So at each layer it would imply a
series of operations to our input image.

160
00:09:12,270 --> 00:09:15,900
So we can think of our input
image as a matrix of values.

161
00:09:15,930 --> 00:09:17,460
It's a matrix of value,
right?

162
00:09:17,490 --> 00:09:22,490
I'll pixel values and we apply a series
of operations to that image because at

163
00:09:23,070 --> 00:09:25,350
each layer,
at each convolutional layer,

164
00:09:25,530 --> 00:09:27,900
we have what are called
a stack of filters.

165
00:09:28,380 --> 00:09:32,370
And these filters are learned over time.
And so for Bgg 16,

166
00:09:32,371 --> 00:09:34,440
they trained it on thousands of images.

167
00:09:34,560 --> 00:09:37,410
So it's already got a bunch
of filters at each layer.

168
00:09:37,620 --> 00:09:41,520
And at what's happening on each of
these filters is it is multiplying those

169
00:09:41,521 --> 00:09:44,720
filter values by the
input image. Okay. And

170
00:09:46,810 --> 00:09:49,810
video is glitching lot skipping a
lot of brains. Okay, thanks for that.

171
00:09:49,870 --> 00:09:51,670
Let me just remove myself.
That's going to help.

172
00:09:52,270 --> 00:09:53,103
All right.

173
00:09:54,250 --> 00:09:58,150
And so readings from Hong Kong.
Okay. So hopefully that helps. Okay.

174
00:09:58,151 --> 00:10:02,810
And let me know if this is
still glitching. Alright,
close up. This other friend,

175
00:10:02,830 --> 00:10:05,200
just practicum minimal. Okay. So, uh,

176
00:10:07,530 --> 00:10:10,590
we're going to it. Uh, so
that's what we're going to do.

177
00:10:10,591 --> 00:10:12,720
And so this is the BGG 16 layer.
Okay.

178
00:10:12,721 --> 00:10:17,340
And so the idea here is that
let's, let's, let's also look at,

179
00:10:17,400 --> 00:10:21,150
uh, this, this image right
here that's helping, right?

180
00:10:21,290 --> 00:10:22,123
Okay.

181
00:10:22,990 --> 00:10:26,110
So let's take a look at
this. So let, let me,

182
00:10:26,140 --> 00:10:29,620
let me explain what's happening here
for a second. So this is a great,

183
00:10:30,160 --> 00:10:34,270
great image right here. So we want the
contour lines from the content image.

184
00:10:34,271 --> 00:10:38,140
So we want all those lines
from the content image and
we want the textures from

185
00:10:38,141 --> 00:10:41,380
the style image. Okay? Those are
the two different things we want.

186
00:10:41,650 --> 00:10:44,620
And the way we're going to do that
is we're going to add each layer.

187
00:10:44,621 --> 00:10:49,510
There are a collection of filters.
So what are, what are these filters?

188
00:10:49,630 --> 00:10:53,910
Thanks Allen. What are these filters?
These filters are three d, uh, vectors.

189
00:10:53,911 --> 00:10:57,970
So why are they three d? While they are
today, there are a collection of matrices,

190
00:10:57,971 --> 00:11:01,360
right? But there are three d
because of the, the third, uh,

191
00:11:01,870 --> 00:11:06,010
the third dimension is, it's, it's
that RGB and it's a collection of them.

192
00:11:06,280 --> 00:11:09,940
So we've got like say however many filters
we wanted to find, the more filters,

193
00:11:10,090 --> 00:11:14,560
the more accurate our, uh, if we
were willing to do classification,

194
00:11:14,590 --> 00:11:18,250
it's going to be, and these are the
filters that we're going to use.

195
00:11:18,251 --> 00:11:21,250
And so what happens is at
each convolutional filter,

196
00:11:21,470 --> 00:11:25,240
we weren't to perform eight matrix
multiplication and then a summation

197
00:11:25,241 --> 00:11:27,160
operations.
And if there,

198
00:11:27,161 --> 00:11:31,720
if it detects if it detects the feature
and the result is going to be a very

199
00:11:31,721 --> 00:11:34,990
large number, but if it doesn't detect
the feature is going to be zero.

200
00:11:35,290 --> 00:11:38,530
And so we can think of these filters
at feature identifiers. Okay.

201
00:11:38,531 --> 00:11:41,860
They're identifying certain features.
And so what we're going to do for,

202
00:11:42,130 --> 00:11:46,160
for this or this is we're
going to perform, um,

203
00:11:46,830 --> 00:11:51,780
we're going to minimize the loss between
the labeled image and the feature. Uh,

204
00:11:51,790 --> 00:11:53,020
so what happened actually,

205
00:11:53,500 --> 00:11:58,500
what BGG was initially set out to do was
he was initially set out to minimize a

206
00:11:58,541 --> 00:12:02,830
loss between a label image and a future
map output. So at each of these layers,

207
00:12:02,831 --> 00:12:04,990
after all of these operations,

208
00:12:05,110 --> 00:12:09,700
it's once an outmoded output what's
called a feature map or an activation map.

209
00:12:09,730 --> 00:12:13,450
It's the same thing, which is just
a huge matrix of values. Okay?

210
00:12:13,750 --> 00:12:17,500
And we want to minimize the difference
between what that feature map is and then

211
00:12:17,501 --> 00:12:21,940
what our content is. Okay? So
that's what we're gonna do here.

212
00:12:22,240 --> 00:12:26,840
And um, so those are
our two images, right?

213
00:12:26,841 --> 00:12:30,350
We have a content image that's going to
be whatever we want to modify and then a

214
00:12:30,351 --> 00:12:31,131
style image,

215
00:12:31,131 --> 00:12:34,430
which is going to be whenever style that
we think is cool that we want to apply

216
00:12:34,431 --> 00:12:37,580
to this content image. Lastly,
we have this mixed image,

217
00:12:37,581 --> 00:12:42,320
which is going to be just an empty random
noise initialized matrix that we're

218
00:12:42,321 --> 00:12:44,240
going to add to over time.
Okay?

219
00:12:44,540 --> 00:12:47,990
We're going to use what kind of
compute two different style or uh,

220
00:12:48,080 --> 00:12:48,920
loss functions.

221
00:12:49,190 --> 00:12:52,460
We're going to do the style loss and
we're going to do the content loss.

222
00:12:52,760 --> 00:12:54,890
And then we're going to
combine those loss functions.

223
00:12:55,130 --> 00:12:56,990
And then we're going to
use a gradient value,

224
00:12:56,991 --> 00:13:00,440
which we're going to talk about
to update this mixed image. Okay?

225
00:13:00,441 --> 00:13:03,530
So that's the high level overview of
what this, what's going to happen.

226
00:13:03,531 --> 00:13:08,330
And after a hundred to a
thousand iterations, this
image is going to be mixed.

227
00:13:08,630 --> 00:13:11,750
Okay? So that's what the high
level is of what this is. Okay?

228
00:13:12,410 --> 00:13:14,750
So we're going to start off by
importing our for dependencies.

229
00:13:14,751 --> 00:13:18,200
Map all live is going to help us plot
out what we see tensorflow is our machine

230
00:13:18,201 --> 00:13:23,120
learning library num Pi is going to help
us calculate what's called the Graham

231
00:13:23,120 --> 00:13:25,250
Matrix that we're going to do.
I'm going to talk about later all on.

232
00:13:25,580 --> 00:13:29,000
And then Pila images is going to show
the image that we want to show. Okay?

233
00:13:29,240 --> 00:13:33,440
I'm now using tensorflow version a
one and everybody else should as well.

234
00:13:33,530 --> 00:13:37,870
They have updated it. And
the other thing is, uh, uh,

235
00:13:37,910 --> 00:13:41,240
I'm using python three so everybody
should update to python three. Yes,

236
00:13:41,450 --> 00:13:46,040
I finally updated to python three. Okay.
And it's really easy to update. Just,

237
00:13:46,320 --> 00:13:50,420
you know, Google Update Python Three
Jupiter notebook. It's just, um, you know,

238
00:13:50,530 --> 00:13:53,750
you could do it in two or three lines,
a command lines with Anaconda.

239
00:13:54,020 --> 00:13:57,350
So the first thing we're
going to do is import BGG 16.

240
00:13:57,351 --> 00:14:00,980
This is a 16 layer convolutional
neural network. Okay.

241
00:14:01,100 --> 00:14:02,750
This was pretrained.
Okay.

242
00:14:02,751 --> 00:14:06,290
So this network already
has all of those filters.

243
00:14:06,750 --> 00:14:10,190
They're already has all of those filters
and we want to use these filters as

244
00:14:10,191 --> 00:14:13,850
tools to help us perform style transfer.
Okay.

245
00:14:13,851 --> 00:14:17,720
So that's the first step is important.
Bgg 16 and never going to download it.

246
00:14:17,730 --> 00:14:20,390
And so I'm already downloaded it.
It's a big file,

247
00:14:20,391 --> 00:14:23,570
half a Gig and it's probably
going to take, you know,
depending on your bandwidth,

248
00:14:23,600 --> 00:14:26,360
anywhere from 10 minutes to an
hour to download this thing.

249
00:14:26,600 --> 00:14:27,650
But once you download it,

250
00:14:27,770 --> 00:14:31,070
you're good to go because everything
else is going to be local. Okay.

251
00:14:31,100 --> 00:14:35,150
So now the next step is to define
our image helper functions.

252
00:14:35,360 --> 00:14:38,120
So we've got three of these and you
know, they're, they're very, you know,

253
00:14:38,121 --> 00:14:42,290
standard load, load the image, save
the image and plot the image. Okay.

254
00:14:42,440 --> 00:14:46,090
And it's using non Pi to do
these three, uh, functions.

255
00:14:46,091 --> 00:14:49,400
So these are just standard functions
and I'll talk about these later on,

256
00:14:49,401 --> 00:14:53,540
but right now, just know that there to an
image, save an image and plot an image.

257
00:14:53,541 --> 00:14:57,460
Okay? So we haven't done any
machine learning yet. Uh,
these are just, you know,

258
00:14:57,470 --> 00:15:01,700
standard image help her function. So now
let's get to the machine learning. Okay?

259
00:15:01,820 --> 00:15:06,820
So what we're going to do right now
is we are going to define our loss

260
00:15:08,880 --> 00:15:11,700
functions. Okay? So before
we define our loss function,

261
00:15:11,720 --> 00:15:14,690
we want you to find
the mean squared error.

262
00:15:14,691 --> 00:15:18,290
So let me just type this out and I'm
going to talk about what is the mean

263
00:15:18,291 --> 00:15:20,030
squared error.
Okay?

264
00:15:20,031 --> 00:15:24,970
So the mean squared error is a function
given input tensors so are in presenters.

265
00:15:24,980 --> 00:15:28,280
In this case we're going to be called
A and B and I'll talk about what these

266
00:15:28,281 --> 00:15:31,730
templates are,
but it's just one line of code.

267
00:15:31,790 --> 00:15:35,510
And the one line is going to be 10
truckloads reduce mean function.

268
00:15:35,690 --> 00:15:36,500
And then it's going to,

269
00:15:36,500 --> 00:15:39,650
we're going to take the square value
of the difference between both of these

270
00:15:39,651 --> 00:15:43,940
tenters. That's it. Okay. So, and
then I'll, I'll compile that. Okay.

271
00:15:43,941 --> 00:15:45,050
So what is happening here?

272
00:15:45,051 --> 00:15:50,000
So the mean squared error
is the average of two,

273
00:15:50,110 --> 00:15:53,330
uh, is the, is the, is
the difference between,

274
00:15:53,360 --> 00:15:57,190
it's the average of the square of the
difference between both the output feature

275
00:15:57,200 --> 00:16:00,920
map and the image that we're
going to the army put him in.

276
00:16:00,921 --> 00:16:05,510
So let's look at what's happening
here. Okay. So it was called, um,

277
00:16:06,680 --> 00:16:10,760
BGG 16, because there's 16
layers and uh, you know,

278
00:16:10,820 --> 00:16:13,790
more layers mean generally
better predictions,

279
00:16:13,791 --> 00:16:17,430
but less layers mean less computation
times. So it's a trade off.

280
00:16:17,760 --> 00:16:20,930
It's up for mean squared error.
We're taking two input tents.

281
00:16:20,970 --> 00:16:24,840
So one of these tents, hers is
going to be our image. Okay. Uh,

282
00:16:24,920 --> 00:16:28,280
either our content they made or our
style image and we're going to use it for

283
00:16:28,281 --> 00:16:32,930
both and the other tents or is going
to be the, uh, the feature map. Okay.

284
00:16:32,931 --> 00:16:36,680
The result of the, uh,
whenever layer that we choose.

285
00:16:36,681 --> 00:16:40,190
And so what we're gonna do is we're
going to subtract the difference.

286
00:16:40,191 --> 00:16:44,060
So these are two matrices, okay. And
we're going to subtract the difference,

287
00:16:44,300 --> 00:16:46,760
the square of the, okay. And
then we're going to square that.

288
00:16:47,240 --> 00:16:51,620
And then we're going to do reduce means.
So what is reducing meat? Okay, so right.

289
00:16:51,621 --> 00:16:53,940
So this just this value right here.
Do you have thoughts?

290
00:16:53,941 --> 00:16:58,910
Square of the difference between these
two tensors is going to be a matrix

291
00:16:58,911 --> 00:17:02,600
valley. And then we want to reduce the
mean. So what did that mean? So we,

292
00:17:02,601 --> 00:17:06,350
if we have a matrix to reduce the mean,
so it would just be like this.

293
00:17:06,620 --> 00:17:11,060
We're going to find the average of all
of those values inside of that Matrix.

294
00:17:11,061 --> 00:17:16,000
So for this, a two dimensional, uh,
this matrix right here, one, one, two,

295
00:17:16,001 --> 00:17:20,700
two,
okay?

296
00:17:21,120 --> 00:17:25,140
It's going to be a 1.5. So that's the
average value of this whole major.

297
00:17:25,141 --> 00:17:28,830
So this is going to output a scaler
which is a single value, okay?

298
00:17:28,831 --> 00:17:32,410
That's what means where an error is
doing, okay? And it's a weight. And, and,

299
00:17:32,411 --> 00:17:35,730
and the reason we square it so
that it's positive. Okay? Uh,

300
00:17:35,731 --> 00:17:39,900
we went to a positive value. Oh, okay.
So that's what we're going to use as a,

301
00:17:40,110 --> 00:17:44,310
as a helper function inside of our
content laws and our style loss. Okay?

302
00:17:44,311 --> 00:17:48,180
So the first thing we're going to do
is write out a function for our content

303
00:17:48,181 --> 00:17:49,014
loss.
Okay.

304
00:17:49,140 --> 00:17:53,400
So we're going to call it create content
loss and inside of it we're going to

305
00:17:53,401 --> 00:17:58,140
use that, uh, mean squared error
function. All right, thanks Erez.

306
00:17:58,550 --> 00:18:03,160
Um, so our parameters for this,
we're going to be session.
Okay. So our are session,

307
00:18:03,300 --> 00:18:07,530
the model we're going to
use, I need to relax. Okay.

308
00:18:07,531 --> 00:18:09,830
I'm trying to talk slower
and he's lied sections.

309
00:18:09,831 --> 00:18:13,590
So let me do that because at one point
I'm height and the other point I want to

310
00:18:13,591 --> 00:18:17,400
be as clear and communicative
as possible so I will slow down.

311
00:18:17,401 --> 00:18:20,850
I'm really trying to improve
the speed of my speech.

312
00:18:20,851 --> 00:18:24,720
I've gotten a lot of great feedback on
that and I'm very open to more feedback.

313
00:18:25,050 --> 00:18:29,160
So the parameters for this content laws
are going to be the tensorflow session,

314
00:18:29,490 --> 00:18:34,170
the model, which is DGG 16, the
content image, and then the layer ids,

315
00:18:34,171 --> 00:18:38,370
which are the indices for which layers
we want to use to get those output

316
00:18:38,371 --> 00:18:40,090
feature maps. And these are the, the,

317
00:18:40,330 --> 00:18:45,030
the layers that we have decided to
use for optimizing for content loss.

318
00:18:45,210 --> 00:18:47,700
And these are going to be the
higher level layers. Okay.

319
00:18:47,701 --> 00:18:52,140
Because those higher level layers in
a convolutional nets are akin to the

320
00:18:52,141 --> 00:18:52,830
content,
right?

321
00:18:52,830 --> 00:18:56,520
These are the big high level objects
that are inside of an image or like,

322
00:18:56,640 --> 00:19:00,660
you know, for a van Gogh it would be the
moon and the houses, things like that.

323
00:19:00,661 --> 00:19:04,440
And the lower levels are the texture
or the contours, like the lungs,

324
00:19:05,510 --> 00:19:09,570
quantum may, I actually increases the
speed of my videos. Interesting. Okay,

325
00:19:09,571 --> 00:19:13,140
well you're in the minority. Okay.
But maybe, I don't even know.

326
00:19:13,500 --> 00:19:16,290
It'd be cool to get some data.
Maybe I can do a boat back to this.

327
00:19:16,410 --> 00:19:19,740
So the first thing we're going to do
is once you've define HP dictionary,

328
00:19:19,770 --> 00:19:24,300
now a Phoenix and is a python
dictionary object that's generated with

329
00:19:24,301 --> 00:19:26,060
placeholders as Keith's.

330
00:19:26,520 --> 00:19:30,700
This essentially is going to generate
a set of placeholder values. Okay.

331
00:19:31,140 --> 00:19:35,820
And in a place holders are
going to be your image, right?

332
00:19:35,821 --> 00:19:38,750
So that's it.
So what this did is it generated a team.

333
00:19:38,751 --> 00:19:43,470
Now you care where the key was, the image
and the value was the content image.

334
00:19:43,560 --> 00:19:47,940
So we do this every time we want to feed
anything into arc computation graph,

335
00:19:47,941 --> 00:19:51,540
we feed it in as a dictionary,
okay? So that was the first step.

336
00:19:51,930 --> 00:19:55,200
And then the next step we're going to
do is we're going to define what our

337
00:19:55,201 --> 00:19:55,801
layers are.

338
00:19:55,801 --> 00:19:59,760
Now we have our model that we defined
as our parameter and then we're going to

339
00:19:59,761 --> 00:20:03,930
get those cancers, uh, by
defining those layer ideas. Okay?

340
00:20:03,931 --> 00:20:08,580
So we can play around with what indices
we want to use for our layer ids and the

341
00:20:08,581 --> 00:20:10,110
researchers in this paper did as well.

342
00:20:10,111 --> 00:20:13,710
You're going to get different results
from different layers that you use, okay?

343
00:20:13,711 --> 00:20:16,860
And this is not to say that these are
the best and disease, but they are,

344
00:20:16,950 --> 00:20:21,760
there are a set of indices that do give
us good results. And abstracting this, uh,

345
00:20:21,930 --> 00:20:24,960
question even further, what
defines beauty? Can we,

346
00:20:25,350 --> 00:20:28,950
can we frame beauty in and of
itself as an optimization problem?

347
00:20:29,220 --> 00:20:30,900
This is something to
think about in the future.

348
00:20:31,050 --> 00:20:34,800
How can we minimize a loss for beauty?
Beauty is so subjective, but can,

349
00:20:34,980 --> 00:20:38,610
can it be objective? So something to
blow your mind a little bit. Uh, okay,

350
00:20:38,611 --> 00:20:40,200
so those are layers.

351
00:20:40,230 --> 00:20:43,720
So the next thing we're going to do is
we're going to calculate our values.

352
00:20:43,721 --> 00:20:46,470
So these are the output values
when we've run our session,

353
00:20:46,770 --> 00:20:50,320
given the layers that we've just helped
calculated and we beat it in our feet

354
00:20:50,410 --> 00:20:53,590
dictionary. Okay. Okay.

355
00:20:53,591 --> 00:20:58,591
So what this is going to do is it's
going to get me a output values for those

356
00:20:58,841 --> 00:21:03,160
layers, for the, for the content image.
Okay? So the next step is we're going to

357
00:21:04,330 --> 00:21:05,163
okay.

358
00:21:05,260 --> 00:21:08,890
Say, okay, so we're going to
run the model graph now. Okay.

359
00:21:08,891 --> 00:21:13,470
So for the model graph,
we're going to say as defaults.

360
00:21:13,840 --> 00:21:16,210
All right?
See how many,

361
00:21:17,590 --> 00:21:17,850
okay.

362
00:21:17,850 --> 00:21:21,970
Excellent. Monograph as
default. And uh, okay.

363
00:21:21,971 --> 00:21:24,460
So now what we're going to do is
we're going to initialize our losses.

364
00:21:24,461 --> 00:21:29,020
So this is setting, so we can, so we're
going to add computational notes to it.

365
00:21:29,021 --> 00:21:31,420
And uh,
that's what we're going to do right now.

366
00:21:31,421 --> 00:21:34,300
So let's first define our
losses because we're active.

367
00:21:34,301 --> 00:21:39,160
Then I calculate a collection of
losses and utilize an empty list. Okay?

368
00:21:39,161 --> 00:21:43,480
We'll call it layer, uh, losses.
That's the name of our list. And

369
00:21:45,320 --> 00:21:49,150
the next step is we're going to move
down a little bit. We're gonna say, okay,

370
00:21:49,151 --> 00:21:53,800
so for each layer that we have for valued,
for each layer that we have,

371
00:21:53,801 --> 00:21:57,880
what we you iterate through those layers
that we get fined in those indices.

372
00:22:00,490 --> 00:22:03,610
Okay? Uh, values layers,

373
00:22:06,970 --> 00:22:07,803
okay?

374
00:22:10,000 --> 00:22:10,600
Okay.

375
00:22:10,600 --> 00:22:14,020
That's where they start contributing to
AI is to just start pushing code to get

376
00:22:14,021 --> 00:22:18,430
hub that you, that you find
fun and documenting it really
well. And then, you know,

377
00:22:18,431 --> 00:22:21,040
marketing, like posting it to
people and sharing it with people.

378
00:22:21,041 --> 00:22:22,570
We're all sharing,
you know,

379
00:22:22,630 --> 00:22:25,420
the line between research
and production is quite thin.

380
00:22:25,421 --> 00:22:28,780
Everything is really a discovery
in and up in, in any, in any way,

381
00:22:28,781 --> 00:22:31,350
even as simple hyper parameter change.
Uh,

382
00:22:31,410 --> 00:22:35,360
since you can result in an
incredible discovery, uh, personal,

383
00:22:35,380 --> 00:22:36,790
their link is in the description.
Okay?

384
00:22:36,791 --> 00:22:40,780
So what we're doing is for every layer
we are iterating through every single

385
00:22:40,781 --> 00:22:45,070
layer. Right now we're waiting to get
that value. Okay? So what does that value?

386
00:22:45,071 --> 00:22:48,820
We're going to define it as a TF
constant with comedic 10, not change.

387
00:22:49,240 --> 00:22:53,590
And this is once you, uh, BB,
uh, content, images value. Okay.

388
00:22:53,591 --> 00:22:57,790
So then what we're going to do now is open
to calculate that loss. Okay, now lost.

389
00:22:58,090 --> 00:23:02,440
And now this is where we use that mean
squared error that we defined earlier.

390
00:23:02,740 --> 00:23:06,260
And we're gonna use it to the two in
pretenses are going to be the value add a

391
00:23:06,261 --> 00:23:10,570
layer and then the constant
value. So this is the, the book,

392
00:23:10,571 --> 00:23:14,630
the content image and then the, the,
the set of features at a layer. Amber,

393
00:23:14,650 --> 00:23:18,070
what you minimize that loss. The
basketball for deep learning is, um,

394
00:23:19,110 --> 00:23:23,410
the deep learning book by
Ian Goodfellow. Okay? Uh, no.

395
00:23:23,411 --> 00:23:27,490
The one by Yoshua Bengio search
Giyasova Nto learning such a great book,

396
00:23:27,610 --> 00:23:32,050
especially for the mass loss
amines. Right? Air. Okay.
So now we're going to say,

397
00:23:32,051 --> 00:23:32,321
okay,

398
00:23:32,321 --> 00:23:35,680
so these are all of our losses that were
calculated and we'll get to append it

399
00:23:35,681 --> 00:23:36,514
to that list,

400
00:23:36,550 --> 00:23:41,510
that empty Lou when to do it,
right?

401
00:23:41,980 --> 00:23:46,730
More Games. And I'm a full on game
AI next. So we'll see how that goes.

402
00:23:46,731 --> 00:23:49,190
I think it'll be very,
very popular.

403
00:23:49,490 --> 00:23:52,370
So once we have all of
those loss functions,

404
00:23:54,820 --> 00:23:58,470
like be a good average value,

405
00:23:58,500 --> 00:24:00,180
you think that's reduced mean function.
Okay?

406
00:24:00,181 --> 00:24:05,181
So these are our layers losses and
that's after we're done with everything.

407
00:24:05,400 --> 00:24:09,850
Okay? And then, uh,
we're going to say, okay,

408
00:24:09,851 --> 00:24:11,920
so at the end of this we're
going to return the total loss.

409
00:24:12,100 --> 00:24:16,090
So what this is going to do is this is
going to give us a total loss value.

410
00:24:16,210 --> 00:24:21,170
And let's talk about what we
just did. We said, okay, uh,

411
00:24:22,030 --> 00:24:26,190
we're going to get the mean squared or
of the teacher had to be in the given

412
00:24:26,191 --> 00:24:30,210
layers in the model. So between the
content image and the mixed image.

413
00:24:30,390 --> 00:24:34,800
And so when this is minimized, it's
going to, when we minimize this,

414
00:24:34,801 --> 00:24:39,180
it's going to make them mixed image
that much more stylized. Okay? So this,

415
00:24:39,181 --> 00:24:43,560
this defines our content boss. So ideally
we can do the live style loss as well,

416
00:24:43,561 --> 00:24:48,000
right? We just take both up, feature the
feature maps from a layer and then the,

417
00:24:48,050 --> 00:24:52,790
uh, you know, the, the
image, uh, where whether the,

418
00:24:52,960 --> 00:24:57,150
the style image of the content image and
we just calculate the mean square error

419
00:24:57,151 --> 00:25:00,510
between them and we minimize
that. But we cannot, uh,

420
00:25:00,960 --> 00:25:05,730
previous line from the last either a typo.
Thank you. But we cannot do that. Okay.

421
00:25:05,731 --> 00:25:09,730
So we cannot do that because,
uh,

422
00:25:10,090 --> 00:25:14,470
for whatever reason, wow. That actually
compile without any errors because w okay.

423
00:25:14,471 --> 00:25:18,970
So let's, let's actually answer
this, why we can't talk about,

424
00:25:21,550 --> 00:25:21,950
okay.

425
00:25:21,950 --> 00:25:26,720
Right. Total loss. Thank you Allen.
So, so we don't do that for style.

426
00:25:26,721 --> 00:25:30,040
For style. We add eight, another step
called the gram matrix and let's,

427
00:25:30,200 --> 00:25:32,360
let's really talk about
what is happening here.

428
00:25:33,620 --> 00:25:36,540
So the reason we use a gram
matrix, so let, let's let,

429
00:25:36,541 --> 00:25:39,380
let me show an image of this, this,
this, this, this will help. So

430
00:25:44,080 --> 00:25:48,990
that's okay. Okay. So this is,
so this is kind of scary looking,

431
00:25:48,991 --> 00:25:53,370
but don't worry about it. A grime
interest. All it is, is we are taking the,

432
00:25:53,730 --> 00:25:57,140
uh, measuring the correlation
between our teacher chant,

433
00:25:57,180 --> 00:26:00,590
like doctors after flattening the
featured filter image into vectors.

434
00:26:00,591 --> 00:26:03,640
So all this is doing is
it's taking, it's, it's,

435
00:26:04,170 --> 00:26:09,170
it's the matrix product between our
initial matrix and then its transpose,

436
00:26:10,261 --> 00:26:14,010
which is just, uh, which is just
flipping at 90 degrees. Essentially.

437
00:26:14,011 --> 00:26:16,470
We're just multiplying a
matrix by its transpose.

438
00:26:16,471 --> 00:26:21,471
That's it multiplying a matrix by its
transpose that is the grand matrix.

439
00:26:21,540 --> 00:26:26,400
Okay. And so that's what
we're doing for that layer.

440
00:26:26,460 --> 00:26:31,290
Okay. And for our style. So for
every uh, style layer that we choose,

441
00:26:31,530 --> 00:26:33,630
we're going to calculate a gram matrix.

442
00:26:33,900 --> 00:26:37,530
And that Graham Matrix is what we're
going to use to minimize via the mean

443
00:26:37,531 --> 00:26:40,380
squared error. So let's just start
building and then we'll start,

444
00:26:40,410 --> 00:26:45,060
start talking about what exactly is
happening. So for brand matrix function,

445
00:26:45,061 --> 00:26:47,160
we're going to have our input tensor.
Okay.

446
00:26:47,161 --> 00:26:51,400
So you think better of the dot products
for vectors of the feature activity

447
00:26:51,520 --> 00:26:53,340
patients have a style layer.

448
00:26:55,460 --> 00:26:56,210
Okay.

449
00:26:56,210 --> 00:26:59,650
Uh, yeah I did. And it was the equal sign,
right? For the total total loss. Okay.

450
00:26:59,651 --> 00:27:02,230
So the grand major 10,

451
00:27:02,320 --> 00:27:05,980
remember guys we following along and
the get help link that I've linked to in

452
00:27:05,981 --> 00:27:09,550
the district and it's got all my notes.
I'm basically talking through it and,

453
00:27:09,590 --> 00:27:14,350
and coding at the same time.
So this is going to be a for the tensor,

454
00:27:14,470 --> 00:27:16,870
okay. This is going to be a 40 tensor, uh,

455
00:27:16,960 --> 00:27:21,070
at a given layer because we
have the, we have, right?

456
00:27:21,071 --> 00:27:23,560
So it's gonna be the collection
of pixels and then the RGB,

457
00:27:23,561 --> 00:27:27,370
which makes it three d and it's 40,
because we have a collection of those.

458
00:27:27,580 --> 00:27:30,310
So we have several of those.
So we have a collection of broody tensors,

459
00:27:30,430 --> 00:27:34,030
which means it take for the tenser and
that's what the shape is going to be.

460
00:27:34,330 --> 00:27:37,600
And what we want to do for our style
layers is we're going to calculate our,

461
00:27:38,340 --> 00:27:39,810
uh,
uh,

462
00:27:40,370 --> 00:27:45,290
brand matrix hello up Doula. So now we're
going to say, let's get those channels.

463
00:27:45,340 --> 00:27:49,400
Okay. So channels are just even
those. So if you think of, uh,

464
00:27:49,700 --> 00:27:53,810
the outputs of each layer,
so an output of each layer is going to be,

465
00:27:54,640 --> 00:27:59,200
let's see what our history was.
CDS,

466
00:27:59,210 --> 00:28:00,380
like stacks of layers.

467
00:28:00,560 --> 00:28:04,400
Each of these stacks is a matrix
and we call those our channels.

468
00:28:04,670 --> 00:28:07,100
Each of these is is one of our channels.
Okay.

469
00:28:07,101 --> 00:28:11,780
So it's the word activation and
feature as it's used similarly.

470
00:28:11,781 --> 00:28:14,480
So feature map activation
happens, same thing. Okay,

471
00:28:14,630 --> 00:28:16,040
so back our number of channels.

472
00:28:16,041 --> 00:28:19,310
Where we want to do is we want
to define these channels and

473
00:28:22,270 --> 00:28:25,180
we're going to get the number of Eagle
Peter Channels for the input tensor,

474
00:28:25,450 --> 00:28:29,950
which is assumed to be a convolutional
layer with four dimensions. Okay. And then

475
00:28:31,530 --> 00:28:35,250
we're going to say, let's get the
matrix, which is going to be the,

476
00:28:36,510 --> 00:28:40,080
let's talk about what this matrix
and this matrix is going to be.

477
00:28:40,260 --> 00:28:43,410
We have a shape, it's going to be
negative one. And then number of council,

478
00:28:43,440 --> 00:28:44,550
what did we just do here?
So

479
00:28:46,510 --> 00:28:48,550
hang on one means whatever
number makes this state of fit.

480
00:28:48,580 --> 00:28:49,900
That's why we put negative one in here.

481
00:28:49,901 --> 00:28:52,300
But what we're doing is
we're reshaping the tensor.

482
00:28:52,510 --> 00:28:54,610
So it is a two dimensional matrix.

483
00:28:54,611 --> 00:28:58,660
So it basically just a flattens the
contents of each of the feature channels.

484
00:28:59,140 --> 00:28:59,471
That's what the,

485
00:28:59,471 --> 00:29:02,740
it's flattening the contents of each
of the feature channels so that we can

486
00:29:02,741 --> 00:29:07,600
multiply it, uh, in a second through ts
matrix multiplication function. We are,

487
00:29:08,080 --> 00:29:11,300
we are making it, it's a kin
to normalization. Okay. It's,

488
00:29:11,660 --> 00:29:15,760
we're taking both of these values
between art style, uh, and our, uh,

489
00:29:15,790 --> 00:29:17,440
mixed image and we are normalizing it.

490
00:29:17,441 --> 00:29:21,040
You think this reshape function such
so that we can multiply it in a second.

491
00:29:21,070 --> 00:29:23,590
Okay. So let's get back
Graham Matrix now. Okay.

492
00:29:23,591 --> 00:29:28,270
So we're going to use 10 truckloads
matrix multiplication function to do this

493
00:29:28,480 --> 00:29:30,640
and we've got this great
transpose function.

494
00:29:30,641 --> 00:29:34,690
So we're going to remember it's a grand
matrix and just a matrix multiplied by

495
00:29:34,691 --> 00:29:39,640
its transpose. So the same matrix will
multiply by its transpose and then

496
00:29:40,800 --> 00:29:41,250
okay,

497
00:29:41,250 --> 00:29:42,510
okay.
So there transposed

498
00:29:42,570 --> 00:29:45,810
by the Matrix and remove it's
comma cause we don't need it.

499
00:29:46,290 --> 00:29:49,830
And then that's going to be art remix
and then we can return that. Okay.

500
00:29:57,200 --> 00:30:01,690
Uh, so it style transfer is an extension
of a convolutional nets. Uh, it has uh,

501
00:30:01,750 --> 00:30:03,300
Ganzer a whole different ballgame.

502
00:30:03,380 --> 00:30:05,560
There are a whole different ballgame and
we're going to talk about that later.

503
00:30:05,561 --> 00:30:07,810
But before we understand how gangs work,

504
00:30:07,811 --> 00:30:12,520
we have to understand how a transfer
learning works and how convolutional nets

505
00:30:12,521 --> 00:30:17,020
really work. And that's the goal of this.
Okay? So that's it for our grand matrix.

506
00:30:17,050 --> 00:30:21,070
So that is the extra step we add
freestyle loss. Okay. So let's see.

507
00:30:21,100 --> 00:30:23,650
Let's actually compute style loss.
All right?

508
00:30:25,150 --> 00:30:29,200
So what we're gonna do is we're going to
compute soloff's now given that Graham

509
00:30:29,200 --> 00:30:30,430
Matrix function that we used earlier.

510
00:30:30,670 --> 00:30:35,670
So the input to this are going to be the
same basic format that like we did for

511
00:30:36,911 --> 00:30:40,330
the content lots, except we're
using a solid image as our input,

512
00:30:40,331 --> 00:30:43,510
not at content image, right? And
we're adding this extra step,

513
00:30:43,511 --> 00:30:44,770
which is Graham maker steps.

514
00:30:44,771 --> 00:30:48,310
So we'll talk about what this looks like
when we get to it, but we're feeding in,

515
00:30:48,320 --> 00:30:52,450
remember the dictionary and it's
creates placeholders for our, uh,

516
00:30:52,451 --> 00:30:54,160
feed dicks and

517
00:30:55,950 --> 00:30:56,700
okay,

518
00:30:56,700 --> 00:30:59,980
went to, and this is going to create a
placeholder value for our style image.

519
00:31:00,250 --> 00:31:04,210
And then the next step is to get the
layers to our layers are going to be

520
00:31:04,600 --> 00:31:07,200
whatever we got from our layer id.

521
00:31:07,201 --> 00:31:11,050
So whatever we defined and we defined
these earlier or we will define these

522
00:31:11,051 --> 00:31:11,920
layer ids,
right?

523
00:31:11,960 --> 00:31:15,820
These are essentially a can to hyper
parameters for this or this particular

524
00:31:15,821 --> 00:31:19,930
optimization problem because as we tune
these are the results will be different,

525
00:31:19,931 --> 00:31:21,100
right?
So,

526
00:31:22,560 --> 00:31:22,850
okay,

527
00:31:22,850 --> 00:31:26,670
because there are layers. So now we're
going to define our model. Okay. So it's,

528
00:31:26,690 --> 00:31:30,450
you know, very similar. We're going
to define our model as defaults and

529
00:31:33,170 --> 00:31:34,003
okay,

530
00:31:34,090 --> 00:31:36,910
so we're going to define our gram layer.
So this is where our,

531
00:31:37,000 --> 00:31:41,620
this is the line that is difference
comparatively compared to the content,

532
00:31:42,130 --> 00:31:46,180
uh, Blas. This style loss means we
have to take the grand maple scenes.

533
00:31:46,420 --> 00:31:49,810
That is a difference here. We're taking
the grant-maker seeds of each layer.

534
00:31:49,811 --> 00:31:53,440
We're not just saying here's the raw
layer of value, which is just that matrix.

535
00:31:53,441 --> 00:31:57,600
We're saying get the gram matrix on
that layer. So, and also, you know, to,

536
00:31:57,610 --> 00:32:00,660
to give some backup to this gets,

537
00:32:00,661 --> 00:32:04,840
he's the guy who initially made this when
asked why the grand matrix in a talk,

538
00:32:04,841 --> 00:32:06,580
he said the grant Matrix and codes,

539
00:32:06,650 --> 00:32:09,670
second order statistics
of the set of filters. Oh,

540
00:32:09,740 --> 00:32:11,550
I'll talk about the noise
and get a second Javier.

541
00:32:11,830 --> 00:32:14,410
But basically it's looking
at it from a higher level.

542
00:32:14,830 --> 00:32:17,680
So it sort of mushes all the
features at a given layer,

543
00:32:17,920 --> 00:32:22,090
tossing spatial information aside in
favor of a measure of how different

544
00:32:22,091 --> 00:32:24,580
teachers are correlated.
So by, so Graham mates,

545
00:32:24,581 --> 00:32:29,020
your seats essentially or like it toss
away everything that's unnecessary just

546
00:32:29,021 --> 00:32:33,310
to focus on this style. And,
and this works for style,

547
00:32:33,311 --> 00:32:36,520
but not for content. It's lower layer. And

548
00:32:37,820 --> 00:32:41,450
I'm sure there's more theory why
reading the Grand Matrix, but, uh,

549
00:32:41,480 --> 00:32:44,690
that's the best I could get out
of Getty's. Um, and you know,

550
00:32:44,780 --> 00:32:46,640
it's better than just
saying it just works. Right.

551
00:32:46,641 --> 00:32:51,240
Which is a lot of machine learning.
Uh, right. So, so that's the grim, uh,

552
00:32:51,680 --> 00:32:55,100
layers. And then we have,
where were we again?

553
00:32:55,101 --> 00:32:57,650
So I went up for a second and go
back down. Okay. So where were we?

554
00:32:57,651 --> 00:32:58,820
We were rights here.

555
00:32:59,180 --> 00:33:03,590
So we said that we're taking our grand
layers and we were feeding an art

556
00:33:03,591 --> 00:33:04,101
dictionary.

557
00:33:04,101 --> 00:33:09,101
So for feeding at that dictionary
that we just defined edict,

558
00:33:10,250 --> 00:33:13,980
and we're saying that,
uh,

559
00:33:15,290 --> 00:33:18,980
we're going to define
our layers, losses. So

560
00:33:20,590 --> 00:33:24,320
I'll just say now we're defining that
MP a list that we're going to add all of

561
00:33:24,321 --> 00:33:27,350
our layer losses too,
right? So, so that's that.

562
00:33:27,380 --> 00:33:30,950
Those are our two lines before we get
started with our iteration periods.

563
00:33:30,950 --> 00:33:33,860
So for our iteration period, what we're
going to do is we're going to say, okay,

564
00:33:33,861 --> 00:33:36,860
so for all of those brand makeup seats,
at each layer,

565
00:33:37,070 --> 00:33:41,660
we're going to compute the loss
function so that we can minimize it.

566
00:33:42,020 --> 00:33:46,790
And so we're happy. We have to, um, input
here the value, which is a marketing edge,

567
00:33:47,060 --> 00:33:50,720
and then the grand layer,
which is the grand later. Okay?

568
00:33:50,721 --> 00:33:54,620
So the value is going to be
constant because it's a TF dot.

569
00:33:54,621 --> 00:33:56,880
Con because we don't want
it to change, right? We,

570
00:33:57,110 --> 00:33:59,390
it's not a variable because
we don't want it to change.

571
00:33:59,391 --> 00:34:02,390
It's going to stay the same. And, uh,

572
00:34:02,540 --> 00:34:06,410
now we're going to just talk to the loss
to loss is going to be the mean squared

573
00:34:06,411 --> 00:34:09,620
error between,
and now this is the important part.

574
00:34:09,860 --> 00:34:14,860
The important part is we're calculating
the mean square error of the Graham

575
00:34:15,411 --> 00:34:18,080
layer and then the value constants.

576
00:34:18,230 --> 00:34:23,060
So this is between the grant matrix and
the value of a brand mantra matrix when

577
00:34:23,090 --> 00:34:26,780
inputting a style image. Okay? So

578
00:34:29,180 --> 00:34:33,800
that's between each of the layers and
the input style image layer. Okay?

579
00:34:33,801 --> 00:34:36,200
So then once we have all of those losses,

580
00:34:36,320 --> 00:34:40,580
we're going to add them all
to our wrist style list.

581
00:34:40,640 --> 00:34:45,560
So layer equal layer the losses
at each layer. So you know,

582
00:34:45,590 --> 00:34:49,820
we're combining these losses and we
later combine the combination of those

583
00:34:49,821 --> 00:34:53,240
losses between, right? So it's like
combining and then combining again we'll,

584
00:34:53,420 --> 00:34:55,190
we'll talk about the
second step of combining.

585
00:34:55,191 --> 00:34:57,230
But this is the first step of Kumbaya.

586
00:34:57,231 --> 00:35:01,250
We're combining losses for a
style of and for content. Okay,

587
00:35:01,251 --> 00:35:05,360
so we're appending whatever we calculated
at each iteration here. And then

588
00:35:07,100 --> 00:35:09,950
now we're going to calculate
the total loss with total loss.

589
00:35:10,430 --> 00:35:12,920
Total loss is going to be the

590
00:35:14,790 --> 00:35:19,310
going to reduce the mean
queen

591
00:35:21,060 --> 00:35:24,910
players so that we're going to take the
average of all of those losses. Remember,

592
00:35:25,100 --> 00:35:28,820
there's just takes the average of every
single number that we have in our matrix

593
00:35:29,090 --> 00:35:32,930
and then we're going to return that
value. Okay. And that's our style, floss.

594
00:35:32,931 --> 00:35:37,160
And we get, and this is a scalar value,
it's a, it's a single number. Okay.

595
00:35:37,170 --> 00:35:39,930
The scalar about him.
So that's our style loss.

596
00:35:40,970 --> 00:35:45,420
And then what do we got here? We've
got some invalid syntax. My favorite,

597
00:35:45,480 --> 00:35:46,710
my favorites.
Okay.

598
00:35:47,980 --> 00:35:50,980
Alright. Comma. Yeah. Okay.

599
00:35:52,080 --> 00:35:54,450
So that's what we did for that.
And uh,

600
00:35:57,010 --> 00:36:01,900
right. So feed dick, model dot
creates. Okay. Model dots. Create.

601
00:36:02,610 --> 00:36:03,640
See dicked.

602
00:36:04,630 --> 00:36:05,140
Yeah.

603
00:36:05,140 --> 00:36:09,820
Image style. Image. Uh, what is it
saying here? Oh, brand made friends.

604
00:36:10,120 --> 00:36:15,060
So for Graham Matrix Graham
layers, we have, see Dick,

605
00:36:15,190 --> 00:36:20,000
where was I? So many things to keep track
of your Oh, right. That was what it was.

606
00:36:20,260 --> 00:36:22,870
It's okay. So, um,

607
00:36:23,800 --> 00:36:24,260
okay,

608
00:36:24,260 --> 00:36:25,330
let's see. Oh, right, yeah.

609
00:36:26,610 --> 00:36:27,443
Great.

610
00:36:28,580 --> 00:36:33,230
Brand Matrix layers and then edict
or where we do our majors layers,

611
00:36:33,231 --> 00:36:34,160
four layers.

612
00:36:35,870 --> 00:36:36,703
Oh,
right.

613
00:36:39,190 --> 00:36:42,340
Let's see. Hold on. I had a lot of
code here that I'm looking at him.

614
00:36:42,390 --> 00:36:43,223
Hold on a second.

615
00:36:43,240 --> 00:36:48,240
So Graham layers are going
to be the gram matrix layers,

616
00:36:48,821 --> 00:36:53,410
four layers in theirs.
Oh,

617
00:36:53,411 --> 00:36:56,860
so what's actually, there's an extra
line here that I forgot about. So

618
00:36:59,040 --> 00:37:03,090
not about certain line
here.

619
00:37:06,540 --> 00:37:09,390
Hold on. There's a certain
line that I'm missing here. Ah,

620
00:37:09,930 --> 00:37:13,870
okay.
I'm just remove these right here.

621
00:37:16,020 --> 00:37:20,470
Great. So now, so there's actually one
more loss. I lied. There's one more loss,

622
00:37:20,680 --> 00:37:25,390
but I lied because it's
very, very trivial. And we
used, it was using the paper,

623
00:37:25,391 --> 00:37:28,640
but it's, it's not, you know,
it's very trivial and it's,

624
00:37:28,720 --> 00:37:32,020
it just starts to confuse if we,
if we talk about it at the start,

625
00:37:32,230 --> 00:37:34,280
but we're going to talk about it now.
So this is just,

626
00:37:34,390 --> 00:37:37,900
this is the de noising loss. And so
what happened was when, when they,

627
00:37:37,930 --> 00:37:39,670
when they didn't do this last one,

628
00:37:39,671 --> 00:37:43,330
they just computed the style and
the content was, the image was okay,

629
00:37:43,331 --> 00:37:45,490
but when they added this denoising loss,

630
00:37:45,760 --> 00:37:48,580
which we can also call
the total variation loss,

631
00:37:48,610 --> 00:37:52,930
it's also called that what happened
was the results improved. So,

632
00:37:53,860 --> 00:37:54,270
okay.

633
00:37:54,270 --> 00:37:57,540
What it does is it calculates
the difference between the,

634
00:37:57,541 --> 00:38:01,650
so it shifts the input image by
one pixel on the x and y axis.

635
00:38:01,710 --> 00:38:05,700
And then it calculates a difference
between the shifted image and the original

636
00:38:05,701 --> 00:38:07,740
image. And so the absolute, and we,

637
00:38:07,741 --> 00:38:11,460
and we use the absolute value to make it
positive. Okay. So let's talk about this.

638
00:38:11,461 --> 00:38:13,680
So this is the one more lost
than to never going to add.

639
00:38:13,920 --> 00:38:16,980
Very pretty a lot function. It's going
to be, you know, two lines of code,

640
00:38:17,340 --> 00:38:21,780
but a necessary to just know
slightly improve our results.

641
00:38:22,320 --> 00:38:22,651
And you know,

642
00:38:22,651 --> 00:38:26,900
there could be even more lock function
that we can think about and um, great.

643
00:38:26,910 --> 00:38:28,530
So there are 16 layers here.
Okay.

644
00:38:30,210 --> 00:38:30,860
Okay.

645
00:38:30,860 --> 00:38:34,690
Or is the absolute
value, um, for this and,

646
00:38:35,750 --> 00:38:36,150
okay.

647
00:38:36,150 --> 00:38:39,990
Uh, in fact I can just,
you know, I'm just going to

648
00:38:42,180 --> 00:38:44,740
paste this in here because we're going
to get right to the meat of the code.

649
00:38:44,950 --> 00:38:47,940
Now just talk about it since it's
just two lines. It's got a lot of, uh,

650
00:38:49,820 --> 00:38:53,780
medical things here. So we are, we are,
what we're doing here is we are, uh,

651
00:38:53,840 --> 00:38:56,960
taking the absolute value to make
this a positive value, right?

652
00:38:57,140 --> 00:39:00,590
And we're going to calculate the sum of
the pixels in these images and basically

653
00:39:00,591 --> 00:39:05,240
it can help suppress noise in the mixed
images that were generating. Okay? So

654
00:39:07,080 --> 00:39:10,460
we'll calculate the sum of the pixel
values between the shifted image and our

655
00:39:10,461 --> 00:39:12,590
original adage and the variation.

656
00:39:12,591 --> 00:39:15,020
And the variation is referring
to that shifted image.

657
00:39:15,220 --> 00:39:18,950
And the original image is it removes
the noise and the noise is like the

658
00:39:18,951 --> 00:39:23,660
blurriness. It's not that clear.
And by shifting it in my, you know,

659
00:39:23,661 --> 00:39:27,590
minimizing it, we're kind of like
recreating this blurriness and we're,

660
00:39:27,680 --> 00:39:28,460
we're saying,
you know,

661
00:39:28,460 --> 00:39:30,830
we could even shift it more than
one pixel line and try that.

662
00:39:30,831 --> 00:39:35,090
They didn't try that, you know, shifting,
you know, we could do other, um, you know,

663
00:39:35,450 --> 00:39:39,170
artificial noising step, like,
what can we do to like, you know,

664
00:39:39,500 --> 00:39:41,750
mess up this image in whatever way.
Okay.

665
00:39:42,800 --> 00:39:46,610
And then we're going to
optimize for minimizing that
so that our actual value is

666
00:39:46,611 --> 00:39:48,140
smaller. Okay. So,

667
00:39:50,180 --> 00:39:55,010
so now what we're going to do is, um,
how has the, how has the frame rate,

668
00:39:55,011 --> 00:39:55,660
by the way guys,

669
00:39:55,660 --> 00:39:59,540
I definitely tell me in the comments
how you feel about the frame rates. Um,

670
00:39:59,990 --> 00:40:03,140
I'm trying to improve my
life live streams. Okay.

671
00:40:03,141 --> 00:40:05,960
So now we're going to get to the good
stuff. This is the mean of the code.

672
00:40:06,110 --> 00:40:09,490
This is where it all comes together
to style transfer algorithms.

673
00:40:09,620 --> 00:40:13,010
This is where we build our model and
we're going to use the loss on that.

674
00:40:13,011 --> 00:40:14,150
We calculated,
okay,

675
00:40:14,390 --> 00:40:18,140
so let's talk about what these
parameters are going to be.

676
00:40:18,320 --> 00:40:21,060
So the creditors are going to be uh,
uh,

677
00:40:23,060 --> 00:40:27,170
the text is blurred. Pretty cool frame
rate. Thanks sir. Okay, framer seems good.

678
00:40:27,230 --> 00:40:30,260
All right, cool. So how much,

679
00:40:30,290 --> 00:40:34,550
so how much do we want to weigh these
loss functions is a good question. Okay,

680
00:40:34,700 --> 00:40:38,840
so you don't like this. This can be
played with, right? So what they did,

681
00:40:38,910 --> 00:40:41,060
so you can see here that the weight style,

682
00:40:41,360 --> 00:40:44,790
the wait for the style is going to be
10. And so it's almost, you know, it's,

683
00:40:44,840 --> 00:40:47,360
it's like eight times more than
the weight for the content.

684
00:40:47,540 --> 00:40:50,360
And we can modify these
weights so that we can,

685
00:40:51,140 --> 00:40:56,060
we've got 1:44 PM over there.
Okay. Um, very the text,

686
00:40:57,110 --> 00:41:00,500
I'll make this bigger. Yeah. Seven
20 Pete by C bomb. Okay. Interesting.

687
00:41:00,501 --> 00:41:03,560
So we've got all over
the place. Um, okay. So,

688
00:41:04,550 --> 00:41:07,640
so we're weighing this style way
more than we're rang the content.

689
00:41:07,641 --> 00:41:10,520
And it doesn't mean that these
are the best weights and in fact,

690
00:41:10,760 --> 00:41:15,110
we can have learning out rhythms for
learning the best ways we could learn the

691
00:41:15,110 --> 00:41:18,020
best weeks later. Right? So that's that.

692
00:41:18,021 --> 00:41:19,790
Those are the weights
that we're going to use.

693
00:41:19,820 --> 00:41:22,820
And we're going to define these weights,
uh, here in a second, but right.

694
00:41:22,850 --> 00:41:24,890
So let's go ahead and just
do our first cap. Like,

695
00:41:26,000 --> 00:41:29,840
assuming that everything else we did
was just a helper function for this.

696
00:41:29,990 --> 00:41:33,860
This is the real deal. So we're
first going to define model. Okay.

697
00:41:33,861 --> 00:41:38,030
It's gonna be easy. 16. We imported
it. We're good to go. Right? 16 layer,

698
00:41:38,031 --> 00:41:42,530
convolutional net, fully connected layer.
At the end, it's thinking like, oh,

699
00:41:42,531 --> 00:41:47,030
I'm going to be used for classification.
That what is thinking right now? Okay, so

700
00:41:48,560 --> 00:41:52,430
now we're going, but it doesn't know
any better. He doesn't know any better.

701
00:41:52,431 --> 00:41:54,230
We're not going to use
it for classification.

702
00:41:54,440 --> 00:41:56,490
We're going to use it for
style transfer itself.

703
00:41:56,720 --> 00:41:59,720
We've got our graph and we're
went to eat in our model. Okay?

704
00:41:59,721 --> 00:42:00,560
So that's the session.

705
00:42:00,561 --> 00:42:05,270
Remember the session always encapsulates
our computation graphs. Okay?

706
00:42:05,271 --> 00:42:08,870
So then we've got these print functions
here that we're going to use to help us

707
00:42:08,930 --> 00:42:10,010
see what's happening.

708
00:42:10,011 --> 00:42:13,260
And I'll just paste these in because
they're really just help her, you know?

709
00:42:13,790 --> 00:42:18,790
So now, now is the, the good stuff.
So cures are lost for our content. We,

710
00:42:18,890 --> 00:42:21,990
our first loss function
and we defined the, um,

711
00:42:23,670 --> 00:42:24,580
we defined find the

712
00:42:29,640 --> 00:42:30,810
lost function, right? So

713
00:42:32,720 --> 00:42:36,120
the session is going to,
we're going to give it the session value,

714
00:42:36,121 --> 00:42:41,121
we're going to get a model value and
we're going to give it a content image and

715
00:42:42,691 --> 00:42:47,530
the layer ids. Okay? So no buffering dot.

716
00:42:47,540 --> 00:42:52,440
Interesting. Okay, good
thing. A good thing. All good
things to consider. Okay. So

717
00:42:54,300 --> 00:42:56,040
once you give it that content,
obviously,

718
00:42:56,041 --> 00:43:00,270
because we are trying to minimize the
loss for the contents and then we're going

719
00:43:00,271 --> 00:43:03,930
to say other layer id. So these
are the indices. So right.

720
00:43:03,931 --> 00:43:06,750
We just feed in those layering
the teas and if went to, uh,

721
00:43:06,870 --> 00:43:11,430
calculate the difference between the raw
activations to after given layers and

722
00:43:11,431 --> 00:43:15,210
our content image. And we think of that
as a matrix, just the rock divisions,

723
00:43:15,570 --> 00:43:19,860
activations, no hidden step and the
value, the value is our last content.

724
00:43:19,861 --> 00:43:22,830
And remember this is eight scalar value.
Okay,

725
00:43:22,831 --> 00:43:27,750
this going to give us a scalar value.
The next step is to calculate our,

726
00:43:28,430 --> 00:43:30,300
our silos.
Okay,

727
00:43:30,450 --> 00:43:33,600
so for our style loss
or is that extra step,

728
00:43:33,830 --> 00:43:37,980
the extra step is going to be
the brand to these calculation.

729
00:43:37,981 --> 00:43:42,750
So it's not that we just give it
those raw activations. We also,

730
00:43:42,751 --> 00:43:45,530
once you give it the,
we take those rocks,

731
00:43:45,550 --> 00:43:49,980
the patients and we calculate the
gram matrices from that. Okay.

732
00:43:50,550 --> 00:43:55,430
And the same thing, but
on the, you know, in this

733
00:43:57,120 --> 00:43:59,760
and this, uh, you know,
function. We're not,

734
00:43:59,761 --> 00:44:01,100
we're not talking about
the grand mason city's,

735
00:44:01,110 --> 00:44:04,350
that's all happening internally because
we could find that on the outside it

736
00:44:04,351 --> 00:44:07,240
looks the same. We're just good
programming, right? We, we,

737
00:44:07,250 --> 00:44:09,480
we want it to look the same because I'm

738
00:44:11,220 --> 00:44:11,710
okay.

739
00:44:11,710 --> 00:44:15,150
There was no reason for us to expose
that grant makers brown matrix or

740
00:44:15,220 --> 00:44:20,030
calculation, uh, externally for, you know,
this, this function for re re usability.

741
00:44:20,060 --> 00:44:23,450
Okay. So that's for our loss
and that's where our style,

742
00:44:23,600 --> 00:44:27,410
and remember we had one more very trivial
loss function for de noising. Right?

743
00:44:27,411 --> 00:44:29,960
So for noising we'd say we just said,
well,

744
00:44:30,140 --> 00:44:33,720
take our model then remember to
the noises so that, you know,

745
00:44:33,840 --> 00:44:38,670
it's just so little less per worried, you
know, a little catch up at the end. Okay.

746
00:44:38,700 --> 00:44:42,360
So those are our three loss functions.
And now what we're going to do,

747
00:44:44,010 --> 00:44:44,843
mmm.

748
00:44:45,740 --> 00:44:50,450
Is we're going to adjust,
be here.

749
00:44:50,451 --> 00:44:51,290
That's a great question.

750
00:44:51,291 --> 00:44:55,610
Why don't we use the gray mates
and sees for content loss. Um, so,

751
00:44:56,990 --> 00:45:01,130
uh, so it's a second order updates.
It's a second order statistic,

752
00:45:01,131 --> 00:45:05,350
meaning for, for stock. So style
is actually, you know, it's, it's,

753
00:45:06,260 --> 00:45:09,890
you can think of style as more abstract
and content content is something we can

754
00:45:10,220 --> 00:45:13,550
point out and say that is
content. Like for example, the,

755
00:45:13,640 --> 00:45:15,500
what is the famous content like the,
the,

756
00:45:15,520 --> 00:45:19,460
the clock that is bending in
the Dolly picture dollies. Um,

757
00:45:21,550 --> 00:45:25,470
Geez, where's my mouse? The
Dolly pick, you know, with the,

758
00:45:25,490 --> 00:45:27,790
with the clock that's bending.
That is, that is content.

759
00:45:27,791 --> 00:45:30,910
That is something we could look at and
we can definitively say that is the

760
00:45:30,970 --> 00:45:35,080
content. So we can take the raw
activation and say, you know,

761
00:45:35,081 --> 00:45:39,280
it's just literally there. It's,
it's, it describes that that object,

762
00:45:39,460 --> 00:45:41,140
but style is much more nuance.

763
00:45:41,141 --> 00:45:44,860
Style is much more embedded and
ingrained throughout every layer.

764
00:45:44,890 --> 00:45:47,860
It's not just like at one way or we see,
oh that is the,

765
00:45:47,890 --> 00:45:50,170
that is where the clock is. It's,
it's embedded in every layer.

766
00:45:50,171 --> 00:45:54,400
So by taking the brand matrix,
we're kind of abstracting that.

767
00:45:54,740 --> 00:45:57,970
We're taking another layer
of abstraction to say

768
00:45:59,920 --> 00:46:04,340
that we want to style is even more
abstract and content. And so Graham major,

769
00:46:04,341 --> 00:46:06,910
she's helped us create that
extra layer of abstraction. Okay.

770
00:46:07,750 --> 00:46:09,970
So now we're going to

771
00:46:11,770 --> 00:46:16,210
create those adjustment weights, right?
So for our content and our style.

772
00:46:16,211 --> 00:46:19,530
So it's basically just the same
thing here. So we'll just, you know,

773
00:46:19,630 --> 00:46:21,820
copy and paste the same thing over
and over again for three lines.

774
00:46:21,930 --> 00:46:25,600
But basically it is creating tentraflow
variables for adjusting the values of

775
00:46:25,601 --> 00:46:29,260
the loss functions. Okay.
So we went to adjust how,

776
00:46:29,390 --> 00:46:31,250
uh,
uh,

777
00:46:31,650 --> 00:46:33,570
we want to adjust how,
uh,

778
00:46:34,820 --> 00:46:35,300
okay,

779
00:46:35,300 --> 00:46:37,040
how much we want to weight each of them.
Okay.

780
00:46:38,260 --> 00:46:42,620
And so now what we're going to do is
we're going to initialize them, right?

781
00:46:42,621 --> 00:46:44,780
So we're,
we say we're gonna say session not run.

782
00:46:45,020 --> 00:46:46,760
We want to commercialize this value so

783
00:46:48,940 --> 00:46:50,350
isn't the actual run step.

784
00:46:50,620 --> 00:46:55,620
And the next step is we're going to
actually adjust them because we haven't

785
00:46:56,471 --> 00:46:59,560
actually adjusted them. We've just
declined them. Now we actually adjust it.

786
00:46:59,740 --> 00:47:04,380
Now we actually,
uh,

787
00:47:05,230 --> 00:47:06,031
Skoll kinds were,

788
00:47:06,031 --> 00:47:10,560
can definitely be applied to audio and
wavenet is a great application of that.

789
00:47:10,710 --> 00:47:12,100
Um, and there are, you know,

790
00:47:12,670 --> 00:47:16,060
there's a definitely a lot of discoveries
to be made around speeding up wave net.

791
00:47:16,420 --> 00:47:17,890
Okay.
Um,

792
00:47:18,280 --> 00:47:21,880
but the idea of transferring the style
to something can be applied to all forms

793
00:47:21,881 --> 00:47:26,860
of media, not just images, audio, video,
uh, you know, all sorts of things.

794
00:47:28,180 --> 00:47:30,100
But these are updated values.

795
00:47:30,101 --> 00:47:33,640
And the reason we're using this
one e 10 value is because we,

796
00:47:33,700 --> 00:47:37,810
it basically is just taking the
reciprocal values of the loss functions.

797
00:47:38,230 --> 00:47:42,370
And then it's going to,
uh, using this small value,

798
00:47:42,371 --> 00:47:46,360
one e minus 10 is added to avoid
the possibility of division by zero.

799
00:47:46,360 --> 00:47:49,870
So if Los content was equal to zero,
this would just throw an error.

800
00:47:49,871 --> 00:47:53,780
So that's what we add is very small. You
can almost think of it as a bias vector,

801
00:47:54,250 --> 00:47:58,750
but for adjusting, adjusting
these, uh, these, uh, uh,

802
00:47:58,870 --> 00:48:03,700
wait values. Okay. And so now we're
going to actually combine those losses.

803
00:48:03,940 --> 00:48:05,280
So now that we've defined the law,

804
00:48:05,281 --> 00:48:09,460
says we defined how much we want to
weight each of them. Now we finally,

805
00:48:09,490 --> 00:48:13,900
we combine the losses.
One big,

806
00:48:13,930 --> 00:48:15,220
huge rocks function,

807
00:48:15,221 --> 00:48:19,830
and it's a weighted loss function that
we will minimize to generate the mixed

808
00:48:19,840 --> 00:48:22,760
images. And the reason we're
multiplying these loss, uh,

809
00:48:23,020 --> 00:48:27,290
values with the reciprocal adjustment
values that we tabulate it up here is

810
00:48:27,291 --> 00:48:31,310
because we can use the relative weights
for the loss functions that are easier

811
00:48:31,311 --> 00:48:36,311
to select the exact choice and the co the
client later the style and the content

812
00:48:38,100 --> 00:48:40,640
labors. So this is our combined
loss function and Guinea.

813
00:48:40,700 --> 00:48:44,670
And so give it a five minutes and
we're going to get right to the, um,

814
00:48:47,060 --> 00:48:50,000
we're going to get right to the actual
output value. We're almost there guys.

815
00:48:50,001 --> 00:48:53,200
Stick. You guys are very patient
for sticking with us, right?

816
00:48:53,210 --> 00:48:55,100
There's a lot of stuff
we're talking to now.

817
00:48:55,101 --> 00:48:58,160
So now we're going to calculate
the gradients. So let's,

818
00:48:58,250 --> 00:49:00,620
so the gradient is a great
thing to talk about, right?

819
00:49:00,621 --> 00:49:05,280
So we have our combined loss functions
and now we're in these tension built dean

820
00:49:05,510 --> 00:49:09,800
radiant function to get full value of Rep.
It's not just one

821
00:49:11,180 --> 00:49:12,013
you,

822
00:49:13,490 --> 00:49:17,690
uh, we're using multiple gradient values
and we're going to get the combined loss

823
00:49:17,990 --> 00:49:22,360
given our model and could
value and they'll combine loss.

824
00:49:22,361 --> 00:49:24,760
So this is what it's going to
do is going to get the gradient,

825
00:49:24,840 --> 00:49:28,280
the combined lost function
with regard to the input image,

826
00:49:28,430 --> 00:49:30,260
which is the mixed image.
So this,

827
00:49:30,320 --> 00:49:33,890
this wants to minimize difference
between the mixed image and remember that

828
00:49:33,891 --> 00:49:37,460
mixed images, just the blurry, you
know, uh, nothing image, right?

829
00:49:37,470 --> 00:49:41,200
It's initialized random noise image and
that's what we want to output as are

830
00:49:41,230 --> 00:49:46,230
fully know output value
that the transferred style
image and the gradient is

831
00:49:47,031 --> 00:49:49,820
going to get the um,
it's a mathematical function.

832
00:49:49,821 --> 00:49:54,690
So the gradient value is going to
give us a direction. And so, uh,

833
00:49:54,790 --> 00:49:59,780
a great image of this,
I haven't. Great. Um,

834
00:50:02,390 --> 00:50:06,760
I'll talk about building an AI
writer also. I'll do another one.

835
00:50:08,490 --> 00:50:09,323
Uh,

836
00:50:10,050 --> 00:50:10,291
you know,

837
00:50:10,291 --> 00:50:15,280
generates Shakespeare or paintings or
Shakespeare or text check out that is not,

838
00:50:15,320 --> 00:50:17,800
you have to create an that's
Nike and some dude. Um,

839
00:50:19,680 --> 00:50:22,300
what's like that gradient act sigmoid.
Basically,

840
00:50:22,301 --> 00:50:23,770
I'm just trying to visualize
what this looks like,

841
00:50:23,771 --> 00:50:26,080
but basically we are taking the,

842
00:50:29,750 --> 00:50:33,120
sorry. Okay. So we have a
sigmoid function and we,

843
00:50:33,121 --> 00:50:34,830
the gradient is like if
we were to take a line,

844
00:50:34,831 --> 00:50:38,250
I'm just showing this with my mouse
up or down. That's it. Up or down.

845
00:50:38,640 --> 00:50:42,270
We take numbers and do we
want to push these numbers up,

846
00:50:42,330 --> 00:50:45,090
we want to push these numbers down.
And so that's what the gradient is doing.

847
00:50:45,091 --> 00:50:47,490
So when we take these radiant values,
okay,

848
00:50:47,520 --> 00:50:52,200
we take these Brady and values and we
multiply it by weights are the weights in

849
00:50:52,201 --> 00:50:53,310
this case are going to be the image.

850
00:50:53,490 --> 00:50:56,730
It's going to update our image in
a direction which is up or down.

851
00:50:56,910 --> 00:50:59,190
That is going to minimize a loss.
Okay?

852
00:50:59,191 --> 00:51:03,900
So the gradient is a collection of
those gradients for each of those, uh,

853
00:51:04,050 --> 00:51:08,730
feature vectors. Uh, for each of those,
remember it's a, it's a stack of features.

854
00:51:08,760 --> 00:51:13,380
It's a stack of features, okay?
To take the list of 10 search,

855
00:51:17,050 --> 00:51:18,440
radiant was important.
Super important,

856
00:51:21,120 --> 00:51:24,000
pushing numbers up and down so
you didn't get that right. So

857
00:51:26,550 --> 00:51:28,560
these are all collection of scalar values.
Okay?

858
00:51:28,561 --> 00:51:32,370
These are a collection of scalar values.
And when we take these gradients and we,

859
00:51:32,580 --> 00:51:37,460
uh, these are a collection
of scalar values and, um,

860
00:51:39,330 --> 00:51:42,330
we're going to use them, not here, but in
a second. We're going to actually, I'll,

861
00:51:42,331 --> 00:51:46,270
I'll talk about them when we, when
we get to number, basically, uh,

862
00:51:48,260 --> 00:51:49,490
I'll talk about them.
Okay.

863
00:51:49,491 --> 00:51:52,370
So this is going to give us this
list of scalar values. Okay?

864
00:51:52,550 --> 00:51:54,500
That's what greatness is doing
with regard to the loss function.

865
00:51:54,501 --> 00:51:58,160
And we'll talk about what it's doing
with this scalar values in a second.

866
00:51:58,161 --> 00:52:00,730
But just think about it as scalar values.
Right now we're,

867
00:52:00,790 --> 00:52:05,270
we're about to get stem. So now we're
going to initialize that mixed image.

868
00:52:05,271 --> 00:52:08,450
We haven't actually initialize that mixed
image yet. Now we initialize it, right?

869
00:52:08,570 --> 00:52:11,060
So we're using random,
the num pies,

870
00:52:11,090 --> 00:52:16,090
random dot rand function to initialize
an empty matrix of just random values.

871
00:52:16,311 --> 00:52:21,200
Okay? And we're going to update its
image to us through iteration. Okay?

872
00:52:22,430 --> 00:52:25,820
So,
so now it's time for our training staff.

873
00:52:26,030 --> 00:52:28,840
So for every,
so for

874
00:52:31,070 --> 00:52:34,730
number of iterations that we have and
we have quite a bit of iterations to do,

875
00:52:34,840 --> 00:52:38,090
you know, anywhere from a hundred
to thousands. This by the way,

876
00:52:38,091 --> 00:52:42,920
it's going to take like an hour
on my laptop, which is a Mac book,

877
00:52:42,921 --> 00:52:47,030
2016 forced touch bar,
which sucks.

878
00:52:47,370 --> 00:52:51,570
I need a better computer anyway. So, um,

879
00:52:52,200 --> 00:52:54,140
great. So now, so the first step remember,

880
00:52:54,141 --> 00:52:56,880
is going to be to create the
feed dictionary. All right?

881
00:52:56,930 --> 00:53:01,910
So we're going to create their feed
dictionary and then given that mixing the

882
00:53:01,980 --> 00:53:06,440
director, we dress initialize them, makes
an image, create that feed dictionary.

883
00:53:06,850 --> 00:53:07,683
Okay.

884
00:53:11,430 --> 00:53:15,360
Now what we're going to do is we're going
to calculate the value of the gradient

885
00:53:15,630 --> 00:53:19,410
as well as adjusting the dial you,
so

886
00:53:21,110 --> 00:53:25,890
it's breaking up from time
to time. It could just be
you. Okay. Interesting to um,

887
00:53:26,040 --> 00:53:28,530
notes.
So we got a couple minutes left.

888
00:53:28,600 --> 00:53:32,220
So what I'm going to do now is I'm going
to talk about the gradients and so in

889
00:53:32,221 --> 00:53:34,470
order to focus on the gradients
that we're going to do,

890
00:53:36,780 --> 00:53:39,850
paste the rest so that we can focus
on the Greenheck values. Okay. So,

891
00:53:42,040 --> 00:53:43,430
so we have those gradients,
right?

892
00:53:43,690 --> 00:53:48,210
There are a collection of scalar values
between the mixed image and our combined

893
00:53:48,211 --> 00:53:50,550
loss function. So, you
know, think of them as like,

894
00:53:50,730 --> 00:53:55,320
there are the representation of like
the what we want to use to help us,

895
00:53:55,740 --> 00:53:58,810
you know, increase the style
in our, that mixed image. What,

896
00:53:58,890 --> 00:54:01,680
how do we stylize that image to
the gradients are going to give us,

897
00:54:01,950 --> 00:54:06,690
tell us how to update our image.
Okay. A gradient is a slope value.

898
00:54:06,720 --> 00:54:10,650
It's a given, a sigmoid function. So

899
00:54:15,230 --> 00:54:16,970
if it would just,

900
00:54:23,990 --> 00:54:26,110
you remember, so for
you know, fee for next,

901
00:54:26,111 --> 00:54:29,500
we took the derivative a sigmoid
and it gave us a, a line.

902
00:54:29,501 --> 00:54:32,680
A straight line is great. It means
slope. It's just a straight line.

903
00:54:32,950 --> 00:54:37,270
And the line either po points up or
at points down, this is a great image.

904
00:54:37,330 --> 00:54:39,130
Either points up or it points down.

905
00:54:40,810 --> 00:54:41,643
Okay?

906
00:54:44,190 --> 00:54:47,850
Uh, so it's, you know, it could be
plus two or minus two, right? And so,

907
00:54:49,240 --> 00:54:52,750
so when we take these gradients
and we multiply it by that image,

908
00:54:52,810 --> 00:54:56,260
it's going to transfer it. It's going
to update the image in some way.

909
00:54:56,261 --> 00:55:01,060
And every time we, every time we minimize
our loss, the gradients is going to be,

910
00:55:01,630 --> 00:55:05,050
it's going to be better. And by better,
I mean it's going to help us. Uh,

911
00:55:05,140 --> 00:55:05,973
it's going to be,

912
00:55:06,340 --> 00:55:10,960
it's going to minimize the difference
between the output image and our style

913
00:55:10,961 --> 00:55:14,080
image, right? It's gonna every time it's
going to be minimal, minimal. All right?

914
00:55:14,081 --> 00:55:17,080
So eventually when it's zero,
a local minimum, uh, the,

915
00:55:17,090 --> 00:55:20,830
the output image is going to be the most
stylized that it can be for whatever,

916
00:55:20,850 --> 00:55:22,660
uh,
however we frame this problem.

917
00:55:22,661 --> 00:55:26,290
So this step is going to remove the single
dimensional entries from the shape of

918
00:55:26,291 --> 00:55:30,670
an array so that our greatest value is
going to be reduced such that it's going

919
00:55:30,671 --> 00:55:34,360
to be the same size so that we
can multiply it by our matrix.

920
00:55:36,530 --> 00:55:40,980
Okay? So then we're going to
scale the gradient. So what do we,

921
00:55:41,010 --> 00:55:42,150
what are we doing and
why are we doing this?

922
00:55:42,151 --> 00:55:43,890
This is the same thing as learning rates.

923
00:55:43,891 --> 00:55:48,030
So it's the ratio between the weights
and the updates. So if, if, if,

924
00:55:48,050 --> 00:55:52,410
if we don't scale it properly, then it's
not going to converge fast. But if we,

925
00:55:52,740 --> 00:55:56,280
if we don't scale it fast enough,
then it's not going to converge ever.

926
00:55:56,370 --> 00:55:59,430
If we steal it too. No, sorry.
If we scale it too slowly,

927
00:55:59,580 --> 00:56:01,950
then it's never going to convert.
If we scale it too fast,

928
00:56:02,130 --> 00:56:06,700
there's going to overfit so, so we
have to update not just our, um,

929
00:56:07,350 --> 00:56:08,460
gradients,
but our,

930
00:56:08,670 --> 00:56:12,660
our weights at each layer so that
it's going to converge properly.

931
00:56:12,661 --> 00:56:16,260
That's what this step is. And then we're
going to perform in gradient descent.

932
00:56:16,440 --> 00:56:18,810
And so this is the actual
gradient distance part, right?

933
00:56:18,930 --> 00:56:22,290
This is what I'm talking about. We take
those beck gradients, which is a scaler,

934
00:56:22,680 --> 00:56:26,170
and then we multiply it by the scale of
value that we calculated here and it's

935
00:56:26,171 --> 00:56:29,110
going to give us that output mixed image,
which is going to suck.

936
00:56:29,290 --> 00:56:31,150
It's going to suck at it.
It's not gonna look like anything.

937
00:56:31,420 --> 00:56:33,400
But the more we update this gradient,

938
00:56:33,640 --> 00:56:36,820
the more this image is going
to look doper and doper. Okay.

939
00:56:37,060 --> 00:56:40,750
Like more and more stylized. Okay.
And so that's gonna be our mix image.

940
00:56:40,751 --> 00:56:44,860
And then we went to clip all the values
that are not between zero and 255.

941
00:56:45,070 --> 00:56:45,821
So everything more,

942
00:56:45,821 --> 00:56:49,150
we're going to clip it because we
want this to be an art be values.

943
00:56:49,480 --> 00:56:52,270
And then we're going to print out the
number of iterations and we're going to

944
00:56:52,271 --> 00:56:55,780
plot them. Okay? So that's
what that's going to do.

945
00:56:56,440 --> 00:56:59,210
And then we're ready to,
uh,

946
00:56:59,290 --> 00:57:01,960
show you know what we're going to,

947
00:57:02,810 --> 00:57:07,720
so that's that part style
transfer algorithm. Now we
can print out load images.

948
00:57:07,750 --> 00:57:11,980
Not that fine. Yeah, I probably
didn't. Oh, I need to find the load.

949
00:57:11,981 --> 00:57:15,280
It makes function earlier. It's all good.
I didn't compile that earlier. Let's um,

950
00:57:16,640 --> 00:57:17,720
we just show this.
Okay.

951
00:57:17,900 --> 00:57:21,650
So is it actually like if I were
to actually run this right now,

952
00:57:21,651 --> 00:57:23,480
it would take a lot of computation power,

953
00:57:23,481 --> 00:57:25,150
which would lag the hell
out of this livestream.

954
00:57:25,220 --> 00:57:27,650
And I definitely don't want to
lag this slide stream further.

955
00:57:27,651 --> 00:57:30,680
So let me talk about this for two minutes
and we're going to do an ending to a,

956
00:57:30,690 --> 00:57:34,100
okay. So where were we? Okay,

957
00:57:34,250 --> 00:57:39,200
so remember, so Devin d a
style image, the content image.

958
00:57:39,440 --> 00:57:42,470
And then the indices or
whatever we want to use,

959
00:57:42,471 --> 00:57:46,160
like what are the layers we're choosing
for this? And then how much went away.

960
00:57:46,190 --> 00:57:50,590
Each of those loss functions,
it's going to slow, minimize
that loss. So this, this,

961
00:57:51,110 --> 00:57:54,230
even this first iteration is going
to take like, like five minutes.

962
00:57:54,231 --> 00:57:57,920
So even in this first
iteration, you already see
that it's getting better. Like,

963
00:57:57,980 --> 00:58:02,420
like already you went from nothing to
this in one single iteration. Okay.

964
00:58:03,260 --> 00:58:07,010
And after the others, it's just gonna be,
so it's kind of like an ex, uh, um, uh,

965
00:58:07,011 --> 00:58:09,710
negative exponential curve. So, uh, it's,

966
00:58:09,711 --> 00:58:14,480
it's super good at first and then every
subsequent iteration is going to get, uh,

967
00:58:14,600 --> 00:58:16,780
you know, the, the, the, um,

968
00:58:16,820 --> 00:58:20,900
improvement is going to get smaller
and smaller over time. Okay.

969
00:58:21,360 --> 00:58:22,193
Hm.

970
00:58:22,780 --> 00:58:26,110
Okay.
So let me do five minute Q and a to end

971
00:58:28,540 --> 00:58:30,610
and then we're going to get started.
Hi Guys,

972
00:58:30,970 --> 00:58:32,440
I'm definitely going to improve black.
Don.

973
00:58:32,441 --> 00:58:34,930
I really want to improve these livestreams
and I really want to, and I will,

974
00:58:35,140 --> 00:58:35,741
I promise that.
Well,

975
00:58:35,741 --> 00:58:37,720
because I love you guys and want
to make this better for you. Okay.

976
00:58:37,721 --> 00:58:40,870
So ask any leftover questions
you have from this live stream,

977
00:58:41,110 --> 00:58:42,760
which I'm going to read out very clearly,

978
00:58:43,050 --> 00:58:46,510
but the people who are
watching this later. And then
I'm going to ask, you know,

979
00:58:46,511 --> 00:58:51,100
whatever other questions you have as
well about life or Amin machine learning.

980
00:58:52,450 --> 00:58:52,930
So Raj,

981
00:58:52,930 --> 00:58:57,550
what do you think of neuro evolution of
augmenting topologies needs as a genetic

982
00:58:57,580 --> 00:59:00,800
algorithm? And do you think you
will do a video on it? Sometimes.

983
00:59:00,910 --> 00:59:04,490
So genetic algorithms I've done a video
on genetic algorithm is called um,

984
00:59:04,960 --> 00:59:08,500
genetic algorithms learn python for
data science. They're really cool.

985
00:59:08,530 --> 00:59:12,430
The idea of evolution, Darwinian
evolution, it's a really cool, and it's,

986
00:59:12,640 --> 00:59:17,590
it's how we've evolved, right? But in
practice, in practice, we don't see,

987
00:59:17,680 --> 00:59:22,390
um, you know, as good results
as we see with you know,

988
00:59:22,460 --> 00:59:26,980
these with deep learning. But you
know, we might later on we, you know,

989
00:59:26,990 --> 00:59:27,823
who knows.

990
00:59:27,830 --> 00:59:32,810
And I think that there are ideas from
Jeanette genetic algorithms that can be

991
00:59:32,811 --> 00:59:34,280
applied to deep learning.
Remember,

992
00:59:34,550 --> 00:59:38,330
what we're seeing in the real discoveries
that are happening right now is where

993
00:59:38,331 --> 00:59:42,440
we're taking these abstract ideas,
this idea of hierarchy from deep learning.

994
00:59:42,441 --> 00:59:44,990
This idea of an agent of an other,

995
00:59:45,100 --> 00:59:47,470
of reinforcement of trial
and error for reinforcing.

996
00:59:47,670 --> 00:59:50,810
And by combining these ideas,
we're going to get even better results.

997
00:59:50,900 --> 00:59:55,100
So I think genetic algorithms have a
lot of great ideas to give to us. Okay.

998
00:59:55,250 --> 00:59:58,130
And uh, I will, I will definitely
do more videos on genetic,

999
00:59:59,030 --> 01:00:02,270
how returns in the future, how to
communicate with objective c. Uh,

1000
01:00:02,271 --> 01:00:03,860
don't use objective c,
use swift,

1001
01:00:04,730 --> 01:00:06,770
how to improve because apple
is now maintaining that.

1002
01:00:06,770 --> 01:00:09,620
And actually swift is great for
even server side code at this point,

1003
01:00:09,621 --> 01:00:13,520
not just mobile apps.
How to improve CV for Google internship.

1004
01:00:13,521 --> 01:00:17,780
Mccool I have a video on job interviews
that I'm going to release very soon

1005
01:00:17,810 --> 01:00:20,990
either this week or next week.
I already have the footage.

1006
01:00:20,991 --> 01:00:22,490
I just need to edit and release that.

1007
01:00:23,690 --> 01:00:26,660
How close are we to humans
to solving intelligence?

1008
01:00:27,020 --> 01:00:29,800
My best guess is five to 10 years.
Uh,

1009
01:00:30,220 --> 01:00:33,470
unless some kind of cataclysmic,
you know,

1010
01:00:33,500 --> 01:00:35,500
anything bad happens that prevents that,

1011
01:00:35,501 --> 01:00:37,430
the rate of discovery
that's happening right now.

1012
01:00:38,270 --> 01:00:43,030
Are there starter videos that
you talked slower in? Uh,

1013
01:00:44,510 --> 01:00:48,410
I'm just going to keep talking
slower and slower. Okay. Uh, okay.

1014
01:00:48,411 --> 01:00:49,700
So a couple more questions.

1015
01:00:52,170 --> 01:00:55,850
Do you think an evolutionary slash genetic
algorithm to create the structure of

1016
01:00:55,851 --> 01:00:58,820
a neural network? Absolutely.
I mean, absolutely. They've,

1017
01:00:58,850 --> 01:01:01,670
we've seen them creates a
bunch of other things as well.

1018
01:01:01,671 --> 01:01:03,860
I don't think I've ever
seen anyone try to do that.

1019
01:01:03,861 --> 01:01:06,860
So that's a great project
to try to recreate,

1020
01:01:07,840 --> 01:01:10,550
let's say a simple blue
layer before neural networks.

1021
01:01:10,690 --> 01:01:14,240
You think genetic algorithms,
that would be a great project.

1022
01:01:15,420 --> 01:01:15,810
Okay.

1023
01:01:15,810 --> 01:01:17,380
What's 10 years is very optimistic,

1024
01:01:17,381 --> 01:01:20,890
but just look at like the paper that
was just released yesterday by deep mine

1025
01:01:21,250 --> 01:01:24,780
when they already beat their DQ
network. That is, can be, uh,

1026
01:01:24,870 --> 01:01:27,400
generalized to a bunch of different games.
Um,

1027
01:01:27,700 --> 01:01:32,120
what else should we learn in
AI ml and d l after ml and DL?

1028
01:01:32,170 --> 01:01:34,780
That's really the, the
bleeding edge right now. Um,

1029
01:01:34,960 --> 01:01:37,710
but I would say if you want to
go just even further like that,

1030
01:01:37,711 --> 01:01:42,100
the real future one shot learning for
specifically probabilistic programming.

1031
01:01:42,130 --> 01:01:47,020
Okay. Probabilistic programming or you
could call it Basie and program learning.

1032
01:01:47,021 --> 01:01:47,854
It's the same thing.

1033
01:01:51,220 --> 01:01:55,030
You have any examples of using a neural
net on random images from the internet?

1034
01:01:56,300 --> 01:01:58,960
Uh, yeah. Build a tensorflow
image classifier in five minutes.

1035
01:02:00,070 --> 01:02:00,610
Okay.

1036
01:02:00,610 --> 01:02:03,880
Okay. How do you keep up with all
the white papers that are released?

1037
01:02:04,180 --> 01:02:09,180
Andre Karpati has a great website
called Archive sanity.org.

1038
01:02:09,390 --> 01:02:14,380
I've Ar Xib, sn, s a n.

1039
01:02:14,440 --> 01:02:19,410
I, t y, Google that and then
a n d. R. E. J. Great. It, I,

1040
01:02:19,440 --> 01:02:22,830
that's my tool. Okay. I'm going to answer
two more questions and then we're done.

1041
01:02:23,250 --> 01:02:24,450
If it's only five to 10 years,

1042
01:02:24,451 --> 01:02:28,050
should I start a computer science degree
next year or should it rule on my own

1043
01:02:28,140 --> 01:02:31,410
with you? And did your you Udacity roll
on your own? Anton roll on your own.

1044
01:02:31,500 --> 01:02:35,670
Remember to have your get hub full upgrade
projects because get hub is the new

1045
01:02:35,671 --> 01:02:38,360
resume.
Okay.

1046
01:02:38,720 --> 01:02:42,650
And practice your interviewing skills and
a whole video on that very soon. Okay.

1047
01:02:42,651 --> 01:02:44,750
Two more. Okay. So actually
two more questions.

1048
01:02:46,130 --> 01:02:47,720
Additional resources for style transfer.

1049
01:02:47,721 --> 01:02:50,930
I will link those to those in the
description. Also my last video last week,

1050
01:02:50,950 --> 01:02:55,340
the video, cause that's some
great resources in there.

1051
01:02:55,460 --> 01:02:59,870
One more question. Okay. What
do you think about the new,

1052
01:03:02,340 --> 01:03:03,173
no,

1053
01:03:08,290 --> 01:03:11,160
uh,
I want to make it a good question.

1054
01:03:15,400 --> 01:03:19,270
What drives you? Shabaam Goop Jab I. Okay.

1055
01:03:19,330 --> 01:03:22,870
So what drives me to be totally
honest with driving number one,

1056
01:03:22,871 --> 01:03:26,980
one anything is to solve intelligence by
teaching you guys, you know, whatever I,

1057
01:03:27,010 --> 01:03:31,660
whatever, I know you guys can help us all
because it's a, it's a shared journey.

1058
01:03:31,661 --> 01:03:34,320
We're trying to solve intelligence
so that we can solve everything else.

1059
01:03:34,321 --> 01:03:36,280
We have so many problems in the world.

1060
01:03:36,430 --> 01:03:39,270
If you've traveled to developing
countries, you see just the,

1061
01:03:39,470 --> 01:03:42,190
the scope of problems is
so immense and it is just,

1062
01:03:42,640 --> 01:03:45,460
I am very impatient and I want to
solve all these in my lifetime.

1063
01:03:45,461 --> 01:03:48,010
I want to see it all sorts
and the best way to do that,

1064
01:03:48,011 --> 01:03:51,970
it's to make better and more intelligent
software. It is the best way to do that.

1065
01:03:52,240 --> 01:03:56,200
Okay. And that's what
drives me. And also just,

1066
01:03:56,201 --> 01:03:59,140
I've always wanted to do great things
and this is a great way to do that.

1067
01:03:59,140 --> 01:04:02,920
And also I just, I want to be out
there and I went to, I feel like I,

1068
01:04:03,160 --> 01:04:06,970
I feel like I have a responsibility to
read. It's like this internal, like I,

1069
01:04:07,270 --> 01:04:11,370
I just feel like I need to
dream big. And we, and, and,

1070
01:04:11,371 --> 01:04:15,160
and I went to and see you guys become
leaders as well because you are all the

1071
01:04:15,161 --> 01:04:18,770
real leaders of the future. I'm here
to help you guys become leaders. Okay.

1072
01:04:20,650 --> 01:04:23,650
So that's what I'm here for and I will,
I will keep going. Oh, keep going.

1073
01:04:23,651 --> 01:04:28,590
No matter what happens, I
will just keep going and, oh,

1074
01:04:28,591 --> 01:04:31,530
keep going until my last breath. Hopefully
there's no last breath because we saw,

1075
01:04:31,640 --> 01:04:35,250
hey, I, and you know, we
had this singularity. Okay.
Is Deep owning a fad? No,

1076
01:04:35,251 --> 01:04:38,200
it's not a fad. It's a,
it's, it's a next step in,

1077
01:04:38,210 --> 01:04:41,700
in a series of discoveries and I'm
sure the next thing is going to be even

1078
01:04:41,701 --> 01:04:46,030
better. But Dave, uh, in a way, it's
not like it's the end goal, right?

1079
01:04:46,110 --> 01:04:48,240
There's going to be more accurate,
but it's a part of this

1080
01:04:49,980 --> 01:04:54,390
thing about I'm not working
at Twilio. Um, okay. So,

1081
01:04:55,320 --> 01:04:58,620
uh, this wonderful time. All right,
so that's all for my questions.

1082
01:04:58,920 --> 01:05:02,640
Thanks guys for being here. I have a
video coming up this, uh, on Friday,

1083
01:05:02,641 --> 01:05:07,500
like always. And uh, okay, so that's
it for this livestream. Let's see.

1084
01:05:07,501 --> 01:05:11,730
Anything else I want to do now? I'll just
say I'll say the rapper next time. Okay.

1085
01:05:11,731 --> 01:05:15,030
So love you guys remember to, uh, links
are going to be in the description.

1086
01:05:15,031 --> 01:05:18,410
Everything's going to be awesome.
Remember to join our channel. All right,

1087
01:05:18,440 --> 01:05:20,810
love you guys. And uh,
thanks for watching.

1088
01:05:20,811 --> 01:05:25,790
For now I've got to go drink some coffee
and then transfer the style of the

1089
01:05:25,791 --> 01:05:30,470
coffee into my brain and just minimize
a loss between my sleepiness and

1090
01:05:30,560 --> 01:05:34,570
wakefulness. So, oh, freestyle. Oh,
someone said freestyle. So I'll do it.

1091
01:05:34,580 --> 01:05:39,500
Cause you guys know I love to freestyle.
Um, uh, Prince Albert copied. So,

1092
01:05:40,330 --> 01:05:40,940
okay,

1093
01:05:40,940 --> 01:05:43,600
I love to drink coffee.
No, no, no, that's,

1094
01:05:43,610 --> 01:05:46,850
that's what I want to do it about
machine learning. So, uh, so what's a,

1095
01:05:46,870 --> 01:05:51,260
what did we just talked about? We talked
about a style transfer. So style. Okay.

1096
01:05:53,070 --> 01:05:55,890
I love to talk about style. I
take my boat, drive down the road,

1097
01:05:55,891 --> 01:06:00,790
but now I do it in a spit out bile.
That's not about it's flow. Anyway,

1098
01:06:00,960 --> 01:06:04,650
that's it for this time. People
laughing cause I'm trying to freestyle.

1099
01:06:04,740 --> 01:06:08,280
It doesn't matter because I'm
trying to go with the Nile River.

1100
01:06:08,340 --> 01:06:12,300
You got ancient secrets that the Egyptians
made, but now we got even more men,

1101
01:06:12,301 --> 01:06:17,010
bars, bars, bars. Okay. Woo.
Freestyle transfer. Anyway. All right.

1102
01:06:17,011 --> 01:06:20,880
Thanks for watching guys.
Okay.

