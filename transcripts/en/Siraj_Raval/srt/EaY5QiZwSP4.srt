1
00:00:00,030 --> 00:00:01,350
Hello world,
it's Raj.

2
00:00:01,410 --> 00:00:05,070
And today I'm going to show you how to
build your own self driving car in a

3
00:00:05,071 --> 00:00:09,540
simulated environment. And it's actually
much simpler than what we've been doing.

4
00:00:09,541 --> 00:00:13,110
Like so recall we've been talking about
generative adversarial networks and

5
00:00:13,111 --> 00:00:16,920
variational auto encoders and
all sorts of stochastic models.

6
00:00:17,070 --> 00:00:20,010
This comparatively is
actually surprisingly simple,

7
00:00:20,040 --> 00:00:23,160
which is crazy if you think about it,
a self driving car, it's simple. No,

8
00:00:23,161 --> 00:00:25,680
but it actually is.
It's nine lines of chaos.

9
00:00:25,710 --> 00:00:27,990
I mean the model itself is
and then the helper code.

10
00:00:28,290 --> 00:00:31,560
But we're going to talk about how you
can build this and I'm going to show you

11
00:00:31,561 --> 00:00:35,850
step by step the entire process. Okay? So
here's an example of what it looks like,

12
00:00:36,050 --> 00:00:37,110
uh,
when it's,

13
00:00:37,111 --> 00:00:39,810
when it's fully trained and it's
running in the simulated environment.

14
00:00:39,811 --> 00:00:41,790
So I'm super excited.
I hope you are.

15
00:00:41,791 --> 00:00:45,630
And at the end I'm going to answer some
questions just straight up from youtube

16
00:00:45,631 --> 00:00:48,270
comments. So I'm excited for
this. Let's, let's get started.

17
00:00:48,690 --> 00:00:51,510
So the first thing we want to do,
I'm going to stop this. A demo.

18
00:00:51,511 --> 00:00:53,010
This is what it's eventually
going to look like.

19
00:00:53,011 --> 00:00:55,860
And now the car's going to crash into
the water because I turned off the

20
00:00:55,861 --> 00:00:59,480
autonomous feature. Oh, let me
just turn off the simulator. Okay.

21
00:00:59,880 --> 00:01:01,770
Simulator is gone.
Okay.

22
00:01:01,771 --> 00:01:06,771
So let's first go ahead and talk about
what this is and what the whole deal is

23
00:01:08,761 --> 00:01:12,570
behind all of this. A little bit of theory
and then we'll get back into the code.

24
00:01:13,530 --> 00:01:17,580
Okay. So where are we? Where
are we? There we are. Okay.

25
00:01:17,970 --> 00:01:21,180
So how does simulate a self driving
car is the name of this tutorial.

26
00:01:21,210 --> 00:01:24,680
And so you Udacity recently
open source their simulators.

27
00:01:24,681 --> 00:01:28,770
So they built a simulator specifically
for self driving cars. So cool. Right?

28
00:01:28,771 --> 00:01:32,190
It's just for self driving
cars. Uh, and it was,

29
00:01:32,250 --> 00:01:34,920
it was built for their self driving
car and inner degree students and they

30
00:01:34,921 --> 00:01:38,400
recently open sourced it. So,
uh, it was built with unity,

31
00:01:38,401 --> 00:01:40,500
which is if you haven't used unity before,

32
00:01:40,740 --> 00:01:45,180
I would definitely recommend at least
checking it out. If I had more time,

33
00:01:45,181 --> 00:01:49,320
I would definitely be diving into unity
and building all sorts of cool three d

34
00:01:49,321 --> 00:01:51,050
models that I could play with.
And you know,

35
00:01:51,060 --> 00:01:55,650
maybe even generating three
models with generative models. Uh,

36
00:01:55,860 --> 00:01:57,420
but yeah, it's, it's, it's a great tool.

37
00:01:57,421 --> 00:02:01,710
It's very much using in virtual reality
and more and more in machine learning

38
00:02:01,711 --> 00:02:05,250
for, for modeling and things like that.
But definitely check it out. But yeah,

39
00:02:05,251 --> 00:02:09,900
they built this thing in unity and uh,
they added a bunch of prebuilt scripts.

40
00:02:09,930 --> 00:02:14,310
They added a bunch of scripts and the
scripts a control things like gravity and

41
00:02:14,311 --> 00:02:19,311
momentum and acceleration and all sorts
of things that you would think would be

42
00:02:19,381 --> 00:02:20,910
in a self driving car simulation.

43
00:02:21,150 --> 00:02:23,850
And you can modify these things as well
as they're just values that you could

44
00:02:23,851 --> 00:02:25,570
just change in code.
Uh,

45
00:02:25,620 --> 00:02:29,880
but you can find that the actual
simulator itself right here on get hub,

46
00:02:30,180 --> 00:02:34,570
and I'll also have a link to it in the
description and in the get hub read meat.

47
00:02:34,571 --> 00:02:37,920
But it's a binary file.
You don't have to compile it from source.

48
00:02:37,921 --> 00:02:40,170
That is like an exe, you
know, you just download it.

49
00:02:40,171 --> 00:02:43,170
It's like a dot hap file and you
can just download it for Linux,

50
00:02:43,171 --> 00:02:47,220
Mac and windows and then boom, you're
good to go. And it's got two modes.

51
00:02:47,221 --> 00:02:49,230
It's got a training mode
and an autonomous mode.

52
00:02:49,231 --> 00:02:52,050
And I'll talk about what each
of those modes is, but the,

53
00:02:52,480 --> 00:02:55,740
the high level is you just
download it and it just works.

54
00:02:55,741 --> 00:02:59,620
No dependencies to install or anything.
So it's super, super simple. Okay.

55
00:02:59,620 --> 00:03:01,900
So that's what they built.

56
00:03:02,140 --> 00:03:05,380
And so let's talk about the three
step process and how this works. Okay.

57
00:03:05,381 --> 00:03:06,850
There's a data generation part,

58
00:03:07,150 --> 00:03:10,270
then there's a training part
and then there's a testing part.

59
00:03:10,271 --> 00:03:14,470
So the first part is the data generation
park. And so what happens is, uh,

60
00:03:14,490 --> 00:03:18,220
we are going to first
look at what Nvidia did.

61
00:03:18,221 --> 00:03:22,960
So to generate data.
What nvidia did was they took their,

62
00:03:22,990 --> 00:03:27,160
they took a car and they did the same
exact thing that we're going to do.

63
00:03:27,220 --> 00:03:30,340
We're going to replicate what Nvidia and
you, Udacity did. It's the same thing.

64
00:03:30,730 --> 00:03:34,630
They built a nine layer convolutional
network and the attached three cameras to

65
00:03:34,631 --> 00:03:35,590
the head of a car.
Okay?

66
00:03:35,591 --> 00:03:40,591
So the attached three cameras to the
head of a car and they had a human driver

67
00:03:41,260 --> 00:03:45,010
drive the car while the cameras were
attached and all the car had to do with

68
00:03:45,011 --> 00:03:49,990
collect data and buy data.
I mean the steering, uh, let
me turn off the sound here.

69
00:03:50,170 --> 00:03:51,490
The steering commands that the,

70
00:03:51,491 --> 00:03:55,300
that the human driver was inputting
as well as the camera feed.

71
00:03:55,360 --> 00:03:59,350
So the three sets of camera images coming
from, from all three cameras. Okay.

72
00:03:59,351 --> 00:04:03,700
At the same time. And that was
the data generation park. Okay.

73
00:04:03,701 --> 00:04:04,690
And so there were,

74
00:04:04,720 --> 00:04:08,950
there was images from the center left
and right cameras with the Associated

75
00:04:08,950 --> 00:04:10,600
Steering Angle, speed, throttle and brake.

76
00:04:10,601 --> 00:04:15,601
So there were four of physics variables
as well as the static images that were

77
00:04:16,421 --> 00:04:20,140
coming in. And it saves it all to a
CSV, which is what we're going to do.

78
00:04:20,141 --> 00:04:22,870
And ideally, ideally you have
a joystick for this thing,

79
00:04:22,871 --> 00:04:24,940
but I don't have a joystick.
Ain't nobody got time for that.

80
00:04:25,180 --> 00:04:28,450
And just because it's
like, it's easier, it's,

81
00:04:28,451 --> 00:04:32,410
it's smoother with the transitions and
stuff using a keyboard that wasd keys.

82
00:04:32,410 --> 00:04:34,900
It's kind of erratic, but whatever.
I mean it works. It works.

83
00:04:34,990 --> 00:04:39,430
What you thought was based
off of a keyboard training.
So whatever it works. Uh,

84
00:04:39,431 --> 00:04:39,851
so yeah,

85
00:04:39,851 --> 00:04:42,970
so that's where the data generation
part and then there's the training part.

86
00:04:42,971 --> 00:04:47,440
Okay. So what the I, the idea is
that we have a human driver. Okay.

87
00:04:47,480 --> 00:04:51,520
So the human driver is just driving around
and we're reporting all that data and

88
00:04:51,521 --> 00:04:54,340
then we're going to get a
machine to clone that behavior.

89
00:04:54,341 --> 00:04:59,050
So we call this process behavioral
cloning. Okay. Behavioral cloning.

90
00:04:59,380 --> 00:05:02,980
And to do this, we're going to build
a nine layer convolutional network,

91
00:05:03,010 --> 00:05:06,520
nine layers. And in chaos, that's
just literally nine lines of code.

92
00:05:06,970 --> 00:05:10,810
And it was based off of Nvidia's end to
end learning for self driving car paper.

93
00:05:11,410 --> 00:05:12,041
And Yeah.

94
00:05:12,041 --> 00:05:15,400
So they trained a model for 72 hours
on the whole book in a whole bunch of

95
00:05:15,401 --> 00:05:20,260
different driving conditions, sleep,
rain, hail, all, all sorts of things.

96
00:05:20,260 --> 00:05:23,770
Wet Rain, you know, everything.
So here's the hardware design.

97
00:05:23,860 --> 00:05:27,340
So the hardware design was,
it's obviously a steering wheel,

98
00:05:27,490 --> 00:05:30,910
but the steering wheel is attached to a
controller. What was that? What was the,

99
00:05:30,911 --> 00:05:34,540
uh, so many acronyms here. Could
the controller area network bus.

100
00:05:34,900 --> 00:05:38,260
And so it's feeding in those four
variables that I talked about. Right.

101
00:05:38,590 --> 00:05:41,890
And you're also have your three cameras
and the three cameras are all feeding in

102
00:05:41,950 --> 00:05:43,090
continuous streams,

103
00:05:43,091 --> 00:05:47,470
like just frame by frame of all the
images that the car is seeing and it's fed

104
00:05:47,471 --> 00:05:51,990
into this drive px, a computer, which is
essentially like a motherboard with us,

105
00:05:52,020 --> 00:05:55,720
a cluster of genes onboard,
gps attached to it, and then a,

106
00:05:55,721 --> 00:05:59,270
and then a solid state storage would
just store the results. That's it. Okay.

107
00:05:59,271 --> 00:06:02,360
So that's the, that's the high level
idea behind the hardware behind it.

108
00:06:02,630 --> 00:06:06,410
And then the software behind it. Oh,
and also a interesting little tidbit,

109
00:06:06,411 --> 00:06:07,880
I just report it from the paper.

110
00:06:08,120 --> 00:06:12,260
Instead of inputting the
steering command are directly,

111
00:06:12,410 --> 00:06:17,410
they inputted one over r and they found
that this may turn smoother and it made

112
00:06:18,021 --> 00:06:21,120
the, it made the, uh,

113
00:06:21,230 --> 00:06:23,360
autonomous angles at the car moved

114
00:06:24,890 --> 00:06:28,100
independent of the geometry of the car.
So the car was facing left,

115
00:06:28,250 --> 00:06:31,310
it didn't matter or the conversation,
right. It's all about what the cameras is,

116
00:06:31,311 --> 00:06:36,311
what the camera's c and then using that
as the signal to then move the steering

117
00:06:37,341 --> 00:06:38,330
ankle.
So it's,

118
00:06:38,480 --> 00:06:42,560
it's independent of the direction of
the car is facing and it sounds kind of

119
00:06:42,561 --> 00:06:46,040
counterintuitive. Like wait, you would
want that but you actually wouldn't end.

120
00:06:46,041 --> 00:06:49,160
We'll learn more about why that
is as we get into this code. Okay.

121
00:06:49,340 --> 00:06:53,510
So the software designed for this code
and it's so crazy cause going from

122
00:06:53,511 --> 00:06:56,900
generative adversarial networks to this.
It's like that's it.

123
00:06:56,930 --> 00:07:00,230
That's all it takes for self
driving car. Like what? But that's,

124
00:07:00,231 --> 00:07:03,830
that is actually how it is.
Check this out. So here's,
here's, here's what happens.

125
00:07:04,880 --> 00:07:07,940
We have, uh, we have two inputs, right?

126
00:07:07,941 --> 00:07:11,750
We have our steering angle and then we
have our sets of cameras, right? Let's,

127
00:07:11,800 --> 00:07:15,410
so three sets of images.
Those are our inputs. And so

128
00:07:17,000 --> 00:07:20,570
we can think of the problem as a
supervised learning problem, right?

129
00:07:20,720 --> 00:07:22,640
We have our input data,
which is,

130
00:07:22,700 --> 00:07:26,870
which are the images and then
our output labels, which are the,

131
00:07:27,230 --> 00:07:31,610
if we could just abstract all of the
steering angles and one value, you know,

132
00:07:31,611 --> 00:07:35,870
like one binary value that would be
our label. Like based on what you see,

133
00:07:36,590 --> 00:07:38,750
how should you move the
car? That's it, right?

134
00:07:38,810 --> 00:07:41,900
So we have a CSV just listed
and all of those things, right?

135
00:07:42,110 --> 00:07:46,190
And at the same time we have uh,
what the car is trying to do.

136
00:07:46,190 --> 00:07:49,670
So during the training process,
assuming we've generated data 72,

137
00:07:49,700 --> 00:07:53,820
let's say 72 hours of human generated
driving data, we can then, uh,

138
00:07:54,230 --> 00:07:55,700
compare the,

139
00:07:56,390 --> 00:08:00,410
both of those results together so we can
compute the error or lost between the

140
00:08:00,411 --> 00:08:02,000
two. Right? So if we have,

141
00:08:02,180 --> 00:08:06,080
let's just say we have the camera
angles and the steering wheel from the

142
00:08:06,081 --> 00:08:10,070
autonomous car and then the camera angles
and the steering wheel variable from

143
00:08:10,071 --> 00:08:12,410
the human generated data.

144
00:08:12,530 --> 00:08:16,760
And then we just vectorize both
of those values into one value.

145
00:08:16,970 --> 00:08:19,850
And then we find a difference between
those values and that difference is our

146
00:08:19,851 --> 00:08:20,570
error.

147
00:08:20,570 --> 00:08:25,490
And then we use backpropagation to then
update our weights based on that error

148
00:08:25,491 --> 00:08:30,110
value. Okay. So it's taking that,
that weight value or that back,

149
00:08:30,140 --> 00:08:34,700
that air value and in back
propagating it in our weights. Okay.

150
00:08:34,850 --> 00:08:38,900
So images are images are fed into the
CNN and then it computes a proposed

151
00:08:38,901 --> 00:08:41,810
steering committee. Okay. And that
is the predicted steering command.

152
00:08:41,840 --> 00:08:45,170
And we want to find a difference between
the predicted steering command and what

153
00:08:45,171 --> 00:08:49,490
the actual steering command would
be from the training data. Okay. Uh,

154
00:08:49,491 --> 00:08:52,820
and then the proposed command is
compared to the desired command, right?

155
00:08:52,821 --> 00:08:56,010
Label the target label
versus the actual outputs.

156
00:08:56,310 --> 00:08:59,850
And then the weights of the CNN are
adjusted to bring the CNN output closer to

157
00:08:59,851 --> 00:09:01,110
the desired output.

158
00:09:01,650 --> 00:09:03,680
And the way that adjustment is
accomplished via backpropagation.

159
00:09:04,080 --> 00:09:07,200
So eventually you want, it's trained,
then all you're going to need is,

160
00:09:07,440 --> 00:09:11,400
is the center camera, just one camera,
you feed it to the, to the CNN,

161
00:09:11,430 --> 00:09:13,170
and then it outputs a prediction.

162
00:09:13,171 --> 00:09:17,160
And the prediction is the angle of the
steering wheel, just one output. Right?

163
00:09:18,030 --> 00:09:22,590
So that's it for training and then for
testing, right? So once, once we've,

164
00:09:22,680 --> 00:09:26,400
once we've trained this autonomous model
for testing, we could think of it in,

165
00:09:26,401 --> 00:09:30,510
in terms of a simulator as a
server client architecture, right?

166
00:09:30,690 --> 00:09:33,570
The server is going to be the simulator
itself. That is our, you know,

167
00:09:33,571 --> 00:09:34,980
the APP that we downloaded that,

168
00:09:34,981 --> 00:09:38,700
that little three d game and the client
is going to be our python program that

169
00:09:38,760 --> 00:09:43,230
what we write and what it's going to do
is it's going to just be a feedback loop.

170
00:09:43,260 --> 00:09:46,440
It's going to be a feedback loop
so we can consider it as just,

171
00:09:46,550 --> 00:09:47,970
so this is how we can consider it.

172
00:09:47,971 --> 00:09:52,800
It's just the client is piping in steering
angles and throttles to the server

173
00:09:52,920 --> 00:09:55,190
and the server is piping back,
uh,

174
00:09:56,910 --> 00:10:01,560
images from the car and steering
angles so that it can train it, right?

175
00:10:01,561 --> 00:10:04,350
It's just that it's just a, it's
just a feedback loop. So that's,

176
00:10:04,351 --> 00:10:08,070
that's the basic idea behind, you know,
how this works. High level and video,

177
00:10:08,071 --> 00:10:10,350
have the paper on it and
then you, Udacity, you know,

178
00:10:10,351 --> 00:10:13,020
was inspired by it and now
I'm bringing it to you guys.

179
00:10:13,020 --> 00:10:17,430
So it's just the chain of a chain of
whatever. Okay, so let's build this thing,

180
00:10:17,580 --> 00:10:19,230
right enough talk,
let's go this thing.

181
00:10:19,231 --> 00:10:21,900
So that's the first step is
to install our dependencies.

182
00:10:22,050 --> 00:10:24,840
And you can do this really easily
with just one line of code.

183
00:10:24,990 --> 00:10:26,610
There's an environments dot

184
00:10:28,170 --> 00:10:31,890
yml file and you can use
Anaconda to do this. Okay?

185
00:10:33,750 --> 00:10:38,340
So if we look in the environments file,
we've got like 20 dependencies here,

186
00:10:38,341 --> 00:10:40,950
but you don't have to, you know, as
long as you run this one line of code,

187
00:10:41,160 --> 00:10:44,640
it's going to install all of these
dependencies. I make this bigger,

188
00:10:45,600 --> 00:10:50,190
all of these dependencies
super easily. Okay? So yeah,

189
00:10:50,191 --> 00:10:54,390
you've got open CV, which we all know
is a pain to install. So luckily for us,

190
00:10:54,391 --> 00:10:57,090
Anaconda is going to make it
super easy to install. Okay?

191
00:10:57,240 --> 00:11:00,210
So that's the first step.
Now, I would do this myself,

192
00:11:00,211 --> 00:11:03,570
but I've already installed
the dependency here. Uh,

193
00:11:03,600 --> 00:11:08,220
but what I can do, right? So you just
paste that in and once you paste that in,

194
00:11:08,430 --> 00:11:11,580
then you're going to type in, I can
show you the command. You say source,

195
00:11:13,200 --> 00:11:17,780
activate. What was the
command? I'll put it in the,

196
00:11:17,790 --> 00:11:18,860
I'll put it in the get how breathing,

197
00:11:18,870 --> 00:11:21,960
but you then you activate your conda
environment and it's gonna be called

198
00:11:21,961 --> 00:11:26,760
behavioral cloning. Source
activate, behavioral cloning.

199
00:11:26,790 --> 00:11:28,320
And then that activates the environment.

200
00:11:28,321 --> 00:11:32,160
So you install your dependencies in
this container, this Anaconda container,

201
00:11:32,280 --> 00:11:33,240
and then you activate it.

202
00:11:33,241 --> 00:11:36,870
So then all those dependencies are then
active in that Shell, in that session,

203
00:11:37,080 --> 00:11:40,830
in terminal. Okay. And so once we have
that, then we can generate our data. Okay.

204
00:11:40,831 --> 00:11:44,040
Where we've got our dependencies.
Now, step two is to generate our data.

205
00:11:44,041 --> 00:11:48,150
So this is, it's a five step process.
We're going to install our dependencies,

206
00:11:48,450 --> 00:11:51,720
which we assume I've done.
Step two is to generate the data.

207
00:11:51,750 --> 00:11:54,420
So we're going to drive and
we're going to replicate,

208
00:11:54,580 --> 00:11:56,860
replicate what the Nvidia
did with the human drivers.

209
00:11:57,040 --> 00:12:00,160
Step three is to write the training
script, step forwards to train it.

210
00:12:00,220 --> 00:12:04,000
Then have our agents learn or clone
the behavior of us, the human.

211
00:12:04,240 --> 00:12:08,470
And step five is to write the testing
scripts and then let it run. Okay?

212
00:12:08,471 --> 00:12:11,500
So let's go ahead and generate our data.
So to generate our data,

213
00:12:11,770 --> 00:12:14,800
we're going to have to actually drive
this baby, which is gonna be a lot of fun.

214
00:12:15,160 --> 00:12:18,790
Now you just double click on the
APP, you know, I downloaded it,

215
00:12:18,791 --> 00:12:20,680
you can double click on it
and then you know, it's got,

216
00:12:20,710 --> 00:12:24,250
it's got a couple of settings I sent
it to. Fantastic because why not?

217
00:12:24,340 --> 00:12:28,410
Of course the choice, uh, but
uh, you know, fastest, you know,

218
00:12:28,490 --> 00:12:30,880
depending on your processor, you,
you would want to change this.

219
00:12:31,240 --> 00:12:34,870
So I'm going to go ahead and run
it at 800 by 600 and it's gonna,

220
00:12:35,230 --> 00:12:39,400
it's gonna pop up just like that. And
I'm going to go into training mode. Okay.

221
00:12:39,401 --> 00:12:43,270
So for training, for training mode,
I'll just click on training mode.

222
00:12:43,540 --> 00:12:47,350
And the controls are going to be w a
s. D. Okay. So just like this, see,

223
00:12:47,351 --> 00:12:51,190
this is me driving right now.
Hi, I'm driving the car. Okay.

224
00:12:51,340 --> 00:12:54,820
And now I'm going to stop the car
and I'm driving it again. Okay.

225
00:12:54,821 --> 00:12:56,440
So this is human driving.

226
00:12:56,710 --> 00:13:00,310
So what we're going to do is we're going
to generate data so that we can train

227
00:13:00,340 --> 00:13:04,720
our, our car on that data. Okay? So
to do this, we just have to type in,

228
00:13:04,930 --> 00:13:08,830
just type our right to record are.
And so then it's going to ask, well,

229
00:13:08,831 --> 00:13:10,240
where do you want to save this data too?

230
00:13:10,241 --> 00:13:13,360
And I'm going to say let's
save it to the desktop. Okay,

231
00:13:14,020 --> 00:13:17,050
let's save it to the
desktop and start recording.

232
00:13:17,410 --> 00:13:22,410
And now what it's doing is it is
reporting three sets of images from three

233
00:13:23,051 --> 00:13:26,800
virtual cameras of the car. Okay?
Assume that the cameras are on top,

234
00:13:26,950 --> 00:13:30,760
but what it's doing is it's capturing
frames from this game from three different

235
00:13:30,761 --> 00:13:34,060
angles. And it's also recording the, my,

236
00:13:34,630 --> 00:13:37,900
the four variables I talked
about speed, throttle, and the,

237
00:13:37,930 --> 00:13:41,680
the other two of the steering angle.
There's one more that I'll look at,

238
00:13:41,860 --> 00:13:45,490
but basically what you want to do as
you train this thing is you want to

239
00:13:45,491 --> 00:13:49,990
complete either one between
one and five laps. Okay?

240
00:13:50,380 --> 00:13:54,760
Ideally five. But, and look, I'm off
track, but let me just stop recording.

241
00:13:54,790 --> 00:13:57,880
And so then once you're done, you know,
driving between one and five laps,

242
00:13:58,120 --> 00:14:01,150
then hit our again and it's
going to capture that data.

243
00:14:01,151 --> 00:14:05,110
So it's going to replay what you've
just done and it's going to go up to a

244
00:14:05,110 --> 00:14:06,370
hundred percent and when it's done,

245
00:14:06,430 --> 00:14:10,180
it's going to save it all to a CSV file
that we're going to look at and see

246
00:14:10,250 --> 00:14:11,890
what's inside of there
so we could observe it.

247
00:14:12,220 --> 00:14:15,730
So we've got 52% and in the meantime,

248
00:14:15,760 --> 00:14:19,900
let me go to the CSV file and
show you guys that. What else?

249
00:14:19,901 --> 00:14:21,930
What else can I show you
while this captures? Well,

250
00:14:21,931 --> 00:14:23,230
it's actually fun to just watch this.

251
00:14:23,231 --> 00:14:27,730
Let me see what else I can talk about the
training and testing script. Uh, yeah,

252
00:14:27,731 --> 00:14:32,110
we're going to be using carrots 95% here
we go. Done. Okay, let's check it out.

253
00:14:32,111 --> 00:14:33,790
What if,
what did we save here?

254
00:14:34,240 --> 00:14:38,470
So if I go to open and then
I go to my desktop there,

255
00:14:38,500 --> 00:14:41,590
my driving log, just just like
we thought it would be. Okay.

256
00:14:41,591 --> 00:14:44,530
So let's take a look at what this is.
Let's take a look at what this is.

257
00:14:47,110 --> 00:14:50,110
What we've got here are three images,
right?

258
00:14:50,111 --> 00:14:54,350
And it's the three columns are images,
they're pointing to images.

259
00:14:54,500 --> 00:14:57,620
And these are the images that it's
pointing to right here, this image folder.

260
00:14:58,100 --> 00:15:02,690
Okay? They're pointing their
absolute, uh, directory values.

261
00:15:02,710 --> 00:15:04,460
It shows us exactly where they are.
See,

262
00:15:04,461 --> 00:15:07,190
these are the images that they're
pointing to, just like that.

263
00:15:08,330 --> 00:15:10,820
And then these are frames that
were captured from the game.

264
00:15:11,150 --> 00:15:15,050
And we've got three sets of images
for the center for the left.

265
00:15:15,080 --> 00:15:17,600
And these are labeled with
the direction and the right.

266
00:15:17,630 --> 00:15:22,160
So we've got three sets of images
and then we've got four values here.

267
00:15:22,161 --> 00:15:25,040
And these four values are those
values that I talked about up here,

268
00:15:25,220 --> 00:15:29,600
which are the,
which ones are they?

269
00:15:29,630 --> 00:15:33,170
The steering angle, the speed, the
throttle, and the brake. All four values.

270
00:15:33,171 --> 00:15:36,830
And these are what I inputted and
see how at the start I wasn't moving.

271
00:15:36,830 --> 00:15:39,860
So these are, these are zero
values, but then as I start moving,

272
00:15:40,190 --> 00:15:44,270
they're going to change. Okay. So
that's it. That's it for our data.

273
00:15:44,330 --> 00:15:46,880
So what you want to do is
write training between one run,

274
00:15:46,881 --> 00:15:51,680
one full lap and five laps. Okay, so
somewhere in between there. So yes,

275
00:15:51,740 --> 00:15:55,940
that's, that's it for our
uh, data generation part.
Where were we in our process?

276
00:15:55,941 --> 00:15:59,840
We were at step two. So assume that I've
generated data. Okay. Just like that.

277
00:15:59,890 --> 00:16:01,880
It would take a while,
but I generated data.

278
00:16:02,030 --> 00:16:04,490
So the next step is for us
to write our training script.

279
00:16:04,610 --> 00:16:08,060
So let's write this training
script. Okay. So where were we

280
00:16:09,680 --> 00:16:13,070
for our training script?
I'm going to say,

281
00:16:14,900 --> 00:16:17,540
okay, so we've got two files
here. We've got a training script,

282
00:16:17,541 --> 00:16:21,450
which is modeled up high, and then we've
got a testing script called Dr Puy. Well,

283
00:16:21,460 --> 00:16:22,910
let's write our training scripts,
right?

284
00:16:23,030 --> 00:16:27,440
We've generated our data and
we've saved it to the desktop.

285
00:16:27,590 --> 00:16:31,670
And now we want to build a model that
will see a convolutional network and we'll

286
00:16:31,671 --> 00:16:36,230
read from this data and then it will
output output steering commands.

287
00:16:36,260 --> 00:16:39,560
So we've got pandas. Pandas is going
to be our data analysis to toolkits.

288
00:16:39,860 --> 00:16:42,820
None Pie's going to help us do matrix
math. We're going to import psychic,

289
00:16:42,821 --> 00:16:47,390
can't learn just so we can split our
training and testing data into sets into

290
00:16:47,420 --> 00:16:48,080
sets.

291
00:16:48,080 --> 00:16:52,190
And then we're going to use care os as
our machine learning model sequential

292
00:16:52,191 --> 00:16:55,250
because it's going to be a linear
stack of layers. Very simple model.

293
00:16:55,580 --> 00:16:59,630
And then Adam for gradient descent model
checkpoints. So we could save our model.

294
00:16:59,870 --> 00:17:02,960
And then we've got a mid layer
types that we're going to use.

295
00:17:03,320 --> 00:17:06,860
Then our helper class utils it's going
to define our input shape and generate

296
00:17:06,861 --> 00:17:11,510
training images and then our, our cars
for command line arguments. And lastly,

297
00:17:11,511 --> 00:17:13,760
r o s module for reading files.

298
00:17:13,940 --> 00:17:16,970
So what I'm gonna do is I'm going to
write the code for building the model

299
00:17:16,971 --> 00:17:20,030
itself. Uh, but all of all the
rest of it is prewritten, right?

300
00:17:20,031 --> 00:17:21,860
So the data loading parts are prewritten.

301
00:17:22,100 --> 00:17:25,310
We're going to load that CSV
file that we just created, right?

302
00:17:25,311 --> 00:17:29,840
That driving log and make it bigger,
make it bigger. So that driving log,

303
00:17:29,841 --> 00:17:30,230
we're going to,

304
00:17:30,230 --> 00:17:33,200
we're going to generate that data or
we're going to read from that data using

305
00:17:33,201 --> 00:17:36,530
pandas and then we're going to say,
okay,

306
00:17:36,531 --> 00:17:40,070
so now we have that in a data frame
variable, very easily possible variable.

307
00:17:40,071 --> 00:17:44,360
Thank you pandas. Then we're going to
say for the center left and right, uh,

308
00:17:44,361 --> 00:17:47,710
columns get those values and that this
is going to be our input data that's

309
00:17:47,720 --> 00:17:48,980
going to be our x,
right?

310
00:17:49,260 --> 00:17:52,930
And then are a output data is going to
be our steering commands. So we can,

311
00:17:53,220 --> 00:17:55,980
we can can catenate that
into one variable, right?

312
00:17:56,100 --> 00:18:00,280
So then we have our input data and our
input and our output labels and we want

313
00:18:00,281 --> 00:18:04,560
to find the mapping between the two and
it says a supervised learning problem.

314
00:18:04,561 --> 00:18:08,220
And once we find the mapping between
the two, then given novel input data,

315
00:18:08,221 --> 00:18:11,640
which is novel a camera
images of what a car sees,

316
00:18:11,790 --> 00:18:13,920
we can then output the predicted label,

317
00:18:13,921 --> 00:18:17,580
which will be the Syrian command
c very intuitive. Right. Okay.

318
00:18:17,581 --> 00:18:21,210
So we've got our input data and our output
labels and then we can split the data

319
00:18:21,211 --> 00:18:25,350
into training and testing data.
So it's 80% training, 20% testing,

320
00:18:25,530 --> 00:18:28,650
and we can define the size of that in
our command line argument and test size.

321
00:18:28,651 --> 00:18:32,970
Okay, we're just going to be a point
to oh, this is going to be this value.

322
00:18:33,540 --> 00:18:34,920
And so yeah,
so we're going to have a training,

323
00:18:34,921 --> 00:18:38,540
our training data and our testing data
and our validation data and we returned

324
00:18:38,640 --> 00:18:43,220
that. Okay, so, and then we've got
the code for building our model, uh,

325
00:18:43,230 --> 00:18:47,220
and then training the model and
then the main function, right?

326
00:18:47,280 --> 00:18:49,650
So let's forget about these
command line arguments.

327
00:18:49,651 --> 00:18:53,970
So let's just go straight to the main
function and let's say that for our main

328
00:18:53,971 --> 00:18:56,380
function after printing, you
know, whatever our parameters are,

329
00:18:56,390 --> 00:18:58,180
we're going to load our
data using that funk,

330
00:18:58,181 --> 00:19:00,540
that function that we just talked about.

331
00:19:00,700 --> 00:19:02,670
And then we're going to
take that data and use it to

332
00:19:05,100 --> 00:19:07,170
train our model and look
first we'll build our model.

333
00:19:07,320 --> 00:19:10,140
And then once we built our model and
loaded our data, we'll train our model,

334
00:19:10,170 --> 00:19:13,260
right? Using those two parameters as
well as any command line arguments.

335
00:19:13,590 --> 00:19:14,800
So this committee,

336
00:19:14,880 --> 00:19:19,880
this helper function just
as for converting a string
to a boolean value for our

337
00:19:20,311 --> 00:19:24,140
command line argument. But this training
model function is really interesting. Uh,

338
00:19:24,240 --> 00:19:27,660
let's first build a model and
then we'll talk about the, uh,

339
00:19:27,870 --> 00:19:30,930
the training model function.
Okay. So for this first part,

340
00:19:32,010 --> 00:19:34,470
we're going to build this model and it's
going to be a sequential model, right?

341
00:19:34,471 --> 00:19:36,930
It's going to be sequential model,
very simple model.

342
00:19:37,140 --> 00:19:39,200
And we can just pull this
straight from the paper it's,

343
00:19:39,210 --> 00:19:42,420
or even the paper write the paper told
us the parameters with which we could

344
00:19:42,421 --> 00:19:44,700
build our network.
So we'll use those parameters,

345
00:19:44,701 --> 00:19:46,440
we'll use those parameters
to build our network.

346
00:19:46,740 --> 00:19:49,230
So the first step is for us to say,
okay,

347
00:19:49,590 --> 00:19:52,950
we want our first layer to be an
image normalization layer. Okay,

348
00:19:52,951 --> 00:19:53,940
we can totally do that.

349
00:19:54,390 --> 00:19:58,650
Our image normalization layer using our
lambda function and the land of function

350
00:19:59,010 --> 00:20:03,330
is going to help us do so really
easily. And we'll say, okay,

351
00:20:03,331 --> 00:20:04,380
it's going to be,

352
00:20:06,300 --> 00:20:10,110
let me type this out and then I'll
talk about it. Input, shape. Okay,

353
00:20:10,170 --> 00:20:11,430
so what's the deal here?

354
00:20:12,030 --> 00:20:16,110
So x exited.
Yeah.

355
00:20:16,350 --> 00:20:19,960
So this is going to avoid saturation
and make our grants work better.

356
00:20:19,990 --> 00:20:23,280
Now notice that these are magic
number's right here. Uh, but we,

357
00:20:23,340 --> 00:20:25,180
but the authors found that,
you know,

358
00:20:25,320 --> 00:20:27,540
after training and testing
out different values,

359
00:20:27,690 --> 00:20:30,540
these are the ones that work best
for normalizing the images, right?

360
00:20:30,541 --> 00:20:34,260
When we input it to avoid saturation and
make the gradients worked at or what do,

361
00:20:34,261 --> 00:20:37,260
what do we mean exactly by that is,
you know,

362
00:20:37,980 --> 00:20:41,730
the images can be shadowy, they can,
you know, depending on the lighting,

363
00:20:41,731 --> 00:20:45,930
it can be certain things can be
obstructed or the hue or that, you know,

364
00:20:45,960 --> 00:20:50,960
all of these color correction values could
be off and they could give us results

365
00:20:51,761 --> 00:20:56,140
that are bad. So we went to avoid
that, right? So that's that. When we,

366
00:20:56,141 --> 00:20:57,580
when we say image normalization,

367
00:20:57,581 --> 00:21:02,581
what we really mean is we want to format
or reshape these image tensor values

368
00:21:02,890 --> 00:21:06,430
and two values that will give us
good predictions in the end. Right?

369
00:21:06,580 --> 00:21:09,430
So that's it for our first model.

370
00:21:09,431 --> 00:21:12,760
And then we've got a bunch
of convolutional layers
that we can essentially

371
00:21:12,761 --> 00:21:13,210
copied it.

372
00:21:13,210 --> 00:21:15,520
Copy and paste ones who've written
out the first one because they're very

373
00:21:15,521 --> 00:21:19,060
similar. And so the first one is going
to have a filter size of 24. Okay,

374
00:21:19,061 --> 00:21:23,140
I got you. And it's got, it's going to
be a five by five convolution. Okay.

375
00:21:23,141 --> 00:21:27,250
I can do that as well. And then it's
going to have an activation function,

376
00:21:27,251 --> 00:21:31,840
which is going to be Elu, which means
exponential when your unit. So can,

377
00:21:31,841 --> 00:21:34,040
we've got Elu here. Okay. Which is

378
00:21:36,100 --> 00:21:39,460
more suited for this task
then rectified linear units.

379
00:21:39,760 --> 00:21:42,940
And we're going to sub sample with two
by two because that's the length of our

380
00:21:42,941 --> 00:21:47,560
strides. And then we'll add
our closing parentheses.

381
00:21:47,980 --> 00:21:51,960
Okay. So that's it. Um, and
so why do we use the loo?

382
00:21:51,980 --> 00:21:55,900
Is it's because it takes care of the
vanishing gradient problem. That's why.

383
00:21:56,170 --> 00:21:59,680
So okay. So we've got five
of these layers. Let me just
paste that one, two, three,

384
00:21:59,681 --> 00:22:03,580
four. How many of these five I think
that's fine. That's fine. Okay.

385
00:22:03,760 --> 00:22:06,310
So then we want to make sure, okay,
so what's the difference here?

386
00:22:06,311 --> 00:22:10,240
The filter size here is 36 this is how
you can just read from a paper and just

387
00:22:10,241 --> 00:22:12,550
write out the model directly,
right? It's not that hard.

388
00:22:12,551 --> 00:22:16,180
They have the parameters and with a
simple library like carrots, you can,

389
00:22:16,240 --> 00:22:20,530
you can build a model pretty easily.
So we've got 36 we've got 48

390
00:22:22,990 --> 00:22:27,080
64
64 okay.

391
00:22:27,081 --> 00:22:31,190
And so then we can remove the sub sampling
for this, for these last two layers,

392
00:22:31,191 --> 00:22:35,540
since the census, stride size is one
by one respectively for each of the,

393
00:22:35,600 --> 00:22:36,433
for each of them.

394
00:22:36,560 --> 00:22:41,560
So they'll just end in the activation
and then we're going to add a dropout

395
00:22:42,440 --> 00:22:46,580
layer. Okay? So it's asking
for 50% dropout. We can do
that. So we'll say, okay,

396
00:22:46,581 --> 00:22:50,810
drop out. We'll add it based on
what the user says it's going to be.

397
00:22:50,840 --> 00:22:51,850
And we're going to,
it's going to,

398
00:22:51,890 --> 00:22:55,400
we're going to input 50% later
and then we're going to say, okay,

399
00:22:55,401 --> 00:22:59,780
so now that it's dropped out,
we're going to flatten the the data.

400
00:23:00,140 --> 00:23:01,550
And so why do we thought flattened it?

401
00:23:01,551 --> 00:23:05,810
Because we're going to start feeding in
a series of fully connected layers and y,

402
00:23:05,870 --> 00:23:06,380
y,

403
00:23:06,380 --> 00:23:11,380
y series of fully connected layers because
the convolutional layers are meant to

404
00:23:11,541 --> 00:23:16,230
handle feature engineering. So that
means that the image processing part,

405
00:23:16,231 --> 00:23:17,680
so the filters, right? So we,

406
00:23:17,681 --> 00:23:22,681
we feed in a set of images and what the
convolutional layers we'll do is each of

407
00:23:23,421 --> 00:23:27,500
them respectively is going
to create a set of filters.

408
00:23:27,620 --> 00:23:31,970
And these filters are going to be, you
know, increasingly abstract, right?

409
00:23:31,970 --> 00:23:34,460
So they're going to start off with low
level features and they're going to get

410
00:23:34,490 --> 00:23:37,970
increasingly more extract. So they're
going to be able to detect images.

411
00:23:38,150 --> 00:23:41,150
But what we want to output is
not an image, but we want to,

412
00:23:41,300 --> 00:23:45,800
what it is that we want to output is a
value and that value is single value.

413
00:23:45,830 --> 00:23:48,020
And that as the steering command,
the right, it's a direction.

414
00:23:48,021 --> 00:23:50,780
How do you want to move this,
this wheel. So to do that,

415
00:23:50,781 --> 00:23:55,010
to get a single value from these high
dimensional image tensors, we have to,

416
00:23:55,190 --> 00:23:56,570
we have to squash that data.

417
00:23:56,571 --> 00:24:00,530
And the way to do that is by applying a
series of fully connected layers. Okay.

418
00:24:00,680 --> 00:24:02,690
And so what's gonna Happen is,
uh,

419
00:24:02,750 --> 00:24:06,440
each of these fully connected layers is
going to progressively get smaller and

420
00:24:06,441 --> 00:24:08,690
smaller in terms of the
number of neurons they have.

421
00:24:08,930 --> 00:24:09,860
And you'll see what I mean here.

422
00:24:09,860 --> 00:24:12,950
So it says the first one should have
a hundred neurons. So we'll say, okay,

423
00:24:12,951 --> 00:24:14,030
so this is a dense,

424
00:24:14,240 --> 00:24:17,690
which means fully connected layer and
it's activation function, like all the,

425
00:24:17,750 --> 00:24:19,610
all the other layers
is going to be he Lou.

426
00:24:19,970 --> 00:24:23,960
And so then what we can do is we can just
copy and paste this. I'll say one, two,

427
00:24:23,990 --> 00:24:26,060
three. So there's going to
be four of them in total.

428
00:24:26,270 --> 00:24:29,100
Each of them is going to be smaller.
So hundred neurons, 15 [inaudible],

429
00:24:29,190 --> 00:24:32,030
10 neurons,
and then just a single neuron.

430
00:24:32,031 --> 00:24:35,720
And this one won't have an activation
function because it's the last layer and

431
00:24:35,721 --> 00:24:40,721
that's going to output are driving
a value our steering down and say,

432
00:24:42,351 --> 00:24:44,480
okay, so it's a summary. And
so of all of those summer,

433
00:24:44,540 --> 00:24:49,490
all those values to get the summary and
then return the model. Okay. And so then

434
00:24:53,360 --> 00:24:54,230
we'll say,

435
00:24:57,190 --> 00:25:00,580
how much do we have here that they're,
there we go and then return the model.

436
00:25:00,610 --> 00:25:03,510
Okay, cool. So right, so for
our fully connected layers,

437
00:25:03,520 --> 00:25:06,730
we start off with a big layer and then
we want to get progressively smaller.

438
00:25:06,760 --> 00:25:11,760
And so the way to do that is by using a
model summary or by is by using a series

439
00:25:11,921 --> 00:25:14,080
of fully connected layers
that get smaller and smaller.

440
00:25:14,260 --> 00:25:16,510
And what that's going to do
is going to squash our data.

441
00:25:16,511 --> 00:25:20,620
So it's going to basically be like a
triangle in terms of the number of values

442
00:25:20,621 --> 00:25:21,520
in that,
in that,

443
00:25:21,550 --> 00:25:24,760
in those matrices that are being
propagated forward in our network.

444
00:25:24,790 --> 00:25:28,300
So it's gonna be like, you
know, uh, 10 uh, a matrix,

445
00:25:28,301 --> 00:25:32,830
the matrix with 10 in indices and then
like a matrix matrix with five indices

446
00:25:32,980 --> 00:25:36,880
and a matrix with two indices and
eventually one single scalar value.

447
00:25:36,940 --> 00:25:40,240
And that is our output and that's
what this is going to do. Right.

448
00:25:40,420 --> 00:25:44,620
And the wine in the paper,
they noted this, but I, I
didn't actually document this.

449
00:25:44,890 --> 00:25:49,410
They noted that it's not sure where
the image part and the ND, uh,

450
00:25:49,570 --> 00:25:53,590
steering part begin and end because it's
all kind of connected, right? In terms of

451
00:25:55,360 --> 00:25:57,490
what the,
what the neural network looks like.

452
00:25:57,580 --> 00:25:59,650
But that's part of the black
box magic of neural networks.

453
00:25:59,651 --> 00:26:04,651
We don't know exactly where one feature
starts in one feature ends in terms of

454
00:26:05,320 --> 00:26:10,030
where it lies in bs in this abstraction
hierarchy. But we know that all as a,

455
00:26:10,031 --> 00:26:14,350
as a whole, as a sum total, there is
some, there is some connectedness, right?

456
00:26:14,500 --> 00:26:18,610
So anyway, so that's it for our model.
And then once we have this model,

457
00:26:18,611 --> 00:26:19,720
we're going to train the model.

458
00:26:20,290 --> 00:26:22,210
And so let me talk about
this last training function.

459
00:26:22,450 --> 00:26:25,030
So for the training function,
we're going to say, okay,

460
00:26:25,090 --> 00:26:28,510
take the model and then the,
the training data and the validation data.

461
00:26:28,610 --> 00:26:31,270
So modeling data and train
it, right? So to do this,

462
00:26:31,480 --> 00:26:33,700
we're going to run the
model checkpoint function.

463
00:26:33,701 --> 00:26:38,701
And what this does is it saves our model
at ace in a checkpoint that we bear,

464
00:26:40,100 --> 00:26:40,933
that we,

465
00:26:42,480 --> 00:26:42,860
Yep.

466
00:26:42,860 --> 00:26:46,440
That we say that we want and it's gonna
be model dot h five and then we're going

467
00:26:46,441 --> 00:26:49,570
to say, well, what is the loss function
that we want to monitor? We're,

468
00:26:49,600 --> 00:26:51,960
which we're going to call
the validation loss. Not yet,

469
00:26:51,961 --> 00:26:53,850
but we're going to call it that.
And

470
00:26:55,350 --> 00:26:57,900
we only want to save the best model.
Okay?

471
00:26:57,930 --> 00:27:01,890
And then we're going to say the mode is
going to be auto and automotive means

472
00:27:01,891 --> 00:27:05,250
the direction is automatically inferred
from the name of the monitor quantity.

473
00:27:05,670 --> 00:27:09,620
Okay? So that's it for our checkpoint.
And then we want to compile our models.

474
00:27:09,621 --> 00:27:11,490
So what are we going to do
here? We're going to say, okay,

475
00:27:11,491 --> 00:27:14,360
well what is our loss function are going
to be? Well, there are several laws,

476
00:27:14,370 --> 00:27:17,070
assumptions that we can use and we're
going to use a really simple one called

477
00:27:17,071 --> 00:27:18,960
mean squared error.
What does that mean?

478
00:27:18,990 --> 00:27:22,590
So our model is going to output
a predicted a steering angle,

479
00:27:22,740 --> 00:27:26,040
and then we have an actual steering
angle from the human driver given those

480
00:27:26,041 --> 00:27:26,874
camera angles.

481
00:27:27,090 --> 00:27:31,650
And then we want to find the difference
between those angles and do that for all

482
00:27:31,651 --> 00:27:35,580
of the uh, data points that we have. Okay.

483
00:27:35,581 --> 00:27:40,200
And then some of the differences.
And then, uh, hold on.

484
00:27:40,410 --> 00:27:43,210
We want to find the difference.
Square, the difference, Adam,

485
00:27:43,260 --> 00:27:45,450
all the differences and then
divide by the number of them.

486
00:27:45,451 --> 00:27:50,130
And that's going to be the mean squared
error. The sum of the squared errors.

487
00:27:50,160 --> 00:27:54,840
Okay. Or the mean of the
squared errors. Right. Uh,

488
00:27:54,841 --> 00:27:58,650
and so then we're going to use the Adam
optimizer, which is gradient descent. Uh,

489
00:27:58,710 --> 00:27:58,980
yeah.

490
00:27:58,980 --> 00:28:02,310
And so that's how we compile our model
and then we're going to generate some

491
00:28:02,311 --> 00:28:06,390
data. So what we're doing here is
we're running the fit generator. Okay.

492
00:28:06,391 --> 00:28:11,391
And so what did fit generator does is it
lets you do realtime data augmentation

493
00:28:12,061 --> 00:28:15,930
on images on the CPU in parallel
to training our model on the GPU.

494
00:28:16,140 --> 00:28:19,800
What do we mean by that? What we are
generating batches of data. Okay.

495
00:28:19,950 --> 00:28:23,420
While we are generating those batches
of data from, from our training data,

496
00:28:23,430 --> 00:28:24,540
like the,
the,

497
00:28:24,900 --> 00:28:28,470
the buckets or the containers from
which we train our model in from the,

498
00:28:28,471 --> 00:28:31,170
from the huge set at the same
time we're actually, we're,

499
00:28:31,470 --> 00:28:32,610
we're training our model,
right?

500
00:28:32,611 --> 00:28:37,260
So what this fit generator function does
is it does both simultaneously. Okay.

501
00:28:37,261 --> 00:28:41,390
So it's super valuable and then
cool.

502
00:28:41,740 --> 00:28:43,870
So then we can train this
model, right? We just, we'll,

503
00:28:43,871 --> 00:28:47,410
we'll run python model.py and
it'll start raining on our driving.

504
00:28:47,630 --> 00:28:52,330
He'll start training on our driving
logs and we want to then, uh,

505
00:28:52,390 --> 00:28:54,040
once it's training,
once it's done training,

506
00:28:54,041 --> 00:28:57,010
we're going to write our testing scripts.
So training can take a while.

507
00:28:57,130 --> 00:29:00,100
It depends on whether you're
using it on the CPU or the GPU,

508
00:29:00,101 --> 00:29:02,380
if you're running it on the
cloud or on your local machine.

509
00:29:02,590 --> 00:29:05,890
But training can take a while and we can
definitely speed it up by running it on

510
00:29:05,891 --> 00:29:09,550
the GPU. I read this thing on my Mac book
and it took about eight hours to train.

511
00:29:09,790 --> 00:29:14,020
So yeah, it all depends on what kind
of specification you have. Right?

512
00:29:14,200 --> 00:29:16,810
So once we've, so assume that
we've trained it, it could,

513
00:29:16,830 --> 00:29:18,730
it's going to take hours
and hours to train.

514
00:29:18,850 --> 00:29:21,130
So we're not going to train it right now,
but as soon we've trained it,

515
00:29:21,340 --> 00:29:24,940
then we can write our testing script.
Okay, so let's go to our testing code.

516
00:29:25,470 --> 00:29:28,540
So let's check this out. So let's,
let's check out our testing code.

517
00:29:28,720 --> 00:29:31,570
So for our testing code,
remember it is a server client model.

518
00:29:31,630 --> 00:29:32,231
That's what we're using.

519
00:29:32,231 --> 00:29:36,300
We're using a server client model
and that means that the uh, the,

520
00:29:36,390 --> 00:29:41,390
that the simulator is the server and
then our client is then script that we're

521
00:29:41,801 --> 00:29:45,370
writing. So we want to think
of it like a thing of it,

522
00:29:45,371 --> 00:29:47,890
like a server client models.
We're going to use flasks to do this,

523
00:29:47,891 --> 00:29:48,880
the web app framework.

524
00:29:49,240 --> 00:29:51,670
So let me talk about the dependencies
and then we'll talk about the code.

525
00:29:51,850 --> 00:29:54,520
So the first thing I want to do is
to find our command line arguments.

526
00:29:54,760 --> 00:29:58,110
Base 64 is going to help us to code
camera images. They time for, uh,

527
00:29:58,150 --> 00:30:02,590
for timestamps. Uh, what else? We
got high level file operations.

528
00:30:02,620 --> 00:30:06,820
Socket io is going to help us work work
with this as a real time server in terms

529
00:30:06,821 --> 00:30:09,370
of piping commands through event handlers.

530
00:30:09,600 --> 00:30:13,870
We're going to use a vent lid
for concurrent networking.
Uh, and then we have uh,

531
00:30:13,930 --> 00:30:18,930
more web framework dependencies and then
image manipulation with pillow flats

532
00:30:19,691 --> 00:30:21,130
because our web framework and then bites,

533
00:30:21,131 --> 00:30:24,460
I have to deal with input output and
of course care os it's just a load our

534
00:30:24,461 --> 00:30:28,270
model and our help class. Okay. So we'll
start off by initializing our server.

535
00:30:28,271 --> 00:30:28,930
Okay.

536
00:30:28,930 --> 00:30:33,610
It's going to be a socket io server
and it's going to use flask to do this.

537
00:30:33,790 --> 00:30:37,150
And we'll initialize our model and imagery
as empty because we're going to fill

538
00:30:37,151 --> 00:30:38,830
those as we later on.

539
00:30:39,310 --> 00:30:42,360
And then we're going to set a Max and
mins feed for our autonomous cars.

540
00:30:42,361 --> 00:30:46,210
So it can't go faster than 25 miles an
hour and it can't go less than 10 miles

541
00:30:46,211 --> 00:30:49,330
an hour. Uh, and then it's what we're
going to define a speed limit as well.

542
00:30:49,340 --> 00:30:51,370
What are you going to
be at Max? Speed. Okay.

543
00:30:51,371 --> 00:30:55,750
So then let me skip this function
because we're going to write it now.

544
00:30:55,751 --> 00:30:59,380
Let me talk about that. The
other functions. So let's
go into this main function.

545
00:30:59,381 --> 00:31:02,230
So these are the command line
arguments that defined, you know, what,

546
00:31:02,410 --> 00:31:05,410
where is the model and
where are the images, uh,

547
00:31:06,760 --> 00:31:09,910
that we want to wear. The images
from the runner going to be saved.

548
00:31:10,150 --> 00:31:13,390
So we'll load the model using
our load function and then,

549
00:31:13,600 --> 00:31:17,050
and we'll tell it via command line where
that model is and it's going to create

550
00:31:17,051 --> 00:31:20,680
an image folder and then it can either
record the run or not depending on how we,

551
00:31:20,890 --> 00:31:25,720
what we say. And then it's going
to launch this flask middleware,

552
00:31:25,780 --> 00:31:29,590
which is going to let our client
communicate with the server and then we're

553
00:31:29,591 --> 00:31:33,880
going to deploy it as a w s Gi
server, right? And the, that acronym,

554
00:31:33,940 --> 00:31:36,910
what was it again?
It was w Sgi.

555
00:31:38,320 --> 00:31:42,730
Let me brush up on my web, my web
stuff here. That'd be West Gi.

556
00:31:42,731 --> 00:31:46,060
It's not crud create, read, update a
web server gateway interface, right?

557
00:31:46,240 --> 00:31:51,040
We have 101 acronyms. Okay.
So what these functions are,

558
00:31:51,160 --> 00:31:55,750
are, these are event handlers and this is
why we're using a socket io as a server

559
00:31:55,870 --> 00:31:59,800
because behind under the
hood for the simulator,

560
00:31:59,920 --> 00:32:04,660
it's got the, it's got the architecture
necessary to send commands that we need.

561
00:32:04,810 --> 00:32:07,810
We just need to create event handlers
to then accept those commands, right?

562
00:32:07,870 --> 00:32:11,050
So we don't have to code the server part,
we just have to close the client part.

563
00:32:11,051 --> 00:32:14,140
So this is really the easiest way to
get started with building a self driving

564
00:32:14,141 --> 00:32:17,200
car. This simulator that you'd ask
to be released is the easiest way.

565
00:32:17,380 --> 00:32:20,250
Obviously there's grand theft auto,
which is awesome and stuff. Uh,

566
00:32:20,500 --> 00:32:24,390
but you can only run that out if you're on
windows. And then also, you know, there,

567
00:32:24,430 --> 00:32:28,000
it's got a whole bunch of extra features
that we don't necessarily need. Um,

568
00:32:28,030 --> 00:32:29,890
but yeah, we could also do it
in grant that thought of it.

569
00:32:29,891 --> 00:32:31,300
Right now this is the easiest,

570
00:32:31,301 --> 00:32:33,670
if you're looking for the easiest way to
get started with building self driving

571
00:32:33,671 --> 00:32:38,080
cars, this is the way. Okay. So, so
we have event handlers for connects,

572
00:32:38,081 --> 00:32:42,380
which is going to just send a,
uh, the sid the session Id, uh,

573
00:32:42,381 --> 00:32:43,640
and then we've got a send control.

574
00:32:43,641 --> 00:32:46,490
We're just going to send the actual
commands that are model emits,

575
00:32:46,790 --> 00:32:51,290
but then we have the telemetry function.
And so that is going to be the,

576
00:32:51,560 --> 00:32:54,650
um, that's going to be the big
thick, the meat of our code.

577
00:32:54,651 --> 00:32:57,350
And that's what we're gonna
write out here. Okay. So
we're going to write up this,

578
00:32:57,351 --> 00:33:01,520
this part right here. So we're gonna say,
okay, so what this does is it's going to

579
00:33:03,110 --> 00:33:04,730
make the prediction and then send it.

580
00:33:04,970 --> 00:33:07,460
It's going to make the prediction of what
the steering angle is going to be and

581
00:33:07,461 --> 00:33:09,080
then we're going to send it to the server.
Okay?

582
00:33:09,230 --> 00:33:11,300
So let's go ahead and write this down.
So if data,

583
00:33:11,360 --> 00:33:14,870
so we're going to feed this in our data
and then we're going to create an if

584
00:33:14,871 --> 00:33:19,160
statement says if data. So once we
got our data as our, as our focus,

585
00:33:19,161 --> 00:33:22,280
we're going to say,
let's get the current angle of the car.

586
00:33:22,281 --> 00:33:27,230
So we'll say the steering angle. We want
the steering angle of the car. Okay,

587
00:33:27,231 --> 00:33:30,620
so that's the first variable
that we want and it's going to,

588
00:33:30,621 --> 00:33:34,160
we're going to retrieve it
from our data data frame. Okay.

589
00:33:34,161 --> 00:33:37,340
And then we want the throttle. Okay?
So remember we want these variable,

590
00:33:37,341 --> 00:33:42,170
we want these values so that we can
manipulate them and turn them into one

591
00:33:42,171 --> 00:33:45,470
single scalar value that will
tell our car where to go.

592
00:33:45,740 --> 00:33:48,260
And we want the speed and the
speed is going to be a float.

593
00:33:48,560 --> 00:33:52,370
It's going to be a float value.
And just like the rest it's going to,

594
00:33:52,371 --> 00:33:56,480
we're going to pull it from this
data frame using the Scott Key,

595
00:33:56,570 --> 00:33:59,510
which is going to be speed,
human readable Qi.

596
00:33:59,810 --> 00:34:03,440
And then we're going to get the current
image from the center of the camera for

597
00:34:03,441 --> 00:34:06,800
the center camera of the car using
pillow, right? So say image of open.

598
00:34:07,100 --> 00:34:10,010
So and then we'll use this word bites.
Io comes into play.

599
00:34:10,050 --> 00:34:15,050
This is what we're using it because we
want to convert it from a 64 this image

600
00:34:16,460 --> 00:34:20,060
into what we can read
directly into our model.

601
00:34:20,210 --> 00:34:23,660
So we'll say base 64 d
code data and then image.

602
00:34:26,910 --> 00:34:31,080
Okay. And so then we'll say, okay,
so once we have those things,

603
00:34:31,081 --> 00:34:35,940
we'll go ahead and and do some
tensor processing on this image.

604
00:34:35,941 --> 00:34:40,260
So we need to feed this image into
our network, right? So to do that,

605
00:34:41,040 --> 00:34:43,900
to do that, we're going to say, image,

606
00:34:50,040 --> 00:34:52,260
let's see what else do we
need here, image. And then

607
00:34:58,800 --> 00:34:59,730
so we're going to convert the,

608
00:34:59,780 --> 00:35:03,600
the image to an array and then we're going
to apply the preprocessing step to it.

609
00:35:03,601 --> 00:35:06,780
And then the model is going to
expect a 40 array. So that's what,

610
00:35:06,930 --> 00:35:10,920
that's what this image is going to be.
And so once we have that, then we can say,

611
00:35:11,910 --> 00:35:16,890
then we can say, uh, predict the steering
angle for the car. Give them that image.

612
00:35:16,950 --> 00:35:18,900
So we're going to say, okay, so
let's predict the steering angle.

613
00:35:18,901 --> 00:35:21,360
Using our model was a model
that predicts just one line,

614
00:35:21,630 --> 00:35:25,200
given the image and the batch
size, whichever, which is
whatever it's going to be.

615
00:35:25,201 --> 00:35:28,230
Let's just say one for this simple
example. And then once we have that,

616
00:35:28,231 --> 00:35:31,590
we're going to say, okay, so then given
the speed limit, that global value,

617
00:35:31,591 --> 00:35:32,550
they'll be initialized.

618
00:35:32,780 --> 00:35:36,570
It's greater than if the speed of the car
is greater than what we've said as our

619
00:35:36,571 --> 00:35:38,520
speed. Then change it. Say, okay,

620
00:35:38,521 --> 00:35:41,610
well the new speed limit is
going to be the men speed.

621
00:35:41,910 --> 00:35:46,500
So then that means slow down, right?
And so else if it's not, then we'll,

622
00:35:46,530 --> 00:35:49,470
then we can say the speed limit is
going to be the Max speed, right?

623
00:35:49,680 --> 00:35:52,620
So we don't want it to go faster than the
speed limit is what we're saying here.

624
00:35:53,130 --> 00:35:56,730
And once we've done that,
then we can say, okay,

625
00:35:56,731 --> 00:35:59,670
the throttles going to be
1.0 minus the steering angle.

626
00:35:59,730 --> 00:36:01,620
So this is a magic number territory.

627
00:36:01,710 --> 00:36:03,330
This is where it guessing
and checking comes in,

628
00:36:03,780 --> 00:36:07,260
what will say minus speed over speed limit

629
00:36:09,690 --> 00:36:12,210
turns to George squared.
Okay.

630
00:36:13,520 --> 00:36:15,240
And then we can send the control

631
00:36:18,180 --> 00:36:20,700
using that helper function that we defined
before using the steering angle and

632
00:36:20,701 --> 00:36:23,820
throttle. Cool. That's it
for this code. Right? So

633
00:36:26,220 --> 00:36:27,120
that's it.
We profit,

634
00:36:27,121 --> 00:36:30,270
we preprocess the image and then we fed
it into our model and then it outputs

635
00:36:30,300 --> 00:36:33,700
the the steering angle and then we
can use that to then send that control

636
00:36:33,701 --> 00:36:36,750
directly to the server. We have
the sand control function. Okay.

637
00:36:36,751 --> 00:36:38,760
And it's going to admit that as a,
as a,

638
00:36:39,690 --> 00:36:44,070
as a packet to the server and the server
will read that in. So the actual event,

639
00:36:44,520 --> 00:36:47,280
the event handling logic is,
is written by the,

640
00:36:47,850 --> 00:36:51,840
is under the hood for the simulator
and we can just send it via our client.

641
00:36:52,020 --> 00:36:54,120
That's it. Okay. So then once we had that,

642
00:36:54,150 --> 00:36:58,830
then we can compile it and it's going to
run the script just like I did right at

643
00:36:58,831 --> 00:37:00,030
the beginning. All right, so to end this,

644
00:37:00,031 --> 00:37:02,670
I'm going to answer three
questions randomly from the
youtube comments and then

645
00:37:02,671 --> 00:37:05,860
we're out of here. Okay. So the
first question is, let's see what,

646
00:37:05,861 --> 00:37:09,210
what kind of questions we got here,
how to work with multiple datasets.

647
00:37:09,240 --> 00:37:11,340
This is a great question
and it's worthy of a video,

648
00:37:11,341 --> 00:37:13,740
but essentially there are several
ways of thinking about this.

649
00:37:13,741 --> 00:37:18,030
One way is you can just combine all your
data sets into one big dataset using

650
00:37:18,031 --> 00:37:21,690
pandas. And that's what I would do.
That that's probably the best way.

651
00:37:21,691 --> 00:37:22,620
That's the cleanest way.

652
00:37:23,010 --> 00:37:25,110
But another way you could do it
is thinking about it serially.

653
00:37:25,111 --> 00:37:28,080
So you'll want to train your model on
one dataset and then train your model on

654
00:37:28,081 --> 00:37:32,070
the next Dataset. But I would, I would
just combine all your data sets into one,

655
00:37:32,250 --> 00:37:35,250
two more questions that I'm going
to read from the comments. Um,

656
00:37:36,890 --> 00:37:37,850
what else do we got here?

657
00:37:40,790 --> 00:37:44,090
How can I discover a foreign language
like Russian? Do you tell me?

658
00:37:44,270 --> 00:37:47,030
So this is for the language
translation of video.

659
00:37:47,150 --> 00:37:51,580
So discovering a language is,
um,

660
00:37:52,250 --> 00:37:55,820
quite a challenging task,
but think of it has associations.

661
00:37:55,910 --> 00:37:58,580
So as long as you have some kind of
labels and the labels could be a different

662
00:37:58,581 --> 00:37:59,001
language,

663
00:37:59,001 --> 00:38:03,350
but maybe you're trying to discover an
ancient language or discover the rules of

664
00:38:03,351 --> 00:38:06,590
some language you don't know, then as long
as you have some kind of associations,

665
00:38:06,710 --> 00:38:10,490
you can treat it as a supervised
learning problem. Okay. And, uh,

666
00:38:10,491 --> 00:38:14,240
I've got two language translation videos
and links to those in the description

667
00:38:14,241 --> 00:38:17,380
of that video. And one more question. Um,

668
00:38:18,290 --> 00:38:21,320
once you have this neural net training
can be optimized to run locally or does

669
00:38:21,321 --> 00:38:23,360
it have to be run as is every time?

670
00:38:27,210 --> 00:38:28,810
Yeah.
You can re optimize a network.

671
00:38:28,960 --> 00:38:33,160
You can use the pre trained model or you
can use your card. You can retrain it.

672
00:38:33,161 --> 00:38:34,090
Again,
it all depends.

673
00:38:34,091 --> 00:38:37,310
You can retrain it on your data or you
can use it or you can use it pretrained

674
00:38:37,320 --> 00:38:39,550
models at someone else's trend.
That's it for this session.

675
00:38:39,551 --> 00:38:42,040
Please subscribe for more
programming videos. And for now,

676
00:38:42,070 --> 00:38:45,820
I've got to go clean my kitchen,
so thanks for watching.

