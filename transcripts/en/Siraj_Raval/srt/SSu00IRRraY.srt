1
00:00:00,110 --> 00:00:02,640
Oh world. It's the Raj. In this episode,

2
00:00:02,641 --> 00:00:06,450
we're going to build a stock price
prediction graph using [inaudible] in 40

3
00:00:06,451 --> 00:00:09,300
lines of python. Have you ever
wanted to get rich quick, sir?

4
00:00:09,301 --> 00:00:10,800
My models are very profitable.

5
00:00:10,801 --> 00:00:15,570
I always retrain them to prevent
over fitting three times a week.

6
00:00:15,690 --> 00:00:19,500
Those are rookie numbers in this ragged.
Really? How often do you retrain?

7
00:00:19,520 --> 00:00:22,800
I'm going to have to work workout and
then once, right if your lunch. Oh,

8
00:00:22,830 --> 00:00:25,860
the stock market allows
you to buy and sell units.

9
00:00:25,900 --> 00:00:30,450
The ownership in a company which we call
stocks. If the company's profits go up,

10
00:00:30,540 --> 00:00:34,680
you own some of those profits. If they
go down, you lose profits with them.

11
00:00:34,710 --> 00:00:35,940
It's as simple as that.

12
00:00:35,970 --> 00:00:39,420
So if you were to buy stocks and
the right company at the right time,

13
00:00:39,540 --> 00:00:41,100
you can become rich overnight.

14
00:00:41,370 --> 00:00:45,930
Is there something we could do to predict
future stock prices given a Dataset of

15
00:00:45,931 --> 00:00:50,070
past prices?
Machine learning.

16
00:00:50,580 --> 00:00:52,830
This sounds like a data science problems,

17
00:00:52,890 --> 00:00:55,410
but according to the
efficient market hypothesis,

18
00:00:55,470 --> 00:00:57,690
the stock market is
random and unpredictable,

19
00:00:57,720 --> 00:01:01,800
but major financial firms like JP Morgan
and Goldman Sachs having been hiring

20
00:01:01,801 --> 00:01:06,510
quantitative traders for years to build
predictive models on past market data

21
00:01:06,690 --> 00:01:10,920
and you can be sure that if these firms
do have profitable models for trading,

22
00:01:11,040 --> 00:01:14,250
they are not going to share it with us.
Come at me Wall Street,

23
00:01:14,400 --> 00:01:18,030
they have no incentive to think about all
the features we could incorporate into

24
00:01:18,031 --> 00:01:22,410
a financial model. Sentiment analysis
on company opinions, past stock prices,

25
00:01:22,470 --> 00:01:26,760
sales growth, dividends, all the profits.
Warren be missed for hating on bitcoin.

26
00:01:26,820 --> 00:01:31,740
Changes in stock prices are not
completely random but very close to it.

27
00:01:31,800 --> 00:01:36,480
Good traders will use predictive models
as a tool when deciding where to invest

28
00:01:36,600 --> 00:01:40,080
and we're going to build three different
predictive models that predict the

29
00:01:40,081 --> 00:01:41,460
prices of apple stock.

30
00:01:41,550 --> 00:01:45,770
Then plot them all on a graph to compare
their results are steps we'll be doing

31
00:01:45,771 --> 00:01:50,550
staller dependencies, collect our Dataset,
right our script and analyze our graph.

32
00:01:50,610 --> 00:01:52,200
These are our four dependencies.

33
00:01:52,320 --> 00:01:56,640
CSB will allow us to read data from the
CSV file of stock prices that we later

34
00:01:56,641 --> 00:02:00,960
download. Num Py will let
us perform calculations on
our data side, can't learn.

35
00:02:00,961 --> 00:02:03,450
We'll let us build a predictive
model and map talk live.

36
00:02:03,451 --> 00:02:07,110
We'll let us plot our data points with
our models on a graph for us to analyze.

37
00:02:07,230 --> 00:02:08,400
Let's collect our data set.

38
00:02:08,520 --> 00:02:12,270
We want to list of stock prices from the
past 30 days and we can get this data

39
00:02:12,300 --> 00:02:14,490
easily from Google finance.
As you can see,

40
00:02:14,491 --> 00:02:17,970
it'd be much higher if they didn't
miss the boat on Ai. Next step,

41
00:02:18,000 --> 00:02:18,833
write our script.

42
00:02:18,870 --> 00:02:22,230
Our for dependencies are here at the
top and we'll use the given names to

43
00:02:22,231 --> 00:02:23,730
reference them throughout our code.

44
00:02:23,970 --> 00:02:27,690
One thing to note about map plot line
is that since it's a graphical library,

45
00:02:27,810 --> 00:02:30,900
it'll depend on a graphical backend
and there are several options.

46
00:02:30,960 --> 00:02:33,570
If it doesn't want apply to graph
on your machine for some reason,

47
00:02:33,630 --> 00:02:37,870
just use the switch backend option and
try out a few different possible backends.

48
00:02:38,030 --> 00:02:40,650
All right, let's start
hacking on our script. First,

49
00:02:40,710 --> 00:02:42,480
let's initialize to empty lists,

50
00:02:42,540 --> 00:02:46,170
dates and prices will then
write a function called get
data that will fill them

51
00:02:46,171 --> 00:02:47,520
both with the relevant data.

52
00:02:47,820 --> 00:02:51,680
We'll call it get data and its argument
will be the name of our stock prices CSB

53
00:02:51,690 --> 00:02:52,230
file.

54
00:02:52,230 --> 00:02:55,950
We'll use the width as blocked to open
our file and assign it to the CSV file

55
00:02:55,951 --> 00:02:57,540
variable.
The open statement.

56
00:02:57,541 --> 00:03:01,480
We'll extract the contents of our CSV
fall to read it, hence the our parameter.

57
00:03:01,540 --> 00:03:04,090
Next we'll want to create
a file reader variable,

58
00:03:04,120 --> 00:03:08,230
which the CSV module will create for
us using the reader method with our CSV

59
00:03:08,231 --> 00:03:09,370
file as the perimeter.

60
00:03:09,520 --> 00:03:13,600
This will allow us to iterate over every
row in our CSV file and we can return a

61
00:03:13,601 --> 00:03:16,090
string for each line.
Using the next method.

62
00:03:16,210 --> 00:03:19,030
We'll call the next method
first to skip the first row,

63
00:03:19,100 --> 00:03:23,080
since it's just column names.
Now for each row in our CSV file reader,

64
00:03:23,140 --> 00:03:26,410
we'll add both the date and price
values to our respective lists.

65
00:03:26,590 --> 00:03:29,710
The upenn function will allow us to
add an item to the end of our list.

66
00:03:29,860 --> 00:03:33,700
We only want the day of the
month, so we'll say get that
first column in our row,

67
00:03:33,790 --> 00:03:37,510
which is that the index zero and use
the split function to remove the dashes

68
00:03:37,511 --> 00:03:40,780
between each of those three values.
Then get that first value in the list,

69
00:03:40,870 --> 00:03:41,703
which is the day.

70
00:03:41,740 --> 00:03:45,070
We'll wrap that using the into keyword
to convert the day to an integer for

71
00:03:45,071 --> 00:03:47,980
prices will append that list
as well with the opening price,

72
00:03:48,130 --> 00:03:51,670
which is in the next column of our row
and convert that to a float to be more

73
00:03:51,671 --> 00:03:55,330
precise in our later calculations.
Okay. Not that precise.

74
00:03:55,390 --> 00:03:58,120
Well place the return statement at
the end to finish our with block.

75
00:03:58,300 --> 00:04:01,660
Let's move on to our second and last
helper function called predict price.

76
00:04:01,840 --> 00:04:03,790
To build our predictive model and graphic,

77
00:04:03,880 --> 00:04:07,420
well first use num Pi to format
our list into an end by one matrix.

78
00:04:07,450 --> 00:04:10,780
The three parameters will be the list
we want to reshape the new shape,

79
00:04:10,870 --> 00:04:13,690
which will be a one dimensional array.
The size of our dates list,

80
00:04:13,780 --> 00:04:16,600
and finally the order of elements.
Let's create three models.

81
00:04:16,630 --> 00:04:18,940
Each of them will be a type
of support vector machine.

82
00:04:19,120 --> 00:04:21,610
A support vector machine
is a linear separator.

83
00:04:21,760 --> 00:04:25,330
It takes data that's already classified
and tries to predict a set of

84
00:04:25,390 --> 00:04:29,440
unclassified data, so if we only had two
data classes, it would look like this.

85
00:04:29,530 --> 00:04:33,130
It would be the line such
that the distances from the
closest points in each of

86
00:04:33,131 --> 00:04:37,510
the two groups would be farthest away.
When we add a new data point to our graph,

87
00:04:37,600 --> 00:04:39,460
depending on which side of the line it is,

88
00:04:39,520 --> 00:04:41,800
we could classify it
accordingly with the label.

89
00:04:41,830 --> 00:04:45,850
The right now we're not predicting a
class label, so we don't need to classify.

90
00:04:46,030 --> 00:04:49,060
Instead we're predicting
the next value in a series,

91
00:04:49,120 --> 00:04:53,230
which means we want to use regression.
SVMS can be used for regression as well.

92
00:04:53,380 --> 00:04:57,790
The support vector regression is a type
of Svm that uses this space between data

93
00:04:57,791 --> 00:05:00,700
points as a margin of error
and predicts the most likely.

94
00:05:00,701 --> 00:05:03,430
Next point in a Dataset,
let's create our first model,

95
00:05:03,431 --> 00:05:05,260
a linear support vector regression.

96
00:05:05,320 --> 00:05:08,950
We'll use the spr module we imported
from psychic learn to create it and it's

97
00:05:08,951 --> 00:05:12,040
going to take three parameters.
The kernel, which is a type of Svm.

98
00:05:12,070 --> 00:05:13,180
Then our penalty parameter.

99
00:05:13,181 --> 00:05:17,350
See of the error term we want to things
when using an SVR aligned with the

100
00:05:17,351 --> 00:05:21,490
largest minimum margin and align that
correctly separates as many instances as

101
00:05:21,491 --> 00:05:23,710
possible,
but we can't always have boats.

102
00:05:23,830 --> 00:05:27,370
See determines how much we want
the ladder. Our next SVR is Paula.

103
00:05:27,371 --> 00:05:28,930
No meal in math folklore.

104
00:05:28,931 --> 00:05:32,650
The no free lunch theorem states
that there are no guarantees for one

105
00:05:32,651 --> 00:05:36,100
optimization to work better than
the other, so we'll try both. Also,

106
00:05:36,101 --> 00:05:40,120
if you work at Google, you actually do
get free lunch, so take that. Finally,

107
00:05:40,121 --> 00:05:43,090
we'll create one more SVR
using a radial basis function.

108
00:05:43,180 --> 00:05:47,230
RBF defined similarity to be the
Euclidean distance between two inputs.

109
00:05:47,260 --> 00:05:50,410
If both are right on top of each other,
then that similarity is one.

110
00:05:50,440 --> 00:05:51,760
If too far it's a zero.

111
00:05:51,790 --> 00:05:55,540
Our gamma defines how far too far it
is and let's fit or train each of our

112
00:05:55,541 --> 00:05:59,360
models on our date and price. Using
the fit method, it's time to create.

113
00:05:59,361 --> 00:06:03,380
Our graft will plot the initial data
points as black dots with the data label

114
00:06:03,381 --> 00:06:05,210
and plot each of our models as well.

115
00:06:05,270 --> 00:06:08,020
We'll use the predict method
of the SVR object in psychic.

116
00:06:08,021 --> 00:06:10,400
Learn using the dates
matrix as our parameter.

117
00:06:10,430 --> 00:06:13,370
Each will be a different color and
we'll give them a distinct label.

118
00:06:13,400 --> 00:06:17,180
We can set the x axis and the y axis
accordingly and we'll add a title and a

119
00:06:17,181 --> 00:06:18,620
legend.
The show function.

120
00:06:18,621 --> 00:06:22,160
We'll display it on the screen and want
to return the predictions from each of

121
00:06:22,161 --> 00:06:22,760
our models.

122
00:06:22,760 --> 00:06:27,020
Now we can call our get data method on
our CSV and create a variable to store

123
00:06:27,021 --> 00:06:30,320
our predicted price given our
dates and prices for this date.

124
00:06:30,470 --> 00:06:32,870
Well printout results for each
of our models to command line.

125
00:06:32,930 --> 00:06:34,130
Let's analyze our graph.

126
00:06:34,250 --> 00:06:38,240
We can see that each of our models shows
up in our graph and that the RBF model

127
00:06:38,280 --> 00:06:42,320
seems to fit our data the best so we can
use its prediction in command line to

128
00:06:42,321 --> 00:06:44,930
stack dead presidents.
So to break it down,

129
00:06:44,990 --> 00:06:48,560
the efficient market hypothesis states
that the data needed to set the prices

130
00:06:48,561 --> 00:06:51,350
for tomorrow.
Stocks only come from tomorrow,

131
00:06:51,560 --> 00:06:55,760
but well tuned machine learning models
can give us predictions that are slightly

132
00:06:55,761 --> 00:06:58,520
better than random if we use
the right data and support.

133
00:06:58,521 --> 00:07:02,300
Vector machines are a type of ml model
that can be used for both classification

134
00:07:02,360 --> 00:07:05,150
and regression to predict novel
data points. Intergraph graph.

135
00:07:05,210 --> 00:07:08,180
The winner of the coding challenge
from last week's video is victor.

136
00:07:08,200 --> 00:07:09,210
See Ronna Vic,

137
00:07:09,220 --> 00:07:12,680
you're created a system that recommends
artists to users using the last dot.

138
00:07:12,681 --> 00:07:16,700
Fm Music Dataset that asks of the week,
and the runner up is Kevin Nelson.

139
00:07:16,790 --> 00:07:18,650
He demoed his own recommender algorithm.

140
00:07:18,740 --> 00:07:22,400
The challenge for this video is to
create a financial model to predict stock

141
00:07:22,401 --> 00:07:26,990
prices with a neural network using both
price history and sentiment analysis.

142
00:07:27,050 --> 00:07:29,660
As features details are in
the code, read me, post your,

143
00:07:29,661 --> 00:07:32,540
get humbling in the comments, and I'll
announce the winner. In the next video,

144
00:07:32,600 --> 00:07:35,390
please subscribe for more
programming videos. And for now,

145
00:07:35,420 --> 00:07:38,720
I've got to predict snapchat's IPO price,
so thanks for watching.

