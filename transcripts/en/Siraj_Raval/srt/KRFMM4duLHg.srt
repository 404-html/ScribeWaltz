1
00:00:00,070 --> 00:00:03,040
Hey Peter, how's it going? Hey sarge,
how are you doing? Pretty good.

2
00:00:03,041 --> 00:00:05,410
Can I ask you 67 questions?
You sure.

3
00:00:06,460 --> 00:00:08,260
What is the culture like at UC Berkeley?

4
00:00:09,390 --> 00:00:12,660
Very supportive. Uh,
hardworking but fun culture.

5
00:00:13,080 --> 00:00:17,430
Will online learning replaced
physical learning? Well,

6
00:00:17,860 --> 00:00:21,360
um, I think it started to shift a lot
in that direction, but I personally,

7
00:00:21,370 --> 00:00:23,130
the real luck to meet the
people I'm learning from.

8
00:00:23,640 --> 00:00:27,660
What is something you miss
about where you grew up? Um,

9
00:00:29,250 --> 00:00:34,200
I'd say the food. The food? Yeah.
What time do you wake up? Um,

10
00:00:34,300 --> 00:00:38,280
it 20. What website do you
absolutely love to spend time on?

11
00:00:39,560 --> 00:00:41,370
Um,
let's see.

12
00:00:42,540 --> 00:00:45,330
I try to avoid spending too
much time on any websites.

13
00:00:46,080 --> 00:00:48,240
Machine learning paper of 2017.

14
00:00:50,030 --> 00:00:54,850
Um, I'm going to pass on
that. It seems too, too,

15
00:00:55,000 --> 00:00:59,910
too picky to meet one person. Who
would it be? Okay. I need one person.

16
00:00:59,911 --> 00:01:03,690
Who could it be? Um, Roger Federer.

17
00:01:04,380 --> 00:01:08,130
Favorite car? Uh, I prefer my bike.

18
00:01:08,340 --> 00:01:10,470
What's it like working
with physical robots?

19
00:01:12,130 --> 00:01:16,780
It's been really surprising how people
connect so strongly when they see

20
00:01:16,781 --> 00:01:19,390
physical robots do things.
I never anticipated this.

21
00:01:19,450 --> 00:01:21,370
When bringing people buy for
the first time in the lab,

22
00:01:22,030 --> 00:01:26,800
bravest thing you've ever done?
I'm not the one to take a lot of risks.

23
00:01:26,801 --> 00:01:30,680
I would say. What is one
thing that scares you? Um,

24
00:01:32,730 --> 00:01:36,310
I like to take good care of my
health, I guess. Favorite movie,

25
00:01:37,390 --> 00:01:42,060
Shawshank redemption. Do you
play any instruments? No.

26
00:01:42,760 --> 00:01:45,640
What's more interesting?
Physics or neuroscience

27
00:01:47,990 --> 00:01:51,260
call. But uh, I'm at, I've been more
inclined to study physics so far.

28
00:01:51,820 --> 00:01:53,500
Best present you've ever received.

29
00:01:59,650 --> 00:02:01,240
What is something you do to relax?

30
00:02:04,050 --> 00:02:08,490
A lot of physical exercise, running
tennis, basketball, cycling.

31
00:02:09,430 --> 00:02:11,020
What is something surprising about you

32
00:02:17,690 --> 00:02:21,400
beat that? Uh, back in high
school, my, uh, well my goal was,

33
00:02:21,401 --> 00:02:24,530
was tried to become a
professional basketball player
rather than a researcher.

34
00:02:25,410 --> 00:02:26,820
You prefer cats or dogs?

35
00:02:28,280 --> 00:02:31,490
I prefer a no pets in my house.

36
00:02:32,160 --> 00:02:34,980
Why do you like reinforcement
learning specifically? So much

37
00:02:37,230 --> 00:02:41,850
beauty of reinforcement learning is
that it kind of gets to what is kind of

38
00:02:41,851 --> 00:02:44,310
close to what you think about when
you build a real intelligence system.

39
00:02:44,311 --> 00:02:46,380
It's something that has,
tries to achieve goals,

40
00:02:46,410 --> 00:02:48,930
try to learn things about the
environments. Never done before.

41
00:02:49,290 --> 00:02:50,850
And I find that very intriguing.

42
00:02:51,620 --> 00:02:53,680
Favorite project you used to work on?

43
00:02:55,490 --> 00:02:59,980
I would say Stanford helicopter
project as a phd student and I

44
00:02:59,980 --> 00:03:04,530
think a live, it was the big pants we
went through to get to the results, um,

45
00:03:04,810 --> 00:03:07,270
which made it yet more
rewarding too to get to them.

46
00:03:07,780 --> 00:03:12,430
What project are you currently working on?
A lot of our work is,

47
00:03:12,460 --> 00:03:14,410
so there's a few things
going on at Berkeley.

48
00:03:14,620 --> 00:03:16,930
A lot of the work is on
reinforcement learning, imitation,

49
00:03:16,931 --> 00:03:17,920
learning metal learning.

50
00:03:18,310 --> 00:03:22,150
I'd embodied intelligence with trying
to put this into practice and get real

51
00:03:22,151 --> 00:03:25,960
robots in the real world to do these
things. And then I have great scope.

52
00:03:25,961 --> 00:03:27,190
We're trying to do it now.

53
00:03:27,280 --> 00:03:30,460
Ai for grading automatically grade
your homework and exams are largely

54
00:03:30,461 --> 00:03:34,060
automatically grade them to uh,
let teachers spend time on other things.

55
00:03:34,560 --> 00:03:37,710
If you could repeat one experience again,
what would it be?

56
00:03:40,390 --> 00:03:42,360
Speed one experience again.
What would it be?

57
00:03:45,460 --> 00:03:46,500
I'll pass on that for now.

58
00:03:47,160 --> 00:03:50,010
Why do you think deep learning
has gotten so popular recently?

59
00:03:52,090 --> 00:03:52,800
I think it's,

60
00:03:52,800 --> 00:03:57,730
it's getting really good results on
problems that people just weren't able to

61
00:03:57,731 --> 00:04:00,820
get the same results on. Think
computer vision, speech recognition,

62
00:04:01,120 --> 00:04:04,540
learning to peer that play video games,
learning to control robots, prompts.

63
00:04:04,541 --> 00:04:08,170
I seemed out of reach for a very long
time and now there's a real tangible

64
00:04:08,171 --> 00:04:10,470
progress.
What's your favorite operating

65
00:04:10,510 --> 00:04:15,390
system? Macro s for me.
Do you play any sports?

66
00:04:16,420 --> 00:04:19,140
Um, they'll play it. I tried to

67
00:04:19,220 --> 00:04:23,300
play a lot of sports. My favorite ones
are tennis, basketball and a running.

68
00:04:24,150 --> 00:04:28,070
What one source you use to stay
up to date in machine learning?

69
00:04:29,600 --> 00:04:33,770
Um, definitely archive
is uh, critical. Uh,

70
00:04:33,780 --> 00:04:37,950
and then newsfeeds, like her
party's archive, sanity preserver.

71
00:04:37,970 --> 00:04:41,300
And also on Twitter. I follow a lot of
people that poster papers on Twitter.

72
00:04:41,660 --> 00:04:46,130
What's one? And they'll research or
you fall in Twitter? Just a random one.

73
00:04:47,030 --> 00:04:51,170
Jeff Dean programming.
Language of choice for machine.

74
00:04:53,170 --> 00:04:57,890
I should admit that as a professor
I don't write a lot of code. Um,

75
00:04:58,130 --> 00:05:01,220
so it's mostly my students who,
who write the code.

76
00:05:01,221 --> 00:05:05,740
So I don't really have a preference here.
Favorite professor? Harris professor? No,

77
00:05:05,780 --> 00:05:09,980
I'll go with my phd advisor. Android.
Why do you think programming is fun?

78
00:05:11,460 --> 00:05:15,130
You think programming is fun because in
a very short amount of time you can do

79
00:05:15,150 --> 00:05:18,170
very powerful things compared to any
other engineering discipline where

80
00:05:18,171 --> 00:05:22,220
typically it takes days, weeks, months
to build something and programming.

81
00:05:22,221 --> 00:05:25,160
You can build something in an
hour that actually does something.

82
00:05:25,680 --> 00:05:29,750
Last person you talked to on the phone?
I'm

83
00:05:31,960 --> 00:05:36,840
not sure. Yeah. You get an all
expenses paid trip to one country.

84
00:05:36,841 --> 00:05:39,990
Where do you go?
Australia.

85
00:05:41,420 --> 00:05:45,810
Would you live on Mars?
It depends on who comes along with me.

86
00:05:46,230 --> 00:05:50,970
What's one thing you can't live without?
Exercise.

87
00:05:51,390 --> 00:05:53,160
What is one skill you wished you had?

88
00:05:58,730 --> 00:06:01,760
Have time to polish more programming
skills which have not finding time for

89
00:06:01,790 --> 00:06:05,810
anymore. What is the law? What is
usually the last thing you do before bed?

90
00:06:07,550 --> 00:06:12,550
I do a few dedicated stretches
and breathing exercises
that get me into sleeping

91
00:06:13,671 --> 00:06:16,460
mode.
What texts editor do you use?

92
00:06:18,680 --> 00:06:20,930
I use sublime.
Sublime.

93
00:06:21,860 --> 00:06:24,010
What open source library
do you really like?

94
00:06:26,760 --> 00:06:27,550
Okay.

95
00:06:27,550 --> 00:06:29,110
Personally,
don't use them myself,

96
00:06:29,111 --> 00:06:32,620
but I know my group benefits a
lot from tensorflow and Pi Torch.

97
00:06:33,070 --> 00:06:35,380
What was a hard problem
your team recently solved?

98
00:06:37,400 --> 00:06:38,233
MMM,

99
00:06:41,720 --> 00:06:44,030
super. Recently. Those
results are not public yet,

100
00:06:44,720 --> 00:06:46,760
but there'll be a couple of
papers coming out that it will be,

101
00:06:46,820 --> 00:06:49,940
I'm very excited about of
things that are already public.

102
00:06:50,600 --> 00:06:55,600
I would say the one shot visual limitation
where work led by Chelsea Finn where

103
00:06:56,781 --> 00:07:01,250
we're able to learn from videos of
humans showing how to do something rather

104
00:07:01,251 --> 00:07:04,430
than from tell operating robots
and the robot can learn from that.

105
00:07:05,690 --> 00:07:07,670
What's the goal for embodied.ai?

106
00:07:08,630 --> 00:07:13,460
Our goal is our longterm goal is
essentially make physical goods as readily

107
00:07:13,461 --> 00:07:18,200
available and as cheaply available as
digital goods by making manufacturing and

108
00:07:18,201 --> 00:07:22,820
logistics extremely,
extremely streamlined, best
advice you've ever received.

109
00:07:24,010 --> 00:07:26,660
Um,
let's see.

110
00:07:33,130 --> 00:07:34,860
Maybe I wouldn't say explicit advice,

111
00:07:34,861 --> 00:07:38,280
but I think maybe what our hold
the closest to my heart as a,

112
00:07:38,340 --> 00:07:41,820
what I've seen from being
Andrex phd students is, um,

113
00:07:42,780 --> 00:07:47,060
how kindness is always in everything
he's doing and how, you know,

114
00:07:47,130 --> 00:07:49,770
that is just a really important
value and no matter, you know,

115
00:07:49,771 --> 00:07:50,880
what you're trying to achieve.

116
00:07:51,630 --> 00:07:54,480
What's one piece of advice you'd
give yourself 20 years ago?

117
00:07:57,430 --> 00:07:59,250
Um,
that's all

118
00:08:04,580 --> 00:08:06,380
pretty happy with how things have gone.

119
00:08:06,410 --> 00:08:10,540
I don't think I would give myself any
other advice and that I think not,

120
00:08:10,580 --> 00:08:12,800
I'm not saying I went down the
shortest path and everything,

121
00:08:12,801 --> 00:08:16,100
but I think sometimes going down a path
that ends and having to restart is not

122
00:08:16,101 --> 00:08:19,520
about thing you spend more time
on the internet is or real life.

123
00:08:21,230 --> 00:08:26,230
I spend most of my time
I'm behind the computer,

124
00:08:26,960 --> 00:08:31,220
uh, and as a way to essentially
communicate about research
with my collaborators.

125
00:08:32,060 --> 00:08:34,010
What's something you've
learned in the past month?

126
00:08:39,570 --> 00:08:42,590
MMM,
I would

127
00:08:42,590 --> 00:08:46,070
say what I've heard in the last month is
that I have not found any time to read

128
00:08:46,071 --> 00:08:49,760
any papers in. I need to change
that. If you ran the world,

129
00:08:49,761 --> 00:08:54,080
what is one light you didn't
enact immediately? If it
worked? The rule the world?

130
00:08:54,081 --> 00:08:56,740
Is that what you said? Wow.
What a hypothetical. Um,

131
00:08:59,220 --> 00:09:04,070
I think it's really complicated too to put
things in place. But I think, you know,

132
00:09:04,170 --> 00:09:05,370
if just in general people,

133
00:09:05,790 --> 00:09:09,030
if we could somehow find a way for people
to be more kind of just generally kind

134
00:09:09,031 --> 00:09:09,841
and everything they do,

135
00:09:09,841 --> 00:09:13,240
I think a lot of problems would be
resolved in the singularity near

136
00:09:15,810 --> 00:09:20,340
not sure what's near, but uh, I guess
given we started embodied intelligence,

137
00:09:20,341 --> 00:09:21,420
we think there is still,
you know,

138
00:09:21,421 --> 00:09:26,340
a lot to be done with regular AI
before the singularity will take over.

139
00:09:26,550 --> 00:09:28,140
If you were to start from scratch today,

140
00:09:28,170 --> 00:09:30,870
what is he learning resource you
would use to learn machine learning?

141
00:09:33,150 --> 00:09:36,110
Yeah, so it's a couple of
things I would use. I would um,

142
00:09:36,530 --> 00:09:39,290
look had the faster they
AI to learn a few things.

143
00:09:39,291 --> 00:09:44,090
From there I would look had Andrew Rinks,
uh,

144
00:09:44,150 --> 00:09:45,740
deep learning AI course.

145
00:09:45,741 --> 00:09:50,360
I would look at [inaudible] d planning
course and then I would look at the

146
00:09:50,361 --> 00:09:54,980
deeper El bootcamp that we built last
summer and also surrogate Levin's deep

147
00:09:54,981 --> 00:09:56,210
reinforced planning course.

148
00:09:56,480 --> 00:10:00,080
And all of those are available on line
so anybody can start working with those

149
00:10:00,350 --> 00:10:04,360
favorite subject in school.
When you were growing up cause x,

150
00:10:04,880 --> 00:10:06,650
if you could be a superhero,
who would it be?

151
00:10:10,210 --> 00:10:11,043
Yeah,

152
00:10:12,290 --> 00:10:15,160
I guess I,
in fact if I could be a superhero,

153
00:10:15,170 --> 00:10:17,010
I'm not too familiar
with most superhero sell.

154
00:10:17,060 --> 00:10:19,850
Maybe I'll pick a real world person and
I'd like to be somebody who really mix a

155
00:10:19,851 --> 00:10:20,481
lot of difference.

156
00:10:20,481 --> 00:10:25,481
So I think the way Elon Musk is tackling
things like climate change bottom up by

157
00:10:25,611 --> 00:10:28,730
building companies that can really make
a change. I find that really inspiring.

158
00:10:29,060 --> 00:10:32,220
What's your spirit animal?
A Koala?

159
00:10:32,990 --> 00:10:35,450
What do you predict comes next
after the deep learning hype?

160
00:10:40,390 --> 00:10:40,900
Okay.

161
00:10:40,900 --> 00:10:45,900
I think what we've seen with deep learning
is at the essence leverage the things

162
00:10:46,151 --> 00:10:49,780
that are today available that you didn't
have before. More data, more compute.

163
00:10:50,200 --> 00:10:54,220
And so I see a trend where we'll continue
to have more data and more compute.

164
00:10:54,280 --> 00:10:58,420
So if anything comes about
that can leverage even better,
more data, more compute,

165
00:10:58,450 --> 00:11:00,670
maybe metal learning if you consider
it separate from deep learning.

166
00:11:00,671 --> 00:11:01,600
But I think it's part of it.

167
00:11:01,900 --> 00:11:05,800
But anything that really leveraged to
the latest resources that are available.

168
00:11:06,610 --> 00:11:10,540
But more questions, coffee or
tea, tea, summer or winter,

169
00:11:11,170 --> 00:11:13,720
summer,
Google home or Amazon Alexa.

170
00:11:14,680 --> 00:11:18,040
I always switch both of
them off chrome or safari,

171
00:11:19,510 --> 00:11:22,000
chrome, WWDC or Google. Io.

172
00:11:23,860 --> 00:11:28,270
None of them are are the rights or
rights for me, nips and I clear. Awesome.

173
00:11:28,690 --> 00:11:32,140
All right, Peter, that's it
for my questions. Thanks so
much for answering those.

174
00:11:32,590 --> 00:11:34,260
Sure. Thanks, Sarah. Have a good one.

