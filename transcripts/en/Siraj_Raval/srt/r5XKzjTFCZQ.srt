1
00:00:07,210 --> 00:00:10,570
Hello, we're old. It's Haraj.
And welcome to this live session.

2
00:00:10,571 --> 00:00:15,130
Today we're going to be talking about
the differentiable neural computer.

3
00:00:15,390 --> 00:00:19,510
Just, I mean, just take a second to just
soak in how awesome that name is. I mean,

4
00:00:19,511 --> 00:00:22,170
this is, this is a really,
really cool model. It,

5
00:00:22,171 --> 00:00:27,171
it came out of deep mind a few months
ago and it is the successor to the neural

6
00:00:27,341 --> 00:00:30,760
Turing machine.
So recall from my last weekly video,

7
00:00:30,761 --> 00:00:35,500
we talked about metal learning or learning
to learn the edge of deep learning

8
00:00:35,520 --> 00:00:39,760
and, and future directions that
we should move. So this is like,

9
00:00:40,240 --> 00:00:44,210
this is a relatively complex model.
Uh,

10
00:00:44,420 --> 00:00:48,460
and it's definitely the coolest
model that I've ever seen and I've,

11
00:00:48,700 --> 00:00:52,000
I've really had a lot of, it was,
it was really fun studying this,

12
00:00:52,001 --> 00:00:55,590
this thing because it gave me so many
ideas of directions we should move and

13
00:00:55,600 --> 00:00:59,020
things we can do with this.
But let's talk about the problem here.

14
00:00:59,260 --> 00:01:04,120
And the problem is how do we create
more general purpose learning machines?

15
00:01:04,510 --> 00:01:08,950
And that was the problem with which they
designed this, this, uh, this model. Okay.

16
00:01:09,220 --> 00:01:14,220
So I'm going to show you guys what the
demo is for this and I'm going to then

17
00:01:15,430 --> 00:01:19,000
talk about what other things we
could do with this. But before we,

18
00:01:19,030 --> 00:01:22,840
before we do that, let me answer
some questions. All right,

19
00:01:24,190 --> 00:01:25,690
so to start off with,

20
00:01:25,750 --> 00:01:29,410
go ahead and ask some questions while
I explain a little bit more about this.

21
00:01:29,411 --> 00:01:33,640
Okay. And then I'll look back at
questions through slack. Okay. So

22
00:01:35,440 --> 00:01:37,350
neural networks are great, right? We've,

23
00:01:37,351 --> 00:01:39,760
we do a bunch of amazing
things with that with them.

24
00:01:39,761 --> 00:01:42,580
But the problem with neural networks are,

25
00:01:42,640 --> 00:01:47,640
are that they are made to focus on a
single task or whatever you train it on,

26
00:01:48,521 --> 00:01:51,810
right? You can take a neural network
and you can train it to, you know,

27
00:01:51,820 --> 00:01:54,340
learn to recognize cat,
you know, cats in images,

28
00:01:54,341 --> 00:01:58,480
but then you can't take that same neural
network and then ask it questions about

29
00:01:58,510 --> 00:02:03,490
the London subway or the best path to
take, uh, two from point a to point B.

30
00:02:03,520 --> 00:02:06,220
You just can't do that.
But what if you could,

31
00:02:06,490 --> 00:02:10,270
and how would you design a system
like that? So that is what the DNC is,

32
00:02:10,271 --> 00:02:11,500
is it is,

33
00:02:11,920 --> 00:02:16,390
it is a neural network with an
external memory store. So it's,

34
00:02:16,930 --> 00:02:19,390
so it's got two parts.
You've got the controller,

35
00:02:19,420 --> 00:02:22,120
which is a normal neural network.
You could use a feed forward net,

36
00:02:22,121 --> 00:02:25,570
you could use recurrent net, you could
use any kind of network you want.

37
00:02:25,780 --> 00:02:27,160
And in this thing,
this example,

38
00:02:27,161 --> 00:02:29,050
we're gonna be using a feed
forward neural network.

39
00:02:29,320 --> 00:02:33,640
And then you've got the memory bank and
the memory bank is an external matrix

40
00:02:33,820 --> 00:02:37,810
and the controller interacts
with the memory bank by,

41
00:02:38,080 --> 00:02:42,070
by performing a series of
read and write operations.

42
00:02:42,100 --> 00:02:44,410
So we call these heads,
we end right heads.

43
00:02:44,590 --> 00:02:49,180
So it takes an input it up, it, it
propagates it through the network.

44
00:02:49,330 --> 00:02:54,190
And simultaneously it's reading and
writing to the matrix to learn about,

45
00:02:54,490 --> 00:02:59,380
to both, right, what it's learned and
then read from the past time steps, what,

46
00:02:59,470 --> 00:03:02,050
what it can use to then
make the output prediction.

47
00:03:02,290 --> 00:03:06,190
And then it outputs the prediction,
right? So that's the basic idea.

48
00:03:06,910 --> 00:03:10,420
And what we're going to do in
this example is we're going to,

49
00:03:10,930 --> 00:03:12,550
let me see if I have the output somewhere.

50
00:03:14,320 --> 00:03:18,460
The output is to basically map.
So here's the output.

51
00:03:19,270 --> 00:03:23,200
I know you guys like seeing the output,
which is a definitely a good thing.

52
00:03:23,800 --> 00:03:27,100
And so here's what it
looks like when I ran this.

53
00:03:27,910 --> 00:03:32,350
We have two sets of numbers, right?
Zero is just one hot and coded vectors.

54
00:03:32,351 --> 00:03:34,750
So zero one zero, zero,
zero that's the input.

55
00:03:34,900 --> 00:03:36,220
And then one zero zero zero one zero,

56
00:03:36,221 --> 00:03:38,710
zero and then we want to learn
the mapping between the two.

57
00:03:38,770 --> 00:03:41,200
So then given some input,
we'll know the output, right?

58
00:03:41,201 --> 00:03:44,680
So it's just binary mapping,
which is a very simple use case,

59
00:03:44,681 --> 00:03:48,280
which is what we need for this model
because the model itself is where the

60
00:03:48,281 --> 00:03:51,280
learning should occur.
But let me show you what they used it for,

61
00:03:51,281 --> 00:03:54,880
which what deepmind use it for.
Okay, so this is what it looks like.

62
00:03:54,881 --> 00:03:58,030
So you have your inputs and your outputs
and it learns the mapping between the

63
00:03:58,031 --> 00:03:59,740
two, right? [inaudible] right. We,

64
00:03:59,750 --> 00:04:02,140
that would in my build a neural
net in four minutes video,

65
00:04:02,200 --> 00:04:05,950
same exact idea except a
way more amazing model.

66
00:04:06,160 --> 00:04:08,890
So what they did,
and let's talk about what they did first.

67
00:04:09,430 --> 00:04:11,500
What deepmind did is they said,
okay,

68
00:04:12,820 --> 00:04:16,240
let's apply this to the
London Underground. Okay.

69
00:04:16,420 --> 00:04:19,180
And right.
So the questions are coming in.

70
00:04:19,181 --> 00:04:22,040
So let me answer two questions
and then let me go back to what,

71
00:04:22,240 --> 00:04:24,250
what I was just talking about.
Question number one,

72
00:04:24,490 --> 00:04:28,180
does it learn and predict
the hyper parameters? No. Uh,

73
00:04:28,810 --> 00:04:33,280
that that is hyper parameter optimization
and it can be added onto this.

74
00:04:33,520 --> 00:04:35,710
And the second question is,
uh,

75
00:04:36,430 --> 00:04:41,350
can we do image recognition
with this? Yes. Oh,

76
00:04:41,351 --> 00:04:42,161
and then one more question.

77
00:04:42,161 --> 00:04:44,380
What's the difference between
this and the neural train machine?

78
00:04:44,381 --> 00:04:46,780
I'll get right to that in a
second. Okay. So back to this,

79
00:04:47,050 --> 00:04:50,250
what they did was they applied it to
the London Underground. Okay? So what,

80
00:04:50,270 --> 00:04:51,250
what do I mean by this?

81
00:04:51,490 --> 00:04:54,670
Basically the first thing they did was
they generated all these like random

82
00:04:54,671 --> 00:04:57,550
graphs, right? This is a graph
problem. It's a graph problem, right?

83
00:04:57,610 --> 00:05:01,000
Subway systems are all graphs. They
have nodes. And they're all connected.

84
00:05:01,300 --> 00:05:05,830
And what they did was they gave it
a set of graphs and they had these

85
00:05:05,880 --> 00:05:09,280
handcrafted, uh, inputs,
right? So they would say,

86
00:05:09,281 --> 00:05:13,810
so this graph resembled some generated
subway and then it had a set of labels.

87
00:05:13,811 --> 00:05:16,750
So it was a supervised learning problem,
right?

88
00:05:16,751 --> 00:05:20,950
So they had this generated graph or
subway and then it's associated labels.

89
00:05:21,220 --> 00:05:26,220
And the labels would be that the different
paths that you could take from point

90
00:05:26,261 --> 00:05:30,340
a to point B. So you could go through
Oxford circus and taught them hands,

91
00:05:30,370 --> 00:05:34,790
whatever, and in central whatever. So
that's what they did. And then one,

92
00:05:34,820 --> 00:05:37,450
once they kept training it on
these randomly generated graphs,

93
00:05:37,630 --> 00:05:39,970
then they gave it the
actual London Underground,

94
00:05:40,230 --> 00:05:44,500
a graph with its associated pairs.
And it learned to then if you,

95
00:05:44,530 --> 00:05:48,610
if you asked if you, if
you then said, you know,

96
00:05:48,611 --> 00:05:51,100
two points like point a and point B,

97
00:05:51,280 --> 00:05:55,660
it would tell you the optimal path to
get there because it had been training on

98
00:05:55,661 --> 00:05:59,210
that. But here's where it gets even. So
Norman, so you could, you could do that.

99
00:05:59,211 --> 00:06:02,300
Normally you, you wouldn't need an
external memory store to do that.

100
00:06:02,301 --> 00:06:05,480
You could do that with a recurrent
network and LSTM network.

101
00:06:05,810 --> 00:06:09,290
But what was really cool then was
they added something else onto this.

102
00:06:09,440 --> 00:06:11,690
They added a question answering system.

103
00:06:11,870 --> 00:06:16,130
So not only did they train it on
the London Underground's paths,

104
00:06:16,280 --> 00:06:18,920
but they also added a
natural language to it.

105
00:06:18,921 --> 00:06:22,160
So they train at first on
randomly generated graphs,

106
00:06:22,400 --> 00:06:25,100
then they train it on a
text database where the,

107
00:06:25,250 --> 00:06:28,070
where it was a question answer database,
um,

108
00:06:28,130 --> 00:06:33,130
and it learned to associate a questions
with what they're associated answers and

109
00:06:33,681 --> 00:06:38,420
then an associated both. So then you
could then ask it, hey, we, you know,

110
00:06:38,421 --> 00:06:41,660
in natural language, like a
query, what's the best place to,

111
00:06:41,960 --> 00:06:45,140
what's the best way to get from point
a to point B in natural language?

112
00:06:45,320 --> 00:06:49,280
And then because it had this external
memory store that had the previous

113
00:06:49,281 --> 00:06:50,570
learnings from the generator graph,

114
00:06:50,810 --> 00:06:53,750
it could then apply those to
the natural language questions.

115
00:06:53,900 --> 00:06:56,660
So you see these two entirely
different data types,

116
00:06:56,780 --> 00:07:00,590
these two entirely different datasets
that this thing was able to train on.

117
00:07:00,830 --> 00:07:05,150
So it w it learned to optimize for one
dataset and then it learns to optimize

118
00:07:05,151 --> 00:07:08,420
for the next dataset and it
could associate between the two,

119
00:07:08,840 --> 00:07:10,340
which is the cool part.

120
00:07:10,640 --> 00:07:15,200
And you could then extrapolate this
kind of thinking to anything really.

121
00:07:15,201 --> 00:07:18,950
You could train it on some set of
images and their associated labels.

122
00:07:19,160 --> 00:07:22,850
And then something entirely
unrelated like you know, uh,

123
00:07:22,851 --> 00:07:24,700
also a question to answer dataset.

124
00:07:24,710 --> 00:07:28,850
So you could learn natural language and
then also maybe an audio data set so it

125
00:07:28,851 --> 00:07:32,930
could learn the labels for audio. So
then you could ask it things like, hey,

126
00:07:32,931 --> 00:07:36,560
what kind of sound does this cap make?

127
00:07:36,680 --> 00:07:39,760
So it would see the cat picture and then
it would associate a sound with it and

128
00:07:39,780 --> 00:07:43,610
it's got the language.
So it's like this general purpose idea.

129
00:07:43,760 --> 00:07:47,990
Now it's not perfect, it's not Agi,
but it's a step in that direction,

130
00:07:48,200 --> 00:07:51,380
which is very cool. And they
called it a computer, right?

131
00:07:51,381 --> 00:07:55,850
Why do they call it a computer? Will
recall that computers, computers are,

132
00:07:56,240 --> 00:08:00,440
they have two parts. They have a processor
and then they have memory, right?

133
00:08:00,441 --> 00:08:03,320
You have your CPU and then you've
got ram random access memory.

134
00:08:03,530 --> 00:08:07,030
And so what happens little, you know,
colonel level talk for a second. What,

135
00:08:07,031 --> 00:08:08,630
what's happening at the kernel level.

136
00:08:08,631 --> 00:08:13,631
Every time you're doing anything
on the computer is you the,

137
00:08:14,220 --> 00:08:17,060
the Ram preloads a bunch of instructions.

138
00:08:17,240 --> 00:08:21,830
And then each instruction is fed
to the CPU a one step at a time.

139
00:08:21,890 --> 00:08:26,510
And what the CPU does is it takes in an
instruction, decodes it, executes it,

140
00:08:26,570 --> 00:08:30,950
and then repeats the process. And this
process is called the instruction cycle.

141
00:08:31,160 --> 00:08:35,060
And it is the hallmark of how computing
works, right? And then there's the GPU,

142
00:08:35,061 --> 00:08:37,760
but that's a different story.
We're talking about the CPU. Now,

143
00:08:37,860 --> 00:08:42,350
von Neumann architecture and computer
science was his very famous, right?

144
00:08:42,351 --> 00:08:45,980
And a lot of computing is based
off of that idea. But what this is,

145
00:08:45,981 --> 00:08:49,880
and now this is not deep mind talking.
This is Saroj talking. Uh, or this is,

146
00:08:49,910 --> 00:08:53,480
this is my, this is, this is
my w what, what should happen?

147
00:08:54,290 --> 00:08:59,200
We can use this as a framework for
building hardware as well, right? So it's,

148
00:08:59,201 --> 00:09:01,470
it's a computer, but it's,
it's, it's all software.

149
00:09:01,471 --> 00:09:03,810
There's no hardware associated with it.
But if we,

150
00:09:03,900 --> 00:09:07,320
if we switch our thinking from serially,
uh,

151
00:09:07,680 --> 00:09:12,680
decoding these instructions and instead
learning from instructions at the kernel

152
00:09:13,171 --> 00:09:16,650
level, at the hardware level, then we
can get some really interesting results.

153
00:09:16,680 --> 00:09:18,810
Now there are people working on this,
uh,

154
00:09:18,840 --> 00:09:21,060
but I think it's really cool
to think about what the next,

155
00:09:21,180 --> 00:09:25,620
the successor to both von Neumann
architecture is and also the successor to

156
00:09:25,710 --> 00:09:29,160
silicon and what new mediums we
could use for computing could be.

157
00:09:29,490 --> 00:09:34,170
So it's a lot of very exciting possibility
with just this, uh, architecture,

158
00:09:34,171 --> 00:09:35,550
the software architecture.
Okay.

159
00:09:36,030 --> 00:09:38,220
And let me show you guys one
more thing that they did.

160
00:09:39,030 --> 00:09:44,030
So to keep going with this idea of
associating to different data types.

161
00:09:44,880 --> 00:09:46,710
So they first fed this thing,

162
00:09:51,320 --> 00:09:55,370
they first fed it, some associations
like Joe is a mother, a freer, you know,

163
00:09:55,371 --> 00:09:58,100
Bob is a mother or a Ba.
Ba is a husband and Bert.

164
00:09:58,101 --> 00:10:02,930
So a bunch of different associations. So
natural language, texts, associations.

165
00:10:03,380 --> 00:10:07,190
Okay. And then once it had those
associations, 49 inputs later,

166
00:10:07,640 --> 00:10:11,360
then you could say things like,
who is fray as maternal great uncle.

167
00:10:11,480 --> 00:10:14,780
And because it's,
it's a graph problem.

168
00:10:14,870 --> 00:10:17,960
It took this natural language and
it constructed a graph out of it,

169
00:10:18,170 --> 00:10:19,340
then it's just a graph problem,
right?

170
00:10:19,341 --> 00:10:23,690
You can just traverse the graph to find
who Frey as maternal great uncle is,

171
00:10:23,810 --> 00:10:28,460
even though we didn't explicitly tell it,
who would that uncle was. Okay. So there,

172
00:10:28,760 --> 00:10:31,820
it can do multiple things,
right? It's not just language,

173
00:10:32,000 --> 00:10:36,860
it's also a graph construction. And the
fact that it's using an external, uh,

174
00:10:37,340 --> 00:10:40,460
David structure for memory. It's such
a simple concept isn't it? I mean,

175
00:10:40,461 --> 00:10:43,550
if you think about it, it's one of
those intuitive things like Duh,

176
00:10:43,910 --> 00:10:46,160
like of course there should
be an external memory store,

177
00:10:46,280 --> 00:10:48,800
but just no one tried it
before. I mean, you know,

178
00:10:48,890 --> 00:10:51,440
we did have the dynamic memory
network out of Facebook.

179
00:10:51,680 --> 00:10:53,840
We didn't have the neural Turing
machine by deep mine. But this is,

180
00:10:54,020 --> 00:10:55,640
this is a really cool idea.
That's what I'm trying to say.

181
00:10:55,670 --> 00:10:57,380
This is a really cool idea and

182
00:10:58,010 --> 00:10:58,843
okay.

183
00:10:59,730 --> 00:11:03,090
Yeah. So that's what they did.

184
00:11:03,120 --> 00:11:06,090
And we've got an also neural networks.

185
00:11:07,110 --> 00:11:09,510
Neural networks have memory,
right? They have memory,

186
00:11:09,720 --> 00:11:13,590
but the memory is so interpolated
with the memory are the weights.

187
00:11:13,800 --> 00:11:15,990
It's interpolated with the processing you.

188
00:11:16,350 --> 00:11:18,900
But if we detach the memory
into a separate component,

189
00:11:19,170 --> 00:11:21,570
that's when the results start
to get magical. And that's what,

190
00:11:21,571 --> 00:11:24,180
that's what this is. Okay. Oh,
and here's the coolest part.

191
00:11:24,240 --> 00:11:28,020
So the whole system is
differentiable. Okay. So the
whole thing is differentiable.

192
00:11:28,140 --> 00:11:31,580
What do I mean by that? That means,
you know, when we differentiate or, uh,

193
00:11:31,650 --> 00:11:35,430
back propagate our net, our
neural networks, we for propagate.

194
00:11:35,580 --> 00:11:38,160
And then we take the difference
between the output and the prediction.

195
00:11:38,790 --> 00:11:40,290
That's our error or loss.

196
00:11:40,380 --> 00:11:43,410
And then we use that loss to compute the
partial derivative with respect to each

197
00:11:43,411 --> 00:11:46,560
of the weights backwards.
And then we continually do that.

198
00:11:46,561 --> 00:11:49,560
And that's how we update our network.
But, and that's how we differentiate.

199
00:11:49,770 --> 00:11:53,040
But this whole thing is differentiable.
So it's not just the controller,

200
00:11:53,060 --> 00:11:57,250
the network, but it's also
the, it's also the memory

201
00:11:58,780 --> 00:12:01,210
memory store.
So this thing is differentiable too.

202
00:12:01,211 --> 00:12:04,840
So will you compute the
partial derivatives with
respect to all of these rows in

203
00:12:04,841 --> 00:12:08,200
memory? Okay. So there's
actually a lot of parts here.

204
00:12:08,350 --> 00:12:11,830
And what we're gonna do is we're going
to go through each part, step by step,

205
00:12:12,160 --> 00:12:16,120
and I'm going to talk about how each part
works. Okay. Uh, so get ready for this.

206
00:12:16,121 --> 00:12:17,980
This is going to be up. This
is gonna be amazing. Okay.

207
00:12:18,160 --> 00:12:20,560
You're going to have your mind blown.
So let's go,

208
00:12:20,561 --> 00:12:23,350
let's go ahead and get started with
this. We have a lot to go over. Uh,

209
00:12:23,351 --> 00:12:27,070
so it's gonna be a lot of fun.
The first thing that they did here.

210
00:12:27,071 --> 00:12:29,050
So let me answer one of the questions.

211
00:12:29,050 --> 00:12:32,440
One of the questions was how is
this different from its predecessor,

212
00:12:32,441 --> 00:12:33,580
the neural Turing machine?

213
00:12:33,640 --> 00:12:37,840
So there are several ways that in
here I in text how it's different.

214
00:12:37,841 --> 00:12:40,380
Here's how it is different in text,
but there are several ways,

215
00:12:40,450 --> 00:12:41,590
several ways that is different.

216
00:12:41,620 --> 00:12:46,620
But basically it can all be summed up
as there are more memory access methods.

217
00:12:47,080 --> 00:12:50,470
Okay. And so it's different
ways of interacting with memory.

218
00:12:50,471 --> 00:12:52,530
So a more complex,
uh,

219
00:12:52,750 --> 00:12:55,660
a more optimized way of
interacting with memory,

220
00:12:55,840 --> 00:12:58,030
then the neural Turing machine and,

221
00:12:58,900 --> 00:13:03,040
and it added this Tim temporal. I
loved the, I love the terminology here.

222
00:13:03,041 --> 00:13:07,240
I love how deep mind
uses like a neuroscience
terminology because I mean they

223
00:13:07,241 --> 00:13:11,400
have actual neuroscientists working on
their team but they added this temporal

224
00:13:11,470 --> 00:13:12,460
link Matrix.

225
00:13:12,490 --> 00:13:16,330
So you see these arrows pointing to
different arose in this memory bank or

226
00:13:16,331 --> 00:13:17,164
memory matrix.

227
00:13:17,870 --> 00:13:22,870
The reason that's there is so that they
so that they can so that the network can

228
00:13:23,800 --> 00:13:28,210
know when it's reading or writing the
order with which things were written.

229
00:13:28,240 --> 00:13:30,520
Re read or written to memory,
right.

230
00:13:30,521 --> 00:13:34,090
It's the order and the order
helps because you know,

231
00:13:34,091 --> 00:13:37,690
whether it's who is frail as
great uncles, paternal, whatever,

232
00:13:37,870 --> 00:13:39,580
you want to know the order sometimes.

233
00:13:39,670 --> 00:13:43,960
And so this adds an ordering to
the ReadWrite heads. Okay. So

234
00:13:46,120 --> 00:13:50,830
right. Okay. So one more thing
before we start looking at the code.

235
00:13:51,070 --> 00:13:55,060
Okay. I don't want to talk
about attention. So right.
So we have our controller,

236
00:13:55,210 --> 00:13:59,950
we have our read and write heads and
then we have our memory bank. Okay.

237
00:14:00,220 --> 00:14:05,110
So the question then is how do we
know where in this matrix to write to,

238
00:14:05,170 --> 00:14:07,780
how do we know where in
this matrix to read too?

239
00:14:07,990 --> 00:14:10,270
And the degree to which
we should do those things.

240
00:14:10,450 --> 00:14:12,670
And that's where
attention comes into play.

241
00:14:12,671 --> 00:14:17,260
We call it attention because
it's a way for us to frame how,

242
00:14:17,690 --> 00:14:20,950
uh,
how precedents or how,

243
00:14:21,400 --> 00:14:25,390
how important or how waiting is
played into how we read and write.

244
00:14:25,570 --> 00:14:29,040
What do I mean by that?
How do we know where to store,

245
00:14:29,041 --> 00:14:33,490
store to store stuff basically.
So they added three attention mechanisms.

246
00:14:34,540 --> 00:14:36,440
The first one,
it's called content lookup.

247
00:14:36,640 --> 00:14:39,310
So thinking about content address systems,
right?

248
00:14:39,550 --> 00:14:43,760
When you have a content address
system, the, the key, uh,

249
00:14:43,870 --> 00:14:48,040
the key each tells you what that content,
that content value is.

250
00:14:48,310 --> 00:14:51,500
So it's the same thing with this.
We have a reader right head, okay.

251
00:14:51,501 --> 00:14:55,430
And that's good. That's going to
contain some, you know, content address.

252
00:14:55,580 --> 00:14:57,680
And then we have a similar
content address and memory.

253
00:14:57,890 --> 00:15:00,350
And so what we do is then
we find the similarity,

254
00:15:00,351 --> 00:15:04,250
the coastline similarity between all
the content addresses to see what's the

255
00:15:04,251 --> 00:15:06,440
most similar.
And when we could use that,

256
00:15:06,710 --> 00:15:10,580
that value that's the most similar to
then update our network, right? So,

257
00:15:10,730 --> 00:15:14,120
so content look up via a
similarity measure is the first.

258
00:15:14,270 --> 00:15:18,270
And we'll go through each of these uh,
attention mechanism. The second one, uh,

259
00:15:18,390 --> 00:15:22,820
the second, uh, attention mechanism
is a temporal linking, right?

260
00:15:22,940 --> 00:15:26,780
So how do we know the order that things
were re read and written to memory and

261
00:15:26,781 --> 00:15:30,320
how do we then update our
network based on that?

262
00:15:30,860 --> 00:15:33,710
And the third one is
allocating memory for writing.

263
00:15:33,711 --> 00:15:36,740
So this is a dynamic
allocation for writing part.

264
00:15:37,040 --> 00:15:40,250
Instead of having some static amount
of memory dedicated to writing,

265
00:15:40,430 --> 00:15:44,060
we are dynamically allocating it.
So we're going to erase it and then,

266
00:15:44,330 --> 00:15:46,790
and then rewrite,
rewrite over it dynamically.

267
00:15:47,420 --> 00:15:49,520
You'll understand more
when we get to that part.

268
00:15:49,521 --> 00:15:52,520
So there are three attention
mechanisms here. Okay.

269
00:15:52,910 --> 00:15:57,910
And I love how they compared the
attention mechanisms to the hippocampal,

270
00:15:59,840 --> 00:16:04,700
uh, ca three and one synapse synapse
regions of the brain, which is super cool.

271
00:16:05,270 --> 00:16:09,080
And they also did this actually
recall from the, from the deep cue,

272
00:16:10,250 --> 00:16:13,460
from deep cue, the, the network
that could beat all the,

273
00:16:13,461 --> 00:16:16,820
of all those Atari Games
that use something else
from the hippocampal region.

274
00:16:16,940 --> 00:16:20,770
It was called, what was it called,
experience replay, which uh,

275
00:16:20,960 --> 00:16:22,400
came directly from neuroscience.

276
00:16:22,401 --> 00:16:26,420
So deep minds papers read a lot like
new mantas except they actually pub.

277
00:16:26,480 --> 00:16:30,140
They actually have great
results. So, oh yeah. Anyway,

278
00:16:30,800 --> 00:16:34,940
so here we go. With this, let's get
to the code and also let me answer

279
00:16:36,520 --> 00:16:39,400
two more questions before we
get to the code. Question one,

280
00:16:39,401 --> 00:16:43,180
can we use this DNC for real
problems like data association?

281
00:16:43,600 --> 00:16:46,810
Absolutely. Absolutely you can.
And they did, right? With the,

282
00:16:46,811 --> 00:16:48,550
with the family members
in the family trees,

283
00:16:48,730 --> 00:16:53,620
you can abstract that or
you can extrapolate that
problem to something entirely

284
00:16:53,621 --> 00:16:56,500
different.
Like finding associations between

285
00:16:59,940 --> 00:17:01,770
people,
obviously people,

286
00:17:01,771 --> 00:17:06,771
but ideas and images and
different types of data,

287
00:17:06,900 --> 00:17:10,380
different data types, numbers,
stuff like that. Yes, you can.

288
00:17:10,381 --> 00:17:11,340
And then one more question,

289
00:17:11,640 --> 00:17:15,130
can you explain the memory and
head operations in great details.

290
00:17:15,131 --> 00:17:18,780
Still confused about it? Yes. Let me,

291
00:17:20,100 --> 00:17:22,320
let me do that. As I go down
because that's, that's what this,

292
00:17:22,380 --> 00:17:25,860
that's what the code is, right? The
details of that. But high level,

293
00:17:26,730 --> 00:17:29,520
we have an external memory store,
right?

294
00:17:29,550 --> 00:17:34,050
We have a neural network controller and
then we have an external memory store,

295
00:17:34,051 --> 00:17:37,500
which is a matrix, right? It's a
matrix that we defined and you know,

296
00:17:37,710 --> 00:17:42,710
x by y Matrix and we ever our neural
network and for our neural network we feed

297
00:17:44,071 --> 00:17:47,910
it in an input. Okay. And it's
forward propagating. Right?

298
00:17:48,600 --> 00:17:51,720
And then it's reading and writing
to memory. So it's saying,

299
00:17:51,750 --> 00:17:56,750
so the degree to which we're reading
and writing is dependent on how we

300
00:17:57,271 --> 00:17:58,950
structure it,
which we're going to go into.

301
00:17:59,250 --> 00:18:00,840
But it's reading and
writing to memory too.

302
00:18:00,870 --> 00:18:04,720
It's reading to see w just like it would
read its own weights just like it's,

303
00:18:04,800 --> 00:18:06,870
it would read its own right weights.

304
00:18:06,930 --> 00:18:11,410
It's reading from the memory store to
make predictions to compute that those,

305
00:18:11,520 --> 00:18:15,330
that series of matrix operations that
it would to then output that that

306
00:18:15,331 --> 00:18:16,164
prediction.
Right.

307
00:18:16,350 --> 00:18:19,040
And it's writing for memory to then
just like it would write to its way.

308
00:18:19,041 --> 00:18:19,590
It's right.

309
00:18:19,590 --> 00:18:24,120
Just like how you multiply each weight by
each value as you propagate it forward.

310
00:18:24,300 --> 00:18:28,470
You're also multiplying it by this memory,
this external memory,

311
00:18:28,560 --> 00:18:32,370
a matrix,
and then we differentiate,

312
00:18:32,371 --> 00:18:34,710
which is going to be awesome
when we get to it. Okay,

313
00:18:34,711 --> 00:18:36,750
so let's get started with
the code from scratch.

314
00:18:36,900 --> 00:18:40,410
We don't have time to just write it all
out because there's a lot of code and

315
00:18:40,411 --> 00:18:43,290
there's a lot of theory here.
So we're going to focus on the theory.

316
00:18:43,530 --> 00:18:47,280
We're going to focus on the
theory and then uh, we'll,

317
00:18:47,430 --> 00:18:51,930
we'll compile it and run it and it's
going to be awesome. Okay, so, oh,

318
00:18:51,931 --> 00:18:52,620
there's another question.

319
00:18:52,620 --> 00:18:55,680
Is it better to have loops in neural
networks thing to go without it?

320
00:18:56,400 --> 00:19:00,240
Is it better to have loops?
It's better if that's your use case.

321
00:19:00,241 --> 00:19:03,510
What we're using in this in this
example is a feed forward network.

322
00:19:03,540 --> 00:19:07,290
It's a feed forward network, uh, but
you could use a recurrent net. In fact,

323
00:19:07,291 --> 00:19:10,590
in the paper they use a recurrent nets.
And when you would,

324
00:19:10,620 --> 00:19:13,530
when would you want to use guys
helping answer this question?

325
00:19:13,770 --> 00:19:15,780
When would you want to
use a recurrent network?

326
00:19:15,900 --> 00:19:17,550
When would you want to have loops,
right?

327
00:19:17,700 --> 00:19:21,120
When would you want to have the state
fed back into the input at the next time

328
00:19:21,121 --> 00:19:25,680
step, when you have a sequence, okay?
When you have any kind of sequence,

329
00:19:25,681 --> 00:19:30,030
any kind of sequential data, then you
would want a recurrent network, okay?

330
00:19:30,210 --> 00:19:32,610
But the most simple type of
network is a feed forward net.

331
00:19:32,730 --> 00:19:35,460
And that's what we're doing here
because we want to really, you know,

332
00:19:35,490 --> 00:19:38,820
break it down to its bare essentials
so we can understand the general

333
00:19:38,821 --> 00:19:42,030
architecture. And once we
understand the general architecture,

334
00:19:42,210 --> 00:19:46,980
then we could use this for crazy new use
cases that no one has ever done before.

335
00:19:47,160 --> 00:19:50,490
We are at the bleeding edge right now.
So let's, let's get started. Okay.

336
00:19:50,820 --> 00:19:52,740
So we're going to define the DNC,

337
00:19:52,741 --> 00:19:57,360
the differentiable neural computer as its
own class. Okay? And like all classes,

338
00:19:57,361 --> 00:19:59,580
we want to initialize it in the,
in its function.

339
00:19:59,910 --> 00:20:02,670
So let's go step by step through
what we're going to define here.

340
00:20:03,000 --> 00:20:05,460
So the first thing we're going to define,
uh,

341
00:20:05,490 --> 00:20:09,090
is the input data and the output data,
or the sizes of both.

342
00:20:09,240 --> 00:20:10,380
Now this is what it's gonna look like.

343
00:20:10,381 --> 00:20:15,381
Recall that it is a set
of pair of binary pairs,

344
00:20:17,041 --> 00:20:21,330
one zero zero one zero zero
and these pairs are going
to be randomly initialized.

345
00:20:21,331 --> 00:20:22,164
It doesn't matter,

346
00:20:22,290 --> 00:20:24,750
but there's gonna be a mapping
both for the input and output data,

347
00:20:24,760 --> 00:20:28,080
just a sets because they're both just
a series of ones and zeroes, right?

348
00:20:28,290 --> 00:20:33,290
And we want to learn the mapping between
the two so that given some novel inputs

349
00:20:33,750 --> 00:20:34,710
with ones and Zeros,

350
00:20:34,830 --> 00:20:38,220
we can then predict what the probable
output set of ones and Zeros would be,

351
00:20:38,460 --> 00:20:41,850
right? Because we already have a set of
them. It's a supervised learning problem.

352
00:20:42,090 --> 00:20:44,700
And then we want to then predict
what that label would be.

353
00:20:45,600 --> 00:20:48,580
So we have our inputs size and our output
size that we're going to define here.

354
00:20:48,581 --> 00:20:52,150
Okay. And notice that these are coming
from the parameters up here, right?

355
00:20:52,150 --> 00:20:55,600
We're going to define these when
we initialized our DNC later on.

356
00:20:55,601 --> 00:20:58,810
But we're defining the class right now.
So that's the first part.

357
00:20:59,110 --> 00:21:04,110
The next part is for us to define
our read and write vector size.

358
00:21:04,720 --> 00:21:08,380
So notice how it's called numb words.
And words size.

359
00:21:09,670 --> 00:21:12,620
But there are no words here,
right? This is kind of like,

360
00:21:12,800 --> 00:21:14,880
like they had words in the deep mind code.

361
00:21:14,881 --> 00:21:18,010
So this is kind of like leftover from
that. But there are no words here.

362
00:21:18,190 --> 00:21:23,190
But what we can think of these two
variables as are the sizes of our read and

363
00:21:23,201 --> 00:21:25,480
write vectors.
Because when we initialize them,

364
00:21:25,600 --> 00:21:28,810
we'll be using these variables as,

365
00:21:28,840 --> 00:21:33,100
as parameters to define the size
of our read and write vectors.

366
00:21:33,370 --> 00:21:36,940
And a couple other variables that
will, that will, uh, talk about.

367
00:21:37,240 --> 00:21:40,990
But they're basically these constant
values that we are going to use to,

368
00:21:41,020 --> 00:21:45,760
to initialize a bunch of variables later
on. But their constant, these values,

369
00:21:45,790 --> 00:21:49,120
these two values are constant, right?
The number of words and the word size.

370
00:21:50,800 --> 00:21:53,710
In fact, we're going to use it to
initialize the size of our memory matrix.

371
00:21:53,920 --> 00:21:57,970
Our memory matrix is going to be the
number of words by the word size.

372
00:21:58,060 --> 00:22:02,260
That's the size of our memory
matrix. Okay. So then, uh,

373
00:22:02,290 --> 00:22:06,010
we want to define our heads, right? So
how many heads do we want? And so that is,

374
00:22:06,170 --> 00:22:09,340
so basically a head is an operation.
How many times,

375
00:22:09,430 --> 00:22:12,250
how many times do we want to be reading
and writing to memory while we're

376
00:22:12,251 --> 00:22:15,160
training our network?
And we're just going to say one,

377
00:22:15,370 --> 00:22:17,770
we're going to have a single
head for every time step.

378
00:22:17,890 --> 00:22:20,980
It's going to be reading and writing
to memory. Just one head. Okay,

379
00:22:20,981 --> 00:22:25,270
so just to keep it simple, but we
could have multiple heads. Okay,

380
00:22:25,300 --> 00:22:29,440
so then we're going to
define our interface size.

381
00:22:29,680 --> 00:22:33,340
So what is this? So, oh,
so let me go back up here.

382
00:22:33,341 --> 00:22:36,910
So I left out one part because
I wanted to get to it now.

383
00:22:37,000 --> 00:22:39,070
So we have our inputs,
right?

384
00:22:39,071 --> 00:22:41,890
We have our input data and then
we feed it to our controller.

385
00:22:41,891 --> 00:22:44,950
It reads and writes and then it
and then outputs a prediction.

386
00:22:45,280 --> 00:22:49,090
But a DNC doesn't just
output a prediction.

387
00:22:49,330 --> 00:22:53,530
It also outputs a,
an interface vector.

388
00:22:53,770 --> 00:22:58,270
And what the interface vector does is
it defines how we're going to interact

389
00:22:58,271 --> 00:23:02,590
with the memory bank at the next time
step. So it's outputting, putting things,

390
00:23:02,710 --> 00:23:06,190
it's out putting our prediction and
what's called an interface vector.

391
00:23:06,400 --> 00:23:10,180
And we use this interface vector to
then feed it back into the network.

392
00:23:10,210 --> 00:23:13,810
So then that the next time step, we know
how to interact with the memory bank.

393
00:23:14,440 --> 00:23:15,370
So that's what we're doing here.

394
00:23:15,371 --> 00:23:19,510
We're defining that the size
of that interface vector.

395
00:23:20,650 --> 00:23:21,530
And yes,
there,

396
00:23:21,600 --> 00:23:24,760
there are like three places in the
code where there are magic numbers.

397
00:23:24,761 --> 00:23:26,650
And let me make sure that
you guys can see this.

398
00:23:26,890 --> 00:23:30,760
So there are three places in the
code where there are magic numbers,

399
00:23:31,660 --> 00:23:32,493
but,

400
00:23:36,190 --> 00:23:38,530
but that's uh,

401
00:23:39,190 --> 00:23:42,400
that's just how it is because I mean,
we could,

402
00:23:42,401 --> 00:23:46,070
we could change these in our results would
be better. Uh, you know, I tried out,

403
00:23:46,340 --> 00:23:49,070
I tried out several, several
numbers here, but these, these,

404
00:23:49,130 --> 00:23:53,060
these produced the best convergence and
that's just all of deep learning, right?

405
00:23:53,061 --> 00:23:56,120
For all hyper parameters.
But we're defining them by these,

406
00:23:56,121 --> 00:24:00,890
remember these set a vector is this numb
words and word size that we're going to

407
00:24:00,891 --> 00:24:05,810
consistently used throughout this, this
code. Okay. So we define our input data.

408
00:24:05,960 --> 00:24:10,960
We define these two variables that will
help us initialize our memory matrix,

409
00:24:11,940 --> 00:24:16,220
saw a length and width and then are
the number of heads we want to read and

410
00:24:16,221 --> 00:24:19,490
write with the interface size,
which is the size of that output,

411
00:24:19,520 --> 00:24:21,380
that associated vector with the output.

412
00:24:21,740 --> 00:24:24,980
And then are then we're going
to define our input size,

413
00:24:25,070 --> 00:24:28,730
which is the size of the input,
right? Which is going to be uh,

414
00:24:28,880 --> 00:24:31,850
after we flatten it, what does that
size of that input going to be?

415
00:24:32,060 --> 00:24:36,040
So we're going to define that here,
using those, those same two, uh,

416
00:24:36,410 --> 00:24:39,980
parameters that we talked about before.
And then the output side,

417
00:24:40,010 --> 00:24:41,690
what do we want the output size to be?
Well,

418
00:24:41,691 --> 00:24:46,691
it's going to be the size of the
output that we defined earlier plus the

419
00:24:47,001 --> 00:24:47,811
interface size,

420
00:24:47,811 --> 00:24:52,400
cause it's one big vector that we could
split and then use later on. Okay.

421
00:24:52,880 --> 00:24:54,540
And then we're going to define a,

422
00:24:55,130 --> 00:24:58,880
a distribution on both outputs,
both the,

423
00:25:01,680 --> 00:25:06,480
both the prediction and the interface.
So we have distributions around both.

424
00:25:08,010 --> 00:25:11,790
And finally we create our memory
matrix. All right. Our memory matrix.

425
00:25:11,820 --> 00:25:15,900
This thing up here, right over
here, it's just the matrix.

426
00:25:15,930 --> 00:25:19,710
We can define it in one line of code. It's
just a matrix. It's not some, you know,

427
00:25:19,711 --> 00:25:20,700
pseudo magical thing.

428
00:25:20,910 --> 00:25:25,830
We'll define it as a set of Zeros using
our number of words by our word size,

429
00:25:25,831 --> 00:25:29,880
but there are no words. It's just the
size versus the length versus width. Okay?

430
00:25:30,820 --> 00:25:35,040
And Times W. Okay, we have
some more variables here.

431
00:25:35,250 --> 00:25:38,130
So we've defined our matrix,
we defined a sides of our heads,

432
00:25:38,250 --> 00:25:40,710
our input size or output size or you know,

433
00:25:41,550 --> 00:25:45,150
input output heads and memory matrix size.

434
00:25:45,360 --> 00:25:50,220
And now remember we don't just
have an external memory matrix.

435
00:25:50,370 --> 00:25:54,600
We have a third matrix, right?
We have our neural network,

436
00:25:54,601 --> 00:25:58,140
which we can consider one huge matrix.
We have our memory matrix,

437
00:25:58,320 --> 00:26:00,300
but we also have this
third matrix over here,

438
00:26:00,301 --> 00:26:03,480
which is this temporal linkage matrix,
right?

439
00:26:03,690 --> 00:26:05,370
This is how we sequentially,

440
00:26:05,830 --> 00:26:08,100
this is how whenever we're
reading and writing to memory,

441
00:26:08,340 --> 00:26:12,900
we decide what order we should read and
write to the ordering matters, right?

442
00:26:13,050 --> 00:26:15,420
Ordering definitely matters.
Whether it's a graph,

443
00:26:15,421 --> 00:26:20,400
traversal problem or natural language
problem, the order matters because

444
00:26:21,990 --> 00:26:25,920
we're going to continually
feed it data. Okay. So

445
00:26:27,730 --> 00:26:28,421
right. So, okay,

446
00:26:28,421 --> 00:26:33,421
so we have our usage vector and the
usage vector is going to record which

447
00:26:33,491 --> 00:26:35,140
locations have been used so far.

448
00:26:35,320 --> 00:26:40,320
So it's kind of like it's deciding where
in the memory bank have we are read and

449
00:26:42,161 --> 00:26:42,994
written to before.

450
00:26:43,080 --> 00:26:46,980
Then we'll store that there and we'll
use that usage vector to then define our,

451
00:26:47,030 --> 00:26:51,860
our temporal link Matrix. Okay. Later on.

452
00:26:52,610 --> 00:26:57,140
But right now we just initialize it with
Zeros and then we have our precedence.

453
00:26:57,141 --> 00:26:57,740
Wait,

454
00:26:57,740 --> 00:27:01,070
we're just going to represent the degree
to which the last location was written

455
00:27:01,071 --> 00:27:02,990
to and the previous time step.

456
00:27:03,290 --> 00:27:07,160
Once I get through up to this output,
wait right here,

457
00:27:07,190 --> 00:27:11,790
then I'll answer questions.
Okay. So then, right,

458
00:27:11,791 --> 00:27:14,760
so that's our Tempura
link Matrix essentially.

459
00:27:14,910 --> 00:27:18,720
So we have what we've defined our major
components and now we've got to define

460
00:27:18,721 --> 00:27:23,440
our, uh, read and write
head variables. Oh, right.

461
00:27:23,441 --> 00:27:27,730
Head weights variables. I mean, let me
update that because we only have one head,

462
00:27:27,731 --> 00:27:30,670
right?
But we have weights for that head right?

463
00:27:30,820 --> 00:27:34,600
We have a set of read weights and a set
of right weights and these weights are

464
00:27:34,601 --> 00:27:37,300
just matrices.
They're small matrices,

465
00:27:37,540 --> 00:27:41,320
but they define the degree to which we're
reading and the degree to which we're

466
00:27:41,321 --> 00:27:44,230
writing. It's what do I
mean by the degree to which,

467
00:27:44,440 --> 00:27:49,030
well recall that reading and writing is
just, they're just matrix operations.

468
00:27:49,031 --> 00:27:53,560
They're just multiplication and we
can define how much we're multiplying.

469
00:27:53,561 --> 00:27:56,920
We can tune that similar to how we use
a learning rate when whenever we're

470
00:27:56,921 --> 00:27:59,740
updating our weights, it's
like that. These weights,

471
00:27:59,920 --> 00:28:04,300
these read and write weights define how
much we're multiplying the memory matrix

472
00:28:04,301 --> 00:28:08,260
by, and remember the entire
thing is differentiable.

473
00:28:08,380 --> 00:28:11,140
So everything is updated,
right? You might be,

474
00:28:11,230 --> 00:28:15,280
because you might be wondering how do
we know what the read wage should be or

475
00:28:15,281 --> 00:28:16,540
what the right way it should be,

476
00:28:16,541 --> 00:28:19,960
or even what the usage weight
or the link matrix should be.

477
00:28:20,770 --> 00:28:24,730
We're differentiating everything based
on the output that the loss between the

478
00:28:24,731 --> 00:28:28,750
output and the, uh, the predicted
output in the actual outputs.

479
00:28:28,930 --> 00:28:32,320
And we're using that to differentiate
the entire thing. All the components,

480
00:28:32,500 --> 00:28:34,000
which is amazing.
If you think about it,

481
00:28:34,180 --> 00:28:36,670
it's an end to end system
end to end differentiable.

482
00:28:38,170 --> 00:28:41,290
So we have a read weights are right
weights and then our read vectors,

483
00:28:41,950 --> 00:28:46,950
which are going to use the right
read weights to then apply that.

484
00:28:46,970 --> 00:28:47,830
That's what we actually do.

485
00:28:47,831 --> 00:28:51,520
The Matrix multiplication with we take
our weights times are vectors and then

486
00:28:51,521 --> 00:28:53,260
that's how we get our,
uh,

487
00:28:54,410 --> 00:28:55,020
okay.

488
00:28:55,020 --> 00:28:58,560
That's how we get our output
for the, for the Matrix. Okay.

489
00:28:58,561 --> 00:29:02,650
So then we've got our
uh, placeholders, right?

490
00:29:02,740 --> 00:29:04,320
These are our tension flow placeholders.

491
00:29:04,440 --> 00:29:07,390
We're going to feed in our input and
output pair, right? Those ones and Zeros,

492
00:29:07,570 --> 00:29:11,020
both of them are gateways and we just
feed them both in learning the mapping and

493
00:29:11,021 --> 00:29:15,000
then predicted output. Okay.
So then we define our networks.

494
00:29:15,001 --> 00:29:18,790
So because this is a super simple use
case, we have one read head. Okay.

495
00:29:18,791 --> 00:29:21,250
We have just binary input output pairs.

496
00:29:21,580 --> 00:29:24,820
Let's just define a feed forward to
layer feed forward network, right?

497
00:29:25,060 --> 00:29:29,000
It's got set of weights and set of
biases. So weight bias, weight bias. Nope,

498
00:29:29,470 --> 00:29:34,000
that's it. Okay. Uh, let me make
sure that we can see everything here.

499
00:29:35,050 --> 00:29:35,540
Okay.

500
00:29:35,540 --> 00:29:39,410
Okay. This is a little longer line.
So let me, let me go over here.

501
00:29:39,650 --> 00:29:43,930
Float 32 we've named our, you
know, standard deviation of 0.1.

502
00:29:44,230 --> 00:29:48,430
We defined the size by
using the input size. Okay,

503
00:29:48,640 --> 00:29:52,540
so this part's going to be cut off here
as well, but just recognize that it's,

504
00:29:52,570 --> 00:29:57,190
it's similar. Okay. So let me
make it bigger again. Okay.

505
00:29:57,191 --> 00:30:01,390
So where was I? So, okay,

506
00:30:01,391 --> 00:30:02,430
so we divide our network and let me,

507
00:30:02,740 --> 00:30:04,390
let me talk about these and
then I'll answer questions.

508
00:30:04,690 --> 00:30:08,080
So then we have our output weights. So
we have weights for our output, right?

509
00:30:09,850 --> 00:30:14,650
So all of these components have
weights. Are, are our output,

510
00:30:14,860 --> 00:30:18,520
our output values have weights,
spoke the interface factor and the output.

511
00:30:19,090 --> 00:30:22,630
And why do they have weights so that
we can then differentiate. We don't,

512
00:30:22,690 --> 00:30:23,710
we don't,
uh,

513
00:30:23,770 --> 00:30:27,700
we take the partial derivative
with respect to not just
our controllers weights,

514
00:30:27,910 --> 00:30:31,990
but by the weights up our outputs,
by the weights of our heads,

515
00:30:32,080 --> 00:30:34,200
by the weights of our Matrix,
uh,

516
00:30:34,390 --> 00:30:38,590
and by the weights of
our Tempura link Matrix.

517
00:30:38,770 --> 00:30:41,320
So we take the partial derivative
with respect to everything.

518
00:30:41,560 --> 00:30:45,730
So even the weights, even the
outputs have weights. Okay.

519
00:30:45,760 --> 00:30:50,760
Both the and we and we initialize them
randomly using this TF truncated normal

520
00:30:51,250 --> 00:30:56,140
function. Okay. And then we
also have a read vectors output.

521
00:30:56,141 --> 00:31:01,120
Wait. Okay. So now let me answer some
questions because now we can get to the,

522
00:31:01,750 --> 00:31:03,940
the fun part.
So the questions are,

523
00:31:05,980 --> 00:31:10,240
let me just see who's, who's who.
Okay. We've got 408 people here.

524
00:31:13,080 --> 00:31:15,080
All right. People are doing good. Okay.

525
00:31:15,290 --> 00:31:17,840
Is it better to have loops in neural
networks then too? No, no, no.

526
00:31:17,841 --> 00:31:18,674
I already answered that.

527
00:31:18,860 --> 00:31:22,880
Can you tell me what is the difference
between fine tuning and transfer learning?

528
00:31:25,160 --> 00:31:26,210
Transfer learning.

529
00:31:27,170 --> 00:31:27,690
Okay.

530
00:31:27,690 --> 00:31:31,230
Okay. So fine tuning is a, is a kind
of vague term. You could think of.

531
00:31:31,231 --> 00:31:32,820
Transfer learning as fine tuning.

532
00:31:33,000 --> 00:31:36,030
In fact you could think of all machine
learning is fine tuning. We are,

533
00:31:36,930 --> 00:31:39,030
we are iteratively improving our model.

534
00:31:39,150 --> 00:31:44,010
But transfer learning is when you
train a network on some task. Okay.

535
00:31:44,011 --> 00:31:49,011
And then you used that pretrained
model to then learn from my different,

536
00:31:49,361 --> 00:31:50,400
try a different tasks.

537
00:31:50,401 --> 00:31:53,160
So you're transferring the
learnings from one task to another.

538
00:31:53,820 --> 00:31:58,140
Two more questions. What if the Matrix is
larger than the amount of Ram you have.

539
00:31:58,530 --> 00:31:59,790
So that

540
00:32:01,760 --> 00:32:05,880
would probably not happen unless
you have a really, uh, both, uh,

541
00:32:05,881 --> 00:32:09,210
really bad computer and the model is huge,

542
00:32:09,270 --> 00:32:13,440
like gigantic. Uh, but if that
happened, then you would have a,

543
00:32:13,680 --> 00:32:17,880
an overflow or ramp up your, uh,
an overflow for, of Ram and your,

544
00:32:17,970 --> 00:32:20,760
and your computer. Your system
would notify you of that with a,

545
00:32:20,790 --> 00:32:22,680
with a pop up unless it was like,

546
00:32:22,770 --> 00:32:26,850
I dunno Debbie and or something
would and in which case you're just,

547
00:32:26,880 --> 00:32:27,960
you're screwed.
Okay.

548
00:32:27,961 --> 00:32:32,790
So then do you guys use radial basis
functions as kernels in neural networks?

549
00:32:33,210 --> 00:32:38,040
So I haven't seen those used a lot.
Uh,

550
00:32:38,130 --> 00:32:41,450
those are rarely used.
I see it. I can recall.

551
00:32:41,480 --> 00:32:43,610
Radial basis function is being used in

552
00:32:44,860 --> 00:32:45,693
uh,

553
00:32:46,400 --> 00:32:49,190
mark off chains. So like
Markov models. I see.

554
00:32:49,191 --> 00:32:54,191
Those used with those is mid is mid I
data a sequence of data that can be fed

555
00:32:55,041 --> 00:32:59,300
into a looping neural network. I'm
trying to create a mid I generator. Yes.

556
00:32:59,330 --> 00:33:02,210
I've got like three videos on that.
Generate music intenser flow,

557
00:33:02,900 --> 00:33:07,900
how to build an AI composer and how
to generate music and tensorflow live.

558
00:33:09,410 --> 00:33:14,060
Check out all of the videos.
Okay, so back to this back.

559
00:33:14,061 --> 00:33:16,580
Back in black. Okay, so
we define all of our,

560
00:33:16,610 --> 00:33:20,480
all we did was we just defined all of
our vectors that we're going to be using,

561
00:33:20,481 --> 00:33:22,400
right? All of our, all of our components,

562
00:33:22,401 --> 00:33:25,430
we defined our components of
this thing but the country. Okay?

563
00:33:25,431 --> 00:33:27,570
So that would be the controller,
the,

564
00:33:27,710 --> 00:33:31,460
the weights for the output and the
weights for the interface vector. The,

565
00:33:31,610 --> 00:33:35,960
the read, the, the one head
that we're using in the waits
for it, the memory bank,

566
00:33:35,961 --> 00:33:40,010
which is a memory matrix that the
tempura link Matrix and it's associated

567
00:33:40,011 --> 00:33:40,844
weights.

568
00:33:40,960 --> 00:33:41,950
That's it.
Okay.

569
00:33:43,440 --> 00:33:46,260
That's what we just defined.
And now we're going to actually,

570
00:33:47,800 --> 00:33:48,633
uh,

571
00:33:49,040 --> 00:33:50,960
go right into the step function.
So,

572
00:33:51,800 --> 00:33:54,410
so notice how I've got
two functions up here.

573
00:33:54,920 --> 00:33:57,590
Each of these is for a
different attention mechanism.

574
00:33:57,591 --> 00:34:01,310
So we have three attention mechanisms
for the network for the controller to

575
00:34:01,311 --> 00:34:04,520
decide how we're going to
deal with this memory bank,

576
00:34:05,060 --> 00:34:08,810
how we're going to update this
memory bank. And read from it. Uh,

577
00:34:08,840 --> 00:34:12,170
but let's go straight into the step
function and then we'll talk about the

578
00:34:12,171 --> 00:34:16,940
details of these helper functions. So
we'll start at a high level and then go,

579
00:34:17,340 --> 00:34:19,880
uh,
increasingly a more low level.

580
00:34:20,690 --> 00:34:21,523
So

581
00:34:22,950 --> 00:34:26,130
here's what happens. The step function
happens at every time step, right?

582
00:34:26,190 --> 00:34:28,110
So whenever we build
our session at the end,

583
00:34:28,290 --> 00:34:31,770
we're going to run this step function
continuously. So at every time step,

584
00:34:31,920 --> 00:34:35,820
the controller receives an input vector
from the Dataset and emits an output

585
00:34:35,821 --> 00:34:36,630
vector,

586
00:34:36,630 --> 00:34:41,010
but it also receives a set of read vectors
from the memory matrix at a previous

587
00:34:41,011 --> 00:34:43,770
time step via the read heads.
Okay?

588
00:34:43,771 --> 00:34:47,610
Then it emits an interface vector that
defines its interaction with the memory

589
00:34:47,700 --> 00:34:51,060
at the current time step.
So now I'm going to add something else on.

590
00:34:51,090 --> 00:34:55,740
This is notice I'm adding things on, uh,
iteratively. So remember how I said, Oh,

591
00:34:55,741 --> 00:34:58,920
you have one input and you have one
output. And then I was like, actually,

592
00:34:59,040 --> 00:35:01,200
you have one input and
then you have two outputs.

593
00:35:01,530 --> 00:35:05,640
One output is the predicted output and
the other output is an interface vector

594
00:35:05,700 --> 00:35:08,850
that defines how you interact with the
memory bank. And the next time set,

595
00:35:09,150 --> 00:35:13,020
well we've actually not just got
two outputs. We've got two inputs.

596
00:35:13,200 --> 00:35:17,880
So one of the inputs is the data itself,
but the other input is going to be

597
00:35:21,310 --> 00:35:22,143
the

598
00:35:24,030 --> 00:35:27,960
read vector from the previous time step.
So think about this for a second.

599
00:35:28,170 --> 00:35:29,610
This is not a recurrent network.

600
00:35:29,611 --> 00:35:33,870
We're using a feed forward network but
because we're not feeding in the state of

601
00:35:33,871 --> 00:35:35,730
the controller from a previous time step,

602
00:35:35,970 --> 00:35:40,920
but what we are feeding from a
previous time step is the read vector.

603
00:35:41,310 --> 00:35:45,960
So it's a feed forward network but so
the controller is feed forward but as a

604
00:35:45,961 --> 00:35:48,270
whole there is recurrence happening.

605
00:35:48,750 --> 00:35:52,680
So you could think of the differential
neural computer as a whole,

606
00:35:52,950 --> 00:35:56,880
as a recurrent network but not in the
traditional sense or feeding in the

607
00:35:56,881 --> 00:35:59,460
previous state of the network
to the previous time step.

608
00:35:59,700 --> 00:36:03,250
But in the sense that we are feeding in
the read vector from the previous times

609
00:36:03,251 --> 00:36:06,750
that from the memory matrix, from the
external memory store back into the input.

610
00:36:06,751 --> 00:36:09,620
So in that way it's recurrent. Okay. So,

611
00:36:11,090 --> 00:36:12,960
so that's what's happening
at every time step.

612
00:36:12,961 --> 00:36:16,680
It receives an input vector
from the dataset and missing
an output vector and an

613
00:36:16,681 --> 00:36:20,830
interface vector. And then at the next
time seven and puts the next, the,

614
00:36:20,831 --> 00:36:23,820
the next input is going to be from
the Dataset and the read vector.

615
00:36:24,030 --> 00:36:28,250
And then we just repeat that over and over
again. So let's, let's do this. Let's,

616
00:36:28,251 --> 00:36:30,570
let's programmatically go
through what this looks like.

617
00:36:30,870 --> 00:36:35,370
So the first step is first is for us to
reshape our input so that it's, it's,

618
00:36:36,000 --> 00:36:38,640
it's fit for the size of our network,
right?

619
00:36:39,120 --> 00:36:42,690
So we've got our input data and remember,
uh,

620
00:36:42,750 --> 00:36:47,700
we also have the read vectors,
right? Both of those things.

621
00:36:47,730 --> 00:36:50,430
We've got our input and they're read
vectors from the previous time step.

622
00:36:51,570 --> 00:36:54,960
And then we take that input and then we
forward propagate through the network.

623
00:36:56,100 --> 00:36:59,370
We forward propagate through the
network and in remember it's a two layer

624
00:36:59,371 --> 00:37:00,150
network,
right?

625
00:37:00,150 --> 00:37:04,260
So we do a matrix multiplication by
the weights and biases Tan h as our

626
00:37:04,261 --> 00:37:07,590
activation function matrix
multiplication 10 age.

627
00:37:07,740 --> 00:37:12,630
And this l two activation is going to
be our output. Okay. Um, well, sorry.

628
00:37:12,660 --> 00:37:13,680
No, no, no. Sorry.

629
00:37:13,920 --> 00:37:17,490
This is going to be our output and we're
going to use that last activation to

630
00:37:17,491 --> 00:37:21,270
compute it by then doing
matrix multiplication. But
this is our output vector.

631
00:37:21,900 --> 00:37:24,270
And then this is going to
be our interface vector.

632
00:37:24,271 --> 00:37:25,950
So remember there are two outputs,

633
00:37:26,220 --> 00:37:29,910
the both a normal output and
the interface vector. Okay.

634
00:37:29,911 --> 00:37:31,320
So now we have both of our outputs.

635
00:37:31,500 --> 00:37:36,360
We forward propagated and it's time to
then use these two vectors to then learn

636
00:37:36,361 --> 00:37:41,010
and do more, more things with. Okay.
So then we've got this one line.

637
00:37:41,011 --> 00:37:44,010
So remember I said how there's magic
numbers in three parts of this code?

638
00:37:44,400 --> 00:37:48,930
We talked about that one. This is
the other part. So the partition,

639
00:37:49,350 --> 00:37:53,310
what the F is this?
So the partition is a,

640
00:37:57,150 --> 00:38:02,150
it's what we're going to use to define
our interaction with the memory matrix.

641
00:38:03,330 --> 00:38:08,040
Okay. So we take this partition
and it's a, it's a 10,

642
00:38:08,700 --> 00:38:12,720
it's a, it's a, it's think of it as a
list or an array with 10 parts to it.

643
00:38:12,900 --> 00:38:17,820
And it's just one big, uh, one big
matrix that we're then going to

644
00:38:19,640 --> 00:38:21,840
that were there aren't
going to convert into a,

645
00:38:22,140 --> 00:38:27,060
a set of keys and a set of
strings and a set of vectors.

646
00:38:27,061 --> 00:38:31,070
Okay. So let me go ahead and, uh,

647
00:38:32,370 --> 00:38:36,700
talk about how we're going to split
these up into a set of keys and vectors.

648
00:38:36,970 --> 00:38:40,750
All right. But first, let me answer
some questions before we get into this.

649
00:38:42,100 --> 00:38:45,910
So in terms of questions we've got,

650
00:38:47,050 --> 00:38:51,340
can we use neural nets to make something
like a PCB layout designer because

651
00:38:51,341 --> 00:38:55,480
currently available
ones are crap. Ah, yes.

652
00:38:55,540 --> 00:39:00,310
How would you do that?
You would want to use a generative model?

653
00:39:01,540 --> 00:39:06,490
Uh, probably a generative
adversarial network. Train it on.

654
00:39:09,550 --> 00:39:13,450
Now, I'm not, I'm not familiar with
the components of how a PCB works,

655
00:39:13,630 --> 00:39:17,170
but I assume that you can think of it
as a graph problem as well because you

656
00:39:17,171 --> 00:39:20,710
have different components and data is
flowing through the hardware in a certain

657
00:39:20,711 --> 00:39:24,730
way or you know, it's some kind of
mapping. But think of it as a graph,

658
00:39:24,731 --> 00:39:28,360
traversal problem and you're feeding it
all these graphs and it's supervised,

659
00:39:28,510 --> 00:39:31,600
right? And you have the correct
paths for all of these examples.

660
00:39:31,810 --> 00:39:33,580
And then given these set of examples,

661
00:39:33,581 --> 00:39:38,581
you can then generate a new path which
would then be a new PCB layout design.

662
00:39:41,050 --> 00:39:43,720
That's just one way. But yes, you
could for sure. Okay, so back to this.

663
00:39:44,980 --> 00:39:49,720
So we want to convert our interface vector
into a set of readings factors and we

664
00:39:49,721 --> 00:39:54,670
use the partition to do that. Okay. So
what do I mean by the partition? Let me,

665
00:39:54,671 --> 00:39:58,210
let me back up here for a second. Let me
back up. Let's back up. Let's back up.

666
00:39:58,930 --> 00:40:03,550
We have our controller and it outputs
to things it outputs are output vector,

667
00:40:03,551 --> 00:40:07,690
which is our prediction. And the
outputs are interface vector. Okay.

668
00:40:07,691 --> 00:40:12,430
And our interface vector is meant for our
network to then decide how to interact

669
00:40:12,431 --> 00:40:16,150
with the memory bank at the next
time step. But how do we know?

670
00:40:16,900 --> 00:40:21,100
So how do we know exactly how to
interact with the memory bank? Well,

671
00:40:21,101 --> 00:40:25,630
we're gonna use this partition and what
the partition does is it defines sizes

672
00:40:25,990 --> 00:40:29,410
for 10 different.
Think of these as placeholders.

673
00:40:30,040 --> 00:40:32,590
What these 10 placeholders
are going to be,

674
00:40:32,920 --> 00:40:36,310
or they're going to become
these 10 variables right here.

675
00:40:37,000 --> 00:40:38,350
They're going to become
these 10 variables.

676
00:40:38,351 --> 00:40:41,590
So before we initialize these variables,
we define the sizes of them.

677
00:40:41,860 --> 00:40:44,240
And what these variables are going
to do is they're going to be,

678
00:40:44,440 --> 00:40:46,360
they're going to come out
of the interface vector.

679
00:40:46,540 --> 00:40:51,310
So think of the interface sector as one
big matrix or one big vector, same thing.

680
00:40:51,790 --> 00:40:56,790
And then we use the partition to then
split that vector and two sizes that we've

681
00:40:57,911 --> 00:40:59,170
predefined beforehand.

682
00:40:59,470 --> 00:41:04,470
And each of those is going to be a a V
and an important component that we're

683
00:41:04,541 --> 00:41:08,650
going to then use to update our memory
bank. So we have our interface vector,

684
00:41:08,830 --> 00:41:12,730
we define a partition to split it up
into a set of sizes that we want and then

685
00:41:12,731 --> 00:41:17,731
we dynamically partition it using tfs
dynamic partition function into the read

686
00:41:17,830 --> 00:41:20,050
key into three read variables,

687
00:41:20,980 --> 00:41:25,900
three right variables and then three
gate variables which I haven't talked

688
00:41:25,901 --> 00:41:30,680
about, which we will. And then I
read a set of read modes. So there,

689
00:41:30,681 --> 00:41:32,740
there are quite a few
parts here. Okay. So,

690
00:41:32,960 --> 00:41:36,440
so once we have these variables
then we can define what the Sh,

691
00:41:36,490 --> 00:41:39,170
what the shape and size of them are.

692
00:41:39,380 --> 00:41:43,910
So we've initialize them as parts of the
interface vector because we're going to

693
00:41:43,911 --> 00:41:45,980
then update our memory bank using these.

694
00:41:47,120 --> 00:41:50,150
So we have our set of read vectors
and our set of right vectors.

695
00:41:50,270 --> 00:41:53,750
So the keys defined where we want to,

696
00:41:55,070 --> 00:41:59,620
we will, we'll use the keys
to find a similarity between
whatever we have in our,

697
00:41:59,830 --> 00:42:03,320
our memory bank too so that we could
then read from it whatever is the most

698
00:42:03,321 --> 00:42:06,830
similar or maybe it's whatever is the
least similar that's that's up for it to

699
00:42:06,831 --> 00:42:09,020
learn with its own weights.
Right.

700
00:42:09,021 --> 00:42:11,300
It depends on the use case
and that's up for it to learn.

701
00:42:11,660 --> 00:42:15,660
A lot of these things like you
might be asking, well why, uh,

702
00:42:16,070 --> 00:42:20,000
why does it choose one place or the other?
That's all dependent on the data,

703
00:42:20,001 --> 00:42:23,980
right? It learns how to interact
with it. We're just defining the,

704
00:42:24,480 --> 00:42:25,460
the blueprint here.

705
00:42:25,460 --> 00:42:29,360
We're defining a blueprint and then it's
going to learn how to interact with the

706
00:42:29,361 --> 00:42:34,160
memory matrix, but we can
definitely improve the, uh,

707
00:42:34,820 --> 00:42:38,420
the blueprint. So, so the key
is going to be like, you know,

708
00:42:38,450 --> 00:42:40,050
it's like for a dictionary, it's, it's,

709
00:42:40,080 --> 00:42:43,790
it's the content address and
then the string is going to be,

710
00:42:44,450 --> 00:42:47,150
it's going to help us initialize
our read weights. Okay.

711
00:42:47,151 --> 00:42:48,500
This is str is going to help.

712
00:42:48,501 --> 00:42:52,130
This value is going to help us initialize
our read waits for a right factors.

713
00:42:52,131 --> 00:42:55,640
It's the same thing we have, our
key string is going to help us, uh,

714
00:42:55,790 --> 00:42:59,030
initialize our weights.
And then we have two vectors here.

715
00:42:59,040 --> 00:43:03,140
There are two components to writing.
First we erase and then we write.

716
00:43:03,200 --> 00:43:06,140
So it's like an override.
So if before we write to something,

717
00:43:06,260 --> 00:43:09,980
we wouldn't erase what's already there.
And then right over that empty space.

718
00:43:10,910 --> 00:43:12,560
Okay.
And

719
00:43:15,690 --> 00:43:15,931
yeah,

720
00:43:15,931 --> 00:43:19,800
and so then we initialize these using
the sigmoid function and then the soft

721
00:43:19,801 --> 00:43:21,870
plus, which is another, uh,

722
00:43:22,830 --> 00:43:23,300
yeah,

723
00:43:23,300 --> 00:43:25,910
which is another probability function.
Okay.

724
00:43:25,911 --> 00:43:28,730
So then we have a read vectors
in our right vectors that we,

725
00:43:28,970 --> 00:43:33,950
we've created from our interface factor,
which was one of our two outputs.

726
00:43:34,550 --> 00:43:37,310
And now we're going to define our gates.
So what are these?

727
00:43:37,430 --> 00:43:41,900
So recall from LSTM networks
from gru networks, we had gates.

728
00:43:42,130 --> 00:43:46,670
Now these gates are just ski scalar
values. They're just single numbers.

729
00:43:46,970 --> 00:43:49,160
But we call them gates
because they define,

730
00:43:50,840 --> 00:43:54,500
they define the degree to which we,
we perform a certain operation.

731
00:43:54,740 --> 00:43:59,540
So remember LSTM networks had, forget
it had each LSTM cell has a forget gate.

732
00:43:59,870 --> 00:44:04,550
Okay. And it had two other dates and
then a gru unit has a update gate.

733
00:44:04,580 --> 00:44:07,730
It's got to reset gate and
these gates to find that the,

734
00:44:08,030 --> 00:44:11,180
the degree to which we are
performing these operations,

735
00:44:11,181 --> 00:44:13,940
whether it be reset or
update and it's differential.

736
00:44:13,970 --> 00:44:16,610
Those were differentiable too.
So recall we,

737
00:44:16,640 --> 00:44:19,040
whenever we differentiated
our LSTM network,

738
00:44:19,100 --> 00:44:24,100
we updated those gate values and so then
it read and erased and in Erie or wrote

739
00:44:25,730 --> 00:44:30,380
as it as necessary as it
as it would best converge.

740
00:44:30,650 --> 00:44:33,510
So it was up to it to learn what
these gate values should be.

741
00:44:33,720 --> 00:44:38,100
Everything is learned, the right
vectors, the, the gates, the keys,

742
00:44:38,190 --> 00:44:41,250
all of it is learned through
differentiation through backpropagation.

743
00:44:43,230 --> 00:44:48,210
Okay. We're just the
beautiful architecture that
everything is, is, is learned.

744
00:44:48,270 --> 00:44:50,370
We don't define anything
sadequee except for those,

745
00:44:50,730 --> 00:44:54,750
those two lines of magic numbers
that I, that I showed you guys. Okay.

746
00:44:54,751 --> 00:44:57,510
So then we have three gates.
The first one is the free gate,

747
00:44:57,780 --> 00:45:01,950
which defines the degree to
which locations that read
heads will be freed. Okay.

748
00:45:03,690 --> 00:45:04,860
Then the allocate,

749
00:45:04,890 --> 00:45:08,010
which is the fraction of writing that
as being allocated to in a new location

750
00:45:08,520 --> 00:45:11,010
and then the right than the right gate.

751
00:45:11,040 --> 00:45:13,260
The amount of information
to be written to memory.

752
00:45:13,470 --> 00:45:17,910
So how much do we want to write to memory?
So we, so we have one gate for reading,

753
00:45:18,030 --> 00:45:22,170
one gate for writing and then one
gate for dynamic memory allocation.

754
00:45:22,171 --> 00:45:24,320
So at every time step we,

755
00:45:24,390 --> 00:45:29,040
we are deciding how much memory do want
to allocate to some, to some head value,

756
00:45:29,041 --> 00:45:32,730
whether it be a read or a right. It's
not some static dynamic. You know,

757
00:45:32,740 --> 00:45:37,710
a static allocation is dynamic. It
changes at every time step. Okay.

758
00:45:37,711 --> 00:45:39,990
So then we have one more uh,

759
00:45:40,260 --> 00:45:42,870
variable from our partition that
we talked about at the very end.

760
00:45:42,871 --> 00:45:46,620
What was that last one? It was the read
modes. So what are these read modes?

761
00:45:48,030 --> 00:45:51,870
The read heads can use gates called
read modes to switch between content,

762
00:45:51,871 --> 00:45:55,980
look up using a read key and reading out
locations either forwards or backwards

763
00:45:56,130 --> 00:45:58,800
in the order they were written.
So the mode is,

764
00:45:59,010 --> 00:46:02,160
it tells us how we should
read. Okay. So it's like,

765
00:46:02,340 --> 00:46:07,340
it's an addition to the read weights
that helps define should we read in a

766
00:46:08,041 --> 00:46:11,340
forward direction or backward direction.
And it again,

767
00:46:11,610 --> 00:46:15,690
this thing learns how to do
that. We just defined that, hey,

768
00:46:15,960 --> 00:46:18,060
there should be a direction
with word reading,

769
00:46:19,620 --> 00:46:24,620
create some differentiable value that we
can then learn to update via training.

770
00:46:25,080 --> 00:46:25,913
Okay.

771
00:46:27,060 --> 00:46:30,750
And then so we've defined
that and now we're going to,

772
00:46:36,010 --> 00:46:39,190
when I said we're going to dynamically
allocate memory, this is what I mean,

773
00:46:39,490 --> 00:46:42,430
the usage Vectra is, is, is what, what is,

774
00:46:42,730 --> 00:46:45,160
what's going to help us
dynamically allocate memory.

775
00:46:45,550 --> 00:46:47,750
So we have a retention vector,
which is this,

776
00:46:48,010 --> 00:46:50,470
which is the helper vector
for the usage factor.

777
00:46:50,740 --> 00:46:54,700
But the retention vector is used to
calculate the usage vector and it's asking

778
00:46:54,701 --> 00:46:59,650
us what's available to write to,
okay, what is available to write too.

779
00:46:59,740 --> 00:47:02,470
So then,
uh,

780
00:47:02,530 --> 00:47:06,490
we can then write to it. So let
me go back for a second. Let me,

781
00:47:06,491 --> 00:47:10,990
let me do a little high level refresher.
We had our input,

782
00:47:11,230 --> 00:47:14,980
we Ford propagated it through
the network and then we computed,

783
00:47:14,981 --> 00:47:18,550
our output vector is both the predicted
output and the interface vector.

784
00:47:18,940 --> 00:47:19,690
And then we can,

785
00:47:19,690 --> 00:47:23,110
and then we partition that interface
vector using this partition,

786
00:47:23,410 --> 00:47:28,410
a variable and the dynamic partition
function and to a set of parameters with

787
00:47:29,381 --> 00:47:33,730
which we can then interact with our memory
bank at the next time step. We then,

788
00:47:33,840 --> 00:47:38,530
uh, initialized and flattened and resized
all the reading right vectors and the

789
00:47:38,531 --> 00:47:41,920
gates, which the regionwide white
vectors. And then the gates,

790
00:47:42,040 --> 00:47:46,390
which controls the degree to which we're
reading and writing as well as the read

791
00:47:46,391 --> 00:47:48,670
modes,
which is the direction that we're reading.

792
00:47:49,270 --> 00:47:53,770
And now we're going to actually perform
the read and writing both the reading

793
00:47:53,771 --> 00:47:55,570
and the writing. Okay, so for the,

794
00:47:55,780 --> 00:47:58,300
so we're going to start
off with performing the
writing and then we'll do the

795
00:47:58,301 --> 00:48:02,050
reading. Okay, so now let me, let me write
that out. So we're going to rights first.

796
00:48:02,560 --> 00:48:04,540
So now we're going to actually
do the writing and reading.

797
00:48:04,541 --> 00:48:07,510
We define all of our variables.
Now it's time to actually do the writing.

798
00:48:07,690 --> 00:48:11,440
So for the writing will
compute our usage vector,

799
00:48:11,620 --> 00:48:13,630
which we'll use to
dynamically allocate memory.

800
00:48:14,050 --> 00:48:18,160
And then we're going to define our set
of right to waits for the right head.

801
00:48:18,430 --> 00:48:22,840
So retrieved the writing allocation
waiting. Okay. And then we just,

802
00:48:22,870 --> 00:48:27,340
we decided where to write to and then we
can define our right weights using both

803
00:48:27,341 --> 00:48:29,590
of those variables,
both the allocate,

804
00:48:29,680 --> 00:48:33,040
allocate weights and
the alloc allocate gate.

805
00:48:34,480 --> 00:48:36,220
And that's going to give
us our right weights,

806
00:48:36,460 --> 00:48:39,040
how much space to allocate for
them and where to write too,

807
00:48:39,580 --> 00:48:42,220
like how much space to dedicate
to writing and where to write too.

808
00:48:43,120 --> 00:48:47,800
And then then we can update our right
to our memory matrix using that.

809
00:48:47,950 --> 00:48:52,950
So first we recall we first
erase using this erase vector,

810
00:48:53,710 --> 00:48:58,240
then we right. And both
of these operations occur
through matrix multiplication.

811
00:48:58,720 --> 00:49:02,860
First we erase, then we right.
And that's it for writing.

812
00:49:04,000 --> 00:49:05,890
Okay,
now we're going to read.

813
00:49:05,920 --> 00:49:10,600
So we writ rewrote first and now
we're going to read. So for reading

814
00:49:12,190 --> 00:49:15,790
and guys if you sit through
this, I'm, I'm, I'm, I'm going
to wrap at the end. So, so,

815
00:49:15,850 --> 00:49:18,610
so get ready for this and we're almost
done. So I'm going to answer questions.

816
00:49:19,210 --> 00:49:22,540
Okay. I know there's a lot of
parts to this, but it's, it's,

817
00:49:22,570 --> 00:49:26,100
it's an amazing architecture and it's
definitely worth looking into. It's,

818
00:49:26,101 --> 00:49:28,510
it's an amazing architecture.
Okay.

819
00:49:28,511 --> 00:49:33,511
So we've written to our memory matrix
and now we're going to read from it.

820
00:49:33,581 --> 00:49:35,050
So as well as writing,

821
00:49:35,051 --> 00:49:38,500
the controller can read from multiple
locations and memory memory can be

822
00:49:38,501 --> 00:49:42,430
searched based on the content of each
location using content lookup or the

823
00:49:42,431 --> 00:49:46,690
associated tempura links can be followed
backwards and forwards to recall

824
00:49:46,691 --> 00:49:49,000
information written in
sequence or reverse,

825
00:49:49,090 --> 00:49:51,310
which is our third attention mechanism.
Now I haven't,

826
00:49:51,330 --> 00:49:55,810
I haven't actually talked about our, uh,
attention mechanisms yet, but let me,

827
00:49:56,410 --> 00:50:00,070
this is going to be our
first, which is, uh,

828
00:50:00,400 --> 00:50:05,230
which is recalling memory using
our tempura links, which is that,

829
00:50:05,231 --> 00:50:09,460
remember that Matrix of, of arrows
right up here. That's going to be our,

830
00:50:09,490 --> 00:50:13,420
that's essentially an attention
mechanism. Like how do we, uh,

831
00:50:13,960 --> 00:50:16,990
we didn't write to memory based
on what's happened before. Okay.

832
00:50:16,991 --> 00:50:21,670
So we'll define our link matrix,
which is that those,

833
00:50:21,671 --> 00:50:23,620
those sets of arrows,
that third matrix,

834
00:50:23,810 --> 00:50:27,500
that the third big matrix
I talked about using, uh,

835
00:50:27,660 --> 00:50:31,820
though the weight factor that we defined
here at using our right are right with

836
00:50:31,910 --> 00:50:34,190
vape weights. Okay. And so then

837
00:50:36,590 --> 00:50:41,590
we'll use the link matrix and our right
weights to define our precedence weights

838
00:50:42,680 --> 00:50:45,500
and our precedents weight
is going to help us

839
00:50:47,600 --> 00:50:49,670
with our,
let's see what else.

840
00:50:58,450 --> 00:50:59,283
Okay,

841
00:50:59,790 --> 00:51:01,440
so then are precedents,
wait,

842
00:51:06,590 --> 00:51:07,790
so we don't actually,

843
00:51:14,060 --> 00:51:15,640
okay, so we, so the precedents waste,

844
00:51:15,660 --> 00:51:20,210
which was used to create the link Matrix
and then we updated it right here.

845
00:51:20,211 --> 00:51:21,890
So we just updated it like we've,

846
00:51:21,891 --> 00:51:25,490
we've used it to define our link Matrix
and now we can just update it. Okay.

847
00:51:26,740 --> 00:51:30,230
And so let me make sure you
guys can see this. Okay.

848
00:51:30,350 --> 00:51:34,610
So now we're going to define our three
modes. Remember our read modes forward,

849
00:51:34,611 --> 00:51:38,240
backward and content.
Look up by using matrix multiplication on,

850
00:51:38,300 --> 00:51:41,380
on our read weights. Okay. Uh, for,

851
00:51:41,381 --> 00:51:44,300
for three modes and these
are all differentiable,

852
00:51:44,301 --> 00:51:46,880
all the modes are differentiable.
And

853
00:51:49,000 --> 00:51:51,820
for lookup we're going to diff, we're
going to initialize it using content,

854
00:51:51,821 --> 00:51:54,250
look up.
And then we're going to,

855
00:51:54,820 --> 00:51:58,150
now we can initialize our read
weights using those three modes.

856
00:51:58,540 --> 00:52:02,770
And then we'll create our read vector
using the redx weights and the memory

857
00:52:02,771 --> 00:52:03,580
matrix.

858
00:52:03,580 --> 00:52:08,140
And then we multiply it together to get
a read or read vector and then we can

859
00:52:08,141 --> 00:52:13,141
return it as the sum of our
outputs and what we just,

860
00:52:13,630 --> 00:52:14,380
uh,

861
00:52:14,380 --> 00:52:18,700
calculated that product value that which
is what we've now read from memory and

862
00:52:18,730 --> 00:52:22,510
we feed it back into the
next time step. Right? Okay.

863
00:52:22,600 --> 00:52:26,500
And so what this, what this function
right here is this run function is,

864
00:52:26,730 --> 00:52:30,400
is it's essentially just,
uh,

865
00:52:30,820 --> 00:52:32,920
creating the outputs for,

866
00:52:33,130 --> 00:52:35,950
for each of the inputs using unstack

867
00:52:37,510 --> 00:52:40,690
a sequence of outputs. So this,
this just generates are, are,

868
00:52:40,700 --> 00:52:44,650
are associated output sequence. So
a small little helper function. Uh,

869
00:52:44,651 --> 00:52:49,020
but okay. So also, let me go back and
now let me define the other two, uh,

870
00:52:49,300 --> 00:52:52,300
attention mechanism. So we talked
about one of the attention mechanisms,

871
00:52:52,450 --> 00:52:56,380
which was the, uh, Tempura linkage, right?

872
00:52:56,530 --> 00:53:00,790
How do we define the order with which
we are updating our memory bank?

873
00:53:00,880 --> 00:53:02,770
But there are two more
attention mechanisms here.

874
00:53:02,890 --> 00:53:05,650
The first one is content
lookup, right? So remember it's,

875
00:53:05,651 --> 00:53:09,100
it's kind of like recommendation
systems. It's kind of like, you know, uh,

876
00:53:10,900 --> 00:53:13,750
word vectors where we are finding
the distance between two vectors.

877
00:53:13,930 --> 00:53:16,720
We're doing that with our
controller and our memory bank.

878
00:53:16,780 --> 00:53:21,070
So whenever we're reading from, uh, our
memory bank where we have a vector here,

879
00:53:21,071 --> 00:53:24,760
right, the, the read wait vector.
And then we have our vectors,

880
00:53:24,761 --> 00:53:26,610
which are all the rows in the memory bank.

881
00:53:26,820 --> 00:53:30,540
And we want to find a similarity between
all of them and then find the one that

882
00:53:30,541 --> 00:53:34,380
is either the most similar or the least
similar and it's up to it to learn what

883
00:53:34,620 --> 00:53:35,453
like level of,

884
00:53:35,500 --> 00:53:39,900
of similarity it needs to then read from
it learns where to read from using this

885
00:53:39,901 --> 00:53:41,700
content.
Look up attention mechanism.

886
00:53:42,030 --> 00:53:46,200
So we find the l two norm of using the
key. So let me, let me read this out.

887
00:53:46,380 --> 00:53:49,890
A key vector emitted by the controller
is compared to the content of each

888
00:53:49,891 --> 00:53:52,590
location in memory according
to a similarity measure.

889
00:53:52,890 --> 00:53:54,210
The similarity score is determined,

890
00:53:54,211 --> 00:53:58,380
a weighting that can be used by the heads
for associative recall or by the right

891
00:53:58,381 --> 00:54:02,190
head to modify an existing vector
in memory. So we have a key, uh,

892
00:54:02,191 --> 00:54:04,830
Riki and we then compute the l two norm,

893
00:54:05,040 --> 00:54:07,350
which is a way of normalizing of vector.

894
00:54:07,351 --> 00:54:09,360
It's a standard formula
for normalizing a vector.

895
00:54:09,540 --> 00:54:12,990
It's a square root of the sum
of the absolute values squared.

896
00:54:13,110 --> 00:54:15,840
So if we take all of the components
of a vector, square them,

897
00:54:15,841 --> 00:54:19,290
and then square root it,
and that's going to be r a l two norm.

898
00:54:20,130 --> 00:54:23,070
And we'll do that for both
the memory matrix and the key.

899
00:54:23,250 --> 00:54:26,910
And then we'll perform a
matrix multiplication to
compute these similarity.

900
00:54:27,120 --> 00:54:29,670
And then we'll squash it with
a soft Max and return that.

901
00:54:29,840 --> 00:54:31,410
And that's gonna give
us a probability value.

902
00:54:31,411 --> 00:54:36,411
That is a percentage of how similar
the key is to to the memory matrix.

903
00:54:37,170 --> 00:54:39,750
So that's, that's one, that's
our second attention mechanism.

904
00:54:39,930 --> 00:54:43,620
And then our third attention mechanism
is the actual dynamic allocation of

905
00:54:43,621 --> 00:54:46,740
memory as we, as we train
this model. So how do we,

906
00:54:46,741 --> 00:54:51,060
so basically what this does is it
retrieves the writing allocation weighting

907
00:54:51,061 --> 00:54:52,650
based on the usage free list.

908
00:54:52,830 --> 00:54:56,850
So which is the usage of vector and the
usage of each location is represented as

909
00:54:56,851 --> 00:55:01,410
a number between zero and one and a
weighting that picks out unused locations.

910
00:55:01,500 --> 00:55:05,190
It's delivered to the right head,
it's independent of the size.

911
00:55:05,191 --> 00:55:09,130
And the contents of the men memory.
So that means that you can use a on,

912
00:55:09,240 --> 00:55:10,350
you can use a DNC,

913
00:55:10,351 --> 00:55:15,150
this DNC on a task where using one size
of memory and later you can upgrade to a

914
00:55:15,151 --> 00:55:19,290
larger memory. So it's independent of
sizes. See the only parameter for it,

915
00:55:19,291 --> 00:55:21,690
his self that we're not
telling it well you should be,

916
00:55:21,900 --> 00:55:24,660
you should allocate memory
of this size of exercise.

917
00:55:24,870 --> 00:55:28,140
It decides that for itself and it
can be arbitrarily big or small.

918
00:55:28,380 --> 00:55:30,840
Theoretically it could
be infinity. Okay. So

919
00:55:32,670 --> 00:55:37,420
we are then taking the sorted
usage vector. We're going
to sort the usage vector,

920
00:55:37,840 --> 00:55:39,330
uh, uh, sending lea,

921
00:55:39,600 --> 00:55:43,140
and then we're going to compute the
cumulative product of all of those

922
00:55:43,141 --> 00:55:44,460
components.
And then for,

923
00:55:44,580 --> 00:55:48,750
and then you and then initialize our
allocation weights using those values.

924
00:55:49,260 --> 00:55:50,850
And then for each of our use of vectors,

925
00:55:50,970 --> 00:55:54,300
we're going to flatten it and then add
it to the weight matrix and return the

926
00:55:54,301 --> 00:55:56,370
allocation waiting for each row in memory.

927
00:55:56,620 --> 00:56:01,620
This is essentially a matrix of allocation
values that we can then use to decide

928
00:56:01,920 --> 00:56:03,510
how best we want to allocate memory.

929
00:56:03,540 --> 00:56:06,750
So it's a matrix that we were
returning from this. Okay, so that's,

930
00:56:06,751 --> 00:56:09,420
those are our three attention mechanisms.
I know it's a lot to take in,

931
00:56:09,720 --> 00:56:11,340
but those are our three
attention mechanisms.

932
00:56:11,341 --> 00:56:16,020
And now let's get to our main function
and we'll talk about how we can actually

933
00:56:16,021 --> 00:56:19,290
use this. We, we've defined everything,
we didn't find our attention mechanisms,

934
00:56:19,500 --> 00:56:24,500
our parameters are hyper parameters are
components of our differential neural

935
00:56:24,640 --> 00:56:27,700
computer and now it's time for us
to actually train this, this thing.

936
00:56:28,000 --> 00:56:31,690
So we'll start off by defining these
parameters and these parameters are going

937
00:56:31,691 --> 00:56:35,950
to be used, are going to be used to
initialize our data randomly, right?

938
00:56:36,340 --> 00:56:40,270
This random dot ran into is going to
initialize our input data and our output

939
00:56:40,271 --> 00:56:45,130
data, which are a set of binary
numbers ones and Zeros. Okay?

940
00:56:45,131 --> 00:56:49,840
So now we'll go ahead and initialize
or tensor flow session initialize a

941
00:56:49,841 --> 00:56:52,870
differentiable and your old
computer and then run it.

942
00:56:52,900 --> 00:56:55,960
And the run function is then going
to compute the output. It's gonna,

943
00:56:56,230 --> 00:57:00,700
it's gonna run this step function seat
that we defined this huge step function.

944
00:57:00,701 --> 00:57:04,450
It's going to at every time step for a
number of iterations we want and it's

945
00:57:04,451 --> 00:57:09,250
going to output the, you know, whatever
that output's going to be like one zero,

946
00:57:09,251 --> 00:57:11,410
zero, zero like that. That's
going to be the output.

947
00:57:11,740 --> 00:57:15,880
And then once we have our predicted
output and we have our expected output,

948
00:57:16,450 --> 00:57:18,910
we then want to compute
the loss between those.

949
00:57:18,911 --> 00:57:21,970
And we'll do that with a dis
sigmoid cross entropy function.

950
00:57:22,270 --> 00:57:26,740
And that's gonna give us our loss then.
And this is use case dependent,

951
00:57:26,770 --> 00:57:28,810
we don't always have to do this,
but we're doing it right now.

952
00:57:28,960 --> 00:57:32,530
We're going to regularize
each layer of our controller.

953
00:57:33,040 --> 00:57:35,530
And what regularization does is it can

954
00:57:37,090 --> 00:57:41,890
improve convergence sometimes. Okay.
And we'll use the l two loss to do that,

955
00:57:43,610 --> 00:57:44,920
which is similar to the l two norm.

956
00:57:45,580 --> 00:57:49,600
And then once we have that we'll add
the regular risers in and then we'll

957
00:57:49,601 --> 00:57:51,760
optimize it using Adam,
which is grading dissent.

958
00:57:51,970 --> 00:57:55,180
And so when we do gradient descent,
it's being applied to the controller,

959
00:57:55,181 --> 00:57:56,440
the memory bank,
their head,

960
00:57:56,740 --> 00:58:01,510
the three attention mechanisms and
the team portal linkage matrix.

961
00:58:01,990 --> 00:58:05,650
Everything is, is, is differentiable.
And once we've done that,

962
00:58:05,651 --> 00:58:10,030
we can initialize all of our variables
and then initialize our input and output

963
00:58:10,031 --> 00:58:11,170
data using the,

964
00:58:11,560 --> 00:58:14,560
The v the variables we defined right up
here that I talked about right up here.

965
00:58:15,940 --> 00:58:19,420
And then for each iteration
we're going to feed in the pair,

966
00:58:19,930 --> 00:58:20,960
each input output pairings,

967
00:58:20,980 --> 00:58:25,690
your feed dect and then run our session
using our loss optimizer and output and

968
00:58:25,691 --> 00:58:29,770
then feeding in our input and outputs.
And that's going to give us our results.

969
00:58:30,010 --> 00:58:34,600
And let me run this again,
which is the code, but in it's,

970
00:58:34,620 --> 00:58:36,850
it's in a,
I literally just took this from a,

971
00:58:37,180 --> 00:58:41,350
a python file and then paste
it into a Jupiter notebook.

972
00:58:41,470 --> 00:58:43,270
So let me do it from,
from command line,

973
00:58:43,630 --> 00:58:47,040
which is a python DNC to pot.
Nope,

974
00:58:47,440 --> 00:58:49,780
both on TNC dot pie.
Okay.

975
00:58:52,900 --> 00:58:56,950
Bunch of warnings because we've
got a lot of, uh, you know, things,

976
00:58:57,100 --> 00:58:59,500
a lot of deprecations happening.
Okay.

977
00:59:04,060 --> 00:59:04,990
Okay.
So

978
00:59:11,580 --> 00:59:13,380
I just want to see what everyone's
saying here. Okay, great.

979
00:59:16,200 --> 00:59:18,150
I know I should write a book.
I did write a book,

980
00:59:18,151 --> 00:59:20,490
it's called decentralized applications.
I'll probably write a book later,

981
00:59:20,491 --> 00:59:23,480
but I've got to do a lot of other
things first. So, uh, other questions.

982
00:59:23,690 --> 00:59:28,220
Can we run DNC on calming home
PC? Yes, you can. If you have a,

983
00:59:28,520 --> 00:59:31,430
any kind of computer, you can run this
thing because look at this. I mean this,

984
00:59:33,320 --> 00:59:37,670
this is just binary scalar values.
I mean,

985
00:59:37,850 --> 00:59:39,260
you don't need a Gpu for this.

986
00:59:39,261 --> 00:59:44,261
You just need to CPU and
any kind of numerical data
you can run easily on a CPU,

987
00:59:44,571 --> 00:59:48,410
on a home PC. But if you want to start
applying this to graph traversal problems,

988
00:59:48,411 --> 00:59:52,400
like deep minded, like solving
the, the London Underground,
like the shortest path,

989
00:59:53,530 --> 00:59:56,900
uh, then you need a Gpu. But you
could still do this on a home PC.

990
00:59:56,901 --> 01:00:01,070
You don't need a cluster for this one.
Would you need a cluster?

991
01:00:01,220 --> 01:00:05,450
If you are applying this to natural
language, then you need a cluster.

992
01:00:05,451 --> 01:00:08,360
If you're applying this, if you want
to create a question answering system,

993
01:00:08,570 --> 01:00:13,100
then you want to, you do this in
the cloud. Okay. Using, uh, using,

994
01:00:14,860 --> 01:00:18,670
I have a video on that coming out in
two days. So I'll, I'll tell you guys,

995
01:00:18,760 --> 01:00:23,110
use Floyd hub use Floyd hub. Okay. But I
have, I have a video coming out on that.

996
01:00:23,590 --> 01:00:25,330
Okay. So on cloud options. Okay.

997
01:00:25,360 --> 01:00:29,980
So we've got two minutes and I'm going
to spend the rest of this session

998
01:00:30,010 --> 01:00:33,220
answering questions for the
last two minutes. But, uh,

999
01:00:34,640 --> 01:00:38,840
I also want to play this in the
background because it's, it's cool. Okay.

1000
01:00:39,230 --> 01:00:41,900
This is what you can
do, right? Associations,

1001
01:00:41,960 --> 01:00:45,890
associations between unrelated datasets,
whether the beat language,

1002
01:00:45,920 --> 01:00:50,920
natural language or graph traversal or
image recognition or speech recognition

1003
01:00:51,261 --> 01:00:56,261
or speech generation or audio generation
or graphics generation or you know,

1004
01:00:59,330 --> 01:01:04,330
all sorts of different domains can be
learned if we have an external memory

1005
01:01:04,850 --> 01:01:09,410
memory store that acts as the blueprint
to then create these learning systems,

1006
01:01:09,411 --> 01:01:10,400
these neural networks.

1007
01:01:10,610 --> 01:01:14,360
So we separate the processing from the
memory and we have results that make our

1008
01:01:14,361 --> 01:01:18,530
hearts sing. So for the last
set of questions we have here,

1009
01:01:20,920 --> 01:01:21,753
uh,

1010
01:01:27,760 --> 01:01:32,230
do you know if they invited people for
the Ai Nanodegree I don't know. Uh, and

1011
01:01:34,230 --> 01:01:37,810
live stream next week.
So this is the last livestream for awhile.

1012
01:01:37,880 --> 01:01:41,720
I've been doing live streams for the past
17 weeks and it's been super fun. Uh,

1013
01:01:41,930 --> 01:01:45,330
this is a Ted talk and,
uh,

1014
01:01:45,400 --> 01:01:48,780
instead I'm going to be doing
something similar. It's,

1015
01:01:48,781 --> 01:01:52,450
it's going to be a prerecorded version
of like me, you know, typing out stuff.

1016
01:01:52,660 --> 01:01:56,200
It's not going to be live at
least for a while. Uh, and yeah,

1017
01:01:56,201 --> 01:01:58,000
you're still going to get
amazing content like this.

1018
01:01:58,001 --> 01:02:02,110
It's just not always going to be live.
Uh, I will do lives again in the future.

1019
01:02:02,111 --> 01:02:06,160
Don't worry. I know. It's not like I'm
stopping my lives and, uh, yeah. So,

1020
01:02:06,161 --> 01:02:06,761
but this is,

1021
01:02:06,761 --> 01:02:11,761
this is this differentiable
neural computer is the future.

1022
01:02:12,250 --> 01:02:17,010
This is this idea of separating
processing and memory is the future. Okay.

1023
01:02:17,030 --> 01:02:21,540
Let me, let me wrap as well to, to the
sa out. So just throw on a beat and um,

1024
01:02:21,570 --> 01:02:22,680
I'll wrap about something.

1025
01:02:24,400 --> 01:02:25,233
Okay.

1026
01:02:26,340 --> 01:02:29,040
Thank you guys for staying through
the session. You guys are heroes.

1027
01:02:29,220 --> 01:02:31,050
I'm very proud of you
for staying through this.

1028
01:02:31,051 --> 01:02:33,900
This is nontrivial and the fact
that you stayed through this,

1029
01:02:33,930 --> 01:02:37,260
it makes me very proud of you and very
proud to be a part of this community that

1030
01:02:37,261 --> 01:02:40,940
we are all in together. So whenever
you guys are ready, go ahead and, uh,

1031
01:02:42,330 --> 01:02:43,260
play that beat.

1032
01:02:43,620 --> 01:02:47,480
How much data does this
need? It depends. Uh,

1033
01:02:48,210 --> 01:02:52,200
it depends, uh, how much data
it needs on what your use cases.

1034
01:02:54,310 --> 01:02:58,940
Oh, I definitely need you guys. Okay.
I'm going to keep having livestreams.

1035
01:02:58,980 --> 01:03:03,570
Don't worry about it. Uh, just, just not
the, you know, current time being. Okay.

1036
01:03:05,640 --> 01:03:09,390
I love the DNC.
I try to do it like I want to be me.

1037
01:03:09,600 --> 01:03:12,030
I don't care about all these models.
You see,

1038
01:03:12,270 --> 01:03:17,270
I only want to use something that takes
three different data sets and put them

1039
01:03:17,491 --> 01:03:21,960
together. You see, look, I take
a one die. You didn't converge.

1040
01:03:22,110 --> 01:03:25,260
The beat stops, but it doesn't
matter, man. I'm like, I splurge.

1041
01:03:25,290 --> 01:03:27,960
I burst out into the
world like on the king.

1042
01:03:28,290 --> 01:03:30,420
Don't stop and look at
on machine learning mat.

1043
01:03:30,570 --> 01:03:35,520
It's like being the worst service
ever created by Microsoft. Oh, I just,

1044
01:03:35,521 --> 01:03:39,960
this Microsoft man, don't
look before I get shot. Okay,

1045
01:03:40,140 --> 01:03:44,790
so that's the wrap. All right. So
thank you guys for showing up for now.

1046
01:03:44,791 --> 01:03:48,120
I've got to go create some,
some more amazing content for you guys.

1047
01:03:48,270 --> 01:03:52,850
Thank you for showing up. I love you
guys and cool. Thanks for watching. Huh?

