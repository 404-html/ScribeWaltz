1
00:00:00,190 --> 00:00:03,760
Cloud or edge. Why not? Both.

2
00:00:04,590 --> 00:00:05,300
Okay.

3
00:00:05,300 --> 00:00:06,050
Hello world,

4
00:00:06,050 --> 00:00:11,050
it's Saroj and until recently released a
toolkit for developers called open Vino

5
00:00:12,140 --> 00:00:17,140
to help build computer vision applications
that can be used at the edge or in

6
00:00:17,301 --> 00:00:18,134
the cloud.

7
00:00:18,260 --> 00:00:23,180
Open Beano stands for open visual
inference and neural network optimization.

8
00:00:23,480 --> 00:00:28,480
The toolkit is available for both windows
and Linux platforms and it enables us

9
00:00:29,811 --> 00:00:34,280
to use convolutional neural networks
for computer vision at the edge.

10
00:00:34,640 --> 00:00:39,640
It also supports heterogeneous
execution across Intel's computer vision

11
00:00:39,860 --> 00:00:44,860
accelerators using a common API for
the CPU Intel integrated graphics,

12
00:00:45,350 --> 00:00:49,700
the Intel Mobidius neural compute stick,
which I already made a video about.

13
00:00:49,910 --> 00:00:52,910
An FPGA basically develop once,

14
00:00:52,940 --> 00:00:57,680
deploy anywhere and since computer
vision can be difficult to master,

15
00:00:57,890 --> 00:01:02,890
it includes an easy to use library of
CBE functions and pre optimized kernels.

16
00:01:03,590 --> 00:01:07,640
This can be applied to a whole range
of applications like face detection,

17
00:01:07,910 --> 00:01:11,120
object detection and
license plate recognition,

18
00:01:11,121 --> 00:01:14,660
which we'll demo in this video.
Using these dependencies.

19
00:01:14,661 --> 00:01:19,130
It's inference engine can run deep
learning models easily and its model

20
00:01:19,131 --> 00:01:24,131
optimizer imports converts and optimizes
models that were trained in standard

21
00:01:24,801 --> 00:01:28,670
frameworks into a format
and usable by Intel tools.

22
00:01:28,820 --> 00:01:33,140
Like the inference engine. If you don't
feel like training your own model,

23
00:01:33,200 --> 00:01:38,150
the toolkit comes with a
bunch of different pretrained
models you can use at the

24
00:01:38,151 --> 00:01:38,751
low level.

25
00:01:38,751 --> 00:01:43,751
The toolkit includes support for both
the open CV and open VX computer vision

26
00:01:44,391 --> 00:01:48,110
libraries,
especially optimized for Intel hardware.

27
00:01:48,320 --> 00:01:53,320
It also has an included media SDK
that offers us access to hardware,

28
00:01:53,600 --> 00:01:56,900
accelerated video codecs
and frame processing,

29
00:01:57,290 --> 00:02:02,290
and it enables the use of the popular
open cl library on the GPU or CPU for

30
00:02:02,931 --> 00:02:04,130
Intel processors.

31
00:02:04,190 --> 00:02:08,870
Optimizing and deploying one of these
models is relatively easy. First,

32
00:02:08,871 --> 00:02:13,070
we just configure the model optimizer
for whichever framework we're using,

33
00:02:13,130 --> 00:02:17,000
including tensorflow on x,
mx net and cafe.

34
00:02:17,360 --> 00:02:22,220
Then we can convert a trained model
to produce an optimized intermediate

35
00:02:22,221 --> 00:02:27,221
representation of the model based on the
trained networked apology weights and

36
00:02:27,471 --> 00:02:28,490
bias values.

37
00:02:28,730 --> 00:02:32,930
We can then test the
model in the intermediate
representation format using the

38
00:02:32,960 --> 00:02:37,460
inference engine in the target environment
via either the provided inference

39
00:02:37,461 --> 00:02:42,020
engine validation application or
one of several sample applications.

40
00:02:42,290 --> 00:02:42,861
Lastly,

41
00:02:42,861 --> 00:02:47,480
we can integrate the inference engine
into our application to deploy the model

42
00:02:47,510 --> 00:02:48,950
in the target environment.

43
00:02:49,070 --> 00:02:54,070
So let's demo the example of using open
Beano to perform vehicle detection,

44
00:02:54,111 --> 00:02:57,380
which will detect a car
and it's licensed plate.

45
00:02:57,770 --> 00:03:00,640
We'll want to use a
pretrained model for this,

46
00:03:00,730 --> 00:03:04,210
specifically the faster or CNN model.

47
00:03:04,570 --> 00:03:09,130
This is actually to neural networks
eight regional proposal network that

48
00:03:09,131 --> 00:03:14,131
generates region proposals and a
network using these proposals to detect

49
00:03:14,260 --> 00:03:15,093
objects.

50
00:03:15,340 --> 00:03:20,340
The output of the RPN is a bunch of boxes
that will be examined by a classifier

51
00:03:21,220 --> 00:03:25,060
and regressor to eventually
check the occurrence of objects.

52
00:03:25,390 --> 00:03:30,390
The RPN thus predicts the possibility
of a box being background or foreground

53
00:03:30,550 --> 00:03:32,530
and refines it in the first step.

54
00:03:32,531 --> 00:03:35,830
The input image goes through
the convolutional network,

55
00:03:35,950 --> 00:03:40,600
which will output a set of convolutional
feature maps on the last convolutional

56
00:03:40,601 --> 00:03:45,340
layer. Then a sliding window. It's
run spatially on these feature maps.

57
00:03:45,580 --> 00:03:49,630
For each sliding window.
A set of nine anchor boxes are generated,

58
00:03:49,750 --> 00:03:51,400
which all have the same center,

59
00:03:51,460 --> 00:03:56,230
but with three different aspect ratios
and three different scales. Lastly,

60
00:03:56,231 --> 00:04:00,880
the spatial features extracted from these
convolutional feature maps are given

61
00:04:00,881 --> 00:04:05,740
to a smaller network, which has two
tasks, classification and regression.

62
00:04:06,250 --> 00:04:09,670
The output of the regressor
decides the predicted bounding box.

63
00:04:09,880 --> 00:04:14,320
The output of the classification sub
network is a probability p indicating

64
00:04:14,321 --> 00:04:18,760
whether the predicted box contains
an object or it's from a background.

65
00:04:18,970 --> 00:04:21,160
We can download the weights,
metadata,

66
00:04:21,220 --> 00:04:25,780
and model weights directly from
Github and Dropbox respectively.

67
00:04:26,020 --> 00:04:30,370
It's a cafe model so we can run it
through the model optimizer using the

68
00:04:30,371 --> 00:04:32,110
following command in terminal.

69
00:04:32,440 --> 00:04:36,790
This will create an
intermediate representation
that our inference engine can

70
00:04:36,820 --> 00:04:41,820
serve when we run the application will
receive an output file labeled zero dot

71
00:04:42,161 --> 00:04:44,680
BMP.
When we opened that file,

72
00:04:44,681 --> 00:04:47,920
we'll see the detected car
and closed in rectangles.

73
00:04:48,220 --> 00:04:52,780
It outputs the list of classes of the
detected objects along with the respected

74
00:04:52,781 --> 00:04:57,040
confidence values and the coordinates of
the rectangles and the standard output

75
00:04:57,041 --> 00:04:58,570
stream.
As you can see,

76
00:04:58,571 --> 00:05:02,830
this high performance
library makes computer vision
really simple for anyone to

77
00:05:02,831 --> 00:05:07,090
try. I've linked to some great resources
to learn more in the video description,

78
00:05:07,091 --> 00:05:10,330
including a link to the free
download on the open VNL website.

79
00:05:10,480 --> 00:05:12,580
Please subscribe for
more programming videos,

80
00:05:12,581 --> 00:05:16,180
and for now I've got to keep it
open source, so thanks for watching.

