1
00:00:00,300 --> 00:00:05,160
Here we go. I'm about to start
starting the stream. All right.

2
00:00:05,640 --> 00:00:09,900
Okay. Okay. Okay. Okay. Okay,

3
00:00:10,140 --> 00:00:14,400
here we go. Here we go. Here we
go. Um, all right. Hello world.

4
00:00:14,401 --> 00:00:17,980
It's a Raj and welcome to my live stream.
Um,

5
00:00:18,060 --> 00:00:22,800
in this livestream I'm going to
build a machine learning Api, uh,

6
00:00:22,801 --> 00:00:25,440
and it's called a neural
style transfer Api. And why?

7
00:00:25,441 --> 00:00:30,000
Talk about it if I can just show you.
Okay. So here is the base image. Okay.

8
00:00:30,001 --> 00:00:33,060
It's this best laptop for
machine learning image.

9
00:00:33,300 --> 00:00:38,280
And when I feed it into style transfer,
it's going to become this.

10
00:00:38,430 --> 00:00:39,610
Okay?
So it's going to do that.

11
00:00:39,611 --> 00:00:43,740
So what I want to do is just do another
demo and just show you really quickly

12
00:00:44,350 --> 00:00:46,830
how this works. Hi everybody.
It's good to see you.

13
00:00:46,831 --> 00:00:50,040
I have a little chat window
here of everybody here. Hello.

14
00:00:50,041 --> 00:00:54,630
We're all blessings from Norway. Wow. The
Vikings, the vikings are alive and well.

15
00:00:55,440 --> 00:00:58,050
Oh Man, I'm so happy to
see you guys. Uh, I wanted,

16
00:00:58,140 --> 00:01:01,680
I kind of like last minute decided to
do a livestream because, uh, you know,

17
00:01:01,681 --> 00:01:04,530
I set up a live stream studio and uh,
it's time.

18
00:01:04,620 --> 00:01:08,250
So I really want to do these weekly,
right? So, so that, that's the goal. Okay,

19
00:01:08,251 --> 00:01:10,230
so down to business.

20
00:01:10,290 --> 00:01:14,880
So what we've got here is we've got this
little app file and inside of this app

21
00:01:14,881 --> 00:01:18,210
fall, I have my, my thumbnail
videos that I use for youtube.

22
00:01:18,450 --> 00:01:22,790
And so what I want to do is I'm going to,
um,

23
00:01:22,980 --> 00:01:25,410
take that image and I'm
going to send it to my API.

24
00:01:25,411 --> 00:01:29,880
So what I did was I created an API
and so I can send that image there.

25
00:01:29,881 --> 00:01:34,290
So here's the, here's the console.
Let me open up the console.

26
00:01:34,291 --> 00:01:38,310
We got people from all over the
world here in Malaysia, India,

27
00:01:38,340 --> 00:01:42,210
Casa Blanca as a movie, Saudi
Arabia, Canada, Nantucket,

28
00:01:42,460 --> 00:01:46,440
Nan Tuck it. That's what's up right there.
I think that's like a, a jam as well.

29
00:01:46,560 --> 00:01:51,320
Nantucket jam sounds like
it would be though, right?
Like a peach jam. All right,

30
00:01:51,330 --> 00:01:55,260
so let me send this uh,
image test.

31
00:01:55,320 --> 00:02:00,270
I remember I called it test three
or jpeg. I'm sending it to, uh, the,

32
00:02:00,630 --> 00:02:04,020
hold on, it's not called test three
is called test two. Dot. Jpeg.

33
00:02:06,230 --> 00:02:10,980
Uh, who test two. Dot. Jpeg and okay,

34
00:02:10,981 --> 00:02:14,210
hold on. Gimme a second.
Gimme a second here. Uh

35
00:02:17,940 --> 00:02:21,000
Oh no. Yes, I see. It's because it's
not a Jpeg, right? It's gotta be,

36
00:02:21,001 --> 00:02:23,720
it's gotta be be a jpeg right now.
It's an,

37
00:02:23,721 --> 00:02:28,200
it's a PNG de image files.
We got Utah,

38
00:02:28,680 --> 00:02:32,310
Utah. What's up Utah? Okay, so test
three now. Now let's do this again.

39
00:02:32,311 --> 00:02:34,680
Let's do this again. You
Ready? Ready? So remember that,

40
00:02:34,681 --> 00:02:38,670
how to learn mathematics fast
image I just showed you guys now.

41
00:02:39,870 --> 00:02:41,370
Okay, here we go. Here we go.

42
00:02:42,140 --> 00:02:44,720
I thought the data machine
learning is happening in France,

43
00:02:44,870 --> 00:02:49,290
in France on a trained neural style
transfer model is happening as we speak

44
00:02:49,291 --> 00:02:53,430
right now.
And when it is done,

45
00:02:54,210 --> 00:02:59,190
we will see that output.
Okay, so where is that output?

46
00:03:00,910 --> 00:03:05,680
Where is that output? So you saw that,

47
00:03:05,681 --> 00:03:09,070
right? That did not exist before and that
is some machine learning right there.

48
00:03:09,190 --> 00:03:14,020
I took my plain little image and I turned
it into this style transferred image.

49
00:03:14,230 --> 00:03:17,350
Okay, so that's, that's it's
tutorial for today's video. Okay.

50
00:03:17,351 --> 00:03:19,810
So I'm going to show you guys how
to do that in the cloud. Okay.

51
00:03:19,811 --> 00:03:23,350
So you can build this code yourself.
I don't care where you are,

52
00:03:23,351 --> 00:03:24,460
I don't care who you are.

53
00:03:24,700 --> 00:03:29,550
You will build this code and you
will in four command line, uh,

54
00:03:30,580 --> 00:03:32,200
for commands on command line.

55
00:03:32,350 --> 00:03:36,040
You will send this to the cloud
and create an Api just like that,

56
00:03:36,041 --> 00:03:38,380
that you can run in France on.
You could curl the image,

57
00:03:38,381 --> 00:03:41,830
you could send a post request,
you can build a service.
That's how this goes. Okay,

58
00:03:41,831 --> 00:03:44,680
so we're going to start off with this.
Okay.

59
00:03:44,681 --> 00:03:47,620
So also also before I started doing this,

60
00:03:47,621 --> 00:03:51,710
I'm just going to say 10
names just to, you know, done.

61
00:03:51,720 --> 00:03:56,470
Y'All fit tra polar bear at Lewis,
RB Schick, Ali, David and Ben.

62
00:03:56,560 --> 00:03:58,600
Thank you guys for being here.
So let's get started. Okay,

63
00:03:58,630 --> 00:04:01,960
so for people who are watching
this recorded, we wanna,

64
00:04:01,990 --> 00:04:05,290
I wanna I want to satisfy both
the live and my recorded audience.

65
00:04:05,590 --> 00:04:09,340
So we have three steps to do this. The
steps, step one is to build the model,

66
00:04:09,341 --> 00:04:12,490
of course, right? We've got to build
the model and once we build the model,

67
00:04:12,491 --> 00:04:14,590
then we can train the model on Floyd hubs.

68
00:04:14,591 --> 00:04:18,910
I'm going to talk about a service called
Floyd hub. It's not the best service.

69
00:04:18,940 --> 00:04:20,530
Okay?
I just want to say that it's not the best,

70
00:04:20,531 --> 00:04:24,100
but it is the best for beginners just
to get something quick and dirty.

71
00:04:24,101 --> 00:04:28,510
Up and running. Floyd hub
is great. All right. If you
want to start scaling really,

72
00:04:28,511 --> 00:04:31,300
really scaling to, you know,
hundreds of thousands of users,

73
00:04:31,450 --> 00:04:33,040
then you want to move to AWS,

74
00:04:33,130 --> 00:04:35,650
then you want to move to
Google cloud or even a zero.

75
00:04:35,680 --> 00:04:40,270
And I'll have videos on each of those
individual platforms coming out soon,

76
00:04:40,271 --> 00:04:41,830
either next week or the week after that.
Okay?

77
00:04:41,831 --> 00:04:44,590
So the third step is to
serve the model via an API.

78
00:04:44,591 --> 00:04:48,400
So if you're not familiar with neural
style transfer, here's how it goes, right?

79
00:04:48,401 --> 00:04:50,650
You have an image, right? It
could be me, it could be you.

80
00:04:51,010 --> 00:04:54,700
And then you have a source image and
that's the style that you want to transfer

81
00:04:54,701 --> 00:04:59,020
to your base image. And when you do
that, boom you get, you get this filter.

82
00:04:59,050 --> 00:05:03,190
And this paper came out I think
four years ago, four years ago now,

83
00:05:03,191 --> 00:05:06,140
and it was called neural style transfer.
It was by gat teas.

84
00:05:06,200 --> 00:05:07,570
That was the name of the researcher.

85
00:05:07,780 --> 00:05:12,580
And there had been a lot of variations
to that, to that original paper.

86
00:05:12,820 --> 00:05:16,740
But really that original paper
was the, the landmark. It's,

87
00:05:16,750 --> 00:05:20,200
it's the one that started it all.
Okay. We've got someone saying,

88
00:05:20,201 --> 00:05:21,610
make South America great again.

89
00:05:22,030 --> 00:05:25,390
So we got some really hilarious
people in this chat room. Okay.

90
00:05:25,391 --> 00:05:29,080
So you guys are so hilarious by the way.
Uh, I forgot how funny you guys are. Okay.

91
00:05:29,081 --> 00:05:32,950
So how are we going to do this?
Well, it turns out that we,

92
00:05:32,951 --> 00:05:36,250
all we need to do is use one
neural network. Okay? It's,

93
00:05:36,251 --> 00:05:37,840
it's a convolutional neural network.

94
00:05:37,841 --> 00:05:40,980
We're going to build this
thing in python in tensorflow,

95
00:05:41,290 --> 00:05:42,400
and that's all we really need.

96
00:05:42,640 --> 00:05:46,770
So what happens when we
have a convolutional neural
network is what it is,

97
00:05:46,771 --> 00:05:50,380
is it's a series of matrix operations.
It's a series of matrix operations.

98
00:05:50,381 --> 00:05:54,150
We have our input data that is an image.
And an image is just a matrix, right?

99
00:05:54,151 --> 00:05:54,791
It's just numbers,

100
00:05:54,791 --> 00:05:59,791
pixel values between zero and two 55 that
say what color every pixel should be.

101
00:06:00,320 --> 00:06:02,570
And we take that input, um, matrix,

102
00:06:02,780 --> 00:06:07,010
and we continuously apply operations
to it. Multiplication, right?

103
00:06:07,011 --> 00:06:09,500
The dot product.
And in Linear Algebra terms,

104
00:06:09,680 --> 00:06:12,500
we're just multiplying
a matrix by the Matrix,

105
00:06:12,530 --> 00:06:16,040
by the matrices and the weights of the
network over and over and over and over

106
00:06:16,041 --> 00:06:19,580
again. And we might add some
other little tweaks to that,

107
00:06:19,581 --> 00:06:22,820
but it's just a series of operations.
And you might be thinking, well,

108
00:06:22,821 --> 00:06:26,060
that's too hard. I don't understand
that. Well, let me stop you there.

109
00:06:26,270 --> 00:06:27,920
It's not too hard.
First of all,

110
00:06:27,921 --> 00:06:30,820
stop telling yourself that it's
all about your belief that it can.

111
00:06:31,100 --> 00:06:34,940
It's like athletes, right? So if, if you
believe that you can become, you know,

112
00:06:34,941 --> 00:06:37,820
like wolverine level jacked status,
you will do that.

113
00:06:37,821 --> 00:06:40,940
If you believe that you can learn
something, then you will learn it.

114
00:06:41,180 --> 00:06:44,420
You got to believe, right?
So again, I am not a phd,

115
00:06:44,540 --> 00:06:47,930
but do I feel very comfortable with this
stuff enough to go live in front of a

116
00:06:47,931 --> 00:06:52,340
live audience on the Internet with
my name on the line? Yes, I do.

117
00:06:52,670 --> 00:06:53,810
So,
and why is that?

118
00:06:53,811 --> 00:06:57,140
Because I believed that I could
learn it even though I'm not a phd.

119
00:06:57,141 --> 00:07:01,100
And guess what? I did learn it. So,
so take that as an example. Okay. So,

120
00:07:02,870 --> 00:07:04,710
uh, right, so convolutional networks,

121
00:07:04,740 --> 00:07:08,460
they're just a series of matrix operations
apply to input data until we get an

122
00:07:08,461 --> 00:07:11,430
output. And the output is a
prediction, right? And so, right,

123
00:07:11,431 --> 00:07:12,960
this is used for image classification,

124
00:07:12,990 --> 00:07:17,760
but what the researchers have neural style
transfer thought were they, they said,

125
00:07:17,790 --> 00:07:18,570
you know what,

126
00:07:18,570 --> 00:07:23,570
let's use those intermediary layers and
and use those to trans to transfer the

127
00:07:25,291 --> 00:07:29,790
style of one image onto another. Let's
not care about the outputs of the network,

128
00:07:29,791 --> 00:07:33,450
right? So just cut out that, uh, the,

129
00:07:33,960 --> 00:07:36,870
the last part of the network
and just care about what's,

130
00:07:36,880 --> 00:07:38,850
what's happening in the middle right here,
right?

131
00:07:38,851 --> 00:07:43,851
So these colored images are
actually just matrix values.

132
00:07:44,370 --> 00:07:48,450
These are matrix values and they have
numbers and through optimization,

133
00:07:48,451 --> 00:07:50,460
through the learning process,
those neuro,

134
00:07:50,520 --> 00:07:54,360
those numbers become better and better
at classifying the image, right?

135
00:07:54,361 --> 00:07:57,870
Through a training process, which we
don't actually care about right now.

136
00:07:57,871 --> 00:08:02,130
What we care about are these learned
layers because we can use those learned

137
00:08:02,131 --> 00:08:05,220
layers and apply what they've
learned to our image, right?

138
00:08:05,221 --> 00:08:06,540
So that's what we're going to focus on.

139
00:08:06,870 --> 00:08:10,320
We're going to use these layers to
then create our style transfer image.

140
00:08:10,321 --> 00:08:13,110
And so how do, um, how does that work?

141
00:08:16,490 --> 00:08:19,700
So here's how it works. So there are
three parts of this workflow, right?

142
00:08:19,701 --> 00:08:23,990
So we have a content extractor,
we have a style extractor,

143
00:08:24,140 --> 00:08:26,720
and then we have, um, the
combination of both, like,

144
00:08:26,721 --> 00:08:30,530
so we put them together for now
I'm going to talk about math. Okay.

145
00:08:30,531 --> 00:08:33,930
So get ready for this. I'm going to
talk about math in a second. So, uh,

146
00:08:33,950 --> 00:08:38,180
this is the fun part, right? So, uh, so
the first part is the content extractor,

147
00:08:38,181 --> 00:08:41,330
right? So we have our
image and what we want. So,

148
00:08:41,390 --> 00:08:44,060
so there are different ways that
we can think about this problem.

149
00:08:44,061 --> 00:08:47,480
And so what the researchers did was
they said, okay, we have an image.

150
00:08:47,600 --> 00:08:51,620
And that image has some content in it.
That means it has a human, you know,

151
00:08:51,621 --> 00:08:55,190
objects inside of the image. It's
got a sunset, it's got a mountain,

152
00:08:55,200 --> 00:08:59,580
whatever it's got in terms of, um,
objects though. That's the content.

153
00:08:59,581 --> 00:09:03,870
And we want a way to preserve
that content and, and,

154
00:09:04,410 --> 00:09:09,360
and model that content and represent that
content mathematically. So then we can,

155
00:09:09,420 --> 00:09:11,730
we can later, um, utilize, that's right.

156
00:09:11,731 --> 00:09:16,731
So what they did was they used a very
famous convolutional network called BGG

157
00:09:17,731 --> 00:09:21,660
19. This was a convolutional network that
was trained on hundreds of thousands of

158
00:09:21,661 --> 00:09:26,490
images of all sorts of categories from
boats to planes to dogs, whatever.

159
00:09:26,491 --> 00:09:29,580
Okay. So they took this
pretrained network. Okay.

160
00:09:29,910 --> 00:09:33,780
And this is what it looks
like. A convolutional network.
We have a convolution,

161
00:09:33,781 --> 00:09:37,920
which is a matrix operation, a
pooling, a pooling operation,

162
00:09:37,921 --> 00:09:41,310
which is another operation. You
know, I have a great, I don't,

163
00:09:41,370 --> 00:09:43,830
I don't want to repeat
what I've repeated before.

164
00:09:43,860 --> 00:09:47,040
If you want to know how a
convolutional network in general works,

165
00:09:47,190 --> 00:09:51,330
search convolutional network
Saroj on youtube first link.

166
00:09:51,810 --> 00:09:56,460
It's an amazing explanation if I do say
so myself. Uh, but so that's how it works.

167
00:09:56,461 --> 00:10:01,110
But what, what we care about are
these, are these layers. Okay.

168
00:10:01,111 --> 00:10:04,710
So this is actually just one layer, right?
So, but what a convolutional network is,

169
00:10:04,750 --> 00:10:08,310
it's multiple layers. So we
care about this, this layer,

170
00:10:08,340 --> 00:10:12,300
you know a few of these layers
right here and this is pulling. So,

171
00:10:12,420 --> 00:10:15,360
so if we were to visualize,
and by the way guys,

172
00:10:15,361 --> 00:10:18,350
the code is going to be in the get hub,
uh,

173
00:10:18,450 --> 00:10:20,910
in the video description that get
helped code by the way. So if so,

174
00:10:20,911 --> 00:10:23,490
follow along with me here.
So if we were,

175
00:10:23,520 --> 00:10:25,950
if we were to visualize what
these layers have learned,

176
00:10:25,951 --> 00:10:28,590
it's going to look like this, right?
So it's going to be images. I mean,

177
00:10:28,591 --> 00:10:32,340
it's going to be edges and then it's
going to get increasingly more abstract

178
00:10:32,341 --> 00:10:32,881
over time.

179
00:10:32,881 --> 00:10:36,840
So edges will become eyes and eyes
will become faces and faces will become

180
00:10:36,841 --> 00:10:40,320
humans as the layer
the network progresses.

181
00:10:40,530 --> 00:10:45,060
So what they did was they
represented content as this formula.

182
00:10:45,061 --> 00:10:45,894
Get ready now?

183
00:10:45,990 --> 00:10:48,990
Now you got me excited because now
I'm talking about math by the way,

184
00:10:53,640 --> 00:10:54,473
okay?

185
00:10:55,330 --> 00:10:56,650
Okay,
so

186
00:10:58,740 --> 00:10:59,690
[inaudible]

187
00:11:01,520 --> 00:11:05,840
you guys are so funny. Oh my God, you
guys said the most random stuff. Okay,

188
00:11:05,841 --> 00:11:10,310
so content, right? So content,
how did they represent content?

189
00:11:10,311 --> 00:11:13,190
Like what is actually in the
image in terms of objects.

190
00:11:13,490 --> 00:11:17,120
So what they did was they passed both
images through the network, right?

191
00:11:17,121 --> 00:11:21,250
So you have your base image, what you want
to stylize, and then you have the, the,

192
00:11:21,300 --> 00:11:26,300
the style image or the image, the art,
let's just call it artistic image.

193
00:11:26,780 --> 00:11:29,030
And so they pass both through the network.

194
00:11:29,270 --> 00:11:32,180
And so what they did was they found
and they took a particular layer,

195
00:11:32,181 --> 00:11:36,800
let's call it layer to layer two of of
five, but it can be any layer really. Um,

196
00:11:36,801 --> 00:11:40,940
and it took layer two or five and that's,
that's um, that's a matrix of values,

197
00:11:40,941 --> 00:11:42,950
right?
Is it to learn matrix of values.

198
00:11:43,800 --> 00:11:44,633
Okay.

199
00:11:45,330 --> 00:11:50,190
And once we do that, uh, we can then
that's gonna that's gonna give us, um,

200
00:11:50,400 --> 00:11:53,740
a scalar value, okay. That's going
to give us a scalar, a single value.

201
00:11:54,070 --> 00:11:57,280
And what we can do is we can find the
difference between those values, right?

202
00:11:57,281 --> 00:12:00,250
So we pass in one image and
it's going to learn a filter.

203
00:12:00,251 --> 00:12:02,190
It's going to learn a filter for that.
We'll pass it on.

204
00:12:02,191 --> 00:12:03,970
Another image is going to
learn a filter for that.

205
00:12:03,971 --> 00:12:07,930
We can basically subtract those two
filters together and we can get the,

206
00:12:08,320 --> 00:12:12,900
and then we can square that. And we
can do that for all of those, um,

207
00:12:13,090 --> 00:12:16,300
images. We'll sum them
all up and then, uh,

208
00:12:17,510 --> 00:12:18,110
okay,

209
00:12:18,110 --> 00:12:20,480
we're finding their difference
and then we're squaring it. Okay?

210
00:12:20,481 --> 00:12:22,370
So that's how that works.

211
00:12:22,490 --> 00:12:26,840
And that's what the sigma notation meets
for all of those images. Okay. So, um,

212
00:12:27,050 --> 00:12:30,590
we're also multiplying each of
the represent representations
by the value Alpha.

213
00:12:30,591 --> 00:12:35,270
That's right. That's right. The value
Alpha. Um, but we have those two features.

214
00:12:35,271 --> 00:12:38,420
That's what I'm trying to say here.
We have to learn to matrices.

215
00:12:38,600 --> 00:12:43,520
We're finding the difference between
them and that is our content loss. So,

216
00:12:43,670 --> 00:12:44,990
right.
So last functions,

217
00:12:44,991 --> 00:12:48,350
I've got such an amazing loss function
video coming out this weekend.

218
00:12:48,470 --> 00:12:50,630
I cannot wait to show you guys this.

219
00:12:50,720 --> 00:12:55,720
But last functions are all about measuring
how bad our network is that making a

220
00:12:55,911 --> 00:12:59,540
prediction, right? So what we
want is we want a loss function.

221
00:12:59,570 --> 00:13:02,630
That's not going to measure how
bad we are at classifying dogs.

222
00:13:02,960 --> 00:13:07,960
We want a loss function that measures
how bad we are at creating a stylized

223
00:13:08,781 --> 00:13:13,490
image. And so if you think about
it, that's a very abstract, uh,

224
00:13:13,550 --> 00:13:17,390
at first thought like
how good a filter is.

225
00:13:17,720 --> 00:13:22,370
But by and representing it mathematically
this way, we have found a way to

226
00:13:23,700 --> 00:13:28,550
thrives 20, 20, I mean guys, one thing at
a time, right? I got to take over this,

227
00:13:28,551 --> 00:13:33,260
uh, youtube game first and then
we'll talk about that. I'm not,

228
00:13:33,261 --> 00:13:36,290
I'm not saying anything anyway.
You guys are so funny. Oh my God,

229
00:13:36,291 --> 00:13:40,370
I need to like close this chat
window because, um, okay. Anyway, no,

230
00:13:40,371 --> 00:13:43,680
I like it though. I can do both. So,
so that's content, right? We have,

231
00:13:43,850 --> 00:13:45,690
we have the content and now we're,

232
00:13:45,740 --> 00:13:48,320
the next thing we're gonna do is
we're going to strike the style. So,

233
00:13:48,380 --> 00:13:51,350
so content is just, think of
it as a single value, right?

234
00:13:51,351 --> 00:13:56,150
So all of this comes down to a single
value that represents, um, how,

235
00:13:56,870 --> 00:13:57,240
okay,

236
00:13:57,240 --> 00:13:58,170
how,
um,

237
00:13:59,250 --> 00:13:59,520
yeah,

238
00:13:59,520 --> 00:14:03,240
how much content has been
transferred to our base image.

239
00:14:03,390 --> 00:14:06,690
It's like how different our base
images from our content image.

240
00:14:06,870 --> 00:14:09,300
And what we want to do is we
want to minimize that difference.

241
00:14:09,330 --> 00:14:11,250
And when we minimize that difference,

242
00:14:11,490 --> 00:14:15,840
our base image will become more and more
and more like that style image in terms

243
00:14:15,841 --> 00:14:19,980
of content. But content is not
enough. There's also style, right?

244
00:14:19,981 --> 00:14:21,240
So for style,

245
00:14:21,910 --> 00:14:22,680
okay,

246
00:14:22,680 --> 00:14:25,650
for style,
we're going to do the same thing except,

247
00:14:26,300 --> 00:14:26,720
okay.

248
00:14:26,720 --> 00:14:30,620
We don't want, we don't care about
the content. We care about the, uh,

249
00:14:30,650 --> 00:14:34,970
the texture of the image,
right? The colors, the what,

250
00:14:35,060 --> 00:14:38,360
what is where, right? So if we think
about like a filter in general,

251
00:14:38,361 --> 00:14:40,730
there's not really images
that are being overlaid.

252
00:14:40,731 --> 00:14:42,830
They're just like these
textures and colors, right?

253
00:14:42,831 --> 00:14:46,220
So there's this kind of gradient, not,
not in the sense of the math word.

254
00:14:46,400 --> 00:14:50,930
It can be very careful about words
here. But, um, how do they extract the,

255
00:14:51,320 --> 00:14:53,930
well, what one thing to
think would be, well,

256
00:14:53,931 --> 00:14:55,670
let's just directly do the same thing,
right?

257
00:14:55,671 --> 00:14:59,120
So input the style image and find
a difference. Right? Between them.

258
00:14:59,330 --> 00:15:02,720
But what the instead what they did was
they said let's compute what's called a

259
00:15:02,721 --> 00:15:06,840
gram matrix. And what a gram
matrix is. It is, it is the,

260
00:15:06,980 --> 00:15:11,240
it is the transpose of the Matrix,
right?

261
00:15:11,241 --> 00:15:13,970
So a grant matrix is the multiple,

262
00:15:13,971 --> 00:15:16,820
if you take a matrix and you
multiply it by the transposed,

263
00:15:16,821 --> 00:15:20,180
so you flip it of itself,
that's the grand matrix.

264
00:15:20,570 --> 00:15:25,310
And so they took those grand matrices
for both the base image and the style

265
00:15:25,320 --> 00:15:28,250
image, the artistic image, and they
found the difference between them.

266
00:15:28,310 --> 00:15:32,240
So that's what this,
so this calculates the gram matrix then,

267
00:15:32,840 --> 00:15:34,400
uh,
once we do that,

268
00:15:34,401 --> 00:15:38,150
we can find the difference between them
and we multiply by this out by this

269
00:15:38,151 --> 00:15:43,040
value Beta. So there are
two like threshold, not
threshold, but static values.

270
00:15:43,041 --> 00:15:47,420
Here we have Alpha, which
is for the content. We have
Beta, which is for the style,

271
00:15:47,421 --> 00:15:51,650
and we can tweak those to see how
stylized our end result will be.

272
00:15:52,130 --> 00:15:56,480
So that gives us our loss for, for saying
how stylized we want our image to be.

273
00:15:56,690 --> 00:15:59,900
So what we want to do is we
want to combine both of those.

274
00:15:59,901 --> 00:16:04,670
And the way that we combine both of
those is by creating this final equation

275
00:16:04,671 --> 00:16:07,550
here. So we just, we just
add them up. That's it.

276
00:16:07,700 --> 00:16:12,410
We add the content loss and we add the
style loss and that's our total loss

277
00:16:12,590 --> 00:16:14,210
variation loss,
you can call it.

278
00:16:14,540 --> 00:16:18,950
So our loss function consist of other
loss functions and the reason we added it

279
00:16:18,980 --> 00:16:20,840
is because we just want a single,

280
00:16:21,440 --> 00:16:26,030
we want a single end to end optimization
approach where we can just optimize the

281
00:16:26,031 --> 00:16:27,290
entire thing.
We,

282
00:16:27,340 --> 00:16:31,790
we compute the error using
this loss function and then
we use the air to compute

283
00:16:31,791 --> 00:16:35,600
the partial derivative with respect
to the weights of our network. Okay.

284
00:16:35,601 --> 00:16:37,820
And if you want to understand
how backpropagation works,

285
00:16:37,821 --> 00:16:42,230
again search backpropagation Saroj on
youtube and like a million links will pop

286
00:16:42,231 --> 00:16:45,590
up there as well.
Literally anything AI related,

287
00:16:45,620 --> 00:16:49,730
just search the name of what you're
thinking and then the word Saroj and I

288
00:16:49,731 --> 00:16:54,731
promise you it's going to show
up on youtube 98% of the time.

289
00:16:55,190 --> 00:16:57,590
Okay. So all right. So,

290
00:16:57,680 --> 00:17:00,950
and the way they optimize it
was using El bfgs and this,

291
00:17:01,130 --> 00:17:05,180
this is a second order optimization scheme
and I've got a great video on that as

292
00:17:05,181 --> 00:17:08,510
well. Just search second order
optimization by Saroj on Youtube.

293
00:17:08,780 --> 00:17:11,600
And we talk about how instead of
just competing the derivative,

294
00:17:11,840 --> 00:17:15,680
we compute the derivative of the
derivative and in some cases it's called

295
00:17:15,681 --> 00:17:19,930
Newton's method and another in
another case it's called El bfgs. Um,

296
00:17:19,940 --> 00:17:23,030
but it is a gradient based
optimization ski. Okay,

297
00:17:23,031 --> 00:17:28,031
so we're going to build this now
we want to make this into an API.

298
00:17:28,190 --> 00:17:32,270
So let's get to the
code, shall we? So let's,

299
00:17:32,271 --> 00:17:33,980
let's just build a simple model here.
Okay.

300
00:17:33,981 --> 00:17:38,520
So what we first want to do is
we want to import Vgg, right?

301
00:17:38,521 --> 00:17:43,370
So VGG is that convolutional network.
We also want to implement,

302
00:17:43,580 --> 00:17:45,610
we will also want to import tensorflow.

303
00:17:46,570 --> 00:17:50,100
We've got people doing the hundred
days of ml code challenge, by the way.

304
00:17:50,101 --> 00:17:51,460
Amazing stuff.
Hi.

305
00:17:51,590 --> 00:17:56,070
I am so proud of the people of the
wizards who are, who are doing that.

306
00:17:56,100 --> 00:17:58,080
It's just a,
it's just amazing mind blowing.

307
00:17:59,340 --> 00:18:04,020
So VGG is our network.
Tensorflow is our tensorflow,

308
00:18:04,060 --> 00:18:08,310
is my city. No, no. Tensor flow
is our machine learning library.

309
00:18:08,850 --> 00:18:10,680
And then we're going to import,
transform.

310
00:18:14,010 --> 00:18:17,640
We're going to import, transform
to then transform our images as we,

311
00:18:17,700 --> 00:18:22,080
as we do want to modify them a yes,
I know coding train. I love Dan.

312
00:18:22,081 --> 00:18:24,840
We actually collaborated with Dan and
I'll probably will collaborate with Dan

313
00:18:24,841 --> 00:18:29,400
again. He's a great guy and I promoted
him and he's promoted me. And you know,

314
00:18:29,460 --> 00:18:32,790
in a way we're kind of all like the
Kardashians of machine learning shift.

315
00:18:32,791 --> 00:18:36,460
Mid me three blue one brown,
uh, this evening. Uh, Carrie,

316
00:18:36,461 --> 00:18:38,820
Carrie Huang is coming over.
Um,

317
00:18:38,850 --> 00:18:40,380
he doesn't know that I'm
live streaming right now,

318
00:18:40,381 --> 00:18:44,010
but he's coming in a few hours. So I
mean, we all, we're all like, you know,

319
00:18:44,011 --> 00:18:45,690
cross promoting each other.
And you know,

320
00:18:45,691 --> 00:18:49,110
what I really want to do is I want to
make a curriculum that involves all of

321
00:18:49,111 --> 00:18:51,550
them. And you know, we
all have our, you know,

322
00:18:51,570 --> 00:18:53,700
we all have our distribution
channels or youtube channels,

323
00:18:53,880 --> 00:18:56,850
but we're all pushing content
towards the same curriculum.

324
00:18:57,000 --> 00:19:01,170
Can you imagine the anime
cross over level? You know,

325
00:19:01,171 --> 00:19:03,600
if I'm like sitting here
building convolutional network,

326
00:19:03,780 --> 00:19:07,860
Daniel Shiffman comes in and he is
like adding in his like p five dot.

327
00:19:07,861 --> 00:19:12,060
JS javascript stuff for like front
end stuff. You know, Carrie comes in,

328
00:19:12,061 --> 00:19:13,680
he's hilarious.
Uh,

329
00:19:13,740 --> 00:19:16,860
Andrew Trust comes in and he like
explains things so beautifully.

330
00:19:17,760 --> 00:19:20,970
Jabrill's comes in of course, and
he liked, makes a game out of it.

331
00:19:21,080 --> 00:19:25,410
Drills is all is awesome as
well. We collabed as well.
Uh, how cool would that be?

332
00:19:25,411 --> 00:19:29,670
We guys, we need to make this
happen. I mean, it's gonna
happen. So, um, we'll see.

333
00:19:29,671 --> 00:19:34,560
We'll see. So one step
at a time, basically the
Kardashians as, okay. So, uh,

334
00:19:34,590 --> 00:19:37,500
let's, let's get to this before
we run out of time here. So, uh,

335
00:19:37,501 --> 00:19:40,290
from utils import get image.
Okay.

336
00:19:40,320 --> 00:19:45,320
So now what we really want
is a couple of those layers.

337
00:19:46,140 --> 00:19:48,720
So we're going to specify what
those layers are going to be.

338
00:19:48,721 --> 00:19:51,810
So let's just call these
layers by their names,

339
00:19:51,811 --> 00:19:56,460
which they were named by the VGG
authors. Uh, and once we do that

340
00:19:58,480 --> 00:20:02,080
Relu to renew three relu that Oda really,

341
00:20:02,081 --> 00:20:06,130
really relieved by the way his
stance were rectified linear unit,

342
00:20:06,160 --> 00:20:11,160
which is a type of activation function
that diminishes the vanishing gradient

343
00:20:11,291 --> 00:20:13,690
problem we look for.
Okay.

344
00:20:13,691 --> 00:20:16,420
So we've got four layers here that we're
going to begin to think about when it

345
00:20:16,421 --> 00:20:19,960
comes to style. And then when it comes
to content, we just have one layer.

346
00:20:19,961 --> 00:20:23,260
We're going to call relu four two.
Okay.

347
00:20:23,680 --> 00:20:27,940
And so now that we have that,
let's,

348
00:20:31,540 --> 00:20:36,270
let's now say,
let's optimize.

349
00:20:36,271 --> 00:20:39,480
So in the optimize function here,

350
00:20:40,800 --> 00:20:44,310
we want to perform optimization.
Okay?

351
00:20:44,311 --> 00:20:48,220
So what I'm gonna do is going to say

352
00:20:51,340 --> 00:20:53,470
inside of our TF graphs,
so we want,

353
00:20:53,471 --> 00:20:58,471
we want to initialize our graph and we
wants to take VGG an existing network and

354
00:20:58,931 --> 00:21:02,620
extract those features from it,
right? So, so how do we do that?

355
00:21:02,621 --> 00:21:05,920
How do we actually extract features from,
from Vgg in?

356
00:21:05,921 --> 00:21:09,050
So I'm going to show you how we do that.
Um,

357
00:21:09,880 --> 00:21:11,110
as default.

358
00:21:13,420 --> 00:21:15,730
If that device is going to be our device,

359
00:21:18,240 --> 00:21:21,270
right?
How's device?

360
00:21:30,920 --> 00:21:35,780
Yes, Youtube is my main job. It is my
main job. That's the way I like it.

361
00:21:35,990 --> 00:21:40,950
Okay. Uh, okay. So with that,

362
00:21:41,430 --> 00:21:44,560
we're going to compute
this style image first. Um,

363
00:21:44,561 --> 00:21:46,890
and that's going to be TF dot placeholder.

364
00:21:48,630 --> 00:21:51,510
So we want a place holder for that
style image, right? So the initial,

365
00:21:51,511 --> 00:21:55,350
let me make this bigger. Let me
make this bigger, bigger, bigger,

366
00:21:55,440 --> 00:21:59,100
bigger is always better.
Not Always, not always.

367
00:22:00,650 --> 00:22:05,240
Okay. Style image is going to be,
we're going to use a place holder.

368
00:22:05,241 --> 00:22:07,110
So what the placeholder is in the,
in,

369
00:22:07,120 --> 00:22:11,960
in the Tantra flow computation graph
is it is the gateway into the network,

370
00:22:11,961 --> 00:22:13,850
right?
So this is where data flows in.

371
00:22:14,150 --> 00:22:17,120
And so that's why we're creating a place
holder here because we want a way to

372
00:22:17,150 --> 00:22:18,560
input the style image,
right?

373
00:22:18,740 --> 00:22:21,920
So we're gonna do that for the style
image and we want to do that for the, uh,

374
00:22:23,720 --> 00:22:28,670
the base image. Okay? So our placeholder
is going to be of tight float 32.

375
00:22:28,671 --> 00:22:33,560
It's a very simple image. We have a
predefined shape that we want to give it.

376
00:22:45,280 --> 00:22:50,050
My sound and image are not in sync.
Okay? Well that we got to fix that.

377
00:22:50,080 --> 00:22:52,240
Really? Okay. Hold on.

378
00:22:53,980 --> 00:22:58,910
Let me go check that out. Really,

379
00:22:58,950 --> 00:23:03,390
my sound and image are not in
sync. Seriously. Oh my God. See,

380
00:23:03,391 --> 00:23:07,230
this is what happens when a life stream
alone. I'm like trying to set up this, uh,

381
00:23:07,890 --> 00:23:11,700
this whole thing. Okay. Uh, okay.

382
00:23:11,701 --> 00:23:15,360
So what I want to do actually is just,
okay,

383
00:23:15,420 --> 00:23:16,830
so next time I'm going
to be better about this,

384
00:23:16,831 --> 00:23:21,420
but let's find that since it's
syncing for you. Right. Great.

385
00:23:21,810 --> 00:23:25,410
Let's look at this code. So let me
just show you this code guys. Okay.

386
00:23:26,010 --> 00:23:29,880
So we have our style image. Okay. So,
and then we have our base image here.

387
00:23:30,120 --> 00:23:34,620
We have our network vgg.net we feed
both in as parameters that gives us our

388
00:23:34,621 --> 00:23:36,900
network. Okay. So once we have that,

389
00:23:36,930 --> 00:23:41,820
we take those layers and we compute the
gram matrices of each of those layers.

390
00:23:42,000 --> 00:23:42,833
Okay.

391
00:23:42,900 --> 00:23:47,450
We compute the gram matrices of each
of those using them and then using the

392
00:23:47,451 --> 00:23:49,190
matrix multiply featured,
right?

393
00:23:49,430 --> 00:23:54,430
Remember the gram matrix is the transpose
of a matrix multiplied by itself,

394
00:23:55,910 --> 00:24:00,110
which is exactly what this line is.
This is the grand matrix.

395
00:24:00,290 --> 00:24:02,400
We are feeding all of those.
Um,

396
00:24:03,530 --> 00:24:03,750
okay.

397
00:24:03,750 --> 00:24:08,250
We are feeding and I'll wrap at the end.
By the way, do not leave and I will wrap.

398
00:24:08,310 --> 00:24:11,730
If you leave, you don't get to hear the
rap, I'll probably make a fool of myself.

399
00:24:11,760 --> 00:24:14,280
But that's just how it goes,
right? Whatever it takes, right?

400
00:24:14,490 --> 00:24:17,730
Ai Solve Ai or die trying.
So Graham Matrix,

401
00:24:17,731 --> 00:24:21,120
we're storing all of those inside
of this array style features, okay?

402
00:24:21,121 --> 00:24:24,090
So that that was us computing the style,

403
00:24:24,180 --> 00:24:29,180
a loss in the form of Graham matress cs
for all of those layers that we defined

404
00:24:29,641 --> 00:24:31,680
beforehand, right? So that was that.

405
00:24:33,750 --> 00:24:38,460
And so once we do that,
then then and only then we can say,

406
00:24:38,461 --> 00:24:42,600
okay, inside of our TF graph,
let's compute the content preacher.

407
00:24:42,601 --> 00:24:46,260
So we already did this for style and now
we're doing the same thing for content.

408
00:24:46,261 --> 00:24:49,120
So we already defined a content layer,
right?

409
00:24:49,121 --> 00:24:52,890
And remember there was no Graham
Matrix involved in the content.

410
00:24:52,891 --> 00:24:56,730
So you don't see that here we are directly
pulling the learn to value for the

411
00:24:56,731 --> 00:25:01,170
content just like this.
Whereas for the gram matrix,
we had to compute that, right?

412
00:25:01,171 --> 00:25:05,280
Using TF or NP numb Pi's
Matrix multiply function.

413
00:25:08,590 --> 00:25:12,430
And so once we do that,
then we can combine both of them.

414
00:25:12,610 --> 00:25:16,450
So this right here is
just, um, this is like a,

415
00:25:18,150 --> 00:25:22,830
this is like, uh, an exception check,
right? If it's, if it's slow, then, uh,

416
00:25:23,460 --> 00:25:26,700
set the image back to what it was before
because it's taking too long so we can

417
00:25:26,701 --> 00:25:29,070
ignore that part. So, um,

418
00:25:30,720 --> 00:25:34,740
now for our content loss,
we already found, uh, the,

419
00:25:35,400 --> 00:25:37,500
the value from that specific layer.

420
00:25:37,650 --> 00:25:40,140
And this is us computing it by
multiplying it by the weight.

421
00:25:40,630 --> 00:25:43,950
And so if you look at this, you're
thinking, wait a second. Uh,

422
00:25:45,910 --> 00:25:46,700
yeah.

423
00:25:46,700 --> 00:25:48,510
What you're thinking like,
wait a second,

424
00:25:51,510 --> 00:25:56,430
where is that? Where is
that? [inaudible] right?

425
00:25:56,431 --> 00:26:00,010
So here it is. This is, this is
exactly what we're doing. See?

426
00:26:00,060 --> 00:26:04,560
So this equation is what we
are looking at right here.

427
00:26:05,440 --> 00:26:05,790
Okay.

428
00:26:05,790 --> 00:26:08,370
Where is it? Where is it? It is,

429
00:26:08,610 --> 00:26:12,570
it is the difference
between both of those, uh,

430
00:26:12,690 --> 00:26:16,590
features divided by the size of the
content and multiplied by the weight.

431
00:26:17,190 --> 00:26:21,230
And that gives us the content loss.
Okay.

432
00:26:21,560 --> 00:26:24,440
So now that we have all
of those style layers,

433
00:26:27,220 --> 00:26:28,053
yeah.

434
00:26:28,480 --> 00:26:31,340
Now that we have those layers, we can, uh,

435
00:26:31,900 --> 00:26:34,450
compute the style was,

436
00:26:34,480 --> 00:26:38,260
so we had the style layer values and now
we're competing the style lost values

437
00:26:38,740 --> 00:26:41,730
until it comes out to this. So what
is happening here? Let's talk about,

438
00:26:41,750 --> 00:26:45,750
we have our, the size, the height by
the width, by the number of filters.

439
00:26:45,780 --> 00:26:49,560
So it's a three dimensional tensor size.
We have our features.

440
00:26:49,590 --> 00:26:54,270
So what we're doing is we're reshaping
what we just computed. Uh, no,

441
00:26:54,271 --> 00:26:56,820
not this one.
This is for each of the layers.

442
00:26:56,821 --> 00:27:01,780
So these are the features for the layers.
We have our grand major season,

443
00:27:01,781 --> 00:27:03,360
that's our style.
Grand matrices.

444
00:27:03,690 --> 00:27:07,950
We append to the law says the difference
between those grand matrices and that

445
00:27:07,951 --> 00:27:12,330
gives us our style losses.
And lastly, we use that.

446
00:27:13,460 --> 00:27:16,880
We use that value multiplied by the way,
and that is our style loss.

447
00:27:17,660 --> 00:27:21,320
Now the word variation here
just means, uh, this total loss.

448
00:27:21,321 --> 00:27:23,210
So I said the total variation loss.

449
00:27:24,620 --> 00:27:28,340
And so in order to compute
the total variation loss,

450
00:27:28,341 --> 00:27:32,030
we add both the style loss
and the content lost together.

451
00:27:32,360 --> 00:27:35,090
And that's going to give
us our total loss. Okay.

452
00:27:35,270 --> 00:27:37,940
So this right here is this
preprocessing step. That's not,

453
00:27:38,180 --> 00:27:42,230
it's not really necessary, but they
went ahead and did it anyway. Um,

454
00:27:42,440 --> 00:27:46,660
it's just kind of a, it's a nice
to have. It's, it's a Gotcha.

455
00:27:47,110 --> 00:27:50,050
That's the thing about a
lot of this research code. I
mean, this is research code.

456
00:27:50,051 --> 00:27:52,900
Like it's Kinda, it's Kinda messy.
It's, you know, it's, it's not good.

457
00:27:53,170 --> 00:27:56,380
One of the most impactful
things you can do, by the way,

458
00:27:56,381 --> 00:27:59,440
if you're interested in Ai, which I
love you if you are, which you are.

459
00:27:59,441 --> 00:28:02,110
So I love you. If you're
watching this, uh,

460
00:28:02,500 --> 00:28:07,240
one of the most impactful things you can
do is creating clean, well documented,

461
00:28:07,241 --> 00:28:11,560
readable code. All right? For the ml
community as, as a whole, right? This is,

462
00:28:11,950 --> 00:28:14,740
this is what beginners
need better code. And, um,

463
00:28:16,120 --> 00:28:19,960
carrots would be a great wrapper for this
and there is a karass wrapper for this.

464
00:28:19,961 --> 00:28:24,940
Um, but, um, right? And so this
is the training loop, train,

465
00:28:24,941 --> 00:28:26,620
train, train, et cetera. Okay.

466
00:28:26,621 --> 00:28:30,880
So now let's get to the part that I've
been talking about the API part, right? So

467
00:28:32,680 --> 00:28:35,830
how did I do this?
So if you look at what I've done here,

468
00:28:38,010 --> 00:28:39,360
if you look at what I've done here,

469
00:28:40,080 --> 00:28:44,820
I have made an API using Floyd hubs.
So let's,

470
00:28:44,821 --> 00:28:47,100
let's talk about Floyd huff for a second.
Okay.

471
00:28:47,101 --> 00:28:51,330
So Floyd hub is not the best.

472
00:28:52,490 --> 00:28:53,160
Okay?

473
00:28:53,160 --> 00:28:57,150
Oh my God, it's Lloyd.
All right. Fully hobbies,

474
00:28:57,160 --> 00:29:01,470
not necessarily the best
GPU, um, provider on the web.

475
00:29:01,471 --> 00:29:04,710
But I'll tell you what it is, is it's
really easy for beginners to get started.

476
00:29:04,711 --> 00:29:07,720
Okay? So I've got a couple of jobs
here that I've been running. Um,

477
00:29:08,850 --> 00:29:13,650
and so when it comes down to it for
Floyd hub, you literally can say,

478
00:29:13,770 --> 00:29:18,390
here is my, here is my, uh, repository.

479
00:29:18,391 --> 00:29:22,320
So I've got a repository here and right?

480
00:29:22,321 --> 00:29:26,790
So let me open this. Here's my repository.
Let me, let me look at this. And Sublime.

481
00:29:27,240 --> 00:29:31,950
Sublime, okay. Evaluate,

482
00:29:33,700 --> 00:29:34,430
okay,

483
00:29:34,430 --> 00:29:37,160
you've got to have this.
So in this Floyd requirements that txt,

484
00:29:37,161 --> 00:29:39,440
you just add all of your dependencies,
just like list them,

485
00:29:39,590 --> 00:29:43,810
and it's going to install all of
dependencies in your virtual environment,

486
00:29:43,811 --> 00:29:46,660
in the cloud for you. So this is
gonna be tentraflow can we care?

487
00:29:46,661 --> 00:29:49,690
Os It'd be whatever you want and it will
install that for you and your virtual

488
00:29:49,691 --> 00:29:52,960
environment.
So what you can do is once you,

489
00:29:53,170 --> 00:29:57,160
once you find your repository, you can
run the command Floyd in it, right?

490
00:29:57,161 --> 00:29:59,770
So Floyd and knit fast style transfer.

491
00:30:00,040 --> 00:30:04,330
And what that does is it initializes a
new project in your current directory and

492
00:30:04,331 --> 00:30:07,360
then you can serve, well, first of
all, you can even train that model.

493
00:30:07,361 --> 00:30:10,390
So this is a pre trained model
that we can serve directly from our

494
00:30:11,800 --> 00:30:12,633
hold on,

495
00:30:15,240 --> 00:30:19,200
old on.
We can run that directly from our

496
00:30:21,100 --> 00:30:25,030
command line like that. And so what this
is now doing is it's taking our code,

497
00:30:25,270 --> 00:30:26,103
it's,

498
00:30:26,240 --> 00:30:26,500
yeah,

499
00:30:26,500 --> 00:30:30,640
putting it on the web. And so, oh,
I've reached your Max number of jobs.

500
00:30:30,641 --> 00:30:33,640
I've been running a lot of jobs on
this thing. And so once we do that,

501
00:30:33,700 --> 00:30:34,930
then we can simply,

502
00:30:42,080 --> 00:30:43,100
I got some people,

503
00:30:46,890 --> 00:30:47,610
okay.

504
00:30:47,610 --> 00:30:52,610
So then we can simply just run a simple
API call using this line of code just

505
00:30:53,161 --> 00:30:57,630
like this, and then it's going
to return back, whatever that,

506
00:31:00,700 --> 00:31:04,650
whatever that output images like I just
like I showed you before. Okay. Um,

507
00:31:04,870 --> 00:31:07,450
that is super simple.
And if we go to the,

508
00:31:07,451 --> 00:31:11,470
the code that I have for you in the
get hub description, if we go to that,

509
00:31:12,500 --> 00:31:15,950
check it out. Amazing instructions
for you. Here's how to train it.

510
00:31:16,450 --> 00:31:16,890
Yeah.

511
00:31:16,890 --> 00:31:20,670
Or here's how to train on Floyd hub one
line of code and you're training your

512
00:31:20,671 --> 00:31:25,050
model on this, a cloud service. Here's
how to evaluate it, right? You trained it,

513
00:31:25,051 --> 00:31:28,260
okay, here's, here's, here's
how you rent in France. Okay.

514
00:31:28,500 --> 00:31:29,880
You can do the same thing for video.

515
00:31:30,090 --> 00:31:33,420
And really this applies to any kind of
model. And how do you even do this? Well,

516
00:31:33,450 --> 00:31:36,780
you got to make a Floyd hub account,
right? Let me do this with you. Okay,

517
00:31:36,781 --> 00:31:41,230
let's do this together.
Let's make a [inaudible] hub
account sign up for free. Um,

518
00:31:44,830 --> 00:31:45,663
okay.

519
00:31:46,960 --> 00:31:51,430
It's raw. It's raw edge, okay.

520
00:31:55,730 --> 00:31:58,790
No credit cards need to care.
And no, they didn't sponsor this.

521
00:31:58,820 --> 00:32:03,500
They did not sponsor this video. I just
personally like it. Okay. Just like that.

522
00:32:03,890 --> 00:32:06,590
And so I dunno how it's already, oh,
it's already got projects for me,

523
00:32:06,591 --> 00:32:10,220
so we can just look at those if we
wanted to. And so inside of this work,

524
00:32:10,250 --> 00:32:12,200
it's even got the instructions,
like how do we do well,

525
00:32:12,201 --> 00:32:16,280
we just initialize it here.
And so once we initialize it locally,

526
00:32:18,570 --> 00:32:23,310
we can add some code here and then we
can run it on a Gpu. So Floyd, Ron Gpu,

527
00:32:23,311 --> 00:32:26,820
and then it's gonna run
on a GPU in the cloud.

528
00:32:26,970 --> 00:32:30,880
So I want to say, and so once we do
that, we can serve it as well from,

529
00:32:30,930 --> 00:32:34,590
from that API. We can, we can create an
API around this. So you might be thinking,

530
00:32:34,591 --> 00:32:37,890
well, w w there must be machine
learning APIs out there.

531
00:32:37,891 --> 00:32:42,440
So clarify as one example,
right? So clarify does have, um,

532
00:32:46,510 --> 00:32:50,890
does have some models that are trained
for you pre trained in the cloud and

533
00:32:50,891 --> 00:32:55,690
they're pretty good, but they're doing way
too much, right? So someone can clearly,

534
00:32:55,840 --> 00:32:59,410
uh, pick one of these and do them really
well. He's the, one of the newer models,

535
00:32:59,470 --> 00:33:03,620
I'm talking about generative adversarial
networks. I'm talking about, um,

536
00:33:04,570 --> 00:33:08,050
I'm talking about variational
auto encoders. Um, you know,

537
00:33:08,051 --> 00:33:09,790
one of the more advanced
models that you know,

538
00:33:09,880 --> 00:33:13,330
people don't know about so much and you
know, clarify as a great example of a,

539
00:33:13,540 --> 00:33:14,110
of a,

540
00:33:14,110 --> 00:33:19,110
of a group of people who create a really
sustainable business around just Ai.

541
00:33:19,841 --> 00:33:24,400
So think about it, just having one single
API call as a service, you can do that.

542
00:33:24,401 --> 00:33:28,990
You can make so much money, you can
make so much money doing that. And um,

543
00:33:29,590 --> 00:33:32,440
you know, just just yesterday
I had a farmer in Belgium who,

544
00:33:32,920 --> 00:33:36,340
who emailed me a picture of his crop
and he was asking if I can help him with

545
00:33:36,580 --> 00:33:37,780
classifying.
That's right.

546
00:33:37,781 --> 00:33:42,520
So there's just so much potential
out there to create really impactful

547
00:33:42,521 --> 00:33:45,310
businesses for the world.
Uh, clarifies one example.

548
00:33:46,120 --> 00:33:48,780
I just want to show you that
really quickly. Okay. So, uh,

549
00:33:48,820 --> 00:33:52,180
that's it for this live stream.
Let me answer some questions at the,

550
00:33:52,210 --> 00:33:53,980
at the end and I'm going to wrap.
So guys,

551
00:33:53,981 --> 00:33:58,630
go ahead and ask them questions and
then once you do that, uh, I will.

552
00:34:01,420 --> 00:34:02,253
Okay.

553
00:34:02,310 --> 00:34:06,210
I will, I will end this live stream
after our answer your questions. Okay.

554
00:34:06,211 --> 00:34:11,100
So while I look for an instrumental
to play rap instrumental,

555
00:34:18,620 --> 00:34:19,640
any questions guys?

556
00:34:21,360 --> 00:34:24,230
What are the questions here? How to
become confident with large code bases?

557
00:34:24,300 --> 00:34:25,133
Great question.

558
00:34:25,200 --> 00:34:28,740
So the best thing to do is to contact
the author of the code base, right?

559
00:34:28,741 --> 00:34:33,741
So they are the architect and they
know what parts are best for beginners.

560
00:34:34,170 --> 00:34:37,980
So don't just try to dive in
yourself, contact the author, um,

561
00:34:38,010 --> 00:34:41,400
look at the documentation.
Ideally, ideally it's got
documentation, but if not,

562
00:34:41,401 --> 00:34:44,940
contact the author and uh, they
will help you. They will guide you.

563
00:34:44,970 --> 00:34:49,110
Don't just try to do it yourself. I mean
you can, but uh, it would take longer.

564
00:34:49,111 --> 00:34:52,290
So you want to go the
fastest way to do this. Um,

565
00:34:53,580 --> 00:34:57,460
what bit are you thinking of making
next? Um, I want videos on GPU,

566
00:34:57,461 --> 00:35:01,800
s specifically GPU providers.
Should I go for AI or ml?

567
00:35:01,801 --> 00:35:05,500
Which one before? Guys, AI is the
biggest bubble machine. One again,

568
00:35:05,501 --> 00:35:09,630
is inside and deepening its inside,
but she wanted, gives a subset of Ai.

569
00:35:10,830 --> 00:35:14,190
Do you think Java's triple
over Tech Python soon in ml?

570
00:35:14,280 --> 00:35:18,150
I don't think it's going to overtake it,

571
00:35:18,420 --> 00:35:21,570
but I think it will catch up for sure.
It is catching up.

572
00:35:22,290 --> 00:35:25,860
Is machine learning very impro if very
important. Of course it is my niece.

573
00:35:25,861 --> 00:35:29,250
Thank you. And two more
questions. Two more questions.

574
00:35:30,450 --> 00:35:35,100
Is Floyd costly when you said
train and test? Um, yes. So,

575
00:35:35,101 --> 00:35:39,060
so that's why I'm saying it's
only for beginners, right?

576
00:35:39,061 --> 00:35:42,130
Because once you want to start scaling,
Dan's going to get expensive. And,

577
00:35:42,150 --> 00:35:43,890
and I think when it comes to scaling,

578
00:35:43,891 --> 00:35:47,730
you want them the cheapest solution
that is also the most dependable.

579
00:35:47,940 --> 00:35:52,770
And for that I would choose either AWS
cloud or Azure. But to start off with,

580
00:35:52,860 --> 00:35:57,210
you know, there's, there's a very
small learning curve for Floyd hub.

581
00:35:57,240 --> 00:36:00,450
That's why you should start with that.
Um,

582
00:36:02,440 --> 00:36:03,273
okay.

583
00:36:03,400 --> 00:36:06,450
How does start with deep learning? Uh,
watch my intro to deep learning, sir.

584
00:36:06,490 --> 00:36:10,960
Playlist on Youtube. Juris law. Um,
it's because that's my signature.

585
00:36:11,290 --> 00:36:15,820
And a William, last question. What ceiling
would you recommend for tensorflow?

586
00:36:16,060 --> 00:36:17,650
I would recommend python.
Okay.

587
00:36:17,651 --> 00:36:20,320
So now I'm going to rap about some
topics where someone just say a topic,

588
00:36:20,321 --> 00:36:21,154
one word go

589
00:36:24,230 --> 00:36:28,530
Friday everybody. It's Friday.
How it kind of a hard beat.

590
00:36:30,960 --> 00:36:33,770
Here we go.
All right,

591
00:36:33,771 --> 00:36:38,270
so I'm about to wrap NASA a freestyle.
Someone's going to say a topic right now.

592
00:36:41,850 --> 00:36:45,840
Here we go. Where's the, where's
the, where's the topic guys?

593
00:36:48,650 --> 00:36:49,483
Where's the topics?

594
00:36:50,360 --> 00:36:55,360
I think these guys are a Gnn
that's not really like a topic.

595
00:36:56,690 --> 00:36:57,523
Awesome.
Awesome.

596
00:37:00,780 --> 00:37:01,290
Okay.

597
00:37:01,290 --> 00:37:05,530
Hey Yo, are we some Isaac
Asimov? Don't try to look at me.

598
00:37:05,531 --> 00:37:09,580
Don't try to Piss me off.
I try to read Psi by him.

599
00:37:09,581 --> 00:37:13,090
My books in mom movies in my
looks try to dress that way.

600
00:37:13,180 --> 00:37:16,840
I got hair is so wavy. Okay. I level up.

601
00:37:16,841 --> 00:37:20,770
I leveled down NLP man.
I'm rapping like a cloud.

602
00:37:20,980 --> 00:37:25,750
You guys are laughing in the chat but
it's okay cause I got big coin any way.

603
00:37:26,050 --> 00:37:30,850
It's all good. Hey, hey.
Hey. All right. Oh Wow.

604
00:37:30,870 --> 00:37:32,690
Actually I sleep with her.
Alright guys,

605
00:37:32,691 --> 00:37:34,380
so thanks for tuning
in to this live stream.

606
00:37:34,490 --> 00:37:37,280
I've got more livestreams coming
up for you. I love you guys.

607
00:37:37,281 --> 00:37:40,880
Thank you for watching. I've got so much
AI machine learning content coming up.

608
00:37:40,881 --> 00:37:45,200
So if you haven't subscribed, hit
the subscribe button and, um, yeah.

609
00:37:45,260 --> 00:37:46,093
Thanks guys

610
00:37:46,340 --> 00:37:47,990
for watching.
Okay.

