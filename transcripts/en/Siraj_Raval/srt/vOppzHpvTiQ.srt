1
00:00:00,120 --> 00:00:00,781
Hello world.

2
00:00:00,781 --> 00:00:05,220
It's Saroj and welcome to intro to deep
learning and this first episode will

3
00:00:05,221 --> 00:00:08,520
predict an animal's body weight
given only the weight of its brain.

4
00:00:08,820 --> 00:00:12,480
This course will be four months long
and it'll all be released on my channel.

5
00:00:12,690 --> 00:00:15,570
I'll have a live session every
Wednesday at 10:00 AM pst.

6
00:00:15,750 --> 00:00:19,770
That explains every week's topic in depth
and I'm collaborating with you Udacity

7
00:00:19,920 --> 00:00:23,160
to offer a nanodegree to those that
successfully complete this course.

8
00:00:23,340 --> 00:00:26,940
This course is for anyone who wants to
learn how to harness the incredible power

9
00:00:27,120 --> 00:00:29,610
of neural networks and become
a deep learning engineer.

10
00:00:29,910 --> 00:00:32,820
You don't have to be an experienced
developer or a mathematician.

11
00:00:33,000 --> 00:00:37,230
The only prerequisite for this course is
knowing quantum mechanics. Just kidding.

12
00:00:37,231 --> 00:00:38,790
Only basic python syntax.

13
00:00:39,000 --> 00:00:42,330
We'll learn what we need to along
the way by building an AI that can do

14
00:00:42,360 --> 00:00:44,970
everything from predicting
the price of Tesla stock,

15
00:00:45,120 --> 00:00:47,280
the painting surrealists masterpieces.

16
00:00:47,490 --> 00:00:51,630
Traditionally programming has been about
defining every single step for program

17
00:00:51,750 --> 00:00:54,420
to reach an outcome,
but machine learning flips that approach.

18
00:00:54,600 --> 00:00:55,433
With machine learning,

19
00:00:55,560 --> 00:00:59,070
we defined the outcome and the
program learns the steps to get there.

20
00:00:59,400 --> 00:01:03,330
So if I want it to build an APP that
can recognize California license plates

21
00:01:03,690 --> 00:01:04,890
instead of writing out coach,

22
00:01:04,891 --> 00:01:08,100
you recognize the hundreds of
different features of a license plate,

23
00:01:08,310 --> 00:01:11,730
like the shape of certain letters
and the colors. We just say,

24
00:01:11,850 --> 00:01:14,310
here are some examples of
a California license plate.

25
00:01:14,580 --> 00:01:16,770
Learn the steps you need so
that you can recognize it.

26
00:01:17,100 --> 00:01:20,970
Or if I wanted to make a Bot that can
beat Super Mario instead of writing code

27
00:01:20,971 --> 00:01:23,370
for every possible scenario,
like jump.

28
00:01:23,371 --> 00:01:25,200
If you see a coupon and
it's running towards you,

29
00:01:25,380 --> 00:01:28,260
we'd say the goal is to get to
the end point without dying.

30
00:01:28,500 --> 00:01:32,130
Learn the steps to get there and sometimes
we don't even have an idea of what

31
00:01:32,131 --> 00:01:33,540
steps could possibly be.

32
00:01:33,810 --> 00:01:37,110
Like if we're a bank and we suspect
there's some kind of fraudulent activity

33
00:01:37,111 --> 00:01:37,680
happening,

34
00:01:37,680 --> 00:01:41,460
but we're not sure exactly how to detect
that or even know what to look for,

35
00:01:41,610 --> 00:01:44,430
we can say,
here's a log of all user activity.

36
00:01:44,640 --> 00:01:48,300
Find the users that are unlike the rest
and it will learn the steps to detect

37
00:01:48,301 --> 00:01:52,020
the anomalies by itself. Machine learning
is already everywhere on the Internet.

38
00:01:52,050 --> 00:01:55,260
Every major service uses it in some way.
In fact,

39
00:01:55,450 --> 00:01:58,770
youtube using it right now to decide
which other videos you might like.

40
00:01:58,950 --> 00:02:02,310
As you watch this and it's use
as will only grow over time.

41
00:02:02,311 --> 00:02:05,070
It will be embedded in all of
our internet connected devices.

42
00:02:05,071 --> 00:02:08,580
Everything from fridges, two
cars, two personal assistants,

43
00:02:08,790 --> 00:02:10,680
we learning and adapting to our needs.

44
00:02:10,950 --> 00:02:15,210
And you know that rule that says you need
10,000 hours to master any skill? Well,

45
00:02:15,211 --> 00:02:18,720
we'll just be able to offload
that training time to our
machines and it'll give

46
00:02:18,721 --> 00:02:23,640
us superpowers instantly. Anyone will
be able to compose a symphony. Alexa,

47
00:02:23,641 --> 00:02:27,460
I feel melancholy. Make me a piano
piece for this and how to be to it.

48
00:02:29,100 --> 00:02:32,610
Anyone will be able to direct the
movie. Okay Google, recreate star wars,

49
00:02:32,640 --> 00:02:35,460
but put me in it.
I dockerize most of my code now.

50
00:02:37,500 --> 00:02:40,170
Damn right. With machine
learning, if you can dream it,

51
00:02:40,320 --> 00:02:44,820
it can exist and the field is currently
advancing very fast as researchers build

52
00:02:44,821 --> 00:02:49,200
on each other's work. Ah, my
neural nets sucks. Go deeper. Wow.

53
00:02:49,201 --> 00:02:50,430
I just achieved state of the art.

54
00:02:51,720 --> 00:02:54,930
There are a lot of machine learning models
out there and one of them is called a

55
00:02:54,931 --> 00:02:56,070
neural network.

56
00:02:56,250 --> 00:03:00,550
When we use a neural network that's not
just one or two but layers deep to make

57
00:03:00,551 --> 00:03:02,830
a prediction,
we call that deep learning.

58
00:03:03,010 --> 00:03:07,000
It's a subset of machine learning that
has outperformed almost every other type

59
00:03:07,001 --> 00:03:10,180
of model almost every time
on a huge range of tasks.

60
00:03:10,450 --> 00:03:12,460
We'll dive into deep
learning more next episode,

61
00:03:12,461 --> 00:03:15,430
but this video will just focus
on machine learning in general.

62
00:03:15,610 --> 00:03:18,130
We usually class learning
into three different styles.

63
00:03:18,370 --> 00:03:21,850
The first style is called supervised
learning. It's where we give a model,

64
00:03:21,880 --> 00:03:23,620
a labeled Dataset like car pictures,

65
00:03:23,740 --> 00:03:25,960
so it gets feedback on what's
correct and what's not.

66
00:03:26,170 --> 00:03:29,320
It just had to learn the mapping between
the labels and that data and then it

67
00:03:29,321 --> 00:03:32,860
can fall some given task like
classifying the type of car and an image.

68
00:03:33,070 --> 00:03:36,310
It's all relatively straightforward and
we've gotten incredible results from it.

69
00:03:36,580 --> 00:03:39,220
The second learning style is
called unsupervised learning.

70
00:03:39,550 --> 00:03:42,220
This is when we give a model
a dataset without labels.

71
00:03:42,310 --> 00:03:44,740
It gets no feedback on
what's correct or not.

72
00:03:44,741 --> 00:03:49,300
It has to learn by itself
what the structure of the
data is to solve some given

73
00:03:49,301 --> 00:03:52,010
task. This is harder to
do, but more convenient.

74
00:03:52,011 --> 00:03:55,270
Since not everyone has a perfectly
labeled dataset sitting around.

75
00:03:55,510 --> 00:03:57,940
Most data is unlabeled,
it's messy and complex,

76
00:03:58,450 --> 00:04:00,490
and the third type is
reinforcement learning.

77
00:04:00,491 --> 00:04:03,370
This is where it model isn't
given feedback right off the bat.

78
00:04:03,580 --> 00:04:05,590
It only gets it if it achieves its goal.

79
00:04:05,770 --> 00:04:09,220
So if we're trying to create
a reinforcement learning
Bot that can learn to beat

80
00:04:09,221 --> 00:04:12,610
humans at chess, it would only
receive feedback if it won the game.

81
00:04:12,610 --> 00:04:14,260
Whereas in the supervisor approach,

82
00:04:14,261 --> 00:04:17,170
we get feedback every move and
in the unsupervised approach,

83
00:04:17,350 --> 00:04:21,070
we'd never get feedback even if it won,
unlike the other two learning styles.

84
00:04:21,280 --> 00:04:25,240
Reinforcement learning is linked to the
idea of interacting with an environment

85
00:04:25,420 --> 00:04:26,500
through trial and error.

86
00:04:26,710 --> 00:04:29,890
So I've got a data set of measurements
of different animals and we want to

87
00:04:29,891 --> 00:04:32,200
predict an animal's body
weight given its brain weight.

88
00:04:32,530 --> 00:04:33,930
Since our data is labeled.

89
00:04:33,931 --> 00:04:37,690
This will be a supervisor approach and
the type of machine learning task will

90
00:04:37,691 --> 00:04:42,040
perform is called regression will write
out a 10 line python script to do this

91
00:04:42,250 --> 00:04:43,750
and I'll explain things as we go.

92
00:04:44,140 --> 00:04:46,240
We'll start off by importing
our three dependencies.

93
00:04:46,360 --> 00:04:48,790
The first one is pandas which
will let us read our Dataset.

94
00:04:49,000 --> 00:04:50,410
The second one is psychic learn,

95
00:04:50,411 --> 00:04:54,280
which is the machine learning library
we're using for this example and the third

96
00:04:54,281 --> 00:04:57,520
is map taught live which will let
us visualize our model and data.

97
00:04:57,880 --> 00:05:01,600
Now that we've imported our dependencies,
we can read our dataset using pandas.

98
00:05:01,780 --> 00:05:05,710
We'll use the read FWF function to
read our animal data, set a table,

99
00:05:05,711 --> 00:05:09,730
a fixed with formatted lines into a pen
as data frame object which is a two d

100
00:05:09,731 --> 00:05:13,450
data structure of rows and columns are
dataset contains the average brain and

101
00:05:13,451 --> 00:05:15,760
body weight for a number
of animal species.

102
00:05:15,970 --> 00:05:17,980
Once our data is in our
data frame variables,

103
00:05:18,100 --> 00:05:21,490
we can easily parse and read both
measurements into two separate variables.

104
00:05:21,730 --> 00:05:25,060
We'll store our brain measurements and
the x value is variable and the body

105
00:05:25,061 --> 00:05:26,920
measurements in the y value is variable.

106
00:05:27,070 --> 00:05:30,190
So if we were to plot this data
right now on a standard two d graph,

107
00:05:30,340 --> 00:05:34,070
it would look like this. And our goal
is that given a new animals bodyweight,

108
00:05:34,180 --> 00:05:38,380
we'll be able to predict what it's brain
sizes. So how are we going to do that?

109
00:05:38,800 --> 00:05:42,820
Yeah. Uh Huh. You know what it
is independent, independent,

110
00:05:43,000 --> 00:05:44,320
independent and depend.

111
00:05:44,321 --> 00:05:47,320
What data's got the values for
the brain and the body weight.

112
00:05:47,410 --> 00:05:50,230
And I'm wondering what to
use to find that they relate.

113
00:05:50,430 --> 00:05:53,080
Linear regrets helps
find the relationship.

114
00:05:53,081 --> 00:05:56,890
We're gunna measure it and find the
only line of best fit the equation.

115
00:05:56,900 --> 00:06:01,640
Y equals Mx. Plus B is all we need
is the y intercept and m measures.

116
00:06:01,641 --> 00:06:05,360
House deed plotted on the graph.
Let's predict the body with the brain.

117
00:06:05,630 --> 00:06:08,310
Low Air ops, champagne. Well

118
00:06:08,310 --> 00:06:08,761
you suck.

119
00:06:08,761 --> 00:06:12,570
It learns linear model object
to initialize our linear
regression and store it

120
00:06:12,571 --> 00:06:15,930
in the body regression variable.
Then we can fit our model on our x,

121
00:06:15,931 --> 00:06:19,320
y value pairs. Now that we have the
line of best fit, we can plot our x,

122
00:06:19,321 --> 00:06:22,110
y value pairs on a map,
plot lives scatterplot, Ben,

123
00:06:22,111 --> 00:06:25,710
plot our regression line by saying
for every x value we have predict the

124
00:06:25,711 --> 00:06:28,860
associated why value and draw a line
that intersects all those points,

125
00:06:29,280 --> 00:06:31,140
we can then display it
using the show function.

126
00:06:31,380 --> 00:06:33,180
Let's go ahead and compile
this code in terminal.

127
00:06:33,470 --> 00:06:36,180
Our scatter plot will appear with
all our data points mapped out.

128
00:06:36,450 --> 00:06:40,040
The x axis represents brain weights
and the y axis represents body weights.

129
00:06:40,380 --> 00:06:43,740
Our regression line seems to fit most of
the data pretty well and there seems to

130
00:06:43,741 --> 00:06:47,490
be a very strong correlation here between
brainwave and bodyweight and as we

131
00:06:47,491 --> 00:06:49,590
move along the line given any brainwave,

132
00:06:49,770 --> 00:06:53,100
we can also predict the associated
bodyweight. So to break it down,

133
00:06:53,101 --> 00:06:56,760
while traditional programming is about
defining the steps to reach an outcome,

134
00:06:57,000 --> 00:07:00,720
machine learning is about defining the
outcome and our program will learn the

135
00:07:00,721 --> 00:07:04,560
steps to get there. There are three
different learning styles, supervised,

136
00:07:04,770 --> 00:07:08,640
unsupervised and reinforcement
learning and linear regression models.

137
00:07:08,641 --> 00:07:12,420
The relationship between an independent
and dependent variable to create the

138
00:07:12,421 --> 00:07:15,120
line of best fit,
which we can then use to make predictions.

139
00:07:15,540 --> 00:07:18,360
The winter of last week's coding
challenge is Mick Fan Holt.

140
00:07:18,630 --> 00:07:22,830
He modified the game world to be more
complex and his cue learning Bob was much

141
00:07:22,831 --> 00:07:24,480
more efficient and reaching the goal.

142
00:07:24,481 --> 00:07:28,590
Then my demo bought wizard of the week
and the runner up is Michelle Batu.

143
00:07:28,650 --> 00:07:31,350
He generated maps using
cellular automaton.

144
00:07:31,620 --> 00:07:35,670
The challenge for this video is to use
psychic learn to create a regression line

145
00:07:35,840 --> 00:07:39,450
for a different dataset that all provide
and print out the error between your

146
00:07:39,451 --> 00:07:41,370
prediction and the actual value.

147
00:07:41,670 --> 00:07:44,850
Details are in the read me posts or
get help link in the comments and I'll

148
00:07:44,851 --> 00:07:46,110
announce the winner in one week.

149
00:07:46,410 --> 00:07:50,010
Please hit that subscribe button and
for now I've got to feel the learn,

150
00:07:50,190 --> 00:07:51,450
so thanks for watching.

