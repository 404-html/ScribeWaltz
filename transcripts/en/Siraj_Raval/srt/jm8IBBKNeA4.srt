1
00:00:00,780 --> 00:00:01,730
All right.

2
00:00:03,350 --> 00:00:05,330
All right.
We're about to go live.

3
00:00:05,390 --> 00:00:09,500
I'm going to start streaming and
there we go. Okay, here I come.

4
00:00:09,501 --> 00:00:14,390
I'm going to about to go live. All
right. Hello world. It's a Raj,

5
00:00:14,391 --> 00:00:16,040
and in this live stream,

6
00:00:16,041 --> 00:00:19,460
we're going to be solving
this Kaggle competition.

7
00:00:19,790 --> 00:00:24,020
This is a $100,000 salt
identification challenge,

8
00:00:24,170 --> 00:00:28,100
right on Kaggle is, you can see right
here, there's a month to go still.

9
00:00:28,101 --> 00:00:31,340
So there's still time to,
to compete in this challenge.

10
00:00:31,610 --> 00:00:36,610
And there are 2100 teams across the
world that are competing for this 100 k

11
00:00:37,250 --> 00:00:40,640
prize money and of those teams,
I am one of them.

12
00:00:40,670 --> 00:00:45,140
And what I'm going to do is I'm going
to try to win that prize money in this

13
00:00:45,160 --> 00:00:48,710
livestream because I'm crazy.
We'll see how far I can go, right?

14
00:00:48,711 --> 00:00:50,660
And I'm going to do it with you.
What I want you to do,

15
00:00:50,661 --> 00:00:54,860
both my live stream people in the house
right now and my recorded viewers,

16
00:00:54,870 --> 00:00:57,460
we're going to later watch this video,
is I want you to fight,

17
00:00:57,590 --> 00:01:00,120
fire up a Google colab notebooks.

18
00:01:00,130 --> 00:01:05,090
I just go to colab.research.google.com
and I want you to fire up a notebook.

19
00:01:05,091 --> 00:01:08,720
Why am I saying this? Because you don't
have to deal with the dependencies.

20
00:01:09,080 --> 00:01:11,690
That's why we don't want to have
to deal with that to locally.

21
00:01:11,691 --> 00:01:15,500
And we can use colab to do
that. Okay. 100 K. Exactly.

22
00:01:15,740 --> 00:01:17,510
So that's what we're going to
do in this live stream. Let's,

23
00:01:17,511 --> 00:01:18,890
let's take a look at this data.
Okay.

24
00:01:18,891 --> 00:01:22,100
And you might be wondering what model are
you going to use for this? Right? Well,

25
00:01:22,101 --> 00:01:25,340
I'm not going to tell you because
that's my secret. No, of course I am.

26
00:01:25,341 --> 00:01:29,240
It's called a unit. It's a unit.
It's a type of convolutional network.

27
00:01:29,300 --> 00:01:30,440
We'll talk about that later,

28
00:01:30,441 --> 00:01:34,640
but we've got to do some exploratory
data analysis first. Okay.

29
00:01:34,970 --> 00:01:37,160
Hi everybody. Okay, so that's
what we're going to do.

30
00:01:37,370 --> 00:01:40,160
And let me just say 10 names and
then we're gonna get started.

31
00:01:40,370 --> 00:01:43,970
Vodoun Satya at Sun Deep Sigh.
Steve,

32
00:01:44,120 --> 00:01:48,740
Omar and [inaudible] and [inaudible].
All right,

33
00:01:48,920 --> 00:01:53,780
so and smart sniper. All right,
so I'll do a Q and a later on,

34
00:01:53,781 --> 00:01:56,630
but let me just get this, get
this thing started. Okay. So

35
00:01:58,420 --> 00:02:02,710
they want to, so they want to find,
they are oil and gas companies.

36
00:02:02,740 --> 00:02:05,980
They want to find where salt
deposits are in the earth.

37
00:02:06,040 --> 00:02:07,420
And you might be wondering why,

38
00:02:07,480 --> 00:02:11,140
because it turns out that where
there is a lot of salt, there's also,

39
00:02:11,141 --> 00:02:15,610
there tends to be a lot of oil and gas.
And why do they want oil and gas?

40
00:02:15,611 --> 00:02:17,080
Because they can sell that,
right?

41
00:02:17,081 --> 00:02:21,100
And so these companies make money
by drilling under the earth,

42
00:02:21,190 --> 00:02:23,320
finding oil and gas and selling that.

43
00:02:23,500 --> 00:02:28,420
And so right now a lot of this is done
by humans, right? Um, geophysicists,

44
00:02:28,450 --> 00:02:30,940
they're trying to predict
where salt is going to be.

45
00:02:31,030 --> 00:02:36,030
They have to use human vision to analyze
these seismic images and see and try to

46
00:02:37,271 --> 00:02:40,990
discern whether or not salt is present.
And if it is present,

47
00:02:41,080 --> 00:02:42,970
then it's a good idea to drill there.

48
00:02:43,150 --> 00:02:48,150
But the problem is if a human wrongly
classifies some piece of land as being

49
00:02:48,701 --> 00:02:53,530
salt rich, then they have to waste company
resources by drilling in that land,

50
00:02:53,531 --> 00:02:56,740
right? So they don't want to do
that. They want to be very efficient.

51
00:02:56,890 --> 00:03:01,890
So we want to use machine vision to
figure out which of these thousands of

52
00:03:02,231 --> 00:03:04,780
images have salt.
And once we find that,

53
00:03:04,781 --> 00:03:09,190
then we can dedicate all of our time
and resources and human capital towards

54
00:03:09,191 --> 00:03:13,480
that region of the earth to find the
oil and gas. How do we do this? Well,

55
00:03:13,990 --> 00:03:15,940
well,
it turns out if we look at the data,

56
00:03:16,580 --> 00:03:16,830
okay,

57
00:03:16,830 --> 00:03:18,270
the data that they've given us,

58
00:03:18,690 --> 00:03:23,100
what they've given us is a set of
images inside of this test and train,

59
00:03:23,190 --> 00:03:25,650
test and train file.
There's a train dot CSV.

60
00:03:25,830 --> 00:03:29,250
There's a test.zip and this
contains images. Okay. So,

61
00:03:29,870 --> 00:03:30,590
okay,

62
00:03:30,590 --> 00:03:35,040
let me just join this competition
real quick. Are, there we go. So, um,

63
00:03:36,000 --> 00:03:40,200
right. I've accepted the rules.
There we go. There we go. So, uh,

64
00:03:40,260 --> 00:03:42,390
it's got an ID and it's got a mask.
And we're,

65
00:03:42,391 --> 00:03:46,080
what we're going to do is we're going to
visualize this inside of Colab and then

66
00:03:46,081 --> 00:03:47,640
we're going to,
uh,

67
00:03:47,910 --> 00:03:51,330
perform some exploratory data analysis
and then build our model. Okay?

68
00:03:51,331 --> 00:03:54,750
So that's a bit of our background.
Let's just get right on into this. Okay.

69
00:03:54,751 --> 00:03:59,090
So I want you to in Colab with me certain
installing for dependencies that we're

70
00:03:59,100 --> 00:04:01,470
going to need that are not
to pre-installed here. Okay?

71
00:04:01,471 --> 00:04:06,420
So the first one is going to be, uh, image
io because we want to deal with images,

72
00:04:06,421 --> 00:04:07,830
right?
This is an image data set.

73
00:04:08,010 --> 00:04:12,300
I'm also going to show you how to import
a Kaggle Dataset into colab. Okay?

74
00:04:12,301 --> 00:04:14,880
So we're going to do that as well.
So we're going to,

75
00:04:15,030 --> 00:04:16,440
we're going to install image io,

76
00:04:16,441 --> 00:04:20,040
which is going to help
us with image processing.

77
00:04:20,340 --> 00:04:24,030
We're going to also install Pi torch
to build our deep learning model.

78
00:04:24,031 --> 00:04:28,710
Are you net model? Why am I
using Pi Torch? All the cool
kids are using Pi torch.

79
00:04:28,980 --> 00:04:32,730
I am one of them. And so are you probably,
so let's just, let's use some pie torch.

80
00:04:32,731 --> 00:04:35,490
Okay. Also, tensorflow is
cool. I know Google's watching.

81
00:04:35,491 --> 00:04:37,950
I know Kaggle is out there. I
love you guys as well. Look,

82
00:04:38,550 --> 00:04:42,480
I am so much less, um, how do I say this?

83
00:04:43,140 --> 00:04:46,470
Religious about a specific
framework. I, I, you know,

84
00:04:46,471 --> 00:04:47,970
sometimes you got to use Pi towards,

85
00:04:47,971 --> 00:04:51,630
sometimes you got to use a little bit of
tensor flow, whatever works, whatever.

86
00:04:51,631 --> 00:04:55,080
If there is an existing implementation
of whatever you want to build and it's

87
00:04:55,081 --> 00:04:59,100
already on get hub, I don't care
if it's in Kuda just use it, right?

88
00:04:59,101 --> 00:05:02,370
Whatever it is, they're build off of it
and then switch it to whatever. All right,

89
00:05:02,371 --> 00:05:04,080
so we're going to use Pi torch.

90
00:05:09,000 --> 00:05:13,230
What are you guys even saying
that seriously disrupt my
core with AI at Google.

91
00:05:13,231 --> 00:05:16,170
Amsterdam, you guys are
like on something. Anyway,

92
00:05:16,230 --> 00:05:20,130
so Pi Torch Kaggle as well.
Of course.

93
00:05:20,131 --> 00:05:24,030
That's how we're going to import the
datasets. And then lastly, um, Pi widgets,

94
00:05:24,031 --> 00:05:28,350
which is going to be like a
little graphical thing for,
to see how the model is,

95
00:05:28,380 --> 00:05:31,920
you know, training, it's a little visual
thing for us. So it's called Pi widgets.

96
00:05:32,130 --> 00:05:35,520
So what I'm gonna do is I'm just going
to go ahead and install all of these with

97
00:05:35,521 --> 00:05:36,960
this. Uh, that's it just for,

98
00:05:37,590 --> 00:05:41,370
and now he's going to do some dependency
installs for us in the browser.

99
00:05:41,460 --> 00:05:45,420
Using a GPU is a GPU runtime environment.
Boom.

100
00:05:45,480 --> 00:05:48,250
Image io successfully
installed. Sucks. Oh,

101
00:05:48,310 --> 00:05:51,270
torch is going to take a while for sure.
In the meantime, while this is loading,

102
00:05:51,480 --> 00:05:53,820
let me answer some questions here.
Hi.

103
00:05:53,821 --> 00:05:58,821
Can you say some use cases for
training on KL loss function.

104
00:05:59,600 --> 00:06:04,120
Oh Wow. Interesting. Yes, for sure. So
neural style transfer is one example that,

105
00:06:04,220 --> 00:06:07,580
so for those of you who don't know,
k l stands for,

106
00:06:08,060 --> 00:06:12,740
I'm going to mispronounce this cold
back. Leibler divergence. Okay.

107
00:06:13,460 --> 00:06:18,350
The coal back Leibler divergence. Um,
it's also used in some adversarial model.

108
00:06:18,351 --> 00:06:21,640
So generative adversarial networks.
It's used sometimes there. Um,

109
00:06:21,680 --> 00:06:23,960
but neural style transfer,

110
00:06:23,961 --> 00:06:26,570
whenever you want to take the style
of an image and put it on another one,

111
00:06:26,780 --> 00:06:28,550
whenever you want to do
an adversarial model,

112
00:06:28,551 --> 00:06:32,690
that could be a good use lost function
actually for adversarial models.

113
00:06:32,691 --> 00:06:36,860
That's one of the hottest areas of
research right now is figuring out what a

114
00:06:36,861 --> 00:06:41,600
good loss function for an adversarial
network would be. Um, those are two.

115
00:06:42,220 --> 00:06:45,080
Do you watch anime? No, I
used to watch dragon ball Z,

116
00:06:45,081 --> 00:06:48,740
but now I just make content and run the
school of Ai. That's, that's what I do.

117
00:06:49,730 --> 00:06:50,750
Hurray for Pi Torch.

118
00:06:50,751 --> 00:06:55,580
How do you easily decide the ml
algorithm to choose that is the,

119
00:06:55,850 --> 00:07:00,350
that is the value that you bring
as an AI researcher, as an,

120
00:07:00,351 --> 00:07:05,030
as a data scientist, as a machine learning
person, figuring out what model to use.

121
00:07:05,090 --> 00:07:09,620
Right? That's, that's what you bring. So
how it's not, it's not a simple process.

122
00:07:09,621 --> 00:07:13,640
You just have to get a feel for what all
these models are good for and when to

123
00:07:13,641 --> 00:07:17,730
use them. It's an intuition
that you have to build. Um,

124
00:07:18,230 --> 00:07:22,700
is Google colab faster than spider? I
have to say. I haven't used spider before.

125
00:07:22,850 --> 00:07:25,160
Can you explain about active learning?

126
00:07:25,190 --> 00:07:30,020
Active learning is learning in
real time. It's adaptive. Um,

127
00:07:30,110 --> 00:07:31,880
I would say reinforcement learning is,

128
00:07:31,881 --> 00:07:36,881
can be mostly categorized into that field
of particularly relating to optimizing

129
00:07:37,971 --> 00:07:39,500
some network of,
say,

130
00:07:39,501 --> 00:07:44,501
Internet of things devices or a supply
chain or some kind of real time pipeline

131
00:07:44,721 --> 00:07:48,080
of delivery or whatever.
How do we get better at Bda?

132
00:07:48,110 --> 00:07:51,230
Look at get hub repositories,
look at these Jupiter notebooks,

133
00:07:51,231 --> 00:07:54,110
watch my live streams to hit
subscribe if you haven't yet.

134
00:07:54,230 --> 00:07:58,970
That's how you get better. Please make
augmented reality models in videos,

135
00:07:59,060 --> 00:08:03,740
um, augmented reality models of
machine learning. Interesting.

136
00:08:04,070 --> 00:08:05,300
When,
uh,

137
00:08:05,330 --> 00:08:09,590
there is a good augmented reality
device that's accessible to consumers.

138
00:08:09,591 --> 00:08:13,730
I will do that. Not Magic leap.
Apple will do it. Let's just be real.

139
00:08:13,731 --> 00:08:18,170
Apple will be the one to do that
in 20, I think it's 20, 22 or 2020.

140
00:08:18,350 --> 00:08:20,540
When apple releases their ar device,

141
00:08:20,750 --> 00:08:25,670
that is the moment that ar becomes
mainstream. Give me motivation please.

142
00:08:25,730 --> 00:08:30,500
Okay. I, the fact that I'm
even here, it should be enough
motivation for you. Right?

143
00:08:30,501 --> 00:08:34,280
I could totally mess this up right now,
but that's it.

144
00:08:34,520 --> 00:08:39,500
M and M or MGK. Um, m and M. Okay. Okay.

145
00:08:39,501 --> 00:08:43,010
Great. So this installed. Okay. We don't
even need Pi Pi widgets. Actually that,

146
00:08:43,230 --> 00:08:45,080
that's just a nice to have.
Let's keep going here.

147
00:08:45,500 --> 00:08:47,230
So now we're going to
import our dependencies.

148
00:08:47,231 --> 00:08:48,980
So we're going to first import ols.

149
00:08:49,000 --> 00:08:51,740
That's going to be for our file input
output because we're going to have to deal

150
00:08:51,741 --> 00:08:55,560
with files. We're going to import
num Pi to do some matrix math.

151
00:08:55,561 --> 00:08:58,410
We do that every time we do
machine learning. Of course,

152
00:08:58,860 --> 00:09:00,080
we're going to import image Ieo,

153
00:09:00,090 --> 00:09:05,040
like we just installed a map plot lines
so that we can do some exploratory data

154
00:09:05,041 --> 00:09:07,950
analysis panda.
So we can do some data,

155
00:09:07,951 --> 00:09:10,500
preprocessing a porch,

156
00:09:10,501 --> 00:09:13,080
which we already installed.

157
00:09:15,450 --> 00:09:20,400
And then, um, we need to just in case
we need it, like a backup dataset.

158
00:09:20,430 --> 00:09:24,930
Let's important the torches a
torches like backup data thing.

159
00:09:25,410 --> 00:09:28,410
So that's that. That's, that's US
importing our dependencies. Okay,

160
00:09:28,411 --> 00:09:32,880
so now I'm going to show you how to
import data from Kaggle into Google colab.

161
00:09:32,910 --> 00:09:34,470
All right, so that's, that's
what I'm going to do here.

162
00:09:35,820 --> 00:09:38,670
So let me just compile this
import. Great. It worked.

163
00:09:38,940 --> 00:09:43,620
And so here's what we have to do.
We're going to say. So from Google,

164
00:09:43,621 --> 00:09:48,270
colab import files, and we need
to import a specific file here.

165
00:09:48,271 --> 00:09:52,320
Let me show you what I mean. So we want
to connect Kaggle took Google colab.

166
00:09:52,321 --> 00:09:56,670
So we're going to run this and so this
is going to give us an interface to

167
00:09:56,671 --> 00:09:59,430
upload a file to Google Colab.

168
00:09:59,610 --> 00:10:03,990
So what we're going to do is we're going
to go into our capital account, uh,

169
00:10:04,020 --> 00:10:07,920
go under my account. This is like a
throwaway, like super old accounts,

170
00:10:07,921 --> 00:10:08,754
so I don't even care.

171
00:10:08,820 --> 00:10:13,770
And then go to go to the API and
create a new API token. Okay.

172
00:10:13,920 --> 00:10:17,880
What is going to do is it's going to
download a file called Kaggle. Dot. Jason.

173
00:10:18,090 --> 00:10:22,350
Okay, I'm going to rename this to Kaggle.
Dot. Jason, cause I already have one.

174
00:10:22,920 --> 00:10:25,620
Kaggle. Dot. Jason. Good.

175
00:10:25,920 --> 00:10:30,270
And then we're going to upload that file
to Google Colab. So I'm going to say,

176
00:10:30,570 --> 00:10:34,800
um, choose files on the
desktop, Kaggle. Dot. Jason.

177
00:10:35,490 --> 00:10:37,650
And uh,
I did that.

178
00:10:40,460 --> 00:10:41,293
Okay.

179
00:10:42,030 --> 00:10:42,530
Okay.

180
00:10:42,530 --> 00:10:47,300
Right. Kaggle dot. Jason. There we go.

181
00:10:47,330 --> 00:10:51,770
Okay. There we go. Upload it. Awesome.
It's there now. So now that that's there,

182
00:10:52,070 --> 00:10:55,550
let's check if it's there. Okay. So what
we can do is we can run a command line,

183
00:10:55,610 --> 00:10:58,110
like a command here. So we can say, ah,

184
00:10:58,160 --> 00:11:02,180
let's do an ls and let's ensure that
the file that we just uploaded is indeed

185
00:11:02,181 --> 00:11:06,530
there. It's, it's right there.
Perfect. So now that the file is there,

186
00:11:06,531 --> 00:11:08,840
we can see we're connected
to the cow goal Api.

187
00:11:09,200 --> 00:11:13,400
And the reason I did this is because we
want to import that data set directly

188
00:11:13,401 --> 00:11:16,490
from Kaggle into colab. And this
is an important skill, by the way.

189
00:11:16,491 --> 00:11:20,150
You're going to need this.
So pay attention here. Um,

190
00:11:22,490 --> 00:11:24,290
so what I'm going to do now is yes,

191
00:11:24,291 --> 00:11:27,410
all this script is going to be uploaded
right after the live stream. Guys,

192
00:11:27,411 --> 00:11:29,840
there has to be some kind of
pomp and circumstance here.

193
00:11:29,841 --> 00:11:32,710
I can't just give you everything
from the start, right? You got it.

194
00:11:32,711 --> 00:11:35,090
It's got to be a journey so that,
that's how it goes.

195
00:11:35,091 --> 00:11:37,550
So now let's do some configuration.

196
00:11:37,551 --> 00:11:42,551
So the Kaggle Api client
actually prefers that we store,

197
00:11:43,250 --> 00:11:44,083
um,

198
00:11:46,490 --> 00:11:49,640
that we store it somewhere.

199
00:11:49,670 --> 00:11:54,320
What's the tilty till the mark? Like, um,

200
00:11:55,150 --> 00:11:57,010
this thing,
right?

201
00:11:59,010 --> 00:12:03,100
So, uh, we need to store it in
the Kaggle directory. So it's,

202
00:12:03,120 --> 00:12:07,710
that's where it's going to
expect it to be. And then we can,

203
00:12:07,711 --> 00:12:08,550
once we do that,

204
00:12:08,790 --> 00:12:13,590
we're going to copy that file to that
directory that we just created. Okay.

205
00:12:13,591 --> 00:12:15,270
That's what we're doing right now.

206
00:12:16,720 --> 00:12:19,810
We just created this directory
that's Dot Kaggle directory.

207
00:12:20,380 --> 00:12:22,470
And once it's there we
have to see h moderate.

208
00:12:22,471 --> 00:12:27,460
Can anybody tell me what ch Maude does?
A little bit of Unix, a quizzing for you.

209
00:12:28,420 --> 00:12:30,820
Hello world. It's her garage. So
somebody came here just for that.

210
00:12:30,821 --> 00:12:35,200
So I thought I would.
So ch mod 600 and this is for permissions,

211
00:12:35,201 --> 00:12:39,100
not 6,600 and once we have that,

212
00:12:39,370 --> 00:12:43,450
we're going to say,
just give it the permissions that it,

213
00:12:43,480 --> 00:12:46,840
that it needs because we're going to
access this file in a second. All right,

214
00:12:46,841 --> 00:12:51,360
so that's it for our file
configuration. All right, good.

215
00:12:51,570 --> 00:12:53,970
And now check this out.
Check this out.

216
00:12:54,210 --> 00:12:58,560
We can download our data
set directly from Kaggle.

217
00:12:59,520 --> 00:13:02,490
Good. Exactly. Yes.
Eunice unix permissions.

218
00:13:04,470 --> 00:13:08,860
Yeah, exactly. Copy that. I don't
care. You know what I mean? So, uh,

219
00:13:08,940 --> 00:13:12,040
we're going to download it exactly
from, uh, from there. So what we can do,

220
00:13:12,130 --> 00:13:14,430
you go here,
see here it is.

221
00:13:15,210 --> 00:13:17,700
We can just copy this and paste it here.

222
00:13:21,200 --> 00:13:24,890
Okay. And now we can download
this data set directly into

223
00:13:26,170 --> 00:13:27,003
colab.

224
00:13:27,830 --> 00:13:28,663
Yes.

225
00:13:29,130 --> 00:13:31,950
Good,
good.

226
00:13:35,520 --> 00:13:40,050
Yup. That's, that's how it should
be. That is how it should be.

227
00:13:42,360 --> 00:13:46,740
Now I'm going to unzip it. So I'm going
to say, well what do we have here?

228
00:13:47,720 --> 00:13:48,220
Okay.

229
00:13:48,220 --> 00:13:52,360
Okay. It's all here. All of those
files are now here with an ls.

230
00:13:52,390 --> 00:13:56,890
Remember exclamation point before ls.
Now once we have that,

231
00:13:56,950 --> 00:14:00,040
we are going to want to unzip
this train.zip file, right? We,

232
00:14:00,041 --> 00:14:03,460
cause we want to see these images,
we can't just have it be a zip file.

233
00:14:03,850 --> 00:14:07,780
So now it's going to unzip all of
those images and there are quite a lot,

234
00:14:07,781 --> 00:14:09,640
I think there's 1800 of these images.

235
00:14:10,360 --> 00:14:13,930
When will the school
of Ai Workshops start?

236
00:14:13,960 --> 00:14:15,700
That is a great question.

237
00:14:16,210 --> 00:14:19,450
We have a lot to do and um,

238
00:14:21,760 --> 00:14:23,140
look for midterms,
midterms.

239
00:14:23,141 --> 00:14:28,141
So five weeks in midterms or when I'm
going to feel like we'll all be ready to

240
00:14:28,961 --> 00:14:33,280
do, uh, a little, you know,
global hackathon kind of deal.

241
00:14:33,281 --> 00:14:36,910
No promises, but we're going to
do something big for sure guys.

242
00:14:37,150 --> 00:14:40,000
There's way too much that's coming. I
don't want to say it. I don't want to,

243
00:14:40,090 --> 00:14:42,460
I don't want to say what's happened,
what's going to happen.

244
00:14:42,490 --> 00:14:45,250
Like there's too much.
You guys aren't even going to believe it,

245
00:14:45,251 --> 00:14:47,590
so I don't even want to
get too hyped right now.

246
00:14:47,591 --> 00:14:51,010
So there's a lot of stuff coming like
in general that it's going to be,

247
00:14:51,710 --> 00:14:56,190
so anyway, so we downloaded all
those images and a, where is it?

248
00:14:56,420 --> 00:15:01,010
Okay. That's a lot, right? That's
a lot of images. Oh my God,

249
00:15:01,310 --> 00:15:05,790
hold on. That's a lot. Am I really
going to scroll through all this?

250
00:15:06,570 --> 00:15:07,180
Okay.

251
00:15:07,180 --> 00:15:08,380
Wow.

252
00:15:08,840 --> 00:15:11,830
Okay.
Hm Hm.

253
00:15:17,840 --> 00:15:20,990
Okay. There we go. So those
are all of our images.

254
00:15:23,060 --> 00:15:23,390
Okay.

255
00:15:23,390 --> 00:15:27,000
Hello Germany. Okay. All right.

256
00:15:27,240 --> 00:15:30,240
So now we're going to create a
class to represent our data set.

257
00:15:30,241 --> 00:15:32,490
So we downloaded our Dataset,
we connected it from Kaggle,

258
00:15:32,730 --> 00:15:35,040
and now we are going to
create a class for it. Okay.

259
00:15:35,041 --> 00:15:38,370
So our class is going to be

260
00:15:40,400 --> 00:15:41,200
okay.

261
00:15:41,200 --> 00:15:44,260
Just see where we are right now. Cool.
Cool. Cool. Everything's going well.

262
00:15:45,130 --> 00:15:47,560
Our class is going to be

263
00:15:48,330 --> 00:15:48,890
okay.

264
00:15:48,890 --> 00:15:53,450
Um,
tgs salt data set,

265
00:15:54,500 --> 00:15:57,620
that's what I'll call it. And the
input will be the Dataset that we have.

266
00:15:57,621 --> 00:16:01,430
All right, that's it. So this is just the
basic like preprocessing class, you know,

267
00:16:01,820 --> 00:16:02,653
simple stuff.

268
00:16:02,900 --> 00:16:07,900
But we're going to initialize it with
the location of the Dataset and the list

269
00:16:10,011 --> 00:16:12,440
of files.
By that I mean the images.

270
00:16:14,390 --> 00:16:16,170
Now,
um,

271
00:16:16,550 --> 00:16:19,850
let me set that root path to remember
this is the constructor function.

272
00:16:19,851 --> 00:16:24,740
So this just some basic initialization
steps here. And once we do that,

273
00:16:24,741 --> 00:16:28,040
now we're going to create to get her
methods the first get her method.

274
00:16:28,090 --> 00:16:31,610
This is really just for us to be
able to access what's inside of this,

275
00:16:32,090 --> 00:16:35,840
this inside of the data. We're just
gonna return the length of the law,

276
00:16:35,870 --> 00:16:38,000
the number of images that
we have. So, you know,

277
00:16:38,001 --> 00:16:42,080
we just needed a function that will
tell us how many images we have. That's,

278
00:16:42,110 --> 00:16:42,860
that's it.

279
00:16:42,860 --> 00:16:46,370
And then we need another function that's
going to get one of those images so we

280
00:16:46,371 --> 00:16:50,420
can actually process it and, and
do things with it. So by the index.

281
00:16:50,421 --> 00:16:52,400
So we'll give it a value,
an index value.

282
00:16:52,401 --> 00:16:56,870
And we'll say somewhere at
this index we want to, um,

283
00:16:58,760 --> 00:17:03,440
we want to, uh, retrieve
whatever you've got.

284
00:17:03,500 --> 00:17:08,420
So the file id is going to be, uh,
we're going to give it the index.

285
00:17:08,421 --> 00:17:11,960
That's going to be the place in the file
list array. That's gonna be our file Id.

286
00:17:12,350 --> 00:17:14,150
And then we're going to
give it the image folder.

287
00:17:14,180 --> 00:17:17,300
And this is where we use the [inaudible]
command that I talked about earlier,

288
00:17:17,301 --> 00:17:20,270
the operating system or
not command the library.

289
00:17:20,630 --> 00:17:23,900
And we're going to join the
root path with the images.

290
00:17:24,860 --> 00:17:25,693
Yeah.

291
00:17:25,770 --> 00:17:27,690
Now it's not enough to
just have the folders.

292
00:17:27,691 --> 00:17:30,540
We're going to have the path
as well, the image path. Okay.

293
00:17:30,600 --> 00:17:35,520
So we're going to do this not just for
the image, but for the, um, the mask.

294
00:17:35,521 --> 00:17:39,120
So let me talk about the mask as well.
We have a mask.

295
00:17:44,470 --> 00:17:49,210
[inaudible] image folder,
file id,

296
00:17:50,010 --> 00:17:52,410
and plus.
Dot.

297
00:17:52,411 --> 00:17:55,320
P and g are right.

298
00:17:55,500 --> 00:17:59,010
That's our image folder in our image path.
Okay,

299
00:17:59,250 --> 00:18:02,190
so file ID,
image folder,

300
00:18:03,420 --> 00:18:07,710
image path.
And that's good.

301
00:18:07,770 --> 00:18:11,010
That's good for that. Now, so
this is, let me just comment this.

302
00:18:11,011 --> 00:18:14,580
So this is going to be for
heart image folder plus path.

303
00:18:15,090 --> 00:18:19,530
Now we actually need another one for
the uh, the label folder plus pass.

304
00:18:19,531 --> 00:18:22,110
So what is our label here?
So let's, let's, let's,

305
00:18:22,170 --> 00:18:24,930
I'm going to visualize this and
then it'll be much more interesting,

306
00:18:26,430 --> 00:18:30,950
but right now I want to just say the,

307
00:18:31,130 --> 00:18:33,540
the label is going to be,

308
00:18:34,680 --> 00:18:35,290
yeah,

309
00:18:35,290 --> 00:18:38,920
uh, I'm just going to copy this
actually. The label's going to be the,

310
00:18:38,980 --> 00:18:42,220
the mass image of the salt and I'll
show you exactly what I mean by that,

311
00:18:42,610 --> 00:18:45,160
but it's going to call them,
it's gonna be called mask folder.

312
00:18:45,280 --> 00:18:48,520
It's gonna be called Mass Path. And
we're going to use the same operations,

313
00:18:48,521 --> 00:18:52,690
except this is going to be the root path.
There's going to be called masks.

314
00:18:52,960 --> 00:18:57,340
And then this is going to be
called the mask folder. Okay.

315
00:18:57,341 --> 00:19:01,000
Mass folder plus file id plus P
and. G. That makes sense. Okay,

316
00:19:01,001 --> 00:19:05,170
now we have both of those. Now we can
read it, read it, and store it in memory.

317
00:19:05,410 --> 00:19:09,490
So remember, these are not formatted
for proper data preprocessing.

318
00:19:09,640 --> 00:19:10,660
That's what we have to do.

319
00:19:10,780 --> 00:19:14,740
So we're going to convert these into
byte arrays using the image io library.

320
00:19:14,920 --> 00:19:17,590
We're going to read whatever that,
um,

321
00:19:18,550 --> 00:19:20,200
that data directly,

322
00:19:20,350 --> 00:19:24,750
and we're going to convert it into
a byte array right here and p. Dot.

323
00:19:24,751 --> 00:19:27,160
You int eight?

324
00:19:28,190 --> 00:19:29,023
Uh Huh.

325
00:19:29,060 --> 00:19:33,380
D type, I think that works. I feel
like this should be highlighted.

326
00:19:33,830 --> 00:19:35,930
D type equals

327
00:19:37,680 --> 00:19:40,140
you int eight,
right?

328
00:19:41,090 --> 00:19:41,923
No.

329
00:19:44,210 --> 00:19:45,890
Yeah, that's fine. So that's that.

330
00:19:45,891 --> 00:19:49,100
And now we want one more and that's gonna
be for the mask and that's going to be

331
00:19:49,101 --> 00:19:54,020
an umpire or re, uh, we're
gonna read that one as well.

332
00:19:54,300 --> 00:19:58,850
Now that's gonna be the mask path mass
path. So now that we have both of those,

333
00:19:58,910 --> 00:20:03,440
now we can return them both. Right? So
this is, this is just that basic class.

334
00:20:03,441 --> 00:20:07,790
We want it to make data preprocessing
step and now we can finally return both

335
00:20:07,791 --> 00:20:11,780
the image and the mask. Why
byed array? Because that's,

336
00:20:11,960 --> 00:20:14,450
that is what our neural network will,
it will expire.

337
00:20:14,480 --> 00:20:19,010
Expect it's going to need a
vectorized format. Uh, right.

338
00:20:19,580 --> 00:20:21,380
It's going to need a vectorized format.

339
00:20:21,410 --> 00:20:25,520
Now the number of dimensions that your
input data should be will depend on your

340
00:20:25,521 --> 00:20:27,830
neural network for the unit in particular.

341
00:20:27,831 --> 00:20:32,690
We're going to do it this way and I'll
tell you why when we build the unit. Okay,

342
00:20:32,930 --> 00:20:36,740
we've got some people typing in Russian
in the chat and all sorts of languages,

343
00:20:37,010 --> 00:20:39,390
which is amazing. It's
amazing to see that. Uh,

344
00:20:39,530 --> 00:20:42,800
we have a very global
community here. Um, and yeah,

345
00:20:42,830 --> 00:20:44,750
I just feel very honored
to have everybody here,

346
00:20:44,751 --> 00:20:48,070
both my live and my recorded viewers.
Thank you for being here. Okay,

347
00:20:48,100 --> 00:20:50,320
so now that's it for that,
for that a class.

348
00:20:51,580 --> 00:20:52,360
Okay.

349
00:20:52,360 --> 00:20:56,770
Wow. It did not. It actually
worked. Okay, let's keep going.

350
00:20:56,771 --> 00:20:59,740
I'm getting too good at this.
So now we, we created that.

351
00:20:59,800 --> 00:21:00,820
Now we're going to initialize it.

352
00:21:00,821 --> 00:21:04,330
We're going to actually use that
class that we just initialized.

353
00:21:06,040 --> 00:21:10,120
So we'll read or use panders to
read that CSV file first, right?

354
00:21:10,121 --> 00:21:14,470
The train though CSV, which contains the
ids for the images as well as the mask.

355
00:21:14,860 --> 00:21:17,980
And I'm about to visualize it so we can
finally see what I'm talking about here.

356
00:21:18,230 --> 00:21:18,640
Um,

357
00:21:18,640 --> 00:21:22,450
there's also one more data point that is
really interesting and that's the depth

358
00:21:22,510 --> 00:21:25,540
data and that's in its own CSV,
the file.

359
00:21:25,570 --> 00:21:30,570
Now what we can do is we can think of
that def file as a feature that we're

360
00:21:31,241 --> 00:21:34,600
going to input into our model, right?
So just we'll think of it as a feature.

361
00:21:35,270 --> 00:21:35,730
Okay.

362
00:21:35,730 --> 00:21:38,190
And, uh, if we think of it as a feature,

363
00:21:38,430 --> 00:21:43,430
then the idea of using a neural
network where the network is just,

364
00:21:45,000 --> 00:21:47,040
we don't have to do any
feature engineering, right?

365
00:21:47,041 --> 00:21:52,041
We can just input all the features we
need into our model and it's going to just

366
00:21:52,530 --> 00:21:55,530
figure out what the relevant
features are, right? That's the idea.

367
00:21:55,531 --> 00:21:59,700
So do we really know if it's going to be,

368
00:22:03,550 --> 00:22:06,400
do we really know if it's going to
be a relevant teacher? Who knows?

369
00:22:06,401 --> 00:22:09,400
We're going to have to visualize
it. All right, so now that I, okay.

370
00:22:10,170 --> 00:22:13,680
Dot. Values. Oh right list.

371
00:22:16,740 --> 00:22:20,400
Good
depth.

372
00:22:24,450 --> 00:22:25,283
What's the deal here?

373
00:22:27,270 --> 00:22:30,000
File be depth dot CSV.

374
00:22:32,490 --> 00:22:33,323
Really?

375
00:22:35,920 --> 00:22:38,170
Oh,
depths with an S.

376
00:22:42,040 --> 00:22:44,110
Okay.
Now let's visualize this.

377
00:22:44,540 --> 00:22:45,373
Okay,

378
00:22:46,590 --> 00:22:49,940
so now that we've imported it,
we can, we can visualize this.

379
00:22:49,941 --> 00:22:52,860
So we're going to say a plot,
a two by two array.

380
00:22:52,890 --> 00:22:55,800
This is going to be an image
using the image and the mass.

381
00:22:55,801 --> 00:22:59,400
So we're going to plot them side by side
so we can see what the differences and

382
00:22:59,401 --> 00:23:01,060
we can also,
um,

383
00:23:03,180 --> 00:23:04,013
okay,

384
00:23:04,290 --> 00:23:08,790
we can just analyze it. All right,
so, um, we're going to create a plot

385
00:23:10,240 --> 00:23:11,110
here

386
00:23:14,040 --> 00:23:18,690
and image show the image.
Okay,

387
00:23:18,840 --> 00:23:20,220
so actually no, no, no, no, no.

388
00:23:22,990 --> 00:23:27,070
We're going to say subplots we have,
we're going to create a subplot.

389
00:23:27,310 --> 00:23:31,660
And so for each of these axes we're
going to plot a different image.

390
00:23:31,661 --> 00:23:35,170
So we have to plot our original image.
Now next to it,

391
00:23:35,171 --> 00:23:37,210
we're going to plot our label.
What is our label?

392
00:23:37,240 --> 00:23:39,820
Our label is going to be our mask.
You might be thinking,

393
00:23:39,821 --> 00:23:42,970
why is a mask considered a label?
Well,

394
00:23:43,000 --> 00:23:48,000
the reason is because we want to segment
the salt and we want to say that it is

395
00:23:48,351 --> 00:23:49,184
different.

396
00:23:53,820 --> 00:23:54,653
Okay.

397
00:23:55,250 --> 00:23:56,960
From the input image.

398
00:24:03,590 --> 00:24:07,550
Okay. So set title, and
this is just for, to,

399
00:24:07,551 --> 00:24:11,000
for make to make it pretty a little
bit image and then set the title,

400
00:24:13,670 --> 00:24:17,660
the mask, the mask, the movie,

401
00:24:17,840 --> 00:24:22,450
the mask. All right.
That should work. Good.

402
00:24:22,660 --> 00:24:24,940
Now we can finally print it
out. All right. Just two lines.

403
00:24:24,941 --> 00:24:28,900
And then we can finally see these
images for let's just do five images,

404
00:24:28,901 --> 00:24:29,734
let's say,

405
00:24:29,830 --> 00:24:33,700
and we're going to print out both the
images and the mask from our Dataset and

406
00:24:33,701 --> 00:24:36,040
which ones? Well, let's
just randomly pick.

407
00:24:37,210 --> 00:24:37,660
Yeah.

408
00:24:37,660 --> 00:24:41,740
One between zero and you know,

409
00:24:41,770 --> 00:24:44,560
however big the data set is.
So the length of the Dataset

410
00:24:47,250 --> 00:24:51,580
and um,
yeah.

411
00:24:53,100 --> 00:24:58,100
And then we'll finally plot it using
our function that we created earlier.

412
00:24:58,560 --> 00:25:00,480
Image mask.

413
00:25:03,610 --> 00:25:04,443
What's the deal?

414
00:25:09,940 --> 00:25:12,430
Aix.
A R R is not defined.

415
00:25:14,550 --> 00:25:18,390
Oh,
okay.

416
00:25:23,930 --> 00:25:25,460
[inaudible] is not defined.

417
00:25:27,920 --> 00:25:32,370
Oh, oh, right. That's a,

418
00:25:32,390 --> 00:25:36,860
that's a dot method.
Gotcha. How about now?

419
00:25:38,810 --> 00:25:43,310
Yes. Good, good. Very good. Very good.

420
00:25:43,400 --> 00:25:48,080
Check this out. So, so
supervised learning,

421
00:25:48,081 --> 00:25:50,780
it's super easy. We're going to get
into reinforcement learning next week.

422
00:25:50,781 --> 00:25:54,800
Don't even worry. I have so
much reinforcement learning
content coming for you.

423
00:25:55,280 --> 00:25:58,100
You won't even be prepared.
That's how much I have coming for you.

424
00:25:58,101 --> 00:26:01,250
But right now let's focus on
supervised learning, right?

425
00:26:02,090 --> 00:26:04,550
So Soult identification,

426
00:26:05,000 --> 00:26:09,170
what they've done here is they created
a mask and what the mask does is it

427
00:26:09,171 --> 00:26:12,110
segments the salt in the seismic image.

428
00:26:12,290 --> 00:26:16,430
So on the left you're seeing
the raw seismic image of the,

429
00:26:16,490 --> 00:26:19,280
of the earth, right? The
layer of the earth that it's,

430
00:26:19,310 --> 00:26:23,510
that it's captured right next to it
is the mask and the mask is our label.

431
00:26:23,511 --> 00:26:27,570
Because what the mask does
is the white area is uh,

432
00:26:27,620 --> 00:26:31,640
where the salt is or no,
the black area is where the salt is.

433
00:26:31,880 --> 00:26:36,020
So it segments out the salt for
us. So we can see that. Okay,

434
00:26:36,021 --> 00:26:39,890
in the first image that's all white. So
there's no salt. But in the second image,

435
00:26:40,130 --> 00:26:44,170
yes there is some salt there in the
third image, not so much. Fourth, fifth.

436
00:26:44,400 --> 00:26:46,200
So that's how we are.

437
00:26:46,820 --> 00:26:47,410
Okay?

438
00:26:47,410 --> 00:26:49,900
That's the label that we're trying
to learn. There is a mapping.

439
00:26:49,901 --> 00:26:54,430
So consider the input a matrix of numbers,
a pixel values, right? Cause it is,

440
00:26:54,820 --> 00:26:59,770
it's a matrix of pixel values
and we want to be able to map,

441
00:26:59,771 --> 00:27:03,880
learn that mapping between that matrix
of pixel values and the label matrix

442
00:27:03,910 --> 00:27:07,180
pixel value. So just think of it as
the lines connecting all of them.

443
00:27:07,390 --> 00:27:08,240
And there's this,
there's a,

444
00:27:08,320 --> 00:27:13,320
there's one single function that we can
learn and this is the perfect optimal

445
00:27:13,781 --> 00:27:18,020
function that exists somewhere out there
in time and space on this hyper plane

446
00:27:18,040 --> 00:27:21,880
of curvature of optimization,
right? The optimization landscape.

447
00:27:22,060 --> 00:27:26,620
It's like a bunch of hills and valleys
and we want to find the ideal parameters

448
00:27:26,621 --> 00:27:27,730
for our function,
right?

449
00:27:27,731 --> 00:27:32,470
That function is going to
be this beautiful black box
where we input the image

450
00:27:32,500 --> 00:27:35,590
and it's going to output the mask,
which is going to tell us whether or not.

451
00:27:35,590 --> 00:27:38,440
So is there, the only problem is
we have to learn this function.

452
00:27:38,441 --> 00:27:39,700
We've got to learn those weights.

453
00:27:39,730 --> 00:27:43,690
And the search space for those weights
is massive. They can be anything.

454
00:27:44,020 --> 00:27:48,080
So what we're going to do is we're
going to use a very good model, a very,

455
00:27:48,700 --> 00:27:52,240
I don't want to say great, but a very
good model to learn this function. Okay.

456
00:27:52,540 --> 00:27:57,010
So great. So now we saw that. Okay.

457
00:27:57,460 --> 00:27:58,990
Uh, let's just, just for fun,

458
00:27:59,020 --> 00:28:03,790
let's just also plot the
distribution of depths so we can see,

459
00:28:03,791 --> 00:28:08,791
because there's this other interesting
statistic that we could use here called

460
00:28:12,990 --> 00:28:17,030
hello,
hello Poona and Hello Paris.

461
00:28:17,060 --> 00:28:19,190
We even have beans in
the house, guys, deans,

462
00:28:19,610 --> 00:28:24,230
our deans are here to help you
write the deans of school of Ai.

463
00:28:24,231 --> 00:28:28,040
And there are about 800 of them were not
accepting applications for new deans.

464
00:28:28,041 --> 00:28:30,620
We still have to build the
[inaudible] infrastructure that we've,

465
00:28:32,260 --> 00:28:34,090
I'm working on right now.
But after a while,

466
00:28:34,091 --> 00:28:36,700
we will start accepting new
applications for Dean's.

467
00:28:36,701 --> 00:28:38,260
Give us maybe like two or three months,

468
00:28:38,560 --> 00:28:41,590
but our deans are here to help you and
they're 800 of them. So definitely,

469
00:28:41,591 --> 00:28:45,660
you know, ask them questions.
They're here to help. Um, yeah,

470
00:28:46,370 --> 00:28:51,110
why so salty? I was waiting for
someone to say that. Good job. Truly,

471
00:28:51,890 --> 00:28:55,480
truly a funny person.
All right. So, um, ah,

472
00:28:56,360 --> 00:29:01,130
so now we're just going to
plot the distribution of
depth depth just because, um,

473
00:29:01,430 --> 00:29:05,210
it'd be interesting to see and then we
might use that as a feature depending on

474
00:29:05,211 --> 00:29:08,270
what it looks like because we want
to see if there's a correlation here.

475
00:29:08,450 --> 00:29:11,000
We'll just call it depth distribution.

476
00:29:12,440 --> 00:29:13,210
Okay.

477
00:29:13,210 --> 00:29:16,300
It could be interesting.
Okay, there we go.

478
00:29:16,750 --> 00:29:21,750
So what this is showing us
is a distribution of depths
for all of those images.

479
00:29:22,300 --> 00:29:24,730
So the depth is a number,
it's a scalar.

480
00:29:24,731 --> 00:29:29,650
It's a single number between z between
zero and 800 as we can see here.

481
00:29:30,310 --> 00:29:34,090
And what it's doing is it's measuring,
this graph shows us that, hey,

482
00:29:34,091 --> 00:29:35,800
most of the,
um,

483
00:29:36,890 --> 00:29:40,780
there it's most of the
depth values, the, the,

484
00:29:40,781 --> 00:29:45,250
the range of depth values is between
four and 600. It's about 500 ish.

485
00:29:45,760 --> 00:29:49,900
Now what would be interesting is to
see the correlation between these depth

486
00:29:49,901 --> 00:29:52,780
values and uh,
the,

487
00:29:55,010 --> 00:29:59,580
the, the, the occurrence of salt in
the image. So maybe we could even, um,

488
00:30:00,470 --> 00:30:00,970
okay,

489
00:30:00,970 --> 00:30:03,700
maybe we could even see what
that looks like. Right. So, um,

490
00:30:03,850 --> 00:30:06,850
there is one thing I want
to mention though is that,

491
00:30:10,630 --> 00:30:14,110
is that the, okay, so the image is
actually if we look in the data file,

492
00:30:14,140 --> 00:30:18,460
we'll notice the image is actually
in this run length in coding mask.

493
00:30:18,640 --> 00:30:21,580
It's an r l e mask,
which is just a bunch of numbers.

494
00:30:21,760 --> 00:30:24,100
So run linkedin coding by the way is,
I mean there,

495
00:30:24,160 --> 00:30:28,160
there are many different types of
encoding schemes out there, right? Um,

496
00:30:28,380 --> 00:30:30,340
but this is one of them.

497
00:30:30,400 --> 00:30:35,400
And it's a compression scheme and run
like the encoding is basically Tldr.

498
00:30:35,560 --> 00:30:39,130
It's a, it's, it's a lossless data
compression technique that says, you know,

499
00:30:39,280 --> 00:30:43,360
remember, remember images or matrices
right there, matrix. He's a pixel values.

500
00:30:43,660 --> 00:30:47,890
And in a single row the same value
could be repeated multiple times, right?

501
00:30:47,891 --> 00:30:51,670
So let's say that value for simplicity
sake is just the letter B or it's a

502
00:30:51,671 --> 00:30:55,660
number two 55 and if it's
repeated eight times in a row,

503
00:30:55,810 --> 00:30:59,350
well we can just say eight B or eight,

504
00:30:59,440 --> 00:31:03,460
two 55 as we see right here,
represents all those values.

505
00:31:03,610 --> 00:31:07,420
And so if we just store it like
that, that's less space. And it,

506
00:31:07,480 --> 00:31:11,320
and then we can like we can decode it.
I was looking for the word,

507
00:31:11,321 --> 00:31:13,660
we can decode it later. So, um,

508
00:31:14,000 --> 00:31:14,510
okay.

509
00:31:14,510 --> 00:31:18,650
Well we need to do is remember how we
said we have to do some data preprocessing

510
00:31:18,651 --> 00:31:19,880
to input it into our model.

511
00:31:20,060 --> 00:31:22,760
This is another data
preprocessing step we have to do.

512
00:31:22,940 --> 00:31:27,770
We have to convert that rung
linkedin coding scheme, um, into uh,

513
00:31:27,830 --> 00:31:32,720
an actual vector that we can
input into our, uh, unit,

514
00:31:32,750 --> 00:31:34,310
which I'm going to talk
about before we built.

515
00:31:34,311 --> 00:31:36,620
By the way we have to
go over how units work.

516
00:31:38,460 --> 00:31:38,910
Okay.

517
00:31:38,910 --> 00:31:40,440
So we have our width,
we have our height.

518
00:31:42,370 --> 00:31:42,870
Okay.

519
00:31:42,870 --> 00:31:47,520
We have our number of rows and columns,
right?

520
00:31:47,521 --> 00:31:51,900
Just the width and height of our image.
Okay. So I'm going to do a try, um,

521
00:31:52,110 --> 00:31:55,670
block here because I want to, because uh,
there could be an exception and we'll,

522
00:31:55,671 --> 00:31:56,850
we'll catch the exception there.

523
00:31:56,851 --> 00:32:00,660
But what we first want to do is get all
of those numbers and then those pair,

524
00:32:00,661 --> 00:32:04,560
so by numbers, remember has had eight
B. So eight is the number in that list.

525
00:32:04,561 --> 00:32:06,870
So we want to get those numbers.

526
00:32:10,280 --> 00:32:14,210
So get all of those numbers for the
RL e string and the string is what is

527
00:32:14,211 --> 00:32:17,450
specifying?
What's that R l e file.

528
00:32:20,650 --> 00:32:21,483
Okay.

529
00:32:22,200 --> 00:32:24,630
You guys are all over the
place in the chat. By the way,

530
00:32:24,840 --> 00:32:29,750
you guys need to not be talking about VGG.
Okay, we're, we're talking about units.

531
00:32:29,790 --> 00:32:34,110
Okay. Vgg is not as good for
this. It is objectively worse.

532
00:32:34,140 --> 00:32:39,060
That's I'm saying that right now a VGG
is objectively worse for this problem and

533
00:32:39,080 --> 00:32:43,670
a unit. Why? Just pay attention and
you'll see. You'll see why. Okay.

534
00:32:44,780 --> 00:32:48,980
Um, all right, I love you guys by the
way. So let's get back to this. All right,

535
00:32:48,981 --> 00:32:51,410
so that's our, those are our only
numbers, but that's not enough.

536
00:32:51,440 --> 00:32:54,260
We also need our pair of values.
Remember those pairs? There's just,

537
00:32:54,261 --> 00:32:57,140
there are a bunch of these parents,
so we're going to retreat both of those

538
00:32:58,830 --> 00:33:02,500
and it's going to be a num, py or
ray. We can reference it using those,

539
00:33:02,550 --> 00:33:06,630
the numbers variable that we just created
and we want to reshape it so that it

540
00:33:06,631 --> 00:33:10,620
fits into our network just like that.
Now that we have that,

541
00:33:10,621 --> 00:33:13,220
we can create our image.
We're using this, um,

542
00:33:14,700 --> 00:33:17,280
image variable and we're
initializing it as empty,

543
00:33:17,550 --> 00:33:21,950
but it's dimensions are the rose
by the columns, uh, that we,

544
00:33:22,230 --> 00:33:23,760
that we've already defined.

545
00:33:27,380 --> 00:33:31,670
And uh, you int eight. Okay,

546
00:33:32,870 --> 00:33:37,280
now, now we've defined this empty image
and now we can fill that image with the

547
00:33:37,281 --> 00:33:39,230
values that we've created here.

548
00:33:39,500 --> 00:33:42,920
So we'll say for index
length in our l e pairs,

549
00:33:43,550 --> 00:33:48,550
get the pixel value and then
store whatever we have defined

550
00:33:53,150 --> 00:33:56,360
right there. Okay? So
that's in our for loop.

551
00:33:56,930 --> 00:34:00,050
And now we can do some
reshaping and we can say, um,

552
00:34:02,000 --> 00:34:06,410
reshape that image by the
rows and columns and then,

553
00:34:09,770 --> 00:34:10,950
and then,
um,

554
00:34:12,270 --> 00:34:15,500
send it to its transpose because,
um,

555
00:34:19,050 --> 00:34:20,790
that's going to flip the black and whites.

556
00:34:23,900 --> 00:34:26,700
Um, so it's just easier to read because
the screen is already white in the

557
00:34:26,701 --> 00:34:31,530
background and that's the end of
our tri loop. And so we could say,

558
00:34:31,620 --> 00:34:35,160
let's, let's catch any exceptions.
Um, if there was an empty image,

559
00:34:35,161 --> 00:34:37,260
that's the exception,
then we'll just say, okay,

560
00:34:37,320 --> 00:34:39,570
it's just an empty image
and we'll return that.

561
00:34:42,600 --> 00:34:46,530
Okay. Okay. That's that.

562
00:34:47,310 --> 00:34:52,290
I think this needs one
more. Yup. And at the very,

563
00:34:52,291 --> 00:34:56,330
very end
well returned the image.

564
00:34:57,170 --> 00:34:59,270
All right.
That's it for that.

565
00:35:03,390 --> 00:35:07,740
That is it.
I'm your role model.

566
00:35:07,741 --> 00:35:12,450
Thank you very much. I like I, I
accept your responsibility. Okay.

567
00:35:12,480 --> 00:35:16,710
I accept that role. I accept the
role of being your role model.

568
00:35:16,770 --> 00:35:18,060
I will not let you down.

569
00:35:18,330 --> 00:35:23,330
I will continue to teach AI and continue
to inspire and educate for free.

570
00:35:23,970 --> 00:35:27,960
That's the real deal here for free.
Watch me develop,

571
00:35:27,961 --> 00:35:32,961
deliver some quality education for
free in a way nobody has done before.

572
00:35:33,360 --> 00:35:37,640
Watch. Just watch. Okay. But I guess
I'm doing it right now, but it's,

573
00:35:37,650 --> 00:35:41,370
this is the beginning. There's a
typo. How many hours do you study?

574
00:35:41,400 --> 00:35:43,800
Let me just take a one question.
How many hours do you study?

575
00:35:43,801 --> 00:35:45,150
I know this is a valuable question,

576
00:35:45,151 --> 00:35:48,780
so I'm going to take it because
I analyze all my data and I read,

577
00:35:48,840 --> 00:35:50,790
you know what audience
retention looks like,

578
00:35:50,791 --> 00:35:54,540
what kind of content the audience likes.
I'm always analyzing data, by the way.

579
00:35:54,541 --> 00:35:58,630
And I know this is a very viable
question. I study probably, um,

580
00:36:00,410 --> 00:36:03,380
less than I did before because
as you build knowledge,

581
00:36:03,560 --> 00:36:05,260
you need to study less
because you're just billing.

582
00:36:05,261 --> 00:36:06,710
It's a dependency graph of knowledge.

583
00:36:07,160 --> 00:36:11,510
So I probably study like
a five to 10 hours a week,

584
00:36:11,540 --> 00:36:16,400
10 hours Max. Most of it is output.
It's not even studying anymore. Um,

585
00:36:16,460 --> 00:36:20,150
most of it is output. Although with
reinforcement learning I am studying more.

586
00:36:20,151 --> 00:36:24,230
So then probably nine to
10 hours. Uh, that's it.

587
00:36:25,460 --> 00:36:26,140
Okay,

588
00:36:26,140 --> 00:36:27,820
cool.
Let me answer one more question.

589
00:36:29,380 --> 00:36:33,580
What is the Kaggle challenge?
Cheers from Italy. Um,

590
00:36:33,880 --> 00:36:37,930
good artsy. I love Italy but
we won't get into that. Um,

591
00:36:39,360 --> 00:36:40,193
okay.

592
00:36:40,280 --> 00:36:41,210
Thank you very much.

593
00:36:41,270 --> 00:36:44,060
Please do a video about how to get started
in machine learning for beginners on

594
00:36:44,061 --> 00:36:46,940
Kaggle. That's a great idea. And
I'll add it to my cue. All right,

595
00:36:48,050 --> 00:36:53,020
line 13 rows. Oh, thank
you very much. See,

596
00:36:53,740 --> 00:36:58,180
thank you for that. Good. That was it. No,

597
00:36:59,200 --> 00:37:01,580
like I said, we want to measure, um,

598
00:37:02,710 --> 00:37:07,000
we want to see the proportion of like
how much depth is it felt effecting the

599
00:37:07,001 --> 00:37:07,834
salt.

600
00:37:08,020 --> 00:37:13,020
And so what we're going to do is we're
going to write that out right here.

601
00:37:16,950 --> 00:37:18,870
Okay,
so salt.

602
00:37:22,780 --> 00:37:23,613
Okay.

603
00:37:24,010 --> 00:37:26,140
Okay. I'm going to focus you
guys. You're very interesting.

604
00:37:26,141 --> 00:37:28,690
The questions are very interesting here,
but I've got to focus here.

605
00:37:28,750 --> 00:37:32,800
So the salt proportion is what
we're looking at right now.

606
00:37:41,490 --> 00:37:43,700
Now we want to measure
how salty and images,

607
00:37:43,710 --> 00:37:47,160
what we want is a single metric
to say how salty is an image?

608
00:37:47,280 --> 00:37:50,670
How great would that be if it
was like it's 20% salty? Well,

609
00:37:50,671 --> 00:37:51,910
and then we can have some low,
you know,

610
00:37:52,020 --> 00:37:56,960
some threshold value where this
minimum amount of salt requires, uh,

611
00:37:56,970 --> 00:38:01,080
you know, further eyes to look at this.
So we want to develop that metric.

612
00:38:02,400 --> 00:38:07,380
So what we can say is, let's see all the
unique values that we have in our image,

613
00:38:07,381 --> 00:38:08,850
right?
Those unique numbers.

614
00:38:09,210 --> 00:38:11,970
And we're going to count how
many unique numbers there are.

615
00:38:13,110 --> 00:38:16,140
That's a very personal question,
my friend. All right? Um,

616
00:38:16,950 --> 00:38:21,420
return counts one,
two,

617
00:38:21,421 --> 00:38:23,580
or one. Dot. Okay.

618
00:38:25,080 --> 00:38:29,130
And that's how the total number
of values that we could have.

619
00:38:29,850 --> 00:38:30,683
That's it,

620
00:38:35,200 --> 00:38:39,390
right? Yes. All right.

621
00:38:41,020 --> 00:38:44,260
No,
now that I've defined that file,

622
00:38:44,261 --> 00:38:46,090
I'm going to create a training mask.

623
00:38:49,110 --> 00:38:53,920
Do you guys saying line eight?
I'm fine. Train mask. Mask. Okay.

624
00:38:53,921 --> 00:38:56,050
So I'm going to cry.
I'm going to merge the depth.

625
00:38:56,080 --> 00:39:00,540
I'm going to take that of value. I'm
going to merge it into the uh, other, uh,

626
00:39:00,670 --> 00:39:03,880
data frame object that I have.
That's what I'm doing right here.

627
00:39:03,910 --> 00:39:07,900
Cause I wanna I wanna use that
perhaps. Probably. Yes, I'll use it.

628
00:39:08,620 --> 00:39:12,010
Okay. So that's what I'm
doing here. I'm going to merge

629
00:39:13,660 --> 00:39:14,493
that

630
00:39:20,700 --> 00:39:21,533
one more line.

631
00:39:25,210 --> 00:39:26,470
The salt proportion?

632
00:39:30,050 --> 00:39:30,883
Yeah.

633
00:39:31,240 --> 00:39:35,830
Train mask. Mask. Yeah,

634
00:39:35,831 --> 00:39:39,130
I know about the title. I don't care.
It was fine. Uh, because we're already,

635
00:39:39,160 --> 00:39:42,940
we were beyond that. Okay. We are beyond

636
00:39:45,210 --> 00:39:50,190
proportion pecs. Good.

637
00:39:50,240 --> 00:39:54,030
All right. I think that's
trained math sol proportion.

638
00:39:56,190 --> 00:39:57,023
Okay.

639
00:39:57,350 --> 00:39:57,950
I guess that,

640
00:39:57,950 --> 00:40:02,950
and so now we can literally merge it and
why saying let's merge using the merge

641
00:40:03,500 --> 00:40:04,100
function,

642
00:40:04,100 --> 00:40:08,540
the depth and then we'll store
it in this column right here

643
00:40:10,810 --> 00:40:13,450
and then we'll see what we have.
Now let's see what we have.

644
00:40:15,700 --> 00:40:18,040
Good. Okay. So we have
our salt proportion,

645
00:40:18,041 --> 00:40:22,420
that's its own column and a,
we have our mask values,

646
00:40:22,421 --> 00:40:25,420
we have our r l e values,
we have our id, we have,

647
00:40:25,421 --> 00:40:27,070
and we have our depth right here under z.

648
00:40:27,520 --> 00:40:30,470
So we have all of the
values we need and deed.

649
00:40:30,520 --> 00:40:32,860
What deep learning is going to do is
going to figure out the features that are

650
00:40:32,861 --> 00:40:36,830
important.
Okay.

651
00:40:36,950 --> 00:40:41,560
So there's one more exploratory data
analysis step that I want to do here. Um,

652
00:40:41,640 --> 00:40:46,640
and that is comparing the depth to the
salt a ratio and seeing how they relate

653
00:40:48,650 --> 00:40:52,520
because that would be really
useful to see that wouldn't it be?

654
00:40:52,550 --> 00:40:53,810
It would be very useful.
I know.

655
00:40:58,380 --> 00:41:03,380
So proportion merged and then
z and now we want to see the,

656
00:41:05,220 --> 00:41:07,020
what am I going to call this,
the proportion

657
00:41:08,610 --> 00:41:10,410
of salt versus depth.

658
00:41:20,490 --> 00:41:22,950
Hmm.
Hmm.

659
00:41:25,580 --> 00:41:29,390
Interesting. Cool. All right.

660
00:41:32,950 --> 00:41:37,190
Uh,
let's see how correlated that is.

661
00:41:37,220 --> 00:41:40,880
NP P. Dot. Let's see. Um, one
more thing before we get into,

662
00:41:40,960 --> 00:41:44,510
let's just get into units. So yeah,
depth is one thing. We have it in our,

663
00:41:44,630 --> 00:41:47,570
we have an entire feature set. It's one
of the features. Let's keep going here.

664
00:41:47,630 --> 00:41:50,410
So this is a computer vision
problem, white, we're,

665
00:41:50,440 --> 00:41:53,600
we're trying to learn the mapping
between the input and the output data.

666
00:41:54,200 --> 00:41:58,430
And so there are a bunch of models out
there that we could use. There's resonate,

667
00:41:58,431 --> 00:42:00,240
there's inception,
there's Alex Net,

668
00:42:00,241 --> 00:42:05,241
there's Vgg and this is a map of the
accuracy to the amount of operations that

669
00:42:05,301 --> 00:42:09,530
requires. This is a map. So it
was noticed that VGG requires the,

670
00:42:09,550 --> 00:42:14,420
a lot of operations, but of the most
accurate is if we go all the way up.

671
00:42:14,421 --> 00:42:15,890
That's inception before.

672
00:42:17,450 --> 00:42:20,540
But there's one model that's
not on this list. So let's see.

673
00:42:20,840 --> 00:42:25,820
This is the accuracy by the type of
model and ynet wins out all of them.

674
00:42:26,240 --> 00:42:30,680
Ynet but a of all of those models,
we're going to use zero.

675
00:42:30,681 --> 00:42:34,730
We're going to use a unit. And you might
be asking why are you using a unit?

676
00:42:35,060 --> 00:42:37,430
Because think about our specific problem.

677
00:42:37,670 --> 00:42:41,330
We are not just trying to do a
classification between different images.

678
00:42:41,660 --> 00:42:44,600
We're trying to do a classic,
we're trying to do a segmentation.

679
00:42:44,780 --> 00:42:46,220
So we're trying to do classification,

680
00:42:46,221 --> 00:42:51,221
molten multi-class classification inside
of a single image right here is salt

681
00:42:51,650 --> 00:42:56,400
here is not salt.
And it's been shown that unit is uh,

682
00:42:56,800 --> 00:43:01,370
a standard architecture
for computer vision when we
need not to only segment the

683
00:43:01,371 --> 00:43:02,960
whole image by its class,

684
00:43:03,260 --> 00:43:07,550
but also to segment areas
of an image by class, right?

685
00:43:07,551 --> 00:43:11,180
So produce a mask that will separate
images into several classes.

686
00:43:13,060 --> 00:43:17,940
Um, but the, the, so there
are downsides as there always
are. There are many layers,

687
00:43:17,941 --> 00:43:21,590
so it takes a significant amount of
time to train. Okay. But you know,

688
00:43:21,591 --> 00:43:26,240
there's always an up and down side.
Could we use auto encoders?

689
00:43:26,241 --> 00:43:27,770
We could,
we could use,

690
00:43:27,890 --> 00:43:31,550
I mean the unit is essentially
an auto encoder, right?

691
00:43:31,551 --> 00:43:35,570
Let me talk about how that works. So, um,

692
00:43:35,690 --> 00:43:40,450
but in contrast to a particular, in,
in contrast to a regular auto encoder,

693
00:43:40,700 --> 00:43:41,660
it predicts a pixel,

694
00:43:41,661 --> 00:43:45,740
why segmentation map of the input image
rather than classifying the input image

695
00:43:45,770 --> 00:43:48,650
as a whole. Okay. So it's saying like,

696
00:43:48,680 --> 00:43:52,640
here is the every pixel in the original
image and it's asking a question to

697
00:43:52,641 --> 00:43:56,870
which class does this
individual pixel belong? Okay.

698
00:43:57,290 --> 00:44:00,950
And that kind of flexibility allows it
to predict different parts of the seismic

699
00:44:00,951 --> 00:44:02,540
image. Salt, not salt.

700
00:44:03,170 --> 00:44:06,440
What it's doing is it's passing the
feature map from each level of the

701
00:44:06,441 --> 00:44:10,280
contracting path over the,
the analogous level to the expanding path.

702
00:44:10,490 --> 00:44:14,630
So let me talk about how this works.
Okay. So here's an image of a unit. Okay.

703
00:44:14,870 --> 00:44:15,290
So it's an,

704
00:44:15,290 --> 00:44:20,290
it's an encoder decoder architecture
and what it specifically,

705
00:44:20,481 --> 00:44:24,440
and here's another image actually.
It's okay. Um, all right.

706
00:44:24,680 --> 00:44:29,180
There's a lot to time clearly. I'm excited
right now to explain how this works.

707
00:44:29,210 --> 00:44:34,200
So let's start about, let's, let's start
with the first layer, the encoding layer.

708
00:44:34,201 --> 00:44:35,850
What did the first layer contains?

709
00:44:35,851 --> 00:44:38,760
Is a bunch of encoding blocks
like convolutional blocks.

710
00:44:39,180 --> 00:44:42,600
And what it's doing is it's downsampling.
Okay?

711
00:44:42,601 --> 00:44:46,890
So that first part is we're applying
convolutions followed by a Max pool

712
00:44:47,070 --> 00:44:48,150
downsampling APP,

713
00:44:48,220 --> 00:44:53,220
a APP technique to encode the input
image and to feature representations at

714
00:44:54,331 --> 00:44:58,320
multiple different levels. So here is an
example, okay. Of what that looks like.

715
00:44:59,640 --> 00:45:04,200
We're saying do a convolutional,
so a convolution is like a flashlight.

716
00:45:04,230 --> 00:45:07,260
It's if we imagine image as
a matrix of pixel values,

717
00:45:07,410 --> 00:45:11,490
a convolutional operation says let's
for every pixel value in that image,

718
00:45:11,580 --> 00:45:16,560
let's do a matrix multiplication by our,
our, our, uh, feature map that exists,

719
00:45:16,590 --> 00:45:20,550
that that's a part of that convolutional
filter and let's multiply it and we'll

720
00:45:20,551 --> 00:45:24,660
get a result. And that result is a bunch
of feature maps and we continually do,

721
00:45:24,720 --> 00:45:26,610
we continually input those feature maps.

722
00:45:26,700 --> 00:45:31,560
And there are more and more and more as
we go down the list of blocks until we

723
00:45:31,561 --> 00:45:32,394
get to the output.

724
00:45:32,550 --> 00:45:35,730
But it's continuously creating more
and more feature maps by applying a

725
00:45:35,731 --> 00:45:39,330
convolutional flashlight. It's like a,
it's like a flashlight because it's, it's,

726
00:45:39,331 --> 00:45:44,040
it's going over every value in every row
for every column until it does it for

727
00:45:44,041 --> 00:45:48,000
all of the values in that convolutional
image [inaudible] for that image.

728
00:45:48,750 --> 00:45:50,970
And once we'd done the
convolutional operation,

729
00:45:51,000 --> 00:45:53,310
then we're going apply
at pooling operation.

730
00:45:53,311 --> 00:45:57,060
And what a pooling operation
does is it saves us time, right?

731
00:45:57,061 --> 00:46:01,380
It saves the algorithm time because
it only looks at the Max value for Max

732
00:46:01,381 --> 00:46:03,420
pooling inside of a specific region.

733
00:46:03,421 --> 00:46:07,440
So it's saying what's the most relevant
part of the image? And let's, let's,

734
00:46:07,470 --> 00:46:10,050
let's propagate that
forward and forget the rest.

735
00:46:11,670 --> 00:46:14,630
And by downsampling what downsampling is,

736
00:46:14,631 --> 00:46:19,631
as is a fancy word for taking a high
resolution image and making it a low

737
00:46:19,711 --> 00:46:23,430
resolution image. It's
compressing that image. Now the,

738
00:46:23,730 --> 00:46:24,720
there's a second part,

739
00:46:24,721 --> 00:46:28,230
the decoder of the network that consists
of upsampling and concatenation.

740
00:46:28,231 --> 00:46:32,310
Now I know a lot of people think, why
don't want to call this de convolutions,

741
00:46:32,311 --> 00:46:34,920
I want to call this upsampling.
And so what upsampling is,

742
00:46:34,921 --> 00:46:39,540
is it's taking a low resolution image and
it's creating a high resolution image.

743
00:46:39,690 --> 00:46:41,550
And so it's,
it's doing the opposite.

744
00:46:42,090 --> 00:46:45,960
And so we can see what that looks like
right here. It's still convolutions.

745
00:46:46,140 --> 00:46:49,420
It's still, um, an
activation function. Relu uh,

746
00:46:49,530 --> 00:46:53,670
look at my video activation functions
Saroj for more information on how,

747
00:46:53,700 --> 00:46:56,040
which activation function you should use.

748
00:46:56,730 --> 00:47:00,270
And then once it's done that
it's going to output that.

749
00:47:00,270 --> 00:47:03,000
Now here's the really interesting part.
So if we look back at the image,

750
00:47:03,090 --> 00:47:06,270
what makes a unit really interesting
are these lines right here?

751
00:47:06,271 --> 00:47:10,200
Can anyone tell me what these lines mean?
And they're also here.

752
00:47:10,410 --> 00:47:14,880
What do these lines mean in this a unit?
What is that right?

753
00:47:16,140 --> 00:47:20,580
The answer, by the way, it's a skip
connection. What it's saying is right.

754
00:47:20,581 --> 00:47:21,780
So the check itself,

755
00:47:21,930 --> 00:47:26,370
the data is propagating right from
every convolutional block, right?

756
00:47:26,730 --> 00:47:28,410
But while it's doing that,

757
00:47:28,411 --> 00:47:32,310
it's sending what it computed
across the network to the,

758
00:47:32,560 --> 00:47:37,330
to the other end of the network, to the
decoder layer. So it's passing info,

759
00:47:37,331 --> 00:47:40,360
not just forward. It's passing
it to the side to the decoder.

760
00:47:40,570 --> 00:47:41,560
And that's a skip connection.

761
00:47:41,710 --> 00:47:45,190
And the reason it does that is that
this improves accuracy apparently,

762
00:47:46,420 --> 00:47:49,510
but it's a skip connection and we
can see exactly what that looks like.

763
00:47:49,600 --> 00:47:53,830
So rather than continuously just writing
out a bunch of the same lines because

764
00:47:53,831 --> 00:47:56,260
it just convolution Max
pooling convolution, I've art,

765
00:47:56,290 --> 00:47:58,990
I've actually prewritten this, this, um,

766
00:48:02,580 --> 00:48:05,790
yeah, skip connections. Yeah, that's
what I said. But yes, exactly.

767
00:48:05,970 --> 00:48:09,120
I'm actually prewritten in out here. So
let me show you exactly what I mean. So,

768
00:48:09,270 --> 00:48:11,550
right, we have our input
that we input right here.

769
00:48:11,730 --> 00:48:15,120
We have our feature map and then we
input that directly into the first layer.

770
00:48:15,150 --> 00:48:19,620
Right? We apply our activation function
to it and then we continually, uh,

771
00:48:19,770 --> 00:48:22,380
say convolution pooling,
send it to the next layer,

772
00:48:22,560 --> 00:48:25,950
convolution pooling sends to the next
time we do that for four convolutional

773
00:48:25,951 --> 00:48:29,960
blocks. We join all of those. We
can catenate all those values. Okay.

774
00:48:29,970 --> 00:48:34,500
And to the [inaudible] features
is going to be our, um,

775
00:48:35,520 --> 00:48:37,740
our lowest level
representation of the data.

776
00:48:38,370 --> 00:48:41,400
And that's what we input into
the D Kotler. And so this is the,

777
00:48:41,490 --> 00:48:46,230
let me just write that down.
This is the decoder layer. Okay.

778
00:48:46,710 --> 00:48:48,180
And so once we have our decor layer,

779
00:48:48,210 --> 00:48:53,210
we do the exact opposite in that we're
doing a UN upsampling up a operation

780
00:48:54,511 --> 00:48:55,344
here.

781
00:48:55,380 --> 00:48:59,820
Now here is where that skip
connection is happening.

782
00:48:59,821 --> 00:49:04,800
Notice this contact Nate.
Skip connections.

783
00:49:04,830 --> 00:49:08,100
Million exclamation points though.

784
00:49:08,120 --> 00:49:12,150
So what are those? Look, I'm being silly,

785
00:49:12,720 --> 00:49:17,040
but uh, it's connecting. See you. Six
to see four. Where's [inaudible]? Well,

786
00:49:17,041 --> 00:49:20,760
[inaudible] is up here. Okay. It's,
it's doing the same for you. Seven to c,

787
00:49:20,761 --> 00:49:24,810
three c three is up here.
It's doing the same thing for you.

788
00:49:24,811 --> 00:49:29,430
Seven to eight to see, to what
we're see too, it's up here.

789
00:49:29,550 --> 00:49:33,210
So that is the stip connection operation
that you're seeing programmatically

790
00:49:33,270 --> 00:49:37,770
happening right here. Okay.
So convolutions pooling,

791
00:49:38,010 --> 00:49:42,690
activation function, repeat convolutions,
pooling activation function,

792
00:49:42,780 --> 00:49:47,250
repeat in code, decode,
skip connections, that unit,

793
00:49:47,850 --> 00:49:51,930
good for multi-class
calcification inside of an image,

794
00:49:52,030 --> 00:49:56,850
Aka Image Segmentation,
Aka our problem is what we're doing.

795
00:49:57,450 --> 00:50:02,040
Why four layers? Quite great question. So
Andrea carpathy and his blog posts, um,

796
00:50:02,550 --> 00:50:07,540
uh, the unreasonable effectiveness of
recurrent networks. First stated that, um,

797
00:50:07,920 --> 00:50:10,530
there is a diminishing return to the
amount of layers that you can add to a

798
00:50:10,531 --> 00:50:10,830
network.

799
00:50:10,830 --> 00:50:15,660
So the more layers you add
doesn't necessarily mean
that it's going to be better.

800
00:50:15,720 --> 00:50:19,200
And there's a kind of sweet spot
between three, four, five, six layers,

801
00:50:20,040 --> 00:50:22,440
one sections like 30 layers.

802
00:50:22,800 --> 00:50:26,610
But for computationals Sake,
uh, that's, that's what it is.

803
00:50:26,930 --> 00:50:30,560
So when we compile that, it's just
going to show us, thank you Cara Ross,

804
00:50:30,710 --> 00:50:35,390
what that looks like. The architecture.
Okay. And once we have that, and then,

805
00:50:35,420 --> 00:50:37,820
you know,
there's more just like data preprocessing,

806
00:50:37,821 --> 00:50:39,680
but we have those images as by your res.

807
00:50:40,070 --> 00:50:45,070
And we do one more preprocessing step
where we just combine them into a giant

808
00:50:45,531 --> 00:50:49,130
vector, one by one by one by one. It's
just an array of all those values.

809
00:50:49,640 --> 00:50:53,950
And once we have that we're going to use
probably the most used part of psychic

810
00:50:53,960 --> 00:50:57,860
learn I've ever used, which is
this training testing split, um,

811
00:50:58,400 --> 00:51:01,220
module which lets us split
the training and testing data.

812
00:51:02,000 --> 00:51:06,740
And once we have that, we
have two callbacks, uh,

813
00:51:06,820 --> 00:51:11,200
one is early stopping. These are just
a flags for our network. Thank you.

814
00:51:11,201 --> 00:51:13,900
Free Code camp. I'm glad to
see you guys here. I did a,

815
00:51:13,901 --> 00:51:16,750
I did a medium blog post for
them. They're, they're very cool.

816
00:51:16,780 --> 00:51:21,220
Great brand check 'em out
model checkpoints were going
to save a model as this

817
00:51:21,250 --> 00:51:22,750
and then we fit the model.
Okay.

818
00:51:22,870 --> 00:51:27,190
So what I did was I actually started
training and then I stopped it right here

819
00:51:27,191 --> 00:51:32,140
at the second epoch because the
first epoch took 277 seconds,

820
00:51:32,141 --> 00:51:36,790
which is six 12, 1824, four minutes.
And I had to do that for 50 epochs.

821
00:51:36,850 --> 00:51:41,410
So 50 epochs times four minutes
is 200 minutes, which is six,

822
00:51:41,411 --> 00:51:45,430
12, 18, three hours and 20 minutes.

823
00:51:45,460 --> 00:51:49,000
That's some real time that for you,
Matrix operations happening right here.

824
00:51:49,001 --> 00:51:52,150
Skip connections, right? And uh,

825
00:51:52,180 --> 00:51:55,480
that is too long for a live stream
and we're reaching an hour as well.

826
00:51:55,510 --> 00:51:59,950
But that is the model. Okay.
Now, what else could we use here?

827
00:52:00,760 --> 00:52:00,881
Well,

828
00:52:00,881 --> 00:52:05,881
it turns out now Kaggle has this great
idea of having a discussion right on the,

829
00:52:08,380 --> 00:52:09,213
uh,

830
00:52:10,340 --> 00:52:12,860
website.
It's also got people doing the units.

831
00:52:13,070 --> 00:52:16,000
It's got people trying out
different things. Let's see what,

832
00:52:16,001 --> 00:52:18,140
what's like the most up voted?
Uh,

833
00:52:20,430 --> 00:52:21,263
right

834
00:52:22,030 --> 00:52:23,470
search by most votes.

835
00:52:25,170 --> 00:52:25,520
Okay.

836
00:52:25,520 --> 00:52:30,410
This person wrote up a whole intro to
seismic geo physics. Thank you very much.

837
00:52:31,160 --> 00:52:34,700
Look at this quality stuff. People,
these people are sharing data.

838
00:52:35,080 --> 00:52:38,390
They're sharing results.
Even though it's $100,000 prize.

839
00:52:38,710 --> 00:52:41,810
It just want to help out. They just
want to help. That's, that's the spirit.

840
00:52:41,840 --> 00:52:44,690
That's the spirit right
there. Right? Okay.

841
00:52:44,691 --> 00:52:46,140
So what I'm gonna do is
going to end this with a,

842
00:52:46,490 --> 00:52:51,200
with a Q and a and a rap
as well. So let's just, um,

843
00:52:51,710 --> 00:52:55,820
let's do a little rap. Okay.
Just say it. Just say a topic.

844
00:52:57,760 --> 00:52:59,860
Did you train on Gpu? Yes, I train on GPU.

845
00:53:00,130 --> 00:53:05,130
You can do that by the same runtime
and then change runtime type GPU.

846
00:53:05,810 --> 00:53:07,330
Just like that.
Right.

847
00:53:07,390 --> 00:53:10,060
Obviously I'm not gonna train a two
hour model on a live stream. Right.

848
00:53:10,061 --> 00:53:14,110
We don't have two hours,
but that's, that's the idea.
And yes, I'll do a video on,

849
00:53:14,950 --> 00:53:19,030
on what implementing neural networks
do. That's like all my videos. Okay.

850
00:53:19,480 --> 00:53:22,390
Um,
instrumental beat.

851
00:53:25,900 --> 00:53:26,080
I

852
00:53:26,080 --> 00:53:29,800
would love to present in Holland. No,
Netherlands. I love you. Seriously.

853
00:53:30,130 --> 00:53:34,090
How I'll come back India as well. I'm
coming back guys. Everywhere. Africa,

854
00:53:34,091 --> 00:53:37,120
I'm coming. Um, South America as well.

855
00:53:37,630 --> 00:53:41,260
I got to do a world trip before the
year ends. Um, I'm saying too much.

856
00:53:42,280 --> 00:53:43,113
Where was I?

857
00:53:45,600 --> 00:53:46,433
Yeah,
exactly.

858
00:53:51,280 --> 00:53:53,570
Yeah. I don't know what this is. Matt.

859
00:54:01,680 --> 00:54:02,513
Recurrence.

860
00:54:09,790 --> 00:54:13,870
That's why the youth Colab, it's
so bad. I'm just kidding, man.

861
00:54:14,080 --> 00:54:18,520
It got me so mad. I try to use
it. Put all my dependencies.

862
00:54:18,670 --> 00:54:23,050
I tried to put different things, man.
Can't you see I got a demo over here.

863
00:54:23,051 --> 00:54:26,860
I got convolutional blocks.
I got 48 lines, man.

864
00:54:27,070 --> 00:54:29,950
Gotta wear some socks.
I'm not wearing anything right now.

865
00:54:30,010 --> 00:54:33,520
I'm just trying to wrap. I'm trying
to do it for you. You're the crowd.

866
00:54:33,820 --> 00:54:36,760
I see that you've got this
contact and nation and upsampling,

867
00:54:36,940 --> 00:54:39,460
but I'm going to do something else.
It's called downsampling.

868
00:54:39,700 --> 00:54:42,490
When I'm done with this,
I'm going to close my laptop and go,

869
00:54:42,700 --> 00:54:46,480
because that's how I do math. This is how
I flow. Let me end it on that. Good. Yeah.

870
00:54:46,520 --> 00:54:51,360
No. Before I go too high up right now,
uh, this has been a great live stream.

871
00:54:51,470 --> 00:54:56,410
Thank you everybody for joining
and for now, I've got to go, um,

872
00:54:57,440 --> 00:54:59,900
work on school of AI stuff,
so thanks for watching.

873
00:55:00,660 --> 00:55:01,190
All right.

