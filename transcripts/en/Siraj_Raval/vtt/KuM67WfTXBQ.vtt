WEBVTT

1
00:00:00.300 --> 00:00:04.650
Deep learning on a stick.
Who needs flying cars?
Hello world.

2
00:00:04.651 --> 00:00:09.651
It's Saroj and there's this really cool little device called the Intel Mobidius

3
00:00:10.050 --> 00:00:13.170
neural compute stick I want to talk about today.

4
00:00:13.440 --> 00:00:17.520
It's the world's first USB based deep learning inference kits.

5
00:00:17.760 --> 00:00:22.760
It's tiny fan lists and you can use it to learn AI programming on a huge range

6
00:00:23.581 --> 00:00:24.720
of hosts devices.

7
00:00:25.140 --> 00:00:29.190
I've been having a lot of fun with it and we'll go through a demo of performing

8
00:00:29.191 --> 00:00:33.600
computer vision by deploying a deep neural network to it,

9
00:00:34.140 --> 00:00:35.310
but more importantly,

10
00:00:35.311 --> 00:00:39.540
this represents a trend of AI moving to the edge instead of the cloud.

11
00:00:39.840 --> 00:00:42.900
Centralized cloud computing has worked pretty well,

12
00:00:43.080 --> 00:00:45.960
but it can't overcome the laws of physics.

13
00:00:46.440 --> 00:00:49.560
Only Jeff Dean can do that.
The weight of data,

14
00:00:49.590 --> 00:00:54.590
the speed of light as people use more realtime services waiting on a data center

15
00:00:55.531 --> 00:00:57.810
across the world will become cumbersome.

16
00:00:58.200 --> 00:01:03.200
Latency is important for both mission critical systems like self driving cars

17
00:01:03.450 --> 00:01:05.910
and consumer services like video chat.

18
00:01:06.270 --> 00:01:11.270
Most of the internets underlying infrastructure runs on rule based systems

19
00:01:11.820 --> 00:01:15.000
without any learning technology behind it.

20
00:01:15.570 --> 00:01:20.310
Upgrading this infrastructure is going to take a unique understanding of all the

21
00:01:20.311 --> 00:01:24.210
different contexts the Internet works with.
For example,

22
00:01:24.240 --> 00:01:27.120
every manufacturing plant is different.

23
00:01:27.150 --> 00:01:29.520
Even though they use the same equipment,

24
00:01:29.790 --> 00:01:34.790
an AI model created in the cloud to help plan the supply chain or different

25
00:01:35.371 --> 00:01:36.750
plants won't work.

26
00:01:36.900 --> 00:01:41.130
Sometimes the edge isn't always connected to the cloud and when it is,

27
00:01:41.280 --> 00:01:43.980
it's expensive to move high volume,

28
00:01:44.110 --> 00:01:48.180
real time data for training or realtime decisions to the cloud.

29
00:01:48.390 --> 00:01:53.390
An AI model trained locally for specific plants needs would allow for fast real

30
00:01:54.641 --> 00:01:56.070
time decision making.

31
00:01:56.310 --> 00:02:01.310
This also presents an opportunity for hundreds of startups to create AI pipeline

32
00:02:02.461 --> 00:02:05.250
tools,
not just one winner take all.

33
00:02:05.250 --> 00:02:09.270
Since there's such a diversity in terms of the infrastructure and data and

34
00:02:09.450 --> 00:02:11.070
applications specific needs,

35
00:02:11.400 --> 00:02:16.400
real money is being invested into putting AI at the edge for all sorts of

36
00:02:16.411 --> 00:02:16.921
companies.

37
00:02:16.921 --> 00:02:21.921
Since getting even a small sliver of increased productivity will result in a

38
00:02:22.351 --> 00:02:27.351
massive impact for their revenues and let's not forget the increased security of

39
00:02:27.871 --> 00:02:31.590
keeping data local instead of sending it out to a third party.

40
00:02:31.800 --> 00:02:36.800
The neural compute stick or NCS is a perfect example of a device that allows

41
00:02:37.590 --> 00:02:41.160
anyone to test and deploy AI models locally.

42
00:02:41.400 --> 00:02:45.060
It's super low power since it just consumes a single watt.

43
00:02:45.450 --> 00:02:49.950
There's no need for connectivity and you can feel secure knowing that the data

44
00:02:49.980 --> 00:02:52.230
is never leaving your device.

45
00:02:52.620 --> 00:02:57.300
You can run a whole host of deep learning applications that involve images,

46
00:02:57.360 --> 00:02:59.100
Aka computer vision.

47
00:02:59.260 --> 00:03:04.260
So let's go through the pipeline of getting a real time object classification

48
00:03:04.391 --> 00:03:06.700
demo running using this thing.

49
00:03:07.090 --> 00:03:09.910
We can find the stick on a bunch of sites.

50
00:03:10.150 --> 00:03:14.560
I prefer using Amazon since prime is the greatest thing since sliced bread.

51
00:03:15.070 --> 00:03:20.070
The NCS supports to deep learning frameworks currently tensorflow and cafe,

52
00:03:21.310 --> 00:03:26.170
but models trained using these frameworks need to be converted into an

53
00:03:26.171 --> 00:03:28.840
appropriate format to run on the device.

54
00:03:29.230 --> 00:03:33.340
The NCS DK has three libraries that help with this.

55
00:03:33.610 --> 00:03:38.610
Compile converts a model into the appropriate format profile,

56
00:03:38.891 --> 00:03:43.891
gives layer by layer statistics to evaluate model performance and check compares

57
00:03:45.161 --> 00:03:49.300
the inference results from running the network on the device versus pure

58
00:03:49.301 --> 00:03:50.560
tensorflow or cafe.

59
00:03:50.860 --> 00:03:55.390
You can install the NC Sdk by cloning it from get hub.
Then running,

60
00:03:55.420 --> 00:03:58.810
make install to compile it.
Once that's finished,

61
00:03:58.840 --> 00:04:00.760
we can clone the NC APP zoo,

62
00:04:00.780 --> 00:04:04.120
a collection of community projects that make use of the NCS.

63
00:04:04.600 --> 00:04:09.600
We can get started by importing the MBN C API module to access the API.

64
00:04:11.020 --> 00:04:13.360
Then we'll check for the USB device,

65
00:04:13.600 --> 00:04:18.430
which the API lets us do using the enumerate devices function.

66
00:04:18.790 --> 00:04:23.790
We could even connect multiple NCS devices to the same application processor to

67
00:04:25.031 --> 00:04:28.570
scale inference performance.
But for now,
let's just pick one.

68
00:04:28.810 --> 00:04:32.410
We'll find a pre compiled model called Alex Net,

69
00:04:32.440 --> 00:04:37.440
which was trained on lots of images with their associated labels and load it

70
00:04:38.080 --> 00:04:39.400
onto the NCS.

71
00:04:39.760 --> 00:04:44.760
We're going to simply read images from a folder on our local machine and offload

72
00:04:44.931 --> 00:04:47.260
it to the NCS.
For inference,

73
00:04:47.650 --> 00:04:52.420
all the neural network processing is done completely on the NCS device,

74
00:04:52.630 --> 00:04:54.060
which frees up our machines,

75
00:04:54.061 --> 00:04:59.061
CPU and memory resources to perform other application level tasks.

76
00:04:59.620 --> 00:05:02.140
We can load an image onto the NCS,

77
00:05:02.170 --> 00:05:07.030
but we'll need to resize it to match the dimensions defined by the pretrained

78
00:05:07.090 --> 00:05:10.300
network and we'll convert the color scheme accordingly,

79
00:05:10.480 --> 00:05:15.480
as well as its data type to an array and load the image onto the NCS has a

80
00:05:15.761 --> 00:05:16.594
tensor.

81
00:05:16.600 --> 00:05:21.190
We can retrieve the results from the device and print them out for us to view.

82
00:05:21.490 --> 00:05:24.280
Lastly,
in order to avoid memory leaks,

83
00:05:24.430 --> 00:05:28.660
we can allocate to any used memory.
When we run it on an image,

84
00:05:28.690 --> 00:05:32.620
it'll immediately make a class prediction in the order of likelihood.

85
00:05:32.950 --> 00:05:36.130
Pretty awesome.
Three points to remember from this video.

86
00:05:36.490 --> 00:05:38.410
The Mobidius neural compute stick.

87
00:05:38.440 --> 00:05:42.700
Let's anyone test and deploy AI models at the edge,

88
00:05:42.730 --> 00:05:43.720
AKA locally.

89
00:05:44.080 --> 00:05:48.790
This is useful because it has lower latency than the cloud and gives increased

90
00:05:48.791 --> 00:05:49.540
security.

91
00:05:49.540 --> 00:05:54.460
Since the data stays on your machine and using the NC Sdk,

92
00:05:54.640 --> 00:05:59.440
we can test a whole host of deep learning applications on the device easily.

93
00:05:59.560 --> 00:06:00.880
With a few lines of code,

94
00:06:01.270 --> 00:06:05.380
it does subscribe button and I will make you an AI master.
For now.

95
00:06:05.440 --> 00:06:08.320
I've got to train myself,
so thanks for watching.

