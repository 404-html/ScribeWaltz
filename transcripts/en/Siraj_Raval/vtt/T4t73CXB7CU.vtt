WEBVTT

1
00:00:00.030 --> 00:00:04.410
Hello world.
It's a Raj,
and this is a guide to core ml.

2
00:00:04.440 --> 00:00:09.180
That is Apple's new machine learning framework for all of its ios devices.

3
00:00:09.420 --> 00:00:12.720
We're going to go through the development workflow of what it's like to work

4
00:00:12.721 --> 00:00:15.150
with core ml.
We're going to talk about its API,

5
00:00:15.151 --> 00:00:18.420
we're going to talk about its features,
we're going to talk about its pros,

6
00:00:18.421 --> 00:00:20.100
we're going to talk about its cons,

7
00:00:20.370 --> 00:00:25.370
and then we're going to build a spam classifier for text messages on Ios,

8
00:00:26.040 --> 00:00:30.030
on an iPhone device to really implement what we've just learned.

9
00:00:30.420 --> 00:00:32.070
And so that's what we're going to do today.

10
00:00:32.160 --> 00:00:35.520
I'm very excited for this because Cornell has a lot of hype,
right?
But there's,

11
00:00:35.521 --> 00:00:39.690
it's not very well understood in terms of what's happening under the hood.

12
00:00:39.780 --> 00:00:41.250
So let's talk about that,
right?

13
00:00:41.430 --> 00:00:46.230
So apple released this framework this year at WWDC with a lot of hype.

14
00:00:46.410 --> 00:00:48.990
There's always gotta be high when apple does anything,
right?

15
00:00:49.380 --> 00:00:52.380
And so actually let's start off with the demo,
right?
Let's start off with a demo.

16
00:00:53.910 --> 00:00:58.910
So I'll type in a text message and then how classify it as hammer spam ham means

17
00:01:01.081 --> 00:01:04.950
not spam,
right?
That's it.
That's what we're going to do.
Just that simple thing.

18
00:01:06.510 --> 00:01:09.150
Okay.
That's going to be our demo.
So that's what we're going to do.

19
00:01:09.151 --> 00:01:11.730
It's going to classify it as ham or spam.

20
00:01:11.910 --> 00:01:14.630
And we're going to build that using the messages framework,
which,

21
00:01:14.700 --> 00:01:19.320
which allows us to build a custom APP that uses iMessage.

22
00:01:19.440 --> 00:01:22.470
Or we could build an extension to the existing I iMessage APP,

23
00:01:22.471 --> 00:01:26.160
which is what we'll do.
Okay.
So that's what we're going to do today.
And okay.

24
00:01:26.161 --> 00:01:28.890
Before we get into the features,
let's just talk about some history here.

25
00:01:29.190 --> 00:01:32.550
This is not the first machine learning framework that apple has released.

26
00:01:32.730 --> 00:01:37.050
In fact,
last year it released two of them,
uh,
to not much,

27
00:01:37.170 --> 00:01:40.950
not as much hype as core Mel had.
So get ready for some acronyms.

28
00:01:41.100 --> 00:01:45.690
The first acronym is MPs,
CNN,
which stands for metal performance,

29
00:01:45.720 --> 00:01:50.420
shader,
convolutional neural network.
And the second one is n s,

30
00:01:50.430 --> 00:01:54.930
which stands for basic neural network sub routines.
Actually it'd be n an s.

31
00:01:54.931 --> 00:01:58.290
So there's,
there's,
there's,
there's always more acronyms there,
but both of these,

32
00:01:58.480 --> 00:02:03.060
the let developers build convolutional neural networks,
both of them,
uh,

33
00:02:03.360 --> 00:02:04.051
MPs,

34
00:02:04.051 --> 00:02:08.700
CNN was for the Gpu and then BNS was for the CPU.

35
00:02:08.730 --> 00:02:09.960
That was the difference there.

36
00:02:10.620 --> 00:02:13.380
And both of them let you run inference on your device.

37
00:02:13.410 --> 00:02:14.790
So remember there's a difference.

38
00:02:14.791 --> 00:02:17.040
There's a difference between training and inference.

39
00:02:17.340 --> 00:02:20.310
None of these frameworks are going to let you train your model on your ios

40
00:02:20.311 --> 00:02:22.650
device,
but they will let you run inference.

41
00:02:22.650 --> 00:02:27.000
That means running a pre trained a model on your device without needing an

42
00:02:27.001 --> 00:02:30.430
internet connection.
So both of them were uh,

43
00:02:30.780 --> 00:02:34.620
released last year they released a set of data types and function types and then

44
00:02:34.621 --> 00:02:37.890
different types of layers.
And for all intents and purposes,

45
00:02:37.891 --> 00:02:39.930
they let you build CNNS.
But that was it.

46
00:02:40.200 --> 00:02:45.060
It was also very hard to create a.ml to create a model file.

47
00:02:45.270 --> 00:02:47.070
A lot of developers were having trouble with that.

48
00:02:47.250 --> 00:02:52.170
So based on the troubles that developers were having and just the fact that

49
00:02:52.171 --> 00:02:55.620
machine learning is happening everywhere and apple is seems to be just now

50
00:02:55.621 --> 00:02:58.560
catching on it.
They built core ml.

51
00:02:58.590 --> 00:03:01.960
So what core ml is also,
I want to say one more thing.

52
00:03:01.961 --> 00:03:03.940
So the reason they built two different frameworks,

53
00:03:03.941 --> 00:03:08.941
one for the CPU in one for the GPU is because the CPU is sometimes faster than

54
00:03:09.521 --> 00:03:14.140
the GPU for inference not for training,
for training,
the GPU is always faster.

55
00:03:14.260 --> 00:03:17.440
So you kind of have to guess and check with using both.

56
00:03:17.470 --> 00:03:20.620
But what apple did was they said,
well we don't have to,
we don't want to have,

57
00:03:20.650 --> 00:03:22.240
you have to worry about all these things.

58
00:03:22.390 --> 00:03:24.610
So we'll build a framework around both of them.

59
00:03:24.760 --> 00:03:28.330
So that runs on the CPU and the GPU.
So that's what core ml is.

60
00:03:28.630 --> 00:03:33.070
Core mill is built on top of the previously to released libraries and acts as a

61
00:03:33.071 --> 00:03:36.580
layer of abstraction on top of them.
And when I say abstraction,

62
00:03:37.060 --> 00:03:41.050
I mean abstraction.
Seriously.
It is almost too easy to use.
Like you'll,

63
00:03:41.051 --> 00:03:44.800
you'll see what I'm saying.
It's very easy to use.
And then on top of core ml,

64
00:03:44.920 --> 00:03:47.620
they built three other API APIs.
One is for,

65
00:03:47.650 --> 00:03:51.520
one is for when it's called vision and it's for all of your image analysis
tasks,

66
00:03:51.730 --> 00:03:56.470
object recognition,
classification.
And then there's uh,
foundations,

67
00:03:56.471 --> 00:04:00.220
which is for natural language processing.
That's for sentiment analysis,

68
00:04:00.280 --> 00:04:05.260
predicting the next word in a sequence sequence,
all sorts of tax related,
uh,

69
00:04:05.350 --> 00:04:06.183
machine learning.

70
00:04:06.250 --> 00:04:10.060
And then there's game played tip and allows your App to evaluate decision trees.

71
00:04:10.510 --> 00:04:13.920
So those are the three domains that build on top of core ml.

72
00:04:13.960 --> 00:04:17.650
And so the reason they built all three of these on top of core ml is for

73
00:04:17.651 --> 00:04:18.820
modularity,
right?

74
00:04:18.821 --> 00:04:23.821
So let's say you have an APP and what you want to do is classify where somebody

75
00:04:24.041 --> 00:04:28.330
is.
So part of your app is tagging everything you see.

76
00:04:28.450 --> 00:04:31.700
So let's say you're on a beach,
it would tag all the things that,

77
00:04:31.840 --> 00:04:35.920
that the APP sees.
It would tag the water,
it would tag sand,

78
00:04:36.010 --> 00:04:39.250
it would tag sunshine,
maybe some beach volleyball players.

79
00:04:39.400 --> 00:04:42.160
And then once you have all those tags using the vision library,

80
00:04:42.370 --> 00:04:46.900
then you can use the NLP library foundations to then take those words and

81
00:04:46.901 --> 00:04:50.410
classify what scene it is.
And it would say,
based on these words,

82
00:04:50.530 --> 00:04:53.170
this must be a beach and then you'd output a beach.

83
00:04:53.320 --> 00:04:56.740
So that's just one example of how these libraries can interact together.

84
00:04:57.460 --> 00:04:59.170
And so for the development workflow,

85
00:04:59.290 --> 00:05:04.240
what apple has done is it's essentially built a pdf for machine learning models,

86
00:05:04.241 --> 00:05:06.820
right?
The PDF is a standard formats,
right?

87
00:05:06.940 --> 00:05:09.580
And so that's what they tried to do with machine learning models.

88
00:05:09.581 --> 00:05:12.880
It's in the.ml model format.

89
00:05:13.030 --> 00:05:17.230
And so you can use the.ml model on any ios device,
Mac,

90
00:05:17.820 --> 00:05:21.730
Mac,
apple,
TV,
Ios or iPhones,
all of it.

91
00:05:22.060 --> 00:05:25.990
And I pads all of it.
And so it's a very simple process.

92
00:05:25.991 --> 00:05:30.100
It's a two step process.
The first step is to load a pre trained and l model.

93
00:05:30.240 --> 00:05:32.440
And the second step is to make predictions with it,
right?

94
00:05:32.590 --> 00:05:37.210
The training isn't happening on a device,
so it's that simple.
Uh,
so,

95
00:05:37.240 --> 00:05:40.870
but sometimes,
and so when I say using a pretrained model,

96
00:05:40.960 --> 00:05:45.760
apple has a list of these pretrained ml models that I have a link to in this a

97
00:05:45.761 --> 00:05:50.410
Jupiter notebook.
Uh,
and they're,
they're all these very popular models,

98
00:05:50.411 --> 00:05:53.680
mobile net squeeze nets,
googling that resonant.

99
00:05:53.740 --> 00:05:55.870
These are old convolutional networks,
by the way.

100
00:05:55.871 --> 00:06:00.871
Inceptions huge VGG all of their pretrained models are a convolutional networks.

101
00:06:01.730 --> 00:06:05.220
And so you can just use those,
but let's say that you don't want to use their,

102
00:06:05.240 --> 00:06:07.940
their,
uh,
pretrained models.
Let's say you want to build your own,

103
00:06:08.150 --> 00:06:09.980
then it becomes a three step process.

104
00:06:10.100 --> 00:06:13.610
The first step then becomes to convert your pre trained model and whatever

105
00:06:13.611 --> 00:06:16.760
machine learning library you're using,
whether it's cafe or psychic,

106
00:06:16.761 --> 00:06:21.761
learn into a.ml model using a tool that they've created for this called core ml

107
00:06:22.731 --> 00:06:25.400
tool.
It's a,
it's a python library.
We'll talk about that.

108
00:06:25.610 --> 00:06:29.360
And then you do the next two steps,
load the model and make the predictions.

109
00:06:29.690 --> 00:06:30.590
And so here,

110
00:06:30.591 --> 00:06:34.700
it's an amazing list of all sorts of machine learning models that you could use

111
00:06:34.701 --> 00:06:36.550
for core ml,
right?
The,

112
00:06:36.551 --> 00:06:40.100
there's a bunch of pretrained core ml models and then they have models for

113
00:06:40.101 --> 00:06:43.340
different libraries that you can then convert to Cornell.
Now,

114
00:06:43.341 --> 00:06:45.650
I had do have a very disappointing things to say.

115
00:06:45.920 --> 00:06:50.210
They don't have support for tensorflow.
I know.
What are you?

116
00:06:50.480 --> 00:06:55.340
Are you serious?
There is no tensor flow.
It's okay,
whatever,
whatever,
whatever.

117
00:06:55.370 --> 00:06:58.430
You can build your own,
uh,
conversion script,
uh,

118
00:06:58.730 --> 00:07:01.760
for your tensorflow models to run on core ml.
In fact,

119
00:07:01.761 --> 00:07:04.730
there must be something on get hub.
I'm just making a prediction right now.

120
00:07:04.910 --> 00:07:05.960
A prediction.
Anyway,

121
00:07:06.260 --> 00:07:11.260
so it's either a two step or three step process and so it's the.ml model is like

122
00:07:12.591 --> 00:07:15.920
the pdf of machine learning.
All you have to do is once you train it,

123
00:07:15.921 --> 00:07:17.630
you drag and drop it into x code.

124
00:07:17.780 --> 00:07:21.670
So you just drag and drop the.ml model and then you drag and drop your Dataset

125
00:07:21.710 --> 00:07:25.460
or whatever you want to test your model on.
And then you could call it very,

126
00:07:25.461 --> 00:07:28.370
very simply.
I'll show you the code right here.
Here's a code,
the sample code.

127
00:07:28.730 --> 00:07:31.100
But basically when you import the model into x code,

128
00:07:31.101 --> 00:07:33.090
it's going to look like this.
You've got it.

129
00:07:33.140 --> 00:07:35.600
It's going to parse the data inside of it.
It's a very,

130
00:07:35.780 --> 00:07:40.100
it's very neatly packed for x code to read.
So it will be able to say,
Oh,

131
00:07:40.101 --> 00:07:41.540
here are your inputs here.

132
00:07:41.541 --> 00:07:44.630
You're expected inputs and their data types and its description.

133
00:07:44.810 --> 00:07:48.110
Here's the outputs.
It'll tell you the learn parameters and the weights.

134
00:07:48.140 --> 00:07:50.450
That means the weights in the biases as well.

135
00:07:50.600 --> 00:07:53.150
So it's a very clean format for x code.

136
00:07:54.140 --> 00:07:57.860
And so once you imported that model,
you can call it just like this.

137
00:07:58.100 --> 00:08:02.120
You can call it by saying,
let model equal resonant 50 let's say for example,

138
00:08:02.121 --> 00:08:04.910
that's the one we're using.
And then you'd say,
here's my image,

139
00:08:04.911 --> 00:08:09.440
let Pixel buffer up,
type CV pixel buffer equal my image wherever it's located.

140
00:08:09.800 --> 00:08:13.340
And then I'll just make a prediction using model dot prediction feed at the

141
00:08:13.341 --> 00:08:16.190
image as the parameter and then print it out,
right?
That's it.

142
00:08:16.191 --> 00:08:18.260
That's your prediction.
It's that simple.

143
00:08:19.130 --> 00:08:21.500
So let's talk about the pros and cons,
right?

144
00:08:21.501 --> 00:08:25.490
So here's an image of all of the machine learning libraries that are compatible

145
00:08:25.491 --> 00:08:26.330
with core ml.

146
00:08:26.360 --> 00:08:30.890
That means that that means that the core ml tools python package can convert a

147
00:08:30.891 --> 00:08:35.180
model trained with these frameworks into the.ml model format that you can then

148
00:08:35.181 --> 00:08:35.600
run,

149
00:08:35.600 --> 00:08:40.600
that you can then use to run inference on your device cafe Caerus xg boost live

150
00:08:41.241 --> 00:08:44.000
has SVM psychic learn Turi,
right?

151
00:08:44.001 --> 00:08:47.860
So the pros are it's optimized for on device performance,
which minimize,

152
00:08:47.910 --> 00:08:50.960
minimize his memory footprint and power consumption.

153
00:08:51.110 --> 00:08:54.350
That's the one thing you know about Apple's library as opposed to any third

154
00:08:54.351 --> 00:08:55.170
party framework.

155
00:08:55.170 --> 00:08:59.610
You know that it is going to be optimized a f for its devices because they make

156
00:08:59.611 --> 00:09:01.350
the hardware and the software.

157
00:09:02.130 --> 00:09:05.040
We also know that apple really cares about user privacy.

158
00:09:05.160 --> 00:09:07.410
That means use the privacy of users data.

159
00:09:07.620 --> 00:09:11.310
So that means you don't have to send the users' data to the server.

160
00:09:11.430 --> 00:09:15.150
It stays local and encrypted and it means that you can,

161
00:09:15.440 --> 00:09:17.820
and because inferences were happening on device,

162
00:09:17.850 --> 00:09:19.200
you don't need an internet connection.

163
00:09:19.201 --> 00:09:23.280
So they could be in like a ditch or a prison or why am I thinking of these weird

164
00:09:23.281 --> 00:09:23.850
places,

165
00:09:23.850 --> 00:09:27.840
but somewhere without Internet connection and then it will be able to perform

166
00:09:27.841 --> 00:09:28.890
inference there,
right?

167
00:09:28.891 --> 00:09:31.500
You don't need an Internet connection and it decides itself.

168
00:09:31.501 --> 00:09:35.940
Remember it's a layer of abstraction on top of the previous two machine learning

169
00:09:35.941 --> 00:09:36.774
libraries.

170
00:09:37.320 --> 00:09:42.210
It decides itself whether to run on the CPU or the GPU or both.
So it's,
it's,

171
00:09:42.211 --> 00:09:47.070
it's self optimizes what it's running on and because it can run on the CPU,

172
00:09:47.100 --> 00:09:48.450
you can run it on the simulator,

173
00:09:48.600 --> 00:09:52.260
which you can't if it were to just run on the GPU because the simulator doesn't

174
00:09:52.261 --> 00:09:56.040
support the GPU yet and it supports many model types.

175
00:09:56.040 --> 00:09:59.670
That's the last pro it support support vector machines.
They're all listed here.

176
00:09:59.850 --> 00:10:03.060
It supports three types of neural networks at convolutional network,

177
00:10:03.240 --> 00:10:07.620
a recurrent network for sequences,
and then a feed forward network.
Right?

178
00:10:07.621 --> 00:10:11.910
And then you've got tree ensembles as tree ensemble ensembles like random forest

179
00:10:11.911 --> 00:10:15.690
and boosted trees,
linear regression and logistic regression.
Okay?

180
00:10:15.691 --> 00:10:18.600
So that's it for the pros and we have to talk about the cons,
right?

181
00:10:18.720 --> 00:10:21.570
It's not perfect.
The first is that there is no,

182
00:10:21.590 --> 00:10:24.750
there is only native support for supervised machine learning models.

183
00:10:24.751 --> 00:10:27.150
That means that models that require labels,

184
00:10:27.230 --> 00:10:31.020
there is no support for unsupervised models or for reinforcement learning.

185
00:10:31.050 --> 00:10:35.460
So that's that.
That can be a big,
uh,
uh,
pain and no training on device,
right?

186
00:10:35.461 --> 00:10:40.020
So you can only perform inference on a device.
Also,
it only PR,
uh,

187
00:10:40.140 --> 00:10:43.380
support certain layer types.
So you can just create a new layer,

188
00:10:43.381 --> 00:10:45.590
type yourself and add it to core ml.
It's,

189
00:10:45.660 --> 00:10:49.410
it's impossible to extend core Mel's native layer types,

190
00:10:50.310 --> 00:10:55.140
and it only supports a specific set of training tools,
not tensorflow.
However,

191
00:10:55.141 --> 00:10:58.950
you can write your own custom conversion script for tensorflow models.

192
00:10:59.280 --> 00:11:01.860
You can't look at the output produced by the intermediate layers,

193
00:11:01.890 --> 00:11:06.300
only the output layers.
It only supports regression and classification.

194
00:11:06.301 --> 00:11:06.961
That means no,

195
00:11:06.961 --> 00:11:11.610
none of the unsupervised techniques like clustering or ranking or dimensionality

196
00:11:11.611 --> 00:11:16.260
reduction.
And my biggest gripe is this kind of ties into no training on device,

197
00:11:16.261 --> 00:11:20.490
but no federated learning,
right?
Federated Learning is a technique.

198
00:11:20.570 --> 00:11:23.220
Google actually published a blog post on this very recently,

199
00:11:23.460 --> 00:11:27.930
but basically you can utilize all the phones that you deploy your app too.

200
00:11:27.931 --> 00:11:31.800
You can train it on their data locally instead of having it train on a server.

201
00:11:32.190 --> 00:11:36.810
And so you can combine all of that training into one big model that is then

202
00:11:36.811 --> 00:11:39.020
deployed to everybody.
So you're,

203
00:11:39.030 --> 00:11:42.300
you're learning from all the devices that you're,
that you're deployed to.

204
00:11:42.990 --> 00:11:46.950
And so Tldr core ml is super simple.
We saw very simple code sample already,

205
00:11:47.040 --> 00:11:50.550
but it's limited in its functionality.
So if you want full control,

206
00:11:50.700 --> 00:11:54.700
you're going to have to DIY with either the two native libraries that is built

207
00:11:54.701 --> 00:11:58.420
on top of,
or you can just use another third party framework.

208
00:11:58.421 --> 00:12:02.440
Hormel is not the only way to do machine learning on Ios devices.

209
00:12:02.620 --> 00:12:06.460
There are other ways,
surprisingly,
right?
And I've got a list of them right here.

210
00:12:06.461 --> 00:12:09.910
There are a lot of third party frameworks that work with Ios.

211
00:12:09.911 --> 00:12:12.430
They'll let you do a bunch of different machine learning tasks.

212
00:12:12.580 --> 00:12:16.630
So of course ml doesn't fit your needs specifically or you don't want to extend

213
00:12:16.631 --> 00:12:19.330
it,
then go ahead and use these.
All right,

214
00:12:19.331 --> 00:12:23.800
so what are steps in this tutorial are our steps are going to be first in python

215
00:12:23.950 --> 00:12:27.280
to look at what it means to import a Dataset,
train a model,

216
00:12:27.370 --> 00:12:30.550
and then convert that trained model into a.ml model.

217
00:12:30.760 --> 00:12:35.470
Then we'll go into x code and then in swift will drag and drop our datasets are

218
00:12:35.471 --> 00:12:37.900
trained ml model into x code.

219
00:12:38.080 --> 00:12:41.530
Then we'll write our basic prediction code and then we'll run the APP.
All right,

220
00:12:41.531 --> 00:12:44.860
let's get started with this.
So for our python code,
so I'll,

221
00:12:44.861 --> 00:12:48.010
I'll write out the swift code,
but we'll just clients over the python code.

222
00:12:48.340 --> 00:12:51.820
So far our dependencies for the python code,
we have to,
right?
We have two.

223
00:12:51.821 --> 00:12:54.130
One is for num Pi for matrix math,

224
00:12:54.131 --> 00:12:57.790
and then the second is psychic learn and all of its sub modules,
right?

225
00:12:58.450 --> 00:12:59.050
We're going to run,

226
00:12:59.050 --> 00:13:01.930
we're going to train three models and then we're going to pick the best one.

227
00:13:01.931 --> 00:13:03.580
And I'll talk about what those three models are,

228
00:13:03.581 --> 00:13:07.750
but you can get a little hint from here as well as two techniques to vectorize

229
00:13:08.050 --> 00:13:12.130
the all each of these models.
So in total,
there'll be six different,
uh,

230
00:13:12.550 --> 00:13:15.130
pipelines that will build.
So for each of the models,

231
00:13:15.190 --> 00:13:18.910
we'll try out two different vectorization techniques,
right?
So two,
two and two.

232
00:13:18.911 --> 00:13:22.990
So which makes six,
right?
So that's it for psych,
it learn for num Pi.

233
00:13:23.170 --> 00:13:27.790
And so core ml tools,
the,
the python package only supports python two.

234
00:13:27.791 --> 00:13:29.830
So if you,
if you have python three,

235
00:13:29.950 --> 00:13:34.720
you can use these commands to initialize your python environment and then you

236
00:13:34.721 --> 00:13:39.340
can import a core ml tools,
right?
Just like that.

237
00:13:39.610 --> 00:13:43.440
So I'll go back up here,
compile,
but uh,

238
00:13:45.640 --> 00:13:47.920
okay.
And so now we can import our data.

239
00:13:47.921 --> 00:13:50.080
So let's take a look at our data set really quickly here.

240
00:13:50.290 --> 00:13:54.370
What does our data set look like?
We have an SMS spam collection datasets,

241
00:13:54.550 --> 00:13:58.420
and it's a bunch of human labeled,
uh,
SMS messages.

242
00:13:58.421 --> 00:14:02.110
Either Ham or spam,
right?
Spam or not spam.
All right,

243
00:14:02.111 --> 00:14:03.490
so that's the data set we're going to use.

244
00:14:03.491 --> 00:14:07.330
And so what we can do is we can open that data data set.
It's a txt file.

245
00:14:07.360 --> 00:14:08.500
We'll go through it,
we'll,

246
00:14:08.501 --> 00:14:12.010
we'll split all the lines and then we'll convert it into a training and a

247
00:14:12.011 --> 00:14:14.920
testing set.
Using psychic learns,
train test,
split function.

248
00:14:15.160 --> 00:14:18.280
We can print out the training set to just see,
you know what it looks like.

249
00:14:18.281 --> 00:14:19.180
It looks kind of messy,

250
00:14:19.330 --> 00:14:22.300
but these are some text messages and it's just kind of label ham or stem.

251
00:14:22.301 --> 00:14:26.110
That's it,
right?
Binary classification,
right?

252
00:14:26.111 --> 00:14:29.860
So that's it for importing our data and now we can look at our models,
right?

253
00:14:29.861 --> 00:14:32.590
So we're going to use three models and each of these models,

254
00:14:32.591 --> 00:14:35.410
I've created a video just explaining the entire model.

255
00:14:35.470 --> 00:14:37.510
So definitely check out each of these videos.

256
00:14:37.630 --> 00:14:39.400
In my math of intelligence playlist,

257
00:14:39.550 --> 00:14:43.240
I've got one for the multinomial naive Bayes support vector machine,

258
00:14:43.360 --> 00:14:46.630
and for the random forest,
which are the three models that we're going to use,

259
00:14:46.720 --> 00:14:48.460
but to just go over them at a high level.

260
00:14:48.700 --> 00:14:53.450
Multinomial naive Bayes is a version of the naive Bayes classifier.

261
00:14:53.480 --> 00:14:55.930
These are all classifiers where it,

262
00:14:55.931 --> 00:15:00.620
it's just computing conditional probabilities for all the words in a set of

263
00:15:00.621 --> 00:15:04.220
documents,
right?
It's just iteratively computing conditional probabilities.

264
00:15:04.400 --> 00:15:07.910
But definitely check out my naive Bayes video on that.
And then I have,

265
00:15:07.940 --> 00:15:09.710
we're going to use a support vector machine.

266
00:15:09.800 --> 00:15:11.120
And so this is a little refresher here.

267
00:15:11.121 --> 00:15:14.570
Writes a support vector machine is a type of machine learning model that can

268
00:15:14.571 --> 00:15:16.100
classify two different classes.

269
00:15:16.310 --> 00:15:20.030
And what it does is it builds a hyperplane by using the,

270
00:15:20.060 --> 00:15:23.360
by using the support vectors that are the points that are the closest to each

271
00:15:23.361 --> 00:15:25.220
other between the two classes.

272
00:15:25.370 --> 00:15:28.850
And then maximize the margin between them and draws a hyperplane right in

273
00:15:28.851 --> 00:15:30.740
between them.
And so when we add a class,

274
00:15:31.010 --> 00:15:33.890
depending on what side of the line it goes on,
we can classify it.

275
00:15:34.250 --> 00:15:38.000
And for a random forest or random forest is a set of decision trees,
you know?

276
00:15:38.001 --> 00:15:42.610
Yes,
no,
it just,
it asks a series of questions and then it,

277
00:15:42.890 --> 00:15:46.100
the result is what it,
what something is.
It'll classify it.

278
00:15:46.280 --> 00:15:49.280
And what we can do is we can say,
let's create a bunch of decision trees.

279
00:15:49.430 --> 00:15:52.880
Have them all classify some data,
have them vote,
and then pick the,

280
00:15:52.881 --> 00:15:53.900
pick the winner,
right?

281
00:15:53.990 --> 00:15:57.260
What is the most likely class based on a set of decision trees,

282
00:15:57.440 --> 00:16:00.890
random forest rights.
That's why I told the forest,
because it's a set of trees.

283
00:16:02.000 --> 00:16:03.950
And then in terms of vectorization strategies,

284
00:16:04.160 --> 00:16:05.990
we're going to use either the account vectorized sir,

285
00:16:06.050 --> 00:16:07.730
which is just basically a bag of words.

286
00:16:07.731 --> 00:16:09.770
It just counts the number of times a word appears.

287
00:16:10.220 --> 00:16:13.970
Or we could use a more advanced way of doing this called TF IDF.

288
00:16:14.120 --> 00:16:18.760
And what this says is it's a technique to score each vector,
right?
Uh,

289
00:16:18.920 --> 00:16:22.340
for a term I in a document,
Jay.
So for each of the words,

290
00:16:22.341 --> 00:16:24.710
what we can do is we can say the score,
it's TF.

291
00:16:24.711 --> 00:16:29.711
IDF score is the number of occurrences of I in j times the log of the total

292
00:16:31.821 --> 00:16:36.320
number of documents or SMS messages in our case over the number of documents

293
00:16:36.350 --> 00:16:39.530
containing I.
And so we'll,
we'll compute both of these,

294
00:16:39.531 --> 00:16:43.640
the Callen vectorize are and the TF IDF for all three of these models giving us

295
00:16:43.641 --> 00:16:47.630
six different pipelines to use.
Right?
So here's,

296
00:16:47.631 --> 00:16:49.250
here's US building the pipeline,
right?

297
00:16:49.370 --> 00:16:53.510
We have six different pipelines for each of the models.
We'll try out both TF,

298
00:16:53.511 --> 00:16:56.960
IDF and count vectorized,
sir.
Once we have all those pipelines,

299
00:16:56.961 --> 00:17:00.590
will put them into a list and then we'll perform classification using all of

300
00:17:00.591 --> 00:17:04.190
them.
And so we'll find this is running right now,
we're running live.

301
00:17:04.550 --> 00:17:09.550
We'll find that the support vector machine using TF IDF wins,

302
00:17:10.131 --> 00:17:13.040
right?
This has the highest accuracy,
98 98 98.

303
00:17:13.130 --> 00:17:17.810
So that's the one that we're going to convert into.
Dot Ml model file.

304
00:17:17.930 --> 00:17:20.240
So we'll see.
What we'll do is we'll say,
okay,

305
00:17:20.360 --> 00:17:25.360
we'll get all the ordering of the words and from this dot txt file and then

306
00:17:25.371 --> 00:17:30.050
we'll vectorize it and then we'll convert that uh,

307
00:17:30.110 --> 00:17:31.940
model.
We'll say here's the model,

308
00:17:31.941 --> 00:17:36.941
the LINEAR SVC fit it to the vectorized data and then use core ml tools to then

309
00:17:37.191 --> 00:17:39.570
convert for specifically for psychic learn,

310
00:17:39.600 --> 00:17:41.660
it's got converters dot psychic learn dot.

311
00:17:41.661 --> 00:17:45.860
Convert the model based on the two rows,
the message and the label.

312
00:17:46.010 --> 00:17:48.800
And that will create a core ml model in memory.

313
00:17:48.930 --> 00:17:53.400
And then we can save it using the save function as a.ml model file.
So when we,

314
00:17:53.610 --> 00:17:54.630
when we compile this,

315
00:17:54.780 --> 00:17:58.640
it's going to save it and then we can then drag and drop it into x code.
Okay,

316
00:17:58.641 --> 00:18:00.690
so now that's the first part we did it.

317
00:18:00.691 --> 00:18:02.880
We train a model in python on our machine.

318
00:18:03.150 --> 00:18:06.390
Now we're going to deploy it to x code.
So let's check out x code now.

319
00:18:07.540 --> 00:18:09.690
So in x code,
what I've,
what I have here,

320
00:18:09.880 --> 00:18:14.040
it's a is the a d a skeleton file.
It's a skeleton file.

321
00:18:14.041 --> 00:18:17.460
All it has is eight Scott,
a storyboard with you know,

322
00:18:17.520 --> 00:18:22.020
a label and then a button right in the the button and the label are wired back

323
00:18:22.170 --> 00:18:24.210
to the view controller,
right?
This is in swift.

324
00:18:24.360 --> 00:18:28.770
We've got one view controller with all the logic,
which has no logic as of now.

325
00:18:29.010 --> 00:18:32.160
And then we have the storyboard,
right?

326
00:18:32.730 --> 00:18:36.270
What's happening here is that for the view controller,

327
00:18:36.330 --> 00:18:39.960
we have an IB action that's going to fire every time the button is pushed.

328
00:18:40.050 --> 00:18:42.390
So inside of here,
we'll put our prediction logic,

329
00:18:42.600 --> 00:18:46.500
and then we have this other function for to perform TF IDF that we're going to

330
00:18:46.501 --> 00:18:49.500
fill out.
Okay,
so let's,
let's do that.
But first,

331
00:18:49.590 --> 00:18:53.430
let's drag and drop our created ml model to our

332
00:18:54.980 --> 00:18:57.230
project.
Just like that.
We'll drag and drop it.

333
00:18:57.830 --> 00:19:02.480
And also our spam collection,
our data set,

334
00:19:02.481 --> 00:19:06.050
because we can test it out on that,
on the training data as well.
Okay,

335
00:19:06.051 --> 00:19:09.260
so then let's go back here and let's start writing the out.

336
00:19:09.261 --> 00:19:12.710
Let's see what this looks like.
Okay,
so,
so first of all,

337
00:19:12.711 --> 00:19:17.711
let's retrieve the text that the user has typed in where we want to retrieve

338
00:19:17.991 --> 00:19:22.310
that message so then we can classify it as spam or not spam.

339
00:19:23.570 --> 00:19:26.120
And so what we'll do is we'll say,

340
00:19:26.600 --> 00:19:30.920
if the text is copied,

341
00:19:31.220 --> 00:19:34.160
let's go ahead and vectorize that text by saying,

342
00:19:34.520 --> 00:19:37.460
let vector equal TF IDF.

343
00:19:37.490 --> 00:19:41.480
And now we haven't actually written out the functionality for this function yet,

344
00:19:41.690 --> 00:19:45.290
but we can just say,
well,
if we feed the texts into TF IDF,

345
00:19:45.450 --> 00:19:48.560
it'll create a vector for us.
And then in a do statement,

346
00:19:48.680 --> 00:19:50.360
we'll make the prediction right.
We'll say,

347
00:19:50.600 --> 00:19:55.100
let the prediction equal tried the message classifier,

348
00:19:56.780 --> 00:20:00.380
right?
That's our message classifier.
Make the prediction,

349
00:20:00.680 --> 00:20:02.630
the message classifier is named right there.

350
00:20:02.631 --> 00:20:05.750
So we can just call it just like that.
And then we'll feed it as the parameter,

351
00:20:05.751 --> 00:20:08.690
the vector that we computed using TF IDF.

352
00:20:08.960 --> 00:20:11.600
And that's going to store the prediction.
We can print,

353
00:20:11.630 --> 00:20:15.050
we can print out the prediction for our,
our own logging purposes.

354
00:20:15.290 --> 00:20:17.210
And then we can to the W,

355
00:20:17.211 --> 00:20:22.211
we can send back that data to the interface or the storyboard by saying,

356
00:20:22.611 --> 00:20:25.430
set the label to the prediction.
Uh,

357
00:20:25.670 --> 00:20:30.320
and then so we'll also have a catch statements.
So if it can't make a prediction,

358
00:20:30.560 --> 00:20:33.350
then we'll set the label to no prediction,

359
00:20:38.870 --> 00:20:42.170
just like that.
And that's it for our logic right here.

360
00:20:42.620 --> 00:20:45.940
And then we'll go to RTF,
DF function.
And so la,

361
00:20:46.040 --> 00:20:50.380
now it's right out this TFD f code.
So what's happening here is

362
00:20:53.090 --> 00:20:54.170
we can say,

363
00:20:56.300 --> 00:20:57.133
<v 1>uh,</v>

364
00:20:59.910 --> 00:21:02.820
<v 0>first we want to import the words ordering and the words.</v>

365
00:21:02.970 --> 00:21:06.780
So we'll go ahead and important both of those just like this.
And so it's,

366
00:21:06.840 --> 00:21:09.750
it's finding where both of these text files are.

367
00:21:10.020 --> 00:21:14.350
And the next step for us is going to say is going to be let's create a do

368
00:21:14.351 --> 00:21:18.000
statement.
And the next step for us is going to,
is going to be,

369
00:21:18.001 --> 00:21:22.410
let me just write this out like this,
just like that.
And so the next step for us,

370
00:21:22.411 --> 00:21:27.330
let me just paste this in right here.
Boom.
Like that or delete this.

371
00:21:27.690 --> 00:21:31.910
Okay.
It's like that.

372
00:21:32.240 --> 00:21:36.410
And so we're going to say,
let's retrieve the ordering.
So,

373
00:21:36.680 --> 00:21:40.640
so inside of our dues statement or retrieved the ordering data will retrieve the

374
00:21:40.641 --> 00:21:45.140
SMS data.
We'll remove the trailing new line from both of them as well,

375
00:21:45.310 --> 00:21:47.390
right?
Removing the trailing new line.

376
00:21:47.540 --> 00:21:50.270
And so once we've retrieved both of those text files,

377
00:21:50.480 --> 00:21:54.680
we're going to vectorize our words just by using this,

378
00:21:54.770 --> 00:21:56.210
we're going to vectorize our words.

379
00:21:57.640 --> 00:21:57.910
<v 1>Okay.</v>

380
00:21:57.910 --> 00:22:00.170
<v 0>But we're going to have a collection of each of those words that we're going to</v>

381
00:22:00.171 --> 00:22:03.050
split by the separator,
the empty space.
And then we,

382
00:22:03.051 --> 00:22:05.660
we will vectorize each of those words.

383
00:22:05.840 --> 00:22:10.220
And so now for the vectorization part,
that here's where the real meat of it,

384
00:22:10.221 --> 00:22:12.650
it goes,
right?
So we're going to say for each word,

385
00:22:12.800 --> 00:22:16.580
let's count the number of times the word shows up in an SMS,
right?

386
00:22:16.581 --> 00:22:20.570
We're going to count the number of times it shows up in an SMS and then we're

387
00:22:20.571 --> 00:22:25.571
going to multiply it by the log of the total SMS messages divided by the SMS

388
00:22:26.181 --> 00:22:28.220
messages that contain that word.

389
00:22:28.700 --> 00:22:32.030
And so that's going to give us the TF IDF score,

390
00:22:32.180 --> 00:22:35.690
which we can then store in the vectorized,
uh,
array.

391
00:22:35.870 --> 00:22:40.550
And then we'll return that array of all the TF IDF scores of each of the words

392
00:22:40.551 --> 00:22:44.120
in the SMS documents.
And that's it for that.

393
00:22:44.180 --> 00:22:45.740
And then we can go ahead and compile this

394
00:22:48.800 --> 00:22:52.550
and it works just like that.
So overall,
I think this is a very fun library.

395
00:22:52.551 --> 00:22:53.080
It's gonna.
It's,

396
00:22:53.080 --> 00:22:56.930
it's a great way to introduce regular developers who've never done any kind of

397
00:22:56.931 --> 00:23:00.440
data science or machine learning to machine learning because it's so simple to

398
00:23:00.441 --> 00:23:04.490
use.
If you've never coded for Ios before,
I would highly recommend it.

399
00:23:04.520 --> 00:23:07.530
It's a lot of fun.
And if core Mel doesn't give you what you want,

400
00:23:07.531 --> 00:23:10.070
and you can always use the two frameworks that it's built on,

401
00:23:10.071 --> 00:23:13.100
or you could just use a third party library.
All right?
That's it.

402
00:23:13.160 --> 00:23:15.800
Please subscribe for more programming.
Video is,
and for now,

403
00:23:15.860 --> 00:23:19.760
I've got to be thankful for automatic reference counting,
so thanks for watching.

