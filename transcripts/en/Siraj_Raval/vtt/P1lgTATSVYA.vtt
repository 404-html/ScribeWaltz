WEBVTT

1
00:00:00.030 --> 00:00:02.970
Streaming in three,
two,

2
00:00:03.360 --> 00:00:07.680
one go event is starting,
stream has begun.

3
00:00:08.040 --> 00:00:12.420
The world is here and ready for reinforcement learning.
I think we're live.
Great.

4
00:00:12.510 --> 00:00:15.750
Hello world.
It's the Raj and welcome to my live stream.

5
00:00:15.751 --> 00:00:20.751
And in this livestream I'm going to attempt this Kaggle challenge called the two

6
00:00:21.181 --> 00:00:26.070
sigma financial modeling challenge.
It's $100,000 worth of prize money.

7
00:00:26.310 --> 00:00:27.300
And I'm going to sit,

8
00:00:27.330 --> 00:00:31.410
I'm going to create an algorithm that's going to hopefully get into the top 50

9
00:00:31.510 --> 00:00:34.320
leaderboards.
We'll,
we'll see how well it does,

10
00:00:34.620 --> 00:00:38.730
but I want to just start off by saying that the point of this video is first of

11
00:00:38.731 --> 00:00:42.360
all to talk about some time forecasting techniques.
Now,

12
00:00:42.420 --> 00:00:45.360
for some reason in all of the videos that I've made,

13
00:00:45.540 --> 00:00:48.840
I haven't talked about time series forecasting,
um,

14
00:00:49.350 --> 00:00:51.930
outside of the context of deep neural networks.

15
00:00:52.110 --> 00:00:57.110
But I will in this video and the other part of this video is for me to show that

16
00:00:58.021 --> 00:01:01.960
reinforcement learning can be used in the real world,
um,

17
00:01:02.280 --> 00:01:06.930
in an applicable setting.
And,
um,
it,
this is part of move 37 so,
so,
so,

18
00:01:06.931 --> 00:01:10.390
so that's why I'm doing this.
And,
and,
uh,
how this,
uh,

19
00:01:10.560 --> 00:01:13.350
video is going to be structured is it's going to be an intro Q and.
A.

20
00:01:13.351 --> 00:01:16.230
So I'm going to answer two questions.
So go ahead and start asking them now.

21
00:01:16.500 --> 00:01:20.850
I'm going to go over a time series lecture brief Q and a exploratory data

22
00:01:20.851 --> 00:01:25.440
analysis or Eda for our datasets,
brief Q and a and then reinforcement learning.

23
00:01:25.441 --> 00:01:29.970
And the point of this is to predict,
um,
a value.
Um,

24
00:01:30.030 --> 00:01:32.250
obviously all machine learning is about predicting a value,

25
00:01:32.251 --> 00:01:36.450
but we're trying to predict a specific target value and we'll talk about that

26
00:01:36.600 --> 00:01:37.201
when we get to it.

27
00:01:37.201 --> 00:01:40.680
But let me just start off by answering two questions and then we'll get into the

28
00:01:40.681 --> 00:01:45.120
code.
Okay.
Uh,
the first question is,
hi everybody,

29
00:01:45.600 --> 00:01:48.000
thank you for being here.
The first question is,

30
00:01:49.200 --> 00:01:53.490
can you suggest some gesture recognition algorithms?
Sure.
So,
uh,

31
00:01:53.491 --> 00:01:57.540
right now pose estimation is the,
the,
the,
the state of the art.

32
00:01:57.660 --> 00:01:59.190
So go to use tensorflow.
Dot.

33
00:01:59.191 --> 00:02:03.690
JS probably the easiest to use implementation for pose estimation in the

34
00:02:03.691 --> 00:02:08.010
browser.
Anybody can do it.
So that's the one to use.
Okay.
So that's the first one.

35
00:02:08.011 --> 00:02:13.011
The next question out of two is what does it require to create a Bot like a

36
00:02:14.041 --> 00:02:16.500
human?
Great advanced question.

37
00:02:16.501 --> 00:02:21.350
Now I'm going to minimize this and hello everybody.
So the,
that question,
um,

38
00:02:21.700 --> 00:02:26.640
about like a human that is Agi,
artificial general intelligence,
you know,

39
00:02:26.641 --> 00:02:29.970
the Turing test,
which hasn't really been passed yet.
Um,

40
00:02:30.180 --> 00:02:33.480
but that would be an open domain chat bot that would,

41
00:02:33.750 --> 00:02:37.980
it would be trained on data that is not a closed loop but just,
you know,

42
00:02:37.981 --> 00:02:42.270
the entire Internet and this hasn't been solved,
but uh,
the,
the,
the,

43
00:02:42.271 --> 00:02:44.760
the best way forward with that would be,

44
00:02:45.480 --> 00:02:50.480
I would say using deep reinforcement learning in the context of,

45
00:02:51.600 --> 00:02:54.440
of text data and,
and the web and,

46
00:02:54.441 --> 00:02:57.420
and having an open domain where there's this,

47
00:02:57.600 --> 00:03:00.670
there's a cycle where you're using reinforcement learning where you're using a

48
00:03:00.671 --> 00:03:01.690
reward signal,

49
00:03:01.750 --> 00:03:05.980
the train a deep neural network where it's searching the internet itself,
it's,

50
00:03:06.010 --> 00:03:09.550
it's querying the internet and it's building off of these queries.

51
00:03:09.670 --> 00:03:11.410
It's using natural language processing,

52
00:03:11.440 --> 00:03:15.100
hence the deep neural network to create abstractions from the text data.

53
00:03:15.400 --> 00:03:18.700
And then based on those abstractions,
it's learning to maximize a reward,

54
00:03:18.820 --> 00:03:22.180
which would be to say,
you know,
you could frame it so that a human would say,

55
00:03:22.870 --> 00:03:27.520
you know,
yes,
no binary,
you know,
that this is a good response or not.
Uh,
yeah.
So,

56
00:03:27.521 --> 00:03:30.040
so that's kind of a research direction that I'm thinking of of,

57
00:03:30.041 --> 00:03:34.060
of what hasn't been done.
But what would be cool for human level chatbots.
Okay.

58
00:03:34.061 --> 00:03:35.110
So that's it for the Q and.
A.

59
00:03:35.440 --> 00:03:40.440
Let's start talking about time series analysis because in this dataset they're

60
00:03:40.721 --> 00:03:45.310
asking us to predict a,
a target variable based on the past.
Okay.
So,

61
00:03:45.610 --> 00:03:49.360
um,
so let's just talk about time series analysis in general,
right?

62
00:03:49.480 --> 00:03:52.840
Where we have two variables,
right?
So let's start off with univariate,

63
00:03:52.930 --> 00:03:57.310
a single variable time series analysis.
So we have some price data.

64
00:03:57.340 --> 00:03:58.780
Let's say this is for bitcoin.
Okay.

65
00:03:58.781 --> 00:04:01.960
This is a bitcoin price over a period of days.
Now,

66
00:04:01.990 --> 00:04:05.830
if we want to forecast the price for the next day,
how do we do that?
Right?

67
00:04:05.831 --> 00:04:09.970
This is a time series where the variables depend on the time,
right?

68
00:04:10.070 --> 00:04:14.380
The what the values are,
what their target variables are,
are,
are,

69
00:04:14.740 --> 00:04:19.660
are completely dependent on the time step,
right?
So,
so that would,

70
00:04:19.690 --> 00:04:22.030
that's what makes it different from a regular data set.

71
00:04:22.031 --> 00:04:24.670
A time series data set depends on the time.

72
00:04:25.090 --> 00:04:27.790
So what we would do here is the naive approach.

73
00:04:27.820 --> 00:04:31.690
Let's just start off with a naive approach where we say what this next data

74
00:04:31.691 --> 00:04:36.400
point is going to be in this graph is going to be the target variable.

75
00:04:36.700 --> 00:04:40.150
That's it.
So we're just going to say that the predictive variable,

76
00:04:40.180 --> 00:04:44.440
and here's the equation is going to be the the variable from the previous time

77
00:04:44.441 --> 00:04:47.140
step.
That's it,
right?
That's the equation right there.

78
00:04:47.290 --> 00:04:49.900
And we would call this the naive approach,
right?

79
00:04:50.050 --> 00:04:54.370
And so what happens is when we have a data sets like this where just imagine the

80
00:04:54.371 --> 00:04:58.990
entire thing is one dataset and we have split it into training and testing data

81
00:04:59.380 --> 00:05:02.470
where we say,
okay,
this is the entire training dataset.

82
00:05:02.560 --> 00:05:06.940
Now based on this last data point,
predict the next point.
Well,
it's going to say,

83
00:05:06.941 --> 00:05:10.630
well based on this one,
let me just do that again because that's our variable.

84
00:05:11.020 --> 00:05:14.230
That's our equation,
our forecast model.

85
00:05:14.470 --> 00:05:16.150
And so it'll do that again and again and again.

86
00:05:16.180 --> 00:05:18.190
And what happens is it's just a straight line.

87
00:05:18.280 --> 00:05:21.310
So this is a very bad approach and this is the naive approach,

88
00:05:21.370 --> 00:05:25.690
but let's see how we can improve on this.
So how would we improve?
Well,

89
00:05:25.750 --> 00:05:29.620
check out this graph so it's got volatility,
it's going up,
it's going down.

90
00:05:29.800 --> 00:05:32.860
But notice that there is an average line.

91
00:05:32.861 --> 00:05:37.780
You can imagine that there is this average line,
the line of best fit,

92
00:05:37.840 --> 00:05:41.470
you could call where it is the average between the ups and the downs.

93
00:05:41.500 --> 00:05:45.970
And we could draw it mentally through this model.
And so if we do that,

94
00:05:46.000 --> 00:05:46.930
if we do that,

95
00:05:47.980 --> 00:05:51.560
then we can make the assumption that the next price is,

96
00:05:51.820 --> 00:05:55.840
is going to be the average of all the prices that came before it,
right?

97
00:05:55.841 --> 00:05:56.920
So if we have that,

98
00:05:57.210 --> 00:06:02.210
that sequence of values of all of those why values the y values are right here

99
00:06:03.471 --> 00:06:07.970
on this,
on this axis,
and the x values are here the days,

100
00:06:08.390 --> 00:06:09.950
then we could use this equation.

101
00:06:09.980 --> 00:06:14.480
Now don't be afraid about the fact that we are using a little bit of math here.

102
00:06:14.600 --> 00:06:18.830
What this says is the target variable y which we can call y hat.

103
00:06:18.920 --> 00:06:22.910
The one we want to predict is going to be equal to the sum.

104
00:06:22.911 --> 00:06:26.150
That's a sigma notation.
This eat,
this Greek he looking letter,

105
00:06:26.390 --> 00:06:31.250
the sum of all of those variables that came before it divided by the total

106
00:06:31.251 --> 00:06:35.390
number of them x.
So from I to x,
where x is the number of variables,

107
00:06:35.510 --> 00:06:37.850
add them all up.
That's what sigma notation means.

108
00:06:38.060 --> 00:06:41.360
And then divide by the number of them and that's the average and that's our

109
00:06:41.361 --> 00:06:46.010
prediction.
So if we do that,
then this is what our line is going to look like.

110
00:06:46.340 --> 00:06:49.880
Okay,
so it's saying based on this last data point right here,

111
00:06:50.000 --> 00:06:52.130
what's going to be the next one?
Well,
it's not going to be up here.

112
00:06:52.131 --> 00:06:55.490
It's going to be down here because we're taking into account all of those data

113
00:06:55.491 --> 00:06:58.040
points from the very,
very beginning to the very end.

114
00:06:59.570 --> 00:07:02.390
But notice that this is not ideal either,
right?

115
00:07:02.390 --> 00:07:04.280
We need something that's going to be better than that.

116
00:07:04.400 --> 00:07:06.620
So how do we improve on that?
Well,

117
00:07:06.621 --> 00:07:09.830
we would use a different technique called the moving average.

118
00:07:10.040 --> 00:07:13.010
So what the moving average does is it says,
well,

119
00:07:13.011 --> 00:07:16.700
the points at the very beginning and the points near the end,

120
00:07:16.880 --> 00:07:21.710
these are completely different directions.
So let's only consider the points,

121
00:07:21.950 --> 00:07:26.450
um,
immediately before our forecasts are our target variable that we want to

122
00:07:26.451 --> 00:07:28.790
predict.
So we'll have a window,
okay.

123
00:07:28.791 --> 00:07:32.030
And we'll just average those and we'll leave out what we'll leave out the

124
00:07:32.031 --> 00:07:36.530
beginning.
And so what that equation looks like is this where y hat,

125
00:07:36.560 --> 00:07:41.560
the predictor variable is going to be the sum of all of those,

126
00:07:42.020 --> 00:07:44.450
that all of those values that came before our,

127
00:07:44.660 --> 00:07:49.460
our target variable up to a certain threshold which we define as p,

128
00:07:49.760 --> 00:07:50.690
you know,
say the first,

129
00:07:50.720 --> 00:07:55.160
the previous five or the previous six variables divided by the total number of

130
00:07:55.161 --> 00:07:58.160
them.
And that's the average.
And so if we do that,

131
00:07:58.400 --> 00:08:02.180
now notice there's a little bit,
um,
it's,
it's getting better,
our prediction,

132
00:08:02.181 --> 00:08:06.610
right?
It looks like this.
Now how can we approve on this?
Um,

133
00:08:06.670 --> 00:08:10.850
notice I'm going through a lot of techniques very fast,
so slow me down if you,

134
00:08:10.851 --> 00:08:14.930
if you feel like it's too fast.
Um,
well,

135
00:08:15.320 --> 00:08:19.400
one way we can improve that is by using a technique called simple exponential

136
00:08:19.401 --> 00:08:23.630
smoothing.
What that means is,
you know,

137
00:08:24.290 --> 00:08:28.250
let's,
let's take into account all of those variables because clearly all of them

138
00:08:28.251 --> 00:08:31.640
matter,
but let's weight them differently.
Okay,

139
00:08:31.641 --> 00:08:35.390
let's weight them differently where we say the variables that came immediately

140
00:08:35.391 --> 00:08:39.230
proceeding are our,
for our predictor,
our target variable.

141
00:08:39.500 --> 00:08:43.160
We'll weigh them more than the variables that came at the very beginning because

142
00:08:43.161 --> 00:08:46.460
these matter more.
So how do we do that mathematically?
Right?

143
00:08:46.670 --> 00:08:49.850
And here's how we take this constant value,

144
00:08:49.910 --> 00:08:53.660
which we're gonna call Alpha and we do the same thing where we're at,

145
00:08:53.661 --> 00:08:58.620
where we're adding them all up,
but we're multiplying it by this,
this,

146
00:08:58.680 --> 00:08:59.550
this,
this,

147
00:08:59.551 --> 00:09:04.170
a constant value and squared cubed to the fourth,

148
00:09:04.171 --> 00:09:08.850
to the fifth.
Notice this trend here of exponential,
exponential increasing.

149
00:09:10.470 --> 00:09:13.350
And so this is called simple,
exponential smoothing,
okay?

150
00:09:13.830 --> 00:09:18.830
And what this means is that these variables are going to be weighted

151
00:09:19.861 --> 00:09:21.840
differently.
Now here's a question for you.

152
00:09:21.841 --> 00:09:25.950
I'm very excited and I'll be very impressed if someone can answer this question.

153
00:09:26.340 --> 00:09:31.340
What does this formula look like that we already know about from reinforcement

154
00:09:32.551 --> 00:09:36.780
learning literature,
such rich literature?
What does this formula look like?

155
00:09:36.781 --> 00:09:38.670
If anybody can answer that,
I'm going to be very impressed.

156
00:09:38.671 --> 00:09:43.590
Let me keep going though.
Okay,
ready?
Okay.

157
00:09:43.950 --> 00:09:48.660
It looks very similar to the discount factor from reinforcement learning.

158
00:09:48.810 --> 00:09:51.990
So in the reinforcement learning context,
we have an agent.

159
00:09:52.020 --> 00:09:55.290
It acts in an environment,
right?
It's making an action.

160
00:09:55.380 --> 00:09:58.050
And it receives an observation of this,
of the next state.

161
00:09:58.320 --> 00:10:01.920
And in order to maximize reward,
how do we maximize reward?
Well,

162
00:10:01.921 --> 00:10:06.720
here's how we calculate reward at every time step we can predict what the reward

163
00:10:06.721 --> 00:10:10.620
will be for being in a specific state up to our end state,
the terminal state,

164
00:10:10.890 --> 00:10:15.890
and we'll add up all those rewards multiplied by a constant factor called the

165
00:10:16.261 --> 00:10:17.430
discount factor.

166
00:10:17.910 --> 00:10:21.620
And we are waiting those rewards in order of um,

167
00:10:21.750 --> 00:10:25.680
the rewards that came pre immediately,
previously.
We're weighing them more.

168
00:10:25.681 --> 00:10:28.830
We're saying that there are more important than the reward that came at the
very,

169
00:10:28.831 --> 00:10:31.800
very beginning.
And that's the discount factor.

170
00:10:33.810 --> 00:10:37.800
Yeah.
Wow.
Actually people got that.
I'm,
I'm very,
I'm very impressed.

171
00:10:37.980 --> 00:10:42.330
Good job guys.
Very good.
So let's keep improving here.
So,

172
00:10:42.900 --> 00:10:43.980
so the,
by the way,

173
00:10:43.981 --> 00:10:48.210
the reason I wanted to say that is because is to just give you some intuition

174
00:10:48.211 --> 00:10:49.730
behind reinforcement learning.
It's,
it's,

175
00:10:49.731 --> 00:10:53.750
it's a framework for viewing the world really.
And,

176
00:10:53.751 --> 00:10:57.120
and how intelligent agents interact in the world.

177
00:10:57.450 --> 00:11:02.450
It's not the actual mathematics of intelligence of pattern recognition,

178
00:11:03.090 --> 00:11:06.120
but it's more about framing these pattern recognition networks.

179
00:11:06.210 --> 00:11:11.010
In the context of a dynamic world that adapts to that intelligent agent.

180
00:11:11.280 --> 00:11:14.910
More on that at the end.
So Holt was a mathematician in the,

181
00:11:14.911 --> 00:11:19.911
in 1964 I think was a year who invented a linear trend model where he said,

182
00:11:20.160 --> 00:11:24.660
you know what,
this idea of single exponential smoothing it works,

183
00:11:24.661 --> 00:11:26.130
it's fine.
However,

184
00:11:27.450 --> 00:11:31.530
let's improve on that because it doesn't take into account the idea of a trend.

185
00:11:31.770 --> 00:11:36.770
Now a trend is a general direction that we see that a graph is moving in and the

186
00:11:37.591 --> 00:11:42.591
way to mathematically define a trend as Holt a suggested in his linear trend

187
00:11:43.171 --> 00:11:48.171
model would be to create a forecast equation that consists of two other

188
00:11:48.511 --> 00:11:49.440
equations.

189
00:11:49.830 --> 00:11:54.830
So we have a level equation and then we have a trend and we use both of those

190
00:11:55.361 --> 00:11:58.630
equations to compute the final forecast equation.

191
00:11:58.780 --> 00:12:03.780
So it's l plus h B where l is the level of equation and B is a trend location.

192
00:12:04.690 --> 00:12:08.830
We have to constant factors,
we have alpha and we have beta.

193
00:12:08.950 --> 00:12:11.290
They're both different and we can tune them accordingly.

194
00:12:11.800 --> 00:12:16.090
And the level equation is the same idea of exponential smoothing,

195
00:12:16.240 --> 00:12:18.870
but applied to,
um,
both the level,

196
00:12:18.890 --> 00:12:21.820
the average value in the series and the trend.

197
00:12:22.510 --> 00:12:24.040
And if we do that,

198
00:12:24.130 --> 00:12:28.870
then notice our graphs forecast is getting much better.
Okay.

199
00:12:29.230 --> 00:12:31.690
Now there's one more technique I want to talk about.

200
00:12:31.691 --> 00:12:36.691
And this is an improvement that Holt made to that a linear trend model.

201
00:12:37.841 --> 00:12:41.170
We'll start coding in a second,
but,
uh,
it's called the seasonal,

202
00:12:41.260 --> 00:12:44.620
it's called his winter seasonal method.
So there's another,

203
00:12:45.460 --> 00:12:50.140
there's another concept in forecasting called seasonality,

204
00:12:50.380 --> 00:12:55.030
where in a,
in a set of data there's gonna be,
there's gonna be seasons,
right?
So,

205
00:12:55.060 --> 00:12:58.360
um,
in any kind of time series data,
there's going to be some kind of seasonal,

206
00:12:58.361 --> 00:13:00.250
not any,
but most of them real world.

207
00:13:00.340 --> 00:13:03.070
There's going to be some seasonality where there's going to be some kind of

208
00:13:03.071 --> 00:13:07.860
predictable up and some predictable down,
let's say,
you know,
retail,
um,

209
00:13:08.050 --> 00:13:12.220
for retail stores there's going to be more people buying toys in December

210
00:13:12.221 --> 00:13:15.760
because of Christmas and you know,
a lot of western countries or you know,

211
00:13:15.761 --> 00:13:19.940
wherever,
uh,
or there's going to be,
you know,
some kind of trend in the,

212
00:13:19.941 --> 00:13:24.460
in the seasonal direction for stock markets as well.
You know,
based on this,

213
00:13:24.850 --> 00:13:26.950
this is what's happening,
here's how the market is going to go.

214
00:13:27.310 --> 00:13:30.580
So in order to mathematically defined seasonality,

215
00:13:30.820 --> 00:13:35.020
we have now three equations.
So we're adding onto what we had before.
Again,

216
00:13:35.021 --> 00:13:39.190
we're using our level,
we're using our trend,
and now we add a third equation,

217
00:13:39.191 --> 00:13:41.060
which is the seasonal,
um,

218
00:13:41.770 --> 00:13:45.850
equation where the level of equation shows the weighted average between the

219
00:13:45.851 --> 00:13:49.570
seasonally adjusted observation and the non seasonal forecast for time.

220
00:13:49.571 --> 00:13:53.080
T t the trend equation is the same as Holt's linear method.

221
00:13:53.290 --> 00:13:56.710
And the seasonal equation shows the weighted average between the current

222
00:13:56.890 --> 00:14:00.940
seasonal index and the seasonal index of the same season last year.

223
00:14:01.120 --> 00:14:06.010
So they're all,
all each of these equations is interdependent on each other.
Okay.

224
00:14:06.610 --> 00:14:10.720
And so what happens when we do that is now we are getting somewhere.

225
00:14:10.721 --> 00:14:15.310
It's checkout this,
this graph,
it's,
it's a much better graph,
right?
So,
so,

226
00:14:15.311 --> 00:14:19.240
so that,
that's the idea of seasonality.

227
00:14:19.241 --> 00:14:22.570
Now that's for the case of univariate time series.

228
00:14:22.571 --> 00:14:25.210
Now if we have multi-variate time series,

229
00:14:25.300 --> 00:14:29.770
that's multiple input data for whatever the multiple predictor variables for

230
00:14:29.771 --> 00:14:32.050
whatever our target variable is going to be,

231
00:14:32.140 --> 00:14:35.950
which is the case for our two sigma financial modeling contest,

232
00:14:36.490 --> 00:14:41.490
then we're going to use a model that is very similar to a whole to winter

233
00:14:42.611 --> 00:14:45.970
seasonal method that's taking into account.
They'll the level,
the trend,

234
00:14:46.000 --> 00:14:48.430
the seasonality,
right?
To make the forecast.

235
00:14:48.670 --> 00:14:53.420
But it's also finding linear interdependencies between these predictor
variables.

236
00:14:53.750 --> 00:14:55.530
So it's the same idea of a,
of a,

237
00:14:55.610 --> 00:15:00.610
of multiple equations that are relating to each other in a way that we,

238
00:15:00.770 --> 00:15:02.240
once they relate to each other,

239
00:15:02.270 --> 00:15:06.860
we can create a graph and said some popular models for that are a Rhema or
remax,

240
00:15:07.000 --> 00:15:09.140
um,
et cetera.
Um,
and I'll make it,

241
00:15:09.150 --> 00:15:13.640
I'll make a dedicated video on those because you really need to make a dedicated

242
00:15:13.641 --> 00:15:16.820
video on those in,
or we could create it.

243
00:15:16.830 --> 00:15:20.400
Like we could treat this as a supervise problem is many people have done where

244
00:15:20.401 --> 00:15:25.220
we use the power of LSTM networks to then treat it as a supervise problem where

245
00:15:25.221 --> 00:15:29.750
we say the predictor variable,
let's say pollution,
uh,
that's the,

246
00:15:29.810 --> 00:15:32.000
or sorry,
the target,
the,
all these words,

247
00:15:32.180 --> 00:15:36.860
the target variable is going to be the result of the predictor variables,

248
00:15:37.040 --> 00:15:41.990
the temperature,
the,
um,
the human waste use amount,
et cetera.

249
00:15:42.200 --> 00:15:47.120
So there's a mapping between those two.
And the reason we use LSTM networks,
long,

250
00:15:47.121 --> 00:15:51.130
short term memory neural networks is because they take into account longterm

251
00:15:51.220 --> 00:15:52.580
sequence data and they can,

252
00:15:52.970 --> 00:15:57.410
they store memory in a way that is beneficial to sequential data,

253
00:15:57.440 --> 00:15:58.970
which is the case of time series data.

254
00:15:59.090 --> 00:16:02.750
And so that's why we've seen a lot of LSTM networks you being used in time

255
00:16:02.751 --> 00:16:07.400
series data.
Okay,
so let's get,
let's get into some EDA.
And like I said,

256
00:16:07.401 --> 00:16:09.830
I'm going to answer some questions now.
All right.

257
00:16:10.700 --> 00:16:12.980
So what are some questions?

258
00:16:16.160 --> 00:16:19.910
Okay.
Uh,
what's out of focus?

259
00:16:21.530 --> 00:16:25.490
I know it is.
Okay.
Uh,
when did you start programming?

260
00:16:25.491 --> 00:16:28.940
I started programming,
you know,
that's,
that's,
that's,

261
00:16:28.941 --> 00:16:32.450
that's a hard question because,
you know,
I've,
I've been,
I used to like,

262
00:16:32.600 --> 00:16:33.770
I guess the,
the,

263
00:16:35.300 --> 00:16:39.350
I guess the earliest time that I started programming was,
oh,

264
00:16:39.351 --> 00:16:40.550
it's almost embarrassing to say,

265
00:16:40.551 --> 00:16:45.260
but like mark modifying halo two when I was I think 13 or 14.
Uh,

266
00:16:45.280 --> 00:16:49.100
so that was,
that was,
that was a while ago,
but I wasn't even programming.

267
00:16:49.101 --> 00:16:52.930
I was more like downloading scripts and just like hacking it and stuff.
So,

268
00:16:52.970 --> 00:16:56.150
so it's been a while,
but really seriously programming,
um,

269
00:16:57.380 --> 00:17:01.010
probably a couple of years,
couple of years.
Okay.
Who is paying you?

270
00:17:01.011 --> 00:17:03.920
Nobody's paying me.
I mean,
Youtube ads are paying me a Patriot fan.

271
00:17:03.921 --> 00:17:07.370
You guys are paying me,
um,
to do this.
Nobody's paying me,

272
00:17:07.371 --> 00:17:09.050
nobody's paying me cargo and nobody's paying me.

273
00:17:09.051 --> 00:17:10.690
I would have to say that if somebody was paying it,

274
00:17:11.960 --> 00:17:16.310
which is the best book for our El Sutton and Bartow,
have the Bible of our l,

275
00:17:16.311 --> 00:17:18.920
which is called an introduction to reinforcement learning.

276
00:17:18.921 --> 00:17:23.330
Find it on the Internet.
It's,
it's all,
it's,
it's all available for free.
And,
uh,

277
00:17:23.360 --> 00:17:28.160
last question is,
um,
I'm going to get a haircut for sure.

278
00:17:28.250 --> 00:17:33.200
Will you attend?
I will do time series data.
Definitely depends on other factors.

279
00:17:33.860 --> 00:17:38.060
It depends on a lot of factors.
If there's multiple variables.
Okay.

280
00:17:39.730 --> 00:17:43.570
Okay.
Now,
uh,
to the Dataset,
let's go ahead and do this.
So,

281
00:17:43.960 --> 00:17:46.620
so first of all,
now the Dataset is in the video description.
So,

282
00:17:46.640 --> 00:17:49.890
so check the video description.
We're going to do this in Google together.
Okay.

283
00:17:49.891 --> 00:17:53.610
So we're ready for our exploratory data analysis step.

284
00:17:54.130 --> 00:17:54.630
<v 1>Okay.</v>

285
00:17:54.630 --> 00:17:58.740
<v 0>Okay.
So what I did was,
by the way,
with Google Colab,
with these two lines,</v>

286
00:17:58.741 --> 00:18:02.810
you can mount whatever data set you want into Google Colab and then Colette

287
00:18:02.850 --> 00:18:06.390
directly.
So what I did was I downloaded it.
It's an h five file,

288
00:18:06.540 --> 00:18:10.050
uploaded it to my Google drive and then called it with this,
uh,

289
00:18:10.110 --> 00:18:12.270
these two lines of code.
Very simple.
Thank you.

290
00:18:12.271 --> 00:18:15.510
Google colab or making it much easier to do.
All right,
so,

291
00:18:15.511 --> 00:18:17.010
so let's get into this code.

292
00:18:17.520 --> 00:18:18.150
<v 1>Okay.</v>

293
00:18:18.150 --> 00:18:22.350
<v 0>Our first step is going to be to list out our Dataset,
right?
We,
we,</v>

294
00:18:22.520 --> 00:18:26.490
we have this data set where I have this data set in my Google drive and I have a

295
00:18:26.491 --> 00:18:30.300
link for you in the video description and I'll just want to see if it's there.

296
00:18:30.510 --> 00:18:34.140
Okay,
good.
It's there.
That was it.
Okay.
So once I've seen that it's there,

297
00:18:34.230 --> 00:18:37.440
now I'm going to convert it into a pandas data frame.

298
00:18:37.441 --> 00:18:40.590
But before that I've got to import this dependency or install this dependency

299
00:18:40.591 --> 00:18:42.870
called tables.
That's going to let me do that.

300
00:18:43.110 --> 00:18:46.380
And now we can import pandas are handy dandy data,

301
00:18:46.650 --> 00:18:51.650
preprocessing python library to then to then say,

302
00:18:52.620 --> 00:18:57.570
let's import this Dataset at train dot h five.
Okay.

303
00:18:57.571 --> 00:19:01.020
Recursively and we're going to import it as trains.

304
00:19:01.050 --> 00:19:02.160
That's what we're going to call it.

305
00:19:02.550 --> 00:19:06.630
And then we're going to say our data frame is going to be trained dot yet,

306
00:19:06.690 --> 00:19:11.520
and then we'll,
we'll call it by its name,
train,
and that's it.
And hopefully

307
00:19:14.610 --> 00:19:15.000
good.

308
00:19:15.000 --> 00:19:18.840
So now we have it as a data frame and now we can see how big is our data set.

309
00:19:18.841 --> 00:19:23.730
How big is this thing?
We got to check it out.
This thing is massive.

310
00:19:23.760 --> 00:19:28.650
It is over 1.7 million data points,
which is big.

311
00:19:28.770 --> 00:19:32.370
So let's examine this dataset just to see the head,
just the,
the,

312
00:19:32.380 --> 00:19:33.960
the first few variables.

313
00:19:37.480 --> 00:19:41.540
Okay.
So here's our data set.
Okay.
So we have an id,
we have a timestamp,

314
00:19:41.590 --> 00:19:43.480
which is going to,
you know,
be a different time.

315
00:19:43.780 --> 00:19:47.560
And so these are all of our predictor variables.

316
00:19:47.740 --> 00:19:52.330
Now what do these mean,
right?
W W what,
what do these mean?
Right?
And um,

317
00:19:52.540 --> 00:19:56.620
so there's like more than 40 to 44 variables and then we have why?

318
00:19:56.621 --> 00:20:01.600
So why is our predictor variable?
So in the,
in the,
in this competition,
two sigma,

319
00:20:01.601 --> 00:20:03.310
what they did was they said this is a book,

320
00:20:03.340 --> 00:20:05.740
these are a bunch of financial instruments.

321
00:20:05.800 --> 00:20:10.450
So financial instruments are like derivatives,
bonds,
mortgages,
you know,

322
00:20:10.451 --> 00:20:13.870
stocks,
assets,
all of these different types of financial instruments.

323
00:20:13.871 --> 00:20:15.430
But they anonymize them.

324
00:20:15.790 --> 00:20:20.260
So we're calling them just technical 41 technical 42 and then we have our

325
00:20:20.261 --> 00:20:21.070
predictor variable.

326
00:20:21.070 --> 00:20:23.440
Now what does this predictor variable they didn't reveal to us,

327
00:20:23.680 --> 00:20:27.040
but we can think of it as a price,
right?
Let's just think of it as a price in a,

328
00:20:27.041 --> 00:20:27.874
in a trend.

329
00:20:28.180 --> 00:20:33.180
And this price for this asset is dependent on all of these other anonymized

330
00:20:33.191 --> 00:20:36.700
financial instruments.
And so based on all of these financial instruments,

331
00:20:36.701 --> 00:20:39.310
can we predict the price for whatever this is?

332
00:20:39.311 --> 00:20:43.630
Let's just say it's a stock for this case.
Okay?
So let's keep,

333
00:20:43.660 --> 00:20:47.430
let's keep going here.
So our next step is to say,
well,
how many are,

334
00:20:47.550 --> 00:20:50.200
we'll call them labels too.
So why he's going to be labels,

335
00:20:50.650 --> 00:20:53.680
how many labels and how many values do we have?

336
00:20:53.830 --> 00:20:58.390
So what we're gonna do is we're gonna list them both by creating two matrices

337
00:20:59.230 --> 00:21:04.230
and saying the labels are going to be upended by the number of columns that we

338
00:21:05.501 --> 00:21:09.610
have.
The values are going to be upended by the number of

339
00:21:13.760 --> 00:21:16.520
non empty variables we have.

340
00:21:16.521 --> 00:21:21.110
And then we'll print out all of those columns and all of those values starting

341
00:21:21.111 --> 00:21:24.710
from the very beginning.
All right.

342
00:21:27.520 --> 00:21:31.760
Oh right.
The F,
let's see if that works.
Good.
Okay.

343
00:21:31.970 --> 00:21:35.990
So these are all of our variables,
all of our values,
all of our labels in values.

344
00:21:35.991 --> 00:21:37.730
Okay.
So just like that.

345
00:21:38.230 --> 00:21:41.180
So now we want to see how much we have to do some data cleaning.

346
00:21:41.181 --> 00:21:43.010
How much missing data do we have?

347
00:21:43.220 --> 00:21:48.220
So now we can use a map plot line to see just how much missing data we have.

348
00:21:49.640 --> 00:21:53.690
Cause we probably have a lot.
So Plt,
that's our map hot wide.

349
00:21:53.960 --> 00:21:57.020
And then we'll say we'll use this inline.

350
00:21:59.280 --> 00:21:59.530
<v 1>Okay.</v>

351
00:21:59.530 --> 00:22:04.300
<v 0>A call to say that we want to be able to show a map pop live graph inside of the</v>

352
00:22:04.870 --> 00:22:08.380
browser.
Okay.
So we're going to create a map,

353
00:22:08.381 --> 00:22:10.360
plop live graph.

354
00:22:10.630 --> 00:22:15.630
And we're going to say that it's going to contain a finger size.

355
00:22:18.010 --> 00:22:22.600
That's going to be between 12 and 50 so we'll,
we'll,
we'll keep it,
we'll keep it

356
00:22:24.220 --> 00:22:28.720
small,
relatively small.
And we're going to start from those labels,

357
00:22:29.230 --> 00:22:33.370
which I named and I n D and connected to those labels.

358
00:22:33.371 --> 00:22:37.690
We have all of our values and I'm going to color them.

359
00:22:39.370 --> 00:22:42.820
I'm going to label them why.
So in my graph it's going to say why.

360
00:22:43.300 --> 00:22:45.070
And now we can say,

361
00:22:47.080 --> 00:22:47.560
<v 1>okay,</v>

362
00:22:47.560 --> 00:22:50.800
<v 0>let's say set the why ticks.</v>

363
00:22:50.920 --> 00:22:55.240
So these are going to be the intervals between these variables to um,

364
00:22:56.410 --> 00:23:00.310
let's say it's going to be half of the width that I defined four,
which is 0.9,

365
00:23:00.640 --> 00:23:04.510
because those values we saw before,
um,
they seem to be,

366
00:23:07.460 --> 00:23:08.870
they seem to be,
um,

367
00:23:11.740 --> 00:23:14.260
in that range.
So now we'll say,

368
00:23:15.630 --> 00:23:16.980
why ticks?

369
00:23:18.330 --> 00:23:19.040
<v 1>Okay,</v>

370
00:23:19.040 --> 00:23:23.990
<v 0>and let me just do that again.
Why ticks tick labels.
So,</v>

371
00:23:25.100 --> 00:23:29.330
um,
that's the labels.
And then we have

372
00:23:30.830 --> 00:23:35.180
our other line,
which is our horizontal line.
Oh,

373
00:23:35.181 --> 00:23:37.460
I'm going to name it the other line horizontal

374
00:23:39.320 --> 00:23:42.230
and we're going to have that,
that's for,
that's for y.

375
00:23:42.680 --> 00:23:45.020
And then count of missing values.
That's,

376
00:23:45.140 --> 00:23:49.670
we're looking for the count of missing values x label.
And one more,

377
00:23:49.671 --> 00:23:52.490
which is our title for our graph number of

378
00:23:54.170 --> 00:23:59.130
missing values in each column.
Okay.
That's it.
And show the plot.

379
00:23:59.990 --> 00:24:02.360
Okay.
Let's see.
Of course,

380
00:24:02.750 --> 00:24:05.510
invalid syntax to,
to,
to,

381
00:24:05.511 --> 00:24:08.960
to X.
Dot X.
Dot.
Set.

382
00:24:09.200 --> 00:24:14.200
Why ticks I n d plus with just like that?

383
00:24:14.590 --> 00:24:15.423
Uh Huh.

384
00:24:18.450 --> 00:24:22.320
I N D NP is not defined right?

385
00:24:23.280 --> 00:24:27.480
Is it really not defined?
I didn't important empire up there.
Okay,
fine.
Has an NP.

386
00:24:33.830 --> 00:24:36.020
Okay.
Six size,
right.

387
00:24:37.640 --> 00:24:41.480
So sometimes you just got to deal with these errors.

388
00:24:43.290 --> 00:24:44.490
Nice.
Okay.

389
00:24:44.491 --> 00:24:49.440
So it looks like we've got quite a lot of missing values and our data.
And so,

390
00:24:49.560 --> 00:24:52.560
you know,
if we,
we could,
we could just clean them all out,

391
00:24:52.561 --> 00:24:54.690
but this is a good step to wow.

392
00:24:54.691 --> 00:24:57.570
So fundamental 61 has a lot of missing values,

393
00:24:57.900 --> 00:25:00.520
so there's a lot of missing values in this data.
Okay.
So,
so that's,

394
00:25:00.870 --> 00:25:03.540
that's what we wanted to do was just to,
just to see that.

395
00:25:03.541 --> 00:25:06.250
And so let's just show one more pretty graph.
It's,
it's,

396
00:25:06.251 --> 00:25:08.180
it's a rainbow graph and we can use a,

397
00:25:08.190 --> 00:25:11.310
the other plotting library calls seaborne to,
to do this.

398
00:25:11.311 --> 00:25:16.050
It's just one more very simple graph.
And so we'll say,

399
00:25:16.980 --> 00:25:20.370
and I'll take questions.
Um,
right after number eight here.

400
00:25:20.610 --> 00:25:25.470
So six,
how many people do we have in here?
Okay.

401
00:25:25.710 --> 00:25:29.040
Two and 33.
Okay,
cool.
So

402
00:25:32.710 --> 00:25:33.730
that's it for this.

403
00:25:34.000 --> 00:25:39.000
So now we can see at each time step we want to see at each time step what the

404
00:25:39.011 --> 00:25:42.670
data looks like.
So we'll say

405
00:25:46.600 --> 00:25:51.600
how much of each a predictor variable do we have at each time step.

406
00:25:54.770 --> 00:25:57.470
Okay.
So now,
um,

407
00:25:58.360 --> 00:25:58.770
<v 1>okay,</v>

408
00:25:58.770 --> 00:26:03.450
<v 0>we can see that.
Cool.
Okay.
So that's the count for each versus the timestamps.</v>

409
00:26:03.560 --> 00:26:07.890
So there's more and more.
It's,
it's a,
it's going up.
Okay.
So it's going up.

410
00:26:07.891 --> 00:26:11.180
The trend of the data is going up.
So that's just one thing to know.
It's,

411
00:26:11.181 --> 00:26:15.600
it's a linear trend upwards as,
as,
as,
as,
as time goes on.

412
00:26:15.630 --> 00:26:19.200
Okay.
And so lastly,
we'll just one line of code and we're done with this,
uh,

413
00:26:19.201 --> 00:26:20.034
Eda Park.

414
00:26:22.290 --> 00:26:23.123
<v 1>Okay.</v>

415
00:26:23.330 --> 00:26:27.670
<v 0>Um,
how many unique assets do we have in total?
And that's</v>

416
00:26:30.480 --> 00:26:33.660
Prince,
the length of df.id.
Dot.
Unique

417
00:26:37.060 --> 00:26:38.530
1,424.
Okay,
so,

418
00:26:38.860 --> 00:26:43.410
so let's answer some questions and I'll talk about reinforcement learning.
Okay.

419
00:26:43.470 --> 00:26:48.470
Um,
okay,

420
00:26:48.471 --> 00:26:49.460
cool.
So

421
00:26:51.830 --> 00:26:55.760
can we use our n n with Lstm to predict the scenarios?
Yes,
you can,

422
00:26:55.761 --> 00:26:58.610
like I mentioned before and deep reinforcement learning is the,

423
00:26:58.611 --> 00:27:01.460
is the cutting edge for that too.
Um,

424
00:27:02.570 --> 00:27:04.010
why not use Phillip asks,

425
00:27:04.190 --> 00:27:08.510
why not use pandas data frame methods to call the columns instead of using
loops?

426
00:27:08.720 --> 00:27:13.250
Philip,
that's a totally valid question and we could have done that.
And lastly,

427
00:27:13.340 --> 00:27:16.740
uh,
one more question.
What is your opinion of no,
that's no.

428
00:27:21.190 --> 00:27:24.550
How deep do you need?
Do you need to know math for reinforcement learning?

429
00:27:24.880 --> 00:27:28.330
How deep do you need to know math for reinforcement learning?
Um,

430
00:27:28.880 --> 00:27:29.280
<v 1>okay,</v>

431
00:27:29.280 --> 00:27:30.210
<v 0>that's a great question.</v>

432
00:27:30.390 --> 00:27:34.350
I compared to supervised and unsupervised learning,

433
00:27:34.560 --> 00:27:39.560
it is more necessary to know the math behind it because that ecosystem is not as

434
00:27:40.831 --> 00:27:45.110
developed as a supervised learning,
um,
ecosystem.
And,
um,
while you,

435
00:27:45.180 --> 00:27:48.120
we can use open Ai's,
Jim,
could you a simple,
you know,

436
00:27:48.121 --> 00:27:52.650
random policy for an agent inside of a game if you want to do anything more

437
00:27:52.651 --> 00:27:56.820
complex.
Um,
deep Q.
If you really want to understand these algorithms,
then yes,

438
00:27:56.821 --> 00:27:58.560
you're going to need to know how,

439
00:27:58.620 --> 00:28:02.430
what the idea behind policy functions are and the idea behind value functions

440
00:28:02.431 --> 00:28:04.350
both for a state and an action.

441
00:28:04.680 --> 00:28:06.750
You're going to need to know how the bellman equation works.

442
00:28:06.751 --> 00:28:08.340
And that's really what it comes down to.

443
00:28:08.640 --> 00:28:12.120
Understand the bellman equation and everything else will follow.

444
00:28:12.180 --> 00:28:14.710
And then that that's,
and there,
there's four of them actually,

445
00:28:14.840 --> 00:28:18.810
and I will continue to talk about them,
but let's continue going here.
So,

446
00:28:19.620 --> 00:28:24.180
um,
that's it for my QA now to our l,
right?
So that's our eda now for our ELL.

447
00:28:24.390 --> 00:28:28.020
So,
um,
how do we use reinforcement learning in time series data?

448
00:28:28.050 --> 00:28:30.750
So in reinforcement learning,

449
00:28:30.930 --> 00:28:33.960
there is an agent that is acting on the outside world.

450
00:28:33.961 --> 00:28:37.350
It is observing the effects of the environment and it's learning how to improve

451
00:28:37.351 --> 00:28:41.850
it's behavior.
That's why we see it being used so often in games,
right?
So,

452
00:28:42.300 --> 00:28:46.060
but in contrast,
a time series forecast is,
is,

453
00:28:46.070 --> 00:28:48.270
is a setting where there is a passive observer.

454
00:28:48.330 --> 00:28:53.330
So the agent is passively observing the the Dataset and it's not really

455
00:28:54.211 --> 00:28:58.470
interacting with the environment because the environment is not reacting to the

456
00:28:58.471 --> 00:29:02.430
agent.
It is,
it is a one way.
Um,

457
00:29:02.580 --> 00:29:06.000
it is a one way action,
right?

458
00:29:06.390 --> 00:29:09.660
Whereas in a game world,
for example,
I Karch poll,
right?
Where the,

459
00:29:09.690 --> 00:29:11.970
where the pole is trying to balance itself,
right?

460
00:29:12.090 --> 00:29:15.750
If the agent's action in a given state is to move to the left than the

461
00:29:15.751 --> 00:29:19.950
environment,
the,
the,
the platform that it's balancing on,
we'll then move.

462
00:29:19.980 --> 00:29:23.550
It's reacting,
right?
So in a real world,
how do we use this?
Well,

463
00:29:23.880 --> 00:29:28.410
what is a system that adapts to changes that an agent,
an AI mix?

464
00:29:28.650 --> 00:29:33.390
Well,
the stock market could be one where a state,
uh,

465
00:29:33.391 --> 00:29:36.570
will change because the state is the account balance.

466
00:29:36.780 --> 00:29:40.080
If you have an account balance when you make,
when an agent makes an action,

467
00:29:40.200 --> 00:29:43.390
like buy,
sell,
hold,
the balance will change.

468
00:29:43.450 --> 00:29:46.510
Or if we want to get more Meta,
then the,

469
00:29:46.870 --> 00:29:50.560
the entire stock market will change.
So if an agent makes a trade,

470
00:29:50.830 --> 00:29:55.480
then the market will change,
right?
So we can,
that is a reactive environment.

471
00:29:55.481 --> 00:29:59.410
What's another reactive environment?
Electricity grids,

472
00:29:59.650 --> 00:30:04.480
sensor networks,
interconnected routing grids of,
of,
of,
of,
of data,
of,
of,

473
00:30:04.710 --> 00:30:05.620
of connections,
right?

474
00:30:05.620 --> 00:30:10.300
So any kind of system that adapts on adaptive system that,
that,

475
00:30:10.301 --> 00:30:15.250
that reacts to an agent interacting with that environment is a use case for

476
00:30:15.251 --> 00:30:16.450
reinforcement learning.

477
00:30:16.750 --> 00:30:21.160
So a static data set is not necessarily a reinforcement learning scenario.

478
00:30:21.490 --> 00:30:22.660
So how do we solve this though?

479
00:30:22.661 --> 00:30:26.320
Because there are a bunch of companies out there that have these systems like

480
00:30:26.321 --> 00:30:30.610
Google for example,
they used reinforcement learning to improve the,

481
00:30:31.590 --> 00:30:34.850
they,
they use it to improve the quality of their,
um,

482
00:30:35.620 --> 00:30:39.730
power usage and their giant data center.
And they reduced our cooling bit bill,

483
00:30:39.880 --> 00:30:42.520
but I think it was 40% and even more after that.

484
00:30:43.000 --> 00:30:45.370
So there are companies out there,
electricity companies,

485
00:30:45.371 --> 00:30:48.220
power utility companies as public works,

486
00:30:48.221 --> 00:30:53.020
companies that have these systems that need to be optimized,
but they don't,

487
00:30:53.140 --> 00:30:55.660
and they have these real time data sets,

488
00:30:55.661 --> 00:30:57.970
rights meters that are happening in real time.

489
00:30:58.360 --> 00:31:03.250
What they need then is a reinforcement learning solution.
But right now,

490
00:31:03.251 --> 00:31:06.330
and here's an here's a startup idea.
I want to get to you guys.
Um,

491
00:31:06.730 --> 00:31:08.710
this stream is going up and down.

492
00:31:08.711 --> 00:31:10.990
Like there were 200 people here and now there's 600 people here.

493
00:31:10.991 --> 00:31:15.570
This is crazy by the way.
So,
um,
so where was I?
So,
um,

494
00:31:16.030 --> 00:31:20.350
this is a call to action for startups.
Okay.
Because I see a real need here,
here.

495
00:31:20.351 --> 00:31:24.970
Here's a pain point where there are companies that need a reinforcement learning

496
00:31:24.971 --> 00:31:29.971
solution to help optimize their profits for their systems and their data

497
00:31:30.011 --> 00:31:34.600
scientists out there that want to use reinforcement learning to then solve these

498
00:31:34.601 --> 00:31:38.800
systems.
So what there needs to be is an intermediary that is,

499
00:31:38.801 --> 00:31:41.410
that offers a simulation as a service.

500
00:31:41.860 --> 00:31:45.610
And so what these simulation as a service companies do or startups will do is

501
00:31:45.611 --> 00:31:47.920
they'll go,
they'll approach,
and here's how I would do it.

502
00:31:47.920 --> 00:31:51.310
I would approach one of these companies and say,
you know,
I,
you know,

503
00:31:51.311 --> 00:31:53.680
I understand reinforcement learning.
I understand that,
you know,

504
00:31:53.710 --> 00:31:58.330
we can offer you a 30% reduction in your costs if you give us access to your

505
00:31:58.331 --> 00:32:03.130
real time Api.
And we'll create a simulated environment based on that.

506
00:32:03.490 --> 00:32:08.380
And then we will give it to say Kaggle two to then allow their data scientists

507
00:32:08.381 --> 00:32:13.300
to create our El Algorithms.
And so there is an intermediary step here.

508
00:32:13.301 --> 00:32:13.510
Now,

509
00:32:13.510 --> 00:32:17.980
now Kaggle can do this themselves and they have thought about this and who knows

510
00:32:17.981 --> 00:32:20.530
what's gonna happen there.
But this is an idea that,
that,

511
00:32:20.560 --> 00:32:23.980
that's time has come and more and more people are getting interested in

512
00:32:23.981 --> 00:32:27.640
reinforcement learning and there needs to be more simulated real world,

513
00:32:27.670 --> 00:32:31.750
not game world environments out there.
So that's my suggestion.

514
00:32:31.990 --> 00:32:34.540
And so hopefully you understand the difference here between time series

515
00:32:34.541 --> 00:32:39.010
forecasting and reinforcement learning.
Um,
from,
from,
from what I've said so far,

516
00:32:39.470 --> 00:32:43.740
why there's a need for it and how we can apply reinforcement learning to time

517
00:32:43.741 --> 00:32:48.680
series.
If there is some reactive component to the dataset itself,

518
00:32:48.681 --> 00:32:53.510
it can just be a static data set.
It has to be a real time API.
Okay.

519
00:32:53.570 --> 00:32:56.510
So,
so there is a possibility that we're going to see more of that in the future.

520
00:32:56.810 --> 00:33:01.640
Now,
um,
what I did find though,

521
00:33:01.641 --> 00:33:06.530
what I did find was a library.
So the closest thing on Kaggle to,

522
00:33:06.560 --> 00:33:07.393
um,

523
00:33:07.550 --> 00:33:12.550
to this idea of reinforcement learning was created by this guy and it's called

524
00:33:12.741 --> 00:33:16.400
the Kaggle Gym.
So what he did was he framed,

525
00:33:16.640 --> 00:33:21.230
he framed the reinforcement learning problem.
He framed the,

526
00:33:21.290 --> 00:33:23.360
not the reinforcement learning.
He framed the,

527
00:33:23.390 --> 00:33:26.120
the two sigma problem of predicting the,

528
00:33:26.121 --> 00:33:31.121
the target variable as a reinforcement learning problem as a mark decision

529
00:33:31.791 --> 00:33:32.624
process.

530
00:33:32.900 --> 00:33:37.730
And what I think this was the pioneering step in saying,

531
00:33:38.210 --> 00:33:43.210
let's create a simulation of a dataset and then solve the datasets,

532
00:33:43.720 --> 00:33:48.260
um,
and then solve the Dataset in the context of a simulated setting.

533
00:33:48.620 --> 00:33:52.730
Right?
And so he created this library called Kaggle Gym,
um,
which,

534
00:33:52.760 --> 00:33:53.720
which takes that library.

535
00:33:53.721 --> 00:33:58.190
And what I've done is I've pasted in this library here and we're going to talk

536
00:33:58.191 --> 00:33:59.510
about it and then we're going to use it.

537
00:33:59.540 --> 00:34:03.620
So we're going to use that capital gym library to solve this problem.
Okay.
So,
um,

538
00:34:03.650 --> 00:34:06.650
so little refresher here.
So in reinforcement learning,

539
00:34:06.770 --> 00:34:10.670
we have a mark Haub decision process where we have an agent.

540
00:34:10.730 --> 00:34:14.900
It performs a set of actions in a given state to,
to maximize reward.

541
00:34:15.200 --> 00:34:19.340
And the action that it takes given a state is considered the policy.

542
00:34:19.490 --> 00:34:22.910
So policy suggests it's a function that says,
that says,

543
00:34:22.940 --> 00:34:26.630
given this state and given this action,
oh no,
given this state,

544
00:34:26.690 --> 00:34:30.350
what's the best action to take?
Okay?
That's how policy works.

545
00:34:31.550 --> 00:34:36.450
And so,
um,
there's two other,
uh,

546
00:34:36.470 --> 00:34:38.990
functions here that are part of a mark of decision process.

547
00:34:38.990 --> 00:34:43.340
The transition probability that says,
what is the next likely states to go in?

548
00:34:43.341 --> 00:34:47.630
If you take an action in this given states and a reward function that's going to

549
00:34:48.170 --> 00:34:48.980
help you Max,

550
00:34:48.980 --> 00:34:52.850
help the agent maximize what we're awarded receives for taking a given action.

551
00:34:53.120 --> 00:34:56.810
Now this can be learned over time and that would be considered cue learning.

552
00:34:56.900 --> 00:34:58.580
That would be considered a model free method.

553
00:34:58.581 --> 00:35:01.010
These two functions could be learned over time,

554
00:35:01.160 --> 00:35:03.860
or they can be given to us beforehand,

555
00:35:04.040 --> 00:35:07.670
in which case this would be a complete Markov decision process.

556
00:35:07.820 --> 00:35:09.350
But in the real world,

557
00:35:09.410 --> 00:35:13.100
we will never almost never have a complete mark off decision process.

558
00:35:13.280 --> 00:35:18.050
We will almost always have a partially observable mark Haub decision process.

559
00:35:18.380 --> 00:35:21.950
What that means is that we won't have these transition probabilities,

560
00:35:22.040 --> 00:35:26.120
we won't have this reward function will have to learn them or we could just

561
00:35:26.121 --> 00:35:30.260
avoid those functions and learn what's called the Q function directly.

562
00:35:30.440 --> 00:35:32.600
Let me talk about that at the end.
Okay.

563
00:35:32.601 --> 00:35:37.200
I just wanted to introduce the idea of a mark of decision process before we get

564
00:35:37.210 --> 00:35:38.043
into this code.

565
00:35:38.820 --> 00:35:43.820
So in this Kaggle gym environment that frons a sloth who births a suggested we

566
00:35:47.281 --> 00:35:51.330
have an r score.
So what,
so what Kaggle suggested was that,

567
00:35:53.790 --> 00:35:54.623
<v 1>okay,</v>

568
00:35:55.040 --> 00:35:58.830
<v 0>what Kaggle suggested,
let me just go back.</v>

569
00:36:00.060 --> 00:36:02.040
Was that the data,

570
00:36:02.760 --> 00:36:05.670
we evaluate the scores using this equation right here.
Okay,

571
00:36:05.671 --> 00:36:10.110
let me make this bigger.
This is called the or score.

572
00:36:10.380 --> 00:36:14.610
So the,
our score is one minus the,
the um,

573
00:36:14.910 --> 00:36:17.220
the difference between the target and the

574
00:36:18.090 --> 00:36:18.520
<v 1>okay.</v>

575
00:36:18.520 --> 00:36:22.950
<v 0>And the predictive variable squared,
the sum of all of them divided by,
uh,</v>

576
00:36:23.110 --> 00:36:26.650
the predictive variable minus,
um,

577
00:36:28.710 --> 00:36:31.740
what was you again,
this constant value you,
it's not called you,

578
00:36:31.950 --> 00:36:34.700
it's called forgetting the name of it,
but the,

579
00:36:34.770 --> 00:36:37.200
this constant value and one minus that and that's r squared.

580
00:36:37.530 --> 00:36:42.090
And then we can derive our from our squared by saying or equals sine of r

581
00:36:42.091 --> 00:36:46.800
squared times the square root of the absolute value of r squared.

582
00:36:46.890 --> 00:36:47.880
And that's going to give us our,

583
00:36:47.970 --> 00:36:51.330
and that's going to be are we can consider that a loss function because it's

584
00:36:51.331 --> 00:36:54.960
going to give us one scalar value.
It's gonna give us a scalar value,

585
00:36:55.170 --> 00:37:00.090
which we can use to measure how good our,
um,
our predictive variable is,

586
00:37:00.220 --> 00:37:04.140
our predicted target is.
And then based on that or score,

587
00:37:04.141 --> 00:37:06.720
we can see what the leaderboard says and then you know,

588
00:37:06.721 --> 00:37:10.920
we can see what everybody's,
our scoring is here.
So the highest one was 0.02.

589
00:37:11.250 --> 00:37:14.790
So we'll see what we can get using this Taggle gym library that was created

590
00:37:14.791 --> 00:37:18.150
before.
So let me answer any other questions.

591
00:37:19.910 --> 00:37:22.490
Mu Yes.
Thank you very much.
Moo,
moo.
Alpha Theta.

592
00:37:22.520 --> 00:37:27.020
I was in Mu Alpha Theta in high school.
How can I forget?
Move.
Okay.

593
00:37:27.230 --> 00:37:30.470
How does start the basics?
Move 37 is my course.
It's all on Youtube for free.

594
00:37:30.471 --> 00:37:35.460
Check it out.
Um,
right me.
You all right.

595
00:37:35.660 --> 00:37:40.010
Great guys.
Thank you.
Okay,
so,
um,
so what is this,
what,
let me start off with this.

596
00:37:40.190 --> 00:37:41.150
The or score.

597
00:37:41.180 --> 00:37:44.300
This function is just the programmatic version of the equation that I just

598
00:37:44.301 --> 00:37:47.810
showed and uh,
that's it.
So that's what we're going to compute it.
So let me,

599
00:37:47.811 --> 00:37:50.930
let me go through this.
So inside of this gym,

600
00:37:51.890 --> 00:37:55.220
this Kaggle gym environment,
we have an observation.

601
00:37:55.490 --> 00:37:59.510
And so what the observation is,
is it is our,
uh,
training.

602
00:37:59.930 --> 00:38:04.310
It is our,
it is our predictive variable.
What we want to predict and our,

603
00:38:04.460 --> 00:38:08.690
it is our,
it is the variable that we are predicting.

604
00:38:08.690 --> 00:38:11.840
So the predictive variable and the target variable,
what is already there,

605
00:38:11.841 --> 00:38:15.380
because we already have those targets or labels,
we can call them labels,
right?

606
00:38:15.620 --> 00:38:19.250
So labels,
man,
I'm sweating today.
Yes.
Okay.

607
00:38:19.700 --> 00:38:22.850
We can call them labels.
So inside of our environment.

608
00:38:22.880 --> 00:38:26.000
So inside of this environment and in our environment,
what is it?

609
00:38:26.180 --> 00:38:28.430
Our environment is art static data set.

610
00:38:29.780 --> 00:38:32.960
We'll split it up into training and testing data.
Okay.

611
00:38:33.320 --> 00:38:35.000
And then here's the step.

612
00:38:35.320 --> 00:38:38.750
So this is basically recreating that open AI gym environment or,

613
00:38:38.890 --> 00:38:41.200
or an agent takes it,
take us,
it takes a step.

614
00:38:41.290 --> 00:38:43.930
The perimeter is the action that it takes and then it works.

615
00:38:43.931 --> 00:38:45.430
He's an observation and a reward.

616
00:38:45.700 --> 00:38:49.000
So in this very naive implementation,

617
00:38:50.530 --> 00:38:51.820
how it's computed,

618
00:38:51.821 --> 00:38:56.821
how the or score is computed is just by saying that the predictive variable is

619
00:38:58.091 --> 00:39:00.910
only going to be the variable from the previous time step.

620
00:39:01.170 --> 00:39:03.280
We could do that actually.
I mean we could,

621
00:39:03.281 --> 00:39:07.930
we could choose our own policy based on this,
but but what inside of this alone,

622
00:39:07.960 --> 00:39:12.420
all it's saying is this is really the,
the the key right here.
Like this,

623
00:39:12.421 --> 00:39:13.254
this part right here,

624
00:39:13.540 --> 00:39:17.380
the reward for taking a step in this environment is going to be the,

625
00:39:17.590 --> 00:39:22.240
our score of our predictive variable and our target.
Okay.
That's our reward.

626
00:39:22.241 --> 00:39:24.910
And we returned that as well as an observation,

627
00:39:24.911 --> 00:39:29.140
which is going to be the values of both as we saw before.
And,
um,

628
00:39:29.200 --> 00:39:33.190
a boolean this has done or not.
And then info,
which is a logging,
um,
variable,

629
00:39:33.220 --> 00:39:37.240
right?
So,
so based on that,
we can create a policy.
So,
so let's,

630
00:39:37.270 --> 00:39:39.310
let's write one using this,
this variable.

631
00:39:39.490 --> 00:39:41.470
And the reason I pasted it all is because this,

632
00:39:41.471 --> 00:39:45.190
this could be its own python file,
right?
Taggle Jim.
Dot Pie.
Okay.

633
00:39:45.191 --> 00:39:47.860
So let's,
let's test this out.

634
00:39:47.861 --> 00:39:50.680
So we'll say let's create our own agent environment loop.

635
00:39:50.830 --> 00:39:55.690
We'll define our own policy and then based on that,
we'll,
um,

636
00:39:57.470 --> 00:40:00.500
we'll keep,
we'll,
we'll try to improve it.
Okay.
So

637
00:40:03.930 --> 00:40:05.580
inside of this test function will say,

638
00:40:05.760 --> 00:40:07.830
go ahead and create the environment using make,

639
00:40:07.831 --> 00:40:11.640
which is the function that I just defined.
Get the initial observation,

640
00:40:11.641 --> 00:40:15.030
which is going to be our variables that we defined before.

641
00:40:15.360 --> 00:40:18.570
We'll print them out so we can see them,
you know,
just for logging purposes,

642
00:40:18.571 --> 00:40:19.020
you know,

643
00:40:19.020 --> 00:40:24.020
what is the observation of both the target and of the,

644
00:40:25.620 --> 00:40:29.910
the um,
the training data or the,
the,
the predicted,

645
00:40:30.300 --> 00:40:33.990
the predicted value.
And then based on both of those,

646
00:40:37.590 --> 00:40:42.360
we'll create our training loop.
Okay.
So this is the agent environment loop.

647
00:40:42.570 --> 00:40:47.460
Okay.
Based on that.
So what we'll say is wild,

648
00:40:47.461 --> 00:40:49.380
true.
Here's the loop begins.

649
00:40:49.770 --> 00:40:53.220
But target value is going to be the initial observation.

650
00:40:56.050 --> 00:40:57.550
<v 1>And then,
um,</v>

651
00:40:58.620 --> 00:41:02.680
<v 0>we'll choose some starting point to just start from,
um,</v>

652
00:41:02.760 --> 00:41:05.640
like what is the predictor variable that we want to start from and we'll just

653
00:41:05.641 --> 00:41:07.140
say,
um,

654
00:41:11.510 --> 00:41:13.520
6.06.

655
00:41:13.940 --> 00:41:15.330
<v 1>And then,
um,</v>

656
00:41:16.660 --> 00:41:19.690
<v 0>observation was,
so what are we going to get return when we take a step?</v>

657
00:41:19.840 --> 00:41:22.730
I'll continue to explain this guys,
let me just write this out.
I'm,

658
00:41:22.800 --> 00:41:27.070
I'm not done explaining this is going to,
so it's going to return.

659
00:41:27.071 --> 00:41:28.870
So this is the class that we just talked about.

660
00:41:29.080 --> 00:41:32.770
It's going to return all three of these things based on the action,

661
00:41:32.771 --> 00:41:36.680
which is the target we take.
And if we're done break,

662
00:41:36.710 --> 00:41:40.160
we're done with the loop else.
Now what do we do with the rewards,
right?

663
00:41:40.161 --> 00:41:45.161
So we can choose any policy and here is where we actually show what that policy

664
00:41:45.441 --> 00:41:46.274
is going to be.

665
00:41:47.600 --> 00:41:52.600
And so what I'm going to do and as you're seeing right now is I'm going to print

666
00:41:53.841 --> 00:41:57.920
out three variables and then I'm done.
So I'm going to print out the info.

667
00:41:58.070 --> 00:42:02.510
I'm going to print out the,
the amount of rewards I'm going to print out

668
00:42:04.910 --> 00:42:09.470
the first few rewards,
zero through 15 okay.
So that's that

669
00:42:11.570 --> 00:42:14.570
invalid syntax for make.
Oh right.
Environment

670
00:42:15.480 --> 00:42:16.350
<v 2>equals make.</v>

671
00:42:19.370 --> 00:42:21.110
<v 0>Okay.
And then I'll test it out.</v>

672
00:42:21.140 --> 00:42:24.560
All I do is just run test and that's going to give us

673
00:42:27.480 --> 00:42:31.170
<v 2>what
environment's not defined.</v>

674
00:42:32.210 --> 00:42:36.480
Did it really?
No it is,
it is.
Check this out.

675
00:42:37.680 --> 00:42:42.480
Right?
Right.
And then,

676
00:42:43.980 --> 00:42:44.813
Yup.

677
00:42:49.200 --> 00:42:51.280
<v 0>Oh okay.
I'll surveys shins.</v>

678
00:42:51.300 --> 00:42:54.690
Not defined line nine ops or

679
00:42:56.510 --> 00:42:57.470
<v 2>vacation</v>

680
00:43:04.110 --> 00:43:06.780
<v 0>rewards is not defined.
Rewards out of pen.</v>

681
00:43:09.480 --> 00:43:10.380
Oh,
rewards.

682
00:43:15.020 --> 00:43:15.853
<v 1>Yeah.</v>

683
00:43:17.420 --> 00:43:18.253
<v 2>Okay.</v>

684
00:43:20.580 --> 00:43:22.920
<v 0>Okay.
Let me answer some questions now cause we're definitely gonna have some</v>

685
00:43:22.921 --> 00:43:27.300
questions here.
Okay.

686
00:43:31.940 --> 00:43:32.780
Oh,
break.

687
00:43:33.200 --> 00:43:37.010
<v 2>How did this not catch it?
Okay.
Gotcha.
Okay.
Let me answer some questions here.</v>

688
00:43:39.200 --> 00:43:40.033
Thank you.

689
00:43:41.710 --> 00:43:42.543
<v 0>MMM.</v>

690
00:43:50.560 --> 00:43:52.390
Let's see what we get here.
Okay.

691
00:43:52.391 --> 00:43:57.250
So our public score is going to be 0.017 so compare it to,

692
00:43:59.100 --> 00:44:03.540
so we're like number 43 and guess what this,
okay,
so,
so,
so guess what,

693
00:44:03.560 --> 00:44:06.780
so here's our policy,
right?
Here's our policy right here.

694
00:44:07.890 --> 00:44:10.620
All we're saying this is the naive method,

695
00:44:10.650 --> 00:44:14.760
but in the context of a Mark Cobb decision process,
this is,
that's it.
The,
the,

696
00:44:14.761 --> 00:44:18.600
the basic idea here is that we framed this as a mark Haub decision process where

697
00:44:18.601 --> 00:44:21.460
an agent is taking action in an environment,
uh,

698
00:44:21.690 --> 00:44:25.290
to move from one state to the next state.
And we're trying to maximize reward.

699
00:44:25.500 --> 00:44:30.260
And the policy to choose that action is going to be the predict.
The,

700
00:44:30.270 --> 00:44:34.770
the variable that want to predict is going to be the variable from the last time

701
00:44:34.771 --> 00:44:38.370
step.
And then to compute the how good it is,

702
00:44:38.550 --> 00:44:41.460
we're just going to find the difference between the predicted and the actual

703
00:44:41.461 --> 00:44:45.690
variable.
So it's going to be the variable in t minus one and.
T.

704
00:44:45.900 --> 00:44:49.050
That's it.
We could have done this in one line of code.
However,

705
00:44:49.260 --> 00:44:52.200
in the context of a mark of decision process which we have here,

706
00:44:52.500 --> 00:44:56.850
we can then add to it by creating another policy by creating a better policy

707
00:44:57.000 --> 00:45:00.990
that's going to improve on this.
It's like what would be an example to learning?

708
00:45:01.260 --> 00:45:06.090
Okay,
so Q learning where an agent is taking an action,

709
00:45:06.091 --> 00:45:09.300
given a state in order to maximize a reward.

710
00:45:09.690 --> 00:45:14.490
And we are computing this Q table,
which is um,
a bunch of,
it's a,

711
00:45:14.491 --> 00:45:19.491
it's a giant matrix of possible actions that we can take in any given state.

712
00:45:19.740 --> 00:45:23.400
And then we're going to optimally choose what those actions will be by

713
00:45:23.430 --> 00:45:27.630
iteratively updating the Q table using what's called the bellman equation.

714
00:45:27.780 --> 00:45:32.460
And with a bellman equation does is it relates one state to another.

715
00:45:32.670 --> 00:45:37.590
And if we can relate any one state in an environment to another state,

716
00:45:37.770 --> 00:45:41.940
then we can compute those variables that are different between them,
right?

717
00:45:42.000 --> 00:45:46.620
Like the state,
the state,
the state value function,
and the action value function.

718
00:45:46.890 --> 00:45:49.380
And using those,
we can compute an optimal policy.

719
00:45:50.340 --> 00:45:53.850
So that's how we could improve on this.
However,
like I said before,

720
00:45:53.880 --> 00:45:56.100
we need an environment that's going to be reactive.

721
00:45:56.130 --> 00:45:59.370
And this is also just a show that you don't necessarily have to have the

722
00:45:59.371 --> 00:46:03.860
greatest,
you know,
cutting edge algorithm in the world to place well,
um,

723
00:46:03.930 --> 00:46:08.400
on to,
on a,
on a challenge or to do well in general,

724
00:46:08.430 --> 00:46:09.091
in machine learning.

725
00:46:09.091 --> 00:46:13.020
Sometimes linear regression can work better than a deep neural network if your

726
00:46:13.021 --> 00:46:17.880
data set is small or,
or,
or,
um,
you know,
for,
for a variety of reasons.

727
00:46:18.840 --> 00:46:21.430
So my point is that,
um,

728
00:46:21.690 --> 00:46:24.630
so we placed using this very simple methodology.

729
00:46:24.930 --> 00:46:27.150
Obviously it's a very naive method,

730
00:46:27.360 --> 00:46:32.360
but I wanted to really sneak in a lecture on reinforcement learning on cue,

731
00:46:32.551 --> 00:46:36.900
learning on the difference between time series forecasting and reinforcement

732
00:46:36.901 --> 00:46:41.570
learning into this problem of this capital challenge.
And,
and this was the,

733
00:46:41.571 --> 00:46:42.404
the most,

734
00:46:42.630 --> 00:46:47.220
this specific challenge was the most RL friendly challenge that's available on

735
00:46:47.221 --> 00:46:50.370
Kaggle right now.
And like I said,
this is a great example.

736
00:46:50.400 --> 00:46:55.400
This is a great opportunity for aspiring data scientists out there to create a

737
00:46:55.471 --> 00:47:00.210
service that creates simulated environments that can be offered to real world

738
00:47:00.211 --> 00:47:04.510
companies.
And,
you know,
just to create a business out of that.
Um,

739
00:47:04.550 --> 00:47:07.980
so I see a real need for that and that that could be a use case for this.

740
00:47:09.030 --> 00:47:12.180
I'll answer two more questions.
Um,
Qa or have,

741
00:47:12.210 --> 00:47:15.420
I actually have a great cue learning video coming out this weekend.

742
00:47:15.570 --> 00:47:17.610
I'm going to have some great links for you in the video description,

743
00:47:17.720 --> 00:47:20.340
the data sets in the video description and uh,

744
00:47:21.480 --> 00:47:25.580
let me do a wrap.
So just say,
uh,
just say,
uh,

745
00:47:26.400 --> 00:47:29.070
just say I'm a topic,

746
00:47:29.150 --> 00:47:32.660
I'll do a freestyle rap on the topic before I end this live stream before it

747
00:47:32.720 --> 00:47:34.910
ended.
Okay.
So

748
00:47:36.970 --> 00:47:38.150
it'll beat

749
00:47:40.000 --> 00:47:44.800
my favorite pie company is school of Ai and we're actually a nonprofit

750
00:47:44.801 --> 00:47:48.160
organization and it is the adventure of a lifetime.
And it is,

751
00:47:48.430 --> 00:47:51.940
it is a story that's going to be told,
um,
decades from now.

752
00:47:51.970 --> 00:47:53.860
And it's not even about me,
it's about the deans.

753
00:47:53.861 --> 00:47:57.810
It's about the people running this.
Um,
yeah.
Really it's,
it's,

754
00:47:57.830 --> 00:48:01.150
it's a family on the students,
the wizards.
We're all a family.

755
00:48:01.151 --> 00:48:03.550
The people watching this.
We are all a family.

756
00:48:03.551 --> 00:48:05.440
If you were here at the end of this live stream,

757
00:48:05.620 --> 00:48:09.400
you are a dedicated data data scientists who cares about,

758
00:48:09.401 --> 00:48:13.720
or AI researcher who cares about the future of AI and using it to solve real

759
00:48:13.721 --> 00:48:17.580
world problems.
And that's our mission.
Those are our values.
Okay,
so um,

760
00:48:19.870 --> 00:48:23.780
open Ai.
Okay.
No,
no,
I want to do different one chat Bot.

761
00:48:26.310 --> 00:48:27.143
<v 1>Okay.</v>

762
00:48:28.740 --> 00:48:29.450
<v 3>Yeah.</v>

763
00:48:29.450 --> 00:48:32.090
<v 0>Okay.
Here we go.
This is,</v>

764
00:48:33.330 --> 00:48:34.950
there's always a little tag at the beginning.

765
00:48:40.910 --> 00:48:42.440
I try to use a chat bot.

766
00:48:42.470 --> 00:48:46.670
I try to make map plot lied plotted out with the graph.

767
00:48:46.910 --> 00:48:50.780
But you can't because it's text data,
man.
You gotta use math.

768
00:48:50.930 --> 00:48:53.180
I don't know what you're using,
man.
You're out of class.

769
00:48:53.410 --> 00:48:57.380
You've got to take a chat Bot and visualize it in a way that people can't

770
00:48:57.470 --> 00:49:01.790
realize it.
It's okay.
Let me show you instead of not clot lab,

771
00:49:01.791 --> 00:49:06.770
let's do something else.
Like I call it map plot.
Jai.
It's a new library.

772
00:49:06.890 --> 00:49:10.880
I just invented it.
It's made for chat bots.
The visualize in the browser.

773
00:49:11.060 --> 00:49:15.470
It's like a laptop.
It runs on any browser in the cloud,
Gpu,

774
00:49:15.471 --> 00:49:20.460
CPU,
CPU.
I don't care.
That's it.
That's it for you.
All right.
That's it.
All right.

775
00:49:20.480 --> 00:49:22.580
That's it for the rap.
Our thank you guys for showing up.

776
00:49:22.610 --> 00:49:23.910
I hope I made this joyful for you.

777
00:49:23.910 --> 00:49:28.910
Time series forecasting or l Mark Haub decision processes and the accessibility

778
00:49:29.041 --> 00:49:33.150
of Kaggle as a way to earn a passive income.
And,
and,

779
00:49:33.160 --> 00:49:35.340
and in a way to hone your skills as a data scientist.

780
00:49:35.520 --> 00:49:38.100
These are all the things that I hope you've learned in this livestream.

781
00:49:38.340 --> 00:49:41.430
I love you guys.
Um,
we're about to hit 500,000 subscribers,

782
00:49:41.431 --> 00:49:42.840
so I can't wait until all your friends,

783
00:49:42.990 --> 00:49:46.110
we want to grow this community as fast as possible.
Uh,
so thank you guys.

784
00:49:46.111 --> 00:49:48.150
I love you and thanks for watching.
For now.

785
00:49:48.151 --> 00:49:53.130
I've got to go work on school of AI stuff.
So yeah,
thanks for watching.

786
00:49:53.830 --> 00:49:53.890
<v 1>Okay.</v>

