WEBVTT

1
00:00:00.030 --> 00:00:01.530
Hello world,
it's a Raj.

2
00:00:01.531 --> 00:00:05.790
And today we're going to learn how to deploy a karass model to production.

3
00:00:06.120 --> 00:00:07.590
And the APP that we're going to build,

4
00:00:07.591 --> 00:00:11.190
this specific app is going to be able to detect any handwritten character that

5
00:00:11.191 --> 00:00:13.080
you draw in the browser.
It's just,

6
00:00:13.230 --> 00:00:16.470
it's just going to be able to tell what that is.
So let me write out a two.

7
00:00:17.100 --> 00:00:19.710
This is a debt.
This is the demo right here.
I hit predict.

8
00:00:19.980 --> 00:00:24.140
So to let me clear that.
Okay,
how about a three,
Scott?

9
00:00:24.480 --> 00:00:28.110
A three.
Okay,
let's try something else.
How about a nine?

10
00:00:30.060 --> 00:00:33.930
That's a seven because that was badly drawn.
And then one more.

11
00:00:33.931 --> 00:00:38.670
How about a zero,
a zero or a six?
Zero.
Cool.

12
00:00:38.790 --> 00:00:43.530
Okay,
so that's what we're going to do and we've got four steps here.

13
00:00:43.560 --> 00:00:46.000
Okay.
So the first step is the trainer model in care off.

14
00:00:46.000 --> 00:00:49.550
So we're going to train our model,
simple and t,
Henry and [inaudible].

15
00:00:49.590 --> 00:00:52.380
It's all over the Internet.
That's not really the value add here.
The value add,

16
00:00:52.381 --> 00:00:54.990
it's going to be us writing our flask backend.

17
00:00:55.020 --> 00:00:57.660
So we're going to glaze over this chaos model,
this m and ist,

18
00:00:57.840 --> 00:00:59.190
and then we're going to get to the real meat of it,

19
00:00:59.280 --> 00:01:02.010
which is writing out a flask web app to serve it.

20
00:01:02.220 --> 00:01:05.040
So our first step is going to be a trainer model and Cara Ross.

21
00:01:05.280 --> 00:01:07.050
And then our next step is going to be a save it.

22
00:01:07.490 --> 00:01:10.260
Then our third step is going to be to write our flask backend,

23
00:01:10.290 --> 00:01:14.460
which is a python web app framework.
It's a very,
it's a,
it's a very small,
thin,

24
00:01:14.640 --> 00:01:17.540
very thin weight,
a micro framework for,

25
00:01:17.541 --> 00:01:22.140
for serving data in the browser.
It using a python backend for requests,
you know,

26
00:01:22.141 --> 00:01:24.600
get posts set,
um,
to serve on.

27
00:01:24.660 --> 00:01:27.720
So we're going to use it to serve our saved care os model.
Okay.

28
00:01:27.721 --> 00:01:28.650
And then once we're done,

29
00:01:28.651 --> 00:01:30.570
it's going to be running locally just like it is right now.

30
00:01:30.600 --> 00:01:34.140
Like it is on local host on port eight,
eight,
eight,
eight.

31
00:01:34.470 --> 00:01:38.160
And then we're going to deploy this code to Google cloud and that means anyone

32
00:01:38.161 --> 00:01:38.994
can use it.

33
00:01:39.030 --> 00:01:44.030
So I already made a video on how to deploy our tensorflow model to production,

34
00:01:44.131 --> 00:01:47.070
right.
Using tensorflow serving.
And that's where like,
you know,

35
00:01:47.090 --> 00:01:50.310
high grade production quality,
you know,
millions of people are using it.

36
00:01:50.400 --> 00:01:53.100
It's what Google uses.
That's when you want to use tensorflow survey.

37
00:01:53.430 --> 00:01:58.200
So you could use carrots with tensorflow serving as well.
In fact,
Francoise show,

38
00:01:58.201 --> 00:01:59.850
let Schwab Chalet,

39
00:02:00.120 --> 00:02:02.730
I kind of work on my French and Dutch now that I'm here in Europe.

40
00:02:02.880 --> 00:02:05.670
We might get interrupted by an angry Dutch lady,
but it's all good.

41
00:02:05.670 --> 00:02:09.780
The show must go on.
She's next door.
Okay.
Uh,
where was I?
Yeah,

42
00:02:09.781 --> 00:02:14.570
so we have to,
we could use tensorflow serving if we wanted to.
Um,
but you know,

43
00:02:14.600 --> 00:02:17.330
save it with carrots and then use tensorflow serving cause you,
it's,

44
00:02:17.490 --> 00:02:20.970
you would build a model of care ROSC save it as a tensorflow file and serve it

45
00:02:20.971 --> 00:02:25.380
with tensorflow serving.
But the easiest way,
the absolute bare bones,

46
00:02:25.440 --> 00:02:27.870
easiest way to take a train model,

47
00:02:27.970 --> 00:02:31.770
deploy it to a web app and then share it with your friends is using this.
Okay.

48
00:02:31.771 --> 00:02:34.140
This is the easiest way that I've found that I've been trying out a bunch of

49
00:02:34.141 --> 00:02:37.890
different ways.
So if you have a model and you just want to show people,
right,

50
00:02:38.040 --> 00:02:41.760
this is the way to do that.
If you have a model and you want to not,

51
00:02:41.790 --> 00:02:44.880
not just show people as a demo because it's easy to access in the browser,

52
00:02:44.970 --> 00:02:47.590
but you want to actually build a business around it,
tension,

53
00:02:47.610 --> 00:02:50.640
float serving as the way that also applies to this.
Right?

54
00:02:50.730 --> 00:02:52.170
And we'll talk about how it applies.

55
00:02:53.160 --> 00:02:57.600
What I mean by applies as we would still deploy our code to Google cloud and we

56
00:02:57.601 --> 00:03:00.940
would still,
uh,
train a model with chaos,
right?

57
00:03:01.120 --> 00:03:03.670
The only difference is for the back end,
we wouldn't use flask.

58
00:03:03.760 --> 00:03:07.760
We would use tensorflow survey.
Okay.
So this is for that,
you know,

59
00:03:07.810 --> 00:03:09.700
easily getting it into the browser basically.
That's,

60
00:03:09.760 --> 00:03:13.840
that's what I'm trying to say.
Okay.
So where was that?
Let's,
let's,
let's get,

61
00:03:13.841 --> 00:03:17.050
sorry.
Right.
So first I'm gonna explain what we're,
what's going on here,

62
00:03:17.051 --> 00:03:21.010
like what this is,
and then we'll get into the,
to the code part.
Okay.
So,

63
00:03:22.450 --> 00:03:24.430
okay,
so what is our stack look like or,

64
00:03:24.450 --> 00:03:26.660
so we're going to use carrots with a tensorflow backend.

65
00:03:26.680 --> 00:03:31.060
So carrots where the attentional backend to train a very simple eight layer

66
00:03:31.061 --> 00:03:34.540
convolutional network to recognize handwritten character digits,
right?

67
00:03:34.600 --> 00:03:37.960
So zero through nine are these images and then they all have a label,
you know,

68
00:03:37.961 --> 00:03:40.870
zero one,
two,
three,
four.
And our job,
our,

69
00:03:41.050 --> 00:03:44.830
our CNNS job is to learn the mapping between the two,
right?
Pattern recognition,

70
00:03:45.130 --> 00:03:48.010
very tried and true model.
Everyone knows about it,
but here's the,

71
00:03:48.011 --> 00:03:48.844
here's the cool part.

72
00:03:48.970 --> 00:03:52.510
We're going to use flask as our backend to serve these pretrained models.

73
00:03:52.511 --> 00:03:53.950
So we're going to train it locally,

74
00:03:54.090 --> 00:03:57.760
it's gonna and then we're going to save the model as a weight file and then

75
00:03:57.761 --> 00:04:01.180
we're going to serve it with flask.
You could also use node,
right?

76
00:04:01.181 --> 00:04:04.240
You could use any number of jazz web frameworks.
There's like amber,

77
00:04:04.360 --> 00:04:05.710
all these jams from books out there,

78
00:04:05.830 --> 00:04:10.270
but I would not want to write a back at back backend code in javascript.

79
00:04:10.630 --> 00:04:11.830
People do it all the time.

80
00:04:12.100 --> 00:04:16.980
I don't want to do it because I just prefer python,
right?
We,
we,
we,

81
00:04:16.981 --> 00:04:20.050
we as machine learning engineers,
we write python anyway,

82
00:04:20.051 --> 00:04:24.100
so let's just use a python framework.
You could also use Django,
but again,

83
00:04:24.101 --> 00:04:28.030
this is the simplest way to do it.
Why?
Because flask is just you.
You literally,

84
00:04:28.060 --> 00:04:32.950
I mean,
look at this.
This is an example right here.
Pip install flask,
import it,

85
00:04:33.640 --> 00:04:38.140
initialize it,
right or out.
Boom.
And that's all you need to run.
And then this,

86
00:04:38.170 --> 00:04:41.770
it's going to type out,
hello?
Where is going to show helloworld in the,

87
00:04:41.771 --> 00:04:44.890
in the browser with Django,
you know there's a,
there's a kind of skeleton to it,

88
00:04:44.891 --> 00:04:48.730
you know the APP,
you know the html files has to go in a certain directory.

89
00:04:48.820 --> 00:04:51.760
The js files had to go in a certain directory.
It's similar to um,

90
00:04:51.970 --> 00:04:56.080
what's that ruby framework rails.
It's similar to rails in that way.
But you know,

91
00:04:56.081 --> 00:04:57.520
philosophy is just super simple,
right?

92
00:04:58.540 --> 00:05:01.930
I'm talking to people who like are experimenting with their models and they just

93
00:05:01.931 --> 00:05:05.650
want to like show people,
right.
You know,
10,
2000,
400 people,

94
00:05:05.830 --> 00:05:08.410
but not like millions of people.
Right.
Tensorflow serving as the way to do that.

95
00:05:08.440 --> 00:05:10.960
Okay,
so what else is out there?
Right?
Why,

96
00:05:10.961 --> 00:05:15.130
why use flask and just native javascript?
Aren't there other frameworks?

97
00:05:15.190 --> 00:05:16.960
The answer is yes,
there are.

98
00:05:17.050 --> 00:05:19.480
This is just the simplest way cause I've been trying out a bunch of them,

99
00:05:19.481 --> 00:05:23.110
but I want to talk about three just so you get an idea of what the space looks

100
00:05:23.111 --> 00:05:27.340
like.
Okay.
So the first is uh,
[inaudible] dot js.

101
00:05:27.520 --> 00:05:29.590
Now this is like the defacto,

102
00:05:29.800 --> 00:05:32.650
like most stars for using tariffs in the browser.

103
00:05:33.700 --> 00:05:37.030
It's gotten GPU support.
It can only,
it can only,

104
00:05:37.031 --> 00:05:39.130
it only supports Ford pass inference.

105
00:05:39.310 --> 00:05:41.650
That means you don't train your models in the browser.

106
00:05:41.890 --> 00:05:44.440
You have to have them trained.
Once they're trained,

107
00:05:44.570 --> 00:05:48.490
then it's going to use GPU acceleration to make that prediction right.

108
00:05:48.491 --> 00:05:52.150
To go through the layers.
Once you've got your inputs to just make,

109
00:05:52.270 --> 00:05:57.270
make inference faster and it's using web loss and Ndra these two libraries that

110
00:05:57.291 --> 00:06:01.160
are basically like the javascript versions of Num Pi and uh,

111
00:06:01.550 --> 00:06:06.020
not Kuda but like,
um,
yeah,
whatever,
whatever,
whatever.

112
00:06:06.021 --> 00:06:10.670
Kutas whatever's on top of Kuta right when it comes to when it comes to running

113
00:06:10.700 --> 00:06:14.710
things in python.
So that's what it does.
You use Karasin tensorflow.

114
00:06:14.750 --> 00:06:19.490
It's got a bunch of interactive demos and uh,
it's pretty cool.
It's pretty cool.

115
00:06:20.090 --> 00:06:24.350
Uh,
but again,
it's a lot of work to get to get to get working.

116
00:06:24.351 --> 00:06:27.470
I was trying it out,
but check out these demos.
These demos are pretty cool.

117
00:06:27.650 --> 00:06:29.480
Like this bi-directional Lstm Demo.

118
00:06:29.900 --> 00:06:34.850
So it's basically like doing sentiment analysis on,
on texts.
So like I really,

119
00:06:34.851 --> 00:06:39.350
really love my life is going to be,
you know,
green.
Whereas they say,

120
00:06:39.980 --> 00:06:43.940
whereas the FSA hatred,
you know,
sex,

121
00:06:44.390 --> 00:06:49.040
sin,
drugs,
oh,
it's not that bad.
50,
50%.

122
00:06:49.070 --> 00:06:53.570
Okay.
I hate people.
Hatred.

123
00:06:55.520 --> 00:07:00.290
Urgent kill me.
Needs more training,

124
00:07:00.640 --> 00:07:05.390
need more training.
Okay.
Just like people do sometimes.
Okay.

125
00:07:05.600 --> 00:07:08.960
So that's one way you could do it,
right?

126
00:07:09.000 --> 00:07:13.070
So if you want Gpu acceleration once this,
so I'm saying try out this way,

127
00:07:13.071 --> 00:07:13.790
do this way.

128
00:07:13.790 --> 00:07:16.700
You can literally get this running in 30 seconds using the code in the browser.

129
00:07:16.940 --> 00:07:20.420
Literally you just clone the Repo,
install it with pip install,

130
00:07:20.421 --> 00:07:24.650
require requirements at txt recursively and then run the APP.

131
00:07:24.710 --> 00:07:28.130
It's that simple.
It's literally that simple and you'll have it in your browser.

132
00:07:28.310 --> 00:07:31.660
Once you get that,
once you get this working and you've got to feel for how this,

133
00:07:31.661 --> 00:07:35.330
this structure works,
then move on to using [inaudible] such js.
Okay.

134
00:07:35.331 --> 00:07:39.200
Later on if you want Gpu acceleration and then tensorflow serving.

135
00:07:39.500 --> 00:07:43.650
Another way to do this is web DNA.
So actually,
so Francoise,
the,

136
00:07:43.660 --> 00:07:48.660
the creator of care os recently shared this library as the fastest way to do it

137
00:07:49.071 --> 00:07:51.320
in the browser web DNS.
Uh,

138
00:07:51.350 --> 00:07:55.610
so he liked cl so they clocked it against Carol sijs and it Blue Care Os.
Dot.

139
00:07:55.611 --> 00:07:58.670
Js Out of the water.
However,
how long,
so you might be saying like,

140
00:07:58.671 --> 00:08:00.860
why don't you just use this one then why Karen called Jazz?

141
00:08:01.310 --> 00:08:02.660
When I tried running this,

142
00:08:02.810 --> 00:08:05.420
I got a specific error and I didn't see it in the issues,

143
00:08:05.600 --> 00:08:08.510
but it is a real error and the error was uh,

144
00:08:08.810 --> 00:08:13.220
it was like XC run cannot find metal dependency.
And I was like,

145
00:08:13.430 --> 00:08:14.263
what do you mean metal?

146
00:08:14.270 --> 00:08:18.380
So I was like looking up like metal OSX and I found out that metal is an,

147
00:08:18.381 --> 00:08:22.730
is an apple specific dependency for running code on the GPU.
Right.

148
00:08:22.880 --> 00:08:24.350
Don't you love how apple always like,

149
00:08:24.710 --> 00:08:27.530
like wraps all of their libraries with these like neat,

150
00:08:27.531 --> 00:08:31.160
pristine interfaces and it just makes you want to just dive into and be like,

151
00:08:31.161 --> 00:08:34.040
yes,
I'll do anything with metal.
Yes,
this looks so awesome.

152
00:08:34.130 --> 00:08:39.110
But the fact is that uh,
not everybody has OSX and this requires,

153
00:08:39.140 --> 00:08:43.940
this has an OSX specific dependency,
web,
Dnn.
So if you have Mac,
definitely,

154
00:08:43.941 --> 00:08:47.340
definitely try it out.
But not everybody has Mac.
This,
the one I'm using is,

155
00:08:47.450 --> 00:08:51.860
is operating system agnostic,
which is what we want.
Okay.

156
00:08:51.861 --> 00:08:56.580
So now that we have that,
let's what else?

157
00:08:56.640 --> 00:09:00.090
So,
so that's one.
And so the,
the third one is called Neo cortex.

158
00:09:00.330 --> 00:09:02.730
So neocortex is also very cool.

159
00:09:02.731 --> 00:09:06.990
It's got some great examples in the browser that we can,
that we can try out.

160
00:09:08.380 --> 00:09:13.380
So in initializes and then does the same thing or like predicting classifying

161
00:09:13.621 --> 00:09:16.890
these images.
But the problem with neo cortex says,
look,

162
00:09:16.950 --> 00:09:20.340
look at this and this is a good thing to do.
Look at when the last commit was,

163
00:09:20.370 --> 00:09:24.840
it was a year ago.
We want libraries that are actively maintained.
Why?

164
00:09:24.841 --> 00:09:25.950
Because if you don't,

165
00:09:26.040 --> 00:09:30.600
then it leads to what's called Code Rot and code rot is when code just

166
00:09:30.601 --> 00:09:35.160
deprecates.
Right?
And we don't want deprecated code,
but it is pretty cool.
Okay,

167
00:09:35.161 --> 00:09:37.290
so those are three that I wanted to talk about.
Okay.

168
00:09:37.350 --> 00:09:41.270
So let's go ahead and actually do this.
Okay.
So,
um,

169
00:09:41.460 --> 00:09:46.320
where do we get started here to get started?
Let me x out of these.
X,

170
00:09:46.321 --> 00:09:51.060
x,
x,
x,
not the,
okay.
Gone.

171
00:09:51.420 --> 00:09:54.630
Gone,
gone.
Okay.
So now

172
00:09:56.820 --> 00:09:58.530
let's get back to what we were doing here.

173
00:10:01.280 --> 00:10:01.750
<v 1>Sorry.
So</v>

174
00:10:01.750 --> 00:10:04.300
<v 0>the first thing we're going to do is,
is train our model,
right?</v>

175
00:10:04.301 --> 00:10:07.300
So I'm just going to glaze over this code and like talk about what's happening.

176
00:10:07.301 --> 00:10:10.210
I'm not going to actually type it out because we've seen him and I see many

177
00:10:10.211 --> 00:10:10.571
times,

178
00:10:10.571 --> 00:10:13.720
but I'm just going to refresh just so we have some kind of base to move forward

179
00:10:13.721 --> 00:10:14.290
from.

180
00:10:14.290 --> 00:10:18.820
So we're going to build a model that's going to be able to classify handwritten

181
00:10:18.821 --> 00:10:20.350
character digits.
Okay.

182
00:10:20.410 --> 00:10:25.410
So we're going to MPR import future just for python compatibility between two

183
00:10:25.451 --> 00:10:28.120
and three carats and all of its dependencies.

184
00:10:28.420 --> 00:10:30.700
And once we've got care os we're going to say,
okay,

185
00:10:30.880 --> 00:10:33.850
we're going to do this with mini batch grading dissent with batch sizes of one

186
00:10:33.851 --> 00:10:38.410
28 images per batch.
There's 10 different classes and then 12 epochs,
right?

187
00:10:38.830 --> 00:10:41.470
So there,
there are certain number of batches within each box.

188
00:10:41.560 --> 00:10:44.350
So we defined a number of epochs and then run a certain number of batches for

189
00:10:44.351 --> 00:10:45.940
every epoch during training.

190
00:10:46.270 --> 00:10:49.180
And then we're going to use this beautiful method that's super simple.

191
00:10:49.181 --> 00:10:52.270
If only all data sets you use something like this,
right?
Low data,

192
00:10:52.360 --> 00:10:55.450
it's going to download it,
split it into training and testing sets for us.

193
00:10:55.480 --> 00:10:59.170
Just like that.
Okay?
Once we have that,
then we're going to say,
well,

194
00:10:59.260 --> 00:11:01.090
assuming what,
what format it's in,

195
00:11:01.120 --> 00:11:04.750
we're going to arrange the data in a certain way.
So that's why this,

196
00:11:04.900 --> 00:11:09.220
this channels first a flag is there.
Either it's going to be,
you know,

197
00:11:09.250 --> 00:11:13.600
it's going to show that a certain layer of convolutional matrix cs or it's going

198
00:11:13.601 --> 00:11:15.550
to do it the other way.
It's going to reverse it.

199
00:11:16.570 --> 00:11:21.070
And so then more reshaping and to float 32,
and then we're going to,

200
00:11:21.330 --> 00:11:25.110
uh,
convert our class vectors to be binary class major CS.
Uh,

201
00:11:25.330 --> 00:11:27.880
is it this or not?
And then we're going to build our model.

202
00:11:27.910 --> 00:11:32.380
So it's going to be a sequential model and chaos with eight different layers,

203
00:11:32.381 --> 00:11:32.561
right?

204
00:11:32.561 --> 00:11:36.310
So we're going to start off with a convolutional layer that's going to act as a

205
00:11:36.311 --> 00:11:40.120
filter for that image.
And then we're gonna say,
okay,
now that we have this layer,

206
00:11:40.360 --> 00:11:42.550
we'll add another convolutional layer.
So it's going to be,

207
00:11:42.670 --> 00:11:46.390
it's going to take that big image and continuously split it into smaller subsets

208
00:11:46.391 --> 00:11:49.810
of images.
And they were going to use pooling to decide what,
which,

209
00:11:49.960 --> 00:11:52.180
what part of the image is most relevant.

210
00:11:52.181 --> 00:11:57.100
That that is what part of the image has had something drawn on it.

211
00:11:57.101 --> 00:12:00.160
Write the character itself.
That's,
that's the relevant part.

212
00:12:00.370 --> 00:12:04.150
Then dropout is a technique to improve convergence by randomly turning neurons

213
00:12:04.151 --> 00:12:04.984
on and off.

214
00:12:05.200 --> 00:12:08.080
We're going to flatten it because it has way too many dimensions and we want a

215
00:12:08.081 --> 00:12:11.020
very small,
uh,
output prediction,
right?
A label.

216
00:12:11.021 --> 00:12:14.860
We don't want like this huge array as our output.
Once we have that,

217
00:12:14.861 --> 00:12:15.694
then we're going to say,
okay,

218
00:12:15.700 --> 00:12:19.630
we're going to use a dense layer because we want all that relevant data drop
out.

219
00:12:19.631 --> 00:12:22.810
Again just for convergence and say usually drop out happens twice,

220
00:12:22.900 --> 00:12:25.420
sometimes three times,
but I don't see it happen more than that.

221
00:12:25.660 --> 00:12:29.960
Unless you're using like,
yeah,
generally it's two to three times a.

222
00:12:30.080 --> 00:12:32.410
Then we're going to use a last dense layer to squash it.

223
00:12:32.411 --> 00:12:37.380
Using a softmax function is going to output a list of probabilities of what

224
00:12:37.450 --> 00:12:38.283
class is going to be.

225
00:12:38.350 --> 00:12:42.640
It's a multi-class classification problem and then once we're done with that,

226
00:12:42.641 --> 00:12:44.770
we're going to use our optimizer at a Delta,

227
00:12:44.771 --> 00:12:48.010
which if you saw my evolution of grading dissent video,
which I hope you did,

228
00:12:48.280 --> 00:12:52.120
you now have a better understanding of why we use these optimizers,
right?

229
00:12:52.210 --> 00:12:57.210
It's an adaptive learning rate method that is is is rivaled only by Adam and

230
00:12:57.311 --> 00:12:58.630
Adam Grad.
Okay,

231
00:12:58.660 --> 00:13:02.470
and so then we're going to use this categorical Google Cross entropy as our loss

232
00:13:02.471 --> 00:13:06.070
function because we have multiple classes,

233
00:13:06.100 --> 00:13:10.720
not binary cross entropy.
Is this,
that is this,
you know,
black or white?
No,

234
00:13:10.780 --> 00:13:13.090
it's categorical cause we've got 10 classes.

235
00:13:13.630 --> 00:13:16.090
Then we're going to train that stuff.
We're going to train the model,

236
00:13:16.150 --> 00:13:18.970
okay with this fit method and then we're going to test how well it did.

237
00:13:19.150 --> 00:13:21.970
And then at the very end,
this is now,
this is the very important part.

238
00:13:22.150 --> 00:13:25.270
That's that's US building our model.
Okay,
we're done building a model.

239
00:13:25.420 --> 00:13:28.960
Now it's time to save it to Jason and the weights file.

240
00:13:29.170 --> 00:13:31.960
So we're going to save two different entities here.

241
00:13:31.961 --> 00:13:36.820
One is a Jason file and the Jason File is there because we want to save the

242
00:13:36.821 --> 00:13:38.470
structure of the model itself.

243
00:13:38.630 --> 00:13:41.110
This is going to save the architecture of the model.

244
00:13:41.350 --> 00:13:44.950
The other part are the weights and the weights are the learnings,
right?

245
00:13:44.951 --> 00:13:45.850
Once we've trained it,

246
00:13:46.090 --> 00:13:51.090
all of those learned values from the matrices of what it means to be a zero or a

247
00:13:51.971 --> 00:13:55.810
one or a two,
any of those images,
all that's going to go in our weights file.

248
00:13:55.900 --> 00:13:56.410
Okay?

249
00:13:56.410 --> 00:13:59.050
And so we're going to save that and we're going to say both of them and we're

250
00:13:59.051 --> 00:14:02.830
going to load both of them later using flask.
Okay.

251
00:14:02.831 --> 00:14:06.400
So that's it for our training part and then we would just train this model,

252
00:14:06.460 --> 00:14:10.510
right?
Which I could do,
but I mean I,
I trained it before,

253
00:14:10.990 --> 00:14:12.010
uh,

254
00:14:16.060 --> 00:14:18.910
right.
So just like that,
right?
It's going to do everything,

255
00:14:18.911 --> 00:14:21.850
but I already have a trained here at the h five file and the Jason Fall,

256
00:14:21.970 --> 00:14:25.330
h five by the way,
is the format for Karrass models.
Okay.

257
00:14:25.630 --> 00:14:30.190
So we'll have both of those and once we have those,
we're going to,
let's see,

258
00:14:30.280 --> 00:14:35.020
let's see.
Now we're going to write our flask APP.
So we did,
we trained our model,

259
00:14:35.021 --> 00:14:38.410
we did step one,
and then we saved it.
That was step two.

260
00:14:38.411 --> 00:14:39.520
And now we're at step three,

261
00:14:39.700 --> 00:14:43.510
writing our flask backend to say to serve our saved model.

262
00:14:43.511 --> 00:14:46.600
That is the h five file as well as a Jason File.

263
00:14:47.080 --> 00:14:49.750
And then we'll look at the dependency classes that make the help make that

264
00:14:49.751 --> 00:14:54.740
happen.
Okay,
so going to first import flask,
right?

265
00:14:54.741 --> 00:14:56.000
This is our web framework.

266
00:14:56.001 --> 00:15:00.950
Our microservices framework and a few of its a related dependencies,

267
00:15:00.951 --> 00:15:04.400
right?
Because flask alone isn't enough.

268
00:15:04.430 --> 00:15:07.580
We've also got to have these dependencies.
We've got flask,

269
00:15:07.670 --> 00:15:11.660
we've got render templates.
Why do we have render templates?
Because uh,

270
00:15:11.810 --> 00:15:15.020
generating html from python alone is kind of messy.

271
00:15:15.050 --> 00:15:19.310
So what this does is it lets us define an html fought html file,

272
00:15:19.430 --> 00:15:21.890
a standalone html file,
and then we can just call that,

273
00:15:22.400 --> 00:15:23.780
it's called index dot html.

274
00:15:23.960 --> 00:15:27.800
This is going to help us render that using python and then requests for just

275
00:15:27.801 --> 00:15:32.210
handling all these guest posts.
Set requests,
right.
Okay.
So that's for flask.

276
00:15:32.420 --> 00:15:36.590
And then we're going to import,
hold on.

277
00:15:36.591 --> 00:15:41.450
It's render template,
not templates template to play.
Okay?

278
00:15:42.020 --> 00:15:43.310
Uh,
that's not a language.
Okay.

279
00:15:43.311 --> 00:15:47.620
So then we're going to import PSI PI and [inaudible] gonna just have a couple of

280
00:15:47.630 --> 00:15:50.390
functions because what we're gonna do is we're going to take that image that

281
00:15:50.391 --> 00:15:53.750
they user draws and we're going to reshape it using these methods,
right?

282
00:15:53.751 --> 00:15:57.380
So this is our scientific computing library and we're going to reshape whatever

283
00:15:57.381 --> 00:15:59.900
they use or draws.
So it's in the right image format.

284
00:15:59.901 --> 00:16:02.990
And then feed that directly into our pretrained model.
Right?

285
00:16:02.991 --> 00:16:06.110
So we've got him saved in,
read an image,
resize.

286
00:16:06.170 --> 00:16:09.260
Those are the three that we're going to need.
Okay.
So we've got that.

287
00:16:09.261 --> 00:16:14.150
And then of course num Pi Duh cause that's our matrix math operations,

288
00:16:14.210 --> 00:16:15.980
uh,
library.
We love that.

289
00:16:16.220 --> 00:16:20.360
And then we're going to have of course import care os dot models to import our

290
00:16:20.361 --> 00:16:24.410
model that we've trained.
And lastly,
Ari.
Ari is regular expressions,

291
00:16:24.560 --> 00:16:29.210
a great way to handle a huge sets of string data without having to sort through

292
00:16:29.211 --> 00:16:33.950
all of it.
Okay.
Uh,
and so that's all we've got some more.

293
00:16:33.951 --> 00:16:37.670
So import sis is going to help us do some system level operations.

294
00:16:37.671 --> 00:16:40.610
Like this is how,
this is not what we're actually going to load the file itself.

295
00:16:40.970 --> 00:16:41.840
Okay.
We've got that.

296
00:16:41.841 --> 00:16:46.250
And then we're going to import unless for some operating system data.

297
00:16:46.490 --> 00:16:49.340
And then we're going to,
now we're going to use this to say,
okay,

298
00:16:50.330 --> 00:16:54.110
we're going to say this is where our model is.
Let's define where our model is.

299
00:16:54.560 --> 00:16:59.330
All right and,
and o to do this.
See our imports are already coming in handy here.

300
00:16:59.600 --> 00:17:00.433
So we're going to say,
okay,

301
00:17:01.010 --> 00:17:04.790
so that's where our model is saved in this model and the model folder.
Okay.

302
00:17:05.060 --> 00:17:05.893
And then

303
00:17:08.060 --> 00:17:12.140
from load import that,
okay.

304
00:17:13.070 --> 00:17:13.903
So that's gonna,

305
00:17:13.940 --> 00:17:17.240
that's gonna that tells our app where the model is going to be saved.

306
00:17:17.510 --> 00:17:21.050
And then we're going to say we're going to import this load classes,

307
00:17:21.080 --> 00:17:24.170
which is going to help us load the model and then we're going to initialize it.

308
00:17:24.200 --> 00:17:26.030
Okay.
So that's it for dependencies.

309
00:17:26.050 --> 00:17:30.260
And now we can initialize flask app are initialized our Flask App.

310
00:17:30.440 --> 00:17:35.060
So we're gonna say,
okay,
so the APP is flask given end name,

311
00:17:35.150 --> 00:17:38.650
which is going to be,
we'll,
we'll define later.
Okay.
So that,

312
00:17:38.651 --> 00:17:42.350
that's it for our flask APP.
And then we're going to import two or so,

313
00:17:42.360 --> 00:17:46.610
not important declared to global variables that we've defined elsewhere.

314
00:17:46.610 --> 00:17:48.290
And you'll see what these are.

315
00:17:48.291 --> 00:17:53.291
But basically the is the model object for how we encapsulate the model file.

316
00:17:53.910 --> 00:17:57.730
And the graph is the computation graph,
right?
Uh,

317
00:17:58.740 --> 00:18:02.100
which is like a session from inside.
We run the model,

318
00:18:02.970 --> 00:18:04.860
it's a kin to a session.
In this case,

319
00:18:05.880 --> 00:18:08.880
and then we're going to initialize these variables.
So we're gonna say,
okay,

320
00:18:08.881 --> 00:18:13.881
so model and graph initialized both of them from the load,

321
00:18:14.310 --> 00:18:17.760
from then,
that's where the load,
uh,
dependency comes from,
from load in port.

322
00:18:18.120 --> 00:18:21.660
That's where that come from,
comes from.
Okay.
So then once we have that,

323
00:18:21.870 --> 00:18:25.860
let's write out that main function,
right?
That's right at that main function.

324
00:18:25.861 --> 00:18:29.520
So we're going to say,
okay,
if name equals Maine,

325
00:18:31.450 --> 00:18:32.283
<v 1>okay,</v>

326
00:18:34.090 --> 00:18:38.680
<v 0>what port should we run this APP in?
Right?
Hold on.
If,</v>

327
00:18:41.060 --> 00:18:44.420
well,
we're going to decide that the port is going to be,

328
00:18:48.110 --> 00:18:49.640
well,
let's get it from the environment.

329
00:18:49.970 --> 00:18:54.970
It's going to be port 5,000 because nothing else is running on that port.

330
00:18:55.160 --> 00:18:58.760
Oh,
let's,
it is,
which it's not.
It's not.
And once we have that,

331
00:18:58.761 --> 00:19:01.910
we can run the APP locally using app.run.
So we'll say,

332
00:19:02.690 --> 00:19:07.430
oh,
that's,
that's where we're going to run it.
That's like in the browser.

333
00:19:07.431 --> 00:19:08.031
That's the address.

334
00:19:08.031 --> 00:19:12.530
So it's gonna be like 0.04 at port 55,000 all right.

335
00:19:12.531 --> 00:19:15.740
And so we can define that as well.
Super simple stuff.
You know,

336
00:19:16.010 --> 00:19:20.630
if you do machine learning for a while,
everything else seems super trivial.

337
00:19:20.900 --> 00:19:23.960
Just boring in a way.
No,
it's not boring.
Just,
I mean just you know,

338
00:19:23.961 --> 00:19:27.200
boiler plate stuff.
But the,
the what we're doing overall is cool.
Okay.

339
00:19:27.201 --> 00:19:31.400
So then we'll say,
okay,
so run this APP.
We've,
we've defined it and let's,

340
00:19:31.520 --> 00:19:32.353
I've already did that.

341
00:19:33.260 --> 00:19:38.210
We defined it and now that's it.
That's it.
That's it for the,

342
00:19:38.450 --> 00:19:41.030
that's it for the name pot for the main main file.

343
00:19:41.210 --> 00:19:43.820
So now we've got to write some helper functions here,
right?

344
00:19:43.970 --> 00:19:46.190
So we've got two helper functions that we want to make here.

345
00:19:47.180 --> 00:19:51.380
The first one is called index,
and then the other one is called predict.

346
00:19:51.530 --> 00:19:56.270
So we'll say,
okay,
so this is how we're routing our,
uh,
files.

347
00:19:56.330 --> 00:19:59.480
So this is,
so this is the APP dot fuck app.py file.

348
00:19:59.481 --> 00:20:02.360
This is how all of this is how we tell our APP.

349
00:20:02.540 --> 00:20:05.780
What happens whenever a user goes to a certain address,
right?
So if you go to,

350
00:20:05.910 --> 00:20:09.890
you know,
slash looney tunes,
then load up the looney tunes function.

351
00:20:09.891 --> 00:20:13.800
If you go to slash hello world.
And a lot of the hello world function.
So if they,

352
00:20:13.801 --> 00:20:15.940
if the user goes to this,
just,
you know,

353
00:20:15.980 --> 00:20:19.820
slash that means that while they're on the main page,
so let's give,

354
00:20:19.880 --> 00:20:22.460
let's serve them the index.
So

355
00:20:23.960 --> 00:20:28.670
we'll say at this route,
let's define an index function,

356
00:20:28.910 --> 00:20:32.620
which we'll write this functionality and all it's going to do it all it's gonna

357
00:20:32.640 --> 00:20:37.310
do is it's going to render the template,
which is index dot html,

358
00:20:37.340 --> 00:20:40.130
which we'll talk about afterwards.
That's one of our dependencies here,
right?

359
00:20:40.270 --> 00:20:42.440
This is the high level code.
So that's it.

360
00:20:42.441 --> 00:20:44.150
It's going to render that html template,

361
00:20:44.151 --> 00:20:47.770
index dot html that's going to serve html.
That's okay.

362
00:20:47.771 --> 00:20:51.400
So then once we've got that,
then we can say,
okay,

363
00:20:51.460 --> 00:20:55.590
well what about if the user goes to this predict,
uh,

364
00:20:57.310 --> 00:20:58.450
route?
Well,

365
00:20:58.451 --> 00:21:02.530
the user isn't going to specifically go to predict when the user hits a submit.

366
00:21:02.580 --> 00:21:05.950
You know,
when they draw the number to hit submit on click,

367
00:21:06.220 --> 00:21:07.930
that's when predictors called,
well,

368
00:21:07.960 --> 00:21:12.400
now we've got to write code for that predicts when to show what happens when the

369
00:21:12.401 --> 00:21:16.360
user clicks that.
So we're going to use two methods here.
We're going to use both,

370
00:21:16.361 --> 00:21:19.060
get an post

371
00:21:22.650 --> 00:21:27.010
and
we'll see.
Okay?

372
00:21:27.370 --> 00:21:28.203
So

373
00:21:29.630 --> 00:21:30.030
<v 1>okay,</v>

374
00:21:30.030 --> 00:21:32.940
<v 0>for project we're going to say,
well,
let's get that image data.</v>

375
00:21:32.941 --> 00:21:36.870
So from the request,
where are we good

376
00:21:40.060 --> 00:21:44.840
from?
The requests were going to get that data
and hold on.

377
00:21:47.490 --> 00:21:49.300
Okay?
And that's going to get the raw,

378
00:21:49.640 --> 00:21:52.470
that's going to get the raw data format from the image,
right?

379
00:21:52.471 --> 00:21:55.650
It's just the raw serialized data.

380
00:21:55.830 --> 00:21:58.590
And now we have to reshape it so we can fit it into our model,
right?

381
00:21:58.710 --> 00:22:00.660
The user drew drew something,
right?

382
00:22:00.840 --> 00:22:03.300
We were going to get that image or we're going to reshape it.

383
00:22:03.301 --> 00:22:05.220
So it's fit to be fed into our model.

384
00:22:05.340 --> 00:22:07.920
And then we're going to take that image VA into our model and it's going to

385
00:22:07.921 --> 00:22:11.100
output the prediction.
Okay?
So we'll say,
okay,

386
00:22:11.101 --> 00:22:15.180
so we've got that image data and now we're going to encode it using this helper

387
00:22:15.181 --> 00:22:16.560
function.
Oh,
we have one scene.

388
00:22:16.620 --> 00:22:19.180
We have one more helper function that I forgot about.

389
00:22:19.200 --> 00:22:23.460
So we've got image data and we're going to say,
uh,

390
00:22:23.550 --> 00:22:24.600
that's going to convert the image.

391
00:22:24.601 --> 00:22:29.310
That's going to basically convert the image into a more suitable format.
Uh,

392
00:22:29.340 --> 00:22:33.600
so once we have that,
we're going to read it into memory.
So right now it's still,

393
00:22:34.760 --> 00:22:37.050
we're reading it directly from the saved image.

394
00:22:37.200 --> 00:22:39.960
Now we're going to read it into memory using this

395
00:22:41.820 --> 00:22:45.240
mode l
and then we're going,

396
00:22:45.310 --> 00:22:48.290
and then we're going to invert the image.
So we're going to say,
okay,
and P.
Dot.

397
00:22:48.300 --> 00:22:49.630
In verb.
And what this does is,

398
00:22:49.631 --> 00:22:52.990
is it's a bit wise inversion so that all the black becomes white and all the

399
00:22:52.991 --> 00:22:55.810
white becomes black.
And it makes it easier for us to classify,

400
00:22:59.370 --> 00:23:00.480
okay,
once we have that,

401
00:23:00.620 --> 00:23:03.480
then we're going to make it the right size will say x equals image,

402
00:23:03.660 --> 00:23:06.570
resize ex,
uh,

403
00:23:06.600 --> 00:23:09.690
when we want it to be 28 by 28 pixels,
right?

404
00:23:09.691 --> 00:23:11.880
Because that's what our model expects.
That's,

405
00:23:11.881 --> 00:23:13.590
that's the image size that we trained it on.

406
00:23:13.591 --> 00:23:17.010
So we're going to resize it like that,
and then we're going to reshape it.

407
00:23:17.040 --> 00:23:19.140
So let's say x equals X.
Dot.
Reshaped,

408
00:23:22.140 --> 00:23:22.920
and then we're going to end.

409
00:23:22.920 --> 00:23:27.920
So now we're going to make it into a four d tensor of one 20 of one 28 21 of

410
00:23:29.671 --> 00:23:32.820
that size.
So it's say four d tenser and that,

411
00:23:33.390 --> 00:23:36.810
that is what we feed into our model of 40 tensor.
Okay.

412
00:23:36.840 --> 00:23:38.700
So image that reshape.

413
00:23:41.220 --> 00:23:42.620
So now with our computation graphs,

414
00:23:42.621 --> 00:23:46.940
so this is where that graph global variable comes in,
say graph dot.
As default,

415
00:23:50.210 --> 00:23:52.820
the prediction.
So we'll say modeled up,
predict x,

416
00:23:53.000 --> 00:23:58.000
given that newly reshaped image and then convert the response to a strength.

417
00:23:58.701 --> 00:23:59.640
So we've,

418
00:23:59.660 --> 00:24:04.160
we're going to take whatever comes out as a response and we're gonna use this

419
00:24:05.270 --> 00:24:07.490
array string method to convert it to a string.

420
00:24:08.090 --> 00:24:12.200
And we're going to say NPDR Arg Max to get the Max value of whatever came out of

421
00:24:12.201 --> 00:24:15.920
that using only a single access to eye single dimensional response,

422
00:24:15.950 --> 00:24:19.670
which is just one string.
And then we're going to return it.
Return response

423
00:24:22.820 --> 00:24:24.350
<v 1>just like that.
Okay.</v>

424
00:24:24.790 --> 00:24:29.620
<v 0>And yeah,
that's it.
Oh,
we've got,
and then that one,
we had that one more method.</v>

425
00:24:29.621 --> 00:24:33.680
What was it?
It was a convert image.
And so this is that last,
uh,

426
00:24:33.681 --> 00:24:36.400
two line helper function.
So this is,

427
00:24:36.430 --> 00:24:40.060
this is going to help us convert our image into a raw representation or it's

428
00:24:40.061 --> 00:24:45.010
going to decode it from base 64 and to raw data base 64 is like the default

429
00:24:45.011 --> 00:24:47.590
encoding whenever we write it out.
That's just like how it,

430
00:24:47.710 --> 00:24:51.250
how native the native javascript decided to encode it as.

431
00:24:51.430 --> 00:24:54.970
And we have to Dakota from base 64 and to just raw,
um,

432
00:24:55.270 --> 00:24:57.790
binary data so we could then,

433
00:24:58.390 --> 00:25:01.870
a lot of image conversion happens here.
So we'll say,
okay,

434
00:25:03.920 --> 00:25:07.630
and so this is what we use our regular expressions.
These were to say,
well,

435
00:25:07.631 --> 00:25:11.530
get all the parts of the image that are encoded in base 64 and

436
00:25:13.370 --> 00:25:14.270
<v 1>convert them</v>

437
00:25:16.100 --> 00:25:18.530
into this string so that

438
00:25:24.790 --> 00:25:28.180
<v 0>put them in the string so that we can then they code them.
So then we could say,</v>

439
00:25:28.630 --> 00:25:31.570
we'll take whatever the,
so it's going to be saved as output dot P and g,

440
00:25:31.571 --> 00:25:33.640
the image,
uh,
that the user drew.

441
00:25:34.860 --> 00:25:36.700
So we're going to take that image and then

442
00:25:37.800 --> 00:25:41.850
<v 1>say
decode it</v>

443
00:25:43.470 --> 00:25:44.580
from base 64.

444
00:25:47.130 --> 00:25:51.240
<v 0>Cool.
Okay.
So that's it for,
that's it for this file,
for the APP to five APP dot.</v>

445
00:25:51.241 --> 00:25:55.470
Py File.
And then once we have that,
now we can look at our dependencies here.

446
00:25:55.471 --> 00:25:58.440
Like how did we,
how did we do this?
Right?

447
00:25:58.441 --> 00:26:02.310
And so we called some classes here and what I want to do is talk is talk about

448
00:26:02.311 --> 00:26:06.630
what classes we called.
Okay.
Let me just make sure all of this is correct.

449
00:26:07.740 --> 00:26:09.870
Um,
basically four.

450
00:26:11.420 --> 00:26:12.800
<v 1>Yup.
Yup,
Yup,
Yup,
Yup.</v>

451
00:26:18.860 --> 00:26:19.693
Okay,

452
00:26:21.670 --> 00:26:26.530
<v 0>cool.
All right.
So,
so we have that.
And so now I want to,</v>

453
00:26:27.440 --> 00:26:28.273
<v 1>okay,</v>

454
00:26:28.910 --> 00:26:33.830
<v 0>look at the,
uh,</v>

455
00:26:33.831 --> 00:26:38.180
where was I?
Okay.
App Dot.
Py.
Train a pie.
And then,

456
00:26:40.170 --> 00:26:43.810
okay,
so then the low dot pilots.
Look,
it's,
so let's look at some of these file.

457
00:26:43.811 --> 00:26:45.970
So low dot Powell,
remember we load the Pyre,

458
00:26:46.110 --> 00:26:49.650
remember what we called in it at the beginning?
Remember when we were like,

459
00:26:50.280 --> 00:26:52.590
where was it modeled?
Graph in it.

460
00:26:52.800 --> 00:26:55.690
This is what's happening in load up high under model.
And this star,

461
00:26:55.740 --> 00:26:58.350
these are saved,
uh,
models by the way.
H five and Jason,

462
00:26:59.010 --> 00:27:02.040
what we did was we loaded up our Jason.
Okay.

463
00:27:02.070 --> 00:27:06.690
And our h five file and we compile them so that we can then get the default

464
00:27:06.691 --> 00:27:10.410
graph.
Okay.
And so we said

465
00:27:12.510 --> 00:27:12.661
no,

466
00:27:12.661 --> 00:27:16.650
we compile them and then we returned that default graph from tensorflow cause we

467
00:27:16.651 --> 00:27:21.150
needed both of them.
Okay.
So we had both of them.
And so,
uh,

468
00:27:21.780 --> 00:27:23.910
when we hit compile,
it's not actually training,

469
00:27:23.970 --> 00:27:26.340
it's just evaluating based on what it already is.

470
00:27:26.370 --> 00:27:28.550
Like it's already trained and we're already,
we're,
we're,

471
00:27:28.650 --> 00:27:30.750
we're going to make sure that the loss has a certain,

472
00:27:31.410 --> 00:27:32.700
that's what we have these prints statements.

473
00:27:32.701 --> 00:27:34.290
We're going to make sure that the loss is a certain way.

474
00:27:34.440 --> 00:27:38.280
The accuracy is at a certain level and that uh,
yeah.

475
00:27:38.310 --> 00:27:40.980
And then we can print those out.
So that's what load.py does.

476
00:27:41.100 --> 00:27:43.800
And then we've got this index dot js file.
Now this is,

477
00:27:43.950 --> 00:27:47.760
this is what's happening in the background of the,
of index dot html.

478
00:27:48.120 --> 00:27:51.780
This is like pure javascript and there's no j query.

479
00:27:51.900 --> 00:27:54.150
Basically what it's doing here is it's,

480
00:27:54.690 --> 00:27:57.900
it's listening to your mouse movement to track,

481
00:27:57.990 --> 00:28:00.770
to actually make the drawing happen.
It's all in javascript.

482
00:28:00.780 --> 00:28:02.820
It's actually very short.
It's 83 lines of code,

483
00:28:03.090 --> 00:28:06.720
but in Javascript it's using an event listener to the tech mouse movements to

484
00:28:06.721 --> 00:28:11.130
then draw pixels on the screen.
Okay?
That's what this first part is doing.

485
00:28:11.460 --> 00:28:14.250
And then right here what it's saying is now that here's the,

486
00:28:14.251 --> 00:28:18.660
here's the really important part,
and then wait for the plane,
okay?

487
00:28:18.980 --> 00:28:22.770
And then the clear buttons is just going to clear the screen and we can select

488
00:28:22.771 --> 00:28:24.000
the colors and the line with.

489
00:28:24.180 --> 00:28:28.200
So here's the last dependency that I want to talk about is the index dot html

490
00:28:28.380 --> 00:28:31.260
file.
So for index dot html,

491
00:28:33.090 --> 00:28:36.180
we're drawing a bunch of dom elements,
right?
Like you know,

492
00:28:36.181 --> 00:28:40.410
the button and the,
uh,
the,

493
00:28:40.560 --> 00:28:44.780
the like little browser thing at the top,
this,

494
00:28:44.820 --> 00:28:47.550
the panel at the top.
And so then we've got this.

495
00:28:47.551 --> 00:28:52.440
Now here's the most important part.
When we click my button right on click,

496
00:28:52.830 --> 00:28:56.220
this is what,
this is the function that we want to run,
okay?
We're going to say,

497
00:28:56.430 --> 00:28:57.720
get the element by ID.

498
00:28:57.721 --> 00:29:01.740
So we're pulling an element directly from the dom and storing that in the canvas

499
00:29:01.741 --> 00:29:05.730
object.
And that is our image that the user drew.
And then we're going to say,

500
00:29:05.760 --> 00:29:09.350
well,
converted to it,
uh,
uh,

501
00:29:09.520 --> 00:29:11.010
a suitable string format.

502
00:29:11.011 --> 00:29:15.690
So then we can then make a request to it and then use Ajax as a way to make a

503
00:29:15.691 --> 00:29:19.530
post to the predict route using the image as a parameter.

504
00:29:19.650 --> 00:29:22.770
So it's going to make a prediction using that image.
And then it's when it,

505
00:29:23.130 --> 00:29:24.980
when it's successful with this callback,

506
00:29:25.160 --> 00:29:29.580
it's going to return that response and that response was here,

507
00:29:29.820 --> 00:29:33.370
right?
This is the output prediction.
Once it's,
uh,

508
00:29:33.570 --> 00:29:35.760
made the prediction and we've reshaped that image,

509
00:29:35.880 --> 00:29:38.400
it's going to return it here and then it's going to output.

510
00:29:38.401 --> 00:29:41.980
It's just like that right to html.
Okay.
So,
um,

511
00:29:43.060 --> 00:29:47.410
that's how that works.
And so now,
where are we now?
So we've done step three.

512
00:29:47.411 --> 00:29:51.040
We've written our flask backend to serve our sales model.
It's that easy.

513
00:29:51.041 --> 00:29:54.610
There's no other magic happening under the hood.
It's just raw flask,

514
00:29:54.700 --> 00:29:57.970
raw java script and chaos with the tension for the backend.

515
00:29:58.150 --> 00:29:59.740
And you can make a web app just like that.

516
00:30:00.400 --> 00:30:01.930
And there's a bunch of other helper library.

517
00:30:01.990 --> 00:30:04.840
There's a bunch of other libraries and and talking about them as well,

518
00:30:04.960 --> 00:30:09.490
and they give you things like Gpu acceleration,
um,
and

519
00:30:11.200 --> 00:30:13.000
more infrastructure.
Tensorflow serving,

520
00:30:13.001 --> 00:30:16.300
I'm talking about tensorflow serving specifically gives you more infrastructure

521
00:30:16.450 --> 00:30:20.620
to run different versions of models to deal with life cycles management,

522
00:30:20.860 --> 00:30:22.630
things like that.
Okay,

523
00:30:22.631 --> 00:30:26.500
so now we're in the last plot part deploying our code to Google cloud.
Okay,

524
00:30:26.501 --> 00:30:30.970
so this is actually super,
super simple.
It's two,
it's two commands,

525
00:30:31.410 --> 00:30:35.740
g cloud APP deploy,
and then g cloud APP brows.
This deploy APP,

526
00:30:35.770 --> 00:30:40.240
this deploy command is going to take your entire repository when you're in that

527
00:30:40.241 --> 00:30:41.074
main,

528
00:30:41.080 --> 00:30:44.410
when you're in that main directory and just deploy all of it to Google cloud,

529
00:30:44.560 --> 00:30:46.030
assuming you've authenticated,
right?

530
00:30:46.030 --> 00:30:47.950
Like you've already typed in your username and password,

531
00:30:48.160 --> 00:30:52.090
they will deploy that to its own container and Google cloud.
Okay?

532
00:30:52.180 --> 00:30:54.010
And once it's done,
it's going to build a container.

533
00:30:54.070 --> 00:30:55.630
So it's going to build a container image,

534
00:30:55.780 --> 00:30:59.560
it's going to dockerize it and then deploy that to app engine.
Hold on.

535
00:30:59.680 --> 00:31:01.000
It's not going to dockerize it.

536
00:31:01.001 --> 00:31:03.160
We would have to dockerize it ourselves if we wanted to,

537
00:31:03.340 --> 00:31:07.570
but it's going to deploy as a container to app engine and app engine is Google

538
00:31:07.571 --> 00:31:11.110
cloud's a service.
We're running apps,
it's like Heroku,

539
00:31:11.111 --> 00:31:14.470
but like Google cloud's version.
And then once it's there,
if we want to view it,

540
00:31:14.500 --> 00:31:18.670
we just type in Google g cloud app brows and then it's going to be at our

541
00:31:18.671 --> 00:31:23.290
project I id,
which is going to output.hubspot.com and just like that,

542
00:31:23.380 --> 00:31:27.010
you can now serve this model to your friends and show them what you've built.

543
00:31:27.370 --> 00:31:31.630
Okay.
So the more info is here,
right?

544
00:31:31.631 --> 00:31:33.280
Right on Google cloud,
I put a link to it,

545
00:31:33.400 --> 00:31:37.120
but basically you need to download the Sdk for Google cloud to be able to use

546
00:31:37.121 --> 00:31:41.560
this.
It's not just a simple pip install.
Okay.
And once you've got that,

547
00:31:41.770 --> 00:31:46.420
then you could run it super easily.
Right.
Uh,
also this guy,

548
00:31:46.450 --> 00:31:49.720
I found this really great tutorial as well.
Uh,
it's,

549
00:31:49.780 --> 00:31:53.020
it's more detailed then what I'm doing.

550
00:31:53.050 --> 00:31:56.650
It's actually a little complicated like,
but it's a,

551
00:31:56.651 --> 00:32:00.730
it's a pretty good tutorial as well.
Linked to that.
They're basically,
yeah,

552
00:32:00.731 --> 00:32:02.380
we can just deploy it to Google cloud.
Cool.

553
00:32:02.381 --> 00:32:05.170
So I'm going to end this by answering two questions and then we're out of here.

554
00:32:05.380 --> 00:32:08.220
So question one is,
um,

555
00:32:11.380 --> 00:32:14.530
how can I count objects in an image?
Great question.

556
00:32:14.740 --> 00:32:18.760
So for something simple like that,
you can just use open CV,
right?

557
00:32:18.761 --> 00:32:19.810
You can just use open CV.

558
00:32:19.811 --> 00:32:22.390
You don't actually have to use a pre trained model for that.
You could,

559
00:32:22.600 --> 00:32:24.880
but I think that would be overkill.
Uh,
yeah,

560
00:32:24.950 --> 00:32:29.630
use open CV and then the method is called,
um,
yeah,
we'll,

561
00:32:29.631 --> 00:32:31.930
is it like multi object detection?

562
00:32:35.840 --> 00:32:38.710
Yeah.
Multitrack or that's the class,
the multitrack or class.

563
00:32:38.920 --> 00:32:40.040
And in one more question,

564
00:32:42.870 --> 00:32:46.970
<v 1>uh,
could you</v>

565
00:32:46.970 --> 00:32:50.030
<v 0>please make a video about semantic nets using tensorflow?</v>

566
00:32:50.180 --> 00:32:53.490
I've got several videos on semantic next with tensorflow.
Um,

567
00:32:53.790 --> 00:32:57.050
check out my live,

568
00:32:57.140 --> 00:33:01.250
my earlier live videos from the u Udacity deep learning nanodegree several

569
00:33:01.251 --> 00:33:04.980
semantic nets like a game of Thrones.
Just search like game of Thrones.

570
00:33:04.981 --> 00:33:07.190
Saroj that one's going to be good for you.
Cool.

571
00:33:07.280 --> 00:33:08.750
Please subscribe if you liked this video.

572
00:33:08.751 --> 00:33:12.950
And for now I've got to go deploy my hair to production.
So thanks for watching.

