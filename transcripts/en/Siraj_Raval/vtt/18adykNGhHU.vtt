WEBVTT

1
00:00:00.850 --> 00:00:01.140
Okay.

2
00:00:01.140 --> 00:00:01.973
<v 1>Okay.</v>

3
00:00:14.370 --> 00:00:15.203
<v 0>Yeah.</v>

4
00:00:21.700 --> 00:00:22.533
Okay.

5
00:00:42.980 --> 00:00:43.813
Okay.

6
00:00:47.650 --> 00:00:50.710
<v 1>Okay.
It's working.
Okay guys.
Oh my God.</v>

7
00:00:50.740 --> 00:00:53.140
It was open broadcaster software.

8
00:00:53.320 --> 00:00:55.990
I can you guys bring everyone over here.

9
00:00:55.991 --> 00:00:58.960
So if you still have that other license and you just paste the link to this in

10
00:00:58.961 --> 00:01:00.460
that,
in that a chat,

11
00:01:00.550 --> 00:01:04.900
because I am never going to use open broadcaster software again.

12
00:01:05.050 --> 00:01:09.960
I'm only using Google hangout.
All right?
Okay.
So it's fine now.
No,

13
00:01:10.060 --> 00:01:12.940
everything is working.
Everything is better.
I'm live.
Good to go.

14
00:01:12.941 --> 00:01:17.370
We got everybody in here.
Great.
Works much better.
Hi Guys.
Okay,

15
00:01:17.371 --> 00:01:20.130
so we're gonna start off with a five minute Q and a and then we're going to

16
00:01:20.131 --> 00:01:22.110
start building a recommender system.
Okay?

17
00:01:22.200 --> 00:01:25.200
We're going to talk about several types of recommender systems in this episode

18
00:01:25.500 --> 00:01:30.300
and uh,
we're going to do it in the,
in,
in high python notebook.
Okay.
OPS sucks.

19
00:01:30.301 --> 00:01:30.631
Totally.

20
00:01:30.631 --> 00:01:33.000
So let's start with the five minute Q and a and then we're gonna get started.

21
00:01:33.000 --> 00:01:37.410
All right?
So come on,
give it to a of Google hangouts,

22
00:01:37.770 --> 00:01:40.640
right?
I'm using Google.
Hey,

23
00:01:40.660 --> 00:01:42.930
I've been using Google hangouts for since forever.

24
00:01:42.931 --> 00:01:46.200
I just tried to do something different because I wanted to do up the quality of

25
00:01:46.201 --> 00:01:49.590
my stream.
But that was just never again.

26
00:01:49.710 --> 00:01:54.360
What projects are you programming for fun?
Uh,
right now I am just making content.

27
00:01:54.361 --> 00:01:58.710
I really wish I had the time to just do some research,
um,
made some publications,

28
00:01:58.930 --> 00:02:01.490
uh,
but join a research group online.

29
00:02:01.500 --> 00:02:05.220
But I love making content even more so that's what I'm doing right now.

30
00:02:05.250 --> 00:02:08.580
If I wasn't the project that would be working on is probably trying to push the

31
00:02:08.581 --> 00:02:12.580
field forward.
In terms of Bayesean like probabilistic programming,

32
00:02:12.581 --> 00:02:13.830
like trying to move past the,

33
00:02:13.831 --> 00:02:18.320
pointing to something that requires less data and computation.
Uh,

34
00:02:19.500 --> 00:02:22.380
how are you going to use,
are you gonna use tensorflow and not this session?
Uh,

35
00:02:22.620 --> 00:02:26.280
what do you think of tensor flow fold?
I've never heard of that,
like came back.

36
00:02:26.960 --> 00:02:27.900
Um,
okay.

37
00:02:33.840 --> 00:02:34.673
<v 0>Okay.</v>

38
00:02:35.040 --> 00:02:38.400
<v 1>One question as soon as the one,
okay.
You went to Google.
I don't,</v>

39
00:02:38.520 --> 00:02:42.100
apart from your videos,
what do you recommend to learn machine learning from?
Uh,

40
00:02:43.280 --> 00:02:44.610
you'd asked against great courses.

41
00:02:45.100 --> 00:02:50.100
You Demi and also Andrew Young's black is not back like as good videos.

42
00:02:52.471 --> 00:02:56.220
Okay.
Okay.
Okay.
No lag.
Thank you.
Okay,

43
00:02:56.250 --> 00:02:58.380
so we're going to answer three more questions and then we're gonna get right

44
00:02:58.381 --> 00:03:03.160
into it because been lagging and,
and doing some dumb things.
Okay.

45
00:03:03.190 --> 00:03:07.330
Can you suggest a math book for machine learning?
I would recommend Khan Academy.

46
00:03:07.331 --> 00:03:11.650
I would actually not recommend a textbook because every time I read a textbook

47
00:03:11.920 --> 00:03:13.930
it just,
I don't absorb it.
You know,

48
00:03:13.960 --> 00:03:17.210
like I'll read it and I'll like get it for a while,
but I,

49
00:03:17.220 --> 00:03:18.790
after like a few months,
I'll forget everything.

50
00:03:18.791 --> 00:03:21.790
So the way to do it is not just practice makes perfect,

51
00:03:21.791 --> 00:03:26.590
but practice makes retention.
You have to continuously practice this stuff.
And,

52
00:03:26.730 --> 00:03:30.840
and where do you that is a cheat sheets and Khan Academy.
Uh,

53
00:03:30.910 --> 00:03:34.330
like short bits of information as you go in your journey.
Okay.

54
00:03:34.450 --> 00:03:36.280
Rather than just sit there,

55
00:03:36.340 --> 00:03:39.490
read an entire textbook and then forget it after a few months.
Okay.

56
00:03:40.030 --> 00:03:43.960
How can I do to get involved in machine when he would search a join a research

57
00:03:43.961 --> 00:03:48.160
group online?
Uh,
there are several,

58
00:03:48.161 --> 00:03:50.170
if you go to the machine learning stuff,
separate it.
They have a,

59
00:03:50.530 --> 00:03:53.590
they have a weekly reading groups.
So that would be a good place to find people.

60
00:03:54.010 --> 00:03:57.490
What do you think of data camp?
Data questions,
similar.
All great projects.

61
00:03:57.640 --> 00:04:00.370
I don't know about them.
And they go,
how many years have you been studying?

62
00:04:00.490 --> 00:04:02.780
On and off for like four years.
Uh,

63
00:04:05.500 --> 00:04:08.260
what are your thoughts on c Plus Plus for MLN?
Deep learning?
Uh,

64
00:04:08.290 --> 00:04:09.370
Steve Muscles is great.

65
00:04:09.670 --> 00:04:13.900
I don't have time to deal with deadlocks and uh,

66
00:04:14.290 --> 00:04:18.370
like syntax and the STD library we're focused on,
uh,

67
00:04:18.460 --> 00:04:20.080
algorithms and that's why I use python.

68
00:04:21.130 --> 00:04:25.630
Can you recommend research topic for CS student?
Uh,
focus on,
uh,

69
00:04:25.690 --> 00:04:28.960
unsupervised learning and generative models.
Can you record?

70
00:04:30.080 --> 00:04:30.630
<v 0>Okay.</v>

71
00:04:30.630 --> 00:04:34.020
<v 1>And she and management,
how they go hand in hand management,</v>

72
00:04:34.021 --> 00:04:35.420
like management per company?
Yeah.

73
00:04:35.520 --> 00:04:37.650
<v 2>Uh,
uh</v>

74
00:04:38.590 --> 00:04:42.370
<v 1>hmm.
Well you can try to find the,
if you,
if you,</v>

75
00:04:42.400 --> 00:04:44.920
if you model your company as a machine when he problems,

76
00:04:44.950 --> 00:04:49.330
you can find what tasks are most profitable for your objective and your

77
00:04:49.331 --> 00:04:52.510
objective could be to maximize profit for your company.
So if you were to,

78
00:04:52.840 --> 00:04:55.300
if you were to look at the data of what people are doing in your company,

79
00:04:55.450 --> 00:04:58.240
you were to put that in an excel spreadsheet and then you could find those

80
00:04:58.241 --> 00:05:03.190
teachers that are most relevant and then improve efficiency in those areas.
Okay.

81
00:05:03.191 --> 00:05:05.380
So one more question and then we're going to get started,

82
00:05:06.520 --> 00:05:08.350
which is reading books for,

83
00:05:09.840 --> 00:05:13.480
do you think I'm Harrison Kinsley Centex you can channel,
yes.
In Texas grades.
Uh,

84
00:05:13.481 --> 00:05:18.160
he's the currently the most viewed guy on youtube,
but,
uh,

85
00:05:18.280 --> 00:05:22.950
yeah,
he's,
he's a great guy.
Okay.
So,
so we're gonna get started.
Uh,
but,
but sorry,

86
00:05:23.140 --> 00:05:24.340
what do you,
oh wait,
Jason,

87
00:05:24.850 --> 00:05:28.030
will you make some time to make a video about hyper brainery Tootie?
Yes.

88
00:05:28.031 --> 00:05:30.880
Chick that is coming up.
I'm grammar tuning that is coming up for sure,

89
00:05:30.970 --> 00:05:34.510
because that's something I need to talk about.
Practice makes permanent.
Exactly.

90
00:05:34.511 --> 00:05:35.590
So let's get started.

91
00:05:35.950 --> 00:05:39.670
One thing is every time I do this live stream for an athlete to a brief out,

92
00:05:39.671 --> 00:05:42.460
so I'm just gonna freestyle off the dumb right now,
uh,
on some things.

93
00:05:42.461 --> 00:05:45.880
If someone just say a topic and then I'm just going to freestyle without music.

94
00:05:48.250 --> 00:05:50.020
I felt like last time was good,
but it wasn't amazing.

95
00:05:50.021 --> 00:05:51.190
So I want to make this one amazing.

96
00:05:52.440 --> 00:05:53.273
<v 2>Uh,</v>

97
00:05:54.540 --> 00:05:58.670
<v 1>how do you get control system with tensorflow that get hub link?</v>

98
00:05:58.850 --> 00:06:03.380
What is a generated my machine learning human learning robots,
robots.

99
00:06:05.720 --> 00:06:08.270
When I was in seventh grade,
I made my first robot.

100
00:06:08.510 --> 00:06:12.110
It flowed on the floor like it was a little flow of bile.
I see the desk,

101
00:06:12.111 --> 00:06:16.850
Brene enemies looking at me telling me,
you can't make that.
No,
not.
I said,

102
00:06:16.851 --> 00:06:21.670
no,
I'm going to make it anyways.
So I went back and went my fiddle in place,
Yo,

103
00:06:21.920 --> 00:06:24.890
I'll put meteors and other things together.

104
00:06:24.980 --> 00:06:28.280
And it made a little construction men and was against the weather.

105
00:06:28.370 --> 00:06:32.630
It went out in the rain.
It got nos for short circuits.
It came back,
man.

106
00:06:32.810 --> 00:06:36.620
It was my lurk in back.
Okay.
So that was it.
Okay.

107
00:06:36.680 --> 00:06:38.030
So now we're gonna get started with this.

108
00:06:38.360 --> 00:06:41.420
And I didn't build a robot in 10th grade.
It was more like 10th grade.
Okay.

109
00:06:41.480 --> 00:06:44.120
So that was the storytelling rap.
And now we're going to get started.

110
00:06:44.121 --> 00:06:47.540
So let me start screen sharing and then we're going to do this.
So guys,

111
00:06:47.660 --> 00:06:49.610
let me give you the link to this by the way.

112
00:06:49.611 --> 00:06:52.730
So I have the link and we're going to review this together and I'm going to put

113
00:06:52.731 --> 00:06:56.330
it in the description.
So,
okay,

114
00:06:56.331 --> 00:06:57.800
so here's the link to the code.

115
00:06:58.580 --> 00:07:02.540
Let me send you this link to the code and I want to give a shout out to some

116
00:07:02.541 --> 00:07:07.010
people because I forgot about that.
Nestor Dance,
a dark sedan come Po,

117
00:07:07.310 --> 00:07:12.200
uh,
Dan.
David.
Okay.
Alpha.
Okay,

118
00:07:12.230 --> 00:07:14.780
so that was at 417 people here are watching.

119
00:07:14.781 --> 00:07:16.820
I'm so excited for recommended systems.
Okay.

120
00:07:17.090 --> 00:07:18.970
Because there's so much cool shit we can do with this.

121
00:07:19.070 --> 00:07:22.640
There's just so much to talk about,
about recommended since.
Okay.
So guys,

122
00:07:22.850 --> 00:07:27.570
let me add this to the in real life time.
Boom.

123
00:07:27.690 --> 00:07:30.390
Link is there in real time.
Now we're going to start screen sharing.
Okay,

124
00:07:30.420 --> 00:07:34.980
here we go.
What do I want to screen?
Sure.
I want to and share my screen.
Okay.

125
00:07:35.340 --> 00:07:37.800
So now that we have that,

126
00:07:37.920 --> 00:07:40.530
let me minimize this Google hangout.

127
00:07:40.950 --> 00:07:45.420
And we are going to do this.
Okay,

128
00:07:46.200 --> 00:07:49.230
here we go.
So let's start at the very beginning of this.
Let's look at the very,

129
00:07:49.380 --> 00:07:53.550
very beginning and I'm going to minimize my screen.

130
00:07:54.060 --> 00:07:58.650
So
let's get started with this.
Okay.

131
00:07:59.790 --> 00:08:04.530
And let me see here.
Let me see here.
Let me see here.
Let me see here.

132
00:08:04.800 --> 00:08:07.580
Okay,
great.

133
00:08:08.540 --> 00:08:11.240
So let me maximize what we've got here.

134
00:08:11.840 --> 00:08:14.310
We're going to build a song recommend.
Okay.

135
00:08:14.330 --> 00:08:18.050
So the data set we're going to use is,
uh,

136
00:08:18.460 --> 00:08:22.900
so let me show myself,
because I need to show myself you spray sprain,
importing,

137
00:08:23.930 --> 00:08:26.900
not screen.
Important.
What was it?
It was movie report.
Okay.

138
00:08:29.110 --> 00:08:33.380
There are,
I am in the corner.
All right.
Okay.
All right,
so great.

139
00:08:33.470 --> 00:08:34.430
So I'm there like always.

140
00:08:34.700 --> 00:08:38.480
So we're going to build a song recommender and now how are we going to do that?

141
00:08:38.481 --> 00:08:40.180
How are we going to build a song,

142
00:08:40.220 --> 00:08:44.750
recommend her a recommender?
This is a pro.

143
00:08:44.780 --> 00:08:48.290
This is a problem that Amazon has.
Netflix has,
Gulu has,

144
00:08:48.560 --> 00:08:50.030
every website had this problem.

145
00:08:50.031 --> 00:08:54.680
How do we personalize content for users and how do we feed it to them?
Okay.

146
00:08:54.740 --> 00:08:57.960
So what we're going to try to,
that's what we're going to think about this life.

147
00:08:58.140 --> 00:09:03.120
How do we personalize content for users and feed it to them?
Okay.
Uh,
and,

148
00:09:03.121 --> 00:09:05.880
uh,
dating recommender,
we're going to do that too,
uh,
in the,

149
00:09:05.900 --> 00:09:09.420
in the next weekly video,
not,
not this video.
So before we,
even,

150
00:09:09.810 --> 00:09:11.280
before we even think about this,

151
00:09:11.400 --> 00:09:15.980
let's talk about the goal of recommender systems to identify relevant data for

152
00:09:16.000 --> 00:09:20.310
users.
Whether that's articles,
movies,
games,
people,
places.
In fact,
let me just,

153
00:09:20.311 --> 00:09:23.040
let's just look at what Amazon recommended for me.
Okay.
Let's see.

154
00:09:23.100 --> 00:09:25.530
What does Amazon recommends for,
to Raj?
What do we got here?

155
00:09:25.950 --> 00:09:29.880
Valentine's Day that's not personalized.
Uh,
when we got here.

156
00:09:30.480 --> 00:09:34.620
Recommend inspired by your browsing history.
Okay.
Okay.

157
00:09:34.621 --> 00:09:37.980
So if you look at this,
you would think something's weird is going on in here.

158
00:09:37.981 --> 00:09:42.180
I swear I needed costumes for a,
a video that I'm making,

159
00:09:42.390 --> 00:09:45.480
but what it did was it looked at what I've looked at in the past and the

160
00:09:45.481 --> 00:09:48.710
recommended items based on my past history.
Okay.

161
00:09:49.080 --> 00:09:52.290
And books on machine learning.
So it's looking at my past history,

162
00:09:52.440 --> 00:09:56.210
but it's not just my task.
It would other similar users have looked at as long.

163
00:09:56.550 --> 00:09:59.490
We're going to talk about these different types of systems in a second.
Okay.

164
00:10:00.090 --> 00:10:02.320
So I was looking at,

165
00:10:02.750 --> 00:10:05.560
I'm looking at making a video and it needed costumes for it anyway.

166
00:10:05.580 --> 00:10:09.210
I have like a whole choir singing my name anyway,
that's consistent.

167
00:10:09.211 --> 00:10:11.640
So there are three types of recommender systems okay.

168
00:10:11.790 --> 00:10:14.940
That we're going to talk about.
But first one is content based.

169
00:10:14.941 --> 00:10:18.510
The second one is collaborative and the third one is popularity.
Okay.

170
00:10:18.511 --> 00:10:20.970
So we're going to go through this step by step.
Okay.

171
00:10:20.971 --> 00:10:22.860
But before we talk about any of these,

172
00:10:23.040 --> 00:10:24.480
and we're going to talk about them in depth,

173
00:10:24.840 --> 00:10:28.560
we're going to first load our music data.
So let's look at our music data.
Okay.

174
00:10:28.890 --> 00:10:33.660
What do we have for our music data?
For Our music data,

175
00:10:34.470 --> 00:10:38.820
we are going to look at two two files.
Okay.

176
00:10:38.880 --> 00:10:41.730
So the first one is,
let's see what this says.

177
00:10:42.930 --> 00:10:46.230
This is a lot of songs.
Okay.
There's,
there's a lot of songs here.

178
00:10:46.231 --> 00:10:50.040
And then the next one is the,
the,
the,
the next database or some.
So let's just,

179
00:10:50.100 --> 00:10:52.920
let's just look at the website for,
it's like what is this?
What is this data?

180
00:10:52.921 --> 00:10:56.760
We always want to analyze that data is that we have first before we do anything,

181
00:10:56.970 --> 00:10:58.050
what is that data that we have?

182
00:10:58.260 --> 00:11:02.490
So this is the dataset and it's a mixture of songs from a bunch of music

183
00:11:02.491 --> 00:11:04.860
websites and user ratings.
Okay?

184
00:11:04.920 --> 00:11:09.390
So it's a collection of songs and the ratings that user gates users gift gave

185
00:11:09.391 --> 00:11:12.330
the songs.
So last the times a website thirsty.

186
00:11:12.390 --> 00:11:16.700
This is my jam secondhand songs.
It's a bunch of different,
uh,

187
00:11:17.310 --> 00:11:21.690
ratings by users of their favorite songs that what we're going to train our

188
00:11:21.691 --> 00:11:25.170
model on,
okay?
Now we have two different datasets.

189
00:11:25.530 --> 00:11:27.630
Our job is to integrate this data,
okay?

190
00:11:27.631 --> 00:11:32.460
This is a very important part of the data processing pipeline.
It is.

191
00:11:32.610 --> 00:11:36.990
We want to integrate this data,
okay?
So to integrate this data,

192
00:11:37.260 --> 00:11:40.860
we're going to use pandas,
okay?
So what we first do is we say,
okay,

193
00:11:40.861 --> 00:11:45.420
here are your two files.
Okay?
And let me make this a little bigger.

194
00:11:46.110 --> 00:11:49.240
These are our two files,
once the CSD and one is,
uh,

195
00:11:50.220 --> 00:11:52.110
is a triplet.
Okay.
These,
these are,

196
00:11:52.290 --> 00:11:56.460
these are triplets up here with tripling his user Id,
Song Id and listen count.

197
00:11:56.590 --> 00:12:00.250
Okay.
So we want to integrate these two together.

198
00:12:00.280 --> 00:12:04.210
So the first thing we'll do is we will read the table,
uh,

199
00:12:04.300 --> 00:12:07.900
using pandas and we'll store and this variable.
And then we'll say,
okay,

200
00:12:07.930 --> 00:12:11.280
let's define those three columns.
He's write a song idea and listen cal.

201
00:12:11.650 --> 00:12:13.060
Then we're going to read the Metadata,

202
00:12:13.061 --> 00:12:15.880
which is that other file that we had and we're going to store in this variable

203
00:12:15.881 --> 00:12:20.560
song,
df two.
So DF means data frames.
So we have two data frame,

204
00:12:21.030 --> 00:12:21.863
<v 2>uh,</v>

205
00:12:22.660 --> 00:12:24.640
<v 1>two data frames and</v>

206
00:12:27.310 --> 00:12:29.560
we're going to combine them with pandas merge function.

207
00:12:29.561 --> 00:12:32.710
We're going to combine both of them.
And it's a,
it's actually,

208
00:12:33.010 --> 00:12:33.843
<v 2>uh,</v>

209
00:12:34.780 --> 00:12:37.330
<v 1>one,
one of those.
So whenever we,</v>

210
00:12:37.540 --> 00:12:39.970
whenever we are integrating two data sets together,

211
00:12:40.000 --> 00:12:43.030
sometimes there are duplicate columns and we can,

212
00:12:43.420 --> 00:12:45.780
we can drop those duplicates and replaced it.
Okay.

213
00:12:46.000 --> 00:12:48.820
And the way we do that is what we,
we specify,

214
00:12:49.040 --> 00:12:49.730
<v 2>uh,</v>

215
00:12:49.730 --> 00:12:53.150
<v 1>what that column is.
That's a duplicate.
So that we can then replace it.</v>

216
00:12:53.151 --> 00:12:54.320
So in our case,

217
00:12:54.380 --> 00:12:58.820
some ID is the one duplicates across these two datasets to replace it.

218
00:12:58.880 --> 00:13:03.240
And that's how we merge it.
And the final result,
the integrated,
the integrated

219
00:13:03.350 --> 00:13:05.000
<v 2>uh,
uh,</v>

220
00:13:05.550 --> 00:13:08.790
<v 1>data frame variable is called song df.
And we can look at what this,</v>

221
00:13:08.840 --> 00:13:12.260
what this now looks like.
Okay.
So once we,
um,

222
00:13:14.110 --> 00:13:16.660
once we have that done,
let me,

223
00:13:16.690 --> 00:13:20.230
let me give you guys the full file as well.
Uh,
yeah.

224
00:13:20.231 --> 00:13:24.760
Let me give you guys a full file.
Hold on a second.
So you guys have everything.

225
00:13:25.450 --> 00:13:29.530
So
check this out.
So

226
00:13:31.920 --> 00:13:35.670
here's the full file,
which I haven't paced that.
I was just

227
00:13:37.920 --> 00:13:38.753
<v 0>okay,</v>

228
00:13:39.050 --> 00:13:43.890
<v 1>sure that each it,
okay.
So here's the,
here's the data.
Okay.</v>

229
00:13:43.920 --> 00:13:48.030
So let's see what,
what it is.
We have an index.
We have a user id,

230
00:13:48.740 --> 00:13:52.160
a song.
It was encounter title,
release artist's name,

231
00:13:52.190 --> 00:13:55.450
and what do we want to do?
We want to,

232
00:13:55.490 --> 00:13:58.670
it is very similar to an inner join in SQL.
Exactly.

233
00:13:59.590 --> 00:14:03.890
But it's using pandas.
It's the same conceptual idea.
It's not SQL,

234
00:14:03.891 --> 00:14:08.430
but it's conceptually the same.
Exactly.
Well,
so someone asks,

235
00:14:08.450 --> 00:14:12.740
what teachers should we be using?
And that's a great question.
So

236
00:14:14.050 --> 00:14:15.340
with deep learning,

237
00:14:16.090 --> 00:14:19.930
architecture engineering is the new feature engineering.
Okay.

238
00:14:19.960 --> 00:14:22.570
If there's anything you guys remember from this session,

239
00:14:22.930 --> 00:14:26.560
remembered that architecture engineering is the new feature engineer.

240
00:14:26.830 --> 00:14:30.370
That means that all of that engineering complexity that we had to do,

241
00:14:30.400 --> 00:14:33.030
thinking about what teachers are relevant and what features aren't,

242
00:14:33.850 --> 00:14:34.541
doesn't matter.

243
00:14:34.541 --> 00:14:38.740
Because with deep learning it learns the high level features from whatever

244
00:14:38.741 --> 00:14:43.030
features we give it.
More or less,
there are some caveats.
Okay.
More or less,

245
00:14:43.450 --> 00:14:44.290
but it learns those.

246
00:14:44.291 --> 00:14:47.950
And so the complexity that moves to the architecture rather than hand tuning

247
00:14:47.951 --> 00:14:52.730
features for hand tuning models,
what are the hyper parameters?
What are the,

248
00:14:52.790 --> 00:14:54.350
you know,
uh,
type,

249
00:14:54.380 --> 00:14:58.460
what is the type of neural network one he used for this specific data set?
Okay.

250
00:14:58.670 --> 00:15:03.050
So in our case,
what we want to do is we want to predict a song or a user,

251
00:15:03.110 --> 00:15:05.720
the songs,
sorry.
Plurals songs.

252
00:15:06.080 --> 00:15:09.590
That's uh,
this user will like,

253
00:15:09.800 --> 00:15:12.410
we don't want to predict artists,
we just want to predict song.

254
00:15:12.411 --> 00:15:16.010
So what is something we could do that could just make it easier for us to look

255
00:15:16.011 --> 00:15:20.510
at and just make it easier for our model in general?
Well,
why don't we just,

256
00:15:20.630 --> 00:15:24.770
why don't we do so the first part of this is why don't we do,

257
00:15:25.130 --> 00:15:27.710
we're going to be doing the data transformation step.

258
00:15:27.711 --> 00:15:29.870
We've already integrated our data into one file.

259
00:15:30.050 --> 00:15:31.730
The next step would be to clean our data,

260
00:15:31.880 --> 00:15:35.840
but we are getting at is relatively clean.
I mean there's not any really,
it's,

261
00:15:36.000 --> 00:15:40.250
it's a relatively clean data set.
So let's just move right on to transformation.

262
00:15:40.270 --> 00:15:44.360
And the transformation we're going to do here is we're going to combine the song

263
00:15:44.410 --> 00:15:47.780
and the artists are columns together because we don't care about the artists,

264
00:15:47.781 --> 00:15:50.600
we just care about the song.
So just for simplicity sake,

265
00:15:50.810 --> 00:15:53.060
let's just go and combine these two columns.

266
00:15:53.270 --> 00:15:57.100
So what's happening here is the first thing it's doing is it is,
um,

267
00:15:58.910 --> 00:16:01.910
it is going to put,
we're going to create a subset of the data.

268
00:16:02.030 --> 00:16:05.120
So the first 10,000 songs,
that's what we're going to focus on.

269
00:16:05.300 --> 00:16:08.390
The first 10,000 songs,
we're going to merge the song,

270
00:16:08.750 --> 00:16:12.350
the song and the artist title into one color.
Okay?

271
00:16:12.410 --> 00:16:14.300
So it's one column that we're going to focus on.

272
00:16:14.810 --> 00:16:17.780
Now we're going to show the most popular songs in the Dataset.

273
00:16:17.840 --> 00:16:18.880
So what does that look like?

274
00:16:19.280 --> 00:16:22.520
We're going to group them by the listen count and the percentage.

275
00:16:22.521 --> 00:16:26.570
So there are four lines here.
Let's,
let's,
let's,
uh,
hey quantum,

276
00:16:26.571 --> 00:16:31.030
really appreciate it
Mikael.
Really appreciate it.
Okay,

277
00:16:31.031 --> 00:16:35.020
so we're going to show these most popular songs.
Okay,

278
00:16:35.050 --> 00:16:38.820
so we're going to start off with this is what it looks like,
but let's,
let's,

279
00:16:38.821 --> 00:16:41.260
let's talk about these four lines of code in detail.
So we're going to,

280
00:16:41.590 --> 00:16:46.090
so let's talk about [inaudible].
So what we're going to do is we're going to say,

281
00:16:46.840 --> 00:16:50.590
uh,
what this does is it groups.

282
00:16:50.650 --> 00:16:54.430
So the first line is it groups them in order of listen,
count,
descending,
okay,

283
00:16:54.431 --> 00:16:55.264
but,
but listen,
count.

284
00:16:55.390 --> 00:16:59.860
Then it gets a total sum of listen counts to calculate the percentage and that

285
00:16:59.861 --> 00:17:01.600
is what's on this right hand column.

286
00:17:02.020 --> 00:17:05.950
Then it's going to add a new column called percentage two to calculate that

287
00:17:05.951 --> 00:17:07.660
percentage.
It,
it,
it,
it,

288
00:17:07.680 --> 00:17:10.900
it summed up all those listen counts and it had to calculate the percentage and

289
00:17:10.901 --> 00:17:14.500
it does this by dividing by listen count times a hundred and that's going to

290
00:17:14.501 --> 00:17:19.260
give us this 0.4 5.32 and then finally it's going to list them in,
uh,

291
00:17:20.110 --> 00:17:22.090
the most popular songs at the top.
Okay,

292
00:17:22.091 --> 00:17:24.400
so now we have this subset of data and this,

293
00:17:24.610 --> 00:17:26.530
now this is what we're talking about,
right?
We wanted,

294
00:17:26.590 --> 00:17:30.310
we wanted something really simple for us to look at for us to understand.

295
00:17:30.490 --> 00:17:34.670
Now if we really wanted to,
we did it have to do this though we didn't have to,

296
00:17:34.880 --> 00:17:38.600
but it's simpler to look at.
Okay.
And model will likely be more accurate.

297
00:17:38.630 --> 00:17:40.640
And just because,
and another thing,

298
00:17:40.670 --> 00:17:44.510
just because a feature engineering isn't as relevant with deep learning,

299
00:17:44.810 --> 00:17:48.020
that doesn't mean that we shouldn't engineer our features at all.

300
00:17:48.140 --> 00:17:49.530
You don't like for simplicity sake,

301
00:17:49.710 --> 00:17:52.860
having this is just simpler to look at and it helps.

302
00:17:53.070 --> 00:17:56.310
Now it's [inaudible]. [inaudible] helps.
Okay.
And the,

303
00:17:56.311 --> 00:17:58.260
and whatever you do can have a difference.

304
00:17:58.380 --> 00:18:01.440
Can get that last mile difference between,
you know,

305
00:18:01.441 --> 00:18:05.820
your model being 98% and 99% accurate.
If you're trying to get there,
then yeah,

306
00:18:05.850 --> 00:18:08.610
go ahead and,
and make it more simple.
Okay.
So that can we did for that.

307
00:18:09.870 --> 00:18:14.610
When do we hit get to hear the choir?
Uh,
Fredrick,
we'll talk about that later.

308
00:18:14.990 --> 00:18:18.570
Uh,
okay.
So,
so that's that.
Now let's keep on going.

309
00:18:18.571 --> 00:18:20.910
We haven't actually done any recommendations there.
We're just,

310
00:18:21.120 --> 00:18:24.620
we're just doing some data.
Preprocessing.
What do I mean by listen,
count.
Listen,

311
00:18:24.621 --> 00:18:29.621
tell is a number of times each song was listened to in general by all of users.

312
00:18:30.810 --> 00:18:31.620
Okay.

313
00:18:31.620 --> 00:18:35.910
Because we're going to start off with a very naive approach for recommendations

314
00:18:36.270 --> 00:18:38.280
of very naive approach.
Okay?

315
00:18:38.281 --> 00:18:41.940
So let's count the number of unique users in the Dataset.
Okay.
To do this,

316
00:18:41.941 --> 00:18:46.680
we'll say,
okay,
what is the number of unique values?
Really Handy,
uh,

317
00:18:47.310 --> 00:18:50.130
method right here.
Unique.
Okay.
And then we say,
okay,

318
00:18:50.131 --> 00:18:55.131
well those 365 users and does dataset just so we know how many users there are.

319
00:18:55.380 --> 00:18:58.680
And whenever you're looking at a Dataset,
be sure to look at these things.
Okay?

320
00:18:58.790 --> 00:19:03.270
You use I python notebooks.
Look at all of your columns,
analyze your data,

321
00:19:03.390 --> 00:19:06.590
see what tells you that there are,
what count of everything there is.

322
00:19:07.050 --> 00:19:10.030
What is the percentage?
Shouldn't it?
Psalm two,
one,
um,

323
00:19:14.970 --> 00:19:18.480
nope.
No,
so the percent,
it's not,
it's not percentage.
Uh,

324
00:19:18.510 --> 00:19:23.130
in relation to a all songs,
it's percentage in relation to,

325
00:19:23.610 --> 00:19:25.290
uh,
hold on.

326
00:19:27.730 --> 00:19:28.563
<v 0>Okay.</v>

327
00:19:28.740 --> 00:19:32.040
<v 1>Actually hold on a second.
You are right.</v>

328
00:19:32.200 --> 00:19:36.340
This code needs to be recompiled this,
this needs to be recompiled it.

329
00:19:36.341 --> 00:19:41.160
So the percentage here,
it needs to be altered,
so,
so good.
Good,
good call.
Uh,
Tina.

330
00:19:41.890 --> 00:19:46.150
Good call.
Yeah.
Okay.
So,
but anyway,

331
00:19:46.151 --> 00:19:50.450
so let's keep going.
That's the basic idea.
Okay.

332
00:19:50.451 --> 00:19:53.530
So we're going to count up the number of unique songs of the day is had 5,000,

333
00:19:53.531 --> 00:19:56.780
about 5,000.
And now we're going to create a song recommender.
Okay.

334
00:19:56.840 --> 00:20:01.010
So the first thing we'll do is we're going to split it into training and testing

335
00:20:01.011 --> 00:20:05.630
data and we're going to use a train test split functions from Psych Hitler.
Okay.

336
00:20:05.660 --> 00:20:06.980
That's what's I kept learning.
Gives us,

337
00:20:07.130 --> 00:20:10.430
whenever we do any machine learning before we train our model.

338
00:20:10.460 --> 00:20:15.380
And the thing we always want to split our data into training and testing data,

339
00:20:15.500 --> 00:20:20.240
okay?
That's what we want to do.
And we're going to end,
we're saying arbitrarily,

340
00:20:20.241 --> 00:20:25.241
let's pick 20% as our testing sites and then it'll know that 80% is our training

341
00:20:26.091 --> 00:20:30.530
size.
Okay?
So there's that.
Now lets,
it says,
okay,
so sim,

342
00:20:30.560 --> 00:20:35.030
so the first thing it's doing here is it saying simple popularity recommended

343
00:20:35.031 --> 00:20:37.160
class can be used as a black box.
Well,

344
00:20:37.161 --> 00:20:38.540
we're not going to look at it as a black box.

345
00:20:38.541 --> 00:20:42.080
We're going to look at this code in a second,
okay?
But what it does,
it says,
okay,

346
00:20:42.200 --> 00:20:45.950
based on the popularity of each song,

347
00:20:47.220 --> 00:20:51.400
uh,
create a recommender based on this training data and then printout per user

348
00:20:51.401 --> 00:20:54.430
five.
Given this user id,
what are the recommended songs?

349
00:20:54.460 --> 00:20:57.130
And it's going to print out.
So what does this look like in code?

350
00:20:57.131 --> 00:21:00.280
So to look at this in code,
let's,
let's look at this class.
Okay.

351
00:21:00.281 --> 00:21:03.960
So we're going to look at this class actually.
So let me go right into this.

352
00:21:03.980 --> 00:21:07.510
This class.
So in this recommenders file,
right?
So what is this?

353
00:21:07.660 --> 00:21:12.180
What is this metadata loop looking at?
Let's look at this together.
Recommenders,

354
00:21:12.181 --> 00:21:15.690
popularity recommender pop.
Okay,
let's look at what that is here.

355
00:21:15.810 --> 00:21:19.680
So this is the recommenders file and now we want to look at the popularity

356
00:21:19.740 --> 00:21:23.850
recommenders class.
So where is that?
Okay,
here it is.

357
00:21:23.851 --> 00:21:27.050
Popularity recommended me.
Let me,
let me increase the size of this.

358
00:21:27.300 --> 00:21:31.020
So let's just look at this.
Create a function.
Okay,
so what is it doing here?

359
00:21:31.021 --> 00:21:32.730
And this is what it's doing.
Okay,

360
00:21:32.731 --> 00:21:36.240
so this is a very naive approach.

361
00:21:36.420 --> 00:21:39.840
It's not personalized.
What it does is it says,
okay,

362
00:21:39.841 --> 00:21:41.940
based on your training data and then user id,

363
00:21:42.270 --> 00:21:46.630
we want to get account of the user ids for each unique song as a recommendations

364
00:21:46.631 --> 00:21:47.640
for.
Okay?

365
00:21:47.641 --> 00:21:52.200
So basically what it's saying is how many times have had each song,

366
00:21:52.830 --> 00:21:57.390
has each song been listened to and then sort the songs based on a recommendation

367
00:21:57.391 --> 00:22:00.300
score.
Now what does that recommendation score it?

368
00:22:00.390 --> 00:22:05.390
The recommendations for is given by the,

369
00:22:06.310 --> 00:22:09.870
the score that the user at the scoring that user gave it.

370
00:22:10.560 --> 00:22:12.450
And we can find that for them,

371
00:22:14.480 --> 00:22:16.040
the score that the user gave it.

372
00:22:24.040 --> 00:22:28.120
So we're calculating the score by the number of times that a song has been

373
00:22:28.121 --> 00:22:32.110
listened to in general.
And that is that metric that we're using for the score.

374
00:22:32.320 --> 00:22:36.340
That's it.
Then we rank those.
So we,
so we,
so we rank those in order.

375
00:22:36.520 --> 00:22:37.840
So all it's doing,

376
00:22:38.290 --> 00:22:42.580
all this is doing is giving you for any user,

377
00:22:42.820 --> 00:22:47.700
the top 10 recommended songs in general.
And it doesn't focus on the user.

378
00:22:47.730 --> 00:22:51.250
Okay.
It's not focused on you,
it doesn't care about you.
It doesn't care.

379
00:22:51.251 --> 00:22:53.620
I care about you,
but it doesn't care about you.
Okay.
I'm sorry,

380
00:22:54.340 --> 00:22:56.020
but that's just like,
okay.

381
00:22:56.530 --> 00:23:00.280
But it's saying what are those top 10 songs that are going to be recommended to

382
00:23:00.281 --> 00:23:04.900
you?
And those top 10 songs are just in general,

383
00:23:04.901 --> 00:23:06.940
they're just the most popular songs.
There's no,

384
00:23:06.970 --> 00:23:10.270
there's no personalization happening here.
This is the naive approach.

385
00:23:10.420 --> 00:23:13.780
So if we give it user five it's going to say,
okay,
you're the top 10 songs.

386
00:23:13.960 --> 00:23:17.530
Harmonia undo,
and then dog dates.
Okay.
Well,

387
00:23:17.531 --> 00:23:22.480
what about for user eight harmonia undo and dog days.

388
00:23:22.780 --> 00:23:25.870
It doesn't care about the user.
That's a naive approach.
Okay.

389
00:23:26.020 --> 00:23:28.570
And this is before machine learning.
So we wanted to show that.

390
00:23:28.630 --> 00:23:32.770
I want to show the most trivial case before we do machine learning.
Okay.

391
00:23:32.950 --> 00:23:34.480
That was the most trivial case.

392
00:23:34.780 --> 00:23:38.260
Now we're going to focus on exactly Tevin.

393
00:23:38.270 --> 00:23:42.820
It's the top cabinet.
It's the top 10 songs based on the listened cap.
Okay.

394
00:23:47.290 --> 00:23:51.540
Oh,
we're going to focus on the personalization kid.
Okay.
This is,

395
00:23:51.750 --> 00:23:53.640
now we're going to talk about some machine learning.
Okay,

396
00:23:53.641 --> 00:23:56.610
you guys ready for this?
So to talk about two machine learning.
Okay.

397
00:23:58.160 --> 00:24:00.110
Now we're going to do a different type of recommender system.

398
00:24:00.140 --> 00:24:02.840
It is called an item similarity.

399
00:24:03.260 --> 00:24:06.800
The top songs are based on just listen.
That's it.
So far,

400
00:24:07.190 --> 00:24:10.340
hacker Heco or awkward listen cap.
Okay,

401
00:24:10.430 --> 00:24:15.410
so this on items,
similarity based recommender systems.

402
00:24:15.890 --> 00:24:19.970
What the hell is this?
Let's talk about this.
So

403
00:24:22.080 --> 00:24:26.940
here is a great website.
So there are two types of,

404
00:24:27.450 --> 00:24:30.180
so there are two types of recommender systems.
Okay?

405
00:24:30.360 --> 00:24:34.510
There are content based and collaborative base content based.

406
00:24:34.560 --> 00:24:37.170
Predict what you like based on what you'd like in the past.

407
00:24:37.440 --> 00:24:42.440
Collaborative systems predict what you like based on what other users liked.

408
00:24:43.080 --> 00:24:48.060
Now,
most major services like Netflix and Hulu,
you say hybrid approach.

409
00:24:48.150 --> 00:24:49.460
So it's not just what you like,

410
00:24:49.490 --> 00:24:52.500
it's what you liked in the past and what other users like.

411
00:24:52.640 --> 00:24:54.870
And it combines those approaches in a,
in a,
in a way.

412
00:24:54.871 --> 00:24:58.510
But right now we're going to focus on collaborative,
uh,

413
00:24:58.640 --> 00:25:00.960
Sung Sung ground.
You're not too late.

414
00:25:01.260 --> 00:25:04.470
Right now we're going to focus on a collaborative approach and we can split the

415
00:25:04.471 --> 00:25:09.210
collaborative approach into two different approaches.
Okay.
Item item,

416
00:25:09.211 --> 00:25:13.380
collaborative and user item collaborative.
Let's talk about each.
Okay,

417
00:25:14.250 --> 00:25:17.350
so let's talk about,
um,

418
00:25:17.820 --> 00:25:21.870
let's see which one do we want to talk about first we want to talk about item

419
00:25:21.871 --> 00:25:26.570
item.
Okay,
so let's talk about this.
So user items.

420
00:25:26.571 --> 00:25:30.530
So what is user item collaborative approach look like?
Well,
look at this.

421
00:25:30.650 --> 00:25:34.550
We're creating a matrix of values.
So for each user here,

422
00:25:34.860 --> 00:25:38.360
we list their rating for each item.
So you know this,

423
00:25:38.650 --> 00:25:41.300
this user right here would let me share this link as well.

424
00:25:44.900 --> 00:25:49.640
Okay.
Check out that link.
So this user,
all the items that they like,

425
00:25:49.670 --> 00:25:52.460
okay,
all the heightened that this next,
you're like all of these items,

426
00:25:52.520 --> 00:25:54.950
this snack,
these are like from this matrix,

427
00:25:54.951 --> 00:25:59.600
we're going to calculate the similarity.
Now that's is a user items,

428
00:26:00.470 --> 00:26:03.260
okay?
And we're going to talk about that now.
This is item item,

429
00:26:03.500 --> 00:26:07.160
collaborative filtering,
it filtering.
So this is what item item looks like.

430
00:26:07.190 --> 00:26:09.560
So let's just look into the code because that's what we're about to do.

431
00:26:09.620 --> 00:26:12.170
Item item.
So it's saying,
okay,

432
00:26:12.171 --> 00:26:17.110
so Craig is items similarity recommender initialize this class and then creative

433
00:26:17.120 --> 00:26:20.750
for a user and then print out the recommendations.
So let's look at this code.

434
00:26:20.751 --> 00:26:25.550
Okay,
what is this code doing?
So,
okay,
so here we are in item,

435
00:26:25.870 --> 00:26:29.810
uh,
in items similarity recommender.
Okay,

436
00:26:29.840 --> 00:26:33.620
so let's look at what it's doing here.
There's a bunch of these helper methods.

437
00:26:33.621 --> 00:26:37.130
But what is,
what is that main method that we're looking at?
Okay,

438
00:26:37.220 --> 00:26:40.850
what is that main method?
The main method is,
okay,
right here,

439
00:26:40.851 --> 00:26:43.380
generate the top recommendations.
Okay,

440
00:26:47.500 --> 00:26:48.071
so here we go.

441
00:26:48.071 --> 00:26:52.720
So the first thing it's doing is this going to create a co occurrence matrix?

442
00:26:53.430 --> 00:26:56.290
Okay.
That's what it's doing is create a co occurrence matrix.

443
00:26:56.470 --> 00:27:00.820
Let's talk about what a co occurrence matrix is.
A co-occurrence Matrix.

444
00:27:00.821 --> 00:27:05.250
Here's an example.
Let's assume that someone,

445
00:27:05.340 --> 00:27:08.940
a bunch of users bought a bunch of different products.
So what we would say is,

446
00:27:09.120 --> 00:27:13.050
let's see this,
this is the one right here.
So for,

447
00:27:13.080 --> 00:27:17.130
so for each product,
what is the likelihood that I use are also brought,

448
00:27:17.131 --> 00:27:21.930
the bottle is not a it for each user.
How many times,

449
00:27:22.490 --> 00:27:26.790
let me repeat it one more time.
I'm down for each product.

450
00:27:26.970 --> 00:27:31.500
What is the number of times that a user who bought that said product but another

451
00:27:31.501 --> 00:27:32.760
product?
Okay.

452
00:27:32.790 --> 00:27:37.790
So for product 1001 that user bought whatever the number of times we've brought

453
00:27:37.880 --> 00:27:41.190
1001 they bought a thousand to one time,
they bought 1,003,

454
00:27:41.220 --> 00:27:45.840
three times where we are creating a co occurrence matrix.
Okay?

455
00:27:47.420 --> 00:27:51.910
So uh,
co-occurrence matrix in our case would be for item items.
So,

456
00:27:52.420 --> 00:27:56.420
but for,
for so songs,
songs or items in our case,

457
00:27:56.570 --> 00:28:00.920
songs or items.
Okay.
So we are creating a matrix of songs.

458
00:28:01.640 --> 00:28:01.851
Okay.

459
00:28:01.851 --> 00:28:06.680
So we want to calculate the weighted average of the scores in a co occurrence

460
00:28:06.681 --> 00:28:08.930
matrix for all users songs.

461
00:28:09.560 --> 00:28:14.510
Then we're going to sort the indices based upon their value and maintain the

462
00:28:14.511 --> 00:28:16.940
corresponding sport so big.

463
00:28:16.970 --> 00:28:21.020
So we pretty a cove occurrence matrix of songs that user's life.
Okay.

464
00:28:21.021 --> 00:28:26.021
So basically based on what songs you've liked in the past,

465
00:28:27.170 --> 00:28:30.410
we can see those,
those top songs that you've liked.

466
00:28:30.680 --> 00:28:34.670
And then based on those top songs,
what are the users that liked that,

467
00:28:34.700 --> 00:28:38.600
those songs the most?
And then what are those songs that they liked the most?

468
00:28:38.720 --> 00:28:42.740
So it's kind of like a second order.
Uh,
we're,
it's like a second order function.

469
00:28:43.670 --> 00:28:47.270
How is it co-occurrence matrix different from a normal matrix,
Rick question?

470
00:28:47.480 --> 00:28:47.980
Well,

471
00:28:47.980 --> 00:28:52.980
I mean a normal matrix is just a matrix of users and songs and a bunch of other

472
00:28:54.141 --> 00:28:58.250
features.
A co-occurrence matrix if you're taking the same,

473
00:28:59.330 --> 00:29:03.320
the same value for both our,
our rows and columns.

474
00:29:03.440 --> 00:29:07.220
So it would be songs and songs.
Okay.
So based on this song,

475
00:29:07.221 --> 00:29:11.450
how many sometime did you like what other set of songs?
Okay,

476
00:29:11.540 --> 00:29:13.940
so we're creating a co occurrence matrix

477
00:29:15.470 --> 00:29:19.970
and based on what you liked in the past,
other users,
uh,

478
00:29:20.220 --> 00:29:23.120
what you've gotten past,
what are the most likely,

479
00:29:23.210 --> 00:29:27.470
the other songs you'll like based on what other similar users have lacked.
Okay,

480
00:29:27.471 --> 00:29:31.670
so that is what we did for the personalize song.
Okay.

481
00:29:31.700 --> 00:29:35.570
And they tend to be sparse matrices.
Kyle,
great insight.

482
00:29:36.140 --> 00:29:38.090
These coke,

483
00:29:38.120 --> 00:29:42.820
these co-occurrence matrices tend to be sparse because not all because?

484
00:29:43.090 --> 00:29:47.740
Because why is that?
Because the base,

485
00:29:47.950 --> 00:29:50.530
the space of possible possible songs,

486
00:29:50.560 --> 00:29:55.560
it's so bad that you can't just say that whoever likes this song is going to

487
00:29:55.601 --> 00:29:58.450
like every other song,
right?
There are millions of songs out there.

488
00:29:58.480 --> 00:30:01.900
So whenever we're dealing with recommender systems,
we have,

489
00:30:01.960 --> 00:30:06.870
we tend to have lot of sparsity more so than I've seen in a lot of other

490
00:30:06.871 --> 00:30:07.704
applications.

491
00:30:07.740 --> 00:30:11.280
So this is one of those fields where dealing with sparsity is very important.

492
00:30:13.160 --> 00:30:17.900
Here's what the result of doing that gave us.
He's with the resolve gave us,

493
00:30:17.930 --> 00:30:20.900
they gave us this list of scores.
Now we can rank things.
Okay.

494
00:30:20.901 --> 00:30:25.220
And we rate these up to 10 and that's going to be our recommendations.

495
00:30:25.580 --> 00:30:26.960
So that is one.

496
00:30:27.840 --> 00:30:28.250
<v 0>Okay.</v>

497
00:30:28.250 --> 00:30:31.580
<v 1>Is it feasible to have a matrix with such huge dimensions?
Yes,</v>

498
00:30:31.640 --> 00:30:33.740
and we routinely do in data science.

499
00:30:33.980 --> 00:30:38.060
We routinely have huge ass matrices.
Okay.

500
00:30:38.210 --> 00:30:41.210
We routinely have huge asked me to see that we load into memory.

501
00:30:41.630 --> 00:30:43.940
I'm sure there are better ways,
just like there are,

502
00:30:44.150 --> 00:30:48.410
there must be better ways or um,
sampling data then uniformly random.

503
00:30:48.470 --> 00:30:49.700
But we just,
you know,

504
00:30:49.760 --> 00:30:52.610
we're moving fast and we need people to be focusing on these things.

505
00:30:52.910 --> 00:30:57.800
But right now,
yes,
we just load the entire fucking matrix into writing.
Okay.

506
00:30:57.830 --> 00:30:59.630
So that is that.

507
00:30:59.810 --> 00:31:04.040
Now we've got a personalized model and this is just repeating the same thing for

508
00:31:04.041 --> 00:31:08.030
different user.
Okay.
Let's keep on going here.
Let's keep on going.
Okay.

509
00:31:09.610 --> 00:31:13.750
And we could use the same matrix for socks.
So based on a song,

510
00:31:13.960 --> 00:31:18.130
what is it similar saga?
Like what,
why?
Because,
well,
the first one you say,

511
00:31:18.260 --> 00:31:19.780
you know,
second order it looked at,

512
00:31:19.810 --> 00:31:23.170
not just as something to use the co-occurrence major to see based on the songs

513
00:31:23.171 --> 00:31:24.970
with you,
what users like.
Now this is just looks,

514
00:31:25.050 --> 00:31:28.780
looks at a raw song makers and gives us the course for that.

515
00:31:29.200 --> 00:31:32.920
Now this is not using deep learning.
I want to say that right up front,

516
00:31:32.980 --> 00:31:35.860
right up front.
This is not using deep learning.

517
00:31:35.890 --> 00:31:40.840
It's just using a linear Algebra and matrices.
Okay.

518
00:31:41.050 --> 00:31:44.620
That all using and we can get good results from this.
Okay.

519
00:31:49.330 --> 00:31:53.470
Okay.
So some people are saying that they prefer it when I Code and uh,

520
00:31:53.471 --> 00:31:56.240
I got feedback last time that they prefer it when I don't code.

521
00:31:56.350 --> 00:31:57.310
So we're going to see,

522
00:31:57.311 --> 00:32:01.060
we're going to see this is the first live stream I've ever done or I'm not doing

523
00:32:01.270 --> 00:32:03.040
any code,
I'm just having it there.

524
00:32:03.190 --> 00:32:05.710
So I'm going to see feedback based on this and an overall,

525
00:32:05.711 --> 00:32:07.360
I'll decide how to move forward.

526
00:32:07.361 --> 00:32:10.960
Like I already decided this live stream not to ever use obs ever again.

527
00:32:11.170 --> 00:32:13.960
So that was one thing.
And then based on the feedback in general from here,

528
00:32:13.961 --> 00:32:18.730
I'm going to decide if I'm going to a code next time or just look at it like

529
00:32:18.731 --> 00:32:23.260
this.
Okay.
So we'll see.
So,
so make sure to give me your feedback.

530
00:32:23.530 --> 00:32:26.890
Brutal honesty back.
You know,
you know me guys,
you know how I love it.
Okay.

531
00:32:27.520 --> 00:32:31.910
I'm here waiting for you to code.
Okay.
Okay.

532
00:32:31.911 --> 00:32:35.570
We are going to,
we're going to get to deep learning.
Okay.

533
00:32:37.420 --> 00:32:41.030
Clone yourself and do both.
I wish that was coding is better.
Okay,

534
00:32:41.750 --> 00:32:46.360
I'm going to put the notebook.
All right.
Coding is you.
Yeah.
Yeah.

535
00:32:46.420 --> 00:32:51.280
Okay.
Okay.
So,
okay,
so I'm going to coat
omics,

536
00:32:51.670 --> 00:32:56.480
omics,
coding.
All right.
It's getting difficult to Paul.
Okay.
Okay.
So,

537
00:32:56.481 --> 00:32:59.950
okay,
so everybody wants to tell it.
Okay.
Okay.
Clearly.
Okay.
Okay guys.
Okay.
Okay.

538
00:32:59.951 --> 00:33:04.850
Okay.
You guys miss me?
I promise that next live stream I will code.

539
00:33:04.860 --> 00:33:05.360
Okay.

540
00:33:05.360 --> 00:33:08.900
But it's just that this one I set up so that I don't code because that was the

541
00:33:08.901 --> 00:33:12.170
feedback that I got.
Overwhelming feedback.
Okay.
So,

542
00:33:12.260 --> 00:33:15.620
but now I'm promise I'm going to code from now on moving forward,

543
00:33:15.621 --> 00:33:17.700
but let's just keep going with this.
Okay.
Um,

544
00:33:22.270 --> 00:33:27.230
God damn.
People are just going back and forth.
Yeah.

545
00:33:27.231 --> 00:33:29.730
Okay.
We'll have a call.
We'll have a call.
That's a good idea.
He attached.

546
00:33:29.810 --> 00:33:33.470
Great idea.
We'll have a port.
Let's keep going.
So,
okay,
what are we doing here?

547
00:33:33.620 --> 00:33:36.200
Okay,
so we've,
we've done our uh,

548
00:33:36.500 --> 00:33:40.340
personalized item based collaborative filtering.
Okay.

549
00:33:40.790 --> 00:33:43.820
Now we're going to do with called calculate the,

550
00:33:43.850 --> 00:33:47.420
we want to measure the performance of our two model.
What was our first model?

551
00:33:48.410 --> 00:33:50.820
The first model was we want we,

552
00:33:50.850 --> 00:33:54.190
the first model was a not based on you at all.
I remember it.

553
00:33:54.191 --> 00:33:55.970
It was just based on the popularity of a song.

554
00:33:56.330 --> 00:34:00.440
The next model was based on you using a co-occurrence Matrix,
right?

555
00:34:00.441 --> 00:34:02.720
It was a collaborative filtering model.

556
00:34:02.840 --> 00:34:06.500
Now how are we going to measure the performance of these two models?
Okay.

557
00:34:07.040 --> 00:34:08.460
The poll will be 50,
50 grade.

558
00:34:08.870 --> 00:34:10.910
How are we going to measure the performance of these two models?

559
00:34:11.180 --> 00:34:14.270
We're going to use something called precision recall.
Now,

560
00:34:14.271 --> 00:34:16.550
what does precision recall look like?
Let's look at this.

561
00:34:17.150 --> 00:34:19.760
Precision recall is a good way of

562
00:34:21.320 --> 00:34:25.340
of measuring the value of our recommender system.

563
00:34:25.341 --> 00:34:27.740
Now I have gotten a great link for this.

564
00:34:27.920 --> 00:34:31.760
Then I'm going to throw up on the screen here.
Let me,
let me find this link.

565
00:34:31.970 --> 00:34:36.260
It's an awesome link.
Okay,
here it is.
And let me,

566
00:34:36.290 --> 00:34:40.530
let me paste it for you guys too.
Okay,

567
00:34:40.531 --> 00:34:43.440
so check out this link.
I'm going to throw it up.
Okay.

568
00:34:43.800 --> 00:34:48.000
So what is precision recall?
Let me,
let me blow up this.
Uh,
this image.

569
00:34:48.720 --> 00:34:53.700
This is what it is.
So there are two metrics here.
Precision and recall.

570
00:34:53.970 --> 00:34:58.320
Okay,
so precision and recall,
precision is the

571
00:34:59.820 --> 00:35:03.610
based on some,
so let me,
let me hold on a second.

572
00:35:06.040 --> 00:35:10.060
Precision is the proportion of top results that are relevant considering some

573
00:35:10.061 --> 00:35:12.850
definition of relevance to our problem domain.

574
00:35:13.120 --> 00:35:16.000
What is that definition of relevant to our problem domain?

575
00:35:16.720 --> 00:35:20.690
It could be the number of times a song has been listened to.
It could be a,

576
00:35:20.890 --> 00:35:22.450
the number of users that

577
00:35:23.120 --> 00:35:23.953
<v 0>mmm.</v>

578
00:35:25.400 --> 00:35:28.640
<v 1>Have all liked the song.
Some value of relevancy.
Okay.</v>

579
00:35:28.641 --> 00:35:32.990
That we're going to define and recall is that would measure the proportion of

580
00:35:33.110 --> 00:35:37.530
all relevant Saul results included in the top results.
Okay,

581
00:35:37.531 --> 00:35:42.531
so they're measuring the relevancy of songs in relation to the precision in

582
00:35:43.351 --> 00:35:48.351
relation to the top 10 results and then recall is how good are they in relation

583
00:35:49.771 --> 00:35:53.490
to all of the songs.
So there are two different measures.
Okay.

584
00:35:53.580 --> 00:35:56.340
There are two different measures.
Okay.

585
00:35:56.730 --> 00:35:59.310
So I promise.
Next live stream,

586
00:35:59.311 --> 00:36:02.370
I'm going to code every single bit.
Okay.

587
00:36:02.940 --> 00:36:07.110
I promise because you know I every live stream,
I have coded everything.
Okay?

588
00:36:07.230 --> 00:36:09.690
So I will continue to do that.
That's where I feel most at home.

589
00:36:09.990 --> 00:36:12.900
I'm just going to do it this way this one time.
All right,
so

590
00:36:15.110 --> 00:36:18.290
we're going to use precision and recall to calculate this.

591
00:36:18.410 --> 00:36:21.870
Now we've got a class that does this.
Okay?

592
00:36:22.090 --> 00:36:26.790
Then when we get to the graph,
we're going to plot the graph.

593
00:36:26.850 --> 00:36:29.940
This is what it looks like.
This is what it looks like.
So precision is the y.

594
00:36:29.941 --> 00:36:33.030
Access and recall is the x access.

595
00:36:33.990 --> 00:36:36.750
And what it looks like is,
let me,
let me make this bigger,

596
00:36:38.800 --> 00:36:43.800
but it looks like is it looks pretty much like the item similarity model has

597
00:36:45.141 --> 00:36:50.120
higher values for recall and precision up up to a certain point.

598
00:36:50.150 --> 00:36:52.590
So basically this tells us that more items,

599
00:36:52.591 --> 00:36:54.890
similarity model is better than our popularity mom.

600
00:36:54.980 --> 00:36:59.480
It's more accurate now I'm it made a great point.

601
00:36:59.870 --> 00:37:04.790
Uh,
f one score is also a good measure.
Okay,

602
00:37:04.810 --> 00:37:08.940
there are there,
there's several.
Precision is one.
Recall is another f one score.

603
00:37:08.990 --> 00:37:12.620
There's a lot of ways we could measure how good a

604
00:37:14.370 --> 00:37:17.720
um,
oh good are,
sorry.

605
00:37:17.990 --> 00:37:21.380
How good our model is in relation to another mall.
Okay,

606
00:37:22.280 --> 00:37:24.290
so that was it for our item base.

607
00:37:24.320 --> 00:37:27.920
Now we have one more type of recommender system that we're going to look at.

608
00:37:28.400 --> 00:37:33.110
Now this is a matrix factorization based recommended recommender system.

609
00:37:33.590 --> 00:37:37.270
Okay,
so
what,
so what am I talking?

610
00:37:43.640 --> 00:37:48.610
Awesome.
Okay.
So
wow.

611
00:37:54.190 --> 00:37:56.320
Okay.
DMV calling me.
Okay,
so

612
00:37:58.990 --> 00:38:01.900
now what we're going to do is we're going to create this recommender system.

613
00:38:01.930 --> 00:38:06.220
Okay?
And we're going to talk about Janzen Gans in a second.
But,
okay,

614
00:38:06.221 --> 00:38:09.040
so let's,
my phone is in my year right now.

615
00:38:09.041 --> 00:38:11.640
Can you just start to say,

616
00:38:14.140 --> 00:38:16.390
okay,
so let's,

617
00:38:17.880 --> 00:38:18.550
<v 0>okay,</v>

618
00:38:18.550 --> 00:38:19.990
<v 1>focus on our recommender system.</v>

619
00:38:24.550 --> 00:38:25.840
Okay.
And

620
00:38:31.770 --> 00:38:36.570
<v 0>Yeah,
finally,</v>

621
00:38:36.580 --> 00:38:38.090
all these things out of my year.
So what would you use?

622
00:38:38.260 --> 00:38:42.250
We're going to compute SBD to calculate a recommenders recommendations.

623
00:38:42.251 --> 00:38:45.580
Let's talk about what this is doing.
Okay.
So,

624
00:38:47.250 --> 00:38:51.510
<v 1>uh,
so the,
so the singular value decomposition.
Okay.</v>

625
00:38:51.511 --> 00:38:55.650
So what is this?
It is a matrix a with,
so let me,

626
00:38:55.680 --> 00:38:56.710
let me throw up a,

627
00:38:57.450 --> 00:39:02.450
so the SPD is a way that we can perform matrix factorization,

628
00:39:03.480 --> 00:39:07.290
which is a technique that is used to build recommender systems.
Okay.

629
00:39:07.320 --> 00:39:09.690
So SPD is basically,

630
00:39:09.691 --> 00:39:14.540
it's a matrix and he said factorized matrix of the original similarity makers.

631
00:39:14.550 --> 00:39:18.570
So we'll create some similarity makers and then we'll perform this process right

632
00:39:18.571 --> 00:39:21.420
here in this method called singular value decomposition.

633
00:39:21.660 --> 00:39:25.350
Now what this does is it ultimately outputs three,
okay,

634
00:39:25.590 --> 00:39:29.680
what are these three bounds?
So you s MBT,

635
00:39:29.910 --> 00:39:33.540
you represents user of doctors.
Okay.
Uh,

636
00:39:33.600 --> 00:39:36.780
s represents the,
uh,

637
00:39:39.110 --> 00:39:40.310
item vectors and,

638
00:39:40.990 --> 00:39:45.830
and then VT is points in a two dimensional space.
So,

639
00:39:47.140 --> 00:39:47.890
<v 0>okay.</v>

640
00:39:47.890 --> 00:39:50.780
<v 1>So what we're doing is we're going to use STD to compute rating.</v>

641
00:39:50.800 --> 00:39:54.370
So it's going to,
in vector space,
it's going to create Jews are vectors.

642
00:39:54.460 --> 00:39:58.450
It's gonna create item vectors and instead create a joint embedding vector for

643
00:39:58.451 --> 00:40:00.550
both of them in a two dimensional Spitz.

644
00:40:00.850 --> 00:40:05.380
And we're going to use these vectors to measure the distance from one users.

645
00:40:05.520 --> 00:40:06.353
Uh,

646
00:40:06.500 --> 00:40:06.810
<v 0>okay.</v>

647
00:40:06.810 --> 00:40:09.510
<v 1>One user's preferences and another goose was properties.</v>

648
00:40:09.720 --> 00:40:13.830
And whoever has the smallest distance between users,

649
00:40:13.950 --> 00:40:17.920
we're going to use their songs as recommenders.
Okay.
That's,
that's,
that's,

650
00:40:18.750 --> 00:40:19.650
that's kind of

651
00:40:22.680 --> 00:40:26.780
an explanation that we're talking about.
So it's okay.
It's a,

652
00:40:26.830 --> 00:40:29.430
it's a little like PCA.
Yeah.
It's a little like principal component analysis.

653
00:40:29.431 --> 00:40:30.150
Exactly.

654
00:40:30.150 --> 00:40:34.200
We are vectorizing matress seats or vectorizing matrices and the recruits,

655
00:40:34.320 --> 00:40:38.220
we're computing the distance between major cs.
Uh,
okay.
So

656
00:40:41.450 --> 00:40:43.370
it's,
it's not clustering,
it's,

657
00:40:44.300 --> 00:40:48.540
<v 0>mmm.
Okay.</v>

658
00:40:50.920 --> 00:40:55.370
<v 1>Hold on.
Okay.
So,
so let's see what we have here.</v>

659
00:40:55.460 --> 00:40:58.070
Do I have any links for STDs?
So,

660
00:41:00.330 --> 00:41:02.040
so,
so this,
this,
this whole,

661
00:41:02.310 --> 00:41:05.730
this whole method here of computing the SPD and then using it to estimate

662
00:41:05.731 --> 00:41:10.290
ratings is how Matrix factorization is used to recommend,

663
00:41:10.680 --> 00:41:13.310
uh,
products for users.

664
00:41:13.311 --> 00:41:17.930
So we can look at,
I mean,

665
00:41:17.931 --> 00:41:21.860
let me show you guys this check,
check,
check this out for a second.
So this,

666
00:41:23.140 --> 00:41:23.600
<v 0>okay,</v>

667
00:41:23.600 --> 00:41:25.760
<v 1>is the input that we're going to give it?
It's a,</v>

668
00:41:25.790 --> 00:41:29.280
it's a user item Matrix,
okay.

669
00:41:29.300 --> 00:41:32.240
And this is what we perform it singular value decomposition off.

670
00:41:32.510 --> 00:41:35.900
So the are going to be songs and the users are the users.
Okay.

671
00:41:36.560 --> 00:41:38.210
Once we perform SPD on this,

672
00:41:38.211 --> 00:41:41.570
it's going to give us a set of directors and what we have those vectors,

673
00:41:41.660 --> 00:41:45.800
we're going to measure the distance between vectors to give us recommend

674
00:41:45.920 --> 00:41:46.760
recommendations.

675
00:41:46.970 --> 00:41:50.210
That's the most simple way of putting it where it's going to measure the

676
00:41:50.211 --> 00:41:54.260
distance between vectors to give us recommendations.
Okay.
And

677
00:41:56.280 --> 00:41:59.700
and down here,
it's got a little bit of the intuition behind it,
but um,

678
00:42:01.280 --> 00:42:04.670
so when we plot those and that's where this code ends.

679
00:42:04.671 --> 00:42:09.500
But I want to talk about deep learning right now for a second,
okay.

680
00:42:09.501 --> 00:42:13.450
Because we haven't done deep one.
And yet this is the,
this is just,
um,

681
00:42:14.030 --> 00:42:15.710
this is without the pointing.
So let's,

682
00:42:15.711 --> 00:42:20.120
let's talk about deeper learning right now.
Okay.
So let me pull this up.

683
00:42:24.450 --> 00:42:29.010
Let me pull this up.
So what is a good,
so,

684
00:42:29.160 --> 00:42:31.360
so this code doesn't have the pointing because

685
00:42:33.440 --> 00:42:36.890
I think a good one,
it's like Hulu has a great,

686
00:42:36.980 --> 00:42:38.480
so I think who has a VR yet?

687
00:42:38.600 --> 00:42:41.270
Hulu has state of the art right now in recommender systems.

688
00:42:41.271 --> 00:42:44.960
So what is doing here?
So,

689
00:42:45.260 --> 00:42:49.520
so right now I think Hulu has state of the art had they got state of the art and

690
00:42:49.540 --> 00:42:52.370
recommended system.
So let's look at what they're doing for deep learning.

691
00:42:52.700 --> 00:42:57.170
There are a lot of ways to apply deep on it.
This problem set,
right?
So if we,

692
00:42:58.960 --> 00:43:03.760
so here's one way,
okay,
so their method is called CF nay.
Okay.

693
00:43:04.030 --> 00:43:05.290
That's what they call their method.

694
00:43:05.500 --> 00:43:08.360
They definitely need some marketing to help with that,
that name.
But,
uh,

695
00:43:08.380 --> 00:43:12.490
so what they did was they said,
okay,
let's take an example.
Now,

696
00:43:12.491 --> 00:43:15.910
here's an example that they're using and let's say user rate four movies,

697
00:43:15.911 --> 00:43:20.020
transformers,
spongebob,
a Ninja Turtles,

698
00:43:20.021 --> 00:43:23.650
and interstellar with the spores for two,
three and five on a five star scale,

699
00:43:24.730 --> 00:43:29.380
they're going to create a joint probability of that vector factorized as a

700
00:43:29.381 --> 00:43:32.950
product of conditionals by chain rule.
Now what the heck did I just say?

701
00:43:33.130 --> 00:43:34.540
So this is what it looks like.

702
00:43:34.960 --> 00:43:38.530
It's going to calculate the probability that the user gets transformers at four

703
00:43:38.531 --> 00:43:40.420
star rating conditioned on nothing.

704
00:43:42.700 --> 00:43:44.980
There's gonna be the probability that a user gets spongebob,

705
00:43:45.180 --> 00:43:48.940
a rink rat tooth already conditioned on what had just happened,

706
00:43:49.180 --> 00:43:52.000
and then the probability of teenage mutant Ninja turtles condition or that

707
00:43:52.001 --> 00:43:53.740
condition on that condition on that.
So you see what I'm saying?

708
00:43:53.741 --> 00:43:55.630
This is a chain rule.

709
00:43:55.660 --> 00:44:00.660
It's a chain of probabilities based on what previous previously has occurred.

710
00:44:00.970 --> 00:44:05.970
So it's a chain of probabilities and each conditional is modeled by its own

711
00:44:06.130 --> 00:44:07.630
separate neural network.

712
00:44:08.140 --> 00:44:13.120
And the parameters for all of these neural networks are shared amongst all

713
00:44:13.180 --> 00:44:16.960
models.
So it's got several neural networks for all of these conditionals.

714
00:44:16.961 --> 00:44:20.110
Can you imagine how many neural networks,

715
00:44:22.770 --> 00:44:25.830
can you imagine how many neural networks are using for this?
Okay,

716
00:44:25.831 --> 00:44:28.840
so they've got a lot of neural networks and they're going to,
uh,

717
00:44:29.370 --> 00:44:32.910
minimize the negative log likelihood,
the probability of the Becker among,

718
00:44:32.960 --> 00:44:34.680
I'll use it.
Okay.

719
00:44:34.681 --> 00:44:37.800
So that's one that is like the state of the art way of doing it.
Okay.

720
00:44:37.801 --> 00:44:42.570
So we did blackbox,
all of this,
right?
Obviously it's a 10 lines of code,

721
00:44:43.060 --> 00:44:46.030
but Brittany,
we're just looking at it theoretically in detail.
Like what is,

722
00:44:46.120 --> 00:44:49.330
what is the cutting edge right now in the field?
Okay.
So

723
00:44:51.190 --> 00:44:54.940
let me,
let me show you guys just think as well.
So leading edge right here.

724
00:44:58.170 --> 00:45:00.000
Okay.
So,
so,
uh,

725
00:45:00.090 --> 00:45:03.390
let's go back to where we were and

726
00:45:07.500 --> 00:45:12.400
yeah,
so I think we went through all of it actually.
Yeah.
Okay.
So cool.

727
00:45:12.401 --> 00:45:15.580
We went through all that,
that code and um,

728
00:45:20.210 --> 00:45:22.130
yeah,
we're going to talk more about recommender systems.

729
00:45:22.131 --> 00:45:26.060
This was nearly not enough to talk about it.
We're going to do a lot more,

730
00:45:26.061 --> 00:45:28.190
this was a good high level over read.
This was good,

731
00:45:28.400 --> 00:45:31.580
but we're going to do a better high level overview or sorry,

732
00:45:31.850 --> 00:45:33.560
an additional eye level overview,

733
00:45:34.120 --> 00:45:34.953
<v 2>uh,</v>

734
00:45:37.030 --> 00:45:41.800
<v 1>later on.
Okay.
Stop screen sharing.
Okay.
Back to me.</v>

735
00:45:42.030 --> 00:45:42.910
Oh,
you guys.
Okay.

736
00:45:43.540 --> 00:45:46.510
So that was it for the code and we're going to end with another five minute Q

737
00:45:46.511 --> 00:45:47.410
and.
A.
Okay.

738
00:45:48.250 --> 00:45:52.900
So what else is on guys?
We're going to,

739
00:45:55.870 --> 00:45:56.703
<v 0>okay.</v>

740
00:45:57.310 --> 00:45:59.830
<v 1>I will link to code for deep learning based recommender.</v>

741
00:46:00.070 --> 00:46:03.640
Right now we want to learn the concepts.
Okay.
Deep One.
There's a lot of,

742
00:46:04.180 --> 00:46:06.740
there's a lot of conceptual,
um,

743
00:46:07.510 --> 00:46:09.910
things we have to learn about recommenders before we get to deep learning

744
00:46:10.120 --> 00:46:15.120
because I think that deep learning for recommender systems is the most complex,

745
00:46:18.410 --> 00:46:19.243
<v 2>uh,</v>

746
00:46:19.900 --> 00:46:21.460
<v 1>task right now in,</v>

747
00:46:22.320 --> 00:46:25.450
in deep learning to me there it's actually more complex than generative

748
00:46:25.451 --> 00:46:28.990
adversarial networks.
Uh,
so we're going to talk about it more.

749
00:46:28.991 --> 00:46:32.130
This was clearly not enough.
I'm not satisfied,
but I'm satisfied.

750
00:46:32.160 --> 00:46:33.720
I'm satisfied with this license,
but not satisfied.

751
00:46:33.740 --> 00:46:37.120
They're talking about it enough.
Okay.
So wrap about music.
Recommenders.

752
00:46:37.420 --> 00:46:41.680
I rapped already.
I,
okay.
Um,
okay.

753
00:46:43.310 --> 00:46:47.330
Uh,
bragged about me.
Is Greg a minute.
Okay.
So that was a fourth person.
So,
uh,

754
00:46:47.390 --> 00:46:48.223
here we go.

755
00:46:50.650 --> 00:46:52.560
Yo rap about music recommenders.

756
00:46:52.840 --> 00:46:54.730
I see this girl up there and she's like a sender.

757
00:46:54.790 --> 00:46:56.710
Do you try and give me some mail?
It's like get out of here,

758
00:46:56.740 --> 00:47:00.310
but I'm not going back.
I got a treatment.
They are not really,
I don't drink beer.

759
00:47:00.311 --> 00:47:04.330
I'm more a coffee drinker,
man.
This is crazy.
You could call me Sean Speaker.

760
00:47:04.510 --> 00:47:08.290
I go out everyday on the streets telling people,
Hey,
I like this song.
They like,

761
00:47:08.380 --> 00:47:12.210
man,
you need a drink of people battle Snapple,
all these drinks.

762
00:47:12.220 --> 00:47:15.040
But I'm bored man.
I got songs,
man.
I'm done with that.
So,

763
00:47:16.140 --> 00:47:16.973
<v 2>okay.</v>

764
00:47:17.860 --> 00:47:22.060
<v 1>Is it possible to write a collaborative filtering algorithm without deep</v>

765
00:47:22.061 --> 00:47:26.630
learning?
Yes.
Absolutely.
Yes.
Yes.
That's,
that's,

766
00:47:26.640 --> 00:47:30.670
that's what we,
that's what we just did.
Okay.
And I should have clarified that.

767
00:47:30.940 --> 00:47:31.773
Okay.

768
00:47:32.320 --> 00:47:36.100
What do you think about trying to group possible actions and optimized path

769
00:47:36.290 --> 00:47:40.570
taking in this group in reinforcement learning to reduce size,

770
00:47:40.660 --> 00:47:44.110
size of state space.
Okay.

771
00:47:44.111 --> 00:47:48.460
Reinforcement learning in general should be applied everywhere.

772
00:47:48.840 --> 00:47:53.410
It is going to be applied everywhere because no pack net.
Okay.

773
00:47:53.411 --> 00:47:57.760
Path neck by deepmind.
Okay.
Pack Net.
Let me,
let me make the path name.

774
00:47:57.820 --> 00:48:00.580
But this is,
this is so dope because they applied,

775
00:48:01.200 --> 00:48:05.470
they applied reinforcement learning to a neural net architecture.
Check this out,

776
00:48:05.920 --> 00:48:09.250
check out that link.
We only put in a description for people watching us,

777
00:48:09.580 --> 00:48:14.560
but it used a reinforcement reinforcement learning agent inside of a neural

778
00:48:14.561 --> 00:48:17.860
network to find the optimal parameters.
So get,
get this for a second.

779
00:48:18.100 --> 00:48:22.960
It is looking inside of it is using an AI inside of an AI,

780
00:48:22.961 --> 00:48:27.190
which is a neural network to find the optimal hyper parameters.
How Joe is that?

781
00:48:27.220 --> 00:48:30.520
Okay.
And so that's that.
So yes,

782
00:48:30.521 --> 00:48:33.820
we can use reinforcement learning every work including recommender systems.

783
00:48:34.120 --> 00:48:37.510
Two more questions and then we are Outta here.
Okay.

784
00:48:41.220 --> 00:48:42.053
Um,

785
00:48:42.900 --> 00:48:47.900
how much usage data is typically required to make a good performing recommender

786
00:48:48.061 --> 00:48:51.090
systems?
Rosio quake.
Great question.

787
00:48:51.390 --> 00:48:55.860
You definitely need a lot of data.
Like 100,000 plus sets.

788
00:48:55.950 --> 00:49:00.900
There's a lot of of reckon.
There's a lot of recommender system libraries.

789
00:49:01.040 --> 00:49:01.873
How,
I mean,
sorry,

790
00:49:01.890 --> 00:49:05.400
data sets out there publicly available a link to them in the description.

791
00:49:05.550 --> 00:49:09.300
But you need a lot.
You need a lot.
Okay.
If you want it to be accurate,

792
00:49:09.301 --> 00:49:12.960
you need a lot.
And,
and don't be intimidated by that because it's everywhere.

793
00:49:14.500 --> 00:49:16.360
Okay,
well actually I'll,
I'll take two more

794
00:49:19.350 --> 00:49:22.830
favorite entrepreneur.
What favorite entrepreneur is?

795
00:49:24.530 --> 00:49:25.490
Probably

796
00:49:28.050 --> 00:49:30.530
my favorite entrepreneur is to POCs,

797
00:49:30.531 --> 00:49:34.770
sugar because Tupac face so much oppression.

798
00:49:35.010 --> 00:49:38.700
He faced so much suffering and in the face of all of that,

799
00:49:38.850 --> 00:49:43.500
Tupac believed in himself enough to broadcast themselves to the world and say,

800
00:49:43.650 --> 00:49:47.220
Hey,
I'm Tupac Shakur.
I don't care how many haters I have.

801
00:49:47.520 --> 00:49:52.520
I'm going to be myself and I'm going to be out essentially a messiah for a bunch

802
00:49:53.881 --> 00:49:57.750
of people.
And so yeah,
Tupac is my favorites.
Uh,
entrepreneur.

803
00:49:59.630 --> 00:50:04.630
I also have a book of Tupacs poetry called the rose that grew through concrete.

804
00:50:05.630 --> 00:50:09.240
One more question.
Yeah.
We're going to talk about,

805
00:50:09.900 --> 00:50:11.820
let's make it a good one.
Okay.

806
00:50:13.410 --> 00:50:16.350
When are you making a robot with machine learning?

807
00:50:20.110 --> 00:50:20.943
<v 0>Okay,</v>

808
00:50:21.320 --> 00:50:24.560
<v 1>next video.
Okay.
I just said it.
So now it has to happen.</v>

809
00:50:24.561 --> 00:50:28.460
So the next weekly video we're going to make a,
okay.
So

810
00:50:30.720 --> 00:50:33.480
detached.
If you want to do research post in the slack channel,
guys,

811
00:50:33.630 --> 00:50:37.350
we need our own research group,
okay?
We need our own research group.

812
00:50:37.380 --> 00:50:41.670
I want publications coming out of this community,
okay?
You guys are so smart.

813
00:50:41.700 --> 00:50:45.900
We need to build community,
okay?

814
00:50:45.901 --> 00:50:49.290
We're going to build a research community,
okay?
We were going to publish,

815
00:50:49.410 --> 00:50:54.060
we're going to build a brand that publishes worldclass machine winning research.

816
00:50:54.061 --> 00:50:57.570
Okay?
So that's what we're gonna do.
All right?
All right,
so,

817
00:50:57.600 --> 00:51:01.260
so that's it for the livestream.
Okay.
And next time I'm going to code everything.

818
00:51:01.290 --> 00:51:03.030
This time I didn't,
uh,
I love you guys.

819
00:51:03.270 --> 00:51:07.860
And for now I've got to edit this next video.

820
00:51:07.920 --> 00:51:11.820
I just have to edit it myself.
Like you,
Udacity has offered me an editor,

821
00:51:12.150 --> 00:51:15.960
but I just cannot do it.
I just have to do it myself right now.
Okay?

822
00:51:15.990 --> 00:51:19.530
So that's what I got to do.
And,
uh,
thanks for watching.
Bye.

