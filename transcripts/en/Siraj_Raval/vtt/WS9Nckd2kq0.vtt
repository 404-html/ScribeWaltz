WEBVTT

1
00:00:00.080 --> 00:00:00.800
Hello world,

2
00:00:00.800 --> 00:00:05.800
it's Saroj and I've built an automated trading Bot called neuro fund and I built

3
00:00:06.201 --> 00:00:10.610
it with a machine learning library called tensorflow and not just any
tensorflow,

4
00:00:10.730 --> 00:00:11.930
the new version of tensorflow,

5
00:00:11.931 --> 00:00:16.931
tensorflow 2.0 and in this video I'm going to show you how I built this and what

6
00:00:16.971 --> 00:00:21.971
the important features of tentraflow 2.0 are so that you can make money with it.

7
00:00:22.551 --> 00:00:25.520
And by make money,
I mean build an AI startup,

8
00:00:25.750 --> 00:00:29.720
work at a company that requires that as a dependency of knowledge,

9
00:00:30.470 --> 00:00:35.000
do something great with this knowledge that will impact people's lives and make

10
00:00:35.001 --> 00:00:36.770
you money.
That's the point of this video.

11
00:00:36.920 --> 00:00:41.780
And let me start off by showing you how neural fund my Automated Investment Ai

12
00:00:41.780 --> 00:00:45.950
Works.
What it does is it makes predictions about stock prices in the future for

13
00:00:45.951 --> 00:00:50.180
various companies in a sector that the user selects say technology.

14
00:00:50.360 --> 00:00:54.050
So within technology,
apple,
Google,
and say Amazon or three different stocks,

15
00:00:54.320 --> 00:00:58.160
and it's going to use an AI model to predict future prices for each of these

16
00:00:58.310 --> 00:01:02.480
stocks.
And then based on the stock that is,
it predicts to be the highest price.

17
00:01:02.600 --> 00:01:06.470
It will buy that for you.
So it's like an automated hedge fund manager.

18
00:01:06.590 --> 00:01:10.490
And rather than having a 20% cut,
which hedge fund managers take,

19
00:01:10.640 --> 00:01:13.850
it's going to take a 2% cut.
So let me go ahead and demo this for you.

20
00:01:14.730 --> 00:01:18.780
So the first step for us is to sign up for neuro fund and to sign up,

21
00:01:18.781 --> 00:01:22.860
I'm going to give it a name and then I'll type in a password and then I'll hit

22
00:01:22.861 --> 00:01:23.940
submit.
Great.

23
00:01:23.941 --> 00:01:27.480
So I've signed up and now what I have to do is select the industry that I want

24
00:01:27.481 --> 00:01:28.710
my AI to invest in.

25
00:01:28.711 --> 00:01:33.270
So all select technology and it's going to pick some stocks to invest in for me

26
00:01:33.450 --> 00:01:34.620
and I'll click on invest.

27
00:01:34.860 --> 00:01:39.210
And now what's going to happen is it's going to ask me to complete my charge.

28
00:01:39.240 --> 00:01:43.230
So it's going to ask me for 100 bucks and I'm gonna fill this out using a fake

29
00:01:43.290 --> 00:01:44.220
credit card.

30
00:01:44.870 --> 00:01:45.170
<v 1>Okay.</v>

31
00:01:45.170 --> 00:01:49.760
<v 0>For testing purposes,
and this is using the Stripe Api.
And once I pay,</v>

32
00:01:49.761 --> 00:01:51.860
it's going to take 2% of that,

33
00:01:51.861 --> 00:01:56.030
so two box and it's going to invest the rest for me.
So I'll pay

34
00:02:00.580 --> 00:02:03.940
and once I've paid see the balances right now,
98 USD,

35
00:02:03.941 --> 00:02:05.800
it took the rest it's going to,

36
00:02:05.801 --> 00:02:08.920
and so I chose to invest in apple stock based on its predictions.

37
00:02:09.160 --> 00:02:11.560
And so this was just a chart of apple stock,

38
00:02:11.561 --> 00:02:15.730
but the point is that in the background it is continuously learning about stock

39
00:02:15.731 --> 00:02:18.730
prices in the future using tensorflow serving.

40
00:02:18.731 --> 00:02:22.630
I'm going to talk about how that works in the background and it's tensional a

41
00:02:22.631 --> 00:02:24.100
2.0 this is a,

42
00:02:24.110 --> 00:02:27.490
this is an automated investment bought and I'm going to show you how I built

43
00:02:27.491 --> 00:02:30.580
this.
All right,
so in this tutorial there are 10 steps.

44
00:02:30.581 --> 00:02:33.640
We're going to start by looking at what some prerequisite videos you should

45
00:02:33.641 --> 00:02:34.474
watch are.

46
00:02:34.750 --> 00:02:38.080
Then we're going to talk about the problems with tensorflow 1.0 how cash flow,

47
00:02:38.081 --> 00:02:42.880
2.0 fixes those problems.
We'll build this stock prediction model in in Colab.

48
00:02:43.000 --> 00:02:46.240
We'll download that model,
we'll serve it using tensorflow serving,

49
00:02:46.360 --> 00:02:50.620
and then we'll add some extra functionality like user's authentication payments,

50
00:02:50.621 --> 00:02:55.060
and then finally we'll deploy it to the web so users can actually use it at the

51
00:02:55.061 --> 00:02:58.900
end.
We'll talk about ways of improving that APP.
All right,
so first of all,

52
00:02:59.080 --> 00:03:02.290
if you haven't,
go ahead and watch four videos,
right?

53
00:03:02.291 --> 00:03:05.860
So one is called how to make money with tensorflow.
So that was for 1.0,

54
00:03:05.861 --> 00:03:07.810
but a lot of the concepts still apply.

55
00:03:08.200 --> 00:03:10.990
Then watch seven ways to make money with machine learning.

56
00:03:11.320 --> 00:03:13.420
And then watch one of my most recent videos,

57
00:03:13.421 --> 00:03:17.380
watch me build an AI startup and then watch this playlist called intro to

58
00:03:17.381 --> 00:03:21.820
tensorflow just on youtube search intro to tensorflow Saroj and it'll show up.

59
00:03:22.840 --> 00:03:25.780
And once you do that,
let's talk about some of the problems with tensorflow.

60
00:03:25.810 --> 00:03:27.310
One Point Oh so first of all,

61
00:03:27.670 --> 00:03:30.980
there is this programming paradigm called data flow.
And it tends to flow.

62
00:03:30.990 --> 00:03:35.810
Team did not invent this.
This existed for a while.
And the idea behind,
uh,

63
00:03:35.890 --> 00:03:40.270
behind data flow is that it creates what's called a static computation graph.

64
00:03:40.450 --> 00:03:44.740
So imagine any set of operations in any function or in any equation,

65
00:03:44.950 --> 00:03:49.120
we can represent that as a graph where different nodes,
our operations like add,

66
00:03:49.210 --> 00:03:51.700
subtract,
multiply,
divide,
right?

67
00:03:51.880 --> 00:03:56.880
And data will flow through these computation graphs operation by operation.

68
00:03:57.101 --> 00:03:58.480
Let's say first that you want to add,

69
00:03:58.660 --> 00:04:01.090
then you want to subtract and then you want to divide,
right?
So there's a,

70
00:04:01.091 --> 00:04:05.200
there's a sequence of operations and astatic computation graph can represent

71
00:04:05.201 --> 00:04:06.160
these operations.

72
00:04:06.430 --> 00:04:10.960
And one way of representing data in these computation graphs is by considering

73
00:04:10.961 --> 00:04:15.961
them as tensors and what our tensors tensors our n dimensional arrays.

74
00:04:16.090 --> 00:04:19.030
So that means they are groups of numbers with n dimensions.

75
00:04:19.031 --> 00:04:21.280
This could be one dimension.
This can be two dimensions.

76
00:04:21.340 --> 00:04:24.250
This could be three dimensions.
This could be a million dimensions,
right?

77
00:04:24.251 --> 00:04:25.690
Which we can visualize.

78
00:04:26.200 --> 00:04:31.030
And the idea is that these tensions flow through the graph from input to output.

79
00:04:31.030 --> 00:04:32.890
And they make a prediction when the prediction could,

80
00:04:32.891 --> 00:04:35.410
would be the output of the function.
Tensorflow,

81
00:04:36.730 --> 00:04:41.020
and this is great and the reason they did this is because creating a computation

82
00:04:41.021 --> 00:04:45.820
graph in this way,
a static computation graph allows for very easy parallelism.

83
00:04:45.821 --> 00:04:49.240
It's easy to distribute computation across different nodes.

84
00:04:49.390 --> 00:04:53.380
If you abstract the idea of operations to um,

85
00:04:53.530 --> 00:04:56.590
objects in what is considered object oriented programming,

86
00:04:56.980 --> 00:05:00.520
it makes it easier to have distributed execution across multiple machines.

87
00:05:00.850 --> 00:05:02.320
And it's easier to compile.

88
00:05:02.321 --> 00:05:06.940
And it's more portable because when a static computation graph is created in one

89
00:05:06.941 --> 00:05:08.930
language,
let's say python,
uh,

90
00:05:09.010 --> 00:05:12.400
we can then export it and load it up in a different language because it is

91
00:05:12.401 --> 00:05:16.320
language agnostic.
All great things.
So the idea behind tensorflow,

92
00:05:16.330 --> 00:05:19.660
1.0 was we import our data,
define our model.

93
00:05:19.700 --> 00:05:22.090
This is a static model at runtime.

94
00:05:22.240 --> 00:05:25.570
The data will flow through this static graph and then we'll get some output and

95
00:05:25.660 --> 00:05:29.080
is an example of some tensorflow 2.0 code right here.

96
00:05:29.290 --> 00:05:32.290
And let me also just write out something very simple so you could see what I

97
00:05:32.291 --> 00:05:36.520
mean.
So once we've imported tensor flow,
then we can define two constants,
right?

98
00:05:36.521 --> 00:05:39.760
So the first constant is going to be called a,

99
00:05:39.790 --> 00:05:42.400
the second constant is going to be called B.

100
00:05:42.670 --> 00:05:46.420
And both of these represent single values.
The first represents two,

101
00:05:46.630 --> 00:05:51.220
and the second represents three.
And once we have these constants,

102
00:05:51.221 --> 00:05:55.120
these tensor flow variables,
we can perform operations on these constants.

103
00:05:55.121 --> 00:05:58.130
Like let's say C is going to be equal to a plus B,

104
00:05:58.310 --> 00:06:01.730
whereas d is going to be equal to a times B.

105
00:06:02.330 --> 00:06:03.440
And then once we've done that,

106
00:06:03.441 --> 00:06:06.530
then we launch our graph by using what's called the session object.

107
00:06:06.560 --> 00:06:09.800
We have a TF dot session.
And then inside of that session,

108
00:06:10.010 --> 00:06:12.620
we perform our operations.

109
00:06:12.621 --> 00:06:17.540
Let's say it's ad or it's multiply.
And when we do this,

110
00:06:17.541 --> 00:06:21.410
we can see that it computed this operation.

111
00:06:21.680 --> 00:06:25.790
But the problem is that it computed it,
when we ran that computation,

112
00:06:25.791 --> 00:06:29.420
graphs are right here is where this operation a plus B occurred,
right?

113
00:06:29.421 --> 00:06:32.690
So if we want it to say,
well,
let's see what B is right over here,

114
00:06:34.040 --> 00:06:37.460
it's not gonna work,
right?
Because it is a static computation graph.

115
00:06:37.461 --> 00:06:39.980
First we have to define the graph,
then we can run the graph.

116
00:06:39.981 --> 00:06:42.830
We can't just debug inside of the graph as it's being built.

117
00:06:43.100 --> 00:06:45.890
And this is a problem.
The second problem is verbosity.

118
00:06:45.891 --> 00:06:50.640
So there's so many concepts in tentraflow,
placeholders,
variables,
uh,

119
00:06:50.990 --> 00:06:53.420
hyper parameter values,
formatting convention.

120
00:06:53.570 --> 00:06:57.200
There's a lot to learn and we haven't even begun to talk about deep learning

121
00:06:57.201 --> 00:07:00.230
theory here.
And so this is an example of verbosity.

122
00:07:00.231 --> 00:07:04.900
I basically just copied and pasted some code from what's called a DC Gan.

123
00:07:04.950 --> 00:07:07.370
Uh,
it's a type of generative adversarial network,

124
00:07:07.520 --> 00:07:10.100
the convolutional generative adversarial network.

125
00:07:10.100 --> 00:07:13.730
And I basically just copied some tentraflow 1.0 code here to show you that

126
00:07:13.731 --> 00:07:17.300
there's a lot happening here.
And this can be confusing for beginners.

127
00:07:18.110 --> 00:07:19.460
Even if you have coded before,

128
00:07:19.461 --> 00:07:22.970
they could still be confusing because there's so many different,
uh,

129
00:07:23.000 --> 00:07:27.230
tensorflow specific naming conventions here that we have to get to know,

130
00:07:27.510 --> 00:07:30.140
you know,
global variables and initializer at the session,

131
00:07:30.380 --> 00:07:32.900
the different types of optimizers that saver,
right?

132
00:07:33.020 --> 00:07:35.300
So it's very verbose code and uh,

133
00:07:35.330 --> 00:07:40.210
there's also very messy Api APIs because they're always adding more to the API

134
00:07:40.211 --> 00:07:43.340
APIs over time.
There's a lot of deprecated Apis,

135
00:07:43.550 --> 00:07:47.210
a lot of new packages are being added to this.
And I made this meme like,

136
00:07:47.211 --> 00:07:51.140
should I use this sequence to sequence or this one,
I don't know.
And lastly,

137
00:07:51.141 --> 00:07:53.150
it's very hard to debug,
right?

138
00:07:53.151 --> 00:07:58.151
So if we have some value here like x,

139
00:07:59.000 --> 00:08:02.120
and it's a value called zero,
and then we're,

140
00:08:02.390 --> 00:08:05.900
we have another value called Y and we say,
well,

141
00:08:05.960 --> 00:08:10.130
why is going to be this value?
The log of x plus one divided by x?

142
00:08:10.140 --> 00:08:15.110
We're dividing by zero and then we say y plus one is c and then inside of our

143
00:08:15.111 --> 00:08:19.360
session we'll have to say,
well print out that value of,
see,
let's see what,

144
00:08:19.370 --> 00:08:21.200
what z evaluates too.

145
00:08:21.470 --> 00:08:25.160
And of course it's going to evaluate as Nan Nan,

146
00:08:25.161 --> 00:08:29.360
but the problem was why,
but we didn't.
We couldn't,
we couldn't see that.

147
00:08:29.361 --> 00:08:32.480
It was why?
Because if we print out why,
it's not going to tell us,

148
00:08:32.481 --> 00:08:35.690
hey the problem was here because why hasn't been compiled?

149
00:08:35.691 --> 00:08:38.540
It hasn't been completed yet.
It's waiting until the graph has built.

150
00:08:38.840 --> 00:08:43.370
So that's what they wanted to fix with tensorflow 2.0 so they're actually a lot

151
00:08:43.371 --> 00:08:46.430
of features that tends to flow 2.0 has that 1.0 doesn't,

152
00:08:46.431 --> 00:08:49.490
but what I've done is I picked the three or four of them that I consider it to

153
00:08:49.491 --> 00:08:50.870
be the most important.
Sorry,

154
00:08:50.880 --> 00:08:54.560
six or seven of them that I consider to be the most important and here they are.

155
00:08:54.920 --> 00:08:58.770
The first one is that it allows for rapid prototyping by having what's called

156
00:08:58.800 --> 00:09:02.460
eager execution mode as the default mode.
Right.

157
00:09:02.461 --> 00:09:07.461
And so eager execution mode is it is an imperative programming paradigm that

158
00:09:07.771 --> 00:09:10.350
doesn't create a static computation graph.

159
00:09:10.560 --> 00:09:13.440
It creates what's called Ed dynamic computation graph,

160
00:09:13.650 --> 00:09:15.180
and this is more python Anik.

161
00:09:15.300 --> 00:09:19.260
It's more in line with how python was built and this makes it much easier to

162
00:09:19.261 --> 00:09:23.370
debug.
It makes it much easier to read the code.
It's less for boasts,

163
00:09:23.490 --> 00:09:27.330
so just having this alone is such an important feature.

164
00:09:27.510 --> 00:09:32.250
Pi Torch already does this.
In fact,
chainer did this about three years ago,

165
00:09:32.670 --> 00:09:35.730
but now this is a native concept and tensorflow,

166
00:09:35.731 --> 00:09:40.500
which makes things much simpler to to understand,
and I had this code right here,

167
00:09:41.190 --> 00:09:42.023
which I'll compile.

168
00:09:42.060 --> 00:09:46.500
So right here you can see I'm installing the latest version of tensorflow 2.0

169
00:09:46.501 --> 00:09:51.330
with this pip command and then I'll import tensorflow.
It's executing eagerly.

170
00:09:51.720 --> 00:09:55.830
I'll create this value for x and then I'll do perform a matrix multiplication

171
00:09:55.831 --> 00:09:59.910
using x and notice how I can then print out that value m,

172
00:10:00.060 --> 00:10:02.550
which is x times x or X.
Dot.

173
00:10:02.551 --> 00:10:05.900
Product x before creating a session.
In fact,

174
00:10:05.950 --> 00:10:08.550
there are no sessions anymore,
right?

175
00:10:08.580 --> 00:10:13.470
All of this is being computed with each line and this is super valuable.
In fact,

176
00:10:13.471 --> 00:10:16.590
we can also use num Pi natively,
right?

177
00:10:16.591 --> 00:10:21.591
So we can use num py functions to perform operations on these TF variables like

178
00:10:22.171 --> 00:10:25.470
see this Constance et cetera.
And notice there's,
there's our output.

179
00:10:25.471 --> 00:10:29.250
Exactly as we wanted that to work,
there were no errors.
And like I said,

180
00:10:29.251 --> 00:10:32.400
this makes it easier to debug because we can just print out,

181
00:10:32.700 --> 00:10:36.260
hey what's the value of m before computing,
you know,

182
00:10:36.360 --> 00:10:39.960
anything else later on and it's going to tell us what that value is.

183
00:10:39.960 --> 00:10:43.310
So it makes debugging a lot easier.
It's less verbose.

184
00:10:43.390 --> 00:10:48.360
And one major reason for this is because they are now using care Ross as the

185
00:10:48.450 --> 00:10:49.081
high level,

186
00:10:49.081 --> 00:10:53.520
the official high level Api of tentraflow 2.0 which is awesome.

187
00:10:53.700 --> 00:10:57.390
And so this code right here is an example of training a model and it's takes

188
00:10:57.391 --> 00:11:01.770
about 45 seconds to train and Colab,
which is super good,

189
00:11:01.771 --> 00:11:03.290
super short.
And the,

190
00:11:03.550 --> 00:11:06.600
the whole point here is all we have to do is we have to import flow.

191
00:11:06.750 --> 00:11:11.340
We're not importing care us.
Why?
Because Ken Ross is now built into tensorflow,

192
00:11:11.550 --> 00:11:14.730
and what that means is we can call carrots just like that.

193
00:11:14.880 --> 00:11:18.120
See this TF dot Ken Ross,
uh,
module right here,

194
00:11:18.930 --> 00:11:22.890
and we're downloading the MNI ist dataset.
We trained it,
we tested it,

195
00:11:23.040 --> 00:11:26.820
and this will finish training in about a few more seconds,

196
00:11:27.030 --> 00:11:31.470
but that's all it took for us to train our model on data using tensorflow.

197
00:11:31.470 --> 00:11:35.910
We built a neural network right here in a few lines using the carrot sequential

198
00:11:35.911 --> 00:11:39.960
API.
It trained it,
it tested it,
and an in five epochs.

199
00:11:40.140 --> 00:11:44.520
We're done with training.
There you go.
There's our it trained right there,
right?

200
00:11:44.521 --> 00:11:45.480
So that's super easy.

201
00:11:45.510 --> 00:11:49.800
And there's more granular control as well in that we not only do they have

202
00:11:49.801 --> 00:11:51.690
carrots as a new high level API,

203
00:11:51.830 --> 00:11:56.830
they have a full lower API that allows you to access those native internal

204
00:11:57.641 --> 00:12:01.750
operations that tensorflow is using using what's called TF dot.
Raw ops.

205
00:12:01.960 --> 00:12:04.900
But the thing about that tensorflow team,
which they're definitely watching,

206
00:12:05.140 --> 00:12:08.410
I tried to search for this and the documentation,
I did not find it.

207
00:12:08.411 --> 00:12:11.770
So definitely make that easier for developers to,
to find.
Okay.

208
00:12:12.010 --> 00:12:15.880
But that's another point that it allows for more granular control at the low

209
00:12:15.881 --> 00:12:19.540
level as well as high level.
And you might be thinking,

210
00:12:19.541 --> 00:12:23.110
well I wrote a bunch of code and tensorflow 1.0 how am I going to convert it to

211
00:12:23.111 --> 00:12:28.111
2.0 they have this nifty little command called TF upgrade Vitu and all you have

212
00:12:28.361 --> 00:12:30.130
to do is say,
here's my old tensorflow,

213
00:12:30.190 --> 00:12:35.190
1.0 file and here's my new tentraflow 1.0 file and it will make all those

214
00:12:35.471 --> 00:12:39.880
changes automatically for you,
which is awesome to backwards compatibility.

215
00:12:39.880 --> 00:12:41.830
And here's perhaps my favorite feature.

216
00:12:42.040 --> 00:12:46.490
Tenser board is now available inside of Colab.
Now tensor board,

217
00:12:46.510 --> 00:12:47.380
if you don't know,

218
00:12:47.610 --> 00:12:51.100
is tension flows way of visualizing your model during training.

219
00:12:51.280 --> 00:12:53.110
You can visualize the hyper parameters,

220
00:12:53.260 --> 00:12:57.130
you can visualize a lot while it's happening and it's super,
super useful.

221
00:12:57.400 --> 00:13:01.900
And using end Grok,
which is a tunnel to be able to access this,
we can,

222
00:13:02.530 --> 00:13:06.610
we have tents board right there and now we can perform all sorts of visual

223
00:13:06.640 --> 00:13:10.090
visualizations as per necessary.
You know,
we don't have a model right now,

224
00:13:10.091 --> 00:13:13.600
but we could perform any kind of visualization right in the cloud.

225
00:13:13.601 --> 00:13:14.770
We don't have to download anything.

226
00:13:14.920 --> 00:13:18.970
So those are the main points about tentraflow 2.0 that I thought were worth

227
00:13:18.971 --> 00:13:23.620
mentioning because it makes it easier for anybody to enter into this field and

228
00:13:23.621 --> 00:13:27.220
that will make it easier for you to build something of value for other people,

229
00:13:27.221 --> 00:13:31.270
right?
If as long as you can understand these tools at a high level,

230
00:13:31.420 --> 00:13:36.190
you can put pieces together to make a prototype and then you can generate value

231
00:13:36.191 --> 00:13:39.430
using that,
right?
So here's what we're going to do.

232
00:13:39.580 --> 00:13:43.540
We're going to build this stock prediction model with tentraflow 2.0 in this

233
00:13:43.541 --> 00:13:46.210
colab notebook and then we're going to train it in the cloud.

234
00:13:46.330 --> 00:13:49.780
Then we'll download it and then we'll create a web app around that.
All right,

235
00:13:50.080 --> 00:13:52.660
so let's go to this stock prediction example right here.

236
00:13:52.690 --> 00:13:53.950
So inside of this example,

237
00:13:53.951 --> 00:13:57.610
what I'm going to do is I'm going to use what's called a transformer neural

238
00:13:57.611 --> 00:14:00.910
network to predict prices for one company stock.

239
00:14:00.911 --> 00:14:04.300
And I'm just going to randomly pick a general electric or apple,

240
00:14:04.301 --> 00:14:06.100
whatever you want to pick,
it doesn't matter.

241
00:14:06.310 --> 00:14:10.270
So what I'm first going to do is import the data and once I have that data,

242
00:14:10.450 --> 00:14:13.420
then I can view that data and see what it is.

243
00:14:13.420 --> 00:14:18.420
And so what I did was I pulled the data from Yahoo Finance for GE right here as

244
00:14:19.211 --> 00:14:22.720
a text file and it downloaded that and it showed it to me right here.

245
00:14:22.721 --> 00:14:25.330
And we can actually just,
if we wanted to,

246
00:14:25.331 --> 00:14:29.290
we could manually download it by saying download data right here and it will

247
00:14:29.291 --> 00:14:32.260
download it as a CSV file.
And then we upload it to Colab.

248
00:14:33.880 --> 00:14:38.260
And so once we have that,
we will be able to visualize it as a data frame,
right?

249
00:14:38.261 --> 00:14:42.550
These are all the prices for,
uh,
for about 90 days of historical data.

250
00:14:43.060 --> 00:14:45.970
And once we have that,
we're going to visualize it right here.
Okay.

251
00:14:45.971 --> 00:14:49.600
The data's going up over time.
It makes sense.

252
00:14:50.350 --> 00:14:52.370
And then once we have that data,

253
00:14:52.371 --> 00:14:54.650
we're going to perform a bunch of preprocessing on it.

254
00:14:54.651 --> 00:14:58.670
I'm going to skim through this because there's a lot of preprocessing here,

255
00:15:00.050 --> 00:15:01.010
but it's very basic stuff.

256
00:15:01.010 --> 00:15:05.060
We want to reformat a and you can really just find copy and paste a lot of this

257
00:15:05.270 --> 00:15:07.040
preprocessing code.
Um,

258
00:15:07.041 --> 00:15:11.150
and then once we have that we can show what it looks like over time.

259
00:15:11.151 --> 00:15:13.430
And then we get to the fun part,
which is building our model,

260
00:15:13.580 --> 00:15:15.230
which is called the transformer network.

261
00:15:15.231 --> 00:15:20.231
Now the transformer network has replaced all variations of recurrent networks.

262
00:15:21.140 --> 00:15:23.120
That includes LSTM networks,

263
00:15:23.210 --> 00:15:27.620
gru networks for time series prediction for sequence prediction.

264
00:15:27.621 --> 00:15:29.840
Let me clarify for sequence prediction.

265
00:15:30.290 --> 00:15:34.490
And Google invented this for specifically for language translation and their

266
00:15:34.491 --> 00:15:34.881
model.

267
00:15:34.881 --> 00:15:39.881
Bert uses a transformer network open AI's modeled gpt to uses a transformer

268
00:15:41.301 --> 00:15:43.520
network to make word predictions,

269
00:15:43.521 --> 00:15:47.390
which allows for text generation and have two great videos on how this works in

270
00:15:47.391 --> 00:15:51.920
detail.
See both of these open AI tech generator and natural language processing.

271
00:15:52.220 --> 00:15:56.180
Now what we're gonna do is we're going to re purpose this transformer network

272
00:15:56.210 --> 00:16:00.380
because it's so new for asset price prediction and that is the exciting part.

273
00:16:00.380 --> 00:16:04.700
Taking some of these bleeding edge models and reapplying them to use cases that

274
00:16:04.701 --> 00:16:08.150
nobody thought about.
That is the value that we can bring to people.

275
00:16:08.390 --> 00:16:12.350
And this is an example of a transformer network right here.

276
00:16:12.351 --> 00:16:16.160
Now remember all of these machine learning models,
these neural models,

277
00:16:16.270 --> 00:16:19.700
there are collections of different matrix operations.
Add,
subtract,
multiply,

278
00:16:19.701 --> 00:16:20.534
divide.

279
00:16:20.720 --> 00:16:25.720
And what we do is these boxes represent these matrix operations and once you get

280
00:16:26.181 --> 00:16:30.260
to know a few neural architecture is feed forward,
are current,
you know,
uh,

281
00:16:30.320 --> 00:16:32.570
Hockfield networks.
Once you get to know a few,

282
00:16:32.571 --> 00:16:36.200
you realize that they're all just the same thing but just different ordering of

283
00:16:36.201 --> 00:16:37.070
operations.

284
00:16:37.280 --> 00:16:41.450
So you kind of just jumble up this pile of Matrix math and that's your new

285
00:16:41.510 --> 00:16:43.280
neural network,
that's your new architecture.

286
00:16:43.281 --> 00:16:46.130
And sometimes you'll achieve state of the art performance with that.

287
00:16:46.131 --> 00:16:49.630
That's really how it works.
That is AI research,

288
00:16:49.660 --> 00:16:53.960
jumbling up these what are called differential blocks and seeing what's going to

289
00:16:53.961 --> 00:16:56.600
give a better output.
And so this is one example.

290
00:16:56.601 --> 00:16:59.120
It's an encoder decoder architecture,
right?

291
00:16:59.121 --> 00:17:01.640
So input sequence of past prices,

292
00:17:01.820 --> 00:17:04.850
output will be the sequence of the next price is based on it,

293
00:17:04.851 --> 00:17:07.540
what it's going to predict.
And uh,

294
00:17:07.580 --> 00:17:10.370
both of those videos should show you in detail how the transformer works.

295
00:17:10.400 --> 00:17:15.400
So how did I build a transformer for tensorflow 2.0 because I couldn't find one.

296
00:17:15.920 --> 00:17:18.170
I could not find a transformer on get hub.

297
00:17:18.440 --> 00:17:22.190
Unbelievably that was written in tensorflow 2.0 so what did I do?

298
00:17:22.191 --> 00:17:24.260
Did I build it from scratch?
No.

299
00:17:24.440 --> 00:17:29.440
What I did was I found an existing transformer that this guy built on Kaggle

300
00:17:30.260 --> 00:17:32.200
Shoe Gian Shadow to tissue Gian.

301
00:17:33.410 --> 00:17:37.400
So this was an existing transformer network that this guy built on Kaggle and it

302
00:17:37.401 --> 00:17:41.810
was built for tentraflow 1.0 and what I did was I copied and pasted it and I

303
00:17:41.811 --> 00:17:46.490
repurposed it for tentraflow 2.0 so he might be asking how did you repurpose

304
00:17:46.491 --> 00:17:50.670
that for tension flow 2.0 and the answer is that it didn't work at first.

305
00:17:50.670 --> 00:17:54.330
Once I installed tensorflow 2.0 when I could have done it's,

306
00:17:54.331 --> 00:17:57.210
I could have used that script that I talked about that converts everything to

307
00:17:57.211 --> 00:18:02.211
2.0 but instead what I did was I just like manually went through and I changed

308
00:18:02.551 --> 00:18:04.920
it myself just to learn what the differences are.

309
00:18:05.310 --> 00:18:09.870
And it turns out that the only difference was rather than using check this out

310
00:18:10.290 --> 00:18:12.900
rather than using,
uh,
from Ken Ross.
Dot.
Models.

311
00:18:12.901 --> 00:18:14.760
All of these imports just said Care Os.

312
00:18:15.450 --> 00:18:18.270
What I did was I just had to change it to tensorflow.

313
00:18:18.330 --> 00:18:21.630
Dot Care Ross and then a compile for tentraflow 2.0 why?

314
00:18:21.631 --> 00:18:22.950
Because like I said before,

315
00:18:23.040 --> 00:18:27.450
Ken Ross is now a part of tentraflow 2.0 and so there we go.

316
00:18:27.451 --> 00:18:31.260
We got a bleeding edge model.
Never been built before and 2.0 at least publicly.

317
00:18:31.261 --> 00:18:34.120
Definitely internally.
They have this at Google.
Uh,

318
00:18:34.210 --> 00:18:39.150
and then it's going to compile and hopefully this works
great.
Just like that.
See,

319
00:18:39.180 --> 00:18:42.780
and this a big model.
It's,
it's got a lot,
there's a lot there.

320
00:18:42.781 --> 00:18:44.820
We were not going to go into all that theory.
Uh,

321
00:18:45.120 --> 00:18:48.000
we built it there and then we fit it in.
I already have this right here for you.

322
00:18:48.030 --> 00:18:50.910
My training code,
it's going to be in the,
in the video description.

323
00:18:51.060 --> 00:18:54.660
This actually took a while to train a while,
meaning 20 minutes,

324
00:18:54.930 --> 00:18:58.980
which is not that long.
And then we have a prediction of the price right here.

325
00:18:59.070 --> 00:19:03.180
Okay?
So it's not that good,
but it's,
it's not bad.
It's like they're,

326
00:19:03.181 --> 00:19:08.070
so we just need more data.
But the point is that we train this in the cloud.

327
00:19:08.071 --> 00:19:13.071
We didn't have to use any of our local gps and we saved the model by this single

328
00:19:13.171 --> 00:19:15.270
line model.
Dot.
Say my model dot h five.

329
00:19:15.271 --> 00:19:17.970
So this will save it and then we can download it by just saying,

330
00:19:17.971 --> 00:19:19.770
let me download whatever file is here.

331
00:19:19.980 --> 00:19:23.580
And using this sidebar we can download whatever file is there.
So great.

332
00:19:23.610 --> 00:19:25.590
Now that we have trained a model,

333
00:19:25.650 --> 00:19:28.620
we want to serve this model to a user in the form of a web app.

334
00:19:28.621 --> 00:19:32.100
So let me take some time to help explain tensorflow serving to you.

335
00:19:32.101 --> 00:19:36.480
I really think this is one of the most powerful tools in the entire machine

336
00:19:36.481 --> 00:19:40.320
learning pipeline.
And it's because sometimes you want,

337
00:19:40.321 --> 00:19:43.290
you want a model to be able to continuously learn from data,
right?

338
00:19:43.291 --> 00:19:46.260
You don't want to just train a model,
it's trained on data,
it's static,

339
00:19:46.290 --> 00:19:48.270
you serve it to a user and it's just always there.

340
00:19:48.390 --> 00:19:50.400
You want it to continuously learn over time.

341
00:19:50.550 --> 00:19:54.630
And tensorflow serving allows your model to gracefully do this because there's a

342
00:19:54.631 --> 00:19:56.280
lot of things that can go wrong here.

343
00:19:56.400 --> 00:19:59.760
And that's why Google built it for themselves because they have these continuous

344
00:19:59.761 --> 00:20:04.170
training pipelines internally for tools like search and maps,
et cetera.

345
00:20:05.220 --> 00:20:10.220
So the idea is that it's got this version control system built in where you have

346
00:20:10.261 --> 00:20:11.130
a version of the model,

347
00:20:11.131 --> 00:20:15.240
it's called model one and it's trained on some data and end users are making

348
00:20:15.241 --> 00:20:18.630
requests,
is model posts,
requests,
get requests for inference.

349
00:20:18.900 --> 00:20:20.670
And this is happening,
but in the background,

350
00:20:20.880 --> 00:20:23.340
another version of this model is training on new data.

351
00:20:23.670 --> 00:20:25.830
And once this model has fully trained on new data,

352
00:20:25.980 --> 00:20:30.300
it will gracefully phase out that original model and it will phase in the newly

353
00:20:30.301 --> 00:20:33.180
trained model.
And then once that sin,
it's going to be training another one.

354
00:20:33.360 --> 00:20:36.330
Now this is just one version of how you could do this,
right?

355
00:20:36.420 --> 00:20:38.730
You can do this several ways.
You can have multiple models,

356
00:20:38.731 --> 00:20:41.760
you can have multiple models training,
multiple bottles serving.

357
00:20:41.910 --> 00:20:46.050
You can combine data from multiple outputs to create some ensemble technique.

358
00:20:46.200 --> 00:20:47.440
There's a lot we can do,

359
00:20:47.441 --> 00:20:51.970
but just to be very simple about this tentacle of serving allows you to create

360
00:20:52.930 --> 00:20:56.830
models that serve users in a production environment that allows you to

361
00:20:56.831 --> 00:21:01.780
experiment very fast.
And so think about how the data science pipeline looks.

362
00:21:01.781 --> 00:21:05.170
And if we look at the production grade ml pipeline,

363
00:21:05.240 --> 00:21:09.640
brining that ml code that we just did,
it's such a small part of it,
right?

364
00:21:09.641 --> 00:21:13.480
This configuration,
there's monitoring,
and this is all considered Dev ops,
right?

365
00:21:13.481 --> 00:21:16.240
Serving analysis,
machine resource management.
There's a lot.

366
00:21:16.241 --> 00:21:20.620
So tentacle of serving takes care of all of that for us,
which is awesome.

367
00:21:21.100 --> 00:21:22.420
So you might be thinking,
well,

368
00:21:22.421 --> 00:21:27.070
why can't I just use a regular web framework like Django or,
uh,
you know,

369
00:21:27.071 --> 00:21:31.060
what have you like flask to do this?
Well,
you could,

370
00:21:31.061 --> 00:21:34.420
you could rapid simple model with an API like flask or whatever,

371
00:21:34.630 --> 00:21:36.550
but there's some really good reasons we don't want to do that.

372
00:21:36.580 --> 00:21:40.780
The first reason is that serving is faster because it was optimized for a

373
00:21:40.781 --> 00:21:45.730
continuous versioned model environment because that's what they do at Google,

374
00:21:45.760 --> 00:21:46.000
right?

375
00:21:46.000 --> 00:21:50.920
They have CPU and GPU and sometimes TPU and they have to allocate resources

376
00:21:50.921 --> 00:21:54.310
efficiently,
both in terms of memory and in terms of space.

377
00:21:54.370 --> 00:21:59.020
So it has better time complexity to be computer sciency about it and it has

378
00:21:59.021 --> 00:22:00.610
better a space efficiency.

379
00:22:00.760 --> 00:22:03.730
And this version control system that's built in is just amazing.

380
00:22:03.970 --> 00:22:06.790
That's exactly what we want to happen.
And more importantly,

381
00:22:06.820 --> 00:22:10.630
they use it for their,
you know,
very scale,
very production,
great products.

382
00:22:10.750 --> 00:22:14.620
So we should use it as well.
And um,
you might be thinking,
well,

383
00:22:14.650 --> 00:22:18.130
does it use http?
Does it use a GRPC?

384
00:22:18.340 --> 00:22:20.080
And it used to use GRPC.

385
00:22:20.230 --> 00:22:23.950
And there's this great talk by my previous company Twillio love you Tulio that

386
00:22:23.951 --> 00:22:28.570
explains how grpc works.
But recently they added http support as well.

387
00:22:28.690 --> 00:22:30.850
So that's a great thing as well.
So it uses both.

388
00:22:30.880 --> 00:22:34.690
Now let's consider some concepts inside of tensorflow serving.
Okay,
so this is,

389
00:22:34.691 --> 00:22:37.630
uh,
this is a,
an image of the pipeline.

390
00:22:37.631 --> 00:22:39.820
The life cycle of what's called a servable.

391
00:22:40.300 --> 00:22:43.990
And a cerebral is the central abstraction of tensorflow serving.

392
00:22:44.000 --> 00:22:47.110
It's just a name of an object.
You know,
an object can be named anything.

393
00:22:47.111 --> 00:22:51.700
And inside of this programming paradigm,
a servable represents a model.

394
00:22:51.701 --> 00:22:54.460
So a truly trained model,
but it doesn't just have to be a model.

395
00:22:54.670 --> 00:22:58.600
It can also be some other algorithm,
you know,
some kind of any kind of algorithm.

396
00:22:58.601 --> 00:23:03.520
But server bowls are that central layer of abstraction that uses users will

397
00:23:03.521 --> 00:23:05.470
perform inference on or width.

398
00:23:06.590 --> 00:23:09.820
So the idea is that for a servable,
a separable could be,

399
00:23:09.821 --> 00:23:13.150
let's say in our case it's going to be that fully trained stock prediction
model.

400
00:23:13.151 --> 00:23:16.480
Okay,
so that's our servable.
Now the servable will have versions to it.

401
00:23:16.481 --> 00:23:18.700
There's a first version,
the second version,
the third version,

402
00:23:18.940 --> 00:23:23.620
and if we take those versions,
we can consider it as a stream and so in gets,

403
00:23:23.621 --> 00:23:25.150
the analogy would be a Dag,
right?

404
00:23:25.150 --> 00:23:28.240
A directed [inaudible] graph to be computer sciency about it,

405
00:23:28.480 --> 00:23:30.850
but in the tentraflow serving paradigm there,

406
00:23:31.030 --> 00:23:36.030
the server bowls make up a stream with all of their versions in it and models in

407
00:23:36.320 --> 00:23:40.270
in the serving paradigm can represent multiple service goals.

408
00:23:40.330 --> 00:23:43.750
So an actual model can represent multiple models,

409
00:23:43.960 --> 00:23:46.970
but we don't have to consider models right now let's just consider service goals

410
00:23:47.150 --> 00:23:49.250
because we're not going to have to deal with that ourselves.

411
00:23:49.880 --> 00:23:53.450
Then there are loaders,
so loaders will manage a server,
bubbles lifecycle,

412
00:23:53.480 --> 00:23:56.090
and in loader we'll pull a cervical using a source.

413
00:23:56.210 --> 00:24:01.210
So the source object has direct input output access to your file system.

414
00:24:01.820 --> 00:24:05.090
So a source,
we'll pull that model from your file.

415
00:24:05.240 --> 00:24:08.960
The loader will use a source to load that model into,
into memory.

416
00:24:08.990 --> 00:24:12.320
And then a manager,
which is kind of the controller in this pipeline,

417
00:24:12.560 --> 00:24:17.090
will detect what the inspired version is in which we can write logic for like

418
00:24:17.300 --> 00:24:20.660
which version of a model do we want to serve to a user.
The newest one,

419
00:24:20.780 --> 00:24:25.160
one that's trained in 30 days and tensorflow has some default aspired versions

420
00:24:25.161 --> 00:24:27.140
for us,
which we can use as well.

421
00:24:27.230 --> 00:24:29.930
But the manager will handle the full lifecycle of a servable.

422
00:24:30.050 --> 00:24:34.880
The manager will say,
okay,
we want to use this inspired version.
Okay,

423
00:24:35.750 --> 00:24:38.480
in court is the highest level,
um,

424
00:24:38.510 --> 00:24:42.860
superclass in everything tangible serving core,
which wraps everything here.

425
00:24:42.890 --> 00:24:45.320
So let me outline the steps here.
So first of all,

426
00:24:45.380 --> 00:24:49.310
we train a model called a transformer on data and use it for inference.

427
00:24:49.640 --> 00:24:51.320
Then we train it on newer data.

428
00:24:51.321 --> 00:24:55.340
So a user is inferencing this version of our transformer in real time.
Uh,

429
00:24:55.341 --> 00:24:59.570
meanwhile we're training on it again on newer stock data that it's pulling from

430
00:24:59.571 --> 00:25:01.280
the web via an API.

431
00:25:01.580 --> 00:25:05.390
And so the Thor's plug and creates a loader for specific version of this model.

432
00:25:05.630 --> 00:25:09.440
And this loader has all the metadata necessary to load this servable computation

433
00:25:09.441 --> 00:25:12.350
graph.
It points to it on the disc,
the source,

434
00:25:12.890 --> 00:25:15.860
the source then notifies the manager of the aspired version,

435
00:25:16.040 --> 00:25:17.750
which is this one right here,
this green graph.

436
00:25:18.650 --> 00:25:20.840
The loader will then tell the source,
okay,

437
00:25:20.870 --> 00:25:22.940
load the new version based on that version.

438
00:25:22.941 --> 00:25:27.590
Policy would specify the aspired version and then it will pull that from the

439
00:25:27.591 --> 00:25:29.810
file system into the source,
into the loader.

440
00:25:29.840 --> 00:25:31.460
The loader will then give it to the manager.

441
00:25:31.640 --> 00:25:36.020
The manager will then hand that servable that the result of that inference

442
00:25:36.021 --> 00:25:39.620
request back to the clients.
And that's how it works.
So this is,

443
00:25:39.680 --> 00:25:42.490
so this version system is happening in real time and uh,

444
00:25:42.530 --> 00:25:44.990
that's how tentraflow serving works at a high level.

445
00:25:44.991 --> 00:25:48.830
It has http and grpc support and now it's,

446
00:25:48.831 --> 00:25:52.890
we're onto step six of this tutorial.
We want to build tensorflow serving.

447
00:25:52.891 --> 00:25:54.680
So how are we going to do this?
Well,

448
00:25:54.681 --> 00:25:59.681
the easiest way I found was use this base repository called simple,

449
00:25:59.780 --> 00:26:02.270
simple tentraflow serving great stuff.

450
00:26:02.271 --> 00:26:06.230
What this guy did was he implemented all of these serving features,
right?

451
00:26:06.470 --> 00:26:10.880
Restful http API APIs supporting inference,
acceleration for Gpu,

452
00:26:11.000 --> 00:26:14.030
supporting dynamic online and offline model versions.

453
00:26:14.031 --> 00:26:17.570
Basically everything we would want that we would have to build from scratch,

454
00:26:17.690 --> 00:26:21.860
which we don't have to remember.
This is a mentality that I want you guys,

455
00:26:21.861 --> 00:26:23.720
you wizards,
the loves of my life.

456
00:26:23.810 --> 00:26:28.520
This is a mentality that I want you to adopt because it's my mentality,

457
00:26:28.730 --> 00:26:31.130
this mentality of rapid experimentation,

458
00:26:31.340 --> 00:26:35.420
of not doing anything that is unnecessary,
fastest method to prototype.

459
00:26:35.540 --> 00:26:36.890
If there exists components,

460
00:26:37.010 --> 00:26:40.700
if there exists pieces of a puzzle in terms of code on get hub,

461
00:26:40.760 --> 00:26:42.740
we don't have to build that ourselves.
Right?

462
00:26:43.330 --> 00:26:47.310
And the first version of Uber just combined a bunch of existing Api is together

463
00:26:47.430 --> 00:26:49.380
and slapped a pretty interface on it,
right?

464
00:26:49.650 --> 00:26:52.950
Uber use payments from stripe maps from Google,

465
00:26:52.951 --> 00:26:56.460
which did everything it showed where drivers were,
it even did routing for them.

466
00:26:56.490 --> 00:26:56.941
Of course,

467
00:26:56.941 --> 00:27:01.530
nowadays they have their own routing algorithms using deep RL and some amazing

468
00:27:01.531 --> 00:27:04.230
work.
But my point is when it comes to a prototype,

469
00:27:04.380 --> 00:27:08.340
just put piece of the puzzle together to get something very basic out there and

470
00:27:08.341 --> 00:27:09.420
then improve it over time.

471
00:27:09.421 --> 00:27:13.320
So my point of saying all of that is that we're going to build off of this

472
00:27:13.321 --> 00:27:17.730
existing simple tentraflow serving demo at all of our functionality to it.

473
00:27:17.731 --> 00:27:21.450
And that is the first version of our APP.
So let's get right to it.

474
00:27:21.451 --> 00:27:25.770
I'll first of all download this app and it's going to take a while to download.

475
00:27:26.280 --> 00:27:28.950
Let's see what it asks us to do.
Okay.

476
00:27:28.951 --> 00:27:31.410
So we just have to install it.

477
00:27:32.920 --> 00:27:36.460
We can either install it with pip from the source.

478
00:27:38.500 --> 00:27:42.460
So we'll go ahead and install it from the source.

479
00:27:42.940 --> 00:27:47.770
So what we have to do is say setup.py as it's saying right here,
and get help.

480
00:27:47.790 --> 00:27:48.623
Let me make this bigger

481
00:27:50.620 --> 00:27:54.790
terminal is my safe space install.

482
00:27:56.130 --> 00:27:56.890
<v 1>Okay.</v>

483
00:27:56.890 --> 00:27:57.950
<v 0>Huh.
Awesome.</v>

484
00:27:58.400 --> 00:28:03.400
Now we will develop as he says here,

485
00:28:03.891 --> 00:28:08.630
or she develop.
Great.

486
00:28:09.170 --> 00:28:12.700
And lastly,
we'll do a Bazell build of it.

487
00:28:16.470 --> 00:28:18.420
Awesome.
Okay.
So that all of that worked.

488
00:28:18.660 --> 00:28:21.480
So now what we're gonna do is we're going to start the server with the saved

489
00:28:21.481 --> 00:28:25.980
models.
So this APP allows us to load different types of models by specifying,

490
00:28:26.010 --> 00:28:30.210
okay,
simpletons role serving and then what's the model that we want to load and

491
00:28:30.211 --> 00:28:31.500
hopefully this works.
Okay,

492
00:28:31.501 --> 00:28:34.500
so now we have this app running on our local machine called tit,

493
00:28:34.501 --> 00:28:38.760
simple tensorflow serving and it allows us to load up any type of model that we

494
00:28:38.761 --> 00:28:39.151
want.

495
00:28:39.151 --> 00:28:42.900
And there are a lot of different models that this guy has put into this app and

496
00:28:42.901 --> 00:28:46.440
we can see those models right here.
So models.
In fact,

497
00:28:46.490 --> 00:28:48.540
we'll just look at it on our local machine.
Let's check it out.

498
00:28:50.990 --> 00:28:55.460
All these different models for em and ist for detecting iris flowers.

499
00:28:55.461 --> 00:28:56.960
You know all those different types of models.

500
00:28:56.961 --> 00:29:01.460
We have here models that were trained in mx nets that we can then convert into

501
00:29:01.461 --> 00:29:04.940
tentraflow using onyx and different language agnostic tools,

502
00:29:04.941 --> 00:29:06.230
library agnostic tools.

503
00:29:06.620 --> 00:29:11.330
The whole point is notice how the models are stored right here and they have

504
00:29:11.390 --> 00:29:15.750
both a proto buff file and a variables file.
Those are the only two dependency.

505
00:29:15.751 --> 00:29:19.340
So using this boiler plates templates application,

506
00:29:19.580 --> 00:29:21.470
we can train a model like we just did in the cloud,

507
00:29:21.680 --> 00:29:26.540
load it or serve it via this web app and wrap all sorts of functionality around

508
00:29:26.541 --> 00:29:28.970
it,
like user authentication,
et cetera.

509
00:29:30.050 --> 00:29:33.440
And it will be able to predict using that data just like we saw right here.

510
00:29:33.830 --> 00:29:37.910
So let's take a look at this code and see what exactly it's doing and how it's

511
00:29:37.911 --> 00:29:40.640
doing,
what it's doing.
So if we go into this code,

512
00:29:40.641 --> 00:29:42.010
let me make it little bit bigger.

513
00:29:43.540 --> 00:29:43.960
<v 1>Okay,</v>

514
00:29:43.960 --> 00:29:48.580
<v 0>let's go into what looks like the main code server.</v>

515
00:29:48.640 --> 00:29:52.120
Server dot.
Py.
That looks important.
So in server dot pie,

516
00:29:53.950 --> 00:29:54.330
<v 1>okay,</v>

517
00:29:54.330 --> 00:29:58.620
<v 0>we see that it's using flask and it's wrapping.</v>

518
00:29:58.621 --> 00:30:02.160
It's both using flask and tensorflow serving.

519
00:30:02.190 --> 00:30:04.950
So flask creates an AP,
an http Api,

520
00:30:04.951 --> 00:30:08.400
and then internally it's using serving four model versioning.

521
00:30:09.390 --> 00:30:14.010
And inside of this we'll see that depending on which model you choose,

522
00:30:14.011 --> 00:30:18.100
a different inference service is loaded up,
right?
So we have,
we can have onyx,

523
00:30:18.150 --> 00:30:20.640
we could have a Pi torch model,
we have a tensor flow model.

524
00:30:20.910 --> 00:30:23.610
And so in that example we loaded up a tensorflow model.

525
00:30:24.090 --> 00:30:26.070
Then there the route there,
there are the routes,

526
00:30:26.071 --> 00:30:30.000
the routes for the different web pages that we have and we just need to add

527
00:30:30.001 --> 00:30:33.730
routes for user login and then you know a payment like,

528
00:30:33.750 --> 00:30:37.830
like purchase and then then we can leverage these existing routes,

529
00:30:37.980 --> 00:30:40.920
these existing functions like do inference.
So,
okay.

530
00:30:41.010 --> 00:30:44.790
But I'm very curious as to what this tentraflow infant service looks like

531
00:30:44.791 --> 00:30:49.320
because that's the one we're using here.
So for tentraflow inference service,

532
00:30:50.190 --> 00:30:52.470
what is doing is exactly what we talked about.

533
00:30:52.471 --> 00:30:55.950
See there's a function right here for dynamically reloading models,
right?

534
00:30:55.951 --> 00:30:58.860
So it starts a new threat to load models periodically.

535
00:30:59.250 --> 00:31:02.790
So it'll load up a model to start off.
And this is just continuously running.

536
00:31:03.180 --> 00:31:07.320
It'll load the model to start off that.
We feed it when we,
when we launch it,

537
00:31:07.590 --> 00:31:10.230
and then it's got functions for dynamically reloading models,

538
00:31:10.231 --> 00:31:12.570
creating new threads,
loading saved models.

539
00:31:12.571 --> 00:31:15.660
And it's going to call these as per the manager's requests,
right?

540
00:31:15.661 --> 00:31:19.590
So a lot of this boiler plate is already abstracted away from us.

541
00:31:19.830 --> 00:31:23.730
So all we have to do is define what that initial model looks like and then it's

542
00:31:23.731 --> 00:31:26.400
going to load up new versions of that model.
However,

543
00:31:26.401 --> 00:31:30.210
we do have to define where that data,
that new training data is coming from.

544
00:31:30.540 --> 00:31:31.740
And so what we can do

545
00:31:32.710 --> 00:31:37.180
as we can find in this code where it's asking for training data and then we can

546
00:31:37.181 --> 00:31:39.940
modify it.
So inference right here.

547
00:31:39.941 --> 00:31:44.680
So inference is happening within the context of dynamically loading and

548
00:31:44.681 --> 00:31:47.890
reloading models,
right?
So inferences,
what's constantly happening.
Okay,

549
00:31:47.891 --> 00:31:52.510
so inside of this training.py file right here,

550
00:31:52.690 --> 00:31:57.010
we'll notice that it is preparing training data from a local directory.

551
00:31:57.011 --> 00:32:02.011
So we can modify this so that it will download data using the Yahoo Finance Api

552
00:32:05.350 --> 00:32:08.170
from a specific date.
It will format that data,

553
00:32:08.200 --> 00:32:12.550
it will turn it into a request and it will then make a prediction using it.

554
00:32:12.700 --> 00:32:14.920
But right now we don't want to make a prediction,

555
00:32:14.921 --> 00:32:19.921
we just want to download that data as a request and then format it as an input.

556
00:32:20.260 --> 00:32:24.100
And then we'll say,
we'll create a place holder around it,
shape equals none.

557
00:32:24.580 --> 00:32:26.530
And then we will say

558
00:32:28.300 --> 00:32:32.020
this request Jason Data.
It's not like that.
This is input data.

559
00:32:35.240 --> 00:32:38.320
Tf Dot placeholder.
This is our train data actually.

560
00:32:39.800 --> 00:32:43.490
So there are,
so this is the training file.
So whenever a model needs to train,

561
00:32:43.491 --> 00:32:47.240
it's going to use this and it's going to continuously use that new data that we

562
00:32:47.241 --> 00:32:49.250
are pulling from the web.
We have this API.

563
00:32:49.550 --> 00:32:51.830
Then inside of inference is going to make,

564
00:32:51.831 --> 00:32:55.790
it's going to perform inference and these models are going to be trained

565
00:32:56.360 --> 00:33:00.470
dynamically,
right?
So all of these functions,
load saved,
model version,

566
00:33:01.730 --> 00:33:05.780
dynamically reload models,
load custom operations.

567
00:33:06.140 --> 00:33:09.560
This is happening in realtime as part as part of our tensorflow inference

568
00:33:09.561 --> 00:33:10.394
service,

569
00:33:10.550 --> 00:33:14.450
which is all we needed to do was define where that new data input is coming
from.

570
00:33:14.600 --> 00:33:14.991
We already,

571
00:33:14.991 --> 00:33:19.100
we've already trained that data from the previous stock data and then we'll

572
00:33:19.101 --> 00:33:22.880
define an interval like let's say every 30 days or sorry,

573
00:33:22.881 --> 00:33:26.270
every two hours we'll train a new model every one hour.
You know,

574
00:33:26.271 --> 00:33:29.030
we can change that up,
but the point is using a timer.

575
00:33:29.210 --> 00:33:32.640
But the point is that we now have an infant service.
It's running in real time.

576
00:33:33.290 --> 00:33:35.510
And now we want to,
uh,

577
00:33:35.540 --> 00:33:38.450
we want to create user authentication,

578
00:33:38.451 --> 00:33:43.451
we want to create a payment functionality and we want to add that to our

579
00:33:44.391 --> 00:33:47.420
existing tentraflow serving apps.
So how do we do that?
Well,

580
00:33:47.421 --> 00:33:52.070
it turns out that just last week I made this AI startup prototype,

581
00:33:52.190 --> 00:33:55.730
which data a lot of this boiler plate code,
which I can copy and paste.

582
00:33:55.820 --> 00:33:59.960
So basically in the layout I said,
you know,
here's my background color.

583
00:33:59.961 --> 00:34:03.890
I generated that logo using the tool brand mark,

584
00:34:03.891 --> 00:34:08.540
that io I talked about before.
And then I said,
okay,
so here's the,

585
00:34:08.570 --> 00:34:11.810
here's the logo right here that I just added it as a source.

586
00:34:11.990 --> 00:34:13.520
I uploaded it to injure,

587
00:34:15.140 --> 00:34:18.590
right neuro fund named at that,

588
00:34:19.640 --> 00:34:20.473
place it there.

589
00:34:20.540 --> 00:34:24.770
And then I use stripe to create that payments file,

590
00:34:24.771 --> 00:34:28.780
which is in layout dot.
Html.
So here's the paint,

591
00:34:28.940 --> 00:34:30.230
here's the payment page,
right?

592
00:34:30.231 --> 00:34:34.430
So if these are as if the user has authenticated and make them pay,

593
00:34:34.700 --> 00:34:36.620
and then it's going to make a charge to post.

594
00:34:36.621 --> 00:34:40.490
So I'll just take these files and copy them to this existing repository.

595
00:34:40.610 --> 00:34:43.660
And once those files are in my templates file,
now it's going to,

596
00:34:43.970 --> 00:34:46.190
I basically took all that existing code.

597
00:34:46.340 --> 00:34:49.490
I'm only using the backend coats and none of that front end code.

598
00:34:49.491 --> 00:34:50.810
Whenever a user logs in,

599
00:34:50.930 --> 00:34:55.070
it's going to use a sequel database to store that username and password.

600
00:34:55.610 --> 00:34:56.660
Then it's going to say,

601
00:34:56.690 --> 00:35:00.860
well pay with stripe and then the user pays with stripe a hundred bucks,

602
00:35:00.890 --> 00:35:04.340
which I hard coded and it can be anything.
It's going to take two of those bucks,

603
00:35:04.341 --> 00:35:08.600
send them to my personal stripe accounts,
and then the rest of it,
the $98,

604
00:35:08.601 --> 00:35:12.620
it's going to invest using uh,
the Quandl Api.

605
00:35:12.800 --> 00:35:15.770
And then any other API's we want to invest with.
And we're going to,

606
00:35:15.800 --> 00:35:19.850
we're going to store all of those tokens,
that token for a specific user id,

607
00:35:19.970 --> 00:35:24.740
a token for the specific payment id that this user made and the specific model

608
00:35:24.741 --> 00:35:28.100
that the user is using inside of the SQL database as rows.

609
00:35:28.280 --> 00:35:32.630
And that makes it easy to find an index.
And once we have that,

610
00:35:33.020 --> 00:35:36.770
then we can add that the rest of the logic for us,
we had the inference,

611
00:35:37.380 --> 00:35:41.430
we have the user
off logic,
we have the payment logic,

612
00:35:41.431 --> 00:35:44.880
it's just a simple stripe.
And then the rest of it is just formatting html.

613
00:35:44.881 --> 00:35:49.140
So it looks nice.
So recall how in the original demo that I had here,

614
00:35:49.260 --> 00:35:54.260
I basically just copied and pasted this line chart to just show the apple price.

615
00:35:55.471 --> 00:36:00.000
And I also hard coded it to choose apple.
But what we can do is we can,

616
00:36:00.030 --> 00:36:02.430
but it's predicting using that time series data,
right?

617
00:36:02.460 --> 00:36:03.930
What the next best price would be.

618
00:36:03.960 --> 00:36:08.580
What we can do is have it perform inference on several different stock prices.

619
00:36:08.730 --> 00:36:12.210
Find the Delta between the prediction and the actual result and whichever one

620
00:36:12.211 --> 00:36:15.450
has a smaller delta,
we'll use that one and we'll invest in that.

621
00:36:15.451 --> 00:36:19.980
So we'll do a stock price dot invest,
whatever the price is,
right?
So we,

622
00:36:20.130 --> 00:36:23.180
we need to authenticate with some sock Api,
but

623
00:36:25.320 --> 00:36:28.250
which,
you know there are several,
I like the Quanta one,
but there's,

624
00:36:28.280 --> 00:36:32.640
there's several of them.
Alpaca Commission,
Free Api stockbrokers you can build.

625
00:36:32.641 --> 00:36:34.560
And trade with real time market data for free.

626
00:36:34.710 --> 00:36:38.550
You get an Api key and then you can use it with zero commission,

627
00:36:38.551 --> 00:36:39.384
which is awesome.

628
00:36:39.660 --> 00:36:44.610
So we have connected our API for stock price pulling and making purchases.

629
00:36:44.850 --> 00:36:48.630
We have integrated that with stripe user auth and inference and not just any

630
00:36:48.631 --> 00:36:49.230
inference,

631
00:36:49.230 --> 00:36:53.460
dynamically continuously training inference using tensorflow serving and not

632
00:36:53.461 --> 00:36:57.450
just any tentraflow serving tensorflow 2.0 there's a lot more to this code.

633
00:36:57.451 --> 00:37:00.690
You'll find it all in the video description.
If you have any questions,

634
00:37:00.691 --> 00:37:02.370
any comments,
let me know in the comments section.

635
00:37:02.371 --> 00:37:05.820
I'm always trying to improve my content,
improve my code quality,

636
00:37:05.980 --> 00:37:09.510
improve the topics that I'm talking about to make sure that I am providing as

637
00:37:09.511 --> 00:37:11.580
much value as possible for you guys.

638
00:37:11.760 --> 00:37:15.150
And it's a Saturday morning and I'm here recording this because I love you guys

639
00:37:15.151 --> 00:37:17.550
and I want this to be released very soon.

640
00:37:17.551 --> 00:37:20.140
So I hope you found this video educational and inspirational.

641
00:37:20.190 --> 00:37:21.990
What's the next AI startup you're going to build?

642
00:37:21.991 --> 00:37:25.020
Let me know in the comment section and please subscribe for more programming

643
00:37:25.021 --> 00:37:29.230
videos.
For now,
I've got to invest in myself,
so thanks for watching.

