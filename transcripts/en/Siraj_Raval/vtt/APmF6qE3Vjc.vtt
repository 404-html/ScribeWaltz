WEBVTT

1
00:00:02.270 --> 00:00:03.840
Right task this starting.

2
00:00:11.940 --> 00:00:12.773
<v 1>Okay.</v>

3
00:00:14.960 --> 00:00:19.660
<v 0>All right.
Well we got here.
What do we have to do?
That's what I'm trying to ask.</v>

4
00:00:19.661 --> 00:00:22.390
What do we have here?
We have people in the house.

5
00:00:23.440 --> 00:00:26.980
Every body.
Yeah.

6
00:00:27.760 --> 00:00:31.690
Rajio convolutional network.
Yeah.
Okay.
Hi everybody.

7
00:00:31.750 --> 00:00:33.170
Welcome to the livestream.

8
00:00:33.240 --> 00:00:37.360
Today we are going to build a convolutional neural network and we're going to

9
00:00:37.361 --> 00:00:41.380
build a with just tensorflow.
We are not using care.
We are not using anything.

10
00:00:41.560 --> 00:00:43.900
In fact,
I'm going to take these off if we're not using anything.

11
00:00:43.901 --> 00:00:46.870
I'm not even using the headphone.
I'm not even using my hands.

12
00:00:46.871 --> 00:00:50.110
Actually we are just not skating.
I'm using my hands,
but what we're going to do,

13
00:00:50.111 --> 00:00:53.660
hi everybody.
We're going to build a convolutional neural network.

14
00:00:53.661 --> 00:00:57.350
Come just tensorflow and,
okay,
so what?

15
00:00:57.420 --> 00:00:59.860
That's what we're going to do and let me see who else is in here.

16
00:00:59.861 --> 00:01:04.140
We got no crafter and Simon.
We got Daniel and Anthony.
We got look in some bid.

17
00:01:04.160 --> 00:01:05.260
An RN do.

18
00:01:05.530 --> 00:01:10.530
Hard mode is on hard mode is on and well we have so many Joe people here,

19
00:01:11.350 --> 00:01:15.280
not audible.
Am I not audible?
You can't hear me.
Is that the case?

20
00:01:15.430 --> 00:01:19.030
Cause I'm gonna just turn this off.
I'm gonna just,
you can hear me right?
Bones,

21
00:01:19.031 --> 00:01:22.870
jaw.
Oh,
we've got an international crowd.
We got [inaudible],
we got Paolo,

22
00:01:22.990 --> 00:01:24.280
we got the whole world in here guys.

23
00:01:24.281 --> 00:01:29.281
We have 200 we have 200 countries represented in our community.

24
00:01:30.250 --> 00:01:31.330
That's amazing,
isn't it?

25
00:01:31.510 --> 00:01:33.430
So what we're going to do is we're going to build this and uh,

26
00:01:33.520 --> 00:01:36.960
let's start off with a five minute,
two and a half.
So just hit me questions.

27
00:01:37.180 --> 00:01:41.640
Just going to go into it because I'm excited and I hope you guys are okay.

28
00:01:42.970 --> 00:01:44.520
Give me what your best questions.

29
00:01:45.860 --> 00:01:46.260
<v 1>Okay.</v>

30
00:01:46.260 --> 00:01:49.290
<v 0>When is the hangout for patriots are,
it's going to be in two weeks.</v>

31
00:01:49.440 --> 00:01:52.410
I'll schedule it soon.
Thanks for the reminder.
I know you from Daniel walked.
Yes,

32
00:01:52.411 --> 00:01:55.470
I went to high school with him.
He's a great guy.
I'm doing great.
Thank you.

33
00:01:55.950 --> 00:01:59.130
You're awesome.
Too high from the Netherlands and France and Italy and India.

34
00:01:59.280 --> 00:02:01.110
Oh my God guys.
There we have,

35
00:02:01.140 --> 00:02:04.350
we have just started this community and we already have people doing amazing

36
00:02:04.680 --> 00:02:08.640
stuff.
We had someone who was,
who gave a talk on,
on our,
uh,

37
00:02:08.670 --> 00:02:10.320
somewhere I think in South Africa or something.

38
00:02:10.321 --> 00:02:14.160
We hit someone who got their dataset teacher on the first first page of Kaggle.

39
00:02:14.250 --> 00:02:17.700
So we have a lot of great stuff happening and we're just getting started.

40
00:02:17.701 --> 00:02:19.650
So hello from grease cap.
Why tensorflow?

41
00:02:19.651 --> 00:02:23.850
Because tensorflow is actually faster than num Pi.

42
00:02:24.210 --> 00:02:24.691
You heard me?

43
00:02:24.691 --> 00:02:28.740
Tensorflow is actually faster than num py wide because it runs on a different

44
00:02:28.741 --> 00:02:29.960
interpreter.
Then just python.

45
00:02:30.030 --> 00:02:33.400
The computation graph has its own interpreter and it's not,

46
00:02:33.420 --> 00:02:34.650
and it can run in parallel.

47
00:02:34.651 --> 00:02:38.460
So it's parallel execution and we'll talk about that during the talk from

48
00:02:38.461 --> 00:02:41.640
Antarctica only Eskimos.
Here we have Antarctica and the house.

49
00:02:41.820 --> 00:02:44.190
Where is the link to the Open Ai in GTA?
Five.

50
00:02:44.191 --> 00:02:48.960
I'll make a video on that within three.
Within a month.

51
00:02:50.050 --> 00:02:51.790
Please explain your hidden layer.
This tutorial,

52
00:02:51.820 --> 00:02:54.490
because in Pong live you didn't explain.
I will explain the hidden layers.

53
00:02:54.580 --> 00:02:58.960
I'm going to explain what's happening in each of the filter maps.
Okay.

54
00:02:59.350 --> 00:03:03.480
Three more minutes.
Any application of ML and robotics?
Uh,
sure.

55
00:03:03.490 --> 00:03:05.290
There's a lot control theory specifically,

56
00:03:05.291 --> 00:03:09.520
like ideal ways of moving your physical arm to pick up the object and you can

57
00:03:09.521 --> 00:03:12.700
run a loss on June optimization function use backpropagation and everything
else.

58
00:03:12.701 --> 00:03:13.630
Everything applies.

59
00:03:13.930 --> 00:03:17.790
It's just reinforcement learning m and I see exactly when to use them.

60
00:03:17.800 --> 00:03:21.760
An ice tea.
The code is in the description.
Google search bots,
not yet.

61
00:03:22.650 --> 00:03:26.810
Uh,
best resources currently available for learning about generative modeling.
Uh,

62
00:03:27.340 --> 00:03:31.960
wow.
I would say the best resources are for that Ian Goodfellow,

63
00:03:31.961 --> 00:03:34.510
his book because I mean he's the guy who made generative adversarial networks

64
00:03:34.511 --> 00:03:37.130
and so if anybody knows about it,
he does.
And that's kind of the,

65
00:03:37.160 --> 00:03:38.200
that's still a bleeding edge.

66
00:03:38.530 --> 00:03:42.220
Any video coming up on Apache spark and Mli Apache's like,
not that cool to me,

67
00:03:42.460 --> 00:03:46.790
but I mean if you send me a link,
maybe I'll,
maybe I'll be convinced.
Uh,

68
00:03:47.290 --> 00:03:50.110
CNN for speech.
I have a few videos on that search tension,

69
00:03:50.111 --> 00:03:52.120
full speech recognizer but I'll make more in the future.

70
00:03:52.330 --> 00:03:55.510
What is a good reference to learn about ml?
My channel,
watch all my videos.

71
00:03:55.511 --> 00:03:59.140
There is more content in my videos and most people don't recognize this.

72
00:03:59.290 --> 00:04:03.850
Then in the entire web I have,
I have written essay after essay,
week after week,

73
00:04:03.880 --> 00:04:05.980
all my scripts,
my videos are huge,

74
00:04:05.981 --> 00:04:09.760
huge technical writing scripts across almost every topic at this point.

75
00:04:09.820 --> 00:04:12.370
And we were just going to keep going and they're more topics and there's endless

76
00:04:12.371 --> 00:04:16.210
topics.
Two more questions and then we're gonna get started.
Resources for NLP.

77
00:04:16.230 --> 00:04:20.140
Let me,
let me talk slower
resources.

78
00:04:20.470 --> 00:04:23.470
There's just so many questions coming in guys.
By the way,

79
00:04:23.471 --> 00:04:26.050
let me just say that we have somebody from you,
Udacity in the house.

80
00:04:26.051 --> 00:04:26.884
His name is Lupe.

81
00:04:27.010 --> 00:04:30.580
So shout out to Luke and he's going to be in here to help answer some questions

82
00:04:30.581 --> 00:04:33.670
because we've got a lot of people here.
So any questions you have Lucas,

83
00:04:33.671 --> 00:04:37.060
NBN and straight.
So Luke,
if you're here,
shout us people can see you.
All right,

84
00:04:37.270 --> 00:04:40.490
so,
okay,
so two more questions.
Kevin Murphy.
Okay.

85
00:04:43.480 --> 00:04:47.020
Any image similarity detection NTF there is.
That's not what we're doing.

86
00:04:47.230 --> 00:04:50.140
We're not doing,
we're not doing a similarity detection right now.
Uh,

87
00:04:50.340 --> 00:04:54.760
but it is possible.
And Tf as is.
There's Luke right there.
Okay.

88
00:04:54.761 --> 00:04:56.650
So one more question and then we're gonna get started.

89
00:05:01.300 --> 00:05:03.850
How to practice ml in smartphone,

90
00:05:04.510 --> 00:05:07.870
how to practice ml in smartphone practice ml.

91
00:05:07.990 --> 00:05:09.780
You don't want to practice coding on a smart phone,

92
00:05:09.990 --> 00:05:14.250
but you can use ml on a spark phone by having a server with your,
uh,

93
00:05:14.800 --> 00:05:18.400
with your,
with your neural net.
And then you just call it with an API.
Don't run,

94
00:05:18.760 --> 00:05:22.090
don't run your deep deep model on your mobile phone because it's not going to

95
00:05:22.091 --> 00:05:24.490
work yet.
But we need more.
We need,
we need better,

96
00:05:24.580 --> 00:05:28.570
more robust models that run on less computation before we do that.
Okay,

97
00:05:28.571 --> 00:05:30.460
so that's it for our questions.
Let's get started with,

98
00:05:30.461 --> 00:05:32.500
this is going to be awesome.
We're going to run this code.

99
00:05:32.750 --> 00:05:35.650
The link to it isn't the read me.
Okay.
So let's start screen sharing and let's,

100
00:05:35.651 --> 00:05:36.610
let's get started.
All right.

101
00:05:38.560 --> 00:05:39.230
<v 1>Okay,</v>

102
00:05:39.230 --> 00:05:40.190
<v 0>here we go.</v>

103
00:05:45.960 --> 00:05:50.650
Entire screen,
all of it.
Share all of it.
Okay.
Okay,

104
00:05:51.040 --> 00:05:54.710
so here we go.
I see.
Here we go a lot.
So I'm getting better at certain things.

105
00:05:54.740 --> 00:05:57.380
I mean,
I like saying here he goes,
but I'm saying I'm blessed and is a,

106
00:05:57.410 --> 00:06:01.220
this is a function of having to do this every or wanting to do this every week.

107
00:06:01.820 --> 00:06:04.010
Okay,
so here's our code.
Okay,

108
00:06:04.011 --> 00:06:08.570
let me just lay that out and then let me get these comments every year so I

109
00:06:08.571 --> 00:06:11.000
could see them at the same time on my different screen.

110
00:06:12.590 --> 00:06:15.500
Let me make this a little bigger because we are really going to dive into this.

111
00:06:15.560 --> 00:06:19.880
We're really gonna go into this like all the details.
Okay.
So,

112
00:06:20.740 --> 00:06:21.573
<v 1>okay,</v>

113
00:06:22.660 --> 00:06:23.710
<v 0>so here we go.
With this.</v>

114
00:06:23.980 --> 00:06:28.450
Let me also just have my face in the corner because you got to have the face,

115
00:06:28.451 --> 00:06:32.740
I mean,
right.
He does not the screen importing the movie reporting.

116
00:06:33.700 --> 00:06:34.160
<v 1>Okay,</v>

117
00:06:34.160 --> 00:06:37.310
<v 0>there I am.
Whoa.
Too Big.
Too Much Raj.
It's never too much around.</v>

118
00:06:37.340 --> 00:06:39.980
There is for today,
right now.
Okay,
so there we go right there.

119
00:06:40.370 --> 00:06:41.900
And then the code was here.
Here we go.

120
00:06:42.940 --> 00:06:43.490
<v 1>Okay,</v>

121
00:06:43.490 --> 00:06:46.670
<v 0>we're going to build an,
we're going to build a convolutional neural net.</v>

122
00:06:46.671 --> 00:06:49.370
We're seeing,
and this is fake news.
Oh my God,

123
00:06:49.430 --> 00:06:53.780
please don't bring politics in here.
I am politics free.
I am politics free.
Okay,

124
00:06:53.781 --> 00:06:58.410
we are talking about Ai.
Don't bring that in here.
Okay,

125
00:06:58.500 --> 00:07:01.680
so we're going to CNN and why are we building a CNN?

126
00:07:01.681 --> 00:07:05.790
Why don't we just use open CV,
right?
Why don't we use open CV?
It's easier,
right?

127
00:07:05.791 --> 00:07:09.390
It's easier to understand.
We can just talk about a similarity because

128
00:07:10.890 --> 00:07:11.370
right?

129
00:07:11.370 --> 00:07:16.370
Because CNNS outperform every other type of outreach them for image

130
00:07:16.651 --> 00:07:18.990
classification.
They are the state of the art.

131
00:07:19.320 --> 00:07:23.430
The dataset we're going to use for this is the m n I s t dataset.
Okay?

132
00:07:25.320 --> 00:07:26.153
<v 1>Okay.</v>

133
00:07:26.210 --> 00:07:28.940
<v 0>We're going to use the M and ist Dataset and it looks like this.</v>

134
00:07:28.941 --> 00:07:31.960
And why are we using this Dataset?
Because it is younger.

135
00:07:31.970 --> 00:07:36.350
Kuhn was the guy who first used it in his 1990 remember the weekly video?

136
00:07:36.550 --> 00:07:39.590
He used it for his first,
uh,
competition on that in the 90s,

137
00:07:39.591 --> 00:07:41.420
which worked really good,
really well.

138
00:07:41.421 --> 00:07:45.050
But now it works even better because we have more data and more computing power.

139
00:07:45.230 --> 00:07:49.070
The other thing is it's a great easy to s to start with multi-class

140
00:07:49.071 --> 00:07:52.940
classification problem.
It's a multi-class classification problems,
right?

141
00:07:52.941 --> 00:07:57.740
There are 10 classes here,
one for every digit,
one for every digit,

142
00:07:57.741 --> 00:08:00.850
right?
So one would be one,
two would be two people.
I know.
Ego.

143
00:08:00.880 --> 00:08:04.140
It is a boring Dataset,
but it's not about the data set right now.
We're,

144
00:08:04.250 --> 00:08:07.220
the interesting part is going to be this model architecture and that's going to

145
00:08:07.221 --> 00:08:09.020
be the interesting part.
Okay.
So,

146
00:08:10.530 --> 00:08:10.950
<v 1>okay,</v>

147
00:08:10.950 --> 00:08:11.970
<v 0>five minutes to answer a question.</v>

148
00:08:11.971 --> 00:08:14.460
It's not enough for 350 50 people waiting a whole week,
man,

149
00:08:14.461 --> 00:08:17.790
that is quite the pressure.
But Hey,
it's all good because you know it's,

150
00:08:17.820 --> 00:08:20.810
it's Gucci,
it is Gucci.
Okay,
so here we go.
So that was,

151
00:08:20.910 --> 00:08:22.450
that's the M in ist Dataset.

152
00:08:22.470 --> 00:08:24.480
It's going to be multi-class classification problems.

153
00:08:24.930 --> 00:08:28.260
And this is better than a linear model because the best we can get with open CV,

154
00:08:30.070 --> 00:08:30.903
<v 1>okay?</v>

155
00:08:31.020 --> 00:08:32.820
<v 0>The best we can get with open CV is</v>

156
00:08:36.340 --> 00:08:40.190
of 91% so we're gonna use molten glass classification and this is what it's

157
00:08:40.191 --> 00:08:41.450
gonna look like.
So let's,
let's,

158
00:08:41.451 --> 00:08:43.580
let's start off by just looking at our architecture.

159
00:08:43.581 --> 00:08:46.730
Now this is a fully trained architecture that we are looking at right now,

160
00:08:49.140 --> 00:08:52.730
man,
man,
you guys have the funniest comments.
You guys are the funniest comments.

161
00:08:52.731 --> 00:08:54.290
I love you guys.
Okay,

162
00:08:54.291 --> 00:08:57.900
so this is what it a fully trained competent convolutional net looks like.

163
00:08:58.020 --> 00:09:01.440
And what we're gonna do is we're going to look at this in detail before we get

164
00:09:01.441 --> 00:09:03.810
to the code.
So let's just look at,
let me blow this up a little bit.
Okay,

165
00:09:03.811 --> 00:09:07.710
so here we go.
We're going to start off with an input image like seven.
Okay?

166
00:09:08.190 --> 00:09:10.410
We have an input image like seven and

167
00:09:12.170 --> 00:09:13.940
we're going to put it into our convolutional net.

168
00:09:13.941 --> 00:09:15.920
And it's going to output a class.

169
00:09:16.070 --> 00:09:20.150
The class is going to be one of 10 different classes.
Okay?

170
00:09:20.151 --> 00:09:23.690
So that's what we're going to do.
So how does it,

171
00:09:23.780 --> 00:09:25.760
how does it output that class is the question,

172
00:09:25.761 --> 00:09:30.470
what is the magic that is happening in a convolutional net to output a class?

173
00:09:30.680 --> 00:09:34.370
Well,
it has layers.
And so this is a trained network.

174
00:09:34.371 --> 00:09:37.460
So we're going to talk about a train network and then we're going to talk about

175
00:09:37.580 --> 00:09:42.230
how it became that.
Good.
So when we put an input image like seven,

176
00:09:42.231 --> 00:09:45.500
and it's going to go to the first convolutional where like you see right here,

177
00:09:45.501 --> 00:09:46.910
this first convolutional layer.

178
00:09:48.020 --> 00:09:52.880
And in the first convolutional layer we have 16,
uh,
filter matrices.

179
00:09:52.940 --> 00:09:56.280
These are 16,
five by five filters and built.

180
00:09:56.281 --> 00:09:58.700
Hers can be thought of as weights,
okay?

181
00:09:58.701 --> 00:10:00.860
They can be thought of as weights in a network.

182
00:10:02.630 --> 00:10:03.463
<v 1>Okay?</v>

183
00:10:03.620 --> 00:10:06.020
<v 0>These are 16,
five by five filters.
And what these,</v>

184
00:10:06.021 --> 00:10:09.560
what is going to happen with these filters is we're going to take this image and

185
00:10:09.561 --> 00:10:12.260
we're going to multiply each of the,
uh,

186
00:10:12.740 --> 00:10:16.100
we're going to multiply each of these filters by one pixel in the image.

187
00:10:16.101 --> 00:10:19.220
So it's going to go left to right.
It's going to go from left to right.

188
00:10:19.221 --> 00:10:22.190
And what does this look like?
Well,
I have this very handy little,

189
00:10:24.000 --> 00:10:25.640
I have it very handy little,
uh,

190
00:10:27.790 --> 00:10:28.280
<v 1>okay.</v>

191
00:10:28.280 --> 00:10:29.150
<v 0>Animation here,</v>

192
00:10:29.570 --> 00:10:33.800
which is also in the notes and I need to remove the parentheses.

193
00:10:33.970 --> 00:10:35.270
But this is what it's going to look like.

194
00:10:38.090 --> 00:10:40.510
It's under his blog and somebody's blog.
Where is it?
Where is it?
Where is it?

195
00:10:40.511 --> 00:10:42.790
There it is.
This is what it's going to look like,
right?

196
00:10:42.880 --> 00:10:45.520
It is involving the word convolutional,
the W.

197
00:10:45.580 --> 00:10:48.250
And I'm going to contrast it to other architectures in a second.
Okay?
Hold on.

198
00:10:49.080 --> 00:10:53.740
But did the word convolutional comes from consulting because we are convulsing

199
00:10:53.950 --> 00:10:58.690
from one part of the image across all of it involving mean sliding.

200
00:10:58.840 --> 00:11:03.400
We take our filter and we multiply it by,
uh,
it's,
it's,

201
00:11:03.430 --> 00:11:06.670
it's essentially a dot product.
We are doing matrix multiplication.

202
00:11:06.820 --> 00:11:10.450
That's all it is.
It's matrix multiplication.
We're taking our filter,

203
00:11:11.430 --> 00:11:11.880
<v 1>okay?</v>

204
00:11:11.880 --> 00:11:16.320
<v 0>We're taking our filter and we're multiplying it by every part of the input</v>

205
00:11:16.350 --> 00:11:19.620
image.
And it's going to,
and we're going to all of those,
uh,

206
00:11:19.680 --> 00:11:23.400
the results are going to,
are going to result in an,
in a feature map image.

207
00:11:23.401 --> 00:11:25.710
And now let's talk about what that feature map image looks like.

208
00:11:26.490 --> 00:11:27.323
<v 1>Okay?</v>

209
00:11:28.430 --> 00:11:32.400
<v 0>So,
okay,
so what,</v>

210
00:11:32.420 --> 00:11:36.510
we're going to multiply each of these images by one pixel in the input image and

211
00:11:36.511 --> 00:11:41.140
it's going to output a 16 channels.
And this,
each of these channels is a,

212
00:11:41.150 --> 00:11:44.880
is a matrix.
And we can think of this whole thing as a feature map.

213
00:11:44.910 --> 00:11:49.410
That's what we call it.
We call it a feature,
or we could call it an activation.

214
00:11:49.411 --> 00:11:51.420
Now both words for it.
And

215
00:11:53.780 --> 00:11:57.330
it's either a feature map or an activation map.
Just 16 channels of this.

216
00:11:57.570 --> 00:11:59.020
And so that's the first image,
right?

217
00:11:59.040 --> 00:12:01.680
We are multiplying one month right from left to right,
left to right,

218
00:12:01.681 --> 00:12:05.610
left to right.
Left,
right.
Let me show one more,
a little animation of this.

219
00:12:07.530 --> 00:12:08.363
<v 1>Yeah.</v>

220
00:12:08.700 --> 00:12:09.860
<v 0>Which one?
More little animation of it.</v>

221
00:12:13.090 --> 00:12:13.923
<v 1>Hold on.</v>

222
00:12:15.030 --> 00:12:16.980
<v 0>There were good.
So here's one more animation.</v>

223
00:12:18.050 --> 00:12:18.600
<v 1>Okay.</v>

224
00:12:18.600 --> 00:12:21.740
<v 0>Hey,
this animation,
right?
And this was in the weekly video.</v>

225
00:12:21.800 --> 00:12:24.260
It's sliding just like that.
And the outputs,
the feature map.

226
00:12:24.320 --> 00:12:28.220
So we can think of this feature map as one,
a big ass image,
right?
Uh,

227
00:12:28.221 --> 00:12:29.120
actually there's several,

228
00:12:29.150 --> 00:12:31.710
there's several images and it makes one big ass feature mouth.
Oh,

229
00:12:31.770 --> 00:12:34.940
so that's the word dress.
There are several images.
Okay.

230
00:12:35.420 --> 00:12:37.130
This is going to be uploaded to youtube right when I'm done,

231
00:12:38.670 --> 00:12:42.380
but it's better to walk the line.
Exactly.
So that's what's going to happen.
So,

232
00:12:42.381 --> 00:12:46.010
okay,
so that's what's happening in the first layer is going to create a bunch of

233
00:12:46.011 --> 00:12:50.710
images.
Guys.
Be Nice to each other.

234
00:12:50.950 --> 00:12:53.620
We're going to create a bunch of images.
And then on the,
in the next layer,

235
00:12:53.621 --> 00:12:54.850
it's a little more complicated.

236
00:12:54.851 --> 00:12:59.170
In the next layer it's a little more complicated because we are now,

237
00:12:59.171 --> 00:13:03.820
we have a 16 by 36,
uh,
set of filters.

238
00:13:04.000 --> 00:13:05.920
So there's six.
We don't actually see all of them here.

239
00:13:05.921 --> 00:13:09.310
We only have this burst 16,
set the section,
second 16.

240
00:13:09.311 --> 00:13:13.660
Set a depth to tell.
We'll probably play me in a movie one day for sure.

241
00:13:13.700 --> 00:13:16.090
I'm sure about if somebody,
well,
for sure.
Um,

242
00:13:16.091 --> 00:13:17.980
I'm convinced there's going to a movie about me one day.

243
00:13:18.160 --> 00:13:21.310
So we're going to have 60,
my 36 a convolutional layer.

244
00:13:21.610 --> 00:13:26.080
And each of these is,
we're gonna multiply it by each of these.
So for the first,

245
00:13:26.200 --> 00:13:27.460
so here's,
here's what's going to happen.

246
00:13:27.610 --> 00:13:30.430
So for this first image right up here where my,
where my mouse is pointed at,

247
00:13:31.010 --> 00:13:35.410
let me wait.
It makes us a little bigger.

248
00:13:35.880 --> 00:13:38.900
Does it actually didn't make it bigger?
It's just made everything but this big.

249
00:13:38.960 --> 00:13:41.550
So,
so good job man.
Good job man.

250
00:13:42.400 --> 00:13:43.233
<v 1>Hold on.</v>

251
00:13:44.350 --> 00:13:47.380
<v 0>So we're going to multiply each of these images by each of these pixels in one</v>

252
00:13:47.381 --> 00:13:50.800
image.
And we're going to do so all of these,
and we're going to sum them all up.

253
00:13:50.920 --> 00:13:54.670
So for,
so let's talk about this first left Corner Pixel.
At the top left,

254
00:13:54.910 --> 00:13:57.280
we're going to multiply every single weight up here,

255
00:13:57.281 --> 00:14:01.800
all 16 of them by that one pixel,
and we're going to sum them all together.

256
00:14:01.900 --> 00:14:04.630
And the sum of that makes up a single pixel right here.

257
00:14:04.900 --> 00:14:09.250
Then we're going to take the next 16 and multiply it by the second a pixel.

258
00:14:09.370 --> 00:14:11.110
And then the next [inaudible].
So we're going to take,

259
00:14:11.190 --> 00:14:13.360
so basically all of these feature weights,

260
00:14:13.510 --> 00:14:17.170
all of these filter weights are multiplied in some together to make a single

261
00:14:17.171 --> 00:14:20.650
image right here.
And this new feature map,
it's even bigger.

262
00:14:20.890 --> 00:14:24.070
And we're going to do that for every single image here.
So what happens is,

263
00:14:25.280 --> 00:14:29.130
so what happens is these channels,
these 36 channels there,
it's a,

264
00:14:29.140 --> 00:14:31.780
it's a bigger feature map and they're more dense.

265
00:14:31.900 --> 00:14:34.270
And what do I mean by more dense?
It's,
it's,

266
00:14:34.960 --> 00:14:39.460
it's only focused on the features that it thinks are relevant because all of the

267
00:14:39.461 --> 00:14:42.850
features and things are relevant are going to show up here then.
Okay,

268
00:14:42.851 --> 00:14:45.220
so once we have that,
so you have 16 yes,

269
00:14:45.400 --> 00:14:47.780
so we started with 16 filters and then we,

270
00:14:48.220 --> 00:14:53.120
we started with six 16 filters and then we get 16 by six filters and these are

271
00:14:53.121 --> 00:14:56.480
five by five pixels and it's just,
it's just a matrix of numbers.

272
00:14:56.690 --> 00:14:58.220
It's a matrix of numbers.
Okay.

273
00:14:59.930 --> 00:15:00.400
<v 1>Okay.</v>

274
00:15:00.400 --> 00:15:02.360
<v 0>Real Han Pinto.
Okay.
So,</v>

275
00:15:03.290 --> 00:15:05.780
so it's a matrix of numbers and then we think are fully connected.

276
00:15:05.781 --> 00:15:08.210
Layer right here are fully connected layer and we,

277
00:15:08.540 --> 00:15:12.200
and so what are fully connected layer does is it takes that huge

278
00:15:12.201 --> 00:15:16.580
multidimensional feature map and it squashes it into a two dimensional picture

279
00:15:16.581 --> 00:15:17.120
map.

280
00:15:17.120 --> 00:15:21.200
It's watches it into a two dimensional theater feature map just so we could then

281
00:15:21.201 --> 00:15:23.600
squash it with the sigmoid and the output layer.

282
00:15:23.810 --> 00:15:26.040
And what happened when we squash it with a sigmoid,
it's,

283
00:15:26.041 --> 00:15:30.740
it's going to give us one of these 10 different probabilities and one of these

284
00:15:30.741 --> 00:15:32.060
10 different probabilities.

285
00:15:32.150 --> 00:15:36.330
We could then convert to a class which is going to be seven.
Okay?

286
00:15:36.331 --> 00:15:39.660
That's the very highest level that we're going to talk about right here.

287
00:15:42.290 --> 00:15:43.400
Um,
okay,

288
00:15:43.401 --> 00:15:46.940
so that's the very highest level and we're going to talk about in detail as we

289
00:15:46.941 --> 00:15:50.750
write the code,
as we write the code,
we're going to talk about it in detail.

290
00:15:50.990 --> 00:15:52.680
Now one interesting thing about it,

291
00:15:52.920 --> 00:15:57.030
a convolutional nets that I really like is we can understand how they work,

292
00:15:57.210 --> 00:15:58.110
but we don't understand,

293
00:15:58.690 --> 00:15:58.930
<v 1>okay?</v>

294
00:15:58.930 --> 00:16:01.450
<v 0>So well we can understand perfectly how they work.</v>

295
00:16:01.630 --> 00:16:04.930
All the matrix multiplication we can get from a high level of why these series

296
00:16:04.931 --> 00:16:08.320
of abstractions can detect a feature or how they can detect a feature.

297
00:16:08.530 --> 00:16:11.350
But we don't know why it works so well.

298
00:16:11.351 --> 00:16:15.550
And that to me is very exciting and we'll talk about about that in a second.

299
00:16:15.551 --> 00:16:17.770
So that's the highest level.
So let's keep going now.

300
00:16:17.771 --> 00:16:20.770
Now we're going to get to start building this thing.
Okay?

301
00:16:21.700 --> 00:16:22.200
<v 1>Okay.</v>

302
00:16:22.200 --> 00:16:24.210
<v 0>Before we start,
let's,
let's just talk about what,</v>

303
00:16:24.240 --> 00:16:28.470
this is just another example of convolution that's happening in the first
filter.

304
00:16:28.830 --> 00:16:32.490
This is one more example.
So the rent.
So,
so here's the thing about that.

305
00:16:32.491 --> 00:16:34.200
So this is why it's red and black.

306
00:16:34.530 --> 00:16:38.250
So the red filter weights means that the filter has a positive reaction to the

307
00:16:38.251 --> 00:16:39.090
black pixels.

308
00:16:39.480 --> 00:16:43.290
While the blue filters means that culture has a negative reaction to the play

309
00:16:43.310 --> 00:16:45.420
back quick old pixels and why?

310
00:16:47.580 --> 00:16:48.413
<v 1>Okay.</v>

311
00:16:48.730 --> 00:16:51.730
<v 0>And why do I,
why do I talk?
What do I mean by positive and negative?</v>

312
00:16:51.790 --> 00:16:54.650
Positive means that it has detected something that there is,

313
00:16:54.940 --> 00:16:58.420
that there is something there and blue means that there is nothing there.

314
00:16:58.660 --> 00:17:02.260
And so what happens is it's only going to get what it considers to be relevant

315
00:17:02.530 --> 00:17:05.110
and this is what it considers to be relevant in the first feature map.

316
00:17:05.290 --> 00:17:07.000
Just this wine over here,

317
00:17:07.001 --> 00:17:11.410
this feature it considers to be the relevant feature in the first feature map.

318
00:17:11.440 --> 00:17:15.760
Okay.
That's the result of the first convolution.
And it does this for several.

319
00:17:15.761 --> 00:17:20.020
It's going to take several of these images.
They're all gonna look,

320
00:17:21.330 --> 00:17:24.700
but for different parts of the,
of the,
of the number,

321
00:17:24.760 --> 00:17:26.200
they're all going to look like the number seven,

322
00:17:26.201 --> 00:17:31.120
but it's going to highlight different parts of it.
Okay.
Some kid.
Yes,

323
00:17:31.121 --> 00:17:35.090
I did explain it.
Next video.
Thanks for calling that out.
Um,
okay.

324
00:17:36.520 --> 00:17:37.220
<v 1>Okay,</v>

325
00:17:37.220 --> 00:17:40.310
<v 0>so,
so that's what going to happen.
So now let's start running our code.</v>

326
00:17:40.311 --> 00:17:44.200
We'll start off by importing our dependencies.
We got intention flow and num,
py,

327
00:17:44.201 --> 00:17:47.120
psych it,
learn.
And we'll talk about each of these when we get to it.

328
00:17:47.330 --> 00:17:52.330
How does it determine what is relevant that that is the question.

329
00:17:53.100 --> 00:17:54.030
That is the question.

330
00:17:54.031 --> 00:17:57.240
We don't know why it determines the certain features as relevant,

331
00:17:57.241 --> 00:17:59.610
but we do know is it can detect what is rolling.

332
00:17:59.620 --> 00:18:04.410
We know how it detects relevancy by multiplying matrices together and then out

333
00:18:04.411 --> 00:18:07.260
putting a a binary yes or no,

334
00:18:07.610 --> 00:18:11.460
whereas in the feature is there or the feature is not,
but we don't know why.
Why?

335
00:18:11.461 --> 00:18:12.240
It's why.

336
00:18:12.240 --> 00:18:15.570
It's like why it's determining that this is the specific thing is relevant.

337
00:18:16.440 --> 00:18:19.590
So that's really interesting,
right?
So let's get started with this.

338
00:18:20.740 --> 00:18:21.290
<v 1>Okay.</v>

339
00:18:21.290 --> 00:18:24.080
<v 0>Basically magic.
No,
I mean we're going to figure this out.
I mean give it,</v>

340
00:18:24.081 --> 00:18:26.540
give it like a few months.
I'm sure someone's going to open a paper on this.

341
00:18:26.870 --> 00:18:28.220
So let's start building this.
Now.

342
00:18:28.400 --> 00:18:31.670
We're going to start out by defining our hyper parameters are hyper parameters

343
00:18:31.671 --> 00:18:34.400
in this case are going to be the convolutional layers.

344
00:18:34.670 --> 00:18:38.920
Why do we define a five by five filter size for this,
for this feature map.

345
00:18:38.930 --> 00:18:41.780
Now somebody asked me why I didn't do a uh,

346
00:18:42.080 --> 00:18:43.670
can I signed the difference between architecture?

347
00:18:43.671 --> 00:18:45.830
So let's talk about a fully connected layer for a second.

348
00:18:46.310 --> 00:18:50.330
Let's talk about a fully connected layer.
Okay,
so if you look at this image

349
00:18:52.430 --> 00:18:53.000
image,
it's,

350
00:18:53.000 --> 00:18:57.890
it's showing a box and this box represents a three d filter.

351
00:18:57.920 --> 00:19:01.070
It's representing a three d filtering,
a three dimensional filter.

352
00:19:01.071 --> 00:19:04.970
And the third dimension by the way,
is the depth,
which is RGB values.

353
00:19:05.060 --> 00:19:09.020
So it has three different two dimensional matrix matrices,
one for red,

354
00:19:09.021 --> 00:19:10.340
one for green,
one for blue.

355
00:19:10.730 --> 00:19:14.660
And the reason we're not using a normal feed forward neural network with a fully

356
00:19:14.661 --> 00:19:18.740
connected layer is because there would be a combination tutorial explosion.

357
00:19:18.980 --> 00:19:23.930
If we multiplied a three dimensional input image by a two dimensional

358
00:19:25.520 --> 00:19:29.030
set of weights,
it would be a huge number.
Okay?

359
00:19:29.240 --> 00:19:32.060
Especially for big images with 10 10 80 pixels.

360
00:19:32.390 --> 00:19:36.620
So that's why we use a convolutional layer instead of a fully connected layer.

361
00:19:36.830 --> 00:19:40.190
That's why we use that because it is a,
is a smaller,

362
00:19:41.540 --> 00:19:42.240
<v 1>okay.</v>

363
00:19:42.240 --> 00:19:46.640
<v 0>It gives us a smaller result.
So,
so back to where we were going.</v>

364
00:19:46.641 --> 00:19:48.620
So that's why we're,
that's why we're creating our filter map.

365
00:19:49.750 --> 00:19:50.583
<v 1>And</v>

366
00:19:53.100 --> 00:19:57.090
<v 0>it's three d because there are,
there are three color channels,
red,</v>

367
00:19:57.180 --> 00:20:02.100
green and blue,
red,
green and blue.
Okay.
So that's,

368
00:20:02.101 --> 00:20:06.480
so we define our filter sidebar as five by five so that's going to be a specific

369
00:20:06.481 --> 00:20:09.090
size for all of those little filters that we saw up there.

370
00:20:10.020 --> 00:20:10.250
<v 1>Okay.</v>

371
00:20:10.250 --> 00:20:11.780
<v 0>It's going to be a five by five cards.</v>

372
00:20:13.760 --> 00:20:14.593
<v 1>MMM.</v>

373
00:20:15.690 --> 00:20:17.850
<v 0>Okay.
Thanks.
Sorrow.
So,</v>

374
00:20:17.970 --> 00:20:20.790
and then we're going to find a number of filters are going to be 16 and so

375
00:20:20.791 --> 00:20:23.610
that's going to be in our first filter is going to be 16 of them.

376
00:20:23.790 --> 00:20:27.270
And then for their Burnett.
So first layer it's gonna be 16 or next one,

377
00:20:27.271 --> 00:20:28.560
there's going to be 36

378
00:20:29.400 --> 00:20:29.740
<v 1>okay.</v>

379
00:20:29.740 --> 00:20:32.900
<v 0>And I'll explain why we use a fully connected layer at the end because we do use</v>

380
00:20:32.901 --> 00:20:37.901
a fully connected layer at the end and we'll define it as a size to be 128 here.

381
00:20:38.480 --> 00:20:41.330
So those are our hyper parameters for our layers.

382
00:20:41.520 --> 00:20:45.740
Then we load our datasets or data set is going to be the MNI ISC dataset.

383
00:20:45.920 --> 00:20:50.260
We said 100 to true,
which means we're going to use one hot encoding.

384
00:20:51.030 --> 00:20:51.310
<v 1>Yeah.</v>

385
00:20:51.310 --> 00:20:55.630
<v 0>One hot encoding is it is an encoding scheme that is very simple that it just,</v>

386
00:20:56.110 --> 00:20:59.140
it,
it converts them to binary ones or Zeros,

387
00:20:59.290 --> 00:21:02.890
which is great for a simple classification,
which is what we're about to do.

388
00:21:03.220 --> 00:21:06.970
So this is our data is going to be for in the data initialization.
Why there's,

389
00:21:07.120 --> 00:21:11.350
why these numbers?
Well we could,
we could try,
we could try it.

390
00:21:11.410 --> 00:21:15.100
So choosing hyper parameters is its own field of study.

391
00:21:15.400 --> 00:21:17.990
Should we do big hyper parameters,
small hyper parameters.

392
00:21:18.220 --> 00:21:21.070
Usually we test out different things for guessing checks.

393
00:21:21.130 --> 00:21:23.680
They're actually hyper parameter optimization methods,

394
00:21:23.681 --> 00:21:28.120
search strategies for our neuroleptic.
Try out different sets of,

395
00:21:31.370 --> 00:21:32.203
<v 1>yeah,</v>

396
00:21:32.780 --> 00:21:35.300
<v 0>try out different sets of thanks Luke for answering that.</v>

397
00:21:35.570 --> 00:21:36.920
Try out different sets of,

398
00:21:41.650 --> 00:21:46.250
of ways,
uh,
of,
of hyper parameters.
So that's where a load loading data.

399
00:21:46.251 --> 00:21:47.540
And so we're going to use our,

400
00:21:47.660 --> 00:21:51.500
we're going to load up our training test and validation data right now.
Okay.

401
00:21:52.160 --> 00:21:55.550
And then we're going to define some more hyper parameters.

402
00:21:55.580 --> 00:21:59.420
So we know that those Mni is t images are 28 pixels by each dimension.

403
00:21:59.421 --> 00:22:02.150
So we'll define it by image size.
These are,
these are,

404
00:22:02.180 --> 00:22:03.710
we don't want to have a what,
what's,
what's,

405
00:22:03.730 --> 00:22:07.310
what's the computer science word for it?
We don't want to have not magic numbers.

406
00:22:07.640 --> 00:22:10.700
Uh,
but I think it's magic numbers,
right?
We don't want to have magic numbers.

407
00:22:10.701 --> 00:22:12.650
Those are just scattered,
uh,

408
00:22:12.680 --> 00:22:16.490
values in our code that we don't want to think about.
Ah,
right.

409
00:22:16.491 --> 00:22:18.890
So that's all we're going to define.

410
00:22:18.891 --> 00:22:21.530
These features are defined these variables beforehand.

411
00:22:21.890 --> 00:22:25.670
Then we're going to define our image slides as flats.

412
00:22:25.670 --> 00:22:29.060
Who's going to be a one dimensional array of this length and then our two bull.

413
00:22:29.240 --> 00:22:33.410
And so it's a tuple week because we're going to input a two pole into the,
uh,

414
00:22:33.810 --> 00:22:35.930
this is our input.
We don't have our image size.

415
00:22:35.960 --> 00:22:38.210
And then we're going to define the number of channels.

416
00:22:38.390 --> 00:22:42.800
There's going to be one because we're using gray scale.
Luckily for us,

417
00:22:42.950 --> 00:22:47.690
this,
uh,
so I talked about three d convolution.
When we have an Rgb,
uh,

418
00:22:47.790 --> 00:22:52.280
we were using RGB,
but in this specific case,
this is gray scale.

419
00:22:52.790 --> 00:22:57.460
These are gray scale,
uh,
m and ist numbers.
So there were all,

420
00:22:57.461 --> 00:23:00.350
you're going to find one channel,
but if we're using color images,

421
00:23:00.470 --> 00:23:03.890
we define how many channels we're going to use.
Three channels.
Yes,

422
00:23:03.891 --> 00:23:06.600
I'm doing a time series video on Friday.
It's going to be dope.

423
00:23:06.620 --> 00:23:08.120
You guys are gonna love,
it's gonna be really popular

424
00:23:09.810 --> 00:23:12.410
there would have finding the number of classes,
10 of them.

425
00:23:13.140 --> 00:23:13.540
<v 1>Okay?</v>

426
00:23:13.540 --> 00:23:16.840
<v 0>Okay.
Because there are 10 numbers.
Now let's plot out these images.</v>

427
00:23:16.841 --> 00:23:21.370
This is a simple numb five planning code to plot out the number of images.

428
00:23:22.300 --> 00:23:22.810
Okay?

429
00:23:22.810 --> 00:23:26.410
This is not where it can be used for CFR with some modifications that I'll talk

430
00:23:26.411 --> 00:23:30.250
about at the end.
So when we plan out these images,
this is what it looks like.

431
00:23:30.490 --> 00:23:33.670
It's going to it all.
It's not,
it's not,
it's not predicting anything here.

432
00:23:33.830 --> 00:23:38.470
It's just playing out the images and their labels.
Okay.
Images in their labels.

433
00:23:38.680 --> 00:23:40.210
Oh my God.
Time series is going to go,

434
00:23:40.270 --> 00:23:43.870
is going to be so amazing with LSTM networks.
I'm going to talk about on Friday.

435
00:23:44.350 --> 00:23:46.610
So that's his.
Now let's talk about tensorflow.
No,

436
00:23:46.611 --> 00:23:50.840
I talked about how tensor flow is scalable.

437
00:23:51.230 --> 00:23:54.220
It's scalable because it could be used on CPU and GPU.

438
00:23:54.500 --> 00:23:55.640
If you run it in the cloud,

439
00:23:55.641 --> 00:24:00.110
you can easily scale it across DPU and you can define how many gps do you want

440
00:24:00.111 --> 00:24:03.200
to run it off.
You cannot do that with just non pot.

441
00:24:03.740 --> 00:24:08.170
That's why it's better than using just non pot.
Any kind of,
uh,

442
00:24:08.300 --> 00:24:12.530
any kind of production grade machine learning that you want to do,

443
00:24:12.770 --> 00:24:15.830
do not do it with just on pie use tensor flow,

444
00:24:15.831 --> 00:24:18.560
because it is the best machine learning library that we have so far.

445
00:24:18.890 --> 00:24:21.710
So the first thing we're going to do before we start defining our computation

446
00:24:21.711 --> 00:24:26.711
graph is we're going to define helper functions for our weights and our biases.

447
00:24:27.110 --> 00:24:30.660
Our weights are going to be initialized at random when they're going to be

448
00:24:30.661 --> 00:24:33.710
initialized randomly,
and we're just defining variable for them.

449
00:24:33.711 --> 00:24:38.690
We're not doing anything else.
We're just defining variables and then our biases.

450
00:24:38.930 --> 00:24:42.200
Why are we using biases?
What is the point of biases?

451
00:24:42.201 --> 00:24:46.600
So explanations for use of biases are actually really bad or cross nets.

452
00:24:46.730 --> 00:24:50.300
We can think of biases as we can think of them very intuitively for linear

453
00:24:50.301 --> 00:24:53.130
Russian models because we just think of them as the Wa.

454
00:24:53.440 --> 00:24:58.070
We think of them as the y intercept.
Any y equals mx plus B slow formula.

455
00:24:58.250 --> 00:25:02.450
It's just a y intercept.
But for a multidimensional array,
or sorry,

456
00:25:02.710 --> 00:25:06.410
for multidimensional computation such as the case intenser flow.

457
00:25:07.250 --> 00:25:07.750
<v 1>Yeah,</v>

458
00:25:07.750 --> 00:25:10.870
<v 0>youth biases as a constant value across.</v>

459
00:25:10.910 --> 00:25:15.670
It's always going to be a constant value is carrying across the matrix back.

460
00:25:15.760 --> 00:25:19.330
And what this does is it improves convergence.
It makes sure that our,

461
00:25:19.470 --> 00:25:23.290
it makes sure that our model is more accurate by having a constant value.

462
00:25:23.291 --> 00:25:27.580
That kind of a kind of anchor point to where we started off in between where we

463
00:25:27.581 --> 00:25:31.390
started off and what we ended.
And we'll talk about biases more.
Okay.

464
00:25:32.210 --> 00:25:32.380
<v 1>Okay.</v>

465
00:25:32.380 --> 00:25:37.140
<v 0>They make it,
yeah,
so Heinz level,
it makes it easier for the math to optimize.
Um,</v>

466
00:25:38.470 --> 00:25:40.120
so,
okay,
so those are our two helper functions.

467
00:25:40.300 --> 00:25:44.770
We haven't actually started building our computation graph.
Yes.
Right.
Okay.

468
00:25:44.950 --> 00:25:47.710
We start building our computation graph.
Didn't do the math.

469
00:25:47.711 --> 00:25:49.240
It's going to be all right.
Uh

470
00:25:50.160 --> 00:25:50.400
<v 1>Okay.</v>

471
00:25:50.400 --> 00:25:53.820
<v 0>You can sit back and laugh,
but it's okay cause we're going to go so hard.</v>

472
00:25:54.000 --> 00:25:58.260
You're going to Barf in this class.
I rhymed all that by the way.

473
00:25:58.380 --> 00:26:01.920
So this is our convolutional layer in our convolutional layer.

474
00:26:02.010 --> 00:26:04.530
We're going to define our previous layer,

475
00:26:04.740 --> 00:26:07.140
then our input channels or filter size and number of filters.

476
00:26:07.141 --> 00:26:10.440
And then you're pulling two,
two.
Let's talk about pooling.

477
00:26:10.441 --> 00:26:14.970
I did not talk about Uli.
So before we,
we look at this,

478
00:26:15.120 --> 00:26:15.511
let's,

479
00:26:15.511 --> 00:26:18.870
let's go back to the image for a second and let's talk about two more things

480
00:26:18.871 --> 00:26:19.651
that we didn't talk about.

481
00:26:19.651 --> 00:26:23.070
Let's go all the way back up to this initial image that I showed you guys.

482
00:26:23.400 --> 00:26:26.220
So in the first convolutional layer and the second convolutional layer,

483
00:26:26.490 --> 00:26:31.110
it's not just involving,
it's performing to other operations is performing.

484
00:26:31.390 --> 00:26:35.820
Uh,
it's performing cooling and is performing Relu.
Now,

485
00:26:37.450 --> 00:26:39.820
now we perform Relu to reduce,

486
00:26:39.880 --> 00:26:44.880
to increase the nonlinearity of our that makes it easier for our model to learn

487
00:26:45.751 --> 00:26:49.920
nonlinear functions,
uh,
which is,
which is the case for this.
Uh,

488
00:26:50.040 --> 00:26:54.960
it turns all of our negative values into Zeros.
Okay.

489
00:26:54.961 --> 00:26:58.320
And then it,
which improves it only unique linearity.

490
00:26:58.350 --> 00:27:03.150
And we'll talk about that when we,
when we,
when we,
when we do that in a second.

491
00:27:03.151 --> 00:27:03.984
But,

492
00:27:04.960 --> 00:27:05.750
<v 1>uh,</v>

493
00:27:05.750 --> 00:27:07.640
<v 0>then we're also doing max pooling.</v>

494
00:27:07.641 --> 00:27:11.870
We're pooling is an operation where we just take the best parts of what we just

495
00:27:11.910 --> 00:27:15.740
calculated and by best,
the Max values,
which is those,

496
00:27:16.500 --> 00:27:19.550
it's kind of like involving were for every part of the Matrix.
We're just saying,

497
00:27:19.551 --> 00:27:23.120
what is the Max value from this matrix?
So if there's like six,
seven,
eight,
nine,

498
00:27:23.121 --> 00:27:25.520
we'll take nine and there there's a,

499
00:27:25.610 --> 00:27:28.970
there's an entire field of research over pooling and we'll talk about that later

500
00:27:28.971 --> 00:27:32.450
on.
But it's taking the Max value.
So back to where we were,

501
00:27:32.540 --> 00:27:37.310
I just wanted it to define those two
processes that we're doing.

502
00:27:37.920 --> 00:27:38.753
<v 1>Okay.</v>

503
00:27:39.440 --> 00:27:42.080
<v 0>So back to this,
the convolutional layer,</v>

504
00:27:42.470 --> 00:27:46.010
we're going to have an a shape and the shape is going to consist of all those

505
00:27:46.130 --> 00:27:49.790
hyper,
all of those parameters that we defined.
What is the size of our filters,

506
00:27:49.791 --> 00:27:53.750
the number of input channels,
which is one,
because this is a gray scale image.

507
00:27:56.940 --> 00:28:00.110
<v 1>Okay.
And the number</v>

508
00:28:01.110 --> 00:28:04.620
<v 0>filters because he's our weights now that we've actually created helper</v>

509
00:28:04.621 --> 00:28:09.360
functions.
And this is the,
this is the actual initialization a step,
right?
Well,

510
00:28:09.361 --> 00:28:10.380
for a convolutional layer,

511
00:28:10.500 --> 00:28:14.910
so our convolutional layer is actually a block and a consistent three
operations.

512
00:28:14.911 --> 00:28:15.420
Remember,

513
00:28:15.420 --> 00:28:19.830
a convolutional layer isn't just a series of matrix multiplication and a

514
00:28:19.831 --> 00:28:22.140
summation of all this.
It's also,

515
00:28:24.620 --> 00:28:25.550
it's also a

516
00:28:33.660 --> 00:28:37.810
right,
it's also a,
uh,
it's also relu.
And it's also,
um,

517
00:28:39.510 --> 00:28:41.620
what else did it beside relu it's also,

518
00:28:44.840 --> 00:28:45.850
it's also,

519
00:28:45.970 --> 00:28:46.803
<v 1>uh,</v>

520
00:28:47.790 --> 00:28:48.451
<v 0>using cooling.</v>

521
00:28:48.451 --> 00:28:51.600
So there are three operations that are happening in a convolutional layer.

522
00:28:52.700 --> 00:28:53.533
<v 1>Okay.</v>

523
00:28:56.110 --> 00:28:59.050
<v 0>Three operations.
And so this is the default tensor flow.</v>

524
00:28:59.290 --> 00:29:02.290
This is the default tensorflow,
convolutional Tootie

525
00:29:03.790 --> 00:29:04.870
function.
Okay?
And we'll,

526
00:29:04.871 --> 00:29:08.740
we're wrapping this in our own functions so that we can add biases and we can

527
00:29:08.741 --> 00:29:09.574
add,

528
00:29:13.310 --> 00:29:17.060
we can use biases and we can use weights.
Now here's another thing.

529
00:29:17.600 --> 00:29:20.840
Now in this competition where we know about her input,
we know about our weights,

530
00:29:20.960 --> 00:29:25.010
what our strides strides are.
I think of striding like in real life,
right?

531
00:29:25.011 --> 00:29:27.500
What are,
what,
what is a stride by the way?
Like a,
like a,

532
00:29:27.501 --> 00:29:30.740
normally a stride is when you like kind of,
you take a big stride,

533
00:29:30.770 --> 00:29:33.230
you take a big ass step,
you take a big step.

534
00:29:33.410 --> 00:29:37.220
And that would striding up is in internet it defines how,

535
00:29:37.520 --> 00:29:42.190
what are the intervals that we are
creating these multiplications,

536
00:29:42.340 --> 00:29:46.630
right?
So is it every pixel?
Is it every two pixels is every three pixels?

537
00:29:46.840 --> 00:29:50.380
That's what we define as strides.
So the smaller the stride,

538
00:29:50.500 --> 00:29:54.640
the more accurate it's going to be,
but it's more computation.

539
00:29:54.641 --> 00:29:55.480
So there's a trade off,

540
00:29:55.960 --> 00:29:59.230
more accurate classification for more con need computation.

541
00:29:59.680 --> 00:30:02.560
Then we're defining patty.
It's a massive big step.

542
00:30:03.220 --> 00:30:06.100
And then we're going to define padding.
So padding is going to be same,

543
00:30:06.220 --> 00:30:08.800
which means the input image is padded with Zeros.

544
00:30:08.920 --> 00:30:11.530
So the size of the output is the same.
Okay?

545
00:30:11.531 --> 00:30:16.210
So that means that the difference between the input image and the filters,

546
00:30:16.630 --> 00:30:18.730
the matrices aren't the same size.

547
00:30:18.790 --> 00:30:22.330
So we'll pad to pad the smaller one with Zeros.

548
00:30:22.480 --> 00:30:26.020
So they're the same size.
We wanted to be the same size,

549
00:30:26.021 --> 00:30:29.050
so it's easier to form matrix multiplication and so that,

550
00:30:29.051 --> 00:30:32.110
so the output is going to be the same.
That's what we performed Caddick

551
00:30:33.610 --> 00:30:35.680
then we're going to perform cooling.

552
00:30:35.950 --> 00:30:40.510
And so downsampling is what we is what we call this process of pooling.

553
00:30:40.930 --> 00:30:44.650
Downsampling is the name of this process.
We call all sorts of pooling.

554
00:30:44.860 --> 00:30:49.420
Max Pooling average pooling offers the cooling,
we call it a Max,

555
00:30:49.480 --> 00:30:52.600
we call it,
uh,
downsample and chancellors.

556
00:30:52.630 --> 00:30:56.800
Tensorflow has a built in function for this called Max pooling where we define

557
00:30:56.801 --> 00:31:01.690
the size of the,
of,
of the pool and the strides as well for the pool.

558
00:31:01.870 --> 00:31:05.050
So it's similar to convolution,
it's similar,
it's a similar process.

559
00:31:05.051 --> 00:31:07.570
It's a kind of like a flashlight that's shining over the image.

560
00:31:07.990 --> 00:31:11.740
And the part that is looking at,
remember it's called the receptive field.

561
00:31:11.920 --> 00:31:14.680
Whatever it's focused on is the receptive field.

562
00:31:16.960 --> 00:31:21.280
Okay,
so now,
and so then we'll define our right.
So then our third operation,

563
00:31:21.281 --> 00:31:25.510
and this is the third operation in every convolutional block is going to be

564
00:31:25.600 --> 00:31:28.510
rectified linear unit or Relu,
uh,

565
00:31:28.540 --> 00:31:31.420
which is going to calculate the Max Max value,

566
00:31:31.421 --> 00:31:34.390
which turns all the negative numbers,
two zeroes.

567
00:31:34.391 --> 00:31:38.530
It's of similar to absolute value and allows it to learn more complicated

568
00:31:38.560 --> 00:31:40.600
functions than just linear regression.

569
00:31:41.100 --> 00:31:45.570
Those are the three operations that occur in a convolutional blocks and in

570
00:31:45.571 --> 00:31:49.030
traditional CNN,
three blocks are there,
right?

571
00:31:49.031 --> 00:31:53.740
This happens three times and then squash it and it outputs a probability.

572
00:31:54.880 --> 00:31:57.700
This is going to return our layer,
which is what we,

573
00:31:58.090 --> 00:31:59.920
the resulting layer and the resulting weights.

574
00:31:59.950 --> 00:32:03.610
After we performed these three computations on it.
Okay?

575
00:32:04.900 --> 00:32:08.440
Now we're going to do that three times and then then we're going to flatten the

576
00:32:08.441 --> 00:32:13.300
layer.
We're going to find that using a fully connected layer.
So,
okay,

577
00:32:13.301 --> 00:32:16.690
so let me just talk about the steps here to flatten the layer,

578
00:32:17.040 --> 00:32:20.020
to flatten the layer that have some copy for a second

579
00:32:24.680 --> 00:32:25.790
to flatten a layer.

580
00:32:26.940 --> 00:32:27.410
<v 1>Okay,</v>

581
00:32:27.410 --> 00:32:29.630
<v 0>well,
why don't you first see the layer shape?
Okay,</v>

582
00:32:29.631 --> 00:32:31.390
the what is the shape of that layer?
What does the,

583
00:32:31.460 --> 00:32:34.460
what does the dimensions that it's going by,
and then we're going to say,

584
00:32:34.461 --> 00:32:37.940
how many features does this layer have?
Okay,
what are the features?

585
00:32:37.941 --> 00:32:41.150
And to get that,
we're going to the num elements function.

586
00:32:42.020 --> 00:32:46.310
We're going to use those features.
Those features are what we want to squash.

587
00:32:46.490 --> 00:32:49.850
And the word squash means reduced the dimensionality,
okay?

588
00:32:50.030 --> 00:32:53.630
We're going to reduce the dimensionality to a two dimensional vector,

589
00:32:53.780 --> 00:32:57.140
which we can then reduce even further into a scaler.

590
00:32:57.290 --> 00:33:00.620
And that statement went to the single value is going to be our probability.

591
00:33:01.690 --> 00:33:02.060
<v 1>Yeah,</v>

592
00:33:02.060 --> 00:33:03.500
<v 0>it's got to be our probability.</v>

593
00:33:04.190 --> 00:33:09.190
I am made up of a drive to solve intelligence because I have probable and I have

594
00:33:10.300 --> 00:33:13.550
see all the problems in the world and it is the most important thing.

595
00:33:13.590 --> 00:33:17.740
The entire world.
I will die for this cause I will die for this cause.
So

596
00:33:19.050 --> 00:33:19.550
<v 1>okay,</v>

597
00:33:19.550 --> 00:33:21.740
<v 0>layer flat is that last?</v>

598
00:33:22.620 --> 00:33:22.850
<v 1>Okay</v>

599
00:33:22.850 --> 00:33:26.500
<v 0>is that last shake.
Once we reshaped that number of features play,</v>

600
00:33:26.501 --> 00:33:29.420
your flight is going to be that two dimensional vector.
Okay.

601
00:33:29.540 --> 00:33:31.730
And then we were going to return that.
Okay.

602
00:33:33.020 --> 00:33:33.853
<v 1>Yeah.</v>

603
00:33:34.040 --> 00:33:34.873
<v 0>So then</v>

604
00:33:39.420 --> 00:33:40.740
so then for our fully connected layer,

605
00:33:40.741 --> 00:33:45.490
we're going to perform matrix multiplication and then
focus,
focus,

606
00:33:45.491 --> 00:33:50.470
focus.
So
hold on a second,
hold on a second.
Hold on.

607
00:33:52.640 --> 00:33:54.300
Once we find the layer,
we,

608
00:33:54.350 --> 00:33:57.350
we input it into the fully connected layer as a dementia.

609
00:34:00.950 --> 00:34:05.510
And it's going to output a is going to output a,
uh,
the fully connected layer.

610
00:34:05.540 --> 00:34:07.400
A probability.
That's,
that's what is output.

611
00:34:09.560 --> 00:34:12.590
It's going to help with a fully connected layer,
which they probability,
okay,
so,

612
00:34:14.370 --> 00:34:18.150
so the,
so we all we did so far,
we define our helper functions.

613
00:34:18.190 --> 00:34:20.530
Now let's build our graph using these helper functions.

614
00:34:20.710 --> 00:34:23.770
And because we define all of these complicated helper functions,

615
00:34:24.010 --> 00:34:27.390
now we can easily define our computation graph.

616
00:34:27.820 --> 00:34:31.450
So we start off with our placeholder value and the placeholder is going to take

617
00:34:31.451 --> 00:34:32.500
in that image,
right?

618
00:34:32.650 --> 00:34:36.910
The image is going to be a two dimensional grayscale image,
right?

619
00:34:36.920 --> 00:34:39.640
We need to be a number.
So it's going to be not just the inmates,

620
00:34:39.641 --> 00:34:42.550
we're also going to input the delay.
Okay?

621
00:34:43.010 --> 00:34:43.200
<v 1>Okay.</v>

622
00:34:43.200 --> 00:34:47.430
<v 0>A label.
So we have two placeholders for the pretty image and the label.</v>

623
00:34:47.970 --> 00:34:50.640
Then we're going to input it into our convolutional layer.

624
00:34:53.630 --> 00:34:54.290
Yeah,
I'm going to go,

625
00:34:54.290 --> 00:34:57.830
I'm going to do a Q and a session after this to explain things more.
Okay.
So,

626
00:34:57.860 --> 00:34:59.540
so write down your questions.
Okay.

627
00:35:00.420 --> 00:35:00.710
<v 1>Okay.</v>

628
00:35:00.710 --> 00:35:05.080
<v 0>All right.
So then let me remove me so I can,
yeah,
so,</v>

629
00:35:05.170 --> 00:35:06.260
so that's going to be that.
So then,

630
00:35:06.320 --> 00:35:08.450
so let's define our first convolutional layer.

631
00:35:08.600 --> 00:35:11.510
Let's define our first convolutional layer using our helper function that we

632
00:35:11.511 --> 00:35:12.344
created.

633
00:35:12.470 --> 00:35:16.610
Our first convolutional layer is going to take the images and input and create a

634
00:35:17.090 --> 00:35:18.110
set of filters.

635
00:35:18.290 --> 00:35:22.100
And each of those filters has a width and a height equal to the filter size that

636
00:35:22.101 --> 00:35:25.880
we defined.
And then finally,
when we wish to downsample it using Max pooling,

637
00:35:26.120 --> 00:35:28.790
so it's going to be half the size.
That's going to be our output.

638
00:35:28.791 --> 00:35:32.150
It's going to be that feature map that's going to be our first filter.

639
00:35:32.151 --> 00:35:35.360
And we can look at what happened here,
right?
It's a,
it's a tensor flow objects.

640
00:35:35.361 --> 00:35:36.310
You have got tensor,

641
00:35:36.640 --> 00:35:41.400
we define relu on it and it's going to be a shape of size question mark 14,

642
00:35:41.401 --> 00:35:44.850
14 by 16 and then the type is going to be float 32.

643
00:35:44.880 --> 00:35:46.740
It's the Matrix of value,
right?

644
00:35:46.950 --> 00:35:50.370
On Matrix is a table of values of a pixel values.

645
00:35:50.790 --> 00:35:53.580
We'll do that again for the next convolutional layer,
right?

646
00:35:53.581 --> 00:35:55.230
So there are two convolutional layer.

647
00:35:55.410 --> 00:35:59.490
We took the output of that first layer and we fed it into this next layer.

648
00:36:00.360 --> 00:36:00.880
<v 1>Okay,</v>

649
00:36:00.880 --> 00:36:03.730
<v 0>then we're going to flatten it or would you flatten it?</v>

650
00:36:05.520 --> 00:36:06.353
<v 1>MMM.</v>

651
00:36:07.020 --> 00:36:10.290
<v 0>What would you flatten it using the uh,
this,</v>

652
00:36:12.290 --> 00:36:16.380
we're going to flatten it over here.
Uh,
right.
It's,
it's afforded Meisel,

653
00:36:16.381 --> 00:36:19.440
Texstar and we need to find that in 22 dimensional tents.
Are you doing that?

654
00:36:20.280 --> 00:36:22.530
That helper,
that helper function we created?
Right?

655
00:36:22.531 --> 00:36:26.340
So if we were to then visualize that flattening layer,
it would be,

656
00:36:26.341 --> 00:36:29.040
you see it now,
it's the shape is going to be two dimensions,
right?

657
00:36:29.160 --> 00:36:31.410
For the first time it had four,
four numbers.
You're right,

658
00:36:31.411 --> 00:36:35.610
cause he was four dimensions.
Uh,
and now it's just two dimensions.
Okay?

659
00:36:37.480 --> 00:36:38.313
<v 1>Okay.</v>

660
00:36:38.360 --> 00:36:40.850
<v 0>So now we're going to look at a number of features,</v>

661
00:36:40.880 --> 00:36:45.450
which we have a lot of features.
And so now it's not the fly knit,
flattened,

662
00:36:45.650 --> 00:36:48.650
flattened two dimensional vector into a probability.

663
00:36:48.920 --> 00:36:52.940
And we're going to do this twice.
So we have two fully connected layers.
Okay.

664
00:36:55.540 --> 00:37:00.050
We have two fully connected layers here.
And uh,
for each of them,
yeah,

665
00:37:00.130 --> 00:37:03.210
we're going to define them.
We already defined the helper function.
Uh,

666
00:37:03.220 --> 00:37:07.210
so what we're gonna do is we're going to run them both on that input data and

667
00:37:07.211 --> 00:37:10.570
it's going to output,
uh,
this one.

668
00:37:10.750 --> 00:37:14.470
It's going to output this two dimensional vector,
which we condense squash.

669
00:37:14.471 --> 00:37:19.150
Do you think a softmax function.
Okay.
The softmax function is a sigmoid function.

670
00:37:19.300 --> 00:37:22.210
It's going to output a probability,
one of 10 classes.

671
00:37:22.540 --> 00:37:25.720
This probability is going to be mapped to one of 10 classes.

672
00:37:26.140 --> 00:37:27.520
And the way it's going to be mapped,

673
00:37:27.580 --> 00:37:32.580
the way our network knows where to map this is by using an optimizer and a loss

674
00:37:32.660 --> 00:37:34.810
function.
Okay,
so this is the,

675
00:37:35.020 --> 00:37:39.160
this is the gradient descent and an optimization step.
Okay.

676
00:37:39.760 --> 00:37:40.593
So,

677
00:37:41.250 --> 00:37:41.790
<v 1>okay,</v>

678
00:37:41.790 --> 00:37:46.620
<v 0>for our gradient descent and optimization step,
we're going to use,
okay,
what is,</v>

679
00:37:46.621 --> 00:37:47.454
what is that?

680
00:37:48.190 --> 00:37:48.680
<v 1>Okay,</v>

681
00:37:48.680 --> 00:37:52.070
<v 0>what is our loss function?
It's going to be called Cross entropy.</v>

682
00:37:52.430 --> 00:37:56.230
Cross entropy is our loss function.
Here's a great,
um,

683
00:37:56.980 --> 00:38:01.970
Cora link for the cross.
That can be function like learning about it.

684
00:38:02.270 --> 00:38:07.270
So basically it's similar to softmax except instead of sock in a softmax

685
00:38:07.820 --> 00:38:10.670
function,
we're determining the type of activation layer.

686
00:38:11.300 --> 00:38:13.010
But in cross entropy we're using,

687
00:38:13.310 --> 00:38:17.010
we're using it to measure the error at the softmax layer.
It's,

688
00:38:17.270 --> 00:38:18.620
it's similar to soft Max,

689
00:38:18.621 --> 00:38:22.190
but different because we're using it to measure the error at the softmax layer

690
00:38:25.660 --> 00:38:27.520
loss.
It's a loss of function because it gets,

691
00:38:27.521 --> 00:38:29.320
it's going to output an error value.

692
00:38:29.620 --> 00:38:34.420
And we're going to use this error value to error value that it's that it's how

693
00:38:34.440 --> 00:38:39.100
pudding,
right?
Uh,
between the real and expected value.
So right?

694
00:38:39.101 --> 00:38:41.720
And so it's going to output is going to help put a prediction,
right?

695
00:38:41.721 --> 00:38:44.860
It's gonna be like,
you know,
60% chance that it's a point 70,

696
00:38:44.861 --> 00:38:47.820
but in reality hits a 100% chance that it's a,

697
00:38:48.010 --> 00:38:51.100
that is that the number is this a 60% chance that the number is seven?

698
00:38:51.250 --> 00:38:54.190
But in really it's 100% chance at number seven.

699
00:38:54.400 --> 00:38:58.030
So that difference between the 60% prediction and the 100% reality,

700
00:38:58.300 --> 00:39:00.730
that error value is what we want to minimize.

701
00:39:00.910 --> 00:39:04.420
And the way we minimize that error is using an optimization method.

702
00:39:04.600 --> 00:39:07.300
Now Adam is just another word for gradient descent.

703
00:39:07.320 --> 00:39:12.250
It's a type of gradient descent optimization function.
Now gradient descent

704
00:39:13.820 --> 00:39:17.510
determines the direction that we want to update our weights or weights in this

705
00:39:17.511 --> 00:39:19.700
case are going to be those filter values.

706
00:39:19.910 --> 00:39:23.780
How do we update those filter values so they are more accurate that they give us

707
00:39:23.900 --> 00:39:26.310
a more accurate result that these,
that they,

708
00:39:27.380 --> 00:39:31.160
that they are more closely aligned to features that would be in the image.

709
00:39:31.370 --> 00:39:31.760
Can we,

710
00:39:31.760 --> 00:39:36.760
how can we modify those initial matrices in those filters such that the output,

711
00:39:37.101 --> 00:39:41.090
a more accurate prediction.
Now bringing the set is going to give us that because

712
00:39:42.180 --> 00:39:42.860
<v 1>okay,</v>

713
00:39:42.860 --> 00:39:47.410
<v 0>it is using the chain rule because,
okay,
so whole,
I mean,
so grading dissent,</v>

714
00:39:47.411 --> 00:39:49.990
I mean that can be a full explanation.
So let's,
let's talk about it.

715
00:39:50.260 --> 00:39:52.630
Let's talk about grieving to send a little bit.
So for grading the sound,

716
00:39:52.631 --> 00:39:55.090
we're using the chain rule.
So what is the chain rule?

717
00:39:55.091 --> 00:39:58.480
We're taking the derivative of the loss function and we are,

718
00:39:58.510 --> 00:40:03.310
we're cursively taking the derivative of each layer back propagating our loss to

719
00:40:03.340 --> 00:40:06.520
each layer and then we're updating our weights using the gradient.

720
00:40:07.300 --> 00:40:10.360
So I've explained this a couple times in a couple of videos,
but I,
you know,

721
00:40:10.390 --> 00:40:14.170
honestly I need a video just for backpropagation and that's going to come up

722
00:40:14.171 --> 00:40:14.741
very soon.

723
00:40:14.741 --> 00:40:19.741
But it is bad propagating weights by taking the derivative recursive we across

724
00:40:19.981 --> 00:40:23.580
each layer.
Okay.
And there's probably a great image for this

725
00:40:25.170 --> 00:40:30.070
backpropagation recursive
recursive derivative.

726
00:40:33.170 --> 00:40:35.650
It's all about recursion when it comes to backpropagation.

727
00:40:35.810 --> 00:40:39.260
I mean the chain rule is just recursively taking derivative about derivatives of

728
00:40:39.261 --> 00:40:42.440
derivatives,
but,
and that's from statistics.

729
00:40:42.441 --> 00:40:44.780
So knowing the chain rule is very important.

730
00:40:45.290 --> 00:40:48.620
You have to know how back application works because it is the,

731
00:40:48.740 --> 00:40:51.710
it is the optimization method that is used across all networks.

732
00:40:53.390 --> 00:40:56.240
So with t tensorflow,
we can basically just plug and play.

733
00:40:56.241 --> 00:41:01.241
It's a plug in play model to just type in whatever type of optimization function

734
00:41:02.451 --> 00:41:06.530
we want to use.
And then it's got to minimize that loss over time.
Okay.
So then,

735
00:41:07.380 --> 00:41:07.700
<v 1>okay,</v>

736
00:41:07.700 --> 00:41:10.090
<v 0>uh,
well use the reduced me.</v>

737
00:41:10.470 --> 00:41:13.650
So then we're going to use tensorflow has reduced mean function to measure the

738
00:41:13.651 --> 00:41:18.180
CALC classification accuracy.
Okay.
So it's a binary yes or no or no value,

739
00:41:18.210 --> 00:41:20.100
zero or one true or false.

740
00:41:21.790 --> 00:41:22.623
<v 1>[inaudible]</v>

741
00:41:24.520 --> 00:41:28.410
<v 0>okay.
So then we're going to run our session.</v>

742
00:41:28.560 --> 00:41:33.190
We always have to run or computation graph once we built it.
So then,
um,

743
00:41:33.950 --> 00:41:35.690
so once we run our session,

744
00:41:36.790 --> 00:41:37.510
<v 1>okay,</v>

745
00:41:37.510 --> 00:41:38.530
<v 0>so these are helped.</v>

746
00:41:38.600 --> 00:41:43.600
This is us running are running our session and then we're going to plot our

747
00:41:43.691 --> 00:41:46.240
values after a set of iterations.

748
00:41:49.470 --> 00:41:53.180
Okay.
We do a set of iterations of,

749
00:41:53.660 --> 00:41:58.110
these are all just printing out,
testing,
accuracies and,
and training accuracy.

750
00:41:58.290 --> 00:42:03.090
But really what I want to get to is we've,
we've created our graph,
we've run it,

751
00:42:03.270 --> 00:42:06.870
and now we want to see the accuracy.
So after one run,

752
00:42:06.871 --> 00:42:11.130
so after one small set of batches,
we have a 13.7% accuracy,

753
00:42:11.160 --> 00:42:15.000
which is very terrible.
It is worse than linear regression.
It is terrible.

754
00:42:15.180 --> 00:42:17.670
We never want a 13.7% accuracy,
right?

755
00:42:17.940 --> 00:42:20.910
But after training it either more one optimization iteration,

756
00:42:20.911 --> 00:42:22.500
we have a 14.3% right?

757
00:42:22.680 --> 00:42:26.820
So after a hundred we have 59.8% so you see that the more we run this

758
00:42:26.821 --> 00:42:31.140
optimization,
the more accurate.
After a thousand,
we have 90% okay.

759
00:42:31.141 --> 00:42:36.141
And so a thousand would take probably on a standard grade 2015 knack book with a

760
00:42:37.280 --> 00:42:40.140
two point,
you know,
probably a 2.7 gigahertz CPU.

761
00:42:40.410 --> 00:42:43.740
1,000 iterations of this will take like 30 minutes or less.
Okay?

762
00:42:43.920 --> 00:42:48.660
So this is all computationally,
uh,
possible on a,
on a local machine.

763
00:42:48.661 --> 00:42:50.520
Right now we don't have to use the cloud for this stuff,

764
00:42:51.750 --> 00:42:52.270
<v 1>okay?</v>

765
00:42:52.270 --> 00:42:54.640
<v 0>Okay?
This is multi-class classification.</v>

766
00:42:54.641 --> 00:42:57.220
That's what this is considered multi-class classification.

767
00:42:57.310 --> 00:43:00.640
So let's visualize those weights that we created,
right?
So this is,

768
00:43:00.700 --> 00:43:03.790
this is using not plot life to visualize those weights,
okay?

769
00:43:03.791 --> 00:43:07.630
Because those are matrices.
So we're going to visualize those matrices using map,

770
00:43:07.631 --> 00:43:11.050
plot wide.
And if we look at those weights that we just visualize,
so let's,

771
00:43:11.051 --> 00:43:13.500
let's look at those visuals.
Okay?
This,

772
00:43:16.550 --> 00:43:19.310
this is an image from the test set.
These,
these aren't the actual visual list.

773
00:43:19.580 --> 00:43:24.090
These are the visualizations.
So we've colored the relevant,
uh,

774
00:43:24.440 --> 00:43:29.440
we call it the relevant parts of the matrix red and the irrelevant or the

775
00:43:29.550 --> 00:43:32.990
irrelevant Lou.
Okay?
Binary.
Right?
So,

776
00:43:33.350 --> 00:43:36.000
so why is it that that,
so why is it that,
you know,

777
00:43:36.050 --> 00:43:39.230
this line is what's considered to be a good feature?
Hope.

778
00:43:39.290 --> 00:43:43.700
Why is it that it's considered this bottom right part to be a good feature?

779
00:43:43.940 --> 00:43:48.450
You don't know why,
but what happens is it's going to be more and more accurate.

780
00:43:48.451 --> 00:43:50.100
It's,
it's features are going to be more and more,

781
00:43:51.030 --> 00:43:51.863
<v 1>uh,</v>

782
00:43:53.090 --> 00:43:55.760
<v 0>close to what we want to make the accurate prediction.</v>

783
00:43:56.270 --> 00:43:57.290
So that's what it looks like.

784
00:43:57.291 --> 00:44:01.550
It's a matrix of pixel values that it weren't at these weights,
these weights,

785
00:44:01.610 --> 00:44:05.900
these filters right between each of the convolutional layers.

786
00:44:06.590 --> 00:44:10.000
And so if we plot these,
what's happening in these,
this is the feature map.

787
00:44:10.370 --> 00:44:13.130
This is what it looks like and see it's highlighting different parts of the

788
00:44:13.131 --> 00:44:17.780
image.
It's going to combine all of these to output a probability.
Okay.

789
00:44:19.760 --> 00:44:23.270
And See,
and so in the next convolutional layer,
we have even more filters.

790
00:44:23.271 --> 00:44:28.130
We have 16 by 36 even more pixel features,
and

791
00:44:30.100 --> 00:44:31.980
those are the results.
And then we

792
00:44:31.980 --> 00:44:35.340
<v 1>closed the session,
right.
Always closed in when we're done.
Okay.</v>

793
00:44:35.341 --> 00:44:37.860
And then they're more exercises,
so,
okay.

794
00:44:38.140 --> 00:44:41.770
<v 0>So yeah,
that's it for our a convolutional layer and</v>

795
00:44:43.610 --> 00:44:46.280
let's let's guys stick around for a second.
Sit around,
sit around.
Let me,

796
00:44:46.520 --> 00:44:50.100
let me go back to stop the screen sharing.
Okay,

797
00:44:50.310 --> 00:44:54.330
so go ahead and ask questions guys cause we have some questions to ask.

798
00:44:54.900 --> 00:44:58.880
Okay.
The the notebook is in the description.

799
00:44:58.881 --> 00:45:00.320
I'm going to add the read me in a second.

800
00:45:00.820 --> 00:45:03.920
I am so proud of all of you guys for being in this live session for watching

801
00:45:03.921 --> 00:45:07.520
this video.
It is awesome to see you guys here.
This stuff is not easy.

802
00:45:07.640 --> 00:45:08.391
It's not easy,

803
00:45:08.391 --> 00:45:13.190
but it's very important and knowing this is going to put you a huge step above

804
00:45:13.550 --> 00:45:15.230
everybody,
every other developer.

805
00:45:15.231 --> 00:45:18.740
Just the fact that you even recognize the little things about convolutional nets

806
00:45:18.920 --> 00:45:23.240
is very important.
Okay.
For your career,
for your academic career,
for your,

807
00:45:23.570 --> 00:45:25.040
for any startup yet you want to do,

808
00:45:25.100 --> 00:45:29.030
it's very important because all successful startups,
all successful companies,

809
00:45:29.240 --> 00:45:33.020
all successful academic research in computer science,

810
00:45:33.021 --> 00:45:34.300
it's going to get the bleeding edge.

811
00:45:34.301 --> 00:45:38.120
It's going to get the most attention is going to involve deep learning at this

812
00:45:38.121 --> 00:45:41.120
point and then we're going to build on that later and it's going to get even

813
00:45:41.121 --> 00:45:44.930
better.
So I'm very proud of you guys for being here.
Okay,
you guys are awesome.

814
00:45:44.940 --> 00:45:48.260
I'm honored to be a part of this community.
Okay,

815
00:45:48.261 --> 00:45:53.261
so the room is soundproof and next week I'm going to actually improve the

816
00:45:53.361 --> 00:45:55.850
quality of this live stream.
So I'm very excited for that.

817
00:45:57.420 --> 00:45:58.253
<v 1>Okay.</v>

818
00:45:59.490 --> 00:46:00.990
<v 0>We are growing so fast.</v>

819
00:46:00.991 --> 00:46:05.160
We have 500 developers joining this community every single day on average.

820
00:46:05.161 --> 00:46:06.450
We are going so fast,

821
00:46:06.451 --> 00:46:10.500
so it's a very exciting time to be here and I'm just going to get better at

822
00:46:10.501 --> 00:46:12.840
explaining and you guys are just going to get better at doing these things.

823
00:46:13.080 --> 00:46:15.930
I mean it's just incredible the amount of coding challenges you guys have done.

824
00:46:16.040 --> 00:46:19.980
It is incredible what you guys have done.
It is just incredible.
So,

825
00:46:20.770 --> 00:46:23.220
okay,
can I share resources to help you grow up?

826
00:46:23.500 --> 00:46:26.920
I'm going to put so many CNN resources in the description.

827
00:46:26.921 --> 00:46:29.320
It's not even going to be funny within the hour.

828
00:46:30.010 --> 00:46:31.660
If you want the image to be manipulated,

829
00:46:31.661 --> 00:46:35.230
do I add another matrix to affect the color channels?
Have it output,

830
00:46:35.260 --> 00:46:36.370
multichannel image,

831
00:46:38.800 --> 00:46:41.900
the image to be manipulated.
If you want the image to be manipulated,

832
00:46:41.901 --> 00:46:45.020
we're going to perform eight entirely different optimization process,

833
00:46:45.170 --> 00:46:48.510
not gradient descent,
gradient descent,

834
00:46:48.590 --> 00:46:51.860
and that's what's used in neural style transfer and we're going to get to that

835
00:46:51.861 --> 00:46:55.400
three videos for now.
Have you heard about good AI AI challenge know?

836
00:46:56.510 --> 00:47:00.990
Can this be done with python with the same level of difficulty?
Python,

837
00:47:01.020 --> 00:47:05.880
this word python.
Okay guys,
can you do more stuff on financial subject?

838
00:47:05.881 --> 00:47:07.140
Yes,
it's coming out on Friday.

839
00:47:07.560 --> 00:47:11.340
Is Max pulling across channels or a specific teacher frame?

840
00:47:12.390 --> 00:47:15.300
Max pulling is done across all channels.

841
00:47:16.530 --> 00:47:20.850
It's every Wednesday at 10:00 AM pst also tree to the next live stream because

842
00:47:20.860 --> 00:47:24.000
there's going to be even better quality.
I'm not going to use Google hangouts.

843
00:47:24.150 --> 00:47:28.070
It's going to be even better,
better quality.
Okay,
thanks coach.
Your car.

844
00:47:29.230 --> 00:47:31.450
We have so much to do.
We have so much.

845
00:47:32.170 --> 00:47:36.940
Did you guys remember to share your share your victories with all of us?

846
00:47:36.970 --> 00:47:39.220
One victory is a victory for all of us.

847
00:47:39.430 --> 00:47:43.030
You are a very special person for knowing neural networks.

848
00:47:43.060 --> 00:47:47.290
You don't even understand how important you are to the future of the human race.

849
00:47:47.380 --> 00:47:49.510
Even every commit counts on get up.

850
00:47:49.690 --> 00:47:53.530
Every commit to every repo counts because it's like the butterfly effect.

851
00:47:54.580 --> 00:47:58.180
You guys are the butterfly effect.
If a butterfly flaps its wings in Colombia,

852
00:47:58.240 --> 00:48:01.600
it's going to cause a tornado later on somewhere in a different continent.

853
00:48:01.750 --> 00:48:03.280
It's like that fur coat and machine learning.

854
00:48:03.460 --> 00:48:04.930
The rate of discovery that is happening,

855
00:48:05.140 --> 00:48:08.920
the fact that you even push any open source code to get up is going to be even

856
00:48:08.921 --> 00:48:13.270
looked at by any other developer is very important because then they're going to

857
00:48:13.271 --> 00:48:14.730
build and they're going to build and they're going to do it.

858
00:48:14.731 --> 00:48:18.250
Then other people are going to build,
so it's all,
it's all,
it's all connected.

859
00:48:18.251 --> 00:48:21.520
Everything we're doing is connected here.
Okay.
So it's

860
00:48:25.710 --> 00:48:28.200
don't think that anything you do is meaningless and this field,

861
00:48:28.260 --> 00:48:30.030
everything that you open source,

862
00:48:30.150 --> 00:48:35.150
everything that you output is going to have immense value to the entire world as

863
00:48:35.671 --> 00:48:39.240
machine learning propagates across every industry.
Okay?

864
00:48:39.630 --> 00:48:41.670
So let's cost tornadoes with code.

865
00:48:41.730 --> 00:48:45.660
Let me answer two more questions and then we're done with this livestream.
Okay.

866
00:48:47.510 --> 00:48:51.350
Can you make a video on Gan?
Aye.
Have a video on gain search,

867
00:48:51.351 --> 00:48:53.050
generative adversarial networks.
I'm going to do another one.

868
00:48:53.051 --> 00:48:56.950
It's gonna be even better.
Any flat strip requests,
we can all discuss it.
Yes,

869
00:48:56.951 --> 00:48:57.790
I have a slack channel.

870
00:48:57.820 --> 00:49:01.240
It's in the description of every single video of mine joined decide channel.

871
00:49:01.241 --> 00:49:04.510
Okay.
There's a lot of great people in there.
Okay,
so that was one question.

872
00:49:04.511 --> 00:49:09.270
One more question.
How do I learn you sides?

873
00:49:09.271 --> 00:49:11.130
Constant practice.
How do I learn?

874
00:49:11.730 --> 00:49:16.020
I input of diverse set of sources.
So I have,
you know,

875
00:49:16.021 --> 00:49:18.840
if I'm learning about convolutional legs,
so it's like for these past video,

876
00:49:18.841 --> 00:49:19.590
for example,

877
00:49:19.590 --> 00:49:24.590
I had Andre these of the unreasonable effectiveness of neuro neural networks,

878
00:49:24.961 --> 00:49:26.580
epic blog post up in one tab.

879
00:49:26.790 --> 00:49:30.300
And then I had another attack from I think Chris Olah great blog by the way,

880
00:49:30.450 --> 00:49:34.650
Chris Olah,
Andre Chapati,
two of my favorites blogs.

881
00:49:34.860 --> 00:49:36.370
And then I had other tests.

882
00:49:36.371 --> 00:49:39.600
And so what I'm doing is I'm going between different tabs and I'm,

883
00:49:39.900 --> 00:49:44.370
and I'm Max pooling.
Ah,
I'm,
I'm,
I'm taking the,

884
00:49:44.430 --> 00:49:47.370
the optimal information from each of these and I'm,

885
00:49:47.560 --> 00:49:50.190
and I'm saying every time I have a question one I took on another source.

886
00:49:50.191 --> 00:49:53.940
So you have to have multiple diverse sets of learning resources.
Okay?

887
00:49:56.760 --> 00:50:00.490
So that's how I learned and I,
and I just,
and I truly love what I'm doing.

888
00:50:00.491 --> 00:50:03.550
So I think it's very important to love what you're learning because that is such

889
00:50:03.551 --> 00:50:06.790
an important thing.
And I believe in myself,
I believe in myself.

890
00:50:06.791 --> 00:50:07.930
That's such an important thing.

891
00:50:07.931 --> 00:50:11.710
And you guys all need to believe in yourself as well because you are very,

892
00:50:11.740 --> 00:50:14.590
very important.
Okay?
You guys are awesome.
I'm so honored.

893
00:50:14.950 --> 00:50:18.670
I'm so honored to be here every Wednesday making videos for you guys.

894
00:50:18.760 --> 00:50:22.120
And the community is getting better as well.
Our community is getting better.

895
00:50:22.210 --> 00:50:23.950
People are helping each other in the comments.

896
00:50:24.100 --> 00:50:27.650
The number of coding submissions are going up every week and the quality of the

897
00:50:27.651 --> 00:50:31.190
coatings emissions are going up every week as well.
So we are all getting better.

898
00:50:31.220 --> 00:50:34.380
It's incredible and we aren't forced to be reckoned with God.

899
00:50:34.400 --> 00:50:37.280
We are a force to be reckoned with.
Okay.
So,

900
00:50:39.960 --> 00:50:41.850
ah,
okay.
So that's it for our questions.

901
00:50:41.851 --> 00:50:46.770
And so now I'm going to end it with a motivational wrap.
Okay.
So,

902
00:50:46.800 --> 00:50:47.633
um,

903
00:50:48.460 --> 00:50:49.293
<v 1>uh,</v>

904
00:50:49.650 --> 00:50:53.200
<v 0>okay.
So any,
uh,
by the way,</v>

905
00:50:53.201 --> 00:50:56.290
there's so much money to be made here and we're going to talk about all the

906
00:50:56.291 --> 00:51:00.310
money to be made as well from each of us.
Okay?
We are all going to get very rich.

907
00:51:00.670 --> 00:51:03.280
Not that that should be the driving factor.
That,
and that is a good thing.

908
00:51:03.281 --> 00:51:05.770
It's good to build wealth,
the driving factor,

909
00:51:05.771 --> 00:51:09.250
it should be to make as much of an impact as you can and as a side result,

910
00:51:09.251 --> 00:51:10.510
you will make money because this stuff,

911
00:51:10.660 --> 00:51:12.880
I'll make a video on that like waste to make money with machine learning.

912
00:51:12.881 --> 00:51:17.740
I know it's going to be important.
So a freestyle.
Okay.
D three js.

913
00:51:17.741 --> 00:51:22.370
That's,
that's,
that's my freestyle d three.
Dot.
Js.
Okay.
Yeah.

914
00:51:22.380 --> 00:51:26.850
When I visualize made two cs,
I use d three.
I do it with Java script.

915
00:51:26.851 --> 00:51:31.851
Can't you see I see all these mid two C's in a vector.

916
00:51:32.250 --> 00:51:37.250
It's like three d two d one d scaler that dirt tensor.

917
00:51:37.441 --> 00:51:40.110
All these words,
man.
I don't know.
Call me Victor.

918
00:51:40.500 --> 00:51:43.200
I was looking at all these statistics.

919
00:51:43.230 --> 00:51:45.900
I was looking at linear Algebra with six.

920
00:51:45.960 --> 00:51:50.790
I was hitting it with my brain every day.
I went back.
Yo,
it's going to be okay.

921
00:51:50.940 --> 00:51:55.000
Okay,
so that was it.
Everybody's on your rich.
Okay.
Wasn't in the section,
uh,

922
00:51:55.020 --> 00:51:59.340
programming,
uh,
dash wizards that did for the video.
Thanks for being here guys.

923
00:51:59.460 --> 00:52:00.180
For now,

924
00:52:00.180 --> 00:52:05.010
I've got to make the sickest a stock prediction video using LSTM networks.

925
00:52:05.070 --> 00:52:06.360
So thanks for watching.

