WEBVTT

1
00:00:00.240 --> 00:00:02.850
Oh world.
It's Raj and more robots.

2
00:00:04.740 --> 00:00:08.820
We're going to learn a bit about how military robots work and then teach a

3
00:00:08.821 --> 00:00:13.490
simulated robot how to walk using a reinforcement learning technique called

4
00:00:13.520 --> 00:00:15.750
proximal policy optimization.

5
00:00:16.140 --> 00:00:20.370
Military warfare is as old as mankind and the better the technology,

6
00:00:20.520 --> 00:00:24.870
the more likely the chance of winning is so it makes sense that militaries want

7
00:00:24.871 --> 00:00:29.280
the most advanced weaponry they can get their hands on by whatever means

8
00:00:29.281 --> 00:00:30.750
necessary.
Ideally,

9
00:00:30.780 --> 00:00:35.340
militaries can minimize deaths of their own soldiers while maximizing their

10
00:00:35.341 --> 00:00:40.110
effectiveness.
That means removing the human from the loop as much as possible,

11
00:00:40.200 --> 00:00:43.830
which is where the field of military robotics comes in.

12
00:00:44.220 --> 00:00:47.970
The first real advances there came from none other than electrical wizard.

13
00:00:48.000 --> 00:00:48.900
Nikola Tesla.

14
00:00:48.930 --> 00:00:53.930
In 1898 Tesla demoed a controlled motor boat to a government representative.

15
00:00:54.390 --> 00:00:58.710
It laid the foundation for the first unmanned vehicles and weapons as world war

16
00:00:58.711 --> 00:00:59.670
one began,

17
00:00:59.910 --> 00:01:04.530
Germany used radio controlled motor boats to ram into enemy ships containing

18
00:01:04.531 --> 00:01:08.790
more than 300 pounds of explosives during both world wars.

19
00:01:08.910 --> 00:01:10.140
Inspired by Teslas.

20
00:01:10.170 --> 00:01:14.040
Initial invention using radio waves as a communication signal was a

21
00:01:14.041 --> 00:01:15.390
revolutionary idea.

22
00:01:15.630 --> 00:01:20.130
The Germans use it to deploy the first remotely piloted aerial drone called the

23
00:01:20.131 --> 00:01:24.000
Fritz.
They dropped the device at a high altitude from a bummer.

24
00:01:24.240 --> 00:01:29.160
Then a bombardier would steer the Fritz via radio link using the joystick and it

25
00:01:29.161 --> 00:01:32.340
wasn't just the Germans getting it on the radio controlled fund.

26
00:01:32.430 --> 00:01:35.370
Americans dropped more than 450 radio,

27
00:01:35.371 --> 00:01:39.900
remote controlled grind bombs during World War Two remote controlled vehicles on

28
00:01:39.901 --> 00:01:40.681
land,
air,

29
00:01:40.681 --> 00:01:45.150
and sea have improved in the decades since World War II as more than 40

30
00:01:45.151 --> 00:01:48.840
countries have developed a technological breakthroughs in that regard.

31
00:01:48.990 --> 00:01:53.190
There are three important trends happening right now that are causing rapid

32
00:01:53.220 --> 00:01:55.620
advancement in military technology,

33
00:01:55.890 --> 00:02:00.360
namely the plummeting costs and soaring performance of computer hardware.

34
00:02:00.630 --> 00:02:03.210
The rise of cloud networked robots,

35
00:02:03.300 --> 00:02:08.300
and of course advances in machine learning put together these trends mean it's

36
00:02:08.851 --> 00:02:12.090
getting easier to create more powerful robots.

37
00:02:12.180 --> 00:02:16.680
Soldiers no longer need to aim at targets if they can just use a convolutional

38
00:02:16.681 --> 00:02:18.540
network to detect enemies.

39
00:02:18.810 --> 00:02:23.310
Calm Nets are neural networks that can run the features of any type of object

40
00:02:23.340 --> 00:02:27.450
it's trained on be that a certain type of vehicle or a type of soldier.

41
00:02:27.780 --> 00:02:29.460
Using a pretrained network.

42
00:02:29.580 --> 00:02:34.580
Soldiers can dawn a set of goggles that show a computed bounding box around

43
00:02:34.831 --> 00:02:39.750
their targets or even feed the computed coordinate to a weapon and how it's

44
00:02:39.751 --> 00:02:40.350
positioned,

45
00:02:40.350 --> 00:02:45.120
adjusted accordingly and fire automatically effectively using auto aim.

46
00:02:45.240 --> 00:02:49.860
Reinforcement learning has been an effective tool to get robots to learn how to

47
00:02:49.861 --> 00:02:51.840
navigate virtual environments.

48
00:02:52.110 --> 00:02:57.110
Some soldiers go through extensive simulated training before being deployed to

49
00:02:57.301 --> 00:03:02.301
the real world and an l agent could prove useful as an unpredictable and

50
00:03:02.891 --> 00:03:07.891
adaptive enemy during combat simulation for a range of soldiers from fighter

51
00:03:07.931 --> 00:03:09.670
pilots to ground soldiers,

52
00:03:09.730 --> 00:03:14.670
these agents could use techniques like cue learning or policy gradients or actor

53
00:03:14.680 --> 00:03:18.910
critic to learn how best to avoid enemy fire and even create effective

54
00:03:18.911 --> 00:03:21.550
strategies to confuse the enemy before attacking.

55
00:03:22.120 --> 00:03:26.680
Ai Can also be used to change the medium with which soldiers control if their

56
00:03:26.681 --> 00:03:27.514
weapons,

57
00:03:27.640 --> 00:03:32.380
they can issue orders via voice command instead of having to use a keyboard in

58
00:03:32.420 --> 00:03:36.520
tense situations.
Thanks to developments in natural language processing.

59
00:03:36.610 --> 00:03:40.990
Speech recognition is getting really good and recurrent networks help make this

60
00:03:40.991 --> 00:03:44.320
possible.
If we have some labeled audio Dataset,

61
00:03:44.530 --> 00:03:49.270
we can train a recurrent network by slicing the audio up into small chunks,

62
00:03:49.540 --> 00:03:54.340
feeding those chunks into the RNN sequentially and generating a prediction for

63
00:03:54.341 --> 00:03:55.174
the next chunk,

64
00:03:55.270 --> 00:03:59.260
computing an error back propagating the error gradients and repeating that

65
00:03:59.261 --> 00:03:59.920
process.

66
00:03:59.920 --> 00:04:04.600
Lots of times since recurrent networks are made for sequential data,

67
00:04:04.750 --> 00:04:07.960
audio is a perfect use case.
After training,

68
00:04:07.990 --> 00:04:12.970
they can recognize human speech with incredible accuracy and this is essential

69
00:04:12.971 --> 00:04:14.980
for mission critical applications.

70
00:04:15.040 --> 00:04:20.040
Governments have mountains of data from surveillance systems and satellites of

71
00:04:20.141 --> 00:04:20.974
all kinds,

72
00:04:21.160 --> 00:04:25.660
finding disturbances using unsupervised learning techniques like anomaly

73
00:04:25.661 --> 00:04:30.100
detection via auto encoders,
war.
It doesn't just have to happen in real life.

74
00:04:30.370 --> 00:04:32.890
It can happen online as well.
Today,

75
00:04:32.891 --> 00:04:35.590
the process of finding and countering bugs,

76
00:04:35.800 --> 00:04:40.540
hacks and all sorts of cyber infection vectors is still effectively artisinal.

77
00:04:40.840 --> 00:04:45.840
Professional security experts search millions of lines of code to find and fix

78
00:04:46.001 --> 00:04:50.650
vulnerabilities that could be taken advantage of by users with ulterior motives.

79
00:04:50.680 --> 00:04:54.670
All of this could be automated using deep learning to find the features of

80
00:04:54.671 --> 00:04:58.270
vulnerable code and learning to patch bugs by itself.

81
00:04:58.420 --> 00:05:01.840
So we'll based intelligence can only do so much,

82
00:05:01.900 --> 00:05:06.850
but by integrating learning algorithms,
machines can become far more capable.

83
00:05:06.851 --> 00:05:08.200
When a human is in the loop,

84
00:05:08.320 --> 00:05:12.280
they are able to make the final call the highest level decision.

85
00:05:12.820 --> 00:05:15.850
That's the one that the human makes,
but as AI gets better,

86
00:05:15.880 --> 00:05:18.220
it's able to make more decisions for itself.

87
00:05:18.430 --> 00:05:22.900
So how many decisions did we delegate to AI?
How much is too much?

88
00:05:23.260 --> 00:05:25.360
Take the idea of a swarm.
For example,

89
00:05:25.660 --> 00:05:29.950
any aircraft manned or unmanned can be brought down by a single missile,

90
00:05:30.280 --> 00:05:33.460
but a swarm can take multiple hits and keep going.

91
00:05:33.730 --> 00:05:38.200
It's a collection of drones that can coordinate together as a single entity.

92
00:05:38.650 --> 00:05:43.030
One could take out enemies systems while the other creates a distraction.

93
00:05:43.180 --> 00:05:45.670
While the other picks up important cargo.

94
00:05:46.090 --> 00:05:50.830
Evolutionary techniques like particles form optimization can make this happen.

95
00:05:50.920 --> 00:05:55.780
The U S Department of Defense recently released a document called a human

96
00:05:55.810 --> 00:06:00.810
systems roadmap review that reveals a plan to use AI to create autonomous

97
00:06:01.161 --> 00:06:06.161
weapons using social media analytics to make decisions on lethal force with

98
00:06:06.471 --> 00:06:08.060
minimal human involvement.

99
00:06:08.390 --> 00:06:13.220
It shows that while having a human in the loop is necessary for the near term,

100
00:06:13.540 --> 00:06:16.970
there are far term vision is self aware of systems.

101
00:06:17.210 --> 00:06:19.640
They defined this as systems that have perception,

102
00:06:19.940 --> 00:06:24.380
reasoning and intelligence allowing for entities to have existence,

103
00:06:24.450 --> 00:06:25.280
intent,

104
00:06:25.280 --> 00:06:29.930
relationships and understanding in the battlespace relative to a mission.

105
00:06:30.620 --> 00:06:35.620
That means drones that coordinate amongst themselves make decisions for

106
00:06:36.051 --> 00:06:38.630
themselves,
prioritize by themselves,

107
00:06:38.631 --> 00:06:43.130
and of course decide who to kill and when to kill them by themselves.

108
00:06:43.690 --> 00:06:47.570
That was kind of scary and reminiscent of the infamous skynet system from the

109
00:06:47.571 --> 00:06:50.030
movie terminator.
In the movie,

110
00:06:50.090 --> 00:06:55.090
the military system becomes self aware and decides to kill all humans and no one

111
00:06:55.251 --> 00:06:56.150
can shut it down.

112
00:06:56.450 --> 00:07:00.890
We know of one system that can't be shut down and that's bitcoin.

113
00:07:00.920 --> 00:07:05.920
Because the blockchain miners must verify transactions using the proof of work

114
00:07:05.960 --> 00:07:06.793
algorithm.

115
00:07:06.890 --> 00:07:11.420
It would require more computing power than the 500 fastest supercomputers in the

116
00:07:11.421 --> 00:07:16.421
world combined to shut it down and no one has that much computing power on AI

117
00:07:17.211 --> 00:07:21.050
agent that lives on this kind of blockchain couldn't be shut down.

118
00:07:21.380 --> 00:07:26.380
And if it's objective was to say destroy humanity and it has access to weapons

119
00:07:26.451 --> 00:07:30.110
of mass destruction,
that's how skynet happens IRL.

120
00:07:30.350 --> 00:07:31.490
So how do we stop this?

121
00:07:31.820 --> 00:07:36.230
We've got to spread awareness and educate ourselves on how AI works.

122
00:07:36.500 --> 00:07:38.900
The more people that understand the power of AI,

123
00:07:39.050 --> 00:07:42.800
the less likely it is that governments will abuse this power and the more likely

124
00:07:42.801 --> 00:07:44.900
it will be used for beneficial purposes.

125
00:07:45.290 --> 00:07:49.850
More research into creating explainable AI systems that give us a detailed list

126
00:07:50.000 --> 00:07:54.560
of why an AI made a certain decision will help unravel the black box of deep

127
00:07:54.561 --> 00:07:58.910
learning and help fuel a debate for policymakers as they regulate this

128
00:07:58.911 --> 00:08:03.380
technology.
So to give an example of how a robot can learn to walk,

129
00:08:03.620 --> 00:08:08.150
we can use a reinforcement learning technique called proximal policy

130
00:08:08.180 --> 00:08:09.050
optimization.

131
00:08:09.650 --> 00:08:14.650
This is to randomly initialized neural networks and a teacher that rewards

132
00:08:14.900 --> 00:08:16.010
forward progress.

133
00:08:16.430 --> 00:08:20.240
The policy gradient technique takes steps in the direction that improves a

134
00:08:20.241 --> 00:08:20.930
policy.

135
00:08:20.930 --> 00:08:25.640
A similar technique is called trust region policy optimization or trp.
Oh,

136
00:08:26.030 --> 00:08:30.440
the idea is to take steps in the direction that improves the policy while

137
00:08:30.441 --> 00:08:35.330
simultaneously not straying too far from the old policy.
That's the difference.

138
00:08:35.720 --> 00:08:39.920
Making too big a change from the previous policy in high dimensional

139
00:08:39.921 --> 00:08:44.210
environments can lead to a dramatic decrease in performance.

140
00:08:44.540 --> 00:08:49.220
A little forward lean can help running speed,
but too much causes a crash.

141
00:08:49.640 --> 00:08:53.090
A naive solution is to take minuscule policy steps,

142
00:08:53.390 --> 00:08:57.540
but the question then becomes how small a step Turp Oh,

143
00:08:57.541 --> 00:09:01.350
takes a principled approach to controlling the rate of policy change.

144
00:09:01.650 --> 00:09:06.570
The algorithm places a constraint on the average KL divergence between the new

145
00:09:06.660 --> 00:09:08.700
and old policy after each update.

146
00:09:08.790 --> 00:09:13.620
So proximal policy optimization is an implementation of trp.
Oh,

147
00:09:13.830 --> 00:09:17.250
that adds the Kale divergence term to training a loss function.

148
00:09:17.460 --> 00:09:19.080
With this loss function in place,

149
00:09:19.081 --> 00:09:22.980
we can train the policy with gradient descent like a typical neural network.

150
00:09:23.610 --> 00:09:25.590
In our PPO algorithm,

151
00:09:25.650 --> 00:09:30.650
we capture sequences of states' actions and rewards from our environment and add

152
00:09:30.711 --> 00:09:35.090
it to our data.
Batch line 10 adds value estimates to each visit.

153
00:09:35.091 --> 00:09:39.090
It's state from the rollouts with predicted state values in hand.

154
00:09:39.300 --> 00:09:42.810
We calculate the advantages and add these to the Dataset.

155
00:09:42.870 --> 00:09:47.870
In line 11 the advantage of a state action is how much better or worse an action

156
00:09:48.781 --> 00:09:53.130
performs.
Then the expectation of present policy from the same state.

157
00:09:53.520 --> 00:09:56.520
We update the policy in line 13 finally,

158
00:09:56.550 --> 00:10:00.180
we update our value function to reflect our latest data.

159
00:10:00.510 --> 00:10:04.560
In line 14 we use the present date of batch and the previous data batch to

160
00:10:04.561 --> 00:10:08.640
smooth changes in the value function.
For our policy update function.

161
00:10:08.820 --> 00:10:13.820
We store the old policy and compute the KL divergence as we make policy gradient

162
00:10:14.010 --> 00:10:18.540
updates.
And after only 25,000 training episodes are humanoid,

163
00:10:18.541 --> 00:10:20.070
we'll start learning how to walk.

164
00:10:20.220 --> 00:10:23.550
It's pretty hilarious to watch the progress in the meantime.
All right,

165
00:10:23.551 --> 00:10:25.200
so three ending points here.

166
00:10:25.440 --> 00:10:30.440
Militaries can use AI to create autonomous weapons systems and that means less

167
00:10:30.661 --> 00:10:33.540
and less of a need for humans in the loop.
Uh,

168
00:10:33.550 --> 00:10:38.550
skynet's likes scenario can occur if the public isn't made aware of AI dangerous

169
00:10:38.760 --> 00:10:40.410
and governments go unchecked.

170
00:10:40.530 --> 00:10:45.530
And proximal policy optimization uses two neural nets and the teacher to forward

171
00:10:45.901 --> 00:10:48.510
progress.
To train an AI to complete an objective.

172
00:10:48.900 --> 00:10:52.830
This week's coding challenge is to use the PPO technique on a game of your

173
00:10:52.831 --> 00:10:56.700
choice.
Details are in the read me posted.
Get up links in the comments section,

174
00:10:56.850 --> 00:10:58.680
and winners will be announced next week.

175
00:10:58.920 --> 00:11:01.620
Please subscribe for more programming videos.
And for now,

176
00:11:01.680 --> 00:11:04.440
I've got to go prevent skynet,
so thanks for watching.

