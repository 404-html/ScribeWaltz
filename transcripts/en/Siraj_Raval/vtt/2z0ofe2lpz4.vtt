WEBVTT

1
00:00:00.330 --> 00:00:05.330
Can we learn to learn to learn hello world.

2
00:00:06.450 --> 00:00:11.450
It's a Raj and what if neural networks could learn how to learn the process of

3
00:00:11.641 --> 00:00:12.630
learning to learn.

4
00:00:12.660 --> 00:00:17.660
We're a top level AI optimized as a bottom level AI or several of them is

5
00:00:17.881 --> 00:00:22.080
considered metal learning and it's currently a very popular topic in Ai.

6
00:00:22.500 --> 00:00:27.500
The reason being metalevel AI algorithms generally make AI systems learn faster,

7
00:00:28.260 --> 00:00:32.880
adapt to changes in their environments in a more robust way and generalize to

8
00:00:32.881 --> 00:00:37.230
more tasks and they can be used to optimize a models architecture.

9
00:00:37.350 --> 00:00:42.240
It's parameters,
the type of Dataset it uses or some combination of all of them.

10
00:00:42.600 --> 00:00:43.950
If we look at the literature,

11
00:00:43.980 --> 00:00:48.510
there are some pretty hilariously named metal learning papers that demonstrate

12
00:00:48.511 --> 00:00:53.511
these techniques like learning to learn by gradient descent by gradient descent,

13
00:00:54.520 --> 00:00:59.160
got to love it and darts or differential architecture search algorithm.

14
00:00:59.460 --> 00:01:03.900
But in this video I want to focus on a specific metal learning technique called

15
00:01:03.901 --> 00:01:05.190
neuro evolution.

16
00:01:05.520 --> 00:01:09.810
This is the process of using what's called an evolutionary algorithm to learn

17
00:01:09.840 --> 00:01:11.040
neural architectures.

18
00:01:11.160 --> 00:01:15.720
The reason this technique piqued my interest is because justice year Google

19
00:01:15.721 --> 00:01:18.570
published some research detailing their effort.

20
00:01:18.690 --> 00:01:23.520
At using an evolutionary algorithm to learn the architecture of a neural image

21
00:01:23.521 --> 00:01:26.940
classifier and it ended up becoming the state of the art,

22
00:01:27.240 --> 00:01:30.850
which was somewhat surprising to many in the research community.

23
00:01:30.851 --> 00:01:35.851
Since evolutionary algorithms haven't shown nearly as much promise for real

24
00:01:36.451 --> 00:01:41.451
world use cases as supervised and unsupervised methods have so far and don't

25
00:01:41.461 --> 00:01:41.731
forget,

26
00:01:41.731 --> 00:01:46.200
brute forcing neural networks can perform tasks that would be difficult for

27
00:01:46.201 --> 00:01:49.170
humans if they're given large amounts of training data.

28
00:01:49.500 --> 00:01:54.360
But discovering the optimal architectures for these networks is nontrivial and

29
00:01:54.361 --> 00:01:57.120
takes researchers a lot of trial and error.

30
00:01:57.510 --> 00:02:00.780
Image classification is a well known problem in the community.

31
00:02:01.050 --> 00:02:04.140
As deep learning researchers established the state of the art.

32
00:02:04.170 --> 00:02:05.220
A couple of years ago,

33
00:02:05.580 --> 00:02:09.840
researchers worked hard on developing newer architectures that progressive Lee

34
00:02:09.841 --> 00:02:14.640
brought the state of Vr to newer levels.
Year.
After a year,
ambitiously,

35
00:02:14.670 --> 00:02:19.670
Google decided to try an evolutionary algorithm to try to learn what a neural

36
00:02:19.831 --> 00:02:24.831
architecture would look like for image classification instead of hand designing

37
00:02:25.591 --> 00:02:29.760
it and it outperformed the rest,
and it wasn't just Google.

38
00:02:29.790 --> 00:02:34.790
Neuro evolutionary strategies have started to see more adoption as popular tech

39
00:02:35.221 --> 00:02:39.960
companies like Uber have started adopting them to help improve the performance

40
00:02:39.990 --> 00:02:41.190
of their products.

41
00:02:41.580 --> 00:02:46.580
Uber's dispatch algorithm has to analyze thousands of features in real time to

42
00:02:46.831 --> 00:02:51.831
generate more than 30 million Ryder driver match pair predictions per minute and

43
00:02:52.531 --> 00:02:56.070
neuro evolution helps them speed up this crucial process.

44
00:02:56.340 --> 00:03:00.700
They've got a great blog post on this as well that list several examples.

45
00:03:01.000 --> 00:03:05.200
So why applied evolution to neural network design?
Well,

46
00:03:05.230 --> 00:03:07.630
to quote the contemporary poet Marshall Mathers,

47
00:03:07.840 --> 00:03:11.260
we ain't nothing but mammals and nature demonstrates this.

48
00:03:11.410 --> 00:03:13.280
When the evolutionary biologists,

49
00:03:13.281 --> 00:03:17.020
Charles Darwin visited the Galapagos Islands decades ago,

50
00:03:17.200 --> 00:03:21.760
he noticed that some birds appeared to have evolved from a single ancestral

51
00:03:21.761 --> 00:03:24.070
flock.
They shared common features,

52
00:03:24.100 --> 00:03:27.520
but we're characterized by their unique beak forms,

53
00:03:27.521 --> 00:03:29.890
which sprung from their unique DNA.

54
00:03:30.190 --> 00:03:32.980
We can think of DNA as a metal level construct.

55
00:03:33.010 --> 00:03:36.790
It's a blueprint that guides the replication of cells,

56
00:03:37.000 --> 00:03:42.000
a longterm memory store that captures instructions necessary to recreate

57
00:03:42.221 --> 00:03:45.700
biological systems that transcend their death.

58
00:03:45.970 --> 00:03:50.440
His hypothesis was that the isolation of each species to a different island

59
00:03:50.560 --> 00:03:52.150
caused this diversity.

60
00:03:52.360 --> 00:03:56.920
Eventually he turned this hypothesis into his now famous theory of natural

61
00:03:56.921 --> 00:03:57.754
selection.

62
00:03:57.790 --> 00:04:02.770
This process is algorithmic and we can simulate it on silicon processors.

63
00:04:02.890 --> 00:04:05.260
By creating evolutionary algorithms,

64
00:04:05.500 --> 00:04:10.480
an evolutionary algorithm creates a population of randomly generated members.

65
00:04:10.810 --> 00:04:15.040
Each of these members are represented by some algorithm.
It could be any kind,

66
00:04:15.041 --> 00:04:19.900
not just a machine learning algorithm,
even blockchain,
no.

67
00:04:20.620 --> 00:04:24.850
Then it will give each member a score based on an objective function.

68
00:04:25.120 --> 00:04:27.550
This score is called the fitness function.

69
00:04:27.760 --> 00:04:31.600
It's a measure of how well a member did in relation to the goal.

70
00:04:31.900 --> 00:04:33.670
Once all members are scored,

71
00:04:33.671 --> 00:04:37.870
the algorithm will select the highest scoring members by some predefined

72
00:04:37.871 --> 00:04:42.310
threshold and breed them to produce more members like them.

73
00:04:42.730 --> 00:04:47.730
Breeding involves some interpolation of each member's features that is

74
00:04:47.831 --> 00:04:51.130
application specific.
In addition to breeding,

75
00:04:51.131 --> 00:04:55.840
will mutate some members randomly to attempt to find even better candidates.

76
00:04:56.110 --> 00:05:00.670
The rest of the members die off in a very Darwinian survival of the fittest way.

77
00:05:01.060 --> 00:05:04.510
This process repeats for as many iterations as necessary.

78
00:05:04.750 --> 00:05:09.250
Actually in this context,
we'd call them generations as we defined at the end.

79
00:05:09.251 --> 00:05:13.060
The idea is that we'll be left with the very best possible members of a

80
00:05:13.061 --> 00:05:13.930
population.

81
00:05:14.350 --> 00:05:18.310
The steps are all inspired by Darwin's theory of natural selection.

82
00:05:18.550 --> 00:05:23.550
We can think of them as optimizers searching the possible space of solutions for

83
00:05:23.561 --> 00:05:24.394
the right one.

84
00:05:24.580 --> 00:05:28.720
They're all a part of the broader class of algorithms called evolutionary

85
00:05:28.721 --> 00:05:31.960
computation.
If we again look at the animal kingdom,

86
00:05:31.961 --> 00:05:36.961
we'll observe that there is a complex interplay in two intertwined processes,

87
00:05:37.400 --> 00:05:39.820
interlife learning and intro life learning.

88
00:05:40.210 --> 00:05:44.170
We can think of interlife learning as a process of evolution and natural

89
00:05:44.171 --> 00:05:45.730
selection traits.

90
00:05:45.760 --> 00:05:50.760
Epigenetics and microbiomes are passed on between animal generations and intro

91
00:05:51.761 --> 00:05:55.900
life.
Learning relates to how an animal learns during its lifetime.
That is,

92
00:05:55.930 --> 00:05:58.370
this is conditioned on its interaction with the world.

93
00:05:58.610 --> 00:06:02.360
Things like recognizing objects,
learning to communicate and walking.

94
00:06:02.810 --> 00:06:06.800
Both of these natural approaches are mirrored in computer science.

95
00:06:07.040 --> 00:06:10.550
Evolutionary algorithms can be considered interlife learning,

96
00:06:10.580 --> 00:06:15.580
whereas neural networks can be thought of as intro life learning or any gradient

97
00:06:16.280 --> 00:06:21.080
based optimization strategy really where specific experiences results in an

98
00:06:21.110 --> 00:06:22.340
update in behavior.

99
00:06:22.550 --> 00:06:27.500
So how do we perform neuro evolution using both of these processes to complete a

100
00:06:27.501 --> 00:06:32.360
goal?
Let's say we have a very simple fully connected neural network.

101
00:06:32.720 --> 00:06:36.680
Our goal will be to find the best parameters for image classification.

102
00:06:37.040 --> 00:06:40.010
There are four main ones,
the number of layers,
our network,

103
00:06:40.011 --> 00:06:44.900
we'll have the number of neurons and each layer what the activation function

104
00:06:44.901 --> 00:06:48.980
will be and what the optimization algorithm will be.
To start,

105
00:06:48.981 --> 00:06:51.860
we'll initialize our neural network with random weights,

106
00:06:52.070 --> 00:06:56.720
but not just one neural network like we usually do.
Let's initialize several.

107
00:06:56.750 --> 00:07:01.370
To create a population will need to train the weights of each network using an

108
00:07:01.371 --> 00:07:06.320
image data set.
Then benchmark how well it performs at classifying test data.

109
00:07:06.740 --> 00:07:11.240
We'll use its classification accuracy on the test set as our fitness function.

110
00:07:11.630 --> 00:07:14.570
If we sort all of our networks by their accuracy,

111
00:07:14.571 --> 00:07:18.320
we can see which ones are the lowest performing and remove them.

112
00:07:18.620 --> 00:07:21.770
Will only select the top scoring networks to be a part of.

113
00:07:21.771 --> 00:07:26.480
The next generation will also select a few of the lower scoring networks since

114
00:07:26.630 --> 00:07:31.040
it could potentially result in us not getting stuck in a local maximum.

115
00:07:31.190 --> 00:07:32.360
As we optimize,

116
00:07:32.480 --> 00:07:36.470
we can also randomly mutate some of our network parameters as well.

117
00:07:36.890 --> 00:07:41.240
Both of these methods are like an evolutionary way of preventing overfitting.

118
00:07:41.540 --> 00:07:45.680
Now we're going to breed our top picks.
In our neural network case.

119
00:07:45.740 --> 00:07:50.210
We'll create a new network or child by combining a random assortment of

120
00:07:50.211 --> 00:07:54.950
parameters from its parent networks so a child could have the same number of

121
00:07:54.951 --> 00:07:59.570
layers as one parent and the rest of its parameters are from another parent.

122
00:07:59.810 --> 00:08:01.730
Another child could have the opposite.

123
00:08:02.030 --> 00:08:07.030
This mirrors how biology works in real life and helps our algorithm converge on

124
00:08:07.341 --> 00:08:08.810
an optimized network.

125
00:08:08.990 --> 00:08:13.460
If we test out our algorithm and compare it to a brute force search will find

126
00:08:13.461 --> 00:08:17.000
that our algorithm gives us the same result as brute force,

127
00:08:17.210 --> 00:08:22.210
but in seven hours of training instead of 63 as the parameter complexity of the

128
00:08:22.731 --> 00:08:27.380
network increases.
Evolutionary Algorithms provide exponential speed ups.

129
00:08:27.740 --> 00:08:31.370
Google did this as well,
but with lots more data and computing power,

130
00:08:31.700 --> 00:08:36.700
they use hundreds of Gpu and TPU is for days they initialized a thousand

131
00:08:37.041 --> 00:08:41.090
identical convolutional neural networks with no hidden layers.

132
00:08:41.300 --> 00:08:43.820
Then through the evolutionary process,

133
00:08:44.060 --> 00:08:49.060
networks with higher accuracies are selected as parents copied and mutated to

134
00:08:49.581 --> 00:08:52.040
generate children.
While the rest die out.

135
00:08:52.310 --> 00:08:56.130
It progressively discovered better and better network architectures.

136
00:08:56.460 --> 00:08:58.080
In a later experiments,

137
00:08:58.140 --> 00:09:01.800
they used a fixed stack of repeated modules called cells.

138
00:09:02.070 --> 00:09:03.930
The number of cells stayed the same,

139
00:09:03.931 --> 00:09:06.900
but the architecture of each cell mutated over time.

140
00:09:07.800 --> 00:09:11.460
They also decided to use a specific form of regularization to improve the

141
00:09:11.461 --> 00:09:15.300
network's accuracy.
Instead of letting the lowest scoring networks die,

142
00:09:15.301 --> 00:09:18.690
they removed the oldest one's regardless of how well they scored,

143
00:09:18.990 --> 00:09:23.280
and it ended up improving the accuracy because their networks didn't utilize

144
00:09:23.400 --> 00:09:27.060
wait inheritance and they all needed to train from scratch.

145
00:09:27.390 --> 00:09:31.740
This technique selects for networks that remain accurate when they are
retrained.

146
00:09:31.741 --> 00:09:36.741
So only architectures that remain accurate through each generation survive in

147
00:09:36.841 --> 00:09:40.890
the long run,
which means we'll get networks that we trained really well.

148
00:09:40.920 --> 00:09:44.460
They called their model Amoeba net and it's the new state of the art in image

149
00:09:44.461 --> 00:09:47.100
classification.
So what have we learned here?

150
00:09:47.310 --> 00:09:52.310
Metal learning is the process of learning to learn where an AI optimizes one or

151
00:09:52.741 --> 00:09:54.210
several other ais.

152
00:09:54.570 --> 00:09:58.620
Evolutionary Algorithms used concepts from the evolutionary process,

153
00:09:58.770 --> 00:10:03.770
like mutation and natural selection to solve complex problems and a metal

154
00:10:03.931 --> 00:10:08.730
learning technique called neuro evolution uses evolutionary algorithms to

155
00:10:08.731 --> 00:10:10.920
optimize neural networks.
Specifically,

156
00:10:11.520 --> 00:10:14.280
please subscribe for more programming videos.
And for now,

157
00:10:14.310 --> 00:10:16.800
I've got to find a gradient,
so thanks for watching.

