WEBVTT

1
00:00:01.660 --> 00:00:03.500
Miss your chance to blow this up.

2
00:00:04.610 --> 00:00:06.980
<v 1>It actually takes more than a one shot to train a model.</v>

3
00:00:12.180 --> 00:00:15.290
Hello world,
it's Saroj and welcome to fresh machine learning.

4
00:00:15.350 --> 00:00:19.010
This course is all about making bleeding edge machine learning accessible to

5
00:00:19.011 --> 00:00:19.730
developers.

6
00:00:19.730 --> 00:00:23.000
The field is moving faster than Steve Balmer at a developer conference.

7
00:00:23.030 --> 00:00:24.230
<v 0>It's the belt look for some pills.</v>

8
00:00:25.440 --> 00:00:28.530
<v 1>We're going to learn to apply some of the latest machine learning techniques to</v>

9
00:00:28.531 --> 00:00:32.190
practical examples that you can integrate into your own apps.

10
00:00:32.280 --> 00:00:36.240
Neural networks had been around since the 50s but we've just never had as much

11
00:00:36.241 --> 00:00:38.370
data and computing power as we do now.

12
00:00:38.400 --> 00:00:42.240
We call it deep learning these days and it deserves the press it's gotten but so

13
00:00:42.241 --> 00:00:44.610
many articles claim and replicates the human brain.

14
00:00:44.730 --> 00:00:47.940
Some even make it sound like if we give a deep neural net enough data and

15
00:00:47.941 --> 00:00:52.770
compute,
it'll suddenly become self aware.
The brain is indeed a neural network,

16
00:00:52.771 --> 00:00:56.520
but do we really learn the way a deep neural net does what?
Let's think about it.

17
00:00:56.521 --> 00:01:00.270
In order for deep neural net to learn to say recognize an image off of banana.

18
00:01:00.300 --> 00:01:03.360
You first have to feed it hundreds of thousands of banana images.

19
00:01:03.390 --> 00:01:05.640
But think about the way you and I learn.

20
00:01:05.790 --> 00:01:08.700
If I were to show you an image of a banana for the first time,

21
00:01:08.820 --> 00:01:11.850
you'd probably be able to recognize a novel banana instantly,

22
00:01:11.880 --> 00:01:13.590
even if it was a different shape or color.

23
00:01:13.650 --> 00:01:17.790
We humans don't seem to need thousands of examples just to generalize just a
few.

24
00:01:17.880 --> 00:01:21.030
And we learn richer representations than machines do as well.

25
00:01:21.060 --> 00:01:24.570
We can use the concepts that we learn in other ways,
like creating new examples.

26
00:01:24.600 --> 00:01:26.280
If we could create an algorithm to do this,

27
00:01:26.281 --> 00:01:29.340
to learn concepts with a few examples,
wouldn't that be incredible?

28
00:01:29.400 --> 00:01:32.730
It would further democratize the fields so that not just the big companies like

29
00:01:32.731 --> 00:01:36.210
Google and Amazon with huge private internal data sets are able to train their

30
00:01:36.211 --> 00:01:39.420
models,
but anyone can.
So is there an algorithm that does this well?

31
00:01:39.450 --> 00:01:42.840
There was a recent paper that came out called human level concept learning

32
00:01:42.930 --> 00:01:46.140
through probabilistic program induction.
The authors said,

33
00:01:46.170 --> 00:01:49.860
let's build a model capable of what's called one shot learning one shot learning

34
00:01:49.861 --> 00:01:53.970
is a type of ml that learns an object category after just one or a few examples.

35
00:01:54.000 --> 00:01:54.770
Oh,

36
00:01:54.770 --> 00:01:59.130
we use something called BZ and program learning or BPL to do this Basie and

37
00:01:59.131 --> 00:02:02.940
refers to base theorem which attempts to use simple stochastic programming to

38
00:02:02.941 --> 00:02:04.020
represent concepts.

39
00:02:04.050 --> 00:02:07.680
The words the castic referring to the theory of probability is what Bayes

40
00:02:07.681 --> 00:02:09.210
theorem loosely revolves around.

41
00:02:09.330 --> 00:02:13.500
So by using simple the castic programs or probability algorithms,

42
00:02:13.570 --> 00:02:15.450
BPL can represent concepts.

43
00:02:15.480 --> 00:02:20.070
BPL build these simple stochastic programs compositionally from parts subparts

44
00:02:20.160 --> 00:02:23.280
and spatial relations.
All these things exist in a hierarchy of knowledge,

45
00:02:23.310 --> 00:02:25.560
which a machine has game through little experience.

46
00:02:25.590 --> 00:02:28.740
So they trained it on a Dataset of head writing characters and it was able to

47
00:02:28.741 --> 00:02:32.670
recognize characters with a better error rate than deep learning or even humans.

48
00:02:32.730 --> 00:02:36.390
So does that mean that BPL is a way to go?
Well,
it does have its flaws.

49
00:02:36.391 --> 00:02:39.510
It lacks explicit knowledge of certain things like parallel lines,

50
00:02:39.511 --> 00:02:42.600
symmetry and connections between ends of strokes and other strokes.

51
00:02:42.630 --> 00:02:45.150
And the learning hasn't really transferrable to other things.

52
00:02:45.151 --> 00:02:48.600
So it's not better than deep learning in every way.
A few months later though,

53
00:02:48.601 --> 00:02:52.230
deep mind challenge the paper by releasing their own called one shot learning

54
00:02:52.231 --> 00:02:54.240
with memory augmented neural networks.

55
00:02:54.320 --> 00:02:57.840
The basic idea they had was that deep learning is very data intensive,

56
00:02:57.870 --> 00:03:01.300
but perhaps there's a way to build a deep neural net that only needs a few

57
00:03:01.301 --> 00:03:04.060
examples to learn deep learning without the huge datasets.

58
00:03:04.090 --> 00:03:05.440
So they built what's called a memory.

59
00:03:05.441 --> 00:03:08.980
Augmented neural network on man has two parts,
a controller,

60
00:03:09.040 --> 00:03:12.640
which is either a feed forward neural net or LSTM neural net and an external

61
00:03:12.641 --> 00:03:13.390
memory module.

62
00:03:13.390 --> 00:03:16.520
The controller interacts with the external memory module with a number of read,

63
00:03:16.521 --> 00:03:18.970
write heads.
It's capable of longterm storage,

64
00:03:18.971 --> 00:03:22.330
be a slow updates of the weights and short term storage be the external memory

65
00:03:22.331 --> 00:03:22.750
module.

66
00:03:22.750 --> 00:03:26.260
They fed it a few examples of handwritten characters and continuously trained it

67
00:03:26.290 --> 00:03:28.960
thousands of times on just those examples.
And guess what?

68
00:03:28.990 --> 00:03:30.730
It outperforms humans as well.

69
00:03:30.760 --> 00:03:34.450
So they proved that one shot learning can be accomplished by using a neural

70
00:03:34.451 --> 00:03:36.850
network architecture,
which is pretty dope.

71
00:03:36.880 --> 00:03:40.420
So there are lots of methodologies to implement one shot learning and in this

72
00:03:40.421 --> 00:03:42.220
episode we're going to implement our own.

73
00:03:42.250 --> 00:03:46.270
We're going to build a one shot handwritten character classifier in python using

74
00:03:46.271 --> 00:03:47.420
the PSI Pi Library.

75
00:03:47.421 --> 00:03:51.550
So we've got an import our dependencies first we're going to want three

76
00:03:51.551 --> 00:03:55.270
libraries,
num,
Pi,
Psi,
Pi and copy.
Once we have those we can define two variables,

77
00:03:55.330 --> 00:03:58.060
the number of runs we want to complete and a reference far for where we store

78
00:03:58.061 --> 00:03:58.810
our class label.

79
00:03:58.810 --> 00:04:01.540
Then in our main method we can create an array of the size of runs,

80
00:04:01.570 --> 00:04:04.870
which is 20 we'll use this array to store all of our classification error rates,

81
00:04:04.900 --> 00:04:05.733
one every run.

82
00:04:05.740 --> 00:04:09.280
Then we'll write a four loop to train our algorithm 20 times for each run or run

83
00:04:09.281 --> 00:04:10.420
a classification function,

84
00:04:10.421 --> 00:04:13.660
which will attempt to classify a small sample set of images and store the error

85
00:04:13.661 --> 00:04:14.494
rate in the array.

86
00:04:14.500 --> 00:04:17.380
Then we'll print out the error rate to terminal and when we are done with all of

87
00:04:17.381 --> 00:04:17.910
our runs,

88
00:04:17.910 --> 00:04:20.860
we'll go ahead and get the mean error rate from the array and print it out as

89
00:04:20.861 --> 00:04:24.280
the last statement in terminal.
So how does this classification step work?

90
00:04:24.310 --> 00:04:27.160
Before we answer that,
we need to understand these two methods,
load images,

91
00:04:27.161 --> 00:04:30.040
points and modified how store distance,
the load images,
points,

92
00:04:30.041 --> 00:04:32.860
function loads and image files.
In our case,
this will be a character image.

93
00:04:32.890 --> 00:04:36.520
It then converts the image to an array and finds all the non zero values that is

94
00:04:36.521 --> 00:04:39.100
all of the inks pixels and store that in an array.

95
00:04:39.160 --> 00:04:42.220
Then it creates an array of all the coordinates of those pixels and returns that

96
00:04:42.280 --> 00:04:43.061
the modified house store.

97
00:04:43.061 --> 00:04:46.060
If distance is a metric that computes the similarity between two images by

98
00:04:46.061 --> 00:04:49.150
comparing their pixel coordinate erase that comes from the load images points

99
00:04:49.151 --> 00:04:49.510
function.

100
00:04:49.510 --> 00:04:52.420
It calculates the mean difference between both images and returns it the last

101
00:04:52.421 --> 00:04:55.750
parameter of the classification function costs just notifies a function that

102
00:04:55.751 --> 00:04:59.350
small values from the modified Hausdorff distance mean more similar.
Lastly,

103
00:04:59.380 --> 00:05:02.260
let's take a look at the classification function itself and this function.

104
00:05:02.290 --> 00:05:05.320
We were treated both our training and testing images and load their image point

105
00:05:05.321 --> 00:05:06.370
major cs into memory.

106
00:05:06.430 --> 00:05:09.820
Then we compute the cost matrix using the modified house torque distance.

107
00:05:09.850 --> 00:05:12.220
After that,
we compute the error rate and return it.
That's all.

108
00:05:12.250 --> 00:05:15.130
We do this for every run and then average them all and get the average error

109
00:05:15.131 --> 00:05:17.590
rate,
which isn't state of the art like deepmind or Bpl,

110
00:05:17.620 --> 00:05:20.970
but it does make for a good baseline demo of one shot.
Learning one shot.

111
00:05:20.971 --> 00:05:24.460
Learning will only get more popular over time.
Bunch of cooling's down below.

112
00:05:24.490 --> 00:05:27.130
Check them out and please subscribe for more videos.
For now,

113
00:05:27.160 --> 00:05:30.010
I've got to go fix an index out of bounds there,
so thanks for watching.

