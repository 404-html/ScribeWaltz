WEBVTT

1
00:00:00.090 --> 00:00:05.010
Hello world.
It's a Raj and Kenon AI really create another Ai.

2
00:00:05.400 --> 00:00:06.360
Of course it can.

3
00:00:06.570 --> 00:00:11.430
Neuro evolution is a technique that involves optimizing neural networks using

4
00:00:11.460 --> 00:00:13.110
evolutionary algorithms.

5
00:00:13.320 --> 00:00:18.320
We'll cover some example demos involving neuro evolutionary algorithms learning

6
00:00:18.900 --> 00:00:21.600
in a simulated environment.
In this video,

7
00:00:21.630 --> 00:00:26.630
mastering the art of deep learning takes lots of motivation and countless hours

8
00:00:27.451 --> 00:00:28.830
of productive work,

9
00:00:29.070 --> 00:00:34.070
but at the same time the need for deep learning experts keeps increasing more

10
00:00:34.531 --> 00:00:35.880
and more.
Because of this,

11
00:00:35.881 --> 00:00:40.590
there is this gap in the supply and demand equilibrium which is unlikely to go

12
00:00:40.591 --> 00:00:43.110
away anytime soon.
To solve this,

13
00:00:43.230 --> 00:00:48.230
companies are releasing systems that automate the creation of AI models.

14
00:00:48.450 --> 00:00:51.420
One example of this is auto ml by Google.

15
00:00:51.690 --> 00:00:54.510
This is a cloud offering that lets developers,

16
00:00:54.690 --> 00:00:59.690
including those with no ml expertise build custom image recognition models.

17
00:01:00.690 --> 00:01:05.190
This will likely be expanded to include other basic and l building blocks as

18
00:01:05.191 --> 00:01:07.620
well like speech translation,

19
00:01:07.740 --> 00:01:10.620
video and natural language recognition.

20
00:01:11.070 --> 00:01:16.070
This entire pipeline from importing data to tagging it to architecting the model

21
00:01:17.010 --> 00:01:21.480
to training is all done through a drag and drop interface.

22
00:01:21.720 --> 00:01:23.010
Drop it like a boss.

23
00:01:23.730 --> 00:01:27.510
It's doing this using a parent child network architecture.

24
00:01:27.870 --> 00:01:32.870
A parent neural network will propose a child model architecture randomly,

25
00:01:33.630 --> 00:01:38.070
which is then trained and evaluated for quality on some task.

26
00:01:38.370 --> 00:01:43.370
That feedback is then used to inform the parent how to improve its next

27
00:01:44.100 --> 00:01:46.020
generated child architecture.

28
00:01:46.380 --> 00:01:51.380
This process is repeated thousands of times every time generating new

29
00:01:51.421 --> 00:01:53.340
architectures,
testing them,

30
00:01:53.460 --> 00:01:57.960
and giving that feedback to the parent to learn from the gradient update acts as

31
00:01:57.961 --> 00:02:02.961
feedback and eventually the parent learns to assign high probability to areas of

32
00:02:03.211 --> 00:02:07.830
architecture space that achieved the best accuracy for a given dataset.

33
00:02:07.920 --> 00:02:12.060
Another more recent example is by Uber on neuro evolution.

34
00:02:12.480 --> 00:02:17.130
Uber Ai Research released a set of five papers focused on this technique.

35
00:02:17.490 --> 00:02:22.490
The researchers state that genetic algorithms are an effective method to train

36
00:02:23.040 --> 00:02:28.040
deep neural networks for reinforcement learning problems and that they

37
00:02:28.110 --> 00:02:31.740
outperform traditional reinforcement learning approaches.

38
00:02:31.830 --> 00:02:36.690
In some domains,
evolutionary methods have a long history,

39
00:02:36.691 --> 00:02:38.370
but they are on the rise.

40
00:02:38.640 --> 00:02:42.090
This continues the trend of resurrecting decade old ideas,

41
00:02:42.250 --> 00:02:46.980
applying them to real world problems using modern hardware and getting strong

42
00:02:46.981 --> 00:02:50.520
results.
This was the case for convolutional networks,

43
00:02:50.580 --> 00:02:54.870
recurrent networks and reinforcement learning in general.
In fact,

44
00:02:54.900 --> 00:02:59.900
the whole history of deep learning is full of reinvention and resurrection.

45
00:03:01.240 --> 00:03:05.560
Backpropagation,
for example,
was reinvented several times.

46
00:03:05.650 --> 00:03:08.290
Machine learning is an optimization problem,

47
00:03:08.350 --> 00:03:11.440
whether the task at hand is classification,

48
00:03:11.590 --> 00:03:13.900
regression or reinforcement learning.

49
00:03:14.110 --> 00:03:19.110
The objective is almost always to find a function that maps input data to output

50
00:03:19.211 --> 00:03:19.630
data.

51
00:03:19.630 --> 00:03:24.630
A data scientist will try and infer the parameters and hyper parameters of their

52
00:03:24.941 --> 00:03:29.290
model from the training data and verify with the test data.

53
00:03:29.440 --> 00:03:33.700
Whether the approximated function performs well on an unseen Dataset.

54
00:03:34.060 --> 00:03:38.350
The core problem is finding the right hyper parameter settings that result in

55
00:03:38.351 --> 00:03:40.630
the lowest loss or the highest reward.

56
00:03:40.960 --> 00:03:44.230
The traditional way to do this is using gradient descent,

57
00:03:44.440 --> 00:03:49.060
which is called back propagation.
In the context of neural networks,

58
00:03:49.450 --> 00:03:52.600
let's say our network has two different parameters.

59
00:03:52.930 --> 00:03:56.470
This is just so we can visualize the optimizations surface.

60
00:03:56.680 --> 00:03:59.650
Usually there's a giant number of parameters,

61
00:03:59.651 --> 00:04:04.651
so it's impossible to visualize the graph of all the values of both parameters

62
00:04:04.930 --> 00:04:06.880
and all the possible error values.

63
00:04:07.130 --> 00:04:11.200
Looks like a very rough terrain with hills and valleys like East Texas.

64
00:04:11.740 --> 00:04:15.400
We want to find the point at the bottom of the steepest valley.
The minimum,

65
00:04:15.830 --> 00:04:20.770
the gradient we compute and every iteration tells us which direction to search

66
00:04:20.920 --> 00:04:22.300
to find that minimum.

67
00:04:22.640 --> 00:04:26.710
Think of it like rolling a ball around this surface till we find that minimum.

68
00:04:26.890 --> 00:04:30.970
That's currently the most popular way to optimize a network.

69
00:04:31.450 --> 00:04:36.280
Neuro evolution,
genetic algorithms,
evolutionary strategies.
These techniques,

70
00:04:36.281 --> 00:04:40.240
however,
all revolve around the concept of genetic evolution.

71
00:04:40.750 --> 00:04:45.190
If we're doing genetic optimization in the context of deep neural networks,

72
00:04:45.430 --> 00:04:48.250
we'd start with an initial population of models.

73
00:04:48.280 --> 00:04:53.230
Usually a model is randomly initialized and several offspring are derived based

74
00:04:53.231 --> 00:04:56.740
on this initial model.
In the case of deep neural networks,

75
00:04:56.830 --> 00:05:00.100
we initialize a model,
add small random vectors,

76
00:05:00.250 --> 00:05:03.700
sampled from a simple golf and distribution to the perimeters.

77
00:05:04.000 --> 00:05:06.040
This results in a cloud of models,

78
00:05:06.041 --> 00:05:09.490
which all resides somewhere on the optimization surface.

79
00:05:09.940 --> 00:05:13.000
This is an important distinction from gradient descent.

80
00:05:13.300 --> 00:05:17.920
We Start and continue to work with the population of models instead of a single

81
00:05:17.921 --> 00:05:21.070
model.
So starting from this original population,

82
00:05:21.250 --> 00:05:24.400
the genetic optimization cycle begins first.

83
00:05:24.430 --> 00:05:26.740
A fitness evaluation is performed.

84
00:05:27.040 --> 00:05:31.990
This corresponds with checking where the models are in the optimization surface

85
00:05:32.200 --> 00:05:35.770
and determining which of the models perform best,

86
00:05:35.980 --> 00:05:38.860
meaning which are the most fit by some measure.

87
00:05:39.190 --> 00:05:41.440
So muddles will perform better than others,

88
00:05:41.441 --> 00:05:46.120
and that's because of the way their parameters have been initialized.
Next,

89
00:05:46.121 --> 00:05:49.450
a selection is performed based on the fitness evaluation.

90
00:05:49.780 --> 00:05:51.310
In evolution strategies,

91
00:05:51.311 --> 00:05:55.900
the offspring is reduced to a single model weighted by the fitness evaluation

92
00:05:56.290 --> 00:06:01.130
for deep neural networks.
The fitness is defined as the loss or the reward.

93
00:06:01.340 --> 00:06:05.990
So we're basically moving around on the optimization surface and using the

94
00:06:06.020 --> 00:06:08.480
offspring to point in the right direction.

95
00:06:08.870 --> 00:06:11.720
This is another big difference from gradient descent.

96
00:06:11.930 --> 00:06:14.210
Instead of computing the gradients,

97
00:06:14.240 --> 00:06:19.100
we're sending out multiple antennas and moving in the direction that looks best.

98
00:06:19.130 --> 00:06:21.590
It's kind of like a structured random search.

99
00:06:21.740 --> 00:06:25.610
The end result of this selection phase is that we have a single model.

100
00:06:25.640 --> 00:06:28.480
The next step is reproduction Tki.

101
00:06:28.580 --> 00:06:33.260
The same process as in the initial phase is repeated based on the newly selected

102
00:06:33.261 --> 00:06:36.800
prime model.
A new set of ops spring is derived.

103
00:06:37.070 --> 00:06:40.070
The process then continues with these offspring.

104
00:06:40.490 --> 00:06:45.490
Typically in genetic optimization mutation is also performed in order to improve

105
00:06:45.651 --> 00:06:47.780
the variety of offspring.
All right.

106
00:06:47.810 --> 00:06:52.160
Now let's see what the code looks like for using neuro evolution to create the

107
00:06:52.220 --> 00:06:56.600
optimal neural network capable of being the simple game of flappy birds.

108
00:06:57.050 --> 00:07:01.370
To define the basic architecture of the game,
we've got two classes,

109
00:07:01.550 --> 00:07:02.690
pipe and bird.

110
00:07:02.960 --> 00:07:07.730
These classes defined the behavior for the pipes and the bird element of the

111
00:07:07.731 --> 00:07:08.564
game.

112
00:07:08.600 --> 00:07:12.770
These classes along with the game function are enough to run the game.

113
00:07:12.890 --> 00:07:17.890
The game function initializes both of these classes and runs one round of the

114
00:07:17.901 --> 00:07:20.450
game.
The arguments to this function,

115
00:07:20.540 --> 00:07:25.540
genome and config are used for running the neuroevolution algorithm.

116
00:07:26.000 --> 00:07:29.960
Implementing the running of the game in one function allows it to be called at

117
00:07:29.990 --> 00:07:34.640
any time at the convenience of the NDA t algorithm.
Neat.

118
00:07:35.030 --> 00:07:39.650
The function also computes the fitness of each genome during the game run.

119
00:07:40.010 --> 00:07:44.240
The evaluate genomes function relates directly to the running of the neat

120
00:07:44.300 --> 00:07:49.300
algorithm and is responsible for evaluating all genomes of the population for a

121
00:07:50.301 --> 00:07:51.680
particular generation.

122
00:07:52.130 --> 00:07:57.130
It calls the game function for all genomes present in the current population and

123
00:07:57.471 --> 00:08:02.390
assigns the fitness value returned by the game function to the corresponding

124
00:08:02.391 --> 00:08:07.370
genome.
We are using the neat implementation of the neat python package,

125
00:08:07.610 --> 00:08:12.500
which requires a config file that contains a list of algorithm parameters and

126
00:08:12.501 --> 00:08:13.334
their values.

127
00:08:13.610 --> 00:08:18.260
Let's just maintain the default values for all the parameters except for the

128
00:08:18.261 --> 00:08:23.261
number of inputs and the fitness threshold value which will set to 600 once the

129
00:08:23.691 --> 00:08:24.560
game is trained.

130
00:08:24.770 --> 00:08:29.180
We can see that the number of generations taken by the algorithm to meet the

131
00:08:29.181 --> 00:08:33.140
fitness threshold very linearly with the difficulty of the game,

132
00:08:33.260 --> 00:08:36.410
which was dictated by the length of the gap between the pipes.

133
00:08:36.620 --> 00:08:40.550
The optimal neural networks were not only different in terms of their weight

134
00:08:40.551 --> 00:08:44.420
values,
but also in terms of their architecture.
All right.

135
00:08:44.421 --> 00:08:46.640
Some things to keep in mind from this video.

136
00:08:46.910 --> 00:08:51.530
Neuro evolution is a technique that involves optimizing neural networks using

137
00:08:51.620 --> 00:08:56.100
evolutionary algorithms as the demand for better AI increase.

138
00:08:56.190 --> 00:09:01.110
So will the demand for AI that can design AI most efficiently and we can use

139
00:09:01.111 --> 00:09:05.680
neuro evolution as an alternative optimization technique to great and descent.

140
00:09:06.090 --> 00:09:10.020
Last week's coding challenge.
Winner is dare baldy.
First of all,

141
00:09:10.110 --> 00:09:12.240
I love the documentation he wrote,

142
00:09:12.410 --> 00:09:15.060
makes it really easy for anyone to get started.

143
00:09:15.300 --> 00:09:20.300
He successfully face swapped me with an actor named Kal Penn and has ambitions

144
00:09:20.791 --> 00:09:23.670
to apply this technology to music signals.

145
00:09:23.700 --> 00:09:28.380
Next for a first get hub repo,
you totally rocked it.
Awesome job.

146
00:09:28.740 --> 00:09:30.420
And the runner up is power deep.

147
00:09:30.421 --> 00:09:34.740
Sing stellar effort on trying out different architectures for bass swapping.

148
00:09:34.800 --> 00:09:39.300
This week's challenge apply neuro evolution to help an AI move more efficiently

149
00:09:39.301 --> 00:09:42.480
in a twoD or Three d environment poster,
get hubs,

150
00:09:42.490 --> 00:09:47.310
links in the youtube comment section and I'll announce the top two entries next

151
00:09:47.310 --> 00:09:49.950
week.
Yo,
did you like this video?
If so,

152
00:09:49.980 --> 00:09:53.820
hit the subscribe button and all your dreams will come true.
For now,

153
00:09:53.850 --> 00:09:56.340
I've got to evolve,
so thanks for watching.

