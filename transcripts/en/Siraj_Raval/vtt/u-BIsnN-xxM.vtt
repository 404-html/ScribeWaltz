WEBVTT

1
00:00:00.060 --> 00:00:04.470
Hello world,
it's a Raj and Numenta.
Today I'm going to talk about new mentees.

2
00:00:04.500 --> 00:00:09.500
Hierarchical temporal memory system sounds super complicated and it's not

3
00:00:10.050 --> 00:00:10.561
actually.

4
00:00:10.561 --> 00:00:15.480
So this video is going to be me explaining how it works and how it compares to

5
00:00:15.481 --> 00:00:18.570
the hottest technology of today,
which is deep learning,
right?

6
00:00:18.690 --> 00:00:22.140
We hear a lot about deep learning.
I make a lot of videos about deep learning.

7
00:00:22.141 --> 00:00:25.470
Everybody talks about deep learning and the machine learning community,
right?

8
00:00:25.471 --> 00:00:30.030
That is the set of algorithms that it's outperforming everything else on a

9
00:00:30.031 --> 00:00:31.530
specific set of benchmarks.

10
00:00:31.830 --> 00:00:36.270
But there is this other technology called hierarchical temporal memory that this

11
00:00:36.271 --> 00:00:40.800
company called Numenta is working on that I think deserves some light and some

12
00:00:40.801 --> 00:00:41.610
attention.

13
00:00:41.610 --> 00:00:46.610
And especially now as back propagation we found is starting to face some limits

14
00:00:47.820 --> 00:00:52.710
and we have to create new algorithms and entirely new architectures and ideas to

15
00:00:52.711 --> 00:00:54.690
continue to progress the state of the art.

16
00:00:54.990 --> 00:00:57.120
So I want to talk a bit about how this works.

17
00:00:57.210 --> 00:00:59.040
We're going to go over the code at the end,

18
00:00:59.041 --> 00:01:02.970
but before that we have a lot of theory to cover.
Okay,
so let's just,
let's go.

19
00:01:03.840 --> 00:01:04.673
So,
uh,

20
00:01:04.830 --> 00:01:09.830
Numenta is this company slash research organization based in Redwood City and it

21
00:01:10.741 --> 00:01:12.390
was started by a guy named Jeff Hawkins.

22
00:01:12.420 --> 00:01:16.540
So if you don't know who Jeff Hawkins is,
he's the guy behind the palm pilot,
uh,

23
00:01:16.800 --> 00:01:18.870
which was that phone with,
with the pen.

24
00:01:19.080 --> 00:01:21.000
And he sold it for a lot of money back in the day.

25
00:01:21.001 --> 00:01:24.330
And basically the dude had a lot of money and he had decided to put all of that

26
00:01:24.331 --> 00:01:27.390
money into Numenta,
which is this research organization.

27
00:01:27.780 --> 00:01:31.380
He also published his book in 2004 called on intelligence.

28
00:01:31.660 --> 00:01:33.930
So I've got this timeline right here of,
you know,

29
00:01:33.960 --> 00:01:36.660
the all the milestones and it's a great book.

30
00:01:36.690 --> 00:01:38.970
So you should definitely read that book.
I read that book.

31
00:01:39.690 --> 00:01:44.490
It's essentially a pop neuroscience book that explains some of his high level

32
00:01:44.491 --> 00:01:47.940
ideas of how the brain must work.
And uh,
Andrew Ang,

33
00:01:47.941 --> 00:01:52.660
the popular Stanford professor behind the machine learning course by core.

34
00:01:52.661 --> 00:01:55.500
Sarah also admits that he was one of his influences.

35
00:01:55.501 --> 00:01:59.910
So definitely read that book on intelligence.
It's a good book,
but okay.

36
00:01:59.911 --> 00:02:01.740
So from there he published the book.

37
00:02:01.741 --> 00:02:05.250
He started a new mentor in 2005 and since then they've been working on this

38
00:02:05.251 --> 00:02:09.480
system that they call the hierarchical temporal memory system that aims to

39
00:02:09.481 --> 00:02:13.650
replicate the human neocortex.
We're going to go into all of that in a second,

40
00:02:14.730 --> 00:02:15.690
but the goal,

41
00:02:15.720 --> 00:02:20.210
Jeff Hawkins goal and his team's goal in making this system was to study the

42
00:02:20.211 --> 00:02:24.690
human neocortex and establish it's working principles.
How does it work?

43
00:02:24.691 --> 00:02:28.680
What are its rules?
Forget about current machine learning techniques,

44
00:02:28.800 --> 00:02:32.460
forget about mathematical optimization when it comes to second order

45
00:02:32.461 --> 00:02:35.190
optimization or gradients are derivatives,
et cetera.

46
00:02:35.430 --> 00:02:38.130
Let's just start with the neocortex and go from there.

47
00:02:38.520 --> 00:02:41.400
And He published the book.
He opens doors,

48
00:02:41.430 --> 00:02:44.400
they open sourced this new pic platform,

49
00:02:44.401 --> 00:02:47.520
which is the new [inaudible] platform for intelligent computing.

50
00:02:47.760 --> 00:02:51.030
And there are really four ways to get started with our technology that they've

51
00:02:51.031 --> 00:02:53.220
released.
So they've got some research and theory.

52
00:02:53.221 --> 00:02:55.130
So there there are resource or organizations,

53
00:02:55.190 --> 00:02:58.590
so they're publishing papers and from those papers they have some technology

54
00:02:58.591 --> 00:03:01.660
that they developed.
And there are four ways to get into this.

55
00:03:01.840 --> 00:03:02.980
The first is called Grok.

56
00:03:02.981 --> 00:03:07.870
So Brock is an actual product that uses the new pick technology for stock market

57
00:03:07.871 --> 00:03:10.240
stuff,
but I'm not going to talk about that.

58
00:03:10.300 --> 00:03:13.360
There's also the anomaly detection engine which is licensed.

59
00:03:13.710 --> 00:03:16.300
There are some sample apps and then there's new pick itself,

60
00:03:16.301 --> 00:03:19.600
which is that's what we're going to go into this new pick technology.

61
00:03:20.680 --> 00:03:23.620
They all serve their own purposes.
And uh,
for the,

62
00:03:23.680 --> 00:03:27.760
for the data scientists slash high level programmer like good programmers,

63
00:03:27.970 --> 00:03:30.130
new pig is the way to go,
which is who we are.

64
00:03:30.131 --> 00:03:31.540
So of course we're going to go into that.

65
00:03:31.541 --> 00:03:35.950
We are the coolest people on the planet ever,
ever by the way.
We are.
So cool.

66
00:03:35.951 --> 00:03:38.590
Don't,
don't,
don't get me on this tangent of how cool we are right now.

67
00:03:38.591 --> 00:03:42.340
But seriously,
man,
I,
I,
I've been reading your comments.

68
00:03:42.341 --> 00:03:45.490
I'm just looking into the discussions and the slack channel and the Youtube

69
00:03:45.491 --> 00:03:48.310
comments on Twitter,
on Facebook and man,
I mean,

70
00:03:48.311 --> 00:03:52.180
you guys are so smart and I'm just so honored to have you guys as an audience

71
00:03:52.181 --> 00:03:55.930
and I'm going to continue to make content for you just to short,
you know,
Love,

72
00:03:56.650 --> 00:03:59.950
love tirade from me to you.
But,
uh,
yeah,

73
00:03:59.951 --> 00:04:02.680
you guys inspire me that I just wanted to say that,
but back to this.

74
00:04:03.040 --> 00:04:06.460
So how is HCM different from deep learning?
Right?
Deep learning works.

75
00:04:06.550 --> 00:04:09.280
Why are you talking about this?
Saroj what's the point,
right?

76
00:04:09.310 --> 00:04:12.370
The machine learning sub reddit laughs at this technology half the time.

77
00:04:12.580 --> 00:04:15.940
It's true.
They do.
But uh,
that's,
you know,
it's okay.

78
00:04:15.941 --> 00:04:19.930
We need to give them some love,
some light.
Look,
they're trying to solve AGI.
Okay.

79
00:04:19.931 --> 00:04:22.750
There's trying to solve it and show them some love.
Okay.

80
00:04:23.320 --> 00:04:28.150
So the idea is that AI 1.0 was all about hand coded systems,
right?
Heuristics,

81
00:04:28.151 --> 00:04:30.010
things like that.
Custom engineering.

82
00:04:30.340 --> 00:04:35.340
But then AI 2.0 was learning from data sets instead of hand coding rules and so

83
00:04:35.531 --> 00:04:38.350
deep learning,
artificial neural networks and also in,
you know,

84
00:04:38.351 --> 00:04:41.950
in a lot of ways support vector machines and a whole bunch of other machine

85
00:04:41.951 --> 00:04:44.290
learning models.
All of those fit into this category.

86
00:04:45.370 --> 00:04:50.370
But AI 3.0 in the way that Numenta views it is using html,

87
00:04:50.530 --> 00:04:53.140
which is true machine intelligence.
So,
okay,

88
00:04:53.141 --> 00:04:58.141
so the difference here is that the one really key difference is that the HCM

89
00:04:59.321 --> 00:05:03.010
technology uses online unsupervised data.

90
00:05:03.070 --> 00:05:05.560
So you can't compare it to deep learning.
So here's what I mean.

91
00:05:05.800 --> 00:05:09.130
So when we're using deep learning,
we are training it on some static data set,

92
00:05:09.131 --> 00:05:13.320
right?
We're saying,
okay,
here's a bunch of images like the CFR data image,

93
00:05:13.450 --> 00:05:16.570
image net or something like that.
And we're saying learns from all these images.

94
00:05:16.720 --> 00:05:19.000
Okay,
you've learned it,
okay,
now it's time for inference.

95
00:05:19.001 --> 00:05:21.340
It's time to use this predicted model in the real world.

96
00:05:21.700 --> 00:05:26.230
So the way HTM works is it's using streams of data,
it's learning in real time.

97
00:05:26.231 --> 00:05:30.160
Online means in real time.
Offline means like beforehand,
right?

98
00:05:30.161 --> 00:05:33.310
So that is really cool.
10 portal streams,
right?

99
00:05:33.311 --> 00:05:38.050
So streams that are continuous that are sequences of data,
which is how we learn,

100
00:05:38.051 --> 00:05:41.950
right?
We are constantly getting these temporal streams through our eyes,

101
00:05:42.010 --> 00:05:46.240
through our senses,
through our mouth,
knows all of our five senses.
This is,

102
00:05:46.630 --> 00:05:51.010
this is sequential data that our brain is learning from online or in real time.

103
00:05:52.120 --> 00:05:56.770
So the closest comparison to what the HTM is is the LSTM network.

104
00:05:56.860 --> 00:06:00.410
So recurrent networks are all about using sequential data,
right?

105
00:06:00.411 --> 00:06:03.950
It's sequential data.
So our recurring net when at every time step,

106
00:06:03.980 --> 00:06:06.890
it feeds in not just the,
the,
the input data.

107
00:06:06.920 --> 00:06:10.580
It also pre feeds in the previous Laurent hidden state.

108
00:06:10.581 --> 00:06:14.660
That encoding that it learned itself so that it can learn sequences of data

109
00:06:15.260 --> 00:06:18.410
because you know the,
the,
the ordering matters of data,
right?

110
00:06:18.411 --> 00:06:21.970
That's why it's feeding in the previous hidden state sequences in sequences,

111
00:06:22.000 --> 00:06:25.580
the order matters.
However,
what happens is for recurrent networks,

112
00:06:26.780 --> 00:06:30.230
what happens is over time it,
it,

113
00:06:30.290 --> 00:06:32.330
the gradient can't back propagate enough.

114
00:06:32.360 --> 00:06:35.660
The grading gets smaller and smaller and smaller as it goes from the last layers

115
00:06:35.661 --> 00:06:38.360
to the first layers.
And this is a problem,
right?

116
00:06:38.600 --> 00:06:40.640
Ideally the gradient doesn't vanish,
right?

117
00:06:40.641 --> 00:06:42.410
This is called the vanishing gradient problem.

118
00:06:42.560 --> 00:06:46.220
So the first layers aren't updated as know as,
as much as they should be.

119
00:06:46.460 --> 00:06:50.690
So the way to prevent that is to use what's called an long short term memory or

120
00:06:50.691 --> 00:06:54.850
Lstm cell.
And you use that Lstm cell and it's got this input gate,

121
00:06:54.851 --> 00:06:57.190
he's got an output gate,
it's got to forget gate.
Uh,

122
00:06:57.200 --> 00:07:01.010
but basically it's job is to kind of trap in memory over the longterm.

123
00:07:01.250 --> 00:07:03.560
And so when using this LSTM architecture,

124
00:07:03.650 --> 00:07:07.550
we're able to it on longer term sequences,
like entire books,
entire novels.

125
00:07:07.730 --> 00:07:11.420
And so we can have,
you know,
someone,
uh,
an AI output,

126
00:07:11.421 --> 00:07:16.180
the writing of Nicha after a reading,
thus folks are Giustra or,
um,

127
00:07:16.400 --> 00:07:18.200
beyond good and evil.
Great book by the way,

128
00:07:18.201 --> 00:07:21.770
beyond good and evil is such a great book on another tangent,
but back to this.

129
00:07:22.070 --> 00:07:25.370
So anyway,
so let's keep thinking of entirely new architectures guys.

130
00:07:25.371 --> 00:07:29.090
Like we can't just say,
all right,
deep minds,
deep deep Q network.
Oh,

131
00:07:29.091 --> 00:07:32.090
it beat Atari.
It'd be like 20 different Atari Games.
Great.

132
00:07:32.091 --> 00:07:34.960
Feed it more processing powers and you know,
Agi,

133
00:07:34.970 --> 00:07:38.900
there we go because look back propagation is not the end.
Okay.

134
00:07:39.080 --> 00:07:40.580
I am not a neuroscientist,

135
00:07:40.581 --> 00:07:44.420
but I'm pretty sure that our brain is not back propagating gradients.
Okay.

136
00:07:44.421 --> 00:07:46.190
There's gotta be something more to it than that.

137
00:07:46.670 --> 00:07:49.970
So let's keep thinking of new architecture.
So let's keep this,
uh,
this,

138
00:07:49.971 --> 00:07:51.970
this pace of innovation going well.
You know,
we,

139
00:07:51.971 --> 00:07:54.950
we've got the hype train started so,
so let's keep it moving here.

140
00:07:55.970 --> 00:07:59.330
So the ATM is directly based on the New York neocortex.

141
00:07:59.331 --> 00:08:03.290
While deep learning is slightly inspired by neuroscience,
right?
So it's,
you know,

142
00:08:03.291 --> 00:08:07.640
input times wait,
activates,
right?
Their Matrix operations and you know,

143
00:08:07.641 --> 00:08:11.120
sometimes they'll,
researchers will incorporate ideas from neuroscience,

144
00:08:11.121 --> 00:08:15.550
like replay memory for example,
but it's not like just directly,
you know,

145
00:08:15.850 --> 00:08:19.090
neocortex inspired like what these guys are trying to do,
which I commend.

146
00:08:19.230 --> 00:08:20.180
I think it's a great idea.

147
00:08:20.330 --> 00:08:24.720
It's not giving them great results obviously right now,
but the idea is good and,

148
00:08:24.721 --> 00:08:28.850
and eventually it will keep in mind people laughed at deep learning in the early

149
00:08:28.850 --> 00:08:31.340
days,
right?
Deep learning in the 90s.
And before that was a joke.

150
00:08:31.550 --> 00:08:33.800
And now it's the hottest technology.
So you know,

151
00:08:33.801 --> 00:08:35.210
sometimes it's just that little tweak,

152
00:08:35.211 --> 00:08:39.050
that little innovation that sparks a revolution.
So the Hem,

153
00:08:39.080 --> 00:08:44.060
the hen M can learn complex temporal structure with several orders of magnitude,

154
00:08:44.090 --> 00:08:45.650
fewer examples,

155
00:08:45.680 --> 00:08:50.660
dozens rather than millions and can also be easily configured to do reliable one

156
00:08:50.661 --> 00:08:54.620
shot learning learning from a few examples in specific cases,

157
00:08:54.621 --> 00:08:57.990
not all over la,
not not in every type of data,
right?

158
00:08:57.990 --> 00:09:01.500
This is sequential data for specific types of sequential data.

159
00:09:02.550 --> 00:09:05.160
But the idea is that we have some hierarchy,
right?

160
00:09:05.161 --> 00:09:08.300
We have some level of stacks cells and it's,

161
00:09:08.340 --> 00:09:13.050
it's temporal in that it operates over time series data in an unsupervised

162
00:09:13.051 --> 00:09:13.650
manner.

163
00:09:13.650 --> 00:09:17.610
And Colin's themselves decide to activate based on input previous states of

164
00:09:17.611 --> 00:09:20.640
connected neighbors.
So there,
so you might be thinking,

165
00:09:20.641 --> 00:09:23.340
well it sounds kind of like convolutional networks,

166
00:09:23.580 --> 00:09:27.480
but the only way that the HCM is like a convolutional network is that it is a

167
00:09:27.481 --> 00:09:31.500
tree like structure with locally connected,
Aka sparse weights.

168
00:09:31.530 --> 00:09:36.300
But unlike convolutional nets,
it doesn't use shared weights.
Okay.
So in a way,

169
00:09:36.301 --> 00:09:38.430
it's basically like an auto encoder.

170
00:09:38.700 --> 00:09:43.290
It's like a recurrent auto encoder that doesn't use doc propagation.

171
00:09:43.470 --> 00:09:46.770
It uses what's called heavy and learning or a variant of heavy and learning.

172
00:09:46.830 --> 00:09:51.830
It is an auto encoder that is recurrent and uses heavy and learning.

173
00:09:53.250 --> 00:09:57.850
That's the Tldr of HTM right there.
Okay.
So,
but for me,

174
00:09:57.851 --> 00:10:01.920
if the really the main thing that interests me about HTM is the fact that it

175
00:10:02.070 --> 00:10:03.930
uses online data,

176
00:10:03.931 --> 00:10:08.931
like real time data and in terms of algorithms that can do that from real time

177
00:10:09.121 --> 00:10:12.150
data streams,
I can't think of any that don't use experience replay.

178
00:10:12.540 --> 00:10:15.390
And it does this quite well.
Like you can learn a sheet of music for instance,

179
00:10:15.540 --> 00:10:19.890
after as little as 26 iterations.
And uh,
you know,
I've got this video here,

180
00:10:20.350 --> 00:10:24.910
it's a shadow of a demo of someone who built in,
hey,

181
00:10:24.911 --> 00:10:26.010
I drum composer,

182
00:10:28.380 --> 00:10:29.213
<v 1>check this out.</v>

183
00:10:35.760 --> 00:10:39.240
<v 0>Yeah.
So anyway,
uh,
check out this video as well as in the description.
But uh,</v>

184
00:10:39.810 --> 00:10:40.080
there are,

185
00:10:40.080 --> 00:10:43.500
there are some really cool applications that have been made with the HTM.
Didn't,

186
00:10:43.501 --> 00:10:45.540
you know,
they have these hackathons and they have people make things.

187
00:10:45.541 --> 00:10:47.430
So there are definitely,
um,

188
00:10:47.670 --> 00:10:50.100
cool applications that have been made using little data.

189
00:10:50.460 --> 00:10:52.710
So it definitely deserves more exploration.

190
00:10:54.130 --> 00:10:54.963
<v 1>Okay.</v>

191
00:10:55.650 --> 00:10:59.430
<v 0>Okay.
Anyway,
so hierarchical temporal memory explained,</v>

192
00:10:59.460 --> 00:11:03.570
it's all starts with the NEO Cortex,
right?
Who you are,
your identity,

193
00:11:03.571 --> 00:11:07.470
your memories,
how you think,
how you move,
how you create,
how you learn,

194
00:11:07.590 --> 00:11:11.070
how you talk,
all of that you are stored.

195
00:11:11.100 --> 00:11:13.120
It's all stored in your neocortex.

196
00:11:13.200 --> 00:11:16.920
That is this central part of the brain right here.
It's very wrinkly.
But if you,

197
00:11:17.220 --> 00:11:20.940
if you flattened it,
it would look like a,
like a dinner Napkin.
It's,
it's very,

198
00:11:21.060 --> 00:11:25.470
it's very small,
but the rest of the brain,
the mid brain is about remember,

199
00:11:25.530 --> 00:11:27.360
remembering things,
interacting with others,

200
00:11:27.510 --> 00:11:30.570
and then you've got the reptilian brain in the back that's all about,
you know,

201
00:11:30.571 --> 00:11:35.490
basic bodily instincts like survive,
react,
repeat,
repeat,
repeat.
Right?
So,

202
00:11:35.700 --> 00:11:39.030
but the NEOCORTEX is really the seat of intelligence and that's what they're

203
00:11:39.031 --> 00:11:43.560
trying to replicate here,
right?
So reptiles don't have one.
Only we mammals do.

204
00:11:43.760 --> 00:11:45.780
Um,
and uh,
it makes you,
you,

205
00:11:46.050 --> 00:11:50.190
so what the cortex does is the neo cortex learns a model from fast changing

206
00:11:50.191 --> 00:11:52.860
sensory data through our eyes,
nose,
mouth,
ears,

207
00:11:53.050 --> 00:11:56.410
and the model generates predictions,
anomalies and actions.

208
00:11:56.680 --> 00:11:59.830
And most of the sensory changes are due to your own movements,
right?

209
00:11:59.831 --> 00:12:03.370
So the neocortex loans a sensory motor model of the world,

210
00:12:03.371 --> 00:12:05.200
the motor part is from movement,
right?
So,

211
00:12:06.280 --> 00:12:09.760
and what we know is that the regions are linked together in a hierarchy.

212
00:12:09.910 --> 00:12:13.780
So ideas become more abstract and permanent up the chain as we go up that

213
00:12:13.781 --> 00:12:17.620
hierarchy.
So recall from deep learning,
neural nets do this as well,
right?

214
00:12:17.621 --> 00:12:20.200
They formed this hierarchy of features,
especially,
you know,

215
00:12:20.201 --> 00:12:24.280
when you think about image classification and classifying the canonical example,

216
00:12:24.310 --> 00:12:27.190
which is,
which are dogs and cats,
right?
You've got your,

217
00:12:27.640 --> 00:12:30.490
you've got your low level shapes and then higher level and high level,

218
00:12:30.491 --> 00:12:34.120
and then a face of a dog from an eye all the way up to a face and an hierarchy.

219
00:12:34.120 --> 00:12:35.170
And this is similar,
right?

220
00:12:35.320 --> 00:12:38.740
It's all very similar to how the NEOCORTEX works in terms of hierarchies.

221
00:12:39.070 --> 00:12:41.020
But there are some principles that they're following here.

222
00:12:41.021 --> 00:12:44.980
So that the one principle is that there is a common algorithm everywhere in the

223
00:12:44.981 --> 00:12:47.620
neocortex.
There's one algorithm to rule them all.

224
00:12:48.220 --> 00:12:52.300
They also operates on sequential memory and online learning,
right?

225
00:12:52.301 --> 00:12:56.110
So the input and output of the neo cortex or our sensory input and motor

226
00:12:56.111 --> 00:13:00.460
commands and what it acts as our sensory organs,

227
00:13:00.470 --> 00:13:01.740
axis encoders.

228
00:13:01.850 --> 00:13:05.260
So what they do is they turn these input values that this raw data that we're

229
00:13:05.261 --> 00:13:09.250
being fed in into what are called sparse distributed representations,

230
00:13:09.340 --> 00:13:12.460
some kind of encoding,
right?
Some kind of encoded representation.

231
00:13:12.880 --> 00:13:16.060
And so there are a lot of different types of encoders out.

232
00:13:16.061 --> 00:13:18.190
Their gps in a way is an encoder,

233
00:13:18.191 --> 00:13:21.900
but which doesn't have a biological counterpart.
It encodes all sorts of,

234
00:13:21.901 --> 00:13:22.090
you know,

235
00:13:22.090 --> 00:13:25.780
traffic data and map data and encodes it into something readable that we can

236
00:13:25.781 --> 00:13:27.190
look at.
But uh,

237
00:13:27.290 --> 00:13:31.090
so they have this idea of what's called a sparse distributed representation.

238
00:13:31.480 --> 00:13:35.140
And in this,
the idea is it's just a series of ones and Zeros.

239
00:13:35.141 --> 00:13:38.710
There are different ways of representing data.
Okay.
In deep learning.

240
00:13:39.050 --> 00:13:41.440
We use this a lot as well.
One hot encoding,

241
00:13:41.441 --> 00:13:44.140
there's all these different types of encoding models,

242
00:13:44.141 --> 00:13:47.530
but this is what they call them,
right?
So one example would be this,
right?

243
00:13:47.531 --> 00:13:51.430
So zero one one zero,
zero and so these ones and Zeros are what?

244
00:13:51.520 --> 00:13:52.570
What are encoded.

245
00:13:52.571 --> 00:13:57.571
And so neurons in in this system also use ones and Zeros to represent on and off

246
00:13:57.731 --> 00:14:01.840
states.
And this is the data structure of the brain,
right?
Sparse,

247
00:14:01.841 --> 00:14:05.590
distributed representations.
Everything is an SDR,
right?

248
00:14:05.620 --> 00:14:09.730
It's used for every aspect of cognitive function.
It's how memories are stored.

249
00:14:09.731 --> 00:14:12.370
It's how data is interpreted.
It's how data is encoded.

250
00:14:12.520 --> 00:14:16.930
It's all using this SDR and neurons received them from other neurons and from

251
00:14:16.931 --> 00:14:17.890
everywhere else,
right?

252
00:14:17.890 --> 00:14:21.400
So it's from all over the place and you're on their side and you're on the top

253
00:14:21.730 --> 00:14:26.680
and they can overlap.
I eat that.
You can form sets and unions combining SDRs.

254
00:14:26.920 --> 00:14:28.870
So let's say we have two different scrs,
right?

255
00:14:29.050 --> 00:14:32.160
Zero one zero and then other one is like zero one zero,
zero,

256
00:14:32.210 --> 00:14:35.230
just a different set of numbers.
How do we combine them?
Well,

257
00:14:35.231 --> 00:14:38.200
we can use some form of addition of multiplication.

258
00:14:38.270 --> 00:14:41.770
There are different types of ways that we can combine different Sdrs.

259
00:14:43.090 --> 00:14:47.920
And so the idea of using an encoder is to take that data,
numbers,
dates,

260
00:14:47.921 --> 00:14:50.590
temperatures,
gps coordinates,
what have you,

261
00:14:50.770 --> 00:14:53.960
and convert them into an encoded SDR,
right?

262
00:14:54.080 --> 00:14:57.470
So we have some raw data and encode it.
And now we have this SDR.

263
00:14:57.680 --> 00:15:01.670
And then the temporal memory is this algorithm that learns,
transitions,
uh,

264
00:15:01.671 --> 00:15:03.410
patterns from this Sdr.

265
00:15:03.740 --> 00:15:08.030
And it learns continuously as well as input data is changing in real time.

266
00:15:08.360 --> 00:15:10.430
The HTM model is updating itself,

267
00:15:10.610 --> 00:15:13.220
so it builds this predictive model of the world.

268
00:15:13.280 --> 00:15:14.990
So every time it receives an input,

269
00:15:15.110 --> 00:15:17.630
it attempts to predict what is going to happen next.

270
00:15:17.780 --> 00:15:21.260
So this is great for anomaly,
a anomaly detection for life.

271
00:15:21.270 --> 00:15:25.190
Say The stock market for realtime stocks.
It's good for musical data.

272
00:15:25.191 --> 00:15:29.060
It's good for,
you know,
you know,
traffic lights and predicting,
you know,
traffic,

273
00:15:29.230 --> 00:15:32.780
et cetera.
But anything that's real time.
Uh,

274
00:15:32.781 --> 00:15:35.330
but they've got a part of the new pick platform.

275
00:15:35.510 --> 00:15:40.510
They've got this very cool visual editor that lets you encode data and look at

276
00:15:41.091 --> 00:15:44.510
what the different types of encoding looks like a,
but basically you could say,

277
00:15:44.511 --> 00:15:47.180
okay,
I have this date.
How would I encode it?

278
00:15:47.360 --> 00:15:50.630
You could say the day of the week is going to be this set of squares,

279
00:15:50.870 --> 00:15:52.820
the weekend's gonna be this time of day season.

280
00:15:52.821 --> 00:15:55.040
And then combine that all and it looks like this.

281
00:15:55.250 --> 00:15:58.790
And then depending on what the date is,
these blue squares change,

282
00:15:58.791 --> 00:16:01.670
like where the squares are are highlighted,
highlighted.

283
00:16:01.820 --> 00:16:03.800
And this all comes out to a set of ones and Zeros.

284
00:16:05.700 --> 00:16:09.330
But there are certain principles to how,
uh,
this,
this should operate.

285
00:16:09.331 --> 00:16:13.590
The encoder is the outermost system of the HTM.
It's how data is,

286
00:16:13.740 --> 00:16:18.080
is encoded.
It's how it's structured before it's fed into this 10 poral,
um,

287
00:16:18.300 --> 00:16:23.280
memory algorithm.
So,
uh,
the similar data should be highly overlapping,
right?

288
00:16:23.281 --> 00:16:27.900
So same,
the same input should create the same output.
So it's deterministic data.

289
00:16:28.170 --> 00:16:32.190
The output should have the same dimensionality as the input and the output

290
00:16:32.191 --> 00:16:35.490
should have similar sparsity to the input.
Okay.
So

291
00:16:36.610 --> 00:16:39.400
once that data is encoded properly,

292
00:16:39.670 --> 00:16:42.190
then it's using this spatial pooling algorithm.

293
00:16:42.430 --> 00:16:44.770
So the idea is that for pooling in general,

294
00:16:44.771 --> 00:16:48.970
it's all about what parts of this input that I'm getting from this data are the

295
00:16:48.971 --> 00:16:52.440
most relevant.
And let me feed that forward.
Right?
So you know,
in,

296
00:16:52.441 --> 00:16:55.660
in terms of convolutional networks,
we have max pooling men pooling.

297
00:16:55.900 --> 00:16:58.600
They also use this idea of spatial pooling,
right?

298
00:16:58.601 --> 00:17:03.601
So what its purpose is is to normalize sparsity of encoded representations.

299
00:17:03.880 --> 00:17:07.030
So it accepts an input vector and it outputs an output vector.

300
00:17:07.480 --> 00:17:09.670
And it's important when talking about sequential memory,

301
00:17:09.790 --> 00:17:13.150
it's maintaining that fixed sparsity is the goal,
right?

302
00:17:13.151 --> 00:17:17.200
So the idea for Tim poor memory is that it learns sequences and it predicts

303
00:17:17.230 --> 00:17:21.770
outcomes.
So the idea behind the neuron itself.

304
00:17:21.771 --> 00:17:22.670
So in deep learning,

305
00:17:22.671 --> 00:17:25.730
the neuron either has an active state where it has an inactive state,

306
00:17:25.970 --> 00:17:28.910
but what they use as,
they call this,
the peer Middle Neuron,

307
00:17:28.911 --> 00:17:33.530
which has an active state on inactive state and a predictive state,
and they,

308
00:17:33.570 --> 00:17:34.480
they consider.

309
00:17:34.520 --> 00:17:38.780
So now we're getting into this territory that kind of resembles a Hinton's

310
00:17:38.870 --> 00:17:41.360
capsule network paper.
That was recently released.

311
00:17:41.780 --> 00:17:45.800
So the idea of neurons having layers and columns,
right?
So there,

312
00:17:46.070 --> 00:17:51.030
the idea is that in the neo cortex there are columns and layers and inside of

313
00:17:51.031 --> 00:17:55.290
these layers and columns are the neurons themselves.
So in short,

314
00:17:55.470 --> 00:17:59.940
Hinton's capital network paper said instead of having this two dimensional

315
00:17:59.970 --> 00:18:03.300
neural network,
right,
instead of having neurons in two dimensions,

316
00:18:03.480 --> 00:18:06.660
let's have them as three dimensions.
So it added a third dimension.

317
00:18:06.900 --> 00:18:09.450
And in a lot of ways to HCM is already doing that.

318
00:18:09.451 --> 00:18:13.110
They're adding three dimensions to this neural network architecture,

319
00:18:14.690 --> 00:18:18.200
right?
So the idea is that weak AI is not going to produce intelligence.

320
00:18:18.470 --> 00:18:20.780
We need to incorporate movement of some kind.

321
00:18:20.781 --> 00:18:24.620
I he interacting with an environment.
So I he reinforcement learning.

322
00:18:24.650 --> 00:18:26.600
And you see that a lot from,
you know,
the,

323
00:18:26.630 --> 00:18:29.660
the breakthroughs that are happening out of deep mind or open Ai.

324
00:18:29.870 --> 00:18:33.620
They're heavily using reinforcement learning and so better neurons,

325
00:18:33.650 --> 00:18:37.190
I like the peer.
Middle Neuron has have layers and they have columns.

326
00:18:37.250 --> 00:18:41.150
So there are three dimensional and it has both an active in an inactive state as

327
00:18:41.151 --> 00:18:45.230
well as a predictive state.
And Dana doesn't,
doesn't just flow feed forward.

328
00:18:45.320 --> 00:18:48.470
There's lateral inputs,
so from other neurons in,
in that layer.

329
00:18:48.620 --> 00:18:51.040
And then it's apical who so,

330
00:18:51.041 --> 00:18:54.350
so data is flowing down from the higher layers as well.

331
00:18:54.470 --> 00:18:59.020
So it's not just feed forward,
it's happening apical,
feedforward and then uh,

332
00:18:59.120 --> 00:18:59.953
laterally.

333
00:19:01.390 --> 00:19:05.020
So in terms of similarities to hidden Hinton's capsule network,

334
00:19:05.050 --> 00:19:08.140
both systems are defined by the relative locations of features.

335
00:19:08.350 --> 00:19:11.470
And there's a voting process that figures out the most consistent represent

336
00:19:11.500 --> 00:19:13.630
interpretation of sensory data.

337
00:19:13.960 --> 00:19:16.750
But the big difference is that HCM models movement,

338
00:19:16.960 --> 00:19:20.710
it explicitly models how information changes as we move our sensors,

339
00:19:21.070 --> 00:19:24.970
like our eyes around and how to integrate that information quickly to recognize

340
00:19:24.971 --> 00:19:25.804
objects.

341
00:19:25.870 --> 00:19:30.870
So there's also a great blog post by Numenta on how HTM and Hinton's capital

342
00:19:32.471 --> 00:19:35.020
network paper are similar.
I'll link to that in the description.

343
00:19:35.230 --> 00:19:38.740
Lots of awesome links are going to be in the description,
by the way.
Okay,

344
00:19:38.741 --> 00:19:41.290
so now I want to go into some of the code here.
So,

345
00:19:41.970 --> 00:19:42.400
<v 1>okay,</v>

346
00:19:42.400 --> 00:19:46.030
<v 0>here's their get hub repository.
It's a,
it's a really big project.</v>

347
00:19:46.210 --> 00:19:50.960
They've got 434 issues,
lots of,
uh,
great commits.
It's,

348
00:19:50.961 --> 00:19:54.130
it's been around for awhile.
This,
this a repository.

349
00:19:54.131 --> 00:19:57.130
They've been working on it for years.
So it's,
it's,
it's,
it's,

350
00:19:57.160 --> 00:19:58.330
it's pretty well developed,

351
00:19:58.540 --> 00:20:01.990
but in the end you can install it with the simple pip install,
like for Python,

352
00:20:02.050 --> 00:20:04.270
pip install,
new pick and,
and you're good to go.

353
00:20:04.540 --> 00:20:07.750
But what I want to do is I want to look at this example that kind of

354
00:20:07.870 --> 00:20:11.540
incorporates all of these concepts that I've been talking about together and

355
00:20:11.541 --> 00:20:14.680
they've got this great Pi Python Notebook here that I'm going to go into right

356
00:20:14.681 --> 00:20:15.514
now.

357
00:20:20.550 --> 00:20:21.383
Okay.

358
00:20:21.490 --> 00:20:22.323
<v 1>So,</v>

359
00:20:26.410 --> 00:20:30.300
<v 0>right.
So,
okay,
so we are,
we're going to go ahead and get started with the num py.</v>

360
00:20:30.301 --> 00:20:32.050
So let's,
let's take a look at what's happening here.

361
00:20:32.410 --> 00:20:36.850
So we're going to import their encoder library called scalar and Coder,
right?

362
00:20:36.851 --> 00:20:39.880
So we have some data like three,
four,
five equals right?

363
00:20:40.090 --> 00:20:44.950
And we want to encode deck and we can use this in co scalar and coder a class to

364
00:20:44.951 --> 00:20:49.660
do that until what happens is it encodes these numbers into their own unique

365
00:20:49.720 --> 00:20:51.910
representation.
These are SDRs.

366
00:20:51.911 --> 00:20:56.050
All of these are sparse distributed representations,

367
00:20:56.530 --> 00:20:57.363
right?

368
00:20:57.880 --> 00:21:00.610
We can do that for a hundred we can do that for a thousand whatever number we

369
00:21:00.611 --> 00:21:02.980
want.
And we can encode them different ways.

370
00:21:02.981 --> 00:21:06.610
There are different ways that we can create these representations in general.

371
00:21:06.730 --> 00:21:11.320
And there's a whole theory behind how we should best represent data,
but right,

372
00:21:11.321 --> 00:21:14.200
so there are different ways we can do it for numbers.
We could do it for,

373
00:21:14.830 --> 00:21:16.600
we can do it for words as well,
right?

374
00:21:16.601 --> 00:21:20.140
So for that we have the category encoder and then we have this spacial pooler.

375
00:21:20.141 --> 00:21:24.610
So for the spatial pooler we can initialize the spacial pooler,

376
00:21:24.820 --> 00:21:26.710
give it some parameters,

377
00:21:26.711 --> 00:21:30.760
like what are the dimensions of the input column dimensions,
potential radius,

378
00:21:30.910 --> 00:21:32.530
just like deep learning.
These are,

379
00:21:32.680 --> 00:21:35.970
these are hyper parameters that can be optimized right there.

380
00:21:36.130 --> 00:21:36.941
It's kind of like this,

381
00:21:36.941 --> 00:21:40.360
these magic numbers that researchers just kind of tweak and then different

382
00:21:40.420 --> 00:21:44.800
amazing results come out of that's,
it's just like that.
So we can say,
okay,

383
00:21:44.801 --> 00:21:46.570
so for all of this input data,

384
00:21:46.571 --> 00:21:50.050
we're going to feed it through this spatial pooler and it's going to output the

385
00:21:50.051 --> 00:21:52.840
most relevant features from that data.

386
00:21:55.540 --> 00:21:59.350
Right?
So now that you know,
once we have said this raw data,

387
00:21:59.560 --> 00:22:03.870
we've encoded into an SDR,
we fed it through pooling,
then we can apply the,

388
00:22:03.970 --> 00:22:06.850
the temporal memory,
a algorithm to it.

389
00:22:07.120 --> 00:22:12.010
So it takes the form of this backtracking t m a function right here,

390
00:22:12.130 --> 00:22:14.620
which is,
which is the optimization algorithm.

391
00:22:14.621 --> 00:22:16.870
We can call this the optimization algorithm right here.

392
00:22:17.110 --> 00:22:19.330
So we give it the number of columns,
you know,
the hyper parameters.

393
00:22:19.331 --> 00:22:23.020
We initialize it and then we say,
okay,
so we have our input data,

394
00:22:23.021 --> 00:22:25.450
it's going to be this set up one's and zero's.

395
00:22:25.660 --> 00:22:28.320
Each of these represents a different letter.
And then we're going to,

396
00:22:28.340 --> 00:22:31.240
this is really the learning step right here.
This is the,

397
00:22:31.420 --> 00:22:36.370
this is the training step,
so to speak.
So we can say for 10 iterations,
uh,

398
00:22:36.640 --> 00:22:39.430
we're going to say,
send each letter in the sequence in order.

399
00:22:39.640 --> 00:22:43.470
We'll use the compute function of the TM,
the,
the,
uh,

400
00:22:43.690 --> 00:22:47.800
temporal memory class to do that.
And then we'll reset it at the end.

401
00:22:48.040 --> 00:22:51.880
And then at the very end,
it's going to output how it's learning to predict the,

402
00:22:52.070 --> 00:22:55.630
it's,
it's learning to predict what state it's going to be in and the numbers are

403
00:22:55.631 --> 00:22:59.080
going to get closer to the input data,
that stream of input data over time,

404
00:22:59.081 --> 00:23:03.070
the learning process.
So it's,
it's very similar.
You might be thinking,
okay,

405
00:23:03.071 --> 00:23:07.400
so this training process looks very similar to um,

406
00:23:07.510 --> 00:23:12.280
backpropagation,
right?
So all of deep learning pretty much uses backpropagation,

407
00:23:12.550 --> 00:23:14.950
but they're not using backpropagation here.
Uh,
it's,

408
00:23:14.951 --> 00:23:17.710
it's more similar to what's called heavy and learning.
Uh,
it's,

409
00:23:17.711 --> 00:23:19.720
it's hidden inside of this compute function,

410
00:23:19.930 --> 00:23:22.660
but let's just go over heavy and learning as well.

411
00:23:23.740 --> 00:23:28.480
So basically a synaptic between two neurons is strengthened when the,

412
00:23:28.690 --> 00:23:30.610
when the neurons on either side of the synapse,

413
00:23:30.611 --> 00:23:35.110
but the input and the outputs have highly correlated outputs.
So in essence,

414
00:23:35.111 --> 00:23:37.330
when an input neuron input neuron fires,

415
00:23:37.480 --> 00:23:40.000
if frequently leads to the firing of the output neuron.

416
00:23:40.450 --> 00:23:45.120
So the synapsis strengthened.
So,
uh,
heavy and learning is used in,
um,

417
00:23:45.350 --> 00:23:47.360
what are called self organizing maps.

418
00:23:47.480 --> 00:23:52.290
So self organizing maps are a type of unsupervised learning technique that could

419
00:23:52.310 --> 00:23:55.310
come from neural networks that use heavy and learning like this.

420
00:23:55.700 --> 00:24:00.230
So it's kind of like whatever's closest in terms of like there's some measure of

421
00:24:00.231 --> 00:24:04.400
closeness,
right,
between input and output data.
And so if,
if,
if,

422
00:24:04.440 --> 00:24:09.440
if the next data point is similar to what has already been learned in the

423
00:24:10.011 --> 00:24:12.620
encoded representation,
then it's clothes,

424
00:24:12.730 --> 00:24:16.340
then go ahead and add some value there.
So it's kind of like this map,

425
00:24:16.370 --> 00:24:20.750
so you get hotter,
hotter,
hotter,
colder,
colder,
colder,
right?
And so then,
uh,

426
00:24:20.940 --> 00:24:24.080
it's like clustering in a way.
You can even think of it as clustering,
right?

427
00:24:24.080 --> 00:24:26.570
So heavy and learning helps do that.
It helps,

428
00:24:26.780 --> 00:24:31.010
it helps group similar data together.
So then when we have some new data points,

429
00:24:31.011 --> 00:24:34.610
it'll say,
oh,
it's,
it's close to this cluster prediction,
classification,

430
00:24:34.611 --> 00:24:38.430
whatever it is.
Here it is.
Right?
So it's kind of like that.
But,
um,

431
00:24:39.080 --> 00:24:44.000
in terms of a,
um,
an equation for heavy and learning,
we have this,
right?

432
00:24:44.120 --> 00:24:48.710
Where is it here and then that Dah,
Dah,
Dah.

433
00:24:49.240 --> 00:24:54.060
Well,
I just had it.
I was
okay.
It's like that.
So it's,

434
00:24:54.090 --> 00:24:57.950
it's,
it's still a matrix operation.
It's still map.
It's still just matrix,

435
00:24:57.951 --> 00:25:01.580
multiplication and addition.
There's,
there's nothing magically different here.

436
00:25:01.581 --> 00:25:04.520
There,
there are different types of wording or different terminologies,

437
00:25:04.640 --> 00:25:06.800
but the basic ideas are similar.

438
00:25:06.980 --> 00:25:10.010
It's just that they've architected it a bit differently from other types of

439
00:25:10.011 --> 00:25:12.110
neural networks.
But remember,
in essence,

440
00:25:12.111 --> 00:25:15.200
the HTM is very similar to a recurrent network.

441
00:25:15.290 --> 00:25:18.530
It uses heavy and learning and its uses online,

442
00:25:18.680 --> 00:25:23.030
continuous unsupervised data,
data streams.
So if you want to learn more about it,

443
00:25:23.031 --> 00:25:26.150
check out all the links in the description.
And I hope you enjoyed this video.

444
00:25:26.270 --> 00:25:28.280
Please subscribe for more programming videos.

445
00:25:28.281 --> 00:25:31.610
And for now I've got to go call Hinton.
So thanks for watching.

