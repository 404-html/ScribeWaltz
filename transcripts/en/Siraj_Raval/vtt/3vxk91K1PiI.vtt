WEBVTT

1
00:00:01.390 --> 00:00:02.223
Okay.

2
00:00:07.600 --> 00:00:08.433
<v 1>Hello.</v>

3
00:00:16.530 --> 00:00:17.363
<v 0>Okay.</v>

4
00:00:21.780 --> 00:00:26.430
<v 1>Hello.
Okay,
wait,
somebody's going to hear me right?</v>

5
00:00:29.340 --> 00:00:32.070
You can hear me?
I'm testing this.

6
00:00:32.400 --> 00:00:37.130
<v 0>Hello.
Okay,
wait,
I'm going to hear me like,</v>

7
00:00:37.690 --> 00:00:42.550
all right,
I'm testing this.

8
00:00:44.970 --> 00:00:48.760
<v 1>All right,
perfect.
So,
okay,
cool.
Here we are.</v>

9
00:00:49.030 --> 00:00:52.480
Hi everybody.
What's good?
What's good?

10
00:00:52.930 --> 00:00:55.990
Welcome to this.
We're about to code some stuff

11
00:00:57.850 --> 00:01:02.410
about to code some stuff.
All right.
Um,
there's like an echo,

12
00:01:02.411 --> 00:01:03.280
which is weird.

13
00:01:03.460 --> 00:01:07.600
So like I can hear myself after I've typed something,

14
00:01:07.601 --> 00:01:11.680
so I'm just gonna lie.
Mute my own voice.
There we go.
Okay.

15
00:01:12.970 --> 00:01:14.590
So yeah.
Okay,
here we go.

16
00:01:14.591 --> 00:01:19.591
We're going to code some game ais with open AI gym.

17
00:01:19.990 --> 00:01:24.070
Open Ai is the,
uh,
startup.
You know,

18
00:01:24.130 --> 00:01:28.210
Elon Musk a startup.
They want to decentralize everything.

19
00:01:28.211 --> 00:01:31.990
Decentralize Ai,
make sure that it's not in the hands of just Google.

20
00:01:32.020 --> 00:01:34.900
So I'm a big fan of that.
Uh,
so yeah,

21
00:01:34.901 --> 00:01:38.230
I want to start off with like a few minute Q and.
A.

22
00:01:38.410 --> 00:01:42.370
If anyone wants to ask me anything,
we could just get on that,

23
00:01:42.371 --> 00:01:45.760
you know what I mean?
So
what's up?

24
00:01:45.761 --> 00:01:47.710
Everybody ask away.

25
00:01:50.040 --> 00:01:52.980
I will wait just a little bit and then we'll get right into the code.

26
00:01:53.640 --> 00:01:55.950
I've never done this before,
so this is,

27
00:01:58.200 --> 00:02:00.600
do I think I'm a brogrammer?
I,

28
00:02:02.390 --> 00:02:06.350
I think sometimes that happens.

29
00:02:07.340 --> 00:02:11.060
I think from time to time I'm a programmer,
but I really try not to be like,

30
00:02:11.061 --> 00:02:15.140
I don't want to be a programmer,
but like I,
I,

31
00:02:15.270 --> 00:02:20.180
I think I can be sometimes.
How old am I?
I am 25 years old.

32
00:02:20.600 --> 00:02:22.130
I'm 25 years old.

33
00:02:23.390 --> 00:02:24.223
<v 0>Yes.</v>

34
00:02:24.970 --> 00:02:26.710
<v 1>What do I do for a living?</v>

35
00:02:26.950 --> 00:02:31.690
I do this youtube thing full time.
Uh,
I,

36
00:02:32.740 --> 00:02:35.540
that's,
that's my living.
I just through youtube full time,

37
00:02:35.710 --> 00:02:39.260
I'm not making that much right now.
I mean,
you know,
it's,
it's,

38
00:02:39.270 --> 00:02:43.990
it's getting better and better,
but right now it's like,
it's,
you know,

39
00:02:44.200 --> 00:02:46.630
it's,
it's still a climbing up in terms of the money I'm making.

40
00:02:47.020 --> 00:02:51.040
Ads are not good by the way,
like that,
that stuff is just not working out.

41
00:02:51.041 --> 00:02:53.060
So there are other methods,
uh,

42
00:02:53.080 --> 00:02:56.350
clients approaching me and stuff to make videos for them.
Uh,

43
00:02:56.650 --> 00:03:00.970
what ingredients do I usually put on hamburgers?
I usually put a,

44
00:03:01.510 --> 00:03:04.000
Oh my God,
these questions are really coming in.
Uh,

45
00:03:04.060 --> 00:03:07.870
what in Greece I put on hamburgers.
I put a onions.
That's right.

46
00:03:07.871 --> 00:03:08.970
I know a lot of people hate on you,

47
00:03:09.040 --> 00:03:11.650
but I loved them and I like everything is spicy.

48
00:03:11.770 --> 00:03:15.910
It's probably because I grew up eating spicy food because my parents are Indian

49
00:03:16.090 --> 00:03:19.630
and I was born in Texas,
so like double spice whammy there.

50
00:03:20.140 --> 00:03:23.260
What is your favorite machine learning library to use?
It is tensorflow.

51
00:03:23.470 --> 00:03:26.140
Are Your parents?
Are Your pants a compressed file?

52
00:03:26.141 --> 00:03:29.560
Because I'd love to unzip them.
Thank you.
They are compressed right now.

53
00:03:30.070 --> 00:03:33.610
Are you an AI researcher?
Not Officially.
What's your qualifications?

54
00:03:33.640 --> 00:03:36.130
I went to school at Columbia studying machine learning there.

55
00:03:36.370 --> 00:03:38.830
Worked in the robotics lab,
worked at Twilio,

56
00:03:38.870 --> 00:03:40.480
been a software engineer for two years,

57
00:03:40.630 --> 00:03:45.290
studying machine learning for two years on my own.
Are you going to school?
No.
Uh,

58
00:03:45.670 --> 00:03:49.330
no.
I'm not.
School is overrated.
Learn everything from the Internet.

59
00:03:49.900 --> 00:03:52.810
I know that's kind of like,
you know,
weird or whatever,

60
00:03:52.811 --> 00:03:56.680
but like learn everything from the Internet.
Traditional school is stupid.

61
00:03:57.040 --> 00:04:00.280
Where do you work?
I work on this youtube channel fulltime.
What's your education?

62
00:04:01.000 --> 00:04:05.620
My education is a college undergrad.

63
00:04:05.920 --> 00:04:10.180
Are we all just modifying scripts?
I guess.
So when did you start programming?
Uh,

64
00:04:10.330 --> 00:04:14.530
like freshman year of college I was,
uh,

65
00:04:15.400 --> 00:04:18.190
I was like studying finance and I was like,
okay,
Yo,

66
00:04:18.191 --> 00:04:21.100
I need to like make some money.
I want to,

67
00:04:21.190 --> 00:04:24.910
I want to do some great things in my life.
So I'm,

68
00:04:25.240 --> 00:04:30.240
so I took a semester off and I went to Europe for a Guy Kalscheur for three and

69
00:04:30.671 --> 00:04:31.091
a half months.

70
00:04:31.091 --> 00:04:36.091
I stayed with a guy named Alex McCall and he was awesome and he like inspired

71
00:04:36.671 --> 00:04:37.180
me.
He wrote,

72
00:04:37.180 --> 00:04:40.990
he wrote the book on Java script and he has a startup now and he traveled the

73
00:04:40.991 --> 00:04:41.824
world for a year.

74
00:04:41.830 --> 00:04:44.740
So I think just meeting somebody really inspirational and person just changed me

75
00:04:44.741 --> 00:04:46.870
and I was like,
okay,
I got to do computer science stuff.

76
00:04:47.050 --> 00:04:49.840
So it was freshman year of college.
Have you taken psychedelics substances?

77
00:04:49.841 --> 00:04:51.010
The answer is yes.
Uh,

78
00:04:51.250 --> 00:04:53.350
do it in a controlled environment with someone you care about.

79
00:04:53.530 --> 00:04:57.550
Would you present wavenet I have in a video check out generate music with

80
00:04:57.551 --> 00:04:58.384
tensorflow.

81
00:04:59.170 --> 00:05:00.003
<v 2>Uh,</v>

82
00:05:00.870 --> 00:05:03.300
<v 1>yes.
I'm going to do a video on Google's do research paper,</v>

83
00:05:03.301 --> 00:05:05.250
the machine machine translation once soon.

84
00:05:05.700 --> 00:05:08.410
A brain fuck machine learning program.

85
00:05:10.470 --> 00:05:15.390
That would be awesome.
Uh,
okay.
What's your favorite computer vision project?

86
00:05:15.580 --> 00:05:20.190
Uh,
probably um,
open CV still because like,
I mean,

87
00:05:20.220 --> 00:05:24.530
you're Europeans have like tried to make their own CV thing.
Sorry.

88
00:05:24.570 --> 00:05:27.630
W Americans are still better as software definitively.

89
00:05:27.900 --> 00:05:30.750
If you learn everything on then how do you prove that what you know when you

90
00:05:30.751 --> 00:05:32.190
apply for a job if you have no title?

91
00:05:32.860 --> 00:05:33.693
<v 2>MMM,</v>

92
00:05:34.590 --> 00:05:36.750
<v 1>that's a good question actually.
I mean with you Udacity,</v>

93
00:05:36.751 --> 00:05:38.760
there's like nano degrees,
so there's that,

94
00:05:38.820 --> 00:05:41.970
there's projects and then there's just like presenting yourself in person.

95
00:05:42.300 --> 00:05:47.160
So I think like your github repository,
they get hub repository,
get hub profiles.

96
00:05:47.161 --> 00:05:49.470
Are there new resume,
at least if you're in software,

97
00:05:51.990 --> 00:05:55.040
<v 2>I,
I want to do more than youtube,</v>

98
00:05:55.680 --> 00:05:58.910
<v 1>uh,
to inspire and equip developers.
I'm looking at other methods.</v>

99
00:05:58.911 --> 00:06:02.000
This is one way I'm experiments you right now.
When did you start learning ml?

100
00:06:02.030 --> 00:06:06.980
I would say I started learning ml two years ago is a master's degree worth it.

101
00:06:07.280 --> 00:06:12.110
I think that a masters degree is worth it for two reasons.

102
00:06:12.111 --> 00:06:17.111
You get the time to study and you don't have other obligations.

103
00:06:17.960 --> 00:06:18.680
If you can,

104
00:06:18.680 --> 00:06:22.880
if you can find the way to have the time to study without a master's degree,

105
00:06:23.240 --> 00:06:27.440
then I would go for that because the bureaucracies involved with graduate school

106
00:06:27.650 --> 00:06:31.400
are totally get in the way.
So really it's just about money and time.

107
00:06:31.401 --> 00:06:36.200
Like if you can find a way to study,
go for it.
That's what I did.
The best move

108
00:06:38.090 --> 00:06:42.290
I've come across for ml is probably that you Udacity,

109
00:06:42.291 --> 00:06:44.150
one by Google on deep learning.

110
00:06:44.360 --> 00:06:47.720
It's that one dude who works at Google and it's using tensorflow and it's like

111
00:06:47.721 --> 00:06:52.490
four modules and Andrew OnX course is great,
but it's totally overrated.

112
00:06:52.610 --> 00:06:54.680
In fact,
that's one of the reasons I started my channel because,

113
00:06:54.681 --> 00:06:58.910
because there's not enough application specific code,
it's all just like,

114
00:06:59.090 --> 00:07:02.900
here's this like huge,
uh,
algorithm in this huge equation.

115
00:07:02.901 --> 00:07:06.890
Like how do whatever you want with it.
And so my videos are more like,

116
00:07:07.100 --> 00:07:09.650
here's this huge algorithm,
but like,
here's what you can do with it.

117
00:07:10.010 --> 00:07:11.810
Favorite idol.
Um,

118
00:07:12.950 --> 00:07:17.950
my favorite idol is probably a Kanye West to pop shucker,

119
00:07:18.560 --> 00:07:22.700
uh,
and President Obama.
Um,

120
00:07:23.960 --> 00:07:28.850
who else?
Uh,
let's see.
I just like,
like revolutionaries.

121
00:07:28.851 --> 00:07:32.330
People who like just don't,
they don't,
they don't give a shit.
They just like,

122
00:07:32.360 --> 00:07:37.310
you know,
they have something to say and they want to say it really loud.
So,
yeah.

123
00:07:37.550 --> 00:07:38.620
And also,
uh,

124
00:07:38.690 --> 00:07:42.920
Ian Goodfellow at open AI because generative adversarial networks are awesome.

125
00:07:43.520 --> 00:07:45.440
Uh,
and just like,
uh,

126
00:07:45.530 --> 00:07:48.680
everybody who works at the mind because that stuff is awesome.

127
00:07:49.610 --> 00:07:52.610
Why Heran Bay died?
I don't know.
Kiana or tensorflow,

128
00:07:52.611 --> 00:07:54.920
tensorflow because it has more support for it.

129
00:07:55.100 --> 00:07:57.200
How easy it is to find a remote ml job.

130
00:07:57.470 --> 00:08:02.450
It's actually really easy compared to other types of jobs.
Uh,

131
00:08:02.480 --> 00:08:06.020
for someone new to ml,
would Khan academy cover the math you need?
Absolutely.

132
00:08:06.230 --> 00:08:09.200
I love Khan Academy and it Kinda counted me if you're watching this for some

133
00:08:09.201 --> 00:08:10.730
reason,
you know,

134
00:08:10.760 --> 00:08:15.080
contact me because I want to get on that Murphy's probabilistic tests or

135
00:08:15.081 --> 00:08:17.620
elements of statistical learning.
Uh,

136
00:08:17.630 --> 00:08:20.300
I would actually not recommend reading a textbook because for me,

137
00:08:20.301 --> 00:08:24.110
whenever I read a textbook I'm just like super bored.
I'm like,
oh my God,

138
00:08:24.111 --> 00:08:25.580
and by the end of the day it's like okay,

139
00:08:25.610 --> 00:08:30.110
I learned a lot but like really I just feel like I like what do I do with all

140
00:08:30.111 --> 00:08:33.800
this?
Like I prefer like short form articles,
long form articles,

141
00:08:33.890 --> 00:08:36.080
videos and implementing things.

142
00:08:36.260 --> 00:08:39.980
That's the best way to learn for me is just to implement.
So our,
our June,

143
00:08:39.981 --> 00:08:44.030
I would just like go to get hub search and machine learning and just like start

144
00:08:44.300 --> 00:08:48.140
like recoding those projects that you see another job to earn more money.

145
00:08:48.141 --> 00:08:51.800
I don't right now I do this full time.
Hopefully it works out R or python,

146
00:08:51.801 --> 00:08:56.801
100% python for NL and data analysis are is like python is just way more

147
00:08:57.361 --> 00:08:59.400
modular.
It has way more support.
I did,

148
00:08:59.401 --> 00:09:03.930
I saw that youtube 8 million that's saying today my plans for the future.

149
00:09:03.931 --> 00:09:05.580
I want to be the bill Nye of computer science.

150
00:09:05.581 --> 00:09:09.330
I want to be like the guy who like people look at and they're like,

151
00:09:09.570 --> 00:09:12.750
that guy inspired me.
I want to do machine learning.

152
00:09:12.751 --> 00:09:14.910
I just want to get everybody to do,
to do machine learning.

153
00:09:14.911 --> 00:09:18.570
I think it's the future.
I think that's what everything will be,
is to,

154
00:09:18.750 --> 00:09:21.780
is everything is going to like involve machine learning in some way.

155
00:09:22.170 --> 00:09:26.490
If you don't know python,
uh,
and you want to do,
see no dude,

156
00:09:26.700 --> 00:09:31.700
you should totally like python is better than c because c involves like,

157
00:09:32.370 --> 00:09:36.750
you know,
dealing with memory and like deadlocks.
If you're,
if you're new to,

158
00:09:37.020 --> 00:09:39.780
if you're new to programming,
you should definitely start off with python.

159
00:09:40.980 --> 00:09:41.813
<v 0>Uh,</v>

160
00:09:43.410 --> 00:09:45.280
<v 1>how did I learn coding?</v>

161
00:09:45.790 --> 00:09:48.700
I started to,

162
00:09:49.840 --> 00:09:50.673
<v 0>uh,</v>

163
00:09:51.230 --> 00:09:52.970
<v 1>what did I do?
Oh,
I had this idea.
Okay.</v>

164
00:09:53.000 --> 00:09:56.080
So I remember in college the way I learned coding was everybody went home for

165
00:09:56.090 --> 00:09:58.790
this,
for,
for winter break.
And I stayed in,

166
00:09:58.791 --> 00:10:00.470
so I was like two weeks and I was like,
what are you doing?

167
00:10:00.471 --> 00:10:04.280
And I stayed in for winter break and I had this idea for the iPhone app or you

168
00:10:04.281 --> 00:10:07.850
could just like wave your phone like a conductor's baton and it would change the

169
00:10:07.851 --> 00:10:12.620
tempo of the music in real time.
And so I was just like,
I kind of do this.

170
00:10:12.680 --> 00:10:13.850
So just based on the idea,

171
00:10:13.851 --> 00:10:18.680
I like force myself to learn ios and like it was super hard.

172
00:10:18.681 --> 00:10:21.710
But like by the end,
like when I finally started moving the phone and the,

173
00:10:21.920 --> 00:10:25.130
the tempo started changing.
I had to learn about fast fourier transforms.

174
00:10:25.131 --> 00:10:27.890
I had to learn about audio engineering by,
by the end of it,

175
00:10:27.920 --> 00:10:30.740
it actually works and the APP was kind of bad,
but like it worked.

176
00:10:30.920 --> 00:10:34.490
And so that success like kept me going and it kept it make,

177
00:10:34.550 --> 00:10:35.780
it made me want to do more and more.

178
00:10:36.410 --> 00:10:39.800
Thanks for saying you love my channel of no js is better for machine learning,

179
00:10:39.801 --> 00:10:44.450
I guess it is.
Uh,
yeah,
the Udacity course search deep learning.
You Udacity,

180
00:10:44.480 --> 00:10:49.430
Google.
It's going to be the first link.
My favorite ml podcasts would be,
uh,

181
00:10:51.010 --> 00:10:53.870
or blog would be,
um

182
00:10:58.850 --> 00:11:03.070
hmm.
I'm not sure.
I,
there's so many.
I just liked the machine learning sub.
Right.

183
00:11:03.110 --> 00:11:07.430
That's where most of my stuff comes from.
Uh,
build apps in real time.
Okay,
cool.

184
00:11:08.790 --> 00:11:12.810
Yeah,
sure.
See US faster for sure.
Um,
but,
uh,

185
00:11:14.220 --> 00:11:15.580
I guess,
um,

186
00:11:16.920 --> 00:11:20.640
with python you can wrap seashells and then call them in python so you don't

187
00:11:20.641 --> 00:11:23.340
actually have to write the sea.
So there see happening under the hood.

188
00:11:23.341 --> 00:11:25.950
But like python is great for like understanding things.

189
00:11:26.220 --> 00:11:29.970
The best tutorial for tensorflow are my videos so far.
Uh,

190
00:11:29.971 --> 00:11:34.060
and also Google's official ones on their website.
Uh,

191
00:11:34.061 --> 00:11:36.600
so what am I sources for learning about big machine learning?
This,

192
00:11:36.710 --> 00:11:39.200
the machine learning sub reddit.
The um,

193
00:11:40.330 --> 00:11:44.700
what else is there?
There's hacker news.
There's um,

194
00:11:44.770 --> 00:11:48.230
the futurology sub reddit.
There's um,

195
00:11:48.330 --> 00:11:53.290
I follow a few machine learning researchers on Twitter,
so like a board,

196
00:11:53.291 --> 00:11:57.500
Yann Macun,
uh,
which is not real,
but it's actually hilarious.
Uh,

197
00:11:57.940 --> 00:12:01.030
and there's one more Balaji Srinivasan on Twitter.

198
00:12:01.090 --> 00:12:05.470
All of the guys who work at Andreessen Horowitz are all like really on the ball

199
00:12:05.471 --> 00:12:08.170
when it comes to what's next.
I did do the Andrew on course.

200
00:12:08.290 --> 00:12:11.680
I didn't remember much of it.
So like I would just like,

201
00:12:11.710 --> 00:12:14.530
that's like part reason I started my channel.
Uh,

202
00:12:14.890 --> 00:12:19.840
cause I just thought it was boring.
Hi.
Uh,
do you ever yes,

203
00:12:19.841 --> 00:12:23.860
I'm worried about advanced AI and I think the best way to solve that is to make

204
00:12:23.861 --> 00:12:28.270
sure it's democratized and everybody has access to it.
And uh,

205
00:12:29.680 --> 00:12:33.430
I think that we should,
AI should augment ourselves.

206
00:12:33.431 --> 00:12:37.300
So we'll have like a neural lace in our brain or some kind of chip or something

207
00:12:37.390 --> 00:12:39.940
or even,
you know what,
the iPhone seven,
you just put it in your ear.

208
00:12:40.120 --> 00:12:41.440
You can start talking to Siri.

209
00:12:41.500 --> 00:12:43.750
So it is going to be less and less weird to talk to your phone.

210
00:12:44.080 --> 00:12:47.620
But I think AI can augment us and make us better rather than it being like a

211
00:12:47.621 --> 00:12:51.610
separate thing,
like a god that it just like controls us.

212
00:12:51.760 --> 00:12:55.860
It should make us gods.
So that's what I think will help us,
uh,

213
00:12:55.900 --> 00:12:58.150
not have an evil Ai.
Okay.

214
00:12:58.180 --> 00:13:01.090
We're going to start building the game bought in 30 seconds.
Here we go.

215
00:13:01.450 --> 00:13:03.890
I'm going to answer any last questions.
Favorite place in the world.

216
00:13:03.910 --> 00:13:08.800
Go hiking is a Yosemite.
How do I,

217
00:13:08.860 --> 00:13:13.690
do I keep myself fit?
Yes.
I go to the gym.
Yes,
I would collaborate with ml people.

218
00:13:14.020 --> 00:13:17.540
Game Theory and Ai.
That's a long question.
Uh,

219
00:13:17.590 --> 00:13:20.770
if you want to become an AI researcher,
start learning,
uh,

220
00:13:21.940 --> 00:13:25.900
just go to get and like,
uh,
go to the tensor flow,
uh,

221
00:13:25.930 --> 00:13:29.290
get hub repository to the model section and try to re implement all of those

222
00:13:29.291 --> 00:13:33.900
models.
Okay,
here we go.
We're going to start building this,
this Bot.
Uh,

223
00:13:33.970 --> 00:13:38.830
yes.
I like,
um,
drugs from time to time.
Okay,
here we go.

224
00:13:39.340 --> 00:13:42.790
We're going to start,
we're going to start building this thing.
Okay.

225
00:13:42.791 --> 00:13:46.300
So I'm going to start sharing my screen.
I just have to just get,
get on this.

226
00:13:46.510 --> 00:13:51.070
So the first thing I'm going to do is share my screen.

227
00:13:51.100 --> 00:13:54.730
Okay,
here we go.
Desktop.
All right.

228
00:13:54.820 --> 00:13:59.140
And here I am.
I'm going to show up here.
Okay,
here we go.

229
00:14:00.100 --> 00:14:02.650
All right,
so I'm going to go sublime and I'd say,

230
00:14:02.710 --> 00:14:06.790
and I'm going to say I'm going to make a directory and I'm going to say,

231
00:14:06.850 --> 00:14:10.060
let me just make sure that I'm,
I'm still on here.
Okay.

232
00:14:11.390 --> 00:14:11.830
<v 0>Okay,</v>

233
00:14:11.830 --> 00:14:15.610
<v 1>here we go.
We got a minimum.
I'm going to minimize this so I don't have to.
Okay.</v>

234
00:14:15.611 --> 00:14:19.950
There we go.
All right.
And this is going to be minimized.

235
00:14:20.670 --> 00:14:22.290
Make sure it's all good.

236
00:14:23.070 --> 00:14:28.070
I'll put this up here and we're going to get started in a second.

237
00:14:28.861 --> 00:14:32.490
It's Laggy,
right?
It's laggy,
but you guys can still hear me right?

238
00:14:32.520 --> 00:14:37.290
Like even though it's laggy.
Okay,
so here we go.

239
00:14:37.380 --> 00:14:39.690
I'm going to say make directory.
I'm going to make a new directory.

240
00:14:39.691 --> 00:14:43.370
So I'm going to start this,
this spot.
I'm going to say make directory,
uh,

241
00:14:43.400 --> 00:14:46.980
test one,
test two,
test one that already,

242
00:14:46.981 --> 00:14:51.590
just make your artistry cats too.
Okay,
so TD tube.

243
00:14:51.620 --> 00:14:54.530
Now I'm in my text to directory,
right?
Okay,
here we go.

244
00:14:54.920 --> 00:14:59.120
The first thing I want to do,
um,
okay.
Make sure it's all good.

245
00:14:59.140 --> 00:15:03.500
There's so many windows open right now.
Holy shoot.
Audio is not laggy at least.

246
00:15:03.501 --> 00:15:07.700
Okay,
cool.
Green Cli is for real hackers.
Well,

247
00:15:07.730 --> 00:15:11.630
I like whatever I like.
Okay,
so here we go.

248
00:15:11.690 --> 00:15:16.310
So first thing want to do is clone a gym.
So the gym repository is the,

249
00:15:16.640 --> 00:15:21.020
the,
the uh,
reinforcement learning library creative by open Ai.

250
00:15:21.230 --> 00:15:24.710
We're going to quote it into this.
Oh,
increase the font size.
Good call.
Thank you.

251
00:15:24.711 --> 00:15:27.410
Thank you.
How do we going to do this?
Boom,
boom,
boom,
boom,
boom,
boom,
boom,
boom,

252
00:15:27.411 --> 00:15:31.570
boom.
Right?
How's that?
Okay.

253
00:15:31.600 --> 00:15:35.530
We increase the font size.
I'm in the corner over here.
Boom.

254
00:15:36.130 --> 00:15:40.630
Make sure it's all good.
Okay,
so now that Jim is in here,

255
00:15:40.631 --> 00:15:44.230
we're going to CD at the gym.
The gym is like a training for AI.

256
00:15:44.231 --> 00:15:47.800
It makes it better and better over time.
And we want to install everything.

257
00:15:47.801 --> 00:15:51.580
So we're going to use PIP r python module to install literally everything.

258
00:15:52.810 --> 00:15:57.310
Okay?
So it's literally gonna install all of our dependencies for python,
for Jim.

259
00:15:57.610 --> 00:16:01.420
And that's it.
That's all.
So one one just has done,
we're ready to go.
Okay.

260
00:16:01.630 --> 00:16:06.220
So now that we've installed a gym,
we're going to run our first environment.

261
00:16:06.221 --> 00:16:10.630
Okay.
So let's,
I'm going to use sublime.
Sublime is my text editor of choice.

262
00:16:10.960 --> 00:16:15.250
And I'm going to say test,
run dot pie.
So it's got an open that up and sublime.

263
00:16:15.280 --> 00:16:19.330
So I'm going to bring that down here.
Okay.
And

264
00:16:21.170 --> 00:16:22.040
<v 4>here we go.</v>

265
00:16:24.820 --> 00:16:28.060
<v 1>Here we go.
Here we go.
So the first thing we'll do is I'm going to import gym.</v>

266
00:16:28.120 --> 00:16:32.530
Okay.
That's,
that's the environment.
And then I'm going to create an environment.

267
00:16:32.830 --> 00:16:35.890
Okay.
So it's going to be Jim.
Um,

268
00:16:37.510 --> 00:16:42.080
Jim.
Yeah,
this is going to be on the channel at the end of the transmission.
Uh,

269
00:16:42.100 --> 00:16:46.300
you're going to be able to view it afterwards.
So yeah.
Anyways,
so,
so,

270
00:16:46.720 --> 00:16:49.210
so this,
so the first step is to initialize the environment.

271
00:16:49.211 --> 00:16:53.560
What are we going to train the agent in a,
okay,
so bright.

272
00:16:53.590 --> 00:16:56.590
So it's Kinda,
it's Kinda not HD right now guys.
I'm sorry about this,

273
00:16:56.591 --> 00:17:00.040
my first live stream,
but uh,
it's going to be better next time.

274
00:17:00.070 --> 00:17:02.740
If I do this next time,
I probably will.
Cause this is kind of fun.

275
00:17:03.520 --> 00:17:06.370
Our increased font size.
Good call.
Good call.
Good call.
Thank you.
Thank you.

276
00:17:06.371 --> 00:17:10.960
Thank you.
Here we go.
I'm going to increase the font size.
Let's see.

277
00:17:13.540 --> 00:17:17.200
Ooh,
boom,
boom,
boom,
boom,
boom.
Okay,
that's huge.
All right,

278
00:17:17.201 --> 00:17:20.410
so we're going to initialize our environment.
It's going to be card pole.

279
00:17:20.500 --> 00:17:23.710
So the car pull environment is jets like a stick,
right?

280
00:17:23.711 --> 00:17:27.550
So the carpal game is like a stick and it's just trying to balance as as a box

281
00:17:27.551 --> 00:17:28.384
move.

282
00:17:28.940 --> 00:17:29.700
<v 4>Okay.</v>

283
00:17:29.700 --> 00:17:34.230
<v 1>Okay.
I don't use an ide because I don't have time for that.
It's just bloated.</v>

284
00:17:34.231 --> 00:17:37.470
I just want a simple,
you know,
python just super fast.
You run a script,
that's it.

285
00:17:37.471 --> 00:17:40.050
Okay,
so here we go.
So we got card pole,
right?

286
00:17:40.140 --> 00:17:42.810
And we're going to reset the environment,
which means like it just makes like,

287
00:17:42.960 --> 00:17:45.520
let's get started.
Just to me it's like initialize,

288
00:17:45.530 --> 00:17:47.280
like the environment is ready to go.

289
00:17:47.550 --> 00:17:50.790
So we're going to run this for a thousand steps.
Okay.

290
00:17:50.791 --> 00:17:52.950
So we're going to say what salads and time steps.

291
00:17:53.100 --> 00:17:56.790
And for each time step we want to render the environment.
So we're going to say,

292
00:17:56.820 --> 00:18:00.900
okay,
so then we're going to be able to view it.
Okay.
So we're going to say,

293
00:18:00.990 --> 00:18:05.520
take a step and step means,
uh,
we're going to take a random step.

294
00:18:05.670 --> 00:18:08.340
So that'd be the agent.
In our case,
it's going to be the carp.

295
00:18:08.341 --> 00:18:12.480
Coal is going to move in a random direction every time.
And so the,
uh,

296
00:18:14.160 --> 00:18:18.300
so the method of doing this is action space sample.

297
00:18:18.480 --> 00:18:23.300
So that's the method that says pick a random action.
Okay.
Okay.

298
00:18:23.310 --> 00:18:26.310
So let's just see how that,
how that works.
We're going to run that just,

299
00:18:26.311 --> 00:18:30.750
that's great.
That's it.
So we're going to say python tests,
run dot.
Py.
Boom.

300
00:18:31.110 --> 00:18:35.450
What happens of python tests run stuff.

301
00:18:35.470 --> 00:18:39.480
Pie and valid syntax.
What the hell?
Okay,
here we go.
Oh,
you're right.
Yeah,

302
00:18:39.481 --> 00:18:44.280
that thing.
Cool.
Let's run this little module name requests.
Oh my God.

303
00:18:44.310 --> 00:18:46.860
Here we go.
Uh,
okay.

304
00:18:47.250 --> 00:18:51.390
So we're going to make sure we have virtual environment.

305
00:18:51.420 --> 00:18:53.460
We'll create a virtual environment,
right?

306
00:18:55.290 --> 00:18:56.123
<v 5>Uh,</v>

307
00:18:56.630 --> 00:18:59.370
<v 1>all right.
Thanks guys.
Okay,
so we have a virtual environment.</v>

308
00:18:59.460 --> 00:19:01.740
We're going to source our virtual environment,

309
00:19:02.010 --> 00:19:06.840
which means that we can see what's going down here.

310
00:19:07.380 --> 00:19:09.990
Okay.
And we're going to say pip install requests.

311
00:19:12.100 --> 00:19:16.510
Okay.
And so then we're going to run it again.
Oh and non pot.
So,
oh,

312
00:19:16.540 --> 00:19:20.390
I gotta re-install like that.
Blah,
boom,
boom,
boom.

313
00:19:21.110 --> 00:19:25.780
Let me go to reinstall Jim.
One more time.
I forgot.
You have to,
you have to uh,

314
00:19:26.740 --> 00:19:30.330
Redo your environment.
Okay.
Uh,
virtue.

315
00:19:30.331 --> 00:19:33.910
You have to create a virtual environment so that your dependencies aren't all

316
00:19:33.911 --> 00:19:34.744
over the place.

317
00:19:34.840 --> 00:19:39.340
I always create a virtual environment for every repository that I'd mic.

318
00:19:40.640 --> 00:19:41.390
<v 5>Okay.</v>

319
00:19:41.390 --> 00:19:44.450
<v 1>Okay.
So once this is done,
we're going to run this code.
This is the code.</v>

320
00:19:44.451 --> 00:19:45.284
One more time.

321
00:19:45.380 --> 00:19:49.310
We create the environment a thousand times steps render at every time step and

322
00:19:49.311 --> 00:19:53.900
then take a random step.
That's all it does.
Hey,
thanks for coming to the party,

323
00:19:53.901 --> 00:19:58.400
Anthony.
It's all good.
Here we go.
Test run.
Let's see it.
Boom.

324
00:19:58.460 --> 00:20:00.830
Okay.
That's it.
That's all I did.

325
00:20:00.831 --> 00:20:04.010
It just ran for a thousand times steps and then doing it.
Didn't learn anything.

326
00:20:04.250 --> 00:20:06.710
Now we're going to add a little bit of logic to this.
Okay.

327
00:20:06.800 --> 00:20:11.360
So the great thing about Jim is it is a reinforcement learning library.

328
00:20:11.540 --> 00:20:16.430
Okay?
It's,
it's all about learning with through trial and error.

329
00:20:16.580 --> 00:20:21.450
The agent is going to get better and better over time.
Uh,
okay.
Uh,

330
00:20:21.490 --> 00:20:26.290
our June a virtual environment is kind of like,
uh,
it's,
it's,

331
00:20:27.110 --> 00:20:31.550
it's,
it's like creating a container where you say,
okay,

332
00:20:31.670 --> 00:20:34.580
I don't want to have to deal with anything else on the,
on my operating system.

333
00:20:34.580 --> 00:20:38.180
I don't want to have to mess with any other dependencies.

334
00:20:38.210 --> 00:20:42.050
I just want to be in dislike,
empty box.
And in this empty box,

335
00:20:42.051 --> 00:20:44.360
I'm going to reinstall all of my,
uh,

336
00:20:47.440 --> 00:20:49.240
Oh man,
these,
these comments are hilarious.

337
00:20:49.300 --> 00:20:52.390
I'm just going to install all the dependencies that I need for this specific

338
00:20:52.391 --> 00:20:57.130
repository.
I do it every time I have a new repository.

339
00:20:57.160 --> 00:20:59.350
Okay.
So let's,
so let's make this thing smarter.

340
00:20:59.351 --> 00:21:02.530
Let's add some actual machine learning in here.
Okay.
So we're gonna keep,

341
00:21:02.590 --> 00:21:07.090
we're gonna keep this car pull environment.
Okay?
And I'm going to,

342
00:21:07.210 --> 00:21:09.040
I'm going to say for a number of episodes,

343
00:21:11.450 --> 00:21:14.780
I'm going to say for a number of episodes,
let's say I episode,

344
00:21:16.100 --> 00:21:19.460
each episode is like,
if you know your cart falls over.

345
00:21:19.490 --> 00:21:22.700
So I'm going to say for a number of episodes in the range of 20 to two for 20

346
00:21:22.701 --> 00:21:27.050
episodes.
So for 20 episodes,
I'm going to get my,

347
00:21:27.051 --> 00:21:28.760
an observation from my environment.

348
00:21:28.780 --> 00:21:32.930
And observation is different depending on whatever your environment is.

349
00:21:33.080 --> 00:21:36.170
Jim has like a thousand environments.
You could have pac man,

350
00:21:36.290 --> 00:21:40.070
you can have a bunch of Atari Games,
you could have even three d games do.

351
00:21:40.340 --> 00:21:42.770
So we're just using Karch poll because that's simple for right now.

352
00:21:43.040 --> 00:21:46.430
So I'm going to say,
okay,
so for this observation we're going to reset,

353
00:21:46.640 --> 00:21:49.400
which means like just get that first observation,
okay?

354
00:21:49.700 --> 00:21:54.570
And then we're going to say I want to a hundred times steps for every,
um,

355
00:21:55.520 --> 00:22:00.260
when a hundred times steps for every uh,
episode.
Okay?

356
00:22:00.950 --> 00:22:05.270
So we're going to render this environment at every time step and we're going to

357
00:22:05.271 --> 00:22:09.440
print out whatever we're observing.
In our case,
in the case of the card pole,

358
00:22:09.590 --> 00:22:13.580
it's going to be the,
an array of velocities of where the car pool is moving.

359
00:22:13.790 --> 00:22:15.680
We haven't done any machine learning yet,

360
00:22:15.860 --> 00:22:19.400
I'm just rendering this thing as it moves.
Okay?
But we're about to,

361
00:22:19.910 --> 00:22:23.600
this is the machine learning part.
Okay.
I'm going to take an action.
Okay.

362
00:22:23.840 --> 00:22:27.710
And this action is going to be a random,
it's,
it's going to be a random action

363
00:22:29.810 --> 00:22:33.740
and
or range.

364
00:22:33.741 --> 00:22:37.810
100 okay.
T and range 100 yes.

365
00:22:38.090 --> 00:22:42.920
Oh yes.
Thank you.
As he,
as he,
Yup.
Yup,
Yup.

366
00:22:43.220 --> 00:22:47.510
Good call.
All right,
cool.
I'm not running on a GPU.

367
00:22:47.511 --> 00:22:51.140
I'm running on a CPU on a Mac book.
Okay,
so here we go.

368
00:22:51.230 --> 00:22:52.790
So for that action,

369
00:22:52.820 --> 00:22:56.780
we want to take a step and a step is going to complete the ancient environment.

370
00:22:56.781 --> 00:22:59.450
Luke.
Okay.
I'm going to explain that in a second,

371
00:22:59.570 --> 00:23:01.610
but we're going to get back an observation.

372
00:23:02.180 --> 00:23:07.180
So we're going to get back an observation or reward done info and we'll take a

373
00:23:09.591 --> 00:23:10.190
step.

374
00:23:10.190 --> 00:23:15.190
So what's happening here is a step function completes an action and it returned

375
00:23:16.011 --> 00:23:20.700
back four variables.
The observation is what it sees.
The reward is a,

376
00:23:20.720 --> 00:23:24.460
it's different depending on whatever environment you're in.
In our case,
it's at,

377
00:23:24.470 --> 00:23:27.350
the pole is still standing up.
So it's going to be a set of philosophies.

378
00:23:27.650 --> 00:23:30.890
Done is just a boolean.
Like did,
did we die or not?

379
00:23:30.891 --> 00:23:33.650
An Info is a bunch of diagnostics.
That's it.

380
00:23:33.651 --> 00:23:37.580
That one line is the reinforcement learning that's happening here.
Okay.

381
00:23:37.581 --> 00:23:40.700
So we're going to say like,
okay,
so if we're done,

382
00:23:40.820 --> 00:23:44.780
if we're done then just printout.
Okay.
Episode.
It's finished.

383
00:23:46.220 --> 00:23:49.790
Windows is not life.
Uh,

384
00:23:50.780 --> 00:23:54.410
windows is bad.
The sorry window sucks.

385
00:23:54.680 --> 00:23:59.060
After time steps,
uh,
after whatever number of times,

386
00:23:59.061 --> 00:24:02.810
that's okay now and then we're going to say break.

387
00:24:03.540 --> 00:24:06.680
We're going to say break.
Okay,
so let's run that.
Okay.

388
00:24:06.830 --> 00:24:08.090
This is the actual machine learning.

389
00:24:08.110 --> 00:24:11.120
It's important learning c agent environment loop.

390
00:24:13.230 --> 00:24:15.840
All right,
so let's run this baby.
Boom.

391
00:24:16.580 --> 00:24:17.190
<v 0>Yeah.</v>

392
00:24:17.190 --> 00:24:20.310
<v 1>So what does printing are the velocities like as it's moving,</v>

393
00:24:20.340 --> 00:24:24.630
it's learning to get better every time.
Okay.

394
00:24:24.690 --> 00:24:29.690
And so the episode is finished so that that trains our agent and we can save

395
00:24:29.851 --> 00:24:34.200
those weights over time.
Um,
oh,
let's see.

396
00:24:34.201 --> 00:24:38.900
Let me answer what I miss.
The old hello world.
Hello world.
It's Suraj.

397
00:24:39.750 --> 00:24:43.830
There you go.
There is,
there it is.
Okay.
What does step actually do?

398
00:24:44.040 --> 00:24:44.940
Step completes.

399
00:24:44.941 --> 00:24:49.230
An action step is a function that takes an action and actually implements it in

400
00:24:49.231 --> 00:24:53.010
the,
in the rendered environment.
Uh,
make a bit for synthetic gradients.

401
00:24:53.011 --> 00:24:55.230
Paper that Yo,
I really want to make one.

402
00:24:55.260 --> 00:24:58.290
I had been waiting to make one on that paper.
That paper is so dope.

403
00:24:58.500 --> 00:25:00.360
I want to read that paper.
I was like,
oh my God.

404
00:25:00.361 --> 00:25:03.660
Back propagation is not a thing anymore.
This is amazing.
So yes,

405
00:25:03.780 --> 00:25:07.680
I will make one on that.
[inaudible] to his life a true word.
Word.

406
00:25:08.100 --> 00:25:12.000
Is there a way to run tensorflow and open AI on windows?
Great question.

407
00:25:12.570 --> 00:25:15.690
I know there's a way to run flow.
I'm not sure about open Ai.
Okay.

408
00:25:16.500 --> 00:25:20.480
So that was the,
that was a simple problem.
Now I'm going to,
uh,

409
00:25:21.420 --> 00:25:26.270
let's see.
I want to do something a little more complicated.
So,
uh,

410
00:25:26.310 --> 00:25:28.650
I'm going to say we're going to,

411
00:25:31.200 --> 00:25:36.120
we're going to,
uh,
do something a little more complex.

412
00:25:36.270 --> 00:25:39.030
So we're going to do the same thing in the car pool environment,

413
00:25:39.060 --> 00:25:42.320
but we're going to,
uh,

414
00:25:42.620 --> 00:25:46.760
use something called hill climbing as a policy.
Okay?
So help climbing.

415
00:25:48.830 --> 00:25:50.590
Oh,
climbing means we're going to,

416
00:25:50.910 --> 00:25:54.570
and not just to not just try a bunch of random steps,

417
00:25:54.870 --> 00:25:59.340
but update our weights by,
uh,
making sure that,

418
00:25:59.910 --> 00:26:03.810
Hi Nico.
Uh,
yeah.

419
00:26:05.040 --> 00:26:07.920
All right.
You guys are getting obsessed with we'd now like,
all right.
Just chill.

420
00:26:08.280 --> 00:26:11.720
You know what I'm saying?
Okay.
Here we go.
We're,
we're,
we're,
we're,

421
00:26:11.750 --> 00:26:15.000
we're focused right now,
right.
Okay.
Here we go.
We got to be focused.
Let's,

422
00:26:15.001 --> 00:26:18.360
let's focus here.
All right.
So he'll,
climbing is a technique where we say,
ah,

423
00:26:18.510 --> 00:26:20.160
initialize weights randomly

424
00:26:21.840 --> 00:26:25.560
and we're going to initialize waste randomly and then,
and then if,

425
00:26:25.620 --> 00:26:28.740
if the weights are are good,
if the reward is like a good thing,

426
00:26:28.890 --> 00:26:30.990
then we want to save those weights.
So we,

427
00:26:31.080 --> 00:26:35.220
so we incorporate memory into this as well.
It's not just randomly trying things.

428
00:26:35.460 --> 00:26:38.460
We use our memory just like our,
you know,
our brains use memory as well.

429
00:26:38.580 --> 00:26:43.400
So utilize memory to save.
Oh wait,

430
00:26:43.401 --> 00:26:48.270
it weights.
Yeah.
Focused.
Exactly.
Essentially.
Oh,
the Arduino.
Yes,

431
00:26:48.271 --> 00:26:51.060
there is the Japanese to come.
Or farmer did,
did something like that.

432
00:26:51.061 --> 00:26:53.550
If you go to get hub and type in tensorflow,
Arduino,

433
00:26:53.700 --> 00:26:58.590
I promise you 100% you will find at least three repositories.
Okay,
so here we go.

434
00:26:59.580 --> 00:27:02.520
So,
um,
right.
So,

435
00:27:02.550 --> 00:27:05.010
oh also I'm want to import num py cause I'm about to do some,

436
00:27:05.011 --> 00:27:07.410
some math magic in here.
Okay,
here we go.

437
00:27:08.230 --> 00:27:12.090
Why don't just be stuck at on local maximums?
No.
Okay.
So,

438
00:27:12.210 --> 00:27:15.150
so first thing I'm going to do cause define a run episode.
Okay.

439
00:27:15.151 --> 00:27:18.270
I'm going to say the two parameters for that are going to be the environment and

440
00:27:18.271 --> 00:27:21.750
a parameter.
It's a parameters are going to be the weights.
Okay.

441
00:27:22.440 --> 00:27:23.273
<v 2>MMM.</v>

442
00:27:26.480 --> 00:27:29.090
<v 1>So this,
hold on a second.
Okay.</v>

443
00:27:29.091 --> 00:27:32.570
So this isn't,
this is going to be art,

444
00:27:32.630 --> 00:27:34.700
our implementation of the Asian environment loop.

445
00:27:34.730 --> 00:27:38.390
It's going to take our agent from start to finish and it's going to result in

446
00:27:38.391 --> 00:27:40.940
some reward value depending on whatever action.

447
00:27:41.210 --> 00:27:44.810
And we're going to initialize it after we've initialize our environment.
Okay.

448
00:27:44.990 --> 00:27:47.990
So this is a function that we're going to initialize after we initialize our

449
00:27:47.991 --> 00:27:50.480
environment.
Okay.
So

450
00:27:50.950 --> 00:27:51.783
<v 2>mmm.</v>

451
00:27:52.330 --> 00:27:54.790
<v 1>Well the stream be available to watch tomorrow.
Yes,
it will be.</v>

452
00:27:54.940 --> 00:27:57.970
And I'm going to end it in like 10 minutes.
Okay.

453
00:27:57.971 --> 00:28:02.971
So that's cause that cause I've got some technical writing to do and I've got

454
00:28:03.100 --> 00:28:07.210
other stuff to do for the channel.
Okay.
Here we go.
So first off,

455
00:28:07.211 --> 00:28:10.840
first things first.
Okay.
We're going to get,
okay.
First things first.

456
00:28:10.930 --> 00:28:13.990
We're going to get our observation like we always do.
All right.

457
00:28:13.991 --> 00:28:15.790
That's the first thing we do in an episode.

458
00:28:16.030 --> 00:28:20.200
And then we're going to get to make this total reward variable.
Yeah.

459
00:28:20.290 --> 00:28:23.540
Contested on Mario.
I'll will remember that for next time.
Uh,

460
00:28:23.590 --> 00:28:25.510
so for 200 times steps.

461
00:28:26.870 --> 00:28:27.703
<v 2>Okay,</v>

462
00:28:27.890 --> 00:28:28.910
<v 1>we're going to do this.
Okay.</v>

463
00:28:29.030 --> 00:28:32.900
So for in the range of 200,

464
00:28:36.500 --> 00:28:40.760
we're going to render our,
you can test it on literally any game.

465
00:28:40.870 --> 00:28:45.680
Ameya yes,
yes.
I'm going to upload the sample code,
Carlos.
Absolutely.
Absolutely.

466
00:28:45.890 --> 00:28:50.350
I'm going to put it into the description for this video.
Okay.
So we're gonna say,

467
00:28:50.360 --> 00:28:54.440
okay,
go ahead and render and render our environment like we always do.
Okay.

468
00:28:54.470 --> 00:28:58.340
So now we're going to initialize random weight sectors.
Okay.

469
00:28:59.810 --> 00:29:03.910
So I'm going to say,
so I'm going to say,

470
00:29:04.310 --> 00:29:07.240
um,
take an action.
Okay.

471
00:29:07.840 --> 00:29:10.090
And if it's zero.

472
00:29:10.420 --> 00:29:14.500
So actually I'm just going like type this out cause like it's hard to do like a

473
00:29:14.501 --> 00:29:15.281
million things at once.
Her.

474
00:29:15.281 --> 00:29:19.210
Now let me just type this out and I'm going to then explain it in a second.

475
00:29:19.750 --> 00:29:23.560
Okay.
It's less than zero out swat.
Okay.

476
00:29:23.620 --> 00:29:27.280
So what's happening here is I'm initializing random weight factors as parameters

477
00:29:27.520 --> 00:29:30.550
and multiplying by risk,
their respective observation.

478
00:29:30.790 --> 00:29:35.020
And I'm going to use matrix multiplication to some of the products and if the

479
00:29:35.021 --> 00:29:38.350
total is less than zero,
then we move left El swing move.
Right?

480
00:29:38.530 --> 00:29:43.150
So what this is doing is it's randomly initializing wait vectors to move the

481
00:29:43.151 --> 00:29:47.770
pole left or right.
Okay.
That's all it's doing left or right.
Okay.

482
00:29:47.800 --> 00:29:50.770
Let me see what the comments up here are.
Um,

483
00:29:54.280 --> 00:29:55.113
<v 2>okay.</v>

484
00:29:55.730 --> 00:30:00.380
<v 1>Let's see.
What's the difference between range and x range?
Uh,</v>

485
00:30:00.590 --> 00:30:03.170
so in so rank returns a list,

486
00:30:03.171 --> 00:30:05.960
an x range returns an x ray and objects.

487
00:30:05.961 --> 00:30:10.360
We'll just kind of like an iterator and generates numbers on demand.
Um,

488
00:30:11.960 --> 00:30:13.340
I think like I,

489
00:30:15.680 --> 00:30:19.450
it's weird because in python three range does what x range used to do.

490
00:30:19.630 --> 00:30:21.220
An x range doesn't exist.

491
00:30:21.340 --> 00:30:25.180
So if you want to write code that will run on both python two and python three,

492
00:30:25.470 --> 00:30:29.320
uh,
you shouldn't use x range.
So I'm just being weird.

493
00:30:29.321 --> 00:30:33.430
So like don't just like use range like yeah,
exactly.

494
00:30:33.431 --> 00:30:36.730
Mighty magic though.
Yeah,
exactly.
So,
um,

495
00:30:37.990 --> 00:30:42.160
can you upload where you've,
Reebok has this video later?
Yes.
Okay.

496
00:30:42.520 --> 00:30:47.440
Um,
let me see.
Am I still okay?
Cool.
Everybody's in here.
Everybody's good.
Okay.

497
00:30:47.470 --> 00:30:51.070
So here we go.
Where were we?
So yeah,
I've,
I've initialized random weights,

498
00:30:51.370 --> 00:30:56.110
neutralize random weights.
Okay.
And then we got this,

499
00:30:56.111 --> 00:30:59.200
we can finish this guys in eight minutes are we got eight minutes left.

500
00:30:59.830 --> 00:31:02.720
And so I also try to squeeze in time for more questions,

501
00:31:02.810 --> 00:31:06.590
which you guys can also ask us.
I'm doing this.
Okay,
here we go.
So,
um,

502
00:31:07.400 --> 00:31:12.170
now I want to get my observation and my reward and done and info.

503
00:31:12.440 --> 00:31:16.640
And that's going to happen as I take the step function as always the
environment,

504
00:31:16.641 --> 00:31:19.730
that stuff,
and I took complete the action.
Okay.

505
00:31:20.120 --> 00:31:24.080
And so now I'm going to increase my rewards.
I'm going to say total reward.

506
00:31:24.290 --> 00:31:29.000
That variable that I initialized it for is going to get whatever is in my reward

507
00:31:29.001 --> 00:31:33.980
now.
So if it's done,
so that means if the whole tip too far,
uh,
if done,

508
00:31:34.070 --> 00:31:39.070
then break right and then return the total reward.

509
00:31:40.990 --> 00:31:44.710
All right,
so there's that.
So that is our,
uh,

510
00:31:44.750 --> 00:31:49.400
run episode function.
Okay.
Hi.
Read it.
Yes,

511
00:31:49.401 --> 00:31:52.580
exactly.
Exactly.
So now,

512
00:31:54.020 --> 00:31:54.853
<v 2>MMM,</v>

513
00:31:56.920 --> 00:31:59.680
<v 1>so now I'm going to do the actual train function.
Okay,
here we go.</v>

514
00:31:59.830 --> 00:32:03.370
So training time,
let's train this baby.
Let's try this baby.

515
00:32:03.790 --> 00:32:08.230
What's the observation?
The observation in this case is,
uh,
the,
it's,

516
00:32:08.231 --> 00:32:12.580
it's an array of full of velocity values.

517
00:32:12.790 --> 00:32:16.600
So it's a set of vectors of where the pole is in space.

518
00:32:16.990 --> 00:32:21.910
What model does this actual use?
Uh,
the model is,
uh,
it's,

519
00:32:22.390 --> 00:32:26.770
it's,
it's a type of reinforcement learning,
uh,
that is co is,

520
00:32:26.910 --> 00:32:30.670
it's the agent environment loop.
Um,
thank you Omar.

521
00:32:30.790 --> 00:32:34.750
I will definitely do more of these.
It seems that you know,
it depending on,

522
00:32:34.790 --> 00:32:37.510
you know,
how you guys like this,
which it seems like this is,
this is good.

523
00:32:37.540 --> 00:32:40.730
This is kind of fun.
This is crazy.
This is like a rush right now.
I'm like,

524
00:32:41.090 --> 00:32:45.950
I've never done this before.
So I feel like I feel like I'm in the zone.
Like,

525
00:32:45.980 --> 00:32:50.450
you know what I'm saying?
All right,
here we go.
So,
um,
okay,
here we go.

526
00:32:50.590 --> 00:32:54.890
So,
so now it's time to initialize our environments.
I'm going to say Jim.
Dot.

527
00:32:54.920 --> 00:32:59.000
Make a card poll these zero.

528
00:32:59.390 --> 00:33:00.223
All right.

529
00:33:00.290 --> 00:33:05.120
And so now I've made my environment and now I'm going to say,

530
00:33:05.121 --> 00:33:09.080
okay,
episodes her update.

531
00:33:11.050 --> 00:33:11.880
<v 0>Okay.</v>

532
00:33:11.880 --> 00:33:14.310
<v 1>Equals five.
So that's how many episodes I want.</v>

533
00:33:15.170 --> 00:33:18.120
And so now I'm going to find a function called noise scaling.

534
00:33:18.240 --> 00:33:20.220
So noise scaling is the,

535
00:33:20.580 --> 00:33:24.630
is it's a value that I'm going to multiply my weights by every time so that they

536
00:33:24.631 --> 00:33:27.480
get better over time.
So this is,
this is,

537
00:33:27.510 --> 00:33:31.490
this is the actual hill climbing policy.
So that's the name of the policies.

538
00:33:31.530 --> 00:33:36.360
Hill climbing,
which answers your question?
Um,
a mighty magic.
It's hill climbing.

539
00:33:36.361 --> 00:33:37.350
That's the type of policy.

540
00:33:39.400 --> 00:33:40.080
<v 0>Okay.</v>

541
00:33:40.080 --> 00:33:43.260
<v 1>Uh,
the environment line from above.
Uh,
let's see</v>

542
00:33:45.050 --> 00:33:48.860
the environment line from above you.
Oh,
you know what?
I do need to delete that.

543
00:33:48.980 --> 00:33:53.690
Thank you for.
Thank you for catching that.
Uh,
his Sean.
Thank you.
All right,

544
00:33:53.691 --> 00:33:58.640
here we go.
So noise scaling.
All right,
we did that.

545
00:33:59.060 --> 00:34:03.560
Total reward noise stealing.
Where was I?

546
00:34:04.700 --> 00:34:09.690
Where am I based?
Um,
I will fix all that.

547
00:34:09.710 --> 00:34:13.980
I am in San Francisco,
California.
All right.
Um,
all right,
here we go.

548
00:34:13.981 --> 00:34:16.410
So now I'm going to create my parameters.

549
00:34:16.740 --> 00:34:21.150
Why does this kind of like not like,
oh,

550
00:34:21.240 --> 00:34:25.800
thank you.
Uh,
Lozier.
Okay,
so

551
00:34:26.850 --> 00:34:27.410
<v 0>yeah,</v>

552
00:34:27.410 --> 00:34:30.170
<v 1>now I'm going to randomly initialized vectors of weights.</v>

553
00:34:30.430 --> 00:34:33.890
We set parameters equals num,
Pi dot.
Random num,
py dot.

554
00:34:33.891 --> 00:34:38.891
Random Dot whammed four times to mine.

555
00:34:38.981 --> 00:34:43.340
It's one that's going to neutralize I set of weights between negative one and

556
00:34:43.341 --> 00:34:45.200
one.
Okay.
That's just what that is.

557
00:34:45.260 --> 00:34:49.220
So then I'm going to say batch reward equals zero and that's the reward that I'm

558
00:34:49.221 --> 00:34:53.600
going to save later.
Okay.
So I'm going to run this for 2000 episodes.
Okay.

559
00:34:53.601 --> 00:34:54.740
That's what I want to run this for.

560
00:34:54.880 --> 00:34:59.880
So I'm going to say in the range of of 2000 run this ish.

561
00:35:00.800 --> 00:35:05.450
Okay.
Isn't always stealing like the learning rate in a way.
Yes,

562
00:35:05.480 --> 00:35:09.050
yes it is.
That's,
that's a,
that's a great question.
It is.
It is just like that.

563
00:35:09.110 --> 00:35:10.130
It is a,
it is,

564
00:35:10.160 --> 00:35:14.660
it is something that that improves your training over time.

565
00:35:14.960 --> 00:35:16.940
Just like the learning rate does.
Okay.

566
00:35:16.970 --> 00:35:21.530
So new prams equals parameters plus,

567
00:35:21.910 --> 00:35:24.650
um,
none pied are random.

568
00:35:25.510 --> 00:35:29.360
And so this is going to be the same thing that that set of initialized weights

569
00:35:29.450 --> 00:35:33.620
between negative one and one minus one.
And this is where,

570
00:35:33.650 --> 00:35:38.400
this is where the noise scaling goes.
I'm going to say times noise scaling.

571
00:35:38.730 --> 00:35:41.880
This is the machine learning part right here.
Okay.

572
00:35:43.100 --> 00:35:46.950
So it's going to update those wick,
that new set of parameters every time.
Okay.

573
00:35:48.150 --> 00:35:50.130
First Return.
Not In a good place.

574
00:35:54.220 --> 00:35:57.820
Oh yeah,
you're right.
You're totally right.
Thank you.
Thank you.
Thank you.

575
00:35:58.720 --> 00:36:03.400
Thank you for that.
Um,
Andrea's okay,

576
00:36:03.401 --> 00:36:08.200
here we go.
Here we go.
Um,
all right,

577
00:36:08.350 --> 00:36:10.990
so now,
so now,
okay.

578
00:36:11.050 --> 00:36:15.370
Reward is Ryan episode.
We're going to get that reward.

579
00:36:15.371 --> 00:36:17.920
We're going to use our run episode function.
Okay.

580
00:36:17.921 --> 00:36:19.990
That's going to complete the agent environment loop.

581
00:36:20.770 --> 00:36:23.580
And we're going to say environments as the parameter,

582
00:36:23.590 --> 00:36:25.810
the one we've just initialize and those,

583
00:36:25.811 --> 00:36:28.490
that new set of perimeters that we initialize.
Okay.
That's the,

584
00:36:28.491 --> 00:36:30.520
those are the two parameters that we're going to use.

585
00:36:30.730 --> 00:36:34.390
So that's gonna be a reward.
And now we're going to print that.

586
00:36:34.460 --> 00:36:35.350
We're going to say prince.

587
00:36:36.480 --> 00:36:37.150
<v 2>Yeah.</v>

588
00:36:37.150 --> 00:36:40.420
<v 1>Uh,
we're going to print reward,
reward.</v>

589
00:36:41.040 --> 00:36:41.873
<v 2>MMM.</v>

590
00:36:43.120 --> 00:36:47.450
<v 1>La.
And then best,</v>

591
00:36:49.100 --> 00:36:52.760
and then we're going to say,
um,
reward.

592
00:36:53.130 --> 00:36:53.963
<v 2>Okay.</v>

593
00:36:55.060 --> 00:36:59.200
<v 1>Then best reward.
So that's going to show us some good friends.
Right?
Okay.</v>

594
00:36:59.201 --> 00:37:03.490
Here we go.
Here we go.
All right.
One more like little last thing.
Okay.

595
00:37:03.491 --> 00:37:07.000
So we're going to say if the reward,
if the reward improves with noise,

596
00:37:07.001 --> 00:37:09.280
we went to update the reward and keep the weights.

597
00:37:09.340 --> 00:37:12.430
So if reward is greater than best reward,

598
00:37:13.240 --> 00:37:14.980
then that's reward.

599
00:37:15.040 --> 00:37:20.040
Well then become whatever the reward was and parameters,

600
00:37:22.490 --> 00:37:26.840
it's going to get what the new parameters are.
And then finally,

601
00:37:26.900 --> 00:37:31.220
if the upper threshold of 200 is reached,
which we want it set for the reward,

602
00:37:31.490 --> 00:37:35.480
then we break.
That's it.
Okay.
Um,

603
00:37:36.120 --> 00:37:36.953
<v 2>okay,</v>

604
00:37:37.730 --> 00:37:41.090
<v 1>so there's that.
Um,
where else are we?</v>

605
00:37:43.660 --> 00:37:45.520
I'm struggling to

606
00:37:47.880 --> 00:37:50.830
like see anything here.
Okay.
So then,
okay,
so that's it.
That's it.

607
00:37:50.831 --> 00:37:52.090
So now we're going to just run this,

608
00:37:52.120 --> 00:37:54.460
we're going to say try and we're going to run our train function with submit

609
00:37:54.461 --> 00:37:56.950
equals false cause we don't want it submitted it anywhere.

610
00:37:57.040 --> 00:38:01.270
And then we're going to say prince.
Okay,
so let's just run that shit.
Let is,

611
00:38:01.271 --> 00:38:03.070
could you reduce noise over time?

612
00:38:03.630 --> 00:38:04.463
<v 2>MMM,</v>

613
00:38:05.930 --> 00:38:08.550
<v 1>we could.
We could,
we could reduce it over time.
Um,</v>

614
00:38:08.570 --> 00:38:11.180
I think for this simple example,
we're kind of keep it static,

615
00:38:11.210 --> 00:38:14.200
but there's a bunch of things.
Yeah,
no,
absolutely.
You could reduce it over time.

616
00:38:14.210 --> 00:38:18.320
You can try different,
you can,
you can make sure your weights aren't a random,

617
00:38:18.321 --> 00:38:23.150
you could try,
you could try weights that,
uh,
our synthetic,
I mean,

618
00:38:23.151 --> 00:38:25.160
you could look at different policies.
That's the fun of it.

619
00:38:25.161 --> 00:38:29.270
Like open AI has totally gamified this whole process.
So let's run that.

620
00:38:30.520 --> 00:38:32.360
Awesome.
Okay.
Sorry.

621
00:38:34.990 --> 00:38:36.600
<v 2>Yeah.
Uh,</v>

622
00:38:37.290 --> 00:38:40.050
<v 1>yeah.
Oh my God.
Okay.
Uh,</v>

623
00:38:41.190 --> 00:38:45.420
let's see what's going on here.
Uh,
what the F okay,

624
00:38:45.510 --> 00:38:49.490
but we'll name observations is not defined.
Where is that?
What line is that on?

625
00:38:49.500 --> 00:38:52.260
Global name observations is not defined.

626
00:38:52.800 --> 00:38:56.070
That is underlined 17 let's see that guys.
What's going on here?

627
00:38:56.100 --> 00:38:57.960
Global name observation.
Oh,

628
00:38:57.961 --> 00:39:02.700
observations is not defined observation.
There we go.
Run that.

629
00:39:03.720 --> 00:39:08.620
Oh,
so,
okay.
So yeah,
it's doing,
it's doing hill climbing.
It's doing,
hey.

630
00:39:08.621 --> 00:39:12.480
Oh climbing.
It's duly here climbing.
Okay,
cool.
Okay.

631
00:39:12.481 --> 00:39:16.950
I'm really happy that this is working.
Okay.
Where's the next for the four?

632
00:39:17.190 --> 00:39:22.190
So it is trying a bunch of random weights and it is multiplying that noise

633
00:39:22.411 --> 00:39:26.820
scaling constant that we had before every time if the weights are better,

634
00:39:27.000 --> 00:39:30.990
it's remembering those weights instead of just continuously trying other new

635
00:39:30.991 --> 00:39:35.430
random ways and that way it gets better and better over time.
Okay.

636
00:39:36.150 --> 00:39:38.100
This is going to run for probably like,

637
00:39:39.240 --> 00:39:42.750
isn't it so good when it works or the way it's part of a neural network?

638
00:39:42.870 --> 00:39:45.780
That is a great question.
Mighty magic magic.
It is.

639
00:39:45.810 --> 00:39:49.800
It is part of a neural network.
Okay.
It's a,
it's a one layer neural network.

640
00:39:50.310 --> 00:39:54.290
So the best way is 11 and the old one is to the,

641
00:39:54.340 --> 00:39:59.340
to the best one is on the right.
And the old one is on the left and

642
00:40:01.330 --> 00:40:05.660
um,
hopefully it's,
it finishes soon.

643
00:40:07.040 --> 00:40:10.640
Yes,
it is.
It is like a genetic algorithm.

644
00:40:10.760 --> 00:40:13.460
Is there a way to make it deeper or change the size of hidden layers?

645
00:40:13.940 --> 00:40:17.450
Not with just gym.
We would have to integrate tensorflow,

646
00:40:17.630 --> 00:40:21.490
which I can do in a future video.
I actually,
I think tensorflow and,

647
00:40:21.820 --> 00:40:26.270
and Jim go together very well.
Uh,
but

648
00:40:30.670 --> 00:40:35.180
yeah,
so,
so yeah.
So,
so that's,
that's a training.
So now while I train,

649
00:40:35.200 --> 00:40:36.070
I'm going to answer,

650
00:40:36.140 --> 00:40:40.330
I'm going to give it five more minutes to answer any other questions.

651
00:40:40.720 --> 00:40:44.110
So I'll just like,
just like go for it.
Like,
just the like whatever you want,

652
00:40:44.111 --> 00:40:46.840
I will reveal all,
just go for it.
You know what I mean?

653
00:40:48.500 --> 00:40:50.650
You guys have any questions and stuff?

654
00:40:52.630 --> 00:40:56.170
So let me just like a full screen this baby so there's less lag.

655
00:40:56.890 --> 00:41:01.310
Less lag.
All right.
Um,

656
00:41:01.900 --> 00:41:06.850
stop screen sharing.
Okay.
I think there's less lag now.
Right?
Okay.

657
00:41:06.880 --> 00:41:11.820
So,
hi.
Hi.
Hi.
So there's less lag.
Can you show the show while,

658
00:41:12.050 --> 00:41:16.860
um,
the code while it's running as well?
Uh,

659
00:41:16.890 --> 00:41:20.580
yes.
I can show the code in a second.
You know,
I'm just going to link to it later.

660
00:41:20.640 --> 00:41:24.390
What is the best Linux sister to get started?
The intention float.
Who been to,
uh,

661
00:41:24.530 --> 00:41:26.880
do you do more of these if you have time?
I totally will.

662
00:41:27.180 --> 00:41:29.340
How many years until I Jarvis like AI is real?

663
00:41:29.341 --> 00:41:32.530
How would I would say a decade from now,
uh,
at,

664
00:41:32.810 --> 00:41:36.570
at a decade from now,
seven to 10 years.
Where do you start learning ml?

665
00:41:36.660 --> 00:41:39.680
Like fulltime?
No.
Period.
A little.
I did shit.

666
00:41:41.000 --> 00:41:44.520
Oh my God.
I love it.
You guys are so funny.
Uh,

667
00:41:44.570 --> 00:41:47.180
where to start learning ml by channel.
Start from video one.

668
00:41:47.181 --> 00:41:50.210
Go all the way through.
Implement all the code associated with my videos.

669
00:41:51.020 --> 00:41:55.250
Thanks Tyler.
You are awesome.
I told him very well in two months for a Gig.

670
00:41:55.940 --> 00:41:57.470
Uh,
Yo,
uh,

671
00:41:58.530 --> 00:42:02.010
to watch my videos and also go to the machine learning sub reddit.

672
00:42:02.120 --> 00:42:05.180
Go to go to it every single day.
I've made it a habit of mine.
I wake up,

673
00:42:05.181 --> 00:42:07.400
go to the machine learning,
separate it,
look through everything.

674
00:42:07.490 --> 00:42:10.250
People are super harsh in the machine learning sub.
By the way,

675
00:42:10.430 --> 00:42:12.740
like they will just tear everything apart.

676
00:42:12.860 --> 00:42:16.250
Usually like skeptical people who are like super smart or like that.
Anyway,

677
00:42:16.370 --> 00:42:18.020
if you meet one of these ml researchers,

678
00:42:18.110 --> 00:42:21.140
they'll just like these hyper critical people that was just like tear you down

679
00:42:21.141 --> 00:42:24.410
with their eyes cause you know,
they're just like,
hmm.
You know,
like scientists,

680
00:42:24.411 --> 00:42:27.740
right?
Who is hiring for these skills?
Absolutely.

681
00:42:27.741 --> 00:42:32.000
Everybody in fact that that nanodegree guy,
you Udacity who I'm working with,

682
00:42:32.240 --> 00:42:35.480
oops,
I just revealed that by the way,
that self driving car course,

683
00:42:35.481 --> 00:42:38.850
like I'm an assistant instructor for that.
Awesome.
Uh,

684
00:42:38.900 --> 00:42:42.680
just cause the guy saw my videos,
but uh,
that guy was like,

685
00:42:42.710 --> 00:42:46.370
even if we had a dude,
Dessi is awesome.
He's like,

686
00:42:46.760 --> 00:42:48.230
even if our course was full,

687
00:42:48.231 --> 00:42:51.500
we would still have like less than 1% of the need for self driving car
engineers.

688
00:42:51.740 --> 00:42:54.020
So that,
so who is hiring for these skills?

689
00:42:54.170 --> 00:42:58.210
Literally like everybody will soon start hiring for these skills.

690
00:42:58.220 --> 00:43:01.040
Like right now there's like a tech companies and not 10 companies,

691
00:43:01.190 --> 00:43:06.080
but soon every single company is going to be a tech company.
Uh,
awesome.

692
00:43:06.081 --> 00:43:10.670
Nico,
you're awesome.
Um,
will you organize meetups as well?

693
00:43:11.070 --> 00:43:15.110
Actually having my first talk tomorrow at the write the docs meetup in San

694
00:43:15.110 --> 00:43:19.030
Francisco.
Right.
The docs.
Cause you're asking me like how I do all this stuff.
Uh,

695
00:43:19.100 --> 00:43:22.820
but yes,
I want to organize meetups.
Definitely shoot me an email with some ideas.

696
00:43:22.821 --> 00:43:26.240
Like I'm open to it.
Uh,
cool.

697
00:43:26.241 --> 00:43:31.220
How much math you think is needed to do real research?
Yo,
you,

698
00:43:31.310 --> 00:43:36.110
you definitely need some actual like real like cutting edge stuff.

699
00:43:36.140 --> 00:43:38.450
You've then you've then you've got to know some math,

700
00:43:38.630 --> 00:43:43.350
I would say like linear Algebra,
statistics and um,

701
00:43:45.740 --> 00:43:49.160
game theory.
Um,
and also just like,
uh,

702
00:43:49.550 --> 00:43:52.190
like quantum physics that has nothing to do with machine learning,

703
00:43:52.191 --> 00:43:54.950
but like quantum physics,
quantum mechanics,
that's stuff is just like,

704
00:43:55.030 --> 00:43:57.920
it puts you in this way of thinking that I think can be applied to machine

705
00:43:57.921 --> 00:44:02.810
learning.
Uh,
Yo,
I would love to come to Brazil at some point.
Hi.

706
00:44:02.811 --> 00:44:06.740
Graph theory.
Exactly.
Yeah,
exactly.
Amazon is paying shit.

707
00:44:06.741 --> 00:44:10.610
Tons of gold and I would love to do,
yes.

708
00:44:10.611 --> 00:44:13.880
I'm working with Sebastian through,
uh,

709
00:44:14.600 --> 00:44:18.710
and uh,
yeah.
Wow.
So everything

710
00:44:21.140 --> 00:44:23.900
cool.
Wow.
So this was a trip.
All right guys.

711
00:44:23.901 --> 00:44:27.590
Well one more question and then I'm out.
Whoever,
whichever question I see first,

712
00:44:28.760 --> 00:44:33.150
let's see,
just go for it.
Just let's see it.
I'm,
I'm done.
I'm ready for this.

713
00:44:35.770 --> 00:44:36.850
Yes.
Anytime.

714
00:44:37.150 --> 00:44:41.560
How would you use ml to look at your video for example and see when the video

715
00:44:41.561 --> 00:44:44.560
change from just your face to the view?
I'm sure.

716
00:44:46.590 --> 00:44:50.650
Um,
uh,
um,

717
00:44:53.330 --> 00:44:58.090
uh,
girls do think mls sexy cause we are going to make it sexy,
right?

718
00:44:58.210 --> 00:45:02.380
Well let's make it sexy because we're awesome.
Um,
awesome.

719
00:45:02.381 --> 00:45:06.190
Do I own bitcoins?
I do.
I actually used to be super obsessed with bitcoins.

720
00:45:06.400 --> 00:45:10.330
If you guys look at my older videos you'll see like this big coin music video I

721
00:45:10.331 --> 00:45:12.400
made,
which was actually pretty hilarious.

722
00:45:12.550 --> 00:45:15.100
But I definitely want to make a machine learning music videos soon.

723
00:45:15.101 --> 00:45:17.020
That's like more,
you know,
production heavy.

724
00:45:17.021 --> 00:45:21.520
Cause like once you get at 10,000 subscribers on Youtube and they'll let you use

725
00:45:21.521 --> 00:45:24.520
their studio space in La,
which I'd like to use for a music video.

726
00:45:24.610 --> 00:45:27.700
I just don't have time cause I'm like doing this full time.

727
00:45:27.790 --> 00:45:31.630
Am I still a researcher or working for any company?
I'm not working for anybody.

728
00:45:31.900 --> 00:45:36.100
I am working for me and then clients approach me.
Thank you and I,

729
00:45:36.310 --> 00:45:39.250
no one can buy me out except for deed mine.
So yes,

730
00:45:39.251 --> 00:45:41.890
deep mind if you're watching you can totally buy me out.

731
00:45:42.100 --> 00:45:43.750
I will do anything for you.

732
00:45:44.000 --> 00:45:47.590
A to pocket machine learning video would be awesome.

733
00:45:48.190 --> 00:45:51.220
Do I program in other languages?
Yeah,
I mean like when I worked at Twilio,

734
00:45:51.221 --> 00:45:56.221
like I had to write documentation in like 10 different languages and like Ah,

735
00:45:56.700 --> 00:45:59.800
it's,
but I just prefer python because it's just simple like you know,

736
00:45:59.801 --> 00:46:02.650
like this stuff is just like,
I just want to get right to the good stuff.

737
00:46:02.651 --> 00:46:06.310
The logic,
the algorithms,
that's what matters is not the syntax stuff.

738
00:46:06.510 --> 00:46:09.010
Just pick some language and just go for it.
Like,
you know,

739
00:46:09.011 --> 00:46:09.960
and I would say it's python.

740
00:46:10.430 --> 00:46:11.263
<v 2>MMM,</v>

741
00:46:12.010 --> 00:46:15.400
<v 1>okay.
Deep learning is not going away anytime soon.</v>

742
00:46:15.430 --> 00:46:18.220
It's going to evolve into something better in my opinion.

743
00:46:18.221 --> 00:46:20.110
We're going to start getting into one shot learning,

744
00:46:20.111 --> 00:46:22.960
like that's what's going to come after deep learning where you don't need like a

745
00:46:22.961 --> 00:46:26.500
huge amount of example to train and things.

746
00:46:26.860 --> 00:46:31.150
And what am I doing in my free time?
I,
what do I do in my free time?
Yeah,

747
00:46:31.151 --> 00:46:34.780
that's a good question.
So besides doing this,
I uh,

748
00:46:34.910 --> 00:46:37.850
I ha I have recently started taking uh,

749
00:46:38.020 --> 00:46:40.690
like Bruce Lee classes to kind of be like Bruce Lee.

750
00:46:41.110 --> 00:46:43.210
I have freestyle rap.

751
00:46:43.740 --> 00:46:44.573
<v 2>MMM.</v>

752
00:46:47.130 --> 00:46:51.210
<v 1>And I hang out with my uh,
friends.</v>

753
00:46:51.600 --> 00:46:55.440
And how did object to see break my heart.
It really just,

754
00:46:55.770 --> 00:47:00.150
it's just when I saw swift I was like,
Yo,
you know,
why did I,

755
00:47:00.330 --> 00:47:04.200
okay,
I'll tell you how object to see broke my heart.
I was like,
uh,

756
00:47:04.260 --> 00:47:08.370
splitting strings let like like in like four or five lines of code in objective

757
00:47:08.371 --> 00:47:13.080
C.
And I was like,
Yo,
this takes so long to do like,

758
00:47:13.081 --> 00:47:16.680
I just need like to do it in swift.
You just do it in one line.
In Python,

759
00:47:16.710 --> 00:47:21.360
it's just in one line.
Objective c doing anything.
Yes.
G Cuando.
Yes.

760
00:47:21.480 --> 00:47:24.330
That is exactly what I'm doing.
I'm excited cause I met this dude.

761
00:47:24.331 --> 00:47:25.470
He's like his awesome.

762
00:47:25.770 --> 00:47:30.070
Why don't I do a freestyle rap right now and memorize my ml lyrics.
Uh,

763
00:47:30.130 --> 00:47:34.210
I will do a quick grab a,
here we go.
I mean I need a beat,

764
00:47:34.211 --> 00:47:38.650
but like let's just go for it.
Here we go.
I'm just going to freestyle you.

765
00:47:38.651 --> 00:47:42.940
I got back propagation.
I do it for this nation.
You guys see me?

766
00:47:43.060 --> 00:47:47.400
I'm like a hardcore fasion.
Yeah,
I'm from the planet.
Facia.

767
00:47:47.560 --> 00:47:50.410
I came out here and take you synthetic south,

768
00:47:50.620 --> 00:47:54.700
like a geisha from Japan with all this stuff all around.

769
00:47:54.790 --> 00:47:59.020
It's like I'm Peter Pan.
I fly in the clouds.
Okay.
That was it.
Anyway.

770
00:47:59.680 --> 00:48:01.840
Uh,
Yo Bayes is cool.

771
00:48:01.841 --> 00:48:05.410
I'm not saying anything bad about bays like basis basis.
Pretty cool.

772
00:48:05.620 --> 00:48:10.420
A bitcoin trading bot,
that would be a lot of Yo.
Okay.
Encore dot.

773
00:48:10.421 --> 00:48:15.130
Ai.
That's actually my next video.
Uh,
I mean,
nope.
Thank you.

774
00:48:15.550 --> 00:48:19.870
A recommendation system.
It's actually did build,
build a recommender system.

775
00:48:20.020 --> 00:48:22.330
That's machine learning for hackers.
Number four.
Check that out.

776
00:48:22.360 --> 00:48:26.470
I got to Redo that video cause I used to talk way too fast and

777
00:48:28.750 --> 00:48:33.580
I know Anthony,
I know that that was amazing.
It was an okay.
Okay.

778
00:48:33.850 --> 00:48:37.300
Um,
Yo Yo yo yo.
Okay.
Meg Dg,
let me like,

779
00:48:37.630 --> 00:48:41.110
I need to understand this question.
Okay,
thank you.
I love Tunisia as well.

780
00:48:41.111 --> 00:48:45.580
I want to go there eventually when I go there.
Okay.

781
00:48:46.260 --> 00:48:49.560
Kenta to flow.
Yes.

782
00:48:49.750 --> 00:48:52.810
I mean can it work with the video stream?
I guess so.

783
00:48:53.590 --> 00:48:55.450
I guess I could work with the video stream.

784
00:48:55.570 --> 00:48:57.100
I don't know exactly what you mean by that.

785
00:48:57.101 --> 00:49:00.790
Like do you mean like training it on like video frames?
Why no windows?

786
00:49:00.820 --> 00:49:05.820
Because I dunno like I switched over to Unix based systems and I never went back

787
00:49:06.550 --> 00:49:08.890
and I know like you know what Satya Nadella and stuff,

788
00:49:08.891 --> 00:49:11.640
Microsoft is trying to be all cool and stuff and like,
you know,

789
00:49:11.680 --> 00:49:15.790
implement bash like a terminal.
But um,
I just,

790
00:49:15.820 --> 00:49:18.910
Oh also I switched to an android phone cause like Google now is way better than

791
00:49:18.911 --> 00:49:22.660
Siri.
I think Kamiah I will be successful 100%.

792
00:49:22.661 --> 00:49:26.020
They're going to be bought out by probably Google A.
All right guys.

793
00:49:26.080 --> 00:49:29.470
So that's it for now.
I'm going to make more of these.
Okay.

794
00:49:29.650 --> 00:49:32.020
Thank you for watching.
I think this was a success.

795
00:49:32.170 --> 00:49:35.410
I'm going to hit stop broadcast and,
uh,

796
00:49:35.710 --> 00:49:40.220
thank you all for being here and you're going to be able to see links to,
to a,

797
00:49:40.221 --> 00:49:44.290
a bunch of things.
All right.
So thank you guys for watching.
Um,

798
00:49:45.190 --> 00:49:48.280
uh,
for now.
All right,
let's say for now,

799
00:49:48.281 --> 00:49:52.210
I've got to go to the bathroom to do things.

800
00:49:52.870 --> 00:49:57.640
Uh,
so thanks for watching.
Thank you.
Bye.

801
00:49:58.720 --> 00:50:00.790
Love you guys.
Okay,
bye.

802
00:50:04.160 --> 00:50:05.780
<v 0>All right.</v>

