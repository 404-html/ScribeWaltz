WEBVTT

1
00:00:00.150 --> 00:00:04.470
Are you a good driver?
The answer is no.
Hello world,

2
00:00:04.520 --> 00:00:08.820
it's Saroj and like it or not self driving cars are the future of

3
00:00:08.821 --> 00:00:09.810
transportation.

4
00:00:10.050 --> 00:00:14.610
We'll build a surprisingly simple demo in this video and let's a car learn how

5
00:00:14.611 --> 00:00:19.611
to mimic a human driver in a simulation using deep learning major technology

6
00:00:20.101 --> 00:00:24.240
companies like Lyft and Waymo and total as an auto makers like Toyota and

7
00:00:24.241 --> 00:00:29.241
General Motors have spent billions of dollars developing self driving cars and

8
00:00:29.821 --> 00:00:34.560
the belief that the market for them could one day be worth trillions of dollars.

9
00:00:34.830 --> 00:00:39.810
Autonomous buses and shuttles are currently being deployed in cities and

10
00:00:39.811 --> 00:00:40.644
airports.

11
00:00:40.710 --> 00:00:45.710
Driverless trucks are already delivering beer long distances and even autonomous

12
00:00:46.261 --> 00:00:49.320
flying taxis seem to be in our near future.

13
00:00:49.590 --> 00:00:51.930
And there's good reason for this revolution.

14
00:00:52.110 --> 00:00:57.110
Self driving cars would greatly reduce the price of transport for consumers

15
00:00:57.451 --> 00:00:59.310
since there's no human in the loop.

16
00:00:59.610 --> 00:01:03.390
And by using autonomous fleets of shared electric cars,

17
00:01:03.600 --> 00:01:06.960
we'd only need 10% of cars on the road currently,

18
00:01:07.170 --> 00:01:11.010
which would reduce co two emissions and pickup trucks immensely.

19
00:01:11.640 --> 00:01:13.710
And when that shift happens,

20
00:01:13.711 --> 00:01:18.711
we can begin to redesign our cities into beautiful creative spaces meant for

21
00:01:19.291 --> 00:01:20.790
people,
not cars.

22
00:01:21.090 --> 00:01:25.920
Perhaps the most popular reason of all of them is that it would create a safer

23
00:01:25.950 --> 00:01:27.600
environment for everyone.

24
00:01:27.930 --> 00:01:32.580
Data from the National Highway Traffic Safety Administration indicates that more

25
00:01:32.581 --> 00:01:36.690
than 90% of car accidents are caused by human error.

26
00:01:37.020 --> 00:01:41.790
That means self driving cars had the potential to save more lives than airbags.

27
00:01:41.830 --> 00:01:46.830
Seat belts and stability control combined a truly first of its kind technology

28
00:01:47.521 --> 00:01:48.390
for road safety.

29
00:01:48.720 --> 00:01:53.720
Unfortunately though one of Uber's autonomous cars made global headlines when it

30
00:01:53.911 --> 00:01:57.420
had a fatal collision with a pedestrian in Arizona,

31
00:01:57.660 --> 00:02:02.280
engineers at Uber have since been decoding what went wrong and this presents a

32
00:02:02.281 --> 00:02:05.370
new realm of legal and regulatory questions.

33
00:02:05.520 --> 00:02:09.450
We'll have to learn how to answer who should be held responsible for this kind

34
00:02:09.451 --> 00:02:10.284
of accident?

35
00:02:10.800 --> 00:02:15.360
How should a self driving car make hard decisions on who's life is worth

36
00:02:15.361 --> 00:02:19.080
preserving more?
How do we make self drying laundry?

37
00:02:19.490 --> 00:02:23.280
All those self driving cars are inexpensive technology.

38
00:02:23.460 --> 00:02:28.110
There is definitely room for lean startups in this space that can create

39
00:02:28.111 --> 00:02:29.490
software for them.

40
00:02:29.700 --> 00:02:34.260
Level five is building software and collecting data that's needed to scale

41
00:02:34.261 --> 00:02:36.090
autonomous vehicles globally.

42
00:02:36.510 --> 00:02:41.190
No tow aims to make these cards safer by gathering data from human driver

43
00:02:41.191 --> 00:02:46.191
behavior and there's a big space to combine blockchain technology with fleets of

44
00:02:46.831 --> 00:02:50.220
these cars to create even more autonomous systems,

45
00:02:50.430 --> 00:02:55.430
which Porsche has started trying out to increase transparency of decisions that

46
00:02:56.401 --> 00:03:00.370
it's cards mic but enough about the possibilities.

47
00:03:00.371 --> 00:03:02.890
Let's dive into how these things work.
Right?

48
00:03:03.130 --> 00:03:07.210
Self driving cars have five core components that form a pipeline,

49
00:03:07.450 --> 00:03:10.900
computer vision,
sensor,
fusion,
localization,

50
00:03:10.930 --> 00:03:14.290
path planning and control in that order.
Let's go through them.

51
00:03:14.740 --> 00:03:17.710
Computer vision is the first step in the pipeline.

52
00:03:17.740 --> 00:03:20.080
It's how cameras see the road.

53
00:03:20.290 --> 00:03:25.120
We humans handled a vision problem by handling a car's steering wheels with just

54
00:03:25.121 --> 00:03:26.680
our two eyes and a brain.

55
00:03:27.070 --> 00:03:31.930
A self driving car uses camera images to find the lane lines and track other

56
00:03:31.931 --> 00:03:36.580
vehicles on the road.
Most of them have lots of cameras,
not just to.

57
00:03:36.910 --> 00:03:38.110
Tesla,
for example,

58
00:03:38.111 --> 00:03:43.111
gives its cars eight surround cameras that provide 360 degrees of visibility

59
00:03:43.360 --> 00:03:47.050
around the car at up to 250 meters of range.

60
00:03:47.080 --> 00:03:49.120
Providing superhuman vision ability.

61
00:03:49.480 --> 00:03:54.100
There are so many tasks that camera's enabled like Layne finding road curvature,

62
00:03:54.101 --> 00:03:58.300
estimation,
obstacle detection and classification and traffic,

63
00:03:58.301 --> 00:04:00.880
light detection.
Those are some of the main ones,

64
00:04:00.970 --> 00:04:03.940
but imagine a pedestrian is about to cross the road.

65
00:04:04.150 --> 00:04:08.110
A car has to first find where that object is in a camera image.

66
00:04:08.350 --> 00:04:12.340
We can call this detection,
then determine what that object is.

67
00:04:12.341 --> 00:04:14.470
We can call that classification.

68
00:04:14.800 --> 00:04:19.450
Deep learning has emerged as the most accurate approach to working with camera,

69
00:04:19.451 --> 00:04:20.890
video and images.

70
00:04:21.130 --> 00:04:24.670
In order to train a neural network on what a stop sign looks like.

71
00:04:24.820 --> 00:04:29.820
It's fed thousands of stop sign images and it gradually learns it's abstract

72
00:04:29.831 --> 00:04:30.790
representation,

73
00:04:30.940 --> 00:04:34.990
robustly able to classify all variations of a stop sign.

74
00:04:35.410 --> 00:04:39.970
This is much more efficient than the traditional or old AAF approach to computer

75
00:04:39.971 --> 00:04:44.230
vision.
Things that focus on color extraction and other low level features,

76
00:04:44.320 --> 00:04:48.790
but the camera is not the only type of sensor a car can have,

77
00:04:48.820 --> 00:04:52.540
especially if bit by a radioactive spider sensor.

78
00:04:52.541 --> 00:04:56.770
Fusion is how the data from other sensors together with the camera data build a

79
00:04:56.771 --> 00:05:01.390
complete understanding of the vehicles environment.
As good as cameras are.

80
00:05:01.420 --> 00:05:06.420
There are certain measurements like distance and velocity at which other sensors

81
00:05:06.610 --> 00:05:10.840
excel and some sensors can work better in adverse weather.

82
00:05:11.080 --> 00:05:15.700
By combining all of our sensor data,
we get a better understanding of the world.

83
00:05:15.940 --> 00:05:18.880
There are different sensors for different use cases.

84
00:05:19.030 --> 00:05:24.030
Radar is good for determining how far away an object is and how fast it's going,

85
00:05:25.120 --> 00:05:27.790
but radar signatures can be pretty sparse.

86
00:05:28.030 --> 00:05:30.040
It'll tell you that something is ahead,

87
00:05:30.070 --> 00:05:35.020
but it won't be able to tell you what that thing is.
That's where lidar comes in.

88
00:05:35.230 --> 00:05:38.200
It emits an array of pulsed laser beams.

89
00:05:38.410 --> 00:05:40.420
The create a Three d point cloud.

90
00:05:40.630 --> 00:05:45.630
Lidar is the happy medium between camera and radar that allows a car to detect

91
00:05:46.450 --> 00:05:51.220
and track objects from far away.
Ultrasonic sensors on the other hand,

92
00:05:51.310 --> 00:05:56.310
have a small sensing distance which makes them useful for lateral movements like

93
00:05:56.681 --> 00:05:57.514
parking.

94
00:05:57.530 --> 00:06:02.530
We can combine all of this sensor data together using what's called a filter.

95
00:06:02.630 --> 00:06:04.520
There are a lot of potential filters,

96
00:06:04.521 --> 00:06:07.790
but a popular one is called a Kalman filter.

97
00:06:07.940 --> 00:06:12.940
This filter relies on probability and a measurement update cycle to put together

98
00:06:13.430 --> 00:06:18.350
a probabilistic understanding of the world like predicting the speed at which

99
00:06:18.380 --> 00:06:20.240
another vehicle is moving.

100
00:06:20.600 --> 00:06:25.580
The Coleman filter keeps track of the estimated state of the system and the

101
00:06:25.581 --> 00:06:28.160
variance of uncertainty of the estimate.

102
00:06:28.490 --> 00:06:32.090
The estimate is updated using a state transition model.

103
00:06:32.300 --> 00:06:35.090
It's pretty similar to a hidden Markov model.

104
00:06:35.480 --> 00:06:40.480
Next localization is how a car figures out what its position in the world is,

105
00:06:41.150 --> 00:06:44.990
which is the next step after a understand what the world looks like.

106
00:06:45.260 --> 00:06:49.580
Our phones are equipped with gps so they do this for our position,

107
00:06:49.880 --> 00:06:54.260
but unfortunately gps is only accurate to within about two meters.

108
00:06:54.650 --> 00:06:59.000
If a car were wrong by that much,
it could result in fatal accidents.

109
00:06:59.330 --> 00:07:04.330
So more sophisticated algorithms are used to help a vehicle localize itself to

110
00:07:04.701 --> 00:07:07.610
within two centimeters.
By matching the point cloud,

111
00:07:07.640 --> 00:07:12.640
it sees to the point cloud that the map has measuring the vehicles distance to

112
00:07:12.681 --> 00:07:17.681
specific landmarks around it like mailboxes poles and childish Gambino.

113
00:07:18.410 --> 00:07:20.540
The next step is path planning,

114
00:07:20.570 --> 00:07:25.570
which is what happens after the car knows what the world looks like and where it

115
00:07:25.821 --> 00:07:27.170
is in that world.

116
00:07:27.320 --> 00:07:31.880
The car charts a trajectory through the world to get to where he wants to go.

117
00:07:32.060 --> 00:07:35.870
First it predicts what the other vehicles around it will do.

118
00:07:36.140 --> 00:07:40.400
Then it will decide which maneuver it wants to take in response to those

119
00:07:40.401 --> 00:07:45.320
vehicles.
Lastly,
a trajectory is built to execute the maneuver safely.

120
00:07:45.680 --> 00:07:50.120
The final step of the pipeline is control.
Once a car has a trajectory,

121
00:07:50.240 --> 00:07:54.920
it has to turn the steering wheel and hit the throttle or break accordingly to

122
00:07:54.921 --> 00:07:56.120
follow that trajectory.

123
00:07:56.390 --> 00:07:59.900
When we have an idea of the path we want our car to follow,

124
00:08:00.110 --> 00:08:02.270
we try to control it and to do this,

125
00:08:02.300 --> 00:08:06.560
it can sometimes be tricky like attempting a hard turn at high speed.

126
00:08:06.620 --> 00:08:10.520
This is something race car drivers are great at and computers are getting really

127
00:08:10.521 --> 00:08:11.354
good at.

128
00:08:11.420 --> 00:08:16.250
Control theory is the study of how to apply force to an object to control its

129
00:08:16.251 --> 00:08:19.250
movement.
I'm not about to dive into that right now,

130
00:08:19.251 --> 00:08:23.090
but Brian Douglas has a great video on controlled theory.

131
00:08:23.270 --> 00:08:27.440
Link to that in the video description.
Quite a lot of components,
right?

132
00:08:27.860 --> 00:08:29.930
Let's build something doable for us.

133
00:08:30.110 --> 00:08:34.880
You'd ask any has this self driving car nanodegree that's pretty popular and

134
00:08:34.881 --> 00:08:39.500
they opened sourced one of the projects involved called the behavioral cloning.

135
00:08:39.830 --> 00:08:44.660
They built this custom simulator that lets anyone drive a car and train it to

136
00:08:44.661 --> 00:08:45.950
drive by itself.

137
00:08:46.220 --> 00:08:50.930
We can build a neural network using care to try and replicate human steering

138
00:08:50.931 --> 00:08:52.610
behavior.
To do this,

139
00:08:52.611 --> 00:08:57.270
the network takes as input the frame of the frontal camera and predicts the

140
00:08:57.271 --> 00:09:01.290
steering direction had each instance.
So there's a simple mapping.

141
00:09:01.291 --> 00:09:03.750
It tries to learn between an image,

142
00:09:03.810 --> 00:09:07.080
that camera frame and a label that direction to move.

143
00:09:07.230 --> 00:09:11.700
And since all of this data can be recorded while you drive the car with the

144
00:09:11.701 --> 00:09:15.870
Arrow keys,
we can train a car on that data set easily.

145
00:09:16.170 --> 00:09:21.170
A convolutional network learns from images building increasingly abstract

146
00:09:21.240 --> 00:09:25.380
generalized representations of the image data set it learns from.

147
00:09:25.650 --> 00:09:28.380
I have a great video on convolutional nets.

148
00:09:28.410 --> 00:09:30.180
See the link in the video description.

149
00:09:30.600 --> 00:09:35.550
Students have reported that training takes anywhere from one to 24 hours on a

150
00:09:35.551 --> 00:09:38.050
laptop with all sorts of GPU gps.

151
00:09:38.250 --> 00:09:42.300
It's pretty easy to get this project up and running and I highly recommend you

152
00:09:42.301 --> 00:09:45.600
check it out.
So three points to keep in mind from this video.

153
00:09:45.900 --> 00:09:49.050
Autonomous cars are the future of transportation.

154
00:09:49.290 --> 00:09:53.670
They have already started being deployed and will one day become commonplace.

155
00:09:53.970 --> 00:09:58.830
Self driving cars,
use computer vision,
sensor,
fusion,
localization,

156
00:09:58.860 --> 00:10:02.820
path planning and control to navigate their environment.

157
00:10:03.090 --> 00:10:07.470
And we can train our own self driving car by trying out that you Udacity

158
00:10:07.471 --> 00:10:12.360
simulator on our local machines.
Hey,
you made it to the end.
You win.

159
00:10:12.540 --> 00:10:16.800
Hit the subscribe button and all your code will become free for now.

160
00:10:16.830 --> 00:10:19.860
I've got to take public transit,
so thanks for watching.

