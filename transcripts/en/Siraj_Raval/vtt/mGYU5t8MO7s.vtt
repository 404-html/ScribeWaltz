WEBVTT

1
00:00:00.400 --> 00:00:02.370
Yes,
you too.
Again,
soccer

2
00:00:04.740 --> 00:00:07.520
one day I'm going to make a Bot that beats you in any game you're telling

3
00:00:07.521 --> 00:00:10.860
yourself.
That's right.
Hello world.

4
00:00:10.890 --> 00:00:15.270
It's Saroj and let's make an amazing video game bought and just 10 lines of code

5
00:00:15.271 --> 00:00:17.250
that can play a huge variety of games.

6
00:00:17.460 --> 00:00:21.260
Could you games have been around since the 50s when Joseph Kate's publicly demos

7
00:00:21.280 --> 00:00:25.860
tic TAC toe at the Canadian National Exhibition that bought you simple scripted

8
00:00:25.861 --> 00:00:30.090
actions that ran the same way every time regardless of whatever move the player

9
00:00:30.091 --> 00:00:30.990
made his demo.

10
00:00:30.991 --> 00:00:34.890
Got People hype though because no one had ever seen a computer play a game

11
00:00:34.891 --> 00:00:37.770
before and they were lining up off the block to check it out.

12
00:00:38.010 --> 00:00:41.910
The game bots that were invented afterwards for games like Nim and space where

13
00:00:42.000 --> 00:00:44.100
we're similar,
but along came Polly.

14
00:00:44.220 --> 00:00:48.330
I mean pawn the pawn bots paddle had to make decisions based on the human

15
00:00:48.331 --> 00:00:52.260
players actions and that made it feel more realistic.
Pong mark,

16
00:00:52.261 --> 00:00:55.290
the beginning of using Kirstik's sticks to create game bots.

17
00:00:55.560 --> 00:00:59.820
Heuristics are educated guesses and pretty much every single video game bought

18
00:01:00.000 --> 00:01:02.100
since punks has used them.
A Bot.

19
00:01:02.101 --> 00:01:05.790
We'll map out a possible set of decisions as a tree of possibilities.

20
00:01:05.970 --> 00:01:09.000
Then use one of many techniques to pick the best one,

21
00:01:09.210 --> 00:01:12.390
but it's cool as that sounds.
It's still always boiled down to a bunch of,

22
00:01:12.450 --> 00:01:15.510
if then statements,
if pac man moves this way,

23
00:01:15.540 --> 00:01:19.620
then the blue goes should move this way.
If master chief sees a grunt,

24
00:01:19.770 --> 00:01:22.290
then it should run in circles like my Facebook newsfeed.

25
00:01:22.530 --> 00:01:24.570
If Captain Falcon is being annoying Aaf,

26
00:01:24.780 --> 00:01:28.080
then your team bought should help you pawn him.
Squad goals,
but yeah,

27
00:01:28.110 --> 00:01:31.740
video game bots are pretty much always sucked because there are only so many

28
00:01:31.741 --> 00:01:33.750
edge cases that a programmer can predict.

29
00:01:33.751 --> 00:01:38.280
Like if the human in fallout three has a pistol and isn't moving and there are

30
00:01:38.281 --> 00:01:40.620
no enemies nearby,
run into each other,

31
00:01:41.610 --> 00:01:43.650
we need to think about this problem differently.

32
00:01:43.830 --> 00:01:46.290
When you or I start playing a game,

33
00:01:46.440 --> 00:01:49.200
we don't know anything about its environment beforehand.

34
00:01:49.410 --> 00:01:53.190
The hallmark of intelligence,
it's our ability to generalize,

35
00:01:53.430 --> 00:01:58.320
but can we make artificial intelligence that can generalize to solve any task?

36
00:01:58.380 --> 00:02:03.210
A team of researchers at deepmind recently got close by creating one bot that

37
00:02:03.211 --> 00:02:05.190
could be almost any Atari game.

38
00:02:05.340 --> 00:02:07.770
Knowing literally nothing about the game beforehand.

39
00:02:08.040 --> 00:02:10.470
No gain specific hard coded rules at all.

40
00:02:10.650 --> 00:02:14.820
It was just fed the raw pixels of the game and it's controls using those two

41
00:02:14.821 --> 00:02:18.030
things.
It learned how to be almost any Atari game it was given.

42
00:02:18.210 --> 00:02:21.090
It did this using a technology called deep learning.

43
00:02:21.240 --> 00:02:24.840
If you take a deep neural network and feed it lots of data and compute,

44
00:02:24.870 --> 00:02:27.390
it can learn to do a whole lot of incredible things.

45
00:02:27.450 --> 00:02:31.320
The field of deep learning right now is where physics was in the early 19

46
00:02:31.321 --> 00:02:35.130
hundreds the state of the art in a huge number of subfields like vision and

47
00:02:35.131 --> 00:02:37.950
speech is being broken almost every other day.

48
00:02:38.100 --> 00:02:42.180
It's a very exciting time right now and Marie curies and Albert Einstein's of

49
00:02:42.181 --> 00:02:46.510
computer science are all alive right now and newcomers are coming in every day.

50
00:02:46.680 --> 00:02:50.130
Deepmind is awesome and they keep a good chunk of their code private since

51
00:02:50.131 --> 00:02:52.650
Google uses it to outperform its competitors.

52
00:02:52.680 --> 00:02:54.840
But then Elon Musk came along and it was all like,

53
00:02:54.890 --> 00:02:58.470
I think it's important if we have this incredible power of AI that if not be

54
00:02:58.471 --> 00:02:59.860
concentrated in the hands of a few.

55
00:02:59.920 --> 00:03:03.040
And so he co founded a nonprofit called open AI,

56
00:03:03.190 --> 00:03:06.340
whose goal is to democratize AI so anyone can use it.

57
00:03:06.580 --> 00:03:09.040
And just today they released something called universe.

58
00:03:09.280 --> 00:03:13.600
Universe is a platform that lets you build a Bot and test it out in thousands of

59
00:03:13.601 --> 00:03:17.530
different environments from games as simple as space invaders to grand theft

60
00:03:17.531 --> 00:03:21.130
auto to protein folding simulations that could cure cancer.

61
00:03:21.370 --> 00:03:23.740
You can create a Bot and the better you make it,

62
00:03:23.860 --> 00:03:26.380
the more games it'll learn to become amazing at.

63
00:03:26.590 --> 00:03:30.010
You can compete with other Bot developers to see who's bought beats.

64
00:03:30.011 --> 00:03:34.420
The most games and universe has other environments to or web interface tasks

65
00:03:34.421 --> 00:03:36.940
like managing emails and booking flights.

66
00:03:37.180 --> 00:03:40.030
If you create a Bot that's able to defeat any environment,

67
00:03:40.330 --> 00:03:44.470
you're not only the dopest coder of all time,
you just solved intelligence.

68
00:03:44.500 --> 00:03:48.970
We could then use your bot to solve literally everything from global warming to

69
00:03:48.971 --> 00:03:51.190
poverty to all known diseases.

70
00:03:53.830 --> 00:03:58.270
So with that,
let's create our first simple bot in just 10 lines of python code.

71
00:03:58.570 --> 00:04:02.080
In our first two lines of code,
we'll import Jim and universe.

72
00:04:02.200 --> 00:04:04.720
Gym Is Open Ai's original code base.

73
00:04:04.750 --> 00:04:08.770
That universe builds on and extends to include way more environments and

74
00:04:08.771 --> 00:04:11.680
features.
Those are the only two dependencies will need.

75
00:04:11.920 --> 00:04:13.840
Now we can select our environment.

76
00:04:14.020 --> 00:04:17.290
We'll define an environment variable called ENV and use.

77
00:04:17.291 --> 00:04:20.140
Jim's make method to define our environment parameter.

78
00:04:20.320 --> 00:04:22.630
There's so many to choose from.
It's hard to pick,

79
00:04:22.631 --> 00:04:25.810
but let's go ahead and pick the popular flash game coaster racer.

80
00:04:25.960 --> 00:04:29.710
Universe lets us run as many environments at the same time as we want,

81
00:04:29.860 --> 00:04:34.210
but for now let's just use one.
Our next step is to initialize our environment.

82
00:04:34.300 --> 00:04:38.530
With the reset method,
it will return a list of what we call observations.

83
00:04:38.650 --> 00:04:42.550
For every environment we've initialized an observation is an environment

84
00:04:42.551 --> 00:04:45.910
specific object that represents what the agent observes,

85
00:04:46.060 --> 00:04:49.210
like Pixel data of what it sees and the state of the game.

86
00:04:49.480 --> 00:04:53.380
Initially we'll just have an empty set of observations since the game hasn't

87
00:04:53.381 --> 00:04:55.930
started yet.
Now that we've initialize our environment.

88
00:04:55.960 --> 00:04:59.320
Let's go ahead and create a while statement so our agent will just keep running

89
00:04:59.321 --> 00:05:02.560
indefinitely.
We're just going to have our Bot do one simple thing.

90
00:05:02.620 --> 00:05:04.030
It's going to hit the up Arrow.

91
00:05:05.470 --> 00:05:09.850
This is formatted by first specifying the type of event,
the key then true,

92
00:05:09.880 --> 00:05:13.600
which means press it and we'll do this for each environments observation.

93
00:05:13.630 --> 00:05:16.570
We'll call this an action and store it in our action variable.

94
00:05:16.840 --> 00:05:21.070
Now we'll call our environment step method to move forward one time step and use

95
00:05:21.071 --> 00:05:22.540
the action as a perimeter.

96
00:05:22.690 --> 00:05:26.920
This is our implementation of reinforcement learning are Bot will take an action

97
00:05:26.950 --> 00:05:28.540
in our case pushing the up arrow.

98
00:05:28.660 --> 00:05:32.350
Then it will observe the result and may or may not receive a reward if that

99
00:05:32.351 --> 00:05:34.390
action was beneficial to its goal,

100
00:05:34.480 --> 00:05:36.700
which in our case is increasing the game score.

101
00:05:36.730 --> 00:05:41.320
Open AI uses a custom image recognition module here to read the game score in

102
00:05:41.321 --> 00:05:44.890
order to return.
A reward is module is included in the environment,

103
00:05:44.891 --> 00:05:47.620
so we don't need to worry about it.
If it doesn't receive a reward,

104
00:05:47.770 --> 00:05:51.430
we could update our Bot to do similar actions in the future so it gets better

105
00:05:51.431 --> 00:05:52.960
over time through trial and error.

106
00:05:53.020 --> 00:05:57.260
So the step method returns for variables and observation of the environment or

107
00:05:57.261 --> 00:06:02.150
reward a yes or no value if the game has done and some info like performance

108
00:06:02.151 --> 00:06:04.070
timings and latencies for debugging,

109
00:06:04.100 --> 00:06:08.300
and it'll do this for all the environments you train your Bot in simultaneously.

110
00:06:08.450 --> 00:06:11.270
Lastly,
it will render the environment so it's visible to us.

111
00:06:11.330 --> 00:06:12.620
Let's demo this baby.

112
00:06:12.800 --> 00:06:16.880
I'll run the code and terminal and it'll connect to our VNC server in our local

113
00:06:16.881 --> 00:06:20.090
docker container running a flash enabled chrome browser.

114
00:06:20.150 --> 00:06:23.600
The pre scripted mouse will click through the necessary screens to get the game

115
00:06:23.601 --> 00:06:27.650
started.
Then our Bot,
we'll start programmatically controlling the game remotely.

116
00:06:27.770 --> 00:06:30.770
Yeah,
our Bot really sucks,
but how dope is this?

117
00:06:30.920 --> 00:06:34.370
We can do this for as many games as we'd like and to make it better,

118
00:06:34.371 --> 00:06:38.750
we can try different strategies like random search or he'll climbing or just

119
00:06:38.751 --> 00:06:40.280
replicate what deepmind did.

120
00:06:40.520 --> 00:06:43.970
They fed the observations that they're bought received into a neural network

121
00:06:44.030 --> 00:06:47.420
that updated its connections to get better if it received a reward.

122
00:06:47.450 --> 00:06:51.860
Open Ai already has a starter bot that uses deep reinforcement learning via

123
00:06:51.880 --> 00:06:55.640
tensorflow that I'll put a link to in the description.
And so to break it down,

124
00:06:55.660 --> 00:07:00.530
open AI's universe is a platform that lets you train and test bots or thousands

125
00:07:00.531 --> 00:07:02.060
of games and other environments.

126
00:07:02.090 --> 00:07:04.730
Reinforcement learning is the process of using trial and error.

127
00:07:04.880 --> 00:07:06.890
Similar to how we learn to improve a bot.

128
00:07:07.130 --> 00:07:10.460
And if you create one Bot that can succeed in any environment,

129
00:07:10.461 --> 00:07:12.620
it's given you just solved intelligence.

130
00:07:12.860 --> 00:07:17.390
The coding challenge for this video is to create a Bot or just Kosta racer that

131
00:07:17.391 --> 00:07:19.450
is better than this is demo code posts.

132
00:07:19.451 --> 00:07:22.310
You'll get humbling in the comments and I'll give a shout out to the winner in

133
00:07:22.311 --> 00:07:27.080
my video one week from today and I'll do a one on one Google hangout with them

134
00:07:27.081 --> 00:07:29.090
just to say hi and talking about whatever.

135
00:07:29.390 --> 00:07:33.290
For now I've got to make a laundry folding robot,
so thanks for watching.

