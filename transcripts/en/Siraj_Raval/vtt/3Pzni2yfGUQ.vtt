WEBVTT

1
00:00:00.060 --> 00:00:00.893
The data

2
00:00:02.970 --> 00:00:05.640
ready to make the data wit hello world.

3
00:00:05.670 --> 00:00:10.670
It's Iraj and welcome to data lit my free 12 week intro to data science course,

4
00:00:11.430 --> 00:00:15.270
our release all my videos right here on my youtube channels.
So if you're new,

5
00:00:15.271 --> 00:00:20.070
click subscribe to stay updated.
If you want access to the weekly quizzes,

6
00:00:20.130 --> 00:00:24.360
supplementary content from my assistant instructors and support,

7
00:00:24.540 --> 00:00:29.100
you can register for the course on the school of AI website using the link in

8
00:00:29.101 --> 00:00:32.390
the video description.
A quick Google search for the terms.

9
00:00:32.400 --> 00:00:37.400
Data scientist will bring up headlines like the job of the future or the sexiest

10
00:00:37.501 --> 00:00:41.340
job of the century.
Smell like data science.

11
00:00:41.520 --> 00:00:45.660
The reason being,
as more businesses come online every day,

12
00:00:45.780 --> 00:00:47.340
they're collecting more data.

13
00:00:47.490 --> 00:00:52.490
We're collectively generating over 28 k gigs of data every minute of every day

14
00:00:52.980 --> 00:00:57.150
and the businesses that are leading the charge in their industries are the ones

15
00:00:57.151 --> 00:01:00.810
using that data to make decisions and increase their revenue.

16
00:01:00.930 --> 00:01:03.870
Unlike apple data,
science is here to stay.

17
00:01:03.900 --> 00:01:06.330
It applies to virtually any industry.

18
00:01:06.480 --> 00:01:09.750
It pays very well and it's a respectable field to work in.

19
00:01:09.900 --> 00:01:14.400
What's not to like about it besides are the best part is that the tools of data

20
00:01:14.401 --> 00:01:19.230
science have been democratized to the point where anyone can do it if they have

21
00:01:19.231 --> 00:01:23.940
the drive to anywhere in the world,
whether it's working with transactional data,

22
00:01:24.000 --> 00:01:26.880
social data,
scientific data or sensor data.

23
00:01:27.060 --> 00:01:31.230
Being able to know how to properly extract insights is a primary skill for data

24
00:01:31.231 --> 00:01:35.550
scientists in this video will play the role of a data scientist at a startup

25
00:01:35.670 --> 00:01:38.610
making a new device that monitors a patient's heartbeat.

26
00:01:38.880 --> 00:01:43.620
Our job is to do some market research and figure out how consumers feel about

27
00:01:43.621 --> 00:01:46.950
the main competitor to our product.
The Apple Watch,

28
00:01:47.250 --> 00:01:49.110
there are several ways to do this,

29
00:01:49.200 --> 00:01:53.400
but the most straightforward way is to go to Twitter and search for mentions of

30
00:01:53.401 --> 00:01:54.450
the Apple Watch.

31
00:01:54.510 --> 00:01:59.460
We could naively just manually observed that data ourselves by scrolling

32
00:01:59.461 --> 00:02:02.490
endlessly to try to get a feel for people's opinions,

33
00:02:02.700 --> 00:02:06.990
but we're going to implement a more thorough scalable driven process by

34
00:02:06.991 --> 00:02:09.480
performing what's called sentiment analysis.

35
00:02:09.780 --> 00:02:12.270
Another word for this is opinion mining.

36
00:02:12.480 --> 00:02:16.710
This is a data science technique that centers around building systems that can

37
00:02:16.740 --> 00:02:19.980
identify and extract opinions within text,

38
00:02:20.280 --> 00:02:23.100
but usually besides just identifying an opinion,

39
00:02:23.280 --> 00:02:27.750
these systems can extract attributes of the expression like the polarity meaning

40
00:02:27.751 --> 00:02:32.340
if the speaker is expressing a positive or negative opinion since publicly and

41
00:02:32.341 --> 00:02:36.570
privately available,
data over the Internet is growing exponentially.

42
00:02:36.810 --> 00:02:41.640
Huge amounts of texts expressing opinions are available on review sites,
forums,

43
00:02:41.641 --> 00:02:42.960
blogs,
social media,

44
00:02:43.110 --> 00:02:47.940
and the best dinosaur.com sentiment analysis can help craft this unstructured

45
00:02:47.941 --> 00:02:52.860
information into structured data on public opinions about products and brands.

46
00:02:53.100 --> 00:02:56.910
Any topic that people can express opinions about.
If you think about it,

47
00:02:56.940 --> 00:03:00.670
all texts information can be categorized,
either fact or opinion.

48
00:03:00.880 --> 00:03:05.710
Sentiment analysis then can be modeled as a classification problem where to sub

49
00:03:05.711 --> 00:03:07.210
problems need to be resolved.

50
00:03:07.450 --> 00:03:11.560
The first being is this text and opinion or not and the second big,

51
00:03:11.740 --> 00:03:15.310
what is its polarity.
There are different types of opinions as well.

52
00:03:15.490 --> 00:03:18.490
Direct opinions given an opinion about an entity directly.

53
00:03:18.730 --> 00:03:22.540
A comparative opinion is expressed by comparing one entity to another.

54
00:03:22.770 --> 00:03:27.280
On the explicit opinion on a subject is expressed directly on implicit opinion

55
00:03:27.310 --> 00:03:30.790
is implied.
The most difficult type of opinion to analyze,

56
00:03:30.791 --> 00:03:34.540
we'd likely be metaphors and that they include a lot of related semantic

57
00:03:34.541 --> 00:03:39.040
information.
We can choose to perform sentiment analysis at the document level,

58
00:03:39.130 --> 00:03:41.620
sentence level,
or even sub sentence level,

59
00:03:41.710 --> 00:03:45.700
and we can focus on any number of ways of analyzing the sentiment.

60
00:03:45.880 --> 00:03:49.360
We can turn polarity into a larger,
more detailed spectrum.

61
00:03:49.570 --> 00:03:53.320
We can classify specific emotions like happiness and frustration.

62
00:03:53.560 --> 00:03:58.180
We can choose to analyze the sentiment of how a customer feels about only one

63
00:03:58.181 --> 00:03:59.560
aspect of a product.

64
00:03:59.770 --> 00:04:03.490
Try to decipher someone's intent and if we're feeling really ambitious,

65
00:04:03.640 --> 00:04:07.450
apply sentiment analysis across languages,
Russian texts,

66
00:04:07.451 --> 00:04:09.160
we'll probably analyze you instead.

67
00:04:09.550 --> 00:04:14.230
Clearly there are a lot of ways of framing our task,
so how do we do all of this?

68
00:04:14.470 --> 00:04:17.770
There are two major ways we can implement sentiment analysis.

69
00:04:18.070 --> 00:04:20.980
The first way is to use a rule based system.

70
00:04:21.160 --> 00:04:25.600
These perform sentiment analysis based on a set of manually crafted rules.

71
00:04:25.900 --> 00:04:29.410
These rules identify things like subjectivity and polarity.

72
00:04:29.530 --> 00:04:31.120
By utilizing a lexicon.

73
00:04:31.420 --> 00:04:35.830
A lexicon is a dictionary of positive and negative opinion words and

74
00:04:35.831 --> 00:04:40.270
expressions.
There are several out there that are freely available to use.

75
00:04:40.360 --> 00:04:40.961
For example,

76
00:04:40.961 --> 00:04:45.760
the center words lexicon contains over one 55 k English words with their

77
00:04:45.761 --> 00:04:47.800
associated polarity scores.

78
00:04:47.980 --> 00:04:52.420
A basic example of a rule based method would be to defined two lists of

79
00:04:52.421 --> 00:04:55.210
polarized words,
both negative and positive.

80
00:04:55.570 --> 00:04:59.440
Then given a text count the number of positive and negative words that

81
00:04:59.460 --> 00:05:00.293
appearance,

82
00:05:00.400 --> 00:05:04.090
if the number of positive words is greater than the negative word count,

83
00:05:04.210 --> 00:05:08.830
return a positive sentiment else return negative if it's the same amount,

84
00:05:08.920 --> 00:05:12.700
return neutral.
See,
that wasn't so hard yet.

85
00:05:13.030 --> 00:05:17.500
Obviously we can add support for new expressions and vocabulary by creating new

86
00:05:17.501 --> 00:05:20.200
rules,
but that can serve as a basic example

87
00:05:22.050 --> 00:05:26.170
<v 1>snake to find the good and bad structured text.</v>

88
00:05:26.820 --> 00:05:31.820
Good Ma analyzers somewhere on her rogue nags.

89
00:05:32.530 --> 00:05:37.530
<v 0>The second way to do sentiment analysis is to use an automatic method one that</v>

90
00:05:37.931 --> 00:05:41.620
doesn't rely on rules,
but instead on machine learning,

91
00:05:41.890 --> 00:05:46.600
we can model this as a classification problem where some given algorithm is fed

92
00:05:46.601 --> 00:05:51.220
text and returns a corresponding polarity.
During the training process,

93
00:05:51.221 --> 00:05:56.221
the algorithm learns to associate a particular input with a particular output

94
00:05:56.650 --> 00:05:58.760
using an optimization strategy.

95
00:05:59.240 --> 00:06:02.810
There are several classification algorithms we could use for this,

96
00:06:02.900 --> 00:06:05.840
but for now let's stick with a rule based system.

97
00:06:06.290 --> 00:06:11.150
The automated approach is easier to scale and usually offers more accurate

98
00:06:11.151 --> 00:06:13.370
results,
but it requires training.

99
00:06:13.371 --> 00:06:18.260
Data to learn from the rule based approach requires no training process and it's

100
00:06:18.290 --> 00:06:21.140
easier to debug.
This is a good starting point.

101
00:06:21.410 --> 00:06:23.600
We're going to use Twitter as our data source here.

102
00:06:23.601 --> 00:06:28.370
It's rich with public opinion data,
but in order to extract tweets for analysis,

103
00:06:28.580 --> 00:06:33.580
we to access our Twitter account and create an APP from apps.twitter.com from

104
00:06:33.591 --> 00:06:37.400
this app we're creating,
we're going to save the following four variables,

105
00:06:37.610 --> 00:06:42.410
the consumer key consumer secret access token and access token secret,

106
00:06:42.560 --> 00:06:45.110
which we'll use to access the Twitter API.

107
00:06:45.470 --> 00:06:49.370
Now we're going to write this script in the browser using Google's Colab,

108
00:06:49.490 --> 00:06:51.620
a python environment in the cloud.

109
00:06:52.010 --> 00:06:54.200
If this is the first time you've coated before,

110
00:06:54.350 --> 00:06:58.670
welcome to the wonderful world of programming in python.
There's no turning back.

111
00:06:58.730 --> 00:07:02.360
We're going to first install several libraries that we'll use in our sentiment

112
00:07:02.361 --> 00:07:07.160
analysis app.
Using the pip install command,
pandas will help us perform data.

113
00:07:07.161 --> 00:07:11.810
Preprocessing tweet pie will let us access to Twitter,
API and Bader.

114
00:07:11.840 --> 00:07:15.830
We'll let us perform the actual sentiment analysis by looking up words in.

115
00:07:15.831 --> 00:07:19.040
It's built in lexicon.
Once we've installed our libraries,

116
00:07:19.041 --> 00:07:20.870
we can import them one by one.

117
00:07:21.020 --> 00:07:25.490
Then we can use the Twitter Api Library tweet pie to extract a list of tweets

118
00:07:25.580 --> 00:07:28.910
that mentioned the Apple Watch.
By specifying it as a keyword.

119
00:07:29.120 --> 00:07:34.010
We can set this count to 200 so we'll get 200 tweets.
If we print out the tweaks,

120
00:07:34.011 --> 00:07:36.410
we can see each of them in a list format.

121
00:07:36.740 --> 00:07:38.960
This collection of tweets is our dataset.

122
00:07:39.200 --> 00:07:41.450
Now that we have that initial information,

123
00:07:41.660 --> 00:07:45.980
we need to reformat it so that it's easier to process for sentiment analysis.

124
00:07:46.370 --> 00:07:51.020
The pandas library will allow us to manipulate the info in a simple way by

125
00:07:51.021 --> 00:07:53.450
converting it into a data frame object.

126
00:07:53.750 --> 00:07:57.920
Think of it like a spreadsheet with rows and columns.
Once we have a data frame,

127
00:07:57.921 --> 00:08:02.150
we can access some of the tweets metadata by using one of several attributes,

128
00:08:02.330 --> 00:08:06.710
so there's a lot of data that we can get from a single tweet but not all of this

129
00:08:06.711 --> 00:08:10.040
data is always useful for our goal,
so if we'd like,

130
00:08:10.041 --> 00:08:14.450
we can remove some of this data before we perform sentiment analysis.

131
00:08:14.451 --> 00:08:19.400
We want to clean our text data so that any character that isn't an Alpha numeric

132
00:08:19.401 --> 00:08:23.600
value will be remapped into a new one that satisfies this condition.

133
00:08:23.930 --> 00:08:24.411
To do that,

134
00:08:24.411 --> 00:08:28.220
we can use the real library which is used to work with regular expressions.

135
00:08:28.610 --> 00:08:31.820
This is a sequence of characters that define a search pattern.

136
00:08:32.060 --> 00:08:36.140
Usually this pattern is used by string searching algorithms for doing search and

137
00:08:36.141 --> 00:08:37.370
replace in strings.

138
00:08:37.760 --> 00:08:42.760
The Bader library is a lexicon and rule based sentiment analysis tool that is

139
00:08:42.861 --> 00:08:46.700
specifically attuned to sentiments expressed in social media.

140
00:08:47.000 --> 00:08:51.530
It actually stands for Bailyn's aware dictionary and sentiments reasoner.

141
00:08:51.980 --> 00:08:55.130
There is no machine learning occurring here.
This library,

142
00:08:55.140 --> 00:08:59.640
we'll parse any string input by searching for polarity scores for each word and

143
00:08:59.641 --> 00:09:02.340
it's lexicon and return a full score.

144
00:09:02.730 --> 00:09:05.070
In order to place these results in our data frame,

145
00:09:05.130 --> 00:09:07.560
we'll just add an extra column to our data.

146
00:09:07.830 --> 00:09:11.850
This column is going to contain the sentiment analysis and we can plot the data

147
00:09:11.851 --> 00:09:13.050
frame to see the updates.

148
00:09:13.080 --> 00:09:17.250
Now we can print out our results and see what the overall score was.

149
00:09:17.440 --> 00:09:19.530
It looks like people like their apple watches.

150
00:09:19.531 --> 00:09:23.940
We might need to think of a different product or do some more in depth market

151
00:09:23.941 --> 00:09:28.140
analysis by figuring out what part of the Apple Watch they dislike the most.

152
00:09:28.141 --> 00:09:31.920
That gave us pretty good signal,
a public sentiment about the Apple Watch,

153
00:09:32.070 --> 00:09:36.330
but if we wanted to scale our app to apply sentiment analysis to millions of

154
00:09:36.331 --> 00:09:37.110
tweets,

155
00:09:37.110 --> 00:09:42.000
we'd probably want to use an automated approach instead of a rule based
approach.

156
00:09:42.270 --> 00:09:47.130
There are a huge number of powerful tools that exist today that make this kind

157
00:09:47.131 --> 00:09:51.720
of capability really easy to implement from the psychic learn library in python

158
00:09:51.721 --> 00:09:53.280
to WeChat in Java,

159
00:09:53.400 --> 00:09:57.030
all we need is a Dataset with at least 10 k examples to learn from.

160
00:09:57.270 --> 00:09:59.160
But that's a topic for another lesson.

161
00:09:59.490 --> 00:10:01.950
There are three points to remember from this video.

162
00:10:02.220 --> 00:10:06.180
Sentiment analysis is a technique that involves building systems that can

163
00:10:06.181 --> 00:10:09.240
identify and extract opinions from text.

164
00:10:09.510 --> 00:10:13.920
It can be rule based matching words with sentiment scores from a lexicon or

165
00:10:13.921 --> 00:10:14.551
automated,

166
00:10:14.551 --> 00:10:18.930
where a trained pattern matching algorithm will predict a words that sentiment.

167
00:10:19.170 --> 00:10:24.170
And we can build a sentiment analyzer in a few lines of python using the Twitter

168
00:10:24.240 --> 00:10:25.830
Api and debater python framework.

169
00:10:25.950 --> 00:10:28.060
And what do you want to use sentiment analysis for?

170
00:10:28.061 --> 00:10:30.540
And let me know in the comments section and please subscribe for more

171
00:10:30.541 --> 00:10:35.010
programming videos.
For now,
I'm going to find my polarity.
So thanks for watching.

