WEBVTT

1
00:00:07.360 --> 00:00:10.760
Oh world.
It's the Raj and welcome to this live stream.
Uh,

2
00:00:10.780 --> 00:00:15.780
today we're going to be generating m and I s t digit,

3
00:00:15.970 --> 00:00:19.570
uh,
images with a variational auto encoder.

4
00:00:19.600 --> 00:00:23.050
Now I know what you might be thinking.
M and ice tea,
not again,

5
00:00:23.240 --> 00:00:25.060
it's please know m and ist.

6
00:00:25.450 --> 00:00:28.660
You might be thinking I'm just screw this.

7
00:00:28.661 --> 00:00:31.810
You might be trying to get out of the live stream,
but I'm telling you stop.
Okay?

8
00:00:31.811 --> 00:00:33.600
Because this is not about Emma and ist.

9
00:00:33.850 --> 00:00:36.610
This is about something much cooler than him.
And ice tea.

10
00:00:36.850 --> 00:00:38.920
This is about generative models,

11
00:00:38.921 --> 00:00:41.980
specifically my current favorite type of generative model,

12
00:00:41.981 --> 00:00:45.760
the variational auto encoder.
Okay?
This is going to be dope.

13
00:00:45.820 --> 00:00:48.640
We can even generate Pokemon with this.
Okay.
And we're going to look into that.

14
00:00:48.641 --> 00:00:51.130
So sit tight because that's going to be dope.
Who want,

15
00:00:51.131 --> 00:00:55.780
who doesn't want to make Pokemon?
I do.
Okay,
so,
hi everybody.

16
00:00:55.781 --> 00:00:56.680
Thanks for coming in.

17
00:00:56.980 --> 00:01:01.120
I'm going to start off with a two minute Q and a and then I'm going to go right

18
00:01:01.121 --> 00:01:04.240
into the code.
Okay?
I've got this ipython notebook,

19
00:01:04.241 --> 00:01:06.550
Jupiter notebook and it's got the images in there,

20
00:01:06.551 --> 00:01:10.780
but I'm going to be coding all of it live and a,
yeah,
so it's gonna be awesome.

21
00:01:11.080 --> 00:01:16.080
So let's get down to business to defeat determinism.

22
00:01:17.680 --> 00:01:22.630
Okay.
So do we have any questions because I love answering them.

23
00:01:23.630 --> 00:01:27.400
All right,
so any questions about AI,
machine learning,
deep learning,

24
00:01:27.401 --> 00:01:29.620
all of it is all good.
You know,

25
00:01:29.621 --> 00:01:34.000
so just just throw them at me and I will definitely be the person to,

26
00:01:34.450 --> 00:01:35.890
to answer them.
Okay.

27
00:01:36.340 --> 00:01:41.340
So Hi everybody from Columbia and India and Pokemon and Hydro Bot and all over

28
00:01:42.881 --> 00:01:43.331
the place.

29
00:01:43.331 --> 00:01:48.280
We have over 150 countries represented in this community and we almost have

30
00:01:48.281 --> 00:01:52.870
100,000 subscribers making us the largest AI community in the world.

31
00:01:53.320 --> 00:01:55.630
So it's a huge deal right now we are making history.

32
00:01:55.631 --> 00:01:57.490
You guys are a part of history.

33
00:01:57.820 --> 00:02:00.790
So Matt Camp will asks,

34
00:02:01.780 --> 00:02:04.960
can you cover or maybe mentioned clustering?
So that's a great question.

35
00:02:05.230 --> 00:02:08.800
In this course,
this is a part of a course.
Remember guys,
a series of,

36
00:02:09.250 --> 00:02:13.390
of data points of knowledge that we are,
we are building off of over time.

37
00:02:13.391 --> 00:02:16.390
And so right now we are finally on unsupervised learning.

38
00:02:16.690 --> 00:02:19.630
So what is one technique to learn from,

39
00:02:19.870 --> 00:02:24.520
from data that without labels clustering.
So,
uh,
with for clustering,

40
00:02:25.420 --> 00:02:30.130
we are going to talk about clustering at the end.
Yes.
We'll,

41
00:02:30.131 --> 00:02:33.930
we'll talk about clustering.
Not Like k means clustering,
uh,

42
00:02:34.000 --> 00:02:36.430
which is the most popular type what we're talking about,

43
00:02:36.431 --> 00:02:38.710
clustering in an embedded space.
Okay.

44
00:02:38.711 --> 00:02:41.980
So that's clustering in terms of the latent space that's we're going to go over.

45
00:02:42.070 --> 00:02:44.590
So one more question and then we'll get it.
We're going to get started with this.

46
00:02:44.591 --> 00:02:49.030
Okay.
So Akshay Bhatia asks thoughts on cafe too.
Okay.

47
00:02:49.031 --> 00:02:52.630
So here are my thoughts on cafe one through five.
No,

48
00:02:52.660 --> 00:02:57.130
just no is my thoughts on it.
Don't use it.
Use tensorflow.
Use Pi torch.

49
00:02:57.400 --> 00:02:58.660
Don't use cafe.
Why?

50
00:02:58.661 --> 00:03:03.320
Because cafe makes you define models,
uh,

51
00:03:04.240 --> 00:03:07.360
through what are those?
Like Jason Files?
No,
you want to,

52
00:03:07.361 --> 00:03:10.780
you want to define your models programmatically.
Why?
For modularity?

53
00:03:10.781 --> 00:03:13.060
Because you want to call them through different parts of your code.

54
00:03:13.300 --> 00:03:16.810
You don't want to just define some static file that you then have to go into and

55
00:03:17.200 --> 00:03:21.000
um,
there's not,
there's not a lot of reusability with cafe.
Um,

56
00:03:21.100 --> 00:03:23.590
internally within cafe there's a lot of reusability,

57
00:03:23.591 --> 00:03:27.190
but you can't really use it with other frameworks as easily because it's not

58
00:03:27.191 --> 00:03:31.100
programmatic.
Okay.
So that's it for the questions.
Actually,
one more.
This is,

59
00:03:31.101 --> 00:03:32.200
it's actually a very good question.

60
00:03:32.440 --> 00:03:37.440
Could auto encoding be usefully applied to generate genomic sequences?

61
00:03:38.710 --> 00:03:42.220
Yes,
absolutely.
You could.
Absolutely.
Because remember an auto encoder,

62
00:03:42.221 --> 00:03:45.190
and we're going to talk about this reconstructs the input data.

63
00:03:45.550 --> 00:03:49.270
So that's exactly,
so you could reconstruct genomic sequences,

64
00:03:49.271 --> 00:03:51.610
but you could also generate novel genomic sequences.

65
00:03:51.970 --> 00:03:56.260
You could have you seen the movie Jurassic Park.
We could make that happen.

66
00:03:56.470 --> 00:03:57.490
I'm dead serious.

67
00:03:57.640 --> 00:04:02.640
We could generate DNA sequences of velociraptors and t Rex's by reading datasets

68
00:04:04.840 --> 00:04:05.673
of,

69
00:04:05.920 --> 00:04:10.920
of current mammals and then extrapolating or what's the reverse of extrapolating

70
00:04:11.590 --> 00:04:15.160
back into the past and trying to find those base pairs from,

71
00:04:15.220 --> 00:04:17.680
from which everything else sprung up from.

72
00:04:17.950 --> 00:04:20.440
So there's a lot of cool stuff coming.
Okay,

73
00:04:20.441 --> 00:04:24.640
so we are just at the beginning of this.
Let's get started.
Okay.
Okay.

74
00:04:24.670 --> 00:04:28.790
Ganzer coming next.
So let's get started with this.
Uh,

75
00:04:28.900 --> 00:04:32.320
we've got 333 people live,
so this is gonna be amazing.
Let me,

76
00:04:32.380 --> 00:04:34.330
let me make this bigger.
So,

77
00:04:34.840 --> 00:04:39.840
generative models model a distribution of data over high dimensional space.

78
00:04:40.090 --> 00:04:43.360
What does that mean?
So this image is a little weird because it starts with Czi.

79
00:04:43.570 --> 00:04:46.390
So Czi is the latent space.
So what do I mean by that?

80
00:04:47.260 --> 00:04:50.290
Czi is after we've encoded some data,

81
00:04:50.350 --> 00:04:53.020
we have then represented it in some,
right?

82
00:04:53.021 --> 00:04:55.690
We have a representation of some high dimensional data.

83
00:04:55.900 --> 00:04:58.150
And what do I mean by high dimensional?
Well,

84
00:04:58.180 --> 00:05:02.590
even an Mni is t digit image is 784 dimensions.
So the,

85
00:05:02.591 --> 00:05:04.570
these dimensions are pixels,
right?

86
00:05:04.571 --> 00:05:08.050
784 because it's a 28 by 28 image,
right?

87
00:05:08.051 --> 00:05:12.040
So 784 dimensions.
We've taken the 784 dimensional data,

88
00:05:12.050 --> 00:05:14.800
Pii data piece,
data point,

89
00:05:15.100 --> 00:05:18.310
and we've compressed it into a lower dimensional space.

90
00:05:18.380 --> 00:05:22.390
That could be like 10 or 12 or 20 dimensions.
It's a representation.

91
00:05:22.660 --> 00:05:26.920
But what happens when we in compressed data always there is some loss of that

92
00:05:26.921 --> 00:05:29.680
data.
It's lossy.
So,
so,
uh,

93
00:05:29.681 --> 00:05:34.681
we take that lossy small dimensional representation and we generate and we

94
00:05:35.381 --> 00:05:39.550
reconstruct the original input with this yellow part,
right?
So this is the,

95
00:05:39.551 --> 00:05:43.240
so it's already been encoded into z and then we decode it and then we create a

96
00:05:43.241 --> 00:05:46.420
generated distribution of this data.
Okay?
So what do I mean by that?

97
00:05:47.500 --> 00:05:49.840
So let me,
let me say two things.

98
00:05:49.841 --> 00:05:54.100
The first thing is that latent is the same as embedding.

99
00:05:54.130 --> 00:05:56.200
It means the same as hidden.
Okay?
These are just,

100
00:05:57.080 --> 00:05:59.990
when it comes to cicastic models,
when it comes to generative models,

101
00:06:00.230 --> 00:06:03.110
only now do we start using the word latent.
Because I dunno,

102
00:06:03.111 --> 00:06:06.560
Bays just like the word Layton,
but it means the same thing.
Don't be confused.

103
00:06:06.740 --> 00:06:11.660
Latent embedding hidden.
It means the same thing.
Okay?
So then distribution,

104
00:06:11.661 --> 00:06:15.080
what do I mean by distribution?
Right?
You can think of a tutee distribution.

105
00:06:15.110 --> 00:06:18.980
A tutee distribution is that is that bell curve,
right?
It's a golf Sian curve.

106
00:06:19.160 --> 00:06:22.070
So that's a two d distribution.
But how do you,
what?

107
00:06:22.071 --> 00:06:24.320
What even is a distribution in general?

108
00:06:24.590 --> 00:06:29.570
A distribution is a realm of possibility.
Okay?
It's a realm of possibility.

109
00:06:29.750 --> 00:06:34.750
What are all the possible values that some piece of data can be contained in?

110
00:06:35.151 --> 00:06:39.380
What is the wall that it can be contained in,
and that is what a distribution is.

111
00:06:39.590 --> 00:06:44.090
A high dimensional distribution represents the realm of possibility of all the

112
00:06:44.091 --> 00:06:45.800
values from some dataset.
Okay,

113
00:06:46.040 --> 00:06:49.580
so we have some generated distribution versus the true data distribution,

114
00:06:49.581 --> 00:06:52.820
which is what the actual there that we're training on.

115
00:06:52.821 --> 00:06:56.290
What is a real distribution of that data versus what we generate and we're going

116
00:06:56.291 --> 00:06:59.690
to use a loss function that I'm going to define that's going to minimize the

117
00:06:59.691 --> 00:07:03.650
difference between those two until they are indistinguishable from each other.

118
00:07:03.830 --> 00:07:08.120
And this word indistinguishable is used in variational auto encoders and it's

119
00:07:08.121 --> 00:07:10.790
used in generative adversarial networks,

120
00:07:10.791 --> 00:07:13.970
which I know you guys are super excited to go into.
I am too,

121
00:07:14.150 --> 00:07:16.070
and we're going to go into those,
but we've got to,

122
00:07:16.160 --> 00:07:18.350
we've got to get our variational stuff down first.
Okay.

123
00:07:18.530 --> 00:07:21.740
The name of the game is stochasticity.
Okay.

124
00:07:22.330 --> 00:07:25.250
Non-Deterministic randomness.
Okay.

125
00:07:25.280 --> 00:07:28.220
There's so much cool stuff we can do once we start getting into this.
Okay.

126
00:07:28.430 --> 00:07:31.130
So auto encoders are a type of generative model.
Okay.

127
00:07:31.131 --> 00:07:35.840
And so a regular auto encoder,
it looks like this.
It's boring.
It's plain.

128
00:07:35.841 --> 00:07:39.290
It's simple.
But I mean,
I mean you can use it for a lot of cool things,

129
00:07:39.291 --> 00:07:42.420
but just comparatively compared to variational auto encoders,

130
00:07:42.470 --> 00:07:45.830
they're not as cool.
So it's a five step process,
right?

131
00:07:45.831 --> 00:07:48.950
We start off by initially by initializing our weights randomly,

132
00:07:49.130 --> 00:07:53.660
we always randomly initialized weights and then we do a full forward pass

133
00:07:53.990 --> 00:07:56.120
through the batch,
through the encoding and then decoding.

134
00:07:56.150 --> 00:07:59.810
So we can just think of both neural nets and auto encoder is there are two

135
00:07:59.811 --> 00:08:02.180
neural networks,
right?
An encoder and a decoder.

136
00:08:02.600 --> 00:08:05.210
But when we do a forward pass for all intensive purposes,

137
00:08:05.211 --> 00:08:08.360
we just think of it as one big ass neural network,
right?

138
00:08:08.480 --> 00:08:10.910
We start at the input and we get to the output.

139
00:08:10.970 --> 00:08:13.460
But for forming a chain of computations,
right?

140
00:08:13.640 --> 00:08:17.360
It's just matrix multiplication at every layer until we get an output,
right?

141
00:08:17.660 --> 00:08:20.440
And then we construct a loss function via MSE,

142
00:08:20.560 --> 00:08:25.040
which means mean squared error of the original data to the reconstructed data.

143
00:08:25.041 --> 00:08:29.000
What does the mean squared error.
It's a very generic loss function used a lot.

144
00:08:29.210 --> 00:08:30.110
It's used a lot.

145
00:08:30.380 --> 00:08:35.380
And it just means take the output versus the expected output been the difference

146
00:08:35.661 --> 00:08:38.140
between the two,
those two.
So subtract it,
uh,

147
00:08:38.260 --> 00:08:42.920
and then add up the difference between all of your input output Paris divided by

148
00:08:42.921 --> 00:08:45.980
the number of them,
and then those differences,

149
00:08:45.981 --> 00:08:49.160
you square them divided by the number of them and you get the mean of the

150
00:08:49.161 --> 00:08:50.120
squared error.
Okay?

151
00:08:50.121 --> 00:08:52.950
So it's a very simple formula and then we calculate the great answer using

152
00:08:52.960 --> 00:08:56.460
backpropagation.
Okay,
that's auto encode.
Those are auto encoders.

153
00:08:56.461 --> 00:08:59.810
But right now what we're going to do is,
um,

154
00:09:01.470 --> 00:09:05.760
you guys are hilarious.
Okay,
I love you guys.
Okay,
so those are auto encoders,

155
00:09:05.790 --> 00:09:08.220
right?
So now we're gonna,
we're gonna,
we're gonna,

156
00:09:08.400 --> 00:09:09.900
we're gonna turn it up a little bit.
Okay.

157
00:09:09.901 --> 00:09:12.420
Now we're going into variational auto encoders.

158
00:09:12.421 --> 00:09:16.320
So what are the problems with auto encoders there?
They have so many problems.

159
00:09:16.321 --> 00:09:18.540
99 of them.
No,
that's not,
that's JC.

160
00:09:18.660 --> 00:09:23.040
So problems are they will overfit unless you have a large training dataset.

161
00:09:23.220 --> 00:09:27.040
So this actually applies to all neural networks,
all neural networks.
Oh,

162
00:09:27.050 --> 00:09:29.350
we'll overfed until you have,
um,

163
00:09:30.810 --> 00:09:33.990
all generic deterministic neural networks that we're used to,

164
00:09:34.020 --> 00:09:35.040
that we've been talking about.

165
00:09:35.220 --> 00:09:38.790
They will all overfit unless we have a lot of data.
So how do we prevent this?

166
00:09:38.791 --> 00:09:41.730
How do we prevent over fitting?
There's,
or there's another problem,

167
00:09:41.731 --> 00:09:45.480
the gradients diminish quickly.
So wait,
updates get progressively smaller.

168
00:09:45.630 --> 00:09:49.110
The farther we go from the output,
the vanishing gradient problem.

169
00:09:49.380 --> 00:09:52.530
And now if you can remember and um,
here's a pop quiz for you.

170
00:09:52.860 --> 00:09:56.160
How do we solve the vanishing gradient problem for recurrent networks that give

171
00:09:56.161 --> 00:10:00.420
you five seconds,
five,
four,
three,
two,
one.

172
00:10:00.660 --> 00:10:04.170
LSTM cells,
right?
LSTM sells gru cells.
Why?

173
00:10:04.320 --> 00:10:07.890
Because they capture gradients over time because we were back propagating

174
00:10:07.891 --> 00:10:12.690
through time and we use these cells to,
to not have that great advantage.

175
00:10:12.720 --> 00:10:14.670
But there's another way that we can solve this.

176
00:10:15.000 --> 00:10:19.500
The solution to both of these problems is to add a variational component to

177
00:10:19.501 --> 00:10:23.520
regularize training.
What do I mean by regularize to improve,

178
00:10:23.850 --> 00:10:24.990
to improve training.

179
00:10:25.920 --> 00:10:30.920
So the variational component is we add some kind of random distribution inside

180
00:10:31.531 --> 00:10:33.870
of that.
And we're going to,
we're going to go through this mathematically.

181
00:10:33.871 --> 00:10:36.640
So I'll talk about,
so I'll,
I'll go into detail about,

182
00:10:36.720 --> 00:10:38.070
about what I'm talking about,

183
00:10:38.490 --> 00:10:42.240
but we start off with an input x and then the inputs going to be some image or

184
00:10:42.241 --> 00:10:46.200
whatever.
And then we say,
what is the probability of xe given x?

185
00:10:46.230 --> 00:10:50.190
So what is the probability of this hidden state value given x?

186
00:10:50.400 --> 00:10:51.960
And it's going to give us this hidden state.

187
00:10:52.350 --> 00:10:54.210
And then we take the hidden state and we said,
what is it?

188
00:10:54.211 --> 00:10:57.660
Probability of the output x given this hidden state?

189
00:10:57.750 --> 00:10:59.160
And that's gonna give us our output.

190
00:10:59.400 --> 00:11:03.060
And this little three d dimensional bad ass looking curve thing is what we're

191
00:11:03.061 --> 00:11:05.700
going to,
we're going to coat it,
we're going to coat it.
Okay.
So,

192
00:11:06.240 --> 00:11:07.770
so there were introduced three years ago.

193
00:11:07.800 --> 00:11:11.430
They're built on top of standard function approximators neural networks.

194
00:11:11.940 --> 00:11:14.970
By the way,
neural networks are considered universal function.

195
00:11:14.971 --> 00:11:18.090
Approximators I haven't actually said that in this course,
by the way,

196
00:11:18.091 --> 00:11:21.840
but they are.
What do I mean by that?
Given any set of inputs and outputs,

197
00:11:21.930 --> 00:11:23.370
you have some function,
right?
You have some,

198
00:11:23.610 --> 00:11:26.940
you have some relation to mapping between this data,
right?
Like the most,

199
00:11:26.941 --> 00:11:30.270
the simplest one that we could think about is y equals mx plus B,
right?

200
00:11:30.450 --> 00:11:34.560
The F of x equals y equals mx plus B.

201
00:11:34.560 --> 00:11:37.890
There's a relationship between y and x and the function is mx plus B.

202
00:11:38.220 --> 00:11:42.510
But neural networks can find a function,
a mapping between any sets of input,

203
00:11:42.511 --> 00:11:45.900
output pairs,
and uh,
so there are amazing,
okay,

204
00:11:45.901 --> 00:11:50.610
so let's go ahead and get started with this.
Not LSD,

205
00:11:50.640 --> 00:11:55.000
l s t m although anyway,
let's,
let's just get into the code guys.
Uh,

206
00:11:55.040 --> 00:11:58.090
where were we?
So let's just get started with this.
Oh,

207
00:11:58.091 --> 00:11:59.950
and I've got some bad ass examples here.
I didn't,

208
00:11:59.951 --> 00:12:04.210
I didn't actually show those examples,
but we can generate Pokemon.

209
00:12:04.211 --> 00:12:06.580
So this dude,
remember,
by the way,
we,

210
00:12:06.581 --> 00:12:08.770
we got to get away from this m and ice t stuff,
guys.

211
00:12:08.771 --> 00:12:13.750
I mean if you look at the nips papers from 2016 the most used data set by far

212
00:12:14.530 --> 00:12:19.390
was m and ice tea.
But what would be better as a standard like base format?

213
00:12:19.960 --> 00:12:22.480
Pokemon would be better.
Not The new stuff.

214
00:12:22.481 --> 00:12:26.500
I'm talking about the original hundred 50 Pokemon that everybody knows and
loves.

215
00:12:26.560 --> 00:12:30.190
Okay,
use those.
Why?
Because when we are using generative models,

216
00:12:30.191 --> 00:12:34.480
we can generate new Pokemon that are a fusion of the ones that already exist.

217
00:12:34.570 --> 00:12:36.370
So this guy tried it out over here and now,

218
00:12:36.371 --> 00:12:38.650
and I've linked to this and the and the notebook.
So check it out.

219
00:12:38.860 --> 00:12:41.290
So these were the original and this is where the reconstructions,

220
00:12:41.410 --> 00:12:45.070
so the reconstructions were clearly terrible.
He did.
It was a very bad job.

221
00:12:45.130 --> 00:12:47.380
But the point is that he tried.
So that was awesome.

222
00:12:47.381 --> 00:12:50.740
So check out that repo a and a for at least for the Dataset.

223
00:12:50.800 --> 00:12:53.680
And then one more example,
we can generate faces as well.

224
00:12:53.710 --> 00:12:57.040
Now this is the second most used example for both generative adversarial

225
00:12:57.041 --> 00:13:00.010
networks and for variational auto encoder is generating faces.

226
00:13:00.850 --> 00:13:05.680
So this fray faces manifold is the,
it's like the Dataset.

227
00:13:05.710 --> 00:13:09.340
And for generating faces,
you can do that too.
Okay,
so those are two examples.

228
00:13:09.341 --> 00:13:11.230
And Dell,
let's just get started with this code.
All right,

229
00:13:11.500 --> 00:13:16.500
so the first step is for us to import our dependencies because we have only

230
00:13:16.571 --> 00:13:19.680
three that we're going to use.
Hard mode is not on because uh,

231
00:13:19.720 --> 00:13:23.750
we're not hard mode in this case would actually be a lot of code.

232
00:13:23.770 --> 00:13:25.360
And then what I want,
what do you mean by hard mode?

233
00:13:25.780 --> 00:13:30.760
I'm talking about using just non pie.
We're going to use tensorflow.

234
00:13:30.790 --> 00:13:35.500
Okay.
And that's the name of this livestream tensorflow,
right.
So right,
so,
so,

235
00:13:35.501 --> 00:13:36.650
so that's what the name of the livestream.

236
00:13:36.670 --> 00:13:41.080
So once we've imported our dependencies,
we're going to import our Datas Dataset.

237
00:13:41.110 --> 00:13:42.540
Okay.
So tensorflow,

238
00:13:42.550 --> 00:13:47.550
luckily for us has M and ice tea beautifully packaged for us and we can just

239
00:13:47.861 --> 00:13:50.270
import it.
We could just import that data set.

240
00:13:50.470 --> 00:13:55.470
There's no if and or buts there is just data when it comes to this stuff,

241
00:13:56.830 --> 00:13:58.210
it's easy.
We just say input data,

242
00:13:58.211 --> 00:14:00.900
we've already called it and then we can just read it with this read Dataset

243
00:14:00.970 --> 00:14:05.530
function.
The Reed datasets on Chin.
Given

244
00:14:07.810 --> 00:14:10.540
the location of our data,
which is going to be in temp data.

245
00:14:10.750 --> 00:14:14.820
And then we say one hot equals true,
which means we want to one hot encoding.

246
00:14:15.160 --> 00:14:15.761
What does that mean?

247
00:14:15.761 --> 00:14:20.761
It's a way of encoding data such that it differential differentiates it without

248
00:14:23.080 --> 00:14:23.913
ranking them.

249
00:14:26.580 --> 00:14:29.250
So then what happens is they get an error.
So that's,
that's the next step.

250
00:14:29.640 --> 00:14:33.880
So then what I've got to do is I've got to make sure it's plural.
There we go,

251
00:14:34.060 --> 00:14:36.940
boom.
So we've got our dataset because we don't care about the data.
Really.

252
00:14:36.941 --> 00:14:38.950
We care about this,
this model,
what does it look like?

253
00:14:39.070 --> 00:14:43.990
So let's go ahead and define some parameters here.
Uh,
well the number of Pixels,

254
00:14:43.991 --> 00:14:47.110
right?
[inaudible] these are a set of handwritten character digits there,

255
00:14:47.111 --> 00:14:50.830
28 by 28 pixels for the image.
I'm going to say 20 by 28 does a number of,

256
00:14:51.170 --> 00:14:55.040
and we're going to use this as a parameter when we define our tensors,
right?

257
00:14:55.041 --> 00:14:59.600
So let's go ahead and say,
let's define our placeholder.
And what is this?

258
00:14:59.601 --> 00:15:02.300
This is an unsupervised learning problem.

259
00:15:02.301 --> 00:15:04.850
We don't have labels for this data or we do,
but we don't,

260
00:15:04.880 --> 00:15:06.320
we don't care about them.
In this case,

261
00:15:06.560 --> 00:15:10.830
we're going to learn to Jen to reconstruct our input images given our,
uh,

262
00:15:11.210 --> 00:15:13.340
just our input images.
Just,
just given that alone.

263
00:15:13.340 --> 00:15:16.010
So we're going to say tentraflow doff float.

264
00:15:16.850 --> 00:15:21.080
And so this is our placeholder,
right?
This is what we're feeding in our,

265
00:15:23.330 --> 00:15:26.240
our initial values.
Okay.

266
00:15:27.020 --> 00:15:31.970
So x equals TF.
Dot.
Placeholder.
Get the float.
Good.

267
00:15:31.971 --> 00:15:32.840
We got the good stuff.

268
00:15:32.930 --> 00:15:36.710
Now let's go ahead and define some variable or some functions here.

269
00:15:36.950 --> 00:15:39.470
So the first one is going to be the weights.
Very so,
by the way,

270
00:15:39.471 --> 00:15:43.420
this is for our input input,
the images,
this our gateway,
right?

271
00:15:43.470 --> 00:15:47.870
Remember placeholders are gateways
and a,
yeah,

272
00:15:47.930 --> 00:15:50.540
so wait variables.
Okay,
let's get start with our but wait variable.

273
00:15:50.550 --> 00:15:54.080
So the weight variables are going to represent the strength of connections

274
00:15:54.081 --> 00:15:58.340
between our units here.
So given some shape,
which is a tenser and some name,

275
00:15:58.580 --> 00:16:00.270
we're going to create wait variable.

276
00:16:00.271 --> 00:16:04.700
So the reason we're defining these functions here is because they're uneasy way

277
00:16:04.701 --> 00:16:09.410
for us to reuse what is going to be used for as many layers as we have.

278
00:16:09.590 --> 00:16:14.590
This is good practice to encapsulate your logic that you think is going to be

279
00:16:15.561 --> 00:16:18.920
reusable into functions.
Okay?

280
00:16:18.950 --> 00:16:22.370
So that's just oop,
object oriented programming.

281
00:16:22.910 --> 00:16:26.390
And so then we've got our,
our good stuff.

282
00:16:26.391 --> 00:16:28.640
So truncated normal.

283
00:16:28.641 --> 00:16:31.520
It outputs a random value that's either going to be bounded,

284
00:16:31.700 --> 00:16:36.290
truncated means bounded.
So it's gonna be bounded between some set interval.
Okay?

285
00:16:36.291 --> 00:16:38.120
And so the standard deviation is gonna be 0.1.

286
00:16:38.300 --> 00:16:42.800
The deviation is how far off from the mean does it,
does it,
does it move?
Okay?

287
00:16:42.801 --> 00:16:45.050
So that's going to be our,
our weight values,
that's it.

288
00:16:45.110 --> 00:16:45.980
Those are our weight values.

289
00:16:45.981 --> 00:16:50.060
And then we could just return that as a variable because tentraflow works with

290
00:16:50.061 --> 00:16:50.720
variables.

291
00:16:50.720 --> 00:16:55.310
So we'll add initial to our variable and then we're going to give it a name that

292
00:16:55.311 --> 00:16:56.840
we're going to name it outside of the function.

293
00:16:56.841 --> 00:17:01.640
And then it goes into the function like,
like it does.

294
00:17:01.670 --> 00:17:04.520
Okay.
So then we've got our biases.
So bias.

295
00:17:04.521 --> 00:17:06.410
These are actually not that well understood.
There's,

296
00:17:06.411 --> 00:17:10.130
there's not a lot of great explanations around why we use biases.

297
00:17:10.131 --> 00:17:11.660
It's just kind of like,
you know,
hand wavy,

298
00:17:11.930 --> 00:17:14.840
Oh and then we have our bias and then that's,
and then the cows come home.

299
00:17:14.841 --> 00:17:17.300
That's actually a bad analogy for this.

300
00:17:17.301 --> 00:17:22.301
But what happens is we need biases because they are used to increase the

301
00:17:22.761 --> 00:17:26.780
flexibility of the model to fit to the data they prevent over fitting there like

302
00:17:26.781 --> 00:17:29.360
an anchor but like an anchor point.
So you know,

303
00:17:29.361 --> 00:17:33.740
y equals mx plus B that the equation B is the bias because it's,
it's it,

304
00:17:33.741 --> 00:17:34.281
it moves,

305
00:17:34.281 --> 00:17:38.900
it translates a graph right across a plane and um,

306
00:17:40.070 --> 00:17:44.240
they allow us to fit data even when the,
an input value is zero.

307
00:17:44.270 --> 00:17:48.260
If an input value is zero,
then if there wasn't a bias,
it would just train,

308
00:17:48.290 --> 00:17:50.340
it would just output zero.
But since there's a bias,

309
00:17:50.550 --> 00:17:53.040
there's some constant value there.
We have something,

310
00:17:53.041 --> 00:17:55.050
we have some value that we could continue training.

311
00:17:55.270 --> 00:17:58.040
So prevents overfitting and it increased the CR.

312
00:17:58.100 --> 00:18:01.560
It increases the flexibility of our model to fit to the data.
Specifically,

313
00:18:01.630 --> 00:18:06.060
it allows the network to fit the data when all the input features are equal to

314
00:18:06.480 --> 00:18:09.810
zero,
which is what I just said.
Okay.
So let's,

315
00:18:09.811 --> 00:18:12.150
I'm going to answer questions once I've finished this,
this,
um,

316
00:18:13.140 --> 00:18:17.100
this is good stuff.
So we've got our truncated normal and the trunk had a normal,

317
00:18:17.430 --> 00:18:20.320
it's also going to be a,
um,

318
00:18:20.910 --> 00:18:25.140
it's going to be generated randomly and then we're gonna return it as a
variable.

319
00:18:26.190 --> 00:18:29.910
Variable is a modifiable tenser and uh,
yeah,

320
00:18:29.911 --> 00:18:34.410
these are primitives and tensorflow guys,
isn't Pi Torch so dope though.

321
00:18:34.411 --> 00:18:36.750
I'm definitely gonna make a video and Pi Torch soon.
Not,

322
00:18:36.751 --> 00:18:39.150
not that tensorflow is an also awesome,
but,
uh,

323
00:18:39.570 --> 00:18:42.560
there's some good stuff coming out of Pi Torch recently.
Seriously.
Uh,

324
00:18:42.570 --> 00:18:45.160
so we've got FC layer.
So what does this,
so we've got our weights,

325
00:18:45.170 --> 00:18:49.260
we got our biases,
and now we're going to create a fully connected layer.

326
00:18:49.350 --> 00:18:54.350
A fully connected layer is one where all the neurons in one on one on the input

327
00:18:54.421 --> 00:18:57.290
are connected to every neuron in the output.
Okay.
So we,

328
00:18:57.300 --> 00:18:59.280
that means we want all of the data.

329
00:18:59.550 --> 00:19:01.110
And what do I mean by like you might be thinking like,

330
00:19:01.111 --> 00:19:03.960
well don't we always want all the data like when else?
No,

331
00:19:03.961 --> 00:19:05.910
because sometimes we only want part of the data.

332
00:19:06.090 --> 00:19:09.870
Will it be a good example of this convolution?
It's convolutional networks.

333
00:19:10.020 --> 00:19:11.910
If we have an image of say a banana,

334
00:19:12.120 --> 00:19:14.490
we don't care where in the image the banana is.

335
00:19:14.491 --> 00:19:17.130
We just care that there is a banana.
So what do we do?

336
00:19:17.250 --> 00:19:18.780
We don't use a fully connected layer.

337
00:19:18.900 --> 00:19:23.400
We use a convolutional layer that acts as a flashlight and it slowly moves

338
00:19:23.401 --> 00:19:27.810
through the image until it finds that banana.
And it only uses that part.
Why?

339
00:19:27.870 --> 00:19:32.580
Because it's computationally efficient.
Okay.
So given our fully connected layer,

340
00:19:32.610 --> 00:19:33.200
what we,

341
00:19:33.200 --> 00:19:38.200
we don't want that in this case we want a fully connected layer because we are

342
00:19:39.031 --> 00:19:42.810
not labeling data,
we are generating data.
So we want all of that image.

343
00:19:44.010 --> 00:19:45.150
Okay?
So

344
00:19:47.730 --> 00:19:49.920
cause we don't know what it is that we want.

345
00:19:49.921 --> 00:19:52.350
We're not classifying anything we're generating.
We don't,

346
00:19:52.410 --> 00:19:56.820
we don't care if it's a banana or whatever it is.
Um,
okay.
So,

347
00:19:57.210 --> 00:20:00.930
so the fully connected layer is going to do a matrix multiplication between the

348
00:20:00.931 --> 00:20:04.390
input the weights and then add the bias.
It's like y equals mx plus B.

349
00:20:04.391 --> 00:20:09.060
It's same thing.
So those are our three layers that we have.
Okay.

350
00:20:09.061 --> 00:20:12.630
So,
um,
yeah,
those are our layers.

351
00:20:12.630 --> 00:20:14.380
And now let's start writing out our encoder.

352
00:20:14.381 --> 00:20:17.340
So before we start writing at an encoder answering questions,

353
00:20:17.790 --> 00:20:19.920
let me answer some questions.
Now.
What do we got?

354
00:20:19.921 --> 00:20:23.790
We got before we have even more people here.
I will,
yes,

355
00:20:23.791 --> 00:20:27.510
I did a video intenser board.
I'll,
yeah,
yeah,
yeah,
yeah,
of course.
Great.
So,

356
00:20:29.280 --> 00:20:31.830
uh,
[inaudible] says,

357
00:20:31.831 --> 00:20:35.610
please do a comparison between tensor flow and Amex net in your style someday.

358
00:20:36.960 --> 00:20:41.400
I'll consider it.
I did.
Tai says difference between RBM and an auto encoder.

359
00:20:41.401 --> 00:20:41.671
Please.

360
00:20:41.671 --> 00:20:46.671
So rbms that's a restricted Boltzmann machine and those are used,

361
00:20:47.890 --> 00:20:52.660
I mean to me the coolest use case of rbms are in generating music.

362
00:20:52.790 --> 00:20:56.860
There are more similar to mark off chains then to uh,
auto encoders.

363
00:20:57.310 --> 00:21:02.290
They auto encoders reconstruct their,
they're meant for,

364
00:21:02.350 --> 00:21:03.730
they're meant for image compression.

365
00:21:03.731 --> 00:21:07.780
Whereas rbms are are from the start meant for generation.

366
00:21:08.440 --> 00:21:11.020
Two more questions and then we'll get started.
Pershant asks,

367
00:21:11.050 --> 00:21:16.050
is it possible to make multilayer auto encoders learn to completely repeat in

368
00:21:18.700 --> 00:21:19.900
completely repeat.

369
00:21:21.030 --> 00:21:25.120
I'm just going to paraphrase is probably what you're saying is to to to

370
00:21:25.121 --> 00:21:26.590
reconstruct the input.
Yes they are.

371
00:21:27.010 --> 00:21:28.360
Two more question actually two more questions.

372
00:21:28.390 --> 00:21:32.170
Does drop out reduced overfitting yes.
It that's the,
that's the point of dropout.

373
00:21:32.171 --> 00:21:34.540
That's the,
that is the point of dropout.

374
00:21:35.020 --> 00:21:40.020
When somebody is overfit their minds are too closed.

375
00:21:40.390 --> 00:21:44.530
So how do you prevent close mindedness?
You add new experiences,
you,

376
00:21:44.950 --> 00:21:49.270
you do,
you have some kind of new experience and then so drop out,

377
00:21:49.271 --> 00:21:50.440
drop out is akin to that.

378
00:21:50.441 --> 00:21:54.970
It is opening and closing connections randomly so that new Sonata synaptic

379
00:21:54.971 --> 00:21:58.150
connections can be made.
All right.
And then the last question is,

380
00:21:58.151 --> 00:22:03.151
does it make any sense to use to fcs to run in parallel and they combine atlast

381
00:22:03.520 --> 00:22:04.390
give output,

382
00:22:05.830 --> 00:22:09.970
does it make any sense to use to fully connected layers to run in parallel and

383
00:22:09.971 --> 00:22:14.350
then they combine?
So yeah.
Yeah,
no,
for sure.

384
00:22:14.351 --> 00:22:18.100
I mean you could run them in parallel.
Distributed tensorflow is a thing.

385
00:22:18.380 --> 00:22:21.280
We haven't actually talked in detail about that,
but uh,
yeah,

386
00:22:21.281 --> 00:22:25.150
it's definitely a cool thing.
Yeah,
for sure.
So yeah.
Anyway,
back to the encoder.

387
00:22:25.151 --> 00:22:26.800
So we've defined our functions.

388
00:22:26.860 --> 00:22:30.190
Let's go ahead and start putting them to use by defining our encoder,
right?

389
00:22:30.400 --> 00:22:31.101
This is what our encoder,

390
00:22:31.101 --> 00:22:34.870
it looks like we've got our input and codes it into light and space and then we

391
00:22:34.871 --> 00:22:37.330
output it.
All right.
It's simple stuff.
We've been talking about this.

392
00:22:37.510 --> 00:22:38.950
Let's go ahead and get started with their encoder.

393
00:22:38.951 --> 00:22:41.770
The encoder time guys for our latent dimensionalities.

394
00:22:41.771 --> 00:22:44.510
So it's going to be 20 so what do I mean by latent dimentionality?

395
00:22:44.511 --> 00:22:49.510
So we have this latent space,
this,
this,
this representation space.

396
00:22:49.511 --> 00:22:52.070
We want a certain number of dimensions,
right?
And what,

397
00:22:52.090 --> 00:22:55.000
what are those dimensions is going to be,
let's say 20 now,

398
00:22:55.001 --> 00:22:59.560
should they ideally be 21 at 21 why not 19 we're just going to try 20 a lot of

399
00:22:59.561 --> 00:23:01.900
machine learning is guessing and checking these hyper parameters.

400
00:23:02.140 --> 00:23:05.410
So we have a latent dimensionality of 20 for this light and space and then a

401
00:23:05.411 --> 00:23:08.200
hidden dimensionality of 500 what do I mean by this?

402
00:23:08.380 --> 00:23:11.680
This means 500 neurons and the input layer.

403
00:23:11.890 --> 00:23:14.110
So let's go ahead and say the final layer one.

404
00:23:14.140 --> 00:23:18.700
This is going to be a two layer feed forward neural network.

405
00:23:18.760 --> 00:23:21.370
So let's just find our two layers.
We have our

406
00:23:23.890 --> 00:23:26.890
first set of weights and now we're going to use those variables that we just

407
00:23:26.891 --> 00:23:27.311
defined.

408
00:23:27.311 --> 00:23:32.311
We just define them and the number of pixels and the hidden dimensionally,

409
00:23:33.310 --> 00:23:35.080
this is going to be the size of our tensor.

410
00:23:35.081 --> 00:23:38.230
We want to make sure that that then that's why we define these things because we

411
00:23:38.231 --> 00:23:41.530
want them to be in a size that fits our tensor and then we're going to name it.

412
00:23:41.770 --> 00:23:45.500
Okay,
so that's our weight.
That's for our weights.
And then for our right,

413
00:23:45.501 --> 00:23:50.000
so each layer has it's own set of weights and its own set of biases.

414
00:23:50.330 --> 00:23:51.163
And

415
00:23:52.820 --> 00:23:56.840
we have our hidden dimensionality and then our B encoder.

416
00:23:58.400 --> 00:24:03.320
Okay?
So right there we go.
Boom.
So that's for layer one.

417
00:24:03.321 --> 00:24:06.910
And then,
oh,
we have one more step here.
Okay.
So this is that,

418
00:24:06.911 --> 00:24:07.744
this is the fun part.

419
00:24:07.880 --> 00:24:11.030
I'm just gonna write Tan h here and then explain what I'm talking about,
right?

420
00:24:11.031 --> 00:24:12.830
So we've got some input data,

421
00:24:12.831 --> 00:24:16.070
we put it through the weights and the biases and well,
we've needs,

422
00:24:16.100 --> 00:24:18.740
we need to compute something,
right?
We need to compute something.

423
00:24:19.010 --> 00:24:23.660
So to compute something,
we're going to use a Tan h function.
So what is Tan h?

424
00:24:23.840 --> 00:24:28.340
So this is our fully connected layer,
given the,
uh,
input data,

425
00:24:28.370 --> 00:24:32.210
and then those weights that we just defined in those biases that we just
defined,

426
00:24:32.780 --> 00:24:34.430
we're going to compute some output value.

427
00:24:35.510 --> 00:24:38.090
Then we're going to feed the output value to this activation function.

428
00:24:38.090 --> 00:24:42.950
That is Tan h.
So teenagers are activation function,
okay?
So weights,

429
00:24:43.240 --> 00:24:48.080
uh,
encoder biases and ex FC layer.
It's all good.

430
00:24:48.081 --> 00:24:48.930
Okay,
so activate.

431
00:24:48.931 --> 00:24:53.931
So the teenage function is considered the hyperbolic or the hyperbolic tangent

432
00:24:54.291 --> 00:24:57.560
function,
which is similar to sigmoid except the range.

433
00:24:57.590 --> 00:24:59.900
So sigmoids range is between zero and one,

434
00:25:00.290 --> 00:25:04.570
whereas 10 ages range is between negative one and one.
So it's a,
it's a,

435
00:25:04.640 --> 00:25:07.670
it's a larger range.
And when do we use it versus sigmoid?

436
00:25:07.671 --> 00:25:12.470
So there's actually a lot of theory behind activation functions and when we use

437
00:25:12.471 --> 00:25:15.560
it,
but in this case,
we're just going to say,
uh,

438
00:25:16.850 --> 00:25:20.240
it avoids the vanishing gradient problem compared to the sigmoid,

439
00:25:20.270 --> 00:25:23.180
not in all cases.
But when it comes to generative models,

440
00:25:23.440 --> 00:25:26.330
Tan h avoids the granted vanishing gradient problem.
Why?

441
00:25:26.750 --> 00:25:28.760
There's a whole bunch of reasons behind that.

442
00:25:28.790 --> 00:25:30.560
We don't have time to go into all that right now,

443
00:25:30.561 --> 00:25:33.560
but let's just say it avoids the advantaging radiant problem.

444
00:25:34.130 --> 00:25:37.880
And this is a problem in all neural networks.
Okay?
No,
no one is safe.

445
00:25:37.910 --> 00:25:41.720
No network is safe.
Okay?
So whatever we can do to prevent that,

446
00:25:42.470 --> 00:25:43.820
we're going to do,
all right,
so this,
uh,
this,

447
00:25:43.821 --> 00:25:47.000
this next layer where we can actually just copy and paste this cause it's,

448
00:25:47.001 --> 00:25:49.940
you know,
it's the same thing more or less.

449
00:25:52.510 --> 00:25:55.130
Am You m U and then m you,

450
00:25:55.370 --> 00:25:58.490
what do I mean by m you mean?
Okay.

451
00:25:58.970 --> 00:26:02.350
M U is stands for mean and then we're going to rename it and then I'm going to

452
00:26:02.360 --> 00:26:03.440
answer and no,
it'll actually,

453
00:26:03.441 --> 00:26:07.760
I just answered some questions so I'm just going to keep going here and you buy

454
00:26:07.761 --> 00:26:12.761
a Cs and then we'll call it what I've just called it.

455
00:26:13.580 --> 00:26:18.200
Do what I do.
I do what I do.
I do what I do.

456
00:26:19.970 --> 00:26:24.920
Oh Man.
Okay.
So X.
Right?
It's all good,

457
00:26:24.921 --> 00:26:28.010
right?
It's all good.
You guys got to,
yeah,
it's got to keep me in check.

458
00:26:28.370 --> 00:26:32.570
You guys got to keep me in check.
You guys got to keep me in check.

459
00:26:32.600 --> 00:26:36.440
I love reading your comments.
You guys are hilarious.
Okay.
Uh,

460
00:26:39.020 --> 00:26:42.830
see what I love about you guys is that you help each other out.
That's,

461
00:26:42.831 --> 00:26:47.340
it is a culture that we are trying to create here.
Okay.

462
00:26:47.640 --> 00:26:51.720
So those are two layers.
And so now is the,
is the dope part.
Okay.
So,

463
00:26:51.721 --> 00:26:54.480
so this is what makes me really excited.

464
00:26:54.780 --> 00:26:58.920
So we've got our two layers and then generally,
I mean normally that's it,
right?

465
00:26:58.921 --> 00:27:02.760
This is we wipe our hands clean,
drink some coffee,
do whatever you gotta do,

466
00:27:02.910 --> 00:27:06.230
go home,
play Gamecube,
knocking cube.

467
00:27:06.870 --> 00:27:11.340
But in this case or we're going to do is we are going to,
um,

468
00:27:12.270 --> 00:27:16.080
normally we would,
I'll put a vector of real values,
right?
And that's it.

469
00:27:16.500 --> 00:27:19.200
And then we use backpropagation like we always do,

470
00:27:19.201 --> 00:27:24.090
we compute the partial derivative with respect to the weights given our error

471
00:27:24.091 --> 00:27:28.590
value.
And then it's all good,
right?
It's all Gucci.
But in this case,

472
00:27:28.980 --> 00:27:32.970
we have a stick,
we have randomness built into the model.

473
00:27:32.971 --> 00:27:35.820
So we can't just brag,
propagate.
Normally we've got to,

474
00:27:36.210 --> 00:27:40.020
we've got to perform a trick,
a re parameterization step.

475
00:27:40.020 --> 00:27:41.430
And I'm going to talk about what I mean by that.

476
00:27:41.431 --> 00:27:45.420
So what we're instead of incentive,
how putting a vector of,
um,

477
00:27:45.780 --> 00:27:48.450
instead of how putting a vector of real values to this hint state,

478
00:27:48.690 --> 00:27:52.890
we're going to output a vector of means and the vector of standard deviations

479
00:27:53.220 --> 00:27:55.170
and then we're going to have a random component.
Okay?

480
00:27:55.290 --> 00:27:56.640
And so when we back propagate,

481
00:27:56.760 --> 00:28:00.110
we're only going to back propagate in relation to this mean value and the

482
00:28:00.111 --> 00:28:03.840
standard deviation value.
We don't care about this random value over here.
Why?

483
00:28:03.841 --> 00:28:08.400
Because we can't,
we can't take a partial derivative of a value that is random,

484
00:28:08.580 --> 00:28:09.900
that is not predetermined.

485
00:28:10.080 --> 00:28:13.370
The mean and the standard deviation are predetermined values.

486
00:28:13.371 --> 00:28:17.160
So of course we can back propagate but a random value.
We can't do that.

487
00:28:17.220 --> 00:28:21.270
So what we do is we separate the random value.
We put it off to the side and say,

488
00:28:21.300 --> 00:28:25.050
all right,
you just sit there.
It's all good.
You just,
you just live your life.

489
00:28:25.320 --> 00:28:28.200
And then we have this mean and we had the standard deviation and that's what we

490
00:28:28.201 --> 00:28:30.570
back propagate with.
Okay?
So I'm going to show you what I mean by this.
So,

491
00:28:31.800 --> 00:28:34.650
so what we do,
his here is,
I'm actually going to,

492
00:28:37.390 --> 00:28:38.223
<v 2>uh,</v>

493
00:28:39.200 --> 00:28:43.700
<v 1>wait a second.
Uh,
let's see.
So for layer two,</v>

494
00:28:44.900 --> 00:28:49.030
layer two,
oh yeah,
so there's no Tan h function here.
So,

495
00:28:49.290 --> 00:28:52.220
so for layer two,
there's just at the FC layer,
okay,

496
00:28:52.221 --> 00:28:55.190
because this is the mean value this.
So this is the mean value.

497
00:28:55.191 --> 00:28:59.600
So we're not going to perform that activation function.
We just,
if we did that,

498
00:28:59.601 --> 00:29:00.500
it wouldn't be the mean,
right?

499
00:29:00.530 --> 00:29:04.910
So we've got that layer and then we've got our log STD

500
00:29:06.500 --> 00:29:09.660
layer.
Okay.
So then,
okay,
so we just do this twice.

501
00:29:10.440 --> 00:29:12.570
So this is going to be for our standard deviation.

502
00:29:14.160 --> 00:29:15.600
So we'll just call it STD.

503
00:29:15.840 --> 00:29:18.960
And then what we're going to do is we're gonna say w log STD.

504
00:29:20.610 --> 00:29:24.690
So they also call it log sigma and a lot of uh,
re repository.

505
00:29:24.691 --> 00:29:26.340
They call it logs sigma.
Uh,

506
00:29:26.341 --> 00:29:31.341
but what we say is we say we say log STD and wd legacy be locks,

507
00:29:32.240 --> 00:29:33.570
STM,
we name it properly.

508
00:29:33.810 --> 00:29:38.190
Cause remember we got to make sure that the names are all good.
Be Log,
STD,

509
00:29:38.550 --> 00:29:42.760
all the names,
all the good stuff.
Always,

510
00:29:43.000 --> 00:29:47.860
always low prices.
Wait,
that's something else.
Okay.
Log,
STD.

511
00:29:49.990 --> 00:29:51.140
And then h and coder.

512
00:29:52.120 --> 00:29:54.760
Let me make sure that it's all good because you got to do this right.

513
00:29:54.761 --> 00:29:59.310
You can just compile some bs.
So FC layer.
Uh Huh.
Yup.

514
00:29:59.820 --> 00:30:04.290
Okay.
Latent
[inaudible].
Yup.

515
00:30:04.320 --> 00:30:07.800
Bias.
Wwe.
Yup.
Yup,
Yup,
Yup.
Oh No.

516
00:30:09.580 --> 00:30:14.460
And then latent,
you got to make sure that it's all good over here.
Okay.

517
00:30:14.760 --> 00:30:17.760
Okay.
Okay.
Okay,
I get ya.
Yeah.
Oh See,

518
00:30:19.230 --> 00:30:21.390
see I missed some stuff here.
Okay.

519
00:30:21.391 --> 00:30:26.391
So we've got our encoder and now we're going to do to write out our Dakota who's

520
00:30:26.461 --> 00:30:27.720
ready to ride out and decoder.

521
00:30:28.050 --> 00:30:31.920
Oh actually before we were at card or we got around it,
our,
our,
our step here.

522
00:30:32.130 --> 00:30:36.660
Right.
Okay.
So here's the step.
Here's the step.
So this is,

523
00:30:36.661 --> 00:30:40.050
I'm going to write this out in all caps by the way,
because it's that important.

524
00:30:40.590 --> 00:30:42.580
Get ready for this if you haven't been paying attention to,

525
00:30:42.581 --> 00:30:46.680
if you haven't been awake,
wake up.
Cause this time for the randomness,

526
00:30:46.980 --> 00:30:49.560
the randomness.
See how many times or would that ass,

527
00:30:49.590 --> 00:30:50.423
that's how important this is.

528
00:30:50.820 --> 00:30:55.050
So what we're gonna do is we're gonna say noise equals TF.
Dot.

529
00:30:55.051 --> 00:30:59.730
Random normal for.
So we're going to create a random normal distribution.

530
00:31:00.270 --> 00:31:02.370
And then we're going to say,
well,
what are,

531
00:31:02.400 --> 00:31:06.180
what are the intervals that we want to generate?
This random normal distribution.

532
00:31:06.840 --> 00:31:09.180
This is our randomness.
This noise,

533
00:31:09.210 --> 00:31:12.030
this variable right here is a randomness from which we're going to,

534
00:31:12.510 --> 00:31:14.730
we're going to take this randomness and we're going to,

535
00:31:15.390 --> 00:31:19.740
let me just show you what I'm,
what we're going to do with it.
So we've got our,

536
00:31:19.800 --> 00:31:22.440
so we have our mean and we have our standard deviation values.

537
00:31:22.680 --> 00:31:26.160
And we're going to say,Z is going to be our ultimate output.

538
00:31:26.161 --> 00:31:28.070
So this is the z is our ultimate output.

539
00:31:28.071 --> 00:31:33.000
So the z is the ultimate output of our Incode coder that we then feed to our

540
00:31:33.001 --> 00:31:36.450
decoder.
So what we care about in the end is z.
That's,
that's the output.

541
00:31:36.780 --> 00:31:40.020
So given some,
so given,
so our values,
so we have our mean.

542
00:31:40.170 --> 00:31:44.340
So we take our mean and we add it to the multiplication to the,

543
00:31:45.450 --> 00:31:47.100
to the product.

544
00:31:48.000 --> 00:31:52.230
I blink for a second of our noise and our standard deviation.

545
00:31:52.500 --> 00:31:57.480
And we're going to perform this exponential step by taking half of the standard

546
00:31:57.481 --> 00:32:01.890
deviation.
And
that's going to be our,

547
00:32:03.270 --> 00:32:08.270
our step ultimate muscle ultimate outputs of our encoder.

548
00:32:09.060 --> 00:32:11.260
Okay?
Okay?

549
00:32:11.261 --> 00:32:16.150
So when we back propagate,
we care about these two values.
Okay?

550
00:32:16.151 --> 00:32:19.360
The mean and the standard deviation,

551
00:32:19.840 --> 00:32:24.790
we don't care about the noise,
but the noise helps us generate z by,

552
00:32:24.910 --> 00:32:29.380
because we multiply it by the standard deviation plus the meat.

553
00:32:29.800 --> 00:32:34.800
So it's adding randomness to this output without effecting backpropagation,

554
00:32:35.560 --> 00:32:39.320
which is perfect.
How beautiful is that solution?
It's a beautiful solution.
It,

555
00:32:39.770 --> 00:32:42.320
so this lets us back propagate and um,

556
00:32:44.770 --> 00:32:48.460
and the less information that we pass,
uh,
using that one variable,

557
00:32:48.461 --> 00:32:52.240
the more efficiently we can encode the original image.
Okay?

558
00:32:52.241 --> 00:32:55.030
So the higher we raise the standard deviation on our golf galcion until it

559
00:32:55.031 --> 00:32:56.530
reaches one.
Okay?

560
00:32:56.531 --> 00:33:01.120
So this constraint forces the encoder to be very efficient.

561
00:33:01.780 --> 00:33:05.350
So because we are looking for efficiency here,
okay?
So that's it for our encoder.

562
00:33:05.410 --> 00:33:09.670
And,
uh,
let me make sure that it,
okay,
so let's see what we got here.
Wait,

563
00:33:09.671 --> 00:33:14.590
variable.
It's not defined because I call it weight variable.
Wait,

564
00:33:14.591 --> 00:33:18.940
did I even see I even variables.
That's what it is.

565
00:33:19.540 --> 00:33:21.340
Wait variables.

566
00:33:24.660 --> 00:33:25.493
<v 0>Okay.</v>

567
00:33:26.890 --> 00:33:29.140
<v 1>There we go.
All right,
so,</v>

568
00:33:32.980 --> 00:33:33.813
<v 0>okay,</v>

569
00:33:34.180 --> 00:33:38.050
<v 1>so we've got some errors.
So we've got weight variables is not defined.</v>

570
00:33:40.690 --> 00:33:42.790
Oh,
because I renamed it up here.
That's why.

571
00:33:43.510 --> 00:33:46.990
<v 0>Yeah,
great.
Yup.
Yup.</v>

572
00:33:47.790 --> 00:33:50.370
<v 1>FC layers not defined.
I definitely define FC layer.</v>

573
00:33:50.371 --> 00:33:53.670
I don't know what you're talking about.
Oh,
because it's lowercase,
right?

574
00:33:54.930 --> 00:33:59.070
Guys,
this is what's,
this is the thing that happens when things happen,
right?

575
00:33:59.550 --> 00:34:01.500
Things happen when things happen.
Okay.

576
00:34:04.390 --> 00:34:06.860
We're getting closer,
we're getting closer.
Watch the debug the,

577
00:34:06.870 --> 00:34:08.350
it's all about the debugging in the end.

578
00:34:09.250 --> 00:34:13.510
Mean what are you talking about here?
What'd you talking about,
Willis?

579
00:34:13.600 --> 00:34:15.970
What do we got?
We've got dimensions must be equal,

580
00:34:16.150 --> 00:34:20.470
but our seven 84 and 500 from Matt Mall.
Oh,
okay.

581
00:34:22.770 --> 00:34:24.330
Well,
okay,
let me,

582
00:34:24.390 --> 00:34:28.290
let me answer some questions as well while we talk about,

583
00:34:28.410 --> 00:34:32.520
and let me see what people are saying over here.
Programming woes.

584
00:34:33.120 --> 00:34:37.320
Yo,
we've got even more people.
This is,
this is a record right here.
Uh,

585
00:34:37.350 --> 00:34:40.830
can we use an autoencoder to detect anomalies in time series data?

586
00:34:43.560 --> 00:34:48.350
That's a good question.
I,
I wouldn't,

587
00:34:48.410 --> 00:34:52.550
I wouldn't use that.
I would use,
um,
how would use k means,

588
00:34:52.700 --> 00:34:56.450
which I haven't talked about,
but I will a spoiler,

589
00:34:56.510 --> 00:34:58.390
but I will start talking about,
um,

590
00:34:58.460 --> 00:35:03.200
K-means and a more generic machine learning algorithms.
Uh,
but I wouldn't,

591
00:35:03.840 --> 00:35:06.450
uh,
what's this second layer you just wrote?
Same weight dimensions.

592
00:35:06.451 --> 00:35:08.850
There's the other layer.
Yeah,
same weight dimensions.
Uh,

593
00:35:08.870 --> 00:35:12.380
except we are not applying an yeah,
exactly.

594
00:35:12.381 --> 00:35:16.850
The second layer is the same dimensions.
Uh,

595
00:35:16.860 --> 00:35:21.860
accept.
Okay.

596
00:35:21.861 --> 00:35:25.400
Let me just,
I gotta I gotta pace this one in because we got to keep going in.

597
00:35:25.401 --> 00:35:26.810
What is this?
This is something else.

598
00:35:29.720 --> 00:35:33.950
Uh,
there's so much,
these are all my notes.

599
00:35:33.980 --> 00:35:36.860
There are so many notes here,
isn't it?
Either.
So,

600
00:35:40.190 --> 00:35:42.230
so in terms of documentation,
I mean,

601
00:35:42.231 --> 00:35:45.680
this is the most documented code I think I've ever written.

602
00:35:45.681 --> 00:35:48.590
So that's going to be a treat for you guys.
Okay.

603
00:35:48.880 --> 00:35:50.920
<v 2>So where were we?</v>

604
00:35:52.110 --> 00:35:53.580
<v 1>I was answering a question here.</v>

605
00:35:54.330 --> 00:35:57.320
I wanted to make sure there are so many different things happening here that

606
00:35:57.321 --> 00:36:00.870
want to make sure that what this guy asked is,
so the second layer

607
00:36:02.850 --> 00:36:05.140
is going to have a fully connected,

608
00:36:05.150 --> 00:36:07.470
so it has a fully connected layer at the end of it,

609
00:36:07.770 --> 00:36:11.360
whereas the first layer does not.
The first layer applies and

610
00:36:13.170 --> 00:36:14.570
they both have fully connected layers,

611
00:36:14.580 --> 00:36:16.740
but the first layer applies an activation function to it,

612
00:36:16.741 --> 00:36:19.800
whereas this next layer doesn't.
Because if we applied an activation,

613
00:36:19.801 --> 00:36:22.170
then we wouldn't get a mean value.
And we need a mean value.

614
00:36:22.350 --> 00:36:26.850
We need to me and we need a standard deviation value as a way of representing

615
00:36:27.360 --> 00:36:29.190
the computations that happen in the encoder.

616
00:36:29.520 --> 00:36:31.890
<v 2>Okay.
So,</v>

617
00:36:35.790 --> 00:36:40.620
<v 1>oh my God.
Oh my God.
Okay.
So we've got to say,</v>

618
00:36:41.980 --> 00:36:42.813
<v 2>nope.</v>

619
00:36:43.650 --> 00:36:46.170
<v 1>Eventually we're going to compile this.
Eventually</v>

620
00:36:48.660 --> 00:36:50.490
<v 2>it worked.
I'll,
Hallelujah.</v>

621
00:36:50.650 --> 00:36:54.040
<v 1>Okay,
so Dakota time guys.
Two more questions and then decode or time.</v>

622
00:36:56.070 --> 00:36:58.310
Okay.
Ricardo Muliro ask,

623
00:36:58.311 --> 00:37:01.650
would it be possible to develop this model with simpler TF code like TF,

624
00:37:01.710 --> 00:37:06.540
learn dot input data,
TF,
Aflac?
Yes,
absolutely.
No.
Uh,
um,
yeah.
Ricardo,

625
00:37:06.570 --> 00:37:06.931
I'm just,

626
00:37:06.931 --> 00:37:10.440
I'm doing it intention file because it's more intensive and this is a longer

627
00:37:10.441 --> 00:37:13.920
session.
But if you look at my weekly videos care os it's all,

628
00:37:13.921 --> 00:37:17.970
you can do this in 10 lines.
Yes,
you can do this when an API with lump one line,

629
00:37:17.971 --> 00:37:21.450
but we're trying to learn,
uh,
you know,
a lot of stuff here too.
Okay.

630
00:37:21.451 --> 00:37:26.010
What's the difference between a usual denoising auto encoder and a variational

631
00:37:26.100 --> 00:37:30.090
autoencoder uh,
denoising there's a lot of differences,
but,
um,

632
00:37:30.390 --> 00:37:34.380
denoising auto encoders don't have to cast the city built in so they don't have

633
00:37:34.381 --> 00:37:38.700
this,
uh,
they don't have this re parameterization step that we just performed.

634
00:37:39.180 --> 00:37:39.931
One more question.

635
00:37:39.931 --> 00:37:44.520
Is it possible to use symbolic language to show or try to figure out how the

636
00:37:44.521 --> 00:37:47.940
model works?
Symbolic language,

637
00:37:48.120 --> 00:37:51.360
symbolic language could mean a lot of things,
but

638
00:37:52.950 --> 00:37:57.430
yeah,
um,
symbolic language to show them.

639
00:37:57.630 --> 00:38:00.740
So one way of thinking about this are,
is in terms of computation graphs.

640
00:38:00.741 --> 00:38:04.330
So if we,
if we think about what the computation graph it looks like,
uh,

641
00:38:04.530 --> 00:38:07.130
so Pi Torch is actually a great,
as is a,
is a,

642
00:38:07.140 --> 00:38:11.550
is a great resource for that because what you rights versus what you see on the

643
00:38:11.551 --> 00:38:15.420
graph,
they look very similar.
It's,
it's,
it's not different.
So Pi Torch,

644
00:38:16.170 --> 00:38:18.300
actually one more question because I'm just kind of

645
00:38:21.120 --> 00:38:22.200
what is latent space?

646
00:38:22.230 --> 00:38:26.250
Lane space is the representation of what we've just learned.

647
00:38:26.520 --> 00:38:29.190
A lower dimensional representation of what we've just learned.

648
00:38:29.880 --> 00:38:33.930
Latent equals hidden equals embedding that means the same thing.
Okay.

649
00:38:34.110 --> 00:38:37.450
So Dakota time.
So for the decoder,

650
00:38:38.560 --> 00:38:42.460
we've got that embedding and now we're going to

651
00:38:44.870 --> 00:38:47.930
reconstruct the embedding and

652
00:38:51.670 --> 00:38:53.060
I'm going to,

653
00:39:01.030 --> 00:39:04.840
okay,
so let me,
let me open something up.
I'm going to,

654
00:39:04.850 --> 00:39:07.930
I'm going to open up one that already has,
I'm just estimating time here.

655
00:39:08.290 --> 00:39:13.290
So what I'm gonna do is I'm going to say I'm going to open up my exact same

656
00:39:13.370 --> 00:39:17.140
notebook except it's got all the code already there.

657
00:39:17.680 --> 00:39:22.120
And uh,
which is what I'm reading off of by the way.
And I'm just,

658
00:39:22.121 --> 00:39:23.890
because we need to explain with the Dakota look.

659
00:39:23.891 --> 00:39:27.670
So for the decoder we have two layers.
So it's,
it's,

660
00:39:27.671 --> 00:39:30.700
it's also a two layer co.
It's a two layer feed forward network,

661
00:39:30.701 --> 00:39:33.220
just like the encoder.
And if you,
so what do we,

662
00:39:33.260 --> 00:39:34.990
so let's go buy this line by line.
Okay,

663
00:39:35.290 --> 00:39:38.590
so line one is we defined our weights for layer one.
Okay.

664
00:39:38.591 --> 00:39:40.200
And then we used the latent dimentionality,

665
00:39:40.210 --> 00:39:42.490
which is 20 and the hidden dimentionality,

666
00:39:42.491 --> 00:39:46.660
which is 500 which is the number of neurons to define what the size of this

667
00:39:46.661 --> 00:39:49.420
weight variable,
which is a matrix,
what does that look like?

668
00:39:49.750 --> 00:39:51.970
Then we say this is our bias variable.

669
00:39:52.030 --> 00:39:55.120
And so our bias variable is going to be much smaller.

670
00:39:55.121 --> 00:39:57.460
It's only good to be the sides for hidden dimensionality,

671
00:39:57.461 --> 00:40:01.060
which is 500 and then what we say is we say,

672
00:40:02.590 --> 00:40:04.870
we say,
okay,
so given our weights,
given our biases,

673
00:40:05.110 --> 00:40:09.610
let's then define our hidden layer.
Let's define the actual layer itself.

674
00:40:09.760 --> 00:40:12.640
So we say this is going to be a fully connected layer.

675
00:40:12.641 --> 00:40:16.720
So layer one is fully connected.
They are both fully connected layers,

676
00:40:16.721 --> 00:40:21.190
both layer one and layer two are both fully connected layers and this is how we

677
00:40:21.191 --> 00:40:24.160
define we say are fully connected layer gets art z,

678
00:40:24.161 --> 00:40:27.940
which is the output of our encoder.
This is where z comes in.

679
00:40:27.941 --> 00:40:29.200
What we just calculated,

680
00:40:29.470 --> 00:40:34.060
what the re parameterization step is right here given an Rz given our set of

681
00:40:34.061 --> 00:40:37.300
weights,
given our center biocese compute the fully connected layer,

682
00:40:37.450 --> 00:40:39.600
it's what you output a set of.
Um,

683
00:40:39.730 --> 00:40:44.730
it's going to output that a set of values of doctor that we then squash with our

684
00:40:46.391 --> 00:40:48.730
dimensionality,
with our activation function,

685
00:40:49.050 --> 00:40:51.820
which is going to be Tan h are hyperbolic tangent.

686
00:40:52.270 --> 00:40:55.500
And then that's going to be the,
the hidden state values were and that,

687
00:40:55.501 --> 00:40:59.800
that sort of an h hidden decoder.
Okay.
So that's layer one.

688
00:40:59.890 --> 00:41:01.960
And then for layer two we say,
okay,

689
00:41:02.050 --> 00:41:07.050
we've got those values and we wanted the feed them to our next hidden layer.

690
00:41:07.420 --> 00:41:11.590
So again,
we,
we,
and we're going to call this reconstruction.
Okay.

691
00:41:11.591 --> 00:41:14.320
And this is important because we're going to use reconstruction later when we

692
00:41:14.321 --> 00:41:16.270
generate a novel data points.

693
00:41:16.271 --> 00:41:20.440
So we say w reconstruct the be reconstruct and he's our weights and biases for

694
00:41:20.441 --> 00:41:21.820
layer two.
And then,

695
00:41:25.280 --> 00:41:26.990
and then we say for our fully connected layer,

696
00:41:26.991 --> 00:41:30.250
we'll use both of those terms to then,
uh,

697
00:41:31.220 --> 00:41:35.360
I'll put a vector of values that we didn't squash with a sigmoid function.

698
00:41:35.390 --> 00:41:40.190
And so why do we use a sigmoid function versus a Tan h function for this last,

699
00:41:40.540 --> 00:41:41.373
uh,
step?

700
00:41:41.810 --> 00:41:46.040
Because a sigmoid function is going to output a set of values between zero and

701
00:41:46.041 --> 00:41:49.420
one.
These are Bernoulli parameters.
What,

702
00:41:49.421 --> 00:41:51.590
what do I mean by Bernoulli parameters?
Because

703
00:41:53.440 --> 00:41:56.410
in the end we just care about if something is real or fake,
right?

704
00:41:56.411 --> 00:41:57.640
That's a binary output.

705
00:41:57.641 --> 00:42:02.290
It's a binary classification and a Bernoulli distribution only outputs values

706
00:42:02.291 --> 00:42:06.240
between zero or values that are either zero or one there binary out,

707
00:42:06.241 --> 00:42:09.130
but that's what we call it.
Bernoulli.
So Bernoulli's just a word for this,

708
00:42:09.131 --> 00:42:11.470
but to be technical about it,

709
00:42:11.471 --> 00:42:14.800
it's considered 784 boat Bernoulli parameters,

710
00:42:14.801 --> 00:42:18.940
which means 784 values between zero and one.
Okay.

711
00:42:18.941 --> 00:42:21.860
And that's going to be the reconstructed image,
uh,

712
00:42:23.810 --> 00:42:25.550
right.
And so that's what sigmoid helps us do.

713
00:42:25.580 --> 00:42:30.080
It turns into those eyes to eyes between zero and one.
And so our reconstruction,

714
00:42:30.110 --> 00:42:33.540
this is,
this is our reconstructed image right here.
This,
this,

715
00:42:33.570 --> 00:42:35.300
this set of value stored in here.
Okay.

716
00:42:36.290 --> 00:42:40.160
So that is our reconstructed distribution.
Okay.
So,

717
00:42:40.940 --> 00:42:41.340
<v 0>okay.</v>

718
00:42:41.340 --> 00:42:43.120
<v 1>Uh,
let me,
let me answer some questions.
Uh,</v>

719
00:42:43.160 --> 00:42:46.080
and then we're going to get started with our loss function,

720
00:42:46.110 --> 00:42:50.760
which is going to be amazing.
Okay,
so questions we've got our

721
00:42:58.760 --> 00:42:59.660
or a,

722
00:43:05.430 --> 00:43:10.050
how do you,
why are we calculating me and using FC layer?
Uh,

723
00:43:12.610 --> 00:43:16.910
right.
So
why are we doing that?

724
00:43:16.911 --> 00:43:18.120
Because the,

725
00:43:18.510 --> 00:43:22.040
the FC layer is going to give us a mean if we don't apply an activation function

726
00:43:22.041 --> 00:43:22.874
to it.

727
00:43:23.460 --> 00:43:24.150
<v 0>Okay.</v>

728
00:43:24.150 --> 00:43:28.050
<v 1>So Dick,
he,
Omar asked,
how do you handle time series data labeled in?</v>

729
00:43:28.410 --> 00:43:32.310
So for time series data,
you would want to use a recurrent network,
uh,

730
00:43:32.340 --> 00:43:35.460
and you would just,
uh,
the,

731
00:43:35.461 --> 00:43:39.700
the labels would be the targets and the expected output and then you could do

732
00:43:39.701 --> 00:43:42.480
something like mean squared error to do that.
I've got a great video on that.

733
00:43:42.481 --> 00:43:47.120
See how to use tensorflow for time series.
Could you also,

734
00:43:47.130 --> 00:43:50.670
so math camp,
so asks how do we cluster the latent space?

735
00:43:50.970 --> 00:43:52.800
I assume we take z and then what?

736
00:43:54.230 --> 00:43:55.063
<v 0>MMM,</v>

737
00:43:56.350 --> 00:43:58.360
<v 1>that's a great question.
So the latent space,</v>

738
00:43:58.361 --> 00:44:02.590
we can actually visualize that with map plot live,
which we,
we will do.
And it's,

739
00:44:02.620 --> 00:44:06.610
it's actually,
it's going to be clustered already.
It's going to self cluster,

740
00:44:07.090 --> 00:44:08.530
it's going to self cluster.

741
00:44:08.770 --> 00:44:12.880
And we could just read that visually as humans and then say and then see like,

742
00:44:12.910 --> 00:44:14.740
oh,
all these data points are related over here.

743
00:44:14.800 --> 00:44:17.470
So for m and ist clusters are going to happen.

744
00:44:17.471 --> 00:44:19.120
And this is a great lead in question two.

745
00:44:19.121 --> 00:44:23.570
What I'm going to show you for and ist clusters are going to happen around,
uh,

746
00:44:23.620 --> 00:44:27.310
numbers.
So,
so all the ones,
all the representations of the one,

747
00:44:27.311 --> 00:44:30.610
all the images like of the number one are going to be represented together here.

748
00:44:30.611 --> 00:44:33.840
And then all of the twos are gonna be here and in threes,
right?
All these images,

749
00:44:33.841 --> 00:44:38.841
we're going to be clustered together in a similar space and light and space.

750
00:44:40.110 --> 00:44:41.960
Okay.
So,
uh,

751
00:44:42.930 --> 00:44:45.510
that's a great leading question to us defining our loss function.

752
00:44:45.511 --> 00:44:46.344
And you'll see why.

753
00:44:46.500 --> 00:44:51.480
So now we've got our generated or generated image and we want to compare the

754
00:44:51.481 --> 00:44:55.990
generated image to what we,
to the actual image,
right?

755
00:44:55.991 --> 00:44:57.640
So how do we,
we want to compare that,
right?

756
00:44:57.700 --> 00:45:00.190
Cause if we go back all the way up here,
what is it we want to do?

757
00:45:00.310 --> 00:45:04.540
We want to use a loss function to minimize the two distributions

758
00:45:05.890 --> 00:45:10.420
between the generated data and the true data.
And uh,
so what we do

759
00:45:11.580 --> 00:45:12.030
<v 0>okay,</v>

760
00:45:12.030 --> 00:45:16.730
<v 1>is we say,
this is what our last function looks like.
So get,</v>

761
00:45:16.740 --> 00:45:21.210
so get ready for this.
So math time,
this looks kind of scary,
doesn't it?

762
00:45:21.240 --> 00:45:22.980
Because it's not in plain English.

763
00:45:22.981 --> 00:45:27.210
Math is an entirely different beautiful language that we have to get used to.

764
00:45:27.540 --> 00:45:30.330
We just have to get used to it.
It just wasn't taught well in school.

765
00:45:30.840 --> 00:45:33.720
We're going to Redo all of that.
Okay.
We're going to Redo all of that.
Okay.

766
00:45:34.110 --> 00:45:35.910
Math teachers were so boring.

767
00:45:36.420 --> 00:45:40.380
Most of mine were and they didn't really didn't show the beauty that math is.

768
00:45:40.381 --> 00:45:42.540
Math is so beautiful.
Okay.
So let me,

769
00:45:42.690 --> 00:45:43.800
let me show you guys what I'm talking about here.

770
00:45:44.160 --> 00:45:47.280
So what we have here are three equations,
right?

771
00:45:47.281 --> 00:45:52.281
These three lines of all of these symbols that represent constant terms.

772
00:45:53.040 --> 00:45:54.150
These are laws,

773
00:45:54.180 --> 00:45:58.890
these are rules that we've found to always output a the same thing,
right?

774
00:45:59.130 --> 00:46:02.430
Given this given some set and certainly all of the same thing given send some

775
00:46:02.431 --> 00:46:05.640
set of inputs.
We can always,
I'll put a set of outputs.
So,

776
00:46:07.030 --> 00:46:11.620
so here's what this looks like.
So what we have here,
uh,
or

777
00:46:14.160 --> 00:46:15.960
a set of inputs and outputs.

778
00:46:17.360 --> 00:46:18.000
<v 0>Yeah.</v>

779
00:46:18.000 --> 00:46:20.670
<v 1>So what we want to calculate is the variational lower bound,</v>

780
00:46:20.671 --> 00:46:22.440
which is what this first equation is.

781
00:46:22.441 --> 00:46:27.441
It is the variational lower bound and it consists of these two other equations.

782
00:46:27.840 --> 00:46:31.590
So if we take these two other equations and combine them,
that's what this,

783
00:46:31.710 --> 00:46:33.560
that's what this topic equation.
So this topic,

784
00:46:33.561 --> 00:46:37.380
why Asian is called the variational lower bound,
and how do we calculate it?

785
00:46:37.500 --> 00:46:39.540
Or we take the log likelihood,

786
00:46:39.570 --> 00:46:43.680
the second value minus the KL divergence,

787
00:46:43.920 --> 00:46:46.290
which is this second dice.
So see,
see how this,
first of all,

788
00:46:46.291 --> 00:46:51.120
he says log p x a probability of x,

789
00:46:51.121 --> 00:46:55.960
given Z,
what is the law of probability of x given z?
Minus.
So we say it,

790
00:46:55.980 --> 00:47:00.090
we say it up here,
right?
Minus the Kale divergence term.

791
00:47:00.210 --> 00:47:02.550
And I'll talk about what each of these mean.
Okay.
So

792
00:47:03.940 --> 00:47:04.270
<v 0>yeah,</v>

793
00:47:04.270 --> 00:47:05.600
<v 1>the,
the very,</v>

794
00:47:05.601 --> 00:47:10.130
so the variational lower bound is what we want to minimize.
That is our,

795
00:47:10.280 --> 00:47:14.690
that is our final loss function.
And that's what,
that's what we call the,
the,

796
00:47:15.020 --> 00:47:19.070
the uh,
combination,
which is really the difference of these two terms.

797
00:47:19.190 --> 00:47:22.670
So let's talk about them in order.
So the first one is called the log likelihood.

798
00:47:22.760 --> 00:47:25.430
So what do I mean by the log likelihood?
So

799
00:47:26.950 --> 00:47:27.930
for the log likelihood,

800
00:47:28.400 --> 00:47:32.470
it tells us how effectively the decoder has learned to reconstruct an input

801
00:47:32.471 --> 00:47:36.070
image x given its latent representation z.

802
00:47:36.250 --> 00:47:40.240
So how effective is it?
How well did we compare these?

803
00:47:40.390 --> 00:47:45.390
How well does this new distribution right up here compared to the old one?

804
00:47:45.580 --> 00:47:48.460
We want them to be very similar.
And these are high dimension this,

805
00:47:48.461 --> 00:47:50.320
these are high dimensional distributions,
right?

806
00:47:50.380 --> 00:47:53.290
But we can just think of them for our sake as just that bell curve.

807
00:47:53.680 --> 00:47:57.490
We want them to fit.
We went to those two bell curves to look the same to,

808
00:47:57.970 --> 00:48:01.840
to be merged so that if you were to plot one on top of the other,

809
00:48:01.841 --> 00:48:03.550
you can tell a difference.
It would just be an outline.

810
00:48:03.880 --> 00:48:07.210
So that's what we want and that's what this term gives us.
Okay?

811
00:48:07.660 --> 00:48:11.890
That's what the log likelihood gives us.
Okay.
So,

812
00:48:12.040 --> 00:48:13.840
and we can write this out programmatically,
right?

813
00:48:13.930 --> 00:48:18.930
Still log likelihood is going to be the log probability of x given our given,

814
00:48:20.310 --> 00:48:23.650
that's the Kale divergence term.
So the,
the,
uh,
let's see,
let me,

815
00:48:23.680 --> 00:48:26.980
let me go down here.
We've got it.
I got to make this phone bigger.

816
00:48:27.760 --> 00:48:29.950
So let's start off with each of these terms.
Okay.

817
00:48:29.951 --> 00:48:33.970
So we've got the sigma sigma means that we have some set,
some set of values.

818
00:48:33.971 --> 00:48:37.420
So we're going to continuously perform these operations as a,
as a,
as a set.

819
00:48:37.840 --> 00:48:40.180
So we're going to say x times the log of y.

820
00:48:40.330 --> 00:48:42.640
And so we'll ride this out programmatically.
It's all the same.

821
00:48:42.641 --> 00:48:46.420
It's just a chain of operations that's going to give us this log likelihood.

822
00:48:46.830 --> 00:48:51.830
So we say x times a log of y plus one minus x times log of one minus Y,

823
00:48:54.340 --> 00:48:57.490
and then we can write to sell.
Okay.
And I'll show you that.

824
00:48:57.520 --> 00:48:59.770
And so this next term is the KL divergence term.

825
00:49:01.660 --> 00:49:03.280
So the cake for the Kale divergence term,

826
00:49:03.281 --> 00:49:08.140
if the encoder outputs of those representations of Zee are different than those

827
00:49:08.141 --> 00:49:11.290
from the standard normal distribution,
it's going to receive a penalty.

828
00:49:11.320 --> 00:49:13.810
So it's a regular realization term,
that's what we call it.

829
00:49:14.230 --> 00:49:18.670
Because if we didn't include this that the encoder would learn to cheat and give

830
00:49:18.700 --> 00:49:22.300
each data point or representation in a different region of Euclidean space.

831
00:49:22.450 --> 00:49:25.300
Euclidean space is the same as latent space.
In this case,

832
00:49:25.390 --> 00:49:26.680
it would just the same thing.

833
00:49:26.950 --> 00:49:31.950
So if we didn't use this regularization term than if I wrote a two and that's an

834
00:49:32.021 --> 00:49:36.270
image and I fed it to the model and they encoded it and it would plot it in

835
00:49:36.280 --> 00:49:39.760
representation space,
there'll be over here.
And then if someone else wrote it,

836
00:49:39.790 --> 00:49:44.350
let's say Jeff Dean wrote a two.
Okay.
And then encoded it.

837
00:49:44.590 --> 00:49:48.280
And then we plotted that if we didn't use irregular riser,

838
00:49:48.490 --> 00:49:50.440
then the both representations will be far off.

839
00:49:50.470 --> 00:49:53.170
It would just be like over here and over here.
But we don't want that.

840
00:49:53.171 --> 00:49:56.380
We want them to cluster.
And so that's what this does it,

841
00:49:56.381 --> 00:50:00.310
it makes sure that the distance between two values that should be very close

842
00:50:00.311 --> 00:50:04.630
together is small.
That's what the KL,
divergence or the,
the,
the,

843
00:50:04.720 --> 00:50:07.720
the full name of this as the,
was it coal,

844
00:50:07.721 --> 00:50:12.180
black Leibler divergence,
something like that.
And so the Kale lover,

845
00:50:12.220 --> 00:50:12.661
that's what it does.

846
00:50:12.661 --> 00:50:15.430
It minimize the distance between these two points so that there are cluster

847
00:50:15.431 --> 00:50:16.960
together,
which is what we want.

848
00:50:17.080 --> 00:50:21.970
So both of these equations do to respective things for us.
The first term,

849
00:50:22.820 --> 00:50:23.740
the first equation,

850
00:50:24.130 --> 00:50:28.430
the log likelihood is going to make sure that our reconstructed image is similar

851
00:50:28.970 --> 00:50:32.900
as possible to our input,
to our input image.
And the second term,

852
00:50:32.960 --> 00:50:35.870
the Kale divergence.
Make sure that the,
uh,

853
00:50:36.530 --> 00:50:40.810
that the values that we encode our are close together in hidden space in Layton

854
00:50:40.830 --> 00:50:43.280
space.
Okay.
So that's what both of them do.

855
00:50:43.281 --> 00:50:47.330
And if we take both of these terms and we subtract them,
and these are right.

856
00:50:48.020 --> 00:50:51.860
So the value on the left is what the entire equation equals.

857
00:50:51.980 --> 00:50:54.800
So we'll just use that over here.
If we just subtract,

858
00:50:54.801 --> 00:50:57.200
both of them will get the variational lower bound,

859
00:50:57.470 --> 00:51:01.280
which is what the ultimate loss function is.
Okay?
So,

860
00:51:02.890 --> 00:51:03.480
<v 0>okay.</v>

861
00:51:03.480 --> 00:51:06.930
<v 1>Um,
and what this is going to do is it's going to let us use to cast the gradient</v>

862
00:51:06.931 --> 00:51:09.540
descent,
which they standard backpropagation technique.

863
00:51:09.630 --> 00:51:14.580
It means backpropagation with respect to the variational parameters that those

864
00:51:14.581 --> 00:51:18.270
are the mean and the standard deviation.
Okay?
Uh,

865
00:51:18.300 --> 00:51:21.180
and so this is what it looks like programmatically,
right?

866
00:51:21.181 --> 00:51:26.070
And what we did here is we just wrote out each of these,

867
00:51:26.420 --> 00:51:29.370
uh,
values and operations.

868
00:51:29.580 --> 00:51:33.270
So if we were to look at that,
if we were to look at the,
um,

869
00:51:33.660 --> 00:51:35.940
what can we look at here?
Uh,

870
00:51:40.140 --> 00:51:42.840
let's see.
So for log likelihood,
we'll say x times TF.
Dot.

871
00:51:42.841 --> 00:51:45.540
Law of reconstruction plus one e minus nine.

872
00:51:45.600 --> 00:51:49.920
And what does it x times log likelihood y minus C,

873
00:51:49.980 --> 00:51:52.200
it's the same thing,
right?
It's,
it's the same exact thing.

874
00:51:52.650 --> 00:51:57.150
Plus one minus x times TF log,
but one mice,
sir.
You see how it's the same thing?

875
00:51:57.151 --> 00:52:01.440
Like we're just literally number by number operation by operation.

876
00:52:01.500 --> 00:52:05.290
We were just riding it out programmatically.
Right?
Anyone can do this.
It's,
it's,

877
00:52:05.320 --> 00:52:09.240
it's,
it's not hard just to get used to these symbols.
They're just symbols.
Okay.

878
00:52:09.241 --> 00:52:10.410
They just represent something.

879
00:52:10.440 --> 00:52:15.300
And for some people actually it's easier to look at the code.
And,
and for,
for me,

880
00:52:15.301 --> 00:52:16.860
for example,
it's actually easier for me,

881
00:52:17.130 --> 00:52:20.430
like for me to think about mathematical terms if I look at it programmatically

882
00:52:20.460 --> 00:52:24.960
because I'm programming anyway.
I'm not,
I'm not writing out equations anyway.

883
00:52:24.990 --> 00:52:26.460
Okay.
So,
but these are,

884
00:52:26.490 --> 00:52:30.060
these are standard terms and you'll see them a lot in papers.
Also.

885
00:52:30.090 --> 00:52:34.620
On a side note about math,
when you see just chains of equations and papers,

886
00:52:34.800 --> 00:52:39.800
it's easy to get afraid because we haven't learned to represent these equations

887
00:52:41.910 --> 00:52:43.350
in more condensed terms.

888
00:52:43.351 --> 00:52:46.170
So usually what you're going to see is you're going to see a condensed version

889
00:52:46.171 --> 00:52:50.250
of an equation and then you're gonna see it.
You're going to see the long form.

890
00:52:50.251 --> 00:52:51.390
So you're gonna see all of it.

891
00:52:51.630 --> 00:52:56.610
And so like the sigma term right here means the,
the stigma term.

892
00:52:56.640 --> 00:52:59.340
So this could actually be re this equation right here could actually be written

893
00:52:59.341 --> 00:53:02.700
out by lots and lots of equations,
but we use a sigma term to,

894
00:53:03.930 --> 00:53:07.470
to represent it.
Okay.
So those are our terms there.
And so,
right,

895
00:53:07.471 --> 00:53:09.270
so we've written out for the Kale term,

896
00:53:09.271 --> 00:53:11.460
the log likelihood and then we use our variational lower bound,

897
00:53:11.461 --> 00:53:15.330
which is a log likelihood minus the Kale term.

898
00:53:15.330 --> 00:53:18.810
And then we use the mean value of that.
And then we use our optimizer.

899
00:53:18.811 --> 00:53:23.070
So we're going to use a negative value here because of a,

900
00:53:23.130 --> 00:53:24.650
it's a little quirk with tensor flow,

901
00:53:24.651 --> 00:53:28.380
whereas if you were to use a positive value,
it wouldn't minimize it,

902
00:53:28.381 --> 00:53:32.190
it would maximize it.
So we're going to use a negative value to offset,
uh,
this,

903
00:53:32.191 --> 00:53:33.300
this core contents for flow.
And I've,

904
00:53:33.330 --> 00:53:36.260
and I've recorded that in the get hub and the read me not in the review,

905
00:53:36.270 --> 00:53:40.590
but in the code that you have.
Okay.
So yeah,
so that's our,
that's our term.

906
00:53:40.591 --> 00:53:43.320
And we're using a,
what was it we're using at a Delta,

907
00:53:43.321 --> 00:53:47.700
which is a form of stochastic gradient descent.
And uh,
yeah.
Okay.

908
00:53:47.701 --> 00:53:51.420
So let's keep going with training.
So now we initialize our variables.

909
00:53:51.421 --> 00:53:55.470
You've got her save her function here.
And then let me answer one question.

910
00:53:55.471 --> 00:53:57.630
By the way,
what are people saying here?

911
00:53:59.230 --> 00:54:00.100
<v 2>Uh,</v>

912
00:54:02.290 --> 00:54:06.730
<v 1>Bernoulli
better.
Newly.
Okay.</v>

913
00:54:07.390 --> 00:54:10.130
Oh my God.
This is one guy who's like,
I'm Italian and I have to say it.

914
00:54:10.150 --> 00:54:14.890
Stop using hands.
It was the funniest comment.
Um,
okay.
So,
okay.

915
00:54:15.280 --> 00:54:16.113
Two questions.

916
00:54:19.780 --> 00:54:20.613
<v 0>Okay.</v>

917
00:54:21.710 --> 00:54:23.210
<v 1>And has a lot of good questions.</v>

918
00:54:23.480 --> 00:54:27.560
Could you consider doing NLP for text mining using deep learning and work Tabak

919
00:54:28.250 --> 00:54:31.550
and topic model to automatically classify unstructured text?

920
00:54:33.200 --> 00:54:34.033
<v 2>Uh,</v>

921
00:54:34.930 --> 00:54:38.530
<v 1>you would use NLP for text mining.
That's,
that's a good thought.</v>

922
00:54:38.770 --> 00:54:43.690
Using deep learning.
That's it.
Even better thought and word to Vec.
Yeah,

923
00:54:43.930 --> 00:54:46.840
I actually did this in a video.
Uh,
what was it?

924
00:54:48.160 --> 00:54:52.150
Word vectors using game of Thrones.
So search Saroj word vectors.
Game of Thrones.

925
00:54:52.510 --> 00:54:55.600
Okay,
that's it.
All right.
Um,

926
00:54:59.270 --> 00:55:02.330
right.
So,
okay,
so it's a for training.
We're going to say,
okay,
let's,

927
00:55:02.390 --> 00:55:05.120
we're going to import time to clock our training time.
And we're saying,
okay,

928
00:55:05.121 --> 00:55:08.720
we want 100,000 iterations and we say we're recording [inaudible] interval is

929
00:55:08.721 --> 00:55:12.290
going to be a thousand because we want to print out things every thousand

930
00:55:12.291 --> 00:55:16.880
intervals.
And so we have these three arrays just for just for us,
for our,
uh,

931
00:55:17.060 --> 00:55:20.000
logging purposes.
They don't do anything like for the,

932
00:55:20.030 --> 00:55:24.380
for the actual computation there just for us to log this log of our values over

933
00:55:24.381 --> 00:55:26.060
time.
And so then we say,
okay,

934
00:55:26.061 --> 00:55:30.350
and same for iteration array is just for us for logging.
And so then we say,
okay,

935
00:55:30.830 --> 00:55:34.280
for all of those iterations and we're going to feed data into our model in

936
00:55:34.340 --> 00:55:34.881
batches.

937
00:55:34.881 --> 00:55:39.881
Like we always do batches of 200 to 200 images in a batch or we say,

938
00:55:39.951 --> 00:55:42.510
okay,
so the first batch went to you.
Um,

939
00:55:43.550 --> 00:55:47.570
and were you use a round functions to make sure it's binary feed into x batch.

940
00:55:47.630 --> 00:55:50.210
And then this is how we feed it into our model.
We say section dot.

941
00:55:50.211 --> 00:55:54.890
Ron Given our off optimizer feed Dick.
And we always fit it in,
in,
in terms of,
in,

942
00:55:54.891 --> 00:55:59.270
in a dictionary x batch.
And there's no target labels,
right?
There's no,

943
00:55:59.330 --> 00:56:03.200
this is unsupervised learning.
There are no labels here.
Okay.
So then,

944
00:56:03.840 --> 00:56:07.150
and this is where,
and then every interval,
uh,

945
00:56:07.400 --> 00:56:09.500
every thousand iterations,

946
00:56:09.590 --> 00:56:12.080
we're going to print out the values that we are in for,
for,

947
00:56:12.470 --> 00:56:15.170
for all of these terms here.
Okay.
And so then when we train it,

948
00:56:17.320 --> 00:56:18.153
<v 2>mmm.</v>

949
00:56:21.280 --> 00:56:23.320
<v 1>So you see it's training right now.
It's gonna take awhile,</v>

950
00:56:23.660 --> 00:56:27.220
but let's wait for her to train.
Let me answer a question while the trains.
Uh,

951
00:56:31.110 --> 00:56:31.943
<v 0>okay.</v>

952
00:56:32.140 --> 00:56:33.160
<v 1>So</v>

953
00:56:34.660 --> 00:56:39.390
another question before we get started with the good stuff is a

954
00:56:42.040 --> 00:56:46.590
make a video on basic pandas dataset.
All tutorials are already processed.

955
00:56:46.820 --> 00:56:49.480
I don't know any book recommendations for ml.
Yeah.

956
00:56:49.600 --> 00:56:53.350
So the deep learning book by Bengio actually,
you know,

957
00:56:53.351 --> 00:56:56.560
just to really condense what I'm asking you to look at.
So yeah,

958
00:56:56.561 --> 00:56:59.110
it's training right here,
blah,
blah,
blah.
Stop Training.

959
00:56:59.670 --> 00:57:03.910
That's going to take some of my Mac book would probably take like six hours to

960
00:57:03.911 --> 00:57:08.570
train this.
Uh,
just read that math chapter that first met.

961
00:57:08.580 --> 00:57:11.410
Like what does the math needed for deep learning?
Like that's a great chapter.

962
00:57:11.860 --> 00:57:15.670
It's a great chapter.
And uh,
I've got some great stuff coming out on that,

963
00:57:15.671 --> 00:57:16.900
but I'm not going to spoil you guys too much.

964
00:57:16.901 --> 00:57:19.510
So let's assume we've trained it and then we plotted it.

965
00:57:19.511 --> 00:57:21.100
And so this plot is what,

966
00:57:21.101 --> 00:57:25.840
why we is why we collected those values in arrays so that we could plot the

967
00:57:25.841 --> 00:57:28.480
values of these three loss terms over time.

968
00:57:28.780 --> 00:57:32.140
And you could see that they are converging.
They are,

969
00:57:32.190 --> 00:57:35.560
they are minimizing like that.
Okay.
Uh,

970
00:57:39.120 --> 00:57:43.770
but uh,
right and so actually,

971
00:57:43.890 --> 00:57:46.680
so these last terms should be going the opposite way.

972
00:57:46.681 --> 00:57:50.820
Like it should be going like that.
Not like that.
So if we were to flip this,

973
00:57:50.821 --> 00:57:51.051
they should,

974
00:57:51.051 --> 00:57:54.210
it should look like that because I lost minimizing this is actually increasing.

975
00:57:54.420 --> 00:57:57.810
And I think this is because we set the,
uh,
remember how we set the,

976
00:57:58.180 --> 00:58:01.710
the variation variational lower bound,
too negative.
I think that's why I,

977
00:58:01.711 --> 00:58:06.120
but it should be going down.
Okay.
So then for our results,

978
00:58:06.150 --> 00:58:08.790
here's how we plot out her images.
So we say,
okay,

979
00:58:08.791 --> 00:58:13.320
so let's take some images from our testing set and then we reshape it to 28 by

980
00:58:13.321 --> 00:58:17.010
28 pixels.
And then we say,
okay,
for a subplot,
let's plot it.
Okay.

981
00:58:17.190 --> 00:58:21.150
And so that's what it,
so that's what's,
what's on the left here.
Looks like.
Okay.

982
00:58:21.151 --> 00:58:24.770
So what's on the left here?
These are our test images and the ones on our right,

983
00:58:24.820 --> 00:58:27.660
our,
our reconstructed images to say,
okay,

984
00:58:28.650 --> 00:58:33.210
reconstruction dot evil feed dick x.
So we,
we take our,

985
00:58:33.550 --> 00:58:34.383
um,

986
00:58:35.550 --> 00:58:39.420
test image and we feed it directly to that reconstruction,

987
00:58:40.200 --> 00:58:44.910
uh,
layer at the very end,
right up here,
this last layer of the decoder,

988
00:58:45.090 --> 00:58:49.110
we feed it in directly using the evil function of tensor flow.
And we say,
okay,

989
00:58:49.111 --> 00:58:53.250
so feed that directly to the x reconstruction,
reshape it to it's 20 by 28,

990
00:58:53.251 --> 00:58:56.100
whatever it is,
it's going to be output of whatever,
it's not a values,

991
00:58:56.130 --> 00:59:00.750
and then plot it.
And we could see how we've now reconstructed these values.

992
00:59:00.870 --> 00:59:04.800
Okay.
Um,
and so haven't wrapped in a while.

993
00:59:04.801 --> 00:59:09.000
So I'm going to rap about something.
So let's see.
Uh,
I've got 390 people.

994
00:59:09.001 --> 00:59:13.710
So let's see,
for a wrap,
I'm just going to rap about variational audit.
Actually,

995
00:59:13.950 --> 00:59:16.080
if I were to wrap about variational audit encoders,

996
00:59:16.350 --> 00:59:19.680
then you would think that it's off that I've planned something.

997
00:59:19.681 --> 00:59:22.940
So what I'm going to do as I'm to ask one of you guys to take say a topic and

998
00:59:22.941 --> 00:59:26.210
I'm going to rap about it because the lesson is over.
So the wrap is here.

999
00:59:26.211 --> 00:59:27.210
So someone says,

1000
00:59:27.220 --> 00:59:31.490
shout out a topic that you want me to rap it out in machine learning or deep

1001
00:59:31.491 --> 00:59:35.930
learning.
Well,
I answered some questions.
So with this technique,

1002
00:59:35.931 --> 00:59:37.640
is it possible to generate content,

1003
00:59:37.730 --> 00:59:42.730
textual basing and pulverized pulverize news about this theme and the Internet?

1004
00:59:45.080 --> 00:59:45.760
<v 0>Yeah.</v>

1005
00:59:45.760 --> 00:59:50.460
<v 1>Good job for using that term.
Pulverized.
Yes.
You can create fake news.</v>

1006
00:59:50.510 --> 00:59:55.480
Absolutely.
I mean this is,
this has been done.
Yeah.
Don't rap,

1007
00:59:55.481 --> 00:59:59.380
rap and Hindi.
What a rap about Mexican cartels.
That's not relevant.

1008
01:00:00.460 --> 01:00:04.510
I am a super newb.
C'Mon guys.
Russian girls guys.

1009
01:00:05.020 --> 01:00:07.690
That's not deep learning.
I mean it could be,
it will be in the future,
but

1010
01:00:08.290 --> 01:00:09.123
<v 0>uh,</v>

1011
01:00:10.780 --> 01:00:12.610
<v 1>I am waiting for a term guys.
Come on.</v>

1012
01:00:13.520 --> 01:00:14.160
<v 0>Okay,</v>

1013
01:00:14.160 --> 01:00:18.510
<v 1>cycle again.
There it goes.
So
go for it.
Let's,</v>

1014
01:00:18.670 --> 01:00:22.360
I've got my DJ over here.
There we go.
Psycho.
Gans everybody,

1015
01:00:22.690 --> 01:00:27.160
it's time for the cycle.
Are you ready for the cycle again?
Cause we're gonna go.

1016
01:00:27.550 --> 01:00:31.570
We're gonna talk about cycle.
Gans
Psycho.

1017
01:00:31.660 --> 01:00:35.970
Gans it's like I do it when I ride my bicycle.
Man.
I do it every day.

1018
01:00:36.180 --> 01:00:40.200
I was talking about gangs,
but right now it's about to be via is.

1019
01:00:40.201 --> 01:00:44.040
I'm like a clown.
Wait,
listen,
I'm trying to listen to this beat.

1020
01:00:44.250 --> 01:00:49.080
I'm trying to wrap about generative adversarial.
Neat.
It's so cool when I do it.

1021
01:00:49.290 --> 01:00:52.350
I've got networks that generate stuff like I'm a fluid.

1022
01:00:52.560 --> 01:00:55.620
You could generate new fluids,
you could generate everything.

1023
01:00:55.621 --> 01:00:59.190
You could generate anything that your mind thinks it's all the same.

1024
01:00:59.250 --> 01:01:02.370
You take some data.
You weren't a distribution man,
man.

1025
01:01:02.371 --> 01:01:05.490
It's like Mu Alpha Theta in maths in high school.

1026
01:01:05.491 --> 01:01:10.320
Remember that club that you were in everyday,
man,
it's like a flub.
Yo.

1027
01:01:10.620 --> 01:01:15.300
Anything that I said rhymes because it's like online every time.

1028
01:01:15.420 --> 01:01:18.360
Okay,
so that was it.
Uh,
right.

1029
01:01:18.361 --> 01:01:23.361
So thanks guys for showing up for this and uh,

1030
01:01:25.430 --> 01:01:25.720
<v 0>okay.</v>

1031
01:01:25.720 --> 01:01:30.150
<v 1>No,
are we've got,
uh,
what do we've got?
We've got a hundred.</v>

1032
01:01:30.240 --> 01:01:31.320
Got 375 people here.

1033
01:01:31.410 --> 01:01:34.380
Thanks for watching guys and make sure to look at this stuff.

1034
01:01:34.381 --> 01:01:36.920
The code is in the read me,
the code is,
uh,

1035
01:01:36.960 --> 01:01:39.360
the code is in the getting the get hub repo and the description.

1036
01:01:39.570 --> 01:01:41.100
I want you guys to start generating things.

1037
01:01:41.101 --> 01:01:43.350
We don't have enough people generating cool stuff.

1038
01:01:43.351 --> 01:01:46.650
We only have people generating m and ice tea digits and faces.

1039
01:01:46.830 --> 01:01:49.830
Let's start generating some cool stuff.
Let's start generating DNA sequences.

1040
01:01:50.040 --> 01:01:51.450
Let's start generating,
uh,

1041
01:01:52.740 --> 01:01:57.740
like new fashion styles and just let's start generating entire three d worlds

1042
01:01:59.971 --> 01:02:04.971
and maps and just alternate realities and just things that you would never even

1043
01:02:06.421 --> 01:02:08.790
imagine.
Entire movies.
We're going to generate all of that stuff.
Okay.

1044
01:02:08.791 --> 01:02:12.540
So thanks guys for showing up.
Come and do a hit in Moscow.

1045
01:02:12.541 --> 01:02:16.170
I would love to come to Moscow when I do go to Moscow.

1046
01:02:16.171 --> 01:02:19.860
Hopefully I don't die if I go there.
No,
I'm just kidding.
I love Moscow.
I don't,

1047
01:02:20.130 --> 01:02:22.700
I can't say I love it because I haven't been there,
but I love Russian dot.

1048
01:02:22.780 --> 01:02:27.600
[inaudible] pizza.
Okay.
Uh,

1049
01:02:28.440 --> 01:02:32.610
yes,
I know Russian Donnie's nine.
Krosky you didn't expect that,
did you?

1050
01:02:33.240 --> 01:02:37.590
No one expects that I actually know a lot of languages.
Okay.
So seven in fact,

1051
01:02:38.130 --> 01:02:41.290
uh,
not including programming.
Bye guys.
I love you guys.
Think for now,

1052
01:02:41.310 --> 01:02:42.750
I've got to go,
uh,

1053
01:02:43.470 --> 01:02:47.430
work on generative adversarial networks,
so thanks for watching.

