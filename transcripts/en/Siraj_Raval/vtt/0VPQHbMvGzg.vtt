WEBVTT

1
00:00:05.290 --> 00:00:08.320
Hello world,
it's Saroj welcome to this live stream that,

2
00:00:08.380 --> 00:00:12.670
and in this livestream we're going to talk about generative adversarial
networks.

3
00:00:12.970 --> 00:00:15.580
Okay.
I've talked about it in the past in the last video,

4
00:00:15.700 --> 00:00:18.910
but now we're going to really dive into how they work.
So get ready for this.

5
00:00:18.911 --> 00:00:22.660
This is some bleeding edge tech and thank you all for coming to this live

6
00:00:22.661 --> 00:00:23.494
session.

7
00:00:23.590 --> 00:00:27.610
I've got this Jupiter notebook set up and what I'm going to do is I'm going to

8
00:00:27.790 --> 00:00:30.430
talk about parts of the code that you know,

9
00:00:30.431 --> 00:00:34.870
they're basically repeats of what we've already done and I'm going to code the

10
00:00:34.871 --> 00:00:39.040
parts that are particularly interesting,
the parts that matter a lot,

11
00:00:39.100 --> 00:00:40.800
that the parts that are unique to gans.

12
00:00:40.801 --> 00:00:43.810
So in this case it's going to be the math part,
uh,

13
00:00:43.840 --> 00:00:47.470
specifically the loss functions and then how we train gans.
Uh,

14
00:00:47.471 --> 00:00:49.540
so definitely check out the Jupiter notebook.

15
00:00:49.540 --> 00:00:51.370
It's in the description for this video.

16
00:00:51.400 --> 00:00:55.360
And in this next hour we're going to talk about all the details of,
of Gans,

17
00:00:55.361 --> 00:00:57.910
how they work,
how you could implement them yourselves,

18
00:00:58.060 --> 00:01:00.520
and ways for you to think about in your,

19
00:01:00.550 --> 00:01:04.090
whether you're trying to create a startup or you're implementing this in

20
00:01:04.091 --> 00:01:04.810
production,

21
00:01:04.810 --> 00:01:08.860
or whether you're trying to do some kind of research around gans directions that

22
00:01:08.861 --> 00:01:11.590
you can move.
Okay,
so that's what this livestream is all about.

23
00:01:11.980 --> 00:01:15.520
What I'm gonna do is I'm going to start off by answering questions for two

24
00:01:15.521 --> 00:01:19.600
minutes and then we're going to just get into the code.
All right.

25
00:01:19.601 --> 00:01:21.250
Code and theory.
So

26
00:01:23.480 --> 00:01:25.960
cycled gans are coming soon.
We've got cycle gans,

27
00:01:25.961 --> 00:01:30.520
we've got w Gannon's we got by gangs.
There's a lot of guns out there.
Fantastic.

28
00:01:30.521 --> 00:01:34.120
Gans and where to find them.
That should be the name of a book by Jk Rowling.

29
00:01:34.210 --> 00:01:37.450
So actually it is a blog post by the way,
which I want you guys to check out.

30
00:01:37.451 --> 00:01:42.130
I'll actually pointed point to point you to it in a second.
But yeah,

31
00:01:42.131 --> 00:01:45.190
generative models are really cool.
I'm really into generative models.

32
00:01:45.400 --> 00:01:49.090
And if you were to ask me Saroj,
what would you do?
A,

33
00:01:49.150 --> 00:01:50.680
if you were to do research full time,

34
00:01:50.681 --> 00:01:54.940
I would say I would focus on improving optimization techniques for generative

35
00:01:54.941 --> 00:01:59.860
adversarial networks.
That,
or synthetic gradients or one shot learning,

36
00:02:00.010 --> 00:02:03.730
which I haven't even touched on yet,
but that's at the end of the course.
Okay.

37
00:02:03.731 --> 00:02:04.780
So two questions.

38
00:02:05.050 --> 00:02:09.460
Can you make a tutorial on loading a pretrained model like inception net?

39
00:02:10.210 --> 00:02:14.800
So yeah,
I can do that,
but the,
at the same time,
uh,
that's,
yeah,
that is a,

40
00:02:14.801 --> 00:02:19.000
that is a very trivial tutorial because using a pretrained model is just a few

41
00:02:19.001 --> 00:02:23.140
lines of code,
right?
You just load it up as a checkpoint in tensorflow and then,

42
00:02:23.520 --> 00:02:28.210
uh,
feed your data to it.
But yeah,
I can do that in a second.

43
00:02:28.211 --> 00:02:32.110
All right.
All right.
So everybody is excited for Gans right now.

44
00:02:32.170 --> 00:02:35.890
And so one more question before we get started is,
uh,

45
00:02:35.920 --> 00:02:40.900
what do you think about using gans to sequence length without,
okay.
No,
no,

46
00:02:40.901 --> 00:02:41.620
no.
Wait,

47
00:02:41.620 --> 00:02:44.800
what do you think about using gans to produce data sets and reinforcement

48
00:02:44.801 --> 00:02:47.830
learning environments?
That's a great question.
So I,

49
00:02:48.220 --> 00:02:51.700
I have never seen gans applied to reinforcement learning.
Uh,

50
00:02:51.701 --> 00:02:54.340
although that would be a great

51
00:02:55.870 --> 00:03:00.190
research idea.
I,
I don't,
I don't,
I don't.
So have to frame that problem.

52
00:03:00.191 --> 00:03:02.830
Like what would that look like?
So in a reinforcement learning environment,

53
00:03:03.100 --> 00:03:05.690
you have trial and error,
you have a reward value and you're,

54
00:03:05.691 --> 00:03:08.230
you're trying to optimize.
So your agent is,

55
00:03:08.290 --> 00:03:11.260
is getting the most reward for whatever your objective is.

56
00:03:11.440 --> 00:03:15.130
So how would again fit into that framework of thinking?
Uh,

57
00:03:15.250 --> 00:03:18.910
generative adversarial networks are used to generate data that looks similar to

58
00:03:18.911 --> 00:03:19.744
training data.

59
00:03:19.870 --> 00:03:24.870
So you would want to perhaps generate or simulate different types of states,

60
00:03:26.380 --> 00:03:27.430
different environments,

61
00:03:27.550 --> 00:03:31.570
and have your agent or multiple agents run in all of these variations of these

62
00:03:31.571 --> 00:03:32.404
environments.

63
00:03:32.410 --> 00:03:35.080
And it would be optimizing for rewards and each of these environments.

64
00:03:35.200 --> 00:03:39.510
And what would happen is just by trying out all the different environments,
the,

65
00:03:39.590 --> 00:03:41.950
the agent,
the sum total of,
of the,

66
00:03:42.310 --> 00:03:47.310
of the weights of the agents would be so good that they would be generalized to

67
00:03:47.351 --> 00:03:51.760
any once any one variation of those environments,
if that makes sense.

68
00:03:51.760 --> 00:03:54.730
So we're talking about simulations.
So like cities,

69
00:03:54.731 --> 00:03:55.750
like different types of cities.

70
00:03:55.751 --> 00:04:00.360
So like then your agent will be able to navigate through any city because it,

71
00:04:00.390 --> 00:04:02.410
it's,
it's navigated through multiple cities.
So that's,

72
00:04:02.411 --> 00:04:05.890
that's a possible on the fly idea I just thought about,
so anyway,
so let's,

73
00:04:05.891 --> 00:04:08.470
let's get,
let's get start with the code here.
Okay.
Uh,

74
00:04:08.471 --> 00:04:13.030
we have a lot to live up to in this livestream.
Gans are very,
uh,
cool right now.

75
00:04:13.031 --> 00:04:16.570
They're also notoriously difficult to train,
which we'll talk about.
So what is,

76
00:04:16.571 --> 00:04:21.100
what is a type of gang we'll be using in this tutorial?
We will be using a,
uh,

77
00:04:21.760 --> 00:04:25.930
a deep convolutional generative adversarial network.
Okay.
What does that mean?

78
00:04:25.931 --> 00:04:29.020
That means we have to convolutional networks.
Well,
we have,

79
00:04:29.740 --> 00:04:32.800
we have a convolutional network,
which is the,
uh,

80
00:04:34.410 --> 00:04:38.380
a generator.
And we have the deep convolutional network,

81
00:04:38.381 --> 00:04:39.610
which is the discriminator.

82
00:04:39.640 --> 00:04:44.110
So we have a convolutional network that takes in a set of numbers and then it

83
00:04:44.111 --> 00:04:46.780
converts it to an image and then a d convolutional network.

84
00:04:46.800 --> 00:04:49.420
It takes in an image and converts it to a set of numbers.

85
00:04:49.540 --> 00:04:52.510
And so why do we have the generator be a convolutional net and why do we have

86
00:04:52.511 --> 00:04:54.310
the discriminator be a d convolutional net?

87
00:04:54.730 --> 00:04:59.730
Because we are going to generate a handwritten character digits that look very

88
00:04:59.771 --> 00:05:02.080
similar to the,
to those that already exist.

89
00:05:02.260 --> 00:05:05.800
So the generator is going to continuously generate,
uh,

90
00:05:06.100 --> 00:05:09.130
images that look similar to the handwritten character digits,

91
00:05:09.160 --> 00:05:13.600
which are these and the discriminator,
we'll say,
are those real,

92
00:05:13.601 --> 00:05:16.690
are those a part of the training data or are they not?
Are they generated?

93
00:05:16.930 --> 00:05:18.580
So it has to answer to detect.

94
00:05:18.730 --> 00:05:21.880
It's going to take in that image and it's going to output probabilities if it's

95
00:05:21.881 --> 00:05:22.990
real or fake.

96
00:05:23.290 --> 00:05:28.120
And both of these train with their own respective loss functions over time and

97
00:05:28.121 --> 00:05:30.760
eventually they both get really good at doing their job generator.

98
00:05:30.761 --> 00:05:34.480
We'll get really good at generating a fake digits to try to fool the

99
00:05:34.481 --> 00:05:38.440
discriminator and the discriminator we'll get really good at tried to detect if

100
00:05:38.441 --> 00:05:42.580
those images are real or fake.
That's the high level and that's the high level.

101
00:05:42.610 --> 00:05:43.443
Okay.

102
00:05:43.540 --> 00:05:47.440
So what we're doing is we're building a deep convolutional Gan and the generator

103
00:05:47.470 --> 00:05:49.450
is going to,
let's see,
let's look at what this looks like.

104
00:05:49.451 --> 00:05:51.130
I've got a little short video for you guys here.

105
00:05:51.430 --> 00:05:55.950
When we're generating faces over time,
this is what it looks like.
See,
they are,

106
00:05:55.990 --> 00:05:59.540
it's going to iteratively better and better.
How creepy slash awesome is that.

107
00:06:00.350 --> 00:06:04.580
Check that out.
Okay.
It gets better just like that.
And

108
00:06:07.990 --> 00:06:12.990
the other thing I want to talk about is the techniques that are used for deep

109
00:06:13.661 --> 00:06:17.890
convolutional gans to improve on Vanilla Gans.
So Vanilla Gans like the,
the,

110
00:06:17.891 --> 00:06:22.210
the first paper by Ian Goodfellow was great,

111
00:06:22.240 --> 00:06:25.420
but since then there've been a lot of papers that have built on this,

112
00:06:25.450 --> 00:06:26.680
on this idea.
Okay?

113
00:06:26.681 --> 00:06:30.910
So the first and so deep convolutional Gantz improve them from the vanilla gans

114
00:06:31.090 --> 00:06:35.560
in two ways.
The first way is they used batch normalization.

115
00:06:35.710 --> 00:06:38.500
So this is,
this is something that is very important to talk about.

116
00:06:38.501 --> 00:06:42.850
Bathroom lization what is this?
So normally,
so let me just shoot this up here.

117
00:06:43.090 --> 00:06:47.830
This is the algorithm for batch normalization.
What is this?
So,
uh,

118
00:06:47.890 --> 00:06:52.890
recall that a very important preprocessing step for neural networks is to

119
00:06:53.290 --> 00:06:57.160
normalize your data so that all of your features are on the same scale,
right?

120
00:06:57.161 --> 00:07:01.750
And so if you have weight as one feature and it's on a scale of say zero to 300

121
00:07:01.751 --> 00:07:06.250
in terms of pounds as a metric versus something like,
uh,
I dunno,

122
00:07:06.460 --> 00:07:09.400
hair length,
which is going to be on in the middle of the millimeter scale,

123
00:07:09.640 --> 00:07:14.260
it's hard for your model to converge when you have two wildly different,
uh,

124
00:07:14.710 --> 00:07:16.900
metrics.
So what we do is we normalize,

125
00:07:16.901 --> 00:07:19.690
so they're all going to be on the same scale,
be that zero to one,

126
00:07:19.810 --> 00:07:23.890
which is the normal normal case or zero to 10 or whatever,
whatever it is.

127
00:07:24.010 --> 00:07:28.120
And what this does is it helps our model converge batch normalization is a

128
00:07:28.121 --> 00:07:32.770
technique that was invented two years ago and in 2015 which says let do

129
00:07:32.771 --> 00:07:36.700
normalization in mini batches.
So let's just normalize all over the place.

130
00:07:36.850 --> 00:07:41.530
And what happened is when they did this,
it improved their convolutional net.

131
00:07:41.680 --> 00:07:46.480
They're state of the art convolutional net by not in terms of accuracy but,

132
00:07:46.510 --> 00:07:51.280
but in terms of uh,
computational efficiency.

133
00:07:51.281 --> 00:07:55.510
So it achieved the same results in 14 times,
uh,

134
00:07:55.560 --> 00:08:00.340
this 14 times faster than it did then it would without batch mineralization.

135
00:08:00.490 --> 00:08:04.540
So clearly a very important technique and we'll see it implemented in this code

136
00:08:04.720 --> 00:08:08.710
as just one line of code.
Okay?
And so here's what it does.
It says,
okay,

137
00:08:09.270 --> 00:08:12.010
to just go over this real briefly,
we say,
okay,

138
00:08:12.011 --> 00:08:15.970
so sigma notation means for all of our samples,

139
00:08:15.990 --> 00:08:20.140
m are the number number of samples in our code.
Let's get the variance,
okay.

140
00:08:20.141 --> 00:08:20.531
And so the,

141
00:08:20.531 --> 00:08:25.531
so this value right here is going to represent our mean value over over our,

142
00:08:26.710 --> 00:08:28.990
uh,
all of our samples.

143
00:08:29.230 --> 00:08:31.750
And then we're going to calculate the variance over those samples.

144
00:08:31.751 --> 00:08:34.930
And so that's what this value is,
that we're going to take both of those values,

145
00:08:34.931 --> 00:08:36.940
the mean and the variance,
and we're going to,

146
00:08:37.060 --> 00:08:40.260
we're going to find a difference between the two.
Okay?
Uh,
or sorry,

147
00:08:40.420 --> 00:08:45.420
the difference between each sample and the mean over the square root of the

148
00:08:45.461 --> 00:08:49.000
variance plus epsilon,
which is a constant term.

149
00:08:49.210 --> 00:08:52.450
And that's going to give us x hat,
which is the normalization term.

150
00:08:52.720 --> 00:08:56.820
We take that and we multiply it by constants here.

151
00:08:56.850 --> 00:08:59.010
These are Lauren parameters.
Okay.
And you'll,

152
00:08:59.030 --> 00:09:02.220
you'll see what I'm talking about here and that's going to give us the,
uh,

153
00:09:02.340 --> 00:09:06.570
which basically scale each of these.
So this one's scales and the shifts.
Okay.

154
00:09:06.571 --> 00:09:10.740
Scale by multiplying and then shift by adding,
and that's going to give us a y.

155
00:09:10.770 --> 00:09:14.370
Okay.
So that's batch normalization in a nutshell.

156
00:09:14.610 --> 00:09:18.540
The other important thing that they did was that they used Relu.
Okay,

157
00:09:18.541 --> 00:09:21.780
so Relu as opposed to,
uh,
what was it?

158
00:09:21.930 --> 00:09:25.680
Sigmoid when it comes to deep convolutional gans,
they outperformed them.

159
00:09:25.681 --> 00:09:27.030
That's all.
Okay.
So that was,

160
00:09:27.031 --> 00:09:30.930
those were the two main improvements that they made for,
for these,

161
00:09:30.960 --> 00:09:34.970
for these networks.
Okay.
So gans are hard to train.
They're not easy to train it.

162
00:09:35.070 --> 00:09:37.740
If you've ever raise your hand,
if you've ever tried to train again,

163
00:09:38.910 --> 00:09:41.580
I don't care if I can't see you.
Raise your hand anyway.
Okay.
See,

164
00:09:41.670 --> 00:09:45.250
so that's probably a lot of people,
I'm just guessing.
But,
uh,

165
00:09:45.630 --> 00:09:47.670
there are hard to train and,
and they're not easy.

166
00:09:47.671 --> 00:09:52.220
So what I can do is I can say generative adversarial network visualization.

167
00:09:52.240 --> 00:09:54.210
I want to show you guys what this looks like to train.

168
00:09:54.211 --> 00:09:59.211
So if we were to look at what this looks like visually,

169
00:09:59.700 --> 00:10:03.450
so in terms of a,
a video,
it would look like this.

170
00:10:06.080 --> 00:10:06.290
<v 0>Okay?</v>

171
00:10:06.290 --> 00:10:09.680
<v 1>Convergence is nontrivial for generative adversarial networks.</v>

172
00:10:09.681 --> 00:10:11.420
There's so many things that can go wrong.

173
00:10:11.780 --> 00:10:16.280
There's so many things that can go wrong.
Okay.
This,

174
00:10:16.281 --> 00:10:20.600
this is some really wonky looking ish.
Let's see what this is,

175
00:10:20.601 --> 00:10:23.120
what's happening here.
Okay,
hold on.
Let me just,

176
00:10:26.110 --> 00:10:30.250
okay.
So what we want,
just look at the top left or this,

177
00:10:30.550 --> 00:10:33.830
look at this box right here.
Okay.
We want those green and blue,
uh,

178
00:10:34.030 --> 00:10:38.440
values to merge together,
okay?
So they're on the same plane.
Uh,
just,

179
00:10:38.441 --> 00:10:40.450
just for the sake of a visualization.

180
00:10:40.630 --> 00:10:43.840
But what's happening is what happens is sometimes the discriminator,

181
00:10:43.870 --> 00:10:46.120
sometimes a generator fools a discriminator.

182
00:10:46.420 --> 00:10:50.200
By finding one value in this,
in the,

183
00:10:50.201 --> 00:10:52.820
in the appropriate data distribution,
it finds one,

184
00:10:52.900 --> 00:10:57.370
one value that that would fool the discriminator every time and it sticks to it

185
00:10:57.490 --> 00:11:00.910
and doesn't try anything else.
So then you're,
you think that your model is like,

186
00:11:00.970 --> 00:11:04.870
Hey,
I've converged buddy,
it's over.
But actually it's just found one value.

187
00:11:05.080 --> 00:11:08.110
So you have to mitigate for that.
The other important thing,
and this is,

188
00:11:08.170 --> 00:11:13.060
this is what I find very interesting is when we have,

189
00:11:13.150 --> 00:11:13.983
uh,

190
00:11:14.660 --> 00:11:15.220
<v 0>okay,</v>

191
00:11:15.220 --> 00:11:17.740
<v 1>these loss functions not,
which I'm going to show you down here.</v>

192
00:11:17.920 --> 00:11:20.590
These are our two loss functions.
By the way,
we'll get to these.
I just,

193
00:11:20.591 --> 00:11:22.090
I just really want to talk about that for a second.

194
00:11:22.600 --> 00:11:25.720
The first loss function up here is for the discriminator.
Okay?

195
00:11:25.721 --> 00:11:28.270
This is what we want to minimize for the discriminator.

196
00:11:28.450 --> 00:11:30.400
The second loss function is for the generator,

197
00:11:30.401 --> 00:11:31.600
and I'll talk about the details here,

198
00:11:31.601 --> 00:11:35.440
but just know that we have to loss function for generative adversarial networks,

199
00:11:35.710 --> 00:11:38.350
one for the discriminator and one for the generator.

200
00:11:38.590 --> 00:11:42.760
And they're not meant for generative adversarial networks.

201
00:11:42.970 --> 00:11:45.520
These are,
this is the castic gradient descent.

202
00:11:45.790 --> 00:11:48.340
These are meant for convolutional networks.

203
00:11:48.370 --> 00:11:50.980
They're meant for feed forward and recurrent networks.

204
00:11:51.160 --> 00:11:55.870
But what we've done is we've applied to this adversarial approach when in fact

205
00:11:55.871 --> 00:12:00.280
we should be,
which is more of a game than an optimization problem.
It's,

206
00:12:00.300 --> 00:12:03.070
it is,
it is high level and optimization problem,

207
00:12:03.280 --> 00:12:05.980
but it's not a problem where we are trying to minimize

208
00:12:07.480 --> 00:12:11.910
the cost function of a,
of one network.
We have two networks and they're,
you know,

209
00:12:11.930 --> 00:12:15.030
they,
they have this very specific type of scenario that they're going through

210
00:12:15.050 --> 00:12:17.170
together.
And,
uh,

211
00:12:17.560 --> 00:12:22.480
we need better optimization techniques for generative adversarial networks and

212
00:12:22.570 --> 00:12:26.890
we need those techniques to be made for a game theoretic approach.

213
00:12:26.891 --> 00:12:29.260
So this is a great space for research.

214
00:12:29.410 --> 00:12:34.240
A lot of optimization for generative adversarial networks are that use to cast

215
00:12:34.241 --> 00:12:35.110
the gradient descent,

216
00:12:35.230 --> 00:12:38.800
which are most of them implement some kind of hacky technique,
which you'll see.

217
00:12:38.830 --> 00:12:42.490
And I'll,
and I'll even,
we're actually going to do as well as you can see here,

218
00:12:42.730 --> 00:12:46.420
0.5,
0.45 these magic numbers right here.
Okay.

219
00:12:46.870 --> 00:12:51.490
Less than points 0.6.
Okay.
So that's,
that's the high level.
Okay.
So let's,
let's,

220
00:12:51.520 --> 00:12:53.980
let's,
let's start talking about the code here.
So remember,

221
00:12:54.130 --> 00:12:57.790
I'm going to code the parts that I think are really relevant and then just gloss

222
00:12:57.791 --> 00:13:02.710
over the parts that are just standard.
Like this.
For example,
importing am an ist.

223
00:13:02.920 --> 00:13:06.070
We all know how that works.
The two lines of code,
right?
Uh,

224
00:13:06.970 --> 00:13:09.160
I've got 50 k training samples,
uh,

225
00:13:09.190 --> 00:13:12.040
50 k validation samples and 10 k testing samples.

226
00:13:12.280 --> 00:13:14.020
Tensorflow does this for us beautifully.

227
00:13:14.110 --> 00:13:17.380
It'll download the data set from the web,
uh,
preprocess it,

228
00:13:17.440 --> 00:13:22.360
and then it's set for us to use and it will sort it all in this m and ist

229
00:13:22.361 --> 00:13:25.120
variable we're going to be using tensorflow.
Okay.

230
00:13:25.121 --> 00:13:28.720
And this and this tutorial num py,
date,
time for logging,

231
00:13:28.721 --> 00:13:32.440
and then map out live to show our progress during training.
Okay.

232
00:13:32.441 --> 00:13:35.380
And so this is actually the one that I want to look at this just the same thing.

233
00:13:35.460 --> 00:13:38.110
This is the same exact thing.
Okay.
So

234
00:13:40.190 --> 00:13:41.023
<v 2>great.</v>

235
00:13:44.160 --> 00:13:47.670
<v 1>What do we got here?
Okay,
so I just went ahead and just compiled that bart part.</v>

236
00:13:47.671 --> 00:13:50.490
So just downloaded the data and,
cool.

237
00:13:50.520 --> 00:13:55.520
So we've got that part and now we're going to calculate the square root of

238
00:13:56.431 --> 00:14:00.390
infinity.
No,
I'm just kidding.
Now we're going to look at the discriminator.
Okay.

239
00:14:00.391 --> 00:14:04.740
So it's a great idea to modular modularize these parts into their own functions

240
00:14:05.010 --> 00:14:08.880
because these networks can be pretty big and you want to do this anyway just

241
00:14:08.881 --> 00:14:12.710
because of several reasons.
It's just good programming practice,
uh,

242
00:14:12.780 --> 00:14:14.250
object oriented practice and,

243
00:14:14.610 --> 00:14:18.540
and it's also just easier because you'll find that as you're building these

244
00:14:18.541 --> 00:14:21.630
things don't want to latch on extra features like um,

245
00:14:21.980 --> 00:14:24.150
not just change tune these hyper parameters.

246
00:14:24.330 --> 00:14:27.420
You might want to add new layers and new techniques to it,

247
00:14:27.421 --> 00:14:28.680
like drop out and things like that.

248
00:14:28.681 --> 00:14:32.520
So having them in their own functions is just good practice.
Okay.

249
00:14:32.760 --> 00:14:37.760
So the first thing we're gonna do is I'm going to talk about this structure a

250
00:14:37.891 --> 00:14:38.310
bit.

251
00:14:38.310 --> 00:14:41.820
So the generator and so we're going to talk about this more mathematically then

252
00:14:41.821 --> 00:14:46.710
just high level.
The generator is receiving a z.
So what is z?

253
00:14:46.920 --> 00:14:51.380
Z is noise.
What is noise?
Noise is,
let me move this out of way.

254
00:14:53.440 --> 00:14:56.230
Noise in this case means randomness,

255
00:14:56.260 --> 00:14:58.830
random values that we just generate from nothing just from,

256
00:14:59.080 --> 00:15:01.990
not from nothing from a distribution,
right?
The Golf,
Sian Distribution.

257
00:15:02.320 --> 00:15:04.810
We're generating some random noise,
okay?
Every time.

258
00:15:05.140 --> 00:15:08.740
And that's what it starts off with.
We're not giving it some image.

259
00:15:08.770 --> 00:15:11.470
So in some networks,
so let's be clear here,

260
00:15:11.560 --> 00:15:16.270
in some networks we take for the generator,
we take the original image from the,

261
00:15:16.271 --> 00:15:19.960
from the training data,
and we generate some noise from that image.

262
00:15:20.110 --> 00:15:25.000
But in this case,
we're generating noise from nothing.
So just a,
from,

263
00:15:25.020 --> 00:15:29.860
from just a distribution that is not an independent,

264
00:15:29.861 --> 00:15:33.550
that's the word I'm looking for.
An independent GoSTEM distribution.
Uh,

265
00:15:33.551 --> 00:15:36.970
and we'll talk about why we're doing that.
But first,
let me keep going here.

266
00:15:37.270 --> 00:15:40.000
We're generating noise here,
which is what z represents.

267
00:15:40.030 --> 00:15:42.100
And then we feed that to the generator.
Well,

268
00:15:42.101 --> 00:15:45.550
the generator will do is it will up sample.
What is upsampling mean?

269
00:15:45.820 --> 00:15:49.620
Upsampling is a term for convolutional networks where we take,
uh,

270
00:15:49.660 --> 00:15:54.660
an image and we split it into more smaller and more numerous versions of that

271
00:15:58.721 --> 00:16:02.040
image,
right?
So if we have one image,
if we upsampling it,

272
00:16:02.080 --> 00:16:06.280
we could have then four smaller images.
And then if we up sample it again,

273
00:16:06.370 --> 00:16:10.690
we could have 16 smaller images and upset.
Well,
again,
we have 32 so you see,

274
00:16:10.780 --> 00:16:13.010
you see what I'm saying?
So we just keep up sampling.

275
00:16:13.011 --> 00:16:16.810
And so what happens is by the end we're going to have a law to values,

276
00:16:16.840 --> 00:16:18.910
but they're all very,
very small images.

277
00:16:18.911 --> 00:16:21.790
And then we squash all those values together and then we have those output

278
00:16:21.791 --> 00:16:25.260
probabilities real or fake.
Okay.
That's where the generator does.

279
00:16:25.261 --> 00:16:29.490
And then the discriminator is going just taken an image and it's going to,
uh,

280
00:16:30.220 --> 00:16:33.760
it's going to a downsample.
Okay.
And

281
00:16:34.800 --> 00:16:35.633
<v 0>yeah,</v>

282
00:16:39.610 --> 00:16:42.100
<v 1>the discriminator is going to downsample.
Why?</v>

283
00:16:42.101 --> 00:16:46.210
Because it is a d convolutional network.
And so for downsampling,

284
00:16:46.240 --> 00:16:50.560
it's going to take a image,
a big image,
and it's going to create,

285
00:16:50.910 --> 00:16:51.743
<v 0>uh,</v>

286
00:16:54.960 --> 00:16:57.540
<v 1>it's going to take a big image and it's going to create smaller and more</v>

287
00:16:57.541 --> 00:17:02.430
numerous images,
uh,
that will progressively get smaller and smaller.

288
00:17:02.460 --> 00:17:06.300
Okay.
So,
wow,

289
00:17:06.301 --> 00:17:09.870
I just realized that I got that backwards.
So for the generator,

290
00:17:09.871 --> 00:17:13.620
it's going to take a lot of values and it's going to progressively create more,

291
00:17:13.700 --> 00:17:17.520
uh,
fewer and US bigger images.

292
00:17:17.670 --> 00:17:20.970
I've actually written this down right over here when I write that down.

293
00:17:22.590 --> 00:17:23.150
<v 0>Yeah.</v>

294
00:17:23.150 --> 00:17:25.220
<v 1>So here's the word.
So I,
so the reason is,</v>

295
00:17:25.430 --> 00:17:30.430
let me just paste this note into my demo right here to remember this.

296
00:17:31.730 --> 00:17:32.570
There's a lot to remember.

297
00:17:33.350 --> 00:17:37.820
So the generator is going to create bigger and less images in every layer,

298
00:17:38.060 --> 00:17:41.540
and the discriminators going to create smaller and more images in every layer.

299
00:17:41.690 --> 00:17:45.140
So if we were to,
the best way to really show this and to just visualize,

300
00:17:45.380 --> 00:17:48.200
and that's gonna take away all confusion.
Convolutional network.

301
00:17:50.430 --> 00:17:51.263
<v 2>Okay?</v>

302
00:17:57.190 --> 00:17:58.023
Just like that.

303
00:18:03.970 --> 00:18:08.710
So
let me just maximize that because I ain't got time for that,

304
00:18:09.870 --> 00:18:10.703
right?

305
00:18:10.810 --> 00:18:15.370
<v 1>Okay.
So you see this right here,
see,
see how we're getting more and more images.</v>

306
00:18:15.371 --> 00:18:19.240
There's,
but they're smaller,
more and smaller images.
Okay?

307
00:18:19.270 --> 00:18:21.280
So that's what the discriminator is doing.

308
00:18:21.281 --> 00:18:24.870
And so the generator doing the opposite,
we literally just flip that around.

309
00:18:24.871 --> 00:18:28.570
And so we get a lot of values and that we can immediately convert to a lot of

310
00:18:28.571 --> 00:18:33.190
small images and we gen and then we'd just compress it into one big image.

311
00:18:33.191 --> 00:18:35.710
And that's the generated image.
Okay,
that's,
yeah.

312
00:18:36.980 --> 00:18:40.040
<v 2>Cool.
So anyway,
where were we?
Where were we?</v>

313
00:18:41.010 --> 00:18:43.900
<v 1>Use the same notebooks by the way.
Okay,
so let's talk about the discriminator.</v>

314
00:18:44.170 --> 00:18:46.060
Let me,
let me answer one question.

315
00:18:47.060 --> 00:18:50.380
<v 2>Let me answer one question.
Uh,</v>

316
00:18:51.500 --> 00:18:53.790
or I forgot to

317
00:18:54.970 --> 00:18:57.720
<v 1>the discriminate or,
so,
uh,</v>

318
00:19:01.540 --> 00:19:06.310
hi sir.
Rod.
This is doc I program in Javascript c plus plus and python.
Nice.

319
00:19:06.790 --> 00:19:11.170
I'm doing neural networks late lately and I'm 15 years old.
You're a hero.

320
00:19:11.770 --> 00:19:16.660
What would be your best advice on getting expertise in the field?
So doc,

321
00:19:16.690 --> 00:19:21.360
I would say don't focus on languages.
Just pick one language,

322
00:19:21.400 --> 00:19:24.790
pick one.
And I'm going to say it's python,
pig python.
Okay.

323
00:19:24.791 --> 00:19:29.710
Pick Python and then focus all of your mental energy on the algorithms.
Okay.

324
00:19:29.920 --> 00:19:32.680
Don't focus on the syntax.
And that's why it's great to use python.

325
00:19:33.010 --> 00:19:36.820
Focus on the algorithms and the intuition.
It's a way of thinking.

326
00:19:37.120 --> 00:19:41.770
If you learn the way of thinking,
then you can apply it to novel,
novel problems,

327
00:19:42.040 --> 00:19:45.520
novel ideas.
Okay.
Try to develop an intuition around this.

328
00:19:45.521 --> 00:19:49.630
Given any new problem in machine learning,
you'll be able to say,
oh,

329
00:19:49.660 --> 00:19:53.260
you have to use a convolutional net and you use this many strides and you have

330
00:19:53.261 --> 00:19:56.860
to use uh,
uh,
you know,
drop out in this layer and you know,

331
00:19:57.250 --> 00:20:00.580
if you can give it,
give it a new problem,
know how to,
how to work it,

332
00:20:01.000 --> 00:20:04.960
you're good to go.
And how do you develop that by focusing on the algorithms,

333
00:20:05.140 --> 00:20:09.730
focus on techniques and look at what's trending on get hub in terms of machine

334
00:20:09.731 --> 00:20:12.670
learning,
be active in the community post,
you know,

335
00:20:12.671 --> 00:20:15.220
in machine learning and the machine learning sub reddit posts in my,

336
00:20:15.240 --> 00:20:18.490
the comments from my videos,
if you're a part of the U.
Dot.
City curriculum,

337
00:20:18.491 --> 00:20:22.030
posting the and the slack channel,
just talk to people.
Okay,

338
00:20:22.031 --> 00:20:26.350
talk to people and you,
you're going to learn a lot.
Normally this stuff was,

339
00:20:26.650 --> 00:20:30.850
was a restricted to only those who went to the top universities in the world who

340
00:20:30.851 --> 00:20:33.430
paid large amounts of money.
But because of the Internet,

341
00:20:33.580 --> 00:20:36.160
you can work from anywhere in the world.
Uh,

342
00:20:36.400 --> 00:20:40.600
learn to become an expert in anything,
especially machine learning.
Okay.

343
00:20:40.601 --> 00:20:43.510
So that's my answer.
Let's get back into this further.
The discriminator.

344
00:20:43.840 --> 00:20:47.170
We have a co,
we have our,
uh,

345
00:20:52.110 --> 00:20:56.600
let me see where we are for a second.
Are convolutional network.
Okay.

346
00:20:56.610 --> 00:21:00.070
So discriminator is our convolutional network.
Let me talk about all of this.

347
00:21:00.071 --> 00:21:02.380
So let's,
let's go,
let's go line by line here.

348
00:21:02.760 --> 00:21:06.700
So the first part is we're going to initialize weights and biases.
Okay.

349
00:21:06.701 --> 00:21:08.830
For our first convolutional block,

350
00:21:09.010 --> 00:21:12.550
now the word block is a word that I've invented and it's going to become

351
00:21:12.580 --> 00:21:17.020
commonplace because I said so.
So the,
so the word block is we take,

352
00:21:17.790 --> 00:21:18.100
<v 0>okay,</v>

353
00:21:18.100 --> 00:21:21.040
<v 1>so convolutional nets generally follow the same pattern,
right?</v>

354
00:21:21.160 --> 00:21:25.150
We start off with a convolutional layer and then we apply some activation

355
00:21:25.151 --> 00:21:28.930
function to it.
And then we have added some kind of pooling layer.
Okay.

356
00:21:28.960 --> 00:21:30.070
Or sometimes we switch to the two,

357
00:21:30.071 --> 00:21:32.920
but it's always the same three things over and over again.

358
00:21:33.100 --> 00:21:35.230
And we could think of these things as a block,
right?

359
00:21:35.410 --> 00:21:38.110
Convolutional convolution activation pooling.

360
00:21:38.350 --> 00:21:40.210
So that's how you should remember it.
Blocks.

361
00:21:40.390 --> 00:21:44.350
And so in this convolutional network,
we have three convolutional blocks.

362
00:21:44.680 --> 00:21:49.680
We start off with the weights and biases for are a convolution and then we uh,

363
00:21:49.990 --> 00:21:54.880
we add them together.
So for this convolutional block,

364
00:21:55.270 --> 00:21:57.160
this line right here,
it says,
okay,

365
00:21:57.280 --> 00:22:00.370
taking that image and we're going to feed in the image directly to our

366
00:22:00.371 --> 00:22:01.840
discriminator,
right?
And it's good to output.

367
00:22:01.841 --> 00:22:04.120
If the image is real or fic and we say,

368
00:22:04.210 --> 00:22:06.940
well what are the filters is going to be what we just defined what those filters

369
00:22:06.941 --> 00:22:10.270
are going to be.
It's going to be this set of weights.
Values.
Okay,

370
00:22:10.480 --> 00:22:14.380
these are 32 different,
five by five pixel values.

371
00:22:14.560 --> 00:22:18.010
And why did we define them as this?
Uh,
because

372
00:22:22.730 --> 00:22:23.530
<v 0>okay,</v>

373
00:22:23.530 --> 00:22:26.170
<v 1>they are,
well it's one of the things where if we,</v>

374
00:22:26.171 --> 00:22:29.770
if we were going to try more like a higher value,
like 33 for example,

375
00:22:30.040 --> 00:22:34.360
it could actually improve convergence versus 31 but there's not a specific

376
00:22:34.361 --> 00:22:37.300
reason.
It's just this,
like I said,
rule of thumb,

377
00:22:37.330 --> 00:22:39.460
it's been implemented before and a paper with good results.

378
00:22:39.580 --> 00:22:43.840
Those numbers are probably going to be good.
So that's for our weights.

379
00:22:43.930 --> 00:22:47.530
We initialize them randomly using this truncated normal function.
Okay.

380
00:22:47.531 --> 00:22:51.430
With the standard deviation of 0.02 how far off from the mean should we be?

381
00:22:51.431 --> 00:22:55.240
And that's what 0.02 stands for.
That's what standard deviation stands for.

382
00:22:55.720 --> 00:22:57.550
And then we're going to add our bias.
Okay.

383
00:22:59.110 --> 00:22:59.943
<v 0>And</v>

384
00:23:01.560 --> 00:23:03.620
<v 1>strides what our strides.
So the,</v>

385
00:23:03.621 --> 00:23:07.740
so strides in this case stands for batch height with and channels.

386
00:23:07.830 --> 00:23:12.690
Those are the four values for strides.
Okay.
Um,
so what is a sign of our batch?

387
00:23:12.740 --> 00:23:15.540
Always the height of a stride was the width.
And then how many channels,

388
00:23:15.630 --> 00:23:20.430
what are strides?
Remember convolutional layers.
A convolution is a,

389
00:23:20.960 --> 00:23:25.950
to convey,
solve literally means to,
to slide because it's a flashlight,

390
00:23:25.951 --> 00:23:29.640
it's moving.
How is it moving?
Because
well,

391
00:23:29.880 --> 00:23:32.550
we're not actually doing the iteration where we're saying like for every single

392
00:23:32.551 --> 00:23:35.340
pixel it's not like a four loop that we're writing or we're saying for every

393
00:23:35.341 --> 00:23:37.530
pixel in the image apply,
apply,
apply,
apply.

394
00:23:37.710 --> 00:23:39.090
That's what this one line of code does.

395
00:23:39.091 --> 00:23:41.490
But under the hood you can bet that's what it's doing.

396
00:23:41.790 --> 00:23:46.520
We're saying for all of these pixels,
uh,
check if,

397
00:23:46.690 --> 00:23:51.080
uh,
the multiply by the value that we're looking for.

398
00:23:51.260 --> 00:23:53.820
And then if there's,
if there's a,
if there's a result here,
if it's a,

399
00:23:53.850 --> 00:23:55.460
if it's a non zero results,

400
00:23:55.640 --> 00:23:58.220
that means that there is something in the image that we're looking for.

401
00:23:58.580 --> 00:24:02.420
But strides means in this case,
stride across the image of like what,

402
00:24:02.430 --> 00:24:05.390
what is the interval of that flashlight as we straight across.

403
00:24:05.960 --> 00:24:10.800
And then for padding,
same,
it just means to pat evenly left and rights.
Uh,

404
00:24:10.880 --> 00:24:14.300
and padding is when we add zeroes to make sure that those values are the same.

405
00:24:14.480 --> 00:24:15.410
So if we have,

406
00:24:15.620 --> 00:24:19.130
if we're multiplying or dividing or performing any kind of operation on two

407
00:24:19.131 --> 00:24:22.970
numbers,
like you know,
one,
two,
three times one,
two,
three,

408
00:24:22.971 --> 00:24:25.510
four just for um,

409
00:24:28.350 --> 00:24:32.350
for cleanliness we want to pad that one,
two,
three,
so that it's got one,

410
00:24:32.400 --> 00:24:33.540
it's going to be one,
two,
three,
four,

411
00:24:33.570 --> 00:24:36.990
zero so that it's going to be the same length.
Okay.

412
00:24:37.500 --> 00:24:41.130
And I talked about this in my tension in my image classifier,

413
00:24:41.160 --> 00:24:42.810
how to build an image classifier video.

414
00:24:42.811 --> 00:24:47.811
So check out that video for really in depth exploration of how convolutional

415
00:24:47.851 --> 00:24:51.840
networks work.
Uh,
but really our focus right now is to focus on,
um,

416
00:24:52.290 --> 00:24:57.030
the generative approach,
the adversarial approach.
Okay.
So then for our bias,

417
00:24:57.031 --> 00:24:57.990
we're just going to add it in,
right?

418
00:24:57.991 --> 00:25:00.750
We just add our bias in and why do we add our bias in?

419
00:25:00.960 --> 00:25:04.080
Because if we didn't have a bias,
then if we fed some,
uh,

420
00:25:04.110 --> 00:25:08.700
if we fed some zero value to this layer and we multiply it by whatever our

421
00:25:08.701 --> 00:25:11.660
weights are,
it doesn't matter what our wastes are,
it's the,

422
00:25:11.661 --> 00:25:14.580
that value is going to be zero.
And what does that do for convergence?

423
00:25:14.610 --> 00:25:18.090
It's not a good thing for convergence because it means that our ultimate value

424
00:25:18.240 --> 00:25:22.350
is going to be zero.
So what biases do,
biases are our anchor.

425
00:25:22.410 --> 00:25:26.100
They say that even if you have a zero value,
let's add some,

426
00:25:26.520 --> 00:25:29.970
some preset constant to it.
So it's going to be a non zero value.

427
00:25:30.180 --> 00:25:33.480
So there's always going to be some value in that layer and it's going to improve

428
00:25:33.481 --> 00:25:34.314
convergence.

429
00:25:35.010 --> 00:25:38.190
So that's what we add our bias and then we squash it with our nonlinear

430
00:25:38.490 --> 00:25:39.780
nonlinearity.
Okay.

431
00:25:40.590 --> 00:25:45.590
So remember in a block there are convolutions followed by an activation function

432
00:25:46.140 --> 00:25:50.610
and then ultimately a pooling layer.
So we're using average pooling in this,

433
00:25:50.640 --> 00:25:55.380
a discriminator in this convolutional network as opposed to Max pooling average

434
00:25:55.381 --> 00:25:59.460
pooling wolf downsample by dividing the input into rectangular pooling regions

435
00:25:59.760 --> 00:26:03.520
and computing the average of each region.
It's just simple,
uh,

436
00:26:04.170 --> 00:26:06.870
finding the mean,
finding the average.
So take us out of numbers,

437
00:26:07.170 --> 00:26:10.110
add them up and divide by the number of numbers.
Okay?
That's what,

438
00:26:10.111 --> 00:26:14.280
that's all it's doing.
And what is the,
what is the,
uh,
what are those numbers?

439
00:26:14.340 --> 00:26:16.470
Those numbers are the values inside of the image.

440
00:26:16.471 --> 00:26:18.510
Like if we were to look at an image as a matrix,

441
00:26:18.570 --> 00:26:22.220
it's got a bunch of values like numbers,
okay?
Pixels,
pixel values.
That's what,

442
00:26:22.230 --> 00:26:25.710
that's what it is.
Okay.
And then so we just repeat that,
right?

443
00:26:25.711 --> 00:26:29.620
That's the whole point of it being a block.
We repeat the block again,
uh,

444
00:26:29.880 --> 00:26:34.610
for the next layer.
Okay.
And this time,
this time for the discriminator,

445
00:26:35.090 --> 00:26:36.950
there are going to be,
let me see here,

446
00:26:42.030 --> 00:26:46.530
they're going to be more,
more images,
more numerous images,

447
00:26:46.531 --> 00:26:48.690
but they're going to be smaller.
So we,
so we,

448
00:26:48.691 --> 00:26:53.340
so you see here that the weight matrix here is double the size of the one that

449
00:26:53.341 --> 00:26:55.020
came before.
So this is 32,

450
00:26:55.260 --> 00:26:59.580
so this is going to be 64 and you see for the next one we,
we really,
there's a,

451
00:26:59.640 --> 00:27:02.940
we really explode that,
that value to 10 24,

452
00:27:03.210 --> 00:27:07.110
so it's an exponential increase in values.
Okay.
Uh,

453
00:27:07.140 --> 00:27:12.140
and so these are going to search for 64 different five by five pixel features.

454
00:27:12.360 --> 00:27:15.270
So I'm really going to the details of how this convolutional network is working,

455
00:27:15.390 --> 00:27:18.150
but don't get too caught up in them because really just it's,

456
00:27:18.180 --> 00:27:21.600
it's just taking an image and then it's al putting a probability value by

457
00:27:21.601 --> 00:27:25.200
continuously,
uh,
consolving around that image,
creating more smoke,

458
00:27:25.260 --> 00:27:27.600
crank smaller and more numerous images until,

459
00:27:27.601 --> 00:27:29.790
until we have an output output probability,

460
00:27:30.030 --> 00:27:33.180
which is going to be really bad at first because we don't,

461
00:27:33.240 --> 00:27:36.990
our weights aren't trained,
but eventually it's gonna get really good.
Okay.

462
00:27:36.991 --> 00:27:40.110
And then at the very end,
we have our two fully connected layers.

463
00:27:40.230 --> 00:27:42.150
So when it comes to convolutional nets,

464
00:27:42.151 --> 00:27:46.500
they generally have fully connected layers at the end almost every time.

465
00:27:46.530 --> 00:27:49.920
And Andrea [inaudible] has said this many times in his blog posts,

466
00:27:50.100 --> 00:27:52.620
you generally add fully connected layers at the end.

467
00:27:52.830 --> 00:27:54.450
Why don't we add them at the beginning?

468
00:27:54.660 --> 00:27:57.870
Because when you're trying to classify an image,

469
00:27:57.871 --> 00:28:00.630
which is essentially what the discriminator is trying to do,
real or fake,

470
00:28:01.290 --> 00:28:05.700
it doesn't matter what all parts of the,
what's in all parts of the image,

471
00:28:05.701 --> 00:28:06.990
what's in the bottom left corner.

472
00:28:07.020 --> 00:28:09.750
It just matters if that what you're looking for is inside of that image.

473
00:28:09.930 --> 00:28:11.460
So we don't need a fully connected layer.

474
00:28:11.461 --> 00:28:15.480
We need a convolutional layer that looks for that for the parts that matter.

475
00:28:15.650 --> 00:28:18.180
Where's it a fully connected layer which says,
let's just take that,

476
00:28:18.181 --> 00:28:22.440
this whole thing and we're going to use all of that input for that as the all of

477
00:28:22.441 --> 00:28:26.040
that output from this layer as input to this next layer.

478
00:28:27.210 --> 00:28:28.050
We don't need that at the beginning,

479
00:28:28.051 --> 00:28:31.200
but we need that at the end because at the end we've,
uh,

480
00:28:31.590 --> 00:28:33.840
we've extracted all the important features.

481
00:28:33.930 --> 00:28:35.520
So now that we have all the good stuff,

482
00:28:35.640 --> 00:28:38.940
now we're going to apply a fully connected layer to it.
Okay?

483
00:28:39.360 --> 00:28:42.480
So we do that twice and we're initializing them as random.

484
00:28:42.840 --> 00:28:46.020
And then eventually we do our last matrix multiplication,

485
00:28:46.290 --> 00:28:48.690
which is the first set of weights,

486
00:28:48.810 --> 00:28:53.370
times that layer value plus the bias.
And,
and ultimately that's going to,

487
00:28:53.371 --> 00:28:57.990
it's a simple binary classifier.
It's going to output real or fake.
Okay?

488
00:28:57.991 --> 00:29:02.220
Two values to values,
one for real and one for fake,
both of probability values.

489
00:29:02.490 --> 00:29:07.380
Okay?
So that's our discriminator.
And now I'm going to talk about the generator,

490
00:29:07.381 --> 00:29:11.910
which is a d convolutional net.
But first let me answer two questions.
Okay.

491
00:29:13.680 --> 00:29:14.513
So

492
00:29:19.130 --> 00:29:20.990
here are the questions.
So the questions are,

493
00:29:21.530 --> 00:29:25.100
how different is this from a variational auto encoder?
Great question.

494
00:29:25.550 --> 00:29:26.383
Great question.

495
00:29:26.420 --> 00:29:31.420
So variational auto encoders are different in that the loss function is

496
00:29:35.031 --> 00:29:39.180
different.
The,
they're different in a couple of ways.
It's,

497
00:29:39.181 --> 00:29:41.650
it's not just one,
one way.
Um,

498
00:29:42.490 --> 00:29:44.620
you don't have this mini Max approach to the loss function.

499
00:29:44.700 --> 00:29:48.940
A variational auto encoder is using a loss function for the encoder and decoder,

500
00:29:49.210 --> 00:29:52.660
but they're not competing against each other where one is not trying to fool the

501
00:29:52.661 --> 00:29:55.630
other.
That's what generative networks are doing.
Adversarial networks are doing.

502
00:29:55.990 --> 00:29:56.380
Uh,

503
00:29:56.380 --> 00:30:01.300
and we don't have a re parameterization tech technique like in a variational

504
00:30:01.301 --> 00:30:04.990
audit encoders.
We separate the randomness,

505
00:30:05.140 --> 00:30:09.580
the stochasticity inside of the model from the values that we can then update.

506
00:30:09.581 --> 00:30:13.960
Our parameters are gradients with respect to these a deterministic parameters.

507
00:30:14.080 --> 00:30:17.890
And when we leave this randomness beside in this,
uh,

508
00:30:18.340 --> 00:30:22.090
in adversarial networks and this particular implementation,

509
00:30:22.330 --> 00:30:26.780
we don't have stochasticity built into the model.
It's just,
it's,

510
00:30:26.840 --> 00:30:31.330
it's outside of the model.
So we don't need a reprioritization check.
A prick.

511
00:30:32.200 --> 00:30:33.880
Okay.
Okay.
I answer your question.
One more question.

512
00:30:35.940 --> 00:30:36.773
<v 0>Okay.</v>

513
00:30:37.000 --> 00:30:40.780
<v 1>Is there an equivalent of gans or auto encoders that can find the parameters of</v>

514
00:30:40.781 --> 00:30:45.550
a model,
for example,
to find the best parameters of the latent pdf?
PDF?

515
00:30:47.190 --> 00:30:48.023
<v 0>Yeah.</v>

516
00:30:48.050 --> 00:30:51.950
<v 1>Parameters of the model is there,
including with cans I parameters of a model.
Oh,</v>

517
00:30:51.951 --> 00:30:56.860
okay.
So,
so,
okay.
So for model parameter,
uh,

518
00:30:57.170 --> 00:31:01.280
optimization,
learning to learn metal learning,
as I like to call it,

519
00:31:01.880 --> 00:31:03.170
there are several techniques.

520
00:31:03.171 --> 00:31:06.620
One of them that I to shout it out last time was great search.
Um,

521
00:31:06.740 --> 00:31:11.660
but there are actually better techniques of doing this.
Um,
there's random search.

522
00:31:11.750 --> 00:31:13.070
There's,
um,

523
00:31:14.480 --> 00:31:18.200
hyper hyper parameter optimization is an entire field in and of itself.

524
00:31:18.201 --> 00:31:22.550
And I actually have not touched on that in this course.
Um,
because,

525
00:31:23.730 --> 00:31:27.840
uh,
you know,
I should though,
I should and I will probably go into that.
But yes,

526
00:31:27.841 --> 00:31:28.960
you can do that,
but you wouldn't

527
00:31:30.810 --> 00:31:34.290
intuitively I wouldn't think to apply a generative adversarial network to the

528
00:31:34.440 --> 00:31:36.330
problem of optimizing hyper parameters.

529
00:31:36.331 --> 00:31:40.740
But what do I know that that that's actually a great idea that that could be a

530
00:31:40.741 --> 00:31:43.650
great idea.
I mean,
no one's ever thought of it.
This is a good rule of thumb.

531
00:31:43.680 --> 00:31:47.220
Whenever you're thinking of research ideas,
the best researchers,

532
00:31:47.250 --> 00:31:51.180
the people who really push the space forward are the bravest people.

533
00:31:51.630 --> 00:31:55.290
There are the people who are willing to go against the grain to go against the

534
00:31:55.291 --> 00:31:59.400
popular opinion in the community of what is what is supposed to work and what is

535
00:31:59.401 --> 00:32:00.234
supposed to be valid.

536
00:32:00.360 --> 00:32:05.100
And they try things that are considered weird or just totally out there.

537
00:32:05.370 --> 00:32:09.300
And what happens is these people who do this,
like Ian Goodfellow end up

538
00:32:10.130 --> 00:32:10.490
<v 0>okay</v>

539
00:32:10.490 --> 00:32:14.990
<v 1>getting fame and recognition and their models are put to great use and they</v>

540
00:32:14.991 --> 00:32:19.640
provide a lot of value to society.
So this idea is,
you know,

541
00:32:19.641 --> 00:32:21.620
it could be great.
So definitely try it out.
Okay.

542
00:32:22.230 --> 00:32:22.900
<v 0>Okay.</v>

543
00:32:22.900 --> 00:32:26.800
<v 1>Okay.
So back to the,
actually one more.
This is a great question.
Mohawn asks,</v>

544
00:32:26.801 --> 00:32:31.270
is it possible to use Gan to generate smaller goals of a big task?
Yes.

545
00:32:31.480 --> 00:32:36.480
So this idea of using neural networks iteratively add in layers is something

546
00:32:37.871 --> 00:32:42.050
that I've been thinking about a lot.
So think about some,

547
00:32:42.680 --> 00:32:43.513
like if,
if,

548
00:32:43.640 --> 00:32:47.420
so machine learning is going to be happening in every layer of the stack,
okay.

549
00:32:47.480 --> 00:32:50.930
From operating systems to compilers,
rendering,

550
00:32:51.860 --> 00:32:54.740
all of it,
it's all going to be machine learning in the end.
Right now,

551
00:32:54.741 --> 00:32:56.750
a lot of it is hard coded,
but it's all going to be machine learning.

552
00:32:56.930 --> 00:32:59.360
So if you think about a stack,
what do I mean by stack?

553
00:32:59.570 --> 00:33:03.290
A series of layers of abstractions,

554
00:33:03.320 --> 00:33:05.450
of software scaffolding,
right?

555
00:33:05.540 --> 00:33:08.180
You have an operating system and then on top of that you have a compiler.

556
00:33:08.181 --> 00:33:10.480
And on top of that you have an interpreter.
You know,

557
00:33:10.640 --> 00:33:15.480
you keep going up the stack rendering and then you have whatever else.
Um,

558
00:33:15.740 --> 00:33:19.450
and that's not even including networking.
If you were to make a request,

559
00:33:19.460 --> 00:33:24.110
a query to this software,
it would first see you.
If I were to say,
you know,

560
00:33:24.170 --> 00:33:25.003
find me,

561
00:33:27.050 --> 00:33:31.400
find me the best taco place in San Francisco,

562
00:33:31.850 --> 00:33:34.490
it would first use natural language processing to deconstruct that.

563
00:33:34.491 --> 00:33:36.890
So that's a recurrent network.
Okay.

564
00:33:36.960 --> 00:33:41.220
Using LSTM cells to find the semantic meaning of what you've just said,
to,

565
00:33:41.310 --> 00:33:42.830
to extract those vector values.

566
00:33:43.340 --> 00:33:47.990
And then it would take those vectors and it would say,
okay,
uh,
find the,

567
00:33:48.170 --> 00:33:52.590
take the pretrained vectors of all the restaurants,
uh,

568
00:33:52.620 --> 00:33:56.660
NSF,
and then find the best routing technique to find all those closest to you.

569
00:33:57.140 --> 00:33:59.150
You see how there's machine learning happening everywhere.

570
00:33:59.300 --> 00:34:02.810
Like find the best route machine learning,
find the best restaurants,

571
00:34:02.930 --> 00:34:06.740
machine learning,
and take what you've said and convert that into vectors,

572
00:34:06.741 --> 00:34:08.720
machine learning.
And so you,
you've got this,

573
00:34:08.780 --> 00:34:13.460
you've got this network of neural networks.
So if you really think about it,

574
00:34:13.670 --> 00:34:18.150
it's just one big brain is we're building one big brain of just net,

575
00:34:18.740 --> 00:34:20.480
just one giant neural network,

576
00:34:20.840 --> 00:34:25.580
convolutional nets to recurrent nets to be forward nets and just general

577
00:34:25.581 --> 00:34:29.690
adversarial nets.
It's all going to be one big huge brain that we're building.

578
00:34:29.900 --> 00:34:33.190
And the in the Internet is the nervous system.
And I could just keep going high.

579
00:34:33.191 --> 00:34:35.660
There's a lot of philosophy here,
but let's just keep going.

580
00:34:35.840 --> 00:34:40.340
So now for the generator,
a ws,

581
00:34:40.730 --> 00:34:45.590
the ultimate super neural network,
Dragon Ball,
z x,
Goku Goku we so cool.

582
00:34:45.620 --> 00:34:49.610
Okay.
So for the generator,
uh,
we have,
it's the opposite,
right?

583
00:34:49.611 --> 00:34:52.070
It's a d convolutional net.
So what do I mean by that?

584
00:34:52.100 --> 00:34:54.290
We just literally flipped the architecture.

585
00:34:54.410 --> 00:34:56.960
But what do I mean when I say flip the architecture?

586
00:34:57.140 --> 00:35:00.230
We don't flip it line by line.
We don't say,
well,

587
00:35:00.260 --> 00:35:03.500
let's start off with the activation function this time and then let's apply

588
00:35:03.501 --> 00:35:07.580
pooling and then let's do convolution.
No,
we flip the blocks.

589
00:35:07.610 --> 00:35:11.000
And that's why the word blocks is very important because we have to think about

590
00:35:11.001 --> 00:35:15.060
them in terms of blocks because we,
they,
they,
they,

591
00:35:15.280 --> 00:35:18.350
the blocks maintain the same ordering.
But the,

592
00:35:18.590 --> 00:35:21.080
the order of the blocks themselves is what is flipped.

593
00:35:21.320 --> 00:35:24.860
So for the first d convolutional block,
we have our weights and biases.

594
00:35:24.980 --> 00:35:28.850
We performed matrix multiplication,
reshape it into,
uh,

595
00:35:29.060 --> 00:35:33.260
a smaller image.
Okay.
Um,
and or,
sorry,

596
00:35:33.280 --> 00:35:37.800
a bigger,
bigger image.
And we just,
these images get bigger and bigger.
Okay.

597
00:35:38.040 --> 00:35:42.820
And so
we have this vector of values that we feed it.

598
00:35:43.030 --> 00:35:43.840
And so for the,

599
00:35:43.840 --> 00:35:46.960
for the inputs here we have the batch size and the z dimentionality.

600
00:35:47.230 --> 00:35:50.980
So the batch size is how many images do we want to feed it at a time.

601
00:35:51.250 --> 00:35:55.350
The Z dimentionality is what are the dimensions for that latent space that we

602
00:35:55.380 --> 00:35:58.450
then want to our model to build off of what is a latent space,

603
00:35:58.630 --> 00:36:03.160
those random values that we want to,
uh,
then convert into

604
00:36:09.360 --> 00:36:09.560
what are,

605
00:36:09.560 --> 00:36:13.400
you guys are hilarious that we are then going to convert into that big image.

606
00:36:13.430 --> 00:36:14.263
Right?
Okay.

607
00:36:16.190 --> 00:36:17.023
<v 0>So</v>

608
00:36:17.520 --> 00:36:19.050
<v 1>what do we use those values for?</v>

609
00:36:19.080 --> 00:36:21.210
You can see them put to use right here in this first line.

610
00:36:21.570 --> 00:36:26.570
So Z is that random value from which we create an image from.

611
00:36:28.680 --> 00:36:31.710
And so this image,
this value isn't dependent on an image.

612
00:36:31.720 --> 00:36:36.360
It says created from a truncated normal golf steam distribution using the batch

613
00:36:36.361 --> 00:36:40.170
size ends and z dimensionality as its parameters.
It's not actually,

614
00:36:40.171 --> 00:36:42.510
it's not actually based off of anything.

615
00:36:42.511 --> 00:36:45.450
It's based off of an independent golf and distribution.

616
00:36:45.750 --> 00:36:48.930
And from this Z is we generate an image and you might be asking,

617
00:36:49.200 --> 00:36:52.950
how the hell do we generate an image from a set of random values based off of

618
00:36:52.951 --> 00:36:55.320
nothing?
Because during training,

619
00:36:55.470 --> 00:36:57.990
as our weights improve this network,

620
00:36:58.020 --> 00:37:00.480
this random value will be able to,

621
00:37:00.600 --> 00:37:04.170
it will know exactly how to take that random value and best converted into a

622
00:37:04.171 --> 00:37:07.500
generated photorealistic looking image after we train.

623
00:37:07.590 --> 00:37:10.050
And that's the whole point of our loss functions.
Okay,

624
00:37:11.130 --> 00:37:14.400
so we generate 50 features and then 25 features.

625
00:37:14.401 --> 00:37:17.820
And what do I mean by features here?
Features are those images.

626
00:37:17.850 --> 00:37:20.910
There are less and less and less and less images.
So if we,

627
00:37:20.970 --> 00:37:22.230
if we were to look at this,

628
00:37:23.110 --> 00:37:23.490
<v 0>yeah,</v>

629
00:37:23.490 --> 00:37:27.180
<v 1>just flip this.
Let me just say literally just d.</v>

630
00:37:29.640 --> 00:37:30.473
<v 0>Okay.</v>

631
00:37:31.780 --> 00:37:33.810
<v 1>What's a good event?
This is a good man.
No,
this is not marriage.</v>

632
00:37:34.160 --> 00:37:38.000
<v 0>This is a good image.
Okay.</v>

633
00:37:39.810 --> 00:37:44.040
<v 1>The convolutional network.
Big Image.
Smaller images.
Okay.</v>

634
00:37:45.090 --> 00:37:48.270
All right.
So then we have our,

635
00:37:48.830 --> 00:37:49.663
<v 0>okay.
And then</v>

636
00:37:52.110 --> 00:37:55.620
<v 1>we are not doing batch normalization in the last layer,</v>

637
00:37:55.650 --> 00:37:58.080
but we done bachelor normalization here.
Okay?

638
00:37:58.081 --> 00:38:01.080
So remember that equation that I showed you for batch normalization at the

639
00:38:01.081 --> 00:38:03.680
beginning.
Now it's being put to use.
And so we,

640
00:38:03.690 --> 00:38:07.950
what we do is we apply it and these,
these layers,
all of these legacy once,

641
00:38:07.980 --> 00:38:12.020
twice,
three times,
but not in the last layer.
Uh,

642
00:38:12.950 --> 00:38:17.870
but we do add at sigmoid activator to make the generated images CRISPR.
Okay?

643
00:38:18.320 --> 00:38:21.620
So it's going to be one big cute image that we output in the end.

644
00:38:21.890 --> 00:38:23.510
And check this out.

645
00:38:25.250 --> 00:38:29.830
Maximization is using epsilon,
which is that he value,
what was it right here.

646
00:38:30.050 --> 00:38:34.480
Remember this,
uh,
right here,
this epsilon value,
uh,
and this is a constant value,

647
00:38:34.481 --> 00:38:37.840
which is one e minus five,
which just means that it's a notation for a very,

648
00:38:37.841 --> 00:38:39.520
very small 0.05.

649
00:38:40.080 --> 00:38:44.920
But I mean 0.01 with five place values after the decimal point.

650
00:38:45.280 --> 00:38:50.170
And then given our g one,
which is that,
that first layer,
okay?

651
00:38:52.240 --> 00:38:53.073
<v 0>MMM.</v>

652
00:38:54.180 --> 00:38:58.710
<v 1>Okay.
So that's that.
That's our generator and that's our discriminator.
Okay.</v>

653
00:38:58.830 --> 00:39:00.990
So now this is the part that I'm going to code.

654
00:39:01.350 --> 00:39:06.000
Now we're going to talk about the optimization techniques.
Okay?
So

655
00:39:08.060 --> 00:39:10.670
let me go to the optimization techniques.

656
00:39:11.270 --> 00:39:13.550
Here they are right here.

657
00:39:14.930 --> 00:39:19.290
Let me ask her one question first.
The question is,
Hey Roger,

658
00:39:19.300 --> 00:39:22.280
I was going through an interesting paper called G U N,

659
00:39:22.610 --> 00:39:25.490
which is generative on adversarial networks.

660
00:39:25.790 --> 00:39:29.660
Can you talk a bit more about that too?
I haven't heard of that paper.

661
00:39:29.661 --> 00:39:32.690
That's pretty cool.
Generative adversarial networks.
That's cool.

662
00:39:32.780 --> 00:39:36.680
The space is moving so fast,
you just can't keep up with all of the papers.
Good.

663
00:39:37.030 --> 00:39:41.120
A good a thought though.
I need to check that out.
So back to this,

664
00:39:41.150 --> 00:39:43.820
what we're doing here is we have to loss functions.

665
00:39:44.090 --> 00:39:46.640
The first one is for the discriminator.
Okay?

666
00:39:46.790 --> 00:39:49.730
And I'm going to go through what each of these terms mean mathematically.

667
00:39:50.000 --> 00:39:53.840
Let's start with the first from the,
from the top,
from the,
from the,
and the left.

668
00:39:53.930 --> 00:39:57.050
My left,
maybe you were left to this.

669
00:39:57.050 --> 00:40:00.320
Just this upside down triangle means the gradients.
Okay.

670
00:40:00.860 --> 00:40:02.570
We're trying to find the gradient values,
right?

671
00:40:02.571 --> 00:40:04.610
That's what the loss function is all about.

672
00:40:05.000 --> 00:40:07.820
Let's find the greatest value for the discriminator.
Okay.

673
00:40:08.450 --> 00:40:12.680
So we're saying one over m and then sigma,

674
00:40:13.070 --> 00:40:17.840
I equals one m times.
What is m?
M is the number of samples,

675
00:40:17.990 --> 00:40:21.830
which means the number of images that we are training on.
So we have m images,

676
00:40:21.890 --> 00:40:25.820
okay?
And we're gonna apply as loss function to all those images in a batch.

677
00:40:25.850 --> 00:40:29.180
So there are m images in a batch.
So for this first term right here,

678
00:40:29.181 --> 00:40:33.110
we have log d x to the eye.
So what do I mean by that?
Well,
not to the,

679
00:40:33.111 --> 00:40:37.100
I just ex the ex ex term.
Okay.

680
00:40:37.430 --> 00:40:39.500
What do I mean by this?
This,
this term right here,

681
00:40:39.560 --> 00:40:44.560
log dia backs corresponds to optimizing the probability that the real data x is

682
00:40:45.471 --> 00:40:47.000
rated highly,
okay?

683
00:40:47.120 --> 00:40:50.600
That will means we want to optimize to make sure that the real image that is

684
00:40:50.601 --> 00:40:54.340
presented to the discriminator is optimized for it.

685
00:40:54.500 --> 00:40:57.860
So why do we use log?
Why don't we just say D of x?
Okay.

686
00:40:58.040 --> 00:41:02.740
Because in probability,
if we,

687
00:41:02.800 --> 00:41:07.390
we are,
we are constantly multiplying all of these probability values together,

688
00:41:07.391 --> 00:41:10.270
right?
And what happens when you multiply probabilities together,

689
00:41:10.540 --> 00:41:13.180
they get progressive.
The,
the,
uh,

690
00:41:13.210 --> 00:41:15.880
the product becomes really small.

691
00:41:15.970 --> 00:41:20.970
So if we were to say 0.01 times 0.01 10.01 that value that resulting product,

692
00:41:24.240 --> 00:41:27.500
it's going to be point a million zeros and then one that's,

693
00:41:27.501 --> 00:41:31.540
that's a huge number and it's going to get exponentially bigger by times a

694
00:41:31.541 --> 00:41:33.770
number of probabilities that we multiply by.

695
00:41:34.130 --> 00:41:38.060
So what we do is we use log and so what log does is it gets rid of those 0.0

696
00:41:38.061 --> 00:41:42.260
ones because computers have limited digital floating point precision.

697
00:41:42.470 --> 00:41:46.760
And this makes up for that because those are just huge values,
right?

698
00:41:47.030 --> 00:41:48.740
That's why we use log and probabilities.

699
00:41:48.860 --> 00:41:52.280
But just think of it as just a scaling term.
What we really mean is just the,

700
00:41:52.600 --> 00:41:53.960
the D of X.
Okay?

701
00:41:53.961 --> 00:41:58.961
So we have log probability of Dax plus the log probability of one minus D of g

702
00:42:01.280 --> 00:42:04.580
of Z.
Okay?
What does this mean?
So we have g of Z,

703
00:42:04.730 --> 00:42:07.990
which is the generators probability given the,

704
00:42:07.991 --> 00:42:11.180
that state that we just talked about,
Z,
that random,
that random value.

705
00:42:11.570 --> 00:42:13.700
And so we take say d of GFC.

706
00:42:13.790 --> 00:42:16.640
So if given the value that comes out of the generator,

707
00:42:17.080 --> 00:42:20.750
feed it to d and then we say,
okay,
is this real or fake?
What is the probability?

708
00:42:20.900 --> 00:42:25.040
So we feed the generated value entity and that's going to give us our

709
00:42:25.220 --> 00:42:28.310
probability that it's a fake.
Okay.

710
00:42:29.570 --> 00:42:33.740
So this whole second term corresponds to optimizing the probability that the

711
00:42:33.741 --> 00:42:36.200
generated data GMC is rated poorly.

712
00:42:36.560 --> 00:42:41.560
And so we do one minus that value because it's 100% minus the probability that

713
00:42:42.051 --> 00:42:42.870
it's real or fake.

714
00:42:42.870 --> 00:42:46.640
And that's going to give us the probability that it's rated poorly.

715
00:42:47.720 --> 00:42:49.640
Okay.
And so we do one minus that.

716
00:42:49.641 --> 00:42:54.380
So we have two terms here and we use them together to form this loss.
Okay.

717
00:42:54.440 --> 00:42:55.273
And then,

718
00:42:57.070 --> 00:42:57.810
<v 0>yeah,</v>

719
00:42:57.810 --> 00:42:59.880
<v 1>that's what that is.
And uh,</v>

720
00:43:03.430 --> 00:43:05.980
so this is the term for the generator.
So for the generator,

721
00:43:06.190 --> 00:43:10.630
we have one over m.
So we have the same one minus D of Josie.

722
00:43:10.900 --> 00:43:14.560
But what the generator's trying to do is up is to increase the probability that

723
00:43:14.561 --> 00:43:18.190
the generated data is rated highly.
Okay.
So we have one.

724
00:43:18.220 --> 00:43:22.900
So for the number of samples log probability of one minus the of g of C.

725
00:43:23.320 --> 00:43:26.410
Okay.
And this will make sense when we look at more sense when we look at it

726
00:43:26.411 --> 00:43:28.000
programmatically.
Okay.

727
00:43:29.840 --> 00:43:33.050
By alternating radiant optimization between both of these networks,

728
00:43:33.410 --> 00:43:36.380
we're going to on new batches of real and generated data.

729
00:43:36.530 --> 00:43:40.280
The gain will slowly converge to produce data that it's as realistic hasn't

730
00:43:40.281 --> 00:43:43.970
network is capable of modeling.
So these loss functions,

731
00:43:44.060 --> 00:43:47.370
they are meant not meant,

732
00:43:47.430 --> 00:43:52.430
but they are generally used for convolutional nets feed for nets like neural

733
00:43:54.331 --> 00:43:55.560
nets that are not adversarial,

734
00:43:55.590 --> 00:43:58.350
but we are applying them to this adversarial problem,

735
00:43:58.351 --> 00:44:03.220
this game theoretic problem where we are trying to find the Nash Equilibrium,
uh,

736
00:44:03.310 --> 00:44:07.840
between two networks.
Okay.
It's a game.
It's a mini Max game.
We are,

737
00:44:08.320 --> 00:44:13.170
we are simultaneously minimizing the probability that something is fake and also

738
00:44:13.171 --> 00:44:18.150
maximizing the probability that is real.
So that's what that is.
And so let me,

739
00:44:18.180 --> 00:44:19.013
um,

740
00:44:26.010 --> 00:44:26.843
<v 0>okay.</v>

741
00:44:29.330 --> 00:44:32.730
<v 1>Two minute papers with Cardozo.
I fair.
I love the guy.</v>

742
00:44:32.880 --> 00:44:36.210
I actually did a collab with them a long time ago.
He's a,
he's a cool guy.

743
00:44:36.600 --> 00:44:39.570
I just typed his last name,
man.
Uh,
where was I?

744
00:44:40.260 --> 00:44:41.700
So what are we doing here?

745
00:44:43.540 --> 00:44:46.300
What are we doing?
Oh,
I know what we're doing.

746
00:44:46.600 --> 00:44:48.040
We're going to say if we're going to cut this part out.

747
00:44:48.310 --> 00:44:52.180
So we have our tensor flow session,
right?
Because we're about to train our,
our,

748
00:44:52.270 --> 00:44:54.090
our network.
So we all,
we need to,

749
00:44:54.140 --> 00:44:56.710
to our session session and then we're gonna say,
okay,

750
00:44:56.740 --> 00:45:01.740
so the batch size is going to be 50 and then a number of dimensions is going to

751
00:45:01.871 --> 00:45:05.530
be 100 so z can be a lot of dimensions.

752
00:45:05.560 --> 00:45:09.010
And so we want to limit how many dimensions he can be in so that it's just

753
00:45:09.011 --> 00:45:12.520
faster for our model to,
to converge.
And we want 50 images in a batch.

754
00:45:13.060 --> 00:45:16.690
And what we're going to feed the discriminator is going to be the image and how

755
00:45:16.691 --> 00:45:18.940
do we feed it in.
We use our gateway intention flow,

756
00:45:18.950 --> 00:45:23.620
the placeholder to feed that human gene and the type it's going to be is a float

757
00:45:23.621 --> 00:45:26.050
value.
And then we're going to define the shape of that image.

758
00:45:26.470 --> 00:45:30.340
And the shape is going to be a 20 by 28 image,
okay.

759
00:45:30.970 --> 00:45:34.540
With a depth of one APP,
but it's a 20 by 28 image.

760
00:45:34.900 --> 00:45:39.820
And then we have our placeholder down.
You okay?

761
00:45:40.670 --> 00:45:41.140
<v 0>Okay.</v>

762
00:45:41.140 --> 00:45:45.400
<v 1>To feed him,
put the two d.
Okay.</v>

763
00:45:45.430 --> 00:45:49.480
Feed image two D,
image two d.
Okay,
so now,

764
00:45:50.590 --> 00:45:51.120
<v 0>okay,</v>

765
00:45:51.120 --> 00:45:54.480
<v 1>we're going to define GFC.
Okay.
So this is g z.</v>

766
00:45:54.720 --> 00:45:57.750
So remember these equations that we define,
it appeared there's GMC,

767
00:45:57.900 --> 00:46:00.450
there's d of Goc,
and then there's the events.

768
00:46:00.451 --> 00:46:03.570
There's three different equations and we'll talk about what each of these means.

769
00:46:03.571 --> 00:46:08.070
We have GMC.
So GMC is going to be,
we'll just call it jersey.

770
00:46:08.280 --> 00:46:12.080
And so we're going to initialize that generator function that we've already,
um,

771
00:46:13.110 --> 00:46:15.330
we're going to call that generator function that we've already defined.

772
00:46:15.630 --> 00:46:17.580
And then we're going to give it those two printers.

773
00:46:17.581 --> 00:46:20.220
We justifying the batch size and the z dimensions.

774
00:46:20.520 --> 00:46:25.300
And GMC is going to hold the generated images.
Okay?
So that's GMC.

775
00:46:25.710 --> 00:46:30.120
The next term is d of x.
So x is going to say,

776
00:46:32.450 --> 00:46:34.190
uh,
the Webex is going to say,

777
00:46:34.850 --> 00:46:38.180
it's going to hold the discriminators prediction probabilities for the real

778
00:46:38.210 --> 00:46:42.430
images.
That's what d avax does.
It holds the probabilities of the real images.

779
00:46:42.431 --> 00:46:46.340
Can we say d backs equals that discriminator that we defined,
uh,

780
00:46:46.640 --> 00:46:51.500
given that the image which is in the place holder.
So that's for the real images,

781
00:46:52.010 --> 00:46:55.970
probs of real images.
And then lastly,

782
00:46:56.240 --> 00:46:59.270
we have d of g of z.

783
00:46:59.450 --> 00:47:01.250
So remember up in this equation up here,

784
00:47:01.251 --> 00:47:03.800
those were the three terms that we were dealing with.

785
00:47:04.010 --> 00:47:08.840
We were dealing with Dfax GFC and then d of GFC.

786
00:47:08.930 --> 00:47:10.820
So we're defining those right now.
Okay.

787
00:47:14.320 --> 00:47:16.180
So,
and what does the GFC hold?

788
00:47:16.181 --> 00:47:19.330
It holds the props of generated images.

789
00:47:21.160 --> 00:47:25.390
So we say [inaudible] [inaudible] called DG equals discriminator,

790
00:47:25.920 --> 00:47:30.880
give in GMC the word.
Literally see if we're in that generate value.

791
00:47:31.180 --> 00:47:34.090
And we say reuse to true because well,
once we use it over and over.

792
00:47:35.230 --> 00:47:40.000
<v 2>Okay.
Right,
right.
Okay.</v>

793
00:47:40.600 --> 00:47:41.433
So,

794
00:47:43.890 --> 00:47:47.700
<v 1>right.
I wish we could just use a simple optimization technique like mean squared</v>

795
00:47:47.701 --> 00:47:51.030
error.
Right.
But we can't because it's just not going to work for gans.

796
00:47:51.300 --> 00:47:54.420
Gans are hard to train.
They are not easy to train.

797
00:47:54.690 --> 00:47:58.470
This is why we need better optimization techniques.
Where Gans let's get to work.

798
00:47:58.471 --> 00:48:02.760
Let's start building better optimization techniques for gans.
Okay.

799
00:48:02.970 --> 00:48:05.940
Think,
think game theory.
Think Game Theory.
Okay.

800
00:48:05.941 --> 00:48:10.180
Think of approaches that no one has ever thought of before.
Okay,

801
00:48:10.181 --> 00:48:12.370
so now we're going to define our loss.
Our first loss.

802
00:48:12.371 --> 00:48:14.980
Remember we have two losses here.
We have a generators,
laws,

803
00:48:15.010 --> 00:48:15.960
and our discriminators law.

804
00:48:15.961 --> 00:48:20.961
So for our generators loss we're going to say let's find the mean value.

805
00:48:21.131 --> 00:48:24.280
So we have a set of numbers and we add them all up and divide by the number of

806
00:48:24.281 --> 00:48:24.790
them.

807
00:48:24.790 --> 00:48:28.900
What are we finding the mean value off what we're finding the mean value of the

808
00:48:29.170 --> 00:48:30.670
cross entropy

809
00:48:33.820 --> 00:48:38.260
<v 2>with lodge,
it's what the hell are you doing,
sir?</v>

810
00:48:38.270 --> 00:48:40.290
Roger of DMG.

811
00:48:41.740 --> 00:48:43.840
And then our labels,

812
00:48:44.110 --> 00:48:48.820
which are ones like DMG.
Okay,

813
00:48:49.170 --> 00:48:50.003
so,

814
00:48:55.280 --> 00:49:00.140
<v 1>so we want the generator network to create images that will generate images that</v>

815
00:49:00.141 --> 00:49:02.230
will fool the discriminator.
And we want the,

816
00:49:02.280 --> 00:49:06.500
the sort of the generator wants to discriminator to output a one which is a

817
00:49:06.501 --> 00:49:09.560
positive example and wants it,
it wants it to discriminate and saying,
okay,

818
00:49:09.561 --> 00:49:14.330
one means yes,
this is real and zero means no,
this is not real.
So we want a one.

819
00:49:14.660 --> 00:49:17.660
Okay.
So the loss function,
the difference,

820
00:49:17.720 --> 00:49:22.720
the difference that we're trying to kick compute here is between us one,

821
00:49:23.150 --> 00:49:25.640
which is why I said once.
So the reason I'm saying one,

822
00:49:25.641 --> 00:49:30.470
like the of Ge is to say the size of the FG just have a matrix of ones and the

823
00:49:30.490 --> 00:49:33.470
of g is going to be,
uh,
the actual generated values.

824
00:49:33.590 --> 00:49:35.810
So we're going to minimize the difference between those two.

825
00:49:35.990 --> 00:49:38.480
So we use cross entropy to do that.
Okay.

826
00:49:40.220 --> 00:49:41.053
<v 0>MMM.</v>

827
00:49:43.420 --> 00:49:45.790
<v 1>And so the whole point of using the width lodges,</v>

828
00:49:46.030 --> 00:49:50.230
a component is because the function will operate on unscaled values.

829
00:49:50.350 --> 00:49:52.720
So we don't have to scale them.
That's what lodge it's means.

830
00:49:52.840 --> 00:49:56.260
So we have a matrix of which DMG,
which is the generated images.

831
00:49:56.261 --> 00:50:00.220
And then we have a,
from the discriminator and then the,
uh,

832
00:50:01.000 --> 00:50:01.480
<v 0>okay.</v>

833
00:50:01.480 --> 00:50:05.980
<v 1>The probabilities of the generated images.
Okay.
So that's our gs loss.
Okay?</v>

834
00:50:05.981 --> 00:50:07.870
So that's our first loss.
And then we have,

835
00:50:08.490 --> 00:50:11.600
<v 2>hey,
can</v>

836
00:50:13.790 --> 00:50:16.410
I,
so we have quite a bit to go over.

837
00:50:16.411 --> 00:50:18.990
So I'm just gonna go over this.

838
00:50:19.400 --> 00:50:22.220
<v 1>Sometimes I can type out all the code and sometimes it's just,</v>

839
00:50:22.221 --> 00:50:24.350
it's just too much.
So this is one of those examples when you're,

840
00:50:24.351 --> 00:50:28.340
when you're dealing with cutting edge technology,
sometimes you just gotta,

841
00:50:28.610 --> 00:50:33.020
you just gotta do what you gotta do.
Okay?
So
that's our GI loss.

842
00:50:33.021 --> 00:50:36.890
And the next loss that we're going to calculate compute r is the discriminators

843
00:50:36.891 --> 00:50:40.550
loss.
So it's one last function,
but it's got two components.
Remember,

844
00:50:40.551 --> 00:50:42.710
it's got two components.
So remember up here,

845
00:50:43.070 --> 00:50:46.790
the generators is just this one component right here.
One big component.

846
00:50:47.000 --> 00:50:49.190
But the discriminator had two components,
right?

847
00:50:49.340 --> 00:50:52.260
Log of d of x plus log of one minus t of Geo.

848
00:50:52.380 --> 00:50:56.210
So we have to have two components and add them together to get the a song.

849
00:50:56.360 --> 00:51:00.950
So that's what we'll do here.
Programmatically will say,
uh,

850
00:51:02.120 --> 00:51:03.230
let me make this smaller.

851
00:51:04.130 --> 00:51:07.460
We want to compute the loss between Dmx and the correct label of one,

852
00:51:07.550 --> 00:51:08.870
which is what this first one does.

853
00:51:09.260 --> 00:51:12.800
And then the last between DMG and the correct label of zero,

854
00:51:12.920 --> 00:51:16.790
which is what this align does.
So we're taking the average,

855
00:51:17.120 --> 00:51:21.500
the mean or average value of the cross entropy between,
uh,

856
00:51:21.780 --> 00:51:26.780
the d of x with one and then the cross entropy of d a g t of GFC with a zero.

857
00:51:30.980 --> 00:51:31.610
Okay.

858
00:51:31.610 --> 00:51:35.390
So the probability that an image is real and their probability that an image is

859
00:51:35.391 --> 00:51:40.310
fake,
we had them together.
Okay.
And that's going to be our de la.

860
00:51:40.311 --> 00:51:42.740
So we have our GI loss and then our d loss.
Okay.

861
00:51:42.741 --> 00:51:46.040
And then let me get through this,
this,
um,
code block right here.

862
00:51:46.041 --> 00:51:49.820
And then I'll answer questions.
And then we're gonna,

863
00:51:49.880 --> 00:51:54.740
we're gonna call our variables here.
This is a,
this is some great.
So,

864
00:51:54.770 --> 00:51:59.270
uh,
this is some great,
uh,
syntax right here.
I think this is really beautiful.

865
00:51:59.540 --> 00:52:00.373
So

866
00:52:01.340 --> 00:52:01.960
<v 0>yeah,</v>

867
00:52:01.960 --> 00:52:05.920
<v 1>great thing about tensorflow is we can call variables that are defined under a</v>

868
00:52:05.921 --> 00:52:06.401
certain name.

869
00:52:06.401 --> 00:52:10.630
And this is why it's important to name your variables and to have constant

870
00:52:10.631 --> 00:52:13.150
values that relate variables that are related.

871
00:52:13.180 --> 00:52:17.050
Because we can just say for all of those variables in our tensorflow variables

872
00:52:17.051 --> 00:52:20.500
that already exist,
which we can call using this trainable variables function.

873
00:52:20.830 --> 00:52:23.560
We'll say if all those variables that start with d underscore,

874
00:52:23.770 --> 00:52:25.180
those are all of our discriminator variables,

875
00:52:25.181 --> 00:52:28.090
which are the weights which we want to update,
right?

876
00:52:28.120 --> 00:52:30.960
So we can just call them just like that.
And then all of our weights for our,

877
00:52:31.060 --> 00:52:34.950
for our generator so we can store those weights and dvrs and store the toys and

878
00:52:35.010 --> 00:52:37.690
[inaudible] see how easy that was.
And three lines of code.

879
00:52:37.750 --> 00:52:42.310
We called all of our weights so we can update them using our gradients.
Okay.

880
00:52:42.311 --> 00:52:44.260
So then we want to train our discriminator.
Okay.

881
00:52:44.261 --> 00:52:45.610
So this is what we're doing here.

882
00:52:46.720 --> 00:52:51.720
We're training our discriminator by minimizing the for discriminator.

883
00:52:52.481 --> 00:52:54.010
We want to,
um,

884
00:52:56.280 --> 00:52:59.250
we're minimizing two losses here.
These these two components,

885
00:52:59.251 --> 00:53:01.980
but we want to make sure that it is finding the,

886
00:53:02.150 --> 00:53:05.070
it is discriminating between real and fake and it's,

887
00:53:05.100 --> 00:53:08.800
it's got to make sure that the value that it looks at,
if it,

888
00:53:08.801 --> 00:53:11.640
if it classifies it as fake,
that they are fic.

889
00:53:11.880 --> 00:53:14.250
So that's what that first line does.
And if it classifies it a real day,

890
00:53:14.290 --> 00:53:19.140
Israel and these two respective lines are optimizing for both of those

891
00:53:19.170 --> 00:53:23.040
scenarios.
And we're using Adam because Adam seems to be

892
00:53:24.750 --> 00:53:26.060
the best optimization

893
00:53:26.060 --> 00:53:29.540
technique for generative adversarial networks in several papers that I've looked

894
00:53:29.541 --> 00:53:34.440
at from Wasserstein gans to buy guns.
Adam seems to work pretty well.
Um,

895
00:53:34.640 --> 00:53:36.350
but obviously,
like I said before,

896
00:53:36.440 --> 00:53:40.240
it can be much improved and there's a lot of potential there,
uh,

897
00:53:40.880 --> 00:53:42.860
for greatness.
So,

898
00:53:44.800 --> 00:53:47.680
but for D and then for the g g we're doing the same thing.

899
00:53:47.920 --> 00:53:51.610
And so why these learning rates?
Why Point Oh one first the 0.0,

900
00:53:51.820 --> 00:53:56.760
why 0.01 because,
um,
by the way,
um,

901
00:53:58.210 --> 00:54:01.570
because it's,
it was,
it was tried in the,
uh,
original DC Gann paper,
by the way.

902
00:54:01.690 --> 00:54:05.470
Momentum.
Adam uses something called momentum,
which is a great technique.

903
00:54:05.471 --> 00:54:08.740
This is a tangent,
but it's uh,
it's an important tangent.
So,
so check this out.

904
00:54:09.190 --> 00:54:14.190
Momentum is a technique for optimization that is really cool.

905
00:54:17.230 --> 00:54:21.490
And what I want to show you is the best blog posts I've ever seen.
A momentum.

906
00:54:21.491 --> 00:54:24.580
Look at him.
Look how beautiful this is.
So you can just say,

907
00:54:26.180 --> 00:54:27.470
you can visually interact with this,

908
00:54:27.620 --> 00:54:32.620
this still great publication for visually looking at math and a great

909
00:54:32.781 --> 00:54:37.340
opportunity for publishing.
So if you want to publish some research,
you're a,

910
00:54:37.341 --> 00:54:40.370
you're a developer,
you're living,
you know,
you're not a part of an institution,

911
00:54:40.371 --> 00:54:44.630
but you still want to make a contribution to the field.
This still is your,

912
00:54:45.030 --> 00:54:49.210
uh,
should be,
you are research publication of choice.
Publish here.
Uh,

913
00:54:49.220 --> 00:54:53.030
we've got all the cool kids publishing here and you can utilize some d three.

914
00:54:53.031 --> 00:54:56.950
Dot.
Js that still has got some great instructions on how to,
um,
you know,

915
00:54:56.960 --> 00:55:01.280
publish a good paper here,
but check it out.
A lot of great visual stuff here.

916
00:55:01.580 --> 00:55:04.460
The whole point of this still has had make machine learning papers readable,

917
00:55:04.640 --> 00:55:09.570
right?
No one wants to read PDFs that are locked away in archiver.
I mean,
I,

918
00:55:09.571 --> 00:55:13.070
I want to read them,
but it's just better to have them be visually appealing.

919
00:55:13.760 --> 00:55:14.810
Okay.
So that's that.

920
00:55:14.900 --> 00:55:18.620
And then we're going to save those values because we want to visualize it using

921
00:55:18.621 --> 00:55:22.690
tensor board.
And so we're going to use this summary Scalar versus to,
uh,

922
00:55:22.730 --> 00:55:27.110
extract the protocol buffers that we then write using the,
the writer function,

923
00:55:27.111 --> 00:55:29.570
right?
And so,

924
00:55:34.060 --> 00:55:34.301
okay,

925
00:55:34.301 --> 00:55:39.301
so we have respective scalers for all of those lost function components that we

926
00:55:39.340 --> 00:55:41.170
optimize that we defined earlier.

927
00:55:41.470 --> 00:55:45.650
And then we're going to write them to tensor board in the log directory tends,

928
00:55:45.651 --> 00:55:48.370
or board.
Slash.
Gan.
And you can name this whatever you want,

929
00:55:48.371 --> 00:55:53.320
but I'm calling attention board slash can hear.
Okay.
Okay.
So,
uh,

930
00:55:53.380 --> 00:55:55.630
last part here.
So for the,
so for that,
for the,

931
00:55:55.810 --> 00:55:59.890
we've defined our loss functions and now we want to train this network.
And so,

932
00:56:00.250 --> 00:56:02.560
uh,
there are,
uh,
several things that can go wrong here.

933
00:56:02.561 --> 00:56:07.000
So remember I talked about how the loss functions that we use for Gans right now

934
00:56:07.001 --> 00:56:09.280
are not ideal.
They're,
they're,
they're good.

935
00:56:09.281 --> 00:56:12.550
They work that can generate faces and a bunch of other things.
But remember,

936
00:56:12.640 --> 00:56:17.640
gans are hard to train and these are three points that that come up when we

937
00:56:18.071 --> 00:56:22.390
train them.
One of the Ar points slash fail fail cases,

938
00:56:22.391 --> 00:56:25.930
failure cases,
the discriminator loss is approached zero.

939
00:56:25.960 --> 00:56:29.240
That means that it leaves no gradients for the generators optimizer.

940
00:56:29.241 --> 00:56:31.720
So if the discriminators loss approaches zero,

941
00:56:31.780 --> 00:56:33.670
then those gradients are going to banish.

942
00:56:33.671 --> 00:56:36.070
They're going to w this is the vanishing gradient problem,

943
00:56:36.071 --> 00:56:39.700
not applied to recurrent nets,
but to generative adversarial networks.

944
00:56:39.850 --> 00:56:43.510
So for current next,
the way we solved that was by using LSTM sells for,

945
00:56:43.511 --> 00:56:47.920
but for dance,
we don't really have,
uh,
a technique to,
to solve it.

946
00:56:47.921 --> 00:56:50.700
So we have to do something a little hacky here.
Um,

947
00:56:50.890 --> 00:56:55.810
but I think that there is some progress,
some great progress to,

948
00:56:56.140 --> 00:57:00.620
to prevent that.
And that would be in Wasserstein Ganz,
Wga n,

949
00:57:00.760 --> 00:57:04.090
so Google that.
Okay.
So that's one failure case.

950
00:57:04.091 --> 00:57:07.720
The other is that the discriminators lost could rise unbounded by generated

951
00:57:07.721 --> 00:57:08.860
images.
That means that,

952
00:57:09.900 --> 00:57:10.733
<v 2>uh,</v>

953
00:57:13.400 --> 00:57:15.000
<v 1>that the gradient that their generators,</v>

954
00:57:15.001 --> 00:57:18.060
training stalls and then discriminators just never going to converge.

955
00:57:18.480 --> 00:57:22.920
And then the divergent discriminator accuracy,
it just learns a shortcut.

956
00:57:23.040 --> 00:57:25.680
And this is what I was talking about before,
where we are,

957
00:57:25.681 --> 00:57:29.160
it just going to discriminate is going to classify everything as either real or

958
00:57:29.161 --> 00:57:33.360
everything has generated just through some,
some blip in the network.
Uh,

959
00:57:33.361 --> 00:57:37.390
so three things that could go wrong that are documented here,
um,

960
00:57:37.950 --> 00:57:40.200
but several things could go wrong,
right?
So,

961
00:57:43.450 --> 00:57:45.910
so during every iteration there'll be two updates being made,

962
00:57:45.911 --> 00:57:49.750
one to the discriminator and one to the generator for the generator update,

963
00:57:49.751 --> 00:57:51.160
we'll feed in a random z Becker,

964
00:57:51.190 --> 00:57:54.640
which I talked about before to the generator and pass that output to the

965
00:57:54.641 --> 00:57:57.040
discriminator to obtain the probability score.

966
00:57:57.200 --> 00:58:00.760
That's what the DG variable is we specified earlier.
Okay.

967
00:58:01.720 --> 00:58:04.510
So let's look at what this looks like.
So we define,
um,

968
00:58:05.770 --> 00:58:09.010
those values that we want that does that mean real versus steak?

969
00:58:09.190 --> 00:58:13.810
So just zero means fake.
Okay.
And for the generator.
And then for,

970
00:58:14.290 --> 00:58:16.930
uh,
the discriminator,
we have one and one,

971
00:58:16.931 --> 00:58:19.750
which is what we're optimizing for and the real and fake directions.

972
00:58:20.080 --> 00:58:23.920
So we have 50,000 trading iterations.
And what we're going to say is,
uh,

973
00:58:23.950 --> 00:58:28.240
for each of these batches,
right?
So for all batches we're going to say these are,

974
00:58:28.241 --> 00:58:29.950
so these are the random,
these are the,

975
00:58:29.980 --> 00:58:33.580
these are the magic numbers 0.6 versus 0.5 versus 0.45.

976
00:58:33.970 --> 00:58:37.060
And why we're saying greater than,
because we want ideally what we're,

977
00:58:37.080 --> 00:58:41.560
where we are hard coding in here is we want to stop training each of these loss

978
00:58:41.570 --> 00:58:45.440
phone functions once these values are,
um,

979
00:58:46.060 --> 00:58:49.960
less than these 0.6.
So if it's greater than 0.6,

980
00:58:49.990 --> 00:58:52.630
then just keep training until it's less than 0.6.
You see what I'm saying?

981
00:58:52.900 --> 00:58:55.390
And vice versa for all of these and not vice versa.

982
00:58:55.460 --> 00:58:57.790
Apply the same logic to all of these things.

983
00:58:58.000 --> 00:59:00.970
So first we trained the discriminator and then we train the generator,

984
00:59:01.030 --> 00:59:03.880
and then we train the discriminator,

985
00:59:03.881 --> 00:59:08.290
classifying real images as fake on,
uh,
on real values.
Okay?

986
00:59:08.950 --> 00:59:13.480
Um,
so the,
so this is why we have three of these generators for the general.

987
00:59:13.510 --> 00:59:15.220
So the first one is for the generator.

988
00:59:15.460 --> 00:59:19.240
The next one is for the first one is to train the discriminator on the generated

989
00:59:19.241 --> 00:59:21.560
images.
The next one is to train the generator.

990
00:59:21.620 --> 00:59:25.820
And the last one is to train a discriminator to classify we overseas fake.
Okay.

991
00:59:25.821 --> 00:59:27.410
And then we print these out.

992
00:59:29.050 --> 00:59:33.610
Let me go back here and make sure that I've compiled everything to make sure

993
00:59:33.611 --> 00:59:35.260
that it all compiles here.

994
00:59:36.730 --> 00:59:40.120
<v 2>Yup.
Yup,
Yup,
Yup,
Yup.</v>

995
00:59:41.050 --> 00:59:44.540
<v 1>Do have not fine.
Cause they didn't find up here.
Okay.</v>

996
00:59:44.541 --> 00:59:46.970
So we are running out of time.
So let me say this.

997
00:59:47.030 --> 00:59:50.120
So this is us visualizing what's what,
what it's looking like.

998
00:59:50.270 --> 00:59:53.390
And I'm gonna wrap up in five minutes.
So

999
00:59:54.890 --> 00:59:59.720
see here that the discriminator is getting better.

1000
00:59:59.820 --> 01:00:02.510
It's the number is actually bigger,
but it's negative.
So it's,
it's good.

1001
01:00:02.520 --> 01:00:06.830
It's getting better over time and then it saving it to this pretrained a folder

1002
01:00:07.130 --> 01:00:10.340
and then,
uh,
we can even display it.
But here's the thing,
quick thing,

1003
01:00:10.430 --> 01:00:13.520
and then I'll ask you some questions.
Um,
check this blog posts out,
by the way,

1004
01:00:13.540 --> 01:00:16.880
a fantastic gans and where to find them

1005
01:00:20.820 --> 01:00:23.070
because we're not going to have time to visualize a loss.

1006
01:00:23.100 --> 01:00:24.840
But what I can do is I can show you the loss,

1007
01:00:24.841 --> 01:00:26.280
what it's going to look like and why.

1008
01:00:26.640 --> 01:00:30.000
Why said we need better optimization techniques for Gan despite the amazing

1009
01:00:30.001 --> 01:00:31.170
results that they achieve.

1010
01:00:32.280 --> 01:00:33.113
<v 2>Uh,</v>

1011
01:00:33.650 --> 01:00:34.483
<v 1>okay,
check this out.</v>

1012
01:00:34.940 --> 01:00:37.340
This is what the loss is going to look like for both of them.

1013
01:00:40.080 --> 01:00:41.280
<v 2>Hold on.
There we go.</v>

1014
01:00:41.830 --> 01:00:44.740
<v 1>For the generator and the discriminary generators,
green discriminators blue.</v>

1015
01:00:44.800 --> 01:00:48.820
Okay,
check this out.
What we want is the loss to minimize,
right?

1016
01:00:48.821 --> 01:00:51.730
We want to see it go down.
But what's happening here is it's not minimizing,

1017
01:00:51.731 --> 01:00:55.570
it's just going all over the place.
So how do we know when to stop training?

1018
01:00:56.320 --> 01:01:00.640
We just have to guess kind of,
we kind of have to guess when it's,
when it's,

1019
01:01:00.700 --> 01:01:05.140
there's no,
there's no point of a mathematical convergence.
It's more of a,

1020
01:01:05.200 --> 01:01:08.350
it's more of an intuition.
You have to have an intuition behind.
Okay,

1021
01:01:08.500 --> 01:01:11.520
well just by looking at an image and saying this is,
this is,
um,

1022
01:01:12.370 --> 01:01:14.770
sufficiently photorealistic but fake,

1023
01:01:15.280 --> 01:01:18.250
which works and we've generated some really cool things,

1024
01:01:18.251 --> 01:01:22.060
but we need better optimization techniques.
And remember this,
the bleeding edge,

1025
01:01:22.061 --> 01:01:22.540
right?
We are,

1026
01:01:22.540 --> 01:01:26.740
we are at the edge of human knowledge on neural networks and deep learning.

1027
01:01:26.741 --> 01:01:28.360
Right now we're at the end of this course.

1028
01:01:28.750 --> 01:01:33.520
So if you were looking for a really cool idea on how to improve the space,

1029
01:01:33.970 --> 01:01:37.720
better optimization techniques for generative adversarial networks.
Okay.

1030
01:01:37.721 --> 01:01:42.220
Because this needs to be better.
And it's not that,
it's some crazy hard thing.

1031
01:01:42.221 --> 01:01:46.480
It's just no one's ever,
no one's ever attempted to do this before.
Okay.

1032
01:01:46.720 --> 01:01:50.200
That's it for the,
for this live stream.
Let me answer some questions,
some,
some,

1033
01:01:50.201 --> 01:01:54.920
uh,
last questions.
Okay.
Uh,

1034
01:02:01.890 --> 01:02:06.650
so the last questions are,
could we start the,
the wrap,
by the way,

1035
01:02:06.651 --> 01:02:11.150
I'm going to wrap by the way.
We have two minutes.
Can you use gas for NLPs?
Yes,

1036
01:02:11.151 --> 01:02:15.200
you can.
No,
that's a great area of research.
Yes.
Yes.

1037
01:02:15.320 --> 01:02:17.540
I want to see more of that.
I actually haven't seen enough of that.

1038
01:02:17.780 --> 01:02:22.290
And then are we optimizing for zero sum game when we are optimizing for a zero

1039
01:02:22.291 --> 01:02:22.861
sum game?

1040
01:02:22.861 --> 01:02:25.980
Why don't we use methods of well studied game playing algorithms for Gan?

1041
01:02:28.310 --> 01:02:32.840
Yes.
See you are thinking the exact way that I'm trying to convey.

1042
01:02:33.200 --> 01:02:36.890
There's this entire field of research around game theory that we haven't really

1043
01:02:36.891 --> 01:02:40.880
applied to generative adversarial networks even though it is a game theoretic

1044
01:02:41.260 --> 01:02:42.620
problem.
Right.
So,

1045
01:02:43.950 --> 01:02:44.540
<v 0>okay.</v>

1046
01:02:44.540 --> 01:02:46.900
<v 1>All right,
so I'm going to wrap at the end.
We've got two more minutes.</v>

1047
01:02:47.290 --> 01:02:50.350
So it's going to be to a Kendrick's new album down,

1048
01:02:50.440 --> 01:02:54.200
which I've been listening to a lot.
If you've been listening to it,

1049
01:02:54.570 --> 01:02:58.820
you get this out.
All right,
so let me someone,
someone throw out a topic.

1050
01:02:59.530 --> 01:03:01.070
I'm throwing a topic when we got here.

1051
01:03:04.610 --> 01:03:08.130
What's the topic?
One more topic.
I'm looking for a one word topic.

1052
01:03:09.960 --> 01:03:14.850
Carlos as,
come on.
Here we go.
One more topic.

1053
01:03:14.851 --> 01:03:17.040
People first to say it versus say it gets it.

1054
01:03:25.240 --> 01:03:28.720
Cool.
Topics,
rods.
That's not the topic.
So Dan,
better

1055
01:03:30.990 --> 01:03:35.880
rap.
I'm an animal.
Come on,
let's see a topic.
I get Gan.
Okay,
fine.

1056
01:03:36.490 --> 01:03:41.070
Yeah.
Okay.
I try to rap dance.
Kazaam the man.

1057
01:03:41.071 --> 01:03:45.780
I do it every day,
man.
I'm like,
no cans now was a famous guy.

1058
01:03:45.960 --> 01:03:47.880
He was living in Siberia.

1059
01:03:47.940 --> 01:03:51.180
He came back looking at people like he was from my beer.
Yeah.

1060
01:03:51.360 --> 01:03:55.800
He was one of the best researchers.
The fall time,
if you want to be like him,
man,

1061
01:03:55.830 --> 01:04:00.540
you got to learn to ride,
not just with words.
You've got to run with math.

1062
01:04:00.570 --> 01:04:05.570
You gotta go back to back to back to back with every single loss function that

1063
01:04:05.791 --> 01:04:09.690
you try.
Don't try and make it stop.
Sit down and try to cry.

1064
01:04:09.750 --> 01:04:13.260
If you can't get this,
sit down.
I don't want to listen.

1065
01:04:13.390 --> 01:04:18.180
You've got to be the best man.
Look,
it's don't be just in.
Okay.

1066
01:04:18.720 --> 01:04:23.240
That's it for our route.
See,
that's how you know it's live.

1067
01:04:23.270 --> 01:04:24.860
That's how you know it's live.
Okay.

1068
01:04:24.861 --> 01:04:28.920
So thank you guys for showing up and for that,

1069
01:04:29.990 --> 01:04:34.580
I've got a research,
some gans some more,
and it's gonna be really exciting.

1070
01:04:34.581 --> 01:04:37.310
So love you guys.
Thanks for watching.

1071
01:04:39.350 --> 01:04:39.400
<v 0>Yeah.</v>

