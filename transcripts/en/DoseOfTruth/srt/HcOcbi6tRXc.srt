1
00:00:07,680 --> 00:00:10,460
Wesley yang reported that
you met with Tech Titans,

2
00:00:10,461 --> 00:00:12,140
Marc Andreessen and Peter Teal,

3
00:00:12,290 --> 00:00:15,110
both of whom advocate
decentralized education.

4
00:00:15,111 --> 00:00:16,670
Can you share anything about this?

5
00:00:17,300 --> 00:00:18,133
Um,

6
00:00:18,680 --> 00:00:20,720
I don't know if I can
share anything interesting.

7
00:00:20,960 --> 00:00:21,261
I mean,

8
00:00:21,261 --> 00:00:23,210
I enjoyed the meeting mark and Peter.

9
00:00:23,211 --> 00:00:24,650
I met mark several times.

10
00:00:24,970 --> 00:00:25,310
Um,

11
00:00:25,310 --> 00:00:26,510
I've only met Peter Wants,

12
00:00:26,511 --> 00:00:30,140
although I've spent some time with
Eric Weinstein who works with Peter,

13
00:00:31,570 --> 00:00:31,880
you know,

14
00:00:31,880 --> 00:00:33,740
Peter is Libertarian oriented.

15
00:00:34,160 --> 00:00:34,993
Um,

16
00:00:35,270 --> 00:00:36,103
and so

17
00:00:37,080 --> 00:00:37,650
he,

18
00:00:37,650 --> 00:00:38,220
he,

19
00:00:38,220 --> 00:00:43,220
he shares concerns about the potential
totalitarian function of Internet

20
00:00:45,001 --> 00:00:48,440
technology and manifesting itself well in,

21
00:00:48,441 --> 00:00:52,110
in the constant monitoring
of our behavior and also in,

22
00:00:53,490 --> 00:00:54,930
in the emergent censorship.

23
00:00:54,931 --> 00:00:57,030
Let's say Marc Andreessen,

24
00:00:57,060 --> 00:01:00,730
well Mark's a smart guy and he knows
a lot of other smart guys and we,

25
00:01:00,840 --> 00:01:05,840
we spent a lot of time talking about
the possibility of online education and,

26
00:01:06,300 --> 00:01:07,610
and uh,

27
00:01:07,770 --> 00:01:10,920
but there isn't anything really
exciting I can report about that.

28
00:01:10,921 --> 00:01:15,060
I mean they were all
preliminary discussions of a
sort to see if we could get

29
00:01:15,061 --> 00:01:16,170
long and if we could talk.

30
00:01:16,171 --> 00:01:17,670
And so far we've been able to,

31
00:01:18,030 --> 00:01:23,030
I am making a fair bit of headway
with this university project,

32
00:01:23,251 --> 00:01:26,580
although we don't really conceptualize
it as a university project anymore.

33
00:01:26,581 --> 00:01:31,581
We're conceptualizing it as an adaptive
learning system and we're trying to use

34
00:01:32,431 --> 00:01:37,431
it to index people's no index knowledge
on the web funnel money to creative

35
00:01:37,950 --> 00:01:40,140
producers of educational content,

36
00:01:40,560 --> 00:01:44,250
allow people to test their knowledge
no matter how it's generated and to

37
00:01:44,251 --> 00:01:45,600
accredit people properly.

38
00:01:45,601 --> 00:01:46,890
And we'll release,

39
00:01:47,130 --> 00:01:51,030
release more information about that in
the upcoming months as we move closer and

40
00:01:51,031 --> 00:01:52,560
closer to a functional prototype.

41
00:01:52,770 --> 00:01:53,850
The plan at the moment,

42
00:01:54,180 --> 00:01:56,250
I've talked to lots of
people like Andrea said,

43
00:01:56,251 --> 00:01:57,540
and teal who,

44
00:01:57,570 --> 00:02:01,770
who are very interested in technology
and education and who also are very well

45
00:02:01,771 --> 00:02:06,570
capitalized and have had the opportunity
multiple times to pull in investors

46
00:02:06,571 --> 00:02:08,190
into this educational project.

47
00:02:08,191 --> 00:02:11,550
But I haven't done that
partly because weirdly enough,

48
00:02:11,551 --> 00:02:12,360
you know,

49
00:02:12,360 --> 00:02:14,430
you think money is a
solution to a problem,

50
00:02:14,431 --> 00:02:15,264
but it's also,

51
00:02:15,480 --> 00:02:17,370
it's often a problem in and of itself.

52
00:02:17,371 --> 00:02:19,980
And if I generated
several million dollars,

53
00:02:19,981 --> 00:02:20,341
let's say,

54
00:02:20,341 --> 00:02:22,200
to fund this educational,

55
00:02:22,550 --> 00:02:23,383
um,

56
00:02:23,520 --> 00:02:23,790
um,

57
00:02:23,790 --> 00:02:24,623
endeavor,

58
00:02:24,630 --> 00:02:28,140
then I would not only have to worry about
how to design the educational system,

59
00:02:28,141 --> 00:02:31,470
but then I'd have to worry about how to
spend that money and shepherd that money

60
00:02:31,471 --> 00:02:32,370
intelligently.

61
00:02:32,610 --> 00:02:37,110
And that's actually a huge administrative
problem of sufficient magnitude to

62
00:02:37,111 --> 00:02:39,510
stop you from doing any
creative thinking at all.

63
00:02:40,260 --> 00:02:44,490
So what we're doing instead is I'm funding
the university project at the moment

64
00:02:44,491 --> 00:02:49,491
or the online education project as a
consequence of my patriot and funding car.

65
00:02:50,640 --> 00:02:52,710
Fixed that in about
five seconds this time.

66
00:02:53,250 --> 00:02:53,710
So,

67
00:02:53,710 --> 00:02:54,543
um,

68
00:02:55,640 --> 00:02:56,210
okay.

69
00:02:56,210 --> 00:02:59,710
I'm finding that from my Patriot patrion
donations and I like that better.

70
00:03:00,130 --> 00:03:01,150
The only problem is,

71
00:03:01,151 --> 00:03:04,600
is that I would like to offer the people
that I have his employees a certain

72
00:03:04,601 --> 00:03:06,070
amount of financial stability.

73
00:03:06,430 --> 00:03:07,200
And so,

74
00:03:07,200 --> 00:03:07,871
and you know,

75
00:03:07,871 --> 00:03:10,990
it isn't obvious to me how
stable the Patriot on funding is,

76
00:03:10,991 --> 00:03:12,700
although it's been very stable so far.

77
00:03:12,701 --> 00:03:13,301
But you know,

78
00:03:13,301 --> 00:03:14,950
who knows how that will work out.

79
00:03:14,951 --> 00:03:19,951
So I think what we're going to do is to
crowd fund in October or November once

80
00:03:21,311 --> 00:03:23,590
we have a minimal viable product.

81
00:03:23,920 --> 00:03:28,180
And I think I'd rather do that than
raise money privately anyways because I

82
00:03:28,181 --> 00:03:31,630
don't want this project
to be beholden to anyone.

83
00:03:31,960 --> 00:03:36,790
And I wanted to maintain control over
its direction with a small group of

84
00:03:36,791 --> 00:03:37,480
programmers.

85
00:03:37,480 --> 00:03:37,751
You know,

86
00:03:37,751 --> 00:03:41,200
it's often a small group of people who
are working tightly together that solve

87
00:03:41,201 --> 00:03:42,520
very complicated problems.

88
00:03:42,520 --> 00:03:44,470
And that's certainly been
the case with working.

89
00:03:44,471 --> 00:03:48,460
Say with Daniel Higgins and Robert Peel
on the self authoring programs and so

90
00:03:48,461 --> 00:03:49,090
forth.

91
00:03:49,090 --> 00:03:49,930
Small team.

92
00:03:50,230 --> 00:03:50,591
We've,

93
00:03:50,591 --> 00:03:54,190
we've thought about going the venture
capital route and expanding and trying to

94
00:03:54,191 --> 00:03:55,360
make a big business out of it.

95
00:03:55,361 --> 00:03:57,070
But our sense was more that,

96
00:03:57,670 --> 00:03:58,990
and maybe we were wrong about this,

97
00:03:58,991 --> 00:04:02,830
but that was better to go directly after
customers and to build the business

98
00:04:02,831 --> 00:04:07,831
incrementally and to test it along
each step and not to get enticed by the

99
00:04:08,021 --> 00:04:10,120
possibility of Unicorn level money.

100
00:04:11,050 --> 00:04:11,883
And so,

101
00:04:12,180 --> 00:04:12,820
um,

102
00:04:12,820 --> 00:04:13,653
anyways,

103
00:04:14,290 --> 00:04:14,980
that's the,

104
00:04:14,980 --> 00:04:16,210
that's the situation there.

105
00:04:16,211 --> 00:04:19,060
And I've got three really
bright people working on this,

106
00:04:19,470 --> 00:04:20,303
um,

107
00:04:20,680 --> 00:04:24,790
open educational platform and
it's really quite exciting.

108
00:04:24,791 --> 00:04:25,431
And I would say we're,

109
00:04:25,431 --> 00:04:28,480
we're well ahead of schedule
from where I thought we would be.

110
00:04:28,720 --> 00:04:30,310
So that's pretty cool.

111
00:04:30,700 --> 00:04:34,720
Have you spoken to Nassim to lab
following your brief Twitter exchange?

112
00:04:34,750 --> 00:04:36,760
We'd love to hear a conversation
with the two of you.

113
00:04:36,910 --> 00:04:38,620
I'd like to talk to him
too because he's very,

114
00:04:38,621 --> 00:04:39,340
very smart.

115
00:04:39,340 --> 00:04:40,090
He's a,

116
00:04:40,090 --> 00:04:43,690
he's touchy though and so I have
some apprehension about that.

117
00:04:43,691 --> 00:04:43,880
I've,

118
00:04:43,880 --> 00:04:47,500
I've talked to lots of touchy people over
the last couple of years and I'm a bit

119
00:04:47,501 --> 00:04:48,340
apprehensive about it,

120
00:04:48,341 --> 00:04:49,390
but I would like to do that.

121
00:04:49,600 --> 00:04:51,430
There's a lot of people
I'd like to talk to.

122
00:04:51,760 --> 00:04:54,160
He's one of them and you know,

123
00:04:54,161 --> 00:04:54,610
it's,

124
00:04:54,610 --> 00:04:57,670
I'm having a hard time setting up those
conversations at the moment because I'm

125
00:04:57,671 --> 00:04:58,690
doing so much touring.

126
00:04:58,900 --> 00:05:03,490
I am talking again to Jonathan Heit
though in the near future and I think

127
00:05:03,491 --> 00:05:05,680
probably to Steven pinker as well.

128
00:05:05,980 --> 00:05:06,791
And by the way,

129
00:05:06,791 --> 00:05:08,410
for those of you who are wondering,

130
00:05:08,680 --> 00:05:09,513
um,

131
00:05:09,970 --> 00:05:11,710
I am going to release the,

132
00:05:12,070 --> 00:05:13,210
and so is Sam.

133
00:05:13,211 --> 00:05:18,211
We're going to release the videos
from the Sam Harris Peterson debates.

134
00:05:19,110 --> 00:05:19,720
Um,

135
00:05:19,720 --> 00:05:21,250
I'll put them on my youtube channel.

136
00:05:21,250 --> 00:05:21,571
Sam,

137
00:05:21,571 --> 00:05:22,600
we'll put them on his will,

138
00:05:22,601 --> 00:05:24,280
make them into podcasts as well.

139
00:05:24,580 --> 00:05:28,510
I'm going to release the first
one on September 1st and uh,

140
00:05:29,020 --> 00:05:30,760
and everyone will have access to it.

141
00:05:30,940 --> 00:05:31,420
Um,

142
00:05:31,420 --> 00:05:34,240
it's taken us a while to figure
out exactly how to do this,

143
00:05:34,241 --> 00:05:37,840
partly because Travis Pangbourne who
hosted the events wanted to raise some

144
00:05:37,841 --> 00:05:39,550
money with the videos,

145
00:05:40,720 --> 00:05:45,460
at least in part to help offset the
costs that he incurred for those events,

146
00:05:45,461 --> 00:05:47,080
which were very expensive,

147
00:05:47,170 --> 00:05:47,951
believe it or not,

148
00:05:47,951 --> 00:05:51,700
and difficult to generate a
profit for from on his end.

149
00:05:52,170 --> 00:05:53,003
Um,

150
00:05:53,170 --> 00:05:58,170
and also he wants to translate the
material that he already has into multiple

151
00:06:00,201 --> 00:06:00,741
languages.

152
00:06:00,741 --> 00:06:03,370
So we agreed to let him win.

153
00:06:03,410 --> 00:06:05,180
We had to make a three
way agreement for this,

154
00:06:05,181 --> 00:06:05,391
you know,

155
00:06:05,391 --> 00:06:07,430
because Sam was involved
and I was involved in,

156
00:06:07,431 --> 00:06:08,750
so it was Pangbourne and so,

157
00:06:09,170 --> 00:06:11,090
and we didn't know how
the events would go,

158
00:06:11,091 --> 00:06:11,421
you know,

159
00:06:11,421 --> 00:06:14,810
so we weren't actually that concerned
with the damn videos to begin with because

160
00:06:15,170 --> 00:06:15,681
we take,

161
00:06:15,681 --> 00:06:16,270
uh,

162
00:06:16,270 --> 00:06:16,670
we,

163
00:06:16,670 --> 00:06:17,250
we'd take an,

164
00:06:17,250 --> 00:06:17,720
uh,

165
00:06:17,720 --> 00:06:18,553
a risk,

166
00:06:18,620 --> 00:06:20,360
I'm not complaining about this by the way,

167
00:06:20,450 --> 00:06:21,810
like I'm not complaining
about taking risks,

168
00:06:21,860 --> 00:06:23,290
but we didn't salmon,

169
00:06:23,300 --> 00:06:24,410
I hadn't even met,

170
00:06:24,411 --> 00:06:24,651
you know,

171
00:06:24,651 --> 00:06:27,290
we didn't know if we were going to have
conversations that were worthwhile.

172
00:06:27,290 --> 00:06:29,570
We didn't know if anybody
would show up for the events.

173
00:06:29,840 --> 00:06:32,870
And so we were way more concerned about
whether or not we'd get a crowd of any

174
00:06:32,871 --> 00:06:33,261
sort,

175
00:06:33,261 --> 00:06:37,040
whether the events would be successful
and whether we could actually talk then

176
00:06:37,160 --> 00:06:40,010
what we would do with the videos if the,

177
00:06:40,190 --> 00:06:43,100
or even if there would be videos
if the events were successful.

178
00:06:43,520 --> 00:06:47,360
And so it turned out that we couldn't
talk and we did have useful discussions.

179
00:06:47,361 --> 00:06:48,470
At least we thought so.

180
00:06:48,710 --> 00:06:52,550
And the audiences responded very well
and there was large crowds and so it was

181
00:06:52,551 --> 00:06:53,151
successful.

182
00:06:53,151 --> 00:06:55,340
So then it turned out that
the videos were worthwhile,

183
00:06:55,341 --> 00:07:00,341
but we hadn't discussed who had control
over the videos or who was going to edit

184
00:07:01,221 --> 00:07:02,330
them or any of those things.

185
00:07:02,331 --> 00:07:05,240
And we had to do that
post hoc after the fact,

186
00:07:05,241 --> 00:07:06,620
which isn't the best way of doing it.

187
00:07:07,160 --> 00:07:11,690
And then it took Travis a while to
assemble a team to do the actual editing.

188
00:07:11,691 --> 00:07:14,030
And so that was our compromise.

189
00:07:14,060 --> 00:07:15,110
And you know,

190
00:07:15,140 --> 00:07:18,620
it would've been better if we could
have released the videos and all of that

191
00:07:18,710 --> 00:07:20,150
immediately after the talks.

192
00:07:20,151 --> 00:07:21,350
But you know,

193
00:07:21,710 --> 00:07:24,920
when you're doing something new and you
don't know exactly what you're doing,

194
00:07:25,130 --> 00:07:26,720
you're not going to do it perfectly.

195
00:07:27,080 --> 00:07:29,390
And so we didn't do that perfectly,

196
00:07:29,391 --> 00:07:31,220
but the events were good.

197
00:07:31,221 --> 00:07:34,820
And I enjoyed talking to Sam and I
learned a lot from the discussion.

198
00:07:34,821 --> 00:07:36,380
I really had to sharpen my thinking.

199
00:07:36,381 --> 00:07:37,820
I really figured out something,

200
00:07:37,821 --> 00:07:38,091
you know,

201
00:07:38,091 --> 00:07:43,091
I figured out that I think the
fundamental issue here is how you take the

202
00:07:43,251 --> 00:07:46,760
infinite world of facts
that presents itself to you,

203
00:07:47,690 --> 00:07:49,820
independent of the value of those facts.

204
00:07:49,821 --> 00:07:54,380
So value neutral facts and they have
to be filtered to a single point,

205
00:07:54,560 --> 00:07:57,950
like a single point of perception because
you have to point your eyes at one

206
00:07:57,951 --> 00:08:01,130
thing and your attention at one
thing and a single point of action.

207
00:08:01,430 --> 00:08:06,430
And so there's a tremendous reducing of
the world of fact to the extraordinarily

208
00:08:07,550 --> 00:08:11,060
simple and targeted rule
of Vail or world of value.

209
00:08:11,510 --> 00:08:12,500
And your,

210
00:08:12,650 --> 00:08:17,330
your brain is the instrument that
does that reducing and it's sort of,

211
00:08:17,900 --> 00:08:21,980
it's in keeping with Elvis Huxley's
suppositions about that and they were

212
00:08:21,981 --> 00:08:26,981
motivated by Henri Bergson the idea that
the brain was a reducing valve and that

213
00:08:27,021 --> 00:08:30,350
what psychedelic experience did
was open the doors of perception.

214
00:08:30,500 --> 00:08:32,300
Something William Blake also talked about.

215
00:08:32,990 --> 00:08:37,990
The brain seems to be in some sense the
part of the structure that reduces the

216
00:08:38,001 --> 00:08:42,950
infinite complexity of the world of facts
to the finite and single point domain

217
00:08:42,951 --> 00:08:44,030
of world of values.

218
00:08:44,270 --> 00:08:48,560
And that's partly neurologically
instantiated and partly sociologically

219
00:08:48,561 --> 00:08:52,340
instantiated become as we
come to a negotiated agreement
about what constitutes

220
00:08:52,341 --> 00:08:52,940
value,

221
00:08:52,940 --> 00:08:56,010
just like we do about what
constitutes economically.

222
00:08:56,310 --> 00:09:01,310
And so the structure that reduces facts
to values is a reducing structure that's

223
00:09:02,791 --> 00:09:06,000
similar caneously and Stan Shealy
instantiated neurologically and

224
00:09:06,001 --> 00:09:06,960
sociologically.

225
00:09:07,320 --> 00:09:10,470
And I understand that a lot more clearly
because I had these discussions with

226
00:09:10,471 --> 00:09:13,050
Sam and I'm writing a lot
about that in this next book,

227
00:09:13,410 --> 00:09:15,530
which is it's a followup.

228
00:09:15,531 --> 00:09:19,650
I s I suspect that's the plan at the
moment to 12 rules for life because I had

229
00:09:19,830 --> 00:09:21,330
written originally 40 rules,

230
00:09:21,331 --> 00:09:22,620
so I have more to go.

231
00:09:22,740 --> 00:09:26,790
I've written about half of the new book
and I spent a lot of time writing about,

232
00:09:26,791 --> 00:09:30,870
at least in part what I had to become
clearer about as a consequence of my

233
00:09:30,871 --> 00:09:32,010
discussions with Harris.

234
00:09:32,280 --> 00:09:36,320
And so I took a look at the videos and
I think the debates were productive and,

235
00:09:36,360 --> 00:09:37,950
and their audiences seem to find them.

236
00:09:37,951 --> 00:09:38,251
So,

237
00:09:38,251 --> 00:09:39,320
and certainly salmon.

238
00:09:39,330 --> 00:09:39,721
I did,

239
00:09:39,721 --> 00:09:41,280
I really enjoyed meeting him.

240
00:09:41,281 --> 00:09:42,270
We got along quite well.

241
00:09:42,271 --> 00:09:45,960
He has much better sense of humor
than I presumed from listening.

242
00:09:45,961 --> 00:09:46,171
Well,

243
00:09:46,171 --> 00:09:47,550
from the two podcasts we did.

244
00:09:47,550 --> 00:09:47,851
Of course,

245
00:09:47,851 --> 00:09:49,950
I wasn't in great humor
when I did those either.

246
00:09:50,370 --> 00:09:51,203
Um,

247
00:09:51,510 --> 00:09:52,380
and you know,

248
00:09:52,381 --> 00:09:54,780
I also think that I'm also,

249
00:09:55,020 --> 00:09:58,650
what would you say I'm a
fan of Sam's motivation?

250
00:09:59,000 --> 00:09:59,340
Uh,

251
00:09:59,340 --> 00:10:01,410
or at least as far as
I could determine it.

252
00:10:01,440 --> 00:10:01,651
I mean,

253
00:10:01,651 --> 00:10:05,610
he wants to ground the world of value
in something that isn't merely arbitrary

254
00:10:05,611 --> 00:10:06,444
revelation.

255
00:10:07,050 --> 00:10:08,190
And Fair enough,

256
00:10:08,191 --> 00:10:08,521
man,

257
00:10:08,521 --> 00:10:09,354
that's a good,

258
00:10:09,570 --> 00:10:14,570
that's a good aim to ground ethics and
something that's solid and not just

259
00:10:15,931 --> 00:10:16,980
arbitrary opinion,

260
00:10:17,220 --> 00:10:19,320
but I think that the
devil's in the details.

261
00:10:19,321 --> 00:10:21,780
And so that's basically what we discussed.

262
00:10:22,050 --> 00:10:22,591
So,

263
00:10:22,591 --> 00:10:22,950
um.

