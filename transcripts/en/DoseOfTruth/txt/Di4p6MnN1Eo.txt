Speaker 1:          00:11          Thank you for coming. I appreciate it a lot. Uh, I wanted to get your opinion on censorship they were seeing on the web. Uh, it's accelerating. You are a very notable example. You were locked out of your Gmail and Indian Trump account. Pardon me? Oh yeah. Trump just got a deleted by an air in person, you know, now they're saying that perhaps this was just a contractor and you know, maybe, uh, someone from Twitter who's gone in a very far left direction, uh, youtube has gone in a very far left I erection. Uh, I'm just wondering, I've started a, an alternative to youtube called Pew Tube. Uh, what kind of, um, what, what do you see for possible solutions and just your thoughts in general?

Speaker 2:          00:56          Here's an, it's a crazy thought, but I'm going to tell it to you anyways. So I was just reading one of Ray Kurzweil's books, I think it was called, how to make a mind. I really liked it actually. It helped me understand how the brain compresses information because the world is really complicated day, so you have to make a low resolution representation of it to live in it. And he actually explained to me in a way that I hadn't really understood how the brain might do that neurologically. So that was cool. But you know, Kurt swells this guy who thinks that he's a smart guy, a very smart guy and uh, he's invented a fair bit of high end technical technological software and hardware and he's the guy that thinks that we're heading towards the singularity. And so the singularity is, you know how processing speed doubles every 18 months and like hard disk capacity every year and there's a bunch of doublings going on, a huge number of them and they accelerate exponentially.

Speaker 2:          01:53          And so it's probably, we're probably three years away, maybe even less then from building a computer that has, is the capacity to make as many calculations as reasonable estimates of the calculating capacity of the human brain are currently set up 18 months away, two years away, something like that. And then we're 18 months away from having one. That's twice that fast and then 18 months away from having one. That's twice as fast as that. So that's like say six years and then we've got something that's eight times as smart as a human being. But there's a twist on that. And this is Kurt swells twist, which is as soon as you make a machine smart enough to make the next machine that's smarter than it, which is sort of what we're doing because computers are so fast that that will scale up to near infinite computing power computing power almost instantaneously.

Speaker 2:          02:47          Now, let me think. No, probably not. And Alan Gates partner has written critiques of Kurtzweil and you know, you might think if something's impossible it won't happen. Even if you don't know why. And there's reasons to, to not think that that will happen. But Kurzweil's trace back the doubling of computing power way before the existence of the transistor and it's been ridiculously stable, crazily stable. So God only knows what we're coming up with here. You know, and you don't know what something of infinite computing power might be like, like you seriously don't know. And there are serious people who are very, very, very worried about that. They're very worried, for example, that companies like Facebook and Google will manage that first. And you know, those companies are already making censorship AI bots and that's not that smart. It's sort of like making really fast robots that can shoot people.

Speaker 2:          03:43          It's not that smart. And we're doing that to very rapidly. And you know, I know some guys who work in advanced AI and you know how you look, you watch the term terminator movies and you see the robots that miss when they shoot at you. Like they're not very bright because the bright ones not only shoot at where you are, but they estimate where you're going to be when you make your escape moves and they shoot their simultaneously and their death rate is 100% and so there's no war against the robots. I mean, when those things get going, they're going to be so much faster than us that will look like we're moving through molasses to them.

Speaker 3:          04:17          So

Speaker 2:          04:22          you know, so maybe what we're deciding now with all of our individual decisions about censorship and the way that we're going to construct the world and all that is exactly what kind of super intelligence we're going to bring into being. And I would suggest that we try to bring one in that's good and moral rather than one that's evil and demonic, right? So what can we do about that?

Speaker 3:          04:48          The,

Speaker 2:          04:49          there's only one answer to that. As far as I know that that works is gay rock together. You're going to be the person who's working in Ai, right? I know some of these people, they better be good people because they're going to build whatever they're like into their machines. They better have their head screwed on straight because they're going to get amplified like mad. And I don't like what's happening with Google and Facebook and Youtube, they're building censorship bots predicated on a certain kind of ideology, the kind of ideology that we outlined today. It's a very bad idea. Hopefully good people will stop that. So then that, what that means is that your moral obligation is to be good. And the way you do that is first by stopping being bad. And everyone can do that a little bit. So I hope that's what everyone does because the consequences of not doing it are not going to be pleasant. They never are.

Speaker 3:          05:51          Thank you.