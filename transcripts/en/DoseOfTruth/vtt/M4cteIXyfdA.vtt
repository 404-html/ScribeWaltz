WEBVTT

1
00:00:07.650 --> 00:00:07.861
<v Speaker 1>Yeah,</v>

2
00:00:07.861 --> 00:00:10.050
<v Speaker 1>well I was also really interested at the time,</v>

3
00:00:10.051 --> 00:00:10.321
<v Speaker 1>man,</v>

4
00:00:10.321 --> 00:00:13.050
<v Speaker 1>now in the biological basis of behavior.</v>

5
00:00:13.080 --> 00:00:13.381
<v Speaker 1>Right.</v>

6
00:00:13.381 --> 00:00:13.831
<v Speaker 1>And so,</v>

7
00:00:13.831 --> 00:00:14.040
<v Speaker 1>and,</v>

8
00:00:14.040 --> 00:00:14.880
<v Speaker 1>and in the,</v>

9
00:00:15.460 --> 00:00:15.990
<v Speaker 1>uh,</v>

10
00:00:15.990 --> 00:00:19.860
<v Speaker 1>in the relationship between fundamental motivational systems and thought because</v>

11
00:00:20.250 --> 00:00:24.660
<v Speaker 1>obviously our thought is grounded in fundamental motivational systems and your</v>

12
00:00:24.661 --> 00:00:27.690
<v Speaker 1>work on disgust with maybe you can tell the viewers a little bit about,</v>

13
00:00:28.110 --> 00:00:31.980
<v Speaker 1>was really interesting to me because it was an emotional system that hadn't been</v>

14
00:00:31.981 --> 00:00:32.731
<v Speaker 1>studied much.</v>

15
00:00:32.731 --> 00:00:32.971
<v Speaker 1>I mean,</v>

16
00:00:32.971 --> 00:00:34.800
<v Speaker 1>you were really one of the pioneers in the,</v>

17
00:00:34.801 --> 00:00:36.600
<v Speaker 1>in the psychological study of disgust.</v>

18
00:00:36.830 --> 00:00:36.970
<v Speaker 2>Well,</v>

19
00:00:36.970 --> 00:00:38.710
<v Speaker 2>the way to explain it is that Paul Rosin,</v>

20
00:00:38.740 --> 00:00:42.310
<v Speaker 2>my advisor at Penn is the pioneer in this study of disgust.</v>

21
00:00:42.311 --> 00:00:45.610
<v Speaker 2>And he'd studied it as a food related emotion and he'd written a bit about it</v>

22
00:00:45.611 --> 00:00:46.690
<v Speaker 2>being a moral emotion.</v>

23
00:00:47.170 --> 00:00:52.170
<v Speaker 2>And I was a graduate student at Penn and I was interested in morality and I was</v>

24
00:00:52.361 --> 00:00:55.270
<v Speaker 2>reading the Bible and I was reading,</v>

25
00:00:55.310 --> 00:00:55.860
<v Speaker 2>um,</v>

26
00:00:55.860 --> 00:00:56.020
<v Speaker 2>uh,</v>

27
00:00:56.020 --> 00:00:59.170
<v Speaker 2>anthropological accounts of different countries and different cultures.</v>

28
00:00:59.470 --> 00:01:03.280
<v Speaker 2>And at the time morality was all about reasoning about harm,</v>

29
00:01:03.281 --> 00:01:04.240
<v Speaker 2>rights and justice.</v>

30
00:01:04.450 --> 00:01:06.910
<v Speaker 2>So Lawrence Kohlberg was the leading figure in the field.</v>

31
00:01:07.420 --> 00:01:10.150
<v Speaker 2>And because I was looking at morality across cultures,</v>

32
00:01:10.600 --> 00:01:11.433
<v Speaker 2>uh,</v>

33
00:01:11.530 --> 00:01:12.670
<v Speaker 2>and when you look across cultures,</v>

34
00:01:12.671 --> 00:01:15.190
<v Speaker 2>it's not just about fairness and Harmon rights,</v>

35
00:01:15.191 --> 00:01:19.730
<v Speaker 2>it's about menstruation and food taboos and skin lesions.</v>

36
00:01:19.731 --> 00:01:20.890
<v Speaker 2>And it's very physical.</v>

37
00:01:21.160 --> 00:01:21.521
<v Speaker 2>And I was,</v>

38
00:01:21.521 --> 00:01:21.761
<v Speaker 2>you know,</v>

39
00:01:21.761 --> 00:01:22.540
<v Speaker 2>why?</v>

40
00:01:22.540 --> 00:01:24.580
<v Speaker 2>Why does so many societies,</v>

41
00:01:24.790 --> 00:01:28.630
<v Speaker 2>why is it like the normal default way of being is to somehow bring the body into</v>

42
00:01:28.631 --> 00:01:29.020
<v Speaker 2>morality?</v>

43
00:01:29.020 --> 00:01:29.853
<v Speaker 2>Why is that?</v>

44
00:01:30.250 --> 00:01:33.970
<v Speaker 2>And so I just happened to be at Penn where the world's expert in disgust was and</v>

45
00:01:33.971 --> 00:01:37.360
<v Speaker 2>I went to talk to them and that started one of the best collaborations of my</v>

46
00:01:37.361 --> 00:01:38.194
<v Speaker 2>life.</v>

47
00:01:38.380 --> 00:01:40.600
<v Speaker 2>And what it led to is,</v>

48
00:01:40.601 --> 00:01:42.220
<v Speaker 2>is a broadening of the,</v>

49
00:01:42.250 --> 00:01:43.061
<v Speaker 2>of the moral domain.</v>

50
00:01:43.061 --> 00:01:48.061
<v Speaker 2>Basically there's a sort of a western secular approach that you see in western</v>

51
00:01:48.431 --> 00:01:49.264
<v Speaker 2>philosophers.</v>

52
00:01:49.650 --> 00:01:49.980
<v Speaker 2>I have,</v>

53
00:01:49.980 --> 00:01:54.670
<v Speaker 2>their morality is about harm and utilitarianism and let's minimize harm or it's</v>

54
00:01:54.671 --> 00:01:56.530
<v Speaker 2>about rights and principles,</v>

55
00:01:56.531 --> 00:01:56.711
<v Speaker 2>you know,</v>

56
00:01:56.711 --> 00:02:01.600
<v Speaker 2>manual con and a much better way psychologically I think about morality is</v>

57
00:02:01.601 --> 00:02:02.381
<v Speaker 2>virtue ethics.</v>

58
00:02:02.381 --> 00:02:03.640
<v Speaker 2>It's just a lot of stuff.</v>

59
00:02:03.670 --> 00:02:05.890
<v Speaker 2>It's just we have just a lot of stuff that we judge on.</v>

60
00:02:06.340 --> 00:02:10.960
<v Speaker 2>And this led me eventually to realize that people on the left and people on the</v>

61
00:02:10.961 --> 00:02:12.970
<v Speaker 2>right care about different stuff.</v>

62
00:02:13.150 --> 00:02:15.820
<v Speaker 2>Everybody cares about harm and fairness,</v>

63
00:02:16.270 --> 00:02:19.900
<v Speaker 2>but the stuff about keeping your boundaries around the group,</v>

64
00:02:19.960 --> 00:02:20.771
<v Speaker 2>it'll to wall,</v>

65
00:02:20.771 --> 00:02:21.970
<v Speaker 2>protect the group,</v>

66
00:02:22.180 --> 00:02:23.470
<v Speaker 2>hold the group together,</v>

67
00:02:23.590 --> 00:02:24.550
<v Speaker 2>hate traders.</v>

68
00:02:24.850 --> 00:02:25.151
<v Speaker 2>Um,</v>

69
00:02:25.151 --> 00:02:25.361
<v Speaker 2>you know,</v>

70
00:02:25.361 --> 00:02:26.470
<v Speaker 2>everybody can do that.</v>

71
00:02:26.680 --> 00:02:27.461
<v Speaker 2>But right.</v>

72
00:02:27.461 --> 00:02:32.461
<v Speaker 2>We morality built on these additional additional foundations of these additional</v>

73
00:02:32.561 --> 00:02:33.730
<v Speaker 2>emotions and foundations.</v>

74
00:02:34.020 --> 00:02:34.510
<v Speaker 2>Um,</v>

75
00:02:34.510 --> 00:02:37.360
<v Speaker 2>so that work on discussed that I was just beginning to talk about them when we</v>

76
00:02:37.361 --> 00:02:42.250
<v Speaker 2>first met in 1994 led eventually to what we now call moral foundations theory</v>

77
00:02:42.490 --> 00:02:46.150
<v Speaker 2>and with might with that five or six colleagues that if you go to your</v>

78
00:02:46.151 --> 00:02:47.080
<v Speaker 2>morals.org,</v>

79
00:02:47.340 --> 00:02:47.560
<v Speaker 2>uh,</v>

80
00:02:47.560 --> 00:02:48.760
<v Speaker 2>you can take our test,</v>

81
00:02:48.761 --> 00:02:49.630
<v Speaker 2>you can learn all about it.</v>

82
00:02:50.110 --> 00:02:50.650
<v Speaker 2>Um,</v>

83
00:02:50.650 --> 00:02:53.410
<v Speaker 2>but it led to the perspective that ultimately was,</v>

84
00:02:53.710 --> 00:02:57.850
<v Speaker 2>I think the right perspective as the cultural war was heating up and as left and</v>

85
00:02:57.851 --> 00:02:58.540
<v Speaker 2>right,</v>

86
00:02:58.540 --> 00:03:00.940
<v Speaker 2>we're essentially becoming like different countries,</v>

87
00:03:00.941 --> 00:03:01.690
<v Speaker 2>different cultures.</v>

