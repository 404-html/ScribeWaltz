Speaker 1:          00:00          Welcome back to six zero, nine, nine artificial general intelligence. Today we have Mark Graber.

Speaker 2:          00:12          Thank you.

Speaker 1:          00:16          He is the. He really doesn't need an introduction, but we'll give him one. Anyway, he's the founder and CEO, CEO of Boston Dynamics. He founded the Cmu leg lab in 1980, the mit leg lab in 1986. Boston dynamics in 1992. He and his team have developed some of the most amazing robots ever built, including big dog atlas handle spots, spot many. These robots move with the agility, dexterity, and even grace that rivals and often supersedes that of human movement. He continues to inspire us with what robots are capable of achieving in the real world and what physical form future intelligence systems may take as they become integrated in our daily lives. So please give a warm welcome.

Speaker 2:          01:02          Thank you.

Speaker 3:          01:08          This is our grand mission or aspiration, which is to make robots that are equal to or greater than a people in animals. And it's, you know, it's a daunting mission because a, we're so good at things. It seems effortless. You know, I'm standing here. No one questions that I could stand here like this, but a lot's going on, I can manipulate things, I can pick up this water, I could reach in my pocket and use my hands with all the sensors in my hands and coordinate that and maybe most of all our perception systems, you know, there's audience has, what is it, 250 people in it or something. And I can look out there and see every one of you a stabilized in space even while I'm moving. It's a, it's just astounding. And the, you know, robots aren't there yet, but I think they can be.

Speaker 3:          02:00          And uh, our goal is to keep chipping away, uh, to try and get there. Before I get started, I wanted to say that I got my start in robotics, uh, here at Mit. I was a graduate student. I was in the, what was then called the psychology department, the brain and cognitive sciences department. But I was taking an iap course just like you are. And it might've been a, you know, exactly this time of year when I followed one of my professor burt told Horn back, I had, I was jabbering away at him asking him some questions about this or that. And we walked back to tech square, which is where the AI lab was in those days. And uh, we went up to the ninth floor and Russell Oscar, who was a guy working in the lab, had an arm all taken apart on the table.

Speaker 3:          02:47          It was like a thousand pieces. And I was a roboticist from that day on. I swear I didn't switch my major by, uh, you know, got bertold to be an advisor. I found a topic that had to do with robotics in that time. It was a manipulation thing, but eventually became legged, uh, thing. And uh, it was amazing, you know, and, uh, I've never looked back. So, um, here are some animals doing things that are a very exciting climbing around on very rough terrain. A very sure footed, using a mixture of their proprioception and their vision. And look, there's even a baby that probably is only a couple of months old, has no trouble at all doing these things. And a look at the grace and suppleness and, uh, the fearlessness of, uh, of these animals. It's amazing here are animals running for their lives. Uh, the Gazelle is trying to stay alive for the next 10 minutes and the cheetahs trying to get a meal so that it can stay alive in general.

Speaker 3:          04:00          And uh, you know, even people can do things, uh, that are breathtec. I assume all of you were out this morning getting a little exercise, climbing up the green building that we're in now. And then maybe the other places around here. It's funny, I had bumped into some people when I came into the room who were climbing the stairways, I think that were going on a trek up and down them. But I'd like to see the going outside. So probably most of you have seen this video. This is a, this is sort of where we were after about 10 years of work thing to make machines that could work out in the real world that we're dynamically stabilize dynamics is a big deal for our company and for what we do. So, uh, some active sensing and control and understanding of the physics. Um, here's, this robot has all this control on board and it has reflexes and sensors and this is an extension a to a thousand pound robot that could carry about 400 pounds of payload. And we took it all around the United States, testing it, uh, in various situations. Uh, here we have it in Virginia doing some bushwhacking. It's actually following a person, but the person is only in that have you intermittently. So it has to be able to keep track of where the person is and a deal with that. And then back in good old Boston, 10 inches of snow just marches right up the hill.

Speaker 3:          05:30          Here's the Cheetah. And now you know, mit has its own cheetah. This is our cheetah. Uh, the people, no Song Bay who's doing the Mit Cheetah, um, a very dynamic machine and basically an experiment and seeing how fast we could make something like this run, although you notice it's on a parking lot, so it wasn't doing this on rough terrain and getting both efficiency and the speed in, in the context of machine they'd also can do rough terrain is a really big challenge that remains with us. So this is just a snapshot of a most of the robots that we built at Boston dynamics over the years. And uh, I'm not going to talk about most of them. I'm just going to talk about the last four. Uh, these are all robots that we developed since we'd been part of Google, which has been the last four years.

Speaker 3:          06:25          A spot many. There's a spot on the floor here which we'll demo the later spot. Atlas, the humanoid. Some of you may remember the humanoid that we used in the Darpa robotics challenge. You have one here and uh, and then handle it, which is our latest version. So I'll say a few words to say about each of them. So we had been developing a big dog and those other quieter peds that I showed you for quite some number of years and it was amazing for us to find out when we did this project on a spot, this is the predecessor to that, that there was still a lot to learn and we kind of revolutionize the hardware design and how the control worked and got a much higher level of rough terrain performance. And part of the solution to that was to be able to decompose the control problem into a many separate controllers that operated in different regions of state space.

Speaker 3:          07:22          Uh, and that allowed us both to have programmers work on multiple solutions to the problem. I'm a and also have the complexity of each controller is simplified by only having to operate in a small part of the dynamic space here. We've added a robot arm to the, to the previous version of spot. Um, and uh, you know, we believe that mobile manipulation that is manipulation when you can move the base is really a powerful, a way of doing things. Now, this is probably the most important thing I want to show tonight and I'll show it three different times, the idea that we don't build controllers that just do one particular thing, but that they can determine where they are in the execution, here's another version of it, and then adjust what they're doing in order to compensate for disturbances in the real world. I know this class is about ai and probably autonomy.

Speaker 3:          08:22          Um, I think that the, one of the most important ways of getting to autonomy is to have the low level implementation's very robust to disturbances so that the planning steps don't have to take care of all the minutia of the details of the real world. And that's what we've been trying to do there. Um, we've been experimenting with doing delivery of packages to people's houses. These are all employees of Boston dynamics, so we didn't go crashing a ordinary people's houses. And, uh, it turns out that there's just lots of different kinds of stairways and interests ways. Um, and uh, uh, the robot's doing very well. We're up to something between 70 and 80 percent of, uh, of the kinds of, uh, stairs and access places we, uh, encounter, um, after collecting data and making a improvements and adjustments.

Speaker 3:          09:20          So I'm going to say a few philosophical things or approach things. Um, a lot of people think that this is the model of how a computer and a robot interact. That is, there's the robot, uh, which is hardware and electronics and sensors and, uh, and then there's a computer and that the computer, I'm listens to the sensors on the robot and then gives it instructions and tells it what to do. And while I think that's actually going on, there's another part to the story which is that the physical world is also giving instructions to the robot. And that means that the energy's stored in the robot, either in its springs or in. It's a, uh, it's motion. Those are all important determinants of how the robot is going to behave, uh, in the time coming forward. And so we like to think in terms of designing the hardware of the robot, the physical world, and the computer all as one holistic thing where we take into account the, those interactions.

Speaker 3:          10:28          Sometimes we call this a harmony, you know, a harmonic system is one usually where you have energy oscillating back and forth. Almost all legged locomotion has some amount of a harmony going on between potential energy of elevation, potential energy of elastic deformation, kinetic energy of motion, and, uh, you know, inverted pendulum things. And, and the like, uh, another part of our approach we call build it, break it, fix it. Now I have friends who build their robots and are so into the, the beauty of what they've created that they kind of put it on an altar and afraid of actually hurting it. Uh, so, uh, and in fact, I even have friends here at mit that have done that where they have a goal, play that robot and uh, they're afraid of taking it out into the world. I mean, we're just the opposite. Uh, every one of our robots is designed to get bashed the bits.

Speaker 3:          11:30          We have staff who are there to fix the robot on a daily basis, uh, as we break it. And I think doing that build a break it fix it means that we're able to learn a lot from the actual physical robot working in the world and uh, we can use that knowledge in order to improve the robot, improve it's behavior and uh, we really like to go around that loop as quickly and as we can early in the, in the process and do it as many times as we can. So here's what build a break it fix. It looks like a, this is in Somerville, our engineers. This is, I'm a Boston driver. Yeah. This robot's supposed to be using his visual system to avoid the trees. I think it might've fallen in love with this tree. We don't purposely give them any emotion, but boy, it's hard not to see that. And here's the first time we tested the pusher response to this robot.

Speaker 3:          12:55          Did you hear that? That's the new guy's car. So some guy who just started that week trend a have $5,000, which we paid for, uh, in, in repairs to his vintage BMW. So the last thing sort of about philosophy is long term versus short term. Uh, you know, our company is 25 years old and we've mostly been a longterm a robotics company that is, we're interested in moving the boundary forward in what robots can do and we're interested in, you know, making it so robots meet the dream of being the equal or better than people in animals.

Speaker 2:          13:38          But now we've started function doesn't break.

Speaker 3:          13:53          Okay, got it. We still on. Can you hear me? Um, but uh, lately we've started to realize that some of our robots have enough capability that maybe it's time to try and productize them and we will learn a lot by doing that to. One of the things, for instance, that I've always claimed a, is that we always spent a lot of money on building our robots in them and use that as a competitive advantage. That is, Darpa was a frequent funder of us. Darpa always said, let's take money out of the equation and just figure out, um, uh, you know, how to get the solution and then worry about getting the cost down later. So I always assumed and argued that once we get a robot doing things that are interesting, then you can go and redesign it to make it a lower cost. While we're going, we're going to test that because it might not be true.

Speaker 3:          14:46          It might be that we've designed ourselves into inexpensive coroner and, uh, that it might be too late, but, uh, the robot that will show in a little bit is much significantly cost reduced from the prototype event. And it'll be interesting to see whether we could get it down to the kind of prices that are useful. So this is just a picture again, of the idea of aiming long but also aiming short and I think it's going to be a challenge to see whether we can keep the culture of the company to support both of these directions because people manufacturing stuff have a different mindset than people trying to get out to the future horizons. And, uh, it's gonna be a challenge to keep both those kinds of people are happy.

Speaker 3:          15:34          Here's some of the things that, uh, uh, some of the kinds of applications you can look at, uh, based on, um, modest, a technical capabilities I've shown mobility and manipulation here, but you could put cost, reliability. There's many things that could be on these axes, you know, entertainment like robots and theme parks is something that I think we should be able to do. I already talked about home delivery. I think home delivery is waiting for self driving cars to get all the way they are self driving trucks. And once they do, then we will be working on getting it from the truck to the, to the home. Um, logistics, um, there's about a trillion boxes moved every year around the world and most of it's done by hand. And so there's really a big opportunity to having robots help with moving those trillion box's security, which could mean either commercial security, like patrolling your shopping center or the military type security, a construction.

Speaker 3:          16:39          A lot of people have been coming to us with their construction applications, a asking if we can help and, you know, I'm not going to talk about it now, but if afterwards you want to ask about that, I can fill you in a little more. And I think this is really the ultimate, a home run application, a care for the elderly and the disabled. Um, I used to say that I wanted to have robots that would help me take care of my, uh, my parents and uh, uh, older people. But I realize now that it's probably going to be my children using them to help take care of me. But you guys are, you're all a little bit younger and I think, uh, uh, there'll be a time when, uh, you could use robots to help make your parents' lives better. Now, some of you may think that your parents don't want that, but, uh, I think it's a complex question.

Speaker 3:          17:31          We've seen some surveys that say that, you know, people aren't totally happy with the idea of their kids taking care of them on a moment by moment basis. And, uh, I think there's going to be an opportunity for doing something, but technically this is still a ways off. It's, it's a tough thing. Okay, let's get back to the robots. Um, spot mini is a robot that weighs about 60 pounds that previous spot weight about 180 pounds. This one weighs about 60 pounds. Um, and uh, here's some anatomy. It's got an arm with a five degrees of freedom. Each leg has three degrees of freedom.

Speaker 3:          18:09          It's got about a 500 watt hour battery batteries for these things are challenged because, you know, uh, you can have consumer products like electric drills that have relatively small batteries. And then there's electric cars that had big batteries and there's not really much available in between. So we've done a lot of work on the battery technology for these things to make the safe and reliable and hot swappable and things like that. Uh, then there's radios and computers. Uh, the previous version had three quad core, I seven [inaudible]. This one has two. We're trying to cut back on the cost and then there can be some sensors, lidars stereo and the like. So you can see spot man, he's a little bit smaller than spot.

Speaker 2:          19:05          Um,

Speaker 3:          19:06          this isn't a real house and those aren't real people. Those are engineers. Um, this is a inside of a warehouse we have out on one slash 28 where we've built the house. You can see that they don't, we don't mind scuffing up the walls here and there is a lot of scuffing that happens. Some of you may recognize active Koski who is a, uh, an mit alum and he's again disturbing the robot here, the robots using its vision to do some stepping stone type operations. And I think gene is going to talk a little bit more about this in a couple of minutes. And here's a case where it's doing stepping stones on real stones and it's keeping its balance, figuring out where to put the feet. Um, and again, this robot only has stereo looking out the front, whereas this one has a stereo on all four sides.

Speaker 3:          20:03          Now, one of the cool things about animals is that they have these stabilization mechanisms for their sensors. That was a real chicken, no robotics involved and here's our attempt to show that these, this robot can do the same sort of thing and if you think about it, when you're manipulating, you really want the hand to be stabilized in space and so you'd like the body to be able to kind of coordinate with the hands so that you can concentrate on what the world real world task is. A man, you guys didn't pick up the banana peels, Huh?

Speaker 3:          20:49          So our concept for the spot many product is to make a platform. It's sort of the, we're thinking of it like the android of robots. So with android there's a hardware platform and then there's a software platform and then a developer's third party developers create their own apps that use the platform. So we've made this spot so that there's a place to mount hardware on the robot, but there's also an API to program it through. And then there's a facility to have additional computing external to the robot. And we're working with third parties to develop their own applications that run on the platform.

Speaker 2:          21:34          Um,

Speaker 3:          21:35          this is a video that, uh, we haven't been able to release publicly. Please don't tape it and show it,

Speaker 2:          21:42          um,

Speaker 3:          21:44          because I can't, I'll explain later if you want to know why not, but this is just a revealing that we do have an arm on the, on the new version of spot. It's using a camera in the hand to find the, the door handle. This robot doesn't weigh a lot, so it has to use tricks to keep the door open. So that's why he puts his foot in the door. And here again, we want to show that the, we've made the solution robust to certain kinds of disturbances. So Andy, there, andy sitting over here is a pushing on the door, pushing on the hand. The robot keeps track of how far, how much progress it's made in doing its task. It's so, it's so smart and even kicks that, uh, that shell out of the way. Now that was total accident and now it's just gone back to try again.

Speaker 2:          23:02          Okay.

Speaker 3:          23:05          Um, and then this is a demo of autonomy. A here are, the robot has a, in a previous session, we've taken it around the lab. This is Boston dynamics take into the realm of lab and recorded visual data that can be used for navigation and it's using its stereo to match up features in the environment so that they can navigate a Ngo, um, where it had gone in the previous, uh, on the previous path. So there's no one driving it for this. It's all a, uh, autonomous that was outside my office every day around noon. The robot seems to show, and I hear it pausing out there,

Speaker 3:          23:51          I don't know why it turned there as sometimes it comes up with a solution that isn't in here. You'll see another one that comes up with a solution that isn't cool, why, what call is an optimization, but it does, uh, it does get a solution. So we're pretty excited by this. We call this patrol route and we're working on developing a lot of software to support it, to make it so that other people can capture a patrol route and then execute them on a, on a routine basis, and then do the other tasks while they're on the, on the patrol route. Seth, you're on. So we're now we'll do a demo of a spot mini. So for this, for this demo, Seth Scott, a joystick and he's telling it the speed to go in the forward direction and turning, but the robots doing all its own, uh, gates selection, coordination of legs, balance obviously. So the robot has a bunch of different gates that can walk here. It's doing one leg at a time. Um, it can try it. I know you do whatever gets you on set.

Speaker 3:          25:19          He's got to use the selected yet. So here's trotting, which is diagonal pairs of legs. Um, it can do pacing, which is lateral pairs of legs to get working together. I have to tell you, in the earliest days of me being involved in legged locomotion, I thought gate was a big deal, but it's really kind of a small thing. Um, and I don't think it's central to what matters, which is support, stability, propulsion, and things like that. I'm going to wrap up shortly. I just thought I'd say a couple of words about the mechanical side. Uh, you know, the atlas is a new version of a humanoid. Uh, I know some of you worked with the Darpa robotics challenge, humanoid, uh, which was a big hulking thing that we made and this is a much more svelte one. And the way we got there was to uh, work on, uh, the elements of the mechanical design to take advantage of three d printing and, uh, uh, some optimization.

Speaker 3:          26:23          And we did, we focused on two or three different things. One is making some of the leg parts where we embed hydraulic pathways, hydraulic actuators, places for valve mounts and filters and things like that into the leg. And this is what that looks like. There's a single upper leg part that incorporated 15 or 20 different separate components in the previous design which made it lighter, more compact, and a higher strength to weight ratio. We also developed a hydraulic power unit, which takes many components. The thing on the left are the components as separate ones and we were able to print parts that integrated them so that there was a motor or a pump inside of a motor, an accumulator, a reservoir, valves, filters and those things, and we shrunk it down so that the robot could be smaller and lighter. And using that approach, we went from about a 375 pound DRC robot to a one 90 pound robot.

Speaker 3:          27:31          And then the current one is about a hundred and 65 pounds. Now this picture might lead you to believe that I'm advertising myself as only weighing 165 pounds. And unfortunately that's not true, but I'm working on it, but it is close to my size and weight. And, uh, I don't know. I don't think we have this out as a video. Here's, um, uh, some, a robot behavior that uses whole body motion, meaning the mobility based plus the arms plus the torso or all combining in order to handle these, uh, these boxes. It's using vision with the qr codes to simplify the task here we're trying to go at human speeds of operation. And so the robot searches for a box using its vision.

Speaker 3:          28:25          I think that, I think that was the only take we ever got with both robots working together and uh, you know, one of the problems with youtube as everybody's already seen what you've been up to by the time you get it, go around to give a talk. So I imagine most of you have seen this, but, uh, here's a, a par core robot we're working on where, uh, we've actually strengthened the hips so that it can do a little bit more jumping and, uh, uh, and, uh, it's kind of interesting that we, we've been interested in making a robot a little bit like the humanoid that, um, has less degrees of freedom, fewer degrees of freedom, and a simpler. And we designed this robot and the ultimate version of this, we'll have about 10 joints, whereas the humanoid had 28 and have many, many of the same capabilities. Uh, we have, uh, some use cases for this that I'm not going to talk about today. Uh, but, uh, this robot can lift heavy loads. It has a relatively small footprint given, uh, what his strength is. So the way things are done in logistics now is to use big robot arms that take up a lot of floor area or heavy. Um, and uh, we're looking at ways of using a robot like this one, not exactly this, we, it's sort of an evolution of this design in order to do logistics operations.

Speaker 3:          30:05          So I want to make a pitch to you. A Boston dynamics is hiring, um, and uh, I hope some of you will apply for a job there. These are how many years? It, six times three. These are 18, um, mit alum that currently work at the company, many of them for many years. Uh, so I'm sort of making the point that these people are happy. They're just like, just like you could be. And uh, I hope you'll look at our website and see what we're, uh, what we're looking for and considerate. So I'm just going to wrap up by talking about, you know, I used to be a professor here at Carnegie Mellon and when I was a professor will use the mostly wrote papers and uh, we were excited by, uh, you know, how many papers we could, right, and how many people cited them, uh, in their papers. But as a company guy instead of papers, I think we count youtube hits a and instead of citations want to tell you what this is, but most of you probably know. So now we count. Now we count spoofs instead of citations. And I'm happy to say that we're doing great. We have about, uh, uh, about two dozen big dog spoofs. Here's four of them. In the upper left is in Akihabara, Japan. The upper right is a Los Angeles online television show. It's the Netherlands on the lower left. And I guess that's Appalachia on the right. The poor kid doesn't even have a friend

Speaker 2:          32:03          to a to be in his movie.

Speaker 3:          32:09          Well, what about, what about atlas? Can you hear that?

Speaker 2:          32:37          No.

Speaker 3:          32:41          Here's, here's another one.

Speaker 2:          33:11          Thank you.

Speaker 3:          33:19          So we have, we have a big crew working on all these projects. You see you've gotten to meet a couple of them here, but it's really quite a team in a, uh, an absolute pleasure to work with. So anyway, thank you.

Speaker 2:          33:30          Thank you.

Speaker 1:          33:39          Thanks for the presentation. It was amazing. Uh, what sort of physics simulation, like if any do you have in your robots and do you really retain dead lake with the current trend of neural networks? We can just like do end to end modeling of these robots, but like without any sort of notion of physics but just like neural networks.

Speaker 3:          34:00          Um, so we have simulators that we've worked on for a long time, very detailed in some cases validated, validated me and compare the behavior of the simulator to the physics of, of ground truth. And uh, you know, I think they're important for our work and we use them frequently, but the end to end doesn't ring quite true. Usually the one we use simulation, the user is knowledgeable about the tradeoffs between doing a physical experiment and doing a simulated experiment and they're usually getting at some specifically or specific setup question rather than the idea that you start at one end, you know, to at least in our experience trying to simulate all the subtleties of the hydraulic actuator, backlashing gears a flexibility, uh, you know, the non rigidity in the components, that's a big undertaking and usually so, so I'm distracting that you can't really get on with what you're doing. So I think we use experiment for those subtleties and we use simulation for a bigger level dynamics questions.

Speaker 1:          35:13          Hey, would you say mechanical concerns or computational capability is more of a difficulty in terms of determining how quickly you can perform tasks with the robots?

Speaker 3:          35:27          Um, you know, we like to say that they're equally important. We, we now, although we didn't start out this way, we now have equal strength in our groups in mechanical design and implementation and in the software and controls and sensing. And I think, you know, they all matter. I think if you try and get by with just marginally designed hardware, uh, you don't get much experimental time in because the thing's broken all the time. Uh, so even though we are rough on our machines, they mostly keep working because, because we put a lot of attention to detail and how they're designed. Uh, but you know, there's still the, I think perception is still a tall pole in the tent. Certainly if you want to rival human perception, I don't think we're anywhere near there. I said I think the self driving car stuff is helping. Uh, there's a lot of interesting things happened there. I think specialized hardware is getting, you know, a, a six and, and things that could help. Um, but you know, it's, it's all still needed.

Speaker 4:          36:35          So, um, you guys have developed various components that all kind of come together to build one robot. Have you seen applications for any of these separate components elsewhere? So a organic design, for example, for the atlas, maybe prosthetics or hip replacements or something like that because there seems to be a lot of development going on and then individually as well as that they pay.

Speaker 3:          36:59          Sure. I mean, you're asking a very good question. There's a question in case people couldn't hear his are, aside from the value to the whole robot of the components we're making, are the components useful some other way. And uh, you know, the, the place where we think it's probably most true is the specialized hydraulic components. We've made servo valves and uh, the HPU, I'm sure we could sell them into other industry, uh, as a, as a company focused question though, uh, that that's really what it comes to. Do we really want to be doing that? Will that absorb too much time and attention and personnel or do we want to, you know, our heart is really in building a future generations of robots. So I think we're going to probably stay there.

Speaker 2:          37:46          Okay.

Speaker 5:          37:48          Thanks. I was wondering, have you done any research in regards to getting the robots to perform tasks involving direct physical contact with humans?

Speaker 2:          38:00          Nope,

Speaker 3:          38:01          I can. Only. The only thing we've done is we've done tele operation, which is not what you mean, where we have a human moving and the robot, you know, copying, which is very interesting because, uh, you can see that that's a way of showing how fast the robot can be and how coordinated they can be using a human and for part of the computing, uh, but we have, we don't have them interacting with people. I guess the closest as we once did a thing where a person and a robot picked up a stretcher and work together to pick up the stretcher, but they weren't touching each other. They going through the, uh, the stretcher material. We have plans, uh, you know, we're really, to be honest, we're really struggling with coming up with some strong concepts for safety. Even without doing that, um, you know, robots, uh, it's, you know, your first real people's first reaction and how you make a robot safe if there's a problem, don't really work very well. You can't freeze the robot, uh, you have to find some, you have to keep them going. I find a way to get into a safer state. So I think having come in contact with people is just gonna be harder. So eventually we want to, to help to carry the lift, the elderly and things like that. But we're not there yet.

Speaker 1:          39:22          Um, my question is about the relative rates of progress in robotics and machine intelligence. So an economist might maybe measure it by seeing how much money is going into computing hardware versus arms and legs centers naturally, that kind of thing. Um, so on one one possible scenario, the um, the machine intelligence receives the head and the robots a progressing more slowly because of a kind of a slow build test cycle. Basically it's, they will well things, it's not so easy to get a rapid build test cycle with a robot. And then the other scenario, the robots are more advanced than the machine intelligence. Machine intelligence is just such a conceptually difficult problem. So I'm in one side of the machines are telling the humans want to do in the other scenario that humans telling the machines what to do if you'd like. Um, so do you have any kind of perspective on that whole issue with the machine intelligence folk going to rush ahead using robots, guys struggling behind or the robot's going to get there before the massive problem and machine intelligence get sold or maybe somewhere in the middle

Speaker 3:          40:28          I think. Let's see. I don't know exactly what you mean by machine intelligence. Are you talking about um, you know, having Google do better search. So we were intelligent

Speaker 1:          40:39          mutation in general. So I start, I talked about economists measuring sensors, actuators, and compute hardware. So that's the kind of split I'm thinking about.

Speaker 3:          40:49          Yeah, I think that it's always been a misconception that the hardware components by themselves, uh, constitute progress in intelligence or in robot behavior. Uh, they're, I think they're important ingredients. But by themselves, you know, when I was a graduate student here, I can remember reading an ad for a, an uh, uh, optical character recognition system and what the ad said was, uh, you know, we have camera, we have a thing for holding the paper. You're looking at, all you have to do is write the software. So it was all done except for you to write the software. And uh, you know, it's the whole problem was there. So I don't know if I'm answering your question. Uh, you know, robotics is hard. Uh, I think it feels like we're making progress if you keep pushing, we keep making progress. It's not like there's a knee in the curve that we've hit a. But I also think that the rest of the ai world is making a good progress too. And yeah, it's fun being a part of it.

Speaker 5:          41:58          Hi, my question is mostly related to security. Uh, so since you are productizing your robots now, um, there has been research on the lidars mainly, uh, where you could spoof allied are and, and the sensor basically cannot see anything. Uh, so are you looking into that as well, taking into consideration these awesome robots could be in let's say in our defense, you know, working for the defense as well. So those are like really harsh environments.

Speaker 3:          42:36          Yeah, I mean these are very hard problems, you know, if someone, if a, if an intelligent adversary wants to trick the robot, it's not all that hard, uh, these days, uh, you know, we're, we're working probably the other end of the problem, you know, trying to do the basics. Uh, right now, uh, I don't think, you know, I don't, I don't think robots are going to be as autonomous in a hostile environment as, as people either think or fear, uh, because uh, of how frail they'll still be a until we get further along.

Speaker 6:          43:14          Hi there. Hey, I wanted to ask about two things that are going to probably play a big role in adoption. The first is price, so if you could speak to the current unit price of a spot, many and how that you think is going to evolve over time. And the second is sort of consumer psychology. Uh, I felt like when I saw the, um, the, the test at the end of the robot swearing my level of comfort with it being in my house suddenly shot up because it seemed way more human. So I was just thinking about what kinds of experiments you guys have run away, what you've thought about with respect to making people more comfortable with robots working around them.

Speaker 3:          43:50          Yeah. Uh, in terms of costs, I, you know, we're not saying what this thing costs yet, but we will later in the year, um, we have reduced the cost of this by about a factor of 10 from what the first prototypes cost. So we're making progress. Um, in terms of the psychology of robots, it's been very interesting to watch, you know, we uh, we got branded sort of as robot abusers because we kicked our robot. Really what we were doing was trying to show how good they were at balancing and we weren't, we didn't think we were abusing him. I have video of me pushing on my daughter when she was one years old and actually knocking her over, but that wasn't my goal. I wanted to kind of test out her her balance and uh, uh, I bet you, you know, if you guys have kids or you're or at all that you've done stuff like that.

Speaker 3:          44:42          Um, so, but we've adjusted a little bit and so we don't usually push on the robots in our videos despite the one we showed with the hockey and hockey sticking a hand on this thing. Uh, that's why we had the banana peels. There's a way to have the robot crash without us being having our fingerprints on it. Um, you know, I guess the other data point I have is that if you look at the likes and dislikes on our youtube videos, um, we found a way to get the likes to dislikes ratio much higher by partly probably by not looking like we're abusing the, uh, uh, the robots. Um, there's probably a long way to go to make these things really friendly. Um, and uh, uh, I have to admit there's a little spirit at our, at our company of being kind of a, you know, it's fun being bad boys in terms of uh, you know, just make the robot do cool stuff and leave the, uh, the emotions to others. Um, and certainly the social robots that have so much going into making them cute. Uh, I don't know. I'm sure we'll have marketing people working on that. I don't know what else to say.

Speaker 1:          46:01          Hi. So in terms of research purpose, our practical purposes, so one of the reasons to choose to investigate on this, um, humanoid robots. So it seems like, um, it cannot run as fast as the Cheetah and the, it also cannot carry as many staff as the big dog.

Speaker 3:          46:21          Yeah. You're basically saying that the humanized don't seem to be as practical in terms of function

Speaker 1:          46:27          more efficient, like a, like a humanoid robot is more efficient than these are cheaters and the big box.

Speaker 3:          46:34          Well, the motivated. So I don't have a good answer. Uh, the motivation for the DRC that Darpa robotics challenge, which was humanoid robots, was to say that they wanted to use robots that could go the places designed for humans. And uh, and so that's why they used the human form. And I think, you know, there's an argument there. Uh, it is true that the, uh, human form has a lot of complexity to it because you have very complicated legs in the IPAD and they're supporting the weight of the body and the arms, whereas the quieter beds can spread all that out. I'm, uh, so I'm sympathetic to your question. I don't really have an answer. Um, I can tell you that the public's reaction to a humanoid robot is off the scale compared to anything we've done with a quadrupedal robots for what that's worth. So, uh, we always get a lot of viewership if we show a human doing something. Uh, but I think it's a question that we will keep addressing. We are gonna keep pushing on getting the humanoid to do more and more human, like things. Uh, even though we probably won't commercialize them as soon as we commercialize the other stuff,

Speaker 1:          47:52          how do you specify goals? And although you said earlier that it's expensive to do like simulations and stuff, do you have any intentions of doing any deep reinforcement learning?

Speaker 3:          48:01          What was the last time?

Speaker 1:          48:02          Do you have any intentions of doing deep reinforcement learning?

Speaker 3:          48:05          Um, I'll do the last one first. Um,

Speaker 3:          48:12          we, I'm sure we will use learning before too long. Uh, I'm not sure whether it will be deep reinforcement learning or something else, but mostly we're interested in optimizing the complicated a stage space partitioning. We do a right now we use, you know, people make a very simple decisions as to how to divide up the space and we think that these things could probably be a really improved if we, uh, uh, use the learning approach, that's probably the first place we will apply it. We do a little bit of learning here and there, but not much compared to how much learning is talked about out there. What was the other question?

Speaker 3:          48:51          How do we specify a goal? You mean to the robot or how do we decide as a company? So, um, I don't think there's any across the board answer. We write applications, for instance, for each of these uses. So for instance, in the, uh, where we were doing the patrol route, we have an application that has a Ui that lets the user, uh, you know, tell it the information it needs to tell, can tell it to go ahead and start on the patrol. Uh, and things like that. Um, for, for the door, I think, uh, I think, uh, there's a button on the, on the controller we can show you afterwards if you want. And uh, you walk the robot up to the door, were you steering it and then you press the button and then it starts looking for the door handle and it goes through the whole, you know, goes through the door. But I don't think these answers are fundamental. I think you could do it lots of different ways. You know, we're working on all the machinery coming up from the bottom to be able to do these things. And then, you know, in some case you could have it be buttons on a, on a Ui, it could be a, an API that's accessed through some higher level ai, uh, and we just aren't sweating that part of it at this point.

Speaker 1:          50:09          Hi. Um, so aside from locomotion, um, I can use my body for like nonverbal communication to communicate my intentions and other such things, even though I'm not always aware of it. Um, and I'm guess I'm wondering if this is something that you've considered for these robots.

Speaker 3:          50:26          I think the we've come is having the robot go like this after the flip, which was a way of communicating a, we really haven't done anything along those lines. I'll bet you though the people writing code, uh, it can interpret it a lot of the subtleties of what's, you know, what's working and what isn't by looking at things like that. But the robot isn't trying to communicate that way.

Speaker 7:          50:52          I have two questions. How robots really, really fast.

Speaker 3:          51:01          How do we make them fast?

Speaker 7:          51:04          No, my question is how did you make them fast? I mean like the time how,

Speaker 3:          51:14          where you get a lot of people who are really smart and good at working together with each other at our lab and then they make plans and a, which everybody tries to stay on the plan and then, uh, you know, pull it together. Sometimes it doesn't go as fast as we'd like, especially if we have to buy parts from someone else and they're slow. That happens a lot, honestly. A, is that what you mean? So we don't make them that fast, you know, we're, we're pretty fast, you know, usually I'm four or five months to build a new robot. Um, something like that. But mostly it's getting people to work together. What's the, what's the other question?

Speaker 7:          52:02          The other question is why do the people push the robots?

Speaker 3:          52:08          Why did, why do they push, why do they push? We're trying. The robots are always balancing them themselves and so we want to show that they're, that they can balanced by, by, um, showing that when you knock them, they still, they don't fall over, they stay up on their feet. So we're kind of showing off. Are you building anything? Why not? You should, um, it's way off what we were in the basement. I'm not good at building. No. Yes. Yes you are. You might think you're not. Some games they are. You had to give it a try. You're the right age. The right age to get started. I'm six and a half.

Speaker 2:          53:00          Okay.

Speaker 3:          53:09          Would that, I think please give mark a big hand. Thank you very much.