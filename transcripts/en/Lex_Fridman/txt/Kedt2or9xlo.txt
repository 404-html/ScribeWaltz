Speaker 1:          00:00:00       The following is a conversation with Arielle Vinnie Alice. He's a senior research scientist at Google deep mind, and before that he was a Google brain and Berkeley. Okay. His research has been cited over 39,000 times. He's truly one of the most brilliant and impactful minds in the field of deep learning. He's behind some of the biggest papers and ideas and AI, including sequence to sequence learning, audio generation, image captioning, neural machine translation, and of course reinforcement learning. He's a lead researcher of the Alpha Star Project, creating an agent, the defeated a top professional at the game of starcraft. This conversation is part of the artificial intelligence podcasts. If you enjoy it, subscribe on Youtube, iTunes, or simply connect with me on Twitter at Lex Freedman, spelledF , r I, d. And now here's my conversation, Arielle Minneapolis, you spearheaded the deepmind team behind Alpha Star that recently beat a top professional players, starcraft, so you have an incredible wealth of work and deep learning and a bunch of fields. But let's talk about starcraft first. Let's go back to the very beginning, even before Alpha Star, before deep mine, before deep learning first, what came first for you? A love for programming or a love for video games?

Speaker 2:          00:01:24       I think for me it definitely came first. The drive to play video games. I really liked computers. I do and really coats much. But what I would do is I would just mess with the computer, break it and fix it. That was the level of skills, I guess that again, in my very early days, I mean when I was 10 or 11 and then I, I really got into video games, especially starcraft, actually the first version, I spent most of my time just playing kind of pseudo professionally as professionally as you could play back in 98 in Europe, which was not very main scene leg that what's called nowadays e-sports, right? Of course, in the 90s. So, uh,

Speaker 1:          00:02:08       how'd you get into starcraft? What, what was your favorite race? How do you develop, how did you develop your skill? What, what was your strategy, all that kind of thing.

Speaker 2:          00:02:18       So as a player I tended to try to play not many games, not to kind of disclose the strategies that I kind of developed. And I like to play random, actually not in competitions but just to, I think in starcraft there's, well there's three main races and I found it very useful to play with all of them. Um, so I would choose random many times even sometimes in tournaments to gain skill on the three races because it's not how you play against someone, but also if you understand the race because you played, you also understand what's annoying, what then when you're on the other side, what to do to annoy that person to try to gain advantages here and there and so on. So I actually played random, I must say in terms of favorite race, I really liked [inaudible]. Um, I was probably best at circ and that's probably what I tend to use towards the end of my career before starting university.

Speaker 2:          00:03:11       So let's step back a little bit. Could you try to describe starcraft two people that may never have played video games, especially the massively online variety like starcraft. Starcraft is a real time strategy game. And the way to think about starcraft, perhaps if you understand the beat chess, is that there are, there's a board which is called mapper or, or like, yeah, like the mob where people play against each other. There's obviously many ways you can play, but the most interesting one is the one versus one set up where you just play against someone, someone else or even the built in Ai, right? The laser put, uh, a system that can play the game reasonably well if you don't know how to play. And then in this board you have again, pieces like in chess, but these pieces are not there initially. Like they are in chess.

Speaker 2:          00:04:02       You actually need to decide to gather resources to decide which pieces to build. So in a way you starting almost with no pieces, you start gathering resources. In starcraft, there's minerals and gas that you can gather. And then you must decide how much do you want to focus, for instance, on gathering more resources or starting to build units or pieces. And then once you have enough pieces or maybe like attack, um, you a a good attack composition, then you go and attack the other side of the map. And now the other main difference with Chaz is that you don't see the other side of the map. So you're not seeing the moves of the enemy. It's what we call partially observable. So as a result that you must not only decide trading of economy versus building your own units, but you also must decide whether you want to scout to gather information.

Speaker 2:          00:04:56       Um, but also by scouting you might be giving away some information that you might be hiding from the enemy. So there's a lot of complex decision making, um, all in real time. There's also unlike chess, this is not a turn based game. You play basically all the time continuously. And thus some skill in terms of speed and accuracy of clicking is also very important. And people that train for these really play this game at at an amazing skill level. I've seen many times, these are new, if you can witness these, life is really, really impressive. Um, so in a way it's kind of a chess where you then see the other side of the board. You were building your own pieces and you'll also need to gather resources to basically get some money to build other buildings, pieces, technology and so on. From the perspective of the human player. The difference between that and chess or maybe that and uh, a game like turn based strategy, like here's a mighty magic is that there's an anxiety because you have to make these decisions really quickly.

Speaker 3:          00:05:58       And if you are not actually aware of what decisions work it, it's a very stressful, balanced. The of everything you described is actually quite stressful, difficult to balance for a amateur human player. I don't know if it gets easier at the professional level, like if they're fully aware of what they have to do. But at the amateur level there's this anxiety, oh crap, I'm being attacked. Oh crap. I have to uh, build up resources. Oh, I have to probably expand. And all these, the time, the a real time strategy aspect is really stressful and computation. I'm sure difficult. We'll get into it. But, uh,

Speaker 2:          00:06:34       for me

Speaker 3:          00:06:35       battlenet s so starcraft was released in [inaudible] 98, 20 years ago. It was just hard to believe. Uh, and a blizzard battlenet with a Diablo in 96 came out. And to me it might be a narrow perspective, but it changed online gaming and perhaps society forever. Yeah. But I may have made way too narrow viewpoint. But from your perspective, uh, can you talk about the history of gaming over the past 20 years? Is this how transformational, how important is this line of games?

Speaker 2:          00:07:12       Right. So I think I kind of was an active gamer. Wiles. These was developing the Internet, um, online gaming. So for me that the way it came was I played other games strategy related, I played a bit of common and conquer. And then I played Warcraft two, which is from blizzard. But at the time I didn't know, I didn't understand about what bleeds or was or anything work off to was just the game, which is, which was actually very similar to start in many ways. It's also real time strategy game where there's orks and humans. So there's only two racist. But it was offline and it was offline, right? So I remember a friend of mine came to to school say, oh, there's this new cool game called starcraft. And I just said, oh, this sounds like just a copy of Warcraft two, um, until I kind of installed it.

Speaker 2:          00:07:59       And at the time, um, I am from Spain, so we didn't have intern like very good internet. Right? So there was, for us a starcraft became first kind of an offline experience where you kind of start to play these missions, right? You play against some sort of scripted things. The, to double up the story of the characters in the game. Um, and then later on I started playing against the beauty in AI, um, and I thought it was impossible to defeat it. Then eventually you defeat one and you can actually bring in seven built in the eyes. At the same time, we also felt impossible, but actually it's not that hard to beat seven [inaudible] at once. So once we achieve that also we discovered that we could play, um, as I said, Internet wasn't that great, but we could play with the land right on, like basically against each other if we were in the same okay.

Speaker 2:          00:08:49       Plays because you could just connect machines with like cables, right? Um, so we started playing in land mode and against, you know, as a group of friends and it was really, really like much more entertaining than playing against the ice. And later on as Internet was starting to double up and being a bit faster and more reliable, then it's when I started experiencing battlenet, which is these amazing universe, not only because of the fact that you can play the game against anyway, anyone in the world, but you can also get to no more people you just get exposed to now, like these vast variety of, it's kind of a bit of when the chats came about, right? There was a chat system, you could play against people, but you could also chat with people not only about Steiger, but about anything. And that became a way of life for kind of two years. Um, and, and obviously they need became like kind of exploded in mean that I started to play more seriously going to tournaments and so on, so forth.

Speaker 3:          00:09:44       Do you have a sense and a societal sociological level, what's this whole part of society that many of us are not aware of and it's a huge part of society, which is gamers. I mean I'm, every time I come across that in youtube or streaming sites, I mean this is the huge number of people play games religiously. Do you have a sense of those folks, especially now that you've returned to that realm a little bit and the Ai side?

Speaker 2:          00:10:12       Yeah, so in fact I even after stock or if I actually played world of Warcraft, which is the main sort of online walls on presence that you get to interact with lots of people. So I played that for a little bit. It was, to me it was a bit less stressful than starcraft because winning was kind of a given. You just put in this world and you can always complete missions. But I think it was actually the social aspect of specialty starcraft first. And then games like world of Warcraft really shaped me in, in a very interesting way because you are, you get to experience is just people you wouldn't usually interact with, right? So even nowadays, I still have many Facebook friends from the area where I played online and their ways of thinkings, even political. Um, they just don't, we don't live in it like we don't interact in the, in the real world, but we were connected by basically fiber.

Speaker 2:          00:11:06       And that way I actually get to understand a bit better, um, that we live in a diverse world. And these were just connections that were made by, because, you know, I happened to go in a city in a beautiful city, a as a priest and I met these, you know, these warrior and we became friends and then we start like playing together. Right? So I think it's, it's, it's transformative and more and more and more people are more aware of it. I mean, it's, it's becoming quite mainstream. But back in the day, as you were saying, in 2000 2005 even, it was very still very strange thing to do, especially in Europe. I think there were exceptions like Korea for instance, it was amazing that that, that everything happened so early in terms of cyber cafes, like it's if you go to sell it gets a CT that um, back into the starcraft was kind of, you could be a celebrity by playing starcraft, but this was like 99, 2000, right?

Speaker 2:          00:12:03       It's not like recently. So, um, yeah, it's quite, it's quite the interesting too to look back and, and yeah, I think it's changing society the same way. Of course like technology and social networks and so on are also transforming things. And a quick tangent, let me ask, you're also one of the most productive people in your particular chosen a passion and path in life. Uh, and yet you're also appreciate and enjoy video games. Do you think it's possible to do, uh, to enjoy video games and moderation? Someone told me that you could choose two out of three. Um, when I was playing video games, you could choose having a girlfriend, um, playing video games or studying. Yeah. And I think for the most part it was relatively true. These things do take time. Uh, games like stock. If you take the game pretty seriously and you want to study it, then you obviously we'll dedicate more time to it.

Speaker 2:          00:12:59       And I definitely took gaming and obviously studying very seriously. I, I, I love learning science and et Cetera. Um, so to me, especially when I started university Undergrad, I kind of step off starcraft. I actually fully stopped playing. Um, and then we'll have worker of was a bit more casual. You could just connect online. And I mean, it was, it was fun. Um, but I, as I said, that was not as much time investment as it was for and starcraft. Okay. So let's get into Alpha Star. What are the a year behind the team? Uh, so deep mine has been working on starcraft and released a bunch of cool open source agents and so on past few years, but Alpha Star really is the moment where, uh, the first time you'd beat a world class player. So what are the parameters of the challenge in the way that Alpha Star took it on and how did you and David and the rest of the deepmind team get into it?

Speaker 2:          00:13:58       Consider the, you can even beat the bus in the world or top players. I think it all started in back in 2015. Um, actually I'm lying. I think it was 2014 when the mine was acquired by Google and I at the time was at Google brain, which is in, it was in California, is still in California. Uh, we had the summit where we got together the two groups. So Google brain and Google deepmind got together and we gave a series of talks and given that they were doing deep reinforcement learning for games, I decided to bring up part of my past. Um, we, Jay had developed at Berkeley, like these things, which we call Berkeley over mind, which is really just a, a starcraft one Bot, right? So I talked about that and I remember that means just came to me and said, well, maybe not now.

Speaker 2:          00:14:45       It's, it's perhaps a bit too early, but you should just come to the mind and do these again. Uh, with deep reinforcement learning. Right? And at the time it sounded very science fiction for, for several reasons. Uh, but then in 2016, when I actually moved to London and joined the mine, I'm transferring from brain. It became apparent that because of the Alphago moment, um, and kind of bleeds or reaching out to us to say, wait, do you want the next challenge? And also me being full time at deep. So sort of, kind of all these came together and then I was, I went to Irvine in California to the blizzard headquarters to just chat with them and try to explain how would it all work before you do anything. And the approach has always been about the learning perspective, right? So, um, in, in Berkeley we did a lot of rule based, you know, conditioning and if you have more than three units then go attack.

Speaker 2:          00:15:42       And if the other has more units than me, I retreat and so on and so forth. And of course the point of debris enforcement learning, deep learning, machine learning in general is that all these should be learned behavior. So that kind of was the DNA of the project since its inception in 2016 where we just didn't even have an environment to work with. And so this, that's how it all started really. So if you go back to that conversation with Dennis, or even in your own head, how far away did you, cause that's, we're talking about Atari Games. We're talking about go, which is kind of, if you're honest about a really far away from starcraft in, in, uh, well now that you've beaten it, maybe you could say as close, but, uh, it's much, it seems like starcraft is way harder than go philosophically in mathematically speaking.

Speaker 2:          00:16:31       Uh, so how far away did, did you think you were? Do you think it's 1,019 and 18? You could be doing as well as you have? Yeah. When I, when I kind of thought about, okay, I'm going to dedicate, you know, a lot of my time and focus on these and obviously I do a lot of different research in deep learning. So spending time on it. I mean I really had to kind of think there's going to be something good happening out of this. Um, so really I thought, well these sounds impossible and it probably is impossible to do the full thing, like the all like the full game, um, where you play one versus one. Um, and it's only a neural network playing and so on. Um, so it really felt like, I just didn't even think it was possible. But on the other hand, I could see some stepping stones like towards that goal.

Speaker 2:          00:17:18       Um, clearly you could define sub problems in starcraft and sort of dissected a beat and say, okay, here is a part of the game. Here is another part. Um, and also obviously the fact that, so this was really also critical to me, the fact that we could access human replace, right? So pleaser was very kind and in fact they open source these for the whole community where you can just go and it's not every single stock of game ever played, but it's a lot of them you can just go and download and everyday they will you, you can just query a data set and say, well give me all the games that were played today. And given my kind of experience with language and sequences and supervised learning, I thought, well that's definitely going to be very helpful. And something quite unique now because ever before we had such a large data set of replays of people playing the game at this scale of such a complex video game. Right? So that to me was a precious resource. And as soon as I knew that [inaudible] was able to kind of give these to the community, I started to feel positive about something [inaudible] happening. But, but I also thought the full thing, like really no rules, no, no single line of code that tries to say, well, I mean if you see these units builds the detector, all these, I'm not having any of these as specializations seemed really, really, really difficult to me intuitively. I do also like that blizzard was teasing or even trolling

Speaker 3:          00:18:43       meal, a sort of almost uh, yeah, pulling you in into this really difficult challenge. Did they have any aware what's, what's the interest from the perspective of blizzard except just curiosity?

Speaker 2:          00:18:57       Yeah, I think believes or has really understood and really bring, bring forward this competitiveness of east ports in the Games. The starcraft really kind of sparked a lot of like something that almost was never seen, especially as I was saying, eat back in Korea. So they just probably thought, wow, this is such a pure one versus one setup that it will be great to see, um, if something that can play Atari or go and then later on chess could, could even tackle these kind of complex real time strategy game. Right. So for them, they wanted to see first obviously whether it was possible, if, if, if the game they created was in a way it's solvable to some extent. And I think on the other hand, they also are a pretty modern company that innovates a lot. So just starting to understand AI for them to how to bring AI into games is not, is not AI for games, but games for AI, right? I mean both ways I think can work. And you up, we obviously at the man use games for AI, right, to drive AI progress, but pleaser might actually be able to do and many other companies to start to understand and do the opposite. So I think that is also something they can get out of these. And they definitely, we have brainstorm a lot about about these, right.

Speaker 3:          00:20:13       But one of the interesting things to me about starcraft and Diablo and these games that blizzard is created is the task of balancing classes, for example, a sort of making the game fair from the starting point. And then let's skill determine the outcome. Uh, is there, uh, I mean, can you first comment there's three races are Protoss and Taryn, I don't know if I've ever said that out loud. Is that how you pronounce it, Taryn? Yeah. Uh, yeah. I don't think I've ever sold in person interacted with anybody about starcraft. It's funny.

Speaker 2:          00:20:48       Uh, so they seem to be pretty balanced. I wonder if the AI, the work that you're doing with Alpha Star would help balance them even further. Is that something you think about? Is that something that blizzard is thinking about? Right. So, so balancing when you add a new need or a new spell type is obviously possible given that you can always train or retrain at scale. Some agent that might start using that in unintended ways. But I think actually if you understand how starcraft has kind of coy evolve with players in a way, I think it's actually very cool the ways that many of the things and strategies that people came up with, right? So I think it's, we've seen it over and over in starcraft that bleeds or comes up with maybe a new unit and then some players get creative and do something kind of unintentional or something that blizzard designers that just simply didn't test or think about.

Speaker 2:          00:21:43       And then after that becomes kind of mainstream in the community bleeds or patches the gang. And then they kind of, maybe we can that strategy or, or make it actually more interesting but a bit more balanced. So these kind of continual talk between players and research, this is kind of what has defined them actually in actually most games I the stacker but also in world of Warcraft they would do that. There are several classes and it would be not good that everyone plays absolutely the same raise or and so on. Right. So, um, I think they do care about balancing of course. And they do a fair amount of testing, but it's also beautiful to, to also see how players get creative anyways. And I mean, whether I can be more creative at this point. I don't think so. Right. I mean, it's just sometimes some things are so amazing happens. Like I remember back in the days like you have these drop ships that could drop the rivers and that was actually not thought about that you could drop these unit that has these what's called splash damage that would basically eliminate all the enemies workers at once. No one thought that you could actually put them in really early game, do that kind of damaged and then you know, things changing the game. But I don't know, I think there's, it's quite an amazing exploration process from both sides. Players and blizzard alike.

Speaker 3:          00:23:01       Well it's a, it's almost like a reinforcement learning exploration, but any, the scale of humans that play that play blizzard games is almost on the scale of a large scale, deep mind RL experiment. I mean, if you look at the numbers, it's, I mean you're talking about, I don't know how many games, but hundreds of thousands of games. Probably a month. Yeah. I mean, so you could, it's almost the same as running a RL agents. What aspect of the problem of starcraft he thinks the hardest. Does it the, like you said, the imperfect information, is it the fact they have to do long term planning? Is it the realtime aspects we have to Duke stuff really quickly? Is it the fact that a large action space so you can do so

Speaker 2:          00:23:46       many possible things? Or is it the, you know, in the game theoretic sense there is no national Glybera at least you don't know what the optimal strategy is because there's way too many options, right? What's, is there something that stands out as just like the hardest, the most annoying thing? So when we sort of looked at the problem and start to define the parameters of it, what are the observations, what are the actions? Um, it became very apparent. Um, that's, you know, the, the very first barrier that one would hit in starcraft would be because of the action space being so large and as not being able to search like you could in, in chess or go, even though the search space is vast. Um, the main problem that we identified was that of exploration. Right? So without any sort of human knowledge or human prior.

Speaker 2:          00:24:36       If you think about starcraft and you know how deep reinforcement learning algorithm works work, which is essentially by issuing random actions and hoping that they will get some wins sometimes so they could learn. So if you think of the of the action space in starcraft, almost anything you can do in the early game is bad because any action involves taking workers which are mining minerals for free. That's something that the game does automatically sends them to mind and you would immediately just take them out of mining and send them around. So just thinking how, how is it going to be possible to, to get to understand that these concepts, but but even more like expanding, right? There's, there's these buildings you can place in other locations in the map to gather more resources, but the location of the building is important and you have to select a worker, send it, walking to that location, build the building, wait for the building to be built, and then boot extra workers there so they start mining that just that feels like impossible.

Speaker 2:          00:25:40       If you just randomly click to produce that state desirable state that then you could hope to learn from because eventually that may yield to an extra win. Right? So for me, the exploration problem and due to the action space and the fact that there's not really turns, there's so many turns because the game essentially teaks at 22 times per second if you, I mean that's how they could, is criticize sort of time. Obviously you always have to discreet ice time. There's no, no such thing as real time, but it's really a lot of time steps of things that could go wrong. And that definitely felt Apriori like the hardest. Um, you mentioned many good ones. I think partial observability. Um, the fact that there is no perfect strategy because of the Paschal observability those are very interesting problems. We start seeing more and more now in terms of us, we solved the previous ones. But the core problem to me was, uh, exploration and solving it has been basically kind of the focus and how we saw the first breakthroughs. So exploration in a, in a multi hierarchical way. So like

Speaker 3:          00:26:44       22 times a second. Exploration has a very different meaning than it does in terms of should I gather resources early or should I wait or so on. And so how do you solve the long term? Let's talk about the internals of Alpha Stein. So first of all, how do you represent the state of the game, uh, as an input? How do you then do the longterm sequence modeling? How do you build a policy? What, what's the, what's the architecture like? So out of a star has

Speaker 2:          00:27:15       obviously several components, but everything passes through what we call the policy, which is a neural network. And that's kind of the beauty of it there is I could just now give you a neural network and some weights and if you fed the right observations and you understood the actions the same way we do, you would have basically the agent playing the game. There is absolutely nothing else needed other than those weights that were trained. Now the first step is observing the game and we've experimented with a few alternatives. The one that we currently use mixes, both spacial sort of images that you would process from the game that is the zoomed out version of the, of the map and also assume the inversion of the camera or the screen as we call it, but also we give to the agent the least of units that it sees more of as a set of objects that it can operate on that is not necessarily required to use it.

Speaker 2:          00:28:14       And we have versions of the game that play well without these set vision. That is not like how humans perceive the game, but it certainly helps a lot because it's a very natural way to encode the game is by just looking at all the unions that there are there. They have properties like health was Aetion type of unit, whether it's my unit or the enemies. And that's sort of is kind of the, the summary of, of the state of, of the, of the game. Not that least of units or set of units that you see all the time.

Speaker 3:          00:28:47       Well that's pretty close to the way humans see the game. Why do you say it's not? Isn't that a, you're saying the exactness of it is not only to humans,

Speaker 2:          00:28:55       the exactness of it is perhaps not the problem. I guess maybe the problem if you look at it from how actually humans play the game is that they play with a mouse and a keyboard and a screen and they don't see sort of a structured object with all the units, what they see, what they see on the screen. Right? Yeah. So

Speaker 3:          00:29:12       you remember that there's a siren interrupt. There's a plot that he showed with camera based. We do exactly that. Right? Move around. And that seems to converge to similar performance.

Speaker 2:          00:29:22       Yeah. I think that's what we're kind of experimenting with what's necessary or not, but using the set. So, so actually if you look at research in computer region where it makes a lot of sense to treat images as two dimensional race, there is actually a very nice paper from Facebook, I think. Um, I forgot who the authors are, but I think it's, um, part of gaming skills group. And what they do is they take an image which is that these two dimensional signal and they actually take pixel by Pixel and scramble the image as if it was just a least of pixels. And crucially they encode the position of the pixels with the x y coordinates. And this is just kind of a new architecture, which we incidentally also using stacked graph called the transformer, which is a very popular paper from last year, which yielded very nice result in machine translation.

Speaker 2:          00:30:15       And if you actually believe in this kind of, oh it's actually a set of pixels, as long as you encode x why it's okay then you, you could argue that the list of units that we see is precisely that because we have each unit as a kind of pixel, if you will, and then their x, y coordinates. So in that perspective we, without knowing it, we use the same architecture that was shown to work very well on Pascal and image net and so on. So the interesting thing here is putting it in that way, it starts to move a tours the way usually work with language. So what, and especially with your expertise and uh, uh, work in language, it seems like there's echoes of a lot of, um, the way you would work with natural language in the way you've approached Alpha Star right there.

Speaker 2:          00:31:03       What's, does that help with the longterm sequenced modeling there somehow? Exactly. So, so now that we understand what an observation for a given time step is, uh, we need to move on to say, well, there's going to be a sequence of such observations and an agent. We'll need to given all that he'd seen not only the current time step but all that he'd seen. Why? Because there is partial observability we must remember whether we saw a worker going somewhere for instance, right? Because then there might be an expansion on the top right of the map. So given that what you must then think about this, there is the problem of given all the observations, you have to predict the next action. And not only given all the observations, but given all the observations and given all the actions you've taken predict the next action. And that sounds exactly like machine translation where, and that's exactly how kind of I saw the problem, especially when you are given supervised data or replace from humans because the problem is exactly the same.

Speaker 2:          00:32:03       You're translating essentially a prefix of observations and actions onto what's going to happen next, which is exactly how you would train a model to translate or to generate language as well. Right? Do you have a certain prefix? You must remember everything that comes in the past because otherwise you might start having non-coherent text and the same architectures. Um, we using LSTM and transformers to operate on across time to kind of integrate. All that's happened in the past, those architectures that work so well in translation or language malady are exactly the same than what the agent is using to issue actions in the game and the way we train it. Moreover for imitation, which is step one of Alpha stories, take all the human experience and try to imitate it. Match like you try to imitate translators that translated many pairs of sentences from French to English.

Speaker 2:          00:32:56       Say that sort of principle applies exactly the same. It's almost the same code, except that instead of words, you have a slightly more complicated objects, which are the observations and the actions are also a bit more complicated. That Dan award is there a self play component then too. So once you run out of imitation, right? So, so indeed you can bootstrap from human replace, but then the agents you get are actually not as good as the humans you imitated. Right? So how do we imitate, well, we take humans from 3000 MMR and hire 3000 and memories. Just a metric of human skill and 3000 and [inaudible] might be like 50% percentile, right? So it's just Kevin average human, what's the, so maybe quick pause and Mars. A ranking scale. The matchmaking rating for players. So it's threes. I remember there's like a master and a grand master was 3000.

Speaker 2:          00:33:54       So 3000 is pretty bad. Um, I think it's kind of goals level. It just sounds really good relative to chess, I think. Oh yeah, yeah. No, the, the, the ratings. The best thing though. Water at 7,000. [inaudible] um, so 3008, we'd like Eloy. Indeed. Right, so (300) 030-0500 just allows us to not feel there are a lot of the data so we like to have a lot of data and deep learning as as you probably know, so we take these kind of 3,500 and above but then we do a very interesting trick which is we tell the neural network what level they are imitating so we say these replay you are going to try to imitate to predict the next action for all the actions that you're going to see is a 4,000 MMR replay. These one is a 6,000 MMR we play and what what's cool about these is then we take these policy that is being trained from human and then we can ask it to play like a 3000 Mr player by setting a bit saying, well okay play like a 3000 MMR player or play like a 6,000 MMR player and you actually see how the policy behaves differently.

Speaker 2:          00:34:57       It gets worse. The economy. If you play like a gold level player, it does less actions per minute, which is the number of clicks or number of actions that you will issue in the whole minutes and it's very interesting to see that. It kind of imitates the skill level quite well, but if we ask it to play like a 6,000 MMR player, we tested of course these policies to see how well they do. They actually beat all the builtin ais that bleeds or put in the game, but they're nowhere near 6,000 MMR players. Right? They might be maybe around gold level platinum perhaps. So there's still a lot of work to be done for the policy to truly understand what it means to win. So far we only ask them, okay, here is the screen and that's what's happened on the game until this point. What would the next action be if we ask, you know, we ask a pro to now say, oh, you're going to click here or here or there.

Speaker 2:          00:35:49       And the point is experiencing, experiencing wins and losses is very important to then start to refine a, otherwise the policy can get loose, can, can just go off policy as we call it. That's so interesting that you can at least hope eventually to be able to control a policy, uh, approximately to be at a some MMR level as that's so interesting. Especially given that you have ground truth for a lot of these cases. Right. Uh, can I ask you a personal question? Sure. Uh, what's your MMR? Well, I haven't played stacker off too, so I am unranked Oh, says the kind of lowest league. Okay. So I used to play starcraft one, the first one, but you haven't seriously playing doctor I've talked to. So the best player we have at deep mind is about 5,000 MMR. We gs hi masters is not at grand master level.

Speaker 2:          00:36:41       Um, grandmaster level would be the top 200 players in a certain region like Europe or America or Asia. Um, but for me it's would be hard to say I am very bad at the game. I actually played Alphas therapy too late and he'd beat me. I remember the whole team was, oh, Oreo, you should play. And I was, oh, it looks like it's not so good yet. And then I remember I, I kind of got busy and waited an extra week and I played on it really lead me very badly. I mean, how did that feel? Is that, isn't that an amazing feeling lens? Amazing. Yeah. I mean obviously I tried my best and I tried to also impress my, cause I actually played the first game, so I'm still pretty good at micro management. Um, the brummies I just don't understand starcraft two. I understand starcraft and when I played starcraft I probably was consistently like for, for a couple of years, stop 32 in Europe.

Speaker 2:          00:37:34       Um, so I was decent, but at the time we didn't have these kind of MMR system as as well established. So it will be hard to know what it was back then. So what's the difference in the interface between Alpha Star and starcraft and the human player and starcraft? Is there any significant differences between the way they both see the game? I would say the way they see the game, there's a few things that are just very hard to simulate. Um, the main one perhaps, which is all be using hindsight, these, um, what's called cloaked units, which are invisible units. So in, in starcraft you can make some units that you need to have a particular kind of, you need to detectives. So these unions, I am visible. If you cannot detect them, you cannot target them. So they would just, you know, destroy your buildings or kill your workers.

Speaker 2:          00:38:27       But despite the fact you cannot target the unit, there's a shimmer that as a human you observe. I mean, you need to train a little bit, do you need to pay attention, but you would see these kind of spacetime spacetime like distortion and you wouldn't know. Okay. There are, yeah. Yeah. There's like a wave thing. Shimmers tends to storage. I don't like it. That's really like the term is Shimmer, shimmer. So these Shimmer, um, professional players actually can see it immediately. They understand it very well, but it's still something that requires certain amount of attention and, and, and it's kind of a bit annoying to deal with. Whereas for Alpha Star, in terms of vision, it's very hard for us to simulate sort of all, you know, are, are you looking at these pixels in the screen and so on. So, um, the only thing we can do is we, there is a unit that's invisible over there.

Speaker 2:          00:39:19       So Alpha Starwood know that immediately. Um, obviously still obeys the rules. You cannot attack the, you need, you must have a detector and so on. But it's, it's kind of one of the main things that he just doesn't feel there's, there's a very proper way. I mean, you could imagine, oh, you, you don't have hypers. Maybe you don't know exactly where it is, or sometimes you see it, sometimes you don't. But it's, it's just really, really complicated to get it so that everyone would agree, oh, that's, that's the best way to simulate these. Right. You know, it seems like a perception problem. It is a perception problem. So, so the only problem is people are, you ask her what's the difference between how humans perceive the game? I would say they wouldn't be able to tell a shimmer immediately as it appears on the screen. Whereas Alpha starting principal sees it very sharply, right?

Speaker 2:          00:40:05       It sees, it sees that the beat turned from zero to one, meaning there is now a unit there, although you don't know the unit or you don't know, you know, you know that you cannot attack it and so on. Um, so that from, from a vision standpoint, that probably is the one that is kind of the most obvious one. Then there are things humans cannot do perfectly, even professionals, which is they might miss a detail or they might have not seen a unit. And obviously as a computer, if there's a corner of the screen that turns green because a unit enters the field of view that can go into the memory of the agent, the LSTM and proceeds there for a while and for whatever for however long is relevant. Right. And in terms of action, uh, it seems like the rate of actions from Alpha stars comparative, it's not slower than professional players but is there but it's more precise as what right.

Speaker 2:          00:40:56       So, so that's, that's very, that's really probably the one that is causing us more issues for couple of reasons. Right. The first one is starcraft has been an AI environment for quite a few years. Um, in fact, I mean I was participating in the very first competition back in 2010 and there's really not been that kind of a very clear set of rules, how the actions per minute, the rate of actions that you can issue is and as a result of these agents or blogs that people build in a kind of almost very cool way. They do like 20,000, 40,000 actions per minute. Now now to put this in perspective, a very good professional human, my do 300 to 800 actions per minute. They might not be as precise. That's why the range is a bit tricky to, to identify exactly. I mean 300 actions per minute precisely is probably realistic.

Speaker 2:          00:41:53       Um, 800 is probably not. But you see humans doing a lot of actions because they warm up and they kind of select things and spam and so on, just so that when they need, they have the accuracy. So we came into this by not having kind of a standard way to say, well, how do we measure, um, whether an agent is at human level or not. On the other hand, we had the huge advantage, which is because we do imitation learning agents turned out to act like humans in terms of rate of actions, even precisions and in precisions of actions in the supervised policy, you could see all these, you could see how agents like to spam click to move here. If you played especially the outro, you wouldn't know what I mean. I mean, it was just dumb like spam or movie or Murphy or move here.

Speaker 2:          00:42:40       You're doing literally like, um, maybe five actions in two seconds. But these actions are not bay, meaning meaningful one would have sufficed. So on the one hand we start from these immigration policy that is at the ballpark of the actions per millions of humans because it's actually statistically trying to imitate humans. So we see these very nicely in the curves that we showed him, the blog posts, like there's these actions per minute and the distribution looks very human like, um, but then of course as self play kicks in and that's the buy, we haven't talked too much yet, but of course the agent mass played in itself to improve, then there's almost no guarantees that these actions will not become more precise or even the rate of actions is going to increase over time. Um, so what we did, and this is probably kind of the first of them that we thought was reasonable, is we looked at the distribution of actions for humans for certain windows of time.

Speaker 2:          00:43:36       And just to give a perspective, because I guess I mentioned that some of these agents that are programmatic, let's call them, they do 40,000 actions per minute. Professionals, as I said, do 300 to 800. So what we looked at is we look at the distribution over professional gamers and we took reasonably high actions per minute, but we kind of identify certain cutoffs after weeds. Even if the agent wanted to act, these actions would be dropped. But the problem is these cutoff is probably set a bit too high. And what ends up happening even though the games and when we as the professionals and the gamers by by and large, they feel like it's playing human. Like, um, there are some Asians that developed, um, maybe slightly too high aps, uh, which is actions per minute combined with the position. Um, which made people sort of start discussing a very interesting issue, which is should we limited these, should we just let it loose and see what cool things it can come up with? Right. Interesting. Um, so this is in itself an extremely interesting question, but the same way that modeling the Shimmer will be so difficult modeling. Absolutely. All the details about muscles and precision and tiredness of humans would be quite difficult. Right? So we really hear in kind of innovating in the sense of, okay, what could be maybe the next iteration of putting more rules that makes the agents

Speaker 3:          00:45:03       more human, like in terms of restrictions, putting constraints that more constraints. Yeah, that's really interesting. That's really innovative. So one of the constraints you put on your, on yourself, or at least focused in is on the protests race as far as I understand. Uh, can you tell me about the different races and how they, uh, so protest Taryn and a Zerg, how do they compare? How do they interact? Why did you choose protests? Right. Yeah, it's in the dynamics of the game scene from a strategic perspective.

Speaker 2:          00:45:35       So protose um, so in, in stock or if there are three races, um, indeed in the demonstration we saw only the protest race. So maybe let's start with that. One. Practice is kind of the most technologically advanced race. Um, it has units that are expensive but powerful, right? So in general, you want to kind of conserve your units, um, as you go attack. So you want to, and then you want to utilize these tactical advantages of very fancy spells and so on, so forth. Um, and at the same time, uh, there kind of people say like there, there'll be easier to play perhaps. Right. But that I actually didn't know. I mean I just talked to now a lot to the players that we work with Tlo and manner and they said, Oh yeah, protests is actually, people think is actually one of the easiest races. So perhaps the easier, that doesn't mean that it's know obviously professional players Xcel at the three races and there's never like a raise that dominates for debate long time anyways.

Speaker 3:          00:46:39       If you look at the top, I don't know, a hundred in the world, is there one race that dominates the lists?

Speaker 2:          00:46:44       It would be hard to know because it depends on the regions. I think. Um, it's pretty equal in terms of distribution and blizzard once it to be equal. Right. They don't want, they wouldn't want one raise like protest to not be representative in the top place. Right. Um, so definitely like they tried to be like the balance. Right. So then maybe the opposite race of Protos CCIRC Zurich is a raised where you just kind of expand and take over as many resources as you can and they have a very high capacity to regenerate their units. So if you have an army, it's not that valuable in terms of losing the whole army is not a big deal as Dirk because you can then rebuild it. And given that you generally accumulate a huge bank resources, um, Zurich's typically play by applying a lot of pressure, maybe losing the whole army but then rebuilding it quickly. So, um, although of course every race, I mean there's never, um, I mean they're pretty diverse. I mean, there are some units that are technologically advanced and they do some very interesting spells and there's some units in protests that are less valuable and you could lose a lot of them and rebuild them and it wouldn't be a big

Speaker 3:          00:47:54       deal. All right, so maybe I'm missing out, maybe I'm going to say some dumb stuff, but, uh, so summary of strategies. So first there's collection of a lot of resources, right? So that's one option. The other one is explore expanding, so building other basins. Then the other is obviously attack building units and attacking with those units. And then, uh, I don't know what else there is a, maybe there's the different timing of attacks, like do I attack early attack rate? What are the different strategies that emerged that you've learned about? I've read a bunch of people are super happy that you guys have apparently at Alpha Pi star apparel is discovered that it's really good to, uh, what does it saturate? Oh yeah. Let me know the line. Yeah, the mineral line is, yeah. Yeah. And that's a, for greedy amateur players like myself, that's always been a good strategy. You just build up a lot of money and he's just feels good to just accumulate and accumulate. Uh, so thank you for discovering that and validating all of us. But is there other strategies that you discovered interesting, a unique to a, to this game? Yeah. So

Speaker 2:          00:49:03       if you look at the kind of not being a starcraft two player, but of course starcraft, starcraft two and realtime strategy games in general are very similar. Um, I would classify perhaps, um, the openings of the game. They're very important. And generally I would say there's two kinds of openings. One that's standard opening. That's generally how players find sort of a, a balance between risk an economy and building some units early on so that they could defend but they're not to expose basically, but also expanding quite quickly. Um, so these, these would be kind of a standard opening and within a standard opening then you, what you do choose generally's what technology are you aiming towards? So there's a bit of rock paper, scissors of you could go for spaceships or you could go for invisible units or you could go for either not like massive units that attack against certain kinds of units, but they're weaker hands.

Speaker 2:          00:50:00       Others. So standard openings themselves have some choices like rock, paper, scissors style. Of course, if you scout and you're good at guessing what the opponent is doing, then you can play in as an advantage. Because if you know you're going to play rock, I mean I'm going to play paper obviously. So you can imagine that normal standard games, Instagram looks like a continuous rock paper, scissors game where you guess what the distribution of rock paper and Caesar is from the anime and reacting accordingly to try to beat it or you know, put the paper out before he kind of changes his mind from rock to Caesars and then you would be in a weak position. So sorry to pause on that. Yeah, I didn't realize this element because I know it's true. Put Poker and I looked at it Broaddus you're the CEO. You're also estimating trying to guess the distributor trying to better but our estimate the distribution, what the opponent is likely to be doing.

Speaker 2:          00:50:56       Yeah. I mean not as a player. You definitely want to have a belief state over what's APP on the other side of the map. Um, and when your belief state becomes inaccurate, when you start having that serious doubts, whether he's going to play something that you must know, that's when you, Scott, you want to then gather information, right? Is improving the accuracy of the belief or improving the belief state part of the loss that you tried to optimize? Or is it just an a side effect? It's implicit buttons lists. You could explicitly model it and it would be quite good at probably predicting what's on the other side of the map. But so far it's all implicit. The law, there's no, no additional reward for predicting the enemy. So there's these standard openings and then there's what people call it cheese, which is very interesting.

Speaker 2:          00:51:42       And Alpha Star sometimes really likes these kinds of cheese. Um, these cheeses, what they are is kind of an online strategy. You're going to do something sneaky, you're gonna hide enemies, hide your own buildings, close to the enemy base, or you're going to go for hiding your technology called buildings so that you do invisible units and the enemy just cannot react to the tactic and thus lose the game. And there's quite a few of these cheeses and variance of, of them and they're, it's where actually the belief state becomes even more important. Because if I scout your base and I see no buildings at all, any human prayer, know something's up, they might know, well you're hiding something close to my base. Should I build suddenly a lot of units to defense? You'll should I actually block my ramp with workers so that you cannot come and destroy my base.

Speaker 2:          00:52:33       So there's all these is happening and defending against Jesus is extremely important. And in the Alpha Star League, many agents actually double up some cheesy strategies. And in the games we saw against Tlo and manner, two out of the 10 agents were actually doing these kinds of strategies, which are cheesy strategies. And then there's a barrier of cheesy strategy we just called all in. So an all in strategy is not perhaps as drastic as, oh, I'm going to build cannons on your base and then bring all my workers and try to just disrupt your base and game over. Or Gigi, as we say in starcraft, um, there's these kind of very cool things that you can align precisely at the certain time mark. So for instance, you can generate exactly 10 unit composition. That is perfect. Like five of these type five of these other type and align the upgrade so that at four and a half, let's say you have these 10 units and the upgrade just finished and at that point that army is really scary and unless the enemy really knows what's going on, if you push, you might then have an advantage because maybe the enemy is doing something more standard.

Speaker 2:          00:53:42       It expanded to match it. It developed too much economy and and he'd trade off badly against having defenses and the enemy will lose, but it's called Arlene because if you don't win then you're going to lose. So you see players that do these kinds of strategies if they don't succeed, gave me, is not over. I mean they still have a base and they still gathering minerals, but they will just DJ out of the game because they know, well game is over. I gambled and I failed. So is if we start entering the game theoretic aspects of the game, it's really rich and it's really, that's why it also makes it quite entertaining to watch. Even if I don't play, I still enjoy watching the game. But the agents are trying to do these Mosley impressively, but one element that we improved in self place creating the Alpha state league and the Alpha Star League is not pure self play.

Speaker 2:          00:54:34       It's trying to create a different personalities of agents so that some of them will become cheese, cheesy agents. Some of them might become very economical, very greedy, like getting all, all the resources, but then being maybe early on they going to be weak, but later on they're going to be very strong. And by creating this personality of agents, which sometimes it just happens naturally that you can see kind of an evolution of agents that given the previous generation, they train against all of them and then they generate kind of the count, the perfect counter to that distribution. But these, these agents, you must have them in the populations because if you don't have them, you're not covered against these things, right? It's kind of you want to, you want to create all sorts of the opponents that you will find in the wild so you can be exposed to these cheeses early aggression later, aggression, more expansions, dropping units.

Speaker 2:          00:55:26       In your base from the site, all these things and pure self play is getting a bit stuck at finding some subset of these, but not all of these. So the Alpha Star League is a way to kind of do an in of agents that they're all playing in a league match. Like people play on Battle Net, right? They play, you play against someone who does newco strategy and you immediately, oh my God, I want to try it, I want to play again. And these to me was another critical part of the, of the, of the problem, which was can we create a battle net four agents? Yeah. That's kind of what the office star League fascinating

Speaker 3:          00:56:04       and where they stick to their different strategies. Yeah. Wow. That's, that's really, really interesting. So, but that said, you, uh, uh, we're fortunate enough or skilled enough to win five zero. Uh, and so how hard is it to win? I mean, that's not the goal. I guess. I don't know what the goal is. The goal should be doing majority,

Speaker 2:          00:56:24       not five zero. But how hard is it in general to win? Uh, all matchups I a one one V one. So that's a very interesting question because once you see Alpha Star and superficially you think, well, okay it one, let's if you, some of the games like 10 to one, right, they'd lost the game that it played with the camera interface. You might think, well that's, that's done right. There's, it's, it's super human at the game and that's not really the claim we really can make actually the claim is we beat a professional gamer for the first time. Um, start growth has really been a thing that has been going on for a few years. But

Speaker 2:          00:57:04       [inaudible] a moment like this hasn't not had not occurred before yet, but are these agents impossible to beat? Absolutely not. Right? So that's a bit what's, you know, kind of the differences the agents play at grandmaster level. They are definitely understand the game enough to play extremely well. Um, but are they unbeatable? Do they play perfect? Um, no, and actually in starcraft, because of these sneaky strategies, it's always possible that you might take a huge risk sometimes, but you might get wins right out of these. So I think that as a domain, it's still has a lot of opportunities, not only because of course we want to learn with less experience. We would like to, I mean, if I, if I learned to pray protests, I can play, turn and learn it much quicker than Alpha Star Canton. Right? So there are obvious interesting research challenges as well, but even as, as the raw, as the raw performance goes, um, really the claim here can be, we are at the pro level or at, at grant high grandmaster level.

Speaker 2:          00:58:08       Um, but obviously, um, the players also did not know what to expect, right? These kind of their prior distribution was a bit off because they played this kind of new like alien brain as they like to say drive. And that's what makes it exciting for them. But also, I think if you look at the games closely, you see there were weaknesses in some points. Maybe Alpha start did not scout or if it had had invisible units going against, at certain points it wouldn't have known and it would have been bad. So there's still quite a lot of work to do. Um, but it's really a very, very exciting moment for us to be seeing. Wow. A single neural net on a GPU is actually playing against these guys who are amazing. I mean, you have to see them play in life. They're really, really amazing players.

Speaker 4:          00:58:55       Yeah, I'm sure there's, there's a, there must, there must be a guy in Poland somewhere right now training his butt off to make sure that this never happens again with Alpha star. So that's really exciting in terms of Alpha star having some holes to exploit, which is great. And then you build on top of each other and it feels like starcraft, unlike go, even if you win, it's still not there. Still not there. So

Speaker 3:          00:59:22       many different dimensions in which you can explore. So that's really, really interesting. Do you think there's a ceiling to Alpha Star? You've said that it hasn't reached, you know, it's, this is a big, like what, let me actually just pause for a second. How did it feel to, to come here to this point to, to beat a top professional player like that night? I mean, you know, Olympic athletes have their gold medal, right? This is your gold medal sense. Sure. You're cited a lot. You've published a lot of procedures, papers, whatever. But this is like a win. Uh, how did it feel?

Speaker 2:          00:59:56       I mean it was, for me it was unbelievable. Um, because first the, we need south me, it was so exciting. I mean the, so looking back to those last days of 2018 really well, that's when the games were played. Um, I'm sure I, I look back at that moment, I say, oh my God, I want to be like in a project like that, it's like I already feel the nostalgia of like, yeah, that was huge in terms of the energy and the team effort that went into it. And so in that sense, as soon as it happened, I already knew it was kind of, I was losing it a little bit. So it is almost like sad that it happened and oh my God. But on the other hand, it also verifies the approach. Um, but to me also, there's so many challenges and interesting aspects of intelligence that even though we can train a neural network to play at the level of the best humans, um, there's still so many challenges.

Speaker 2:          01:00:54       So for me it's also like, well, this is really an amazing achievement, but I already was also thinking about next steps. I mean, as I said, these Asians play protest versus protos. Um, but they should be able to play a different race much quicker, right? So that would be an amazing achievement. Some people call these metal reinforcement learning, metal learning and so on, right? So there's so many possibilities after that moment, but the moment he'd solve it really felt great. Um, it's, I, we had these bets, so, so I, I'm kind of a pessimistic in general, so I kind of send an email to the team. I said, okay, let's against deal offers, right? Like what's going to be the result? And I really thought we would lose like five zero. Right? Aye. I, we had some calibration made against the 5,000 MMR player. Um, Dlo was much stronger than that player.

Speaker 2:          01:01:47       Even if he played protests, which is his off race. Um, but yeah, it was not imagined we would wait. So for me that was just kind of a test run or something. And then it really kind of, he was really surprised and unbelievably, we went to these, to these bar to celebrate and, and Dave thousand me, well wait, why don't we invite someone who is a thousand MMR stronger in protests, like an actual protest player like that. He ended up being manner. Right. And you know, we had some drinks and I said, sure, why not? But then I thought, well that's really going to be impossible to beat. I mean even because it is so much, I had a thousand MMR is really like 99% probability that Manna, we'd beat Tlo as protest versus protests. Right. So we did that and to me the second, the second game was much more important.

Speaker 2:          01:02:38       Even though a lot of uncertainty kind of disappeared after, we cannot beat the yellow. I mean he's a professional player, so that was kind of over. That's really a very nice achievement. But man, I really was at the top and you could see he played much better, but our agents got much better too. So it's a, and then after the first game, I said, if we take a single game, at least we can say we beat a game. I mean, even if we don't meet the serious, for me that was a huge relief and I mean, I remembered it. Hacking them is, and immediate was, it was really like these moment for me will resonate forever as a researcher. And I mean, as a person and a, yeah, it's a really great accomplishment and it was great also to be there with the team in the room. I don't know if you saw like, so it was really like, I mean, from my perspective,

Speaker 4:          01:03:25       the other interesting thing is just like watching Kasparov, uh, watching Mana, uh, was also interesting because he didn't, his kind of a a loss of words. I mean, whenever you lose, I've done a lot of sports. You sometimes say excuses, you look for reasons, right. And he couldn't really come up with reasons. Yeah. I mean, uh, uh, so with the offerings for protests, you could say it was, it felt awkward. It wasn't, but here it was. Yeah, it was, it was just beaten and it was beautiful to look at a human being being superseded by an AI system. And, um, it's a, it's a beautiful moment for, for researchers. So

Speaker 2:          01:04:04       yeah, for sure. It was, it was, I mean, probably the highlight of my career so far, um, because of its uniqueness and coolness and I don't know, I mean it's obviously, as you said, you can look at papers, citations and so on, but these, these really is like a testament of the whole machine learning approach, um, and using games to advance technology. I mean, it's really, it really was. Everything came together at that moment that that's really the summary.

Speaker 4:          01:04:29       Also on the other side, it's a popularization of AI too because it's just like traveling to a, to the moon and so on. I mean, this is where a very large community of people that don't really know AI, they get to really interact with it. Very important.

Speaker 2:          01:04:46       We must, um, you know, writing papers, hubs, our peers, researchers to understand what we're doing. But I think AI is becoming mature enough that we must sort of try to explain what it is and perhaps through games is, is a, an abusive way because these games always had built in AI. So it may be everyone experience an AI playing a video game even if they don't know, because there's always some scripted element and some people might even call that AI already. Right.

Speaker 4:          01:05:13       Uh, so what are other applications of a, the approaches underlying Alpha Star that you see happening? There's a lot of echoes of, he said, transformer of language modeling. So on, have you already started thinking where the breakthroughs in Alpha star get expanded to other applications?

Speaker 2:          01:05:32       Right. So I thought that about a few things for like kind of next month's, next years. Um, the main thing I'm thinking about actually is what's next as a, as a kind of a grand challenge because um, for me like we've seen a tardy and then there's like the, the sort of three dimensional walls that we've seen also like pretty good performance from these capture the flag agents that also some people at the mine and elsewhere are working on. We've also seen some amazing results on like for instance, Dota two which is also a very complicated game. So for me, like the main thing I'm thinking about is what's next in terms of challenge. So as a researcher I see sort of two tensions between research and then applications or areas or domains where you apply them. So on the one hand we've done thanks to the application of starcraft, he's very hard.

Speaker 2:          01:06:23       We develop some techniques, some new research that now we could look at elsewhere. Like are there other applications where we can apply this? And the obvious ones, absolutely you can think of. Um, feeding back to sort of the community we took from, which was mostly sequenced modeling or natural language processing. So we've developed or an extended things from the transformer and we use pointer networks. We combine LSTM and transformers in interesting ways. So that's perhaps the kind of lowest hanging fruit of feeding back to now. Um, different fields of machine learning that's not playing video games.

Speaker 4:          01:07:00       Let me go old school and jump to the, to Mr Alan Turing. Yeah. Uh, so the touring test, no, it says in natural language test to compensational tests. What's your thought of it as a test for intelligence? Uh, do you think it is a grand challenge that's worthy of undertaking? Maybe if it is, would you reformulate it or phrase it somehow differently?

Speaker 2:          01:07:23       Right. So I, I really love the touring test because I also like sequences and language understanding. And in fact some of the early work we did in machine translation, we tried to apply to apply to kind of a neuro chat bot. Um, which obviously would never pass the Turing test because it was very limited. But it is a very fascinating, fascinating idea that you could really have an AI that would be indistinguishable from humans in terms of asking or convert conversing with with it. Right. So I think the test itself seems very nice and it's kind of well defined actually like the, the passing it or not. I think there's quite a few rules that feel like pretty simple and, and, and you know, you could, you could really like have, I mean I think they have these competitions every year, so the Lug nut prize, but

Speaker 3:          01:08:16       I don't know if you've seen, eh, I don't know if you've seen the kind of, uh, bots that emerge from that competition. They're not quite as, um, what you would, uh, it feels like that there's weaknesses with the way touring formulated. It needs to be, uh, that the definition of a genuine rich, fulfilling human conversation and needs to be something else. Like the Alexa Prize, which I'm not as well familiar with, has tried to define that more, I think by saying you have to continue keeping a conversation for 30 minutes, something like that. Uh, so basically forcing the agent not to just fool, but to have an engaging conversation kind of thing. Is that, um, I mean, is this, have you thought about this problem richly? Like has, and if, if you have in general, how, how far away are we from? You worked a lot on language, uh, understanding language generation, but the full dialogue, the conversation. Yeah. You know, just sitting at the bar, having a couple of beers for an hour, that kind of conversation. Have you thought about,

Speaker 2:          01:09:23       yeah. So I think you'd touched here on the critical point, which is feasibility, right? So, so there's, there's a great sort of essay by humming, which describes sort of grand challenges of physics and he argues that, well, okay, for instance, teleportation or time travel are great grand challenges of physics, but there's no attacks we really don't know or cannot kind of make any progress. So that's why most physicists and so on, they don't work on these in their PhDs and, and as part of their careers. So I see the Turing test as I in the food Turing test as a bit still too early. Like I am. I think we're, especially with the current trend of deep learning language models, we've seen some amazing examples, I think gpt to being the most recent one, which is very impressive. But to understand, to fully solve

Speaker 2:          01:10:19       passing or fooling a human, to think that you're, that there's a human on the other side. I think we're quite far. So as a result, I don't see myself and I probably would not recommend people doing a phd on solving the Turing test because it just feels it's kind of too early or too hard of a problem. Yeah. But that said, you said the exact same thing about starcraft, but a few years ago, so in the two demos, so a, I agree. Yeah. You'll probably also be the person who passes the Turing test in three years. I mean, I think, I think that, yeah, so, so we have the sun record. This is nice. It's true. It's true. I mean the, the, it's through that progress. Sometimes it's a bit unpredictable. I really wouldn't have not I even six months ago, I would not have predicted the level that we see that these agents can deliver, um, at the grand master level.

Speaker 2:          01:11:07       But I, I have worked on language enough and basically my concern is not that something happen, a breakthrough could happen that would bring us to sobbing or passing the Turing test is that I just think the statistical approach to it like this, he is not, is not going to cut it. So we, we need, we need to break through, which is great for the community. Um, but given that I, I think there's quite a more uncertainty, whereas for starcraft, I knew what the steps would be to kind of get us there. I think it was clear that using the mutation learning part and then using these battlenet for agents, we're going to be key. And it turned out that this was the case and a little more was needed, but not much more for touring test. I just don't know what the plan or execution plan would look like. So that's why I'm, I myself working on it as a, as a grand challenge is hard. But there are quite a few sub challenges that are related that you could see. Well, I mean, what if you create a great assistant like Google already has like the Google Assistant. So can we make it better and can we make it fully new role? And so on that I start to believe maybe we're reaching a point where we should attempt these challenges.

Speaker 1:          01:12:20       I like La like this conversation so much because it echoes very much to start our conversation. It's exactly how you approach starcraft. Let's break it down into small pieces and solve those and you end up solving the whole game. Great. But that said, you, you're behind some of the sort of biggest pieces of work and deep learning in the last several years. So you mentioned some limits. What do you think of the current limits of deep learning and how do we overcome those limits?

Speaker 2:          01:12:47       So if I had to actually use a single wart to defined the main challenge in deep learning is a challenge. That probably has been the chance for many years. And he's that of generalization. So what that means is that okay, all that we're doing is feeding functions to data. And when the data we see ease, not from the same distribution or even if they're sometimes that it is very close to the distribution, but because of the way we train it with limited samples, um, we then get to these states where we just don't see generalization as much as we can generalize. And I think adversarial examples are a clear example of these. But if you study machine learning and literature and you know, the, the reason why svms came very popular where because they were dealing and they had some guarantees about generalization, which is unseen data or out of distribution or even within distribution where you take an image of adding a bit of noise, these models fail.

Speaker 2:          01:13:51       So I think really, I don't see a lot of progress on generalization in, in the strong generalization sense of the word. I think our newer neural networks, you can always find design examples that will make their outputs arbitrary, which is, which, which is not good because we humans will never be fooled by these kind of images or manipulation of the image. And if you look at the mathematics, you kind of understand this is a bunch of matrices multiplied together. Um, there's probably numerics and instability that you can just find corner cases. So I think that's really the underlying topic many times we see when, um, even even at the grand stage of like during tests generalization, I mean you've used, if you start passing the Turing test, should you, should it be in English or should it be in any language? Right? I mean, as a human, if you could, you could, if you ask something in a different language, you actually will go and do some research and try to translate it and so on.

Speaker 2:          01:14:57       Should the Turing test include, include that? Right. And it's really a difficult problem and very fascinating and very mysterious actually. Yeah, absolutely. But do you think it's, if you were to try to solve it, can you not grow the size of data intelligently in such a way that the distribution of your training set does include the entirety of the testing set? I think is that one path. The other path is totally new methodologies, not statistical. So a path that has worked well and it worked well even in starcraft and in machine translation and in languages scaling up the data and the model. And that's kind of been maybe the only single formula that the leap still delivers today in deep learning, right? It's, it's that scale data scale and mother's care really do more and more of the things that we thought, oh, there's no way it can generalize to these or if there's no way it can generalize to that, but I don't think fundamentally it will be solved with this.

Speaker 2:          01:15:54       And for instance, I'm really liking, um, some style or approach that would not only have neural networks but it would have programs or some discrete decision making because there is where I feel there's a bit more like, like I mean the example of the best example I think for understanding disease. Um, I also work to be done or like we can learn an algorithm with a neural network, right? So you're given many examples and needs is going to sort your sort of the input numbers or something like that. But really strong generalization is you give me some numbers or you asked me to create an algorithm that sorts numbers and instead of creating a neural net, which will be fragile because it's going to go out of range, at some point you're going to give you the numbers that are too large, too small and whatnot. You just, if you just create a piece of code that sorts the numbers, then you can prove that that will generalize to absolutely all the possible input you could give. So I think that's the problem comes with some exciting prospects. I mean scale is a bit more boring, but it really works. And then maybe programs and discrete abstractions are a bit less developed. But clearly I think they're quite exciting. In terms of future for the field,

Speaker 4:          01:17:09       do you draw any insight, wisdom from the 80s and expert systems and symbolic systems of all competing? Do you ever go back to those sort of reasoning, that kind of logic? Do you think that might make a comeback? You'll have to dust off those books?

Speaker 2:          01:17:24       Yeah, I actually love actually I think more inductive biases. Um, the problem really is what are you trying to solve? If what you're trying to solve is so important that tried to solve it no matter what, then absolutely use rules, use domain knowledge and then use a bit of the magic of machine learning to empower to make the system as the best system that will detect cancer or, or, um, you know, or, or the tech weather patterns. Right. Or in terms of stock graphics also was a very big challenge. So I was definitely happy that if we had to get take catercorner here and that it could have been interesting to do. Um, and in fact in stacker of wheat we start thinking about expert systems because it's a very, you know, you can differ, I mean people actually build stacker up boards by thinking about those principle like state machines and a rule based.

Speaker 2:          01:18:20       And then you could, you could think of combining a bit of a rule based system, but that has also neuro networks incorporated to make it generalize that we'd better. So absolutely. I mean we should, we should definitely go back to those ideas and anything that makes the problem simpler as long as your problem is important, that's okay. And that's research driving a very important problem. And on the other hand, if you want to really focus on the limits of reinforcement learning, then of course you must try not to look at a mutation data or to you to look some like for some rules of the domain that would help a lot or even feature engineering, right? So these, these attention that depending on what you do, I think both, both ways are definitely fine and I would never not do one or the other if you're, as long as you, what you're doing is important and needs to be soft. Right? Right.

Speaker 4:          01:19:10       Uh, so there's a bunch of different ideas that, that um, that you developed that I really enjoy. So, but one, one is a translating from some image captioning trends, any family shit text. She's just another just beautiful, beautiful idea. I think that um, resonates throughout your work actually. So does the underlying nature of reality being language always somehow. Uh, so, uh, what's the connection between images and texts, the rather the visual world and a world of language in your view?

Speaker 2:          01:19:46       Right. So I think a piece of research that's been central to, I would say even extending into starcraft is this idea of sequence to sequence learning. Which what we really meant by that is that you can, you can now really input anything to a neural network as the input x. And then low neural network will learn a function f that will take acts as an input. And produce any output y and these x and y's don't need to be like static or like features like a scene, like a fixed back doors or anything like that. He could be really sequences and now beyond like data structures, right? So that paradigm was tested in a very interesting way when we moved from translating French to English to translating an image too. It's caption, but the beauty, the beauty of it is that really, and that's actually how it happened.

Speaker 2:          01:20:42       I ran, I change a line of code in this thing that was doing machine translation. I and I came the next day and I saw how it, like it was producing captions that seemed like, Oh my God, this is really, really working. And the principle is the same, right? So I think I don't see texts, vision, speech waveforms as something different. Um, eat as long as you basically learn a function that will vectorize you know, these into. And then after we vectorize it, we can then use transformers. LSTM is whatever the flavor of the month of the model is a and then as long as we have enough supervised data, really, um, these formula will work and we'll keep working, I believe to some extent model of these generalization issues that I mentioned before.

Speaker 4:          01:21:34       So, but the testers to vectorize sort of former representation as meaningful and your intuition now having worked with all this media is that once you, uh, are able to form that representation, you could basically take any things and you sequence is there, the, going back to starcraft, is there limits on the length, uh, so that we didn't really touch on the long term aspect. How did you overcome the whole really long term aspect of things here? Is there some tricks or zone?

Speaker 2:          01:22:05       The main street, so starcraft, if you look at absolutely every frame you might think it's, it's quite a long game. So we would have to multiply 22 times, 60 seconds per minute times, maybe at least 10 minutes per game on average. So there are quite a few frames, but the trick really was too only observed in fact, which may be seen as a limitation, but it is also a computational advantage only observe when you act and then what the neural network decides is what is the gap going to be until the next action. Um, and if you look at most starcraft games that we have in the, in the data set that bleeds provided, it turns out that most games are actually only, I mean it is still a long sequence, but it's maybe like a thousand to 1500 actions, which if you start looking at Alice dms, large Lstm is transformers.

Speaker 2:          01:23:08       It's not like it's not that that difficult, especially if you have supervised learning. If you had to do it with reinforcement learning, the credit assignment problem, what is it that in this game that made you, when that will be really difficult. But thankfully because of imitation learning, we didn't kind of have to deal with these directly. Although if we had to, we tried it. And what happened is you just take all your workers and attack with them. And that sort of, it's kind of obvious in retrospect because you start trying random actions. One of the actions will be a worker that goes to the enemy base and because it's self plate, it's not going to know how to defend because he basically doesn't know almost anything. And eventually what you double up is this, take our workers and attack. Um, because the, the, the, the create assignment issue in our rally is really, really hard. I do believe we could do better and that's maybe a research challenge for the future. Um, but yeah, even even in starcraft, the sequences are maybe a thousand, which I believe there is within the realm of what transformers can do.

Speaker 1:          01:24:10       Yeah. I guess the difference between starcraft and go is go and chest stuff starts happening right away. Right? So there's not, yeah, it's pretty easy to self plant, not easy, but through selfless as possible to develop reasonable strategies as quickly as opposed to starcraft.

Speaker 2:          01:24:27       In gold, there's only 400 actions, but one action ease, what people would call the God action. That would be if you had expanded the whole search three, that's the best action. If you did mini macs or whatever algorithm you would do if you had the computational capacity. But in starcraft, the 400 is, is, is miniscule like in 400. You don't even like you, you couldn't even click on the pixels around a unit. Right. So, um, I think the problem there is in terms of action, space size is way harder. So does surge is impossible. So there's quite a few challenges in deed that make these, um, kind of a step step up in terms of machine learning for humans, maybe they playing starcraft is seems more intuitive because it's, it looks real. I mean, you know, like get the graphics and everything moves smoothly. Whereas I, I don't know how to, I mean, go is like a game that I wouldn't really need to study. It feels quite complicated, but for machines kind of maybe he the reverse. Yes. Well, it shows you the gap actually between a deep learning and however the heck our brains work. Uh,

Speaker 1:          01:25:33       so you developed a lot of really interesting ideas. It's, it's to just ask, what's the, what's your process of developing new ideas? Do you like brainstorming with others? Do you like thinking alone? Do you like a,

Speaker 2:          01:25:46       uh,

Speaker 1:          01:25:47       like a, was it Ian Goodfellow said he came up with gans after a few beers.

Speaker 2:          01:25:51       Uh, right. He thinks beers are essential for coming up and new ideas. We had beers to decide to play another game game of or after a week. So it's really similar to that story. Actually explain these in a, in a deepmind retreat and I said this is the same as the gun story. I mean, we were in a bar and we decided let's play again next weekend. That's what happened. I feel like we're doing the wrong message to young undergrads. Yeah, no, but in general, like, yeah. Do you like brainstorming? Do you like thinking alone, working stuff out? And so I think, I think throughout the years also things change, right? So, um, initially I was very fortunate to be, um, with great minds like Geoff Hinton, Jeff Dean Elliott, Sutzkever. I was really fortunate to join brain at a very good time. So at that point it ideas, I was just kind of brainstorming with my colleagues and learned a lot and keep learning is actually something you should never stop doing.

Speaker 2:          01:26:47       Right? So learning implies reading papers and also discussing ideas with others. It's very hard at some point to not communicate that being reading a paper from, from someone or actually this cussing. Right? So definitely, um, that communication aspect needs to be there whether it's written or oral. Um, nowadays I'm also trying to be a bit more strategic about what research to do. So I was describing a little bit this sort of tension between research for the sake of research. And then you have on the other hand applications that can drive the research right? And honestly, the formula that has worked best for me is just find a heart problem and then try to see how research feeds into it, how it doesn't fit into it, and then you must innovate. So I think machine translation drove sequence to sequence. Um, then maybe like learning algorithms that had to like communitorial algorithms led to pointer networks.

Speaker 2:          01:27:50       Starcraft led to really scaling up in mutational learning. And the Alpha Star League. So that's been a formula that I personally like, but the other one is also buried. And I seen it succeed a lot of the times where you just want to investigate model based RL as, as a kind of a research topic. And then you must then start to think, well, how are the tests? How are you going to test these ideas? Um, you need to kind of a minimal environment to try things. You need to read a lot of papers and so on. And that's also very fun to do. And something I've also done quite a few times, um, both at, at brain, at the mine and obviously as, as a PLC. So, so I think besides the, the ideas and discussions, I think it's important also because you start sort of guiding not only your own goals but other people's goals, um, to the next breakthrough.

Speaker 2:          01:28:43       So you must really kind of understand these, you know, feasibility also as we were discussing before, right? Weather whether these domain is ready to be tackled or not. And you don't want to be too early. You obviously don't want to be too late. So it's, it's really interesting. Um, these are strategic component of research, which I think as a Grad student I just had no idea to read papers and discussed ideas and I think this has been maybe the major change and I recommend people kind of feed forward to success how it looks like and try to back track other than just kind of looking out at these looks cool, these looks cool. And then you do a bit of random work, which sometimes you stumble upon some interesting things. But in general it's, it's also good to plan a bit. Yeah. Like it, uh, especially like your approach of taking a really hard problems, stepping right in and then being super skeptical about yeah.

Speaker 2:          01:29:35       Being a, I mean there, there's a balance of both, right? There's a silly optimism and a, and a critical, uh, sort of a skepticism that's good to balance, which is why it's good to have a team of people that's that balance that you don't do that on your own. You have both mentors that have seen or you obviously you want to chat and discuss whether it's the right time. I mean that means came in 2014 and he said maybe in a beat we'll do starcraft and maybe he knew and that's, and I'm just following his lead, which is great because he's, he's brilliant, right? So these, these things are obviously quite important that you want to be surrounded by people who, you know, are diverse. They have their knowledge, their there is also important too. I mean, I, I've, I've learned a lot from people who actually have an idea that I might not think it's good, but if I give them the space to try it, I've been proven wrong many, many times as well.

Speaker 2:          01:30:36       So that's great. It's, I think it's, um, your colleagues are more important than yourself. I think so. Sure. Now, uh, let's real quick talk about another impossible problem. Uh, Agi, right? What do you think it takes to build a system that's human level intelligence? We talked a little bit about the Turing test dark after all these have echoes of general intelligence. But if you think about just something that you would sit back and say, wow, this is really something that resembles human level intelligence, what do you think it takes to build that? So I find that Agi, oftentimes it's maybe not very well defined. So what I'm trying to then come up with for myself is what would be a result look like? That you would start to believe that you would have agents or neural nets that no longer sort of over feet to a single task, right?

Speaker 2:          01:31:31       But actually kind of learn the skill of learning, so to speak. And that actually is a field that I am fascinated by, which is the learning to learn or metal learning, which is about no longer learning about the single domain. So you can think about the learning algorithm itself is general, right? So the same formula we applied for Alpha star or starcraft, we can now apply to kind of almost any video or you could apply to many other problems and domains. But the algorithm is what's kind of generalizing, but the neural network, the weights, those weights are useless even to play another race. Right? I train a network to play very well at products versus products. I need to throw away those weights. If I want to play now Taryn versus Taryn, I would need to retrain and Edward from scratch we'd the same algorithm.

Speaker 2:          01:32:24       That's beautiful but the network itself will not be useful. So I think when I, if I see an approach that can absorb or start solving new problems without the need to kind of restart the process, I think that to me would be a nice way to define some form of Agi. Again, either know the grandiose like age, I mean he should during test we saw before Agi. I mean I don't know. I think, I think concretely I would like to see clearly that metal learning happen. Meaning there there is and architecture or network that as it sees new, new problem or new data it solves it and to make it kind of a benchmark, each should solve it at the same speed that we do solve new problems. When I define your new object and you have to recognize it. When I, when you start playing a new game, you played all the time, the games, but now you play a new Atari game. Well you, you're going to be pretty quickly, pretty good at the game. So that's perhaps what, what's the domain and what's the exact benchmark is a bit difficult. I think as a community we might need to do some work to define it, but I think this first step I could see it happen relatively soon, but then the whole, what Agi means and so on, I am a bit more confused about what I think people mean different things. There's an emotional, psychological level that, um,

Speaker 3:          01:33:50       like even the Turing test passing the Turing test is something that we just pass judgment on as human beings. What it means to be, you know, as a, as a, as a dog a is an s an AGI system. Yeah. Like what level? What does it mean? Uh, right? Yeah. What does, what does it mean? But I liked the generalization, and maybe as a community would converge towards a group of domains that are sufficiently far away. There'll be really damn impressive if Fossa able to generalize some, perhaps not as close as protests. And Zurg was like, yeah, could be a good stuff. And then the really good stuff, but then then like could from starcraft two Wikipedia. Yeah. And back. Yeah. That kind of thing. And that, that feels also quite hard and far. But

Speaker 2:          01:34:35       I think this, as long as you put a benchmark out, as we discovered for instance, with image net, then tremendous progress can be had. So I think maybe there's a lack of benchmark, but I'm sure we'll find one and the community, we'll, we'll then work towards that. MMM. And then beyond what Agi might mean or would imply, I really am hopeful to see basically machine learning or AI just scaling up and helping people that might not have the resources to hire an assistant or that, uh, they might not even know what the weather is like, but you know, so, so I think there's, in terms of the impact, the positive impact of Ai, I think that's maybe what we should also not lose focus, right? The research community building edgy. I mean, that's a real nice goal, but a man, I think the way that deep mind puts it is, and then use it to solve everything else. Right? So I think we should penalize.

Speaker 3:          01:35:33       Yeah. We shouldn't forget of all the, all the positive things that are actually coming out of AI already and they're going to be coming out. Right. But that, and then, no, let me ask, uh, relative to the popular perception, do you have any worry about the existential threat of artificial intelligence in the near or far future that some people have?

Speaker 2:          01:35:55       I think I'm in the near future. I'm, I'm skeptical, so I'm hope I'm not wrong. But I'm, um, I'm not concerned, but I appreciate efforts, ongoing efforts and even like whole research field on AI safety emerging and in conferences and so on. I think that's great. Um, in the long term, I really hope we just can't simply have the benefits outweigh the potential dangers. I am hopeful for that. Um, but also we must remain vigilant to kind of monitor and assess whether the tradeoffs are, are there and, and, and we have, you know, enough, I'm also lead time to prevent or to redirect our efforts if need be. Right. So, um, but I'm, I'm quite, I'm quite optimistic about the technology and definitely more fearful of other threats in terms of planetary level, um, at, at this point. But obviously that's the one I kind of have more power on. So clearly I do start thinking more and more about these and it's kind of, it's grown in me actually to, to start reading more about AI safety, which is a fuel that so far I have not really contributed to, but maybe

Speaker 3:          01:37:06       there's something to be done there as well. I think it's really important. You know, I, I talk about this a few folks, but it's important to ask you and shove it in your head because you're at the leading edge of actually, uh, what people are excited about and AI, I mean the work with Alpha star it, it's arguably at the very cutting edge of the kind of thing that people are afraid of. And so you speaking to that fact and uh, that we're actually quite far away to the kind of thing that people might be afraid of, but it's still worthwhile to think about in a salsa. Good that you're, uh, the, you're not as worried and you're also open to us.

Speaker 2:          01:37:45       Yeah, I mean there's two aspects. I mean me not being worried, but obviously we should prepare for four, four, eight rides for, for like, for, for things that could go wrong. Misuse of the technologies as, as with any technology is, right. So I think there's, there's always trade offs and I, as a society, we've kind of solved these to some extent with in the past. So I'm hoping that by having the researchers and the whole community brainstorm and come up with interesting solutions to the new things that will happen in the future, that we can still also push the research to the avenue that I think is kind of the greatest avenue, which is to understand intelligence, right? How are we doing what we're doing? Um, and you know, obviously from a scientific standpoint that is kind of the drive my personal driver or all the time I spend doing what I'm doing.

Speaker 2:          01:38:38       Really. Where do you see the deep learning as a field heading? What do you think the next big, big breakthrough? My B. So I think deep learning, I discuss a little of these before. Deep learning has to be combined with some form of democratization programs, indices. I think that's kind of as a researching itself is an interesting topic to expand and start doing more research. Uh, and then as kind of what we'll deep learning and able to do in the future. I don't think that's going to be what's going to happen this year, but also this idea of starting not to throw away all the ways that this idea of learning to learn and really having, um, these agents not having to restart their weights. And you, you can have an agent that is kind of solving or classifying images on image net but also generating speech if you ask it to generate some speech.

Speaker 2:          01:39:34       And, and it should really be kind of almost the same network, but my boat, none. That might not be a neural network. It might be a neural network with a optimization algorithm attached to it. But I think this idea of generalization to new task is something that we first must defined good benchmarks, but then, uh, I think that's going to be exciting. And I'm not sure how close we are, but I think there's, if you have a very limited domain, um, I think we can start doing some progress and more much like how we did a lot of programs in computer vision, we should start thinking, am I real like a talk that I gave that [inaudible] cave at ICML a few years ago, which is these trained tests paradigm should be broken. We, you know, we should stop thinking about a training test at, at, sorry, a training set and a test set and these are closed, you know, things that are untouchable. I think we should go beyond these. And in metal learning we call these the metta training set and the metatarsal, which is really thinking about, if I know about image net, why would that network not work on [inaudible], which is a much simpler problem. But right now it really doesn't it, you know, but it, it just feels wrong. Right? So I think that's kind of the, there's the, uh, on the application or the benchmark sites, we probably see quite a few more interest and progress and hopefully people defining new and exciting challenge is really,

Speaker 1:          01:41:00       do you have any hope or interest and knowledge graphs within this context? So this is kind of totally, yeah. Constructing Gra. So going back now, graphs, yeah, well neural networks and graphs, but I mean a different kind of knowledge graph. Uh, uh, sort of, uh, like semantic grass or there's concepts.

Speaker 2:          01:41:18       Yeah. So I think, I think the, um, the idea of graphs is, is, so I've been quite interested in sequences first and then more interesting or different data structures like graphs. And I've studied graph neural networks, um, in the last three years or so. I, uh, I found these models just very interesting from like deep learning sites standpoint. Um, but then how, how, what do we want, why do we want these models are, and why would we use them? What's the application? What's kind of the killer application of graphs? Right, right. And perhaps if we could extract a knowledge graph from Wiki automatically, that would be interesting because then these graphs have these very interesting structure that also is a bit more comfortable with this idea of programs and deep learning, kind of working together, the jumping neighborhoods and so on. You could imagine defining some primitives to, to go around and graphs.

Speaker 2:          01:42:18       Right. So I think I really liked the idea of a knowledge graph and in fact when we, we started or you know, as part of the research we did for starcraft, I thought, wouldn't it be cool to give the graph of all the Prereq? There's like there's all these buildings that depend on each other and you need that, have prerequisites of being billed by that. And so this is information that the network can learn an extract, but it would have been great to see, um, or to think of really starcraft as a giant graph that even also as the game evolves, you just kind of started taking branches and so on. And we try, we, we, the bit of research on these, nothing too relevant. Um, but I, I really liked the idea

Speaker 1:          01:43:04       and it has elements that are, which something you also worked with in terms of visualizing, you'll network says elements of having human interpretable, uh, being able to generate knowledge representations that are human interpretable that maybe human experts can then tweak or at least understand the, so there's a lot of interesting aspect there. And for me personally, I'm just a huge fan of Wikipedia and, and it's a shame that, uh, our neural networks aren't taking advantage of all the structured knowledge and that's on the web. What's next for, uh, for you, what's next for deep mind? What are you excited about? What a for Alpha Star.

Speaker 2:          01:43:39       Yeah, so I think the obvious next steps would be too apply Alpha star too. Other races. I mean that's sort of shows that the algorithm works because we wouldn't want to have created by mistake something in the architecture that happens to work for protests but not for other races. Right. So Asbury effication I think that's an obvious next step that we are working on. And then I would like to see, so agents and players can specialize on different skillsets that allow them to be very good. I think we've seen Alpha start understanding very well when to take battles and when to not to do that. Do that. Also very good at micro management and moving the units around and so on. And also very good at producing nonstop and trading of economy with building units. But I have not perhaps seen as much as I would like this idea of the poker idea that you mentioned.

Speaker 2:          01:44:39       Right. I'm not sure it's stacked graph or Alpha star rather has developed a deep understanding of what the opponent is doing and reacting to that and sort of trying to to, to treat the player to do something else or that, you know, so these kinds of reasoning I would like to see more. So I think purely from a research standpoint, um, there's perhaps also quite a few, a few things to be done there in the domain of starcraft. Yeah. In the domain of games. I've seen some interesting work in sort of a, and even auctions manipulating other players. So forming a bleed state and just messing with people. So theory of mind. Yep. So it's a fascinating, exactly. Theory of mine on stock, or if he's kind of, they're really made for each other. So that will be very exciting to see those techniques applied to starcraft or perhaps starcraft driving new techniques. Right. As as, as I said, this is always the tension between the two. Well, oil, thank you so much for talking today. Awesome. It was great to be here. Thanks.