Speaker 1:          00:00          The following is a conversation with Elon Musk. He's a CEO of Tesla, SpaceX Neuralink and a co founder of several other companies. This conversation is part of the artificial intelligence podcasts. The series includes leading researchers in academia and industry including CEOs and Ctos of automotive, robotics, AI at technology companies. This conversation happened after the release of the paper from our group at MIT on driver functional vigilance during use of Tesla's autopilot. The Tesla team reached out to me offering a podcast conversation with mister Musk. I accepted with full control of questions I could ask and the choice of what is released publicly. I ended up editing out nothing of substance. I've never spoken with Ilan before this conversation publicly or privately, neither he nor his companies have any influence on my opinion, nor on the rigor and integrity of the scientific method that I practice them a position and MIT.

Speaker 1:          01:01          Tessa has never financially supported my research and I've never owned a Tesla vehicle. I've never owned Tesla stock. This podcast is not a scientific paper. It is a conversation. I respect Ilan as I do all other leaders and engineers have spoken with. We agree on some things and this is a grant. Others, my goal is always with these conversations is to understand the way the guests sees the world. One particular point of disagreement in this conversation was the extent to which camera based driver monitoring will improve outcomes and for how long it would remain relevant for AI assisted driving. As someone who works on and is fascinated by human centered artificial intelligence, I believe that if implemented an integrated effectively camera based driver monitoring is likely to be of benefit in both the short term and the longterm. In contrast, Elan and Tesla's focus is on the improvement of autopilot such that it's statistical safety benefits override any concern of human behavior and psychology.

Speaker 1:          02:09          Elon and I may not agree on everything, but I deeply respect the engineering and innovation behind the efforts that he leads. My goal here is to catalyze a rigorous nuanced and objected discussion in industry and academia on AI assisted driving, one that ultimately makes for safer and better world. And now here's my conversation with Elon Musk. What was the vision, the dream of autopilot when uh, in the beginning, the big picture system level when it was first conceived and started being installed in 2014 and the hardware and the cars. What was the vision? The dream I would characterize as vision or dream it's, and we've got there obviously two massive revolutions in, in the automobile industry.

Speaker 2:          03:00          One is the transition to electric electrification. Um, and then the other is autonomy and yeah, it became obvious to me that in the future any, any car that does not have autonomy, I would be about as useful as a host. Which is not to say that there's no use, it's just rare and somewhat it isn't Craddick if somebody has a horse at this point, it's just obvious that cars will drive themselves completely. It's just a question of time. And if we did not participate in the autonomy revolution than our costs would not be useful to people relative to cars that are autonomous, not autonomous car is arguably worth five to 10 times more than I call, which is not autonomous in a longterm trends. What you mean by long term. But let's say at least for the next five years, path, 10 years.

Speaker 1:          04:01          So there a lot of very interesting design choices with autopilot early on. First is showing on the instrument cluster or in the model three and the center stack display what the combined sends the sweet seas. What was the thinking behind that choice? Was there a debate? What was the process?

Speaker 2:          04:20          The whole point of the display is to provide a health check on the, the vehicles perception of reality. So the vehicles, uh, taking in information for a bunch of sensors, primarily cameras, but also radar ultrasonics, a gps and so forth. And then, uh, that that information is then rendered into vector space. Uh, and that, you know, with a bunch of objects with PR, with properties like lane lines and traffic lights and other cars. Um, and then in vector space that is rerender it onto a display so you can confirm whether the car knows what's going on or not by looking out the window. Right.

Speaker 1:          05:03          I think that's an extremely powerful thing for people to get an understanding. So it become one with the system and understanding what the system is capable of. Now have you considered showing more? So if we look at the computer vision, you know like road segmentation, lane detection, vehicle detection, object detection, underlying the system there is at the edges some uncertainty. Have you considered revealing the parts that the, the uncertainty in the system, the set apart movies associated with with say image recognition or something that code right now it shows like the vehicles in the vicinity of very clean, crisp image and people do confirm that there's a car in front of me and the system sees there's a car in front of me. But to help people build an intuition of what computer vision is by showing some of the uncertainty,

Speaker 2:          05:53          well, I think I'm in my car. I always look, look at this sort of the debug view and it's theirs to debug views. Uh, W one is augmented vision, uh, where, which I'm sure you've seen where it basically we draw boxes and labels around objects that are recognized and then there's what we call the visualizer, which is basically a vector space representation. Summing up, uh, the input from all sensors that that doesn't, does not show any pictures, but it shows, uh, all of the, it's basically shows that cause view of, of, of the world in vector space. Um, but I think this is very difficult for people to know. Normal people to understand. They were not know what the heck they're looking at. He said it's almost an Asian. My challenge to the current things that are being displayed is optimized for the general public understanding of what the system is capable of.

Speaker 2:          06:48          It's like if have no idea what, how computer vision works or anything, you can still look at the screen and see if the car knows what's going on. And then if you're, you know, if you're a development engineer or if you're, you know, if you're, if you have the development bold like I do, then you can see, uh, you know, all the debugging information. But those were just be like total diverse to most people. What's your view on how to best this effort? So there's three, I would say technical aspects of autopilot that I really important. It's just the underlying algorithms like the neural network architecture. There's the data so that the strain on, and then there's the hardware development and maybe others. But so look, algorithm data, hardware, you don't, you only have so much money. I only have so much time. What do you think is the most important thing to, to uh, allocate resources to do you see it as pretty evenly distributed between those three?

Speaker 2:          07:44          We automatically get a fast amounts of data because all of our cars have eight external facing cameras and radar and usually 12 ultrasonic sensors. Uh, GPS obviously. Um, and I am you. And so we basically have a fleet that has, uh, and we've got about 400,000 cars on the road that have that level of data. Actually, I think you keep close track of it actually. Yes. Yeah. So we're, we're approaching half a million cars on the road that have the full sensor suite. Yeah. Though, so this is, I'm, I'm not sure how many other cars on the road have this central suite, but I'd be surprised if it's more than 5,000, which means that we have 99% of all the data. So there's this huge inflow of data, absolutely massive inflow of data. And then we, it's, it's taken about three years, but now we're finally developed off full self driving computer, which can process an order of magnitude as much as the nvidia system that we currently have in the, in the cars.

Speaker 2:          08:56          And it's really just a, to use it, you unplug the Nvidia computer and plug that tells the computer in and that's it. And it's, it's uh, in fact we're not even, we still exploring the boundaries of capabilities. Uh, we were able to run the cameras at full frame rate, full resolution, uh, not even crop the images. And it's still got headroom even on one of the systems, the harder the full self driving computer is really two computers, two systems on a chip that a fully redundant. So you could put a bolt through basically any part of that system. And it still works. There were done and see are they perfect copies of each other or also it's purely for a diamond C as opposed to an argue machine kind of architecture where they're both making decisions. This is purely for redundancy. I think even more like it's, if you ever say a twin engine aircraft, commercial aircraft, this system will operate best if both systems are operating, but it's, it's capable of operating safely on one.

Speaker 2:          09:56          So, but as it is right now, we can just run, we're, we haven't even hit the, the, the, at the edge of performance. So there's no need to actually distribute to functionality across both soc. We can actually just run a full duplicate on each one. Do you haven't really explored or hit the limit of the soon? Not yet at the limit. No. So the magic of deep learning is that it gets better with data. And he said there's a huge inflow of data. But yeah, the thing about driving the really valuable data to learn from as the edge cases. So how do you, I mean, I've, I've heard you talk somewhere about, uh, autopilot disengagements being an important moment of time to use. Is there other edge cases or perhaps can you speak to those edge cases? What aspects of that might be valuable or if you have other ideas, how to discover more and more and more agile cases in driving?

Speaker 2:          11:00          Well, there's a lot of things that learnt though. Suddenly a edge cases where I say somebody is on autopilot and they take over and then, okay, that, that, that that's a trigger that goes up to a system that says, okay, did the trip, the takeover for convenience or do they take over because the autopilot wasn't working properly. There's also like, let's say what we're trying to figure out, what is the optimal spline for traversing at an intersection? Um, then then the ones where there are no interventions and we, uh, are the right ones. So you then say, okay, when it looks like this, do the following and the, and the, and, and then you get the optimal spine for a complex, uh, now getting a complex intersection. So that's for this or this kind of the common case, you're trying to capture a huge amount of samples of a particular intersection.

Speaker 2:          11:53          How when things went right and then there's the edge case where as you said, not for convenience but something didn't go exactly right. Somebody took over, somebody sorted manual control from autopilot and it really like the way to look at this as view all input as error. If the user had to do input it though something, all input is error. That's a powerful line to think of it that way because they may very well be air, but if you want to exit the highway or if you want to uh, isn't navigation decision that all autopilots not currently designed to do, then the driver takes over. How do you know the difference is going to change with navigate an autopilot which were just released and without stoking phone. So the navigation like lane lane change based, it like assuming control in order to change their lane change or exit the freeway or, or doing highway interchange.

Speaker 2:          12:44          The vast majority of that will go away with the release that just went out. He has that. I don't think people quite understand how big of a step that is. Yeah, they don't. So if you drive the car then you do, so you still have to keep your hands on the steering wheel. Currently. When it does the automatic lane change, what are, so there's these, these big leaps through the development of autopilot through its history and what stands out to you as the big leaps? I would say this one, navigate and autopilot without, uh, confirm what I'll having to confirm is a huge leap. It was a huge leap, automatically overtakes low cars. So it's, it's both navigation and seeking the fastest lane. So it'll, it'll, it'll to overtake slow cars, um, and exit the freeway and take highway interchanges and, and then, uh, we have a traffic light traffic lights to recognition, which introduced initially as a, as a warning. I mean on the development version that I'm driving the car fully, fully stops and goes at traffic lights. So those are the steps. Right. You've just mentioned somethings that an inkling of a step towards full autonomy. What would you say are the biggest technological roadblocks to full cell driving? Actually, I don't think we're, I think we're just the full self driving computer that we're just the Tosa, oracle, the FSD computer, uh, that, that's now in production.

Speaker 2:          14:21          Uh, so if your order, uh, any model SRX or any model three that has the full self driving package, you will get the FSD computer that that was, that's important to have enough base computation. Uh, then refining the neural net and the control software. Uh, but all of that can just be providers know their update. The thing that's really profound and where I'll be emphasizing at the sort of what the investor day that we're having focused on autonomy is that the car is currently being produced with the hardware. Cardi being produced is capable of full self driving like capable is an interesting word because I'm like the hardware is, and as we were the software, the capabilities will increase dramatically. Um, and then the reliability will increase dramatically and then it will receive regulatory approval. So essentially buying a car today is an investment in the future.

Speaker 2:          15:19          You want, you're essentially buying a car. You're buying th th th th I think the most profound thing is that if you buy a Tesla today, I believe you are buying an appreciating asset, not a depreciating asset. So that's a really important statement there. Because if hardware is capable enough, that's the hard thing to upgrade. Yes, usually exact. So then the rest is a software problem. Yes, I've software has no marginal costs really. But what's your intuition on the software side? How hard are the remaining steps to get it to where, uh, you know, uh, the experience, uh, not just the safety, but the full experience is something that people would, uh, enjoy. Well, I think people enjoy it very much so on, on, on the highway. So it's a total game changer for quality of life, for using, you know, Tesla autopilot on the highways.

Speaker 2:          16:20          Uh, so it's really just extending that functionality to Sydney streets, adding in the traffic, light traffic, light recognition, uh, navigating complex intersections and um, and, and then being able to navigate a complicated po parking lots so the car can, uh, exit a parking space and come and find you, even if it's in a, a complete maze of a parking lot. And, uh, and, and then if, and then you can just, it just drop you off and find a parking spot by itself. Yeah. In terms of enjoyability and something that people would, uh, would actually find a lot of use from the parking lot is a, is a really, you know, it's, it's rich of annoyance when you have to do it manually. So there's a lot of benefit to be gained from automation there. So let me start injecting the human into this discussion a little bit. Uh, so let's talk, talk about full autonomy. If you look at the current level four vehicles being tests on row, like Waymo and so on, they're only technically autonomous. They're really level two systems with just the different design philosophy because there's always a safety driver in almost all cases in their monitoring system. Right. Do you see Teslas full self driving as still for a time to come, requiring supervision of the human being. So it's capabilities and Paul phone off to drive but nevertheless requires a human to still be supervising.

Speaker 1:          17:50          Just like a safety driver is in a other fully autonomous vehicles.

Speaker 2:          17:57          I think it, it will require detecting hands on wheel for at least a six months or something like that from here. It really is a question of like from a regulatory standpoint, uh, what, how much safer than a person does autopilot needs to be for it took to be okay to not monitor the car, you know, and, and this was a debate that one can have it and then if you, but you need a large samples, large amount of data, um, so that you can prove with high confidence, statistically speaking, that the car is dramatically safer than a person. Um, and that adding in the person monitoring does not materially affect the safety. So it might, it need to be like two or 300% safe a person. And how do you prove that incidents per mile

Speaker 1:          18:52          incidence per mile. So crashes and fatalities,

Speaker 2:          18:57          fridge fatality would be a factor, but there's there they're just not enough fatalities to be statistically significant at scale. But there are enough crashes, you know, the former crashes and fatalities. So you can assess where is the probability of a, of a crash that then there's another step which properly of injury and probability of Ponant injury, their power, probability of death and all of those need to be a much better than a person, uh, by at least paps 200%.

Speaker 1:          19:33          And you think there is a, the ability to have a healthy discourse with the regulatory bodies on this topic.

Speaker 2:          19:40          I mean, there's no question that um, uh, regulators paid a disproportionate amount of attention to that which generates press. This is just an objective fact and tells the, generates a lot of press. So the, you know, in the United States, this I think almost 40,000 automotive deaths per year, but if there are four and Tesla, they will probably receive a thousand times more press than anyone else.

Speaker 1:          20:08          So the psychology of that is actually fascinating. I don't think we'll have enough time to talk about that, but I have to talk to you about the human side of things. So myself and our team and MIT recently released a paper on functional vigilance of drivers while using autopilot. This is work we've been doing since autopilot was first released publicly over three years ago, collecting video driver faces and drive her body. So I saw that you tweeted a quote from the abstract so I can at least a guests the, you've glanced at it. Yeah. Right. Can I talk you through what we found? Sure. Okay. So it appears that in the data that we've collected, that drivers are maintaining functional vigilance such that we're looking at 18,000 disengagement from autopilot, 18,900 and annotating were they able to take over control in a timely manner? So they were there present looking at the road. Uh, to take over control. Okay. So this goes against what, what many would predict from the body of literature and vigilance with automation. Now the question is, do you think these results hold across the broader population? So ours is just a small subset. Do you think, uh, one of the criticism is that, you know, there's a small minority of drivers that may be highly responsible where their vigilance decrement would increase with autopilot use. I think

Speaker 2:          21:40          this was all really going to be swept. I mean, the systems improving so much so fast that this is going to be a moot point very soon. Where vigilance is if something's many times safer than a person, than adding a person. Uh, just the, the, the, the effect on safety is, is limited. Um, and in fact it could be negative.

Speaker 1:          22:10          That's really interesting. So the, uh, the, so the fact that a human may, some percent of the population may, uh, exhibit a visualist sacrament will not affect overall statistics, numbers of safety?

Speaker 2:          22:22          No. In fact, I think it will become very, very quickly maybe and towards the end of this year. But I would say I would be shocked if it's not next year, but at the latest that um, having the post, having a human intervene will decrease safety, decrease the, it's like imagine if you're in an elevator and I used to be that the elevator operators, um, and you couldn't go in an elevator by yourself and work the, the lever to move between floors. Um, and now, uh, nobody wants it in elevator operator because the automated elevator that stops the floors is much safer than the elevator operator. And in fact it will be quite dangerous to have someone with a lever that can move the elevator between floors. Okay.

Speaker 1:          23:09          So that's a, that's a really powerful statement and really interesting one. But I also have to ask from a user experience and from a safety perspective, one of the passions for me algorithmically is a camera based detection of a, of just sensing the human but detecting what the driver is looking at cognitive load, body pose on the computer vision side. That's a fascinating problem. But do you, and there's many in industry you believe you have to have camera based driver monitoring. Do you think there could be benefit gained from driving? Monitoring?

Speaker 2:          23:41          If you have a system that's, that's Adam, that's outer below a human level, reliability, then driving monitoring, it makes sense. But if your system is dramatically better, more liable than, than a human, then drive monitoring, monitoring is not just not help much. And uh, like I said, you just like as you wouldn't want someone interview, like you wouldn't want someone in the elevator if you're in an elevator, do you really want someone with a big lever? So some random person operating elevator between floors, I wouldn't trust that or I'd rather have the buttons.

Speaker 1:          24:17          Okay. You're optimistic about the pace of improvement of the system, not from what you've seen with a full self driving car computer. The rate of improvement is exponential. So one of the other very interesting design choices early on that connects to this is the operational design domain of autopilot. So where autopilot is able to be turned on. The contrast. Another vehicle system that we were studying is the Cadillac supercrew system. That's in terms of OGD very constrained to particular kinds of highways. Well mapped, tested as much narrower than the odd of Tesla vehicles. What's theirs? There's blogs and add. Yeah, that's good. That's it. That's a good line. Uh, what was the design decision, uh, what's in that different philosophy of thinking where there's pros and cons? What we see with a, uh, a wide o d d is drive test. As drivers are able to explore more the limitations of the system at least early on. And they understand together with the instrument cluster display, they start to understand what are the capabilities. So that's a benefit. The con is you're, you're letting drivers use it basically anywhere. Uh, so anyways, that can detect lanes with Collins, was there a philosophy, a design decisions that were challenging there were being made there? Or from the very beginning? Was that, uh, don on purpose with intent?

Speaker 2:          25:54          Well, I mean I think it's frankly, it's pretty crazy giving it, letting people drive it a two ton death machine manually. Uh, that's crazy. Like, I guess like in the future of people were like, I can't believe anyone was just a larger drive for one of these two ton death machines and think just drive wherever they wanted to just like elevators and just like move the elevator with the lever wherever you want. It can stop it halfway between floors if you want. It's pretty crazy. So it's going to seem like a mad thing in the future that people were driving cars.

Speaker 1:          26:32          So I have a bunch of questions about the human psychology, about behavior and so on. I don't know what it would become mean that we're told him. Uh, because uh, you have faith in the AI system, uh, not faith, but uh, the both on the hardware side and the deep learning approach of learning from data, we'll make it just far safer than humans. Yeah, exactly. Recently there are a few hackers who are tricked autopilot act and not unexpected ways of adversarial examples. So we all know that neural network systems are very sensitive to minor disturbances. These adversarial examples on input. Do you think it's possible to defend against something like this for the product? For the industry? Sure. Yeah. Can you elaborate on the, on the confidence behind that answer?

Speaker 2:          27:23          Um, well the, you know, in New Orleans is just like basically a bunch of mates, matrix math. Oh you have to be like a very sophisticated somebody who really understands neural nets and like basically reverse engineer how the matrix is being built and then create a little thing that's just exactly, um, causes the matrix math to be slightly off, but it's very easy to then block it. Block that by having, well basically Anthydrate negative recognition. It's like if the system sees something that looks like a matrix hack, uh, excluded.

Speaker 3:          27:58          Okay.

Speaker 2:          27:58          The Sofa, it is such an easy thing to do. Okay.

Speaker 1:          28:02          So learn both on the, the validated and the invalid data. So basically learn on the adversarial examples to be able to exclude them.

Speaker 2:          28:09          Yeah. You like, you're basically wanted us to both know what is, what is a car and what is definitely not a car and you train for this is a car and this is definitely not a car. Those are two different things. Repeat people have no idea. Neural Nets really they, it's probably thinking unless it involves like, you know, fishing net thing.

Speaker 1:          28:29          So as you know, so taking it a step beyond just Tesla and autopilot, current deep learning approaches still seem in some ways to beef far from General Intelligence Systems. Do you think the current approaches will take us to general intelligence or do totally new ideas need to be invented?

Speaker 3:          28:54          Okay.

Speaker 2:          28:55          I think we're missing a few key ideas for general intelligence, general artificial, general intelligence, but it's going to be upon us very quickly and then we'll need to figure out what should we do if we even have that choice.

Speaker 3:          29:15          Yes.

Speaker 2:          29:15          But it's, it's amazing how he will, can't differentiate between say the narrow AI that allows a car to figure out what a lane line is and, and, and you know, and, and navigate streets versus general intelligence. Like these are just very different things like your toaster and uh, and your computer or both machines, but once much more sophisticated than another, you're

Speaker 1:          29:39          confident with Tesla, you can create the world's

Speaker 2:          29:42          best toaster Bose best host for. Yes, most of the world's best self driving. I'm a yes to to me the, right now this seems game set match. I don't, I mean that's how I don't want to be complacent or over confident, but that's what it appears. That is just literally what it, how it appears right now. I could be wrong, but it appears to be the case that Tesla is vastly ahead of everyone. Do you think we will ever create an AI system that we can love and loves his back in a deep, meaningful way? Like in the movie her.

Speaker 3:          30:19          Okay.

Speaker 2:          30:20          I think AI will be capable of convincing you to fall in love with it very well. And that's different than us humans. You know, we start getting into a metaphysical question of like, do my emotions and thoughts exist in a different realm, the physical, and maybe they do, maybe they don't. I don't know. But from a physics standpoint, I think I tend to think of things, you know, like physics was my main sort of training and from a physics standpoint essentially if it loves you in a way that is that you can't tell whether it's real or not. It is real. It's a physics view of love. Yeah. If there's no, if the, if you cannot, if you cannot prove that it does not, if there's no tests that you can apply that would make it make it, allow you to tell the difference, then there is no difference.

Speaker 2:          31:17          Right. And it's similar to a seeing our world of simulation. There may not be a test to tell the difference between what the real world simulation and therefore from a physics perspective it might as well be the same thing. Yes. There may be ways to test whether it's a simulation. They might be. I'm not saying there aren't, but you could certainly imagine that assimilation could, could correct that. Once an entity in the simulation found a way to detect the simulation, it could either restart the pores, the rip simulation, start a new simulation, or do one of any other things that then correct for that error. So when maybe you or somebody else creates an AGI system and you get to ask her one question, what would that question be? What's outside of the simulation?

Speaker 3:          32:21          Okay.

Speaker 2:          32:21          Ilan, thank you so much for talking today as a pleasure. All right. Thank you.