Speaker 1:          00:00          Welcome to course six as zero, nine, nine artificial general intelligence. We will explore the nature of intelligence from as much as possible. An engineering perspective. You will hear many voices. My voice will be that of an engineer. Our mission is to engineer intelligence. The mit motto is mined in hand. What that means is we want to explore the fundamental science of what makes an intelligent system, the core concepts behind our understanding of what is intelligence, but we always want to ground it in the creation of intelligence systems. We always want to be in the now in today in understanding how today we can build artificial intelligence systems that can make for a better world that is the core for us here at Mit, first and foremost, where scientists and engineers, our goal is to engineer intelligence.

Speaker 1:          01:19          We want to provide with this approach a balanced to the very important but overrepresented view of artificial general intelligence. That black box reasoning view, where the idea is, once we know how to create a human level intelligence system, how will society be impacted? Will robots take over and kill everyone? Will we achieve a utopia that will remove the need to do any of the messy jobs that will make us all extremely happy? Those kinds of beautiful philosophical concepts are interesting to explore, but that's not what we're interested in doing. I believe that from an engineering perspective, we want to focus on the black box of Agi, start to build insights and intuitions about how we create systems that approach human level intelligence. I believe we're very far away from creating anything resembling human level intelligence. However, the dimension of the metric behind the ward far may not be time in time, perhaps through a few breakthroughs may be even one breakthrough.

Speaker 1:          02:50          Everything can change, but as we stand now, our current methods as we will explore from the various ideas and approaches and the guest speakers coming here, uh, over the next two weeks and beyond, our best understanding, our best intuition insights are not yet at the level of reaching without a major leap and breakthrough and paradigm shift towards human level intelligence. So it's not constructive to consider the impact of artificial intelligence to consider questions of safety and ethics. Fundamental, extremely important questions, we it's not constructive to consider those questions without also deeply considering the black box of the actual methods of artificial intelligence, human level, artificial intelligence, and that's what I see. What I hope this course can be, its first iteration, it's first exploratory attempt to try to look at different approaches of how we can engineer intelligence. That's the role of mit is tradition of mine in hand is to consider the big picture, the future impact of society 10, 20, 30, 40 years out, but fundamentally grounded in what kind of methods do we have today and what are the limitations and possibilities of achieving that.

Speaker 1:          04:21          The black box of Agi and in the future impact on society of creating artificial intelligence systems that get become increasingly more intelligent. The fundamental disagreement lies in the fact the very core of that black box, which is how hard is it to build an Agi system? How hard is it to create a human level artificial intelligence system? That's the open question for all of us, from, from Josh Tenenbaum to Andrea carpathy to folks some open ai to Boston dynamics, the brilliant leaders in various fields of artificial intelligence that will come here. That's the open question. How hard is. It has been a lot of incredibly impressive results in deep learning in neuroscience and computational cognitive science in robotics, but how far are we still to go to the Agi? That's the fundamental question that we need to explore before we consider the questions, the future impact on society. And the goal for this class is to build intuition. One, talk at a time, a project at a time build intuition about where we stand, about what the limitations of current approaches are. How can we close the gap?

Speaker 1:          05:55          A Nice meme that I caught on twitter recently of a, the difference between the engineering approach at the very simplest of a google intern typing a for loop that just does a grid search on parameters for neural network. Uh, and on the right is the way media would report this for loop the Google ai created its own baby ai. I think it's easy for us to go one way or the other, but we'd like to do both. Our first goal is to avoid the pitfalls of black box thinking of the futurism thinking that results in hype, that's detached from scientific engineering, understanding of what the actual systems are doing. That's what the media often reports. That's what some of our speakers will explore in a rigorous way. It's still an important topic to explore. Ray Kurzweil on Wednesday. We'll look at. We'll explore this topic next week talking about Ai Safety and autonomous weapons systems.

Speaker 1:          07:08          We'll explore this topic that future impact 10, 20 years out. How do we design systems today that would lead to safe systems tomorrow. Still very important, but the reality is a lot of us need to put a lot more emphasis on the left, on the for loops, on creating these systems at the same time. The second goal of what we're trying to do here is not emphasize the silliness, the simplicity, the naive basic nature of this four loop and the same way as was the process in creating nuclear weapons before, during World War Two. The idea that as an engineer, as a scientist, that I am just the scientist is also a flawed way of thinking. We have to consider the big picture impact the near term negative consequences that are preventable, the low hanging fruit, the that can be prevented through that engineering process. We have to do both and in this engineering approach we always have to be cautious that just because we don't understand, we're just because we our intuition, our best understanding of the capabilities of modern systems that learn to act in this world seem limited, seem far from human level intelligence.

Speaker 1:          08:34          Our ability to learn and represent common sense reasoning seems limited. The exponential potentially exponential. It's could be argued and he will. A growth of technology of these ideas means that just around the corner is a singularity is a breakthrough idea that will change everything. We have to be cautious of that. Moreover, we have to be cautious of the fact that every decade over the past century, our adoption of new technologies has gotten faster and faster. The rate at which a new technology from its birth to its wide mass adoption has shortened and shortened and shortened. That means that new idea, the moment it drops into the world can have widespread effects overnight, so as an I think the in in the engineering approach is fundamentally cynical on artificial general intelligence because every aspect of it is so difficult. We have to always remember that overnight. Everything can change through this question of beginning to approach from a deep learning perspective, from deeper enforcement learning from brain simulation, complex cognitive science from computational neuroscience, from cognitive architecture, some robotics from a legal perspective and autonomous weapons systems.

Speaker 1:          10:09          As we begin to approach these questions, we need to start to build intuition. How far away are we from creating intelligence systems? The singularity here is that spark, that moment when we're truly surprised by the intelligence of the systems we create. I'd like to visualize it by the, by the certain analogy that we're in this dark room looking for a light switch with no knowledge of where the lights, which is. There's going to be people that say, well, it's a small rooms are all small. We're right there and say anywhere. We'll be able to find it anytime time. The reality is we know very little so we have to stumble around, feel our way around to build the intuition of far, far away. We really are.

Speaker 1:          11:03          And many will. Speakers here, we'll talk about how we define intelligence, how we can begin to see intelligence. What are the fundamental impacts of creating intelligence systems? I'd like to sort of see the positive reason for this little class and for these efforts that have fascinated people throughout the century of trying to create intelligence systems is that there is something about human beings that want that craze to explore, to uncover the mysteries of the universe. Fundamental in itself, a desire to uncover the mysteries of the universe, not for a purpose, and there's often an underlying purpose of money, of greed, of, uh, the, uh, power craving for power and so on. But there's seems to be an underlying desire to explore. Nice little book, an exploration, a very short introduction by Stewart Weaver. He says, for all the different forums that takes in different historical periods for for all the worthy and unworthy motives that lie behind it. Exploration travel for the sake of discovery and adventure is a human compulsion, a human obsession even. It is defining element of a distinctly human identity and it will never arrest at any frontier, whether terrestrial or extraterrestrial. From 325 BC. He with a long, 7,500 mile journey

Speaker 1:          12:46          on the ocean to explore the Arctic, to Christopher Columbus and his flawed harshly criticize the modern scholarshipped trip that ultimately pave the way, didn't discover, paved the way to colonization of the Americas, to the Darwin trip, the voyage of the Beagle. Whilst this planet has gone, cycling on according to the fixed law of gravity from so simple, a beginning, endless forms most beautiful and most wonderful have been and are being evolved to the first venture into space by Urunga, Guardian, first human in space in 1961. What he said over the radio is, the earth is blue. It is amazing this. These are the words that I think drive our exploration in the sciences and the engineering and today in ai from the first walk on the moon and now the desire to colonize Mars and beyond. That's where I see this desire to create intelligence systems,

Speaker 1:          14:16          talking about the positive and negative impact of ai on society. Talking about the business case so the jobs lost, jobs gained, jobs, created diseases cured the autonomous vehicles, the ethical questions, the safety of autonomous weapons, of the misuse of ai in the financial markets. Underneath it all, and there are people, many people have spoken about this. What drives myself and many in the community is a desire to explore, to uncover the mystery of the universe and that hope that you join me in that very effort with speakers that come here in the next two weeks and beyond.

Speaker 1:          14:57          The website for the course is Agi that mit did you. I am a part of an amazing team, many of whom you know Agi at Mit. That edu is the email. We're on slack. Deep Dash Mit does slack up for registered at Mit students. It created account on the website and submit five new links and vote on 10 to vote Ai, which is an aggregator of information and material we've put together for the topic of Agi and submit a entry to one of the competitions, one of the three competitions projects that we have in this course and the projects are dream vision. I'll go over them in a little bit. Dream Vision, Angele ethical car, and the aggregator of material. Vote Ai. We have guest speakers, incredible guest speakers. I will go over them today and as before with the deep learning for self driving cars course, we have shirts and they're free for in person, for people that attend in person for the last lecture, most likely or you can order them online.

Speaker 1:          16:17          Okay. Dream vision will take the Google g dream idea. We explore the idea of creativity where Einstein's view of intelligence, the mark of intelligence is creativity. This idea is something we explore by using neural networks and interesting ways to visualize what the network see and in so doing, create beautiful visualizations in time through video. So taking the ideas of deep dream and combining them together with multiple video streams to mix, dream and reality, and the competition is through mechanical Turk was set up a competition of who produces the most beautiful visualization will provide code to generate this visualization and ideas of how you can make it more and more beautiful and how to submit it to the competition. Angel, the artificial neural generator of emotion and language is a different twist on the turing test where we don't use words, we only use emotions to speak expression of those emotions and we create. We use an age a, a, a, a face customizable with 26 muscles. All of which can be controlled or controlled with an Lstm we use in your network to train the generation of emotion

Speaker 1:          17:59          and the competition in you. Submitting the code to the competition is you get 10 seconds to impress with the these expressions of emotion, the viewer. It's Ab testing. Your goal is to impress the viewer enough to where they choose your agent versus another agent, and those that are most loved agents, most loved will be the ones that are declared winners in a twist. We will add human beings into this mix, so we've created a system that maps are human faces, myself and the Ta's to where we ourselves enter an outcome in the competition and try to convince you to keep us as your friend. That's the turing test.

Speaker 1:          18:56          Okay. Ethical car building in the ideas of the trolley problem and the moral machine done here in the media lab. They incredible, interesting work. We take a machine learning approach to it and take what we've developed, the deep reinforcement learning competition for a six zero, nine for the deep traffic and we add pedestrians into it to cast stochastic irrational, unpredictable pedestrians, and we add human life to the loss function where there's a tradeoff between getting from point a to point b. So in deep traffic, the deeper enforcement learning competition, the goal was to go as fast as possible. Here it's up to you to decide what you, what your agents goal is. There's a parade of front tradeoff between getting from point a to point B as fast as possible and hurting pedestrians.

Speaker 1:          20:08          This is not a ethical question. It's an engineering question and it's a serious one because fundamentally in creating autonomous vehicles that function in this world, we want them to get from point a to point B as quickly as possible. The United States government insurance companies put a price tag on human life. We put that power in your hands in designing these agents to ask the question of a, how can we create machine learning systems where the objective function, the loss function has human life as part of it and vote ai is an aggregator of different links, different articles, papers, videos on the topic of artificial general intelligence where people vote on a vote, quality articles up and down and choose on the sentiment of positive and negative. We'd like to explore the different ways to the different arguments for and against artificial general intelligence.

Speaker 1:          21:26          There is an incredible list of speakers the best in their disciplines from Josh Tenenbaum, Ghana, mit to ray Kurzweil at Google, to Lisa Feldman, Barrett and nature Bensky from northeastern university, Andre Carpathy, Steven Wolf from Richard Moise, Mark Reiber, ltss giver, and myself, Josh Tenenbaum. Tomorrow I'd like to go through each of these speakers and talk about the perspectives they bring that to try to try to see the approach, the ideas they bring to the table. They're not, in most cases interested in the discussion of the future impact on society without grounding it into the expertise, into the actual engineering, into creating these intelligence systems. So Josh is a computation and cognitive science expert. Professor Faculty here at Mit. He will talk about how we can create common sense understanding systems that see a world of physical objects and their interactions and our own possibilities to act, interact with others, the intuitive physics.

Speaker 1:          22:46          How do we build into systems the intuitive physics of the world more than just the deep learning memorization engines that take patterns and learn through supervised way to map those patterns to classification. Actually begin to understand the intuitive common sense physics of the world and learn rapid model based learning. Learn from nothing, learned from very little, just like we do as children, just like we do as human being successfully, often only need one example to learn a concept. How do we create systems that learn from very few, sometimes a single example and integrate ideas from various disciplines, of course, from neural networks, but also probabilistic generative models and symbol processing architectures. It's gonna be incredible of course, from a, from a different area of the world. Uh, another incredible thinker, intellectual speaker is Ray Kurzweil. He'll be here on Wednesday at 1:00 PM and he will do a whirlwind discussion of where we stand with intelligence, creating intelligence systems, how we see natural intelligence, our own human intelligence, how we define it, how we understand it, and how that transfers to the increasing exponential growth of development, of artificial general intelligence. Something I'm very excited about

Speaker 1:          24:20          is Lisa Feldman Barrett coming here on Thursday. She's written a book, I believe, how emotions are made. He argues that emotions are created, that there is a distinction, there is a detachment between what we feel in our bodies, the physical state of our bodies, and the expression of emotion from, from body to the contextually grounded to the face expressing that emotion, which means now why is this a person who is a psychology person in a fundamentally engineer and computer science topic like Agi? Because if emotions are created and the way she argues and she'll systematically break it down, that means we're learning societal. As human beings, we're learning societal norms of how to express emotion. The idea of emotional intelligence has learned, which means we can have machines learn this idea. It's a machine learn just like it's a human learning problem. It's some machine learning problem in a little bit of a twist.

Speaker 1:          25:28          She asked that instead of giving a talk, I have a conversation with her so there's going to be a little bit challenging and fun and, uh, she's great looking forward to it and we'll explore different ways that we can get emotion expressed through video, through audio, through the project. The Angel Project that I mentioned. So there's has been worked and reenacting intelligence, so a well reenacting mapping face to face mapping different emotions on video that was previously recorded. So if you can imagine that means we can take emotions that we've created, the kind of emotion creation we've been discussing and remap it on previous video. That's one way to see intelligence is taking raw human data that we already have and mapping new computer generated the the, the underlying fundamentals of human, but the surface appearance, the representation of emotion, visual or auditory is generated by computer. It could be in the embodied form like with Sophia,

Speaker 2:          26:52          so different if you take a long time for to context and jealousy and it might be possible than any. The more ethical, a good partnership.

Speaker 1:          27:17          Very important to note for those captivated by Sophia in the press or have seen these videos. Sophia is an art exhibit. She's not a strong natural language processing system. This is not an agi system, but it's a beautiful visualization of embodying of. It's a beautiful visualization of how easy it is to trick us human beings. That there is intelligence, an underlying something that the emotional expression, the physical embodiment and the emotional expression that has that has some degree of humor that has some degree of wit and intelligence is enough to captivate us, so that's an argument for not creating intelligence from scratch, but having machines at the very surface, the display of that emotion, the generation, the mapping of the visual and the auditory elements were underneath. It is really trivial technology that's fundamentally relying on humans. Like in Sophia's case and in the simplest form, we remove all elements of shit.

Speaker 1:          28:31          How should I say, attractive appearance from a, from an agent. We really keep it to the simplest muscles aspect, characteristics of the face and see with 26 muscles controlled by a neural network through time, so recurrent neural network. I was tm. How can we explore the generation of emotion? Can we get this thing, and this is an open question for us too. We just created the system. We don't know if we can. Can we get it to make us feel something, make us feel something. By watching it express its feelings, can it become human before our eyes can now learn to back competing against other agents? Ab testing on Turk. I'm mechanical Turk. Can the winters be very convincing to make us feel entertained? Pity, love. Maybe some of you will fall in love with Angela here, mate Devenski. On Friday we'll talk about cognitive modeling architectures, so you will speak about the cognitive modeling aspect. Can have a a Ma. Can we model cognition in some kind of systematic way to try to build intuition of Hok? Complicated cognition is Andrea [inaudible], famous for being the state of the art human on the image net challenge, the representative, the 95 percent accuracy performance among other things he's also famous for is now a tesla. He will talk about

Speaker 1:          30:12          the role, the limitations, the possibilities of deep learning. We'll talk, as I have spoken about in the past few weeks and throughout about our misunderstanding or are flawed intuition about what are the difficult and what are the easy problems in deep learning and the power of the representational learning, the ability of neural networks to form deeper and deeper representations that the underlying raw data that ultimately forms that takes complex information that's hard to make sense of and a converted into useful actionable knowledge

Speaker 1:          30:57          that is from a certain Lens in a certain certain Lens and a certain problem space can be clearly defined as understanding of the complex information understanding is ultimately taking complex information and reducing it to a simple essential elements, representational learning and the trivial case here in drawing a having to draw a straight line to separate the blue and the red curves. That's impossible to do in a in a Nigel input space on the left. What the act of learning is for deep neural networks in this formulation is to construct the topology under which there exists a straight line to accurately classify blue versus red. That's the problem, and for a simple blue and red line, it seems trivial here, but this works in the general case for arbitrary input spaces for arbitrary, nonlinear, highly dimensional input spaces and the ability to automatically learn features too, to learn hierarchical representations of the raw sensory data means that you could do a lot more with data, which means you can expand further and further and further to create intelligence systems that, uh, operate successfully with real world data. That's what representation learning means. That deep learning allows because the arbitrary number of features that can be automatically determined, you can learn a lot of things about a pretty complex world. Unfortunately, there needs to be a lot of supervised data. There still needs to be a lot of human input.

Speaker 1:          32:41          Andre and others, Josh will talk about the difference between our human brain are biological and neural network and the artificial neural network, the full human brain with 100 billion neurons, 1000 trillion synapses and the biggest neural networks out there, the artificial neural networks having much smaller, $60, million synapses for resident at 1:52. The biggest difference, the parameter is the human brain being several orders of magnitude more synapses. That topology being much more complex, chaotic, the asynchronous nature of the human brain and the learning algorithm of artificial neural networks is trivial and constrained with backpropagation is essentially an optimization function over a, over a clearly defined last function from the output to the, uh, to the input using backpropagation to teach, to adjust the waist on that network. The learning algorithm for our human brain is most of the unknown, but it's certainly much more complicated than backpropagation.

Speaker 1:          33:56          The power consumption. The human brain is a lot more efficient than artificial neural networks. And there's a very kind of artificial, a trivial supervised learning process for training artificial neural networks. You have to have a training stage and you have to have an evaluation stage and once the network is trained, there's no clear way to continue training it or there's, there's a lot of ways, but they're inefficient. It's not designed to do online learning, uh, naturally to always be learning is designed to be, to learn and then be applied. Obviously our human brains are always learning, but the beautiful, fascinating thing is that they're both distributed computation systems on a large scale, so it's not a, uh, there's, it doesn't ultimately boil down to a single compute unit. The computation is distributed. The backpropagation learning process distributed can be paralyzed in a GPU, massively parallelized.

Speaker 1:          35:00          The underlying computational unit of a neuron is trivial, but can be stacked together to form forward neural networks, recurrent neural networks to represent both spacial information with images and temporal information with a audio speech, text sequences of images and video and so on. Mapping from one to one, one to many, many to one, so the mapping, any kind of structure vector and time data as an input to any kind of classification, regression sequences, captioning, video, audio as output, learning in the general sense, but in a domain that's precisely defined for the supervised training process. We can think of the in deep learning case. You can think of the supervised methods where humans have to annotate the data as memorization of the data. We can think of the exciting new and growing field of semi supervised learning when most of the data through off through generative adversarial networks or through significant data augmentation, clever data augmentation, most of it is done automatically. The annotation process or through simulation and then reinforcement learning where most of the, uh, most of the labels are extremely sparse and come rarely. And so the system has to figure out how to operate in the world with very little human input, very little human data.

Speaker 1:          36:38          We can think of that as reasoning because you take very little information from our teachers, the humans and transfer it across, generalize it across a to reason about the world. And finally, uh, unsupervised learning, the excitement of the community that promise, the hope. You could think of that as understanding because ultimately it's taking data with very little or no human input. And for me representations that that data is how we think of understanding, requiring, making sense of the world without strict input of how to make sense of the world. The kind of process of discovering information, maybe discovering new ideas, new ways to simplify the world to represent the world that you can do new things with it. The new is the key element there. Understanding and uh, Andrea and Eylea and others will talk about the certainly the past, but the future of deep learning.

Speaker 1:          37:36          Whereas going to go is it over hyped, under hyped? What is the future? Will the compute of CPU GPU as six continue with the breakthroughs, the Moore's law and its various forms of massive parallelization continue and the large data sets with tens of millions of images grow to billions and trillions. Will the algorithms improve? Is there a groundbreaking idea that's still coming with, uh, with Geoff Hinton's? Capsule networks is a fundamental architectural changes in your networks that we can come up with that will change everything, that will ease the learning process. They'll make the learning process more efficient or will be able to represent higher and higher orders of information is such that you can transfer knowledge between domains and the software architectures that support intensive Florida Pi Torch. Uh, I would say the last year and this year will be the year of deep learning frameworks. So will, those will certainly keep coming in their various forms and the financial backing is growing and growing the open challenges for deep learning.

Speaker 1:          38:51          Really a lot of this course is kind of connected to deep learning because that's where a lot of the recent breakthroughs that inspire us to think about intelligence systems come from. But the challenges are many, the, the need, the ability to transfer between different domains as in reinforcement learning and robotics. The need for huge data and an efficient learning. Uh, we're, we're still need supervised data. Uh, inability to learn in an unsupervised way is a huge problem and not fully automated learning. There's still a degree, a significant degree of hyper parameter tuning necessary with the reward functions. The loss functions are ultimately defined by humans and therefore are deeply flawed. When we released those systems into the real world where there is no ground truth for the testing set and the goal isn't achieving a class, a high classification on a trivial, a image classification, localization detection problem, but rather to have an autonomous vehicle that doesn't kill pedestrians or an industrial robot that operates in jointly with other human beings and all the edge cases that come up.

Speaker 1:          40:08          How does deep learning methods, how to machine learning methods generalize over the edge cases, the weird stuff that happens in the real world? Those are all the problems there. Stephen Wolfram will be here on Monday evening at 7:00 PM, has done a lot of amazing things, I would say is very interesting from his recent interest in knowledge based programming. Wolfram Alpha I think is the fuel for most middle school and high school students. Now, for the first time taking calculus I pray, probably go to Wolfram Alpha to answer their own questions, but more seriously, there is a, a deep connected graph of knowledge as being built there with the wool from wool, from Alpha and wool from language that still will explore in terms of language and interesting thing. He was part of the team on arrival that, uh, worked on the language. If for those of you are familiar to arrival where a alien species spoke with us, US humans through a very interesting, beautiful, complicated language and he was brought in as a representative human to interpret that language just like in the movie, who's represent that in real life.

Speaker 1:          41:28          And you use the skills that him and his son Christopher used to analyze this language. Very interesting. That process is extremely interesting. I hope he talks about it and his background with Mathematica and a new kind of science. The sort of another set of ideas that have inspired people in terms of creating intelligence systems is the idea that from very simple things, very simple rules, extremely complex patterns can emerge. His work with cellular Automata did just that take an extremely simple mathematical constructs here with cellular Automata. These are, these are grids of computational units that switch on and off and some kind of predefined way and only operate locally based on their local neighborhood and somehow based on different kinds of rules, different patterns emerge. Here's the three dimensional cellular automata with a simple rule starting with nothing with a single cell. They grow and really interesting, complex ways.

Speaker 1:          42:42          This emergent complexity is inspiring. It's the same kind of thing that inspires us about neural networks that you can take a simple computational unit and when combined together in arbitrary ways can form complex representations. That's also very interesting. You can see knowledge from a knowledge perspective. You could see knowledge formation in the same kind of way. Simplicity at a mass distributed scale, resulting complexity. Next Tuesday, Richard, noise from article 36 coming all the way from UK for us. We'll talk about it works with autonomous weapons systems, works with also a nuclear weapons, but primarily autonomous weapon systems and concern legal policy and technological aspects of banning these weapons. There's been a lot of agreement about the safety hazards of autonomous systems that make decisions to kill a human being. Mara Criber, CEO, Boston Dynamics, previously long time ago, faculty here at Mit, we'll talk about. We'll bring robots and talked to us about his work of robots in the real world as a, doing a lot of exciting stuff with humanoid robotics at 80 kinds of robots operating on legs.

Speaker 1:          44:07          Uh, it's incredible work, extremely exciting and gets to explore the idea of how difficult it is to build these robots systems that operate in the real world, uh, from both the Qa control aspect and from the way the final result is perceived by our society. It's very interesting to see when intelligence in robotics is embodied and then taking in by us and what that inspires. Fear, excitement, hope, concern, and all of the above. Les is a expert in many aspects of machine learning. Is the cofounder of open Ai. Talk about there different aspects of game playing that they've recently been exploring by using deeper enforcement, learning to play arcade games

Speaker 1:          45:05          and d on the deep mind side, using deep reinforcement learning to beat the best in the world that the game of go in 2017. The big fascinating breakthrough achieved by that team with Alphago, zero training and agent that through self play playing itself, not an expert games so truly from scratch, learning to beat the best in the world, including the previous iteration of Alphago. We'll explore what aspects of the stack of intelligent robotics systems intelligent agents can be learned in this way. So deep learning, the memorization, the supervised learning memorization approach. It looks at the sensor data feature extraction representation, learning aspect of this, taking the sensor data from camera, a lidar audio, extracting the features for me, higher order of representations and on those representations. Learning to actually accomplish some kind of classification regression task, figuring out based on the representation what is going on in the raw sensory data and then combining that data together to reason about it and finally in the robotic domains, taking it all together as with humanoid, robotics, industrial robotics, autonomous vehicles taking altogether and actually acting in this world where the effectors and the open question is, how much of this ai stack can be learned? That's something for us to discuss, to think about. The eylea will touch on with deeper enforcement learning. We can certainly learn representations and perform classifications. They are better than human I damaged classification, image, net and segmentation tasks

Speaker 1:          46:54          and the excitement of deep learning is what's highlighted there in the red box can be done end to ends. Raw sensory data out to the knowledge, to the output, to the classification. Can we begin to reason is the open question with the knowledge based programming that Stephen Wolfman, we'll talk about. Can we begin to take these automatically generated high order representations and combine them together to form knowledge basis, to form a aggregate grass of ideas that can then be used the reason

Speaker 1:          47:26          and can we then combine them together to act in the world for whether in simulation with arcade games or simulation of autonomous vehicles or box systems are actually in the physical world with robots moving about that end to end from raw sensory data to action be learned. That's the open question for for artificial general intelligence for this class. Can this entire process be end to end? Can we build systems and how do we do it that achieve this process end to end in the same way that humans do. We're born in this raw sensory environment, taking in very little information and learn to operate successfully an arbitrary constraints, arbitrary goals, and to do so. We have lectures, we have three projects and we have guest speakers from various disciplines. I hope that all these voices will be heard and will feed a conversation about artificial intelligence and it's positive and it's concerning effects in society and how do we move forward from an engineering approach.

Speaker 1:          48:47          The topics will be deep learning, deep reinforcement learning, cognitive modeling, competition, cognitive science, emotion creation, knowledge based programming, ai safety with autonomous weapons systems and personal robotics with human centered artificial intelligence. That's for the first two weeks of this class. That's the part where if you're actually registered students, that's where you need to submit the project. That's when we all meet here every, every night with an incredible speakers, but this will continue. We're already have several speakers scheduled the next couple of months yet to be announced, but they're incredible and we have conversations on video. We'll have new projects. I hope this continues throughout 2018 on the topics of Ai Ethics and bias. There's a lot of incredible work in a way know of a speaker. There are coming on the topic of how do we create artificial intelligence systems that are do not discriminate, did not form the kind of biases that US humans do in this world that are operating under social norms, but our reasoning beyond the flawed aspects of those social norms with bias, creativity as well.

Speaker 1:          50:02          The project of dream vision and beyond. There's so much exciting work qa and using machine learning methods to create beautiful art and music, a brain stimulation, neuroscience, computation, neuroscience. Shockingly, in the first two weeks we don't have a computation neuroscience speaker, which is a fascinating perspective. Brain simulation or neuroscience in general. Computation neuroscience is a fascinating approach from the from the mark of actual brain work to get the perspective of how our brain works and how we can create something that mimics, that resembles the fundamentals of what makes our brain intelligent. And finally the turing test. The traditional definite shouldn't have intelligence defined by Alan Turing was grounded in natural language processing and creating chat bots that impress us, that amaze us and trick us into thinking they're human. We will have a project and a speaker on natural language processing in March that I like to thank you for coming today and look forward to seeing your submissions for the three projects. Thank you very much.