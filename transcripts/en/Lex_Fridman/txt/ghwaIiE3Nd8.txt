Speaker 1:          00:00:00       The following is a conversation with Greta van Rossum, creator of Python, and one of the most popular programming languages in the world used in almost any application that involves computers from web, backend development to psychology, neuroscience, computer vision, robotics, deep learning, natural language processing, and almost any subfield of Ai. This conversation as part of MIT course on artificial general intelligence and the artificial intelligence podcast. If you enjoy it, subscribe on Youtube, iTunes or your podcast provider of choice or simply connect with me on Twitter at Lex Friedman, spelled f, r I. D. And now here's my conversation with Guido winter. Awesome. You were born in the Netherlands in 1956 your parents in the world around you was deeply impacted by World War II as well as my family from the Soviet Union. So with that context, what is your view of human nature? Are some humans inherently good and some inherently evil or do we all have both good and evil within us?

Speaker 2:          00:01:15       Ouch. I did not expect a such a deep one. I, I guess we all have good and evil potential in us, and a lot of it depends on circumstances and context

Speaker 1:          00:01:33       out of that world, at least on the Soviet Union side in Europe, sort of out of suffering, out of challenge, out of that kind of a set of traumatic events often emerge as beautiful art, music literature. In a interview I read or heard, you said you enjoyed Dutch literature when you were a child. Can, can you tell me about the books that had an influence on you in your childhood?

Speaker 2:          00:02:01       Well, west as a teenager, my favorite writer was my favorite Dutch author was a guy named that [inaudible] who's writing, certainly his early novels were all about sort of,

Speaker 3:          00:02:22       uh,

Speaker 2:          00:02:23       ambiguous things that happened during World War II. I think he was a young adult during that time and he wrote about it a lot and very interesting, very good books I thought. I think in a nonfiction way, no, it was all fiction, but it was very much set in in the ambiguous world of resistance against the Germans where often you couldn't tell whether someone, it was truly in the resistance or really a spy for the Germans and then some of the character

Speaker 1:          00:03:06       jurors in his novels sort of cross that line and you never really find out what exactly happened. And in his novels there was always a good guy and a bad guy is the nature of good and evil. Is it clear there's a hero?

Speaker 2:          00:03:22       It's no, his heroes are often more, his main characters are often anti heroes and and and so they're, they're are not, not very heroic. Dare, dare often date

Speaker 1:          00:03:36       day fail at some level to accomplish their lofty goals and looking at the trajectory through the rest of your life. Has Literature, Dutch or English or translation had an impact outside of the technical world that you existed in? Hmm.

Speaker 2:          00:03:58       I still read novels. I don't think that it impacts me that much directly.

Speaker 1:          00:04:06       Does it impact your work is just, it's a,

Speaker 2:          00:04:08       it's a separate world. My work is, is highly technical and sort of the, the world of art and literature doesn't really directly have any bearing on it.

Speaker 1:          00:04:20       You don't think there's a creative element to the design? You know, some would say art design of a language is art.

Speaker 3:          00:04:27       Uh,

Speaker 2:          00:04:30       I'm not disagreeing with that. I'm just saying that sort of, I don't feel direct influences from more traditional

Speaker 1:          00:04:39       art on my own creativity. All right. Of course you don't feel, it doesn't mean it's not somehow deeply there and your subconscious knows, who knows. So let's go back to your early teens, your hobbies or building electronic circuits, building mechanical models. Uh Huh.

Speaker 3:          00:04:59       Okay.

Speaker 1:          00:05:00       What, if you can just put yourself back in the mind of that a young Guido 12, 13, 14, was that grounded in a desire to create a system so to create something or was it more just tinkering? Just the joy of puzzle solving?

Speaker 2:          00:05:18       Uh, I think it was more the latter actually. I maybe towards the end of my high school period, I felt confident enough that that I designed my own circuits. Death were sort of interesting somewhat, but lots of that time I literally just took a model kit and follow the instructions, putting the things together. I mean that, I think the first few years that I build electronics kits, I really did not have enough understanding off sort of electronics to really understand what I was doing. I mean, I could debug it and I could sort of follow the instructions very carefully, uh, which has had, which has always stayed with me, but I had a very naive model of like how a transistor works. And I, I don't think that, that in those days I had any understanding of coils and capacitors, which, which actually sort of was a major problem when I started to build more complex digital circuits because it was unaware of the, sort of the analog part of the, how they actually work. And I would have things that the scheme, the schematic looked every, everything looked fine and, uh, it didn't work. And what I didn't realize was that there was some megahertz level oscillation that was throwing the circuit off because I had a sort of two wires were too close or the switches were, uh, we're kind of poorly built.

Speaker 1:          00:07:13       But through that time,

Speaker 4:          00:07:16       okay.

Speaker 1:          00:07:16       I think it's really interesting and instructive to think about because it has echoes of it are in this time now. So in the 1970s, the personal computer was being born. So did you sense in tinkering with these circuits? Did you sense the encroaching revolution and personal computing? So if at that point you're sick, what, we'll sit you down and ask you to predict the eighties in the nineties do you think you'd be able to do so successfully to unroll this, the process?

Speaker 2:          00:07:49       No, I, I had no clue. I, I remember I think in the summer after my senior year, or maybe it was the summer after my junior year. Well, at some point, I think when I was 18 I went on a trip to the math Olympiad in eastern Europe and there was like, I was part of the Dutch team and there were other nerdy kits that sort of had different experiences and one of them told me about this amazing thing called a computer and I had never heard that word. My own explorations in electronics. We're sort of about very simple digital circuits and I, I had sort of, I had the idea that I somewhat understood how a digital calculator worked and so there is maybe some echoes of computers dare, but I didn't, didn't, I never made that connection. I didn't know that when my parents were paying for magazine subscriptions using punched cards, that there was something called a computer that was involved with, would read those cards and transferred money between accounts. I was also not really interested in those things. It was only when I went to university to study math that I've found out that they had a computer and students were allowed to use it

Speaker 1:          00:09:23       and there was some, you're supposed to talk to that computer by programming it or did that feel like,

Speaker 2:          00:09:30       yeah, that was the only thing you could do with it, that the computer wasn't really connected to the real world. The only thing you could do us sort of, you typed your program on a bunch of punched cards, you gave the punched cards, do the operator, and an hour later the operator gave you back your printout and so all you could do was write a program that did something very abstract and I don't even remember what my first forays into programming were, but there were sort of doing simple math exercises and just to learn how a programming language worked.

Speaker 1:          00:10:15       Did you sense, okay, first year of college you see this computer, you're, you're able to have a program in the, generate some output. Did you start seeing the possibility of this or was it a continuation of the tinkering with circuits? Did, did you start to imagine that one, the personal computer, but did you see it as something that, is it

Speaker 2:          00:10:39       tool, they've got tools like awards

Speaker 1:          00:10:42       processing tool maybe, maybe for gaming or something? Or did you start to imagine that it could be, you know, going to the world of robotics? Like you've, you know, the Frankenstein picture that you could create an artificial being, there's like another entity in front of you. You did not stay, I

Speaker 2:          00:10:59       don't think I really saw it that way. I was really more interested in the tinkering. It's, it's maybe not as sort of a complete coincidence that I ended up sort of creating a programming language, which is a tool for other programmers. I've always been very focused on the sort of activity of programming itself and not so much what happens with, with the program. You right, right. I do remember, and I don't, maybe in my second or third year, probably my second actually, someone pointed out to me that there was this thing called Conway's game of life. Uh, you're probably familiar with it. Uh, I think the 70s, I think he came up with it. So there was a scientific American column by someone who did a monthly column about mathematical diversions and also blinking out on the guy's name. It was, it was very famous at the time and I think up to the 90s or so, and one of his columns was about Conway's game of life and he had some illustrations and he wrote down all the rules and sort of if there was the suggestion that this was philosophically interesting that that was why Conway had called it that.

Speaker 2:          00:12:26       And all I had was like the two pages photocopy of that article. I don't even remember where he got it. Uh, but it spoke to me and I remember implementing a version of that game

Speaker 2:          00:12:42       for the batch computer we were using where I had hope, has cal program that sort of read an initial situation from input and read some numbers that that said do so many generations and print every so many generations. And then out would come pages and pages of off sort of things as of different kinds. And I remember much later, I've done a similar thing using python, but I'd sort of debt original version I wrote at the time I found interesting because I combined it with some trick I had learned during my electronics hobbyist times. I essentially, first on paper, I designed a simple circuit built out of logic gates that took nine bits of input, which is the sort of the cell and its neighbors and produced a new value for that cell. And it's like a combination of, of a half adder and some other clipping, you know, it's actually a full adder. And so I had worked that out and then I translated that into a series of Boolean operations on Pascal integers where you could use the integers as bitwise, uh, values. And so I could basically generate 60 bits of a generation in, uh, in like

Speaker 2:          00:14:27       eight instructions are so nice. So I was proud of that. It's funny that you mentioned. So, uh, for people who don't know, Conway's game of life has a, there's, it's a cellular Automata, whether it's single compute units that kind of look at their neighbors and uh, figure out what they look like in the next generation based on the state of their neighbors. And this deeply distributed

Speaker 1:          00:14:52       a system in, in concept at least. And then there's simple rules that all of them follow. And somehow out of the simple rule, when you step back and look at what occurs, uh, it's, it's beautiful. There's a, an emergent complexity, even though the underlying rules are simple. There's an emergent complexity. Now the funny thing is you've implemented this and the thing that you're commenting on is you're proud of a hack you did to make it run efficiently when you're not commenting on like, this is a beautiful implementation. Uh, you're not commenting on the fact that there's an emerging complexity that you've, you've, you've quoted a simple program and when you step back and you print out the following generation after generation, that's stuff that you may have not predicted would happen, is happening. Right? And then there was this is that magic. That's the magic that all of us feel when we program. When you, when you create a program and then you run it and whether it's hello world or a show, something on screen, if there's a graphical component, are you seeing the magic in the mechanism of creating that?

Speaker 2:          00:16:05       I think I went back and forth, uh, as a student, we had an incredibly small budget, uh, of computer time that we could use. It was actually measured. I once got in trouble with one of my professors because I had overspent the department's budget. It's a different story, but so

Speaker 1:          00:16:28       aye.

Speaker 2:          00:16:29       I actually wanted the efficient implementation because I also wanted to explore what would happen with a larger number of generations and a larger sort of size of the, of the board. And so once the, the implementation was flawless, uh, I would feed a different patterns. And then I think maybe there was a, a followup article where there were patterns that debt, we're like gliders, patterns, depth repeated themselves after a number of generations, but, uh, translated one or two positions to the right or up or something like that. Uh, and there were, I remember things like glider guns while you can, you can Google Conway's game of life if there's still, people still go on who over it

Speaker 1:          00:17:27       for a reason because it's not really well understood why, I mean, this is what Stephen Wolfram is obsessed about. Uh, he's just the, the, we don't have the mathematical tools to describe the kind of complexity that emerges in these kinds of systems. And the only way you can do is to run it.

Speaker 2:          00:17:47       I'm not convinced that that it's sort of a problem that lends itself to classic mathematical analysis.

Speaker 1:          00:17:56       No. And, uh, so one, one theory of how you create an artificial intelligence or artificial being as you kind of have to, same with the game of life. You kind of have to create a universe and let it run, that creating it from scratch in a design way in the, you know, coding up a python program that creates, uh, a full intelligence system may be quite challenging that you might need to create a universe just like the game of life has.

Speaker 2:          00:18:26       Well, you might have to experiment with a lot of different universes before there is a set of rules that doesn't essentially always just end up repeating itself in a, in a trivial way.

Speaker 1:          00:18:42       Yeah. And, and uh, Steve Wolf from Stephen Wolfman works with these simple rules, says that it's kind of surprising how quickly you find rules that create interesting things you shouldn't be able to, but somehow you do. And so maybe our universe is laden with, uh, with rules that will create interesting things. They might not look like humans, but you know, emerging phenomena that's interesting may not be as difficult to create as we think. Sure. But let me sort of ask at that time, you know, some of the world, at least in popular press, uh, was kind of captivated perhaps at least in America by the idea of artificial intelligence that, that these computers would be able to think pretty soon. And that to you at all, did that in science fiction or in reality in any way.

Speaker 4:          00:19:37       Okay.

Speaker 2:          00:19:37       I didn't really start reading science fiction until much, much later. I think as a teenager, I, I read maybe one bundle of science fiction stories.

Speaker 1:          00:19:54       Was it in the background somewhere? Like in your thoughts?

Speaker 2:          00:19:57       Yeah, that's sort of the using computers to build something intelligent always fell to me because I had, I felt I had so much understanding of what actually goes on inside a computer. I, I knew how many bits of memory it had and how difficult it was to program and sort of, I didn't believe at all that, that you could just build something intelligent out of doubt, that that would really sort of satisfy my definition of intelligence. They think the most, the most influential thing that I read, uh, in my early twenties was Godel Escher Bach. That was about,

Speaker 5:          00:20:48       and that was a big eye opener in, in some sense.

Speaker 1:          00:20:53       In what sense? So, so, so yeah. So on your own brain, did you use, did you at the time or do you now see your own brain is a computer or is it because they're a total separation of the way? So yeah, you're very pragmatically practically know the limits of memory, the limits of this sequential computing or weekly paralyzed computing and you just know what we have now and it's hard to see how it creates, but it's also easy to see. It wasn't in the forties, 50s, 60s and now at least similarities between the brain and in our computers.

Speaker 5:          00:21:31       Oh yeah. I mean, I, I totally believe that brains are computers in some sense. I mean, the rules they use to play by are pretty different from the rules we, we can sort of implement in, in our current hardware. But I don't believe in like a separate thing that infuses us with intelligence or consciousness and or any of that. There's no soul. I've, I've been an atheist probably from when I was 10 years old just by thinking a bit about math and the universe and then, well my parents were atheists. Uh, now I know that you, you, you could be an atheist and still believe that there is something sort of about intelligence or consciousness that cannot possibly emerge from a fixed set of rules. I am not in that camp. I totally see that sort of given how many millions of years evolution took its time. DNA is, is a particular machine that that sort of

Speaker 6:          00:22:56       yeah,

Speaker 5:          00:22:57       and codes information and an unlimited amount of information in, in chemical a form and has figured out a way to replicate itself. I thought that death was, maybe it's 300 million years ago, but I thought it was closer to half a minute, half a billion years ago. That that's sort of originated and it hasn't really changed that the sort of, the structure of DNA hasn't changed ever since. That is like are binary code that we have in hardware. I mean

Speaker 1:          00:23:35       the basic programming language hasn't changed, but maybe the programming itself

Speaker 5:          00:23:40       of his lead ditch did sort of it, it happened to be a set of rules that was good

Speaker 2:          00:23:46       enough to, to sort of develop endless variability and and sort of the, the idea of self replicating molecules competing with each other for resources and one tight eventually sort of always taking over. That's happened before there were any fossils so we don't know how that's exactly happened but I believe it, it's, it's clear that that did happen. And

Speaker 1:          00:24:19       can you comment on consciousness and how yous see it? Because I think we'll talk about programming quite a bit. We'll talk about, you know, intelligence connecting to programming fundamentally, but the consciousness consciousness is this whole lot of other thing. Do you think about it often as a developer of a programming language

Speaker 2:          00:24:40       and, and as a human, those, those are pretty sort of separate topics? My sort of, my line of work working with programming does not involve anything that that goes in the direction of developing intelligence or consciousness. But sort of privately as an avid reader of popular science writing, I I have some thoughts which, which is mostly that I don't actually believe that consciousness is an all or nothing thing. I have a feeling that, and I forget what I read that influenced this, but I feel that if you look at a cat or a dog or a mouse, they have some form of intelligence. If you look at a fish it has some form of intelligence and that evolution just took a long time. But I feel that the, the sort of evolution of more and more intelligence that led to, to sort of the human form of intelligence followed the evolution of does census, especially the visual sense. I mean there is an enormous amount of processing that's needed to interpret a scene and humans are still better at that then then computers are, yeah. And so and, and, and I have a feeling that there is a sort of

Speaker 6:          00:26:34       okay

Speaker 2:          00:26:35       dare the reason that that like mammals is in particular developed the levels of that they have and then eventually read sort of into from going from intelligence to to self awareness and consciousness has to do with sort of being a robot that has very highly developed census

Speaker 1:          00:26:58       as a lot of rich sensory information coming in. So the, that's a really interesting thought that the, that whatever that basic mechanism of DNA, whatever that basic building blocks of programming is you, if you just add more abilities, more, more uh, high resolution sensors, more sensors, you just keep stacking those things on top that this basic programming in trying to survive develops very interesting things that start to us humans to appear like intelligence and consciousness.

Speaker 2:          00:27:32       Yeah. So in, in, in, as far as robots go, I think that the self driving cars have the sort of,

Speaker 6:          00:27:40       yeah,

Speaker 2:          00:27:41       the greatest opportunity of developing something like that because

Speaker 6:          00:27:46       okay.

Speaker 2:          00:27:47       When I drive myself, I don't just pay attention to the rules of the road.

Speaker 6:          00:27:53       Okay.

Speaker 2:          00:27:53       I also look around and I get clues from that. Oh, this is a shopping district. Oh, here's an old lady crossing the street. Oh, here is someone carrying a pile of mail. There's a mailbox at that shit. They're gonna cross the street to reach that mailbox. And I slowed down and I don't even think about that. Yeah. And, and so there is, there is so much where you turn your observations into an understanding of what other consciousnesses are going to do or what other systems in the world are going to be. Oh, that two he is gonna fall. Yeah. I see sort of, I see much more of a, I expect somehow that if anything is going to become conscious, it's going to be the self driving car and not the network of a bazillion computers at in a Google or Amazon data center that are all network together to uh, to do whatever they do.

Speaker 1:          00:29:04       So in that sense, so you actually highlight, cause that's what I work in autonomous vehicles. You highlight big gap between what we currently can't do and what we truly need to be able to do to solve the problem under that formulation. Then consciousness and intelligence is something that basically a system should have in order to interact with us humans as opposed to some kind of abstract notion of, of uh, uh, consciousness. Consciousness is something that you need to have to be able to empathize, to be able to, um, fear the, understand what the fear of death is. All these aspects that are important for interacting with pedestrians need to be able to do basic computation based on our human desires and thoughts.

Speaker 2:          00:29:57       Sort of. Yeah. If you, if you look at the dog, the dog clearly knows. I mean, I'm not the dog out under my belt. I have friends who have dogs. The dogs clearly know what the humans around them are going to do, or at least they have a model of what those humans are going to do. And they learn the dog. Some dogs know when you're going out and they want to go out with you. They are sad when you leave alone, they cry. Uh, they're afraid because they were mistreated when they were younger. Uh, we, we don't assign sort of consciousness to dogs or at least not, not all that much, but I also don't think they have none of that. So I think it's, it's consciousness and intelligence are not all or nothing.

Speaker 1:          00:30:50       The spectrum, it's really interesting. But in returning to,

Speaker 2:          00:30:55       yeah,

Speaker 1:          00:30:56       programming languages and the way we think about building these kinds of things about building intelligence, building consciousness, building artificial beings. So I think one of the exciting ideas came in the 17th century and with a lightness hubs to cart where there's this feeling that you can convert all thought, all reasoning, all the thing that we find very special in our brains. You can convert all of that into logic so you can formalize it, former reasoning and then once you formalize everything, all of knowledge, then you can just calculate and that's what we're doing with our brains is we're calculating. So there's this whole idea that we, that this is possible that this one,

Speaker 2:          00:31:40       if you weren't aware of the concept of pattern matching in the sense that we are aware of it now a day, sort of thought you, they had this covered incredible bits of mathematics like newtons, calculus and dare sort of idealism, dare, dare sort of extension of what they could do with logic and math sort of went along those lines and they fought

Speaker 2:          00:32:14       Doris Doris like yeah, logic. There's, there's like a bunch of rules and a bunch of input. They didn't realize that how you recognize a face is not just a bunch of rules, but is there a shit ton of data plus, uh, a circuit that that sort of interprets the visual clues and the context and everything else and somehow can massively parallel pattern match against stored rules. I mean, but if I see you tomorrow here in front of the Dropbox offers, I might recognize you even if I'm wearing a different shirt. Yeah. But if I, if I see you tomorrow in a coffee shop in Belmont, I might have no idea that it was you or on the beach or whatever. And I make those kind of mistakes myself all the time. I see someone that I only know as like, oh, this person is a colleague of my wife's. Yeah. And then I see them at the movies and

Speaker 1:          00:33:18       I don't recognize them. But do you see those, you call it pattern matching. Do you see that rules is, uh, unable to encode that to you? Everything. You see all the pieces of information. You look around this room, I'm wearing a black shirt. I have a certain height. I'm a human. All of these you can, there's probably tens of thousands of facts. You pick up moment by moment about this scene. You take them for granted and you accumulate, aggregate them together to understand the scene. You don't think all of that could be encoded to where at the end of the day you can just put it all on the table and calculate, oh,

Speaker 2:          00:33:57       I don't even know what that means. I mean, yes, in the sense that there is no there, there is no actual magic dare, but there are enough layers of abstraction from sort of from the facts as they enter my eyes and my ears to the understanding of the scene that that I don't think that that AI has really covered enough of, of,

Speaker 4:          00:34:26       yeah.

Speaker 2:          00:34:27       Of that distance. It's like if you take a human body and you realize it's built out of Adam's well that that is a uselessly reductionist view. Right? Right. The body is built out of organs. The organs are built out of cells. The cells are built out of proteins. The proteins are built out of amino acids. The amino acids are built out of Adams and then you go to quantum mechanics.

Speaker 1:          00:34:57       So that's a very pragmatic view. I mean obviously as an engineer I agree with that kind of view, but I also, you also have to consider the, the, the Sam Harris view of, well we'll intelligence is just information processing these, just like you said, you take in sensory information, he do some stuff with it and you come up with actions that are intelligent,

Speaker 2:          00:35:20       that make, he makes it sound so easy. I don't know who Sam Harris is.

Speaker 1:          00:35:24       Uh Oh. Uh Oh, it's philosopher. So like this how philosophers often think, right? Essentially that's what the car, it was, wait a minute. If there is, like you said, no magic. So you basically says it doesn't appear like there's any magic, but we know so little about it that it might as well be magic. So Jay, just because we know that we're made of atoms just because we know we're made of Oregon's the fact that we know very little hot to get from the Adams to organs in a way that's three creatable means it that you shouldn't get too excited just yet about the fact that he figured out that we're made of atoms.

Speaker 2:          00:36:02       Right. And, and, and the same about taking facts as are our sensory organs. Take them in and turning that into reasons and the actions that sort of Darryl, lots of abstractions that we haven't quite figured out how to, how to deal with those. I mean, I,

Speaker 2:          00:36:27       so sometimes I didn't know if I can go on a tangent or not to lose a drag you back in. Sure. So if I take a simple program that parses, uh, say, say I have a compiler, it parses the program. In a sense, the input routine of that compiler of the parser is a sense a sensing Oregon and it builds up a mighty complicated internal representation of the program had just saw. It doesn't just have a linear sequence of bytes representing the text of the program anymore. It has an abstract syntax tree and I didn't know how many of your viewers or listeners are familiar with compiler technology, but there is fewer and fewer these days. All right. Uh, that's also true. Probably people want to take a shortcut, but there is sort of this abstraction is a data structure that's the compiler then uses to produce outputs that is relevant, like a translation of the program to machine code that can be executed by by hardware and then the data structure gets thrown away when a fish or a fly sees sort of gets visual impulses. I'm sure it also builds up some data structure and for the fly that may be very minimal. A fly may may have only a few. I mean in the case of a fly's brain, I could imagine that there are

Speaker 4:          00:38:15       okay

Speaker 2:          00:38:16       few enough layers of abstraction that it's not much more than when it's darker here than it is here. Well, I can sense motion because of fly sort of response when you move your arm towards it. So clearly it's visual processing is intelligent or not intelligent, but it has in an abstraction for emotion and we still have similar things in in but much more complicated in our brains. I mean otherwise you couldn't drive a car if you couldn't if you didn't have an incredibly good abstraction for motion.

Speaker 1:          00:38:54       Yeah. In some sense the same attraction for motion is probably one of the primary sources of our, of information for us. We just know what to do. I think we know what to do with that. We've built up other obstructions on top

Speaker 2:          00:39:08       much more complicated data structures based on that and we build more persistent data structures sort of after some processing. Some information sort of gets stored in our memory pretty much permanently and and is available on the recall. I mean there are some things that you sort of, you're conscious that you're remembering it. Like you give me your phone number a, well, at my age I have to write it down, but I could imagine, I could remember those seven numbers are 10, 10 digits and reproduce them in a while if I sort of repeat them to myself a few times. Uh, so that's a fairly conscious form of memorization. On the other hand, how do I recognize your face? I have no idea. My brain has a whole bunch of specialized hardware that knows how to recognize faces. I don't know how much of that is sort of coded in our DNA and how much of that is trained over and over between the ages of zero and three, but, but, but somehow our brains know how to do lots of things like that, that are useful in our interactions with, with other humans, with, without really being conscious

Speaker 1:          00:40:28       just of how it's done anymore. Right? So, so what our actual day to day lives, we're operating at the very highest level of abstraction where we're just not even conscious of all the little details underlying it. There's compilers on top of sec turtles on top of turtles or turtles all the way down. It's composite all the way down. But that's essentially, you say that there's no magic. That's what I, what I was trying to get at I think is with Deckard started this whole train of saying that there's no magic. I mean there's all this before.

Speaker 2:          00:41:00       Also have the notion though that the soul and the body where we're fundamentally

Speaker 1:          00:41:06       separate. Yeah. I think he had to write in God in there for political reasons. So I don't, I don't actually, I'm not historian. Uh, but there's notions in there that all of reasoning, all of human thought can be formalized. I think that continued in the 20th century with, with the Russell and with, uh, with Gail's, uh, incompleteness Theorem, this debate of what, what, what are the limits of the things that could be formalized. That's the Turing machine came along and this is exciting idea. I mean, underlying a lot of computing that you can do quite a lot with a computer. You can, you can encode a lot of the stuff we're talking about in terms of recognizing faces and so on. Theoretically in an algorithm that can then run on a computer. And in that context I like to ask programming in a philosophical way.

Speaker 2:          00:42:02       So what, so what is what, what is it

Speaker 1:          00:42:04       mean to program a computer? So he said you write a python program or a compiled c plus plus programming that compiles to some bike code. It's forming layers. You're, you're, you're programming a layer of abstraction that's higher. How do you see programming in that context? Can it keep getting higher and higher levels of abstraction?

Speaker 2:          00:42:29       I think in a span of, at some point the higher level of levels of obstruction will not be called programming and they will not resemble what we, we call programming at the moment. There will not be source code. I mean there will still be source code sort of adds a lower level of the machine just like they're still molecules and electrons and, and sort of proteins in our brains. But and, and so there are still programming and, and, and system administration. And who knows what's keeping to keep the machine running. But what the machine does is, is a different level of abstraction in a sense. And as far as they understand the way that for last decade or more people have made progress with things like facial recognition or the self driving cars is all by endless endless amounts of training data where at least as as as a lay person and I feel myself totally as a lay person in that field it looks like.

Speaker 6:          00:43:45       Yeah,

Speaker 2:          00:43:46       the researchers who published the results don't necessarily know exactly how, how their algorithms work and

Speaker 6:          00:43:56       okay.

Speaker 2:          00:43:57       I often get upset when I sort of read a sort of a fluff piece about Facebook in the newspaper or social networks and they say, well, algorithms and it, that's like a totally different interpretation of the word algorithm. Yeah. Because for me, the way I was trained or what I learned when I was eight or 10 years old, and an algorithm is a set of rules that you completely understand that can be mathematically analyzed and, and, and you can prove things. You can proof that Eris Dasani Civ produces all prime numbers and only prime numbers.

Speaker 1:          00:44:39       Yeah. So the, I don't know if you know who capacity is, I'm afraid not. So he's a head of AI at Tesla now, but he was at Stanford before and he has this cheeky way of calling this concept software 2.0 to, let me disentangle that for a second. So, so kind of what you're referring to as the traditional traditional, the algorithm, the concept of an algorithm is something that's there. It's clear, you can read it, you understand it, you can prove it's functioning as kind of software 1.0 and what software 2.0 is is exactly what you described, which is you have neural networks, which is a type of machine learning that you feed a bunch of data and that neural network learns to do a function. All you specifies the inputs and the outputs you want and you can't look inside, you can't analyze it. All you can do is train his function to map the inputs, the outputs by giving a lot of data. And that sense programming becomes getting a lot of cleaning, getting a lot of data. That's what programming is a in as well. That would be programming 2.0 2.02 programming 2.0

Speaker 2:          00:45:53       I wouldn't call it that. Programming it, it's just a different activity. Just like building organs out of cells is not called chemistry.

Speaker 1:          00:46:03       Well, so let's just, uh, let's just step back and think sort of more generally. I've of course, but you know, it's like, uh, as a parent teaching, teaching your kids things can be called programming in that same sense that that's hot program has been used. You providing them data, examples use cases. So imagine writing a function not by, uh, not with four loops and uh, clearly readable text, but more saying, well, here's a lot of examples of what this function should take. And here's a lot of examples of when it takes those functions. It should do this and then figuring out the rest. So that's 2.0 concept. And the question I have for you usually it's like it's a very fuzzy way. This is the reality of a lot of these pattern recognition systems. And so it's a fuzzy way of quote unquote programming. What do you think about this kind of world? Uh, it should, it, should it be called something totally different than a programming? It's like if you're a software engineer, does that mean you're, you're designing systems that are very, can be systematically tested, evaluated, they have a very specific specification and then this other fuzzy 2.0 world machine learning world. That's something else. Totally. Or is there some intermixing that it's possible?

Speaker 5:          00:47:40       Well, the question is probably only being as, because we don't quite know what that software 2.0 actually is and it sort of a think there is a truism that every task that AI has has tackled in the past. At some point we realized how it was done and then it was no longer considered part of artificial intelligence because it was no longer necessary to, to use that term. It was just, Oh, now we know how to do this. And a new field of science or engineering has been developed and I don't know if sort of every form of learning or sort of controlling computer systems should always be called programming. So I did, I don't know, maybe I'm focused too much on the terminology I, but I expect that debt, there just will be different concepts where people with sort of different education and a different model of what they're trying to do. Uh, will, we'll develop those concepts. Yeah.

Speaker 1:          00:49:07       I guess if you could comment, and another way to put this concept is I think, I think the kind of functions that neural networks provide is things as opposed to being able to upfront prove that this should work for all cases. You throw at it all, you're able, it's the worst case analysis versus average case analysis. All you able to say is it's, it seems and everything we've tested to work 99.9% of the time, but we can't guarantee it and it, it fails in unexpected ways or give me me give you examples of how it fails in unexpected ways, but it's like really good most of the time. Yeah. But there no room for that in current ways. We think about programming.

Speaker 6:          00:49:56       Yeah.

Speaker 5:          00:49:56       Uh,

Speaker 6:          00:49:59       yeah.

Speaker 5:          00:50:00       Programming 1.0 is actually sort of getting to that point to where there's sort of the ideal of a bug free program has been abandoned long ago by most software developers. We only care about bugs that manifest themselves often enough, be annoying and we're willing to take the occasional crash or outage or incorrect result,

Speaker 3:          00:50:37       uh,

Speaker 5:          00:50:39       for granted because we can't possibly, we don't have enough programmers to make all the code book free. And it would be an incredibly tedious business. And if you try to throw formal methods added, it gets, it becomes even more tedious. So every once in a while the user clicks on a link in and somehow they get an error and the average user doesn't panic. They just click again and see if it works better the second time, which often magically it does. Or they go up and they try some other way of performing their tasks. So that's sort of an end to end recovery mechanism and inside systems there is all sorts of retries and timeouts and fallbacks. And I imagine that that sort of biological systems are even more full of that because otherwise they wouldn't survive.

Speaker 1:          00:51:46       Do you think programming should be taught and thought of as exactly what you just said? I come from is kind of um, you're, you're almost denying that fact always

Speaker 5:          00:52:00       in insertive basic programming education, there's sort of the programs you're, you're having students write are so small and simple

Speaker 3:          00:52:16       debt.

Speaker 5:          00:52:19       If there is a bug, you can always find it and fix it because the sort of programming as it's being taught in some even elementary middle schools in highschool introduction to programming classes in college, typically it's programming in the small, very few classes sort of actually teach software engineering, building large systems. I mean every summer here at Dropbox we have a large number of interns. Every tech company in on the West Coast has the same thing. These interns are always amazed because this is the first time in their life that they see what goes on in a really large software development environment and everything they've learned in college was almost always about a much smaller scale and somehow that difference in scale makes a qualitative in how you,

Speaker 2:          00:53:26       how you do things and how you think about it.

Speaker 1:          00:53:29       If you then take a few steps back into decades, 70s and 80s when you were first thinking about python or just that world of programming languages, the, did you ever think that there would be systems as large as underlying Google, Facebook and Dropbox? Did you, when you were thinking about python,

Speaker 2:          00:53:51       I was actually always caught by surprise by every state. Yeah. Pretty much every stage of computing.

Speaker 1:          00:53:59       So maybe just because, um, you spoken in other interviews, but I think the evolution of programming languages are fascinating. It's especially because it leads from my perspective towards greater and greater degrees of intelligence. I learned the first programming language I played with in, in Russia was, um, well the turtle logo logo. Yeah. And, uh, and, and if you look, I just have a list of programming languages, all of which have no have played with a little bit. I mean, they're all beautiful in different ways from Fortran, cobol, Lisp, Algol 60 basic logo. Again, see, um, as a few, uh, the object oriented came along in the 60s. Simula Pascal, small talk, all of that leaves the classics. The classics. Yeah. The classic hits, Right. Uh, scheme built that's built on top of the list on the database side, SQL c plus plus, and all of that leads up to Python, Pascal to, that's before python and Matlab, these kinds of different communities, different languages.

Speaker 1:          00:55:10       So can you talk about that world? I know that I'm sort of python came out of ABC, which actually never knew that language. I just, I haven't researched this conversation. Went Back to ABC and it looks remarkably, it, it has a lot of annoying qualities, but underneath those like all caps and so on. Uh, but underneath that there's elements of python that are quite, they're already there. I got all the good stuff, all the good stuff. So, but in that world, you're swimming these programming languages where you focused on just the good stuff in your specific circle or did you have a sense of what, what does everyone chasing? You said, um, that every programming language is built to scratch an itch. Were you aware of all the itches in the community and if not, or if yes. I mean, what we trying to scratch with python?

Speaker 2:          00:56:05       Well, I'm glad I wasn't aware of all the itches because I would probably not have been able to do anything. I mean, if you're trying to solve every problem at once and you'll saw nothing, well yeah. And it's, it's too overwhelming. Yeah. And so I had a very, very focused problem. I wanted a programming language that sets,

Speaker 3:          00:56:31       yeah,

Speaker 2:          00:56:32       somewhere in between Shell scripting and see

Speaker 3:          00:56:38       and no,

Speaker 2:          00:56:41       arguably dairies like one is higher level, one is lower level

Speaker 3:          00:56:48       and

Speaker 2:          00:56:49       by film is sort of a language of an intermediate level, although it's still pretty much at the high level. And I was, I was thinking about much more about I want a tool that I can use to be more productive as a programmer in a very specific environment. Uh, and I also had given myself a time budget for the development of the tool and that was sort of about three months for both the design, like thinking through what are all the features of the language syntactically and semantically and how do I implement the whole pipeline from parsing the source code to executing it.

Speaker 1:          00:57:43       So I think both with the timeline and the goals, it seems like productivity was at the core of it, that as a goal. So like for me, in the 90s and a, the first decade of the 21st century, I was always doing machine learning. Ai Programming for my research was always in c plus plus. Wow. And then, and then the other people who are a little more mechanical engineering, electrical engineering are our mat lobby. Uh, the, that a little bit more mat lab focus, those are the world them and maybe a little bit Java to, uh, but no people who are more interested in. And I'm emphasizing the object oriented nature of things. So we'll then in um, last 10 years or so, especially with the oncoming of neural networks in these packages are built on python to interface with, with the neon that works. I switched to python and it's just, I've noticed a significant boost that I can't exactly, cause I don't think about it, but I can't exactly put into words why I'm just much, much more productive.

Speaker 1:          00:58:52       Just being able to get the job done much, much faster. So how do you think whatever that qualitative differences, I don't know if it's quantitative, it could be just a feeling. I don't know if I'm actually more productive, but how do you think about, yeah. Well, uh, that, that's right. I think there's an elements and they just speak to one aspect that I think those effects I productivity is plus was was I really enjoyed creating performant code and creating a beautiful structure where everything that, you know, this kind of going into this, especially with the newer, newer standards of templated programming, of just really creating this beautiful, a formal structure that I found myself spending most of my time doing that as opposed to getting, parsing a file and extracting and few keywords or whatever the task was trying to do. So what is it about python and how do you think of productivity in general as you were designing it now sort of through the decades, last three decades? What do you think it means to be a productive programmer?

Speaker 3:          00:59:59       Okay.

Speaker 1:          01:00:00       How did you try to design it into language?

Speaker 5:          01:00:03       There are different tasks and as a programmer it's, it's useful to have different tools available that sort of are suitable for different tasks, right? So I still write c code, I still write shellcode, but I write most of my, my things in python.

Speaker 3:          01:00:23       Uh,

Speaker 5:          01:00:25       why do I still use those other languages? Because sometimes the task just demands it. And well, I would say most of the time the task actually demands a certain language because the task is not write a program that solves problem x from scratch, but it's more like fix a bug in existing program acts or add a small feature to an existing large program.

Speaker 3:          01:00:53       Uh, but

Speaker 5:          01:00:58       even if, if you sort of, if you're not constrained in your choice of language by context like that,

Speaker 3:          01:01:08       uh,

Speaker 5:          01:01:09       dairy is still the fact that if you write it in a certain language, then you sort of, you, you have this balance between how long does it time, does it take you to write the code and how long does the code run?

Speaker 3:          01:01:30       Right. And

Speaker 5:          01:01:33       when you're in sort of in the phase of exploring solutions, you often spend much more time writing the code done, running it because every time you've sort of, you've run it, you see that the output is not quite what you wanted and you spend some more time coding.

Speaker 3:          01:01:55       Uh, and

Speaker 5:          01:01:59       a language like python just makes death iteration much faster because there are fewer details. There is a large library, uh, sort of there fewer details that, that you have to get right before your program compiles and runs a, there are libraries that don't do all sorts of stuff for you so you can sort of very quickly take a bunch of existing components, put them together and uh, get your prototype application running. Just like when I was building electronics, I was using a breadboard most of the time. So I had this like sprawl out circuits that if you shook it, it would stop working because it was not put together very well, but it functioned and all I wanted was to see that it worked and then move on to the next, next schematic or design or add something to it. Once you've sort of figured out, oh, this is the perfect design for my radio or light sensor or whatever, then you can say, okay, how do we design a PCB for this? How do we solve it or the components in a small space? How do we make it so that it is robust against, uh, say voltage fluctuations or mechanical, uh, disruption? I mean, I know nothing about that when it comes to designing electronics, but I know a lot about that when it comes to to writing code.

Speaker 1:          01:03:40       So the initial initial steps are uh, the efficient fast and there's not much stuff that gets in the way. But you're kind of describing, um, from a, like Darwin described the evolution of species, right? You're, you're, you're observing of what is about true about python. Now if you take step back, if the art of, if the act of creating languages is art and you had three months to do it, initial stubs, and so you just specified a bunch of goals, sort of things that you observe about python. Perhaps you had those goals, but how do you create the rules, the syntactic structure, the, the features that result in those? So I have in the beginning and they have followup questions about through the evolution of Python two. But in the very beginning when you were sitting there creating the lexical analyzer or whatever,

Speaker 5:          01:04:36       evolution was still a big part of it because I sort of, I said to myself, I don't want to have to design everything from scratch. I'm going to borrow features from other languages that I like. Oh, interesting. So you basically, exactly. You first observe what you like. Yeah. And so that's why if you're 17 years old and you want to sort of create a programming language, you're not going to be very successful at it because you have no experience with other languages. Whereas I was in my, let's

Speaker 2:          01:05:17       say mid thirties,

Speaker 3:          01:05:20       uh,

Speaker 2:          01:05:21       I hadn't written parsers before, so I had worked on the implementation of ABC. I had spent years, the Baiting, the design of ABC with its authors. It's the, with its designers. I had nothing to do with the design. It was designed fully as it was when ended up being implemented when I joined the team. But so you borrow ideas and concepts and very concrete sort of local rules from different languages, like the indentation and certain auto syntactic features from ABC. But I chose to borrow string literals and how numbers work from C and and various other things.

Speaker 1:          01:06:07       So in then, if you take that further, so yet you've had this funny sounding, but I think surprisingly accurate and or at least practical a title of a benevolent dictator for life for quite, you know, for the last three decades or whatever, or no, not the actual title, but functionally speaking. Uh, so you had to make decisions, design decisions, can you maybe let's take python to python releasing python three as an example. It's not backward compatible to python two in, in ways that a lot of people know. So what was that deliberation discussion decision like? Yeah. What was the psychology of that experience? Do you regret any aspects of how their experience undergone?

Speaker 2:          01:06:59       Yeah. So it was a group process really at that point, even though I was BDFL in nine in name and, and certainly everybody's sort of respected my, my position as the creator and the current sort of owner of the language design. I was looking as everyone else for feedback, sort of python three. Dot. Oh. In some sense was sparked by author people in the community, uh, pointing out, oh well there are a few issues that sort of bite users over and over. Can we do something about that? And for Python three we took a number of those python wards as they were called at the time. And we said, can we try to sort of make small changes to the language that addressed those warts? And we had sort of in the past we had always taken backwards compatibility very seriously. And so many python warts in earlier versions had already been resolved because they could be resolved while maintaining backwards compatibility or sort of using the theory gradual path of evolution of the language in a certain area.

Speaker 2:          01:08:31       And so we were stuck with a number of warts that were widely recognized as problems, not like roadblocks, but nevertheless sort of things that some people trip over. And you know, that that's always the same thing that, that people trip over when they trip. And we could not think of a backwards compatible way of resolving those issues, but it's still an option to not resolve the issues. Right. And so, yes, for, for a long time we had sort of resigned ourselves to, well, okay, the language is not going to be perfect in this way. And that's way in that way. And we sort of, certain of these, I mean there are still plenty of things where you can say, well that's, that particular detail is better in Java or in our or in visual basic or whatever. Uh, and we're okay with that because, well, we can't easily change it. Uh, it's not too bad. We can do a little bit with user education where we can have a static analyzer or warnings, uh, in, in the parts or something. But there were things where we thought, well these are really problems that are not going away, Derek getting worse in the future.

Speaker 2:          01:10:00       Uh, we should do something right,

Speaker 1:          01:10:02       should do something. But ultimately there is a decision to be made, right? Yes. So was that the toughest decision in the history of python yet to make as the benevolent dictator for life or if not, what are, are there maybe even on a smaller scale, what was the decision where you were really torn up about

Speaker 2:          01:10:22       well, the toughest decision was probably to resign.

Speaker 1:          01:10:27       All right, let's go there. Hold on a second then. Let me just, because in the interest of time too, cause I have a few cool questions for you. I mean let's touch a really important one because it was quite dramatic and beautiful and certain kinds of ways, uh, in July this year, three months ago you wrote, now that pep five 72 is done. I don't ever want to have to fight so hard for a pap and find that so many people despise my decisions. I would like to remove myself entirely from the decision process. I still be there for awhile as an ordinary core developer and I'll still be available to mentor people, possibly more available, but I'm basically giving myself a permanent vacation from being BDFL benevolent dictator for life and you all will on your own, Christophe. Just this, it's a, it's almost Shakespearean. I'm not going to appoint a successor, so what are you're all going to do? Create a democracy. Anarchy, a dictatorship, a federation. So that was a very dramatic and beautiful a set of statements. It's almost, that's open ended nature called the community to create a future for python is this kind of beautiful aspect to it. Wow. If so, what? And and dramatic, you know, what was making that decision like what was on your heart, on your mind? Stepping back now a few months later, we could take me through your mic. Okay.

Speaker 5:          01:11:55       Thank you. Bless you. Liked of writing because it was actually written pretty quickly. It was literally something like after months and months of going around in circles, I had finally approved pep five 72 which I had a big hand in its design, although I didn't initiate it originally. I sort of gave you the bunch of nudges in a direction that would be better for the language. So sorry. So sorry. Just to ask as a CIO is no one or no, no, pep five 72 was actually uh, a small feature, which is assignment expressions or assignment expressions. Okay. Debt had been

Speaker 6:          01:12:51       okay.

Speaker 5:          01:12:51       I thought there was just a lot of the bay to where a lot of people claimed that day knew what was python I can with was not python sick. And they knew that this was going to destroy the language. This was a violation of pythons, most fundamental design philosophy. And I thought that was all bullshit because I was in favor of it and I would think I know something about pythons design philosophy. So I was really tired and also stressed of that thing. And literally after sort of announcing I was going to accept it a certain Wednesday evening, I had finally send the email, it's accepted now let's just go implement it. Uh, so I went to bed feeling really relieved that's behind me and I wake up Thursday morning, 7:00 AM and I think, well that was the last one that's going to be such, such a terrible debate and that's a going to be, that's the last time that I let myself be so stressed out about a pep decision.

Speaker 5:          01:14:05       Yeah. I should just resign. I've been sort of thinking about retirement for half a decade. I've been joking and sort of mentioning retirement, sort of telling the community some point in the future I'm going to retire. Yeah. Don't take the F l a part of my title too literally. And I thought, okay, this is it. I'm done. A uh, had the day off. I wanted to have a good time with my wife. We were going to a little beach town nearby, uh, and in he think maybe 15, 20 minutes, I wrote that thing dead. You just called Shakespearian. And the funny thing is I get so much crap for calling your Shakespeare. I didn't even realize what a monumental decision it was because five minutes later I read that a link to my message back on Twitter where people were already discussing on Twitter, Guido resigned as the BDFL and I had, I had posted it on an internal forum that I thought was only read by core developers. So I thought I would at least have one day before news would sort of get out

Speaker 1:          01:15:28       the on your own aspect. I had also an element of quite, it was quite a powerful element of the uncertainty that lies ahead. But can you also just briefly talk about, you know like for example I played guitar as a hobby for fun and whenever I play people are super positive, it's super friendly, they're like, this is awesome, this is great. But sometimes I enter as an outside observer, I entered the program in community and there seems to some sometimes be camps and whatever the topic and and the two camps, the two or plus camps often pretty harsh a criticizing the opposing camps as, as an onlooker. I may be totally wrong on this.

Speaker 5:          01:16:13       Yeah, well like wars are, are sort of a favorite activity in the programming community.

Speaker 1:          01:16:20       And what is the psychology behind that? Is, is that okay for healthy community to have? Is that, is that a productive force

Speaker 5:          01:16:27       similarly for the evolution of the language? Well, if everybody is patting each other on the back and never telling the truth, yes.

Speaker 3:          01:16:36       Uh,

Speaker 5:          01:16:38       it would not be good thing. I think there is a middle ground where sort of being nasty to each other is not okay. But dare dare is, is, is a middle ground where there is healthy ongoing criticism and feedback that is very productive. And you, you mean at, at every level you see that, I mean, someone proposes to

Speaker 2:          01:17:09       fix a very small issue in a code base. Uh, chances are that some reviewer will sort of respond by saying, well, actually you can do it better the other way.

Speaker 3:          01:17:24       All right. Uh,

Speaker 2:          01:17:26       when it comes to deciding on the future of the Python, the core developer community, we now have I think five or six competing proposals for a constitution.

Speaker 1:          01:17:41       So that future, do you have a fear of that future? Do you have a hope for the future?

Speaker 2:          01:17:48       Confident about that future it by and large, I think that the debate has been very healthy and productive. Uh, and I actually went, when I wrote that resignation email, I knew that that python was in a very good spot and that the python core development community, the, the group of 50 or a hundred people who sort of write or review most of the code that goes into python, those people get along very well. Most of the time. Uh, a large number of different areas of expertise are represented.

Speaker 3:          01:18:34       Uh,

Speaker 2:          01:18:36       different levels of experience in the Pif of Corp Dev community, different levels of experience completely outside in software development, in general, large systems, small systems, embedded systems. So I, I felt okay resigning because I knew that that the community can really take care of it itself.

Speaker 1:          01:19:03       And out of a grab bag of future feature developments, let me ask if you can comment maybe on all very quickly, concurrent programming, parallel computing, asynch io. These are things that people have, uh, expressed hope, complained about, whatever have discussed on, on reddit a sink. I also the parallelization in general, uh, packaging, I was totally clueless on this. I just use Pixton install stuff, but apparently there's pip and of poetry. There's these dependency packaging systems that manage dependencies and so on that are emerging and there's a lot of confusion about what's, what's the right thing to use. Then also a functional programming. The the ever, you know, uh, the, the, the uh, I we're going to get more functional programming or not this kind of, this kind of idea. And of course the uh, the, the Gill as a connected to the parallelization I suppose the global interpreter lock problem. Can you just comment on whichever you want to comment on?

Speaker 2:          01:20:13       Well, let's take the gill and pure realization and asynch io as one one topic. I'm not that hopeful debt python will develop into a sort of high concurrency hi parallelism language that sort of, the way the language is designed, the way most users use the language, the way the language is implemented, all make that a pretty unlikely future.

Speaker 1:          01:20:50       So you think it might not even need to really the way people use it. It might not be something that should be of great

Speaker 2:          01:20:57       I think. I think asynch io is a special case because it sort of allows overlapping io and only io and doubt is, is a sort of best practice of supporting very high throughput io many collections. Uh, for a second. Uh, I'm not worried about that. I think async io will evolve. There are a couple of competing packages. We have some very smart people who are sort of pushing us in sort of to make a CIO better parallel computing. I think that python is not the language for that. Uh, there are, there are ways to work around it, but you sort of, you can't expect to write an algorithm in python and have a compiler automatically paralyzed that what you can do is use a package like num Pi and there are a bunch of other very powerful packages that sort of use all the CPS available because you tell the package, here's the data, here's the abstract operation to apply over and go at it. And then, then we're back in the C plus plus world. But the, those packages are themselves implemented usually in c plus plus.

Speaker 1:          01:22:23       That's right. That's where it tensorflow and all these bags just coming where they paralyzed because gps for example, they'd take care of that for you. So in terms of packaging, uh, can you comment on,

Speaker 2:          01:22:33       Ah, coaching and packaging has always been my least favorite topic. It's, it's, it's a really tough problem because a d o s and the platform one to own packaging, uh, but dare packaging solution is not specific to a language. Like if you take Linux, there are two competing packaging solutions for Linux or Unix

Speaker 5:          01:23:06       in uh, in general and, but they all work across all languages and several languages like node, javascript, uh, and Ruby and python all have their own packaging solutions that only work within the ecosystem of that language. Well, what should you use? That is a tough problem. My own own approach is I use the system packaging system to install python and I use the python packaging system den to install third party python packages. That's what most people do. 10 years ago, Python packaging was really a terrible situation. Nowadays, pip is the future. There is, there is a separate ecosystem for a numerical and scientific Picom Python based on Anaconda dose two can live together. I don't think there is a need for more than that. Great. So that's, that's packaging.

Speaker 1:          01:24:14       That's, well, at least for me that's, that's where I've been extremely happy. I, I didn't, I didn't even know this was an issue until it was brought up. Well, in the interest of time, I mean you sort of skipped through a million other questions I have. So watch the five hour, five, five and a half hour oral history, uh, the abdominal, the Computer History Museum and the Nice thing about it, it gave this, because of the linear progression of the interview, he gave this feeling of a life, you know, a life well lived with interesting things in it. Um, sort of a pretty, I would say a good spend of, of this little existence we have on earth. So outside of your family, looking back, what about this journey are you really proud of? Are there moments that stand out? Accomplishments, ideas? Is it the creation of python itself? The stands out as a thing that you look back and say, damn, I did pretty good there.

Speaker 6:          01:25:16       Okay.

Speaker 5:          01:25:17       Well, I would say that python is definitely the best thing I've ever done. And I wouldn't sort of say just the creation of python, but the way I sort of raised by form like a baby. I didn't just conceive a child, but I raised a child and now I'm setting the child free in the world. And I've set up the child to, to sort of be able to take care of himself. And I'm, I'm very proud of that.

Speaker 1:          01:25:52       And as the announcer of Monte Python's flying circus used to say, and now for something completely different, do you have a favorite Monty python moment or a moment hitchhiker's guide or any other literature show, a movie that cracks you up when you think about it? Oh, you can always play me. The parents, the dead parent sketch. Oh, that's brilliant. Yeah, that's my favorite as well. Okay, great. Thank you so much for talking with me today. It's been a great conversation.