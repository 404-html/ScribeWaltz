Speaker 1:          00:00:00       The following is a conversation with Thomas San home. He's a professor of same you and Co creator of [inaudible], which is the first AI system to beat top human players in the game of heads up. No limit. Texas hold'em. He has published over 450 papers on game theory and machine learning, including a best paper in 2017 at nips. Now renamed to new reps, which is where I caught up with him for this conversation, has research and companies have had wide reaching impact in the real world, especially because he and his group not only propose new ideas but also build systems to prove that these ideas work in the real world. This conversation is part of the MIT course on artificial general intelligence and the artificial intelligence podcasts. If you enjoy, subscribe on Youtube, iTunes or simply connect with me on Twitter at Lex Friedman, spelled f. R I. D. And now here's my conversation with Thomas sent home.

Speaker 2:          00:01:03       Can you describe at the high level the game of Poker Texas? Hold 'em, heads up Texas hold'em for people who might not be familiar. This card game. Yeah, happy to. So heads up, no, let me fix this. Hold them. It has really emerged in the Ai community as main benchmark for testing these application independent algorithms for imperfect information games holding. And this is a game, uh, that's actually played by humans. You don't see that much on TV or casinos because uh, well for that reverse reasons, but uh, are you do see it in some expert level casinos and you see it in the best poker movies of all time. It's actually an event in the world series of poker, but mostly it's played online and typically for pretty bad big sums of money. And this is a game that usually only experts play. So if you go to your home game on a Friday night, it probably is not going to be heads up.

Speaker 2:          00:02:00       No limit. Texas hold that mic might be, uh, not limit Texas hold'em in some cases, but typically for a big group and it's not as competitive while heads up means it's two player. So it's really like me against you and my better or are you a better much like chess or, or, or go in that sense, but in an imperfect information game, which makes it much harder cause I have to deal with issues of uh, you knowing things that they don't know and I know things that you don't know instead of pieces being nicely laid on the board for both of us to see. So in Texas hold'em, uh, there's uh, two cars that you only see the lawn to you and there is, they gradually layouts some cars that add up overall to five cards that everybody can see. The imperfect nature of the information is the two cards that you're holding in front year.

Speaker 2:          00:02:49       So as you said, you know, you first get two cards in private each and then you, uh, there's a betting rod, then you get three clubs in public on the table, then there's a betting round, then you get the fourth card in public on the table dissipating around. Then you'll get the five fifth card on the table is a big raw. So there's a total of four betting rounds. And for tranches of inflammation, revelation, if you will. The only the first tranche is private and then it's public from there. And this is probably probably by far the most popular game in AI and just the general public in terms of imperfect information. So that's probably the most popular spectator game to watch. Right? So the, which is why it's a super exciting given tackle. So it's a, it's on the order of chess, I would say in terms of popularity, in terms of the AI, setting it as the bar of what is intelligence.

Speaker 2:          00:03:46       So in 2017 liberators, how do you pronounce it, really brought us the broadest, the broadest beats. It'll let him there. A little bit of Latin. A Lebron has beads, a few, uh, for expert human players. Can you describe that event? What you learned from it? What was it like? What was the process in general for people who have not read the papers and the study? Yeah. So the event was that, uh, we invited four or the top 10 players with these are specialists players in heads up, no limit Texas hold'em, which is very important because this game is actually quite different than the multiplayer version. We brought them in to Pittsburgh to play at the Rivers Casino, uh, for 20 days. We wanted to get the hundred and 20,000 hands in because, uh, we wanted to get statistical significance. So it's a lot of hands for humans to play even for these top pros who play fairly quickly normally.

Speaker 2:          00:04:42       So we couldn't just have one of them play so many hands, 20 days. They were playing basically morning to evening and um, uh, you've raised 200,000 as a little incentive for them to play. And the setting was so that they didn't all get 50,000. Um, we actually paid them out based on how they did against the AI each. So they had an incentive to play as hard as they could, whether they're way ahead or way behind or right at the mark of beating their Ai. And you don't make any money. Unfortunately, right now we can't make any money. So, so originally a couple of years earlier, I was, uh, actually explored whether we could actually play for money because that would be of course a interesting as well, uh, to play against the top people for money. But the Pennsylvania gaming board said no, so, so we couldn't, so this is much like an exhibit Le uh, like for a musician or a boxer or something like that.

Speaker 2:          00:05:39       Nevertheless, you are keeping track of the money and brought us, uh, one close to $2 million I think so. So if that, if it was for real money, uh, if you were able to earn money, that was a quite impressive and inspiring achievement. Just a few details of what, what were the players looking at? I mean they were they behind a computer? What, what was the interface like? Yes. That they were playing much like they normally do these top players when they play this game, they play mostly online. So they used to playing through a Ui. Yes. And they did the same thing here. So there was this layout. You could imagine there's a table on the screen, this, the, the human sitting there. And then there's the AI sitting there. And the ta, this Korean source, everything that's happening in the Chi is coming out and source the bets being made. And we also had the best in history for the human. So if the human, for God, what had happened in the hand so far, they could actually reference back and, and, and, and so forth. Is there a reason

Speaker 1:          00:06:38       we're given access to the bedding history for,

Speaker 2:          00:06:41       well, we, we just, uh, uh, it's, it didn't really matter that they wouldn't have focused on any way. These are top quality people, but we just wanted to put out there. So it's not a question of what human forgetting and the AI somehow trying to get that advantage of better memory. So what was that like? I mean, that was an incredible accomplishment. So what did it feel like before

Speaker 1:          00:07:02       the event? Did you have doubt,

Speaker 2:          00:07:04       hope, or what, where was your confidence at? Yeah, that's great. So, great question. So, uh, 18 months earlier, I had organized a similar brains versus AI competition without previous AI called Claudico and we couldn't beat the teams. Uh, so, uh, at this time around, it was only 18 months later and I knew that this new, a liberal autos was way stronger, but it's hard to say how you'll do against the top humans before you try it. So I thought we had about a 50 50 shot and the international betting sites, both us, us, us as a four to one or five to one underdog. So it's kind of interesting that people really believe in people and I get over Ai, uh, not just people, people don't just believe over believe in themselves, but they have overconfidence in other people as well compared to the performance of Ai. And uh, yeah, so we were a four to one or five to 100 dog and even after three days of beating the humans in a row, we were still 50, 50. On the international betting sites. Do you think there's something special and magical Bob Poker

Speaker 1:          00:08:10       in the way people think about it? In a sense you have. I mean, even in chess, there's no Hollywood movies. Poker is the star of many movies. And there's this feeling that a certain human facial expressions and body language, eye movement, all these towels are critical to poker. Like you can look into somebody's soul.

Speaker 2:          00:08:35       I understand they're betting strategy and so on there. So that's probably

Speaker 1:          00:08:38       probably why the possibly do you think that is why people have a confidence that humans will output? Because AI systems cannot in this construct, perceive these kinds of tells. They're only looking at bedding patterns and uh, and nothing

Speaker 2:          00:08:56       else. The betting patterns and, and Statistics. So what's more important to you if you step back and human players, human versus human? What's the role of these towels of these, uh, ideas that we romanticize? Yeah. So I, I'll split it into two parts. So one is wider. Humans trust humans more than AI and all have overconfidence in humans. Yes. I think that's, that's not really related. Those are the teller question. It's just that, that they've seen these top layers, how good they are and they're really fantastic. So it's just hard to believe the bad or that the knee, I could beat them. Yeah. So I think that's where that comes from. And, and that's actually maybe a more general lesson about AI until you've seen it over perform a human. It's hard to believe that it could. But, um, then the tailors, um, a lot of these top players, they're so good at hiding tales that among the top players, it's actually not really worth it for them to invest a lot of effort trying to find tellers in each other because they're so good at hiding them.

Speaker 2:          00:10:05       So a yes at the kind of Friday evening game, tell us up going to be a huge thing. You can read other people and if you're a good reader, you'll, you'll read them like an open book. But at the top levels of poker now the tells become a lesson of much, much smaller and smaller aspect of the game. As you go to the top levels, the amount of strategies, the minds of possible actions is, um, is very large, uh, 10 to the power of hundred plus. Uh, so there has to be some, I've read a few papers related to has it has to form some abstractions of various hands and actions. So what kind of abstractions are effective for the game of poker? Yeah, so you're exactly right. So, uh, when you go from a game theory that's 10 to the 161, especially in an imperfect information game, it's weight or life to solve directly even that with our fastest equilibrium finding algorithms.

Speaker 2:          00:11:03       So, uh, you want to abstract it first and abstraction in games is much trickier than abstraction in MDPs are other single agent settings because you have these abstraction pathologies that if I have a finer grained abstraction, the strategy that I can get from that for the real game might actually be worse than the strategy I can get from the coarse grained obstruction. Do you have to be very careful? Now the, the kinds of obstruction is just to zoom out. We're talking about there's the hands obstructions and then there's betting strategies. What wedding actions? Yeah, beating action. So, so there's inflammation obstruction. Talk about general gangs, inflammation obstruction, which is the abstraction of what chance does. And this would be the cogs indication of poker. And then there's action abstraction, which is abstracting the actions of the actual players, which would be fits in the case of poker yourself and the other players and other players.

Speaker 2:          00:12:03       And uh, for inflammation obstruction, we were completely automated. So this was, these are algorithms, uh, with they do what we call potential aware abstraction where we don't just look at the value of the hand, but also how it might materialize in the good or bad hands over time. And it's a certain kind of bottom up process, uh, with integer programming there and clustering and various aspects how you build, build this abstraction. And then in the action abstraction there, it's largely based on how um, humans, other and other ais have played this game in the past. But in the beginning, we actually use an automated action obstruction technology, which is provably convergent that it finds the optimal combination or bed sizes, but it's not very scalable. So we couldn't use it for the whole game, but we used it for the first couple of pitting actions.

Speaker 2:          00:12:59       So what's more important? Uh, the strength of the hand. So the information extraction or the, uh, how you play them. Uh, the actions does it, you know, the romanticized notion again is that it doesn't matter what happens, you have that the actions, the bedding, uh, maybe the way you win, no matter what hands here. So that's why you have to play a lot of hands so that the role of luck gets smaller. So you could otherwise get lucky and get some good hands and then you're going to win the match. Even with thousands of hands, you can get lucky, uh, because there's so much variance in no limit Texas hold'em, because if we both go all in, it's a huge stack, uh, or variants or there are these massive swings in no limit Texas hold'em. So that's why you have to play not just thousands, but, uh, over a hundred thousand hands, they'll get statistical significance.

Speaker 2:          00:13:54       This is, let me ask another way. This question, if you didn't even look at your hands, but they didn't know that the opponents didn't know that, how well would you be able to do? Oh, that's a good question. There's actually, I heard the story that there's this Norwegian female poker player call and it Oberstar who's actually won a tournament by doing exactly that, but that would be extremely rare. So I cannot really play well. No. Okay. So, so that the hands do have some role to play? Yes. So lowbrow does, does not, uh, use as far as I understand, a use learning methods and deep learning is there room for learning in the, you know, the, there's no reason why the US doesn't, you know, combine with an Alphago type approach for estimating the quality a four function estimator. W what are your thoughts on this?

Speaker 2:          00:14:52       Maybe as compared to another algorithm, which I'm not that familiar with deep stack, the, the engine that does use deep learning, that is unclear how well it does, but nevertheless uses deep learning. So what are your thoughts about learning methods to aid in the way that Tele Broaddus plays the game of poker? Yeah. So as you said, Libratone did not use learning methods and played very well without them. Since then, we have actually actually here we have a couple of papers on things that do use learning techniques. Excellent. Uh, so, um, and, and deep learning in particular and uh, sort of the way you're talking about where it's learning and evaluation function. But um, in imperfect information games, unlike let's say in go or now, now also in chess and Shogee, it's not sufficient to learn and evaluation for a state because the value of an inflammation set depends not only on the exact state, but it also depends on both players beliefs.

Speaker 2:          00:15:59       Like if I have a bad hand, I'm much better off if the appointed thinks I'm, I have a good hand and vice versa. If I have a good hand, I'm much better off if the opponent believes I have a bad hand. Uh, so the value of our state is not just a function of the cards, it depends on a, if you will, the path of play. But only do they extent that is captured in the belief distributions. So, so that's why it's not a simple as, uh, as it is imperfect information games. And I don't want to say it simple, they're either, it's of course very complicated computationally there too. But at least conceptually it's very straightforward. There's a state, there's an evaluation function. You can try to learn it here. You have to do something more. Uh, and uh, what we do is in one of these papers were looking at allowing where we allow with the opponent to actually take different strategies at the leaf of the search tree yet if you will.

Speaker 2:          00:16:56       And, and that, uh, is a different way of doing it. And it doesn't assume therefore a particular way that the opponent place, but it allows our opponent to choose from a set of different continuation strategies and that forces us to not be too optimistic in our look ahead search. And that's what, that's one way you can do sound. Look ahead, search in imperfect information games, which is very different, difficult. And in, in, in your ass you were asking about deep stack, what they did. If we're very different than what we do either in [inaudible] or in this new work, they were just randomly generating various situations in the game. Then they were doing it the look ahead from there to the end of the game as if that was a start of a different game. And then they were using deep learning to learn those values of those states.

Speaker 2:          00:17:47       But the states were not the physical states. They include the belief distributions. When you talk about look ahead of war deep stack or when Luvata's does it mean considering every possibility that the game can evolve? Are we talking about extremely sort of at this exponential growth of a tree? Yes, so we're, we're, we're talking about exactly that much like you do in Alpha Beta search or monitor tree research, but with different techniques. So there's different search algorithm and then we have to deal with the leaves differently. So if you think about what Librato stayed, we didn't have to worry about this because we only did it at the end of the game. So we would always terminate into a real situation and we would know what the payout is. It didn't do this depth limited local hits. But now in this new paper, which is called depth limited, I think it's called depth limited search for imperfect information games, we can actually do sound depth, the limited local heads.

Speaker 2:          00:18:47       So we can actually start to do the local head from the beginning of the game on because that's too complicated to do for this whole long game. So in liberal arts we were just doing it for the end. So and then the other side, this belief distribution. So is it explicitly modeled what kind of beliefs that the opponent might have? Yeah, it is explicitly modeled, but it's not assumed. The beliefs are actually output, not input of course, the starting beliefs, our input, but they just fall from the rules of the game because we know that the dealer deals uniformly from the deck. So I know that every pair of cards that you might have is equally unlikely. I know that for a fact that just follows from the rules of the game. Of course except the two cards that I have. I know you don't have those.

Speaker 2:          00:19:36       Yes. Uh, you have to take that into account. That's called cod removal. And that's very important is as the dealing, I was coming from a single deck in heads up. So all can assume single deck, the as you know, if, if I have the ace of spades, I know you don't have an ace of space. Great. So in the beginning your belief is basically the fact that it's a fair dealing of hands. But how do you adjust, start to adjust that belief? Well, that's where this beauty of game theory comes. So natural equilibrium, which John Nash introduce in 1950 introduces what rational play is when you have more than one player. And these appears or strategies where strategies are contingency plans, one for each player. Uh, so neither player wants to deviate or different strategy given that the other doesn't deviate. But as a side effect, you get the beliefs from base role.

Speaker 2:          00:20:33       So Nash equilibrium really isn't just deriving in this imperfect information games, Nash Equilibrium. It doesn't just define strategies. It also defines beliefs for both of us and it refines beliefs for each state. So at the each state, each, if they do call inflammation sits at each inflammation sets in the game. There's a set of different states that we might be in, but I don't know which one we're in. It now basically ruined. Tells me exactly what is a probability distribution over those real states. In my mind, how does national, they give you that distribution. So why? I'll do a simple example. So you know the game rock, paper, scissors. So we, we can draw it. This player one moves first and then player two moles. But of course it's important that player tool doesn't know what player one moved. Otherwise player tool would win every time.

Speaker 2:          00:21:28       So we can draw that as an information set where player one makes one or three moves first and then there's an inflammation set for player too. So player to doesn't know which of those nodes, the world. A world is it. Once we know the strategy for player one Nash Equilibrium will say that the play one third rock, one third paper, one third seizures. From that I can derive my beliefs on the information set that they're one third one third one third. There's a bays gives you that there's an issue. But is that specific to a particular player or is it uh, is it something you quickly update with the Muslim with game theory isn't really player specific. So that's what also why we don't need any data. Uh, we don't need any history how these particular humans played in the past or how any AI or human had played before.

Speaker 2:          00:22:17       It's all about rationality. So we just take the AI just thinks about what would our rational upon it do and what would I do if I were, I am rushing island. What's that? That's, that's idea of game theory. So it's really a data free opponent free approach. So comes from the design of the game as opposed to the design of the player. Exactly. There's no opponent modeling per se. I mean, we've done some work on combining opponent modeling with Game Theory. So they're going to exploit weak players even more. But that's another strand and in Libra does. We didn't turn that on because I decided that these players are too good and when you start to exploit an opponent, you typically open yourselves up, self up to exploitation and these guys have so few holes to exploit and their world's leading experts in counter exploitation. So I decided that and that we're not the kind of tenant that stuff on.

Speaker 2:          00:23:09       Actually I saw a few papers in a exploiting opponents and sound very interesting to uh, explore. Uh, do you think there's room for exploitation, Jay? Generally outside of Libre is, is there a subject, uh, or people differences that could be exploited maybe not just in poker but in general interactions and negotiations, all of these other domains that you're considering? Yeah, I definitely, we've done some work on that and I eat a really like their work at hybridizes that too. So you figure out what were the rational upon it. And by the way, that's safe in these sum games to players. There were some games because if the opponent does something irrational, yes it might show a throw off my beliefs, but the amount that the player can gain by throwing off my belief is always less than they lose by playing poorly. So, so it's safe.

Speaker 2:          00:24:03       But uh, still if somebody's weak as a player, you might want to play differently to exploit them more so that you can think about it this way, a game theoretic strategies on a beatable, but it doesn't maximally beat other opponents. So the winnings per hand might be better with a different strategy. And the hybrid is that you start from a game theoretic approach and then as you gain data from the, about the opponent in certain parts of the game tree, that in those parts of the game three, you start to tweak your strategy more and more towards exploitation while still staying fairly close to the game theoretic strategy. So as to not open yourself up to exploitation too much.

Speaker 1:          00:24:46       How, how do you do that? Do you, um, try to vary up strategies, make it unpredictable? It's like, uh, uh, what is it a tit for tat strategies in, um, prisoner's dilemma or

Speaker 2:          00:25:00       well, Italian that that's a repeated game kind of compete against, that's right in this dilemma repeated games. But, but even there, there's no proof that says that that's the best thing. But experimentally it actually, yeah.

Speaker 1:          00:25:11       Does, does, does well, so what kind of games are there? First of all, I don't know if this is something that you could just summarize that there's perfect information games where all the information is on the table. There is imperfect information games, there's repeated games that you play over and over. There's a zero sum games. Uh, there's non zero sum games. Yeah. And then there's a really important distinction. You're making a two player versus more players. So what are, what other games are there and what's the difference? For example, with this two player game versus more players, what are the key differences in review? So let me start from the,

Speaker 2:          00:25:54       the basic. So a repeated game is a game where the same exact game is played it over and over in these extensive form games. Uh, where I think about three form maybe with these inflammation says to represent incomplete information. You can have kind of repetitive interactions. Even repeated games are a special case of that by the way. But uh, the game doesn't have to be exactly the same. It's like in sourcing origins. Yes, we're going to see you the same supply base year to year. But what I'm buying is a little different every time. And the supply base is a little different every time and so on. So it's not really repeated. So to find a purely repeated game is actually very rare in the world. So they're really a very, uh, course model of what's going on. Then if you move up from repair, just repeated, simple, repeated matrix games.

Speaker 2:          00:26:49       Uh, not all the way to extensive form of games, but in between there stochastic games where you know, there's these, uh, you think about it like these little matrix games and when you take an action and your text in action, they determine not which next date I'm going to next game I'm going to, but the distribution of our next games where I might be going through there. So that's the stochastic game, but it's like major schemes, repeated stochastic games, extensive form games that is from less to more general and, and poker is an example of the last one. So it's really in the most general sitting extensive form games and that's kind of what the Ai community has been working on and been benched marked on with this heads up. No limit. Texas hold'em, can you describe an extensive form games? What's the, what's the motto here?

Speaker 2:          00:27:41       So if you're a present with the tree form, so it's really the tree form. Like in chess there's a search tree versus a major third. It's a matrix here. And uh, that the new matrix is called the matrix form or by matrix form or normal form game and here you have the tree forms so you can actually do certain types of reasoning there that you lose the information when you go the normal phone as say there's a certain form of equivalence. Like if you go from three form and you said every possible contingency plan is a strategy, then I can actually go back to the normal form but they lose some information from the lack of sequence reality. Then the multiplayer versus two player distinction is an important one. So two player games in zero sum are conceptually easier and computational easier. The steel huge like this one, this one, eh, but they're conceptually easier and computational, easier in that conceptually you don't have to worry about which equilibrium is the other guy going into play when there are multiple because any equilibrium strategy is a best response to any other equilibrium strategy.

Speaker 2:          00:28:51       So I can play a different equilibrium from you and we'll still get the right values of the game that falls apart even with two players. When you heard general some games, even with our cooperation, just even without cooperation. So there's a big gap from two players here are to top layer general some or even two, three players there. Awesome. That's a, that's a big gap at least in theory. Can you maybe none mathematically provide intuition while falls apart with three or more players? Uh, it's, it seems like you should still be able to have a national equilibrium that yeah. That that's instructive. That holds, okay. So it is true that all finite games have a nash equilibrium, right? So this is what John Nash actually proved. So they do have a nash

Speaker 1:          00:29:42       equilibrium. That's not the problem. The problem is that there can be many and then there's a question of which equilibrium to select. So, and if you select your strategy from a different equilibrium and I select mine, they then did what does that mean? Uh, and, and in these non zero sum games, we may lose some joints benefit where her by being just simply stupid. We could actually both be better off if we did something else. Yes. And in three player you get other problems. Also like collusion, like maybe you and I can get up on a third player and we can do radically better by color coding. So that are, there are lots of issues that come up there. So no brown student you work with on this has mentioned, uh, I looked through the Ama on reddit. He mentioned that the ability of poker players to collaborate, we make the game. He was asked the question of how would you make the game of poker or both of you were asked the question, how would you make the game of poker, uh, beyond being solvable by current AI methods? And he said that there's not many ways of making poker more difficult, uh, but uh, collaboration or cooperation between players, uh, would make it extremely difficult. So can you provide the intuition behind why that is? Uh, if you agree with that idea?

Speaker 2:          00:31:05       Yeah, so, uh, we, uh, I've done a lot of work, a coalitional games and we actually have a paper here with my other student, couple of [inaudible] and some other collaborators on a, an on that actually just came back from the poster session where we presented. But, uh, so, uh, when you have a collusion, it's a, it's a different problem and it typically gets even harder then even the game representations, some of the game representations don't really allow yeah. Would a computation, so we actually introduced a new game representation for, for that. Is that kind of

Speaker 1:          00:31:39       [inaudible] part of the model is, are you, do you have, do you have information about the fact that other players are cooperating or is it just this chaos? There were, nothing is known so, so there's some, something's unknown. Can you give an example of a collusion type game or is it used breach?

Speaker 2:          00:31:58       Right. So think about bridge. It's like when you and I are on a team, I'll pay offs are the same. The problem is that we can't talk. So, so when I get my car, because I can't whisper to you what my cards are, that would not be allowed. So, uh, we have to somehow coordinate our strategies ahead of time and only ahead of time. And then there are certain signals that we can talk about, but they have to be such that the other team also understands that. So, uh, so that, that's, that's an example where the coordination is already built into the rules of the game. But in many other situations like auctions or negotiations or diplomatic relationships, poker, it's not really built in, but it still can be very helpful for the colluders.

Speaker 1:          00:32:45       I've read you write somewhere the negotiations you come to the table with prior, uh, like a strategy that like, that you're willing to do and not willing to do those kinds of things. So how do you start to now moving away from poker movie beyond poker into other applications like negotiations? How do you start applying this to other, to other domains? Yeah. Even real world domains that you've worked on.

Speaker 2:          00:33:12       Yeah, I actually have two startup companies doing exactly that. One is called strategic machine and that's for kind of beans in applications, gaming, sports, all sorts of things like that. Any applications of these two business and two sports at doe, uh, gaming too about various types of things for in finance, electricity markets and so on. And the other is called strategy robot, where we are taking this to a military security, cybersecurity and intelligence applications.

Speaker 1:          00:33:43       I think you've worked a little bit in, um, how, how do you put it to advertisement, sort of suggesting, um, ads kind of thing.

Speaker 2:          00:33:54       Yeah. Auction, that's another company optimized markets optimize, but that's much more about a combinatorial market and optimization based technology that's not using these a game theoretic reasoning technologies.

Speaker 1:          00:34:06       I see. Okay. So what sort of high level do you think about our ability to use game theoretic concepts to model human behavior? Do you think, do you think human behavior is amenable to this kind of modeling? So outside of the poker games and where have you seen it done successfully in your work? I'm not sure. The goal really is

Speaker 2:          00:34:30       modeling humans. Uh, like for example, if I'm playing a zero sum game, yes, I don't really care that the opponent is actually following in my model of rational behavior because if they're not,

Speaker 1:          00:34:44       that's even better for me. Right. So, so the sea, the opponents and games, there's a, the prerequisite is that you formalize the interaction in some way that can be amenable to analysis. And you've done this amazing work with mechanism design, designing games that have certain outcomes. Uh, but so I'll tell you an example from my, from my world of autonomous vehicles, right? We're studying pedestrians, pedestrians and cars, negotiating this nonverbal communication. There's this weird game dance of tension where pedestrians are basically saying, I trust that you won't kill me. And so as a Jaywalker will step onto the road, even though I'm breaking the law and there's this tension and the question is, would really don't know how to model well in trying to model intent. And so people sometimes bring up ideas and game theory and so on. Do you think that aspect of human behavior can use these kinds of imperfect information approaches modeling? How do we, how do you start to attack a problem like that? Uh, when you don't even know how the game design and game to describe the situation in order to solve it?

Speaker 2:          00:36:04       Okay, so I haven't really thought about Jay walking by. One thing that, uh, I think would be a good application in an autonomous vehicles is the following. So let's say that you have fleets of autonomous car as operating by different companies. So maybe here's the way more fleet. And here's the Uber Fleet. Uh, if you think about the rules of the road, they define certain legal rules, but that still leaves a huge strategy space open. Like as a simple example, when cars merge, you know how he must merge, you know, there's low down and look at each other and tried to tried to merge. Wouldn't they do better if these situations would all repeat pre negotiated. So we can actually merge at full speed and we know that this is the situation, this is how we do it and it's all going to be faster. But there are way too many situations to negotiate manually. So you could use automated negotiation. This is the idea, at least you could use automated negotiation to negotiate all of these situations or many of them in advance. And of course it might be that, hey, maybe you're not going to always let me go first. Maybe you said, okay, well in these situations I'll let you go first. But in exchange you're going to give me two arms. You're gonna let me go first in this situation. Yes. So it's this huge combinatorial negotiation.

Speaker 1:          00:37:20       And do you think there's room in that example of merging two model, this whole situation is an imperfect information game or do you really want to consider it to be a perfect

Speaker 2:          00:37:30       no, that's a good question. Yeah, that's a good question.

Speaker 1:          00:37:33       Pay The price of a assuming that you don't know everything.

Speaker 2:          00:37:39       Yeah, I don't know. It's certainly much easier games with perfect inflammation, a much easier. So if you can get away with it, uh, you should. But if the real situation is of imperfect information, then you're going to have to deal with and for imperfect information.

Speaker 1:          00:37:55       Great. So what lessons have you learned the annual computer poker competition? An incredible accomplishment of Ai. You know, you look at the history of the Blue Alphago, these kind of moments when AI stepped up in an engineering effort and a scientific effort combined to, to beat the best human player. So what, what do you take away from this whole experience? What have you learned about designing? It has systems that play these kinds of games. And what does that mean for sort of, uh, AI in general for the future of Iai Development?

Speaker 2:          00:38:30       Yeah. So that's a good question. Uh, so there's so much to say about it. I do like these type of performance oriented research, although in my group we go all the way from idea to theory, the experiments to big system fielding the commercialization. So we spend that spectrum by, but I think that in a lot of situations in AI, you really have to build the big systems and evaluate them at scale before you know what works and doesn't. And we've seen that in the computational game theory community if there are a lot of techniques that look good in this mall, but then this is to look good in the large. And we've also seen that there are a lot of techniques that look superior in theory. And I really mean in evenings or convergence rates better like first autometrix better convergence rates, like the CFR based bits, algorithms you have the CFR, Bay based Algorithms are the fastest in practice.

Speaker 2:          00:39:24       So it really tells me that you have to test this. In reality, the theory isn't tight enough, if you will, to tell you which algorithms are better than the others. And, uh, you have to look at these things that in the large, because any sorts of projections you'd all from the small can at least in this domain be very misleading. So that, that's kind of from, from our kind of a science and engineering perspective. From a personal perspective, it's been just a wild experience in that, uh, with the first poker competition, the first, uh, brains versus AI and machine barker competition that we organized, there had been, by the way, for other poker games, there had been previous competitions, but this was no heads up, no limit. This was the first. And uh, I probably became the most hated person in the world of poker and I didn't mean to cry.

Speaker 2:          00:40:12       I size that, the crack in the game for, so yeah, it was a lot of people felt that it was a real threat to the whole game, the whole existence of the game. If, if, if AI becomes better than humans, people would be scared to play poker because there are these superhuman AI is running around taking their money and you know, all of that sort of, so I just, it's just really aggressive. Uh, the comments were super aggressive. I got everything. Just short of death threats. Do you think the same was true for chess? Cause right now they just completed the world championships and chess and humans just started ignoring the fact that there is AI systems now that I'll perform humans and they still enjoy the game is still a beautiful game. He's, that's what I think. And I think the same thing happens in poker as a, so I didn't think of myself as somebody who was going to kill the game and I don't think I did. Yeah, I've really learned to love of this game. I wasn't the poker player before, but learn so many nuances about it from these ais and they've really changed how the game's played by the way. So they have these very Martian ways of playing poker and the dop humorous are now incorporating those types of strategies into their own play. So if anything, to me, our work has made poker a richer, more interesting game for humans to play. Not something that is going to steer humans away from it entirely.

Speaker 1:          00:41:34       Just a quick comment and something you said, which is if I may say so an academia is a little bit rare sometimes it is, it's a pretty brave to put your ideas to the test. And the way you described saying that it's sometimes good ideas don't work when you actually tried to apply them at scale. And so where does that come from? I mean, what if you could do, um, advice for people? What, what drives you in that sense? Will you always this way? I mean, it takes a brave person, I guess is what I'm saying. To test their ideas and to see if this thing actually works against human top human players and

Speaker 2:          00:42:11       so on. Yeah. I don't know about brave, but it takes a lot of work. It takes a lot of work and a lot of time, uh, to organize, do, make something big and to organize an event and stuff like that. And what drives you in that effort? Because you could still, I would argue, get a best paper award at nips as you did in 17 without doing this. That's right. Yes. And so, uh, so in, in general, I believe it's very important to do things in eh, in, in the real world and at scale. And that's really where the, the, the pudding, if you're will proof is in the pudding. That's where it is. In this particular case, it was kind of a competition between different groups and for many years as to who can be the first one to beat the top humans at heads up, no limit. Texas hold'em. So the game, eh, it became kind of, uh, uh, or, uh, like a competition who can get there. Yeah. So a little friendly competition can be a can do wonders for progress. Yes. So

Speaker 1:          00:43:17       the topic of mechanism design, which is really interesting, also kind of new to me except as an observer of, I dunno, politics and Amy, I'm an observer of mechanisms, but you, you write in your paper and the automated mechanism design that I quickly read some mechanisms design is designing the rules of the game so you get a certain desirable outcome and you have this work on doing so in an automatic fashion as opposed to fine tuning it. So what have you learned from those efforts? Uh, if we look, say I dunno at a complex like, um, our political system, can we design our political system to have in an automated fashion, uh, to have outcomes that we want? Can we design something like, um,

Speaker 2:          00:44:06       traffic lights to be smart? It where it gets outcomes that we want. So what, what are the lessons that you draw from that work? Yeah, so I still very much believe in the automated mechanism design direction. Yes. But it's not a panacea. There are impossibility results in mechanism design saying that there is no mechanism that accomplices objective x in Class C so, so it, it's not going up. There's no way you using any mechanism design tools manual or automated to do certain things in mechanism design. He came. Describe that again. So meaning there, it's impossible to achieve. That would likely impossible. So saw these are, these are not statements about human ingenuity date who might come up with something smart. These approves that if you want to accomplish properties x in Class C, that is not doable with any mechanism. The good thing about automated mechanism design is that we're not really designing for a class.

Speaker 2:          00:45:10       We're designing for specific settings at a title. So even if there's any possibility that result for the whole class, it just doesn't mean that all of the cases in the class are impossible. It just means that some of the cases are impossible. So we can actually carve these islands of possibility within these noni possible classes. And we've actually done that. So what one of the famous results in mechanism design is some Irish and Satterthwaite theorem for by Roger Myerson and Mark Satterthwaite from 1983. It's an impossibility of efficient trade under imperfect information. We show that you can in many settings avoid that and get the efficient trade anyway, depending on how the design the game. Okay. So depending on how you design the game, man, of course it's not a, it doesn't in any way, any way. Uh, contradicting possibility was Arthur in possibility results is still there, but it just a finance sports within this impossible class where in those sports you don't have the possibility, sorry if I'm going a bit philosophical, but a, what lessons do you draw towards, like I mentioned politics or human interaction and designing mechanisms for outside of just these kinds of trading or auctioning or purely formal games are human interaction like a political system?

Speaker 2:          00:46:34       What, how can you think it's applicable to yeah. Politics or to business, uh, to negotiations, these kinds of things. Designing rules that have certain outcomes. Yeah. Yeah. I do think so. Have you seen success that successfully done the didn't really, oh you mean mechanism design or automated automated mechanisms zone. So, so mechanism design itself has had fairly limited success so far. There are certain cases but most of the real world situations are actually not sound from a mechanism design perspective. Even in those cases where they've been designed by very knowledgeable mechanism designed people, the people are typically just taking some insights from the theory and applying those insights into the real world rather than applying the mechanisms directly. So one famous example is the FCC spectrum auctions. So, um, uh, I've also had a small role in that and uh, very good economists have been word excellent economists have been working on that we'll know game theory yet the rules that are designed in practice there, they were such at beating truthful is not the best strategy.

Speaker 2:          00:47:51       Usually mechanism design. We tried to make things easy for the participants saw telling the truth is the best strategy. But uh, but even in those very high stakes auctions where you have tens of billions of dollars worth of spectrum auction, truth telling is not the best strategy. And, and by the way, nobody knows even a single optimal bidding strategy for those auctions. What's the challenge of coming up with an optimum? Because there's a lot of players and there's impersonal, it's almost a lot of players, but many items for sale and the these mechanisms are such that even with just two items or one item breeding truthfully wouldn't be the best strategy.

Speaker 1:          00:48:31       If you look at the history of Ai, it's marked by seminal events, Alpha go beating the world champion human goal player. I would put [inaudible] winning the heads up. No limit hold'em is one of those such event. Thank you.

Speaker 2:          00:48:46       What do you think

Speaker 1:          00:48:49       is the next such event, whether it's in your life or in the broadly AI community that you think might be out there that would surprise the world?

Speaker 2:          00:49:01       So that's a great question and under really know the answer in terms of game solving a heads up, no limit. Texas hold'em really was the one remaining widely agreed upon benchmark. So that was the big milestone. Now are there other things? Yes, certainly there are, but there is not one that the community has kind of focused on. So what could it be? Other things, there are groups working on starcraft, there are groups working on Dota two. These are video games. Yes. Or You could have like diplomacy or Hanabi, you know, things like that. These are like recreational games, but none of them are uh, really acknowledged as kind of the main next challenge problem like chess or go or heads up. No limit. Texas hold'em was, so I don't really know in the game solving space what is a, what will be the next benchmark.

Speaker 2:          00:49:55       I hope kind of hope that they will be an expense mark because the really the different groups working on the same problem really drove these application independent techniques for board very quickly, over 10 years. Do you think there's an open problem that excites you, that you start moving away from games into real world games? Like say the stock market trading? Yeah. So that's, that's kind of how I am. So I am probably not going to work as hard on these recreational benchmarks. Uh, I'm doing two startups on game solving technology, strategic machine and strategy robot. Then we're really interested in pushing this stuff into practice. What do you think would be a really, you know, uh, a powerful result that'd be surprising. That would, would be, um,

Speaker 1:          00:50:48       if you can say, I mean the, you know, five years, 10 years from now, something that statistically you would say is not

Speaker 2:          00:50:56       very likely, but if there's a breakthrough, what achieve? Yeah. So I think at the overall we're in a very different situation in game theory then we are in, let's say, machine learning. Yes. So in machine learning, it's a fairly mature technology and it's very broadly applied and proven success in the real world in game solving. There are almost no applications yet. We have just become superhuman, which machine learning you could argue happened in the 90s, if not earlier, and uh, at least unsupervised supervised learning, certain complex supervised learning applications. Now I think the next challenge problem, I know you're not asking about this way, you're, you're asking, but the technology breakthrough, but I think that big, big breakthrough is to be able to show at, hey, maybe most of let's say military planning or most of business strategy, we'll actually be done strategically using computational game theory that that's what I would like to see as the next five or 10 year goals.

Speaker 1:          00:51:58       Maybe you can explain to me again, forgive me if this is an obvious question, but, uh, you know, machine learning methods and all networks are suffer from not being transparent and they'd be explainable I game theoretic methods, you know, Nash Equilibria. Do they generally, when you see the different solutions, are they,

Speaker 2:          00:52:17       uh, when you, when you talk about military operations, are they, once you see the strategies, do they make sense of they explainable or do they suffer from the same problems as you know? And that works too. So that's, that's a good question. I would say a little bit yes and no. And while what I mean by that is that these games are the strategies, let's say Nash Equilibrium, it has provable properties. So it's unlike let's say, deep learning where you're kind of cross your fingers, hopefully it'll work. And then after the fact when you have the weights, you're still crossing your fingers and I hope it will work. Uh, here. You know that the solution qualities there, this provable solution, quality guarantees. Now that doesn't necessarily mean that the strategies are human. Understandable. That's a whole other problem. So as I, so I think it deep learning and computational game theory are in the same boat in that sense that both are difficult to understand, but at least the game theoretic techniques, they have these guarantees of sort of quality. So did you see business operations, strategic operations, even military in the future,

Speaker 1:          00:53:25       at least the, the strong candidates being proposed by automated systems? Do you see that?

Speaker 2:          00:53:33       Yeah, I do. I do. But that's more of a belief, belief then a and a substantiated fact depending on where you land,

Speaker 1:          00:53:40       optimism or pessimism. And that's a really, to me, that's an exciting future. Especially if there's a provable things in terms of optimality. So looking into the future, there's a few folks worried about the, especially you look at the game of poker, which is probably one of the last benchmarks in terms of games being solved. They, they worry about the future and the existential threats of artificial intelligence. So the negative impact in whatever form on society. Is that something that concerns you as much or are you more optimistic about the positive impacts of AI?

Speaker 2:          00:54:21       Oh, I am much more optimistic about the positive impacts. So just in my own work, what we've done so far, but we run the nation where kidneys change. Hundreds of people are walking around alive today, who would it be? And it's increased employment. You have, you have a lot of people now running kidney changes and at the transplant centers interacting with the kidney exchange, you have extra surgeons, nurses, anesthesiologists, hospitals, all of that. And so, so employment is increasing from that and the world is becoming a better place. Another example is a common authorial sourcing auctions. We uh, did 800 large scale combinatorial sourcing options from 2001 to 2010, uh, in a previous startup of mine called combine it. And, um, we increased the supply chain efficiency on that $60 billion of spend by 12.6%. So that's over $6 billion of efficiency improvement in the world. And this is not like shifting value from somebody to somebody else. Just efficiency improvement like in trucking, less empty driving so there's less waste, less carbon footprint and so on.

Speaker 1:          00:55:33       It's a huge positive impact in the near term, but sort of tea to stay in it for, for a little longer because I think game theory has a role

Speaker 2:          00:55:42       in play here. Well let, let me actually come back and do that. That is one thing. I think AI is also going to make the world much safer. So, uh, so, so that's another aspect that often gets overlooked. What, let me ask this question, maybe I can speak

Speaker 1:          00:55:55       to the safer. So I talked to Max Tegmark and Stuart Russell, uh, who are very concerned about existential threats of Ai. And often the concern is about value misalignment. So Ai Systems basically a working, operating towards goals that are not the same as human civilization, human beings. So it seems like game theory has a role to play there. Uh, two to make sure the values are aligned with human beings. I don't know if that's how you think about it. If not,

Speaker 2:          00:56:31       how do you think AI might help with this problem? Uh, how, how do you think AI might make the world safer? Yeah, I think this value is alignment is a fairly theoretical worry and I haven't really seen it in it cause I do a lot of real applications. I don't see it anywhere. Uh, the closest I've seen it was the following type of mental exercise really where I had this argument in the late eighties when we were building these transportation optimization systems and somebody had to hear it and it's a good idea to have high utilization of assets. So they told me I take, why don't you put that as the objective? And we didn't even pull it as an objective because I just showed him at, you know, if you had that as your objective, the solution would be the load your trucks fallen driving circles, nothing would ever get delivered. You'd have a hundred percent utilization. So yeah, I know this phenomenon, I've known this for over 30 years in about, but I've never seen it actually be a problem. Reality in reality. And yes, if you have the wrong objective, the AI will optimize that to the hilt and it's going to hurt more than some human who's kind of trying to solve within a half baked way with some human insight too. But I, I just haven't seen that materialize in practice.

Speaker 1:          00:57:49       There's this gap that you've actually put your finger on very clearly just now between theory and reality. That's very difficult to put into words. I think it's what you can theoretically imagine. Uh, the worst possible case or even, yeah, I mean, bad cases and what usually happens in reality. So for example, to me, maybe it's something you can comment on. Uh, having grown up in, I grew up in the Soviet Union, you know, there's currently 10,000 nuclear weapons in the world and for many decades. It's a theoretically a surprising to me that the nuclear war is not broken out.

Speaker 2:          00:58:31       Do you think about this aspect is from a game theoretic perspective in general, why is that true? A why in theory you could see how

Speaker 1:          00:58:41       things will go terribly wrong and somehow yet they have not. Yeah.

Speaker 2:          00:58:45       So I do think that that about that a lot. I think the biggest two threats that we're facing as mankind, one is climate change and others nuclear war. So as, as, so those are my main two worries that that worry about. And I, I've tried to do something about climate, had thought about trying to do something for climate change twice actually before two of my startups. I've actually commissioned studies of what we could do on those things and we didn't really find a sweet spot, but I'm still keeping an eye out on that. If there's something where we could actually provide a market's a lotion or optimizations law or some other technology solution to problems right now. Um, like for example, pollution critic markets was what we were looking at them. And it was much more, the lack of political will by those markets were not so successful rather than bad market design. So I could go in and make a Beta market design, but that wouldn't really move the needle on the world very much if there's no political will. And in the u s you know, the market, uh, at least the Chicago market was just shut down, uh, uh, and, and so on. So it doesn't really help how great your market design was.

Speaker 1:          00:59:51       And then the nuclear side, it's more so global warming is a more encroaching problem, you know, nuclear weapons. I've been here, it's an obvious problem, has just been sitting there. So how do you think about, what is the mechanism design there that just made everything seem stable and are you

Speaker 2:          01:00:13       still extremely worried? I am still extremely worried. So yeah, you probably know the simple game theory of mad. So, so, so, uh, at least, uh, mutually assured destruction and it's lazy. It doesn't require any computation with small matrix eats. You can actually convince yourself that the game is such that nobody wants to initiate. Hmm. Yeah, that's a very coarse grained analysis and it really works in a situation where you have two superpowers or small number of super powers. Now things are very different. You have a smaller nukes or the threshold of initiating a smaller and you have smaller countries and non non nation actors who make it an org sense. I won. So it's, I think it's riskier now than it was maybe ever before.

Speaker 1:          01:00:58       And what idea application of Ai, you've talked about a little bit, but what is the most exciting to you right now? I mean you, you're here at nips new Europe's now you have few excellent pieces of work. But what are you thinking into the future with several companies you're doing? What's the most exciting thing or one of the exciting things?

Speaker 2:          01:01:21       The number one thing for me right now is coming up with these a scalable techniques for game solving and applying them into the real world that I was still very interested in market design as well and we're doing that in optimize markets, but I'm most interested if number one right now is strategic machine strategy robot. Getting that technology out there and seeing as you were in the trenches doing applications, what needs to be actually filled, what technology gaps still need to be filled. So it's so hard to just put your feet on the table and imagine what needs to be done. But when you're actually doing real applications, the applications tell you what needs to be done. And I really enjoy that interaction.

Speaker 1:          01:02:00       Is it a challenging process to apply some of the state of the art techniques you're working on and having the various players in industry or the military or people who could really benefit from it, actually use it? What's that process like of, you know, in autonomous vehicles will work with automotive companies and they're, uh, in in many ways are a little bit old fashioned. It's difficult. They really want to use this technology. There's clearly will have a significant benefit, but the systems aren't quite in place to easily have them integrated in terms of data, in terms of compute, in terms of all of these kinds of things. So do you, is that one of the bigger challenges that you're facing and how you tackle that challenge?

Speaker 2:          01:02:50       Yeah, I think that's always the challenge that that's kind of slowness and inertia really of let's do things the way we've always done it. You just have to find the internal champions at the customer who understand that hey, things can't be the same way in the future, otherwise bad things are going to happen. And it's in autonomous vehicles. It's actually very interesting that the car makers are doing that and they're very traditional. But at the same time you have tech companies who have nothing to do with the cars or transportation like Google and Baidu really pushing on autonomous cars. I find that fascinating.

Speaker 1:          01:03:23       Clearly you're super excited about actually these ideas having an impact in the world. Uh, in terms of the technology, in terms of ideas and research. Are there directions they you're also excited about whether that's on the, some of the approaches you talked about for the imperfect information games, whether it's applying deep learning, just some of these problems. Is there something that you're excited and in the research side of things? Yeah.

Speaker 2:          01:03:49       Yeah. Lots of different things in the game solving. Uh, so solving even bigger games, uh, games where you have, um, more he didn't action of the play your actions as well. Uh, poker is a game where really the chance actions are hidden or some of them are hidden, but to play your actions are public. It multiplayer games of various sorts, collusion, a opponent exploitation, all, all and an even longer games. Some games that basically go forever, but they're not repeated. So seek extensive on games that go forever. What would that even look like? How do you represent that? How do you solve that? What's an example of a game like that? Oh, this is the sum of this. The classic games that you mentioned, that's a business strategy. So it's not just modeling like a particular interaction, but thinking about the business from here to eternity or r I c or like let's say, um, military strategy.

Speaker 2:          01:04:49       So it's not like war is going to go away. How do you the think about military strategy that's going to go forever. How do you even model that? How do you know whether a move was good that you use somebody made and, and, and, and so on. Uh, so that, that's kind of one direction. I'm also very interested in learning much more scalable techniques for integer programming. So we had a nice EML paper this summer on that for the Automated Algorithm configuration paper that has theoretical generalization guarantees. So if I see these many training examples and I told my algorithm and this way it's going to have good performance on the real distribution, which have not seen. So we just kind of interesting that, you know, algorithm configuration has been going on now for at least 17 years. Seriously. And there has not been any generalization her theory before. Well this is really exciting and has been, it's a huge honor to talk to you. Thank you. Summarize to us. Thank you for bringing the, brought us to the world and all the great work you're doing. Well, thank you very much. It's been fun. Good questions.