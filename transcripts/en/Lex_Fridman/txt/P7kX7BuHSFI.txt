Speaker 1:          00:00:00       Welcome back to success zero, nine, nine artificial general intelligence. Today we have Stephen Wolfe from.

Speaker 2:          00:00:07       Thank you.

Speaker 1:          00:00:13       That's the first. I didn't even get started. You already clapping, uh, in his book and you kind of. Sciencey has explored and reveal the power, beauty and complexity of cellular Automata as simple computational systems, which incredible complexity it can emerge. It's actually one of the books that really inspired me to get into artificial intelligence. He's created the Wolfram Alpha competition knowledge engine created Mathematica that has now expanded to become wolfram language. Both he and his son were involved in helping analyze, create the alien language from the movie arrival of which they used the Wolfram language. Please again, give Steven a warm welcome.

Speaker 2:          00:00:53       Thanks so much. The

Speaker 3:          00:00:58       brief here is to talk about how artificial general intelligence is going to be achieved. Is that the set, the basic picture? So I, I, maybe I'm reminded of kind of a storage. I don't think I've ever told them public, but um, that something that happened just a few buildings over from here. So this was 2009 and Wolfram Alpha was, was about to arrive on the scene. I assume most of you have used wolf now for a cmo of Alpha. Yes. The pump. How many of you have used Wolf Malfa? Okay, that's good. Um, so I had long been a friend of Marvin Minsky and Marvin was a sort of pioneer of the ai world and I kind of seen for years, you know, question answering systems that tried to, uh, to sort of general intelligence question answering. And so Marvin, and so I was going to show Marvin, you know, Wolf Malfa, he looks at it, he's like, oh, okay, that's fine.

Speaker 3:          00:01:57       Whatever said no, Marvin, this time it actually works. You can try real questions. This is actually something useful. This is not just a toy. And it was kind of interesting to see. It took. It took about five minutes from Marvin to realize that this was finally a question answering system that could actually answer questions that were useful to people. Um, and so one question is, how do we, how do we achieve that? So, you know, you go to wealth Malfa and you can ask it. I mean, it's, I don't know what we can ask it. I don't know. What's the, um, uh, some random question. What does the population of Cambridge actually, here's a question divided by. Let's try that. What's the population of Cambridge? It's probably gonna figure out that we mean Cambridge, Massachusetts is going to give us some number. It's going to give us some plot.

Speaker 3:          00:02:43       Actually, what I want to know is number of students at mit divided by population of Cambridge specific configure that out. Um, and uh, okay. It's kind of interesting. I know that's divided by. Oh, that's interesting it guests that we were talking about Cambridge University as the, as the denominator there. So it says the number of students at mit divided by the number of students at Cambridge University. It's interesting. I'm actually surprised. Let's see what happens. If I say con Cambridge a, the, I'm not as will probably fail horribly. No, that's, that's good. Okay. So, um, no, that's interesting. That's a plot as a function of time of the fraction of the, uh, of um, okay. So anyway, so I'm glad it works. Um, the uh, so one, one question is how did we manage to get so many things have to work in order to get stuff like this to work, you have to be able to understand the natural language, you have to have data sources, you have to be able to compute things from the data and so on.

Speaker 3:          00:03:50       One of the things that was a surprise to me was in terms of natural language understanding was the critical thing turned out to be just knowing a lot of stuff. The actual pausing of the national language is kind of a, I think it's kind of clever and we use a bunch of ideas that came from my new kind of science project and so on. But I think the most important thing is just knowing a lot of stuff about the world is, is really important to actually being able to, to understand natural language in it and a useful situation. I think the other thing is having a, uh, actually having access to lots of data. Let me show you a typical example here of what is needed. So I asked about the ISS and hopefully it'll wake up and tell us something here. Come on. What's going on here?

Speaker 3:          00:04:35       There we go. Okay. So it figured out that we probably are talking about a spacecraft, another file format, and now it's going to give us a plot that shows us where the ISS is right now. So to make this work we obviously have to have some feed of a radar tracking data about satellites and so on, which we have for every satellite that's, that's out there. Um, but then that's not good enough to just have that feed. Then you also have to be able to do celestial mechanics to work out well. Whereas the ISS actually right now based on the orbital elements that have been deduced from radar and then if we want to know things like, okay, when is it going to. It's not currently visible from Boston, Massachusetts. It will next rise at 7:36 PM, uh, on Monday and today. Um, so, you know, this requires a mixture of data about what's going on in the world together with models about how the world is supposed to work.

Speaker 3:          00:05:31       Being able to predict things and so on. And I think another thing that kind of realized about, about Ai and so on from the Wolf Malfa effort has been that, you know, one of the earlier ideas for how long would achieve ai was let's make it work. Kind of like brainstorm and let's make it figure stuff out and stuff. It has to do physics, let's have it do physics by pure reasoning. Uh, like, you know, people at least used to do physics, but in the last 300 years we've had a different way to do physics that wasn't sort of based on natural philosophy. It was instead based on things like mathematics. And so one of the things that we were doing and worth Malfa was to kind of cheat relative to what had been done in previous ai systems, which was instead of using kind of reasoning type methods, were just saying, okay, we want to compute where the ISS is going to be, but we've got a bunch of equations of motion that correspond to differential equations.

Speaker 3:          00:06:27       We're just going to solve the equations of motion and get an answer. That's kind of leveraging the last 300 years or so of, of, of exact science that have been done, rather than trying to make use of kind of human reasoning ideas. And I might might say that in terms of the history of the wharf Malford project, when I was a kid a disgustingly long time ago, I was interested in ai kinds of things and I, in fact, I was kind of upset recently to find a bunch of stuff I did when I was 12 years old, kind of trying to assemble a pre version of orphan malfa way back before it was technologically possible. But it's also a reminder that one just does the same thing. One's whole life, so to speak at some level. Um, but, uh, uh, what happened was when, when I, um, I started off working mainly in physics and then I got involved in building computer systems to do things like mathematical computation and so on.

Speaker 3:          00:07:22       And, uh, I then sort of got interested in, okay, so can we generalize this stuff and come we can we really make a systems that can answer sort of arbitrary questions about the world and for example, uh, sort of the, the, the, the, the promise would be if there's something that is systematically no one in our civilization make it automatic to answer questions on the base of that systematic knowledge. And back in the, in around late 19 seventies, early 19 eighties, my conclusion was that you wanted to do something like that. The only realistic path to being able to do it was to build something much like a brain. And so I got interested in neural nets and I tried to do things with neural nets back in 1980 and nothing very interesting happened where I couldn't get them to do anything very interesting. And uh, that term.

Speaker 3:          00:08:08       So I kind of had the idea that, that the only way to get the kind of thing that now exists in Wolf Malfa for example, was to build a brain like thing. And then many years later, for reasons I can explain, I kind of came back to this and realized, actually it wasn't true that you had to build a brain, like things sort of mere computation was sufficient and that was kind of what got me started actually trying to build both Malfa when we started building wealth Malfa, one of the things I did was go to a sort of a field trip to a big reference library and you know, you see all these shelves of books and so on. And the question is, can we take all of this knowledge that exists in all of these books and actually automate being able to answer questions on the basis of it.

Speaker 3:          00:08:48       And I think we've pretty much done that for that, at least the books you find than a typical reference library. Um, so that was a, it looked kind of daunting at the beginning because it's this, there's a lot of knowledge and information out there. But actually it turns out there are a few thousand domains and we've steadily gone through and worked on these different domains. Another feature of the wharf project was that we didn't really, uh, you know, I've been involved a lot in doing basic science and trying to have sort of grand theories of the world. One of my principals in building Wolfram Alpha was not to start from a grand theory of the world that is not to kind of start from some global ontology of the world and then try and build down into all these different domains, but instead to work up from having, you know, hundreds then thousands of domains that actually work, whether they're, you know, information about cars or information about sports or information about movies or whatever else, how each of these domains.

Speaker 3:          00:09:40       I'm sort of building up from the bottom in each of these domains. And then finding that there were common themes in these domains that we could then build into frameworks and then sort of construct the whole system on the basis of that. And that's kind of, that's kind of how it's worked. And I can talk about some of the actual frameworks that we ended up using and so on. Um, but, uh, maybe I should explain a little bit more. So, so one question is, how does, how does wealth map are actually sort of work inside? And the answer is it's a big program, it's about, it's the core system has about 15 million lines of Wolfram language code, um, and it's some number of terabytes of raw data. Um, and uh, so the, the way, the thing that sort of made building wealth now for possible was this language Wolfram from language which started with Mathematica, which came out in 1988 and has been sort of progressively growing since then.

Speaker 3:          00:10:35       So maybe I should show you some things about wealth language and, and, uh, you know, it's easy. You can go use this. Mit has a site license for it, you can use it all over the place, you can find it on the web, et Cetera, et Cetera, et cetera. Um, but, uh, okay, the basics work. Um, the uh, let, let's, let's start off with something like, let's make a random graph and um, let's say we have a random graph with 200 nodes, 400 vertices. Okay. So those isn't random graph. The first important thing about Wilson languages, it's a symbolic language. So I can just pick up this graph and I could say, you know, I want to do some analysis of this graph. That graph is just a symbolic thing that I can just do computations on. Or I could say let's, let's get a um, a, another good thing to do is get a current image. See, there we go. Um, and now I could go and say something like, um, uh, let's, let's do some basic thing. Let's say let's edge detect that image again, this, this image is just a thing that we can manipulate. We could take the image, we could make it. Um, uh, I don't know. We could take the image and petitioners, little pieces. Do computations on that. I don't know. Simple. Let's do, let's just say sought each row of the image. Assemble the image again. Whoops.

Speaker 3:          00:12:00       Assemble, let image again. We'll get some, some mixed up picture there. If I wanted to, I could, for example, let's say let's make that the current image and let's say make that dynamic. I can be just running that code hopefully, and it'll loop and we can, uh, make that work. So the one, one general point here is, there's no, this is just an image for us is just a piece of data. Like anything else, if we just have a variable a thing called x, it just says, okay, that's X. I don't need to know particular value. It's just a symbolic thing that corresponds to a, that's a thing called x. Now you know, what gets interesting when you have a symbolic language and so on is we're interested in having it represent stuff about the world as well as just abstract kinds of things. I mean, I, you know, I can abstractly say, you know, find some funky integral, um, I don't know what, you know, that's then representing a using symbolic variables to represent algebraic kinds of things.

Speaker 3:          00:13:03       But I could also just say I dunno, something like Boston and Boston is another kind of symbolic thing that, uh, has. If I say what, what does it really inside that's, it's the entity, a city, Boston, Massachusetts, United States actually noticed when I type that in, I was using natural language to type it in and it gave me a bunch of disambiguation here. It said, assuming Boston as a city, uh, assuming Boston, Massachusetts, use Boston, New York or. Okay, there's, let's use, let's use Boston in the Philippines, which I've never heard of, but um, uh, let's try using that instead. And now if I look at that, it'll say it's Boston in some province of the Philippines, etc. Etc. Etc. Now I might ask it of that. I could say somEthing like, what's the population of that? Um, and it, um, uh, okay. It's a fairly small place.

Speaker 3:          00:13:57       Or I could say, for example, let me, let me do this. Let me say jill list plot from that bostoN a take from that boston too. And now let's type In boston again and now let's have it used the default meaning of the word of boston. and then let's join those up. And now this should plot, um, this should show me a plot. There we go. Okay, so there's the, um, a path from the boston that we picked in the Philippines to the boston here. Oh, we could ask it. I don't know. I could just say, um, I could ask it the distance from one to another or something like that. So the, the, one of the thIngs here, one things we found really, really useful actually in both languages. The first of all, there's a way of representing stuff about the world, like cities for example.

Speaker 3:          00:14:45       Well, let's say I want to say let's, let's do this. Let's say, uh, uh, let's do something, let's say capital cities in south America. Okay. So notice this is a piece of natural language. This will get interpreted into something which is precise symbolic language code that we can then compute with and that will give us the citizens of the capital cities in south America. I could, for example, let's say I say fine shortest tour. So now I'm going to use some, uh, some ups. No, I don't want to do that, but I want to do first is to say, show me the job positions of all those cities online, 21 there, so now it will find the geo positions and now we'll say compute the shortest tour. So that's saying there's a 10,000 mile traveling salesman tour around those cities. So I could take those cities were online 21 and I could say order the cities according to this and then I could make another geo lists a lot of that, join it up.

Speaker 3:          00:15:46       Um, and this should now show us a, a traveling salesman tour of the, um, of the capital cities in south America. Um, so, you know, it's, it's sort of interesting to see what's involved in making stuff like this work. Um, the uh, uh, one of my, my goal has been to sort of automate as much as possible about things that have to be computed and that means knowing as many algorithms as possible and also knowing as much data about the world as possible. And I kind of view this as sort of a knowledge based programming approach where you have a typical kind of idea and programming languages as you know, we have some small programming languages, has a few primitives that are pretty much tied into what a machine can intrinsically do and then maybe you'll have libraries that add onto that. And so on.

Speaker 3:          00:16:38       My kind of a crazy idea of many, many years ago has been to build an integrated system where all of the stuff about different domains of knowledge and so on are all just built into the system and uh, and designed in a coherent way. I mean this has been kind of the story of my life for the last 30 years, is trying to keep the design of the system coherent even as one adds all sorts of different areas of, of, uh, of capability. So as, um, I mean we can go and dive into all sorts of different kinds of things here. But, um, maybe as an example. Well, let's do, what could we do here we could take. Um, let's try. How about this? Is that a bone? I think so that's a bone. So let's try a that as a mesh region, see if that works.

Speaker 3:          00:17:32       So this will now Use a completely different domain of, um, of human endeavor. Okay. Whoops. There's two of those buttons. Let's try, let's just try a, let's try left humerus and let's try the, the, that, the mesh region for that. And now we should have a bone here. Okay. There's a representational of bone. Let's take that bone. We could, for example, say um, let's take the surface area of that as in some some units or I could let, let's do some much more outrageous thing. Let's say we take, um, region distance. So we're going to take the distance from some, from that bone to a point, let's say zero, zero, z, and let's make a plot of that distance with z going from, let's say I have no idea where the, where the bone is, but let's try something like this. So that was really borIng.

Speaker 3:          00:18:30       Let's try. Um, so what this is doing, again, a whole bunch of stuff has to work in order for this to, to operate this test, to be. This is a, this is some region in three d space that's represented by some mesh. You have to compute, you know, do the computational geometry to figure out where it is. If I wanted to let, let's try anatomy, anatomy, plot three d, and let's say something like lefthand for example, and now it's going to show us probably the complete data that it has about the geometry of, of, um, uh, of a lefthand. There we gO. Um, okay. So there's, there's the results. And we could take that apart and start computIng things from it. And so on. So what I'm a. So this is, um, um, so there's, uh, there's a lot of kind of computational knowledge that's built in here. Um, one, uh, let's, let's talk a little bit about kind of the modern machine learning story. So for instance, if I say, let's get a picture here. Let's say, um, let's, let's just say picture of assembly. Got a favorite kind of animal.

Speaker 3:          00:19:43       What? Panda. Okay, so let's try. Okay. Giant panda. Okay. Okay, there's a panda. Let's see what, um, now let's try saying, let's try for this panda. Let's try saying image identify, and now here will be embarrassed probably, but let's just see. Let's see what happens. If I say image, identify that and now it'll hopefully wake up, wake up, wake up. This only takes a few hundred milliseconds. Okay, very good. John panto. Let's, let's see what it will see. What the runners up were to the giant panda. Um, uh, let's say we want to say the ten one is up in all categories for that thing. Okay. So giant panda, a kitchenaid, which I've never heard of. Our pandas. Commerce eat bamboo shoots. Okay. So that was so lucky. It didn't get that one. It's really sure it's a mammal and it's absolutely certain it's a vertebrate. Okay. So you might ask how did it figure this out?

Speaker 3:          00:20:53       And so then you can kind of look under the hood and say, so we have a whole framework for representing neuron that symbolically. And so this is the actual model that it's using to do this. So this is a um, so there's a neural net and it's got. We can drill down and we can see there's a piece of the neural net. We can drill down even further to one of these and we can probably see what that's our batch normalization layer somewhere deep, deep inside the trails of the not pander, but to have this thing. Okay, so now let's take that object which has just a symbolic object and let's feed it the picture of the panda and we can see 'em and the ups. I was not giving up the right thing. What did I do wrong here? Let's. Let's take. Oh, I see what I did.

Speaker 3:          00:21:39       Okay, let's take this thing and feed it the picture of the panda and it says a giant panda. Okay. How about we do something more outrageous? Let's take that neuron that. And let's only use the first, let's say 10 layers of the neuron that. So let's just take out 10 layers of the neuron that and feed it the panda. And now what we'll get is something from the insides of the neuron that. And I could say for example, let's just make those into images. Okay? So that's what. That's what the neural net had figured out about the panda after 10 layers of going through the neuron that and maybe actually be interesting to see, let's do a feature space plots and now we're going to have those intermediate things in the brain of the neural net so to speak. Um, this is now taking. So what this is doing is to do dimension reduction on this space of images.

Speaker 3:          00:22:31       And so not very exciting. It's probabLy mostly distinguishing these by, by total gray level, but that's kind of showing us the space of, um, of different term, a different sort of features of the insides of the chanel on that. So it's also what's interesting to see here is things like the symbolic representation of the neuron nets. And if you, if you're wondering how does that actually work inside, it's underneath it susan mx net, which we happen to have contributed to a lot and there's sort of a bunch of symbolic layers on top of that that feed into that. And maybe I can show you here, let, let me show you how you would train one of these neural nets. That's also kind of fun. So we have a data repository that has all sorts of useful data. One piece of data it has is a bunch of neuron that training set.

Speaker 3:          00:23:13       So this is the standard training set of handwritten digits. Okay. So there's amnesty and you notice that these things here, that's Just an image which I could copy out and I could do, let's say I could do color and a gate on that image because it's just an image. Um, and there's, there's the results and so on. And now I could say, let's take, let's take a neuron that like, let's take a simple neural net like lynette for example. Um, okay. So let's take lanette and then let's take the untrained initial evaluation network. So this is now a version of love, that simple standard neuron that, that didn't get trained. So for example, if I, if I take that, that symBolic representation of that, and I could say net initialize than it will take that and it'll just put random weights until the net. Okay?

Speaker 3:          00:24:04       So if I take those random weights and I feed it a zero here, I feed it, that image of a zero, it will presumaBly produced something completely random and this particular case too, right? So now, now what I would like to do is to take this. So thAt was just randomly initializing the weights. So now what I'd like to do is to take, uh, the training set and I'd like to actually train a learn at using eminence training set. So let's take, let's take this and let's take a random sample of a. Let's say I don't know, a thousand pieces of lanette. Come on. Why is it having to load it again? There we go. Okay. So there's a, there's a random sample a was on line 21. And now let me go down here and say, uh, what was it? Well we can just take this, this thing here.

Speaker 3:          00:24:54       So this is the uninitialized version of lanette and we can say take that. And then let's say net train of that with the thing on line 21, which was that thousand instances. So now what it's doing is it's running training on, um, and that's, you see the loss going down and so on. It's running the training for, uh, for those thousand instances of, of uh, uh, lynette and it will, we can stop it if we want to. Actually, this is a new display. This is very nice. This is, this is a new version of language which is coming out next week, which I'm showing you, But it's quite similar to what exists today, but because that's one of the features of running a software company is that you always run the very latest version of things for better or worse. And that's, and this is also a good way to debug it was supposed to come out next week.

Speaker 3:          00:25:42       If I find some horrifying bug, maybe we'll get to later, but let's try and let's, um, let's try this. Okay, now it says it's zero. Okay? And so, so this is now a trained version of lynette trained with that, uh, with that training data. I'm one of the things so we can talk about all kinds of details of, of neural nets and so on. But maybe I should zoom out to talk a little bit about bigger picture as it, as I see it. So one question is a sort of a question of what is in principle possible to do with computation? So, you know, we have as we're, you know, we're building all kinds of things. We're making image identifiers were figuring out all kinds of things about where the international space station is. And so on question is what is, what is in principle possible to compute?

Speaker 3:          00:26:35       and so the, uh, you know, one of the places one can ask that question is when one looks at, for example, models of the natural world can say, you know, how do we make models of the natural world? Kind of a, a traditional approach has been, let's use mathematical equations to make models of the natural world. A question is if we want to kind of generalize that and say, well, what are all possible ways to make models of things? What can we say about that question? So I spent many years in my lifetime to address that question. And basically what I've thought about a lot is that if you want to make a model of a thing, you have to have definite rules by which the thing operates. What's the most general way to represent possible rules while in today's world we think of that as a program.

Speaker 3:          00:27:19       So the next question is, well, what does the space of all possiBle programs look like? And most of the time, you know, we're writing programs like wolfram language is 50 million lines of code and it's a big complicated program that was for built for fairly specific purpose. But the question is if we just look At sort of the space of possible programs more or less at random, what's out there in the space of possible program. So I got an interest in many years ago in cellular automata, which are really good example of a very simple kind of program. So let me show you an example of one of these. So this is, these are the rules for a typical cellular automaton. And this just says you have a row of black and white squares. And this just says, you look at a black look at a square, say what color is that square?

Speaker 3:          00:28:02       What color left left. And right neighbors decide what color the square will be on the next step based on that rule. Okay? So really simple rule. So now let's, let's take a look at what, what actually happens if we use that rule a bunch of times so we can take that rule. The 2:54 is just the binary digits that correspond to those positions and this rule. So now I can say this, I could say let's do 50 steps, let me do this. And now if I run according to the rule I just defined, it turns out to be pretty trivial. It's just sAying, uh, if any, if any square is we start off with a black square. If any square is, um, if any neighbouring squares, black makeup, black square. So we've, we've used a very simple program, we've got a very simple result out, okay, let's try a different program.

Speaker 3:          00:28:50       we can try changing this will get them. That's a program with one bit different. Now we get that kind of pattern. So the question is, well, what happens, you might say, okay, if you've got such a trivial program, it's not surprising, you're just going to get trevor results out. So. But you can do an experiment to test that hypothesis and you just say, let's take all possible programs that are 256 possible programs that are based on these eight bits here. Let's just take bullets. Just, whoops, let's just take come. Let's say the first 64 of those programs and let's just make a. I'm a go. Let's just make a table of the results that we get by running those first 64 programs here. So here we get the result and what you see is, well most of them are pretty trivial. The likely they started with black cell in the middle and it just tools off to one side.

Speaker 3:          00:29:44       Occasionally we get something more exciting happening. Like here's a nice nested pattern that we get. We were to continue it longer. It would, it would make a more detailed nesting. But then my all time favorite science discovery. If you go on and just look at these after a while, you find this one here, which is rule 30 and this in this numbering scheme, and that's doing something a bit more complicated. You say, well, what's going on here? You know, we just started off with this very simple rule. LeT's see what happens. Maybe after a while, you know, if we run rule 30 long enough, it will resolve into something simpler. SO let's try running it. Let's say 500 steps. Um, and that's, whoops, that's the result we get. Let's say a, just make it full screen.

Speaker 3:          00:30:32       Okay? So aliasing a bit on the project to the but, but um, you've got the basic idea. This is a. So this just started off from one black sell at the top and this is what it made. And that's pretty weird because all of this is, you know, this is a sort of not the way it's supposed things are supposed to work because what we have here is just that little program down there and it makes this big complicated pattern here. And we can see there's a certain amount of regularity on one side, but for example, the center column of this pattern is for all practical purposes completely around. In fact, it was, we used as the random number generator and mathematic or wolfram language for many years. It was recently retired after, after excellent service because we found it somewhat more efficient one, um, But, um, uh, the, um, so, you know, what do we learn from this?

Speaker 3:          00:31:21       What we learned from this is out in the computational universe of possible programs. It's possible to get even with very simple programs, very rich, complicated behavior. While that's important, if you're interested in modeling the natural world because you might think that there are programs that represent systems in nature that might work this way and so on. it's also important for technology because it says, okay, let's say you're trying to find a, um, let's say you're trying to find a Program that's a good random number generator. How are you going to do that? While you could start thinking very hard and you could try and make up, you know, you can try and write down all kinds of flow charts about how this random number generator is going to work or you can say, forget that I'm just going to search the computational universe of possible programs and just look for one that serves as a good random numBer generator and this particular case, after you've searched 30 programs, you'll find one that makes a good random number generator.

Speaker 3:          00:32:13       Why dOes it work? That's a complicated story. It's not a story that I think necessarily we can really tell very well, but what's important is that this is this idea that out in the computational universe, there's a lot of rich, sophisticated stuff that can be essentially mined for our technological purposes. That's the important thing. Whether we understand how this works is a different matter. I mean it's like when we look at the natural world, the physical world, we're used to kind of mining things. You know, we started using magnets to do magnetic stuff long before we understand, understood the theory of pharaoh mannerism and so on. And so similarly here we can sort of go out into the computational universe and find stuff that's useful for our purposes now. In fact, the, the world of sort of deep learning and neural nets and so on as a little bit like this, it uses the trick that there's a certain degree of differentiability there so you can kind of home in on let's try and find something that's incrementally better and for certain kinds of problems that works pretty well.

Speaker 3:          00:33:14       I think the thing that we've done a lot, I've done a lot is just sort of exhaustive search and the computational universe of possible programs, just such a trillion programs and try and find one that does something interesting and useful for you. Um, there's a lot of things to say about what, um, what actually in, in the such a chilean programs and find one that's useful. Let me show you another example of that. Um, let's see. So I was interested in awhile ago in um, uh, the, I have to look something up here. Sorry, I'm in. I'm a see, I'm in, I'm a boolean algebra and in, um, uh, it was interested in, in the space of all possible mathematics says, um, and ah, let me just see here. Uh, I'm not finding what I wanted to find. Sorry, uh, was a good example. I should have memorized this but I haven't.

Speaker 3:          00:34:15       So I'm. Here we go. There it is. Um, so I was interested in, if you just look at. So we talked about sort of looking at the space of all possible, um, uh, the space of all possible programs. Another thing you can do is say if you're going to invent mathematics from nothing, what possible axiom systems could be used in mathematics. So I was curious where do that again might seem like a completely crazy thing to do. So just say, let's just start enumerating axiom systems at random and see if we find one that's interesting and useful, but it turns out once you have this idea that out in the computational universe of possible programs, that's actually a lot of low hanging fruit to be found. It turns out you can apply that in lots of places. I mean, the thing to understand is why?

Speaker 3:          00:35:06       Why do we not see a lot of engineering structures that look like this? The reason is because our traditional model of engineering has been we engineer things in a way where we were, we can foresee what the outcome of our engineering steps that are going to be and when it comes to something like this, we can find it out in the computational universe what we can't readily foresee, what's going to happen. We can't do Sort of a step by step design of this particular thing. And so in engineering and human engineering as it's been practiced so far, most of it has consisted of building things where we can foresee step by step what the outcome of our engineering it's going to be. And we see that in programs, we see that in in other kinds of engineering structures and so there's sort of a different kind of engineering which is about mining the computational universe of possible programs and it's worth realizing there's a lot more that can be done a lot more efficiently by mining the computational universe of possible programs than by just constructing things step by step as a human.

Speaker 3:          00:36:00       So for example, if you look for optimal algorithms for things like, I don't know, even something like sorting networks, the optimal sorting networks look very complicated. They're not things that you would construct by sort of step by step thinking about things with a in a kind of a in a kind of typical human way. And so this, this idea, you know, if you're really going to have computation work efficiently, you are going to end up with these programs that are sort of just mined from the computational universe and one of the issues with mining thing so that there this makes use of computation much more efficiently than a typical thing that we might construct. Now, one feature of this is it's hard to understand what's going on and there's actually a fundamental reason for that, which is in our efforts to sort of understand what's going on, we get to use our brains are computers are mathematics or whatever and our goal is this, this particular little program that a certain amount of computation to work out this pattern.

Speaker 3:          00:36:58       The question is can we kind of outrun that computation and say, oh, I can tell that actually this particular bit down here is going to be a black black bit a. You don't have to go and do all that computation. But it turns out that, and again, this will maybe as a digression, which, which, um, there's this phenomenon I called computational irresponsibility, which I think is really common and it's a consequence of this thing I call principle of computational equivalence. And that the principle of computational equivalents basically says as soon as you have a system whose behavior isn't fairly easy to analyze, the chances are that the computation it's doing is essentially as sophisticated as it could be. And That has consequences. Like it implies that the typical thing like this will correspond to a universal computer that you can use to program and a thing.

Speaker 3:          00:37:47       It also has the consequence of this computational reducibility phenomenon that says you can't expect our brains to be able to outrun the computations that are going on inside the system. If there was computational reduce ability, then we can expect that this thing went to a lot of trouble and did a million steps of evolution. But actually just by using our brains, we can jump ahead and see what the answer will be. Computational irreducible suggest that isn't the case. If we're going to make the most efficient use of computational resources, we will inevitably run into computational irritability all over the place. It has the consequence that we get the situation where we can't readily sort of foresee and understand what's going to happen. So back to mathematics for a second. so this is just an axiom system, um, that, uh, so I looked for all possible look through sort of all possible axiom systems starting off with the really tiny ones.

Speaker 3:          00:38:38       And I asked the question, what's the first axiom system that corresponds to boolean algebra? so it turns out this, this thing here, this tiny little thing here, a generates all theorems of boolean algebra does it. It is the simplest axiom for boolean algebra. Now, something I have to show you this because it's a new feature. You see the, if I say find equational proof, let's say I want to prove commuter activity of the nand operation. I'm going to show you something here. This is going to try to generate, let's see if this works. And this is going to try to generate an automated proof based on that axiom system of that result. So it had 102 steps and the proof. And um, let's try and say, let's look at, for example, the proof network here. Actually, let's look at the proof dataset. Um, no, that's not what I wanted.

Speaker 3:          00:39:29       Oh, I should learn how to use the, the, um, let's see what I want is the, um, you know, proof dataset. There we go. Very good. Okay, so this is actually, let's, let's say, uh, first of all, let's say the proof graph. Okay? So this is going to show me the, how that proof was done. So there are a bunch of lemons that got approved and from those lemars, those cameras were combined that eventually approved the result. So let's, let's take a look at the. Let's take a look at what some of those lenders where, okay, so here's, here's the result. So after, so it goes through and these are various lemars it's using, and eventually after many pages of nonsense it will get to the result. Okay? Each one of these, some of these llamas are kind of complicated. The, that's uh, that's that lama.

Speaker 3:          00:40:23       It's a pretty complicated lemme etc. Etc. Etc. So you might ask what on earth is going on here? And the answer is, so I first generated version of this proof 20 years ago and I tried to understand what was going on and I completely failed and it's sort of embarrassing because this is supposed to be approved for. It's supposed to be, you know, demonstrating some results. And what we realize is that, you know, what does it mean to have a proof of something? What does it mean to explain how a thing is done? You know, what, what is the purpose of a proof sort of proof is basically to let humans understand why something is true. And so for example, if you go to, um, let's say we go to wolf alpha and we do, you know, some random thing where we say let's do an integral of something or another, it will be able to very quickly.

Speaker 3:          00:41:10       In fact, it Will take it one milliseconds internally to work out the answer to that integral, okay? But then somebody who's wants to hand in a piece of homework or something like that, needs to explain why is this true? Okay, well, we have this handy step by step solution thing here, which explains why it's true. Now, the thing I should admit about the step by step solutIon is it's completely fake. That is the steps that are described in the step by step solution. I have absolutely nothing to do with the way that internally, that integral was computed. These are steps created purely for the purpose of telling a story to humans about why the center came out the way it did and now what we're seeing and so that's a. So that's one thing is knowing the answer. The other thing is being able to tell a story about why the answer work that way.

Speaker 3:          00:41:59       Well, what we see here is this is a proof, but it was an automatically generated proof and it's a really lousy story for us humans. I mean if it turned out that one of these theorems here was one that had been proved by gauss or something and appeared in all the textbooks, we wouldn't be much happier because then we would start to have a kind of human representable story about what was going on. Instead we just get a bunch of machine generated Lammas that we can't understand that we can't kind of wrap our brains around and it's sorta the same thing that's going on in. When we look at when is neuron that's we're seeing, you know, when we were looking, wherever it was at the innards of that neuron that. And we say, well, how is it figuring out that that's a picture of a panda?

Speaker 3:          00:42:40       Well, the answer is it decided that, you know, if we humans were saying, how would you figure out if it's a picture of a panda, we might say, well look and see if it has eyes. That's a clue for whether it's an animal look and see if it's looks like it's kind of round and furry and things that's a version of whether it's a pander and et cetera, et cetera, et cetera. But what it's doing is it learned to a bunch of criteria for, you know, is it a pandora? Is it one of 10,000 other possible things that it could have recognized? And it learns those criteria in a way that was somehow optimal based on the training that it got and so on. But it learned things which were distinctions which are different from the distinctions that we humans make in the language that we as humans use.

Speaker 3:          00:43:21       And so in some sense, you know, when, when we start talking about, well, describe a picture, we have a certain human language for describing that picture. We have in our human, in typical human languages, we have maybe 30 to 50,000 words that we use to describe things. Those words are words that have sort of evolved as being useful for describing the world that we live in when it comes to this neural net. It could be using, it could say, well, uh, the, the words that it is effectively learnt, which allow it to make distinctions about what's going on in the, in the analysis that it's doing it as effectively invented words that describe distinctions, but those words have nothing to do with our historically invented words that exist in our languages. So it's kind of an interesting situation that, that it is, its way of thinking, so to speak.

Speaker 3:          00:44:10       if you say, well, what's it thinking about? How do we describe what it's thinking? That's a tough thing to answer because just like with the, with the automated theorem, we're, we're sort of stuck having to say, well, we can't really tell a human story because the things that had invented a things for which we don't even have wordS in our languages and so on. Okay. So one thing to reAlize is in this kind of space of sort of all possible computations, that a lot of stuff out there that can be done, there's this coat kind of ocean of sophisticated computation and then the question that we have to ask for us humans is, okay, how do we make use of all of that stuff? So what we've got kind of on the one hand is we've got the things we know how to think about human languages, our way of describing things, our way of talking about stuff.

Speaker 3:          00:45:02       That's the One, one side of things. The other side of things we have is this very powerful kind of ocean of computation on the other side where lots of things can happen. So the question is how do we make use of this sort of ocean of computation in the best possible way for our human purposes and building technology and so on. And So the way I see, you know, my kind of a part of what I've spent a very long time doing this kind of building a language that allows us to take human thinking. On the one hand and describe and sort of provide a sort of computational communication language that allows us to get the benefit of what's possible over in the sort of ocean of computation in a way that's rooted in what we humans actually want to do. And so I kind of view or from language as being sort of an attempt to make a bridge between.

Speaker 3:          00:45:55       So, you know, on the one hand there's all possible computations. On the other hand, there's things we think we want to do and I view often language languages being my best attempt right now to make a way to take our sort of human computational thinking and be able to actually implement it. So in a sense, iT's a language which works in two on two sides. It's both a language where you as a, uh, as uh, the machine can understand, okay, it's looking at this and that's what it's going to compute. But on the other hand, it's also a language for us humans to think about things and computational terms. So, you know, if I go and I, I don't know, one of these, one of these things that I'm doing here, whatever it is that this wasn't that exciting but, but, um, you know, find shortest tour of the geo position of a capital cities in south America.

Speaker 3:          00:46:49       That is a language that's a representation or a precise language of something. And the idea is that that's a language which we humans can find useful in thinking about things in computational terms. It also happens to be a language that the machine can immediately understand and execute. And so I think this is sort of a general, you know, when I think about ai in general, the, you know, what is the sort of, what's the overall problem? Well, part of the overall problem is so how do we tell the ais what to do, so to speak. There's this very powerful, you know, this sort of ocean of computation is what we get to mine for purposes of building ai kinds of things. But then the question is how do we tell ais what to do and what I see, what I've tried to do with wolfram language is to provide a, a way of kind of accessing that computation and sort of making use of the knowledge that our civilization has accumulated and because that's the, you know, there's the general computation on, on this side and there's the specific things that we humans have thought about and the question is to make use of the things that we've thought about to do, do things that we care about doing.

Speaker 3:          00:48:01       Actually, if you're interested in these kinds of things. I happen to just write a blog post last couple of days ago. It's kind of a funny blog posts. It's about, um, well you can see the title there. It came because a friend of mine has, has this crazy project to put little, little sort of a desks or something that, um, should represent kind of the best achievements of human civilization, so to speak, to send out. It's, it's hitchhiking on various spacecraft that are going out into the solar system in the next little while. And the question is what to put on this little desk that kind of represents, you know, the achievements of civilization. It's kind of, it's kind of depressing when you go back and you look at what, um, what people have tried to do on this before. And I'm realizing how hard it is to tell even whether something is an artifact or not.

Speaker 3:          00:48:52       um, but this is a, this was sort of a, um, uh, that's a good one. That's from 11,000 years ago. Can you. The question is, can you figure out what on earth it is and what it means? And this is, uh, uh, but, but, so what, what's relevant about this is the, this, this whole question of there are things that are out there and the computational universe. And you know, when we think about extraterrestrial intelligence, I find it kind of interesting that artificial intelligence is our first example of an alien intelligence. We don't happen to have found what we view as extraterrestrial intelligence right now, but we are in the process of building pretty decent version of an alien intelligence here. And the question is, if you ask questions like, well, you know, what is it thinking? Is it, does it have a purpose and what it's doing and so on, and you're confronted with things like this.

Speaker 3:          00:49:43       It's very, we can kind of do a test run of, you know, what's, what's its purpose? What is it trying to do in a way that is very similar to the kinds of questions you would ask about, about extraterrestrial intelligence. But in any case, the, the, um, uh, the, the main point is that I see there's sort of ocean of computation, there's the, let's describe what we actually want to do with that ocean of computation. And that's where, you know, that's one of the primary problems we have now. People talk about, you know, ai and what is ai going to allow us to automate. And my basic answer to that would be we'll be able to automate everything that we can describe. The problem is it's not clear what we can describe or put another way, you know, you imagine various jobs and people are doing things that are repeated judgment, jobs, things like this there where we can readily automate those things.

Speaker 3:          00:50:34       But the thing that we can't really automate is saying, well, what are we trying to do that is, what are our goals? Because in a sense, when, when we see one of these systems, you know, let's say, let's say it's a, it's a cellular automaton here. Okay? The question is, what is the cellular automaton trying to do? Maybe I can. Maybe I'll give you another cellular automaton that there's a little bit more exciting here. Let's do this one. So the, the um, the question is what is the cellular automaton trying to do? You know, it's got this whole big structure here and things are happening with it. We can go, we can run it for a couple of thousand steps. We can ask. So nice example of kind of undecidability and action. What's going to happen here? This is kind of the whole thing. Problem is this kind of holt, what's it going to do?

Speaker 3:          00:51:16       A, there's computational or disability that we actually can't tell. There's the case where we know this is a universal computer. In fact eventually, well, I wouldn't even spell it for you if I went on long enough. It would, it would go into some kind of cycle. But, um, we can ask what is this thing trying to do? What is it, you know, is it, what's it thinking about? What's it, what's its goal, what's its purpose? And you know, we get very quickly and in a big mess thinking about those kinds of things. I've, I've, um, one of the things that comes out of this principle of computational equivalence is thinking about what kinds of things have a, are capable of, of sophisticated computation. So, so I mentioned a while back here, sort of my personal history with wealth malware of having thought about doing something like wealth now for when I was a kid and then believing that you sort of had to build a brain to make that possible and so on.

Speaker 3:          00:52:10       And one of the things that I then thought was that there was some kind of bright line between what is intelligent and what is merely computational, so to speak. In other words that there was something which is like, oh, we've got this great thing that we humans have that is intelligence and all these things in nature and so on. And all the stuff that's going on there. It's just computation or it's just, you know, things operating according to rules that's different. There's some bright line distinction between these things. Well, I think the thing that came about after I looked at all these cellular automata and all kinds of other things like that is I sort of came up with this principle of computational equivalence, a idea which we've now got quite a lot of evidence for, which I talked about people are interested in. But that basically there isn't a, that once you reach a certain level of computational sophistication, everything is equivalent.

Speaker 3:          00:53:05       And that means that that implies that there really isn't a bright line distinction between, for example, the computation is going on in our brains and the computations going on in this simple cellular automata and so on. And that essentially philosophical point is what actually got me to start trying to build both from alpha because I realized that, gosh, you know, I've been looking for this sort of the magic bullets of intelligence and I just decided probably there isn't one and actually it's all just computation. And so that means we can actually in practice build something that doeS this kind of intelligent like thing. And so that's what I think is the case, is that there really isn't sort of a bright line distinction and that has, that has more extreme consequences. Like people will say things like, you know, the weAther has a mind of its own.

Speaker 3:          00:53:48       Okay. Sounds kind of silly. Sounds kind of animistic primitive and so on. But in fact, the fluid dynamics of the weather is as computationally sophisticated as the stuff that goes on in our brains. But we can start askIng, but then you say, but the weather doesn't have a purpose. You know, what's the purpose of the weather? Well, you know, maybe the weather is trying to equalize the temperature between the, you know, the, the north pole and the tropics or something. And then we have to say, well, but that's not a purpose. And the way that we think about purposes, that's just, you know, and we get very confused. And in the end what we realized is when we're talking about things like purposes, we have to have this kind of chain of provenance that goes back to humans and human history and all that kind of thing.

Speaker 3:          00:54:33       And I think it's the same type of thing when we talk about computation and ai and so on. The thing that we. This question of sort of purpose goals, things like this, that's the thing which is intrinsically human and not something that we can ever sort of automatically generate. It makes no sense to talk about automatically generating it. Because these computational systems, they do all kinds of stuff. You know, we can say they've got a purpose. We can attribute purposes to them, et cetera, et cetera, et cetera. But you know, ultimately it's sort of the human thread of purpose that we have to have to deal with. So that means, for example, when we talk about ais and we were interested in things like, so how do we tell, you know, like, like we'd like to be able to tell. We talk about ai ethics for example.

Speaker 3:          00:55:14       We'd like to be able to make a statement to the ais like, you know, please be nIce to, to us humans and that's a, you know, that's something. So one of the issues there is so, so talking about that kind of thing, I'm one of the issues is how are we going to make a statement like be nice to us humans. What's the, how are we going to explain that to an ai? And this is where again, you know my, my efforts to build a language, a computational communication language that bridges the world of what we humans think about and the world of what is possible and computation is important. And So one of the things I've been interested in is actually building what I call a symbolic discourse language that can be a general representation for a sort of the kinds of things that we might want to, uh, put in, uh, that we might want to say and things like be nice to humans.

Speaker 3:          00:56:11       So sort of a little bit of background to that. So you know, in, in the modern world, people are keen on smart contracts. They often think of them has been deeply tied into blockchain, which I don't think it's really quite right. The important thing about smart contracts is it's a way of having sort of an agreement between parties which can be executed automatically. And that agreement may be, you know, you may choose to sort of anchor that agreement on blockchain. You may not, but the whole point is you have to watch, you know, when people like legal contracts, they write them in an approximation to english. They write them in legal ease typically because they're trying to write them in something a little bit more precise than regular english. But the limitiNg case of that is to make a symbolic discourse language in which you can write the contract and code basically.

Speaker 3:          00:56:58       And the. I've been very interested in using wolfram language to do that because in wolfram language we have a language which can describe things about the world and we can talk about the kinds of things that people actually talk about in contracts and so on. We're most of the way there to being able to do that. And then when you start thinking about that, you start thInking about, okay, so we've got this language to describe things that we, that we care about in the world. And so when it comes to things like tell the ais to be nice to humans, we can imagine using both language to sort of build an ai constitution that says this is how the ai is supposed to work. But when we talk about sort of just the, the untethered, untethered, ai doesn't have any particular, it's just going to do what it does.

Speaker 3:          00:57:47       And if we want it to, you know, if we want to somehow align it with human purposes, we have to have some way to sort of talk to the ai and that's, that's uh, you know, I view my efforts to bilbo from language as, as way to do that. I mean, I, you know, as I was showing at the beginning, you can use, you can take natural language and wIth natural language you can build up a certain amount of, you can say a certain number of things and natural language. You can then say, well, how do we make this more precise in a precise symbolic language if you want to build up more complicated things, it gets hard to do that and natural language. And so you have to kind of build up more serious programs in, in, in symbolic language. And I've probably been numb, been yacking while here and I'm happy to. I can talk about all kinds of different things here. But, but maybe I'm, uh, I've not seen as many reactions as I might've expected to think. So I'm not sure which things people are interested in, which they're not. But, so maybe I should, maybe I should stop here and we can have discussion questions, comments? Yes.

Speaker 2:          00:58:54       Two microphones. If you have questions, please come up.

Speaker 4:          00:58:58       So, uh, I have a quick question. It's close to the earlier part of your talk where you say you don't build a top down ontology, you actually build from the bottom up with disparate domains. What do you feel are the core technologies of the knowledge representation which you used within wolfram alpha that allows you a different domains to reason about each other to come up with solutions and is there any feeling of differentiability for examples if you were to come up with a plan to do something new within wolfram alpha language, how would you go about doing that?

Speaker 5:          00:59:30       Okay, so we've done maybe a couple of thousand domains. Okay. They, what is actually involved in doing one of these domains. It's, it's a gnarly business. Every domain has some crazy different thing about it. I tried to make up actually a while ago, we, um, let me show you something that kind of a hierarchy of what it means to make. See if I can find this here, kind of a hierarchy of what it means to make a domain computable. Uh, where is it? Here we go. Okay, here we go. So this is sort of a hierarchy of levels of what it means to make a domain computable from just, you know, you've got some, you know, you've got some array of data that's quite structured. Forget the separate issue about extracting things from unstructured data, but let's imagine that you were given, you know, a, a bunch of data about landing sites of meteorites or something. Okay. So you go through various levels, so you know, things like, okay, the landing sites of the meteorites are the other positions, just strings or there's some kind of canonical representation of geo possession. Is the, is the type of meteorite, you know, some of them are iron meteorites, some of them are stone meteorites. Have you made a canonical representation? have you made some kind of a way to uh, to identify what. I'm sorry, go ahead. No, no, I mean to do that. So,

Speaker 4:          01:01:01       so my question is, if you did have positions as a string as well as a canonical representation, do you have redundant pieces of the same redundant representations of the same information in different?

Speaker 5:          01:01:14       You always, everything can that you have. You have a minimal representation of everything. So our goal is to make everything canonical. Now that's, you know, there is a lot of complexity in doing that. I mean if you, you know, in each. Okay. So another feature of these domains. Okay. So here's another, another thing to say, you know, it will be lovely if I could just automate everything and cut the humans out of the loop. Turns out this doesn't work. And in fact, whenever we do these domains, it's fairly critical to have expert humans who really understand the domain or you simply get it wrong. And it's also having said that once you've done enough domains, you can do a lot of crosschecking between domains and we are the number one reporters of error and have errors and in pretty much all standardized data sources because we can do that kind of cross checkinG.

Speaker 5:          01:02:04       But I think if you ask the question, what's involved in, um, in bringing online a new domain, it's those sort of hierarchy of things. Some of those take a few hours. You can get to the point of having, you know, we've got good enough tools for ingesting data, figuring out, oh, those are names of cities in that column. Let's canonic allies. Those, some may be questions, but many of them will be able to nail down and to get to the full level of, you've got some complicated domain and it's fully computable is probably a year of work. Um, and, uh, and you might say, well, gosh, why? Why are you wasting your time? You've got to be able to automate that. So you can probably tell we're fairly sophisticated about machine learning kinds of things and so on. And we have tried to automate as much as we can and we have got a pretty efficient pipeline.

Speaker 5:          01:02:57       But if you actually want to get it right and you see it, here's an example of what happens, that there's a level even going between wolf malfa more from language. there's a level of. So for example, let's say you're looking at, you know, lakes in Wisconsin. Okay. So people are querying about lakes in Wisconsin and wolfram alpha, they'll name a particular lake and they want to know, you know, how big is the lake? okay, fine. In wolfram language they'll be doing a systematic computation about lakes in Wisconsin. So if there's a lake missing, you're going to get the wrong answer. And So that's a kind of higher level of, of uh, of, of difficulty. Okay. But the, there's, I think you're asking some more technical questions about ontologies and I can try and answer those. Actually. One quick question. Can you know there's, there's a lot of other questions. Okay. All right. I'll give it a recycles as I've got a simple question. Who or what are your key influences? Whoa. Gosh. In terms of of language design for orphan language in the context of machine intelligence, if you liked, if you want to make it tailored to this audience.

Speaker 5:          01:04:08       I don't know. I've been absorbing stuff forever. I think my main in terms of language design, probably lisp in apl with my sort of early influences, but in terms of, of um, thinking about ai,

Speaker 6:          01:04:25       you know, in, I mean I'm kind of

Speaker 5:          01:04:31       quite knowledgeable. I like history of science. I'm pretty knowledgeable about the early history of kind of mathematical logic, symbolic kinds of things. I would say. Okay, maybe I can answer that in the negative. Okay. I have, for example, in building wolfram alpha, I thought, gosh, let me do my homework. Let me learn all about computational linguistics. Let me hire some computational linguistics phds. That will be a good way to get the start. It turns out we used almost nothing from the, from the previous sort of history of computational linguistics, partly because what we were trying to do, namely short question, natural language understanding is different from a lot of the natural language processing, which has been done in the past. I also have made to my disappointment, very little use of, you know, people like marvin minsky for example. I really don't think. I mean, I knew marvin for years and in fact some of his early work on simple turing machines and things, those are probably more influential to me than his work on, on ai and you know, probably my, my mistake of not understanding that better, but really I would say that I've been been rather uninfluenced by, by sort of the traditional ai kinds of things.

Speaker 5:          01:05:42       I mean, it probably hasn't helped that I've kind of lived through a time when one sort of ai went from, you know, when I was a kid, ai was going to solve everything in the world and then, you know, it kind of decade for awhile and then sort of come back. So I, I, so I would say I can describe my negative, my non influences better than my give is that you made it your own head and it sounds as though that's pretty much right? Yeah, I mean, yes, I mean in so far as there's things to me, I mean look things like the um, uh, you know. Okay. So for example, studying simple programs as a. I'm trying to understand the universal simple programs. Actually, the personal history of that sort of interesting. I mean, I, I, you know, I used to do particle physics when I was a kid basically.

Speaker 5:          01:06:27       And um, uh, then I actually got interested. Okay. So I'll tell you the history of that just as an example of how sort of interesting as a sort of history of ideas type thing. So I was interested in, in how order arises in the universe. So you know, you start off from the hot big bang and then pretty soon you end up with a bunch of humans and galaxies and things like this. How does this happen? So I got an interest in that question. I was also interested in things like neural networks for sort of ai purposes and I thought let me make a minimal model that encompasses sort of how complex things arise from, from other stuff. And I ended up sort of making simpler and simpler and simpler models and eventually wound up with cellular automata and whIch I didn't know were called cellular automata when I started looking at them and then found they did an interesting things and the two areas where cellular automata had been singularly unuseful in analyzing things are large scale structure in the universe and your own networks.

Speaker 5:          01:07:26       So it turned out. But, but that, by the way, the fact that I couldn't have even imagined that one could just start. Yeah, I should say, you know, I've been doing physics and in physics, the kind of intellectual concept is you take the world as it is and you're trying to drill down and find out what, you know, what makes the world out of primitives and so on. It's kind of a reduced to find things. Then I built my first computer language, I think of the snp which went the other way round where I was just like, I'm just going to make up this computer language and you know, just make up what I want the primitives to be. And then I'm going to build stuff up from it. I think that the fact that I kind of had the idea of doing things like making up a little automatons as possible models for the world was a consequence of the fact that I've worked on this computer language, which was a thing which worked the opposite way round from the way that one is used to doing natural, which is sort of this reductionist approach.

Speaker 5:          01:08:18       And that's. I mean, so that's just an example of I've found. I happened to have spent a bunch of time studying, as I say, history of science and one of my, one of my hobbies is sort of history of ideas. I even wrote this little book called idea makers, which is about biographies of a bunch of people who for one reason or another I've written about. And so I'm, I'm always curious about this thing about how do people actually wind up figuring out the things they figure out. and you know, one of the, one of the conclusions that my, you know, investigations with many people is there a very rarely moments of inspiration. Usually it's long multi-decade kinds of things which only later get compressed into something short. And also the path is often much, uh, you know, it's, it's, it's, it's quite, uh, can I say that the steps are quite small and you know, but the path is often kind of complicated and that's what, that's what it's been for me.

Speaker 5:          01:09:15       So I. Simple question, complex answer, sorry about that. Oh, so, um, when I basically see it from the wall from languages, it's a way to describe all of objective reality. It's kind of formalizing your swabbed, the entire domain of discourse, user philosophical term. And you kind of hinted at this in your, a lecture where the, where it sort of leaves offices that when we start to talk about more esoteric, philosophical concepts, purpose, I guess this would lead to things like epistemology because essentially you only have signed there as amazing as sciences. There are other things that are talked aboUt not, you know, like idealism versus materialism, etc. Do you have an idea of how well from might or might not be able to branch into those discourses? Because I'm hearing echoes in my head at that time, baal shem said that an ai needs a, you know, when you give an ai a purpose, there's like, I think he said, philosophers are divided completely evenly between the top four ways to measure how good something should be.

Speaker 5:          01:10:11       It's like utilitarianism and sugar are the foremost japanese. Yeah. Right. So the first thing is, I mean, this problem of making what about 300 years ago, people like live nets were interested in the same problem that I'm interested in, which is how do you formalize sort of everyday discourse and live minutes had the original idea, you know, he was originally trained as a lawyer and he had this idea if he could only reduce all law, all legal questions to matters of logic, he could have a machine that would basically describe the answer every legal case. He was unfortunately a few hundred years too early. Um, even though he did have, you know, he tried to, he tried to do all kinds of things, very similar things I've tried to do, like he tried to get various dukes to assemble big libraries of data. And stuff like this, but, but the point.

Speaker 5:          01:10:58       So what he tried to do was to make a formalized representation of everyday discourse for whatever reason for the last 300 years. Basically people haven't tried to do that. There's, it's almost completely barren landscape. There was this period of time in the 16 hundredS when people talked about philosophicAl languages. Lightness was one. A guy called John Wilkins was another and they tried to break down human thought into something. Symbolic. People haven't done that for a long time. Um, in terms of what can we do that with, um, you know, I've been trying to figure out what the best way to do it is. I think it's actUally not as hard as one might think these areas. One thing you have to understand these areas like philosophy and so on are there on the harder end. I mean things like, good example, typical example, you know, I want to have a piece of chocolate.

Speaker 5:          01:11:48       Okay. They in wolfram language right now, we have a pretty good description of pieces of chocolate. We know all sorts of, you know, we probably know 100 different kinds of chocolate. We know how big the pieces are, all that kind of thing that I want part of that sentence. We can't do that right now. Um, but I don't think that's that hard and I'm, you know, that's now if you ask, let's say we had, I think the different thing you're saying is let's say we had the omnipotent ai so to speak, that was able to, you know, where we turn over the control of the central bank to the ai return over all these other things to the ai. Then the question is we say to the ai now do the right thing. And then the problem with that is, and this is why I talk about, you know, creating ai constitutions and so on, we have absolutely no idea what to do.

Speaker 5:          01:12:38       The right thing is supposed to mean. And philosophers have been arguing about that. You know, utilitarianism is an example of that, of one of the answers to that. Although it's not a complete answer by any means, it's not really an answer. It's just a way of posing the question. Um, and so I think that the, you know, one of, one of the features of um, so I think it's a really hard problem to, you know, you think to yourself, what should the ai constitution actually say? So first thing you might think is, oh, there's going to be something like asimov's laws of robotics that's going to be one, you know, golden rule for ais. And if we just follow that golden rule or we. Well, okay, I think that that is absolutely impossible. And in fact I think you can even sort of mathematically prove that that's impossible because I think as soon as you have a system that, you know, essentially what you're trying to do is you're trying to put in constraints that, okay, basically as soon as you have a system that shows computational irreplaceability, I think it is inevitable that you have a case of have unintended consequences of things, which means that you never get, just say, put everything in this one very nice box.

Speaker 5:          01:13:47       You always have to say, let's put on a patch here. Let's put on a patch there. And so on a version of this much more abstract version of this girdle's theorem. So girdle's theorem is, you know, it starts out by taking the, uh, you know, it's girls' therapist trying to talk about integers and says, start off with pianos, axioms, pianos, axioms, you might say in piano thought described integers and nothing but the integers. Okay? So another thing that's provable from pianos, accidents will be true about integers and vice versa. Okay. What girdle's theorem shows is that yoU can, that will never work, that there are an infinite hierarchy of patches that you have to put on two pianos, axioms if you want to describe the integers and nothing but the integers. And I think the same is true if you want to have a legal system effectively that has no bizarre, unintended consequences.

Speaker 5:          01:14:37       I don't think it's possible to just say, you know, if you, when you're describing something in the world that's complicated like that, I don't think it's possible to just have a small set of rules that will always do what we want. So to speak. I think it's inevitable that you have to have a long essentially code of laws and that's what, you know. So my guess is that what we'll actually have to happen is, you know, as we try and describe what you, we want the eyes to do, you know, I don't know the socio political aspects of how we'll figure out whether it's one ai constitution or one per, you know, city or whatever. We can talk about that. That's a separate issue. But, but, um, you know, I think what will happen is it'll be much like human laws. There'll be a complicated thing that gets progressively patched. And so I think it's some and these ideas like, um, you know, oh, we'll just make the eyes, you know, run the world according to, you know, mills, you know, John Stuart mill's idea. It's not going to work the best, which is not surprising. This philosophy has, has, has made the point that it's not as easy, not an easy problem for the last 2000 years. And they're right. It's not an easy problem. Thank you.

Speaker 7:          01:15:49       I, I'm, you're talking about computational reducibility and computational equivalent and also that earlier on in your intellectual adventures you're interested in particle physics and things like that. I've heard you make the comment before and in other contexts that things like molecules compute and I was curious to ask you exactly what you mean by that. In what sense does,

Speaker 5:          01:16:16       I mean, what would you like to compute so to speak? I mean in other words, you what, what is the case is that no one definition of your computing is given a particular computation like, I don't know, finding square roots or something you can program. A surprising thing is that an awful lot of stuff can be programmed to do any computation you want that some, you know, when it comes to. I mean I think for example, when you look at nanotechnology and so on, the, the, the current, you know, one of the current belief says to make very small computers, you should take what we know about making big computers and just, you know, make them smaller so to speak. I don't think that's the approach you have to use. I think you can take the components that exist at a lot of molecules and say, how do we assemble those components to be able to do complicated computations?

Speaker 5:          01:17:14       I mean, it's likely cellular automata that the, you know, the underlying rule for the seller automaton is very simple. Yet when that rule is applied, many times it can do a sophisticated computation. So I think that that's the, that's the sense in which, what can I say, the raw material that you need for computation can be, you know, there's a great diversity and the raw material that you can use for computation. Our particular human development, you know, stack of, of, uh, of technologies that we use for computation right now is just one particular path. And we can, you know, so a very practical example of this is algorithmic drugs. So the question is right now drugs pretty much work by most drugs work by, you know, there is a binding site on a molecule, drug fits into binding site, does something. The question is, can you imagine having something where the molecule is something which has computations going on in it, where it goes around and it looks at that, you know, that thing it's supposed to be binding to and it figures out, oh, there's this knob here and that knob there, it reconfigures itself.

Speaker 5:          01:18:17       It's computing something. It's trying to figure out, you know, is this likely to be a tumor cell or whatever based on some more complicated thing. That's the type of thing that I mean by, by computations happening at a scale. Okay. I guess I meant to ask if it follows from that, if in your view like the molecules in the track board and in my face and in the table are in any sense currently during doing computer. I mean the question of what computation. Look, one of the things to realize if you look at kind of the sort of past and future of things, the, the um. Okay. So here's an observation. Actually I was about leipnetz actually. Enlightenment says time. Leipnetz made a, a calculator type computer out of bras. Took them 30 years. Okay. So in his day there was, you know, at most one computer in the world as far as he was concerned, right?

Speaker 5:          01:19:07       Today's world, there may be 10 billion computers, maybe 20 billion computers. I don't know. The question is what's that gonna look like in the future? And I think the answer is that in time probably everything we have will be made of computers and the following sense that basically it won't be, you know, in today's world things are made of, you know, metal, plastic, whatever else. But actually that won't make it. There won't be any point in doing that once we know how to do, you know, I'm not a killer scale manufacturing and so on. We might as well just make everything out of programmable stuff. And I think that's a, that's a sense in which, you know, the, the, um, you know, the one example we have molecular computing right now is us bio and biology. Biology does a reasonable job of specific kinds of molecular computing.

Speaker 5:          01:19:52       Um, it's kind of embarrassing. I think that the only, you know, molecule we know that sort of a memory molecule is dna and it's kind of, you know, which is kind of the, you know, the particular biological solution in time. We'll know lots of others and um, you know, I think the, the, um, sort of the end point is so if you're asking is, is computation going on in this water bottle? The answer is absolutely. It's probably even many aspects of that computation, a pretty sophisticated. If we wanted to know what would happen to particular molecules here, it's going to be hard to tell there's going to be computational reproducibility and so on. Can we make use of that for our human purposes? Can we piggyback on that to achieve something technological that's different issue and that's the for that we have to build up this whole sort of chain of, of technology to be able to connect it, which is what I've kind of been been keep on talking about is how do we connect sort of what is possible computationally in the universe to what we humans can kind of conceptualize that we want to do in computation and that's, you know, that's the bridge that we have to make and that's the hard part.

Speaker 5:          01:20:54       but getting the intrinsic, getting the computation done is, is um, you know, those computation going on all over the place. But maybe a couple more questions. I was hoping you could elaborate on what you were talking about earlier of like searching the entire space of possible programs. So that's very broad. So maybe like what kind of searching of that space we're good at and what we're not. And I guess what I mean, I would say that we're at an early stage and not knowing how to do that. Okay. So I've done lots of these things and they are the thing that I've noticed is if you do an exhaustive search, then you don't miss even things that you weren't looking for. If you do a non exhaustive search, there is a tremendous tendency to miss things that you weren't looking for. Um, and so, you know, we've done such as a bunch of function evaluation and wolfram language is done by, was done by searching for optimal approximations in some big space, a bunch of stuff with hashing has done that way.

Speaker 5:          01:21:59       A bunch of image processing is done that way where we're just sort of searching this, doing exhaustive searches and maybe trillions of programs to find things. Now, you know, there is, on the other side of that story is the incremental improvements story with, with deep learning and neural networks and so on, where because there is differentiability um, you're able to sort of incrementally get to a better solution. Now in fact, people are making less and less differentiability and deep learning neural nets. And so I think eventually there's going to be sort of a, a grand unification of these kinds of approaches. Right now we're still, you know, I don't really know what the, you know, the exhaustive search side of things, which you can use for all sorts of purposes. I mean, there's the reason, the surprising thing that makes exhaustive search not crazy is that there is rich sophisticated stuff near at hand and the computational universe, if you had to go quadrillions, you know, through a quadrillion cases before you ever found a thing.

Speaker 5:          01:23:01       Exhaustive search will be hopeless, but you don't in many cases. Um, and uh, you know, I would say that we are in a fairly primitive stage of the, of the science of how to do those such as. Well. My guess is that there'll be some sort of unification, which needless to say, I've thought a bunch about between kind of the norm. That tradeoff typically in neural net says you can have a neural net that is very good at that is uses it's computational resources. Well, but it's really hard to train. Or you can have a neural net that doesn't use this computational resources so well, but it's very easy to train because it's very smoothly and you know, my guess is that somewhere in the harder to train but makes use of things that are to the complete computational universe is where one's going to see progress, but it's, it's a, it's a really interesting area and I consider us own it at the beginning of figuring that out. The one last question.

Speaker 8:          01:24:01       Keep going. Thank you for your talk. I just to give a bit of context for my question, I researched how we could teach ai toolkits and evolving platforms for that. How we could teach artificial intelligence and machine learning to children and I know you develop resources for that as well. So I was wondering like where do you think it's problematic that we have computation that is very efficient and can promote utd darien and problem solving perspective? It achieves all the goals but we don't understand that how we have it worked. So we have to create this fake steps and if he could think of scenarios where that could become very problematic over time and why do we approach it such and such a deterministic way. And when you mentioned that computational intelligence are differentiated by this, like very thin line, how does that affect the way you learn and how do you think that will affect the way we learn? We learn.

Speaker 5:          01:24:52       So I mean look, my general principle about, you know, future generations and what they should learn. I mean, first point is very obvious point that for every field that people study archaeology to zoology, there either is now a computational x or there will be soon. So you know, every field, the paradigm of computation is becoming important, perhaps the dominant paradigm in that field. Okay. So how do you teach kids to be useful in a world where everything is computational? I think the number one thing is to teach them how to think in computational terms. What does that mean? It doesn't mean writing code necessarily. I mean, in other words, one of the things that's happening right now as a practical matter, as you know, there've been these waves of enthusiasm for teaching coding of various kinds. You know, we're in a. We're not actually, we're in the end of an uptick wave.

Speaker 5:          01:25:48       I think it's going down again, you know, it's been up and down for 40 years or so. Okay. Why doesn't that work? What doesn't work? Because while there are people like people who are students at mit for example, for whom they really to learn engineering style coding and it really makes sense to them to learn that the vast majority of people, it's just not going to be irrelevant because they're not going to write a low level c program or something. And it's the same thing that's happened in math education, which has been sort of a disaster there. Which is the number one takeaway for most people from the math they learn in school is I don't like math. And you know, that's not for all of them obviously, but that's the, you know, if you asked a general scale, you know, what people and why is that?

Speaker 5:          01:26:35       Well, part of the reason is because what's been taught is rather low level and mechanical. It's not about mathematical thinking particularly. It's mostly about what teachers can teach and what assessment processes can assess and so on. Okay. So how should one teach computational thinking? I mean, I'm, I'm kind of excited about what we can do with wolfram language because I think we have a high enough level language that people can actually write, you know, that for example, I reckon by age 11 or 12, and I've done many experiments on this, so I have some, the only problem with my experiments as most of my experiments end up being with kids who are high achieving kids, despite many efforts to reach lower achieving kids, that always ends up that the kids who actually do the things that I set up for the high achieving kids. but, but setting that aside, you know, you take the typical um, uh, you know, 11, 12, 13 year olds and so on, and they can learn how to write stuff in this language.

Speaker 5:          01:27:33       And what's interesting is they learn to start thinking here, I'll show you. Let's be very practical. I can show you. I was doing every sunday I do a little little thing with some middle school kids and I might even be able to find my stuff from yesterday. This is, this is, um, okay. Let's see. Programming adventures sharing 20 days. Okay, let's see what I did. Oh, look at that. That was, that was why I thought of the south America thing here because I had just done that with these kids. Um, the, um, and so, uh, what are we doing? We were trying to figure out this, this. I'm trying to figure out the shortest tour thing that I just showed you, which is this is how I got where I got what to show you is, is what I was doing with these kids. But this, this wAs my version of this.

Speaker 5:          01:28:19       But the kids all had various different versions of this and we had, um, somebody suggested, let's just enumerate, let's just look at all possible permutations of these cities and figure out what their distances are. There's the histograM of those. That's what we get from those. Okay. How do you get the largest distance from those, et cetera. Terror, terror. And this is okay. This was my version of that. The kids had similar stuff and this is, you know, this is, I think, and it probably went off into, oh, there we go. There's the one for the whole whole earth. And then they wanted to know how do you do that in three d? So I was showing them how to convert to x, y, z coordinates in three d and make the corresponding thing in three d. So what's. This maybe isn't the. This is a random example from yesterday.

Speaker 5:          01:29:08       So it's not, not a highly considered example, but, but, um, uh, what I think is interesting is that we seem to have finally reached the point where we've automated enough of the actual doing of the computation that the kids can be exposed mostly to thinking about what you might want to compute. And you know, part of our role in language design as far as I'm concerned, is to get it as much as possible to the point where, for example, you can do a bunch of natural language input, you can do things which make it as easy as possible for kids to not get mixed up in the kind of what the, you know, how the computation gets done, but rather to just think about how you formulate the computation. So for example, a typical example I've used a bunch of times in, you know, what does it mean to write code versus do other things.

Speaker 5:          01:29:55       Like a, a typical sort of test example would be, I dunno you, you asked somebody a, you're gonna, there's practical problem. We had them alpha. You give a lat long position on the earth and you say you're going to make a map that lat long position. What, what scale of map should you make? The lat, long as in the middle of the pacific, making a 10 mile radius map isn't very interesting. Fits in the middle of manhattan. A 10 mile radius map might be quite, quite a sensible thing to do. So the question has come up with an algorithm and come up with even a way of thinking about that question. What do you do? You know, how should you figure that out while you might say, you know, oh, let's look at the visual complexity of the image. Let's look at how far it is to another city that's far.

Speaker 5:          01:30:37       You know, there are various different things, but thinking about that as a kind of computational thinking exercise that um, uh, is um, uh, you know, that's the kind of thing. So in terms of what one automates and whether, whether people need to understand how it works inside. Okay. Main point is you'll, in the end it will not be possible to know how it works inside. So you might as well stop having that be a criterion. I mean, that is, there are plenty of things that weren't teachers, people that are, let's say, in, in lots of areas of biology, medicine, whatever else, you know, maybe we'll know how it works inside one day, but you can still, there's an awful lot of useful stuff you can teach without knowing how it works inside. And I think also as we get to computation to be more efficient, inevitably we will be dealing with things where you don't know how it works inside.

Speaker 5:          01:31:29       Now, you know, we've seen this in math education because I've happened to make tools that automate a bunch of things that people do in math education. And I think, well, to tell a silly story, I mean, my, my older daughter, who at some point in the past was doing calculus, you know, and learning doing intervals and things. And I was saying to her, you know, I didn't think humans still did that stuff anymore. Um, which was a very unending comment. But um, but, but in any case, I mean the, the, you know, the, a question of whether do humans need to know how to do that stuff or not. So I haven't done an integral by hand and probably 35 years that's true. More or less true that. But when I was using computers to do them, the I was for awhile in Hawaii, I used to do physics and so on.

Speaker 5:          01:32:17       I use computers to the stuff. I was a really, really good integrator except that it wasn't really me. It was me plus the computer. So how did that come to be? Well, the answer was that because I was doing things by computer, I was able to try zillions of examples and I got a much better intuition that most people got for how these things would work, roughly how, what you did to make the thing go and so on. Whereas people who are like, I'm just working this one thing out by hand. You get a different, you know, you, you don't get that intuition. So I think, you know, two points. First of all this, how do you think about things computationally? How do you formulate the question computationally that's really important and something that we are now in a position I think to actually teach and it is not really something you teach by, you know, teaching, you know, traditional quotes, coding, because a lot of that is.

Speaker 5:          01:33:07       Okay, we're going to make a loop. We're going to define variables. I just as I think I probably have a copy here. Yeah, the, I wrote this book for this book kind of for kids about oral language except it seems to be useful to adults as well, but I wrote it for kids. So it's, um, I'm, one of the amusing things in this book is it doesn't talk it. Talk about assigning values to variables until chapter 38. So in other words, that will be a thing that you would find in chapter one of most, you know, low level programming, coding type type things. It turns out it's not that relevant to know how to do that. it's also kind of confusing and I'm uh, not necessarily. And so, no, in terms of the, you asked where will we get in trouble when people don't know how this stuff works inside.

Speaker 5:          01:33:51       Um, that's, I mean, you know, I think one just has to get used to that because it's like, you know, you might say, well we live in the world and it's full of natural processes where we don't know how they work inside, but somehow we managed to survive and we go to a lot of effort to do natural science to try and figure out how stuff works inside. But it turns out we can still use plenty of things even when we don't know how they work inside. We don't need to know. um, and I think the, um, I mean I think the main point is computational error, reducibility guarantees that we will be using things where we don't know and can't know how they work inside. And you know, I think the, the, perhaps the thing that is a little bit, you know, to me a little bit unfortunate as a, you know, as a typical human type thing.

Speaker 5:          01:34:40       The fact that I can readily see that, you know, the ai stuff we build is sort of effectively creating languages and things that are completely outside of the domain to understand and where by by that I mean, you know, our human language, but that's 50,000 words or whatever has been developed over the last however many tens of thousands of years. And as a society we've developed this way of communicating and explaining things. You know, the ais are reproducing that process very quickly, but they're coming up with a, an, a historical, you know, something, you know, that way of describing the world that doesn't happen to relate at all to our historical way of doing it. And that's um, you know, it's a little bit disquieting to me as a human that, that, you know, are things going on inside where I know it is. You know, in principle I could learn that language, but it's not the historical one that we've all learned.

Speaker 5:          01:35:34       And it really wouldn't make a lot of sense to do that because you learn it for one ai and then another one gets trained and it's going to use something different. So it's some. But my main, I guess my main point for, for education. So another point about education I just make, which is something I haven't figured out but, but um, just is um, you know, when do we get to make a good model for the human learner using machine learning? So in other words, you know, part of what we're trying to do, like, like I've got that automated proof, I would really like to manage to figure out a way what is the best way to present that proof so human can understand it. And basically for that we have to have a bunch of heuristics about how humans understand things. So as an example, if we're doing, let's say a lot of visualization stuff and wolfram language, okay, we have tried to automate to automate it aesthetics.

Speaker 5:          01:36:23       So what we're doing is we're laying out a graph. What way of laying out that graph is most likely for humans to understand it. And we've done that by building a bunch of heuristics and so on, but that's an example of, you know, if we could do that for learning and we say what's the optimal path given that the person is trying to understand this proof, for example, what's the optimal path to lead them through understanding that proof. I suspect we will learn a lot more and probably fairly small number of years about that. And it will be the case that, you know, for example, if you've got, oh I don't know, you can do simple things like you know, you go to wikipedia and you look at what the path of, you know, how do you, if you want to learn this concept, what are the concepts you have to learn?

Speaker 5:          01:37:04       We have much more detailed symbolic information about what is actually necessary to know in order to understand this. And so on. It is, I think, reasonably likely that we will be able to. I mean if I look at. I was interested recently in the history of math education. so I wanted to look at the complete sort of path of math textbooks. You know, for the past, well basically the, uh, like 1200, you know, even actually produced this one of the early math textbooks. So there'd been these different ways of teaching math and you know, I think we've, we've gradually evolved a fairly optimized way for the typical person though. It's probably the variation of the population is not well understood for you know, how to explain certain concepts. And we've gone through some pretty weird ways of doing it from the 16 hundreds and so on were which have gone out of style and possibly, you know, who knows what that's because of. Well, but anyway, so, so, you know, we've kind of learned this path of what's the optimal way to explain adding fractions or something for humans for the typical human. But I think we'll learn a lot more about how, you know, by, by essentially making a model for the human. A machine model for the human will learn more about how to, um, you know, how to optimize, how to explain stuff to humans, a coming attraction. But

Speaker 9:          01:38:22       by the way, do you think we're close to that at all? Because you, you, you said that there's a, something in wolfram alpha that, that presents the human a nice, our. Where are we, how far? He said coming attraction, tenure.

Speaker 5:          01:38:34       All right. So I mean in that explaining stuff to humans thing is a lot of human work right now being able to automate explaining stuff to humans. Okay. So some of these things but see, I mean, so an interesting question actually just today I was working on something that's related to this. Yeah, it's, it's, it's being able to, um, the question is given a whole bunch of, can we, for example, train a machine learning system from explanations that it can see roughly can we train it to give explanations that are likely to be understandable? Maybe. I think the. Okay. So an example that I'd like to do. Okay. I'd like to do a debugging assistant where the typical thing is program runs program gives wrong answer. Human says, why did you get the wrong way? Did it give the wrong answer? Well, the first piece of information to the computer is that was the human thought.

Speaker 5:          01:39:31       That was the wrong answer because the computer just did what it was told and it didn't know that was supposed to be the wrong answer. So then the question is, can you, in fact, you know, in that domain, can you actually have a reasonable conversation in which the human is explaining the computer what they thought it was supposed to do. The computer is explaining what happened, why did it happen? And so on. Same thing for math tutoring. Um, you know, we have a lot of, you know, we've got a lot of stuff, you know, we're, we're sort of very widely used for people who want to understand the steps in math, you know, can we make a thing where people tell us? I think it's this. okay, I'll tell you one, one little factoid which I did work out. so if you do multi arithmetic, multi digital edition.

Speaker 5:          01:40:12       Okay. Okay. So the, the basis of this is kind of silly, silly thing, but, but you know, if you get the right answer for an audition some. Okay. You don't get very much information. The student gives the wrong answer. The question is can you tell them where they went wrong? So I'd say you have afforded in addition some and the student gives the wrong answer. Can you back trace and figure out what they likely did wrong? And the answer is you can you, you just make this graph of all the different things that can happen, you know, when did they know there are certain things that are more common, transposing numbers and things or you know, having a one on a mixed up, those kinds of things you can with very high probability given afforded addition some with the wrong answer. You can Say this is the mistake you made, which is sort of interesting and that's being done in a fairly symbolic way. Whether one can do that in a, you know, more machine learning kind of way for more complicated directions. I'm not sure, but that's a, that's one that works. The. Yeah. I just had a followup question.

Speaker 7:          01:41:16       So do you think, uh, you know, like in the future it is, is it wasn't moved to simulate virtual environment which can actually understand how the human mind works and then build a, you know, like finite state machines inside of this watch and environment, uh, to, to provide a better learning experience and a more personalized learning experience.

Speaker 5:          01:41:39       Well, I mean, so the question is if, if, if you're going to, you know, can you optimize if you're playing a video game or something and that video game is supposed to be educational, can you optimize the experience based on a model of you so to speak? Yeah, I'm sure the answer is yes. And I'm sure the, you know, the question of how complicated the model of you will be as an interesting question. They don't know the answer to. I mean I've, I've kind of wondered a similar question. So I, I'm a kind of personal analytics enthusiastic. I collect tons of data about myself. I mean, I do it mostly because it's been super easy to do and I've done it for like 30 years and I have, you know, every key stroke I've typed on a computer, like every keystroke I've typed here and the screen of my computer every, every 30 seconds or so of maybe 15 seconds, I'm not sure it does.

Speaker 5:          01:42:25       A screenshot is a super boring movie to watch. But anyway, I've been collecting all this stuff and so a question that I've asked is, is there enough data that a bot of me could be made? Other words, do I have enough data about, you know, I've got, I've written a million emails, I have all of those. I've received 3 million emails. I'm over that period of time. I've got endless, you know, things I've typed, et cetera, et cetera, et cetera. You know, is there enough data to reconstruct you know me? Basically, I think the answer is probably yes. Not sure, But I think the answer's probably yes. And so the question is in an environment where you're interacting with some video game, trying to learn something, whatever else, you know, how long is it going to be before it can learn enough about you to change that environment in a way that's useful for explaining the next thing to you?

Speaker 5:          01:43:18       I would guess I would guess that have done that. This is comparatively easy. I might be wrong, but, but um, uh, and that the, um, I mean, I think, you know, it's an interesting thing because no one's dealing with, you know, there's a space of human personalities. There's a space of human learning styles, you know, I'm sort of always interested in the space of all possible x, y, z, and there's, you know, there's that question of, well, how do you parameterize the space of all possible human learning styles and is there a way that we will learn, you know, like, can we do that symbolically and say these are 10 learning styles or is it something. I think that's the case Where it's better to use, you know, sort of soft machine learning type methods to kind of feel out that space. Maybe very last question.

Speaker 7:          01:44:10       I was just intuitively thinking when you spoke about an ocean, I thought of isaac newton when he said, uh, uh, you know, the famous quote, I might not, and I thought instead of newton on the beach, what a friends list. Where there a, what question would he ask? What would he say? And I'm trying to understand your, the alien ocean and humans through maybe franz liszt and music.

Speaker 5:          01:44:42       well, so I mean, the, the quote from newton is, is, um, a sort of an interesting quote. I think it goes something like this if, you know, uh, people are talking about how wonderful calculus and all that kind of thing are. And newton says, uh, you know, to others, I may seem like I've done a lot of stuff, but to me I seem like a child who, who picked up a particularly elegance, you know, seashell on the, on the beach. And I've been studying this seashell for awhile. Even though there's this ocean of truth out there waiting to be discovered, that's roughly the quote. Okay. I find that quote interesting for the following reason. The, what newton did was, you know, calculus and things like it. If yoU look at the computational universe of all possible programs, there is a small corner. Newton was exactly right and what he said that his, he picked off calculus, which is a corner of the possible things that can happen in the computational universe that happened to be an elegant seashells, so to speak.

Speaker 5:          01:45:42       They happened to be a case where you can figure out what's going on and uh, and so on, while there is still the sort of ocean of, uh, of other sort of computational possibilities out there. Uh, but, but when it comes to, you know, you're asking about music. I, oH, I think my computer stopped being able to get anywhere but, but sort of interest in the, uh, see if we can get to the site. So this is a, this is a website that we made years ago and now my computer isn't playing on a thing, but let's try that. Okay. So these things are created by basically just searching computational universe of possible programs. It's sort of interesting because everyone has kind of a story. Some of them look more interesting than others. Let's try that one

Speaker 10:         01:46:44       anyway.

Speaker 5:          01:46:45       The, the um, what's, what's interesting, what was interesting to me about this was this is a very trivial, you know, what this is doing is very trivial at some level. It's just, it actually happens to use cellular automata. You can even have it show you, I think someplace here. Where is it? Somewhere there's a way of showIng your show the evolution. This is, this is showing the behind the scenes what was actually happening, what it chose to use to generate that musical piece. Um, and uh, what I thought was interesting about this site, I thought, well, you know, howard computers be relevant to music, etc. Etc. Etc. Well, you know, what would happen is a human would have an idea and then the computer would kind of dress up that idea and then, you know, a bunch of years go by and I talked to people who are composers and things and they say, oh yeah, I really liked that.

Speaker 5:          01:47:36       Well, from town site, okay, that's nice. They say it, it's a very good place for me to get ideas. So that's sort of the opposite of what I would've expected. Namely what's happening is, you know, human comes here, you know, listens to some ten second fragment. And they said, oh, that's an interesting idea. And then they kind of embellish it using kind of something that is humanly meaningful, but it's like, you know, you're taking a photograph and you see some interest in configuration and then kind of your, you know, you're filling that with kind of some human, a sort of context. Um, but, uh, but, so I'm not quite sure what, um, uh, what you were asking about. I mean, back to the newton quote, the thing that I think has some, uh, another way to think about that quote is us humans, you know, with our sort of historical development of, you know, our intellectual history have explored this very small corner of what's possible in the computational universe and everything that we care about is contained in the small corner.

Speaker 5:          01:48:46       And that means that, you know, you could say, well, gee, you know, I want to know what w, w, w, what we end up wanting to talk about other things that we as a society have decided we care about and what. There's an interesting feedback loop I just mentioned it should end, but, but, um, so you might say, so here's, here's a funny thing. So let's take language, for example, language evolves. We say we, we make up language to describe what we see in the world. Okay, fine, that's a fine idea. Imagine the paleolithic times, people will make up language. They probably didn't have a word for table because they didn't have any tables. They probably had a word for rock. But then we ended up as a result of the particular, you know, development that our civilization has gone through. We build tables and there was sort of a synergy between coming up with a word for table and deciding tables were a thing and we should build a bunch of them.

Speaker 5:          01:49:46       And so there's this sort of complicated interplay between the things that we learn, how to describe and how to think about the things that we build and put an our environment and then the things that we end up wanting to talk about because there are things that we have experienced in our environment. And so that's the, you know, I think as we look at sort of the progress of civilization, there's, you know, there's various layers of. First we, you know, we invented a thing that we can then think about and talk about. Then we build an environment based on that. Then that allows us to do more stuff and we build on top of that. And that's why, for example, when we talk about computational thinking and teaching it to kids and so on, that's one reason that's kind of important because we're building a layer of things that people are then familiar with that's different from what we've had so far. And they give people a way to talk about things. I'll give you one example that I'm seated. I have that still up the

Speaker 6:          01:50:39       uh, okay. One, one. One example here, uh,

Speaker 5:          01:50:47       from this blog post of mine. Actually. So

Speaker 6:          01:50:50       the. Alright, is it? Okay. So that,

Speaker 5:          01:50:56       that thIng, there is a nested pattern, you know, it's a, it's a penske,

Speaker 6:          01:51:01       um, that, that

Speaker 5:          01:51:05       tile pattern was created in 12, 10, 80.

Speaker 5:          01:51:09       okay. that's the first example I know of a fractal pattern. Okay. Well, the art historians wrote about these patterns. There are a bunch of his particular style or pattern they wrote about these for years. They never diScussed that nest pattern. These patterns also have, you know, pictures of lions and elephants and things like that. And then they wrote about those kinds of things, but they never mentioned the nested pattern until basically about 25 years ago when fractals and so on became a thing. And then it's, oh, I can now talk about that. It's a nested patterns, fractal. And then, you know, before that time, the art historians were blind to that particular part of this pattern. It was just like, I don't know what that is, that there's no, you know, I don't have a word to describe it. I'M not going to, I'm not going to talk about it.

Speaker 5:          01:51:58       So that's a, you know, it's part of this feedback loop of, of things that we learn to describe. Then we build in terms of those things. Then we built another layer. I think one of the things, I mean you talk about, you know, just in the sort of thing, one thing I'm really interested in is the evolution of purposes. So if you look back in human history, there's a, you know, what was thought to be worth doing a thousand years ago is different from what's thought to be worth doing today. And part of that is, is, um, uh, you know, good examples of things like walking on a treadmill or buying goods and virtual worlds. Both of theSe are hard to explain to somebody from a thousand years ago because each one ends up being a whole sort of societal story about we're doing this because we do that because we do that.

Speaker 5:          01:52:44       And so the question is how will these purposes evolve in the future? And I think one of the things that I view as a sort of sobering thought is that that term, actually one thing I found rather disappointing and then I became less pessimistic about it is if you think about the future of the human condition and you know, we'd been successful in making ai systems and we can read out brains and we can upload consciousnesses and things like that. And we've actually got this box with trillions of souls in it. And the question is, what are these souls doing? And to us today, it looks like they're playing video games. So the rest of eternity. And that seems like a kind of a bad outcome. It's like we've gone through all of this long history and what do we end up with? We end up with a trillion souls in a box playing video games and I thought this is a very depressing outcome, so to speak.

Speaker 5:          01:53:34       And then I realized that that actually, if you look at the sort of arc of human history people, are there any given time in history, people have been. uh, my main conclusion is that any time in history, the things people do seem meaningful and purposeful to them at that time in history and history moves on and you know, like a thousand years ago, there were a lot of purposes that people had that you know what to do with weird superstitions and things like that that we say, why the heck were you doing that? That just doesn't make any sense. Right? But to them at that time, it made all the sense in the world. And I think that, you know, the thing that makes me sort of less depressed about the future, so to speak, is that at any given time in history, you know, you can still have meaningful purposes.

Speaker 5:          01:54:26       Even thOugh they may not look meaningful from a different point in history and that sort of a whole theory, you can kind of build up based on kind of the trajectories that you've followed through the space of purposes and sort of interesting. If you can jump, like you say, let's get cryonically frozen for 300 years and then be back again. The the interest in cases. Then you knoW all the purposes that you sort of, you know, that you find yourself in ones that have any continuity with what we know today. I should stop with that. That's a beautiful way to end it.

Speaker 2:          01:54:59       Yeah.