Speaker 1:          00:00:00       The following is a conversation with Tomasa Pojo. He's a professor at Mit and as a director of the center for brains, minds and machines cited over 100,000 times. His work has had a profound impact on our understanding of the nature of intelligence in both biological and artificial neural networks. He has been an advisor to many highly impactful researchers and entrepreneurs and AI, including Dennis, has hobbyists of deep mind, Amnon, Shaw, Schwab, Mobileye, and Christof Koch of the Allen Institute for Brain Science. This conversation is part of the MIT course on artificial general intelligence and artificial intelligence podcasts. If you enjoy, subscribe on Youtube, iTunes, or simply connect with me on Twitter at Lex Friedman, spelled f, r I. D. And now here's my conversation with to muscle

Speaker 2:          00:00:51       [inaudible].

Speaker 1:          00:00:52       You've mentioned that in your childhood you've developed a fascination with physics, especially the theory of relativity, and that Einstein was also a childhood hero. To you, what aspect of Einstein's genius, the nature of his genius do you think was essential for discovering the theory of relativity?

Speaker 2:          00:01:12       You know, Einstein was a hero to me and I'm sure to many people because he was able to make a, of course a major, major contribution to physics with simplifying a bit, just a good Dunkin experiment if four to experiment, you know, imagining communication with the lights between a stationary observer and somebody on a train. And, uh, I fought, uh, um, you know, the, the, the, the, the fact that just with the force of his fault, of his thinking of his mind, he could get to some, something so deep in term of physical reality, how time and depend on space and speed is, it was something absolutely fascinating was the power of intelligence, of the power of the mind.

Speaker 1:          00:02:08       Do you think the ability to imagine, to visualize as he did, as a lot of great physicists do, do you think that's in all of us human beings or is there something special to that one particular human being?

Speaker 2:          00:02:22       I think, you know, all of us can learn and have an in principle similar breakthroughs that are lesson to be learned from Einstein. He was one of five phd students at Atr and the, I'd cannot see shit, take any shit off, shoot it in a sewer leak in physics. And he was the worst of the five. The only one who did not get an academic position when he graduated, when he finished his phd and he went to, as everybody knows for the patent office. And so it's not so much that he worked for the patent office, but the fact that obviously he was mad, but he was not the top student or obviously was the antique conformist, was not thinking in the traditional way that probably is teachers and the other students were doing. So there is a lot to be said about, you know, trying to be, to do the opposite or something quite different from what other people are doing that Saturday too for the stock market. Never, never buy for very bodies by

Speaker 1:          00:03:36       and also true for science. Yes. So you've also mentioned staying on the theme of physics, that you were excited and he young age by the mysteries of the universe that a physics could uncover such as I saw mentioned the possibility of time travel. So the most out of the box question I think I'll get to ask today. Do you think time travel is possible?

Speaker 2:          00:04:03       Oh, why? It would be nice if it were possible right now. Uh, you know, you signed to never say no. Um,

Speaker 1:          00:04:12       but your understanding of the nature of time,

Speaker 2:          00:04:15       yeah. It's very likely that it's not possible to travel in time. Um, he, we may be able to travel forward in time if we can, for instance, Freezo selves or uh, you know, go on some spacecraft traveling close to the speed of light. But in terms of actively traveling, for instance, back in time, I find probably very unlikely.

Speaker 1:          00:04:45       So do you still hold the, the underlying dream of the engineering intelligence that will build systems that are able to do such huge leaps, like discovering the kind of mechanism that will be required to travel through time? Do you still hold that dream or are echoes of it from each childhood?

Speaker 2:          00:05:07       Yeah, I, you know, I don't think whether there are certain problems that probably cannot be solved depending what, what you believe about the physical reality, like, uh, you know, maybe totally impossible to create energy from nothing or to travel back in time. But, uh, um, about making the machines that can think as well as we do or better or more likely, especially in the short and midterm help us think better, which is in a sense it's happening already with the computers we have and it will happen more and more. But that I certainly believe, and I don't seem principle why computers at some point could not become more intelligent than we are. Although the word intelligence is a tricky one and one no, shoot,

Speaker 1:          00:06:04       discuss what they mean with that intelligence consciousness where it's like, love is all these are very, uh, need to be disentangled. So you've mentioned also that you believe the problem of intelligence is the greatest problem in science greater than the origin of life and the origin of the universe. You've also, uh, in the talk, I've listened to a said that you're open to arguments against, uh, against you. So what do you think is the most captivating aspect of this problem of understanding the nature of intelligence? Why does it a captivate you as it does

Speaker 2:          00:06:47       what originally? I think one of the motivation that I, uh, there's a, I guess a teenager when I was infatuated with theory of relativity was really that I, I found that there was a, the problem of time and space and general relativity, but there were so many other programs have this same level of difficulty and the importance that they could, even if I were to Einstein, it was difficult to hope to solve all of that. So what about solving a problem? Who Solution and allow me to solve all the problems and the source. What if we could find the key to an intelligence, you know, 10 times better or faster, the nice tight.

Speaker 1:          00:07:37       So that's sort of seeing artificial intelligence as a, as a tool to expand our capabilities. But is there just an inherent curiosity in you and just understanding what it is in our in, in here that makes it all all work?

Speaker 2:          00:07:54       Yes. Episode. The all right, so I was starting, I started saying this was the motivation when I was a teenager, but you know, soon after I think the problem of human intelligence became a real focus of, you know, of my extent of my science and my research because I think he's, for me the most interesting problem is really asking, uh, oh we, we are right is asking not only the question about science, but even about the very tool we are using to do science, which is all brain. How does our brain work from, where does it come from, what are its limitation? Can we make it better?

Speaker 1:          00:08:46       And that in many ways is the ultimate question that underlies this whole effort of science. So you've significant contributions in both the science of intelligence and the engineering of intelligence in a hypothetical way. Let me ask, how far do you think we can get in creating intelligence systems without understanding the biological, the understanding of how the human brain creates intelligence? Put another way. Do you think we can build a strong assets and without really getting at the core, the functional and the understanding of the function, nature of the brain? What are the seas

Speaker 2:          00:09:26       difficult question. You know, we did, uh, um, solve problems like flying without, oh really? Using too much or knowledge about how birds fly. It was important I guess to know that you could have a thinks heavier than, than air being able to fly like birds. But beyond that property we did not learn very much. You know, some, you know, the, the brothers, right? Did learn a lot of, of salvation about birds and designing their, their aircraft. But, uh, you know, you can argue we did not use much of biology in that particular case. Now, in the case of intelligence, I think that, uh, it's, it's a bit of a bat right now if you are, if you ask a, okay. Um, we, we all agree we'll get at some point, maybe soon, maybe later to a machine that is indistinguishable from my secretary saying in terms of what I can ask the machine to do.

Speaker 2:          00:10:47       I think we'll get there. And now the question is, and you can ask people, do you think we'll get there without any knowledge about, uh, you know, the human brain or the to the best way to get their eyes to understand better the human brain? Yeah. Okay. This is, I think an educated bet that different people with different background will decide in different ways. The recent history story of the progress in AI in the last, I would say five years or 10 years has been the, the main, uh, breakthroughs. The main recent breakthroughs. Oh, really? Start from neuroscience. Okay. I can mention reinforcement learning as one. And he's one of the, our goal teams at the core of Alpha goal, which is the system to beat the kind of an official world champion of goal Lisi doll. And two free years ago in Sule, um, that's one.

Speaker 2:          00:11:53       And that started really with the work of Pavlov. Um, 900 Marvin Minsky in the 60s and many other neuroscientists later on. Um, and deep learning, uh, started, uh, which is at the core again of Alphago and systems like autonomous driving systems for cars, like the systems that, uh, Mobileye, which is a company started by one of my expos. Dot Com. Nosha sure. Um, the, the salt that is a quarter of those things and deep learning, really the initial ideas in terms of the architecture of this layer. Heirarchical networks started with work of Torsten Visa, Lynn Individually, Bill at Harvard, up the river in the 60s. So recent, the story suggests that neuroscience played a big role in this breakthroughs. My personal bet is that there is a good chance they continue to play a big role, maybe not in all the future breakthroughs, but in some of them at least in inspiration. So he at least in an inspiration. Absolutely, yes.

Speaker 1:          00:13:07       So you see, you studied both artificial and biologic when you're on that works. He said, these mechanisms that underlie deep learning and reinforcement learning, but there is nevertheless a significant differences between biological and artificial neural networks as they stand now. So between the two, what do you find is the most interesting, mysterious, maybe even beautiful difference as as it currently stands in our understanding?

Speaker 2:          00:13:37       I must confess that until recently I found that the artificial networks too simplistic relative to real neural networks. But, uh, you know, recently I've been started to think that yes, there are very big simplification of what you find in the brain. But on the other hand that are much closer in terms of the architecture to the brain than other models that we had that computer science used as model of thinking which will mathematical logics, you know, least prologue and those kind of things. So in comparison to those that are much closer to the brain, you have networks of neurons, which is what the brain is about. The artificial neurons in the mod there is, as I said, the caricature of the biological neurons, but they're still neuron, single units communicating with other units. Something that is absent in, you know, the traditional computer type models of mathematics or reasoning and so on. So aspect do you,

Speaker 1:          00:14:52       would you like to see in artificial neural networks added over time as we try to figure out ways to improve them?

Speaker 2:          00:14:59       So one of the main differences and, um, you know, problems in terms of deep learning today and it's not only deep learning and the brain is the need for deep learning techniques to have, uh, a lot of labeled examples, you know, for Easter, for image nature of like it training site, which is 1 million images, each one labeled by some human in terms of which object is there. And, um, it's, it's clear that in biology the baby may be able to see millions of images in the first years of life, but we will not have million of labels given to him or her by parents or take take a caretakers. So, uh, how do you solve that? You know, I think there is this interesting challenge that today, uh, deep learning and related techniques are all about big data, big data, meaning a lot of examples labelled by humans. Um, whereas in nature you have, uh, so the, the, the, this big data is and go into infinity, that's the best you know, and meaningly able data. But I think the biological world is more and going to one child can learn, it's a beautiful erotic, very small number of labeled examples. Like you tell a child this is a car you don't need to say like in image net, you know, this is a car, this is a car, this is not a card, this is not the cat 1 million.

Speaker 1:          00:16:53       So, and of course where the alpha go in or at least a Alpha zero variants, there's because of the, because of the world of Goa, so simplistic that you can actually learn by yourself or self play. You can play against each other and the real world, I mean the visual system that you've studied extensively is a lot more complicated than the game of go. So on the comment about children, which your fascinatingly good at learning new stuff, how much of it do you think is hardware? How much of it is software?

Speaker 2:          00:17:26       Yeah, that's a good, a deep question is in a sense it's the old question of nurture and nature and munchies in the gene and how much is in the experience of an individual. Obviously it's both that play a role and I believe that the way evolution gives put prior information, so to speak, hardwired, it's not really hardwired, but um, uh, that's essentially in a pot. I think what's going on is that evolution as, um, you know, most necessarily if you believe in Darwin is very opportunistic and, and think about, uh, uh, our DNA and the DNA of the resolve, Sheila, uh, out of DNA does not have many more genes than the resolve. Sheila aren't mountain the fly, the fly, the fruit fly. Now we know that the fruit fly does not learn a very much during its individual existence. It looks like one of these machinery that it's really mostly not 100%, but you know, 95% hardcore that by the jeans.

Speaker 2:          00:18:51       But since we don't have many more genes than the Safiullah is evolution, couldn't call it in as a kind of general learning machinery and then had to give very weak priors. Um, like for instance, let me take, give a specific example, which is a recent work by a member of our center for brains, minds and machines. We know him because of work of other people in our group and other groups that there are cells in a part of our brain neurons that are tuned to faces. They seems to be involved in face that a clinician now, this face area exist, uh, uh, seems to be present in young children and adults. Um, and one question is, is there from the beginning is hard wired by evolution or you know, somehow he's, it learned very quick. So what's your, by the way, a lot of the questions I'm asking we, the answers we don't really know, but as a person who has contributors, some profound ideas and these fields, you're a good person to guests at some of these.

Speaker 2:          00:20:08       So, of course, as a caveat before, a lot of the stuff we're talking about, but what is your hunch? Is the face of the part of the brain that that seems to be concentrated on face recognition. Are you born with that or are you just, is designed to, to learn that quickly? Like the face of the mother and it's, and I, my hunch, your mom by bias was the second one learned very quickly. And it turns out that the marriage Livingstone at Harvard has done some amazing experiments in which she raised baby monkeys depriving them of fees during the first weeks of life. So they see technicians but that the conditioner have a mask. Yes. And um, and so when they look to, mmm. At the area in the brain of this menchies that usually you find faces, they found no face preference. So my guess is the, what evolution does in this case is that he's a plastic and area and which is plastic, which is kind of predetermined to be imprinted very easily. But the command from the gene is not a detailed psychiatry for a face template. Could be, but this will let acquired property a lot of bits cause you had to specify a lot of connection of a lot of neurons instead at the command, the command from the gene is something like in print, memorize what you see most often in the first two weeks of life, especially in connection with food and maybe nipples. I don't write well

Speaker 1:          00:21:54       source of food and that area is very plastic at first and then solidifies. It'd be interesting if a variant of that experiment would show a different kind of pattern associated with food than a face pattern. Whether that could stick. Yeah.

Speaker 2:          00:22:10       That I don't indications that during the experiment, well the monkey saw quite often where, um, the blue gloves of the technicians that were given to the baby monkeys, the milk and some of the cells instead of being faced sensitive in that area. Uh, Hanson's

Speaker 1:          00:22:33       Oh that's fascinating. Can you, uh, talk about what are the different parts of the brain and in your view sort of loosely and how do they contribute to intelligence? Do you see the brain as a bunch of different modules and they together come in the human brain to create intelligence? Or is it all one, um, much of the same kind of fundamental, uh, um, the architecture?

Speaker 2:          00:23:04       Yeah, that's, um, you know, that's an important question and there was a phase in a neuroscience back in the 1950 or so in which it was believed for a while that the brain was equipped potential. This was the term you could cut out a piece and I'm nothing special happened apart, little bit less performance. There was a, a surgeon. Lastly, we'll need a lot of experiments of this type with mice and the riots and concluded that every part of the brain was essentially equivalent to any other one. It turns out that that's, that's really not true. It's a, that are very specific modules in the brain as you said. And uh, you know, people may lose the ability to speak if you have a stroke in a certain region or me and lose control of their legs in another region or so. There are very specific, the brain is also quite flexible and redundant.

Speaker 2:          00:24:17       So often it can correct things and uh, you know, uh, kind of, um, take over functions from one part of the brain to the other. But uh, but, but really that are specific modules. So the answer that we know from this old world, which was basically on based on lesions, either on animals or very often the where and the mine of what they did, there was a mine are very interesting data coming from, um, from the war, from different types of, um, injuries, injuries that soldiers had in the brain and uh, more recently, um, functional Mri, which allow you to, to check which part of the brain are active when you're doing different tasks as you know, can replace some of this. You can see that certain parts of the brain are involved, are active.

Speaker 1:          00:25:30       Yup. And that's all right. But sort of taking a step back to that part of the brain that discovers that, uh, specializes in the face and how that might be learned. What's your intuition behind, you know, is it possible that a sort of from a physicist perspective, when you get lower and lower that it's all the same stuff and it just, when you're born it's plastic and quickly figures out this part is going to be about vision. This is going to be about language. This is about common sense reasoning. Do you have an intuition that that kind of learning is going on really quickly or is it really kinda solidified in hardware? That's a great question. So there are parts of the brain

Speaker 2:          00:26:14       like the cerebellum or they put campus that are quite different from each other that they clearly have different anatomy, different connectivity there. Then there is uh, the, the CORTEX, which is the most developed part of the brain in humans and in the cortex you have different regions of the cortex that are responsible for vision, for audition, for motor control, for language. Now, one of the big puzzles of, of this is that in the cortex is the Cortex, is the Cortex, is, looks like it tastes the same in terms of hardware, in terms of type of neurons and connectivity across these different modalities. So for the Cortex, letting aside this other parts of the brain, like spinal cord, hippocampus or a bedroom and so on for the Cortex, I think your question about hardware and software and learning and so on, it's think is rather open. And um, you know, I find it very interesting for is it to think about an architecture, computer architecture that is good for vision and the same time he's good for language seems to be, you know, saw different problem areas that you have to solve.

Speaker 1:          00:27:49       But the underlying mechanism might be the same and that's really instructive for who may be artificial neuron nowadays. So we've done a lot of great work in vision and human vision, computer vision. And you mentioned the problem of human vision is really as difficult as the problem of general intelligence and maybe that connects to the cortex discussion. Can you describe the human visual cortex and how the humans begin to understand the world through the raw sensory information that what's, uh, for folks enough familiar, especially in on the computer vision side, we don't often actually take a step back except saying what the sentence or two that one is inspired by the other w w what is it that we know about the human visual cortex. That's interesting.

Speaker 2:          00:28:40       So we know quite a bit at that same time we don't know about, but the bit we know, you know, in a, in a sense we know a lot of the details and um, and men we don't know. And uh, we know a lot of the top level, um, the answer to top level question, but we don't know some basic ones even in terms of general neuroscience, forgetting vision, you know, why do we sleep? It's such a basic question and we really don't have an answer.

Speaker 1:          00:29:14       Do you think, so taking a step back on that, so sleep for example, it's fascinating. Do you think that's a neuroscience question? Or if we talk about abstractions, what do you think is an interesting way to study intelligence or most effective on the levels of abstraction as a chemicals and biological is electrophysical mathematical as you've done a lot of excellent work and not side. Which uh, psychology, sort of like a, which level abstraction do

Speaker 2:          00:29:42       you think in terms of levels of abstraction? I think we need all of them. It's when you know, it's like if you ask me what does it mean to understand the computer, that's much simpler. But in a computer I could say, well I understand how to use PowerPoint. That's my level of understanding a computer. It's, it has a reasonable, you know, it gives me some power to produce lights and beautiful slides and now somebody else, he says, well I know all of the transistor work that are inside the computer. I can write the equation for, you know, transistors and diodes and silk. It's a logical circuits and I can ask this guy, do you know how to operate PowerPoint? No idea. So do you think if we discovered computers locking amongst us full of these transistors that are also operating under windows and have PowerPoint, do you think it's the digging in a little bit more, how useful is it to understand the transistor in order to be able to understand PowerPoint and these higher level at a good intelligent, fussy?

Speaker 2:          00:31:00       So I think in the case of computers, because they were made by engineers by as these different level of understanding, rather separate on purpose, they are separate modules so that the engineer that designed the silicate for the chiefs does not need to know what a PPO is inside PowerPoint and somebody you can write to the software translating from one to the end to the other. So in that case, I don't think understanding the transistor help you understand PowerPoint or very lethal. Um, if you want to understand the computer, these question, you know, I would say you have to understanding a different levels if you really want to build it.

Speaker 2:          00:31:51       But, uh, but for the brain, I think this levels of understanding, so the algorithms, which kind of competition, you know, the equivalent of PowerPoint and the silk, it's, you know, the transistors, I think they are much more intertwined with each other. That is not, you know, in neatly a level of the software separate from the hardware. And so that's why I think in the case of the brain, the problem is more difficult to more than four computers requires the interaction, the collaboration between different types of expertise. That's a big, the brain is a big car mass that you can't just and disentangle, uh, like level Ken. But his is much more difficult and it's not, uh, know. It's not completely obvious. And as I said, I think he's one of the, if you think he's the greatest problem in science. So I think it's, it's fair that

Speaker 1:          00:32:51       it's difficult. It's a difficult one that said, you do talk about composition and why it might be useful. And when you discuss why these new neural networks in artificial or biological sense learn anything, you talk about composition anally. See there's a sense that nature can be disentangled our proper, uh, well all aspects of our cognition could be disentangled a little bit to some degree. So why do you think, what, first of all, how do you see composition malty and why do you think it exists at all in nature? I spoke about the,

Speaker 2:          00:33:34       I use the, the term composition when we look at deep neural networks, multi layers and trying to understand when and why they are more powerful than a more classical one layer networks, lakes linear classifier, [inaudible] machines, so called. Um, and what we found is that in terms of approximating or learning or representing a function, Eh, a mapping from an input to an output, like from an image to the label in the image. Um, if this function as a particular structure, then deep networks are much more powerful than shallow network to approximate the underlying function. And their particular structure is a structure of composition. Reality. If the function is made up of functions or functions, so that you need to look on when you are interpreting an image, classifying an image, you don't need to look at all pixels at once, but you can compute something from a small groups of pixels and then you can compute something on the output of this local computation and so on, which is similar to what you do. And you read the sentence, you don't need to read the first and the last letter, but you can read syllables combined them in words, combined their words in sentences. So this is this kind of structure.

Speaker 1:          00:35:21       So that's as part of the discussion of why deep neural networks may be more effective than the shallow methods. And is your sense for most things we can use neural networks for those problems are going to be compositional in nature, like a like language, like vision. How far can we get in this kind of, right. So Hazel, most philosophy, well let's go there.

Speaker 2:          00:35:53       Yeah, let's go there. So friend of mine, Max Tegmark,

Speaker 1:          00:35:57       who is a physicist at Mit, I've talked to him on this thing. Yeah. And he disagrees with you right a little bit.

Speaker 2:          00:36:05       You know, it we agree on most, but the conclusion is a bit different. He, he, his conclusion is that for images, for instance, the compositional structure of this function that we have to learn or to solve these problems comes from physics, comes from the fact that you have local interactions in physics between atoms and other items between particle of matter and other particles between planets and other planets, between stars and other. It's all local. Yeah. Um, and that's true. Um, but you could push this argument a bit farther. Um, and not this argument actually, you could argue that, um, you know, maybe that's part of the true, but maybe what happens is kind of the opposite is that our brain is wired up as a deep network so it can learn, understand, solve problems that have this compositional structure and cannot do it, cannot solve problems that don't have this composition as traction. So the problem is who we are a customer too. We think about, we test our algorithms on our, this composition instruction because our brain is made up.

Speaker 1:          00:37:42       And that's in a sense, an evolutionary perspective that we've, so the, the ones that didn't have, uh, there weren't dealing with a compositional nature of reality, uh, died off. Yeah. It could be maybe the reason

Speaker 2:          00:38:00       why we have this local connectivity in the brain, like simple cells in cortex looking on in this small part of the image, each one of them and another says looking at the small number of this simple cells and so on. The reason for this may be purely that was difficult to grow longer range of connectivity. So supposedly it's, you know, for biology it's possible to grow short range connectivity but not longer. And because there is a limited number of long range and so you have it, this, this limitation from the biology and this means you build a deep convolutional neck. This will be something that deep convolutional network, and this is great for solving certain class of problems. These are the ones we are, we find easy and important for our life. And yes, they were enough for us to survive.

Speaker 1:          00:39:07       And uh, and you can start a successful business on solving those problems, right? The Mobileye driving as a compositional problem. So on the, on the learning tasks, I mean we don't know much about how the brain learns in terms of optimization, but uh, so the thing that's sick Cassick gradient descent is what artificial neural networks use for the most part to, uh, adjust the parameters in such a way that it's able to deal based on the label data, it's able to solve the problem. So what's your intuition about why it works at all? How hard of a problem it is to optimize in your own network, artificial neuron that work? Is there other alternatives? Yeah, just in general, your intuitions behind this very simplistic algorithm that seems to do pretty good. Surprising.

Speaker 2:          00:40:06       Yes. So I find neuroscience, the architecture of Cortex is really similar to the architecture of deep networks. So there is a nice correspondence there between the biology and this kind of local connectivity heirarchical um, architecture. The stochastic gradient descent, as you said, is, um, it's a very simple technique. It seems pretty unlikely that biology could do that from, from what we know right now about cortex and neurons and signups is, um, so it's a big question open whether there are other optimization learning algorithms that can replace stochastic gradient descent. And My, my guess is yes, but nobody has found yet a real answer. I mean people are trying, still trying and there are some interesting ideas.

Speaker 2:          00:41:18       The fact that um, stochastic gradient descent is so successful, this has become clear is not so mysterious. And the reason is that, um, it's an interesting fact that you know, is a change in a sense in how people think about statistics and, and this is the following is that typically when you had data and you had say a model with parameters, you are trying to fit the model to the data, you know, to fit the parameters. Typically the kind of, um, kind of a crowd wisdom type Ida was you should have at least a, you know, twice the number of data than the number of parameters. Um, maybe 10 times is better. Now, the way you train the neural net or this is, is that a, have they have 10 or a hundred times more parameters than date. Exactly the opposite and which, you know, it has been one of the puzzles about the neuron NATO's how can you get something that really works when you have so much freedom in a scene on that a little Derek in general by somehow, right, exactly.

Speaker 2:          00:42:44       Do you think this, the stochastic nature of it is essential? The randomness. So I think we have some initial understanding why this happens. But um, one nice side effect of having this over parametrization more parameters than data is that when you look for the Minima of a loss, functional, extra stochastic gradient descent is doing, um, you'll find, I, I made some calculations based on some older basic theory move Algebra called the bizarre theory him. And that gives you an, a, an estimate of the number of solution of a system of polynomial equation. Anyway, the bottom line is that there are probably more minima for a typical deep networks. Um, then atoms in the universe. Just to say that I lost because of the over parametrization more global minimum zero minimum good meaning. So it's not mobile in their life. Yeah, a lot of them. So we have a lot of solutions so it's not so surprising that you can find them relatively is, and this is because of the overall parameters, ish.

Speaker 2:          00:44:04       They all PR parameterization sprinkles that entire space for solutions that pretty good. So surprising. It is like, you know, if you have a system of linear equation and you have more unknowns than equations, then you have, we know you have an infinite number of solutions and the, the question is to pick one that's another story, but have an infinite number of solutions so that a lot of, of value of euro knowns that satisfied the equation. But it's possible that there's a lot of those solutions that aren't very good. Uh, what's surprising is it and why can you pick one that generalizes? While that's a separate question, we'd support it. Dancers. Yep. One one, a theorem that people like to talk about that kind of inspires imagination of the power in your networks is the universality a university approximation there that you can approximate any computable function which just a finite number of neurons in a single hidden layer.

Speaker 2:          00:45:04       Do you find this theorem one surprising? Do you find it useful, interesting, inspiring? No, they these who are now, you know, I never found it very surprising. It was known since the atcs since I entered the field because it's basically the same as via stress theory, which says that that can approximate any continuous function with a polynomial of sufficiently with a sufficient number of terms or norm news. Yeah, it's basically the same and the proves a very similar, so your intuition was there was never any doubt that that works in theory could get, I'd be very strong. Approximately the question, the interesting question is that if this theory says you can approximate fine, but when you ask how many neurons for instance, or in the case of Chordoma Khomeini monomials, I need to get a good approximation.

Speaker 2:          00:46:11       Then it turns out that that depends on the dimensionality of your function, how many variables you have, but it depends on the dimensionality of your functioning in a bad way. It's footings. And suppose you want a narrower, which is no worse than 10% in your approximation and come up with a net or the proximity or function within 10%. Then it turns out that the number of units you need are in the order of 10 to the dementia. Now deep how many variables? So if you have, you know, two variables is the steward, you have hundred units and okay, but if you have say 200 by 200 pixel image is now this is, you know, 40,000, whatever. And we can go to the size of the universe pretty quickly. Yeah. EXAC 10 to the 40,000 or something. And so this is called the curse of dimensionality, not, you know, quite appropriately.

Speaker 2:          00:47:22       And the hope is with the extra layers, you can, uh, remove the curse. What we proved is that tissue have deep layers on heirarchical architecture, don't them with a local connectivity of the type of convolutional deep learning. And if you're dealing with a function that has this kind of hierarchical architecture, then you avoid completely the curse. You spoken a lot about supervised deep learning. Yeah. Uh, what are your thoughts, hopes, views on the challenges of unsupervised learning, the, with gans with a generative adversarial networks. Do you see those as distinct, the, the power of gans this, those as distinct from supervised methods in your networks? Are they, are they all in the same representation? Ballpark Ganz is one way to get a estimation of a probability densities, which is somewhat new way people have not done before. I, I don't know whether I'm, the suit really play an important role in intelligence or, um, it's, it's interesting.

Speaker 2:          00:48:43       I'm, I'm less enthusiastic about it to many people in the field. I have the feeling that many people in the field, uh, I'm really impressed by the ability to have producing realistic looking images in this generic active way, which describes the popularity and the methods. But you're saying that while that's exciting and called to look at it may not be the tool that's useful for four. So you described the kind of beautifully current supervised methods go and infinity in terms of number of labeled points and we really have to figure out how to go to and to one and you're thinking gans might help but they might not be the right I don't think in for that problem, which I really think is important. I think they may have, uh, they certainly have applications for instance in computer graphics. And you know, I did work long ago which was a little bit similar in terms of saying, okay, I have a network and I present images and I can, um, so the input, it's images and output is for instance, the pose of the image.

Speaker 2:          00:49:57       You know, a face a much is smiling is rotated 45 degrees or not. Uh, what about having a net or that I train with the same data set, but now I inverting input and output. Now the input is the pose or the expression in number certain numbers and the output is the image. And they train it. And we did pretty good, interesting results in terms of producing, but very rarely stick looking images was, um, you know, the less sophisticated mechanism, but the output was pretty less than gains, but the output to pretty much have the same quality. So I think for a computer graphics type application yet definitely gains can be quite useful. And not only for that for, but um, for, you know, helping for instance, on this problem and unsupervised example of reducing the number of labeled examples. Um, I think people, uh, it's like they think they can get out more than they put in, you know,

Speaker 1:          00:51:10       it has no free lunches. Right. So what do you think, what's your intuition? Um, uh, how can we slow the growth of ant infinity and supervise and to infinity and supervised learning? So for example, uh, Mobileye has very successfully, I mean, essentially annotated large amounts of data to be able to drive a car. Now, one thought is, so we're trying to teach machines, school of Ai, and we're trying to, so how can we become better teachers? Maybe that's one, one way.

Speaker 2:          00:51:47       No, you got to your, you know what, I like that because when, uh, um, again, one caricature of the history of computer science, you could say is

Speaker 1:          00:52:01       begins with programmers. Expensive. Yep. Continuous labelers cheap. Yep. And the future it would be schools, like we have four kids. Yeah. Currently the labeling methods, we're not selective about which examples we, we teach network. So it's, so I think the focus of making one shut and let networks I learn much faster as often on the architecture side. But how can we pick better examples of the wish to learn? Uh, do you have intuitions about that? Well, that's part of the

Speaker 2:          00:52:41       part of the problem, but the other one is, um, you know, if we look at, um, biology, a reasonable assumption I think is, um, in the same spirit of that I said evolution is opportunistic and has week prior's. You know, the way I think the intelligence of a child, the baby may develop is, um, by bootstrapping.

Speaker 1:          00:53:13       Hmm. Week. Prior's from evolution for instance. Um, in that you can assume that that

Speaker 2:          00:53:24       you have in organisms including human babies builtin some basic machinery to detect motion and relative motion. And the effect that is, you know, we know all insects from fruit flies are other animals. They have this, uh, even in the rightness of it, in the very peripheral part, it's very conserved across species. Something that evolution discovered early. He may be the reason why babies tend to look in the first few days to moving objects and not to not moving on. Now moving objects means okay there are attracted by motion, but motion also means that motion gives automatic segmentation from the background. So because of motion boundaries, you know, either the object is moving or the Aa of the BBC tracking the moving object and the background is moving. Right?

Speaker 1:          00:54:32       Yeah. So just purely on the visual characteristics of the scene, that seems to be like

Speaker 2:          00:54:37       most useful, right? So it's like looking at an object without backgrounds. Tobacco, it's ideal for learning the object. Otherwise it's really difficult because you have so much stuff. So suppose you do this at the beginning of the first weeks. Then after that you can recognize object. Now they're imprinted the number of, even in the background, even without motion.

Speaker 1:          00:55:05       So that's at the, by the way, I just want to ask on a object recognition problem. So there is this being responsive to movement and as you detection essentially, what's the gap between being effectively effective at visually recognizing stuff, detecting word it is and understanding the scene. Is this a huge gap of many layers or is it, are we, is it close?

Speaker 2:          00:55:32       No, I'm thinking that's a huge guy. I'm think present I'll go to, with all the success that we have and the fact that a lot of very useful, I think we are, we are in a golden age for application, so of um, low level vision and low level speech recognition and so on, you know, Alexa and so on, um, that are many more things. So similar level to be done including medical diagnosis and so on. But we are far from what we call understanding of a scene of language, of actions of people. Uh, that is despite the claims that's, I think they're very far or a little bit off. So

Speaker 1:          00:56:19       in popular culture and among many researchers, some of which I spoke with the sewer Russell and Eli Musk, uh, in and out of the AI field, there's a concern about the existential threat of AI and how do you think about this concern in, and is it valuable to think about large scale, longterm unintended consequences of intelligence system?

Speaker 2:          00:56:50       So we tried to build, I always think it's better to worry first, you know, early rather than late. So some worry is good. I'm not against wearing at all. Personally. I think that, um, uh, you know, it will take a long time before there is a real reason to be worried. But as I said, that I think is good to put in place and think about possible safety against, uh, uh, what I find a bit misleading or things like that have been said about people I know, like Elon Musk and uh, what he's Bostrom in particular, northeast first name know nick, Nick Bostrom, right. Um, you know, and the couple of other people that, for instance, um, AI is more than just the nuclear weapons, right? Yeah. I think that's really a problem that can be misleading, right? Because in terms of priority, which should still be more worried about nuclear weapons and uh, you know, people are doing about it and so on. Then yeah.

Speaker 1:          00:58:06       Uh, spoken about Dennis Savvis and yourself seeing, uh, that you think it'd be about a hundred years out before we have s and general intelligence system that's on par with a human being. Do you have any updates for those predictions? What I think he said, he said 28,

Speaker 2:          00:58:25       it said 20, right? This was a couple of years ago. I have not asked him again. So

Speaker 1:          00:58:30       should I, your own prediction, what's your prediction about when you'll be truly surprised? Uh, and what's the confidence interval on that?

Speaker 2:          00:58:42       And I, it's so difficult to predict the future. Even the presence, it's pretty hard to predict, but I would be, as I said, this is completely is, oh, it'd be more like a Rod Brooks, I think he's about 200

Speaker 1:          00:59:01       when we have this kind of Agi system, artificial general intelligence system. You're sitting in a room with, uh, her, him at. Do you think it will be a, the underlying design and such a system is something we'll be able to understand. It will be simple. Do you think be explainable, understandable by us? Yay. Intuition. Again, we're in the realm of philosophy a little bit. What

Speaker 2:          00:59:32       Billy? No, but again, it depends what you really mean for understanding. So I think, uh, you know, we don't, and there's 10 what, how deep networks work. I think we're beginning to have a theory now, but in the case of deep networks, or even in the case of the simple, simpler canon machines or leaner classifier, we really don't understand the individual units also we, but we understand, you know, the computation and the limitations and the properties of it are a, it's similar to manifest things in a we, what does it mean when the stand, how a fusion bomb works. How many of us, you know, many of us understand the basic principle and some of us may understand deeper details.

Speaker 1:          01:00:40       In that sense, understanding is as a community, as a civilization, can we build another copy of it? Okay. And in that sense, do you think there'll be, there'll need to be some evolutionary component where it runs away from our understanding or do you think it could be engineered from the ground up the same way you go from the transistor drop point?

Speaker 2:          01:01:02       It's so many years ago, this was actually, let me see, 40 41 years ago I wrote a paper with a David Marr was um, one of the founding father of computer vision competition. At least I wrote a paper about levels of understanding, which is relate to the question of discussed earlier about understanding power point or this transistors and so on. And uh, uh, you know, in that kind of framework we had the level of the hardware and the top level of the algorithms we did not have learning recently. I updated adding levels and one level I added to those free was learning. So, and you can imagine, you could have a good understanding of how you construct learning machine like we do, but being enabled to describe in detail what the lend me machines we'll discover right now, that would be still a powerful understanding if I can build a learning machine, even if I don't understand in detail every time made it to learn something.

Speaker 1:          01:02:26       Just like our children, if they, if they start listening to a certain type of music, I don't know Miley Cyrus or something. You don't understand why they came to that particular preference, but you understand the learning process. That's very interesting. Yeah. Yup. So, uh, on learning for systems to be part of our world, it has a certain, one of the challenging things that you've spoken about is learning ethics, learning morals, and w w how hard do you think is the problem of, first of all, humans understanding or ethics, what is the origin and the neural on low level of ethics? What is it at the higher level? Is that something that's learnable for machines and your

Speaker 2:          01:03:15       intuition? I think, yeah, it thinks he's learnable, very likely. Um, I, I think I is one of these problems where I think understanding the neuroscience of ethics, you know, people discuss, there is an ethics of neuroscience. Yeah. Yes. You know, how a neuroscientist should, those should not behave, can think of a neurosurgeon and the ethics rules, he has to be a, he, she has to be. But I'm more interested in the neuroscience of it

Speaker 1:          01:03:57       on my mind right now. The neuroscience of ethics. It's very matter. Yeah.

Speaker 2:          01:04:01       And uh, you know, I think that would be important to understand also for being able to, to design machines that have, that are ethical machines in our sense of ethics. And you think there is something in neuroscience, there's patterns, tools in euro size that can help us shed some light on ethics or is it mostly on the psychologist as sociology in which higher level know that he's protect called you. But there is also in the meantime that are, um, that he's evidence if a high of a specific areas of the brain that are involved in certain ethical judgment and not only this, you can stimulate those area with magnetic fields and change the ethical decisions. Yeah. Okay. Wow. So that's a work by a colleague of mine, Rebecca sacs, and there is a sort of searches doing similar work and I think, you know, this is the beginning, but um, ideally at some point we'll have an understanding of how this works and white evolved. Right.

Speaker 1:          01:05:18       The big why question. Yeah. It must have some, some purpose.

Speaker 2:          01:05:21       Yeah. Obviously it has, you know, some social purpose is a probably

Speaker 1:          01:05:30       if neuroscience holds the key to at least eliminate some aspect of ethics, that means it could be a learnable problem. Yup. Exactly. And as we're getting into harder and harder questions, let's go, uh, to the hard problem of consciousness. Yeah. Uh, is this an important problem for us to think about and solve on the engineering of intelligence side of your work? Of our dream?

Speaker 2:          01:05:55       You know, it's clear. So, you know, again, this is a deep problem partly because it's very difficult to define consciousness and the, and that is the debate among a neuroscientist and a about what the consciousness and feed also for us of course, whether consciousness is something that requires flesh and blood so to speak or could be, you know, that we could have silicon devices that are conscious or up to statement. Like everything has some degree of consciousness and some more than others. This is like Giulio Tononi and uh, she would just

Speaker 1:          01:06:54       recently talked to a Christof Koch. Okay. So Christopher was my first graduate student. Do you think it's important to eliminate aspects of consciousness in order to engineer intelligence systems? Do you think an intelligence system would ultimately have cautiousness? Are they too, are they interlinked?

Speaker 2:          01:07:18       You know, most of the people working in artificial intelligence, I think we're done, sir. We don't strictly need consciousness to have an intelligence system.

Speaker 1:          01:07:30       That's sort of the easier question because yeah. Cause it's, it's a very engineering answer to the question. Yes. Facet during tasks on onion consciousness. But if you were to go, you think it's possible that we need to have that kind of self awareness?

Speaker 2:          01:07:47       That's it. We May, yes. So for instance, I, I personally think that when test and machine or a person in a Turing test in an extended Turing testing, I think consciousness is part of what we require in that test. You know, implicitly to say that this is intelligent disagrees. So yes, he does it that despite many other romantic notions he holds, he disagrees with that one. Yes. So, you know, we'd see. Do you think, as a quick question, Ernest Becker, fear of death, do you think mortality and those kinds of things that are important for well, for consciousness and for intelligence, the finiteness of life finiteness of existence or is that just a side effect of evolution, evolutionary side effect that's useful to, uh, for natural selection? Do you think this kind of thing that we're going to, this interview is going to run out of time soon.

Speaker 2:          01:09:05       Our life. We'll run out of time soon. Do you think that's needed to make this conversation good and, and life good? You know, I never fought the boat, isn't that I stink, which, and I think, uh, uh, Steve Jobs in his commencement speech, it's time for our good that, you know, having a finite life was important for, for stimulating achievements. It's on, it was a different, I live everyday like it's your last, yeah. So, and I should the, I don't think strictly you need more vitality for consciousness, but who knows, they seem to go together in our biological systems, right? Yep, Yep. You've mentioned, uh, before and students are associated with, uh, the Alphago and mobilize the big recent success stories in Ai. I think it's captivated the entire world of what AI can do. So what do you think will be the next breakthrough and what's your intuition about the next breakthrough?

Speaker 2:          01:10:13       Of course, I don't know where the next breakthroughs is. A, I think that, um, that he's a good chance, as I said before, the, the next break fruits also be inspired by, you know, neuroscience, but which one? I don't know. And there's, so MIT has this quest for intelligence and there's a few moon shots, which in that spirit to which ones are you excited about? What a, which projects kind of, uh, well, of course I'm excited about one of the moon with, we choose our center for brains, minds and machines. That one which is feeling fully funded by NSF. Um, and it's, uh, it is about visual intelligence. It's an that one is particularly about understanding visual in villages. So the visual cortex and, and visual intelligence in the, of how we look around ourselves and understand the word [inaudible], meaning what, what is going on, how we could, um, go from here to there without hitting obstacles.

Speaker 2:          01:11:31       Um, you know, whether that are other agents, people in the India, these are all things that we perceive very quickly. And um, and it's something actually quite close to being conscious. Not Quite, but you know, there is this interesting experiment that was run at Google x, which is in a sense is just, Eh, virtual reality experiment. But in which the had a subject sitting in a chair with the goggles, like calculus and so on, earphones. And they were seeing through the eyes of our whole boat nearby two cameras, microphones for a CV. So their sensory system was there and the impression of all the subject very strong, they could not shake it off was that they were where the robot wars, they could look at themselves from the robot and steel few day where they were, where the robot is still looking at their body, their self worth had moved.

Speaker 1:          01:12:48       Some aspect of seeing, understanding has to have ability to place yourself, uh, have a self awareness about your position in the world and what the world is, right? So yeah, so we may have to solve the hard problem of consciousness to solve them on their way, but it's quite, quite a moonshot eyes. So you've been an advisor to some incredible minds, including Dennis, a Sabas, Christof Koch. I'm not shy. Schwab, like you said, all went on to become seminal figures in their respective fields. From your own success as a researcher and from perspective as a mentor of these researchers, having guided them in the way of advice, what does it take to be successful in science and engineering careers? Whether you're talking to somebody in their teens, twenties and thirties, what does that path look like?

Speaker 2:          01:13:48       It's curiosity and having fun and I think he's important. Also having fun with other curious minds. It's the people who surround with too. So yeah. Fun. And curiosity is there

Speaker 1:          01:14:08       mentioned Steve Jobs, is there also underlying ambition

Speaker 2:          01:14:13       that's unique that you saw or is it really does boil down to insatiable curiosity and fun when of course, you know, it's been cooked. Curious in a active and ambitious way. Yes, the um, definitely but I think sometime mean in science and that are friends of mine like this, um, you know, that are some of the scientists like to work by themselves and kind of communicate, um, only when they completed their work or discover something. Um, I think I always found that the, the actual process of, uh, you know, discovering something is more fun if it's together with other intelligent and curious and fun people. So he see the fun in that process. The side effect of that process will be that you'll actually end up discovering something. Yes. So as a, if lad many incredible efforts here, what's the secret to being a good advisor, mentor, leader in a research setting?

Speaker 2:          01:15:28       As a similar spirit or, yeah. What, what, what advice could you give to people, Young Faculty and so on? It's partly repeating what I said about an environment that should be friendly and fun and ambitious and uh, you know, I think I learned a lot from some of my advisors and friends and some would have physicists and the, that it was, for instance, this, um, behavior that was encouraged of when somebody comes with a new idea in the group, you're, unless he's already stupid, but you are always enthusiastic and then, and the all enthusiastic for a few minutes, for a few hours. Then you start, you know, asking critical you a few questions. I tasted this, but this is a process that is, I think is very, very good. This, you have to be enthusiastic. Sometime people are very critical from the beginning. That's not, yes, you have to give it a chance to see, to grow that sad.

Speaker 2:          01:16:39       It was some of your ideas that you're quite revolutionary. So there's eye witness, especially in the human vision side and neuroscience side. There can be some pretty heated arguments. Um, do you enjoy these? Does that a part of science and that could uh, yeah, academic pursuits that you enjoy, is it, is that something that happens in your group as well? Uh, yeah, absolutely. I also spent some time in Germany. Again, there is this tradition in which people, uh, more forthright, less kind than here. Yeah. So you know, in the u s I knew, right. A bad letter, you still say this guy is nice know. Yes. So,

Speaker 1:          01:17:26       yeah, here in America is degrees of Nice. It's all just degrees of Nicea. Right?

Speaker 2:          01:17:31       Right. So as long as this does not become personal and it's really like, you know, the football game with his rules. That's great.

Speaker 1:          01:17:44       It's fun. So if you some off on yourself in a position to ask one question of an oracle, like a genie, maybe a God, whoa. And you're guaranteed to get a clear answer, what kind of question would you ask? What would be the question you would ask

Speaker 2:          01:18:04       in the spirit of our discussion? It could be how could be they become 10 times more intelligent.

Speaker 1:          01:18:11       And so, but see, you only get a clear, short answer. So do you think there's a clear short answer to that? No. And that's the answer you'll get. Okay. So you've mentioned a flowers of uh, Elgar not oh yeah. As a story that inspires you and you in your childhood as this a story of a mouse and human achieving genius level intelligence and then understanding what was happening while slowly becoming not intelligent again in this tragedy of gaining intelligence and losing intelligence. Do you think in that spirit and that story, do you think intelligence is a gift or a curse from the perspective of happiness and meaning of life? You, you tried to create intelligence system that understands the universe, but on an individual level, the meaning of life? Do you think intelligence is a gift?

Speaker 2:          01:19:10       That's a good question. I don't know.

Speaker 1:          01:19:22       As one of the, as one people consider the smartest people in the world in some, in some dimension, at the very least. Uh, what do you think?

Speaker 2:          01:19:34       I don't know. He may be invariant to intelligence. Happiness would be nice if it were.

Speaker 1:          01:19:43       That's the hope. Yeah. You can be smart and happy and clueless. I'm happy. Yeah. As always on the discussion or the meaning of life is probably a good place to end. Tommaso thank you so much for talking today. This was great.