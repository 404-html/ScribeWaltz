Speaker 1:          00:00:00       The following is a conversation with Juergen Schmidhuber. He's the CO director of at [inaudible] Swiss ai lab and a cocreator of long short term memory networks. Lsts are used in billions of devices today for speech recognition, translation and much more over 30 years. He has proposed a lot of interesting out of the box ideas, a metal learning adversarial networks, computer vision, and even a formal theory of quote, creativity, curiosity and fun. This conversation is part of the mit course and artificial general intelligence and the artificial intelligence podcast. If you enjoy subscribe on Youtube, itunes or simply connect with me on twitter at [inaudible] Friedman, spelled f, r I. D. And now here's my conversation with Juergen Schmidhuber early on you dreamed of AI systems that self improve cursively when was that dream born

Speaker 2:          00:01:01       man and was a baby now has not true when I was a teenager.

Speaker 1:          00:01:06       And what was the catalyst for that birth? What was the thing that first inspired you

Speaker 2:          00:01:13       when it wasn't? Why I'm, I was thinking about what to do in my life and then I thought the most exciting thing as to soul, the riddles, the universe. And, and that means you have to become a physicist. However, then I realized that that is something, even grandma, you can't try to build a machine that isn't really a machine any longer. That learns to become a much better physicist then I could ever hope to be. And that's how I thought. Maybe I can multiply my tiny little bit of creativity and to engineer

Speaker 1:          00:01:53       team, but ultimately that creativity will be multiplied to understand the universe around us. That's, that's the, the curiosity for that mystery that that drove you.

Speaker 2:          00:02:05       Yes. Uh, so if you can build a machine that lance to solve more and more complex problems, I'm more and more general problem solver, then you basically have solved all the problems, at least all the solvable problems.

Speaker 1:          00:02:26       So how do you think, what is the mechanism for that kind of general solver look like? Obviously we don't quite yet have one or know how to build one boy of ideas. And you have had throughout your career several ideas about it. So how do you think about that mechanism?

Speaker 2:          00:02:43       So in the 80s, I thought about how to build this machine that lance was so of all these columns and I cannot solve myself. And I thought it is clear that it has to be a machine that not only learns too solve this problem here and this problem here, but it also has to learn to improve the learning algorithm itself, right? So it has to have the learning algorithm and um, representation that allows it to inspect it and modify it so that it can come up with a better learning algorithm. So when I called that and metal learning, learning to loan and recursive self improvement, that is really the pinnacle of that where you then not only you learn, um, how to improve on that problem and on that, but you also improve the way the machine improves and you also improve the way it improves the way and improves itself. And that was my 1987 diploma thesis, which was all about that hierarchy of metal rnrs that have no computational limits except for the well known limits that Google identified in 1931 and a four. The limits of physics

Speaker 1:          00:04:06       in the recent years matter learning has gained popularity in a, in a specific kind of form. You've talked about how that's not really metal learning with, with neural networks, that's more basic transfer learning. Can you talk about the difference between the big general metal learning and a more narrow sense of metal learning the way it's used today, the waste talked about today. Let's take,

Speaker 2:          00:04:31       what's the example of a deep neural network that has a learn to classify images and maybe you have trained that network on 100 different databases of images and now a new database comes along and you want to quickly learn the new thing as well. So when a simpler way of doing that as you take the network, which already knows 100 types of databases and then you would just take the top layer of that and you retrain that, uh, using the new label data that you have in the new image database. And then it turns out that it really, really quickly kind of learn that to one shot basically, because from the first 100 datasets, it already has learned so much about, about computer vision that it can reuse that. And that is then almost good enough to solve the new task except you need a little bit of adjustment on the top.

Speaker 2:          00:05:38       So that is transfer learning and it has been done. And principal for many decades, people have done similar things with decades met aligning. True mental learning is about having the learning algorithm itself open to introspection by the system that is using it and also open to modification such that the lighting system has an opportunity to modify any part of the learning algorithm and then evaluate the consequences of that modification and then learn from that to create a better learning algorithm and so on. Recursively so that's a very different animal where you are opening the space off possible learning algorithms to the learning system itself.

Speaker 1:          00:06:35       Right. So you've, uh, like in the 2004 paper he described a gate on machines and programs that were right themselves. Yeah. Right. Philosophically, and even in your paper mathematically, these are really compelling ideas. But practically do you see the self referential programs being successful in the near term to having an impact where sort of a demonstrates to the world that this direction is a

Speaker 2:          00:07:06       is a good one to pursue in the near term? Yes. We had these two different types of fundamental research, how to build a universal problem solver. One basically exploiting poof such and things like that that you need to come up with a some topically optimal theoretically optimal self improvers and problem solvers. However one has to admit that. So it was this proof. So ads comes in an additive constant, an overhead and additive overhead that vantages in comparison to uh, what you have to do to solve large problems. However, for many of the small problems that we want to solve in our everyday life, we cannot ignore this constant overhead. And that's why we also have been doing other things, non universal things such as recurrent neural networks, which are trained by gradient descent and local search techniques which aren't universally adored, which aren't provably optimal at all.

Speaker 2:          00:08:21       Like the other stuff that we did but which are much more practical as long as we only want to solve the small problems that we are typically trying to solve in this environment here. Yeah, so it's a universal problem solvers and like the Google machine but also marcus hooters, fastest way of solving all possible problems, which he developed around 2002 in my lab. They are associated with these constant overheads for proof search, which guarantees that the that you're doing is optimum, for example, that is this fastest way off solving all problems with a computable solution, which is due to a macros macro Ceuta and uh, um, to explain what's going on there. Let's take traveling salesmen problems with traveling salesman problems. You have a number of cities in cities and you try to find the shortest path through all these cities without visiting any city twice.

Speaker 2:          00:09:29       And nobody knows the fastest way of solving traveling salesman problems. Tsp is, but let's assume there is a method of solving them within end to the five operations where n is the number of cities. Then the universal method of Macros is going to solve the same traveling salesman problem. Also within enter the five steps plus a couple of one plus a constant number of steps that you need for the proofs archer, which you need to show that this particular class of problems that traveling salesman, salesman problems can be solved within a certain time bound, um, within Oda into the five steps basically. And there's a additive constant doesn't care for and which means as end is getting larger and larger as you have more and more cities, the constant overhead pales in comparison and that means that almost are large problems are solved in the best possible way of a today. We already have a universal problem solver like that. However, it's not practical because the overhead, the constant overhead is so large that for the smaller kinds of problems that you want to solve in this level biosphere,

Speaker 1:          00:11:04       by the way, when you say small, you're talking about things that fall within the constraints of our computational systems that they can, they can seem quite large joints, mere humans,

Speaker 2:          00:11:14       right? That's right. Yeah. So they seem large and even unsolvable in a practical sense today, but they are still small compared to almost all problems because almost all problems are large problems which are much larger than any constant.

Speaker 1:          00:11:32       Do you find it useful as a person who is dreamed of creating a general learning system, has worked on creating one is done a lot of interesting ideas there to think about

Speaker 2:          00:11:44       p

Speaker 1:          00:11:45       versus np, this a formalization of how hard problems are, how they scale this kind of case analysis type of thinking. Do you find that useful or is it only just a mathematical, it's a set of mathematical techniques to give you intuition about what's good and bad.

Speaker 2:          00:12:05       Hmm. So p versus NP, that's super interesting from a theoretical point of view and in fact as you thinking about that problem, you can also get inspiration for better practical problems. All of us, on the other hand, we have to admit that at the moment as the best practical problems, all of us for all kinds of problems that we are now solving through what is called ai at the moment. No, not the kind that is inspired by these questions. Yeah, no, they have, you are using, um, general purpose computer such as recurrent neural networks, but we have a such technique which is just local search, great in descend to try to find a program that is running on the [inaudible] such that it can solve some interesting problems such as speech recognition or machine translation and something like that. And there is very little theory behind the best solutions that we have at the moment

Speaker 1:          00:13:09       that can do that. Do you think that needs to change? Do you think that will change or can we go, can we create a general intelligence systems without ever really proving that that system was intelligent and some kind of mathematical way solving machine translation perfectly or something like that within some kind of syntactic definition of a language? Or can we just be super impressed by the thing working extremely well and that's sufficient?

Speaker 2:          00:13:35       There's an old saying and I don't know who brought it up first, which says there's nothing more practical than a good theory and um, yeah, and a good theory off problem solving.

Speaker 3:          00:13:52       Okay.

Speaker 2:          00:13:52       Under limited resources like he in this universe or on this little planet has to take into account these limited resources. And so probably that is locking a theory which is related to what we already have. Fees isn't tightly optimal problems almost, which, which tells us what we need. In addition to that to come up with a practically optimal problems over psalm, I believe we will have something like that and maybe just a few little tiny twists unnecessary to, to change what we already have to come up with that as well. As long as we don't have that, we admit that we are taking sub optimal ways and recurrent neural network isn't long short term memory for equipped with local search techniques. And we are happy that it works better as in any competing methods. But um, that doesn't mean that we would be, think we had done.

Speaker 1:          00:15:00       You've said that an Agi system will ultimately be a simple one, a general intelligence system, and ultimately be as simple one, maybe a pseudocode have a few lines, we'll be able to describe it. Can you talk through your intuition behind this idea, why you feel that us as core intelligence is a simple

Speaker 2:          00:15:24       algorithm experience tells us that the stuff that works best as really simple. So the [inaudible] ugly optimal ways of solving problems if you look at them and just a few lines of code, it's really true, although they ask these amazing property is just a few lines of code. Then the most promising and most useful practical things maybe don't have this proof of optimality associated with them. However they are. So just a few lines of code. The most successful and recurrent neural networks you can write them down and five lions up pseudo code.

Speaker 1:          00:16:08       That's a beautiful, almost poetic idea. But what you're

Speaker 2:          00:16:14       okay

Speaker 1:          00:16:14       describing there is this, the lines of pseudocode are sitting on top of layers and layers of abstractions in a sense. So you're saying at the very top, it'll be a beautifully written sort of a algorithm, but do you think that there's many layers of abstraction we have to first learn to construct?

Speaker 2:          00:16:37       Of course we are building on all these um, great obstructions that people have invented over the millennia. Such as Matrix multiplications and roll numbers and basic arithmetic x and Calculus and durations of um, error functions and derivatives off error functions and stuff like that. So without that language, that greatly simplifies our way of thinking about these problems. We couldn't do anything. So in that sentence, as always, we are standing on the shoulders of the giants who in the past, um, simply fired the problem off problem solving. So much that now we have a chance to do the final step

Speaker 1:          00:17:29       to the final step will be as simple one. If we, if we take a step back through all of human civilization and just the university chair, uh, how do you think about evolution and what if creating a universe is required to achieve this final step? What if going through very painful, an inefficient process of evolution is needed to come up with this set of abstractions that ultimately to intelligence? Do you think

Speaker 4:          00:17:59       there's a shortcut or do you think we have to create

Speaker 1:          00:18:03       something like our universe in order to create something like human level intelligence?

Speaker 2:          00:18:07       Mm. So far, the only example we have is this one is this universe in which we live. You better, maybe not, but um, yeah, part of this whole process, right?

Speaker 2:          00:18:27       Apparently. So it might be the case that the code that runs the universe Israeli really simple everything points to that possibility because gravity and other basic forces are really simple laws that can be easily described also in just a few lines of code basically. And uh, and then, uh, the use of the events that the apparently random events in the history of the universe, which as far as we know at the moment don't have a compact code, but who knows, maybe somebody and the near future is going to figure it out. Pseudo random generator, which is, um, which is computing, whether it's the measurement of that, um, spin up and down. The thing here is I'm going to be positive or negative

Speaker 1:          00:19:18       underlying quantum mechanics. Do you ultimately think quantum mechanics is a pseudo random number generator all deterministic? There's no randomness scenario. Our universe

Speaker 4:          00:19:30       does God play dice? Okay.

Speaker 2:          00:19:33       A couple of years ago on a famous physicist, quantum physicists, Anton Zeilinger, he wrote an essay in nature and it started more or less like that one aussie fundamental insights, ah, see offset 20th century was that the universe is fundamentally random on the quantum level.

Speaker 5:          00:20:02       Yeah.

Speaker 2:          00:20:02       And that whenever you measure spin up or down or something like that, a new bit of information enters the history. I'll see you on it. And while I was reading that, I was honored the typing, the responds and they had to publish it because it was right that there is no evidence, no physical evidence for that. So there is an alternative explanation, but everything that'd be considered around them is actually the random such as the decimal expansion of Pi 3.141 and so on, which looks around, Huh, but isn't.

Speaker 2:          00:20:44       So Pi is interesting because every three digit sequence, every sequence off three digits, a p is roughly one in a thousand times and every five digit sequence a p has roughly one in 10,000 times. What do you, what you would expect if it was run random. But that's a very short algorithm, a short program that computers, all of that. So it's extremely compressible. And who knows, maybe tomorrow somebody and some Grad student at som goes back over all these data points, better decay and whatever and figures out, oh, it's the second billion digits of Pi or something like that. We don't have any fundamental reason at the moment to believe that this is truly random and not just a deterministic video game. If it was a deterministic video game, it would be much more beautiful because beauty, simplicity and many of the basic laws of the universe like gravity and the other basic forces are very simple.

Speaker 2:          00:21:54       So very short programs can explain what these are doing and um, and it would be awful and ugly. The universe would be ugly. The history of the universe would be ugly if for the extra things, the random seemingly random data points that we get all the time, that we really need a huge number of extra bits to strive all these, um, these extra bits of information. So as long as we don't have evidence that that is no short programs, that computes the entire history of the entire universe, we are as scientists compelled to look further for that shortest program.

Speaker 6:          00:22:43       Your intuition says there exists a shortage, a program that can backtrack to the, to the creation of the universe, the shortest path to the creation. Yes.

Speaker 2:          00:22:54       Including all the um, entanglement things and all the spin up and down measurements that have been taken place, um, since 13.8 billion years ago. And so, yeah, so we don't have a proof that it is a random, we don't have a proof of that it is compressible to a short program. But as long as we don't have that fruit, we are obliged as scientists to keep looking for that simple explanation.

Speaker 6:          00:23:27       Absolutely. So you said simplicity is beautiful or beauties simple. Either one works, but you also work on curiosity, discovery, you know, the romantic notion of randomness, of serendipity, of, of, um, being surprised

Speaker 2:          00:23:46       by things that are about you, kind of in our poetic notion of reality. We think as humans require randomness. So you don't find randomness beautiful. You, you s you find simple determinism. Beautiful. Yeah. Okay. So why, why? Because see, explanation becomes shorter. A universe that is compressible to a short program as much more elegant and much more beautiful than another one which needs an almost infinite number of bits to be described as far as we know.

Speaker 5:          00:24:31       Okay.

Speaker 2:          00:24:31       Many things that are happening in this universe are really simple in terms of um, short programs does that compute gravity and uh, see interaction between elementary particles and so on. So all of that seems to be very, very simple. Every electron seems to reuse the same sub program all the time as it is interacting with other elementary particles. If b now

Speaker 5:          00:25:01       okay,

Speaker 2:          00:25:01       required an extra article, injecting new bits of information all the time for these extra things which are commonly not understood, such as better tk, then, um, the whole

Speaker 2:          00:25:22       description length, awesome data that we can observe the history, I'll say you'll never else would become a much longer and therefore uglier and uglier. Again, simplicities elegant and beautiful. All the history of science has a history of compression progress. Yeah. So you, you've described sort of as we build up of distractions and you've talked about the idea of compression. How do you see this, the history of science, the history of humanity, our civilization and life on earth as some kind of a path towards greater and greater compression? What do you mean by that? How do you think about that? And deeds? He, history of science is a history of compression progress. What does that mean? Hundreds of years ago there was an astronomer who his name was Kepler and he looked at the data points that he got by watching planets move. And then you had all these data points and suddenly you out that he can greatly compress the data by predicting it through an ellipse lawn.

Speaker 2:          00:26:38       So it turns out that all these data points are more or less on ellipsis around sun. And another guy came along whose name was Newton and before him hook and they set the same thing that is making these planets move. Like that is what makes the apples fall down. And uh, also holds form stones and form all kinds of other objects. And some of the many, many of these compressions off these observations became much more compressible because as long as you can predict the next thing, given what you have seen so far, you can compress it. You don't have to store that data extra. This is called predictive coding. And then there was still something wrong with that theory of the universe. And you had deviations from these predictions of the theory. And 300 years later, another guy came along whose name was Einstein and he, um, he was able to explain a way, all these deviations from the predictions are the old theory through a new theory, which was called the general theory of relativity, which at first glance it looks a little bit more complicated and you have to warp space and time.

Speaker 2:          00:28:02       But you can phrase it within one single sentence, which is no matter how fast you accelerate and how fast are hard, you decelerate. And, um, no matter what is the gravity in your local framework, lightspeed always looks the same. And from, from that, you can calculate all the consequences. So it's a very simple thing and that allows you to further compress all the observations because suddenly there are hardly any deviations any longer that you can measure from the predictions of this new theory. And so on of signs is a history of compression progress. You would never arrive immediately at the shortest explanation of the data, but you're making progress. Whenever you are making progress, you have an insight, you will see, oh, first I needed so many bits of information to describe the data, to describe my falling apples, my video, or falling apples. I need so many data now, so many pixels we'll have to be stored.

Speaker 2:          00:29:08       But then suddenly I realize, no, that is a very simple way of predicting the third frame in the video from the first tool. And um, and maybe not every little detail can be predicted, but more or less, most of these orange blogs, blobs that are coming down, they accelerate in the same way, which means that I can greatly compress the video and the amount of compression progress. That is the depths of the insight that you have at that moment. That's the fun that you have, the scientific fun, that fun and that discovery and we can build artificial systems that do the same thing. So measure as a depth off their insights as they are looking at the data which is coming in through their own experiments and we give them a reward. And in terms of getting ward and proportion to this depth of insight w and since they are trying to maximize the rewards they get, they are suddenly motivated to come up with new actions sequences with new experiments that half the property that the data that is coming in as a consequence is experiments has the property that they can learn something about, see a pattern in there which they hadn't seen yet before.

Speaker 6:          00:30:28       So there's an idea of power play. You described a training in general problem solver in this kind of way of looking for the unsolved problems. Can you describe that idea a little further?

Speaker 2:          00:30:40       It's another very simple idea. So normally what you do and computer science you have, you have some guy who gives you a problem and then there is a, a huge search space of potential solution candidates and you somehow try them out. And um, you have more or less sophisticated ways of moving around in that search space until you finally found a solution which you consider a satisfactory. That's what most of computer science is about. Power play just goes one little step further and says, let's not only search for solutions to a given problem, but let such to pass of problems and their solutions where the system itself has the opportunity to phrase its own problem. So we are looking suddenly at pairs of problems and their solutions or modifications off the problem solver that is opposed to generate a solution to that new problem. And, and this additional degree of freedom allows us to build who you are. Systems that are like scientists in the sense that they not only trying to solve and try to find answers to existing questions. No, there are also free to pose their own questions. So if you want to build an artificial scientists, we have to give it that freedom and power play is exactly doing that. So that's, that's a dimension of

Speaker 6:          00:32:21       freedom that's important to have. But how do you, how hard do you think that, how multidimensional and difficult the space of then coming up with your own questions is as, it's one of the things that as human beings we are considered to be, the thing makes us special. The intelligence that makes us special is that brilliant insight. Yeah. That can create something totally new.

Speaker 2:          00:32:47       Yes. So now let's look at the extreme case. Let's look at the set of all possible problems that you can formally this crime, which is infinite, which should be the next problem that a scientist or a power play is going to solve. Well, it should be

Speaker 2:          00:33:12       the easiest problem that goes beyond what you already know. So it should be the simplest problem that the current problems, all of that you have, which can already solve 100 problems that he cannot sold yet by just generalizing. So it has to be new. So it has to require a modification. On the problem solver such that the new problem solver canceled this new thing, but the only problem solve, I cannot do it. And in addition to that, we have to make sure that the problem solver, it doesn't forget any of the previous solutions. Right. And so by definition, power play is now trying to search and this pair and, and, and the set of pairs of problems and problem solve, um, modifications for our combination that, uh, minimize the time to achieve these criteria. So as honest, trying to find the problem, which is easiest to add to the repertoire. So just like grads

Speaker 6:          00:34:15       Zudans and academics and researchers can spend their whole career in a local minima hmm. Stuck trying to, uh, come up with interesting questions, but ultimately doing very little. Yeah.

Speaker 2:          00:34:27       Do you think it's easy?

Speaker 6:          00:34:29       Well, in this approach of looking for the simplest, unsolvable problem to get stuck in a local minima is not never really discovering

Speaker 2:          00:34:38       mew,

Speaker 6:          00:34:39       uh, you know, really jumping outside of the hunter problems that you've already solved in a genuine creative way.

Speaker 3:          00:34:47       Okay.

Speaker 2:          00:34:47       No, because that's the nature of power play that it's always trying to break. It's crown generalization abilities by coming up with a new problem, which is beyond the current horizon. Just shifting the horizon, I'm knowledge a little bit out there. Breaking the existing rules such as a new thing becomes solvable, but it wasn't solvable by the old thing. So like adding a new axiom, um, like what Google did when he came up with these new sentences, new he runs that didn't have a proof in the former system, which means you can add them to the repertoire. Yeah. Hoping that, that they, um, are not going to damage the consistency also whole thing.

Speaker 6:          00:35:35       So in the, uh, paper with the amazing title, formal theory of creativity, fun and intrinsic motivation, you talk about discovery as intrinsic reward. So if you view human as intelligent agents, what do you think is the purpose and meaning of life for us humans is, you've talked about this discovery. I do you see humans as an instance of power play agents?

Speaker 2:          00:36:04       Yeah. So humans are curious and um, that means they behave like scientists. Not only the official scientists, but even the baby is behave like scientists. And they play around with that toy is to figure out how the world works and how it is responding to that actions. And that's how they learned about gravity and everything. And Yeah, in 1995 we had the first systems like that. We just try to, to play around with the environment and come up with situations that go beyond what they knew at that time and then get a reward for creating these situations and then becoming, um, more general problems, all of us and being able to understand more of the wild. So yeah, I think in principle that, um, that, that curiosity, um,

Speaker 6:          00:36:57       strategy

Speaker 2:          00:36:59       or sophist more sophisticated versions of what a justice crime they are, what we have built in as well because evolution discovered that that's a good way of exploring the unknown wild. And the guy who explores the unknown wild has a higher chance of solving problems that he needs to survive in this world. On the other hand,

Speaker 6:          00:37:21       yeah,

Speaker 2:          00:37:21       those guys who were too curious, they were weeded out as well. So you have to find this tradeoff evolution and found a certain trade off. Apparently in our society there is a certain percentage of extremely expansive guys and it doesn't matter if they die because many of the others are more conservative. And um, and so yeah, it would be surprising to me if I'm

Speaker 6:          00:37:49       okay

Speaker 2:          00:37:49       if that principal of artificial curiosity wouldn't be present in almost exactly the same form here

Speaker 6:          00:37:58       in our brains. So you're a bit of a musician and an artist. So continuing on this topic of creativity, what do you think is the role of creativity and intelligence? So you've kind of implied that it's essential for intelligence if you think of intelligence as a problem solving system is ability to solve problems. But do you think it's essential, this idea of creativity?

Speaker 2:          00:38:28       We never have a program, a sub program that is called creativity or something. It's just a effect of what our problems all of us do. They are searching a space of problems. Oh, I space off a cannon dates off solution candidates until they hopefully find a solution to a given problem. But then there are these two types of creativity and uh, both of them are now present in our machines. Um, the first one has been around for a long time, which is human gives problem to machine, machine, tries to find a solution to that. And this has been happening for many decades and for many decades machines have found creative solutions to interesting problems where humans were not aware of these, um, particularly in creative solutions but then appreciate it that the machine found that. The second is the pure creativity that I would call it what I just mentioned.

Speaker 2:          00:39:25       I would call the applied creativity like applied art where somebody tells you now make a nice picture of off this pope and you will get money for that. Okay, so here's the artist and he makes a convincing picture as the pope and the pope lakes it and gives them the money. And then there is the pure creative creativity, which is more like the power play and the artificial curiosity thing where you have the freedom to select your own problem. Like a scientist who defines his on question two study. And so that is the pure creativity, if you will, as opposed to the applied creativity, which serves another

Speaker 6:          00:40:14       in that distinction, there's almost echoes of narrow ai versus generally I say this kind of constrained painting or pope seems like the, the approaches of what people are calling narrow ai and pure creativity seems to be okay. Maybe I'm just biased as a human, but it seems to be an essential element of human level intelligence. Is that what you're implying?

Speaker 2:          00:40:44       To a degree, if you zoom back a little bit and you're just look at 'em gentlemen problem solving machine, which is trying to solve arbitrary problems, then this machine will figure out in the course are solving problems that it's good to be curious. So all of what I said just now about this pre one curiosity and there's Seville to invent new problems that the system doesn't know how to solve yet should be just a byproduct of the general signage. However, apparently evolution has built it into us. The cards are turned out to be so successful. Uh, uh, pre wiring, uh, buyers are very successful exploratory buyers that, um, that'd be a born with.

Speaker 6:          00:41:33       And you've also said that consciousness in the same kind of way may be a byproduct of, of problem solving. Do you think, do you find this an interesting byproduct? Do you think is a useful byproduct? What are your thoughts on consciousness in general? Or is it simply a byproduct of greater and greater capabilities of problem solving that's, uh, that's similar to creativity in that sense?

Speaker 2:          00:42:00       Yeah. We never have a procedure called consciousness and now let machines, however we get as side effects of what these machines are doing, things that seem to be closely related to what people can and consciousness. So for example, in 1990, we had simple systems which were basically, um, recurrent networks and therefore university of computers trying to map incoming data into actions that lead to success. Uh, maximizing reward and a given environment always findings a charging station in time whenever the battery is low and negative signals are coming from the battery. Always find the charging station in time without bumping against painful obstacles on the way. So complicated things but very easily motivated. And then, uh, we give these little guys a separate, we can't run a truck, which is just predicting what's happening. If I do, that happened that what will happen as a consequence are these actions that I'm executing and it's just trained on the long and long history of interactions with the wild.

Speaker 2:          00:43:14       So it becomes a predictive model. Lots of wild basically. And therefore also a compressor arsene observations after awhile because whatever you can predict you don't have to store extra. And so compression as a side effect our prediction. And how does this require network compress? Well it's inventing little subprograms little sub natural networks that stand for everything that frequently appears and the environment like bottles and microphones and faces maybe lots of faces in my um, uh, environments or I'm learning to create something like a prototype phase and the new phase comes along and all I have to encode the deviations from the prototype. So it's compressing all the time. The stuff that frequently appears. There's one thing that appears all the time that is present all the time when the agent is interacting with its environment, which is the agent itself. So just for data compression reasons, it is extremely natural for this recurrent network to come up with little sub networks that stand for the properties off the agents, the Hams, you know the, the, the other actuators and all the stuff said you need to better in code the data which is influenced by the actions of the agent.

Speaker 2:          00:44:34       So they're just as a side effect of they are compression during problem solving, you have internal self models now you can use this model of the wand to plan your future and that's what you also have done since 1990 so the recurrent network, which is c controller, which is trying to maximize reward can use this model as a network of the wilds. It says model network Arthur wild predictive model after wilde to plan ahead and say let's not do this action sequence. Let's do this action sequence instead because it leads to more predicted three rewards. And whenever it's waking up, these learners up networks that stand for itself, it's like it's thinking about itself and it's thinking about itself and it's okay exploring mentally the consequences of its own actions. And now you tell me what is still missing

Speaker 6:          00:45:37       missing the next, the the gap to consciousness. Yeah, I, there, there isn't, that's a really beautiful idea that um, you know, if life is a collection of data and in life is a process of compressing that data to act efficiently in that data, you yourself appear very often. So it's useful to a form compressions of yourself and it's a really beautiful formulation or cautiousness is as unnecessary side effect. It's actually quite compelling to me. You've described Rnn ins and developed a Lstm as long short term memory networks that are there a type of recurrent neural networks and they have gotten a lot of success recently. So these are networks that model the temporal aspects in the data to temporal patterns in the data. And you've called them the deepest of the new on that works. Right. So what do you think is the value of depth in the models that we use to learn?

Speaker 2:          00:46:43       Yeah, since you mentioned the long short term memory and the Lstm, um, I have to mention the names off the brilliant students who has of course, of course. Um, first of all, and my first student ever set for Haida who had fundamental insights already and this diploma thesis then Felix [inaudible] had additional important contributions. Alex Grey's a guy from Scotland who, um, is mostly responsible for this CTC algorithm, which is now how often use to, to train the Lstm to do the speech recognition on all the Google, android phones and whatever and CV and so on. So, um, uh, these guys, without these guys, um, I would be nothing. It's a lot of incredible work. What does, now the depth,

Speaker 6:          00:47:30       what is the importance of depth? Well, um, most problems in the real world, uh, deep in the sense that, um, the kind input doesn't tell you all you need to know about the environment. So instead, um, you have to have a memory of what happened in the past and often important pads of that memory I dated. They are pretty old. And so, um, when you're doing speech recognition for example, and somebody says 11, then that's about half a second or something like that, which means it's already a 50 time steps. And another guy or the same guys that says seven. So the ending is the same Evan, but now the system has to see the distinction between seven and 11. And the only way I can see the differences it has to store that, uh, 50 steps ago there was an s or an uber 11 or seven.

Speaker 6:          00:48:34       So there you have already a problem of depth 50, because for each time step you have something like a virtual, a layer in the expanded and evolved version of [inaudible] network, which is doing the speech recognition. So these long time lax, they translate into problem depth and most rotten ones. And this wild I that you're rarely have to look far back in time to understand what is the problem and to solve it. But just like with Lstm, you don't necessarily need to, when you look back in time, remember every aspect, you just need to remember the important aspects.

Speaker 2:          00:49:14       That's fine. It's a network has to learn to put the important stuff and into memory and to ignore the unimportant noise.

Speaker 6:          00:49:23       So, but in that sense, deeper and deeper is better. Or is there a limitation? Is there, I mean Lstm is one of the great examples of architectures that, uh, do something beyond just deeper and deeper networks, this clever mechanisms for filtering data for remembering and forgetting. So do you think that kind of thinking is necessary? If you think about it, Lstm is a leap, a big leap forward over traditional Vanilla rnn. What do you think is the next leap it within this context? So as Sam was a very clever improvement, but lcm still don't have the same kind of ability to see far back in the future in the, in the past as us humans do the credit assignment problem across way back, not just 50 times stuff. So a hundred or a thousand, but millions and billions,

Speaker 2:          00:50:24       not clear. What are the practical limits as the LSTM when it comes to looking back already in 2006, I think we had examples where it not only look back tens or thousands of steps, but really millions of steps and um, who, um, Paris, um, artists in my lap, I think once the first author of a paper where we really was a 2006 or something, had examples where I'd learn to look back for more than 10 million steps. Right? So for most problems I've speech recognition, it's not necessary to look that far back. But the examples where does now, so looking back thing that's rather easy because that has only one past, but there are many possible futures and so our reinforcement learning system, which is trying to maximize its future expected reward and doesn't know yet which of these many possible future should I select give him this one single pass is facing problems that the Lstm by itself cannot solve.

Speaker 2:          00:51:36       So the other Sam is good for coming up with a compact representation of the history. So far. I'll say history and observations and action so far. But now how do you plan in an efficient and good way among all these, how do you select one of these many possible action sequences that are reinforcement learning system has to consider to maximize reward in this unknown future? So again, we have this basic setup where you have one that we cannot work, which gets in the video and the speech and whatever, and it's executing the actions and is trying to maximize reward. So that is no teacher who tells it what to do at which point in time. And then there's the other network, which is just predicting what's going to happen if I do that. And then, and that could be an lstm network and it allows us to look back all the way to make better predictions off the next time step.

Speaker 2:          00:52:41       So essentially, although it's predicting only the next time step and is motivated to learn to put into memory something that happened maybe a million steps ago, because it's important, uh, to memorize that. If you want to predict that at the next time step, the next event, you know, now, um, how can a model of the one, I like that a predictive model of the wild be used by the first guy, it's called it the controller and the model, the controller and the model. How can the model be used by the controller to efficiently select a ma among these many possible futures? So now eve way we had, um, about 30 years ago was let's just is some model last awhile as a stand in, as a simulation, as a wild and millisecond by millisecond. We plan the future and that means we have to roll it out.

Speaker 2:          00:53:35       It's really in detail and it will work only if the model is really good. And it will still be inefficient because we have to look at all these possible futures and there are so many awesome. So instead, what do we do now since 2015 and [inaudible] systems control model systems. If you give as the controller the opportunity to learn by itself, how to use theory, potentially relevant parts of the m of the model and trying to solve new problems more quickly and if it wants to, it can learn to ignore the m and sometimes there's a good idea to ignore the m because it's really bad, it's a bad predictor and this particular, um, situation of life, uh, where the control is currently trying to maximize rewind, however it can also allow them to address and exploit some of the sub programs that came about in the model network through compressing as a data by predicting it. So it now has an opportunity to reuse that code, the algorithmic inflammation in the modern or trying to reduce its own search space search that it can solve a new problem more quickly then without the model

Speaker 6:          00:54:53       compression. So you're ultimately optimistic and excited about the power of our, of reinforcement learning in the context of real systems. Absolutely. Yeah. So you see rl as a potential, having a huge impact beyond just sort of the m part is often develop on supervised learning methods. You see rl as a, uh, for problems of self driving cars or any kind of applied side of robotics. That's the correct, interesting direction for research in your view.

Speaker 2:          00:55:34       I do think so. We have a company called NASCENCE nascence which, um, has applied during placement learning too little audis.

Speaker 6:          00:55:44       There are these

Speaker 2:          00:55:45       where's land to park without a teacher. The same principles where you were stock cars. So these little Audi is, they are small, maybe like that, so much smaller than the real audis, but they have all the sends Aras, uh, that you find in the real audi is you find the cameras that Leanne sends us, they'd go up to 120, 20 kilometers an hour if you, if, if they want to. And, um, and they are pain sensor ass basically and they don't want to bump against obstacles and the Audis and so on as they, um, my salon like little babies to park takes the raw vision input and translate that into actions that lead to successful packing behavior, which is a rewarding thing. And yes, they learned that. We have examples like that and it's only in the beginning, um, know this is just the tip of the iceberg and I believe the next wave of ai is going to be all about that.

Speaker 2:          00:56:45       So at the moment, the current wave of AI is about passive pattern observation and the prediction and um, and that's what you have on your smartphone and what the major companies on the Pacific of Mri using to sell you ads to do marketing. That's the crown, a source of profit in ai. And that's only one or 2% of the wild economy. Him. Yeah. Um, which is big enough to make these companies is pretty much the most valuable companies in the hand. But there's a much, much bigger practice, enough the economy going to be affected by the next wave, which is really about machines that shape the data through it was our own axons. Think simulation is ultimately the biggest way that that though those methods will be successful in the next 10, 20 years. We're not talking about a hundred years from now. We're talking about sort of the near term impact of rl.

Speaker 2:          00:57:42       Do you think really good simulation is required or is there other techniques like imitation, learning, you know, observing other humans operating in the real world, where, where do you think the success will come from? So at the moment we have a tendency of using physics simulations to learn behavior for machines that, um, learn to solve problems that humans also do not know how to solve. However, this is not the future because the future is and what little babies do or they don't use a physics engine to simulate the wild. No, they learn a predictive model of the wild, which, um, maybe sometimes it's wrong in many ways, but captures all kinds of important abstract, high level predictions which are really important to be successful. And, um, and that's what is, what's the future 30 years ago when he started that type of free sites. But it's still the future and now we know much better how to go there, um, uh, to, to move that, to move forward and to really make work in systems based on that where you have a learning model, lots of odd and model off the wild that learns to predict what's going to happen if I do that and that.

Speaker 2:          00:59:01       And then, uh, the controller uses and model to more quickly learn successful action sequences. And then of course, always this curiosity thing and the beginning of the model and stupid. So the controller should be motivated to come up with experiments with action sequences that lead to data. Does that improve as a model,

Speaker 6:          00:59:24       do you think, uh, improving the model, constructing and understanding of the world in this connection? Is that now the, the popular approaches that have been successful or you're grounded in ideas of neural networks, but in the 80s with expert systems, there's symbolic ai approaches which uh, to us humans are more intuitive in the sense that it makes sense that you build up knowledge and just knowledge representation. What kind of lessons can we draw into our current approaches in four from expert systems from symbolic Ai.

Speaker 2:          01:00:00       So I um, became aware of all of that in the ats and back then a lottery program logic programming was a huge thing. It was inspiring to you yourself.

Speaker 6:          01:00:10       Did you find it compelling because most, a lot of your work was, uh, not so much in that realm, right? Is more in the learning systems,

Speaker 2:          01:00:18       yes or no, but we did all of that is, are we, my first, um, publication ever actually was, um, 1987 was a, the implementation of, um, genetic algorithm of a genetic programming system in prolog, prolog. That's what you learned back then, which is a logic programming language and the Japanese, the anthis huge fifth generation ai project, which was mostly about logic programming back then. Although in your network exists, existed and, and well known back then and deep learning has existed since 1965. Um, since this guy in the Ukraine, um, eva can echo started it, but, um, the Japanese and many other people, they focus really on this logic programming. And I was influenced to the extent that I said, okay, let's take these biologically inspired Ireland's like evolution, uh, programs, uh, and um, and, and, and implement that in the language, which I know, which was prologue for example back then and then, um, in, in many ways as came back later because the Google machine for example, has a proof search on board and without that it would not be optimal. While mark was hooked as a universal algorithm for solving all well defined problems as approved search on board. So that's very much logic programming. Without that, it would not be a, some talking optimum. But then on the other hand, because we have a very pragmatic guys also, um, we focused on recon you on and that's where I was and, and, and sub optimal, uh, stuff such as gradient base search and program space. Rather than prove up the optimal thing, things

Speaker 6:          01:02:09       that logic programming does it certain certainly has a usefulness in, uh, when you're trying to construct something provably optimal approvable good or something like that. But is it useful for, for practical problems?

Speaker 2:          01:02:21       It's really useful for our theory. Improving the best deer improvers today are not neural networks, right? No. Say a logic programming systems and they are much better theater improvers then most math students in the first or second semester.

Speaker 6:          01:02:37       Hmm. But for reasoning to, for playing games of go or chess or for robots, autonomous vehicles that operate in the real world or a object manipulation, you think learning.

Speaker 2:          01:02:51       Yeah. As long as the problem is have little to do with um, with theo improving themselves, then um, as long as that is not the case, um, you, you were just wanting to have better pattern recognition. So to build a self driving car you want to have better pattern recognition and um, and a pedestrian recognition and all these things and you want to your minimum, you want to minimize the number of false positives, which is currently is slowing down self driving cars. In many ways. And um, and all of that has very little to do with logic programming. Yeah.

Speaker 6:          01:03:27       What are you most excited about in terms of directions of artificial intelligence at this moment and then the next few years in your own research, in the broader community?

Speaker 7:          01:03:41       So I think in the not so distant future, we will have for the first time little robots that learn like kids. Um, I will be able to say to the robot, um, lucky a robot, we are going to assemble as much fun that's takes a slab of plastic, um, and the school driver and let's screw and the screwed like that, you know, not, not like that, like that, not like that, like that. And I don't have a data lover or something. He will see me and he will hear me and he tried try to do something with his own actuators, which will be really different from mine, but he will understand the difference and we'll learn to imitate me, but not in the supervised way. Um, where a teacher has giving targets signals for all his muscles all the time. No. By doing this high level imitation where he first has to learn to imitate me and then to interpret these additional noises coming from my mouth, um, as helping helpful signals to, to do that banner and then it will by itself come up with a faster ways and more efficient ways of doing the same thing.

Speaker 7:          01:05:03       And finally I stopped his learning algorithm and make a million copies and sell it. And so at the moment this is not possible but we already see how we are going to get them and you can imagine to the extent that this works economically and cheaply, it's going to change everything. Almost our production is going to be effected by that and a much bigger wave, much bigger ai wave is coming. Then the one that we are currently witnessing, which is mostly about passive pattern recognition on your smartphone. This is about active machines that shapes a data through the actions they are executing and they learned to do that in a good way.

Speaker 8:          01:05:51       Okay.

Speaker 7:          01:05:52       So many of the traditional industries are going to be affected by that. All the companies that are building machines, well equipped for you as machines with cameras and other sense auras. And they are going to learn to solve all kinds of problems through interaction with humans but also a lot on their own to improve what they already can do them. And lots of old economy is going to be effected by that. And in recent years I have seen that old economy is actually waking up and realizing that those are the canes. And um,

Speaker 9:          01:06:32       are you optimistic about the future? Are you concerned? Uh, there's a lot of people concerned on, in the near term about the transformation of the nature of work. The kind of ideas he just suggested would have a significant impact of what kinds of things could be automated. Are you optimistic about that future? Are you nervous about that future? And looking a little bit farther into the future, there's people like Elon Musk, uh, Stuart Russell concerned about the existential threats of that future. So in the near term job loss in the long term existential threat or these concerns to you or you ultimately optimistic.

Speaker 7:          01:07:15       So let's first address the near future.

Speaker 7:          01:07:22       We have had predictions off job losses for many decades. For example, when industrial robots came along, many pete, many people predict and lots of jobs are going to get lost. And in a sense they were right because back then there were car factories on hundreds of people and these factories assembled cars and today the same car factories have hundreds of robots and maybe three guys watching the robots. On the other hand, those countries that have lots of robots, para camp, Aton, Japan, Korea, Germany, Switzerland, a couple of other countries, they have really low unemployment rates. Somehow all of new jobs were created accent and nobody anticipated. There's always jobs. And um, decades ago I always said it's really easy to say which jobs are going to get lost, but it's really hard to predict the new ones. 30 years ago, who would have predicted all these people and making money as a youtube bloggers.

Speaker 7:          01:08:43       For example, 200 years ago, 60% of all people used to work in agriculture today, maybe 1%, but still only, I dunno, 5% unemployment, lots of new jobs were created and Homo Ludens, the playing man is inventing new jobs all the time. Most of these jobs are not existentially necessary for the survival of our species. There are only very few existentially necessary jobs such as farming and building houses and, and warming up the houses. But less than 10% of the population is doing that. And most of these newly invented jobs are about, um, interacting with other people in new ways through new media and so on, getting new kite types of Kudos and forms of likes and whatever, and even making money through that Homo Ludens. The playing man doesn't want to be an implied and that's why he's inventing new jobs all the time. And he keeps considering these jobs as really important and there's investing a lot of energy and hours of work and to, and to those new jobs,

Speaker 9:          01:10:08       there's a quite beautifully put, were really nervous about the future because we can't predict what kind of new jazz would be created. But your ultimately optimistic that we, uh, humans are so restless that we create and give meaning to newer in your jobs. Totally new likes on faith, things that get likes on facebook or whatever the social platform is. So what about long term existential threat of ai or our whole civilization may be swallowed up by this ultra super intelligent systems.

Speaker 7:          01:10:45       Maybe it's not going to be smaller dub, but um, I'd be surprised if a b where we humans were the last step and the evolution of the universe. And um, you, you've actually had this beautiful comments somewhere that I've seen saying that artificial quite insightful is artificial general intelligence systems. Jessica as humans will likely

Speaker 9:          01:11:14       not want to interact with humans. They'll just interact amongst themselves, just like ants interact amongst themselves and only tangentially interact with humans. And it's, it's quite an interesting idea that once we create a gi, they will lose interest in humans and, and have compete for their own facebook likes on their own social platforms. So within that, uh, quite elegant idea,

Speaker 7:          01:11:40       the, how do we know

Speaker 9:          01:11:43       in a hypothetical sense that there's not already intelligent systems out there? How do you think broadly of general intelligence greater than us, how would we know it's out there? How do we know it's around us? And could it already be,

Speaker 7:          01:12:01       I'd be surprised if within the next few decades or something like that, the um, the won't have ais are truly smart in every single way and better problem solvers and almost every single important way. And I'd be surprised that they wouldn't realize what we have realized a long time ago, which has that almost all physical resources are not here and this biosphere but without

Speaker 7:          01:12:34       the rest of the solar system gets 2 billion times more solar energy than our little plot. There's lots of material out there that you can use to build robots and self replicating robot factories and all that stuff. And they're going to do with that. And they will be scientists, um, and curious and they will explore what they can do them. And in the beginning they will be fascinated by life and by their own origins. And I was urbanization. They will want to understand that completely. Just like people today would like to understand how life works and um, and also, um, the history of our own existence and subluxation, but then also the physical laws that created all of that. So they, um, in the beginning they will be fascinated by life once they understand that there was interest. I'm like anybody who loses interest and things he understands. And then as you said, um, the most interesting sources,

Speaker 7:          01:13:49       information for them will be others have their own kinds. So at least in the long run, that seems to be some sort of protection through lack of interest on the other side. And um, and now it seems also clear as far as we understand physics, you need maton energy to compute and to build more robots and infrastructure and more Ai. Civilization and I ecology is consisting of trillions of different types of ai and so it seems inconceivable to me that this thing is not going to expand some ai ecology not controlled by one ai by trillions of different types of ai as competing and all kinds of quickly evolving and disappearing ecological niches in ways that we cannot fathom at the moment, but it's going to expound limited lightspeed and physics, but it's going to expand and we realize that the universe is still young. It's only 13.8 billion years old and it's going to be a thousand times older than that.

Speaker 7:          01:15:11       There's plenty of time to conquer the entire universe and to fill it with intelligence and senders and receivers that ais can travel the way they are traveling an hour labs today, which is by radio or from sender to receiver and let's call the current age of the universe one Ian, when Ian now it will take just a few eons from now and the entire visible universe. There's going to be full of that stuff and let's look ahead to a time when the universe is going to be 1000 times older than it is now. They will look back and they will say, look, almost immediately after the big bang, only a few eons later, the entire universe started to become intelligent. Now to your question, how do we see whether anything like that has already happened or has already in a more advanced stage in some other parts of the universe, the visible unit routes we are trying to look out there and nothing like that has happened so far?

Speaker 9:          01:16:20       Or is that charter? What do you think? We'll recognize it. Well, how do we know it's not among us? How do we know planets aren't in themselves intelligent beings? How do we know ants seen as a collective or not much greater intelligence than our own? These kinds of ideas. And it was a boy. I was thinking about these things

Speaker 7:          01:16:45       and I thought maybe it has already happened because back then I know, I knew, I learned from poplar physics box that the structure of the large scale structure of the universe is not homogeneous and you have these clusters of galaxies and then in between the these huge empty spaces. And I thought, hmm, maybe say island's really empty. It's just that in the middle of that some ai, so lization already has expanded and then has covered a bottle of 1 billion light years time visa and it's using all the energy of all the styles within that bubble for its own unfathomable practices. And so it always happened and we just fail to interpretate the signs. But then alarm of that gravity by itself explains the large scale structure of the universe and that this is not a convincing explanation. And then I thought maybe vb, it's the dark matter because as long as we know today 80% of the measurable matter is invisible and we know that because otherwise our galaxy or other galaxies worked fall apart. They would, they are rotating too quickly and then the idea was maybe all us, he is ai civilizations that are already out there. They they just invisible because they are really efficient and using the energies are their own local systems and that's why they appear doctors. What's, this is awesome at a convincing explanation because then the question becomes why is there,

Speaker 7:          01:18:38       are there still any visible stars were left in our own galaxy, which also must have a lot of dark matter, so that is awesome. Not a convincing thing and today I like to thing it's quite plausible that maybe the first, at least in our local light cone within it's a few hundreds of millions of light years and we can reliably observe, observe. Is that exciting to you? They will. Might be the first, and it would make us much more importance because if we mess it up through a nuclear war, then, then maybe this will have an effect on the, on the, on the development on the entire universe. So let's not mess it up. It's not miss it. You again, thank you so much for talking today. I really appreciate it. It's my pleasure.