Speaker 1:          00:00          Welcome to mit course six zero nine, nine artificial general intelligence. Today we have ray Kurzweil. He is one of the world's leading inventors, thinkers and futurists with a 30 year track record of accurate predictions called the restless genius by the Wall Street Journal and the ultimate thinking machine by Forbes magazine. He was selected as one of the top entrepreneurs by ink magazine, which described him as the rightful heir to Thomas Edison. PBS selected him as one of the 16 revolutionaries who made America. Ray was the principal investigator of the first CCD flatbed scanner, the first Omni font optical character recognition, the first point to speech reading machine for the blind, the first text to speech synthesizer, the first music synthesizer capable of recreating the grand piano and other orchestra instruments, and the first commercially marketed large vocabulary speech recognition. Among his many honors, he received a Grammy Award for outstanding achievements in music technology. He's the recipient of the National Medal of Technology, was inducted into the national inventors hall of fame, holds 21 honorary doctorates, and honors from three US presidents. Ray has written five national bestselling books including the New York Times bestsellers. The singularity is near from 2005 and how to create a mind from 2012. He's Co founder and Chancellor of Singularity University and a director of engineering at Google. Heading up a team developing machine intelligence and natural language understanding. Please give a warm welcome.

Speaker 2:          01:49          It's good to be back. I've been in this lecture hall many times and walked the infinite Carter. I came here as an undergraduate in 1965. Within a year of my being here, they started a new major called computer science. It did not get its own course number. It's six one. Even biotechnology recently got its own course number, but how many of you are cs majors? Okay. How many of you do work in deep learning? How many of you have heard of deep learning? I came here first in 1962 when I was 14. I became excited about artificial intelligence. It it had only gotten its name six years earlier, the 1956 dartmouth conference by Marvin Minsky and John Mccarthy, so I wrote a Minsky, a letter. There was no email back then and he invited me up. He spent all day with me, is if he had nothing else to do, he was the consummate educator.

Speaker 2:          03:07          I then, and uh, the AI field had already bifurcated into two warring camps, the symbolic school which Minsky was associated with a. and the connectionist school, uh, was not widely known. In fact, I think it's still not widely known that minsky actually invented the neural net in 1953, but he had become negative about. It's largely because there's a lot of hype that these giant brains could solve any problem. So the first popular neural nets, the perceptron was being promulgated by Frank Rosenblatt at Cornell. So minsky says, where are you going now? And saying, I said to c Rosenblatt at Cornell is that, don't bother doing that. And I went there and Rosenblatt was touting the perceptron that had ultimately would be able to solve any problem. So I brought some printed letters that had the camera and it did a perfect job of recognizing them as long as they were carrier 10 different type style.

Speaker 2:          04:15          Didn't work at all. And he said, but don't worry, we can take the output of the perceptron undefeated as the input to another perceptron and take the output of that and feed it to a third layer, and as we add more layers, it'll get smarter and smarter and generalize. And so that's interesting. Have you tried that? Well, no, but it's high in our research agenda. Things did not move quite as quickly back then as they do now. He died nine years later. Never having tried that idea turns out to be remarkably prescient. I mean he never tried multilayer neural nets and all the excitement that we've seen now about deep learning comes from a combination of two things, both many layer neural nets and the law of accelerating returns, which I'll get to a little bit later, which is basically the exponential growth of computing so that we can run these massive nets and handle massive amounts of data.

Speaker 2:          05:17          It would be decades before that idea was tried several decades later, the three level neural nets were tried. There were a little bit better. They could deal with multiple types. Styles still weren't very flexible. That's not hard to add other layers. It's a very straightforward concept. Uh, there was a math problem, a, the disappearing gradient or the exploding gradient, which I'm sure many of you are familiar with. Basically, you need to take maximum advantage of the range of values, uh, in the gradients, uh, not let them disappear. And a loser resolution, a, that's a fairly straightforward mathematical transformation. With that insight, we could now go to 100 layer neural nets and s that's behind sort of all the fantastic gains that we've seen recently. A alpha go, a trained on every online game and then became a fair go player and then trained itself by playing itself and soared past the best human alphago.

Speaker 2:          06:33          Zero started with no human input at all, within hours of iteration, soared past Alphago. Uh, also sort past the best chest programs that had another innovation. Uh, basically you need to evaluate the quality of the board at each point. And they used a, another 100 layer neural nets to do that evaluation. Um, so there's still a problem in the field, uh, which is there's a motto that life begins at a billion examples. One of the reasons I'm at Google is we have a billion examples, for example, does have pictures of dogs and cats that are labeled. So you've got a picture of a cat and it says cat and then you can learn from it and you need a lot of them, a Alphago trained on a million online moves. That's how many we had of master games and that only created a, a sort of fair go player.

Speaker 2:          07:37          A good amateur could defeat it. So they worked around that in the case of goal by basically generating an infinite amount of data by having the system play itself, uh, had a chat with Dennis Hassabis. What kind of situations can you do that with? You have to have some way of simulating the world. So go or chess or even though go is considered a difficult game, it's a, you know, the definition of it is exists on one page, uh, so you can simulate it. A, that applies to math. I mean, mass axioms are going to be contained on a page or two. It's not very complicated. Uh, it gets more difficult when you have real life situations like biology, so we have biological simulators, but the simulators on perfect, so learning from the simulators will only be as good as the simulators. That's actually the key to being able to do deep learning on biology.

Speaker 2:          08:42          Autonomous Vehicles. You need real life data. Uh, so the waymo systems have gone three and a half million miles. Uh, that's good. That's enough data to then create a very good simulator. The simulator is really quite realistic because they had a lot of real world experience and the, they've got a billion miles in the simulator, but we don't always have that opportunity to either create the data or have the data around humans can learn from a small number of examples. Uh, your significant other, your professor, your boss, your investor a can tell you something once or twice and you might actually learn from that. Some humans have been reported to do that. And, uh, that's, that's, that's kind of the remaining advantage of humans. Now. There's actually no backpropagation and the human brain, it doesn't use deep learning. It uses a different architecture that same year in 1962 or older paper, how I thought the human brain worked.

Speaker 2:          09:48          Uh, there was actually very little neuroscience to go on. There was one neuro science test, Vernon mountcastle. It had something relevant to say, which he did. I mean, there was a, the common wisdom at the time, and there's still a lot of neuroscience instead say this. So we have all these different regions of the brain. They do different things. They must be different than v one in the back of the head where the optic nerve skills into that can tell that that's a curved line. That's a straight line. Does a simple feature extractions on visual images. It's actually a large part of the neocortex does a cruciform gyrus up here, which can recognize faces. Uh, we know that because if it gets knocked out through injury or stroke, people can't recognize faces. They will learn it again with a different region of the neocortex is the famous frontal Cortex, which does language and poetry and music.

Speaker 2:          10:46          Uh, so these must work on different principles. He did autopsies on the neocortex and all these different regions and found they all look the same. They had the same repeating pattern, same interconnections. Uh, he said Neocortex is neocortex. So I had that hint. Otherwise I could actually observe human brains and action, which I did from time to time. And there's a lot of hints that you can get that way. For example, if I ask you to recite the alphabet, you actually don't do it from a to z, you do it as a sequence of sequences a, b, c, d, e, f, g, H, I, j, k, two. We learn things as forward sequences of sequences forward because if I ask you to recite the alphabet backwards, you can't do it unless you learn that as a new sequence. So these are all interesting. Hence I wrote a paper that I, that the Neocortex is organized as a hierarchy of modules and each module can learn to simple pattern and that's how I got to meet President Johnson.

Speaker 2:          11:48          And that initiated a half century of thinking about issue. I came to mit to study with Marvin Minsky. Actually, I came for two reasons. Once Minsky became my mentor, which was the mentorship that lasted for over 50 years, the fact that mit was so advanced and actually had a computer, which the other colleges I considered didn't have a. It was an IBM 70, 94, 32 K of 36 fit words. So it's 150 k of core storage to microsecond cycle time to cycles for instruction. So a quarter of a map and that thousands of students and professors share that one machine in 2012. I wrote a book about this thesis is now actually an explosion of neuroscience evidence to support it. The European brain reverse engineering project has identified or repeating module of about 100 neurons, repeated it $300 million times. So it's about $30 billion neurons in the NEOCORTEX. The neocortex is the outer layer of the brain.

Speaker 2:          12:55          That's part where we do our thinking, uh, and they can see in each module, axons coming in from another, a module, and then the output acts, the single output accident of that module goes as the input to another module. So we can see it organized as a hierarchy. It's not a physical hierarchy. The hierarchy comes from these connections. The neocortex is a very thin structure. It's actually one module thick, the six layers of neurons, but it constitutes one module. And we can see that it learns and simple pattern and various reasons I cite in the book the pattern recognition model that's using is basically a hidden Markov model. How many of you have worked with mark off models? And that's usually no hands go up when I asked that question. Um, but a Markov model is not. It is learned a, but it's not backpropagation.

Speaker 2:          13:56          It can learn local features. So it's very good for speech recognition and speech recognition. I work, I did in the eighties, used these mark models that became the standard approach because it can deal with local variations. So the fact that a vow will is stretched. It can learn that in a Markov model, it doesn't learn long distance relationships that's handled by the hierarchy and something we don't fully understand yet is exactly how the neocortex creates that hierarchy. But we have figured out how I can connect this module two, this module, does it then grow? I mean, there's no virtual communication or wireless communication. It's actually a connection. So does it grow and Axon in are from one place to another which could be inches apart. Uh, actually they all, all these connections are there from birth, uh, like the streets and avenues of Manhattan, this vertical and horizontal connection.

Speaker 2:          14:59          So if the decides and how it makes that decision is still not fully understood that it wants to connect this module two, this module, there's already a vertical, horizontal and a vertical connection. It just activates them. We can actually see that now and could see that happening in real time on noninvasive brain scans. Uh, so this utterance amount of evidence that in fact the neocortex is a hierarchy of modules that can learn. Each module learns so simple sequential pattern. And even though the patterns we perceive don't seem like sequences, they may seem three dimensional or even more complicated. They are in fact represented, uh, as sequences. But the complexity comes in with the hierarchy. So the NEOCORTEX emerged 200 million years ago, uh, with mammals. All mammals have a neocortex. It's one of the distinguishing features of mammals. These first mammals were small. They were rodents where they were capable of a new type of thinking.

Speaker 2:          16:07          Uh, other nonmelanoma animals had fixed behaviors, but those fixed behaviors were very well adapted for their ecological niche. But these new mammals could invent a new behavior. So creativity and innovation was one feature of the NEOCORTEX. So analysis, escaping a predator, it's usual. Escape Path is blocked. It will invent a new behavior to deal with. It probably wouldn't work, but if it did work, it would remember it. And we'd have a new behavior and that behavior could spread virally through the community. Another mouse watching this say to itself, that was really clever going around that rock, I'm going to remember to do that. Uh, and it would have a new behavior. Didn't help these early mammals that much because as I say, the Mammalian and animals who were very well adapted to their niches and nothing much happened for $135 million years, but then 65 million years ago something did happened, there was a sudden violent change to the environment.

Speaker 2:          17:12          We now call it the cretaceous extinction event. There's been debate as to whether it was a immediate or an asteroid. I mean a media or a volcanic eruption. A the asteroid or media or hypothesis is in the ascendancy. But if you dig down to an area of rock reflecting 65 million years ago, the geologist will explain that it shows a very violent sudden change to the environment. And we see it all around the globe. So it was a worldwide phenomenon. The reason we call it an extinction event is that's when the dinosaurs went extinct. Uh, that's when 75 percent of all the animal and plant species went extinct. And that's when mammals overtook their ecological niche. So to anthropomorphize, biological evolution said to itself, hmm, this neocortex is pretty good stuff. And it began to grow it. So now mammals got bigger, their brains got bigger at an even faster pace, taking up a larger fraction of their body.

Speaker 2:          18:14          The neocortex got bigger even faster than that. And developed these curvatures that are distinctive, have a primate brain basically to increase its surface area. But if you stretched it out, uh, the human neocortex is still a flat structure. It's about the size of a table, Napkin justice thin, uh, and uh, it's basically, uh, created a primates which became dominant in their ecological niche. A then something else happened 2 million years ago. And biological evolution decided to increase the neocortex further and increase the size of the enclosure and basically filled up the frontal cortex, uh, with our big skulls, with more neocortex. And up until recently, it was felt that, as I said, that this was, the frontal cortex was different because it does these qualitatively different things. But we now realized that it's really just additional neocortex.

Speaker 2:          19:24          So remember what we did with it. We were already doing a very good job of being primates. So we put it at the top of the neocortical hierarchy. And we increased the size of the hierarchy, it was maybe 20 percent more neocortex, but it doubled and tripled the number of levels because as you go up the hierarchy, it's kind of like a pyramid. There's fewer and fewer modules and that was the enabling factor for us to invent language and art. Music. Every human culture we've ever discovered has music. No primate culture has music. There's debate about that, but it's really true.

Speaker 2:          20:04          Invention technology, a technology required another evolutionary adaptation, which is this humble appendage here. Uh, no other animal has add. If you look at a chimpanzee, it looks like they have a similar hand, but the thumb is actually down here. It doesn't work very well if you watch them trying to grab a stick a so we could imagine creative solutions. Yeah. I could take that branch and strip off the leaves and put a point on it and we could actually carry out these ideas and create tools and then use tools to create new tools and started a whole nother evolutionary process of tool making. And that all came with the, with the NEOCORTEX. So Larry Page read my book a 2012 and liked it, so I met with him in essence for an investment in a company I'd started actually a couple of weeks earlier to develop those ideas commercially because that's how I went about things as a serial entrepreneur and he said, well, we'll invest, but let me give you a better idea.

Speaker 2:          21:09          Why don't you do it here at Google, we have a billion pictures of dogs and cats and we got a lot of other data and lots of computers and lots of talents, all of which is true. And says, well, I don't know. I just started this company, uh, to develop this as well by your company and said, Hey, are you going to value a company that hasn't done anything? And just started a couple of weeks ago and he said we can value anything. Uh, so I took my first job five years ago and had been basically applying this model, this hierarchical model, um, to understanding language, which I think really is the holy grail of Ai. I think touring was correct in designating basically text communication as well. We now call a turing complete problem that it requires. There's no simple NLP tricks that you can apply to pass a valid turing test with an emphasis on the word valid Mitch Kapor.

Speaker 2:          22:11          And I had a six month debate on what the rules should be because if you read turing's 1950 paper, uh, he describes this in a few paragraphs and doesn't really describe how to go about it, but if it's a valid turing test, meaning it's really convincing you through into interrogation and dialogue, uh, that it's a human that requires a full range of human intelligence. And I think that a test says to the test of time, we're making very good progress on that. I mean, just last week you may have read that two systems, uh, past the paragraph comprehension test. It's really very impressive. When I came to Google, we were trying to pass these paragraph comprehension tests. We aced the first, the first grade test, second grade tests were Kinda got average performance. And the third grade test had too much inference. I already, you had to know some common sense knowledge is it's called a and make implications of things that were in different parts of the paragraph and there's too much in France and really didn't, didn't work.

Speaker 2:          23:24          So this is now an adult level, just slightly surpassed average human performance. Uh, but we've seen that one something, an ai does something at average human levels. It doesn't take long for it to soar past a average human levels. I think it'll take longer in language and it didn't sort of simple games like go, uh, it's actually very impressive that it surpasses now average human performance to use an Lstm long short temporal memory. But if you look at the adult test in order to answer these questions, it has to put together inferences and implications of several different things in the paragraph with some common sense. Knowledge is not explicitly stated. So that's, I think a pretty impressive milestone. So I've been developing, I've got a team of about 45 people, um, and we've been developing this hierarchical model. We don't use Markov models because we can use deep learning for each module.

Speaker 2:          24:30          And so we create an embedding for each word and recreate an embedding for each sentence, uh, this week. Have a can talk about it because we have a published paper on it. It can take into consideration context. If you use smart reply on Ge Fuse, g mail on your phone, you'll see it gives you three suggestions for responses. That's called smart reply there that are simple suggestions. But it has to actually understand perhaps a complicated email, uh, and the, the quality of the suggestions and squarely quite good. Quite on point. Uh, that's where my team using this kind of hierarchical model, uh, so instead of mark off models, it uses embeddings, uh, cause we can use backpropagation, we might as well use it. Uh, but I think what's missing from deep learning is this hierarchical aspect of understanding because the world is hierarchical. That's why a evolution developed a hierarchical brain structure to understand the natural hierarchy in the world.

Speaker 2:          25:41          And there are several problems with big, deep neural nets. One is the fact that you really do need a billion examples and we don't. Sometimes we can generate them as in the case of go, uh, or if we have a really good simulator as in the case of autonomous vehicles, not quite the case yet in biology, a very often you don't have ability to example, if you suddenly have billions of examples of language but they're not annotated. And how would you annotate it anyway with more language that we can understand in the first place. So it's kind of a chicken and an egg problem. Uh, so I believe this hierarchical structures needed another criticism of deep neural nets. They don't explain themselves very well. It's a big, a black box that gives you pretty remarkable answers. I mean, in the case of these Games Dennis described it's playing in both go and chess is almost an alien intelligence because it will do things that were shocking to you and experts like sacrificing a queen and a bishop at the same time, uh, or in close succession which shocked everybody, but then went on win or early in a go game, putting a piece at the corner of the board, which is kinda crazy to most experts because you really want to start controlling territory.

Speaker 2:          26:57          And yet on reflection, that was the brilliant move that enabled us to win that game.

Speaker 2:          27:05          But it doesn't really explain how it does these things. So if, yeah, if you have a hierarchy, it's much better at explaining it because you could look at the content of the, of the modules in the hierarchy and they'll explain what they're doing. And, uh, just to end on the first application of applying this to health and medicine, this will get into high gear and we're going to really see a breakout of the linear extension to longevity that we've experienced. A, I believe we're only about a decade away from longevity, escape velocity. We're adding more time than is going by, not just to infant life expectancy, but to your remaining life expectancy. I think if someone is diligent, they can be there already. I think I've at longevity, escape velocity now a word on what life expectancy means. It used to be assumed that not much would happen. So whatever your life expectancy is a with or without scientific progress, it really didn't matter. Now it matters a lot. So life expectancy really means, you know, how long would you live, what's the statistical likelihood if there were not continued tying antic progress, but that's a very inaccurate assumption that scientific progress is extremely rapid. I mean, just as an ai and biotech, there are advances now. Every week is quite stunning.

Speaker 2:          28:38          Now you could have a computed life expectancy, let's say 30 years, 50 years, 70 years from now, you could still be hit by the proverbial bus tomorrow. We're working on that with self driving vehicles. Um, but we'll get, we'll get to a point. I think if you're diligent, you can be there now in terms of basically advancing your own statistical life expectancy, at least to keep pace with the passage of time. I think it will be there for most of the population at least if they're diligent within about a decade. So if he can hang in there, we may get to see the remarkable century ahead. Thank you very much.

Speaker 3:          29:26          You, I have a

Speaker 2:          29:27          question. Please raise your hand and we'll get you on mic. Uh, high. Uh, so you mentioned, uh, both your neural network models and symbolic models. Uh, and I was wondering how far have

Speaker 4:          29:42          you had been thinking about combining these two approaches? Creating a symbiosis between neural models. Send symbolic ones.

Speaker 5:          29:51          I don't think we want to use symbolic models as they've been used. How many are familiar with the psych project? That was a very diligent effort in Texas to define all of common sense reasoning and it kind of collapsed on itself and became impossible to debug because you fix one thing and it would break three other things. That complexity ceiling has become typical of, of trying to define things through logical rules. Uh, now it does seem that humans can understand logical rules. We have logical rules written down for things like law and game playing and so on. Uh, but you can actually define a connection as system to have such a high reliability on a certain type of action that it looks like it's a symbolic role, even though it's represented in a connectionist way. And connection systems can both capture the soft edges because many things in life are not a sharply defined. They can also generate exceptions. So you, you don't want to sacrifice your queen and chest except certain situations that might be a good idea. So you can capture that kind of complexity. Uh, so we do want to be able to learn from accumulated human wisdom that looks like it's symbolic. But, uh, I think we'll do it with a connection of system. But again, I'm, I think the connection systems should develop a sense of hierarchy and not just be one big massive neural net.

Speaker 4:          31:44          So I understand how we won, you know, using your cortex to extract useful stuff and commercialize that, but I'm wondering how, you know, our middle brain and the organs that are below the neocortex will be useful for, um, you know, turning that into what you want to do. So.

Speaker 5:          32:03          Well, the cerebellum is an interesting case in point. It actually has more neurons in the neocortex and it's used to govern most of our behavior. Uh, some things, if you write a signature that's actually controlled by the cerebellum, so a simple sequence is stored in the cerebellum, but there's not any reasoning to it. It's basically a script. Uh, and most of our movement now has actually been migrated from the cerebellum to the NEOCORTEX. Cerebellum is still there. Uh, some people, a tire cerebellum is destroyed through disease. Uh, they still function fairly. Normally they're moving, might be a little erratic as our movement is largely controlled by the Neocortex, but some of the subtlety is a kind of preprogrammed script and so they'll look a little clumsy, but they're actually functioning okay. Um, a lot of other areas of the brain control, autonomic functions like breathing and uh, but our thinking really is, is controlled by the neocortex in terms of a mastering intelligence. I think the NEOCORTEX is the brain region we want to study.

Speaker 4:          33:25          I'm curious what you think might happen after the singularity is reached in terms of this exponential growth of information. Yeah. Do you think it will continue or will there be a whole paradigm shift? What do you predict?

Speaker 5:          33:42          Well, in the singularity is near talk about the atomic limits based on molecular computing as we understand it, uh, and it can actually go well past 20 slash 45 and actually go to trillions of trillions of times a greater computational capacity than we have today. So I don't see that stopping anytime soon and we'll go way beyond what we can imagine. Um, and it becomes an interesting discussion. What the impact on a human civilization will be. So take it maybe slightly more mundane issue that comes up as us going to eliminate most jobs are all jobs. A point I make is it's not the first time in human history. We've done that. How many jobs circa 1900 exists today. Uh, and that was the feeling of the Luddites, which was some actual society and that formed in 1800 after the automation of the textile industry in England.

Speaker 5:          34:47          They looked at all these jobs going away and felt old employment's going to be just limited to an elite. Uh, indeed, those jobs did go away, but new jobs were created. So if I were oppression futurist in 1900, I would say, well, 38 percent of your work on farms and 25 percent work in factories. That's two thirds of the working for us, but I predict by 20 1,515 years from now, it's going to be two percent on farms and nine percent in factories. And everybody would go, oh my God, we're going to be out of work. And I said, well, don't worry for all these jobs we eliminate through automation. We're going to invent new jobs. People say, Oh, really? What new jobs? And I'd say, well, I don't know. We haven't invented them yet. That's the political problem. We can see jobs very clearly going away fairly soon.

Speaker 5:          35:37          Like driving a car or truck, uh, and the new jobs haven't been invented. I mean, it's just look at the last five or six years as many of the increase in employment has been through mobile app related types of ways of making money that just weren't contemplated even six years ago. If I really pressured, I would say, well, you're going to get jobs creating mobile apps and websites and doing data analytics and a self driving cars, cars. What's a car? And nobody would have any idea what I'm talking about a now the new job. Some people say, yeah, we created new jobs for. It's not as many actually. We've gone from 24 million jobs in 1900, 242 million jobs today for 30 percent of the population to 45 percent of the population. The new jobs pay 11 times as much in constant dollars and they're more interesting.

Speaker 5:          36:34          I mean, as I talk to people starting out their career now, they really want a career that gives him some life definition and purpose and gratification. We're moving up maslow's hierarchy a 100 years ago. You are happy if you had a backbreaking job to put food on your family's table. So, and we couldn't do these new jobs without enhancing our intelligence. So we've been doing that a well for most of the last 100 years through education. We've expanded k through 12 and constant dollars tenfold. We've gone from 38,000 college students in 1870 to $50 million today. Uh, more recently we have brain extenders and not yet connected directly in our brain, but they're great close at hand when I was here at mit to take my bicycle across campus to get to the computer and show an ID to get in the building. Now we carry them in our, in our pockets and under our belts.

Speaker 5:          37:33          A, they're going to go inside our bodies and brains. I think that's a really important distinction, but so we're basically going to be continuing to enhance our capability through merging with Ai. And that's the, I think ultimate answer to the kind of Dystopian view we see in futures movies where it's the ai versus a brave band of humans for control of humanity. We don't have one or two ais in the world today. We have several billion, 3 billion smartphones at last count and it'll be 6 billion in just a couple of years according to the projections. Uh, so we're, we're already deeply integrated with this, uh, and I think that's going to continue and it's going to continue to do things that we can't even imagine today just as we are doing today. Things we couldn't imagine know even 20 years ago

Speaker 6:          38:26          you showed many grasp that go through exponential growth, but I haven't seen one that isn't. So I would be very interested in hearing you haven't seen what that, what that is not exponential. So tell me about regions that you've investigated that have not seen exponential growth. And why do you think that's the case?

Speaker 5:          38:45          Well, price, performance and capacity of information technology invariably follows a exponential where it impacts human society. It can be linear. So for example, the growth of democracy, uh, has been linear but still pretty steady. I could count the number of democracies on the fingers of one hand to century, go a two centuries ago. You could count the number of democracies in the world on the fingers of one finger. Now there are dozens of them that this has become kind of a consensus that that's how we should be governed. So the, and I attribute all this to the growth in information technology, communication in particular for a progression of social cultural institutions, um, but information technology because it ultimately depends on a vanishingly small energy and material requirement grows exponentially and will for a long time. Uh, there was recently a criticism that, well, chest scars have. It's actually a remarkably a straight linear progression, so humans think it's like 2,800 and it just soared past that in 1997 with deep blue and it's kept going, uh, and a remarkably straight and St. well, this is linear, not exponential, but the chest score is a logarithmic, uh, measurement, uh, so, uh, it, it really is exponential progression.

Speaker 6:          40:28          So philosophers like to think about the meaning of things, especially in the 20th century. So for instance, Martin Heidegger gave a couple of speeches and lectures on the relationship of human society to technology, and he particularly distinguished between the mode of thinking, which is calculating, thinking and a mode of thinking, which is reflective thinking or meditative thinking. Um, and, uh, he posed this question, what is the meaning and purpose of technological development? And he couldn't find an answer. He, he recommended it to remain open to what you called. He called this an openness to the mystery. Uh, I wonder whether you have any thoughts on this. Is there a meaning, a purpose of technological element? And, and is there a way for us human success, excess that meaning.

Speaker 5:          41:21          Well, we started using technology to shore up weaknesses and our own capabilities. So physically, I mean, who here could build this building? So we've leveraged the power of our muscles with machines, uh, and were in fact very bad at doing things that, you know, the simplest computers can do a pike factor numbers or even just multiply two digit numbers. Computers can do that trivially. We can't do it. So we originally started using computers to make up for that weakness. Uh, I think the essence of what I've been writing about is to master the unique strengths of, of humanity, creating loving expressions and poetry and music and, uh, the kinds of things we associate with the better qualities of humanity with machines. That's the true promise of Ai, uh, that we're not there yet, but we're making pretty stunning progress just in the last year, this so many milestones that are really significant, including in language.

Speaker 5:          42:34          Um, and, but I think of technology as an expression of humanity. It's part of who we are and the human species is already a, a biological technological civilization and it's part of who we are and ai is as part of humans. Uh, so ai is human and it's just, it's part of the technological expression of humanity. And we use technology to extend our reach. You know, I couldn't reach that fruit at that higher branch a thousand years ago. So we invented a tool to extend our physical reach. Now extend our mental reach. We can access all of human knowledge with a few keystrokes. Um, and we're going to make ourselves literally smarter by merging with Ai.

Speaker 7:          43:31          Hi, first of all, honor to hear you speak here. Uh, so I first read the singularity is near nine years ago or so, and it changed the way I thought entirely, but something I think it caused me to oversee deeply discount was tail risk in geopolitics in systems that span the entire globe. Um, and my concern is that there are, there's obviously the possibility of tail risk, existential level events, swamping all of these trends that are otherwise waterproof climate proof, you name it. So my question for you is, what steps do you think we can take in designing engineered systems in designing social and economic institutions to kind of minimize our exposure to these tail risks and, and survive to make it, to, um, you know, a beautiful mind filled future?

Speaker 5:          44:48          Yeah. Well, the world was first introduced to a human made existential risk. Uh, when I was in elementary school, we would have these civil defense drills get under our desks and put our hands behind our head to protect this former thermonuclear war. Uh, and it worked. We made it through, but that was really the first introduction to an existential risk, uh, and those weapons are still there by the way, and they're still on a hair trigger and they don't get that much attention. Uh, there's been a lot of discussion, a much of which I've been in the forefront of initiating the existential risks of what's sometimes referred to as gnr g for genetics, which is biotechnology and financial technology and grey goo robotics, which is ai. Uh, and I've been accused of being an optimist. I think you have to be an optimist to be an entrepreneur.

Speaker 5:          45:51          If you knew all the problems you were going to encounter, you'd never start any project. But, uh, I've written a lot about the downsides. I remain optimistic. Uh, there are specific paradigms and not foolproof that we can follow to keep these technologies safe. So, for example, uh, over 40 years ago, uh, some visionaries recognize the revolutionary potential. Both were promise and peril of biotechnology, neither of the promise and the peril of what's feasible 40 years ago. But they had a conference at the Sylmar Conference Center in California, uh, to develop both a professional ethics and strategies to keep biotechnology safe and they've been known to see in Sylmar guidelines. They've been refined through successive sylmar conferences. Much of that is baked into law and an, in my opinion, it's worked quite well. We're now, as I mentioned, getting profound benefit. It's a trickle today. It'll be a flood over the next decade.

Speaker 5:          46:58          And the number of people who have been harmed either through intentional or accidental abuse of biotechnology so far, zero. Actually, I take that back. There was one boy who died in gene therapy trials, but 12 years ago and there's congressional hearings and the, uh, canceled all research for a gene therapy for a number of years. You could do an interesting message thesis and demonstrate that, you know, 300,000 people died as a result of that delay, but you can't name them. They can't go on. So we don't know who they are. But, um, so it has to do with the balancing of risk. But in large measure, virtually no one has been hurt by biotechnology. Now, that doesn't mean you can cross it off our list. Okay? We took care of that one because the technology keeps getting more sophisticated. Crispers great opportunity. This hundreds of trials of crispr technologies overcome disease, but it could be abused.

Speaker 5:          47:56          You can easily describe scenarios, so we have to keep reinventing it. Uh, January, we had our first Sylmar conference on ai ethics. And so I think this is a good paradigm. It's not foolproof. Uh, I think the best way we can assure a democratic, a future that includes ideas of liberty is to practice that in the world today because the future world of the singularity, which is a merger of biological biological intelligence, uh, is not going to come from Mars. I mean, it's going to emerge from our society today. Uh, so if we practice these ideals today, it's gonna have a higher chance of us practicing them as we get more enhanced with technology. Uh, that doesn't sound like a foolproof solution or it isn't. But I think that's the best approach in terms of technological solutions. I mean, ai is the most daunting. You can imagine.

Speaker 5:          48:53          A, there are technical solutions to biotechnology and nanotechnology. Uh, there's really no set routine. You can put it in your ai software that will assure that have remained safe intelligence. It's inherently not controllable. There's some ai that's smarter than you that's out for your destruction. The best way to deal with that is not to get in that situation in the first place. If you are in that situation, find some ai that will be on your side. Um, but basically, uh, it's going to it, I believe we have been headed through technology, uh, to a, to a better reality, a look around the world and people really think things are getting worse. Uh, and I think that's because our information about what's wrong with the world is getting exponentially better. I say, Oh, this is the most peaceful time in human history in previously. What are you crazy?

Speaker 5:          49:50          Didn't you hear about the event yesterday and last week and a while, a hundred years ago, that could be a battle and wiped out the next village. And you wouldn't even hear about it for months. Uh, have all these graphs on education and literacy has gone from 10 percent to 90 percent over a century and a health wealth, uh, poverty's declined 95 percent in Asia over the last 25 years was documentary about the World Bank. All these trends are very smoothly getting better and everybody thinks things are getting, but, but, but you're right, like on violence, that curve could be quite disruptive. There's an existential event, uh, as I say, I'm optimistic, but I think that is something we need to deal with and a lot of it is not technological, it's dealing with our social cultural institutions.

Speaker 8:          50:51          So you mentioned also exponential growth of software and Ivs, I guess related to software. So one of the reasons for which you said that all that information technology is exponential is because of fundamental properties of matter and energy. But in the case of ideas, why would it have to be exponential?

Speaker 5:          51:10          Well, a lot of ideas produce exponential gains. They don't increase performance linearly. There's a case study during the Obama Administration by the scientific advisory board on assessing this question, how much gains on 23 classical engineering problems were gained through hardware improvements over the last decade and software improvement. So there's about a thousand to one improvement. It's about doubling every year from hardware that was an average of something like 26,000 to one through software improvements, algorithmic improvements. So we do see both ends. Apparently if you come up with an advance, it doubles the performance so it multiplies it by 10. We see basically exponential growth from each innovation. Um, so, and we certainly see that in deep learning. Uh, the architectures are getting better while we also have more data and more computation and more memory to throw at these at these algorithms. Thank you very much.

Speaker 3:          52:23          Thank you.