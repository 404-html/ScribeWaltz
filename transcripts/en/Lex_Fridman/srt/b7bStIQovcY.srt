1
00:00:00,090 --> 00:00:03,120
The following is a conversation
with Thomas San home.

2
00:00:03,540 --> 00:00:06,660
He's a professor of same you
and Co creator of [inaudible],

3
00:00:06,960 --> 00:00:10,980
which is the first AI system to beat top
human players in the game of heads up.

4
00:00:10,981 --> 00:00:12,390
No limit.
Texas hold'em.

5
00:00:13,160 --> 00:00:17,210
He has published over 450 papers on
game theory and machine learning,

6
00:00:17,360 --> 00:00:20,630
including a best paper in 2017 at nips.

7
00:00:21,170 --> 00:00:23,390
Now renamed to new reps,

8
00:00:23,600 --> 00:00:26,240
which is where I caught up
with him for this conversation,

9
00:00:27,080 --> 00:00:31,700
has research and companies have had
wide reaching impact in the real world,

10
00:00:32,210 --> 00:00:37,210
especially because he and his group not
only propose new ideas but also build

11
00:00:37,461 --> 00:00:41,630
systems to prove that these
ideas work in the real world.

12
00:00:42,170 --> 00:00:46,370
This conversation is part of the MIT
course on artificial general intelligence

13
00:00:46,520 --> 00:00:51,230
and the artificial intelligence podcasts.
If you enjoy, subscribe on Youtube,

14
00:00:51,440 --> 00:00:55,370
iTunes or simply connect with
me on Twitter at Lex Friedman,

15
00:00:55,700 --> 00:00:57,500
spelled f. R I. D.

16
00:00:58,090 --> 00:01:01,990
And now here's my conversation
with Thomas sent home.

17
00:01:03,110 --> 00:01:07,910
Can you describe at the high level
the game of Poker Texas? Hold 'em,

18
00:01:07,940 --> 00:01:10,910
heads up Texas hold'em for
people who might not be familiar.

19
00:01:11,600 --> 00:01:16,520
This card game. Yeah, happy to. So heads
up, no, let me fix this. Hold them.

20
00:01:16,521 --> 00:01:21,350
It has really emerged in the Ai community
as main benchmark for testing these

21
00:01:21,351 --> 00:01:26,060
application independent algorithms for
imperfect information games holding.

22
00:01:26,420 --> 00:01:30,950
And this is a game, uh, that's
actually played by humans.

23
00:01:30,980 --> 00:01:34,730
You don't see that much on
TV or casinos because uh,

24
00:01:35,000 --> 00:01:36,710
well for that reverse reasons,
but uh,

25
00:01:37,110 --> 00:01:41,690
are you do see it in some expert level
casinos and you see it in the best poker

26
00:01:41,691 --> 00:01:45,530
movies of all time. It's actually an
event in the world series of poker,

27
00:01:45,710 --> 00:01:50,710
but mostly it's played
online and typically for
pretty bad big sums of money.

28
00:01:50,871 --> 00:01:54,440
And this is a game that
usually only experts play.

29
00:01:54,530 --> 00:01:58,580
So if you go to your home
game on a Friday night,

30
00:01:58,700 --> 00:02:01,910
it probably is not going to be heads up.
No limit. Texas hold that mic might be,

31
00:02:02,150 --> 00:02:04,610
uh,
not limit Texas hold'em in some cases,

32
00:02:04,611 --> 00:02:09,611
but typically for a big group and it's
not as competitive while heads up means

33
00:02:09,621 --> 00:02:10,460
it's two player.

34
00:02:10,461 --> 00:02:15,140
So it's really like me against you and
my better or are you a better much like

35
00:02:15,141 --> 00:02:19,370
chess or, or, or go in that sense,
but in an imperfect information game,

36
00:02:19,490 --> 00:02:23,300
which makes it much harder cause
I have to deal with issues of uh,

37
00:02:23,720 --> 00:02:27,080
you knowing things that they don't know
and I know things that you don't know

38
00:02:27,200 --> 00:02:30,710
instead of pieces being nicely laid
on the board for both of us to see.

39
00:02:31,070 --> 00:02:33,620
So in Texas hold'em, uh, there's uh,

40
00:02:33,890 --> 00:02:38,350
two cars that you only see
the lawn to you and there is,

41
00:02:38,510 --> 00:02:43,100
they gradually layouts some cars that
add up overall to five cards that

42
00:02:43,101 --> 00:02:44,000
everybody can see.

43
00:02:44,450 --> 00:02:48,470
The imperfect nature of the information
is the two cards that you're holding in

44
00:02:48,471 --> 00:02:50,480
front year. So as you said, you know,

45
00:02:50,481 --> 00:02:54,830
you first get two cards in private each
and then you, uh, there's a betting rod,

46
00:02:55,160 --> 00:02:59,280
then you get three clubs in public on
the table, then there's a betting round,

47
00:02:59,410 --> 00:03:02,500
then you get the fourth card in public
on the table dissipating around.

48
00:03:02,680 --> 00:03:05,650
Then you'll get the five fifth
card on the table is a big raw.

49
00:03:05,680 --> 00:03:09,940
So there's a total of four betting rounds.
And for tranches of inflammation,

50
00:03:09,941 --> 00:03:10,990
revelation,
if you will.

51
00:03:11,110 --> 00:03:15,640
The only the first tranche is private
and then it's public from there.

52
00:03:16,510 --> 00:03:21,510
And this is probably probably by far
the most popular game in AI and just the

53
00:03:25,421 --> 00:03:28,060
general public in terms
of imperfect information.

54
00:03:28,360 --> 00:03:33,040
So that's probably the most
popular spectator game to watch.

55
00:03:33,041 --> 00:03:37,810
Right? So the, which is why it's a
super exciting given tackle. So it's a,

56
00:03:37,811 --> 00:03:41,680
it's on the order of chess,
I would say in terms of popularity,

57
00:03:41,920 --> 00:03:46,120
in terms of the AI, setting it as
the bar of what is intelligence.

58
00:03:46,330 --> 00:03:50,230
So in 2017 liberators,
how do you pronounce it,

59
00:03:50,260 --> 00:03:53,800
really brought us the broadest, the
broadest beats. It'll let him there.

60
00:03:54,070 --> 00:03:57,500
A little bit of Latin. A
Lebron has beads, a few, uh,

61
00:03:57,670 --> 00:04:00,370
for expert human players.

62
00:04:01,030 --> 00:04:04,840
Can you describe that event? What you
learned from it? What was it like?

63
00:04:04,841 --> 00:04:09,390
What was the process in general for people
who have not read the papers and the

64
00:04:09,640 --> 00:04:11,770
study? Yeah. So the event was that, uh,

65
00:04:11,980 --> 00:04:16,300
we invited four or the top 10 players
with these are specialists players in

66
00:04:16,301 --> 00:04:17,680
heads up,
no limit Texas hold'em,

67
00:04:17,710 --> 00:04:22,380
which is very important because this
game is actually quite different than the

68
00:04:22,420 --> 00:04:23,500
multiplayer version.

69
00:04:23,890 --> 00:04:27,910
We brought them in to Pittsburgh
to play at the Rivers Casino, uh,

70
00:04:27,911 --> 00:04:32,770
for 20 days. We wanted to get the
hundred and 20,000 hands in because, uh,

71
00:04:33,100 --> 00:04:35,350
we wanted to get statistical significance.

72
00:04:35,900 --> 00:04:40,900
So it's a lot of hands for humans to
play even for these top pros who play

73
00:04:40,901 --> 00:04:42,100
fairly quickly normally.

74
00:04:42,680 --> 00:04:47,260
So we couldn't just have one of
them play so many hands, 20 days.

75
00:04:47,500 --> 00:04:51,880
They were playing basically
morning to evening and um, uh,

76
00:04:51,881 --> 00:04:55,300
you've raised 200,000 as a little
incentive for them to play.

77
00:04:55,600 --> 00:05:00,320
And the setting was so that
they didn't all get 50,000. Um,

78
00:05:01,030 --> 00:05:05,230
we actually paid them out based on
how they did against the AI each.

79
00:05:05,410 --> 00:05:09,280
So they had an incentive to
play as hard as they could,

80
00:05:09,400 --> 00:05:13,660
whether they're way ahead or way behind
or right at the mark of beating their Ai.

81
00:05:13,720 --> 00:05:17,890
And you don't make any money.
Unfortunately, right now we
can't make any money. So,

82
00:05:17,891 --> 00:05:21,170
so originally a couple of
years earlier, I was, uh,

83
00:05:21,350 --> 00:05:24,940
actually explored whether
we could actually play for
money because that would be

84
00:05:24,941 --> 00:05:29,500
of course a interesting as well, uh, to
play against the top people for money.

85
00:05:29,501 --> 00:05:33,030
But the Pennsylvania gaming board
said no, so, so we couldn't,

86
00:05:33,040 --> 00:05:36,340
so this is much like an exhibit Le uh,

87
00:05:36,370 --> 00:05:40,300
like for a musician or a boxer or
something like that. Nevertheless,

88
00:05:40,301 --> 00:05:43,920
you are keeping track of the
money and brought us, uh,

89
00:05:44,410 --> 00:05:48,670
one close to $2 million I think so.
So if that,

90
00:05:48,690 --> 00:05:51,820
if it was for real money, uh,
if you were able to earn money,

91
00:05:51,821 --> 00:05:55,150
that was a quite impressive
and inspiring achievement.

92
00:05:55,360 --> 00:05:58,820
Just a few details of what,
what were the players looking at?

93
00:05:58,850 --> 00:06:02,420
I mean they were they behind a computer?
What, what was the interface like? Yes.

94
00:06:02,421 --> 00:06:06,470
That they were playing much like they
normally do these top players when they

95
00:06:06,471 --> 00:06:11,090
play this game, they play mostly online.
So they used to playing through a Ui.

96
00:06:11,330 --> 00:06:14,510
Yes. And they did the same thing
here. So there was this layout.

97
00:06:14,511 --> 00:06:18,860
You could imagine there's a
table on the screen, this, the,

98
00:06:19,010 --> 00:06:22,740
the human sitting there. And then
there's the AI sitting there. And the ta,

99
00:06:22,741 --> 00:06:23,680
this Korean source,

100
00:06:23,690 --> 00:06:26,960
everything that's happening in the Chi
is coming out and source the bets being

101
00:06:26,961 --> 00:06:31,670
made. And we also had the best in history
for the human. So if the human, for God,

102
00:06:31,671 --> 00:06:35,870
what had happened in the hand so far, they
could actually reference back and, and,

103
00:06:35,871 --> 00:06:37,960
and, and so forth. Is there a reason

104
00:06:38,360 --> 00:06:40,880
we're given access to
the bedding history for,

105
00:06:41,140 --> 00:06:43,860
well, we, we just, uh, uh, it's,

106
00:06:44,440 --> 00:06:47,350
it didn't really matter that they
wouldn't have focused on any way.

107
00:06:47,351 --> 00:06:51,280
These are top quality people,
but we just wanted to put out there.

108
00:06:51,281 --> 00:06:54,790
So it's not a question of
what human forgetting and
the AI somehow trying to get

109
00:06:54,791 --> 00:06:57,970
that advantage of better memory.
So what was that like? I mean,

110
00:06:57,971 --> 00:07:01,920
that was an incredible accomplishment.
So what did it feel like before

111
00:07:02,000 --> 00:07:04,830
the event?
Did you have doubt,

112
00:07:04,940 --> 00:07:09,470
hope, or what, where was your
confidence at? Yeah, that's great. So,

113
00:07:09,500 --> 00:07:12,500
great question. So, uh, 18 months earlier,

114
00:07:12,530 --> 00:07:16,820
I had organized a similar brains versus
AI competition without previous AI

115
00:07:16,821 --> 00:07:21,260
called Claudico and we couldn't
beat the teams. Uh, so, uh,

116
00:07:21,261 --> 00:07:25,220
at this time around, it was only 18
months later and I knew that this new,

117
00:07:25,270 --> 00:07:27,530
a liberal autos was way stronger,

118
00:07:27,800 --> 00:07:32,060
but it's hard to say how you'll do
against the top humans before you try it.

119
00:07:32,390 --> 00:07:37,390
So I thought we had about a 50 50 shot
and the international betting sites,

120
00:07:37,670 --> 00:07:41,210
both us, us, us as a four to
one or five to one underdog.

121
00:07:41,750 --> 00:07:46,400
So it's kind of interesting that people
really believe in people and I get over

122
00:07:46,401 --> 00:07:50,720
Ai, uh, not just people, people don't
just believe over believe in themselves,

123
00:07:50,721 --> 00:07:54,350
but they have overconfidence in other
people as well compared to the performance

124
00:07:54,351 --> 00:07:56,780
of Ai. And uh, yeah,

125
00:07:56,781 --> 00:08:01,490
so we were a four to one or five to 100
dog and even after three days of beating

126
00:08:01,491 --> 00:08:06,020
the humans in a row, we were still 50,
50. On the international betting sites.

127
00:08:06,500 --> 00:08:09,860
Do you think there's something
special and magical Bob Poker

128
00:08:10,070 --> 00:08:14,870
in the way people think about
it? In a sense you have. I mean,

129
00:08:14,871 --> 00:08:17,300
even in chess,
there's no Hollywood movies.

130
00:08:17,301 --> 00:08:20,870
Poker is the star of many movies.

131
00:08:21,200 --> 00:08:26,200
And there's this feeling that a certain
human facial expressions and body

132
00:08:28,911 --> 00:08:33,140
language, eye movement, all these
towels are critical to poker.

133
00:08:33,320 --> 00:08:34,880
Like you can look into somebody's soul.

134
00:08:35,060 --> 00:08:38,910
I understand they're betting strategy
and so on there. So that's probably

135
00:08:38,910 --> 00:08:43,750
probably why the possibly do you think
that is why people have a confidence that

136
00:08:43,751 --> 00:08:45,440
humans will output?

137
00:08:45,610 --> 00:08:48,850
Because AI systems
cannot in this construct,

138
00:08:48,910 --> 00:08:50,830
perceive these kinds of tells.

139
00:08:51,010 --> 00:08:54,470
They're only looking at
bedding patterns and uh,

140
00:08:55,380 --> 00:08:56,100
and nothing

141
00:08:56,100 --> 00:08:59,070
else. The betting patterns
and, and Statistics.

142
00:08:59,310 --> 00:09:04,310
So what's more important to you if
you step back and human players,

143
00:09:05,881 --> 00:09:10,440
human versus human?
What's the role of these towels of these,

144
00:09:10,910 --> 00:09:14,520
uh, ideas that we romanticize? Yeah. So I,

145
00:09:14,540 --> 00:09:17,430
I'll split it into two parts.
So one is wider.

146
00:09:17,431 --> 00:09:22,431
Humans trust humans more than AI and
all have overconfidence in humans.

147
00:09:23,371 --> 00:09:26,700
Yes. I think that's, that's not really
related. Those are the teller question.

148
00:09:26,940 --> 00:09:29,580
It's just that,
that they've seen these top layers,

149
00:09:29,581 --> 00:09:31,800
how good they are and
they're really fantastic.

150
00:09:32,040 --> 00:09:36,840
So it's just hard to believe the bad or
that the knee, I could beat them. Yeah.

151
00:09:36,841 --> 00:09:38,630
So I think that's where that comes from.
And,

152
00:09:38,790 --> 00:09:42,840
and that's actually maybe a more general
lesson about AI until you've seen it

153
00:09:42,841 --> 00:09:47,720
over perform a human. It's hard to believe
that it could. But, um, then the tailors,

154
00:09:47,810 --> 00:09:51,300
um,
a lot of these top players,

155
00:09:51,510 --> 00:09:56,220
they're so good at hiding tales
that among the top players,

156
00:09:56,221 --> 00:10:01,221
it's actually not really worth it for
them to invest a lot of effort trying to

157
00:10:01,621 --> 00:10:05,130
find tellers in each other because
they're so good at hiding them.

158
00:10:05,610 --> 00:10:09,570
So a yes at the kind
of Friday evening game,

159
00:10:09,800 --> 00:10:11,580
tell us up going to be a huge thing.

160
00:10:11,790 --> 00:10:14,400
You can read other people and
if you're a good reader, you'll,

161
00:10:14,430 --> 00:10:16,290
you'll read them like an open book.

162
00:10:16,410 --> 00:10:19,780
But at the top levels of poker now
the tells become a lesson of much,

163
00:10:19,860 --> 00:10:23,640
much smaller and smaller aspect of
the game. As you go to the top levels,

164
00:10:24,480 --> 00:10:29,300
the amount of strategies, the
minds of possible actions is, um,

165
00:10:29,520 --> 00:10:34,110
is very large, uh, 10 to
the power of hundred plus.

166
00:10:34,520 --> 00:10:36,810
Uh,
so there has to be some,

167
00:10:36,870 --> 00:10:41,870
I've read a few papers related to has
it has to form some abstractions of

168
00:10:42,151 --> 00:10:43,560
various hands and actions.

169
00:10:44,010 --> 00:10:48,810
So what kind of abstractions are
effective for the game of poker?

170
00:10:49,140 --> 00:10:51,330
Yeah, so you're exactly right. So, uh,

171
00:10:51,360 --> 00:10:55,050
when you go from a game
theory that's 10 to the 161,

172
00:10:55,380 --> 00:10:57,690
especially in an imperfect
information game,

173
00:10:57,930 --> 00:11:01,890
it's weight or life to solve directly
even that with our fastest equilibrium

174
00:11:01,891 --> 00:11:04,090
finding algorithms. So, uh,

175
00:11:04,650 --> 00:11:09,650
you want to abstract it first and
abstraction in games is much trickier than

176
00:11:11,101 --> 00:11:16,080
abstraction in MDPs are other single
agent settings because you have these

177
00:11:16,081 --> 00:11:19,620
abstraction pathologies that if I
have a finer grained abstraction,

178
00:11:20,700 --> 00:11:24,390
the strategy that I can get from that
for the real game might actually be worse

179
00:11:24,510 --> 00:11:27,000
than the strategy I can get from
the coarse grained obstruction.

180
00:11:27,170 --> 00:11:29,110
Do you have to be very careful?
Now the,

181
00:11:29,111 --> 00:11:31,080
the kinds of obstruction
is just to zoom out.

182
00:11:31,110 --> 00:11:36,110
We're talking about there's the hands
obstructions and then there's betting

183
00:11:36,571 --> 00:11:39,330
strategies. What wedding actions?
Yeah, beating action. So,

184
00:11:39,331 --> 00:11:43,200
so there's inflammation obstruction.
Talk about general gangs,

185
00:11:43,230 --> 00:11:47,490
inflammation obstruction, which is
the abstraction of what chance does.

186
00:11:47,610 --> 00:11:49,680
And this would be the
cogs indication of poker.

187
00:11:50,100 --> 00:11:52,200
And then there's action abstraction,

188
00:11:52,500 --> 00:11:56,620
which is abstracting the
actions of the actual players,

189
00:11:57,010 --> 00:12:02,010
which would be fits in the case of
poker yourself and the other players and

190
00:12:02,411 --> 00:12:04,800
other players.
And uh,

191
00:12:05,660 --> 00:12:07,930
for inflammation obstruction,

192
00:12:08,290 --> 00:12:13,120
we were completely automated. So
this was, these are algorithms,

193
00:12:13,400 --> 00:12:13,800
uh,

194
00:12:13,800 --> 00:12:17,620
with they do what we call potential aware
abstraction where we don't just look

195
00:12:17,621 --> 00:12:18,790
at the value of the hand,

196
00:12:18,940 --> 00:12:22,510
but also how it might materialize
in the good or bad hands over time.

197
00:12:22,720 --> 00:12:25,100
And it's a certain kind
of bottom up process, uh,

198
00:12:25,240 --> 00:12:29,650
with integer programming
there and clustering and
various aspects how you build,

199
00:12:29,710 --> 00:12:30,880
build this abstraction.

200
00:12:31,450 --> 00:12:35,020
And then in the action abstraction there,

201
00:12:35,200 --> 00:12:38,860
it's largely based on how um,
humans,

202
00:12:38,900 --> 00:12:43,480
other and other ais have played this
game in the past. But in the beginning,

203
00:12:43,870 --> 00:12:47,350
we actually use an automated
action obstruction technology,

204
00:12:47,680 --> 00:12:52,680
which is provably convergent that it finds
the optimal combination or bed sizes,

205
00:12:54,010 --> 00:12:57,280
but it's not very scalable.
So we couldn't use it for the whole game,

206
00:12:57,281 --> 00:13:01,060
but we used it for the first couple of
pitting actions. So what's more important?

207
00:13:01,061 --> 00:13:03,010
Uh,
the strength of the hand.

208
00:13:03,040 --> 00:13:07,160
So the information extraction or the,
uh,

209
00:13:07,180 --> 00:13:11,580
how you play them. Uh, the
actions does it, you know,

210
00:13:11,590 --> 00:13:14,710
the romanticized notion again is
that it doesn't matter what happens,

211
00:13:14,711 --> 00:13:19,240
you have that the actions, the
bedding, uh, maybe the way you win,

212
00:13:19,241 --> 00:13:20,260
no matter what hands here.

213
00:13:20,590 --> 00:13:25,590
So that's why you have to play a lot
of hands so that the role of luck gets

214
00:13:25,921 --> 00:13:26,754
smaller.

215
00:13:26,800 --> 00:13:30,390
So you could otherwise get lucky and get
some good hands and then you're going

216
00:13:30,391 --> 00:13:35,230
to win the match. Even with thousands
of hands, you can get lucky, uh,

217
00:13:35,290 --> 00:13:38,530
because there's so much variance
in no limit Texas hold'em,

218
00:13:38,710 --> 00:13:42,450
because if we both go all
in, it's a huge stack, uh,

219
00:13:42,460 --> 00:13:47,410
or variants or there are these massive
swings in no limit Texas hold'em.

220
00:13:47,800 --> 00:13:50,890
So that's why you have to play
not just thousands, but, uh,

221
00:13:51,310 --> 00:13:55,400
over a hundred thousand hands, they'll
get statistical significance. This is,

222
00:13:55,750 --> 00:14:00,730
let me ask another way. This question,
if you didn't even look at your hands,

223
00:14:02,020 --> 00:14:04,450
but they didn't know that the
opponents didn't know that,

224
00:14:04,580 --> 00:14:08,560
how well would you be able to do? Oh,
that's a good question. There's actually,

225
00:14:08,740 --> 00:14:12,310
I heard the story that there's this
Norwegian female poker player call and it

226
00:14:12,311 --> 00:14:16,480
Oberstar who's actually won a
tournament by doing exactly that,

227
00:14:16,780 --> 00:14:18,310
but that would be extremely rare.

228
00:14:18,720 --> 00:14:23,710
So I cannot really play well. No. Okay.

229
00:14:23,870 --> 00:14:27,520
So, so that the hands do
have some role to play? Yes.

230
00:14:27,820 --> 00:14:30,310
So lowbrow does, does not, uh,

231
00:14:30,311 --> 00:14:33,130
use as far as I understand,

232
00:14:33,131 --> 00:14:38,131
a use learning methods and deep learning
is there room for learning in the,

233
00:14:40,150 --> 00:14:43,570
you know, the, there's no reason
why the US doesn't, you know,

234
00:14:43,630 --> 00:14:48,280
combine with an Alphago type approach for
estimating the quality a four function

235
00:14:48,281 --> 00:14:51,310
estimator.
W what are your thoughts on this?

236
00:14:52,070 --> 00:14:54,800
Maybe as compared to another algorithm,

237
00:14:54,801 --> 00:14:56,950
which I'm not that familiar
with deep stack, the,

238
00:14:56,951 --> 00:15:01,580
the engine that does use deep learning,
that is unclear how well it does,

239
00:15:01,581 --> 00:15:03,320
but nevertheless uses deep learning.

240
00:15:03,470 --> 00:15:08,020
So what are your thoughts about learning
methods to aid in the way that Tele

241
00:15:08,020 --> 00:15:10,590
Broaddus plays the game of
poker? Yeah. So as you said,

242
00:15:10,680 --> 00:15:15,680
Libratone did not use learning methods
and played very well without them.

243
00:15:15,711 --> 00:15:16,281
Since then,

244
00:15:16,281 --> 00:15:21,200
we have actually actually here we have
a couple of papers on things that do use

245
00:15:21,201 --> 00:15:24,660
learning techniques.
Excellent. Uh, so, um, and,

246
00:15:24,661 --> 00:15:27,300
and deep learning in particular and uh,

247
00:15:27,470 --> 00:15:32,240
sort of the way you're talking about
where it's learning and evaluation

248
00:15:32,241 --> 00:15:36,980
function. But um, in
imperfect information games,

249
00:15:37,430 --> 00:15:42,110
unlike let's say in go or now,
now also in chess and Shogee,

250
00:15:42,410 --> 00:15:47,410
it's not sufficient to learn and
evaluation for a state because the

251
00:15:50,240 --> 00:15:55,240
value of an inflammation set
depends not only on the exact state,

252
00:15:55,401 --> 00:15:58,700
but it also depends on
both players beliefs.

253
00:15:59,300 --> 00:16:03,620
Like if I have a bad hand, I'm much
better off if the appointed thinks I'm,

254
00:16:03,670 --> 00:16:06,380
I have a good hand and vice versa.
If I have a good hand,

255
00:16:06,470 --> 00:16:11,300
I'm much better off if the opponent
believes I have a bad hand. Uh,

256
00:16:11,301 --> 00:16:15,080
so the value of our state is not
just a function of the cards,

257
00:16:15,460 --> 00:16:18,950
it depends on a, if you
will, the path of play.

258
00:16:19,580 --> 00:16:24,050
But only do they extent that is captured
in the belief distributions. So,

259
00:16:24,051 --> 00:16:27,200
so that's why it's not a simple as,
uh,

260
00:16:27,340 --> 00:16:30,530
as it is imperfect information games.
And I don't want to say it simple,

261
00:16:30,531 --> 00:16:34,130
they're either, it's of course very
complicated computationally there too.

262
00:16:34,220 --> 00:16:37,280
But at least conceptually it's very
straightforward. There's a state,

263
00:16:37,550 --> 00:16:40,610
there's an evaluation function.
You can try to learn it here.

264
00:16:41,120 --> 00:16:44,030
You have to do something more. Uh, and uh,

265
00:16:44,031 --> 00:16:49,031
what we do is in one of these papers
were looking at allowing where we allow

266
00:16:50,061 --> 00:16:54,050
with the opponent to actually take
different strategies at the leaf of the

267
00:16:54,051 --> 00:16:57,830
search tree yet if you
will. And, and that, uh,

268
00:16:58,160 --> 00:16:59,870
is a different way of doing it.

269
00:16:59,871 --> 00:17:03,680
And it doesn't assume therefore a
particular way that the opponent place,

270
00:17:04,010 --> 00:17:08,900
but it allows our opponent to choose
from a set of different continuation

271
00:17:08,901 --> 00:17:13,901
strategies and that forces us to not be
too optimistic in our look ahead search.

272
00:17:15,530 --> 00:17:18,080
And that's what, that's one way
you can do sound. Look ahead,

273
00:17:18,081 --> 00:17:22,970
search in imperfect information games,
which is very different, difficult.

274
00:17:23,330 --> 00:17:26,840
And in, in, in your ass you were
asking about deep stack, what they did.

275
00:17:27,090 --> 00:17:30,830
If we're very different than what we
do either in [inaudible] or in this new

276
00:17:30,831 --> 00:17:31,664
work,

277
00:17:32,000 --> 00:17:36,050
they were just randomly generating
various situations in the game.

278
00:17:36,440 --> 00:17:40,250
Then they were doing it the look ahead
from there to the end of the game as if

279
00:17:40,251 --> 00:17:42,620
that was a start of a different game.

280
00:17:42,950 --> 00:17:47,900
And then they were using deep learning
to learn those values of those states.

281
00:17:47,900 --> 00:17:50,100
But the states were not
the physical states.

282
00:17:50,280 --> 00:17:52,110
They include the belief distributions.

283
00:17:52,560 --> 00:17:57,560
When you talk about look ahead of war
deep stack or when Luvata's does it mean

284
00:17:59,460 --> 00:18:02,310
considering every possibility
that the game can evolve?

285
00:18:02,640 --> 00:18:07,410
Are we talking about extremely sort of at
this exponential growth of a tree? Yes,

286
00:18:07,500 --> 00:18:09,570
so we're, we're, we're
talking about exactly that

287
00:18:11,370 --> 00:18:15,930
much like you do in Alpha Beta
search or monitor tree research,

288
00:18:15,931 --> 00:18:17,250
but with different techniques.

289
00:18:17,430 --> 00:18:20,880
So there's different search algorithm
and then we have to deal with the leaves

290
00:18:20,881 --> 00:18:23,910
differently.
So if you think about what Librato stayed,

291
00:18:23,970 --> 00:18:27,630
we didn't have to worry about this because
we only did it at the end of the game.

292
00:18:28,560 --> 00:18:33,090
So we would always terminate into a real
situation and we would know what the

293
00:18:33,091 --> 00:18:36,660
payout is. It didn't do this
depth limited local hits.

294
00:18:36,870 --> 00:18:40,530
But now in this new paper,
which is called depth limited,

295
00:18:40,710 --> 00:18:43,710
I think it's called depth limited
search for imperfect information games,

296
00:18:43,890 --> 00:18:47,090
we can actually do sound depth,
the limited local heads.

297
00:18:47,090 --> 00:18:50,790
So we can actually start to do the local
head from the beginning of the game on

298
00:18:51,060 --> 00:18:54,690
because that's too complicated
to do for this whole long game.

299
00:18:54,930 --> 00:18:59,160
So in liberal arts we were just doing it
for the end. So and then the other side,

300
00:18:59,190 --> 00:19:00,720
this belief distribution.

301
00:19:00,721 --> 00:19:05,721
So is it explicitly modeled what kind
of beliefs that the opponent might have?

302
00:19:07,380 --> 00:19:11,550
Yeah, it is explicitly
modeled, but it's not assumed.

303
00:19:11,880 --> 00:19:15,870
The beliefs are actually output,
not input of course,

304
00:19:15,871 --> 00:19:18,720
the starting beliefs,
our input,

305
00:19:18,840 --> 00:19:22,320
but they just fall from the rules of
the game because we know that the dealer

306
00:19:22,321 --> 00:19:24,120
deals uniformly from the deck.

307
00:19:24,420 --> 00:19:29,420
So I know that every pair of cards that
you might have is equally unlikely.

308
00:19:30,450 --> 00:19:33,120
I know that for a fact that just
follows from the rules of the game.

309
00:19:33,180 --> 00:19:37,430
Of course except the two
cards that I have. I know you
don't have those. Yes. Uh,

310
00:19:37,560 --> 00:19:39,870
you have to take that into account.
That's called cod removal.

311
00:19:39,871 --> 00:19:41,940
And that's very important
is as the dealing,

312
00:19:41,941 --> 00:19:46,590
I was coming from a single deck in
heads up. So all can assume single deck,

313
00:19:46,591 --> 00:19:51,090
the as you know, if, if
I have the ace of spades,

314
00:19:51,240 --> 00:19:53,790
I know you don't have an ace of space.
Great.

315
00:19:53,910 --> 00:19:58,860
So in the beginning your
belief is basically the fact
that it's a fair dealing

316
00:19:58,861 --> 00:20:03,090
of hands. But how do you adjust,
start to adjust that belief? Well,

317
00:20:03,240 --> 00:20:07,950
that's where this beauty of game
theory comes. So natural equilibrium,

318
00:20:08,310 --> 00:20:13,310
which John Nash introduce
in 1950 introduces what
rational play is when you have

319
00:20:14,161 --> 00:20:15,030
more than one player.

320
00:20:15,990 --> 00:20:20,310
And these appears or strategies where
strategies are contingency plans,

321
00:20:20,340 --> 00:20:22,820
one for each player.
Uh,

322
00:20:22,860 --> 00:20:27,860
so neither player wants to deviate or
different strategy given that the other

323
00:20:27,960 --> 00:20:30,390
doesn't deviate.
But as a side effect,

324
00:20:30,780 --> 00:20:33,270
you get the beliefs from base role.

325
00:20:33,840 --> 00:20:37,680
So Nash equilibrium really isn't just
deriving in this imperfect information

326
00:20:37,681 --> 00:20:41,310
games, Nash Equilibrium. It
doesn't just define strategies.

327
00:20:41,910 --> 00:20:46,910
It also defines beliefs for both of us
and it refines beliefs for each state.

328
00:20:48,820 --> 00:20:51,410
So at the each state,
each,

329
00:20:51,520 --> 00:20:55,270
if they do call inflammation sits at
each inflammation sets in the game.

330
00:20:55,540 --> 00:20:59,020
There's a set of different
states that we might be in,

331
00:20:59,021 --> 00:21:02,590
but I don't know which one we're in.
It now basically ruined.

332
00:21:02,591 --> 00:21:06,880
Tells me exactly what is a probability
distribution over those real states.

333
00:21:07,180 --> 00:21:12,080
In my mind, how does national, they
give you that distribution. So why?

334
00:21:12,260 --> 00:21:17,190
I'll do a simple example. So you know
the game rock, paper, scissors. So we,

335
00:21:17,230 --> 00:21:21,370
we can draw it. This player one moves
first and then player two moles.

336
00:21:21,610 --> 00:21:26,170
But of course it's important that player
tool doesn't know what player one moved.

337
00:21:26,440 --> 00:21:28,090
Otherwise player tool
would win every time.

338
00:21:28,570 --> 00:21:31,960
So we can draw that as an information
set where player one makes one or three

339
00:21:31,961 --> 00:21:35,740
moves first and then there's an
inflammation set for player too.

340
00:21:36,210 --> 00:21:40,360
So player to doesn't know which
of those nodes, the world.

341
00:21:40,390 --> 00:21:41,350
A world is it.

342
00:21:42,430 --> 00:21:46,570
Once we know the strategy for player one
Nash Equilibrium will say that the play

343
00:21:46,571 --> 00:21:49,060
one third rock, one third
paper, one third seizures.

344
00:21:49,390 --> 00:21:53,230
From that I can derive my beliefs on the
information set that they're one third

345
00:21:53,231 --> 00:21:56,810
one third one third. There's a bays
gives you that there's an issue.

346
00:21:57,580 --> 00:22:01,350
But is that specific to a
particular player or is it uh,

347
00:22:01,410 --> 00:22:06,410
is it something you quickly update with
the Muslim with game theory isn't really

348
00:22:07,541 --> 00:22:11,610
player specific. So that's what
also why we don't need any data. Uh,

349
00:22:11,710 --> 00:22:15,130
we don't need any history
how these particular humans
played in the past or how

350
00:22:15,131 --> 00:22:17,020
any AI or human had played before.

351
00:22:17,440 --> 00:22:20,140
It's all about rationality.

352
00:22:20,260 --> 00:22:25,160
So we just take the AI just thinks about
what would our rational upon it do and

353
00:22:25,300 --> 00:22:29,330
what would I do if I were, I am
rushing island. What's that? That's,

354
00:22:29,331 --> 00:22:30,700
that's idea of game theory.

355
00:22:31,090 --> 00:22:35,560
So it's really a data free
opponent free approach.

356
00:22:35,590 --> 00:22:39,850
So comes from the design of the game
as opposed to the design of the player.

357
00:22:40,090 --> 00:22:43,360
Exactly. There's no opponent
modeling per se. I mean,

358
00:22:43,361 --> 00:22:46,360
we've done some work on combining
opponent modeling with Game Theory.

359
00:22:46,361 --> 00:22:48,520
So they're going to exploit
weak players even more.

360
00:22:48,820 --> 00:22:51,040
But that's another
strand and in Libra does.

361
00:22:51,041 --> 00:22:55,330
We didn't turn that on because I decided
that these players are too good and

362
00:22:55,331 --> 00:22:59,710
when you start to exploit an opponent,
you typically open yourselves up,

363
00:22:59,740 --> 00:23:04,270
self up to exploitation and these guys
have so few holes to exploit and their

364
00:23:04,271 --> 00:23:06,550
world's leading experts
in counter exploitation.

365
00:23:06,760 --> 00:23:08,930
So I decided that and that we're not
the kind of tenant that stuff on.

366
00:23:09,220 --> 00:23:13,240
Actually I saw a few papers
in a exploiting opponents
and sound very interesting

367
00:23:13,241 --> 00:23:17,890
to uh, explore. Uh, do you think
there's room for exploitation, Jay?

368
00:23:17,891 --> 00:23:22,400
Generally outside of Libre
is, is there a subject, uh,

369
00:23:22,630 --> 00:23:27,630
or people differences that could be
exploited maybe not just in poker but in

370
00:23:28,361 --> 00:23:30,490
general interactions and negotiations,

371
00:23:30,491 --> 00:23:34,420
all of these other domains that you're
considering? Yeah, I definitely,

372
00:23:34,720 --> 00:23:39,100
we've done some work on that and I eat
a really like their work at hybridizes

373
00:23:39,101 --> 00:23:43,960
that too. So you figure out what were
the rational upon it. And by the way,

374
00:23:43,961 --> 00:23:46,760
that's safe in these sum games to players.

375
00:23:46,761 --> 00:23:49,430
There were some games because if the
opponent does something irrational,

376
00:23:49,580 --> 00:23:52,040
yes it might show a throw off my beliefs,

377
00:23:53,090 --> 00:23:58,090
but the amount that the player can gain
by throwing off my belief is always less

378
00:23:59,180 --> 00:24:03,920
than they lose by playing
poorly. So, so it's safe. But uh,

379
00:24:03,980 --> 00:24:06,560
still if somebody's weak as a player,

380
00:24:06,740 --> 00:24:11,150
you might want to play differently to
exploit them more so that you can think

381
00:24:11,151 --> 00:24:14,870
about it this way,
a game theoretic strategies on a beatable,

382
00:24:15,620 --> 00:24:19,630
but it doesn't maximally
beat other opponents.

383
00:24:19,631 --> 00:24:24,050
So the winnings per hand might be
better with a different strategy.

384
00:24:24,260 --> 00:24:28,040
And the hybrid is that you start from a
game theoretic approach and then as you

385
00:24:28,041 --> 00:24:32,480
gain data from the, about the opponent
in certain parts of the game tree,

386
00:24:32,600 --> 00:24:34,190
that in those parts of the game three,

387
00:24:34,400 --> 00:24:39,400
you start to tweak your strategy more
and more towards exploitation while still

388
00:24:39,951 --> 00:24:42,110
staying fairly close to the
game theoretic strategy.

389
00:24:42,180 --> 00:24:46,400
So as to not open yourself
up to exploitation too much.

390
00:24:46,810 --> 00:24:49,060
How, how do you do that? Do you, um,

391
00:24:49,580 --> 00:24:54,470
try to vary up strategies, make
it unpredictable? It's like, uh,

392
00:24:55,100 --> 00:24:59,720
uh, what is it a tit for tat strategies
in, um, prisoner's dilemma or

393
00:25:00,730 --> 00:25:04,040
well, Italian that that's a repeated
game kind of compete against,

394
00:25:04,130 --> 00:25:07,570
that's right in this dilemma
repeated games. But, but even there,

395
00:25:07,571 --> 00:25:09,790
there's no proof that says
that that's the best thing.

396
00:25:10,090 --> 00:25:11,650
But experimentally it actually,
yeah.

397
00:25:11,650 --> 00:25:15,070
Does, does, does well, so what kind
of games are there? First of all,

398
00:25:15,370 --> 00:25:18,940
I don't know if this is something that
you could just summarize that there's

399
00:25:19,180 --> 00:25:22,090
perfect information games where all
the information is on the table.

400
00:25:22,420 --> 00:25:25,120
There is imperfect information games,

401
00:25:25,480 --> 00:25:28,060
there's repeated games that
you play over and over.

402
00:25:28,570 --> 00:25:32,170
There's a zero sum games.
Uh,

403
00:25:32,470 --> 00:25:34,740
there's non zero sum games.
Yeah.

404
00:25:35,410 --> 00:25:37,570
And then there's a really
important distinction.

405
00:25:37,571 --> 00:25:42,220
You're making a two player
versus more players. So what are,

406
00:25:43,280 --> 00:25:46,210
what other games are there and
what's the difference? For example,

407
00:25:46,211 --> 00:25:49,720
with this two player
game versus more players,

408
00:25:50,020 --> 00:25:52,830
what are the key differences in review?
So let me start from the,

409
00:25:54,080 --> 00:25:54,710
the basic.

410
00:25:54,710 --> 00:25:59,710
So a repeated game is a game where the
same exact game is played it over and

411
00:26:01,921 --> 00:26:06,120
over in these extensive form games.
Uh,

412
00:26:06,180 --> 00:26:10,260
where I think about three form maybe
with these inflammation says to represent

413
00:26:10,290 --> 00:26:11,540
incomplete information.

414
00:26:12,450 --> 00:26:15,690
You can have kind of
repetitive interactions.

415
00:26:15,890 --> 00:26:19,730
Even repeated games are a special
case of that by the way. But uh,

416
00:26:20,430 --> 00:26:24,540
the game doesn't have to be exactly the
same. It's like in sourcing origins. Yes,

417
00:26:24,541 --> 00:26:27,360
we're going to see you the
same supply base year to year.

418
00:26:27,450 --> 00:26:29,730
But what I'm buying is a
little different every time.

419
00:26:29,731 --> 00:26:32,550
And the supply base is a little
different every time and so on.

420
00:26:32,551 --> 00:26:33,960
So it's not really repeated.

421
00:26:34,260 --> 00:26:38,190
So to find a purely repeated game
is actually very rare in the world.

422
00:26:38,670 --> 00:26:42,810
So they're really a very, uh,
course model of what's going on.

423
00:26:43,620 --> 00:26:47,490
Then if you move up from
repair, just repeated, simple,

424
00:26:47,491 --> 00:26:51,570
repeated matrix games. Uh, not all
the way to extensive form of games,

425
00:26:51,571 --> 00:26:55,590
but in between there stochastic
games where you know,

426
00:26:55,620 --> 00:26:57,480
there's these,
uh,

427
00:26:57,750 --> 00:27:02,430
you think about it like these little
matrix games and when you take an action

428
00:27:02,460 --> 00:27:03,960
and your text in action,

429
00:27:04,170 --> 00:27:09,000
they determine not which next date
I'm going to next game I'm going to,

430
00:27:09,090 --> 00:27:13,130
but the distribution of our next games
where I might be going through there.

431
00:27:13,360 --> 00:27:17,180
So that's the stochastic game,
but it's like major schemes,

432
00:27:17,190 --> 00:27:18,870
repeated stochastic games,

433
00:27:18,960 --> 00:27:23,330
extensive form games that is
from less to more general and,

434
00:27:23,331 --> 00:27:26,070
and poker is an example of the last one.

435
00:27:26,220 --> 00:27:31,220
So it's really in the most general sitting
extensive form games and that's kind

436
00:27:31,251 --> 00:27:36,251
of what the Ai community has been working
on and been benched marked on with

437
00:27:36,451 --> 00:27:39,630
this heads up. No limit. Texas hold'em,
can you describe an extensive form games?

438
00:27:39,720 --> 00:27:44,040
What's the, what's the motto here? So
if you're a present with the tree form,

439
00:27:44,310 --> 00:27:45,630
so it's really the tree form.

440
00:27:45,750 --> 00:27:49,890
Like in chess there's a search tree
versus a major third. It's a matrix here.

441
00:27:50,070 --> 00:27:50,881
And uh,

442
00:27:50,881 --> 00:27:54,600
that the new matrix is called the matrix
form or by matrix form or normal form

443
00:27:54,601 --> 00:27:58,560
game and here you have the tree forms
so you can actually do certain types of

444
00:27:58,561 --> 00:28:03,561
reasoning there that you
lose the information when
you go the normal phone as

445
00:28:04,350 --> 00:28:06,930
say there's a certain form of equivalence.

446
00:28:06,931 --> 00:28:11,880
Like if you go from three form and you
said every possible contingency plan is a

447
00:28:11,881 --> 00:28:12,660
strategy,

448
00:28:12,660 --> 00:28:16,500
then I can actually go back to the normal
form but they lose some information

449
00:28:16,501 --> 00:28:18,240
from the lack of sequence reality.

450
00:28:18,570 --> 00:28:22,800
Then the multiplayer versus two player
distinction is an important one.

451
00:28:22,830 --> 00:28:27,830
So two player games in zero sum are
conceptually easier and computational

452
00:28:32,191 --> 00:28:35,840
easier. The steel huge like
this one, this one, eh,

453
00:28:36,000 --> 00:28:38,790
but they're conceptually
easier and computational,

454
00:28:38,791 --> 00:28:43,791
easier in that conceptually you don't
have to worry about which equilibrium is

455
00:28:43,891 --> 00:28:48,090
the other guy going into play when there
are multiple because any equilibrium

456
00:28:48,091 --> 00:28:51,570
strategy is a best response to
any other equilibrium strategy.

457
00:28:51,930 --> 00:28:55,980
So I can play a different equilibrium
from you and we'll still get the right

458
00:28:55,981 --> 00:28:59,190
values of the game that falls
apart even with two players.

459
00:28:59,191 --> 00:29:02,670
When you heard general some games,
even with our cooperation,

460
00:29:02,700 --> 00:29:04,410
just even without cooperation.

461
00:29:04,740 --> 00:29:09,660
So there's a big gap from two players
here are to top layer general some or even

462
00:29:09,661 --> 00:29:13,920
two, three players there. Awesome. That's
a, that's a big gap at least in theory.

463
00:29:14,250 --> 00:29:19,250
Can you maybe none mathematically provide
intuition while falls apart with three

464
00:29:20,461 --> 00:29:22,350
or more players? Uh, it's,

465
00:29:22,351 --> 00:29:25,770
it seems like you should still be able
to have a national equilibrium that

466
00:29:27,330 --> 00:29:31,650
yeah. That that's
instructive. That holds, okay.

467
00:29:31,770 --> 00:29:36,770
So it is true that all finite
games have a nash equilibrium,

468
00:29:37,770 --> 00:29:42,050
right? So this is what John Nash
actually proved. So they do have a nash

469
00:29:42,050 --> 00:29:43,820
equilibrium.
That's not the problem.

470
00:29:43,821 --> 00:29:48,440
The problem is that there can be many
and then there's a question of which

471
00:29:48,441 --> 00:29:50,630
equilibrium to select.
So,

472
00:29:50,631 --> 00:29:54,440
and if you select your strategy from a
different equilibrium and I select mine,

473
00:29:56,370 --> 00:29:59,950
they then did what does
that mean? Uh, and,

474
00:30:00,010 --> 00:30:01,820
and in these non zero sum games,

475
00:30:02,030 --> 00:30:06,980
we may lose some joints benefit where
her by being just simply stupid.

476
00:30:06,981 --> 00:30:09,700
We could actually both be better
off if we did something else. Yes.

477
00:30:09,830 --> 00:30:12,800
And in three player you get other
problems. Also like collusion,

478
00:30:13,160 --> 00:30:18,160
like maybe you and I can get up on a third
player and we can do radically better

479
00:30:18,891 --> 00:30:21,770
by color coding. So that are, there
are lots of issues that come up there.

480
00:30:22,170 --> 00:30:26,820
So no brown student you work
with on this has mentioned, uh,

481
00:30:26,910 --> 00:30:28,890
I looked through the Ama on reddit.

482
00:30:29,310 --> 00:30:33,060
He mentioned that the ability of poker
players to collaborate, we make the game.

483
00:30:33,720 --> 00:30:38,580
He was asked the question of how would
you make the game of poker or both of you

484
00:30:38,581 --> 00:30:41,070
were asked the question, how would
you make the game of poker, uh,

485
00:30:41,350 --> 00:30:46,350
beyond being solvable
by current AI methods?

486
00:30:46,980 --> 00:30:51,980
And he said that there's not many
ways of making poker more difficult,

487
00:30:52,170 --> 00:30:53,910
uh,
but uh,

488
00:30:53,911 --> 00:30:57,590
collaboration or cooperation
between players, uh,

489
00:30:57,750 --> 00:30:59,550
would make it extremely difficult.

490
00:30:59,730 --> 00:31:03,420
So can you provide the intuition
behind why that is? Uh,

491
00:31:03,450 --> 00:31:05,190
if you agree with that idea?

492
00:31:05,290 --> 00:31:07,870
Yeah, so, uh, we, uh,
I've done a lot of work,

493
00:31:08,050 --> 00:31:12,780
a coalitional games and we actually
have a paper here with my other student,

494
00:31:12,790 --> 00:31:15,330
couple of [inaudible] and
some other collaborators on a,

495
00:31:15,440 --> 00:31:19,200
an on that actually just came back from
the poster session where we presented.

496
00:31:19,720 --> 00:31:22,410
But, uh, so, uh, when you
have a collusion, it's a,

497
00:31:22,420 --> 00:31:25,960
it's a different problem and it
typically gets even harder then

498
00:31:27,490 --> 00:31:29,320
even the game representations,

499
00:31:29,560 --> 00:31:34,450
some of the game representations don't
really allow yeah. Would a computation,

500
00:31:34,451 --> 00:31:39,340
so we actually introduced a
new game representation for,
for that. Is that kind of

501
00:31:39,640 --> 00:31:43,090
[inaudible] part of the model
is, are you, do you have,

502
00:31:43,690 --> 00:31:47,350
do you have information about the fact
that other players are cooperating or is

503
00:31:47,351 --> 00:31:50,950
it just this chaos? There were,
nothing is known so, so there's some,

504
00:31:50,951 --> 00:31:51,910
something's unknown.

505
00:31:52,330 --> 00:31:57,330
Can you give an example of a collusion
type game or is it used breach?

506
00:31:58,160 --> 00:32:01,520
Right. So think about bridge. It's
like when you and I are on a team,

507
00:32:02,300 --> 00:32:06,660
I'll pay offs are the same. The
problem is that we can't talk. So,

508
00:32:06,680 --> 00:32:09,950
so when I get my car, because I can't
whisper to you what my cards are,

509
00:32:10,310 --> 00:32:12,990
that would not be allowed. So, uh,

510
00:32:13,190 --> 00:32:18,190
we have to somehow coordinate our
strategies ahead of time and only ahead of

511
00:32:19,431 --> 00:32:22,520
time. And then there are certain
signals that we can talk about,

512
00:32:22,760 --> 00:32:27,380
but they have to be such that the other
team also understands that. So, uh,

513
00:32:27,381 --> 00:32:28,131
so that,
that's,

514
00:32:28,131 --> 00:32:32,270
that's an example where the coordination
is already built into the rules of the

515
00:32:32,271 --> 00:32:32,960
game.

516
00:32:32,960 --> 00:32:37,960
But in many other situations like
auctions or negotiations or diplomatic

517
00:32:38,570 --> 00:32:42,440
relationships, poker,
it's not really built in,

518
00:32:42,710 --> 00:32:45,110
but it still can be very
helpful for the colluders.

519
00:32:45,480 --> 00:32:50,480
I've read you write somewhere
the negotiations you come
to the table with prior,

520
00:32:52,390 --> 00:32:55,150
uh,
like a strategy that like,

521
00:32:55,160 --> 00:32:57,890
that you're willing to do and not
willing to do those kinds of things.

522
00:32:58,310 --> 00:33:03,310
So how do you start to now moving away
from poker movie beyond poker into other

523
00:33:03,831 --> 00:33:07,610
applications like negotiations?
How do you start applying this to other,

524
00:33:08,180 --> 00:33:12,440
to other domains? Yeah. Even real
world domains that you've worked on.

525
00:33:12,480 --> 00:33:15,450
Yeah, I actually have two startup
companies doing exactly that.

526
00:33:15,480 --> 00:33:19,950
One is called strategic machine and
that's for kind of beans in applications,

527
00:33:19,980 --> 00:33:22,830
gaming, sports, all sorts
of things like that.

528
00:33:22,890 --> 00:33:27,640
Any applications of these two
business and two sports at doe,

529
00:33:27,950 --> 00:33:32,780
uh, gaming too about various
types of things for in finance,

530
00:33:32,781 --> 00:33:36,290
electricity markets and so on.
And the other is called strategy robot,

531
00:33:36,560 --> 00:33:40,520
where we are taking this
to a military security,

532
00:33:40,610 --> 00:33:42,950
cybersecurity and
intelligence applications.

533
00:33:43,480 --> 00:33:48,300
I think you've worked a
little bit in, um, how,

534
00:33:48,310 --> 00:33:52,950
how do you put it to advertisement,
sort of suggesting, um,

535
00:33:53,110 --> 00:33:54,580
ads kind of thing.

536
00:33:54,630 --> 00:33:57,780
Yeah. Auction, that's another
company optimized markets optimize,

537
00:33:57,781 --> 00:34:02,250
but that's much more about a combinatorial
market and optimization based

538
00:34:02,251 --> 00:34:06,600
technology that's not using these a
game theoretic reasoning technologies.

539
00:34:06,820 --> 00:34:07,511
I see.
Okay.

540
00:34:07,511 --> 00:34:12,511
So what sort of high level do you think
about our ability to use game theoretic

541
00:34:15,941 --> 00:34:18,640
concepts to model human behavior?
Do you think,

542
00:34:19,000 --> 00:34:22,810
do you think human behavior is
amenable to this kind of modeling?

543
00:34:23,020 --> 00:34:26,830
So outside of the poker games and where
have you seen it done successfully in

544
00:34:26,831 --> 00:34:30,520
your work? I'm not
sure. The goal really is

545
00:34:30,920 --> 00:34:34,580
modeling humans. Uh, like for example,

546
00:34:34,581 --> 00:34:36,370
if I'm playing a zero sum game,
yes,

547
00:34:36,470 --> 00:34:41,470
I don't really care that the opponent
is actually following in my model of

548
00:34:41,541 --> 00:34:44,270
rational behavior because if they're not,

549
00:34:44,800 --> 00:34:48,680
that's even better for
me. Right. So, so the sea,

550
00:34:48,700 --> 00:34:50,560
the opponents and games,
there's a,

551
00:34:51,090 --> 00:34:56,090
the prerequisite is that you formalize
the interaction in some way that can be

552
00:34:58,810 --> 00:35:00,430
amenable to analysis.

553
00:35:00,970 --> 00:35:04,090
And you've done this amazing
work with mechanism design,

554
00:35:04,091 --> 00:35:08,940
designing games that have
certain outcomes. Uh,

555
00:35:10,000 --> 00:35:14,890
but so I'll tell you an example from my,
from my world of autonomous vehicles,

556
00:35:14,900 --> 00:35:19,480
right? We're studying
pedestrians, pedestrians and cars,

557
00:35:19,490 --> 00:35:21,880
negotiating this nonverbal communication.

558
00:35:22,120 --> 00:35:27,120
There's this weird game dance of tension
where pedestrians are basically saying,

559
00:35:27,251 --> 00:35:31,780
I trust that you won't kill me. And so
as a Jaywalker will step onto the road,

560
00:35:31,781 --> 00:35:35,710
even though I'm breaking the law and
there's this tension and the question is,

561
00:35:35,740 --> 00:35:40,380
would really don't know how to model
well in trying to model intent.

562
00:35:40,650 --> 00:35:44,610
And so people sometimes bring up
ideas and game theory and so on.

563
00:35:44,820 --> 00:35:49,820
Do you think that aspect of human
behavior can use these kinds of imperfect

564
00:35:50,881 --> 00:35:54,660
information approaches modeling?
How do we,

565
00:35:54,870 --> 00:35:57,910
how do you start to attack
a problem like that? Uh,

566
00:35:58,010 --> 00:36:03,010
when you don't even know how the game
design and game to describe the situation

567
00:36:03,090 --> 00:36:03,960
in order to solve it?

568
00:36:04,250 --> 00:36:08,130
Okay, so I haven't really thought about
Jay walking by. One thing that, uh,

569
00:36:08,330 --> 00:36:12,710
I think would be a good application in
an autonomous vehicles is the following.

570
00:36:12,980 --> 00:36:17,510
So let's say that you have fleets of
autonomous car as operating by different

571
00:36:17,511 --> 00:36:22,070
companies. So maybe here's the way more
fleet. And here's the Uber Fleet. Uh,

572
00:36:22,071 --> 00:36:26,540
if you think about the rules of the road,
they define certain legal rules,

573
00:36:26,541 --> 00:36:31,220
but that still leaves a huge strategy
space open. Like as a simple example,

574
00:36:31,221 --> 00:36:33,890
when cars merge, you know
how he must merge, you know,

575
00:36:33,891 --> 00:36:38,891
there's low down and look at each
other and tried to tried to merge.

576
00:36:39,231 --> 00:36:43,160
Wouldn't they do better
if these situations would
all repeat pre negotiated.

577
00:36:43,430 --> 00:36:47,150
So we can actually merge at full speed
and we know that this is the situation,

578
00:36:47,420 --> 00:36:50,000
this is how we do it and
it's all going to be faster.

579
00:36:50,510 --> 00:36:53,600
But there are way too many
situations to negotiate manually.

580
00:36:54,080 --> 00:36:57,050
So you could use automated negotiation.
This is the idea,

581
00:36:57,051 --> 00:37:01,130
at least you could use automated
negotiation to negotiate all of these

582
00:37:01,131 --> 00:37:05,840
situations or many of them in advance.
And of course it might be that, hey,

583
00:37:06,680 --> 00:37:10,190
maybe you're not going to always let
me go first. Maybe you said, okay,

584
00:37:10,191 --> 00:37:12,260
well in these situations
I'll let you go first.

585
00:37:12,410 --> 00:37:14,500
But in exchange you're
going to give me two arms.

586
00:37:14,510 --> 00:37:17,120
You're gonna let me go first
in this situation. Yes.

587
00:37:17,240 --> 00:37:19,850
So it's this huge
combinatorial negotiation.

588
00:37:20,670 --> 00:37:24,690
And do you think there's room in
that example of merging two model,

589
00:37:24,691 --> 00:37:28,200
this whole situation is an imperfect
information game or do you really want to

590
00:37:28,201 --> 00:37:29,550
consider it to be a perfect

591
00:37:30,110 --> 00:37:33,240
no, that's a good question.
Yeah, that's a good question.

592
00:37:33,630 --> 00:37:38,490
Pay The price of a assuming
that you don't know everything.

593
00:37:39,760 --> 00:37:43,720
Yeah, I don't know. It's certainly much
easier games with perfect inflammation,

594
00:37:43,721 --> 00:37:47,810
a much easier. So if you
can get away with it, uh,

595
00:37:48,080 --> 00:37:52,360
you should. But if the real situation
is of imperfect information,

596
00:37:52,630 --> 00:37:55,060
then you're going to have to deal
with and for imperfect information.

597
00:37:55,140 --> 00:38:00,060
Great. So what lessons have you learned
the annual computer poker competition?

598
00:38:00,690 --> 00:38:03,390
An incredible accomplishment of Ai.
You know,

599
00:38:03,391 --> 00:38:06,540
you look at the history
of the Blue Alphago,

600
00:38:06,990 --> 00:38:11,990
these kind of moments when AI stepped
up in an engineering effort and a

601
00:38:12,331 --> 00:38:16,650
scientific effort combined to, to
beat the best human player. So what,

602
00:38:16,651 --> 00:38:19,470
what do you take away from
this whole experience?

603
00:38:19,471 --> 00:38:21,210
What have you learned about designing?

604
00:38:21,211 --> 00:38:23,910
It has systems that play
these kinds of games.

605
00:38:23,970 --> 00:38:26,910
And what does that mean for sort of,
uh,

606
00:38:27,090 --> 00:38:30,120
AI in general for the
future of Iai Development?

607
00:38:30,740 --> 00:38:34,340
Yeah. So that's a good question. Uh,
so there's so much to say about it.

608
00:38:35,410 --> 00:38:38,860
I do like these type of
performance oriented research,

609
00:38:39,130 --> 00:38:42,850
although in my group we go all
the way from idea to theory,

610
00:38:42,900 --> 00:38:45,970
the experiments to big system
fielding the commercialization.

611
00:38:45,971 --> 00:38:50,590
So we spend that spectrum by, but I
think that in a lot of situations in AI,

612
00:38:51,070 --> 00:38:56,020
you really have to build the big systems
and evaluate them at scale before you

613
00:38:56,021 --> 00:38:57,370
know what works and doesn't.

614
00:38:57,790 --> 00:39:01,990
And we've seen that in the computational
game theory community if there are a

615
00:39:01,991 --> 00:39:04,240
lot of techniques that
look good in this mall,

616
00:39:05,170 --> 00:39:06,880
but then this is to
look good in the large.

617
00:39:07,120 --> 00:39:12,120
And we've also seen that there are a
lot of techniques that look superior in

618
00:39:12,191 --> 00:39:13,024
theory.

619
00:39:13,300 --> 00:39:17,160
And I really mean in evenings
or convergence rates better
like first autometrix

620
00:39:17,170 --> 00:39:21,640
better convergence rates, like the CFR
based bits, algorithms you have the CFR,

621
00:39:21,641 --> 00:39:24,520
Bay based Algorithms are
the fastest in practice.

622
00:39:24,850 --> 00:39:28,240
So it really tells me that you
have to test this. In reality,

623
00:39:28,241 --> 00:39:30,880
the theory isn't tight enough,
if you will,

624
00:39:30,881 --> 00:39:35,470
to tell you which algorithms are
better than the others. And, uh,

625
00:39:35,530 --> 00:39:38,380
you have to look at these
things that in the large,

626
00:39:38,560 --> 00:39:42,250
because any sorts of projections you'd
all from the small can at least in this

627
00:39:42,251 --> 00:39:44,940
domain be very misleading.
So that, that's kind of from,

628
00:39:44,941 --> 00:39:47,500
from our kind of a science
and engineering perspective.

629
00:39:47,530 --> 00:39:52,140
From a personal perspective, it's been
just a wild experience in that, uh,

630
00:39:52,210 --> 00:39:55,810
with the first poker
competition, the first, uh,

631
00:39:56,260 --> 00:39:59,680
brains versus AI and machine barker
competition that we organized,

632
00:39:59,800 --> 00:40:01,750
there had been, by the
way, for other poker games,

633
00:40:01,751 --> 00:40:04,990
there had been previous competitions,
but this was no heads up, no limit.

634
00:40:05,000 --> 00:40:07,150
This was the first.
And uh,

635
00:40:07,420 --> 00:40:11,770
I probably became the most hated person
in the world of poker and I didn't mean

636
00:40:11,771 --> 00:40:16,360
to cry. I size that, the crack
in the game for, so yeah,

637
00:40:16,420 --> 00:40:20,950
it was a lot of people felt that it
was a real threat to the whole game,

638
00:40:21,400 --> 00:40:25,240
the whole existence of the game. If,
if, if AI becomes better than humans,

639
00:40:26,050 --> 00:40:30,100
people would be scared to play poker
because there are these superhuman AI is

640
00:40:30,101 --> 00:40:33,550
running around taking their money and
you know, all of that sort of, so I just,

641
00:40:33,820 --> 00:40:37,810
it's just really aggressive. Uh,
the comments were super aggressive.

642
00:40:37,930 --> 00:40:40,840
I got everything.
Just short of death threats.

643
00:40:42,160 --> 00:40:43,990
Do you think the same was true for chess?

644
00:40:43,991 --> 00:40:48,310
Cause right now they just completed the
world championships and chess and humans

645
00:40:48,311 --> 00:40:52,510
just started ignoring the fact that
there is AI systems now that I'll perform

646
00:40:52,511 --> 00:40:55,470
humans and they still enjoy the game
is still a beautiful game. He's,

647
00:40:55,510 --> 00:40:59,200
that's what I think. And I think the
same thing happens in poker as a,

648
00:40:59,201 --> 00:41:02,560
so I didn't think of myself as somebody
who was going to kill the game and I

649
00:41:02,561 --> 00:41:05,620
don't think I did. Yeah, I've
really learned to love of this game.

650
00:41:05,621 --> 00:41:07,000
I wasn't the poker player before,

651
00:41:07,001 --> 00:41:11,800
but learn so many nuances about it from
these ais and they've really changed how

652
00:41:11,801 --> 00:41:13,000
the game's played by the way.

653
00:41:13,210 --> 00:41:17,440
So they have these very Martian ways of
playing poker and the dop humorous are

654
00:41:17,441 --> 00:41:22,270
now incorporating those types
of strategies into their
own play. So if anything,

655
00:41:22,271 --> 00:41:27,160
to me,
our work has made poker a richer,

656
00:41:27,161 --> 00:41:29,380
more interesting game for humans to play.

657
00:41:29,800 --> 00:41:33,320
Not something that is going to
steer humans away from it entirely.

658
00:41:34,250 --> 00:41:35,990
Just a quick comment
and something you said,

659
00:41:35,991 --> 00:41:40,991
which is if I may say so an academia
is a little bit rare sometimes it is,

660
00:41:42,930 --> 00:41:45,570
it's a pretty brave to put
your ideas to the test.

661
00:41:45,571 --> 00:41:49,530
And the way you described saying that
it's sometimes good ideas don't work when

662
00:41:49,531 --> 00:41:54,210
you actually tried to apply them at scale.
And so where does that come from?

663
00:41:54,211 --> 00:41:59,110
I mean, what if you could do,
um, advice for people? What,

664
00:41:59,120 --> 00:42:02,670
what drives you in that sense?
Will you always this way? I mean,

665
00:42:02,730 --> 00:42:05,280
it takes a brave person,
I guess is what I'm saying.

666
00:42:05,281 --> 00:42:10,260
To test their ideas and to see if this
thing actually works against human top

667
00:42:10,261 --> 00:42:11,140
human players and

668
00:42:11,270 --> 00:42:14,220
so on. Yeah. I don't know about
brave, but it takes a lot of work.

669
00:42:14,680 --> 00:42:19,420
It takes a lot of work and a lot
of time, uh, to organize, do,

670
00:42:19,421 --> 00:42:22,650
make something big and to organize
an event and stuff like that.

671
00:42:22,950 --> 00:42:26,910
And what drives you in that effort?
Because you could still, I would argue,

672
00:42:26,911 --> 00:42:31,440
get a best paper award at nips as
you did in 17 without doing this.

673
00:42:31,441 --> 00:42:35,910
That's right. Yes. And
so, uh, so in, in general,

674
00:42:35,911 --> 00:42:39,110
I believe it's very important
to do things in eh, in,

675
00:42:39,130 --> 00:42:42,830
in the real world and at scale.
And that's really where the,

676
00:42:44,120 --> 00:42:48,030
the, the pudding, if you're will proof
is in the pudding. That's where it is.

677
00:42:48,360 --> 00:42:49,830
In this particular case,

678
00:42:50,040 --> 00:42:55,040
it was kind of a competition between
different groups and for many years as to

679
00:42:57,121 --> 00:43:00,990
who can be the first one to beat the
top humans at heads up, no limit.

680
00:43:00,991 --> 00:43:05,760
Texas hold'em. So the game,
eh, it became kind of, uh, uh,

681
00:43:06,130 --> 00:43:09,780
or, uh, like a competition
who can get there. Yeah.

682
00:43:09,781 --> 00:43:14,340
So a little friendly competition can
be a can do wonders for progress. Yes.

683
00:43:16,310 --> 00:43:17,140
So

684
00:43:17,140 --> 00:43:19,900
the topic of mechanism design,
which is really interesting,

685
00:43:19,901 --> 00:43:23,790
also kind of new to me except
as an observer of, I dunno,

686
00:43:23,830 --> 00:43:28,100
politics and Amy, I'm an
observer of mechanisms, but you,

687
00:43:28,250 --> 00:43:33,190
you write in your paper and the automated
mechanism design that I quickly read

688
00:43:34,000 --> 00:43:38,770
some mechanisms design is designing the
rules of the game so you get a certain

689
00:43:38,771 --> 00:43:43,771
desirable outcome and you have this work
on doing so in an automatic fashion as

690
00:43:45,071 --> 00:43:49,810
opposed to fine tuning it. So what
have you learned from those efforts?

691
00:43:50,240 --> 00:43:54,410
Uh, if we look, say I dunno
at a complex like, um,

692
00:43:54,680 --> 00:43:55,810
our political system,

693
00:43:56,260 --> 00:44:00,970
can we design our political system
to have in an automated fashion,

694
00:44:01,370 --> 00:44:05,980
uh, to have outcomes that we want?
Can we design something like, um,

695
00:44:06,520 --> 00:44:08,890
traffic lights to be smart?

696
00:44:08,930 --> 00:44:12,060
It where it gets outcomes that we want.
So what,

697
00:44:12,061 --> 00:44:15,340
what are the lessons that you
draw from that work? Yeah,

698
00:44:15,341 --> 00:44:19,690
so I still very much believe in the
automated mechanism design direction. Yes.

699
00:44:20,850 --> 00:44:22,590
But it's not a panacea.

700
00:44:22,980 --> 00:44:27,480
There are impossibility results in
mechanism design saying that there is no

701
00:44:27,481 --> 00:44:32,481
mechanism that accomplices
objective x in Class C so,

702
00:44:34,250 --> 00:44:36,060
so it,
it's not going up.

703
00:44:36,110 --> 00:44:41,110
There's no way you using any mechanism
design tools manual or automated to do

704
00:44:41,281 --> 00:44:45,780
certain things in mechanism
design. He came. Describe
that again. So meaning there,

705
00:44:45,810 --> 00:44:47,380
it's impossible to achieve.
That

706
00:44:49,380 --> 00:44:52,580
would likely impossible.
So saw these are,

707
00:44:52,670 --> 00:44:56,100
these are not statements about human
ingenuity date who might come up with

708
00:44:56,101 --> 00:44:56,934
something smart.

709
00:44:57,060 --> 00:45:02,060
These approves that if you want to
accomplish properties x in Class C,

710
00:45:02,430 --> 00:45:04,050
that is not doable with any mechanism.

711
00:45:04,860 --> 00:45:08,850
The good thing about automated mechanism
design is that we're not really

712
00:45:08,851 --> 00:45:13,460
designing for a class. We're designing
for specific settings at a title.

713
00:45:14,070 --> 00:45:17,790
So even if there's any possibility
that result for the whole class,

714
00:45:18,180 --> 00:45:22,500
it just doesn't mean that all of the
cases in the class are impossible.

715
00:45:22,501 --> 00:45:24,660
It just means that some of
the cases are impossible.

716
00:45:24,990 --> 00:45:29,700
So we can actually carve these islands
of possibility within these noni possible

717
00:45:29,701 --> 00:45:31,890
classes.
And we've actually done that.

718
00:45:31,891 --> 00:45:35,750
So what one of the famous results in
mechanism design is some Irish and

719
00:45:35,751 --> 00:45:40,350
Satterthwaite theorem for by Roger
Myerson and Mark Satterthwaite from 1983.

720
00:45:40,920 --> 00:45:44,880
It's an impossibility of efficient
trade under imperfect information.

721
00:45:45,150 --> 00:45:50,130
We show that you can in many settings
avoid that and get the efficient trade

722
00:45:50,131 --> 00:45:53,760
anyway, depending on how
the design the game. Okay.

723
00:45:53,761 --> 00:45:57,350
So depending on how you design the
game, man, of course it's not a,

724
00:45:57,351 --> 00:45:59,940
it doesn't in any way, any way. Uh,

725
00:46:00,180 --> 00:46:03,540
contradicting possibility was Arthur
in possibility results is still there,

726
00:46:03,840 --> 00:46:08,840
but it just a finance sports within this
impossible class where in those sports

727
00:46:10,741 --> 00:46:15,390
you don't have the possibility, sorry
if I'm going a bit philosophical, but a,

728
00:46:15,391 --> 00:46:17,390
what lessons do you draw towards,

729
00:46:17,400 --> 00:46:22,400
like I mentioned politics or human
interaction and designing mechanisms for

730
00:46:23,190 --> 00:46:27,900
outside of just these kinds
of trading or auctioning or

731
00:46:30,930 --> 00:46:34,650
purely formal games are human interaction
like a political system? What,

732
00:46:34,890 --> 00:46:38,160
how can you think it's applicable to yeah.

733
00:46:38,310 --> 00:46:42,630
Politics or to business,

734
00:46:42,780 --> 00:46:46,200
uh, to negotiations,
these kinds of things.

735
00:46:46,230 --> 00:46:51,090
Designing rules that have certain
outcomes. Yeah. Yeah. I do think so.

736
00:46:51,300 --> 00:46:55,140
Have you seen success that
successfully done the didn't really,

737
00:46:55,200 --> 00:46:58,910
oh you mean mechanism design or
automated automated mechanisms zone. So,

738
00:46:58,920 --> 00:47:03,920
so mechanism design itself has
had fairly limited success so far.

739
00:47:06,390 --> 00:47:11,390
There are certain cases but most of the
real world situations are actually not

740
00:47:12,240 --> 00:47:14,340
sound from a mechanism design perspective.

741
00:47:14,580 --> 00:47:18,750
Even in those cases where they've been
designed by very knowledgeable mechanism

742
00:47:18,751 --> 00:47:19,680
designed people,

743
00:47:19,950 --> 00:47:24,210
the people are typically just taking some
insights from the theory and applying

744
00:47:24,211 --> 00:47:29,010
those insights into the real world rather
than applying the mechanisms directly.

745
00:47:29,200 --> 00:47:33,850
So one famous example is the
FCC spectrum auctions. So,

746
00:47:33,851 --> 00:47:37,990
um, uh, I've also had a
small role in that and uh,

747
00:47:38,410 --> 00:47:42,220
very good economists have been word
excellent economists have been working on

748
00:47:42,221 --> 00:47:46,710
that we'll know game theory yet the rules
that are designed in practice there,

749
00:47:47,100 --> 00:47:51,130
they were such at beating
truthful is not the best strategy.

750
00:47:51,760 --> 00:47:52,930
Usually mechanism design.

751
00:47:52,931 --> 00:47:57,340
We tried to make things easy for the
participants saw telling the truth is the

752
00:47:57,341 --> 00:47:59,440
best strategy.
But uh,

753
00:47:59,470 --> 00:48:03,040
but even in those very high
stakes auctions where you
have tens of billions of

754
00:48:03,040 --> 00:48:07,930
dollars worth of spectrum auction,
truth telling is not the best strategy.

755
00:48:08,770 --> 00:48:09,970
And,
and by the way,

756
00:48:09,971 --> 00:48:13,630
nobody knows even a single optimal
bidding strategy for those auctions.

757
00:48:14,120 --> 00:48:15,810
What's the challenge of
coming up with an optimum?

758
00:48:15,900 --> 00:48:18,150
Because there's a lot of
players and there's impersonal,

759
00:48:18,260 --> 00:48:20,020
it's almost a lot of players,

760
00:48:20,021 --> 00:48:25,021
but many items for sale and the these
mechanisms are such that even with just

761
00:48:25,331 --> 00:48:30,220
two items or one item breeding
truthfully wouldn't be the best strategy.

762
00:48:31,360 --> 00:48:34,270
If you look at the history of Ai,

763
00:48:34,570 --> 00:48:36,460
it's marked by seminal events,

764
00:48:36,950 --> 00:48:39,880
Alpha go beating the world
champion human goal player.

765
00:48:40,150 --> 00:48:42,370
I would put [inaudible]
winning the heads up.

766
00:48:42,371 --> 00:48:45,340
No limit hold'em is one of
those such event. Thank you.

767
00:48:46,700 --> 00:48:47,800
What do you think

768
00:48:49,390 --> 00:48:51,550
is the next such event,

769
00:48:52,540 --> 00:48:57,540
whether it's in your life or
in the broadly AI community
that you think might be

770
00:48:58,301 --> 00:49:01,000
out there that would surprise the world?

771
00:49:01,560 --> 00:49:05,390
So that's a great question and under
really know the answer in terms of game

772
00:49:05,391 --> 00:49:08,270
solving a heads up,
no limit.

773
00:49:08,271 --> 00:49:13,271
Texas hold'em really was the one
remaining widely agreed upon benchmark.

774
00:49:14,390 --> 00:49:18,120
So that was the big milestone.
Now are there other things? Yes,

775
00:49:18,121 --> 00:49:18,891
certainly there are,

776
00:49:18,891 --> 00:49:22,580
but there is not one that the
community has kind of focused on.

777
00:49:22,910 --> 00:49:27,290
So what could it be? Other things,
there are groups working on starcraft,

778
00:49:27,650 --> 00:49:31,550
there are groups working on Dota
two. These are video games. Yes.

779
00:49:31,580 --> 00:49:36,230
Or You could have like
diplomacy or Hanabi, you know,

780
00:49:36,231 --> 00:49:40,410
things like that. These are
like recreational games,
but none of them are uh,

781
00:49:40,790 --> 00:49:45,790
really acknowledged as kind of the main
next challenge problem like chess or go

782
00:49:47,181 --> 00:49:49,670
or heads up. No limit. Texas hold'em was,

783
00:49:49,940 --> 00:49:53,270
so I don't really know in the
game solving space what is a,

784
00:49:53,360 --> 00:49:55,220
what will be the next benchmark.

785
00:49:55,370 --> 00:49:58,710
I hope kind of hope that they will be
an expense mark because the really the

786
00:49:58,910 --> 00:50:03,770
different groups working on the same
problem really drove these application

787
00:50:03,771 --> 00:50:06,980
independent techniques for board
very quickly, over 10 years.

788
00:50:07,460 --> 00:50:09,980
Do you think there's an open
problem that excites you,

789
00:50:09,981 --> 00:50:14,981
that you start moving away from
games into real world games?

790
00:50:15,001 --> 00:50:19,110
Like say the stock market trading? Yeah.
So that's, that's kind of how I am.

791
00:50:19,260 --> 00:50:24,260
So I am probably not going to work as
hard on these recreational benchmarks.

792
00:50:27,620 --> 00:50:30,170
Uh, I'm doing two startups
on game solving technology,

793
00:50:30,171 --> 00:50:32,270
strategic machine and strategy robot.

794
00:50:32,271 --> 00:50:36,380
Then we're really interested in
pushing this stuff into practice.

795
00:50:37,400 --> 00:50:42,340
What do you think would
be a really, you know, uh,

796
00:50:43,110 --> 00:50:47,780
a powerful result that'd be
surprising. That would, would be, um,

797
00:50:48,720 --> 00:50:53,190
if you can say, I mean the, you
know, five years, 10 years from now,

798
00:50:53,191 --> 00:50:56,790
something that statistically
you would say is not

799
00:50:56,870 --> 00:51:01,850
very likely, but if there's a
breakthrough, what achieve? Yeah.

800
00:51:01,851 --> 00:51:06,851
So I think at the overall we're in a
very different situation in game theory

801
00:51:08,960 --> 00:51:12,770
then we are in, let's say, machine
learning. Yes. So in machine learning,

802
00:51:12,771 --> 00:51:17,771
it's a fairly mature technology and it's
very broadly applied and proven success

803
00:51:18,470 --> 00:51:22,700
in the real world in game solving.
There are almost no applications yet.

804
00:51:24,440 --> 00:51:26,150
We have just become superhuman,

805
00:51:26,630 --> 00:51:30,440
which machine learning you could argue
happened in the 90s, if not earlier,

806
00:51:31,520 --> 00:51:33,600
and uh,
at least unsupervised supervised learning,

807
00:51:33,680 --> 00:51:35,870
certain complex supervised
learning applications.

808
00:51:37,670 --> 00:51:41,240
Now I think the next challenge problem,
I know you're not asking about this way,

809
00:51:41,241 --> 00:51:44,240
you're, you're asking, but the technology
breakthrough, but I think that big,

810
00:51:44,241 --> 00:51:46,310
big breakthrough is to be able to show at,
hey,

811
00:51:46,820 --> 00:51:50,690
maybe most of let's say military
planning or most of business strategy,

812
00:51:50,780 --> 00:51:55,280
we'll actually be done strategically using
computational game theory that that's

813
00:51:55,281 --> 00:51:58,010
what I would like to see as
the next five or 10 year goals.

814
00:51:58,380 --> 00:52:02,670
Maybe you can explain to me again, forgive
me if this is an obvious question, but,

815
00:52:03,060 --> 00:52:03,571
uh,
you know,

816
00:52:03,571 --> 00:52:08,340
machine learning methods and all networks
are suffer from not being transparent

817
00:52:08,341 --> 00:52:12,870
and they'd be explainable I game theoretic
methods, you know, Nash Equilibria.

818
00:52:12,900 --> 00:52:16,410
Do they generally, when you see
the different solutions, are they,

819
00:52:17,100 --> 00:52:20,580
uh, when you, when you talk about
military operations, are they,

820
00:52:20,610 --> 00:52:22,290
once you see the strategies,

821
00:52:22,291 --> 00:52:26,340
do they make sense of they explainable
or do they suffer from the same problems

822
00:52:26,341 --> 00:52:29,190
as you know? And that works too.
So that's, that's a good question.

823
00:52:29,220 --> 00:52:31,650
I would say a little bit yes and no.

824
00:52:31,710 --> 00:52:36,630
And while what I mean by that is
that these games are the strategies,

825
00:52:36,660 --> 00:52:40,590
let's say Nash Equilibrium,
it has provable properties.

826
00:52:40,770 --> 00:52:44,820
So it's unlike let's say, deep learning
where you're kind of cross your fingers,

827
00:52:44,940 --> 00:52:48,210
hopefully it'll work. And then after
the fact when you have the weights,

828
00:52:48,360 --> 00:52:52,500
you're still crossing your fingers
and I hope it will work. Uh, here.

829
00:52:52,560 --> 00:52:56,930
You know that the solution qualities
there, this provable solution,

830
00:52:56,970 --> 00:52:57,990
quality guarantees.

831
00:52:58,530 --> 00:53:03,120
Now that doesn't necessarily mean that
the strategies are human. Understandable.

832
00:53:03,480 --> 00:53:05,210
That's a whole other problem.
So as I,

833
00:53:05,211 --> 00:53:09,630
so I think it deep learning
and computational game
theory are in the same boat

834
00:53:09,631 --> 00:53:12,600
in that sense that both are
difficult to understand,

835
00:53:13,750 --> 00:53:15,640
but at least the game
theoretic techniques,

836
00:53:15,641 --> 00:53:19,540
they have these guarantees
of sort of quality.

837
00:53:19,810 --> 00:53:22,860
So did you see business operations,
strategic operations,

838
00:53:22,880 --> 00:53:24,760
even military in the future,

839
00:53:25,980 --> 00:53:26,791
at least the,

840
00:53:26,791 --> 00:53:31,791
the strong candidates being
proposed by automated systems?

841
00:53:32,760 --> 00:53:33,660
Do you see that?

842
00:53:33,980 --> 00:53:36,170
Yeah, I do. I do. But
that's more of a belief,

843
00:53:36,270 --> 00:53:40,710
belief then a and a substantiated
fact depending on where you land,

844
00:53:40,910 --> 00:53:44,840
optimism or pessimism. And that's a
really, to me, that's an exciting future.

845
00:53:45,710 --> 00:53:50,180
Especially if there's a provable
things in terms of optimality.

846
00:53:50,570 --> 00:53:53,450
So looking into the future,

847
00:53:54,050 --> 00:53:58,520
there's a few folks worried about the,

848
00:53:58,790 --> 00:54:01,220
especially you look at the game of poker,

849
00:54:01,221 --> 00:54:05,270
which is probably one of the last
benchmarks in terms of games being solved.

850
00:54:05,480 --> 00:54:10,070
They, they worry about the future and
the existential threats of artificial

851
00:54:10,071 --> 00:54:13,880
intelligence. So the negative
impact in whatever form on society.

852
00:54:13,881 --> 00:54:18,881
Is that something that concerns you as
much or are you more optimistic about the

853
00:54:19,281 --> 00:54:20,990
positive impacts of AI?

854
00:54:21,230 --> 00:54:26,230
Oh, I am much more optimistic about the
positive impacts. So just in my own work,

855
00:54:26,231 --> 00:54:29,620
what we've done so far, but we run
the nation where kidneys change.

856
00:54:29,920 --> 00:54:33,700
Hundreds of people are walking
around alive today, who would it be?

857
00:54:34,060 --> 00:54:36,550
And it's increased employment.
You have,

858
00:54:36,580 --> 00:54:40,690
you have a lot of people now running
kidney changes and at the transplant

859
00:54:40,691 --> 00:54:44,860
centers interacting with
the kidney exchange,

860
00:54:45,550 --> 00:54:50,110
you have extra surgeons, nurses,
anesthesiologists, hospitals,

861
00:54:50,380 --> 00:54:51,690
all of that.
And so,

862
00:54:51,700 --> 00:54:54,970
so employment is increasing from that
and the world is becoming a better place.

863
00:54:55,300 --> 00:54:59,840
Another example is a common
authorial sourcing auctions. We uh,

864
00:54:59,860 --> 00:55:04,860
did 800 large scale combinatorial
sourcing options from 2001 to 2010,

865
00:55:06,700 --> 00:55:10,340
uh, in a previous startup of
mine called combine it. And, um,

866
00:55:11,110 --> 00:55:16,110
we increased the supply chain efficiency
on that $60 billion of spend by 12.6%.

867
00:55:18,220 --> 00:55:22,240
So that's over $6 billion of
efficiency improvement in the world.

868
00:55:22,420 --> 00:55:25,180
And this is not like shifting value
from somebody to somebody else.

869
00:55:25,420 --> 00:55:28,270
Just efficiency improvement
like in trucking,

870
00:55:28,390 --> 00:55:33,220
less empty driving so there's less waste,
less carbon footprint and so on.

871
00:55:33,760 --> 00:55:36,550
It's a huge positive
impact in the near term,

872
00:55:36,880 --> 00:55:39,560
but sort of tea to stay in it for,

873
00:55:39,660 --> 00:55:42,610
for a little longer because I
think game theory has a role

874
00:55:42,700 --> 00:55:45,400
in play here. Well let, let me actually
come back and do that. That is one thing.

875
00:55:45,520 --> 00:55:50,200
I think AI is also going to make
the world much safer. So, uh,

876
00:55:50,201 --> 00:55:54,240
so, so that's another aspect
that often gets overlooked. What,

877
00:55:54,250 --> 00:55:55,860
let me ask this question,
maybe I can speak

878
00:55:55,860 --> 00:56:00,100
to the safer. So I talked to Max
Tegmark and Stuart Russell, uh,

879
00:56:00,150 --> 00:56:02,850
who are very concerned about
existential threats of Ai.

880
00:56:02,851 --> 00:56:06,420
And often the concern is
about value misalignment.

881
00:56:06,421 --> 00:56:11,421
So Ai Systems basically a working,

882
00:56:12,060 --> 00:56:16,830
operating towards goals that are
not the same as human civilization,

883
00:56:16,890 --> 00:56:21,840
human beings. So it seems like game
theory has a role to play there. Uh,

884
00:56:23,210 --> 00:56:27,870
two to make sure the values
are aligned with human beings.

885
00:56:28,050 --> 00:56:30,750
I don't know if that's how
you think about it. If not,

886
00:56:31,490 --> 00:56:35,650
how do you think AI might help
with this problem? Uh, how,

887
00:56:35,690 --> 00:56:39,860
how do you think AI might
make the world safer? Yeah,

888
00:56:39,890 --> 00:56:44,890
I think this value is alignment is a
fairly theoretical worry and I haven't

889
00:56:47,961 --> 00:56:51,890
really seen it in it cause I
do a lot of real applications.

890
00:56:52,010 --> 00:56:53,910
I don't see it anywhere.
Uh,

891
00:56:54,050 --> 00:56:58,640
the closest I've seen it was the following
type of mental exercise really where

892
00:56:59,000 --> 00:57:01,910
I had this argument in the late
eighties when we were building these

893
00:57:01,911 --> 00:57:05,240
transportation optimization systems and
somebody had to hear it and it's a good

894
00:57:05,241 --> 00:57:09,270
idea to have high utilization of assets.
So they told me I take,

895
00:57:09,290 --> 00:57:11,030
why don't you put that as the objective?

896
00:57:11,570 --> 00:57:15,980
And we didn't even pull it as an
objective because I just showed him at,

897
00:57:16,010 --> 00:57:18,530
you know,
if you had that as your objective,

898
00:57:18,590 --> 00:57:21,860
the solution would be the load
your trucks fallen driving circles,

899
00:57:22,030 --> 00:57:24,890
nothing would ever get delivered.
You'd have a hundred percent utilization.

900
00:57:25,040 --> 00:57:29,810
So yeah, I know this phenomenon, I've
known this for over 30 years in about,

901
00:57:29,811 --> 00:57:34,160
but I've never seen it actually be a
problem. Reality in reality. And yes,

902
00:57:34,161 --> 00:57:35,390
if you have the wrong objective,

903
00:57:35,391 --> 00:57:39,560
the AI will optimize that to the hilt
and it's going to hurt more than some

904
00:57:39,561 --> 00:57:40,820
human who's kind of trying to

905
00:57:42,680 --> 00:57:46,080
solve within a half baked way with
some human insight too. But I,

906
00:57:46,120 --> 00:57:48,450
I just haven't seen that
materialize in practice.

907
00:57:49,310 --> 00:57:54,310
There's this gap that you've actually
put your finger on very clearly just now

908
00:57:54,950 --> 00:57:59,000
between theory and reality.
That's very difficult to put into words.

909
00:57:59,001 --> 00:58:03,330
I think it's what you can
theoretically imagine. Uh,

910
00:58:03,360 --> 00:58:06,740
the worst possible case
or even, yeah, I mean,

911
00:58:06,770 --> 00:58:11,630
bad cases and what usually happens
in reality. So for example,

912
00:58:11,631 --> 00:58:15,970
to me, maybe it's something you can
comment on. Uh, having grown up in,

913
00:58:16,010 --> 00:58:19,150
I grew up in the Soviet Union,
you know,

914
00:58:19,250 --> 00:58:24,170
there's currently 10,000 nuclear weapons
in the world and for many decades.

915
00:58:24,320 --> 00:58:29,320
It's a theoretically a surprising to me
that the nuclear war is not broken out.

916
00:58:31,010 --> 00:58:35,960
Do you think about this aspect is from
a game theoretic perspective in general,

917
00:58:36,200 --> 00:58:41,030
why is that true?
A why in theory you could see how

918
00:58:41,280 --> 00:58:44,850
things will go terribly wrong and
somehow yet they have not. Yeah.

919
00:58:45,660 --> 00:58:47,370
So I do think that that about that a lot.

920
00:58:47,371 --> 00:58:50,250
I think the biggest two threats
that we're facing as mankind,

921
00:58:50,460 --> 00:58:54,180
one is climate change and
others nuclear war. So as, as,

922
00:58:54,190 --> 00:58:57,670
so those are my main two worries
that that worry about. And I,

923
00:58:57,671 --> 00:58:59,730
I've tried to do something about climate,

924
00:58:59,840 --> 00:59:03,570
had thought about trying to do something
for climate change twice actually

925
00:59:04,000 --> 00:59:05,150
before two of my startups.

926
00:59:05,151 --> 00:59:09,870
I've actually commissioned studies of
what we could do on those things and we

927
00:59:09,871 --> 00:59:12,810
didn't really find a sweet spot,
but I'm still keeping an eye out on that.

928
00:59:12,811 --> 00:59:16,710
If there's something where we could
actually provide a market's a lotion or

929
00:59:16,711 --> 00:59:21,711
optimizations law or some other
technology solution to problems right now.

930
00:59:21,850 --> 00:59:26,540
Um, like for example, pollution critic
markets was what we were looking at them.

931
00:59:26,900 --> 00:59:28,040
And it was much more,

932
00:59:28,130 --> 00:59:33,130
the lack of political will by those
markets were not so successful rather than

933
00:59:33,561 --> 00:59:36,980
bad market design. So I could go
in and make a Beta market design,

934
00:59:37,250 --> 00:59:40,580
but that wouldn't really move the needle
on the world very much if there's no

935
00:59:40,581 --> 00:59:43,630
political will. And in the u
s you know, the market, uh,

936
00:59:43,631 --> 00:59:47,660
at least the Chicago market was just
shut down, uh, uh, and, and so on.

937
00:59:47,661 --> 00:59:50,720
So it doesn't really help how
great your market design was.

938
00:59:51,220 --> 00:59:52,900
And then the nuclear side,

939
00:59:53,140 --> 00:59:56,980
it's more so global warming
is a more encroaching

940
00:59:59,430 --> 01:00:03,180
problem, you know, nuclear
weapons. I've been here,

941
01:00:03,450 --> 01:00:07,020
it's an obvious problem, has just been
sitting there. So how do you think about,

942
01:00:07,620 --> 01:00:12,620
what is the mechanism design there that
just made everything seem stable and are

943
01:00:12,751 --> 01:00:13,410
you

944
01:00:13,410 --> 01:00:17,240
still extremely worried? I am
still extremely worried. So yeah,

945
01:00:17,241 --> 01:00:21,720
you probably know the simple game
theory of mad. So, so, so, uh, at least,

946
01:00:22,100 --> 01:00:24,530
uh, mutually assured
destruction and it's lazy.

947
01:00:24,540 --> 01:00:27,510
It doesn't require any computation
with small matrix eats.

948
01:00:27,511 --> 01:00:30,420
You can actually convince yourself that
the game is such that nobody wants to

949
01:00:30,421 --> 01:00:31,950
initiate. Hmm. Yeah,

950
01:00:31,951 --> 01:00:36,951
that's a very coarse grained analysis
and it really works in a situation where

951
01:00:37,021 --> 01:00:40,560
you have two superpowers or
small number of super powers.

952
01:00:40,561 --> 01:00:41,820
Now things are very different.

953
01:00:42,090 --> 01:00:47,090
You have a smaller nukes or the threshold
of initiating a smaller and you have

954
01:00:48,031 --> 01:00:53,031
smaller countries and non non nation
actors who make it an org sense.

955
01:00:53,640 --> 01:00:57,600
I won. So it's, I think it's riskier
now than it was maybe ever before.

956
01:00:58,450 --> 01:01:03,280
And what idea application of Ai,

957
01:01:03,790 --> 01:01:07,600
you've talked about a little bit, but what
is the most exciting to you right now?

958
01:01:07,700 --> 01:01:08,100
I mean you,

959
01:01:08,100 --> 01:01:13,100
you're here at nips new Europe's now
you have few excellent pieces of work.

960
01:01:15,091 --> 01:01:18,000
But what are you thinking into the future
with several companies you're doing?

961
01:01:18,001 --> 01:01:20,820
What's the most exciting thing
or one of the exciting things?

962
01:01:21,260 --> 01:01:25,940
The number one thing for me right now
is coming up with these a scalable

963
01:01:25,941 --> 01:01:30,941
techniques for game solving and applying
them into the real world that I was

964
01:01:31,271 --> 01:01:34,710
still very interested in market design
as well and we're doing that in optimize

965
01:01:34,760 --> 01:01:35,540
markets,

966
01:01:35,540 --> 01:01:39,740
but I'm most interested if number one
right now is strategic machine strategy

967
01:01:39,741 --> 01:01:40,160
robot.

968
01:01:40,160 --> 01:01:44,600
Getting that technology out there and
seeing as you were in the trenches doing

969
01:01:44,601 --> 01:01:47,240
applications,
what needs to be actually filled,

970
01:01:47,270 --> 01:01:49,580
what technology gaps
still need to be filled.

971
01:01:49,910 --> 01:01:53,330
So it's so hard to just put your feet on
the table and imagine what needs to be

972
01:01:53,331 --> 01:01:56,270
done. But when you're actually
doing real applications,

973
01:01:56,380 --> 01:01:59,060
the applications tell you
what needs to be done.

974
01:01:59,270 --> 01:02:00,860
And I really enjoy that interaction.

975
01:02:00,960 --> 01:02:05,960
Is it a challenging process to apply
some of the state of the art techniques

976
01:02:06,241 --> 01:02:11,241
you're working on and having the various
players in industry or the military or

977
01:02:15,901 --> 01:02:18,870
people who could really benefit from it,
actually use it?

978
01:02:19,170 --> 01:02:21,450
What's that process like of,
you know,

979
01:02:21,451 --> 01:02:24,890
in autonomous vehicles will work with
automotive companies and they're, uh,

980
01:02:24,920 --> 01:02:29,190
in in many ways are a little bit
old fashioned. It's difficult.

981
01:02:29,400 --> 01:02:31,950
They really want to use this technology.

982
01:02:31,951 --> 01:02:34,470
There's clearly will have
a significant benefit,

983
01:02:34,740 --> 01:02:39,740
but the systems aren't quite in place to
easily have them integrated in terms of

984
01:02:40,801 --> 01:02:44,410
data, in terms of compute, in terms of
all of these kinds of things. So do you,

985
01:02:44,640 --> 01:02:49,640
is that one of the bigger challenges that
you're facing and how you tackle that

986
01:02:49,711 --> 01:02:50,220
challenge?

987
01:02:50,220 --> 01:02:50,461
Yeah,

988
01:02:50,461 --> 01:02:54,060
I think that's always the challenge
that that's kind of slowness and inertia

989
01:02:54,061 --> 01:02:57,500
really of let's do things
the way we've always done it.

990
01:02:57,830 --> 01:03:02,060
You just have to find the
internal champions at the
customer who understand that

991
01:03:02,061 --> 01:03:04,460
hey, things can't be the
same way in the future,

992
01:03:04,640 --> 01:03:08,530
otherwise bad things are going to happen.
And it's in autonomous vehicles.

993
01:03:08,550 --> 01:03:11,290
It's actually very interesting that the
car makers are doing that and they're

994
01:03:11,300 --> 01:03:12,170
very traditional.

995
01:03:12,380 --> 01:03:15,350
But at the same time you have tech
companies who have nothing to do with the

996
01:03:15,351 --> 01:03:20,351
cars or transportation like Google and
Baidu really pushing on autonomous cars.

997
01:03:21,830 --> 01:03:23,090
I find that fascinating.

998
01:03:23,210 --> 01:03:28,100
Clearly you're super excited
about actually these ideas
having an impact in the

999
01:03:28,101 --> 01:03:32,420
world. Uh, in terms of the technology,
in terms of ideas and research.

1000
01:03:32,620 --> 01:03:37,620
Are there directions they you're also
excited about whether that's on the,

1001
01:03:39,410 --> 01:03:42,410
some of the approaches you talked about
for the imperfect information games,

1002
01:03:42,740 --> 01:03:45,080
whether it's applying deep learning,
just some of these problems.

1003
01:03:45,081 --> 01:03:49,310
Is there something that you're excited
and in the research side of things? Yeah.

1004
01:03:49,400 --> 01:03:53,150
Yeah. Lots of different things
in the game solving. Uh,

1005
01:03:53,151 --> 01:03:58,100
so solving even bigger games,
uh, games where you have, um,

1006
01:03:58,700 --> 01:04:01,990
more he didn't action of the
play your actions as well. Uh,

1007
01:04:02,000 --> 01:04:06,630
poker is a game where really the chance
actions are hidden or some of them are

1008
01:04:06,631 --> 01:04:08,480
hidden,
but to play your actions are public.

1009
01:04:11,150 --> 01:04:14,800
It multiplayer games of various sorts,
collusion,

1010
01:04:15,270 --> 01:04:18,350
a opponent exploitation,
all,

1011
01:04:18,351 --> 01:04:23,150
all and an even longer games.
Some games that basically go forever,

1012
01:04:23,151 --> 01:04:27,890
but they're not repeated. So seek
extensive on games that go forever.

1013
01:04:28,550 --> 01:04:31,850
What would that even look like? How do
you represent that? How do you solve that?

1014
01:04:32,000 --> 01:04:34,940
What's an example of a game like
that? Oh, this is the sum of this.

1015
01:04:34,941 --> 01:04:37,040
The classic games that you mentioned,
that's a business strategy.

1016
01:04:37,310 --> 01:04:40,580
So it's not just modeling
like a particular interaction,

1017
01:04:40,820 --> 01:04:45,820
but thinking about the business from
here to eternity or r I c or like let's

1018
01:04:46,701 --> 01:04:50,840
say, um, military strategy. So it's
not like war is going to go away.

1019
01:04:51,030 --> 01:04:55,400
How do you the think about military
strategy that's going to go forever.

1020
01:04:56,690 --> 01:04:57,900
How do you even model that?

1021
01:04:58,080 --> 01:05:03,080
How do you know whether a move was
good that you use somebody made and,

1022
01:05:03,861 --> 01:05:06,760
and, and, and so on. Uh, so that,
that's kind of one direction.

1023
01:05:06,970 --> 01:05:11,970
I'm also very interested in learning
much more scalable techniques for integer

1024
01:05:12,401 --> 01:05:13,234
programming.

1025
01:05:13,450 --> 01:05:18,450
So we had a nice EML paper this summer
on that for the Automated Algorithm

1026
01:05:18,641 --> 01:05:23,350
configuration paper that has
theoretical generalization guarantees.

1027
01:05:23,560 --> 01:05:28,240
So if I see these many training examples
and I told my algorithm and this way

1028
01:05:28,570 --> 01:05:31,690
it's going to have good performance
on the real distribution,

1029
01:05:31,691 --> 01:05:35,380
which have not seen. So we just
kind of interesting that, you know,

1030
01:05:35,410 --> 01:05:40,300
algorithm configuration has been
going on now for at least 17 years.

1031
01:05:40,301 --> 01:05:44,860
Seriously. And there has not been
any generalization her theory before.

1032
01:05:45,970 --> 01:05:49,870
Well this is really exciting and has been,
it's a huge honor to talk to you.

1033
01:05:49,871 --> 01:05:52,030
Thank you. Summarize to us.
Thank you for bringing the,

1034
01:05:52,031 --> 01:05:54,310
brought us to the world and all
the great work you're doing. Well,

1035
01:05:54,311 --> 01:05:56,350
thank you very much. It's
been fun. Good questions.

