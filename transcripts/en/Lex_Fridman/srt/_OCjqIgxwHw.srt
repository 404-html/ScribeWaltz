1
00:00:00,090 --> 00:00:05,090
Welcome back to six as zero,
nine for deep learning for self driving 

2
00:00:05,090 --> 00:00:09,201
cars.
Today we will talk about autonomous 

3
00:00:12,111 --> 00:00:17,111
vehicles,
also referred to as driverless cars,

4
00:00:18,500 --> 00:00:21,020
autonomous cars,
robot cars.

5
00:00:22,640 --> 00:00:27,640
First,
the Utopian view where for many 

6
00:00:29,510 --> 00:00:34,490
autonomous vehicles have the opportunity
to transform our society into a positive

7
00:00:34,491 --> 00:00:39,491
direction.
One point 3 million people die every 

8
00:00:39,491 --> 00:00:43,391
year in automobile crashes globally.
Thirty five,

9
00:00:43,971 --> 00:00:45,440
38,
40,000

10
00:00:45,441 --> 00:00:50,441
die every year in the United States,
so the one opportunity that's huge.

11
00:00:51,230 --> 00:00:56,230
That's one of the biggest focus for us 
here and mit for people who truly care 

12
00:00:56,571 --> 00:01:01,571
about this is to design the autonomous 
systems are artificial intelligence 

13
00:01:01,571 --> 00:01:06,371
systems that say lies and those systems 
help work with deal with or take away 

14
00:01:11,030 --> 00:01:14,450
what Nitsa calls the four ds of human 
folly,

15
00:01:15,890 --> 00:01:17,480
drunk,
drugged,

16
00:01:17,600 --> 00:01:19,070
distracted,
and drowsy.

17
00:01:19,071 --> 00:01:24,071
Driving autonomous vehicles have the 
ability to take away drunk driving,

18
00:01:26,300 --> 00:01:27,680
distracted,
drowsy,

19
00:01:28,820 --> 00:01:32,060
and drugged.
Eliminated car ownership.

20
00:01:32,180 --> 00:01:35,540
So taking shared mobility to another 
level,

21
00:01:38,600 --> 00:01:43,600
eliminating car ownership from the 
business side has the opportunity to 

22
00:01:43,760 --> 00:01:48,760
save people money and increase mobility 
and access making vehicles.

23
00:01:52,880 --> 00:01:57,880
Removing ownership makes vehicles more 
accessible because the cost of getting 

24
00:01:59,391 --> 00:02:04,391
from point a to point b drops an order 
to magnitude and the insertion of 

25
00:02:08,841 --> 00:02:13,841
software and intelligence into vehicles 
makes those vehicles,

26
00:02:13,940 --> 00:02:18,170
makes the idea of transportation.
It makes the way we see moving from a to

27
00:02:18,171 --> 00:02:20,840
point b,
a totally different experience,

28
00:02:21,490 --> 00:02:24,920
much like with our smartphone,
it makes it a personalized,

29
00:02:25,160 --> 00:02:27,860
efficient,
and reliable experience.

30
00:02:29,030 --> 00:02:32,780
Now for the negative view,
for the dystopian view,

31
00:02:35,250 --> 00:02:40,250
eliminate jobs,
any technology throughout its history,

32
00:02:40,470 --> 00:02:45,470
throughout our history of human 
civilization has always created fear 

33
00:02:45,470 --> 00:02:49,110
that jobs that rely on the prior 
technology will be lost.

34
00:02:49,800 --> 00:02:54,800
This is a huge fear,
especially in trucking because so many 

35
00:02:56,700 --> 00:03:01,700
people in the United States and across 
the rely work in the transportation 

36
00:03:01,841 --> 00:03:03,670
industry,
transportation sector,

37
00:03:04,930 --> 00:03:09,930
and the possibility that ai will remove 
those jobs has potential catastrophic 

38
00:03:10,870 --> 00:03:11,830
consequences.

39
00:03:13,730 --> 00:03:18,730
The idea one that we have to struggle 
with in the 21st century of the role of 

40
00:03:24,111 --> 00:03:29,111
intelligence systems that aren't human 
beings being further and further 

41
00:03:29,181 --> 00:03:33,980
integrated into our lives is the idea 
that a failure of an autonomous vehicle,

42
00:03:34,340 --> 00:03:36,320
even if they're much rare,
if the.

43
00:03:36,350 --> 00:03:41,350
Even if they're much safer that there is
a possibility for an ai algorithm 

44
00:03:41,840 --> 00:03:46,840
designed by probably one of the 
engineers in this room will kill a 

45
00:03:46,840 --> 00:03:50,831
person where that person would not have 
died if they were in control of the 

46
00:03:52,341 --> 00:03:55,400
vehicle.
The idea of intelligence system,

47
00:03:55,730 --> 00:04:00,730
one indirect interaction with a human 
being killing that human being is one 

48
00:04:00,730 --> 00:04:03,020
that we have to struggle with on a 
philosophical,

49
00:04:03,021 --> 00:04:08,021
ethical and technological level.
Artificial intelligence systems in 

50
00:04:11,411 --> 00:04:16,411
popular culture,
less so in engineering concerns may not 

51
00:04:17,651 --> 00:04:22,060
be grounded ethically grounded at this 
time.

52
00:04:22,061 --> 00:04:24,010
Much of the focus of building these 
systems,

53
00:04:24,011 --> 00:04:29,011
as we'll talk about today and throughout
this course that focuses on the 

54
00:04:29,011 --> 00:04:30,430
technology,
how do we make these things work,

55
00:04:31,420 --> 00:04:35,140
but of course,
decades out years or decades out,

56
00:04:35,380 --> 00:04:40,380
the ethical concern started rising for 
Rodney Brooks,

57
00:04:42,880 --> 00:04:47,880
one of the seminal people from Mit.
Those ethical concerns will not be an 

58
00:04:47,880 --> 00:04:51,280
issue for another several decades,
at least five decades,

59
00:04:52,390 --> 00:04:55,840
but they're still important.
It continues the thought,

60
00:04:55,870 --> 00:04:58,630
the idea of what is the role of Ai in 
our society?

61
00:04:59,440 --> 00:05:02,740
When that car gets to make a decision 
about human life,

62
00:05:03,580 --> 00:05:05,710
what is it making that decision based 
on,

63
00:05:06,070 --> 00:05:11,070
especially when it's a black box,
what is the ethical grounding of that 

64
00:05:11,070 --> 00:05:12,760
system?
Does it conform with our social norms?

65
00:05:14,000 --> 00:05:14,720
Does it go,
go,

66
00:05:14,750 --> 00:05:18,350
go against them,
and there's many other concerns?

67
00:05:18,650 --> 00:05:23,650
Security is definitely a big one.
A car this not even artificial 

68
00:05:25,551 --> 00:05:27,650
intelligence based the car,
this software base.

69
00:05:27,651 --> 00:05:30,860
As they're becoming more and more 
millions,

70
00:05:30,890 --> 00:05:35,890
most of the cars on roads today,
I run by millions of lines of source 

71
00:05:35,890 --> 00:05:40,121
code.
The idea that those lines of source code

72
00:05:40,400 --> 00:05:45,400
written again by some of the engineers 
in this room get to decide the life of a

73
00:05:45,531 --> 00:05:50,531
human being means then a hacker from 
outside of the car can manipulate that 

74
00:05:53,031 --> 00:05:56,930
code to also decide the fate of the 
human being.

75
00:05:57,080 --> 00:06:02,080
That's a huge concern for us from the 
engineering perspective.

76
00:06:04,950 --> 00:06:09,950
The truth is somewhere in the middle we 
want to find what is the best positive 

77
00:06:09,950 --> 00:06:14,811
way we can build these systems to 
transform our society to improve the 

78
00:06:14,811 --> 00:06:19,131
quality of life of everyone amongst us,
but there's a grain of salt to the hype 

79
00:06:24,130 --> 00:06:29,130
of autonomous vehicles.
We have to remember as we discussed in 

80
00:06:29,130 --> 00:06:30,480
the previous lecture,
new will come up again and again.

81
00:06:30,481 --> 00:06:35,481
Our intuition about what is difficult 
and what is easy for deep learning for 

82
00:06:38,191 --> 00:06:43,191
autonomous systems is flawed.
If we use our infuse ourselves.

83
00:06:44,340 --> 00:06:49,340
In this example,
human beings are extremely good at 

84
00:06:49,340 --> 00:06:50,940
driving.
This will come up again and again.

85
00:06:52,020 --> 00:06:57,020
Our intuition has to be grounded in 
understanding of what is the source of 

86
00:06:57,020 --> 00:06:58,740
data,
what is the annotation,

87
00:06:58,800 --> 00:07:01,290
and what is the approach?
What is the algorithm,

88
00:07:01,950 --> 00:07:04,380
so you have to be careful about using 
our intuition,

89
00:07:04,381 --> 00:07:09,381
extending a decades out and making 
predictions whether there's towards the 

90
00:07:09,381 --> 00:07:10,230
Utopian or dystopian view

91
00:07:12,140 --> 00:07:17,140
and as we'll talk about some of the 
advancements of companies working in 

92
00:07:17,140 --> 00:07:21,281
this space today,
you have to take what people say in the 

93
00:07:21,441 --> 00:07:23,810
media,
what the companies say.

94
00:07:23,840 --> 00:07:28,840
Some of the speakers that will be 
speaking at this class say about their 

95
00:07:28,840 --> 00:07:30,890
plans for the future and their current 
capabilities.

96
00:07:32,000 --> 00:07:37,000
I think us a guide that can provide is 
when there's a promise of a future 

97
00:07:38,481 --> 00:07:43,481
technology,
future vehicles that are two years out 

98
00:07:43,481 --> 00:07:45,300
or more.
That has to be.

99
00:07:46,140 --> 00:07:51,140
That's a very delicate prediction one 
that is within a year as we'll give a 

100
00:07:51,931 --> 00:07:56,931
few examples today is skeptical.
The real proof comes in actual testing 

101
00:08:02,401 --> 00:08:06,390
on public roads or in the most 
impressive,

102
00:08:06,420 --> 00:08:11,400
the most amazing.
The reality of it is when it's available

103
00:08:11,401 --> 00:08:16,401
to consumer purchase.
I would like to use Rodney Brooks as a 

104
00:08:19,380 --> 00:08:24,380
so it doesn't come from my mouth,
but I happen to agree his prediction is 

105
00:08:25,891 --> 00:08:30,891
no earlier than 2032 drivers.
Taxi service in a major US city will 

106
00:08:32,641 --> 00:08:36,540
provide arbitrary pickup and drop off 
locations fully autonomously.

107
00:08:38,240 --> 00:08:43,240
That's 14 years away and by 2045 it will
do so in multiple cities across the 

108
00:08:47,960 --> 00:08:49,780
United States.
So think about that,

109
00:08:50,020 --> 00:08:52,670
that a lot of the engineers working in 
this space,

110
00:08:52,790 --> 00:08:55,280
a lot of folks are actually building 
these systems,

111
00:08:55,350 --> 00:09:00,350
agree with this idea,
and that is the earliest I believe this 

112
00:09:01,320 --> 00:09:05,280
will happen and Rodney believes,
but

113
00:09:08,040 --> 00:09:11,430
as all technophobes have been wrong,
it could be wrong.

114
00:09:12,570 --> 00:09:17,570
This is a map on the x axis,
a plot on the x axis of time throughout 

115
00:09:18,361 --> 00:09:23,361
the 20th century and the adoption rate 
on the y axis from zero to 100 percent 

116
00:09:23,640 --> 00:09:26,890
of the various technologies from 
electricity to cars to radio,

117
00:09:26,891 --> 00:09:31,110
the telephone and so on.
And as we get closer to today,

118
00:09:31,200 --> 00:09:35,730
the technology adoption rate,
when it goes from zero to 100 percent,

119
00:09:36,390 --> 00:09:41,390
the number of years it takes to adopt 
that technology is getting shorter and 

120
00:09:41,390 --> 00:09:43,530
shorter and shorter.
As a society,

121
00:09:43,531 --> 00:09:48,531
we're better at throwing away the 
technology evolved and accepting of 

122
00:09:48,531 --> 00:09:52,451
technology of new.
So if a brilliant idea to solve some of 

123
00:09:52,891 --> 00:09:54,600
the problems were discussing comes 
along,

124
00:09:54,630 --> 00:09:59,630
it could change everything overnight.
So let's talk about different approaches

125
00:10:02,741 --> 00:10:07,600
to autonomy.
We'll talk about sensors afterwards.

126
00:10:08,140 --> 00:10:10,930
We'll talk about companies,
players in this space,

127
00:10:11,740 --> 00:10:16,740
and then we'll talk about ai and the 
actual algorithms and how they can help 

128
00:10:19,810 --> 00:10:22,330
solve some of the problems with 
autonomous vehicles.

129
00:10:24,130 --> 00:10:28,030
Levels of autonomy.
Here's a useful

130
00:10:30,330 --> 00:10:35,330
taxonomies of levels of autonomy,
useful for initial discussion,

131
00:10:38,130 --> 00:10:43,130
for legal discussion and for policy 
making and for blog posts.

132
00:10:43,541 --> 00:10:46,890
The media reports,
but it's not useful.

133
00:10:46,950 --> 00:10:51,950
I would argue for design and engineering
of the underlying intelligence and the 

134
00:10:52,230 --> 00:10:54,780
system viewed from a holistic 
perspective,

135
00:10:54,900 --> 00:10:59,900
the entire thing,
creating an experience that's safe and 

136
00:10:59,900 --> 00:11:00,570
enjoyable.
So let's go over those levels.

137
00:11:01,170 --> 00:11:03,180
The five,
the six levels.

138
00:11:05,130 --> 00:11:08,220
This is presented by sae report j three 
zero,

139
00:11:08,221 --> 00:11:13,221
one six.
The most widely accepted taxonomists 

140
00:11:13,221 --> 00:11:15,450
nation of autonomy.
No automation at level zero.

141
00:11:15,840 --> 00:11:18,750
Level one and level two is increasing 
levels of automation.

142
00:11:18,751 --> 00:11:23,360
Level one is cruise control,
level two is adaptive cruise control and

143
00:11:23,370 --> 00:11:25,830
lane keeping.
Level three,

144
00:11:26,310 --> 00:11:31,310
I don't know what level three is.
There's a lot of people that will 

145
00:11:31,310 --> 00:11:32,880
explain that.
Level three is conditional automation,

146
00:11:32,881 --> 00:11:35,970
meaning it's constrained to certain 
geographical location.

147
00:11:36,600 --> 00:11:39,030
I will explain that from an engineer 
perspective.

148
00:11:39,270 --> 00:11:44,270
I'm a personally a little bit confused 
on where that stands.

149
00:11:45,300 --> 00:11:48,450
I'll try to redefine how we should view 
automation.

150
00:11:49,050 --> 00:11:53,370
Level four and level five is high full 
level automation.

151
00:11:53,710 --> 00:11:58,710
Level four is when the vehicle can drive
itself fully for part of the time.

152
00:11:59,890 --> 00:12:03,580
There's certain areas in which you can 
take care of everything no matter what.

153
00:12:03,581 --> 00:12:08,581
No human inter interaction input 
safekeeping as required.

154
00:12:10,600 --> 00:12:13,150
Level five,
automation is the car does everything.

155
00:12:14,980 --> 00:12:15,550
Everything.

156
00:12:18,010 --> 00:12:23,010
I would argue that those levels aren't 
useful for designing systems that 

157
00:12:23,771 --> 00:12:27,400
actually work in the real world.
I would argue that there's two systems,

158
00:12:28,330 --> 00:12:33,330
but first a starting point that every 
system to some degree involves a human.

159
00:12:35,410 --> 00:12:40,410
It starts with manual control from a 
human human getting in the car and a 

160
00:12:41,951 --> 00:12:46,090
human electing to do something so that's
the manual control.

161
00:12:46,480 --> 00:12:49,570
What we're talking about.
When the human engages the system,

162
00:12:50,410 --> 00:12:55,410
when the system is first available and 
the human chooses to turn it on,

163
00:12:56,170 --> 00:13:01,170
that's one we have to ai systems,
human centered autonomy,

164
00:13:01,960 --> 00:13:06,910
when the human is needed is involved and
full autonomy.

165
00:13:07,150 --> 00:13:11,350
When ai is fully responsible for 
everything from the legal perspective,

166
00:13:11,410 --> 00:13:16,410
that means a two full autonomy means the
car they designer,

167
00:13:16,690 --> 00:13:20,380
the AI system is liable,
is responsible,

168
00:13:21,010 --> 00:13:24,280
and for the human center of autonomy,
the human is responsible.

169
00:13:27,270 --> 00:13:31,800
What does this practically mean for 
human centered autonomy,

170
00:13:32,490 --> 00:13:34,890
and we'll discuss examples of all of 
these.

171
00:13:36,240 --> 00:13:41,240
When a human interaction is necessary.
The question then becomes is how often 

172
00:13:44,040 --> 00:13:49,040
is the system available?
Is it available on in traffic 

173
00:13:49,741 --> 00:13:51,300
conditions,
so for traffic,

174
00:13:51,360 --> 00:13:53,610
bumper to bumper is available on the 
highway.

175
00:13:53,640 --> 00:13:56,220
Is that sensor based like in the Tesla 
vehicle,

176
00:13:56,221 --> 00:13:59,460
meaning based on the visual 
characteristics to the scene,

177
00:13:59,760 --> 00:14:02,430
the vehicle is confident enough to be 
able to control,

178
00:14:02,490 --> 00:14:06,120
to make control decisions,
perception control decisions.

179
00:14:07,620 --> 00:14:12,620
The other factor not discussed enough 
and I think poorly imprecisely discussed

180
00:14:16,171 --> 00:14:21,171
when it is,
is the number of seconds given to the 

181
00:14:21,171 --> 00:14:23,580
driver,
not guaranteed,

182
00:14:23,730 --> 00:14:28,730
but provided as a sort of feature to the
driver to take over and the Tesla 

183
00:14:28,861 --> 00:14:31,350
vehicle in all vehicles on the road 
today,

184
00:14:31,470 --> 00:14:36,470
that time is zero.
Zero seconds of guaranteed zero seconds 

185
00:14:36,470 --> 00:14:37,140
have provided.
There is some,

186
00:14:37,530 --> 00:14:40,920
there is some room and sometimes it's 
hundreds of milliseconds,

187
00:14:40,921 --> 00:14:45,921
sometimes it's multiple seconds,
but really there's no standard of how 

188
00:14:45,921 --> 00:14:49,581
many seconds you get to say wake up,
take control.

189
00:14:51,500 --> 00:14:56,500
Then tele operation,
something that some of the companies 

190
00:14:56,780 --> 00:15:01,780
will mention are playing with is when a 
human being as involved remotely 

191
00:15:01,780 --> 00:15:06,190
controlling the vehicle remotely,
so being able to take over control of 

192
00:15:06,190 --> 00:15:07,610
the vehicle when you're,
uh,

193
00:15:08,000 --> 00:15:13,000
when you're not able to control it.
So support by human that's not inside 

194
00:15:13,000 --> 00:15:17,471
the car.
That's a very interesting idea to 

195
00:15:17,471 --> 00:15:19,931
explore.
But for the human centered autonomy 

196
00:15:19,931 --> 00:15:22,730
side,
all of those features and not required,

197
00:15:22,760 --> 00:15:27,760
they're not guaranteed the human driver,
the human inside the car is always 

198
00:15:28,191 --> 00:15:29,660
responsible.
At the end of the day,

199
00:15:29,661 --> 00:15:33,440
they must pay attention to a degree 
that's required to take over.

200
00:15:33,441 --> 00:15:37,670
When the system fails and no matter 
under this consideration,

201
00:15:37,730 --> 00:15:42,730
under this level of autonomy,
the system will fail at some point.

202
00:15:43,730 --> 00:15:45,230
That is the,
that is the point.

203
00:15:45,260 --> 00:15:50,260
That is the collaboration between human 
and robot is the system will fail and 

204
00:15:50,260 --> 00:15:51,980
the human has to catch one that does.

205
00:15:53,600 --> 00:15:58,280
And then full autonomy is ai is fully 
responsible,

206
00:15:58,820 --> 00:16:01,250
not that doesn't.
Again,

207
00:16:01,251 --> 00:16:06,251
as we will present some companies in the
marketing material and that pr side of 

208
00:16:06,251 --> 00:16:10,331
things,
they might present that there is 

209
00:16:10,331 --> 00:16:12,551
significant degrees of autonomy.
If you're talking about l three or l 

210
00:16:12,551 --> 00:16:16,220
four or l five,
you have to read between the lines.

211
00:16:17,450 --> 00:16:20,450
You're not allowed to have tele 
operation.

212
00:16:22,400 --> 00:16:25,610
If a human is remotely operating the 
vehicle,

213
00:16:25,730 --> 00:16:29,540
a humanist still in the loop,
a humanness still evolved.

214
00:16:29,900 --> 00:16:32,060
It's still a human centered and autonomy
system.

215
00:16:33,320 --> 00:16:38,320
You don't get the ten second rule,
which is ge just because you give the 

216
00:16:40,341 --> 00:16:45,341
driver 10 seconds to take control.
That somehow removes liability for you.

217
00:16:45,620 --> 00:16:48,950
If you say that that's it.
As an AI system,

218
00:16:48,951 --> 00:16:53,470
I can't take a can't resolve,
can't deal,

219
00:16:53,480 --> 00:16:55,490
can't control the vehicle in this 
situation,

220
00:16:56,020 --> 00:16:58,580
and you have 10 seconds to take over,
that's not good enough.

221
00:16:58,640 --> 00:17:01,730
The driver might be sleeping.
That driver may have had a heart attack.

222
00:17:01,731 --> 00:17:06,731
They're not able to control the vehicle.
Full autonomous systems might must find 

223
00:17:07,460 --> 00:17:11,110
safe harbor.
That must get you full.

224
00:17:11,120 --> 00:17:16,120
Stop from point a to point b.
That point b might be your desired 

225
00:17:16,120 --> 00:17:18,170
destination or it might be a safe 
parking lot,

226
00:17:18,620 --> 00:17:21,500
but it has to bring you to a safe 
location.

227
00:17:21,860 --> 00:17:25,820
This is a clear definition of the two 
systems and the human.

228
00:17:25,821 --> 00:17:28,400
Of course,
as far as our certain.

229
00:17:28,620 --> 00:17:33,620
A current conception of artificial 
intelligence in cars today is a human 

230
00:17:33,620 --> 00:17:38,590
always overrides the AI system,
so we should for the for the in the 

231
00:17:39,291 --> 00:17:44,291
general case,
the human gets to choose to take 

232
00:17:45,381 --> 00:17:50,381
control.
The Ai can't take controls any human 

233
00:17:50,381 --> 00:17:53,560
except when danger is imminent,
meaning sudden crashes like an ab 

234
00:17:53,560 --> 00:17:58,251
events.
We're not yet ready for AI systems to 

235
00:17:58,251 --> 00:17:59,430
say as a society to say,
no,

236
00:17:59,431 --> 00:17:59,940
no,
no.

237
00:17:59,970 --> 00:18:02,280
You're drunk.
You can't drive.

238
00:18:06,700 --> 00:18:11,080
So beyond the traditional levels from 
level zero to level five,

239
00:18:11,410 --> 00:18:13,990
the starting point is level zero,
no automation.

240
00:18:14,050 --> 00:18:16,390
All cars start here.
Level one,

241
00:18:16,391 --> 00:18:21,391
level two and level three,
I would argue fall into human senator 

242
00:18:21,391 --> 00:18:23,330
autonomy systems,
a one

243
00:18:25,080 --> 00:18:28,200
because they involve some degree of a 
human.

244
00:18:28,770 --> 00:18:33,770
Now four or five to some degree,
there's some crossover fall into full 

245
00:18:34,021 --> 00:18:37,160
autonomy,
even though with all four,

246
00:18:37,200 --> 00:18:42,200
with way Mo,
as you can ask on Friday and anyone 

247
00:18:42,200 --> 00:18:46,731
cruise uber playing in this space,
there's very often a human driver 

248
00:18:47,311 --> 00:18:52,170
involved.
One of the huge accomplishments of waymo

249
00:18:52,960 --> 00:18:55,780
over the past month.
Incredible accomplishment.

250
00:18:56,020 --> 00:18:57,250
We're in Phoenix,
Arizona.

251
00:18:57,251 --> 00:19:01,090
They drove without the car,
drove without a driver.

252
00:19:02,530 --> 00:19:06,010
The meaning there was no safety driver 
to catch.

253
00:19:06,040 --> 00:19:10,300
There is no engineer staff member there 
to catch the car.

254
00:19:10,840 --> 00:19:15,840
A human being that doesn't work for 
Google or Waymo got into that car and 

255
00:19:15,911 --> 00:19:18,430
got from a to point b without a safety 
driver.

256
00:19:19,060 --> 00:19:24,060
That's an incredible accomplishment and 
that particular trip was a fully 

257
00:19:24,431 --> 00:19:29,431
autonomous trip.
That is full autonomy when there's no 

258
00:19:29,431 --> 00:19:33,891
human to catch the car.
No Ai presentation is good without cats.

259
00:19:39,650 --> 00:19:44,650
So full autonomy.
A two system is when you do nothing but 

260
00:19:46,131 --> 00:19:51,131
write along.
Human centered autonomy system is when 

261
00:19:51,621 --> 00:19:54,910
you have some control.
I'm sorry,

262
00:19:54,911 --> 00:19:59,911
I had to.
So the two paths for autonomous systems,

263
00:20:00,611 --> 00:20:05,290
they want an a two in blue.
On the left is a one human centered,

264
00:20:05,350 --> 00:20:07,660
on the right is a two full autonomy

265
00:20:09,990 --> 00:20:14,990
and then blue is from the artificial 
intelligent perspective is easy,

266
00:20:18,530 --> 00:20:21,290
easier,
and then red is harder,

267
00:20:22,340 --> 00:20:27,340
easier,
meaning we do not have to achieve 100 

268
00:20:27,340 --> 00:20:31,151
percent accuracy.
Harder means everything that's off of 

269
00:20:31,561 --> 00:20:36,561
100 percent accuracy,
no matter how small has a potential of 

270
00:20:36,651 --> 00:20:41,651
costing human lives and huge amounts of 
money for companies.

271
00:20:46,610 --> 00:20:51,610
So let's discuss.
We'll discuss later in the lecture about

272
00:20:52,301 --> 00:20:55,570
the algorithms behind each of these 
methods and the left and the right,

273
00:20:56,440 --> 00:21:01,440
but this summarizes the two approaches,
the localization mapping for the car to 

274
00:21:01,811 --> 00:21:06,640
determine where it's located.
For the human centered autonomy,

275
00:21:06,790 --> 00:21:10,360
it's easy.
It still has to do the perception it has

276
00:21:10,361 --> 00:21:15,361
to localize itself within the lane.
It has defined all the neighboring 

277
00:21:15,361 --> 00:21:19,441
pedestrians in the vehicles in order to 
be able to control the vehicle to some 

278
00:21:19,441 --> 00:21:21,520
degree,
but because the human is there,

279
00:21:21,521 --> 00:21:24,160
it doesn't have to do so perfectly when 
it fails.

280
00:21:24,161 --> 00:21:27,370
A humans there to catch it.
Seen understanding,

281
00:21:27,460 --> 00:21:30,070
perceiving everything in the environment
from the camera,

282
00:21:30,071 --> 00:21:31,420
from law,
whether it's Lidar,

283
00:21:31,421 --> 00:21:32,590
radar,
ultrasonic,

284
00:21:33,670 --> 00:21:37,830
the planning of the vehicle,
whether it's just staying within lane,

285
00:21:37,850 --> 00:21:39,430
uh,
for adaptive cruise control,

286
00:21:39,460 --> 00:21:42,070
controlling the longitudinal movement of
the vehicle,

287
00:21:42,250 --> 00:21:47,250
or it's changing lanes at the Tesla 
autopilot or higher degrees of 

288
00:21:47,250 --> 00:21:47,250
automation.

289
00:21:47,250 --> 00:21:49,960
All of those movement planning decisions
can be made autonomy.

290
00:21:50,240 --> 00:21:54,400
When the human is there to catch,
it's easier because you're allowed to be

291
00:21:54,401 --> 00:21:56,590
wrong.
Rarely but wrong.

292
00:21:57,670 --> 00:22:01,240
The hard part is getting the human robot
interaction piece right.

293
00:22:02,560 --> 00:22:07,560
That's next Wednesday lecture as we'll 
discuss about how deep learning can be 

294
00:22:10,121 --> 00:22:14,470
used to interact first.
Perceive everything about the driver and

295
00:22:14,471 --> 00:22:19,471
second to interact with the driver.
That part is hard because he can't screw

296
00:22:19,961 --> 00:22:24,961
up on that part.
You have to make sure you help the 

297
00:22:24,961 --> 00:22:26,290
driver know where your flaws are so they
can take over.

298
00:22:26,560 --> 00:22:31,560
If the driver's not paying attention,
you have to bring their attention back 

299
00:22:31,560 --> 00:22:31,660
to the road,
back to the interaction.

300
00:22:32,020 --> 00:22:35,500
You have to get that piece right because
for a flawed system,

301
00:22:36,010 --> 00:22:38,710
one that's rarely flawed.
The rarities,

302
00:22:38,711 --> 00:22:43,711
the challenge in fact has to get the 
interaction right and then the final 

303
00:22:44,681 --> 00:22:45,940
piece is communication.

304
00:22:47,230 --> 00:22:52,230
The autonomous vehicle,
fully autonomous vehicle must 

305
00:22:52,230 --> 00:22:54,640
communicate extremely well with the 
external world,

306
00:22:54,850 --> 00:22:58,030
with a pedestrian is the Jay Walker's 
the humans in this world.

307
00:22:58,031 --> 00:23:02,320
The cyclists that that communication 
piece one,

308
00:23:02,321 --> 00:23:06,310
at least that is part of a safe and 
enjoyable driving experience,

309
00:23:06,520 --> 00:23:10,360
is extremely difficult on the Ta Waymo 
vehicle.

310
00:23:10,420 --> 00:23:15,420
I wish them luck if they come to Boston.
I'm getting from point a to point b 

311
00:23:15,430 --> 00:23:20,430
because pedestrians will take advantage 
of vehicle must assert itself in order 

312
00:23:22,391 --> 00:23:27,391
to be able to navigate Boston streets 
and that assertion is communication.

313
00:23:28,990 --> 00:23:33,990
That piece is extremely difficult for a 
tesla vehicle for for a a human centered

314
00:23:36,911 --> 00:23:39,640
autonomy vehicle.
L Two l three.

315
00:23:41,260 --> 00:23:44,950
The way you deal with Boston pedestrians
is you take over,

316
00:23:45,800 --> 00:23:47,540
roll down the window,
yells something,

317
00:23:47,541 --> 00:23:52,541
and then speed up getting the piece for 
an artificial intelligence system to 

318
00:23:54,201 --> 00:23:56,450
actually be able to accomplish something
like that.

319
00:23:56,450 --> 00:24:01,450
As we'll discuss on the ethics side and 
the engineering side is extremely 

320
00:24:01,450 --> 00:24:04,100
difficult.
That said,

321
00:24:04,310 --> 00:24:08,390
most of the literature and the human 
factors field and the autonomous vehicle

322
00:24:08,391 --> 00:24:13,391
field,
anyone that's studied autonomy in 

323
00:24:13,391 --> 00:24:16,031
aviation and in vehicles is extremely 
skeptical about a human centered 

324
00:24:16,911 --> 00:24:19,550
approach they think is deeply 
irresponsible,

325
00:24:20,060 --> 00:24:25,060
is deeply irresponsible because is as 
argued because human beings,

326
00:24:28,130 --> 00:24:33,130
when you give them a technology which 
will take control part of the time,

327
00:24:34,400 --> 00:24:39,400
they'll get lazy.
They would take advantage of that 

328
00:24:39,400 --> 00:24:39,400
technology.
They will overtrust that technology.

329
00:24:39,400 --> 00:24:43,841
They'll assume a work perfectly always.
This is the idea that this is this idea 

330
00:24:48,141 --> 00:24:53,141
extended beyond further and further 
means that the better the system gets,

331
00:24:53,570 --> 00:24:55,790
the better of the car,
it gets a driving itself.

332
00:24:55,970 --> 00:24:59,570
The more the humans will sit back and be
completely distracted.

333
00:24:59,571 --> 00:25:03,560
It will not be able to reengage 
themselves in order to safely catch when

334
00:25:03,561 --> 00:25:04,610
the system fails.

335
00:25:05,180 --> 00:25:10,180
This is Chris Urmson,
the founder of the Google self driving 

336
00:25:10,180 --> 00:25:13,121
cars program,
and now the co founder of one of the 

337
00:25:14,631 --> 00:25:17,210
other co founder is a speaker.
This class on next Friday,

338
00:25:17,211 --> 00:25:20,480
Sterling Anderson have a company called 
Aurora,

339
00:25:20,720 --> 00:25:24,500
a startup.
He was one of the big proponents,

340
00:25:28,160 --> 00:25:33,160
or the I should say,
our opponents of the idea that human 

341
00:25:33,160 --> 00:25:38,021
centered autonomy could work.
They tried it publicly,

342
00:25:38,170 --> 00:25:43,170
spoken about the fact that Google,
as in the early self driving car 

343
00:25:43,170 --> 00:25:45,110
program,
they've tried shared autonomy.

344
00:25:45,480 --> 00:25:50,480
They've tried l two and it failed 
because they're engineers that people 

345
00:25:50,480 --> 00:25:55,181
driving their vehicles fell asleep and 
that's the belief that people have and 

346
00:25:57,321 --> 00:25:59,630
we'll talk about why that may not be 
true.

347
00:26:00,110 --> 00:26:05,110
There's a fascinating truth in the way 
human beings can interact with 

348
00:26:05,110 --> 00:26:08,000
artificial intelligence systems that may
work.

349
00:26:08,090 --> 00:26:10,040
In this case,
as I mentioned,

350
00:26:10,041 --> 00:26:15,041
it's the human robot interaction,
building that deep connection between 

351
00:26:15,041 --> 00:26:18,470
human and machine of understanding of 
communication.

352
00:26:20,690 --> 00:26:25,690
This is what we believe happens,
so there's a lot of videos like this as 

353
00:26:25,690 --> 00:26:26,300
a it's,
it's fun,

354
00:26:26,510 --> 00:26:31,510
but it's also representative of what 
what society believes happens when 

355
00:26:32,301 --> 00:26:37,301
automation is allowed to enter the human
experience and driving where the human 

356
00:26:40,281 --> 00:26:45,281
life is a steak that you can become 
completely disengaged.

357
00:26:46,630 --> 00:26:46,890
Hmm.

358
00:26:51,740 --> 00:26:56,740
It's kind of.
It's kind of a natural thing to think,

359
00:26:57,950 --> 00:27:01,550
but the question is,
does this actually happened?

360
00:27:02,270 --> 00:27:07,270
What actually happens on public roads,
the amazing thing that people don't 

361
00:27:08,271 --> 00:27:09,410
often talk about

362
00:27:11,940 --> 00:27:16,940
is that there is hundreds of thousands 
of vehicles on the road today,

363
00:27:19,800 --> 00:27:23,160
equipped with autopilot,
Tesla,

364
00:27:23,190 --> 00:27:27,450
autopilot that have a significant degree
of autonomy.

365
00:27:28,440 --> 00:27:33,440
That's data,
that's information so we can answer the 

366
00:27:33,440 --> 00:27:37,341
question what actually happens.
So many of the people behind this team 

367
00:27:37,341 --> 00:27:41,970
of instrumented 25 vehicles,
21 of which are Tesla,

368
00:27:41,971 --> 00:27:46,971
autopilot vehicles now with over 
collected recording everything about the

369
00:27:47,071 --> 00:27:49,110
driver,
two cameras to hd,

370
00:27:49,111 --> 00:27:52,670
cameras on the driver,
two cameras on the a one,

371
00:27:52,680 --> 00:27:56,370
the camera on the external roadway and 
collecting everything about the car,

372
00:27:56,460 --> 00:27:58,350
including audio,
the state,

373
00:27:58,351 --> 00:28:00,300
the pulling,
everything from the Cambus,

374
00:28:00,540 --> 00:28:03,040
the kinematics of the vehicle,
Imu,

375
00:28:03,120 --> 00:28:08,120
gps,
all of that information over now over 

376
00:28:08,120 --> 00:28:08,490
300,000
miles,

377
00:28:08,850 --> 00:28:13,850
over 5 billion video frames.
All as we'll talk about,

378
00:28:14,491 --> 00:28:19,491
analyze the computer vision.
You extract from that video of the 

379
00:28:19,491 --> 00:28:22,890
driver of everything they're doing.
That level of distraction,

380
00:28:22,891 --> 00:28:26,610
the allocation of attention,
the drowsiness,

381
00:28:26,640 --> 00:28:29,820
emotional states,
the hands on,

382
00:28:29,821 --> 00:28:32,040
we'll hands off,
we'll body pose,

383
00:28:32,460 --> 00:28:34,770
I activity,
smartphone usage,

384
00:28:34,800 --> 00:28:37,950
all of these factors,
all of these things that you would think

385
00:28:37,951 --> 00:28:42,951
would fall apart when you start letting 
autonomy into your life.

386
00:28:42,961 --> 00:28:46,650
We'll talk about what the initial 
reality is.

387
00:28:46,830 --> 00:28:49,230
That should be inspiring and thought 
provoking,

388
00:28:50,860 --> 00:28:53,080
as I said,
three cameras,

389
00:28:54,100 --> 00:28:59,100
single board computer recording all the 
data over a thousand machines in holyoke

390
00:29:00,990 --> 00:29:05,990
and distributed computation,
running the deep learning algorithms 

391
00:29:05,990 --> 00:29:10,140
I've had mentioned on these five plus 
billion video frames going from the raw 

392
00:29:11,091 --> 00:29:14,300
data to the actionable useful 
information.

393
00:29:15,570 --> 00:29:17,970
The slides are up online if you'd like 
to look through them,

394
00:29:18,540 --> 00:29:23,540
I'll fly through some of them and this 
is the video of one of thousands of 

395
00:29:25,111 --> 00:29:28,170
trips.
We have an autopilot in our data,

396
00:29:28,560 --> 00:29:33,560
a car driving autonomously,
large fraction of the time on highways 

397
00:29:34,290 --> 00:29:37,110
from here to California.
I'm here to Chicago,

398
00:29:37,860 --> 00:29:40,650
to Florida and all across the United 
States.

399
00:29:43,840 --> 00:29:48,840
We take that data and using the 
supervised learning algorithms,

400
00:29:50,230 --> 00:29:55,230
semi-supervised.
The number of frames here is huge for 

401
00:29:55,311 --> 00:30:00,100
those that work in computer vision.
Five billion frames is several orders of

402
00:30:00,350 --> 00:30:05,350
magnitude larger than any data set that 
people are working with in computer 

403
00:30:05,361 --> 00:30:09,890
vision,
actively annotated,

404
00:30:12,850 --> 00:30:17,850
so we want to use that data for 
understanding the behavior of what 

405
00:30:17,861 --> 00:30:22,000
people are actually doing in the cars 
and we want to train the algorithms,

406
00:30:22,001 --> 00:30:27,001
the do perception and control.
A quick summary over 300,000

407
00:30:27,191 --> 00:30:29,620
miles,
25 vehicles.

408
00:30:29,770 --> 00:30:32,530
The color is a true to the actual colors
of the vehicles,

409
00:30:33,050 --> 00:30:38,050
a little fun fact.
Tesla model x model less and now a model

410
00:30:39,071 --> 00:30:39,490
three,

411
00:30:41,520 --> 00:30:46,290
500,500
plus miles a day and growing.

412
00:30:47,160 --> 00:30:52,160
Now,
most days in 2018 are over a thousand 

413
00:30:52,680 --> 00:30:57,150
miles a day.
This is a quick gps map in red is manual

414
00:30:57,151 --> 00:31:02,151
driving across the Boston area and Blue 
Cyan is autonomous driving.

415
00:31:02,430 --> 00:31:05,640
This is giving you the sense of just the
scope of this data.

416
00:31:05,910 --> 00:31:10,900
This is a huge number of miles with 
automated driving,

417
00:31:11,230 --> 00:31:16,230
several orders of magnitude larger than 
what Waymo is doing that what cruises 

418
00:31:17,201 --> 00:31:19,060
doing,
what Uber is doing.

419
00:31:24,830 --> 00:31:29,830
The miles driven in this data with 
autopilot confirming what are.

420
00:31:32,091 --> 00:31:37,091
Y'All must [inaudible] stated it's 33 
percent of miles driven autonomously.

421
00:31:38,680 --> 00:31:43,680
This is a remarkable number for those of
you who drive and for those of you who 

422
00:31:43,811 --> 00:31:47,950
are familiar with these technologies,
that is remarkable adoption rate,

423
00:31:48,310 --> 00:31:51,850
that 33 percent of the miles are driven 
in autopilot.

424
00:31:52,120 --> 00:31:56,140
That means these drivers are getting use
out of the system.

425
00:31:56,680 --> 00:31:59,530
It's working for them.
That's an incredible number.

426
00:32:01,830 --> 00:32:06,830
It's also incredible because under the 
the decades of literature from aviation 

427
00:32:08,790 --> 00:32:13,020
to automation in vehicles to to Chris 
Urmson and Waymo,

428
00:32:13,380 --> 00:32:18,380
the belief is such high numbers are 
likely to lead to crashes,

429
00:32:19,440 --> 00:32:24,330
two fatalities to at the very least 
highly irresponsible behavior.

430
00:32:25,890 --> 00:32:28,800
Drivers overtrusting the systems and 
getting in trouble.

431
00:32:29,850 --> 00:32:32,910
We can run the glance classification 
algorithms.

432
00:32:33,450 --> 00:32:36,240
Again,
this is for next Wednesday discussion.

433
00:32:36,260 --> 00:32:40,760
The actual algorithm is the algorithm 
that tells the region that the driver is

434
00:32:40,761 --> 00:32:43,880
looking at and it's comparing road 
instrument cluster,

435
00:32:43,881 --> 00:32:46,490
left rear view center stack,
and right.

436
00:32:46,820 --> 00:32:51,820
Does the allocation of glance change 
with autopilot or with manual driving?

437
00:32:54,050 --> 00:32:57,890
It does not appear to have any 
significant noticeable way,

438
00:32:58,160 --> 00:33:01,370
meaning you don't start playing chess,
you don't start.

439
00:33:01,400 --> 00:33:06,400
You don't get in the back seat to sleep,
you don't start texting in your smart 

440
00:33:07,101 --> 00:33:10,140
phone and watching a movie,
at least in this Dataset,

441
00:33:10,220 --> 00:33:14,360
this promise here for the human centered
approach,

442
00:33:16,250 --> 00:33:21,200
the observation to summarize this 
particular data is that people are using

443
00:33:21,201 --> 00:33:26,201
it a lot.
The percentage of miles and percentage 

444
00:33:26,201 --> 00:33:28,490
of hours is incredibly high,
at least relative to what was it will be

445
00:33:28,491 --> 00:33:33,080
expected from these systems and given 
that there's no crashes,

446
00:33:33,530 --> 00:33:38,530
there's no near crashes in autopilot.
The road type is mostly highway 

447
00:33:40,820 --> 00:33:45,820
traveling at high speeds.
The mental engagement looked at

448
00:33:47,880 --> 00:33:52,880
8,000
trestles of control from machine to 

449
00:33:52,880 --> 00:33:55,491
human,
so human beings taking control of the 

450
00:33:55,491 --> 00:33:55,491
vehicle saying,
you know what?

451
00:33:55,491 --> 00:33:59,990
I'm going to take control now.
I'm not comfortable with the situation 

452
00:33:59,990 --> 00:34:02,841
for whatever reason either not 
comfortable or electing to do something 

453
00:34:02,841 --> 00:34:04,860
that the vehicle is not able to like 
turn off the highway,

454
00:34:05,100 --> 00:34:08,520
make a right or left turn stop for a 
stop sign.

455
00:34:08,521 --> 00:34:12,210
These kinds of things.
Physical engagement,

456
00:34:12,270 --> 00:34:17,270
as I said,
glance remains the same and what do we 

457
00:34:17,270 --> 00:34:21,171
take from this?
It says something that I'd like to 

458
00:34:21,171 --> 00:34:21,171
really emphasize this.
We've talked to,

459
00:34:21,171 --> 00:34:25,970
we talk about autonomous vehicles in 
this class and the guest speakers who 

460
00:34:25,970 --> 00:34:30,291
are all on the other side,
so I'm representing the human center 

461
00:34:30,291 --> 00:34:32,670
side.
Most all our speakers are focused on the

462
00:34:32,671 --> 00:34:37,671
full autonomy side because that's the 
side roboticist know how to solve.

463
00:34:37,770 --> 00:34:41,190
That's the fascinating algorithm nerd 
side,

464
00:34:41,780 --> 00:34:44,100
and that's the side I love as well.

465
00:34:44,360 --> 00:34:49,360
It's just my belief stands that the 
solving the perception control problem 

466
00:34:49,360 --> 00:34:51,660
is extremely difficult and two,
three decades away.

467
00:34:51,960 --> 00:34:56,960
So in the meantime we have to utilize 
the human robot interaction to actually 

468
00:34:56,960 --> 00:35:01,761
bring these ai systems onto the road to 
successfully operate and the way we do 

469
00:35:01,761 --> 00:35:06,411
that counterintuitively is we have to 
have.

470
00:35:08,220 --> 00:35:13,020
We have to let the artificial 
intelligence systems reveal their flaws.

471
00:35:14,310 --> 00:35:19,200
One of the most endearing things to 
human beings can do to each other.

472
00:35:19,230 --> 00:35:23,490
Friends is revealed their flaws to each 
other.

473
00:35:24,480 --> 00:35:26,520
Now,
from an automotive perspective,

474
00:35:26,521 --> 00:35:31,521
from a company perspective is perhaps 
not appealing for an ai system to reveal

475
00:35:33,971 --> 00:35:38,971
what it sees about the world and would 
it doesn't see about the world where it 

476
00:35:38,971 --> 00:35:40,530
succeeds and where it fails,

477
00:35:41,930 --> 00:35:45,080
but that is perhaps exactly what it 
needs to do.

478
00:35:45,890 --> 00:35:49,700
In the case of autopilot,
the way the very limited,

479
00:35:50,090 --> 00:35:55,090
but I believe successful way it's 
currently doing that is allowing you to 

480
00:35:55,090 --> 00:35:58,451
use autopilot basically anywhere,
so what people are doing is they're 

481
00:35:58,451 --> 00:36:02,291
trying to engage their turn on autopilot
in places where they really shouldn't.

482
00:36:03,560 --> 00:36:08,560
Rural rural roads,
curvy with terrible road markings with a

483
00:36:11,240 --> 00:36:16,240
in heavy rain conditions with snow,
with lots of cars driving at high speeds

484
00:36:17,211 --> 00:36:20,960
all around.
They turn autopilot on to understand,

485
00:36:20,961 --> 00:36:22,820
to experience the limitations of the 
system,

486
00:36:23,060 --> 00:36:28,060
to to interact.
That human robot interaction is through 

487
00:36:28,800 --> 00:36:33,800
it's tactile.
By turning it on and seeing is it going 

488
00:36:33,800 --> 00:36:34,250
to work here?
How's it going to fail?

489
00:36:34,251 --> 00:36:35,990
And the human is always there to catch 
it.

490
00:36:36,260 --> 00:36:39,140
That interaction,
that's communication,

491
00:36:39,470 --> 00:36:44,470
that intimate understanding is what 
creates successful integration of ai in 

492
00:36:44,470 --> 00:36:49,021
the car.
Before we're able to solve the full 

493
00:36:49,021 --> 00:36:51,161
autonomy puzzle.
Learn the limitations by exploring it 

494
00:36:51,561 --> 00:36:54,920
starts with this guy and hundreds of 
others.

495
00:36:55,580 --> 00:36:58,100
If you search on Youtube,
first time with the autopilot,

496
00:36:59,620 --> 00:37:03,160
the amazing experience of direct 
transfer,

497
00:37:03,161 --> 00:37:07,870
of control of your life to an artificial
intelligence system in this case,

498
00:37:07,990 --> 00:37:12,990
given control to Tesla autopilot system.
This is why in the human centered camp 

499
00:37:13,781 --> 00:37:18,781
of autonomy,
I believe that autonomous vehicles can 

500
00:37:18,911 --> 00:37:22,210
be viewed as personal robots with which 
you build,

501
00:37:22,240 --> 00:37:26,440
build a relationship or the human robot 
interaction is the key problem,

502
00:37:26,770 --> 00:37:28,390
not the perception control

503
00:37:35,560 --> 00:37:40,560
and they're the flaws of both humans and
machines must be clearly communicated 

504
00:37:41,801 --> 00:37:46,801
and perceived perceived because he used 
the computer vision algorithms to detect

505
00:37:47,531 --> 00:37:52,531
everything about the human and 
communicated because on the displays of 

506
00:37:52,531 --> 00:37:56,581
the car or even through voice,
it has to be able to reveal when it 

507
00:37:56,581 --> 00:38:01,350
doesn't see different aspects of the 
scene from the human centered approach,

508
00:38:05,251 --> 00:38:10,251
then we can focus on the left,
the perception and control side.

509
00:38:10,640 --> 00:38:15,640
Perceiving everything about the external
environment and controlling the vehicle 

510
00:38:15,640 --> 00:38:17,480
without having to worry about being 99 
point nine,

511
00:38:17,481 --> 00:38:17,930
nine,
nine,

512
00:38:17,980 --> 00:38:19,610
nine,
nine percent correct.

513
00:38:20,360 --> 00:38:25,360
Approaching 100 percent correct because 
in the cases where it's extremely 

514
00:38:25,360 --> 00:38:28,640
difficult,
we can let the human catch the system,

515
00:38:30,440 --> 00:38:35,090
we can reveal the flaws and let the 
human takeover on the system can't.

516
00:38:36,370 --> 00:38:41,370
So let's get to the sensors,
the sources of raw data that we'll get 

517
00:38:43,751 --> 00:38:48,751
to work with.
There's three.

518
00:38:50,960 --> 00:38:53,500
There's cameras,
so image sensors,

519
00:38:54,220 --> 00:38:59,160
rgb infrared,
visual data.

520
00:38:59,580 --> 00:39:04,580
There's radar and ultrasonic and there's
lidar.

521
00:39:07,500 --> 00:39:12,240
Let's discuss the strengths first.
Discuss really what these sensors are,

522
00:39:12,270 --> 00:39:17,270
the strength and weaknesses and how they
can be integrated together for sensor 

523
00:39:17,761 --> 00:39:22,761
fusion,
so radar is the trust of the old trusted

524
00:39:22,981 --> 00:39:27,981
friend.
The sensor that's commonly available in 

525
00:39:27,981 --> 00:39:30,740
most vehicles that have a degree of 
autonomy on the left is a visualization 

526
00:39:31,651 --> 00:39:36,651
of the kind of data on high resolution 
rate or that's able to be extracted.

527
00:39:38,780 --> 00:39:43,780
It's cheap.
Both radar which works with 

528
00:39:43,780 --> 00:39:48,280
electromagnetic waves and ultrasonic,
which works with sound waves,

529
00:39:49,790 --> 00:39:52,790
sending a wave,
letting it bounce off the obstacles,

530
00:39:53,420 --> 00:39:58,420
knowing the speed of that wave,
being able to calculate the distance to 

531
00:39:58,420 --> 00:40:02,471
the obstacle based on that,
it does extremely well in challenging 

532
00:40:05,271 --> 00:40:06,500
weather,
rain,

533
00:40:06,501 --> 00:40:11,501
snow.
The downside is a slow resolution 

534
00:40:13,800 --> 00:40:15,690
compared to the other senses we'll 
discuss,

535
00:40:16,350 --> 00:40:21,350
but it is the one that's most reliable 
and using automotive industry today and 

536
00:40:21,350 --> 00:40:23,640
it's the one that's in sense of fusion 
is always there.

537
00:40:25,470 --> 00:40:30,470
Lidar visualized on the right.
The downside is it's expensive,

538
00:40:32,970 --> 00:40:37,970
but it produces an extremely accurate 
depth information and a high resolution 

539
00:40:37,970 --> 00:40:42,651
map of the environment that has 360 
degrees of visibility.

540
00:40:47,270 --> 00:40:52,270
It has some of the big strengths of 
radar in terms of reliability,

541
00:40:52,850 --> 00:40:55,310
but with much higher resolution and 
accuracy.

542
00:40:56,180 --> 00:41:01,180
The downside is cost.
Here's a quick visualization comparing 

543
00:41:02,011 --> 00:41:05,580
the two of the kind of information and 
get to work with the.

544
00:41:05,940 --> 00:41:10,940
The density and the quality of 
information with Lidar is much higher 

545
00:41:13,080 --> 00:41:17,370
and lighter has been the successful 
source of ground truth.

546
00:41:17,900 --> 00:41:22,900
The reliable sensor relied upon on 
vehicles that don't care about cost

547
00:41:26,400 --> 00:41:31,400
and camera.
The thing that most people here should 

548
00:41:31,400 --> 00:41:32,010
be passionate about because machine 
learning,

549
00:41:32,250 --> 00:41:37,250
deep learning,
the most ability to have a significant 

550
00:41:37,250 --> 00:41:39,170
impact there.
Why versus cheap,

551
00:41:39,260 --> 00:41:42,230
so it's everywhere.
Second is the highest resolution,

552
00:41:42,231 --> 00:41:47,231
so there's the most,
the most highly dense amount of 

553
00:41:47,231 --> 00:41:50,381
information,
which means information is something 

554
00:41:50,841 --> 00:41:55,841
that can be learned and inferred to 
interpret the external scene.

555
00:41:56,430 --> 00:42:01,220
So that's why it's the best source of 
data for understanding the scene.

556
00:42:02,090 --> 00:42:07,090
And the other reason it's awesome for 
deep learning is because of the hugeness

557
00:42:07,941 --> 00:42:10,790
of data involved,
the,

558
00:42:10,820 --> 00:42:15,820
it's many orders of magnitude more data 
available for driving in camera,

559
00:42:16,071 --> 00:42:19,400
visible light or infrared than it is in 
Lidar.

560
00:42:21,770 --> 00:42:22,980
Uh,
the.

561
00:42:24,900 --> 00:42:29,040
And our world is designed for visible 
light.

562
00:42:29,130 --> 00:42:33,630
Our eyes work in similar ways,
the cameras at least crudely.

563
00:42:33,631 --> 00:42:38,250
So the source data is similar.
The lane markings,

564
00:42:38,580 --> 00:42:41,670
the traffic size of traffic lights,
the other vehicles,

565
00:42:41,990 --> 00:42:46,770
the other pedestrians all operate with 
each other in this rgb space.

566
00:42:47,940 --> 00:42:52,940
In terms of visual characteristics,
the downside is cameras are bad at depth

567
00:42:54,061 --> 00:42:59,061
estimation,
it's noisy and difficult even with 

568
00:42:59,061 --> 00:43:02,271
stereo vision cameras to estimate depth 
relative to lidar and they're not good 

569
00:43:03,031 --> 00:43:07,440
and extreme weather and they're not good
at least visible light cameras at night.

570
00:43:10,440 --> 00:43:15,440
So let's compare the ranges.
Here's a plot and meters on the x axis 

571
00:43:15,930 --> 00:43:20,930
of the range.
And Acuity on the y axis with ultrasonic

572
00:43:25,740 --> 00:43:30,740
lidar radar and camera passive visual 
sensor plotted the range of cameras as 

573
00:43:36,091 --> 00:43:41,091
the greatest this is looking at.
We're going to look at several different

574
00:43:41,161 --> 00:43:44,190
conditions.
This is for clear well lit conditions,

575
00:43:44,520 --> 00:43:47,370
so during the day,
no rain,

576
00:43:48,630 --> 00:43:53,630
no fog,
lidar and radar have a smaller range 

577
00:43:53,630 --> 00:43:57,441
under 200 meters and ultrasonic sensors 
used mostly for park assistance and 

578
00:43:57,631 --> 00:44:02,631
these kinds of things.
And blind spot warning has terrible 

579
00:44:02,631 --> 00:44:06,531
range,
is designed for extremely close as high 

580
00:44:06,531 --> 00:44:10,011
resolution distance estimation for 
extremely close distances here,

581
00:44:11,620 --> 00:44:14,960
a little bit small,
but looking at up top is clear.

582
00:44:14,961 --> 00:44:19,961
Well lit conditions the plow would just 
looked at and I'm bottom is clear dark 

583
00:44:19,961 --> 00:44:21,840
conditions,
so just a clear night day,

584
00:44:22,080 --> 00:44:27,080
no rain but it's night.
And on the bottom right is heavy rain.

585
00:44:27,780 --> 00:44:32,780
Snow or fog.
Vision falls in terms of range and 

586
00:44:33,211 --> 00:44:37,980
accuracy under dark conditions and in 
rain,

587
00:44:37,981 --> 00:44:42,981
snow or fog radar.
Our old trusted friend stay strong.

588
00:44:44,850 --> 00:44:49,290
The same range just under 200 meters and
at the same acuity,

589
00:44:50,940 --> 00:44:55,920
same with sonar.
Lighter works well at night,

590
00:44:56,700 --> 00:44:59,580
but it does not do well with rain or fog
or snow.

591
00:45:01,750 --> 00:45:06,010
One of the biggest downsides of lighter 
other than cost.

592
00:45:06,160 --> 00:45:11,160
So here's another interesting way to 
visualize this that I think is 

593
00:45:11,160 --> 00:45:13,450
productive far discussion of which 
sensor will win out.

594
00:45:14,080 --> 00:45:19,080
Is that the ell musk prediction of 
camera or is it the way more prediction 

595
00:45:19,480 --> 00:45:24,480
of Lidar for lidar in this kind of plot 
that will look for every single sensor,

596
00:45:29,040 --> 00:45:34,040
the greater the radius of the blue,
the more successful that sensor is that 

597
00:45:35,191 --> 00:45:40,191
accomplishing that feature with a bunch 
of features lined up around the circle,

598
00:45:41,310 --> 00:45:44,070
so range for lighter is pretty good,
not great,

599
00:45:44,071 --> 00:45:47,160
but pretty good.
Resolution is also pretty good.

600
00:45:47,790 --> 00:45:50,700
It works in the dark.
It works in bright light,

601
00:45:53,300 --> 00:45:58,300
but it falls apart in the snow.
It does not provide color information,

602
00:45:59,221 --> 00:46:01,050
texture,
information contrast.

603
00:46:01,770 --> 00:46:04,890
It's able to detect speed,
but the sensor size,

604
00:46:04,950 --> 00:46:07,080
at least to date,
is huge.

605
00:46:07,350 --> 00:46:09,720
The sensor cost,
at least to date,

606
00:46:09,810 --> 00:46:14,810
is extremely expensive and it doesn't do
well in proximity.

607
00:46:15,930 --> 00:46:19,820
We're ultrasonic shines.
Speaking of which,

608
00:46:20,220 --> 00:46:23,330
ultrasonic,
same kind of plot does well in proximity

609
00:46:23,340 --> 00:46:24,890
detection.
It's cheap,

610
00:46:24,891 --> 00:46:28,250
the cheapest sensor or the four and 
census size.

611
00:46:28,251 --> 00:46:32,300
You can get it to be tiny.
It works in snow,

612
00:46:32,330 --> 00:46:36,410
fog and rain,
but it's resolution is terrible.

613
00:46:36,470 --> 00:46:41,210
It's range is nonexistent and it's not 
able to detect speed.

614
00:46:42,790 --> 00:46:45,820
That's where radar steps up.
It's able to detect speed.

615
00:46:45,880 --> 00:46:49,690
It's also cheap.
It's also small,

616
00:46:51,940 --> 00:46:56,940
but the resolution is very low and it's 
just like lidar is not able to provide 

617
00:46:56,940 --> 00:46:57,890
texture.
Information,

618
00:46:57,910 --> 00:47:01,060
call information camera.

619
00:47:03,350 --> 00:47:07,130
The sensor costs is cheap.
The sensor size is small,

620
00:47:07,640 --> 00:47:12,170
not good up close proximity.
The range is the longest of all of them.

621
00:47:12,290 --> 00:47:16,730
Resolution is the best of all of them.
It doesn't work in the dark.

622
00:47:17,270 --> 00:47:20,630
It works in bright light,
but not always.

623
00:47:20,840 --> 00:47:25,840
One of the biggest downfalls of cameras 
sensors is the sensitivity to lighting 

624
00:47:25,840 --> 00:47:27,020
variation.
It works.

625
00:47:27,470 --> 00:47:29,230
It doesn't work in the snow.
Fog,

626
00:47:29,231 --> 00:47:33,340
rain so suffers much like lidar from 
that,

627
00:47:33,640 --> 00:47:38,410
but it provides rich,
interesting textural information.

628
00:47:38,620 --> 00:47:42,100
The very kind that deep learning needs 
to make sense of this world.

629
00:47:43,780 --> 00:47:48,780
So let's look at the cheap sensors.
Ultrasonic radar and cameras,

630
00:47:52,990 --> 00:47:57,990
which is one approach.
Putting a bunch of those in the car and 

631
00:47:57,990 --> 00:48:01,600
fusing them together,
the cost there is low.

632
00:48:02,560 --> 00:48:07,560
One of the nice ways to visualize using 
this visualization technique when 

633
00:48:07,841 --> 00:48:12,841
they're fused together on the bottom,
it gives you a sense of them working 

634
00:48:13,691 --> 00:48:18,691
together to compliment each other's 
strengths and the question is where the 

635
00:48:22,001 --> 00:48:27,001
camera or lidar will win out for partial
autonomy or full autonomy on the bottom,

636
00:48:29,151 --> 00:48:34,151
showing this kind of visualization for a
lidar sensor and on top showing this 

637
00:48:35,511 --> 00:48:40,511
kind of visualization for fused radar,
ultrasonic and camera.

638
00:48:42,860 --> 00:48:47,860
At least under these considerations,
the fusion of the cheap sensors can do 

639
00:48:49,311 --> 00:48:50,450
as well as lighter.

640
00:48:51,730 --> 00:48:56,730
Now,
the open question is whether the Lidar 

641
00:48:56,730 --> 00:48:57,070
and the future of this technology can 
become cheap and it's ranged,

642
00:48:57,071 --> 00:49:02,071
can increase [inaudible].
Then Lidar can win out solid state lidar

643
00:49:02,170 --> 00:49:07,170
and a lot of developments with a lot of 
startup ladder companies are promising 

644
00:49:07,170 --> 00:49:10,540
to decrease the costs and increase the 
range of the sensors,

645
00:49:11,770 --> 00:49:16,770
but for now we plow long dedication on 
the camera front.

646
00:49:19,300 --> 00:49:23,020
The annotated driving data grows 
exponentially.

647
00:49:24,250 --> 00:49:29,250
More and more people are beginning to 
annotate and study the particular 

648
00:49:30,281 --> 00:49:35,281
driving perception and control problems 
and the very algorithms for the 

649
00:49:38,111 --> 00:49:43,111
supervisor and semi-supervised and 
generative networks that we use to work 

650
00:49:43,111 --> 00:49:47,281
with this data are improving.
So it's a race and of course radar and 

651
00:49:47,791 --> 00:49:50,140
ultrasonic.
I was there to help,

652
00:49:51,340 --> 00:49:55,030
so companies that are playing in this 
space,

653
00:49:56,320 --> 00:49:58,060
some of them are speaking here

654
00:50:01,360 --> 00:50:06,360
waymo in April 2017.
They exited their testing,

655
00:50:08,470 --> 00:50:13,470
their extensive impressive testing 
process and allowed the first rider and 

656
00:50:15,281 --> 00:50:20,281
Phoenix public rider in November 2017 
and it's an incredible accomplishment 

657
00:50:23,050 --> 00:50:28,050
for our company and for an artificial 
intelligence system in November 2017.

658
00:50:28,610 --> 00:50:33,610
No safety driver.
So the car truly achieved full autonomy 

659
00:50:33,800 --> 00:50:37,700
and there are a lot of constraints,
but it's full autonomy.

660
00:50:37,880 --> 00:50:42,880
It's a step.
It's an amazing step in the direction 

661
00:50:42,880 --> 00:50:45,860
towards full autonomy much sooner than 
people would otherwise predict.

662
00:50:46,730 --> 00:50:51,730
And the miles,
4 million miles driven autonomously by 

663
00:50:51,730 --> 00:50:55,541
November 2017 and growing quickly 
growing in terms of full autonomous 

664
00:50:55,881 --> 00:51:00,881
driving,
if I can say so cautiously because most 

665
00:51:00,881 --> 00:51:05,480
of those miles have a safety driver.
So I would argue it's not full autonomy,

666
00:51:05,960 --> 00:51:10,220
but however they define full autonomy,
it's 4 million miles driven,

667
00:51:11,060 --> 00:51:16,060
incredible uber in terms of miles second
on that list,

668
00:51:17,000 --> 00:51:22,000
they have driven 2 million miles 
autonomy by December of this of last 

669
00:51:23,240 --> 00:51:24,410
year,
2017,

670
00:51:26,810 --> 00:51:31,810
the quiet player here in terms of not 
making any declarations of being fully 

671
00:51:33,811 --> 00:51:37,650
autonomous,
just quietly driving in a human centered

672
00:51:37,651 --> 00:51:42,651
way.
L Two over 1 billion miles in autopilot.

673
00:51:43,890 --> 00:51:48,890
Over 300,000
vehicles today are equipped with 

674
00:51:49,171 --> 00:51:54,171
autopilot technology,
with the ability to drive control the 

675
00:51:54,171 --> 00:51:57,651
car laterally and longitudinally.
And if anyone believes the CEO of Tesla,

676
00:52:03,480 --> 00:52:08,220
there'll be over 1 million such vehicles
by the end of 2018.

677
00:52:11,440 --> 00:52:16,440
But no matter what,
the 300 thousands and incredible number 

678
00:52:16,440 --> 00:52:19,180
and the 1 billion miles is an incredible
number.

679
00:52:20,890 --> 00:52:23,920
Autopilot was first released in 
September 2014,

680
00:52:24,100 --> 00:52:29,100
one of the first systems on the road to 
do so autopilot.

681
00:52:30,400 --> 00:52:35,400
And I caught myself as one of the 
skeptics in October 2016.

682
00:52:36,370 --> 00:52:41,370
Autopilot decided to let go of an 
incredible work done by Mobileye.

683
00:52:43,270 --> 00:52:48,170
Now Intel,
we're designing their perception control

684
00:52:48,171 --> 00:52:53,171
system.
They decided to let go of it completely 

685
00:52:53,171 --> 00:52:55,511
and start from scratch using mostly deep
learning methods that drive px to system

686
00:52:56,061 --> 00:53:01,061
from Nvidia and eight cameras.
They decided to start from scratch.

687
00:53:03,620 --> 00:53:07,910
That's the kind of boldness,
the kind of risk taking.

688
00:53:07,940 --> 00:53:12,940
They can come with naivety,
but in this case it worked incredible.

689
00:53:16,480 --> 00:53:21,480
A eight system is going to be released 
at the end of 2018 and this promising 

690
00:53:22,451 --> 00:53:27,451
one of the first vehicles that's 
promising what they're calling l and the

691
00:53:27,781 --> 00:53:32,781
definition of l three,
a coordinated Thorston Lionheart,

692
00:53:34,620 --> 00:53:37,110
the head of the automated driving an 
Audi,

693
00:53:37,770 --> 00:53:42,770
and Audi is one of the function is 
operating as intended if the customer 

694
00:53:43,531 --> 00:53:48,531
turns the traffic jam pilot on.
Now this l three system is designed only

695
00:53:49,951 --> 00:53:54,951
for traffic jams,
bumper to bumper traffic under 60 

696
00:53:55,231 --> 00:53:56,370
kilometers an hour.

697
00:53:57,970 --> 00:54:01,750
If the customer turns the traffic jam 
pilot on and uses it as intended,

698
00:54:01,870 --> 00:54:05,410
and the car was in control at the time 
of the accident,

699
00:54:05,560 --> 00:54:10,560
the driver goes to the insurance company
and the insurance company will 

700
00:54:10,560 --> 00:54:12,250
compensate the victims of the accident 
and aftermath.

701
00:54:12,580 --> 00:54:15,070
They come to us,
we will pay them.

702
00:54:16,500 --> 00:54:21,500
So that means the car is liable.
The problem is under the definition of 

703
00:54:24,061 --> 00:54:25,020
l,
two l three,

704
00:54:25,021 --> 00:54:28,260
perhaps there is some truth to this 
being an l three system.

705
00:54:29,700 --> 00:54:34,700
The important thing here is nevertheless
less deeply and fundamentally human 

706
00:54:34,700 --> 00:54:39,051
centered because even as you see here in
this demonstration video with a 

707
00:54:39,051 --> 00:54:43,351
reporter,
the car for a poorly understood reason,

708
00:54:43,710 --> 00:54:46,080
transfer control to the driver says,
that's it,

709
00:54:46,081 --> 00:54:48,750
I can't.
I can't take care of the situation.

710
00:54:48,930 --> 00:54:49,830
You take control.

711
00:54:50,730 --> 00:54:55,730
How,
how much time do you have in terms of 

712
00:54:55,730 --> 00:54:58,140
seconds before you really need to know 
to take over?

713
00:54:58,830 --> 00:55:00,810
Well,
this is the new thing about level three.

714
00:55:01,220 --> 00:55:06,120
With level three,
the system allows the driver to give the

715
00:55:06,121 --> 00:55:09,630
prompt to take over vico control again 
ahead of time,

716
00:55:09,631 --> 00:55:14,070
which is in this case up to 10 seconds.
Okay,

717
00:55:14,610 --> 00:55:19,230
so if the traffic jam situation clears 
up or anything,

718
00:55:19,310 --> 00:55:22,770
she failed her in the system careers,
everything you might think of,

719
00:55:23,130 --> 00:55:28,130
the system still needs to be able to dry
automatically because it's a driver has 

720
00:55:28,130 --> 00:55:32,160
this time to take over.
You might ask them,

721
00:55:32,340 --> 00:55:37,340
what is new about this?
So why is he saying this is the first 

722
00:55:37,340 --> 00:55:41,870
level three system worldwide on the 
market when talking about these levels 

723
00:55:42,961 --> 00:55:46,250
of automation,
there's a classification which starts as

724
00:55:46,260 --> 00:55:51,260
low as zero,
which is basically the driver's doing 

725
00:55:51,260 --> 00:55:51,260
everything,
there's no assistance,

726
00:55:51,260 --> 00:55:51,330
nothing.

727
00:55:52,390 --> 00:55:57,390
And then it gradually becomes into 
partly automation and when we're talking

728
00:55:57,991 --> 00:56:00,650
about these assistants functions like 
lay,

729
00:56:00,651 --> 00:56:02,440
keeping a distance,
keeping a,

730
00:56:02,540 --> 00:56:04,950
we're talking about level two assistants
functions,

731
00:56:05,610 --> 00:56:10,610
which is um,
meaning that the driver is obliged to 

732
00:56:12,571 --> 00:56:16,920
permanently monitored the traffic 
situation to keep the hands on the wheel

733
00:56:17,310 --> 00:56:22,310
even though there's the support and 
assistance and to intervene immediately 

734
00:56:22,310 --> 00:56:26,990
if anything is not quite right.
So you know that from living assistance 

735
00:56:26,990 --> 00:56:31,000
systems when the steering is not 
perfectly in the right lane,

736
00:56:31,090 --> 00:56:33,100
you have to intervene and correct 
immediately.

737
00:56:33,340 --> 00:56:37,780
And that is the main difference.
Now we gotta take over the crest.

738
00:56:38,050 --> 00:56:39,350
So what,
so let's,

739
00:56:39,470 --> 00:56:40,820
let's talk about what

740
00:56:42,730 --> 00:56:47,730
that means.
This is still a human center system is 

741
00:56:47,730 --> 00:56:51,721
still struggles.
It's still must solve the human robot 

742
00:56:51,721 --> 00:56:51,721
interaction problem

743
00:56:52,570 --> 00:56:57,570
and there's many others playing in the 
space and they on the full autonomy 

744
00:56:57,570 --> 00:56:57,570
side,
Waymo,

745
00:56:57,570 --> 00:57:00,190
uber,
GM cruise Yutani.

746
00:57:01,330 --> 00:57:03,880
The CTO,
which we'll speak here on Tuesday,

747
00:57:04,450 --> 00:57:09,450
optimists ride is annuity voyage,
the CEO of which we'll speak here next 

748
00:57:12,880 --> 00:57:17,440
Thursday,
and Aurora not listed,

749
00:57:17,610 --> 00:57:20,590
the the founder of which we'll speak 
here next Friday,

750
00:57:21,580 --> 00:57:26,580
and the human centered autonomy side.
The reason I am a speaking about us so 

751
00:57:27,551 --> 00:57:29,500
much today is we don't have any 
speakers.

752
00:57:29,680 --> 00:57:34,680
I'm the speaker.
The Tesla autopilot is for several years

753
00:57:34,811 --> 00:57:39,811
now doing incredible work on that side.
We're also working with Volvo pilot 

754
00:57:39,811 --> 00:57:44,140
assist as a lot of different approaches.
They're more conservative.

755
00:57:44,500 --> 00:57:48,310
Interesting.
The audio traffic jam assist,

756
00:57:48,311 --> 00:57:53,311
as I mentioned,
the eight being released at the end of 

757
00:57:53,311 --> 00:57:54,310
this year.
I'm the Mercedes drive politest system.

758
00:57:54,311 --> 00:57:59,311
The eclass an interesting vehicle that I
got to drive quite a bit as the Cadillac

759
00:58:00,430 --> 00:58:01,480
Super Cruise.
The ct six,

760
00:58:01,870 --> 00:58:06,870
which is very much constrained 
geographically to highway driving and 

761
00:58:08,380 --> 00:58:11,050
the loudest.
Proudest of the mall.

762
00:58:11,470 --> 00:58:14,170
George Hotz of the.
I opened pilot.

763
00:58:15,100 --> 00:58:20,100
Let's just leave that there,
so where can ai help?

764
00:58:26,490 --> 00:58:30,240
We'll get into the details of the coming
lectures on each individual component.

765
00:58:30,540 --> 00:58:35,520
I'd like to get some examples.
The key areas,

766
00:58:35,550 --> 00:58:40,550
problem spaces that we can use machine 
learning to solve from data is 

767
00:58:41,340 --> 00:58:46,340
localization and mapping,
so being able to localize yourself in 

768
00:58:46,340 --> 00:58:47,040
the space,
very first question,

769
00:58:47,041 --> 00:58:52,041
that robot and use to answer,
where am I seeing understanding,

770
00:58:52,710 --> 00:58:54,870
taking the scene in and interpreting 
that scene,

771
00:58:55,170 --> 00:59:00,170
detecting all the entities in the scene,
detecting the class of those entities in

772
00:59:01,891 --> 00:59:05,700
order to then do movement planning to 
move around those entities.

773
00:59:06,210 --> 00:59:09,270
And finally,
driver's state essential element for the

774
00:59:09,271 --> 00:59:12,210
human robot interaction.
Perceive everything about the driver,

775
00:59:12,330 --> 00:59:17,330
everything about the pedestrians and the
cyclists and the cars outside the human 

776
00:59:17,330 --> 00:59:21,070
element of those,
the human perception side.

777
00:59:22,040 --> 00:59:23,510
So first the,
where am I?

778
00:59:23,900 --> 00:59:28,900
Visual adometry using cameras sensors,
which is really where,

779
00:59:29,800 --> 00:59:31,870
once again,
deep learning is most,

780
00:59:31,990 --> 00:59:36,990
uh,
the vision sensor is the most amenable 

781
00:59:36,990 --> 00:59:40,290
to learning based approaches.
And visual adometry is using camera to 

782
00:59:40,290 --> 00:59:45,121
localize yourself.
To answer the where am I question the 

783
00:59:45,121 --> 00:59:50,091
traditional approaches slam detect 
features in the scene and track them 

784
00:59:53,191 --> 00:59:58,191
through time from frame to frame.
And from the movement of those features 

785
00:59:58,351 --> 01:00:02,040
are able to estimate a thousands of 
features.

786
01:00:02,160 --> 01:00:04,560
Tracking,
estimate the location,

787
01:00:04,830 --> 01:00:08,070
the orientation of the vehicle or the 
camera.

788
01:00:11,120 --> 01:00:16,120
Those methods was stereo.
Vision first requires taking two camera 

789
01:00:16,120 --> 01:00:21,071
streams on distorting them.
Competing disparity map from the 

790
01:00:21,071 --> 01:00:22,700
different perspectives,
the two camera computing,

791
01:00:22,880 --> 01:00:27,020
the matching between the two,
the feature detection,

792
01:00:27,560 --> 01:00:32,560
the sift to fast or any of the methods 
of extracting non deep learning methods 

793
01:00:32,601 --> 01:00:37,601
of extracting features,
strong detectable features that can be 

794
01:00:37,601 --> 01:00:41,861
tracked through from frame to frame,
tracking those features and estimating 

795
01:00:41,861 --> 01:00:44,510
the trajectory,
the orientation of the camera.

796
01:00:45,020 --> 01:00:50,020
That's the traditional approach to 
visual odometry in the recent years 

797
01:00:50,020 --> 01:00:54,571
since 2015,
but most success in the last year has 

798
01:00:55,781 --> 01:01:00,781
been the end to end.
Deep learning approaches either Stereo 

799
01:01:00,781 --> 01:01:04,500
monocular cameras.
Deep Vo is one of the most successful.

800
01:01:06,250 --> 01:01:11,250
The ntn methods is taken a sequence of 
images extracting with a CNN from each 

801
01:01:11,321 --> 01:01:14,450
image,
the central features from each image,

802
01:01:14,690 --> 01:01:19,690
and then using rnn recurrent neural 
network to track over time the 

803
01:01:19,690 --> 01:01:24,131
trajectory,
the pose of the camera image to pose and

804
01:01:25,791 --> 01:01:30,791
to end.
Here's the visualization on a kitty 

805
01:01:30,791 --> 01:01:32,960
dataset using DPO.
Again,

806
01:01:32,961 --> 01:01:37,550
taking the video up on the top right as 
an input and estimating,

807
01:01:37,551 --> 01:01:42,551
what's visualized is the position of the
vehicle in red is the estimate based 

808
01:01:45,140 --> 01:01:50,140
again end to end with a CNN and rnn.
The in red is the estimate in blue is 

809
01:01:51,741 --> 01:01:53,810
the ground truth in the Kitty Dataset,

810
01:01:55,750 --> 01:01:59,410
so this removes a lot of the modular 
parts of Slam,

811
01:02:00,330 --> 01:02:04,180
a visual adometry and allows it to be 
end to end,

812
01:02:04,570 --> 01:02:07,900
which means it's learnable,
which means it gets better with data.

813
01:02:09,280 --> 01:02:10,090
That's huge

814
01:02:11,590 --> 01:02:16,590
and that's vision alone.
This is one of the exciting 

815
01:02:16,590 --> 01:02:20,191
opportunities for ai or people working 
in ai is the ability to use a single 

816
01:02:22,441 --> 01:02:27,441
sensor and perhaps the most inspiring 
because that sensor is similar to our 

817
01:02:27,441 --> 01:02:32,271
own the sensor that we ourselves use of 
our eyes to use that alone as the 

818
01:02:34,531 --> 01:02:39,330
primary sensor to control a vehicle.
That's really exciting and the fact that

819
01:02:39,331 --> 01:02:44,331
deep learning that the vision visible 
light is the most amenable to deep 

820
01:02:44,331 --> 01:02:48,771
learning approaches makes this 
particular an exciting area for deep 

821
01:02:48,771 --> 01:02:50,880
learning research seen understanding of 
course,

822
01:02:51,150 --> 01:02:53,940
who can do a thousand slides on this?
Traditionally,

823
01:02:53,970 --> 01:02:55,820
object detection,
pedestrians,

824
01:02:55,830 --> 01:03:00,830
vehicles,
there is a bunch of different types of 

825
01:03:00,830 --> 01:03:03,600
classifiers and feature extraction is 
hard like features and deep learning has

826
01:03:03,660 --> 01:03:07,950
basically taken over and dominate every 
aspect of scene,

827
01:03:07,951 --> 01:03:10,140
interpretation,
perception,

828
01:03:10,260 --> 01:03:12,030
understanding,
tracking,

829
01:03:12,540 --> 01:03:13,830
recognition,
classification,

830
01:03:13,831 --> 01:03:14,940
detection problems

831
01:03:15,820 --> 01:03:20,820
and audio.
Can't forget audio that we can use audio

832
01:03:23,360 --> 01:03:28,360
as source of information,
whether that's detecting honks or in 

833
01:03:28,360 --> 01:03:31,751
this case using the audio of the tires,
microphones on the tires to determine,

834
01:03:32,601 --> 01:03:37,601
visualize.
There's a spectrogram of the audio 

835
01:03:37,601 --> 01:03:39,671
coming in.
For those of you who are particularly 

836
01:03:42,380 --> 01:03:47,380
have a particularly tuned ear,
can listen to the different audio coming

837
01:03:48,021 --> 01:03:53,021
in here of wet road and drive road after
the rain so there's no rain,

838
01:03:54,421 --> 01:03:59,421
but the road is nevertheless wet and 
detecting that as extremely important 

839
01:03:59,421 --> 01:04:01,110
for vehicles because they still don't 
have traction.

840
01:04:01,111 --> 01:04:06,030
Control is that have poor control in 
road to road surface,

841
01:04:06,120 --> 01:04:11,120
tired road surface connection,
and being able to detect that from just 

842
01:04:11,120 --> 01:04:11,970
audio is a very interesting approach.

843
01:04:15,490 --> 01:04:17,200
Finally or not.
Finally,

844
01:04:17,201 --> 01:04:21,520
next for the perception control side.
Finally is the movement planning.

845
01:04:21,550 --> 01:04:24,250
Getting from a to point b from point a 
to point b.

846
01:04:24,550 --> 01:04:28,870
traditional approaches,
the optimization based approach,

847
01:04:29,400 --> 01:04:33,400
determine the optimal control,
try to reduce the problem,

848
01:04:33,430 --> 01:04:38,430
formalize the problem in a way that's 
amenable to optimization based 

849
01:04:38,531 --> 01:04:43,531
approaches.
There's a lot of assumptions that need 

850
01:04:43,531 --> 01:04:45,940
to be made.
Once those assumptions are made,

851
01:04:46,000 --> 01:04:51,000
you're able to determine to generate 
thousands or millions of possible 

852
01:04:51,551 --> 01:04:56,551
trajectories and have an objective 
function would determine which of the 

853
01:04:56,551 --> 01:04:58,510
trajectories to take.
Here's a race car optimizing how to take

854
01:04:58,690 --> 01:05:00,340
a turn at high speed

855
01:05:02,860 --> 01:05:07,860
learning reinforcement,
learning the application you'll know or 

856
01:05:08,981 --> 01:05:13,981
it's three enforcement learning is 
particularly exciting for both the 

857
01:05:13,981 --> 01:05:18,601
control and the planning side,
so that's where the two of the 

858
01:05:20,591 --> 01:05:22,810
competitions were doing in this class 
coming into play,

859
01:05:23,740 --> 01:05:28,740
the simplistic two dimensional world of 
deep traffic and the high high speed 

860
01:05:30,431 --> 01:05:35,431
moving.
I risked world of deep crash.

861
01:05:38,740 --> 01:05:40,240
We'll explore those tomorrow.

862
01:05:42,550 --> 01:05:47,550
Tomorrow's lecture is on deeper 
enforcement learning and finally 

863
01:05:47,550 --> 01:05:51,901
driver's state detecting everything 
about the driver and then interacting 

864
01:05:52,001 --> 01:05:57,001
with them.
On the left in green are the easier 

865
01:05:57,001 --> 01:05:58,750
problems on the right in red are the 
harder problems in terms of perception,

866
01:05:58,751 --> 01:06:02,350
in terms of how amenable they are to 
deep learning methods.

867
01:06:02,830 --> 01:06:07,830
Body pose estimation is a very well 
studied problem.

868
01:06:08,470 --> 01:06:11,710
We have extremely good detectors for 
estimating the pose,

869
01:06:12,130 --> 01:06:13,600
the hands,
the elbows,

870
01:06:13,601 --> 01:06:15,490
the shoulders,
every aspect,

871
01:06:15,580 --> 01:06:18,640
visible aspect of the body.
Head pose,

872
01:06:18,820 --> 01:06:22,240
the orientation of the head or extremely
good at that,

873
01:06:22,930 --> 01:06:25,750
and as we get smaller and smaller in 
terms of size,

874
01:06:25,930 --> 01:06:28,420
blink rate,
blink duration,

875
01:06:28,870 --> 01:06:32,530
Ipos and bling dynamics start getting 
more and more difficult.

876
01:06:32,980 --> 01:06:36,550
All of these metrics,
all of these metrics extremely important

877
01:06:36,551 --> 01:06:41,551
for detecting things like drowsiness or 
as components of detecting emotion or 

878
01:06:41,551 --> 01:06:46,070
where people are looking and driving 
where your head is turned is not 

879
01:06:46,241 --> 01:06:50,500
necessarily where you're looking in 
regular life.

880
01:06:51,820 --> 01:06:54,190
Non-Driving life.
When you look somewhere,

881
01:06:54,191 --> 01:06:59,191
you usually turn your head to look with 
your eyes in driving your head office.

882
01:07:02,141 --> 01:07:05,770
They still or moves very subtly.
Your eyes do a lot more moving.

883
01:07:06,520 --> 01:07:11,140
It's the kind of a effect it would 
described as the lizard owl effect.

884
01:07:12,130 --> 01:07:15,130
Some fraction of people,
a small fraction are owls,

885
01:07:15,550 --> 01:07:19,870
meaning they move their head a lot and 
some people,

886
01:07:19,900 --> 01:07:23,950
most people are lizards moving eyes to 
allocate their attention.

887
01:07:24,520 --> 01:07:27,820
The problem with eyes is from the 
computer vision perspective,

888
01:07:27,821 --> 01:07:32,821
they're much harder to detect in 
lighting variation in the real world 

889
01:07:32,821 --> 01:07:33,760
conditions,
they get harder and we'll discuss how to

890
01:07:33,761 --> 01:07:35,830
deal with it.
Of course,

891
01:07:35,980 --> 01:07:39,070
that's where deep learning steps up and 
really helps with real world data.

892
01:07:40,450 --> 01:07:45,450
Cognitive load.
We'll discuss as well as the meeting of 

893
01:07:45,450 --> 01:07:46,330
the cognitive load of the driver to 
give.

894
01:07:46,331 --> 01:07:51,331
A quick clip is this is the driver 
glance I've seen before estimating the 

895
01:07:51,331 --> 01:07:56,011
very most important problem on driver 
state side is determining whether 

896
01:07:59,261 --> 01:08:01,420
they're looking on road or off road.

897
01:08:02,080 --> 01:08:03,700
It's the dumbest,
simplest,

898
01:08:03,820 --> 01:08:07,390
but most important aspect.
Are they looking at are they in the seat

899
01:08:07,420 --> 01:08:12,420
and looking on the road or are they not?
That's driver glance classification.

900
01:08:14,200 --> 01:08:17,990
Not estimating the Xyz geometric 
orientation where they're looking,

901
01:08:18,290 --> 01:08:23,290
but actually binary class classification
on road or off road body pose 

902
01:08:24,051 --> 01:08:28,820
estimation,
determining of the hands on wheel or not

903
01:08:28,880 --> 01:08:33,880
determining if the body alignment is 
standard is good for seatbelt,

904
01:08:34,370 --> 01:08:39,370
for safety.
This is one of the important things for 

905
01:08:39,370 --> 01:08:42,461
autonomous vehicles.
If there's an imminent danger to the 

906
01:08:42,461 --> 01:08:45,581
driver,
the driver should be asked to return to 

907
01:08:45,581 --> 01:08:48,440
a position that is safe for them in a in
case of a crash driver.

908
01:08:48,441 --> 01:08:49,190
Emotion

909
01:08:53,690 --> 01:08:58,280
on the top is a satisfied on the bottom 
as a frustrated driver,

910
01:08:58,850 --> 01:09:02,360
they self report as satisfied.
This is what the voice based navigation.

911
01:09:02,361 --> 01:09:06,280
One of the biggest sources of 
frustrations for people in cars is voice

912
01:09:06,281 --> 01:09:11,281
based navigation.
Trying to tell an artificial 

913
01:09:11,281 --> 01:09:12,710
intelligence system using your voice 
alone where you would like to go.

914
01:09:13,580 --> 01:09:18,580
Huge source of frustration.
One of the interesting things in our 

915
01:09:18,580 --> 01:09:22,721
large data set that we have from the 
effective computing perspective is 

916
01:09:22,721 --> 01:09:26,831
determining which of the features are 
most commonly associated with frustrated

917
01:09:26,900 --> 01:09:29,930
voice based interaction,
and that's a smile is shown.

918
01:09:29,931 --> 01:09:34,931
There is the counterintuitive notion 
that emotion in particular emotion and 

919
01:09:35,541 --> 01:09:40,541
the car is very context dependent,
that smiling is not necessarily a sign 

920
01:09:40,541 --> 01:09:44,811
of happiness and the stoic board look of
the driver up top is not necessarily a 

921
01:09:48,860 --> 01:09:53,860
reflection of unhappiness is indeed a 10
out of 10 in terms of satisfaction with 

922
01:09:55,671 --> 01:10:00,671
the experience if he has ever been 
satisfied with anything happens to be 

923
01:10:03,471 --> 01:10:08,471
Dan Brown,
one of the amazing engineers in our 

924
01:10:08,471 --> 01:10:10,841
team,
cognitive load estimating from the eye 

925
01:10:10,841 --> 01:10:14,741
region and sequences of images and three
d convolutional neural networks taking 

926
01:10:15,321 --> 01:10:19,070
in a sequence of images from the eye,
looking at the blink dynamics in the eye

927
01:10:19,100 --> 01:10:22,790
position to determine the cognitive load
from zero to two,

928
01:10:23,240 --> 01:10:24,590
how deep thought you are.

929
01:10:25,460 --> 01:10:28,940
Two paths to autonomous future.
Again,

930
01:10:29,930 --> 01:10:34,930
I would like to maybe for the last time,
but probably not argue for the one on 

931
01:10:36,771 --> 01:10:40,340
the left because our brilliant much 
smarter than me.

932
01:10:40,520 --> 01:10:43,010
Guest speakers will argue for the one on
the right.

933
01:10:44,780 --> 01:10:49,780
The human centered approach allows us to
solve the problems in 99 percent 

934
01:10:49,780 --> 01:10:51,200
accuracy of localization,
seen understanding,

935
01:10:51,201 --> 01:10:56,201
movement planning.
Those are the problems we're taking on 

936
01:10:56,201 --> 01:10:58,690
this class.
The scene segmentation and we'll talk 

937
01:10:58,690 --> 01:11:01,031
about on Thursday the control that we'll
talk about tomorrow and then drive our 

938
01:11:01,031 --> 01:11:02,600
state that we'll talk about next 
Wednesday.

939
01:11:02,750 --> 01:11:06,320
These problems can be solved with deep 
learning today.

940
01:11:06,920 --> 01:11:11,920
The problems in the right,
solving them to close to 100 percent 

941
01:11:11,920 --> 01:11:13,190
accuracy are extremely difficult and 
maybe decades away.

942
01:11:13,770 --> 01:11:18,770
Because for full autonomy to be here,
we have to solve this situation.

943
01:11:20,580 --> 01:11:22,620
I've shown this many times octet 
triomphe.

944
01:11:23,220 --> 01:11:28,220
We have to solve this situation.
I give you just a few examples.

945
01:11:33,450 --> 01:11:37,110
What do you do have to solve this 
situation?

946
01:11:44,790 --> 01:11:49,790
I sorta subtler situation here is a,
is it busy crosswalk where no autonomous

947
01:11:53,281 --> 01:11:58,281
vehicle will ever have a hope of getting
through unless it asserts itself and I,

948
01:11:58,640 --> 01:12:03,640
there's a couple of vehicles here that 
kind of nudged ourselves through or at 

949
01:12:03,640 --> 01:12:06,240
least when they have the right of way.
Don't necessarily nudge,

950
01:12:06,360 --> 01:12:08,670
but don't hesitate when a pedestrian is 
present.

951
01:12:08,850 --> 01:12:13,770
An ambulance flying by,
even though if you use a trajectory.

952
01:12:13,771 --> 01:12:18,720
So as a pedestrian and intent modeling 
algorithm to predict the momentum of the

953
01:12:18,721 --> 01:12:20,370
pedestrian,
uh,

954
01:12:20,371 --> 01:12:25,080
to estimate where they can possibly go,
you would then Thomas vehicle will stop.

955
01:12:25,290 --> 01:12:27,780
But these vehicles don't stop.
They assert themselves,

956
01:12:27,781 --> 01:12:32,781
they move forward.
Now for full autonomy system,

957
01:12:35,920 --> 01:12:38,110
this may not be the last time I showed 
this video,

958
01:12:40,030 --> 01:12:45,030
but because it's taking full control,
it's following a reward,

959
01:12:45,101 --> 01:12:49,000
function and objective function and all 
of the problems,

960
01:12:49,001 --> 01:12:52,930
the ethical and the ai problems that 
arise,

961
01:12:53,560 --> 01:12:57,190
like this close runner problem will 
arise.

962
01:12:57,880 --> 01:13:02,880
So we have to solve those problems.
We have to design that objective 

963
01:13:02,880 --> 01:13:04,470
function.
So with that,

964
01:13:05,010 --> 01:13:10,010
I'd like to thank you and encourage you 
to come tomorrow because you get a 

965
01:13:10,351 --> 01:13:14,400
chance to participate in deep traffic,
deep reinforcement learning competition.

966
01:13:14,580 --> 01:13:15,300
Thank you very much.

