1
00:00:00,210 --> 00:00:03,660
Welcome back to six zero,
nine,

2
00:00:03,670 --> 00:00:08,670
nine artificial general intelligence.
Today we have Mark Graber.

3
00:00:12,010 --> 00:00:16,720
Thank you.

4
00:00:16,790 --> 00:00:19,790
He is the.
He really doesn't need an introduction,

5
00:00:19,791 --> 00:00:21,200
but we'll give him one.
Anyway,

6
00:00:21,740 --> 00:00:24,680
he's the founder and CEO,
CEO of Boston Dynamics.

7
00:00:24,770 --> 00:00:29,450
He founded the Cmu leg lab in 1980,
the mit leg lab in 1986.

8
00:00:29,690 --> 00:00:34,690
Boston dynamics in 1992.
He and his team have developed some of 

9
00:00:34,690 --> 00:00:39,131
the most amazing robots ever built,
including big dog atlas handle spots,

10
00:00:39,551 --> 00:00:43,040
spot many.
These robots move with the agility,

11
00:00:43,041 --> 00:00:48,041
dexterity,
and even grace that rivals and often 

12
00:00:48,041 --> 00:00:50,831
supersedes that of human movement.
He continues to inspire us with what 

13
00:00:50,831 --> 00:00:55,220
robots are capable of achieving in the 
real world and what physical form future

14
00:00:55,221 --> 00:00:59,360
intelligence systems may take as they 
become integrated in our daily lives.

15
00:00:59,660 --> 00:01:02,090
So please give a warm welcome.

16
00:01:02,390 --> 00:01:07,390
Thank you.

17
00:01:08,360 --> 00:01:13,360
This is our grand mission or aspiration,
which is to make robots that are equal 

18
00:01:14,871 --> 00:01:19,220
to or greater than a people in animals.
And it's,

19
00:01:19,221 --> 00:01:21,610
you know,
it's a daunting mission because a,

20
00:01:21,920 --> 00:01:26,000
we're so good at things.
It seems effortless.

21
00:01:26,001 --> 00:01:27,410
You know,
I'm standing here.

22
00:01:27,590 --> 00:01:30,020
No one questions that I could stand here
like this,

23
00:01:30,200 --> 00:01:33,890
but a lot's going on,
I can manipulate things,

24
00:01:33,891 --> 00:01:38,891
I can pick up this water,
I could reach in my pocket and use my 

25
00:01:38,891 --> 00:01:42,131
hands with all the sensors in my hands 
and coordinate that and maybe most of 

26
00:01:42,131 --> 00:01:44,030
all our perception systems,
you know,

27
00:01:44,031 --> 00:01:45,710
there's audience has,
what is it,

28
00:01:45,711 --> 00:01:50,711
250 people in it or something.
And I can look out there and see every 

29
00:01:50,711 --> 00:01:53,930
one of you a stabilized in space even 
while I'm moving.

30
00:01:54,160 --> 00:01:56,180
It's a,
it's just astounding.

31
00:01:56,181 --> 00:01:56,760
And the,
you know,

32
00:01:56,780 --> 00:02:00,470
robots aren't there yet,
but I think they can be.

33
00:02:00,800 --> 00:02:03,590
And uh,
our goal is to keep chipping away,

34
00:02:03,910 --> 00:02:05,240
uh,
to try and get there.

35
00:02:05,780 --> 00:02:10,780
Before I get started,
I wanted to say that I got my start in 

36
00:02:10,780 --> 00:02:10,780
robotics,
uh,

37
00:02:10,780 --> 00:02:12,470
here at Mit.
I was a graduate student.

38
00:02:12,740 --> 00:02:17,740
I was in the,
what was then called the psychology 

39
00:02:17,740 --> 00:02:20,021
department,
the brain and cognitive sciences 

40
00:02:20,021 --> 00:02:20,021
department.
But I was taking an iap course just like

41
00:02:20,021 --> 00:02:22,160
you are.
And it might've been a,

42
00:02:22,340 --> 00:02:27,340
you know,
exactly this time of year when I 

43
00:02:27,340 --> 00:02:28,940
followed one of my professor burt told 
Horn back,

44
00:02:29,060 --> 00:02:34,060
I had,
I was jabbering away at him asking him 

45
00:02:34,060 --> 00:02:35,120
some questions about this or that.
And we walked back to tech square,

46
00:02:35,121 --> 00:02:37,190
which is where the AI lab was in those 
days.

47
00:02:37,820 --> 00:02:42,820
And uh,
we went up to the ninth floor and 

48
00:02:42,820 --> 00:02:43,700
Russell Oscar,
who was a guy working in the lab,

49
00:02:43,910 --> 00:02:47,060
had an arm all taken apart on the table.

50
00:02:47,210 --> 00:02:52,210
It was like a thousand pieces.
And I was a roboticist from that day on.

51
00:02:53,270 --> 00:02:56,320
I swear I didn't switch my major by,
uh,

52
00:02:56,330 --> 00:02:58,430
you know,
got bertold to be an advisor.

53
00:02:58,730 --> 00:03:03,550
I found a topic that had to do with 
robotics in that time.

54
00:03:03,551 --> 00:03:06,760
It was a manipulation thing,
but eventually became legged,

55
00:03:06,980 --> 00:03:07,690
uh,
thing.

56
00:03:07,930 --> 00:03:09,700
And uh,
it was amazing,

57
00:03:09,720 --> 00:03:10,970
you know,
and,

58
00:03:10,971 --> 00:03:12,730
uh,
I've never looked back.

59
00:03:13,450 --> 00:03:14,290
So,
um,

60
00:03:14,291 --> 00:03:19,291
here are some animals doing things that 
are a very exciting climbing around on 

61
00:03:19,291 --> 00:03:22,960
very rough terrain.
A very sure footed,

62
00:03:23,230 --> 00:03:26,680
using a mixture of their proprioception 
and their vision.

63
00:03:26,920 --> 00:03:31,920
And look,
there's even a baby that probably is 

64
00:03:31,920 --> 00:03:34,231
only a couple of months old,
has no trouble at all doing these 

65
00:03:34,231 --> 00:03:38,281
things.
And a look at the grace and suppleness 

66
00:03:38,290 --> 00:03:38,930
and,
uh,

67
00:03:38,931 --> 00:03:41,200
the fearlessness of,
uh,

68
00:03:41,201 --> 00:03:46,201
of these animals.
It's amazing here are animals running 

69
00:03:46,631 --> 00:03:48,720
for their lives.
Uh,

70
00:03:48,820 --> 00:03:53,820
the Gazelle is trying to stay alive for 
the next 10 minutes and the cheetahs 

71
00:03:53,820 --> 00:03:56,440
trying to get a meal so that it can stay
alive in general.

72
00:04:00,130 --> 00:04:01,630
And uh,
you know,

73
00:04:01,631 --> 00:04:04,040
even people can do things,
uh,

74
00:04:04,090 --> 00:04:09,090
that are breathtec.
I assume all of you were out this 

75
00:04:09,090 --> 00:04:11,520
morning getting a little exercise,
climbing up the green building that 

76
00:04:11,520 --> 00:04:14,191
we're in now.
And then maybe the other places around 

77
00:04:14,191 --> 00:04:14,191
here.
It's funny,

78
00:04:14,191 --> 00:04:16,450
I had bumped into some people when I 
came into the room who were climbing the

79
00:04:16,451 --> 00:04:19,000
stairways,
I think that were going on a trek up and

80
00:04:19,001 --> 00:04:21,880
down them.
But I'd like to see the going outside.

81
00:04:22,780 --> 00:04:25,270
So probably most of you have seen this 
video.

82
00:04:25,840 --> 00:04:30,840
This is a,
this is sort of where we were after 

83
00:04:30,840 --> 00:04:34,981
about 10 years of work thing to make 
machines that could work out in the real

84
00:04:35,431 --> 00:04:40,431
world that we're dynamically stabilize 
dynamics is a big deal for our company 

85
00:04:40,980 --> 00:04:42,840
and for what we do.
So,

86
00:04:42,841 --> 00:04:47,841
uh,
some active sensing and control and 

87
00:04:47,841 --> 00:04:49,340
understanding of the physics.
Um,

88
00:04:51,090 --> 00:04:53,910
here's,
this robot has all this control on board

89
00:04:53,911 --> 00:04:58,911
and it has reflexes and sensors and this
is an extension a to a thousand pound 

90
00:04:59,851 --> 00:05:03,030
robot that could carry about 400 pounds 
of payload.

91
00:05:03,300 --> 00:05:05,070
And we took it all around the United 
States,

92
00:05:05,071 --> 00:05:06,370
testing it,
uh,

93
00:05:06,520 --> 00:05:08,940
in various situations.
Uh,

94
00:05:09,270 --> 00:05:12,870
here we have it in Virginia doing some 
bushwhacking.

95
00:05:13,110 --> 00:05:18,110
It's actually following a person,
but the person is only in that have you 

96
00:05:18,110 --> 00:05:21,711
intermittently.
So it has to be able to keep track of 

97
00:05:21,711 --> 00:05:21,780
where the person is and a deal with 
that.

98
00:05:21,990 --> 00:05:26,990
And then back in good old Boston,
10 inches of snow just marches right up 

99
00:05:27,061 --> 00:05:27,660
the hill.

100
00:05:30,000 --> 00:05:31,290
Here's the Cheetah.
And now you know,

101
00:05:31,291 --> 00:05:34,200
mit has its own cheetah.
This is our cheetah.

102
00:05:34,830 --> 00:05:37,440
Uh,
the people,

103
00:05:37,441 --> 00:05:41,940
no Song Bay who's doing the Mit Cheetah,
um,

104
00:05:45,060 --> 00:05:50,060
a very dynamic machine and basically an 
experiment and seeing how fast we could 

105
00:05:50,060 --> 00:05:54,920
make something like this run,
although you notice it's on a parking 

106
00:05:54,920 --> 00:05:55,800
lot,
so it wasn't doing this on rough terrain

107
00:05:56,130 --> 00:05:59,600
and getting both efficiency and the 
speed in,

108
00:05:59,630 --> 00:06:04,630
in the context of machine they'd also 
can do rough terrain is a really big 

109
00:06:04,630 --> 00:06:08,741
challenge that remains with us.
So this is just a snapshot of a most of 

110
00:06:11,271 --> 00:06:13,820
the robots that we built at Boston 
dynamics over the years.

111
00:06:14,240 --> 00:06:19,240
And uh,
I'm not going to talk about most of 

112
00:06:19,240 --> 00:06:21,161
them.
I'm just going to talk about the last 

113
00:06:21,161 --> 00:06:21,161
four.
Uh,

114
00:06:21,161 --> 00:06:23,360
these are all robots that we developed 
since we'd been part of Google,

115
00:06:23,540 --> 00:06:25,160
which has been the last four years.

116
00:06:25,550 --> 00:06:30,550
A spot many.
There's a spot on the floor here which 

117
00:06:30,550 --> 00:06:31,460
we'll demo the later spot.
Atlas,

118
00:06:31,490 --> 00:06:36,490
the humanoid.
Some of you may remember the humanoid 

119
00:06:36,490 --> 00:06:37,190
that we used in the Darpa robotics 
challenge.

120
00:06:37,191 --> 00:06:40,130
You have one here and uh,
and then handle it,

121
00:06:40,131 --> 00:06:45,131
which is our latest version.
So I'll say a few words to say about 

122
00:06:45,131 --> 00:06:48,371
each of them.
So we had been developing a big dog and 

123
00:06:48,561 --> 00:06:53,561
those other quieter peds that I showed 
you for quite some number of years and 

124
00:06:53,561 --> 00:06:57,251
it was amazing for us to find out when 
we did this project on a spot,

125
00:06:57,410 --> 00:07:02,410
this is the predecessor to that,
that there was still a lot to learn and 

126
00:07:02,410 --> 00:07:06,641
we kind of revolutionize the hardware 
design and how the control worked and 

127
00:07:07,131 --> 00:07:10,760
got a much higher level of rough terrain
performance.

128
00:07:11,150 --> 00:07:15,890
And part of the solution to that was to 
be able to decompose the control problem

129
00:07:16,160 --> 00:07:21,160
into a many separate controllers that 
operated in different regions of state 

130
00:07:21,471 --> 00:07:21,920
space.

131
00:07:22,320 --> 00:07:27,320
Uh,
and that allowed us both to have 

132
00:07:27,320 --> 00:07:27,650
programmers work on multiple solutions 
to the problem.

133
00:07:28,100 --> 00:07:33,100
I'm a and also have the complexity of 
each controller is simplified by only 

134
00:07:34,701 --> 00:07:39,380
having to operate in a small part of the
dynamic space here.

135
00:07:39,381 --> 00:07:44,210
We've added a robot arm to the,
to the previous version of spot.

136
00:07:44,680 --> 00:07:46,130
Um,
and uh,

137
00:07:46,420 --> 00:07:48,710
you know,
we believe that mobile manipulation that

138
00:07:48,711 --> 00:07:53,711
is manipulation when you can move the 
base is really a powerful,

139
00:07:53,930 --> 00:07:56,570
a way of doing things.
Now,

140
00:07:56,571 --> 00:08:01,571
this is probably the most important 
thing I want to show tonight and I'll 

141
00:08:01,571 --> 00:08:03,710
show it three different times,
the idea that we don't build controllers

142
00:08:03,711 --> 00:08:08,711
that just do one particular thing,
but that they can determine where they 

143
00:08:08,711 --> 00:08:10,160
are in the execution,
here's another version of it,

144
00:08:10,550 --> 00:08:15,550
and then adjust what they're doing in 
order to compensate for disturbances in 

145
00:08:15,951 --> 00:08:20,951
the real world.
I know this class is about ai and 

146
00:08:20,951 --> 00:08:20,951
probably autonomy.

147
00:08:22,610 --> 00:08:24,680
Um,
I think that the,

148
00:08:24,980 --> 00:08:29,980
one of the most important ways of 
getting to autonomy is to have the low 

149
00:08:29,980 --> 00:08:33,821
level implementation's very robust to 
disturbances so that the planning steps 

150
00:08:33,821 --> 00:08:38,711
don't have to take care of all the 
minutia of the details of the real 

151
00:08:38,711 --> 00:08:42,821
world.
And that's what we've been trying to do 

152
00:08:42,821 --> 00:08:42,821
there.
Um,

153
00:08:42,821 --> 00:08:45,800
we've been experimenting with doing 
delivery of packages to people's houses.

154
00:08:46,190 --> 00:08:48,620
These are all employees of Boston 
dynamics,

155
00:08:48,621 --> 00:08:51,800
so we didn't go crashing a ordinary 
people's houses.

156
00:08:52,130 --> 00:08:53,030
And,
uh,

157
00:08:53,240 --> 00:08:58,240
it turns out that there's just lots of 
different kinds of stairways and 

158
00:08:58,240 --> 00:08:59,310
interests ways.
Um,

159
00:08:59,520 --> 00:09:01,000
and uh,
uh,

160
00:09:01,050 --> 00:09:06,050
the robot's doing very well.
We're up to something between 70 and 80 

161
00:09:06,050 --> 00:09:06,690
percent of,
uh,

162
00:09:06,990 --> 00:09:08,240
of the kinds of,
uh,

163
00:09:08,460 --> 00:09:10,440
stairs and access places we,
uh,

164
00:09:10,560 --> 00:09:11,890
encounter,
um,

165
00:09:12,240 --> 00:09:16,800
after collecting data and making a 
improvements and adjustments.

166
00:09:20,160 --> 00:09:24,150
So I'm going to say a few philosophical 
things or approach things.

167
00:09:24,660 --> 00:09:29,660
Um,
a lot of people think that this is the 

168
00:09:29,660 --> 00:09:33,141
model of how a computer and a robot 
interact.

169
00:09:33,660 --> 00:09:35,460
That is,
there's the robot,

170
00:09:35,980 --> 00:09:40,980
uh,
which is hardware and electronics and 

171
00:09:40,980 --> 00:09:40,980
sensors and,
uh,

172
00:09:40,980 --> 00:09:43,140
and then there's a computer and that the
computer,

173
00:09:43,150 --> 00:09:47,520
I'm listens to the sensors on the robot 
and then gives it instructions and tells

174
00:09:47,521 --> 00:09:52,521
it what to do.
And while I think that's actually going 

175
00:09:52,521 --> 00:09:56,541
on,
there's another part to the story which 

176
00:09:56,541 --> 00:09:58,830
is that the physical world is also 
giving instructions to the robot.

177
00:09:59,370 --> 00:10:02,850
And that means that the energy's stored 
in the robot,

178
00:10:02,851 --> 00:10:05,580
either in its springs or in.
It's a,

179
00:10:05,950 --> 00:10:07,650
uh,
it's motion.

180
00:10:07,950 --> 00:10:11,520
Those are all important determinants of 
how the robot is going to behave,

181
00:10:11,690 --> 00:10:13,680
uh,
in the time coming forward.

182
00:10:14,220 --> 00:10:18,600
And so we like to think in terms of 
designing the hardware of the robot,

183
00:10:18,870 --> 00:10:23,870
the physical world,
and the computer all as one holistic 

184
00:10:23,870 --> 00:10:26,970
thing where we take into account the,
those interactions.

185
00:10:28,170 --> 00:10:30,550
Sometimes we call this a harmony,
you know,

186
00:10:30,551 --> 00:10:35,551
a harmonic system is one usually where 
you have energy oscillating back and 

187
00:10:35,551 --> 00:10:39,681
forth.
Almost all legged locomotion has some 

188
00:10:39,681 --> 00:10:43,050
amount of a harmony going on between 
potential energy of elevation,

189
00:10:43,290 --> 00:10:48,000
potential energy of elastic deformation,
kinetic energy of motion,

190
00:10:48,360 --> 00:10:49,390
and,
uh,

191
00:10:49,530 --> 00:10:51,330
you know,
inverted pendulum things.

192
00:10:51,331 --> 00:10:52,230
And,
and the like,

193
00:10:53,880 --> 00:10:58,880
uh,
another part of our approach we call 

194
00:10:58,880 --> 00:10:58,880
build it,
break it,

195
00:10:58,880 --> 00:11:02,871
fix it.
Now I have friends who build their 

196
00:11:02,871 --> 00:11:06,561
robots and are so into the,
the beauty of what they've created that 

197
00:11:08,761 --> 00:11:13,761
they kind of put it on an altar and 
afraid of actually hurting it.

198
00:11:14,370 --> 00:11:15,360
Uh,
so,

199
00:11:15,450 --> 00:11:16,200
uh,
and in fact,

200
00:11:16,201 --> 00:11:19,390
I even have friends here at mit that 
have done that where they have a goal,

201
00:11:19,391 --> 00:11:22,890
play that robot and uh,
they're afraid of taking it out into the

202
00:11:22,891 --> 00:11:24,090
world.
I mean,

203
00:11:24,091 --> 00:11:25,990
we're just the opposite.
Uh,

204
00:11:26,030 --> 00:11:29,790
every one of our robots is designed to 
get bashed the bits.

205
00:11:30,120 --> 00:11:34,200
We have staff who are there to fix the 
robot on a daily basis,

206
00:11:34,350 --> 00:11:35,670
uh,
as we break it.

207
00:11:35,910 --> 00:11:40,910
And I think doing that build a break it 
fix it means that we're able to learn a 

208
00:11:40,910 --> 00:11:44,890
lot from the actual physical robot 
working in the world and uh,

209
00:11:44,940 --> 00:11:47,940
we can use that knowledge in order to 
improve the robot,

210
00:11:47,941 --> 00:11:51,870
improve it's behavior and uh,
we really like to go around that loop as

211
00:11:51,871 --> 00:11:56,871
quickly and as we can early in the,
in the process and do it as many times 

212
00:11:59,141 --> 00:12:01,900
as we can.
So here's what build a break it fix.

213
00:12:01,901 --> 00:12:06,901
It looks like a,
this is in Somerville,

214
00:12:13,330 --> 00:12:15,220
our engineers.
This is,

215
00:12:15,221 --> 00:12:20,221
I'm a Boston driver.
Yeah.

216
00:12:27,631 --> 00:12:31,950
This robot's supposed to be using his 
visual system to avoid the trees.

217
00:12:36,890 --> 00:12:38,900
I think it might've fallen in love with 
this tree.

218
00:12:40,130 --> 00:12:41,990
We don't purposely give them any 
emotion,

219
00:12:41,991 --> 00:12:44,720
but boy,
it's hard not to see that.

220
00:12:45,290 --> 00:12:49,700
And here's the first time we tested the 
pusher response to this robot.

221
00:12:55,180 --> 00:12:57,280
Did you hear that?
That's the new guy's car.

222
00:12:57,281 --> 00:13:02,281
So some guy who just started that week 
trend a have $5,000,

223
00:13:03,221 --> 00:13:04,660
which we paid for,
uh,

224
00:13:04,661 --> 00:13:07,930
in,
in repairs to his vintage BMW.

225
00:13:10,270 --> 00:13:15,270
So the last thing sort of about 
philosophy is long term versus short 

226
00:13:15,270 --> 00:13:16,480
term.
Uh,

227
00:13:16,481 --> 00:13:21,481
you know,
our company is 25 years old and we've 

228
00:13:21,481 --> 00:13:24,120
mostly been a longterm a robotics 
company that is,

229
00:13:24,121 --> 00:13:29,121
we're interested in moving the boundary 
forward in what robots can do and we're 

230
00:13:29,911 --> 00:13:31,740
interested in,
you know,

231
00:13:31,741 --> 00:13:36,450
making it so robots meet the dream of 
being the equal or better than people in

232
00:13:36,451 --> 00:13:36,960
animals.

233
00:13:38,100 --> 00:13:43,100
But now we've started function doesn't 
break.

234
00:13:53,780 --> 00:13:55,300
Okay,
got it.

235
00:13:55,380 --> 00:13:57,350
We still on.
Can you hear me?

236
00:13:58,290 --> 00:14:01,150
Um,
but uh,

237
00:14:01,180 --> 00:14:06,180
lately we've started to realize that 
some of our robots have enough 

238
00:14:06,180 --> 00:14:10,020
capability that maybe it's time to try 
and productize them and we will learn a 

239
00:14:10,020 --> 00:14:11,320
lot by doing that to.
One of the things,

240
00:14:11,321 --> 00:14:14,340
for instance,
that I've always claimed a,

241
00:14:14,680 --> 00:14:19,680
is that we always spent a lot of money 
on building our robots in them and use 

242
00:14:20,561 --> 00:14:22,780
that as a competitive advantage.
That is,

243
00:14:22,960 --> 00:14:25,660
Darpa was a frequent funder of us.
Darpa always said,

244
00:14:25,661 --> 00:14:28,630
let's take money out of the equation and
just figure out,

245
00:14:28,870 --> 00:14:30,140
um,
uh,

246
00:14:30,141 --> 00:14:35,141
you know,
how to get the solution and then worry 

247
00:14:35,141 --> 00:14:37,160
about getting the cost down later.
So I always assumed and argued that once

248
00:14:37,161 --> 00:14:39,200
we get a robot doing things that are 
interesting,

249
00:14:39,350 --> 00:14:42,560
then you can go and redesign it to make 
it a lower cost.

250
00:14:42,890 --> 00:14:47,890
While we're going,
we're going to test that because it 

251
00:14:47,890 --> 00:14:47,890
might not be true.

252
00:14:47,890 --> 00:14:50,110
It might be that we've designed 
ourselves into inexpensive coroner and,

253
00:14:50,111 --> 00:14:51,500
uh,
that it might be too late,

254
00:14:51,860 --> 00:14:52,380
but,
uh,

255
00:14:52,400 --> 00:14:57,400
the robot that will show in a little bit
is much significantly cost reduced from 

256
00:14:57,400 --> 00:15:01,571
the prototype event.
And it'll be interesting to see whether 

257
00:15:01,571 --> 00:15:03,770
we could get it down to the kind of 
prices that are useful.

258
00:15:03,920 --> 00:15:08,920
So this is just a picture again,
of the idea of aiming long but also 

259
00:15:09,201 --> 00:15:14,201
aiming short and I think it's going to 
be a challenge to see whether we can 

260
00:15:14,391 --> 00:15:18,620
keep the culture of the company to 
support both of these directions because

261
00:15:18,770 --> 00:15:23,770
people manufacturing stuff have a 
different mindset than people trying to 

262
00:15:23,770 --> 00:15:26,540
get out to the future horizons.
And,

263
00:15:26,541 --> 00:15:31,541
uh,
it's gonna be a challenge to keep both 

264
00:15:31,541 --> 00:15:31,541
those kinds of people are happy.

265
00:15:34,400 --> 00:15:35,990
Here's some of the things that,
uh,

266
00:15:36,140 --> 00:15:41,140
uh,
some of the kinds of applications you 

267
00:15:41,140 --> 00:15:41,140
can look at,
uh,

268
00:15:41,140 --> 00:15:41,720
based on,
um,

269
00:15:41,780 --> 00:15:46,780
modest,
a technical capabilities I've shown 

270
00:15:46,780 --> 00:15:48,770
mobility and manipulation here,
but you could put cost,

271
00:15:48,771 --> 00:15:53,771
reliability.
There's many things that could be on 

272
00:15:53,771 --> 00:15:53,771
these axes,
you know,

273
00:15:53,771 --> 00:15:57,491
entertainment like robots and theme 
parks is something that I think we 

274
00:15:57,491 --> 00:16:00,110
should be able to do.
I already talked about home delivery.

275
00:16:00,320 --> 00:16:05,320
I think home delivery is waiting for 
self driving cars to get all the way 

276
00:16:05,320 --> 00:16:06,560
they are self driving trucks.
And once they do,

277
00:16:06,740 --> 00:16:10,100
then we will be working on getting it 
from the truck to the,

278
00:16:10,310 --> 00:16:12,350
to the home.
Um,

279
00:16:13,460 --> 00:16:15,070
logistics,
um,

280
00:16:15,080 --> 00:16:20,080
there's about a trillion boxes moved 
every year around the world and most of 

281
00:16:21,111 --> 00:16:26,111
it's done by hand.
And so there's really a big opportunity 

282
00:16:26,111 --> 00:16:29,381
to having robots help with moving those 
trillion box's security,

283
00:16:30,111 --> 00:16:32,190
which could mean either commercial 
security,

284
00:16:32,191 --> 00:16:37,191
like patrolling your shopping center or 
the military type security,

285
00:16:38,330 --> 00:16:39,380
a construction.

286
00:16:39,410 --> 00:16:43,370
A lot of people have been coming to us 
with their construction applications,

287
00:16:43,770 --> 00:16:46,250
a asking if we can help and,
you know,

288
00:16:46,251 --> 00:16:51,251
I'm not going to talk about it now,
but if afterwards you want to ask about 

289
00:16:51,251 --> 00:16:51,251
that,
I can fill you in a little more.

290
00:16:51,251 --> 00:16:55,310
And I think this is really the ultimate,
a home run application,

291
00:16:55,700 --> 00:16:59,630
a care for the elderly and the disabled.
Um,

292
00:17:00,440 --> 00:17:05,440
I used to say that I wanted to have 
robots that would help me take care of 

293
00:17:05,440 --> 00:17:05,840
my,
uh,

294
00:17:06,140 --> 00:17:08,960
my parents and uh,
uh,

295
00:17:09,020 --> 00:17:14,020
older people.
But I realize now that it's probably 

296
00:17:14,020 --> 00:17:15,380
going to be my children using them to 
help take care of me.

297
00:17:15,620 --> 00:17:20,620
But you guys are,
you're all a little bit younger and I 

298
00:17:20,620 --> 00:17:20,620
think,
uh,

299
00:17:20,620 --> 00:17:22,190
uh,
there'll be a time when,

300
00:17:22,191 --> 00:17:27,191
uh,
you could use robots to help make your 

301
00:17:27,191 --> 00:17:27,191
parents' lives better.
Now,

302
00:17:27,191 --> 00:17:29,090
some of you may think that your parents 
don't want that,

303
00:17:29,450 --> 00:17:29,830
but,
uh,

304
00:17:29,840 --> 00:17:31,490
I think it's a complex question.

305
00:17:31,670 --> 00:17:34,560
We've seen some surveys that say that,
you know,

306
00:17:34,610 --> 00:17:39,610
people aren't totally happy with the 
idea of their kids taking care of them 

307
00:17:39,610 --> 00:17:40,490
on a moment by moment basis.
And,

308
00:17:40,491 --> 00:17:45,491
uh,
I think there's going to be an 

309
00:17:45,491 --> 00:17:46,391
opportunity for doing something,
but technically this is still a ways 

310
00:17:46,391 --> 00:17:46,391
off.
It's,

311
00:17:46,391 --> 00:17:46,760
it's a tough thing.
Okay,

312
00:17:46,761 --> 00:17:48,920
let's get back to the robots.
Um,

313
00:17:49,020 --> 00:17:54,020
spot mini is a robot that weighs about 
60 pounds that previous spot weight 

314
00:17:54,271 --> 00:17:57,420
about 180 pounds.
This one weighs about 60 pounds.

315
00:17:57,890 --> 00:18:00,090
Um,
and uh,

316
00:18:00,120 --> 00:18:05,120
here's some anatomy.
It's got an arm with a five degrees of 

317
00:18:05,120 --> 00:18:06,720
freedom.
Each leg has three degrees of freedom.

318
00:18:09,680 --> 00:18:14,680
It's got about a 500 watt hour battery 
batteries for these things are 

319
00:18:15,290 --> 00:18:17,120
challenged because,
you know,

320
00:18:17,121 --> 00:18:22,121
uh,
you can have consumer products like 

321
00:18:22,121 --> 00:18:22,490
electric drills that have relatively 
small batteries.

322
00:18:22,640 --> 00:18:27,640
And then there's electric cars that had 
big batteries and there's not really 

323
00:18:27,640 --> 00:18:30,611
much available in between.
So we've done a lot of work on the 

324
00:18:30,611 --> 00:18:32,981
battery technology for these things to 
make the safe and reliable and hot 

325
00:18:32,981 --> 00:18:34,450
swappable and things like that.
Uh,

326
00:18:34,830 --> 00:18:37,550
then there's radios and computers.
Uh,

327
00:18:37,730 --> 00:18:40,170
the previous version had three quad 
core,

328
00:18:40,680 --> 00:18:42,740
I seven [inaudible].
This one has two.

329
00:18:43,010 --> 00:18:48,010
We're trying to cut back on the cost and
then there can be some sensors,

330
00:18:50,030 --> 00:18:55,030
lidars stereo and the like.
So you can see spot man,

331
00:18:58,131 --> 00:18:59,940
he's a little bit smaller than spot.

332
00:19:05,540 --> 00:19:06,170
Um,

333
00:19:06,700 --> 00:19:09,280
this isn't a real house and those aren't
real people.

334
00:19:09,281 --> 00:19:11,040
Those are engineers.
Um,

335
00:19:12,220 --> 00:19:17,220
this is a inside of a warehouse we have 
out on one slash 28 where we've built 

336
00:19:17,220 --> 00:19:18,610
the house.
You can see that they don't,

337
00:19:18,611 --> 00:19:23,611
we don't mind scuffing up the walls here
and there is a lot of scuffing that 

338
00:19:23,611 --> 00:19:26,491
happens.
Some of you may recognize active Koski 

339
00:19:26,491 --> 00:19:26,491
who is a,
uh,

340
00:19:26,491 --> 00:19:29,760
an mit alum and he's again disturbing 
the robot here,

341
00:19:29,770 --> 00:19:34,770
the robots using its vision to do some 
stepping stone type operations.

342
00:19:35,290 --> 00:19:40,290
And I think gene is going to talk a 
little bit more about this in a couple 

343
00:19:40,290 --> 00:19:43,051
of minutes.
And here's a case where it's doing 

344
00:19:43,051 --> 00:19:45,040
stepping stones on real stones and it's 
keeping its balance,

345
00:19:45,070 --> 00:19:47,570
figuring out where to put the feet.
Um,

346
00:19:50,670 --> 00:19:55,670
and again,
this robot only has stereo looking out 

347
00:19:55,670 --> 00:19:58,281
the front,
whereas this one has a stereo on all 

348
00:19:58,281 --> 00:19:58,281
four sides.

349
00:20:03,740 --> 00:20:08,740
Now,
one of the cool things about animals is 

350
00:20:08,740 --> 00:20:09,140
that they have these stabilization 
mechanisms for their sensors.

351
00:20:09,141 --> 00:20:14,141
That was a real chicken,
no robotics involved and here's our 

352
00:20:14,141 --> 00:20:17,810
attempt to show that these,
this robot can do the same sort of thing

353
00:20:19,020 --> 00:20:21,380
and if you think about it,
when you're manipulating,

354
00:20:21,381 --> 00:20:26,381
you really want the hand to be 
stabilized in space and so you'd like 

355
00:20:26,381 --> 00:20:29,891
the body to be able to kind of 
coordinate with the hands so that you 

356
00:20:29,891 --> 00:20:32,920
can concentrate on what the world real 
world task is.

357
00:20:33,580 --> 00:20:38,580
A man,
you guys didn't pick up the banana 

358
00:20:38,580 --> 00:20:38,580
peels,
Huh?

359
00:20:49,860 --> 00:20:53,910
So our concept for the spot many product
is to make a platform.

360
00:20:54,210 --> 00:20:57,330
It's sort of the,
we're thinking of it like the android of

361
00:20:57,331 --> 00:21:02,331
robots.
So with android there's a hardware 

362
00:21:02,331 --> 00:21:04,971
platform and then there's a software 
platform and then a developer's third 

363
00:21:06,151 --> 00:21:09,750
party developers create their own apps 
that use the platform.

364
00:21:10,110 --> 00:21:15,110
So we've made this spot so that there's 
a place to mount hardware on the robot,

365
00:21:16,530 --> 00:21:19,110
but there's also an API to program it 
through.

366
00:21:19,380 --> 00:21:24,380
And then there's a facility to have 
additional computing external to the 

367
00:21:24,380 --> 00:21:28,670
robot.
And we're working with third parties to 

368
00:21:28,670 --> 00:21:30,570
develop their own applications that run 
on the platform.

369
00:21:34,780 --> 00:21:35,250
Um,

370
00:21:35,720 --> 00:21:37,760
this is a video that,
uh,

371
00:21:37,761 --> 00:21:39,830
we haven't been able to release 
publicly.

372
00:21:39,890 --> 00:21:42,200
Please don't tape it and show it,

373
00:21:42,480 --> 00:21:43,030
um,

374
00:21:44,040 --> 00:21:49,040
because I can't,
I'll explain later if you want to know 

375
00:21:49,040 --> 00:21:51,531
why not,
but this is just a revealing that we do 

376
00:21:51,531 --> 00:21:51,810
have an arm on the,
on the new version of spot.

377
00:21:54,580 --> 00:21:56,680
It's using a camera in the hand to find 
the,

378
00:21:56,730 --> 00:22:01,730
the door handle.
This robot doesn't weigh a lot,

379
00:22:03,971 --> 00:22:06,670
so it has to use tricks to keep the door
open.

380
00:22:06,760 --> 00:22:08,350
So that's why he puts his foot in the 
door.

381
00:22:20,580 --> 00:22:22,730
And here again,
we want to show that the,

382
00:22:22,950 --> 00:22:26,580
we've made the solution robust to 
certain kinds of disturbances.

383
00:22:26,820 --> 00:22:28,140
So Andy,
there,

384
00:22:28,200 --> 00:22:31,220
andy sitting over here is a pushing on 
the door,

385
00:22:31,230 --> 00:22:35,220
pushing on the hand.
The robot keeps track of how far,

386
00:22:35,250 --> 00:22:38,040
how much progress it's made in doing its
task.

387
00:22:45,770 --> 00:22:48,170
It's so,
it's so smart and even kicks that,

388
00:22:48,171 --> 00:22:49,950
uh,
that shell out of the way.

389
00:22:49,951 --> 00:22:54,951
Now that was total accident and now it's
just gone back to try again.

390
00:23:02,560 --> 00:23:03,130
Okay.

391
00:23:05,300 --> 00:23:07,700
Um,
and then this is a demo of autonomy.

392
00:23:08,160 --> 00:23:10,820
A here are,
the robot has a,

393
00:23:11,180 --> 00:23:14,810
in a previous session,
we've taken it around the lab.

394
00:23:14,811 --> 00:23:19,811
This is Boston dynamics take into the 
realm of lab and recorded visual data 

395
00:23:19,811 --> 00:23:24,760
that can be used for navigation and it's
using its stereo to match up features in

396
00:23:25,101 --> 00:23:28,730
the environment so that they can 
navigate a Ngo,

397
00:23:29,000 --> 00:23:31,010
um,
where it had gone in the previous,

398
00:23:31,050 --> 00:23:33,260
uh,
on the previous path.

399
00:23:33,261 --> 00:23:36,070
So there's no one driving it for this.
It's all a,

400
00:23:36,410 --> 00:23:41,410
uh,
autonomous that was outside my office 

401
00:23:42,240 --> 00:23:45,030
every day around noon.
The robot seems to show,

402
00:23:45,500 --> 00:23:47,000
and I hear it pausing out there,

403
00:23:51,490 --> 00:23:56,490
I don't know why it turned there as 
sometimes it comes up with a solution 

404
00:23:56,490 --> 00:24:00,151
that isn't in here.
You'll see another one that comes up 

405
00:24:00,151 --> 00:24:00,151
with a solution that isn't cool,
why,

406
00:24:00,790 --> 00:24:04,320
what call is an optimization,
but it does,

407
00:24:04,321 --> 00:24:06,300
uh,
it does get a solution.

408
00:24:07,440 --> 00:24:12,440
So we're pretty excited by this.
We call this patrol route and we're 

409
00:24:12,440 --> 00:24:13,620
working on developing a lot of software 
to support it,

410
00:24:13,740 --> 00:24:18,740
to make it so that other people can 
capture a patrol route and then execute 

411
00:24:18,931 --> 00:24:20,790
them on a,
on a routine basis,

412
00:24:20,940 --> 00:24:23,310
and then do the other tasks while 
they're on the,

413
00:24:23,610 --> 00:24:27,840
on the patrol route.
Seth,

414
00:24:28,040 --> 00:24:33,040
you're on.
So we're now we'll do a demo of a spot 

415
00:24:33,040 --> 00:24:36,661
mini.
So for this,

416
00:24:41,420 --> 00:24:43,580
for this demo,
Seth Scott,

417
00:24:43,581 --> 00:24:48,581
a joystick and he's telling it the speed
to go in the forward direction and 

418
00:24:49,491 --> 00:24:52,610
turning,
but the robots doing all its own,

419
00:24:53,080 --> 00:24:54,650
uh,
gates selection,

420
00:24:55,310 --> 00:25:00,310
coordination of legs,
balance obviously.

421
00:25:02,270 --> 00:25:07,270
So the robot has a bunch of different 
gates that can walk here.

422
00:25:07,660 --> 00:25:10,860
It's doing one leg at a time.
Um,

423
00:25:12,430 --> 00:25:16,130
it can try it.
I know you do whatever gets you on set.

424
00:25:19,760 --> 00:25:22,970
He's got to use the selected yet.
So here's trotting,

425
00:25:23,240 --> 00:25:26,220
which is diagonal pairs of legs.
Um,

426
00:25:26,240 --> 00:25:31,240
it can do pacing,
which is lateral pairs of legs to get 

427
00:25:31,240 --> 00:25:31,580
working together.
I have to tell you,

428
00:25:32,210 --> 00:25:35,300
in the earliest days of me being 
involved in legged locomotion,

429
00:25:35,600 --> 00:25:39,890
I thought gate was a big deal,
but it's really kind of a small thing.

430
00:25:40,300 --> 00:25:45,300
Um,
and I don't think it's central to what 

431
00:25:45,300 --> 00:25:45,300
matters,
which is support,

432
00:25:45,300 --> 00:25:46,910
stability,
propulsion,

433
00:25:47,270 --> 00:25:50,120
and things like that.
I'm going to wrap up shortly.

434
00:25:50,121 --> 00:25:54,230
I just thought I'd say a couple of words
about the mechanical side.

435
00:25:54,460 --> 00:25:55,950
Uh,
you know,

436
00:25:55,960 --> 00:25:59,090
the atlas is a new version of a 
humanoid.

437
00:25:59,480 --> 00:26:01,460
Uh,
I know some of you worked with the Darpa

438
00:26:01,461 --> 00:26:02,870
robotics challenge,
humanoid,

439
00:26:03,140 --> 00:26:08,140
uh,
which was a big hulking thing that we 

440
00:26:08,140 --> 00:26:10,421
made and this is a much more svelte one.
And the way we got there was to uh,

441
00:26:12,080 --> 00:26:14,000
work on,
uh,

442
00:26:14,880 --> 00:26:19,880
the elements of the mechanical design to
take advantage of three d printing and,

443
00:26:21,021 --> 00:26:22,070
uh,
uh,

444
00:26:22,100 --> 00:26:23,300
some optimization.

445
00:26:23,600 --> 00:26:28,600
And we did,
we focused on two or three different 

446
00:26:28,600 --> 00:26:31,061
things.
One is making some of the leg parts 

447
00:26:31,061 --> 00:26:33,470
where we embed hydraulic pathways,
hydraulic actuators,

448
00:26:33,830 --> 00:26:37,310
places for valve mounts and filters and 
things like that into the leg.

449
00:26:37,520 --> 00:26:42,520
And this is what that looks like.
There's a single upper leg part that 

450
00:26:42,520 --> 00:26:47,441
incorporated 15 or 20 different separate
components in the previous design which 

451
00:26:48,091 --> 00:26:49,710
made it lighter,
more compact,

452
00:26:50,130 --> 00:26:55,130
and a higher strength to weight ratio.
We also developed a hydraulic power 

453
00:26:55,951 --> 00:27:00,570
unit,
which takes many components.

454
00:27:00,600 --> 00:27:05,600
The thing on the left are the components
as separate ones and we were able to 

455
00:27:06,181 --> 00:27:11,181
print parts that integrated them so that
there was a motor or a pump inside of a 

456
00:27:11,461 --> 00:27:13,560
motor,
an accumulator,

457
00:27:13,610 --> 00:27:15,690
a reservoir,
valves,

458
00:27:15,691 --> 00:27:20,691
filters and those things,
and we shrunk it down so that the robot 

459
00:27:20,691 --> 00:27:25,230
could be smaller and lighter.
And using that approach,

460
00:27:25,231 --> 00:27:30,231
we went from about a 375 pound DRC robot
to a one 90 pound robot.

461
00:27:31,890 --> 00:27:34,890
And then the current one is about a 
hundred and 65 pounds.

462
00:27:35,550 --> 00:27:40,550
Now this picture might lead you to 
believe that I'm advertising myself as 

463
00:27:40,550 --> 00:27:43,890
only weighing 165 pounds.
And unfortunately that's not true,

464
00:27:44,040 --> 00:27:49,040
but I'm working on it,
but it is close to my size and weight.

465
00:27:50,430 --> 00:27:51,150
And,
uh,

466
00:27:51,151 --> 00:27:56,151
I don't know.
I don't think we have this out as a 

467
00:27:56,151 --> 00:27:56,151
video.
Here's,

468
00:27:56,151 --> 00:27:56,190
um,
uh,

469
00:27:56,220 --> 00:28:01,220
some,
a robot behavior that uses whole body 

470
00:28:01,220 --> 00:28:04,170
motion,
meaning the mobility based plus the arms

471
00:28:04,171 --> 00:28:07,560
plus the torso or all combining in order
to handle these,

472
00:28:07,561 --> 00:28:08,970
uh,
these boxes.

473
00:28:08,971 --> 00:28:13,971
It's using vision with the qr codes to 
simplify the task here we're trying to 

474
00:28:13,971 --> 00:28:18,471
go at human speeds of operation.
And so the robot searches for a box 

475
00:28:18,870 --> 00:28:19,890
using its vision.

476
00:28:25,110 --> 00:28:30,110
I think that,
I think that was the only take we ever 

477
00:28:30,110 --> 00:28:33,291
got with both robots working together 
and uh,

478
00:28:35,280 --> 00:28:40,280
you know,
one of the problems with youtube as 

479
00:28:40,280 --> 00:28:40,280
everybody's already seen what you've 
been up to by the time you get it,

480
00:28:40,280 --> 00:28:42,750
go around to give a talk.
So I imagine most of you have seen this,

481
00:28:43,200 --> 00:28:43,960
but,
uh,

482
00:28:44,220 --> 00:28:48,240
here's a,
a par core robot we're working on where,

483
00:28:48,241 --> 00:28:53,241
uh,
we've actually strengthened the hips so 

484
00:28:53,241 --> 00:28:53,241
that it can do a little bit more jumping
and,

485
00:28:53,241 --> 00:28:54,660
uh,
uh,

486
00:29:04,740 --> 00:29:05,580
and,
uh,

487
00:29:07,260 --> 00:29:12,260
it's kind of interesting that we,
we've been interested in making a robot 

488
00:29:12,260 --> 00:29:14,070
a little bit like the humanoid that,
um,

489
00:29:14,100 --> 00:29:16,770
has less degrees of freedom,
fewer degrees of freedom,

490
00:29:16,771 --> 00:29:21,771
and a simpler.
And we designed this robot and the 

491
00:29:21,771 --> 00:29:22,920
ultimate version of this,
we'll have about 10 joints,

492
00:29:22,921 --> 00:29:26,850
whereas the humanoid had 28 and have 
many,

493
00:29:26,880 --> 00:29:30,040
many of the same capabilities.
Uh,

494
00:29:31,350 --> 00:29:32,650
we have,
uh,

495
00:29:32,700 --> 00:29:35,460
some use cases for this that I'm not 
going to talk about today.

496
00:29:35,820 --> 00:29:36,600
Uh,
but,

497
00:29:36,601 --> 00:29:38,670
uh,
this robot can lift heavy loads.

498
00:29:39,030 --> 00:29:41,410
It has a relatively small footprint 
given,

499
00:29:41,650 --> 00:29:43,090
uh,
what his strength is.

500
00:29:43,360 --> 00:29:48,360
So the way things are done in logistics 
now is to use big robot arms that take 

501
00:29:49,241 --> 00:29:51,940
up a lot of floor area or heavy.
Um,

502
00:29:52,000 --> 00:29:57,000
and uh,
we're looking at ways of using a robot 

503
00:29:57,000 --> 00:29:57,070
like this one,
not exactly this,

504
00:29:57,071 --> 00:29:59,410
we,
it's sort of an evolution of this design

505
00:30:00,070 --> 00:30:02,590
in order to do logistics operations.

506
00:30:05,490 --> 00:30:09,300
So I want to make a pitch to you.
A Boston dynamics is hiring,

507
00:30:09,900 --> 00:30:11,150
um,
and uh,

508
00:30:11,151 --> 00:30:13,380
I hope some of you will apply for a job 
there.

509
00:30:13,710 --> 00:30:16,150
These are how many years?
It,

510
00:30:16,380 --> 00:30:19,280
six times three.
These are 18,

511
00:30:19,660 --> 00:30:24,660
um,
mit alum that currently work at the 

512
00:30:24,660 --> 00:30:25,200
company,
many of them for many years.

513
00:30:25,650 --> 00:30:30,650
Uh,
so I'm sort of making the point that 

514
00:30:30,650 --> 00:30:30,650
these people are happy.
They're just like,

515
00:30:30,650 --> 00:30:32,700
just like you could be.
And uh,

516
00:30:32,701 --> 00:30:35,370
I hope you'll look at our website and 
see what we're,

517
00:30:35,371 --> 00:30:37,530
uh,
what we're looking for and considerate.

518
00:30:39,470 --> 00:30:41,330
So I'm just going to wrap up by talking 
about,

519
00:30:41,331 --> 00:30:46,331
you know,
I used to be a professor here at 

520
00:30:46,331 --> 00:30:48,581
Carnegie Mellon and when I was a 
professor will use the mostly wrote 

521
00:30:48,581 --> 00:30:50,840
papers and uh,
we were excited by,

522
00:30:50,841 --> 00:30:51,350
uh,
you know,

523
00:30:51,410 --> 00:30:52,910
how many papers we could,
right,

524
00:30:53,150 --> 00:30:56,120
and how many people cited them,
uh,

525
00:30:56,121 --> 00:31:01,121
in their papers.
But as a company guy instead of papers,

526
00:31:01,371 --> 00:31:06,371
I think we count youtube hits a and 
instead of citations want to tell you 

527
00:31:07,551 --> 00:31:10,670
what this is,
but most of you probably know.

528
00:31:36,060 --> 00:31:41,060
So now we count.
Now we count spoofs instead of 

529
00:31:41,060 --> 00:31:43,791
citations.
And I'm happy to say that we're doing 

530
00:31:43,791 --> 00:31:43,791
great.
We have about,

531
00:31:43,791 --> 00:31:45,480
uh,
uh,

532
00:31:45,481 --> 00:31:49,320
about two dozen big dog spoofs.
Here's four of them.

533
00:31:49,620 --> 00:31:52,380
In the upper left is in Akihabara,
Japan.

534
00:31:52,560 --> 00:31:55,530
The upper right is a Los Angeles online 
television show.

535
00:31:55,860 --> 00:32:00,860
It's the Netherlands on the lower left.
And I guess that's Appalachia on the 

536
00:32:00,860 --> 00:32:03,820
right.
The poor kid doesn't even have a friend

537
00:32:03,890 --> 00:32:07,840
to a to be in his movie.

538
00:32:09,380 --> 00:32:10,400
Well,
what about,

539
00:32:10,401 --> 00:32:15,401
what about atlas?
Can you hear that?

540
00:32:37,740 --> 00:32:38,620
No.

541
00:32:41,410 --> 00:32:42,820
Here's,
here's another one.

542
00:33:11,450 --> 00:33:16,450
Thank you.

543
00:33:19,370 --> 00:33:24,370
So we have,
we have a big crew working on all these 

544
00:33:24,370 --> 00:33:27,491
projects.
You see you've gotten to meet a couple 

545
00:33:27,491 --> 00:33:27,491
of them here,
but it's really quite a team in a,

546
00:33:27,491 --> 00:33:28,940
uh,
an absolute pleasure to work with.

547
00:33:29,180 --> 00:33:29,990
So anyway,
thank you.

548
00:33:30,600 --> 00:33:35,600
Thank you.

549
00:33:39,390 --> 00:33:41,550
Thanks for the presentation.
It was amazing.

550
00:33:41,760 --> 00:33:44,880
Uh,
what sort of physics simulation,

551
00:33:45,240 --> 00:33:50,240
like if any do you have in your robots 
and do you really retain dead lake with 

552
00:33:51,661 --> 00:33:56,661
the current trend of neural networks?
We can just like do end to end modeling 

553
00:33:56,661 --> 00:34:00,291
of these robots,
but like without any sort of notion of 

554
00:34:00,291 --> 00:34:00,291
physics but just like neural networks.

555
00:34:00,980 --> 00:34:05,980
Um,
so we have simulators that we've worked 

556
00:34:05,980 --> 00:34:08,270
on for a long time,
very detailed in some cases validated,

557
00:34:08,271 --> 00:34:12,450
validated me and compare the behavior of
the simulator to the physics of,

558
00:34:13,070 --> 00:34:15,130
of ground truth.
And uh,

559
00:34:15,900 --> 00:34:20,900
you know,
I think they're important for our work 

560
00:34:20,900 --> 00:34:22,930
and we use them frequently,
but the end to end doesn't ring quite 

561
00:34:22,930 --> 00:34:24,620
true.
Usually the one we use simulation,

562
00:34:24,980 --> 00:34:29,980
the user is knowledgeable about the 
tradeoffs between doing a physical 

563
00:34:29,980 --> 00:34:34,631
experiment and doing a simulated 
experiment and they're usually getting 

564
00:34:34,631 --> 00:34:38,261
at some specifically or specific setup 
question rather than the idea that you 

565
00:34:39,111 --> 00:34:40,460
start at one end,
you know,

566
00:34:40,470 --> 00:34:45,470
to at least in our experience trying to 
simulate all the subtleties of the 

567
00:34:46,701 --> 00:34:51,230
hydraulic actuator,
backlashing gears a flexibility,

568
00:34:51,390 --> 00:34:51,820
uh,
you know,

569
00:34:51,830 --> 00:34:56,830
the non rigidity in the components,
that's a big undertaking and usually so,

570
00:34:57,800 --> 00:35:02,390
so I'm distracting that you can't really
get on with what you're doing.

571
00:35:02,391 --> 00:35:07,391
So I think we use experiment for those 
subtleties and we use simulation for a 

572
00:35:07,520 --> 00:35:09,620
bigger level dynamics questions.

573
00:35:13,350 --> 00:35:18,350
Hey,
would you say mechanical concerns or 

574
00:35:18,350 --> 00:35:22,580
computational capability is more of a 
difficulty in terms of determining how 

575
00:35:23,791 --> 00:35:26,670
quickly you can perform tasks with the 
robots?

576
00:35:27,820 --> 00:35:29,020
Um,
you know,

577
00:35:29,021 --> 00:35:30,820
we like to say that they're equally 
important.

578
00:35:30,821 --> 00:35:31,930
We,
we now,

579
00:35:31,931 --> 00:35:36,730
although we didn't start out this way,
we now have equal strength in our groups

580
00:35:36,731 --> 00:35:41,731
in mechanical design and implementation 
and in the software and controls and 

581
00:35:42,391 --> 00:35:44,550
sensing.
And I think,

582
00:35:44,690 --> 00:35:45,990
you know,
they all matter.

583
00:35:46,260 --> 00:35:50,730
I think if you try and get by with just 
marginally designed hardware,

584
00:35:51,040 --> 00:35:56,040
uh,
you don't get much experimental time in 

585
00:35:56,040 --> 00:35:56,040
because the thing's broken all the time.
Uh,

586
00:35:56,040 --> 00:35:57,810
so even though we are rough on our 
machines,

587
00:35:58,140 --> 00:36:03,140
they mostly keep working because,
because we put a lot of attention to 

588
00:36:03,140 --> 00:36:05,100
detail and how they're designed.
Uh,

589
00:36:05,370 --> 00:36:06,450
but you know,
there's still the,

590
00:36:06,451 --> 00:36:10,170
I think perception is still a tall pole 
in the tent.

591
00:36:11,040 --> 00:36:14,000
Certainly if you want to rival human 
perception,

592
00:36:14,010 --> 00:36:19,010
I don't think we're anywhere near there.
I said I think the self driving car 

593
00:36:19,010 --> 00:36:20,030
stuff is helping.
Uh,

594
00:36:20,060 --> 00:36:21,780
there's a lot of interesting things 
happened there.

595
00:36:21,781 --> 00:36:24,180
I think specialized hardware is getting,
you know,

596
00:36:24,200 --> 00:36:25,290
a,
a six and,

597
00:36:25,430 --> 00:36:28,080
and things that could help.
Um,

598
00:36:28,110 --> 00:36:29,540
but you know,
it's,

599
00:36:29,550 --> 00:36:31,230
it's all still needed.

600
00:36:35,670 --> 00:36:37,530
So,
um,

601
00:36:37,740 --> 00:36:42,740
you guys have developed various 
components that all kind of come 

602
00:36:42,740 --> 00:36:46,911
together to build one robot.
Have you seen applications for any of 

603
00:36:46,911 --> 00:36:49,290
these separate components elsewhere?
So a organic design,

604
00:36:49,291 --> 00:36:50,940
for example,
for the atlas,

605
00:36:50,941 --> 00:36:55,941
maybe prosthetics or hip replacements or
something like that because there seems 

606
00:36:55,941 --> 00:37:00,231
to be a lot of development going on and 
then individually as well as that they 

607
00:37:00,231 --> 00:37:00,231
pay.

608
00:37:00,231 --> 00:37:00,231
Sure.
I mean,

609
00:37:00,231 --> 00:37:04,990
you're asking a very good question.
There's a question in case people 

610
00:37:04,990 --> 00:37:07,361
couldn't hear his are,
aside from the value to the whole robot 

611
00:37:07,400 --> 00:37:12,400
of the components we're making,
are the components useful some other 

612
00:37:12,400 --> 00:37:12,400
way.
And uh,

613
00:37:12,400 --> 00:37:12,400
you know,
the,

614
00:37:12,400 --> 00:37:17,370
the place where we think it's probably 
most true is the specialized hydraulic 

615
00:37:17,370 --> 00:37:20,490
components.
We've made servo valves and uh,

616
00:37:20,610 --> 00:37:25,610
the HPU,
I'm sure we could sell them into other 

617
00:37:25,610 --> 00:37:26,670
industry,
uh,

618
00:37:26,760 --> 00:37:29,360
as a,
as a company focused question though,

619
00:37:29,810 --> 00:37:32,390
uh,
that that's really what it comes to.

620
00:37:32,410 --> 00:37:37,410
Do we really want to be doing that?
Will that absorb too much time and 

621
00:37:37,410 --> 00:37:39,080
attention and personnel or do we want 
to,

622
00:37:39,081 --> 00:37:42,110
you know,
our heart is really in building a future

623
00:37:42,111 --> 00:37:47,111
generations of robots.
So I think we're going to probably stay 

624
00:37:47,111 --> 00:37:47,111
there.

625
00:37:47,111 --> 00:37:47,111
Okay.

626
00:37:48,590 --> 00:37:50,490
Thanks.
I was wondering,

627
00:37:50,760 --> 00:37:55,760
have you done any research in regards to
getting the robots to perform tasks 

628
00:37:55,760 --> 00:37:57,480
involving direct physical contact with 
humans?

629
00:38:00,260 --> 00:38:00,680
Nope,

630
00:38:01,720 --> 00:38:03,550
I can.
Only.

631
00:38:03,670 --> 00:38:06,070
The only thing we've done is we've done 
tele operation,

632
00:38:06,071 --> 00:38:11,071
which is not what you mean,
where we have a human moving and the 

633
00:38:11,071 --> 00:38:11,071
robot,
you know,

634
00:38:11,071 --> 00:38:13,210
copying,
which is very interesting because,

635
00:38:13,570 --> 00:38:16,330
uh,
you can see that that's a way of showing

636
00:38:16,780 --> 00:38:21,780
how fast the robot can be and how 
coordinated they can be using a human 

637
00:38:21,780 --> 00:38:22,570
and for part of the computing,
uh,

638
00:38:22,850 --> 00:38:27,850
but we have,
we don't have them interacting with 

639
00:38:27,850 --> 00:38:29,701
people.
I guess the closest as we once did a 

640
00:38:29,701 --> 00:38:32,221
thing where a person and a robot picked 
up a stretcher and work together to pick

641
00:38:32,321 --> 00:38:34,750
up the stretcher,
but they weren't touching each other.

642
00:38:34,751 --> 00:38:36,440
They going through the,
uh,

643
00:38:36,700 --> 00:38:40,450
the stretcher material.
We have plans,

644
00:38:41,170 --> 00:38:42,370
uh,
you know,

645
00:38:42,700 --> 00:38:44,170
we're really,
to be honest,

646
00:38:44,171 --> 00:38:48,820
we're really struggling with coming up 
with some strong concepts for safety.

647
00:38:48,940 --> 00:38:51,130
Even without doing that,
um,

648
00:38:51,280 --> 00:38:52,450
you know,
robots,

649
00:38:52,920 --> 00:38:54,440
uh,
it's,

650
00:38:55,150 --> 00:39:00,150
you know,
your first real people's first reaction 

651
00:39:00,150 --> 00:39:00,150
and how you make a robot safe if there's
a problem,

652
00:39:00,190 --> 00:39:02,710
don't really work very well.
You can't freeze the robot,

653
00:39:03,270 --> 00:39:05,110
uh,
you have to find some,

654
00:39:05,111 --> 00:39:09,670
you have to keep them going.
I find a way to get into a safer state.

655
00:39:09,820 --> 00:39:13,930
So I think having come in contact with 
people is just gonna be harder.

656
00:39:14,320 --> 00:39:17,410
So eventually we want to,
to help to carry the lift,

657
00:39:17,411 --> 00:39:20,080
the elderly and things like that.
But we're not there yet.

658
00:39:22,850 --> 00:39:27,850
Um,
my question is about the relative rates 

659
00:39:27,850 --> 00:39:27,850
of progress in robotics and machine 
intelligence.

660
00:39:28,080 --> 00:39:33,080
So an economist might maybe measure it 
by seeing how much money is going into 

661
00:39:33,080 --> 00:39:35,770
computing hardware versus arms and legs 
centers naturally,

662
00:39:35,980 --> 00:39:37,500
that kind of thing.
Um,

663
00:39:38,010 --> 00:39:42,460
so on one one possible scenario,
the um,

664
00:39:42,940 --> 00:39:47,940
the machine intelligence receives the 
head and the robots a progressing more 

665
00:39:48,121 --> 00:39:52,710
slowly because of a kind of a slow build
test cycle.

666
00:39:52,711 --> 00:39:54,300
Basically it's,
they will well things,

667
00:39:54,450 --> 00:39:56,850
it's not so easy to get a rapid build 
test cycle with a robot.

668
00:39:58,540 --> 00:40:03,540
And then the other scenario,
the robots are more advanced than the 

669
00:40:03,540 --> 00:40:07,790
machine intelligence.
Machine intelligence is just such a 

670
00:40:07,790 --> 00:40:10,401
conceptually difficult problem.
So I'm in one side of the machines are 

671
00:40:10,401 --> 00:40:14,331
telling the humans want to do in the 
other scenario that humans telling the 

672
00:40:14,331 --> 00:40:14,331
machines what to do if you'd like.
Um,

673
00:40:14,331 --> 00:40:19,280
so do you have any kind of perspective 
on that whole issue with the machine 

674
00:40:19,280 --> 00:40:20,800
intelligence folk going to rush ahead 
using robots,

675
00:40:20,880 --> 00:40:25,880
guys struggling behind or the robot's 
going to get there before the massive 

676
00:40:25,880 --> 00:40:28,710
problem and machine intelligence get 
sold or maybe somewhere in the middle

677
00:40:28,730 --> 00:40:30,210
I think.
Let's see.

678
00:40:30,211 --> 00:40:32,520
I don't know exactly what you mean by 
machine intelligence.

679
00:40:32,940 --> 00:40:35,280
Are you talking about um,
you know,

680
00:40:35,281 --> 00:40:38,790
having Google do better search.
So we were intelligent

681
00:40:39,020 --> 00:40:41,650
mutation in general.
So I start,

682
00:40:41,660 --> 00:40:43,760
I talked about economists measuring 
sensors,

683
00:40:43,761 --> 00:40:45,920
actuators,
and compute hardware.

684
00:40:46,100 --> 00:40:48,700
So that's the kind of split I'm thinking
about.

685
00:40:49,440 --> 00:40:54,440
Yeah,
I think that it's always been a 

686
00:40:54,440 --> 00:40:55,500
misconception that the hardware 
components by themselves,

687
00:40:55,930 --> 00:41:00,930
uh,
constitute progress in intelligence or 

688
00:41:02,070 --> 00:41:04,000
in robot behavior.
Uh,

689
00:41:04,230 --> 00:41:06,030
they're,
I think they're important ingredients.

690
00:41:06,031 --> 00:41:07,440
But by themselves,
you know,

691
00:41:07,441 --> 00:41:12,441
when I was a graduate student here,
I can remember reading an ad for a,

692
00:41:12,840 --> 00:41:14,350
an uh,
uh,

693
00:41:14,400 --> 00:41:18,540
optical character recognition system and
what the ad said was,

694
00:41:18,800 --> 00:41:19,440
uh,
you know,

695
00:41:19,441 --> 00:41:22,950
we have camera,
we have a thing for holding the paper.

696
00:41:22,951 --> 00:41:27,951
You're looking at,
all you have to do is write the 

697
00:41:27,951 --> 00:41:29,901
software.
So it was all done except for you to 

698
00:41:29,901 --> 00:41:29,901
write the software.
And uh,

699
00:41:29,901 --> 00:41:34,071
you know,
it's the whole problem was there.

700
00:41:34,910 --> 00:41:37,160
So I don't know if I'm answering your 
question.

701
00:41:37,500 --> 00:41:38,480
Uh,
you know,

702
00:41:38,481 --> 00:41:40,250
robotics is hard.
Uh,

703
00:41:40,251 --> 00:41:43,250
I think it feels like we're making 
progress if you keep pushing,

704
00:41:43,370 --> 00:41:48,370
we keep making progress.
It's not like there's a knee in the 

705
00:41:48,370 --> 00:41:50,240
curve that we've hit a.
But I also think that the rest of the ai

706
00:41:50,241 --> 00:41:52,890
world is making a good progress too.
And yeah,

707
00:41:52,990 --> 00:41:55,460
it's fun being a part of it.

708
00:41:58,850 --> 00:42:03,850
Hi,
my question is mostly related to 

709
00:42:03,950 --> 00:42:05,270
security.
Uh,

710
00:42:05,330 --> 00:42:08,870
so since you are productizing your 
robots now,

711
00:42:09,150 --> 00:42:14,150
um,
there has been research on the lidars 

712
00:42:14,150 --> 00:42:14,620
mainly,
uh,

713
00:42:14,720 --> 00:42:19,720
where you could spoof allied are and,
and the sensor basically cannot see 

714
00:42:20,421 --> 00:42:21,680
anything.
Uh,

715
00:42:21,710 --> 00:42:26,710
so are you looking into that as well,
taking into consideration these awesome 

716
00:42:29,340 --> 00:42:33,290
robots could be in let's say in our 
defense,

717
00:42:33,291 --> 00:42:34,910
you know,
working for the defense as well.

718
00:42:34,911 --> 00:42:36,710
So those are like really harsh 
environments.

719
00:42:36,860 --> 00:42:38,690
Yeah,
I mean these are very hard problems,

720
00:42:38,691 --> 00:42:40,280
you know,
if someone,

721
00:42:40,281 --> 00:42:45,281
if a,
if an intelligent adversary wants to 

722
00:42:45,281 --> 00:42:45,650
trick the robot,
it's not all that hard,

723
00:42:46,040 --> 00:42:47,420
uh,
these days,

724
00:42:47,720 --> 00:42:48,290
uh,
you know,

725
00:42:48,291 --> 00:42:53,291
we're,
we're working probably the other end of 

726
00:42:53,291 --> 00:42:53,291
the problem,
you know,

727
00:42:53,291 --> 00:42:53,291
trying to do the basics.
Uh,

728
00:42:53,291 --> 00:42:54,290
right now,
uh,

729
00:42:54,291 --> 00:42:56,750
I don't think,
you know,

730
00:42:56,900 --> 00:43:01,900
I don't,
I don't think robots are going to be as 

731
00:43:01,900 --> 00:43:04,661
autonomous in a hostile environment as,
as people either think or fear,

732
00:43:05,630 --> 00:43:07,160
uh,
because uh,

733
00:43:07,170 --> 00:43:10,640
of how frail they'll still be a until we
get further along.

734
00:43:14,340 --> 00:43:15,260
Hi there.
Hey,

735
00:43:15,850 --> 00:43:19,490
I wanted to ask about two things that 
are going to probably play a big role in

736
00:43:19,491 --> 00:43:22,310
adoption.
The first is price,

737
00:43:22,311 --> 00:43:24,920
so if you could speak to the current 
unit price of a spot,

738
00:43:24,921 --> 00:43:27,290
many and how that you think is going to 
evolve over time.

739
00:43:27,780 --> 00:43:31,160
And the second is sort of consumer 
psychology.

740
00:43:31,210 --> 00:43:33,710
Uh,
I felt like when I saw the,

741
00:43:33,711 --> 00:43:34,540
um,
the,

742
00:43:34,570 --> 00:43:39,570
the test at the end of the robot 
swearing my level of comfort with it 

743
00:43:39,570 --> 00:43:41,360
being in my house suddenly shot up 
because it seemed way more human.

744
00:43:41,690 --> 00:43:44,990
So I was just thinking about what kinds 
of experiments you guys have run away,

745
00:43:45,150 --> 00:43:50,150
what you've thought about with respect 
to making people more comfortable with 

746
00:43:50,150 --> 00:43:50,150
robots working around them.

747
00:43:50,670 --> 00:43:51,330
Yeah.
Uh,

748
00:43:51,630 --> 00:43:53,100
in terms of costs,
I,

749
00:43:53,490 --> 00:43:58,490
you know,
we're not saying what this thing costs 

750
00:43:58,490 --> 00:43:58,490
yet,
but we will later in the year,

751
00:43:58,490 --> 00:44:03,380
um,
we have reduced the cost of this by 

752
00:44:03,380 --> 00:44:04,270
about a factor of 10 from what the first
prototypes cost.

753
00:44:04,560 --> 00:44:06,680
So we're making progress.
Um,

754
00:44:07,350 --> 00:44:11,730
in terms of the psychology of robots,
it's been very interesting to watch,

755
00:44:12,030 --> 00:44:13,470
you know,
we uh,

756
00:44:14,190 --> 00:44:18,390
we got branded sort of as robot abusers 
because we kicked our robot.

757
00:44:18,920 --> 00:44:23,880
Really what we were doing was trying to 
show how good they were at balancing and

758
00:44:23,881 --> 00:44:25,830
we weren't,
we didn't think we were abusing him.

759
00:44:26,040 --> 00:44:31,040
I have video of me pushing on my 
daughter when she was one years old and 

760
00:44:31,040 --> 00:44:32,130
actually knocking her over,
but that wasn't my goal.

761
00:44:32,131 --> 00:44:35,100
I wanted to kind of test out her her 
balance and uh,

762
00:44:35,590 --> 00:44:37,440
uh,
I bet you,

763
00:44:37,470 --> 00:44:42,470
you know,
if you guys have kids or you're or at 

764
00:44:42,470 --> 00:44:42,470
all that you've done stuff like that.

765
00:44:42,470 --> 00:44:43,950
Um,
so,

766
00:44:43,980 --> 00:44:48,980
but we've adjusted a little bit and so 
we don't usually push on the robots in 

767
00:44:48,980 --> 00:44:53,511
our videos despite the one we showed 
with the hockey and hockey sticking a 

768
00:44:54,330 --> 00:44:56,180
hand on this thing.
Uh,

769
00:44:56,370 --> 00:45:01,370
that's why we had the banana peels.
There's a way to have the robot crash 

770
00:45:01,370 --> 00:45:02,280
without us being having our fingerprints
on it.

771
00:45:02,810 --> 00:45:04,610
Um,
you know,

772
00:45:05,530 --> 00:45:10,530
I guess the other data point I have is 
that if you look at the likes and 

773
00:45:10,831 --> 00:45:13,770
dislikes on our youtube videos,
um,

774
00:45:13,771 --> 00:45:18,771
we found a way to get the likes to 
dislikes ratio much higher by partly 

775
00:45:19,351 --> 00:45:23,250
probably by not looking like we're 
abusing the,

776
00:45:23,251 --> 00:45:24,120
uh,
uh,

777
00:45:24,140 --> 00:45:25,570
the robots.
Um,

778
00:45:25,590 --> 00:45:28,680
there's probably a long way to go to 
make these things really friendly.

779
00:45:29,160 --> 00:45:31,060
Um,
and uh,

780
00:45:31,910 --> 00:45:36,910
uh,
I have to admit there's a little spirit 

781
00:45:36,910 --> 00:45:37,560
at our,
at our company of being kind of a,

782
00:45:37,620 --> 00:45:40,530
you know,
it's fun being bad boys in terms of uh,

783
00:45:40,630 --> 00:45:45,630
you know,
just make the robot do cool stuff and 

784
00:45:45,630 --> 00:45:45,630
leave the,
uh,

785
00:45:45,630 --> 00:45:46,860
the emotions to others.
Um,

786
00:45:46,861 --> 00:45:51,861
and certainly the social robots that 
have so much going into making them 

787
00:45:51,861 --> 00:45:52,950
cute.
Uh,

788
00:45:53,640 --> 00:45:58,640
I don't know.
I'm sure we'll have marketing people 

789
00:45:58,640 --> 00:45:58,650
working on that.
I don't know what else to say.

790
00:46:01,410 --> 00:46:05,750
Hi.
So in terms of research purpose,

791
00:46:05,880 --> 00:46:10,880
our practical purposes,
so one of the reasons to choose to 

792
00:46:10,880 --> 00:46:11,090
investigate on this,
um,

793
00:46:11,200 --> 00:46:13,720
humanoid robots.
So it seems like,

794
00:46:13,900 --> 00:46:16,690
um,
it cannot run as fast as the Cheetah and

795
00:46:16,691 --> 00:46:21,691
the,
it also cannot carry as many staff as 

796
00:46:21,691 --> 00:46:21,691
the big dog.

797
00:46:21,691 --> 00:46:26,160
Yeah.
You're basically saying that the 

798
00:46:26,160 --> 00:46:26,870
humanized don't seem to be as practical 
in terms of function

799
00:46:27,980 --> 00:46:29,430
more efficient,
like a,

800
00:46:29,670 --> 00:46:34,000
like a humanoid robot is more efficient 
than these are cheaters and the big box.

801
00:46:34,730 --> 00:46:37,640
Well,
the motivated.

802
00:46:37,730 --> 00:46:40,040
So I don't have a good answer.
Uh,

803
00:46:40,041 --> 00:46:43,520
the motivation for the DRC that Darpa 
robotics challenge,

804
00:46:43,760 --> 00:46:48,760
which was humanoid robots,
was to say that they wanted to use 

805
00:46:48,760 --> 00:46:50,780
robots that could go the places designed
for humans.

806
00:46:51,500 --> 00:46:56,500
And uh,
and so that's why they used the human 

807
00:46:56,500 --> 00:46:56,500
form.
And I think,

808
00:46:56,500 --> 00:46:56,500
you know,
there's an argument there.

809
00:46:56,790 --> 00:46:59,180
Uh,
it is true that the,

810
00:46:59,181 --> 00:47:02,300
uh,
human form has a lot of complexity to it

811
00:47:02,600 --> 00:47:07,600
because you have very complicated legs 
in the IPAD and they're supporting the 

812
00:47:07,600 --> 00:47:11,651
weight of the body and the arms,
whereas the quieter beds can spread all 

813
00:47:11,651 --> 00:47:12,180
that out.
I'm,

814
00:47:14,370 --> 00:47:17,240
uh,
so I'm sympathetic to your question.

815
00:47:17,241 --> 00:47:19,440
I don't really have an answer.
Um,

816
00:47:19,670 --> 00:47:24,670
I can tell you that the public's 
reaction to a humanoid robot is off the 

817
00:47:24,670 --> 00:47:29,471
scale compared to anything we've done 
with a quadrupedal robots for what 

818
00:47:29,471 --> 00:47:30,640
that's worth.
So,

819
00:47:30,641 --> 00:47:35,641
uh,
we always get a lot of viewership if we 

820
00:47:35,641 --> 00:47:36,180
show a human doing something.
Uh,

821
00:47:36,730 --> 00:47:38,980
but I think it's a question that we will
keep addressing.

822
00:47:39,210 --> 00:47:43,370
We are gonna keep pushing on getting the
humanoid to do more and more human,

823
00:47:43,371 --> 00:47:45,000
like things.
Uh,

824
00:47:45,100 --> 00:47:50,100
even though we probably won't 
commercialize them as soon as we 

825
00:47:50,100 --> 00:47:50,100
commercialize the other stuff,

826
00:47:52,440 --> 00:47:57,440
how do you specify goals?
And although you said earlier that it's 

827
00:47:57,440 --> 00:47:57,440
expensive to do like simulations and 
stuff,

828
00:47:57,690 --> 00:48:00,600
do you have any intentions of doing any 
deep reinforcement learning?

829
00:48:01,160 --> 00:48:01,820
What was the last time?

830
00:48:02,170 --> 00:48:04,480
Do you have any intentions of doing deep
reinforcement learning?

831
00:48:05,630 --> 00:48:10,140
Um,
I'll do the last one first.

832
00:48:10,141 --> 00:48:10,590
Um,

833
00:48:12,080 --> 00:48:14,490
we,
I'm sure we will use learning before too

834
00:48:14,491 --> 00:48:15,760
long.
Uh,

835
00:48:15,770 --> 00:48:20,770
I'm not sure whether it will be deep 
reinforcement learning or something 

836
00:48:20,770 --> 00:48:23,931
else,
but mostly we're interested in 

837
00:48:23,931 --> 00:48:26,340
optimizing the complicated a stage space
partitioning.

838
00:48:26,341 --> 00:48:29,790
We do a right now we use,
you know,

839
00:48:29,791 --> 00:48:34,791
people make a very simple decisions as 
to how to divide up the space and we 

840
00:48:35,011 --> 00:48:38,640
think that these things could probably 
be a really improved if we,

841
00:48:38,641 --> 00:48:39,590
uh,
uh,

842
00:48:39,600 --> 00:48:44,600
use the learning approach,
that's probably the first place we will 

843
00:48:44,600 --> 00:48:46,971
apply it.
We do a little bit of learning here and 

844
00:48:46,971 --> 00:48:49,281
there,
but not much compared to how much 

845
00:48:49,281 --> 00:48:49,281
learning is talked about out there.
What was the other question?

846
00:48:51,540 --> 00:48:56,540
How do we specify a goal?
You mean to the robot or how do we 

847
00:48:56,540 --> 00:48:59,721
decide as a company?
So,

848
00:49:00,060 --> 00:49:05,060
um,
I don't think there's any across the 

849
00:49:05,060 --> 00:49:05,130
board answer.
We write applications,

850
00:49:05,310 --> 00:49:07,620
for instance,
for each of these uses.

851
00:49:07,860 --> 00:49:09,330
So for instance,
in the,

852
00:49:09,331 --> 00:49:11,640
uh,
where we were doing the patrol route,

853
00:49:11,641 --> 00:49:15,210
we have an application that has a Ui 
that lets the user,

854
00:49:15,530 --> 00:49:16,120
uh,
you know,

855
00:49:16,140 --> 00:49:17,920
tell it the information it needs to 
tell,

856
00:49:18,060 --> 00:49:20,880
can tell it to go ahead and start on the
patrol.

857
00:49:21,130 --> 00:49:22,470
Uh,
and things like that.

858
00:49:22,740 --> 00:49:24,060
Um,
for,

859
00:49:24,480 --> 00:49:25,920
for the door,
I think,

860
00:49:26,280 --> 00:49:27,270
uh,
I think,

861
00:49:27,271 --> 00:49:28,600
uh,
there's a button on the,

862
00:49:28,700 --> 00:49:31,440
on the controller we can show you 
afterwards if you want.

863
00:49:31,740 --> 00:49:34,380
And uh,
you walk the robot up to the door,

864
00:49:34,381 --> 00:49:39,381
were you steering it and then you press 
the button and then it starts looking 

865
00:49:39,381 --> 00:49:39,960
for the door handle and it goes through 
the whole,

866
00:49:40,210 --> 00:49:41,490
you know,
goes through the door.

867
00:49:44,840 --> 00:49:46,610
But I don't think these answers are 
fundamental.

868
00:49:46,611 --> 00:49:48,230
I think you could do it lots of 
different ways.

869
00:49:48,590 --> 00:49:53,590
You know,
we're working on all the machinery 

870
00:49:53,590 --> 00:49:53,930
coming up from the bottom to be able to 
do these things.

871
00:49:54,200 --> 00:49:54,830
And then,
you know,

872
00:49:54,831 --> 00:49:56,750
in some case you could have it be 
buttons on a,

873
00:49:56,810 --> 00:49:59,120
on a Ui,
it could be a,

874
00:49:59,240 --> 00:50:02,300
an API that's accessed through some 
higher level ai,

875
00:50:02,440 --> 00:50:05,690
uh,
and we just aren't sweating that part of

876
00:50:05,691 --> 00:50:06,350
it at this point.

877
00:50:09,350 --> 00:50:10,150
Hi.
Um,

878
00:50:10,290 --> 00:50:12,470
so aside from locomotion,
um,

879
00:50:12,471 --> 00:50:17,471
I can use my body for like nonverbal 
communication to communicate my 

880
00:50:17,471 --> 00:50:19,500
intentions and other such things,
even though I'm not always aware of it.

881
00:50:19,980 --> 00:50:24,980
Um,
and I'm guess I'm wondering if this is 

882
00:50:24,980 --> 00:50:25,920
something that you've considered for 
these robots.

883
00:50:26,550 --> 00:50:30,680
I think the we've come is having the 
robot go like this after the flip,

884
00:50:30,681 --> 00:50:35,681
which was a way of communicating a,
we really haven't done anything along 

885
00:50:35,681 --> 00:50:40,511
those lines.
I'll bet you though the people writing 

886
00:50:40,511 --> 00:50:40,511
code,
uh,

887
00:50:40,511 --> 00:50:40,910
it can interpret it a lot of the 
subtleties of what's,

888
00:50:41,270 --> 00:50:43,190
you know,
what's working and what isn't by looking

889
00:50:43,191 --> 00:50:48,191
at things like that.
But the robot isn't trying to 

890
00:50:48,191 --> 00:50:48,191
communicate that way.

891
00:50:52,390 --> 00:50:57,390
I have two questions.
How robots really,

892
00:51:00,280 --> 00:51:01,390
really fast.

893
00:51:01,750 --> 00:51:02,980
How do we make them fast?

894
00:51:04,440 --> 00:51:09,440
No,
my question is how did you make them 

895
00:51:09,440 --> 00:51:13,520
fast?
I mean like the time how,

896
00:51:14,710 --> 00:51:19,710
where you get a lot of people who are 
really smart and good at working 

897
00:51:20,531 --> 00:51:25,531
together with each other at our lab and 
then they make plans and a,

898
00:51:27,700 --> 00:51:30,880
which everybody tries to stay on the 
plan and then,

899
00:51:30,910 --> 00:51:32,190
uh,
you know,

900
00:51:32,260 --> 00:51:37,260
pull it together.
Sometimes it doesn't go as fast as we'd 

901
00:51:37,260 --> 00:51:40,721
like,
especially if we have to buy parts from 

902
00:51:40,721 --> 00:51:41,830
someone else and they're slow.
That happens a lot,

903
00:51:42,160 --> 00:51:43,520
honestly.
A,

904
00:51:43,720 --> 00:51:48,400
is that what you mean?
So we don't make them that fast,

905
00:51:48,600 --> 00:51:49,030
you know,
we're,

906
00:51:49,110 --> 00:51:50,110
we're pretty fast,
you know,

907
00:51:50,111 --> 00:51:53,830
usually I'm four or five months to build
a new robot.

908
00:51:54,310 --> 00:51:57,190
Um,
something like that.

909
00:51:57,760 --> 00:51:59,710
But mostly it's getting people to work 
together.

910
00:51:59,890 --> 00:52:01,240
What's the,
what's the other question?

911
00:52:02,770 --> 00:52:07,330
The other question is why do the people 
push the robots?

912
00:52:08,820 --> 00:52:10,210
Why did,
why do they push,

913
00:52:10,960 --> 00:52:14,460
why do they push?
We're trying.

914
00:52:14,490 --> 00:52:19,490
The robots are always balancing them 
themselves and so we want to show that 

915
00:52:19,490 --> 00:52:21,810
they're,
that they can balanced by,

916
00:52:22,200 --> 00:52:23,090
by,
um,

917
00:52:23,130 --> 00:52:25,200
showing that when you knock them,
they still,

918
00:52:25,580 --> 00:52:27,750
they don't fall over,
they stay up on their feet.

919
00:52:28,050 --> 00:52:33,050
So we're kind of showing off.
Are you building anything?

920
00:52:35,380 --> 00:52:38,620
Why not?
You should,

921
00:52:40,020 --> 00:52:45,020
um,
it's way off what we were in the 

922
00:52:46,781 --> 00:52:48,640
basement.
I'm not good at building.

923
00:52:49,000 --> 00:52:49,620
No.
Yes.

924
00:52:49,690 --> 00:52:52,340
Yes you are.
You might think you're not.

925
00:52:52,520 --> 00:52:55,000
Some games they are.
You had to give it a try.

926
00:52:56,120 --> 00:52:58,420
You're the right age.
The right age to get started.

927
00:52:58,890 --> 00:53:00,070
I'm six and a half.

928
00:53:00,960 --> 00:53:01,590
Okay.

929
00:53:09,400 --> 00:53:13,210
Would that,
I think please give mark a big hand.

930
00:53:13,260 --> 00:53:13,900
Thank you very much.

