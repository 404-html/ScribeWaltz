WEBVTT

1
00:00:00.090 --> 00:00:05.090
<v Speaker 1>Welcome back to six as zero,</v>
<v Speaker 1>nine for deep learning for self driving </v>

2
00:00:05.090 --> 00:00:09.201
<v Speaker 1>cars.</v>
<v Speaker 1>Today we will talk about autonomous </v>

3
00:00:12.111 --> 00:00:17.111
<v Speaker 1>vehicles,</v>
<v Speaker 1>also referred to as driverless cars,</v>

4
00:00:18.500 --> 00:00:21.020
<v Speaker 1>autonomous cars,</v>
<v Speaker 1>robot cars.</v>

5
00:00:22.640 --> 00:00:27.640
<v Speaker 1>First,</v>
<v Speaker 1>the Utopian view where for many </v>

6
00:00:29.510 --> 00:00:34.490
<v Speaker 1>autonomous vehicles have the opportunity</v>
<v Speaker 1>to transform our society into a positive</v>

7
00:00:34.491 --> 00:00:39.491
<v Speaker 1>direction.</v>
<v Speaker 1>One point 3 million people die every </v>

8
00:00:39.491 --> 00:00:43.391
<v Speaker 1>year in automobile crashes globally.</v>
<v Speaker 1>Thirty five,</v>

9
00:00:43.971 --> 00:00:45.440
<v Speaker 1>38,</v>
<v Speaker 1>40,000</v>

10
00:00:45.441 --> 00:00:50.441
<v Speaker 1>die every year in the United States,</v>
<v Speaker 1>so the one opportunity that's huge.</v>

11
00:00:51.230 --> 00:00:56.230
<v Speaker 1>That's one of the biggest focus for us </v>
<v Speaker 1>here and mit for people who truly care </v>

12
00:00:56.571 --> 00:01:01.571
<v Speaker 1>about this is to design the autonomous </v>
<v Speaker 1>systems are artificial intelligence </v>

13
00:01:01.571 --> 00:01:06.371
<v Speaker 1>systems that say lies and those systems </v>
<v Speaker 1>help work with deal with or take away </v>

14
00:01:11.030 --> 00:01:14.450
<v Speaker 1>what Nitsa calls the four ds of human </v>
<v Speaker 1>folly,</v>

15
00:01:15.890 --> 00:01:17.480
<v Speaker 1>drunk,</v>
<v Speaker 1>drugged,</v>

16
00:01:17.600 --> 00:01:19.070
<v Speaker 1>distracted,</v>
<v Speaker 1>and drowsy.</v>

17
00:01:19.071 --> 00:01:24.071
<v Speaker 1>Driving autonomous vehicles have the </v>
<v Speaker 1>ability to take away drunk driving,</v>

18
00:01:26.300 --> 00:01:27.680
<v Speaker 1>distracted,</v>
<v Speaker 1>drowsy,</v>

19
00:01:28.820 --> 00:01:32.060
<v Speaker 1>and drugged.</v>
<v Speaker 1>Eliminated car ownership.</v>

20
00:01:32.180 --> 00:01:35.540
<v Speaker 1>So taking shared mobility to another </v>
<v Speaker 1>level,</v>

21
00:01:38.600 --> 00:01:43.600
<v Speaker 1>eliminating car ownership from the </v>
<v Speaker 1>business side has the opportunity to </v>

22
00:01:43.760 --> 00:01:48.760
<v Speaker 1>save people money and increase mobility </v>
<v Speaker 1>and access making vehicles.</v>

23
00:01:52.880 --> 00:01:57.880
<v Speaker 1>Removing ownership makes vehicles more </v>
<v Speaker 1>accessible because the cost of getting </v>

24
00:01:59.391 --> 00:02:04.391
<v Speaker 1>from point a to point b drops an order </v>
<v Speaker 1>to magnitude and the insertion of </v>

25
00:02:08.841 --> 00:02:13.841
<v Speaker 1>software and intelligence into vehicles </v>
<v Speaker 1>makes those vehicles,</v>

26
00:02:13.940 --> 00:02:18.170
<v Speaker 1>makes the idea of transportation.</v>
<v Speaker 1>It makes the way we see moving from a to</v>

27
00:02:18.171 --> 00:02:20.840
<v Speaker 1>point b,</v>
<v Speaker 1>a totally different experience,</v>

28
00:02:21.490 --> 00:02:24.920
<v Speaker 1>much like with our smartphone,</v>
<v Speaker 1>it makes it a personalized,</v>

29
00:02:25.160 --> 00:02:27.860
<v Speaker 1>efficient,</v>
<v Speaker 1>and reliable experience.</v>

30
00:02:29.030 --> 00:02:32.780
<v Speaker 1>Now for the negative view,</v>
<v Speaker 1>for the dystopian view,</v>

31
00:02:35.250 --> 00:02:40.250
<v Speaker 1>eliminate jobs,</v>
<v Speaker 1>any technology throughout its history,</v>

32
00:02:40.470 --> 00:02:45.470
<v Speaker 1>throughout our history of human </v>
<v Speaker 1>civilization has always created fear </v>

33
00:02:45.470 --> 00:02:49.110
<v Speaker 1>that jobs that rely on the prior </v>
<v Speaker 1>technology will be lost.</v>

34
00:02:49.800 --> 00:02:54.800
<v Speaker 1>This is a huge fear,</v>
<v Speaker 1>especially in trucking because so many </v>

35
00:02:56.700 --> 00:03:01.700
<v Speaker 1>people in the United States and across </v>
<v Speaker 1>the rely work in the transportation </v>

36
00:03:01.841 --> 00:03:03.670
<v Speaker 1>industry,</v>
<v Speaker 1>transportation sector,</v>

37
00:03:04.930 --> 00:03:09.930
<v Speaker 1>and the possibility that ai will remove </v>
<v Speaker 1>those jobs has potential catastrophic </v>

38
00:03:10.870 --> 00:03:11.830
<v Speaker 1>consequences.</v>

39
00:03:13.730 --> 00:03:18.730
<v Speaker 1>The idea one that we have to struggle </v>
<v Speaker 1>with in the 21st century of the role of </v>

40
00:03:24.111 --> 00:03:29.111
<v Speaker 1>intelligence systems that aren't human </v>
<v Speaker 1>beings being further and further </v>

41
00:03:29.181 --> 00:03:33.980
<v Speaker 1>integrated into our lives is the idea </v>
<v Speaker 1>that a failure of an autonomous vehicle,</v>

42
00:03:34.340 --> 00:03:36.320
<v Speaker 1>even if they're much rare,</v>
<v Speaker 1>if the.</v>

43
00:03:36.350 --> 00:03:41.350
<v Speaker 1>Even if they're much safer that there is</v>
<v Speaker 1>a possibility for an ai algorithm </v>

44
00:03:41.840 --> 00:03:46.840
<v Speaker 1>designed by probably one of the </v>
<v Speaker 1>engineers in this room will kill a </v>

45
00:03:46.840 --> 00:03:50.831
<v Speaker 1>person where that person would not have </v>
<v Speaker 1>died if they were in control of the </v>

46
00:03:52.341 --> 00:03:55.400
<v Speaker 1>vehicle.</v>
<v Speaker 1>The idea of intelligence system,</v>

47
00:03:55.730 --> 00:04:00.730
<v Speaker 1>one indirect interaction with a human </v>
<v Speaker 1>being killing that human being is one </v>

48
00:04:00.730 --> 00:04:03.020
<v Speaker 1>that we have to struggle with on a </v>
<v Speaker 1>philosophical,</v>

49
00:04:03.021 --> 00:04:08.021
<v Speaker 1>ethical and technological level.</v>
<v Speaker 1>Artificial intelligence systems in </v>

50
00:04:11.411 --> 00:04:16.411
<v Speaker 1>popular culture,</v>
<v Speaker 1>less so in engineering concerns may not </v>

51
00:04:17.651 --> 00:04:22.060
<v Speaker 1>be grounded ethically grounded at this </v>
<v Speaker 1>time.</v>

52
00:04:22.061 --> 00:04:24.010
<v Speaker 1>Much of the focus of building these </v>
<v Speaker 1>systems,</v>

53
00:04:24.011 --> 00:04:29.011
<v Speaker 1>as we'll talk about today and throughout</v>
<v Speaker 1>this course that focuses on the </v>

54
00:04:29.011 --> 00:04:30.430
<v Speaker 1>technology,</v>
<v Speaker 1>how do we make these things work,</v>

55
00:04:31.420 --> 00:04:35.140
<v Speaker 1>but of course,</v>
<v Speaker 1>decades out years or decades out,</v>

56
00:04:35.380 --> 00:04:40.380
<v Speaker 1>the ethical concern started rising for </v>
<v Speaker 1>Rodney Brooks,</v>

57
00:04:42.880 --> 00:04:47.880
<v Speaker 1>one of the seminal people from Mit.</v>
<v Speaker 1>Those ethical concerns will not be an </v>

58
00:04:47.880 --> 00:04:51.280
<v Speaker 1>issue for another several decades,</v>
<v Speaker 1>at least five decades,</v>

59
00:04:52.390 --> 00:04:55.840
<v Speaker 1>but they're still important.</v>
<v Speaker 1>It continues the thought,</v>

60
00:04:55.870 --> 00:04:58.630
<v Speaker 1>the idea of what is the role of Ai in </v>
<v Speaker 1>our society?</v>

61
00:04:59.440 --> 00:05:02.740
<v Speaker 1>When that car gets to make a decision </v>
<v Speaker 1>about human life,</v>

62
00:05:03.580 --> 00:05:05.710
<v Speaker 1>what is it making that decision based </v>
<v Speaker 1>on,</v>

63
00:05:06.070 --> 00:05:11.070
<v Speaker 1>especially when it's a black box,</v>
<v Speaker 1>what is the ethical grounding of that </v>

64
00:05:11.070 --> 00:05:12.760
<v Speaker 1>system?</v>
<v Speaker 1>Does it conform with our social norms?</v>

65
00:05:14.000 --> 00:05:14.720
<v Speaker 1>Does it go,</v>
<v Speaker 1>go,</v>

66
00:05:14.750 --> 00:05:18.350
<v Speaker 1>go against them,</v>
<v Speaker 1>and there's many other concerns?</v>

67
00:05:18.650 --> 00:05:23.650
<v Speaker 1>Security is definitely a big one.</v>
<v Speaker 1>A car this not even artificial </v>

68
00:05:25.551 --> 00:05:27.650
<v Speaker 1>intelligence based the car,</v>
<v Speaker 1>this software base.</v>

69
00:05:27.651 --> 00:05:30.860
<v Speaker 1>As they're becoming more and more </v>
<v Speaker 1>millions,</v>

70
00:05:30.890 --> 00:05:35.890
<v Speaker 1>most of the cars on roads today,</v>
<v Speaker 1>I run by millions of lines of source </v>

71
00:05:35.890 --> 00:05:40.121
<v Speaker 1>code.</v>
<v Speaker 1>The idea that those lines of source code</v>

72
00:05:40.400 --> 00:05:45.400
<v Speaker 1>written again by some of the engineers </v>
<v Speaker 1>in this room get to decide the life of a</v>

73
00:05:45.531 --> 00:05:50.531
<v Speaker 1>human being means then a hacker from </v>
<v Speaker 1>outside of the car can manipulate that </v>

74
00:05:53.031 --> 00:05:56.930
<v Speaker 1>code to also decide the fate of the </v>
<v Speaker 1>human being.</v>

75
00:05:57.080 --> 00:06:02.080
<v Speaker 1>That's a huge concern for us from the </v>
<v Speaker 1>engineering perspective.</v>

76
00:06:04.950 --> 00:06:09.950
<v Speaker 1>The truth is somewhere in the middle we </v>
<v Speaker 1>want to find what is the best positive </v>

77
00:06:09.950 --> 00:06:14.811
<v Speaker 1>way we can build these systems to </v>
<v Speaker 1>transform our society to improve the </v>

78
00:06:14.811 --> 00:06:19.131
<v Speaker 1>quality of life of everyone amongst us,</v>
<v Speaker 1>but there's a grain of salt to the hype </v>

79
00:06:24.130 --> 00:06:29.130
<v Speaker 1>of autonomous vehicles.</v>
<v Speaker 1>We have to remember as we discussed in </v>

80
00:06:29.130 --> 00:06:30.480
<v Speaker 1>the previous lecture,</v>
<v Speaker 1>new will come up again and again.</v>

81
00:06:30.481 --> 00:06:35.481
<v Speaker 1>Our intuition about what is difficult </v>
<v Speaker 1>and what is easy for deep learning for </v>

82
00:06:38.191 --> 00:06:43.191
<v Speaker 1>autonomous systems is flawed.</v>
<v Speaker 1>If we use our infuse ourselves.</v>

83
00:06:44.340 --> 00:06:49.340
<v Speaker 1>In this example,</v>
<v Speaker 1>human beings are extremely good at </v>

84
00:06:49.340 --> 00:06:50.940
<v Speaker 1>driving.</v>
<v Speaker 1>This will come up again and again.</v>

85
00:06:52.020 --> 00:06:57.020
<v Speaker 1>Our intuition has to be grounded in </v>
<v Speaker 1>understanding of what is the source of </v>

86
00:06:57.020 --> 00:06:58.740
<v Speaker 1>data,</v>
<v Speaker 1>what is the annotation,</v>

87
00:06:58.800 --> 00:07:01.290
<v Speaker 1>and what is the approach?</v>
<v Speaker 1>What is the algorithm,</v>

88
00:07:01.950 --> 00:07:04.380
<v Speaker 1>so you have to be careful about using </v>
<v Speaker 1>our intuition,</v>

89
00:07:04.381 --> 00:07:09.381
<v Speaker 1>extending a decades out and making </v>
<v Speaker 1>predictions whether there's towards the </v>

90
00:07:09.381 --> 00:07:10.230
<v Speaker 1>Utopian or dystopian view</v>

91
00:07:12.140 --> 00:07:17.140
<v Speaker 1>and as we'll talk about some of the </v>
<v Speaker 1>advancements of companies working in </v>

92
00:07:17.140 --> 00:07:21.281
<v Speaker 1>this space today,</v>
<v Speaker 1>you have to take what people say in the </v>

93
00:07:21.441 --> 00:07:23.810
<v Speaker 1>media,</v>
<v Speaker 1>what the companies say.</v>

94
00:07:23.840 --> 00:07:28.840
<v Speaker 1>Some of the speakers that will be </v>
<v Speaker 1>speaking at this class say about their </v>

95
00:07:28.840 --> 00:07:30.890
<v Speaker 1>plans for the future and their current </v>
<v Speaker 1>capabilities.</v>

96
00:07:32.000 --> 00:07:37.000
<v Speaker 1>I think us a guide that can provide is </v>
<v Speaker 1>when there's a promise of a future </v>

97
00:07:38.481 --> 00:07:43.481
<v Speaker 1>technology,</v>
<v Speaker 1>future vehicles that are two years out </v>

98
00:07:43.481 --> 00:07:45.300
<v Speaker 1>or more.</v>
<v Speaker 1>That has to be.</v>

99
00:07:46.140 --> 00:07:51.140
<v Speaker 1>That's a very delicate prediction one </v>
<v Speaker 1>that is within a year as we'll give a </v>

100
00:07:51.931 --> 00:07:56.931
<v Speaker 1>few examples today is skeptical.</v>
<v Speaker 1>The real proof comes in actual testing </v>

101
00:08:02.401 --> 00:08:06.390
<v Speaker 1>on public roads or in the most </v>
<v Speaker 1>impressive,</v>

102
00:08:06.420 --> 00:08:11.400
<v Speaker 1>the most amazing.</v>
<v Speaker 1>The reality of it is when it's available</v>

103
00:08:11.401 --> 00:08:16.401
<v Speaker 1>to consumer purchase.</v>
<v Speaker 1>I would like to use Rodney Brooks as a </v>

104
00:08:19.380 --> 00:08:24.380
<v Speaker 1>so it doesn't come from my mouth,</v>
<v Speaker 1>but I happen to agree his prediction is </v>

105
00:08:25.891 --> 00:08:30.891
<v Speaker 1>no earlier than 2032 drivers.</v>
<v Speaker 1>Taxi service in a major US city will </v>

106
00:08:32.641 --> 00:08:36.540
<v Speaker 1>provide arbitrary pickup and drop off </v>
<v Speaker 1>locations fully autonomously.</v>

107
00:08:38.240 --> 00:08:43.240
<v Speaker 1>That's 14 years away and by 2045 it will</v>
<v Speaker 1>do so in multiple cities across the </v>

108
00:08:47.960 --> 00:08:49.780
<v Speaker 1>United States.</v>
<v Speaker 1>So think about that,</v>

109
00:08:50.020 --> 00:08:52.670
<v Speaker 1>that a lot of the engineers working in </v>
<v Speaker 1>this space,</v>

110
00:08:52.790 --> 00:08:55.280
<v Speaker 1>a lot of folks are actually building </v>
<v Speaker 1>these systems,</v>

111
00:08:55.350 --> 00:09:00.350
<v Speaker 1>agree with this idea,</v>
<v Speaker 1>and that is the earliest I believe this </v>

112
00:09:01.320 --> 00:09:05.280
<v Speaker 1>will happen and Rodney believes,</v>
<v Speaker 1>but</v>

113
00:09:08.040 --> 00:09:11.430
<v Speaker 1>as all technophobes have been wrong,</v>
<v Speaker 1>it could be wrong.</v>

114
00:09:12.570 --> 00:09:17.570
<v Speaker 1>This is a map on the x axis,</v>
<v Speaker 1>a plot on the x axis of time throughout </v>

115
00:09:18.361 --> 00:09:23.361
<v Speaker 1>the 20th century and the adoption rate </v>
<v Speaker 1>on the y axis from zero to 100 percent </v>

116
00:09:23.640 --> 00:09:26.890
<v Speaker 1>of the various technologies from </v>
<v Speaker 1>electricity to cars to radio,</v>

117
00:09:26.891 --> 00:09:31.110
<v Speaker 1>the telephone and so on.</v>
<v Speaker 1>And as we get closer to today,</v>

118
00:09:31.200 --> 00:09:35.730
<v Speaker 1>the technology adoption rate,</v>
<v Speaker 1>when it goes from zero to 100 percent,</v>

119
00:09:36.390 --> 00:09:41.390
<v Speaker 1>the number of years it takes to adopt </v>
<v Speaker 1>that technology is getting shorter and </v>

120
00:09:41.390 --> 00:09:43.530
<v Speaker 1>shorter and shorter.</v>
<v Speaker 1>As a society,</v>

121
00:09:43.531 --> 00:09:48.531
<v Speaker 1>we're better at throwing away the </v>
<v Speaker 1>technology evolved and accepting of </v>

122
00:09:48.531 --> 00:09:52.451
<v Speaker 1>technology of new.</v>
<v Speaker 1>So if a brilliant idea to solve some of </v>

123
00:09:52.891 --> 00:09:54.600
<v Speaker 1>the problems were discussing comes </v>
<v Speaker 1>along,</v>

124
00:09:54.630 --> 00:09:59.630
<v Speaker 1>it could change everything overnight.</v>
<v Speaker 1>So let's talk about different approaches</v>

125
00:10:02.741 --> 00:10:07.600
<v Speaker 1>to autonomy.</v>
<v Speaker 1>We'll talk about sensors afterwards.</v>

126
00:10:08.140 --> 00:10:10.930
<v Speaker 1>We'll talk about companies,</v>
<v Speaker 1>players in this space,</v>

127
00:10:11.740 --> 00:10:16.740
<v Speaker 1>and then we'll talk about ai and the </v>
<v Speaker 1>actual algorithms and how they can help </v>

128
00:10:19.810 --> 00:10:22.330
<v Speaker 1>solve some of the problems with </v>
<v Speaker 1>autonomous vehicles.</v>

129
00:10:24.130 --> 00:10:28.030
<v Speaker 1>Levels of autonomy.</v>
<v Speaker 1>Here's a useful</v>

130
00:10:30.330 --> 00:10:35.330
<v Speaker 1>taxonomies of levels of autonomy,</v>
<v Speaker 1>useful for initial discussion,</v>

131
00:10:38.130 --> 00:10:43.130
<v Speaker 1>for legal discussion and for policy </v>
<v Speaker 1>making and for blog posts.</v>

132
00:10:43.541 --> 00:10:46.890
<v Speaker 1>The media reports,</v>
<v Speaker 1>but it's not useful.</v>

133
00:10:46.950 --> 00:10:51.950
<v Speaker 1>I would argue for design and engineering</v>
<v Speaker 1>of the underlying intelligence and the </v>

134
00:10:52.230 --> 00:10:54.780
<v Speaker 1>system viewed from a holistic </v>
<v Speaker 1>perspective,</v>

135
00:10:54.900 --> 00:10:59.900
<v Speaker 1>the entire thing,</v>
<v Speaker 1>creating an experience that's safe and </v>

136
00:10:59.900 --> 00:11:00.570
<v Speaker 1>enjoyable.</v>
<v Speaker 1>So let's go over those levels.</v>

137
00:11:01.170 --> 00:11:03.180
<v Speaker 1>The five,</v>
<v Speaker 1>the six levels.</v>

138
00:11:05.130 --> 00:11:08.220
<v Speaker 1>This is presented by sae report j three </v>
<v Speaker 1>zero,</v>

139
00:11:08.221 --> 00:11:13.221
<v Speaker 1>one six.</v>
<v Speaker 1>The most widely accepted taxonomists </v>

140
00:11:13.221 --> 00:11:15.450
<v Speaker 1>nation of autonomy.</v>
<v Speaker 1>No automation at level zero.</v>

141
00:11:15.840 --> 00:11:18.750
<v Speaker 1>Level one and level two is increasing </v>
<v Speaker 1>levels of automation.</v>

142
00:11:18.751 --> 00:11:23.360
<v Speaker 1>Level one is cruise control,</v>
<v Speaker 1>level two is adaptive cruise control and</v>

143
00:11:23.370 --> 00:11:25.830
<v Speaker 1>lane keeping.</v>
<v Speaker 1>Level three,</v>

144
00:11:26.310 --> 00:11:31.310
<v Speaker 1>I don't know what level three is.</v>
<v Speaker 1>There's a lot of people that will </v>

145
00:11:31.310 --> 00:11:32.880
<v Speaker 1>explain that.</v>
<v Speaker 1>Level three is conditional automation,</v>

146
00:11:32.881 --> 00:11:35.970
<v Speaker 1>meaning it's constrained to certain </v>
<v Speaker 1>geographical location.</v>

147
00:11:36.600 --> 00:11:39.030
<v Speaker 1>I will explain that from an engineer </v>
<v Speaker 1>perspective.</v>

148
00:11:39.270 --> 00:11:44.270
<v Speaker 1>I'm a personally a little bit confused </v>
<v Speaker 1>on where that stands.</v>

149
00:11:45.300 --> 00:11:48.450
<v Speaker 1>I'll try to redefine how we should view </v>
<v Speaker 1>automation.</v>

150
00:11:49.050 --> 00:11:53.370
<v Speaker 1>Level four and level five is high full </v>
<v Speaker 1>level automation.</v>

151
00:11:53.710 --> 00:11:58.710
<v Speaker 1>Level four is when the vehicle can drive</v>
<v Speaker 1>itself fully for part of the time.</v>

152
00:11:59.890 --> 00:12:03.580
<v Speaker 1>There's certain areas in which you can </v>
<v Speaker 1>take care of everything no matter what.</v>

153
00:12:03.581 --> 00:12:08.581
<v Speaker 1>No human inter interaction input </v>
<v Speaker 1>safekeeping as required.</v>

154
00:12:10.600 --> 00:12:13.150
<v Speaker 1>Level five,</v>
<v Speaker 1>automation is the car does everything.</v>

155
00:12:14.980 --> 00:12:15.550
<v Speaker 1>Everything.</v>

156
00:12:18.010 --> 00:12:23.010
<v Speaker 1>I would argue that those levels aren't </v>
<v Speaker 1>useful for designing systems that </v>

157
00:12:23.771 --> 00:12:27.400
<v Speaker 1>actually work in the real world.</v>
<v Speaker 1>I would argue that there's two systems,</v>

158
00:12:28.330 --> 00:12:33.330
<v Speaker 1>but first a starting point that every </v>
<v Speaker 1>system to some degree involves a human.</v>

159
00:12:35.410 --> 00:12:40.410
<v Speaker 1>It starts with manual control from a </v>
<v Speaker 1>human human getting in the car and a </v>

160
00:12:41.951 --> 00:12:46.090
<v Speaker 1>human electing to do something so that's</v>
<v Speaker 1>the manual control.</v>

161
00:12:46.480 --> 00:12:49.570
<v Speaker 1>What we're talking about.</v>
<v Speaker 1>When the human engages the system,</v>

162
00:12:50.410 --> 00:12:55.410
<v Speaker 1>when the system is first available and </v>
<v Speaker 1>the human chooses to turn it on,</v>

163
00:12:56.170 --> 00:13:01.170
<v Speaker 1>that's one we have to ai systems,</v>
<v Speaker 1>human centered autonomy,</v>

164
00:13:01.960 --> 00:13:06.910
<v Speaker 1>when the human is needed is involved and</v>
<v Speaker 1>full autonomy.</v>

165
00:13:07.150 --> 00:13:11.350
<v Speaker 1>When ai is fully responsible for </v>
<v Speaker 1>everything from the legal perspective,</v>

166
00:13:11.410 --> 00:13:16.410
<v Speaker 1>that means a two full autonomy means the</v>
<v Speaker 1>car they designer,</v>

167
00:13:16.690 --> 00:13:20.380
<v Speaker 1>the AI system is liable,</v>
<v Speaker 1>is responsible,</v>

168
00:13:21.010 --> 00:13:24.280
<v Speaker 1>and for the human center of autonomy,</v>
<v Speaker 1>the human is responsible.</v>

169
00:13:27.270 --> 00:13:31.800
<v Speaker 1>What does this practically mean for </v>
<v Speaker 1>human centered autonomy,</v>

170
00:13:32.490 --> 00:13:34.890
<v Speaker 1>and we'll discuss examples of all of </v>
<v Speaker 1>these.</v>

171
00:13:36.240 --> 00:13:41.240
<v Speaker 1>When a human interaction is necessary.</v>
<v Speaker 1>The question then becomes is how often </v>

172
00:13:44.040 --> 00:13:49.040
<v Speaker 1>is the system available?</v>
<v Speaker 1>Is it available on in traffic </v>

173
00:13:49.741 --> 00:13:51.300
<v Speaker 1>conditions,</v>
<v Speaker 1>so for traffic,</v>

174
00:13:51.360 --> 00:13:53.610
<v Speaker 1>bumper to bumper is available on the </v>
<v Speaker 1>highway.</v>

175
00:13:53.640 --> 00:13:56.220
<v Speaker 1>Is that sensor based like in the Tesla </v>
<v Speaker 1>vehicle,</v>

176
00:13:56.221 --> 00:13:59.460
<v Speaker 1>meaning based on the visual </v>
<v Speaker 1>characteristics to the scene,</v>

177
00:13:59.760 --> 00:14:02.430
<v Speaker 1>the vehicle is confident enough to be </v>
<v Speaker 1>able to control,</v>

178
00:14:02.490 --> 00:14:06.120
<v Speaker 1>to make control decisions,</v>
<v Speaker 1>perception control decisions.</v>

179
00:14:07.620 --> 00:14:12.620
<v Speaker 1>The other factor not discussed enough </v>
<v Speaker 1>and I think poorly imprecisely discussed</v>

180
00:14:16.171 --> 00:14:21.171
<v Speaker 1>when it is,</v>
<v Speaker 1>is the number of seconds given to the </v>

181
00:14:21.171 --> 00:14:23.580
<v Speaker 1>driver,</v>
<v Speaker 1>not guaranteed,</v>

182
00:14:23.730 --> 00:14:28.730
<v Speaker 1>but provided as a sort of feature to the</v>
<v Speaker 1>driver to take over and the Tesla </v>

183
00:14:28.861 --> 00:14:31.350
<v Speaker 1>vehicle in all vehicles on the road </v>
<v Speaker 1>today,</v>

184
00:14:31.470 --> 00:14:36.470
<v Speaker 1>that time is zero.</v>
<v Speaker 1>Zero seconds of guaranteed zero seconds </v>

185
00:14:36.470 --> 00:14:37.140
<v Speaker 1>have provided.</v>
<v Speaker 1>There is some,</v>

186
00:14:37.530 --> 00:14:40.920
<v Speaker 1>there is some room and sometimes it's </v>
<v Speaker 1>hundreds of milliseconds,</v>

187
00:14:40.921 --> 00:14:45.921
<v Speaker 1>sometimes it's multiple seconds,</v>
<v Speaker 1>but really there's no standard of how </v>

188
00:14:45.921 --> 00:14:49.581
<v Speaker 1>many seconds you get to say wake up,</v>
<v Speaker 1>take control.</v>

189
00:14:51.500 --> 00:14:56.500
<v Speaker 1>Then tele operation,</v>
<v Speaker 1>something that some of the companies </v>

190
00:14:56.780 --> 00:15:01.780
<v Speaker 1>will mention are playing with is when a </v>
<v Speaker 1>human being as involved remotely </v>

191
00:15:01.780 --> 00:15:06.190
<v Speaker 1>controlling the vehicle remotely,</v>
<v Speaker 1>so being able to take over control of </v>

192
00:15:06.190 --> 00:15:07.610
<v Speaker 1>the vehicle when you're,</v>
<v Speaker 1>uh,</v>

193
00:15:08.000 --> 00:15:13.000
<v Speaker 1>when you're not able to control it.</v>
<v Speaker 1>So support by human that's not inside </v>

194
00:15:13.000 --> 00:15:17.471
<v Speaker 1>the car.</v>
<v Speaker 1>That's a very interesting idea to </v>

195
00:15:17.471 --> 00:15:19.931
<v Speaker 1>explore.</v>
<v Speaker 1>But for the human centered autonomy </v>

196
00:15:19.931 --> 00:15:22.730
<v Speaker 1>side,</v>
<v Speaker 1>all of those features and not required,</v>

197
00:15:22.760 --> 00:15:27.760
<v Speaker 1>they're not guaranteed the human driver,</v>
<v Speaker 1>the human inside the car is always </v>

198
00:15:28.191 --> 00:15:29.660
<v Speaker 1>responsible.</v>
<v Speaker 1>At the end of the day,</v>

199
00:15:29.661 --> 00:15:33.440
<v Speaker 1>they must pay attention to a degree </v>
<v Speaker 1>that's required to take over.</v>

200
00:15:33.441 --> 00:15:37.670
<v Speaker 1>When the system fails and no matter </v>
<v Speaker 1>under this consideration,</v>

201
00:15:37.730 --> 00:15:42.730
<v Speaker 1>under this level of autonomy,</v>
<v Speaker 1>the system will fail at some point.</v>

202
00:15:43.730 --> 00:15:45.230
<v Speaker 1>That is the,</v>
<v Speaker 1>that is the point.</v>

203
00:15:45.260 --> 00:15:50.260
<v Speaker 1>That is the collaboration between human </v>
<v Speaker 1>and robot is the system will fail and </v>

204
00:15:50.260 --> 00:15:51.980
<v Speaker 1>the human has to catch one that does.</v>

205
00:15:53.600 --> 00:15:58.280
<v Speaker 1>And then full autonomy is ai is fully </v>
<v Speaker 1>responsible,</v>

206
00:15:58.820 --> 00:16:01.250
<v Speaker 1>not that doesn't.</v>
<v Speaker 1>Again,</v>

207
00:16:01.251 --> 00:16:06.251
<v Speaker 1>as we will present some companies in the</v>
<v Speaker 1>marketing material and that pr side of </v>

208
00:16:06.251 --> 00:16:10.331
<v Speaker 1>things,</v>
<v Speaker 1>they might present that there is </v>

209
00:16:10.331 --> 00:16:12.551
<v Speaker 1>significant degrees of autonomy.</v>
<v Speaker 1>If you're talking about l three or l </v>

210
00:16:12.551 --> 00:16:16.220
<v Speaker 1>four or l five,</v>
<v Speaker 1>you have to read between the lines.</v>

211
00:16:17.450 --> 00:16:20.450
<v Speaker 1>You're not allowed to have tele </v>
<v Speaker 1>operation.</v>

212
00:16:22.400 --> 00:16:25.610
<v Speaker 1>If a human is remotely operating the </v>
<v Speaker 1>vehicle,</v>

213
00:16:25.730 --> 00:16:29.540
<v Speaker 1>a humanist still in the loop,</v>
<v Speaker 1>a humanness still evolved.</v>

214
00:16:29.900 --> 00:16:32.060
<v Speaker 1>It's still a human centered and autonomy</v>
<v Speaker 1>system.</v>

215
00:16:33.320 --> 00:16:38.320
<v Speaker 1>You don't get the ten second rule,</v>
<v Speaker 1>which is ge just because you give the </v>

216
00:16:40.341 --> 00:16:45.341
<v Speaker 1>driver 10 seconds to take control.</v>
<v Speaker 1>That somehow removes liability for you.</v>

217
00:16:45.620 --> 00:16:48.950
<v Speaker 1>If you say that that's it.</v>
<v Speaker 1>As an AI system,</v>

218
00:16:48.951 --> 00:16:53.470
<v Speaker 1>I can't take a can't resolve,</v>
<v Speaker 1>can't deal,</v>

219
00:16:53.480 --> 00:16:55.490
<v Speaker 1>can't control the vehicle in this </v>
<v Speaker 1>situation,</v>

220
00:16:56.020 --> 00:16:58.580
<v Speaker 1>and you have 10 seconds to take over,</v>
<v Speaker 1>that's not good enough.</v>

221
00:16:58.640 --> 00:17:01.730
<v Speaker 1>The driver might be sleeping.</v>
<v Speaker 1>That driver may have had a heart attack.</v>

222
00:17:01.731 --> 00:17:06.731
<v Speaker 1>They're not able to control the vehicle.</v>
<v Speaker 1>Full autonomous systems might must find </v>

223
00:17:07.460 --> 00:17:11.110
<v Speaker 1>safe harbor.</v>
<v Speaker 1>That must get you full.</v>

224
00:17:11.120 --> 00:17:16.120
<v Speaker 1>Stop from point a to point b.</v>
<v Speaker 1>That point b might be your desired </v>

225
00:17:16.120 --> 00:17:18.170
<v Speaker 1>destination or it might be a safe </v>
<v Speaker 1>parking lot,</v>

226
00:17:18.620 --> 00:17:21.500
<v Speaker 1>but it has to bring you to a safe </v>
<v Speaker 1>location.</v>

227
00:17:21.860 --> 00:17:25.820
<v Speaker 1>This is a clear definition of the two </v>
<v Speaker 1>systems and the human.</v>

228
00:17:25.821 --> 00:17:28.400
<v Speaker 1>Of course,</v>
<v Speaker 1>as far as our certain.</v>

229
00:17:28.620 --> 00:17:33.620
<v Speaker 1>A current conception of artificial </v>
<v Speaker 1>intelligence in cars today is a human </v>

230
00:17:33.620 --> 00:17:38.590
<v Speaker 1>always overrides the AI system,</v>
<v Speaker 1>so we should for the for the in the </v>

231
00:17:39.291 --> 00:17:44.291
<v Speaker 1>general case,</v>
<v Speaker 1>the human gets to choose to take </v>

232
00:17:45.381 --> 00:17:50.381
<v Speaker 1>control.</v>
<v Speaker 1>The Ai can't take controls any human </v>

233
00:17:50.381 --> 00:17:53.560
<v Speaker 1>except when danger is imminent,</v>
<v Speaker 1>meaning sudden crashes like an ab </v>

234
00:17:53.560 --> 00:17:58.251
<v Speaker 1>events.</v>
<v Speaker 1>We're not yet ready for AI systems to </v>

235
00:17:58.251 --> 00:17:59.430
<v Speaker 1>say as a society to say,</v>
<v Speaker 1>no,</v>

236
00:17:59.431 --> 00:17:59.940
<v Speaker 1>no,</v>
<v Speaker 1>no.</v>

237
00:17:59.970 --> 00:18:02.280
<v Speaker 1>You're drunk.</v>
<v Speaker 1>You can't drive.</v>

238
00:18:06.700 --> 00:18:11.080
<v Speaker 1>So beyond the traditional levels from </v>
<v Speaker 1>level zero to level five,</v>

239
00:18:11.410 --> 00:18:13.990
<v Speaker 1>the starting point is level zero,</v>
<v Speaker 1>no automation.</v>

240
00:18:14.050 --> 00:18:16.390
<v Speaker 1>All cars start here.</v>
<v Speaker 1>Level one,</v>

241
00:18:16.391 --> 00:18:21.391
<v Speaker 1>level two and level three,</v>
<v Speaker 1>I would argue fall into human senator </v>

242
00:18:21.391 --> 00:18:23.330
<v Speaker 1>autonomy systems,</v>
<v Speaker 1>a one</v>

243
00:18:25.080 --> 00:18:28.200
<v Speaker 1>because they involve some degree of a </v>
<v Speaker 1>human.</v>

244
00:18:28.770 --> 00:18:33.770
<v Speaker 1>Now four or five to some degree,</v>
<v Speaker 1>there's some crossover fall into full </v>

245
00:18:34.021 --> 00:18:37.160
<v Speaker 1>autonomy,</v>
<v Speaker 1>even though with all four,</v>

246
00:18:37.200 --> 00:18:42.200
<v Speaker 1>with way Mo,</v>
<v Speaker 1>as you can ask on Friday and anyone </v>

247
00:18:42.200 --> 00:18:46.731
<v Speaker 1>cruise uber playing in this space,</v>
<v Speaker 1>there's very often a human driver </v>

248
00:18:47.311 --> 00:18:52.170
<v Speaker 1>involved.</v>
<v Speaker 1>One of the huge accomplishments of waymo</v>

249
00:18:52.960 --> 00:18:55.780
<v Speaker 1>over the past month.</v>
<v Speaker 1>Incredible accomplishment.</v>

250
00:18:56.020 --> 00:18:57.250
<v Speaker 1>We're in Phoenix,</v>
<v Speaker 1>Arizona.</v>

251
00:18:57.251 --> 00:19:01.090
<v Speaker 1>They drove without the car,</v>
<v Speaker 1>drove without a driver.</v>

252
00:19:02.530 --> 00:19:06.010
<v Speaker 1>The meaning there was no safety driver </v>
<v Speaker 1>to catch.</v>

253
00:19:06.040 --> 00:19:10.300
<v Speaker 1>There is no engineer staff member there </v>
<v Speaker 1>to catch the car.</v>

254
00:19:10.840 --> 00:19:15.840
<v Speaker 1>A human being that doesn't work for </v>
<v Speaker 1>Google or Waymo got into that car and </v>

255
00:19:15.911 --> 00:19:18.430
<v Speaker 1>got from a to point b without a safety </v>
<v Speaker 1>driver.</v>

256
00:19:19.060 --> 00:19:24.060
<v Speaker 1>That's an incredible accomplishment and </v>
<v Speaker 1>that particular trip was a fully </v>

257
00:19:24.431 --> 00:19:29.431
<v Speaker 1>autonomous trip.</v>
<v Speaker 1>That is full autonomy when there's no </v>

258
00:19:29.431 --> 00:19:33.891
<v Speaker 1>human to catch the car.</v>
<v Speaker 1>No Ai presentation is good without cats.</v>

259
00:19:39.650 --> 00:19:44.650
<v Speaker 1>So full autonomy.</v>
<v Speaker 1>A two system is when you do nothing but </v>

260
00:19:46.131 --> 00:19:51.131
<v Speaker 1>write along.</v>
<v Speaker 1>Human centered autonomy system is when </v>

261
00:19:51.621 --> 00:19:54.910
<v Speaker 1>you have some control.</v>
<v Speaker 1>I'm sorry,</v>

262
00:19:54.911 --> 00:19:59.911
<v Speaker 1>I had to.</v>
<v Speaker 1>So the two paths for autonomous systems,</v>

263
00:20:00.611 --> 00:20:05.290
<v Speaker 1>they want an a two in blue.</v>
<v Speaker 1>On the left is a one human centered,</v>

264
00:20:05.350 --> 00:20:07.660
<v Speaker 1>on the right is a two full autonomy</v>

265
00:20:09.990 --> 00:20:14.990
<v Speaker 1>and then blue is from the artificial </v>
<v Speaker 1>intelligent perspective is easy,</v>

266
00:20:18.530 --> 00:20:21.290
<v Speaker 1>easier,</v>
<v Speaker 1>and then red is harder,</v>

267
00:20:22.340 --> 00:20:27.340
<v Speaker 1>easier,</v>
<v Speaker 1>meaning we do not have to achieve 100 </v>

268
00:20:27.340 --> 00:20:31.151
<v Speaker 1>percent accuracy.</v>
<v Speaker 1>Harder means everything that's off of </v>

269
00:20:31.561 --> 00:20:36.561
<v Speaker 1>100 percent accuracy,</v>
<v Speaker 1>no matter how small has a potential of </v>

270
00:20:36.651 --> 00:20:41.651
<v Speaker 1>costing human lives and huge amounts of </v>
<v Speaker 1>money for companies.</v>

271
00:20:46.610 --> 00:20:51.610
<v Speaker 1>So let's discuss.</v>
<v Speaker 1>We'll discuss later in the lecture about</v>

272
00:20:52.301 --> 00:20:55.570
<v Speaker 1>the algorithms behind each of these </v>
<v Speaker 1>methods and the left and the right,</v>

273
00:20:56.440 --> 00:21:01.440
<v Speaker 1>but this summarizes the two approaches,</v>
<v Speaker 1>the localization mapping for the car to </v>

274
00:21:01.811 --> 00:21:06.640
<v Speaker 1>determine where it's located.</v>
<v Speaker 1>For the human centered autonomy,</v>

275
00:21:06.790 --> 00:21:10.360
<v Speaker 1>it's easy.</v>
<v Speaker 1>It still has to do the perception it has</v>

276
00:21:10.361 --> 00:21:15.361
<v Speaker 1>to localize itself within the lane.</v>
<v Speaker 1>It has defined all the neighboring </v>

277
00:21:15.361 --> 00:21:19.441
<v Speaker 1>pedestrians in the vehicles in order to </v>
<v Speaker 1>be able to control the vehicle to some </v>

278
00:21:19.441 --> 00:21:21.520
<v Speaker 1>degree,</v>
<v Speaker 1>but because the human is there,</v>

279
00:21:21.521 --> 00:21:24.160
<v Speaker 1>it doesn't have to do so perfectly when </v>
<v Speaker 1>it fails.</v>

280
00:21:24.161 --> 00:21:27.370
<v Speaker 1>A humans there to catch it.</v>
<v Speaker 1>Seen understanding,</v>

281
00:21:27.460 --> 00:21:30.070
<v Speaker 1>perceiving everything in the environment</v>
<v Speaker 1>from the camera,</v>

282
00:21:30.071 --> 00:21:31.420
<v Speaker 1>from law,</v>
<v Speaker 1>whether it's Lidar,</v>

283
00:21:31.421 --> 00:21:32.590
<v Speaker 1>radar,</v>
<v Speaker 1>ultrasonic,</v>

284
00:21:33.670 --> 00:21:37.830
<v Speaker 1>the planning of the vehicle,</v>
<v Speaker 1>whether it's just staying within lane,</v>

285
00:21:37.850 --> 00:21:39.430
<v Speaker 1>uh,</v>
<v Speaker 1>for adaptive cruise control,</v>

286
00:21:39.460 --> 00:21:42.070
<v Speaker 1>controlling the longitudinal movement of</v>
<v Speaker 1>the vehicle,</v>

287
00:21:42.250 --> 00:21:47.250
<v Speaker 1>or it's changing lanes at the Tesla </v>
<v Speaker 1>autopilot or higher degrees of </v>

288
00:21:47.250 --> 00:21:47.250
<v Speaker 1>automation.</v>

289
00:21:47.250 --> 00:21:49.960
<v Speaker 1>All of those movement planning decisions</v>
<v Speaker 1>can be made autonomy.</v>

290
00:21:50.240 --> 00:21:54.400
<v Speaker 1>When the human is there to catch,</v>
<v Speaker 1>it's easier because you're allowed to be</v>

291
00:21:54.401 --> 00:21:56.590
<v Speaker 1>wrong.</v>
<v Speaker 1>Rarely but wrong.</v>

292
00:21:57.670 --> 00:22:01.240
<v Speaker 1>The hard part is getting the human robot</v>
<v Speaker 1>interaction piece right.</v>

293
00:22:02.560 --> 00:22:07.560
<v Speaker 1>That's next Wednesday lecture as we'll </v>
<v Speaker 1>discuss about how deep learning can be </v>

294
00:22:10.121 --> 00:22:14.470
<v Speaker 1>used to interact first.</v>
<v Speaker 1>Perceive everything about the driver and</v>

295
00:22:14.471 --> 00:22:19.471
<v Speaker 1>second to interact with the driver.</v>
<v Speaker 1>That part is hard because he can't screw</v>

296
00:22:19.961 --> 00:22:24.961
<v Speaker 1>up on that part.</v>
<v Speaker 1>You have to make sure you help the </v>

297
00:22:24.961 --> 00:22:26.290
<v Speaker 1>driver know where your flaws are so they</v>
<v Speaker 1>can take over.</v>

298
00:22:26.560 --> 00:22:31.560
<v Speaker 1>If the driver's not paying attention,</v>
<v Speaker 1>you have to bring their attention back </v>

299
00:22:31.560 --> 00:22:31.660
<v Speaker 1>to the road,</v>
<v Speaker 1>back to the interaction.</v>

300
00:22:32.020 --> 00:22:35.500
<v Speaker 1>You have to get that piece right because</v>
<v Speaker 1>for a flawed system,</v>

301
00:22:36.010 --> 00:22:38.710
<v Speaker 1>one that's rarely flawed.</v>
<v Speaker 1>The rarities,</v>

302
00:22:38.711 --> 00:22:43.711
<v Speaker 1>the challenge in fact has to get the </v>
<v Speaker 1>interaction right and then the final </v>

303
00:22:44.681 --> 00:22:45.940
<v Speaker 1>piece is communication.</v>

304
00:22:47.230 --> 00:22:52.230
<v Speaker 1>The autonomous vehicle,</v>
<v Speaker 1>fully autonomous vehicle must </v>

305
00:22:52.230 --> 00:22:54.640
<v Speaker 1>communicate extremely well with the </v>
<v Speaker 1>external world,</v>

306
00:22:54.850 --> 00:22:58.030
<v Speaker 1>with a pedestrian is the Jay Walker's </v>
<v Speaker 1>the humans in this world.</v>

307
00:22:58.031 --> 00:23:02.320
<v Speaker 1>The cyclists that that communication </v>
<v Speaker 1>piece one,</v>

308
00:23:02.321 --> 00:23:06.310
<v Speaker 1>at least that is part of a safe and </v>
<v Speaker 1>enjoyable driving experience,</v>

309
00:23:06.520 --> 00:23:10.360
<v Speaker 1>is extremely difficult on the Ta Waymo </v>
<v Speaker 1>vehicle.</v>

310
00:23:10.420 --> 00:23:15.420
<v Speaker 1>I wish them luck if they come to Boston.</v>
<v Speaker 1>I'm getting from point a to point b </v>

311
00:23:15.430 --> 00:23:20.430
<v Speaker 1>because pedestrians will take advantage </v>
<v Speaker 1>of vehicle must assert itself in order </v>

312
00:23:22.391 --> 00:23:27.391
<v Speaker 1>to be able to navigate Boston streets </v>
<v Speaker 1>and that assertion is communication.</v>

313
00:23:28.990 --> 00:23:33.990
<v Speaker 1>That piece is extremely difficult for a </v>
<v Speaker 1>tesla vehicle for for a a human centered</v>

314
00:23:36.911 --> 00:23:39.640
<v Speaker 1>autonomy vehicle.</v>
<v Speaker 1>L Two l three.</v>

315
00:23:41.260 --> 00:23:44.950
<v Speaker 1>The way you deal with Boston pedestrians</v>
<v Speaker 1>is you take over,</v>

316
00:23:45.800 --> 00:23:47.540
<v Speaker 1>roll down the window,</v>
<v Speaker 1>yells something,</v>

317
00:23:47.541 --> 00:23:52.541
<v Speaker 1>and then speed up getting the piece for </v>
<v Speaker 1>an artificial intelligence system to </v>

318
00:23:54.201 --> 00:23:56.450
<v Speaker 1>actually be able to accomplish something</v>
<v Speaker 1>like that.</v>

319
00:23:56.450 --> 00:24:01.450
<v Speaker 1>As we'll discuss on the ethics side and </v>
<v Speaker 1>the engineering side is extremely </v>

320
00:24:01.450 --> 00:24:04.100
<v Speaker 1>difficult.</v>
<v Speaker 1>That said,</v>

321
00:24:04.310 --> 00:24:08.390
<v Speaker 1>most of the literature and the human </v>
<v Speaker 1>factors field and the autonomous vehicle</v>

322
00:24:08.391 --> 00:24:13.391
<v Speaker 1>field,</v>
<v Speaker 1>anyone that's studied autonomy in </v>

323
00:24:13.391 --> 00:24:16.031
<v Speaker 1>aviation and in vehicles is extremely </v>
<v Speaker 1>skeptical about a human centered </v>

324
00:24:16.911 --> 00:24:19.550
<v Speaker 1>approach they think is deeply </v>
<v Speaker 1>irresponsible,</v>

325
00:24:20.060 --> 00:24:25.060
<v Speaker 1>is deeply irresponsible because is as </v>
<v Speaker 1>argued because human beings,</v>

326
00:24:28.130 --> 00:24:33.130
<v Speaker 1>when you give them a technology which </v>
<v Speaker 1>will take control part of the time,</v>

327
00:24:34.400 --> 00:24:39.400
<v Speaker 1>they'll get lazy.</v>
<v Speaker 1>They would take advantage of that </v>

328
00:24:39.400 --> 00:24:39.400
<v Speaker 1>technology.</v>
<v Speaker 1>They will overtrust that technology.</v>

329
00:24:39.400 --> 00:24:43.841
<v Speaker 1>They'll assume a work perfectly always.</v>
<v Speaker 1>This is the idea that this is this idea </v>

330
00:24:48.141 --> 00:24:53.141
<v Speaker 1>extended beyond further and further </v>
<v Speaker 1>means that the better the system gets,</v>

331
00:24:53.570 --> 00:24:55.790
<v Speaker 1>the better of the car,</v>
<v Speaker 1>it gets a driving itself.</v>

332
00:24:55.970 --> 00:24:59.570
<v Speaker 1>The more the humans will sit back and be</v>
<v Speaker 1>completely distracted.</v>

333
00:24:59.571 --> 00:25:03.560
<v Speaker 1>It will not be able to reengage </v>
<v Speaker 1>themselves in order to safely catch when</v>

334
00:25:03.561 --> 00:25:04.610
<v Speaker 1>the system fails.</v>

335
00:25:05.180 --> 00:25:10.180
<v Speaker 1>This is Chris Urmson,</v>
<v Speaker 1>the founder of the Google self driving </v>

336
00:25:10.180 --> 00:25:13.121
<v Speaker 1>cars program,</v>
<v Speaker 1>and now the co founder of one of the </v>

337
00:25:14.631 --> 00:25:17.210
<v Speaker 1>other co founder is a speaker.</v>
<v Speaker 1>This class on next Friday,</v>

338
00:25:17.211 --> 00:25:20.480
<v Speaker 1>Sterling Anderson have a company called </v>
<v Speaker 1>Aurora,</v>

339
00:25:20.720 --> 00:25:24.500
<v Speaker 1>a startup.</v>
<v Speaker 1>He was one of the big proponents,</v>

340
00:25:28.160 --> 00:25:33.160
<v Speaker 1>or the I should say,</v>
<v Speaker 1>our opponents of the idea that human </v>

341
00:25:33.160 --> 00:25:38.021
<v Speaker 1>centered autonomy could work.</v>
<v Speaker 1>They tried it publicly,</v>

342
00:25:38.170 --> 00:25:43.170
<v Speaker 1>spoken about the fact that Google,</v>
<v Speaker 1>as in the early self driving car </v>

343
00:25:43.170 --> 00:25:45.110
<v Speaker 1>program,</v>
<v Speaker 1>they've tried shared autonomy.</v>

344
00:25:45.480 --> 00:25:50.480
<v Speaker 1>They've tried l two and it failed </v>
<v Speaker 1>because they're engineers that people </v>

345
00:25:50.480 --> 00:25:55.181
<v Speaker 1>driving their vehicles fell asleep and </v>
<v Speaker 1>that's the belief that people have and </v>

346
00:25:57.321 --> 00:25:59.630
<v Speaker 1>we'll talk about why that may not be </v>
<v Speaker 1>true.</v>

347
00:26:00.110 --> 00:26:05.110
<v Speaker 1>There's a fascinating truth in the way </v>
<v Speaker 1>human beings can interact with </v>

348
00:26:05.110 --> 00:26:08.000
<v Speaker 1>artificial intelligence systems that may</v>
<v Speaker 1>work.</v>

349
00:26:08.090 --> 00:26:10.040
<v Speaker 1>In this case,</v>
<v Speaker 1>as I mentioned,</v>

350
00:26:10.041 --> 00:26:15.041
<v Speaker 1>it's the human robot interaction,</v>
<v Speaker 1>building that deep connection between </v>

351
00:26:15.041 --> 00:26:18.470
<v Speaker 1>human and machine of understanding of </v>
<v Speaker 1>communication.</v>

352
00:26:20.690 --> 00:26:25.690
<v Speaker 1>This is what we believe happens,</v>
<v Speaker 1>so there's a lot of videos like this as </v>

353
00:26:25.690 --> 00:26:26.300
<v Speaker 1>a it's,</v>
<v Speaker 1>it's fun,</v>

354
00:26:26.510 --> 00:26:31.510
<v Speaker 1>but it's also representative of what </v>
<v Speaker 1>what society believes happens when </v>

355
00:26:32.301 --> 00:26:37.301
<v Speaker 1>automation is allowed to enter the human</v>
<v Speaker 1>experience and driving where the human </v>

356
00:26:40.281 --> 00:26:45.281
<v Speaker 1>life is a steak that you can become </v>
<v Speaker 1>completely disengaged.</v>

357
00:26:46.630 --> 00:26:46.890
<v Speaker 2>Hmm.</v>

358
00:26:51.740 --> 00:26:56.740
<v Speaker 1>It's kind of.</v>
<v Speaker 1>It's kind of a natural thing to think,</v>

359
00:26:57.950 --> 00:27:01.550
<v Speaker 1>but the question is,</v>
<v Speaker 1>does this actually happened?</v>

360
00:27:02.270 --> 00:27:07.270
<v Speaker 1>What actually happens on public roads,</v>
<v Speaker 1>the amazing thing that people don't </v>

361
00:27:08.271 --> 00:27:09.410
<v Speaker 1>often talk about</v>

362
00:27:11.940 --> 00:27:16.940
<v Speaker 1>is that there is hundreds of thousands </v>
<v Speaker 1>of vehicles on the road today,</v>

363
00:27:19.800 --> 00:27:23.160
<v Speaker 1>equipped with autopilot,</v>
<v Speaker 1>Tesla,</v>

364
00:27:23.190 --> 00:27:27.450
<v Speaker 1>autopilot that have a significant degree</v>
<v Speaker 1>of autonomy.</v>

365
00:27:28.440 --> 00:27:33.440
<v Speaker 1>That's data,</v>
<v Speaker 1>that's information so we can answer the </v>

366
00:27:33.440 --> 00:27:37.341
<v Speaker 1>question what actually happens.</v>
<v Speaker 1>So many of the people behind this team </v>

367
00:27:37.341 --> 00:27:41.970
<v Speaker 1>of instrumented 25 vehicles,</v>
<v Speaker 1>21 of which are Tesla,</v>

368
00:27:41.971 --> 00:27:46.971
<v Speaker 1>autopilot vehicles now with over </v>
<v Speaker 1>collected recording everything about the</v>

369
00:27:47.071 --> 00:27:49.110
<v Speaker 1>driver,</v>
<v Speaker 1>two cameras to hd,</v>

370
00:27:49.111 --> 00:27:52.670
<v Speaker 1>cameras on the driver,</v>
<v Speaker 1>two cameras on the a one,</v>

371
00:27:52.680 --> 00:27:56.370
<v Speaker 1>the camera on the external roadway and </v>
<v Speaker 1>collecting everything about the car,</v>

372
00:27:56.460 --> 00:27:58.350
<v Speaker 1>including audio,</v>
<v Speaker 1>the state,</v>

373
00:27:58.351 --> 00:28:00.300
<v Speaker 1>the pulling,</v>
<v Speaker 1>everything from the Cambus,</v>

374
00:28:00.540 --> 00:28:03.040
<v Speaker 1>the kinematics of the vehicle,</v>
<v Speaker 1>Imu,</v>

375
00:28:03.120 --> 00:28:08.120
<v Speaker 1>gps,</v>
<v Speaker 1>all of that information over now over </v>

376
00:28:08.120 --> 00:28:08.490
<v Speaker 1>300,000</v>
<v Speaker 1>miles,</v>

377
00:28:08.850 --> 00:28:13.850
<v Speaker 1>over 5 billion video frames.</v>
<v Speaker 1>All as we'll talk about,</v>

378
00:28:14.491 --> 00:28:19.491
<v Speaker 1>analyze the computer vision.</v>
<v Speaker 1>You extract from that video of the </v>

379
00:28:19.491 --> 00:28:22.890
<v Speaker 1>driver of everything they're doing.</v>
<v Speaker 1>That level of distraction,</v>

380
00:28:22.891 --> 00:28:26.610
<v Speaker 1>the allocation of attention,</v>
<v Speaker 1>the drowsiness,</v>

381
00:28:26.640 --> 00:28:29.820
<v Speaker 1>emotional states,</v>
<v Speaker 1>the hands on,</v>

382
00:28:29.821 --> 00:28:32.040
<v Speaker 1>we'll hands off,</v>
<v Speaker 1>we'll body pose,</v>

383
00:28:32.460 --> 00:28:34.770
<v Speaker 1>I activity,</v>
<v Speaker 1>smartphone usage,</v>

384
00:28:34.800 --> 00:28:37.950
<v Speaker 1>all of these factors,</v>
<v Speaker 1>all of these things that you would think</v>

385
00:28:37.951 --> 00:28:42.951
<v Speaker 1>would fall apart when you start letting </v>
<v Speaker 1>autonomy into your life.</v>

386
00:28:42.961 --> 00:28:46.650
<v Speaker 1>We'll talk about what the initial </v>
<v Speaker 1>reality is.</v>

387
00:28:46.830 --> 00:28:49.230
<v Speaker 1>That should be inspiring and thought </v>
<v Speaker 1>provoking,</v>

388
00:28:50.860 --> 00:28:53.080
<v Speaker 1>as I said,</v>
<v Speaker 1>three cameras,</v>

389
00:28:54.100 --> 00:28:59.100
<v Speaker 1>single board computer recording all the </v>
<v Speaker 1>data over a thousand machines in holyoke</v>

390
00:29:00.990 --> 00:29:05.990
<v Speaker 1>and distributed computation,</v>
<v Speaker 1>running the deep learning algorithms </v>

391
00:29:05.990 --> 00:29:10.140
<v Speaker 1>I've had mentioned on these five plus </v>
<v Speaker 1>billion video frames going from the raw </v>

392
00:29:11.091 --> 00:29:14.300
<v Speaker 1>data to the actionable useful </v>
<v Speaker 1>information.</v>

393
00:29:15.570 --> 00:29:17.970
<v Speaker 1>The slides are up online if you'd like </v>
<v Speaker 1>to look through them,</v>

394
00:29:18.540 --> 00:29:23.540
<v Speaker 1>I'll fly through some of them and this </v>
<v Speaker 1>is the video of one of thousands of </v>

395
00:29:25.111 --> 00:29:28.170
<v Speaker 1>trips.</v>
<v Speaker 1>We have an autopilot in our data,</v>

396
00:29:28.560 --> 00:29:33.560
<v Speaker 1>a car driving autonomously,</v>
<v Speaker 1>large fraction of the time on highways </v>

397
00:29:34.290 --> 00:29:37.110
<v Speaker 1>from here to California.</v>
<v Speaker 1>I'm here to Chicago,</v>

398
00:29:37.860 --> 00:29:40.650
<v Speaker 1>to Florida and all across the United </v>
<v Speaker 1>States.</v>

399
00:29:43.840 --> 00:29:48.840
<v Speaker 1>We take that data and using the </v>
<v Speaker 1>supervised learning algorithms,</v>

400
00:29:50.230 --> 00:29:55.230
<v Speaker 1>semi-supervised.</v>
<v Speaker 1>The number of frames here is huge for </v>

401
00:29:55.311 --> 00:30:00.100
<v Speaker 1>those that work in computer vision.</v>
<v Speaker 1>Five billion frames is several orders of</v>

402
00:30:00.350 --> 00:30:05.350
<v Speaker 1>magnitude larger than any data set that </v>
<v Speaker 1>people are working with in computer </v>

403
00:30:05.361 --> 00:30:09.890
<v Speaker 1>vision,</v>
<v Speaker 1>actively annotated,</v>

404
00:30:12.850 --> 00:30:17.850
<v Speaker 1>so we want to use that data for </v>
<v Speaker 1>understanding the behavior of what </v>

405
00:30:17.861 --> 00:30:22.000
<v Speaker 1>people are actually doing in the cars </v>
<v Speaker 1>and we want to train the algorithms,</v>

406
00:30:22.001 --> 00:30:27.001
<v Speaker 1>the do perception and control.</v>
<v Speaker 1>A quick summary over 300,000</v>

407
00:30:27.191 --> 00:30:29.620
<v Speaker 1>miles,</v>
<v Speaker 1>25 vehicles.</v>

408
00:30:29.770 --> 00:30:32.530
<v Speaker 1>The color is a true to the actual colors</v>
<v Speaker 1>of the vehicles,</v>

409
00:30:33.050 --> 00:30:38.050
<v Speaker 1>a little fun fact.</v>
<v Speaker 1>Tesla model x model less and now a model</v>

410
00:30:39.071 --> 00:30:39.490
<v Speaker 1>three,</v>

411
00:30:41.520 --> 00:30:46.290
<v Speaker 1>500,500</v>
<v Speaker 1>plus miles a day and growing.</v>

412
00:30:47.160 --> 00:30:52.160
<v Speaker 1>Now,</v>
<v Speaker 1>most days in 2018 are over a thousand </v>

413
00:30:52.680 --> 00:30:57.150
<v Speaker 1>miles a day.</v>
<v Speaker 1>This is a quick gps map in red is manual</v>

414
00:30:57.151 --> 00:31:02.151
<v Speaker 1>driving across the Boston area and Blue </v>
<v Speaker 1>Cyan is autonomous driving.</v>

415
00:31:02.430 --> 00:31:05.640
<v Speaker 1>This is giving you the sense of just the</v>
<v Speaker 1>scope of this data.</v>

416
00:31:05.910 --> 00:31:10.900
<v Speaker 1>This is a huge number of miles with </v>
<v Speaker 1>automated driving,</v>

417
00:31:11.230 --> 00:31:16.230
<v Speaker 1>several orders of magnitude larger than </v>
<v Speaker 1>what Waymo is doing that what cruises </v>

418
00:31:17.201 --> 00:31:19.060
<v Speaker 1>doing,</v>
<v Speaker 1>what Uber is doing.</v>

419
00:31:24.830 --> 00:31:29.830
<v Speaker 1>The miles driven in this data with </v>
<v Speaker 1>autopilot confirming what are.</v>

420
00:31:32.091 --> 00:31:37.091
<v Speaker 1>Y'All must [inaudible] stated it's 33 </v>
<v Speaker 1>percent of miles driven autonomously.</v>

421
00:31:38.680 --> 00:31:43.680
<v Speaker 1>This is a remarkable number for those of</v>
<v Speaker 1>you who drive and for those of you who </v>

422
00:31:43.811 --> 00:31:47.950
<v Speaker 1>are familiar with these technologies,</v>
<v Speaker 1>that is remarkable adoption rate,</v>

423
00:31:48.310 --> 00:31:51.850
<v Speaker 1>that 33 percent of the miles are driven </v>
<v Speaker 1>in autopilot.</v>

424
00:31:52.120 --> 00:31:56.140
<v Speaker 1>That means these drivers are getting use</v>
<v Speaker 1>out of the system.</v>

425
00:31:56.680 --> 00:31:59.530
<v Speaker 1>It's working for them.</v>
<v Speaker 1>That's an incredible number.</v>

426
00:32:01.830 --> 00:32:06.830
<v Speaker 1>It's also incredible because under the </v>
<v Speaker 1>the decades of literature from aviation </v>

427
00:32:08.790 --> 00:32:13.020
<v Speaker 1>to automation in vehicles to to Chris </v>
<v Speaker 1>Urmson and Waymo,</v>

428
00:32:13.380 --> 00:32:18.380
<v Speaker 1>the belief is such high numbers are </v>
<v Speaker 1>likely to lead to crashes,</v>

429
00:32:19.440 --> 00:32:24.330
<v Speaker 1>two fatalities to at the very least </v>
<v Speaker 1>highly irresponsible behavior.</v>

430
00:32:25.890 --> 00:32:28.800
<v Speaker 1>Drivers overtrusting the systems and </v>
<v Speaker 1>getting in trouble.</v>

431
00:32:29.850 --> 00:32:32.910
<v Speaker 1>We can run the glance classification </v>
<v Speaker 1>algorithms.</v>

432
00:32:33.450 --> 00:32:36.240
<v Speaker 1>Again,</v>
<v Speaker 1>this is for next Wednesday discussion.</v>

433
00:32:36.260 --> 00:32:40.760
<v Speaker 1>The actual algorithm is the algorithm </v>
<v Speaker 1>that tells the region that the driver is</v>

434
00:32:40.761 --> 00:32:43.880
<v Speaker 1>looking at and it's comparing road </v>
<v Speaker 1>instrument cluster,</v>

435
00:32:43.881 --> 00:32:46.490
<v Speaker 1>left rear view center stack,</v>
<v Speaker 1>and right.</v>

436
00:32:46.820 --> 00:32:51.820
<v Speaker 1>Does the allocation of glance change </v>
<v Speaker 1>with autopilot or with manual driving?</v>

437
00:32:54.050 --> 00:32:57.890
<v Speaker 1>It does not appear to have any </v>
<v Speaker 1>significant noticeable way,</v>

438
00:32:58.160 --> 00:33:01.370
<v Speaker 1>meaning you don't start playing chess,</v>
<v Speaker 1>you don't start.</v>

439
00:33:01.400 --> 00:33:06.400
<v Speaker 1>You don't get in the back seat to sleep,</v>
<v Speaker 1>you don't start texting in your smart </v>

440
00:33:07.101 --> 00:33:10.140
<v Speaker 1>phone and watching a movie,</v>
<v Speaker 1>at least in this Dataset,</v>

441
00:33:10.220 --> 00:33:14.360
<v Speaker 1>this promise here for the human centered</v>
<v Speaker 1>approach,</v>

442
00:33:16.250 --> 00:33:21.200
<v Speaker 1>the observation to summarize this </v>
<v Speaker 1>particular data is that people are using</v>

443
00:33:21.201 --> 00:33:26.201
<v Speaker 1>it a lot.</v>
<v Speaker 1>The percentage of miles and percentage </v>

444
00:33:26.201 --> 00:33:28.490
<v Speaker 1>of hours is incredibly high,</v>
<v Speaker 1>at least relative to what was it will be</v>

445
00:33:28.491 --> 00:33:33.080
<v Speaker 1>expected from these systems and given </v>
<v Speaker 1>that there's no crashes,</v>

446
00:33:33.530 --> 00:33:38.530
<v Speaker 1>there's no near crashes in autopilot.</v>
<v Speaker 1>The road type is mostly highway </v>

447
00:33:40.820 --> 00:33:45.820
<v Speaker 1>traveling at high speeds.</v>
<v Speaker 1>The mental engagement looked at</v>

448
00:33:47.880 --> 00:33:52.880
<v Speaker 1>8,000</v>
<v Speaker 1>trestles of control from machine to </v>

449
00:33:52.880 --> 00:33:55.491
<v Speaker 1>human,</v>
<v Speaker 1>so human beings taking control of the </v>

450
00:33:55.491 --> 00:33:55.491
<v Speaker 1>vehicle saying,</v>
<v Speaker 1>you know what?</v>

451
00:33:55.491 --> 00:33:59.990
<v Speaker 1>I'm going to take control now.</v>
<v Speaker 1>I'm not comfortable with the situation </v>

452
00:33:59.990 --> 00:34:02.841
<v Speaker 1>for whatever reason either not </v>
<v Speaker 1>comfortable or electing to do something </v>

453
00:34:02.841 --> 00:34:04.860
<v Speaker 1>that the vehicle is not able to like </v>
<v Speaker 1>turn off the highway,</v>

454
00:34:05.100 --> 00:34:08.520
<v Speaker 1>make a right or left turn stop for a </v>
<v Speaker 1>stop sign.</v>

455
00:34:08.521 --> 00:34:12.210
<v Speaker 1>These kinds of things.</v>
<v Speaker 1>Physical engagement,</v>

456
00:34:12.270 --> 00:34:17.270
<v Speaker 1>as I said,</v>
<v Speaker 1>glance remains the same and what do we </v>

457
00:34:17.270 --> 00:34:21.171
<v Speaker 1>take from this?</v>
<v Speaker 1>It says something that I'd like to </v>

458
00:34:21.171 --> 00:34:21.171
<v Speaker 1>really emphasize this.</v>
<v Speaker 1>We've talked to,</v>

459
00:34:21.171 --> 00:34:25.970
<v Speaker 1>we talk about autonomous vehicles in </v>
<v Speaker 1>this class and the guest speakers who </v>

460
00:34:25.970 --> 00:34:30.291
<v Speaker 1>are all on the other side,</v>
<v Speaker 1>so I'm representing the human center </v>

461
00:34:30.291 --> 00:34:32.670
<v Speaker 1>side.</v>
<v Speaker 1>Most all our speakers are focused on the</v>

462
00:34:32.671 --> 00:34:37.671
<v Speaker 1>full autonomy side because that's the </v>
<v Speaker 1>side roboticist know how to solve.</v>

463
00:34:37.770 --> 00:34:41.190
<v Speaker 1>That's the fascinating algorithm nerd </v>
<v Speaker 1>side,</v>

464
00:34:41.780 --> 00:34:44.100
<v Speaker 1>and that's the side I love as well.</v>

465
00:34:44.360 --> 00:34:49.360
<v Speaker 1>It's just my belief stands that the </v>
<v Speaker 1>solving the perception control problem </v>

466
00:34:49.360 --> 00:34:51.660
<v Speaker 1>is extremely difficult and two,</v>
<v Speaker 1>three decades away.</v>

467
00:34:51.960 --> 00:34:56.960
<v Speaker 1>So in the meantime we have to utilize </v>
<v Speaker 1>the human robot interaction to actually </v>

468
00:34:56.960 --> 00:35:01.761
<v Speaker 1>bring these ai systems onto the road to </v>
<v Speaker 1>successfully operate and the way we do </v>

469
00:35:01.761 --> 00:35:06.411
<v Speaker 1>that counterintuitively is we have to </v>
<v Speaker 1>have.</v>

470
00:35:08.220 --> 00:35:13.020
<v Speaker 1>We have to let the artificial </v>
<v Speaker 1>intelligence systems reveal their flaws.</v>

471
00:35:14.310 --> 00:35:19.200
<v Speaker 1>One of the most endearing things to </v>
<v Speaker 1>human beings can do to each other.</v>

472
00:35:19.230 --> 00:35:23.490
<v Speaker 1>Friends is revealed their flaws to each </v>
<v Speaker 1>other.</v>

473
00:35:24.480 --> 00:35:26.520
<v Speaker 1>Now,</v>
<v Speaker 1>from an automotive perspective,</v>

474
00:35:26.521 --> 00:35:31.521
<v Speaker 1>from a company perspective is perhaps </v>
<v Speaker 1>not appealing for an ai system to reveal</v>

475
00:35:33.971 --> 00:35:38.971
<v Speaker 1>what it sees about the world and would </v>
<v Speaker 1>it doesn't see about the world where it </v>

476
00:35:38.971 --> 00:35:40.530
<v Speaker 1>succeeds and where it fails,</v>

477
00:35:41.930 --> 00:35:45.080
<v Speaker 1>but that is perhaps exactly what it </v>
<v Speaker 1>needs to do.</v>

478
00:35:45.890 --> 00:35:49.700
<v Speaker 1>In the case of autopilot,</v>
<v Speaker 1>the way the very limited,</v>

479
00:35:50.090 --> 00:35:55.090
<v Speaker 1>but I believe successful way it's </v>
<v Speaker 1>currently doing that is allowing you to </v>

480
00:35:55.090 --> 00:35:58.451
<v Speaker 1>use autopilot basically anywhere,</v>
<v Speaker 1>so what people are doing is they're </v>

481
00:35:58.451 --> 00:36:02.291
<v Speaker 1>trying to engage their turn on autopilot</v>
<v Speaker 1>in places where they really shouldn't.</v>

482
00:36:03.560 --> 00:36:08.560
<v Speaker 1>Rural rural roads,</v>
<v Speaker 1>curvy with terrible road markings with a</v>

483
00:36:11.240 --> 00:36:16.240
<v Speaker 1>in heavy rain conditions with snow,</v>
<v Speaker 1>with lots of cars driving at high speeds</v>

484
00:36:17.211 --> 00:36:20.960
<v Speaker 1>all around.</v>
<v Speaker 1>They turn autopilot on to understand,</v>

485
00:36:20.961 --> 00:36:22.820
<v Speaker 1>to experience the limitations of the </v>
<v Speaker 1>system,</v>

486
00:36:23.060 --> 00:36:28.060
<v Speaker 1>to to interact.</v>
<v Speaker 1>That human robot interaction is through </v>

487
00:36:28.800 --> 00:36:33.800
<v Speaker 1>it's tactile.</v>
<v Speaker 1>By turning it on and seeing is it going </v>

488
00:36:33.800 --> 00:36:34.250
<v Speaker 1>to work here?</v>
<v Speaker 1>How's it going to fail?</v>

489
00:36:34.251 --> 00:36:35.990
<v Speaker 1>And the human is always there to catch </v>
<v Speaker 1>it.</v>

490
00:36:36.260 --> 00:36:39.140
<v Speaker 1>That interaction,</v>
<v Speaker 1>that's communication,</v>

491
00:36:39.470 --> 00:36:44.470
<v Speaker 1>that intimate understanding is what </v>
<v Speaker 1>creates successful integration of ai in </v>

492
00:36:44.470 --> 00:36:49.021
<v Speaker 1>the car.</v>
<v Speaker 1>Before we're able to solve the full </v>

493
00:36:49.021 --> 00:36:51.161
<v Speaker 1>autonomy puzzle.</v>
<v Speaker 1>Learn the limitations by exploring it </v>

494
00:36:51.561 --> 00:36:54.920
<v Speaker 1>starts with this guy and hundreds of </v>
<v Speaker 1>others.</v>

495
00:36:55.580 --> 00:36:58.100
<v Speaker 1>If you search on Youtube,</v>
<v Speaker 1>first time with the autopilot,</v>

496
00:36:59.620 --> 00:37:03.160
<v Speaker 1>the amazing experience of direct </v>
<v Speaker 1>transfer,</v>

497
00:37:03.161 --> 00:37:07.870
<v Speaker 1>of control of your life to an artificial</v>
<v Speaker 1>intelligence system in this case,</v>

498
00:37:07.990 --> 00:37:12.990
<v Speaker 1>given control to Tesla autopilot system.</v>
<v Speaker 1>This is why in the human centered camp </v>

499
00:37:13.781 --> 00:37:18.781
<v Speaker 1>of autonomy,</v>
<v Speaker 1>I believe that autonomous vehicles can </v>

500
00:37:18.911 --> 00:37:22.210
<v Speaker 1>be viewed as personal robots with which </v>
<v Speaker 1>you build,</v>

501
00:37:22.240 --> 00:37:26.440
<v Speaker 1>build a relationship or the human robot </v>
<v Speaker 1>interaction is the key problem,</v>

502
00:37:26.770 --> 00:37:28.390
<v Speaker 1>not the perception control</v>

503
00:37:35.560 --> 00:37:40.560
<v Speaker 1>and they're the flaws of both humans and</v>
<v Speaker 1>machines must be clearly communicated </v>

504
00:37:41.801 --> 00:37:46.801
<v Speaker 1>and perceived perceived because he used </v>
<v Speaker 1>the computer vision algorithms to detect</v>

505
00:37:47.531 --> 00:37:52.531
<v Speaker 1>everything about the human and </v>
<v Speaker 1>communicated because on the displays of </v>

506
00:37:52.531 --> 00:37:56.581
<v Speaker 1>the car or even through voice,</v>
<v Speaker 1>it has to be able to reveal when it </v>

507
00:37:56.581 --> 00:38:01.350
<v Speaker 1>doesn't see different aspects of the </v>
<v Speaker 1>scene from the human centered approach,</v>

508
00:38:05.251 --> 00:38:10.251
<v Speaker 1>then we can focus on the left,</v>
<v Speaker 1>the perception and control side.</v>

509
00:38:10.640 --> 00:38:15.640
<v Speaker 1>Perceiving everything about the external</v>
<v Speaker 1>environment and controlling the vehicle </v>

510
00:38:15.640 --> 00:38:17.480
<v Speaker 1>without having to worry about being 99 </v>
<v Speaker 1>point nine,</v>

511
00:38:17.481 --> 00:38:17.930
<v Speaker 1>nine,</v>
<v Speaker 1>nine,</v>

512
00:38:17.980 --> 00:38:19.610
<v Speaker 1>nine,</v>
<v Speaker 1>nine percent correct.</v>

513
00:38:20.360 --> 00:38:25.360
<v Speaker 1>Approaching 100 percent correct because </v>
<v Speaker 1>in the cases where it's extremely </v>

514
00:38:25.360 --> 00:38:28.640
<v Speaker 1>difficult,</v>
<v Speaker 1>we can let the human catch the system,</v>

515
00:38:30.440 --> 00:38:35.090
<v Speaker 1>we can reveal the flaws and let the </v>
<v Speaker 1>human takeover on the system can't.</v>

516
00:38:36.370 --> 00:38:41.370
<v Speaker 1>So let's get to the sensors,</v>
<v Speaker 1>the sources of raw data that we'll get </v>

517
00:38:43.751 --> 00:38:48.751
<v Speaker 1>to work with.</v>
<v Speaker 1>There's three.</v>

518
00:38:50.960 --> 00:38:53.500
<v Speaker 1>There's cameras,</v>
<v Speaker 1>so image sensors,</v>

519
00:38:54.220 --> 00:38:59.160
<v Speaker 1>rgb infrared,</v>
<v Speaker 1>visual data.</v>

520
00:38:59.580 --> 00:39:04.580
<v Speaker 1>There's radar and ultrasonic and there's</v>
<v Speaker 1>lidar.</v>

521
00:39:07.500 --> 00:39:12.240
<v Speaker 1>Let's discuss the strengths first.</v>
<v Speaker 1>Discuss really what these sensors are,</v>

522
00:39:12.270 --> 00:39:17.270
<v Speaker 1>the strength and weaknesses and how they</v>
<v Speaker 1>can be integrated together for sensor </v>

523
00:39:17.761 --> 00:39:22.761
<v Speaker 1>fusion,</v>
<v Speaker 1>so radar is the trust of the old trusted</v>

524
00:39:22.981 --> 00:39:27.981
<v Speaker 1>friend.</v>
<v Speaker 1>The sensor that's commonly available in </v>

525
00:39:27.981 --> 00:39:30.740
<v Speaker 1>most vehicles that have a degree of </v>
<v Speaker 1>autonomy on the left is a visualization </v>

526
00:39:31.651 --> 00:39:36.651
<v Speaker 1>of the kind of data on high resolution </v>
<v Speaker 1>rate or that's able to be extracted.</v>

527
00:39:38.780 --> 00:39:43.780
<v Speaker 1>It's cheap.</v>
<v Speaker 1>Both radar which works with </v>

528
00:39:43.780 --> 00:39:48.280
<v Speaker 1>electromagnetic waves and ultrasonic,</v>
<v Speaker 1>which works with sound waves,</v>

529
00:39:49.790 --> 00:39:52.790
<v Speaker 1>sending a wave,</v>
<v Speaker 1>letting it bounce off the obstacles,</v>

530
00:39:53.420 --> 00:39:58.420
<v Speaker 1>knowing the speed of that wave,</v>
<v Speaker 1>being able to calculate the distance to </v>

531
00:39:58.420 --> 00:40:02.471
<v Speaker 1>the obstacle based on that,</v>
<v Speaker 1>it does extremely well in challenging </v>

532
00:40:05.271 --> 00:40:06.500
<v Speaker 1>weather,</v>
<v Speaker 1>rain,</v>

533
00:40:06.501 --> 00:40:11.501
<v Speaker 1>snow.</v>
<v Speaker 1>The downside is a slow resolution </v>

534
00:40:13.800 --> 00:40:15.690
<v Speaker 1>compared to the other senses we'll </v>
<v Speaker 1>discuss,</v>

535
00:40:16.350 --> 00:40:21.350
<v Speaker 1>but it is the one that's most reliable </v>
<v Speaker 1>and using automotive industry today and </v>

536
00:40:21.350 --> 00:40:23.640
<v Speaker 1>it's the one that's in sense of fusion </v>
<v Speaker 1>is always there.</v>

537
00:40:25.470 --> 00:40:30.470
<v Speaker 1>Lidar visualized on the right.</v>
<v Speaker 1>The downside is it's expensive,</v>

538
00:40:32.970 --> 00:40:37.970
<v Speaker 1>but it produces an extremely accurate </v>
<v Speaker 1>depth information and a high resolution </v>

539
00:40:37.970 --> 00:40:42.651
<v Speaker 1>map of the environment that has 360 </v>
<v Speaker 1>degrees of visibility.</v>

540
00:40:47.270 --> 00:40:52.270
<v Speaker 1>It has some of the big strengths of </v>
<v Speaker 1>radar in terms of reliability,</v>

541
00:40:52.850 --> 00:40:55.310
<v Speaker 1>but with much higher resolution and </v>
<v Speaker 1>accuracy.</v>

542
00:40:56.180 --> 00:41:01.180
<v Speaker 1>The downside is cost.</v>
<v Speaker 1>Here's a quick visualization comparing </v>

543
00:41:02.011 --> 00:41:05.580
<v Speaker 1>the two of the kind of information and </v>
<v Speaker 1>get to work with the.</v>

544
00:41:05.940 --> 00:41:10.940
<v Speaker 1>The density and the quality of </v>
<v Speaker 1>information with Lidar is much higher </v>

545
00:41:13.080 --> 00:41:17.370
<v Speaker 1>and lighter has been the successful </v>
<v Speaker 1>source of ground truth.</v>

546
00:41:17.900 --> 00:41:22.900
<v Speaker 1>The reliable sensor relied upon on </v>
<v Speaker 1>vehicles that don't care about cost</v>

547
00:41:26.400 --> 00:41:31.400
<v Speaker 1>and camera.</v>
<v Speaker 1>The thing that most people here should </v>

548
00:41:31.400 --> 00:41:32.010
<v Speaker 1>be passionate about because machine </v>
<v Speaker 1>learning,</v>

549
00:41:32.250 --> 00:41:37.250
<v Speaker 1>deep learning,</v>
<v Speaker 1>the most ability to have a significant </v>

550
00:41:37.250 --> 00:41:39.170
<v Speaker 1>impact there.</v>
<v Speaker 1>Why versus cheap,</v>

551
00:41:39.260 --> 00:41:42.230
<v Speaker 1>so it's everywhere.</v>
<v Speaker 1>Second is the highest resolution,</v>

552
00:41:42.231 --> 00:41:47.231
<v Speaker 1>so there's the most,</v>
<v Speaker 1>the most highly dense amount of </v>

553
00:41:47.231 --> 00:41:50.381
<v Speaker 1>information,</v>
<v Speaker 1>which means information is something </v>

554
00:41:50.841 --> 00:41:55.841
<v Speaker 1>that can be learned and inferred to </v>
<v Speaker 1>interpret the external scene.</v>

555
00:41:56.430 --> 00:42:01.220
<v Speaker 1>So that's why it's the best source of </v>
<v Speaker 1>data for understanding the scene.</v>

556
00:42:02.090 --> 00:42:07.090
<v Speaker 1>And the other reason it's awesome for </v>
<v Speaker 1>deep learning is because of the hugeness</v>

557
00:42:07.941 --> 00:42:10.790
<v Speaker 1>of data involved,</v>
<v Speaker 1>the,</v>

558
00:42:10.820 --> 00:42:15.820
<v Speaker 1>it's many orders of magnitude more data </v>
<v Speaker 1>available for driving in camera,</v>

559
00:42:16.071 --> 00:42:19.400
<v Speaker 1>visible light or infrared than it is in </v>
<v Speaker 1>Lidar.</v>

560
00:42:21.770 --> 00:42:22.980
<v Speaker 1>Uh,</v>
<v Speaker 1>the.</v>

561
00:42:24.900 --> 00:42:29.040
<v Speaker 1>And our world is designed for visible </v>
<v Speaker 1>light.</v>

562
00:42:29.130 --> 00:42:33.630
<v Speaker 1>Our eyes work in similar ways,</v>
<v Speaker 1>the cameras at least crudely.</v>

563
00:42:33.631 --> 00:42:38.250
<v Speaker 1>So the source data is similar.</v>
<v Speaker 1>The lane markings,</v>

564
00:42:38.580 --> 00:42:41.670
<v Speaker 1>the traffic size of traffic lights,</v>
<v Speaker 1>the other vehicles,</v>

565
00:42:41.990 --> 00:42:46.770
<v Speaker 1>the other pedestrians all operate with </v>
<v Speaker 1>each other in this rgb space.</v>

566
00:42:47.940 --> 00:42:52.940
<v Speaker 1>In terms of visual characteristics,</v>
<v Speaker 1>the downside is cameras are bad at depth</v>

567
00:42:54.061 --> 00:42:59.061
<v Speaker 1>estimation,</v>
<v Speaker 1>it's noisy and difficult even with </v>

568
00:42:59.061 --> 00:43:02.271
<v Speaker 1>stereo vision cameras to estimate depth </v>
<v Speaker 1>relative to lidar and they're not good </v>

569
00:43:03.031 --> 00:43:07.440
<v Speaker 1>and extreme weather and they're not good</v>
<v Speaker 1>at least visible light cameras at night.</v>

570
00:43:10.440 --> 00:43:15.440
<v Speaker 1>So let's compare the ranges.</v>
<v Speaker 1>Here's a plot and meters on the x axis </v>

571
00:43:15.930 --> 00:43:20.930
<v Speaker 1>of the range.</v>
<v Speaker 1>And Acuity on the y axis with ultrasonic</v>

572
00:43:25.740 --> 00:43:30.740
<v Speaker 1>lidar radar and camera passive visual </v>
<v Speaker 1>sensor plotted the range of cameras as </v>

573
00:43:36.091 --> 00:43:41.091
<v Speaker 1>the greatest this is looking at.</v>
<v Speaker 1>We're going to look at several different</v>

574
00:43:41.161 --> 00:43:44.190
<v Speaker 1>conditions.</v>
<v Speaker 1>This is for clear well lit conditions,</v>

575
00:43:44.520 --> 00:43:47.370
<v Speaker 1>so during the day,</v>
<v Speaker 1>no rain,</v>

576
00:43:48.630 --> 00:43:53.630
<v Speaker 1>no fog,</v>
<v Speaker 1>lidar and radar have a smaller range </v>

577
00:43:53.630 --> 00:43:57.441
<v Speaker 1>under 200 meters and ultrasonic sensors </v>
<v Speaker 1>used mostly for park assistance and </v>

578
00:43:57.631 --> 00:44:02.631
<v Speaker 1>these kinds of things.</v>
<v Speaker 1>And blind spot warning has terrible </v>

579
00:44:02.631 --> 00:44:06.531
<v Speaker 1>range,</v>
<v Speaker 1>is designed for extremely close as high </v>

580
00:44:06.531 --> 00:44:10.011
<v Speaker 1>resolution distance estimation for </v>
<v Speaker 1>extremely close distances here,</v>

581
00:44:11.620 --> 00:44:14.960
<v Speaker 1>a little bit small,</v>
<v Speaker 1>but looking at up top is clear.</v>

582
00:44:14.961 --> 00:44:19.961
<v Speaker 1>Well lit conditions the plow would just </v>
<v Speaker 1>looked at and I'm bottom is clear dark </v>

583
00:44:19.961 --> 00:44:21.840
<v Speaker 1>conditions,</v>
<v Speaker 1>so just a clear night day,</v>

584
00:44:22.080 --> 00:44:27.080
<v Speaker 1>no rain but it's night.</v>
<v Speaker 1>And on the bottom right is heavy rain.</v>

585
00:44:27.780 --> 00:44:32.780
<v Speaker 1>Snow or fog.</v>
<v Speaker 1>Vision falls in terms of range and </v>

586
00:44:33.211 --> 00:44:37.980
<v Speaker 1>accuracy under dark conditions and in </v>
<v Speaker 1>rain,</v>

587
00:44:37.981 --> 00:44:42.981
<v Speaker 1>snow or fog radar.</v>
<v Speaker 1>Our old trusted friend stay strong.</v>

588
00:44:44.850 --> 00:44:49.290
<v Speaker 1>The same range just under 200 meters and</v>
<v Speaker 1>at the same acuity,</v>

589
00:44:50.940 --> 00:44:55.920
<v Speaker 1>same with sonar.</v>
<v Speaker 1>Lighter works well at night,</v>

590
00:44:56.700 --> 00:44:59.580
<v Speaker 1>but it does not do well with rain or fog</v>
<v Speaker 1>or snow.</v>

591
00:45:01.750 --> 00:45:06.010
<v Speaker 1>One of the biggest downsides of lighter </v>
<v Speaker 1>other than cost.</v>

592
00:45:06.160 --> 00:45:11.160
<v Speaker 1>So here's another interesting way to </v>
<v Speaker 1>visualize this that I think is </v>

593
00:45:11.160 --> 00:45:13.450
<v Speaker 1>productive far discussion of which </v>
<v Speaker 1>sensor will win out.</v>

594
00:45:14.080 --> 00:45:19.080
<v Speaker 1>Is that the ell musk prediction of </v>
<v Speaker 1>camera or is it the way more prediction </v>

595
00:45:19.480 --> 00:45:24.480
<v Speaker 1>of Lidar for lidar in this kind of plot </v>
<v Speaker 1>that will look for every single sensor,</v>

596
00:45:29.040 --> 00:45:34.040
<v Speaker 1>the greater the radius of the blue,</v>
<v Speaker 1>the more successful that sensor is that </v>

597
00:45:35.191 --> 00:45:40.191
<v Speaker 1>accomplishing that feature with a bunch </v>
<v Speaker 1>of features lined up around the circle,</v>

598
00:45:41.310 --> 00:45:44.070
<v Speaker 1>so range for lighter is pretty good,</v>
<v Speaker 1>not great,</v>

599
00:45:44.071 --> 00:45:47.160
<v Speaker 1>but pretty good.</v>
<v Speaker 1>Resolution is also pretty good.</v>

600
00:45:47.790 --> 00:45:50.700
<v Speaker 1>It works in the dark.</v>
<v Speaker 1>It works in bright light,</v>

601
00:45:53.300 --> 00:45:58.300
<v Speaker 1>but it falls apart in the snow.</v>
<v Speaker 1>It does not provide color information,</v>

602
00:45:59.221 --> 00:46:01.050
<v Speaker 1>texture,</v>
<v Speaker 1>information contrast.</v>

603
00:46:01.770 --> 00:46:04.890
<v Speaker 1>It's able to detect speed,</v>
<v Speaker 1>but the sensor size,</v>

604
00:46:04.950 --> 00:46:07.080
<v Speaker 1>at least to date,</v>
<v Speaker 1>is huge.</v>

605
00:46:07.350 --> 00:46:09.720
<v Speaker 1>The sensor cost,</v>
<v Speaker 1>at least to date,</v>

606
00:46:09.810 --> 00:46:14.810
<v Speaker 1>is extremely expensive and it doesn't do</v>
<v Speaker 1>well in proximity.</v>

607
00:46:15.930 --> 00:46:19.820
<v Speaker 1>We're ultrasonic shines.</v>
<v Speaker 1>Speaking of which,</v>

608
00:46:20.220 --> 00:46:23.330
<v Speaker 1>ultrasonic,</v>
<v Speaker 1>same kind of plot does well in proximity</v>

609
00:46:23.340 --> 00:46:24.890
<v Speaker 1>detection.</v>
<v Speaker 1>It's cheap,</v>

610
00:46:24.891 --> 00:46:28.250
<v Speaker 1>the cheapest sensor or the four and </v>
<v Speaker 1>census size.</v>

611
00:46:28.251 --> 00:46:32.300
<v Speaker 1>You can get it to be tiny.</v>
<v Speaker 1>It works in snow,</v>

612
00:46:32.330 --> 00:46:36.410
<v Speaker 1>fog and rain,</v>
<v Speaker 1>but it's resolution is terrible.</v>

613
00:46:36.470 --> 00:46:41.210
<v Speaker 1>It's range is nonexistent and it's not </v>
<v Speaker 1>able to detect speed.</v>

614
00:46:42.790 --> 00:46:45.820
<v Speaker 1>That's where radar steps up.</v>
<v Speaker 1>It's able to detect speed.</v>

615
00:46:45.880 --> 00:46:49.690
<v Speaker 1>It's also cheap.</v>
<v Speaker 1>It's also small,</v>

616
00:46:51.940 --> 00:46:56.940
<v Speaker 1>but the resolution is very low and it's </v>
<v Speaker 1>just like lidar is not able to provide </v>

617
00:46:56.940 --> 00:46:57.890
<v Speaker 1>texture.</v>
<v Speaker 1>Information,</v>

618
00:46:57.910 --> 00:47:01.060
<v Speaker 1>call information camera.</v>

619
00:47:03.350 --> 00:47:07.130
<v Speaker 1>The sensor costs is cheap.</v>
<v Speaker 1>The sensor size is small,</v>

620
00:47:07.640 --> 00:47:12.170
<v Speaker 1>not good up close proximity.</v>
<v Speaker 1>The range is the longest of all of them.</v>

621
00:47:12.290 --> 00:47:16.730
<v Speaker 1>Resolution is the best of all of them.</v>
<v Speaker 1>It doesn't work in the dark.</v>

622
00:47:17.270 --> 00:47:20.630
<v Speaker 1>It works in bright light,</v>
<v Speaker 1>but not always.</v>

623
00:47:20.840 --> 00:47:25.840
<v Speaker 1>One of the biggest downfalls of cameras </v>
<v Speaker 1>sensors is the sensitivity to lighting </v>

624
00:47:25.840 --> 00:47:27.020
<v Speaker 1>variation.</v>
<v Speaker 1>It works.</v>

625
00:47:27.470 --> 00:47:29.230
<v Speaker 1>It doesn't work in the snow.</v>
<v Speaker 1>Fog,</v>

626
00:47:29.231 --> 00:47:33.340
<v Speaker 1>rain so suffers much like lidar from </v>
<v Speaker 1>that,</v>

627
00:47:33.640 --> 00:47:38.410
<v Speaker 1>but it provides rich,</v>
<v Speaker 1>interesting textural information.</v>

628
00:47:38.620 --> 00:47:42.100
<v Speaker 1>The very kind that deep learning needs </v>
<v Speaker 1>to make sense of this world.</v>

629
00:47:43.780 --> 00:47:48.780
<v Speaker 1>So let's look at the cheap sensors.</v>
<v Speaker 1>Ultrasonic radar and cameras,</v>

630
00:47:52.990 --> 00:47:57.990
<v Speaker 1>which is one approach.</v>
<v Speaker 1>Putting a bunch of those in the car and </v>

631
00:47:57.990 --> 00:48:01.600
<v Speaker 1>fusing them together,</v>
<v Speaker 1>the cost there is low.</v>

632
00:48:02.560 --> 00:48:07.560
<v Speaker 1>One of the nice ways to visualize using </v>
<v Speaker 1>this visualization technique when </v>

633
00:48:07.841 --> 00:48:12.841
<v Speaker 1>they're fused together on the bottom,</v>
<v Speaker 1>it gives you a sense of them working </v>

634
00:48:13.691 --> 00:48:18.691
<v Speaker 1>together to compliment each other's </v>
<v Speaker 1>strengths and the question is where the </v>

635
00:48:22.001 --> 00:48:27.001
<v Speaker 1>camera or lidar will win out for partial</v>
<v Speaker 1>autonomy or full autonomy on the bottom,</v>

636
00:48:29.151 --> 00:48:34.151
<v Speaker 1>showing this kind of visualization for a</v>
<v Speaker 1>lidar sensor and on top showing this </v>

637
00:48:35.511 --> 00:48:40.511
<v Speaker 1>kind of visualization for fused radar,</v>
<v Speaker 1>ultrasonic and camera.</v>

638
00:48:42.860 --> 00:48:47.860
<v Speaker 1>At least under these considerations,</v>
<v Speaker 1>the fusion of the cheap sensors can do </v>

639
00:48:49.311 --> 00:48:50.450
<v Speaker 1>as well as lighter.</v>

640
00:48:51.730 --> 00:48:56.730
<v Speaker 1>Now,</v>
<v Speaker 1>the open question is whether the Lidar </v>

641
00:48:56.730 --> 00:48:57.070
<v Speaker 1>and the future of this technology can </v>
<v Speaker 1>become cheap and it's ranged,</v>

642
00:48:57.071 --> 00:49:02.071
<v Speaker 1>can increase [inaudible].</v>
<v Speaker 1>Then Lidar can win out solid state lidar</v>

643
00:49:02.170 --> 00:49:07.170
<v Speaker 1>and a lot of developments with a lot of </v>
<v Speaker 1>startup ladder companies are promising </v>

644
00:49:07.170 --> 00:49:10.540
<v Speaker 1>to decrease the costs and increase the </v>
<v Speaker 1>range of the sensors,</v>

645
00:49:11.770 --> 00:49:16.770
<v Speaker 1>but for now we plow long dedication on </v>
<v Speaker 1>the camera front.</v>

646
00:49:19.300 --> 00:49:23.020
<v Speaker 1>The annotated driving data grows </v>
<v Speaker 1>exponentially.</v>

647
00:49:24.250 --> 00:49:29.250
<v Speaker 1>More and more people are beginning to </v>
<v Speaker 1>annotate and study the particular </v>

648
00:49:30.281 --> 00:49:35.281
<v Speaker 1>driving perception and control problems </v>
<v Speaker 1>and the very algorithms for the </v>

649
00:49:38.111 --> 00:49:43.111
<v Speaker 1>supervisor and semi-supervised and </v>
<v Speaker 1>generative networks that we use to work </v>

650
00:49:43.111 --> 00:49:47.281
<v Speaker 1>with this data are improving.</v>
<v Speaker 1>So it's a race and of course radar and </v>

651
00:49:47.791 --> 00:49:50.140
<v Speaker 1>ultrasonic.</v>
<v Speaker 1>I was there to help,</v>

652
00:49:51.340 --> 00:49:55.030
<v Speaker 1>so companies that are playing in this </v>
<v Speaker 1>space,</v>

653
00:49:56.320 --> 00:49:58.060
<v Speaker 1>some of them are speaking here</v>

654
00:50:01.360 --> 00:50:06.360
<v Speaker 1>waymo in April 2017.</v>
<v Speaker 1>They exited their testing,</v>

655
00:50:08.470 --> 00:50:13.470
<v Speaker 1>their extensive impressive testing </v>
<v Speaker 1>process and allowed the first rider and </v>

656
00:50:15.281 --> 00:50:20.281
<v Speaker 1>Phoenix public rider in November 2017 </v>
<v Speaker 1>and it's an incredible accomplishment </v>

657
00:50:23.050 --> 00:50:28.050
<v Speaker 1>for our company and for an artificial </v>
<v Speaker 1>intelligence system in November 2017.</v>

658
00:50:28.610 --> 00:50:33.610
<v Speaker 1>No safety driver.</v>
<v Speaker 1>So the car truly achieved full autonomy </v>

659
00:50:33.800 --> 00:50:37.700
<v Speaker 1>and there are a lot of constraints,</v>
<v Speaker 1>but it's full autonomy.</v>

660
00:50:37.880 --> 00:50:42.880
<v Speaker 1>It's a step.</v>
<v Speaker 1>It's an amazing step in the direction </v>

661
00:50:42.880 --> 00:50:45.860
<v Speaker 1>towards full autonomy much sooner than </v>
<v Speaker 1>people would otherwise predict.</v>

662
00:50:46.730 --> 00:50:51.730
<v Speaker 1>And the miles,</v>
<v Speaker 1>4 million miles driven autonomously by </v>

663
00:50:51.730 --> 00:50:55.541
<v Speaker 1>November 2017 and growing quickly </v>
<v Speaker 1>growing in terms of full autonomous </v>

664
00:50:55.881 --> 00:51:00.881
<v Speaker 1>driving,</v>
<v Speaker 1>if I can say so cautiously because most </v>

665
00:51:00.881 --> 00:51:05.480
<v Speaker 1>of those miles have a safety driver.</v>
<v Speaker 1>So I would argue it's not full autonomy,</v>

666
00:51:05.960 --> 00:51:10.220
<v Speaker 1>but however they define full autonomy,</v>
<v Speaker 1>it's 4 million miles driven,</v>

667
00:51:11.060 --> 00:51:16.060
<v Speaker 1>incredible uber in terms of miles second</v>
<v Speaker 1>on that list,</v>

668
00:51:17.000 --> 00:51:22.000
<v Speaker 1>they have driven 2 million miles </v>
<v Speaker 1>autonomy by December of this of last </v>

669
00:51:23.240 --> 00:51:24.410
<v Speaker 1>year,</v>
<v Speaker 1>2017,</v>

670
00:51:26.810 --> 00:51:31.810
<v Speaker 1>the quiet player here in terms of not </v>
<v Speaker 1>making any declarations of being fully </v>

671
00:51:33.811 --> 00:51:37.650
<v Speaker 1>autonomous,</v>
<v Speaker 1>just quietly driving in a human centered</v>

672
00:51:37.651 --> 00:51:42.651
<v Speaker 1>way.</v>
<v Speaker 1>L Two over 1 billion miles in autopilot.</v>

673
00:51:43.890 --> 00:51:48.890
<v Speaker 1>Over 300,000</v>
<v Speaker 1>vehicles today are equipped with </v>

674
00:51:49.171 --> 00:51:54.171
<v Speaker 1>autopilot technology,</v>
<v Speaker 1>with the ability to drive control the </v>

675
00:51:54.171 --> 00:51:57.651
<v Speaker 1>car laterally and longitudinally.</v>
<v Speaker 1>And if anyone believes the CEO of Tesla,</v>

676
00:52:03.480 --> 00:52:08.220
<v Speaker 1>there'll be over 1 million such vehicles</v>
<v Speaker 1>by the end of 2018.</v>

677
00:52:11.440 --> 00:52:16.440
<v Speaker 1>But no matter what,</v>
<v Speaker 1>the 300 thousands and incredible number </v>

678
00:52:16.440 --> 00:52:19.180
<v Speaker 1>and the 1 billion miles is an incredible</v>
<v Speaker 1>number.</v>

679
00:52:20.890 --> 00:52:23.920
<v Speaker 1>Autopilot was first released in </v>
<v Speaker 1>September 2014,</v>

680
00:52:24.100 --> 00:52:29.100
<v Speaker 1>one of the first systems on the road to </v>
<v Speaker 1>do so autopilot.</v>

681
00:52:30.400 --> 00:52:35.400
<v Speaker 1>And I caught myself as one of the </v>
<v Speaker 1>skeptics in October 2016.</v>

682
00:52:36.370 --> 00:52:41.370
<v Speaker 1>Autopilot decided to let go of an </v>
<v Speaker 1>incredible work done by Mobileye.</v>

683
00:52:43.270 --> 00:52:48.170
<v Speaker 1>Now Intel,</v>
<v Speaker 1>we're designing their perception control</v>

684
00:52:48.171 --> 00:52:53.171
<v Speaker 1>system.</v>
<v Speaker 1>They decided to let go of it completely </v>

685
00:52:53.171 --> 00:52:55.511
<v Speaker 1>and start from scratch using mostly deep</v>
<v Speaker 1>learning methods that drive px to system</v>

686
00:52:56.061 --> 00:53:01.061
<v Speaker 1>from Nvidia and eight cameras.</v>
<v Speaker 1>They decided to start from scratch.</v>

687
00:53:03.620 --> 00:53:07.910
<v Speaker 1>That's the kind of boldness,</v>
<v Speaker 1>the kind of risk taking.</v>

688
00:53:07.940 --> 00:53:12.940
<v Speaker 1>They can come with naivety,</v>
<v Speaker 1>but in this case it worked incredible.</v>

689
00:53:16.480 --> 00:53:21.480
<v Speaker 1>A eight system is going to be released </v>
<v Speaker 1>at the end of 2018 and this promising </v>

690
00:53:22.451 --> 00:53:27.451
<v Speaker 1>one of the first vehicles that's </v>
<v Speaker 1>promising what they're calling l and the</v>

691
00:53:27.781 --> 00:53:32.781
<v Speaker 1>definition of l three,</v>
<v Speaker 1>a coordinated Thorston Lionheart,</v>

692
00:53:34.620 --> 00:53:37.110
<v Speaker 1>the head of the automated driving an </v>
<v Speaker 1>Audi,</v>

693
00:53:37.770 --> 00:53:42.770
<v Speaker 1>and Audi is one of the function is </v>
<v Speaker 1>operating as intended if the customer </v>

694
00:53:43.531 --> 00:53:48.531
<v Speaker 1>turns the traffic jam pilot on.</v>
<v Speaker 1>Now this l three system is designed only</v>

695
00:53:49.951 --> 00:53:54.951
<v Speaker 1>for traffic jams,</v>
<v Speaker 1>bumper to bumper traffic under 60 </v>

696
00:53:55.231 --> 00:53:56.370
<v Speaker 1>kilometers an hour.</v>

697
00:53:57.970 --> 00:54:01.750
<v Speaker 1>If the customer turns the traffic jam </v>
<v Speaker 1>pilot on and uses it as intended,</v>

698
00:54:01.870 --> 00:54:05.410
<v Speaker 1>and the car was in control at the time </v>
<v Speaker 1>of the accident,</v>

699
00:54:05.560 --> 00:54:10.560
<v Speaker 1>the driver goes to the insurance company</v>
<v Speaker 1>and the insurance company will </v>

700
00:54:10.560 --> 00:54:12.250
<v Speaker 1>compensate the victims of the accident </v>
<v Speaker 1>and aftermath.</v>

701
00:54:12.580 --> 00:54:15.070
<v Speaker 1>They come to us,</v>
<v Speaker 1>we will pay them.</v>

702
00:54:16.500 --> 00:54:21.500
<v Speaker 1>So that means the car is liable.</v>
<v Speaker 1>The problem is under the definition of </v>

703
00:54:24.061 --> 00:54:25.020
<v Speaker 1>l,</v>
<v Speaker 1>two l three,</v>

704
00:54:25.021 --> 00:54:28.260
<v Speaker 1>perhaps there is some truth to this </v>
<v Speaker 1>being an l three system.</v>

705
00:54:29.700 --> 00:54:34.700
<v Speaker 1>The important thing here is nevertheless</v>
<v Speaker 1>less deeply and fundamentally human </v>

706
00:54:34.700 --> 00:54:39.051
<v Speaker 1>centered because even as you see here in</v>
<v Speaker 1>this demonstration video with a </v>

707
00:54:39.051 --> 00:54:43.351
<v Speaker 1>reporter,</v>
<v Speaker 1>the car for a poorly understood reason,</v>

708
00:54:43.710 --> 00:54:46.080
<v Speaker 1>transfer control to the driver says,</v>
<v Speaker 1>that's it,</v>

709
00:54:46.081 --> 00:54:48.750
<v Speaker 1>I can't.</v>
<v Speaker 1>I can't take care of the situation.</v>

710
00:54:48.930 --> 00:54:49.830
<v Speaker 1>You take control.</v>

711
00:54:50.730 --> 00:54:55.730
<v Speaker 3>How,</v>
<v Speaker 3>how much time do you have in terms of </v>

712
00:54:55.730 --> 00:54:58.140
<v Speaker 3>seconds before you really need to know </v>
<v Speaker 3>to take over?</v>

713
00:54:58.830 --> 00:55:00.810
<v Speaker 3>Well,</v>
<v Speaker 3>this is the new thing about level three.</v>

714
00:55:01.220 --> 00:55:06.120
<v Speaker 3>With level three,</v>
<v Speaker 3>the system allows the driver to give the</v>

715
00:55:06.121 --> 00:55:09.630
<v Speaker 3>prompt to take over vico control again </v>
<v Speaker 3>ahead of time,</v>

716
00:55:09.631 --> 00:55:14.070
<v Speaker 3>which is in this case up to 10 seconds.</v>
<v Speaker 3>Okay,</v>

717
00:55:14.610 --> 00:55:19.230
<v Speaker 3>so if the traffic jam situation clears </v>
<v Speaker 3>up or anything,</v>

718
00:55:19.310 --> 00:55:22.770
<v Speaker 3>she failed her in the system careers,</v>
<v Speaker 3>everything you might think of,</v>

719
00:55:23.130 --> 00:55:28.130
<v Speaker 3>the system still needs to be able to dry</v>
<v Speaker 3>automatically because it's a driver has </v>

720
00:55:28.130 --> 00:55:32.160
<v Speaker 3>this time to take over.</v>
<v Speaker 3>You might ask them,</v>

721
00:55:32.340 --> 00:55:37.340
<v Speaker 3>what is new about this?</v>
<v Speaker 3>So why is he saying this is the first </v>

722
00:55:37.340 --> 00:55:41.870
<v Speaker 3>level three system worldwide on the </v>
<v Speaker 3>market when talking about these levels </v>

723
00:55:42.961 --> 00:55:46.250
<v Speaker 3>of automation,</v>
<v Speaker 3>there's a classification which starts as</v>

724
00:55:46.260 --> 00:55:51.260
<v Speaker 3>low as zero,</v>
<v Speaker 3>which is basically the driver's doing </v>

725
00:55:51.260 --> 00:55:51.260
<v Speaker 3>everything,</v>
<v Speaker 3>there's no assistance,</v>

726
00:55:51.260 --> 00:55:51.330
<v Speaker 3>nothing.</v>

727
00:55:52.390 --> 00:55:57.390
<v Speaker 3>And then it gradually becomes into </v>
<v Speaker 3>partly automation and when we're talking</v>

728
00:55:57.991 --> 00:56:00.650
<v Speaker 3>about these assistants functions like </v>
<v Speaker 3>lay,</v>

729
00:56:00.651 --> 00:56:02.440
<v Speaker 3>keeping a distance,</v>
<v Speaker 3>keeping a,</v>

730
00:56:02.540 --> 00:56:04.950
<v Speaker 3>we're talking about level two assistants</v>
<v Speaker 3>functions,</v>

731
00:56:05.610 --> 00:56:10.610
<v Speaker 3>which is um,</v>
<v Speaker 3>meaning that the driver is obliged to </v>

732
00:56:12.571 --> 00:56:16.920
<v Speaker 3>permanently monitored the traffic </v>
<v Speaker 3>situation to keep the hands on the wheel</v>

733
00:56:17.310 --> 00:56:22.310
<v Speaker 3>even though there's the support and </v>
<v Speaker 3>assistance and to intervene immediately </v>

734
00:56:22.310 --> 00:56:26.990
<v Speaker 3>if anything is not quite right.</v>
<v Speaker 3>So you know that from living assistance </v>

735
00:56:26.990 --> 00:56:31.000
<v Speaker 3>systems when the steering is not </v>
<v Speaker 3>perfectly in the right lane,</v>

736
00:56:31.090 --> 00:56:33.100
<v Speaker 3>you have to intervene and correct </v>
<v Speaker 3>immediately.</v>

737
00:56:33.340 --> 00:56:37.780
<v Speaker 3>And that is the main difference.</v>
<v Speaker 3>Now we gotta take over the crest.</v>

738
00:56:38.050 --> 00:56:39.350
<v Speaker 3>So what,</v>
<v Speaker 3>so let's,</v>

739
00:56:39.470 --> 00:56:40.820
<v Speaker 3>let's talk about what</v>

740
00:56:42.730 --> 00:56:47.730
<v Speaker 1>that means.</v>
<v Speaker 1>This is still a human center system is </v>

741
00:56:47.730 --> 00:56:51.721
<v Speaker 1>still struggles.</v>
<v Speaker 1>It's still must solve the human robot </v>

742
00:56:51.721 --> 00:56:51.721
<v Speaker 1>interaction problem</v>

743
00:56:52.570 --> 00:56:57.570
<v Speaker 1>and there's many others playing in the </v>
<v Speaker 1>space and they on the full autonomy </v>

744
00:56:57.570 --> 00:56:57.570
<v Speaker 1>side,</v>
<v Speaker 1>Waymo,</v>

745
00:56:57.570 --> 00:57:00.190
<v Speaker 1>uber,</v>
<v Speaker 1>GM cruise Yutani.</v>

746
00:57:01.330 --> 00:57:03.880
<v Speaker 1>The CTO,</v>
<v Speaker 1>which we'll speak here on Tuesday,</v>

747
00:57:04.450 --> 00:57:09.450
<v Speaker 1>optimists ride is annuity voyage,</v>
<v Speaker 1>the CEO of which we'll speak here next </v>

748
00:57:12.880 --> 00:57:17.440
<v Speaker 1>Thursday,</v>
<v Speaker 1>and Aurora not listed,</v>

749
00:57:17.610 --> 00:57:20.590
<v Speaker 1>the the founder of which we'll speak </v>
<v Speaker 1>here next Friday,</v>

750
00:57:21.580 --> 00:57:26.580
<v Speaker 1>and the human centered autonomy side.</v>
<v Speaker 1>The reason I am a speaking about us so </v>

751
00:57:27.551 --> 00:57:29.500
<v Speaker 1>much today is we don't have any </v>
<v Speaker 1>speakers.</v>

752
00:57:29.680 --> 00:57:34.680
<v Speaker 1>I'm the speaker.</v>
<v Speaker 1>The Tesla autopilot is for several years</v>

753
00:57:34.811 --> 00:57:39.811
<v Speaker 1>now doing incredible work on that side.</v>
<v Speaker 1>We're also working with Volvo pilot </v>

754
00:57:39.811 --> 00:57:44.140
<v Speaker 1>assist as a lot of different approaches.</v>
<v Speaker 1>They're more conservative.</v>

755
00:57:44.500 --> 00:57:48.310
<v Speaker 1>Interesting.</v>
<v Speaker 1>The audio traffic jam assist,</v>

756
00:57:48.311 --> 00:57:53.311
<v Speaker 1>as I mentioned,</v>
<v Speaker 1>the eight being released at the end of </v>

757
00:57:53.311 --> 00:57:54.310
<v Speaker 1>this year.</v>
<v Speaker 1>I'm the Mercedes drive politest system.</v>

758
00:57:54.311 --> 00:57:59.311
<v Speaker 1>The eclass an interesting vehicle that I</v>
<v Speaker 1>got to drive quite a bit as the Cadillac</v>

759
00:58:00.430 --> 00:58:01.480
<v Speaker 1>Super Cruise.</v>
<v Speaker 1>The ct six,</v>

760
00:58:01.870 --> 00:58:06.870
<v Speaker 1>which is very much constrained </v>
<v Speaker 1>geographically to highway driving and </v>

761
00:58:08.380 --> 00:58:11.050
<v Speaker 1>the loudest.</v>
<v Speaker 1>Proudest of the mall.</v>

762
00:58:11.470 --> 00:58:14.170
<v Speaker 1>George Hotz of the.</v>
<v Speaker 1>I opened pilot.</v>

763
00:58:15.100 --> 00:58:20.100
<v Speaker 1>Let's just leave that there,</v>
<v Speaker 1>so where can ai help?</v>

764
00:58:26.490 --> 00:58:30.240
<v Speaker 1>We'll get into the details of the coming</v>
<v Speaker 1>lectures on each individual component.</v>

765
00:58:30.540 --> 00:58:35.520
<v Speaker 1>I'd like to get some examples.</v>
<v Speaker 1>The key areas,</v>

766
00:58:35.550 --> 00:58:40.550
<v Speaker 1>problem spaces that we can use machine </v>
<v Speaker 1>learning to solve from data is </v>

767
00:58:41.340 --> 00:58:46.340
<v Speaker 1>localization and mapping,</v>
<v Speaker 1>so being able to localize yourself in </v>

768
00:58:46.340 --> 00:58:47.040
<v Speaker 1>the space,</v>
<v Speaker 1>very first question,</v>

769
00:58:47.041 --> 00:58:52.041
<v Speaker 1>that robot and use to answer,</v>
<v Speaker 1>where am I seeing understanding,</v>

770
00:58:52.710 --> 00:58:54.870
<v Speaker 1>taking the scene in and interpreting </v>
<v Speaker 1>that scene,</v>

771
00:58:55.170 --> 00:59:00.170
<v Speaker 1>detecting all the entities in the scene,</v>
<v Speaker 1>detecting the class of those entities in</v>

772
00:59:01.891 --> 00:59:05.700
<v Speaker 1>order to then do movement planning to </v>
<v Speaker 1>move around those entities.</v>

773
00:59:06.210 --> 00:59:09.270
<v Speaker 1>And finally,</v>
<v Speaker 1>driver's state essential element for the</v>

774
00:59:09.271 --> 00:59:12.210
<v Speaker 1>human robot interaction.</v>
<v Speaker 1>Perceive everything about the driver,</v>

775
00:59:12.330 --> 00:59:17.330
<v Speaker 1>everything about the pedestrians and the</v>
<v Speaker 1>cyclists and the cars outside the human </v>

776
00:59:17.330 --> 00:59:21.070
<v Speaker 1>element of those,</v>
<v Speaker 1>the human perception side.</v>

777
00:59:22.040 --> 00:59:23.510
<v Speaker 1>So first the,</v>
<v Speaker 1>where am I?</v>

778
00:59:23.900 --> 00:59:28.900
<v Speaker 1>Visual adometry using cameras sensors,</v>
<v Speaker 1>which is really where,</v>

779
00:59:29.800 --> 00:59:31.870
<v Speaker 1>once again,</v>
<v Speaker 1>deep learning is most,</v>

780
00:59:31.990 --> 00:59:36.990
<v Speaker 1>uh,</v>
<v Speaker 1>the vision sensor is the most amenable </v>

781
00:59:36.990 --> 00:59:40.290
<v Speaker 1>to learning based approaches.</v>
<v Speaker 1>And visual adometry is using camera to </v>

782
00:59:40.290 --> 00:59:45.121
<v Speaker 1>localize yourself.</v>
<v Speaker 1>To answer the where am I question the </v>

783
00:59:45.121 --> 00:59:50.091
<v Speaker 1>traditional approaches slam detect </v>
<v Speaker 1>features in the scene and track them </v>

784
00:59:53.191 --> 00:59:58.191
<v Speaker 1>through time from frame to frame.</v>
<v Speaker 1>And from the movement of those features </v>

785
00:59:58.351 --> 01:00:02.040
<v Speaker 1>are able to estimate a thousands of </v>
<v Speaker 1>features.</v>

786
01:00:02.160 --> 01:00:04.560
<v Speaker 1>Tracking,</v>
<v Speaker 1>estimate the location,</v>

787
01:00:04.830 --> 01:00:08.070
<v Speaker 1>the orientation of the vehicle or the </v>
<v Speaker 1>camera.</v>

788
01:00:11.120 --> 01:00:16.120
<v Speaker 1>Those methods was stereo.</v>
<v Speaker 1>Vision first requires taking two camera </v>

789
01:00:16.120 --> 01:00:21.071
<v Speaker 1>streams on distorting them.</v>
<v Speaker 1>Competing disparity map from the </v>

790
01:00:21.071 --> 01:00:22.700
<v Speaker 1>different perspectives,</v>
<v Speaker 1>the two camera computing,</v>

791
01:00:22.880 --> 01:00:27.020
<v Speaker 1>the matching between the two,</v>
<v Speaker 1>the feature detection,</v>

792
01:00:27.560 --> 01:00:32.560
<v Speaker 1>the sift to fast or any of the methods </v>
<v Speaker 1>of extracting non deep learning methods </v>

793
01:00:32.601 --> 01:00:37.601
<v Speaker 1>of extracting features,</v>
<v Speaker 1>strong detectable features that can be </v>

794
01:00:37.601 --> 01:00:41.861
<v Speaker 1>tracked through from frame to frame,</v>
<v Speaker 1>tracking those features and estimating </v>

795
01:00:41.861 --> 01:00:44.510
<v Speaker 1>the trajectory,</v>
<v Speaker 1>the orientation of the camera.</v>

796
01:00:45.020 --> 01:00:50.020
<v Speaker 1>That's the traditional approach to </v>
<v Speaker 1>visual odometry in the recent years </v>

797
01:00:50.020 --> 01:00:54.571
<v Speaker 1>since 2015,</v>
<v Speaker 1>but most success in the last year has </v>

798
01:00:55.781 --> 01:01:00.781
<v Speaker 1>been the end to end.</v>
<v Speaker 1>Deep learning approaches either Stereo </v>

799
01:01:00.781 --> 01:01:04.500
<v Speaker 1>monocular cameras.</v>
<v Speaker 1>Deep Vo is one of the most successful.</v>

800
01:01:06.250 --> 01:01:11.250
<v Speaker 1>The ntn methods is taken a sequence of </v>
<v Speaker 1>images extracting with a CNN from each </v>

801
01:01:11.321 --> 01:01:14.450
<v Speaker 1>image,</v>
<v Speaker 1>the central features from each image,</v>

802
01:01:14.690 --> 01:01:19.690
<v Speaker 1>and then using rnn recurrent neural </v>
<v Speaker 1>network to track over time the </v>

803
01:01:19.690 --> 01:01:24.131
<v Speaker 1>trajectory,</v>
<v Speaker 1>the pose of the camera image to pose and</v>

804
01:01:25.791 --> 01:01:30.791
<v Speaker 1>to end.</v>
<v Speaker 1>Here's the visualization on a kitty </v>

805
01:01:30.791 --> 01:01:32.960
<v Speaker 1>dataset using DPO.</v>
<v Speaker 1>Again,</v>

806
01:01:32.961 --> 01:01:37.550
<v Speaker 1>taking the video up on the top right as </v>
<v Speaker 1>an input and estimating,</v>

807
01:01:37.551 --> 01:01:42.551
<v Speaker 1>what's visualized is the position of the</v>
<v Speaker 1>vehicle in red is the estimate based </v>

808
01:01:45.140 --> 01:01:50.140
<v Speaker 1>again end to end with a CNN and rnn.</v>
<v Speaker 1>The in red is the estimate in blue is </v>

809
01:01:51.741 --> 01:01:53.810
<v Speaker 1>the ground truth in the Kitty Dataset,</v>

810
01:01:55.750 --> 01:01:59.410
<v Speaker 1>so this removes a lot of the modular </v>
<v Speaker 1>parts of Slam,</v>

811
01:02:00.330 --> 01:02:04.180
<v Speaker 1>a visual adometry and allows it to be </v>
<v Speaker 1>end to end,</v>

812
01:02:04.570 --> 01:02:07.900
<v Speaker 1>which means it's learnable,</v>
<v Speaker 1>which means it gets better with data.</v>

813
01:02:09.280 --> 01:02:10.090
<v Speaker 1>That's huge</v>

814
01:02:11.590 --> 01:02:16.590
<v Speaker 1>and that's vision alone.</v>
<v Speaker 1>This is one of the exciting </v>

815
01:02:16.590 --> 01:02:20.191
<v Speaker 1>opportunities for ai or people working </v>
<v Speaker 1>in ai is the ability to use a single </v>

816
01:02:22.441 --> 01:02:27.441
<v Speaker 1>sensor and perhaps the most inspiring </v>
<v Speaker 1>because that sensor is similar to our </v>

817
01:02:27.441 --> 01:02:32.271
<v Speaker 1>own the sensor that we ourselves use of </v>
<v Speaker 1>our eyes to use that alone as the </v>

818
01:02:34.531 --> 01:02:39.330
<v Speaker 1>primary sensor to control a vehicle.</v>
<v Speaker 1>That's really exciting and the fact that</v>

819
01:02:39.331 --> 01:02:44.331
<v Speaker 1>deep learning that the vision visible </v>
<v Speaker 1>light is the most amenable to deep </v>

820
01:02:44.331 --> 01:02:48.771
<v Speaker 1>learning approaches makes this </v>
<v Speaker 1>particular an exciting area for deep </v>

821
01:02:48.771 --> 01:02:50.880
<v Speaker 1>learning research seen understanding of </v>
<v Speaker 1>course,</v>

822
01:02:51.150 --> 01:02:53.940
<v Speaker 1>who can do a thousand slides on this?</v>
<v Speaker 1>Traditionally,</v>

823
01:02:53.970 --> 01:02:55.820
<v Speaker 1>object detection,</v>
<v Speaker 1>pedestrians,</v>

824
01:02:55.830 --> 01:03:00.830
<v Speaker 1>vehicles,</v>
<v Speaker 1>there is a bunch of different types of </v>

825
01:03:00.830 --> 01:03:03.600
<v Speaker 1>classifiers and feature extraction is </v>
<v Speaker 1>hard like features and deep learning has</v>

826
01:03:03.660 --> 01:03:07.950
<v Speaker 1>basically taken over and dominate every </v>
<v Speaker 1>aspect of scene,</v>

827
01:03:07.951 --> 01:03:10.140
<v Speaker 1>interpretation,</v>
<v Speaker 1>perception,</v>

828
01:03:10.260 --> 01:03:12.030
<v Speaker 1>understanding,</v>
<v Speaker 1>tracking,</v>

829
01:03:12.540 --> 01:03:13.830
<v Speaker 1>recognition,</v>
<v Speaker 1>classification,</v>

830
01:03:13.831 --> 01:03:14.940
<v Speaker 1>detection problems</v>

831
01:03:15.820 --> 01:03:20.820
<v Speaker 4>and audio.</v>
<v Speaker 4>Can't forget audio that we can use audio</v>

832
01:03:23.360 --> 01:03:28.360
<v Speaker 4>as source of information,</v>
<v Speaker 4>whether that's detecting honks or in </v>

833
01:03:28.360 --> 01:03:31.751
<v Speaker 4>this case using the audio of the tires,</v>
<v Speaker 4>microphones on the tires to determine,</v>

834
01:03:32.601 --> 01:03:37.601
<v Speaker 4>visualize.</v>
<v Speaker 4>There's a spectrogram of the audio </v>

835
01:03:37.601 --> 01:03:39.671
<v Speaker 4>coming in.</v>
<v Speaker 4>For those of you who are particularly </v>

836
01:03:42.380 --> 01:03:47.380
<v Speaker 4>have a particularly tuned ear,</v>
<v Speaker 4>can listen to the different audio coming</v>

837
01:03:48.021 --> 01:03:53.021
<v Speaker 4>in here of wet road and drive road after</v>
<v Speaker 4>the rain so there's no rain,</v>

838
01:03:54.421 --> 01:03:59.421
<v Speaker 4>but the road is nevertheless wet and </v>
<v Speaker 4>detecting that as extremely important </v>

839
01:03:59.421 --> 01:04:01.110
<v Speaker 4>for vehicles because they still don't </v>
<v Speaker 4>have traction.</v>

840
01:04:01.111 --> 01:04:06.030
<v Speaker 4>Control is that have poor control in </v>
<v Speaker 4>road to road surface,</v>

841
01:04:06.120 --> 01:04:11.120
<v Speaker 4>tired road surface connection,</v>
<v Speaker 4>and being able to detect that from just </v>

842
01:04:11.120 --> 01:04:11.970
<v Speaker 4>audio is a very interesting approach.</v>

843
01:04:15.490 --> 01:04:17.200
<v Speaker 1>Finally or not.</v>
<v Speaker 1>Finally,</v>

844
01:04:17.201 --> 01:04:21.520
<v Speaker 1>next for the perception control side.</v>
<v Speaker 1>Finally is the movement planning.</v>

845
01:04:21.550 --> 01:04:24.250
<v Speaker 1>Getting from a to point b from point a </v>
<v Speaker 1>to point b.</v>

846
01:04:24.550 --> 01:04:28.870
<v Speaker 1>traditional approaches,</v>
<v Speaker 1>the optimization based approach,</v>

847
01:04:29.400 --> 01:04:33.400
<v Speaker 1>determine the optimal control,</v>
<v Speaker 1>try to reduce the problem,</v>

848
01:04:33.430 --> 01:04:38.430
<v Speaker 1>formalize the problem in a way that's </v>
<v Speaker 1>amenable to optimization based </v>

849
01:04:38.531 --> 01:04:43.531
<v Speaker 1>approaches.</v>
<v Speaker 1>There's a lot of assumptions that need </v>

850
01:04:43.531 --> 01:04:45.940
<v Speaker 1>to be made.</v>
<v Speaker 1>Once those assumptions are made,</v>

851
01:04:46.000 --> 01:04:51.000
<v Speaker 1>you're able to determine to generate </v>
<v Speaker 1>thousands or millions of possible </v>

852
01:04:51.551 --> 01:04:56.551
<v Speaker 1>trajectories and have an objective </v>
<v Speaker 1>function would determine which of the </v>

853
01:04:56.551 --> 01:04:58.510
<v Speaker 1>trajectories to take.</v>
<v Speaker 1>Here's a race car optimizing how to take</v>

854
01:04:58.690 --> 01:05:00.340
<v Speaker 1>a turn at high speed</v>

855
01:05:02.860 --> 01:05:07.860
<v Speaker 4>learning reinforcement,</v>
<v Speaker 4>learning the application you'll know or </v>

856
01:05:08.981 --> 01:05:13.981
<v Speaker 4>it's three enforcement learning is </v>
<v Speaker 4>particularly exciting for both the </v>

857
01:05:13.981 --> 01:05:18.601
<v Speaker 4>control and the planning side,</v>
<v Speaker 4>so that's where the two of the </v>

858
01:05:20.591 --> 01:05:22.810
<v Speaker 4>competitions were doing in this class </v>
<v Speaker 4>coming into play,</v>

859
01:05:23.740 --> 01:05:28.740
<v Speaker 4>the simplistic two dimensional world of </v>
<v Speaker 4>deep traffic and the high high speed </v>

860
01:05:30.431 --> 01:05:35.431
<v Speaker 4>moving.</v>
<v Speaker 4>I risked world of deep crash.</v>

861
01:05:38.740 --> 01:05:40.240
<v Speaker 4>We'll explore those tomorrow.</v>

862
01:05:42.550 --> 01:05:47.550
<v Speaker 1>Tomorrow's lecture is on deeper </v>
<v Speaker 1>enforcement learning and finally </v>

863
01:05:47.550 --> 01:05:51.901
<v Speaker 1>driver's state detecting everything </v>
<v Speaker 1>about the driver and then interacting </v>

864
01:05:52.001 --> 01:05:57.001
<v Speaker 1>with them.</v>
<v Speaker 1>On the left in green are the easier </v>

865
01:05:57.001 --> 01:05:58.750
<v Speaker 1>problems on the right in red are the </v>
<v Speaker 1>harder problems in terms of perception,</v>

866
01:05:58.751 --> 01:06:02.350
<v Speaker 1>in terms of how amenable they are to </v>
<v Speaker 1>deep learning methods.</v>

867
01:06:02.830 --> 01:06:07.830
<v Speaker 1>Body pose estimation is a very well </v>
<v Speaker 1>studied problem.</v>

868
01:06:08.470 --> 01:06:11.710
<v Speaker 1>We have extremely good detectors for </v>
<v Speaker 1>estimating the pose,</v>

869
01:06:12.130 --> 01:06:13.600
<v Speaker 1>the hands,</v>
<v Speaker 1>the elbows,</v>

870
01:06:13.601 --> 01:06:15.490
<v Speaker 1>the shoulders,</v>
<v Speaker 1>every aspect,</v>

871
01:06:15.580 --> 01:06:18.640
<v Speaker 1>visible aspect of the body.</v>
<v Speaker 1>Head pose,</v>

872
01:06:18.820 --> 01:06:22.240
<v Speaker 1>the orientation of the head or extremely</v>
<v Speaker 1>good at that,</v>

873
01:06:22.930 --> 01:06:25.750
<v Speaker 1>and as we get smaller and smaller in </v>
<v Speaker 1>terms of size,</v>

874
01:06:25.930 --> 01:06:28.420
<v Speaker 1>blink rate,</v>
<v Speaker 1>blink duration,</v>

875
01:06:28.870 --> 01:06:32.530
<v Speaker 1>Ipos and bling dynamics start getting </v>
<v Speaker 1>more and more difficult.</v>

876
01:06:32.980 --> 01:06:36.550
<v Speaker 1>All of these metrics,</v>
<v Speaker 1>all of these metrics extremely important</v>

877
01:06:36.551 --> 01:06:41.551
<v Speaker 1>for detecting things like drowsiness or </v>
<v Speaker 1>as components of detecting emotion or </v>

878
01:06:41.551 --> 01:06:46.070
<v Speaker 1>where people are looking and driving </v>
<v Speaker 1>where your head is turned is not </v>

879
01:06:46.241 --> 01:06:50.500
<v Speaker 1>necessarily where you're looking in </v>
<v Speaker 1>regular life.</v>

880
01:06:51.820 --> 01:06:54.190
<v Speaker 1>Non-Driving life.</v>
<v Speaker 1>When you look somewhere,</v>

881
01:06:54.191 --> 01:06:59.191
<v Speaker 1>you usually turn your head to look with </v>
<v Speaker 1>your eyes in driving your head office.</v>

882
01:07:02.141 --> 01:07:05.770
<v Speaker 1>They still or moves very subtly.</v>
<v Speaker 1>Your eyes do a lot more moving.</v>

883
01:07:06.520 --> 01:07:11.140
<v Speaker 1>It's the kind of a effect it would </v>
<v Speaker 1>described as the lizard owl effect.</v>

884
01:07:12.130 --> 01:07:15.130
<v Speaker 1>Some fraction of people,</v>
<v Speaker 1>a small fraction are owls,</v>

885
01:07:15.550 --> 01:07:19.870
<v Speaker 1>meaning they move their head a lot and </v>
<v Speaker 1>some people,</v>

886
01:07:19.900 --> 01:07:23.950
<v Speaker 1>most people are lizards moving eyes to </v>
<v Speaker 1>allocate their attention.</v>

887
01:07:24.520 --> 01:07:27.820
<v Speaker 1>The problem with eyes is from the </v>
<v Speaker 1>computer vision perspective,</v>

888
01:07:27.821 --> 01:07:32.821
<v Speaker 1>they're much harder to detect in </v>
<v Speaker 1>lighting variation in the real world </v>

889
01:07:32.821 --> 01:07:33.760
<v Speaker 1>conditions,</v>
<v Speaker 1>they get harder and we'll discuss how to</v>

890
01:07:33.761 --> 01:07:35.830
<v Speaker 1>deal with it.</v>
<v Speaker 1>Of course,</v>

891
01:07:35.980 --> 01:07:39.070
<v Speaker 1>that's where deep learning steps up and </v>
<v Speaker 1>really helps with real world data.</v>

892
01:07:40.450 --> 01:07:45.450
<v Speaker 1>Cognitive load.</v>
<v Speaker 1>We'll discuss as well as the meeting of </v>

893
01:07:45.450 --> 01:07:46.330
<v Speaker 1>the cognitive load of the driver to </v>
<v Speaker 1>give.</v>

894
01:07:46.331 --> 01:07:51.331
<v Speaker 1>A quick clip is this is the driver </v>
<v Speaker 1>glance I've seen before estimating the </v>

895
01:07:51.331 --> 01:07:56.011
<v Speaker 1>very most important problem on driver </v>
<v Speaker 1>state side is determining whether </v>

896
01:07:59.261 --> 01:08:01.420
<v Speaker 1>they're looking on road or off road.</v>

897
01:08:02.080 --> 01:08:03.700
<v Speaker 1>It's the dumbest,</v>
<v Speaker 1>simplest,</v>

898
01:08:03.820 --> 01:08:07.390
<v Speaker 1>but most important aspect.</v>
<v Speaker 1>Are they looking at are they in the seat</v>

899
01:08:07.420 --> 01:08:12.420
<v Speaker 1>and looking on the road or are they not?</v>
<v Speaker 1>That's driver glance classification.</v>

900
01:08:14.200 --> 01:08:17.990
<v Speaker 1>Not estimating the Xyz geometric </v>
<v Speaker 1>orientation where they're looking,</v>

901
01:08:18.290 --> 01:08:23.290
<v Speaker 1>but actually binary class classification</v>
<v Speaker 1>on road or off road body pose </v>

902
01:08:24.051 --> 01:08:28.820
<v Speaker 1>estimation,</v>
<v Speaker 1>determining of the hands on wheel or not</v>

903
01:08:28.880 --> 01:08:33.880
<v Speaker 1>determining if the body alignment is </v>
<v Speaker 1>standard is good for seatbelt,</v>

904
01:08:34.370 --> 01:08:39.370
<v Speaker 1>for safety.</v>
<v Speaker 1>This is one of the important things for </v>

905
01:08:39.370 --> 01:08:42.461
<v Speaker 1>autonomous vehicles.</v>
<v Speaker 1>If there's an imminent danger to the </v>

906
01:08:42.461 --> 01:08:45.581
<v Speaker 1>driver,</v>
<v Speaker 1>the driver should be asked to return to </v>

907
01:08:45.581 --> 01:08:48.440
<v Speaker 1>a position that is safe for them in a in</v>
<v Speaker 1>case of a crash driver.</v>

908
01:08:48.441 --> 01:08:49.190
<v Speaker 1>Emotion</v>

909
01:08:53.690 --> 01:08:58.280
<v Speaker 1>on the top is a satisfied on the bottom </v>
<v Speaker 1>as a frustrated driver,</v>

910
01:08:58.850 --> 01:09:02.360
<v Speaker 1>they self report as satisfied.</v>
<v Speaker 1>This is what the voice based navigation.</v>

911
01:09:02.361 --> 01:09:06.280
<v Speaker 1>One of the biggest sources of </v>
<v Speaker 1>frustrations for people in cars is voice</v>

912
01:09:06.281 --> 01:09:11.281
<v Speaker 1>based navigation.</v>
<v Speaker 1>Trying to tell an artificial </v>

913
01:09:11.281 --> 01:09:12.710
<v Speaker 1>intelligence system using your voice </v>
<v Speaker 1>alone where you would like to go.</v>

914
01:09:13.580 --> 01:09:18.580
<v Speaker 1>Huge source of frustration.</v>
<v Speaker 1>One of the interesting things in our </v>

915
01:09:18.580 --> 01:09:22.721
<v Speaker 1>large data set that we have from the </v>
<v Speaker 1>effective computing perspective is </v>

916
01:09:22.721 --> 01:09:26.831
<v Speaker 1>determining which of the features are </v>
<v Speaker 1>most commonly associated with frustrated</v>

917
01:09:26.900 --> 01:09:29.930
<v Speaker 1>voice based interaction,</v>
<v Speaker 1>and that's a smile is shown.</v>

918
01:09:29.931 --> 01:09:34.931
<v Speaker 1>There is the counterintuitive notion </v>
<v Speaker 1>that emotion in particular emotion and </v>

919
01:09:35.541 --> 01:09:40.541
<v Speaker 1>the car is very context dependent,</v>
<v Speaker 1>that smiling is not necessarily a sign </v>

920
01:09:40.541 --> 01:09:44.811
<v Speaker 1>of happiness and the stoic board look of</v>
<v Speaker 1>the driver up top is not necessarily a </v>

921
01:09:48.860 --> 01:09:53.860
<v Speaker 1>reflection of unhappiness is indeed a 10</v>
<v Speaker 1>out of 10 in terms of satisfaction with </v>

922
01:09:55.671 --> 01:10:00.671
<v Speaker 1>the experience if he has ever been </v>
<v Speaker 1>satisfied with anything happens to be </v>

923
01:10:03.471 --> 01:10:08.471
<v Speaker 1>Dan Brown,</v>
<v Speaker 1>one of the amazing engineers in our </v>

924
01:10:08.471 --> 01:10:10.841
<v Speaker 1>team,</v>
<v Speaker 1>cognitive load estimating from the eye </v>

925
01:10:10.841 --> 01:10:14.741
<v Speaker 1>region and sequences of images and three</v>
<v Speaker 1>d convolutional neural networks taking </v>

926
01:10:15.321 --> 01:10:19.070
<v Speaker 1>in a sequence of images from the eye,</v>
<v Speaker 1>looking at the blink dynamics in the eye</v>

927
01:10:19.100 --> 01:10:22.790
<v Speaker 1>position to determine the cognitive load</v>
<v Speaker 1>from zero to two,</v>

928
01:10:23.240 --> 01:10:24.590
<v Speaker 1>how deep thought you are.</v>

929
01:10:25.460 --> 01:10:28.940
<v Speaker 1>Two paths to autonomous future.</v>
<v Speaker 1>Again,</v>

930
01:10:29.930 --> 01:10:34.930
<v Speaker 1>I would like to maybe for the last time,</v>
<v Speaker 1>but probably not argue for the one on </v>

931
01:10:36.771 --> 01:10:40.340
<v Speaker 1>the left because our brilliant much </v>
<v Speaker 1>smarter than me.</v>

932
01:10:40.520 --> 01:10:43.010
<v Speaker 1>Guest speakers will argue for the one on</v>
<v Speaker 1>the right.</v>

933
01:10:44.780 --> 01:10:49.780
<v Speaker 1>The human centered approach allows us to</v>
<v Speaker 1>solve the problems in 99 percent </v>

934
01:10:49.780 --> 01:10:51.200
<v Speaker 1>accuracy of localization,</v>
<v Speaker 1>seen understanding,</v>

935
01:10:51.201 --> 01:10:56.201
<v Speaker 1>movement planning.</v>
<v Speaker 1>Those are the problems we're taking on </v>

936
01:10:56.201 --> 01:10:58.690
<v Speaker 1>this class.</v>
<v Speaker 1>The scene segmentation and we'll talk </v>

937
01:10:58.690 --> 01:11:01.031
<v Speaker 1>about on Thursday the control that we'll</v>
<v Speaker 1>talk about tomorrow and then drive our </v>

938
01:11:01.031 --> 01:11:02.600
<v Speaker 1>state that we'll talk about next </v>
<v Speaker 1>Wednesday.</v>

939
01:11:02.750 --> 01:11:06.320
<v Speaker 1>These problems can be solved with deep </v>
<v Speaker 1>learning today.</v>

940
01:11:06.920 --> 01:11:11.920
<v Speaker 1>The problems in the right,</v>
<v Speaker 1>solving them to close to 100 percent </v>

941
01:11:11.920 --> 01:11:13.190
<v Speaker 1>accuracy are extremely difficult and </v>
<v Speaker 1>maybe decades away.</v>

942
01:11:13.770 --> 01:11:18.770
<v Speaker 1>Because for full autonomy to be here,</v>
<v Speaker 1>we have to solve this situation.</v>

943
01:11:20.580 --> 01:11:22.620
<v Speaker 1>I've shown this many times octet </v>
<v Speaker 1>triomphe.</v>

944
01:11:23.220 --> 01:11:28.220
<v Speaker 1>We have to solve this situation.</v>
<v Speaker 1>I give you just a few examples.</v>

945
01:11:33.450 --> 01:11:37.110
<v Speaker 1>What do you do have to solve this </v>
<v Speaker 1>situation?</v>

946
01:11:44.790 --> 01:11:49.790
<v Speaker 1>I sorta subtler situation here is a,</v>
<v Speaker 1>is it busy crosswalk where no autonomous</v>

947
01:11:53.281 --> 01:11:58.281
<v Speaker 1>vehicle will ever have a hope of getting</v>
<v Speaker 1>through unless it asserts itself and I,</v>

948
01:11:58.640 --> 01:12:03.640
<v Speaker 1>there's a couple of vehicles here that </v>
<v Speaker 1>kind of nudged ourselves through or at </v>

949
01:12:03.640 --> 01:12:06.240
<v Speaker 1>least when they have the right of way.</v>
<v Speaker 1>Don't necessarily nudge,</v>

950
01:12:06.360 --> 01:12:08.670
<v Speaker 1>but don't hesitate when a pedestrian is </v>
<v Speaker 1>present.</v>

951
01:12:08.850 --> 01:12:13.770
<v Speaker 1>An ambulance flying by,</v>
<v Speaker 1>even though if you use a trajectory.</v>

952
01:12:13.771 --> 01:12:18.720
<v Speaker 1>So as a pedestrian and intent modeling </v>
<v Speaker 1>algorithm to predict the momentum of the</v>

953
01:12:18.721 --> 01:12:20.370
<v Speaker 1>pedestrian,</v>
<v Speaker 1>uh,</v>

954
01:12:20.371 --> 01:12:25.080
<v Speaker 1>to estimate where they can possibly go,</v>
<v Speaker 1>you would then Thomas vehicle will stop.</v>

955
01:12:25.290 --> 01:12:27.780
<v Speaker 1>But these vehicles don't stop.</v>
<v Speaker 1>They assert themselves,</v>

956
01:12:27.781 --> 01:12:32.781
<v Speaker 1>they move forward.</v>
<v Speaker 1>Now for full autonomy system,</v>

957
01:12:35.920 --> 01:12:38.110
<v Speaker 1>this may not be the last time I showed </v>
<v Speaker 1>this video,</v>

958
01:12:40.030 --> 01:12:45.030
<v Speaker 1>but because it's taking full control,</v>
<v Speaker 1>it's following a reward,</v>

959
01:12:45.101 --> 01:12:49.000
<v Speaker 1>function and objective function and all </v>
<v Speaker 1>of the problems,</v>

960
01:12:49.001 --> 01:12:52.930
<v Speaker 1>the ethical and the ai problems that </v>
<v Speaker 1>arise,</v>

961
01:12:53.560 --> 01:12:57.190
<v Speaker 1>like this close runner problem will </v>
<v Speaker 1>arise.</v>

962
01:12:57.880 --> 01:13:02.880
<v Speaker 1>So we have to solve those problems.</v>
<v Speaker 1>We have to design that objective </v>

963
01:13:02.880 --> 01:13:04.470
<v Speaker 1>function.</v>
<v Speaker 1>So with that,</v>

964
01:13:05.010 --> 01:13:10.010
<v Speaker 1>I'd like to thank you and encourage you </v>
<v Speaker 1>to come tomorrow because you get a </v>

965
01:13:10.351 --> 01:13:14.400
<v Speaker 1>chance to participate in deep traffic,</v>
<v Speaker 1>deep reinforcement learning competition.</v>

966
01:13:14.580 --> 01:13:15.300
<v Speaker 1>Thank you very much.</v>

