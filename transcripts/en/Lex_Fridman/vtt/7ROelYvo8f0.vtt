WEBVTT

1
00:00:00.180 --> 00:00:05.040
<v Speaker 1>Today we have Josh Tenenbaum,</v>
<v Speaker 1>he's a professor here at mit leading the</v>

2
00:00:05.070 --> 00:00:10.070
<v Speaker 1>computational cognitive science group </v>
<v Speaker 1>among many other topics and cognition </v>

3
00:00:10.070 --> 00:00:14.901
<v Speaker 1>and intelligence.</v>
<v Speaker 1>He is fascinated with the question of </v>

4
00:00:14.901 --> 00:00:17.781
<v Speaker 1>how human beings learn so much from so </v>
<v Speaker 1>little and how these insights can lead </v>

5
00:00:18.511 --> 00:00:21.780
<v Speaker 1>to build ai systems that are much more </v>
<v Speaker 1>efficient learning from data.</v>

6
00:00:22.410 --> 00:00:24.780
<v Speaker 1>So please give Josh a warm welcome.</v>

7
00:00:28.760 --> 00:00:31.370
<v Speaker 2>Thank you.</v>

8
00:00:31.640 --> 00:00:33.230
<v Speaker 1>All right.</v>
<v Speaker 1>Thank you very much.</v>

9
00:00:34.190 --> 00:00:39.190
<v Speaker 1>Thanks for having me.</v>
<v Speaker 1>Excited to be part of what looks like </v>

10
00:00:39.190 --> 00:00:41.060
<v Speaker 1>really quite a very impressive lineup,</v>
<v Speaker 1>especially starting after today and it's</v>

11
00:00:41.120 --> 00:00:46.120
<v Speaker 1>I think quite a great opportunity to get</v>
<v Speaker 1>to see perspectives on artificial </v>

12
00:00:46.120 --> 00:00:50.801
<v Speaker 1>intelligence from many of the leaders in</v>
<v Speaker 1>industry and other entities working on </v>

13
00:00:50.961 --> 00:00:55.961
<v Speaker 1>this great quest.</v>
<v Speaker 1>So I'm going to talk to you about some </v>

14
00:00:55.961 --> 00:01:00.011
<v Speaker 1>of the work that we do in our group,</v>
<v Speaker 1>but also I'm going to try to give a </v>

15
00:01:00.011 --> 00:01:00.950
<v Speaker 1>broader perspective,</v>
<v Speaker 1>reflective of a number of mit faculty,</v>

16
00:01:01.100 --> 00:01:03.950
<v Speaker 1>especially those who are affiliated with</v>
<v Speaker 1>the center for brains,</v>

17
00:01:03.951 --> 00:01:08.951
<v Speaker 1>minds and machines.</v>
<v Speaker 1>So you can see up there on my </v>

18
00:01:08.951 --> 00:01:10.751
<v Speaker 1>affiliation academically,</v>
<v Speaker 1>I'm part of brain and cognitive science </v>

19
00:01:10.751 --> 00:01:11.990
<v Speaker 1>or course nine.</v>
<v Speaker 1>I'm also part of resale,</v>

20
00:01:12.200 --> 00:01:13.970
<v Speaker 1>but I'm also part of the center for </v>
<v Speaker 1>brains,</v>

21
00:01:13.971 --> 00:01:18.971
<v Speaker 1>minds and machines,</v>
<v Speaker 1>which is an NSF funded center science </v>

22
00:01:18.971 --> 00:01:22.271
<v Speaker 1>and Technology Center,</v>
<v Speaker 1>which really stands for the bridge </v>

23
00:01:22.271 --> 00:01:22.271
<v Speaker 1>between the science and the engineering </v>
<v Speaker 1>of intelligence.</v>

24
00:01:22.460 --> 00:01:25.910
<v Speaker 1>It literally straddles Vassar Street and</v>
<v Speaker 1>that we have see sale and bcs members.</v>

25
00:01:25.911 --> 00:01:29.840
<v Speaker 1>We also have partners at Harvard and </v>
<v Speaker 1>other academic institutions and again,</v>

26
00:01:29.841 --> 00:01:34.841
<v Speaker 1>what we stand for.</v>
<v Speaker 1>I want to try to convey some of the </v>

27
00:01:34.841 --> 00:01:37.091
<v Speaker 1>specific things we're doing in the </v>
<v Speaker 1>center and where we want to go with a </v>

28
00:01:37.091 --> 00:01:39.440
<v Speaker 1>vision that really is about jointly </v>
<v Speaker 1>pursuing the science,</v>

29
00:01:39.470 --> 00:01:44.470
<v Speaker 1>the basic science of how intelligence </v>
<v Speaker 1>arises in the human mind and brain and </v>

30
00:01:44.470 --> 00:01:48.821
<v Speaker 1>also the engineering enterprise of how </v>
<v Speaker 1>to build something increasingly like </v>

31
00:01:48.821 --> 00:01:53.441
<v Speaker 1>human intelligence in machines and we </v>
<v Speaker 1>deeply believe that these two projects </v>

32
00:01:53.441 --> 00:01:55.370
<v Speaker 1>have something to do with each other and</v>
<v Speaker 1>our best pursued jointly.</v>

33
00:01:56.390 --> 00:02:01.390
<v Speaker 1>Now it's a really exciting time to be </v>
<v Speaker 1>doing anything related to intelligence </v>

34
00:02:01.390 --> 00:02:02.930
<v Speaker 1>or certainly to ai for all the reasons </v>
<v Speaker 1>that brought you all here.</v>

35
00:02:02.931 --> 00:02:07.931
<v Speaker 1>I don't have to tell you this.</v>
<v Speaker 1>We have all these ways in which ai is </v>

36
00:02:07.931 --> 00:02:07.931
<v Speaker 1>kind of.</v>

37
00:02:07.931 --> 00:02:11.830
<v Speaker 1>Finally here we finally live in the era </v>
<v Speaker 1>of something like real practical ai or </v>

38
00:02:12.200 --> 00:02:17.200
<v Speaker 1>for those who've been around for awhile </v>
<v Speaker 1>and have seen some of the rises and </v>

39
00:02:17.200 --> 00:02:17.200
<v Speaker 1>falls,</v>
<v Speaker 1>you know,</v>

40
00:02:17.200 --> 00:02:19.160
<v Speaker 1>ai is back in a big way,</v>
<v Speaker 1>but from my perspective,</v>

41
00:02:19.161 --> 00:02:24.161
<v Speaker 1>and I think maybe this reflects why we </v>
<v Speaker 1>distinguish what we might call Agi from </v>

42
00:02:24.161 --> 00:02:25.880
<v Speaker 1>Ai,</v>
<v Speaker 1>we don't really have any real ai.</v>

43
00:02:25.881 --> 00:02:28.880
<v Speaker 1>Basically we have what I like to call ai</v>
<v Speaker 1>technologies,</v>

44
00:02:29.180 --> 00:02:34.180
<v Speaker 1>which are systems that do things we used</v>
<v Speaker 1>to think that only humans could do and </v>

45
00:02:34.180 --> 00:02:35.660
<v Speaker 1>now we have machines that do them often </v>
<v Speaker 1>quite well,</v>

46
00:02:35.661 --> 00:02:38.630
<v Speaker 1>maybe even better than any human who's </v>
<v Speaker 1>ever lived.</v>

47
00:02:38.680 --> 00:02:40.250
<v Speaker 1>Right?</v>
<v Speaker 1>Like a machine that plays go,</v>

48
00:02:41.030 --> 00:02:44.180
<v Speaker 1>but none of these systems I would say </v>
<v Speaker 1>are truly intelligent.</v>

49
00:02:44.181 --> 00:02:45.920
<v Speaker 1>None of them have anything like common </v>
<v Speaker 1>sense.</v>

50
00:02:46.110 --> 00:02:51.110
<v Speaker 1>None of them have anything like the </v>
<v Speaker 1>flexible general purpose intelligence </v>

51
00:02:51.110 --> 00:02:53.750
<v Speaker 1>that each of you might use to learn </v>
<v Speaker 1>every one of these skills or tasks.</v>

52
00:02:53.880 --> 00:02:56.330
<v Speaker 1>Right?</v>
<v Speaker 1>Each of these systems had to be built by</v>

53
00:02:56.331 --> 00:03:00.220
<v Speaker 1>large teams of engineers working </v>
<v Speaker 1>together often for a number of years.</v>

54
00:03:00.221 --> 00:03:05.221
<v Speaker 1>I'd often at great cost to somebody </v>
<v Speaker 1>who's willing to pay for it and each of </v>

55
00:03:05.221 --> 00:03:07.150
<v Speaker 1>them just does one thing.</v>
<v Speaker 1>So alphago might beat the world's best,</v>

56
00:03:07.870 --> 00:03:11.680
<v Speaker 1>but it can't drive to the match or even </v>
<v Speaker 1>tell you that.</v>

57
00:03:11.681 --> 00:03:16.681
<v Speaker 1>Go what go is,</v>
<v Speaker 1>I can't even tell you the go is a game </v>

58
00:03:16.681 --> 00:03:16.681
<v Speaker 1>because it doesn't even know what a game</v>
<v Speaker 1>is.</v>

59
00:03:16.681 --> 00:03:17.650
<v Speaker 1>Right?</v>
<v Speaker 1>So what's missing?</v>

60
00:03:18.130 --> 00:03:23.130
<v Speaker 1>Why?</v>
<v Speaker 1>What is it that makes every one of your </v>

61
00:03:23.130 --> 00:03:23.130
<v Speaker 1>brains,</v>
<v Speaker 1>maybe you can't beat,</v>

62
00:03:23.130 --> 00:03:23.740
<v Speaker 1>you know,</v>
<v Speaker 1>the world's best in go,</v>

63
00:03:24.070 --> 00:03:26.830
<v Speaker 1>but any one of you can get behind the </v>
<v Speaker 1>wheel of a car.</v>

64
00:03:26.831 --> 00:03:31.831
<v Speaker 1>I think of this because my daughter is </v>
<v Speaker 1>going to turn 16 tomorrow if she lived </v>

65
00:03:31.831 --> 00:03:33.040
<v Speaker 1>in California,</v>
<v Speaker 1>she'd have a driver's license.</v>

66
00:03:34.140 --> 00:03:36.880
<v Speaker 1>It's a little bit down the line for us </v>
<v Speaker 1>here in Massachusetts.</v>

67
00:03:36.880 --> 00:03:38.190
<v Speaker 1>But um,</v>
<v Speaker 1>you know,</v>

68
00:03:38.200 --> 00:03:43.200
<v Speaker 1>she didn't have to be specially </v>
<v Speaker 1>engineered by a billion dollar startups </v>

69
00:03:43.200 --> 00:03:47.220
<v Speaker 1>and you know,</v>
<v Speaker 1>she got really into chess recently and </v>

70
00:03:47.220 --> 00:03:49.351
<v Speaker 1>now she's taught herself chest by </v>
<v Speaker 1>playing just a handful of games </v>

71
00:03:49.351 --> 00:03:49.351
<v Speaker 1>basically.</v>
<v Speaker 1>Um,</v>

72
00:03:49.351 --> 00:03:51.460
<v Speaker 1>and she can do any one of these </v>
<v Speaker 1>activities at any one of us can.</v>

73
00:03:51.490 --> 00:03:52.660
<v Speaker 1>So what is it?</v>
<v Speaker 1>What's the,</v>

74
00:03:52.661 --> 00:03:54.910
<v Speaker 1>what makes up the difference?</v>
<v Speaker 1>Well,</v>

75
00:03:54.911 --> 00:03:56.560
<v Speaker 1>there's many things,</v>
<v Speaker 1>right?</v>

76
00:03:56.860 --> 00:03:59.980
<v Speaker 1>Um,</v>
<v Speaker 1>I'll talk about the focus for us and our</v>

77
00:04:00.010 --> 00:04:01.810
<v Speaker 1>research and a lot of us,</v>
<v Speaker 1>again,</v>

78
00:04:01.811 --> 00:04:04.830
<v Speaker 1>in CBMM is summarized here.</v>
<v Speaker 1>Um,</v>

79
00:04:04.840 --> 00:04:09.840
<v Speaker 1>what,</v>
<v Speaker 1>what drives the success is right now in </v>

80
00:04:09.840 --> 00:04:10.180
<v Speaker 1>ai,</v>
<v Speaker 1>especially in industry.</v>

81
00:04:10.480 --> 00:04:15.480
<v Speaker 1>Okay.</v>
<v Speaker 1>And all of these ai technologies is </v>

82
00:04:15.480 --> 00:04:15.480
<v Speaker 1>many,</v>
<v Speaker 1>many things,</v>

83
00:04:15.480 --> 00:04:15.480
<v Speaker 1>many things,</v>
<v Speaker 1>but what,</v>

84
00:04:15.480 --> 00:04:19.460
<v Speaker 1>what,</v>
<v Speaker 1>where the progress has been made most </v>

85
00:04:19.460 --> 00:04:19.930
<v Speaker 1>recently and what's getting most of the </v>
<v Speaker 1>attention is of course deep learning,</v>

86
00:04:20.050 --> 00:04:23.470
<v Speaker 1>but other kinds of machine learning </v>
<v Speaker 1>technologies which essentially represent</v>

87
00:04:23.471 --> 00:04:28.471
<v Speaker 1>the maturation of a decades long effort </v>
<v Speaker 1>to solve the problem of pattern </v>

88
00:04:28.471 --> 00:04:28.471
<v Speaker 1>recognition.</v>

89
00:04:28.471 --> 00:04:33.330
<v Speaker 1>That means taking data and finding </v>
<v Speaker 1>patterns in the data that tells you </v>

90
00:04:33.330 --> 00:04:37.381
<v Speaker 1>something you care about,</v>
<v Speaker 1>like how to label a class or how to </v>

91
00:04:37.381 --> 00:04:37.390
<v Speaker 1>predict some other signal.</v>
<v Speaker 1>Okay.</v>

92
00:04:37.930 --> 00:04:39.760
<v Speaker 1>Um,</v>
<v Speaker 1>and pattern recognition is great.</v>

93
00:04:39.761 --> 00:04:44.761
<v Speaker 1>It's an important part of intelligence </v>
<v Speaker 1>and it's reasonable to say that deep </v>

94
00:04:44.761 --> 00:04:48.580
<v Speaker 1>learning as a technology has really made</v>
<v Speaker 1>great strides on pattern recognition and</v>

95
00:04:48.581 --> 00:04:49.660
<v Speaker 1>maybe even,</v>
<v Speaker 1>you know,</v>

96
00:04:49.980 --> 00:04:52.930
<v Speaker 1>has coming close to solving the problems</v>
<v Speaker 1>with pattern recognition.</v>

97
00:04:53.470 --> 00:04:55.450
<v Speaker 1>But intelligence is about many other </v>
<v Speaker 1>things.</v>

98
00:04:55.451 --> 00:04:57.970
<v Speaker 1>Intelligence about a lot more in </v>
<v Speaker 1>particular.</v>

99
00:04:57.971 --> 00:05:02.971
<v Speaker 1>It's about modeling the world and think </v>
<v Speaker 1>about all the activities that a human </v>

100
00:05:02.971 --> 00:05:05.200
<v Speaker 1>does from all over the world that that </v>
<v Speaker 1>go beyond just say,</v>

101
00:05:05.230 --> 00:05:10.230
<v Speaker 1>recognizing patterns in data,</v>
<v Speaker 1>but actually trying to explain and </v>

102
00:05:10.230 --> 00:05:10.330
<v Speaker 1>understand what we see,</v>
<v Speaker 1>for instance,</v>

103
00:05:10.610 --> 00:05:15.610
<v Speaker 1>okay.</v>
<v Speaker 1>Or to be able to imagine things that </v>

104
00:05:15.610 --> 00:05:17.971
<v Speaker 1>we've never seen that never seen,</v>
<v Speaker 1>maybe even very different from anything </v>

105
00:05:17.971 --> 00:05:19.160
<v Speaker 1>we've ever seen,</v>
<v Speaker 1>but we want to see and then two,</v>

106
00:05:19.270 --> 00:05:24.270
<v Speaker 1>to set those as goals to make plans and </v>
<v Speaker 1>solve problems needed to make those </v>

107
00:05:24.270 --> 00:05:26.650
<v Speaker 1>things real or thinking about learning.</v>

108
00:05:26.890 --> 00:05:29.110
<v Speaker 1>Again,</v>
<v Speaker 1>some kinds of learning can be thought of</v>

109
00:05:29.111 --> 00:05:34.111
<v Speaker 1>as pattern recognition if you're </v>
<v Speaker 1>learning sufficient statistics or </v>

110
00:05:34.111 --> 00:05:34.111
<v Speaker 1>weights and a neural net that are used </v>
<v Speaker 1>for those purposes,</v>

111
00:05:34.390 --> 00:05:37.900
<v Speaker 1>but many activities of learning are </v>
<v Speaker 1>about building out new models,</v>

112
00:05:38.020 --> 00:05:39.310
<v Speaker 1>right?</v>
<v Speaker 1>Either refining,</v>

113
00:05:39.311 --> 00:05:44.311
<v Speaker 1>reusing and proving old bottles or </v>
<v Speaker 1>actually building fundamentally new </v>

114
00:05:44.311 --> 00:05:44.500
<v Speaker 1>models as you've experienced more of the</v>
<v Speaker 1>world.</v>

115
00:05:44.710 --> 00:05:47.830
<v Speaker 1>And then think about sharing our models,</v>
<v Speaker 1>communicating our models to others,</v>

116
00:05:48.130 --> 00:05:50.020
<v Speaker 1>modeling their models,</v>
<v Speaker 1>learning from them.</v>

117
00:05:50.290 --> 00:05:55.290
<v Speaker 1>All of these activities of modeling.</v>
<v Speaker 1>These are at the heart of human </v>

118
00:05:55.290 --> 00:05:58.190
<v Speaker 1>intelligence and it requires a much </v>
<v Speaker 1>broader set of tools.</v>

119
00:05:58.191 --> 00:06:03.191
<v Speaker 1>So I want to talk about the ways that </v>
<v Speaker 1>we're studying these activities of </v>

120
00:06:03.191 --> 00:06:05.621
<v Speaker 1>modeling the world and something in a </v>
<v Speaker 1>pretty nontechnical way about what are </v>

121
00:06:05.621 --> 00:06:07.670
<v Speaker 1>the kinds of tools that allow us to </v>
<v Speaker 1>capture these abilities.</v>

122
00:06:07.880 --> 00:06:12.880
<v Speaker 1>Now I think it's.</v>
<v Speaker 1>I want to be very honest upfront and to </v>

123
00:06:12.880 --> 00:06:12.880
<v Speaker 1>say this is just the beginning of a </v>
<v Speaker 1>story,</v>

124
00:06:12.880 --> 00:06:12.920
<v Speaker 1>right?</v>

125
00:06:13.310 --> 00:06:14.990
<v Speaker 1>When you look at deep learning </v>
<v Speaker 1>successes,</v>

126
00:06:15.260 --> 00:06:17.360
<v Speaker 1>that itself is a story that goes back </v>
<v Speaker 1>decades.</v>

127
00:06:17.361 --> 00:06:19.130
<v Speaker 1>I'll say a little bit about that history</v>
<v Speaker 1>in a minute,</v>

128
00:06:19.550 --> 00:06:24.550
<v Speaker 1>but where we are now is just looking </v>
<v Speaker 1>forward to a future when we might be </v>

129
00:06:24.550 --> 00:06:28.151
<v Speaker 1>able to capture these abilities at a </v>
<v Speaker 1>really mature engineering scale and I </v>

130
00:06:28.151 --> 00:06:31.580
<v Speaker 1>would say we are far from being able to </v>
<v Speaker 1>capture the all the ways in which humans</v>

131
00:06:31.790 --> 00:06:34.880
<v Speaker 1>richly flexibly,</v>
<v Speaker 1>quickly build models of the world at the</v>

132
00:06:34.881 --> 00:06:39.881
<v Speaker 1>kind of scale that say silicon valley </v>
<v Speaker 1>wants either big tech companies like </v>

133
00:06:39.881 --> 00:06:42.170
<v Speaker 1>Google or Microsoft or IBM or facebook </v>
<v Speaker 1>or small startups.</v>

134
00:06:42.200 --> 00:06:46.280
<v Speaker 1>Right?</v>
<v Speaker 1>We can get there and I think what I want</v>

135
00:06:46.281 --> 00:06:51.281
<v Speaker 1>to talk to you about here is one route </v>
<v Speaker 1>for trying to get there and this is the </v>

136
00:06:51.281 --> 00:06:53.780
<v Speaker 1>route that CBMM stands for,</v>
<v Speaker 1>the idea that by reverse engineering how</v>

137
00:06:53.781 --> 00:06:58.781
<v Speaker 1>intelligence works in the human mind and</v>
<v Speaker 1>brain that will give us a route to </v>

138
00:06:58.781 --> 00:06:59.360
<v Speaker 1>engineering these abilities in machines.</v>

139
00:06:59.510 --> 00:07:02.000
<v Speaker 1>When we say reverse engineering,</v>
<v Speaker 1>we're talking about science,</v>

140
00:07:02.001 --> 00:07:07.001
<v Speaker 1>but doing science like engineers.</v>
<v Speaker 1>This is our fundamental principle that </v>

141
00:07:07.001 --> 00:07:08.730
<v Speaker 1>if we approach cognitive science and </v>
<v Speaker 1>neuroscience like an engineer,</v>

142
00:07:08.731 --> 00:07:13.731
<v Speaker 1>where so the output of our science isn't</v>
<v Speaker 1>just a description of the brain or the </v>

143
00:07:13.731 --> 00:07:16.751
<v Speaker 1>mind in words,</v>
<v Speaker 1>but in the same terms that an engineer </v>

144
00:07:16.751 --> 00:07:16.751
<v Speaker 1>would use to build an intelligent </v>
<v Speaker 1>system,</v>

145
00:07:16.790 --> 00:07:19.730
<v Speaker 1>then that will be both the basis for a </v>
<v Speaker 1>much more rigorous and deep,</v>

146
00:07:19.820 --> 00:07:24.820
<v Speaker 1>the insightful science,</v>
<v Speaker 1>but also direct translation of those </v>

147
00:07:24.820 --> 00:07:27.821
<v Speaker 1>insights into engineering applications.</v>
<v Speaker 1>Now I said before I talk a little about </v>

148
00:07:28.221 --> 00:07:29.210
<v Speaker 1>history,</v>
<v Speaker 1>um,</v>

149
00:07:29.211 --> 00:07:30.860
<v Speaker 1>what I mean by that is this,</v>
<v Speaker 1>again,</v>

150
00:07:30.861 --> 00:07:32.900
<v Speaker 1>if,</v>
<v Speaker 1>if part of what brought you here as deep</v>

151
00:07:32.901 --> 00:07:34.520
<v Speaker 1>learning,</v>
<v Speaker 1>and I know even if you've never heard of</v>

152
00:07:34.521 --> 00:07:37.970
<v Speaker 1>deep learning before,</v>
<v Speaker 1>which I'm sure is unlikely you saw some,</v>

153
00:07:38.050 --> 00:07:39.470
<v Speaker 1>you know,</v>
<v Speaker 1>a good spectrum of that in the,</v>

154
00:07:39.510 --> 00:07:41.460
<v Speaker 1>in the overview session,</v>
<v Speaker 1>uh,</v>

155
00:07:41.660 --> 00:07:42.200
<v Speaker 1>last night.</v>

156
00:07:42.350 --> 00:07:43.300
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

157
00:07:43.640 --> 00:07:48.640
<v Speaker 1>it's really interesting and important to</v>
<v Speaker 1>look back on the history of where did </v>

158
00:07:48.640 --> 00:07:50.090
<v Speaker 1>techniques for deep learning come from </v>
<v Speaker 1>or reinforcement learning.</v>

159
00:07:50.091 --> 00:07:55.091
<v Speaker 1>Those are the two tools in the,</v>
<v Speaker 1>in the current machine learning arsenal </v>

160
00:07:55.091 --> 00:07:58.181
<v Speaker 1>that are getting the most attention,</v>
<v Speaker 1>things like backpropagation or end to </v>

161
00:07:58.181 --> 00:08:01.241
<v Speaker 1>end,</v>
<v Speaker 1>stochastic gradient descent or temporal </v>

162
00:08:01.241 --> 00:08:01.910
<v Speaker 1>difference learning or cue learning.</v>
<v Speaker 1>Here's a few papers from the literature.</v>

163
00:08:01.911 --> 00:08:02.230
<v Speaker 1>May,</v>
<v Speaker 1>you know,</v>

164
00:08:02.240 --> 00:08:04.040
<v Speaker 1>maybe some of you have read these </v>
<v Speaker 1>original papers.</v>

165
00:08:04.041 --> 00:08:09.041
<v Speaker 1>Here's,</v>
<v Speaker 1>here's the original paper by Romel </v>

166
00:08:09.041 --> 00:08:11.201
<v Speaker 1>heart,</v>
<v Speaker 1>Hinton and colleagues in which they </v>

167
00:08:11.201 --> 00:08:11.201
<v Speaker 1>introduced the backpropagation algorithm</v>
<v Speaker 1>for training multilayer,</v>

168
00:08:11.201 --> 00:08:11.690
<v Speaker 1>perceptrons,</v>
<v Speaker 1>right?</v>

169
00:08:11.691 --> 00:08:16.691
<v Speaker 1>Multilayer neural networks.</v>
<v Speaker 1>Here's the original perceptron paper by </v>

170
00:08:16.691 --> 00:08:19.571
<v Speaker 1>Rosenblatt,</v>
<v Speaker 1>which introduced the one layer version </v>

171
00:08:19.571 --> 00:08:19.880
<v Speaker 1>of that architecture and the basic </v>
<v Speaker 1>perceptron learning algorithm.</v>

172
00:08:20.360 --> 00:08:25.360
<v Speaker 1>Here's the first paper on sort of the </v>
<v Speaker 1>temporal difference learning method for </v>

173
00:08:25.360 --> 00:08:26.420
<v Speaker 1>reinforcement learning from Sutton and </v>
<v Speaker 1>bartow.</v>

174
00:08:27.020 --> 00:08:30.380
<v Speaker 1>Here's the original bolt machine paper </v>
<v Speaker 1>also by Hinton and colleagues,</v>

175
00:08:31.170 --> 00:08:36.170
<v Speaker 1>which you know again is a,</v>
<v Speaker 1>those who don't know that architecture </v>

176
00:08:36.170 --> 00:08:38.810
<v Speaker 1>can give a kind of probabilistic </v>
<v Speaker 1>undirected multilayer perceptron,</v>

177
00:08:39.220 --> 00:08:40.530
<v Speaker 1>um,</v>
<v Speaker 1>or for example,</v>

178
00:08:41.090 --> 00:08:46.090
<v Speaker 1>before the Lstm is if you know about </v>
<v Speaker 1>current recurrent neural network </v>

179
00:08:46.090 --> 00:08:49.001
<v Speaker 1>architecture earlier,</v>
<v Speaker 1>as much simpler versions of the same </v>

180
00:08:49.001 --> 00:08:49.460
<v Speaker 1>idea were proposed by Jeff Ellman and </v>
<v Speaker 1>his simple recurrent networks.</v>

181
00:08:49.820 --> 00:08:54.820
<v Speaker 1>The reason I want to put up the original</v>
<v Speaker 1>papers here is for you to look at both </v>

182
00:08:54.820 --> 00:08:56.310
<v Speaker 1>when they were published,</v>
<v Speaker 1>where they were published.</v>

183
00:08:56.400 --> 00:09:01.400
<v Speaker 1>So if you look at the dates,</v>
<v Speaker 1>you'll see papers going back to the </v>

184
00:09:01.400 --> 00:09:05.820
<v Speaker 1>eighties,</v>
<v Speaker 1>but even the sixties or even the 19 </v>

185
00:09:05.820 --> 00:09:05.820
<v Speaker 1>fifties,</v>
<v Speaker 1>and look at where they were published.</v>

186
00:09:05.820 --> 00:09:07.920
<v Speaker 1>Most of them were published in </v>
<v Speaker 1>psychology journals.</v>

187
00:09:07.921 --> 00:09:10.200
<v Speaker 1>So the journal psychological review,</v>
<v Speaker 1>if you don't know it,</v>

188
00:09:10.201 --> 00:09:15.201
<v Speaker 1>is like the leading journal of </v>
<v Speaker 1>theoretical psychology and mathematical </v>

189
00:09:15.201 --> 00:09:18.111
<v Speaker 1>psychology or cognitive science.</v>
<v Speaker 1>The Journal of the cognitive science </v>

190
00:09:18.111 --> 00:09:20.160
<v Speaker 1>society or the back prop paper was </v>
<v Speaker 1>published in nature,</v>

191
00:09:20.190 --> 00:09:21.990
<v Speaker 1>which is a general interest science </v>
<v Speaker 1>journal.</v>

192
00:09:21.991 --> 00:09:25.170
<v Speaker 1>But by people who are mostly affiliated </v>
<v Speaker 1>with the Institute for Cognitive Science</v>

193
00:09:25.200 --> 00:09:30.200
<v Speaker 1>in San Diego,</v>
<v Speaker 1>so what you see here is already a long </v>

194
00:09:30.200 --> 00:09:30.690
<v Speaker 1>history of scientists thinking like </v>
<v Speaker 1>engineers,</v>

195
00:09:30.840 --> 00:09:35.840
<v Speaker 1>these are people who are in psychology </v>
<v Speaker 1>or cognitive science departments and </v>

196
00:09:35.840 --> 00:09:39.351
<v Speaker 1>publishing in those places,</v>
<v Speaker 1>but by formalizing even very basic </v>

197
00:09:39.351 --> 00:09:40.830
<v Speaker 1>insights about how humans might learn or</v>
<v Speaker 1>how,</v>

198
00:09:40.850 --> 00:09:45.850
<v Speaker 1>you know,</v>
<v Speaker 1>brains might learn in the right kind of </v>

199
00:09:45.850 --> 00:09:45.850
<v Speaker 1>math that led to,</v>
<v Speaker 1>of course,</v>

200
00:09:45.850 --> 00:09:50.121
<v Speaker 1>progress on the science side,</v>
<v Speaker 1>but it led to all the engineering that </v>

201
00:09:50.121 --> 00:09:50.121
<v Speaker 1>we see now.</v>

202
00:09:50.121 --> 00:09:50.121
<v Speaker 1>It wasn't sufficient,</v>
<v Speaker 1>right?</v>

203
00:09:50.121 --> 00:09:51.300
<v Speaker 1>We needed,</v>
<v Speaker 1>we needed,</v>

204
00:09:51.390 --> 00:09:56.390
<v Speaker 1>of course,</v>
<v Speaker 1>lots of innovations and advances in </v>

205
00:09:56.390 --> 00:09:56.700
<v Speaker 1>computing hardware and software systems,</v>
<v Speaker 1>right?</v>

206
00:09:56.820 --> 00:10:01.820
<v Speaker 1>But this is where the basic,</v>
<v Speaker 1>the basic math came from and it came </v>

207
00:10:01.820 --> 00:10:05.331
<v Speaker 1>from doing science like an engineer.</v>
<v Speaker 1>So what I want to talk about and our </v>

208
00:10:05.331 --> 00:10:06.120
<v Speaker 1>vision is what is the future of this </v>
<v Speaker 1>look like?</v>

209
00:10:06.121 --> 00:10:07.950
<v Speaker 1>If we were to look 50 years into the </v>
<v Speaker 1>future,</v>

210
00:10:08.190 --> 00:10:10.580
<v Speaker 1>what would we be looking back on now?</v>
<v Speaker 1>Or you know,</v>

211
00:10:10.620 --> 00:10:12.090
<v Speaker 1>over this timescale.</v>
<v Speaker 1>Well,</v>

212
00:10:12.091 --> 00:10:17.091
<v Speaker 1>here's a,</v>
<v Speaker 1>here's a longterm research roadmap that </v>

213
00:10:17.091 --> 00:10:19.461
<v Speaker 1>reflects some of my ambitions and some </v>
<v Speaker 1>of our centers goals and many others to </v>

214
00:10:19.461 --> 00:10:23.630
<v Speaker 1>right.</v>
<v Speaker 1>We'd like to be able to address basic </v>

215
00:10:23.630 --> 00:10:25.611
<v Speaker 1>questions,</v>
<v Speaker 1>fundamental questions of what it is to </v>

216
00:10:25.611 --> 00:10:25.680
<v Speaker 1>be and to think like a human questions </v>
<v Speaker 1>for example,</v>

217
00:10:25.681 --> 00:10:28.620
<v Speaker 1>of consciousness or meaning and language</v>
<v Speaker 1>or real learning,</v>

218
00:10:28.890 --> 00:10:30.270
<v Speaker 1>right?</v>
<v Speaker 1>Questions like,</v>

219
00:10:30.271 --> 00:10:31.230
<v Speaker 1>um,</v>
<v Speaker 1>you know,</v>

220
00:10:31.290 --> 00:10:35.070
<v Speaker 1>even beyond the individual at questions </v>
<v Speaker 1>of culture or creativity.</v>

221
00:10:35.130 --> 00:10:40.130
<v Speaker 1>Those are our big ideas up there.</v>
<v Speaker 1>And for each of these there are basic </v>

222
00:10:40.130 --> 00:10:40.130
<v Speaker 1>scientific questions,</v>
<v Speaker 1>right?</v>

223
00:10:40.130 --> 00:10:42.300
<v Speaker 1>How do we become aware of the world and </v>
<v Speaker 1>ourselves in.</v>

224
00:10:42.301 --> 00:10:45.330
<v Speaker 1>It starts with perception,</v>
<v Speaker 1>but it really turns into awareness,</v>

225
00:10:45.420 --> 00:10:48.390
<v Speaker 1>awareness of yourself and of the world </v>
<v Speaker 1>and what we might call consciousness,</v>

226
00:10:48.450 --> 00:10:53.450
<v Speaker 1>right?</v>
<v Speaker 1>Or how does a word starts to have a </v>

227
00:10:53.450 --> 00:10:56.181
<v Speaker 1>meaning?</v>
<v Speaker 1>What really is a meaning and how does a </v>

228
00:10:56.181 --> 00:10:57.801
<v Speaker 1>child grasp it or how to children </v>
<v Speaker 1>actually learn what to babies brains </v>

229
00:10:57.801 --> 00:11:01.641
<v Speaker 1>actually start with are they blank </v>
<v Speaker 1>slates or do they start with some kind </v>

230
00:11:01.641 --> 00:11:04.401
<v Speaker 1>of cognitive structure?</v>
<v Speaker 1>And then what is real learning look </v>

231
00:11:04.401 --> 00:11:06.831
<v Speaker 1>like?</v>
<v Speaker 1>These are just some of the questions </v>

232
00:11:06.831 --> 00:11:07.500
<v Speaker 1>that we're interested in working on or </v>
<v Speaker 1>when we talk about culture remain,</v>

233
00:11:07.800 --> 00:11:10.740
<v Speaker 1>how do you learn all the things you </v>
<v Speaker 1>didn't directly experience,</v>

234
00:11:10.980 --> 00:11:15.980
<v Speaker 1>right?</v>
<v Speaker 1>But that somehow you got from the </v>

235
00:11:15.980 --> 00:11:16.530
<v Speaker 1>accumulation of knowledge in society </v>
<v Speaker 1>over many generations or how do you ever</v>

236
00:11:16.590 --> 00:11:19.020
<v Speaker 1>think of new ideas or answers to new </v>
<v Speaker 1>questions?</v>

237
00:11:19.020 --> 00:11:20.490
<v Speaker 1>How do you think of the new questions </v>
<v Speaker 1>themselves?</v>

238
00:11:20.491 --> 00:11:25.491
<v Speaker 1>How do you decide what to think about?</v>
<v Speaker 1>These are all key activities of human </v>

239
00:11:25.491 --> 00:11:29.031
<v Speaker 1>intelligence.</v>
<v Speaker 1>When we talk about how we model the </v>

240
00:11:29.031 --> 00:11:29.031
<v Speaker 1>world,</v>
<v Speaker 1>where our models come from,</v>

241
00:11:29.031 --> 00:11:32.601
<v Speaker 1>what we do with our models.</v>
<v Speaker 1>This is what we're talking about and if </v>

242
00:11:32.601 --> 00:11:35.031
<v Speaker 1>we could get machines that could do </v>
<v Speaker 1>these things well again on the bottom </v>

243
00:11:35.031 --> 00:11:35.190
<v Speaker 1>row,</v>
<v Speaker 1>think of all the actual real engineering</v>

244
00:11:35.191 --> 00:11:40.191
<v Speaker 1>payoffs now in our center and in both my</v>
<v Speaker 1>own activities and a lot of what my </v>

245
00:11:40.191 --> 00:11:45.081
<v Speaker 1>group does these days and what a number </v>
<v Speaker 1>of other colleagues in the center for </v>

246
00:11:45.081 --> 00:11:45.470
<v Speaker 1>brains minds and machines do as well as </v>
<v Speaker 1>an abrupt,</v>

247
00:11:45.480 --> 00:11:47.650
<v Speaker 1>very broadly.</v>
<v Speaker 1>People in pcs and see sale.</v>

248
00:11:48.000 --> 00:11:50.940
<v Speaker 1>One place where we work on the </v>
<v Speaker 1>beginnings of these problems in the near</v>

249
00:11:50.941 --> 00:11:51.990
<v Speaker 1>term,</v>
<v Speaker 1>this is the longterm,</v>

250
00:11:51.991 --> 00:11:53.560
<v Speaker 1>like think 50 years,</v>
<v Speaker 1>maybe,</v>

251
00:11:53.580 --> 00:11:54.820
<v Speaker 1>maybe shorter,</v>
<v Speaker 1>maybe longer,</v>

252
00:11:54.821 --> 00:11:56.440
<v Speaker 1>I don't know,</v>
<v Speaker 1>but think well beyond,</v>

253
00:11:57.160 --> 00:12:00.430
<v Speaker 1>well beyond 10 years,</v>
<v Speaker 1>but in the short term,</v>

254
00:12:00.431 --> 00:12:05.431
<v Speaker 1>five to 10 years,</v>
<v Speaker 1>a lot of our focus is around visual </v>

255
00:12:05.431 --> 00:12:05.431
<v Speaker 1>intelligence and there's many reasons </v>
<v Speaker 1>for that.</v>

256
00:12:05.431 --> 00:12:09.720
<v Speaker 1>Again,</v>
<v Speaker 1>we can build on the successes of deep </v>

257
00:12:09.720 --> 00:12:09.720
<v Speaker 1>networks and a lot of pattern </v>
<v Speaker 1>recognition and machine vision.</v>

258
00:12:09.850 --> 00:12:11.860
<v Speaker 1>It's a good way to put these ideas into </v>
<v Speaker 1>practice.</v>

259
00:12:11.861 --> 00:12:13.630
<v Speaker 1>When we,</v>
<v Speaker 1>when we look at the actual brain,</v>

260
00:12:14.020 --> 00:12:18.130
<v Speaker 1>the visual system in the brain,</v>
<v Speaker 1>in the human and other mammalian brains,</v>

261
00:12:18.131 --> 00:12:23.131
<v Speaker 1>for example,</v>
<v Speaker 1>is really very clearly the best </v>

262
00:12:23.131 --> 00:12:23.131
<v Speaker 1>understood part of the brain and at a </v>
<v Speaker 1>circuit level,</v>

263
00:12:23.131 --> 00:12:25.180
<v Speaker 1>it's the part of the brain that's most </v>
<v Speaker 1>inspired current,</v>

264
00:12:25.840 --> 00:12:27.520
<v Speaker 1>deep learning and neural network </v>
<v Speaker 1>systems.</v>

265
00:12:27.790 --> 00:12:32.790
<v Speaker 1>But even there,</v>
<v Speaker 1>there's things which we still don't </v>

266
00:12:32.790 --> 00:12:35.131
<v Speaker 1>really understand like engineers.</v>
<v Speaker 1>So here's an example of a basic problem </v>

267
00:12:35.131 --> 00:12:39.121
<v Speaker 1>in visual intelligence that we and </v>
<v Speaker 1>others in the center are trying to </v>

268
00:12:39.121 --> 00:12:43.111
<v Speaker 1>solve.</v>
<v Speaker 1>Look around you and you feel like </v>

269
00:12:43.111 --> 00:12:45.180
<v Speaker 1>there's a whole world around you and </v>
<v Speaker 1>there is a whole world around you,</v>

270
00:12:45.181 --> 00:12:46.840
<v Speaker 1>you know,</v>
<v Speaker 1>feel like your brain captures it,</v>

271
00:12:47.380 --> 00:12:50.650
<v Speaker 1>but what the actual sensor data that's </v>
<v Speaker 1>coming in through your eyes,</v>

272
00:12:50.910 --> 00:12:53.770
<v Speaker 1>it looks more like this photograph here </v>
<v Speaker 1>where you can see there's a crowd scene,</v>

273
00:12:53.771 --> 00:12:58.771
<v Speaker 1>but it's mostly blurry except for a </v>
<v Speaker 1>small region of high resolution in the </v>

274
00:12:58.771 --> 00:12:59.770
<v Speaker 1>center,</v>
<v Speaker 1>so that corresponds biologically to what</v>

275
00:12:59.771 --> 00:13:01.330
<v Speaker 1>part of the images in your phobia.</v>

276
00:13:01.330 --> 00:13:06.330
<v Speaker 1>That's the central region of cells in </v>
<v Speaker 1>the retina where you have really high </v>

277
00:13:06.330 --> 00:13:09.721
<v Speaker 1>resolution visual data.</v>
<v Speaker 1>The size of your phobia is roughly like </v>

278
00:13:09.721 --> 00:13:10.420
<v Speaker 1>if you hold out your thumb at arm's </v>
<v Speaker 1>length,</v>

279
00:13:10.450 --> 00:13:12.340
<v Speaker 1>it's a little bit bigger than that,</v>
<v Speaker 1>but not much bigger.</v>

280
00:13:12.550 --> 00:13:17.550
<v Speaker 1>Right?</v>
<v Speaker 1>Most of the image it in terms of the </v>

281
00:13:17.550 --> 00:13:20.461
<v Speaker 1>actual information coming in and a </v>
<v Speaker 1>bottom up sense to your brain is really </v>

282
00:13:20.461 --> 00:13:23.851
<v Speaker 1>quite blurry,</v>
<v Speaker 1>but somehow by looking at just one part </v>

283
00:13:23.851 --> 00:13:25.210
<v Speaker 1>and then by being around or making a few</v>
<v Speaker 1>eye movements,</v>

284
00:13:25.300 --> 00:13:30.300
<v Speaker 1>you get a few glimpses each.</v>
<v Speaker 1>Not much bigger than the size of your </v>

285
00:13:30.300 --> 00:13:33.151
<v Speaker 1>thumb at arm's length.</v>
<v Speaker 1>Somehow you stitch that information </v>

286
00:13:33.151 --> 00:13:35.851
<v Speaker 1>together into what feels like and really</v>
<v Speaker 1>is a rich representation of the whole </v>

287
00:13:35.851 --> 00:13:37.060
<v Speaker 1>world around you.</v>
<v Speaker 1>And when I say around you,</v>

288
00:13:37.061 --> 00:13:40.120
<v Speaker 1>I mean literally around you.</v>
<v Speaker 1>So here's another kind of demonstration.</v>

289
00:13:41.710 --> 00:13:43.930
<v Speaker 1>Without turning around,</v>
<v Speaker 1>nobody's allowed to turn around.</v>

290
00:13:44.560 --> 00:13:49.560
<v Speaker 1>Ask yourself what's behind you.</v>
<v Speaker 1>Now the answer is going to be different </v>

291
00:13:49.560 --> 00:13:49.750
<v Speaker 1>for different people.</v>
<v Speaker 1>Depending on where you're sitting,</v>

292
00:13:49.780 --> 00:13:51.040
<v Speaker 1>right?</v>
<v Speaker 1>For most of you,</v>

293
00:13:51.190 --> 00:13:52.210
<v Speaker 1>you might think,</v>
<v Speaker 1>well,</v>

294
00:13:52.211 --> 00:13:57.211
<v Speaker 1>there's,</v>
<v Speaker 1>I think there's a person pretty close </v>

295
00:13:57.211 --> 00:13:57.211
<v Speaker 1>behind me,</v>
<v Speaker 1>right?</v>

296
00:13:57.211 --> 00:13:57.760
<v Speaker 1>You know you're in a crowded auditorium,</v>
<v Speaker 1>although you haven't seen that person,</v>

297
00:13:57.761 --> 00:13:59.380
<v Speaker 1>you know that they're there,</v>
<v Speaker 1>right?</v>

298
00:14:00.910 --> 00:14:03.460
<v Speaker 1>For people in the very back row,</v>
<v Speaker 1>you know there isn't a person behind you</v>

299
00:14:03.461 --> 00:14:05.050
<v Speaker 1>and you're conscious of being in the </v>
<v Speaker 1>back row,</v>

300
00:14:05.140 --> 00:14:07.030
<v Speaker 1>right?</v>
<v Speaker 1>You might be conscious if there's a wall</v>

301
00:14:07.031 --> 00:14:12.031
<v Speaker 1>right behind you,</v>
<v Speaker 1>but now for the people who are in the </v>

302
00:14:12.031 --> 00:14:12.031
<v Speaker 1>room,</v>
<v Speaker 1>not in the very back,</v>

303
00:14:12.031 --> 00:14:13.630
<v Speaker 1>think about how far behind you is the </v>
<v Speaker 1>back.</v>

304
00:14:13.631 --> 00:14:18.631
<v Speaker 1>Like,</v>
<v Speaker 1>where's the nearest wall behind you so </v>

305
00:14:18.631 --> 00:14:20.251
<v Speaker 1>we can look.</v>
<v Speaker 1>Maybe we can call out a try a little </v>

306
00:14:20.251 --> 00:14:20.251
<v Speaker 1>demonstration.</v>
<v Speaker 1>So I didn't know.</v>

307
00:14:20.251 --> 00:14:21.190
<v Speaker 1>I'm pointing to someone there.</v>
<v Speaker 1>Can you see phrase,</v>

308
00:14:21.340 --> 00:14:22.960
<v Speaker 1>say something if you think I'm pointing </v>
<v Speaker 1>at you?</v>

309
00:14:24.290 --> 00:14:29.290
<v Speaker 1>Uh,</v>
<v Speaker 1>well I could have been pointing at you </v>

310
00:14:29.290 --> 00:14:29.290
<v Speaker 1>but I'm pointing someone behind you.</v>
<v Speaker 1>Okay.</v>

311
00:14:29.290 --> 00:14:29.290
<v Speaker 1>I'll point to you.</v>
<v Speaker 1>Yeah,</v>

312
00:14:29.290 --> 00:14:29.320
<v Speaker 1>I'm pointing to you.</v>
<v Speaker 1>Alright.</v>

313
00:14:29.440 --> 00:14:31.170
<v Speaker 1>So how far is the nearest wall?</v>
<v Speaker 1>But no,</v>

314
00:14:31.220 --> 00:14:34.750
<v Speaker 1>you can't turn around.</v>
<v Speaker 1>You've blown your chance without turning</v>

315
00:14:34.751 --> 00:14:35.170
<v Speaker 1>around.</v>
<v Speaker 1>Okay.</v>

316
00:14:35.171 --> 00:14:36.410
<v Speaker 1>So you,</v>
<v Speaker 1>you were loud.</v>

317
00:14:36.430 --> 00:14:37.120
<v Speaker 1>Okay.</v>
<v Speaker 1>Do you see,</v>

318
00:14:37.121 --> 00:14:38.800
<v Speaker 1>I'm pointing to you there with the tie.</v>
<v Speaker 1>Okay.</v>

319
00:14:38.950 --> 00:14:42.100
<v Speaker 1>So without turning around,</v>
<v Speaker 1>how far is the nearest wall behind you?</v>

320
00:14:46.360 --> 00:14:49.450
<v Speaker 1>That's how far.</v>
<v Speaker 1>Five meters.</v>

321
00:14:49.451 --> 00:14:50.190
<v Speaker 1>Okay.</v>
<v Speaker 1>Well let me,</v>

322
00:14:50.191 --> 00:14:55.191
<v Speaker 1>that might be about right.</v>
<v Speaker 1>No other people can turn around a how </v>

323
00:14:55.191 --> 00:14:55.640
<v Speaker 1>now,</v>
<v Speaker 1>how about you?</v>

324
00:14:55.641 --> 00:15:00.170
<v Speaker 1>How far is the nearest wall behind you?</v>
<v Speaker 1>Ten meters.</v>

325
00:15:00.350 --> 00:15:01.560
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

326
00:15:01.580 --> 00:15:02.750
<v Speaker 1>that might be right?</v>
<v Speaker 1>Yeah.</v>

327
00:15:03.200 --> 00:15:04.920
<v Speaker 1>How about here?</v>
<v Speaker 1>How,</v>

328
00:15:05.040 --> 00:15:05.810
<v Speaker 1>how,</v>
<v Speaker 1>what do you think?</v>

329
00:15:06.560 --> 00:15:07.280
<v Speaker 1>20.</v>
<v Speaker 1>Okay.</v>

330
00:15:07.510 --> 00:15:08.330
<v Speaker 1>Um,</v>
<v Speaker 1>so yeah,</v>

331
00:15:08.331 --> 00:15:09.800
<v Speaker 1>since I didn't grow up in the metric </v>
<v Speaker 1>system,</v>

332
00:15:09.801 --> 00:15:10.850
<v Speaker 1>I barely know,</v>
<v Speaker 1>but yeah,</v>

333
00:15:10.851 --> 00:15:13.790
<v Speaker 1>I mean,</v>
<v Speaker 1>I mean the point is that like your,</v>

334
00:15:14.070 --> 00:15:15.100
<v Speaker 1>your,</v>
<v Speaker 1>your,</v>

335
00:15:15.230 --> 00:15:20.230
<v Speaker 1>each of you is surely not exactly right,</v>
<v Speaker 1>but you're certainly within an order of </v>

336
00:15:20.230 --> 00:15:24.311
<v Speaker 1>magnitude.</v>
<v Speaker 1>And I guess if we actually tried to </v>

337
00:15:24.311 --> 00:15:24.311
<v Speaker 1>measure,</v>
<v Speaker 1>you know,</v>

338
00:15:24.311 --> 00:15:27.041
<v Speaker 1>you're probably,</v>
<v Speaker 1>my guess is you're probably right </v>

339
00:15:27.041 --> 00:15:27.041
<v Speaker 1>within,</v>
<v Speaker 1>you know,</v>

340
00:15:27.041 --> 00:15:27.950
<v Speaker 1>50 percent or less often,</v>
<v Speaker 1>maybe just 20 percent error.</v>

341
00:15:28.550 --> 00:15:29.660
<v Speaker 1>Okay.</v>
<v Speaker 1>So how do you know this?</v>

342
00:15:29.780 --> 00:15:30.830
<v Speaker 1>I mean,</v>
<v Speaker 1>even if it's not,</v>

343
00:15:30.980 --> 00:15:31.940
<v Speaker 1>what did you say?</v>
<v Speaker 1>Twenty meters.</v>

344
00:15:31.941 --> 00:15:36.941
<v Speaker 1>Even if it's not 20 meters,</v>
<v Speaker 1>it's probably closer to 20 meters than </v>

345
00:15:36.941 --> 00:15:38.120
<v Speaker 1>it is to five or 10 meters.</v>
<v Speaker 1>And then it is to 50 meters.</v>

346
00:15:38.210 --> 00:15:40.400
<v Speaker 1>So how did you know this?</v>
<v Speaker 1>You haven't turned around in a while,</v>

347
00:15:40.430 --> 00:15:45.430
<v Speaker 1>right?</v>
<v Speaker 1>But some part of your brain is tracking </v>

348
00:15:45.430 --> 00:15:45.430
<v Speaker 1>the whole world around you,</v>
<v Speaker 1>right?</v>

349
00:15:45.480 --> 00:15:47.000
<v Speaker 1>Um,</v>
<v Speaker 1>and how many people are behind you?</v>

350
00:15:49.100 --> 00:15:50.090
<v Speaker 1>Yeah,</v>
<v Speaker 1>like a few hundred,</v>

351
00:15:50.091 --> 00:15:50.360
<v Speaker 1>right?</v>
<v Speaker 1>I mean,</v>

352
00:15:50.361 --> 00:15:53.510
<v Speaker 1>I don't know if it's 200 or $300,</v>
<v Speaker 1>but it's not a thousand.</v>

353
00:15:54.200 --> 00:15:55.450
<v Speaker 1>I don't think so.</v>
<v Speaker 1>Um,</v>

354
00:15:55.490 --> 00:15:58.460
<v Speaker 1>and it's certainly not 10 or 20 or 50.</v>
<v Speaker 1>Right?</v>

355
00:15:58.550 --> 00:16:01.970
<v Speaker 1>So you track these things and you use </v>
<v Speaker 1>them to plan your actions.</v>

356
00:16:02.630 --> 00:16:03.320
<v Speaker 1>Okay.</v>
<v Speaker 1>So again,</v>

357
00:16:03.770 --> 00:16:06.980
<v Speaker 1>think about how instantly,</v>
<v Speaker 1>effortlessly and very reliably,</v>

358
00:16:07.160 --> 00:16:09.170
<v Speaker 1>okay,</v>
<v Speaker 1>your brain computes all these things.</v>

359
00:16:09.171 --> 00:16:12.350
<v Speaker 1>So the people and objects around you.</v>
<v Speaker 1>And it's not just,</v>

360
00:16:12.570 --> 00:16:17.570
<v Speaker 1>you know,</v>
<v Speaker 1>approximations certainly when we're </v>

361
00:16:17.570 --> 00:16:17.570
<v Speaker 1>talking about what's,</v>
<v Speaker 1>what's behind you in space,</v>

362
00:16:17.570 --> 00:16:19.640
<v Speaker 1>there's a lot of imprecision,</v>
<v Speaker 1>but when it comes to reaching for things</v>

363
00:16:19.641 --> 00:16:22.880
<v Speaker 1>right in front of you,</v>
<v Speaker 1>very precise shape and physical property</v>

364
00:16:22.881 --> 00:16:25.160
<v Speaker 1>estimates needed to pick up and </v>
<v Speaker 1>manipulate objects.</v>

365
00:16:25.340 --> 00:16:30.340
<v Speaker 1>And then when it comes to people,</v>
<v Speaker 1>it's not just the existence of the </v>

366
00:16:30.340 --> 00:16:30.340
<v Speaker 1>people but something about what's in </v>
<v Speaker 1>their head,</v>

367
00:16:30.340 --> 00:16:35.020
<v Speaker 1>right?</v>
<v Speaker 1>You track whether someone's paying </v>

368
00:16:35.020 --> 00:16:35.020
<v Speaker 1>attention to you and you're talking to </v>
<v Speaker 1>them,</v>

369
00:16:35.020 --> 00:16:35.600
<v Speaker 1>what they might want from you,</v>
<v Speaker 1>what they might be thinking about you,</v>

370
00:16:35.690 --> 00:16:37.550
<v Speaker 1>what they might be thinking about other </v>
<v Speaker 1>people.</v>

371
00:16:37.730 --> 00:16:42.730
<v Speaker 1>Okay?</v>
<v Speaker 1>So when we talk about visual </v>

372
00:16:42.730 --> 00:16:44.561
<v Speaker 1>intelligence,</v>
<v Speaker 1>this is the whole stuff we're talking </v>

373
00:16:44.561 --> 00:16:45.820
<v Speaker 1>about and you can start to see how it </v>
<v Speaker 1>turns into basic questions I think of,</v>

374
00:16:46.020 --> 00:16:51.020
<v Speaker 1>of,</v>
<v Speaker 1>of what we might call the beginnings of </v>

375
00:16:51.020 --> 00:16:53.381
<v Speaker 1>consciousness or at least our awareness </v>
<v Speaker 1>of ourself in the world and of ourselves</v>

376
00:16:53.721 --> 00:16:58.721
<v Speaker 1>as a self in the world,</v>
<v Speaker 1>but also other aspects of higher level </v>

377
00:16:58.721 --> 00:17:00.290
<v Speaker 1>intelligence and cognition that are not </v>
<v Speaker 1>just about perception like symbols,</v>

378
00:17:00.440 --> 00:17:02.690
<v Speaker 1>right?</v>
<v Speaker 1>To describe even to ourselves,</v>

379
00:17:03.050 --> 00:17:05.810
<v Speaker 1>what's around us and where we are.</v>
<v Speaker 1>And what we can do with it,</v>

380
00:17:05.960 --> 00:17:10.960
<v Speaker 1>you have to go beyond just what we would</v>
<v Speaker 1>normally call the stuff that perception </v>

381
00:17:10.960 --> 00:17:13.280
<v Speaker 1>to to say the thoughts in somebody's </v>
<v Speaker 1>head in your own thoughts about that.</v>

382
00:17:13.550 --> 00:17:18.550
<v Speaker 1>Okay.</v>
<v Speaker 1>So what we've been doing in CBMM is </v>

383
00:17:18.550 --> 00:17:20.440
<v Speaker 1>trying to develop an architecture for </v>
<v Speaker 1>visual intelligence and I'm not going to</v>

384
00:17:20.441 --> 00:17:23.180
<v Speaker 1>go into any of the details of how this </v>
<v Speaker 1>works and this is just notional.</v>

385
00:17:23.180 --> 00:17:24.740
<v Speaker 1>This is just a picture.</v>
<v Speaker 1>It's like a just a,</v>

386
00:17:24.960 --> 00:17:27.740
<v Speaker 1>a sketch from a grant proposal of what </v>
<v Speaker 1>we say we want to do,</v>

387
00:17:27.920 --> 00:17:32.060
<v Speaker 1>but it's based on a lot of scientific </v>
<v Speaker 1>understanding of how the brain works.</v>

388
00:17:32.061 --> 00:17:37.061
<v Speaker 1>There are different parts of the brain </v>
<v Speaker 1>that correspond to these different </v>

389
00:17:37.061 --> 00:17:38.570
<v Speaker 1>modules in our architecture as well as </v>
<v Speaker 1>some kind of emerging engineering way to</v>

390
00:17:38.571 --> 00:17:41.890
<v Speaker 1>try to capture at the software and maybe</v>
<v Speaker 1>even hardware levels,</v>

391
00:17:41.900 --> 00:17:46.900
<v Speaker 1>how these modules might work.</v>
<v Speaker 1>So we talk about a sort of an early </v>

392
00:17:46.900 --> 00:17:49.991
<v Speaker 1>module of a visual or perceptual stream,</v>
<v Speaker 1>which is like bottom up visual or other </v>

393
00:17:49.991 --> 00:17:54.231
<v Speaker 1>perceptual input.</v>
<v Speaker 1>That's the kind of thing that is pretty </v>

394
00:17:54.231 --> 00:17:55.440
<v Speaker 1>close to what we currently have and say </v>
<v Speaker 1>deep convolutional neural networks.</v>

395
00:17:55.950 --> 00:18:00.950
<v Speaker 1>But then we talk about some kind of the </v>
<v Speaker 1>output of that isn't just pattern class </v>

396
00:18:00.950 --> 00:18:02.310
<v Speaker 1>labels,</v>
<v Speaker 1>but what we call the cognitive core core</v>

397
00:18:02.311 --> 00:18:02.940
<v Speaker 1>cognition.</v>

398
00:18:03.120 --> 00:18:05.520
<v Speaker 1>So we get an understanding of space and </v>
<v Speaker 1>objects,</v>

399
00:18:05.670 --> 00:18:07.320
<v Speaker 1>their physics,</v>
<v Speaker 1>other people,</v>

400
00:18:07.321 --> 00:18:09.810
<v Speaker 1>their minds.</v>
<v Speaker 1>That's the real stuff of cognition.</v>

401
00:18:09.811 --> 00:18:13.620
<v Speaker 1>That has to be the output of perception.</v>
<v Speaker 1>But somehow we have to,</v>

402
00:18:13.710 --> 00:18:14.670
<v Speaker 1>we have,</v>
<v Speaker 1>we have to have,</v>

403
00:18:14.700 --> 00:18:16.920
<v Speaker 1>this is what we call the brain ostp in </v>
<v Speaker 1>this picture.</v>

404
00:18:17.160 --> 00:18:22.160
<v Speaker 1>We have to get there by stitching </v>
<v Speaker 1>together the bottom up inputs from a </v>

405
00:18:22.160 --> 00:18:22.160
<v Speaker 1>glimpse here,</v>
<v Speaker 1>a glimpse here,</v>

406
00:18:22.160 --> 00:18:24.900
<v Speaker 1>a little bit here and there,</v>
<v Speaker 1>and accessing prior knowledge that comes</v>

407
00:18:24.901 --> 00:18:29.520
<v Speaker 1>from our memory systems to tell us how </v>
<v Speaker 1>to stitch these things together into the</v>

408
00:18:29.521 --> 00:18:32.430
<v Speaker 1>really core cognitive representations of</v>
<v Speaker 1>what's out there in the world.</v>

409
00:18:32.760 --> 00:18:37.760
<v Speaker 1>And then if we're going to start to talk</v>
<v Speaker 1>about it in language or to build plans </v>

410
00:18:37.770 --> 00:18:40.620
<v Speaker 1>on top of what we have seen and </v>
<v Speaker 1>understood,</v>

411
00:18:40.830 --> 00:18:43.440
<v Speaker 1>that's where we talk about symbols </v>
<v Speaker 1>coming into the picture.</v>

412
00:18:44.180 --> 00:18:49.180
<v Speaker 1>Okay.</v>
<v Speaker 1>The building blocks of language and </v>

413
00:18:49.180 --> 00:18:49.180
<v Speaker 1>plans and so on.</v>

414
00:18:49.180 --> 00:18:49.180
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

415
00:18:49.350 --> 00:18:50.610
<v Speaker 1>so now we might say,</v>
<v Speaker 1>well,</v>

416
00:18:50.611 --> 00:18:55.611
<v Speaker 1>okay,</v>
<v Speaker 1>this is an architecture that is brain </v>

417
00:18:55.611 --> 00:18:57.921
<v Speaker 1>inspired and cognitively inspired and,</v>
<v Speaker 1>and we're planning to turn into real </v>

418
00:18:57.921 --> 00:18:58.110
<v Speaker 1>engineering and you can say,</v>
<v Speaker 1>well,</v>

419
00:18:58.111 --> 00:18:59.310
<v Speaker 1>do we need that?</v>
<v Speaker 1>Maybe,</v>

420
00:18:59.311 --> 00:18:59.730
<v Speaker 1>you know,</v>
<v Speaker 1>again,</v>

421
00:18:59.760 --> 00:19:02.220
<v Speaker 1>I know this is a question you consider </v>
<v Speaker 1>it in the first lecture,</v>

422
00:19:02.430 --> 00:19:07.430
<v Speaker 1>maybe the engineering tool kit that's </v>
<v Speaker 1>currently been making a lot of progress </v>

423
00:19:07.430 --> 00:19:08.550
<v Speaker 1>in let's say industry.</v>
<v Speaker 1>Maybe that's good enough.</v>

424
00:19:08.551 --> 00:19:10.500
<v Speaker 1>Maybe you know,</v>
<v Speaker 1>let's take deep learning,</v>

425
00:19:10.501 --> 00:19:15.501
<v Speaker 1>but to stand for a broader set of modern</v>
<v Speaker 1>pattern recognition based on </v>

426
00:19:15.501 --> 00:19:16.620
<v Speaker 1>reinforcement learning based tools and </v>
<v Speaker 1>say,</v>

427
00:19:16.621 --> 00:19:17.700
<v Speaker 1>okay,</v>
<v Speaker 1>well maybe,</v>

428
00:19:18.150 --> 00:19:21.090
<v Speaker 1>uh,</v>
<v Speaker 1>that can scale up to this and you might,</v>

429
00:19:21.140 --> 00:19:22.830
<v Speaker 1>you know,</v>
<v Speaker 1>maybe that's possible.</v>

430
00:19:22.831 --> 00:19:24.930
<v Speaker 1>I'm happy in the question period of </v>
<v Speaker 1>people want to debate this.</v>

431
00:19:24.931 --> 00:19:26.700
<v Speaker 1>My sense is no.</v>
<v Speaker 1>Um,</v>

432
00:19:26.701 --> 00:19:28.150
<v Speaker 1>I think that,</v>
<v Speaker 1>um,</v>

433
00:19:28.200 --> 00:19:29.490
<v Speaker 1>it's not a.</v>
<v Speaker 1>When I say no,</v>

434
00:19:29.491 --> 00:19:32.280
<v Speaker 1>I don't mean like it,</v>
<v Speaker 1>it can't happen or it won't happen.</v>

435
00:19:32.460 --> 00:19:37.460
<v Speaker 1>What I mean is the highest value,</v>
<v Speaker 1>the highest expected route right now is </v>

436
00:19:37.460 --> 00:19:38.820
<v Speaker 1>to take this more science based reverse </v>
<v Speaker 1>engineering approach.</v>

437
00:19:39.330 --> 00:19:44.330
<v Speaker 1>And that if at least if you follow the </v>
<v Speaker 1>current trajectory that industry </v>

438
00:19:44.330 --> 00:19:48.171
<v Speaker 1>incentives especially optimize for,</v>
<v Speaker 1>it's not even really trying to take us </v>

439
00:19:48.171 --> 00:19:48.690
<v Speaker 1>to these things.</v>
<v Speaker 1>So think about,</v>

440
00:19:48.691 --> 00:19:51.720
<v Speaker 1>for example,</v>
<v Speaker 1>a case study of visual intelligence that</v>

441
00:19:51.721 --> 00:19:54.780
<v Speaker 1>is in some ways as pattern recognition,</v>
<v Speaker 1>very much of a success.</v>

442
00:19:54.810 --> 00:19:56.820
<v Speaker 1>It's again been mostly driven by </v>
<v Speaker 1>industry.</v>

443
00:19:57.150 --> 00:20:01.230
<v Speaker 1>It's something that if you read in the </v>
<v Speaker 1>news or even play around with in certain</v>

444
00:20:01.510 --> 00:20:04.740
<v Speaker 1>publicly available data sets,</v>
<v Speaker 1>feels like we've made great progress.</v>

445
00:20:04.890 --> 00:20:06.990
<v Speaker 1>And this is an aspect of visual </v>
<v Speaker 1>intelligence,</v>

446
00:20:07.140 --> 00:20:09.390
<v Speaker 1>which is sometimes called image </v>
<v Speaker 1>captioning.</v>

447
00:20:09.620 --> 00:20:12.860
<v Speaker 1>It's bay or mapping images to text.</v>
<v Speaker 1>Um,</v>

448
00:20:13.240 --> 00:20:18.240
<v Speaker 1>you know,</v>
<v Speaker 1>basically there's been a bunch of </v>

449
00:20:18.240 --> 00:20:18.240
<v Speaker 1>systems.</v>
<v Speaker 1>Here's a couple of press releases.</v>

450
00:20:18.240 --> 00:20:18.240
<v Speaker 1>I guess this one's about Google.</v>

451
00:20:18.450 --> 00:20:21.330
<v Speaker 1>Google's Ai can now capture images </v>
<v Speaker 1>almost as well as humans.</v>

452
00:20:21.610 --> 00:20:23.250
<v Speaker 1>Um,</v>
<v Speaker 1>here's ones about Microsoft.</v>

453
00:20:23.500 --> 00:20:26.170
<v Speaker 1>Um,</v>
<v Speaker 1>a couple of years ago I think there were</v>

454
00:20:26.171 --> 00:20:31.171
<v Speaker 1>something like eight papers all released</v>
<v Speaker 1>on to archive around the same time from </v>

455
00:20:31.171 --> 00:20:34.761
<v Speaker 1>basically all the major industry </v>
<v Speaker 1>computer vision groups as well as a </v>

456
00:20:34.761 --> 00:20:34.761
<v Speaker 1>couple of academic partners.</v>
<v Speaker 1>Okay.</v>

457
00:20:35.100 --> 00:20:40.100
<v Speaker 1>Which all driven by basically the same </v>
<v Speaker 1>dataset produced by some Microsoft </v>

458
00:20:40.100 --> 00:20:41.310
<v Speaker 1>researchers.</v>
<v Speaker 1>And other collaborators,</v>

459
00:20:41.630 --> 00:20:44.910
<v Speaker 1>I'm trained a combination of deep </v>
<v Speaker 1>convolutional neural networks,</v>

460
00:20:44.911 --> 00:20:45.690
<v Speaker 1>you know,</v>
<v Speaker 1>state of the art,</v>

461
00:20:45.691 --> 00:20:48.370
<v Speaker 1>visual pattern recognition with </v>
<v Speaker 1>recurrent neural networks,</v>

462
00:20:48.371 --> 00:20:50.660
<v Speaker 1>which had recently been developed for,</v>
<v Speaker 1>you know,</v>

463
00:20:50.680 --> 00:20:53.080
<v Speaker 1>basically kinds of neural statistical </v>
<v Speaker 1>language modeling,</v>

464
00:20:53.320 --> 00:20:55.300
<v Speaker 1>glued them together and produce the </v>
<v Speaker 1>system which,</v>

465
00:20:55.330 --> 00:21:00.330
<v Speaker 1>which,</v>
<v Speaker 1>which made very impressive results in a </v>

466
00:21:00.330 --> 00:21:03.151
<v Speaker 1>big training set and a held out test set</v>
<v Speaker 1>where the goal was to take an image and </v>

467
00:21:03.151 --> 00:21:07.351
<v Speaker 1>write a sentence like short sentence </v>
<v Speaker 1>caption that that would seem like the </v>

468
00:21:07.351 --> 00:21:08.950
<v Speaker 1>kind of way a human would describe that </v>
<v Speaker 1>image.</v>

469
00:21:09.580 --> 00:21:14.580
<v Speaker 1>And these systems have surpassed human </v>
<v Speaker 1>level accuracy on the held out test set </v>

470
00:21:14.580 --> 00:21:17.110
<v Speaker 1>from a big training center.</v>
<v Speaker 1>But what you can see when you really dig</v>

471
00:21:17.111 --> 00:21:22.111
<v Speaker 1>into these things is there's often a lot</v>
<v Speaker 1>of what I would call Dataset </v>

472
00:21:22.111 --> 00:21:22.380
<v Speaker 1>overfitting.</v>
<v Speaker 1>It's not overfitting to the trainings,</v>

473
00:21:22.750 --> 00:21:27.750
<v Speaker 1>but it's overfitting to whatever are the</v>
<v Speaker 1>particular characteristics of this data </v>

474
00:21:27.750 --> 00:21:27.750
<v Speaker 1>set.</v>
<v Speaker 1>You know,</v>

475
00:21:27.750 --> 00:21:31.950
<v Speaker 1>wherever or wherever it came from.</v>
<v Speaker 1>Certain set of photographs in certain </v>

476
00:21:31.950 --> 00:21:32.020
<v Speaker 1>ways of captioning them.</v>
<v Speaker 1>Okay.</v>

477
00:21:32.080 --> 00:21:34.210
<v Speaker 1>Which even a big Dataset,</v>
<v Speaker 1>um,</v>

478
00:21:34.300 --> 00:21:39.300
<v Speaker 1>it's not about quantity.</v>
<v Speaker 1>It's more about the quality of the </v>

479
00:21:39.300 --> 00:21:39.300
<v Speaker 1>nature of what people are doing.</v>
<v Speaker 1>All right.</v>

480
00:21:39.300 --> 00:21:44.300
<v Speaker 1>Um,</v>
<v Speaker 1>so one way to test this system is to </v>

481
00:21:44.300 --> 00:21:46.760
<v Speaker 1>apply it to what seems like basically </v>
<v Speaker 1>the same problem but not within the,</v>

482
00:21:46.870 --> 00:21:51.870
<v Speaker 1>a certain curated or built dataset.</v>
<v Speaker 1>And there's a convenient a twitter bot </v>

483
00:21:51.870 --> 00:21:55.921
<v Speaker 1>that lets you do this.</v>
<v Speaker 1>So there's something called the pick </v>

484
00:21:55.921 --> 00:21:58.261
<v Speaker 1>desk bought,</v>
<v Speaker 1>which takes one of the state of the art </v>

485
00:21:58.261 --> 00:21:58.261
<v Speaker 1>industry.</v>

486
00:21:58.261 --> 00:21:58.261
<v Speaker 1>Ai captioning systems.</v>
<v Speaker 1>A very good one.</v>

487
00:21:58.261 --> 00:21:59.410
<v Speaker 1>Again,</v>
<v Speaker 1>this is not meant to.</v>

488
00:21:59.710 --> 00:22:02.290
<v Speaker 1>I'm not trying to critique these systems</v>
<v Speaker 1>for what they're trying to do.</v>

489
00:22:02.291 --> 00:22:04.600
<v Speaker 1>I'm just trying to point out what they </v>
<v Speaker 1>don't really even try to do.</v>

490
00:22:04.930 --> 00:22:09.930
<v Speaker 1>So this takes the Microsoft caption </v>
<v Speaker 1>bought and just every couple of hours </v>

491
00:22:09.930 --> 00:22:14.551
<v Speaker 1>takes a random image from the web,</v>
<v Speaker 1>captions it and uploads the results to </v>

492
00:22:14.551 --> 00:22:18.091
<v Speaker 1>twitter.</v>
<v Speaker 1>And a couple of months ago when I </v>

493
00:22:18.091 --> 00:22:20.041
<v Speaker 1>prepared a first version of this talk,</v>
<v Speaker 1>I just took a few days in the life of </v>

494
00:22:20.041 --> 00:22:21.250
<v Speaker 1>this twitter Bot.</v>
<v Speaker 1>I didn't take every single image,</v>

495
00:22:21.530 --> 00:22:22.430
<v Speaker 1>but I took,</v>
<v Speaker 1>you know,</v>

496
00:22:22.630 --> 00:22:27.630
<v Speaker 1>most of the images in a way that was </v>
<v Speaker 1>meant to be representative of the </v>

497
00:22:27.630 --> 00:22:30.511
<v Speaker 1>successes.</v>
<v Speaker 1>And the kinds of failures that such a </v>

498
00:22:30.511 --> 00:22:32.701
<v Speaker 1>system will make so we can go through </v>
<v Speaker 1>this and it's a little bit entertaining </v>

499
00:22:32.701 --> 00:22:35.821
<v Speaker 1>and I think quite informative.</v>
<v Speaker 1>So here's just a somewhat random sample </v>

500
00:22:35.821 --> 00:22:38.710
<v Speaker 1>of a few days in the life of one of </v>
<v Speaker 1>these caption bots.</v>

501
00:22:39.220 --> 00:22:42.220
<v Speaker 1>So here we have a picture of a person </v>
<v Speaker 1>holding.</v>

502
00:22:42.430 --> 00:22:45.010
<v Speaker 1>Fortunately my screen is very small here</v>
<v Speaker 1>and I can't read up there,</v>

503
00:22:45.011 --> 00:22:46.130
<v Speaker 1>so maybe you'll have to tell me what </v>
<v Speaker 1>sets,</v>

504
00:22:46.170 --> 00:22:48.940
<v Speaker 1>but a person holding a cell phone.</v>
<v Speaker 1>I guess I'll just read along with you.</v>

505
00:22:49.090 --> 00:22:50.290
<v Speaker 1>So you have a person holding a cell </v>
<v Speaker 1>phone.</v>

506
00:22:50.291 --> 00:22:51.760
<v Speaker 1>Well,</v>
<v Speaker 1>it's not a person holding a cell phone,</v>

507
00:22:51.790 --> 00:22:56.790
<v Speaker 1>but it's kind of close.</v>
<v Speaker 1>It's a person holding some kind of </v>

508
00:22:56.790 --> 00:22:56.790
<v Speaker 1>machine to.</v>
<v Speaker 1>I don't even know what that is,</v>

509
00:22:56.790 --> 00:22:57.580
<v Speaker 1>but it's some kind of musical </v>
<v Speaker 1>instrument,</v>

510
00:22:57.640 --> 00:22:58.630
<v Speaker 1>right?</v>
<v Speaker 1>Um,</v>

511
00:22:59.590 --> 00:23:02.770
<v Speaker 1>so that's a mixed success or failure.</v>
<v Speaker 1>Here's a pretty good one.</v>

512
00:23:02.771 --> 00:23:05.140
<v Speaker 1>A group of people on a,</v>
<v Speaker 1>on a field playing football.</v>

513
00:23:05.320 --> 00:23:06.490
<v Speaker 1>That's,</v>
<v Speaker 1>I would call that a,</v>

514
00:23:06.550 --> 00:23:07.780
<v Speaker 1>you know,</v>
<v Speaker 1>a result,</v>

515
00:23:08.290 --> 00:23:09.910
<v Speaker 1>maybe even a plus.</v>
<v Speaker 1>Um,</v>

516
00:23:09.930 --> 00:23:12.640
<v Speaker 1>here's a group of people standing on top</v>
<v Speaker 1>of a mountain.</v>

517
00:23:12.760 --> 00:23:17.760
<v Speaker 1>So less good there was a mountain,</v>
<v Speaker 1>but as far as I can tell there's no </v>

518
00:23:17.760 --> 00:23:20.131
<v Speaker 1>people,</v>
<v Speaker 1>but these systems like to see people </v>

519
00:23:20.131 --> 00:23:20.230
<v Speaker 1>because of both the combination because </v>
<v Speaker 1>in the data set they were trained on,</v>

520
00:23:20.231 --> 00:23:22.270
<v Speaker 1>there's a lot of people and people often</v>
<v Speaker 1>talk about people.</v>

521
00:23:22.410 --> 00:23:27.410
<v Speaker 1>Okay.</v>
<v Speaker 1>And the fact that you can appreciate </v>

522
00:23:27.410 --> 00:23:28.590
<v Speaker 1>both what I said and why it's funny.</v>
<v Speaker 1>That's there.</v>

523
00:23:28.710 --> 00:23:33.710
<v Speaker 1>You did some of my cognitive activities </v>
<v Speaker 1>that the system is not even trying to </v>

524
00:23:33.710 --> 00:23:33.710
<v Speaker 1>do.</v>
<v Speaker 1>Okay.</v>

525
00:23:33.710 --> 00:23:35.860
<v Speaker 1>Here we've got a building with a cake.</v>
<v Speaker 1>I'll go through these fast building with</v>

526
00:23:35.861 --> 00:23:40.861
<v Speaker 1>a cake,</v>
<v Speaker 1>a large stone building with the clock </v>

527
00:23:40.861 --> 00:23:40.861
<v Speaker 1>tower.</v>
<v Speaker 1>I think that's pretty good.</v>

528
00:23:40.861 --> 00:23:41.440
<v Speaker 1>I'd give that like a b plus.</v>
<v Speaker 1>There's no clock,</v>

529
00:23:41.620 --> 00:23:44.290
<v Speaker 1>but it's plausibly right.</v>
<v Speaker 1>There might be a clock in there.</v>

530
00:23:44.291 --> 00:23:49.291
<v Speaker 1>There's definitely something like that.</v>
<v Speaker 1>Here's a truck parked on the side of a </v>

531
00:23:49.291 --> 00:23:49.291
<v Speaker 1>building.</v>
<v Speaker 1>I don't know,</v>

532
00:23:49.291 --> 00:23:53.231
<v Speaker 1>maybe a b minus.</v>
<v Speaker 1>There is a car on the side of a </v>

533
00:23:53.231 --> 00:23:53.231
<v Speaker 1>building,</v>
<v Speaker 1>but it's not a truck and it's.</v>

534
00:23:53.231 --> 00:23:54.980
<v Speaker 1>And it's not.</v>
<v Speaker 1>Doesn't seem like the main thing and the</v>

535
00:23:54.981 --> 00:23:55.740
<v Speaker 1>image.</v>
<v Speaker 1>Okay.</v>

536
00:23:56.330 --> 00:24:01.330
<v Speaker 1>Here's a necklace made of bananas.</v>
<v Speaker 1>Here's a large ship in the water.</v>

537
00:24:01.760 --> 00:24:06.760
<v Speaker 1>This is pretty good.</v>
<v Speaker 1>I give this like an a minus or b plus </v>

538
00:24:06.760 --> 00:24:07.070
<v Speaker 1>because there is a ship in the water,</v>
<v Speaker 1>but it's not very large.</v>

539
00:24:07.071 --> 00:24:08.720
<v Speaker 1>It's really more of like a tug boat or </v>
<v Speaker 1>something.</v>

540
00:24:09.320 --> 00:24:10.910
<v Speaker 1>Here's a sign sitting on the grass,</v>
<v Speaker 1>you know,</v>

541
00:24:10.911 --> 00:24:12.510
<v Speaker 1>in some sense that's great.</v>
<v Speaker 1>No,</v>

542
00:24:12.520 --> 00:24:13.700
<v Speaker 1>but,</v>
<v Speaker 1>but in another sense,</v>

543
00:24:13.701 --> 00:24:16.550
<v Speaker 1>it's really missing what's actually </v>
<v Speaker 1>interesting and important and meaningful</v>

544
00:24:16.551 --> 00:24:18.000
<v Speaker 1>to humans.</v>
<v Speaker 1>Um,</v>

545
00:24:18.530 --> 00:24:19.310
<v Speaker 1>here's a,</v>
<v Speaker 1>uh,</v>

546
00:24:20.660 --> 00:24:25.070
<v Speaker 1>here's a garden is in the dirt,</v>
<v Speaker 1>a pizza sitting on top of a building,</v>

547
00:24:25.640 --> 00:24:27.830
<v Speaker 1>a small house with a red brick building.</v>
<v Speaker 1>That's pretty good.</v>

548
00:24:27.831 --> 00:24:29.210
<v Speaker 1>Although it kind of weird way of saying </v>
<v Speaker 1>it.</v>

549
00:24:29.510 --> 00:24:31.190
<v Speaker 1>A vintage photo of a pond.</v>
<v Speaker 1>That's good.</v>

550
00:24:31.250 --> 00:24:36.250
<v Speaker 1>They liked vintage photos.</v>
<v Speaker 1>A group of people that are standing in </v>

551
00:24:36.250 --> 00:24:36.250
<v Speaker 1>the grass near bridge.</v>
<v Speaker 1>Again,</v>

552
00:24:36.250 --> 00:24:36.800
<v Speaker 1>there's two people and there's some </v>
<v Speaker 1>grass and there was a bridge,</v>

553
00:24:36.801 --> 00:24:38.870
<v Speaker 1>but it's really not what's going on.</v>

554
00:24:39.610 --> 00:24:41.330
<v Speaker 1>A person in the yard.</v>
<v Speaker 1>Okay.</v>

555
00:24:41.500 --> 00:24:42.600
<v Speaker 1>Kind of,</v>
<v Speaker 1>um,</v>

556
00:24:42.601 --> 00:24:44.270
<v Speaker 1>a group of people standing on top of the</v>
<v Speaker 1>boat.</v>

557
00:24:44.271 --> 00:24:49.271
<v Speaker 1>There's a boat,</v>
<v Speaker 1>there's a group of people there </v>

558
00:24:49.271 --> 00:24:49.271
<v Speaker 1>standing.</v>
<v Speaker 1>But again,</v>

559
00:24:49.271 --> 00:24:51.761
<v Speaker 1>it's the sentence that you see is,</v>
<v Speaker 1>is more based on a bias of what people </v>

560
00:24:51.761 --> 00:24:54.650
<v Speaker 1>have said in the past about images that </v>
<v Speaker 1>are only vaguely like this.</v>

561
00:24:55.120 --> 00:24:57.170
<v Speaker 1>A clock tower lit up at night.</v>
<v Speaker 1>That's really,</v>

562
00:24:57.171 --> 00:24:58.220
<v Speaker 1>I think,</v>
<v Speaker 1>pretty impressive.</v>

563
00:24:58.600 --> 00:25:01.070
<v Speaker 1>A large clock mounted to the side of a </v>
<v Speaker 1>building a little bit less.</v>

564
00:25:01.071 --> 00:25:05.540
<v Speaker 1>So a snow covered feel very good.</v>
<v Speaker 1>A building with snow on the ground.</v>

565
00:25:05.810 --> 00:25:07.830
<v Speaker 1>A little bit less good.</v>
<v Speaker 1>There's no snow white.</v>

566
00:25:08.600 --> 00:25:13.600
<v Speaker 1>Some people who I don't know them,</v>
<v Speaker 1>but I bet that's probably right because </v>

567
00:25:13.600 --> 00:25:17.021
<v Speaker 1>face identifying faces and recognizing </v>
<v Speaker 1>people who are famous because they won </v>

568
00:25:17.021 --> 00:25:20.710
<v Speaker 1>medals in the Olympics.</v>
<v Speaker 1>Probably I would trust current pattern </v>

569
00:25:20.710 --> 00:25:20.710
<v Speaker 1>recognition systems to get that.</v>

570
00:25:20.710 --> 00:25:22.430
<v Speaker 1>A painting of a vase in front of a </v>
<v Speaker 1>mirror.</v>

571
00:25:22.710 --> 00:25:25.100
<v Speaker 1>I'm less good.</v>
<v Speaker 1>Also a famous person there,</v>

572
00:25:25.101 --> 00:25:28.880
<v Speaker 1>but we didn't get him a person walking </v>
<v Speaker 1>in the rain.</v>

573
00:25:28.910 --> 00:25:33.910
<v Speaker 1>Again,</v>
<v Speaker 1>there is sort of a person and there's </v>

574
00:25:33.910 --> 00:25:33.910
<v Speaker 1>some puddles but not,</v>
<v Speaker 1>you know,</v>

575
00:25:33.910 --> 00:25:38.740
<v Speaker 1>a group of stuffed animals.</v>
<v Speaker 1>A car parked in a parking lot that's </v>

576
00:25:38.740 --> 00:25:40.580
<v Speaker 1>good.</v>
<v Speaker 1>A car parked in front of a building.</v>

577
00:25:41.540 --> 00:25:43.610
<v Speaker 1>Less good.</v>
<v Speaker 1>A plate with a fork and knife.</v>

578
00:25:44.090 --> 00:25:45.380
<v Speaker 1>A clear blue sky.</v>
<v Speaker 1>Okay,</v>

579
00:25:45.500 --> 00:25:50.500
<v Speaker 1>so you get the idea again,</v>
<v Speaker 1>like if you actually go and play with </v>

580
00:25:50.500 --> 00:25:50.750
<v Speaker 1>the system,</v>
<v Speaker 1>partly because I think Mike,</v>

581
00:25:50.770 --> 00:25:52.860
<v Speaker 1>but my friends at Microsoft told me </v>
<v Speaker 1>they've improved it.</v>

582
00:25:52.861 --> 00:25:53.720
<v Speaker 1>Some,</v>
<v Speaker 1>you know,</v>

583
00:25:54.000 --> 00:25:54.420
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

584
00:25:54.440 --> 00:25:56.550
<v Speaker 1>this is partly for entertainment value </v>
<v Speaker 1>is,</v>

585
00:25:56.551 --> 00:26:01.551
<v Speaker 1>you know,</v>
<v Speaker 1>I chose what also would be the fun here </v>

586
00:26:01.551 --> 00:26:01.551
<v Speaker 1>example.</v>
<v Speaker 1>So I'm clear,</v>

587
00:26:01.551 --> 00:26:01.551
<v Speaker 1>I want to be quite honest about this and</v>
<v Speaker 1>these are.</v>

588
00:26:01.551 --> 00:26:04.760
<v Speaker 1>I'm not trying to take away what are </v>
<v Speaker 1>impressive ai technologies,</v>

589
00:26:05.270 --> 00:26:10.270
<v Speaker 1>but I think it's clear that there's a </v>
<v Speaker 1>sense of understanding any one of these </v>

590
00:26:10.270 --> 00:26:12.410
<v Speaker 1>images that it's important to see that </v>
<v Speaker 1>even when it seems to be correct,</v>

591
00:26:12.650 --> 00:26:13.040
<v Speaker 1>right?</v>

592
00:26:13.070 --> 00:26:15.170
<v Speaker 1>If it can make the kind of errors that </v>
<v Speaker 1>it makes,</v>

593
00:26:15.650 --> 00:26:20.650
<v Speaker 1>that even when it seems to be correct,</v>
<v Speaker 1>it's probably not doing what you're </v>

594
00:26:20.650 --> 00:26:23.771
<v Speaker 1>doing and it's probably not even trying </v>
<v Speaker 1>to seel towards the dimensions of </v>

595
00:26:23.771 --> 00:26:25.640
<v Speaker 1>intelligence that we think about when </v>
<v Speaker 1>we're talking about human intelligence.</v>

596
00:26:25.670 --> 00:26:27.290
<v Speaker 1>Okay.</v>
<v Speaker 1>Another way to put this,</v>

597
00:26:27.480 --> 00:26:32.480
<v Speaker 1>I'm going to show you a really </v>
<v Speaker 1>insightful blog post from one of your </v>

598
00:26:32.480 --> 00:26:32.480
<v Speaker 1>other speakers.</v>
<v Speaker 1>So,</v>

599
00:26:32.480 --> 00:26:32.750
<v Speaker 1>uh,</v>
<v Speaker 1>in a couple of days,</v>

600
00:26:32.751 --> 00:26:36.020
<v Speaker 1>I'm not sure you're going to have Andre </v>
<v Speaker 1>carpathy who's one of the leading people</v>

601
00:26:36.440 --> 00:26:39.830
<v Speaker 1>in deep learning.</v>
<v Speaker 1>This is a really great blog post.</v>

602
00:26:39.831 --> 00:26:42.470
<v Speaker 1>He wrote a couple of years ago when he </v>
<v Speaker 1>was,</v>

603
00:26:42.471 --> 00:26:45.120
<v Speaker 1>I think still at Stanford.</v>
<v Speaker 1>He got his phd from Stanford.</v>

604
00:26:45.121 --> 00:26:48.270
<v Speaker 1>He did.</v>
<v Speaker 1>He worked at Google a little bit on some</v>

605
00:26:48.330 --> 00:26:51.070
<v Speaker 1>early big neural net ai projects there.</v>
<v Speaker 1>Uh,</v>

606
00:26:51.150 --> 00:26:56.150
<v Speaker 1>he was at open Ai.</v>
<v Speaker 1>He was one of the founders of open ai </v>

607
00:26:56.150 --> 00:26:57.840
<v Speaker 1>and recently he joined Tesla as their </v>
<v Speaker 1>director of Ai Research.</v>

608
00:26:58.500 --> 00:27:03.500
<v Speaker 1>But about five years ago he was looking </v>
<v Speaker 1>at the state of computer vision from a </v>

609
00:27:03.500 --> 00:27:06.360
<v Speaker 1>human intelligence point of view and,</v>
<v Speaker 1>and lamenting how far away we were.</v>

610
00:27:06.361 --> 00:27:08.130
<v Speaker 1>Okay.</v>
<v Speaker 1>So this is the title of his blog posts,</v>

611
00:27:08.131 --> 00:27:10.170
<v Speaker 1>the state of computer vision and ai and </v>
<v Speaker 1>ai.</v>

612
00:27:10.370 --> 00:27:11.730
<v Speaker 1>We are really,</v>
<v Speaker 1>really far away.</v>

613
00:27:11.880 --> 00:27:16.880
<v Speaker 1>And he took this image which was a sort </v>
<v Speaker 1>of a famous image in its own right.</v>

614
00:27:16.891 --> 00:27:19.800
<v Speaker 1>It was a popular image of Obama back </v>
<v Speaker 1>when he was president,</v>

615
00:27:19.920 --> 00:27:22.170
<v Speaker 1>kind of playing around us.</v>
<v Speaker 1>He liked to do when he was on tour.</v>

616
00:27:22.171 --> 00:27:27.171
<v Speaker 1>So if you take a look at this,</v>
<v Speaker 1>you can see you probably all can </v>

617
00:27:27.171 --> 00:27:27.810
<v Speaker 1>recognize the previous president of the </v>
<v Speaker 1>United States,</v>

618
00:27:27.960 --> 00:27:32.960
<v Speaker 1>but you can also get the sense of where </v>
<v Speaker 1>he is and what's going on and you might </v>

619
00:27:32.960 --> 00:27:36.531
<v Speaker 1>see people smiling and you might get the</v>
<v Speaker 1>sense that he's playing a joke on </v>

620
00:27:36.531 --> 00:27:36.531
<v Speaker 1>someone.</v>

621
00:27:36.531 --> 00:27:36.531
<v Speaker 1>Can you see that?</v>
<v Speaker 1>Right?</v>

622
00:27:36.531 --> 00:27:39.210
<v Speaker 1>So how do you know that he's playing a </v>
<v Speaker 1>joke and what that joke is?</v>

623
00:27:39.810 --> 00:27:44.810
<v Speaker 1>Well,</v>
<v Speaker 1>as Andre goes on to talk about and his </v>

624
00:27:44.810 --> 00:27:44.810
<v Speaker 1>blog posts to,</v>
<v Speaker 1>if you think about all the things that,</v>

625
00:27:44.810 --> 00:27:49.610
<v Speaker 1>that you have to really deploy in your </v>
<v Speaker 1>mind to understand that it's a huge </v>

626
00:27:49.610 --> 00:27:53.961
<v Speaker 1>list.</v>
<v Speaker 1>Of course it starts with seeing people </v>

627
00:27:53.961 --> 00:27:53.961
<v Speaker 1>and objects and maybe doing some face </v>
<v Speaker 1>recognition,</v>

628
00:27:53.961 --> 00:27:55.080
<v Speaker 1>but you have to do things like,</v>
<v Speaker 1>for example,</v>

629
00:27:55.260 --> 00:28:00.260
<v Speaker 1>notice his foot on the scale and </v>
<v Speaker 1>understand enough about how scales work </v>

630
00:28:00.260 --> 00:28:04.071
<v Speaker 1>that when a foot presses down,</v>
<v Speaker 1>it exerts forest at the scale of </v>

631
00:28:04.071 --> 00:28:07.131
<v Speaker 1>sensitive,</v>
<v Speaker 1>doesn't just magically measure people's </v>

632
00:28:07.131 --> 00:28:07.131
<v Speaker 1>weight.</v>
<v Speaker 1>But it does that somehow through force.</v>

633
00:28:07.131 --> 00:28:09.150
<v Speaker 1>You have to see who can see that he's </v>
<v Speaker 1>doing that and who can't,</v>

634
00:28:09.180 --> 00:28:11.280
<v Speaker 1>who cannot see that he's doing that </v>
<v Speaker 1>right.</v>

635
00:28:11.281 --> 00:28:16.281
<v Speaker 1>And particularly the person on the scale</v>
<v Speaker 1>and why some people can see that he's </v>

636
00:28:16.281 --> 00:28:16.890
<v Speaker 1>doing that and can see that some other </v>
<v Speaker 1>people can't see it,</v>

637
00:28:17.040 --> 00:28:18.510
<v Speaker 1>why that makes it funny to them.</v>

638
00:28:18.710 --> 00:28:23.710
<v Speaker 1>Okay.</v>
<v Speaker 1>And someday we shouldn't have machines </v>

639
00:28:23.710 --> 00:28:25.260
<v Speaker 1>that can understand this,</v>
<v Speaker 1>but hopefully you can see why,</v>

640
00:28:25.261 --> 00:28:26.130
<v Speaker 1>what I,</v>
<v Speaker 1>what I,</v>

641
00:28:26.420 --> 00:28:31.420
<v Speaker 1>what,</v>
<v Speaker 1>what the kind of architecture that I'm </v>

642
00:28:31.420 --> 00:28:33.321
<v Speaker 1>talking about would be the building </v>
<v Speaker 1>blocks of the ingredients to be able to </v>

643
00:28:33.321 --> 00:28:34.640
<v Speaker 1>get them to do that.</v>
<v Speaker 1>Now I,</v>

644
00:28:34.860 --> 00:28:35.560
<v Speaker 1>when I,</v>
<v Speaker 1>again,</v>

645
00:28:35.561 --> 00:28:40.561
<v Speaker 1>I,</v>
<v Speaker 1>I prepared a version of this talk a few </v>

646
00:28:40.561 --> 00:28:42.650
<v Speaker 1>months ago and I wrote to Andre and I </v>
<v Speaker 1>said I was going to use this and I was </v>

647
00:28:42.650 --> 00:28:45.321
<v Speaker 1>curious if he,</v>
<v Speaker 1>what if he had any reflections on this </v>

648
00:28:45.321 --> 00:28:49.400
<v Speaker 1>and where he thought we were relative to</v>
<v Speaker 1>five years ago because certainly a lot </v>

649
00:28:49.400 --> 00:28:50.220
<v Speaker 1>of progress has been made,</v>
<v Speaker 1>but he said,</v>

650
00:28:50.221 --> 00:28:51.660
<v Speaker 1>here's this email.</v>
<v Speaker 1>Um,</v>

651
00:28:52.010 --> 00:28:53.460
<v Speaker 1>I hope he doesn't mind me sharing it,</v>
<v Speaker 1>but I mean,</v>

652
00:28:53.461 --> 00:28:55.260
<v Speaker 1>again,</v>
<v Speaker 1>he's a very honest person and that's one</v>

653
00:28:55.261 --> 00:28:58.320
<v Speaker 1>of the many reasons why he's such an </v>
<v Speaker 1>important person right now in ai.</v>

654
00:28:58.500 --> 00:29:03.500
<v Speaker 1>Okay.</v>
<v Speaker 1>He's both very technically strong and </v>

655
00:29:03.500 --> 00:29:03.500
<v Speaker 1>honest about what we can do,</v>
<v Speaker 1>but we can't do.</v>

656
00:29:03.500 --> 00:29:03.500
<v Speaker 1>And as he says,</v>
<v Speaker 1>but what does he say?</v>

657
00:29:03.500 --> 00:29:04.940
<v Speaker 1>It's nice to hear from you.</v>
<v Speaker 1>Uh,</v>

658
00:29:05.140 --> 00:29:07.420
<v Speaker 1>it's funny you should bring this up.</v>
<v Speaker 1>I was also thinking about writing a,</v>

659
00:29:07.930 --> 00:29:12.930
<v Speaker 1>a return to this and in short,</v>
<v Speaker 1>basically I don't believe we've made </v>

660
00:29:12.930 --> 00:29:12.930
<v Speaker 1>very much progress,</v>
<v Speaker 1>right?</v>

661
00:29:12.930 --> 00:29:17.450
<v Speaker 1>He points out that in his long list of </v>
<v Speaker 1>things that you need to understand the </v>

662
00:29:17.450 --> 00:29:18.480
<v Speaker 1>image we have made progress on some the </v>
<v Speaker 1>ability to again,</v>

663
00:29:18.590 --> 00:29:21.720
<v Speaker 1>the tech people and do face recognition </v>
<v Speaker 1>for well known individuals.</v>

664
00:29:21.780 --> 00:29:22.540
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

665
00:29:22.560 --> 00:29:24.810
<v Speaker 1>but that's kind of about it all right.</v>
<v Speaker 1>Um,</v>

666
00:29:24.830 --> 00:29:29.830
<v Speaker 1>and he wasn't particularly optimistic </v>
<v Speaker 1>that the current route that's being </v>

667
00:29:29.830 --> 00:29:32.751
<v Speaker 1>pursued and industry is,</v>
<v Speaker 1>is anywhere close to solving or even </v>

668
00:29:32.751 --> 00:29:33.690
<v Speaker 1>really trying to solve these larger </v>
<v Speaker 1>questions.</v>

669
00:29:34.240 --> 00:29:39.240
<v Speaker 1>Um,</v>
<v Speaker 1>if we give this image to that a </v>

670
00:29:39.240 --> 00:29:39.240
<v Speaker 1>captioned bought,</v>
<v Speaker 1>you know,</v>

671
00:29:39.240 --> 00:29:41.100
<v Speaker 1>what we see is again,</v>
<v Speaker 1>represents the same point.</v>

672
00:29:41.110 --> 00:29:42.370
<v Speaker 1>So here's the caption,</v>
<v Speaker 1>but it says,</v>

673
00:29:42.430 --> 00:29:45.610
<v Speaker 1>I think it's a group of people standing </v>
<v Speaker 1>next to a man in a suit and tie,</v>

674
00:29:45.910 --> 00:29:47.350
<v Speaker 1>right?</v>
<v Speaker 1>So that's right,</v>

675
00:29:47.650 --> 00:29:49.420
<v Speaker 1>right.</v>
<v Speaker 1>As far as it goes,</v>

676
00:29:49.540 --> 00:29:51.610
<v Speaker 1>it's just doesn't go far enough.</v>
<v Speaker 1>And the current,</v>

677
00:29:52.120 --> 00:29:57.120
<v Speaker 1>the current ideas of build a Dataset,</v>
<v Speaker 1>train a deep learning algorithm on it </v>

678
00:29:57.120 --> 00:29:57.730
<v Speaker 1>and then repeat,</v>
<v Speaker 1>um,</v>

679
00:29:58.180 --> 00:30:03.180
<v Speaker 1>aren't really even,</v>
<v Speaker 1>I would venture trying to get to what </v>

680
00:30:03.180 --> 00:30:06.931
<v Speaker 1>we're talking about or here's another.</v>
<v Speaker 1>I'll just give you one other example of </v>

681
00:30:06.931 --> 00:30:07.630
<v Speaker 1>a couple of photographs from my recent </v>
<v Speaker 1>vacation.</v>

682
00:30:08.040 --> 00:30:10.300
<v Speaker 1>I'm in a nice warm,</v>
<v Speaker 1>tropical local,</v>

683
00:30:10.670 --> 00:30:12.820
<v Speaker 1>um,</v>
<v Speaker 1>which I think illustrate ways in which,</v>

684
00:30:12.821 --> 00:30:17.821
<v Speaker 1>again,</v>
<v Speaker 1>the gap where we have machines that can </v>

685
00:30:17.821 --> 00:30:20.470
<v Speaker 1>say beat the world's best at go but </v>
<v Speaker 1>can't even beat a child.</v>

686
00:30:20.471 --> 00:30:22.390
<v Speaker 1>A tic TAC toe.</v>
<v Speaker 1>Now what do I mean by that?</v>

687
00:30:22.391 --> 00:30:23.260
<v Speaker 1>Well,</v>
<v Speaker 1>you know,</v>

688
00:30:23.261 --> 00:30:28.261
<v Speaker 1>of course we can build,</v>
<v Speaker 1>we don't even need reinforcement </v>

689
00:30:28.261 --> 00:30:30.811
<v Speaker 1>learning or deep learning to build a </v>
<v Speaker 1>machine that can win or tie do as do </v>

690
00:30:30.811 --> 00:30:30.940
<v Speaker 1>optimally in tic TAC toe.</v>

691
00:30:31.210 --> 00:30:33.190
<v Speaker 1>But think about this.</v>
<v Speaker 1>This is a real tic TAC toe game,</v>

692
00:30:33.191 --> 00:30:35.440
<v Speaker 1>which I saw on the grass outside my </v>
<v Speaker 1>hotel,</v>

693
00:30:35.680 --> 00:30:36.810
<v Speaker 1>right?</v>
<v Speaker 1>Um,</v>

694
00:30:36.880 --> 00:30:41.880
<v Speaker 1>what do you have to do to look at this </v>
<v Speaker 1>and recognize that it's a tic Tac toe </v>

695
00:30:41.880 --> 00:30:44.671
<v Speaker 1>game.</v>
<v Speaker 1>You have to see the objects that you </v>

696
00:30:44.671 --> 00:30:44.671
<v Speaker 1>have to see what's,</v>
<v Speaker 1>you know,</v>

697
00:30:44.671 --> 00:30:44.671
<v Speaker 1>in some sense there's a three by three </v>
<v Speaker 1>grid,</v>

698
00:30:44.671 --> 00:30:46.120
<v Speaker 1>but it's,</v>
<v Speaker 1>but it's only abstract,</v>

699
00:30:46.150 --> 00:30:47.860
<v Speaker 1>right?</v>
<v Speaker 1>It's only limited by this.</v>

700
00:30:47.890 --> 00:30:49.690
<v Speaker 1>These ropes are strings.</v>
<v Speaker 1>Okay?</v>

701
00:30:51.220 --> 00:30:54.010
<v Speaker 1>It's not actually a grid in any simple </v>
<v Speaker 1>geometric sense.</v>

702
00:30:54.280 --> 00:30:59.280
<v Speaker 1>Alright?</v>
<v Speaker 1>But yet a child can look at that and </v>

703
00:30:59.280 --> 00:30:59.280
<v Speaker 1>indeed here's an actual child who was </v>
<v Speaker 1>looking at it and recognize,</v>

704
00:30:59.280 --> 00:31:00.820
<v Speaker 1>oh,</v>
<v Speaker 1>it's a game of tic Tac toe and even know</v>

705
00:31:00.821 --> 00:31:05.821
<v Speaker 1>what they need to do to win,</v>
<v Speaker 1>namely put the x and completed and now </v>

706
00:31:05.821 --> 00:31:05.821
<v Speaker 1>they've got three in a row,</v>
<v Speaker 1>right?</v>

707
00:31:05.821 --> 00:31:05.920
<v Speaker 1>That's literally childsplay.</v>

708
00:31:06.190 --> 00:31:07.280
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

709
00:31:07.390 --> 00:31:09.280
<v Speaker 1>you show this sort of thing though to </v>
<v Speaker 1>one of these,</v>

710
00:31:09.310 --> 00:31:11.290
<v Speaker 1>you know,</v>
<v Speaker 1>image understanding captioned bots,</v>

711
00:31:11.320 --> 00:31:13.930
<v Speaker 1>and I think it's a closeup of a sign.</v>
<v Speaker 1>Okay?</v>

712
00:31:14.180 --> 00:31:14.890
<v Speaker 1>Um,</v>
<v Speaker 1>again,</v>

713
00:31:14.950 --> 00:31:17.530
<v Speaker 1>it's not saying that this is a closeup </v>
<v Speaker 1>of a sign,</v>

714
00:31:17.740 --> 00:31:21.430
<v Speaker 1>is,</v>
<v Speaker 1>is not the same thing.</v>

715
00:31:21.880 --> 00:31:25.180
<v Speaker 1>I would venture as a,</v>
<v Speaker 1>as a cognitive or computational activity</v>

716
00:31:25.390 --> 00:31:27.400
<v Speaker 1>that's going to give us what we need to </v>
<v Speaker 1>say.</v>

717
00:31:27.430 --> 00:31:30.880
<v Speaker 1>Recognize the objects to recognize it as</v>
<v Speaker 1>a game to understand the goal and how to</v>

718
00:31:30.881 --> 00:31:35.881
<v Speaker 1>plan to achieve those goals.</v>
<v Speaker 1>Whereas this kind of architecture is </v>

719
00:31:35.881 --> 00:31:36.550
<v Speaker 1>designed to try to do all of these </v>
<v Speaker 1>things ultimately.</v>

720
00:31:36.551 --> 00:31:41.551
<v Speaker 1>Right?</v>
<v Speaker 1>And I bring in these examples of games </v>

721
00:31:41.551 --> 00:31:44.380
<v Speaker 1>or jokes to really show where perception</v>
<v Speaker 1>goes to cognition,</v>

722
00:31:44.410 --> 00:31:45.480
<v Speaker 1>you know,</v>
<v Speaker 1>that,</v>

723
00:31:45.530 --> 00:31:46.990
<v Speaker 1>uh,</v>
<v Speaker 1>at all the way up to symbols,</v>

724
00:31:47.050 --> 00:31:52.050
<v Speaker 1>right?</v>
<v Speaker 1>So to get objects and forces and mental </v>

725
00:31:52.050 --> 00:31:52.600
<v Speaker 1>states,</v>
<v Speaker 1>that's the cognitive core,</v>

726
00:31:52.960 --> 00:31:57.960
<v Speaker 1>but to be able to get goals and plans </v>
<v Speaker 1>and what do I do or how do I talk about </v>

727
00:31:57.960 --> 00:31:57.960
<v Speaker 1>it?</v>

728
00:31:57.960 --> 00:31:58.300
<v Speaker 1>That's symbols.</v>
<v Speaker 1>Okay,</v>

729
00:31:59.650 --> 00:32:02.290
<v Speaker 1>here's another way into this.</v>
<v Speaker 1>And it's one that also motivates,</v>

730
00:32:02.291 --> 00:32:07.291
<v Speaker 1>I think a lot of really good work on the</v>
<v Speaker 1>engineering side and a lot of our </v>

731
00:32:07.291 --> 00:32:10.501
<v Speaker 1>interest in the science side is think </v>
<v Speaker 1>about robotics and think about what do </v>

732
00:32:10.501 --> 00:32:11.680
<v Speaker 1>you have to do to,</v>
<v Speaker 1>you know,</v>

733
00:32:11.700 --> 00:32:16.700
<v Speaker 1>what,</v>
<v Speaker 1>what does the brain have to be light to </v>

734
00:32:16.700 --> 00:32:16.700
<v Speaker 1>control the body?</v>
<v Speaker 1>So again,</v>

735
00:32:16.700 --> 00:32:19.921
<v Speaker 1>you're gonna hear from certainly,</v>
<v Speaker 1>I think maybe it's next week from Mark </v>

736
00:32:19.921 --> 00:32:23.970
<v Speaker 1>Robert,</v>
<v Speaker 1>who's a one of the founders of Boston </v>

737
00:32:23.970 --> 00:32:26.701
<v Speaker 1>dynamics,</v>
<v Speaker 1>which is one of my favorite companies </v>

738
00:32:26.701 --> 00:32:26.701
<v Speaker 1>anywhere there,</v>
<v Speaker 1>uh,</v>

739
00:32:26.701 --> 00:32:29.380
<v Speaker 1>without doubt the leading maker of </v>
<v Speaker 1>humanoid robots,</v>

740
00:32:29.381 --> 00:32:33.010
<v Speaker 1>legged locomoting robots and industry.</v>
<v Speaker 1>They have also all sorts of other really</v>

741
00:32:33.011 --> 00:32:35.980
<v Speaker 1>cool robots,</v>
<v Speaker 1>robots like dogs,</v>

742
00:32:35.981 --> 00:32:37.270
<v Speaker 1>robots that have,</v>
<v Speaker 1>you know,</v>

743
00:32:37.300 --> 00:32:37.740
<v Speaker 1>you'll,</v>
<v Speaker 1>you'll,</v>

744
00:32:37.750 --> 00:32:42.750
<v Speaker 1>you'll,</v>
<v Speaker 1>I think you'll even get to see live </v>

745
00:32:42.750 --> 00:32:42.750
<v Speaker 1>demonstration of one of his robots.</v>
<v Speaker 1>This really awesome,</v>

746
00:32:42.750 --> 00:32:42.750
<v Speaker 1>impressive stuff.</v>

747
00:32:44.090 --> 00:32:46.850
<v Speaker 1>But what about the minds and brains of </v>
<v Speaker 1>these robots will,</v>

748
00:32:46.851 --> 00:32:47.840
<v Speaker 1>again,</v>
<v Speaker 1>if you ask mark,</v>

749
00:32:47.841 --> 00:32:52.130
<v Speaker 1>ask them how much of of human light </v>
<v Speaker 1>cognition do they have in their robots?</v>

750
00:32:52.131 --> 00:32:54.770
<v Speaker 1>And I think he would say very little.</v>
<v Speaker 1>In fact,</v>

751
00:32:54.800 --> 00:32:56.510
<v Speaker 1>we have asked him that and he would say </v>
<v Speaker 1>very little,</v>

752
00:32:57.110 --> 00:32:59.360
<v Speaker 1>very little.</v>
<v Speaker 1>He's,</v>

753
00:32:59.390 --> 00:33:01.280
<v Speaker 1>he's actually one of the advisors of our</v>
<v Speaker 1>center.</v>

754
00:33:01.281 --> 00:33:03.950
<v Speaker 1>And I think in many ways we're very much</v>
<v Speaker 1>on the same page.</v>

755
00:33:03.951 --> 00:33:08.951
<v Speaker 1>We both want to know how do you build </v>
<v Speaker 1>the kind of intelligence that can </v>

756
00:33:08.951 --> 00:33:10.250
<v Speaker 1>control these bodies.</v>
<v Speaker 1>I'm like the way a human does.</v>

757
00:33:10.660 --> 00:33:11.270
<v Speaker 1>All right.</v>
<v Speaker 1>Um,</v>

758
00:33:11.360 --> 00:33:13.340
<v Speaker 1>here's another example of an industry </v>
<v Speaker 1>robotics effort.</v>

759
00:33:13.341 --> 00:33:15.410
<v Speaker 1>This is Google's arm farm where you </v>
<v Speaker 1>know,</v>

760
00:33:15.411 --> 00:33:20.411
<v Speaker 1>they've,</v>
<v Speaker 1>they've got lots of robot arms and </v>

761
00:33:20.411 --> 00:33:21.941
<v Speaker 1>they're trying to train them to pick up </v>
<v Speaker 1>objects using various kinds of deep </v>

762
00:33:21.941 --> 00:33:21.941
<v Speaker 1>learning and reinforcement learning </v>
<v Speaker 1>techniques.</v>

763
00:33:21.980 --> 00:33:23.240
<v Speaker 1>And I think it's one approach.</v>

764
00:33:23.270 --> 00:33:26.510
<v Speaker 1>I just think it's very,</v>
<v Speaker 1>very different from the way humans learn</v>

765
00:33:26.511 --> 00:33:31.511
<v Speaker 1>to say,</v>
<v Speaker 1>control their body and manipulate </v>

766
00:33:31.511 --> 00:33:33.251
<v Speaker 1>objects and you can see that in terms of</v>
<v Speaker 1>things that go back to what you were </v>

767
00:33:33.251 --> 00:33:33.251
<v Speaker 1>saying when you were introducing me,</v>
<v Speaker 1>right?</v>

768
00:33:33.251 --> 00:33:35.660
<v Speaker 1>Think about how quickly we learn the </v>
<v Speaker 1>things right here.</v>

769
00:33:35.661 --> 00:33:38.060
<v Speaker 1>You have these arm farm is trying to </v>
<v Speaker 1>generate,</v>

770
00:33:38.150 --> 00:33:40.340
<v Speaker 1>you know,</v>
<v Speaker 1>effectively maybe if not infinite,</v>

771
00:33:40.370 --> 00:33:45.370
<v Speaker 1>but hundreds of thousands,</v>
<v Speaker 1>millions of examples of reaches and </v>

772
00:33:45.370 --> 00:33:49.451
<v Speaker 1>pickups of objects even with just a </v>
<v Speaker 1>single gripper and yet a child who in </v>

773
00:33:49.451 --> 00:33:53.621
<v Speaker 1>some ways can't control their body </v>
<v Speaker 1>nearly as well as robots can be </v>

774
00:33:53.621 --> 00:33:55.430
<v Speaker 1>controlled at the low level,</v>
<v Speaker 1>is able to do so much more.</v>

775
00:33:55.730 --> 00:33:58.820
<v Speaker 1>So I'll show you two of my favorite </v>
<v Speaker 1>videos from youtube here,</v>

776
00:33:59.030 --> 00:34:01.010
<v Speaker 1>which motivates some of the research </v>
<v Speaker 1>that we're doing.</v>

777
00:34:01.520 --> 00:34:06.520
<v Speaker 1>The one on the left is a one and a half </v>
<v Speaker 1>year old and the other one's a one year </v>

778
00:34:06.520 --> 00:34:09.311
<v Speaker 1>old.</v>
<v Speaker 1>So just watch this one and a half year </v>

779
00:34:09.311 --> 00:34:11.200
<v Speaker 1>old here doing a popular activity for </v>
<v Speaker 1>many kids as a playing a video up there.</v>

780
00:34:19.040 --> 00:34:19.610
<v Speaker 1>Okay,</v>
<v Speaker 1>there we go.</v>

781
00:34:19.850 --> 00:34:20.840
<v Speaker 1>Okay.</v>
<v Speaker 1>So He's,</v>

782
00:34:20.870 --> 00:34:23.330
<v Speaker 1>he's on doing this stacking cup </v>
<v Speaker 1>activity.</v>

783
00:34:23.930 --> 00:34:28.930
<v Speaker 1>Alright.</v>
<v Speaker 1>He's stacking up cups to make a tall </v>

784
00:34:28.930 --> 00:34:28.930
<v Speaker 1>tower.</v>
<v Speaker 1>He's got a stack of three.</v>

785
00:34:28.930 --> 00:34:33.750
<v Speaker 1>And what you can see for the first part </v>
<v Speaker 1>of this video is it looks like he's </v>

786
00:34:33.750 --> 00:34:35.570
<v Speaker 1>trying to make a second stack at that </v>
<v Speaker 1>he's trying to pick up at once.</v>

787
00:34:35.810 --> 00:34:40.430
<v Speaker 1>Basically he's trying to make a stack of</v>
<v Speaker 1>two that'll go on the stack of three and</v>

788
00:34:40.640 --> 00:34:41.140
<v Speaker 1>you know,</v>
<v Speaker 1>he's,</v>

789
00:34:41.200 --> 00:34:42.830
<v Speaker 1>he's trying to debug his plan because </v>
<v Speaker 1>it's,</v>

790
00:34:42.850 --> 00:34:44.560
<v Speaker 1>it got a little bit stuck here.</v>
<v Speaker 1>Um,</v>

791
00:34:45.770 --> 00:34:46.870
<v Speaker 1>but,</v>
<v Speaker 1>and,</v>

792
00:34:46.871 --> 00:34:47.600
<v Speaker 1>and think about,</v>
<v Speaker 1>I mean,</v>

793
00:34:47.601 --> 00:34:48.920
<v Speaker 1>again,</v>
<v Speaker 1>if you know anything about robots,</v>

794
00:34:48.921 --> 00:34:50.870
<v Speaker 1>manipulating objects,</v>
<v Speaker 1>even just what he did,</v>

795
00:34:50.871 --> 00:34:53.570
<v Speaker 1>no robot can,</v>
<v Speaker 1>can decide to do that and actually do it</v>

796
00:34:53.780 --> 00:34:56.960
<v Speaker 1>right at some point he's almost got it.</v>
<v Speaker 1>It's a little bit tricky,</v>

797
00:34:56.961 --> 00:34:59.550
<v Speaker 1>but some point he's going to get that </v>
<v Speaker 1>stack of two.</v>

798
00:35:00.590 --> 00:35:02.630
<v Speaker 1>He realizes he has to move that opted </v>
<v Speaker 1>out of the way,</v>

799
00:35:02.631 --> 00:35:04.340
<v Speaker 1>look at what he did,</v>
<v Speaker 1>move out of the way,</v>

800
00:35:04.350 --> 00:35:09.350
<v Speaker 1>use two hands to pick it up.</v>
<v Speaker 1>And now he's got a stack of two on a </v>

801
00:35:09.350 --> 00:35:09.350
<v Speaker 1>stack of three and suddenly,</v>
<v Speaker 1>you know,</v>

802
00:35:09.350 --> 00:35:11.270
<v Speaker 1>sub goal completed.</v>
<v Speaker 1>He's now got a stack of five and he,</v>

803
00:35:11.271 --> 00:35:15.050
<v Speaker 1>he gives himself a hand because he know,</v>
<v Speaker 1>he knows he accomplished a key way point</v>

804
00:35:15.080 --> 00:35:20.080
<v Speaker 1>along the way to his final goal.</v>
<v Speaker 1>That's a kind of early symbolic </v>

805
00:35:20.080 --> 00:35:20.080
<v Speaker 1>cognition,</v>
<v Speaker 1>right?</v>

806
00:35:20.080 --> 00:35:22.160
<v Speaker 1>To understand that I'm trying to build a</v>
<v Speaker 1>tall tower,</v>

807
00:35:22.280 --> 00:35:24.080
<v Speaker 1>but the tower is made up of little </v>
<v Speaker 1>towers.</v>

808
00:35:24.081 --> 00:35:24.540
<v Speaker 1>It's,</v>
<v Speaker 1>you know,</v>

809
00:35:24.700 --> 00:35:29.700
<v Speaker 1>and,</v>
<v Speaker 1>and you can take a tower and put it on </v>

810
00:35:29.700 --> 00:35:29.700
<v Speaker 1>top of another tower or a stack,</v>
<v Speaker 1>a stack on a stack and you have a bigger</v>

811
00:35:29.700 --> 00:35:30.200
<v Speaker 1>stack,</v>
<v Speaker 1>right?</v>

812
00:35:30.650 --> 00:35:35.650
<v Speaker 1>So think about how he goes from bottom </v>
<v Speaker 1>up perception to the objects of the </v>

813
00:35:35.650 --> 00:35:35.720
<v Speaker 1>physical needed to manipulate the </v>
<v Speaker 1>objects.</v>

814
00:35:35.720 --> 00:35:39.030
<v Speaker 1>So the ability to make those early kinds</v>
<v Speaker 1>of symbolic plans.</v>

815
00:35:39.720 --> 00:35:42.220
<v Speaker 1>At some point he keeps doing this.</v>
<v Speaker 1>He puts another stack on there.</v>

816
00:35:43.830 --> 00:35:45.270
<v Speaker 1>I'll just jump to the end.</v>
<v Speaker 1>Oops,</v>

817
00:35:45.271 --> 00:35:45.890
<v Speaker 1>sorry.</v>
<v Speaker 1>You missed it.</v>

818
00:35:45.891 --> 00:35:46.660
<v Speaker 1>Sorry.</v>
<v Speaker 1>Keep.</v>

819
00:35:47.640 --> 00:35:50.910
<v Speaker 1>He gets really excited and he gives </v>
<v Speaker 1>himself another big hand,</v>

820
00:35:50.911 --> 00:35:53.370
<v Speaker 1>but falls over again.</v>
<v Speaker 1>Um,</v>

821
00:35:54.180 --> 00:35:57.450
<v Speaker 1>Boston dynamics now has robots that </v>
<v Speaker 1>could pick themselves up after that.</v>

822
00:35:57.451 --> 00:35:59.210
<v Speaker 1>That's really impressive again.</v>
<v Speaker 1>Um,</v>

823
00:35:59.670 --> 00:36:01.440
<v Speaker 1>but all the other stuff to get to that </v>
<v Speaker 1>point,</v>

824
00:36:01.470 --> 00:36:06.470
<v Speaker 1>we don't really know how to do in a </v>
<v Speaker 1>robotic setting or thinking about this </v>

825
00:36:06.470 --> 00:36:06.470
<v Speaker 1>baby here.</v>
<v Speaker 1>This is a younger baby.</v>

826
00:36:06.470 --> 00:36:11.060
<v Speaker 1>This is one of the Internet's most </v>
<v Speaker 1>popular videos because it features a </v>

827
00:36:11.060 --> 00:36:14.661
<v Speaker 1>baby and a cap and,</v>
<v Speaker 1>but the baby's doing something </v>

828
00:36:14.661 --> 00:36:16.080
<v Speaker 1>interesting.</v>
<v Speaker 1>He's got the same cups,</v>

829
00:36:16.081 --> 00:36:19.290
<v Speaker 1>but he's decided he's again,</v>
<v Speaker 1>decided to try a new thing.</v>

830
00:36:19.291 --> 00:36:24.291
<v Speaker 1>So this is thinking about creativity.</v>
<v Speaker 1>He's decided that his goal is to stack </v>

831
00:36:24.291 --> 00:36:25.260
<v Speaker 1>up cups on the back of a cat.</v>

832
00:36:25.260 --> 00:36:27.750
<v Speaker 1>I guess he's asking how many cups going </v>
<v Speaker 1>to fit on the back of a cat?</v>

833
00:36:27.751 --> 00:36:28.590
<v Speaker 1>Well,</v>
<v Speaker 1>three.</v>

834
00:36:28.950 --> 00:36:30.360
<v Speaker 1>Let's see.</v>
<v Speaker 1>Can I fit more?</v>

835
00:36:31.440 --> 00:36:33.360
<v Speaker 1>Let's try another one.</v>
<v Speaker 1>Okay.</v>

836
00:36:33.650 --> 00:36:35.280
<v Speaker 1>Um,</v>
<v Speaker 1>while he can't fit more than three,</v>

837
00:36:35.281 --> 00:36:37.320
<v Speaker 1>it turns out.</v>
<v Speaker 1>And then he then does.</v>

838
00:36:37.410 --> 00:36:39.150
<v Speaker 1>It's not working,</v>
<v Speaker 1>so he changes his goal.</v>

839
00:36:39.270 --> 00:36:42.210
<v Speaker 1>Now his goal appears to be to get the </v>
<v Speaker 1>cuffs on the other side of the cat.</v>

840
00:36:42.480 --> 00:36:45.000
<v Speaker 1>Now watch that part when he reaches back</v>
<v Speaker 1>behind him there.</v>

841
00:36:45.001 --> 00:36:46.650
<v Speaker 1>That's.</v>
<v Speaker 1>I'll just pause it there for a moment.</v>

842
00:36:47.060 --> 00:36:49.080
<v Speaker 1>Um,</v>
<v Speaker 1>so many just reached back there.</v>

843
00:36:49.210 --> 00:36:51.300
<v Speaker 1>That's a particularly striking moment in</v>
<v Speaker 1>the video.</v>

844
00:36:51.540 --> 00:36:54.960
<v Speaker 1>It shows a very strong form of what we </v>
<v Speaker 1>call in cognitive science.</v>

845
00:36:55.620 --> 00:36:57.210
<v Speaker 1>Object permanence.</v>
<v Speaker 1>Okay.</v>

846
00:36:57.510 --> 00:37:02.510
<v Speaker 1>That's the idea that you represent </v>
<v Speaker 1>objects as these permanent enduring </v>

847
00:37:02.510 --> 00:37:05.720
<v Speaker 1>entities in the world.</v>
<v Speaker 1>Even when you can't see them in this </v>

848
00:37:05.720 --> 00:37:08.361
<v Speaker 1>case.</v>
<v Speaker 1>He hadn't seen or touched that optic </v>

849
00:37:08.361 --> 00:37:08.361
<v Speaker 1>behind him for like at least a minute,</v>
<v Speaker 1>right?</v>

850
00:37:08.361 --> 00:37:08.640
<v Speaker 1>Maybe much longer.</v>
<v Speaker 1>I don't know.</v>

851
00:37:09.240 --> 00:37:14.240
<v Speaker 1>And yet he still knew it was there and </v>
<v Speaker 1>he was able to incorporate it in this </v>

852
00:37:14.240 --> 00:37:14.240
<v Speaker 1>plan.</v>
<v Speaker 1>Right.</v>

853
00:37:14.240 --> 00:37:14.970
<v Speaker 1>There's a moment before that when he's </v>
<v Speaker 1>about to reach for it,</v>

854
00:37:14.971 --> 00:37:16.410
<v Speaker 1>but then he sees this other one.</v>
<v Speaker 1>Right.</v>

855
00:37:16.411 --> 00:37:21.411
<v Speaker 1>And it's only when he's now exhausted </v>
<v Speaker 1>all the other objects here that he can </v>

856
00:37:21.411 --> 00:37:21.411
<v Speaker 1>see.</v>
<v Speaker 1>He's like,</v>

857
00:37:21.411 --> 00:37:24.591
<v Speaker 1>okay,</v>
<v Speaker 1>now time to get this audit and bring it </v>

858
00:37:24.591 --> 00:37:24.591
<v Speaker 1>into play.</v>
<v Speaker 1>Right?</v>

859
00:37:24.591 --> 00:37:27.830
<v Speaker 1>So think about what has to be going on </v>
<v Speaker 1>in his brain for him to be able to do </v>

860
00:37:27.830 --> 00:37:27.830
<v Speaker 1>that.</v>
<v Speaker 1>Right?</v>

861
00:37:27.830 --> 00:37:29.850
<v Speaker 1>That's like the analog of you </v>
<v Speaker 1>understanding what's behind you.</v>

862
00:37:30.540 --> 00:37:35.540
<v Speaker 1>Okay.</v>
<v Speaker 1>It's not that these things are </v>

863
00:37:35.540 --> 00:37:35.540
<v Speaker 1>impossible to capture machines far from </v>
<v Speaker 1>it.</v>

864
00:37:35.540 --> 00:37:39.200
<v Speaker 1>It's just that like training a deep </v>
<v Speaker 1>neural network or any kind of pattern </v>

865
00:37:39.200 --> 00:37:39.200
<v Speaker 1>recognition system we don't think is </v>
<v Speaker 1>going to do it,</v>

866
00:37:39.330 --> 00:37:42.090
<v Speaker 1>but we think by reverse engineering how </v>
<v Speaker 1>it works in the brain,</v>

867
00:37:42.420 --> 00:37:44.430
<v Speaker 1>we might be able to do it because we can</v>
<v Speaker 1>do it.</v>

868
00:37:44.550 --> 00:37:49.550
<v Speaker 1>Okay.</v>
<v Speaker 1>It's not just humans that do this kind </v>

869
00:37:49.550 --> 00:37:49.550
<v Speaker 1>of activity.</v>
<v Speaker 1>Here's a couple of,</v>

870
00:37:49.550 --> 00:37:49.890
<v Speaker 1>again,</v>
<v Speaker 1>fit rather famous videos.</v>

871
00:37:49.891 --> 00:37:53.230
<v Speaker 1>You can watch all of these on youtube.</v>
<v Speaker 1>Crows are famous objects,</v>

872
00:37:53.231 --> 00:37:56.840
<v Speaker 1>manipulators and tool users,</v>
<v Speaker 1>but also orangutans,</v>

873
00:37:57.000 --> 00:37:58.980
<v Speaker 1>other primates,</v>
<v Speaker 1>rodents.</v>

874
00:37:59.970 --> 00:38:02.280
<v Speaker 1>We can watch if we just had.</v>
<v Speaker 1>Let me pause this one for a second.</v>

875
00:38:02.460 --> 00:38:07.460
<v Speaker 1>If we watched this orangutan here,</v>
<v Speaker 1>he's got a bunch of big legos and over </v>

876
00:38:07.460 --> 00:38:10.140
<v Speaker 1>the course of this video he's building </v>
<v Speaker 1>up a stack.</v>

877
00:38:10.710 --> 00:38:12.240
<v Speaker 1>Legos.</v>
<v Speaker 1>It's really quite impressive.</v>

878
00:38:13.640 --> 00:38:14.790
<v Speaker 1>Just jumping to the end.</v>

879
00:38:17.220 --> 00:38:20.550
<v Speaker 1>There's actually some controversy out </v>
<v Speaker 1>there of what this video is a fake.</v>

880
00:38:21.050 --> 00:38:23.190
<v Speaker 1>Um,</v>
<v Speaker 1>but the controversy isn't about,</v>

881
00:38:23.480 --> 00:38:25.600
<v Speaker 1>it's not like whether it was,</v>
<v Speaker 1>I dunno,</v>

882
00:38:25.750 --> 00:38:28.800
<v Speaker 1>done with computer animation,</v>
<v Speaker 1>some people think the video was actually</v>

883
00:38:28.801 --> 00:38:33.801
<v Speaker 1>filmed backwards,</v>
<v Speaker 1>that a human built up the stack and the </v>

884
00:38:33.801 --> 00:38:36.651
<v Speaker 1>orangutan just slowly disassembled it </v>
<v Speaker 1>piece by piece and it turns out it's </v>

885
00:38:36.651 --> 00:38:39.681
<v Speaker 1>remarkably hard to tell whether it's </v>
<v Speaker 1>played forward or backwards in time and </v>

886
00:38:39.681 --> 00:38:39.910
<v Speaker 1>people have argued over a little details</v>
<v Speaker 1>because you know,</v>

887
00:38:39.950 --> 00:38:44.950
<v Speaker 1>it will be quite impressive if an </v>
<v Speaker 1>orangutan actually was able to build up </v>

888
00:38:44.950 --> 00:38:48.181
<v Speaker 1>this really impressive stack of Legos.</v>
<v Speaker 1>But I would submit that it would be </v>

889
00:38:48.181 --> 00:38:48.181
<v Speaker 1>almost as impressive if he disassembled </v>
<v Speaker 1>it.</v>

890
00:38:48.640 --> 00:38:50.050
<v Speaker 1>Think about the activity.</v>
<v Speaker 1>I mean,</v>

891
00:38:50.051 --> 00:38:52.450
<v Speaker 1>if I want it to disassemble that,</v>
<v Speaker 1>the easiest thing to do would just be to</v>

892
00:38:52.451 --> 00:38:54.790
<v Speaker 1>knock it over.</v>
<v Speaker 1>That's really all most robots could do.</v>

893
00:38:55.020 --> 00:39:00.020
<v Speaker 1>But to piece by piece,</v>
<v Speaker 1>disassemble it even if it's played </v>

894
00:39:00.020 --> 00:39:02.881
<v Speaker 1>backwards like this.</v>
<v Speaker 1>That's still a really impressive act of </v>

895
00:39:02.881 --> 00:39:04.330
<v Speaker 1>symbolic planning on physical objects.</v>
<v Speaker 1>Or here you've got this,</v>

896
00:39:04.450 --> 00:39:09.450
<v Speaker 1>this famous mouse,</v>
<v Speaker 1>this you can find on the internet under </v>

897
00:39:09.450 --> 00:39:12.160
<v Speaker 1>the mouse versus cracker video.</v>
<v Speaker 1>And what you'll see here over the course</v>

898
00:39:12.161 --> 00:39:17.161
<v Speaker 1>of this video is a mouse valiantly and </v>
<v Speaker 1>mostly hopelessly struggling with a </v>

899
00:39:17.231 --> 00:39:20.050
<v Speaker 1>cracker that they're hoping to bring </v>
<v Speaker 1>back to their nest.</v>

900
00:39:20.051 --> 00:39:22.980
<v Speaker 1>I guess it's a very appealing big meal.</v>
<v Speaker 1>Um,</v>

901
00:39:23.260 --> 00:39:25.480
<v Speaker 1>and at some point after just trying to </v>
<v Speaker 1>get it over the,</v>

902
00:39:25.570 --> 00:39:30.570
<v Speaker 1>over the wall,</v>
<v Speaker 1>at some point the mouse just gives up </v>

903
00:39:30.570 --> 00:39:33.811
<v Speaker 1>because it's just never going to happen </v>
<v Speaker 1>and he just goes away except that </v>

904
00:39:33.811 --> 00:39:37.120
<v Speaker 1>because even mouses can dream or my </v>
<v Speaker 1>dream some point he decides,</v>

905
00:39:37.121 --> 00:39:42.121
<v Speaker 1>okay,</v>
<v Speaker 1>I'm just going to come back for one </v>

906
00:39:42.121 --> 00:39:43.201
<v Speaker 1>more.</v>
<v Speaker 1>Try and he tries one more time and this </v>

907
00:39:43.201 --> 00:39:43.201
<v Speaker 1>time validly gets it over.</v>

908
00:39:43.201 --> 00:39:44.170
<v Speaker 1>Yeah.</v>
<v Speaker 1>Isn't that very impressive?</v>

909
00:39:44.740 --> 00:39:45.810
<v Speaker 1>Congratulations about.</v>
<v Speaker 1>Okay.</v>

910
00:39:46.090 --> 00:39:51.090
<v Speaker 1>You don't have to clap.</v>
<v Speaker 1>You can clap for me at the end or clap </v>

911
00:39:51.090 --> 00:39:51.090
<v Speaker 1>for whoever it later.</v>
<v Speaker 1>Okay.</v>

912
00:39:51.090 --> 00:39:54.780
<v Speaker 1>But I will,</v>
<v Speaker 1>I want to applaud the mouse there every </v>

913
00:39:54.780 --> 00:39:54.780
<v Speaker 1>time I see that.</v>
<v Speaker 1>Okay.</v>

914
00:39:54.780 --> 00:39:57.720
<v Speaker 1>But again,</v>
<v Speaker 1>think what had to be going on in his </v>

915
00:39:57.720 --> 00:39:57.720
<v Speaker 1>brain to be able to do that.</v>
<v Speaker 1>All right.</v>

916
00:39:57.720 --> 00:39:59.410
<v Speaker 1>Um,</v>
<v Speaker 1>it's a crazy thing and yet he formulated</v>

917
00:39:59.411 --> 00:40:04.411
<v Speaker 1>the goal and was able to achieve it.</v>
<v Speaker 1>I'll just show one more video that is </v>

918
00:40:04.411 --> 00:40:06.130
<v Speaker 1>really more about science.</v>
<v Speaker 1>These other ones or you know,</v>

919
00:40:06.160 --> 00:40:08.170
<v Speaker 1>some of them actually were from </v>
<v Speaker 1>scientific experiments,</v>

920
00:40:08.171 --> 00:40:13.171
<v Speaker 1>but this is one that motivates a lot of </v>
<v Speaker 1>the science that I do and it's to me it </v>

921
00:40:13.171 --> 00:40:16.180
<v Speaker 1>sets up kind of a grand cognitive </v>
<v Speaker 1>science challenge for ai and robotics.</v>

922
00:40:16.450 --> 00:40:18.970
<v Speaker 1>It's from an experiment with humans,</v>
<v Speaker 1>again,</v>

923
00:40:19.000 --> 00:40:22.230
<v Speaker 1>18 month old or one and a half year old,</v>
<v Speaker 1>so the kids in this experiment,</v>

924
00:40:22.231 --> 00:40:24.100
<v Speaker 1>we're the same age as the first baby I </v>
<v Speaker 1>showed you.</v>

925
00:40:24.100 --> 00:40:26.830
<v Speaker 1>The one who did the stacking and 18 </v>
<v Speaker 1>months is really a very,</v>

926
00:40:26.860 --> 00:40:30.250
<v Speaker 1>very good age to study.</v>
<v Speaker 1>If you're interested in intelligence for</v>

927
00:40:30.251 --> 00:40:32.080
<v Speaker 1>reasons we can talk about later if </v>
<v Speaker 1>you're interested.</v>

928
00:40:32.950 --> 00:40:36.070
<v Speaker 1>This is from a very famous experiment </v>
<v Speaker 1>done by two psychologists,</v>

929
00:40:36.071 --> 00:40:38.070
<v Speaker 1>Felix Worn Akin and Michael Thomas </v>
<v Speaker 1>Cielo,</v>

930
00:40:38.620 --> 00:40:42.790
<v Speaker 1>and it was studying the spontaneous </v>
<v Speaker 1>helping behavior of young children.</v>

931
00:40:42.940 --> 00:40:47.940
<v Speaker 1>It also contrasted humans and chimps and</v>
<v Speaker 1>the punchline is that chimps sometimes </v>

932
00:40:47.940 --> 00:40:49.030
<v Speaker 1>do things that are kind of like with </v>
<v Speaker 1>this human did,</v>

933
00:40:49.031 --> 00:40:51.850
<v Speaker 1>but not nearly as reliably or as </v>
<v Speaker 1>flexibly.</v>

934
00:40:52.000 --> 00:40:53.790
<v Speaker 1>Okay,</v>
<v Speaker 1>so not nearly as an.</v>

935
00:40:53.860 --> 00:40:58.860
<v Speaker 1>I'll show you a particular kind of </v>
<v Speaker 1>unusual situation where human kids had </v>

936
00:40:58.860 --> 00:41:03.780
<v Speaker 1>relatively little trouble figuring out </v>
<v Speaker 1>what to do or even whether they should </v>

937
00:41:03.780 --> 00:41:07.111
<v Speaker 1>do it,</v>
<v Speaker 1>whereas basically no chimp did what </v>

938
00:41:07.111 --> 00:41:07.111
<v Speaker 1>you're going to see humans sometimes </v>
<v Speaker 1>doing here.</v>

939
00:41:07.111 --> 00:41:11.820
<v Speaker 1>So the experimenter in this movie.</v>
<v Speaker 1>I'll turn on the sound here if you can </v>

940
00:41:11.820 --> 00:41:11.820
<v Speaker 1>hear it.</v>

941
00:41:11.890 --> 00:41:16.890
<v Speaker 1>The experimenter is the tall guy and the</v>
<v Speaker 1>participant is the little kid in the </v>

942
00:41:16.890 --> 00:41:20.800
<v Speaker 1>corner.</v>
<v Speaker 1>The sound but no words,</v>

943
00:41:20.801 --> 00:41:25.801
<v Speaker 1>right?</v>
<v Speaker 1>And at some point he stops and then the </v>

944
00:41:25.801 --> 00:41:26.530
<v Speaker 1>kid just does whatever they want to do.</v>
<v Speaker 1>So watch what he does.</v>

945
00:41:26.531 --> 00:41:28.510
<v Speaker 1>He goes over,</v>
<v Speaker 1>he opens the cabinet,</v>

946
00:41:29.020 --> 00:41:34.020
<v Speaker 1>looks inside,</v>
<v Speaker 1>then he steps back and he looks up at </v>

947
00:41:34.020 --> 00:41:35.360
<v Speaker 1>Felix and then looks down,</v>
<v Speaker 1>okay,</v>

948
00:41:35.361 --> 00:41:39.020
<v Speaker 1>and then the action is completed.</v>
<v Speaker 1>Now what I want you to watch it one more</v>

949
00:41:39.021 --> 00:41:44.021
<v Speaker 1>time and think about what's going to be </v>
<v Speaker 1>going inside the kid's head to </v>

950
00:41:44.021 --> 00:41:44.110
<v Speaker 1>understand this,</v>
<v Speaker 1>to understand like.</v>

951
00:41:44.240 --> 00:41:49.240
<v Speaker 1>So it seems like what it looks like to </v>
<v Speaker 1>us is the kid figured out that this guy </v>

952
00:41:49.240 --> 00:41:52.151
<v Speaker 1>needed help and helped him.</v>
<v Speaker 1>And the paper is full of many other </v>

953
00:41:52.151 --> 00:41:52.151
<v Speaker 1>situations like this.</v>
<v Speaker 1>This is just one.</v>

954
00:41:52.151 --> 00:41:56.800
<v Speaker 1>Okay.</v>
<v Speaker 1>But the key idea is that the situation </v>

955
00:41:56.800 --> 00:41:56.800
<v Speaker 1>is somewhat novel.</v>

956
00:41:56.800 --> 00:41:57.740
<v Speaker 1>People have seen people holding books </v>
<v Speaker 1>and opening cabinets,</v>

957
00:41:57.741 --> 00:42:02.741
<v Speaker 1>but probably it's been,</v>
<v Speaker 1>it's very rare to see this kind of </v>

958
00:42:02.741 --> 00:42:02.741
<v Speaker 1>situation.</v>
<v Speaker 1>Exactly right.</v>

959
00:42:02.741 --> 00:42:03.530
<v Speaker 1>It's,</v>
<v Speaker 1>it's different in some important details</v>

960
00:42:03.680 --> 00:42:05.900
<v Speaker 1>from what you might have seen before.</v>
<v Speaker 1>And there's other ones in there that are</v>

961
00:42:05.901 --> 00:42:08.270
<v Speaker 1>really truly novel because they just </v>
<v Speaker 1>made up a machine right there.</v>

962
00:42:08.960 --> 00:42:09.650
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

963
00:42:09.980 --> 00:42:14.980
<v Speaker 1>but somehow he has to understand </v>
<v Speaker 1>causally from the way the guys banging </v>

964
00:42:14.980 --> 00:42:15.270
<v Speaker 1>the books against the thing that it's,</v>
<v Speaker 1>it's,</v>

965
00:42:15.370 --> 00:42:20.370
<v Speaker 1>it's sort of both a symbol,</v>
<v Speaker 1>but it's also somehow he's got to </v>

966
00:42:20.370 --> 00:42:22.400
<v Speaker 1>understand what he can do and what he </v>
<v Speaker 1>can't do and then what the kid can do to</v>

967
00:42:22.401 --> 00:42:23.460
<v Speaker 1>help.</v>
<v Speaker 1>And I'll,</v>

968
00:42:23.461 --> 00:42:26.000
<v Speaker 1>I'll show this again,</v>
<v Speaker 1>but really just watch.</v>

969
00:42:26.030 --> 00:42:29.770
<v Speaker 1>The main part I want you to see is,</v>
<v Speaker 1>um,</v>

970
00:42:30.850 --> 00:42:35.850
<v Speaker 1>I'll just sort of skip ahead.</v>
<v Speaker 1>So watch this part here.</v>

971
00:42:36.440 --> 00:42:38.930
<v Speaker 1>Let's say I'll just jump right when he </v>
<v Speaker 1>watched.</v>

972
00:42:38.990 --> 00:42:43.990
<v Speaker 1>Right now he's about to look up.</v>
<v Speaker 1>He looks up and makes eye contact and </v>

973
00:42:43.990 --> 00:42:44.540
<v Speaker 1>then his eyes look down.</v>
<v Speaker 1>So again,</v>

974
00:42:45.380 --> 00:42:48.380
<v Speaker 1>he looks up,</v>
<v Speaker 1>he looks up,</v>

975
00:42:48.381 --> 00:42:51.960
<v Speaker 1>and then a Sakata sudden rapid eye </v>
<v Speaker 1>movement down down to his hands up,</v>

976
00:42:51.980 --> 00:42:52.760
<v Speaker 1>down.</v>
<v Speaker 1>Okay?</v>

977
00:42:52.970 --> 00:42:54.770
<v Speaker 1>So that's again,</v>
<v Speaker 1>that's this brain,</v>

978
00:42:54.771 --> 00:42:56.330
<v Speaker 1>ostp and action,</v>
<v Speaker 1>right?</v>

979
00:42:56.360 --> 00:43:00.080
<v Speaker 1>He's making one glance,</v>
<v Speaker 1>small glance at the big guys,</v>

980
00:43:00.100 --> 00:43:02.570
<v Speaker 1>eyes to to make eye contact,</v>
<v Speaker 1>to see,</v>

981
00:43:02.720 --> 00:43:06.350
<v Speaker 1>to get a signal.</v>
<v Speaker 1>Did I understand what you wanted and did</v>

982
00:43:06.351 --> 00:43:11.351
<v Speaker 1>you.</v>
<v Speaker 1>Did you register that joint attention </v>

983
00:43:11.351 --> 00:43:11.390
<v Speaker 1>and then he makes a prediction about </v>
<v Speaker 1>what the guy's going to do.</v>

984
00:43:11.420 --> 00:43:16.420
<v Speaker 1>So he looks right down.</v>
<v Speaker 1>He doesn't just like look around </v>

985
00:43:16.420 --> 00:43:16.550
<v Speaker 1>randomly.</v>
<v Speaker 1>He looks right down to the guys hands to</v>

986
00:43:16.551 --> 00:43:19.010
<v Speaker 1>track the action that he expects to see </v>
<v Speaker 1>happening.</v>

987
00:43:19.220 --> 00:43:24.220
<v Speaker 1>If I did the right thing to help you,</v>
<v Speaker 1>then I expect you're going to put the </v>

988
00:43:24.220 --> 00:43:24.220
<v Speaker 1>books there.</v>

989
00:43:24.220 --> 00:43:27.490
<v Speaker 1>Okay?</v>
<v Speaker 1>So you can see these things happening </v>

990
00:43:27.490 --> 00:43:27.740
<v Speaker 1>and we want to know what's going on </v>
<v Speaker 1>inside the mind that guides all of that.</v>

991
00:43:28.490 --> 00:43:33.490
<v Speaker 1>All right?</v>
<v Speaker 1>So that's the sort of big scientific </v>

992
00:43:33.490 --> 00:43:35.621
<v Speaker 1>agenda that we're working on over the </v>
<v Speaker 1>next few years where we think some kind </v>

993
00:43:35.621 --> 00:43:39.611
<v Speaker 1>of human understanding of human </v>
<v Speaker 1>intelligence and scientific terms could </v>

994
00:43:39.611 --> 00:43:41.960
<v Speaker 1>lead to all sorts of ai payoffs in </v>
<v Speaker 1>particular.</v>

995
00:43:42.140 --> 00:43:47.140
<v Speaker 1>I suppose we could build a robot that </v>
<v Speaker 1>could do what this kid and many other </v>

996
00:43:47.140 --> 00:43:50.111
<v Speaker 1>kids in these experiments do just say,</v>
<v Speaker 1>help you out around the house without </v>

997
00:43:50.111 --> 00:43:51.830
<v Speaker 1>having to be programmed or even really </v>
<v Speaker 1>instructed just to kind of get a sense,</v>

998
00:43:51.860 --> 00:43:52.390
<v Speaker 1>oh yeah,</v>
<v Speaker 1>yeah,</v>

999
00:43:52.391 --> 00:43:54.230
<v Speaker 1>you need to have with that shirt.</v>
<v Speaker 1>Let me help you out.</v>

1000
00:43:54.500 --> 00:43:56.540
<v Speaker 1>Okay.</v>
<v Speaker 1>Even 18 month olds will do that.</v>

1001
00:43:56.541 --> 00:43:58.670
<v Speaker 1>Sometimes not very reliably or </v>
<v Speaker 1>effectively.</v>

1002
00:43:58.671 --> 00:44:01.370
<v Speaker 1>Sometimes they'll try to help and really</v>
<v Speaker 1>do the opposite.</v>

1003
00:44:01.580 --> 00:44:06.580
<v Speaker 1>Right?</v>
<v Speaker 1>But imagine if you could take the </v>

1004
00:44:06.580 --> 00:44:06.980
<v Speaker 1>flexible understanding of humans,</v>
<v Speaker 1>actions,</v>

1005
00:44:06.981 --> 00:44:11.981
<v Speaker 1>goals and so on,</v>
<v Speaker 1>and make those reliable engineering </v>

1006
00:44:11.981 --> 00:44:11.981
<v Speaker 1>technology that would be very useful.</v>

1007
00:44:12.290 --> 00:44:17.290
<v Speaker 1>And it would also be related to say </v>
<v Speaker 1>machines that you could actually start </v>

1008
00:44:17.290 --> 00:44:17.540
<v Speaker 1>to talk to and trust in some ways.</v>
<v Speaker 1>Right?</v>

1009
00:44:17.541 --> 00:44:20.360
<v Speaker 1>That shared understanding.</v>
<v Speaker 1>So how are we going to do this?</v>

1010
00:44:20.361 --> 00:44:25.361
<v Speaker 1>Well,</v>
<v Speaker 1>let me spend the rest of the time </v>

1011
00:44:25.361 --> 00:44:25.361
<v Speaker 1>talking about how we tried to do this,</v>
<v Speaker 1>right,</v>

1012
00:44:25.361 --> 00:44:28.870
<v Speaker 1>some of the,</v>
<v Speaker 1>some of the technology that we're </v>

1013
00:44:28.870 --> 00:44:31.001
<v Speaker 1>building both in our group and more </v>
<v Speaker 1>broadly to try to make these kinds of </v>

1014
00:44:31.001 --> 00:44:34.811
<v Speaker 1>architectures real.</v>
<v Speaker 1>And I'll talk about two or three </v>

1015
00:44:34.811 --> 00:44:34.811
<v Speaker 1>technical ideas,</v>
<v Speaker 1>again,</v>

1016
00:44:34.811 --> 00:44:36.250
<v Speaker 1>not in any detail.</v>
<v Speaker 1>Alright.</v>

1017
00:44:36.450 --> 00:44:41.450
<v Speaker 1>Um,</v>
<v Speaker 1>one is the idea of a probabilistic </v>

1018
00:44:41.450 --> 00:44:41.450
<v Speaker 1>program.</v>
<v Speaker 1>So this is a kind of,</v>

1019
00:44:41.450 --> 00:44:45.950
<v Speaker 1>um,</v>
<v Speaker 1>think of it as a computational </v>

1020
00:44:45.950 --> 00:44:50.211
<v Speaker 1>abstraction that we can use to capture </v>
<v Speaker 1>the common sense knowledge of this core </v>

1021
00:44:50.211 --> 00:44:54.051
<v Speaker 1>cognition.</v>
<v Speaker 1>So when I say we have an intuitive </v>

1022
00:44:54.051 --> 00:44:54.051
<v Speaker 1>understanding of physical objects and </v>
<v Speaker 1>people's goals,</v>

1023
00:44:54.051 --> 00:44:58.910
<v Speaker 1>how do I build a model of that model you</v>
<v Speaker 1>have in the head probabilistic programs </v>

1024
00:44:58.910 --> 00:45:03.051
<v Speaker 1>a little bit more technically are one </v>
<v Speaker 1>way to understand them is as a </v>

1025
00:45:03.051 --> 00:45:06.771
<v Speaker 1>generalization of Bayesian networks or </v>
<v Speaker 1>other kinds of directed graphical </v>

1026
00:45:06.771 --> 00:45:06.771
<v Speaker 1>models.</v>

1027
00:45:06.771 --> 00:45:07.050
<v Speaker 1>If you know those.</v>
<v Speaker 1>Okay.</v>

1028
00:45:07.200 --> 00:45:12.200
<v Speaker 1>But we're,</v>
<v Speaker 1>instead of defining a probability model </v>

1029
00:45:12.200 --> 00:45:15.560
<v Speaker 1>on a graph,</v>
<v Speaker 1>you defined it on a program and thereby </v>

1030
00:45:15.560 --> 00:45:19.230
<v Speaker 1>have access to a much more expressive </v>
<v Speaker 1>toolkit of knowledge representation.</v>

1031
00:45:19.231 --> 00:45:24.231
<v Speaker 1>So data structures,</v>
<v Speaker 1>other kinds of algorithmic tools for </v>

1032
00:45:24.231 --> 00:45:24.231
<v Speaker 1>representing knowledge.</v>
<v Speaker 1>Okay.</v>

1033
00:45:24.231 --> 00:45:27.510
<v Speaker 1>But you still have access to the ability</v>
<v Speaker 1>to do probabilistic inference,</v>

1034
00:45:27.540 --> 00:45:32.540
<v Speaker 1>like in a graphical model,</v>
<v Speaker 1>but also causal inference in a directed </v>

1035
00:45:32.540 --> 00:45:36.531
<v Speaker 1>graphical model.</v>
<v Speaker 1>So for those of you who know about </v>

1036
00:45:36.531 --> 00:45:36.531
<v Speaker 1>graphical models,</v>
<v Speaker 1>that might make some sense to you,</v>

1037
00:45:36.531 --> 00:45:37.980
<v Speaker 1>but just more broadly what this is,</v>
<v Speaker 1>think of this as,</v>

1038
00:45:37.981 --> 00:45:41.610
<v Speaker 1>as a toolkit that allows us to combine </v>
<v Speaker 1>several of the best ideas,</v>

1039
00:45:41.760 --> 00:45:43.770
<v Speaker 1>not just of the recent deep learning </v>
<v Speaker 1>era,</v>

1040
00:45:43.771 --> 00:45:48.771
<v Speaker 1>but over if you look back over the whole</v>
<v Speaker 1>scope of ai and as well as cognitive </v>

1041
00:45:48.771 --> 00:45:52.371
<v Speaker 1>science.</v>
<v Speaker 1>I think there's three or four ideas and </v>

1042
00:45:52.371 --> 00:45:56.091
<v Speaker 1>more but definitely like three ideas we </v>
<v Speaker 1>could really put up there that have </v>

1043
00:45:56.091 --> 00:45:59.571
<v Speaker 1>proven their worth and have had that </v>
<v Speaker 1>have risen and fallen in terms of each </v>

1044
00:45:59.571 --> 00:46:03.501
<v Speaker 1>of these had ideas when the mainstream </v>
<v Speaker 1>of the field thought this was totally </v>

1045
00:46:03.501 --> 00:46:06.651
<v Speaker 1>the way to go and every other idea was </v>
<v Speaker 1>was obviously a waste of time and also </v>

1046
00:46:06.651 --> 00:46:08.700
<v Speaker 1>had its time when many people thought it</v>
<v Speaker 1>was a waste of time.</v>

1047
00:46:08.820 --> 00:46:10.440
<v Speaker 1>Okay.</v>
<v Speaker 1>And these three big ideas,</v>

1048
00:46:10.441 --> 00:46:11.550
<v Speaker 1>I would say our.</v>
<v Speaker 1>First of all,</v>

1049
00:46:11.551 --> 00:46:16.551
<v Speaker 1>the idea of symbolic representation or </v>
<v Speaker 1>symbolic languages for knowledge </v>

1050
00:46:16.551 --> 00:46:20.421
<v Speaker 1>representation,</v>
<v Speaker 1>probabilistic inference in generative </v>

1051
00:46:20.421 --> 00:46:20.820
<v Speaker 1>models to capture uncertainty,</v>
<v Speaker 1>ambiguity,</v>

1052
00:46:20.970 --> 00:46:23.880
<v Speaker 1>learning from sparse data and in their </v>
<v Speaker 1>hierarchical setting,</v>

1053
00:46:24.030 --> 00:46:25.800
<v Speaker 1>learning to learn,</v>
<v Speaker 1>right?</v>

1054
00:46:25.950 --> 00:46:30.950
<v Speaker 1>And then of course the recent </v>
<v Speaker 1>developments with neuro inspired </v>

1055
00:46:30.950 --> 00:46:32.280
<v Speaker 1>architectures for pattern recognition.</v>
<v Speaker 1>Okay?</v>

1056
00:46:32.490 --> 00:46:34.350
<v Speaker 1>Each of these things,</v>
<v Speaker 1>each of these ideas,</v>

1057
00:46:34.590 --> 00:46:39.590
<v Speaker 1>symbolic languages,</v>
<v Speaker 1>probabilistic inference and neural </v>

1058
00:46:39.590 --> 00:46:42.171
<v Speaker 1>networks have some distinctive strengths</v>
<v Speaker 1>that are real weak points of the other </v>

1059
00:46:42.171 --> 00:46:42.171
<v Speaker 1>approaches,</v>
<v Speaker 1>right?</v>

1060
00:46:42.171 --> 00:46:44.130
<v Speaker 1>So to take one example that I haven't </v>
<v Speaker 1>really talked about here,</v>

1061
00:46:44.390 --> 00:46:46.320
<v Speaker 1>um,</v>
<v Speaker 1>people in the butt but you,</v>

1062
00:46:46.360 --> 00:46:49.200
<v Speaker 1>but you mentioned as an outstanding </v>
<v Speaker 1>challenge for neural networks,</v>

1063
00:46:49.350 --> 00:46:54.350
<v Speaker 1>transfer learning or learning to take </v>
<v Speaker 1>knowledge across a number of previous </v>

1064
00:46:54.350 --> 00:46:58.071
<v Speaker 1>tasks to transfer to others.</v>
<v Speaker 1>This is a real challenge and has always </v>

1065
00:46:58.071 --> 00:46:58.071
<v Speaker 1>been a challenge in a neural net.</v>

1066
00:46:58.071 --> 00:47:02.270
<v Speaker 1>Okay.</v>
<v Speaker 1>But if something that's addressed very </v>

1067
00:47:02.270 --> 00:47:02.270
<v Speaker 1>naturally and very scalably in,</v>
<v Speaker 1>for example,</v>

1068
00:47:02.270 --> 00:47:06.801
<v Speaker 1>a hierarchical basie and model,</v>
<v Speaker 1>and if you look at some of the recent </v>

1069
00:47:06.801 --> 00:47:09.921
<v Speaker 1>attempts,</v>
<v Speaker 1>really interesting attempts within the </v>

1070
00:47:09.921 --> 00:47:11.991
<v Speaker 1>deep learning world to try to get kinds </v>
<v Speaker 1>of transfer learning and learning to </v>

1071
00:47:11.991 --> 00:47:11.991
<v Speaker 1>learn,</v>
<v Speaker 1>they're really cool.</v>

1072
00:47:11.991 --> 00:47:16.011
<v Speaker 1>Okay.</v>
<v Speaker 1>But many of them are in some ways kind </v>

1073
00:47:16.011 --> 00:47:17.910
<v Speaker 1>of reinventing within a neural network </v>
<v Speaker 1>paradigm ideas that people,</v>

1074
00:47:17.940 --> 00:47:19.740
<v Speaker 1>you know,</v>
<v Speaker 1>maybe just 10 or 15 years ago,</v>

1075
00:47:19.920 --> 00:47:23.590
<v Speaker 1>developed in very sophisticated ways in </v>
<v Speaker 1>let's say hierarchical Bayesian models.</v>

1076
00:47:23.720 --> 00:47:28.720
<v Speaker 1>Okay.</v>
<v Speaker 1>And a lot of attempts to get sort of </v>

1077
00:47:28.720 --> 00:47:30.400
<v Speaker 1>symbolic an algorithm like behavior in </v>
<v Speaker 1>neural networks are really,</v>

1078
00:47:30.990 --> 00:47:35.990
<v Speaker 1>they're very small steps towards </v>
<v Speaker 1>something which is a very mature </v>

1079
00:47:35.990 --> 00:47:37.450
<v Speaker 1>technology in computer systems and </v>
<v Speaker 1>programming languages,</v>

1080
00:47:38.110 --> 00:47:41.800
<v Speaker 1>probabilistic programs,</v>
<v Speaker 1>I'll just sort of advertise mostly are a</v>

1081
00:47:41.801 --> 00:47:46.801
<v Speaker 1>way to combine the strengths of all of </v>
<v Speaker 1>these approaches to have knowledge </v>

1082
00:47:46.801 --> 00:47:48.790
<v Speaker 1>representations which are as expressive </v>
<v Speaker 1>as anything that anybody ever did in the</v>

1083
00:47:48.791 --> 00:47:53.791
<v Speaker 1>symbolic paradigm that are as flexible </v>
<v Speaker 1>at dealing with uncertainty and sparse </v>

1084
00:47:53.791 --> 00:47:55.360
<v Speaker 1>data as anything in the probabilistic </v>
<v Speaker 1>paradigm.</v>

1085
00:47:55.570 --> 00:47:59.650
<v Speaker 1>But that also can support pattern </v>
<v Speaker 1>recognition tools to be able to,</v>

1086
00:47:59.680 --> 00:48:01.030
<v Speaker 1>for example,</v>
<v Speaker 1>do very fast,</v>

1087
00:48:01.031 --> 00:48:03.700
<v Speaker 1>efficient inference in very complex </v>
<v Speaker 1>scenarios.</v>

1088
00:48:03.850 --> 00:48:05.420
<v Speaker 1>And there's a number of,</v>
<v Speaker 1>probably that's the,</v>

1089
00:48:05.450 --> 00:48:08.740
<v Speaker 1>that's the kind of conceptual framework.</v>
<v Speaker 1>There's a number of actually implemented</v>

1090
00:48:08.741 --> 00:48:09.880
<v Speaker 1>tools.</v>
<v Speaker 1>Um,</v>

1091
00:48:09.881 --> 00:48:14.881
<v Speaker 1>I point to here on the slide a number of</v>
<v Speaker 1>public programming languages which you </v>

1092
00:48:14.881 --> 00:48:14.920
<v Speaker 1>can go explore.</v>
<v Speaker 1>Um,</v>

1093
00:48:15.130 --> 00:48:20.130
<v Speaker 1>for example,</v>
<v Speaker 1>there's one that was developed in our </v>

1094
00:48:20.130 --> 00:48:20.130
<v Speaker 1>group a few years ago,</v>
<v Speaker 1>almost 10 years ago now called church,</v>

1095
00:48:20.130 --> 00:48:24.930
<v Speaker 1>which was the antecedent of some of </v>
<v Speaker 1>these other languages built on a </v>

1096
00:48:24.930 --> 00:48:27.511
<v Speaker 1>functional programming course.</v>
<v Speaker 1>A church is a problematic programming </v>

1097
00:48:27.511 --> 00:48:28.660
<v Speaker 1>language built on the lambda calculous </v>
<v Speaker 1>or really enlist basically,</v>

1098
00:48:29.020 --> 00:48:34.020
<v Speaker 1>um,</v>
<v Speaker 1>but there are many other more modern </v>

1099
00:48:34.020 --> 00:48:37.140
<v Speaker 1>tools,</v>
<v Speaker 1>especially if you are interested in </v>

1100
00:48:37.140 --> 00:48:37.140
<v Speaker 1>neural networks.</v>
<v Speaker 1>There are tools like,</v>

1101
00:48:37.140 --> 00:48:39.820
<v Speaker 1>for example,</v>
<v Speaker 1>pyro or prob torch or base flow that try</v>

1102
00:48:39.821 --> 00:48:42.760
<v Speaker 1>to combine all these ideas in a or,</v>
<v Speaker 1>or for example,</v>

1103
00:48:42.761 --> 00:48:47.761
<v Speaker 1>jen here,</v>
<v Speaker 1>which is a project of the Kauffman </v>

1104
00:48:47.761 --> 00:48:47.761
<v Speaker 1>singles problems,</v>
<v Speaker 1>the computing group.</v>

1105
00:48:47.761 --> 00:48:51.790
<v Speaker 1>Um,</v>
<v Speaker 1>these are all things which are just in </v>

1106
00:48:51.790 --> 00:48:51.790
<v Speaker 1>the very beginning stages,</v>
<v Speaker 1>very,</v>

1107
00:48:51.790 --> 00:48:56.091
<v Speaker 1>very alpha.</v>
<v Speaker 1>You can find out more about them online </v>

1108
00:48:56.091 --> 00:48:56.650
<v Speaker 1>or by writing to their creators.</v>
<v Speaker 1>And I think this is a,</v>

1109
00:48:56.710 --> 00:49:01.710
<v Speaker 1>this is a very exciting place where the </v>
<v Speaker 1>convergence of a number of different ai </v>

1110
00:49:01.710 --> 00:49:06.181
<v Speaker 1>tools are happening and when,</v>
<v Speaker 1>and this will be absolutely necessary </v>

1111
00:49:06.181 --> 00:49:08.440
<v Speaker 1>for making the kind of architecture that</v>
<v Speaker 1>I'm talking about work.</v>

1112
00:49:09.070 --> 00:49:11.770
<v Speaker 1>Another key idea which we've been </v>
<v Speaker 1>building on in our lab.</v>

1113
00:49:12.400 --> 00:49:13.630
<v Speaker 1>Um,</v>
<v Speaker 1>and I think again,</v>

1114
00:49:13.631 --> 00:49:15.550
<v Speaker 1>many people are using some version of </v>
<v Speaker 1>this idea,</v>

1115
00:49:15.551 --> 00:49:20.551
<v Speaker 1>but maybe a little bit different from </v>
<v Speaker 1>the way we're doing it is what will the </v>

1116
00:49:20.551 --> 00:49:25.050
<v Speaker 1>version of this idea that I like to talk</v>
<v Speaker 1>about is what I call the game engine in </v>

1117
00:49:25.050 --> 00:49:28.351
<v Speaker 1>the head.</v>
<v Speaker 1>So this is the idea that it's really </v>

1118
00:49:28.351 --> 00:49:31.741
<v Speaker 1>what the programs are about.</v>
<v Speaker 1>When I talk about problems with </v>

1119
00:49:31.741 --> 00:49:33.931
<v Speaker 1>programs,</v>
<v Speaker 1>I haven't said anything about what kind </v>

1120
00:49:33.931 --> 00:49:33.931
<v Speaker 1>of programs we're using.</v>

1121
00:49:33.931 --> 00:49:35.830
<v Speaker 1>We're just basically these programming </v>
<v Speaker 1>languages at their best and church.</v>

1122
00:49:35.831 --> 00:49:40.831
<v Speaker 1>The language that was developed by Noah </v>
<v Speaker 1>Goodman and mccosh and others and Dan </v>

1123
00:49:40.831 --> 00:49:45.210
<v Speaker 1>Roy in our group some 10 years ago was </v>
<v Speaker 1>intended to be a turing complete </v>

1124
00:49:45.210 --> 00:49:49.140
<v Speaker 1>probabilistic programming language.</v>
<v Speaker 1>So any probability model that was </v>

1125
00:49:49.140 --> 00:49:51.310
<v Speaker 1>computable or for who's inferences </v>
<v Speaker 1>conditional inferences are computable.</v>

1126
00:49:51.311 --> 00:49:55.090
<v Speaker 1>You could represent in these languages,</v>
<v Speaker 1>but that leaves completely open.</v>

1127
00:49:55.180 --> 00:49:56.620
<v Speaker 1>What,</v>
<v Speaker 1>what I'm actually going to,</v>

1128
00:49:56.660 --> 00:49:59.680
<v Speaker 1>what kind of protocol I'm going to write</v>
<v Speaker 1>to model the world.</v>

1129
00:49:59.980 --> 00:50:04.060
<v Speaker 1>And I've been very inspired in the last </v>
<v Speaker 1>few years by thinking about the kinds of</v>

1130
00:50:04.061 --> 00:50:06.670
<v Speaker 1>programs that are in modern video game </v>
<v Speaker 1>engines.</v>

1131
00:50:06.880 --> 00:50:07.840
<v Speaker 1>So again,</v>
<v Speaker 1>I'm probably,</v>

1132
00:50:07.841 --> 00:50:12.841
<v Speaker 1>most of you are familiar with these,</v>
<v Speaker 1>but if you're an increasingly they are </v>

1133
00:50:12.841 --> 00:50:12.841
<v Speaker 1>playing a role in all sorts of ways in </v>
<v Speaker 1>ai,</v>

1134
00:50:12.841 --> 00:50:17.581
<v Speaker 1>but these are tools that were developed </v>
<v Speaker 1>by the video game industry to allow a </v>

1135
00:50:17.581 --> 00:50:20.770
<v Speaker 1>game designer to make a new game with,</v>
<v Speaker 1>without having to do most of,</v>

1136
00:50:20.820 --> 00:50:23.770
<v Speaker 1>in some sense many it must have the hard</v>
<v Speaker 1>technical work by from scratch,</v>

1137
00:50:23.980 --> 00:50:26.950
<v Speaker 1>but rather to focus on the characters,</v>
<v Speaker 1>the world,</v>

1138
00:50:27.020 --> 00:50:28.280
<v Speaker 1>the story,</v>
<v Speaker 1>okay.</v>

1139
00:50:28.280 --> 00:50:29.820
<v Speaker 1>The things that are more interesting </v>
<v Speaker 1>for,</v>

1140
00:50:30.040 --> 00:50:32.680
<v Speaker 1>for designing a novel game in </v>
<v Speaker 1>particular,</v>

1141
00:50:32.681 --> 00:50:37.681
<v Speaker 1>we,</v>
<v Speaker 1>if we want the player to explore some </v>

1142
00:50:37.681 --> 00:50:40.390
<v Speaker 1>new three dimensional world,</v>
<v Speaker 1>but to have them be able to interact </v>

1143
00:50:40.390 --> 00:50:42.470
<v Speaker 1>with the world in real time and to </v>
<v Speaker 1>render nice looking graphics in,</v>

1144
00:50:42.550 --> 00:50:47.550
<v Speaker 1>in real time,</v>
<v Speaker 1>in an interactive way as the player </v>

1145
00:50:47.550 --> 00:50:49.841
<v Speaker 1>moves around and explores the world or </v>
<v Speaker 1>if you want to populate the world with </v>

1146
00:50:49.841 --> 00:50:51.470
<v Speaker 1>non player characters that will behave </v>
<v Speaker 1>in a even vaguely intelligent way.</v>

1147
00:50:51.800 --> 00:50:56.800
<v Speaker 1>Okay.</v>
<v Speaker 1>Game engines give you tools for doing </v>

1148
00:50:56.800 --> 00:50:58.841
<v Speaker 1>all of this without having to write all </v>
<v Speaker 1>of graphics from scratch or all of </v>

1149
00:50:58.841 --> 00:51:00.110
<v Speaker 1>physics.</v>
<v Speaker 1>The rules of physics from scratch.</v>

1150
00:51:00.470 --> 00:51:05.470
<v Speaker 1>Um,</v>
<v Speaker 1>so what are called game physics engines </v>

1151
00:51:05.470 --> 00:51:06.710
<v Speaker 1>and in some sense are a set of </v>
<v Speaker 1>principles but also hacks from newtonian</v>

1152
00:51:06.711 --> 00:51:11.711
<v Speaker 1>mechanics and other areas of physics </v>
<v Speaker 1>that allow you to simulate plausible </v>

1153
00:51:11.711 --> 00:51:13.280
<v Speaker 1>looking physical interactions in very </v>
<v Speaker 1>complex world,</v>

1154
00:51:14.000 --> 00:51:15.770
<v Speaker 1>very approximately,</v>
<v Speaker 1>but very fast.</v>

1155
00:51:16.370 --> 00:51:19.400
<v Speaker 1>There's also what's called [inaudible],</v>
<v Speaker 1>which are basically very simple planning</v>

1156
00:51:19.401 --> 00:51:21.920
<v Speaker 1>models.</v>
<v Speaker 1>So let's say I want to have an ai in the</v>

1157
00:51:21.921 --> 00:51:26.921
<v Speaker 1>game that is like a guard that gardens </v>
<v Speaker 1>have base and a player is going to </v>

1158
00:51:26.921 --> 00:51:28.040
<v Speaker 1>attack the space.</v>
<v Speaker 1>So back in the old Atari days,</v>

1159
00:51:28.041 --> 00:51:29.510
<v Speaker 1>like when I was a kid,</v>
<v Speaker 1>you know,</v>

1160
00:51:29.600 --> 00:51:34.600
<v Speaker 1>the guards would just be like random </v>
<v Speaker 1>things that would fire missiles kind of </v>

1161
00:51:34.600 --> 00:51:34.940
<v Speaker 1>randomly in random directions at random </v>
<v Speaker 1>times,</v>

1162
00:51:34.970 --> 00:51:39.970
<v Speaker 1>right?</v>
<v Speaker 1>But let's say you want a garden to be a </v>

1163
00:51:39.970 --> 00:51:39.970
<v Speaker 1>little intelligent,</v>
<v Speaker 1>so to actually look around and Oh,</v>

1164
00:51:39.970 --> 00:51:44.261
<v Speaker 1>and I see the player and then to </v>
<v Speaker 1>actually start shooting at you and to </v>

1165
00:51:44.261 --> 00:51:46.871
<v Speaker 1>even maybe pursue you.</v>
<v Speaker 1>So that requires putting a little ai in </v>

1166
00:51:46.871 --> 00:51:50.111
<v Speaker 1>the game.</v>
<v Speaker 1>And you do that by having basically </v>

1167
00:51:50.111 --> 00:51:50.900
<v Speaker 1>simple agent models in the game.</v>
<v Speaker 1>So what we think,</v>

1168
00:51:51.140 --> 00:51:56.140
<v Speaker 1>and some of you might think this is </v>
<v Speaker 1>crazy and some of you might think this </v>

1169
00:51:56.140 --> 00:51:56.660
<v Speaker 1>is very natural idea,</v>
<v Speaker 1>I get both kinds of reactions.</v>

1170
00:51:56.900 --> 00:51:59.830
<v Speaker 1>What we think is that these tools have,</v>
<v Speaker 1>you know,</v>

1171
00:51:59.870 --> 00:52:04.870
<v Speaker 1>fast,</v>
<v Speaker 1>approximate renderers physics engines </v>

1172
00:52:04.870 --> 00:52:07.091
<v Speaker 1>and sort of very simple kinds of ai </v>
<v Speaker 1>planning are an interesting first </v>

1173
00:52:07.091 --> 00:52:10.781
<v Speaker 1>approximation to the kinds of common </v>
<v Speaker 1>sense knowledge representations that </v>

1174
00:52:10.781 --> 00:52:13.850
<v Speaker 1>evolution has built into our brains.</v>
<v Speaker 1>So when we talk about the cognitive core</v>

1175
00:52:14.210 --> 00:52:16.460
<v Speaker 1>or how do babies start,</v>
<v Speaker 1>what's,</v>

1176
00:52:16.610 --> 00:52:21.610
<v Speaker 1>you know,</v>
<v Speaker 1>ways in which a baby's brain isn't a </v>

1177
00:52:21.610 --> 00:52:23.981
<v Speaker 1>blank slate.</v>
<v Speaker 1>One interesting idea is that it starts </v>

1178
00:52:23.981 --> 00:52:26.861
<v Speaker 1>with something like these tools and then</v>
<v Speaker 1>wrapped inside a framework for </v>

1179
00:52:26.861 --> 00:52:31.271
<v Speaker 1>probabilistic inference.</v>
<v Speaker 1>That's what we mean by promising </v>

1180
00:52:31.271 --> 00:52:33.191
<v Speaker 1>programs that can support many </v>
<v Speaker 1>activities of common sense perception </v>

1181
00:52:33.191 --> 00:52:35.030
<v Speaker 1>and thinking.</v>
<v Speaker 1>So I'll just give you one example,</v>

1182
00:52:35.540 --> 00:52:37.460
<v Speaker 1>what we call this intuitive physics </v>
<v Speaker 1>engine.</v>

1183
00:52:37.730 --> 00:52:42.730
<v Speaker 1>Okay.</v>
<v Speaker 1>So this is work that we did in our </v>

1184
00:52:42.730 --> 00:52:42.730
<v Speaker 1>groups that Pete,</v>
<v Speaker 1>Natalia,</v>

1185
00:52:42.730 --> 00:52:46.031
<v Speaker 1>and Jess Hamrick did started this work </v>
<v Speaker 1>about five years ago now where we showed</v>

1186
00:52:47.001 --> 00:52:52.001
<v Speaker 1>people in some sense this is also an </v>
<v Speaker 1>illustration of a kind of experiment </v>

1187
00:52:52.001 --> 00:52:52.001
<v Speaker 1>that you might do.</v>

1188
00:52:52.340 --> 00:52:57.340
<v Speaker 1>I keep talking about science,</v>
<v Speaker 1>like I'll show you now a couple of </v>

1189
00:52:57.340 --> 00:52:57.340
<v Speaker 1>experiments,</v>
<v Speaker 1>right?</v>

1190
00:52:57.340 --> 00:52:59.570
<v Speaker 1>So we would show people simple physical </v>
<v Speaker 1>scenes like these blocks worlds scenes,</v>

1191
00:52:59.571 --> 00:53:01.340
<v Speaker 1>and asked them to make a number of </v>
<v Speaker 1>judgments.</v>

1192
00:53:01.610 --> 00:53:06.610
<v Speaker 1>And the model we built does it basically</v>
<v Speaker 1>a little bit of probabilistic inference </v>

1193
00:53:06.610 --> 00:53:10.301
<v Speaker 1>in a game style physics engine.</v>
<v Speaker 1>It perceives the physical state and </v>

1194
00:53:10.301 --> 00:53:14.320
<v Speaker 1>imagines a few different possible ways </v>
<v Speaker 1>the world could go over the next one or </v>

1195
00:53:14.320 --> 00:53:16.580
<v Speaker 1>two seconds to answer questions like </v>
<v Speaker 1>will the stack of blocks fall?</v>

1196
00:53:16.790 --> 00:53:18.590
<v Speaker 1>Or if they fall,</v>
<v Speaker 1>how far will they fall?</v>

1197
00:53:18.650 --> 00:53:23.650
<v Speaker 1>Or which way will they fall?</v>
<v Speaker 1>Or what would happen if say one of the </v>

1198
00:53:23.650 --> 00:53:27.310
<v Speaker 1>colored one color of blocks or one </v>
<v Speaker 1>material like the green stuff is 10 </v>

1199
00:53:27.310 --> 00:53:28.140
<v Speaker 1>times heavier than the gray stuff or </v>
<v Speaker 1>vice versa.</v>

1200
00:53:28.170 --> 00:53:33.170
<v Speaker 1>How will that change the direction of </v>
<v Speaker 1>fall or look at those red and yellow </v>

1201
00:53:33.170 --> 00:53:36.411
<v Speaker 1>stack blocks,</v>
<v Speaker 1>some of which look like they should be </v>

1202
00:53:36.411 --> 00:53:36.411
<v Speaker 1>falling but aren't.</v>

1203
00:53:36.411 --> 00:53:40.010
<v Speaker 1>So why can you infer from the fact that </v>
<v Speaker 1>they are not fall in that one color </v>

1204
00:53:40.010 --> 00:53:44.781
<v Speaker 1>block is much heavier than the other.</v>
<v Speaker 1>Or let me show you a sort of a slightly </v>

1205
00:53:44.781 --> 00:53:49.101
<v Speaker 1>weird task.</v>
<v Speaker 1>It's an like other behavioral </v>

1206
00:53:49.101 --> 00:53:51.681
<v Speaker 1>experiments.</v>
<v Speaker 1>Sometimes we do weird things so that we </v>

1207
00:53:51.681 --> 00:53:52.800
<v Speaker 1>can test ways in which you use your </v>
<v Speaker 1>knowledge that you didn't just,</v>

1208
00:53:52.930 --> 00:53:54.750
<v Speaker 1>you know,</v>
<v Speaker 1>learn from pattern recognition,</v>

1209
00:53:54.900 --> 00:53:58.230
<v Speaker 1>but use it to do new kinds of tasks that</v>
<v Speaker 1>you'd never seen before.</v>

1210
00:53:58.470 --> 00:54:02.340
<v Speaker 1>So here's a task which many of you have </v>
<v Speaker 1>maybe seen me talk about these things.</v>

1211
00:54:02.341 --> 00:54:07.341
<v Speaker 1>So you might have seen this task,</v>
<v Speaker 1>but probably only if you saw me give a </v>

1212
00:54:07.341 --> 00:54:07.341
<v Speaker 1>talk around here before we call this the</v>
<v Speaker 1>red,</v>

1213
00:54:07.341 --> 00:54:12.201
<v Speaker 1>yellow task.</v>
<v Speaker 1>And again we'll make this one </v>

1214
00:54:12.201 --> 00:54:13.731
<v Speaker 1>interactive.</v>
<v Speaker 1>So imagine that the blocks on the table </v>

1215
00:54:13.731 --> 00:54:15.030
<v Speaker 1>or knocked hard enough to bump the </v>
<v Speaker 1>tables,</v>

1216
00:54:15.040 --> 00:54:17.890
<v Speaker 1>bumped hard enough to knock some of the </v>
<v Speaker 1>blocks onto the floor.</v>

1217
00:54:18.160 --> 00:54:23.160
<v Speaker 1>So you tell me,</v>
<v Speaker 1>is it more likely to be red blocks or </v>

1218
00:54:23.160 --> 00:54:23.160
<v Speaker 1>yellow blocks?</v>
<v Speaker 1>What do you say?</v>

1219
00:54:23.160 --> 00:54:23.160
<v Speaker 1>Red.</v>
<v Speaker 1>Okay,</v>

1220
00:54:23.160 --> 00:54:24.940
<v Speaker 1>good.</v>
<v Speaker 1>How about here?</v>

1221
00:54:25.300 --> 00:54:25.390
<v Speaker 3>Yeah,</v>

1222
00:54:27.140 --> 00:54:27.770
<v Speaker 1>yellow.</v>
<v Speaker 1>Good.</v>

1223
00:54:27.800 --> 00:54:30.190
<v Speaker 1>How about here?</v>
<v Speaker 1>Uh Huh.</v>

1224
00:54:30.640 --> 00:54:33.250
<v Speaker 3>Here,</v>
<v Speaker 3>here.</v>

1225
00:54:34.890 --> 00:54:38.850
<v Speaker 3>Okay.</v>
<v Speaker 3>Here.</v>

1226
00:54:40.700 --> 00:54:40.950
<v Speaker 3>Here.</v>

1227
00:54:42.390 --> 00:54:43.130
<v Speaker 1>Okay.</v>
<v Speaker 1>So,</v>

1228
00:54:43.270 --> 00:54:48.270
<v Speaker 1>so you just experienced for yourself </v>
<v Speaker 1>what it's like to be a subject and one </v>

1229
00:54:48.270 --> 00:54:48.270
<v Speaker 1>of these expenses.</v>
<v Speaker 1>We just did the experiment here.</v>

1230
00:54:48.270 --> 00:54:50.100
<v Speaker 1>The data's is all captured on video,</v>
<v Speaker 1>sort of.</v>

1231
00:54:50.610 --> 00:54:54.240
<v Speaker 1>Okay.</v>
<v Speaker 1>You could see that sometimes people were</v>

1232
00:54:54.241 --> 00:54:55.950
<v Speaker 1>very quick.</v>
<v Speaker 1>Other times people were slower,</v>

1233
00:54:56.010 --> 00:55:01.010
<v Speaker 1>sometimes there was a lot of consensus,</v>
<v Speaker 1>sometimes there was a little bit less </v>

1234
00:55:01.010 --> 00:55:01.010
<v Speaker 1>consensus.</v>
<v Speaker 1>Right?</v>

1235
00:55:01.010 --> 00:55:01.860
<v Speaker 1>That reflects uncertainty.</v>
<v Speaker 1>So again,</v>

1236
00:55:01.861 --> 00:55:04.320
<v Speaker 1>there's a long history of studying this </v>
<v Speaker 1>scientifically,</v>

1237
00:55:04.680 --> 00:55:05.760
<v Speaker 1>um,</v>
<v Speaker 1>that,</v>

1238
00:55:05.790 --> 00:55:06.270
<v Speaker 1>you know,</v>
<v Speaker 1>you could,</v>

1239
00:55:06.300 --> 00:55:11.300
<v Speaker 1>but you can see some,</v>
<v Speaker 1>you can see the probabilistic inference </v>

1240
00:55:11.300 --> 00:55:11.700
<v Speaker 1>at work.</v>
<v Speaker 1>Probabilistic inference over what?</v>

1241
00:55:11.850 --> 00:55:16.850
<v Speaker 1>Well,</v>
<v Speaker 1>I would say one way to describe it is </v>

1242
00:55:16.850 --> 00:55:18.330
<v Speaker 1>over a one or a few short,</v>
<v Speaker 1>low precision simulations of the physics</v>

1243
00:55:18.331 --> 00:55:20.550
<v Speaker 1>of these scenes.</v>
<v Speaker 1>So here is what I mean by this.</v>

1244
00:55:20.850 --> 00:55:25.850
<v Speaker 1>I'm going to show you a video of a game </v>
<v Speaker 1>engine reconstruction of one of these </v>

1245
00:55:25.850 --> 00:55:26.440
<v Speaker 1>scenes that simulates a small.</v>

1246
00:55:26.810 --> 00:55:30.110
<v Speaker 1>So here's a small bump,</v>
<v Speaker 1>here's that same scene with a big bump.</v>

1247
00:55:30.170 --> 00:55:32.780
<v Speaker 1>Okay,</v>
<v Speaker 1>now notice that at the micro level,</v>

1248
00:55:32.810 --> 00:55:36.280
<v Speaker 1>different things happen,</v>
<v Speaker 1>but at the cognitive or macro level that</v>

1249
00:55:36.281 --> 00:55:38.500
<v Speaker 1>matters for common sense reasoning,</v>
<v Speaker 1>the same thing happen,</v>

1250
00:55:38.590 --> 00:55:43.590
<v Speaker 1>namely all the yellow blocks went over </v>
<v Speaker 1>onto one side of the table and few or </v>

1251
00:55:43.590 --> 00:55:47.041
<v Speaker 1>none of the red blocks did so it didn't </v>
<v Speaker 1>matter which of those simulations you </v>

1252
00:55:47.041 --> 00:55:47.470
<v Speaker 1>run in your head,</v>
<v Speaker 1>you'd get the same answer in this case,</v>

1253
00:55:47.471 --> 00:55:52.471
<v Speaker 1>right?</v>
<v Speaker 1>This is one that's very easy and high </v>

1254
00:55:52.471 --> 00:55:52.471
<v Speaker 1>confidence.</v>
<v Speaker 1>And also you,</v>

1255
00:55:52.471 --> 00:55:52.990
<v Speaker 1>you didn't have to run the simulation </v>
<v Speaker 1>for very long.</v>

1256
00:55:52.991 --> 00:55:57.991
<v Speaker 1>You only have to run it for a few times.</v>
<v Speaker 1>Steps like that to see what's going to </v>

1257
00:55:57.991 --> 00:55:57.991
<v Speaker 1>happen.</v>
<v Speaker 1>Or similarly here,</v>

1258
00:55:57.991 --> 00:55:58.690
<v Speaker 1>you only have to run it for a few times.</v>
<v Speaker 1>Steps,</v>

1259
00:55:58.750 --> 00:56:03.750
<v Speaker 1>okay?</v>
<v Speaker 1>And it doesn't have to be even very </v>

1260
00:56:03.750 --> 00:56:03.750
<v Speaker 1>accurate.</v>

1261
00:56:03.750 --> 00:56:06.210
<v Speaker 1>Even a fair amount of imprecision will </v>
<v Speaker 1>give you basically the same answer at </v>

1262
00:56:06.210 --> 00:56:09.931
<v Speaker 1>the level that matters for common sense.</v>
<v Speaker 1>So that's the kind of thing our model </v>

1263
00:56:09.931 --> 00:56:13.111
<v Speaker 1>does.</v>
<v Speaker 1>It runs a few low precision simulations </v>

1264
00:56:13.111 --> 00:56:15.721
<v Speaker 1>for a few times steps.</v>
<v Speaker 1>But if you take the average of what </v>

1265
00:56:15.721 --> 00:56:15.760
<v Speaker 1>happens there and you compare that with </v>
<v Speaker 1>people's judgments,</v>

1266
00:56:15.761 --> 00:56:17.680
<v Speaker 1>you get results like what I show you </v>
<v Speaker 1>here,</v>

1267
00:56:17.730 --> 00:56:22.210
<v Speaker 1>the scatter plot shows on the y axis,</v>
<v Speaker 1>the average judgments of people on the x</v>

1268
00:56:22.211 --> 00:56:23.860
<v Speaker 1>axis,</v>
<v Speaker 1>the average of this model,</v>

1269
00:56:23.861 --> 00:56:25.690
<v Speaker 1>and it does a pretty good job.</v>
<v Speaker 1>It's not perfect,</v>

1270
00:56:25.870 --> 00:56:30.870
<v Speaker 1>but the model basically captures peoples</v>
<v Speaker 1>graded sense of what's going on in this </v>

1271
00:56:30.870 --> 00:56:31.780
<v Speaker 1>scene and many of these others,</v>
<v Speaker 1>okay.</v>

1272
00:56:33.330 --> 00:56:36.130
<v Speaker 1>And it doesn't do it with any learning,</v>
<v Speaker 1>but I'll come back to that in a second.</v>

1273
00:56:36.160 --> 00:56:41.160
<v Speaker 1>It just does it by probabilistic </v>
<v Speaker 1>reasoning over a game physics </v>

1274
00:56:41.160 --> 00:56:42.220
<v Speaker 1>simulation.</v>
<v Speaker 1>Now we can use and we have used the same</v>

1275
00:56:42.221 --> 00:56:45.360
<v Speaker 1>kind of technology to capture in very </v>
<v Speaker 1>simple form.</v>

1276
00:56:45.370 --> 00:56:47.440
<v Speaker 1>It's really just proofs of concept at </v>
<v Speaker 1>this point,</v>

1277
00:56:47.680 --> 00:56:52.680
<v Speaker 1>but kind of common sense physical scene </v>
<v Speaker 1>understanding in child and a child </v>

1278
00:56:52.680 --> 00:56:55.120
<v Speaker 1>playing with blocks or other objects or </v>
<v Speaker 1>in what might go on in a young child,</v>

1279
00:56:55.121 --> 00:57:00.121
<v Speaker 1>understanding of other people's actions,</v>
<v Speaker 1>what we call the intuitive psychology </v>

1280
00:57:00.121 --> 00:57:00.121
<v Speaker 1>engine.</v>
<v Speaker 1>We're now,</v>

1281
00:57:00.121 --> 00:57:04.830
<v Speaker 1>the programs are defined over these kind</v>
<v Speaker 1>of very simple planning and perception </v>

1282
00:57:04.830 --> 00:57:05.890
<v Speaker 1>programs and I won't go into any </v>
<v Speaker 1>details.</v>

1283
00:57:05.891 --> 00:57:10.891
<v Speaker 1>I'll just point to a couple of papers </v>
<v Speaker 1>that my group played a very small role </v>

1284
00:57:10.891 --> 00:57:14.521
<v Speaker 1>in,</v>
<v Speaker 1>but we provided some models which </v>

1285
00:57:14.521 --> 00:57:16.411
<v Speaker 1>together with some infant researchers,</v>
<v Speaker 1>people working on both of these are </v>

1286
00:57:16.411 --> 00:57:18.250
<v Speaker 1>experiments that were done with 10 or 12</v>
<v Speaker 1>month infant,</v>

1287
00:57:18.251 --> 00:57:20.920
<v Speaker 1>so younger than even some of the babies </v>
<v Speaker 1>I showed you before,</v>

1288
00:57:20.921 --> 00:57:23.710
<v Speaker 1>but basically like that youngest baby,</v>
<v Speaker 1>the one with the cat.</v>

1289
00:57:24.400 --> 00:57:27.160
<v Speaker 1>Here's an example of showing simple </v>
<v Speaker 1>physical scenes.</v>

1290
00:57:27.161 --> 00:57:32.161
<v Speaker 1>These are moving objects to 12 month </v>
<v Speaker 1>olds where they saw a few objects </v>

1291
00:57:32.171 --> 00:57:37.171
<v Speaker 1>bouncing around inside a gumball machine</v>
<v Speaker 1>and after some point in time the scene </v>

1292
00:57:37.171 --> 00:57:37.171
<v Speaker 1>gets occluded.</v>

1293
00:57:37.171 --> 00:57:39.520
<v Speaker 1>You'll see the scene as occluded and </v>
<v Speaker 1>then after another period of time,</v>

1294
00:57:39.521 --> 00:57:42.760
<v Speaker 1>but one of the objects will appear at </v>
<v Speaker 1>the bottom and the question is,</v>

1295
00:57:42.761 --> 00:57:46.360
<v Speaker 1>is that the audit you expected to see or</v>
<v Speaker 1>not is it's expected or surprising?</v>

1296
00:57:46.600 --> 00:57:51.600
<v Speaker 1>The standard way you study what infants </v>
<v Speaker 1>know is by is by what's called looking </v>

1297
00:57:51.600 --> 00:57:51.700
<v Speaker 1>time methods.</v>
<v Speaker 1>Just like an adult.</v>

1298
00:57:51.880 --> 00:57:53.320
<v Speaker 1>If I show you something that's </v>
<v Speaker 1>surprising,</v>

1299
00:57:53.321 --> 00:57:54.700
<v Speaker 1>you might look longer.</v>
<v Speaker 1>Okay.</v>

1300
00:57:54.850 --> 00:57:56.140
<v Speaker 1>If you're bored,</v>
<v Speaker 1>you'll look away.</v>

1301
00:57:56.170 --> 00:57:57.130
<v Speaker 1>All right?</v>
<v Speaker 1>Um,</v>

1302
00:57:57.850 --> 00:58:02.850
<v Speaker 1>so you can do that same kind of thing </v>
<v Speaker 1>with infants and by measuring how long </v>

1303
00:58:02.850 --> 00:58:06.991
<v Speaker 1>they look at a scene,</v>
<v Speaker 1>you can measure whether you've shown </v>

1304
00:58:06.991 --> 00:58:06.991
<v Speaker 1>them something surprising or not.</v>
<v Speaker 1>All right?</v>

1305
00:58:06.991 --> 00:58:08.470
<v Speaker 1>People.</v>
<v Speaker 1>There are literally hundreds of studies,</v>

1306
00:58:08.471 --> 00:58:13.471
<v Speaker 1>if not more,</v>
<v Speaker 1>using looking time measures to study </v>

1307
00:58:13.471 --> 00:58:16.681
<v Speaker 1>what infants know,</v>
<v Speaker 1>but only with this paper that we </v>

1308
00:58:16.681 --> 00:58:17.920
<v Speaker 1>published a few years ago did we have a </v>
<v Speaker 1>quantitative model,</v>

1309
00:58:17.921 --> 00:58:21.490
<v Speaker 1>but we're able to show a relation </v>
<v Speaker 1>between inverse probability in this case</v>

1310
00:58:21.491 --> 00:58:26.491
<v Speaker 1>and surprise,</v>
<v Speaker 1>so things which were objectively lower </v>

1311
00:58:26.491 --> 00:58:26.980
<v Speaker 1>probability under one of these </v>
<v Speaker 1>probabilistic physics simulations across</v>

1312
00:58:26.981 --> 00:58:30.300
<v Speaker 1>a number of different manipulations of </v>
<v Speaker 1>how fast the objects were,</v>

1313
00:58:30.301 --> 00:58:31.840
<v Speaker 1>where they were when the scene was </v>
<v Speaker 1>occluded,</v>

1314
00:58:31.841 --> 00:58:34.360
<v Speaker 1>how long the delay was,</v>
<v Speaker 1>various physically relevant variables,</v>

1315
00:58:34.510 --> 00:58:39.510
<v Speaker 1>how many objects that were of one type </v>
<v Speaker 1>or another infant's expectations </v>

1316
00:58:39.510 --> 00:58:42.480
<v Speaker 1>connected with this model or another </v>
<v Speaker 1>paper that we published that one was,</v>

1317
00:58:42.580 --> 00:58:43.120
<v Speaker 1>was done.</v>

1318
00:58:43.490 --> 00:58:46.810
<v Speaker 1>The experiments that were done by </v>
<v Speaker 1>Aaronow tagless and Luca Menotti's lab.</v>

1319
00:58:47.170 --> 00:58:50.790
<v Speaker 1>Here is a study that was done just </v>
<v Speaker 1>recently by Sheri Lou enlists,</v>

1320
00:58:50.791 --> 00:58:52.510
<v Speaker 1>spelled [inaudible] lab at there at </v>
<v Speaker 1>Harvard,</v>

1321
00:58:52.511 --> 00:58:54.670
<v Speaker 1>but they're part,</v>
<v Speaker 1>they're partners with us in CBMM,</v>

1322
00:58:55.030 --> 00:58:56.980
<v Speaker 1>which was about infants understanding of</v>
<v Speaker 1>goals,</v>

1323
00:58:56.981 --> 00:59:01.981
<v Speaker 1>so this is more like again,</v>
<v Speaker 1>understanding of agents and intuitive </v>

1324
00:59:01.981 --> 00:59:01.981
<v Speaker 1>psychology.</v>
<v Speaker 1>We're in,</v>

1325
00:59:01.981 --> 00:59:02.800
<v Speaker 1>again,</v>
<v Speaker 1>in very simple cartoon scenes,</v>

1326
00:59:03.430 --> 00:59:08.430
<v Speaker 1>you show an infant and agent that seems </v>
<v Speaker 1>to be doing something like an animated </v>

1327
00:59:08.430 --> 00:59:12.031
<v Speaker 1>cartoon character,</v>
<v Speaker 1>but it jumps over a wall or it rolls up </v>

1328
00:59:12.031 --> 00:59:15.481
<v Speaker 1>a hill or it jumps over a gap and the </v>
<v Speaker 1>question is basically how much does the </v>

1329
00:59:15.491 --> 00:59:20.491
<v Speaker 1>agent want the goal that it seems to be </v>
<v Speaker 1>trying to achieve and what this study </v>

1330
00:59:20.491 --> 00:59:20.491
<v Speaker 1>showed.</v>
<v Speaker 1>Okay,</v>

1331
00:59:20.491 --> 00:59:25.110
<v Speaker 1>and the models here we're done by Tomer </v>
<v Speaker 1>omen was that infants appeared to be </v>

1332
00:59:25.110 --> 00:59:26.780
<v Speaker 1>sensitive to the physical work done by </v>
<v Speaker 1>the agent.</v>

1333
00:59:26.990 --> 00:59:31.990
<v Speaker 1>The more work the agent did in the sense</v>
<v Speaker 1>of the integral of force applied over a </v>

1334
00:59:31.990 --> 00:59:36.641
<v Speaker 1>path,</v>
<v Speaker 1>the more the the infant's thought the </v>

1335
00:59:36.641 --> 00:59:39.881
<v Speaker 1>agent wanted the goal.</v>
<v Speaker 1>We think of this as representing what </v>

1336
00:59:39.881 --> 00:59:40.970
<v Speaker 1>we've sometimes called the naive utility</v>
<v Speaker 1>calculus.</v>

1337
00:59:41.180 --> 00:59:43.530
<v Speaker 1>So the idea that there's a basic </v>
<v Speaker 1>calculus of,</v>

1338
00:59:43.760 --> 00:59:45.990
<v Speaker 1>of costs and benefits,</v>
<v Speaker 1>as you know,</v>

1339
00:59:46.040 --> 00:59:49.100
<v Speaker 1>we take actions which are a little bit </v>
<v Speaker 1>costly to achieve goal states,</v>

1340
00:59:49.101 --> 00:59:51.920
<v Speaker 1>which gives us some reward that's the </v>
<v Speaker 1>most basic way,</v>

1341
00:59:51.921 --> 00:59:56.921
<v Speaker 1>the oldest way to think about rational,</v>
<v Speaker 1>intentional action and it seems that </v>

1342
00:59:56.921 --> 01:00:00.401
<v Speaker 1>even 10 month olds understand some </v>
<v Speaker 1>version of that where the cost can be </v>

1343
01:00:00.401 --> 01:00:01.220
<v Speaker 1>measured in physical terms.</v>
<v Speaker 1>Okay.</v>

1344
01:00:01.580 --> 01:00:03.260
<v Speaker 1>Um,</v>
<v Speaker 1>I see I'm running a little bit behind on</v>

1345
01:00:03.261 --> 01:00:04.130
<v Speaker 1>time and,</v>
<v Speaker 1>and,</v>

1346
01:00:04.430 --> 01:00:09.430
<v Speaker 1>uh,</v>
<v Speaker 1>I wanted to leave some time for </v>

1347
01:00:09.430 --> 01:00:10.601
<v Speaker 1>discussion so I'll,</v>
<v Speaker 1>I'll just go very quickly through a </v>

1348
01:00:10.601 --> 01:00:11.960
<v Speaker 1>couple of other things and I'm happy to </v>
<v Speaker 1>stay around at the end for discussion.</v>

1349
01:00:11.990 --> 01:00:13.090
<v Speaker 1>Okay.</v>
<v Speaker 1>Um,</v>

1350
01:00:13.870 --> 01:00:16.400
<v Speaker 1>the,</v>
<v Speaker 1>what I showed you here was the science.</v>

1351
01:00:16.401 --> 01:00:18.380
<v Speaker 1>Where does the engineering go?</v>
<v Speaker 1>So one way,</v>

1352
01:00:18.381 --> 01:00:22.630
<v Speaker 1>one thing you can do with this is say </v>
<v Speaker 1>build a machine system that can look not</v>

1353
01:00:22.640 --> 01:00:25.280
<v Speaker 1>a little animated cartoon like these </v>
<v Speaker 1>baby experiments,</v>

1354
01:00:25.370 --> 01:00:27.350
<v Speaker 1>but a real person doing something and </v>
<v Speaker 1>again,</v>

1355
01:00:27.440 --> 01:00:31.370
<v Speaker 1>combined physical cough and constraints </v>
<v Speaker 1>of actions with some understanding of,</v>

1356
01:00:31.390 --> 01:00:32.720
<v Speaker 1>of the agents,</v>
<v Speaker 1>utilities,</v>

1357
01:00:32.721 --> 01:00:36.620
<v Speaker 1>that's the math of planning.</v>
<v Speaker 1>Trying to figure out what they wanted.</v>

1358
01:00:36.950 --> 01:00:41.950
<v Speaker 1>So look in the scene here and see if you</v>
<v Speaker 1>can judge which object the woman is </v>

1359
01:00:41.950 --> 01:00:43.370
<v Speaker 1>reaching for.</v>
<v Speaker 1>So you can see there's,</v>

1360
01:00:43.970 --> 01:00:44.460
<v Speaker 1>there's,</v>
<v Speaker 1>um,</v>

1361
01:00:44.510 --> 01:00:49.510
<v Speaker 1>a grid of four by four objects.</v>
<v Speaker 1>There's 16 objects here and she's going </v>

1362
01:00:49.510 --> 01:00:50.990
<v Speaker 1>to be reaching for one of them raised.</v>
<v Speaker 1>It's going to play in slow motion,</v>

1363
01:00:50.991 --> 01:00:53.390
<v Speaker 1>but raise your hand when you know which </v>
<v Speaker 1>ones he's reaching for.</v>

1364
01:00:53.450 --> 01:00:58.450
<v Speaker 1>Okay?</v>
<v Speaker 1>So just watch and raise your hand when </v>

1365
01:00:58.450 --> 01:00:58.450
<v Speaker 1>you know which one she wants.</v>

1366
01:01:00.550 --> 01:01:02.060
<v Speaker 1>Okay,</v>
<v Speaker 1>so most of the hands are up by now.</v>

1367
01:01:02.110 --> 01:01:04.370
<v Speaker 1>All right.</v>
<v Speaker 1>And notice I was looking at your hands.</v>

1368
01:01:04.371 --> 01:01:05.120
<v Speaker 1>Not here,</v>
<v Speaker 1>but when.</v>

1369
01:01:05.150 --> 01:01:10.150
<v Speaker 1>But what happened is most of the hands </v>
<v Speaker 1>were up at about the time when that </v>

1370
01:01:10.150 --> 01:01:11.810
<v Speaker 1>great or the one that dash line shot up.</v>
<v Speaker 1>Okay.</v>

1371
01:01:12.050 --> 01:01:14.750
<v Speaker 1>That's not human data.</v>
<v Speaker 1>You provided the data.</v>

1372
01:01:14.751 --> 01:01:19.751
<v Speaker 1>This is our model.</v>
<v Speaker 1>So our model is predicting more or less </v>

1373
01:01:19.751 --> 01:01:19.790
<v Speaker 1>when you're able to say what her goal </v>
<v Speaker 1>was.</v>

1374
01:01:19.791 --> 01:01:24.791
<v Speaker 1>Okay.</v>
<v Speaker 1>It's well before she actually touched </v>

1375
01:01:24.791 --> 01:01:24.791
<v Speaker 1>the object.</v>
<v Speaker 1>How does the model work?</v>

1376
01:01:24.791 --> 01:01:24.791
<v Speaker 1>Again,</v>
<v Speaker 1>I'll skip the details,</v>

1377
01:01:24.791 --> 01:01:29.590
<v Speaker 1>but it does the same kind of thing that,</v>
<v Speaker 1>that are models of those infants did </v>

1378
01:01:29.590 --> 01:01:30.230
<v Speaker 1>namely get it.</v>
<v Speaker 1>But in this case,</v>

1379
01:01:30.231 --> 01:01:32.360
<v Speaker 1>it does it with a full body model from </v>
<v Speaker 1>robotics,</v>

1380
01:01:32.361 --> 01:01:34.490
<v Speaker 1>so we use what's called the physics </v>
<v Speaker 1>engine,</v>

1381
01:01:35.060 --> 01:01:37.640
<v Speaker 1>which is a standard tool in robotics for</v>
<v Speaker 1>planning,</v>

1382
01:01:37.641 --> 01:01:40.130
<v Speaker 1>physically efficient reaches of say,</v>
<v Speaker 1>a humanoid robot,</v>

1383
01:01:40.340 --> 01:01:45.260
<v Speaker 1>and we say we can give this planner </v>
<v Speaker 1>program a goal object as input.</v>

1384
01:01:45.260 --> 01:01:47.720
<v Speaker 1>We can give each of the possible goal.</v>
<v Speaker 1>Optics is input and say,</v>

1385
01:01:47.840 --> 01:01:49.760
<v Speaker 1>plan the most physically efficient </v>
<v Speaker 1>action,</v>

1386
01:01:49.761 --> 01:01:52.670
<v Speaker 1>so the one that uses like the least </v>
<v Speaker 1>energy to get to that object,</v>

1387
01:01:52.880 --> 01:01:57.880
<v Speaker 1>and then we can do a Bayesian inference.</v>
<v Speaker 1>This is the probabilistic inference </v>

1388
01:01:57.880 --> 01:01:58.680
<v Speaker 1>part.</v>
<v Speaker 1>The program is the planner.</v>

1389
01:01:58.730 --> 01:02:00.170
<v Speaker 1>Okay,</v>
<v Speaker 1>but then we can say,</v>

1390
01:02:00.860 --> 01:02:04.010
<v Speaker 1>I want to do basie and inference to work</v>
<v Speaker 1>backwards from what I observed,</v>

1391
01:02:04.011 --> 01:02:06.380
<v Speaker 1>which was the action to the input to </v>
<v Speaker 1>that program.</v>

1392
01:02:06.381 --> 01:02:08.780
<v Speaker 1>What goal was provided as input to the </v>
<v Speaker 1>planner,</v>

1393
01:02:08.900 --> 01:02:13.900
<v Speaker 1>and here you can see the full array of </v>
<v Speaker 1>four by four possible inputs and those </v>

1394
01:02:13.900 --> 01:02:18.251
<v Speaker 1>bars that are moving up and down.</v>
<v Speaker 1>That's the basie and posterior </v>

1395
01:02:18.251 --> 01:02:20.741
<v Speaker 1>probability of how likely each of those </v>
<v Speaker 1>was to be the goal and what you can see </v>

1396
01:02:20.741 --> 01:02:22.230
<v Speaker 1>as it converges on the right answer at </v>
<v Speaker 1>least.</v>

1397
01:02:22.260 --> 01:02:27.260
<v Speaker 1>Well,</v>
<v Speaker 1>it turns out to be the ground truth </v>

1398
01:02:27.260 --> 01:02:27.260
<v Speaker 1>right answer,</v>
<v Speaker 1>but it's also the right answer according</v>

1399
01:02:27.260 --> 01:02:28.770
<v Speaker 1>to what people think with about the same</v>
<v Speaker 1>kind of data that people took.</v>

1400
01:02:30.060 --> 01:02:30.960
<v Speaker 1>Now you might say,</v>
<v Speaker 1>well,</v>

1401
01:02:30.961 --> 01:02:35.961
<v Speaker 1>okay,</v>
<v Speaker 1>I'm sure if I just wanted to build a </v>

1402
01:02:35.961 --> 01:02:35.961
<v Speaker 1>system that could detect what somebody </v>
<v Speaker 1>was reaching for,</v>

1403
01:02:35.961 --> 01:02:39.951
<v Speaker 1>I could generate a training data set of </v>
<v Speaker 1>this sort of scene and train something </v>

1404
01:02:39.951 --> 01:02:41.790
<v Speaker 1>up to analyze patterns of motion,</v>
<v Speaker 1>but again,</v>

1405
01:02:41.791 --> 01:02:44.340
<v Speaker 1>because the engine in your head actually</v>
<v Speaker 1>does something,</v>

1406
01:02:44.341 --> 01:02:49.341
<v Speaker 1>we think more like this,</v>
<v Speaker 1>it does what we call inverse planning </v>

1407
01:02:49.341 --> 01:02:52.341
<v Speaker 1>over a physics model.</v>
<v Speaker 1>It can apply to much more interesting </v>

1408
01:02:52.341 --> 01:02:52.440
<v Speaker 1>scenes that you haven't really seen much</v>
<v Speaker 1>of before.</v>

1409
01:02:52.530 --> 01:02:54.780
<v Speaker 1>So take the seat on the left,</v>
<v Speaker 1>right where again,</v>

1410
01:02:54.781 --> 01:02:57.900
<v Speaker 1>you see somebody reaching for one of a </v>
<v Speaker 1>four by four array of objects,</v>

1411
01:02:58.170 --> 01:02:59.910
<v Speaker 1>but what you see as a strange kind of </v>
<v Speaker 1>reach,</v>

1412
01:02:59.911 --> 01:03:03.450
<v Speaker 1>can you see why he's doing this?</v>
<v Speaker 1>Strange reach up there?</v>

1413
01:03:03.451 --> 01:03:05.070
<v Speaker 1>It's a little small,</v>
<v Speaker 1>but what is he?</v>

1414
01:03:05.071 --> 01:03:07.260
<v Speaker 1>You can see that he's reaching over </v>
<v Speaker 1>something,</v>

1415
01:03:07.261 --> 01:03:07.530
<v Speaker 1>right?</v>

1416
01:03:07.530 --> 01:03:09.180
<v Speaker 1>It's actually a pane of glass,</v>
<v Speaker 1>right?</v>

1417
01:03:09.190 --> 01:03:12.570
<v Speaker 1>You see that and then there's this other</v>
<v Speaker 1>guy who's helping him,</v>

1418
01:03:13.320 --> 01:03:15.990
<v Speaker 1>who sees what he wants and hands him the</v>
<v Speaker 1>thing he wants.</v>

1419
01:03:16.230 --> 01:03:21.230
<v Speaker 1>So how does the,</v>
<v Speaker 1>for the guy in the foreground see the </v>

1420
01:03:21.230 --> 01:03:22.500
<v Speaker 1>other guy's goal,</v>
<v Speaker 1>how does he in for his goal and know how</v>

1421
01:03:22.501 --> 01:03:27.501
<v Speaker 1>to help him and then how do we look at </v>
<v Speaker 1>the two of them and figure out who's </v>

1422
01:03:27.501 --> 01:03:30.471
<v Speaker 1>trying to help who or that in a scene </v>
<v Speaker 1>like this one here that it's not </v>

1423
01:03:30.471 --> 01:03:31.620
<v Speaker 1>somebody trying to help somebody but </v>
<v Speaker 1>rather the opposite.</v>

1424
01:03:31.860 --> 01:03:36.860
<v Speaker 1>Okay,</v>
<v Speaker 1>so here's a model on the left of how </v>

1425
01:03:36.860 --> 01:03:36.860
<v Speaker 1>that might work.</v>
<v Speaker 1>Right?</v>

1426
01:03:36.860 --> 01:03:40.251
<v Speaker 1>And we think this is the kind of model </v>
<v Speaker 1>needed to tackle this sort of challenge </v>

1427
01:03:40.251 --> 01:03:40.251
<v Speaker 1>here,</v>
<v Speaker 1>right?</v>

1428
01:03:40.251 --> 01:03:41.940
<v Speaker 1>Basically it's a model.</v>
<v Speaker 1>We take this model of,</v>

1429
01:03:42.000 --> 01:03:47.000
<v Speaker 1>of planning,</v>
<v Speaker 1>sort of maximal expected utility </v>

1430
01:03:47.000 --> 01:03:47.000
<v Speaker 1>planning,</v>
<v Speaker 1>which you can run backwards,</v>

1431
01:03:47.000 --> 01:03:48.960
<v Speaker 1>but then we recursively nest these </v>
<v Speaker 1>models inside each other.</v>

1432
01:03:48.960 --> 01:03:53.520
<v Speaker 1>So we say an agent is helping another </v>
<v Speaker 1>agent if this agent is acting apparently</v>

1433
01:03:53.521 --> 01:03:58.521
<v Speaker 1>to us,</v>
<v Speaker 1>seems to be maximizing unexpected </v>

1434
01:03:58.521 --> 01:04:00.710
<v Speaker 1>utility.</v>
<v Speaker 1>That's a positive function of that </v>

1435
01:04:00.710 --> 01:04:03.981
<v Speaker 1>agent's expectation about another </v>
<v Speaker 1>agent's expecting to tilly and that's </v>

1436
01:04:03.981 --> 01:04:05.550
<v Speaker 1>what it means to be a helper.</v>
<v Speaker 1>Hindering is sort of the opposite if one</v>

1437
01:04:05.551 --> 01:04:08.130
<v Speaker 1>seems to be trying to lower somebody's </v>
<v Speaker 1>else's utility.</v>

1438
01:04:08.270 --> 01:04:10.980
<v Speaker 1>Okay,</v>
<v Speaker 1>and we've used these same kind of models</v>

1439
01:04:11.160 --> 01:04:16.160
<v Speaker 1>to also describe infants understanding </v>
<v Speaker 1>of helping and hindering and a range of </v>

1440
01:04:16.160 --> 01:04:19.551
<v Speaker 1>scenes.</v>
<v Speaker 1>I'll just say one last word about </v>

1441
01:04:19.551 --> 01:04:21.330
<v Speaker 1>learning because everybody wants to know</v>
<v Speaker 1>about learning and and the the key thing</v>

1442
01:04:21.331 --> 01:04:21.950
<v Speaker 1>here,</v>
<v Speaker 1>and it's.</v>

1443
01:04:21.980 --> 01:04:24.480
<v Speaker 1>It's definitely part of any picture of </v>
<v Speaker 1>Agi,</v>

1444
01:04:24.840 --> 01:04:28.020
<v Speaker 1>but the thought I want to leave you on </v>
<v Speaker 1>is really about what learning is about.</v>

1445
01:04:28.021 --> 01:04:33.021
<v Speaker 1>Okay.</v>
<v Speaker 1>It will be just a few more slides and </v>

1446
01:04:33.021 --> 01:04:34.311
<v Speaker 1>then I'll stop.</v>
<v Speaker 1>I promise none of the models I showed </v>

1447
01:04:34.311 --> 01:04:34.311
<v Speaker 1>you so far really did any learning.</v>

1448
01:04:34.311 --> 01:04:36.360
<v Speaker 1>They certainly didn't do any task </v>
<v Speaker 1>specific learning.</v>

1449
01:04:36.420 --> 01:04:41.420
<v Speaker 1>Okay.</v>
<v Speaker 1>We set up a provost at program and then </v>

1450
01:04:41.420 --> 01:04:43.551
<v Speaker 1>we let it do inference.</v>
<v Speaker 1>Now that's not to say that we don't </v>

1451
01:04:43.551 --> 01:04:43.551
<v Speaker 1>think people learn to do these things.</v>
<v Speaker 1>We do,</v>

1452
01:04:43.551 --> 01:04:45.810
<v Speaker 1>but the real learning goes on when </v>
<v Speaker 1>you're much younger,</v>

1453
01:04:45.960 --> 01:04:48.150
<v Speaker 1>right?</v>
<v Speaker 1>Everything I showed you in basic form,</v>

1454
01:04:48.151 --> 01:04:50.400
<v Speaker 1>even a one year old baby can do.</v>
<v Speaker 1>Okay.</v>

1455
01:04:50.580 --> 01:04:54.000
<v Speaker 1>The basic learning goes on to support </v>
<v Speaker 1>these kinds of abilities.</v>

1456
01:04:54.001 --> 01:04:55.650
<v Speaker 1>Not that there isn't learning beyond one</v>
<v Speaker 1>year,</v>

1457
01:04:55.860 --> 01:05:00.860
<v Speaker 1>but the basic way you learn to say solve</v>
<v Speaker 1>these physics problems is what goes on </v>

1458
01:05:00.860 --> 01:05:02.940
<v Speaker 1>in your bay,</v>
<v Speaker 1>in the brain of a child between zero and</v>

1459
01:05:02.941 --> 01:05:07.941
<v Speaker 1>12 months.</v>
<v Speaker 1>So this is just an example of some </v>

1460
01:05:07.941 --> 01:05:08.610
<v Speaker 1>phenomena that come from the literature </v>
<v Speaker 1>on infant cognitive development.</v>

1461
01:05:08.880 --> 01:05:13.880
<v Speaker 1>These are very rough timelines.</v>
<v Speaker 1>You can take pictures of this if you </v>

1462
01:05:13.880 --> 01:05:16.671
<v Speaker 1>like.</v>
<v Speaker 1>This is always a popular slide because </v>

1463
01:05:16.671 --> 01:05:16.671
<v Speaker 1>it's.</v>

1464
01:05:16.671 --> 01:05:16.671
<v Speaker 1>It's.</v>
<v Speaker 1>It really is quite inspiring I think,</v>

1465
01:05:16.671 --> 01:05:20.421
<v Speaker 1>and I can give you lots of literature,</v>
<v Speaker 1>but I'm summarizing in very broad </v>

1466
01:05:20.421 --> 01:05:24.241
<v Speaker 1>strokes with big error bars,</v>
<v Speaker 1>what we've learned in the field of </v>

1467
01:05:24.241 --> 01:05:27.931
<v Speaker 1>infant cognitive development about when </v>
<v Speaker 1>and how kids seemed to at least come to </v>

1468
01:05:27.941 --> 01:05:30.280
<v Speaker 1>a certain understanding of basic aspects</v>
<v Speaker 1>of physics.</v>

1469
01:05:30.850 --> 01:05:34.150
<v Speaker 1>So if you really want to study how </v>
<v Speaker 1>people learn to be intelligent,</v>

1470
01:05:34.480 --> 01:05:36.700
<v Speaker 1>a lot of what you have to study our kids</v>
<v Speaker 1>at this age,</v>

1471
01:05:36.701 --> 01:05:40.330
<v Speaker 1>you have to study what's already in </v>
<v Speaker 1>their brain at zero months and what they</v>

1472
01:05:40.331 --> 01:05:42.460
<v Speaker 1>learn and how they learn between four,</v>
<v Speaker 1>six,</v>

1473
01:05:42.461 --> 01:05:43.000
<v Speaker 1>eight,</v>
<v Speaker 1>10,</v>

1474
01:05:43.001 --> 01:05:45.070
<v Speaker 1>12,</v>
<v Speaker 1>and so on and on and on up beyond that.</v>

1475
01:05:45.071 --> 01:05:47.060
<v Speaker 1>Okay.</v>
<v Speaker 1>Now,</v>

1476
01:05:47.380 --> 01:05:52.380
<v Speaker 1>well,</v>
<v Speaker 1>effectively what that amounts to we </v>

1477
01:05:52.380 --> 01:05:52.380
<v Speaker 1>think is if what you're learning is </v>
<v Speaker 1>something like,</v>

1478
01:05:52.380 --> 01:05:57.270
<v Speaker 1>let's say an intuitive game,</v>
<v Speaker 1>physics engine to capture these basic </v>

1479
01:05:57.270 --> 01:05:57.490
<v Speaker 1>abilities than what we need.</v>

1480
01:05:57.490 --> 01:05:58.990
<v Speaker 1>If we're going to try to reverse </v>
<v Speaker 1>engineer,</v>

1481
01:05:58.991 --> 01:06:01.870
<v Speaker 1>that is what we might think of as a </v>
<v Speaker 1>program learning program.</v>

1482
01:06:01.871 --> 01:06:03.730
<v Speaker 1>If your knowledge is in the form of a </v>
<v Speaker 1>program,</v>

1483
01:06:04.030 --> 01:06:06.370
<v Speaker 1>then you have to have programs that </v>
<v Speaker 1>build other programs.</v>

1484
01:06:06.371 --> 01:06:11.371
<v Speaker 1>Right?</v>
<v Speaker 1>This is what I was talking about the </v>

1485
01:06:11.371 --> 01:06:11.470
<v Speaker 1>beginning about learning as building </v>
<v Speaker 1>models of the world are ultimately.</v>

1486
01:06:11.590 --> 01:06:16.590
<v Speaker 1>If you think what we start off with is </v>
<v Speaker 1>something like a game engine that can </v>

1487
01:06:16.590 --> 01:06:20.131
<v Speaker 1>play any game than what you have to </v>
<v Speaker 1>learn is the program of the game that </v>

1488
01:06:20.131 --> 01:06:23.041
<v Speaker 1>you're actually playing or the many </v>
<v Speaker 1>different games that you might be </v>

1489
01:06:23.041 --> 01:06:23.800
<v Speaker 1>playing over your life.</v>
<v Speaker 1>So think of learning as like programming</v>

1490
01:06:23.801 --> 01:06:28.801
<v Speaker 1>the game engine in your head to fit with</v>
<v Speaker 1>your experience and to fit with the </v>

1491
01:06:28.801 --> 01:06:29.710
<v Speaker 1>possible actions that you seem like you </v>
<v Speaker 1>can take.</v>

1492
01:06:30.190 --> 01:06:35.190
<v Speaker 1>Now,</v>
<v Speaker 1>this is what you could call the hard </v>

1493
01:06:35.190 --> 01:06:35.190
<v Speaker 1>problem of learning if you come to </v>
<v Speaker 1>learning from,</v>

1494
01:06:35.190 --> 01:06:38.581
<v Speaker 1>say,</v>
<v Speaker 1>neural networks or other tools in </v>

1495
01:06:38.581 --> 01:06:38.581
<v Speaker 1>machine learning.</v>

1496
01:06:38.581 --> 01:06:41.160
<v Speaker 1>Right?</v>
<v Speaker 1>So what makes machine makes most of </v>

1497
01:06:41.160 --> 01:06:43.201
<v Speaker 1>machine learning go right now and </v>
<v Speaker 1>certainly what makes neural networks so </v>

1498
01:06:43.201 --> 01:06:45.961
<v Speaker 1>appealing is that you can set up a </v>
<v Speaker 1>basically a big function approximator </v>

1499
01:06:45.961 --> 01:06:50.101
<v Speaker 1>that can approximate many of the </v>
<v Speaker 1>functions you might want to do in a </v>

1500
01:06:50.101 --> 01:06:53.071
<v Speaker 1>certain application or task,</v>
<v Speaker 1>but in a way that's end to end </v>

1501
01:06:53.071 --> 01:06:53.950
<v Speaker 1>differentiable and with a meaningful </v>
<v Speaker 1>cost function.</v>

1502
01:06:53.951 --> 01:06:56.350
<v Speaker 1>So you can have one of these nice </v>
<v Speaker 1>optimization landscapes.</v>

1503
01:06:56.351 --> 01:07:01.351
<v Speaker 1>You can compute the gradients on </v>
<v Speaker 1>basically just rolled down hill until </v>

1504
01:07:01.351 --> 01:07:04.081
<v Speaker 1>you get to an optimal solution,</v>
<v Speaker 1>but if you're talking about learning as </v>

1505
01:07:04.081 --> 01:07:05.290
<v Speaker 1>something like search in the space of </v>
<v Speaker 1>programs,</v>

1506
01:07:05.680 --> 01:07:07.480
<v Speaker 1>we don't know how to do anything like </v>
<v Speaker 1>that yet.</v>

1507
01:07:07.481 --> 01:07:11.170
<v Speaker 1>We don't know how to set this up as any </v>
<v Speaker 1>kind of a nice optimization problem with</v>

1508
01:07:11.171 --> 01:07:13.350
<v Speaker 1>any notion of smoothness or gradients.</v>
<v Speaker 1>Okay.</v>

1509
01:07:13.660 --> 01:07:15.220
<v Speaker 1>Rather,</v>
<v Speaker 1>what we need is a,</v>

1510
01:07:15.550 --> 01:07:17.530
<v Speaker 1>instead of learning as like rolling down</v>
<v Speaker 1>hill,</v>

1511
01:07:17.531 --> 01:07:21.100
<v Speaker 1>effectively write a process which just,</v>
<v Speaker 1>if you're willing to wait long enough,</v>

1512
01:07:21.220 --> 01:07:21.940
<v Speaker 1>you know,</v>
<v Speaker 1>some,</v>

1513
01:07:22.240 --> 01:07:23.120
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

1514
01:07:23.350 --> 01:07:28.350
<v Speaker 1>simple algorithm will take care of,</v>
<v Speaker 1>think of what we call the idea of </v>

1515
01:07:28.350 --> 01:07:28.350
<v Speaker 1>learning as programming.</v>

1516
01:07:28.450 --> 01:07:33.450
<v Speaker 1>There's a popular metaphor in cognitive </v>
<v Speaker 1>development called the child as </v>

1517
01:07:33.450 --> 01:07:36.871
<v Speaker 1>scientists,</v>
<v Speaker 1>which emphasizes children as active </v>

1518
01:07:36.871 --> 01:07:39.100
<v Speaker 1>theory builders and children's play as a</v>
<v Speaker 1>kind of casual experimentation.</v>

1519
01:07:39.520 --> 01:07:41.470
<v Speaker 1>But this is the algorithmic compliment </v>
<v Speaker 1>to that.</v>

1520
01:07:41.471 --> 01:07:44.980
<v Speaker 1>What we could call the child is coder or</v>
<v Speaker 1>around Mit will say the child is hacker,</v>

1521
01:07:44.981 --> 01:07:47.560
<v Speaker 1>but the rest of the world,</v>
<v Speaker 1>if you say child is hacker,</v>

1522
01:07:47.561 --> 01:07:52.561
<v Speaker 1>they think of something that someone who</v>
<v Speaker 1>breaks into your email and steals your </v>

1523
01:07:52.561 --> 01:07:52.561
<v Speaker 1>credit card numbers.</v>
<v Speaker 1>We all know that hacking is,</v>

1524
01:07:52.561 --> 01:07:54.040
<v Speaker 1>you know,</v>
<v Speaker 1>making your code more awesome,</v>

1525
01:07:54.730 --> 01:07:55.540
<v Speaker 1>right?</v>
<v Speaker 1>If,</v>

1526
01:07:55.600 --> 01:08:00.600
<v Speaker 1>if,</v>
<v Speaker 1>if your knowledge is some kind of code </v>

1527
01:08:00.600 --> 01:08:02.730
<v Speaker 1>or Lena Library of programs,</v>
<v Speaker 1>then learning is all the ways that a </v>

1528
01:08:02.730 --> 01:08:03.490
<v Speaker 1>child acts on their code to make it more</v>
<v Speaker 1>awesome,</v>

1529
01:08:03.990 --> 01:08:07.240
<v Speaker 1>more awesome can mean more accurate,</v>
<v Speaker 1>but it can also mean faster,</v>

1530
01:08:07.420 --> 01:08:10.900
<v Speaker 1>more elegant,</v>
<v Speaker 1>more transportable to other applications</v>

1531
01:08:10.901 --> 01:08:12.910
<v Speaker 1>or their tasks more explainable to </v>
<v Speaker 1>others.</v>

1532
01:08:13.000 --> 01:08:14.880
<v Speaker 1>Maybe just more entertaining.</v>
<v Speaker 1>Okay.</v>

1533
01:08:14.930 --> 01:08:19.930
<v Speaker 1>Children do.</v>
<v Speaker 1>All of them have all of those goals and </v>

1534
01:08:19.930 --> 01:08:20.330
<v Speaker 1>learning and the activities by which </v>
<v Speaker 1>they make their code more awesome.</v>

1535
01:08:20.570 --> 01:08:23.870
<v Speaker 1>Also correspond to many of the </v>
<v Speaker 1>activities of coding,</v>

1536
01:08:24.540 --> 01:08:29.540
<v Speaker 1>right?</v>
<v Speaker 1>So think about all the ways on a day to </v>

1537
01:08:29.540 --> 01:08:29.540
<v Speaker 1>day basis.</v>
<v Speaker 1>You might make your code more awesome.</v>

1538
01:08:29.540 --> 01:08:29.620
<v Speaker 1>Alright?</v>
<v Speaker 1>Um,</v>

1539
01:08:30.020 --> 01:08:32.720
<v Speaker 1>you might tune,</v>
<v Speaker 1>you might have a big library of existing</v>

1540
01:08:32.721 --> 01:08:37.721
<v Speaker 1>functions with some parameters that you </v>
<v Speaker 1>can tune on a data set that's basically </v>

1541
01:08:37.721 --> 01:08:41.171
<v Speaker 1>what you do with backdrop or stochastic </v>
<v Speaker 1>gradient descent and training a deep </v>

1542
01:08:41.171 --> 01:08:44.531
<v Speaker 1>learning system,</v>
<v Speaker 1>but think about all the ways in which </v>

1543
01:08:44.531 --> 01:08:44.531
<v Speaker 1>you might actually modify the underlying</v>
<v Speaker 1>function.</v>

1544
01:08:44.531 --> 01:08:46.740
<v Speaker 1>So write new code or take old code from </v>
<v Speaker 1>some other thing.</v>

1545
01:08:46.741 --> 01:08:50.690
<v Speaker 1>And Map it over here or make a whole new</v>
<v Speaker 1>library of code or refactor your code to</v>

1546
01:08:50.691 --> 01:08:54.260
<v Speaker 1>some other,</v>
<v Speaker 1>some other basis for that that will work</v>

1547
01:08:54.261 --> 01:08:58.340
<v Speaker 1>more robustly and be more extensible or </v>
<v Speaker 1>transpiling or compiling.</v>

1548
01:08:58.610 --> 01:09:03.610
<v Speaker 1>Right.</v>
<v Speaker 1>Or even just commenting your code or </v>

1549
01:09:03.610 --> 01:09:03.610
<v Speaker 1>asking someone else for their code.</v>
<v Speaker 1>Okay.</v>

1550
01:09:03.610 --> 01:09:05.180
<v Speaker 1>Again,</v>
<v Speaker 1>these are all ways that we make our code</v>

1551
01:09:05.181 --> 01:09:10.181
<v Speaker 1>more awesome and children's learning has</v>
<v Speaker 1>analogs to all of these that we would </v>

1552
01:09:10.181 --> 01:09:12.140
<v Speaker 1>want to understand as an engineer from </v>
<v Speaker 1>an algorithmic point of view.</v>

1553
01:09:12.650 --> 01:09:16.220
<v Speaker 1>So in our group we've been working on on</v>
<v Speaker 1>various early steps towards this.</v>

1554
01:09:16.221 --> 01:09:17.900
<v Speaker 1>And again,</v>
<v Speaker 1>we don't have anything like,</v>

1555
01:09:18.210 --> 01:09:20.570
<v Speaker 1>um,</v>
<v Speaker 1>program writing programs at the level of</v>

1556
01:09:20.571 --> 01:09:23.930
<v Speaker 1>children's learning algorithms.</v>
<v Speaker 1>But one example of something that we did</v>

1557
01:09:23.931 --> 01:09:28.931
<v Speaker 1>in our group,</v>
<v Speaker 1>which you might not have thought of </v>

1558
01:09:28.931 --> 01:09:30.311
<v Speaker 1>being about this,</v>
<v Speaker 1>but it's definitely the ai work we did </v>

1559
01:09:30.311 --> 01:09:33.130
<v Speaker 1>that got the most attention.</v>
<v Speaker 1>And the last couple of years from our </v>

1560
01:09:33.130 --> 01:09:33.560
<v Speaker 1>group,</v>
<v Speaker 1>we had this paper that was in science.</v>

1561
01:09:33.561 --> 01:09:37.850
<v Speaker 1>It was actually on the cover of science,</v>
<v Speaker 1>sort of just hit the market at the right</v>

1562
01:09:37.851 --> 01:09:38.540
<v Speaker 1>time if you like.</v>

1563
01:09:38.540 --> 01:09:43.540
<v Speaker 1>And it got about 100 times more </v>
<v Speaker 1>publicity than anything else I've ever </v>

1564
01:09:43.540 --> 01:09:46.421
<v Speaker 1>done,</v>
<v Speaker 1>which is partly a testament to the </v>

1565
01:09:46.421 --> 01:09:46.820
<v Speaker 1>really great work that Brendan Lake,</v>
<v Speaker 1>who was the first author did for his phd</v>

1566
01:09:46.821 --> 01:09:51.821
<v Speaker 1>here,</v>
<v Speaker 1>but much more so it just about the </v>

1567
01:09:51.821 --> 01:09:53.420
<v Speaker 1>hunger for ai systems at the time when </v>
<v Speaker 1>we published this in 2015 and we built a</v>

1568
01:09:53.421 --> 01:09:58.421
<v Speaker 1>machine system that the way we described</v>
<v Speaker 1>it was doing human level concept </v>

1569
01:09:58.421 --> 01:10:00.500
<v Speaker 1>learning for simple concept,</v>
<v Speaker 1>very simple visual concepts.</v>

1570
01:10:00.501 --> 01:10:03.080
<v Speaker 1>These handwritten characters in many of </v>
<v Speaker 1>the world's alphabets.</v>

1571
01:10:03.290 --> 01:10:05.630
<v Speaker 1>For those of you who know the famous m,</v>
<v Speaker 1>this Dataset,</v>

1572
01:10:05.660 --> 01:10:08.690
<v Speaker 1>the Dataset of handwritten digits zero </v>
<v Speaker 1>through 10 or 33 nine,</v>

1573
01:10:08.691 --> 01:10:09.460
<v Speaker 1>sorry.</v>
<v Speaker 1>Uh,</v>

1574
01:10:09.620 --> 01:10:13.100
<v Speaker 1>that drove so much good research in deep</v>
<v Speaker 1>learning and pattern recognition.</v>

1575
01:10:13.430 --> 01:10:16.850
<v Speaker 1>It did that not because Yann Macun who </v>
<v Speaker 1>put that together or Jeff Hinton,</v>

1576
01:10:16.851 --> 01:10:18.830
<v Speaker 1>who did a lot of work on deep learning </v>
<v Speaker 1>with Ms.</v>

1577
01:10:19.190 --> 01:10:22.910
<v Speaker 1>They weren't interested fundamentally in</v>
<v Speaker 1>character recognition that they saw that</v>

1578
01:10:22.911 --> 01:10:25.730
<v Speaker 1>as a very simple test bed for developing</v>
<v Speaker 1>more general ideas.</v>

1579
01:10:26.060 --> 01:10:31.060
<v Speaker 1>And similarly,</v>
<v Speaker 1>we did this work on getting machines to </v>

1580
01:10:31.060 --> 01:10:33.851
<v Speaker 1>do what we are kind of one shot learning</v>
<v Speaker 1>of generative models also to to develop </v>

1581
01:10:34.011 --> 01:10:39.011
<v Speaker 1>more general ideas.</v>
<v Speaker 1>We saw this as learning very simple </v>

1582
01:10:39.011 --> 01:10:39.410
<v Speaker 1>little mini probabilistic programs in </v>
<v Speaker 1>this case.</v>

1583
01:10:39.411 --> 01:10:42.110
<v Speaker 1>What are those programs that the </v>
<v Speaker 1>programs you used to draw a character.</v>

1584
01:10:42.290 --> 01:10:47.290
<v Speaker 1>So ask yourself how can you look at any </v>
<v Speaker 1>one of these characters and see in a </v>

1585
01:10:47.290 --> 01:10:49.820
<v Speaker 1>sense how somebody might draw it.</v>
<v Speaker 1>The way we tested this in our system was</v>

1586
01:10:49.821 --> 01:10:54.821
<v Speaker 1>this little visual turing test where we </v>
<v Speaker 1>showed people one character in a novel </v>

1587
01:10:54.821 --> 01:10:58.811
<v Speaker 1>alphabet and we said draw another one </v>
<v Speaker 1>and then we compared nine people like </v>

1588
01:10:58.811 --> 01:11:01.460
<v Speaker 1>say on the left and nine samples from </v>
<v Speaker 1>our machine say on the right.</v>

1589
01:11:01.640 --> 01:11:03.020
<v Speaker 1>And we said,</v>
<v Speaker 1>we asked other people,</v>

1590
01:11:03.021 --> 01:11:08.021
<v Speaker 1>could you tell which was the human </v>
<v Speaker 1>drawing another example or imagining </v>

1591
01:11:08.021 --> 01:11:11.351
<v Speaker 1>another example in which was the machine</v>
<v Speaker 1>and people couldn't tell when I said </v>

1592
01:11:11.351 --> 01:11:11.351
<v Speaker 1>ones on the left,</v>
<v Speaker 1>ones on the right.</v>

1593
01:11:11.351 --> 01:11:15.730
<v Speaker 1>I don't actually remember.</v>
<v Speaker 1>And and different ones you could see if </v>

1594
01:11:15.730 --> 01:11:15.730
<v Speaker 1>you can tell.</v>
<v Speaker 1>It's very hard to tell.</v>

1595
01:11:15.730 --> 01:11:17.100
<v Speaker 1>Can you tell which is for each one of </v>
<v Speaker 1>these characters,</v>

1596
01:11:17.310 --> 01:11:20.400
<v Speaker 1>which new set of examples were drawn by </v>
<v Speaker 1>a human versus the machine?</v>

1597
01:11:21.360 --> 01:11:23.880
<v Speaker 1>Here's the right answer and probably you</v>
<v Speaker 1>couldn't tell.</v>

1598
01:11:24.240 --> 01:11:28.080
<v Speaker 1>The way we did this was by assembling a </v>
<v Speaker 1>simple kind of program learning program,</v>

1599
01:11:28.160 --> 01:11:33.160
<v Speaker 1>right?</v>
<v Speaker 1>So we basically said when you draw a </v>

1600
01:11:33.160 --> 01:11:35.301
<v Speaker 1>character,</v>
<v Speaker 1>you're assembling strokes and sub </v>

1601
01:11:35.301 --> 01:11:35.670
<v Speaker 1>strokes with goals and sub goals that </v>
<v Speaker 1>produce ink on the page,</v>

1602
01:11:35.820 --> 01:11:40.820
<v Speaker 1>and when you see a character,</v>
<v Speaker 1>you're working backwards to figure out </v>

1603
01:11:40.820 --> 01:11:43.791
<v Speaker 1>what was the program,</v>
<v Speaker 1>the most efficient program that did </v>

1604
01:11:43.791 --> 01:11:46.161
<v Speaker 1>that.</v>
<v Speaker 1>So you're basically inverting a </v>

1605
01:11:46.161 --> 01:11:46.161
<v Speaker 1>probabilistic program,</v>
<v Speaker 1>doing basie and inference to the program</v>

1606
01:11:46.161 --> 01:11:47.850
<v Speaker 1>most likely to have generated what you </v>
<v Speaker 1>saw.</v>

1607
01:11:48.240 --> 01:11:53.240
<v Speaker 1>This is one small step we think towards </v>
<v Speaker 1>being able to learn programs to being </v>

1608
01:11:53.240 --> 01:11:55.530
<v Speaker 1>able to learn something ultimately like </v>
<v Speaker 1>a whole game engine program.</v>

1609
01:11:56.220 --> 01:12:01.220
<v Speaker 1>The last thing I'll leave you with is </v>
<v Speaker 1>just a pointer to sort of work in </v>

1610
01:12:01.220 --> 01:12:01.220
<v Speaker 1>action,</v>
<v Speaker 1>right?</v>

1611
01:12:01.220 --> 01:12:04.761
<v Speaker 1>So this is some work being done by a </v>
<v Speaker 1>current phd student who works partly </v>

1612
01:12:04.761 --> 01:12:04.990
<v Speaker 1>with me,</v>
<v Speaker 1>but also with Armando solar,</v>

1613
01:12:04.991 --> 01:12:09.991
<v Speaker 1>Lezama and Cecil sale.</v>
<v Speaker 1>This is Kevin Ellis is an example of </v>

1614
01:12:09.991 --> 01:12:09.991
<v Speaker 1>what's now.</v>
<v Speaker 1>I think again,</v>

1615
01:12:09.991 --> 01:12:14.310
<v Speaker 1>an emerging exciting area in Ai,</v>
<v Speaker 1>well beyond anything that we're doing is</v>

1616
01:12:14.610 --> 01:12:17.190
<v Speaker 1>combining techniques from where Amando </v>
<v Speaker 1>comes from,</v>

1617
01:12:17.191 --> 01:12:18.870
<v Speaker 1>which is the world of programming </v>
<v Speaker 1>languages,</v>

1618
01:12:18.871 --> 01:12:23.871
<v Speaker 1>not machine learning or ai,</v>
<v Speaker 1>but tools from programming languages </v>

1619
01:12:23.871 --> 01:12:24.900
<v Speaker 1>which can be used to automatically </v>
<v Speaker 1>synthesize code.</v>

1620
01:12:25.090 --> 01:12:27.180
<v Speaker 1>Okay.</v>
<v Speaker 1>With the machine learning tool kit,</v>

1621
01:12:27.181 --> 01:12:32.181
<v Speaker 1>in this case,</v>
<v Speaker 1>a kind of basie and minimum minimum </v>

1622
01:12:32.181 --> 01:12:32.310
<v Speaker 1>description link idea to be able to make</v>
<v Speaker 1>again,</v>

1623
01:12:32.340 --> 01:12:37.340
<v Speaker 1>what is really one small step towards </v>
<v Speaker 1>machines that can learn programs by </v>

1624
01:12:37.340 --> 01:12:38.730
<v Speaker 1>basically trying to efficiently find the</v>
<v Speaker 1>shortest,</v>

1625
01:12:38.731 --> 01:12:41.730
<v Speaker 1>simplest program which can capture some </v>
<v Speaker 1>data set.</v>

1626
01:12:42.000 --> 01:12:44.220
<v Speaker 1>So we think by combining these kinds of </v>
<v Speaker 1>tools,</v>

1627
01:12:44.280 --> 01:12:49.280
<v Speaker 1>in this case,</v>
<v Speaker 1>let's say from basie and infants over </v>

1628
01:12:49.280 --> 01:12:51.381
<v Speaker 1>programs with a number of tools that </v>
<v Speaker 1>have been developed in other areas of </v>

1629
01:12:51.381 --> 01:12:55.161
<v Speaker 1>computer science that don't look </v>
<v Speaker 1>anything or haven't been considered to </v>

1630
01:12:55.161 --> 01:12:55.680
<v Speaker 1>be machine learning or ai like </v>
<v Speaker 1>programming languages.</v>

1631
01:12:56.070 --> 01:13:01.070
<v Speaker 1>It's one of the many ways that going </v>
<v Speaker 1>forward we're going to be able to build </v>

1632
01:13:01.070 --> 01:13:01.070
<v Speaker 1>smarter,</v>
<v Speaker 1>more human like machines.</v>

1633
01:13:01.650 --> 01:13:06.650
<v Speaker 1>So just to end then,</v>
<v Speaker 1>what I've tried to tell you here is </v>

1634
01:13:06.650 --> 01:13:10.130
<v Speaker 1>taught first of all,</v>
<v Speaker 1>identify the ways in which human </v>

1635
01:13:10.130 --> 01:13:12.651
<v Speaker 1>intelligence goes beyond pattern </v>
<v Speaker 1>recognition to really all these </v>

1636
01:13:12.651 --> 01:13:12.900
<v Speaker 1>activities of modeling the world.</v>
<v Speaker 1>Okay.</v>

1637
01:13:13.320 --> 01:13:18.320
<v Speaker 1>To give you a sense of some of the </v>
<v Speaker 1>domains where you can start to study </v>

1638
01:13:18.320 --> 01:13:18.420
<v Speaker 1>this in common sense,</v>
<v Speaker 1>seen understanding for example,</v>

1639
01:13:18.640 --> 01:13:19.670
<v Speaker 1>um,</v>
<v Speaker 1>or you know,</v>

1640
01:13:19.680 --> 01:13:23.310
<v Speaker 1>something like a one shot learning for </v>
<v Speaker 1>example,</v>

1641
01:13:23.311 --> 01:13:24.090
<v Speaker 1>like what we were just doing.</v>

1642
01:13:24.090 --> 01:13:26.430
<v Speaker 1>Their learning is programming the engine</v>
<v Speaker 1>in your head.</v>

1643
01:13:27.140 --> 01:13:32.140
<v Speaker 1>Okay.</v>
<v Speaker 1>And to give you a sense of some of the </v>

1644
01:13:32.140 --> 01:13:32.140
<v Speaker 1>technical tools,</v>
<v Speaker 1>probabilistic programs,</v>

1645
01:13:32.140 --> 01:13:34.680
<v Speaker 1>program synthesis,</v>
<v Speaker 1>game engines for example,</v>

1646
01:13:34.681 --> 01:13:37.770
<v Speaker 1>as well as a little bit of deep learning</v>
<v Speaker 1>that bringing together,</v>

1647
01:13:37.800 --> 01:13:40.020
<v Speaker 1>we're starting to be able to make these </v>
<v Speaker 1>things real.</v>

1648
01:13:40.110 --> 01:13:45.110
<v Speaker 1>Okay.</v>
<v Speaker 1>Now that's the science agenda and the </v>

1649
01:13:45.110 --> 01:13:45.450
<v Speaker 1>reverse engineering agenda.</v>
<v Speaker 1>But think about for those of you who are</v>

1650
01:13:45.451 --> 01:13:50.451
<v Speaker 1>interested in technology,</v>
<v Speaker 1>what are the many big ai frontiers that </v>

1651
01:13:50.451 --> 01:13:53.811
<v Speaker 1>this opens up?</v>
<v Speaker 1>So the one I'm most excited about is </v>

1652
01:13:53.811 --> 01:13:57.621
<v Speaker 1>this idea which is,</v>
<v Speaker 1>which I've highlighted here in our big </v>

1653
01:13:57.621 --> 01:13:59.990
<v Speaker 1>research agenda.</v>
<v Speaker 1>This is the one I'm most excited about </v>

1654
01:13:59.990 --> 01:13:59.990
<v Speaker 1>to work on for the,</v>
<v Speaker 1>you know,</v>

1655
01:13:59.990 --> 01:14:00.090
<v Speaker 1>it could be the rest of my career </v>
<v Speaker 1>honestly,</v>

1656
01:14:00.330 --> 01:14:05.330
<v Speaker 1>but it's really what is,</v>
<v Speaker 1>what is the oldest and maybe the best </v>

1657
01:14:05.330 --> 01:14:08.070
<v Speaker 1>dream of AI researchers of how to build </v>
<v Speaker 1>a human like intelligence system,</v>

1658
01:14:08.071 --> 01:14:09.570
<v Speaker 1>a real agi system.</v>

1659
01:14:10.110 --> 01:14:15.110
<v Speaker 1>It's the idea that terrain proposed when</v>
<v Speaker 1>he proposed the turing test or Marvin </v>

1660
01:14:15.110 --> 01:14:16.360
<v Speaker 1>Minsky proposed this at different times </v>
<v Speaker 1>in his life or many people have proposed</v>

1661
01:14:16.361 --> 01:14:16.930
<v Speaker 1>this,</v>
<v Speaker 1>right?</v>

1662
01:14:17.230 --> 01:14:22.230
<v Speaker 1>Which is to build a system that grows </v>
<v Speaker 1>into intelligence the way a human does </v>

1663
01:14:22.230 --> 01:14:22.660
<v Speaker 1>that starts like a baby and learns like </v>
<v Speaker 1>a child,</v>

1664
01:14:22.960 --> 01:14:27.960
<v Speaker 1>and I've tried to show you how we're </v>
<v Speaker 1>starting to be able to understand those </v>

1665
01:14:27.960 --> 01:14:31.171
<v Speaker 1>things.</v>
<v Speaker 1>What a baby's mind starts with how </v>

1666
01:14:31.171 --> 01:14:31.390
<v Speaker 1>children actually learn and looking </v>
<v Speaker 1>forward,</v>

1667
01:14:31.391 --> 01:14:36.391
<v Speaker 1>we might.</v>
<v Speaker 1>We might imagine that someday we'll be </v>

1668
01:14:36.391 --> 01:14:36.391
<v Speaker 1>able to build machines that can do this.</v>
<v Speaker 1>I think we can actually start working on</v>

1669
01:14:36.391 --> 01:14:39.520
<v Speaker 1>this right now and we're.</v>
<v Speaker 1>And that's something that we're doing in</v>

1670
01:14:39.521 --> 01:14:41.980
<v Speaker 1>our group.</v>
<v Speaker 1>So if that kind of thing excites you,</v>

1671
01:14:41.981 --> 01:14:46.981
<v Speaker 1>then I encourage you to work on it and </v>
<v Speaker 1>maybe even with us or if any one of </v>

1672
01:14:46.981 --> 01:14:47.770
<v Speaker 1>these other activities of human </v>
<v Speaker 1>intelligence excite you,</v>

1673
01:14:48.070 --> 01:14:53.070
<v Speaker 1>I think taking the kind of science based</v>
<v Speaker 1>reverse engineering approach that we're </v>

1674
01:14:53.070 --> 01:14:55.060
<v Speaker 1>doing and then trying to put that into </v>
<v Speaker 1>engineering practice,</v>

1675
01:14:55.430 --> 01:14:56.410
<v Speaker 1>it's,</v>
<v Speaker 1>this is,</v>

1676
01:14:56.490 --> 01:14:56.980
<v Speaker 1>this is,</v>
<v Speaker 1>uh,</v>

1677
01:14:56.981 --> 01:14:59.250
<v Speaker 1>this is not just a possible route,</v>
<v Speaker 1>but I think it's,</v>

1678
01:14:59.560 --> 01:15:04.560
<v Speaker 1>it's quite possibly the most valuable </v>
<v Speaker 1>route that you could work on right now </v>

1679
01:15:04.560 --> 01:15:07.960
<v Speaker 1>to try to actually achieve at least some</v>
<v Speaker 1>kind of artificial general intelligence,</v>

1680
01:15:07.990 --> 01:15:12.990
<v Speaker 1>especially the kind of intelligence ai </v>
<v Speaker 1>system that's going to live in a human </v>

1681
01:15:12.990 --> 01:15:13.900
<v Speaker 1>world and interact with humans.</v>

1682
01:15:13.930 --> 01:15:18.930
<v Speaker 1>There's many kinds of ai systems that </v>
<v Speaker 1>could live in worlds of data that none </v>

1683
01:15:18.930 --> 01:15:18.940
<v Speaker 1>of us can understand or whatever live in</v>
<v Speaker 1>ourselves.</v>

1684
01:15:19.210 --> 01:15:24.210
<v Speaker 1>But if you want to build machines that </v>
<v Speaker 1>can live in our world and interact with </v>

1685
01:15:24.210 --> 01:15:24.970
<v Speaker 1>us the way we are used to interacting </v>
<v Speaker 1>with other people,</v>

1686
01:15:25.390 --> 01:15:27.640
<v Speaker 1>then I think this is a route that you </v>
<v Speaker 1>should consider.</v>

1687
01:15:27.790 --> 01:15:28.330
<v Speaker 1>Okay.</v>
<v Speaker 1>Thank you.</v>

1688
01:15:30.580 --> 01:15:35.580
<v Speaker 2>Thank you.</v>

1689
01:15:39.870 --> 01:15:44.870
<v Speaker 4>So earlier in the talk you expressed </v>
<v Speaker 4>some skepticism about whether or not </v>

1690
01:15:44.870 --> 01:15:46.420
<v Speaker 4>industry would get us to understanding </v>
<v Speaker 4>human level intelligence.</v>

1691
01:15:46.990 --> 01:15:49.330
<v Speaker 4>It seems that there's a couple of trends</v>
<v Speaker 4>that favorite industry.</v>

1692
01:15:49.510 --> 01:15:54.510
<v Speaker 4>One is the industry is better than </v>
<v Speaker 4>academia accumulating resources and </v>

1693
01:15:54.510 --> 01:15:58.291
<v Speaker 4>plowing back into the topic and it seems</v>
<v Speaker 4>at the moment we've got a bit of brain </v>

1694
01:15:58.291 --> 01:16:02.400
<v Speaker 4>drain going on from academia into </v>
<v Speaker 4>industry and that seems like an ongoing </v>

1695
01:16:02.400 --> 01:16:06.511
<v Speaker 4>trend.</v>
<v Speaker 4>If you look at something like learning </v>

1696
01:16:06.511 --> 01:16:06.511
<v Speaker 4>to fly,</v>
<v Speaker 4>learning to fly into space,</v>

1697
01:16:06.520 --> 01:16:11.520
<v Speaker 4>then it looks like the story is one of </v>
<v Speaker 4>industry kind of taking over the field </v>

1698
01:16:11.520 --> 01:16:16.030
<v Speaker 4>and going off on its own a little bit.</v>
<v Speaker 4>Academic academics still have a role.</v>

1699
01:16:16.090 --> 01:16:19.630
<v Speaker 4>The industry kind of dominate industry </v>
<v Speaker 4>and I would take the field.</v>

1700
01:16:19.631 --> 01:16:19.990
<v Speaker 4>Do you think?</v>

1701
01:16:20.400 --> 01:16:25.400
<v Speaker 1>Well that's a really good question and </v>
<v Speaker 1>it's got several good questions packed </v>

1702
01:16:25.400 --> 01:16:25.400
<v Speaker 1>into one there.</v>
<v Speaker 1>Right?</v>

1703
01:16:25.400 --> 01:16:27.960
<v Speaker 1>I didn't mean to say this wasn't meant </v>
<v Speaker 1>to say go academia,</v>

1704
01:16:28.050 --> 01:16:29.890
<v Speaker 1>bad industry.</v>
<v Speaker 1>What I was taught,</v>

1705
01:16:30.500 --> 01:16:35.500
<v Speaker 1>what I tried to say was the approaches </v>
<v Speaker 1>that are currently getting the most </v>

1706
01:16:35.500 --> 01:16:39.921
<v Speaker 1>attention in industry and they're really</v>
<v Speaker 1>because they are really the most </v>

1707
01:16:39.921 --> 01:16:39.921
<v Speaker 1>valuable ones right now for the short </v>
<v Speaker 1>term,</v>

1708
01:16:39.921 --> 01:16:44.841
<v Speaker 1>you know,</v>
<v Speaker 1>any industry is really focused on what </v>

1709
01:16:44.841 --> 01:16:46.701
<v Speaker 1>it can do.</v>
<v Speaker 1>What are the value propositions on </v>

1710
01:16:46.701 --> 01:16:46.701
<v Speaker 1>basically a two year timescale at most.</v>
<v Speaker 1>I mean if you ask,</v>

1711
01:16:46.701 --> 01:16:49.050
<v Speaker 1>say Google researchers to take the most </v>
<v Speaker 1>prominent example,</v>

1712
01:16:49.560 --> 01:16:50.850
<v Speaker 1>that's pretty much what they'll all tell</v>
<v Speaker 1>you.</v>

1713
01:16:51.120 --> 01:16:56.120
<v Speaker 1>Okay.</v>
<v Speaker 1>Maybe maybe things that might pay off </v>

1714
01:16:56.120 --> 01:17:00.471
<v Speaker 1>initially in two years,</v>
<v Speaker 1>but maybe take five years or more to </v>

1715
01:17:00.471 --> 01:17:00.471
<v Speaker 1>really develop,</v>
<v Speaker 1>but if,</v>

1716
01:17:00.471 --> 01:17:03.890
<v Speaker 1>if you can't show that it's going to do </v>
<v Speaker 1>something practical for us in two years </v>

1717
01:17:03.890 --> 01:17:03.900
<v Speaker 1>in a way that matters for our bottom </v>
<v Speaker 1>line,</v>

1718
01:17:03.901 --> 01:17:05.160
<v Speaker 1>then it's not really worth doing.</v>

1719
01:17:05.210 --> 01:17:07.180
<v Speaker 1>Okay,</v>
<v Speaker 1>so what,</v>

1720
01:17:07.230 --> 01:17:09.670
<v Speaker 1>when we see what I'm talking about is </v>
<v Speaker 1>technologies,</v>

1721
01:17:09.680 --> 01:17:13.220
<v Speaker 1>which right now industry sees as meeting</v>
<v Speaker 1>that specification.</v>

1722
01:17:13.430 --> 01:17:16.040
<v Speaker 1>And what I'm saying is right now,</v>
<v Speaker 1>I think those.</v>

1723
01:17:16.190 --> 01:17:19.570
<v Speaker 1>That's not where the route is to </v>
<v Speaker 1>something like human,</v>

1724
01:17:19.571 --> 01:17:24.500
<v Speaker 1>like the not the most valuable promising</v>
<v Speaker 1>route to humanlike kinds of AI systems.</v>

1725
01:17:24.520 --> 01:17:26.680
<v Speaker 1>All right,</v>
<v Speaker 1>but I hope that like in the case,</v>

1726
01:17:26.681 --> 01:17:27.860
<v Speaker 1>as you said,</v>
<v Speaker 1>you know,</v>

1727
01:17:27.890 --> 01:17:32.890
<v Speaker 1>the basic research that we're doing now </v>
<v Speaker 1>will be successful enough that it will </v>

1728
01:17:32.890 --> 01:17:34.130
<v Speaker 1>get the attention of industry when the </v>
<v Speaker 1>time is right,</v>

1729
01:17:34.610 --> 01:17:38.810
<v Speaker 1>but I think so,</v>
<v Speaker 1>so I hope at some point it won't.</v>

1730
01:17:38.811 --> 01:17:41.870
<v Speaker 1>It will at least the engineering side </v>
<v Speaker 1>will have to be done in industry,</v>

1731
01:17:42.500 --> 01:17:47.500
<v Speaker 1>not just in academia,</v>
<v Speaker 1>but you're also pointing to issues of </v>

1732
01:17:47.500 --> 01:17:47.540
<v Speaker 1>like brain drain and other things like </v>
<v Speaker 1>that.</v>

1733
01:17:47.810 --> 01:17:50.120
<v Speaker 1>That I think these are real issues </v>
<v Speaker 1>confronting our community.</v>

1734
01:17:50.121 --> 01:17:55.121
<v Speaker 1>I think everybody knows this and I'm </v>
<v Speaker 1>sure this will come up multiple times </v>

1735
01:17:55.121 --> 01:17:55.121
<v Speaker 1>here,</v>
<v Speaker 1>which is,</v>

1736
01:17:55.121 --> 01:17:57.920
<v Speaker 1>you know,</v>
<v Speaker 1>I think we have to find ways to even now</v>

1737
01:17:57.950 --> 01:18:01.910
<v Speaker 1>to combine the best of the ideas,</v>
<v Speaker 1>the energy and the resources of academia</v>

1738
01:18:01.911 --> 01:18:02.600
<v Speaker 1>and industry.</v>

1739
01:18:02.840 --> 01:18:05.900
<v Speaker 1>If we want to keep doing basically </v>
<v Speaker 1>something interesting,</v>

1740
01:18:06.280 --> 01:18:06.970
<v Speaker 1>right?</v>
<v Speaker 1>If we,</v>

1741
01:18:07.030 --> 01:18:09.350
<v Speaker 1>if,</v>
<v Speaker 1>if we just want to redefine ai to be,</v>

1742
01:18:09.440 --> 01:18:14.440
<v Speaker 1>well,</v>
<v Speaker 1>whatever people currently call ai but </v>

1743
01:18:14.440 --> 01:18:16.271
<v Speaker 1>scaled up well then then then fine,</v>
<v Speaker 1>forget about it and or if we just want </v>

1744
01:18:16.271 --> 01:18:20.111
<v Speaker 1>to say,</v>
<v Speaker 1>let me and people like me do what we're </v>

1745
01:18:20.111 --> 01:18:22.691
<v Speaker 1>doing.</v>
<v Speaker 1>At what industry would consider a </v>

1746
01:18:22.691 --> 01:18:22.691
<v Speaker 1>snail's pace on toy problems.</v>
<v Speaker 1>Okay fine,</v>

1747
01:18:22.691 --> 01:18:24.240
<v Speaker 1>but if but if we want to,</v>
<v Speaker 1>if you know,</v>

1748
01:18:24.380 --> 01:18:29.380
<v Speaker 1>if I want to take what I'm doing to the </v>
<v Speaker 1>level that that will really be paying </v>

1749
01:18:29.380 --> 01:18:33.821
<v Speaker 1>off that level the industry can </v>
<v Speaker 1>appreciate or just that really has </v>

1750
01:18:33.821 --> 01:18:34.580
<v Speaker 1>technological impact on a broad scale.</v>
<v Speaker 1>Right?</v>

1751
01:18:34.850 --> 01:18:39.850
<v Speaker 1>Or I think if industry wants to take </v>
<v Speaker 1>what it's doing and really build </v>

1752
01:18:39.850 --> 01:18:40.670
<v Speaker 1>machines that are actually intelligent,</v>
<v Speaker 1>right?</v>

1753
01:18:40.850 --> 01:18:43.190
<v Speaker 1>Or machine learning that actually learns</v>
<v Speaker 1>like a person,</v>

1754
01:18:43.200 --> 01:18:46.460
<v Speaker 1>then I think we need each other now and </v>
<v Speaker 1>not just in some point in the future.</v>

1755
01:18:46.610 --> 01:18:49.010
<v Speaker 1>So this is a general challenge for mit </v>
<v Speaker 1>and for,</v>

1756
01:18:49.050 --> 01:18:50.300
<v Speaker 1>for everywhere.</v>
<v Speaker 1>And for Google.</v>

1757
01:18:50.301 --> 01:18:54.750
<v Speaker 1>I mean we just spent a few days talking </v>
<v Speaker 1>to Google about exactly this issue of,</v>

1758
01:18:54.870 --> 01:18:57.650
<v Speaker 1>in fact this was a talk I prepared </v>
<v Speaker 1>partly for that purpose.</v>

1759
01:18:57.800 --> 01:19:00.080
<v Speaker 1>So we wanted to raise those issues and </v>
<v Speaker 1>and it's just.</v>

1760
01:19:00.330 --> 01:19:01.910
<v Speaker 1>I mean really there,</v>
<v Speaker 1>I don't know what I mean.</v>

1761
01:19:01.920 --> 01:19:06.920
<v Speaker 1>What rather I can think of some </v>
<v Speaker 1>solutions to that problem of what you </v>

1762
01:19:06.920 --> 01:19:11.581
<v Speaker 1>could call brain drain from the academic</v>
<v Speaker 1>point of view or what you could call </v>

1763
01:19:11.581 --> 01:19:12.820
<v Speaker 1>just narrowing in into certain local </v>
<v Speaker 1>minima and the industry point of view,</v>

1764
01:19:13.180 --> 01:19:18.180
<v Speaker 1>but they will require the leadership of </v>
<v Speaker 1>both academic institutions like mit and </v>

1765
01:19:18.180 --> 01:19:22.981
<v Speaker 1>companies like Google being creative </v>
<v Speaker 1>about how they might work together in </v>

1766
01:19:22.981 --> 01:19:22.981
<v Speaker 1>ways that are a little bit outside of </v>
<v Speaker 1>their comfort zone.</v>

1767
01:19:22.981 --> 01:19:24.900
<v Speaker 1>I hope that will start to happen,</v>
<v Speaker 1>um,</v>

1768
01:19:25.180 --> 01:19:30.180
<v Speaker 1>including at mit and at many other </v>
<v Speaker 1>universities and companies like Google </v>

1769
01:19:30.180 --> 01:19:31.480
<v Speaker 1>and many others.</v>
<v Speaker 1>And I think we need it to happen for the</v>

1770
01:19:31.481 --> 01:19:33.970
<v Speaker 1>health of all parties concerned.</v>
<v Speaker 1>Okay.</v>

1771
01:19:34.000 --> 01:19:35.110
<v Speaker 1>Thank you very much.</v>
<v Speaker 1>Thanks.</v>

1772
01:19:36.020 --> 01:19:41.020
<v Speaker 5>Uh,</v>
<v Speaker 5>I'm curious about sort of the premise </v>

1773
01:19:41.020 --> 01:19:44.600
<v Speaker 5>that you gave that a.</v>
<v Speaker 5>One of the big gaps missing at </v>

1774
01:19:44.600 --> 01:19:47.931
<v Speaker 5>determining intelligence is the fact </v>
<v Speaker 5>that we need to teach machines how to </v>

1775
01:19:47.931 --> 01:19:52.880
<v Speaker 5>recognize models.</v>
<v Speaker 5>And I'm curious as to what you think </v>

1776
01:19:52.880 --> 01:19:57.590
<v Speaker 5>sort of non goal oriented cognitive </v>
<v Speaker 5>activity comes into play there.</v>

1777
01:19:58.170 --> 01:20:03.170
<v Speaker 5>Things like feelings and emotions and,</v>
<v Speaker 5>and why you don't think that might not </v>

1778
01:20:04.860 --> 01:20:08.130
<v Speaker 5>necessarily be like the most</v>

1779
01:20:08.680 --> 01:20:13.680
<v Speaker 1>important question.</v>
<v Speaker 1>The only reason emotions didn't appear </v>

1780
01:20:13.680 --> 01:20:15.030
<v Speaker 1>on my slide is because there's a few </v>
<v Speaker 1>reasons,</v>

1781
01:20:15.031 --> 01:20:20.031
<v Speaker 1>but the slide is only so big.</v>
<v Speaker 1>I wanted the font to be readable for </v>

1782
01:20:20.031 --> 01:20:21.390
<v Speaker 1>such an important slide.</v>
<v Speaker 1>I had versions of my slide in which I do</v>

1783
01:20:21.391 --> 01:20:22.550
<v Speaker 1>talk about that.</v>
<v Speaker 1>Okay.</v>

1784
01:20:22.740 --> 01:20:24.140
<v Speaker 1>Um,</v>
<v Speaker 1>I,</v>

1785
01:20:24.760 --> 01:20:27.330
<v Speaker 1>it's not that I think feelings or </v>
<v Speaker 1>emotions aren't important.</v>

1786
01:20:27.590 --> 01:20:32.590
<v Speaker 1>I think they are important and I,</v>
<v Speaker 1>and I used to not have many insights on </v>

1787
01:20:32.590 --> 01:20:35.740
<v Speaker 1>it about what to do about them,</v>
<v Speaker 1>but actually partly based on some of my </v>

1788
01:20:35.740 --> 01:20:36.630
<v Speaker 1>colleagues here at Mit,</v>
<v Speaker 1>bcs,</v>

1789
01:20:36.631 --> 01:20:41.631
<v Speaker 1>Laura Schultz and Rebecca Saxe to,</v>
<v Speaker 1>of my cognitive colleagues who I work </v>

1790
01:20:41.631 --> 01:20:41.750
<v Speaker 1>closely with,</v>
<v Speaker 1>um,</v>

1791
01:20:41.810 --> 01:20:43.140
<v Speaker 1>they've been starting to,</v>
<v Speaker 1>to,</v>

1792
01:20:43.350 --> 01:20:46.020
<v Speaker 1>to do research on how people understand </v>
<v Speaker 1>emotions,</v>

1793
01:20:46.021 --> 01:20:51.021
<v Speaker 1>both their own and others and we've been</v>
<v Speaker 1>starting to work with them on </v>

1794
01:20:51.021 --> 01:20:53.601
<v Speaker 1>computational models.</v>
<v Speaker 1>So that's actually something I'm </v>

1795
01:20:53.601 --> 01:20:53.601
<v Speaker 1>actively interested in and even working </v>
<v Speaker 1>on.</v>

1796
01:20:53.601 --> 01:20:53.790
<v Speaker 1>But I would say,</v>
<v Speaker 1>and again,</v>

1797
01:20:53.791 --> 01:20:55.560
<v Speaker 1>for those of you who study emotion or </v>
<v Speaker 1>know about this,</v>

1798
01:20:55.561 --> 01:20:57.300
<v Speaker 1>actually you're going to have lisa </v>
<v Speaker 1>coming in,</v>

1799
01:20:57.301 --> 01:20:57.670
<v Speaker 1>right?</v>
<v Speaker 1>Oh.</v>

1800
01:20:57.671 --> 01:21:00.090
<v Speaker 1>So she's going to basically say a </v>
<v Speaker 1>version of the same thing.</v>

1801
01:21:00.091 --> 01:21:05.091
<v Speaker 1>I think the deepest way to understand </v>
<v Speaker 1>she's one of the world's experts on </v>

1802
01:21:05.091 --> 01:21:06.120
<v Speaker 1>this.</v>
<v Speaker 1>The deepest way to understand emotion is</v>

1803
01:21:06.121 --> 01:21:08.700
<v Speaker 1>very much based on our mental models of </v>
<v Speaker 1>ourselves,</v>

1804
01:21:08.701 --> 01:21:10.410
<v Speaker 1>of the situation we're in and of other </v>
<v Speaker 1>people,</v>

1805
01:21:10.650 --> 01:21:11.640
<v Speaker 1>right?</v>
<v Speaker 1>Think about,</v>

1806
01:21:11.641 --> 01:21:14.400
<v Speaker 1>for example,</v>
<v Speaker 1>all of the different.</v>

1807
01:21:14.820 --> 01:21:15.810
<v Speaker 1>I mean if,</v>
<v Speaker 1>if,</v>

1808
01:21:15.820 --> 01:21:16.230
<v Speaker 1>if,</v>
<v Speaker 1>if,</v>

1809
01:21:16.240 --> 01:21:17.220
<v Speaker 1>if you think about them,</v>
<v Speaker 1>I mean,</v>

1810
01:21:17.221 --> 01:21:18.450
<v Speaker 1>again,</v>
<v Speaker 1>Lisa will talk all about this,</v>

1811
01:21:18.451 --> 01:21:23.451
<v Speaker 1>but if you think about emotion,</v>
<v Speaker 1>it's just a very small set of what are </v>

1812
01:21:23.451 --> 01:21:26.001
<v Speaker 1>sometimes called basic emotions,</v>
<v Speaker 1>like being happy or angry or sad or you </v>

1813
01:21:28.041 --> 01:21:29.580
<v Speaker 1>know,</v>
<v Speaker 1>those are small number of them,</v>

1814
01:21:29.581 --> 01:21:31.230
<v Speaker 1>right?</v>
<v Speaker 1>There's usually only a few,</v>

1815
01:21:31.290 --> 01:21:33.980
<v Speaker 1>right?</v>
<v Speaker 1>You might not say,</v>

1816
01:21:34.020 --> 01:21:39.020
<v Speaker 1>you might see that as somehow like very </v>
<v Speaker 1>basic things that are opposed to some </v>

1817
01:21:39.020 --> 01:21:39.030
<v Speaker 1>kind of cognitive activity.</v>

1818
01:21:39.270 --> 01:21:41.880
<v Speaker 1>But think about all the different words </v>
<v Speaker 1>we have for emotion,</v>

1819
01:21:42.060 --> 01:21:42.960
<v Speaker 1>right?</v>
<v Speaker 1>Um,</v>

1820
01:21:43.080 --> 01:21:44.860
<v Speaker 1>for example,</v>
<v Speaker 1>think about an,</v>

1821
01:21:44.880 --> 01:21:47.340
<v Speaker 1>a,</v>
<v Speaker 1>a famous cognitive emotion like regret.</v>

1822
01:21:47.700 --> 01:21:50.280
<v Speaker 1>What does it mean to feel regret or </v>
<v Speaker 1>frustration?</v>

1823
01:21:50.670 --> 01:21:51.920
<v Speaker 1>Right?</v>
<v Speaker 1>To just to,</v>

1824
01:21:52.050 --> 01:21:57.050
<v Speaker 1>to know both for yourself when you're </v>
<v Speaker 1>not just feeling kind of down or </v>

1825
01:21:57.050 --> 01:22:00.531
<v Speaker 1>negative,</v>
<v Speaker 1>but you're feeling regret that that </v>

1826
01:22:00.531 --> 01:22:02.901
<v Speaker 1>means something like,</v>
<v Speaker 1>I have to feel like there's a situation </v>

1827
01:22:02.901 --> 01:22:06.201
<v Speaker 1>that came out differently from how I </v>
<v Speaker 1>hoped and I realized I could have done </v>

1828
01:22:06.201 --> 01:22:06.990
<v Speaker 1>something differently.</v>
<v Speaker 1>Right?</v>

1829
01:22:07.110 --> 01:22:09.090
<v Speaker 1>So that means you have to be able to </v>
<v Speaker 1>understand,</v>

1830
01:22:09.160 --> 01:22:14.160
<v Speaker 1>you have to have a model,</v>
<v Speaker 1>you have to be able to do a kind of </v>

1831
01:22:14.160 --> 01:22:14.160
<v Speaker 1>counterfactual reasoning and to think,</v>
<v Speaker 1>oh,</v>

1832
01:22:14.160 --> 01:22:18.171
<v Speaker 1>if only I had acted a different way than</v>
<v Speaker 1>I can predict that the world would have </v>

1833
01:22:18.171 --> 01:22:18.171
<v Speaker 1>come out differently and that's the </v>
<v Speaker 1>situation I wanted,</v>

1834
01:22:18.171 --> 01:22:20.160
<v Speaker 1>but instead it came up this other way,</v>
<v Speaker 1>right?</v>

1835
01:22:20.560 --> 01:22:22.530
<v Speaker 1>Um,</v>
<v Speaker 1>or think about frustration again,</v>

1836
01:22:22.890 --> 01:22:24.570
<v Speaker 1>that requires something like </v>
<v Speaker 1>understanding,</v>

1837
01:22:24.571 --> 01:22:26.160
<v Speaker 1>okay,</v>
<v Speaker 1>I've tried a bunch of times,</v>

1838
01:22:26.161 --> 01:22:28.680
<v Speaker 1>I thought this would work,</v>
<v Speaker 1>but it doesn't seem to be working.</v>

1839
01:22:28.681 --> 01:22:31.410
<v Speaker 1>Maybe I'm ready to give up though.</v>
<v Speaker 1>Those are all.</v>

1840
01:22:31.440 --> 01:22:33.810
<v Speaker 1>Those are.</v>
<v Speaker 1>Those are very important human emotions.</v>

1841
01:22:34.110 --> 01:22:36.150
<v Speaker 1>We have to understand to understand </v>
<v Speaker 1>ourselves.</v>

1842
01:22:36.151 --> 01:22:38.790
<v Speaker 1>We need that to understand other people </v>
<v Speaker 1>to understand communication,</v>

1843
01:22:39.030 --> 01:22:42.750
<v Speaker 1>but those are all filtered through the </v>
<v Speaker 1>kinds of models of action that I was.</v>

1844
01:22:42.840 --> 01:22:47.840
<v Speaker 1>Just the ones I was talking about here </v>
<v Speaker 1>with these say cost benefit analysis of </v>

1845
01:22:47.840 --> 01:22:47.840
<v Speaker 1>action.</v>
<v Speaker 1>So what I'm.</v>

1846
01:22:47.840 --> 01:22:52.340
<v Speaker 1>So I'm just trying to say I think this </v>
<v Speaker 1>is very basic stuff that will be the </v>

1847
01:22:52.340 --> 01:22:55.701
<v Speaker 1>basis for building,</v>
<v Speaker 1>I think better engineering style models </v>

1848
01:22:55.701 --> 01:22:57.630
<v Speaker 1>of the full spectrum of human emotion </v>
<v Speaker 1>beyond just like,</v>

1849
01:22:57.631 --> 01:22:59.400
<v Speaker 1>well,</v>
<v Speaker 1>I'm feeling good or bad or scared.</v>

1850
01:22:59.420 --> 01:23:01.770
<v Speaker 1>Okay.</v>
<v Speaker 1>And if I think when you see Lisa,</v>

1851
01:23:01.771 --> 01:23:04.410
<v Speaker 1>she will in her own way,</v>
<v Speaker 1>say something very similar.</v>

1852
01:23:05.470 --> 01:23:06.430
<v Speaker 1>Interesting.</v>
<v Speaker 1>Thanks.</v>

1853
01:23:06.431 --> 01:23:09.340
<v Speaker 1>Yeah,</v>
<v Speaker 1>thanks Josh for your stock.</v>

1854
01:23:09.550 --> 01:23:14.550
<v Speaker 1>So all these are both human cognition </v>
<v Speaker 1>and try to build a model to mimic those </v>

1855
01:23:14.550 --> 01:23:14.920
<v Speaker 1>cognition.</v>
<v Speaker 1>What you don't.</v>

1856
01:23:14.980 --> 01:23:18.310
<v Speaker 1>How much could help you to understand </v>
<v Speaker 1>how the circuit implement those things.</v>

1857
01:23:18.890 --> 01:23:21.330
<v Speaker 1>I mean like the circuits in the brain.</v>
<v Speaker 1>What's the.</v>

1858
01:23:22.260 --> 01:23:23.820
<v Speaker 1>Is that what you work on by Newcastle?</v>
<v Speaker 1>Sorry,</v>

1859
01:23:23.890 --> 01:23:24.310
<v Speaker 1>what?</v>
<v Speaker 1>Is that?</v>

1860
01:23:24.311 --> 01:23:25.540
<v Speaker 1>What you work on by any chance?</v>
<v Speaker 1>Yeah,</v>

1861
01:23:26.330 --> 01:23:27.570
<v Speaker 1>yeah.</v>
<v Speaker 1>Yeah.</v>

1862
01:23:27.880 --> 01:23:29.920
<v Speaker 1>So,</v>
<v Speaker 1>so in the center for brains,</v>

1863
01:23:29.921 --> 01:23:32.530
<v Speaker 1>minds and machines as well as in brain </v>
<v Speaker 1>and cognitive science.</v>

1864
01:23:32.531 --> 01:23:37.531
<v Speaker 1>Yet we have a number of colleagues who </v>
<v Speaker 1>study the actual hardware basis of this </v>

1865
01:23:37.531 --> 01:23:40.090
<v Speaker 1>stuff in the brain and that includes </v>
<v Speaker 1>like the large scale architecture of the</v>

1866
01:23:40.091 --> 01:23:41.780
<v Speaker 1>brain,</v>
<v Speaker 1>say like what Nancy Campbell shirt,</v>

1867
01:23:41.800 --> 01:23:45.250
<v Speaker 1>Rebecca Saxe study with functional brain</v>
<v Speaker 1>imaging or the more detailed circuitry,</v>

1868
01:23:45.251 --> 01:23:50.251
<v Speaker 1>which usually requires recording from </v>
<v Speaker 1>say non brands right at the level of </v>

1869
01:23:50.251 --> 01:23:51.400
<v Speaker 1>individual neurons and connections </v>
<v Speaker 1>between neurons.</v>

1870
01:23:51.470 --> 01:23:53.920
<v Speaker 1>Alright.</v>
<v Speaker 1>So I'm very interested in those things,</v>

1871
01:23:53.921 --> 01:23:56.160
<v Speaker 1>although it's not mostly what I work on.</v>
<v Speaker 1>Right.</v>

1872
01:23:56.350 --> 01:23:57.390
<v Speaker 1>But I would say,</v>
<v Speaker 1>you know,</v>

1873
01:23:57.460 --> 01:23:59.590
<v Speaker 1>again like in many other areas of </v>
<v Speaker 1>science,</v>

1874
01:23:59.620 --> 01:24:04.620
<v Speaker 1>certainly in neuroscience,</v>
<v Speaker 1>the kind of work I'm talking about here </v>

1875
01:24:04.620 --> 01:24:07.980
<v Speaker 1>in a sort of classic reductionist </v>
<v Speaker 1>program sets the target for what we </v>

1876
01:24:07.980 --> 01:24:07.980
<v Speaker 1>might look for.</v>
<v Speaker 1>Like if I,</v>

1877
01:24:08.100 --> 01:24:10.290
<v Speaker 1>if I just want to go,</v>
<v Speaker 1>I would,</v>

1878
01:24:10.430 --> 01:24:12.280
<v Speaker 1>I would,</v>
<v Speaker 1>I would assert right.</v>

1879
01:24:12.281 --> 01:24:17.281
<v Speaker 1>Or my working conjecture is that if,</v>
<v Speaker 1>if you do the kind of work that I'm </v>

1880
01:24:17.281 --> 01:24:22.231
<v Speaker 1>talking about here,</v>
<v Speaker 1>it gives you the right targets or gives </v>

1881
01:24:22.231 --> 01:24:25.261
<v Speaker 1>you a candidates that have targets to </v>
<v Speaker 1>look for what are the neural circuits </v>

1882
01:24:25.261 --> 01:24:25.261
<v Speaker 1>computing.</v>
<v Speaker 1>Right?</v>

1883
01:24:25.270 --> 01:24:30.270
<v Speaker 1>Whereas if you just go in and just say,</v>
<v Speaker 1>start poking around in the brain or have</v>

1884
01:24:30.491 --> 01:24:35.491
<v Speaker 1>some idea that what you're going to try </v>
<v Speaker 1>to do is find the neural circuits which </v>

1885
01:24:35.491 --> 01:24:38.131
<v Speaker 1>underlie behavior without a sense of the</v>
<v Speaker 1>computations needed to produce those </v>

1886
01:24:38.131 --> 01:24:38.680
<v Speaker 1>behaviors.</v>

1887
01:24:39.010 --> 01:24:44.010
<v Speaker 1>I don't,</v>
<v Speaker 1>I think it's going to be very difficult </v>

1888
01:24:44.010 --> 01:24:46.180
<v Speaker 1>to,</v>
<v Speaker 1>to know what to look for and to know </v>

1889
01:24:46.180 --> 01:24:46.780
<v Speaker 1>when you found even Bible answers.</v>
<v Speaker 1>So I think that's,</v>

1890
01:24:46.810 --> 01:24:48.760
<v Speaker 1>you know,</v>
<v Speaker 1>that's the standard kind of reductionist</v>

1891
01:24:48.761 --> 01:24:51.410
<v Speaker 1>program,</v>
<v Speaker 1>but it's not,</v>

1892
01:24:51.500 --> 01:24:52.660
<v Speaker 1>it's,</v>
<v Speaker 1>it's not.</v>

1893
01:24:52.661 --> 01:24:53.810
<v Speaker 1>Um,</v>
<v Speaker 1>I also think it's,</v>

1894
01:24:53.830 --> 01:24:57.130
<v Speaker 1>it's not one that is divorced from the </v>
<v Speaker 1>study of neurocircuits.</v>

1895
01:24:57.370 --> 01:25:02.370
<v Speaker 1>It's also one,</v>
<v Speaker 1>if you look at the broad picture of </v>

1896
01:25:02.370 --> 01:25:04.741
<v Speaker 1>reverse engineering,</v>
<v Speaker 1>it's one where you were neurocircuits </v>

1897
01:25:04.741 --> 01:25:07.570
<v Speaker 1>and understanding the circuits in the </v>
<v Speaker 1>brain play an absolutely critical role.</v>

1898
01:25:07.660 --> 01:25:10.000
<v Speaker 1>Okay.</v>
<v Speaker 1>I would say the main as an.</v>

1899
01:25:10.060 --> 01:25:12.130
<v Speaker 1>When you look at the brain at the </v>
<v Speaker 1>hardware level,</v>

1900
01:25:12.131 --> 01:25:17.131
<v Speaker 1>as an engineer,</v>
<v Speaker 1>I'm mostly looking at the software </v>

1901
01:25:17.131 --> 01:25:17.131
<v Speaker 1>level,</v>
<v Speaker 1>right?</v>

1902
01:25:17.131 --> 01:25:18.100
<v Speaker 1>But when you look at the hardware level,</v>
<v Speaker 1>there are some remarkable properties.</v>

1903
01:25:18.490 --> 01:25:19.720
<v Speaker 1>One remarkable property,</v>
<v Speaker 1>again,</v>

1904
01:25:19.721 --> 01:25:24.370
<v Speaker 1>is how much parallelism there is and in </v>
<v Speaker 1>many ways how fast the computations are.</v>

1905
01:25:24.400 --> 01:25:25.840
<v Speaker 1>Okay,</v>
<v Speaker 1>neurons are slow,</v>

1906
01:25:25.930 --> 01:25:28.030
<v Speaker 1>but the computation of the tubs are very</v>
<v Speaker 1>fast.</v>

1907
01:25:28.180 --> 01:25:33.180
<v Speaker 1>So how do we get elements that are in </v>
<v Speaker 1>some sense quite slow in their time </v>

1908
01:25:33.180 --> 01:25:34.840
<v Speaker 1>constant to produce such intelligent </v>
<v Speaker 1>behavior so quickly?</v>

1909
01:25:34.841 --> 01:25:39.841
<v Speaker 1>That's a great mystery.</v>
<v Speaker 1>And I think if we understood that it </v>

1910
01:25:39.841 --> 01:25:39.841
<v Speaker 1>would have payoff for building all sorts</v>
<v Speaker 1>of,</v>

1911
01:25:39.841 --> 01:25:40.350
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

1912
01:25:40.360 --> 01:25:42.850
<v Speaker 1>apple basically application embedded </v>
<v Speaker 1>circuits.</v>

1913
01:25:42.851 --> 01:25:47.851
<v Speaker 1>Okay.</v>
<v Speaker 1>But also maybe most important is the </v>

1914
01:25:47.851 --> 01:25:47.851
<v Speaker 1>power consumption.</v>
<v Speaker 1>And again,</v>

1915
01:25:47.851 --> 01:25:47.890
<v Speaker 1>many people have,</v>
<v Speaker 1>have,</v>

1916
01:25:48.280 --> 01:25:49.420
<v Speaker 1>have noted this,</v>
<v Speaker 1>right?</v>

1917
01:25:49.630 --> 01:25:52.810
<v Speaker 1>If you look at the power consumption,</v>
<v Speaker 1>the power that the brain consumes,</v>

1918
01:25:52.811 --> 01:25:54.280
<v Speaker 1>like what did I eat today?</v>
<v Speaker 1>Okay?</v>

1919
01:25:54.970 --> 01:25:57.520
<v Speaker 1>Almost nothing.</v>
<v Speaker 1>My daughter,</v>

1920
01:25:57.521 --> 01:25:59.560
<v Speaker 1>who's again,</v>
<v Speaker 1>she's doing an internship here,</v>

1921
01:25:59.561 --> 01:26:04.561
<v Speaker 1>she literally yesterday,</v>
<v Speaker 1>all she ate was a burrito and yet she </v>

1922
01:26:04.561 --> 01:26:07.831
<v Speaker 1>wrote 300 lines of code for her </v>
<v Speaker 1>internship project on really cool </v>

1923
01:26:07.831 --> 01:26:11.951
<v Speaker 1>computational linguistics project.</v>
<v Speaker 1>So somehow she turned a Burrito into a </v>

1924
01:26:11.951 --> 01:26:12.560
<v Speaker 1>model of child language acquisition.</v>

1925
01:26:12.740 --> 01:26:14.240
<v Speaker 1>Okay,</v>
<v Speaker 1>but how did she do that?</v>

1926
01:26:14.241 --> 01:26:15.710
<v Speaker 1>Or how do any of us do this?</v>
<v Speaker 1>Right?</v>

1927
01:26:15.980 --> 01:26:20.980
<v Speaker 1>Um,</v>
<v Speaker 1>where if you look at the power that we </v>

1928
01:26:20.980 --> 01:26:22.541
<v Speaker 1>consume when we simulate even a very,</v>
<v Speaker 1>very small chunk of cortex on our </v>

1929
01:26:22.541 --> 01:26:26.501
<v Speaker 1>conventional hardware,</v>
<v Speaker 1>or we do any kind of machine learning </v>

1930
01:26:26.501 --> 01:26:26.600
<v Speaker 1>thing,</v>
<v Speaker 1>we have systems which are very,</v>

1931
01:26:26.601 --> 01:26:27.140
<v Speaker 1>very,</v>
<v Speaker 1>very,</v>

1932
01:26:27.141 --> 01:26:30.350
<v Speaker 1>very far from the power of the human </v>
<v Speaker 1>brain computationally,</v>

1933
01:26:30.590 --> 01:26:34.790
<v Speaker 1>but in terms of physical energy consumed</v>
<v Speaker 1>way,</v>

1934
01:26:34.850 --> 01:26:36.860
<v Speaker 1>way past what any individual brain is </v>
<v Speaker 1>doing.</v>

1935
01:26:37.010 --> 01:26:40.220
<v Speaker 1>So how do we get circuitry of any sort,</v>
<v Speaker 1>biological,</v>

1936
01:26:40.221 --> 01:26:43.370
<v Speaker 1>or just any physical circuits to be as </v>
<v Speaker 1>smart as we are with,</v>

1937
01:26:43.550 --> 01:26:45.560
<v Speaker 1>with as little energy as we are.</v>
<v Speaker 1>This is,</v>

1938
01:26:45.590 --> 01:26:49.310
<v Speaker 1>this is a huge problem for basically </v>
<v Speaker 1>every area of engineering,</v>

1939
01:26:49.311 --> 01:26:50.060
<v Speaker 1>right?</v>
<v Speaker 1>If you want to,</v>

1940
01:26:50.450 --> 01:26:55.450
<v Speaker 1>if you want to have any kind of robot,</v>
<v Speaker 1>the power consumption is a key </v>

1941
01:26:55.450 --> 01:26:56.510
<v Speaker 1>bottleneck.</v>
<v Speaker 1>Same for self driving cars.</v>

1942
01:26:56.720 --> 01:27:01.720
<v Speaker 1>If we want to build ai without </v>
<v Speaker 1>contributing to global warming and </v>

1943
01:27:01.720 --> 01:27:05.921
<v Speaker 1>climate change,</v>
<v Speaker 1>let alone use ai to solve climate </v>

1944
01:27:05.921 --> 01:27:08.621
<v Speaker 1>change,</v>
<v Speaker 1>we really need to address these issues </v>

1945
01:27:08.621 --> 01:27:08.690
<v Speaker 1>and the brain is a,</v>
<v Speaker 1>is a huge a guide there,</v>

1946
01:27:08.920 --> 01:27:13.920
<v Speaker 1>right?</v>
<v Speaker 1>I think there are some people who are </v>

1947
01:27:13.920 --> 01:27:13.920
<v Speaker 1>really starting to think about this.</v>
<v Speaker 1>How can we say,</v>

1948
01:27:13.920 --> 01:27:15.770
<v Speaker 1>for example,</v>
<v Speaker 1>build somehow brain inspired computers,</v>

1949
01:27:15.771 --> 01:27:20.771
<v Speaker 1>which are very,</v>
<v Speaker 1>very low power but maybe only </v>

1950
01:27:20.771 --> 01:27:20.771
<v Speaker 1>approximate.</v>
<v Speaker 1>So I'm thinking here of Joe Bates,</v>

1951
01:27:20.771 --> 01:27:21.590
<v Speaker 1>I don't know if I don't have,</v>
<v Speaker 1>you know,</v>

1952
01:27:21.591 --> 01:27:22.160
<v Speaker 1>Joe,</v>
<v Speaker 1>he's,</v>

1953
01:27:22.460 --> 01:27:22.890
<v Speaker 1>he's,</v>
<v Speaker 1>uh,</v>

1954
01:27:22.940 --> 01:27:25.430
<v Speaker 1>been around mit and other places for </v>
<v Speaker 1>quite awhile.</v>

1955
01:27:25.460 --> 01:27:27.200
<v Speaker 1>Can I tell them about your company?</v>
<v Speaker 1>So,</v>

1956
01:27:27.320 --> 01:27:32.320
<v Speaker 1>so joe has a low,</v>
<v Speaker 1>a startup in Kendall Square called </v>

1957
01:27:32.320 --> 01:27:33.140
<v Speaker 1>singular computing and they have some </v>
<v Speaker 1>very interesting ideas,</v>

1958
01:27:33.141 --> 01:27:37.130
<v Speaker 1>including some actual implemented </v>
<v Speaker 1>technology for low power,</v>

1959
01:27:37.131 --> 01:27:42.131
<v Speaker 1>approximate computing in a sort of a </v>
<v Speaker 1>brain like way that might lead to </v>

1960
01:27:42.131 --> 01:27:42.890
<v Speaker 1>possibly even like the ability to build </v>
<v Speaker 1>something.</v>

1961
01:27:42.890 --> 01:27:46.070
<v Speaker 1>This is Joe's dream to build on this,</v>
<v Speaker 1>about the size of this table,</v>

1962
01:27:46.071 --> 01:27:50.030
<v Speaker 1>but that has a billion course,</v>
<v Speaker 1>a billion cores and runs on a reasonable</v>

1963
01:27:50.031 --> 01:27:55.031
<v Speaker 1>kind of power consumption.</v>
<v Speaker 1>I would love to have such a machine if </v>

1964
01:27:55.031 --> 01:27:56.360
<v Speaker 1>anybody wants to help joe build that.</v>
<v Speaker 1>I think he'd love to talk to you,</v>

1965
01:27:57.470 --> 01:27:59.130
<v Speaker 1>but it's one of a number of,</v>
<v Speaker 1>of,</v>

1966
01:27:59.150 --> 01:28:00.770
<v Speaker 1>of ideas.</v>
<v Speaker 1>I mean google x,</v>

1967
01:28:00.771 --> 01:28:05.771
<v Speaker 1>people are working on similar things.</v>
<v Speaker 1>Probably most of the major chip </v>

1968
01:28:05.771 --> 01:28:06.080
<v Speaker 1>companies are also inspired by this </v>
<v Speaker 1>idea.</v>

1969
01:28:06.230 --> 01:28:09.410
<v Speaker 1>And I think even if you didn't think you</v>
<v Speaker 1>were interested in the brain,</v>

1970
01:28:09.411 --> 01:28:14.411
<v Speaker 1>if you want to build the kind of ai </v>
<v Speaker 1>we're talking about and run it on </v>

1971
01:28:14.411 --> 01:28:17.741
<v Speaker 1>physical hardware of any sort and </v>
<v Speaker 1>understanding how the brain circuits </v>

1972
01:28:17.741 --> 01:28:21.900
<v Speaker 1>compute what they do,</v>
<v Speaker 1>what I'm talking about with as little </v>

1973
01:28:21.900 --> 01:28:23.740
<v Speaker 1>power as they do,</v>
<v Speaker 1>I don't know any better place to look.</v>

1974
01:28:25.040 --> 01:28:30.040
<v Speaker 6>It seems like a lot of the improvements </v>
<v Speaker 6>in ai have been driven by increasing </v>

1975
01:28:30.040 --> 01:28:31.550
<v Speaker 6>computational power.</v>
<v Speaker 6>How far are you,</v>

1976
01:28:31.700 --> 01:28:36.700
<v Speaker 6>would you say me like Gpu or CPU?</v>
<v Speaker 6>How far would you say we are from </v>

1977
01:28:36.700 --> 01:28:39.050
<v Speaker 6>hardware that could run a general </v>
<v Speaker 6>artificial intelligence</v>

1978
01:28:40.560 --> 01:28:42.300
<v Speaker 1>of the kind that I'm talking about?</v>
<v Speaker 1>Yeah,</v>

1979
01:28:42.301 --> 01:28:44.290
<v Speaker 1>I dunno.</v>
<v Speaker 1>I'll start with a billion cores and then</v>

1980
01:28:44.291 --> 01:28:46.150
<v Speaker 1>we'll see.</v>
<v Speaker 1>I mean,</v>

1981
01:28:46.151 --> 01:28:47.980
<v Speaker 1>I think we're,</v>
<v Speaker 1>I think we're,</v>

1982
01:28:48.060 --> 01:28:48.460
<v Speaker 1>I mean,</v>
<v Speaker 1>I think,</v>

1983
01:28:48.550 --> 01:28:53.550
<v Speaker 1>I think there's no way to answer that </v>
<v Speaker 1>question in a way that software </v>

1984
01:28:53.550 --> 01:28:53.550
<v Speaker 1>independent.</v>
<v Speaker 1>I don't know how to do that right.</v>

1985
01:28:54.400 --> 01:28:58.410
<v Speaker 1>But I think that um,</v>
<v Speaker 1>it's and,</v>

1986
01:28:58.670 --> 01:28:59.650
<v Speaker 1>and you know,</v>
<v Speaker 1>I don't know,</v>

1987
01:28:59.651 --> 01:29:01.710
<v Speaker 1>like when you say how far we you mean?</v>
<v Speaker 1>Uh,</v>

1988
01:29:01.711 --> 01:29:03.960
<v Speaker 1>how far am I with the resources I have </v>
<v Speaker 1>right now?</v>

1989
01:29:03.961 --> 01:29:04.940
<v Speaker 1>How far my,</v>
<v Speaker 1>if,</v>

1990
01:29:05.000 --> 01:29:08.250
<v Speaker 1>if Google decides to put all of its </v>
<v Speaker 1>resources at my disposal,</v>

1991
01:29:08.251 --> 01:29:10.170
<v Speaker 1>like they might if I were working at </v>
<v Speaker 1>deepmind.</v>

1992
01:29:11.440 --> 01:29:13.050
<v Speaker 1>I don't know the answer to that </v>
<v Speaker 1>question,</v>

1993
01:29:13.650 --> 01:29:18.650
<v Speaker 1>but I think the,</v>
<v Speaker 1>I think what we can say is this </v>

1994
01:29:18.650 --> 01:29:18.650
<v Speaker 1>individual neurons.</v>
<v Speaker 1>I mean,</v>

1995
01:29:18.650 --> 01:29:23.511
<v Speaker 1>again,</v>
<v Speaker 1>this goes back to another reason to </v>

1996
01:29:23.511 --> 01:29:23.511
<v Speaker 1>study neurocircuits.</v>
<v Speaker 1>Um,</v>

1997
01:29:23.511 --> 01:29:25.020
<v Speaker 1>if you look at what we currently call </v>
<v Speaker 1>neural networks in the Ai side,</v>

1998
01:29:25.230 --> 01:29:26.700
<v Speaker 1>the model of a neuron is,</v>
<v Speaker 1>is very,</v>

1999
01:29:26.701 --> 01:29:27.720
<v Speaker 1>very simple thing.</v>

2000
01:29:28.710 --> 01:29:31.050
<v Speaker 1>Individual neurons are not only much </v>
<v Speaker 1>more complex,</v>

2001
01:29:31.170 --> 01:29:33.060
<v Speaker 1>but I have a lot more computational </v>
<v Speaker 1>power.</v>

2002
01:29:33.061 --> 01:29:35.280
<v Speaker 1>It's not clear how they use it or </v>
<v Speaker 1>whether they use it,</v>

2003
01:29:35.820 --> 01:29:39.300
<v Speaker 1>but I think it's just as likely that a </v>
<v Speaker 1>neuron is something like a revenue,</v>

2004
01:29:39.720 --> 01:29:44.720
<v Speaker 1>right?</v>
<v Speaker 1>Is that a neuron is something like a </v>

2005
01:29:44.720 --> 01:29:46.521
<v Speaker 1>computer,</v>
<v Speaker 1>like under one neuron in your brain is </v>

2006
01:29:46.521 --> 01:29:46.521
<v Speaker 1>more like a CPU note.</v>
<v Speaker 1>Okay.</v>

2007
01:29:46.590 --> 01:29:47.440
<v Speaker 1>Maybe,</v>
<v Speaker 1>um,</v>

2008
01:29:47.550 --> 01:29:50.770
<v Speaker 1>and thus the 10 billion or trillion,</v>
<v Speaker 1>you know,</v>

2009
01:29:50.800 --> 01:29:52.710
<v Speaker 1>the large number of neurons in your </v>
<v Speaker 1>brain,</v>

2010
01:29:53.100 --> 01:29:58.100
<v Speaker 1>um,</v>
<v Speaker 1>I think it's like 10 billion cortical </v>

2011
01:29:58.100 --> 01:29:59.310
<v Speaker 1>pyramidal neurons or something might be </v>
<v Speaker 1>like 10 billion corps.</v>

2012
01:29:59.520 --> 01:30:00.390
<v Speaker 1>Okay.</v>
<v Speaker 1>For example,</v>

2013
01:30:00.391 --> 01:30:02.940
<v Speaker 1>that's at least as plausible I think to </v>
<v Speaker 1>me as any other estimate.</v>

2014
01:30:03.150 --> 01:30:04.410
<v Speaker 1>So.</v>
<v Speaker 1>And I think so.</v>

2015
01:30:04.500 --> 01:30:08.310
<v Speaker 1>I think we're definitely on the </v>
<v Speaker 1>underside with very big error bars,</v>

2016
01:30:08.430 --> 01:30:13.430
<v Speaker 1>so I completely agree that um,</v>
<v Speaker 1>or if this is what you might be </v>

2017
01:30:13.430 --> 01:30:13.580
<v Speaker 1>suggesting and May,</v>
<v Speaker 1>you know,</v>

2018
01:30:13.670 --> 01:30:15.060
<v Speaker 1>going back to my answer to your </v>
<v Speaker 1>question,</v>

2019
01:30:15.061 --> 01:30:16.820
<v Speaker 1>I don't think we're going to get to what</v>
<v Speaker 1>I'm talking about.</v>

2020
01:30:16.860 --> 01:30:21.480
<v Speaker 1>Anything like a real brain scale without</v>
<v Speaker 1>major innovations on the hardware side.</v>

2021
01:30:21.690 --> 01:30:22.410
<v Speaker 1>And you know,</v>
<v Speaker 1>it's,</v>

2022
01:30:22.470 --> 01:30:27.470
<v Speaker 1>it's interesting that what drove those </v>
<v Speaker 1>innovations in the support current ai </v>

2023
01:30:27.470 --> 01:30:29.340
<v Speaker 1>was mostly not ai.</v>
<v Speaker 1>It was the video game industry.</v>

2024
01:30:29.660 --> 01:30:33.450
<v Speaker 1>I'm a way when I point to the video game</v>
<v Speaker 1>engine in your head,</v>

2025
01:30:33.510 --> 01:30:38.510
<v Speaker 1>that's a similar thing that was driven </v>
<v Speaker 1>by the video game industry on the </v>

2026
01:30:38.510 --> 01:30:39.180
<v Speaker 1>software side.</v>
<v Speaker 1>I think we should all play as many video</v>

2027
01:30:39.181 --> 01:30:44.181
<v Speaker 1>games as we can and contribute to the </v>
<v Speaker 1>growth of the video game industry </v>

2028
01:30:44.181 --> 01:30:44.430
<v Speaker 1>because.</v>
<v Speaker 1>No,</v>

2029
01:30:44.431 --> 01:30:46.790
<v Speaker 1>because I mean,</v>
<v Speaker 1>I mean you can see this [inaudible] like</v>

2030
01:30:46.980 --> 01:30:48.600
<v Speaker 1>there are companies out there.</v>
<v Speaker 1>For example,</v>

2031
01:30:48.601 --> 01:30:51.780
<v Speaker 1>there's a company called improbable </v>
<v Speaker 1>which is a London company.</v>

2032
01:30:52.150 --> 01:30:55.200
<v Speaker 1>I'm London based startup,</v>
<v Speaker 1>a pretty sizable startup at this point,</v>

2033
01:30:55.410 --> 01:30:58.050
<v Speaker 1>which is building something that they </v>
<v Speaker 1>call spatial Oscp,</v>

2034
01:30:58.260 --> 01:30:59.250
<v Speaker 1>which is a.</v>
<v Speaker 1>it's a,</v>

2035
01:30:59.251 --> 01:31:01.170
<v Speaker 1>it's not a,</v>
<v Speaker 1>it's not a hardware idea,</v>

2036
01:31:01.171 --> 01:31:03.000
<v Speaker 1>but it's a kind of software idea for </v>
<v Speaker 1>very,</v>

2037
01:31:03.001 --> 01:31:06.420
<v Speaker 1>very big distributed computing </v>
<v Speaker 1>environments to run much,</v>

2038
01:31:06.421 --> 01:31:09.000
<v Speaker 1>much more complex,</v>
<v Speaker 1>realistic simulations of the world for a</v>

2039
01:31:09.001 --> 01:31:11.580
<v Speaker 1>much more interesting immersive </v>
<v Speaker 1>permanent video games.</v>

2040
01:31:11.730 --> 01:31:15.390
<v Speaker 1>I think that's one thing that might </v>
<v Speaker 1>hopefully that will lead to more fun new</v>

2041
01:31:15.391 --> 01:31:18.600
<v Speaker 1>kinds of games,</v>
<v Speaker 1>but that's one example of where we might</v>

2042
01:31:18.601 --> 01:31:22.380
<v Speaker 1>look to that industry to drive some of </v>
<v Speaker 1>the computer systems,</v>

2043
01:31:22.381 --> 01:31:26.340
<v Speaker 1>really hardware and software systems </v>
<v Speaker 1>that will take.</v>

2044
01:31:26.370 --> 01:31:28.200
<v Speaker 1>We'll take our game to the next level.</v>

2045
01:31:29.400 --> 01:31:34.400
<v Speaker 7>Just understanding algorithmic level or </v>
<v Speaker 7>cognitive level is just to understanding</v>

2046
01:31:35.041 --> 01:31:40.041
<v Speaker 7>the learning.</v>
<v Speaker 7>The meaning of learning will be hard to </v>

2047
01:31:40.041 --> 01:31:41.931
<v Speaker 7>predict,</v>
<v Speaker 7>but on the circuit level these </v>

2048
01:31:41.931 --> 01:31:44.271
<v Speaker 7>different,</v>
<v Speaker 7>but at the what level under could live </v>

2049
01:31:44.271 --> 01:31:44.271
<v Speaker 7>with.</v>

2050
01:31:44.271 --> 01:31:44.820
<v Speaker 1>Well of course it's different.</v>
<v Speaker 1>Right,</v>

2051
01:31:45.110 --> 01:31:47.600
<v Speaker 1>but already I think you made a mistake </v>
<v Speaker 1>there.</v>

2052
01:31:47.601 --> 01:31:48.860
<v Speaker 1>Honestly,</v>
<v Speaker 1>like you said,</v>

2053
01:31:48.861 --> 01:31:50.480
<v Speaker 1>the cognitive goal is learning how to </v>
<v Speaker 1>predict,</v>

2054
01:31:50.481 --> 01:31:55.481
<v Speaker 1>but I'm not sure what you mean by that.</v>
<v Speaker 1>There's many things you could mean and </v>

2055
01:31:55.481 --> 01:31:56.180
<v Speaker 1>are what our cognitive science is about </v>
<v Speaker 1>is learning which of those versions,</v>

2056
01:31:56.270 --> 01:31:57.830
<v Speaker 1>like I don't think it's learning how to </v>
<v Speaker 1>predict.</v>

2057
01:31:57.831 --> 01:32:01.120
<v Speaker 1>I think it's learning what need to know </v>
<v Speaker 1>to plan actions and to uh,</v>

2058
01:32:01.230 --> 01:32:02.110
<v Speaker 1>you know,</v>
<v Speaker 1>all those things.</v>

2059
01:32:02.111 --> 01:32:07.111
<v Speaker 1>Like it's not just about predicting,</v>
<v Speaker 1>it's because there are things we can </v>

2060
01:32:07.111 --> 01:32:10.201
<v Speaker 1>imagine that you would never predict </v>
<v Speaker 1>because they would never happen unless </v>

2061
01:32:10.201 --> 01:32:11.540
<v Speaker 1>we somehow make the world different </v>
<v Speaker 1>generalizations.</v>

2062
01:32:11.560 --> 01:32:14.170
<v Speaker 1>Sorry,</v>
<v Speaker 1>not when you were methodical journalize,</v>

2063
01:32:14.350 --> 01:32:17.350
<v Speaker 1>but especially in this transfer learning</v>
<v Speaker 1>that you are interested in a few hundred</v>

2064
01:32:17.380 --> 01:32:20.080
<v Speaker 1>neurons in prefrontal cortex.</v>
<v Speaker 1>The generalize a lot.</v>

2065
01:32:20.260 --> 01:32:25.260
<v Speaker 1>Yes,</v>
<v Speaker 1>but not kind of a Bayesian model could </v>

2066
01:32:25.260 --> 01:32:25.260
<v Speaker 1>do that.</v>

2067
01:32:25.670 --> 01:32:28.600
<v Speaker 1>You said,</v>
<v Speaker 1>but lazy and model won't do that or they</v>

2068
01:32:28.601 --> 01:32:30.850
<v Speaker 1>don't do it the way a Bayesian model </v>
<v Speaker 1>does for sure.</v>

2069
01:32:30.851 --> 01:32:33.430
<v Speaker 1>Because that's in the abstract level.</v>
<v Speaker 1>Well,</v>

2070
01:32:33.431 --> 01:32:35.890
<v Speaker 1>I mean,</v>
<v Speaker 1>how do you really know like,</v>

2071
01:32:35.891 --> 01:32:38.000
<v Speaker 1>and what does it mean to say that some </v>
<v Speaker 1>neurons do it like.</v>

2072
01:32:38.140 --> 01:32:40.420
<v Speaker 1>So maybe another way to put this is to </v>
<v Speaker 1>say,</v>

2073
01:32:40.421 --> 01:32:45.421
<v Speaker 1>look,</v>
<v Speaker 1>we have a certain math that we use to </v>

2074
01:32:45.421 --> 01:32:47.521
<v Speaker 1>capture these.</v>
<v Speaker 1>You could call it abstract or I call it </v>

2075
01:32:47.521 --> 01:32:47.521
<v Speaker 1>software level abstractions,</v>
<v Speaker 1>right?</v>

2076
01:32:47.521 --> 01:32:49.810
<v Speaker 1>I mean all engineering is based in some </v>
<v Speaker 1>kind of abstraction,</v>

2077
01:32:50.170 --> 01:32:52.060
<v Speaker 1>but you might have a circuit level </v>
<v Speaker 1>abstraction,</v>

2078
01:32:52.061 --> 01:32:57.061
<v Speaker 1>a certain kind of hardware level that </v>
<v Speaker 1>you're interested in describing the </v>

2079
01:32:57.061 --> 01:32:59.791
<v Speaker 1>brain at and I'm mostly working out or </v>
<v Speaker 1>starting from a more software level of </v>

2080
01:32:59.791 --> 01:32:59.791
<v Speaker 1>abstraction.</v>
<v Speaker 1>Right?</v>

2081
01:32:59.791 --> 01:33:01.360
<v Speaker 1>They're all abstractions.</v>
<v Speaker 1>We're not talking about molecules here.</v>

2082
01:33:01.420 --> 01:33:03.640
<v Speaker 1>Right.</v>
<v Speaker 1>We're talking about some abstract notion</v>

2083
01:33:03.641 --> 01:33:05.800
<v Speaker 1>of maybe a circuit or have a program.</v>

2084
01:33:05.850 --> 01:33:10.850
<v Speaker 1>Okay.</v>
<v Speaker 1>Right now it's a really interesting </v>

2085
01:33:10.850 --> 01:33:10.850
<v Speaker 1>question.</v>
<v Speaker 1>If I look at some circuits,</v>

2086
01:33:10.850 --> 01:33:12.250
<v Speaker 1>how do I know what program they're </v>
<v Speaker 1>implementing?</v>

2087
01:33:12.251 --> 01:33:17.251
<v Speaker 1>Right.</v>
<v Speaker 1>If I look at the circuits and this </v>

2088
01:33:17.251 --> 01:33:18.451
<v Speaker 1>machine,</v>
<v Speaker 1>could I tell what program they </v>

2089
01:33:18.451 --> 01:33:18.451
<v Speaker 1>implementing?</v>
<v Speaker 1>Well,</v>

2090
01:33:18.451 --> 01:33:18.451
<v Speaker 1>maybe,</v>
<v Speaker 1>but certainly it will be a lot easier if</v>

2091
01:33:18.451 --> 01:33:22.801
<v Speaker 1>I knew something about what programs </v>
<v Speaker 1>they might be implementing before I </v>

2092
01:33:22.801 --> 01:33:25.261
<v Speaker 1>start to look at the circuitry.</v>
<v Speaker 1>If I just looked at the circuitry </v>

2093
01:33:25.261 --> 01:33:27.990
<v Speaker 1>without knowing what the program was or </v>
<v Speaker 1>what programs the thing might be doing </v>

2094
01:33:27.990 --> 01:33:31.741
<v Speaker 1>or what kind of programming components </v>
<v Speaker 1>would be mappable two circuits in </v>

2095
01:33:31.741 --> 01:33:32.800
<v Speaker 1>different ways.</v>
<v Speaker 1>Right.</v>

2096
01:33:32.801 --> 01:33:35.020
<v Speaker 1>I don't even know how to begin to answer</v>
<v Speaker 1>that question,</v>

2097
01:33:35.260 --> 01:33:40.260
<v Speaker 1>so I think we've made some progress at </v>
<v Speaker 1>understanding what neurons are doing in </v>

2098
01:33:40.260 --> 01:33:44.971
<v Speaker 1>certain low level parts of sensory </v>
<v Speaker 1>system and certain parts of the motor </v>

2099
01:33:44.971 --> 01:33:44.971
<v Speaker 1>system,</v>
<v Speaker 1>like primary motor cortex,</v>

2100
01:33:44.971 --> 01:33:49.951
<v Speaker 1>like basically the parts of the neurons </v>
<v Speaker 1>that are closest to the inputs and </v>

2101
01:33:49.951 --> 01:33:52.741
<v Speaker 1>outputs of the brain,</v>
<v Speaker 1>right where we don't eat when you can </v>

2102
01:33:52.741 --> 01:33:56.641
<v Speaker 1>say we don't need the kind of software </v>
<v Speaker 1>abstractions that I'm talking about or </v>

2103
01:33:56.641 --> 01:34:00.280
<v Speaker 1>where we sort of agree on what those </v>
<v Speaker 1>things already are so we can make enough</v>

2104
01:34:00.281 --> 01:34:02.500
<v Speaker 1>progress on knowing what to look for and</v>
<v Speaker 1>how to.</v>

2105
01:34:02.560 --> 01:34:07.560
<v Speaker 1>How to know when we found it.</v>
<v Speaker 1>But if you want to talk about flexible </v>

2106
01:34:07.560 --> 01:34:07.560
<v Speaker 1>planning,</v>
<v Speaker 1>things that are more like cognition that</v>

2107
01:34:07.870 --> 01:34:10.120
<v Speaker 1>go on and prefrontal Cortex,</v>
<v Speaker 1>right?</v>

2108
01:34:10.630 --> 01:34:11.710
<v Speaker 1>I,</v>
<v Speaker 1>at this point,</v>

2109
01:34:11.711 --> 01:34:16.711
<v Speaker 1>I don't.</v>
<v Speaker 1>I don't think that just by recording </v>

2110
01:34:16.711 --> 01:34:18.751
<v Speaker 1>from those neurons,</v>
<v Speaker 1>we're going to be able to answer those </v>

2111
01:34:18.751 --> 01:34:18.751
<v Speaker 1>questions in a meaningful engineering </v>
<v Speaker 1>way.</v>

2112
01:34:18.751 --> 01:34:20.260
<v Speaker 1>A way that that any engineer,</v>
<v Speaker 1>software,</v>

2113
01:34:20.261 --> 01:34:21.220
<v Speaker 1>hardware,</v>
<v Speaker 1>whatever,</v>

2114
01:34:21.400 --> 01:34:22.150
<v Speaker 1>could really say,</v>
<v Speaker 1>yeah,</v>

2115
01:34:22.151 --> 01:34:22.840
<v Speaker 1>okay,</v>
<v Speaker 1>I get it.</v>

2116
01:34:22.841 --> 01:34:27.841
<v Speaker 1>I get those insights in a way that I can</v>
<v Speaker 1>engineer with and that's what my goal </v>

2117
01:34:27.841 --> 01:34:27.841
<v Speaker 1>is,</v>
<v Speaker 1>right?</v>

2118
01:34:27.841 --> 01:34:31.680
<v Speaker 1>So my goal,</v>
<v Speaker 1>that's my goal to do at the software </v>

2119
01:34:31.680 --> 01:34:31.680
<v Speaker 1>level,</v>
<v Speaker 1>the hardware level or the entire systems</v>

2120
01:34:31.680 --> 01:34:32.830
<v Speaker 1>level,</v>
<v Speaker 1>connecting them and I think that,</v>

2121
01:34:32.920 --> 01:34:37.920
<v Speaker 1>you know,</v>
<v Speaker 1>we can do that by taking what we're </v>

2122
01:34:37.920 --> 01:34:37.920
<v Speaker 1>doing and bringing into contact with </v>
<v Speaker 1>people studying neural circuits,</v>

2123
01:34:37.920 --> 01:34:40.360
<v Speaker 1>but I don't think you can,</v>
<v Speaker 1>you can leave this level out and just go</v>

2124
01:34:40.361 --> 01:34:42.360
<v Speaker 1>straight to the neural circuits and I </v>
<v Speaker 1>think the more you have,</v>

2125
01:34:42.430 --> 01:34:47.430
<v Speaker 1>the more progress we make,</v>
<v Speaker 1>the more we can help people who are </v>

2126
01:34:47.430 --> 01:34:50.580
<v Speaker 1>studying at the neuro circuit level and </v>
<v Speaker 1>they can help us address these other </v>

2127
01:34:50.580 --> 01:34:53.761
<v Speaker 1>engineering questions that we don't </v>
<v Speaker 1>really have access to like the power </v>

2128
01:34:53.761 --> 01:34:53.761
<v Speaker 1>issue or the speed issue.</v>

2129
01:34:53.761 --> 01:34:54.370
<v Speaker 1>Okay.</v>
<v Speaker 1>Thanks.</v>

2130
01:34:54.520 --> 01:34:57.030
<v Speaker 1>That was great.</v>
<v Speaker 1>Maybe give Janssen again</v>

2131
01:34:57.070 --> 01:35:02.070
<v Speaker 2>man.</v>
<v Speaker 2>Thanks.</v>

