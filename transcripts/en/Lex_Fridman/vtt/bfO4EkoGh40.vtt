WEBVTT

1
00:00:00.030 --> 00:00:05.030
<v Speaker 1>So today we have Nader Bensky,</v>
<v Speaker 1>he's a professor at northeastern </v>

2
00:00:05.030 --> 00:00:09.561
<v Speaker 1>university working on various aspects of</v>
<v Speaker 1>computational agents that exhibit human </v>

3
00:00:10.201 --> 00:00:13.200
<v Speaker 1>level intelligence.</v>
<v Speaker 1>Please give a warm welcome.</v>

4
00:00:18.630 --> 00:00:20.640
<v Speaker 1>Thanks a lot.</v>
<v Speaker 1>Thanks for having me here.</v>

5
00:00:20.800 --> 00:00:24.980
<v Speaker 1>So the title that was on the page was a </v>
<v Speaker 1>cognitive modeling.</v>

6
00:00:25.730 --> 00:00:28.220
<v Speaker 1>I'll kind of get there,</v>
<v Speaker 1>but I wanted to put it in context.</v>

7
00:00:28.250 --> 00:00:33.250
<v Speaker 1>So the bigger theme here is I want to </v>
<v Speaker 1>talk about what's called cognitive </v>

8
00:00:33.250 --> 00:00:34.430
<v Speaker 1>architecture and if you've never heard </v>
<v Speaker 1>about that before,</v>

9
00:00:34.460 --> 00:00:39.460
<v Speaker 1>that's great.</v>
<v Speaker 1>And I wanted to contextualize that as </v>

10
00:00:39.460 --> 00:00:42.760
<v Speaker 1>how are we what,</v>
<v Speaker 1>how is that one approach to get us to </v>

11
00:00:42.760 --> 00:00:46.150
<v Speaker 1>Agi and I say what my view of Agi is and</v>
<v Speaker 1>put up a whole bunch of TV and movie </v>

12
00:00:49.561 --> 00:00:51.990
<v Speaker 1>characters that I grew up with that </v>
<v Speaker 1>inspire me.</v>

13
00:00:52.520 --> 00:00:55.320
<v Speaker 1>That'll lead us into what is this thing </v>
<v Speaker 1>called cognitive architecture.</v>

14
00:00:55.321 --> 00:00:58.740
<v Speaker 1>It's a whole research field that crosses</v>
<v Speaker 1>neuroscience,</v>

15
00:00:58.741 --> 00:01:00.720
<v Speaker 1>psychology,</v>
<v Speaker 1>cognitive science,</v>

16
00:01:00.780 --> 00:01:05.780
<v Speaker 1>and all the way into Ai.</v>
<v Speaker 1>So I'll try to give you kind of the </v>

17
00:01:05.780 --> 00:01:08.631
<v Speaker 1>historical big picture view of it,</v>
<v Speaker 1>what some of the actual systems are out </v>

18
00:01:08.631 --> 00:01:09.690
<v Speaker 1>there that might be of interest to you.</v>

19
00:01:09.960 --> 00:01:14.960
<v Speaker 1>And then we'll kind of zoom in on one of</v>
<v Speaker 1>them that I've done a good amount of </v>

20
00:01:14.960 --> 00:01:17.460
<v Speaker 1>work with called soar.</v>
<v Speaker 1>And what I'll try to do is tell a story,</v>

21
00:01:17.610 --> 00:01:22.610
<v Speaker 1>a research story of how we started with </v>
<v Speaker 1>kind of a core research question we look</v>

22
00:01:23.071 --> 00:01:28.071
<v Speaker 1>to how humans operate,</v>
<v Speaker 1>understood that phenomenon and then took</v>

23
00:01:29.161 --> 00:01:31.320
<v Speaker 1>it and saw a really interesting results </v>
<v Speaker 1>from it.</v>

24
00:01:31.380 --> 00:01:34.230
<v Speaker 1>And so at the end,</v>
<v Speaker 1>if this field is of interest,</v>

25
00:01:34.231 --> 00:01:39.231
<v Speaker 1>there's a few pointers for you to go </v>
<v Speaker 1>read more and go experience more of </v>

26
00:01:39.231 --> 00:01:43.250
<v Speaker 1>cognitive architecture.</v>
<v Speaker 1>So just rough definition of agi given us</v>

27
00:01:44.971 --> 00:01:49.971
<v Speaker 1>an Agi class,</v>
<v Speaker 1>depending on the direction that you're </v>

28
00:01:49.971 --> 00:01:53.541
<v Speaker 1>coming from,</v>
<v Speaker 1>it might be kind of understanding </v>

29
00:01:53.541 --> 00:01:56.150
<v Speaker 1>intelligence or maybe developing a </v>
<v Speaker 1>intelligent systems that are operating </v>

30
00:01:56.150 --> 00:01:57.030
<v Speaker 1>at the level of human level </v>
<v Speaker 1>intelligence,</v>

31
00:01:57.430 --> 00:02:00.930
<v Speaker 1>the,</v>
<v Speaker 1>the typical differences between this and</v>

32
00:02:00.931 --> 00:02:03.750
<v Speaker 1>other sorts of maybe ai machine learning</v>
<v Speaker 1>systems.</v>

33
00:02:03.750 --> 00:02:07.320
<v Speaker 1>We want systems that are going to </v>
<v Speaker 1>persist for a long period of time.</v>

34
00:02:07.660 --> 00:02:12.660
<v Speaker 1>Uh,</v>
<v Speaker 1>we want them robust to different </v>

35
00:02:12.660 --> 00:02:12.660
<v Speaker 1>conditions.</v>
<v Speaker 1>We want them learning over time.</v>

36
00:02:12.660 --> 00:02:17.540
<v Speaker 1>And here's the crux of it.</v>
<v Speaker 1>Working on different tasks and a lot of </v>

37
00:02:17.540 --> 00:02:22.191
<v Speaker 1>cases,</v>
<v Speaker 1>task they didn't know were coming ahead </v>

38
00:02:22.191 --> 00:02:22.191
<v Speaker 1>of time.</v>
<v Speaker 1>Uh,</v>

39
00:02:22.191 --> 00:02:26.540
<v Speaker 1>I got into this because I clearly </v>
<v Speaker 1>watched too much TV and too many movies </v>

40
00:02:26.650 --> 00:02:28.380
<v Speaker 1>and,</v>
<v Speaker 1>and I looked back at this and I realized</v>

41
00:02:28.381 --> 00:02:31.110
<v Speaker 1>I think I'm covering seventies,</v>
<v Speaker 1>eighties,</v>

42
00:02:31.230 --> 00:02:34.080
<v Speaker 1>nineties,</v>
<v Speaker 1>I guess it is.</v>

43
00:02:34.140 --> 00:02:39.140
<v Speaker 1>And today,</v>
<v Speaker 1>and so this is what I wanted out of ai </v>

44
00:02:39.140 --> 00:02:43.741
<v Speaker 1>and this is what I wanted to work with.</v>
<v Speaker 1>And then there's the reality that we </v>

45
00:02:43.931 --> 00:02:47.470
<v Speaker 1>have today.</v>
<v Speaker 1>So instead of,</v>

46
00:02:47.530 --> 00:02:50.170
<v Speaker 1>so who's watched a night writer for </v>
<v Speaker 1>instance?</v>

47
00:02:50.590 --> 00:02:51.140
<v Speaker 1>Uh,</v>
<v Speaker 1>I,</v>

48
00:02:51.141 --> 00:02:54.200
<v Speaker 1>I don't think that exists yet.</v>
<v Speaker 1>Uh,</v>

49
00:02:54.470 --> 00:02:59.470
<v Speaker 1>but,</v>
<v Speaker 1>but maybe we're getting there and in </v>

50
00:02:59.470 --> 00:03:01.180
<v Speaker 1>particular for fun,</v>
<v Speaker 1>during the Amazon Sale Day,</v>

51
00:03:01.240 --> 00:03:04.960
<v Speaker 1>I got myself an Alexa and I could just </v>
<v Speaker 1>see myself at some point saying,</v>

52
00:03:05.210 --> 00:03:07.760
<v Speaker 1>Hey Alexa,</v>
<v Speaker 1>please might write me an arcing script,</v>

53
00:03:08.110 --> 00:03:08.840
<v Speaker 1>uh,</v>
<v Speaker 1>you know,</v>

54
00:03:08.841 --> 00:03:10.270
<v Speaker 1>to,</v>
<v Speaker 1>to sync my class.</v>

55
00:03:10.480 --> 00:03:13.330
<v Speaker 1>And if you have an Alexa,</v>
<v Speaker 1>you probably know the following phrase.</v>

56
00:03:13.331 --> 00:03:15.220
<v Speaker 1>This,</v>
<v Speaker 1>this just always hurts me inside.</v>

57
00:03:15.370 --> 00:03:16.690
<v Speaker 1>Which is.</v>
<v Speaker 1>Sorry,</v>

58
00:03:16.990 --> 00:03:20.110
<v Speaker 1>I don't know that one,</v>
<v Speaker 1>which is okay.</v>

59
00:03:20.111 --> 00:03:22.930
<v Speaker 1>Right?</v>
<v Speaker 1>That's a lot of people have no idea what</v>

60
00:03:22.931 --> 00:03:24.610
<v Speaker 1>I'm asking,</v>
<v Speaker 1>let alone how to do that.</v>

61
00:03:24.730 --> 00:03:28.240
<v Speaker 1>So what I want Alexa to respond with </v>
<v Speaker 1>after that is,</v>

62
00:03:28.660 --> 00:03:30.920
<v Speaker 1>do you have time to teach me,</v>
<v Speaker 1>uh,</v>

63
00:03:31.480 --> 00:03:35.440
<v Speaker 1>and to provide some sort of interface by</v>
<v Speaker 1>which back and forth we can kind of talk</v>

64
00:03:35.441 --> 00:03:36.760
<v Speaker 1>through this,</v>
<v Speaker 1>uh,</v>

65
00:03:36.761 --> 00:03:39.370
<v Speaker 1>that we,</v>
<v Speaker 1>we aren't there yet to say the least,</v>

66
00:03:39.371 --> 00:03:44.371
<v Speaker 1>but I'll talk later about some work on a</v>
<v Speaker 1>system called Rosie that's working in </v>

67
00:03:45.581 --> 00:03:47.200
<v Speaker 1>that direction.</v>
<v Speaker 1>We're starting to see,</v>

68
00:03:47.230 --> 00:03:50.980
<v Speaker 1>see some ideas about being able to teach</v>
<v Speaker 1>systems how to work.</v>

69
00:03:52.810 --> 00:03:54.780
<v Speaker 1>So folks who are in this field,</v>
<v Speaker 1>uh,</v>

70
00:03:54.790 --> 00:03:58.180
<v Speaker 1>I think generally fall into these three </v>
<v Speaker 1>categories.</v>

71
00:03:58.690 --> 00:04:01.510
<v Speaker 1>They're just curious.</v>
<v Speaker 1>They want to learn new things,</v>

72
00:04:01.511 --> 00:04:03.550
<v Speaker 1>generate knowledge,</v>
<v Speaker 1>work on hard problems.</v>

73
00:04:04.090 --> 00:04:05.320
<v Speaker 1>Great.</v>
<v Speaker 1>Uh,</v>

74
00:04:05.321 --> 00:04:09.490
<v Speaker 1>I think there are folks who are in kind </v>
<v Speaker 1>of that mental cognitive modeling realm.</v>

75
00:04:09.900 --> 00:04:14.900
<v Speaker 1>And so I'll use this term a lot.</v>
<v Speaker 1>It's really understanding how humans </v>

76
00:04:14.900 --> 00:04:17.770
<v Speaker 1>think,</v>
<v Speaker 1>how humans operate human intelligence at</v>

77
00:04:17.771 --> 00:04:20.980
<v Speaker 1>multiple levels.</v>
<v Speaker 1>And if you can do that one,</v>

78
00:04:20.981 --> 00:04:23.830
<v Speaker 1>there's just knowledge in and of itself </v>
<v Speaker 1>of how we operate.</v>

79
00:04:23.831 --> 00:04:27.370
<v Speaker 1>But there's a lot of really important </v>
<v Speaker 1>applications that you can think of if we</v>

80
00:04:27.371 --> 00:04:32.371
<v Speaker 1>were able to not only understand but </v>
<v Speaker 1>predict how humans would respond,</v>

81
00:04:32.861 --> 00:04:37.330
<v Speaker 1>react and various tasks.</v>
<v Speaker 1>Medicine is an easy one.</v>

82
00:04:37.900 --> 00:04:41.730
<v Speaker 1>There's some work in HCI or Hri.</v>
<v Speaker 1>Uh,</v>

83
00:04:41.740 --> 00:04:46.740
<v Speaker 1>I'll get to later where if you can </v>
<v Speaker 1>predict how humans would respond to it </v>

84
00:04:46.740 --> 00:04:49.600
<v Speaker 1>as you can iterate tightly and develop </v>
<v Speaker 1>better interfaces.</v>

85
00:04:49.760 --> 00:04:54.760
<v Speaker 1>Uh,</v>
<v Speaker 1>it's already being used in the realm of </v>

86
00:04:54.760 --> 00:04:54.970
<v Speaker 1>simulation and defense industries.</v>
<v Speaker 1>Um,</v>

87
00:04:55.120 --> 00:04:58.780
<v Speaker 1>I happen to fall into the latter group </v>
<v Speaker 1>which are the bottom group,</v>

88
00:04:58.781 --> 00:05:02.440
<v Speaker 1>which is systems development,</v>
<v Speaker 1>which is to say just the desire to build</v>

89
00:05:02.441 --> 00:05:07.441
<v Speaker 1>systems for various tasks that are </v>
<v Speaker 1>working on tasks that kind of current </v>

90
00:05:07.441 --> 00:05:09.130
<v Speaker 1>ai,</v>
<v Speaker 1>machine learning can't operate on.</v>

91
00:05:09.760 --> 00:05:11.150
<v Speaker 1>And I think,</v>
<v Speaker 1>uh,</v>

92
00:05:11.180 --> 00:05:16.180
<v Speaker 1>when you're working at this level or on </v>
<v Speaker 1>any system that nobody's really achieved</v>

93
00:05:16.331 --> 00:05:16.840
<v Speaker 1>before,</v>
<v Speaker 1>what do you,</v>

94
00:05:16.841 --> 00:05:21.841
<v Speaker 1>do you,</v>
<v Speaker 1>you kind of look to the examples that </v>

95
00:05:21.841 --> 00:05:21.850
<v Speaker 1>you have,</v>
<v Speaker 1>which in this case that we know of,</v>

96
00:05:21.880 --> 00:05:23.300
<v Speaker 1>it's just humans,</v>
<v Speaker 1>right?</v>

97
00:05:25.720 --> 00:05:30.720
<v Speaker 1>Irrespective of your motivation,</v>
<v Speaker 1>when you have kind of an intent that you</v>

98
00:05:31.661 --> 00:05:36.661
<v Speaker 1>want to achieve in your research,</v>
<v Speaker 1>you kind of let that drive your </v>

99
00:05:36.661 --> 00:05:38.140
<v Speaker 1>approach.</v>
<v Speaker 1>And so I often show my students this,</v>

100
00:05:39.460 --> 00:05:44.460
<v Speaker 1>the turing test,</v>
<v Speaker 1>you might've heard of a or variants of </v>

101
00:05:44.460 --> 00:05:48.211
<v Speaker 1>it that have come before.</v>
<v Speaker 1>These were folks who were trying to </v>

102
00:05:48.211 --> 00:05:51.150
<v Speaker 1>create systems that acted in a certain </v>
<v Speaker 1>way that acted intelligently and the </v>

103
00:05:51.150 --> 00:05:53.980
<v Speaker 1>kind of line that they drew,</v>
<v Speaker 1>the benchmark that they used was to say,</v>

104
00:05:54.160 --> 00:05:56.830
<v Speaker 1>let's make systems that operate like </v>
<v Speaker 1>humans do.</v>

105
00:05:58.370 --> 00:06:03.110
<v Speaker 1>Cognitive modelers will fit up into his </v>
<v Speaker 1>top point here to say it's not enough to</v>

106
00:06:03.170 --> 00:06:06.710
<v Speaker 1>act that way,</v>
<v Speaker 1>but by some definition of thinking,</v>

107
00:06:07.160 --> 00:06:12.160
<v Speaker 1>uh,</v>
<v Speaker 1>we want the system to do what humans do </v>

108
00:06:12.160 --> 00:06:12.920
<v Speaker 1>or at least be able to make predictions </v>
<v Speaker 1>about it.</v>

109
00:06:12.921 --> 00:06:16.790
<v Speaker 1>So that might be things like what errors</v>
<v Speaker 1>with the human make on this task,</v>

110
00:06:16.970 --> 00:06:19.400
<v Speaker 1>or how long would it take them to </v>
<v Speaker 1>perform this task?</v>

111
00:06:19.730 --> 00:06:22.580
<v Speaker 1>Or what emotion would be produced in </v>
<v Speaker 1>this task?</v>

112
00:06:23.930 --> 00:06:27.710
<v Speaker 1>There are folks who are still thinking </v>
<v Speaker 1>about how the computer is operating,</v>

113
00:06:28.040 --> 00:06:32.540
<v Speaker 1>but trying to apply a kind of rational </v>
<v Speaker 1>rules to it.</v>

114
00:06:32.541 --> 00:06:37.541
<v Speaker 1>So a logician for instance,</v>
<v Speaker 1>would say if you have a and you have be </v>

115
00:06:37.800 --> 00:06:42.800
<v Speaker 1>a gives you,</v>
<v Speaker 1>he gives you ca should definitely give </v>

116
00:06:42.800 --> 00:06:42.800
<v Speaker 1>you see,</v>
<v Speaker 1>that's just what's rational.</v>

117
00:06:42.800 --> 00:06:47.530
<v Speaker 1>And so there folks operating in that </v>
<v Speaker 1>direction and then if you go to a intro </v>

118
00:06:47.530 --> 00:06:50.120
<v Speaker 1>ai class anywhere around the country,</v>
<v Speaker 1>particularly Berkeley,</v>

119
00:06:50.121 --> 00:06:53.180
<v Speaker 1>because they have graphics designers </v>
<v Speaker 1>that I get to steal from,</v>

120
00:06:54.100 --> 00:06:59.100
<v Speaker 1>the benchmark would be what the system </v>
<v Speaker 1>produces in terms of action and the </v>

121
00:07:00.201 --> 00:07:05.201
<v Speaker 1>benchmark is some sort of optimal </v>
<v Speaker 1>rational bound irrespective of where you</v>

122
00:07:05.901 --> 00:07:07.540
<v Speaker 1>work in this space.</v>
<v Speaker 1>Uh,</v>

123
00:07:07.890 --> 00:07:12.890
<v Speaker 1>there,</v>
<v Speaker 1>there's kind of a common output that </v>

124
00:07:12.890 --> 00:07:16.420
<v Speaker 1>arrives when you research these areas,</v>
<v Speaker 1>which is you can learn individual bits </v>

125
00:07:16.420 --> 00:07:21.341
<v Speaker 1>and pieces and it can be hard to bring </v>
<v Speaker 1>them together to build a system that </v>

126
00:07:21.951 --> 00:07:24.950
<v Speaker 1>either predicts or act on,</v>
<v Speaker 1>on different tasks.</v>

127
00:07:24.950 --> 00:07:26.990
<v Speaker 1>So this is part of the transfer learning</v>
<v Speaker 1>problem,</v>

128
00:07:26.991 --> 00:07:31.991
<v Speaker 1>but it's also part of a having distinct </v>
<v Speaker 1>theories that are hard to combine </v>

129
00:07:31.991 --> 00:07:33.550
<v Speaker 1>together.</v>
<v Speaker 1>So I'm going to give an example and that</v>

130
00:07:33.560 --> 00:07:37.010
<v Speaker 1>come comes out of cognitive modeling or </v>
<v Speaker 1>perhaps three examples.</v>

131
00:07:38.120 --> 00:07:41.900
<v Speaker 1>So if you were in a HCI class or some </v>
<v Speaker 1>interest psychology classes,</v>

132
00:07:42.530 --> 00:07:44.840
<v Speaker 1>one of the first things you'll learn </v>
<v Speaker 1>about his fits law,</v>

133
00:07:45.290 --> 00:07:50.290
<v Speaker 1>which provides you the ability to </v>
<v Speaker 1>predict the difficulty level of </v>

134
00:07:51.440 --> 00:07:56.240
<v Speaker 1>basically human pointing from where they</v>
<v Speaker 1>start to a particular place and it turns</v>

135
00:07:56.241 --> 00:08:01.241
<v Speaker 1>out that you can learn some parameters </v>
<v Speaker 1>and model this based upon just the </v>

136
00:08:01.400 --> 00:08:05.270
<v Speaker 1>distance from where you are to the </v>
<v Speaker 1>target and the size of the target.</v>

137
00:08:05.990 --> 00:08:08.320
<v Speaker 1>So both moving along distance will take </v>
<v Speaker 1>awhile.</v>

138
00:08:08.450 --> 00:08:12.260
<v Speaker 1>But also if you're aiming for a very </v>
<v Speaker 1>small point that can take longer than if</v>

139
00:08:12.261 --> 00:08:15.140
<v Speaker 1>there's a large area that you just kinda</v>
<v Speaker 1>have to get yourself to.</v>

140
00:08:15.590 --> 00:08:18.770
<v Speaker 1>And so this has held true for many </v>
<v Speaker 1>humans.</v>

141
00:08:19.040 --> 00:08:24.040
<v Speaker 1>So let's say we've learned this and then</v>
<v Speaker 1>we move onto the next task and we </v>

142
00:08:24.040 --> 00:08:26.360
<v Speaker 1>learned about what's called the power </v>
<v Speaker 1>law of practice,</v>

143
00:08:26.570 --> 00:08:30.530
<v Speaker 1>which has been shown true in a number of</v>
<v Speaker 1>different tasks.</v>

144
00:08:30.620 --> 00:08:35.620
<v Speaker 1>What I'm showing here is one of them </v>
<v Speaker 1>where you're going to draw a line </v>

145
00:08:35.620 --> 00:08:37.370
<v Speaker 1>through sequential set of circles here,</v>
<v Speaker 1>starting at one,</v>

146
00:08:37.371 --> 00:08:42.371
<v Speaker 1>going to two and so forth.</v>
<v Speaker 1>Not Making a mistake or at least not </v>

147
00:08:42.371 --> 00:08:44.420
<v Speaker 1>trying to.</v>
<v Speaker 1>And try to do this as fast as possible.</v>

148
00:08:45.440 --> 00:08:49.460
<v Speaker 1>And so for a particular person,</v>
<v Speaker 1>we would fit the AB and c parameters and</v>

149
00:08:49.461 --> 00:08:53.210
<v Speaker 1>we'd see a power law.</v>
<v Speaker 1>So as you perform this task more,</v>

150
00:08:53.211 --> 00:08:58.211
<v Speaker 1>you're going to see a,</v>
<v Speaker 1>a decrease in the amount of reaction </v>

151
00:08:58.211 --> 00:08:59.550
<v Speaker 1>time required to complete the task.</v>
<v Speaker 1>Great.</v>

152
00:08:59.551 --> 00:09:02.880
<v Speaker 1>We've learned two things about humans.</v>
<v Speaker 1>Let's add some more in.</v>

153
00:09:03.150 --> 00:09:03.960
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

154
00:09:03.990 --> 00:09:05.910
<v Speaker 1>for those who might've done some </v>
<v Speaker 1>reinforcement learning,</v>

155
00:09:05.911 --> 00:09:10.911
<v Speaker 1>the learning is one of those approaches,</v>
<v Speaker 1>a temporal difference learning that's </v>

156
00:09:10.911 --> 00:09:15.740
<v Speaker 1>had some evidence of similar sorts of </v>
<v Speaker 1>processes and the dopamine centers of </v>

157
00:09:16.141 --> 00:09:21.141
<v Speaker 1>the brain.</v>
<v Speaker 1>And it basically says in a sequential </v>

158
00:09:21.141 --> 00:09:21.600
<v Speaker 1>learning task,</v>
<v Speaker 1>you perform the task,</v>

159
00:09:21.601 --> 00:09:24.990
<v Speaker 1>you get some sort of reward.</v>
<v Speaker 1>How are you going to kind of update your</v>

160
00:09:24.991 --> 00:09:26.750
<v Speaker 1>representation of what to do in the </v>
<v Speaker 1>future,</v>

161
00:09:26.760 --> 00:09:29.610
<v Speaker 1>such as to maximize expectation of </v>
<v Speaker 1>future reward.</v>

162
00:09:29.850 --> 00:09:33.030
<v Speaker 1>And there are various models of how that</v>
<v Speaker 1>changes over time.</v>

163
00:09:33.150 --> 00:09:38.150
<v Speaker 1>And you can build up functions that </v>
<v Speaker 1>allow you to form better and better and </v>

164
00:09:38.150 --> 00:09:38.970
<v Speaker 1>better given trial and error.</v>
<v Speaker 1>Great.</v>

165
00:09:39.270 --> 00:09:44.270
<v Speaker 1>So we've learned three interesting </v>
<v Speaker 1>models here that hold true over multiple</v>

166
00:09:45.870 --> 00:09:47.280
<v Speaker 1>people,</v>
<v Speaker 1>multiple tasks.</v>

167
00:09:47.490 --> 00:09:52.490
<v Speaker 1>And so my question is,</v>
<v Speaker 1>if we take these together and add them </v>

168
00:09:52.490 --> 00:09:52.560
<v Speaker 1>together,</v>
<v Speaker 1>uh,</v>

169
00:09:52.890 --> 00:09:57.890
<v Speaker 1>how do we start to understand a task as </v>
<v Speaker 1>quote unquote simple as chess,</v>

170
00:09:58.290 --> 00:10:01.050
<v Speaker 1>which is to say we could ask questions,</v>
<v Speaker 1>how,</v>

171
00:10:01.180 --> 00:10:04.600
<v Speaker 1>how long would it take for a person to </v>
<v Speaker 1>play a,</v>

172
00:10:04.680 --> 00:10:08.250
<v Speaker 1>what mistakes would they make after they</v>
<v Speaker 1>played a few games?</v>

173
00:10:08.340 --> 00:10:13.340
<v Speaker 1>How will they adapt themselves or if we </v>
<v Speaker 1>want to develop system that ended up </v>

174
00:10:13.340 --> 00:10:16.470
<v Speaker 1>being good at chess or at least learning</v>
<v Speaker 1>to become better at chess.</v>

175
00:10:16.920 --> 00:10:18.060
<v Speaker 1>My question is,</v>
<v Speaker 1>if you could,</v>

176
00:10:19.120 --> 00:10:22.770
<v Speaker 1>there doesn't seem to be a clear way to </v>
<v Speaker 1>take these very,</v>

177
00:10:22.771 --> 00:10:26.880
<v Speaker 1>very individual theories and kind of </v>
<v Speaker 1>smash them together and get a reasonable</v>

178
00:10:26.881 --> 00:10:30.690
<v Speaker 1>answer of how to play chess or how do </v>
<v Speaker 1>humans play chess?</v>

179
00:10:32.570 --> 00:10:37.230
<v Speaker 1>And so a gentleman in this slide is </v>
<v Speaker 1>Allan Newell,</v>

180
00:10:37.231 --> 00:10:42.231
<v Speaker 1>one of the founders of ai did incredible</v>
<v Speaker 1>work in psychology and other fields.</v>

181
00:10:43.500 --> 00:10:48.500
<v Speaker 1>Uh,</v>
<v Speaker 1>he gave a series of lectures at Harvard </v>

182
00:10:48.500 --> 00:10:51.021
<v Speaker 1>in 1987 and they were published in 1990 </v>
<v Speaker 1>called the unified theories of </v>

183
00:10:51.021 --> 00:10:55.431
<v Speaker 1>cognition.</v>
<v Speaker 1>And his argument to the psychology </v>

184
00:10:55.431 --> 00:10:56.730
<v Speaker 1>community at that point was the argument</v>
<v Speaker 1>on the prior slide.</v>

185
00:10:56.910 --> 00:11:00.570
<v Speaker 1>They had many individual studies,</v>
<v Speaker 1>many individual results,</v>

186
00:11:00.900 --> 00:11:05.900
<v Speaker 1>and so the question was how do you bring</v>
<v Speaker 1>them together to gain this overall </v>

187
00:11:05.900 --> 00:11:06.660
<v Speaker 1>theory,</v>
<v Speaker 1>how do you make forward progress?</v>

188
00:11:07.050 --> 00:11:10.050
<v Speaker 1>And so his proposal was unified theories</v>
<v Speaker 1>of cognition.</v>

189
00:11:10.380 --> 00:11:13.560
<v Speaker 1>She became known as cognitive </v>
<v Speaker 1>architecture,</v>

190
00:11:13.920 --> 00:11:18.920
<v Speaker 1>which is to say,</v>
<v Speaker 1>to bring together your core assumptions,</v>

191
00:11:19.381 --> 00:11:24.381
<v Speaker 1>your core beliefs of what are the fixed </v>
<v Speaker 1>mechanisms and processes that </v>

192
00:11:24.990 --> 00:11:27.540
<v Speaker 1>intelligent agents would use across </v>
<v Speaker 1>tasks.</v>

193
00:11:27.660 --> 00:11:30.450
<v Speaker 1>So the representations,</v>
<v Speaker 1>the learning mechanisms,</v>

194
00:11:30.710 --> 00:11:33.120
<v Speaker 1>um,</v>
<v Speaker 1>the memory systems,</v>

195
00:11:33.690 --> 00:11:38.690
<v Speaker 1>bring them together,</v>
<v Speaker 1>implement them in a theory and use that </v>

196
00:11:38.690 --> 00:11:42.201
<v Speaker 1>across tasks.</v>
<v Speaker 1>And the core idea is that when you </v>

197
00:11:42.201 --> 00:11:45.651
<v Speaker 1>actually have to implement this and see </v>
<v Speaker 1>how it's going to work across different </v>

198
00:11:45.651 --> 00:11:48.861
<v Speaker 1>tasks,</v>
<v Speaker 1>the interconnections between these </v>

199
00:11:48.861 --> 00:11:48.861
<v Speaker 1>different,</v>
<v Speaker 1>uh,</v>

200
00:11:48.861 --> 00:11:52.610
<v Speaker 1>processes and representations would add </v>
<v Speaker 1>constraints and overtime the constraints</v>

201
00:11:53.261 --> 00:11:58.261
<v Speaker 1>would start limiting the design space of</v>
<v Speaker 1>what is necessary and what is possible </v>

202
00:11:58.261 --> 00:11:59.320
<v Speaker 1>in terms of building intelligent </v>
<v Speaker 1>systems.</v>

203
00:11:59.620 --> 00:12:04.620
<v Speaker 1>And so the overall goal from there was </v>
<v Speaker 1>to understand and exhibit a human level </v>

204
00:12:04.620 --> 00:12:06.090
<v Speaker 1>intelligence using these cognitive </v>
<v Speaker 1>architectures.</v>

205
00:12:09.920 --> 00:12:12.130
<v Speaker 1>A natural question to ask is,</v>
<v Speaker 1>okay,</v>

206
00:12:12.131 --> 00:12:17.131
<v Speaker 1>so we've gone from a methodology of </v>
<v Speaker 1>science that we understand how to </v>

207
00:12:17.321 --> 00:12:20.380
<v Speaker 1>operate in a.</v>
<v Speaker 1>We make a hypothesis,</v>

208
00:12:20.410 --> 00:12:24.040
<v Speaker 1>we construct a study,</v>
<v Speaker 1>we gather our data,</v>

209
00:12:24.250 --> 00:12:29.250
<v Speaker 1>we evaluate that data and we false fire.</v>
<v Speaker 1>We do not falsify the original </v>

210
00:12:29.250 --> 00:12:31.870
<v Speaker 1>hypothesis and we can do that over and </v>
<v Speaker 1>over again and we know that we're making</v>

211
00:12:31.900 --> 00:12:35.760
<v Speaker 1>forward progress scientifically.</v>
<v Speaker 1>If I've now taken that model and changed</v>

212
00:12:35.761 --> 00:12:40.761
<v Speaker 1>it into I have a piece of software and </v>
<v Speaker 1>it's representing my theories and to </v>

213
00:12:42.341 --> 00:12:47.341
<v Speaker 1>some extent I can configure that </v>
<v Speaker 1>software in different ways to work on </v>

214
00:12:47.341 --> 00:12:48.190
<v Speaker 1>different tasks.</v>
<v Speaker 1>How do I know that I'm making progress?</v>

215
00:12:48.640 --> 00:12:53.640
<v Speaker 1>And so there's a form of science called </v>
<v Speaker 1>lactose iom and it's kind of shown </v>

216
00:12:55.331 --> 00:13:00.331
<v Speaker 1>pictorially here where you start with </v>
<v Speaker 1>your core of what your beliefs are </v>

217
00:13:00.880 --> 00:13:02.110
<v Speaker 1>about,</v>
<v Speaker 1>uh,</v>

218
00:13:02.830 --> 00:13:06.310
<v Speaker 1>where you're headed,</v>
<v Speaker 1>what is necessary for achieving the goal</v>

219
00:13:06.311 --> 00:13:06.940
<v Speaker 1>that you have.</v>

220
00:13:07.060 --> 00:13:12.060
<v Speaker 1>And around that you'll have kind of </v>
<v Speaker 1>ephemeral hypotheses and assumptions </v>

221
00:13:12.060 --> 00:13:16.261
<v Speaker 1>that over time may grow and shrink.</v>
<v Speaker 1>And so you're trying out different </v>

222
00:13:16.261 --> 00:13:16.261
<v Speaker 1>things,</v>
<v Speaker 1>trying out different things.</v>

223
00:13:16.420 --> 00:13:18.550
<v Speaker 1>And if an assumption is around there </v>
<v Speaker 1>long enough,</v>

224
00:13:19.060 --> 00:13:24.060
<v Speaker 1>it becomes part of that core.</v>
<v Speaker 1>And so as you work on more task and </v>

225
00:13:24.060 --> 00:13:26.620
<v Speaker 1>learn more,</v>
<v Speaker 1>either by your work or by data coming in</v>

226
00:13:26.621 --> 00:13:29.800
<v Speaker 1>from when someone else,</v>
<v Speaker 1>the core is growing larger and larger,</v>

227
00:13:30.430 --> 00:13:33.010
<v Speaker 1>you've got more constraints and you've </v>
<v Speaker 1>made more progress.</v>

228
00:13:33.970 --> 00:13:37.600
<v Speaker 1>And so what I wanted to look at,</v>
<v Speaker 1>where in this community,</v>

229
00:13:37.830 --> 00:13:42.830
<v Speaker 1>uh,</v>
<v Speaker 1>what are some of the core assumptions </v>

230
00:13:42.830 --> 00:13:42.830
<v Speaker 1>that are driving forward scientific </v>
<v Speaker 1>progress.</v>

231
00:13:43.390 --> 00:13:46.450
<v Speaker 1>So one of them actually came out of </v>
<v Speaker 1>those lectures,</v>

232
00:13:46.451 --> 00:13:49.150
<v Speaker 1>they're referred to as noodles,</v>
<v Speaker 1>timescales of human action,</v>

233
00:13:49.420 --> 00:13:54.420
<v Speaker 1>and so off on the left,</v>
<v Speaker 1>the left two columns are both time units</v>

234
00:13:54.941 --> 00:13:59.941
<v Speaker 1>just expressed somewhat differently.</v>
<v Speaker 1>A second from the left being maybe more </v>

235
00:13:59.941 --> 00:14:02.530
<v Speaker 1>useful to a lot of us in understanding </v>
<v Speaker 1>daily life.</v>

236
00:14:03.070 --> 00:14:08.070
<v Speaker 1>Uh,</v>
<v Speaker 1>one step over from there would be kind </v>

237
00:14:08.070 --> 00:14:08.070
<v Speaker 1>of at what level processes are </v>
<v Speaker 1>occurring.</v>

238
00:14:08.070 --> 00:14:10.960
<v Speaker 1>So the lowest three are down at of the </v>
<v Speaker 1>substrate,</v>

239
00:14:11.020 --> 00:14:16.020
<v Speaker 1>the neuronal level.</v>
<v Speaker 1>We're building up to deliberate tasks </v>

240
00:14:16.020 --> 00:14:19.381
<v Speaker 1>that occur in the brain and tasks that </v>
<v Speaker 1>are operating on the order of 10 </v>

241
00:14:19.381 --> 00:14:23.371
<v Speaker 1>seconds.</v>
<v Speaker 1>Some of these might occur in the </v>

242
00:14:23.371 --> 00:14:25.680
<v Speaker 1>psychology laboratory,</v>
<v Speaker 1>but probably a step up to minutes and </v>

243
00:14:25.680 --> 00:14:30.601
<v Speaker 1>hours and then above that really becomes</v>
<v Speaker 1>the interactions between agents over </v>

244
00:14:30.601 --> 00:14:34.361
<v Speaker 1>time and so if we start with that,</v>
<v Speaker 1>the things to take away is that a </v>

245
00:14:34.811 --> 00:14:39.811
<v Speaker 1>regular,</v>
<v Speaker 1>the hypothesis is that regularity is </v>

246
00:14:39.811 --> 00:14:42.790
<v Speaker 1>will occur at these different timescales</v>
<v Speaker 1>and that they're useful and so those who</v>

247
00:14:42.791 --> 00:14:47.230
<v Speaker 1>operate at that lowest timescale might </v>
<v Speaker 1>be considering neuroscience,</v>

248
00:14:47.231 --> 00:14:48.460
<v Speaker 1>cognitive,</v>
<v Speaker 1>neuroscience.</v>

249
00:14:48.850 --> 00:14:50.980
<v Speaker 1>When you shift up to the next couple of </v>
<v Speaker 1>levels,</v>

250
00:14:50.990 --> 00:14:55.990
<v Speaker 1>what we would think about in terms of </v>
<v Speaker 1>the areas of science that deal without </v>

251
00:14:55.990 --> 00:14:59.410
<v Speaker 1>would be psychology and cognitive </v>
<v Speaker 1>science and that will shift up a level </v>

252
00:14:59.410 --> 00:15:02.651
<v Speaker 1>and we're talking about sociology and </v>
<v Speaker 1>economics and the interplay between a </v>

253
00:15:03.200 --> 00:15:08.200
<v Speaker 1>agents over time and so what we'll find </v>
<v Speaker 1>with cognitive architecture is that most</v>

254
00:15:09.351 --> 00:15:11.540
<v Speaker 1>of them will tend to sit at the </v>
<v Speaker 1>deliberate act.</v>

255
00:15:11.690 --> 00:15:16.690
<v Speaker 1>We're trying to take knowledge of a </v>
<v Speaker 1>situation and make a single decision and</v>

256
00:15:16.791 --> 00:15:20.900
<v Speaker 1>then sequences of decisions over time.</v>
<v Speaker 1>We'll build to tasks and tasks.</v>

257
00:15:20.901 --> 00:15:23.480
<v Speaker 1>Over time we'll build to more </v>
<v Speaker 1>interesting phenomenon.</v>

258
00:15:23.960 --> 00:15:26.270
<v Speaker 1>I'm actually going to show that that </v>
<v Speaker 1>isn't strictly true,</v>

259
00:15:26.300 --> 00:15:29.900
<v Speaker 1>that there are folks working in this </v>
<v Speaker 1>field that actually do operate one level</v>

260
00:15:29.901 --> 00:15:33.560
<v Speaker 1>below a,</v>
<v Speaker 1>some other assumptions.</v>

261
00:15:33.590 --> 00:15:38.120
<v Speaker 1>So this is a herb Simon receiving the </v>
<v Speaker 1>Nobel prize in economics,</v>

262
00:15:39.130 --> 00:15:43.760
<v Speaker 1>and part of what he received that award </v>
<v Speaker 1>for was an idea of bounded rationality.</v>

263
00:15:44.500 --> 00:15:49.040
<v Speaker 1>So in various fields we tend to model </v>
<v Speaker 1>humans as rational.</v>

264
00:15:49.150 --> 00:15:51.660
<v Speaker 1>Uh,</v>
<v Speaker 1>and his argument was a,</v>

265
00:15:51.680 --> 00:15:56.680
<v Speaker 1>let's consider that human beings are </v>
<v Speaker 1>operating under various kinds of </v>

266
00:15:57.020 --> 00:16:02.020
<v Speaker 1>constraints.</v>
<v Speaker 1>And so to model the rationality with </v>

267
00:16:02.020 --> 00:16:05.030
<v Speaker 1>respect to unbounded by how complex the </v>
<v Speaker 1>problem is that they're working on,</v>

268
00:16:05.060 --> 00:16:10.040
<v Speaker 1>how big is that search space that they </v>
<v Speaker 1>have to conquer cognitive limitations.</v>

269
00:16:10.250 --> 00:16:14.570
<v Speaker 1>So a speed of operations,</v>
<v Speaker 1>amount of memory,</v>

270
00:16:15.110 --> 00:16:20.110
<v Speaker 1>short term as well as longterm,</v>
<v Speaker 1>as well as other aspects of our </v>

271
00:16:20.110 --> 00:16:23.801
<v Speaker 1>computing infrastructure that are going </v>
<v Speaker 1>to keep us from being able to </v>

272
00:16:23.801 --> 00:16:26.950
<v Speaker 1>arbitrarily solve complex problems as </v>
<v Speaker 1>well as how much time is available to </v>

273
00:16:27.111 --> 00:16:29.810
<v Speaker 1>make that decision.</v>
<v Speaker 1>And so,</v>

274
00:16:29.811 --> 00:16:34.811
<v Speaker 1>uh,</v>
<v Speaker 1>this is actually a phrase that came out </v>

275
00:16:34.811 --> 00:16:34.811
<v Speaker 1>of his speech when he received the Nobel</v>
<v Speaker 1>prize.</v>

276
00:16:34.811 --> 00:16:38.990
<v Speaker 1>Decision makers can satisfy ice either </v>
<v Speaker 1>by finding optimum solutions for a </v>

277
00:16:38.990 --> 00:16:40.730
<v Speaker 1>simplified world,</v>
<v Speaker 1>which is to say,</v>

278
00:16:41.000 --> 00:16:43.400
<v Speaker 1>take your big problem,</v>
<v Speaker 1>simplify in some way,</v>

279
00:16:43.430 --> 00:16:48.430
<v Speaker 1>and then solve that or by finding </v>
<v Speaker 1>satisfactory solutions for a more </v>

280
00:16:48.430 --> 00:16:50.690
<v Speaker 1>realistic world,</v>
<v Speaker 1>take the world and all its complexity,</v>

281
00:16:50.691 --> 00:16:54.320
<v Speaker 1>take the problem in all its complexity </v>
<v Speaker 1>and try to find something that works.</v>

282
00:16:55.160 --> 00:17:00.160
<v Speaker 1>Neither approach in general dominates </v>
<v Speaker 1>the other and both have continued to </v>

283
00:17:00.160 --> 00:17:00.620
<v Speaker 1>coexist.</v>
<v Speaker 1>And so what you're actually going to see</v>

284
00:17:00.820 --> 00:17:05.820
<v Speaker 1>a throughout the cognitive architecture </v>
<v Speaker 1>community is this understanding that </v>

285
00:17:05.840 --> 00:17:09.680
<v Speaker 1>some problems you're not gonna be able </v>
<v Speaker 1>to get an optimal solution to,</v>

286
00:17:09.681 --> 00:17:11.360
<v Speaker 1>if you consider,</v>
<v Speaker 1>for instance,</v>

287
00:17:11.620 --> 00:17:14.420
<v Speaker 1>a bounded amount of computation,</v>
<v Speaker 1>bounded time,</v>

288
00:17:14.600 --> 00:17:17.270
<v Speaker 1>the need to be reactive to a changing </v>
<v Speaker 1>environment,</v>

289
00:17:17.420 --> 00:17:18.530
<v Speaker 1>these sorts of issues.</v>

290
00:17:18.860 --> 00:17:23.860
<v Speaker 1>And so in some sense,</v>
<v Speaker 1>we can decompose problems that come up </v>

291
00:17:23.860 --> 00:17:24.590
<v Speaker 1>over and over again into simpler </v>
<v Speaker 1>problems,</v>

292
00:17:25.010 --> 00:17:26.750
<v Speaker 1>solve those,</v>
<v Speaker 1>uh,</v>

293
00:17:27.000 --> 00:17:30.500
<v Speaker 1>near optimally or optimally fix those </v>
<v Speaker 1>in,</v>

294
00:17:30.501 --> 00:17:32.870
<v Speaker 1>optimize those,</v>
<v Speaker 1>but more general problems.</v>

295
00:17:32.871 --> 00:17:37.871
<v Speaker 1>We might have to satisfy some.</v>
<v Speaker 1>There's also the idea of the symbol </v>

296
00:17:37.871 --> 00:17:42.500
<v Speaker 1>system hypothesis.</v>
<v Speaker 1>So this is a Allen Newell and Herb Simon</v>

297
00:17:42.501 --> 00:17:43.140
<v Speaker 1>there,</v>
<v Speaker 1>uh,</v>

298
00:17:43.610 --> 00:17:46.310
<v Speaker 1>considering how a computer could play </v>
<v Speaker 1>the game of chess.</v>

299
00:17:46.520 --> 00:17:51.520
<v Speaker 1>So the fiscal system,</v>
<v Speaker 1>physical symbol system talks about the </v>

300
00:17:51.520 --> 00:17:55.101
<v Speaker 1>idea of taking something,</v>
<v Speaker 1>some signal abstractly referred to as </v>

301
00:17:55.101 --> 00:17:59.150
<v Speaker 1>symbol,</v>
<v Speaker 1>combining them in some ways to form </v>

302
00:17:59.150 --> 00:18:01.530
<v Speaker 1>expressions and then having operations </v>
<v Speaker 1>that produced new expressions.</v>

303
00:18:01.950 --> 00:18:06.950
<v Speaker 1>I'm a weak interpretation of the idea </v>
<v Speaker 1>that symbol systems are necessary and </v>

304
00:18:08.191 --> 00:18:13.191
<v Speaker 1>sufficient for intelligent systems.</v>
<v Speaker 1>A very weak way of talking about it is </v>

305
00:18:13.191 --> 00:18:16.850
<v Speaker 1>the claim that there's nothing unique </v>
<v Speaker 1>about the neuronal infrastructure that </v>

306
00:18:16.850 --> 00:18:20.190
<v Speaker 1>we have,</v>
<v Speaker 1>but if we got to the software right,</v>

307
00:18:20.310 --> 00:18:25.310
<v Speaker 1>we could implement it in the bits bytes,</v>
<v Speaker 1>ram and processor that makeup modern </v>

308
00:18:25.310 --> 00:18:25.560
<v Speaker 1>computers.</v>

309
00:18:25.560 --> 00:18:27.510
<v Speaker 1>That's kind of the weakest way to look </v>
<v Speaker 1>at this.</v>

310
00:18:27.780 --> 00:18:31.830
<v Speaker 1>That we can do it with silicon and not </v>
<v Speaker 1>carbon.</v>

311
00:18:32.590 --> 00:18:37.590
<v Speaker 1>I'm stronger way that this used to be </v>
<v Speaker 1>looked at was more of a logical </v>

312
00:18:38.041 --> 00:18:41.700
<v Speaker 1>standpoint,</v>
<v Speaker 1>which is to say if we can encode a rules</v>

313
00:18:41.701 --> 00:18:46.701
<v Speaker 1>of logic,</v>
<v Speaker 1>these tend to line up if we think </v>

314
00:18:46.701 --> 00:18:47.790
<v Speaker 1>intuitively have a planning and problem </v>
<v Speaker 1>solving.</v>

315
00:18:47.910 --> 00:18:52.910
<v Speaker 1>And if we can just get that right and </v>
<v Speaker 1>get enough fats in there and enough </v>

316
00:18:52.910 --> 00:18:53.670
<v Speaker 1>rules in there that somehow </v>
<v Speaker 1>intelligence,</v>

317
00:18:54.000 --> 00:18:54.600
<v Speaker 1>uh,</v>
<v Speaker 1>well,</v>

318
00:18:54.660 --> 00:18:59.660
<v Speaker 1>that's what we need for intelligence and</v>
<v Speaker 1>eventually we can get to the point of </v>

319
00:18:59.660 --> 00:19:00.270
<v Speaker 1>intelligence and that's what you need </v>
<v Speaker 1>for intelligence.</v>

320
00:19:01.170 --> 00:19:04.720
<v Speaker 1>And that was a,</v>
<v Speaker 1>a starting point that lasted for awhile.</v>

321
00:19:04.740 --> 00:19:09.740
<v Speaker 1>I think by now,</v>
<v Speaker 1>most folks in this field would agree </v>

322
00:19:09.740 --> 00:19:12.930
<v Speaker 1>that that's necessary to be able to </v>
<v Speaker 1>operate logically,</v>

323
00:19:13.140 --> 00:19:18.140
<v Speaker 1>but that there are going to be </v>
<v Speaker 1>representations and processes that'll </v>

324
00:19:18.140 --> 00:19:19.110
<v Speaker 1>benefit from non symbolic </v>
<v Speaker 1>representations.</v>

325
00:19:19.111 --> 00:19:24.111
<v Speaker 1>So particularly perceptual processing,</v>
<v Speaker 1>visual auditory and processing things in</v>

326
00:19:24.631 --> 00:19:27.330
<v Speaker 1>a more kind of standard machine learning</v>
<v Speaker 1>sort of way.</v>

327
00:19:27.700 --> 00:19:29.400
<v Speaker 1>Uh,</v>
<v Speaker 1>uh,</v>

328
00:19:29.670 --> 00:19:34.670
<v Speaker 1>as well as kind of statistic taking </v>
<v Speaker 1>advantage of statistical rep a </v>

329
00:19:34.670 --> 00:19:34.670
<v Speaker 1>representations.</v>

330
00:19:36.570 --> 00:19:40.830
<v Speaker 1>So we're getting closer to actually </v>
<v Speaker 1>looking at cognitive architectures.</v>

331
00:19:41.100 --> 00:19:46.100
<v Speaker 1>Uh,</v>
<v Speaker 1>I did want to go back to the idea that </v>

332
00:19:46.100 --> 00:19:47.990
<v Speaker 1>different researchers are coming with </v>
<v Speaker 1>different research Fokai Fossa.</v>

333
00:19:48.770 --> 00:19:53.770
<v Speaker 1>Uh,</v>
<v Speaker 1>and we'll start off with kind of the </v>

334
00:19:53.770 --> 00:19:53.940
<v Speaker 1>lowest level and understanding </v>
<v Speaker 1>biological modeling.</v>

335
00:19:53.941 --> 00:19:58.941
<v Speaker 1>So libra and spawn both try to model </v>
<v Speaker 1>different degrees of low level details,</v>

336
00:20:00.420 --> 00:20:02.670
<v Speaker 1>parameters,</v>
<v Speaker 1>firing rates,</v>

337
00:20:03.090 --> 00:20:08.090
<v Speaker 1>connectivities between different kind of</v>
<v Speaker 1>levels of neuronal representations.</v>

338
00:20:09.540 --> 00:20:13.230
<v Speaker 1>They build that up and then they tried </v>
<v Speaker 1>to build tasks above that layer,</v>

339
00:20:13.231 --> 00:20:18.231
<v Speaker 1>but always being very cautious about </v>
<v Speaker 1>being true to a human biological </v>

340
00:20:21.390 --> 00:20:23.910
<v Speaker 1>processes.</v>
<v Speaker 1>At a layer above,</v>

341
00:20:23.911 --> 00:20:28.911
<v Speaker 1>there would be psychological modeling,</v>
<v Speaker 1>which is to say trying to build systems </v>

342
00:20:28.981 --> 00:20:31.650
<v Speaker 1>that are true in some sense to,</v>
<v Speaker 1>uh,</v>

343
00:20:31.680 --> 00:20:36.150
<v Speaker 1>areas of the brain interactions in the </v>
<v Speaker 1>brain and being able to predict a errors</v>

344
00:20:36.151 --> 00:20:41.151
<v Speaker 1>that we made,</v>
<v Speaker 1>a timing that we produced by the human </v>

345
00:20:41.151 --> 00:20:44.631
<v Speaker 1>mind.</v>
<v Speaker 1>And so they're all talk a little bit </v>

346
00:20:44.631 --> 00:20:46.701
<v Speaker 1>about act are his final level down here.</v>
<v Speaker 1>These are systems that are focused </v>

347
00:20:47.650 --> 00:20:52.650
<v Speaker 1>mainly on producing functional systems </v>
<v Speaker 1>that exhibit really cool artifacts and </v>

348
00:20:55.721 --> 00:21:00.721
<v Speaker 1>solve really cool problems.</v>
<v Speaker 1>And so I'll spend most of the time </v>

349
00:21:00.721 --> 00:21:03.481
<v Speaker 1>talking about soar,</v>
<v Speaker 1>but I wanted to point out a relative </v>

350
00:21:03.481 --> 00:21:06.780
<v Speaker 1>newcomer in the game called sigma.</v>
<v Speaker 1>So to talk about spawn a little bit.</v>

351
00:21:07.460 --> 00:21:12.460
<v Speaker 1>We'll see if the sound works in here.</v>
<v Speaker 1>I'm going to let the creator take this </v>

352
00:21:13.641 --> 00:21:13.970
<v Speaker 1>one</v>

353
00:21:16.790 --> 00:21:21.790
<v Speaker 1>or not see how the AB system likes this.</v>

354
00:21:27.170 --> 00:21:27.630
<v Speaker 2>There we go.</v>

355
00:21:31.690 --> 00:21:36.690
<v Speaker 3>Why do you pick the license and the </v>
<v Speaker 3>director of the Center for Science at </v>

356
00:21:36.690 --> 00:21:40.130
<v Speaker 3>the University of philosophy and the </v>
<v Speaker 3>philosophy is considered a general </v>

357
00:21:42.431 --> 00:21:47.431
<v Speaker 3>conceptual issues is any breakdown </v>
<v Speaker 3>equations very concise.</v>

358
00:21:55.250 --> 00:22:00.250
<v Speaker 3>We can like building actual models </v>
<v Speaker 3>recently it's called the small sign </v>

359
00:22:01.790 --> 00:22:06.790
<v Speaker 3>because she wouldn't have million </v>
<v Speaker 3>individual neurons and the model isn't </v>

360
00:22:07.000 --> 00:22:12.000
<v Speaker 3>it and the movement,</v>
<v Speaker 3>so essentially see images and numbers </v>

361
00:22:13.060 --> 00:22:17.060
<v Speaker 3>and in the case of just gotten into that</v>
<v Speaker 3>seat,</v>

362
00:22:18.050 --> 00:22:21.610
<v Speaker 3>reproduce the south and it's looking at.</v>
<v Speaker 3>So for instance,</v>

363
00:22:28.240 --> 00:22:33.240
<v Speaker 3>we all know that we have that show up </v>
<v Speaker 3>and we can simulate a potential area.</v>

364
00:22:39.760 --> 00:22:43.150
<v Speaker 3>Hold on.</v>
<v Speaker 3>I'm working on agents that are extremely</v>

365
00:22:43.151 --> 00:22:48.151
<v Speaker 3>good at one task for instance.</v>
<v Speaker 3>What's special is that pass and this </v>

366
00:22:49.650 --> 00:22:53.640
<v Speaker 3>adds the additional kind of coordinate </v>
<v Speaker 3>the flow of information,</v>

367
00:22:53.680 --> 00:22:54.960
<v Speaker 3>food,</v>
<v Speaker 3>different parts of the model,</v>

368
00:22:55.210 --> 00:22:55.620
<v Speaker 3>something</v>

369
00:23:02.240 --> 00:23:07.240
<v Speaker 1>so provide a pointer at the end.</v>
<v Speaker 1>He's got a really cool book called how </v>

370
00:23:07.240 --> 00:23:08.990
<v Speaker 1>to build a brain and if you google you </v>
<v Speaker 1>can google spawn.</v>

371
00:23:09.230 --> 00:23:14.230
<v Speaker 1>You can find a toolkit where you can </v>
<v Speaker 1>kind of construct circuits that will </v>

372
00:23:14.960 --> 00:23:16.840
<v Speaker 1>approximate functions that you're </v>
<v Speaker 1>interested in,</v>

373
00:23:16.850 --> 00:23:21.850
<v Speaker 1>connect them together,</v>
<v Speaker 1>a set certain properties that you would </v>

374
00:23:21.850 --> 00:23:26.080
<v Speaker 1>want at a low level and build them up </v>
<v Speaker 1>and actually work on tasks at the level </v>

375
00:23:26.451 --> 00:23:31.451
<v Speaker 1>of vision and robotic actuation.</v>
<v Speaker 1>So that's a really cool system as we </v>

376
00:23:33.681 --> 00:23:37.730
<v Speaker 1>move into architectures that are sitting</v>
<v Speaker 1>above that biological level.</v>

377
00:23:37.940 --> 00:23:42.940
<v Speaker 1>I wanted to give you kind of an overall </v>
<v Speaker 1>sense of what they're going to look </v>

378
00:23:42.940 --> 00:23:45.851
<v Speaker 1>like,</v>
<v Speaker 1>what a prototypical architecture is </v>

379
00:23:45.851 --> 00:23:45.980
<v Speaker 1>going to look like.</v>
<v Speaker 1>So they're going to have some ability to</v>

380
00:23:45.981 --> 00:23:47.300
<v Speaker 1>have perception.</v>
<v Speaker 1>Uh,</v>

381
00:23:47.390 --> 00:23:52.390
<v Speaker 1>the modalities typically are more </v>
<v Speaker 1>digital symbolic,</v>

382
00:23:52.490 --> 00:23:53.780
<v Speaker 1>but,</v>
<v Speaker 1>uh,</v>

383
00:23:53.840 --> 00:23:55.960
<v Speaker 1>they will,</v>
<v Speaker 1>depending on the architecture,</v>

384
00:23:55.980 --> 00:24:00.980
<v Speaker 1>be able to handle vision,</v>
<v Speaker 1>audition a and various sensory inputs.</v>

385
00:24:02.390 --> 00:24:05.420
<v Speaker 1>These little gadgets represented in some</v>
<v Speaker 1>sort of short term memory.</v>

386
00:24:05.421 --> 00:24:10.200
<v Speaker 1>Whatever the state's representation for </v>
<v Speaker 1>the particular system is there.</v>

387
00:24:10.620 --> 00:24:15.620
<v Speaker 1>It's typical to have a representation of</v>
<v Speaker 1>the knowledge of what tasks can be </v>

388
00:24:15.620 --> 00:24:18.620
<v Speaker 1>performed when they should be performed,</v>
<v Speaker 1>how they should be controlled.</v>

389
00:24:18.890 --> 00:24:23.890
<v Speaker 1>And so these are typically both actions </v>
<v Speaker 1>that take place internally that manage </v>

390
00:24:24.230 --> 00:24:28.490
<v Speaker 1>the internal state of the system and </v>
<v Speaker 1>perform internal computations,</v>

391
00:24:28.820 --> 00:24:33.820
<v Speaker 1>but also about external actuation and </v>
<v Speaker 1>external might be a digital system,</v>

392
00:24:34.041 --> 00:24:39.041
<v Speaker 1>a game ai,</v>
<v Speaker 1>but it might also be some sort of </v>

393
00:24:39.041 --> 00:24:39.420
<v Speaker 1>robotic actuation and real world.</v>
<v Speaker 1>Uh,</v>

394
00:24:39.860 --> 00:24:44.860
<v Speaker 1>there's typically some sort of mechanism</v>
<v Speaker 1>by which to select from the available </v>

395
00:24:44.860 --> 00:24:49.100
<v Speaker 1>actions in a particular situation.</v>
<v Speaker 1>There's typically some way to augment </v>

396
00:24:49.730 --> 00:24:54.730
<v Speaker 1>this procedural information,</v>
<v Speaker 1>which is to say learn about new actions </v>

397
00:24:54.730 --> 00:24:59.171
<v Speaker 1>possibly modify existing ones.</v>
<v Speaker 1>There's typically some semblance of </v>

398
00:24:59.171 --> 00:25:01.580
<v Speaker 1>what's called a declarative memory.</v>
<v Speaker 1>So whereas procedural,</v>

399
00:25:01.581 --> 00:25:03.060
<v Speaker 1>at least in humans,</v>
<v Speaker 1>uh,</v>

400
00:25:03.110 --> 00:25:08.110
<v Speaker 1>if I asked you to describe how to ride a</v>
<v Speaker 1>bike a,</v>

401
00:25:08.450 --> 00:25:11.510
<v Speaker 1>you might be able to say,</v>
<v Speaker 1>get on the seats and pedal.</v>

402
00:25:11.720 --> 00:25:13.640
<v Speaker 1>But in terms of keeping your balance </v>
<v Speaker 1>there,</v>

403
00:25:13.641 --> 00:25:17.420
<v Speaker 1>you'd have a pretty hard time describing</v>
<v Speaker 1>it declaratively.</v>

404
00:25:18.110 --> 00:25:23.110
<v Speaker 1>So that's kind of the procedural side,</v>
<v Speaker 1>the implicit representation of </v>

405
00:25:23.110 --> 00:25:25.640
<v Speaker 1>knowledge.</v>
<v Speaker 1>Whereas declarative would include facts,</v>

406
00:25:25.700 --> 00:25:27.080
<v Speaker 1>geography,</v>
<v Speaker 1>math,</v>

407
00:25:27.240 --> 00:25:29.780
<v Speaker 1>uh,</v>
<v Speaker 1>but it calls to include experiences that</v>

408
00:25:29.781 --> 00:25:32.930
<v Speaker 1>the hns had a more episodic </v>
<v Speaker 1>representation of declarative memory.</v>

409
00:25:33.290 --> 00:25:36.500
<v Speaker 1>And they'll typically have some way of,</v>
<v Speaker 1>of learning this information.</v>

410
00:25:36.501 --> 00:25:41.501
<v Speaker 1>Augmenting it over time and then finally</v>
<v Speaker 1>some way of taking actions in the world </v>

411
00:25:42.260 --> 00:25:47.260
<v Speaker 1>and they'll all have some sort of cycle </v>
<v Speaker 1>which is perception comes in knowledge </v>

412
00:25:47.871 --> 00:25:50.390
<v Speaker 1>that the agent has is brought to bear on</v>
<v Speaker 1>that.</v>

413
00:25:51.130 --> 00:25:56.130
<v Speaker 1>An action is selected.</v>
<v Speaker 1>Knowledge that knows to condition on </v>

414
00:25:56.130 --> 00:25:59.501
<v Speaker 1>that action will act accordingly,</v>
<v Speaker 1>both with internal processes as well as </v>

415
00:25:59.501 --> 00:26:00.980
<v Speaker 1>eventually to take action and then rinse</v>
<v Speaker 1>and repeat.</v>

416
00:26:02.170 --> 00:26:07.170
<v Speaker 1>Um,</v>
<v Speaker 1>so when we talk about an AI system and </v>

417
00:26:07.170 --> 00:26:09.080
<v Speaker 1>agent in this context,</v>
<v Speaker 1>that would be the fixed representation,</v>

418
00:26:09.081 --> 00:26:13.820
<v Speaker 1>which is whatever architecture we're </v>
<v Speaker 1>talking about plus set of knowledge that</v>

419
00:26:13.821 --> 00:26:17.420
<v Speaker 1>is typically specific to the task button</v>
<v Speaker 1>might be more general.</v>

420
00:26:17.450 --> 00:26:22.450
<v Speaker 1>So oftentimes these systems could </v>
<v Speaker 1>incorporate a more general knowledge </v>

421
00:26:22.450 --> 00:26:24.710
<v Speaker 1>base of facts,</v>
<v Speaker 1>of linguistic facts,</v>

422
00:26:24.711 --> 00:26:29.711
<v Speaker 1>of a geographic facts.</v>
<v Speaker 1>Let's take wikipedia and let's just </v>

423
00:26:29.711 --> 00:26:32.120
<v Speaker 1>stick it in the brain of the system.</v>
<v Speaker 1>There'll be more task general,</v>

424
00:26:32.420 --> 00:26:34.580
<v Speaker 1>but then also whatever it is that you're</v>
<v Speaker 1>doing right now,</v>

425
00:26:35.180 --> 00:26:40.180
<v Speaker 1>how should you proceed in that?</v>
<v Speaker 1>And then it's typical to see this </v>

426
00:26:40.180 --> 00:26:43.620
<v Speaker 1>processing cycle.</v>
<v Speaker 1>And going back to the prior assumption,</v>

427
00:26:43.621 --> 00:26:45.380
<v Speaker 1>the idea is that,</v>
<v Speaker 1>uh,</v>

428
00:26:45.420 --> 00:26:50.370
<v Speaker 1>these primitive cycles allow for the </v>
<v Speaker 1>agent to be reactive to its environment.</v>

429
00:26:50.550 --> 00:26:54.120
<v Speaker 1>So if new things come into his react to,</v>
<v Speaker 1>if the lions sitting over there,</v>

430
00:26:54.121 --> 00:26:56.490
<v Speaker 1>I better run and maybe not do my </v>
<v Speaker 1>calculus homework,</v>

431
00:26:56.491 --> 00:26:59.970
<v Speaker 1>right?</v>
<v Speaker 1>So as long as this cycle is going,</v>

432
00:26:59.971 --> 00:27:02.040
<v Speaker 1>I'm reactive.</v>
<v Speaker 1>But at the same time,</v>

433
00:27:02.160 --> 00:27:05.970
<v Speaker 1>if multiple actions are taken over time,</v>
<v Speaker 1>I'm able to get complex behavior,</v>

434
00:27:06.200 --> 00:27:07.260
<v Speaker 1>uh,</v>
<v Speaker 1>over the longterm.</v>

435
00:27:08.610 --> 00:27:12.090
<v Speaker 1>So this is the act are cognitive </v>
<v Speaker 1>architecture.</v>

436
00:27:12.330 --> 00:27:17.330
<v Speaker 1>Uh,</v>
<v Speaker 1>it has many of the kind of core pieces </v>

437
00:27:17.330 --> 00:27:19.560
<v Speaker 1>that I talked about before.</v>
<v Speaker 1>Let's see if the,</v>

438
00:27:20.120 --> 00:27:22.020
<v Speaker 1>some mouse,</v>
<v Speaker 1>yes,</v>

439
00:27:22.070 --> 00:27:26.190
<v Speaker 1>as useful up there.</v>
<v Speaker 1>So we have the procedural model here.</v>

440
00:27:26.430 --> 00:27:30.300
<v Speaker 1>A short term memory is going to be these</v>
<v Speaker 1>buffers that are on the outside,</v>

441
00:27:30.620 --> 00:27:33.500
<v Speaker 1>uh,</v>
<v Speaker 1>the procedural memory is encoded as what</v>

442
00:27:33.510 --> 00:27:36.750
<v Speaker 1>it called production rules,</v>
<v Speaker 1>or if then rules,</v>

443
00:27:37.250 --> 00:27:40.110
<v Speaker 1>if this is the state of my short term </v>
<v Speaker 1>memory,</v>

444
00:27:40.111 --> 00:27:42.240
<v Speaker 1>this is what I think should happen as a </v>
<v Speaker 1>result,</v>

445
00:27:42.450 --> 00:27:47.450
<v Speaker 1>uh,</v>
<v Speaker 1>you have a selection of the appropriate </v>

446
00:27:47.550 --> 00:27:52.550
<v Speaker 1>rule to fire and an execution.</v>
<v Speaker 1>You're seeing a associated parts of the </v>

447
00:27:52.891 --> 00:27:57.891
<v Speaker 1>brain being represented here,</v>
<v Speaker 1>cool thing that has been done over time </v>

448
00:27:57.891 --> 00:27:58.740
<v Speaker 1>in the act.</v>
<v Speaker 1>Our community is to,</v>

449
00:27:59.000 --> 00:28:04.000
<v Speaker 1>uh,</v>
<v Speaker 1>make predictions about brain areas and </v>

450
00:28:04.000 --> 00:28:07.401
<v Speaker 1>then perform a Mris and,</v>
<v Speaker 1>and gather that data and correlate that </v>

451
00:28:07.401 --> 00:28:08.130
<v Speaker 1>data.</v>
<v Speaker 1>So when you use the system,</v>

452
00:28:08.131 --> 00:28:12.570
<v Speaker 1>you will get predictions about things </v>
<v Speaker 1>like timing of operations,</v>

453
00:28:12.630 --> 00:28:15.900
<v Speaker 1>errors that will occur,</v>
<v Speaker 1>probabilities that something is learned,</v>

454
00:28:16.170 --> 00:28:21.170
<v Speaker 1>but you'll also get predictions about a </v>
<v Speaker 1>to the degree that they can kind of </v>

455
00:28:21.170 --> 00:28:24.921
<v Speaker 1>brain areas that are going to light a </v>
<v Speaker 1>light up a and if you want to,</v>

456
00:28:24.960 --> 00:28:28.500
<v Speaker 1>that's actively being developed at </v>
<v Speaker 1>Carnegie Mellon.</v>

457
00:28:29.760 --> 00:28:34.760
<v Speaker 1>To the left is John Anderson who </v>
<v Speaker 1>developed this cognitive architecture.</v>

458
00:28:35.510 --> 00:28:38.040
<v Speaker 1>Oh,</v>
<v Speaker 1>30 ish years ago.</v>

459
00:28:38.380 --> 00:28:39.840
<v Speaker 1>Uh,</v>
<v Speaker 1>and until the last,</v>

460
00:28:39.841 --> 00:28:44.841
<v Speaker 1>about five years,</v>
<v Speaker 1>he was the primary researcher developer </v>

461
00:28:44.841 --> 00:28:48.051
<v Speaker 1>behind it with Christian.</v>
<v Speaker 1>And then recently he's decided to spend </v>

462
00:28:48.051 --> 00:28:49.950
<v Speaker 1>more time on a cognitive tutoring </v>
<v Speaker 1>systems.</v>

463
00:28:50.160 --> 00:28:53.250
<v Speaker 1>And so Christian has become the primary </v>
<v Speaker 1>developer.</v>

464
00:28:53.460 --> 00:28:56.760
<v Speaker 1>There is a annual act.</v>
<v Speaker 1>Our workshop,</v>

465
00:28:57.210 --> 00:29:02.210
<v Speaker 1>there's a summer school which if you're </v>
<v Speaker 1>thinking about modeling a particular </v>

466
00:29:02.611 --> 00:29:04.770
<v Speaker 1>task,</v>
<v Speaker 1>you can kind of bring your task to them,</v>

467
00:29:04.771 --> 00:29:07.350
<v Speaker 1>bring your data.</v>
<v Speaker 1>They teach you how to use the system and</v>

468
00:29:07.530 --> 00:29:09.780
<v Speaker 1>try to get that study going right there </v>
<v Speaker 1>on the spot,</v>

469
00:29:10.690 --> 00:29:15.690
<v Speaker 1>uh,</v>
<v Speaker 1>to give you a sense of what kinds of </v>

470
00:29:15.690 --> 00:29:15.690
<v Speaker 1>tasks this could be applied to.</v>
<v Speaker 1>So,</v>

471
00:29:15.840 --> 00:29:20.840
<v Speaker 1>uh,</v>
<v Speaker 1>this is a representative of a certain </v>

472
00:29:20.840 --> 00:29:21.630
<v Speaker 1>class of task.</v>
<v Speaker 1>Certainly not the only one.</v>

473
00:29:23.520 --> 00:29:28.520
<v Speaker 1>Let's try this again.</v>
<v Speaker 1>Think powerpoint is going to want a </v>

474
00:29:28.520 --> 00:29:28.620
<v Speaker 1>restart every time.</v>

475
00:29:28.680 --> 00:29:30.270
<v Speaker 1>Okay.</v>
<v Speaker 1>So,</v>

476
00:29:30.300 --> 00:29:35.300
<v Speaker 1>uh,</v>
<v Speaker 1>we're getting predictions about </v>

477
00:29:35.300 --> 00:29:35.300
<v Speaker 1>basically where the eye is going to </v>
<v Speaker 1>move.</v>

478
00:29:35.300 --> 00:29:39.280
<v Speaker 1>What you're not seeing is it's actually </v>
<v Speaker 1>processing things like text and colors </v>

479
00:29:39.280 --> 00:29:42.100
<v Speaker 1>and making predictions about what to do </v>
<v Speaker 1>and how to represent information and how</v>

480
00:29:42.101 --> 00:29:45.460
<v Speaker 1>to process the graph as a whole.</v>
<v Speaker 1>Uh,</v>

481
00:29:45.670 --> 00:29:48.970
<v Speaker 1>I had alluded to this earlier.</v>
<v Speaker 1>There's work by Bonnie John,</v>

482
00:29:49.330 --> 00:29:54.330
<v Speaker 1>a very similar,</v>
<v Speaker 1>so making predictions about how humans </v>

483
00:29:54.330 --> 00:29:57.631
<v Speaker 1>would use computer interfaces.</v>
<v Speaker 1>And at the time she got hired away by </v>

484
00:29:57.631 --> 00:30:01.951
<v Speaker 1>IBM and so they wanted the ability to </v>
<v Speaker 1>have software that you can put in front </v>

485
00:30:01.951 --> 00:30:05.230
<v Speaker 1>of a software designers and when they </v>
<v Speaker 1>think they have a good interface,</v>

486
00:30:05.231 --> 00:30:09.180
<v Speaker 1>press a button.</v>
<v Speaker 1>This model of human cognition with tried</v>

487
00:30:09.181 --> 00:30:14.181
<v Speaker 1>to perform the tasks that had been told </v>
<v Speaker 1>to do and make predictions about how </v>

488
00:30:14.181 --> 00:30:17.401
<v Speaker 1>long it would take.</v>
<v Speaker 1>And so you can have this tight feedback </v>

489
00:30:17.401 --> 00:30:18.670
<v Speaker 1>loop from designer saying,</v>
<v Speaker 1>here's how good your particular,</v>

490
00:30:18.790 --> 00:30:22.090
<v Speaker 1>uh,</v>
<v Speaker 1>interfaces so act are as a whole.</v>

491
00:30:22.290 --> 00:30:27.290
<v Speaker 1>It's very prevalent in this community.</v>
<v Speaker 1>I went to their webpage and counted up </v>

492
00:30:27.290 --> 00:30:30.751
<v Speaker 1>just the papers that they knew about.</v>
<v Speaker 1>It was over 1100 papers over time.</v>

493
00:30:31.840 --> 00:30:33.100
<v Speaker 1>Uh,</v>
<v Speaker 1>if you're interested in it,</v>

494
00:30:33.400 --> 00:30:36.370
<v Speaker 1>the main distribution is in lisp,</v>
<v Speaker 1>but,</v>

495
00:30:36.460 --> 00:30:41.460
<v Speaker 1>uh,</v>
<v Speaker 1>many people have used this and wanting </v>

496
00:30:41.460 --> 00:30:41.460
<v Speaker 1>to apply it to systems that need a </v>
<v Speaker 1>little more processing power.</v>

497
00:30:42.030 --> 00:30:42.970
<v Speaker 1>Uh,</v>
<v Speaker 1>so there's,</v>

498
00:30:43.210 --> 00:30:46.780
<v Speaker 1>the NRL has a java part of it that they </v>
<v Speaker 1>use in robotics.</v>

499
00:30:46.990 --> 00:30:51.990
<v Speaker 1>The air force research lab in Dayton has</v>
<v Speaker 1>implemented it in Erlangen for parallel </v>

500
00:30:53.561 --> 00:30:55.900
<v Speaker 1>processing of large declarative </v>
<v Speaker 1>knowledge bases.</v>

501
00:30:55.980 --> 00:31:00.980
<v Speaker 1>Uh,</v>
<v Speaker 1>they're trying to do service oriented </v>

502
00:31:00.980 --> 00:31:02.860
<v Speaker 1>architectures with it Kuda because they </v>
<v Speaker 1>want what it has to say.</v>

503
00:31:02.861 --> 00:31:05.260
<v Speaker 1>They don't want to wait around for a tap</v>
<v Speaker 1>to figure that stuff out.</v>

504
00:31:05.860 --> 00:31:08.380
<v Speaker 1>Uh,</v>
<v Speaker 1>so that's,</v>

505
00:31:08.410 --> 00:31:12.490
<v Speaker 1>uh,</v>
<v Speaker 1>the two minutes about act are a sigma as</v>

506
00:31:12.491 --> 00:31:17.080
<v Speaker 1>a relative newcomer.</v>
<v Speaker 1>And it's developed out at the University</v>

507
00:31:17.080 --> 00:31:20.200
<v Speaker 1>of southern California by a man named </v>
<v Speaker 1>Paul Rosenbloom,</v>

508
00:31:20.220 --> 00:31:25.220
<v Speaker 1>and I'll mentioned a couple of minutes </v>
<v Speaker 1>because he was one of the prime </v>

509
00:31:25.220 --> 00:31:25.970
<v Speaker 1>developers have soar at Carnegie Mellon,</v>
<v Speaker 1>uh,</v>

510
00:31:26.020 --> 00:31:29.560
<v Speaker 1>so he knows a lot about how solar works </v>
<v Speaker 1>and he's worked on it over the years.</v>

511
00:31:29.890 --> 00:31:34.890
<v Speaker 1>And I think originally I'm going to </v>
<v Speaker 1>speak for him and he'll probably say I </v>

512
00:31:34.890 --> 00:31:38.251
<v Speaker 1>was wrong.</v>
<v Speaker 1>I think originally it was kind of a </v>

513
00:31:38.251 --> 00:31:41.370
<v Speaker 1>mental exercise of can I reproduce sore </v>
<v Speaker 1>using a uniform substrate?</v>

514
00:31:43.000 --> 00:31:44.680
<v Speaker 1>I'll talk about in a little bit.</v>
<v Speaker 1>Uh,</v>

515
00:31:45.070 --> 00:31:49.030
<v Speaker 1>it's 30 years of research code.</v>
<v Speaker 1>If anybody's dealt with research code,</v>

516
00:31:49.031 --> 00:31:54.031
<v Speaker 1>it's 30 years of C and c plus plus with </v>
<v Speaker 1>dozens of graduate students over time.</v>

517
00:31:55.510 --> 00:31:57.830
<v Speaker 1>It's not pretty at all.</v>
<v Speaker 1>Uh,</v>

518
00:31:57.840 --> 00:31:59.210
<v Speaker 1>and,</v>
<v Speaker 1>and theoretically it's,</v>

519
00:31:59.220 --> 00:32:01.450
<v Speaker 1>it's got these boxes sitting out here.</v>
<v Speaker 1>And so,</v>

520
00:32:01.610 --> 00:32:04.960
<v Speaker 1>uh,</v>
<v Speaker 1>he re implemented the core functionality</v>

521
00:32:04.961 --> 00:32:09.961
<v Speaker 1>of sore all using factor graphs and </v>
<v Speaker 1>message passing algorithms under the </v>

522
00:32:09.961 --> 00:32:14.521
<v Speaker 1>hood.</v>
<v Speaker 1>He got to that point and then said </v>

523
00:32:14.521 --> 00:32:14.830
<v Speaker 1>there's nothing stopping me from going </v>
<v Speaker 1>further.</v>

524
00:32:15.010 --> 00:32:18.130
<v Speaker 1>And so now it can do all sorts of modern</v>
<v Speaker 1>machine learning,</v>

525
00:32:18.131 --> 00:32:22.450
<v Speaker 1>vision optimization,</v>
<v Speaker 1>sort of things that would take some time</v>

526
00:32:22.451 --> 00:32:25.240
<v Speaker 1>in any other architecture to be able to </v>
<v Speaker 1>integrate well.</v>

527
00:32:25.750 --> 00:32:26.700
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

528
00:32:26.710 --> 00:32:29.010
<v Speaker 1>it's been an interesting experience.</v>
<v Speaker 1>Uh,</v>

529
00:32:29.020 --> 00:32:34.020
<v Speaker 1>it's now going to be the basis for the </v>
<v Speaker 1>virtual human project out at the </v>

530
00:32:34.020 --> 00:32:37.921
<v Speaker 1>institute for creative technology.</v>
<v Speaker 1>It's a institute associated with the </v>

531
00:32:37.921 --> 00:32:41.310
<v Speaker 1>University of southern California for,</v>
<v Speaker 1>until recently could get your hands on </v>

532
00:32:41.451 --> 00:32:46.451
<v Speaker 1>it,</v>
<v Speaker 1>but in the last couple of years he's </v>

533
00:32:46.451 --> 00:32:48.280
<v Speaker 1>done some tutorials on it.</v>
<v Speaker 1>He's got a public release with </v>

534
00:32:48.280 --> 00:32:51.250
<v Speaker 1>documentation.</v>
<v Speaker 1>So that's something interesting to keep </v>

535
00:32:51.250 --> 00:32:54.371
<v Speaker 1>an eye on what I'm going to spend all </v>
<v Speaker 1>the remaining time on the sore cognitive</v>

536
00:32:54.531 --> 00:32:56.660
<v Speaker 1>architecture.</v>
<v Speaker 1>And so you see,</v>

537
00:32:56.900 --> 00:33:00.350
<v Speaker 1>it looks quite a bit like the </v>
<v Speaker 1>prototypical architecture.</v>

538
00:33:00.351 --> 00:33:02.240
<v Speaker 1>And I'll,</v>
<v Speaker 1>I'll give you a sentence again about how</v>

539
00:33:02.241 --> 00:33:05.480
<v Speaker 1>this all operates.</v>
<v Speaker 1>Give a sense of the people involved.</v>

540
00:33:05.670 --> 00:33:07.670
<v Speaker 1>Uh,</v>
<v Speaker 1>we already talked about Alan Newell.</v>

541
00:33:07.671 --> 00:33:12.671
<v Speaker 1>So both John Laird,</v>
<v Speaker 1>who is my advisor and Paul Rosenbloom </v>

542
00:33:12.671 --> 00:33:14.730
<v Speaker 1>were students of Allan Newell.</v>
<v Speaker 1>Uh,</v>

543
00:33:14.900 --> 00:33:19.900
<v Speaker 1>John's thesis project was related to the</v>
<v Speaker 1>chunking mechanism and soar,</v>

544
00:33:21.051 --> 00:33:24.950
<v Speaker 1>which learns new rules based upon </v>
<v Speaker 1>subgoal reasoning.</v>

545
00:33:25.760 --> 00:33:27.590
<v Speaker 1>Uh,</v>
<v Speaker 1>so he finished that,</v>

546
00:33:27.980 --> 00:33:32.980
<v Speaker 1>I believe the year I was born,</v>
<v Speaker 1>and so he's one of the few researchers </v>

547
00:33:33.711 --> 00:33:37.580
<v Speaker 1>you'll find who still actively working </v>
<v Speaker 1>on their thesis project,</v>

548
00:33:37.980 --> 00:33:40.600
<v Speaker 1>uh,</v>
<v Speaker 1>beyond that,</v>

549
00:33:40.640 --> 00:33:42.950
<v Speaker 1>about I think about 10 years ago.</v>
<v Speaker 1>He,</v>

550
00:33:43.040 --> 00:33:44.270
<v Speaker 1>it.</v>
<v Speaker 1>So our technology,</v>

551
00:33:44.271 --> 00:33:49.271
<v Speaker 1>which is company up in Ann Arbor,</v>
<v Speaker 1>Michigan a while it was called soar </v>

552
00:33:49.271 --> 00:33:49.410
<v Speaker 1>technology,</v>
<v Speaker 1>it doesn't do exclusively sore,</v>

553
00:33:49.420 --> 00:33:54.020
<v Speaker 1>but that's a part of the portfolio,</v>
<v Speaker 1>a general intelligence system stuff,</v>

554
00:33:54.021 --> 00:33:58.310
<v Speaker 1>a lot of defense association.</v>
<v Speaker 1>So,</v>

555
00:33:58.370 --> 00:34:03.370
<v Speaker 1>uh,</v>
<v Speaker 1>some notes of what's going to make sore </v>

556
00:34:03.370 --> 00:34:05.411
<v Speaker 1>different from the other architectures </v>
<v Speaker 1>that fall into this kind of functional </v>

557
00:34:05.411 --> 00:34:06.060
<v Speaker 1>architecture category.</v>
<v Speaker 1>Uh,</v>

558
00:34:06.170 --> 00:34:11.170
<v Speaker 1>a big thing is a focus on efficiency.</v>
<v Speaker 1>So John wants to be able to run sore on </v>

559
00:34:11.170 --> 00:34:15.010
<v Speaker 1>just about anything.</v>
<v Speaker 1>We just got on the mailing list,</v>

560
00:34:15.230 --> 00:34:20.230
<v Speaker 1>a desire to run it on a real time </v>
<v Speaker 1>processor and our answer,</v>

561
00:34:20.661 --> 00:34:23.990
<v Speaker 1>while we had never done it before,</v>
<v Speaker 1>it was probably,</v>

562
00:34:23.991 --> 00:34:25.470
<v Speaker 1>it'll work,</v>
<v Speaker 1>uh,</v>

563
00:34:25.610 --> 00:34:28.670
<v Speaker 1>every release,</v>
<v Speaker 1>there's timing tests and we always,</v>

564
00:34:29.270 --> 00:34:34.270
<v Speaker 1>what we,</v>
<v Speaker 1>what we look at is in a bunch of </v>

565
00:34:34.270 --> 00:34:36.311
<v Speaker 1>different domains for a bunch of </v>
<v Speaker 1>different reasons that relate to human </v>

566
00:34:36.311 --> 00:34:36.311
<v Speaker 1>processing.</v>

567
00:34:36.311 --> 00:34:37.400
<v Speaker 1>There's this magic number that comes out</v>
<v Speaker 1>which is 50 milliseconds,</v>

568
00:34:37.760 --> 00:34:41.990
<v Speaker 1>which is to say in terms of responding </v>
<v Speaker 1>to tasks,</v>

569
00:34:42.140 --> 00:34:44.150
<v Speaker 1>if you're above that time,</v>
<v Speaker 1>uh,</v>

570
00:34:44.240 --> 00:34:47.840
<v Speaker 1>humans will sense a delay and you don't </v>
<v Speaker 1>want that to happen.</v>

571
00:34:48.020 --> 00:34:49.790
<v Speaker 1>Now,</v>
<v Speaker 1>if we're working in a robotics task,</v>

572
00:34:49.791 --> 00:34:52.700
<v Speaker 1>50 milliseconds,</v>
<v Speaker 1>if you're dramatically above that,</v>

573
00:34:52.701 --> 00:34:56.600
<v Speaker 1>you just fell off the curb or worse or </v>
<v Speaker 1>you just hit somebody in a car.</v>

574
00:34:56.601 --> 00:34:57.580
<v Speaker 1>Right?</v>
<v Speaker 1>So we're,</v>

575
00:34:57.581 --> 00:35:01.490
<v Speaker 1>we're trying to keep that as low as </v>
<v Speaker 1>possible and for most agents it,</v>

576
00:35:01.520 --> 00:35:06.520
<v Speaker 1>it doesn't even register.</v>
<v Speaker 1>It's below one millisecond fractions of </v>

577
00:35:06.520 --> 00:35:07.880
<v Speaker 1>a millisecond.</v>
<v Speaker 1>But I'll come back to this because a lot</v>

578
00:35:07.881 --> 00:35:10.460
<v Speaker 1>of the work that I was doing was </v>
<v Speaker 1>computer science,</v>

579
00:35:10.461 --> 00:35:11.960
<v Speaker 1>Ai,</v>
<v Speaker 1>uh,</v>

580
00:35:11.970 --> 00:35:16.970
<v Speaker 1>and,</v>
<v Speaker 1>and a lot of efficient algorithms and </v>

581
00:35:16.970 --> 00:35:17.180
<v Speaker 1>data structures and 50 milliseconds was </v>
<v Speaker 1>that very high upper bound.</v>

582
00:35:18.380 --> 00:35:21.080
<v Speaker 1>It's also one of the projects that has a</v>
<v Speaker 1>public distribution.</v>

583
00:35:21.080 --> 00:35:23.990
<v Speaker 1>You can get it in all sorts of operating</v>
<v Speaker 1>systems.</v>

584
00:35:24.770 --> 00:35:29.770
<v Speaker 1>We use something called Swig that allows</v>
<v Speaker 1>you to interface with it and a bunch of </v>

585
00:35:29.770 --> 00:35:32.801
<v Speaker 1>different languages.</v>
<v Speaker 1>We kind of described the Meta </v>

586
00:35:32.801 --> 00:35:34.421
<v Speaker 1>description and you are able to </v>
<v Speaker 1>basically generate bindings and a bunch </v>

587
00:35:34.421 --> 00:35:37.380
<v Speaker 1>of different platforms.</v>
<v Speaker 1>A core of plus,</v>

588
00:35:37.381 --> 00:35:41.220
<v Speaker 1>plus there was a team at soar attack </v>
<v Speaker 1>that said we don't like c Plus,</v>

589
00:35:41.221 --> 00:35:45.210
<v Speaker 1>plus it gets messy,</v>
<v Speaker 1>so they actually did a port over to pure</v>

590
00:35:45.240 --> 00:35:50.240
<v Speaker 1>Java in case that appeals to you.</v>
<v Speaker 1>There's an annual workshop that takes </v>

591
00:35:50.251 --> 00:35:53.370
<v Speaker 1>place in anarbor.</v>
<v Speaker 1>Typically it's free.</v>

592
00:35:54.150 --> 00:35:59.150
<v Speaker 1>You can go there and get a sore tutorial</v>
<v Speaker 1>and talked to folks who are working on </v>

593
00:35:59.150 --> 00:36:00.300
<v Speaker 1>sore and it's fun.</v>
<v Speaker 1>I've been there every year,</v>

594
00:36:00.301 --> 00:36:05.301
<v Speaker 1>but wine in the last decade.</v>
<v Speaker 1>It's just fun to see the people around </v>

595
00:36:05.301 --> 00:36:08.001
<v Speaker 1>the world better using the system and </v>
<v Speaker 1>all sorts of interesting ways to give </v>

596
00:36:08.311 --> 00:36:10.110
<v Speaker 1>you a sense of the diversity of the </v>
<v Speaker 1>applications.</v>

597
00:36:10.110 --> 00:36:15.110
<v Speaker 1>One of the first was our one store,</v>
<v Speaker 1>which was back in the days when it was </v>

598
00:36:15.110 --> 00:36:19.341
<v Speaker 1>an actual challenge to build a computer,</v>
<v Speaker 1>which is to say that your choice of </v>

599
00:36:19.341 --> 00:36:24.200
<v Speaker 1>certain components would have radical </v>
<v Speaker 1>implications for other parts of the </v>

600
00:36:24.200 --> 00:36:26.280
<v Speaker 1>computer,</v>
<v Speaker 1>so it wasn't just the Dell website where</v>

601
00:36:26.281 --> 00:36:27.690
<v Speaker 1>you just,</v>
<v Speaker 1>I want this much ram,</v>

602
00:36:27.691 --> 00:36:32.691
<v Speaker 1>I want this much cpu.</v>
<v Speaker 1>There was a lot of thinking that went </v>

603
00:36:32.691 --> 00:36:35.181
<v Speaker 1>behind it and then physical Labor that </v>
<v Speaker 1>went to construct your computer and so </v>

604
00:36:35.181 --> 00:36:38.460
<v Speaker 1>it was making that process a lot better.</v>
<v Speaker 1>There are folks that apply it to natural</v>

605
00:36:38.461 --> 00:36:43.461
<v Speaker 1>language processing.</v>
<v Speaker 1>A source seven was the core of the </v>

606
00:36:43.461 --> 00:36:46.050
<v Speaker 1>virtual humans project for a long time.</v>
<v Speaker 1>Hci Tasks,</v>

607
00:36:46.450 --> 00:36:49.110
<v Speaker 1>TAC air soar was one of the largest rule</v>
<v Speaker 1>based systems,</v>

608
00:36:49.440 --> 00:36:51.990
<v Speaker 1>tens of thousands of rules over 48 </v>
<v Speaker 1>hours.</v>

609
00:36:51.991 --> 00:36:56.070
<v Speaker 1>It was a very large scale simulation,</v>
<v Speaker 1>a defense simulation,</v>

610
00:36:56.310 --> 00:36:59.550
<v Speaker 1>lots of games it's been applied to for </v>
<v Speaker 1>various reasons.</v>

611
00:37:00.460 --> 00:37:04.800
<v Speaker 1>And then in the last few years putting </v>
<v Speaker 1>it onto mobile robotics platforms.</v>

612
00:37:04.801 --> 00:37:08.940
<v Speaker 1>This is Edwin Olson's.</v>
<v Speaker 1>A splinter bought an early version of it</v>

613
00:37:08.941 --> 00:37:11.400
<v Speaker 1>that went on to win the magic </v>
<v Speaker 1>competition.</v>

614
00:37:12.470 --> 00:37:17.200
<v Speaker 1>Uh,</v>
<v Speaker 1>then I went onto put sore on the web and</v>

615
00:37:17.260 --> 00:37:22.260
<v Speaker 1>if after this talk,</v>
<v Speaker 1>you're really interested in a dice game </v>

616
00:37:22.260 --> 00:37:24.550
<v Speaker 1>that I'm going to talk about what you </v>
<v Speaker 1>can actually go to the ios app store and</v>

617
00:37:24.551 --> 00:37:26.350
<v Speaker 1>download.</v>
<v Speaker 1>It's called Michigan Liar's dice.</v>

618
00:37:26.351 --> 00:37:28.360
<v Speaker 1>It's free.</v>
<v Speaker 1>You don't have to pay for it,</v>

619
00:37:28.570 --> 00:37:33.570
<v Speaker 1>but you can actually play a liar's dice </v>
<v Speaker 1>with soar and it's.</v>

620
00:37:33.760 --> 00:37:36.340
<v Speaker 1>You can set the difficulty level.</v>
<v Speaker 1>It's pretty good.</v>

621
00:37:36.570 --> 00:37:40.800
<v Speaker 1>It beats me on a regular basis.</v>
<v Speaker 1>I wanted to give you a couple other just</v>

622
00:37:40.801 --> 00:37:45.801
<v Speaker 1>kind of really weird feeling sort of </v>
<v Speaker 1>applications and really cool </v>

623
00:37:45.801 --> 00:37:49.200
<v Speaker 1>applications.</v>
<v Speaker 1>The first one is out of Georgia tech.</v>

624
00:37:49.910 --> 00:37:51.110
<v Speaker 1>Go powerpoint.</v>
<v Speaker 1>Yes.</v>

625
00:37:58.580 --> 00:38:03.580
<v Speaker 3>Interactive art installation in which </v>
<v Speaker 3>you can engage in collaborative </v>

626
00:38:03.911 --> 00:38:08.911
<v Speaker 3>movement,</v>
<v Speaker 3>improvisation with each other and </v>

627
00:38:08.911 --> 00:38:11.251
<v Speaker 3>virtual dance partners.</v>
<v Speaker 3>This actually creates a hybrid space in </v>

628
00:38:11.281 --> 00:38:16.281
<v Speaker 3>which virtual and corporate real bodies </v>
<v Speaker 3>meet for human and nonhuman is blurred </v>

629
00:38:17.740 --> 00:38:21.570
<v Speaker 3>staring contest as to examine their </v>
<v Speaker 3>relationship with technology.</v>

630
00:38:23.010 --> 00:38:28.010
<v Speaker 3>Installation ultimately examines how </v>
<v Speaker 3>humans and machine can cocreate </v>

631
00:38:28.010 --> 00:38:32.440
<v Speaker 3>experiences in a playful environment.</v>
<v Speaker 3>It creates a social space that </v>

632
00:38:34.030 --> 00:38:38.110
<v Speaker 3>encourages human interaction and </v>
<v Speaker 3>collected dance experiences,</v>

633
00:38:38.500 --> 00:38:42.520
<v Speaker 3>allowing them to send this to creatively</v>
<v Speaker 3>explore movement while having fun.</v>

634
00:38:43.870 --> 00:38:44.890
<v Speaker 2>The development</v>

635
00:38:45.070 --> 00:38:50.070
<v Speaker 3>and I had been a hybrid exploration and </v>
<v Speaker 3>art forms of theater and dance as well </v>

636
00:38:50.271 --> 00:38:53.810
<v Speaker 3>as research and artificial intelligence </v>
<v Speaker 3>and cognitive science.</v>

637
00:38:55.750 --> 00:38:58.850
<v Speaker 3>Moving on.</v>
<v Speaker 3>Inspiration from the ancient art form,</v>

638
00:38:58.851 --> 00:39:03.851
<v Speaker 3>a shadow here,</v>
<v Speaker 3>the original two dimensional version of </v>

639
00:39:03.851 --> 00:39:06.110
<v Speaker 3>the installation.</v>
<v Speaker 3>Let us the conceptualization of the dome</v>

640
00:39:06.111 --> 00:39:11.111
<v Speaker 3>and the liminal space when human </v>
<v Speaker 3>silhouettes and virtual characters </v>

641
00:39:11.111 --> 00:39:13.430
<v Speaker 3>meaning dance together on the projection</v>
<v Speaker 3>surface,</v>

642
00:39:14.980 --> 00:39:18.900
<v Speaker 3>rather than rely on preoperative library</v>
<v Speaker 3>of responses,</v>

643
00:39:19.390 --> 00:39:24.390
<v Speaker 3>the virtual dancer learns his partner </v>
<v Speaker 3>and utilize new theories and </v>

644
00:39:24.600 --> 00:39:29.600
<v Speaker 3>systematically reason about them in </v>
<v Speaker 3>order to choose under response.</v>

645
00:39:30.620 --> 00:39:35.620
<v Speaker 3>The points theory is based in dance and </v>
<v Speaker 3>theater and performance along the </v>

646
00:39:35.741 --> 00:39:39.700
<v Speaker 3>dimension,</v>
<v Speaker 3>the tempo reputation,</v>

647
00:39:39.970 --> 00:39:44.040
<v Speaker 3>kinesthetic response,</v>
<v Speaker 3>shape station relationships,</v>

648
00:39:44.080 --> 00:39:47.060
<v Speaker 3>gesture architecture,</v>
<v Speaker 3>and your topic.</v>

649
00:39:47.130 --> 00:39:52.130
<v Speaker 3>Be Virtual.</v>
<v Speaker 3>Dancer is able to use several different </v>

650
00:39:52.130 --> 00:39:56.791
<v Speaker 3>strategies to respond to human rights.</v>
<v Speaker 3>These include transformation and he </v>

651
00:39:59.240 --> 00:40:04.240
<v Speaker 3>mentions for calling it similar or </v>
<v Speaker 3>complimentary movement from memory in </v>

652
00:40:04.240 --> 00:40:08.581
<v Speaker 3>terms of viewpoints,</v>
<v Speaker 3>admissions and apply action response </v>

653
00:40:08.581 --> 00:40:10.210
<v Speaker 3>patterns that the Asian consumer.</v>

654
00:40:14.750 --> 00:40:19.750
<v Speaker 4>This is part of a larger effort from </v>
<v Speaker 4>setting the relationship between </v>

655
00:40:19.750 --> 00:40:24.441
<v Speaker 4>communication,</v>
<v Speaker 4>cognition and creativity where a large </v>

656
00:40:24.441 --> 00:40:28.980
<v Speaker 4>amount of our efforts go into </v>
<v Speaker 4>understanding human creativity and how </v>

657
00:40:28.980 --> 00:40:31.910
<v Speaker 4>we make things together.</v>
<v Speaker 4>Our work together as a way to understand</v>

658
00:40:31.920 --> 00:40:36.920
<v Speaker 4>how we can build cocreative ai that </v>
<v Speaker 4>serves the same purpose where it could </v>

659
00:40:37.561 --> 00:40:41.160
<v Speaker 4>be a colleague and collaborator with us </v>
<v Speaker 4>and create things with us.</v>

660
00:40:47.730 --> 00:40:52.730
<v Speaker 1>Uh,</v>
<v Speaker 1>so brian was a graduate student in John </v>

661
00:40:52.730 --> 00:40:53.930
<v Speaker 1>Lyric lab as well.</v>
<v Speaker 1>Uh,</v>

662
00:40:54.240 --> 00:40:59.240
<v Speaker 1>before I start this,</v>
<v Speaker 1>I alluded to this earlier where we're </v>

663
00:40:59.240 --> 00:41:00.870
<v Speaker 1>getting closer to rosie saying,</v>
<v Speaker 1>can you teach me?</v>

664
00:41:01.020 --> 00:41:02.760
<v Speaker 1>So let me give you some introduction to </v>
<v Speaker 1>this.</v>

665
00:41:02.820 --> 00:41:07.820
<v Speaker 1>In the lower left,</v>
<v Speaker 1>you're seeing the view of a connect </v>

666
00:41:07.820 --> 00:41:08.980
<v Speaker 1>camera onto a flat surface.</v>
<v Speaker 1>There's a,</v>

667
00:41:09.720 --> 00:41:12.720
<v Speaker 1>a robotic arm,</v>
<v Speaker 1>mainly three d printed parts,</v>

668
00:41:12.721 --> 00:41:14.670
<v Speaker 1>few Servos,</v>
<v Speaker 1>uh,</v>

669
00:41:14.750 --> 00:41:19.750
<v Speaker 1>above that.</v>
<v Speaker 1>You're seeing an interpretation of the </v>

670
00:41:19.750 --> 00:41:22.881
<v Speaker 1>scene a,</v>
<v Speaker 1>we're giving it a kind of associations </v>

671
00:41:22.881 --> 00:41:24.210
<v Speaker 1>of the four areas with semantic titles </v>
<v Speaker 1>like,</v>

672
00:41:24.840 --> 00:41:26.280
<v Speaker 1>uh,</v>
<v Speaker 1>one is the table,</v>

673
00:41:26.281 --> 00:41:30.270
<v Speaker 1>one is the garbage,</v>
<v Speaker 1>just just semantic terms for areas.</v>

674
00:41:30.450 --> 00:41:33.030
<v Speaker 1>But other than that,</v>
<v Speaker 1>the agent doesn't actually know all that</v>

675
00:41:33.050 --> 00:41:35.930
<v Speaker 1>much and it's going to operate in two </v>
<v Speaker 1>modalities.</v>

676
00:41:35.931 --> 00:41:38.180
<v Speaker 1>One is,</v>
<v Speaker 1>we'll call it natural language,</v>

677
00:41:38.210 --> 00:41:43.210
<v Speaker 1>natural language,</v>
<v Speaker 1>a restricted subset of English as well </v>

678
00:41:44.181 --> 00:41:45.980
<v Speaker 1>as some quote unquote pointing.</v>

679
00:41:45.980 --> 00:41:49.700
<v Speaker 1>So you're going to see some mouse </v>
<v Speaker 1>pointers in the upper left saying,</v>

680
00:41:49.820 --> 00:41:51.330
<v Speaker 1>I'm talking about this.</v>
<v Speaker 1>Uh,</v>

681
00:41:51.340 --> 00:41:53.960
<v Speaker 1>and this is just a way to indicate </v>
<v Speaker 1>location.</v>

682
00:41:54.410 --> 00:41:56.600
<v Speaker 1>And so starting off we're going to say </v>
<v Speaker 1>things like,</v>

683
00:41:56.630 --> 00:41:58.400
<v Speaker 1>you know,</v>
<v Speaker 1>pick up the blue block and it's going to</v>

684
00:41:58.401 --> 00:42:00.140
<v Speaker 1>be like,</v>
<v Speaker 1>I don't know what blue is,</v>

685
00:42:00.170 --> 00:42:02.090
<v Speaker 1>what is blue?</v>
<v Speaker 1>And we say,</v>

686
00:42:02.091 --> 00:42:03.170
<v Speaker 1>oh,</v>
<v Speaker 1>well that's a color.</v>

687
00:42:03.380 --> 00:42:04.830
<v Speaker 1>Okay.</v>
<v Speaker 1>Uh,</v>

688
00:42:05.090 --> 00:42:08.480
<v Speaker 1>you know,</v>
<v Speaker 1>so go get the green thing.</v>

689
00:42:08.510 --> 00:42:09.320
<v Speaker 1>What's green?</v>
<v Speaker 1>Oh,</v>

690
00:42:09.321 --> 00:42:10.160
<v Speaker 1>it's a color.</v>
<v Speaker 1>Okay.</v>

691
00:42:10.370 --> 00:42:15.370
<v Speaker 1>Uh,</v>
<v Speaker 1>move the blue thing to a particular </v>

692
00:42:15.370 --> 00:42:15.370
<v Speaker 1>location.</v>
<v Speaker 1>Where's that point at?</v>

693
00:42:15.370 --> 00:42:20.111
<v Speaker 1>Okay,</v>
<v Speaker 1>what is moving like really it has to </v>

694
00:42:20.111 --> 00:42:20.870
<v Speaker 1>start from the beginning and it's </v>
<v Speaker 1>described and it said,</v>

695
00:42:20.871 --> 00:42:22.220
<v Speaker 1>okay,</v>
<v Speaker 1>now you finished.</v>

696
00:42:23.420 --> 00:42:28.420
<v Speaker 1>And once we got to that point,</v>
<v Speaker 1>now I can say move the green thing over </v>

697
00:42:28.420 --> 00:42:29.360
<v Speaker 1>here.</v>
<v Speaker 1>And it's got everything that it needs to</v>

698
00:42:29.361 --> 00:42:32.390
<v Speaker 1>be able to then reproduce the task given</v>
<v Speaker 1>a new parameters.</v>

699
00:42:32.480 --> 00:42:36.980
<v Speaker 1>And it's learned that ability.</v>
<v Speaker 1>So let me give it a little bit of time.</v>

700
00:42:39.020 --> 00:42:44.020
<v Speaker 1>Oh,</v>
<v Speaker 1>uh,</v>

701
00:42:45.620 --> 00:42:48.740
<v Speaker 1>so you can look a little bit at top left</v>
<v Speaker 1>in terms of the pointers.</v>

702
00:42:48.741 --> 00:42:51.890
<v Speaker 1>You're going to see some text commands </v>
<v Speaker 1>being entered.</v>

703
00:42:54.080 --> 00:42:57.440
<v Speaker 1>So what kind of attributes is blue?</v>
<v Speaker 1>We're going to say it's a color.</v>

704
00:42:57.680 --> 00:43:00.800
<v Speaker 1>And so that can map it then to a </v>
<v Speaker 1>particular sensory modality.</v>

705
00:43:01.940 --> 00:43:06.940
<v Speaker 1>This is green.</v>
<v Speaker 1>So the pointing what kind of thing is </v>

706
00:43:06.940 --> 00:43:06.940
<v Speaker 1>green,</v>
<v Speaker 1>okay,</v>

707
00:43:06.940 --> 00:43:10.211
<v Speaker 1>color.</v>
<v Speaker 1>So now it knows how to understand blue </v>

708
00:43:10.211 --> 00:43:10.211
<v Speaker 1>and green as colors with respect to the </v>
<v Speaker 1>visual scene.</v>

709
00:43:10.520 --> 00:43:13.730
<v Speaker 1>Um,</v>
<v Speaker 1>move rectangle to the table.</v>

710
00:43:14.870 --> 00:43:17.570
<v Speaker 1>Uh,</v>
<v Speaker 1>what is rectangle?</v>

711
00:43:17.571 --> 00:43:20.510
<v Speaker 1>Okay,</v>
<v Speaker 1>now I can map that onto or understanding</v>

712
00:43:20.900 --> 00:43:23.150
<v Speaker 1>parts of the world.</v>
<v Speaker 1>Is this the blue rectangle?</v>

713
00:43:23.151 --> 00:43:28.100
<v Speaker 1>So the arm is actually pointing itself </v>
<v Speaker 1>to get confirmation from the instructor.</v>

714
00:43:28.500 --> 00:43:33.500
<v Speaker 1>Uh,</v>
<v Speaker 1>and then we're trying to understand in </v>

715
00:43:33.500 --> 00:43:33.500
<v Speaker 1>general,</v>
<v Speaker 1>when you say move something,</v>

716
00:43:33.500 --> 00:43:37.091
<v Speaker 1>what is the goal of this operation?</v>
<v Speaker 1>And so then it also has to declare of </v>

717
00:43:37.091 --> 00:43:39.950
<v Speaker 1>representation of the idea of this task,</v>
<v Speaker 1>not only that had completed it,</v>

718
00:43:40.220 --> 00:43:45.220
<v Speaker 1>then it can look back on having </v>
<v Speaker 1>completed the task and understand what </v>

719
00:43:45.220 --> 00:43:47.030
<v Speaker 1>were the steps that lead to achieving a </v>
<v Speaker 1>particular goal.</v>

720
00:43:50.780 --> 00:43:53.450
<v Speaker 1>So in order to move it,</v>
<v Speaker 1>you're gonna have to pick it up.</v>

721
00:43:54.260 --> 00:43:59.260
<v Speaker 1>It knows which one the blue thing is.</v>
<v Speaker 1>Great.</v>

722
00:44:04.400 --> 00:44:08.330
<v Speaker 1>Now put it in the table.</v>
<v Speaker 1>So that's a particular location.</v>

723
00:44:09.970 --> 00:44:14.970
<v Speaker 1>At this point we can say you're done.</v>
<v Speaker 1>You have accomplished the move the blue </v>

724
00:44:14.970 --> 00:44:19.360
<v Speaker 1>rectangle to the table.</v>
<v Speaker 1>And so I can understand what that very </v>

725
00:44:19.360 --> 00:44:23.111
<v Speaker 1>simple kind of processes like and </v>
<v Speaker 1>associate that with the verb to move and</v>

726
00:44:25.510 --> 00:44:30.510
<v Speaker 1>now we can say move the green object or </v>
<v Speaker 1>not doing the garbage and without any </v>

727
00:44:35.340 --> 00:44:40.320
<v Speaker 1>further interaction based on everything </v>
<v Speaker 1>that I've learned up until that point,</v>

728
00:44:40.350 --> 00:44:45.350
<v Speaker 1>it can successfully complete that task.</v>
<v Speaker 1>So this is a work of Shivali Mohan and </v>

729
00:44:45.350 --> 00:44:49.731
<v Speaker 1>others at the soar group at the </v>
<v Speaker 1>University of Michigan on the rosy </v>

730
00:44:49.731 --> 00:44:53.571
<v Speaker 1>project and they were extending this to </v>
<v Speaker 1>playing games and learning the rules of </v>

731
00:44:53.571 --> 00:44:56.730
<v Speaker 1>games through a tech space descriptions </v>
<v Speaker 1>and multimodal experience.</v>

732
00:44:57.960 --> 00:44:58.950
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

733
00:44:59.100 --> 00:45:00.690
<v Speaker 1>in order to build up to here's a story.</v>

734
00:45:00.690 --> 00:45:03.600
<v Speaker 1>And so I wanted to give you a sense of </v>
<v Speaker 1>how research occurs in the group.</v>

735
00:45:03.930 --> 00:45:08.490
<v Speaker 1>And so there's these back and forth that</v>
<v Speaker 1>occur over time between,</v>

736
00:45:08.760 --> 00:45:13.760
<v Speaker 1>there's this piece of software called </v>
<v Speaker 1>soar and we want to make this thing </v>

737
00:45:13.760 --> 00:45:16.461
<v Speaker 1>better and give it new capabilities.</v>
<v Speaker 1>And so all our agents are going to </v>

738
00:45:16.461 --> 00:45:17.310
<v Speaker 1>become better.</v>
<v Speaker 1>And we always have to keep in mind,</v>

739
00:45:17.311 --> 00:45:22.311
<v Speaker 1>and you'll see this as I go further,</v>
<v Speaker 1>that it has to be useful to a wide </v>

740
00:45:22.311 --> 00:45:25.410
<v Speaker 1>variety of agents.</v>
<v Speaker 1>It has to be task independent and it has</v>

741
00:45:25.411 --> 00:45:27.600
<v Speaker 1>to be efficient for us to do anything in</v>
<v Speaker 1>the architecture.</v>

742
00:45:27.601 --> 00:45:32.601
<v Speaker 1>All of those have to hold true,</v>
<v Speaker 1>so we do something cool in the </v>

743
00:45:32.601 --> 00:45:33.160
<v Speaker 1>architecture and they,</v>
<v Speaker 1>we say,</v>

744
00:45:33.161 --> 00:45:34.830
<v Speaker 1>okay,</v>
<v Speaker 1>let's solve a cool problem.</v>

745
00:45:35.250 --> 00:45:39.000
<v Speaker 1>So let's build some agents to do this.</v>
<v Speaker 1>And so this ends up testing what are the</v>

746
00:45:39.001 --> 00:45:41.790
<v Speaker 1>limitations,</v>
<v Speaker 1>what are the issues that arise,</v>

747
00:45:41.990 --> 00:45:46.990
<v Speaker 1>uh,</v>
<v Speaker 1>in a particular mechanism as well as </v>

748
00:45:46.990 --> 00:45:46.990
<v Speaker 1>integration with others.</v>

749
00:45:46.990 --> 00:45:50.780
<v Speaker 1>Uh,</v>
<v Speaker 1>and we get to solve interesting </v>

750
00:45:50.780 --> 00:45:52.011
<v Speaker 1>problems.</v>
<v Speaker 1>We usually find there was something </v>

751
00:45:52.011 --> 00:45:52.011
<v Speaker 1>missing and then we can go back to the </v>
<v Speaker 1>architecture and rinse and repeat.</v>

752
00:45:53.010 --> 00:45:55.470
<v Speaker 1>Just to give you an idea again how sore </v>
<v Speaker 1>works.</v>

753
00:45:55.650 --> 00:45:58.770
<v Speaker 1>So the working memory is actually a </v>
<v Speaker 1>directed connected graph.</v>

754
00:45:59.370 --> 00:46:02.250
<v Speaker 1>The perception is just a subset of that </v>
<v Speaker 1>graph.</v>

755
00:46:02.251 --> 00:46:05.910
<v Speaker 1>And so there's going to be symbolic </v>
<v Speaker 1>representations of most of the world.</v>

756
00:46:06.260 --> 00:46:09.180
<v Speaker 1>There is a visual subsystem in which you</v>
<v Speaker 1>can provide a scene graph.</v>

757
00:46:09.310 --> 00:46:12.240
<v Speaker 1>I'm just not showing it here.</v>
<v Speaker 1>Uh,</v>

758
00:46:12.241 --> 00:46:14.610
<v Speaker 1>actions are also a subset of that graph.</v>
<v Speaker 1>And so,</v>

759
00:46:14.850 --> 00:46:16.830
<v Speaker 1>uh,</v>
<v Speaker 1>the procedural knowledge,</v>

760
00:46:16.831 --> 00:46:19.010
<v Speaker 1>which is also production rules can </v>
<v Speaker 1>modify.</v>

761
00:46:19.011 --> 00:46:22.200
<v Speaker 1>It can read sections of the input,</v>
<v Speaker 1>modify sections of the output as well as</v>

762
00:46:22.201 --> 00:46:24.930
<v Speaker 1>arbitrary parts of the graph to take </v>
<v Speaker 1>actions.</v>

763
00:46:25.200 --> 00:46:30.200
<v Speaker 1>So the decision procedure says,</v>
<v Speaker 1>of all the things that I know to do and </v>

764
00:46:30.200 --> 00:46:30.930
<v Speaker 1>I've kind of ranked them according to </v>
<v Speaker 1>various preferences,</v>

765
00:46:31.290 --> 00:46:32.850
<v Speaker 1>what single thing should I do?</v>

766
00:46:33.750 --> 00:46:37.920
<v Speaker 1>A semantic memory for facts.</v>
<v Speaker 1>There's episodic memory.</v>

767
00:46:38.070 --> 00:46:42.750
<v Speaker 1>The agent is always actually storing </v>
<v Speaker 1>every experience it's ever had over time</v>

768
00:46:42.751 --> 00:46:45.270
<v Speaker 1>and episodic memory and it has the </v>
<v Speaker 1>ability to get back to that.</v>

769
00:46:45.840 --> 00:46:50.840
<v Speaker 1>And so the similar cycle we saw before </v>
<v Speaker 1>we get input in the perception called </v>

770
00:46:50.840 --> 00:46:54.300
<v Speaker 1>the input link rules are going to fire </v>
<v Speaker 1>all in parallel and say,</v>

771
00:46:54.390 --> 00:46:55.950
<v Speaker 1>here's everything I know about this </v>
<v Speaker 1>situation.</v>

772
00:46:55.951 --> 00:46:58.860
<v Speaker 1>Here's all the things I could do.</v>
<v Speaker 1>Decision Procedure says,</v>

773
00:46:59.160 --> 00:47:03.720
<v Speaker 1>here's what we're going to do based on </v>
<v Speaker 1>the selected operator.</v>

774
00:47:04.020 --> 00:47:08.160
<v Speaker 1>All sorts of things could happen with </v>
<v Speaker 1>respect to memories providing input,</v>

775
00:47:08.360 --> 00:47:13.020
<v Speaker 1>a rules firing to perform computations,</v>
<v Speaker 1>and as well as potentially output in the</v>

776
00:47:13.021 --> 00:47:15.240
<v Speaker 1>world.</v>
<v Speaker 1>Uh,</v>

777
00:47:15.510 --> 00:47:17.910
<v Speaker 1>I don't remember.</v>
<v Speaker 1>Agent reactivity is required.</v>

778
00:47:18.120 --> 00:47:23.120
<v Speaker 1>We want the system to be able to react </v>
<v Speaker 1>to things in the world at a very quick </v>

779
00:47:23.581 --> 00:47:28.581
<v Speaker 1>pace.</v>
<v Speaker 1>So anything that happens in this cycle </v>

780
00:47:28.581 --> 00:47:31.280
<v Speaker 1>at Max,</v>
<v Speaker 1>the overall cycle has to be under 50 </v>

781
00:47:31.280 --> 00:47:31.280
<v Speaker 1>milliseconds.</v>

782
00:47:31.280 --> 00:47:31.960
<v Speaker 1>So that's gonna be a constraint we hold </v>
<v Speaker 1>ourselves to.</v>

783
00:47:32.440 --> 00:47:37.440
<v Speaker 1>And so the story I'll be telling will </v>
<v Speaker 1>say how we got to a point where we </v>

784
00:47:37.440 --> 00:47:42.031
<v Speaker 1>started actually forgetting things and </v>
<v Speaker 1>we're an architecture that doesn't want </v>

785
00:47:42.031 --> 00:47:44.500
<v Speaker 1>to be like humans.</v>
<v Speaker 1>We want to create cool systems,</v>

786
00:47:44.680 --> 00:47:48.130
<v Speaker 1>but what we realized was something that </v>
<v Speaker 1>we do,</v>

787
00:47:48.160 --> 00:47:53.160
<v Speaker 1>there's probably some benefit to it and </v>
<v Speaker 1>we actually put it into our system and </v>

788
00:47:53.160 --> 00:47:55.000
<v Speaker 1>the lead to good outputs.</v>
<v Speaker 1>So here's the research path.</v>

789
00:47:55.001 --> 00:47:59.500
<v Speaker 1>I'm going to walk down a.</v>
<v Speaker 1>We had a just a simple problem which was</v>

790
00:47:59.800 --> 00:48:04.800
<v Speaker 1>we have these memory systems and </v>
<v Speaker 1>sometimes they're going to get a queue </v>

791
00:48:04.800 --> 00:48:07.830
<v Speaker 1>that could relate to multiple memories.</v>
<v Speaker 1>And the question is if you have a fixed </v>

792
00:48:07.830 --> 00:48:11.881
<v Speaker 1>mechanism,</v>
<v Speaker 1>what should you return in a task </v>

793
00:48:11.881 --> 00:48:12.280
<v Speaker 1>independent way?</v>
<v Speaker 1>Which one of these many,</v>

794
00:48:12.281 --> 00:48:17.281
<v Speaker 1>many memories shitty return.</v>
<v Speaker 1>That was our question and we look to </v>

795
00:48:17.281 --> 00:48:17.560
<v Speaker 1>some human data on this.</v>

796
00:48:17.590 --> 00:48:22.590
<v Speaker 1>Something called the rational analysis </v>
<v Speaker 1>of memory done by John Anderson and </v>

797
00:48:22.590 --> 00:48:26.070
<v Speaker 1>realized that in human language,</v>
<v Speaker 1>their recency and frequency effects that</v>

798
00:48:27.670 --> 00:48:29.890
<v Speaker 1>maybe it would be useful.</v>
<v Speaker 1>And so,</v>

799
00:48:30.130 --> 00:48:35.130
<v Speaker 1>uh,</v>
<v Speaker 1>we actually did an analysis found that </v>

800
00:48:35.130 --> 00:48:37.290
<v Speaker 1>not only does this occur but it's useful</v>
<v Speaker 1>in what are called word sense </v>

801
00:48:37.290 --> 00:48:40.291
<v Speaker 1>disambiguation tasks.</v>
<v Speaker 1>And I'll get to that what that means in </v>

802
00:48:40.291 --> 00:48:43.381
<v Speaker 1>a second.</v>
<v Speaker 1>Develop some algorithms to scale this </v>

803
00:48:43.381 --> 00:48:46.171
<v Speaker 1>really well and it turned out to work </v>
<v Speaker 1>out well not only in the original task </v>

804
00:48:46.171 --> 00:48:48.370
<v Speaker 1>but we look to,</v>
<v Speaker 1>to other completely different ones.</v>

805
00:48:48.490 --> 00:48:53.490
<v Speaker 1>The same underlying mechanism ended up </v>
<v Speaker 1>producing some really interesting </v>

806
00:48:53.490 --> 00:48:57.811
<v Speaker 1>outputs.</v>
<v Speaker 1>Suddenly talking about word sense </v>

807
00:48:57.811 --> 00:48:58.690
<v Speaker 1>disambiguation real quick.</v>
<v Speaker 1>So as a core problem in natural language</v>

808
00:48:58.691 --> 00:49:00.460
<v Speaker 1>processing,</v>
<v Speaker 1>if you haven't heard of it before,</v>

809
00:49:00.730 --> 00:49:05.730
<v Speaker 1>let's say we have an agent and for some </v>
<v Speaker 1>reason it needs to understand the verb </v>

810
00:49:05.730 --> 00:49:09.331
<v Speaker 1>to run looks to its memory and finds </v>
<v Speaker 1>that it could,</v>

811
00:49:09.730 --> 00:49:10.790
<v Speaker 1>you know,</v>
<v Speaker 1>run in the park.</v>

812
00:49:10.810 --> 00:49:15.810
<v Speaker 1>It could be running a fever,</v>
<v Speaker 1>could run an election that could run a </v>

813
00:49:15.810 --> 00:49:15.970
<v Speaker 1>program.</v>
<v Speaker 1>And the question is,</v>

814
00:49:15.971 --> 00:49:20.971
<v Speaker 1>what should an task,</v>
<v Speaker 1>independent memory mechanism return if </v>

815
00:49:20.971 --> 00:49:23.200
<v Speaker 1>all you've been given is the verb to </v>
<v Speaker 1>run?</v>

816
00:49:24.160 --> 00:49:28.480
<v Speaker 1>And so the rational analysis of memory </v>
<v Speaker 1>look through multiple texts Corpora,</v>

817
00:49:28.540 --> 00:49:33.490
<v Speaker 1>and what they found was if a particular </v>
<v Speaker 1>word had been used recently,</v>

818
00:49:33.640 --> 00:49:38.290
<v Speaker 1>it's very likely to be reused again.</v>
<v Speaker 1>And if it hadn't been used recently,</v>

819
00:49:38.410 --> 00:49:40.330
<v Speaker 1>there's going to be this effect to </v>
<v Speaker 1>where,</v>

820
00:49:40.540 --> 00:49:41.680
<v Speaker 1>uh,</v>
<v Speaker 1>the expression here,</v>

821
00:49:41.681 --> 00:49:46.681
<v Speaker 1>the t is time since the most recent use.</v>
<v Speaker 1>It's going to some those with a </v>

822
00:49:46.780 --> 00:49:51.780
<v Speaker 1>exponential decay.</v>
<v Speaker 1>So what it looks like if time is going </v>

823
00:49:51.780 --> 00:49:54.700
<v Speaker 1>to the right,</v>
<v Speaker 1>a activation higher is better.</v>

824
00:49:55.270 --> 00:50:00.270
<v Speaker 1>As you get these individual usages,</v>
<v Speaker 1>you get these little drops and then </v>

825
00:50:00.270 --> 00:50:03.440
<v Speaker 1>venture he dropped down.</v>
<v Speaker 1>And so if we had just one usage of a </v>

826
00:50:03.440 --> 00:50:06.481
<v Speaker 1>word,</v>
<v Speaker 1>the red would be what the decay would </v>

827
00:50:06.481 --> 00:50:06.481
<v Speaker 1>look like.</v>

828
00:50:06.481 --> 00:50:10.170
<v Speaker 1>And so the core problem here is if we're</v>
<v Speaker 1>at a particular point and we want to </v>

829
00:50:10.170 --> 00:50:11.170
<v Speaker 1>select between kind of the blue thing or</v>
<v Speaker 1>the red thing,</v>

830
00:50:11.530 --> 00:50:15.160
<v Speaker 1>blue would have a higher activation.</v>
<v Speaker 1>And so maybe that's useful.</v>

831
00:50:15.910 --> 00:50:19.480
<v Speaker 1>This is how things are modeled with </v>
<v Speaker 1>human memory,</v>

832
00:50:20.080 --> 00:50:25.080
<v Speaker 1>but is it useful in general for tasks?</v>
<v Speaker 1>And so we looked at common corpora used </v>

833
00:50:25.871 --> 00:50:28.100
<v Speaker 1>in word sense distribuition and just </v>
<v Speaker 1>said,</v>

834
00:50:28.101 --> 00:50:33.101
<v Speaker 1>well,</v>
<v Speaker 1>if we just look at this corporate twice </v>

835
00:50:33.101 --> 00:50:33.101
<v Speaker 1>and we just use answers,</v>
<v Speaker 1>prior answers,</v>

836
00:50:33.101 --> 00:50:34.160
<v Speaker 1>you know,</v>
<v Speaker 1>I asked the question,</v>

837
00:50:34.600 --> 00:50:36.470
<v Speaker 1>what is the sense of this word?</v>
<v Speaker 1>I took a guess,</v>

838
00:50:36.471 --> 00:50:41.471
<v Speaker 1>I got the right answer and I used that </v>
<v Speaker 1>recency and frequency information to my </v>

839
00:50:41.471 --> 00:50:41.990
<v Speaker 1>task.</v>
<v Speaker 1>Independent memory.</v>

840
00:50:42.140 --> 00:50:45.350
<v Speaker 1>Would that be useful?</v>
<v Speaker 1>And somewhat of a surprise,</v>

841
00:50:45.351 --> 00:50:49.610
<v Speaker 1>but somewhat maybe not have a surprise.</v>
<v Speaker 1>It actually performed really well across</v>

842
00:50:49.611 --> 00:50:52.040
<v Speaker 1>multiple corporate.</v>
<v Speaker 1>So we said,</v>

843
00:50:52.041 --> 00:50:56.660
<v Speaker 1>okay,</v>
<v Speaker 1>this seems like a reasonable mechanism.</v>

844
00:50:57.140 --> 00:51:00.560
<v Speaker 1>Let's look at implementing this </v>
<v Speaker 1>efficiently and the architecture.</v>

845
00:51:00.830 --> 00:51:04.130
<v Speaker 1>And the problem was this term right here</v>
<v Speaker 1>said,</v>

846
00:51:04.160 --> 00:51:09.160
<v Speaker 1>for every memory,</v>
<v Speaker 1>for every time step you're having to k </v>

847
00:51:09.160 --> 00:51:14.050
<v Speaker 1>everything.</v>
<v Speaker 1>That doesn't sound like a recipe for </v>

848
00:51:14.050 --> 00:51:18.491
<v Speaker 1>efficiency if you're talking about lots </v>
<v Speaker 1>and lots of knowledge over long periods </v>

849
00:51:18.491 --> 00:51:18.890
<v Speaker 1>of time.</v>
<v Speaker 1>So we,</v>

850
00:51:19.110 --> 00:51:24.110
<v Speaker 1>uh,</v>
<v Speaker 1>made use of a nice approximation that </v>

851
00:51:24.110 --> 00:51:25.100
<v Speaker 1>Petrofac come up with to approximate </v>
<v Speaker 1>tail effect.</v>

852
00:51:25.101 --> 00:51:26.030
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

853
00:51:26.730 --> 00:51:29.360
<v Speaker 1>access to that happened long,</v>
<v Speaker 1>long ago.</v>

854
00:51:29.361 --> 00:51:31.880
<v Speaker 1>We could basically approximate their </v>
<v Speaker 1>effect on the overall sum.</v>

855
00:51:32.060 --> 00:51:35.300
<v Speaker 1>So we had a fixed set of values,</v>
<v Speaker 1>uh,</v>

856
00:51:35.301 --> 00:51:40.301
<v Speaker 1>and what we basically said is,</v>
<v Speaker 1>since these are always decreasing and </v>

857
00:51:40.301 --> 00:51:44.741
<v Speaker 1>all we care about is relative order,</v>
<v Speaker 1>let's just only recompute when someone </v>

858
00:51:44.741 --> 00:51:45.550
<v Speaker 1>gets a new value.</v>
<v Speaker 1>So it's,</v>

859
00:51:45.551 --> 00:51:48.350
<v Speaker 1>it's a guests,</v>
<v Speaker 1>it's a heuristic and approximation,</v>

860
00:51:48.800 --> 00:51:53.800
<v Speaker 1>but we looked at how this worked on the </v>
<v Speaker 1>same set of Corpora and in terms of </v>

861
00:51:54.021 --> 00:51:59.021
<v Speaker 1>query time,</v>
<v Speaker 1>if we made these approximations well </v>

862
00:51:59.021 --> 00:52:02.021
<v Speaker 1>under our 50 millisecond,</v>
<v Speaker 1>the effect on task performance was </v>

863
00:52:02.021 --> 00:52:02.270
<v Speaker 1>negligible.</v>

864
00:52:02.270 --> 00:52:07.270
<v Speaker 1>In fact,</v>
<v Speaker 1>on a couple of these that God's ever so </v>

865
00:52:07.270 --> 00:52:09.731
<v Speaker 1>slightly better in terms of accuracy.</v>
<v Speaker 1>And actually if we looked at the </v>

866
00:52:09.731 --> 00:52:11.480
<v Speaker 1>individual decisions that were being </v>
<v Speaker 1>made,</v>

867
00:52:11.930 --> 00:52:16.100
<v Speaker 1>making these sorts of approximations,</v>
<v Speaker 1>we're leading to a,</v>

868
00:52:16.101 --> 00:52:17.460
<v Speaker 1>up to 90,</v>
<v Speaker 1>sorry,</v>

869
00:52:17.510 --> 00:52:22.400
<v Speaker 1>at least 90 percent of the decisions </v>
<v Speaker 1>being made were identical to having done</v>

870
00:52:22.401 --> 00:52:27.401
<v Speaker 1>the true a full calculation.</v>
<v Speaker 1>So we said this is great and we </v>

871
00:52:28.551 --> 00:52:33.551
<v Speaker 1>implemented this and worked really well.</v>
<v Speaker 1>And then we started working on what </v>

872
00:52:33.551 --> 00:52:35.630
<v Speaker 1>seemed like completely unrelated </v>
<v Speaker 1>problems.</v>

873
00:52:35.840 --> 00:52:39.140
<v Speaker 1>One was in mobile robotics.</v>
<v Speaker 1>We had a mobile robot.</v>

874
00:52:39.141 --> 00:52:40.760
<v Speaker 1>I'll show a picture of in a little </v>
<v Speaker 1>while,</v>

875
00:52:40.880 --> 00:52:45.880
<v Speaker 1>roaming around the halls performing all </v>
<v Speaker 1>sorts of tasks and what we're finding </v>

876
00:52:45.880 --> 00:52:49.511
<v Speaker 1>was if you have a system that's </v>
<v Speaker 1>remembering everything in your short </v>

877
00:52:49.511 --> 00:52:51.320
<v Speaker 1>term memory and your short term memory </v>
<v Speaker 1>gets really,</v>

878
00:52:51.321 --> 00:52:53.300
<v Speaker 1>really big.</v>
<v Speaker 1>I don't know about you.</v>

879
00:52:53.301 --> 00:52:55.400
<v Speaker 1>My short term memory feels really,</v>
<v Speaker 1>really small.</v>

880
00:52:55.400 --> 00:53:00.400
<v Speaker 1>I would love it to be big,</v>
<v Speaker 1>but if you make your memory really big </v>

881
00:53:00.400 --> 00:53:04.151
<v Speaker 1>and you try to remember something,</v>
<v Speaker 1>you're not having to pull lots and lots </v>

882
00:53:04.151 --> 00:53:04.850
<v Speaker 1>and lots of information into your short </v>
<v Speaker 1>term memory.</v>

883
00:53:05.090 --> 00:53:10.090
<v Speaker 1>So the system was actually getting </v>
<v Speaker 1>slower simply because it had a lot of </v>

884
00:53:10.090 --> 00:53:12.020
<v Speaker 1>short term memory,</v>
<v Speaker 1>a representation of the overall map.</v>

885
00:53:12.021 --> 00:53:16.250
<v Speaker 1>It was looking at so large working </v>
<v Speaker 1>memory problem,</v>

886
00:53:17.000 --> 00:53:18.860
<v Speaker 1>Liar's dice game,</v>
<v Speaker 1>you play with dice.</v>

887
00:53:19.010 --> 00:53:23.420
<v Speaker 1>We were doing an rl based system on this</v>
<v Speaker 1>reinforcement learning and it turned out</v>

888
00:53:24.450 --> 00:53:26.130
<v Speaker 1>a really,</v>
<v Speaker 1>really big value function.</v>

889
00:53:26.131 --> 00:53:31.131
<v Speaker 1>Worse having to store lots of data and </v>
<v Speaker 1>we didn't know which stuff we had to </v>

890
00:53:31.131 --> 00:53:31.840
<v Speaker 1>keep around to keep the performance,</v>
<v Speaker 1>uh,</v>

891
00:53:31.980 --> 00:53:36.980
<v Speaker 1>up.</v>
<v Speaker 1>So we had a hypothesis that forgetting </v>

892
00:53:36.980 --> 00:53:40.880
<v Speaker 1>was actually going to be a beneficial </v>
<v Speaker 1>thing that maybe maybe the the problem </v>

893
00:53:42.451 --> 00:53:43.890
<v Speaker 1>we have with our memories that we </v>
<v Speaker 1>really,</v>

894
00:53:43.891 --> 00:53:45.720
<v Speaker 1>really disliked this forgetting thing.</v>

895
00:53:46.050 --> 00:53:51.050
<v Speaker 1>Maybe it's actually useful.</v>
<v Speaker 1>And so we experimented with the </v>

896
00:53:51.050 --> 00:53:51.050
<v Speaker 1>following policy.</v>
<v Speaker 1>We said,</v>

897
00:53:51.050 --> 00:53:55.370
<v Speaker 1>let's forget a memory if one we haven't </v>
<v Speaker 1>really.</v>

898
00:53:55.630 --> 00:53:58.410
<v Speaker 1>It's not predicted to be useful by this </v>
<v Speaker 1>base level activation.</v>

899
00:53:58.560 --> 00:54:00.840
<v Speaker 1>We haven't used it recently,</v>
<v Speaker 1>we haven't used it frequently,</v>

900
00:54:00.900 --> 00:54:02.850
<v Speaker 1>maybe it's not worth it.</v>
<v Speaker 1>That.</v>

901
00:54:02.851 --> 00:54:07.851
<v Speaker 1>And we felt confident that we could </v>
<v Speaker 1>approximately reconstructed if we </v>

902
00:54:07.851 --> 00:54:10.560
<v Speaker 1>absolutely had to.</v>
<v Speaker 1>And if those two things held,</v>

903
00:54:10.590 --> 00:54:13.500
<v Speaker 1>we could forget something.</v>
<v Speaker 1>Uh,</v>

904
00:54:13.501 --> 00:54:17.760
<v Speaker 1>so it's this bay same basic algorithm,</v>
<v Speaker 1>but instead of the ranking them,</v>

905
00:54:17.761 --> 00:54:22.761
<v Speaker 1>it's if we set a threshold for base </v>
<v Speaker 1>level activation finding when it is that</v>

906
00:54:24.380 --> 00:54:29.380
<v Speaker 1>a memory is going to pass that threshold</v>
<v Speaker 1>and try to forget based upon that in a </v>

907
00:54:29.380 --> 00:54:31.170
<v Speaker 1>way that's efficient,</v>
<v Speaker 1>that isn't going to scale really,</v>

908
00:54:31.171 --> 00:54:36.171
<v Speaker 1>really poorly.</v>
<v Speaker 1>So we were able to come up with an </v>

909
00:54:36.171 --> 00:54:40.431
<v Speaker 1>efficient way to implement this using an</v>
<v Speaker 1>approximation that ended up for most </v>

910
00:54:46.110 --> 00:54:48.840
<v Speaker 1>memories to be exactly correct to the </v>
<v Speaker 1>original.</v>

911
00:54:48.990 --> 00:54:51.990
<v Speaker 1>I'm happy to go over details of this if </v>
<v Speaker 1>anybody's interested later,</v>

912
00:54:52.320 --> 00:54:54.570
<v Speaker 1>but it ended up being a fairly close </v>
<v Speaker 1>approximation.</v>

913
00:54:55.020 --> 00:55:00.020
<v Speaker 1>One that as compared to an accurate,</v>
<v Speaker 1>completely accurate search for the value</v>

914
00:55:01.590 --> 00:55:05.340
<v Speaker 1>ended up being somewhere between 15 to </v>
<v Speaker 1>20 times faster.</v>

915
00:55:06.750 --> 00:55:08.850
<v Speaker 1>And so what we looked at our mobile </v>
<v Speaker 1>robot here.</v>

916
00:55:09.270 --> 00:55:10.860
<v Speaker 1>Oh,</v>
<v Speaker 1>sorry,</v>

917
00:55:10.890 --> 00:55:14.190
<v Speaker 1>let me get this back because our little </v>
<v Speaker 1>robots actually going around.</v>

918
00:55:14.191 --> 00:55:19.191
<v Speaker 1>That's the third floor of the computer </v>
<v Speaker 1>science building at the University of </v>

919
00:55:19.191 --> 00:55:19.191
<v Speaker 1>Michigan.</v>
<v Speaker 1>He's going around,</v>

920
00:55:19.191 --> 00:55:23.451
<v Speaker 1>he's building a map and again,</v>
<v Speaker 1>the idea was this map is getting too </v>

921
00:55:23.451 --> 00:55:24.600
<v Speaker 1>big,</v>
<v Speaker 1>so here was the basic idea as the robots</v>

922
00:55:24.601 --> 00:55:29.601
<v Speaker 1>going around,</v>
<v Speaker 1>it's going to need this map information </v>

923
00:55:29.601 --> 00:55:31.791
<v Speaker 1>about rooms.</v>
<v Speaker 1>The color there is describing kind of </v>

924
00:55:31.791 --> 00:55:34.311
<v Speaker 1>the strength of the memory and as it </v>
<v Speaker 1>gets farther and farther away and it </v>

925
00:55:34.311 --> 00:55:35.970
<v Speaker 1>hasn't used part of the map for planning</v>
<v Speaker 1>or other purposes,</v>

926
00:55:36.060 --> 00:55:39.150
<v Speaker 1>basically make a decay away so that by </v>
<v Speaker 1>the time it gets to the bottom,</v>

927
00:55:39.300 --> 00:55:40.590
<v Speaker 1>it's forgotten about the top.</v>

928
00:55:41.130 --> 00:55:46.130
<v Speaker 1>But we had the belief that we could </v>
<v Speaker 1>reconstruct portion that map if </v>

929
00:55:47.071 --> 00:55:52.071
<v Speaker 1>necessary.</v>
<v Speaker 1>And so the hypothesis was this would </v>

930
00:55:52.071 --> 00:55:54.330
<v Speaker 1>take care of our speed problems and so </v>
<v Speaker 1>what we looked at was,</v>

931
00:55:54.331 --> 00:55:57.210
<v Speaker 1>here's our 50 millisecond thresholds.</v>
<v Speaker 1>If we do know,</v>

932
00:55:57.211 --> 00:56:00.210
<v Speaker 1>forgetting whatsoever,</v>
<v Speaker 1>bad things were happening over time.</v>

933
00:56:00.510 --> 00:56:04.080
<v Speaker 1>So just a 3,600</v>
<v Speaker 1>seconds,</v>

934
00:56:04.560 --> 00:56:07.470
<v Speaker 1>this isn't a very long time,</v>
<v Speaker 1>we're passing that threshold.</v>

935
00:56:07.471 --> 00:56:11.220
<v Speaker 1>This is dangerous for the robot.</v>
<v Speaker 1>If we implemented task specific,</v>

936
00:56:11.221 --> 00:56:14.010
<v Speaker 1>basically cleanup rules,</v>
<v Speaker 1>which is really hard to get right,</v>

937
00:56:14.490 --> 00:56:19.490
<v Speaker 1>that basically solved the problem when </v>
<v Speaker 1>we looked at our general forgetting </v>

938
00:56:19.490 --> 00:56:22.260
<v Speaker 1>mechanism that we're using in other </v>
<v Speaker 1>places at an appropriate level of decay.</v>

939
00:56:22.440 --> 00:56:24.640
<v Speaker 1>We were actually better than hand tune </v>
<v Speaker 1>rules.</v>

940
00:56:25.030 --> 00:56:27.310
<v Speaker 1>So this was kind of a surprise when for </v>
<v Speaker 1>us,</v>

941
00:56:28.880 --> 00:56:31.300
<v Speaker 1>uh,</v>
<v Speaker 1>the other task seems totally unrelated.</v>

942
00:56:31.301 --> 00:56:34.060
<v Speaker 1>It's a dice game.</v>
<v Speaker 1>You cover your Dayas,</v>

943
00:56:34.061 --> 00:56:37.300
<v Speaker 1>you make bids about what are under other</v>
<v Speaker 1>people's cups.</v>

944
00:56:37.510 --> 00:56:42.510
<v Speaker 1>This is played in pirates of the </v>
<v Speaker 1>Caribbean when they're on the boat and </v>

945
00:56:42.510 --> 00:56:43.120
<v Speaker 1>the second movie and bidding for lives </v>
<v Speaker 1>of service.</v>

946
00:56:43.270 --> 00:56:48.270
<v Speaker 1>Honestly,</v>
<v Speaker 1>this is a game we love to play in the </v>

947
00:56:48.270 --> 00:56:48.270
<v Speaker 1>University of Michigan lab.</v>
<v Speaker 1>Uh,</v>

948
00:56:48.270 --> 00:56:48.460
<v Speaker 1>and so we're like,</v>
<v Speaker 1>hm,</v>

949
00:56:48.490 --> 00:56:49.900
<v Speaker 1>could soar,</v>
<v Speaker 1>play this?</v>

950
00:56:50.230 --> 00:56:54.460
<v Speaker 1>And so we built a system that could </v>
<v Speaker 1>learn to play this game rather well with</v>

951
00:56:54.461 --> 00:56:59.461
<v Speaker 1>reinforcement learning.</v>
<v Speaker 1>And so the basic idea was in a </v>

952
00:56:59.461 --> 00:57:01.720
<v Speaker 1>particular state of the game store would</v>
<v Speaker 1>have options of actions to perform,</v>

953
00:57:02.020 --> 00:57:06.070
<v Speaker 1>it could construct a estimates of their </v>
<v Speaker 1>associated value,</v>

954
00:57:06.090 --> 00:57:08.800
<v Speaker 1>it would choose one of those,</v>
<v Speaker 1>and depending on the outcome,</v>

955
00:57:08.950 --> 00:57:11.230
<v Speaker 1>something good happened,</v>
<v Speaker 1>you might update that value.</v>

956
00:57:11.620 --> 00:57:14.660
<v Speaker 1>And the big problem was that the size of</v>
<v Speaker 1>the state space,</v>

957
00:57:14.670 --> 00:57:18.730
<v Speaker 1>the number of possible states and </v>
<v Speaker 1>actions just is enormous.</v>

958
00:57:19.240 --> 00:57:21.850
<v Speaker 1>And so memory was blowing up.</v>
<v Speaker 1>And so what we said,</v>

959
00:57:21.910 --> 00:57:25.810
<v Speaker 1>similar sort of hypothesis,</v>
<v Speaker 1>if we decay away,</v>

960
00:57:26.170 --> 00:57:31.170
<v Speaker 1>these estimates that we could probably </v>
<v Speaker 1>reconstruct and we haven't used in </v>

961
00:57:31.170 --> 00:57:31.690
<v Speaker 1>awhile,</v>
<v Speaker 1>are things going to get better?</v>

962
00:57:33.070 --> 00:57:36.610
<v Speaker 1>And so if we don't forget it all,</v>
<v Speaker 1>40,000</v>

963
00:57:36.611 --> 00:57:38.920
<v Speaker 1>games isn't a whole lot when it comes to</v>
<v Speaker 1>reinforcement learning.</v>

964
00:57:39.190 --> 00:57:44.190
<v Speaker 1>We were up at two gigs.</v>
<v Speaker 1>We wanted to put this on an iphone that </v>

965
00:57:44.190 --> 00:57:47.971
<v Speaker 1>wasn't gonna work.</v>
<v Speaker 1>So well there had been prior work that </v>

966
00:57:48.850 --> 00:57:53.350
<v Speaker 1>had used a similar approach.</v>
<v Speaker 1>They were down at four or 500 megs.</v>

967
00:57:53.470 --> 00:57:56.370
<v Speaker 1>The iphone is not going to be happy,</v>
<v Speaker 1>but it'll work.</v>

968
00:57:56.800 --> 00:57:57.510
<v Speaker 1>Uh,</v>
<v Speaker 1>so that,</v>

969
00:57:57.511 --> 00:58:00.580
<v Speaker 1>that gave us some hope and we </v>
<v Speaker 1>implemented our system.</v>

970
00:58:01.130 --> 00:58:02.350
<v Speaker 1>Okay.</v>
<v Speaker 1>We're somewhere in the middle.</v>

971
00:58:02.351 --> 00:58:05.110
<v Speaker 1>We can fit on the iphone.</v>
<v Speaker 1>A very good iphone,</v>

972
00:58:05.140 --> 00:58:08.350
<v Speaker 1>maybe an ipad.</v>
<v Speaker 1>The question was though,</v>

973
00:58:08.620 --> 00:58:10.090
<v Speaker 1>a one.</v>
<v Speaker 1>Efficiency.</v>

974
00:58:10.150 --> 00:58:11.230
<v Speaker 1>Yeah,</v>
<v Speaker 1>we,</v>

975
00:58:11.310 --> 00:58:13.480
<v Speaker 1>we fit under a 50 milliseconds,</v>
<v Speaker 1>but two,</v>

976
00:58:13.510 --> 00:58:15.970
<v Speaker 1>how does the system actually performed </v>
<v Speaker 1>when you start forgetting stuff,</v>

977
00:58:16.360 --> 00:58:20.230
<v Speaker 1>can it learn to play well?</v>
<v Speaker 1>And so y axis here,</v>

978
00:58:20.231 --> 00:58:22.990
<v Speaker 1>you're seeing Qa competency,</v>
<v Speaker 1>you play a thousand games.</v>

979
00:58:22.991 --> 00:58:24.810
<v Speaker 1>How many do you win?</v>
<v Speaker 1>So the bottom here,</v>

980
00:58:24.820 --> 00:58:29.820
<v Speaker 1>500.</v>
<v Speaker 1>That's flipping a coin whether or not </v>

981
00:58:29.820 --> 00:58:32.530
<v Speaker 1>you're going to win a.</v>
<v Speaker 1>If we do know for getting whatsoever,</v>

982
00:58:32.590 --> 00:58:35.550
<v Speaker 1>this is a pretty good system.</v>
<v Speaker 1>Uh,</v>

983
00:58:36.280 --> 00:58:41.280
<v Speaker 1>the prior work,</v>
<v Speaker 1>while keeping the memory low is also </v>

984
00:58:41.280 --> 00:58:44.401
<v Speaker 1>suffering with respect to how well it </v>
<v Speaker 1>was playing the game and kind of cool </v>

985
00:58:45.041 --> 00:58:50.041
<v Speaker 1>was the system that was basically more </v>
<v Speaker 1>than having the memory requirement was </v>

986
00:58:50.041 --> 00:58:53.080
<v Speaker 1>still performing at the level of no </v>
<v Speaker 1>forgetting whatsoever.</v>

987
00:58:55.360 --> 00:59:00.360
<v Speaker 1>So just to bring back why I went through</v>
<v Speaker 1>the story was we had a problem.</v>

988
00:59:00.550 --> 00:59:03.700
<v Speaker 1>We look to our example of human level </v>
<v Speaker 1>ai,</v>

989
00:59:03.701 --> 00:59:06.340
<v Speaker 1>which is humans themselves.</v>
<v Speaker 1>We took an idea,</v>

990
00:59:06.550 --> 00:59:11.550
<v Speaker 1>it turned out to be beneficial,</v>
<v Speaker 1>we found in a efficient implementations </v>

991
00:59:11.550 --> 00:59:15.571
<v Speaker 1>and then found it was useful in other </v>
<v Speaker 1>parts of the architecture and other </v>

992
00:59:15.571 --> 00:59:15.571
<v Speaker 1>tasks that didn't seem to relate </v>
<v Speaker 1>whatsoever.</v>

993
00:59:16.450 --> 00:59:21.450
<v Speaker 1>But if you download sore right now,</v>
<v Speaker 1>you would gain access to all these </v>

994
00:59:21.450 --> 00:59:22.670
<v Speaker 1>mechanisms for whatever task you want it</v>
<v Speaker 1>to perform.</v>

995
00:59:24.890 --> 00:59:27.320
<v Speaker 1>Just to give some sense in the field of </v>
<v Speaker 1>cognitive architecture,</v>

996
00:59:27.321 --> 00:59:32.321
<v Speaker 1>what's some of the open issues are.</v>
<v Speaker 1>I think this is true in a lot of fields </v>

997
00:59:32.321 --> 00:59:33.200
<v Speaker 1>in ai,</v>
<v Speaker 1>but a integration of systems over time.</v>

998
00:59:33.350 --> 00:59:38.060
<v Speaker 1>The goal was they wouldn't have all </v>
<v Speaker 1>these theories and uh,</v>

999
00:59:38.090 --> 00:59:39.860
<v Speaker 1>so you could just kind of build over </v>
<v Speaker 1>time,</v>

1000
00:59:40.250 --> 00:59:42.320
<v Speaker 1>particularly when folks are working on </v>
<v Speaker 1>different architectures,</v>

1001
00:59:42.321 --> 00:59:43.160
<v Speaker 1>that becomes hard.</v>

1002
00:59:43.540 --> 00:59:48.540
<v Speaker 1>Uh,</v>
<v Speaker 1>but also when you have very different </v>

1003
00:59:48.540 --> 00:59:48.540
<v Speaker 1>initial starting points,</v>
<v Speaker 1>that can still be an issue.</v>

1004
00:59:48.540 --> 00:59:53.080
<v Speaker 1>Transfer learning is an issue we're </v>
<v Speaker 1>building into the space of multimodal </v>

1005
00:59:53.080 --> 00:59:56.981
<v Speaker 1>representations,</v>
<v Speaker 1>which is to say not only abstract </v>

1006
00:59:56.981 --> 00:59:56.981
<v Speaker 1>symbolic,</v>
<v Speaker 1>but also visual.</v>

1007
00:59:56.981 --> 00:59:59.420
<v Speaker 1>Wouldn't it be nice if we had auditory </v>
<v Speaker 1>and other senses,</v>

1008
00:59:59.660 --> 01:00:03.770
<v Speaker 1>but building that into memories and </v>
<v Speaker 1>processing is still an open question.</v>

1009
01:00:04.460 --> 01:00:09.460
<v Speaker 1>There's folks working on metacognition,</v>
<v Speaker 1>which is to say the agent self-assessing</v>

1010
01:00:09.590 --> 01:00:11.600
<v Speaker 1>its own state,</v>
<v Speaker 1>its own processing,</v>

1011
01:00:11.900 --> 01:00:16.900
<v Speaker 1>some work has been done in here but </v>
<v Speaker 1>still a lot and I think the last one is </v>

1012
01:00:16.900 --> 01:00:19.490
<v Speaker 1>a really important question for anybody </v>
<v Speaker 1>taking this kind of class,</v>

1013
01:00:19.700 --> 01:00:22.790
<v Speaker 1>which is what would happen if we did </v>
<v Speaker 1>succeed,</v>

1014
01:00:22.970 --> 01:00:27.970
<v Speaker 1>if we did make human level ai and if you</v>
<v Speaker 1>don't know that picture right there is </v>

1015
01:00:28.580 --> 01:00:31.250
<v Speaker 1>from a show that I recommend that you </v>
<v Speaker 1>watch a,</v>

1016
01:00:31.251 --> 01:00:36.251
<v Speaker 1>it's by the BBC,</v>
<v Speaker 1>it's called humans and it's basically </v>

1017
01:00:36.251 --> 01:00:37.620
<v Speaker 1>what if we were able to develop what are</v>
<v Speaker 1>called synths in the show.</v>

1018
01:00:37.620 --> 01:00:42.620
<v Speaker 1>I think the,</v>
<v Speaker 1>a robot that can clean up after your </v>

1019
01:00:42.620 --> 01:00:45.350
<v Speaker 1>laundry and cook and all that good stuff</v>
<v Speaker 1>interact with you if looks and interacts</v>

1020
01:00:45.351 --> 01:00:50.351
<v Speaker 1>as a human but is completely or servant </v>
<v Speaker 1>and then hilarity and complex issues in </v>

1021
01:00:51.701 --> 01:00:56.701
<v Speaker 1>sue.</v>
<v Speaker 1>So I highly recommend if you haven't </v>

1022
01:00:56.701 --> 01:00:57.590
<v Speaker 1>seen that to go watch that.</v>
<v Speaker 1>Uh,</v>

1023
01:00:58.940 --> 01:01:03.940
<v Speaker 1>I think these days there's a lot of </v>
<v Speaker 1>attention play a paid to machine </v>

1024
01:01:04.701 --> 01:01:07.130
<v Speaker 1>learning in particular deep learning </v>
<v Speaker 1>methods as well.</v>

1025
01:01:07.131 --> 01:01:09.290
<v Speaker 1>It should.</v>
<v Speaker 1>They're doing absolutely amazing things.</v>

1026
01:01:09.590 --> 01:01:11.660
<v Speaker 1>Uh,</v>
<v Speaker 1>and often the question is,</v>

1027
01:01:11.661 --> 01:01:16.661
<v Speaker 1>well,</v>
<v Speaker 1>you're doing this and there's deep </v>

1028
01:01:16.661 --> 01:01:16.661
<v Speaker 1>learning over there,</v>
<v Speaker 1>you know,</v>

1029
01:01:16.661 --> 01:01:21.371
<v Speaker 1>how do they compare?</v>
<v Speaker 1>And I honestly don't feel that that's </v>

1030
01:01:21.411 --> 01:01:26.411
<v Speaker 1>always a fruitful question because most </v>
<v Speaker 1>of the time they tend to be working on </v>

1031
01:01:26.411 --> 01:01:27.480
<v Speaker 1>different problems.</v>
<v Speaker 1>Uh,</v>

1032
01:01:27.890 --> 01:01:30.620
<v Speaker 1>if I'm trying to find objects in the </v>
<v Speaker 1>scene,</v>

1033
01:01:31.370 --> 01:01:33.210
<v Speaker 1>I'm going to pull out tensor flow.</v>
<v Speaker 1>Uh,</v>

1034
01:01:33.220 --> 01:01:34.750
<v Speaker 1>I'm really not going to pull out store.</v>

1035
01:01:34.760 --> 01:01:38.180
<v Speaker 1>It doesn't make sense.</v>
<v Speaker 1>It's not the right tool for the job that</v>

1036
01:01:38.181 --> 01:01:43.181
<v Speaker 1>haven't been said.</v>
<v Speaker 1>There are times when they tend to work </v>

1037
01:01:43.181 --> 01:01:43.181
<v Speaker 1>together really,</v>
<v Speaker 1>really well.</v>

1038
01:01:43.181 --> 01:01:45.140
<v Speaker 1>So the rosy system that you saw there,</v>
<v Speaker 1>there was some,</v>

1039
01:01:45.320 --> 01:01:46.590
<v Speaker 1>uh,</v>
<v Speaker 1>uh,</v>

1040
01:01:47.000 --> 01:01:52.000
<v Speaker 1>I believe neural networks being used in </v>
<v Speaker 1>the object recognition mechanisms for </v>

1041
01:01:52.000 --> 01:01:54.230
<v Speaker 1>the vision system.</v>
<v Speaker 1>There's td learning going on in terms of</v>

1042
01:01:54.231 --> 01:01:57.200
<v Speaker 1>the dice game where we can pick and </v>
<v Speaker 1>choose and use this stuff.</v>

1043
01:01:57.201 --> 01:02:02.201
<v Speaker 1>Absolutely great because there are </v>
<v Speaker 1>problems that are best solved by these </v>

1044
01:02:02.201 --> 01:02:02.201
<v Speaker 1>methods.</v>
<v Speaker 1>So why avoid it?</v>

1045
01:02:02.201 --> 01:02:03.200
<v Speaker 1>Uh,</v>
<v Speaker 1>and then on the other side,</v>

1046
01:02:03.380 --> 01:02:06.150
<v Speaker 1>if you're trying to develop a system </v>
<v Speaker 1>where you,</v>

1047
01:02:06.350 --> 01:02:08.120
<v Speaker 1>you know,</v>
<v Speaker 1>in different situations,</v>

1048
01:02:08.121 --> 01:02:10.130
<v Speaker 1>know exactly what you want the system to</v>
<v Speaker 1>do,</v>

1049
01:02:11.150 --> 01:02:14.210
<v Speaker 1>soar or other rule based systems and to </v>
<v Speaker 1>being the right tool for the right job.</v>

1050
01:02:14.211 --> 01:02:17.540
<v Speaker 1>So absolutely why not make it a piece of</v>
<v Speaker 1>the overall system?</v>

1051
01:02:19.550 --> 01:02:24.550
<v Speaker 1>Uh,</v>
<v Speaker 1>some recommended readings and some </v>

1052
01:02:24.550 --> 01:02:24.550
<v Speaker 1>venues.</v>
<v Speaker 1>Uh,</v>

1053
01:02:24.550 --> 01:02:24.550
<v Speaker 1>I'd mentioned unified theories of </v>
<v Speaker 1>cognition.</v>

1054
01:02:24.550 --> 01:02:26.700
<v Speaker 1>This is Harvard press,</v>
<v Speaker 1>I believe.</v>

1055
01:02:27.630 --> 01:02:30.720
<v Speaker 1>Uh,</v>
<v Speaker 1>the cognitive architecture was mit press</v>

1056
01:02:30.750 --> 01:02:35.750
<v Speaker 1>came out in 2012.</v>
<v Speaker 1>I'll say I'm coauthor and a </v>

1057
01:02:35.970 --> 01:02:40.970
<v Speaker 1>theoretically would get proceeds,</v>
<v Speaker 1>but I've donated them all to the </v>

1058
01:02:40.970 --> 01:02:44.240
<v Speaker 1>University of Michigan.</v>
<v Speaker 1>So I can just make this recommendation </v>

1059
01:02:44.240 --> 01:02:44.240
<v Speaker 1>free of ethical concerns.</v>
<v Speaker 1>Personally,</v>

1060
01:02:45.030 --> 01:02:47.910
<v Speaker 1>it's an interesting bug.</v>
<v Speaker 1>It brings together lots of a history and</v>

1061
01:02:47.911 --> 01:02:49.820
<v Speaker 1>lots of new features.</v>
<v Speaker 1>It's if,</v>

1062
01:02:49.880 --> 01:02:53.640
<v Speaker 1>if you're really interested in soar,</v>
<v Speaker 1>it's an easy sell.</v>

1063
01:02:54.740 --> 01:02:57.210
<v Speaker 1>I had mentioned crystallized Smith's how</v>
<v Speaker 1>to build a brain.</v>

1064
01:02:57.510 --> 01:02:59.520
<v Speaker 1>Really cool read,</v>
<v Speaker 1>download the software,</v>

1065
01:02:59.530 --> 01:03:01.350
<v Speaker 1>go through tutorials.</v>
<v Speaker 1>It's really great.</v>

1066
01:03:02.130 --> 01:03:07.130
<v Speaker 1>How can the human mind and occur in the </v>
<v Speaker 1>physical universe is one of the core </v>

1067
01:03:07.130 --> 01:03:07.350
<v Speaker 1>act,</v>
<v Speaker 1>our books.</v>

1068
01:03:07.680 --> 01:03:12.680
<v Speaker 1>So it talks through a lot of the </v>
<v Speaker 1>psychological underpinnings and how the </v>

1069
01:03:12.680 --> 01:03:12.770
<v Speaker 1>architecture works.</v>
<v Speaker 1>It's,</v>

1070
01:03:12.780 --> 01:03:15.790
<v Speaker 1>it's a fascinating read,</v>
<v Speaker 1>uh,</v>

1071
01:03:15.870 --> 01:03:19.260
<v Speaker 1>one of the papers trying to remember </v>
<v Speaker 1>what year 2008.</v>

1072
01:03:20.700 --> 01:03:23.790
<v Speaker 1>This goes through a lot of different </v>
<v Speaker 1>architectures in the field.</v>

1073
01:03:23.820 --> 01:03:28.820
<v Speaker 1>It's 10 years old,</v>
<v Speaker 1>but it gives you a good kind of broad </v>

1074
01:03:28.820 --> 01:03:29.760
<v Speaker 1>sweep if you want something a little </v>
<v Speaker 1>more recent.</v>

1075
01:03:29.790 --> 01:03:34.790
<v Speaker 1>This is last month's issue of Ai </v>
<v Speaker 1>magazine completely dedicated to </v>

1076
01:03:35.131 --> 01:03:37.200
<v Speaker 1>cognitive systems.</v>
<v Speaker 1>Uh,</v>

1077
01:03:37.201 --> 01:03:39.930
<v Speaker 1>so it's a good place to look for this </v>
<v Speaker 1>sort of stuff.</v>

1078
01:03:40.170 --> 01:03:42.650
<v Speaker 1>In terms of academic venues,</v>
<v Speaker 1>a aaa,</v>

1079
01:03:42.651 --> 01:03:47.651
<v Speaker 1>I often has cognitive systems track.</v>
<v Speaker 1>There's a conference called ICCM </v>

1080
01:03:47.651 --> 01:03:48.600
<v Speaker 1>international conference on cognitive </v>
<v Speaker 1>modeling,</v>

1081
01:03:48.880 --> 01:03:53.880
<v Speaker 1>a where you'll see kind of a span from </v>
<v Speaker 1>biologic all the way up to ai cognitive </v>

1082
01:03:53.911 --> 01:03:58.911
<v Speaker 1>science or cog psy.</v>
<v Speaker 1>They have a conference as well as the </v>

1083
01:03:58.911 --> 01:04:01.551
<v Speaker 1>journal.</v>
<v Speaker 1>A ACS has a conference as well as an </v>

1084
01:04:01.551 --> 01:04:02.240
<v Speaker 1>online journal,</v>
<v Speaker 1>uh,</v>

1085
01:04:02.241 --> 01:04:07.241
<v Speaker 1>advances in cognitive systems.</v>
<v Speaker 1>Cognitive Systems Research is a journal </v>

1086
01:04:07.241 --> 01:04:09.620
<v Speaker 1>that has a lot of this good stuff.</v>
<v Speaker 1>There's Agi.</v>

1087
01:04:09.660 --> 01:04:13.290
<v Speaker 1>The conference,</v>
<v Speaker 1>Becca is biologically inspired cognitive</v>

1088
01:04:13.291 --> 01:04:18.291
<v Speaker 1>architectures and I had mentioned both.</v>
<v Speaker 1>There's a sore workshop and enact our </v>

1089
01:04:18.291 --> 01:04:22.761
<v Speaker 1>workshop that go on annually,</v>
<v Speaker 1>so leave it at this.</v>

1090
01:04:23.461 --> 01:04:28.461
<v Speaker 1>There's some contact information there </v>
<v Speaker 1>and a lot of when I do these days </v>

1091
01:04:28.461 --> 01:04:31.690
<v Speaker 1>actually involves kind of explainable </v>
<v Speaker 1>machine learning,</v>

1092
01:04:31.691 --> 01:04:36.691
<v Speaker 1>integrating that with cognitive systems </v>
<v Speaker 1>as well as a optimization and robotics </v>

1093
01:04:37.241 --> 01:04:40.510
<v Speaker 1>that scales really well and also </v>
<v Speaker 1>integrates with cognitive systems.</v>

1094
01:04:40.900 --> 01:04:41.770
<v Speaker 1>So thank you.</v>

1095
01:04:42.250 --> 01:04:47.250
<v Speaker 5>Thank you.</v>
<v Speaker 5>Do you have</v>

1096
01:04:48.660 --> 01:04:53.660
<v Speaker 1>a question?</v>
<v Speaker 1>Please line up to one of these two </v>

1097
01:04:53.660 --> 01:04:53.660
<v Speaker 1>microphones.</v>
<v Speaker 1>So,</v>

1098
01:04:53.660 --> 01:04:53.970
<v Speaker 1>uh,</v>
<v Speaker 1>what's the,</v>

1099
01:04:54.250 --> 01:04:56.820
<v Speaker 1>what's the main heuristics that you're </v>
<v Speaker 1>using?</v>

1100
01:04:57.250 --> 01:05:02.250
<v Speaker 1>I'm in soar that they're gonna be </v>
<v Speaker 1>heuristics at the task level and the </v>

1101
01:05:02.250 --> 01:05:06.831
<v Speaker 1>agent level or there's the heuristics </v>
<v Speaker 1>that are built into the architecture to </v>

1102
01:05:06.831 --> 01:05:11.510
<v Speaker 1>operate efficiently.</v>
<v Speaker 1>So I'll give you a core example that </v>

1103
01:05:11.510 --> 01:05:14.301
<v Speaker 1>comes into the architecture and it's a </v>
<v Speaker 1>fun trick that if you're a programmer </v>

1104
01:05:14.301 --> 01:05:19.230
<v Speaker 1>you could use all the time,</v>
<v Speaker 1>which is a only changes which is to say </v>

1105
01:05:19.660 --> 01:05:24.660
<v Speaker 1>one of the cool things about [inaudible]</v>
<v Speaker 1>is you can load it up with literally </v>

1106
01:05:24.660 --> 01:05:27.691
<v Speaker 1>billions of rules.</v>
<v Speaker 1>And I say literally because we've done </v>

1107
01:05:27.691 --> 01:05:28.240
<v Speaker 1>it and we know that it can turn over </v>
<v Speaker 1>still in,</v>

1108
01:05:28.241 --> 01:05:31.450
<v Speaker 1>under a millisecond.</v>
<v Speaker 1>And this happens because instead of most</v>

1109
01:05:31.451 --> 01:05:34.360
<v Speaker 1>systems which process all the rules,</v>
<v Speaker 1>we just say,</v>

1110
01:05:34.361 --> 01:05:36.820
<v Speaker 1>well,</v>
<v Speaker 1>anytime anything changes in the world,</v>

1111
01:05:36.910 --> 01:05:38.080
<v Speaker 1>that's what we're going to react to.</v>

1112
01:05:38.410 --> 01:05:40.300
<v Speaker 1>And of course if you look at the </v>
<v Speaker 1>biological world,</v>

1113
01:05:40.330 --> 01:05:45.330
<v Speaker 1>similar sorts of tricks are being used.</v>
<v Speaker 1>So that's one of the core ones that </v>

1114
01:05:45.330 --> 01:05:46.990
<v Speaker 1>actually permeates a multiple of the </v>
<v Speaker 1>mechanisms.</v>

1115
01:05:47.210 --> 01:05:49.960
<v Speaker 1>Uh,</v>
<v Speaker 1>when it comes to individual tasks,</v>

1116
01:05:51.300 --> 01:05:54.090
<v Speaker 1>it really is task specific,</v>
<v Speaker 1>what that is.</v>

1117
01:05:54.091 --> 01:05:57.450
<v Speaker 1>So for instance,</v>
<v Speaker 1>with the liars dice game,</v>

1118
01:05:57.900 --> 01:06:02.900
<v Speaker 1>if you were to go and download it,</v>
<v Speaker 1>when you're setting the level of </v>

1119
01:06:02.900 --> 01:06:07.161
<v Speaker 1>difficulty of it,</v>
<v Speaker 1>what you're basically selecting is the </v>

1120
01:06:07.161 --> 01:06:07.770
<v Speaker 1>subset of sharistics that are being </v>
<v Speaker 1>applied.</v>

1121
01:06:07.890 --> 01:06:12.750
<v Speaker 1>And it starts very simply with things </v>
<v Speaker 1>like if I see lots of sixes,</v>

1122
01:06:12.870 --> 01:06:16.110
<v Speaker 1>then I'm likely to believe a high number</v>
<v Speaker 1>of six exist.</v>

1123
01:06:16.200 --> 01:06:18.600
<v Speaker 1>But if I don't,</v>
<v Speaker 1>they're probably not there at all.</v>

1124
01:06:18.870 --> 01:06:23.870
<v Speaker 1>So it's a start.</v>
<v Speaker 1>But any Bayesian wouldn't really buy </v>

1125
01:06:23.870 --> 01:06:27.711
<v Speaker 1>that argument.</v>
<v Speaker 1>So then you start tacking on a little </v>

1126
01:06:27.711 --> 01:06:31.371
<v Speaker 1>bit of probabilistic calculation and </v>
<v Speaker 1>then attacks on some history of prior </v>

1127
01:06:31.371 --> 01:06:36.021
<v Speaker 1>actions of the agents.</v>
<v Speaker 1>So it really just builds now the rosy </v>

1128
01:06:36.331 --> 01:06:41.331
<v Speaker 1>system.</v>
<v Speaker 1>One of the cool things they're doing is </v>

1129
01:06:41.331 --> 01:06:43.161
<v Speaker 1>game learning and specifically having </v>
<v Speaker 1>the agent be able to accept by a text </v>

1130
01:06:45.500 --> 01:06:50.500
<v Speaker 1>like natural text,</v>
<v Speaker 1>a heuristics about how to play the game </v>

1131
01:06:50.941 --> 01:06:52.350
<v Speaker 1>even when it's not sure what to do.</v>

1132
01:06:52.860 --> 01:06:53.880
<v Speaker 6>Oh,</v>
<v Speaker 6>so you.</v>

1133
01:06:53.940 --> 01:06:56.820
<v Speaker 6>At one point you mentioned about </v>
<v Speaker 6>generating new rules.</v>

1134
01:06:57.660 --> 01:06:59.580
<v Speaker 6>So I'm wondering like how do you do </v>
<v Speaker 6>that?</v>

1135
01:06:59.670 --> 01:07:01.280
<v Speaker 6>So okay,</v>
<v Speaker 6>so I'm.</v>

1136
01:07:01.800 --> 01:07:04.230
<v Speaker 6>The first thing that comes to my mind </v>
<v Speaker 6>are local search methods.</v>

1137
01:07:04.320 --> 01:07:05.270
<v Speaker 6>Okay.</v>
<v Speaker 6>So</v>

1138
01:07:06.170 --> 01:07:11.170
<v Speaker 1>one thing is you can actually implement </v>
<v Speaker 1>heuristic search in rules in the system </v>

1139
01:07:11.170 --> 01:07:12.770
<v Speaker 1>and that's actually how the robot </v>
<v Speaker 1>navigates itself.</v>

1140
01:07:12.771 --> 01:07:17.771
<v Speaker 1>So it does heuristic search,</v>
<v Speaker 1>but at the level of rules generate new </v>

1141
01:07:17.771 --> 01:07:22.121
<v Speaker 1>rules.</v>
<v Speaker 1>That chunking mechanism says the </v>

1142
01:07:22.121 --> 01:07:24.731
<v Speaker 1>following,</v>
<v Speaker 1>if it's the case that in order to solve </v>

1143
01:07:24.731 --> 01:07:27.911
<v Speaker 1>a problem you had to kind of sub goal </v>
<v Speaker 1>and do some other work and you figure </v>

1144
01:07:27.911 --> 01:07:30.680
<v Speaker 1>out how to solve all that work and </v>
<v Speaker 1>you've got a result then,</v>

1145
01:07:30.820 --> 01:07:35.820
<v Speaker 1>and I'm greatly oversimplifying,</v>
<v Speaker 1>but if you ever were in the same </v>

1146
01:07:35.820 --> 01:07:39.131
<v Speaker 1>situation again,</v>
<v Speaker 1>why don't I just memorize the solution </v>

1147
01:07:39.131 --> 01:07:43.151
<v Speaker 1>for that same situation.</v>
<v Speaker 1>So it basically learns over all the sub </v>

1148
01:07:43.151 --> 01:07:48.101
<v Speaker 1>processing that was done and encodes the</v>
<v Speaker 1>situation that was in those conditions </v>

1149
01:07:48.101 --> 01:07:49.490
<v Speaker 1>and the results that were produced as </v>
<v Speaker 1>action.</v>

1150
01:07:49.610 --> 01:07:51.680
<v Speaker 1>And that's the new rule.</v>
<v Speaker 1>Alright,</v>

1151
01:07:51.710 --> 01:07:51.950
<v Speaker 1>thank you.</v>

1152
01:07:53.540 --> 01:07:57.160
<v Speaker 6>I'm high.</v>
<v Speaker 6>So deep learning and neural networks.</v>

1153
01:07:57.190 --> 01:08:02.190
<v Speaker 6>So it looks at it as a bit of an </v>
<v Speaker 6>impedance mismatch between your system </v>

1154
01:08:02.190 --> 01:08:06.241
<v Speaker 6>and those types of system because you've</v>
<v Speaker 6>got a fixed kind of memory architecture </v>

1155
01:08:06.241 --> 01:08:10.711
<v Speaker 6>and they've got the memory and the wills</v>
<v Speaker 6>all kind of mixed together into one </v>

1156
01:08:10.711 --> 01:08:13.441
<v Speaker 6>system.</v>
<v Speaker 6>But could you interface your system or </v>

1157
01:08:13.441 --> 01:08:15.980
<v Speaker 6>sort of like system with deep learning </v>
<v Speaker 6>by playing in deep learning agents as</v>

1158
01:08:15.980 --> 01:08:20.980
<v Speaker 1>rules in your system.</v>
<v Speaker 1>So it would have to have some local </v>

1159
01:08:20.980 --> 01:08:23.471
<v Speaker 1>memory but some reason you can't plug in</v>
<v Speaker 1>deep learning as a kind of a rule like </v>

1160
01:08:24.441 --> 01:08:29.441
<v Speaker 1>module.</v>
<v Speaker 1>So I'm going to answer this.</v>

1161
01:08:29.511 --> 01:08:32.460
<v Speaker 1>You work on it is has there been any </v>
<v Speaker 1>work on that or.</v>

1162
01:08:32.960 --> 01:08:36.410
<v Speaker 1>Yeah,</v>
<v Speaker 1>so I'll answer it at multiple levels.</v>

1163
01:08:36.470 --> 01:08:41.470
<v Speaker 1>One is you are writing a system and you </v>
<v Speaker 1>want to use both of these things.</v>

1164
01:08:41.811 --> 01:08:46.811
<v Speaker 1>How do you make them talk and there is </v>
<v Speaker 1>an Api that you can interface with any </v>

1165
01:08:46.821 --> 01:08:49.550
<v Speaker 1>environment in any set of tools and if </v>
<v Speaker 1>people are earning is one of them.</v>

1166
01:08:49.551 --> 01:08:51.200
<v Speaker 1>Great.</v>
<v Speaker 1>And if so is the other one.</v>

1167
01:08:51.201 --> 01:08:56.201
<v Speaker 1>Cool.</v>
<v Speaker 1>Do you have no problem and you can do </v>

1168
01:08:56.201 --> 01:08:57.851
<v Speaker 1>that today.</v>
<v Speaker 1>And we have done this numerous times in </v>

1169
01:08:57.851 --> 01:08:57.851
<v Speaker 1>terms of integration into the </v>
<v Speaker 1>architecture.</v>

1170
01:08:58.670 --> 01:09:03.670
<v Speaker 1>All we have to do is think of a sub </v>
<v Speaker 1>problem in which all over simplify this,</v>

1171
01:09:06.471 --> 01:09:08.540
<v Speaker 1>but basically function approximation is </v>
<v Speaker 1>useful.</v>

1172
01:09:08.690 --> 01:09:13.690
<v Speaker 1>I'm seeing basically kind of the,</v>
<v Speaker 1>a fixed structure of input.</v>

1173
01:09:14.780 --> 01:09:19.780
<v Speaker 1>I'm getting feedback as to the output </v>
<v Speaker 1>and I want to learn the mapping to that </v>

1174
01:09:19.780 --> 01:09:20.900
<v Speaker 1>over time.</v>
<v Speaker 1>If you can make that case,</v>

1175
01:09:21.170 --> 01:09:23.570
<v Speaker 1>then you integrate it as a part of the </v>
<v Speaker 1>module.</v>

1176
01:09:23.960 --> 01:09:24.970
<v Speaker 1>Great.</v>
<v Speaker 1>Uh,</v>

1177
01:09:24.971 --> 01:09:29.971
<v Speaker 1>and we have learning mechanisms that do </v>
<v Speaker 1>some of that deep learning just hasn't </v>

1178
01:09:30.290 --> 01:09:33.380
<v Speaker 1>been used to my knowledge to solve any </v>
<v Speaker 1>of those sub problems.</v>

1179
01:09:33.381 --> 01:09:36.230
<v Speaker 1>There's nothing keeping it from being </v>
<v Speaker 1>one of those,</v>

1180
01:09:36.380 --> 01:09:40.940
<v Speaker 1>particularly when it comes down to the </v>
<v Speaker 1>low level visual part of things,</v>

1181
01:09:42.340 --> 01:09:47.340
<v Speaker 1>a problem that arises.</v>
<v Speaker 1>So I'll say what actually makes some of </v>

1182
01:09:48.321 --> 01:09:49.650
<v Speaker 1>this difficult,</v>
<v Speaker 1>uh,</v>

1183
01:09:49.670 --> 01:09:51.770
<v Speaker 1>and it's a general problem called symbol</v>
<v Speaker 1>grounding.</v>

1184
01:09:52.550 --> 01:09:56.450
<v Speaker 1>So at the level of what most,</v>
<v Speaker 1>what happens mostly in store,</v>

1185
01:09:56.451 --> 01:10:01.451
<v Speaker 1>it is symbols being manipulated in a </v>
<v Speaker 1>highly discreet way and so how do you </v>

1186
01:10:02.541 --> 01:10:07.541
<v Speaker 1>get yourself from pixels and low level </v>
<v Speaker 1>non symbolic representations to </v>

1187
01:10:07.541 --> 01:10:12.461
<v Speaker 1>something that's stable and discreet and</v>
<v Speaker 1>can be manipulated and that is </v>

1188
01:10:12.770 --> 01:10:17.770
<v Speaker 1>absolutely an open question in that </v>
<v Speaker 1>community and that will make things </v>

1189
01:10:17.770 --> 01:10:17.770
<v Speaker 1>hard.</v>

1190
01:10:17.770 --> 01:10:22.480
<v Speaker 1>So spawn actually has an interesting </v>
<v Speaker 1>answer to that and it has a distributed </v>

1191
01:10:22.480 --> 01:10:27.071
<v Speaker 1>representation and it operates over </v>
<v Speaker 1>distributed representations in what </v>

1192
01:10:27.071 --> 01:10:30.530
<v Speaker 1>might feel like a symbolic way.</v>
<v Speaker 1>So they're kind of ahead of us on that,</v>

1193
01:10:30.890 --> 01:10:35.890
<v Speaker 1>but they're,</v>
<v Speaker 1>they're starting from a lower point and </v>

1194
01:10:35.890 --> 01:10:38.621
<v Speaker 1>so they've dealt with some of these </v>
<v Speaker 1>issues and they have a pretty good </v>

1195
01:10:38.621 --> 01:10:38.621
<v Speaker 1>answer to that and that's how they're </v>
<v Speaker 1>moving up.</v>

1196
01:10:38.621 --> 01:10:41.600
<v Speaker 1>And that's also why I showed sigma,</v>
<v Speaker 1>which is at its low level,</v>

1197
01:10:41.660 --> 01:10:46.660
<v Speaker 1>it's message passing algorithms.</v>
<v Speaker 1>It's implementing things like a slam and</v>

1198
01:10:47.360 --> 01:10:52.360
<v Speaker 1>sat solving and other sorts of really,</v>
<v Speaker 1>really it can implement those on very </v>

1199
01:10:52.360 --> 01:10:55.580
<v Speaker 1>low level primitives but higher up it </v>
<v Speaker 1>can also be doing what soar is doing.</v>

1200
01:10:55.610 --> 01:10:57.790
<v Speaker 1>So there's an answer there as well.</v>
<v Speaker 1>Okay.</v>

1201
01:10:57.800 --> 01:10:58.330
<v Speaker 1>Thank you.</v>
<v Speaker 1>Um,</v>

1202
01:10:58.340 --> 01:11:00.070
<v Speaker 1>so another way of doing it would be to </v>
<v Speaker 1>layer the,</v>

1203
01:11:00.240 --> 01:11:01.360
<v Speaker 1>um,</v>
<v Speaker 1>the system,</v>

1204
01:11:01.370 --> 01:11:04.750
<v Speaker 1>so have a system,</v>
<v Speaker 1>preprocessing the,</v>

1205
01:11:05.050 --> 01:11:07.390
<v Speaker 1>the,</v>
<v Speaker 1>the sensory input or post processing and</v>

1206
01:11:07.391 --> 01:11:12.391
<v Speaker 1>then draft and the other one,</v>
<v Speaker 1>that'd be another way of combining the </v>

1207
01:11:12.391 --> 01:11:12.391
<v Speaker 1>two.</v>

1208
01:11:12.391 --> 01:11:12.500
<v Speaker 1>And that's actually what's going on in </v>
<v Speaker 1>the rosy system.</v>

1209
01:11:12.501 --> 01:11:17.501
<v Speaker 1>So the detection of objects in the scene</v>
<v Speaker 1>is a Jew just software that somebody </v>

1210
01:11:17.501 --> 01:11:22.401
<v Speaker 1>wrote.</v>
<v Speaker 1>I don't believe it's the deep learning </v>

1211
01:11:22.401 --> 01:11:22.740
<v Speaker 1>specifically,</v>
<v Speaker 1>but like the color detection out of it I</v>

1212
01:11:23.190 --> 01:11:28.170
<v Speaker 1>think is an Svm if I'm correct so easily</v>
<v Speaker 1>could be deep learning.</v>

1213
01:11:28.640 --> 01:11:33.640
<v Speaker 1>Thanks.</v>
<v Speaker 1>You mentioned like the importance of </v>

1214
01:11:33.640 --> 01:11:33.990
<v Speaker 1>forgetting in order to food memory </v>
<v Speaker 1>issues,</v>

1215
01:11:34.080 --> 01:11:39.080
<v Speaker 1>but you said you could only forget </v>
<v Speaker 1>because you could reconstruct and I'm </v>

1216
01:11:39.080 --> 01:11:39.080
<v Speaker 1>curious,</v>
<v Speaker 1>how do you,</v>

1217
01:11:39.080 --> 01:11:40.410
<v Speaker 1>when you said we can show you each know </v>
<v Speaker 1>that it happened before,</v>

1218
01:11:40.411 --> 01:11:45.411
<v Speaker 1>so do you just compress the data?</v>
<v Speaker 1>Like do you really forget it or okay,</v>

1219
01:11:46.390 --> 01:11:51.390
<v Speaker 1>so and I put quotes up and I said,</v>
<v Speaker 1>you think you can reconstruct it?</v>

1220
01:11:52.050 --> 01:11:57.050
<v Speaker 1>So we came up with approximations of </v>
<v Speaker 1>this and so let me try to answer this </v>

1221
01:11:57.511 --> 01:12:02.511
<v Speaker 1>very grounded when it comes to the </v>
<v Speaker 1>mobile robot and you had rooms that you </v>

1222
01:12:04.681 --> 01:12:09.681
<v Speaker 1>had been to before the entire map and </v>
<v Speaker 1>its entirety was being constructed in </v>

1223
01:12:09.681 --> 01:12:10.890
<v Speaker 1>the robots.</v>

1224
01:12:11.340 --> 01:12:13.080
<v Speaker 1>Semantic memory.</v>
<v Speaker 1>So here's facts.</v>

1225
01:12:13.081 --> 01:12:18.081
<v Speaker 1>This room is connected to this room </v>
<v Speaker 1>which is connected this room which </v>

1226
01:12:18.081 --> 01:12:18.510
<v Speaker 1>connected this room.</v>
<v Speaker 1>So we had those sorts of representations</v>

1227
01:12:18.511 --> 01:12:23.511
<v Speaker 1>that existed up in semantic memory.</v>
<v Speaker 1>The rules can only operate down on </v>

1228
01:12:23.511 --> 01:12:28.371
<v Speaker 1>anything that's in short term memory.</v>
<v Speaker 1>So basically we were removing things </v>

1229
01:12:28.371 --> 01:12:30.540
<v Speaker 1>from the short term memory and as </v>
<v Speaker 1>necessary be able to reconstruct it from</v>

1230
01:12:30.541 --> 01:12:35.541
<v Speaker 1>the longterm.</v>
<v Speaker 1>You could end up in some situations in </v>

1231
01:12:35.541 --> 01:12:37.380
<v Speaker 1>which you had made a change locally in </v>
<v Speaker 1>short term memory,</v>

1232
01:12:37.560 --> 01:12:42.560
<v Speaker 1>didn't get a chance to get it up and it </v>
<v Speaker 1>actually happened to be forgotten a way </v>

1233
01:12:42.560 --> 01:12:46.880
<v Speaker 1>so you weren't guaranteed,</v>
<v Speaker 1>but it was good enough that the </v>

1234
01:12:46.880 --> 01:12:51.591
<v Speaker 1>connectivity survived.</v>
<v Speaker 1>The agent was able to perform the exact </v>

1235
01:12:51.591 --> 01:12:52.920
<v Speaker 1>same task and we gained some benefit for</v>
<v Speaker 1>the RL system.</v>

1236
01:12:53.790 --> 01:12:58.590
<v Speaker 1>The rule we came up with was the initial</v>
<v Speaker 1>estimates in the value system,</v>

1237
01:12:58.591 --> 01:13:00.150
<v Speaker 1>which is,</v>
<v Speaker 1>here's how good I think that is,</v>

1238
01:13:00.180 --> 01:13:03.240
<v Speaker 1>that's based on the heuristics I </v>
<v Speaker 1>described earlier.</v>

1239
01:13:03.300 --> 01:13:05.790
<v Speaker 1>Some simple probabilistic calculations </v>
<v Speaker 1>of counting some stuff.</v>

1240
01:13:05.791 --> 01:13:10.791
<v Speaker 1>That's where that number came from.</v>
<v Speaker 1>We computer before we could compute it </v>

1241
01:13:10.791 --> 01:13:13.761
<v Speaker 1>again.</v>
<v Speaker 1>The only time we can't reconstruct it </v>

1242
01:13:13.761 --> 01:13:15.460
<v Speaker 1>completely is if it had seen a certain </v>
<v Speaker 1>number of updates over time.</v>

1243
01:13:16.290 --> 01:13:20.550
<v Speaker 1>It's such a large state space.</v>
<v Speaker 1>There are so many actions,</v>

1244
01:13:20.551 --> 01:13:24.960
<v Speaker 1>so many states that most of the states </v>
<v Speaker 1>were never being seen.</v>

1245
01:13:26.010 --> 01:13:29.270
<v Speaker 1>So most of those could be exactly </v>
<v Speaker 1>reproduced by,</v>

1246
01:13:29.271 --> 01:13:34.271
<v Speaker 1>uh,</v>
<v Speaker 1>the agent just thinking about it a </v>

1247
01:13:34.271 --> 01:13:34.271
<v Speaker 1>little bit.</v>
<v Speaker 1>And there was only a tiny,</v>

1248
01:13:34.271 --> 01:13:38.121
<v Speaker 1>tiny,</v>
<v Speaker 1>I'm going to say under one percent of </v>

1249
01:13:38.121 --> 01:13:38.850
<v Speaker 1>the estimate the value system that ever </v>
<v Speaker 1>got updates.</v>

1250
01:13:38.940 --> 01:13:43.940
<v Speaker 1>And that's actually not inconsistent </v>
<v Speaker 1>with a lot of these kinds of problems </v>

1251
01:13:43.940 --> 01:13:44.430
<v Speaker 1>that have really,</v>
<v Speaker 1>really large state spaces.</v>

1252
01:13:44.820 --> 01:13:46.020
<v Speaker 1>So,</v>
<v Speaker 1>uh,</v>

1253
01:13:46.021 --> 01:13:48.000
<v Speaker 1>I think the statement was something </v>
<v Speaker 1>like,</v>

1254
01:13:49.110 --> 01:13:52.650
<v Speaker 1>if we had ever updated it,</v>
<v Speaker 1>don't forget it.</v>

1255
01:13:53.820 --> 01:13:57.870
<v Speaker 1>And you saw that was already reducing </v>
<v Speaker 1>more than half of the memory load.</v>

1256
01:13:58.170 --> 01:14:02.040
<v Speaker 1>We could have something higher to say 10</v>
<v Speaker 1>times something like that.</v>

1257
01:14:02.041 --> 01:14:06.270
<v Speaker 1>And that would say we could reconstruct </v>
<v Speaker 1>almost all of it.</v>

1258
01:14:06.720 --> 01:14:11.720
<v Speaker 1>The prior work that I referenced was </v>
<v Speaker 1>strictly saying if it falls below </v>

1259
01:14:11.720 --> 01:14:16.321
<v Speaker 1>threshold,</v>
<v Speaker 1>no matter how many times they ended up </v>

1260
01:14:16.321 --> 01:14:17.911
<v Speaker 1>dating,</v>
<v Speaker 1>no matter how much information was </v>

1261
01:14:17.911 --> 01:14:19.801
<v Speaker 1>there.</v>
<v Speaker 1>And so when we were adding was probably </v>

1262
01:14:19.801 --> 01:14:22.321
<v Speaker 1>can reconstruct and that was getting us </v>
<v Speaker 1>the balance between the efficiency and </v>

1263
01:14:23.260 --> 01:14:24.040
<v Speaker 1>the ability to forget.</v>

1264
01:14:24.270 --> 01:14:25.950
<v Speaker 7>So just in its infancy,</v>
<v Speaker 7>we can probably,</v>

1265
01:14:25.951 --> 01:14:30.951
<v Speaker 7>we can show you state you keep trying to</v>
<v Speaker 7>use generic is the issue needs to be </v>

1266
01:14:30.951 --> 01:14:30.951
<v Speaker 7>constructed.</v>
<v Speaker 7>Your will,</v>

1267
01:14:30.951 --> 01:14:32.490
<v Speaker 7>you're going to run it again sometime</v>

1268
01:14:33.520 --> 01:14:38.520
<v Speaker 1>fly.</v>
<v Speaker 1>If I get back into that situation and I </v>

1269
01:14:38.520 --> 01:14:40.531
<v Speaker 1>happen to forget it,</v>
<v Speaker 1>the system knew how to compute it the </v>

1270
01:14:40.531 --> 01:14:43.951
<v Speaker 1>first time it goes and looks at all the </v>
<v Speaker 1>hand and just pretends it's in that </v>

1271
01:14:43.951 --> 01:14:44.020
<v Speaker 1>situation for the very,</v>
<v Speaker 1>very first time.</v>

1272
01:14:44.200 --> 01:14:45.580
<v Speaker 1>Reconstruct that value estimate.</v>

1273
01:14:47.070 --> 01:14:50.290
<v Speaker 6>Just a quick question on top of that </v>
<v Speaker 6>again,</v>

1274
01:14:50.950 --> 01:14:51.840
<v Speaker 6>question.</v>
<v Speaker 6>Okay.</v>

1275
01:14:52.320 --> 01:14:55.920
<v Speaker 6>So the actual mechanism of forgetting is</v>
<v Speaker 6>fascinating.</v>

1276
01:14:55.921 --> 01:15:00.921
<v Speaker 6>So lstmrs,</v>
<v Speaker 6>rns have mechanisms for learning what to</v>

1277
01:15:01.621 --> 01:15:03.600
<v Speaker 6>forget and whatnot to forget.</v>
<v Speaker 6>Have you,</v>

1278
01:15:04.400 --> 01:15:09.400
<v Speaker 6>has there been any exploration of </v>
<v Speaker 6>learning the forgetting process says </v>

1279
01:15:09.670 --> 01:15:14.670
<v Speaker 6>doing something complicated or </v>
<v Speaker 6>interesting with which parts to forget </v>

1280
01:15:14.670 --> 01:15:14.670
<v Speaker 6>or not?</v>

1281
01:15:14.670 --> 01:15:19.270
<v Speaker 1>Uh,</v>
<v Speaker 1>the closest I will say was kind of a </v>

1282
01:15:19.270 --> 01:15:23.050
<v Speaker 1>metacognition project that's 10 or 15 </v>
<v Speaker 1>years old at this point,</v>

1283
01:15:23.380 --> 01:15:28.380
<v Speaker 1>which was what happens when it gets into</v>
<v Speaker 1>a place where it actually knows that it </v>

1284
01:15:28.380 --> 01:15:33.331
<v Speaker 1>learned something that's harmful to it,</v>
<v Speaker 1>that's leading to poor decisions.</v>

1285
01:15:34.150 --> 01:15:39.150
<v Speaker 1>Uh,</v>
<v Speaker 1>and in that case it was still a very </v>

1286
01:15:39.150 --> 01:15:41.641
<v Speaker 1>rule based process,</v>
<v Speaker 1>but it wasn't learning to forget he was </v>

1287
01:15:41.641 --> 01:15:43.330
<v Speaker 1>actually learning to override it's prior</v>
<v Speaker 1>knowledge,</v>

1288
01:15:43.570 --> 01:15:48.220
<v Speaker 1>which might be closer to some of what we</v>
<v Speaker 1>do when we know we have a bad habit.</v>

1289
01:15:48.460 --> 01:15:51.280
<v Speaker 1>We don't have a way of forgetting that </v>
<v Speaker 1>habit,</v>

1290
01:15:51.281 --> 01:15:56.281
<v Speaker 1>but instead we can try to learn </v>
<v Speaker 1>something on top of that that leads to </v>

1291
01:15:56.281 --> 01:15:58.660
<v Speaker 1>better a operation in the future.</v>
<v Speaker 1>To my knowledge that's the only work,</v>

1292
01:15:58.690 --> 01:16:00.130
<v Speaker 1>at least in sore that's been done.</v>

1293
01:16:00.890 --> 01:16:05.890
<v Speaker 6>Just find the topic really fascinating.</v>
<v Speaker 6>What lessons do you think we can draw </v>

1294
01:16:06.311 --> 01:16:11.311
<v Speaker 6>from the fact that forgetting.</v>
<v Speaker 6>So ultimately you're the action of </v>

1295
01:16:11.311 --> 01:16:15.130
<v Speaker 6>forgetting a is driven by the fact that </v>
<v Speaker 6>you want to improve performance,</v>

1296
01:16:15.310 --> 01:16:19.540
<v Speaker 6>but do you think for getting is </v>
<v Speaker 6>essential for Agi,</v>

1297
01:16:20.200 --> 01:16:24.310
<v Speaker 6>the act of forgetting for building </v>
<v Speaker 6>systems that operate in as well.</v>

1298
01:16:24.580 --> 01:16:26.110
<v Speaker 6>How important is forgetting?</v>

1299
01:16:26.520 --> 01:16:30.030
<v Speaker 1>I can think of easy answers to that.</v>
<v Speaker 1>So one might be,</v>

1300
01:16:31.890 --> 01:16:33.750
<v Speaker 1>if we take the cognitive modeling </v>
<v Speaker 1>approach,</v>

1301
01:16:33.810 --> 01:16:38.810
<v Speaker 1>we know humans do forget and we know </v>
<v Speaker 1>regularities of how humans forget.</v>

1302
01:16:40.080 --> 01:16:45.080
<v Speaker 1>And so whether or not the system itself </v>
<v Speaker 1>forgets at least has to model the fact </v>

1303
01:16:45.080 --> 01:16:47.550
<v Speaker 1>that the humans it's interacting with </v>
<v Speaker 1>are going to forget.</v>

1304
01:16:47.730 --> 01:16:52.730
<v Speaker 1>And so at least it has to have that </v>
<v Speaker 1>ability to model in order to interact </v>

1305
01:16:52.730 --> 01:16:56.781
<v Speaker 1>effectively because if it assumes we </v>
<v Speaker 1>always remember everything and can't </v>

1306
01:16:56.781 --> 01:16:58.660
<v Speaker 1>operate well in that environment,</v>
<v Speaker 1>uh,</v>

1307
01:16:58.680 --> 01:17:03.680
<v Speaker 1>I think we're going to have a problem is</v>
<v Speaker 1>true for getting going to be necessary.</v>

1308
01:17:09.680 --> 01:17:11.030
<v Speaker 1>That's interesting.</v>
<v Speaker 1>Our,</v>

1309
01:17:11.070 --> 01:17:14.420
<v Speaker 1>our agi system is going to hold a grudge</v>
<v Speaker 1>for all eternity.</v>

1310
01:17:15.230 --> 01:17:19.340
<v Speaker 1>We might want them to forget this early </v>
<v Speaker 1>age when we were forcing them to work in</v>

1311
01:17:19.341 --> 01:17:21.260
<v Speaker 1>our laboratory.</v>
<v Speaker 1>I think I know what you're trying to.</v>

1312
01:17:21.320 --> 01:17:22.100
<v Speaker 1>Yeah,</v>
<v Speaker 1>exactly.</v>

1313
01:17:22.400 --> 01:17:25.820
<v Speaker 1>Exactly.</v>
<v Speaker 1>And how to build such a system.</v>

1314
01:17:25.850 --> 01:17:26.650
<v Speaker 1>Yeah,</v>
<v Speaker 1>exactly.</v>

1315
01:17:28.640 --> 01:17:28.880
<v Speaker 1>Go ahead.</v>

1316
01:17:29.530 --> 01:17:32.500
<v Speaker 6>So I have two quick,</v>
<v Speaker 6>two quick questions.</v>

1317
01:17:33.010 --> 01:17:38.010
<v Speaker 6>One is,</v>
<v Speaker 6>would you be able to speculate on how </v>

1318
01:17:38.010 --> 01:17:41.521
<v Speaker 6>you can connect function approximators </v>
<v Speaker 6>such as deep down works to symbols.</v>

1319
01:17:42.070 --> 01:17:44.350
<v Speaker 6>And the second question is completely </v>
<v Speaker 6>different.</v>

1320
01:17:44.800 --> 01:17:49.800
<v Speaker 6>This is regarding your action selection.</v>
<v Speaker 6>I know you didn't speak much about that </v>

1321
01:17:50.350 --> 01:17:54.430
<v Speaker 6>when you have different theories in your</v>
<v Speaker 6>knowledge representation and you have an</v>

1322
01:17:54.431 --> 01:17:59.431
<v Speaker 6>action selection which has to make </v>
<v Speaker 6>constructive plan by reasoning about the</v>

1323
01:17:59.651 --> 01:18:04.651
<v Speaker 6>different theories and the different </v>
<v Speaker 6>pieces of knowledge that are now held </v>

1324
01:18:04.651 --> 01:18:04.680
<v Speaker 6>within a,</v>
<v Speaker 6>you know,</v>

1325
01:18:04.810 --> 01:18:06.570
<v Speaker 6>your,</v>
<v Speaker 6>your memory or anything like that.</v>

1326
01:18:06.610 --> 01:18:11.610
<v Speaker 6>All your rules.</v>
<v Speaker 6>What kind of algorithms to use in the </v>

1327
01:18:11.610 --> 01:18:12.340
<v Speaker 6>action selection to come up with a </v>
<v Speaker 6>plant,</v>

1328
01:18:12.370 --> 01:18:17.370
<v Speaker 6>you know,</v>
<v Speaker 6>is there any concept of differentiation </v>

1329
01:18:17.370 --> 01:18:19.741
<v Speaker 6>of the symbols or you know,</v>
<v Speaker 6>or grammars or admissible grammars and </v>

1330
01:18:19.741 --> 01:18:20.680
<v Speaker 6>things like that that you use in action </v>
<v Speaker 6>selection?</v>

1331
01:18:21.290 --> 01:18:26.290
<v Speaker 1>I'm actually going to answer the second </v>
<v Speaker 1>question first and then you're going to </v>

1332
01:18:26.290 --> 01:18:27.670
<v Speaker 1>have to remind me of what the first one </v>
<v Speaker 1>was.</v>

1333
01:18:27.980 --> 01:18:28.600
<v Speaker 1>Uh,</v>
<v Speaker 1>when I,</v>

1334
01:18:28.601 --> 01:18:31.510
<v Speaker 1>when I get to the end.</v>
<v Speaker 1>So the action selection mechanism,</v>

1335
01:18:32.020 --> 01:18:35.080
<v Speaker 1>one of these core tenants I said is it's</v>
<v Speaker 1>got to get through this cycle fast.</v>

1336
01:18:35.200 --> 01:18:38.140
<v Speaker 1>So everything that's really,</v>
<v Speaker 1>really built in has to be really,</v>

1337
01:18:38.141 --> 01:18:43.141
<v Speaker 1>really simple.</v>
<v Speaker 1>And so the decision procedure is </v>

1338
01:18:43.141 --> 01:18:43.141
<v Speaker 1>actually really,</v>
<v Speaker 1>really simple.</v>

1339
01:18:43.141 --> 01:18:46.030
<v Speaker 1>It says the rules are going to fire,</v>
<v Speaker 1>the rules are going,</v>

1340
01:18:46.230 --> 01:18:51.230
<v Speaker 1>the production rules are going to fire,</v>
<v Speaker 1>and there's gonna be a subset of them </v>

1341
01:18:51.230 --> 01:18:52.810
<v Speaker 1>that will say something like,</v>
<v Speaker 1>here's an operator that you could select</v>

1342
01:18:53.020 --> 01:18:58.020
<v Speaker 1>to.</v>
<v Speaker 1>These are of acceptable operator </v>

1343
01:18:58.020 --> 01:18:58.020
<v Speaker 1>preferences.</v>
<v Speaker 1>There are ones are gonna say,</v>

1344
01:18:58.020 --> 01:19:01.861
<v Speaker 1>well,</v>
<v Speaker 1>based upon the fact that you said that </v>

1345
01:19:01.861 --> 01:19:01.861
<v Speaker 1>that was acceptable,</v>
<v Speaker 1>I think it's the best thing,</v>

1346
01:19:01.861 --> 01:19:04.150
<v Speaker 1>or the worst thing,</v>
<v Speaker 1>or I think 50 50 chance I'm going to get</v>

1347
01:19:04.151 --> 01:19:05.080
<v Speaker 1>reward out of this.</v>

1348
01:19:05.230 --> 01:19:10.230
<v Speaker 1>There's actually a fixed language of </v>
<v Speaker 1>preferences that are being asserted and </v>

1349
01:19:10.230 --> 01:19:14.131
<v Speaker 1>actually a nice fixed procedure by which</v>
<v Speaker 1>if I have a set of preferences to make a</v>

1350
01:19:15.431 --> 01:19:20.431
<v Speaker 1>very quick and clean decision.</v>
<v Speaker 1>So what's basically happened is you've </v>

1351
01:19:20.431 --> 01:19:24.481
<v Speaker 1>pushed the hard questions of how to make</v>
<v Speaker 1>complex decisions about actions up to a </v>

1352
01:19:25.481 --> 01:19:30.481
<v Speaker 1>higher level.</v>
<v Speaker 1>The low level architecture is always </v>

1353
01:19:30.481 --> 01:19:33.960
<v Speaker 1>given a set of options going to be able </v>
<v Speaker 1>to make a relatively quick decision and </v>

1354
01:19:34.031 --> 01:19:39.031
<v Speaker 1>it gets pushed into the knowledge of the</v>
<v Speaker 1>agent to construct a sequence of </v>

1355
01:19:40.271 --> 01:19:43.080
<v Speaker 1>decisions that overtime is going to get </v>
<v Speaker 1>to.</v>

1356
01:19:43.081 --> 01:19:44.290
<v Speaker 1>The more interesting questions you're </v>
<v Speaker 1>talking,</v>

1357
01:19:44.590 --> 01:19:49.590
<v Speaker 6>but how can you reason that that </v>
<v Speaker 6>sequence will take you to the goal that </v>

1358
01:19:49.590 --> 01:19:49.590
<v Speaker 6>you desire?</v>

1359
01:19:49.590 --> 01:19:50.520
<v Speaker 1>So</v>

1360
01:19:51.610 --> 01:19:53.170
<v Speaker 6>is there any guarantee on that?</v>
<v Speaker 6>Is that.</v>

1361
01:19:53.260 --> 01:19:53.380
<v Speaker 6>Yeah.</v>

1362
01:19:53.710 --> 01:19:58.300
<v Speaker 1>Uh,</v>
<v Speaker 1>in general across tasks.</v>

1363
01:19:58.301 --> 01:20:01.390
<v Speaker 1>No,</v>
<v Speaker 1>but people have,</v>

1364
01:20:01.391 --> 01:20:06.391
<v Speaker 1>for instance,</v>
<v Speaker 1>implemented a star I was mentioning as </v>

1365
01:20:06.391 --> 01:20:06.391
<v Speaker 1>rules,</v>
<v Speaker 1>right?</v>

1366
01:20:06.391 --> 01:20:10.380
<v Speaker 1>Yeah.</v>
<v Speaker 1>So I know given certain properties about</v>

1367
01:20:10.381 --> 01:20:15.381
<v Speaker 1>the search task,</v>
<v Speaker 1>that task that's being searched based </v>

1368
01:20:15.381 --> 01:20:15.870
<v Speaker 1>upon these rules,</v>
<v Speaker 1>given a finite search space,</v>

1369
01:20:16.080 --> 01:20:19.500
<v Speaker 1>eventually it will get there.</v>
<v Speaker 1>And if I have a good heuristic in there,</v>

1370
01:20:19.501 --> 01:20:21.300
<v Speaker 1>I know certain properties about the </v>
<v Speaker 1>optimality.</v>

1371
01:20:22.050 --> 01:20:24.390
<v Speaker 1>So I can reason at that level.</v>
<v Speaker 1>In general,</v>

1372
01:20:24.391 --> 01:20:29.391
<v Speaker 1>I think this comes back to the </v>
<v Speaker 1>assumption I made earlier about bounded </v>

1373
01:20:29.391 --> 01:20:32.061
<v Speaker 1>rationality to say parts of the </v>
<v Speaker 1>architecture or solving sub-problems </v>

1374
01:20:32.310 --> 01:20:37.310
<v Speaker 1>optimally.</v>
<v Speaker 1>The general problems that it's going to </v>

1375
01:20:37.310 --> 01:20:40.281
<v Speaker 1>work on.</v>
<v Speaker 1>It's going to try its best based upon </v>

1376
01:20:40.281 --> 01:20:43.281
<v Speaker 1>the knowledge that it has.</v>
<v Speaker 1>And that's about the end of guarantees </v>

1377
01:20:43.281 --> 01:20:43.340
<v Speaker 1>that you can typically make any </v>
<v Speaker 1>architecture.</v>

1378
01:20:43.540 --> 01:20:46.980
<v Speaker 1>Okay.</v>
<v Speaker 1>I think your first question was</v>

1379
01:20:47.060 --> 01:20:52.060
<v Speaker 6>speculate on connecting symbol,</v>
<v Speaker 6>a product function approximators a </v>

1380
01:20:52.700 --> 01:20:57.700
<v Speaker 6>multiple layer function approximators </v>
<v Speaker 6>like deep learning networks to do </v>

1381
01:20:57.980 --> 01:21:00.470
<v Speaker 6>symbols that you can reason about at a </v>
<v Speaker 6>higher level.</v>

1382
01:21:00.980 --> 01:21:01.250
<v Speaker 6>Yeah,</v>

1383
01:21:02.430 --> 01:21:05.250
<v Speaker 1>I think that's a great open space.</v>
<v Speaker 1>If I had time,</v>

1384
01:21:05.251 --> 01:21:06.810
<v Speaker 1>this will be somebody I'll be working on</v>
<v Speaker 1>right now,</v>

1385
01:21:06.811 --> 01:21:11.811
<v Speaker 1>which is somewhere before I basically </v>
<v Speaker 1>said taking a scene and then detecting </v>

1386
01:21:13.741 --> 01:21:18.741
<v Speaker 1>objects out of that scene and using </v>
<v Speaker 1>those as simple as and reading about </v>

1387
01:21:18.741 --> 01:21:22.011
<v Speaker 1>those over time.</v>
<v Speaker 1>I think the spawn work is quite </v>

1388
01:21:22.011 --> 01:21:22.680
<v Speaker 1>interesting.</v>
<v Speaker 1>So</v>

1389
01:21:24.110 --> 01:21:29.110
<v Speaker 1>the symbols that they're operating on </v>
<v Speaker 1>are actually,</v>

1390
01:21:29.530 --> 01:21:34.530
<v Speaker 1>uh,</v>
<v Speaker 1>a distributed representation of the </v>

1391
01:21:34.530 --> 01:21:37.991
<v Speaker 1>input space.</v>
<v Speaker 1>And the closest I can get to this is if </v>

1392
01:21:37.991 --> 01:21:40.580
<v Speaker 1>you've seen a word tobacco where you're </v>
<v Speaker 1>taking a language corpus and what you're</v>

1393
01:21:40.581 --> 01:21:43.610
<v Speaker 1>getting out of there as a vector of </v>
<v Speaker 1>numbers that has certain properties,</v>

1394
01:21:43.760 --> 01:21:46.940
<v Speaker 1>but it's also a vector that you could </v>
<v Speaker 1>operate on as a unit.</v>

1395
01:21:47.330 --> 01:21:52.330
<v Speaker 1>So it has nice properties.</v>
<v Speaker 1>You can operate with it on other </v>

1396
01:21:52.330 --> 01:21:56.111
<v Speaker 1>vectors.</v>
<v Speaker 1>You know that if I got the same word in </v>

1397
01:21:56.111 --> 01:21:59.920
<v Speaker 1>the same context,</v>
<v Speaker 1>I would get back to that exact same </v>

1398
01:21:59.920 --> 01:22:03.220
<v Speaker 1>vector,</v>
<v Speaker 1>so those are the kind of representation </v>

1399
01:22:03.220 --> 01:22:06.341
<v Speaker 1>that seems like it's going to be able to</v>
<v Speaker 1>bridge that chasm where we can get from </v>

1400
01:22:06.590 --> 01:22:11.450
<v Speaker 1>sensory information to something that </v>
<v Speaker 1>can be operated on and reasoned about in</v>

1401
01:22:11.451 --> 01:22:16.070
<v Speaker 1>this sort of symbolic architecture and </v>
<v Speaker 1>get us from there.</v>

1402
01:22:16.071 --> 01:22:18.140
<v Speaker 1>From actual sensory information.</v>

1403
01:22:22.090 --> 01:22:27.090
<v Speaker 6>I had a question.</v>
<v Speaker 6>What do you think are the biggest </v>

1404
01:22:27.090 --> 01:22:29.740
<v Speaker 6>strengths of the cognitive architecture </v>
<v Speaker 6>approach compared to other approaches in</v>

1405
01:22:29.741 --> 01:22:33.010
<v Speaker 6>artificial intelligence?</v>
<v Speaker 6>And the flip side of that,</v>

1406
01:22:33.040 --> 01:22:38.040
<v Speaker 6>what do you think are the biggest </v>
<v Speaker 6>shortcomings of cognitive architecture </v>

1407
01:22:38.040 --> 01:22:38.380
<v Speaker 6>with respect to us</v>

1408
01:22:39.490 --> 01:22:43.710
<v Speaker 1>actually you being humans,</v>
<v Speaker 1>human level,</v>

1409
01:22:43.711 --> 01:22:48.711
<v Speaker 1>like like what needs to be like?</v>
<v Speaker 1>How come cognitive architecture has not </v>

1410
01:22:48.711 --> 01:22:53.001
<v Speaker 1>solved agi because we want job security.</v>
<v Speaker 1>That's the answer.</v>

1411
01:22:54.150 --> 01:22:59.150
<v Speaker 1>We've totally solved it already.</v>
<v Speaker 1>So strength I think conceptually is </v>

1412
01:23:02.970 --> 01:23:07.970
<v Speaker 1>keeping an eye on the ball,</v>
<v Speaker 1>which is if what you're looking at is </v>

1413
01:23:07.970 --> 01:23:08.320
<v Speaker 1>trying to make human level ai</v>

1414
01:23:10.130 --> 01:23:10.280
<v Speaker 2>I.</v>

1415
01:23:11.660 --> 01:23:13.550
<v Speaker 1>it's hard.</v>
<v Speaker 1>It's challenging.</v>

1416
01:23:13.551 --> 01:23:18.551
<v Speaker 1>It's ambitious to say that's the goal </v>
<v Speaker 1>because for decades we haven't done it.</v>

1417
01:23:20.090 --> 01:23:22.220
<v Speaker 1>It's extraordinarily hard.</v>
<v Speaker 1>It,</v>

1418
01:23:24.020 --> 01:23:29.020
<v Speaker 1>it is less difficult in some ways to </v>
<v Speaker 1>constrain yourself down to a single </v>

1419
01:23:29.020 --> 01:23:33.881
<v Speaker 1>problem that hadn't been said.</v>
<v Speaker 1>I'm not very good at making a car drive </v>

1420
01:23:34.551 --> 01:23:37.520
<v Speaker 1>itself.</v>
<v Speaker 1>In some ways that's a simpler problem.</v>

1421
01:23:38.380 --> 01:23:43.380
<v Speaker 1>It's great at challenging and of itself </v>
<v Speaker 1>and it will have great impact on </v>

1422
01:23:43.380 --> 01:23:43.970
<v Speaker 1>humanity.</v>
<v Speaker 1>It's a great problem to work on.</v>

1423
01:23:44.750 --> 01:23:46.340
<v Speaker 1>Human level.</v>
<v Speaker 1>Ai is huge.</v>

1424
01:23:46.370 --> 01:23:50.720
<v Speaker 1>It's not even well defined as a problem.</v>
<v Speaker 1>And so,</v>

1425
01:23:52.040 --> 01:23:52.960
<v Speaker 1>uh,</v>
<v Speaker 1>what,</v>

1426
01:23:52.970 --> 01:23:56.540
<v Speaker 1>what's the strength here?</v>
<v Speaker 1>Bravery.</v>

1427
01:23:56.690 --> 01:24:01.690
<v Speaker 1>Stupidity in the face of failure,</v>
<v Speaker 1>a resilience over time,</v>

1428
01:24:04.040 --> 01:24:09.020
<v Speaker 1>keeping alive.</v>
<v Speaker 1>This idea of trying to reproduce a level</v>

1429
01:24:09.021 --> 01:24:11.000
<v Speaker 1>of human intelligence that's more </v>
<v Speaker 1>general.</v>

1430
01:24:11.870 --> 01:24:13.670
<v Speaker 1>I don't know if that's a very </v>
<v Speaker 1>satisfactory answer for you.</v>

1431
01:24:15.140 --> 01:24:16.310
<v Speaker 1>Downside</v>

1432
01:24:18.600 --> 01:24:23.600
<v Speaker 1>home runs are fairly rare and by Homerun</v>
<v Speaker 1>I mean a system that finds its way to </v>

1433
01:24:26.610 --> 01:24:29.580
<v Speaker 1>the,</v>
<v Speaker 1>the general populace to the marketplace.</v>

1434
01:24:30.510 --> 01:24:33.700
<v Speaker 1>I'd mentioned Bonnie John specifically </v>
<v Speaker 1>because you know,</v>

1435
01:24:33.701 --> 01:24:38.701
<v Speaker 1>this is 20,</v>
<v Speaker 1>30 years of research and then she found </v>

1436
01:24:38.701 --> 01:24:39.930
<v Speaker 1>a way that actually makes a whole lot of</v>
<v Speaker 1>sense under direct application.</v>

1437
01:24:39.931 --> 01:24:42.120
<v Speaker 1>So it was a lot,</v>
<v Speaker 1>a lot of years of basic research,</v>

1438
01:24:42.121 --> 01:24:44.100
<v Speaker 1>a lot of researchers.</v>
<v Speaker 1>And then there was,</v>

1439
01:24:44.130 --> 01:24:47.220
<v Speaker 1>there was a big win,</v>
<v Speaker 1>there was this one,</v>

1440
01:24:47.400 --> 01:24:50.220
<v Speaker 1>oh,</v>
<v Speaker 1>this was a Bonnie,</v>

1441
01:24:50.221 --> 01:24:53.010
<v Speaker 1>John was a researcher,</v>
<v Speaker 1>or this was using act,</v>

1442
01:24:53.011 --> 01:24:58.011
<v Speaker 1>our models of eye gaze and reaction and </v>
<v Speaker 1>so forth to be able to make predictions </v>

1443
01:24:59.940 --> 01:25:04.650
<v Speaker 1>about how humans would use a user </v>
<v Speaker 1>interfaces.</v>

1444
01:25:06.990 --> 01:25:11.990
<v Speaker 1>So those sorts of outcomes are rare.</v>
<v Speaker 1>It if you work in ai,</v>

1445
01:25:13.260 --> 01:25:15.930
<v Speaker 1>one of the first things you learn about </v>
<v Speaker 1>his blocks world,</v>

1446
01:25:16.410 --> 01:25:21.410
<v Speaker 1>it's kind of in the classic Ai Textbook.</v>
<v Speaker 1>I will tell you I've worked on that </v>

1447
01:25:22.711 --> 01:25:24.420
<v Speaker 1>problem in about three different </v>
<v Speaker 1>variants.</v>

1448
01:25:24.421 --> 01:25:29.421
<v Speaker 1>I've gone to many conferences where </v>
<v Speaker 1>presentations have been made about </v>

1449
01:25:29.421 --> 01:25:31.680
<v Speaker 1>blocks world,</v>
<v Speaker 1>which is to say we're good.</v>

1450
01:25:31.681 --> 01:25:35.450
<v Speaker 1>Progress is being made,</v>
<v Speaker 1>but the way you end up thinking about is</v>

1451
01:25:35.460 --> 01:25:38.340
<v Speaker 1>in really,</v>
<v Speaker 1>really small constrained problems.</v>

1452
01:25:38.341 --> 01:25:41.970
<v Speaker 1>Ironically you have this big vision,</v>
<v Speaker 1>but in order to make progress,</v>

1453
01:25:41.971 --> 01:25:45.150
<v Speaker 1>that ends up being on moving blocks on a</v>
<v Speaker 1>table.</v>

1454
01:25:45.570 --> 01:25:49.580
<v Speaker 1>And so it's.</v>
<v Speaker 1>It's a big challenge.</v>

1455
01:25:49.740 --> 01:25:54.740
<v Speaker 1>I just think it'll take a lot of time.</v>
<v Speaker 1>The I'll say the other thing they </v>

1456
01:25:54.910 --> 01:25:57.090
<v Speaker 1>haven't,</v>
<v Speaker 1>we haven't really gotten too.</v>

1457
01:25:57.091 --> 01:26:01.520
<v Speaker 1>Although I brought up spawn and I </v>
<v Speaker 1>brought up a sigma,</v>

1458
01:26:02.160 --> 01:26:04.160
<v Speaker 1>an idea of how scale this thing,</v>

1459
01:26:05.390 --> 01:26:10.390
<v Speaker 1>something I like about deep learning is </v>
<v Speaker 1>to some extent with lots of asterisks </v>

1460
01:26:10.401 --> 01:26:11.690
<v Speaker 1>and 10,000</v>
<v Speaker 1>foot view,</v>

1461
01:26:11.691 --> 01:26:12.770
<v Speaker 1>it's kind of like,</v>
<v Speaker 1>well,</v>

1462
01:26:13.040 --> 01:26:14.780
<v Speaker 1>we've gotten this far.</v>
<v Speaker 1>All right,</v>

1463
01:26:14.781 --> 01:26:16.880
<v Speaker 1>let's just provide a different inputs,</v>
<v Speaker 1>different outputs,</v>

1464
01:26:16.881 --> 01:26:21.881
<v Speaker 1>and we'll have some tricks on the middle</v>
<v Speaker 1>and suddenly you have end to end deep </v>

1465
01:26:21.881 --> 01:26:25.241
<v Speaker 1>learning,</v>
<v Speaker 1>but a bigger problem and a bigger </v>

1466
01:26:25.241 --> 01:26:26.441
<v Speaker 1>problem there.</v>
<v Speaker 1>There's a way to see how this expands </v>

1467
01:26:26.441 --> 01:26:29.231
<v Speaker 1>given enough data,</v>
<v Speaker 1>given her enough computing and </v>

1468
01:26:29.231 --> 01:26:30.530
<v Speaker 1>incremental advances.</v>
<v Speaker 1>When it comes to sore,</v>

1469
01:26:30.560 --> 01:26:35.560
<v Speaker 1>it takes not only a big idea,</v>
<v Speaker 1>but it takes a lot of software </v>

1470
01:26:35.560 --> 01:26:39.521
<v Speaker 1>engineering to integrate it.</v>
<v Speaker 1>There's a lot of constraints built into </v>

1471
01:26:39.521 --> 01:26:39.521
<v Speaker 1>it.</v>
<v Speaker 1>It,</v>

1472
01:26:39.521 --> 01:26:42.440
<v Speaker 1>it slows it down.</v>
<v Speaker 1>So something like sigma is a,</v>

1473
01:26:42.530 --> 01:26:45.890
<v Speaker 1>Oh well I can change a little bit of the</v>
<v Speaker 1>configuration of the graph.</v>

1474
01:26:45.891 --> 01:26:48.230
<v Speaker 1>I can use variance on the algorithm.</v>
<v Speaker 1>Boom.</v>

1475
01:26:48.350 --> 01:26:50.600
<v Speaker 1>It's integrated like an experiment </v>
<v Speaker 1>fairly quickly.</v>

1476
01:26:50.900 --> 01:26:55.900
<v Speaker 1>So starting with that sort of </v>
<v Speaker 1>infrastructure does not give you the </v>

1477
01:26:55.900 --> 01:27:00.831
<v Speaker 1>constraint.</v>
<v Speaker 1>You kind of want with your big picture </v>

1478
01:27:00.831 --> 01:27:03.501
<v Speaker 1>vision of going towards human level ai,</v>
<v Speaker 1>but in terms of being able to be agile </v>

1479
01:27:03.501 --> 01:27:04.020
<v Speaker 1>in your research,</v>
<v Speaker 1>it's,</v>

1480
01:27:04.021 --> 01:27:04.800
<v Speaker 1>it's kind of incredible.</v>

1481
01:27:05.180 --> 01:27:06.420
<v Speaker 2>I see.</v>
<v Speaker 2>Thank you.</v>

1482
01:27:07.380 --> 01:27:08.280
<v Speaker 2>A couple more.</v>

1483
01:27:09.660 --> 01:27:12.680
<v Speaker 8>You had mentioned that ideas such as </v>
<v Speaker 8>[inaudible] Kate,</v>

1484
01:27:12.910 --> 01:27:17.910
<v Speaker 8>these techniques,</v>
<v Speaker 8>they were based on the original </v>

1485
01:27:17.910 --> 01:27:20.471
<v Speaker 8>inspirations were based off of a human </v>
<v Speaker 8>cognition and because humans can't </v>

1486
01:27:20.471 --> 01:27:23.960
<v Speaker 8>remember everything.</v>
<v Speaker 8>So were there any instances of the other</v>

1487
01:27:23.961 --> 01:27:28.850
<v Speaker 8>way round where some discovery in </v>
<v Speaker 8>cognitive bottling fueled it?</v>

1488
01:27:28.910 --> 01:27:30.890
<v Speaker 8>Another discovery in cognitive science?</v>

1489
01:27:32.310 --> 01:27:35.310
<v Speaker 2>Uh,</v>
<v Speaker 2>so one thing I'm gonna</v>

1490
01:27:36.150 --> 01:27:41.150
<v Speaker 1>went out and your question was based </v>
<v Speaker 1>indicated with respect to human </v>

1491
01:27:41.150 --> 01:27:44.751
<v Speaker 1>cognition.</v>
<v Speaker 1>The study actually was let's look at </v>

1492
01:27:44.751 --> 01:27:47.871
<v Speaker 1>text and properties of text and use that</v>
<v Speaker 1>to then make predictions about what must</v>

1493
01:27:51.031 --> 01:27:56.031
<v Speaker 1>be true about human cognition.</v>
<v Speaker 1>So John Anderson and the other </v>

1494
01:27:56.251 --> 01:28:01.251
<v Speaker 1>researchers looked at,</v>
<v Speaker 1>I believe it was New York Times </v>

1495
01:28:01.251 --> 01:28:01.620
<v Speaker 1>articles,</v>

1496
01:28:03.980 --> 01:28:08.980
<v Speaker 1>his own John Anderson's emails,</v>
<v Speaker 1>and I'm trying to remember what the </v>

1497
01:28:08.980 --> 01:28:13.661
<v Speaker 1>third,</v>
<v Speaker 1>I think it was parents utterances with </v>

1498
01:28:13.661 --> 01:28:18.431
<v Speaker 1>their kids or something like this.</v>
<v Speaker 1>It was actually looking at text corpora </v>

1499
01:28:18.431 --> 01:28:22.090
<v Speaker 1>and the words that were occurring in a </v>
<v Speaker 1>varying frequencies that,</v>

1500
01:28:24.650 --> 01:28:29.650
<v Speaker 1>that analysis,</v>
<v Speaker 1>that rational analysis actually lead to </v>

1501
01:28:29.650 --> 01:28:33.310
<v Speaker 1>models that got integrated within the </v>
<v Speaker 1>act art architecture that then became </v>

1502
01:28:34.641 --> 01:28:39.641
<v Speaker 1>validated through multiple trials that </v>
<v Speaker 1>then became validated with respect to </v>

1503
01:28:39.641 --> 01:28:43.211
<v Speaker 1>Mri scans and is now being used to both </v>
<v Speaker 1>do study back with humans,</v>

1504
01:28:44.691 --> 01:28:48.320
<v Speaker 1>but also develop systems that interact </v>
<v Speaker 1>well with humans.</v>

1505
01:28:48.620 --> 01:28:52.580
<v Speaker 1>So I think that in and of itself ends up</v>
<v Speaker 1>being an example to cheat.</v>

1506
01:28:52.581 --> 01:28:57.581
<v Speaker 1>But the,</v>
<v Speaker 1>uh,</v>

1507
01:28:59.480 --> 01:29:02.490
<v Speaker 1>the UAV,</v>
<v Speaker 1>the sor UAV system,</v>

1508
01:29:02.520 --> 01:29:06.600
<v Speaker 9>I believe is a single robot that has a </v>
<v Speaker 9>multi,</v>

1509
01:29:06.630 --> 01:29:10.670
<v Speaker 9>multiple agents running on it.</v>
<v Speaker 9>So where is this?</v>

1510
01:29:12.840 --> 01:29:14.690
<v Speaker 9>I got it off your website.</v>
<v Speaker 9>Okay.</v>

1511
01:29:14.940 --> 01:29:18.320
<v Speaker 9>But either way,</v>
<v Speaker 9>your systems allow for multi agents.</v>

1512
01:29:18.380 --> 01:29:19.040
<v Speaker 9>Okay.</v>
<v Speaker 9>Uh,</v>

1513
01:29:19.120 --> 01:29:24.120
<v Speaker 9>so my question is how are you preventing</v>
<v Speaker 9>them from converging with new data and </v>

1514
01:29:24.661 --> 01:29:29.661
<v Speaker 9>are you changing what they're forgetting</v>
<v Speaker 9>selectively as one of those ways?</v>

1515
01:29:30.600 --> 01:29:35.600
<v Speaker 1>So I'll say yes,</v>
<v Speaker 1>you can have multiple source systems on </v>

1516
01:29:35.600 --> 01:29:39.171
<v Speaker 1>a single system or multiple systems.</v>
<v Speaker 1>There's not any real strong theory that </v>

1517
01:29:41.341 --> 01:29:45.110
<v Speaker 1>relates to multi agent system.</v>
<v Speaker 1>So there's no real constraint there that</v>

1518
01:29:45.300 --> 01:29:47.670
<v Speaker 1>you can come up with a protocol for them</v>
<v Speaker 1>interacting.</v>

1519
01:29:48.810 --> 01:29:52.500
<v Speaker 1>Each one is going to have its own set of</v>
<v Speaker 1>memories,</v>

1520
01:29:52.501 --> 01:29:57.501
<v Speaker 1>set of knowledge.</v>
<v Speaker 1>There really is no constraint on you </v>

1521
01:29:57.501 --> 01:30:01.131
<v Speaker 1>being able to communicate like you would</v>
<v Speaker 1>if it were any other system interacting </v>

1522
01:30:01.131 --> 01:30:05.811
<v Speaker 1>with sore.</v>
<v Speaker 1>So I don't really think I have a great </v>

1523
01:30:05.811 --> 01:30:05.811
<v Speaker 1>answer for it.</v>
<v Speaker 1>Okay.</v>

1524
01:30:06.660 --> 01:30:10.530
<v Speaker 1>So that is to say if,</v>
<v Speaker 1>if you had good theories,</v>

1525
01:30:10.531 --> 01:30:15.531
<v Speaker 1>good algorithms about how systems work </v>
<v Speaker 1>and how they can bring knowledge </v>

1526
01:30:15.961 --> 01:30:20.961
<v Speaker 1>together form of fusion sort of way.</v>
<v Speaker 1>It might be something that you could </v>

1527
01:30:22.231 --> 01:30:27.231
<v Speaker 1>bring to a multiagent source system,</v>
<v Speaker 1>but there's nothing really there to help</v>

1528
01:30:27.271 --> 01:30:32.271
<v Speaker 1>you.</v>
<v Speaker 1>There's no mechanisms there really to </v>

1529
01:30:32.271 --> 01:30:32.271
<v Speaker 1>help you do that any better than you </v>
<v Speaker 1>would otherwise.</v>

1530
01:30:32.271 --> 01:30:36.770
<v Speaker 1>And you would have to kind of </v>
<v Speaker 1>constraints on your representations of </v>

1531
01:30:36.811 --> 01:30:41.811
<v Speaker 1>processes to what it has fixed in terms </v>
<v Speaker 1>of it's sort of memory and it's sort of </v>

1532
01:30:41.811 --> 01:30:42.220
<v Speaker 1>processing cycle.</v>
<v Speaker 1>Okay.</v>

1533
01:30:42.960 --> 01:30:43.410
<v Speaker 1>Thank you.</v>

1534
01:30:45.510 --> 01:30:50.510
<v Speaker 5>Thank you.</v>

